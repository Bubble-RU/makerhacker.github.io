<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>70 nips-2013-Contrastive Learning Using Spectral Methods</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-70" href="#">nips2013-70</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>70 nips-2013-Contrastive Learning Using Spectral Methods</h1>
<br/><p>Source: <a title="nips-2013-70-pdf" href="http://papers.nips.cc/paper/5007-contrastive-learning-using-spectral-methods.pdf">pdf</a></p><p>Author: James Y. Zou, Daniel Hsu, David C. Parkes, Ryan P. Adams</p><p>Abstract: In many natural settings, the analysis goal is not to characterize a single data set in isolation, but rather to understand the difference between one set of observations and another. For example, given a background corpus of news articles together with writings of a particular author, one may want a topic model that explains word patterns and themes speciﬁc to the author. Another example comes from genomics, in which biological signals may be collected from different regions of a genome, and one wants a model that captures the differential statistics observed in these regions. This paper formalizes this notion of contrastive learning for mixture models, and develops spectral algorithms for inferring mixture components speciﬁc to a foreground data set when contrasted with a background data set. The method builds on recent moment-based estimators and tensor decompositions for latent variable models, and has the intuitive feature of using background data statistics to appropriately modify moments estimated from foreground data. A key advantage of the method is that the background data need only be coarsely modeled, which is important when the background is too complex, noisy, or not of interest. The method is demonstrated on applications in contrastive topic modeling and genomic sequence analysis. 1</p><p>Reference: <a title="nips-2013-70-reference" href="../nips2013_reference/nips-2013-Contrastive_Learning_Using_Spectral_Methods_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('foreground', 0.719), ('cn', 0.285), ('background', 0.255), ('xf', 0.219), ('chromatin', 0.191), ('tens', 0.161), ('docu', 0.142), ('top', 0.135), ('mom', 0.132), ('contrast', 0.11), ('genom', 0.103), ('wj', 0.1), ('chin', 0.085), ('hmm', 0.084), ('wt', 0.08), ('hmma', 0.077), ('hmmb', 0.077), ('topicsf', 0.077), ('xb', 0.072), ('proposit', 0.069)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="70-tfidf-1" href="./nips-2013-Contrastive_Learning_Using_Spectral_Methods.html">70 nips-2013-Contrastive Learning Using Spectral Methods</a></p>
<p>2 0.19610761 <a title="70-tfidf-2" href="./nips-2013-Learning_Hidden_Markov_Models_from_Non-sequence_Data_via_Tensor_Decomposition.html">155 nips-2013-Learning Hidden Markov Models from Non-sequence Data via Tensor Decomposition</a></p>
<p>3 0.14436741 <a title="70-tfidf-3" href="./nips-2013-A_New_Convex_Relaxation_for_Tensor_Completion.html">11 nips-2013-A New Convex Relaxation for Tensor Completion</a></p>
<p>4 0.12146072 <a title="70-tfidf-4" href="./nips-2013-Convex_Tensor_Decomposition_via_Structured_Schatten_Norm_Regularization.html">74 nips-2013-Convex Tensor Decomposition via Structured Schatten Norm Regularization</a></p>
<p>5 0.12046427 <a title="70-tfidf-5" href="./nips-2013-Exact_and_Stable_Recovery_of_Pairwise_Interaction_Tensors.html">113 nips-2013-Exact and Stable Recovery of Pairwise Interaction Tensors</a></p>
<p>6 0.11861979 <a title="70-tfidf-6" href="./nips-2013-When_are_Overcomplete_Topic_Models_Identifiable%3F_Uniqueness_of_Tensor_Tucker_Decompositions_with_Structured_Sparsity.html">353 nips-2013-When are Overcomplete Topic Models Identifiable? Uniqueness of Tensor Tucker Decompositions with Structured Sparsity</a></p>
<p>7 0.11346356 <a title="70-tfidf-7" href="./nips-2013-Simultaneous_Rectification_and_Alignment_via_Robust_Recovery_of_Low-rank_Tensors.html">295 nips-2013-Simultaneous Rectification and Alignment via Robust Recovery of Low-rank Tensors</a></p>
<p>8 0.10261925 <a title="70-tfidf-8" href="./nips-2013-Sparse_Additive_Text_Models_with_Low_Rank_Background.html">301 nips-2013-Sparse Additive Text Models with Low Rank Background</a></p>
<p>9 0.099491164 <a title="70-tfidf-9" href="./nips-2013-Low-Rank_Matrix_and_Tensor_Completion_via_Adaptive_Sampling.html">179 nips-2013-Low-Rank Matrix and Tensor Completion via Adaptive Sampling</a></p>
<p>10 0.092912801 <a title="70-tfidf-10" href="./nips-2013-Multilinear_Dynamical_Systems_for_Tensor_Time_Series.html">203 nips-2013-Multilinear Dynamical Systems for Tensor Time Series</a></p>
<p>11 0.091383003 <a title="70-tfidf-11" href="./nips-2013-On_the_Sample_Complexity_of_Subspace_Learning.html">224 nips-2013-On the Sample Complexity of Subspace Learning</a></p>
<p>12 0.087441318 <a title="70-tfidf-12" href="./nips-2013-Compressive_Feature_Learning.html">65 nips-2013-Compressive Feature Learning</a></p>
<p>13 0.083703622 <a title="70-tfidf-13" href="./nips-2013-Learning_Stochastic_Feedforward_Neural_Networks.html">160 nips-2013-Learning Stochastic Feedforward Neural Networks</a></p>
<p>14 0.07762365 <a title="70-tfidf-14" href="./nips-2013-Phase_Retrieval_using_Alternating_Minimization.html">247 nips-2013-Phase Retrieval using Alternating Minimization</a></p>
<p>15 0.075448565 <a title="70-tfidf-15" href="./nips-2013-Stochastic_Convex_Optimization_with_Multiple__Objectives.html">311 nips-2013-Stochastic Convex Optimization with Multiple  Objectives</a></p>
<p>16 0.073168002 <a title="70-tfidf-16" href="./nips-2013-Reasoning_With_Neural_Tensor_Networks_for_Knowledge_Base_Completion.html">263 nips-2013-Reasoning With Neural Tensor Networks for Knowledge Base Completion</a></p>
<p>17 0.070728846 <a title="70-tfidf-17" href="./nips-2013-Modeling_Clutter_Perception_using_Parametric_Proto-object_Partitioning.html">195 nips-2013-Modeling Clutter Perception using Parametric Proto-object Partitioning</a></p>
<p>18 0.067877553 <a title="70-tfidf-18" href="./nips-2013-Small-Variance_Asymptotics_for_Hidden_Markov_Models.html">298 nips-2013-Small-Variance Asymptotics for Hidden Markov Models</a></p>
<p>19 0.067378618 <a title="70-tfidf-19" href="./nips-2013-Speeding_up_Permutation_Testing_in_Neuroimaging.html">306 nips-2013-Speeding up Permutation Testing in Neuroimaging</a></p>
<p>20 0.066438191 <a title="70-tfidf-20" href="./nips-2013-Robust_Low_Rank_Kernel_Embeddings_of_Multivariate_Distributions.html">281 nips-2013-Robust Low Rank Kernel Embeddings of Multivariate Distributions</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.142), (1, 0.072), (2, 0.096), (3, -0.079), (4, 0.123), (5, -0.066), (6, 0.004), (7, -0.026), (8, 0.031), (9, -0.057), (10, -0.071), (11, 0.054), (12, -0.022), (13, 0.012), (14, -0.004), (15, 0.037), (16, 0.024), (17, 0.025), (18, -0.023), (19, 0.006), (20, -0.043), (21, -0.015), (22, -0.057), (23, -0.015), (24, -0.057), (25, 0.043), (26, 0.023), (27, 0.003), (28, -0.003), (29, -0.048), (30, 0.021), (31, -0.079), (32, 0.114), (33, 0.034), (34, 0.003), (35, 0.004), (36, 0.006), (37, -0.126), (38, 0.018), (39, -0.086), (40, 0.069), (41, -0.071), (42, -0.008), (43, -0.028), (44, -0.071), (45, 0.007), (46, 0.02), (47, 0.073), (48, 0.099), (49, 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92232561 <a title="70-lsi-1" href="./nips-2013-Contrastive_Learning_Using_Spectral_Methods.html">70 nips-2013-Contrastive Learning Using Spectral Methods</a></p>
<p>2 0.73151058 <a title="70-lsi-2" href="./nips-2013-When_are_Overcomplete_Topic_Models_Identifiable%3F_Uniqueness_of_Tensor_Tucker_Decompositions_with_Structured_Sparsity.html">353 nips-2013-When are Overcomplete Topic Models Identifiable? Uniqueness of Tensor Tucker Decompositions with Structured Sparsity</a></p>
<p>3 0.66942126 <a title="70-lsi-3" href="./nips-2013-Learning_Hidden_Markov_Models_from_Non-sequence_Data_via_Tensor_Decomposition.html">155 nips-2013-Learning Hidden Markov Models from Non-sequence Data via Tensor Decomposition</a></p>
<p>4 0.58120388 <a title="70-lsi-4" href="./nips-2013-Multilinear_Dynamical_Systems_for_Tensor_Time_Series.html">203 nips-2013-Multilinear Dynamical Systems for Tensor Time Series</a></p>
<p>5 0.57281077 <a title="70-lsi-5" href="./nips-2013-Sparse_Additive_Text_Models_with_Low_Rank_Background.html">301 nips-2013-Sparse Additive Text Models with Low Rank Background</a></p>
<p>6 0.55740893 <a title="70-lsi-6" href="./nips-2013-Exact_and_Stable_Recovery_of_Pairwise_Interaction_Tensors.html">113 nips-2013-Exact and Stable Recovery of Pairwise Interaction Tensors</a></p>
<p>7 0.55489302 <a title="70-lsi-7" href="./nips-2013-Lexical_and_Hierarchical_Topic_Regression.html">174 nips-2013-Lexical and Hierarchical Topic Regression</a></p>
<p>8 0.54933482 <a title="70-lsi-8" href="./nips-2013-Documents_as_multiple_overlapping_windows_into_grids_of_counts.html">98 nips-2013-Documents as multiple overlapping windows into grids of counts</a></p>
<p>9 0.54849821 <a title="70-lsi-9" href="./nips-2013-Simultaneous_Rectification_and_Alignment_via_Robust_Recovery_of_Low-rank_Tensors.html">295 nips-2013-Simultaneous Rectification and Alignment via Robust Recovery of Low-rank Tensors</a></p>
<p>10 0.54693896 <a title="70-lsi-10" href="./nips-2013-Convex_Tensor_Decomposition_via_Structured_Schatten_Norm_Regularization.html">74 nips-2013-Convex Tensor Decomposition via Structured Schatten Norm Regularization</a></p>
<p>11 0.52704042 <a title="70-lsi-11" href="./nips-2013-A_New_Convex_Relaxation_for_Tensor_Completion.html">11 nips-2013-A New Convex Relaxation for Tensor Completion</a></p>
<p>12 0.51946777 <a title="70-lsi-12" href="./nips-2013-Scalable_Inference_for_Logistic-Normal_Topic_Models.html">287 nips-2013-Scalable Inference for Logistic-Normal Topic Models</a></p>
<p>13 0.49429891 <a title="70-lsi-13" href="./nips-2013-Discovering_Hidden_Variables_in_Noisy-Or_Networks_using_Quartet_Tests.html">92 nips-2013-Discovering Hidden Variables in Noisy-Or Networks using Quartet Tests</a></p>
<p>14 0.48416209 <a title="70-lsi-14" href="./nips-2013-Compressive_Feature_Learning.html">65 nips-2013-Compressive Feature Learning</a></p>
<p>15 0.47253007 <a title="70-lsi-15" href="./nips-2013-Stochastic_Gradient_Riemannian_Langevin_Dynamics_on_the_Probability_Simplex.html">312 nips-2013-Stochastic Gradient Riemannian Langevin Dynamics on the Probability Simplex</a></p>
<p>16 0.47227249 <a title="70-lsi-16" href="./nips-2013-Variance_Reduction_for_Stochastic_Gradient_Optimization.html">345 nips-2013-Variance Reduction for Stochastic Gradient Optimization</a></p>
<p>17 0.46827781 <a title="70-lsi-17" href="./nips-2013-Relevance_Topic_Model_for_Unstructured_Social_Group_Activity_Recognition.html">274 nips-2013-Relevance Topic Model for Unstructured Social Group Activity Recognition</a></p>
<p>18 0.45105112 <a title="70-lsi-18" href="./nips-2013-Annealing_between_distributions_by_averaging_moments.html">36 nips-2013-Annealing between distributions by averaging moments</a></p>
<p>19 0.44678447 <a title="70-lsi-19" href="./nips-2013-Similarity_Component_Analysis.html">294 nips-2013-Similarity Component Analysis</a></p>
<p>20 0.44610557 <a title="70-lsi-20" href="./nips-2013-Designed_Measurements_for_Vector_Count_Data.html">88 nips-2013-Designed Measurements for Vector Count Data</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(6, 0.041), (20, 0.16), (25, 0.066), (30, 0.144), (37, 0.078), (69, 0.01), (70, 0.046), (80, 0.124), (86, 0.128), (87, 0.076)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.94595647 <a title="70-lda-1" href="./nips-2013-Multilinear_Dynamical_Systems_for_Tensor_Time_Series.html">203 nips-2013-Multilinear Dynamical Systems for Tensor Time Series</a></p>
<p>2 0.93905556 <a title="70-lda-2" href="./nips-2013-Probabilistic_Principal_Geodesic_Analysis.html">256 nips-2013-Probabilistic Principal Geodesic Analysis</a></p>
<p>3 0.90986246 <a title="70-lda-3" href="./nips-2013-Inferring_neural_population_dynamics_from_multiple_partial_recordings_of_the_same_neural_circuit.html">141 nips-2013-Inferring neural population dynamics from multiple partial recordings of the same neural circuit</a></p>
<p>same-paper 4 0.90552622 <a title="70-lda-4" href="./nips-2013-Contrastive_Learning_Using_Spectral_Methods.html">70 nips-2013-Contrastive Learning Using Spectral Methods</a></p>
<p>5 0.89490628 <a title="70-lda-5" href="./nips-2013-Predictive_PAC_Learning_and_Process_Decompositions.html">252 nips-2013-Predictive PAC Learning and Process Decompositions</a></p>
<p>6 0.87298888 <a title="70-lda-6" href="./nips-2013-Memory_Limited%2C_Streaming_PCA.html">188 nips-2013-Memory Limited, Streaming PCA</a></p>
<p>7 0.86641484 <a title="70-lda-7" href="./nips-2013-Estimating_the_Unseen%3A_Improved_Estimators_for_Entropy_and_other_Properties.html">110 nips-2013-Estimating the Unseen: Improved Estimators for Entropy and other Properties</a></p>
<p>8 0.86587411 <a title="70-lda-8" href="./nips-2013-Multiscale_Dictionary_Learning_for_Estimating_Conditional_Distributions.html">204 nips-2013-Multiscale Dictionary Learning for Estimating Conditional Distributions</a></p>
<p>9 0.86500752 <a title="70-lda-9" href="./nips-2013-Real-Time_Inference_for_a_Gamma_Process_Model_of_Neural_Spiking.html">262 nips-2013-Real-Time Inference for a Gamma Process Model of Neural Spiking</a></p>
<p>10 0.8633728 <a title="70-lda-10" href="./nips-2013-Online_Learning_of_Nonparametric_Mixture_Models_via_Sequential_Variational_Approximation.html">229 nips-2013-Online Learning of Nonparametric Mixture Models via Sequential Variational Approximation</a></p>
<p>11 0.8623687 <a title="70-lda-11" href="./nips-2013-On_Sampling_from_the_Gibbs_Distribution_with_Random_Maximum_A-Posteriori_Perturbations.html">218 nips-2013-On Sampling from the Gibbs Distribution with Random Maximum A-Posteriori Perturbations</a></p>
<p>12 0.8620019 <a title="70-lda-12" href="./nips-2013-Statistical_analysis_of_coupled_time_series_with_Kernel_Cross-Spectral_Density_operators..html">310 nips-2013-Statistical analysis of coupled time series with Kernel Cross-Spectral Density operators.</a></p>
<p>13 0.86179775 <a title="70-lda-13" href="./nips-2013-Two-Target_Algorithms__for_Infinite-Armed___Bandits_with_Bernoulli_Rewards.html">338 nips-2013-Two-Target Algorithms  for Infinite-Armed   Bandits with Bernoulli Rewards</a></p>
<p>14 0.86162382 <a title="70-lda-14" href="./nips-2013-Learning_to_Pass_Expectation_Propagation_Messages.html">168 nips-2013-Learning to Pass Expectation Propagation Messages</a></p>
<p>15 0.86148751 <a title="70-lda-15" href="./nips-2013-Computing_the_Stationary_Distribution_Locally.html">66 nips-2013-Computing the Stationary Distribution Locally</a></p>
<p>16 0.86106753 <a title="70-lda-16" href="./nips-2013-Sparse_nonnegative_deconvolution_for_compressive_calcium_imaging%3A_algorithms_and_phase_transitions.html">304 nips-2013-Sparse nonnegative deconvolution for compressive calcium imaging: algorithms and phase transitions</a></p>
<p>17 0.86089587 <a title="70-lda-17" href="./nips-2013-Spike_train_entropy-rate_estimation_using_hierarchical_Dirichlet_process_priors.html">308 nips-2013-Spike train entropy-rate estimation using hierarchical Dirichlet process priors</a></p>
<p>18 0.86078912 <a title="70-lda-18" href="./nips-2013-Learning_Hidden_Markov_Models_from_Non-sequence_Data_via_Tensor_Decomposition.html">155 nips-2013-Learning Hidden Markov Models from Non-sequence Data via Tensor Decomposition</a></p>
<p>19 0.86076295 <a title="70-lda-19" href="./nips-2013-Dynamic_Clustering_via_Asymptotics_of_the_Dependent_Dirichlet_Process_Mixture.html">100 nips-2013-Dynamic Clustering via Asymptotics of the Dependent Dirichlet Process Mixture</a></p>
<p>20 0.86043674 <a title="70-lda-20" href="./nips-2013-A_Determinantal_Point_Process_Latent_Variable_Model_for_Inhibition_in_Neural_Spiking_Data.html">6 nips-2013-A Determinantal Point Process Latent Variable Model for Inhibition in Neural Spiking Data</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
