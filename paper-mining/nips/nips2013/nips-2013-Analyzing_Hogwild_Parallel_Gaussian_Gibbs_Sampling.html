<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>34 nips-2013-Analyzing Hogwild Parallel Gaussian Gibbs Sampling</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-34" href="#">nips2013-34</a> knowledge-graph by maker-knowledge-mining</p><h1>34 nips-2013-Analyzing Hogwild Parallel Gaussian Gibbs Sampling</h1>
<br/><p>Source: <a title="nips-2013-34-pdf" href="http://papers.nips.cc/paper/5043-analyzing-hogwild-parallel-gaussian-gibbs-sampling.pdf">pdf</a></p><p>Author: Matthew Johnson, James Saunderson, Alan Willsky</p><p>Abstract: Sampling inference methods are computationally difﬁcult to scale for many models in part because global dependencies can reduce opportunities for parallel computation. Without strict conditional independence structure among variables, standard Gibbs sampling theory requires sample updates to be performed sequentially, even if dependence between most variables is not strong. Empirical work has shown that some models can be sampled effectively by going “Hogwild” and simply running Gibbs updates in parallel with only periodic global communication, but the successes and limitations of such a strategy are not well understood. As a step towards such an understanding, we study the Hogwild Gibbs sampling strategy in the context of Gaussian distributions. We develop a framework which provides convergence conditions and error bounds along with simple proofs and connections to methods in numerical linear algebra. In particular, we show that if the Gaussian precision matrix is generalized diagonally dominant, then any Hogwild Gibbs sampler, with any update schedule or allocation of variables to processors, yields a stable sampling process with the correct sample mean. 1</p><p>Reference: <a title="nips-2013-34-reference" href="../nips2013_reference/nips-2013-Analyzing_Hogwild_Parallel_Gaussian_Gibbs_Sampling_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('hogwild', 0.771), ('gib', 0.333), ('hog', 0.259), ('lift', 0.169), ('tblock', 0.137), ('parallel', 0.106), ('block', 0.105), ('diagon', 0.101), ('tind', 0.098), ('splitting', 0.092), ('gauss', 0.076), ('proposit', 0.075), ('stabl', 0.072), ('upd', 0.067), ('jacob', 0.066), ('it', 0.062), ('synchron', 0.06), ('dblock', 0.059), ('lds', 0.057), ('sampl', 0.055)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="34-tfidf-1" href="./nips-2013-Analyzing_Hogwild_Parallel_Gaussian_Gibbs_Sampling.html">34 nips-2013-Analyzing Hogwild Parallel Gaussian Gibbs Sampling</a></p>
<p>2 0.20838983 <a title="34-tfidf-2" href="./nips-2013-On_Sampling_from_the_Gibbs_Distribution_with_Random_Maximum_A-Posteriori_Perturbations.html">218 nips-2013-On Sampling from the Gibbs Distribution with Random Maximum A-Posteriori Perturbations</a></p>
<p>3 0.12968363 <a title="34-tfidf-3" href="./nips-2013-Projecting_Ising_Model_Parameters_for_Fast_Mixing.html">258 nips-2013-Projecting Ising Model Parameters for Fast Mixing</a></p>
<p>4 0.11718214 <a title="34-tfidf-4" href="./nips-2013-First-order_Decomposition_Trees.html">122 nips-2013-First-order Decomposition Trees</a></p>
<p>5 0.11683534 <a title="34-tfidf-5" href="./nips-2013-Bayesian_Estimation_of_Latently-grouped_Parameters_in_Undirected_Graphical_Models.html">46 nips-2013-Bayesian Estimation of Latently-grouped Parameters in Undirected Graphical Models</a></p>
<p>6 0.099348716 <a title="34-tfidf-6" href="./nips-2013-On_the_Complexity_and_Approximation_of_Binary_Evidence_in_Lifted_Inference.html">220 nips-2013-On the Complexity and Approximation of Binary Evidence in Lifted Inference</a></p>
<p>7 0.098285325 <a title="34-tfidf-7" href="./nips-2013-Active_Learning_for_Probabilistic_Hypotheses_Using_the_Maximum_Gibbs_Error_Criterion.html">23 nips-2013-Active Learning for Probabilistic Hypotheses Using the Maximum Gibbs Error Criterion</a></p>
<p>8 0.09513256 <a title="34-tfidf-8" href="./nips-2013-Large_Scale_Distributed_Sparse_Precision_Estimation.html">146 nips-2013-Large Scale Distributed Sparse Precision Estimation</a></p>
<p>9 0.092829086 <a title="34-tfidf-9" href="./nips-2013-Parallel_Sampling_of_DP_Mixture_Models_using_Sub-Cluster_Splits.html">243 nips-2013-Parallel Sampling of DP Mixture Models using Sub-Cluster Splits</a></p>
<p>10 0.091147065 <a title="34-tfidf-10" href="./nips-2013-Fast_Template_Evaluation_with_Vector_Quantization.html">119 nips-2013-Fast Template Evaluation with Vector Quantization</a></p>
<p>11 0.071510896 <a title="34-tfidf-11" href="./nips-2013-Learning_Stochastic_Inverses.html">161 nips-2013-Learning Stochastic Inverses</a></p>
<p>12 0.062919579 <a title="34-tfidf-12" href="./nips-2013-Dynamic_Clustering_via_Asymptotics_of_the_Dependent_Dirichlet_Process_Mixture.html">100 nips-2013-Dynamic Clustering via Asymptotics of the Dependent Dirichlet Process Mixture</a></p>
<p>13 0.062832922 <a title="34-tfidf-13" href="./nips-2013-Optimistic_Concurrency_Control_for_Distributed_Unsupervised_Learning.html">238 nips-2013-Optimistic Concurrency Control for Distributed Unsupervised Learning</a></p>
<p>14 0.059512932 <a title="34-tfidf-14" href="./nips-2013-Wavelets_on_Graphs_via_Deep_Learning.html">350 nips-2013-Wavelets on Graphs via Deep Learning</a></p>
<p>15 0.056510434 <a title="34-tfidf-15" href="./nips-2013-A_Scalable_Approach_to_Probabilistic_Latent_Space_Inference_of_Large-Scale_Networks.html">13 nips-2013-A Scalable Approach to Probabilistic Latent Space Inference of Large-Scale Networks</a></p>
<p>16 0.056160092 <a title="34-tfidf-16" href="./nips-2013-Streaming_Variational_Bayes.html">317 nips-2013-Streaming Variational Bayes</a></p>
<p>17 0.052352693 <a title="34-tfidf-17" href="./nips-2013-Stochastic_Gradient_Riemannian_Langevin_Dynamics_on_the_Probability_Simplex.html">312 nips-2013-Stochastic Gradient Riemannian Langevin Dynamics on the Probability Simplex</a></p>
<p>18 0.05196825 <a title="34-tfidf-18" href="./nips-2013-Summary_Statistics_for_Partitionings_and_Feature_Allocations.html">320 nips-2013-Summary Statistics for Partitionings and Feature Allocations</a></p>
<p>19 0.050989185 <a title="34-tfidf-19" href="./nips-2013-Memory_Limited%2C_Streaming_PCA.html">188 nips-2013-Memory Limited, Streaming PCA</a></p>
<p>20 0.050896011 <a title="34-tfidf-20" href="./nips-2013-Solving_the_multi-way_matching_problem_by_permutation_synchronization.html">300 nips-2013-Solving the multi-way matching problem by permutation synchronization</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.142), (1, 0.04), (2, 0.029), (3, -0.036), (4, -0.046), (5, 0.064), (6, 0.012), (7, 0.036), (8, 0.026), (9, -0.084), (10, -0.006), (11, 0.088), (12, -0.0), (13, 0.052), (14, 0.025), (15, 0.009), (16, 0.05), (17, -0.06), (18, 0.032), (19, 0.052), (20, 0.103), (21, -0.016), (22, 0.049), (23, 0.052), (24, 0.058), (25, -0.007), (26, -0.071), (27, -0.053), (28, -0.058), (29, -0.126), (30, -0.135), (31, -0.033), (32, -0.0), (33, -0.065), (34, -0.157), (35, -0.028), (36, 0.086), (37, 0.112), (38, 0.066), (39, -0.23), (40, 0.057), (41, 0.003), (42, 0.047), (43, 0.079), (44, 0.024), (45, -0.023), (46, -0.016), (47, -0.007), (48, -0.002), (49, 0.061)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.89824319 <a title="34-lsi-1" href="./nips-2013-Analyzing_Hogwild_Parallel_Gaussian_Gibbs_Sampling.html">34 nips-2013-Analyzing Hogwild Parallel Gaussian Gibbs Sampling</a></p>
<p>2 0.69203752 <a title="34-lsi-2" href="./nips-2013-On_Sampling_from_the_Gibbs_Distribution_with_Random_Maximum_A-Posteriori_Perturbations.html">218 nips-2013-On Sampling from the Gibbs Distribution with Random Maximum A-Posteriori Perturbations</a></p>
<p>3 0.64525074 <a title="34-lsi-3" href="./nips-2013-On_the_Complexity_and_Approximation_of_Binary_Evidence_in_Lifted_Inference.html">220 nips-2013-On the Complexity and Approximation of Binary Evidence in Lifted Inference</a></p>
<p>4 0.64261335 <a title="34-lsi-4" href="./nips-2013-Projecting_Ising_Model_Parameters_for_Fast_Mixing.html">258 nips-2013-Projecting Ising Model Parameters for Fast Mixing</a></p>
<p>5 0.64016533 <a title="34-lsi-5" href="./nips-2013-First-order_Decomposition_Trees.html">122 nips-2013-First-order Decomposition Trees</a></p>
<p>6 0.62957853 <a title="34-lsi-6" href="./nips-2013-Bayesian_Estimation_of_Latently-grouped_Parameters_in_Undirected_Graphical_Models.html">46 nips-2013-Bayesian Estimation of Latently-grouped Parameters in Undirected Graphical Models</a></p>
<p>7 0.5868867 <a title="34-lsi-7" href="./nips-2013-Wavelets_on_Graphs_via_Deep_Learning.html">350 nips-2013-Wavelets on Graphs via Deep Learning</a></p>
<p>8 0.52538341 <a title="34-lsi-8" href="./nips-2013-Learning_Stochastic_Inverses.html">161 nips-2013-Learning Stochastic Inverses</a></p>
<p>9 0.47495604 <a title="34-lsi-9" href="./nips-2013-Scalable_Inference_for_Logistic-Normal_Topic_Models.html">287 nips-2013-Scalable Inference for Logistic-Normal Topic Models</a></p>
<p>10 0.45809245 <a title="34-lsi-10" href="./nips-2013-Embed_and_Project%3A_Discrete_Sampling_with_Universal_Hashing.html">107 nips-2013-Embed and Project: Discrete Sampling with Universal Hashing</a></p>
<p>11 0.44723779 <a title="34-lsi-11" href="./nips-2013-Parallel_Sampling_of_DP_Mixture_Models_using_Sub-Cluster_Splits.html">243 nips-2013-Parallel Sampling of DP Mixture Models using Sub-Cluster Splits</a></p>
<p>12 0.44601983 <a title="34-lsi-12" href="./nips-2013-Large_Scale_Distributed_Sparse_Precision_Estimation.html">146 nips-2013-Large Scale Distributed Sparse Precision Estimation</a></p>
<p>13 0.44022998 <a title="34-lsi-13" href="./nips-2013-Summary_Statistics_for_Partitionings_and_Feature_Allocations.html">320 nips-2013-Summary Statistics for Partitionings and Feature Allocations</a></p>
<p>14 0.43244249 <a title="34-lsi-14" href="./nips-2013-Bayesian_inference_for_low_rank_spatiotemporal_neural_receptive_fields.html">53 nips-2013-Bayesian inference for low rank spatiotemporal neural receptive fields</a></p>
<p>15 0.42512739 <a title="34-lsi-15" href="./nips-2013-Stochastic_Gradient_Riemannian_Langevin_Dynamics_on_the_Probability_Simplex.html">312 nips-2013-Stochastic Gradient Riemannian Langevin Dynamics on the Probability Simplex</a></p>
<p>16 0.42441088 <a title="34-lsi-16" href="./nips-2013-Multiscale_Dictionary_Learning_for_Estimating_Conditional_Distributions.html">204 nips-2013-Multiscale Dictionary Learning for Estimating Conditional Distributions</a></p>
<p>17 0.42356133 <a title="34-lsi-17" href="./nips-2013-Marginals-to-Models_Reducibility.html">184 nips-2013-Marginals-to-Models Reducibility</a></p>
<p>18 0.41134688 <a title="34-lsi-18" href="./nips-2013-BIG_%26_QUIC%3A_Sparse_Inverse_Covariance_Estimation_for_a_Million_Variables.html">45 nips-2013-BIG & QUIC: Sparse Inverse Covariance Estimation for a Million Variables</a></p>
<p>19 0.4056491 <a title="34-lsi-19" href="./nips-2013-What_do_row_and_column_marginals_reveal_about_your_dataset%3F.html">352 nips-2013-What do row and column marginals reveal about your dataset?</a></p>
<p>20 0.4028967 <a title="34-lsi-20" href="./nips-2013-A_Scalable_Approach_to_Probabilistic_Latent_Space_Inference_of_Large-Scale_Networks.html">13 nips-2013-A Scalable Approach to Probabilistic Latent Space Inference of Large-Scale Networks</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(15, 0.243), (20, 0.185), (25, 0.095), (37, 0.049), (47, 0.011), (70, 0.032), (80, 0.114), (86, 0.09), (87, 0.057)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.80368131 <a title="34-lda-1" href="./nips-2013-Analyzing_Hogwild_Parallel_Gaussian_Gibbs_Sampling.html">34 nips-2013-Analyzing Hogwild Parallel Gaussian Gibbs Sampling</a></p>
<p>2 0.73545319 <a title="34-lda-2" href="./nips-2013-Learning_Multiple_Models_via_Regularized_Weighting.html">158 nips-2013-Learning Multiple Models via Regularized Weighting</a></p>
<p>3 0.73310357 <a title="34-lda-3" href="./nips-2013-Which_Space_Partitioning_Tree_to_Use_for_Search%3F.html">355 nips-2013-Which Space Partitioning Tree to Use for Search?</a></p>
<p>4 0.73111969 <a title="34-lda-4" href="./nips-2013-Robust_learning_of_low-dimensional_dynamics_from_large_neural_ensembles.html">286 nips-2013-Robust learning of low-dimensional dynamics from large neural ensembles</a></p>
<p>5 0.73088956 <a title="34-lda-5" href="./nips-2013-Variational_Inference_for_Mahalanobis_Distance_Metrics_in_Gaussian_Process_Regression.html">346 nips-2013-Variational Inference for Mahalanobis Distance Metrics in Gaussian Process Regression</a></p>
<p>6 0.73037899 <a title="34-lda-6" href="./nips-2013-Multi-Task_Bayesian_Optimization.html">201 nips-2013-Multi-Task Bayesian Optimization</a></p>
<p>7 0.73020113 <a title="34-lda-7" href="./nips-2013-One-shot_learning_by_inverting_a_compositional_causal_process.html">226 nips-2013-One-shot learning by inverting a compositional causal process</a></p>
<p>8 0.73003346 <a title="34-lda-8" href="./nips-2013-What_do_row_and_column_marginals_reveal_about_your_dataset%3F.html">352 nips-2013-What do row and column marginals reveal about your dataset?</a></p>
<p>9 0.72975737 <a title="34-lda-9" href="./nips-2013-Optimal_Neural_Population_Codes_for_High-dimensional_Stimulus_Variables.html">236 nips-2013-Optimal Neural Population Codes for High-dimensional Stimulus Variables</a></p>
<p>10 0.72966546 <a title="34-lda-10" href="./nips-2013-Optimistic_Concurrency_Control_for_Distributed_Unsupervised_Learning.html">238 nips-2013-Optimistic Concurrency Control for Distributed Unsupervised Learning</a></p>
<p>11 0.72966105 <a title="34-lda-11" href="./nips-2013-Supervised_Sparse_Analysis_and_Synthesis_Operators.html">321 nips-2013-Supervised Sparse Analysis and Synthesis Operators</a></p>
<p>12 0.72965813 <a title="34-lda-12" href="./nips-2013-Marginals-to-Models_Reducibility.html">184 nips-2013-Marginals-to-Models Reducibility</a></p>
<p>13 0.72921473 <a title="34-lda-13" href="./nips-2013-Structured_Learning_via_Logistic_Regression.html">318 nips-2013-Structured Learning via Logistic Regression</a></p>
<p>14 0.72891605 <a title="34-lda-14" href="./nips-2013-Learning_Stochastic_Feedforward_Neural_Networks.html">160 nips-2013-Learning Stochastic Feedforward Neural Networks</a></p>
<p>15 0.72831917 <a title="34-lda-15" href="./nips-2013-An_Approximate%2C_Efficient_LP_Solver_for_LP_Rounding.html">33 nips-2013-An Approximate, Efficient LP Solver for LP Rounding</a></p>
<p>16 0.72822392 <a title="34-lda-16" href="./nips-2013-EDML_for_Learning_Parameters_in_Directed_and_Undirected_Graphical_Models.html">101 nips-2013-EDML for Learning Parameters in Directed and Undirected Graphical Models</a></p>
<p>17 0.72767705 <a title="34-lda-17" href="./nips-2013-Visual_Concept_Learning%3A_Combining_Machine_Vision_and_Bayesian_Generalization_on_Concept_Hierarchies.html">349 nips-2013-Visual Concept Learning: Combining Machine Vision and Bayesian Generalization on Concept Hierarchies</a></p>
<p>18 0.72764677 <a title="34-lda-18" href="./nips-2013-Non-Uniform_Camera_Shake_Removal_Using_a_Spatially-Adaptive_Sparse_Penalty.html">212 nips-2013-Non-Uniform Camera Shake Removal Using a Spatially-Adaptive Sparse Penalty</a></p>
<p>19 0.7275489 <a title="34-lda-19" href="./nips-2013-BIG_%26_QUIC%3A_Sparse_Inverse_Covariance_Estimation_for_a_Million_Variables.html">45 nips-2013-BIG & QUIC: Sparse Inverse Covariance Estimation for a Million Variables</a></p>
<p>20 0.72744566 <a title="34-lda-20" href="./nips-2013-Optimistic_policy_iteration_and_natural_actor-critic%3A_A_unifying_view_and_a_non-optimality_result.html">239 nips-2013-Optimistic policy iteration and natural actor-critic: A unifying view and a non-optimality result</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
