<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>152 nips-2013-Learning Efficient Random Maximum A-Posteriori Predictors with Non-Decomposable Loss Functions</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-152" href="#">nips2013-152</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>152 nips-2013-Learning Efficient Random Maximum A-Posteriori Predictors with Non-Decomposable Loss Functions</h1>
<br/><p>Source: <a title="nips-2013-152-pdf" href="http://papers.nips.cc/paper/5066-learning-efficient-random-maximum-a-posteriori-predictors-with-non-decomposable-loss-functions.pdf">pdf</a></p><p>Author: Tamir Hazan, Subhransu Maji, Joseph Keshet, Tommi Jaakkola</p><p>Abstract: In this work we develop efﬁcient methods for learning random MAP predictors for structured label problems. In particular, we construct posterior distributions over perturbations that can be adjusted via stochastic gradient methods. We show that any smooth posterior distribution would sufﬁce to deﬁne a smooth PAC-Bayesian risk bound suitable for gradient methods. In addition, we relate the posterior distributions to computational properties of the MAP predictors. We suggest multiplicative posteriors to learn super-modular potential functions that accompany specialized MAP predictors such as graph-cuts. We also describe label-augmented posterior models that can use efﬁcient MAP approximations, such as those arising from linear program relaxations. 1</p><p>Reference: <a title="nips-2013-152-reference" href="../nips2013_reference/nips-2013-Learning_Efficient_Random_Maximum_A-Posteriori_Predictors_with_Non-Decomposable_Loss_Functions_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 In particular, we construct posterior distributions over perturbations that can be adjusted via stochastic gradient methods. [sent-2, score-0.309]
</p><p>2 We show that any smooth posterior distribution would sufﬁce to deﬁne a smooth PAC-Bayesian risk bound suitable for gradient methods. [sent-3, score-0.523]
</p><p>3 In addition, we relate the posterior distributions to computational properties of the MAP predictors. [sent-4, score-0.264]
</p><p>4 We suggest multiplicative posteriors to learn super-modular potential functions that accompany specialized MAP predictors such as graph-cuts. [sent-5, score-0.294]
</p><p>5 We also describe label-augmented posterior models that can use efﬁcient MAP approximations, such as those arising from linear program relaxations. [sent-6, score-0.332]
</p><p>6 The structures of labels are speciﬁed by assignments of random variables, and the likelihood of the assignments are described by a potential function. [sent-11, score-0.151]
</p><p>7 Learning MAP predictors is usually done by structured-SVMs that compare a “loss adjusted” MAP prediction to its training label [25]. [sent-14, score-0.178]
</p><p>8 In practice, most loss functions used decompose in the same way as the potential function, so as to not increase the complexity of the MAP prediction task. [sent-15, score-0.194]
</p><p>9 Bayesian approaches for expected loss minimization, or risk, effortlessly deal with nondecomposable loss functions. [sent-17, score-0.191]
</p><p>10 Interestingly, when incorporating perturbmax models to Bayesian loss minimization one would ultimately like to use the PAC-Bayesian risk [11, 19, 3, 20, 5, 10]. [sent-22, score-0.244]
</p><p>11 We focus on computational aspects when constructing posterior distributions, so that they could be used 1  to minimize the risk bound efﬁciently. [sent-24, score-0.351]
</p><p>12 We show that any smooth posterior distribution would sufﬁce to deﬁne a smooth risk bound which can be minimized through gradient decent. [sent-25, score-0.541]
</p><p>13 In addition, we relate the posterior distributions to the computational properties of MAP predictors. [sent-26, score-0.264]
</p><p>14 We suggest multiplicative posterior models to learn super-modular potential functions, that come with specialized MAP predictors such as graph-cuts [2]. [sent-27, score-0.506]
</p><p>15 We also describe label-augmented posterior models that can use MAP approximations, such as those arising from linear program relaxations [21]. [sent-28, score-0.367]
</p><p>16 Within Bayesian perspectives, the distribution that one learns given the training data is composed from a distribution over the parameter space qw (γ) and over the labels space P [y|w, x] ∝ exp θ(y; x, w). [sent-34, score-0.827]
</p><p>17 ,yn  (2)  Recently, [17, 23] suggested to change of the Bayesian posterior probability models to utilize the MAP prediction in a deterministic manner. [sent-40, score-0.284]
</p><p>18 We denote by yr the set of labels that correspond to the region r, namely (yi )i∈r and consider the following potential functions θ(y; x, w) = r∈R θr (yr ; x, w). [sent-53, score-0.497]
</p><p>19 Thus, MAP prediction can be formulated as an integer linear program: b∗ ∈ arg max br (yr )  s. [sent-54, score-0.197]
</p><p>20 br (yr )θr (yr ; x, w)  (4)  r,yr  br (yr ) ∈ {0, 1},  bs (ys ) = br (yr ) ∀r ⊂ s  br (yr ) = 1, yr  ys \yr  The correspondence between MAP prediction and integer linear program solutions is (yw (x))i = arg maxyi b∗ (yi ). [sent-56, score-1.122]
</p><p>21 This restriction can be relaxed when one replaces the integral constraints br (yr ) ∈ {0, 1} with nonnegative constraints br (yr ) ≥ 0. [sent-58, score-0.342]
</p><p>22 These 2  linear program relaxations can be solved efﬁciently using different convex max-product solvers, and whenever these solvers produce an integral solution it is guaranteed to be the MAP prediction [21]. [sent-59, score-0.204]
</p><p>23 As we focus y on randomized MAP predictors our goal is to learn the parameters w that minimize the expected perturb-max prediction loss, or randomized risk. [sent-62, score-0.362]
</p><p>24 We deﬁne the randomized risk at a single instancelabel pair as R(w, x, y) = Pγ∼qw y = yγ (x) L(ˆ, y). [sent-63, score-0.196]
</p><p>25 ˆ y y ∈Y ˆ  Alternatively, the randomized risk takes the form R(w, x, y) = Eγ∼qw [L(yγ (x), y)]. [sent-64, score-0.196]
</p><p>26 The randomized risk originates within the PAC-Bayesian generalization bounds. [sent-65, score-0.196]
</p><p>27 In the following we state the PAC-Bayesian generalization bound for structured predictors and describe the gradients of these bounds for any smooth posterior distribution. [sent-68, score-0.474]
</p><p>28 It upper 1 bounds the randomized risk by the empirical randomized risk RS (w) = |S| (x,y)∈S R(w, x, y) and a penalty term which decreases proportionally to the training set size. [sent-70, score-0.414]
</p><p>29 Here we state the PACBayesian theorem, that holds uniformly for all posterior distributions over the predictions. [sent-71, score-0.245]
</p><p>30 Let y p(γ) be any probability density function and let qw (γ) be a family of probability density functions parameterized by w. [sent-75, score-0.805]
</p><p>31 The proof technique replaces prior randomized risk, with the posterior randomized risk that holds uniformly for every w, while penalizing this change by their KL-divergence. [sent-79, score-0.523]
</p><p>32 To ﬁnd the best posterior distribution that minimizes the randomized risk, one can minimize its empirical upper bound. [sent-82, score-0.283]
</p><p>33 We show that whenever the posterior distributions have smooth probability density functions qw (γ), the perturb-max probability model is smooth as a function of w. [sent-83, score-1.156]
</p><p>34 Thus the randomized risk bound can be minimized with gradient methods. [sent-84, score-0.286]
</p><p>35 Since qw (γ) is a probability density function and L(ˆ, y) ∈ [0, 1] we can differentiate under the integral (cf. [sent-87, score-0.78]
</p><p>36 y w R(w, x, y)  =  w qw (γ)L(yγ (x), y)dγ  3  Using the identity w qw (γ) = qw (γ) w log(qw (γ)) the ﬁrst part of the proof follows. [sent-90, score-2.227]
</p><p>37 The second part of the proof follows in the same manner, while noting that w (qw (γ) log qw (γ)) = ( w qw (γ))(log qw (γ) + 1). [sent-91, score-2.267]
</p><p>38 The gradient of the randomized empirical risk is governed by the gradient of the log-probability density function of its corresponding posterior model. [sent-92, score-0.508]
</p><p>39 For example, Gaussian model with mean w and identity covariance matrix has the probability density function qw (γ) ∝ exp(− γ − w 2 /2), thus the gradient of its log-density is the linear moment γ, i. [sent-93, score-0.848]
</p><p>40 Taking any smooth distribution qw (γ), we can ﬁnd the parameters w by descending along the stochastic gradient of the PAC-Bayesian generalization bound. [sent-96, score-0.864]
</p><p>41 The gradient of the randomized empirical risk is formed by two expectations, over the sample points and over the posterior distribution. [sent-97, score-0.442]
</p><p>42 Computing these expectations is time consuming, thus we use a single sample γ [log qw (γ)]L(yγ (x), y) as an unbiased estimator for the gradient. [sent-98, score-0.755]
</p><p>43 Similarly we estimate the gradient of the KL-divergence with an unbiased estimator which requires a single sample of w [log qw (γ)](log(qw (γ)/p(γ)) + 1). [sent-99, score-0.797]
</p><p>44 This approach, called stochastic approximation or online gradient descent, amounts to use the stochastic gradient update rule w ←w−η·λ  w [log qw (γ)]  L(yγ (x), y) + log(qw (γ)/p(γ)) + 1  where η is the learning rate. [sent-100, score-0.82]
</p><p>45 Next, we explore different posterior distributions from computational perspectives. [sent-101, score-0.245]
</p><p>46 Speciﬁcally, we show how to learn the posterior model so to ensure the computational efﬁciency of its MAP predictor. [sent-102, score-0.231]
</p><p>47 4  Learning posterior distributions efﬁciently  The ability to efﬁciently apply MAP predictors is key to the success of the learning process. [sent-103, score-0.35]
</p><p>48 Although MAP predictions are NP-hard in general, there are posterior models for which they can be computed efﬁciently. [sent-104, score-0.269]
</p><p>49 Learning unconstrained parameters with random MAP predictors provides some freedom in choosing the posterior distribution. [sent-106, score-0.349]
</p><p>50 In fact, Theorem 2 suggests that one can learn any posterior distribution by performing gradient descent on its risk bound, as long as its probability density function is smooth. [sent-107, score-0.414]
</p><p>51 We show that for unconstrained parameters, additive posterior distributions simplify the learning problem, and the complexity of the bound (i. [sent-108, score-0.294]
</p><p>52 Let q0 (γ) be a smooth probability density function with zero mean and set the posterior distribution using additive shifts qw (γ) = q0 (γ − w). [sent-112, score-1.029]
</p><p>53 This result implies that every additively-shifted smooth posterior distribution may consider the KLdivergence penalty as the square regularization when using a Gaussian prior p(γ) ∝ exp(− γ 2 ). [sent-118, score-0.269]
</p><p>54 This generalizes the standard claim on Gaussian posterior distributions [11], for which q0 (γ) are Gaussians. [sent-119, score-0.245]
</p><p>55 Thus one can use different posterior distributions to better ﬁt the randomized empirical risk, without increasing the computational complexity over Gaussian processes. [sent-120, score-0.324]
</p><p>56 In the following we show how to deﬁne posterior distributions that guarantee efﬁcient predictions, thus allowing efﬁcient sampling and learning. [sent-126, score-0.264]
</p><p>57 1  Learning constrained posterior models  MAP predictions can be computed efﬁciently in important practical cases, e. [sent-128, score-0.269]
</p><p>58 Whenever we restrict ourselves to symmetric potential function θi,j (yi , yj ; x, w) = wi,j yi yj , supermodularity translates to nonnegative constraint on the parameters wi,j ≥ 0. [sent-131, score-0.233]
</p><p>59 In order to model posterior distributions that allow efﬁcient sampling we deﬁne models over the constrained parameter space. [sent-132, score-0.293]
</p><p>60 Unfortunately, the additive posterior models qw (γ) = q0 (γ − w) are inappropriate for this purpose, as they have a positive probability for negative γ values and would generate nonsupermodular models. [sent-133, score-0.969]
</p><p>61 To learn constrained parameters one requires posterior distributions that respect these constraints. [sent-134, score-0.293]
</p><p>62 For nonnegative parameters we apply posterior distributions that are deﬁned on the nonnegative real numbers. [sent-135, score-0.368]
</p><p>63 We suggest to incorporate the parameters of the posterior distribution in a multiplicative manner into a distribution over the nonnegative real numbers. [sent-136, score-0.355]
</p><p>64 For any distribution qα (γ) we determine a posterior distribution with parameters w as qw (γ) = qα (γ/w)/w. [sent-137, score-0.961]
</p><p>65 We show that multiplicative posterior models naturally provide log-barrier functions over the constrained set of nonnegative numbers. [sent-138, score-0.364]
</p><p>66 For any probability distribution qα (γ), let qα,w (γ) = qα (γ/w)/w be the parametrized posterior distribution. [sent-141, score-0.204]
</p><p>67 2 Proof: The entropy of multiplicative posterior models naturally implies the log-barrier function: −H(qα,w )  γ =γ/w ˆ  =  qα (ˆ ) log qα (ˆ ) − log w dˆ = −H(qα ) − log w. [sent-145, score-0.412]
</p><p>68 The multiplicative posterior distribution would provide the barrier function − log w as part of its KLdivergence. [sent-148, score-0.328]
</p><p>69 Thus the multiplicative posterior effortlessly enforces the constraints of its parameters. [sent-149, score-0.298]
</p><p>70 2  Learning posterior models with approximate MAP predictions  MAP prediction can be phrased as an integer linear program, stated in Equation (4). [sent-155, score-0.363]
</p><p>71 Second, without describing the linear program solutions one cannot incorporate loss functions that take the structural properties of approximate MAP predictions into account when computing the the randomized risk. [sent-164, score-0.313]
</p><p>72 Thus we are able to deﬁne posterior distributions that use efﬁcient, although approximate, predictions while taking into account their structures. [sent-177, score-0.281]
</p><p>73 To integrate these posterior distributions to randomized risk we extend the loss function to L(˜w (x), y). [sent-178, score-0.538]
</p><p>74 , by y ˜ ˜ considering loss functions L : Y × Y → [0, 1] while the training examples labels belong to the ˜. [sent-181, score-0.158]
</p><p>75 A trimap is an approximate segmentation of the image into regions that are well inside, well outside and the boundary of the object, something a user can easily specify in an interactive application. [sent-185, score-0.162]
</p><p>76 We learn parameters for the “Gaussian Mixture Markov Random Field” (GMMRF) formulation of [1] using a potential function over foreground/background segmentations Y = {−1, 1}n : θ(y; x, w) = l∈V θi (yi ; x, w) + i,j∈E θi,j (yi , yj ; x, w). [sent-187, score-0.169]
</p><p>77 The local potentials are θi (yi ; x, w) = wyi log P (yi |x), where wyi are parameters to be learned while P (yi |x) are obtained from a Gaussian mixture model learned on the background and foreground pixels for an image x in the initial trimap. [sent-188, score-0.202]
</p><p>78 The pairwise potentials are θi,j (yi , yj ; x, w) = wa exp(−(xi − xj )2 )yi yj , where xi denotes the intensity of image x at pixel i, and wa are the parameters to be learned for the angles a ∈ {0, 90, 45, −45}◦ . [sent-189, score-0.21]
</p><p>79 These potential functions are supermodular as long as the parameters wa are nonnegative, thus MAP prediction can be computed efﬁciently with the graph-cuts algorithm. [sent-190, score-0.23]
</p><p>80 For these parameters we use multiplicative posterior model with the Gamma distribution. [sent-191, score-0.284]
</p><p>81 Our learned parameters outperform structured SVM approaches and Perturb-and-MAP moment matching  Figure 1: Two examples of image (left), input “trimap” (middle) and the ﬁnal segmentation (right) produced using our learned parameters. [sent-206, score-0.212]
</p><p>82 We use two different loss functions for training/testing for our approach to illustrate the ﬂexibility of our approach for learning using various task speciﬁc loss functions. [sent-207, score-0.177]
</p><p>83 Using structured SVM, solving loss-augmented inference maxy∈Y {L(y, y ) + θ(y; x, w)} with the ˆ ˆ hamming loss can be efﬁciently done using graph-cuts. [sent-212, score-0.15]
</p><p>84 These MAP predictors can be integrated to learn complex models using structuredSVM [25]. [sent-225, score-0.18]
</p><p>85 Structured-SVM has a drawback, as its MAP prediction is adjusted by the loss function, therefore it has an augmented complexity. [sent-226, score-0.151]
</p><p>86 Bayesian approaches to loss minimization treat separately the prediction process and the loss incurred, [12]. [sent-229, score-0.227]
</p><p>87 However, the posterior models in the PAC-Bayesian approaches were not extensively studied in the past. [sent-238, score-0.233]
</p><p>88 [10] investigate linear predictors with Gaussian posterior models to have a structured-SVM like bound. [sent-240, score-0.338]
</p><p>89 In our work, we extend these results to smooth posterior distributions, while maintaining the quadratic regularization form. [sent-244, score-0.269]
</p><p>90 In different perspective, [3, 5] describe the optimal posterior, but unfortunately there is no efﬁcient sampling procedure for this posterior model. [sent-246, score-0.244]
</p><p>91 In contrast, our work explores posterior models which allow efﬁcient sampling. [sent-247, score-0.233]
</p><p>92 We investigate two posterior models: the multiplicative models, for constrained MAP solvers such as graph-cuts, and posterior models for approximate MAP solutions. [sent-248, score-0.556]
</p><p>93 We show that any smooth posterior distribution would sufﬁce to deﬁne a smooth PAC-Bayesian risk bound which can be minimized using gradient decent. [sent-251, score-0.541]
</p><p>94 In addition, we relate the posterior distributions to the computational properties of the MAP predictors. [sent-252, score-0.264]
</p><p>95 We suggest multiplicative posterior models to learn supermodular potential functions that come with specialized MAP predictors such as graph-cuts algorithm. [sent-253, score-0.594]
</p><p>96 We also describe label-augmented posterior models that can use efﬁcient MAP approximations, such as those arising from linear program relaxations. [sent-254, score-0.332]
</p><p>97 We did not evaluate the performance of these posterior models and further explorations of such models is required. [sent-255, score-0.262]
</p><p>98 The results here focus on posterior models that would allow for efﬁcient sampling using MAP predictions. [sent-256, score-0.252]
</p><p>99 There are other cases for which speciﬁc posterior distributions might be handy, e. [sent-257, score-0.245]
</p><p>100 Since ES RS (γ) = R(γ), the right term in the risk bound in can be made 1 when choosing F(R(γ)) to be the inverse of the moment generating function bound. [sent-263, score-0.193]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('qw', 0.736), ('yr', 0.395), ('posterior', 0.204), ('rs', 0.19), ('map', 0.182), ('br', 0.123), ('risk', 0.117), ('predictors', 0.105), ('grabcut', 0.08), ('randomized', 0.079), ('loss', 0.078), ('supermodular', 0.067), ('smooth', 0.065), ('gmmrf', 0.061), ('trimap', 0.061), ('multiplicative', 0.059), ('program', 0.058), ('yw', 0.054), ('catoni', 0.054), ('ys', 0.053), ('prediction', 0.051), ('nonnegative', 0.051), ('structured', 0.049), ('moment', 0.046), ('potential', 0.044), ('gradient', 0.042), ('distributions', 0.041), ('yi', 0.041), ('solvers', 0.04), ('kl', 0.04), ('log', 0.04), ('segmentations', 0.039), ('yj', 0.038), ('segmentation', 0.037), ('labels', 0.037), ('predictions', 0.036), ('relaxations', 0.035), ('blake', 0.035), ('effortlessly', 0.035), ('primal', 0.033), ('hazan', 0.033), ('exp', 0.032), ('gamma', 0.032), ('svm', 0.031), ('wyi', 0.03), ('bound', 0.03), ('bs', 0.029), ('models', 0.029), ('perspectives', 0.028), ('learn', 0.027), ('wa', 0.026), ('bayesian', 0.026), ('extreme', 0.025), ('barrier', 0.025), ('herding', 0.025), ('maji', 0.025), ('interactive', 0.025), ('replaces', 0.025), ('structures', 0.024), ('polytope', 0.024), ('dm', 0.024), ('density', 0.024), ('integer', 0.023), ('keshet', 0.023), ('tarlow', 0.023), ('assignments', 0.023), ('hamming', 0.023), ('potentials', 0.022), ('training', 0.022), ('adjusted', 0.022), ('pascal', 0.022), ('functions', 0.021), ('yc', 0.021), ('tamir', 0.021), ('solutions', 0.021), ('describe', 0.021), ('parameters', 0.021), ('minimization', 0.02), ('arising', 0.02), ('approximate', 0.02), ('gaussian', 0.02), ('learned', 0.02), ('fixing', 0.02), ('goodness', 0.02), ('integral', 0.02), ('suggest', 0.02), ('image', 0.019), ('ciently', 0.019), ('sampling', 0.019), ('proof', 0.019), ('relate', 0.019), ('unconstrained', 0.019), ('integrate', 0.019), ('complex', 0.019), ('unbiased', 0.019), ('specialized', 0.018), ('minimized', 0.018), ('truncated', 0.018), ('decaying', 0.018), ('predictive', 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="152-tfidf-1" href="./nips-2013-Learning_Efficient_Random_Maximum_A-Posteriori_Predictors_with_Non-Decomposable_Loss_Functions.html">152 nips-2013-Learning Efficient Random Maximum A-Posteriori Predictors with Non-Decomposable Loss Functions</a></p>
<p>Author: Tamir Hazan, Subhransu Maji, Joseph Keshet, Tommi Jaakkola</p><p>Abstract: In this work we develop efﬁcient methods for learning random MAP predictors for structured label problems. In particular, we construct posterior distributions over perturbations that can be adjusted via stochastic gradient methods. We show that any smooth posterior distribution would sufﬁce to deﬁne a smooth PAC-Bayesian risk bound suitable for gradient methods. In addition, we relate the posterior distributions to computational properties of the MAP predictors. We suggest multiplicative posteriors to learn super-modular potential functions that accompany specialized MAP predictors such as graph-cuts. We also describe label-augmented posterior models that can use efﬁcient MAP approximations, such as those arising from linear program relaxations. 1</p><p>2 0.13391717 <a title="152-tfidf-2" href="./nips-2013-On_Sampling_from_the_Gibbs_Distribution_with_Random_Maximum_A-Posteriori_Perturbations.html">218 nips-2013-On Sampling from the Gibbs Distribution with Random Maximum A-Posteriori Perturbations</a></p>
<p>Author: Tamir Hazan, Subhransu Maji, Tommi Jaakkola</p><p>Abstract: In this paper we describe how MAP inference can be used to sample efﬁciently from Gibbs distributions. Speciﬁcally, we provide means for drawing either approximate or unbiased samples from Gibbs’ distributions by introducing low dimensional perturbations and solving the corresponding MAP assignments. Our approach also leads to new ways to derive lower bounds on partition functions. We demonstrate empirically that our method excels in the typical “high signal high coupling” regime. The setting results in ragged energy landscapes that are challenging for alternative approaches to sampling and/or lower bounds. 1</p><p>3 0.079099372 <a title="152-tfidf-3" href="./nips-2013-PAC-Bayes-Empirical-Bernstein_Inequality.html">242 nips-2013-PAC-Bayes-Empirical-Bernstein Inequality</a></p>
<p>Author: Ilya O. Tolstikhin, Yevgeny Seldin</p><p>Abstract: We present a PAC-Bayes-Empirical-Bernstein inequality. The inequality is based on a combination of the PAC-Bayesian bounding technique with an Empirical Bernstein bound. We show that when the empirical variance is signiﬁcantly smaller than the empirical loss the PAC-Bayes-Empirical-Bernstein inequality is signiﬁcantly tighter than the PAC-Bayes-kl inequality of Seeger (2002) and otherwise it is comparable. Our theoretical analysis is conﬁrmed empirically on a synthetic example and several UCI datasets. The PAC-Bayes-Empirical-Bernstein inequality is an interesting example of an application of the PAC-Bayesian bounding technique to self-bounding functions. 1</p><p>4 0.076252326 <a title="152-tfidf-4" href="./nips-2013-Learning_with_Noisy_Labels.html">171 nips-2013-Learning with Noisy Labels</a></p>
<p>Author: Nagarajan Natarajan, Inderjit Dhillon, Pradeep Ravikumar, Ambuj Tewari</p><p>Abstract: In this paper, we theoretically study the problem of binary classiﬁcation in the presence of random classiﬁcation noise — the learner, instead of seeing the true labels, sees labels that have independently been ﬂipped with some small probability. Moreover, random label noise is class-conditional — the ﬂip probability depends on the class. We provide two approaches to suitably modify any given surrogate loss function. First, we provide a simple unbiased estimator of any loss, and obtain performance bounds for empirical risk minimization in the presence of iid data with noisy labels. If the loss function satisﬁes a simple symmetry condition, we show that the method leads to an efﬁcient algorithm for empirical minimization. Second, by leveraging a reduction of risk minimization under noisy labels to classiﬁcation with weighted 0-1 loss, we suggest the use of a simple weighted surrogate loss, for which we are able to obtain strong empirical risk bounds. This approach has a very remarkable consequence — methods used in practice such as biased SVM and weighted logistic regression are provably noise-tolerant. On a synthetic non-separable dataset, our methods achieve over 88% accuracy even when 40% of the labels are corrupted, and are competitive with respect to recently proposed methods for dealing with label noise in several benchmark datasets.</p><p>5 0.069790304 <a title="152-tfidf-5" href="./nips-2013-Structured_Learning_via_Logistic_Regression.html">318 nips-2013-Structured Learning via Logistic Regression</a></p>
<p>Author: Justin Domke</p><p>Abstract: A successful approach to structured learning is to write the learning objective as a joint function of linear parameters and inference messages, and iterate between updates to each. This paper observes that if the inference problem is “smoothed” through the addition of entropy terms, for ﬁxed messages, the learning objective reduces to a traditional (non-structured) logistic regression problem with respect to parameters. In these logistic regression problems, each training example has a bias term determined by the current set of messages. Based on this insight, the structured energy function can be extended from linear factors to any function class where an “oracle” exists to minimize a logistic loss.</p><p>6 0.069403902 <a title="152-tfidf-6" href="./nips-2013-Thompson_Sampling_for_1-Dimensional_Exponential_Family_Bandits.html">330 nips-2013-Thompson Sampling for 1-Dimensional Exponential Family Bandits</a></p>
<p>7 0.062727816 <a title="152-tfidf-7" href="./nips-2013-Latent_Structured_Active_Learning.html">149 nips-2013-Latent Structured Active Learning</a></p>
<p>8 0.057963856 <a title="152-tfidf-8" href="./nips-2013-Online_Learning_of_Nonparametric_Mixture_Models_via_Sequential_Variational_Approximation.html">229 nips-2013-Online Learning of Nonparametric Mixture Models via Sequential Variational Approximation</a></p>
<p>9 0.054492891 <a title="152-tfidf-9" href="./nips-2013-Active_Learning_for_Probabilistic_Hypotheses_Using_the_Maximum_Gibbs_Error_Criterion.html">23 nips-2013-Active Learning for Probabilistic Hypotheses Using the Maximum Gibbs Error Criterion</a></p>
<p>10 0.053944886 <a title="152-tfidf-10" href="./nips-2013-Streaming_Variational_Bayes.html">317 nips-2013-Streaming Variational Bayes</a></p>
<p>11 0.053901199 <a title="152-tfidf-11" href="./nips-2013-Low-rank_matrix_reconstruction_and_clustering_via_approximate_message_passing.html">180 nips-2013-Low-rank matrix reconstruction and clustering via approximate message passing</a></p>
<p>12 0.052705828 <a title="152-tfidf-12" href="./nips-2013-Bayesian_inference_as_iterated_random_functions_with__applications_to_sequential_inference_in_graphical_models.html">52 nips-2013-Bayesian inference as iterated random functions with  applications to sequential inference in graphical models</a></p>
<p>13 0.049985111 <a title="152-tfidf-13" href="./nips-2013-Projecting_Ising_Model_Parameters_for_Fast_Mixing.html">258 nips-2013-Projecting Ising Model Parameters for Fast Mixing</a></p>
<p>14 0.049059935 <a title="152-tfidf-14" href="./nips-2013-Learning_Stochastic_Inverses.html">161 nips-2013-Learning Stochastic Inverses</a></p>
<p>15 0.047713485 <a title="152-tfidf-15" href="./nips-2013-Robust_Bloom_Filters_for_Large_MultiLabel_Classification_Tasks.html">279 nips-2013-Robust Bloom Filters for Large MultiLabel Classification Tasks</a></p>
<p>16 0.047677077 <a title="152-tfidf-16" href="./nips-2013-Integrated_Non-Factorized_Variational_Inference.html">143 nips-2013-Integrated Non-Factorized Variational Inference</a></p>
<p>17 0.047588143 <a title="152-tfidf-17" href="./nips-2013-Online_Variational_Approximations_to_non-Exponential_Family_Change_Point_Models%3A_With_Application_to_Radar_Tracking.html">234 nips-2013-Online Variational Approximations to non-Exponential Family Change Point Models: With Application to Radar Tracking</a></p>
<p>18 0.046972681 <a title="152-tfidf-18" href="./nips-2013-Learning_Adaptive_Value_of_Information_for_Structured_Prediction.html">150 nips-2013-Learning Adaptive Value of Information for Structured Prediction</a></p>
<p>19 0.046238203 <a title="152-tfidf-19" href="./nips-2013-%CE%A3-Optimality_for_Active_Learning_on_Gaussian_Random_Fields.html">359 nips-2013-Σ-Optimality for Active Learning on Gaussian Random Fields</a></p>
<p>20 0.046201851 <a title="152-tfidf-20" href="./nips-2013-A_simple_example_of_Dirichlet_process_mixture_inconsistency_for_the_number_of_components.html">18 nips-2013-A simple example of Dirichlet process mixture inconsistency for the number of components</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.143), (1, 0.032), (2, -0.002), (3, -0.016), (4, 0.046), (5, 0.078), (6, 0.03), (7, -0.01), (8, 0.052), (9, 0.007), (10, -0.001), (11, 0.048), (12, -0.016), (13, -0.032), (14, 0.009), (15, -0.053), (16, -0.054), (17, -0.022), (18, -0.012), (19, 0.031), (20, -0.089), (21, 0.041), (22, 0.047), (23, -0.003), (24, -0.039), (25, 0.051), (26, 0.031), (27, -0.023), (28, 0.061), (29, 0.126), (30, -0.032), (31, -0.001), (32, -0.026), (33, -0.002), (34, 0.02), (35, -0.033), (36, -0.007), (37, -0.088), (38, 0.047), (39, 0.002), (40, 0.033), (41, -0.086), (42, -0.02), (43, -0.008), (44, 0.005), (45, 0.031), (46, 0.017), (47, 0.071), (48, -0.008), (49, 0.066)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92112714 <a title="152-lsi-1" href="./nips-2013-Learning_Efficient_Random_Maximum_A-Posteriori_Predictors_with_Non-Decomposable_Loss_Functions.html">152 nips-2013-Learning Efficient Random Maximum A-Posteriori Predictors with Non-Decomposable Loss Functions</a></p>
<p>Author: Tamir Hazan, Subhransu Maji, Joseph Keshet, Tommi Jaakkola</p><p>Abstract: In this work we develop efﬁcient methods for learning random MAP predictors for structured label problems. In particular, we construct posterior distributions over perturbations that can be adjusted via stochastic gradient methods. We show that any smooth posterior distribution would sufﬁce to deﬁne a smooth PAC-Bayesian risk bound suitable for gradient methods. In addition, we relate the posterior distributions to computational properties of the MAP predictors. We suggest multiplicative posteriors to learn super-modular potential functions that accompany specialized MAP predictors such as graph-cuts. We also describe label-augmented posterior models that can use efﬁcient MAP approximations, such as those arising from linear program relaxations. 1</p><p>2 0.71936649 <a title="152-lsi-2" href="./nips-2013-On_Sampling_from_the_Gibbs_Distribution_with_Random_Maximum_A-Posteriori_Perturbations.html">218 nips-2013-On Sampling from the Gibbs Distribution with Random Maximum A-Posteriori Perturbations</a></p>
<p>Author: Tamir Hazan, Subhransu Maji, Tommi Jaakkola</p><p>Abstract: In this paper we describe how MAP inference can be used to sample efﬁciently from Gibbs distributions. Speciﬁcally, we provide means for drawing either approximate or unbiased samples from Gibbs’ distributions by introducing low dimensional perturbations and solving the corresponding MAP assignments. Our approach also leads to new ways to derive lower bounds on partition functions. We demonstrate empirically that our method excels in the typical “high signal high coupling” regime. The setting results in ragged energy landscapes that are challenging for alternative approaches to sampling and/or lower bounds. 1</p><p>3 0.63051653 <a title="152-lsi-3" href="./nips-2013-Structured_Learning_via_Logistic_Regression.html">318 nips-2013-Structured Learning via Logistic Regression</a></p>
<p>Author: Justin Domke</p><p>Abstract: A successful approach to structured learning is to write the learning objective as a joint function of linear parameters and inference messages, and iterate between updates to each. This paper observes that if the inference problem is “smoothed” through the addition of entropy terms, for ﬁxed messages, the learning objective reduces to a traditional (non-structured) logistic regression problem with respect to parameters. In these logistic regression problems, each training example has a bias term determined by the current set of messages. Based on this insight, the structured energy function can be extended from linear factors to any function class where an “oracle” exists to minimize a logistic loss.</p><p>4 0.6288147 <a title="152-lsi-4" href="./nips-2013-Projecting_Ising_Model_Parameters_for_Fast_Mixing.html">258 nips-2013-Projecting Ising Model Parameters for Fast Mixing</a></p>
<p>Author: Justin Domke, Xianghang Liu</p><p>Abstract: Inference in general Ising models is difﬁcult, due to high treewidth making treebased algorithms intractable. Moreover, when interactions are strong, Gibbs sampling may take exponential time to converge to the stationary distribution. We present an algorithm to project Ising model parameters onto a parameter set that is guaranteed to be fast mixing, under several divergences. We ﬁnd that Gibbs sampling using the projected parameters is more accurate than with the original parameters when interaction strengths are strong and when limited time is available for sampling.</p><p>5 0.59276134 <a title="152-lsi-5" href="./nips-2013-Bayesian_inference_as_iterated_random_functions_with__applications_to_sequential_inference_in_graphical_models.html">52 nips-2013-Bayesian inference as iterated random functions with  applications to sequential inference in graphical models</a></p>
<p>Author: Arash Amini, Xuanlong Nguyen</p><p>Abstract: We propose a general formalism of iterated random functions with semigroup property, under which exact and approximate Bayesian posterior updates can be viewed as speciﬁc instances. A convergence theory for iterated random functions is presented. As an application of the general theory we analyze convergence behaviors of exact and approximate message-passing algorithms that arise in a sequential change point detection problem formulated via a latent variable directed graphical model. The sequential inference algorithm and its supporting theory are illustrated by simulated examples.</p><p>6 0.56924289 <a title="152-lsi-6" href="./nips-2013-Convex_Calibrated_Surrogates_for_Low-Rank_Loss_Matrices_with_Applications_to_Subset_Ranking_Losses.html">72 nips-2013-Convex Calibrated Surrogates for Low-Rank Loss Matrices with Applications to Subset Ranking Losses</a></p>
<p>7 0.55438548 <a title="152-lsi-7" href="./nips-2013-Learning_Stochastic_Inverses.html">161 nips-2013-Learning Stochastic Inverses</a></p>
<p>8 0.54965252 <a title="152-lsi-8" href="./nips-2013-Marginals-to-Models_Reducibility.html">184 nips-2013-Marginals-to-Models Reducibility</a></p>
<p>9 0.54889303 <a title="152-lsi-9" href="./nips-2013-Analyzing_Hogwild_Parallel_Gaussian_Gibbs_Sampling.html">34 nips-2013-Analyzing Hogwild Parallel Gaussian Gibbs Sampling</a></p>
<p>10 0.54436255 <a title="152-lsi-10" href="./nips-2013-A_Graphical_Transformation_for_Belief_Propagation%3A_Maximum_Weight_Matchings_and_Odd-Sized_Cycles.html">8 nips-2013-A Graphical Transformation for Belief Propagation: Maximum Weight Matchings and Odd-Sized Cycles</a></p>
<p>11 0.52671069 <a title="152-lsi-11" href="./nips-2013-Learning_to_Pass_Expectation_Propagation_Messages.html">168 nips-2013-Learning to Pass Expectation Propagation Messages</a></p>
<p>12 0.51575071 <a title="152-lsi-12" href="./nips-2013-Probabilistic_Principal_Geodesic_Analysis.html">256 nips-2013-Probabilistic Principal Geodesic Analysis</a></p>
<p>13 0.50621867 <a title="152-lsi-13" href="./nips-2013-An_Approximate%2C_Efficient_LP_Solver_for_LP_Rounding.html">33 nips-2013-An Approximate, Efficient LP Solver for LP Rounding</a></p>
<p>14 0.50563121 <a title="152-lsi-14" href="./nips-2013-Geometric_optimisation_on_positive_definite_matrices_for_elliptically_contoured_distributions.html">131 nips-2013-Geometric optimisation on positive definite matrices for elliptically contoured distributions</a></p>
<p>15 0.50498658 <a title="152-lsi-15" href="./nips-2013-Stochastic_Gradient_Riemannian_Langevin_Dynamics_on_the_Probability_Simplex.html">312 nips-2013-Stochastic Gradient Riemannian Langevin Dynamics on the Probability Simplex</a></p>
<p>16 0.50450259 <a title="152-lsi-16" href="./nips-2013-Learning_Stochastic_Feedforward_Neural_Networks.html">160 nips-2013-Learning Stochastic Feedforward Neural Networks</a></p>
<p>17 0.49978688 <a title="152-lsi-17" href="./nips-2013-Conditional_Random_Fields_via_Univariate_Exponential_Families.html">67 nips-2013-Conditional Random Fields via Univariate Exponential Families</a></p>
<p>18 0.49928337 <a title="152-lsi-18" href="./nips-2013-Machine_Teaching_for_Bayesian_Learners_in_the_Exponential_Family.html">181 nips-2013-Machine Teaching for Bayesian Learners in the Exponential Family</a></p>
<p>19 0.4987984 <a title="152-lsi-19" href="./nips-2013-Bayesian_Estimation_of_Latently-grouped_Parameters_in_Undirected_Graphical_Models.html">46 nips-2013-Bayesian Estimation of Latently-grouped Parameters in Undirected Graphical Models</a></p>
<p>20 0.49815169 <a title="152-lsi-20" href="./nips-2013-Reconciling_%22priors%22_%26_%22priors%22_without_prejudice%3F.html">265 nips-2013-Reconciling "priors" & "priors" without prejudice?</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.011), (16, 0.05), (33, 0.141), (34, 0.136), (37, 0.193), (41, 0.047), (45, 0.027), (46, 0.011), (49, 0.033), (56, 0.101), (70, 0.03), (85, 0.034), (89, 0.036), (93, 0.028), (95, 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.88691372 <a title="152-lda-1" href="./nips-2013-Efficient_Optimization_for_Sparse_Gaussian_Process_Regression.html">105 nips-2013-Efficient Optimization for Sparse Gaussian Process Regression</a></p>
<p>Author: Yanshuai Cao, Marcus A. Brubaker, David Fleet, Aaron Hertzmann</p><p>Abstract: We propose an efﬁcient optimization algorithm for selecting a subset of training data to induce sparsity for Gaussian process regression. The algorithm estimates an inducing set and the hyperparameters using a single objective, either the marginal likelihood or a variational free energy. The space and time complexity are linear in training set size, and the algorithm can be applied to large regression problems on discrete or continuous domains. Empirical evaluation shows state-ofart performance in discrete cases and competitive results in the continuous case. 1</p><p>2 0.84045714 <a title="152-lda-2" href="./nips-2013-Scoring_Workers_in_Crowdsourcing%3A_How_Many_Control_Questions_are_Enough%3F.html">290 nips-2013-Scoring Workers in Crowdsourcing: How Many Control Questions are Enough?</a></p>
<p>Author: Qiang Liu, Alex Ihler, Mark Steyvers</p><p>Abstract: We study the problem of estimating continuous quantities, such as prices, probabilities, and point spreads, using a crowdsourcing approach. A challenging aspect of combining the crowd’s answers is that workers’ reliabilities and biases are usually unknown and highly diverse. Control items with known answers can be used to evaluate workers’ performance, and hence improve the combined results on the target items with unknown answers. This raises the problem of how many control items to use when the total number of items each workers can answer is limited: more control items evaluates the workers better, but leaves fewer resources for the target items that are of direct interest, and vice versa. We give theoretical results for this problem under different scenarios, and provide a simple rule of thumb for crowdsourcing practitioners. As a byproduct, we also provide theoretical analysis of the accuracy of different consensus methods. 1</p><p>same-paper 3 0.82894468 <a title="152-lda-3" href="./nips-2013-Learning_Efficient_Random_Maximum_A-Posteriori_Predictors_with_Non-Decomposable_Loss_Functions.html">152 nips-2013-Learning Efficient Random Maximum A-Posteriori Predictors with Non-Decomposable Loss Functions</a></p>
<p>Author: Tamir Hazan, Subhransu Maji, Joseph Keshet, Tommi Jaakkola</p><p>Abstract: In this work we develop efﬁcient methods for learning random MAP predictors for structured label problems. In particular, we construct posterior distributions over perturbations that can be adjusted via stochastic gradient methods. We show that any smooth posterior distribution would sufﬁce to deﬁne a smooth PAC-Bayesian risk bound suitable for gradient methods. In addition, we relate the posterior distributions to computational properties of the MAP predictors. We suggest multiplicative posteriors to learn super-modular potential functions that accompany specialized MAP predictors such as graph-cuts. We also describe label-augmented posterior models that can use efﬁcient MAP approximations, such as those arising from linear program relaxations. 1</p><p>4 0.7920599 <a title="152-lda-4" href="./nips-2013-Predicting_Parameters_in_Deep_Learning.html">251 nips-2013-Predicting Parameters in Deep Learning</a></p>
<p>Author: Misha Denil, Babak Shakibi, Laurent Dinh, Marc'Aurelio Ranzato, Nando de Freitas</p><p>Abstract: We demonstrate that there is signiﬁcant redundancy in the parameterization of several deep learning models. Given only a few weight values for each feature it is possible to accurately predict the remaining values. Moreover, we show that not only can the parameter values be predicted, but many of them need not be learned at all. We train several different architectures by learning only a small number of weights and predicting the rest. In the best case we are able to predict more than 95% of the weights of a network without any drop in accuracy. 1</p><p>5 0.76098943 <a title="152-lda-5" href="./nips-2013-Optimistic_policy_iteration_and_natural_actor-critic%3A_A_unifying_view_and_a_non-optimality_result.html">239 nips-2013-Optimistic policy iteration and natural actor-critic: A unifying view and a non-optimality result</a></p>
<p>Author: Paul Wagner</p><p>Abstract: Approximate dynamic programming approaches to the reinforcement learning problem are often categorized into greedy value function methods and value-based policy gradient methods. As our ﬁrst main result, we show that an important subset of the latter methodology is, in fact, a limiting special case of a general formulation of the former methodology; optimistic policy iteration encompasses not only most of the greedy value function methods but also natural actor-critic methods, and permits one to directly interpolate between them. The resulting continuum adjusts the strength of the Markov assumption in policy improvement and, as such, can be seen as dual in spirit to the continuum in TD(λ)-style algorithms in policy evaluation. As our second main result, we show for a substantial subset of softgreedy value function approaches that, while having the potential to avoid policy oscillation and policy chattering, this subset can never converge toward an optimal policy, except in a certain pathological case. Consequently, in the context of approximations (either in state estimation or in value function representation), the majority of greedy value function methods seem to be deemed to suffer either from the risk of oscillation/chattering or from the presence of systematic sub-optimality. 1</p><p>6 0.76014322 <a title="152-lda-6" href="./nips-2013-Least_Informative_Dimensions.html">173 nips-2013-Least Informative Dimensions</a></p>
<p>7 0.75456101 <a title="152-lda-7" href="./nips-2013-Bayesian_Inference_and_Online_Experimental_Design_for_Mapping_Neural_Microcircuits.html">49 nips-2013-Bayesian Inference and Online Experimental Design for Mapping Neural Microcircuits</a></p>
<p>8 0.75426912 <a title="152-lda-8" href="./nips-2013-Multi-Task_Bayesian_Optimization.html">201 nips-2013-Multi-Task Bayesian Optimization</a></p>
<p>9 0.75354528 <a title="152-lda-9" href="./nips-2013-Wavelets_on_Graphs_via_Deep_Learning.html">350 nips-2013-Wavelets on Graphs via Deep Learning</a></p>
<p>10 0.75314397 <a title="152-lda-10" href="./nips-2013-Online_Learning_of_Nonparametric_Mixture_Models_via_Sequential_Variational_Approximation.html">229 nips-2013-Online Learning of Nonparametric Mixture Models via Sequential Variational Approximation</a></p>
<p>11 0.75277084 <a title="152-lda-11" href="./nips-2013-Robust_learning_of_low-dimensional_dynamics_from_large_neural_ensembles.html">286 nips-2013-Robust learning of low-dimensional dynamics from large neural ensembles</a></p>
<p>12 0.75273889 <a title="152-lda-12" href="./nips-2013-Distributed_Submodular_Maximization%3A_Identifying_Representative_Elements_in_Massive_Data.html">97 nips-2013-Distributed Submodular Maximization: Identifying Representative Elements in Massive Data</a></p>
<p>13 0.75167745 <a title="152-lda-13" href="./nips-2013-Correlations_strike_back_%28again%29%3A_the_case_of_associative_memory_retrieval.html">77 nips-2013-Correlations strike back (again): the case of associative memory retrieval</a></p>
<p>14 0.75088245 <a title="152-lda-14" href="./nips-2013-Real-Time_Inference_for_a_Gamma_Process_Model_of_Neural_Spiking.html">262 nips-2013-Real-Time Inference for a Gamma Process Model of Neural Spiking</a></p>
<p>15 0.75078207 <a title="152-lda-15" href="./nips-2013-EDML_for_Learning_Parameters_in_Directed_and_Undirected_Graphical_Models.html">101 nips-2013-EDML for Learning Parameters in Directed and Undirected Graphical Models</a></p>
<p>16 0.75075924 <a title="152-lda-16" href="./nips-2013-Fantope_Projection_and_Selection%3A_A_near-optimal_convex_relaxation_of_sparse_PCA.html">116 nips-2013-Fantope Projection and Selection: A near-optimal convex relaxation of sparse PCA</a></p>
<p>17 0.75028265 <a title="152-lda-17" href="./nips-2013-Structured_Learning_via_Logistic_Regression.html">318 nips-2013-Structured Learning via Logistic Regression</a></p>
<p>18 0.75021076 <a title="152-lda-18" href="./nips-2013-On_Sampling_from_the_Gibbs_Distribution_with_Random_Maximum_A-Posteriori_Perturbations.html">218 nips-2013-On Sampling from the Gibbs Distribution with Random Maximum A-Posteriori Perturbations</a></p>
<p>19 0.74979293 <a title="152-lda-19" href="./nips-2013-Optimistic_Concurrency_Control_for_Distributed_Unsupervised_Learning.html">238 nips-2013-Optimistic Concurrency Control for Distributed Unsupervised Learning</a></p>
<p>20 0.74939883 <a title="152-lda-20" href="./nips-2013-Similarity_Component_Analysis.html">294 nips-2013-Similarity Component Analysis</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
