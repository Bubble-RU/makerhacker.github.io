<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>137 nips-2013-High-Dimensional Gaussian Process Bandits</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-137" href="#">nips2013-137</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>137 nips-2013-High-Dimensional Gaussian Process Bandits</h1>
<br/><p>Source: <a title="nips-2013-137-pdf" href="http://papers.nips.cc/paper/5152-high-dimensional-gaussian-process-bandits.pdf">pdf</a></p><p>Author: Josip Djolonga, Andreas Krause, Volkan Cevher</p><p>Abstract: Many applications in machine learning require optimizing unknown functions deﬁned over a high-dimensional space from noisy samples that are expensive to obtain. We address this notoriously hard challenge, under the assumptions that the function varies only along some low-dimensional subspace and is smooth (i.e., it has a low norm in a Reproducible Kernel Hilbert Space). In particular, we present the SI-BO algorithm, which leverages recent low-rank matrix recovery techniques to learn the underlying subspace of the unknown function and applies Gaussian Process Upper Conﬁdence sampling for optimization of the function. We carefully calibrate the exploration–exploitation tradeoff by allocating the sampling budget to subspace estimation and function optimization, and obtain the ﬁrst subexponential cumulative regret bounds and convergence rates for Bayesian optimization in high-dimensions under noisy observations. Numerical results demonstrate the effectiveness of our approach in difﬁcult scenarios. 1</p><p>Reference: <a title="nips-2013-137-reference" href="../nips2013_reference/nips-2013-High-Dimensional_Gaussian_Process_Bandits_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 ch  Abstract Many applications in machine learning require optimizing unknown functions deﬁned over a high-dimensional space from noisy samples that are expensive to obtain. [sent-5, score-0.178]
</p><p>2 We address this notoriously hard challenge, under the assumptions that the function varies only along some low-dimensional subspace and is smooth (i. [sent-6, score-0.408]
</p><p>3 In particular, we present the SI-BO algorithm, which leverages recent low-rank matrix recovery techniques to learn the underlying subspace of the unknown function and applies Gaussian Process Upper Conﬁdence sampling for optimization of the function. [sent-9, score-0.522]
</p><p>4 We carefully calibrate the exploration–exploitation tradeoff by allocating the sampling budget to subspace estimation and function optimization, and obtain the ﬁrst subexponential cumulative regret bounds and convergence rates for Bayesian optimization in high-dimensions under noisy observations. [sent-10, score-1.232]
</p><p>5 1  Introduction  The optimization of non-linear functions whose evaluation may be noisy and expensive is a challenge that has important applications in sciences and engineering. [sent-12, score-0.216]
</p><p>6 One approach to this notoriously hard problem takes a Bayesian perspective, which uses the predictive uncertainty in order to trade exploration (gathering data for reducing model uncertainty) and exploitation (focusing sampling near likely optima), and is often called Bayesian Optimization (BO). [sent-13, score-0.289]
</p><p>7 For example, the cost function of neural networks effectively varies only along a few dimensions [2]. [sent-19, score-0.091]
</p><p>8 To this end, we propose an algorithm that learns a low dimensional, not necessarily axis-aligned, subspace and then applies Bayesian optimization on this estimated subspace. [sent-21, score-0.416]
</p><p>9 In particular, our SIBO approach combines low-rank matrix recovery with Gaussian Process Upper Conﬁdence Bound sampling in a carefully calibrated manner. [sent-22, score-0.22]
</p><p>10 We theoretically analyze its performance, and prove bounds on its cumulative regret. [sent-23, score-0.213]
</p><p>11 To the best of our knowledge, we prove the ﬁrst subexponential bounds for Bayesian optimization in high dimensions under noisy observations. [sent-24, score-0.369]
</p><p>12 In contrast to existing approaches, which have an exponential dependence on the ambient dimension, our bounds have in fact polynomial dependence on the dimension. [sent-25, score-0.14]
</p><p>13 Moreover, our performance guarantees depend explicitly on what we could have achieved if we had known the subspace in advance. [sent-26, score-0.327]
</p><p>14 Exploration–exploitation tradeoffs were originally studied in the context of ﬁnite multi-armed bandits [8]. [sent-28, score-0.092]
</p><p>15 A more recent algorithm that enjoys theoretical bounds for functions sampled from a Gaussian Process (GP), or belong to some Repro1  ducible Kernel Hilbert Space (RKHS) is GP-UCB [12]. [sent-30, score-0.151]
</p><p>16 The use of GPs to negotiate exploration– exploitation tradeoffs originated in the areas of response surface and Bayesian optimization, for which there are a number of approaches (cf. [sent-31, score-0.174]
</p><p>17 Bandit algorithms that exploit low-dimensional structure of the function appeared ﬁrst for the linear setting, where under sparsity assumptions one can obtain bounds, which depend only weakly on the ambient dimension [16, 17]. [sent-33, score-0.094]
</p><p>18 They provide bounds on the simple regret under noiseless observations, while we also analyze the cumulative regret and allow noisy observations. [sent-36, score-1.039]
</p><p>19 Also, unless the low-dimensional space is of dimension 1, our bounds on the simple regret improve on theirs. [sent-37, score-0.451]
</p><p>20 In [7] the authors approximate functions that live on low-dimensional subspaces using low-rank recovery and analysis techniques. [sent-38, score-0.163]
</p><p>21 While providing uniform approximation guarantees, their approach is not tailored towards exploration–exploitation tradeoffs, and does not achieve sublinear cumulative regret. [sent-39, score-0.219]
</p><p>22 o Our speciﬁc contributions in this paper can be summarized as follows: • We introduce the SI-BO algorithm for Bayesian bandit optimization in high dimensions, admitting a large family of kernel functions. [sent-41, score-0.215]
</p><p>23 Our algorithm is a natural but non-trivial fusion of modern low-rank subspace approximation tools with GP optimization methods. [sent-42, score-0.421]
</p><p>24 • We derive theoretical guarantees on SI-BO’s cumulative and simple regret in highdimensions with noise. [sent-43, score-0.479]
</p><p>25 To the best of our knowledge, these are the ﬁrst theoretical results on the sample complexity and regret rates that are subexponential in the ambient dimension. [sent-44, score-0.551]
</p><p>26 As performance metric, we consider the regret, which tells us how much better we could have done in round t had we known x∗ , or formally rt = f (x∗ ) − f (xt ). [sent-52, score-0.108]
</p><p>27 Hence, a natural quantity to consider is the cumulative regret deﬁned as RT = t=1 rt . [sent-55, score-0.587]
</p><p>28 T One can also consider the simple regret, deﬁned as ST = mint=1 rt , measuring the quality of the best solution found so far. [sent-56, score-0.108]
</p><p>29 We will give bounds on the more challenging notion of cumulative regret, which also bounds the simple regret via ST ≤ RT /T . [sent-57, score-0.633]
</p><p>30 Formally, we suppose that there exists some function g : Rk → [0, 1] and a matrix A ∈ Rk×d with orthogonal rows so that f (x) = g(Ax). [sent-65, score-0.106]
</p><p>31 1 To be able to recover the subspace we also need the condition that g has Lipschitz continuous second order derivatives and a full rank Hessian at 0, which is satisﬁed for many functions [7]. [sent-72, score-0.434]
</p><p>32 In addition to the low-dimensional subspace assumption, we also assume that g is smooth. [sent-74, score-0.327]
</p><p>33 for t ← 1 to T − mX (mΦ + 1) do 1/2 ˆ zt ← arg maxz µt (z) + βt σt (z) , yt ← f (AT zt ) + noise , D. [sent-78, score-0.12]
</p><p>34 The RKHS for some positive semideﬁnite kernel κ(·, ·) can be constructed by n completing the set of functions i=1 αi κ(xi , ·) under a suitable inner product. [sent-81, score-0.116]
</p><p>35 We wish to maximize f : Bd (1 + ε) → [0, 1], where f (x) = g(Ax) for some matrix ¯ A ∈ Rk×d with orthogonal rows and g belongs to some RKHS Hκ . [sent-86, score-0.106]
</p><p>36 The kernel κ is isotropic κ(x, x ) = κ (x − x ) = κ ( x − x 2 ) and κ is continuous, integrable and with a Fourier transform Fκ that is isotropic and radially non-increasing. [sent-88, score-0.287]
</p><p>37 The oracle noise is Gaussian with zero mean with a known variance σ 2 . [sent-94, score-0.099]
</p><p>38 3  The SI-BO Algorithm  The SI-BO algorithm performs two separate exploration and exploitation stages: (1) subspace identiﬁcation (SI), i. [sent-95, score-0.542]
</p><p>39 estimating the subspace on which the function is supported, and then (2) Bayesian optimization (BO), in order to optimize the function on the learned subspace. [sent-97, score-0.432]
</p><p>40 A key challenge here is to carefully allocate samples between these phases. [sent-98, score-0.17]
</p><p>41 Given the (noisy) oracle for f , we ﬁrst evaluate the function at several suitably chosen points and ˆ then use a low-rank recovery algorithm to compute a matrix A that spans a subspace well aligned ˆ with the one generated by the true matrix A. [sent-101, score-0.582]
</p><p>42 We learn A using the approach from [7], which reduces the learning problem to that of low rank matrix recovery. [sent-106, score-0.111]
</p><p>43 e  3  then Fκ (w) ≥  Thus, sampling the ﬁnite difference f (ξ + εϕ) − f (ξ) provides (up to the curvature error E(ξ, ε, ϕ), and sampling noise) information about the one-dimensional subspace spanned by AT g(Aξ). [sent-117, score-0.391]
</p><p>44 Further, to infer the full kdimensional subspace A, we need to consider at least mX ≥ k centers. [sent-119, score-0.327]
</p><p>45 For concreteness, we choose the Dantzig Selector (DS, [24]), which recovers low rank matrices via minimize M M  ∗  subject to  A∗ (y − A(M )) ≤ λ,  (2)  residual  where · ∗ is the nuclear norm and · is the spectral norm. [sent-123, score-0.13]
</p><p>46 The DS will successfully recover a ˆ matrix X close to the true solution in the Frobenius norm and moreover this distance decreases linearly with λ. [sent-124, score-0.093]
</p><p>47 As shown in [7], choosing the centers C uniformly at √ random from the unit sphere Sd−1 , choosing each direction vector uniformly at random from {±1/ mΦ }k , and—in the case of ˆ noisy observations, resampling f repeatedly—sufﬁces to obtain an accurate X w. [sent-125, score-0.098]
</p><p>48 ˆ close to X, due to a result by Wedin [25] we know that the Because the DS will ﬁnd a matrix X learned subspace will be close to the true one. [sent-131, score-0.364]
</p><p>49 Concretely, we use GP-UCB [12], because it exhibits state ¯ of the art empirical performance, and enjoys strong theoretical bounds for the cumulative regret. [sent-134, score-0.256]
</p><p>50 ˆ In order to trade exploration and exploitation, the GP-UCB algorithm computes, for each point z, a score that combines the predictive mean that we have inferred for that point with its variance, which quantiﬁes the uncertainty in our estimate. [sent-137, score-0.122]
</p><p>51 Here, B is an upper bound on the squared RKHS norm of the function that we optimize, δ is an upper bound on the failure probability and γt depends on the kernel [12]: cf. [sent-139, score-0.141]
</p><p>52 3 The algorithm then greedily maximizes the ucb score above. [sent-141, score-0.408]
</p><p>53 The last ingredient that we need is theory on how to pick σ so that it bounds ˆ the noise during the execution of GP-UCB w. [sent-145, score-0.17]
</p><p>54 4  10 10  5 5  true subspace 0  g (x) ˆ  f(x, y)  0  −5  −5  −10  −10 −15  −15  −20 2 2  1  1  0 −1  y  −20 −2  0 −1 −2  −2  −1. [sent-152, score-0.327]
</p><p>55 5  2  Figure 1: A 2-dimensional function f (x, y) varying along a 1-dimensional subspace and its projections on different subspaces. [sent-156, score-0.327]
</p><p>56 This bound, intuitively, relates the approximation quality λ of the subspace to the quantities mΦ , mX as well as the step size ε. [sent-161, score-0.364]
</p><p>57 A crucial choice in our algorithm is how to allocate samples (by choosing mΦ and mX appropriately) to the tasks of subspace learning and function optimization. [sent-163, score-0.42]
</p><p>58 We now analyze both phases, and determine how to split the queries in order to optimize the cumulative regret bounds. [sent-164, score-0.527]
</p><p>59 Let us ﬁrst consider the regret incurred in the second phase, in the ideal (but unrealistic) case that ˆ the subspace is estimated exactly (i. [sent-165, score-0.721]
</p><p>60 In [12] sublinear bounds for γT have been computed for several popular kernels. [sent-171, score-0.123]
</p><p>61 ˆ What happens if the subspace A is estimated incorrectly? [sent-178, score-0.327]
</p><p>62 Moreover, the considered f ˆ additional regret per sample may be incurred by η = ||f − f ||∞ . [sent-184, score-0.394]
</p><p>63 We now state a general result that formalizes these insights by bounding the cumulative regret in terms of the samples allocated to subspace learning, and the subspace approximation quality. [sent-187, score-1.219]
</p><p>64 ˆ Lemma 1 Assume that we spend 0 < n ≤ T samples to learn the subspace such that f −f ∞ ≤ η, g ≤ B and the error is bounded by σ , each w. [sent-188, score-0.376]
</p><p>65 If we run the GP-UCB ˆ ˆ algorithm for the remaining T − n steps with the suggested σ and δ/4, then the following bound on ˆ the cumulative regret holds w. [sent-191, score-0.479]
</p><p>66 where RUCB (T, g , κ) is the regret of GP-UCB when run for T steps using g and kernel κ 5 . [sent-206, score-0.428]
</p><p>67 ˆ ˆ Lemma 1 breaks down the regret in terms of the approximation error incurred by subspace2 misestimation, and the optimization error incurred by the resulting increased complexity g Hκ ≤ ˆ B. [sent-207, score-0.539]
</p><p>68 We now analyze these effects, and then prove our main regret bounds. [sent-208, score-0.343]
</p><p>69 A notion that will prove to be very helpful for analyzing both, the approximation precision η and the norm of g , is the set of angles between the subspaces that are ˆ ˆ deﬁned by A and A. [sent-210, score-0.188]
</p><p>70 We ˆ to be equal to the singular deﬁne the vector of cosines between the spanned subspaces cos Θ(A, A) ˆ ˆ ˆ values of AAT . [sent-213, score-0.241]
</p><p>71 Analogously sin Θ(A, A)i = (1 − cos Θ(A, A)2 )1/2 . [sent-214, score-0.09]
</p><p>72 Lemma 3 If g ∈ Hκ for a kernel that is isotropic with a radially non-increasing Fourier transform √ ˆ ˆ and g (x) = g(AAT x) for some A, A with orthogonal rows, then for C = C2 2k(1 + ε), ˆ ¯ 2 2 −1 ˆ ˆ ˆ . [sent-220, score-0.262]
</p><p>73 (5) ≤ | prod cos Θ(A, A)| g f −f ≤ C sin Θ(A, A) and g ˆ ∞  Hκ  2  Hκ  d  Here, we use the notation prod x = i=1 xi to denote the product of the elements of a vector. [sent-221, score-0.184]
</p><p>74 By ˆ decreasing the angles we tackle both issues: the approximation error η = f − f ∞ is reduced and the norm of g gets closer to the one of g. [sent-222, score-0.125]
</p><p>75 Hence, g will not be in the RKHS only if M ˆ is rank deﬁcient as dimensions are collapsed. [sent-225, score-0.094]
</p><p>76 We now present our main bounds on the cumulative regret. [sent-227, score-0.213]
</p><p>77 As it turns out, subspace learning is substantially harder in the case of noisy observations. [sent-230, score-0.395]
</p><p>78 The following theorem guarantees ˆ that √ this setting for non-linear kernels we have a regret dominated by GP-UCB, which is of order in Ω∗ ( T γT ), as it is usually exponential in k. [sent-236, score-0.373]
</p><p>79 1 Theorem 4 If the observations are noiseless we can pick mx = O(kd log 1/δ), ε = k2. [sent-237, score-0.432]
</p><p>80 5  Because the noise parameter σ depends on T , we have to slightly change the bounds from [12] as we have ˆ a term of order O( log T + log(1/δ)); c. [sent-239, score-0.125]
</p><p>81 In the noiseless case, it sufﬁces to increase the number of directions mΦ and decrease the step size ε in estimating the ﬁnite differences. [sent-245, score-0.104]
</p><p>82 Nevertheless, we are able to obtain cumulative regret bounds (and thereby the ﬁrst convergence guarantees and rates) for this setting, which only polynomially depend on d. [sent-249, score-0.588]
</p><p>83 Unfortunately, the dependence on T is now weaker than those in the noiseless setting (Theorem 4), and the regret due to the subspace learning might dominate that of GP-UCB. [sent-250, score-0.742]
</p><p>84 Underﬁtting k leads to additional errors that are well-controlled in low-rank subspace estimation [24]. [sent-262, score-0.327]
</p><p>85 5  Experiments  The main intent of our experiments is to provide a proof of concept, conﬁrming that SI-BO not just in theory provides the ﬁrst subexponential regret bounds, but also empirically obtains low average regret for Bayesian optimization in high dimensions. [sent-264, score-0.89]
</p><p>86 To optimize the UCB score we sampled on a grid on the low dimensional subspace. [sent-271, score-0.149]
</p><p>87 We generate random 2-dimensional samples from a GP with Mat` rn kernel e 2 with smoothness parameter ν = 5/2, length scale = 1/2 and signal variance σf = 1. [sent-276, score-0.134]
</p><p>88 The samples are “hidden” in a random 2-dimensional subspace in 100 dimensions. [sent-277, score-0.376]
</p><p>89 We show both the average regret and simple regret (i. [sent-286, score-0.686]
</p><p>90 We ﬁnd that although SI-BO spends a total of mX (mΦ + 1) samples to learn the subspace and thus incurs 7  1  0. [sent-289, score-0.376]
</p><p>91 Our SI-BO approach outperforms the natural benchmarks in terms of cumulative regret, and competes well with the unrealistic ExactUCB approach that knows the true subspace A. [sent-314, score-0.497]
</p><p>92 much regret during this phase, learning the subspace pays off, both for average and simple regret, and SI-BO ultimately outperforms the baseline methods on both data sets. [sent-315, score-0.67]
</p><p>93 This demonstrates the value of accurate subspace estimation for Bayesian optimization in high dimensions. [sent-316, score-0.384]
</p><p>94 6  Conclusion  We have addressed the problem of optimizing high dimensional functions from noisy and expensive samples. [sent-325, score-0.164]
</p><p>95 We presented the SI-BO algorithm, which tackles this challenge under the assumption that the objective varies only along a low dimensional subspace, and has low norm in a suitable RKHS. [sent-326, score-0.224]
</p><p>96 By fusing modern techniques for low rank matrix recovery and Bayesian bandit optimization in a carefully calibrated manner, it addresses the exploration–exploitation dilemma, and enjoys cumulative regret bounds, which only polynomially depend on the ambient dimension. [sent-327, score-1.009]
</p><p>97 Information-theoretic regret bounds for gaussian process optimization in the bandit setting. [sent-402, score-0.585]
</p><p>98 A tutorial on bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning. [sent-409, score-0.154]
</p><p>99 Joint optimization and variable selection of high-dimensional gaussian processes. [sent-437, score-0.092]
</p><p>100 Tight oracle inequalities for low-rank matrix recovery from a minimal number of noisy random measurements. [sent-478, score-0.225]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ucb', 0.374), ('regret', 0.343), ('subspace', 0.327), ('mx', 0.315), ('rkhs', 0.174), ('aat', 0.16), ('cumulative', 0.136), ('exploitation', 0.127), ('gab', 0.115), ('randomh', 0.115), ('randoms', 0.115), ('rucb', 0.115), ('subexponential', 0.115), ('rt', 0.108), ('bo', 0.105), ('snf', 0.101), ('ax', 0.1), ('cos', 0.09), ('gp', 0.089), ('exploration', 0.088), ('kernel', 0.085), ('bounds', 0.077), ('radially', 0.076), ('bandit', 0.073), ('noiseless', 0.072), ('recovery', 0.069), ('noisy', 0.068), ('bayesian', 0.067), ('ambient', 0.063), ('isotropic', 0.063), ('subspaces', 0.063), ('bd', 0.063), ('ds', 0.06), ('tyagi', 0.057), ('xds', 0.057), ('optimization', 0.057), ('norm', 0.056), ('mat', 0.056), ('dimensions', 0.052), ('incurred', 0.051), ('oracle', 0.051), ('cosines', 0.051), ('gait', 0.051), ('ys', 0.05), ('rbf', 0.049), ('samples', 0.049), ('noise', 0.048), ('optimize', 0.048), ('tradeoffs', 0.047), ('carefully', 0.047), ('prod', 0.047), ('sublinear', 0.046), ('pick', 0.045), ('bandits', 0.045), ('krause', 0.045), ('allocate', 0.044), ('cevher', 0.044), ('enjoys', 0.043), ('notoriously', 0.042), ('rank', 0.042), ('resample', 0.04), ('selector', 0.04), ('varies', 0.039), ('dantzig', 0.038), ('orthogonal', 0.038), ('approximation', 0.037), ('rk', 0.037), ('matrix', 0.037), ('eth', 0.037), ('singular', 0.037), ('zt', 0.036), ('lipschitz', 0.035), ('hilbert', 0.035), ('calibrated', 0.035), ('gaussian', 0.035), ('dimensional', 0.035), ('compact', 0.035), ('score', 0.034), ('derivatives', 0.034), ('unrealistic', 0.034), ('polynomially', 0.032), ('angles', 0.032), ('sampling', 0.032), ('directions', 0.032), ('low', 0.032), ('sd', 0.032), ('aligned', 0.031), ('erc', 0.031), ('dimension', 0.031), ('functions', 0.031), ('rows', 0.031), ('runs', 0.03), ('rates', 0.03), ('analogously', 0.03), ('kernels', 0.03), ('challenge', 0.03), ('expensive', 0.03), ('suitably', 0.03), ('acknowledges', 0.03), ('centers', 0.03)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000007 <a title="137-tfidf-1" href="./nips-2013-High-Dimensional_Gaussian_Process_Bandits.html">137 nips-2013-High-Dimensional Gaussian Process Bandits</a></p>
<p>Author: Josip Djolonga, Andreas Krause, Volkan Cevher</p><p>Abstract: Many applications in machine learning require optimizing unknown functions deﬁned over a high-dimensional space from noisy samples that are expensive to obtain. We address this notoriously hard challenge, under the assumptions that the function varies only along some low-dimensional subspace and is smooth (i.e., it has a low norm in a Reproducible Kernel Hilbert Space). In particular, we present the SI-BO algorithm, which leverages recent low-rank matrix recovery techniques to learn the underlying subspace of the unknown function and applies Gaussian Process Upper Conﬁdence sampling for optimization of the function. We carefully calibrate the exploration–exploitation tradeoff by allocating the sampling budget to subspace estimation and function optimization, and obtain the ﬁrst subexponential cumulative regret bounds and convergence rates for Bayesian optimization in high-dimensions under noisy observations. Numerical results demonstrate the effectiveness of our approach in difﬁcult scenarios. 1</p><p>2 0.26859877 <a title="137-tfidf-2" href="./nips-2013-Eluder_Dimension_and_the_Sample_Complexity_of_Optimistic_Exploration.html">106 nips-2013-Eluder Dimension and the Sample Complexity of Optimistic Exploration</a></p>
<p>Author: Dan Russo, Benjamin Van Roy</p><p>Abstract: This paper considers the sample complexity of the multi-armed bandit with dependencies among the arms. Some of the most successful algorithms for this problem use the principle of optimism in the face of uncertainty to guide exploration. The clearest example of this is the class of upper conﬁdence bound (UCB) algorithms, but recent work has shown that a simple posterior sampling algorithm, sometimes called Thompson sampling, can be analyzed in the same manner as optimistic approaches. In this paper, we develop a regret bound that holds for both classes of algorithms. This bound applies broadly and can be specialized to many model classes. It depends on a new notion we refer to as the eluder dimension, which measures the degree of dependence among action rewards. Compared to UCB algorithm regret bounds for speciﬁc model classes, our general bound matches the best available for linear models and is stronger than the best available for generalized linear models. 1</p><p>3 0.20522219 <a title="137-tfidf-3" href="./nips-2013-Sequential_Transfer_in_Multi-armed_Bandit_with_Finite_Set_of_Models.html">292 nips-2013-Sequential Transfer in Multi-armed Bandit with Finite Set of Models</a></p>
<p>Author: Mohammad Gheshlaghi azar, Alessandro Lazaric, Emma Brunskill</p><p>Abstract: Learning from prior tasks and transferring that experience to improve future performance is critical for building lifelong learning agents. Although results in supervised and reinforcement learning show that transfer may signiﬁcantly improve the learning performance, most of the literature on transfer is focused on batch learning tasks. In this paper we study the problem of sequential transfer in online learning, notably in the multi–armed bandit framework, where the objective is to minimize the total regret over a sequence of tasks by transferring knowledge from prior tasks. We introduce a novel bandit algorithm based on a method-of-moments approach for estimating the possible tasks and derive regret bounds for it. 1</p><p>4 0.1667693 <a title="137-tfidf-4" href="./nips-2013-Online_Learning_with_Costly_Features_and_Labels.html">230 nips-2013-Online Learning with Costly Features and Labels</a></p>
<p>Author: Navid Zolghadr, Gabor Bartok, Russell Greiner, András György, Csaba Szepesvari</p><p>Abstract: This paper introduces the online probing problem: In each round, the learner is able to purchase the values of a subset of feature values. After the learner uses this information to come up with a prediction for the given round, he then has the option of paying to see the loss function that he is evaluated against. Either way, the learner pays for both the errors of his predictions and also whatever he chooses to observe, including the cost of observing the loss function for the given round and the cost of the observed features. We consider two variations of this problem, depending on whether the learner can observe the label for free or not. We provide algorithms and upper and lower bounds on the regret for both variants. We show that a positive cost for observing the label signiﬁcantly increases the regret of the problem. 1</p><p>5 0.16324966 <a title="137-tfidf-5" href="./nips-2013-Provable_Subspace_Clustering%3A_When_LRR_meets_SSC.html">259 nips-2013-Provable Subspace Clustering: When LRR meets SSC</a></p>
<p>Author: Yu-Xiang Wang, Huan Xu, Chenlei Leng</p><p>Abstract: Sparse Subspace Clustering (SSC) and Low-Rank Representation (LRR) are both considered as the state-of-the-art methods for subspace clustering. The two methods are fundamentally similar in that both are convex optimizations exploiting the intuition of “Self-Expressiveness”. The main difference is that SSC minimizes the vector 1 norm of the representation matrix to induce sparsity while LRR minimizes nuclear norm (aka trace norm) to promote a low-rank structure. Because the representation matrix is often simultaneously sparse and low-rank, we propose a new algorithm, termed Low-Rank Sparse Subspace Clustering (LRSSC), by combining SSC and LRR, and develops theoretical guarantees of when the algorithm succeeds. The results reveal interesting insights into the strength and weakness of SSC and LRR and demonstrate how LRSSC can take the advantages of both methods in preserving the “Self-Expressiveness Property” and “Graph Connectivity” at the same time. 1</p><p>6 0.1618557 <a title="137-tfidf-6" href="./nips-2013-On_the_Sample_Complexity_of_Subspace_Learning.html">224 nips-2013-On the Sample Complexity of Subspace Learning</a></p>
<p>7 0.15386623 <a title="137-tfidf-7" href="./nips-2013-Dirty_Statistical_Models.html">91 nips-2013-Dirty Statistical Models</a></p>
<p>8 0.14864537 <a title="137-tfidf-8" href="./nips-2013-Online_Learning_with_Switching_Costs_and_Other_Adaptive_Adversaries.html">231 nips-2013-Online Learning with Switching Costs and Other Adaptive Adversaries</a></p>
<p>9 0.14700234 <a title="137-tfidf-9" href="./nips-2013-Dimension-Free_Exponentiated_Gradient.html">89 nips-2013-Dimension-Free Exponentiated Gradient</a></p>
<p>10 0.1446752 <a title="137-tfidf-10" href="./nips-2013-The_Pareto_Regret_Frontier.html">325 nips-2013-The Pareto Regret Frontier</a></p>
<p>11 0.14420085 <a title="137-tfidf-11" href="./nips-2013-Fantope_Projection_and_Selection%3A_A_near-optimal_convex_relaxation_of_sparse_PCA.html">116 nips-2013-Fantope Projection and Selection: A near-optimal convex relaxation of sparse PCA</a></p>
<p>12 0.14267036 <a title="137-tfidf-12" href="./nips-2013-Prior-free_and_prior-dependent_regret_bounds_for_Thompson_Sampling.html">253 nips-2013-Prior-free and prior-dependent regret bounds for Thompson Sampling</a></p>
<p>13 0.13878028 <a title="137-tfidf-13" href="./nips-2013-Online_Learning_in_Markov_Decision_Processes_with_Adversarially_Chosen_Transition_Probability_Distributions.html">227 nips-2013-Online Learning in Markov Decision Processes with Adversarially Chosen Transition Probability Distributions</a></p>
<p>14 0.13739033 <a title="137-tfidf-14" href="./nips-2013-Two-Target_Algorithms__for_Infinite-Armed___Bandits_with_Bernoulli_Rewards.html">338 nips-2013-Two-Target Algorithms  for Infinite-Armed   Bandits with Bernoulli Rewards</a></p>
<p>15 0.13635956 <a title="137-tfidf-15" href="./nips-2013-%28Nearly%29_Optimal_Algorithms_for_Private_Online_Learning_in_Full-information_and_Bandit_Settings.html">2 nips-2013-(Nearly) Optimal Algorithms for Private Online Learning in Full-information and Bandit Settings</a></p>
<p>16 0.13250209 <a title="137-tfidf-16" href="./nips-2013-Robust_learning_of_low-dimensional_dynamics_from_large_neural_ensembles.html">286 nips-2013-Robust learning of low-dimensional dynamics from large neural ensembles</a></p>
<p>17 0.13247848 <a title="137-tfidf-17" href="./nips-2013-Low-Rank_Matrix_and_Tensor_Completion_via_Adaptive_Sampling.html">179 nips-2013-Low-Rank Matrix and Tensor Completion via Adaptive Sampling</a></p>
<p>18 0.12584588 <a title="137-tfidf-18" href="./nips-2013-Online_Robust_PCA_via_Stochastic_Optimization.html">233 nips-2013-Online Robust PCA via Stochastic Optimization</a></p>
<p>19 0.11879069 <a title="137-tfidf-19" href="./nips-2013-Memory_Limited%2C_Streaming_PCA.html">188 nips-2013-Memory Limited, Streaming PCA</a></p>
<p>20 0.11738504 <a title="137-tfidf-20" href="./nips-2013-%28More%29_Efficient_Reinforcement_Learning_via_Posterior_Sampling.html">1 nips-2013-(More) Efficient Reinforcement Learning via Posterior Sampling</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.288), (1, -0.068), (2, 0.241), (3, -0.06), (4, -0.05), (5, -0.073), (6, 0.056), (7, -0.044), (8, -0.161), (9, -0.047), (10, -0.08), (11, 0.115), (12, -0.089), (13, 0.058), (14, 0.127), (15, 0.013), (16, -0.067), (17, 0.028), (18, -0.037), (19, -0.136), (20, 0.011), (21, -0.038), (22, -0.04), (23, -0.015), (24, 0.106), (25, 0.041), (26, -0.049), (27, -0.052), (28, 0.011), (29, 0.048), (30, -0.051), (31, -0.019), (32, 0.061), (33, -0.006), (34, -0.06), (35, 0.08), (36, 0.113), (37, -0.013), (38, 0.118), (39, -0.075), (40, 0.031), (41, 0.018), (42, -0.134), (43, 0.056), (44, 0.092), (45, 0.066), (46, 0.042), (47, 0.035), (48, -0.008), (49, -0.043)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9470042 <a title="137-lsi-1" href="./nips-2013-High-Dimensional_Gaussian_Process_Bandits.html">137 nips-2013-High-Dimensional Gaussian Process Bandits</a></p>
<p>Author: Josip Djolonga, Andreas Krause, Volkan Cevher</p><p>Abstract: Many applications in machine learning require optimizing unknown functions deﬁned over a high-dimensional space from noisy samples that are expensive to obtain. We address this notoriously hard challenge, under the assumptions that the function varies only along some low-dimensional subspace and is smooth (i.e., it has a low norm in a Reproducible Kernel Hilbert Space). In particular, we present the SI-BO algorithm, which leverages recent low-rank matrix recovery techniques to learn the underlying subspace of the unknown function and applies Gaussian Process Upper Conﬁdence sampling for optimization of the function. We carefully calibrate the exploration–exploitation tradeoff by allocating the sampling budget to subspace estimation and function optimization, and obtain the ﬁrst subexponential cumulative regret bounds and convergence rates for Bayesian optimization in high-dimensions under noisy observations. Numerical results demonstrate the effectiveness of our approach in difﬁcult scenarios. 1</p><p>2 0.66011661 <a title="137-lsi-2" href="./nips-2013-On_the_Sample_Complexity_of_Subspace_Learning.html">224 nips-2013-On the Sample Complexity of Subspace Learning</a></p>
<p>Author: Alessandro Rudi, Guillermo D. Canas, Lorenzo Rosasco</p><p>Abstract: A large number of algorithms in machine learning, from principal component analysis (PCA), and its non-linear (kernel) extensions, to more recent spectral embedding and support estimation methods, rely on estimating a linear subspace from samples. In this paper we introduce a general formulation of this problem and derive novel learning error estimates. Our results rely on natural assumptions on the spectral properties of the covariance operator associated to the data distribution, and hold for a wide class of metrics between subspaces. As special cases, we discuss sharp error estimates for the reconstruction properties of PCA and spectral support estimation. Key to our analysis is an operator theoretic approach that has broad applicability to spectral learning methods. 1</p><p>3 0.65395492 <a title="137-lsi-3" href="./nips-2013-Provable_Subspace_Clustering%3A_When_LRR_meets_SSC.html">259 nips-2013-Provable Subspace Clustering: When LRR meets SSC</a></p>
<p>Author: Yu-Xiang Wang, Huan Xu, Chenlei Leng</p><p>Abstract: Sparse Subspace Clustering (SSC) and Low-Rank Representation (LRR) are both considered as the state-of-the-art methods for subspace clustering. The two methods are fundamentally similar in that both are convex optimizations exploiting the intuition of “Self-Expressiveness”. The main difference is that SSC minimizes the vector 1 norm of the representation matrix to induce sparsity while LRR minimizes nuclear norm (aka trace norm) to promote a low-rank structure. Because the representation matrix is often simultaneously sparse and low-rank, we propose a new algorithm, termed Low-Rank Sparse Subspace Clustering (LRSSC), by combining SSC and LRR, and develops theoretical guarantees of when the algorithm succeeds. The results reveal interesting insights into the strength and weakness of SSC and LRR and demonstrate how LRSSC can take the advantages of both methods in preserving the “Self-Expressiveness Property” and “Graph Connectivity” at the same time. 1</p><p>4 0.64317435 <a title="137-lsi-4" href="./nips-2013-Eluder_Dimension_and_the_Sample_Complexity_of_Optimistic_Exploration.html">106 nips-2013-Eluder Dimension and the Sample Complexity of Optimistic Exploration</a></p>
<p>Author: Dan Russo, Benjamin Van Roy</p><p>Abstract: This paper considers the sample complexity of the multi-armed bandit with dependencies among the arms. Some of the most successful algorithms for this problem use the principle of optimism in the face of uncertainty to guide exploration. The clearest example of this is the class of upper conﬁdence bound (UCB) algorithms, but recent work has shown that a simple posterior sampling algorithm, sometimes called Thompson sampling, can be analyzed in the same manner as optimistic approaches. In this paper, we develop a regret bound that holds for both classes of algorithms. This bound applies broadly and can be specialized to many model classes. It depends on a new notion we refer to as the eluder dimension, which measures the degree of dependence among action rewards. Compared to UCB algorithm regret bounds for speciﬁc model classes, our general bound matches the best available for linear models and is stronger than the best available for generalized linear models. 1</p><p>5 0.63582903 <a title="137-lsi-5" href="./nips-2013-Sequential_Transfer_in_Multi-armed_Bandit_with_Finite_Set_of_Models.html">292 nips-2013-Sequential Transfer in Multi-armed Bandit with Finite Set of Models</a></p>
<p>Author: Mohammad Gheshlaghi azar, Alessandro Lazaric, Emma Brunskill</p><p>Abstract: Learning from prior tasks and transferring that experience to improve future performance is critical for building lifelong learning agents. Although results in supervised and reinforcement learning show that transfer may signiﬁcantly improve the learning performance, most of the literature on transfer is focused on batch learning tasks. In this paper we study the problem of sequential transfer in online learning, notably in the multi–armed bandit framework, where the objective is to minimize the total regret over a sequence of tasks by transferring knowledge from prior tasks. We introduce a novel bandit algorithm based on a method-of-moments approach for estimating the possible tasks and derive regret bounds for it. 1</p><p>6 0.60140836 <a title="137-lsi-6" href="./nips-2013-Dirty_Statistical_Models.html">91 nips-2013-Dirty Statistical Models</a></p>
<p>7 0.59999084 <a title="137-lsi-7" href="./nips-2013-Regret_based_Robust_Solutions_for_Uncertain_Markov_Decision_Processes.html">270 nips-2013-Regret based Robust Solutions for Uncertain Markov Decision Processes</a></p>
<p>8 0.58579755 <a title="137-lsi-8" href="./nips-2013-Prior-free_and_prior-dependent_regret_bounds_for_Thompson_Sampling.html">253 nips-2013-Prior-free and prior-dependent regret bounds for Thompson Sampling</a></p>
<p>9 0.56831491 <a title="137-lsi-9" href="./nips-2013-Learning_Prices_for_Repeated_Auctions_with_Strategic_Buyers.html">159 nips-2013-Learning Prices for Repeated Auctions with Strategic Buyers</a></p>
<p>10 0.5504387 <a title="137-lsi-10" href="./nips-2013-%28More%29_Efficient_Reinforcement_Learning_via_Posterior_Sampling.html">1 nips-2013-(More) Efficient Reinforcement Learning via Posterior Sampling</a></p>
<p>11 0.54800808 <a title="137-lsi-11" href="./nips-2013-Estimation_Bias_in_Multi-Armed_Bandit_Algorithms_for_Search_Advertising.html">112 nips-2013-Estimation Bias in Multi-Armed Bandit Algorithms for Search Advertising</a></p>
<p>12 0.5371027 <a title="137-lsi-12" href="./nips-2013-Online_Learning_with_Costly_Features_and_Labels.html">230 nips-2013-Online Learning with Costly Features and Labels</a></p>
<p>13 0.53421015 <a title="137-lsi-13" href="./nips-2013-Fantope_Projection_and_Selection%3A_A_near-optimal_convex_relaxation_of_sparse_PCA.html">116 nips-2013-Fantope Projection and Selection: A near-optimal convex relaxation of sparse PCA</a></p>
<p>14 0.52758819 <a title="137-lsi-14" href="./nips-2013-Efficient_Exploration_and_Value_Function_Generalization_in_Deterministic_Systems.html">103 nips-2013-Efficient Exploration and Value Function Generalization in Deterministic Systems</a></p>
<p>15 0.52372622 <a title="137-lsi-15" href="./nips-2013-The_Pareto_Regret_Frontier.html">325 nips-2013-The Pareto Regret Frontier</a></p>
<p>16 0.52258354 <a title="137-lsi-16" href="./nips-2013-Sketching_Structured_Matrices_for_Faster_Nonlinear_Regression.html">297 nips-2013-Sketching Structured Matrices for Faster Nonlinear Regression</a></p>
<p>17 0.5172407 <a title="137-lsi-17" href="./nips-2013-Thompson_Sampling_for_1-Dimensional_Exponential_Family_Bandits.html">330 nips-2013-Thompson Sampling for 1-Dimensional Exponential Family Bandits</a></p>
<p>18 0.50262934 <a title="137-lsi-18" href="./nips-2013-Dimension-Free_Exponentiated_Gradient.html">89 nips-2013-Dimension-Free Exponentiated Gradient</a></p>
<p>19 0.49733624 <a title="137-lsi-19" href="./nips-2013-Memory_Limited%2C_Streaming_PCA.html">188 nips-2013-Memory Limited, Streaming PCA</a></p>
<p>20 0.49459729 <a title="137-lsi-20" href="./nips-2013-Online_Learning_with_Switching_Costs_and_Other_Adaptive_Adversaries.html">231 nips-2013-Online Learning with Switching Costs and Other Adaptive Adversaries</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.02), (16, 0.029), (19, 0.027), (33, 0.178), (34, 0.116), (41, 0.027), (49, 0.035), (53, 0.147), (56, 0.191), (70, 0.022), (85, 0.038), (89, 0.045), (93, 0.033), (95, 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.95369995 <a title="137-lda-1" href="./nips-2013-Multisensory_Encoding%2C_Decoding%2C_and_Identification.html">205 nips-2013-Multisensory Encoding, Decoding, and Identification</a></p>
<p>Author: Aurel A. Lazar, Yevgeniy Slutskiy</p><p>Abstract: We investigate a spiking neuron model of multisensory integration. Multiple stimuli from different sensory modalities are encoded by a single neural circuit comprised of a multisensory bank of receptive ﬁelds in cascade with a population of biophysical spike generators. We demonstrate that stimuli of different dimensions can be faithfully multiplexed and encoded in the spike domain and derive tractable algorithms for decoding each stimulus from the common pool of spikes. We also show that the identiﬁcation of multisensory processing in a single neuron is dual to the recovery of stimuli encoded with a population of multisensory neurons, and prove that only a projection of the circuit onto input stimuli can be identiﬁed. We provide an example of multisensory integration using natural audio and video and discuss the performance of the proposed decoding and identiﬁcation algorithms. 1</p><p>same-paper 2 0.92436492 <a title="137-lda-2" href="./nips-2013-High-Dimensional_Gaussian_Process_Bandits.html">137 nips-2013-High-Dimensional Gaussian Process Bandits</a></p>
<p>Author: Josip Djolonga, Andreas Krause, Volkan Cevher</p><p>Abstract: Many applications in machine learning require optimizing unknown functions deﬁned over a high-dimensional space from noisy samples that are expensive to obtain. We address this notoriously hard challenge, under the assumptions that the function varies only along some low-dimensional subspace and is smooth (i.e., it has a low norm in a Reproducible Kernel Hilbert Space). In particular, we present the SI-BO algorithm, which leverages recent low-rank matrix recovery techniques to learn the underlying subspace of the unknown function and applies Gaussian Process Upper Conﬁdence sampling for optimization of the function. We carefully calibrate the exploration–exploitation tradeoff by allocating the sampling budget to subspace estimation and function optimization, and obtain the ﬁrst subexponential cumulative regret bounds and convergence rates for Bayesian optimization in high-dimensions under noisy observations. Numerical results demonstrate the effectiveness of our approach in difﬁcult scenarios. 1</p><p>3 0.89917552 <a title="137-lda-3" href="./nips-2013-Convex_Two-Layer_Modeling.html">75 nips-2013-Convex Two-Layer Modeling</a></p>
<p>Author: Özlem Aslan, Hao Cheng, Xinhua Zhang, Dale Schuurmans</p><p>Abstract: Latent variable prediction models, such as multi-layer networks, impose auxiliary latent variables between inputs and outputs to allow automatic inference of implicit features useful for prediction. Unfortunately, such models are difﬁcult to train because inference over latent variables must be performed concurrently with parameter optimization—creating a highly non-convex problem. Instead of proposing another local training method, we develop a convex relaxation of hidden-layer conditional models that admits global training. Our approach extends current convex modeling approaches to handle two nested nonlinearities separated by a non-trivial adaptive latent layer. The resulting methods are able to acquire two-layer models that cannot be represented by any single-layer model over the same features, while improving training quality over local heuristics. 1</p><p>4 0.88881093 <a title="137-lda-4" href="./nips-2013-Confidence_Intervals_and_Hypothesis_Testing_for_High-Dimensional_Statistical_Models.html">68 nips-2013-Confidence Intervals and Hypothesis Testing for High-Dimensional Statistical Models</a></p>
<p>Author: Adel Javanmard, Andrea Montanari</p><p>Abstract: Fitting high-dimensional statistical models often requires the use of non-linear parameter estimation procedures. As a consequence, it is generally impossible to obtain an exact characterization of the probability distribution of the parameter estimates. This in turn implies that it is extremely challenging to quantify the uncertainty associated with a certain parameter estimate. Concretely, no commonly accepted procedure exists for computing classical measures of uncertainty and statistical signiﬁcance as conﬁdence intervals or p-values. We consider here a broad class of regression problems, and propose an efﬁcient algorithm for constructing conﬁdence intervals and p-values. The resulting conﬁdence intervals have nearly optimal size. When testing for the null hypothesis that a certain parameter is vanishing, our method has nearly optimal power. Our approach is based on constructing a ‘de-biased’ version of regularized Mestimators. The new construction improves over recent work in the ﬁeld in that it does not assume a special structure on the design matrix. Furthermore, proofs are remarkably simple. We test our method on a diabetes prediction problem. 1</p><p>5 0.8869527 <a title="137-lda-5" href="./nips-2013-Polar_Operators_for_Structured_Sparse_Estimation.html">249 nips-2013-Polar Operators for Structured Sparse Estimation</a></p>
<p>Author: Xinhua Zhang, Yao-Liang Yu, Dale Schuurmans</p><p>Abstract: Structured sparse estimation has become an important technique in many areas of data analysis. Unfortunately, these estimators normally create computational difﬁculties that entail sophisticated algorithms. Our ﬁrst contribution is to uncover a rich class of structured sparse regularizers whose polar operator can be evaluated efﬁciently. With such an operator, a simple conditional gradient method can then be developed that, when combined with smoothing and local optimization, significantly reduces training time vs. the state of the art. We also demonstrate a new reduction of polar to proximal maps that enables more efﬁcient latent fused lasso. 1</p><p>6 0.8831104 <a title="137-lda-6" href="./nips-2013-On_the_Sample_Complexity_of_Subspace_Learning.html">224 nips-2013-On the Sample Complexity of Subspace Learning</a></p>
<p>7 0.8820855 <a title="137-lda-7" href="./nips-2013-Information-theoretic_lower_bounds_for_distributed_statistical_estimation_with_communication_constraints.html">142 nips-2013-Information-theoretic lower bounds for distributed statistical estimation with communication constraints</a></p>
<p>8 0.8820501 <a title="137-lda-8" href="./nips-2013-Online_Learning_of_Dynamic_Parameters_in_Social_Networks.html">228 nips-2013-Online Learning of Dynamic Parameters in Social Networks</a></p>
<p>9 0.88165534 <a title="137-lda-9" href="./nips-2013-Adaptive_Step-Size_for_Policy_Gradient_Methods.html">28 nips-2013-Adaptive Step-Size for Policy Gradient Methods</a></p>
<p>10 0.88155317 <a title="137-lda-10" href="./nips-2013-Convex_Tensor_Decomposition_via_Structured_Schatten_Norm_Regularization.html">74 nips-2013-Convex Tensor Decomposition via Structured Schatten Norm Regularization</a></p>
<p>11 0.88129699 <a title="137-lda-11" href="./nips-2013-Using_multiple_samples_to_learn_mixture_models.html">344 nips-2013-Using multiple samples to learn mixture models</a></p>
<p>12 0.88125044 <a title="137-lda-12" href="./nips-2013-Local_Privacy_and_Minimax_Bounds%3A_Sharp_Rates_for_Probability_Estimation.html">177 nips-2013-Local Privacy and Minimax Bounds: Sharp Rates for Probability Estimation</a></p>
<p>13 0.88119471 <a title="137-lda-13" href="./nips-2013-Which_Space_Partitioning_Tree_to_Use_for_Search%3F.html">355 nips-2013-Which Space Partitioning Tree to Use for Search?</a></p>
<p>14 0.88107061 <a title="137-lda-14" href="./nips-2013-Fantope_Projection_and_Selection%3A_A_near-optimal_convex_relaxation_of_sparse_PCA.html">116 nips-2013-Fantope Projection and Selection: A near-optimal convex relaxation of sparse PCA</a></p>
<p>15 0.88012612 <a title="137-lda-15" href="./nips-2013-Active_Learning_for_Probabilistic_Hypotheses_Using_the_Maximum_Gibbs_Error_Criterion.html">23 nips-2013-Active Learning for Probabilistic Hypotheses Using the Maximum Gibbs Error Criterion</a></p>
<p>16 0.87863535 <a title="137-lda-16" href="./nips-2013-Online_Learning_with_Costly_Features_and_Labels.html">230 nips-2013-Online Learning with Costly Features and Labels</a></p>
<p>17 0.8784371 <a title="137-lda-17" href="./nips-2013-Structured_Learning_via_Logistic_Regression.html">318 nips-2013-Structured Learning via Logistic Regression</a></p>
<p>18 0.87710035 <a title="137-lda-18" href="./nips-2013-Sequential_Transfer_in_Multi-armed_Bandit_with_Finite_Set_of_Models.html">292 nips-2013-Sequential Transfer in Multi-armed Bandit with Finite Set of Models</a></p>
<p>19 0.87595952 <a title="137-lda-19" href="./nips-2013-On_Sampling_from_the_Gibbs_Distribution_with_Random_Maximum_A-Posteriori_Perturbations.html">218 nips-2013-On Sampling from the Gibbs Distribution with Random Maximum A-Posteriori Perturbations</a></p>
<p>20 0.8759048 <a title="137-lda-20" href="./nips-2013-Data-driven_Distributionally_Robust_Polynomial_Optimization.html">80 nips-2013-Data-driven Distributionally Robust Polynomial Optimization</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
