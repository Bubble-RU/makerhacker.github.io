<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>139 nips-2013-How to Hedge an Option Against an Adversary: Black-Scholes Pricing is Minimax Optimal</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-139" href="#">nips2013-139</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>139 nips-2013-How to Hedge an Option Against an Adversary: Black-Scholes Pricing is Minimax Optimal</h1>
<br/><p>Source: <a title="nips-2013-139-pdf" href="http://papers.nips.cc/paper/4912-how-to-hedge-an-option-against-an-adversary-black-scholes-pricing-is-minimax-optimal.pdf">pdf</a></p><p>Author: Jacob Abernethy, Peter Bartlett, Rafael Frongillo, Andre Wibisono</p><p>Abstract: We consider a popular problem in ﬁnance, option pricing, through the lens of an online learning game between Nature and an Investor. In the Black-Scholes option pricing model from 1973, the Investor can continuously hedge the risk of an option by trading the underlying asset, assuming that the asset’s price ﬂuctuates according to Geometric Brownian Motion (GBM). We consider a worst-case model, in which Nature chooses a sequence of price ﬂuctuations under a cumulative quadratic volatility constraint, and the Investor can make a sequence of hedging decisions. Our main result is to show that the value of our proposed game, which is the “regret” of hedging strategy, converges to the Black-Scholes option price. We use signiﬁcantly weaker assumptions than previous work—for instance, we allow large jumps in the asset price—and show that the Black-Scholes hedging strategy is near-optimal for the Investor even in this non-stochastic framework. 1</p><p>Reference: <a title="nips-2013-139-reference" href="../nips2013_reference/nips-2013-How_to_Hedge_an_Option_Against_an_Adversary%3A_Black-Scholes_Pricing_is_Minimax_Optimal_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract We consider a popular problem in ﬁnance, option pricing, through the lens of an online learning game between Nature and an Investor. [sent-10, score-0.468]
</p><p>2 In the Black-Scholes option pricing model from 1973, the Investor can continuously hedge the risk of an option by trading the underlying asset, assuming that the asset’s price ﬂuctuates according to Geometric Brownian Motion (GBM). [sent-11, score-1.546]
</p><p>3 We consider a worst-case model, in which Nature chooses a sequence of price ﬂuctuations under a cumulative quadratic volatility constraint, and the Investor can make a sequence of hedging decisions. [sent-12, score-0.798]
</p><p>4 Our main result is to show that the value of our proposed game, which is the “regret” of hedging strategy, converges to the Black-Scholes option price. [sent-13, score-0.558]
</p><p>5 We use signiﬁcantly weaker assumptions than previous work—for instance, we allow large jumps in the asset price—and show that the Black-Scholes hedging strategy is near-optimal for the Investor even in this non-stochastic framework. [sent-14, score-0.715]
</p><p>6 1  Introduction  An option is a ﬁnancial contract that allows the purchase or sale of a given asset, such as a stock, bond, or commodity, for a predetermined price on a predetermined date. [sent-15, score-0.842]
</p><p>7 Options are bought and sold for any number of reasons, but in particular they allow ﬁrms and individuals with risk exposure to hedge against potential price ﬂuctuations. [sent-17, score-0.597]
</p><p>8 What ought we pay for the privilege of purchasing an asset at a ﬁxed price on a future expiration date? [sent-19, score-0.944]
</p><p>9 In a seminal paper from 1973, Fischer Black and Myron Scholes introduced what is now known as the Black-Scholes Option Pricing Model, which led to a boom in options trading as well as a huge literature on the problem of derivative pricing [2]. [sent-21, score-0.356]
</p><p>10 Black and Scholes had a key insight that a ﬁrm which had sold/purchased an option could “hedge” against the future cost/return of the option by buying and selling the underlying asset as its price ﬂuctuates. [sent-22, score-1.44]
</p><p>11 Their model is based on stochastic calculus and requires a critical assumption that the asset’s price behaves according to a Geometric Brownian Motion (GBM) with known drift and volatility. [sent-23, score-0.532]
</p><p>12 The GBM assumption in particular implies that (almost surely) an asset’s price ﬂuctuates continuously. [sent-24, score-0.462]
</p><p>13 The Black-Scholes model additionally requires that the ﬁrm be able to buy and sell continuously until the option’s expiration date. [sent-25, score-0.124]
</p><p>14 Neither of these properties are true in practice: the stock market is only open eight hours per day, and stock prices are known to make signiﬁcant jumps even 1  during regular trading. [sent-26, score-0.181]
</p><p>15 An alternative model for option pricing was considered1 by DeMarzo et al. [sent-28, score-0.51]
</p><p>16 [3], who posed the question: “Can we construct hedging strategies that are robust to adversarially chosen price ﬂuctuations? [sent-29, score-0.724]
</p><p>17 ” Essentially, the authors asked if we may consider hedging through the lens of regret minimization in online learning, an area that has proved fruitful, especially for obtaining guarantees robust to worst-case conditions. [sent-30, score-0.286]
</p><p>18 Within this minimax option pricing framework, DeMarzo et al. [sent-31, score-0.616]
</p><p>19 [1] took the minimax option pricing framework a step further, analyzing the zero-sum game being played between an Investor, who is attempting to replicate the option payoff, and Nature, who is sequentially setting the price changes of the underlying asset. [sent-34, score-1.522]
</p><p>20 The Investor’s goal is to “hedge” the payoff of the option as the price ﬂuctuates, whereas Nature attempts to foil the Investor by choosing a challenging sequence of price ﬂuctuations. [sent-35, score-1.33]
</p><p>21 The value of this game can be interpreted as the “minimax option price,” since it is what the Investor should pay for the option against an adversarially chosen price path. [sent-36, score-1.263]
</p><p>22 was to show that the game value approaches the Black-Scholes option price as the Investor’s trading frequency increases. [sent-38, score-1.027]
</p><p>23 Put another way, the minimax price tends to the option price under the GBM assumption. [sent-39, score-1.348]
</p><p>24 First, their techniques used minimax duality to compute the value of the game, but no particular hedging algorithm for the Investor is given. [sent-42, score-0.346]
</p><p>25 ’s result [3]) in which a hedging strategy is given explicitly. [sent-44, score-0.289]
</p><p>26 Second, the result depended on a strong constraint on Nature’s choice of price path: the multiplicative price variance is uniformly constrained, which forbids price jumps and other large ﬂuctuations. [sent-45, score-1.488]
</p><p>27 We consider the problem of minimax option pricing with much weaker constraints: we restrict the sum over the length of the game of the squared price ﬂuctuations to be no more than a constant c, and we allow arbitrary price jumps, up to a bound ⇣. [sent-47, score-1.718]
</p><p>28 We show that the minimax option price is exactly the Black-Scholes price of the option, up to an additive term of O(c⇣ 1/4 ). [sent-48, score-1.348]
</p><p>29 Furthermore, we give an explicit hedging strategy: this upper bound is achieved when the Investor’s strategy is essentially a version of the Black-Scholes hedging algorithm. [sent-49, score-0.575]
</p><p>30 2  The Black-Scholes Formula  Let us now brieﬂy review the Black-Scholes pricing formula and hedging strategy. [sent-50, score-0.432]
</p><p>31 Let us imagine we have an underlying asset A whose price is ﬂuctuating. [sent-55, score-0.821]
</p><p>32 We shall imagine that A’s price path G(t) is described by a geometric Brownian motion with drift µ and volatility , which we can describe via d the deﬁnition of a Brownian motion: G(t) = exp{(µ 1 2 )t + W (t)}. [sent-57, score-0.663]
</p><p>33 2 If an Investor purchases a European call option on some asset A (say, MSFT stock) with a strike price of K > 0 that matures at time T , then the Investor has the right to buy a share of A at price K at time T . [sent-58, score-1.634]
</p><p>34 Of course, if the market price of A at T is G(T ), then the Investor will only “exercise” the option if G(T ) > K, since the Investor has no beneﬁt of purchasing the asset at a price higher than the market price. [sent-59, score-1.662]
</p><p>35 Hence, the payoff of a European call option has a proﬁt function of the form max{0, G(T ) K}. [sent-60, score-0.382]
</p><p>36 Throughout the paper we shall use gEC (x) := max{0, x K} to refer to the payout of the European call when the price of asset A at time T is x (the parameter K is implicit). [sent-61, score-0.916]
</p><p>37 The Black-Scholes derivation begins with a guess: assume that the “value” of the European call option can be described by a smooth function V(G(t), t), depending only on the current price of the asset G(t) and the time to expiration T t. [sent-64, score-1.238]
</p><p>38 We can immediately deﬁne a boundary condition on V, since at the expiration time T the value of the option is V(G(T ), 0) = gEC (G(T )). [sent-65, score-0.417]
</p><p>39 So how do we arrive at a value for the option at another time point t? [sent-66, score-0.318]
</p><p>40 We assume the Investor has a hedging strategy, (x, t) that determines the amount to invest when the current price is x and the time is t. [sent-67, score-0.744]
</p><p>41 Notice that if the asset’s current price is G(t) and the Investor purchases (G(t), t) dollars of asset A at t, then the incremental amount of money made in an inﬁnitesimal amount of time is (G(t), t) dG/G(t), since dG/G(t) is the instantaneous multiplicative price change at time t. [sent-68, score-1.37]
</p><p>42 Of course, if the earnings of the Investor are guaranteed to exactly cancel out the inﬁnitesimal change in the value of the option dV(G(t), t), then the Investor is totally hedged with respect to the option payout for any sample of G for the remaining time to expiration. [sent-69, score-0.702]
</p><p>43 @x @t 2 @x2 Black and Scholes proposed a generic hedging strategy, that the investor should invest dV(G, t) =  (1)  @V (2) @x dollars in the asset A when the price of A is x at time t. [sent-72, score-1.543]
</p><p>44 As mentioned, the goal of the Investor is to hedge out risk so that it is always the case that dV(G, t) = (G, t) dG/G. [sent-73, score-0.135]
</p><p>45 We refer the reader to a standard text on asset pricing for more on this [8]. [sent-76, score-0.534]
</p><p>46 We assume the Investor is allowed to make a trading decision at each of n time periods, and before making this trade the investor observes how the price of the asset has changed since the previous period. [sent-78, score-1.355]
</p><p>47 Without loss of generality, we can assume that the current time is 0 and the trading periods occur at {T /n, 2T /n, . [sent-79, score-0.167]
</p><p>48 4: Nature selects a price ﬂuctuation ri and updates price S S(1 + ri ). [sent-89, score-1.254]
</p><p>49 5: Investor receives (potentially negative) proﬁt of i ri . [sent-90, score-0.165]
</p><p>50 6: end for Qn 7: Investor is charged the cost of the option, g(S) = g (S0 · i=1 (1 + ri )). [sent-91, score-0.165]
</p><p>51 i=1  i=1  3  We can interpret the above expression as a form of regret: the Investor chose to execute a trading Pn strategy, earning him Q i ri , but in hindsight might have rather purchased the option instead, i=1 n with a payout of g (S0 · i=1 (1 + ri )). [sent-94, score-0.852]
</p><p>52 What is the best hedging strategy the Investor can execute to minimize the difference between the option payoff and the gains/losses from hedging? [sent-95, score-0.688]
</p><p>53 Indeed, how much regret may be suffered against a worst-case sequence of price ﬂuctuations? [sent-96, score-0.508]
</p><p>54 The cost of playing the above sequential game is clearly going to depend on how much we expect the price to ﬂuctuate. [sent-98, score-0.588]
</p><p>55 In the original Black-Scholes formulation, the price volatility is a major parameter in the pricing function. [sent-99, score-0.702]
</p><p>56 2 Roughly, this constraint means that in any ✏-sized time interval, the price ﬂuctuation variance shall be no more than ✏. [sent-108, score-0.532]
</p><p>57 This constraint, however, does not allow for large price jumps during trading. [sent-109, score-0.522]
</p><p>58 In the present work, we impose a much weaker set of constraints, described as follows:3 Pn 2 • TotVarConstraint: The total price ﬂuctuation is bounded by a constant c: i=1 ri  c. [sent-110, score-0.651]
</p><p>59 • JumpConstraint: Every price jump |ri | is no more than ⇣, for some ⇣ > 0 (which may depend on n). [sent-111, score-0.499]
</p><p>60 The ﬁrst constraint above says that Nature is bounded by how much, in total, the asset’s price path can ﬂuctuate. [sent-112, score-0.511]
</p><p>61 The latter says that at no given time can the asset’s price jump more than a given value. [sent-113, score-0.499]
</p><p>62 The Minimax Option Price We are now in a position to deﬁne the value of the sequential option pricing game using a minimax formulation. [sent-115, score-0.742]
</p><p>63 That is, we shall ask how much the Investor loses when making optimal trading decisions against worst-case price ﬂuctuations chosen by Nature. [sent-116, score-0.629]
</p><p>64 Let (n) V⇣ (S; c, m) be the value of the game, measured by the investor’s loss, when the asset’s current price is S 0, the TotVarConstraint is c 0, the JumpConstraint is ⇣ > 0, the total number of trading rounds are n 2 N, and there are 0  m  n rounds remaining. [sent-117, score-0.644]
</p><p>65 We deﬁne recursively: (n)  V⇣  (S; c, m) = inf  (n)  sup  r + V⇣  2R r : |r|min{⇣,pc}  (n)  with the base case V⇣  ((1 + r)S; c  r2 , m  1),  (S; c, 0) = g(S). [sent-118, score-0.106]
</p><p>66 (5)  (S; c) :=  This is the value of the game that we are interested in analyzing. [sent-121, score-0.126]
</p><p>67 Towards establishing an upper bound on the value (5), we shall discuss the question of how to choose the hedge parameter on each round. [sent-122, score-0.224]
</p><p>68 We can refer to a “hedging strategy” in this game as a function of the tuple (S, c, m, n, ⇣, g(·)) that returns hedge position. [sent-123, score-0.241]
</p><p>69 In our upper bound, in fact we need only consider hedging strategies (S, c) that depend on S and c; there certainly will be a dependence on g(·) as well but we leave this implicit. [sent-124, score-0.258]
</p><p>70 ” and “Is there a natural hedging strategy (S, c) that (roughly) achieves this value? [sent-126, score-0.289]
</p><p>71 ” In other words, what is the minimax value of the option, as well as the optimal hedge, when we ﬁx the variance budget c and the asset’s current price S, but let the number of rounds tend to 1? [sent-127, score-0.627]
</p><p>72 , ri 1 ]  exp(c/n) 1, but this is roughly equivalent. [sent-133, score-0.183]
</p><p>73 [1] also assumed that the multiplicative price jumps |ri | are bounded by p ˆ ⇣n = ⌦( (log n)/n); this is a stronger assumption than what we impose on (⇣n ) in Theorem 1. [sent-135, score-0.54]
</p><p>74 Our goal will be to show that U is asymptotically the minimax price of the option. [sent-152, score-0.568]
</p><p>75 Most importantly, this function U (S, c) is identical to V(S, 12 (T c)), the Black-Scholes value of the option in (4) when the GBM volatility parameter is in the BlackScholes analysis. [sent-153, score-0.366]
</p><p>76 Let S > 0 be the initial asset price and let c > 0 be the variance budget. [sent-157, score-0.804]
</p><p>77 1  This statement tells us that the minimax price of an option, when Nature has a total ﬂuctuation budget of c, approaches the Black-Scholes price of the option when the time to expiration is c. [sent-163, score-1.467]
</p><p>78 This is particularly surprising since our minimax pricing framework made no assumptions as to the stochastic process generating the price path. [sent-164, score-0.76]
</p><p>79 Unlike [1], however, we do not show that the adversary’s minimax optimal stochastic price path necessarily converges to a GBM. [sent-166, score-0.593]
</p><p>80 The convergence of Nature’s price path to GBM in [1] was made possible by the uniform per-round variance constraint. [sent-167, score-0.487]
</p><p>81 First, we prove a lower (n) bound on the limiting value of V⇣n (S; c) by exhibiting a simple randomized strategy for Nature in the form of a stochastic price path, and appealing to the Lindeberg-Feller central limit theorem. [sent-169, score-0.539]
</p><p>82 The upper bound is obtained by providing an explicit strategy for the Investor: (S, c) = S  @U (S, c) @S  and carefully bounding the difference between the output using this strategy and the game value. [sent-171, score-0.27]
</p><p>83 5  Lower Bound (n)  In this section we prove that U (S, c) is a lower bound to the game value V⇣n (S; c). [sent-174, score-0.154]
</p><p>84 R0 be an L-Lipschitz function, and let {⇣n } be a sequence of positive 2 numbers with lim inf n! [sent-180, score-0.126]
</p><p>85 Then we have n n ⇣ Y ⌘ X (n) V⇣n (S; c) = inf sup · · · inf sup g S · (1 + ri ) i ri 1  r1  n  rn  i=1  n h ⇣ Y ⌘ inf · · · inf E g S · (1 + Ri,n ) 1  n  i=1  n h ⇣ Y ⌘i = E g S· (1 + Ri,n ) . [sent-210, score-0.683]
</p><p>86 2⇡ We remark that the right-hand side of the above bound does not depend on the number of trading periods n. [sent-219, score-0.178]
</p><p>87 The key parameter is ⇣, which determines the size of the largest price jump of the stock. [sent-220, score-0.499]
</p><p>88 However, we expect that as the trading frequency increases, the size of the largest price jump will shrink. [sent-221, score-0.62]
</p><p>89 The proof of Theorem 4 proceeds by providing a “guess” for the Investor’s action, which is a modiﬁcation of the original Black-Scholes hedging strategy. [sent-234, score-0.24]
</p><p>90 Speciﬁcally, when the current price is S and the remaining budget is c, then the Investor invests (S, c) := SUS (S, c). [sent-235, score-0.528]
</p><p>91 Note 2 that a Taylor approximation of the function rm 7! [sent-238, score-0.147]
</p><p>92 U (S + Srm , c rm ) around U (S, c) gives us U (S + Srm , c  1 2 2 3 rm Uc (S, c) + rm S 2 US 2 (S, c) + O(rm ) 2 3 = U (S, c) + rm SUS (S, c) + O(rm ),  2 rm ) = U (S, c) + rm SUS (S, c)  where the last line follows from the Black-Scholes equation (6). [sent-239, score-0.882]
</p><p>93 3 In other words, on each round of the game we add an O(rm ) term to the approximation error. [sent-241, score-0.126]
</p><p>94 Pn Pn 2 Since m=1 rm  c and |rm |  ⇣ by assumption, we get m=1 |rm |3  ⇣c. [sent-243, score-0.147]
</p><p>95 , rn ) =  n X  m=1  ⇣ m 1 Y ✏rm S (1 + ri ), c i=1  Pn  m 1 X i=1  ⌘ 2 ri . [sent-273, score-0.351]
</p><p>96 Let 0  n⇤  n be the largest index such that m=1 rm  c ⇣. [sent-282, score-0.147]
</p><p>97 For 1  m  min{n, n⇤ + 1}: By (11) from Lemma 6 and a little calculation, we have ⇣ m 1 Y ✏rm S (1 + ri ), c  m 1 X  i=1  i=1  ⌘ 2 2 ri  18LK ⇣ 1/4 rm . [sent-285, score-0.477]
</p><p>98 For n⇤ + 2  m  n (if n⇤  n ⇣  ✏rm S Therefore, n X  m=n⇤ +2  ⇣  ✏rm S  m 1 Y i=1  m 1 Y  m 1 X i=1  min{n, n⇤ +1} ⌘ X 2 2 ri  18LK ⇣ 1/4 rm  18LK ⇣ 1/4 c. [sent-287, score-0.312]
</p><p>99 m=1  2): By (12) from Lemma 6, we have m 1 X  (1 + ri ), c  i=1  (1 + ri ), c  i=1  m 1 X  2 ri  i=1  ⌘  ⌘ 4LK 2 rm 2 ri  p · pPn . [sent-288, score-0.807]
</p><p>100 2 2⇡ i=m ri  4LK  p 2⇡  n X  m=n⇤ +2  2 rm pPn  2 i=m ri  8LK 1/4  p ⇣ , 2⇡  where the last inequality follows from Lemma 8 in Appendix B. [sent-289, score-0.477]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('price', 0.462), ('investor', 0.43), ('asset', 0.342), ('option', 0.318), ('hedging', 0.24), ('pricing', 0.192), ('ri', 0.165), ('rm', 0.147), ('gbm', 0.132), ('game', 0.126), ('trading', 0.121), ('hedge', 0.115), ('minimax', 0.106), ('expiration', 0.099), ('sus', 0.099), ('totvarconstraint', 0.099), ('srm', 0.073), ('brownian', 0.069), ('gec', 0.066), ('payout', 0.066), ('payoff', 0.064), ('abernethy', 0.062), ('jumps', 0.06), ('inf', 0.06), ('demarzo', 0.058), ('uctuation', 0.051), ('uctuations', 0.05), ('jumpconstraint', 0.05), ('scholes', 0.05), ('pn', 0.05), ('lemma', 0.049), ('strategy', 0.049), ('volatility', 0.048), ('shall', 0.046), ('sup', 0.046), ('dollars', 0.044), ('calculus', 0.043), ('lim', 0.042), ('motion', 0.038), ('stock', 0.037), ('dv', 0.037), ('jump', 0.037), ('european', 0.036), ('uctuates', 0.035), ('nature', 0.033), ('ppn', 0.033), ('shafer', 0.033), ('taylor', 0.033), ('supremum', 0.03), ('periods', 0.029), ('invests', 0.029), ('wibisono', 0.029), ('bound', 0.028), ('uous', 0.027), ('unrolling', 0.027), ('frongillo', 0.027), ('market', 0.027), ('drift', 0.027), ('eventually', 0.026), ('theorem', 0.026), ('buy', 0.025), ('invest', 0.025), ('purchases', 0.025), ('path', 0.025), ('lk', 0.025), ('sequence', 0.024), ('options', 0.024), ('weaker', 0.024), ('lens', 0.024), ('purchasing', 0.024), ('constraint', 0.024), ('rounds', 0.022), ('predetermined', 0.022), ('adversarially', 0.022), ('regret', 0.022), ('rn', 0.021), ('derivatives', 0.02), ('budget', 0.02), ('nitesimal', 0.02), ('prices', 0.02), ('risk', 0.02), ('book', 0.019), ('approx', 0.019), ('course', 0.019), ('black', 0.019), ('sr', 0.019), ('derivative', 0.019), ('upper', 0.018), ('contract', 0.018), ('super', 0.018), ('roughly', 0.018), ('multiplicative', 0.018), ('uc', 0.017), ('guess', 0.017), ('current', 0.017), ('question', 0.017), ('pay', 0.017), ('adversary', 0.017), ('execute', 0.017), ('imagine', 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000007 <a title="139-tfidf-1" href="./nips-2013-How_to_Hedge_an_Option_Against_an_Adversary%3A_Black-Scholes_Pricing_is_Minimax_Optimal.html">139 nips-2013-How to Hedge an Option Against an Adversary: Black-Scholes Pricing is Minimax Optimal</a></p>
<p>Author: Jacob Abernethy, Peter Bartlett, Rafael Frongillo, Andre Wibisono</p><p>Abstract: We consider a popular problem in ﬁnance, option pricing, through the lens of an online learning game between Nature and an Investor. In the Black-Scholes option pricing model from 1973, the Investor can continuously hedge the risk of an option by trading the underlying asset, assuming that the asset’s price ﬂuctuates according to Geometric Brownian Motion (GBM). We consider a worst-case model, in which Nature chooses a sequence of price ﬂuctuations under a cumulative quadratic volatility constraint, and the Investor can make a sequence of hedging decisions. Our main result is to show that the value of our proposed game, which is the “regret” of hedging strategy, converges to the Black-Scholes option price. We use signiﬁcantly weaker assumptions than previous work—for instance, we allow large jumps in the asset price—and show that the Black-Scholes hedging strategy is near-optimal for the Investor even in this non-stochastic framework. 1</p><p>2 0.24361813 <a title="139-tfidf-2" href="./nips-2013-Adaptive_Market_Making_via_Online_Learning.html">26 nips-2013-Adaptive Market Making via Online Learning</a></p>
<p>Author: Jacob Abernethy, Satyen Kale</p><p>Abstract: We consider the design of strategies for market making in an exchange. A market maker generally seeks to proﬁt from the difference between the buy and sell price of an asset, yet the market maker also takes exposure risk in the event of large price movements. Proﬁt guarantees for market making strategies have typically required certain stochastic assumptions on the price ﬂuctuations of the asset in question; for example, assuming a model in which the price process is mean reverting. We propose a class of “spread-based” market making strategies whose performance can be controlled even under worst-case (adversarial) settings. We prove structural properties of these strategies which allows us to design a master algorithm which obtains low regret relative to the best such strategy in hindsight. We run a set of experiments showing favorable performance on recent real-world stock price data. 1</p><p>3 0.12943371 <a title="139-tfidf-3" href="./nips-2013-Minimax_Optimal_Algorithms_for_Unconstrained_Linear_Optimization.html">191 nips-2013-Minimax Optimal Algorithms for Unconstrained Linear Optimization</a></p>
<p>Author: Brendan McMahan, Jacob Abernethy</p><p>Abstract: We design and analyze minimax-optimal algorithms for online linear optimization games where the player’s choice is unconstrained. The player strives to minimize regret, the difference between his loss and the loss of a post-hoc benchmark strategy. While the standard benchmark is the loss of the best strategy chosen from a bounded comparator set, we consider a very broad range of benchmark functions. The problem is cast as a sequential multi-stage zero-sum game, and we give a thorough analysis of the minimax behavior of the game, providing characterizations for the value of the game, as well as both the player’s and the adversary’s optimal strategy. We show how these objects can be computed efﬁciently under certain circumstances, and by selecting an appropriate benchmark, we construct a novel hedging strategy for an unconstrained betting game. 1</p><p>4 0.082123011 <a title="139-tfidf-4" href="./nips-2013-Online_Learning_with_Switching_Costs_and_Other_Adaptive_Adversaries.html">231 nips-2013-Online Learning with Switching Costs and Other Adaptive Adversaries</a></p>
<p>Author: Nicolò Cesa-Bianchi, Ofer Dekel, Ohad Shamir</p><p>Abstract: We study the power of different types of adaptive (nonoblivious) adversaries in the setting of prediction with expert advice, under both full-information and bandit feedback. We measure the player’s performance using a new notion of regret, also known as policy regret, which better captures the adversary’s adaptiveness to the player’s behavior. In a setting where losses are allowed to drift, we characterize —in a nearly complete manner— the power of adaptive adversaries with bounded memories and switching costs. In particular, we show that with switch� ing costs, the attainable rate with bandit feedback is Θ(T 2/3 ). Interestingly, this √ rate is signiﬁcantly worse than the Θ( T ) rate attainable with switching costs in the full-information case. Via a novel reduction from experts to bandits, we also � show that a bounded memory adversary can force Θ(T 2/3 ) regret even in the full information case, proving that switching costs are easier to control than bounded memory adversaries. Our lower bounds rely on a new stochastic adversary strategy that generates loss processes with strong dependencies. 1</p><p>5 0.076203495 <a title="139-tfidf-5" href="./nips-2013-Learning_Prices_for_Repeated_Auctions_with_Strategic_Buyers.html">159 nips-2013-Learning Prices for Repeated Auctions with Strategic Buyers</a></p>
<p>Author: Kareem Amin, Afshin Rostamizadeh, Umar Syed</p><p>Abstract: Inspired by real-time ad exchanges for online display advertising, we consider the problem of inferring a buyer’s value distribution for a good when the buyer is repeatedly interacting with a seller through a posted-price mechanism. We model the buyer as a strategic agent, whose goal is to maximize her long-term surplus, and we are interested in mechanisms that maximize the seller’s long-term revenue. We deﬁne the natural notion of strategic regret — the lost revenue as measured against a truthful (non-strategic) buyer. We present seller algorithms that are no(strategic)-regret when the buyer discounts her future surplus — i.e. the buyer prefers showing advertisements to users sooner rather than later. We also give a lower bound on strategic regret that increases as the buyer’s discounting weakens and shows, in particular, that any seller algorithm will suffer linear strategic regret if there is no discounting. 1</p><p>6 0.066489607 <a title="139-tfidf-6" href="./nips-2013-Stochastic_Ratio_Matching_of_RBMs_for_Sparse_High-Dimensional_Inputs.html">315 nips-2013-Stochastic Ratio Matching of RBMs for Sparse High-Dimensional Inputs</a></p>
<p>7 0.062358689 <a title="139-tfidf-7" href="./nips-2013-The_Pareto_Regret_Frontier.html">325 nips-2013-The Pareto Regret Frontier</a></p>
<p>8 0.05721058 <a title="139-tfidf-8" href="./nips-2013-Information-theoretic_lower_bounds_for_distributed_statistical_estimation_with_communication_constraints.html">142 nips-2013-Information-theoretic lower bounds for distributed statistical estimation with communication constraints</a></p>
<p>9 0.054861557 <a title="139-tfidf-9" href="./nips-2013-Online_Learning_with_Costly_Features_and_Labels.html">230 nips-2013-Online Learning with Costly Features and Labels</a></p>
<p>10 0.051096462 <a title="139-tfidf-10" href="./nips-2013-Reinforcement_Learning_in_Robust_Markov_Decision_Processes.html">273 nips-2013-Reinforcement Learning in Robust Markov Decision Processes</a></p>
<p>11 0.048456658 <a title="139-tfidf-11" href="./nips-2013-On_the_Linear_Convergence_of_the_Proximal_Gradient_Method_for_Trace_Norm_Regularization.html">222 nips-2013-On the Linear Convergence of the Proximal Gradient Method for Trace Norm Regularization</a></p>
<p>12 0.048201151 <a title="139-tfidf-12" href="./nips-2013-Stochastic_Majorization-Minimization_Algorithms_for_Large-Scale_Optimization.html">313 nips-2013-Stochastic Majorization-Minimization Algorithms for Large-Scale Optimization</a></p>
<p>13 0.047333021 <a title="139-tfidf-13" href="./nips-2013-Stochastic_Convex_Optimization_with_Multiple__Objectives.html">311 nips-2013-Stochastic Convex Optimization with Multiple  Objectives</a></p>
<p>14 0.043119002 <a title="139-tfidf-14" href="./nips-2013-Bayesian_inference_as_iterated_random_functions_with__applications_to_sequential_inference_in_graphical_models.html">52 nips-2013-Bayesian inference as iterated random functions with  applications to sequential inference in graphical models</a></p>
<p>15 0.043113101 <a title="139-tfidf-15" href="./nips-2013-Local_Privacy_and_Minimax_Bounds%3A_Sharp_Rates_for_Probability_Estimation.html">177 nips-2013-Local Privacy and Minimax Bounds: Sharp Rates for Probability Estimation</a></p>
<p>16 0.04114769 <a title="139-tfidf-16" href="./nips-2013-Online_Learning_in_Markov_Decision_Processes_with_Adversarially_Chosen_Transition_Probability_Distributions.html">227 nips-2013-Online Learning in Markov Decision Processes with Adversarially Chosen Transition Probability Distributions</a></p>
<p>17 0.040894642 <a title="139-tfidf-17" href="./nips-2013-Optimization%2C_Learning%2C_and_Games_with_Predictable_Sequences.html">240 nips-2013-Optimization, Learning, and Games with Predictable Sequences</a></p>
<p>18 0.03821829 <a title="139-tfidf-18" href="./nips-2013-Minimax_Theory_for_High-dimensional_Gaussian_Mixtures_with_Sparse_Mean_Separation.html">192 nips-2013-Minimax Theory for High-dimensional Gaussian Mixtures with Sparse Mean Separation</a></p>
<p>19 0.034743089 <a title="139-tfidf-19" href="./nips-2013-Learning_Hidden_Markov_Models_from_Non-sequence_Data_via_Tensor_Decomposition.html">155 nips-2013-Learning Hidden Markov Models from Non-sequence Data via Tensor Decomposition</a></p>
<p>20 0.034658607 <a title="139-tfidf-20" href="./nips-2013-Scoring_Workers_in_Crowdsourcing%3A_How_Many_Control_Questions_are_Enough%3F.html">290 nips-2013-Scoring Workers in Crowdsourcing: How Many Control Questions are Enough?</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.097), (1, -0.038), (2, 0.09), (3, -0.064), (4, 0.01), (5, -0.022), (6, 0.005), (7, 0.003), (8, 0.014), (9, 0.02), (10, 0.03), (11, -0.018), (12, 0.037), (13, 0.007), (14, -0.009), (15, -0.031), (16, 0.034), (17, -0.074), (18, -0.057), (19, 0.023), (20, -0.07), (21, -0.035), (22, -0.049), (23, 0.036), (24, -0.042), (25, 0.021), (26, -0.1), (27, 0.011), (28, -0.012), (29, -0.054), (30, -0.017), (31, 0.019), (32, -0.072), (33, -0.104), (34, -0.032), (35, -0.003), (36, 0.046), (37, 0.038), (38, -0.031), (39, 0.008), (40, -0.115), (41, 0.054), (42, -0.052), (43, -0.029), (44, -0.101), (45, 0.217), (46, 0.094), (47, -0.026), (48, 0.185), (49, 0.079)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95585454 <a title="139-lsi-1" href="./nips-2013-How_to_Hedge_an_Option_Against_an_Adversary%3A_Black-Scholes_Pricing_is_Minimax_Optimal.html">139 nips-2013-How to Hedge an Option Against an Adversary: Black-Scholes Pricing is Minimax Optimal</a></p>
<p>Author: Jacob Abernethy, Peter Bartlett, Rafael Frongillo, Andre Wibisono</p><p>Abstract: We consider a popular problem in ﬁnance, option pricing, through the lens of an online learning game between Nature and an Investor. In the Black-Scholes option pricing model from 1973, the Investor can continuously hedge the risk of an option by trading the underlying asset, assuming that the asset’s price ﬂuctuates according to Geometric Brownian Motion (GBM). We consider a worst-case model, in which Nature chooses a sequence of price ﬂuctuations under a cumulative quadratic volatility constraint, and the Investor can make a sequence of hedging decisions. Our main result is to show that the value of our proposed game, which is the “regret” of hedging strategy, converges to the Black-Scholes option price. We use signiﬁcantly weaker assumptions than previous work—for instance, we allow large jumps in the asset price—and show that the Black-Scholes hedging strategy is near-optimal for the Investor even in this non-stochastic framework. 1</p><p>2 0.78975236 <a title="139-lsi-2" href="./nips-2013-Learning_Prices_for_Repeated_Auctions_with_Strategic_Buyers.html">159 nips-2013-Learning Prices for Repeated Auctions with Strategic Buyers</a></p>
<p>Author: Kareem Amin, Afshin Rostamizadeh, Umar Syed</p><p>Abstract: Inspired by real-time ad exchanges for online display advertising, we consider the problem of inferring a buyer’s value distribution for a good when the buyer is repeatedly interacting with a seller through a posted-price mechanism. We model the buyer as a strategic agent, whose goal is to maximize her long-term surplus, and we are interested in mechanisms that maximize the seller’s long-term revenue. We deﬁne the natural notion of strategic regret — the lost revenue as measured against a truthful (non-strategic) buyer. We present seller algorithms that are no(strategic)-regret when the buyer discounts her future surplus — i.e. the buyer prefers showing advertisements to users sooner rather than later. We also give a lower bound on strategic regret that increases as the buyer’s discounting weakens and shows, in particular, that any seller algorithm will suffer linear strategic regret if there is no discounting. 1</p><p>3 0.76336938 <a title="139-lsi-3" href="./nips-2013-Adaptive_Market_Making_via_Online_Learning.html">26 nips-2013-Adaptive Market Making via Online Learning</a></p>
<p>Author: Jacob Abernethy, Satyen Kale</p><p>Abstract: We consider the design of strategies for market making in an exchange. A market maker generally seeks to proﬁt from the difference between the buy and sell price of an asset, yet the market maker also takes exposure risk in the event of large price movements. Proﬁt guarantees for market making strategies have typically required certain stochastic assumptions on the price ﬂuctuations of the asset in question; for example, assuming a model in which the price process is mean reverting. We propose a class of “spread-based” market making strategies whose performance can be controlled even under worst-case (adversarial) settings. We prove structural properties of these strategies which allows us to design a master algorithm which obtains low regret relative to the best such strategy in hindsight. We run a set of experiments showing favorable performance on recent real-world stock price data. 1</p><p>4 0.54796106 <a title="139-lsi-4" href="./nips-2013-Estimation_Bias_in_Multi-Armed_Bandit_Algorithms_for_Search_Advertising.html">112 nips-2013-Estimation Bias in Multi-Armed Bandit Algorithms for Search Advertising</a></p>
<p>Author: Min Xu, Tao Qin, Tie-Yan Liu</p><p>Abstract: In search advertising, the search engine needs to select the most proﬁtable advertisements to display, which can be formulated as an instance of online learning with partial feedback, also known as the stochastic multi-armed bandit (MAB) problem. In this paper, we show that the naive application of MAB algorithms to search advertising for advertisement selection will produce sample selection bias that harms the search engine by decreasing expected revenue and “estimation of the largest mean” (ELM) bias that harms the advertisers by increasing game-theoretic player-regret. We then propose simple bias-correction methods with beneﬁts to both the search engine and the advertisers. 1</p><p>5 0.47125432 <a title="139-lsi-5" href="./nips-2013-Minimax_Optimal_Algorithms_for_Unconstrained_Linear_Optimization.html">191 nips-2013-Minimax Optimal Algorithms for Unconstrained Linear Optimization</a></p>
<p>Author: Brendan McMahan, Jacob Abernethy</p><p>Abstract: We design and analyze minimax-optimal algorithms for online linear optimization games where the player’s choice is unconstrained. The player strives to minimize regret, the difference between his loss and the loss of a post-hoc benchmark strategy. While the standard benchmark is the loss of the best strategy chosen from a bounded comparator set, we consider a very broad range of benchmark functions. The problem is cast as a sequential multi-stage zero-sum game, and we give a thorough analysis of the minimax behavior of the game, providing characterizations for the value of the game, as well as both the player’s and the adversary’s optimal strategy. We show how these objects can be computed efﬁciently under certain circumstances, and by selecting an appropriate benchmark, we construct a novel hedging strategy for an unconstrained betting game. 1</p><p>6 0.46191555 <a title="139-lsi-6" href="./nips-2013-Robust_Data-Driven_Dynamic_Programming.html">280 nips-2013-Robust Data-Driven Dynamic Programming</a></p>
<p>7 0.45712712 <a title="139-lsi-7" href="./nips-2013-The_Pareto_Regret_Frontier.html">325 nips-2013-The Pareto Regret Frontier</a></p>
<p>8 0.35415751 <a title="139-lsi-8" href="./nips-2013-Information-theoretic_lower_bounds_for_distributed_statistical_estimation_with_communication_constraints.html">142 nips-2013-Information-theoretic lower bounds for distributed statistical estimation with communication constraints</a></p>
<p>9 0.3184782 <a title="139-lsi-9" href="./nips-2013-Data-driven_Distributionally_Robust_Polynomial_Optimization.html">80 nips-2013-Data-driven Distributionally Robust Polynomial Optimization</a></p>
<p>10 0.30463171 <a title="139-lsi-10" href="./nips-2013-Moment-based_Uniform_Deviation_Bounds_for_%24k%24-means_and_Friends.html">197 nips-2013-Moment-based Uniform Deviation Bounds for $k$-means and Friends</a></p>
<p>11 0.29981798 <a title="139-lsi-11" href="./nips-2013-Online_Learning_of_Dynamic_Parameters_in_Social_Networks.html">228 nips-2013-Online Learning of Dynamic Parameters in Social Networks</a></p>
<p>12 0.29496622 <a title="139-lsi-12" href="./nips-2013-Online_Learning_with_Costly_Features_and_Labels.html">230 nips-2013-Online Learning with Costly Features and Labels</a></p>
<p>13 0.28907299 <a title="139-lsi-13" href="./nips-2013-Annealing_between_distributions_by_averaging_moments.html">36 nips-2013-Annealing between distributions by averaging moments</a></p>
<p>14 0.28501958 <a title="139-lsi-14" href="./nips-2013-Reinforcement_Learning_in_Robust_Markov_Decision_Processes.html">273 nips-2013-Reinforcement Learning in Robust Markov Decision Processes</a></p>
<p>15 0.27914706 <a title="139-lsi-15" href="./nips-2013-On_the_Expressive_Power_of_Restricted_Boltzmann_Machines.html">221 nips-2013-On the Expressive Power of Restricted Boltzmann Machines</a></p>
<p>16 0.2774244 <a title="139-lsi-16" href="./nips-2013-Scoring_Workers_in_Crowdsourcing%3A_How_Many_Control_Questions_are_Enough%3F.html">290 nips-2013-Scoring Workers in Crowdsourcing: How Many Control Questions are Enough?</a></p>
<p>17 0.26113966 <a title="139-lsi-17" href="./nips-2013-Predictive_PAC_Learning_and_Process_Decompositions.html">252 nips-2013-Predictive PAC Learning and Process Decompositions</a></p>
<p>18 0.26113799 <a title="139-lsi-18" href="./nips-2013-One-shot_learning_and_big_data_with_n%3D2.html">225 nips-2013-One-shot learning and big data with n=2</a></p>
<p>19 0.25522575 <a title="139-lsi-19" href="./nips-2013-Online_Learning_in_Markov_Decision_Processes_with_Adversarially_Chosen_Transition_Probability_Distributions.html">227 nips-2013-Online Learning in Markov Decision Processes with Adversarially Chosen Transition Probability Distributions</a></p>
<p>20 0.25396016 <a title="139-lsi-20" href="./nips-2013-Solving_inverse_problem_of_Markov_chain_with_partial_observations.html">299 nips-2013-Solving inverse problem of Markov chain with partial observations</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.062), (16, 0.027), (33, 0.093), (34, 0.069), (36, 0.012), (41, 0.012), (49, 0.018), (54, 0.34), (56, 0.094), (70, 0.02), (85, 0.043), (89, 0.037), (91, 0.032), (93, 0.017), (95, 0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.76878142 <a title="139-lda-1" href="./nips-2013-How_to_Hedge_an_Option_Against_an_Adversary%3A_Black-Scholes_Pricing_is_Minimax_Optimal.html">139 nips-2013-How to Hedge an Option Against an Adversary: Black-Scholes Pricing is Minimax Optimal</a></p>
<p>Author: Jacob Abernethy, Peter Bartlett, Rafael Frongillo, Andre Wibisono</p><p>Abstract: We consider a popular problem in ﬁnance, option pricing, through the lens of an online learning game between Nature and an Investor. In the Black-Scholes option pricing model from 1973, the Investor can continuously hedge the risk of an option by trading the underlying asset, assuming that the asset’s price ﬂuctuates according to Geometric Brownian Motion (GBM). We consider a worst-case model, in which Nature chooses a sequence of price ﬂuctuations under a cumulative quadratic volatility constraint, and the Investor can make a sequence of hedging decisions. Our main result is to show that the value of our proposed game, which is the “regret” of hedging strategy, converges to the Black-Scholes option price. We use signiﬁcantly weaker assumptions than previous work—for instance, we allow large jumps in the asset price—and show that the Black-Scholes hedging strategy is near-optimal for the Investor even in this non-stochastic framework. 1</p><p>2 0.56285393 <a title="139-lda-2" href="./nips-2013-Efficient_Algorithm_for_Privately_Releasing_Smooth_Queries.html">102 nips-2013-Efficient Algorithm for Privately Releasing Smooth Queries</a></p>
<p>Author: Ziteng Wang, Kai Fan, Jiaqi Zhang, Liwei Wang</p><p>Abstract: We study differentially private mechanisms for answering smooth queries on databases consisting of data points in Rd . A K-smooth query is speciﬁed by a function whose partial derivatives up to order K are all bounded. We develop an -differentially private mechanism which for the class of K-smooth queries has K accuracy O(n− 2d+K / ). The mechanism ﬁrst outputs a summary of the database. To obtain an answer of a query, the user runs a public evaluation algorithm which contains no information of the database. Outputting the summary runs in time d O(n1+ 2d+K ), and the evaluation algorithm for answering a query runs in time d+2+ 2d K ˜ O(n 2d+K ). Our mechanism is based on L∞ -approximation of (transformed) smooth functions by low degree even trigonometric polynomials with small and efﬁciently computable coefﬁcients. 1</p><p>3 0.44429943 <a title="139-lda-3" href="./nips-2013-Adaptive_Anonymity_via_%24b%24-Matching.html">25 nips-2013-Adaptive Anonymity via $b$-Matching</a></p>
<p>Author: Krzysztof M. Choromanski, Tony Jebara, Kui Tang</p><p>Abstract: The adaptive anonymity problem is formalized where each individual shares their data along with an integer value to indicate their personal level of desired privacy. This problem leads to a generalization of k-anonymity to the b-matching setting. Novel algorithms and theory are provided to implement this type of anonymity. The relaxation achieves better utility, admits theoretical privacy guarantees that are as strong, and, most importantly, accommodates a variable level of anonymity for each individual. Empirical results conﬁrm improved utility on benchmark and social data-sets.</p><p>4 0.44336259 <a title="139-lda-4" href="./nips-2013-Manifold-based_Similarity_Adaptation_for_Label_Propagation.html">182 nips-2013-Manifold-based Similarity Adaptation for Label Propagation</a></p>
<p>Author: Masayuki Karasuyama, Hiroshi Mamitsuka</p><p>Abstract: Label propagation is one of the state-of-the-art methods for semi-supervised learning, which estimates labels by propagating label information through a graph. Label propagation assumes that data points (nodes) connected in a graph should have similar labels. Consequently, the label estimation heavily depends on edge weights in a graph which represent similarity of each node pair. We propose a method for a graph to capture the manifold structure of input features using edge weights parameterized by a similarity function. In this approach, edge weights represent both similarity and local reconstruction weight simultaneously, both being reasonable for label propagation. For further justiﬁcation, we provide analytical considerations including an interpretation as a cross-validation of a propagation model in the feature space, and an error analysis based on a low dimensional manifold model. Experimental results demonstrated the effectiveness of our approach both in synthetic and real datasets. 1</p><p>5 0.44204375 <a title="139-lda-5" href="./nips-2013-Learning_with_Noisy_Labels.html">171 nips-2013-Learning with Noisy Labels</a></p>
<p>Author: Nagarajan Natarajan, Inderjit Dhillon, Pradeep Ravikumar, Ambuj Tewari</p><p>Abstract: In this paper, we theoretically study the problem of binary classiﬁcation in the presence of random classiﬁcation noise — the learner, instead of seeing the true labels, sees labels that have independently been ﬂipped with some small probability. Moreover, random label noise is class-conditional — the ﬂip probability depends on the class. We provide two approaches to suitably modify any given surrogate loss function. First, we provide a simple unbiased estimator of any loss, and obtain performance bounds for empirical risk minimization in the presence of iid data with noisy labels. If the loss function satisﬁes a simple symmetry condition, we show that the method leads to an efﬁcient algorithm for empirical minimization. Second, by leveraging a reduction of risk minimization under noisy labels to classiﬁcation with weighted 0-1 loss, we suggest the use of a simple weighted surrogate loss, for which we are able to obtain strong empirical risk bounds. This approach has a very remarkable consequence — methods used in practice such as biased SVM and weighted logistic regression are provably noise-tolerant. On a synthetic non-separable dataset, our methods achieve over 88% accuracy even when 40% of the labels are corrupted, and are competitive with respect to recently proposed methods for dealing with label noise in several benchmark datasets.</p><p>6 0.44198555 <a title="139-lda-6" href="./nips-2013-Flexible_sampling_of_discrete_data_correlations_without_the_marginal_distributions.html">123 nips-2013-Flexible sampling of discrete data correlations without the marginal distributions</a></p>
<p>7 0.44126186 <a title="139-lda-7" href="./nips-2013-Minimax_Optimal_Algorithms_for_Unconstrained_Linear_Optimization.html">191 nips-2013-Minimax Optimal Algorithms for Unconstrained Linear Optimization</a></p>
<p>8 0.43987736 <a title="139-lda-8" href="./nips-2013-Point_Based_Value_Iteration_with_Optimal_Belief_Compression_for_Dec-POMDPs.html">248 nips-2013-Point Based Value Iteration with Optimal Belief Compression for Dec-POMDPs</a></p>
<p>9 0.43828803 <a title="139-lda-9" href="./nips-2013-Statistical_analysis_of_coupled_time_series_with_Kernel_Cross-Spectral_Density_operators..html">310 nips-2013-Statistical analysis of coupled time series with Kernel Cross-Spectral Density operators.</a></p>
<p>10 0.43536392 <a title="139-lda-10" href="./nips-2013-Computing_the_Stationary_Distribution_Locally.html">66 nips-2013-Computing the Stationary Distribution Locally</a></p>
<p>11 0.43303233 <a title="139-lda-11" href="./nips-2013-Bayesian_entropy_estimation_for_binary_spike_train_data_using_parametric_prior_knowledge.html">51 nips-2013-Bayesian entropy estimation for binary spike train data using parametric prior knowledge</a></p>
<p>12 0.43204942 <a title="139-lda-12" href="./nips-2013-From_Bandits_to_Experts%3A_A_Tale_of_Domination_and_Independence.html">125 nips-2013-From Bandits to Experts: A Tale of Domination and Independence</a></p>
<p>13 0.42686334 <a title="139-lda-13" href="./nips-2013-Information-theoretic_lower_bounds_for_distributed_statistical_estimation_with_communication_constraints.html">142 nips-2013-Information-theoretic lower bounds for distributed statistical estimation with communication constraints</a></p>
<p>14 0.42624328 <a title="139-lda-14" href="./nips-2013-Fantope_Projection_and_Selection%3A_A_near-optimal_convex_relaxation_of_sparse_PCA.html">116 nips-2013-Fantope Projection and Selection: A near-optimal convex relaxation of sparse PCA</a></p>
<p>15 0.42620921 <a title="139-lda-15" href="./nips-2013-The_Pareto_Regret_Frontier.html">325 nips-2013-The Pareto Regret Frontier</a></p>
<p>16 0.426182 <a title="139-lda-16" href="./nips-2013-Optimization%2C_Learning%2C_and_Games_with_Predictable_Sequences.html">240 nips-2013-Optimization, Learning, and Games with Predictable Sequences</a></p>
<p>17 0.42573708 <a title="139-lda-17" href="./nips-2013-DESPOT%3A_Online_POMDP_Planning_with_Regularization.html">79 nips-2013-DESPOT: Online POMDP Planning with Regularization</a></p>
<p>18 0.42569569 <a title="139-lda-18" href="./nips-2013-Online_Learning_of_Dynamic_Parameters_in_Social_Networks.html">228 nips-2013-Online Learning of Dynamic Parameters in Social Networks</a></p>
<p>19 0.42564836 <a title="139-lda-19" href="./nips-2013-Reinforcement_Learning_in_Robust_Markov_Decision_Processes.html">273 nips-2013-Reinforcement Learning in Robust Markov Decision Processes</a></p>
<p>20 0.4248122 <a title="139-lda-20" href="./nips-2013-Modeling_Overlapping_Communities_with_Node_Popularities.html">196 nips-2013-Modeling Overlapping Communities with Node Popularities</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
