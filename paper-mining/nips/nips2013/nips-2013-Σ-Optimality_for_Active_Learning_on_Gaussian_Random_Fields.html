<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>359 nips-2013-Σ-Optimality for Active Learning on Gaussian Random Fields</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-359" href="#">nips2013-359</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>359 nips-2013-Σ-Optimality for Active Learning on Gaussian Random Fields</h1>
<br/><p>Source: <a title="nips-2013-359-pdf" href="http://papers.nips.cc/paper/4951--optimality-for-active-learning-on-gaussian-random-fields.pdf">pdf</a></p><p>Author: Yifei Ma, Roman Garnett, Jeff Schneider</p><p>Abstract: A common classiﬁer for unlabeled nodes on undirected graphs uses label propagation from the labeled nodes, equivalent to the harmonic predictor on Gaussian random ﬁelds (GRFs). For active learning on GRFs, the commonly used V-optimality criterion queries nodes that reduce the L2 (regression) loss. V-optimality satisﬁes a submodularity property showing that greedy reduction produces a (1 − 1/e) globally optimal solution. However, L2 loss may not characterise the true nature of 0/1 loss in classiﬁcation problems and thus may not be the best choice for active learning. We consider a new criterion we call Σ-optimality, which queries the node that minimizes the sum of the elements in the predictive covariance. Σ-optimality directly optimizes the risk of the surveying problem, which is to determine the proportion of nodes belonging to one class. In this paper we extend submodularity guarantees from V-optimality to Σ-optimality using properties speciﬁc to GRFs. We further show that GRFs satisfy the suppressor-free condition in addition to the conditional independence inherited from Markov random ﬁelds. We test Σoptimality on real-world graphs with both synthetic and real data and show that it outperforms V-optimality and other related methods on classiﬁcation. 1</p><p>Reference: <a title="nips-2013-359-reference" href="../nips2013_reference/nips-2013-%CE%A3-Optimality_for_Active_Learning_on_Gaussian_Random_Fields_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract A common classiﬁer for unlabeled nodes on undirected graphs uses label propagation from the labeled nodes, equivalent to the harmonic predictor on Gaussian random ﬁelds (GRFs). [sent-6, score-0.489]
</p><p>2 For active learning on GRFs, the commonly used V-optimality criterion queries nodes that reduce the L2 (regression) loss. [sent-7, score-0.485]
</p><p>3 V-optimality satisﬁes a submodularity property showing that greedy reduction produces a (1 − 1/e) globally optimal solution. [sent-8, score-0.288]
</p><p>4 However, L2 loss may not characterise the true nature of 0/1 loss in classiﬁcation problems and thus may not be the best choice for active learning. [sent-9, score-0.18]
</p><p>5 We consider a new criterion we call Σ-optimality, which queries the node that minimizes the sum of the elements in the predictive covariance. [sent-10, score-0.299]
</p><p>6 Σ-optimality directly optimizes the risk of the surveying problem, which is to determine the proportion of nodes belonging to one class. [sent-11, score-0.429]
</p><p>7 1  Introduction  Real-world data are often presented as a graph where the nodes in the graph bear labels that vary smoothly along edges. [sent-15, score-0.438]
</p><p>8 For example, for scientiﬁc publications, the content of one paper is highly correlated with the content of papers that it references or is referenced by, the ﬁeld of interest of a scholar is highly correlated with other scholars s/he coauthors with, etc. [sent-16, score-0.093]
</p><p>9 Many of these networks can be described using an undirected graph with nonnegative edge weights set to be the strengths of the connections between nodes. [sent-17, score-0.185]
</p><p>10 The model for label prediction in this paper is the harmonic function on the Gaussian random ﬁeld (GRF) by Zhu et al. [sent-18, score-0.096]
</p><p>11 It can generalize two popular and intuitive algorithms: label propagation (Zhu & Ghahramani, 2002), and random walk with absorptions (Wu et al. [sent-20, score-0.167]
</p><p>12 GRFs can be seen as a Gaussian process (GP) (Rasmussen & Williams, 2006) with its (maybe improper) prior covariance matrix whose (pseudo)inverse is set to be the graph Laplacian. [sent-22, score-0.136]
</p><p>13 Active learning addresses these issues by making automated decisions on which nodes to query for labels from experts or the crowd. [sent-24, score-0.31]
</p><p>14 Some popular criteria are empirical risk minimization (Settles, 2010; Zhu et al. [sent-25, score-0.281]
</p><p>15 Namely, we show that greedy reduction of Σ-optimality provides a (1 − 1/e) approximation bound to the global optimum. [sent-29, score-0.238]
</p><p>16 Finally, we show that Σ-optimality outperforms other approaches for active learning with GRFs for classiﬁcation. [sent-31, score-0.18]
</p><p>17 1  V-optimality on Gaussian Random Fields  Ji & Han (2012) proposed greedy variance minimization as a cheap and high proﬁle surrogate active classiﬁcation criterion. [sent-33, score-0.426]
</p><p>18 To decide which node to query next, the active learning algorithm ﬁnds the unlabeled node which leads to the smallest average predictive variance on all other unlabeled nodes. [sent-34, score-0.671]
</p><p>19 The motivation behind Voptimality can be paraphrased as the expected risk minimization with the L2 -surrogate loss (Section 2. [sent-37, score-0.19]
</p><p>20 The greedy solution to the set optimization problem in V-optimality is comparable to the global solution up to a constant (Theorem 1). [sent-40, score-0.193]
</p><p>21 The greedy application of V-optimality can also be interpreted as a heuristic which selects nodes that have high correlation to nodes with high variances (Observation 4). [sent-42, score-0.557]
</p><p>22 (1978) shows that any submodular, monotone and normalized set function yields a (1 − 1/e) global optimality guarantee for greedy solutions. [sent-45, score-0.283]
</p><p>23 2  Σ-optimality on Gaussian Random Fields  We deﬁne Σ-optimality on GRFs to be another variance minimization criterion that minimizes the sum of all entries in the predictive covariance matrix. [sent-50, score-0.23]
</p><p>24 As we will show in Lemma 7, the predictive covariance matrix is nonnegative entry-wise and thus the deﬁnition is proper. [sent-51, score-0.169]
</p><p>25 (2012) in the context of active surveying, which is to determine the proportion of nodes belonging to one class. [sent-53, score-0.394]
</p><p>26 However, we focus on its performance as a criterion in active classiﬁcation heuristics. [sent-54, score-0.239]
</p><p>27 The survey-risk of Σ-optimality replaces the L2 -risk of V-optimality as an alternative surrogate risk for the 0/1-risk. [sent-55, score-0.186]
</p><p>28 We also prove that the greedy application of Σ-optimality has a similar theoretical bound as Voptimality. [sent-56, score-0.16]
</p><p>29 Finally, greedy application of both Σ-optimality and V-optimality need O(N ) time per query candidate evaluation after one-time inverse of a N × N matrix. [sent-60, score-0.218]
</p><p>30 Intuitively, this means that with more labels acquired, the conditional correlation between unlabeled nodes decreases even when their Markov blanket has not formed. [sent-65, score-0.414]
</p><p>31 Suppose the dataset can be represented in the form of a connected undirected graph G = (V, E) where each node has an (either known or unknown) label and each edge eij has a ﬁxed nonnegative weight wij (= wji ) that reﬂects the proximity, similarity, etc. [sent-68, score-0.365]
</p><p>32 Deﬁne the graph Laplacian of G to be L = diag (W 1) − W , i. [sent-70, score-0.093]
</p><p>33 2  The binary GRF is a Bayesian model to generate yi ∈ {0, +1} for every node vi according to, β 1 2 p(y) ∝ exp − = exp − y T Ly . [sent-75, score-0.133]
</p><p>34 , y | | )T ; A GRF infers the output distribution on unlabeled nodes, yu = (yu1 , . [sent-83, score-0.183]
</p><p>35 2)  (−L−1 Lu u  where yu = ˆ y ) is the vector of predictive means on unlabeled nodes and Lu is the principal submatrix consisting of the unlabeled row and column indices in L, that is, the lower-right L Lu block of L = . [sent-87, score-0.53]
</p><p>36 (v− Lu Lu We use L(v− ) and Lu interchangeably because and u partition the set of all nodes v. [sent-89, score-0.179]
</p><p>37 LP stands for label propagation, because the predictive mean on a node is the probability of a random walk leaving that node hitting a positive label before hitting a zero label. [sent-91, score-0.398]
</p><p>38 (2003) proposed the harmonic predictor which looks at predictive means in one-versus-all comparisons. [sent-93, score-0.131]
</p><p>39 The risk function, whose input variable is the labeled subset , is: RV ( ) = Ey  yu  (yui − yui )2 = E E ˆ ui ∈u  (yui − yui )2 y ˆ  = tr(L−1 ). [sent-99, score-0.652]
</p><p>40 3)  ui ∈u  This risk is written with a subscript V because minimizing (2. [sent-101, score-0.187]
</p><p>41 3) is also the V-optimality criterion, which minimizes mean prediction variance in active learning. [sent-102, score-0.18]
</p><p>42 In active learning, we strive to select a subset of nodes to query for labels, constrained by a given budget C, such that the risk is minimized. [sent-103, score-0.562]
</p><p>43 2) is to determine the proportion of nodes belonging to class 1, as would happen when performing a survey. [sent-108, score-0.214]
</p><p>44 For active surveying, the risk would be: RΣ ( ) = Ey  yu  yui − ui ∈u  yui ˆ  2  2  ˆ = E E 1T yu − 1T yu |y  = 1T L−1 1, u  (2. [sent-109, score-0.987]
</p><p>45 5)  ui ∈u  which could substitute the risk R( ) in (2. [sent-110, score-0.187]
</p><p>46 4) and yield another heuristic for selecting nodes in batch active learning. [sent-111, score-0.359]
</p><p>47 6) (v− : | |≤C  Further, we will also consider the application of Σ-optimality in active classiﬁcation because (2. [sent-114, score-0.18]
</p><p>48 5) are approximations of the real objective (the 0/1 risk), greedy reduction of the Σ-optimality criterion outperforms greedy reduction of the V-optimality criterion in active classiﬁcation (Section 3. [sent-118, score-0.708]
</p><p>49 As will be shown later in the theoretical results, the reduction of both risks are submodular set functions and the greedy sequential update algorithm yields a solution that has a guaranteed approximation ratio to the optimum (Theorem 1). [sent-126, score-0.284]
</p><p>50 At the k-th query decision, denote the covariance matrix conditioned on the previous (k − 1) queries as C = (L(v− (k−1) ) )−1 . [sent-127, score-0.168]
</p><p>51 By Shur’s Lemma (or the GP-regression update rule), the one-step lookahead covariance matrix conditioned on (k−1) ∪ {v}, denoted as C = (L(v−( (k−1) ∪{v})) )−1 , has the following update formula: 1 C 0 =C− · C:v Cv: , (2. [sent-128, score-0.096]
</p><p>52 However, in the special case of GPs with kernel matrix equal to the inverse of a graph Laplacian (with = ∅ or δ > 0), the GRF does provide such theoretical guarantees, both for V-optimality and Σ-optimality. [sent-136, score-0.093]
</p><p>53 The following theoretical results concern greedy maximization of the risk reduction function (which is shown to be submodular): R∆ ( ) = R(∅) − R( ) for either R(·) = RV (·) or RΣ (·). [sent-138, score-0.35]
</p><p>54 Theorem 1 (Near-optimal guarantee for greedy applications of V/Σ-optimality). [sent-139, score-0.16]
</p><p>55 In risk reduction, R∆ ( g ) ≥ (1 − 1/e) · R∆ ( ∗ ), (3. [sent-140, score-0.145]
</p><p>56 1) where R∆ ( ) = R(∅) − R( ) for either R(·) = RV (·) or RΣ (·), e is Euler’s number, g is the greedy optimizer, and ∗ is the true global optimizer under the constraint | ∗ | ≤ | g |. [sent-141, score-0.193]
</p><p>57 Walker (2003) describes a suppressor as a variable, knowing which will suddenly create a strong correlation between the predictors. [sent-149, score-0.121]
</p><p>58 Formally, the condition is: corr(yi , yj | 1 ∪ 2 ) ≤ corr(yi , yj | 1 ) ∀vi , vj ∈ v, ∀ 1 , 2 ⊂ v. [sent-155, score-0.11]
</p><p>59 It is well known for Markov random ﬁelds that the labels of two nodes on a graph become independent given labels of their Markov blanket. [sent-159, score-0.418]
</p><p>60 Here we establish that GRF boasts more than that: the correlation between any two nodes decreases as more nodes get labeled, even before a Markov blanket is formed. [sent-160, score-0.435]
</p><p>61 1  Both the V/Σ-optimality are approximations to the 0/1 risk minimization objective. [sent-167, score-0.19]
</p><p>62 Unfortunately, we cannot theoretically reason why greedy Σ-optimality outperforms V-optimality in the experiments. [sent-168, score-0.16]
</p><p>63 9) suggest that both the greedy Σ/V-optimality selects nodes that (1) have high variance and (2) are highly correlated to high-variance nodes, conditioned on the labeled nodes. [sent-176, score-0.38]
</p><p>64 So, the Σ-optimality additionally favors nodes that (3) have consistent global inﬂuence, i. [sent-184, score-0.212]
</p><p>65 Although the properties of V-optimality fall into the more general class of spectral functions (Friedland & Gaubert, 2011), we have seen no proof of either the suppressor-free condition or the submodularity of Σ-optimality on GRFs. [sent-202, score-0.115]
</p><p>66 The GRF prediction operator L−1 Lul maps y ∈ [0, 1]| | to yu = −L−1 Lul y ∈ ˆ u u [0, 1]|u| . [sent-215, score-0.098]
</p><p>67 ˆ u As both Lu ≥ 0 and −Lul ≥ 0, we have y ≥ 0 ⇒ yu ≥ 0 and y ≥ y ⇒ yu ≥ yu . [sent-228, score-0.294]
</p><p>68 1, Figure 1 shows the ﬁrst few nodes selected by different optimality criteria. [sent-254, score-0.269]
</p><p>69 This graph is constructed by a breadth-ﬁrst search from a random node in a larger DBLP coauthorship network graph that we will introduce in the next section. [sent-255, score-0.338]
</p><p>70 On this toy graph, both criteria pick the same center node to query ﬁrst. [sent-256, score-0.283]
</p><p>71 However, for the second and third queries, Voptimality weighs the uncertainty of the candidate node more, choosing outliers, whereas Σ-optimality favors nodes with universal inﬂuence over the graph and goes to cluster centers. [sent-257, score-0.362]
</p><p>72 The node labels were ﬁrst simulated using the model in order to compare the active learning criteria directly without raising questions of model ﬁt. [sent-262, score-0.434]
</p><p>73 We simulated the binary labels with the GRF-sigmoid model and performed active learning with the GRF / LP model for predictions. [sent-264, score-0.253]
</p><p>74 05, which maximizes the average classiﬁcation accuracy increases from 50 random training nodes to 200 random training nodes using the GRF / LP model for predictions. [sent-267, score-0.358]
</p><p>75 Figure 2 shows the binary classiﬁcation accuracy versus the number of queries on both the DBLP coauthorship graph 6  0. [sent-268, score-0.222]
</p><p>76 and the CORA citation graph that we will describe below. [sent-291, score-0.182]
</p><p>77 Figure 2 can be a surprise due to the reasoning behind the L2 surrogate loss, especially when the predictive means are trapped between [−1, 1], but we see here that our reasoning in Sections (3. [sent-293, score-0.124]
</p><p>78 1) can lead to the greedy survey loss actually making a better active learning objective. [sent-295, score-0.374]
</p><p>79 Despite the fact that larger β and δ increase label independence on the graph structure and undermine the effectiveness of both V/Σ-optimality heuristics, we have seen that whenever the V-optimality establishes a superiority over random selections, Σ-optimality yields better performance. [sent-297, score-0.141]
</p><p>80 6  Real-World Experiments  The active learning heuristics to be compared are:4 1. [sent-298, score-0.18]
</p><p>81 The new Σ-optimality with greedy sequential updates: minv 1 (Luk \{v } )−1 1 . [sent-299, score-0.201]
</p><p>82 , 2008): maxv L−1 v ,v (L k ∪{v } )−1 uk (1) maxv yv ˆ  v ,v  (2) yv . [sent-304, score-0.22]
</p><p>83 Selected nodes maximize (1) the average prediction conﬁdence in expectation: maxv Eyv ˆ yk . [sent-309, score-0.298]
</p><p>84 5 The nodes represent scholars and the weighted edges are the number of papers bearing both scholars’ names. [sent-315, score-0.272]
</p><p>85 The largest connected component has 1711 nodes and 2898 edges. [sent-316, score-0.179]
</p><p>86 The node labels were hand assigned in Ji & Han (2012) to one of the four expertise areas of the scholars: machine learning, data mining, information retrieval, and databases. [sent-317, score-0.163]
</p><p>87 6 This is a citation graph of 2708 publications, each of which is classiﬁed into one of seven classes: case based, genetic algorithms, neural networks, probabilistic methods, reinforcement learning, rule learning, and theory. [sent-321, score-0.182]
</p><p>88 We took its largest connected component, with 2485 nodes and 5069 undirected and unweighted edges. [sent-323, score-0.228]
</p><p>89 6 This is another citation graph of 3312 publications, each of which is classiﬁed into one of six classes: agents, artiﬁcial intelligence, databases, information retrieval, machine learning, human computer interaction. [sent-367, score-0.182]
</p><p>90 We took its largest connected component, with 2109 nodes and 3665 undirected and unweighted edges. [sent-369, score-0.228]
</p><p>91 The node choices by both criteria were also visually inspected after embedding the graph to the 2-dimensional space using OpenOrd method developed by Martin et al. [sent-374, score-0.274]
</p><p>92 We also performed real-world experiments on the root-mean-square-error of the class proportion estimations, which is the survey risk that the Σ-optimality minimizes. [sent-377, score-0.214]
</p><p>93 7  Conclusion  For active learning on GRFs, it is common to use variance minimization criteria with greedy onestep lookahead heuristics. [sent-380, score-0.529]
</p><p>94 V-optimality and Σ-optimality are two criteria based on statistics of the predictive covariance matrix. [sent-381, score-0.217]
</p><p>95 They both are also risk minimization criteria: V-optimality minimizes the L2 risk (2. [sent-382, score-0.335]
</p><p>96 Therefore, risk reduction is submodular and the greedy one-step lookahead heuristics can achieve a (1 − 1/e) global optimality ratio. [sent-389, score-0.605]
</p><p>97 While the V-optimality on GRFs inherits from label propagation (and random walk with absorptions) and have good empirical performance, it is not directly minimizing the 0/1 classiﬁcation risk. [sent-391, score-0.126]
</p><p>98 A variance minimization criterion to active learning on graphs. [sent-409, score-0.284]
</p><p>99 Learning from labeled and unlabeled data with label propagation. [sent-436, score-0.174]
</p><p>100 Combining active learning and semisupervised learning using gaussian ﬁelds and harmonic functions. [sent-439, score-0.228]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('grf', 0.513), ('grfs', 0.326), ('active', 0.18), ('nodes', 0.179), ('yui', 0.163), ('greedy', 0.16), ('risk', 0.145), ('eer', 0.14), ('lul', 0.14), ('lij', 0.125), ('loo', 0.123), ('lu', 0.101), ('yu', 0.098), ('graph', 0.093), ('mig', 0.093), ('scholars', 0.093), ('criteria', 0.091), ('optimality', 0.09), ('node', 0.09), ('dblp', 0.089), ('citation', 0.089), ('opt', 0.088), ('rv', 0.085), ('unlabeled', 0.085), ('submodularity', 0.083), ('han', 0.083), ('predictive', 0.083), ('suppressor', 0.082), ('submodular', 0.079), ('cora', 0.076), ('labels', 0.073), ('cvv', 0.07), ('friedland', 0.07), ('gaubert', 0.07), ('lii', 0.07), ('lji', 0.07), ('surveying', 0.07), ('unc', 0.07), ('walker', 0.068), ('queries', 0.067), ('zhu', 0.064), ('lp', 0.062), ('coauthorship', 0.062), ('yk', 0.062), ('ji', 0.061), ('krause', 0.06), ('criterion', 0.059), ('query', 0.058), ('classi', 0.057), ('maxv', 0.057), ('lookahead', 0.053), ('yv', 0.053), ('kempe', 0.053), ('garnett', 0.051), ('undirected', 0.049), ('nemhauser', 0.049), ('harmonic', 0.048), ('label', 0.048), ('publications', 0.047), ('luk', 0.047), ('openord', 0.047), ('shur', 0.047), ('suppressors', 0.047), ('voptimality', 0.047), ('settles', 0.045), ('rhs', 0.045), ('minimization', 0.045), ('reduction', 0.045), ('toy', 0.044), ('yi', 0.043), ('covariance', 0.043), ('nonnegative', 0.043), ('das', 0.043), ('rand', 0.043), ('ui', 0.042), ('wij', 0.042), ('absorptions', 0.041), ('minv', 0.041), ('cvt', 0.041), ('surrogate', 0.041), ('lemma', 0.041), ('labeled', 0.041), ('fields', 0.039), ('propagation', 0.039), ('vt', 0.039), ('yj', 0.039), ('walk', 0.039), ('correlation', 0.039), ('blanket', 0.038), ('xiaojin', 0.038), ('psd', 0.038), ('gp', 0.036), ('monotonicity', 0.036), ('roman', 0.036), ('proportion', 0.035), ('survey', 0.034), ('laplacian', 0.033), ('global', 0.033), ('condition', 0.032), ('citeseer', 0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="359-tfidf-1" href="./nips-2013-%CE%A3-Optimality_for_Active_Learning_on_Gaussian_Random_Fields.html">359 nips-2013-Σ-Optimality for Active Learning on Gaussian Random Fields</a></p>
<p>Author: Yifei Ma, Roman Garnett, Jeff Schneider</p><p>Abstract: A common classiﬁer for unlabeled nodes on undirected graphs uses label propagation from the labeled nodes, equivalent to the harmonic predictor on Gaussian random ﬁelds (GRFs). For active learning on GRFs, the commonly used V-optimality criterion queries nodes that reduce the L2 (regression) loss. V-optimality satisﬁes a submodularity property showing that greedy reduction produces a (1 − 1/e) globally optimal solution. However, L2 loss may not characterise the true nature of 0/1 loss in classiﬁcation problems and thus may not be the best choice for active learning. We consider a new criterion we call Σ-optimality, which queries the node that minimizes the sum of the elements in the predictive covariance. Σ-optimality directly optimizes the risk of the surveying problem, which is to determine the proportion of nodes belonging to one class. In this paper we extend submodularity guarantees from V-optimality to Σ-optimality using properties speciﬁc to GRFs. We further show that GRFs satisfy the suppressor-free condition in addition to the conditional independence inherited from Markov random ﬁelds. We test Σoptimality on real-world graphs with both synthetic and real data and show that it outperforms V-optimality and other related methods on classiﬁcation. 1</p><p>2 0.16380911 <a title="359-tfidf-2" href="./nips-2013-Latent_Structured_Active_Learning.html">149 nips-2013-Latent Structured Active Learning</a></p>
<p>Author: Wenjie Luo, Alex Schwing, Raquel Urtasun</p><p>Abstract: In this paper we present active learning algorithms in the context of structured prediction problems. To reduce the amount of labeling necessary to learn good models, our algorithms operate with weakly labeled data and we query additional examples based on entropies of local marginals, which are a good surrogate for uncertainty. We demonstrate the effectiveness of our approach in the task of 3D layout prediction from single images, and show that good models are learned when labeling only a handful of random variables. In particular, the same performance as using the full training set can be obtained while only labeling ∼10% of the random variables. 1</p><p>3 0.16075775 <a title="359-tfidf-3" href="./nips-2013-Statistical_Active_Learning_Algorithms.html">309 nips-2013-Statistical Active Learning Algorithms</a></p>
<p>Author: Maria-Florina Balcan, Vitaly Feldman</p><p>Abstract: We describe a framework for designing efﬁcient active learning algorithms that are tolerant to random classiﬁcation noise and differentially-private. The framework is based on active learning algorithms that are statistical in the sense that they rely on estimates of expectations of functions of ﬁltered random examples. It builds on the powerful statistical query framework of Kearns [30]. We show that any efﬁcient active statistical learning algorithm can be automatically converted to an efﬁcient active learning algorithm which is tolerant to random classiﬁcation noise as well as other forms of “uncorrelated” noise. We show that commonly studied concept classes including thresholds, rectangles, and linear separators can be efﬁciently actively learned in our framework. These results combined with our generic conversion lead to the ﬁrst computationally-efﬁcient algorithms for actively learning some of these concept classes in the presence of random classiﬁcation noise that provide exponential improvement in the dependence on the error over their passive counterparts. In addition, we show that our algorithms can be automatically converted to efﬁcient active differentially-private algorithms. This leads to the ﬁrst differentially-private active learning algorithms with exponential label savings over the passive case. 1</p><p>4 0.10937922 <a title="359-tfidf-4" href="./nips-2013-Scalable_Influence_Estimation_in_Continuous-Time_Diffusion_Networks.html">288 nips-2013-Scalable Influence Estimation in Continuous-Time Diffusion Networks</a></p>
<p>Author: Nan Du, Le Song, Manuel Gomez-Rodriguez, Hongyuan Zha</p><p>Abstract: If a piece of information is released from a media site, can we predict whether it may spread to one million web pages, in a month ? This inﬂuence estimation problem is very challenging since both the time-sensitive nature of the task and the requirement of scalability need to be addressed simultaneously. In this paper, we propose a randomized algorithm for inﬂuence estimation in continuous-time diffusion networks. Our algorithm can estimate the inﬂuence of every node in a network with |V| nodes and |E| edges to an accuracy of using n = O(1/ 2 ) randomizations and up to logarithmic factors O(n|E|+n|V|) computations. When used as a subroutine in a greedy inﬂuence maximization approach, our proposed algorithm is guaranteed to ﬁnd a set of C nodes with the inﬂuence of at least (1 − 1/e) OPT −2C , where OPT is the optimal value. Experiments on both synthetic and real-world data show that the proposed algorithm can easily scale up to networks of millions of nodes while signiﬁcantly improves over previous state-of-the-arts in terms of the accuracy of the estimated inﬂuence and the quality of the selected nodes in maximizing the inﬂuence. 1</p><p>5 0.10257807 <a title="359-tfidf-5" href="./nips-2013-Active_Learning_for_Probabilistic_Hypotheses_Using_the_Maximum_Gibbs_Error_Criterion.html">23 nips-2013-Active Learning for Probabilistic Hypotheses Using the Maximum Gibbs Error Criterion</a></p>
<p>Author: Nguyen Viet Cuong, Wee Sun Lee, Nan Ye, Kian Ming A. Chai, Hai Leong Chieu</p><p>Abstract: We introduce a new objective function for pool-based Bayesian active learning with probabilistic hypotheses. This objective function, called the policy Gibbs error, is the expected error rate of a random classiﬁer drawn from the prior distribution on the examples adaptively selected by the active learning policy. Exact maximization of the policy Gibbs error is hard, so we propose a greedy strategy that maximizes the Gibbs error at each iteration, where the Gibbs error on an instance is the expected error of a random classiﬁer selected from the posterior label distribution on that instance. We apply this maximum Gibbs error criterion to three active learning scenarios: non-adaptive, adaptive, and batch active learning. In each scenario, we prove that the criterion achieves near-maximal policy Gibbs error when constrained to a ﬁxed budget. For practical implementations, we provide approximations to the maximum Gibbs error criterion for Bayesian conditional random ﬁelds and transductive Naive Bayes. Our experimental results on a named entity recognition task and a text classiﬁcation task show that the maximum Gibbs error criterion is an effective active learning criterion for noisy models. 1</p><p>6 0.10219528 <a title="359-tfidf-6" href="./nips-2013-Distributed_Submodular_Maximization%3A_Identifying_Representative_Elements_in_Massive_Data.html">97 nips-2013-Distributed Submodular Maximization: Identifying Representative Elements in Massive Data</a></p>
<p>7 0.10127161 <a title="359-tfidf-7" href="./nips-2013-Learning_with_Noisy_Labels.html">171 nips-2013-Learning with Noisy Labels</a></p>
<p>8 0.093864687 <a title="359-tfidf-8" href="./nips-2013-Sensor_Selection_in_High-Dimensional_Gaussian_Trees_with_Nuisances.html">291 nips-2013-Sensor Selection in High-Dimensional Gaussian Trees with Nuisances</a></p>
<p>9 0.093177937 <a title="359-tfidf-9" href="./nips-2013-Submodular_Optimization_with_Submodular_Cover_and_Submodular_Knapsack_Constraints.html">319 nips-2013-Submodular Optimization with Submodular Cover and Submodular Knapsack Constraints</a></p>
<p>10 0.088334151 <a title="359-tfidf-10" href="./nips-2013-Curvature_and_Optimal_Algorithms_for_Learning_and_Minimizing_Submodular_Functions.html">78 nips-2013-Curvature and Optimal Algorithms for Learning and Minimizing Submodular Functions</a></p>
<p>11 0.088270806 <a title="359-tfidf-11" href="./nips-2013-Analyzing_the_Harmonic_Structure_in_Graph-Based_Learning.html">35 nips-2013-Analyzing the Harmonic Structure in Graph-Based Learning</a></p>
<p>12 0.075047858 <a title="359-tfidf-12" href="./nips-2013-Computing_the_Stationary_Distribution_Locally.html">66 nips-2013-Computing the Stationary Distribution Locally</a></p>
<p>13 0.072765365 <a title="359-tfidf-13" href="./nips-2013-Near-optimal_Anomaly_Detection_in_Graphs_using_Lovasz_Extended_Scan_Statistic.html">207 nips-2013-Near-optimal Anomaly Detection in Graphs using Lovasz Extended Scan Statistic</a></p>
<p>14 0.072156861 <a title="359-tfidf-14" href="./nips-2013-Regularized_Spectral_Clustering_under_the_Degree-Corrected_Stochastic_Blockmodel.html">272 nips-2013-Regularized Spectral Clustering under the Degree-Corrected Stochastic Blockmodel</a></p>
<p>15 0.072030753 <a title="359-tfidf-15" href="./nips-2013-Buy-in-Bulk_Active_Learning.html">60 nips-2013-Buy-in-Bulk Active Learning</a></p>
<p>16 0.071737573 <a title="359-tfidf-16" href="./nips-2013-Scalable_kernels_for_graphs_with_continuous_attributes.html">289 nips-2013-Scalable kernels for graphs with continuous attributes</a></p>
<p>17 0.070849285 <a title="359-tfidf-17" href="./nips-2013-Learning_Chordal_Markov_Networks_by_Constraint_Satisfaction.html">151 nips-2013-Learning Chordal Markov Networks by Constraint Satisfaction</a></p>
<p>18 0.070090987 <a title="359-tfidf-18" href="./nips-2013-Nonparametric_Multi-group_Membership_Model_for_Dynamic_Networks.html">213 nips-2013-Nonparametric Multi-group Membership Model for Dynamic Networks</a></p>
<p>19 0.069433123 <a title="359-tfidf-19" href="./nips-2013-Reflection_methods_for_user-friendly_submodular_optimization.html">268 nips-2013-Reflection methods for user-friendly submodular optimization</a></p>
<p>20 0.068564296 <a title="359-tfidf-20" href="./nips-2013-A_Gang_of_Bandits.html">7 nips-2013-A Gang of Bandits</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.189), (1, 0.036), (2, -0.008), (3, -0.002), (4, 0.096), (5, 0.112), (6, -0.059), (7, -0.159), (8, 0.019), (9, 0.036), (10, -0.01), (11, -0.115), (12, 0.036), (13, 0.013), (14, -0.002), (15, -0.148), (16, -0.123), (17, 0.13), (18, 0.05), (19, -0.091), (20, -0.007), (21, 0.013), (22, 0.01), (23, -0.072), (24, 0.086), (25, 0.013), (26, -0.01), (27, 0.112), (28, -0.061), (29, -0.012), (30, -0.001), (31, 0.02), (32, -0.025), (33, -0.008), (34, -0.041), (35, 0.024), (36, 0.036), (37, -0.033), (38, -0.037), (39, 0.008), (40, 0.046), (41, -0.054), (42, -0.015), (43, 0.04), (44, -0.064), (45, 0.007), (46, 0.014), (47, 0.043), (48, -0.01), (49, -0.064)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.957196 <a title="359-lsi-1" href="./nips-2013-%CE%A3-Optimality_for_Active_Learning_on_Gaussian_Random_Fields.html">359 nips-2013-Σ-Optimality for Active Learning on Gaussian Random Fields</a></p>
<p>Author: Yifei Ma, Roman Garnett, Jeff Schneider</p><p>Abstract: A common classiﬁer for unlabeled nodes on undirected graphs uses label propagation from the labeled nodes, equivalent to the harmonic predictor on Gaussian random ﬁelds (GRFs). For active learning on GRFs, the commonly used V-optimality criterion queries nodes that reduce the L2 (regression) loss. V-optimality satisﬁes a submodularity property showing that greedy reduction produces a (1 − 1/e) globally optimal solution. However, L2 loss may not characterise the true nature of 0/1 loss in classiﬁcation problems and thus may not be the best choice for active learning. We consider a new criterion we call Σ-optimality, which queries the node that minimizes the sum of the elements in the predictive covariance. Σ-optimality directly optimizes the risk of the surveying problem, which is to determine the proportion of nodes belonging to one class. In this paper we extend submodularity guarantees from V-optimality to Σ-optimality using properties speciﬁc to GRFs. We further show that GRFs satisfy the suppressor-free condition in addition to the conditional independence inherited from Markov random ﬁelds. We test Σoptimality on real-world graphs with both synthetic and real data and show that it outperforms V-optimality and other related methods on classiﬁcation. 1</p><p>2 0.70263898 <a title="359-lsi-2" href="./nips-2013-Statistical_Active_Learning_Algorithms.html">309 nips-2013-Statistical Active Learning Algorithms</a></p>
<p>Author: Maria-Florina Balcan, Vitaly Feldman</p><p>Abstract: We describe a framework for designing efﬁcient active learning algorithms that are tolerant to random classiﬁcation noise and differentially-private. The framework is based on active learning algorithms that are statistical in the sense that they rely on estimates of expectations of functions of ﬁltered random examples. It builds on the powerful statistical query framework of Kearns [30]. We show that any efﬁcient active statistical learning algorithm can be automatically converted to an efﬁcient active learning algorithm which is tolerant to random classiﬁcation noise as well as other forms of “uncorrelated” noise. We show that commonly studied concept classes including thresholds, rectangles, and linear separators can be efﬁciently actively learned in our framework. These results combined with our generic conversion lead to the ﬁrst computationally-efﬁcient algorithms for actively learning some of these concept classes in the presence of random classiﬁcation noise that provide exponential improvement in the dependence on the error over their passive counterparts. In addition, we show that our algorithms can be automatically converted to efﬁcient active differentially-private algorithms. This leads to the ﬁrst differentially-private active learning algorithms with exponential label savings over the passive case. 1</p><p>3 0.69902718 <a title="359-lsi-3" href="./nips-2013-Latent_Structured_Active_Learning.html">149 nips-2013-Latent Structured Active Learning</a></p>
<p>Author: Wenjie Luo, Alex Schwing, Raquel Urtasun</p><p>Abstract: In this paper we present active learning algorithms in the context of structured prediction problems. To reduce the amount of labeling necessary to learn good models, our algorithms operate with weakly labeled data and we query additional examples based on entropies of local marginals, which are a good surrogate for uncertainty. We demonstrate the effectiveness of our approach in the task of 3D layout prediction from single images, and show that good models are learned when labeling only a handful of random variables. In particular, the same performance as using the full training set can be obtained while only labeling ∼10% of the random variables. 1</p><p>4 0.69424832 <a title="359-lsi-4" href="./nips-2013-Auditing%3A_Active_Learning_with_Outcome-Dependent_Query_Costs.html">42 nips-2013-Auditing: Active Learning with Outcome-Dependent Query Costs</a></p>
<p>Author: Sivan Sabato, Anand D. Sarwate, Nati Srebro</p><p>Abstract: We propose a learning setting in which unlabeled data is free, and the cost of a label depends on its value, which is not known in advance. We study binary classiﬁcation in an extreme case, where the algorithm only pays for negative labels. Our motivation are applications such as fraud detection, in which investigating an honest transaction should be avoided if possible. We term the setting auditing, and consider the auditing complexity of an algorithm: the number of negative labels the algorithm requires in order to learn a hypothesis with low relative error. We design auditing algorithms for simple hypothesis classes (thresholds and rectangles), and show that with these algorithms, the auditing complexity can be signiﬁcantly lower than the active label complexity. We also show a general competitive approach for learning with outcome-dependent costs. 1</p><p>5 0.62780398 <a title="359-lsi-5" href="./nips-2013-Scalable_Influence_Estimation_in_Continuous-Time_Diffusion_Networks.html">288 nips-2013-Scalable Influence Estimation in Continuous-Time Diffusion Networks</a></p>
<p>Author: Nan Du, Le Song, Manuel Gomez-Rodriguez, Hongyuan Zha</p><p>Abstract: If a piece of information is released from a media site, can we predict whether it may spread to one million web pages, in a month ? This inﬂuence estimation problem is very challenging since both the time-sensitive nature of the task and the requirement of scalability need to be addressed simultaneously. In this paper, we propose a randomized algorithm for inﬂuence estimation in continuous-time diffusion networks. Our algorithm can estimate the inﬂuence of every node in a network with |V| nodes and |E| edges to an accuracy of using n = O(1/ 2 ) randomizations and up to logarithmic factors O(n|E|+n|V|) computations. When used as a subroutine in a greedy inﬂuence maximization approach, our proposed algorithm is guaranteed to ﬁnd a set of C nodes with the inﬂuence of at least (1 − 1/e) OPT −2C , where OPT is the optimal value. Experiments on both synthetic and real-world data show that the proposed algorithm can easily scale up to networks of millions of nodes while signiﬁcantly improves over previous state-of-the-arts in terms of the accuracy of the estimated inﬂuence and the quality of the selected nodes in maximizing the inﬂuence. 1</p><p>6 0.62435734 <a title="359-lsi-6" href="./nips-2013-Sensor_Selection_in_High-Dimensional_Gaussian_Trees_with_Nuisances.html">291 nips-2013-Sensor Selection in High-Dimensional Gaussian Trees with Nuisances</a></p>
<p>7 0.61478335 <a title="359-lsi-7" href="./nips-2013-Manifold-based_Similarity_Adaptation_for_Label_Propagation.html">182 nips-2013-Manifold-based Similarity Adaptation for Label Propagation</a></p>
<p>8 0.60421813 <a title="359-lsi-8" href="./nips-2013-Buy-in-Bulk_Active_Learning.html">60 nips-2013-Buy-in-Bulk Active Learning</a></p>
<p>9 0.56324583 <a title="359-lsi-9" href="./nips-2013-Robust_Bloom_Filters_for_Large_MultiLabel_Classification_Tasks.html">279 nips-2013-Robust Bloom Filters for Large MultiLabel Classification Tasks</a></p>
<p>10 0.54905498 <a title="359-lsi-10" href="./nips-2013-Learning_Chordal_Markov_Networks_by_Constraint_Satisfaction.html">151 nips-2013-Learning Chordal Markov Networks by Constraint Satisfaction</a></p>
<p>11 0.54869699 <a title="359-lsi-11" href="./nips-2013-Analyzing_the_Harmonic_Structure_in_Graph-Based_Learning.html">35 nips-2013-Analyzing the Harmonic Structure in Graph-Based Learning</a></p>
<p>12 0.53102332 <a title="359-lsi-12" href="./nips-2013-Distributed_Submodular_Maximization%3A_Identifying_Representative_Elements_in_Massive_Data.html">97 nips-2013-Distributed Submodular Maximization: Identifying Representative Elements in Massive Data</a></p>
<p>13 0.52504534 <a title="359-lsi-13" href="./nips-2013-Global_MAP-Optimality_by_Shrinking_the_Combinatorial_Search_Area_with_Convex_Relaxation.html">132 nips-2013-Global MAP-Optimality by Shrinking the Combinatorial Search Area with Convex Relaxation</a></p>
<p>14 0.52179325 <a title="359-lsi-14" href="./nips-2013-Wavelets_on_Graphs_via_Deep_Learning.html">350 nips-2013-Wavelets on Graphs via Deep Learning</a></p>
<p>15 0.51154244 <a title="359-lsi-15" href="./nips-2013-Near-optimal_Anomaly_Detection_in_Graphs_using_Lovasz_Extended_Scan_Statistic.html">207 nips-2013-Near-optimal Anomaly Detection in Graphs using Lovasz Extended Scan Statistic</a></p>
<p>16 0.50835609 <a title="359-lsi-16" href="./nips-2013-Learning_with_Noisy_Labels.html">171 nips-2013-Learning with Noisy Labels</a></p>
<p>17 0.50437242 <a title="359-lsi-17" href="./nips-2013-Active_Learning_for_Probabilistic_Hypotheses_Using_the_Maximum_Gibbs_Error_Criterion.html">23 nips-2013-Active Learning for Probabilistic Hypotheses Using the Maximum Gibbs Error Criterion</a></p>
<p>18 0.47663713 <a title="359-lsi-18" href="./nips-2013-Regularized_Spectral_Clustering_under_the_Degree-Corrected_Stochastic_Blockmodel.html">272 nips-2013-Regularized Spectral Clustering under the Degree-Corrected Stochastic Blockmodel</a></p>
<p>19 0.47136006 <a title="359-lsi-19" href="./nips-2013-Learning_Gaussian_Graphical_Models_with_Observed_or_Latent_FVSs.html">154 nips-2013-Learning Gaussian Graphical Models with Observed or Latent FVSs</a></p>
<p>20 0.46673799 <a title="359-lsi-20" href="./nips-2013-A_Gang_of_Bandits.html">7 nips-2013-A Gang of Bandits</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.018), (16, 0.036), (33, 0.115), (34, 0.083), (41, 0.027), (49, 0.035), (56, 0.123), (70, 0.039), (76, 0.286), (85, 0.048), (89, 0.035), (93, 0.028), (95, 0.063)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.77475166 <a title="359-lda-1" href="./nips-2013-Rapid_Distance-Based_Outlier_Detection_via_Sampling.html">261 nips-2013-Rapid Distance-Based Outlier Detection via Sampling</a></p>
<p>Author: Mahito Sugiyama, Karsten Borgwardt</p><p>Abstract: Distance-based approaches to outlier detection are popular in data mining, as they do not require to model the underlying probability distribution, which is particularly challenging for high-dimensional data. We present an empirical comparison of various approaches to distance-based outlier detection across a large number of datasets. We report the surprising observation that a simple, sampling-based scheme outperforms state-of-the-art techniques in terms of both efﬁciency and effectiveness. To better understand this phenomenon, we provide a theoretical analysis why the sampling-based approach outperforms alternative methods based on k-nearest neighbor search. 1</p><p>same-paper 2 0.76684552 <a title="359-lda-2" href="./nips-2013-%CE%A3-Optimality_for_Active_Learning_on_Gaussian_Random_Fields.html">359 nips-2013-Σ-Optimality for Active Learning on Gaussian Random Fields</a></p>
<p>Author: Yifei Ma, Roman Garnett, Jeff Schneider</p><p>Abstract: A common classiﬁer for unlabeled nodes on undirected graphs uses label propagation from the labeled nodes, equivalent to the harmonic predictor on Gaussian random ﬁelds (GRFs). For active learning on GRFs, the commonly used V-optimality criterion queries nodes that reduce the L2 (regression) loss. V-optimality satisﬁes a submodularity property showing that greedy reduction produces a (1 − 1/e) globally optimal solution. However, L2 loss may not characterise the true nature of 0/1 loss in classiﬁcation problems and thus may not be the best choice for active learning. We consider a new criterion we call Σ-optimality, which queries the node that minimizes the sum of the elements in the predictive covariance. Σ-optimality directly optimizes the risk of the surveying problem, which is to determine the proportion of nodes belonging to one class. In this paper we extend submodularity guarantees from V-optimality to Σ-optimality using properties speciﬁc to GRFs. We further show that GRFs satisfy the suppressor-free condition in addition to the conditional independence inherited from Markov random ﬁelds. We test Σoptimality on real-world graphs with both synthetic and real data and show that it outperforms V-optimality and other related methods on classiﬁcation. 1</p><p>3 0.71754199 <a title="359-lda-3" href="./nips-2013-A_Stability-based_Validation_Procedure_for_Differentially_Private_Machine_Learning.html">14 nips-2013-A Stability-based Validation Procedure for Differentially Private Machine Learning</a></p>
<p>Author: Kamalika Chaudhuri, Staal A. Vinterbo</p><p>Abstract: Differential privacy is a cryptographically motivated deﬁnition of privacy which has gained considerable attention in the algorithms, machine-learning and datamining communities. While there has been an explosion of work on differentially private machine learning algorithms, a major barrier to achieving end-to-end differential privacy in practical machine learning applications is the lack of an effective procedure for differentially private parameter tuning, or, determining the parameter value, such as a bin size in a histogram, or a regularization parameter, that is suitable for a particular application. In this paper, we introduce a generic validation procedure for differentially private machine learning algorithms that apply when a certain stability condition holds on the training algorithm and the validation performance metric. The training data size and the privacy budget used for training in our procedure is independent of the number of parameter values searched over. We apply our generic procedure to two fundamental tasks in statistics and machine-learning – training a regularized linear classiﬁer and building a histogram density estimator that result in end-toend differentially private solutions for these problems. 1</p><p>4 0.70690346 <a title="359-lda-4" href="./nips-2013-Policy_Shaping%3A_Integrating_Human_Feedback_with_Reinforcement_Learning.html">250 nips-2013-Policy Shaping: Integrating Human Feedback with Reinforcement Learning</a></p>
<p>Author: Shane Griffith, Kaushik Subramanian, Jonathan Scholz, Charles Isbell, Andrea L. Thomaz</p><p>Abstract: A long term goal of Interactive Reinforcement Learning is to incorporate nonexpert human feedback to solve complex tasks. Some state-of-the-art methods have approached this problem by mapping human information to rewards and values and iterating over them to compute better control policies. In this paper we argue for an alternate, more effective characterization of human feedback: Policy Shaping. We introduce Advise, a Bayesian approach that attempts to maximize the information gained from human feedback by utilizing it as direct policy labels. We compare Advise to state-of-the-art approaches and show that it can outperform them and is robust to infrequent and inconsistent human feedback.</p><p>5 0.69649822 <a title="359-lda-5" href="./nips-2013-Factorized_Asymptotic_Bayesian_Inference_for_Latent_Feature_Models.html">115 nips-2013-Factorized Asymptotic Bayesian Inference for Latent Feature Models</a></p>
<p>Author: Kohei Hayashi, Ryohei Fujimaki</p><p>Abstract: This paper extends factorized asymptotic Bayesian (FAB) inference for latent feature models (LFMs). FAB inference has not been applicable to models, including LFMs, without a speciﬁc condition on the Hessian matrix of a complete loglikelihood, which is required to derive a “factorized information criterion” (FIC). Our asymptotic analysis of the Hessian matrix of LFMs shows that FIC of LFMs has the same form as those of mixture models. FAB/LFMs have several desirable properties (e.g., automatic hidden states selection and parameter identiﬁability) and empirically perform better than state-of-the-art Indian Buffet processes in terms of model selection, prediction, and computational efﬁciency. 1</p><p>6 0.62963486 <a title="359-lda-6" href="./nips-2013-Latent_Structured_Active_Learning.html">149 nips-2013-Latent Structured Active Learning</a></p>
<p>7 0.6255455 <a title="359-lda-7" href="./nips-2013-Efficient_Algorithm_for_Privately_Releasing_Smooth_Queries.html">102 nips-2013-Efficient Algorithm for Privately Releasing Smooth Queries</a></p>
<p>8 0.59287244 <a title="359-lda-8" href="./nips-2013-%28Nearly%29_Optimal_Algorithms_for_Private_Online_Learning_in_Full-information_and_Bandit_Settings.html">2 nips-2013-(Nearly) Optimal Algorithms for Private Online Learning in Full-information and Bandit Settings</a></p>
<p>9 0.58622169 <a title="359-lda-9" href="./nips-2013-Regularized_M-estimators_with_nonconvexity%3A_Statistical_and_algorithmic_theory_for_local_optima.html">271 nips-2013-Regularized M-estimators with nonconvexity: Statistical and algorithmic theory for local optima</a></p>
<p>10 0.58571714 <a title="359-lda-10" href="./nips-2013-Local_Privacy_and_Minimax_Bounds%3A_Sharp_Rates_for_Probability_Estimation.html">177 nips-2013-Local Privacy and Minimax Bounds: Sharp Rates for Probability Estimation</a></p>
<p>11 0.58305687 <a title="359-lda-11" href="./nips-2013-Learning_Gaussian_Graphical_Models_with_Observed_or_Latent_FVSs.html">154 nips-2013-Learning Gaussian Graphical Models with Observed or Latent FVSs</a></p>
<p>12 0.57976079 <a title="359-lda-12" href="./nips-2013-Reflection_methods_for_user-friendly_submodular_optimization.html">268 nips-2013-Reflection methods for user-friendly submodular optimization</a></p>
<p>13 0.57913452 <a title="359-lda-13" href="./nips-2013-Marginals-to-Models_Reducibility.html">184 nips-2013-Marginals-to-Models Reducibility</a></p>
<p>14 0.57876956 <a title="359-lda-14" href="./nips-2013-Polar_Operators_for_Structured_Sparse_Estimation.html">249 nips-2013-Polar Operators for Structured Sparse Estimation</a></p>
<p>15 0.57774657 <a title="359-lda-15" href="./nips-2013-Online_Learning_of_Dynamic_Parameters_in_Social_Networks.html">228 nips-2013-Online Learning of Dynamic Parameters in Social Networks</a></p>
<p>16 0.57761997 <a title="359-lda-16" href="./nips-2013-Which_Space_Partitioning_Tree_to_Use_for_Search%3F.html">355 nips-2013-Which Space Partitioning Tree to Use for Search?</a></p>
<p>17 0.57506645 <a title="359-lda-17" href="./nips-2013-Robust_Multimodal_Graph_Matching%3A_Sparse_Coding_Meets_Graph_Matching.html">282 nips-2013-Robust Multimodal Graph Matching: Sparse Coding Meets Graph Matching</a></p>
<p>18 0.57450646 <a title="359-lda-18" href="./nips-2013-Fantope_Projection_and_Selection%3A_A_near-optimal_convex_relaxation_of_sparse_PCA.html">116 nips-2013-Fantope Projection and Selection: A near-optimal convex relaxation of sparse PCA</a></p>
<p>19 0.57426476 <a title="359-lda-19" href="./nips-2013-Near-optimal_Anomaly_Detection_in_Graphs_using_Lovasz_Extended_Scan_Statistic.html">207 nips-2013-Near-optimal Anomaly Detection in Graphs using Lovasz Extended Scan Statistic</a></p>
<p>20 0.57408589 <a title="359-lda-20" href="./nips-2013-Statistical_Active_Learning_Algorithms.html">309 nips-2013-Statistical Active Learning Algorithms</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
