<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>59 nips-2013-Blind Calibration in Compressed Sensing using Message Passing Algorithms</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-59" href="#">nips2013-59</a> knowledge-graph by maker-knowledge-mining</p><h1>59 nips-2013-Blind Calibration in Compressed Sensing using Message Passing Algorithms</h1>
<br/><p>Source: <a title="nips-2013-59-pdf" href="http://papers.nips.cc/paper/4947-blind-calibration-in-compressed-sensing-using-message-passing-algorithms.pdf">pdf</a></p><p>Author: Christophe Schulke, Francesco Caltagirone, Florent Krzakala, Lenka Zdeborova</p><p>Abstract: Compressed sensing (CS) is a concept that allows to acquire compressible signals with a small number of measurements. As such it is very attractive for hardware implementations. Therefore, correct calibration of the hardware is a central issue. In this paper we study the so-called blind calibration, i.e. when the training signals that are available to perform the calibration are sparse but unknown. We extend the approximate message passing (AMP) algorithm used in CS to the case of blind calibration. In the calibration-AMP, both the gains on the sensors and the elements of the signals are treated as unknowns. Our algorithm is also applicable to settings in which the sensors distort the measurements in other ways than multiplication by a gain, unlike previously suggested blind calibration algorithms based on convex relaxations. We study numerically the phase diagram of the blind calibration problem, and show that even in cases where convex relaxation is possible, our algorithm requires a smaller number of measurements and/or signals in order to perform well. 1</p><p>Reference: <a title="nips-2013-59-reference" href="../nips2013_reference/nips-2013-Blind_Calibration_in_Compressed_Sensing_using_Message_Passing_Algorithms_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('calibr', 0.47), ('distort', 0.374), ('xil', 0.337), ('blind', 0.262), ('msecor', 0.218), ('compress', 0.201), ('il', 0.19), ('amp', 0.187), ('cs', 0.172), ('phas', 0.171), ('transf', 0.139), ('reconstruct', 0.121), ('mess', 0.11), ('transit', 0.108), ('vil', 0.105), ('diagram', 0.103), ('sens', 0.102), ('ail', 0.087), ('dxil', 0.079), ('gamp', 0.079)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="59-tfidf-1" href="./nips-2013-Blind_Calibration_in_Compressed_Sensing_using_Message_Passing_Algorithms.html">59 nips-2013-Blind Calibration in Compressed Sensing using Message Passing Algorithms</a></p>
<p>2 0.20741308 <a title="59-tfidf-2" href="./nips-2013-Convex_Calibrated_Surrogates_for_Low-Rank_Loss_Matrices_with_Applications_to_Subset_Ranking_Losses.html">72 nips-2013-Convex Calibrated Surrogates for Low-Rank Loss Matrices with Applications to Subset Ranking Losses</a></p>
<p>3 0.19481669 <a title="59-tfidf-3" href="./nips-2013-Low-rank_matrix_reconstruction_and_clustering_via_approximate_message_passing.html">180 nips-2013-Low-rank matrix reconstruction and clustering via approximate message passing</a></p>
<p>4 0.15206867 <a title="59-tfidf-4" href="./nips-2013-Compressive_Feature_Learning.html">65 nips-2013-Compressive Feature Learning</a></p>
<p>5 0.14855744 <a title="59-tfidf-5" href="./nips-2013-Estimating_LASSO_Risk_and_Noise_Level.html">109 nips-2013-Estimating LASSO Risk and Noise Level</a></p>
<p>6 0.13394834 <a title="59-tfidf-6" href="./nips-2013-Sparse_nonnegative_deconvolution_for_compressive_calcium_imaging%3A_algorithms_and_phase_transitions.html">304 nips-2013-Sparse nonnegative deconvolution for compressive calcium imaging: algorithms and phase transitions</a></p>
<p>7 0.094712548 <a title="59-tfidf-7" href="./nips-2013-Non-Uniform_Camera_Shake_Removal_Using_a_Spatially-Adaptive_Sparse_Penalty.html">212 nips-2013-Non-Uniform Camera Shake Removal Using a Spatially-Adaptive Sparse Penalty</a></p>
<p>8 0.083694659 <a title="59-tfidf-8" href="./nips-2013-Phase_Retrieval_using_Alternating_Minimization.html">247 nips-2013-Phase Retrieval using Alternating Minimization</a></p>
<p>9 0.082135201 <a title="59-tfidf-9" href="./nips-2013-Learning_to_Pass_Expectation_Propagation_Messages.html">168 nips-2013-Learning to Pass Expectation Propagation Messages</a></p>
<p>10 0.080603421 <a title="59-tfidf-10" href="./nips-2013-Modeling_Overlapping_Communities_with_Node_Popularities.html">196 nips-2013-Modeling Overlapping Communities with Node Popularities</a></p>
<p>11 0.078715913 <a title="59-tfidf-11" href="./nips-2013-Sparse_Inverse_Covariance_Estimation_with_Calibration.html">302 nips-2013-Sparse Inverse Covariance Estimation with Calibration</a></p>
<p>12 0.076432519 <a title="59-tfidf-12" href="./nips-2013-Designed_Measurements_for_Vector_Count_Data.html">88 nips-2013-Designed Measurements for Vector Count Data</a></p>
<p>13 0.073182896 <a title="59-tfidf-13" href="./nips-2013-Top-Down_Regularization_of_Deep_Belief_Networks.html">331 nips-2013-Top-Down Regularization of Deep Belief Networks</a></p>
<p>14 0.072822437 <a title="59-tfidf-14" href="./nips-2013-Fast_Determinantal_Point_Process_Sampling_with_Application_to_Clustering.html">118 nips-2013-Fast Determinantal Point Process Sampling with Application to Clustering</a></p>
<p>15 0.071474753 <a title="59-tfidf-15" href="./nips-2013-On_the_Relationship_Between_Binary_Classification%2C_Bipartite_Ranking%2C_and_Binary_Class_Probability_Estimation.html">223 nips-2013-On the Relationship Between Binary Classification, Bipartite Ranking, and Binary Class Probability Estimation</a></p>
<p>16 0.067894854 <a title="59-tfidf-16" href="./nips-2013-Transfer_Learning_in_a_Transductive_Setting.html">335 nips-2013-Transfer Learning in a Transductive Setting</a></p>
<p>17 0.06391263 <a title="59-tfidf-17" href="./nips-2013-High-Dimensional_Gaussian_Process_Bandits.html">137 nips-2013-High-Dimensional Gaussian Process Bandits</a></p>
<p>18 0.061723553 <a title="59-tfidf-18" href="./nips-2013-Bellman_Error_Based_Feature_Generation_using_Random_Projections_on_Sparse_Spaces.html">55 nips-2013-Bellman Error Based Feature Generation using Random Projections on Sparse Spaces</a></p>
<p>19 0.055758446 <a title="59-tfidf-19" href="./nips-2013-Bayesian_inference_as_iterated_random_functions_with__applications_to_sequential_inference_in_graphical_models.html">52 nips-2013-Bayesian inference as iterated random functions with  applications to sequential inference in graphical models</a></p>
<p>20 0.054154076 <a title="59-tfidf-20" href="./nips-2013-Transportability_from_Multiple_Environments_with_Limited_Experiments.html">337 nips-2013-Transportability from Multiple Environments with Limited Experiments</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.129), (1, 0.033), (2, 0.01), (3, -0.015), (4, -0.017), (5, 0.026), (6, -0.018), (7, 0.026), (8, -0.005), (9, 0.042), (10, 0.06), (11, 0.05), (12, -0.005), (13, -0.028), (14, -0.031), (15, 0.017), (16, 0.011), (17, -0.048), (18, 0.015), (19, 0.113), (20, -0.062), (21, 0.047), (22, -0.016), (23, 0.055), (24, -0.089), (25, -0.045), (26, 0.087), (27, 0.105), (28, 0.272), (29, 0.17), (30, 0.059), (31, -0.116), (32, 0.139), (33, -0.209), (34, -0.051), (35, -0.081), (36, 0.085), (37, 0.031), (38, 0.042), (39, 0.013), (40, -0.068), (41, 0.131), (42, 0.056), (43, -0.048), (44, -0.028), (45, 0.185), (46, -0.12), (47, 0.004), (48, -0.001), (49, 0.057)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93749774 <a title="59-lsi-1" href="./nips-2013-Blind_Calibration_in_Compressed_Sensing_using_Message_Passing_Algorithms.html">59 nips-2013-Blind Calibration in Compressed Sensing using Message Passing Algorithms</a></p>
<p>2 0.6173954 <a title="59-lsi-2" href="./nips-2013-Low-rank_matrix_reconstruction_and_clustering_via_approximate_message_passing.html">180 nips-2013-Low-rank matrix reconstruction and clustering via approximate message passing</a></p>
<p>3 0.55535579 <a title="59-lsi-3" href="./nips-2013-Convex_Calibrated_Surrogates_for_Low-Rank_Loss_Matrices_with_Applications_to_Subset_Ranking_Losses.html">72 nips-2013-Convex Calibrated Surrogates for Low-Rank Loss Matrices with Applications to Subset Ranking Losses</a></p>
<p>4 0.44832319 <a title="59-lsi-4" href="./nips-2013-Compressive_Feature_Learning.html">65 nips-2013-Compressive Feature Learning</a></p>
<p>5 0.42270583 <a title="59-lsi-5" href="./nips-2013-Sparse_nonnegative_deconvolution_for_compressive_calcium_imaging%3A_algorithms_and_phase_transitions.html">304 nips-2013-Sparse nonnegative deconvolution for compressive calcium imaging: algorithms and phase transitions</a></p>
<p>6 0.42139971 <a title="59-lsi-6" href="./nips-2013-Designed_Measurements_for_Vector_Count_Data.html">88 nips-2013-Designed Measurements for Vector Count Data</a></p>
<p>7 0.40926516 <a title="59-lsi-7" href="./nips-2013-Phase_Retrieval_using_Alternating_Minimization.html">247 nips-2013-Phase Retrieval using Alternating Minimization</a></p>
<p>8 0.40290633 <a title="59-lsi-8" href="./nips-2013-Estimating_LASSO_Risk_and_Noise_Level.html">109 nips-2013-Estimating LASSO Risk and Noise Level</a></p>
<p>9 0.36607072 <a title="59-lsi-9" href="./nips-2013-Bayesian_inference_as_iterated_random_functions_with__applications_to_sequential_inference_in_graphical_models.html">52 nips-2013-Bayesian inference as iterated random functions with  applications to sequential inference in graphical models</a></p>
<p>10 0.34135672 <a title="59-lsi-10" href="./nips-2013-Message_Passing_Inference_with_Chemical_Reaction_Networks.html">189 nips-2013-Message Passing Inference with Chemical Reaction Networks</a></p>
<p>11 0.34120977 <a title="59-lsi-11" href="./nips-2013-Non-Uniform_Camera_Shake_Removal_Using_a_Spatially-Adaptive_Sparse_Penalty.html">212 nips-2013-Non-Uniform Camera Shake Removal Using a Spatially-Adaptive Sparse Penalty</a></p>
<p>12 0.33591282 <a title="59-lsi-12" href="./nips-2013-On_the_Relationship_Between_Binary_Classification%2C_Bipartite_Ranking%2C_and_Binary_Class_Probability_Estimation.html">223 nips-2013-On the Relationship Between Binary Classification, Bipartite Ranking, and Binary Class Probability Estimation</a></p>
<p>13 0.32886788 <a title="59-lsi-13" href="./nips-2013-Fast_Algorithms_for_Gaussian_Noise_Invariant_Independent_Component_Analysis.html">117 nips-2013-Fast Algorithms for Gaussian Noise Invariant Independent Component Analysis</a></p>
<p>14 0.31633806 <a title="59-lsi-14" href="./nips-2013-Bellman_Error_Based_Feature_Generation_using_Random_Projections_on_Sparse_Spaces.html">55 nips-2013-Bellman Error Based Feature Generation using Random Projections on Sparse Spaces</a></p>
<p>15 0.31514776 <a title="59-lsi-15" href="./nips-2013-Reconciling_%22priors%22_%26_%22priors%22_without_prejudice%3F.html">265 nips-2013-Reconciling "priors" & "priors" without prejudice?</a></p>
<p>16 0.30884117 <a title="59-lsi-16" href="./nips-2013-Pass-efficient_unsupervised_feature_selection.html">245 nips-2013-Pass-efficient unsupervised feature selection</a></p>
<p>17 0.30609649 <a title="59-lsi-17" href="./nips-2013-Sign_Cauchy_Projections_and_Chi-Square_Kernel.html">293 nips-2013-Sign Cauchy Projections and Chi-Square Kernel</a></p>
<p>18 0.3046186 <a title="59-lsi-18" href="./nips-2013-Learning_with_Noisy_Labels.html">171 nips-2013-Learning with Noisy Labels</a></p>
<p>19 0.3035059 <a title="59-lsi-19" href="./nips-2013-Sparse_Inverse_Covariance_Estimation_with_Calibration.html">302 nips-2013-Sparse Inverse Covariance Estimation with Calibration</a></p>
<p>20 0.30282429 <a title="59-lsi-20" href="./nips-2013-Learning_to_Pass_Expectation_Propagation_Messages.html">168 nips-2013-Learning to Pass Expectation Propagation Messages</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(20, 0.128), (25, 0.08), (37, 0.064), (70, 0.055), (77, 0.385), (80, 0.046), (86, 0.062), (87, 0.077)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.6644969 <a title="59-lda-1" href="./nips-2013-Blind_Calibration_in_Compressed_Sensing_using_Message_Passing_Algorithms.html">59 nips-2013-Blind Calibration in Compressed Sensing using Message Passing Algorithms</a></p>
<p>2 0.6534847 <a title="59-lda-2" href="./nips-2013-Convex_Calibrated_Surrogates_for_Low-Rank_Loss_Matrices_with_Applications_to_Subset_Ranking_Losses.html">72 nips-2013-Convex Calibrated Surrogates for Low-Rank Loss Matrices with Applications to Subset Ranking Losses</a></p>
<p>3 0.53991932 <a title="59-lda-3" href="./nips-2013-A_message-passing_algorithm_for_multi-agent_trajectory_planning.html">16 nips-2013-A message-passing algorithm for multi-agent trajectory planning</a></p>
<p>4 0.51137418 <a title="59-lda-4" href="./nips-2013-Minimax_Theory_for_High-dimensional_Gaussian_Mixtures_with_Sparse_Mean_Separation.html">192 nips-2013-Minimax Theory for High-dimensional Gaussian Mixtures with Sparse Mean Separation</a></p>
<p>5 0.45859173 <a title="59-lda-5" href="./nips-2013-Using_multiple_samples_to_learn_mixture_models.html">344 nips-2013-Using multiple samples to learn mixture models</a></p>
<p>6 0.45371211 <a title="59-lda-6" href="./nips-2013-On_model_selection_consistency_of_penalized_M-estimators%3A_a_geometric_theory.html">219 nips-2013-On model selection consistency of penalized M-estimators: a geometric theory</a></p>
<p>7 0.45139179 <a title="59-lda-7" href="./nips-2013-B-test%3A_A_Non-parametric%2C_Low_Variance_Kernel_Two-sample_Test.html">44 nips-2013-B-test: A Non-parametric, Low Variance Kernel Two-sample Test</a></p>
<p>8 0.4506194 <a title="59-lda-8" href="./nips-2013-Provable_Subspace_Clustering%3A_When_LRR_meets_SSC.html">259 nips-2013-Provable Subspace Clustering: When LRR meets SSC</a></p>
<p>9 0.44997007 <a title="59-lda-9" href="./nips-2013-When_are_Overcomplete_Topic_Models_Identifiable%3F_Uniqueness_of_Tensor_Tucker_Decompositions_with_Structured_Sparsity.html">353 nips-2013-When are Overcomplete Topic Models Identifiable? Uniqueness of Tensor Tucker Decompositions with Structured Sparsity</a></p>
<p>10 0.44926375 <a title="59-lda-10" href="./nips-2013-Estimation%2C_Optimization%2C_and_Parallelism_when_Data_is_Sparse.html">111 nips-2013-Estimation, Optimization, and Parallelism when Data is Sparse</a></p>
<p>11 0.44848847 <a title="59-lda-11" href="./nips-2013-Phase_Retrieval_using_Alternating_Minimization.html">247 nips-2013-Phase Retrieval using Alternating Minimization</a></p>
<p>12 0.44818291 <a title="59-lda-12" href="./nips-2013-Generalized_Random_Utility_Models_with_Multiple_Types.html">129 nips-2013-Generalized Random Utility Models with Multiple Types</a></p>
<p>13 0.44816405 <a title="59-lda-13" href="./nips-2013-On_the_Linear_Convergence_of_the_Proximal_Gradient_Method_for_Trace_Norm_Regularization.html">222 nips-2013-On the Linear Convergence of the Proximal Gradient Method for Trace Norm Regularization</a></p>
<p>14 0.44814956 <a title="59-lda-14" href="./nips-2013-The_Fast_Convergence_of_Incremental_PCA.html">324 nips-2013-The Fast Convergence of Incremental PCA</a></p>
<p>15 0.44748771 <a title="59-lda-15" href="./nips-2013-Sparse_nonnegative_deconvolution_for_compressive_calcium_imaging%3A_algorithms_and_phase_transitions.html">304 nips-2013-Sparse nonnegative deconvolution for compressive calcium imaging: algorithms and phase transitions</a></p>
<p>16 0.44674319 <a title="59-lda-16" href="./nips-2013-Online_Robust_PCA_via_Stochastic_Optimization.html">233 nips-2013-Online Robust PCA via Stochastic Optimization</a></p>
<p>17 0.44668725 <a title="59-lda-17" href="./nips-2013-A_New_Convex_Relaxation_for_Tensor_Completion.html">11 nips-2013-A New Convex Relaxation for Tensor Completion</a></p>
<p>18 0.44612917 <a title="59-lda-18" href="./nips-2013-Sensor_Selection_in_High-Dimensional_Gaussian_Trees_with_Nuisances.html">291 nips-2013-Sensor Selection in High-Dimensional Gaussian Trees with Nuisances</a></p>
<p>19 0.44592974 <a title="59-lda-19" href="./nips-2013-Trading_Computation_for_Communication%3A_Distributed_Stochastic_Dual_Coordinate_Ascent.html">333 nips-2013-Trading Computation for Communication: Distributed Stochastic Dual Coordinate Ascent</a></p>
<p>20 0.44590271 <a title="59-lda-20" href="./nips-2013-Near-Optimal_Entrywise_Sampling_for_Data_Matrices.html">206 nips-2013-Near-Optimal Entrywise Sampling for Data Matrices</a></p>
<br/><br/><br/></body>
</html>
