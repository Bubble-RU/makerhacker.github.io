<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>352 nips-2013-What do row and column marginals reveal about your dataset?</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-352" href="#">nips2013-352</a> knowledge-graph by maker-knowledge-mining</p><h1>352 nips-2013-What do row and column marginals reveal about your dataset?</h1>
<br/><p>Source: <a title="nips-2013-352-pdf" href="http://papers.nips.cc/paper/5118-what-do-row-and-column-marginals-reveal-about-your-dataset.pdf">pdf</a></p><p>Author: Behzad Golshan, John Byers, Evimaria Terzi</p><p>Abstract: Numerous datasets ranging from group memberships within social networks to purchase histories on e-commerce sites are represented by binary matrices. While this data is often either proprietary or sensitive, aggregated data, notably row and column marginals, is often viewed as much less sensitive, and may be furnished for analysis. Here, we investigate how these data can be exploited to make inferences about the underlying matrix H. Instead of assuming a generative model for H, we view the input marginals as constraints on the dataspace of possible realizations of H and compute the probability density function of particular entries H(i, j) of interest. We do this for all the cells of H simultaneously, without generating realizations, but rather via implicitly sampling the datasets that satisfy the input marginals. The end result is an efﬁcient algorithm with asymptotic running time the same as that required by standard sampling techniques to generate a single dataset from the same dataspace. Our experimental evaluation demonstrates the efﬁciency and the efﬁcacy of our framework in multiple settings. 1</p><p>Reference: <a title="nips-2013-352-reference" href="../nips2013_reference/nips-2013-What_do_row_and_column_marginals_reveal_about_your_dataset%3F_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('pdfs', 0.508), ('knot', 0.477), ('dataspac', 0.393), ('column', 0.19), ('rasch', 0.186), ('blp', 0.162), ('cel', 0.129), ('ls', 0.127), ('px', 0.12), ('entry', 0.109), ('qk', 0.102), ('pdf', 0.096), ('hid', 0.095), ('mcmc', 0.094), ('row', 0.089), ('margin', 0.084), ('ol', 0.075), ('ix', 0.07), ('adjust', 0.065), ('bin', 0.061)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="352-tfidf-1" href="./nips-2013-What_do_row_and_column_marginals_reveal_about_your_dataset%3F.html">352 nips-2013-What do row and column marginals reveal about your dataset?</a></p>
<p>2 0.086047493 <a title="352-tfidf-2" href="./nips-2013-Low-Rank_Matrix_and_Tensor_Completion_via_Adaptive_Sampling.html">179 nips-2013-Low-Rank Matrix and Tensor Completion via Adaptive Sampling</a></p>
<p>3 0.082840122 <a title="352-tfidf-3" href="./nips-2013-Extracting_regions_of_interest_from_biological_images_with_convolutional_sparse_block_coding.html">114 nips-2013-Extracting regions of interest from biological images with convolutional sparse block coding</a></p>
<p>4 0.080949366 <a title="352-tfidf-4" href="./nips-2013-Matrix_factorization_with_binary_components.html">186 nips-2013-Matrix factorization with binary components</a></p>
<p>5 0.077647075 <a title="352-tfidf-5" href="./nips-2013-Large_Scale_Distributed_Sparse_Precision_Estimation.html">146 nips-2013-Large Scale Distributed Sparse Precision Estimation</a></p>
<p>6 0.075591706 <a title="352-tfidf-6" href="./nips-2013-Near-Optimal_Entrywise_Sampling_for_Data_Matrices.html">206 nips-2013-Near-Optimal Entrywise Sampling for Data Matrices</a></p>
<p>7 0.066691831 <a title="352-tfidf-7" href="./nips-2013-Predicting_Parameters_in_Deep_Learning.html">251 nips-2013-Predicting Parameters in Deep Learning</a></p>
<p>8 0.064403079 <a title="352-tfidf-8" href="./nips-2013-Matrix_Completion_From_any_Given_Set_of_Observations.html">185 nips-2013-Matrix Completion From any Given Set of Observations</a></p>
<p>9 0.063131332 <a title="352-tfidf-9" href="./nips-2013-Annealing_between_distributions_by_averaging_moments.html">36 nips-2013-Annealing between distributions by averaging moments</a></p>
<p>10 0.06204905 <a title="352-tfidf-10" href="./nips-2013-Error-Minimizing_Estimates_and_Universal_Entry-Wise_Error_Bounds_for_Low-Rank_Matrix_Completion.html">108 nips-2013-Error-Minimizing Estimates and Universal Entry-Wise Error Bounds for Low-Rank Matrix Completion</a></p>
<p>11 0.061657891 <a title="352-tfidf-11" href="./nips-2013-Flexible_sampling_of_discrete_data_correlations_without_the_marginal_distributions.html">123 nips-2013-Flexible sampling of discrete data correlations without the marginal distributions</a></p>
<p>12 0.061312005 <a title="352-tfidf-12" href="./nips-2013-A_Comparative_Framework_for_Preconditioned_Lasso_Algorithms.html">4 nips-2013-A Comparative Framework for Preconditioned Lasso Algorithms</a></p>
<p>13 0.058740862 <a title="352-tfidf-13" href="./nips-2013-Confidence_Intervals_and_Hypothesis_Testing_for_High-Dimensional_Statistical_Models.html">68 nips-2013-Confidence Intervals and Hypothesis Testing for High-Dimensional Statistical Models</a></p>
<p>14 0.056847956 <a title="352-tfidf-14" href="./nips-2013-Learning_Hidden_Markov_Models_from_Non-sequence_Data_via_Tensor_Decomposition.html">155 nips-2013-Learning Hidden Markov Models from Non-sequence Data via Tensor Decomposition</a></p>
<p>15 0.054576889 <a title="352-tfidf-15" href="./nips-2013-Locally_Adaptive_Bayesian_Multivariate_Time_Series.html">178 nips-2013-Locally Adaptive Bayesian Multivariate Time Series</a></p>
<p>16 0.049628716 <a title="352-tfidf-16" href="./nips-2013-Nonparametric_Multi-group_Membership_Model_for_Dynamic_Networks.html">213 nips-2013-Nonparametric Multi-group Membership Model for Dynamic Networks</a></p>
<p>17 0.045902912 <a title="352-tfidf-17" href="./nips-2013-Speeding_up_Permutation_Testing_in_Neuroimaging.html">306 nips-2013-Speeding up Permutation Testing in Neuroimaging</a></p>
<p>18 0.045751017 <a title="352-tfidf-18" href="./nips-2013-When_are_Overcomplete_Topic_Models_Identifiable%3F_Uniqueness_of_Tensor_Tucker_Decompositions_with_Structured_Sparsity.html">353 nips-2013-When are Overcomplete Topic Models Identifiable? Uniqueness of Tensor Tucker Decompositions with Structured Sparsity</a></p>
<p>19 0.044512521 <a title="352-tfidf-19" href="./nips-2013-Robust_Multimodal_Graph_Matching%3A_Sparse_Coding_Meets_Graph_Matching.html">282 nips-2013-Robust Multimodal Graph Matching: Sparse Coding Meets Graph Matching</a></p>
<p>20 0.044484787 <a title="352-tfidf-20" href="./nips-2013-Embed_and_Project%3A_Discrete_Sampling_with_Universal_Hashing.html">107 nips-2013-Embed and Project: Discrete Sampling with Universal Hashing</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.136), (1, 0.05), (2, 0.027), (3, -0.03), (4, -0.005), (5, 0.008), (6, 0.001), (7, 0.017), (8, 0.019), (9, 0.007), (10, 0.042), (11, 0.017), (12, -0.001), (13, -0.011), (14, -0.016), (15, -0.01), (16, -0.019), (17, -0.095), (18, 0.027), (19, 0.025), (20, 0.064), (21, -0.081), (22, 0.032), (23, 0.041), (24, -0.027), (25, 0.015), (26, -0.062), (27, 0.022), (28, -0.029), (29, 0.012), (30, 0.066), (31, 0.017), (32, -0.001), (33, -0.049), (34, -0.04), (35, -0.013), (36, -0.024), (37, 0.038), (38, -0.002), (39, -0.038), (40, -0.036), (41, -0.051), (42, -0.036), (43, -0.011), (44, 0.013), (45, 0.039), (46, -0.011), (47, -0.031), (48, -0.042), (49, -0.012)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.90900975 <a title="352-lsi-1" href="./nips-2013-What_do_row_and_column_marginals_reveal_about_your_dataset%3F.html">352 nips-2013-What do row and column marginals reveal about your dataset?</a></p>
<p>2 0.78881407 <a title="352-lsi-2" href="./nips-2013-Matrix_factorization_with_binary_components.html">186 nips-2013-Matrix factorization with binary components</a></p>
<p>3 0.71952081 <a title="352-lsi-3" href="./nips-2013-Large_Scale_Distributed_Sparse_Precision_Estimation.html">146 nips-2013-Large Scale Distributed Sparse Precision Estimation</a></p>
<p>4 0.7125774 <a title="352-lsi-4" href="./nips-2013-On_Algorithms_for_Sparse_Multi-factor_NMF.html">214 nips-2013-On Algorithms for Sparse Multi-factor NMF</a></p>
<p>5 0.70276004 <a title="352-lsi-5" href="./nips-2013-Near-Optimal_Entrywise_Sampling_for_Data_Matrices.html">206 nips-2013-Near-Optimal Entrywise Sampling for Data Matrices</a></p>
<p>6 0.67418259 <a title="352-lsi-6" href="./nips-2013-Fast_Algorithms_for_Gaussian_Noise_Invariant_Independent_Component_Analysis.html">117 nips-2013-Fast Algorithms for Gaussian Noise Invariant Independent Component Analysis</a></p>
<p>7 0.67080903 <a title="352-lsi-7" href="./nips-2013-Pass-efficient_unsupervised_feature_selection.html">245 nips-2013-Pass-efficient unsupervised feature selection</a></p>
<p>8 0.64913803 <a title="352-lsi-8" href="./nips-2013-Error-Minimizing_Estimates_and_Universal_Entry-Wise_Error_Bounds_for_Low-Rank_Matrix_Completion.html">108 nips-2013-Error-Minimizing Estimates and Universal Entry-Wise Error Bounds for Low-Rank Matrix Completion</a></p>
<p>9 0.63335377 <a title="352-lsi-9" href="./nips-2013-BIG_%26_QUIC%3A_Sparse_Inverse_Covariance_Estimation_for_a_Million_Variables.html">45 nips-2013-BIG & QUIC: Sparse Inverse Covariance Estimation for a Million Variables</a></p>
<p>10 0.63128227 <a title="352-lsi-10" href="./nips-2013-Speedup_Matrix_Completion_with_Side_Information%3A_Application_to_Multi-Label_Learning.html">307 nips-2013-Speedup Matrix Completion with Side Information: Application to Multi-Label Learning</a></p>
<p>11 0.62660718 <a title="352-lsi-11" href="./nips-2013-Graphical_Models_for_Inference_with_Missing_Data.html">134 nips-2013-Graphical Models for Inference with Missing Data</a></p>
<p>12 0.6246922 <a title="352-lsi-12" href="./nips-2013-Matrix_Completion_From_any_Given_Set_of_Observations.html">185 nips-2013-Matrix Completion From any Given Set of Observations</a></p>
<p>13 0.62223941 <a title="352-lsi-13" href="./nips-2013-Speeding_up_Permutation_Testing_in_Neuroimaging.html">306 nips-2013-Speeding up Permutation Testing in Neuroimaging</a></p>
<p>14 0.61311227 <a title="352-lsi-14" href="./nips-2013-Stochastic_blockmodel_approximation_of_a_graphon%3A_Theory_and_consistent_estimation.html">316 nips-2013-Stochastic blockmodel approximation of a graphon: Theory and consistent estimation</a></p>
<p>15 0.61086309 <a title="352-lsi-15" href="./nips-2013-Learning_Feature_Selection_Dependencies_in_Multi-task_Learning.html">153 nips-2013-Learning Feature Selection Dependencies in Multi-task Learning</a></p>
<p>16 0.6082958 <a title="352-lsi-16" href="./nips-2013-When_in_Doubt%2C_SWAP%3A_High-Dimensional_Sparse_Recovery_from_Correlated_Measurements.html">354 nips-2013-When in Doubt, SWAP: High-Dimensional Sparse Recovery from Correlated Measurements</a></p>
<p>17 0.60629779 <a title="352-lsi-17" href="./nips-2013-Low-Rank_Matrix_and_Tensor_Completion_via_Adaptive_Sampling.html">179 nips-2013-Low-Rank Matrix and Tensor Completion via Adaptive Sampling</a></p>
<p>18 0.59947985 <a title="352-lsi-18" href="./nips-2013-Unsupervised_Spectral_Learning_of_Finite_State_Transducers.html">342 nips-2013-Unsupervised Spectral Learning of Finite State Transducers</a></p>
<p>19 0.59424418 <a title="352-lsi-19" href="./nips-2013-New_Subsampling_Algorithms_for_Fast_Least_Squares_Regression.html">209 nips-2013-New Subsampling Algorithms for Fast Least Squares Regression</a></p>
<p>20 0.59348387 <a title="352-lsi-20" href="./nips-2013-Probabilistic_Low-Rank_Matrix_Completion_with_Adaptive_Spectral_Regularization_Algorithms.html">254 nips-2013-Probabilistic Low-Rank Matrix Completion with Adaptive Spectral Regularization Algorithms</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(16, 0.295), (20, 0.174), (25, 0.099), (37, 0.072), (70, 0.046), (80, 0.081), (86, 0.078), (87, 0.053)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.74521744 <a title="352-lda-1" href="./nips-2013-Optimizing_Instructional_Policies.html">241 nips-2013-Optimizing Instructional Policies</a></p>
<p>same-paper 2 0.73393041 <a title="352-lda-2" href="./nips-2013-What_do_row_and_column_marginals_reveal_about_your_dataset%3F.html">352 nips-2013-What do row and column marginals reveal about your dataset?</a></p>
<p>3 0.72308648 <a title="352-lda-3" href="./nips-2013-Learning_invariant_representations_and_applications_to_face_verification.html">166 nips-2013-Learning invariant representations and applications to face verification</a></p>
<p>4 0.64217937 <a title="352-lda-4" href="./nips-2013-On_model_selection_consistency_of_penalized_M-estimators%3A_a_geometric_theory.html">219 nips-2013-On model selection consistency of penalized M-estimators: a geometric theory</a></p>
<p>5 0.64089811 <a title="352-lda-5" href="./nips-2013-When_are_Overcomplete_Topic_Models_Identifiable%3F_Uniqueness_of_Tensor_Tucker_Decompositions_with_Structured_Sparsity.html">353 nips-2013-When are Overcomplete Topic Models Identifiable? Uniqueness of Tensor Tucker Decompositions with Structured Sparsity</a></p>
<p>6 0.63829982 <a title="352-lda-6" href="./nips-2013-Reflection_methods_for_user-friendly_submodular_optimization.html">268 nips-2013-Reflection methods for user-friendly submodular optimization</a></p>
<p>7 0.63790333 <a title="352-lda-7" href="./nips-2013-Trading_Computation_for_Communication%3A_Distributed_Stochastic_Dual_Coordinate_Ascent.html">333 nips-2013-Trading Computation for Communication: Distributed Stochastic Dual Coordinate Ascent</a></p>
<p>8 0.63721079 <a title="352-lda-8" href="./nips-2013-Capacity_of_strong_attractor_patterns_to_model_behavioural_and_cognitive_prototypes.html">61 nips-2013-Capacity of strong attractor patterns to model behavioural and cognitive prototypes</a></p>
<p>9 0.63666379 <a title="352-lda-9" href="./nips-2013-A_Kernel_Test_for_Three-Variable_Interactions.html">9 nips-2013-A Kernel Test for Three-Variable Interactions</a></p>
<p>10 0.63612044 <a title="352-lda-10" href="./nips-2013-Multiclass_Total_Variation_Clustering.html">202 nips-2013-Multiclass Total Variation Clustering</a></p>
<p>11 0.63610911 <a title="352-lda-11" href="./nips-2013-Curvature_and_Optimal_Algorithms_for_Learning_and_Minimizing_Submodular_Functions.html">78 nips-2013-Curvature and Optimal Algorithms for Learning and Minimizing Submodular Functions</a></p>
<p>12 0.63578558 <a title="352-lda-12" href="./nips-2013-Better_Approximation_and_Faster_Algorithm_Using_the_Proximal_Average.html">56 nips-2013-Better Approximation and Faster Algorithm Using the Proximal Average</a></p>
<p>13 0.63571256 <a title="352-lda-13" href="./nips-2013-Submodular_Optimization_with_Submodular_Cover_and_Submodular_Knapsack_Constraints.html">319 nips-2013-Submodular Optimization with Submodular Cover and Submodular Knapsack Constraints</a></p>
<p>14 0.63566881 <a title="352-lda-14" href="./nips-2013-Variational_Inference_for_Mahalanobis_Distance_Metrics_in_Gaussian_Process_Regression.html">346 nips-2013-Variational Inference for Mahalanobis Distance Metrics in Gaussian Process Regression</a></p>
<p>15 0.63534456 <a title="352-lda-15" href="./nips-2013-Structured_Learning_via_Logistic_Regression.html">318 nips-2013-Structured Learning via Logistic Regression</a></p>
<p>16 0.63517267 <a title="352-lda-16" href="./nips-2013-BIG_%26_QUIC%3A_Sparse_Inverse_Covariance_Estimation_for_a_Million_Variables.html">45 nips-2013-BIG & QUIC: Sparse Inverse Covariance Estimation for a Million Variables</a></p>
<p>17 0.63438213 <a title="352-lda-17" href="./nips-2013-Annealing_between_distributions_by_averaging_moments.html">36 nips-2013-Annealing between distributions by averaging moments</a></p>
<p>18 0.63432282 <a title="352-lda-18" href="./nips-2013-B-test%3A_A_Non-parametric%2C_Low_Variance_Kernel_Two-sample_Test.html">44 nips-2013-B-test: A Non-parametric, Low Variance Kernel Two-sample Test</a></p>
<p>19 0.63408512 <a title="352-lda-19" href="./nips-2013-Generalized_Random_Utility_Models_with_Multiple_Types.html">129 nips-2013-Generalized Random Utility Models with Multiple Types</a></p>
<p>20 0.63396323 <a title="352-lda-20" href="./nips-2013-Optimal_Neural_Population_Codes_for_High-dimensional_Stimulus_Variables.html">236 nips-2013-Optimal Neural Population Codes for High-dimensional Stimulus Variables</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
