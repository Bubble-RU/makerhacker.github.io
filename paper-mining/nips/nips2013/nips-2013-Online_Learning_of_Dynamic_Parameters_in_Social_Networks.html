<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>228 nips-2013-Online Learning of Dynamic Parameters in Social Networks</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-228" href="#">nips2013-228</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>228 nips-2013-Online Learning of Dynamic Parameters in Social Networks</h1>
<br/><p>Source: <a title="nips-2013-228-pdf" href="http://papers.nips.cc/paper/4976-online-learning-of-dynamic-parameters-in-social-networks.pdf">pdf</a></p><p>Author: Shahin Shahrampour, Sasha Rakhlin, Ali Jadbabaie</p><p>Abstract: This paper addresses the problem of online learning in a dynamic setting. We consider a social network in which each individual observes a private signal about the underlying state of the world and communicates with her neighbors at each time period. Unlike many existing approaches, the underlying state is dynamic, and evolves according to a geometric random walk. We view the scenario as an optimization problem where agents aim to learn the true state while suffering the smallest possible loss. Based on the decomposition of the global loss function, we introduce two update mechanisms, each of which generates an estimate of the true state. We establish a tight bound on the rate of change of the underlying state, under which individuals can track the parameter with a bounded variance. Then, we characterize explicit expressions for the steady state mean-square deviation(MSD) of the estimates from the truth, per individual. We observe that only one of the estimators recovers the optimal MSD, which underscores the impact of the objective function decomposition on the learning quality. Finally, we provide an upper bound on the regret of the proposed methods, measured as an average of errors in estimating the parameter in a ﬁnite time. 1</p><p>Reference: <a title="nips-2013-228-reference" href="../nips2013_reference/nips-2013-Online_Learning_of_Dynamic_Parameters_in_Social_Networks_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 We consider a social network in which each individual observes a private signal about the underlying state of the world and communicates with her neighbors at each time period. [sent-6, score-0.681]
</p><p>2 Unlike many existing approaches, the underlying state is dynamic, and evolves according to a geometric random walk. [sent-7, score-0.187]
</p><p>3 We view the scenario as an optimization problem where agents aim to learn the true state while suffering the smallest possible loss. [sent-8, score-0.456]
</p><p>4 Based on the decomposition of the global loss function, we introduce two update mechanisms, each of which generates an estimate of the true state. [sent-9, score-0.15]
</p><p>5 We establish a tight bound on the rate of change of the underlying state, under which individuals can track the parameter with a bounded variance. [sent-10, score-0.282]
</p><p>6 Then, we characterize explicit expressions for the steady state mean-square deviation(MSD) of the estimates from the truth, per individual. [sent-11, score-0.29]
</p><p>7 We observe that only one of the estimators recovers the optimal MSD, which underscores the impact of the objective function decomposition on the learning quality. [sent-12, score-0.13]
</p><p>8 Finally, we provide an upper bound on the regret of the proposed methods, measured as an average of errors in estimating the parameter in a ﬁnite time. [sent-13, score-0.118]
</p><p>9 1  Introduction  In recent years, distributed estimation, learning and prediction has attracted a considerable attention in wide variety of disciplines with applications ranging from sensor networks to social and economic networks [1–6]. [sent-14, score-0.413]
</p><p>10 In this broad class of problems, agents aim to learn the true value of a parameter often called the underlying state of the world. [sent-15, score-0.511]
</p><p>11 The state could represent a product, an opinion, a vote, or a quantity of interest in a sensor network. [sent-16, score-0.18]
</p><p>12 Each agent observes a private signal about the underlying state at each time period, and communicates with her neighbors to augment her imperfect observations. [sent-17, score-0.527]
</p><p>13 Despite the wealth of research in this area when the underlying state is ﬁxed (see e. [sent-18, score-0.159]
</p><p>14 [1–3, 7]), often the state is subject to some change over time(e. [sent-20, score-0.142]
</p><p>15 In this paper we aim to study the sequential prediction problem in the context of a social network and noisy feedback to agents. [sent-25, score-0.348]
</p><p>16 We consider a stochastic optimization framework to describe an online social learning problem when the underlying state of the world varies over time. [sent-26, score-0.387]
</p><p>17 Our motivation for the current study is the results of [8] and [9] where authors propose a social learning scheme in which the underlying state follows a simple random walk. [sent-27, score-0.308]
</p><p>18 This enables us to investigate the interplay of social learning, network structure, and the rate of state change, especially in the interesting case that the rate is 1  greater than unity. [sent-29, score-0.453]
</p><p>19 We then pose the social learning as an optimization problem in which individuals aim to suffer the smallest possible loss as they observe the stream of signals. [sent-30, score-0.318]
</p><p>20 in [13] where the authors develop a distributed method based on dual averaging of sub-gradients to converge to the optimal solution. [sent-32, score-0.112]
</p><p>21 In this paper, we restrict our attention to quadratic loss functions regularized by a quadratic proximal function, but there is no ﬁxed optimal solution as the underlying state is dynamic. [sent-33, score-0.203]
</p><p>22 In this direction, the key observation is the decomposition of the global loss function into local loss functions. [sent-34, score-0.187]
</p><p>23 The ﬁrst method incorporates the averaged prior beliefs among neighbors with the new private observation, while the second one takes into account the observations in the neighborhood as well. [sent-36, score-0.191]
</p><p>24 Interestingly, this quantity relies on the whole spectrum of the communication matrix which exhibits the formidable role of the network structure in the asymptotic learning. [sent-38, score-0.191]
</p><p>25 This fact underscores the dependence of optimality on decomposition of the global loss function. [sent-41, score-0.155]
</p><p>26 Our next contribution is to provide an upper bound for regret of the proposed methods, deﬁned as an average of errors in estimating the parameter up to a given time minus the long-run expected loss due to noise and dynamics alone. [sent-44, score-0.162]
</p><p>27 Finally, we examine the trade-off between the network sparsity and learning quality in a microscopic level. [sent-46, score-0.102]
</p><p>28 Under mild technical constraints, we see that losing each connection has detrimental effect on learning as it monotonically increases the MSD. [sent-47, score-0.117]
</p><p>29 On the other hand, capturing agents communications with a graph, we introduce the notion of optimal edge as the edge whose addition has the most effect on learning in the sense of MSD reduction. [sent-48, score-0.449]
</p><p>30 We prove that such a friendship is likely to occur between a pair of individuals with high self-reliance that have the least common neighbors. [sent-49, score-0.134]
</p><p>31 1  Preliminaries State and Observation Model  We consider a network consisting of a ﬁnite number of agents V = {1, 2, . [sent-51, score-0.423]
</p><p>32 We assume the initial state x0 is a ﬁnite random variable drawn independently by the nature. [sent-56, score-0.104]
</p><p>33 Each agent i forms an estimate or a belief about the true value of xt at time t conforming to an update mechanism that will be discussed later. [sent-58, score-0.205]
</p><p>34 Much of the difﬁculty of this problem stems from the hardness of tracking a dynamic state with noisy observations, especially when |a| > 1, and communication mitigates the difﬁculty by virtue of reducing the effective noise. [sent-59, score-0.193]
</p><p>35 2  Communication Structure  Agents communicate with each other to update their beliefs about the underlying state of the world. [sent-61, score-0.295]
</p><p>36 The interaction between agents is captured by an undirected graph G = (V, E), where V is the set ¯ of agents, and if there is a link between agent i and agent j, then {i, j} ∈ E. [sent-62, score-0.539]
</p><p>37 Each agent i can only V : {i, j} ∈ E} be the set of neighbors of agent i, and Ni = N ¯ communicate with her neighbors, and assigns a weight pij > 0 for any j ∈ Ni . [sent-64, score-0.513]
</p><p>38 We also let pii ≥ 0 denote the self-reliance of agent i. [sent-65, score-0.196]
</p><p>39 , it satisﬁes pij ≥ 0  ,  pij = pji  , and  ￿  pij =  N ￿  pij = 1. [sent-69, score-0.644]
</p><p>40 3  Estimate Updates  The goal of agents is to learn xt in a collaborative manner by making sequential predictions. [sent-75, score-0.414]
</p><p>41 From optimization perspective, this can be cast as a quest for online minimization of the separable, global, time-varying cost function ￿ ￿ N ￿ N ￿ N ￿ ￿2 1 ￿ ˆ 1 ￿ 1 ￿ ˜ ˆ (¯) , (3) min ft (¯) = x fi,t (¯) ￿ E yi,t − x x ¯ = fi,t (¯) ￿ x pij fj,t x x∈R ¯ N i=1 2 N i=1 j=1 at each time period t. [sent-76, score-0.241]
</p><p>42 One approach to tackle the stochastic learning problem formulated above is to employ distributed dual averaging regularized by a quadratic proximal function [13]. [sent-77, score-0.112]
</p><p>43 Equations (4) and (5) are distinct, single-consensus-step estimators differing in the choice of the local loss function with (4) using only private observations while (5) averaging observations over the neighborhood. [sent-79, score-0.213]
</p><p>44 Note that the choice of constant step size provides an insight on the interplay of persistent innovation and learning abilities of the network. [sent-81, score-0.164]
</p><p>45 We remark that agents can easily learn the ﬁxed rate of change a by taking ratios of observations, and we assume that this has been already performed by the agents in the past. [sent-82, score-0.713]
</p><p>46 We also point out that the real-valued (rather than vector-valued) nature of the state is a simpliﬁcation that forms a clean playground for the study of the effects of social learning, effects of friendships, and other properties of the problem. [sent-84, score-0.253]
</p><p>47 4  Error Process  ˆ ˜ Deﬁning the local error processes ξi,t and ξi,t , at time t for agent i, as ˆ ξi,t ￿ xi,t − xt ˆ  and 3  ˜ ξi,t ￿ xi,t − xt , ˜  ˆ ˜ and stacking the local errors in vectors ξt , ξt ∈ RN , respectively, such that ˆ ˆ ˆ ˜ ˜ ˜ ξt ￿ [ξ1,t , . [sent-86, score-0.257]
</p><p>48 Given Assumption 1, the collective error processes ξt and ξt deﬁned in (6) satisfy ˆ ˆ ˆ ξt+1 = Qξt + st  and  ˜ ˜ ˜ ξt+1 = Qξt + st ,  (7)  respectively, where (8)  Q = a(P − αIN ),  and  and  st = (αa)[w1,t , . [sent-94, score-0.254]
</p><p>49 3  Social Learning: Convergence of Beliefs and Regret Analysis  In this section, we study the behavior of estimators (4) and (5) in the mean and mean-square sense, and we provide the regret analysis. [sent-102, score-0.152]
</p><p>50 In the following proposition, we establish a tight bound for a, under which agents can achieve asymptotically unbiased estimates using proper signal weight. [sent-103, score-0.462]
</p><p>51 Given the network G with corresponding communication matrix P satisfying Assumption 1, the rate of change of the social network in (4) and (5) must respect the constraint 2 |a| < , 1 − λN (P ) to allow agents to form asymptotically unbiased estimates of the underlying state. [sent-105, score-0.927]
</p><p>52 Proposition 3 determines the trade-off between the rate of change and the network structure. [sent-106, score-0.173]
</p><p>53 In other words, changing less than the rate given in the statement of the proposition, individuals can always track xt with bounded variance by selecting an appropriate signal weight. [sent-107, score-0.229]
</p><p>54 To capture that, we deﬁne the steady state Mean Square Deviation(MSD) of the network from the truth as follows. [sent-109, score-0.422]
</p><p>55 Given the network G with a rate of change which allows unbiased estimation, the steady state of the error processes in (7) is deﬁned as follows ˆˆ ˜˜ ˆ ˜ Σ ￿ lim E[ξt ξ T ] and Σ ￿ lim E[ξt ξ T ]. [sent-111, score-0.725]
</p><p>56 t→∞  t  t→∞  t  Hence, the (Steady State-)Mean Square Deviation of the network is the deviation from the truth in the mean-square sense, per individual, and it is deﬁned as 1 1 ˆ ˜ ˆ ˜ MSD ￿ Tr(Σ) and MSD ￿ Tr(Σ). [sent-112, score-0.176]
</p><p>57 (12) 2 (λ (P ) − α)2 2 (λ (P ) − α)2 N i=1 1 − a i N i=1 1 − a i  4  Theorem 5 shows that the steady state MSD is governed by all eigenvalues of P contributing to WM SD pertaining to the observation noise, while RM SD is the penalty incurred due to the innovation noise. [sent-115, score-0.45]
</p><p>58 One might advance a conjecture that a complete network, where all individuals can communicate with each other, achieves a lower steady state MSD in the learning process since it provides the most information diffusion among other networks. [sent-117, score-0.454]
</p><p>59 Denoting the complete, star, and cycle graphs on N vertices by KN , SN , and CN , respectively, and denoting their corresponding Laplacians by LKN , LSN , and LCN , under conditions of Theorem 5, (a) For P = I −  1−α N LK N ,  we have 2 ˆ lim MSDKN = RM SD (α) + a2 α2 σw . [sent-120, score-0.099]
</p><p>60 (13)  N →∞  (b) For P = I −  1−α N L SN ,  we have ˆ lim MSDSN = RM SD (α) +  N →∞  2 a 2 α 2 σw . [sent-121, score-0.099]
</p><p>61 1 − a2 (1 − α)2  (14)  (c) For P = I − βLCN , where β must preserve unbiasedness, we have ￿ 2π 2 a 2 α 2 σw dτ ˆ CN = RM SD (α) + lim MSD . [sent-122, score-0.099]
</p><p>62 2 (1 − β(2 − 2 cos(τ )) − α)2 2π N →∞ 1−a 0 (d) For P = I −  1 N LK N ,  (15)  we have ˜ lim MSDKN = RM SD (α). [sent-123, score-0.099]
</p><p>63 It is wellknown that the steady state KF satisﬁes a Riccati equation, and when the parameter of interest is scalar, the Riccati equation simpliﬁes to a quadratic with the positive root ￿ 2 2 2 2 2 2 2 2 a2 σw − σw + N σr + (a2 σw − σw + N σr )2 + 4N σw σr ΣKF = . [sent-136, score-0.29]
</p><p>64 2N Therefore, comparing with the complete graph (16), we have 2 lim ΣKF = σr ≤  N →∞  1−  2 σr 2 (1 − a  α)2  ,  and the upper bound can be made tight by choosing α = 1 for |a| < we should choose an α < 1 to preserve unbiasedness as well. [sent-137, score-0.194]
</p><p>65 62σ 2 < MSDBound = 2σ 2 ,  MSDBound =  N →∞  N  N →∞  N  N →∞  N  which suggests a noticeable improvement in learning even in the star and cycle networks where the number of individuals and connections are in the same order. [sent-143, score-0.132]
</p><p>66 The average loss of all agents in predicting the state, up until time T , is T N T 1￿ 1 ￿ 1￿ 1 ˆ ˆT (ˆi,t − xt )2 = x Tr(ξt ξt ) . [sent-145, score-0.426]
</p><p>67 We, ﬁrst, state a technical lemma from [16] that we invoke later for bounding the quantity RT . [sent-149, score-0.104]
</p><p>68 For simplicity, we assume that magnitudes of both innovation and observation noise are bounded. [sent-150, score-0.16]
</p><p>69 On the other hand, our problem has the network structure and the speciﬁc evolution of the hidden state, not present in the above works. [sent-176, score-0.102]
</p><p>70 6  4  The Impact of New Friendships on Social Learning  In the social learning model we proposed, agents are cooperative and they aim to accomplish a global objective. [sent-177, score-0.544]
</p><p>71 In this direction, the network structure contributes substantially to the learning process. [sent-178, score-0.102]
</p><p>72 In this section, we restrict our attention to estimator (5), and characterize the intuitive idea that making(losing) friendships can inﬂuence the quality of learning in the sense of decreasing(increasing) the steady state MSD of the network. [sent-179, score-0.377]
</p><p>73 To commence, letting ei denote the i-th unit vector in the standard basis of RN , we exploit the negative semi-deﬁnite, edge function matrix ∆P (i, j) ￿ −(ei − ej )(ei − ej )T ,  (20)  P￿ ￿ P + ￿∆P (i, j),  (21)  for edge addition(removal) to(from) the graph. [sent-180, score-0.185]
</p><p>74 Essentially, if there is no connection between agents i and j, for ￿ < min{pii , pjj }, corresponds to a new communication matrix adding the edge {i, j} with a weight ￿ to the network G, and subtracting ￿ from self-reliance of agents i and j. [sent-181, score-1.026]
</p><p>75 Let G − be the network resulted by removing the bidirectional edge {i, j} with the weight ￿ from the network G, so P−￿ and P denote the communication matrices associated to G − and G, respectively. [sent-183, score-0.384]
</p><p>76 Under a mild technical assumption, Proposition 9 suggests that losing connections monotonically increases the MSD, and individuals tend to maintain their friendships to obtain a lower MSD as a global objective. [sent-185, score-0.313]
</p><p>77 However, this does not elaborate on the existence of individuals with whom losing or making connections could have an immense impact on learning. [sent-186, score-0.153]
</p><p>78 We bring this concept to light in the following proposition with ﬁnding a so-called optimal edge which provides the most MSD reduction, in case it is added to the network graph. [sent-187, score-0.243]
</p><p>79 In addition, letting ζmax = maxk>1 |λk (P ) − α|, k=1 ￿ ￿ N ￿ −2￿ (1 − α2 a2 )(pii + pjj ) + a2 α([P 2 ]ii + [P 2 ]jj − 2[P 2 ]ij ) min hk (i, j) ≥ min . [sent-190, score-0.16]
</p><p>80 Representing the ﬁrst order approximation of λk (P￿ ) using deﬁnition of zk (i, j) in (24), we have λk (P￿ ) ≈ λk (P ) + zk (i, j) for ￿ ￿ 1. [sent-192, score-0.34]
</p><p>81 k  Substituting zk (i, j) from (24) to above, we have ￿￿ ￿ N N ￿ ￿ T ￿￿ ￿ 2￿ hk (i, j) ≥ ￿ vk ∆P (i, j)vk (1 − α2 a2 )λk (P ) + a2 αλ2 (P ) ￿2 k 2 1 − a2 ζmax k=1 k=1 ￿ ￿ N ￿￿ ￿ T 2￿ =￿ Tr ∆P (i, j) (1 − α2 a2 )λk (P ) + a2 αλ2 (P ) vk vk ￿2 k 2 1 − a2 ζmax k=1 ￿ ￿ ￿ ￿ 2￿ 2 2 2 2 . [sent-196, score-0.463]
</p><p>82 Beside posing the optimal edge problem as an optimization, Proposition 10 also provides an upper bound for the best improvement that making a friendship brings to the network. [sent-198, score-0.132]
</p><p>83 In view of (25), forming a connection between two agents with more self-reliance and less common neighbors, minimizes the lower bound, which offers the most maneuver for MSD reduction. [sent-199, score-0.349]
</p><p>84 5  Conclusion  We studied a distributed online learning problem over a social network. [sent-200, score-0.236]
</p><p>85 The goal of agents is to estimate the underlying state of the world which follows a geometric random walk. [sent-201, score-0.519]
</p><p>86 Each individual receives a noisy signal about the underlying state at each time period, so she communicates with her neighbors to recover the true state. [sent-202, score-0.32]
</p><p>87 We viewed the problem with an optimization lens where agents want to minimize a global loss function in a collaborative manner. [sent-203, score-0.408]
</p><p>88 Given the structure of the network, we provided a tight upper bound on the rate of change of the parameter which allows agents to follow the state with a bounded variance. [sent-205, score-0.558]
</p><p>89 Moreover, we computed the averaged, steady state, mean-square deviation of the estimates from the true state. [sent-206, score-0.23]
</p><p>90 Furthermore, deﬁning the regret as the average of errors in the process of learning during a ﬁnite time T , we demonstrated that the regret function of the proposed algorithms decays √ with a rate O(1/ T ). [sent-208, score-0.213]
</p><p>91 Finally, under mild technical assumptions, we characterized the inﬂuence of network pattern on learning by observing that each connection brings a monotonic decrease in the MSD. [sent-209, score-0.16]
</p><p>92 Tahbaz-Salehi, “Non-bayesian social learning,” Games and Economic Behavior, vol. [sent-221, score-0.149]
</p><p>93 Tamuz, “Efﬁcient bayesian learning in social networks with gaussian estimators,” arXiv preprint arXiv:1002. [sent-227, score-0.187]
</p><p>94 Xiao, “Optimal distributed online prediction using mini-batches,” The Journal of Machine Learning Research, vol. [sent-233, score-0.121]
</p><p>95 Lall, “A scheme for robust distributed sensor fusion based on average consensus,” in Fourth International Symposium on Information Processing in Sensor Networks. [sent-239, score-0.123]
</p><p>96 Ramanan, “Distributed parameter estimation in sensor networks: Nonlinear observation models and imperfect communication,” IEEE Transactions on Information Theory, vol. [sent-246, score-0.131]
</p><p>97 Jadbabaie, “Exponentially fast parameter estimation in networks using distributed dual averaging,” arXiv preprint arXiv:1309. [sent-252, score-0.114]
</p><p>98 Ozdaglar, “Convergence of rule-of-thumb learning rules in social networks,” in 47th IEEE Conference on Decision and Control, 2008, pp. [sent-257, score-0.149]
</p><p>99 Olfati-Saber, “Distributed kalman ﬁltering for sensor networks,” in 46th IEEE Conference on Decision and Control, 2007, pp. [sent-275, score-0.127]
</p><p>100 Wainwright, “Dual averaging for distributed optimization: convergence analysis and network scaling,” IEEE Transactions on Automatic Control, vol. [sent-285, score-0.185]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('msd', 0.611), ('agents', 0.321), ('steady', 0.186), ('sd', 0.177), ('zk', 0.17), ('pij', 0.161), ('social', 0.149), ('innovation', 0.132), ('agent', 0.109), ('state', 0.104), ('network', 0.102), ('lim', 0.099), ('jadbabaie', 0.099), ('individuals', 0.094), ('regret', 0.09), ('communication', 0.089), ('pii', 0.087), ('friendships', 0.087), ('wm', 0.086), ('vk', 0.078), ('ni', 0.077), ('proposition', 0.077), ('rt', 0.076), ('sensor', 0.076), ('tr', 0.075), ('lcn', 0.074), ('msdkn', 0.074), ('pjj', 0.074), ('private', 0.071), ('st', 0.067), ('edge', 0.064), ('neighbors', 0.063), ('consensus', 0.062), ('estimators', 0.062), ('xt', 0.061), ('hk', 0.059), ('losing', 0.059), ('beliefs', 0.057), ('kf', 0.057), ('communicates', 0.057), ('underlying', 0.055), ('kalman', 0.051), ('lkn', 0.049), ('lsn', 0.049), ('moura', 0.049), ('msdbound', 0.049), ('shahrampour', 0.049), ('tamuz', 0.049), ('distributed', 0.047), ('rm', 0.046), ('communicate', 0.044), ('deviation', 0.044), ('loss', 0.044), ('kar', 0.044), ('riccati', 0.044), ('global', 0.043), ('signal', 0.041), ('underscores', 0.04), ('friendship', 0.04), ('beside', 0.04), ('period', 0.04), ('online', 0.04), ('world', 0.039), ('unbiased', 0.038), ('networks', 0.038), ('change', 0.038), ('averaging', 0.036), ('update', 0.035), ('filter', 0.034), ('prediction', 0.034), ('tight', 0.034), ('rate', 0.033), ('unbiasedness', 0.033), ('interplay', 0.032), ('sequential', 0.032), ('disconnected', 0.031), ('economic', 0.031), ('aim', 0.031), ('gy', 0.03), ('centralized', 0.03), ('rakhlin', 0.03), ('mild', 0.03), ('truth', 0.03), ('ei', 0.03), ('xiao', 0.029), ('jj', 0.029), ('dual', 0.029), ('observation', 0.028), ('connection', 0.028), ('evolves', 0.028), ('bound', 0.028), ('decomposition', 0.028), ('letting', 0.027), ('collective', 0.027), ('cn', 0.027), ('imperfect', 0.027), ('uence', 0.027), ('weight', 0.027), ('processes', 0.026), ('diffusion', 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000006 <a title="228-tfidf-1" href="./nips-2013-Online_Learning_of_Dynamic_Parameters_in_Social_Networks.html">228 nips-2013-Online Learning of Dynamic Parameters in Social Networks</a></p>
<p>Author: Shahin Shahrampour, Sasha Rakhlin, Ali Jadbabaie</p><p>Abstract: This paper addresses the problem of online learning in a dynamic setting. We consider a social network in which each individual observes a private signal about the underlying state of the world and communicates with her neighbors at each time period. Unlike many existing approaches, the underlying state is dynamic, and evolves according to a geometric random walk. We view the scenario as an optimization problem where agents aim to learn the true state while suffering the smallest possible loss. Based on the decomposition of the global loss function, we introduce two update mechanisms, each of which generates an estimate of the true state. We establish a tight bound on the rate of change of the underlying state, under which individuals can track the parameter with a bounded variance. Then, we characterize explicit expressions for the steady state mean-square deviation(MSD) of the estimates from the truth, per individual. We observe that only one of the estimators recovers the optimal MSD, which underscores the impact of the objective function decomposition on the learning quality. Finally, we provide an upper bound on the regret of the proposed methods, measured as an average of errors in estimating the parameter in a ﬁnite time. 1</p><p>2 0.2082223 <a title="228-tfidf-2" href="./nips-2013-Generalized_Random_Utility_Models_with_Multiple_Types.html">129 nips-2013-Generalized Random Utility Models with Multiple Types</a></p>
<p>Author: Hossein Azari Soufiani, Hansheng Diao, Zhenyu Lai, David C. Parkes</p><p>Abstract: We propose a model for demand estimation in multi-agent, differentiated product settings and present an estimation algorithm that uses reversible jump MCMC techniques to classify agents’ types. Our model extends the popular setup in Berry, Levinsohn and Pakes (1995) to allow for the data-driven classiﬁcation of agents’ types using agent-level data. We focus on applications involving data on agents’ ranking over alternatives, and present theoretical conditions that establish the identiﬁability of the model and uni-modality of the likelihood/posterior. Results on both real and simulated data provide support for the scalability of our approach. 1</p><p>3 0.18968703 <a title="228-tfidf-3" href="./nips-2013-A_message-passing_algorithm_for_multi-agent_trajectory_planning.html">16 nips-2013-A message-passing algorithm for multi-agent trajectory planning</a></p>
<p>Author: Jose Bento, Nate Derbinsky, Javier Alonso-Mora, Jonathan S. Yedidia</p><p>Abstract: We describe a novel approach for computing collision-free global trajectories for p agents with speciﬁed initial and ﬁnal conﬁgurations, based on an improved version of the alternating direction method of multipliers (ADMM). Compared with existing methods, our approach is naturally parallelizable and allows for incorporating different cost functionals with only minor adjustments. We apply our method to classical challenging instances and observe that its computational requirements scale well with p for several cost functionals. We also show that a specialization of our algorithm can be used for local motion planning by solving the problem of joint optimization in velocity space. 1</p><p>4 0.1570369 <a title="228-tfidf-4" href="./nips-2013-Point_Based_Value_Iteration_with_Optimal_Belief_Compression_for_Dec-POMDPs.html">248 nips-2013-Point Based Value Iteration with Optimal Belief Compression for Dec-POMDPs</a></p>
<p>Author: Liam C. MacDermed, Charles Isbell</p><p>Abstract: We present four major results towards solving decentralized partially observable Markov decision problems (DecPOMDPs) culminating in an algorithm that outperforms all existing algorithms on all but one standard inﬁnite-horizon benchmark problems. (1) We give an integer program that solves collaborative Bayesian games (CBGs). The program is notable because its linear relaxation is very often integral. (2) We show that a DecPOMDP with bounded belief can be converted to a POMDP (albeit with actions exponential in the number of beliefs). These actions correspond to strategies of a CBG. (3) We present a method to transform any DecPOMDP into a DecPOMDP with bounded beliefs (the number of beliefs is a free parameter) using optimal (not lossless) belief compression. (4) We show that the combination of these results opens the door for new classes of DecPOMDP algorithms based on previous POMDP algorithms. We choose one such algorithm, point-based valued iteration, and modify it to produce the ﬁrst tractable value iteration method for DecPOMDPs that outperforms existing algorithms. 1</p><p>5 0.10476167 <a title="228-tfidf-5" href="./nips-2013-Near-Optimal_Entrywise_Sampling_for_Data_Matrices.html">206 nips-2013-Near-Optimal Entrywise Sampling for Data Matrices</a></p>
<p>Author: Dimitris Achlioptas, Zohar S. Karnin, Edo Liberty</p><p>Abstract: We consider the problem of selecting non-zero entries of a matrix A in order to produce a sparse sketch of it, B, that minimizes A B 2 . For large m n matrices, such that n m (for example, representing n observations over m attributes) we give sampling distributions that exhibit four important properties. First, they have closed forms computable from minimal information regarding A. Second, they allow sketching of matrices whose non-zeros are presented to the algorithm in arbitrary order as a stream, with O 1 computation per non-zero. Third, the resulting sketch matrices are not only sparse, but their non-zero entries are highly compressible. Lastly, and most importantly, under mild assumptions, our distributions are provably competitive with the optimal ofﬂine distribution. Note that the probabilities in the optimal ofﬂine distribution may be complex functions of all the entries in the matrix. Therefore, regardless of computational complexity, the optimal distribution might be impossible to compute in the streaming model. 1</p><p>6 0.098875836 <a title="228-tfidf-6" href="./nips-2013-Reward_Mapping_for_Transfer_in_Long-Lived_Agents.html">278 nips-2013-Reward Mapping for Transfer in Long-Lived Agents</a></p>
<p>7 0.088780515 <a title="228-tfidf-7" href="./nips-2013-Online_Learning_with_Costly_Features_and_Labels.html">230 nips-2013-Online Learning with Costly Features and Labels</a></p>
<p>8 0.087577716 <a title="228-tfidf-8" href="./nips-2013-Matrix_Completion_From_any_Given_Set_of_Observations.html">185 nips-2013-Matrix Completion From any Given Set of Observations</a></p>
<p>9 0.081706397 <a title="228-tfidf-9" href="./nips-2013-Online_Learning_in_Markov_Decision_Processes_with_Adversarially_Chosen_Transition_Probability_Distributions.html">227 nips-2013-Online Learning in Markov Decision Processes with Adversarially Chosen Transition Probability Distributions</a></p>
<p>10 0.078325786 <a title="228-tfidf-10" href="./nips-2013-Learning_and_using_language_via_recursive_pragmatic_reasoning_about_other_agents.html">164 nips-2013-Learning and using language via recursive pragmatic reasoning about other agents</a></p>
<p>11 0.077723503 <a title="228-tfidf-11" href="./nips-2013-High-Dimensional_Gaussian_Process_Bandits.html">137 nips-2013-High-Dimensional Gaussian Process Bandits</a></p>
<p>12 0.074371055 <a title="228-tfidf-12" href="./nips-2013-%28Nearly%29_Optimal_Algorithms_for_Private_Online_Learning_in_Full-information_and_Bandit_Settings.html">2 nips-2013-(Nearly) Optimal Algorithms for Private Online Learning in Full-information and Bandit Settings</a></p>
<p>13 0.073518112 <a title="228-tfidf-13" href="./nips-2013-The_Pareto_Regret_Frontier.html">325 nips-2013-The Pareto Regret Frontier</a></p>
<p>14 0.072676897 <a title="228-tfidf-14" href="./nips-2013-A_multi-agent_control_framework_for_co-adaptation_in_brain-computer_interfaces.html">17 nips-2013-A multi-agent control framework for co-adaptation in brain-computer interfaces</a></p>
<p>15 0.071653374 <a title="228-tfidf-15" href="./nips-2013-Information-theoretic_lower_bounds_for_distributed_statistical_estimation_with_communication_constraints.html">142 nips-2013-Information-theoretic lower bounds for distributed statistical estimation with communication constraints</a></p>
<p>16 0.070639595 <a title="228-tfidf-16" href="./nips-2013-From_Bandits_to_Experts%3A_A_Tale_of_Domination_and_Independence.html">125 nips-2013-From Bandits to Experts: A Tale of Domination and Independence</a></p>
<p>17 0.069076128 <a title="228-tfidf-17" href="./nips-2013-Nonparametric_Multi-group_Membership_Model_for_Dynamic_Networks.html">213 nips-2013-Nonparametric Multi-group Membership Model for Dynamic Networks</a></p>
<p>18 0.068122201 <a title="228-tfidf-18" href="./nips-2013-Recurrent_networks_of_coupled_Winner-Take-All_oscillators_for_solving_constraint_satisfaction_problems.html">267 nips-2013-Recurrent networks of coupled Winner-Take-All oscillators for solving constraint satisfaction problems</a></p>
<p>19 0.067480162 <a title="228-tfidf-19" href="./nips-2013-Efficient_Exploration_and_Value_Function_Generalization_in_Deterministic_Systems.html">103 nips-2013-Efficient Exploration and Value Function Generalization in Deterministic Systems</a></p>
<p>20 0.067474268 <a title="228-tfidf-20" href="./nips-2013-Dimension-Free_Exponentiated_Gradient.html">89 nips-2013-Dimension-Free Exponentiated Gradient</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.198), (1, -0.043), (2, 0.07), (3, -0.032), (4, -0.024), (5, -0.007), (6, 0.042), (7, -0.053), (8, -0.029), (9, 0.003), (10, 0.078), (11, -0.027), (12, 0.066), (13, 0.046), (14, -0.147), (15, 0.176), (16, 0.082), (17, 0.11), (18, 0.086), (19, -0.034), (20, -0.135), (21, -0.129), (22, -0.016), (23, -0.053), (24, -0.126), (25, -0.032), (26, -0.077), (27, 0.09), (28, 0.071), (29, -0.007), (30, -0.038), (31, 0.029), (32, -0.022), (33, -0.145), (34, -0.068), (35, 0.058), (36, 0.088), (37, -0.031), (38, 0.052), (39, 0.074), (40, 0.027), (41, -0.075), (42, -0.056), (43, -0.035), (44, -0.003), (45, -0.059), (46, 0.175), (47, -0.003), (48, -0.041), (49, 0.066)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.91727734 <a title="228-lsi-1" href="./nips-2013-Online_Learning_of_Dynamic_Parameters_in_Social_Networks.html">228 nips-2013-Online Learning of Dynamic Parameters in Social Networks</a></p>
<p>Author: Shahin Shahrampour, Sasha Rakhlin, Ali Jadbabaie</p><p>Abstract: This paper addresses the problem of online learning in a dynamic setting. We consider a social network in which each individual observes a private signal about the underlying state of the world and communicates with her neighbors at each time period. Unlike many existing approaches, the underlying state is dynamic, and evolves according to a geometric random walk. We view the scenario as an optimization problem where agents aim to learn the true state while suffering the smallest possible loss. Based on the decomposition of the global loss function, we introduce two update mechanisms, each of which generates an estimate of the true state. We establish a tight bound on the rate of change of the underlying state, under which individuals can track the parameter with a bounded variance. Then, we characterize explicit expressions for the steady state mean-square deviation(MSD) of the estimates from the truth, per individual. We observe that only one of the estimators recovers the optimal MSD, which underscores the impact of the objective function decomposition on the learning quality. Finally, we provide an upper bound on the regret of the proposed methods, measured as an average of errors in estimating the parameter in a ﬁnite time. 1</p><p>2 0.81553 <a title="228-lsi-2" href="./nips-2013-Generalized_Random_Utility_Models_with_Multiple_Types.html">129 nips-2013-Generalized Random Utility Models with Multiple Types</a></p>
<p>Author: Hossein Azari Soufiani, Hansheng Diao, Zhenyu Lai, David C. Parkes</p><p>Abstract: We propose a model for demand estimation in multi-agent, differentiated product settings and present an estimation algorithm that uses reversible jump MCMC techniques to classify agents’ types. Our model extends the popular setup in Berry, Levinsohn and Pakes (1995) to allow for the data-driven classiﬁcation of agents’ types using agent-level data. We focus on applications involving data on agents’ ranking over alternatives, and present theoretical conditions that establish the identiﬁability of the model and uni-modality of the likelihood/posterior. Results on both real and simulated data provide support for the scalability of our approach. 1</p><p>3 0.72072566 <a title="228-lsi-3" href="./nips-2013-A_message-passing_algorithm_for_multi-agent_trajectory_planning.html">16 nips-2013-A message-passing algorithm for multi-agent trajectory planning</a></p>
<p>Author: Jose Bento, Nate Derbinsky, Javier Alonso-Mora, Jonathan S. Yedidia</p><p>Abstract: We describe a novel approach for computing collision-free global trajectories for p agents with speciﬁed initial and ﬁnal conﬁgurations, based on an improved version of the alternating direction method of multipliers (ADMM). Compared with existing methods, our approach is naturally parallelizable and allows for incorporating different cost functionals with only minor adjustments. We apply our method to classical challenging instances and observe that its computational requirements scale well with p for several cost functionals. We also show that a specialization of our algorithm can be used for local motion planning by solving the problem of joint optimization in velocity space. 1</p><p>4 0.71031356 <a title="228-lsi-4" href="./nips-2013-Point_Based_Value_Iteration_with_Optimal_Belief_Compression_for_Dec-POMDPs.html">248 nips-2013-Point Based Value Iteration with Optimal Belief Compression for Dec-POMDPs</a></p>
<p>Author: Liam C. MacDermed, Charles Isbell</p><p>Abstract: We present four major results towards solving decentralized partially observable Markov decision problems (DecPOMDPs) culminating in an algorithm that outperforms all existing algorithms on all but one standard inﬁnite-horizon benchmark problems. (1) We give an integer program that solves collaborative Bayesian games (CBGs). The program is notable because its linear relaxation is very often integral. (2) We show that a DecPOMDP with bounded belief can be converted to a POMDP (albeit with actions exponential in the number of beliefs). These actions correspond to strategies of a CBG. (3) We present a method to transform any DecPOMDP into a DecPOMDP with bounded beliefs (the number of beliefs is a free parameter) using optimal (not lossless) belief compression. (4) We show that the combination of these results opens the door for new classes of DecPOMDP algorithms based on previous POMDP algorithms. We choose one such algorithm, point-based valued iteration, and modify it to produce the ﬁrst tractable value iteration method for DecPOMDPs that outperforms existing algorithms. 1</p><p>5 0.5414595 <a title="228-lsi-5" href="./nips-2013-Learning_and_using_language_via_recursive_pragmatic_reasoning_about_other_agents.html">164 nips-2013-Learning and using language via recursive pragmatic reasoning about other agents</a></p>
<p>Author: Nathaniel J. Smith, Noah Goodman, Michael Frank</p><p>Abstract: Language users are remarkably good at making inferences about speakers’ intentions in context, and children learning their native language also display substantial skill in acquiring the meanings of unknown words. These two cases are deeply related: Language users invent new terms in conversation, and language learners learn the literal meanings of words based on their pragmatic inferences about how those words are used. While pragmatic inference and word learning have both been independently characterized in probabilistic terms, no current work uniﬁes these two. We describe a model in which language learners assume that they jointly approximate a shared, external lexicon and reason recursively about the goals of others in using this lexicon. This model captures phenomena in word learning and pragmatic inference; it additionally leads to insights about the emergence of communicative systems in conversation and the mechanisms by which pragmatic inferences become incorporated into word meanings. 1</p><p>6 0.46348345 <a title="228-lsi-6" href="./nips-2013-Generalized_Method-of-Moments_for_Rank_Aggregation.html">128 nips-2013-Generalized Method-of-Moments for Rank Aggregation</a></p>
<p>7 0.43027437 <a title="228-lsi-7" href="./nips-2013-Convergence_of_Monte_Carlo_Tree_Search_in_Simultaneous_Move_Games.html">71 nips-2013-Convergence of Monte Carlo Tree Search in Simultaneous Move Games</a></p>
<p>8 0.42079112 <a title="228-lsi-8" href="./nips-2013-Reward_Mapping_for_Transfer_in_Long-Lived_Agents.html">278 nips-2013-Reward Mapping for Transfer in Long-Lived Agents</a></p>
<p>9 0.39805827 <a title="228-lsi-9" href="./nips-2013-Tracking_Time-varying_Graphical_Structure.html">332 nips-2013-Tracking Time-varying Graphical Structure</a></p>
<p>10 0.3849144 <a title="228-lsi-10" href="./nips-2013-Estimation_Bias_in_Multi-Armed_Bandit_Algorithms_for_Search_Advertising.html">112 nips-2013-Estimation Bias in Multi-Armed Bandit Algorithms for Search Advertising</a></p>
<p>11 0.38026252 <a title="228-lsi-11" href="./nips-2013-Message_Passing_Inference_with_Chemical_Reaction_Networks.html">189 nips-2013-Message Passing Inference with Chemical Reaction Networks</a></p>
<p>12 0.36939168 <a title="228-lsi-12" href="./nips-2013-Scalable_Influence_Estimation_in_Continuous-Time_Diffusion_Networks.html">288 nips-2013-Scalable Influence Estimation in Continuous-Time Diffusion Networks</a></p>
<p>13 0.36453655 <a title="228-lsi-13" href="./nips-2013-A_multi-agent_control_framework_for_co-adaptation_in_brain-computer_interfaces.html">17 nips-2013-A multi-agent control framework for co-adaptation in brain-computer interfaces</a></p>
<p>14 0.35545385 <a title="228-lsi-14" href="./nips-2013-Recurrent_networks_of_coupled_Winner-Take-All_oscillators_for_solving_constraint_satisfaction_problems.html">267 nips-2013-Recurrent networks of coupled Winner-Take-All oscillators for solving constraint satisfaction problems</a></p>
<p>15 0.35459644 <a title="228-lsi-15" href="./nips-2013-%28More%29_Efficient_Reinforcement_Learning_via_Posterior_Sampling.html">1 nips-2013-(More) Efficient Reinforcement Learning via Posterior Sampling</a></p>
<p>16 0.35133526 <a title="228-lsi-16" href="./nips-2013-Information-theoretic_lower_bounds_for_distributed_statistical_estimation_with_communication_constraints.html">142 nips-2013-Information-theoretic lower bounds for distributed statistical estimation with communication constraints</a></p>
<p>17 0.34935978 <a title="228-lsi-17" href="./nips-2013-Sinkhorn_Distances%3A_Lightspeed_Computation_of_Optimal_Transport.html">296 nips-2013-Sinkhorn Distances: Lightspeed Computation of Optimal Transport</a></p>
<p>18 0.34729013 <a title="228-lsi-18" href="./nips-2013-Moment-based_Uniform_Deviation_Bounds_for_%24k%24-means_and_Friends.html">197 nips-2013-Moment-based Uniform Deviation Bounds for $k$-means and Friends</a></p>
<p>19 0.34373236 <a title="228-lsi-19" href="./nips-2013-How_to_Hedge_an_Option_Against_an_Adversary%3A_Black-Scholes_Pricing_is_Minimax_Optimal.html">139 nips-2013-How to Hedge an Option Against an Adversary: Black-Scholes Pricing is Minimax Optimal</a></p>
<p>20 0.33849442 <a title="228-lsi-20" href="./nips-2013-Distributed_%24k%24-means_and_%24k%24-median_Clustering_on_General_Topologies.html">94 nips-2013-Distributed $k$-means and $k$-median Clustering on General Topologies</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.026), (16, 0.033), (33, 0.138), (34, 0.107), (41, 0.034), (49, 0.045), (56, 0.129), (60, 0.188), (70, 0.041), (85, 0.061), (89, 0.058), (93, 0.038), (95, 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.93796682 <a title="228-lda-1" href="./nips-2013-Scalable_kernels_for_graphs_with_continuous_attributes.html">289 nips-2013-Scalable kernels for graphs with continuous attributes</a></p>
<p>Author: Aasa Feragen, Niklas Kasenburg, Jens Petersen, Marleen de Bruijne, Karsten Borgwardt</p><p>Abstract: While graphs with continuous node attributes arise in many applications, stateof-the-art graph kernels for comparing continuous-attributed graphs suffer from a high runtime complexity. For instance, the popular shortest path kernel scales as O(n4 ), where n is the number of nodes. In this paper, we present a class of graph kernels with computational complexity O(n2 (m + log n + δ 2 + d)), where δ is the graph diameter, m is the number of edges, and d is the dimension of the node attributes. Due to the sparsity and small diameter of real-world graphs, these kernels typically scale comfortably to large graphs. In our experiments, the presented kernels outperform state-of-the-art kernels in terms of speed and accuracy on classiﬁcation benchmark datasets. 1</p><p>same-paper 2 0.85244793 <a title="228-lda-2" href="./nips-2013-Online_Learning_of_Dynamic_Parameters_in_Social_Networks.html">228 nips-2013-Online Learning of Dynamic Parameters in Social Networks</a></p>
<p>Author: Shahin Shahrampour, Sasha Rakhlin, Ali Jadbabaie</p><p>Abstract: This paper addresses the problem of online learning in a dynamic setting. We consider a social network in which each individual observes a private signal about the underlying state of the world and communicates with her neighbors at each time period. Unlike many existing approaches, the underlying state is dynamic, and evolves according to a geometric random walk. We view the scenario as an optimization problem where agents aim to learn the true state while suffering the smallest possible loss. Based on the decomposition of the global loss function, we introduce two update mechanisms, each of which generates an estimate of the true state. We establish a tight bound on the rate of change of the underlying state, under which individuals can track the parameter with a bounded variance. Then, we characterize explicit expressions for the steady state mean-square deviation(MSD) of the estimates from the truth, per individual. We observe that only one of the estimators recovers the optimal MSD, which underscores the impact of the objective function decomposition on the learning quality. Finally, we provide an upper bound on the regret of the proposed methods, measured as an average of errors in estimating the parameter in a ﬁnite time. 1</p><p>3 0.84081709 <a title="228-lda-3" href="./nips-2013-Scalable_Inference_for_Logistic-Normal_Topic_Models.html">287 nips-2013-Scalable Inference for Logistic-Normal Topic Models</a></p>
<p>Author: Jianfei Chen, June Zhu, Zi Wang, Xun Zheng, Bo Zhang</p><p>Abstract: Logistic-normal topic models can effectively discover correlation structures among latent topics. However, their inference remains a challenge because of the non-conjugacy between the logistic-normal prior and multinomial topic mixing proportions. Existing algorithms either make restricting mean-ﬁeld assumptions or are not scalable to large-scale applications. This paper presents a partially collapsed Gibbs sampling algorithm that approaches the provably correct distribution by exploring the ideas of data augmentation. To improve time efﬁciency, we further present a parallel implementation that can deal with large-scale applications and learn the correlation structures of thousands of topics from millions of documents. Extensive empirical results demonstrate the promise. 1</p><p>4 0.81025052 <a title="228-lda-4" href="./nips-2013-Least_Informative_Dimensions.html">173 nips-2013-Least Informative Dimensions</a></p>
<p>Author: Fabian Sinz, Anna Stockl, January Grewe, January Benda</p><p>Abstract: We present a novel non-parametric method for ﬁnding a subspace of stimulus features that contains all information about the response of a system. Our method generalizes similar approaches to this problem such as spike triggered average, spike triggered covariance, or maximally informative dimensions. Instead of maximizing the mutual information between features and responses directly, we use integral probability metrics in kernel Hilbert spaces to minimize the information between uninformative features and the combination of informative features and responses. Since estimators of these metrics access the data via kernels, are easy to compute, and exhibit good theoretical convergence properties, our method can easily be generalized to populations of neurons or spike patterns. By using a particular expansion of the mutual information, we can show that the informative features must contain all information if we can make the uninformative features independent of the rest. 1</p><p>5 0.77141118 <a title="228-lda-5" href="./nips-2013-Fantope_Projection_and_Selection%3A_A_near-optimal_convex_relaxation_of_sparse_PCA.html">116 nips-2013-Fantope Projection and Selection: A near-optimal convex relaxation of sparse PCA</a></p>
<p>Author: Vincent Q. Vu, Juhee Cho, Jing Lei, Karl Rohe</p><p>Abstract: We propose a novel convex relaxation of sparse principal subspace estimation based on the convex hull of rank-d projection matrices (the Fantope). The convex problem can be solved efﬁciently using alternating direction method of multipliers (ADMM). We establish a near-optimal convergence rate, in terms of the sparsity, ambient dimension, and sample size, for estimation of the principal subspace of a general covariance matrix without assuming the spiked covariance model. In the special case of d = 1, our result implies the near-optimality of DSPCA (d’Aspremont et al. [1]) even when the solution is not rank 1. We also provide a general theoretical framework for analyzing the statistical properties of the method for arbitrary input matrices that extends the applicability and provable guarantees to a wide array of settings. We demonstrate this with an application to Kendall’s tau correlation matrices and transelliptical component analysis. 1</p><p>6 0.76880395 <a title="228-lda-6" href="./nips-2013-Statistical_analysis_of_coupled_time_series_with_Kernel_Cross-Spectral_Density_operators..html">310 nips-2013-Statistical analysis of coupled time series with Kernel Cross-Spectral Density operators.</a></p>
<p>7 0.76858336 <a title="228-lda-7" href="./nips-2013-Robust_Multimodal_Graph_Matching%3A_Sparse_Coding_Meets_Graph_Matching.html">282 nips-2013-Robust Multimodal Graph Matching: Sparse Coding Meets Graph Matching</a></p>
<p>8 0.76648265 <a title="228-lda-8" href="./nips-2013-When_are_Overcomplete_Topic_Models_Identifiable%3F_Uniqueness_of_Tensor_Tucker_Decompositions_with_Structured_Sparsity.html">353 nips-2013-When are Overcomplete Topic Models Identifiable? Uniqueness of Tensor Tucker Decompositions with Structured Sparsity</a></p>
<p>9 0.76423109 <a title="228-lda-9" href="./nips-2013-Polar_Operators_for_Structured_Sparse_Estimation.html">249 nips-2013-Polar Operators for Structured Sparse Estimation</a></p>
<p>10 0.76382935 <a title="228-lda-10" href="./nips-2013-BIG_%26_QUIC%3A_Sparse_Inverse_Covariance_Estimation_for_a_Million_Variables.html">45 nips-2013-BIG & QUIC: Sparse Inverse Covariance Estimation for a Million Variables</a></p>
<p>11 0.7635085 <a title="228-lda-11" href="./nips-2013-Robust_Transfer_Principal_Component_Analysis_with_Rank_Constraints.html">285 nips-2013-Robust Transfer Principal Component Analysis with Rank Constraints</a></p>
<p>12 0.76291132 <a title="228-lda-12" href="./nips-2013-DESPOT%3A_Online_POMDP_Planning_with_Regularization.html">79 nips-2013-DESPOT: Online POMDP Planning with Regularization</a></p>
<p>13 0.76260477 <a title="228-lda-13" href="./nips-2013-Optimal_Neural_Population_Codes_for_High-dimensional_Stimulus_Variables.html">236 nips-2013-Optimal Neural Population Codes for High-dimensional Stimulus Variables</a></p>
<p>14 0.76216614 <a title="228-lda-14" href="./nips-2013-Bayesian_Inference_and_Online_Experimental_Design_for_Mapping_Neural_Microcircuits.html">49 nips-2013-Bayesian Inference and Online Experimental Design for Mapping Neural Microcircuits</a></p>
<p>15 0.76212478 <a title="228-lda-15" href="./nips-2013-Real-Time_Inference_for_a_Gamma_Process_Model_of_Neural_Spiking.html">262 nips-2013-Real-Time Inference for a Gamma Process Model of Neural Spiking</a></p>
<p>16 0.76172942 <a title="228-lda-16" href="./nips-2013-Efficient_Algorithm_for_Privately_Releasing_Smooth_Queries.html">102 nips-2013-Efficient Algorithm for Privately Releasing Smooth Queries</a></p>
<p>17 0.76143193 <a title="228-lda-17" href="./nips-2013-Manifold-based_Similarity_Adaptation_for_Label_Propagation.html">182 nips-2013-Manifold-based Similarity Adaptation for Label Propagation</a></p>
<p>18 0.76132357 <a title="228-lda-18" href="./nips-2013-Online_Robust_PCA_via_Stochastic_Optimization.html">233 nips-2013-Online Robust PCA via Stochastic Optimization</a></p>
<p>19 0.76095009 <a title="228-lda-19" href="./nips-2013-Which_Space_Partitioning_Tree_to_Use_for_Search%3F.html">355 nips-2013-Which Space Partitioning Tree to Use for Search?</a></p>
<p>20 0.76078111 <a title="228-lda-20" href="./nips-2013-EDML_for_Learning_Parameters_in_Directed_and_Undirected_Graphical_Models.html">101 nips-2013-EDML for Learning Parameters in Directed and Undirected Graphical Models</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
