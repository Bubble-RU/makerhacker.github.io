<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>329 nips-2013-Third-Order Edge Statistics: Contour Continuation, Curvature, and Cortical Connections</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-329" href="#">nips2013-329</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>329 nips-2013-Third-Order Edge Statistics: Contour Continuation, Curvature, and Cortical Connections</h1>
<br/><p>Source: <a title="nips-2013-329-pdf" href="http://papers.nips.cc/paper/5194-third-order-edge-statistics-contour-continuation-curvature-and-cortical-connections.pdf">pdf</a></p><p>Author: Matthew Lawlor, Steven W. Zucker</p><p>Abstract: Association ﬁeld models have attempted to explain human contour grouping performance, and to explain the mean frequency of long-range horizontal connections across cortical columns in V1. However, association ﬁelds only depend on the pairwise statistics of edges in natural scenes. We develop a spectral test of the sufﬁciency of pairwise statistics and show there is signiﬁcant higher order structure. An analysis using a probabilistic spectral embedding reveals curvature-dependent components. 1</p><p>Reference: <a title="nips-2013-329-reference" href="../nips2013_reference/nips-2013-Third-Order_Edge_Statistics%3A_Contour_Continuation%2C_Curvature%2C_and_Cortical_Connections_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract Association ﬁeld models have attempted to explain human contour grouping performance, and to explain the mean frequency of long-range horizontal connections across cortical columns in V1. [sent-6, score-0.42]
</p><p>2 However, association ﬁelds only depend on the pairwise statistics of edges in natural scenes. [sent-7, score-0.533]
</p><p>3 We develop a spectral test of the sufﬁciency of pairwise statistics and show there is signiﬁcant higher order structure. [sent-8, score-0.255]
</p><p>4 An analysis using a probabilistic spectral embedding reveals curvature-dependent components. [sent-9, score-0.277]
</p><p>5 Such models are based on evidence of excitatory connections among co-linear and co-circular neurons [5], as well as the presence of co-linearity and co-circularity of edges in natural images [8], [7]. [sent-13, score-0.609]
</p><p>6 Common patterns between excitatory neural connections, co-occurrence statistics, and the geometry of smooth surfaces suggests that the functional and statistical approaches can be linked. [sent-15, score-0.168]
</p><p>7 Statistical questions about edge distributions in natural images have differential geometric analogues, such as the distribution of intrinsic derivatives in natural objects. [sent-16, score-0.559]
</p><p>8 From this perspective, previous studies of natural image statistics have primarily examined “second-order” differential properties of curves; i. [sent-17, score-0.16]
</p><p>9 , the average change in orientation along curve segments in natural scenes. [sent-19, score-0.335]
</p><p>10 The pairwise statistics suggest that curves tend toward co-linearity, in that the (average) change in orientation is small. [sent-20, score-0.488]
</p><p>11 Similarly, for long-range horizontal connections, cells with similar orientation preference tend to be connected to each other. [sent-21, score-0.441]
</p><p>12 From a geometric perspective, do curves in natural scenes exhibit continuity in curvatures, or just in orientation? [sent-23, score-0.199]
</p><p>13 One possibility is to design specialized patterns, such as intensity textures [16], but it is difﬁcult to generalize such results into visual cortex. [sent-27, score-0.173]
</p><p>14 We make use of natural invariances in image statistics to develop a novel spectral technique based on preserving 1  a probabilistic distance. [sent-28, score-0.233]
</p><p>15 This distance characterizes what is beyond association ﬁeld models (discussed next) to reveal the “third-order” structure in edge distributions. [sent-29, score-0.411]
</p><p>16 It has different implications for contours and textures and, more generally, for learning. [sent-30, score-0.162]
</p><p>17 To visualize this distribution, we construct an embedding which reveals likely triplets of edges. [sent-32, score-0.232]
</p><p>18 Following them, we use random variables indicating edges at given locations and orientations. [sent-34, score-0.24]
</p><p>19 More precisely, an edge at position, orientation ri = (xi , yi , θi ), denoted Xri , is a {0, 1} valued random variable. [sent-35, score-0.675]
</p><p>20 Co-occurrence statistics examine various aspects of pairwise marginal distributions, which we denote by P (Xri , Xrj ). [sent-36, score-0.182]
</p><p>21 The image formation process endows scene statistics with a natural translation invariance. [sent-37, score-0.205]
</p><p>22 If the camera were allowed to rotate randomly about the focal axis, natural scene statistics would also have a rotational invariance. [sent-38, score-0.195]
</p><p>23 We can then estimate joint distributions of nearby edges by looking at patches of edges centered at a (position, orientation) location rn and rotating the patch into a canonical orientation and position that we denote r0 . [sent-47, score-0.871]
</p><p>24 These are pairwise statistics of oriented edges in natural images. [sent-57, score-0.576]
</p><p>25 The most important visible feature of these pairwise statistics is that of good continuation: Conditioned on the presence of an edge at the center, edges of similar orientation and horizontally aligned with the edge at the center have high probability. [sent-58, score-1.384]
</p><p>26 We simply interpret them as illustrating the probability (likelihood) of an edge near a horizontal edge at the center position. [sent-62, score-0.812]
</p><p>27 Figure 3: Two approximately equally likely triples of edges under the pairwise independence assumption of Elder et. [sent-63, score-0.601]
</p><p>28 only examining relative orientation with respect to a reference orientation or by explicit rotation of the images. [sent-68, score-0.532]
</p><p>29 It is critical to estimate the degree to which these pairwise statistics characterize the full joint distribution of edges (Fig. [sent-69, score-0.422]
</p><p>30 For example, spin-glass models [15] imply pairwise statistics are sufﬁcient, while Markov random ﬁelds have an order determined by the size of neighborhood cliques. [sent-72, score-0.182]
</p><p>31 3  Contingency Table Analysis  To test whether the joint distribution of edges can be well described by pairwise statistics, we performed a contingency table analysis of edge triples at two different threshold levels from images in the van Hataran database. [sent-73, score-1.06]
</p><p>32 We computed estimated joint distributions for each triple of edges in an 11 × 11 × 8 patch, not constructed to have an edge at the center. [sent-74, score-0.647]
</p><p>33 Using a χ2 test, we computed the probability that each edge triple distribution could occur under hypothesis H0 : {No three way interaction}. [sent-75, score-0.438]
</p><p>34 This is a test of the hypothesis that log P (Xri , Xrj , Xrk ) = f (Xri , Xrj ) + g(Xrj , Xrk ) + h(Xri , Xrk ) for each triple (Xri , Xrj , Xrk ), and includes the cases of independent edges, conditionally independent edges, and other pairwise interactions. [sent-76, score-0.251]
</p><p>35 (The few edge triples for which the null hypothesis cannot be rejected consisted of edges that were spaced very far apart, which are far more likely to be nearly statistically independent of one another. [sent-78, score-0.819]
</p><p>36 ) 3  n = 150705016 percentage of triples where pH0 > . [sent-79, score-0.196]
</p><p>37 (a)  (b)  Figure 4: Example image (a) and edges (b) for statistical analysis. [sent-89, score-0.286]
</p><p>38 Note: color corresponds to orientation To restrict analysis to the statistics of curves, we applied local non-maxima suppression across orientation columns in a direction normal to the given orientation. [sent-90, score-0.657]
</p><p>39 We note that previous studies in pairwise edge statistics have used similar heuristics or hand labeling of edges to eliminate textures. [sent-92, score-0.746]
</p><p>40 The resulting edge maps were subsampled to eliminate statistical dependence due to overlapping ﬁlters. [sent-93, score-0.324]
</p><p>41 Thresholding the edge map yields X : U → {0, 1}, where U ⊂ R2 × S is a discretization of R2 × S. [sent-94, score-0.324]
</p><p>42 We randomly select 21 × 21 × 8 image patches with an oriented edge at the center, and denote these characteristic patches by Vi Since edges are signiﬁcantly less frequent than their absence, we focus on (positive) edge cooccurrence statistics. [sent-96, score-1.134]
</p><p>43 (A small orientation anisotropy has been reported in natural scenes (e. [sent-99, score-0.396]
</p><p>44 , [9]), but does not appear in our data because we effectively averaged over orientations by randomly rotating the images. [sent-101, score-0.177]
</p><p>45 ) We compute the matrix M + where  + Mij = E[Xri Xrj |Yr0 ]  ∼  1 n  n  Vi ViT i=1  Figure 5: Histogram of edge probabilities. [sent-102, score-0.324]
</p><p>46 The threshold to include an edge in M + is p > 0. [sent-103, score-0.354]
</p><p>47 where Vi is a (vectorized) random patch of edges centered around an edge with orientation θi = 0. [sent-105, score-0.868]
</p><p>48 In addition, we only compute pairwise probabilities for edges of high marginal probability (Fig. [sent-106, score-0.409]
</p><p>49 5) 4  5  Visualizing Triples of Edges  By analogy with the pairwise analysis above, we seek to ﬁnd those edge triples that frequently cooccur. [sent-107, score-0.657]
</p><p>50 For pairwise statistics, one simply ﬁxes an edge to lie in the center and “colors” the other edge by the joint probability of the co-occurring pair (Fig. [sent-109, score-0.833]
</p><p>51 Even after conditioning, there are over 12 million edge triples to consider. [sent-112, score-0.52]
</p><p>52 Our trick: Embed edges in a low dimensional space such that the distance between the edges represents the relative likelihood of co-occurrence. [sent-113, score-0.525]
</p><p>53 As before, let Xri be a binary random variable, where Xri = 1 means there is an edge at location ri = (xi , yi , θi ). [sent-115, score-0.409]
</p><p>54 We deﬁne a distance between edges 2 2 2 D+ (ri , rj ) = E[Xri |Yr0 ] − 2E[Xri Xrj |Yr0 ] + E[Xrj |Yr0 ] + + + = Mii − 2Mij + Mjj  The ﬁrst and the last terms represent pairwise co-occurrence probabilities; i. [sent-116, score-0.519]
</p><p>55 Thus this distance is zero if the edges always co-occur in images, given the horizontal edge at the origin, and is large if the pair of edges frequently occur with the horizontal edge but rarely together. [sent-120, score-1.405]
</p><p>56 ) We will now show how, for natural images, edges can be placed in a low dimensional space where the distance in that space will be proportional to this probabilistic distance. [sent-122, score-0.354]
</p><p>57 Deﬁne the spectral embedding Φ : Φ(ri ) = {  xi yi θi  → Rn  λ1 φ1 (i),  λ2 φ2 (i), . [sent-124, score-0.246]
</p><p>58 ,  λn φn (i)}  (1)  The Euclidean distance between embedded points is then Φ(ri ) − Φ(rj )  2  = Φ(ri ), Φ(ri ) − 2 Φ(ri ), Φ(rj ) + Φ(rj ), Φ(rj ) + + + = Mii − 2Mij + Mjj 2 = D+ (ri , rj )  Φ maps edges to points in an embedded space where squared distance is equal to relative probability. [sent-127, score-0.539]
</p><p>59 The usefulness of this embedding comes from the fact that the spectrum of M + decays rapidly (Fig. [sent-128, score-0.218]
</p><p>60 This gives a dramatic reduction in dimensionality, and allows us to visualize the relationship between triples of edges (Fig. [sent-131, score-0.436]
</p><p>61 In particular, a cluster, say, C, of edges in embedding space all have high probability of co-occurring, and the diameter of the cluster d = max D2 (ri , rj ) i,j∈C  bounds the conditional co-occurrence probability of all edges in the cluster. [sent-133, score-0.783]
</p><p>62 Note rapid decay of the spectrum indicating the diffusion distance is well captured by embedding using only the ﬁrst few eigenfunctions. [sent-141, score-0.331]
</p><p>63 Spectral embedding colored by embedding coordinates  0. [sent-142, score-0.421]
</p><p>64 1  Edge map colored by embedding coordinates  φ2  φ3  φ4  Figure 7: Display of third-order edge structure showing how oriented edges are related to their spectral embeddings. [sent-172, score-0.97]
</p><p>65 The eigenvectors of M + are used to color both the edges and the embedding. [sent-176, score-0.284]
</p><p>66 Edges that share colors (coordinates) in all dimensions (φ2 , φ3 , φ4 ) are close in probabilistic distance, which implies they have a high probability of co-occurring along with the edge in the center. [sent-178, score-0.376]
</p><p>67 2 where red edges all have high probability of occurring with the center, but no information is known about their co-occurrence probability. [sent-180, score-0.24]
</p><p>68 Embedding the mapping from R2 × S → Rm reveals the cocircular structure of edge triples in the image data (Fig. [sent-186, score-0.648]
</p><p>69 Under this dimensionality reduction, each small cluster in diffusion space corresponds to half of a cocircular ﬁeld. [sent-189, score-0.152]
</p><p>70 In effect, the coloring by φ2 shows good continuation in orientation (with our crude quantization) while the coloring by φ4 shows co-circular connections. [sent-190, score-0.406]
</p><p>71 To provide a neural interpretation of these results, let each point in R2 × S represent a neuron with a receptive ﬁeld centered at the point (x, y) with preferred orientation θ. [sent-195, score-0.334]
</p><p>72 Each cluster then signiﬁes those neurons that have a high probability of co-ﬁring given that the central neuron ﬁres, so clusters in diffusion coordinates should be “wired” together by the Hebbian postulate. [sent-196, score-0.276]
</p><p>73 Such curvature-based facilitation can explain the non-monotonic variance in excitatory long-range horizontal connections in V1 [3, 4]. [sent-197, score-0.355]
</p><p>74 As clusters of co-circular V1 cells are correlated in their ﬁring, it may be efﬁcient to represent them with a single cell with excitatory feedforward connections. [sent-199, score-0.229]
</p><p>75 7  Implications for Inhibition and Texture  Our approach also has implications beyond excitatory connections for boundary facilitation. [sent-201, score-0.248]
</p><p>76 We repeated our conditional spectral embedding, but now conditioned on the absence of an edge at the center (Fig. [sent-202, score-0.516]
</p><p>77 This could provide a model for inhibition, as clusters of edges in this embedding are likely to co-occur conditioned on the absence of an edge at the center. [sent-204, score-0.915]
</p><p>78 We ﬁnd that the embedding has no natural clustering. [sent-205, score-0.242]
</p><p>79 15  Figure 8: Embeddings conditioned on the absence of an edge at the center location. [sent-221, score-0.443]
</p><p>80 Finally, we repeated this third-order analysis (but without local non-maxima suppression) on a structured model for isotropic textures on 3D surfaces and again found a curvature dependency (Fig. [sent-224, score-0.218]
</p><p>81 Every 3-D surface has a pair of associated dense texture ﬂows in the image plane that correspond to the slant and tilt directions of the surface. [sent-226, score-0.208]
</p><p>82 For isotropic textures, the slant direction corresponds to the most likely orientation signaled by oriented ﬁlters. [sent-227, score-0.475]
</p><p>83 As this is a representation of a dense vector ﬁeld, it is more difﬁcult to interpret than the edge map. [sent-228, score-0.357]
</p><p>84 The resulting clusters show two-sided continuation of the texture ﬂow with a ﬁxed tangential curvature (Fig. [sent-230, score-0.244]
</p><p>85 In summary, then, we have developed a method for revealing third-order orientation structure by spectral methods. [sent-232, score-0.339]
</p><p>86 It is based on a diffusion metric that makes third-order terms explicit, and yields a Euclidean distance measure by which edges can be clustered. [sent-233, score-0.353]
</p><p>87 Given that long-range horizontal connections are consistent with these clusters, how biological learning algorithms converge to them remains an open question. [sent-234, score-0.257]
</p><p>88 (bottom) As before, we looked at the conditional co-occurrence matrices of edge orientations over a series of randomly generated shapes. [sent-273, score-0.449]
</p><p>89 The edge map is thresholded to contain only orientations of high probability. [sent-275, score-0.449]
</p><p>90 The resulting embedding φ(vi ) of those orientations is shown below. [sent-276, score-0.298]
</p><p>91 The eigenvectors of M + are used to color both the orientations and the embedding. [sent-277, score-0.169]
</p><p>92 Clusters of orientations in this embedding have a high probability of co-occurring along with the edge in the center. [sent-278, score-0.622]
</p><p>93 The curve indicator random ﬁeld: Curve organization via edge correlation. [sent-302, score-0.363]
</p><p>94 The independent components of natural scenes are edge ﬁlters. [sent-310, score-0.454]
</p><p>95 Geometrical computations explain projection patterns of longrange horizontal connections in visual cortex. [sent-315, score-0.362]
</p><p>96 Orientation selectivity and the arrangement of horizontal connections in tree shrew striate cortex. [sent-318, score-0.317]
</p><p>97 Emergent properties of layer 2/3 neurons reﬂect the collinear arrangement of horizontal connections in tree shrew visual cortex. [sent-322, score-0.4]
</p><p>98 Edge co-occurrence in natural images predicts contour grouping performance. [sent-334, score-0.213]
</p><p>99 A horizontal bias in human visual processing of orientation and its correspondence to the structural components of natural scenes. [sent-337, score-0.506]
</p><p>100 Independent component ﬁlters of natural images compared with simple cells in primary visual cortex. [sent-343, score-0.251]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('xri', 0.462), ('edge', 0.324), ('xrj', 0.308), ('orientation', 0.266), ('edges', 0.24), ('triples', 0.196), ('embedding', 0.173), ('pairwise', 0.137), ('xrk', 0.125), ('orientations', 0.125), ('textures', 0.118), ('horizontal', 0.116), ('connections', 0.113), ('elder', 0.104), ('rj', 0.097), ('excitatory', 0.091), ('ri', 0.085), ('oriented', 0.085), ('triple', 0.083), ('clusters', 0.079), ('spectral', 0.073), ('natural', 0.069), ('images', 0.068), ('zucker', 0.068), ('slant', 0.068), ('diffusion', 0.068), ('continuation', 0.066), ('scenes', 0.061), ('texture', 0.061), ('cells', 0.059), ('embedded', 0.056), ('ring', 0.056), ('visual', 0.055), ('colors', 0.052), ('rotating', 0.052), ('cocircular', 0.051), ('shrew', 0.051), ('eld', 0.05), ('inhibition', 0.05), ('embeddings', 0.048), ('center', 0.048), ('contour', 0.047), ('image', 0.046), ('cooccurrence', 0.045), ('mjj', 0.045), ('xrn', 0.045), ('statistics', 0.045), ('cortical', 0.045), ('scene', 0.045), ('spectrum', 0.045), ('distance', 0.045), ('color', 0.044), ('implications', 0.044), ('patterns', 0.043), ('association', 0.042), ('haven', 0.042), ('geisler', 0.042), ('mii', 0.042), ('curves', 0.04), ('organization', 0.039), ('william', 0.038), ('coordinates', 0.038), ('patch', 0.038), ('receptive', 0.038), ('curvature', 0.038), ('arrangement', 0.037), ('curved', 0.037), ('coloring', 0.037), ('perceptual', 0.037), ('conditioned', 0.037), ('colored', 0.037), ('suppression', 0.036), ('yale', 0.036), ('rotational', 0.036), ('patches', 0.035), ('explain', 0.035), ('surfaces', 0.034), ('contingency', 0.034), ('vi', 0.034), ('absence', 0.034), ('dense', 0.033), ('cluster', 0.033), ('neuroscience', 0.033), ('probabilities', 0.032), ('lters', 0.032), ('van', 0.031), ('reveals', 0.031), ('hypothesis', 0.031), ('steven', 0.03), ('neuron', 0.03), ('threshold', 0.03), ('grouping', 0.029), ('geometric', 0.029), ('biological', 0.028), ('isotropic', 0.028), ('gabor', 0.028), ('likely', 0.028), ('vision', 0.028), ('neurons', 0.028), ('elds', 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="329-tfidf-1" href="./nips-2013-Third-Order_Edge_Statistics%3A_Contour_Continuation%2C_Curvature%2C_and_Cortical_Connections.html">329 nips-2013-Third-Order Edge Statistics: Contour Continuation, Curvature, and Cortical Connections</a></p>
<p>Author: Matthew Lawlor, Steven W. Zucker</p><p>Abstract: Association ﬁeld models have attempted to explain human contour grouping performance, and to explain the mean frequency of long-range horizontal connections across cortical columns in V1. However, association ﬁelds only depend on the pairwise statistics of edges in natural scenes. We develop a spectral test of the sufﬁciency of pairwise statistics and show there is signiﬁcant higher order structure. An analysis using a probabilistic spectral embedding reveals curvature-dependent components. 1</p><p>2 0.099886209 <a title="329-tfidf-2" href="./nips-2013-Robust_Low_Rank_Kernel_Embeddings_of_Multivariate_Distributions.html">281 nips-2013-Robust Low Rank Kernel Embeddings of Multivariate Distributions</a></p>
<p>Author: Le Song, Bo Dai</p><p>Abstract: Kernel embedding of distributions has led to many recent advances in machine learning. However, latent and low rank structures prevalent in real world distributions have rarely been taken into account in this setting. Furthermore, no prior work in kernel embedding literature has addressed the issue of robust embedding when the latent and low rank information are misspeciﬁed. In this paper, we propose a hierarchical low rank decomposition of kernels embeddings which can exploit such low rank structures in data while being robust to model misspeciﬁcation. We also illustrate with empirical evidence that the estimated low rank embeddings lead to improved performance in density estimation. 1</p><p>3 0.090444475 <a title="329-tfidf-3" href="./nips-2013-Modeling_Clutter_Perception_using_Parametric_Proto-object_Partitioning.html">195 nips-2013-Modeling Clutter Perception using Parametric Proto-object Partitioning</a></p>
<p>Author: Chen-Ping Yu, Wen-Yu Hua, Dimitris Samaras, Greg Zelinsky</p><p>Abstract: Visual clutter, the perception of an image as being crowded and disordered, affects aspects of our lives ranging from object detection to aesthetics, yet relatively little effort has been made to model this important and ubiquitous percept. Our approach models clutter as the number of proto-objects segmented from an image, with proto-objects deﬁned as groupings of superpixels that are similar in intensity, color, and gradient orientation features. We introduce a novel parametric method of clustering superpixels by modeling mixture of Weibulls on Earth Mover’s Distance statistics, then taking the normalized number of proto-objects following partitioning as our estimate of clutter perception. We validated this model using a new 90-image dataset of real world scenes rank ordered by human raters for clutter, and showed that our method not only predicted clutter extremely well (Spearman’s ρ = 0.8038, p < 0.001), but also outperformed all existing clutter perception models and even a behavioral object segmentation ground truth. We conclude that the number of proto-objects in an image affects clutter perception more than the number of objects or features. 1</p><p>4 0.087653272 <a title="329-tfidf-4" href="./nips-2013-Firing_rate_predictions_in_optimal_balanced_networks.html">121 nips-2013-Firing rate predictions in optimal balanced networks</a></p>
<p>Author: David G. Barrett, Sophie Denève, Christian K. Machens</p><p>Abstract: How are ﬁring rates in a spiking network related to neural input, connectivity and network function? This is an important problem because ﬁring rates are a key measure of network activity, in both the study of neural computation and neural network dynamics. However, it is a difﬁcult problem, because the spiking mechanism of individual neurons is highly non-linear, and these individual neurons interact strongly through connectivity. We develop a new technique for calculating ﬁring rates in optimal balanced networks. These are particularly interesting networks because they provide an optimal spike-based signal representation while producing cortex-like spiking activity through a dynamic balance of excitation and inhibition. We can calculate ﬁring rates by treating balanced network dynamics as an algorithm for optimising signal representation. We identify this algorithm and then calculate ﬁring rates by ﬁnding the solution to the algorithm. Our ﬁring rate calculation relates network ﬁring rates directly to network input, connectivity and function. This allows us to explain the function and underlying mechanism of tuning curves in a variety of systems. 1</p><p>5 0.083472513 <a title="329-tfidf-5" href="./nips-2013-Mid-level_Visual_Element_Discovery_as_Discriminative_Mode_Seeking.html">190 nips-2013-Mid-level Visual Element Discovery as Discriminative Mode Seeking</a></p>
<p>Author: Carl Doersch, Abhinav Gupta, Alexei A. Efros</p><p>Abstract: Recent work on mid-level visual representations aims to capture information at the level of complexity higher than typical “visual words”, but lower than full-blown semantic objects. Several approaches [5, 6, 12, 23] have been proposed to discover mid-level visual elements, that are both 1) representative, i.e., frequently occurring within a visual dataset, and 2) visually discriminative. However, the current approaches are rather ad hoc and difﬁcult to analyze and evaluate. In this work, we pose visual element discovery as discriminative mode seeking, drawing connections to the the well-known and well-studied mean-shift algorithm [2, 1, 4, 8]. Given a weakly-labeled image collection, our method discovers visually-coherent patch clusters that are maximally discriminative with respect to the labels. One advantage of our formulation is that it requires only a single pass through the data. We also propose the Purity-Coverage plot as a principled way of experimentally analyzing and evaluating different visual discovery approaches, and compare our method against prior work on the Paris Street View dataset of [5]. We also evaluate our method on the task of scene classiﬁcation, demonstrating state-of-the-art performance on the MIT Scene-67 dataset. 1</p><p>6 0.08200375 <a title="329-tfidf-6" href="./nips-2013-A_Determinantal_Point_Process_Latent_Variable_Model_for_Inhibition_in_Neural_Spiking_Data.html">6 nips-2013-A Determinantal Point Process Latent Variable Model for Inhibition in Neural Spiking Data</a></p>
<p>7 0.077677645 <a title="329-tfidf-7" href="./nips-2013-DeViSE%3A_A_Deep_Visual-Semantic_Embedding_Model.html">81 nips-2013-DeViSE: A Deep Visual-Semantic Embedding Model</a></p>
<p>8 0.077532187 <a title="329-tfidf-8" href="./nips-2013-What_Are_the_Invariant_Occlusive_Components_of_Image_Patches%3F_A_Probabilistic_Generative_Approach.html">351 nips-2013-What Are the Invariant Occlusive Components of Image Patches? A Probabilistic Generative Approach</a></p>
<p>9 0.075823948 <a title="329-tfidf-9" href="./nips-2013-Extracting_regions_of_interest_from_biological_images_with_convolutional_sparse_block_coding.html">114 nips-2013-Extracting regions of interest from biological images with convolutional sparse block coding</a></p>
<p>10 0.067167476 <a title="329-tfidf-10" href="./nips-2013-Projecting_Ising_Model_Parameters_for_Fast_Mixing.html">258 nips-2013-Projecting Ising Model Parameters for Fast Mixing</a></p>
<p>11 0.066959314 <a title="329-tfidf-11" href="./nips-2013-A_Deep_Architecture_for_Matching_Short_Texts.html">5 nips-2013-A Deep Architecture for Matching Short Texts</a></p>
<p>12 0.061896317 <a title="329-tfidf-12" href="./nips-2013-Visual_Concept_Learning%3A_Combining_Machine_Vision_and_Bayesian_Generalization_on_Concept_Hierarchies.html">349 nips-2013-Visual Concept Learning: Combining Machine Vision and Bayesian Generalization on Concept Hierarchies</a></p>
<p>13 0.057702024 <a title="329-tfidf-13" href="./nips-2013-Learning_Chordal_Markov_Networks_by_Constraint_Satisfaction.html">151 nips-2013-Learning Chordal Markov Networks by Constraint Satisfaction</a></p>
<p>14 0.057171233 <a title="329-tfidf-14" href="./nips-2013-Error-Minimizing_Estimates_and_Universal_Entry-Wise_Error_Bounds_for_Low-Rank_Matrix_Completion.html">108 nips-2013-Error-Minimizing Estimates and Universal Entry-Wise Error Bounds for Low-Rank Matrix Completion</a></p>
<p>15 0.05709599 <a title="329-tfidf-15" href="./nips-2013-Learning_invariant_representations_and_applications_to_face_verification.html">166 nips-2013-Learning invariant representations and applications to face verification</a></p>
<p>16 0.056664176 <a title="329-tfidf-16" href="./nips-2013-Scalable_Influence_Estimation_in_Continuous-Time_Diffusion_Networks.html">288 nips-2013-Scalable Influence Estimation in Continuous-Time Diffusion Networks</a></p>
<p>17 0.055879235 <a title="329-tfidf-17" href="./nips-2013-Regularized_Spectral_Clustering_under_the_Degree-Corrected_Stochastic_Blockmodel.html">272 nips-2013-Regularized Spectral Clustering under the Degree-Corrected Stochastic Blockmodel</a></p>
<p>18 0.055188727 <a title="329-tfidf-18" href="./nips-2013-Solving_the_multi-way_matching_problem_by_permutation_synchronization.html">300 nips-2013-Solving the multi-way matching problem by permutation synchronization</a></p>
<p>19 0.054422431 <a title="329-tfidf-19" href="./nips-2013-Translating_Embeddings_for_Modeling_Multi-relational_Data.html">336 nips-2013-Translating Embeddings for Modeling Multi-relational Data</a></p>
<p>20 0.053582739 <a title="329-tfidf-20" href="./nips-2013-Learning_the_Local_Statistics_of_Optical_Flow.html">167 nips-2013-Learning the Local Statistics of Optical Flow</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.15), (1, 0.076), (2, -0.072), (3, -0.03), (4, -0.01), (5, -0.027), (6, 0.011), (7, -0.059), (8, -0.026), (9, 0.047), (10, -0.057), (11, -0.061), (12, 0.063), (13, -0.009), (14, 0.053), (15, 0.06), (16, -0.026), (17, -0.047), (18, -0.07), (19, 0.013), (20, 0.044), (21, -0.019), (22, 0.003), (23, -0.036), (24, -0.094), (25, -0.01), (26, 0.057), (27, 0.039), (28, 0.044), (29, 0.013), (30, -0.026), (31, -0.042), (32, 0.096), (33, 0.011), (34, -0.102), (35, 0.009), (36, 0.057), (37, 0.02), (38, 0.022), (39, 0.001), (40, -0.021), (41, -0.036), (42, -0.057), (43, -0.033), (44, -0.013), (45, -0.021), (46, -0.044), (47, 0.019), (48, 0.053), (49, -0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9629274 <a title="329-lsi-1" href="./nips-2013-Third-Order_Edge_Statistics%3A_Contour_Continuation%2C_Curvature%2C_and_Cortical_Connections.html">329 nips-2013-Third-Order Edge Statistics: Contour Continuation, Curvature, and Cortical Connections</a></p>
<p>Author: Matthew Lawlor, Steven W. Zucker</p><p>Abstract: Association ﬁeld models have attempted to explain human contour grouping performance, and to explain the mean frequency of long-range horizontal connections across cortical columns in V1. However, association ﬁelds only depend on the pairwise statistics of edges in natural scenes. We develop a spectral test of the sufﬁciency of pairwise statistics and show there is signiﬁcant higher order structure. An analysis using a probabilistic spectral embedding reveals curvature-dependent components. 1</p><p>2 0.62973452 <a title="329-lsi-2" href="./nips-2013-What_Are_the_Invariant_Occlusive_Components_of_Image_Patches%3F_A_Probabilistic_Generative_Approach.html">351 nips-2013-What Are the Invariant Occlusive Components of Image Patches? A Probabilistic Generative Approach</a></p>
<p>Author: Zhenwen Dai, Georgios Exarchakis, Jörg Lücke</p><p>Abstract: We study optimal image encoding based on a generative approach with non-linear feature combinations and explicit position encoding. By far most approaches to unsupervised learning of visual features, such as sparse coding or ICA, account for translations by representing the same features at different positions. Some earlier models used a separate encoding of features and their positions to facilitate invariant data encoding and recognition. All probabilistic generative models with explicit position encoding have so far assumed a linear superposition of components to encode image patches. Here, we for the ﬁrst time apply a model with non-linear feature superposition and explicit position encoding for patches. By avoiding linear superpositions, the studied model represents a closer match to component occlusions which are ubiquitous in natural images. In order to account for occlusions, the non-linear model encodes patches qualitatively very different from linear models by using component representations separated into mask and feature parameters. We ﬁrst investigated encodings learned by the model using artiﬁcial data with mutually occluding components. We ﬁnd that the model extracts the components, and that it can correctly identify the occlusive components with the hidden variables of the model. On natural image patches, the model learns component masks and features for typical image components. By using reverse correlation, we estimate the receptive ﬁelds associated with the model’s hidden units. We ﬁnd many Gabor-like or globular receptive ﬁelds as well as ﬁelds sensitive to more complex structures. Our results show that probabilistic models that capture occlusions and invariances can be trained efﬁciently on image patches, and that the resulting encoding represents an alternative model for the neural encoding of images in the primary visual cortex. 1</p><p>3 0.61883783 <a title="329-lsi-3" href="./nips-2013-Mid-level_Visual_Element_Discovery_as_Discriminative_Mode_Seeking.html">190 nips-2013-Mid-level Visual Element Discovery as Discriminative Mode Seeking</a></p>
<p>Author: Carl Doersch, Abhinav Gupta, Alexei A. Efros</p><p>Abstract: Recent work on mid-level visual representations aims to capture information at the level of complexity higher than typical “visual words”, but lower than full-blown semantic objects. Several approaches [5, 6, 12, 23] have been proposed to discover mid-level visual elements, that are both 1) representative, i.e., frequently occurring within a visual dataset, and 2) visually discriminative. However, the current approaches are rather ad hoc and difﬁcult to analyze and evaluate. In this work, we pose visual element discovery as discriminative mode seeking, drawing connections to the the well-known and well-studied mean-shift algorithm [2, 1, 4, 8]. Given a weakly-labeled image collection, our method discovers visually-coherent patch clusters that are maximally discriminative with respect to the labels. One advantage of our formulation is that it requires only a single pass through the data. We also propose the Purity-Coverage plot as a principled way of experimentally analyzing and evaluating different visual discovery approaches, and compare our method against prior work on the Paris Street View dataset of [5]. We also evaluate our method on the task of scene classiﬁcation, demonstrating state-of-the-art performance on the MIT Scene-67 dataset. 1</p><p>4 0.61655664 <a title="329-lsi-4" href="./nips-2013-Modeling_Clutter_Perception_using_Parametric_Proto-object_Partitioning.html">195 nips-2013-Modeling Clutter Perception using Parametric Proto-object Partitioning</a></p>
<p>Author: Chen-Ping Yu, Wen-Yu Hua, Dimitris Samaras, Greg Zelinsky</p><p>Abstract: Visual clutter, the perception of an image as being crowded and disordered, affects aspects of our lives ranging from object detection to aesthetics, yet relatively little effort has been made to model this important and ubiquitous percept. Our approach models clutter as the number of proto-objects segmented from an image, with proto-objects deﬁned as groupings of superpixels that are similar in intensity, color, and gradient orientation features. We introduce a novel parametric method of clustering superpixels by modeling mixture of Weibulls on Earth Mover’s Distance statistics, then taking the normalized number of proto-objects following partitioning as our estimate of clutter perception. We validated this model using a new 90-image dataset of real world scenes rank ordered by human raters for clutter, and showed that our method not only predicted clutter extremely well (Spearman’s ρ = 0.8038, p < 0.001), but also outperformed all existing clutter perception models and even a behavioral object segmentation ground truth. We conclude that the number of proto-objects in an image affects clutter perception more than the number of objects or features. 1</p><p>5 0.58328897 <a title="329-lsi-5" href="./nips-2013-Learning_the_Local_Statistics_of_Optical_Flow.html">167 nips-2013-Learning the Local Statistics of Optical Flow</a></p>
<p>Author: Dan Rosenbaum, Daniel Zoran, Yair Weiss</p><p>Abstract: Motivated by recent progress in natural image statistics, we use newly available datasets with ground truth optical ﬂow to learn the local statistics of optical ﬂow and compare the learned models to prior models assumed by computer vision researchers. We ﬁnd that a Gaussian mixture model (GMM) with 64 components provides a signiﬁcantly better model for local ﬂow statistics when compared to commonly used models. We investigate the source of the GMM’s success and show it is related to an explicit representation of ﬂow boundaries. We also learn a model that jointly models the local intensity pattern and the local optical ﬂow. In accordance with the assumptions often made in computer vision, the model learns that ﬂow boundaries are more likely at intensity boundaries. However, when evaluated on a large dataset, this dependency is very weak and the beneﬁt of conditioning ﬂow estimation on the local intensity pattern is marginal. 1</p><p>6 0.55451602 <a title="329-lsi-6" href="./nips-2013-Extracting_regions_of_interest_from_biological_images_with_convolutional_sparse_block_coding.html">114 nips-2013-Extracting regions of interest from biological images with convolutional sparse block coding</a></p>
<p>7 0.54132998 <a title="329-lsi-7" href="./nips-2013-Manifold-based_Similarity_Adaptation_for_Label_Propagation.html">182 nips-2013-Manifold-based Similarity Adaptation for Label Propagation</a></p>
<p>8 0.52622026 <a title="329-lsi-8" href="./nips-2013-Non-Uniform_Camera_Shake_Removal_Using_a_Spatially-Adaptive_Sparse_Penalty.html">212 nips-2013-Non-Uniform Camera Shake Removal Using a Spatially-Adaptive Sparse Penalty</a></p>
<p>9 0.52424955 <a title="329-lsi-9" href="./nips-2013-Approximate_Bayesian_Image_Interpretation_using_Generative_Probabilistic_Graphics_Programs.html">37 nips-2013-Approximate Bayesian Image Interpretation using Generative Probabilistic Graphics Programs</a></p>
<p>10 0.49776682 <a title="329-lsi-10" href="./nips-2013-Hierarchical_Modular_Optimization_of_Convolutional_Networks_Achieves_Representations_Similar_to_Macaque_IT_and_Human_Ventral_Stream.html">136 nips-2013-Hierarchical Modular Optimization of Convolutional Networks Achieves Representations Similar to Macaque IT and Human Ventral Stream</a></p>
<p>11 0.48944581 <a title="329-lsi-11" href="./nips-2013-Higher_Order_Priors_for_Joint_Intrinsic_Image%2C_Objects%2C_and_Attributes_Estimation.html">138 nips-2013-Higher Order Priors for Joint Intrinsic Image, Objects, and Attributes Estimation</a></p>
<p>12 0.48929211 <a title="329-lsi-12" href="./nips-2013-Near-optimal_Anomaly_Detection_in_Graphs_using_Lovasz_Extended_Scan_Statistic.html">207 nips-2013-Near-optimal Anomaly Detection in Graphs using Lovasz Extended Scan Statistic</a></p>
<p>13 0.48922148 <a title="329-lsi-13" href="./nips-2013-Density_estimation_from_unweighted_k-nearest_neighbor_graphs%3A_a_roadmap.html">87 nips-2013-Density estimation from unweighted k-nearest neighbor graphs: a roadmap</a></p>
<p>14 0.48910505 <a title="329-lsi-14" href="./nips-2013-Learning_invariant_representations_and_applications_to_face_verification.html">166 nips-2013-Learning invariant representations and applications to face verification</a></p>
<p>15 0.48815104 <a title="329-lsi-15" href="./nips-2013-Wavelets_on_Graphs_via_Deep_Learning.html">350 nips-2013-Wavelets on Graphs via Deep Learning</a></p>
<p>16 0.48138309 <a title="329-lsi-16" href="./nips-2013-Tracking_Time-varying_Graphical_Structure.html">332 nips-2013-Tracking Time-varying Graphical Structure</a></p>
<p>17 0.47542399 <a title="329-lsi-17" href="./nips-2013-Robust_Low_Rank_Kernel_Embeddings_of_Multivariate_Distributions.html">281 nips-2013-Robust Low Rank Kernel Embeddings of Multivariate Distributions</a></p>
<p>18 0.47508919 <a title="329-lsi-18" href="./nips-2013-Learning_with_Invariance_via_Linear_Functionals_on_Reproducing_Kernel_Hilbert_Space.html">170 nips-2013-Learning with Invariance via Linear Functionals on Reproducing Kernel Hilbert Space</a></p>
<p>19 0.46729749 <a title="329-lsi-19" href="./nips-2013-Translating_Embeddings_for_Modeling_Multi-relational_Data.html">336 nips-2013-Translating Embeddings for Modeling Multi-relational Data</a></p>
<p>20 0.46409276 <a title="329-lsi-20" href="./nips-2013-One-shot_learning_by_inverting_a_compositional_causal_process.html">226 nips-2013-One-shot learning by inverting a compositional causal process</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.019), (14, 0.228), (16, 0.06), (33, 0.159), (34, 0.117), (41, 0.03), (49, 0.047), (56, 0.083), (70, 0.058), (85, 0.048), (89, 0.036), (93, 0.021), (95, 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.850115 <a title="329-lda-1" href="./nips-2013-Third-Order_Edge_Statistics%3A_Contour_Continuation%2C_Curvature%2C_and_Cortical_Connections.html">329 nips-2013-Third-Order Edge Statistics: Contour Continuation, Curvature, and Cortical Connections</a></p>
<p>Author: Matthew Lawlor, Steven W. Zucker</p><p>Abstract: Association ﬁeld models have attempted to explain human contour grouping performance, and to explain the mean frequency of long-range horizontal connections across cortical columns in V1. However, association ﬁelds only depend on the pairwise statistics of edges in natural scenes. We develop a spectral test of the sufﬁciency of pairwise statistics and show there is signiﬁcant higher order structure. An analysis using a probabilistic spectral embedding reveals curvature-dependent components. 1</p><p>2 0.82143062 <a title="329-lda-2" href="./nips-2013-Stochastic_blockmodel_approximation_of_a_graphon%3A_Theory_and_consistent_estimation.html">316 nips-2013-Stochastic blockmodel approximation of a graphon: Theory and consistent estimation</a></p>
<p>Author: Edoardo M. Airoldi, Thiago B. Costa, Stanley H. Chan</p><p>Abstract: Non-parametric approaches for analyzing network data based on exchangeable graph models (ExGM) have recently gained interest. The key object that deﬁnes an ExGM is often referred to as a graphon. This non-parametric perspective on network modeling poses challenging questions on how to make inference on the graphon underlying observed network data. In this paper, we propose a computationally efﬁcient procedure to estimate a graphon from a set of observed networks generated from it. This procedure is based on a stochastic blockmodel approximation (SBA) of the graphon. We show that, by approximating the graphon with a stochastic block model, the graphon can be consistently estimated, that is, the estimation error vanishes as the size of the graph approaches inﬁnity.</p><p>3 0.76415193 <a title="329-lda-3" href="./nips-2013-Visual_Concept_Learning%3A_Combining_Machine_Vision_and_Bayesian_Generalization_on_Concept_Hierarchies.html">349 nips-2013-Visual Concept Learning: Combining Machine Vision and Bayesian Generalization on Concept Hierarchies</a></p>
<p>Author: Yangqing Jia, Joshua T. Abbott, Joseph Austerweil, Thomas Griffiths, Trevor Darrell</p><p>Abstract: Learning a visual concept from a small number of positive examples is a significant challenge for machine learning algorithms. Current methods typically fail to ﬁnd the appropriate level of generalization in a concept hierarchy for a given set of visual examples. Recent work in cognitive science on Bayesian models of generalization addresses this challenge, but prior results assumed that objects were perfectly recognized. We present an algorithm for learning visual concepts directly from images, using probabilistic predictions generated by visual classiﬁers as the input to a Bayesian generalization model. As no existing challenge data tests this paradigm, we collect and make available a new, large-scale dataset for visual concept learning using the ImageNet hierarchy as the source of possible concepts, with human annotators to provide ground truth labels as to whether a new image is an instance of each concept using a paradigm similar to that used in experiments studying word learning in children. We compare the performance of our system to several baseline algorithms, and show a signiﬁcant advantage results from combining visual classiﬁers with the ability to identify an appropriate level of abstraction using Bayesian generalization. 1</p><p>4 0.70960176 <a title="329-lda-4" href="./nips-2013-Bayesian_Inference_and_Online_Experimental_Design_for_Mapping_Neural_Microcircuits.html">49 nips-2013-Bayesian Inference and Online Experimental Design for Mapping Neural Microcircuits</a></p>
<p>Author: Ben Shababo, Brooks Paige, Ari Pakman, Liam Paninski</p><p>Abstract: With the advent of modern stimulation techniques in neuroscience, the opportunity arises to map neuron to neuron connectivity. In this work, we develop a method for efﬁciently inferring posterior distributions over synaptic strengths in neural microcircuits. The input to our algorithm is data from experiments in which action potentials from putative presynaptic neurons can be evoked while a subthreshold recording is made from a single postsynaptic neuron. We present a realistic statistical model which accounts for the main sources of variability in this experiment and allows for signiﬁcant prior information about the connectivity and neuronal cell types to be incorporated if available. Due to the technical challenges and sparsity of these systems, it is important to focus experimental time stimulating the neurons whose synaptic strength is most ambiguous, therefore we also develop an online optimal design algorithm for choosing which neurons to stimulate at each trial. 1</p><p>5 0.70896745 <a title="329-lda-5" href="./nips-2013-Real-Time_Inference_for_a_Gamma_Process_Model_of_Neural_Spiking.html">262 nips-2013-Real-Time Inference for a Gamma Process Model of Neural Spiking</a></p>
<p>Author: David Carlson, Vinayak Rao, Joshua T. Vogelstein, Lawrence Carin</p><p>Abstract: With simultaneous measurements from ever increasing populations of neurons, there is a growing need for sophisticated tools to recover signals from individual neurons. In electrophysiology experiments, this classically proceeds in a two-step process: (i) threshold the waveforms to detect putative spikes and (ii) cluster the waveforms into single units (neurons). We extend previous Bayesian nonparametric models of neural spiking to jointly detect and cluster neurons using a Gamma process model. Importantly, we develop an online approximate inference scheme enabling real-time analysis, with performance exceeding the previous state-of-theart. Via exploratory data analysis—using data with partial ground truth as well as two novel data sets—we ﬁnd several features of our model collectively contribute to our improved performance including: (i) accounting for colored noise, (ii) detecting overlapping spikes, (iii) tracking waveform dynamics, and (iv) using multiple channels. We hope to enable novel experiments simultaneously measuring many thousands of neurons and possibly adapting stimuli dynamically to probe ever deeper into the mysteries of the brain. 1</p><p>6 0.70652252 <a title="329-lda-6" href="./nips-2013-Least_Informative_Dimensions.html">173 nips-2013-Least Informative Dimensions</a></p>
<p>7 0.70583767 <a title="329-lda-7" href="./nips-2013-Wavelets_on_Graphs_via_Deep_Learning.html">350 nips-2013-Wavelets on Graphs via Deep Learning</a></p>
<p>8 0.70448595 <a title="329-lda-8" href="./nips-2013-Robust_learning_of_low-dimensional_dynamics_from_large_neural_ensembles.html">286 nips-2013-Robust learning of low-dimensional dynamics from large neural ensembles</a></p>
<p>9 0.70349079 <a title="329-lda-9" href="./nips-2013-Inferring_neural_population_dynamics_from_multiple_partial_recordings_of_the_same_neural_circuit.html">141 nips-2013-Inferring neural population dynamics from multiple partial recordings of the same neural circuit</a></p>
<p>10 0.69996864 <a title="329-lda-10" href="./nips-2013-Optimal_Neural_Population_Codes_for_High-dimensional_Stimulus_Variables.html">236 nips-2013-Optimal Neural Population Codes for High-dimensional Stimulus Variables</a></p>
<p>11 0.69838381 <a title="329-lda-11" href="./nips-2013-Extracting_regions_of_interest_from_biological_images_with_convolutional_sparse_block_coding.html">114 nips-2013-Extracting regions of interest from biological images with convolutional sparse block coding</a></p>
<p>12 0.69818074 <a title="329-lda-12" href="./nips-2013-Auxiliary-variable_Exact_Hamiltonian_Monte_Carlo_Samplers_for_Binary_Distributions.html">43 nips-2013-Auxiliary-variable Exact Hamiltonian Monte Carlo Samplers for Binary Distributions</a></p>
<p>13 0.69792002 <a title="329-lda-13" href="./nips-2013-Sparse_nonnegative_deconvolution_for_compressive_calcium_imaging%3A_algorithms_and_phase_transitions.html">304 nips-2013-Sparse nonnegative deconvolution for compressive calcium imaging: algorithms and phase transitions</a></p>
<p>14 0.69648784 <a title="329-lda-14" href="./nips-2013-Firing_rate_predictions_in_optimal_balanced_networks.html">121 nips-2013-Firing rate predictions in optimal balanced networks</a></p>
<p>15 0.696459 <a title="329-lda-15" href="./nips-2013-Multi-Task_Bayesian_Optimization.html">201 nips-2013-Multi-Task Bayesian Optimization</a></p>
<p>16 0.69607794 <a title="329-lda-16" href="./nips-2013-Similarity_Component_Analysis.html">294 nips-2013-Similarity Component Analysis</a></p>
<p>17 0.69563508 <a title="329-lda-17" href="./nips-2013-Bayesian_inference_for_low_rank_spatiotemporal_neural_receptive_fields.html">53 nips-2013-Bayesian inference for low rank spatiotemporal neural receptive fields</a></p>
<p>18 0.69546783 <a title="329-lda-18" href="./nips-2013-Action_is_in_the_Eye_of_the_Beholder%3A_Eye-gaze_Driven_Model_for_Spatio-Temporal_Action_Localization.html">22 nips-2013-Action is in the Eye of the Beholder: Eye-gaze Driven Model for Spatio-Temporal Action Localization</a></p>
<p>19 0.6954239 <a title="329-lda-19" href="./nips-2013-Correlations_strike_back_%28again%29%3A_the_case_of_associative_memory_retrieval.html">77 nips-2013-Correlations strike back (again): the case of associative memory retrieval</a></p>
<p>20 0.69465625 <a title="329-lda-20" href="./nips-2013-Memoized_Online_Variational_Inference_for_Dirichlet_Process_Mixture_Models.html">187 nips-2013-Memoized Online Variational Inference for Dirichlet Process Mixture Models</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
