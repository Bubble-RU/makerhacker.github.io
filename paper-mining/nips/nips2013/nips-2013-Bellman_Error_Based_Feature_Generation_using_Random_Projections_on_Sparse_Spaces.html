<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>55 nips-2013-Bellman Error Based Feature Generation using Random Projections on Sparse Spaces</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-55" href="#">nips2013-55</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>55 nips-2013-Bellman Error Based Feature Generation using Random Projections on Sparse Spaces</h1>
<br/><p>Source: <a title="nips-2013-55-pdf" href="http://papers.nips.cc/paper/5182-bellman-error-based-feature-generation-using-random-projections-on-sparse-spaces.pdf">pdf</a></p><p>Author: Mahdi Milani Fard, Yuri Grinberg, Amir massoud Farahmand, Joelle Pineau, Doina Precup</p><p>Abstract: This paper addresses the problem of automatic generation of features for value function approximation in reinforcement learning. Bellman Error Basis Functions (BEBFs) have been shown to improve policy evaluation, with a convergence rate similar to that of value iteration. We propose a simple, fast and robust algorithm based on random projections, which generates BEBFs for sparse feature spaces. We provide a Ô¨Ånite sample analysis of the proposed method, and prove that projections logarithmic in the dimension of the original space guarantee a contraction in the error. Empirical results demonstrate the strength of this method in domains in which choosing a good state representation is challenging. 1</p><p>Reference: <a title="nips-2013-55-reference" href="../nips2013_reference/nips-2013-Bellman_Error_Based_Feature_Generation_using_Random_Projections_on_Sparse_Spaces_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('bebf', 0.514), ('bellm', 0.336), ('lstd', 0.302), ('scbebf', 0.294), ('cbebf', 0.245), ('compress', 0.205), ('policy', 0.172), ('project', 0.154), ('feat', 0.152), ('clstd', 0.147), ('nrpe', 0.147), ('helicopt', 0.108), ('prj', 0.098), ('rl', 0.089), ('eqn', 0.086), ('xt', 0.084), ('reinforc', 0.082), ('ghavamzadeh', 0.077), ('fard', 0.073), ('grinberg', 0.073)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999952 <a title="55-tfidf-1" href="./nips-2013-Bellman_Error_Based_Feature_Generation_using_Random_Projections_on_Sparse_Spaces.html">55 nips-2013-Bellman Error Based Feature Generation using Random Projections on Sparse Spaces</a></p>
<p>2 0.20402543 <a title="55-tfidf-2" href="./nips-2013-Symbolic_Opportunistic_Policy_Iteration_for_Factored-Action_MDPs.html">322 nips-2013-Symbolic Opportunistic Policy Iteration for Factored-Action MDPs</a></p>
<p>3 0.18873449 <a title="55-tfidf-3" href="./nips-2013-Adaptive_Step-Size_for_Policy_Gradient_Methods.html">28 nips-2013-Adaptive Step-Size for Policy Gradient Methods</a></p>
<p>4 0.18511918 <a title="55-tfidf-4" href="./nips-2013-Compressive_Feature_Learning.html">65 nips-2013-Compressive Feature Learning</a></p>
<p>5 0.18379143 <a title="55-tfidf-5" href="./nips-2013-Optimistic_policy_iteration_and_natural_actor-critic%3A_A_unifying_view_and_a_non-optimality_result.html">239 nips-2013-Optimistic policy iteration and natural actor-critic: A unifying view and a non-optimality result</a></p>
<p>6 0.16639006 <a title="55-tfidf-6" href="./nips-2013-Learning_Adaptive_Value_of_Information_for_Structured_Prediction.html">150 nips-2013-Learning Adaptive Value of Information for Structured Prediction</a></p>
<p>7 0.16457826 <a title="55-tfidf-7" href="./nips-2013-Actor-Critic_Algorithms_for_Risk-Sensitive_MDPs.html">24 nips-2013-Actor-Critic Algorithms for Risk-Sensitive MDPs</a></p>
<p>8 0.15625098 <a title="55-tfidf-8" href="./nips-2013-Learning_from_Limited_Demonstrations.html">165 nips-2013-Learning from Limited Demonstrations</a></p>
<p>9 0.15084648 <a title="55-tfidf-9" href="./nips-2013-Variational_Policy_Search_via_Trajectory_Optimization.html">348 nips-2013-Variational Policy Search via Trajectory Optimization</a></p>
<p>10 0.12970223 <a title="55-tfidf-10" href="./nips-2013-Optimizing_Instructional_Policies.html">241 nips-2013-Optimizing Instructional Policies</a></p>
<p>11 0.12477013 <a title="55-tfidf-11" href="./nips-2013-Online_Learning_in_Markov_Decision_Processes_with_Adversarially_Chosen_Transition_Probability_Distributions.html">227 nips-2013-Online Learning in Markov Decision Processes with Adversarially Chosen Transition Probability Distributions</a></p>
<p>12 0.12175461 <a title="55-tfidf-12" href="./nips-2013-Projected_Natural_Actor-Critic.html">257 nips-2013-Projected Natural Actor-Critic</a></p>
<p>13 0.11216658 <a title="55-tfidf-13" href="./nips-2013-Variational_Planning_for_Graph-based_MDPs.html">347 nips-2013-Variational Planning for Graph-based MDPs</a></p>
<p>14 0.10757939 <a title="55-tfidf-14" href="./nips-2013-Reinforcement_Learning_in_Robust_Markov_Decision_Processes.html">273 nips-2013-Reinforcement Learning in Robust Markov Decision Processes</a></p>
<p>15 0.10021314 <a title="55-tfidf-15" href="./nips-2013-Improved_and_Generalized_Upper_Bounds_on_the_Complexity_of_Policy_Iteration.html">140 nips-2013-Improved and Generalized Upper Bounds on the Complexity of Policy Iteration</a></p>
<p>16 0.09873917 <a title="55-tfidf-16" href="./nips-2013-%28More%29_Efficient_Reinforcement_Learning_via_Posterior_Sampling.html">1 nips-2013-(More) Efficient Reinforcement Learning via Posterior Sampling</a></p>
<p>17 0.094997026 <a title="55-tfidf-17" href="./nips-2013-DESPOT%3A_Online_POMDP_Planning_with_Regularization.html">79 nips-2013-DESPOT: Online POMDP Planning with Regularization</a></p>
<p>18 0.089039847 <a title="55-tfidf-18" href="./nips-2013-Sparse_nonnegative_deconvolution_for_compressive_calcium_imaging%3A_algorithms_and_phase_transitions.html">304 nips-2013-Sparse nonnegative deconvolution for compressive calcium imaging: algorithms and phase transitions</a></p>
<p>19 0.08657781 <a title="55-tfidf-19" href="./nips-2013-Reward_Mapping_for_Transfer_in_Long-Lived_Agents.html">278 nips-2013-Reward Mapping for Transfer in Long-Lived Agents</a></p>
<p>20 0.086194001 <a title="55-tfidf-20" href="./nips-2013-Bayesian_Mixture_Modelling_and_Inference_based_Thompson_Sampling_in_Monte-Carlo_Tree_Search.html">50 nips-2013-Bayesian Mixture Modelling and Inference based Thompson Sampling in Monte-Carlo Tree Search</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.222), (1, -0.172), (2, -0.055), (3, -0.083), (4, 0.012), (5, 0.063), (6, -0.096), (7, -0.075), (8, 0.008), (9, 0.034), (10, -0.001), (11, 0.007), (12, -0.022), (13, 0.011), (14, -0.013), (15, -0.02), (16, -0.013), (17, 0.011), (18, -0.022), (19, 0.053), (20, -0.04), (21, 0.025), (22, -0.031), (23, -0.007), (24, -0.03), (25, 0.06), (26, -0.025), (27, -0.008), (28, -0.016), (29, 0.024), (30, 0.08), (31, -0.032), (32, 0.098), (33, -0.096), (34, 0.033), (35, -0.055), (36, 0.07), (37, -0.049), (38, 0.068), (39, -0.099), (40, 0.086), (41, -0.015), (42, 0.087), (43, -0.014), (44, -0.013), (45, 0.081), (46, 0.001), (47, -0.085), (48, 0.002), (49, 0.03)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.87281895 <a title="55-lsi-1" href="./nips-2013-Bellman_Error_Based_Feature_Generation_using_Random_Projections_on_Sparse_Spaces.html">55 nips-2013-Bellman Error Based Feature Generation using Random Projections on Sparse Spaces</a></p>
<p>2 0.72279602 <a title="55-lsi-2" href="./nips-2013-Symbolic_Opportunistic_Policy_Iteration_for_Factored-Action_MDPs.html">322 nips-2013-Symbolic Opportunistic Policy Iteration for Factored-Action MDPs</a></p>
<p>3 0.71093231 <a title="55-lsi-3" href="./nips-2013-Approximate_Dynamic_Programming_Finally_Performs_Well_in_the_Game_of_Tetris.html">38 nips-2013-Approximate Dynamic Programming Finally Performs Well in the Game of Tetris</a></p>
<p>4 0.69059575 <a title="55-lsi-4" href="./nips-2013-Actor-Critic_Algorithms_for_Risk-Sensitive_MDPs.html">24 nips-2013-Actor-Critic Algorithms for Risk-Sensitive MDPs</a></p>
<p>5 0.68500012 <a title="55-lsi-5" href="./nips-2013-Learning_from_Limited_Demonstrations.html">165 nips-2013-Learning from Limited Demonstrations</a></p>
<p>6 0.68227619 <a title="55-lsi-6" href="./nips-2013-Adaptive_Step-Size_for_Policy_Gradient_Methods.html">28 nips-2013-Adaptive Step-Size for Policy Gradient Methods</a></p>
<p>7 0.67023367 <a title="55-lsi-7" href="./nips-2013-Improved_and_Generalized_Upper_Bounds_on_the_Complexity_of_Policy_Iteration.html">140 nips-2013-Improved and Generalized Upper Bounds on the Complexity of Policy Iteration</a></p>
<p>8 0.65563828 <a title="55-lsi-8" href="./nips-2013-Variational_Policy_Search_via_Trajectory_Optimization.html">348 nips-2013-Variational Policy Search via Trajectory Optimization</a></p>
<p>9 0.63949126 <a title="55-lsi-9" href="./nips-2013-Learning_Adaptive_Value_of_Information_for_Structured_Prediction.html">150 nips-2013-Learning Adaptive Value of Information for Structured Prediction</a></p>
<p>10 0.63557726 <a title="55-lsi-10" href="./nips-2013-Compressive_Feature_Learning.html">65 nips-2013-Compressive Feature Learning</a></p>
<p>11 0.62973982 <a title="55-lsi-11" href="./nips-2013-Optimistic_policy_iteration_and_natural_actor-critic%3A_A_unifying_view_and_a_non-optimality_result.html">239 nips-2013-Optimistic policy iteration and natural actor-critic: A unifying view and a non-optimality result</a></p>
<p>12 0.62524384 <a title="55-lsi-12" href="./nips-2013-Optimizing_Instructional_Policies.html">241 nips-2013-Optimizing Instructional Policies</a></p>
<p>13 0.6232239 <a title="55-lsi-13" href="./nips-2013-Variational_Planning_for_Graph-based_MDPs.html">347 nips-2013-Variational Planning for Graph-based MDPs</a></p>
<p>14 0.59697676 <a title="55-lsi-14" href="./nips-2013-DESPOT%3A_Online_POMDP_Planning_with_Regularization.html">79 nips-2013-DESPOT: Online POMDP Planning with Regularization</a></p>
<p>15 0.57972383 <a title="55-lsi-15" href="./nips-2013-Projected_Natural_Actor-Critic.html">257 nips-2013-Projected Natural Actor-Critic</a></p>
<p>16 0.56004715 <a title="55-lsi-16" href="./nips-2013-Phase_Retrieval_using_Alternating_Minimization.html">247 nips-2013-Phase Retrieval using Alternating Minimization</a></p>
<p>17 0.53743386 <a title="55-lsi-17" href="./nips-2013-Reinforcement_Learning_in_Robust_Markov_Decision_Processes.html">273 nips-2013-Reinforcement Learning in Robust Markov Decision Processes</a></p>
<p>18 0.5326528 <a title="55-lsi-18" href="./nips-2013-Regret_based_Robust_Solutions_for_Uncertain_Markov_Decision_Processes.html">270 nips-2013-Regret based Robust Solutions for Uncertain Markov Decision Processes</a></p>
<p>19 0.5326156 <a title="55-lsi-19" href="./nips-2013-Aggregating_Optimistic_Planning_Trees_for_Solving_Markov_Decision_Processes.html">32 nips-2013-Aggregating Optimistic Planning Trees for Solving Markov Decision Processes</a></p>
<p>20 0.50326943 <a title="55-lsi-20" href="./nips-2013-Bayesian_Mixture_Modelling_and_Inference_based_Thompson_Sampling_in_Monte-Carlo_Tree_Search.html">50 nips-2013-Bayesian Mixture Modelling and Inference based Thompson Sampling in Monte-Carlo Tree Search</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(20, 0.119), (25, 0.099), (37, 0.045), (45, 0.307), (70, 0.047), (80, 0.152), (86, 0.094), (87, 0.046)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.71783102 <a title="55-lda-1" href="./nips-2013-Density_estimation_from_unweighted_k-nearest_neighbor_graphs%3A_a_roadmap.html">87 nips-2013-Density estimation from unweighted k-nearest neighbor graphs: a roadmap</a></p>
<p>same-paper 2 0.69914293 <a title="55-lda-2" href="./nips-2013-Bellman_Error_Based_Feature_Generation_using_Random_Projections_on_Sparse_Spaces.html">55 nips-2013-Bellman Error Based Feature Generation using Random Projections on Sparse Spaces</a></p>
<p>3 0.69729203 <a title="55-lda-3" href="./nips-2013-Higher_Order_Priors_for_Joint_Intrinsic_Image%2C_Objects%2C_and_Attributes_Estimation.html">138 nips-2013-Higher Order Priors for Joint Intrinsic Image, Objects, and Attributes Estimation</a></p>
<p>4 0.64258617 <a title="55-lda-4" href="./nips-2013-Optimal_Neural_Population_Codes_for_High-dimensional_Stimulus_Variables.html">236 nips-2013-Optimal Neural Population Codes for High-dimensional Stimulus Variables</a></p>
<p>5 0.62403357 <a title="55-lda-5" href="./nips-2013-Synthesizing_Robust_Plans_under_Incomplete_Domain_Models.html">323 nips-2013-Synthesizing Robust Plans under Incomplete Domain Models</a></p>
<p>6 0.62344241 <a title="55-lda-6" href="./nips-2013-DESPOT%3A_Online_POMDP_Planning_with_Regularization.html">79 nips-2013-DESPOT: Online POMDP Planning with Regularization</a></p>
<p>7 0.62305963 <a title="55-lda-7" href="./nips-2013-Scalable_Influence_Estimation_in_Continuous-Time_Diffusion_Networks.html">288 nips-2013-Scalable Influence Estimation in Continuous-Time Diffusion Networks</a></p>
<p>8 0.6221301 <a title="55-lda-8" href="./nips-2013-Reward_Mapping_for_Transfer_in_Long-Lived_Agents.html">278 nips-2013-Reward Mapping for Transfer in Long-Lived Agents</a></p>
<p>9 0.62193161 <a title="55-lda-9" href="./nips-2013-On_the_Expressive_Power_of_Restricted_Boltzmann_Machines.html">221 nips-2013-On the Expressive Power of Restricted Boltzmann Machines</a></p>
<p>10 0.61977011 <a title="55-lda-10" href="./nips-2013-Learning_a_Deep_Compact_Image_Representation_for_Visual_Tracking.html">163 nips-2013-Learning a Deep Compact Image Representation for Visual Tracking</a></p>
<p>11 0.61947435 <a title="55-lda-11" href="./nips-2013-Variational_Policy_Search_via_Trajectory_Optimization.html">348 nips-2013-Variational Policy Search via Trajectory Optimization</a></p>
<p>12 0.61827666 <a title="55-lda-12" href="./nips-2013-Firing_rate_predictions_in_optimal_balanced_networks.html">121 nips-2013-Firing rate predictions in optimal balanced networks</a></p>
<p>13 0.61717635 <a title="55-lda-13" href="./nips-2013-Latent_Structured_Active_Learning.html">149 nips-2013-Latent Structured Active Learning</a></p>
<p>14 0.61630517 <a title="55-lda-14" href="./nips-2013-Policy_Shaping%3A_Integrating_Human_Feedback_with_Reinforcement_Learning.html">250 nips-2013-Policy Shaping: Integrating Human Feedback with Reinforcement Learning</a></p>
<p>15 0.61614799 <a title="55-lda-15" href="./nips-2013-Learning_Trajectory_Preferences_for__Manipulators_via_Iterative_Improvement.html">162 nips-2013-Learning Trajectory Preferences for  Manipulators via Iterative Improvement</a></p>
<p>16 0.61510623 <a title="55-lda-16" href="./nips-2013-Universal_models_for_binary_spike_patterns_using_centered_Dirichlet_processes.html">341 nips-2013-Universal models for binary spike patterns using centered Dirichlet processes</a></p>
<p>17 0.61450547 <a title="55-lda-17" href="./nips-2013-Learning_to_Prune_in_Metric_and_Non-Metric_Spaces.html">169 nips-2013-Learning to Prune in Metric and Non-Metric Spaces</a></p>
<p>18 0.61446631 <a title="55-lda-18" href="./nips-2013-Aggregating_Optimistic_Planning_Trees_for_Solving_Markov_Decision_Processes.html">32 nips-2013-Aggregating Optimistic Planning Trees for Solving Markov Decision Processes</a></p>
<p>19 0.61412156 <a title="55-lda-19" href="./nips-2013-Bayesian_Inference_and_Learning_in_Gaussian_Process_State-Space_Models_with_Particle_MCMC.html">48 nips-2013-Bayesian Inference and Learning in Gaussian Process State-Space Models with Particle MCMC</a></p>
<p>20 0.61376405 <a title="55-lda-20" href="./nips-2013-Real-Time_Inference_for_a_Gamma_Process_Model_of_Neural_Spiking.html">262 nips-2013-Real-Time Inference for a Gamma Process Model of Neural Spiking</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
