<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>71 nips-2013-Convergence of Monte Carlo Tree Search in Simultaneous Move Games</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-71" href="#">nips2013-71</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>71 nips-2013-Convergence of Monte Carlo Tree Search in Simultaneous Move Games</h1>
<br/><p>Source: <a title="nips-2013-71-pdf" href="http://papers.nips.cc/paper/5145-convergence-of-monte-carlo-tree-search-in-simultaneous-move-games.pdf">pdf</a></p><p>Author: Viliam Lisy, Vojta Kovarik, Marc Lanctot, Branislav Bosansky</p><p>Abstract: unkown-abstract</p><p>Reference: <a title="nips-2013-71-reference" href="../nips2013_reference/nips-2013-Convergence_of_Monte_Carlo_Tree_Search_in_Simultaneous_Move_Games_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('branislav', 0.364), ('pragu', 0.364), ('kov', 0.335), ('czech', 0.335), ('lis', 0.287), ('netherland', 0.276), ('ch', 0.258), ('bo', 0.251), ('fee', 0.218), ('marc', 0.206), ('engin', 0.167), ('gam', 0.161), ('ag', 0.123), ('mont', 0.119), ('carlo', 0.116), ('technolog', 0.094), ('simult', 0.082), ('mov', 0.08), ('search', 0.059), ('depart', 0.052)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="71-tfidf-1" href="./nips-2013-Convergence_of_Monte_Carlo_Tree_Search_in_Simultaneous_Move_Games.html">71 nips-2013-Convergence of Monte Carlo Tree Search in Simultaneous Move Games</a></p>
<p>Author: Viliam Lisy, Vojta Kovarik, Marc Lanctot, Branislav Bosansky</p><p>Abstract: unkown-abstract</p><p>2 0.089538544 <a title="71-tfidf-2" href="./nips-2013-Generalized_Random_Utility_Models_with_Multiple_Types.html">129 nips-2013-Generalized Random Utility Models with Multiple Types</a></p>
<p>Author: Hossein Azari Soufiani, Hansheng Diao, Zhenyu Lai, David C. Parkes</p><p>Abstract: We propose a model for demand estimation in multi-agent, differentiated product settings and present an estimation algorithm that uses reversible jump MCMC techniques to classify agents’ types. Our model extends the popular setup in Berry, Levinsohn and Pakes (1995) to allow for the data-driven classiﬁcation of agents’ types using agent-level data. We focus on applications involving data on agents’ ranking over alternatives, and present theoretical conditions that establish the identiﬁability of the model and uni-modality of the likelihood/posterior. Results on both real and simulated data provide support for the scalability of our approach. 1</p><p>3 0.06511382 <a title="71-tfidf-3" href="./nips-2013-Minimax_Optimal_Algorithms_for_Unconstrained_Linear_Optimization.html">191 nips-2013-Minimax Optimal Algorithms for Unconstrained Linear Optimization</a></p>
<p>Author: Brendan McMahan, Jacob Abernethy</p><p>Abstract: We design and analyze minimax-optimal algorithms for online linear optimization games where the player’s choice is unconstrained. The player strives to minimize regret, the difference between his loss and the loss of a post-hoc benchmark strategy. While the standard benchmark is the loss of the best strategy chosen from a bounded comparator set, we consider a very broad range of benchmark functions. The problem is cast as a sequential multi-stage zero-sum game, and we give a thorough analysis of the minimax behavior of the game, providing characterizations for the value of the game, as well as both the player’s and the adversary’s optimal strategy. We show how these objects can be computed efﬁciently under certain circumstances, and by selecting an appropriate benchmark, we construct a novel hedging strategy for an unconstrained betting game. 1</p><p>4 0.060385924 <a title="71-tfidf-4" href="./nips-2013-Point_Based_Value_Iteration_with_Optimal_Belief_Compression_for_Dec-POMDPs.html">248 nips-2013-Point Based Value Iteration with Optimal Belief Compression for Dec-POMDPs</a></p>
<p>Author: Liam C. MacDermed, Charles Isbell</p><p>Abstract: We present four major results towards solving decentralized partially observable Markov decision problems (DecPOMDPs) culminating in an algorithm that outperforms all existing algorithms on all but one standard inﬁnite-horizon benchmark problems. (1) We give an integer program that solves collaborative Bayesian games (CBGs). The program is notable because its linear relaxation is very often integral. (2) We show that a DecPOMDP with bounded belief can be converted to a POMDP (albeit with actions exponential in the number of beliefs). These actions correspond to strategies of a CBG. (3) We present a method to transform any DecPOMDP into a DecPOMDP with bounded beliefs (the number of beliefs is a free parameter) using optimal (not lossless) belief compression. (4) We show that the combination of these results opens the door for new classes of DecPOMDP algorithms based on previous POMDP algorithms. We choose one such algorithm, point-based valued iteration, and modify it to produce the ﬁrst tractable value iteration method for DecPOMDPs that outperforms existing algorithms. 1</p><p>5 0.057528719 <a title="71-tfidf-5" href="./nips-2013-A_message-passing_algorithm_for_multi-agent_trajectory_planning.html">16 nips-2013-A message-passing algorithm for multi-agent trajectory planning</a></p>
<p>Author: Jose Bento, Nate Derbinsky, Javier Alonso-Mora, Jonathan S. Yedidia</p><p>Abstract: We describe a novel approach for computing collision-free global trajectories for p agents with speciﬁed initial and ﬁnal conﬁgurations, based on an improved version of the alternating direction method of multipliers (ADMM). Compared with existing methods, our approach is naturally parallelizable and allows for incorporating different cost functionals with only minor adjustments. We apply our method to classical challenging instances and observe that its computational requirements scale well with p for several cost functionals. We also show that a specialization of our algorithm can be used for local motion planning by solving the problem of joint optimization in velocity space. 1</p><p>6 0.056641355 <a title="71-tfidf-6" href="./nips-2013-Bayesian_Hierarchical_Community_Discovery.html">47 nips-2013-Bayesian Hierarchical Community Discovery</a></p>
<p>7 0.051249031 <a title="71-tfidf-7" href="./nips-2013-Reward_Mapping_for_Transfer_in_Long-Lived_Agents.html">278 nips-2013-Reward Mapping for Transfer in Long-Lived Agents</a></p>
<p>8 0.039390326 <a title="71-tfidf-8" href="./nips-2013-Learning_and_using_language_via_recursive_pragmatic_reasoning_about_other_agents.html">164 nips-2013-Learning and using language via recursive pragmatic reasoning about other agents</a></p>
<p>9 0.03906288 <a title="71-tfidf-9" href="./nips-2013-Bayesian_optimization_explains_human_active_search.html">54 nips-2013-Bayesian optimization explains human active search</a></p>
<p>10 0.038635533 <a title="71-tfidf-10" href="./nips-2013-Online_Learning_of_Dynamic_Parameters_in_Social_Networks.html">228 nips-2013-Online Learning of Dynamic Parameters in Social Networks</a></p>
<p>11 0.036696117 <a title="71-tfidf-11" href="./nips-2013-DESPOT%3A_Online_POMDP_Planning_with_Regularization.html">79 nips-2013-DESPOT: Online POMDP Planning with Regularization</a></p>
<p>12 0.034805682 <a title="71-tfidf-12" href="./nips-2013-Learning_to_Prune_in_Metric_and_Non-Metric_Spaces.html">169 nips-2013-Learning to Prune in Metric and Non-Metric Spaces</a></p>
<p>13 0.029926863 <a title="71-tfidf-13" href="./nips-2013-High-Dimensional_Gaussian_Process_Bandits.html">137 nips-2013-High-Dimensional Gaussian Process Bandits</a></p>
<p>14 0.029882837 <a title="71-tfidf-14" href="./nips-2013-Which_Space_Partitioning_Tree_to_Use_for_Search%3F.html">355 nips-2013-Which Space Partitioning Tree to Use for Search?</a></p>
<p>15 0.02750908 <a title="71-tfidf-15" href="./nips-2013-Approximate_Dynamic_Programming_Finally_Performs_Well_in_the_Game_of_Tetris.html">38 nips-2013-Approximate Dynamic Programming Finally Performs Well in the Game of Tetris</a></p>
<p>16 0.024347093 <a title="71-tfidf-16" href="./nips-2013-Bayesian_Inference_and_Learning_in_Gaussian_Process_State-Space_Models_with_Particle_MCMC.html">48 nips-2013-Bayesian Inference and Learning in Gaussian Process State-Space Models with Particle MCMC</a></p>
<p>17 0.023099981 <a title="71-tfidf-17" href="./nips-2013-Distributed_Representations_of_Words_and_Phrases_and_their_Compositionality.html">96 nips-2013-Distributed Representations of Words and Phrases and their Compositionality</a></p>
<p>18 0.022148829 <a title="71-tfidf-18" href="./nips-2013-Robust_Multimodal_Graph_Matching%3A_Sparse_Coding_Meets_Graph_Matching.html">282 nips-2013-Robust Multimodal Graph Matching: Sparse Coding Meets Graph Matching</a></p>
<p>19 0.021200337 <a title="71-tfidf-19" href="./nips-2013-A_multi-agent_control_framework_for_co-adaptation_in_brain-computer_interfaces.html">17 nips-2013-A multi-agent control framework for co-adaptation in brain-computer interfaces</a></p>
<p>20 0.021047737 <a title="71-tfidf-20" href="./nips-2013-Summary_Statistics_for_Partitionings_and_Feature_Allocations.html">320 nips-2013-Summary Statistics for Partitionings and Feature Allocations</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.04), (1, -0.021), (2, 0.007), (3, -0.0), (4, -0.009), (5, -0.013), (6, 0.01), (7, 0.037), (8, 0.012), (9, -0.031), (10, 0.009), (11, -0.023), (12, -0.003), (13, -0.0), (14, -0.023), (15, -0.022), (16, -0.039), (17, -0.054), (18, -0.058), (19, -0.009), (20, -0.065), (21, -0.066), (22, -0.085), (23, 0.006), (24, -0.02), (25, 0.015), (26, 0.033), (27, -0.08), (28, 0.023), (29, 0.001), (30, -0.089), (31, 0.02), (32, -0.02), (33, 0.019), (34, -0.004), (35, -0.028), (36, -0.017), (37, 0.055), (38, 0.038), (39, 0.033), (40, 0.022), (41, -0.021), (42, -0.052), (43, 0.023), (44, -0.01), (45, 0.004), (46, -0.025), (47, 0.038), (48, -0.014), (49, -0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96855175 <a title="71-lsi-1" href="./nips-2013-Convergence_of_Monte_Carlo_Tree_Search_in_Simultaneous_Move_Games.html">71 nips-2013-Convergence of Monte Carlo Tree Search in Simultaneous Move Games</a></p>
<p>Author: Viliam Lisy, Vojta Kovarik, Marc Lanctot, Branislav Bosansky</p><p>Abstract: unkown-abstract</p><p>2 0.58196789 <a title="71-lsi-2" href="./nips-2013-Generalized_Random_Utility_Models_with_Multiple_Types.html">129 nips-2013-Generalized Random Utility Models with Multiple Types</a></p>
<p>Author: Hossein Azari Soufiani, Hansheng Diao, Zhenyu Lai, David C. Parkes</p><p>Abstract: We propose a model for demand estimation in multi-agent, differentiated product settings and present an estimation algorithm that uses reversible jump MCMC techniques to classify agents’ types. Our model extends the popular setup in Berry, Levinsohn and Pakes (1995) to allow for the data-driven classiﬁcation of agents’ types using agent-level data. We focus on applications involving data on agents’ ranking over alternatives, and present theoretical conditions that establish the identiﬁability of the model and uni-modality of the likelihood/posterior. Results on both real and simulated data provide support for the scalability of our approach. 1</p><p>3 0.56435174 <a title="71-lsi-3" href="./nips-2013-A_message-passing_algorithm_for_multi-agent_trajectory_planning.html">16 nips-2013-A message-passing algorithm for multi-agent trajectory planning</a></p>
<p>Author: Jose Bento, Nate Derbinsky, Javier Alonso-Mora, Jonathan S. Yedidia</p><p>Abstract: We describe a novel approach for computing collision-free global trajectories for p agents with speciﬁed initial and ﬁnal conﬁgurations, based on an improved version of the alternating direction method of multipliers (ADMM). Compared with existing methods, our approach is naturally parallelizable and allows for incorporating different cost functionals with only minor adjustments. We apply our method to classical challenging instances and observe that its computational requirements scale well with p for several cost functionals. We also show that a specialization of our algorithm can be used for local motion planning by solving the problem of joint optimization in velocity space. 1</p><p>4 0.56407297 <a title="71-lsi-4" href="./nips-2013-Point_Based_Value_Iteration_with_Optimal_Belief_Compression_for_Dec-POMDPs.html">248 nips-2013-Point Based Value Iteration with Optimal Belief Compression for Dec-POMDPs</a></p>
<p>Author: Liam C. MacDermed, Charles Isbell</p><p>Abstract: We present four major results towards solving decentralized partially observable Markov decision problems (DecPOMDPs) culminating in an algorithm that outperforms all existing algorithms on all but one standard inﬁnite-horizon benchmark problems. (1) We give an integer program that solves collaborative Bayesian games (CBGs). The program is notable because its linear relaxation is very often integral. (2) We show that a DecPOMDP with bounded belief can be converted to a POMDP (albeit with actions exponential in the number of beliefs). These actions correspond to strategies of a CBG. (3) We present a method to transform any DecPOMDP into a DecPOMDP with bounded beliefs (the number of beliefs is a free parameter) using optimal (not lossless) belief compression. (4) We show that the combination of these results opens the door for new classes of DecPOMDP algorithms based on previous POMDP algorithms. We choose one such algorithm, point-based valued iteration, and modify it to produce the ﬁrst tractable value iteration method for DecPOMDPs that outperforms existing algorithms. 1</p><p>5 0.55890721 <a title="71-lsi-5" href="./nips-2013-Learning_and_using_language_via_recursive_pragmatic_reasoning_about_other_agents.html">164 nips-2013-Learning and using language via recursive pragmatic reasoning about other agents</a></p>
<p>Author: Nathaniel J. Smith, Noah Goodman, Michael Frank</p><p>Abstract: Language users are remarkably good at making inferences about speakers’ intentions in context, and children learning their native language also display substantial skill in acquiring the meanings of unknown words. These two cases are deeply related: Language users invent new terms in conversation, and language learners learn the literal meanings of words based on their pragmatic inferences about how those words are used. While pragmatic inference and word learning have both been independently characterized in probabilistic terms, no current work uniﬁes these two. We describe a model in which language learners assume that they jointly approximate a shared, external lexicon and reason recursively about the goals of others in using this lexicon. This model captures phenomena in word learning and pragmatic inference; it additionally leads to insights about the emergence of communicative systems in conversation and the mechanisms by which pragmatic inferences become incorporated into word meanings. 1</p><p>6 0.42137194 <a title="71-lsi-6" href="./nips-2013-Reward_Mapping_for_Transfer_in_Long-Lived_Agents.html">278 nips-2013-Reward Mapping for Transfer in Long-Lived Agents</a></p>
<p>7 0.41543484 <a title="71-lsi-7" href="./nips-2013-Bayesian_Hierarchical_Community_Discovery.html">47 nips-2013-Bayesian Hierarchical Community Discovery</a></p>
<p>8 0.3957656 <a title="71-lsi-8" href="./nips-2013-Learning_to_Prune_in_Metric_and_Non-Metric_Spaces.html">169 nips-2013-Learning to Prune in Metric and Non-Metric Spaces</a></p>
<p>9 0.39193064 <a title="71-lsi-9" href="./nips-2013-Online_Learning_of_Dynamic_Parameters_in_Social_Networks.html">228 nips-2013-Online Learning of Dynamic Parameters in Social Networks</a></p>
<p>10 0.37211573 <a title="71-lsi-10" href="./nips-2013-Robust_Sparse_Principal_Component_Regression_under_the_High_Dimensional_Elliptical_Model.html">283 nips-2013-Robust Sparse Principal Component Regression under the High Dimensional Elliptical Model</a></p>
<p>11 0.32382068 <a title="71-lsi-11" href="./nips-2013-Generalized_Method-of-Moments_for_Rank_Aggregation.html">128 nips-2013-Generalized Method-of-Moments for Rank Aggregation</a></p>
<p>12 0.31079614 <a title="71-lsi-12" href="./nips-2013-Minimax_Optimal_Algorithms_for_Unconstrained_Linear_Optimization.html">191 nips-2013-Minimax Optimal Algorithms for Unconstrained Linear Optimization</a></p>
<p>13 0.30381975 <a title="71-lsi-13" href="./nips-2013-DESPOT%3A_Online_POMDP_Planning_with_Regularization.html">79 nips-2013-DESPOT: Online POMDP Planning with Regularization</a></p>
<p>14 0.27595639 <a title="71-lsi-14" href="./nips-2013-Learning_Trajectory_Preferences_for__Manipulators_via_Iterative_Improvement.html">162 nips-2013-Learning Trajectory Preferences for  Manipulators via Iterative Improvement</a></p>
<p>15 0.25776941 <a title="71-lsi-15" href="./nips-2013-The_Pareto_Regret_Frontier.html">325 nips-2013-The Pareto Regret Frontier</a></p>
<p>16 0.25175792 <a title="71-lsi-16" href="./nips-2013-Which_Space_Partitioning_Tree_to_Use_for_Search%3F.html">355 nips-2013-Which Space Partitioning Tree to Use for Search?</a></p>
<p>17 0.25035128 <a title="71-lsi-17" href="./nips-2013-Policy_Shaping%3A_Integrating_Human_Feedback_with_Reinforcement_Learning.html">250 nips-2013-Policy Shaping: Integrating Human Feedback with Reinforcement Learning</a></p>
<p>18 0.23946814 <a title="71-lsi-18" href="./nips-2013-Learning_from_Limited_Demonstrations.html">165 nips-2013-Learning from Limited Demonstrations</a></p>
<p>19 0.23678586 <a title="71-lsi-19" href="./nips-2013-Bayesian_optimization_explains_human_active_search.html">54 nips-2013-Bayesian optimization explains human active search</a></p>
<p>20 0.22706097 <a title="71-lsi-20" href="./nips-2013-Optimization%2C_Learning%2C_and_Games_with_Predictable_Sequences.html">240 nips-2013-Optimization, Learning, and Games with Predictable Sequences</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(20, 0.012), (37, 0.075), (67, 0.625), (80, 0.071), (86, 0.033)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.83695173 <a title="71-lda-1" href="./nips-2013-Convergence_of_Monte_Carlo_Tree_Search_in_Simultaneous_Move_Games.html">71 nips-2013-Convergence of Monte Carlo Tree Search in Simultaneous Move Games</a></p>
<p>Author: Viliam Lisy, Vojta Kovarik, Marc Lanctot, Branislav Bosansky</p><p>Abstract: unkown-abstract</p><p>2 0.24756318 <a title="71-lda-2" href="./nips-2013-Parametric_Task_Learning.html">244 nips-2013-Parametric Task Learning</a></p>
<p>Author: Ichiro Takeuchi, Tatsuya Hongo, Masashi Sugiyama, Shinichi Nakajima</p><p>Abstract: We introduce an extended formulation of multi-task learning (MTL) called parametric task learning (PTL) that can systematically handle inﬁnitely many tasks parameterized by a continuous parameter. Our key ﬁnding is that, for a certain class of PTL problems, the path of the optimal task-wise solutions can be represented as piecewise-linear functions of the continuous task parameter. Based on this fact, we employ a parametric programming technique to obtain the common shared representation across all the continuously parameterized tasks. We show that our PTL formulation is useful in various scenarios such as learning under non-stationarity, cost-sensitive learning, and quantile regression. We demonstrate the advantage of our approach in these scenarios.</p><p>3 0.20705916 <a title="71-lda-3" href="./nips-2013-Bayesian_Estimation_of_Latently-grouped_Parameters_in_Undirected_Graphical_Models.html">46 nips-2013-Bayesian Estimation of Latently-grouped Parameters in Undirected Graphical Models</a></p>
<p>Author: Jie Liu, David Page</p><p>Abstract: In large-scale applications of undirected graphical models, such as social networks and biological networks, similar patterns occur frequently and give rise to similar parameters. In this situation, it is beneﬁcial to group the parameters for more efﬁcient learning. We show that even when the grouping is unknown, we can infer these parameter groups during learning via a Bayesian approach. We impose a Dirichlet process prior on the parameters. Posterior inference usually involves calculating intractable terms, and we propose two approximation algorithms, namely a Metropolis-Hastings algorithm with auxiliary variables and a Gibbs sampling algorithm with “stripped” Beta approximation (Gibbs SBA). Simulations show that both algorithms outperform conventional maximum likelihood estimation (MLE). Gibbs SBA’s performance is close to Gibbs sampling with exact likelihood calculation. Models learned with Gibbs SBA also generalize better than the models learned by MLE on real-world Senate voting data. 1</p><p>4 0.15387966 <a title="71-lda-4" href="./nips-2013-Projected_Natural_Actor-Critic.html">257 nips-2013-Projected Natural Actor-Critic</a></p>
<p>Author: Philip S. Thomas, William C. Dabney, Stephen Giguere, Sridhar Mahadevan</p><p>Abstract: Natural actor-critics form a popular class of policy search algorithms for ﬁnding locally optimal policies for Markov decision processes. In this paper we address a drawback of natural actor-critics that limits their real-world applicability—their lack of safety guarantees. We present a principled algorithm for performing natural gradient descent over a constrained domain. In the context of reinforcement learning, this allows for natural actor-critic algorithms that are guaranteed to remain within a known safe region of policy space. While deriving our class of constrained natural actor-critic algorithms, which we call Projected Natural ActorCritics (PNACs), we also elucidate the relationship between natural gradient descent and mirror descent. 1</p><p>5 0.14564969 <a title="71-lda-5" href="./nips-2013-Message_Passing_Inference_with_Chemical_Reaction_Networks.html">189 nips-2013-Message Passing Inference with Chemical Reaction Networks</a></p>
<p>Author: Nils E. Napp, Ryan P. Adams</p><p>Abstract: Recent work on molecular programming has explored new possibilities for computational abstractions with biomolecules, including logic gates, neural networks, and linear systems. In the future such abstractions might enable nanoscale devices that can sense and control the world at a molecular scale. Just as in macroscale robotics, it is critical that such devices can learn about their environment and reason under uncertainty. At this small scale, systems are typically modeled as chemical reaction networks. In this work, we develop a procedure that can take arbitrary probabilistic graphical models, represented as factor graphs over discrete random variables, and compile them into chemical reaction networks that implement inference. In particular, we show that marginalization based on sum-product message passing can be implemented in terms of reactions between chemical species whose concentrations represent probabilities. We show algebraically that the steady state concentration of these species correspond to the marginal distributions of the random variables in the graph and validate the results in simulations. As with standard sum-product inference, this procedure yields exact results for tree-structured graphs, and approximate solutions for loopy graphs.</p><p>6 0.14362065 <a title="71-lda-6" href="./nips-2013-Generalized_Method-of-Moments_for_Rank_Aggregation.html">128 nips-2013-Generalized Method-of-Moments for Rank Aggregation</a></p>
<p>7 0.14330678 <a title="71-lda-7" href="./nips-2013-Learning_Hidden_Markov_Models_from_Non-sequence_Data_via_Tensor_Decomposition.html">155 nips-2013-Learning Hidden Markov Models from Non-sequence Data via Tensor Decomposition</a></p>
<p>8 0.13963065 <a title="71-lda-8" href="./nips-2013-Understanding_variable_importances_in_forests_of_randomized_trees.html">340 nips-2013-Understanding variable importances in forests of randomized trees</a></p>
<p>9 0.13932528 <a title="71-lda-9" href="./nips-2013-Bayesian_Inference_and_Online_Experimental_Design_for_Mapping_Neural_Microcircuits.html">49 nips-2013-Bayesian Inference and Online Experimental Design for Mapping Neural Microcircuits</a></p>
<p>10 0.13644531 <a title="71-lda-10" href="./nips-2013-Minimax_Optimal_Algorithms_for_Unconstrained_Linear_Optimization.html">191 nips-2013-Minimax Optimal Algorithms for Unconstrained Linear Optimization</a></p>
<p>11 0.13524464 <a title="71-lda-11" href="./nips-2013-Small-Variance_Asymptotics_for_Hidden_Markov_Models.html">298 nips-2013-Small-Variance Asymptotics for Hidden Markov Models</a></p>
<p>12 0.13003729 <a title="71-lda-12" href="./nips-2013-Projecting_Ising_Model_Parameters_for_Fast_Mixing.html">258 nips-2013-Projecting Ising Model Parameters for Fast Mixing</a></p>
<p>13 0.12796286 <a title="71-lda-13" href="./nips-2013-Variational_Planning_for_Graph-based_MDPs.html">347 nips-2013-Variational Planning for Graph-based MDPs</a></p>
<p>14 0.12727837 <a title="71-lda-14" href="./nips-2013-Learning_Adaptive_Value_of_Information_for_Structured_Prediction.html">150 nips-2013-Learning Adaptive Value of Information for Structured Prediction</a></p>
<p>15 0.12668918 <a title="71-lda-15" href="./nips-2013-Point_Based_Value_Iteration_with_Optimal_Belief_Compression_for_Dec-POMDPs.html">248 nips-2013-Point Based Value Iteration with Optimal Belief Compression for Dec-POMDPs</a></p>
<p>16 0.12517267 <a title="71-lda-16" href="./nips-2013-Bayesian_entropy_estimation_for_binary_spike_train_data_using_parametric_prior_knowledge.html">51 nips-2013-Bayesian entropy estimation for binary spike train data using parametric prior knowledge</a></p>
<p>17 0.12460366 <a title="71-lda-17" href="./nips-2013-Adaptive_Step-Size_for_Policy_Gradient_Methods.html">28 nips-2013-Adaptive Step-Size for Policy Gradient Methods</a></p>
<p>18 0.12355291 <a title="71-lda-18" href="./nips-2013-DESPOT%3A_Online_POMDP_Planning_with_Regularization.html">79 nips-2013-DESPOT: Online POMDP Planning with Regularization</a></p>
<p>19 0.12305817 <a title="71-lda-19" href="./nips-2013-Two-Target_Algorithms__for_Infinite-Armed___Bandits_with_Bernoulli_Rewards.html">338 nips-2013-Two-Target Algorithms  for Infinite-Armed   Bandits with Bernoulli Rewards</a></p>
<p>20 0.1229973 <a title="71-lda-20" href="./nips-2013-Reinforcement_Learning_in_Robust_Markov_Decision_Processes.html">273 nips-2013-Reinforcement Learning in Robust Markov Decision Processes</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
