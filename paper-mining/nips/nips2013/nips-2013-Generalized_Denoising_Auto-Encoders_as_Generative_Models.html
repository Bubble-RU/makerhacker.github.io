<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>127 nips-2013-Generalized Denoising Auto-Encoders as Generative Models</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-127" href="#">nips2013-127</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>127 nips-2013-Generalized Denoising Auto-Encoders as Generative Models</h1>
<br/><p>Source: <a title="nips-2013-127-pdf" href="http://papers.nips.cc/paper/5023-generalized-denoising-auto-encoders-as-generative-models.pdf">pdf</a></p><p>Author: Yoshua Bengio, Li Yao, Guillaume Alain, Pascal Vincent</p><p>Abstract: Recent work has shown how denoising and contractive autoencoders implicitly capture the structure of the data-generating density, in the case where the corruption noise is Gaussian, the reconstruction error is the squared error, and the data is continuous-valued. This has led to various proposals for sampling from this implicitly learned density function, using Langevin and Metropolis-Hastings MCMC. However, it remained unclear how to connect the training procedure of regularized auto-encoders to the implicit estimation of the underlying datagenerating distribution when the data are discrete, or using other forms of corruption process and reconstruction errors. Another issue is the mathematical justiﬁcation which is only valid in the limit of small corruption noise. We propose here a different attack on the problem, which deals with all these issues: arbitrary (but noisy enough) corruption, arbitrary reconstruction loss (seen as a log-likelihood), handling both discrete and continuous-valued variables, and removing the bias due to non-inﬁnitesimal corruption noise (or non-inﬁnitesimal contractive penalty). 1</p><p>Reference: <a title="nips-2013-127-reference" href="../nips2013_reference/nips-2013-Generalized_Denoising_Auto-Encoders_as_Generative_Models_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('walkback', 0.468), ('corrupt', 0.4), ('dae', 0.322), ('tn', 0.261), ('xt', 0.229), ('chain', 0.22), ('deno', 0.192), ('bengio', 0.186), ('train', 0.173), ('alain', 0.14), ('reconstruct', 0.116), ('spury', 0.106), ('energy', 0.098), ('manifold', 0.094), ('asymptot', 0.092), ('rifa', 0.089), ('vint', 0.089), ('markov', 0.088), ('rbm', 0.085), ('contract', 0.083)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9999997 <a title="127-tfidf-1" href="./nips-2013-Generalized_Denoising_Auto-Encoders_as_Generative_Models.html">127 nips-2013-Generalized Denoising Auto-Encoders as Generative Models</a></p>
<p>2 0.17719628 <a title="127-tfidf-2" href="./nips-2013-Adaptive_Multi-Column_Deep_Neural_Networks_with_Application_to_Robust_Image_Denoising.html">27 nips-2013-Adaptive Multi-Column Deep Neural Networks with Application to Robust Image Denoising</a></p>
<p>3 0.15719682 <a title="127-tfidf-3" href="./nips-2013-Robust_Transfer_Principal_Component_Analysis_with_Rank_Constraints.html">285 nips-2013-Robust Transfer Principal Component Analysis with Rank Constraints</a></p>
<p>4 0.15006237 <a title="127-tfidf-4" href="./nips-2013-Stochastic_Ratio_Matching_of_RBMs_for_Sparse_High-Dimensional_Inputs.html">315 nips-2013-Stochastic Ratio Matching of RBMs for Sparse High-Dimensional Inputs</a></p>
<p>5 0.14432806 <a title="127-tfidf-5" href="./nips-2013-Computing_the_Stationary_Distribution_Locally.html">66 nips-2013-Computing the Stationary Distribution Locally</a></p>
<p>6 0.13908392 <a title="127-tfidf-6" href="./nips-2013-A_simple_example_of_Dirichlet_process_mixture_inconsistency_for_the_number_of_components.html">18 nips-2013-A simple example of Dirichlet process mixture inconsistency for the number of components</a></p>
<p>7 0.13626012 <a title="127-tfidf-7" href="./nips-2013-Causal_Inference_on_Time_Series_using_Restricted_Structural_Equation_Models.html">62 nips-2013-Causal Inference on Time Series using Restricted Structural Equation Models</a></p>
<p>8 0.1146429 <a title="127-tfidf-8" href="./nips-2013-Multi-Prediction_Deep_Boltzmann_Machines.html">200 nips-2013-Multi-Prediction Deep Boltzmann Machines</a></p>
<p>9 0.11444443 <a title="127-tfidf-9" href="./nips-2013-Top-Down_Regularization_of_Deep_Belief_Networks.html">331 nips-2013-Top-Down Regularization of Deep Belief Networks</a></p>
<p>10 0.10936358 <a title="127-tfidf-10" href="./nips-2013-Bayesian_Inference_and_Learning_in_Gaussian_Process_State-Space_Models_with_Particle_MCMC.html">48 nips-2013-Bayesian Inference and Learning in Gaussian Process State-Space Models with Particle MCMC</a></p>
<p>11 0.10836807 <a title="127-tfidf-11" href="./nips-2013-A_multi-agent_control_framework_for_co-adaptation_in_brain-computer_interfaces.html">17 nips-2013-A multi-agent control framework for co-adaptation in brain-computer interfaces</a></p>
<p>12 0.10087437 <a title="127-tfidf-12" href="./nips-2013-Convex_Two-Layer_Modeling.html">75 nips-2013-Convex Two-Layer Modeling</a></p>
<p>13 0.099917978 <a title="127-tfidf-13" href="./nips-2013-Learning_a_Deep_Compact_Image_Representation_for_Visual_Tracking.html">163 nips-2013-Learning a Deep Compact Image Representation for Visual Tracking</a></p>
<p>14 0.098579884 <a title="127-tfidf-14" href="./nips-2013-Approximate_Gaussian_process_inference_for_the_drift_function_in_stochastic_differential_equations.html">39 nips-2013-Approximate Gaussian process inference for the drift function in stochastic differential equations</a></p>
<p>15 0.097199984 <a title="127-tfidf-15" href="./nips-2013-Regression-tree_Tuning_in_a_Streaming_Setting.html">269 nips-2013-Regression-tree Tuning in a Streaming Setting</a></p>
<p>16 0.090059549 <a title="127-tfidf-16" href="./nips-2013-Solving_inverse_problem_of_Markov_chain_with_partial_observations.html">299 nips-2013-Solving inverse problem of Markov chain with partial observations</a></p>
<p>17 0.088434584 <a title="127-tfidf-17" href="./nips-2013-Actor-Critic_Algorithms_for_Risk-Sensitive_MDPs.html">24 nips-2013-Actor-Critic Algorithms for Risk-Sensitive MDPs</a></p>
<p>18 0.087084793 <a title="127-tfidf-18" href="./nips-2013-Variational_Policy_Search_via_Trajectory_Optimization.html">348 nips-2013-Variational Policy Search via Trajectory Optimization</a></p>
<p>19 0.086626366 <a title="127-tfidf-19" href="./nips-2013-Dimension-Free_Exponentiated_Gradient.html">89 nips-2013-Dimension-Free Exponentiated Gradient</a></p>
<p>20 0.084814787 <a title="127-tfidf-20" href="./nips-2013-Adaptive_dropout_for_training_deep_neural_networks.html">30 nips-2013-Adaptive dropout for training deep neural networks</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.209), (1, 0.043), (2, 0.033), (3, -0.002), (4, -0.068), (5, -0.022), (6, -0.144), (7, -0.031), (8, -0.021), (9, -0.102), (10, 0.129), (11, -0.031), (12, -0.044), (13, 0.18), (14, -0.017), (15, -0.04), (16, 0.023), (17, 0.077), (18, -0.024), (19, 0.073), (20, 0.082), (21, 0.037), (22, 0.061), (23, -0.052), (24, 0.022), (25, -0.01), (26, 0.06), (27, 0.009), (28, 0.113), (29, -0.093), (30, 0.098), (31, 0.025), (32, 0.024), (33, -0.056), (34, -0.111), (35, 0.106), (36, 0.068), (37, -0.062), (38, 0.052), (39, 0.115), (40, -0.094), (41, 0.001), (42, 0.033), (43, -0.145), (44, 0.075), (45, 0.022), (46, 0.092), (47, 0.049), (48, -0.11), (49, 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92141432 <a title="127-lsi-1" href="./nips-2013-Generalized_Denoising_Auto-Encoders_as_Generative_Models.html">127 nips-2013-Generalized Denoising Auto-Encoders as Generative Models</a></p>
<p>2 0.65476221 <a title="127-lsi-2" href="./nips-2013-Stochastic_Ratio_Matching_of_RBMs_for_Sparse_High-Dimensional_Inputs.html">315 nips-2013-Stochastic Ratio Matching of RBMs for Sparse High-Dimensional Inputs</a></p>
<p>3 0.64837515 <a title="127-lsi-3" href="./nips-2013-Solving_inverse_problem_of_Markov_chain_with_partial_observations.html">299 nips-2013-Solving inverse problem of Markov chain with partial observations</a></p>
<p>4 0.61515486 <a title="127-lsi-4" href="./nips-2013-Adaptive_Multi-Column_Deep_Neural_Networks_with_Application_to_Robust_Image_Denoising.html">27 nips-2013-Adaptive Multi-Column Deep Neural Networks with Application to Robust Image Denoising</a></p>
<p>5 0.60167879 <a title="127-lsi-5" href="./nips-2013-Annealing_between_distributions_by_averaging_moments.html">36 nips-2013-Annealing between distributions by averaging moments</a></p>
<p>6 0.59885567 <a title="127-lsi-6" href="./nips-2013-Causal_Inference_on_Time_Series_using_Restricted_Structural_Equation_Models.html">62 nips-2013-Causal Inference on Time Series using Restricted Structural Equation Models</a></p>
<p>7 0.58823025 <a title="127-lsi-7" href="./nips-2013-Multi-Prediction_Deep_Boltzmann_Machines.html">200 nips-2013-Multi-Prediction Deep Boltzmann Machines</a></p>
<p>8 0.55448246 <a title="127-lsi-8" href="./nips-2013-Approximate_inference_in_latent_Gaussian-Markov_models_from_continuous_time_observations.html">41 nips-2013-Approximate inference in latent Gaussian-Markov models from continuous time observations</a></p>
<p>9 0.54959363 <a title="127-lsi-9" href="./nips-2013-Small-Variance_Asymptotics_for_Hidden_Markov_Models.html">298 nips-2013-Small-Variance Asymptotics for Hidden Markov Models</a></p>
<p>10 0.54540873 <a title="127-lsi-10" href="./nips-2013-A_multi-agent_control_framework_for_co-adaptation_in_brain-computer_interfaces.html">17 nips-2013-A multi-agent control framework for co-adaptation in brain-computer interfaces</a></p>
<p>11 0.52663285 <a title="127-lsi-11" href="./nips-2013-Learning_Stochastic_Feedforward_Neural_Networks.html">160 nips-2013-Learning Stochastic Feedforward Neural Networks</a></p>
<p>12 0.52520323 <a title="127-lsi-12" href="./nips-2013-Approximate_Gaussian_process_inference_for_the_drift_function_in_stochastic_differential_equations.html">39 nips-2013-Approximate Gaussian process inference for the drift function in stochastic differential equations</a></p>
<p>13 0.52240533 <a title="127-lsi-13" href="./nips-2013-RNADE%3A_The_real-valued_neural_autoregressive_density-estimator.html">260 nips-2013-RNADE: The real-valued neural autoregressive density-estimator</a></p>
<p>14 0.51260221 <a title="127-lsi-14" href="./nips-2013-Bayesian_Inference_and_Learning_in_Gaussian_Process_State-Space_Models_with_Particle_MCMC.html">48 nips-2013-Bayesian Inference and Learning in Gaussian Process State-Space Models with Particle MCMC</a></p>
<p>15 0.49943855 <a title="127-lsi-15" href="./nips-2013-Computing_the_Stationary_Distribution_Locally.html">66 nips-2013-Computing the Stationary Distribution Locally</a></p>
<p>16 0.48245904 <a title="127-lsi-16" href="./nips-2013-Robust_Transfer_Principal_Component_Analysis_with_Rank_Constraints.html">285 nips-2013-Robust Transfer Principal Component Analysis with Rank Constraints</a></p>
<p>17 0.47335351 <a title="127-lsi-17" href="./nips-2013-Predictive_PAC_Learning_and_Process_Decompositions.html">252 nips-2013-Predictive PAC Learning and Process Decompositions</a></p>
<p>18 0.46777433 <a title="127-lsi-18" href="./nips-2013-Stochastic_Optimization_of_PCA_with_Capped_MSG.html">314 nips-2013-Stochastic Optimization of PCA with Capped MSG</a></p>
<p>19 0.46345863 <a title="127-lsi-19" href="./nips-2013-Geometric_optimisation_on_positive_definite_matrices_for_elliptically_contoured_distributions.html">131 nips-2013-Geometric optimisation on positive definite matrices for elliptically contoured distributions</a></p>
<p>20 0.45289272 <a title="127-lsi-20" href="./nips-2013-Probabilistic_Principal_Geodesic_Analysis.html">256 nips-2013-Probabilistic Principal Geodesic Analysis</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(20, 0.146), (25, 0.161), (26, 0.154), (36, 0.014), (37, 0.059), (62, 0.011), (70, 0.034), (80, 0.102), (86, 0.146), (87, 0.072)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.90362066 <a title="127-lda-1" href="./nips-2013-Generalized_Denoising_Auto-Encoders_as_Generative_Models.html">127 nips-2013-Generalized Denoising Auto-Encoders as Generative Models</a></p>
<p>2 0.89242965 <a title="127-lda-2" href="./nips-2013-Robust_Low_Rank_Kernel_Embeddings_of_Multivariate_Distributions.html">281 nips-2013-Robust Low Rank Kernel Embeddings of Multivariate Distributions</a></p>
<p>3 0.8741436 <a title="127-lda-3" href="./nips-2013-Optimization%2C_Learning%2C_and_Games_with_Predictable_Sequences.html">240 nips-2013-Optimization, Learning, and Games with Predictable Sequences</a></p>
<p>4 0.87363845 <a title="127-lda-4" href="./nips-2013-Sparse_Additive_Text_Models_with_Low_Rank_Background.html">301 nips-2013-Sparse Additive Text Models with Low Rank Background</a></p>
<p>5 0.87318224 <a title="127-lda-5" href="./nips-2013-Learning_with_Noisy_Labels.html">171 nips-2013-Learning with Noisy Labels</a></p>
<p>6 0.87317342 <a title="127-lda-6" href="./nips-2013-Noise-Enhanced_Associative_Memories.html">210 nips-2013-Noise-Enhanced Associative Memories</a></p>
<p>7 0.87188655 <a title="127-lda-7" href="./nips-2013-Low-Rank_Matrix_and_Tensor_Completion_via_Adaptive_Sampling.html">179 nips-2013-Low-Rank Matrix and Tensor Completion via Adaptive Sampling</a></p>
<p>8 0.87164634 <a title="127-lda-8" href="./nips-2013-Online_Learning_of_Dynamic_Parameters_in_Social_Networks.html">228 nips-2013-Online Learning of Dynamic Parameters in Social Networks</a></p>
<p>9 0.87139326 <a title="127-lda-9" href="./nips-2013-A_Latent_Source_Model_for_Nonparametric_Time_Series_Classification.html">10 nips-2013-A Latent Source Model for Nonparametric Time Series Classification</a></p>
<p>10 0.87090796 <a title="127-lda-10" href="./nips-2013-%CE%A3-Optimality_for_Active_Learning_on_Gaussian_Random_Fields.html">359 nips-2013-Σ-Optimality for Active Learning on Gaussian Random Fields</a></p>
<p>11 0.87090331 <a title="127-lda-11" href="./nips-2013-Dropout_Training_as_Adaptive_Regularization.html">99 nips-2013-Dropout Training as Adaptive Regularization</a></p>
<p>12 0.87053031 <a title="127-lda-12" href="./nips-2013-Fantope_Projection_and_Selection%3A_A_near-optimal_convex_relaxation_of_sparse_PCA.html">116 nips-2013-Fantope Projection and Selection: A near-optimal convex relaxation of sparse PCA</a></p>
<p>13 0.8698507 <a title="127-lda-13" href="./nips-2013-Parametric_Task_Learning.html">244 nips-2013-Parametric Task Learning</a></p>
<p>14 0.86922562 <a title="127-lda-14" href="./nips-2013-A_New_Convex_Relaxation_for_Tensor_Completion.html">11 nips-2013-A New Convex Relaxation for Tensor Completion</a></p>
<p>15 0.8681969 <a title="127-lda-15" href="./nips-2013-Discovering_Hidden_Variables_in_Noisy-Or_Networks_using_Quartet_Tests.html">92 nips-2013-Discovering Hidden Variables in Noisy-Or Networks using Quartet Tests</a></p>
<p>16 0.86815947 <a title="127-lda-16" href="./nips-2013-On_Flat_versus_Hierarchical_Classification_in_Large-Scale_Taxonomies.html">216 nips-2013-On Flat versus Hierarchical Classification in Large-Scale Taxonomies</a></p>
<p>17 0.86739761 <a title="127-lda-17" href="./nips-2013-Confidence_Intervals_and_Hypothesis_Testing_for_High-Dimensional_Statistical_Models.html">68 nips-2013-Confidence Intervals and Hypothesis Testing for High-Dimensional Statistical Models</a></p>
<p>18 0.86553711 <a title="127-lda-18" href="./nips-2013-PAC-Bayes-Empirical-Bernstein_Inequality.html">242 nips-2013-PAC-Bayes-Empirical-Bernstein Inequality</a></p>
<p>19 0.86527085 <a title="127-lda-19" href="./nips-2013-On_the_Expressive_Power_of_Restricted_Boltzmann_Machines.html">221 nips-2013-On the Expressive Power of Restricted Boltzmann Machines</a></p>
<p>20 0.86457568 <a title="127-lda-20" href="./nips-2013-Estimation%2C_Optimization%2C_and_Parallelism_when_Data_is_Sparse.html">111 nips-2013-Estimation, Optimization, and Parallelism when Data is Sparse</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
