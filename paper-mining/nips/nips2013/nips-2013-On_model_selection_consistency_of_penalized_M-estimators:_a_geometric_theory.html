<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>219 nips-2013-On model selection consistency of penalized M-estimators: a geometric theory</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-219" href="#">nips2013-219</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>219 nips-2013-On model selection consistency of penalized M-estimators: a geometric theory</h1>
<br/><p>Source: <a title="nips-2013-219-pdf" href="http://papers.nips.cc/paper/5175-on-model-selection-consistency-of-penalized-m-estimators-a-geometric-theory.pdf">pdf</a></p><p>Author: Jason Lee, Yuekai Sun, Jonathan E. Taylor</p><p>Abstract: Penalized M-estimators are used in diverse areas of science and engineering to Ô¨Åt high-dimensional models with some low-dimensional structure. Often, the penalties are geometrically decomposable, i.e. can be expressed as a sum of support functions over convex sets. We generalize the notion of irrepresentable to geometrically decomposable penalties and develop a general framework for establishing consistency and model selection consistency of M-estimators with such penalties. We then use this framework to derive results for some special cases of interest in bioinformatics and statistical learning. 1</p><p>Reference: <a title="nips-2013-219-reference" href="../nips2013_reference/nips-2013-On_model_selection_consistency_of_penalized_M-estimators%3A_a_geometric_theory_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('lasso', 0.449), ('penal', 0.317), ('decompos', 0.29), ('hb', 0.276), ('hdt', 0.271), ('ha', 0.245), ('irrepres', 0.24), ('geomet', 0.218), ('rp', 0.166), ('pm', 0.153), ('pen', 0.142), ('hc', 0.131), ('negahb', 0.125), ('group', 0.119), ('subspac', 0.115), ('maxg', 0.098), ('relint', 0.09), ('hs', 0.078), ('convex', 0.073), ('ravikum', 0.069)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="219-tfidf-1" href="./nips-2013-On_model_selection_consistency_of_penalized_M-estimators%3A_a_geometric_theory.html">219 nips-2013-On model selection consistency of penalized M-estimators: a geometric theory</a></p>
<p>2 0.39994651 <a title="219-tfidf-2" href="./nips-2013-Model_Selection_for_High-Dimensional_Regression_under_the_Generalized_Irrepresentability_Condition.html">194 nips-2013-Model Selection for High-Dimensional Regression under the Generalized Irrepresentability Condition</a></p>
<p>3 0.29254064 <a title="219-tfidf-3" href="./nips-2013-Estimating_LASSO_Risk_and_Noise_Level.html">109 nips-2013-Estimating LASSO Risk and Noise Level</a></p>
<p>4 0.28276929 <a title="219-tfidf-4" href="./nips-2013-A_Comparative_Framework_for_Preconditioned_Lasso_Algorithms.html">4 nips-2013-A Comparative Framework for Preconditioned Lasso Algorithms</a></p>
<p>5 0.23283283 <a title="219-tfidf-5" href="./nips-2013-Dirty_Statistical_Models.html">91 nips-2013-Dirty Statistical Models</a></p>
<p>6 0.21307343 <a title="219-tfidf-6" href="./nips-2013-Sparse_Overlapping_Sets_Lasso_for_Multitask_Learning_and_its_Application_to_fMRI_Analysis.html">303 nips-2013-Sparse Overlapping Sets Lasso for Multitask Learning and its Application to fMRI Analysis</a></p>
<p>7 0.19477241 <a title="219-tfidf-7" href="./nips-2013-Confidence_Intervals_and_Hypothesis_Testing_for_High-Dimensional_Statistical_Models.html">68 nips-2013-Confidence Intervals and Hypothesis Testing for High-Dimensional Statistical Models</a></p>
<p>8 0.16155128 <a title="219-tfidf-8" href="./nips-2013-Regularized_M-estimators_with_nonconvexity%3A_Statistical_and_algorithmic_theory_for_local_optima.html">271 nips-2013-Regularized M-estimators with nonconvexity: Statistical and algorithmic theory for local optima</a></p>
<p>9 0.15456401 <a title="219-tfidf-9" href="./nips-2013-Lasso_Screening_Rules_via_Dual_Polytope_Projection.html">147 nips-2013-Lasso Screening Rules via Dual Polytope Projection</a></p>
<p>10 0.10679126 <a title="219-tfidf-10" href="./nips-2013-On_the_Linear_Convergence_of_the_Proximal_Gradient_Method_for_Trace_Norm_Regularization.html">222 nips-2013-On the Linear Convergence of the Proximal Gradient Method for Trace Norm Regularization</a></p>
<p>11 0.10606498 <a title="219-tfidf-11" href="./nips-2013-B-test%3A_A_Non-parametric%2C_Low_Variance_Kernel_Two-sample_Test.html">44 nips-2013-B-test: A Non-parametric, Low Variance Kernel Two-sample Test</a></p>
<p>12 0.10501089 <a title="219-tfidf-12" href="./nips-2013-Robust_Multimodal_Graph_Matching%3A_Sparse_Coding_Meets_Graph_Matching.html">282 nips-2013-Robust Multimodal Graph Matching: Sparse Coding Meets Graph Matching</a></p>
<p>13 0.10341523 <a title="219-tfidf-13" href="./nips-2013-A%2A_Lasso_for_Learning_a_Sparse_Bayesian_Network_Structure_for_Continuous_Variables.html">3 nips-2013-A* Lasso for Learning a Sparse Bayesian Network Structure for Continuous Variables</a></p>
<p>14 0.10162622 <a title="219-tfidf-14" href="./nips-2013-Robust_learning_of_low-dimensional_dynamics_from_large_neural_ensembles.html">286 nips-2013-Robust learning of low-dimensional dynamics from large neural ensembles</a></p>
<p>15 0.10039059 <a title="219-tfidf-15" href="./nips-2013-Fantope_Projection_and_Selection%3A_A_near-optimal_convex_relaxation_of_sparse_PCA.html">116 nips-2013-Fantope Projection and Selection: A near-optimal convex relaxation of sparse PCA</a></p>
<p>16 0.090162739 <a title="219-tfidf-16" href="./nips-2013-Probabilistic_Low-Rank_Matrix_Completion_with_Adaptive_Spectral_Regularization_Algorithms.html">254 nips-2013-Probabilistic Low-Rank Matrix Completion with Adaptive Spectral Regularization Algorithms</a></p>
<p>17 0.090058565 <a title="219-tfidf-17" href="./nips-2013-Multiscale_Dictionary_Learning_for_Estimating_Conditional_Distributions.html">204 nips-2013-Multiscale Dictionary Learning for Estimating Conditional Distributions</a></p>
<p>18 0.089527488 <a title="219-tfidf-18" href="./nips-2013-Provable_Subspace_Clustering%3A_When_LRR_meets_SSC.html">259 nips-2013-Provable Subspace Clustering: When LRR meets SSC</a></p>
<p>19 0.082466029 <a title="219-tfidf-19" href="./nips-2013-Better_Approximation_and_Faster_Algorithm_Using_the_Proximal_Average.html">56 nips-2013-Better Approximation and Faster Algorithm Using the Proximal Average</a></p>
<p>20 0.07821393 <a title="219-tfidf-20" href="./nips-2013-When_in_Doubt%2C_SWAP%3A_High-Dimensional_Sparse_Recovery_from_Correlated_Measurements.html">354 nips-2013-When in Doubt, SWAP: High-Dimensional Sparse Recovery from Correlated Measurements</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.183), (1, 0.08), (2, 0.102), (3, 0.007), (4, 0.036), (5, 0.226), (6, -0.123), (7, 0.043), (8, -0.072), (9, 0.225), (10, 0.291), (11, 0.079), (12, -0.099), (13, -0.188), (14, -0.104), (15, 0.14), (16, 0.134), (17, 0.135), (18, -0.008), (19, -0.148), (20, 0.0), (21, -0.03), (22, -0.139), (23, 0.0), (24, 0.113), (25, -0.087), (26, -0.099), (27, 0.005), (28, -0.106), (29, -0.017), (30, -0.063), (31, 0.054), (32, 0.009), (33, 0.026), (34, -0.024), (35, 0.061), (36, -0.014), (37, -0.032), (38, 0.001), (39, -0.016), (40, 0.013), (41, 0.046), (42, -0.02), (43, -0.018), (44, 0.026), (45, 0.055), (46, 0.068), (47, 0.089), (48, 0.05), (49, -0.059)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95848912 <a title="219-lsi-1" href="./nips-2013-On_model_selection_consistency_of_penalized_M-estimators%3A_a_geometric_theory.html">219 nips-2013-On model selection consistency of penalized M-estimators: a geometric theory</a></p>
<p>2 0.84076786 <a title="219-lsi-2" href="./nips-2013-Sparse_Overlapping_Sets_Lasso_for_Multitask_Learning_and_its_Application_to_fMRI_Analysis.html">303 nips-2013-Sparse Overlapping Sets Lasso for Multitask Learning and its Application to fMRI Analysis</a></p>
<p>3 0.82247585 <a title="219-lsi-3" href="./nips-2013-Model_Selection_for_High-Dimensional_Regression_under_the_Generalized_Irrepresentability_Condition.html">194 nips-2013-Model Selection for High-Dimensional Regression under the Generalized Irrepresentability Condition</a></p>
<p>4 0.81052643 <a title="219-lsi-4" href="./nips-2013-A_Comparative_Framework_for_Preconditioned_Lasso_Algorithms.html">4 nips-2013-A Comparative Framework for Preconditioned Lasso Algorithms</a></p>
<p>5 0.7384935 <a title="219-lsi-5" href="./nips-2013-Estimating_LASSO_Risk_and_Noise_Level.html">109 nips-2013-Estimating LASSO Risk and Noise Level</a></p>
<p>6 0.63373619 <a title="219-lsi-6" href="./nips-2013-A%2A_Lasso_for_Learning_a_Sparse_Bayesian_Network_Structure_for_Continuous_Variables.html">3 nips-2013-A* Lasso for Learning a Sparse Bayesian Network Structure for Continuous Variables</a></p>
<p>7 0.58675748 <a title="219-lsi-7" href="./nips-2013-Confidence_Intervals_and_Hypothesis_Testing_for_High-Dimensional_Statistical_Models.html">68 nips-2013-Confidence Intervals and Hypothesis Testing for High-Dimensional Statistical Models</a></p>
<p>8 0.57454491 <a title="219-lsi-8" href="./nips-2013-When_in_Doubt%2C_SWAP%3A_High-Dimensional_Sparse_Recovery_from_Correlated_Measurements.html">354 nips-2013-When in Doubt, SWAP: High-Dimensional Sparse Recovery from Correlated Measurements</a></p>
<p>9 0.51689142 <a title="219-lsi-9" href="./nips-2013-Lasso_Screening_Rules_via_Dual_Polytope_Projection.html">147 nips-2013-Lasso Screening Rules via Dual Polytope Projection</a></p>
<p>10 0.51409274 <a title="219-lsi-10" href="./nips-2013-Dirty_Statistical_Models.html">91 nips-2013-Dirty Statistical Models</a></p>
<p>11 0.49305713 <a title="219-lsi-11" href="./nips-2013-Regularized_M-estimators_with_nonconvexity%3A_Statistical_and_algorithmic_theory_for_local_optima.html">271 nips-2013-Regularized M-estimators with nonconvexity: Statistical and algorithmic theory for local optima</a></p>
<p>12 0.47441575 <a title="219-lsi-12" href="./nips-2013-Polar_Operators_for_Structured_Sparse_Estimation.html">249 nips-2013-Polar Operators for Structured Sparse Estimation</a></p>
<p>13 0.43482798 <a title="219-lsi-13" href="./nips-2013-Multiscale_Dictionary_Learning_for_Estimating_Conditional_Distributions.html">204 nips-2013-Multiscale Dictionary Learning for Estimating Conditional Distributions</a></p>
<p>14 0.42247945 <a title="219-lsi-14" href="./nips-2013-Reconciling_%22priors%22_%26_%22priors%22_without_prejudice%3F.html">265 nips-2013-Reconciling "priors" & "priors" without prejudice?</a></p>
<p>15 0.3521834 <a title="219-lsi-15" href="./nips-2013-On_the_Linear_Convergence_of_the_Proximal_Gradient_Method_for_Trace_Norm_Regularization.html">222 nips-2013-On the Linear Convergence of the Proximal Gradient Method for Trace Norm Regularization</a></p>
<p>16 0.34766236 <a title="219-lsi-16" href="./nips-2013-Fantope_Projection_and_Selection%3A_A_near-optimal_convex_relaxation_of_sparse_PCA.html">116 nips-2013-Fantope Projection and Selection: A near-optimal convex relaxation of sparse PCA</a></p>
<p>17 0.33955592 <a title="219-lsi-17" href="./nips-2013-Provable_Subspace_Clustering%3A_When_LRR_meets_SSC.html">259 nips-2013-Provable Subspace Clustering: When LRR meets SSC</a></p>
<p>18 0.33946386 <a title="219-lsi-18" href="./nips-2013-Better_Approximation_and_Faster_Algorithm_Using_the_Proximal_Average.html">56 nips-2013-Better Approximation and Faster Algorithm Using the Proximal Average</a></p>
<p>19 0.32654077 <a title="219-lsi-19" href="./nips-2013-New_Subsampling_Algorithms_for_Fast_Least_Squares_Regression.html">209 nips-2013-New Subsampling Algorithms for Fast Least Squares Regression</a></p>
<p>20 0.30724919 <a title="219-lsi-20" href="./nips-2013-Graphical_Models_for_Inference_with_Missing_Data.html">134 nips-2013-Graphical Models for Inference with Missing Data</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(12, 0.143), (20, 0.205), (25, 0.1), (37, 0.105), (57, 0.068), (70, 0.069), (80, 0.077), (86, 0.064), (87, 0.07)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.89715743 <a title="219-lda-1" href="./nips-2013-On_model_selection_consistency_of_penalized_M-estimators%3A_a_geometric_theory.html">219 nips-2013-On model selection consistency of penalized M-estimators: a geometric theory</a></p>
<p>2 0.87222707 <a title="219-lda-2" href="./nips-2013-The_Randomized_Dependence_Coefficient.html">327 nips-2013-The Randomized Dependence Coefficient</a></p>
<p>3 0.86114079 <a title="219-lda-3" href="./nips-2013-Distributed_Submodular_Maximization%3A_Identifying_Representative_Elements_in_Massive_Data.html">97 nips-2013-Distributed Submodular Maximization: Identifying Representative Elements in Massive Data</a></p>
<p>4 0.85904813 <a title="219-lda-4" href="./nips-2013-A_Novel_Two-Step_Method_for_Cross_Language_Representation_Learning.html">12 nips-2013-A Novel Two-Step Method for Cross Language Representation Learning</a></p>
<p>5 0.85278773 <a title="219-lda-5" href="./nips-2013-When_in_Doubt%2C_SWAP%3A_High-Dimensional_Sparse_Recovery_from_Correlated_Measurements.html">354 nips-2013-When in Doubt, SWAP: High-Dimensional Sparse Recovery from Correlated Measurements</a></p>
<p>6 0.84538913 <a title="219-lda-6" href="./nips-2013-Reflection_methods_for_user-friendly_submodular_optimization.html">268 nips-2013-Reflection methods for user-friendly submodular optimization</a></p>
<p>7 0.84437722 <a title="219-lda-7" href="./nips-2013-When_are_Overcomplete_Topic_Models_Identifiable%3F_Uniqueness_of_Tensor_Tucker_Decompositions_with_Structured_Sparsity.html">353 nips-2013-When are Overcomplete Topic Models Identifiable? Uniqueness of Tensor Tucker Decompositions with Structured Sparsity</a></p>
<p>8 0.84417802 <a title="219-lda-8" href="./nips-2013-Generalized_Random_Utility_Models_with_Multiple_Types.html">129 nips-2013-Generalized Random Utility Models with Multiple Types</a></p>
<p>9 0.84290308 <a title="219-lda-9" href="./nips-2013-B-test%3A_A_Non-parametric%2C_Low_Variance_Kernel_Two-sample_Test.html">44 nips-2013-B-test: A Non-parametric, Low Variance Kernel Two-sample Test</a></p>
<p>10 0.84080487 <a title="219-lda-10" href="./nips-2013-Sparse_Overlapping_Sets_Lasso_for_Multitask_Learning_and_its_Application_to_fMRI_Analysis.html">303 nips-2013-Sparse Overlapping Sets Lasso for Multitask Learning and its Application to fMRI Analysis</a></p>
<p>11 0.84060585 <a title="219-lda-11" href="./nips-2013-Capacity_of_strong_attractor_patterns_to_model_behavioural_and_cognitive_prototypes.html">61 nips-2013-Capacity of strong attractor patterns to model behavioural and cognitive prototypes</a></p>
<p>12 0.83913833 <a title="219-lda-12" href="./nips-2013-A_Kernel_Test_for_Three-Variable_Interactions.html">9 nips-2013-A Kernel Test for Three-Variable Interactions</a></p>
<p>13 0.83913028 <a title="219-lda-13" href="./nips-2013-Multiclass_Total_Variation_Clustering.html">202 nips-2013-Multiclass Total Variation Clustering</a></p>
<p>14 0.83746034 <a title="219-lda-14" href="./nips-2013-Trading_Computation_for_Communication%3A_Distributed_Stochastic_Dual_Coordinate_Ascent.html">333 nips-2013-Trading Computation for Communication: Distributed Stochastic Dual Coordinate Ascent</a></p>
<p>15 0.83718961 <a title="219-lda-15" href="./nips-2013-Learning_Multi-level_Sparse_Representations.html">157 nips-2013-Learning Multi-level Sparse Representations</a></p>
<p>16 0.83682203 <a title="219-lda-16" href="./nips-2013-Variational_Inference_for_Mahalanobis_Distance_Metrics_in_Gaussian_Process_Regression.html">346 nips-2013-Variational Inference for Mahalanobis Distance Metrics in Gaussian Process Regression</a></p>
<p>17 0.83662808 <a title="219-lda-17" href="./nips-2013-Sensor_Selection_in_High-Dimensional_Gaussian_Trees_with_Nuisances.html">291 nips-2013-Sensor Selection in High-Dimensional Gaussian Trees with Nuisances</a></p>
<p>18 0.83514416 <a title="219-lda-18" href="./nips-2013-Recurrent_networks_of_coupled_Winner-Take-All_oscillators_for_solving_constraint_satisfaction_problems.html">267 nips-2013-Recurrent networks of coupled Winner-Take-All oscillators for solving constraint satisfaction problems</a></p>
<p>19 0.83497947 <a title="219-lda-19" href="./nips-2013-Submodular_Optimization_with_Submodular_Cover_and_Submodular_Knapsack_Constraints.html">319 nips-2013-Submodular Optimization with Submodular Cover and Submodular Knapsack Constraints</a></p>
<p>20 0.83461243 <a title="219-lda-20" href="./nips-2013-Better_Approximation_and_Faster_Algorithm_Using_the_Proximal_Average.html">56 nips-2013-Better Approximation and Faster Algorithm Using the Proximal Average</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
