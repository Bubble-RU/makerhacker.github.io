<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>318 nips-2013-Structured Learning via Logistic Regression</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-318" href="#">nips2013-318</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>318 nips-2013-Structured Learning via Logistic Regression</h1>
<br/><p>Source: <a title="nips-2013-318-pdf" href="http://papers.nips.cc/paper/4870-structured-learning-via-logistic-regression.pdf">pdf</a></p><p>Author: Justin Domke</p><p>Abstract: A successful approach to structured learning is to write the learning objective as a joint function of linear parameters and inference messages, and iterate between updates to each. This paper observes that if the inference problem is “smoothed” through the addition of entropy terms, for ﬁxed messages, the learning objective reduces to a traditional (non-structured) logistic regression problem with respect to parameters. In these logistic regression problems, each training example has a bias term determined by the current set of messages. Based on this insight, the structured energy function can be extended from linear factors to any function class where an “oracle” exists to minimize a logistic loss.</p><p>Reference: <a title="nips-2013-318-reference" href="../nips2013_reference/nips-2013-Structured_Learning_via_Logistic_Regression_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 au  Abstract A successful approach to structured learning is to write the learning objective as a joint function of linear parameters and inference messages, and iterate between updates to each. [sent-4, score-0.3]
</p><p>2 This paper observes that if the inference problem is “smoothed” through the addition of entropy terms, for ﬁxed messages, the learning objective reduces to a traditional (non-structured) logistic regression problem with respect to parameters. [sent-5, score-0.529]
</p><p>3 In these logistic regression problems, each training example has a bias term determined by the current set of messages. [sent-6, score-0.381]
</p><p>4 Based on this insight, the structured energy function can be extended from linear factors to any function class where an “oracle” exists to minimize a logistic loss. [sent-7, score-0.467]
</p><p>5 1 Introduction The structured learning problem is to ﬁnd a function F (x, y) to map from inputs x to outputs as y ∗ = arg maxy F (x, y). [sent-8, score-0.156]
</p><p>6 F is chosen to optimize a loss function deﬁned on these outputs. [sent-9, score-0.133]
</p><p>7 A major challenge is that evaluating the loss for a given function F requires solving the inference optimization to ﬁnd the highest-scoring output y for each exemplar, which is NP-hard in general. [sent-10, score-0.19]
</p><p>8 A standard solution to this is to write the loss function using an LP-relaxation of the inference problem, meaning an upper-bound on the true loss. [sent-11, score-0.19]
</p><p>9 The learning problem can then be phrased as a joint optimization of parameters and inference variables, which can be solved, e. [sent-12, score-0.117]
</p><p>10 , by alternating message-passing updates to inference variables with gradient descent updates to parameters [16, 9]. [sent-14, score-0.353]
</p><p>11 Previous work has mostly focused on linear energy functions F (x, y) = wT Φ(x, y), where a vector of weights w is adjusted in learning, and Φ(x, y) = α Φ(x, yα ) decomposes over subsets of variables yα . [sent-15, score-0.327]
</p><p>12 ensembles of trees [20, 8, 25, 13, 24, 18, 19] or multi-layer perceptrons [10, 21]) to predict each variable independently. [sent-19, score-0.165]
</p><p>13 The learning problem is to select fα from some set of functions Fα . [sent-22, score-0.099]
</p><p>14 Here, following previous work [15], we add entropy smoothing to the LP-relaxation of the inference problem. [sent-23, score-0.194]
</p><p>15 Again, this leads to phrasing the learning problem as a joint optimization of learning and inference variables, alternating between message-passing updates to inference variables and optimization of the functions fα . [sent-24, score-0.456]
</p><p>16 The major result is that minimization of the loss over fα ∈ Fα can be re-formulated as a logistic regression problem, with a “bias” vector added to each example reﬂecting the current messages incoming to factor α. [sent-25, score-0.679]
</p><p>17 No assumptions are needed on the sets of functions Fα , beyond assuming that an algorithm exists to optimize the logistic loss on a given dataset over all fα ∈ Fα We experimentally test the results of varying Fα to be the set of linear functions, multi-layer perceptrons, or boosted decision trees. [sent-26, score-0.571]
</p><p>18 1  2 Structured Prediction The structured prediction problem can be written as seeking a function h that will predict an output y from an input x. [sent-28, score-0.086]
</p><p>19 Most commonly, it can be written in the form h(x; w) = arg max wT Φ(x, y),  (1)  y  where Φ is a ﬁxed function of both x and y. [sent-29, score-0.145]
</p><p>20 It is further assumed that Φ decomposes into a sum of functions evaluated over subsets of variables yα as Φ(x, y) = Φα (x, yα ). [sent-31, score-0.149]
</p><p>21 This paper considers the structured learning problem in a more general setting, directly handling nonlinear function classes. [sent-33, score-0.086]
</p><p>22 We generalize the function h to h(x; F ) = arg max F (x, y), y  where the energy F again decomposes as F (x, y) =  fα (x, yα ). [sent-34, score-0.372]
</p><p>23 α  The learning problem now becomes to select {fα ∈ Fα } for some set of functions Fα . [sent-35, score-0.099]
</p><p>24 Here, we do not make any assumption on the class of functions Fα other than assuming that there exists an algorithm to ﬁnd the best function fα ∈ Fα in terms of the logistic regression loss (Section 6). [sent-37, score-0.42]
</p><p>25 , (xN , y N ), we wish to select the energy F to minimize the empirical risk l(xk , y k ; F ),  R(F ) =  (2)  k  for some loss function l. [sent-41, score-0.25]
</p><p>26 Absent computational concerns, a standard choice would be the slackrescaled loss [22] l0 (xk , y k ; F ) = max F (xk , y) − F (xk , y k ) + ∆(y k , y),  (3)  y  where ∆(y k , y) is some measure of discrepancy. [sent-42, score-0.148]
</p><p>27 We assume that ∆ is a function that decomposes k over α, (i. [sent-43, score-0.089]
</p><p>28 If this inference problem must be solved approximately, there is strong motivation [6] for using relaxations of the maximization in Eq. [sent-49, score-0.198]
</p><p>29 It is easy to show that l1 ≥ l0 , since the two would be equivalent if µ were restricted to binary values, and hence the maximization in l1 takes place over a larger set [6]. [sent-53, score-0.081]
</p><p>30 The maximization in l1 is of a linear objective under linear constraints, and is thus a linear program (LP), solvable in polynomial time using a generic LP solver. [sent-56, score-0.201]
</p><p>31 Here, we make a further approximation to the loss, replacing the inference problem of maxµ∈M θ ·µ with the “smoothed” problem maxµ∈M θ · µ + α H(µα ), where H(µα ) is the entropy of the marginals µα . [sent-58, score-0.194]
</p><p>32 The relaxed loss is l(xk , y k ; F ) = −F (xk , y k ) + max  µ∈M  k θF · µ +  H(µα ) . [sent-61, score-0.148]
</p><p>33 A similar result was previously given [15] bounding the difference of the objective obtained by inference with and without entropy smoothing. [sent-66, score-0.194]
</p><p>34 α  4 Overview Now, the learning problem is to select the functions fα composing F to minimize R as deﬁned in Eq. [sent-69, score-0.14]
</p><p>35 Inspired by previous work [16, 9], our solution (Section 5) is to introduce a vector of “messages” λ to write A in the dual form A(θ) = min A(λ, θ), λ  which leads to phrasing learning as the joint minimization k −F (xk , y k ) + A(λk , θF ) . [sent-74, score-0.158]
</p><p>36 For ﬁxed F , messagepassing can be used to perform coordinate ascent updates to all the messages λk (Section 5). [sent-76, score-0.305]
</p><p>37 These updates are trivially parallelized with respect to k. [sent-77, score-0.093]
</p><p>38 However, the problem remains, for ﬁxed messages, how to optimize the functions fα composing F . [sent-78, score-0.161]
</p><p>39 Section 7 observes that this problem can be re-formulated into a (non-structured) logistic regression problem, with “bias” terms added to each example that reﬂect the current messages into factor α. [sent-79, score-0.619]
</p><p>40 5 Inference In order to evaluate the loss, it is necessary to solve the maximization in Eq. [sent-80, score-0.081]
</p><p>41 For a given θ, consider doing inference over µ, that is, in solving the maximization in Eq. [sent-82, score-0.198]
</p><p>42 Standard Lagrangian duality theory gives the following dual representation for A(θ) in terms of “messages” λα (xβ ) from a region α to a subregion β ⊂ α, a variant of the representation of Heskes [11]. [sent-84, score-0.096]
</p><p>43 3  Algorithm 1 Reducing structured learning to logistic regression. [sent-85, score-0.289]
</p><p>44 For all k, for all α, set the bias term to  1 k bk (y α ) ← ∆(yα , y α ) + α  λk (yβ ) − α γ⊃α  β⊂α  2. [sent-88, score-0.293]
</p><p>45 For all α, solve the logistic regression problem    λk (yα ) . [sent-89, score-0.287]
</p><p>46 γ  K fα ∈Fα  exp fα (xk , yα ) + bk (yα ) α  k k fα (xk , yα ) + bk (yα ) − log α  fα ← arg max  . [sent-90, score-0.727]
</p><p>47 A(θ) can be represented in the dual form A(θ) = minλ A(λ, θ), where A(λ, θ) = max θ · µ +  λα (xβ ) (µαβ (yβ ) − µβ (yβ )) ,  H(µα ) +  µ∈N  α  (8)  α β⊂α xβ  and N = {µ| yα µα (yα ) = 1, µα (yα ) ≥ 0} is the set of locally normalized pseudomarginals. [sent-97, score-0.139]
</p><p>48 Thus, for any set of messages λ, there is an easily-evaluated upper-bound A(λ, θ) ≥ A(θ), and when A(λ, θ) is minimized with respect to λ, this bound is tight. [sent-99, score-0.248]
</p><p>49 In our experiments, we use blocks consisting of the set of all messages λα (yν ) for all regions α containing ν. [sent-102, score-0.248]
</p><p>50 When the graph only contains regions for single variables and pairs, this is a “star update” of all the messages from pairs that contain a variable i. [sent-103, score-0.248]
</p><p>51 It can be shown [11, 15] that the update is λα (yν ) ← λα (yν ) +  1 + Nν  log µα (yν )) − log µα (yν ),  (log µν (yν ) +  (10)  α ⊃ν  for all α ⊃ ν, where Nν = |{α|α ⊃ ν}|. [sent-104, score-0.082]
</p><p>52 6 Logistic Regression Logistic regression is traditionally understood as deﬁning a conditional distribution p(y|x; W ) = exp ((W x)y ) /Z(x) where W is a matrix that maps the input features x to a vector of margins W x. [sent-107, score-0.18]
</p><p>53 It is easy to show that the maximum conditional likelihood training problem maxW k log p(y k |xk ; W ) is equivalent to (W xk )yk − log  max W  exp(W xk )y . [sent-108, score-1.03]
</p><p>54 ) Secondly, we assume that there is a pre-determined “bias” vector bk associated with each training example. [sent-112, score-0.289]
</p><p>55 This yields the learning problem f (xk , y k ) + bk (y k ) − log  max f ∈F  exp f (xk , y) + bk (y)  (11)  ,  y  k  Aside from linear logistic regression, one can see decision trees, multi-layer perceptrons, and boosted ensembles under an appropriate loss as solving Eq. [sent-113, score-1.152]
</p><p>56 11 for different sets of functions F (albeit possibly to a local maximum). [sent-114, score-0.099]
</p><p>57 7 Training Recall that the learning problem is to select the functions fα ∈ Fα so as to minimize the empirical k risk R(F ) = k [−F (xk , y k ) + A(θF )]. [sent-115, score-0.099]
</p><p>58 12, we alternating between optimization of messages {λk } and energy functions k {fα }. [sent-119, score-0.492]
</p><p>59 Optimization with respect to λk for ﬁxed F decomposes into minimizing A(λk , θF ) indepenk dently for each y , which can be done by running message-passing updates as in Section 5 using the k parameter vector θF . [sent-120, score-0.146]
</p><p>60 ρ  is the minimizer of Eq 12 for ﬁxed messages λ, then  ∗ fα = arg max fα  k k fα (xk , yα ) + bk (yα ) − log α  exp fα (xk , yα ) + bk (yα ) α  ,  (13)  yα  k  where the set of biases are deﬁned as  1 k ∆(yα , y α ) + bk (y α ) = α  λα (yβ ) − β⊂α  γ⊃α    λγ (yα ) . [sent-128, score-1.219]
</p><p>61 α  + α β⊂α xβ  Using the deﬁnition of bk from Eq. [sent-133, score-0.244]
</p><p>62 Applying Lemma 3 to the inner maximization gives the closed-form expression k A(λk , θF ) =  log α  exp  1  fα (x, yα ) + bα (yα ) . [sent-193, score-0.175]
</p><p>63 For example, it is common to model image segmentation problems using a 4-connected grid with an energy like F (x, y) = i u(φi , yi ) + v(φij , yi , yj ), where φi /φij are univariate/pairwise features determined by x, and u and v ij are functions mapping local features to local energies. [sent-203, score-0.928]
</p><p>64 In this case, u would be selected to maxk k imize k i u(φk , yi ) + bk (yi ) − log yi exp u(φk , yi ) + bk (yi ) , and analogous expresi i i i sion exists for v. [sent-204, score-0.897]
</p><p>65 8 Experiments  These experiments consider three different function classes: linear, boosted decision trees, and multi-layer perceptrons. [sent-206, score-0.135]
</p><p>66 11 under linear functions f (x, y) = (W x)y , we simply compute the gradient with respect to W and use batch L-BFGS. [sent-208, score-0.176]
</p><p>67 Boosted decision trees use stochastic gradient boosting [7]: the gradient of the logistic loss is computed for each exemplar, and a regression tree is induced to ﬁt this (one tree for each class). [sent-212, score-0.965]
</p><p>68 Then, an optimization adjusts the values of leaf nodes to optimize the logistic loss. [sent-214, score-0.31]
</p><p>69 Finally, the tree values are multiplied by 2  At each time, the new step is a combination of . [sent-215, score-0.087]
</p><p>70 8  ij  yij=(2,1) yij=(2,2)  0  ij  0  −100 0  1  1  y =(1,1)  50  yij=(2,1) f  ij  f 0. [sent-226, score-0.483]
</p><p>71 2  100  y =(1,2)  ij  yij=(2,2) fij  −400 0  1  y =(1,1)  ij  y =(1,2) 50  0  i  0  −200  0. [sent-233, score-0.467]
</p><p>72 2  i  200  f  i  f  fi  −200  y =2  i  200  0  −400 0  yi=1  y =2  i  200  400  yi=1  −50  0. [sent-234, score-0.085]
</p><p>73 8  1  MLP  Figure 1: The univariate (top) and pairwise (bottom) energy functions learned on denoising data. [sent-242, score-0.431]
</p><p>74 Each column shows the result of training both univariate and pairwise terms with one function class. [sent-243, score-0.2]
</p><p>75 2  0 0  Horses  Linear  10 20 Iteration  0  10 20 Iteration  0  10 20 Iteration  Figure 2: Dashed/Solid lines show univariate train/test error rates as a function of learning iterations for varying univariate (rows) and pairwise (columns) classiﬁers. [sent-256, score-0.3]
</p><p>76 Each learning iteration consists of updating fi , performing 25 iterations of message passing, updating fij , and then performing another 25 iterations of message-passing. [sent-262, score-0.515]
</p><p>77 Next, if yi = 0, φk i k is sampled uniformly from [0, . [sent-266, score-0.105]
</p><p>78 Finally, for a pair i k k k k (i, j), if yi = yj , then φk is sampled from [0, . [sent-269, score-0.15]
</p><p>79 A ij k k constant feature is also added to both φi and φij . [sent-272, score-0.197]
</p><p>80 Finally, because there is only a single input feature for univariate and pairwise terms, the resulting functions are plotted in Fig. [sent-279, score-0.215]
</p><p>81 Second, as a more realistic example, we use the Weizmann horses dataset. [sent-281, score-0.128]
</p><p>82 We use 42 univariate features fik consisting of a constant (1) the RBG values of the pixel (3), the vertical and horizontal position (2) and a histogram of gradients [2] (36). [sent-282, score-0.155]
</p><p>83 9 Discussion This paper observes that in the structured learning setting, the optimization with respect to energy can be formulated as a logistic regression problem for each factor, “biased” by the current messages. [sent-286, score-0.559]
</p><p>84 Thus, it is possible to use any function class where an “oracle” exists to optimize a logistic loss. [sent-287, score-0.263]
</p><p>85 Besides the possibility of using more general classes of energies, another advantage of the proposed method is the “software engineering” beneﬁt of having the algorithm for ﬁtting the energy modularized from the rest of the learning procedure. [sent-288, score-0.138]
</p><p>86 The ability to easily deﬁne new energy functions for individual problems could have practical impact. [sent-289, score-0.198]
</p><p>87 In related work, Hazan and Urtasun [9] use a linear energy, and alternate between updating all inference variables and a gradient descent update to parameters, using an entropy-smoothed inference objective. [sent-291, score-0.402]
</p><p>88 [16] also use a linear energy, with a stochastic algorithm updating inference variables and taking a stochastic gradient step on parameters for one exemplar at a time, with a pure LP-relaxation of inference. [sent-293, score-0.358]
</p><p>89 The proposed method iterates between updating all inference variables and performing a full optimization of the energy. [sent-294, score-0.207]
</p><p>90 In practice, however, inference is easily parallelized over the data, and the majority of computational time is spent in the logistic regression subproblems. [sent-296, score-0.44]
</p><p>91 Another related work is Gradient Tree Boosting [4] in which to train a CRF, the functional gradient of the conditional likelihood is computed, and a regression tree is induced. [sent-298, score-0.247]
</p><p>92 The main limitation is the assumption that inference can be solved exactly. [sent-300, score-0.117]
</p><p>93 It appears possible to extend this to inexact inference, where the tree is induced to improve a dual bound, but this has not been done so far. [sent-301, score-0.151]
</p><p>94 Experimentally, however, simply inducing a tree on the loss gradient leads to much slower learning if the leaf nodes are not modiﬁed to optimize the logistic loss. [sent-302, score-0.546]
</p><p>95 Thus, it is likely that such a strategy would still beneﬁt from using the logistic regression reformulation. [sent-303, score-0.287]
</p><p>96 Efﬁcient learning of structured predictors in general graphical models. [sent-334, score-0.086]
</p><p>97 Convexity arguments for efﬁcient minimization of the bethe and kikuchi free energies. [sent-343, score-0.085]
</p><p>98 On parameter learning in CRF-based approaches to object class image segmentation. [sent-374, score-0.089]
</p><p>99 Textonboost for image understanding: Multi-class object recognition and segmentation by jointly modeling texture, layout, and context. [sent-384, score-0.193]
</p><p>100 Scene segmentation with crfs learned from partially labeled images. [sent-394, score-0.157]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('xk', 0.414), ('mlp', 0.249), ('messages', 0.248), ('bk', 0.244), ('logistic', 0.203), ('boosting', 0.187), ('ij', 0.161), ('meshi', 0.147), ('fij', 0.145), ('energy', 0.138), ('yij', 0.128), ('horses', 0.128), ('inference', 0.117), ('univariate', 0.112), ('yi', 0.105), ('segmentation', 0.104), ('boosted', 0.091), ('decomposes', 0.089), ('tree', 0.087), ('structured', 0.086), ('fi', 0.085), ('regression', 0.084), ('maximization', 0.081), ('denoising', 0.078), ('entropy', 0.077), ('gradient', 0.076), ('max', 0.075), ('loss', 0.073), ('perceptrons', 0.073), ('exemplar', 0.073), ('pseudomarginals', 0.072), ('rbg', 0.072), ('arg', 0.07), ('dual', 0.064), ('optimize', 0.06), ('functions', 0.06), ('justin', 0.059), ('phrasing', 0.059), ('urtasun', 0.059), ('updates', 0.057), ('er', 0.056), ('classi', 0.056), ('jamie', 0.055), ('pushmeet', 0.055), ('rother', 0.055), ('iccv', 0.055), ('exp', 0.053), ('carsten', 0.053), ('crfs', 0.053), ('hmax', 0.053), ('updating', 0.052), ('bethe', 0.05), ('nowozin', 0.05), ('bias', 0.049), ('antonio', 0.048), ('trees', 0.048), ('observes', 0.048), ('hazan', 0.047), ('leaf', 0.047), ('ofer', 0.047), ('daphne', 0.047), ('alternating', 0.046), ('image', 0.046), ('tommi', 0.045), ('winn', 0.045), ('layout', 0.045), ('yj', 0.045), ('training', 0.045), ('decision', 0.044), ('ensembles', 0.044), ('features', 0.043), ('object', 0.043), ('marginalized', 0.043), ('pairwise', 0.043), ('ers', 0.042), ('amir', 0.042), ('sebastian', 0.042), ('composing', 0.041), ('log', 0.041), ('linear', 0.04), ('ijcv', 0.04), ('local', 0.039), ('iteration', 0.039), ('select', 0.039), ('wt', 0.038), ('performing', 0.038), ('jaakkola', 0.037), ('parallelized', 0.036), ('added', 0.036), ('minimization', 0.035), ('smoothed', 0.034), ('iterations', 0.033), ('stephen', 0.033), ('lp', 0.032), ('custom', 0.032), ('heskes', 0.032), ('deva', 0.032), ('elidan', 0.032), ('gal', 0.032), ('subregion', 0.032)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="318-tfidf-1" href="./nips-2013-Structured_Learning_via_Logistic_Regression.html">318 nips-2013-Structured Learning via Logistic Regression</a></p>
<p>Author: Justin Domke</p><p>Abstract: A successful approach to structured learning is to write the learning objective as a joint function of linear parameters and inference messages, and iterate between updates to each. This paper observes that if the inference problem is “smoothed” through the addition of entropy terms, for ﬁxed messages, the learning objective reduces to a traditional (non-structured) logistic regression problem with respect to parameters. In these logistic regression problems, each training example has a bias term determined by the current set of messages. Based on this insight, the structured energy function can be extended from linear factors to any function class where an “oracle” exists to minimize a logistic loss.</p><p>2 0.15025586 <a title="318-tfidf-2" href="./nips-2013-Projected_Natural_Actor-Critic.html">257 nips-2013-Projected Natural Actor-Critic</a></p>
<p>Author: Philip S. Thomas, William C. Dabney, Stephen Giguere, Sridhar Mahadevan</p><p>Abstract: Natural actor-critics form a popular class of policy search algorithms for ﬁnding locally optimal policies for Markov decision processes. In this paper we address a drawback of natural actor-critics that limits their real-world applicability—their lack of safety guarantees. We present a principled algorithm for performing natural gradient descent over a constrained domain. In the context of reinforcement learning, this allows for natural actor-critic algorithms that are guaranteed to remain within a known safe region of policy space. While deriving our class of constrained natural actor-critic algorithms, which we call Projected Natural ActorCritics (PNACs), we also elucidate the relationship between natural gradient descent and mirror descent. 1</p><p>3 0.13844207 <a title="318-tfidf-3" href="./nips-2013-Latent_Structured_Active_Learning.html">149 nips-2013-Latent Structured Active Learning</a></p>
<p>Author: Wenjie Luo, Alex Schwing, Raquel Urtasun</p><p>Abstract: In this paper we present active learning algorithms in the context of structured prediction problems. To reduce the amount of labeling necessary to learn good models, our algorithms operate with weakly labeled data and we query additional examples based on entropies of local marginals, which are a good surrogate for uncertainty. We demonstrate the effectiveness of our approach in the task of 3D layout prediction from single images, and show that good models are learned when labeling only a handful of random variables. In particular, the same performance as using the full training set can be obtained while only labeling ∼10% of the random variables. 1</p><p>4 0.12452736 <a title="318-tfidf-4" href="./nips-2013-Learning_to_Pass_Expectation_Propagation_Messages.html">168 nips-2013-Learning to Pass Expectation Propagation Messages</a></p>
<p>Author: Nicolas Heess, Daniel Tarlow, John Winn</p><p>Abstract: Expectation Propagation (EP) is a popular approximate posterior inference algorithm that often provides a fast and accurate alternative to sampling-based methods. However, while the EP framework in theory allows for complex nonGaussian factors, there is still a signiﬁcant practical barrier to using them within EP, because doing so requires the implementation of message update operators, which can be difﬁcult and require hand-crafted approximations. In this work, we study the question of whether it is possible to automatically derive fast and accurate EP updates by learning a discriminative model (e.g., a neural network or random forest) to map EP message inputs to EP message outputs. We address the practical concerns that arise in the process, and we provide empirical analysis on several challenging and diverse factors, indicating that there is a space of factors where this approach appears promising. 1</p><p>5 0.11705869 <a title="318-tfidf-5" href="./nips-2013-Non-Linear_Domain_Adaptation_with_Boosting.html">211 nips-2013-Non-Linear Domain Adaptation with Boosting</a></p>
<p>Author: Carlos J. Becker, Christos M. Christoudias, Pascal Fua</p><p>Abstract: A common assumption in machine vision is that the training and test samples are drawn from the same distribution. However, there are many problems when this assumption is grossly violated, as in bio-medical applications where different acquisitions can generate drastic variations in the appearance of the data due to changing experimental conditions. This problem is accentuated with 3D data, for which annotation is very time-consuming, limiting the amount of data that can be labeled in new acquisitions for training. In this paper we present a multitask learning algorithm for domain adaptation based on boosting. Unlike previous approaches that learn task-speciﬁc decision boundaries, our method learns a single decision boundary in a shared feature space, common to all tasks. We use the boosting-trick to learn a non-linear mapping of the observations in each task, with no need for speciﬁc a-priori knowledge of its global analytical form. This yields a more parameter-free domain adaptation approach that successfully leverages learning on new tasks where labeled data is scarce. We evaluate our approach on two challenging bio-medical datasets and achieve a signiﬁcant improvement over the state of the art. 1</p><p>6 0.1160751 <a title="318-tfidf-6" href="./nips-2013-On_Algorithms_for_Sparse_Multi-factor_NMF.html">214 nips-2013-On Algorithms for Sparse Multi-factor NMF</a></p>
<p>7 0.10958635 <a title="318-tfidf-7" href="./nips-2013-Learning_Adaptive_Value_of_Information_for_Structured_Prediction.html">150 nips-2013-Learning Adaptive Value of Information for Structured Prediction</a></p>
<p>8 0.10503943 <a title="318-tfidf-8" href="./nips-2013-Discriminative_Transfer_Learning_with_Tree-based_Priors.html">93 nips-2013-Discriminative Transfer Learning with Tree-based Priors</a></p>
<p>9 0.1034807 <a title="318-tfidf-9" href="./nips-2013-Projecting_Ising_Model_Parameters_for_Fast_Mixing.html">258 nips-2013-Projecting Ising Model Parameters for Fast Mixing</a></p>
<p>10 0.10100085 <a title="318-tfidf-10" href="./nips-2013-Information-theoretic_lower_bounds_for_distributed_statistical_estimation_with_communication_constraints.html">142 nips-2013-Information-theoretic lower bounds for distributed statistical estimation with communication constraints</a></p>
<p>11 0.099624187 <a title="318-tfidf-11" href="./nips-2013-Direct_0-1_Loss_Minimization_and_Margin_Maximization_with_Boosting.html">90 nips-2013-Direct 0-1 Loss Minimization and Margin Maximization with Boosting</a></p>
<p>12 0.09895806 <a title="318-tfidf-12" href="./nips-2013-Online_learning_in_episodic_Markovian_decision_processes_by_relative_entropy_policy_search.html">235 nips-2013-Online learning in episodic Markovian decision processes by relative entropy policy search</a></p>
<p>13 0.097190946 <a title="318-tfidf-13" href="./nips-2013-Convex_Two-Layer_Modeling.html">75 nips-2013-Convex Two-Layer Modeling</a></p>
<p>14 0.092548683 <a title="318-tfidf-14" href="./nips-2013-Reflection_methods_for_user-friendly_submodular_optimization.html">268 nips-2013-Reflection methods for user-friendly submodular optimization</a></p>
<p>15 0.092229672 <a title="318-tfidf-15" href="./nips-2013-Reservoir_Boosting_%3A_Between_Online_and_Offline_Ensemble_Learning.html">275 nips-2013-Reservoir Boosting : Between Online and Offline Ensemble Learning</a></p>
<p>16 0.086604275 <a title="318-tfidf-16" href="./nips-2013-Regularized_M-estimators_with_nonconvexity%3A_Statistical_and_algorithmic_theory_for_local_optima.html">271 nips-2013-Regularized M-estimators with nonconvexity: Statistical and algorithmic theory for local optima</a></p>
<p>17 0.086488806 <a title="318-tfidf-17" href="./nips-2013-Decision_Jungles%3A_Compact_and_Rich_Models_for_Classification.html">82 nips-2013-Decision Jungles: Compact and Rich Models for Classification</a></p>
<p>18 0.085398801 <a title="318-tfidf-18" href="./nips-2013-Learning_with_Noisy_Labels.html">171 nips-2013-Learning with Noisy Labels</a></p>
<p>19 0.084461704 <a title="318-tfidf-19" href="./nips-2013-Multi-Prediction_Deep_Boltzmann_Machines.html">200 nips-2013-Multi-Prediction Deep Boltzmann Machines</a></p>
<p>20 0.083246998 <a title="318-tfidf-20" href="./nips-2013-Learning_Stochastic_Feedforward_Neural_Networks.html">160 nips-2013-Learning Stochastic Feedforward Neural Networks</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.254), (1, 0.049), (2, -0.038), (3, -0.037), (4, 0.098), (5, 0.064), (6, -0.085), (7, 0.021), (8, 0.064), (9, 0.025), (10, 0.006), (11, -0.001), (12, 0.031), (13, -0.088), (14, -0.039), (15, -0.004), (16, -0.108), (17, 0.022), (18, 0.012), (19, 0.047), (20, -0.087), (21, 0.088), (22, 0.069), (23, -0.012), (24, -0.012), (25, 0.01), (26, 0.098), (27, -0.051), (28, 0.099), (29, 0.009), (30, -0.04), (31, 0.18), (32, -0.076), (33, 0.054), (34, 0.087), (35, 0.055), (36, -0.13), (37, -0.061), (38, 0.066), (39, -0.006), (40, -0.133), (41, -0.052), (42, -0.103), (43, -0.012), (44, 0.099), (45, 0.047), (46, 0.014), (47, 0.048), (48, 0.172), (49, 0.099)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95332116 <a title="318-lsi-1" href="./nips-2013-Structured_Learning_via_Logistic_Regression.html">318 nips-2013-Structured Learning via Logistic Regression</a></p>
<p>Author: Justin Domke</p><p>Abstract: A successful approach to structured learning is to write the learning objective as a joint function of linear parameters and inference messages, and iterate between updates to each. This paper observes that if the inference problem is “smoothed” through the addition of entropy terms, for ﬁxed messages, the learning objective reduces to a traditional (non-structured) logistic regression problem with respect to parameters. In these logistic regression problems, each training example has a bias term determined by the current set of messages. Based on this insight, the structured energy function can be extended from linear factors to any function class where an “oracle” exists to minimize a logistic loss.</p><p>2 0.67006177 <a title="318-lsi-2" href="./nips-2013-Learning_to_Pass_Expectation_Propagation_Messages.html">168 nips-2013-Learning to Pass Expectation Propagation Messages</a></p>
<p>Author: Nicolas Heess, Daniel Tarlow, John Winn</p><p>Abstract: Expectation Propagation (EP) is a popular approximate posterior inference algorithm that often provides a fast and accurate alternative to sampling-based methods. However, while the EP framework in theory allows for complex nonGaussian factors, there is still a signiﬁcant practical barrier to using them within EP, because doing so requires the implementation of message update operators, which can be difﬁcult and require hand-crafted approximations. In this work, we study the question of whether it is possible to automatically derive fast and accurate EP updates by learning a discriminative model (e.g., a neural network or random forest) to map EP message inputs to EP message outputs. We address the practical concerns that arise in the process, and we provide empirical analysis on several challenging and diverse factors, indicating that there is a space of factors where this approach appears promising. 1</p><p>3 0.62378728 <a title="318-lsi-3" href="./nips-2013-Reservoir_Boosting_%3A_Between_Online_and_Offline_Ensemble_Learning.html">275 nips-2013-Reservoir Boosting : Between Online and Offline Ensemble Learning</a></p>
<p>Author: Leonidas Lefakis, François Fleuret</p><p>Abstract: We propose to train an ensemble with the help of a reservoir in which the learning algorithm can store a limited number of samples. This novel approach lies in the area between ofﬂine and online ensemble approaches and can be seen either as a restriction of the former or an enhancement of the latter. We identify some basic strategies that can be used to populate this reservoir and present our main contribution, dubbed Greedy Edge Expectation Maximization (GEEM), that maintains the reservoir content in the case of Boosting by viewing the samples through their projections into the weak classiﬁer response space. We propose an efﬁcient algorithmic implementation which makes it tractable in practice, and demonstrate its efﬁciency experimentally on several compute-vision data-sets, on which it outperforms both online and ofﬂine methods in a memory constrained setting. 1</p><p>4 0.59968674 <a title="318-lsi-4" href="./nips-2013-Learning_Efficient_Random_Maximum_A-Posteriori_Predictors_with_Non-Decomposable_Loss_Functions.html">152 nips-2013-Learning Efficient Random Maximum A-Posteriori Predictors with Non-Decomposable Loss Functions</a></p>
<p>Author: Tamir Hazan, Subhransu Maji, Joseph Keshet, Tommi Jaakkola</p><p>Abstract: In this work we develop efﬁcient methods for learning random MAP predictors for structured label problems. In particular, we construct posterior distributions over perturbations that can be adjusted via stochastic gradient methods. We show that any smooth posterior distribution would sufﬁce to deﬁne a smooth PAC-Bayesian risk bound suitable for gradient methods. In addition, we relate the posterior distributions to computational properties of the MAP predictors. We suggest multiplicative posteriors to learn super-modular potential functions that accompany specialized MAP predictors such as graph-cuts. We also describe label-augmented posterior models that can use efﬁcient MAP approximations, such as those arising from linear program relaxations. 1</p><p>5 0.59761155 <a title="318-lsi-5" href="./nips-2013-Non-Linear_Domain_Adaptation_with_Boosting.html">211 nips-2013-Non-Linear Domain Adaptation with Boosting</a></p>
<p>Author: Carlos J. Becker, Christos M. Christoudias, Pascal Fua</p><p>Abstract: A common assumption in machine vision is that the training and test samples are drawn from the same distribution. However, there are many problems when this assumption is grossly violated, as in bio-medical applications where different acquisitions can generate drastic variations in the appearance of the data due to changing experimental conditions. This problem is accentuated with 3D data, for which annotation is very time-consuming, limiting the amount of data that can be labeled in new acquisitions for training. In this paper we present a multitask learning algorithm for domain adaptation based on boosting. Unlike previous approaches that learn task-speciﬁc decision boundaries, our method learns a single decision boundary in a shared feature space, common to all tasks. We use the boosting-trick to learn a non-linear mapping of the observations in each task, with no need for speciﬁc a-priori knowledge of its global analytical form. This yields a more parameter-free domain adaptation approach that successfully leverages learning on new tasks where labeled data is scarce. We evaluate our approach on two challenging bio-medical datasets and achieve a signiﬁcant improvement over the state of the art. 1</p><p>6 0.58761173 <a title="318-lsi-6" href="./nips-2013-Marginals-to-Models_Reducibility.html">184 nips-2013-Marginals-to-Models Reducibility</a></p>
<p>7 0.58678389 <a title="318-lsi-7" href="./nips-2013-Direct_0-1_Loss_Minimization_and_Margin_Maximization_with_Boosting.html">90 nips-2013-Direct 0-1 Loss Minimization and Margin Maximization with Boosting</a></p>
<p>8 0.58164811 <a title="318-lsi-8" href="./nips-2013-Understanding_variable_importances_in_forests_of_randomized_trees.html">340 nips-2013-Understanding variable importances in forests of randomized trees</a></p>
<p>9 0.57573462 <a title="318-lsi-9" href="./nips-2013-Message_Passing_Inference_with_Chemical_Reaction_Networks.html">189 nips-2013-Message Passing Inference with Chemical Reaction Networks</a></p>
<p>10 0.5646795 <a title="318-lsi-10" href="./nips-2013-Decision_Jungles%3A_Compact_and_Rich_Models_for_Classification.html">82 nips-2013-Decision Jungles: Compact and Rich Models for Classification</a></p>
<p>11 0.55643022 <a title="318-lsi-11" href="./nips-2013-Linear_decision_rule_as_aspiration_for_simple_decision_heuristics.html">176 nips-2013-Linear decision rule as aspiration for simple decision heuristics</a></p>
<p>12 0.54366183 <a title="318-lsi-12" href="./nips-2013-Estimation%2C_Optimization%2C_and_Parallelism_when_Data_is_Sparse.html">111 nips-2013-Estimation, Optimization, and Parallelism when Data is Sparse</a></p>
<p>13 0.54286498 <a title="318-lsi-13" href="./nips-2013-Learning_Feature_Selection_Dependencies_in_Multi-task_Learning.html">153 nips-2013-Learning Feature Selection Dependencies in Multi-task Learning</a></p>
<p>14 0.53992897 <a title="318-lsi-14" href="./nips-2013-Higher_Order_Priors_for_Joint_Intrinsic_Image%2C_Objects%2C_and_Attributes_Estimation.html">138 nips-2013-Higher Order Priors for Joint Intrinsic Image, Objects, and Attributes Estimation</a></p>
<p>15 0.53932607 <a title="318-lsi-15" href="./nips-2013-Parametric_Task_Learning.html">244 nips-2013-Parametric Task Learning</a></p>
<p>16 0.53108674 <a title="318-lsi-16" href="./nips-2013-On_Algorithms_for_Sparse_Multi-factor_NMF.html">214 nips-2013-On Algorithms for Sparse Multi-factor NMF</a></p>
<p>17 0.51278597 <a title="318-lsi-17" href="./nips-2013-A_Graphical_Transformation_for_Belief_Propagation%3A_Maximum_Weight_Matchings_and_Odd-Sized_Cycles.html">8 nips-2013-A Graphical Transformation for Belief Propagation: Maximum Weight Matchings and Odd-Sized Cycles</a></p>
<p>18 0.50986415 <a title="318-lsi-18" href="./nips-2013-Learning_Adaptive_Value_of_Information_for_Structured_Prediction.html">150 nips-2013-Learning Adaptive Value of Information for Structured Prediction</a></p>
<p>19 0.50749725 <a title="318-lsi-19" href="./nips-2013-Machine_Teaching_for_Bayesian_Learners_in_the_Exponential_Family.html">181 nips-2013-Machine Teaching for Bayesian Learners in the Exponential Family</a></p>
<p>20 0.49463487 <a title="318-lsi-20" href="./nips-2013-Stochastic_Majorization-Minimization_Algorithms_for_Large-Scale_Optimization.html">313 nips-2013-Stochastic Majorization-Minimization Algorithms for Large-Scale Optimization</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.022), (16, 0.05), (33, 0.164), (34, 0.114), (41, 0.071), (46, 0.158), (49, 0.035), (56, 0.116), (70, 0.033), (85, 0.039), (89, 0.028), (93, 0.083), (95, 0.03)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.87284237 <a title="318-lda-1" href="./nips-2013-Structured_Learning_via_Logistic_Regression.html">318 nips-2013-Structured Learning via Logistic Regression</a></p>
<p>Author: Justin Domke</p><p>Abstract: A successful approach to structured learning is to write the learning objective as a joint function of linear parameters and inference messages, and iterate between updates to each. This paper observes that if the inference problem is “smoothed” through the addition of entropy terms, for ﬁxed messages, the learning objective reduces to a traditional (non-structured) logistic regression problem with respect to parameters. In these logistic regression problems, each training example has a bias term determined by the current set of messages. Based on this insight, the structured energy function can be extended from linear factors to any function class where an “oracle” exists to minimize a logistic loss.</p><p>2 0.83136541 <a title="318-lda-2" href="./nips-2013-Multi-Task_Bayesian_Optimization.html">201 nips-2013-Multi-Task Bayesian Optimization</a></p>
<p>Author: Kevin Swersky, Jasper Snoek, Ryan P. Adams</p><p>Abstract: Bayesian optimization has recently been proposed as a framework for automatically tuning the hyperparameters of machine learning models and has been shown to yield state-of-the-art performance with impressive ease and efﬁciency. In this paper, we explore whether it is possible to transfer the knowledge gained from previous optimizations to new tasks in order to ﬁnd optimal hyperparameter settings more efﬁciently. Our approach is based on extending multi-task Gaussian processes to the framework of Bayesian optimization. We show that this method signiﬁcantly speeds up the optimization process when compared to the standard single-task approach. We further propose a straightforward extension of our algorithm in order to jointly minimize the average error across multiple tasks and demonstrate how this can be used to greatly speed up k-fold cross-validation. Lastly, we propose an adaptation of a recently developed acquisition function, entropy search, to the cost-sensitive, multi-task setting. We demonstrate the utility of this new acquisition function by leveraging a small dataset to explore hyperparameter settings for a large dataset. Our algorithm dynamically chooses which dataset to query in order to yield the most information per unit cost. 1</p><p>3 0.83114415 <a title="318-lda-3" href="./nips-2013-Dropout_Training_as_Adaptive_Regularization.html">99 nips-2013-Dropout Training as Adaptive Regularization</a></p>
<p>Author: Stefan Wager, Sida Wang, Percy Liang</p><p>Abstract: Dropout and other feature noising schemes control overﬁtting by artiﬁcially corrupting the training data. For generalized linear models, dropout performs a form of adaptive regularization. Using this viewpoint, we show that the dropout regularizer is ﬁrst-order equivalent to an L2 regularizer applied after scaling the features by an estimate of the inverse diagonal Fisher information matrix. We also establish a connection to AdaGrad, an online learning algorithm, and ﬁnd that a close relative of AdaGrad operates by repeatedly solving linear dropout-regularized problems. By casting dropout as regularization, we develop a natural semi-supervised algorithm that uses unlabeled data to create a better adaptive regularizer. We apply this idea to document classiﬁcation tasks, and show that it consistently boosts the performance of dropout training, improving on state-of-the-art results on the IMDB reviews dataset. 1</p><p>4 0.83037591 <a title="318-lda-4" href="./nips-2013-BIG_%26_QUIC%3A_Sparse_Inverse_Covariance_Estimation_for_a_Million_Variables.html">45 nips-2013-BIG & QUIC: Sparse Inverse Covariance Estimation for a Million Variables</a></p>
<p>Author: Cho-Jui Hsieh, Matyas A. Sustik, Inderjit Dhillon, Pradeep Ravikumar, Russell Poldrack</p><p>Abstract: The 1 -regularized Gaussian maximum likelihood estimator (MLE) has been shown to have strong statistical guarantees in recovering a sparse inverse covariance matrix even under high-dimensional settings. However, it requires solving a difﬁcult non-smooth log-determinant program with number of parameters scaling quadratically with the number of Gaussian variables. State-of-the-art methods thus do not scale to problems with more than 20, 000 variables. In this paper, we develop an algorithm B IG QUIC, which can solve 1 million dimensional 1 regularized Gaussian MLE problems (which would thus have 1000 billion parameters) using a single machine, with bounded memory. In order to do so, we carefully exploit the underlying structure of the problem. Our innovations include a novel block-coordinate descent method with the blocks chosen via a clustering scheme to minimize repeated computations; and allowing for inexact computation of speciﬁc components. In spite of these modiﬁcations, we are able to theoretically analyze our procedure and show that B IG QUIC can achieve super-linear or even quadratic convergence rates. 1</p><p>5 0.82990032 <a title="318-lda-5" href="./nips-2013-Trading_Computation_for_Communication%3A_Distributed_Stochastic_Dual_Coordinate_Ascent.html">333 nips-2013-Trading Computation for Communication: Distributed Stochastic Dual Coordinate Ascent</a></p>
<p>Author: Tianbao Yang</p><p>Abstract: We present and study a distributed optimization algorithm by employing a stochastic dual coordinate ascent method. Stochastic dual coordinate ascent methods enjoy strong theoretical guarantees and often have better performances than stochastic gradient descent methods in optimizing regularized loss minimization problems. It still lacks of efforts in studying them in a distributed framework. We make a progress along the line by presenting a distributed stochastic dual coordinate ascent algorithm in a star network, with an analysis of the tradeoff between computation and communication. We verify our analysis by experiments on real data sets. Moreover, we compare the proposed algorithm with distributed stochastic gradient descent methods and distributed alternating direction methods of multipliers for optimizing SVMs in the same distributed framework, and observe competitive performances. 1</p><p>6 0.82634383 <a title="318-lda-6" href="./nips-2013-%28Nearly%29_Optimal_Algorithms_for_Private_Online_Learning_in_Full-information_and_Bandit_Settings.html">2 nips-2013-(Nearly) Optimal Algorithms for Private Online Learning in Full-information and Bandit Settings</a></p>
<p>7 0.82303739 <a title="318-lda-7" href="./nips-2013-A_New_Convex_Relaxation_for_Tensor_Completion.html">11 nips-2013-A New Convex Relaxation for Tensor Completion</a></p>
<p>8 0.82299286 <a title="318-lda-8" href="./nips-2013-Low-rank_matrix_reconstruction_and_clustering_via_approximate_message_passing.html">180 nips-2013-Low-rank matrix reconstruction and clustering via approximate message passing</a></p>
<p>9 0.82278377 <a title="318-lda-9" href="./nips-2013-A_Deep_Architecture_for_Matching_Short_Texts.html">5 nips-2013-A Deep Architecture for Matching Short Texts</a></p>
<p>10 0.82165086 <a title="318-lda-10" href="./nips-2013-Action_is_in_the_Eye_of_the_Beholder%3A_Eye-gaze_Driven_Model_for_Spatio-Temporal_Action_Localization.html">22 nips-2013-Action is in the Eye of the Beholder: Eye-gaze Driven Model for Spatio-Temporal Action Localization</a></p>
<p>11 0.8211655 <a title="318-lda-11" href="./nips-2013-Predicting_Parameters_in_Deep_Learning.html">251 nips-2013-Predicting Parameters in Deep Learning</a></p>
<p>12 0.81942749 <a title="318-lda-12" href="./nips-2013-Learning_Feature_Selection_Dependencies_in_Multi-task_Learning.html">153 nips-2013-Learning Feature Selection Dependencies in Multi-task Learning</a></p>
<p>13 0.81907451 <a title="318-lda-13" href="./nips-2013-Sparse_Additive_Text_Models_with_Low_Rank_Background.html">301 nips-2013-Sparse Additive Text Models with Low Rank Background</a></p>
<p>14 0.81888914 <a title="318-lda-14" href="./nips-2013-Wavelets_on_Graphs_via_Deep_Learning.html">350 nips-2013-Wavelets on Graphs via Deep Learning</a></p>
<p>15 0.8178817 <a title="318-lda-15" href="./nips-2013-Context-sensitive_active_sensing_in_humans.html">69 nips-2013-Context-sensitive active sensing in humans</a></p>
<p>16 0.81769317 <a title="318-lda-16" href="./nips-2013-Extracting_regions_of_interest_from_biological_images_with_convolutional_sparse_block_coding.html">114 nips-2013-Extracting regions of interest from biological images with convolutional sparse block coding</a></p>
<p>17 0.81636339 <a title="318-lda-17" href="./nips-2013-Optimistic_policy_iteration_and_natural_actor-critic%3A_A_unifying_view_and_a_non-optimality_result.html">239 nips-2013-Optimistic policy iteration and natural actor-critic: A unifying view and a non-optimality result</a></p>
<p>18 0.81628805 <a title="318-lda-18" href="./nips-2013-Supervised_Sparse_Analysis_and_Synthesis_Operators.html">321 nips-2013-Supervised Sparse Analysis and Synthesis Operators</a></p>
<p>19 0.81551737 <a title="318-lda-19" href="./nips-2013-Latent_Structured_Active_Learning.html">149 nips-2013-Latent Structured Active Learning</a></p>
<p>20 0.81443608 <a title="318-lda-20" href="./nips-2013-Distributed_Submodular_Maximization%3A_Identifying_Representative_Elements_in_Massive_Data.html">97 nips-2013-Distributed Submodular Maximization: Identifying Representative Elements in Massive Data</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
