<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>2 nips-2013-(Nearly) Optimal Algorithms for Private Online Learning in Full-information and Bandit Settings</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-2" href="#">nips2013-2</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>2 nips-2013-(Nearly) Optimal Algorithms for Private Online Learning in Full-information and Bandit Settings</h1>
<br/><p>Source: <a title="nips-2013-2-pdf" href="http://papers.nips.cc/paper/5012-nearly-optimal-algorithms-for-private-online-learning-in-full-information-and-bandit-settings.pdf">pdf</a></p><p>Author: Abhradeep Guha Thakurta, Adam Smith</p><p>Abstract: We give differentially private algorithms for a large class of online learning algorithms, in both the full information and bandit settings. Our algorithms aim to minimize a convex loss function which is a sum of smaller convex loss terms, one for each data point. To design our algorithms, we modify the popular mirror descent approach, or rather a variant called follow the approximate leader. The technique leads to the ﬁrst nonprivate algorithms for private online learning in the bandit setting. In the full information setting, our algorithms improve over the regret bounds of previous work (due to Dwork, Naor, Pitassi and Rothblum (2010) and Jain, Kothari and Thakurta (2012)). In many cases, our algorithms (in both settings) match the dependence on the input length, T , of the optimal nonprivate regret bounds up to logarithmic factors in T . Our algorithms require logarithmic space and update time. 1</p><p>Reference: <a title="nips-2013-2-reference" href="../nips2013_reference/nips-2013-%28Nearly%29_Optimal_Algorithms_for_Private_Online_Learning_in_Full-information_and_Bandit_Settings_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 com  Abstract We give differentially private algorithms for a large class of online learning algorithms, in both the full information and bandit settings. [sent-4, score-0.855]
</p><p>2 Our algorithms aim to minimize a convex loss function which is a sum of smaller convex loss terms, one for each data point. [sent-5, score-0.276]
</p><p>3 The technique leads to the ﬁrst nonprivate algorithms for private online learning in the bandit setting. [sent-7, score-0.911]
</p><p>4 In the full information setting, our algorithms improve over the regret bounds of previous work (due to Dwork, Naor, Pitassi and Rothblum (2010) and Jain, Kothari and Thakurta (2012)). [sent-8, score-0.327]
</p><p>5 In many cases, our algorithms (in both settings) match the dependence on the input length, T , of the optimal nonprivate regret bounds up to logarithmic factors in T . [sent-9, score-0.54]
</p><p>6 1  Introduction  This paper looks at the information leaked by online learning algorithms, and seeks to design accurate learning algorithms with rigorous privacy guarantees – that is, algorithms that provably leak very little about individual inputs. [sent-11, score-0.527]
</p><p>7 Even the output of ofﬂine (batch) learning algorithms can leak private information. [sent-12, score-0.431]
</p><p>8 Considerable effort has been devoted to designing batch learning algorithms satisfying differential privacy (a rigorous notion of privacy that emerged from the cryptography literature [DMNS06, Dwo06]), for example [BDMN05, KLN+ 08, CM08, CMS11, Smi11, KST12, JT13, DJW13]. [sent-14, score-0.818]
</p><p>9 In this work we provide a general technique for making a large class of online learning algorithms differentially private, in both the full information and bandit settings. [sent-15, score-0.475]
</p><p>10 Our technique applies to algorithms that aim to minimize a convex loss function which is a sum of smaller convex loss terms, one for each data point. [sent-16, score-0.276]
</p><p>11 , with each wt in C, that roughly minimizes the errors P t ft (wt ). [sent-31, score-0.735]
</p><p>12 The difﬁculty for the algorithm is that it computes wt based only on f1 , . [sent-32, score-0.356]
</p><p>13 We seek to minimize the a posteriori regret, Regret(T ) =  T X  ft (wt )  t=1  min w2C  T X  ft (w)  (1)  t=1  In the bandit setting, the input to the algorithms consists only of f1 (w1 ), f2 (w2 ), . [sent-36, score-1.013]
</p><p>14 That is, at each time step t, the algorithm learns only the cost ft 1 (wt 1 ) of the choice wt 1 it made at the previous time step, rather than the full cost function ft 1 . [sent-40, score-1.186]
</p><p>15 A (strongly) adaptive adversary selects ft based on the output so far w1 , w2 , . [sent-45, score-0.463]
</p><p>16 , wt (but not on the algorithm’s internal random coins). [sent-48, score-0.356]
</p><p>17 Most of this effort has been spent on online learning problems are convex, meaning that the loss functions ft are convex (in w) and the parameter set C ✓ Rp is a convex set (note that one can typically “convexify” the parameter space by randomization). [sent-52, score-0.72]
</p><p>18 Each ft can be thought as private information belonging to an individual. [sent-67, score-0.759]
</p><p>19 The appropriate notion of privacy here is when the entire sequence of outputs of the algorithms (w1 , . [sent-68, score-0.438]
</p><p>20 Formally, we say two input sequences F, F 0 2 DT are neighbors if they differ only in one entry (say, replacing ft by ft0 ). [sent-72, score-0.379]
</p><p>21 A randomized algorithm A is (✏, )-differentially private if for every two neighboring sequences F, F 0 2 DT , and for every event O in the output space C T , Pr[A(F ) 2 O]  e✏ Pr[A(F 0 ) 2 O] + . [sent-74, score-0.38]
</p><p>22 1 Our protocols all satisfy ✏-differential privacy (that is, with = 0). [sent-77, score-0.34]
</p><p>23 1  As deﬁned, differential privacy requires indistinguishable outputs only for nonadaptively chosen sequences (that is, sequences where the inputs at time t are ﬁxed ahead of time and do not depend on the outputs at times 1, . [sent-79, score-0.522]
</p><p>24 2  Differential privacy provides meaningful guarantees in against an attacker who has access to considerable side information: the attacker learns the same things about someone whether or not their data were actually used (see [KS08, DN10, KM12] for further discussion). [sent-87, score-0.438]
</p><p>25 Differential privacy is particularly challenging to analyze for online learning algorithms, since a change in a single input at the beginning of the sequence may affect outputs at all future times in ways that are hard to predict. [sent-88, score-0.5]
</p><p>26 Previous Approaches: Despite the challenges, there are several results on differentially private online learning. [sent-98, score-0.6]
</p><p>27 A special case, “learning from experts” in the full information setting, was discussed in the seminal paper of Dwork, Naor, Pitassi and Rothblum [DNPR10] on privacy under continual observation. [sent-99, score-0.398]
</p><p>28 , p}) and the functions fi are linear with coefﬁcients in {0, 1} (that is, ft (w) = hw, ct i where ct 2 {0, 1}p ). [sent-103, score-0.451]
</p><p>29 Their algorithm guarantees a weaker notion of privacy p the one we consider2 but, when adapted to our stronger than setting, it yields a regret bound of O(p T /✏). [sent-104, score-0.636]
</p><p>30 Jain, Kothari and Thakurta [JKT12] deﬁned the general problem of private online learning, and gave algorithms for learning convex functions over convex domains in the full information setting. [sent-105, score-0.769]
</p><p>31 They gave algorithms that satisfy (✏, )-differential privacy with > 0 (our p algorithms satisfy the stronger ˜ variant with = 0). [sent-106, score-0.414]
</p><p>32 Speciﬁcally, their algorithms have regret O( T log(1/ )/✏) for Lipshitz˜ bounded, strongly convex cost functions and O(T 2/3 log(1/ )/✏) for general Lipshitz convex costs. [sent-107, score-0.635]
</p><p>33 The idea of [JKT12] for learning strongly convex functions is to bound the sensitivity of the entire vector of outputs w1 , w2 , . [sent-108, score-0.271]
</p><p>34 Unfortunately, the regret bounds obtained by previous work remain far from the best nonprivate p bounds. [sent-112, score-0.489]
</p><p>35 [Zin03] gave an algorithm with regret O( T ) for general Lipshitz functions, assuming L p and the diameter kCk2 of C are constants. [sent-113, score-0.289]
</p><p>36 When cost functions in F are H-strongly convex for constant H, then the regret can be improved to O(log T ) [HAK07], which is also tight. [sent-117, score-0.446]
</p><p>37 In this work, we give new algorithms that match these nonprivate bounds’ dependence on T , up to (poly log T )/✏ factors. [sent-118, score-0.265]
</p><p>38 We note that [JKT12] give one algorithm for a speciﬁc strongly convex problem, online linear regression, with regret poly(log T ). [sent-119, score-0.518]
</p><p>39 We are not aware of any previous work on privacy in the bandit setting. [sent-121, score-0.569]
</p><p>40 However, even nonprivate algorithms for bandit learning are very delicate, and private versions had until now proved elusive. [sent-123, score-0.823]
</p><p>41 Our Results: In this work we provide a technique for making a large class of online learning algorithms differentially private, in both the full information and bandit settings. [sent-124, score-0.475]
</p><p>42 Speciﬁcally, our algorithms work by measuring the gradient rft (wt ) when ft is learned, and maintaining a differentially private running sum of the gradients observed so far. [sent-129, score-1.016]
</p><p>43 We then show that a class of learning algorithms known collectively as follow the approximate leader (the version we use is due to [HAK07]) can be run given only these noisy sums, and that their regret can be bounded even when these sums are inaccurate. [sent-131, score-0.525]
</p><p>44 Our main algorithm, for strongly convex functions, achieves regret O( log ✏ T ), ignoring factors of the dimension p, Lipschitz continuity L and strong convexity H. [sent-139, score-0.487]
</p><p>45 Setting parameters carefully, we get regret of O( T log✏ T ). [sent-144, score-0.267]
</p><p>46 In the bandit setting, we distinguish between oblivious and adaptive adversaries. [sent-147, score-0.321]
</p><p>47 , p}) Lipshitz  and  Lipshitz and strongly convex  Previous private upper bound. [sent-156, score-0.543]
</p><p>48 2  Private Online Learning: Full-information Setting  In this section we adapt the Follow The Approximate Leader (FTAL) algorithm of [HAK07] to design a differentially private variant. [sent-172, score-0.512]
</p><p>49 Our modiﬁed algorithm, which we call Private Follow The 4  Approximate Leader (PFTAL), needs a new regret analysis as we have to deal with randomness due to differential privacy. [sent-173, score-0.38]
</p><p>50 ˆ 2: Pass 5f1 (w1 ), L2 -bound L and privacy parameter ✏ to the tree based aggregation protocol and ˆ receive the current partial sum in v1 . [sent-178, score-0.532]
</p><p>51 ˆ 2 ˆ 2 w2C  ⌧ =1  Pass 5ft+1 (wt+1 ), L2 -bound L and privacy parameter ✏ to the tree-based protocol (Algoˆ rithm 2) and receive the current partial sum in vt+1 . [sent-181, score-0.431]
</p><p>52 Roughly, at every time step (t + 1), PFTAL outputs a vector w that approximately minimizes the ˜ ˜ sum of the approximations f1 , · · · , ft over the convex set C. [sent-183, score-0.565]
</p><p>53 Let w1 , · · · , wt be the sequence of outputs produced in the ﬁrst t time steps, and let ft be the costˆ ˆ function at step t. [sent-184, score-0.807]
</p><p>54 Consider the following quadratic approximation to ft (as in [HAK07]). [sent-185, score-0.379]
</p><p>55 Deﬁne ˜ ft (w) = ft (wt ) + h5ft (wt ), w ˆ ˆ  wt i + ˆ  H 2 kw  wt k2 ˆ 2  (3)  ˜ where H is the strong convexity parameter. [sent-186, score-1.596]
</p><p>56 Notice that ft and ft have the same value and gradient ˜ ˆ ˜ ˆ ˜ at wt (that is, ft (wt ) = ft (wt ) and 5ft (wt ) = 5ft (wt )). [sent-187, score-1.912]
</p><p>57 Moreover, ft is a lower bound for ft ˆ ˆ ˆ everywhere on C. [sent-188, score-0.787]
</p><p>58 Let wt+1 = arg min ˜  t P ˜ ˜ ˜ f⌧ (w) be the “leader” corresponding to the cost functions f1 , · · · , ft . [sent-189, score-0.473]
</p><p>59 w2C ⌧ =1  ˜ ˜ Minimizing the sum of ft (w) is the same as minimizing the sum of ft (w) ft (wt ), since subtracting ˆ a constant term won’t change the minimizer. [sent-190, score-1.197]
</p><p>60 We can thus write wt+1 as ˜ wt+1 = arg min h ˜ w2C  t X  ⌧ =1  5ft (w⌧ ), wi + ˆ  H 2  t X  ⌧ =1  kw  w⌧ k2 ˆ 2  (4)  Suppose, w1 , · · · , wt have been released so far. [sent-191, score-0.557]
</p><p>61 To release a private approximation to wt+1 , it ˆ ˆ ˜ Pt sufﬁces to approximate vt+1 = ⌧ =1 5ft (w⌧ ) while ensuring differential privacy. [sent-192, score-0.493]
</p><p>62 This problem ⌧ =1  is well studied in the privacy literature. [sent-195, score-0.34]
</p><p>63 In a differentially private version of this tree, we ensure that each node’s sub-tree sum is (✏/log2 T )-differentially private, by adding a noise vector b 2 Rp 5  p  pL0 log T  whose L2 -norm is Gamma distributed and has standard deviation O( ). [sent-204, score-0.568]
</p><p>64 1  Privacy and Utility Guarantees for PFTAL (Algorithm 1)  In this section we provide the privacy and regret guarantees for the PFTAL algorithm (Algorithm 1). [sent-215, score-0.607]
</p><p>65 Hence, ˆ ˆ it sufﬁces to argue privacy for the collection of noisy sums associated to nodes in the binary tree. [sent-221, score-0.376]
</p><p>66 Hence, changing one loss function ft actually affects all subsequent partial sums. [sent-225, score-0.411]
</p><p>67 In terms of regret guarantee, we show that our algorithm enjoys regret of O(p log2. [sent-228, score-0.534]
</p><p>68 Compared to the non-private regret bound of O(log T ), our regret bound has an extra log1. [sent-230, score-0.592]
</p><p>69 A formal regret bound for PFTAL algorithm is given in Theorem 4. [sent-232, score-0.296]
</p><p>70 For adaptive adversaries, the expected regret satisﬁes: ✓ ◆ p(L + HkCk2 )2 log2. [sent-235, score-0.301]
</p><p>71 Results for Lipschitz Convex Costs: Our algorithm for strongly convex costs can be adapted to arbitrary Lipschitz convex costs by executing Algorithm 1 on functions ht (w) = ft (w) + H kwk2 2 2 p ˜ p instead of the ft ’s. [sent-238, score-1.112]
</p><p>72 5 T /(✏ T )) will give us a regret bound of O( pT /✏). [sent-240, score-0.296]
</p><p>73 Existing (nonprivate) bandit algorithms for online convex optimization follow 6  a generic reduction to the full-information setting [FKM05, ADX10], called the “one-point” (or “one-shot”) gradient trick. [sent-243, score-0.536]
</p><p>74 Speciﬁcally, to deﬁne the quadratic lower bounds to the input cost functions (as in (3)), we replace the exact gradient of ft at wt with a one-point approximation. [sent-245, score-0.878]
</p><p>75 Speciﬁcally, to deﬁne the quadratic lower bounds to the input cost functions (as in (3)), we replace the exact gradient of ft at wt with ˆ a one-point approximation. [sent-247, score-0.878]
</p><p>76 As in the full information setting, one may obtain regret bounds for general convex functions in the bandit setting by adding a strongly convex regularizer to the cost functions. [sent-248, score-0.872]
</p><p>77 Corresponding ˜ ˜ ˆ to the smoothed function ft = f ⇤ U Bp , we deﬁne a quadratic lower bound gt : ˆ 2 H ˆ ˜ ˆ ˜ gt (w) = ft (wt ) + h5ft (wt ), w wt i + 2 kw wt k2 ˆ ˜ ˜ (6) ˆ ˆ ˜ ˆ ˜ Notice that gt is a uniform lower bound on ft satisfying gt (wt ) = ft (wt ) and 5ˆt (wt ) = 5ft (wt ). [sent-260, score-2.637]
</p><p>78 Consider the following proxy gt for gt : ˜ ˆ p H ˆ ˜ ˆ ˜ ˜ gt (w) = ft (wt ) h5ft (wt ), wt i +h ft (wt + ut )ut , wi + kw wt k2 ˜ ˜ ˜ 2 (7) | {z } 2 A  where uT is drawn uniformly from the unit sphere Sp 1 . [sent-263, score-1.876]
</p><p>79 Note that in (7) we replaced the gradient ˆ of ft with its one-point approximation only in one of its two occurrences (the inner product with w). [sent-264, score-0.419]
</p><p>80 One difﬁculty ˜ ˜ remains: because ft is only assumed to be deﬁned on C, the approximation p ft (wt + ut )ut is only ˜ deﬁned when wt is sufﬁciently far inside C. [sent-266, score-1.184]
</p><p>81 We obtain: ◆ t t t X X✓p X wt+1 = arg min ˜ g⌧ (w) = arg min h ˜ ft (wt + ut )ut , wi+ H ˜ kw w⌧ k2 ˜ 2 2 w2(1 ⇠)C  ⌧ =1  w2(1 ⇠)C  ⌧ =1  ⌧ =1  (We have use the fact that to minimize gt , one can ignore the constant term A in (7). [sent-269, score-0.658]
</p><p>82 ˆ ˜ Theorem 12 (in Appendix D) gives the precise regret guarantees for this algorithm. [sent-278, score-0.267]
</p><p>83 For adaptive ˜ adversaries the regret is bounded by O(p2/3 T 3/4 ) and for oblivious adversaries the regret is bounded ˜ 2/3 T 2/3 ). [sent-279, score-0.702]
</p><p>84 2  Follow the Approximate Leader (Bandit version): Private Algorithm  To make the bandit version of FTAL ✏-differentially private, we replace the value vt = ⌘ Pt ⇣ p † † ft (wt + ut )ut with a private approximation vt computed using the tree-based sum ⌧ =1 protocol. [sent-281, score-1.252]
</p><p>85 In the following theorem we provide the regret guarantee of the Private FTAL (bandit version). [sent-288, score-0.288]
</p><p>86 This increases the expected regret bound by a factor of (LR + kCk2 ). [sent-302, score-0.296]
</p><p>87 Bound for general convex functions: Our results in this section can be extended to the setting of arbitrary Lipshitz convex costs via regularization, as in Section C (by adding H kwk2 to each cost 2 2 ˜ function ft ) . [sent-304, score-0.659]
</p><p>88 With the appropriate choice of H the regret scales as O(T 3/4 /✏) for both oblivious and adaptive adversaries. [sent-305, score-0.359]
</p><p>89 4  Open Questions  Our work raises several interesting open questions: First, our regret bounds with general convex p ˜ functions have the form O( T /✏). [sent-308, score-0.444]
</p><p>90 We would like to have a regret bound where the parameter 1/✏ is factored out with lower order terms in the regret, i. [sent-309, score-0.296]
</p><p>91 , we would like to have regret bound of the p p form O( T ) + o( T /✏). [sent-311, score-0.296]
</p><p>92 Second, our regret bounds for convex bandits are worse than the non-private bounds for linear and multi-arm bandits. [sent-312, score-0.479]
</p><p>93 For multi-arm bandits [ACBF02] and for linear bandits [AHR08], the non-private p regret bound is known to be O( T ). [sent-313, score-0.364]
</p><p>94 If we use our private algorithm in this setting, we will incur a p ˜ regret of O(T 2/3 ). [sent-314, score-0.647]
</p><p>95 Can we get O( T ) regret for multi-arm or linear bandits? [sent-315, score-0.267]
</p><p>96 Finally, bandit algorithms require internal randomness to get reasonable regret guarantees. [sent-316, score-0.545]
</p><p>97 Can we harness the randomness of non-private bandit algorithms in the design private bandit algorithms? [sent-317, score-0.887]
</p><p>98 Our current privacy analysis ignores this additional source of randomness. [sent-318, score-0.34]
</p><p>99 Optimal algorithms for online convex optimization with multi-point bandit feedback. [sent-323, score-0.453]
</p><p>100 Online convex optimization in the bandit setting: gradient descent without a gradient. [sent-369, score-0.379]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('private', 0.38), ('ft', 0.379), ('wt', 0.356), ('privacy', 0.34), ('regret', 0.267), ('bandit', 0.229), ('nonprivate', 0.188), ('pftal', 0.181), ('differentially', 0.132), ('leader', 0.13), ('pt', 0.117), ('convex', 0.11), ('lipshitz', 0.099), ('dwork', 0.095), ('kw', 0.095), ('differential', 0.09), ('online', 0.088), ('vt', 0.082), ('ut', 0.07), ('cynthia', 0.067), ('abhradeep', 0.066), ('gt', 0.064), ('adam', 0.062), ('oblivious', 0.058), ('continual', 0.058), ('aggregation', 0.057), ('rp', 0.057), ('bp', 0.054), ('lipschitz', 0.054), ('strongly', 0.053), ('adversary', 0.05), ('attacker', 0.049), ('ftal', 0.049), ('rbp', 0.049), ('thakurta', 0.049), ('wi', 0.049), ('outputs', 0.046), ('tree', 0.044), ('kobbi', 0.043), ('kothari', 0.043), ('follow', 0.043), ('poly', 0.041), ('appendix', 0.041), ('naor', 0.04), ('pitassi', 0.04), ('gradient', 0.04), ('fi', 0.039), ('adversaries', 0.038), ('cost', 0.036), ('sums', 0.036), ('zt', 0.034), ('bandits', 0.034), ('adaptive', 0.034), ('bounds', 0.034), ('jain', 0.033), ('functions', 0.033), ('stream', 0.032), ('released', 0.032), ('partial', 0.032), ('convexity', 0.031), ('subgradient', 0.03), ('sum', 0.03), ('bound', 0.029), ('claire', 0.029), ('kln', 0.029), ('moni', 0.029), ('rft', 0.029), ('rothblum', 0.029), ('shiva', 0.029), ('protocol', 0.029), ('sp', 0.028), ('coins', 0.027), ('hide', 0.027), ('icalp', 0.027), ('kifer', 0.027), ('sequence', 0.026), ('algorithms', 0.026), ('log', 0.026), ('delicate', 0.025), ('leak', 0.025), ('pods', 0.025), ('prateek', 0.025), ('dependence', 0.025), ('arg', 0.025), ('ball', 0.025), ('appendices', 0.024), ('hides', 0.024), ('kasiviswanathan', 0.024), ('nissim', 0.024), ('prasad', 0.024), ('costs', 0.024), ('colt', 0.023), ('approximate', 0.023), ('randomness', 0.023), ('rigorous', 0.022), ('adaptively', 0.022), ('gave', 0.022), ('kamalika', 0.022), ('guarantee', 0.021), ('leaf', 0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="2-tfidf-1" href="./nips-2013-%28Nearly%29_Optimal_Algorithms_for_Private_Online_Learning_in_Full-information_and_Bandit_Settings.html">2 nips-2013-(Nearly) Optimal Algorithms for Private Online Learning in Full-information and Bandit Settings</a></p>
<p>Author: Abhradeep Guha Thakurta, Adam Smith</p><p>Abstract: We give differentially private algorithms for a large class of online learning algorithms, in both the full information and bandit settings. Our algorithms aim to minimize a convex loss function which is a sum of smaller convex loss terms, one for each data point. To design our algorithms, we modify the popular mirror descent approach, or rather a variant called follow the approximate leader. The technique leads to the ﬁrst nonprivate algorithms for private online learning in the bandit setting. In the full information setting, our algorithms improve over the regret bounds of previous work (due to Dwork, Naor, Pitassi and Rothblum (2010) and Jain, Kothari and Thakurta (2012)). In many cases, our algorithms (in both settings) match the dependence on the input length, T , of the optimal nonprivate regret bounds up to logarithmic factors in T . Our algorithms require logarithmic space and update time. 1</p><p>2 0.44331995 <a title="2-tfidf-2" href="./nips-2013-A_Stability-based_Validation_Procedure_for_Differentially_Private_Machine_Learning.html">14 nips-2013-A Stability-based Validation Procedure for Differentially Private Machine Learning</a></p>
<p>Author: Kamalika Chaudhuri, Staal A. Vinterbo</p><p>Abstract: Differential privacy is a cryptographically motivated deﬁnition of privacy which has gained considerable attention in the algorithms, machine-learning and datamining communities. While there has been an explosion of work on differentially private machine learning algorithms, a major barrier to achieving end-to-end differential privacy in practical machine learning applications is the lack of an effective procedure for differentially private parameter tuning, or, determining the parameter value, such as a bin size in a histogram, or a regularization parameter, that is suitable for a particular application. In this paper, we introduce a generic validation procedure for differentially private machine learning algorithms that apply when a certain stability condition holds on the training algorithm and the validation performance metric. The training data size and the privacy budget used for training in our procedure is independent of the number of parameter values searched over. We apply our generic procedure to two fundamental tasks in statistics and machine-learning – training a regularized linear classiﬁer and building a histogram density estimator that result in end-toend differentially private solutions for these problems. 1</p><p>3 0.42583185 <a title="2-tfidf-3" href="./nips-2013-Local_Privacy_and_Minimax_Bounds%3A_Sharp_Rates_for_Probability_Estimation.html">177 nips-2013-Local Privacy and Minimax Bounds: Sharp Rates for Probability Estimation</a></p>
<p>Author: John Duchi, Martin J. Wainwright, Michael Jordan</p><p>Abstract: We provide a detailed study of the estimation of probability distributions— discrete and continuous—in a stringent setting in which data is kept private even from the statistician. We give sharp minimax rates of convergence for estimation in these locally private settings, exhibiting fundamental trade-offs between privacy and convergence rate, as well as providing tools to allow movement along the privacy-statistical efﬁciency continuum. One of the consequences of our results is that Warner’s classical work on randomized response is an optimal way to perform survey sampling while maintaining privacy of the respondents. 1</p><p>4 0.32249624 <a title="2-tfidf-4" href="./nips-2013-Stochastic_Convex_Optimization_with_Multiple__Objectives.html">311 nips-2013-Stochastic Convex Optimization with Multiple  Objectives</a></p>
<p>Author: Mehrdad Mahdavi, Tianbao Yang, Rong Jin</p><p>Abstract: In this paper, we are interested in the development of efﬁcient algorithms for convex optimization problems in the simultaneous presence of multiple objectives and stochasticity in the ﬁrst-order information. We cast the stochastic multiple objective optimization problem into a constrained optimization problem by choosing one function as the objective and try to bound other objectives by appropriate thresholds. We ﬁrst examine a two stages exploration-exploitation based algorithm which ﬁrst approximates the stochastic objectives by sampling and then solves a constrained stochastic optimization problem by projected gradient method. This method attains a suboptimal convergence rate even under strong assumption on the objectives. Our second approach is an efﬁcient primal-dual stochastic algorithm. It leverages on the theory of Lagrangian method √ conin strained optimization and attains the optimal convergence rate of O(1/ T ) in high probability for general Lipschitz continuous objectives.</p><p>5 0.31479555 <a title="2-tfidf-5" href="./nips-2013-Linear_Convergence_with_Condition_Number_Independent_Access_of_Full_Gradients.html">175 nips-2013-Linear Convergence with Condition Number Independent Access of Full Gradients</a></p>
<p>Author: Lijun Zhang, Mehrdad Mahdavi, Rong Jin</p><p>Abstract: For smooth and strongly convex optimizations, the optimal iteration complexity of √ the gradient-based algorithm is O( κ log 1/ǫ), where κ is the condition number. In the case that the optimization problem is ill-conditioned, we need to evaluate a large number of full gradients, which could be computationally expensive. In this paper, we propose to remove the dependence on the condition number by allowing the algorithm to access stochastic gradients of the objective function. To this end, we present a novel algorithm named Epoch Mixed Gradient Descent (EMGD) that is able to utilize two kinds of gradients. A distinctive step in EMGD is the mixed gradient descent, where we use a combination of the full and stochastic gradients to update the intermediate solution. Theoretical analysis shows that EMGD is able to ﬁnd an ǫ-optimal solution by computing O(log 1/ǫ) full gradients and O(κ2 log 1/ǫ) stochastic gradients. 1</p><p>6 0.30460721 <a title="2-tfidf-6" href="./nips-2013-Optimization%2C_Learning%2C_and_Games_with_Predictable_Sequences.html">240 nips-2013-Optimization, Learning, and Games with Predictable Sequences</a></p>
<p>7 0.30346572 <a title="2-tfidf-7" href="./nips-2013-Dimension-Free_Exponentiated_Gradient.html">89 nips-2013-Dimension-Free Exponentiated Gradient</a></p>
<p>8 0.30150276 <a title="2-tfidf-8" href="./nips-2013-Online_Learning_with_Switching_Costs_and_Other_Adaptive_Adversaries.html">231 nips-2013-Online Learning with Switching Costs and Other Adaptive Adversaries</a></p>
<p>9 0.21688434 <a title="2-tfidf-9" href="./nips-2013-Eluder_Dimension_and_the_Sample_Complexity_of_Optimistic_Exploration.html">106 nips-2013-Eluder Dimension and the Sample Complexity of Optimistic Exploration</a></p>
<p>10 0.19359773 <a title="2-tfidf-10" href="./nips-2013-The_Pareto_Regret_Frontier.html">325 nips-2013-The Pareto Regret Frontier</a></p>
<p>11 0.18811771 <a title="2-tfidf-11" href="./nips-2013-Online_Learning_with_Costly_Features_and_Labels.html">230 nips-2013-Online Learning with Costly Features and Labels</a></p>
<p>12 0.17945343 <a title="2-tfidf-12" href="./nips-2013-Adaptive_Market_Making_via_Online_Learning.html">26 nips-2013-Adaptive Market Making via Online Learning</a></p>
<p>13 0.17887317 <a title="2-tfidf-13" href="./nips-2013-Efficient_Algorithm_for_Privately_Releasing_Smooth_Queries.html">102 nips-2013-Efficient Algorithm for Privately Releasing Smooth Queries</a></p>
<p>14 0.17154945 <a title="2-tfidf-14" href="./nips-2013-Online_Learning_in_Markov_Decision_Processes_with_Adversarially_Chosen_Transition_Probability_Distributions.html">227 nips-2013-Online Learning in Markov Decision Processes with Adversarially Chosen Transition Probability Distributions</a></p>
<p>15 0.14531565 <a title="2-tfidf-15" href="./nips-2013-Minimax_Optimal_Algorithms_for_Unconstrained_Linear_Optimization.html">191 nips-2013-Minimax Optimal Algorithms for Unconstrained Linear Optimization</a></p>
<p>16 0.13952103 <a title="2-tfidf-16" href="./nips-2013-From_Bandits_to_Experts%3A_A_Tale_of_Domination_and_Independence.html">125 nips-2013-From Bandits to Experts: A Tale of Domination and Independence</a></p>
<p>17 0.13635956 <a title="2-tfidf-17" href="./nips-2013-High-Dimensional_Gaussian_Process_Bandits.html">137 nips-2013-High-Dimensional Gaussian Process Bandits</a></p>
<p>18 0.13167168 <a title="2-tfidf-18" href="./nips-2013-Prior-free_and_prior-dependent_regret_bounds_for_Thompson_Sampling.html">253 nips-2013-Prior-free and prior-dependent regret bounds for Thompson Sampling</a></p>
<p>19 0.12736234 <a title="2-tfidf-19" href="./nips-2013-Mixed_Optimization_for_Smooth_Functions.html">193 nips-2013-Mixed Optimization for Smooth Functions</a></p>
<p>20 0.12369441 <a title="2-tfidf-20" href="./nips-2013-A_Gang_of_Bandits.html">7 nips-2013-A Gang of Bandits</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.228), (1, -0.168), (2, 0.369), (3, -0.332), (4, 0.044), (5, -0.079), (6, -0.084), (7, 0.051), (8, 0.209), (9, 0.358), (10, 0.131), (11, -0.023), (12, -0.107), (13, 0.142), (14, -0.05), (15, 0.148), (16, 0.065), (17, -0.078), (18, -0.01), (19, -0.062), (20, 0.114), (21, -0.032), (22, 0.011), (23, -0.056), (24, 0.101), (25, 0.035), (26, 0.102), (27, -0.053), (28, 0.031), (29, 0.036), (30, 0.05), (31, -0.046), (32, 0.019), (33, 0.045), (34, 0.015), (35, -0.019), (36, 0.055), (37, -0.063), (38, 0.018), (39, -0.013), (40, 0.047), (41, 0.035), (42, 0.011), (43, -0.024), (44, 0.025), (45, -0.024), (46, 0.001), (47, -0.014), (48, -0.005), (49, 0.015)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95195532 <a title="2-lsi-1" href="./nips-2013-%28Nearly%29_Optimal_Algorithms_for_Private_Online_Learning_in_Full-information_and_Bandit_Settings.html">2 nips-2013-(Nearly) Optimal Algorithms for Private Online Learning in Full-information and Bandit Settings</a></p>
<p>Author: Abhradeep Guha Thakurta, Adam Smith</p><p>Abstract: We give differentially private algorithms for a large class of online learning algorithms, in both the full information and bandit settings. Our algorithms aim to minimize a convex loss function which is a sum of smaller convex loss terms, one for each data point. To design our algorithms, we modify the popular mirror descent approach, or rather a variant called follow the approximate leader. The technique leads to the ﬁrst nonprivate algorithms for private online learning in the bandit setting. In the full information setting, our algorithms improve over the regret bounds of previous work (due to Dwork, Naor, Pitassi and Rothblum (2010) and Jain, Kothari and Thakurta (2012)). In many cases, our algorithms (in both settings) match the dependence on the input length, T , of the optimal nonprivate regret bounds up to logarithmic factors in T . Our algorithms require logarithmic space and update time. 1</p><p>2 0.68166786 <a title="2-lsi-2" href="./nips-2013-A_Stability-based_Validation_Procedure_for_Differentially_Private_Machine_Learning.html">14 nips-2013-A Stability-based Validation Procedure for Differentially Private Machine Learning</a></p>
<p>Author: Kamalika Chaudhuri, Staal A. Vinterbo</p><p>Abstract: Differential privacy is a cryptographically motivated deﬁnition of privacy which has gained considerable attention in the algorithms, machine-learning and datamining communities. While there has been an explosion of work on differentially private machine learning algorithms, a major barrier to achieving end-to-end differential privacy in practical machine learning applications is the lack of an effective procedure for differentially private parameter tuning, or, determining the parameter value, such as a bin size in a histogram, or a regularization parameter, that is suitable for a particular application. In this paper, we introduce a generic validation procedure for differentially private machine learning algorithms that apply when a certain stability condition holds on the training algorithm and the validation performance metric. The training data size and the privacy budget used for training in our procedure is independent of the number of parameter values searched over. We apply our generic procedure to two fundamental tasks in statistics and machine-learning – training a regularized linear classiﬁer and building a histogram density estimator that result in end-toend differentially private solutions for these problems. 1</p><p>3 0.65472913 <a title="2-lsi-3" href="./nips-2013-Local_Privacy_and_Minimax_Bounds%3A_Sharp_Rates_for_Probability_Estimation.html">177 nips-2013-Local Privacy and Minimax Bounds: Sharp Rates for Probability Estimation</a></p>
<p>Author: John Duchi, Martin J. Wainwright, Michael Jordan</p><p>Abstract: We provide a detailed study of the estimation of probability distributions— discrete and continuous—in a stringent setting in which data is kept private even from the statistician. We give sharp minimax rates of convergence for estimation in these locally private settings, exhibiting fundamental trade-offs between privacy and convergence rate, as well as providing tools to allow movement along the privacy-statistical efﬁciency continuum. One of the consequences of our results is that Warner’s classical work on randomized response is an optimal way to perform survey sampling while maintaining privacy of the respondents. 1</p><p>4 0.57693458 <a title="2-lsi-4" href="./nips-2013-Efficient_Algorithm_for_Privately_Releasing_Smooth_Queries.html">102 nips-2013-Efficient Algorithm for Privately Releasing Smooth Queries</a></p>
<p>Author: Ziteng Wang, Kai Fan, Jiaqi Zhang, Liwei Wang</p><p>Abstract: We study differentially private mechanisms for answering smooth queries on databases consisting of data points in Rd . A K-smooth query is speciﬁed by a function whose partial derivatives up to order K are all bounded. We develop an -differentially private mechanism which for the class of K-smooth queries has K accuracy O(n− 2d+K / ). The mechanism ﬁrst outputs a summary of the database. To obtain an answer of a query, the user runs a public evaluation algorithm which contains no information of the database. Outputting the summary runs in time d O(n1+ 2d+K ), and the evaluation algorithm for answering a query runs in time d+2+ 2d K ˜ O(n 2d+K ). Our mechanism is based on L∞ -approximation of (transformed) smooth functions by low degree even trigonometric polynomials with small and efﬁciently computable coefﬁcients. 1</p><p>5 0.57573032 <a title="2-lsi-5" href="./nips-2013-Dimension-Free_Exponentiated_Gradient.html">89 nips-2013-Dimension-Free Exponentiated Gradient</a></p>
<p>Author: Francesco Orabona</p><p>Abstract: I present a new online learning algorithm that extends the exponentiated gradient framework to inﬁnite dimensional spaces. My analysis shows that the algorithm is implicitly able to estimate the L2 norm of the unknown competitor, U , achieving √ a regret bound of the order of O(U log(U T + 1)) T ), instead of the standard √ O((U 2 + 1) T ), achievable without knowing U . For this analysis, I introduce novel tools for algorithms with time-varying regularizers, through the use of local smoothness. Through a lower bound, I also show that the algorithm is optimal up to log(U T ) term for linear and Lipschitz losses. 1</p><p>6 0.53318834 <a title="2-lsi-6" href="./nips-2013-Stochastic_Convex_Optimization_with_Multiple__Objectives.html">311 nips-2013-Stochastic Convex Optimization with Multiple  Objectives</a></p>
<p>7 0.53214222 <a title="2-lsi-7" href="./nips-2013-Online_Learning_with_Switching_Costs_and_Other_Adaptive_Adversaries.html">231 nips-2013-Online Learning with Switching Costs and Other Adaptive Adversaries</a></p>
<p>8 0.51406944 <a title="2-lsi-8" href="./nips-2013-Optimization%2C_Learning%2C_and_Games_with_Predictable_Sequences.html">240 nips-2013-Optimization, Learning, and Games with Predictable Sequences</a></p>
<p>9 0.51305711 <a title="2-lsi-9" href="./nips-2013-Linear_Convergence_with_Condition_Number_Independent_Access_of_Full_Gradients.html">175 nips-2013-Linear Convergence with Condition Number Independent Access of Full Gradients</a></p>
<p>10 0.49767673 <a title="2-lsi-10" href="./nips-2013-Adaptive_Market_Making_via_Online_Learning.html">26 nips-2013-Adaptive Market Making via Online Learning</a></p>
<p>11 0.46217069 <a title="2-lsi-11" href="./nips-2013-The_Pareto_Regret_Frontier.html">325 nips-2013-The Pareto Regret Frontier</a></p>
<p>12 0.45421311 <a title="2-lsi-12" href="./nips-2013-Adaptive_Anonymity_via_%24b%24-Matching.html">25 nips-2013-Adaptive Anonymity via $b$-Matching</a></p>
<p>13 0.4400627 <a title="2-lsi-13" href="./nips-2013-Online_Learning_with_Costly_Features_and_Labels.html">230 nips-2013-Online Learning with Costly Features and Labels</a></p>
<p>14 0.42188692 <a title="2-lsi-14" href="./nips-2013-Eluder_Dimension_and_the_Sample_Complexity_of_Optimistic_Exploration.html">106 nips-2013-Eluder Dimension and the Sample Complexity of Optimistic Exploration</a></p>
<p>15 0.42120197 <a title="2-lsi-15" href="./nips-2013-Minimax_Optimal_Algorithms_for_Unconstrained_Linear_Optimization.html">191 nips-2013-Minimax Optimal Algorithms for Unconstrained Linear Optimization</a></p>
<p>16 0.3925949 <a title="2-lsi-16" href="./nips-2013-Mixed_Optimization_for_Smooth_Functions.html">193 nips-2013-Mixed Optimization for Smooth Functions</a></p>
<p>17 0.38247576 <a title="2-lsi-17" href="./nips-2013-From_Bandits_to_Experts%3A_A_Tale_of_Domination_and_Independence.html">125 nips-2013-From Bandits to Experts: A Tale of Domination and Independence</a></p>
<p>18 0.38219222 <a title="2-lsi-18" href="./nips-2013-Learning_Prices_for_Repeated_Auctions_with_Strategic_Buyers.html">159 nips-2013-Learning Prices for Repeated Auctions with Strategic Buyers</a></p>
<p>19 0.35509554 <a title="2-lsi-19" href="./nips-2013-Accelerating_Stochastic_Gradient_Descent_using_Predictive_Variance_Reduction.html">20 nips-2013-Accelerating Stochastic Gradient Descent using Predictive Variance Reduction</a></p>
<p>20 0.35223922 <a title="2-lsi-20" href="./nips-2013-Online_Learning_in_Markov_Decision_Processes_with_Adversarially_Chosen_Transition_Probability_Distributions.html">227 nips-2013-Online Learning in Markov Decision Processes with Adversarially Chosen Transition Probability Distributions</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.028), (16, 0.028), (33, 0.122), (34, 0.064), (36, 0.011), (41, 0.024), (46, 0.243), (49, 0.025), (56, 0.172), (70, 0.019), (85, 0.085), (89, 0.032), (93, 0.03), (95, 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.79853499 <a title="2-lda-1" href="./nips-2013-%28Nearly%29_Optimal_Algorithms_for_Private_Online_Learning_in_Full-information_and_Bandit_Settings.html">2 nips-2013-(Nearly) Optimal Algorithms for Private Online Learning in Full-information and Bandit Settings</a></p>
<p>Author: Abhradeep Guha Thakurta, Adam Smith</p><p>Abstract: We give differentially private algorithms for a large class of online learning algorithms, in both the full information and bandit settings. Our algorithms aim to minimize a convex loss function which is a sum of smaller convex loss terms, one for each data point. To design our algorithms, we modify the popular mirror descent approach, or rather a variant called follow the approximate leader. The technique leads to the ﬁrst nonprivate algorithms for private online learning in the bandit setting. In the full information setting, our algorithms improve over the regret bounds of previous work (due to Dwork, Naor, Pitassi and Rothblum (2010) and Jain, Kothari and Thakurta (2012)). In many cases, our algorithms (in both settings) match the dependence on the input length, T , of the optimal nonprivate regret bounds up to logarithmic factors in T . Our algorithms require logarithmic space and update time. 1</p><p>2 0.73531109 <a title="2-lda-2" href="./nips-2013-PAC-Bayes-Empirical-Bernstein_Inequality.html">242 nips-2013-PAC-Bayes-Empirical-Bernstein Inequality</a></p>
<p>Author: Ilya O. Tolstikhin, Yevgeny Seldin</p><p>Abstract: We present a PAC-Bayes-Empirical-Bernstein inequality. The inequality is based on a combination of the PAC-Bayesian bounding technique with an Empirical Bernstein bound. We show that when the empirical variance is signiﬁcantly smaller than the empirical loss the PAC-Bayes-Empirical-Bernstein inequality is signiﬁcantly tighter than the PAC-Bayes-kl inequality of Seeger (2002) and otherwise it is comparable. Our theoretical analysis is conﬁrmed empirically on a synthetic example and several UCI datasets. The PAC-Bayes-Empirical-Bernstein inequality is an interesting example of an application of the PAC-Bayesian bounding technique to self-bounding functions. 1</p><p>3 0.7198959 <a title="2-lda-3" href="./nips-2013-Structured_Learning_via_Logistic_Regression.html">318 nips-2013-Structured Learning via Logistic Regression</a></p>
<p>Author: Justin Domke</p><p>Abstract: A successful approach to structured learning is to write the learning objective as a joint function of linear parameters and inference messages, and iterate between updates to each. This paper observes that if the inference problem is “smoothed” through the addition of entropy terms, for ﬁxed messages, the learning objective reduces to a traditional (non-structured) logistic regression problem with respect to parameters. In these logistic regression problems, each training example has a bias term determined by the current set of messages. Based on this insight, the structured energy function can be extended from linear factors to any function class where an “oracle” exists to minimize a logistic loss.</p><p>4 0.69793963 <a title="2-lda-4" href="./nips-2013-From_Bandits_to_Experts%3A_A_Tale_of_Domination_and_Independence.html">125 nips-2013-From Bandits to Experts: A Tale of Domination and Independence</a></p>
<p>Author: Noga Alon, Nicolò Cesa-Bianchi, Claudio Gentile, Yishay Mansour</p><p>Abstract: We consider the partial observability model for multi-armed bandits, introduced by Mannor and Shamir [14]. Our main result is a characterization of regret in the directed observability model in terms of the dominating and independence numbers of the observability graph (which must be accessible before selecting an action). In the undirected case, we show that the learner can achieve optimal regret without even accessing the observability graph before selecting an action. Both results are shown using variants of the Exp3 algorithm operating on the observability graph in a time-efﬁcient manner. 1</p><p>5 0.6947462 <a title="2-lda-5" href="./nips-2013-Dimension-Free_Exponentiated_Gradient.html">89 nips-2013-Dimension-Free Exponentiated Gradient</a></p>
<p>Author: Francesco Orabona</p><p>Abstract: I present a new online learning algorithm that extends the exponentiated gradient framework to inﬁnite dimensional spaces. My analysis shows that the algorithm is implicitly able to estimate the L2 norm of the unknown competitor, U , achieving √ a regret bound of the order of O(U log(U T + 1)) T ), instead of the standard √ O((U 2 + 1) T ), achievable without knowing U . For this analysis, I introduce novel tools for algorithms with time-varying regularizers, through the use of local smoothness. Through a lower bound, I also show that the algorithm is optimal up to log(U T ) term for linear and Lipschitz losses. 1</p><p>6 0.68998402 <a title="2-lda-6" href="./nips-2013-Adaptive_Submodular_Maximization_in_Bandit_Setting.html">29 nips-2013-Adaptive Submodular Maximization in Bandit Setting</a></p>
<p>7 0.68960899 <a title="2-lda-7" href="./nips-2013-Computing_the_Stationary_Distribution_Locally.html">66 nips-2013-Computing the Stationary Distribution Locally</a></p>
<p>8 0.68864465 <a title="2-lda-8" href="./nips-2013-Online_Learning_in_Markov_Decision_Processes_with_Adversarially_Chosen_Transition_Probability_Distributions.html">227 nips-2013-Online Learning in Markov Decision Processes with Adversarially Chosen Transition Probability Distributions</a></p>
<p>9 0.68643814 <a title="2-lda-9" href="./nips-2013-Near-Optimal_Entrywise_Sampling_for_Data_Matrices.html">206 nips-2013-Near-Optimal Entrywise Sampling for Data Matrices</a></p>
<p>10 0.68576193 <a title="2-lda-10" href="./nips-2013-Improved_and_Generalized_Upper_Bounds_on_the_Complexity_of_Policy_Iteration.html">140 nips-2013-Improved and Generalized Upper Bounds on the Complexity of Policy Iteration</a></p>
<p>11 0.68548852 <a title="2-lda-11" href="./nips-2013-Online_Learning_of_Dynamic_Parameters_in_Social_Networks.html">228 nips-2013-Online Learning of Dynamic Parameters in Social Networks</a></p>
<p>12 0.68547606 <a title="2-lda-12" href="./nips-2013-Optimization%2C_Learning%2C_and_Games_with_Predictable_Sequences.html">240 nips-2013-Optimization, Learning, and Games with Predictable Sequences</a></p>
<p>13 0.68498087 <a title="2-lda-13" href="./nips-2013-Online_Learning_with_Costly_Features_and_Labels.html">230 nips-2013-Online Learning with Costly Features and Labels</a></p>
<p>14 0.68382269 <a title="2-lda-14" href="./nips-2013-Information-theoretic_lower_bounds_for_distributed_statistical_estimation_with_communication_constraints.html">142 nips-2013-Information-theoretic lower bounds for distributed statistical estimation with communication constraints</a></p>
<p>15 0.68318915 <a title="2-lda-15" href="./nips-2013-Tracking_Time-varying_Graphical_Structure.html">332 nips-2013-Tracking Time-varying Graphical Structure</a></p>
<p>16 0.68046331 <a title="2-lda-16" href="./nips-2013-Online_PCA_for_Contaminated_Data.html">232 nips-2013-Online PCA for Contaminated Data</a></p>
<p>17 0.68021274 <a title="2-lda-17" href="./nips-2013-On_the_Sample_Complexity_of_Subspace_Learning.html">224 nips-2013-On the Sample Complexity of Subspace Learning</a></p>
<p>18 0.67729396 <a title="2-lda-18" href="./nips-2013-Distributed_Exploration_in_Multi-Armed_Bandits.html">95 nips-2013-Distributed Exploration in Multi-Armed Bandits</a></p>
<p>19 0.67651755 <a title="2-lda-19" href="./nips-2013-Sequential_Transfer_in_Multi-armed_Bandit_with_Finite_Set_of_Models.html">292 nips-2013-Sequential Transfer in Multi-armed Bandit with Finite Set of Models</a></p>
<p>20 0.6756801 <a title="2-lda-20" href="./nips-2013-Online_Learning_with_Switching_Costs_and_Other_Adaptive_Adversaries.html">231 nips-2013-Online Learning with Switching Costs and Other Adaptive Adversaries</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
