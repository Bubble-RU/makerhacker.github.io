<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>113 nips-2010-Heavy-Tailed Process Priors for Selective Shrinkage</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-113" href="#">nips2010-113</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>113 nips-2010-Heavy-Tailed Process Priors for Selective Shrinkage</h1>
<br/><p>Source: <a title="nips-2010-113-pdf" href="http://papers.nips.cc/paper/3996-heavy-tailed-process-priors-for-selective-shrinkage.pdf">pdf</a></p><p>Author: Fabian L. Wauthier, Michael I. Jordan</p><p>Abstract: Heavy-tailed distributions are often used to enhance the robustness of regression and classiﬁcation methods to outliers in output space. Often, however, we are confronted with “outliers” in input space, which are isolated observations in sparsely populated regions. We show that heavy-tailed stochastic processes (which we construct from Gaussian processes via a copula), can be used to improve robustness of regression and classiﬁcation estimators to such outliers by selectively shrinking them more strongly in sparse regions than in dense regions. We carry out a theoretical analysis to show that selective shrinkage occurs when the marginals of the heavy-tailed process have sufﬁciently heavy tails. The analysis is complemented by experiments on biological data which indicate signiﬁcant improvements of estimates in sparse regions while producing competitive results in dense regions. 1</p><p>Reference: <a title="nips-2010-113-reference" href="../nips2010_reference/nips-2010-Heavy-Tailed_Process_Priors_for_Selective_Shrinkage_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('hpc', 0.417), ('gpc', 0.375), ('rotam', 0.313), ('hpr', 0.271), ('gpr', 0.209), ('gb', 0.201), ('xd', 0.201), ('shrinkage', 0.198), ('residu', 0.185), ('copul', 0.171), ('xs', 0.142), ('hyperbol', 0.128), ('ygp', 0.125), ('laplac', 0.111), ('gp', 0.096), ('backbon', 0.084), ('diag', 0.08), ('gauss', 0.079), ('tree', 0.073), ('df', 0.07)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="113-tfidf-1" href="./nips-2010-Heavy-Tailed_Process_Priors_for_Selective_Shrinkage.html">113 nips-2010-Heavy-Tailed Process Priors for Selective Shrinkage</a></p>
<p>Author: Fabian L. Wauthier, Michael I. Jordan</p><p>Abstract: Heavy-tailed distributions are often used to enhance the robustness of regression and classiﬁcation methods to outliers in output space. Often, however, we are confronted with “outliers” in input space, which are isolated observations in sparsely populated regions. We show that heavy-tailed stochastic processes (which we construct from Gaussian processes via a copula), can be used to improve robustness of regression and classiﬁcation estimators to such outliers by selectively shrinking them more strongly in sparse regions than in dense regions. We carry out a theoretical analysis to show that selective shrinkage occurs when the marginals of the heavy-tailed process have sufﬁciently heavy tails. The analysis is complemented by experiments on biological data which indicate signiﬁcant improvements of estimates in sparse regions while producing competitive results in dense regions. 1</p><p>2 0.15007243 <a title="113-tfidf-2" href="./nips-2010-Copula_Bayesian_Networks.html">53 nips-2010-Copula Bayesian Networks</a></p>
<p>Author: Gal Elidan</p><p>Abstract: We present the Copula Bayesian Network model for representing multivariate continuous distributions, while taking advantage of the relative ease of estimating univariate distributions. Using a novel copula-based reparameterization of a conditional density, joined with a graph that encodes independencies, our model offers great ﬂexibility in modeling high-dimensional densities, while maintaining control over the form of the univariate marginals. We demonstrate the advantage of our framework for generalization over standard Bayesian networks as well as tree structured copula models for varied real-life domains that are of substantially higher dimension than those typically considered in the copula literature. 1</p><p>3 0.11608572 <a title="113-tfidf-3" href="./nips-2010-Copula_Processes.html">54 nips-2010-Copula Processes</a></p>
<p>Author: Andrew Wilson, Zoubin Ghahramani</p><p>Abstract: We deﬁne a copula process which describes the dependencies between arbitrarily many random variables independently of their marginal distributions. As an example, we develop a stochastic volatility model, Gaussian Copula Process Volatility (GCPV), to predict the latent standard deviations of a sequence of random variables. To make predictions we use Bayesian inference, with the Laplace approximation, and with Markov chain Monte Carlo as an alternative. We ﬁnd our model can outperform GARCH on simulated and ﬁnancial data. And unlike GARCH, GCPV can easily handle missing data, incorporate covariates other than time, and model a rich class of covariance structures. Imagine measuring the distance of a rocket as it leaves Earth, and wanting to know how these measurements correlate with one another. How much does the value of the measurement at ﬁfteen minutes depend on the measurement at ﬁve minutes? Once we’ve learned this correlation structure, suppose we want to compare it to the dependence between measurements of the rocket’s velocity. To do this, it is convenient to separate dependence from the marginal distributions of our measurements. At any given time, a rocket’s distance from Earth could have a Gamma distribution, while its velocity could have a Gaussian distribution. And separating dependence from marginal distributions is precisely what a copula function does. While copulas have recently become popular, especially in ﬁnancial applications [1, 2], as Nelsen [3] writes, “the study of copulas and the role they play in probability, statistics, and stochastic processes is a subject still in its infancy. There are many open problems. . . ” Typically only bivariate (and recently trivariate) copulas are being used and studied. In our introductory example, we are interested in learning the correlations in different stochastic processes, and comparing them. It would therefore be useful to have a copula process, which can describe the dependencies between arbitrarily many random variables independently of their marginal distributions. We deﬁne such a process. And as an example, we develop a stochastic volatility model, Gaussian Copula Process Volatility (GCPV). In doing so, we provide a Bayesian framework for the learning the marginal distributions and dependency structure of what we call a Gaussian copula process. The volatility of a random variable is its standard deviation. Stochastic volatility models are used to predict the volatilities of a heteroscedastic sequence – a sequence of random variables with different variances, like distance measurements of a rocket as it leaves the Earth. As the rocket gets further away, the variance on the measurements increases. Heteroscedasticity is especially important in econometrics; the returns on equity indices, like the S&P; 500, or on currency exchanges, are heteroscedastic. Indeed, in 2003, Robert Engle won the Nobel Prize in economics “for methods of analyzing economic time series with time-varying volatility”. GARCH [4], a generalized version of Engle’s ARCH, is arguably unsurpassed for predicting the volatility of returns on equity indices and currency exchanges [5, 6, 7]. GCPV can outperform GARCH, and is competitive on ﬁnancial data that especially suits GARCH [8, 9, 10]. Before discussing GCPV, we ﬁrst introduce copulas and the copula process. For a review of Gaussian processes, see Rasmussen and Williams [11]. ∗ † http://mlg.eng.cam.ac.uk/andrew Also at the machine learning department at Carnegie Mellon University. 1 1 Copulas Copulas are important because they separate the dependency structure between random variables from their marginal distributions. Intuitively, we can describe the dependency structure of any multivariate joint distribution H(x1 , . . . , xn ) = P (X1 ≤ x1 , . . . Xn ≤ xn ) through a two step process. First we take each univariate random variable Xi and transform it through its cumulative distribution function (cdf) Fi to get Ui = Fi (Xi ), a uniform random variable. We then express the dependencies between these transformed variables through the n-copula C(u1 , . . . , un ). Formally, an n-copula C : [0, 1]n → [0, 1] is a multivariate cdf with uniform univariate marginals: C(u1 , u2 , . . . , un ) = P (U1 ≤ u1 , U2 ≤ u2 , . . . , Un ≤ un ), where U1 , U2 , . . . , Un are standard uniform random variables. Sklar [12] precisely expressed our intuition in the theorem below. Theorem 1.1. Sklar’s theorem Let H be an n-dimensional distribution function with marginal distribution functions F1 , F2 , . . . , Fn . Then there exists an n-copula C such that for all (x1 , x2 , . . . , xn ) ∈ [−∞, ∞]n , H(x1 , x2 , . . . , xn ) = C(F1 (x1 ), F2 (x2 ), . . . , Fn (xn )) = C(u1 , u2 , . . . , un ). (1) If F1 , F2 , . . . , Fn are all continuous then C is unique; otherwise C is uniquely determined on Range F1 × Range F2 × · · · × Range Fn . Conversely, if C is an n-copula and F1 , F2 , . . . , Fn are distribution functions, then the function H is an n-dimensional distribution function with marginal distribution functions F1 , F2 , . . . , Fn . (−1) As a corollary, if Fi (u) = inf{x : F (x) ≥ u}, the quasi-inverse of Fi , then for all u1 , u2 , . . . , un ∈ [0, 1]n , (−1) C(u1 , u2 , . . . , un ) = H(F1 (−1) (u1 ), F2 (−1) (u2 ), . . . , Fn (un )). (2) In other words, (2) can be used to construct a copula. For example, the bivariate Gaussian copula is deﬁned as C(u, v) = Φρ (Φ−1 (u), Φ−1 (v)), (3) where Φρ is a bivariate Gaussian cdf with correlation coefﬁcient ρ, and Φ is the standard univariate Gaussian cdf. Li [2] popularised the bivariate Gaussian copula, by showing how it could be used to study ﬁnancial risk and default correlation, using credit derivatives as an example. By substituting F (x) for u and G(y) for v in equation (3), we have a bivariate distribution H(x, y), with a Gaussian dependency structure, and marginals F and G. Regardless of F and G, the resulting H(x, y) can still be uniquely expressed as a Gaussian copula, so long as F and G are continuous. It is then a copula itself that captures the underlying dependencies between random variables, regardless of their marginal distributions. For this reason, copulas have been called dependence functions [13, 14]. Nelsen [3] contains an extensive discussion of copulas. 2 Copula Processes Imagine choosing a covariance function, and then drawing a sample function at some ﬁnite number of points from a Gaussian process. The result is a sample from a collection of Gaussian random variables, with a dependency structure encoded by the speciﬁed covariance function. Now, suppose we transform each of these values through a univariate Gaussian cdf, such that we have a sample from a collection of uniform random variables. These uniform random variables also have this underlying Gaussian process dependency structure. One might call the resulting values a draw from a Gaussian-Uniform Process. We could subsequently put these values through an inverse beta cdf, to obtain a draw from what could be called a Gaussian-Beta Process: the values would be a sample from beta random variables, again with an underlying Gaussian process dependency structure. We could also transform the uniform values with different inverse cdfs, which would give a sample from different random variables, with dependencies encoded by the Gaussian process. The above procedure is a means to generate samples from arbitrarily many random variables, with arbitrary marginal distributions, and desired dependencies. It is an example of how to use what we call a copula process – in this case, a Gaussian copula process, since a Gaussian copula describes the dependency structure of a ﬁnite number of samples. We now formally deﬁne a copula process. 2 Deﬁnition 2.1. Copula Process Let {Wt } be a collection of random variables indexed by t ∈ T , with marginal distribution functions Ft , and let Qt = Ft (Wt ). Further, let µ be a stochastic process measure with marginal distribution functions Gt , and joint distribution function H. Then Wt is copula process distributed with base measure µ, or Wt ∼ CP(µ), if and only if for all n ∈ N, ai ∈ R, n P( (−1) {Gti (Qti ) ≤ ai }) = Ht1 ,t2 ,...,tn (a1 , a2 , . . . , an ). (4) i=1 (−1) Each Qti ∼ Uniform(0, 1), and Gti is the quasi-inverse of Gti , as previously deﬁned. Deﬁnition 2.2. Gaussian Copula Process Wt is Gaussian copula process distributed if it is copula process distributed and the base measure µ is a Gaussian process. If there is a mapping Ψ such that Ψ(Wt ) ∼ GP(m(t), k(t, t )), then we write Wt ∼ GCP(Ψ, m(t), k(t, t )). For example, if we have Wt ∼ GCP with m(t) = 0 and k(t, t) = 1, then in the deﬁnition of a copula process, Gt = Φ, the standard univariate Gaussian cdf, and H is the usual GP joint distribution function. Supposing this GCP is a Gaussian-Beta process, then Ψ = Φ−1 ◦ FB , where FB is a univariate Beta cdf. One could similarly deﬁne other copula processes. We described generally how a copula process can be used to generate samples of arbitrarily many random variables with desired marginals and dependencies. We now develop a speciﬁc and practical application of this framework. We introduce a stochastic volatility model, Gaussian Copula Process Volatility (GCPV), as an example of how to learn the joint distribution of arbitrarily many random variables, the marginals of these random variables, and to make predictions. To do this, we ﬁt a Gaussian copula process by using a type of Warped Gaussian Process [15]. However, our methodology varies substantially from Snelson et al. [15], since we are doing inference on latent variables as opposed to observations, which is a much greater undertaking that involves approximations, and we are doing so in a different context. 3 Gaussian Copula Process Volatility Assume we have a sequence of observations y = (y1 , . . . , yn ) at times t = (t1 , . . . , tn ) . The observations are random variables with different latent standard deviations. We therefore have n unobserved standard deviations, σ1 , . . . , σn , and want to learn the correlation structure between these standard deviations, and also to predict the distribution of σ∗ at some unrealised time t∗ . We model the standard deviation function as a Gaussian copula process: σt ∼ GCP(g −1 , 0, k(t, t )). (5) f (t) ∼ GP(m(t) = 0, k(t, t )) σ(t) = g(f (t), ω) (6) (7) y(t) ∼ N (0, σ 2 (t)), (8) Speciﬁcally, where g is a monotonic warping function, parametrized by ω. For each of the observations y = (y1 , . . . , yn ) we have corresponding GP latent function values f = (f1 , . . . , fn ) , where σ(ti ) = g(fi , ω), using the shorthand fi to mean f (ti ). σt ∼ GCP, because any ﬁnite sequence (σ1 , . . . , σp ) is distributed as a Gaussian copula: P (σ1 ≤ a1 , . . . , σp ≤ ap ) = P (g −1 (σ1 ) ≤ g −1 (a1 ), . . . , g −1 (σp ) ≤ g −1 (ap )) = ΦΓ (g −1 (a1 ), . . . , g −1 −1 (ap )) = ΦΓ (Φ = ΦΓ (Φ −1 (F (a1 )), . . . , Φ (u1 ), . . . , Φ −1 −1 (9) (F (ap ))) (up )) = C(u1 , . . . , up ), where Φ is the standard univariate Gaussian cdf (supposing k(t, t) = 1), ΦΓ is a multivariate Gaussian cdf with covariance matrix Γij = cov(g −1 (σi ), g −1 (σj )), and F is the marginal distribution of 3 each σi . In (5), we have Ψ = g −1 , because it is g −1 which maps σt to a GP. The speciﬁcation in (5) is equivalently expressed by (6) and (7). With GCPV, the form of g is learned so that g −1 (σt ) is best modelled by a GP. By learning g, we learn the marginal of each σ: F (a) = Φ(g −1 (a)) for a ∈ R. Recently, a different sort of ‘kernel copula process’ has been used, where the marginals of the variables being modelled are not learned [16].1 Further, we also consider a more subtle and ﬂexible form of our model, where the function g itself is indexed by time: g = gt (f (t), ω). We only assume that the marginal distributions of σt are stationary over ‘small’ time periods, and for each of these time periods (5)-(7) hold true. We return to this in the ﬁnal discussion section. Here we have assumed that each observation, conditioned on knowing its variance, is normally distributed with zero mean. This is a common assumption in heteroscedastic models. The zero mean and normality assumptions can be relaxed and are not central to this paper. 4 Predictions with GCPV Ultimately, we wish to infer p(σ(t∗ )|y, z), where z = {θ, ω}, and θ are the hyperparameters of the GP covariance function. To do this, we sample from p(f∗ |y, z) = p(f∗ |f , θ)p(f |y, z)df (10) and then transform these samples by g. Letting (Cf )ij = δij g(fi , ω)2 , where δij is the Kronecker delta, Kij = k(ti , tj ), (k∗ )i = k(t∗ , ti ), we have p(f |y, z) = N (f ; 0, K)N (y; 0, Cf )/p(y|z), p(f∗ |f , θ) = N (k∗ K −1 f , k(t∗ , t∗ ) − k∗ K −1 (11) k∗ ). (12) We also wish to learn z, which we can do by ﬁnding the z that maximizes the marginal likelihood, ˆ p(y|z) = p(y|f , ω)p(f |θ)df . (13) Unfortunately, for many functions g, (10) and (13) are intractable. Our methods of dealing with this can be used in very general circumstances, where one has a Gaussian process prior, but an (optionally parametrized) non-Gaussian likelihood. We use the Laplace approximation to estimate p(f |y, z) as a Gaussian. Then we can integrate (10) for a Gaussian approximation to p(f∗ |y, z), which we sample from to make predictions of σ∗ . Using Laplace, we can also ﬁnd an expression for an approximate marginal likelihood, which we maximize to determine z. Once we have found z with Laplace, we use Markov chain Monte Carlo to sample from p(f∗ |y, z), and compare that to using Laplace to sample from p(f∗ |y, z). In the supplement we relate this discussion to (9). 4.1 Laplace Approximation The goal is to approximate (11) with a Gaussian, so that we can evaluate (10) and (13) and make predictions. In doing so, we follow Rasmussen and Williams [11] in their treatment of Gaussian process classiﬁcation, except we use a parametrized likelihood, and modify Newton’s method. First, consider as an objective function the logarithm of an unnormalized (11): s(f |y, z) = log p(y|f , ω) + log p(f |θ). (14) ˆ The Laplace approximation uses a second order Taylor expansion about the f which maximizes ˆ, for which we use (14), to ﬁnd an approximate objective s(f |y, z). So the ﬁrst step is to ﬁnd f ˜ Newton’s method. The Newton update is f new = f − ( s(f ))−1 s(f ). Differentiating (14), s(f |y, z) = s(f |y, z) = where W is the diagonal matrix − 1 log p(y|f , ω) − K −1 f log p(y|f , ω) − K −1 = −W − K −1 , log p(y|f , ω). Note added in proof : Also, for a very recent related model, see Rodr´guez et al. [17]. ı 4 (15) (16) If the likelihood function p(y|f , ω) is not log concave, then W may have negative entries. Vanhatalo et al. [18] found this to be problematic when doing Gaussian process regression with a Student-t ˆ likelihood. They instead use an expectation-maximization (EM) algorithm for ﬁnding f , and iterate ordered rank one Cholesky updates to evaluate the Laplace approximate marginal likelihood. But EM can converge slowly, especially near a local optimum, and each of the rank one updates is vulnerable to numerical instability. With a small modiﬁcation of Newton’s method, we often get close to ˆ quadratic convergence for ﬁnding f , and can evaluate the Laplace approximate marginal likelihood in a numerically stable fashion, with no approximate Cholesky factors, and optimal computational requirements. Some comments are in the supplementary material but, in short, we use an approximate negative Hessian, − s ≈ M + K −1 , which is guaranteed to be positive deﬁnite, since M is formed on each iteration by zeroing the negative entries of W . For stability, we reformulate our 1 1 1 1 optimization in terms of B = I + M 2 KM 2 , and let Q = M 2 B −1 M 2 , b = M f + log p(y|f ), a = b − QKb. Since (K −1 + M )−1 = K − KQK, the Newton update becomes f new = Ka. ˆ With these updates we ﬁnd f and get an expression for s which we use to approximate (13) and ˜ (11). The approximate marginal likelihood q(y|z) is given by exp(˜)df . Taking its logarithm, s 1ˆ 1 ˆ log q(y|z) = − f af + log p(y|f ) − log |Bf |, (17) ˆ ˆ 2 2 ˆ ˆ where Bf is B evaluated at f , and af is a numerically stable evaluation of K −1 f . ˆ ˆ To learn the parameters z, we use conjugate gradient descent to maximize (17) with respect to z. ˆ ˆ Since f is a function of z, we initialize z, and update f every time we vary z. Once we have found an optimum z , we can make predictions. By exponentiating s, we ﬁnd a Gaussian approximation to ˆ ˜ ˆ the posterior (11), q(f |y, z) = N (f , K − KQK). The product of this approximate posterior with p(f∗ |f ) is Gaussian. Integrating this product, we approximate p(f∗ |y, z) as ˆ q(f∗ |y, z) = N (k∗ log p(y|f ), k(t∗ , t∗ ) − k∗ Qk∗ ). (18) Given n training observations, the cost of each Newton iteration is dominated by computing the cholesky decomposition of B, which takes O(n3 ) operations. The objective function typically changes by less than 10−6 after 3 iterations. Once Newton’s method has converged, it takes only O(1) operations to draw from q(f∗ |y, z) and make predictions. 4.2 Markov chain Monte Carlo We use Markov chain Monte Carlo (MCMC) to sample from (11), so that we can later sample from p(σ∗ |y, z) to make predictions. Sampling from (11) is difﬁcult, because the variables f are strongly coupled by a Gaussian process prior. We use a new technique, Elliptical Slice Sampling [19], and ﬁnd it extremely effective for this purpose. It was speciﬁcally designed to sample from posteriors with correlated Gaussian priors. It has no free parameters, and jointly updates every element of f . For our setting, it is over 100 times as fast as axis aligned slice sampling with univariate updates. To make predictions, we take J samples of p(f |y, z), {f 1 , . . . , f J }, and then approximate (10) as a mixture of J Gaussians: J 1 p(f∗ |f i , θ). (19) p(f∗ |y, z) ≈ J i=1 Each of the Gaussians in this mixture have equal weight. So for each sample of f∗ |y, we uniformly choose a random p(f∗ |f i , θ) and draw a sample. In the limit J → ∞, we are sampling from the exact p(f∗ |y, z). Mapping these samples through g gives samples from p(σ∗ |y, z). After one O(n3 ) and one O(J) operation, a draw from (19) takes O(1) operations. 4.3 Warping Function The warping function, g, maps fi , a GP function value, to σi , a standard deviation. Since fi can take any value in R, and σi can take any non-negative real value, g : R → R+ . For each fi to correspond to a unique deviation, g must also be one-to-one. We use K g(x, ω) = aj log[exp[bj (x + cj )] + 1], j=1 5 aj , bj > 0. (20) This is monotonic, positive, inﬁnitely differentiable, asymptotic towards zero as x → −∞, and K tends to ( j=1 aj bj )x as x → ∞. In practice, it is useful to add a small constant to (20), to avoid rare situations where the parameters ω are trained to make g extremely small for certain inputs, at the expense of a good overall ﬁt; this can happen when the parameters ω are learned by optimizing a likelihood. A suitable constant could be one tenth the absolute value of the smallest nonzero observation. By inferring the parameters of the warping function, or distributions of these parameters, we are learning a transformation which will best model σt with a Gaussian process. The more ﬂexible the warping function, the more potential there is to improve the GCPV ﬁt – in other words, the better we can estimate the ‘perfect’ transformation. To test the importance of this ﬂexibility, we also try a simple unparametrized warping function, g(x) = ex . In related work, Goldberg et al. [20] place a GP prior on the log noise level in a standard GP regression model on observations, except for inference they use Gibbs sampling, and a high level of ‘jitter’ for conditioning. Once g is trained, we can infer the marginal distribution of each σ: F (a) = Φ(g −1 (a)), for a ∈ R. This suggests an alternate way to initialize g: we can initialize F as a mixture of Gaussians, and then map through Φ−1 to ﬁnd g −1 . Since mixtures of Gaussians are dense in the set of probability distributions, we could in principle ﬁnd the ‘perfect’ g using an inﬁnite mixture of Gaussians [21]. 5 Experiments In our experiments, we predict the latent standard deviations σ of observations y at times t, and also σ∗ at unobserved times t∗ . To do this, we use two versions of GCPV. The ﬁrst variant, which we simply refer to as GCPV, uses the warping function (20) with K = 1, and squared exponential covariance function, k(t, t ) = A exp(−(t−t )2 /l2 ), with A = 1. The second variant, which we call GP-EXP, uses the unparametrized warping function ex , and the same covariance function, except the amplitude A is a trained hyperparameter. The other hyperparameter l is called the lengthscale of the covariance function. The greater l, the greater the covariance between σt and σt+a for a ∈ R. We train hyperparameters by maximizing the Laplace approximate log marginal likelihood (17). We then sample from p(f∗ |y) using the Laplace approximation (18). We also do this using MCMC (19) with J = 10000, after discarding a previous 10000 samples of p(f |y) as burn-in. We pass 2 these samples of f∗ |y through g and g 2 to draw from p(σ∗ |y) and p(σ∗ |y), and compute the sample mean and variance of σ∗ |y. We use the sample mean as a point predictor, and the sample variance for error bounds on these predictions, and we use 10000 samples to compute these quantities. For GCPV we use Laplace and MCMC for inference, but for GP-EXP we only use Laplace. We compare predictions to GARCH(1,1), which has been shown in extensive and recent reviews to be competitive with other GARCH variants, and more sophisticated models [5, 6, 7]. GARCH(p,q) speciﬁes y(t) ∼ p 2 2 N (0, σ 2 (t)), and lets the variance be a deterministic function of the past: σt = a0 + i=1 ai yt−i + q 2 j=1 bj σt−j . We use the Matlab Econometrics Toolbox implementation of GARCH, where the parameters a0 , ai and bj are estimated using a constrained maximum likelihood. We make forecasts of volatility, and we predict historical volatility. By ‘historical volatility’ we mean the volatility at observed time points, or between these points. Uncovering historical volatility is important. It could, for instance, be used to study what causes ﬂuctuations in the stock market, or to understand physical systems. To evaluate our model, we use the Mean Squared Error (MSE) between the true variance, or proxy for the truth, and the predicted variance. Although likelihood has advantages, we are limited in space, and we wish to harmonize with the econometrics literature, and other assessments of volatility models, where MSE is the standard. In a similar assessment of volatility models, Brownlees et al. [7] found that MSE and quasi-likelihood rankings were comparable. When the true variance is unknown we follow Brownlees et al. [7] and use squared observations as a proxy for the truth, to compare our model to GARCH.2 The more observations, the more reliable these performance estimates will be. However, not many observations (e.g. 100) are needed for a stable ranking of competing models; in Brownlees et al. [7], the rankings derived from high frequency squared observations are similar to those derived using daily squared observations. 2 Since each observation y is assumed to have zero mean and variance σ 2 , E[y 2 ] = σ 2 . 6 5.1 Simulations We simulate observations from N (0, σ 2 (t)), using σ(t) = sin(t) cos(t2 ) + 1, at t = (0, 0.02, 0.04, . . . , 4) . We call this data set TRIG. We also simulate using a standard deviation that jumps from 0.1 to 7 and back, at times t = (0, 0.1, 0.2, . . . , 6) . We call this data set JUMP. To forecast, we use all observations up until the current time point, and make 1, 7, and 30 step ahead predictions. So, for example, in TRIG we start by observing t = 0, and make forecasts at t = 0.02, 0.14, 0.60. Then we observe t = 0, 0.02 and make forecasts at t = 0.04, 0.16, 0.62, and so on, until all data points have been observed. For historical volatility, we predict the latent σt at the observation times, which is safe since we are comparing to the true volatility, which is not used in training; the results are similar if we interpolate. Figure 1 panels a) and b) show the true volatility for TRIG and JUMP respectively, alongside GCPV Laplace, GCPV MCMC, GP-EXP Laplace, and GARCH(1,1) predictions of historical volatility. Table 1 shows the results for forecasting and historical volatility. In panel a) we see that GCPV more accurately captures the dependencies between σ at different times points than GARCH: if we manually decrease the lengthscale in the GCPV covariance function, we can replicate the erratic GARCH behaviour, which inaccurately suggests that the covariance between σt and σt+a decreases quickly with increases in a. We also see that GCPV with an unparametrized exponential warping function tends to overestimates peaks and underestimate troughs. In panel b), the volatility is extremely difﬁcult to reconstruct or forecast – with no warning it will immediately and dramatically increase or decrease. This behaviour is not suited to a smooth squared exponential covariance function. Nevertheless, GCPV outperforms GARCH, especially in regions of low volatility. We also see this in panel a) for t ∈ (1.5, 2). GARCH is known to respond slowly to large returns, and to overpredict volatility [22]. In JUMP, the greater the peaks, and the smaller the troughs, the more GARCH suffers, while GCPV is mostly robust to these changes. 5.2 Financial Data The returns on the daily exchange rate between the Deutschmark (DM) and the Great Britain Pound (GBP) from 1984 to 1992 have become a benchmark for assessing the performance of GARCH models [8, 9, 10]. This exchange data, which we refer to as DMGBP, can be obtained from www.datastream.com, and the returns are calculated as rt = log(Pt+1 /Pt ), where Pt is the number of DM to GBP on day t. The returns are assumed to have a zero mean function. We use a rolling window of the previous 120 days of returns to make 1, 7, and 30 day ahead volatility forecasts, starting at the beginning of January 1988, and ending at the beginning of January 1992 (659 trading days). Every 7 days, we retrain the parameters of GCPV and GARCH. Every time we retrain parameters, we predict historical volatility over the past 120 days. The average MSE for these historical predictions is given in Table 1, although they should be observed with caution; unlike with the simulations, the DMGBP historical predictions are trained using the same data they are assessed on. In Figure 1c), we see that the GARCH one day ahead forecasts are lifted above the GCPV forecasts, but unlike in the simulations, they are now operating on a similar lengthscale. This suggests that GARCH could still be overpredicting volatility, but that GCPV has adapted its estimation of how σt and σt+a correlate with one another. Since GARCH is suited to this ﬁnancial data set, it is reassuring that GCPV predictions have a similar time varying structure. Overall, GCPV and GARCH are competitive with one another for forecasting currency exchange returns, as seen in Table 1. Moreover, a learned warping function g outperforms an unparametrized one, and a full Laplace solution is comparable to using MCMC for inference, in accuracy and speed. This is also true for the simulations. Therefore we recommend whichever is more convenient to implement. 6 Discussion We deﬁned a copula process, and as an example, developed a stochastic volatility model, GCPV, which can outperform GARCH. With GCPV, the volatility σt is distributed as a Gaussian Copula Process, which separates the modelling of the dependencies between volatilities at different times from their marginal distributions – arguably the most useful property of a copula. Further, GCPV ﬁts the marginals in the Gaussian copula process by learning a warping function. If we had simply chosen an unparametrized exponential warping function, we would incorrectly be assuming that the log 7 Table 1: MSE for predicting volatility. Data set Model Historical 1 step 7 step 30 step TRIG GCPV (LA) GCPV (MCMC) GP-EXP GARCH 0.0953 0.0760 0.193 0.938 0.588 0.622 0.646 1.04 0.951 0.979 1.36 1.79 1.71 1.76 1.15 5.12 JUMP GCPV (LA) GCPV (MCMC) GP-EXP GARCH 0.588 1.21 1.43 1.88 0.891 0.951 1.76 1.58 1.38 1.37 6.95 3.43 1.35 1.35 14.7 5.65 GCPV (LA) GCPV (MCMC) GP-EXP GARCH 2.43 2.39 2.52 2.83 3.00 3.00 3.20 3.03 3.08 3.08 3.46 3.12 3.17 3.17 5.14 3.32 ×103 DMGBP ×10−9 TRIG JUMP DMGBP 20 DMGBP 0.015 600 Probability Density 3 1 Volatility Volatility Volatility 15 2 10 0.01 0.005 5 0 0 1 2 Time (a) 3 4 0 0 2 4 0 6 Time (b) 0 200 400 Days (c) 600 400 200 0 0 0.005 σ (d) 0.01 Figure 1: Predicting volatility and learning its marginal pdf. For a) and b), the true volatility, and GCPV (MCMC), GCPV (LA), GP-EXP, and GARCH predictions, are shown respectively by a thick green line, a dashed thick blue line, a dashed black line, a cyan line, and a red line. a) shows predictions of historical volatility for TRIG, where the shade is a 95% conﬁdence interval about GCPV (MCMC) predictions. b) shows predictions of historical volatility for JUMP. In c), a black line and a dashed red line respectively show GCPV (LA) and GARCH one day ahead volatility forecasts for DMGBP. In d), a black line and a dashed blue line respectively show the GCPV learned marginal pdf of σt in DMGBP and a Gamma(4.15,0.00045) pdf. volatilities are marginally Gaussian distributed. Indeed, for the DMGBP data, we trained the warping function g over a 120 day period, and mapped its inverse through the univariate standard Gaussian cdf Φ, and differenced, to estimate the marginal probability density function (pdf) of σt over this period. The learned marginal pdf, shown in Figure 1d), is similar to a Gamma(4.15,0.00045) distribution. However, in using a rolling window to retrain the parameters of g, we do not assume that the marginals of σt are stationary; we have a time changing warping function. While GARCH is successful, and its simplicity is attractive, our model is also simple and has a number of advantages. We can effortlessly handle missing data, we can easily incorporate covariates other than time (like interest rates) in our covariance function, and we can choose from a rich class of covariance functions – squared exponential, Brownian motion, Mat´ rn, periodic, etc. In fact, the e volatility of high frequency intradaily returns on equity indices and currency exchanges is cyclical [23], and GCPV with a periodic covariance function is uniquely well suited to this data. And the parameters of GCPV, like the covariance function lengthscale, or the learned warping function, provide insight into the underlying source of volatility, unlike the parameters of GARCH. Finally, copulas are rapidly becoming popular in applications, but often only bivariate copulas are being used. With our copula process one can learn the dependencies between arbitrarily many random variables independently of their marginal distributions. We hope the Gaussian Copula Process Volatility model will encourage other applications of copula processes. More generally, we hope our work will help bring together the machine learning and econometrics communities. Acknowledgments: Thanks to Carl Edward Rasmussen and Ferenc Husz´ r for helpful conversaa tions. AGW is supported by an NSERC grant. 8 References [1] Paul Embrechts, Alexander McNeil, and Daniel Straumann. Correlation and dependence in risk management: Properties and pitfalls. In Risk Management: Value at risk and beyond, pages 176–223. Cambridge University Press, 1999. [2] David X. Li. On default correlation: A copula function approach. Journal of Fixed Income, 9(4):43–54, 2000. [3] Roger B. Nelsen. An Introduction to Copulas. Springer Series in Statistics, second edition, 2006. [4] Tim Bollerslev. Generalized autoregressive conditional heteroskedasticity. Journal of Econometrics, 31 (3):307–327, 1986. [5] Ser-Huang Poon and Clive W.J. Granger. Practical issues in forecasting volatility. Financial Analysts Journal, 61(1):45–56, 2005. [6] Peter Reinhard Hansen and Asger Lunde. A forecast comparison of volatility models: Does anything beat a GARCH(1,1). Journal of Applied Econometrics, 20(7):873–889, 2005. [7] Christian T. Brownlees, Robert F. Engle, and Bryan T. Kelly. A practical guide to volatility forecasting through calm and storm, 2009. Available at SSRN: http://ssrn.com/abstract=1502915. [8] T. Bollerslev and E. Ghysels. Periodic autoregressive conditional heteroscedasticity. Journal of Business and Economic Statistics, 14:139–151, 1996. [9] B.D. McCullough and C.G. Renfro. Benchmarks and software standards: A case study of GARCH procedures. Journal of Economic and Social Measurement, 25:59–71, 1998. [10] C. Brooks, S.P. Burke, and G. Persand. Benchmarks and the accuracy of GARCH model estimation. International Journal of Forecasting, 17:45–56, 2001. [11] Carl Edward Rasmussen and Christopher K.I. Williams. Gaussian processes for Machine Learning. The MIT Press, 2006. ` [12] Abe Sklar. Fonctions de r´ partition a n dimensions et leurs marges. Publ. Inst. Statist. Univ. Paris, 8: e 229–231, 1959. [13] P Deheuvels. Caract´ isation compl` te des lois extrˆ mes multivari´ s et de la convergence des types e e e e extrˆ mes. Publications de l’Institut de Statistique de l’Universit´ de Paris, 23:1–36, 1978. e e [14] G Kimeldorf and A Sampson. Uniform representations of bivariate distributions. Communications in Statistics, 4:617–627, 1982. [15] Edward Snelson, Carl Edward Rasmussen, and Zoubin Ghahramani. Warped Gaussian Processes. In NIPS, 2003. [16] Sebastian Jaimungal and Eddie K.H. Ng. Kernel-based Copula processes. In ECML PKDD, 2009. [17] A. Rodr´guez, D.B. Dunson, and A.E. Gelfand. Latent stick-breaking processes. Journal of the American ı Statistical Association, 105(490):647–659, 2010. [18] Jarno Vanhatalo, Pasi Jylanki, and Aki Vehtari. Gaussian process regression with Student-t likelihood. In NIPS, 2009. [19] Iain Murray, Ryan Prescott Adams, and David J.C. MacKay. Elliptical Slice Sampling. In AISTATS, 2010. [20] Paul W. Goldberg, Christopher K.I. Williams, and Christopher M. Bishop. Regression with inputdependent noise: A Gaussian process treatment. In NIPS, 1998. [21] Carl Edward Rasmussen. The Inﬁnite Gaussian Mixture Model. In NIPS, 2000. [22] Ruey S. Tsay. Analysis of Financial Time Series. John Wiley & Sons, 2002. [23] Torben G. Andersen and Tim Bollerslev. Intraday periodicity and volatility persistence in ﬁnancial markets. Journal of Empirical Finance, 4(2-3):115–158, 1997. 9</p><p>4 0.088144042 <a title="113-tfidf-4" href="./nips-2010-Gaussian_sampling_by_local_perturbations.html">101 nips-2010-Gaussian sampling by local perturbations</a></p>
<p>Author: George Papandreou, Alan L. Yuille</p><p>Abstract: We present a technique for exact simulation of Gaussian Markov random ﬁelds (GMRFs), which can be interpreted as locally injecting noise to each Gaussian factor independently, followed by computing the mean/mode of the perturbed GMRF. Coupled with standard iterative techniques for the solution of symmetric positive deﬁnite systems, this yields a very efﬁcient sampling algorithm with essentially linear complexity in terms of speed and memory requirements, well suited to extremely large scale probabilistic models. Apart from synthesizing data under a Gaussian model, the proposed technique directly leads to an efﬁcient unbiased estimator of marginal variances. Beyond Gaussian models, the proposed algorithm is also very useful for handling highly non-Gaussian continuously-valued MRFs such as those arising in statistical image modeling or in the ﬁrst layer of deep belief networks describing real-valued data, where the non-quadratic potentials coupling different sites can be represented as ﬁnite or inﬁnite mixtures of Gaussians with the help of local or distributed latent mixture assignment variables. The Bayesian treatment of such models most naturally involves a block Gibbs sampler which alternately draws samples of the conditionally independent latent mixture assignments and the conditionally multivariate Gaussian continuous vector and we show that it can directly beneﬁt from the proposed methods. 1</p><p>5 0.077493526 <a title="113-tfidf-5" href="./nips-2010-Estimation_of_Renyi_Entropy_and_Mutual_Information_Based_on_Generalized_Nearest-Neighbor_Graphs.html">80 nips-2010-Estimation of Renyi Entropy and Mutual Information Based on Generalized Nearest-Neighbor Graphs</a></p>
<p>Author: Barnabás Póczos, Csaba Szepesvári, David Tax</p><p>Abstract: We present simple and computationally efﬁcient nonparametric estimators of R´ nyi entropy and mutual information based on an i.i.d. sample drawn from an e unknown, absolutely continuous distribution over Rd . The estimators are calculated as the sum of p-th powers of the Euclidean lengths of the edges of the ‘generalized nearest-neighbor’ graph of the sample and the empirical copula of the sample respectively. For the ﬁrst time, we prove the almost sure consistency of these estimators and upper bounds on their rates of convergence, the latter of which under the assumption that the density underlying the sample is Lipschitz continuous. Experiments demonstrate their usefulness in independent subspace analysis. 1</p><p>6 0.070694506 <a title="113-tfidf-6" href="./nips-2010-Approximate_inference_in_continuous_time_Gaussian-Jump_processes.html">33 nips-2010-Approximate inference in continuous time Gaussian-Jump processes</a></p>
<p>7 0.066236131 <a title="113-tfidf-7" href="./nips-2010-Scrambled_Objects_for_Least-Squares_Regression.html">233 nips-2010-Scrambled Objects for Least-Squares Regression</a></p>
<p>8 0.065427341 <a title="113-tfidf-8" href="./nips-2010-Exact_learning_curves_for_Gaussian_process_regression_on_large_random_graphs.html">85 nips-2010-Exact learning curves for Gaussian process regression on large random graphs</a></p>
<p>9 0.058059867 <a title="113-tfidf-9" href="./nips-2010-Kernel_Descriptors_for_Visual_Recognition.html">133 nips-2010-Kernel Descriptors for Visual Recognition</a></p>
<p>10 0.057090223 <a title="113-tfidf-10" href="./nips-2010-Group_Sparse_Coding_with_a_Laplacian_Scale_Mixture_Prior.html">109 nips-2010-Group Sparse Coding with a Laplacian Scale Mixture Prior</a></p>
<p>11 0.056747701 <a title="113-tfidf-11" href="./nips-2010-Probabilistic_latent_variable_models_for_distinguishing_between_cause_and_effect.html">218 nips-2010-Probabilistic latent variable models for distinguishing between cause and effect</a></p>
<p>12 0.055661045 <a title="113-tfidf-12" href="./nips-2010-Worst-case_bounds_on_the_quality_of_max-product_fixed-points.html">288 nips-2010-Worst-case bounds on the quality of max-product fixed-points</a></p>
<p>13 0.051760159 <a title="113-tfidf-13" href="./nips-2010-Slice_sampling_covariance_hyperparameters_of_latent_Gaussian_models.html">242 nips-2010-Slice sampling covariance hyperparameters of latent Gaussian models</a></p>
<p>14 0.051628243 <a title="113-tfidf-14" href="./nips-2010-Spatial_and_anatomical_regularization_of_SVM_for_brain_image_analysis.html">249 nips-2010-Spatial and anatomical regularization of SVM for brain image analysis</a></p>
<p>15 0.051416583 <a title="113-tfidf-15" href="./nips-2010-Unsupervised_Kernel_Dimension_Reduction.html">280 nips-2010-Unsupervised Kernel Dimension Reduction</a></p>
<p>16 0.051001266 <a title="113-tfidf-16" href="./nips-2010-Learning_Kernels_with_Radiuses_of_Minimum_Enclosing_Balls.html">145 nips-2010-Learning Kernels with Radiuses of Minimum Enclosing Balls</a></p>
<p>17 0.049901593 <a title="113-tfidf-17" href="./nips-2010-Gaussian_Process_Preference_Elicitation.html">100 nips-2010-Gaussian Process Preference Elicitation</a></p>
<p>18 0.048908263 <a title="113-tfidf-18" href="./nips-2010-Universal_Kernels_on_Non-Standard_Input_Spaces.html">279 nips-2010-Universal Kernels on Non-Standard Input Spaces</a></p>
<p>19 0.047809407 <a title="113-tfidf-19" href="./nips-2010-Relaxed_Clipping%3A_A_Global_Training_Method_for_Robust_Regression_and_Classification.html">225 nips-2010-Relaxed Clipping: A Global Training Method for Robust Regression and Classification</a></p>
<p>20 0.047442045 <a title="113-tfidf-20" href="./nips-2010-Active_Learning_by_Querying_Informative_and_Representative_Examples.html">25 nips-2010-Active Learning by Querying Informative and Representative Examples</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.146), (1, -0.045), (2, 0.005), (3, -0.032), (4, -0.028), (5, 0.082), (6, -0.024), (7, -0.039), (8, 0.001), (9, -0.028), (10, -0.005), (11, -0.04), (12, 0.064), (13, 0.061), (14, 0.007), (15, -0.011), (16, 0.023), (17, 0.074), (18, 0.136), (19, 0.091), (20, 0.018), (21, 0.035), (22, 0.092), (23, -0.124), (24, 0.024), (25, 0.102), (26, -0.052), (27, -0.053), (28, -0.098), (29, -0.141), (30, 0.044), (31, -0.135), (32, 0.007), (33, 0.038), (34, 0.112), (35, -0.151), (36, -0.044), (37, 0.04), (38, -0.002), (39, -0.037), (40, 0.001), (41, -0.002), (42, -0.018), (43, -0.009), (44, -0.037), (45, 0.02), (46, 0.003), (47, 0.081), (48, -0.055), (49, 0.042)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.84111571 <a title="113-lsi-1" href="./nips-2010-Copula_Processes.html">54 nips-2010-Copula Processes</a></p>
<p>Author: Andrew Wilson, Zoubin Ghahramani</p><p>Abstract: We deﬁne a copula process which describes the dependencies between arbitrarily many random variables independently of their marginal distributions. As an example, we develop a stochastic volatility model, Gaussian Copula Process Volatility (GCPV), to predict the latent standard deviations of a sequence of random variables. To make predictions we use Bayesian inference, with the Laplace approximation, and with Markov chain Monte Carlo as an alternative. We ﬁnd our model can outperform GARCH on simulated and ﬁnancial data. And unlike GARCH, GCPV can easily handle missing data, incorporate covariates other than time, and model a rich class of covariance structures. Imagine measuring the distance of a rocket as it leaves Earth, and wanting to know how these measurements correlate with one another. How much does the value of the measurement at ﬁfteen minutes depend on the measurement at ﬁve minutes? Once we’ve learned this correlation structure, suppose we want to compare it to the dependence between measurements of the rocket’s velocity. To do this, it is convenient to separate dependence from the marginal distributions of our measurements. At any given time, a rocket’s distance from Earth could have a Gamma distribution, while its velocity could have a Gaussian distribution. And separating dependence from marginal distributions is precisely what a copula function does. While copulas have recently become popular, especially in ﬁnancial applications [1, 2], as Nelsen [3] writes, “the study of copulas and the role they play in probability, statistics, and stochastic processes is a subject still in its infancy. There are many open problems. . . ” Typically only bivariate (and recently trivariate) copulas are being used and studied. In our introductory example, we are interested in learning the correlations in different stochastic processes, and comparing them. It would therefore be useful to have a copula process, which can describe the dependencies between arbitrarily many random variables independently of their marginal distributions. We deﬁne such a process. And as an example, we develop a stochastic volatility model, Gaussian Copula Process Volatility (GCPV). In doing so, we provide a Bayesian framework for the learning the marginal distributions and dependency structure of what we call a Gaussian copula process. The volatility of a random variable is its standard deviation. Stochastic volatility models are used to predict the volatilities of a heteroscedastic sequence – a sequence of random variables with different variances, like distance measurements of a rocket as it leaves the Earth. As the rocket gets further away, the variance on the measurements increases. Heteroscedasticity is especially important in econometrics; the returns on equity indices, like the S&P; 500, or on currency exchanges, are heteroscedastic. Indeed, in 2003, Robert Engle won the Nobel Prize in economics “for methods of analyzing economic time series with time-varying volatility”. GARCH [4], a generalized version of Engle’s ARCH, is arguably unsurpassed for predicting the volatility of returns on equity indices and currency exchanges [5, 6, 7]. GCPV can outperform GARCH, and is competitive on ﬁnancial data that especially suits GARCH [8, 9, 10]. Before discussing GCPV, we ﬁrst introduce copulas and the copula process. For a review of Gaussian processes, see Rasmussen and Williams [11]. ∗ † http://mlg.eng.cam.ac.uk/andrew Also at the machine learning department at Carnegie Mellon University. 1 1 Copulas Copulas are important because they separate the dependency structure between random variables from their marginal distributions. Intuitively, we can describe the dependency structure of any multivariate joint distribution H(x1 , . . . , xn ) = P (X1 ≤ x1 , . . . Xn ≤ xn ) through a two step process. First we take each univariate random variable Xi and transform it through its cumulative distribution function (cdf) Fi to get Ui = Fi (Xi ), a uniform random variable. We then express the dependencies between these transformed variables through the n-copula C(u1 , . . . , un ). Formally, an n-copula C : [0, 1]n → [0, 1] is a multivariate cdf with uniform univariate marginals: C(u1 , u2 , . . . , un ) = P (U1 ≤ u1 , U2 ≤ u2 , . . . , Un ≤ un ), where U1 , U2 , . . . , Un are standard uniform random variables. Sklar [12] precisely expressed our intuition in the theorem below. Theorem 1.1. Sklar’s theorem Let H be an n-dimensional distribution function with marginal distribution functions F1 , F2 , . . . , Fn . Then there exists an n-copula C such that for all (x1 , x2 , . . . , xn ) ∈ [−∞, ∞]n , H(x1 , x2 , . . . , xn ) = C(F1 (x1 ), F2 (x2 ), . . . , Fn (xn )) = C(u1 , u2 , . . . , un ). (1) If F1 , F2 , . . . , Fn are all continuous then C is unique; otherwise C is uniquely determined on Range F1 × Range F2 × · · · × Range Fn . Conversely, if C is an n-copula and F1 , F2 , . . . , Fn are distribution functions, then the function H is an n-dimensional distribution function with marginal distribution functions F1 , F2 , . . . , Fn . (−1) As a corollary, if Fi (u) = inf{x : F (x) ≥ u}, the quasi-inverse of Fi , then for all u1 , u2 , . . . , un ∈ [0, 1]n , (−1) C(u1 , u2 , . . . , un ) = H(F1 (−1) (u1 ), F2 (−1) (u2 ), . . . , Fn (un )). (2) In other words, (2) can be used to construct a copula. For example, the bivariate Gaussian copula is deﬁned as C(u, v) = Φρ (Φ−1 (u), Φ−1 (v)), (3) where Φρ is a bivariate Gaussian cdf with correlation coefﬁcient ρ, and Φ is the standard univariate Gaussian cdf. Li [2] popularised the bivariate Gaussian copula, by showing how it could be used to study ﬁnancial risk and default correlation, using credit derivatives as an example. By substituting F (x) for u and G(y) for v in equation (3), we have a bivariate distribution H(x, y), with a Gaussian dependency structure, and marginals F and G. Regardless of F and G, the resulting H(x, y) can still be uniquely expressed as a Gaussian copula, so long as F and G are continuous. It is then a copula itself that captures the underlying dependencies between random variables, regardless of their marginal distributions. For this reason, copulas have been called dependence functions [13, 14]. Nelsen [3] contains an extensive discussion of copulas. 2 Copula Processes Imagine choosing a covariance function, and then drawing a sample function at some ﬁnite number of points from a Gaussian process. The result is a sample from a collection of Gaussian random variables, with a dependency structure encoded by the speciﬁed covariance function. Now, suppose we transform each of these values through a univariate Gaussian cdf, such that we have a sample from a collection of uniform random variables. These uniform random variables also have this underlying Gaussian process dependency structure. One might call the resulting values a draw from a Gaussian-Uniform Process. We could subsequently put these values through an inverse beta cdf, to obtain a draw from what could be called a Gaussian-Beta Process: the values would be a sample from beta random variables, again with an underlying Gaussian process dependency structure. We could also transform the uniform values with different inverse cdfs, which would give a sample from different random variables, with dependencies encoded by the Gaussian process. The above procedure is a means to generate samples from arbitrarily many random variables, with arbitrary marginal distributions, and desired dependencies. It is an example of how to use what we call a copula process – in this case, a Gaussian copula process, since a Gaussian copula describes the dependency structure of a ﬁnite number of samples. We now formally deﬁne a copula process. 2 Deﬁnition 2.1. Copula Process Let {Wt } be a collection of random variables indexed by t ∈ T , with marginal distribution functions Ft , and let Qt = Ft (Wt ). Further, let µ be a stochastic process measure with marginal distribution functions Gt , and joint distribution function H. Then Wt is copula process distributed with base measure µ, or Wt ∼ CP(µ), if and only if for all n ∈ N, ai ∈ R, n P( (−1) {Gti (Qti ) ≤ ai }) = Ht1 ,t2 ,...,tn (a1 , a2 , . . . , an ). (4) i=1 (−1) Each Qti ∼ Uniform(0, 1), and Gti is the quasi-inverse of Gti , as previously deﬁned. Deﬁnition 2.2. Gaussian Copula Process Wt is Gaussian copula process distributed if it is copula process distributed and the base measure µ is a Gaussian process. If there is a mapping Ψ such that Ψ(Wt ) ∼ GP(m(t), k(t, t )), then we write Wt ∼ GCP(Ψ, m(t), k(t, t )). For example, if we have Wt ∼ GCP with m(t) = 0 and k(t, t) = 1, then in the deﬁnition of a copula process, Gt = Φ, the standard univariate Gaussian cdf, and H is the usual GP joint distribution function. Supposing this GCP is a Gaussian-Beta process, then Ψ = Φ−1 ◦ FB , where FB is a univariate Beta cdf. One could similarly deﬁne other copula processes. We described generally how a copula process can be used to generate samples of arbitrarily many random variables with desired marginals and dependencies. We now develop a speciﬁc and practical application of this framework. We introduce a stochastic volatility model, Gaussian Copula Process Volatility (GCPV), as an example of how to learn the joint distribution of arbitrarily many random variables, the marginals of these random variables, and to make predictions. To do this, we ﬁt a Gaussian copula process by using a type of Warped Gaussian Process [15]. However, our methodology varies substantially from Snelson et al. [15], since we are doing inference on latent variables as opposed to observations, which is a much greater undertaking that involves approximations, and we are doing so in a different context. 3 Gaussian Copula Process Volatility Assume we have a sequence of observations y = (y1 , . . . , yn ) at times t = (t1 , . . . , tn ) . The observations are random variables with different latent standard deviations. We therefore have n unobserved standard deviations, σ1 , . . . , σn , and want to learn the correlation structure between these standard deviations, and also to predict the distribution of σ∗ at some unrealised time t∗ . We model the standard deviation function as a Gaussian copula process: σt ∼ GCP(g −1 , 0, k(t, t )). (5) f (t) ∼ GP(m(t) = 0, k(t, t )) σ(t) = g(f (t), ω) (6) (7) y(t) ∼ N (0, σ 2 (t)), (8) Speciﬁcally, where g is a monotonic warping function, parametrized by ω. For each of the observations y = (y1 , . . . , yn ) we have corresponding GP latent function values f = (f1 , . . . , fn ) , where σ(ti ) = g(fi , ω), using the shorthand fi to mean f (ti ). σt ∼ GCP, because any ﬁnite sequence (σ1 , . . . , σp ) is distributed as a Gaussian copula: P (σ1 ≤ a1 , . . . , σp ≤ ap ) = P (g −1 (σ1 ) ≤ g −1 (a1 ), . . . , g −1 (σp ) ≤ g −1 (ap )) = ΦΓ (g −1 (a1 ), . . . , g −1 −1 (ap )) = ΦΓ (Φ = ΦΓ (Φ −1 (F (a1 )), . . . , Φ (u1 ), . . . , Φ −1 −1 (9) (F (ap ))) (up )) = C(u1 , . . . , up ), where Φ is the standard univariate Gaussian cdf (supposing k(t, t) = 1), ΦΓ is a multivariate Gaussian cdf with covariance matrix Γij = cov(g −1 (σi ), g −1 (σj )), and F is the marginal distribution of 3 each σi . In (5), we have Ψ = g −1 , because it is g −1 which maps σt to a GP. The speciﬁcation in (5) is equivalently expressed by (6) and (7). With GCPV, the form of g is learned so that g −1 (σt ) is best modelled by a GP. By learning g, we learn the marginal of each σ: F (a) = Φ(g −1 (a)) for a ∈ R. Recently, a different sort of ‘kernel copula process’ has been used, where the marginals of the variables being modelled are not learned [16].1 Further, we also consider a more subtle and ﬂexible form of our model, where the function g itself is indexed by time: g = gt (f (t), ω). We only assume that the marginal distributions of σt are stationary over ‘small’ time periods, and for each of these time periods (5)-(7) hold true. We return to this in the ﬁnal discussion section. Here we have assumed that each observation, conditioned on knowing its variance, is normally distributed with zero mean. This is a common assumption in heteroscedastic models. The zero mean and normality assumptions can be relaxed and are not central to this paper. 4 Predictions with GCPV Ultimately, we wish to infer p(σ(t∗ )|y, z), where z = {θ, ω}, and θ are the hyperparameters of the GP covariance function. To do this, we sample from p(f∗ |y, z) = p(f∗ |f , θ)p(f |y, z)df (10) and then transform these samples by g. Letting (Cf )ij = δij g(fi , ω)2 , where δij is the Kronecker delta, Kij = k(ti , tj ), (k∗ )i = k(t∗ , ti ), we have p(f |y, z) = N (f ; 0, K)N (y; 0, Cf )/p(y|z), p(f∗ |f , θ) = N (k∗ K −1 f , k(t∗ , t∗ ) − k∗ K −1 (11) k∗ ). (12) We also wish to learn z, which we can do by ﬁnding the z that maximizes the marginal likelihood, ˆ p(y|z) = p(y|f , ω)p(f |θ)df . (13) Unfortunately, for many functions g, (10) and (13) are intractable. Our methods of dealing with this can be used in very general circumstances, where one has a Gaussian process prior, but an (optionally parametrized) non-Gaussian likelihood. We use the Laplace approximation to estimate p(f |y, z) as a Gaussian. Then we can integrate (10) for a Gaussian approximation to p(f∗ |y, z), which we sample from to make predictions of σ∗ . Using Laplace, we can also ﬁnd an expression for an approximate marginal likelihood, which we maximize to determine z. Once we have found z with Laplace, we use Markov chain Monte Carlo to sample from p(f∗ |y, z), and compare that to using Laplace to sample from p(f∗ |y, z). In the supplement we relate this discussion to (9). 4.1 Laplace Approximation The goal is to approximate (11) with a Gaussian, so that we can evaluate (10) and (13) and make predictions. In doing so, we follow Rasmussen and Williams [11] in their treatment of Gaussian process classiﬁcation, except we use a parametrized likelihood, and modify Newton’s method. First, consider as an objective function the logarithm of an unnormalized (11): s(f |y, z) = log p(y|f , ω) + log p(f |θ). (14) ˆ The Laplace approximation uses a second order Taylor expansion about the f which maximizes ˆ, for which we use (14), to ﬁnd an approximate objective s(f |y, z). So the ﬁrst step is to ﬁnd f ˜ Newton’s method. The Newton update is f new = f − ( s(f ))−1 s(f ). Differentiating (14), s(f |y, z) = s(f |y, z) = where W is the diagonal matrix − 1 log p(y|f , ω) − K −1 f log p(y|f , ω) − K −1 = −W − K −1 , log p(y|f , ω). Note added in proof : Also, for a very recent related model, see Rodr´guez et al. [17]. ı 4 (15) (16) If the likelihood function p(y|f , ω) is not log concave, then W may have negative entries. Vanhatalo et al. [18] found this to be problematic when doing Gaussian process regression with a Student-t ˆ likelihood. They instead use an expectation-maximization (EM) algorithm for ﬁnding f , and iterate ordered rank one Cholesky updates to evaluate the Laplace approximate marginal likelihood. But EM can converge slowly, especially near a local optimum, and each of the rank one updates is vulnerable to numerical instability. With a small modiﬁcation of Newton’s method, we often get close to ˆ quadratic convergence for ﬁnding f , and can evaluate the Laplace approximate marginal likelihood in a numerically stable fashion, with no approximate Cholesky factors, and optimal computational requirements. Some comments are in the supplementary material but, in short, we use an approximate negative Hessian, − s ≈ M + K −1 , which is guaranteed to be positive deﬁnite, since M is formed on each iteration by zeroing the negative entries of W . For stability, we reformulate our 1 1 1 1 optimization in terms of B = I + M 2 KM 2 , and let Q = M 2 B −1 M 2 , b = M f + log p(y|f ), a = b − QKb. Since (K −1 + M )−1 = K − KQK, the Newton update becomes f new = Ka. ˆ With these updates we ﬁnd f and get an expression for s which we use to approximate (13) and ˜ (11). The approximate marginal likelihood q(y|z) is given by exp(˜)df . Taking its logarithm, s 1ˆ 1 ˆ log q(y|z) = − f af + log p(y|f ) − log |Bf |, (17) ˆ ˆ 2 2 ˆ ˆ where Bf is B evaluated at f , and af is a numerically stable evaluation of K −1 f . ˆ ˆ To learn the parameters z, we use conjugate gradient descent to maximize (17) with respect to z. ˆ ˆ Since f is a function of z, we initialize z, and update f every time we vary z. Once we have found an optimum z , we can make predictions. By exponentiating s, we ﬁnd a Gaussian approximation to ˆ ˜ ˆ the posterior (11), q(f |y, z) = N (f , K − KQK). The product of this approximate posterior with p(f∗ |f ) is Gaussian. Integrating this product, we approximate p(f∗ |y, z) as ˆ q(f∗ |y, z) = N (k∗ log p(y|f ), k(t∗ , t∗ ) − k∗ Qk∗ ). (18) Given n training observations, the cost of each Newton iteration is dominated by computing the cholesky decomposition of B, which takes O(n3 ) operations. The objective function typically changes by less than 10−6 after 3 iterations. Once Newton’s method has converged, it takes only O(1) operations to draw from q(f∗ |y, z) and make predictions. 4.2 Markov chain Monte Carlo We use Markov chain Monte Carlo (MCMC) to sample from (11), so that we can later sample from p(σ∗ |y, z) to make predictions. Sampling from (11) is difﬁcult, because the variables f are strongly coupled by a Gaussian process prior. We use a new technique, Elliptical Slice Sampling [19], and ﬁnd it extremely effective for this purpose. It was speciﬁcally designed to sample from posteriors with correlated Gaussian priors. It has no free parameters, and jointly updates every element of f . For our setting, it is over 100 times as fast as axis aligned slice sampling with univariate updates. To make predictions, we take J samples of p(f |y, z), {f 1 , . . . , f J }, and then approximate (10) as a mixture of J Gaussians: J 1 p(f∗ |f i , θ). (19) p(f∗ |y, z) ≈ J i=1 Each of the Gaussians in this mixture have equal weight. So for each sample of f∗ |y, we uniformly choose a random p(f∗ |f i , θ) and draw a sample. In the limit J → ∞, we are sampling from the exact p(f∗ |y, z). Mapping these samples through g gives samples from p(σ∗ |y, z). After one O(n3 ) and one O(J) operation, a draw from (19) takes O(1) operations. 4.3 Warping Function The warping function, g, maps fi , a GP function value, to σi , a standard deviation. Since fi can take any value in R, and σi can take any non-negative real value, g : R → R+ . For each fi to correspond to a unique deviation, g must also be one-to-one. We use K g(x, ω) = aj log[exp[bj (x + cj )] + 1], j=1 5 aj , bj > 0. (20) This is monotonic, positive, inﬁnitely differentiable, asymptotic towards zero as x → −∞, and K tends to ( j=1 aj bj )x as x → ∞. In practice, it is useful to add a small constant to (20), to avoid rare situations where the parameters ω are trained to make g extremely small for certain inputs, at the expense of a good overall ﬁt; this can happen when the parameters ω are learned by optimizing a likelihood. A suitable constant could be one tenth the absolute value of the smallest nonzero observation. By inferring the parameters of the warping function, or distributions of these parameters, we are learning a transformation which will best model σt with a Gaussian process. The more ﬂexible the warping function, the more potential there is to improve the GCPV ﬁt – in other words, the better we can estimate the ‘perfect’ transformation. To test the importance of this ﬂexibility, we also try a simple unparametrized warping function, g(x) = ex . In related work, Goldberg et al. [20] place a GP prior on the log noise level in a standard GP regression model on observations, except for inference they use Gibbs sampling, and a high level of ‘jitter’ for conditioning. Once g is trained, we can infer the marginal distribution of each σ: F (a) = Φ(g −1 (a)), for a ∈ R. This suggests an alternate way to initialize g: we can initialize F as a mixture of Gaussians, and then map through Φ−1 to ﬁnd g −1 . Since mixtures of Gaussians are dense in the set of probability distributions, we could in principle ﬁnd the ‘perfect’ g using an inﬁnite mixture of Gaussians [21]. 5 Experiments In our experiments, we predict the latent standard deviations σ of observations y at times t, and also σ∗ at unobserved times t∗ . To do this, we use two versions of GCPV. The ﬁrst variant, which we simply refer to as GCPV, uses the warping function (20) with K = 1, and squared exponential covariance function, k(t, t ) = A exp(−(t−t )2 /l2 ), with A = 1. The second variant, which we call GP-EXP, uses the unparametrized warping function ex , and the same covariance function, except the amplitude A is a trained hyperparameter. The other hyperparameter l is called the lengthscale of the covariance function. The greater l, the greater the covariance between σt and σt+a for a ∈ R. We train hyperparameters by maximizing the Laplace approximate log marginal likelihood (17). We then sample from p(f∗ |y) using the Laplace approximation (18). We also do this using MCMC (19) with J = 10000, after discarding a previous 10000 samples of p(f |y) as burn-in. We pass 2 these samples of f∗ |y through g and g 2 to draw from p(σ∗ |y) and p(σ∗ |y), and compute the sample mean and variance of σ∗ |y. We use the sample mean as a point predictor, and the sample variance for error bounds on these predictions, and we use 10000 samples to compute these quantities. For GCPV we use Laplace and MCMC for inference, but for GP-EXP we only use Laplace. We compare predictions to GARCH(1,1), which has been shown in extensive and recent reviews to be competitive with other GARCH variants, and more sophisticated models [5, 6, 7]. GARCH(p,q) speciﬁes y(t) ∼ p 2 2 N (0, σ 2 (t)), and lets the variance be a deterministic function of the past: σt = a0 + i=1 ai yt−i + q 2 j=1 bj σt−j . We use the Matlab Econometrics Toolbox implementation of GARCH, where the parameters a0 , ai and bj are estimated using a constrained maximum likelihood. We make forecasts of volatility, and we predict historical volatility. By ‘historical volatility’ we mean the volatility at observed time points, or between these points. Uncovering historical volatility is important. It could, for instance, be used to study what causes ﬂuctuations in the stock market, or to understand physical systems. To evaluate our model, we use the Mean Squared Error (MSE) between the true variance, or proxy for the truth, and the predicted variance. Although likelihood has advantages, we are limited in space, and we wish to harmonize with the econometrics literature, and other assessments of volatility models, where MSE is the standard. In a similar assessment of volatility models, Brownlees et al. [7] found that MSE and quasi-likelihood rankings were comparable. When the true variance is unknown we follow Brownlees et al. [7] and use squared observations as a proxy for the truth, to compare our model to GARCH.2 The more observations, the more reliable these performance estimates will be. However, not many observations (e.g. 100) are needed for a stable ranking of competing models; in Brownlees et al. [7], the rankings derived from high frequency squared observations are similar to those derived using daily squared observations. 2 Since each observation y is assumed to have zero mean and variance σ 2 , E[y 2 ] = σ 2 . 6 5.1 Simulations We simulate observations from N (0, σ 2 (t)), using σ(t) = sin(t) cos(t2 ) + 1, at t = (0, 0.02, 0.04, . . . , 4) . We call this data set TRIG. We also simulate using a standard deviation that jumps from 0.1 to 7 and back, at times t = (0, 0.1, 0.2, . . . , 6) . We call this data set JUMP. To forecast, we use all observations up until the current time point, and make 1, 7, and 30 step ahead predictions. So, for example, in TRIG we start by observing t = 0, and make forecasts at t = 0.02, 0.14, 0.60. Then we observe t = 0, 0.02 and make forecasts at t = 0.04, 0.16, 0.62, and so on, until all data points have been observed. For historical volatility, we predict the latent σt at the observation times, which is safe since we are comparing to the true volatility, which is not used in training; the results are similar if we interpolate. Figure 1 panels a) and b) show the true volatility for TRIG and JUMP respectively, alongside GCPV Laplace, GCPV MCMC, GP-EXP Laplace, and GARCH(1,1) predictions of historical volatility. Table 1 shows the results for forecasting and historical volatility. In panel a) we see that GCPV more accurately captures the dependencies between σ at different times points than GARCH: if we manually decrease the lengthscale in the GCPV covariance function, we can replicate the erratic GARCH behaviour, which inaccurately suggests that the covariance between σt and σt+a decreases quickly with increases in a. We also see that GCPV with an unparametrized exponential warping function tends to overestimates peaks and underestimate troughs. In panel b), the volatility is extremely difﬁcult to reconstruct or forecast – with no warning it will immediately and dramatically increase or decrease. This behaviour is not suited to a smooth squared exponential covariance function. Nevertheless, GCPV outperforms GARCH, especially in regions of low volatility. We also see this in panel a) for t ∈ (1.5, 2). GARCH is known to respond slowly to large returns, and to overpredict volatility [22]. In JUMP, the greater the peaks, and the smaller the troughs, the more GARCH suffers, while GCPV is mostly robust to these changes. 5.2 Financial Data The returns on the daily exchange rate between the Deutschmark (DM) and the Great Britain Pound (GBP) from 1984 to 1992 have become a benchmark for assessing the performance of GARCH models [8, 9, 10]. This exchange data, which we refer to as DMGBP, can be obtained from www.datastream.com, and the returns are calculated as rt = log(Pt+1 /Pt ), where Pt is the number of DM to GBP on day t. The returns are assumed to have a zero mean function. We use a rolling window of the previous 120 days of returns to make 1, 7, and 30 day ahead volatility forecasts, starting at the beginning of January 1988, and ending at the beginning of January 1992 (659 trading days). Every 7 days, we retrain the parameters of GCPV and GARCH. Every time we retrain parameters, we predict historical volatility over the past 120 days. The average MSE for these historical predictions is given in Table 1, although they should be observed with caution; unlike with the simulations, the DMGBP historical predictions are trained using the same data they are assessed on. In Figure 1c), we see that the GARCH one day ahead forecasts are lifted above the GCPV forecasts, but unlike in the simulations, they are now operating on a similar lengthscale. This suggests that GARCH could still be overpredicting volatility, but that GCPV has adapted its estimation of how σt and σt+a correlate with one another. Since GARCH is suited to this ﬁnancial data set, it is reassuring that GCPV predictions have a similar time varying structure. Overall, GCPV and GARCH are competitive with one another for forecasting currency exchange returns, as seen in Table 1. Moreover, a learned warping function g outperforms an unparametrized one, and a full Laplace solution is comparable to using MCMC for inference, in accuracy and speed. This is also true for the simulations. Therefore we recommend whichever is more convenient to implement. 6 Discussion We deﬁned a copula process, and as an example, developed a stochastic volatility model, GCPV, which can outperform GARCH. With GCPV, the volatility σt is distributed as a Gaussian Copula Process, which separates the modelling of the dependencies between volatilities at different times from their marginal distributions – arguably the most useful property of a copula. Further, GCPV ﬁts the marginals in the Gaussian copula process by learning a warping function. If we had simply chosen an unparametrized exponential warping function, we would incorrectly be assuming that the log 7 Table 1: MSE for predicting volatility. Data set Model Historical 1 step 7 step 30 step TRIG GCPV (LA) GCPV (MCMC) GP-EXP GARCH 0.0953 0.0760 0.193 0.938 0.588 0.622 0.646 1.04 0.951 0.979 1.36 1.79 1.71 1.76 1.15 5.12 JUMP GCPV (LA) GCPV (MCMC) GP-EXP GARCH 0.588 1.21 1.43 1.88 0.891 0.951 1.76 1.58 1.38 1.37 6.95 3.43 1.35 1.35 14.7 5.65 GCPV (LA) GCPV (MCMC) GP-EXP GARCH 2.43 2.39 2.52 2.83 3.00 3.00 3.20 3.03 3.08 3.08 3.46 3.12 3.17 3.17 5.14 3.32 ×103 DMGBP ×10−9 TRIG JUMP DMGBP 20 DMGBP 0.015 600 Probability Density 3 1 Volatility Volatility Volatility 15 2 10 0.01 0.005 5 0 0 1 2 Time (a) 3 4 0 0 2 4 0 6 Time (b) 0 200 400 Days (c) 600 400 200 0 0 0.005 σ (d) 0.01 Figure 1: Predicting volatility and learning its marginal pdf. For a) and b), the true volatility, and GCPV (MCMC), GCPV (LA), GP-EXP, and GARCH predictions, are shown respectively by a thick green line, a dashed thick blue line, a dashed black line, a cyan line, and a red line. a) shows predictions of historical volatility for TRIG, where the shade is a 95% conﬁdence interval about GCPV (MCMC) predictions. b) shows predictions of historical volatility for JUMP. In c), a black line and a dashed red line respectively show GCPV (LA) and GARCH one day ahead volatility forecasts for DMGBP. In d), a black line and a dashed blue line respectively show the GCPV learned marginal pdf of σt in DMGBP and a Gamma(4.15,0.00045) pdf. volatilities are marginally Gaussian distributed. Indeed, for the DMGBP data, we trained the warping function g over a 120 day period, and mapped its inverse through the univariate standard Gaussian cdf Φ, and differenced, to estimate the marginal probability density function (pdf) of σt over this period. The learned marginal pdf, shown in Figure 1d), is similar to a Gamma(4.15,0.00045) distribution. However, in using a rolling window to retrain the parameters of g, we do not assume that the marginals of σt are stationary; we have a time changing warping function. While GARCH is successful, and its simplicity is attractive, our model is also simple and has a number of advantages. We can effortlessly handle missing data, we can easily incorporate covariates other than time (like interest rates) in our covariance function, and we can choose from a rich class of covariance functions – squared exponential, Brownian motion, Mat´ rn, periodic, etc. In fact, the e volatility of high frequency intradaily returns on equity indices and currency exchanges is cyclical [23], and GCPV with a periodic covariance function is uniquely well suited to this data. And the parameters of GCPV, like the covariance function lengthscale, or the learned warping function, provide insight into the underlying source of volatility, unlike the parameters of GARCH. Finally, copulas are rapidly becoming popular in applications, but often only bivariate copulas are being used. With our copula process one can learn the dependencies between arbitrarily many random variables independently of their marginal distributions. We hope the Gaussian Copula Process Volatility model will encourage other applications of copula processes. More generally, we hope our work will help bring together the machine learning and econometrics communities. Acknowledgments: Thanks to Carl Edward Rasmussen and Ferenc Husz´ r for helpful conversaa tions. AGW is supported by an NSERC grant. 8 References [1] Paul Embrechts, Alexander McNeil, and Daniel Straumann. Correlation and dependence in risk management: Properties and pitfalls. In Risk Management: Value at risk and beyond, pages 176–223. Cambridge University Press, 1999. [2] David X. Li. On default correlation: A copula function approach. Journal of Fixed Income, 9(4):43–54, 2000. [3] Roger B. Nelsen. An Introduction to Copulas. Springer Series in Statistics, second edition, 2006. [4] Tim Bollerslev. Generalized autoregressive conditional heteroskedasticity. Journal of Econometrics, 31 (3):307–327, 1986. [5] Ser-Huang Poon and Clive W.J. Granger. Practical issues in forecasting volatility. Financial Analysts Journal, 61(1):45–56, 2005. [6] Peter Reinhard Hansen and Asger Lunde. A forecast comparison of volatility models: Does anything beat a GARCH(1,1). Journal of Applied Econometrics, 20(7):873–889, 2005. [7] Christian T. Brownlees, Robert F. Engle, and Bryan T. Kelly. A practical guide to volatility forecasting through calm and storm, 2009. Available at SSRN: http://ssrn.com/abstract=1502915. [8] T. Bollerslev and E. Ghysels. Periodic autoregressive conditional heteroscedasticity. Journal of Business and Economic Statistics, 14:139–151, 1996. [9] B.D. McCullough and C.G. Renfro. Benchmarks and software standards: A case study of GARCH procedures. Journal of Economic and Social Measurement, 25:59–71, 1998. [10] C. Brooks, S.P. Burke, and G. Persand. Benchmarks and the accuracy of GARCH model estimation. International Journal of Forecasting, 17:45–56, 2001. [11] Carl Edward Rasmussen and Christopher K.I. Williams. Gaussian processes for Machine Learning. The MIT Press, 2006. ` [12] Abe Sklar. Fonctions de r´ partition a n dimensions et leurs marges. Publ. Inst. Statist. Univ. Paris, 8: e 229–231, 1959. [13] P Deheuvels. Caract´ isation compl` te des lois extrˆ mes multivari´ s et de la convergence des types e e e e extrˆ mes. Publications de l’Institut de Statistique de l’Universit´ de Paris, 23:1–36, 1978. e e [14] G Kimeldorf and A Sampson. Uniform representations of bivariate distributions. Communications in Statistics, 4:617–627, 1982. [15] Edward Snelson, Carl Edward Rasmussen, and Zoubin Ghahramani. Warped Gaussian Processes. In NIPS, 2003. [16] Sebastian Jaimungal and Eddie K.H. Ng. Kernel-based Copula processes. In ECML PKDD, 2009. [17] A. Rodr´guez, D.B. Dunson, and A.E. Gelfand. Latent stick-breaking processes. Journal of the American ı Statistical Association, 105(490):647–659, 2010. [18] Jarno Vanhatalo, Pasi Jylanki, and Aki Vehtari. Gaussian process regression with Student-t likelihood. In NIPS, 2009. [19] Iain Murray, Ryan Prescott Adams, and David J.C. MacKay. Elliptical Slice Sampling. In AISTATS, 2010. [20] Paul W. Goldberg, Christopher K.I. Williams, and Christopher M. Bishop. Regression with inputdependent noise: A Gaussian process treatment. In NIPS, 1998. [21] Carl Edward Rasmussen. The Inﬁnite Gaussian Mixture Model. In NIPS, 2000. [22] Ruey S. Tsay. Analysis of Financial Time Series. John Wiley & Sons, 2002. [23] Torben G. Andersen and Tim Bollerslev. Intraday periodicity and volatility persistence in ﬁnancial markets. Journal of Empirical Finance, 4(2-3):115–158, 1997. 9</p><p>same-paper 2 0.83957624 <a title="113-lsi-2" href="./nips-2010-Heavy-Tailed_Process_Priors_for_Selective_Shrinkage.html">113 nips-2010-Heavy-Tailed Process Priors for Selective Shrinkage</a></p>
<p>Author: Fabian L. Wauthier, Michael I. Jordan</p><p>Abstract: Heavy-tailed distributions are often used to enhance the robustness of regression and classiﬁcation methods to outliers in output space. Often, however, we are confronted with “outliers” in input space, which are isolated observations in sparsely populated regions. We show that heavy-tailed stochastic processes (which we construct from Gaussian processes via a copula), can be used to improve robustness of regression and classiﬁcation estimators to such outliers by selectively shrinking them more strongly in sparse regions than in dense regions. We carry out a theoretical analysis to show that selective shrinkage occurs when the marginals of the heavy-tailed process have sufﬁciently heavy tails. The analysis is complemented by experiments on biological data which indicate signiﬁcant improvements of estimates in sparse regions while producing competitive results in dense regions. 1</p><p>3 0.79833823 <a title="113-lsi-3" href="./nips-2010-Copula_Bayesian_Networks.html">53 nips-2010-Copula Bayesian Networks</a></p>
<p>Author: Gal Elidan</p><p>Abstract: We present the Copula Bayesian Network model for representing multivariate continuous distributions, while taking advantage of the relative ease of estimating univariate distributions. Using a novel copula-based reparameterization of a conditional density, joined with a graph that encodes independencies, our model offers great ﬂexibility in modeling high-dimensional densities, while maintaining control over the form of the univariate marginals. We demonstrate the advantage of our framework for generalization over standard Bayesian networks as well as tree structured copula models for varied real-life domains that are of substantially higher dimension than those typically considered in the copula literature. 1</p><p>4 0.57924855 <a title="113-lsi-4" href="./nips-2010-Estimation_of_Renyi_Entropy_and_Mutual_Information_Based_on_Generalized_Nearest-Neighbor_Graphs.html">80 nips-2010-Estimation of Renyi Entropy and Mutual Information Based on Generalized Nearest-Neighbor Graphs</a></p>
<p>Author: Barnabás Póczos, Csaba Szepesvári, David Tax</p><p>Abstract: We present simple and computationally efﬁcient nonparametric estimators of R´ nyi entropy and mutual information based on an i.i.d. sample drawn from an e unknown, absolutely continuous distribution over Rd . The estimators are calculated as the sum of p-th powers of the Euclidean lengths of the edges of the ‘generalized nearest-neighbor’ graph of the sample and the empirical copula of the sample respectively. For the ﬁrst time, we prove the almost sure consistency of these estimators and upper bounds on their rates of convergence, the latter of which under the assumption that the density underlying the sample is Lipschitz continuous. Experiments demonstrate their usefulness in independent subspace analysis. 1</p><p>5 0.51674426 <a title="113-lsi-5" href="./nips-2010-Slice_sampling_covariance_hyperparameters_of_latent_Gaussian_models.html">242 nips-2010-Slice sampling covariance hyperparameters of latent Gaussian models</a></p>
<p>Author: Iain Murray, Ryan P. Adams</p><p>Abstract: The Gaussian process (GP) is a popular way to specify dependencies between random variables in a probabilistic model. In the Bayesian framework the covariance structure can be speciﬁed using unknown hyperparameters. Integrating over these hyperparameters considers diﬀerent possible explanations for the data when making predictions. This integration is often performed using Markov chain Monte Carlo (MCMC) sampling. However, with non-Gaussian observations standard hyperparameter sampling approaches require careful tuning and may converge slowly. In this paper we present a slice sampling approach that requires little tuning while mixing well in both strong- and weak-data regimes. 1</p><p>6 0.4979974 <a title="113-lsi-6" href="./nips-2010-Scrambled_Objects_for_Least-Squares_Regression.html">233 nips-2010-Scrambled Objects for Least-Squares Regression</a></p>
<p>7 0.48064393 <a title="113-lsi-7" href="./nips-2010-Gaussian_sampling_by_local_perturbations.html">101 nips-2010-Gaussian sampling by local perturbations</a></p>
<p>8 0.46346375 <a title="113-lsi-8" href="./nips-2010-Evaluation_of_Rarity_of_Fingerprints_in_Forensics.html">82 nips-2010-Evaluation of Rarity of Fingerprints in Forensics</a></p>
<p>9 0.46141282 <a title="113-lsi-9" href="./nips-2010-Approximate_inference_in_continuous_time_Gaussian-Jump_processes.html">33 nips-2010-Approximate inference in continuous time Gaussian-Jump processes</a></p>
<p>10 0.45190108 <a title="113-lsi-10" href="./nips-2010-Gaussian_Process_Preference_Elicitation.html">100 nips-2010-Gaussian Process Preference Elicitation</a></p>
<p>11 0.4367654 <a title="113-lsi-11" href="./nips-2010-Learning_sparse_dynamic_linear_systems_using_stable_spline_kernels_and_exponential_hyperpriors.html">154 nips-2010-Learning sparse dynamic linear systems using stable spline kernels and exponential hyperpriors</a></p>
<p>12 0.43503347 <a title="113-lsi-12" href="./nips-2010-Switched_Latent_Force_Models_for_Movement_Segmentation.html">262 nips-2010-Switched Latent Force Models for Movement Segmentation</a></p>
<p>13 0.43013099 <a title="113-lsi-13" href="./nips-2010-Exact_learning_curves_for_Gaussian_process_regression_on_large_random_graphs.html">85 nips-2010-Exact learning curves for Gaussian process regression on large random graphs</a></p>
<p>14 0.42102158 <a title="113-lsi-14" href="./nips-2010-Exact_inference_and_learning_for_cumulative_distribution_functions_on_loopy_graphs.html">84 nips-2010-Exact inference and learning for cumulative distribution functions on loopy graphs</a></p>
<p>15 0.41559792 <a title="113-lsi-15" href="./nips-2010-Inference_with_Multivariate_Heavy-Tails_in_Linear_Models.html">126 nips-2010-Inference with Multivariate Heavy-Tails in Linear Models</a></p>
<p>16 0.37916714 <a title="113-lsi-16" href="./nips-2010-Computing_Marginal_Distributions_over_Continuous_Markov_Networks_for_Statistical_Relational_Learning.html">49 nips-2010-Computing Marginal Distributions over Continuous Markov Networks for Statistical Relational Learning</a></p>
<p>17 0.37802541 <a title="113-lsi-17" href="./nips-2010-Unsupervised_Kernel_Dimension_Reduction.html">280 nips-2010-Unsupervised Kernel Dimension Reduction</a></p>
<p>18 0.36793277 <a title="113-lsi-18" href="./nips-2010-Implicit_Differentiation_by_Perturbation.html">118 nips-2010-Implicit Differentiation by Perturbation</a></p>
<p>19 0.3464919 <a title="113-lsi-19" href="./nips-2010-The_Neural_Costs_of_Optimal_Control.html">268 nips-2010-The Neural Costs of Optimal Control</a></p>
<p>20 0.34129471 <a title="113-lsi-20" href="./nips-2010-Probabilistic_latent_variable_models_for_distinguishing_between_cause_and_effect.html">218 nips-2010-Probabilistic latent variable models for distinguishing between cause and effect</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(7, 0.121), (30, 0.054), (32, 0.09), (34, 0.077), (45, 0.042), (53, 0.37), (68, 0.157)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.69176495 <a title="113-lda-1" href="./nips-2010-Heavy-Tailed_Process_Priors_for_Selective_Shrinkage.html">113 nips-2010-Heavy-Tailed Process Priors for Selective Shrinkage</a></p>
<p>Author: Fabian L. Wauthier, Michael I. Jordan</p><p>Abstract: Heavy-tailed distributions are often used to enhance the robustness of regression and classiﬁcation methods to outliers in output space. Often, however, we are confronted with “outliers” in input space, which are isolated observations in sparsely populated regions. We show that heavy-tailed stochastic processes (which we construct from Gaussian processes via a copula), can be used to improve robustness of regression and classiﬁcation estimators to such outliers by selectively shrinking them more strongly in sparse regions than in dense regions. We carry out a theoretical analysis to show that selective shrinkage occurs when the marginals of the heavy-tailed process have sufﬁciently heavy tails. The analysis is complemented by experiments on biological data which indicate signiﬁcant improvements of estimates in sparse regions while producing competitive results in dense regions. 1</p><p>2 0.65693861 <a title="113-lda-2" href="./nips-2010-Mixture_of_time-warped_trajectory_models_for_movement_decoding.html">167 nips-2010-Mixture of time-warped trajectory models for movement decoding</a></p>
<p>Author: Elaine Corbett, Eric Perreault, Konrad Koerding</p><p>Abstract: Applications of Brain-Machine-Interfaces typically estimate user intent based on biological signals that are under voluntary control. For example, we might want to estimate how a patient with a paralyzed arm wants to move based on residual muscle activity. To solve such problems it is necessary to integrate obtained information over time. To do so, state of the art approaches typically use a probabilistic model of how the state, e.g. position and velocity of the arm, evolves over time – a so-called trajectory model. We wanted to further develop this approach using two intuitive insights: (1) At any given point of time there may be a small set of likely movement targets, potentially identified by the location of objects in the workspace or by gaze information from the user. (2) The user may want to produce movements at varying speeds. We thus use a generative model with a trajectory model incorporating these insights. Approximate inference on that generative model is implemented using a mixture of extended Kalman filters. We find that the resulting algorithm allows us to decode arm movements dramatically better than when we use a trajectory model with linear dynamics. 1 In trod u cti on When patients have lost a limb or the ability to communicate with the outside world, brain machine interfaces (BMIs) are often used to enable robotic prostheses or restore communication. To achieve this, the user's intended state of the device must be decoded from biological signals. In the context of Bayesian statistics, two aspects are important for the design of an estimator of a temporally evolving state: the observation model, which describes how measured variables relate to the system’s state and the trajectory model which describes how the state changes over time in a probabilistic manner. Following this logic many recent BMI applications have relied on Bayesian estimation for a wide range of problems including the decoding of intended human [1] and animal [2] movements. In the context of BMIs, Bayesian approaches offer a principled way of formalizing the uncertainty about signals and thus often result in improvements over other signal processing techniques [1]-[3]. Most work on state estimation in dynamical systems has assumed linear dynamics and Gaussian noise. Under these circumstances, efficient algorithms result from belief propagation. The most frequent application uses the Kalman filter (KF), which recursively combines noisy state observations with the probabilistic evolution of state defined by the trajectory model to estimate the marginal distribution over states [4]. Such approaches have been used widely for applications including upper [1] and lower [5] extremity prosthetic 1 devices, functional electric stimulation [6] and human computer interactions [7]. As these algorithms are so commonly used, it seems promising to develop extensions to nonlinear trajectory models that may better describe the probabilistic distribution of movements in everyday life. One salient departure from the standard assumptions is that people tend to produce both slow and fast movements, depending on the situation. Models with linear dynamics only allow such deviation through the noise term, which makes these models poor at describing the natural variation of movement speeds during real world tasks. Explicitly incorporating movement speed into the trajectory model should lead to better movement estimates. Knowledge of the target position should also strongly affect trajectory models. After all , we tend to accelerate our arm early during movement and slow down later on. Target information can be linearly incorporated into the trajectory model, and this has greatly improved predictions [8]-[12]. Alternatively, if there are a small number of potential targets then a mixture of trajectory models approach [13] can be used. Here we are interested in the case where available data provide a prior over potential t argets but where movement targets may be anywhere. We want to incorporate target uncertainty and allow generalization to novel targets. Prior information about potential targets could come from a number of sources but would generally be noisy. For example, activity in the dorsal premotor cortex provides information about intended target location prior to movement and may be used where such recordings are available [14]. Target information may also be found noninvasively by tracking eye movements. However, such data will generally provide non-zero priors for a number of possible target locations as the subject saccades over the scene. While subjects almost always look at a target before reaching for it [15], there may be a delay of up to a second between looking at the target and the reach – a time interval over which up to 3 saccades are typically made. Each of these fixations could be the target. Hence, a probabilistic distribution of targets is appropriate when using either neural recordings or eye tracking to estimate potential reach targets Here we present an algorithm that uses a mixture of extended Kalman Filters (EKFs) to combine our insights related to the variation of movement speed and the availability of probabilistic target knowledge. Each of the mixture component s allows the speed of the movement to vary continuously over time. We tested how well we could use EMGs and eye movements to decode hand position of humans performing a three -dimensional large workspace reaching task. We find that using a trajectory model that allows for probabilistic target information and variation of speed leads to dramatic improvements in decoding quality. 2 Gen e ral Decod i n g S etti n g We wanted to test how well different decoding algorithms can decode human movement, over a wide range of dynamics. While many recent studies have looked at more restrictive, two-dimensional movements, a system to restore arm function should produce a wide range of 3D trajectories. We recorded arm kinematics and EMGs of healthy subjects during unconstrained 3D reaches to targets over a large workspace. Two healthy subjects were asked to reach at slow, normal and fast speeds, as they would in everyday life. Subjects were seated as they reached towards 16 LEDs in blocks of 150s, which were located on two planes positioned such that all targets were just reachable (Fig 1A). The target LED was lit for one second prior to an auditory go cue, at which time the subject would reach to the target at the appropriate speed. Slow, normal and fast reaches were allotted 3 s, 1.5s and 1s respectively; however, subjects determined the speed. An approximate total of 450 reaches were performed per subject. The subjects provided informed consent, and the protocol was approved by the Northwestern University Institutional Review Board. EMG signals were measured from the pectoralis major, and the three deltoid muscles of the shoulder. This represents a small subset of the muscles involved in reaching, and approximates those muscles retaining some voluntary control following mid-level cervical spinal cord injuries. 2 The EMG signals were band-pass filtered between 10 and 1,000 Hz, and subsequently anti aliased filtered. Hand, wrist, shoulder and head positions were tracked using an Optotrak motion analysis system. We simultaneously recorded eye movements with an ASL EYETRAC-6 head mounted eye tracker. Approximately 25% of the reaches were assigned to the test set, and the rest were used for training. Reaches for which either the motion capture data was incomplete, or there was visible motion artifact on the EMG were removed. As the state we used hand positions and joint angles (3 shoulder, 2 elbow, position, velocity and acceleration, 24 dimensions). Joint angles were calculated from the shoulder and wrist marker data using digitized bony landmarks which defined a coordinate system for the upper limb as detailed by Wu et al. [16]. As the motion data were sampled at 60Hz, the mean absolute value o f the EMG in the corresponding 16.7ms windows was used as an observation of the state at each time-step. Algorithm accuracy was quantified by normalizing the root -mean-squared error by the straight line distance between the first and final position of the endpoint for each reach. We compared the algorithms statistically using repeated measures ANOVAs with Tukey post -hoc tests, treating reach and subject as random effects. In the rest of the paper we will ask how well these reaching movements can be decoded from EMG and eye-tracking data. Figure 1: A Experimental setup and B sample kinematics and processed EMGs for one reach 3 Kal man Fi l ters w i th Target i n f ormati on All models that we consider in this paper assume linear observations with Gaussian noise: (1) where x is the state, y is the observation and v is the measurement noise with p(v) ~ N(0,R), and R is the observation covariance matrix. The model fitted the measured EMGs with an average r2 of 0.55. This highlights the need to integrate information over time. The standard approach also assumes linear dynamics and Gaussian process noise: (2) where, x t represents the hand and joint angle positions, w is the process noise with p(w) ~ N(0,Q), and Q is the state covariance matrix. The Kalman filter does optimal inference for this generative model. This model can effectively capture the dynamics of stereotypical reaches to a single target by appropriately tuning its parameters. However, when used to describe reaches to multiple targets, the model cannot describe target dependent aspects of reaching but boils down to a random drift model. Fast velocities are underestimated as they are unlikely under the trajectory model and there is excessive drift close to the target (Fig. 2A). 3 In many decoding applications we may know the subject’s target. A range of recent studies have addressed the issue of incorporating this information into the trajectory model [8, 13], and we might assume the effect of the target on the dynamics to be linear. This naturally suggests adding the target to the state space, which works well in practice [9, 12]. By appending the target to the state vector (KFT), the simple linear format of the KF may be retained: (3) where xTt is the vector of target positions, with dimensionality less than or equal to that of xt. This trajectory model thus allows describing both the rapid acceleration that characterizes the beginning of a reach and the stabilization towards its end. We compared the accuracy of the KF and the KFT to the Single Target Model (STM), a KF trained only on reaches to the target being tested (Fig. 2). The STM represents the best possible prediction that could be obtained with a Kalman filter. Assuming the target is perfectly known, we implemented the KFT by correctly initializing the target state xT at the beginning of the reach. We will relax this assumption below. The initial hand and joint angle positions were also assumed to be known. Figure 2: A Sample reach and predictions and B average accuracies with standard errors for KFT, KF and MTM. Consistent with the recent literature, both methods that incorporated target information produced higher prediction accuracy than the standard KF (both p<0.0001). Interestingly, there was no significant difference between the KFT and the STM (p=0.9). It seems that when we have knowledge of the target, we do not lose much by training a single model over the whole workspace rather than modeling the targets individually. This is encouraging, as we desire a BMI system that can generalize to any target within the workspace, not just specifically to those that are available in the training data. Clearly, adding the target to the state space allows the dynamics of typical movements to be modeled effectively, resulting in dramatic increases in decoding performance. 4 Ti me Warp i n g 4.1 I m p l e m e n t i n g a t i m e - w a r p e d t r a j e c t o r y mo d e l While the KFT above can capture the general reach trajectory profile, it does not allow for natural variability in the speed of movements. Depending on our task objectives, which would not directly be observed by a BMI, we might lazily reach toward a target or move a t maximal speed. We aim to change the trajectory model to explicitly incorporate a warping factor by which the average movement speed is scaled, allowing for such variability. As the movement speed will be positive in all practical cases, we model the logarithm of this factor, 4 and append it to the state vector: (4) We create a time-warped trajectory model by noting that if the average rate of a trajectory is to be scaled by a factor S, the position at time t will equal that of the original trajectory at time St. Differentiating, the velocity will be multiplied by S, and the acceleration by S 2. For simplicity, the trajectory noise is assumed to be additive and Gaussian, and the model is assumed to be stationary: (5) where Ip is the p-dimensional identity matrix and is a p p matrix of zeros. Only the terms used to predict the acceleration states need to be estimated to build the state transition matrix, and they are scaled as a nonlinear function of xs. After adding the variable movement speed to the state space the system is no longer linear. Therefore we need a different solution strategy. Instead of the typical KFT we use the Extended Kalman Filter (EKFT) to implement a nonlinear trajectory model by linearizing the dynamics around the best estimate at each time-step [17]. With this approach we add only small computational overhead to the KFT recursions. 4.2 Tr a i n i n g t h e t i m e w a r p i n g mo d e l The filter parameters were trained using a variant of the Expectation Maximization (EM) algorithm [18]. For extended Kalman filter learning the initialization for the variables may matter. S was initialized with the ground truth average reach speeds for each movement relative to the average speed across all movements. The state transition parameters were estimated using nonlinear least squares regression, while C, Q and R were estimated linearly for the new system, using the maximum likelihood solution [18] (M-step). For the E-step we used a standard extended Kalman smoother. We thus found the expected values for t he states given the current filter parameters. For this computation, and later when testing the algorithm, xs was initialized to its average value across all reaches while the remaining states were initialized to their true values. The smoothed estimate fo r xs was then used, along with the true values for the other states, to re-estimate the filter parameters in the M-step as before. We alternated between the E and M steps until the log likelihood converged (which it did in all cases). Following the training procedure, the diagonal of the state covariance matrix Q corresponding to xs was set to the variance of the smoothed xs over all reaches, according to how much this state should be allowed to change during prediction. This allowed the estimate of xs to develop over the course of the reach due to the evidence provided by the observations, better capturing the dynamics of reaches at different speeds. 4.3 P e r f o r ma n c e o f t h e t i m e - w a r p e d E K F T Incorporating time warping explicitly into the trajectory model pro duced a noticeable increase in decoding performance over the KFT. As the speed state xs is estimated throughout the course of the reach, based on the evidence provided by the observations, the trajectory model has the flexibility to follow the dynamics of the reach more accurately (Fig. 3). While at the normal self-selected speed the difference between the algorithms is small, for the slow and fast speeds, where the dynamics deviate from average, there i s a clear advantage to the time warping model. 5 Figure 3: Hand positions and predictions of the KFT and EKFT for sample reaches at A slow, B normal and C fast speeds. Note the different time scales between reaches. The models were first trained using data from all speeds (Fig. 4A). The EKFT was 1.8% more accurate on average (p<0.01), and the effect was significant at the slow (1.9%, p<0.05) and the fast (2.8%, p<0.01), but not at the normal (p=0.3) speed. We also trained the models from data using only reaches at the self-selected normal speed, as we wanted to see if there was enough variation to effectively train the EKFT (Fig. 4B). Interestingly, the performance of the EKFT was reduced by only 0.6%, and the KFT by 1.1%. The difference in performance between the EKFT and KFT was even more pronounced on aver age (2.3%, p<0.001), and for the slow and fast speeds (3.6 and 4.1%, both p< 0.0001). At the normal speed, the algorithms again were not statistically different (p=0.6). This result demonstrates that the EKFT is a practical option for a real BMI system, as it is not necessary to greatly vary the speeds while collecting training data for the model to be effective over a wide range of intended speeds. Explicitly incorporating speed information into the trajectory model helps decoding, by modeling the natural variation in volitional speed. Figure 4: Mean and standard error of EKFT and KFT accuracy at the different subjectselected speeds. Models were trained on reaches at A all speeds and B just normal speed reaches. Asterisks indicate statistically significant differences between the algorithms. 5 Mi xtu res of Target s So far, we have assumed that the targets of our reaches are perfectly known. In a real-world system, there will be uncertainty about the intended target of the reach. However, in typical applications there are a small number of possible objectives. Here we address this situation. Drawing on the recent literature, we use a mixture model to consider each of the possible targets [11, 13]. We condition the posterior probability for the state on the N possible targets, T: (6) 6 Using Bayes' Rule, this equation becomes: (7) As we are dealing with a mixture model, we perform the Kalman filter recursion for each possible target, xT, and our solution is a weighted sum of the outputs. The weights are proportional to the prior for that target, , and the likelihood of the model given that target . is independent of the target and does not need to be calculated. We tested mixtures of both algorithms, the mKFT and mEKFT, with real uncert ain priors obtained from eye-tracking in the one-second period preceding movement. As the targets were situated on two planes, the three-dimensional location of the eye gaze was found by projecting its direction onto those planes. The first, middle and last eye samples were selected, and all other samples were assigned to a group according to which of the three was closest. The mean and variance of these three groups were used to initialize three Kalman filters in the mixture model. The priors of the three groups were assigned proportional to the number of samples in them. If the subject looks at multiple positions prior to reaching, this method ensures with a high probability that the correct target was accounted for in one of the filters in the mixture. We also compared the MTM approach of Yu et al. [13], where a different KF model was generated for each target, and a mixture is performed over these models. This approach explicitly captures the dynamics of stereotypical reaches to specific targets. Given perfect target information, it would reduce to the STM described above. Priors for the MTM were found by assigning each valid eye sample to its closest two targets, and weighting the models proportional to the number of samples assigned to the corresponding target, divided by its distance from the mean of those samples. We tried other ways of assigning priors and the one presented gave the best results. We calculated the reduction in decoding quality when instead of perfect priors we provide eye-movement based noisy priors (Fig. 5). The accuracies of the mEKFT, the mKFT and the MTM were only degraded by 0.8, 1.9 and 2.1% respectively, compared to the perfect prior situation. The mEKFT was still close to 10% better than the KF. The mixture model framework is effective in accounting for uncertain priors. Figure 5: Mean and standard errors of accuracy for algorithms with perfect priors, and uncertain priors with full and partial training set. The asterisk indicates a statistically significant effects between the two training types, where real priors are used. Here, only reaches at normal speed were used to train the models, as this is a more realistic training set for a BMI application. This accounts for the degraded performance of the MTM with perfect priors relative to the STM from above (Fig. 2). With even more stereotyped training data for each target, the MTM doesn't generalize as well to new speeds. 7 We also wanted to know if the algorithms could generalize to new targets. In a real application, the available training data will generally not span the entire useable worksp ace. We compared the algorithms where reaches to all targets except the one being tested had been used to train the models. The performance of the MTM was significantly de graded unsurprisingly, as it was designed for reaches to a set of known targets. Performance of the mKFT and mEKFT degraded by about 1%, but not significantly (both p>0.7), demonstrating that the continuous approach to target information is preferable when the target could be anywhere in space, not just at locations for which training data is available. 6 Di scu ssi on and concl u si on s The goal of this work was to design a trajectory model that would improve decoding for BMIs with an application to reaching. We incorporated two features that prominently influence the dynamics of natural reach: the movement speed and the target location. Our approach is appropriate where uncertain target information is available. The model generalizes well to new regions of the workspace for which there is no training data, and across a broad range of reaching dynamics to widely spaced targets in three dimensions. The advantages over linear models in decoding precision we report here could be equally obtained using mixtures over many targets and speeds. While mixture models [11, 13] could allow for slow versus fast movements and any number of potential targets, this strategy will generally require many mixture components. Such an approach would require a lot more training data, as we have shown that it does not generalize well. It would also be run-time intensive which is problematic for prosthetic devices that rely on low power controllers. In contrast, the algorithm introduced here only takes a small amount of additional run-time in comparison to the standard KF approach. The EKF is only marginally slower than the standard KF and the algorithm will not generally need to consider more than 3 mixture components assuming the subject fixates the target within the second pre ceding the reach. In this paper we assumed that subjects always would fixate a reach target – along with other non-targets. While this is close to the way humans usually coordinate eyes and reaches [15], there might be cases where people do not fixate a reach target. Our approach could be easily extended to deal with such situations by adding a dummy mixture component that all ows the description of movements to any target. As an alternative to mixture approaches, a system can explicitly estimate the target position in the state vector [9]. This approach, however, would not straightforwardly allow for the rich target information available; we look at the target but also at other locations, strongly suggesting mixture distributions. A combination of the two approaches could further improve decoding quality. We could both estimate speed and target position for the EKFT in a continuous manner while retaining the mixture over target priors. We believe that the issues that we have addressed here are almost universal. Virtually all types of movements are executed at varying speed. A probabilistic distribution for a small number of action candidates may also be expected in most BMI applications – after all there are usually only a small number of actions that make sense in a given environment. While this work is presented in the context of decoding human reaching, it may be applied to a wide range of BMI applications including lower limb prosthetic devices and human computer interactions, as well as different signal sources such as electrode grid recordings and electroencephalograms. The increased user control in conveying their intended movements would significantly improve the functionality of a neuroprosthetic device. A c k n o w l e d g e me n t s T h e a u t h o r s t h a n k T. H a s w e l l , E . K r e p k o v i c h , a n d V. Ravichandran for assistance with experiments. This work was funded by the NSF Program in Cyber-Physical Systems. R e f e re n c e s [1] L.R. Hochberg, M.D. Serruya, G.M. Friehs, J.A. Mukand, M. Saleh, A.H. Caplan, A. Branner, D. 8 [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] [15] [16] [17] [18] Chen, R.D. Penn, and J.P. Donoghue, “Neuronal ensemble control of prosthetic devices by a human with tetraplegia,” Nature, vol. 442, 2006, pp. 164–171. W. Wu, Y. Gao, E. Bienenstock, J.P. Donoghue, and M.J. Black, “Bayesian population decoding of motor cortical activity using a Kalman filter,” Neural Computation, vol. 18, 2006, pp. 80–118. W. Wu, M.J. Black, Y. Gao, E. Bienenstock, M. Serruya, A. Shaikhouni, and J.P. Donoghue, “Neural decoding of cursor motion using a Kalman filter,” Advances in Neural Information Processing Systems 15: Proceedings of the 2002 Conference, 2003, p. 133. R.E. Kalman, “A new approach to linear filtering and prediction problems,” Journal of basic Engineering, vol. 82, 1960, pp. 35–45. G.G. Scandaroli, G.A. Borges, J.Y. Ishihara, M.H. Terra, A.F.D. Rocha, and F.A.D.O. Nascimento, “Estimation of foot orientation with respect to ground for an above knee robotic prosthesis,” Proceedings of the 2009 IEEE/RSJ international conference on Intelligent robots and systems, St. Louis, MO, USA: IEEE Press, 2009, pp. 1112-1117. I. Cikajlo, Z. Matjačić, and T. Bajd, “Efficient FES triggering applying Kalman filter during sensory supported treadmill walking,” Journal of Medical Engineering & Technology, vol. 32, 2008, pp. 133144. S. Kim, J.D. Simeral, L.R. Hochberg, J.P. Donoghue, and M.J. Black, “Neural control of computer cursor velocity by decoding motor cortical spiking activity in humans with tetraplegia,” Journal of Neural Engineering, vol. 5, 2008, pp. 455-476. L. Srinivasan, U.T. Eden, A.S. Willsky, and E.N. Brown, “A state-space analysis for reconstruction of goal-directed movements using neural signals,” Neural computation, vol. 18, 2006, pp. 2465–2494. G.H. Mulliken, S. Musallam, and R.A. Andersen, “Decoding trajectories from posterior parietal cortex ensembles,” Journal of Neuroscience, vol. 28, 2008, p. 12913. W. Wu, J.E. Kulkarni, N.G. Hatsopoulos, and L. Paninski, “Neural Decoding of Hand Motion Using a Linear State-Space Model With Hidden States,” IEEE Transactions on neural systems and rehabilitation engineering, vol. 17, 2009, p. 1. J.E. Kulkarni and L. Paninski, “State-space decoding of goal-directed movements,” IEEE Signal Processing Magazine, vol. 25, 2008, p. 78. C. Kemere and T. Meng, “Optimal estimation of feed-forward-controlled linear systems,” IEEE International Conference on Acoustics, Speech, and Signal Processing, 2005. Proceedings.(ICASSP'05), 2005. B.M. Yu, C. Kemere, G. Santhanam, A. Afshar, S.I. Ryu, T.H. Meng, M. Sahani, and K.V. Shenoy, “Mixture of trajectory models for neural decoding of goal-directed movements,” Journal of neurophysiology, vol. 97, 2007, p. 3763. N. Hatsopoulos, J. Joshi, and J.G. O'Leary, “Decoding continuous and discrete motor behaviors using motor and premotor cortical ensembles,” Journal of neurophysiology, vol. 92, 2004, p. 1165. R.S. Johansson, G. Westling, A. Backstrom, and J.R. Flanagan, “Eye-hand coordination in object manipulation,” Journal of Neuroscience, vol. 21, 2001, p. 6917. G. Wu, F.C. van der Helm, H.E.J. Veeger, M. Makhsous, P. Van Roy, C. Anglin, J. Nagels, A.R. Karduna, and K. McQuade, “ISB recommendation on definitions of joint coordinate systems of various joints for the reporting of human joint motion–Part II: shoulder, elbow, wrist and hand,” Journal of biomechanics, vol. 38, 2005, pp. 981–992. D. Simon, Optimal state estimation: Kalman, H [infinity] and nonlinear approaches, John Wiley and Sons, 2006. Z. Ghahramani and G.E. Hinton, “Parameter estimation for linear dynamical systems,” University of Toronto technical report CRG-TR-96-2, vol. 6, 1996. 9</p><p>3 0.6223135 <a title="113-lda-3" href="./nips-2010-Optimal_learning_rates_for_Kernel_Conjugate_Gradient_regression.html">199 nips-2010-Optimal learning rates for Kernel Conjugate Gradient regression</a></p>
<p>Author: Gilles Blanchard, Nicole Krämer</p><p>Abstract: We prove rates of convergence in the statistical sense for kernel-based least squares regression using a conjugate gradient algorithm, where regularization against overﬁtting is obtained by early stopping. This method is directly related to Kernel Partial Least Squares, a regression method that combines supervised dimensionality reduction with least squares projection. The rates depend on two key quantities: ﬁrst, on the regularity of the target regression function and second, on the effective dimensionality of the data mapped into the kernel space. Lower bounds on attainable rates depending on these two quantities were established in earlier literature, and we obtain upper bounds for the considered method that match these lower bounds (up to a log factor) if the true regression function belongs to the reproducing kernel Hilbert space. If this assumption is not fulﬁlled, we obtain similar convergence rates provided additional unlabeled data are available. The order of the learning rates match state-of-the-art results that were recently obtained for least squares support vector machines and for linear regularization operators. 1</p><p>4 0.53760588 <a title="113-lda-4" href="./nips-2010-Multivariate_Dyadic_Regression_Trees_for_Sparse_Learning_Problems.html">178 nips-2010-Multivariate Dyadic Regression Trees for Sparse Learning Problems</a></p>
<p>Author: Han Liu, Xi Chen</p><p>Abstract: We propose a new nonparametric learning method based on multivariate dyadic regression trees (MDRTs). Unlike traditional dyadic decision trees (DDTs) or classiﬁcation and regression trees (CARTs), MDRTs are constructed using penalized empirical risk minimization with a novel sparsity-inducing penalty. Theoretically, we show that MDRTs can simultaneously adapt to the unknown sparsity and smoothness of the true regression functions, and achieve the nearly optimal rates of convergence (in a minimax sense) for the class of (α, C)-smooth functions. Empirically, MDRTs can simultaneously conduct function estimation and variable selection in high dimensions. To make MDRTs applicable for large-scale learning problems, we propose a greedy heuristics. The superior performance of MDRTs are demonstrated on both synthetic and real datasets. 1</p><p>5 0.53204417 <a title="113-lda-5" href="./nips-2010-A_unified_model_of_short-range_and_long-range_motion_perception.html">20 nips-2010-A unified model of short-range and long-range motion perception</a></p>
<p>Author: Shuang Wu, Xuming He, Hongjing Lu, Alan L. Yuille</p><p>Abstract: The human vision system is able to effortlessly perceive both short-range and long-range motion patterns in complex dynamic scenes. Previous work has assumed that two different mechanisms are involved in processing these two types of motion. In this paper, we propose a hierarchical model as a uniﬁed framework for modeling both short-range and long-range motion perception. Our model consists of two key components: a data likelihood that proposes multiple motion hypotheses using nonlinear matching, and a hierarchical prior that imposes slowness and spatial smoothness constraints on the motion ﬁeld at multiple scales. We tested our model on two types of stimuli, random dot kinematograms and multiple-aperture stimuli, both commonly used in human vision research. We demonstrate that the hierarchical model adequately accounts for human performance in psychophysical experiments.</p><p>6 0.53194875 <a title="113-lda-6" href="./nips-2010-Guaranteed_Rank_Minimization_via_Singular_Value_Projection.html">110 nips-2010-Guaranteed Rank Minimization via Singular Value Projection</a></p>
<p>7 0.53173602 <a title="113-lda-7" href="./nips-2010-A_Dirty_Model_for_Multi-task_Learning.html">5 nips-2010-A Dirty Model for Multi-task Learning</a></p>
<p>8 0.53126252 <a title="113-lda-8" href="./nips-2010-Layered_image_motion_with_explicit_occlusions%2C_temporal_consistency%2C_and_depth_ordering.html">141 nips-2010-Layered image motion with explicit occlusions, temporal consistency, and depth ordering</a></p>
<p>9 0.53109396 <a title="113-lda-9" href="./nips-2010-Epitome_driven_3-D_Diffusion_Tensor_image_segmentation%3A_on_extracting_specific_structures.html">77 nips-2010-Epitome driven 3-D Diffusion Tensor image segmentation: on extracting specific structures</a></p>
<p>10 0.53086495 <a title="113-lda-10" href="./nips-2010-Over-complete_representations_on_recurrent_neural_networks_can_support_persistent_percepts.html">200 nips-2010-Over-complete representations on recurrent neural networks can support persistent percepts</a></p>
<p>11 0.52989829 <a title="113-lda-11" href="./nips-2010-A_biologically_plausible_network_for_the_computation_of_orientation_dominance.html">17 nips-2010-A biologically plausible network for the computation of orientation dominance</a></p>
<p>12 0.52944368 <a title="113-lda-12" href="./nips-2010-Layer-wise_analysis_of_deep_networks_with_Gaussian_kernels.html">140 nips-2010-Layer-wise analysis of deep networks with Gaussian kernels</a></p>
<p>13 0.5286485 <a title="113-lda-13" href="./nips-2010-Regularized_estimation_of_image_statistics_by_Score_Matching.html">224 nips-2010-Regularized estimation of image statistics by Score Matching</a></p>
<p>14 0.52795708 <a title="113-lda-14" href="./nips-2010-MAP_Estimation_for_Graphical_Models_by_Likelihood_Maximization.html">164 nips-2010-MAP Estimation for Graphical Models by Likelihood Maximization</a></p>
<p>15 0.5279327 <a title="113-lda-15" href="./nips-2010-%28RF%29%5E2_--_Random_Forest_Random_Field.html">1 nips-2010-(RF)^2 -- Random Forest Random Field</a></p>
<p>16 0.52793193 <a title="113-lda-16" href="./nips-2010-Occlusion_Detection_and_Motion_Estimation_with_Convex_Optimization.html">187 nips-2010-Occlusion Detection and Motion Estimation with Convex Optimization</a></p>
<p>17 0.52763063 <a title="113-lda-17" href="./nips-2010-Feature_Transitions_with_Saccadic_Search%3A_Size%2C_Color%2C_and_Orientation_Are_Not_Alike.html">95 nips-2010-Feature Transitions with Saccadic Search: Size, Color, and Orientation Are Not Alike</a></p>
<p>18 0.52717835 <a title="113-lda-18" href="./nips-2010-Gaussian_Process_Preference_Elicitation.html">100 nips-2010-Gaussian Process Preference Elicitation</a></p>
<p>19 0.52686036 <a title="113-lda-19" href="./nips-2010-A_Bayesian_Framework_for_Figure-Ground_Interpretation.html">3 nips-2010-A Bayesian Framework for Figure-Ground Interpretation</a></p>
<p>20 0.52666199 <a title="113-lda-20" href="./nips-2010-Generating_more_realistic_images_using_gated_MRF%27s.html">103 nips-2010-Generating more realistic images using gated MRF's</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
