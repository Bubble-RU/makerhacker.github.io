<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>218 nips-2010-Probabilistic latent variable models for distinguishing between cause and effect</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-218" href="#">nips2010-218</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>218 nips-2010-Probabilistic latent variable models for distinguishing between cause and effect</h1>
<br/><p>Source: <a title="nips-2010-218-pdf" href="http://papers.nips.cc/paper/4173-probabilistic-latent-variable-models-for-distinguishing-between-cause-and-effect.pdf">pdf</a></p><p>Author: Oliver Stegle, Dominik Janzing, Kun Zhang, Joris M. Mooij, Bernhard Schölkopf</p><p>Abstract: We propose a novel method for inferring whether X causes Y or vice versa from joint observations of X and Y . The basic idea is to model the observed data using probabilistic latent variable models, which incorporate the effects of unobserved noise. To this end, we consider the hypothetical effect variable to be a function of the hypothetical cause variable and an independent noise term (not necessarily additive). An important novel aspect of our work is that we do not restrict the model class, but instead put general non-parametric priors on this function and on the distribution of the cause. The causal direction can then be inferred by using standard Bayesian model selection. We evaluate our approach on synthetic data and real-world data and report encouraging results. 1</p><p>Reference: <a title="nips-2010-218-reference" href="../nips2010_reference/nips-2010-Probabilistic_latent_variable_models_for_distinguishing_between_cause_and_effect_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Probabilistic latent variable models for distinguishing between cause and effect Oliver Stegle MPI for Biological Cybernetics T¨ bingen, Germany u oliver. [sent-1, score-0.37]
</p><p>2 de  Abstract We propose a novel method for inferring whether X causes Y or vice versa from joint observations of X and Y . [sent-17, score-0.214]
</p><p>3 The basic idea is to model the observed data using probabilistic latent variable models, which incorporate the effects of unobserved noise. [sent-18, score-0.167]
</p><p>4 To this end, we consider the hypothetical effect variable to be a function of the hypothetical cause variable and an independent noise term (not necessarily additive). [sent-19, score-0.498]
</p><p>5 An important novel aspect of our work is that we do not restrict the model class, but instead put general non-parametric priors on this function and on the distribution of the cause. [sent-20, score-0.128]
</p><p>6 The causal direction can then be inferred by using standard Bayesian model selection. [sent-21, score-0.758]
</p><p>7 1  Introduction  The challenge of inferring whether X causes Y (“X → Y ”) or vice versa (“Y → X”) from joint observations of the pair (X, Y ) has recently attracted increasing interest [1, 2, 3, 4, 5, 6, 7, 8]. [sent-23, score-0.214]
</p><p>8 While the traditional causal discovery methods [9, 10] based on (conditional) independences between variables require at least three observed variables, some recent approaches can deal with pairs of variables by exploiting the complexity of the (conditional) probability distributions. [sent-24, score-0.941]
</p><p>9 On an intuitive level, the idea is that the factorization of the joint distribution P (cause, eﬀect) into P (cause)P (eﬀect | cause) typically yields models of lower total complexity than the factorization into P (eﬀect)P (cause | eﬀect). [sent-25, score-0.112]
</p><p>10 If complexity is measured in terms of Kolmogorov complexity, this kind of reasoning would be in the spirit of the principle of “algorithmically independent conditionals” [11], which can also be embedded into a general theory of algorithmic-information-based causal discovery [12]. [sent-27, score-0.853]
</p><p>11 The following theorem is implicitly stated in the latter reference (see remarks before (26) therein):  1  Theorem 1 Let P (X, Y ) be a joint distribution with ﬁnite Kolmogorov complexity such that P (X) and P (Y | X) are algorithmically independent, i. [sent-28, score-0.124]
</p><p>12 , +  I P (X) : P (Y | X) = 0 ,  (1)  +  where = denotes equality up to additive constants. [sent-30, score-0.227]
</p><p>13 It is important to note at this point that the total complexity of the causal model consists of both the complexity of the conditional distribution and of the marginal of the putative cause. [sent-33, score-0.995]
</p><p>14 However, since Kolmogorov complexity is uncomputable, this does not solve the causal discovery problem in practice. [sent-34, score-0.853]
</p><p>15 The work of [4] measures complexity in terms of norms in a reproducing kernel Hilbert space, but due to the high computational costs it applies only to cases where one of the variables is binary. [sent-36, score-0.086]
</p><p>16 The methods [1, 2, 3, 5, 6] deﬁne classes of conditionals C and marginal distributions M, and prefer X → Y whenever P (X) ∈ M and P (Y | X) ∈ C but P (Y ) ∈ M or P (X | Y ) ∈ C. [sent-37, score-0.193]
</p><p>17 This can be interpreted as a (crude) notion of model complexity: all probability distributions inside the class are simple, and those outside the class are complex. [sent-38, score-0.103]
</p><p>18 However, this a priori restriction to a particular class of models poses serious practical limitations (even when in practice some of these methods “soften” the criteria by, for example, using the p-values of suitable hypothesis tests). [sent-39, score-0.146]
</p><p>19 The key idea is to deﬁne appropriate priors on marginal distributions (of the cause) and on conditional distributions (of the effect given the cause) that both favor distributions of low complexity. [sent-41, score-0.422]
</p><p>20 To decide upon the most likely causal direction, we can compare the marginal likelihood (also called evidence) of the models corresponding to each of the hypotheses X → Y and Y → X. [sent-42, score-0.815]
</p><p>21 An important novel aspect of our work is that we explicitly treat the “noise” as a latent variable that summarizes the inﬂuence of all other unobserved causes of the effect. [sent-43, score-0.247]
</p><p>22 The additional key assumption here is the independence of the “causal mechanism” (the function mapping from the cause and noise to the effect) and the distribution of the cause, an idea that was exploited in a different way recently for the deterministic (noise-free) case [13]. [sent-44, score-0.571]
</p><p>23 2  Theory  We start with a theoretical treatment of how to solve the basic causal discovery task (see Figure 1a). [sent-48, score-0.821]
</p><p>24 1 For the special case of additive Gaussian noise, the method proposed in [1] would also seem to be a valid Bayesian approach to causal discovery with continuous variables. [sent-49, score-1.023]
</p><p>25 However, that approach is ﬂawed, as it either completely ignores the distribution for the cause, or uses a simple Gaussian marginal distribution for the cause, which may not be realistic (from the paper it is not clear exactly what is proposed). [sent-50, score-0.166]
</p><p>26 But, as suggested by Theorem 1, and as illustrated by our empirical results, the complexity of the input distribution plays an important role here that cannot be neglected, especially in the two-variable case. [sent-51, score-0.085]
</p><p>27 2  (a)  (b) X  Y  E “X causes Y ”  or  X  θX  Y ˜ E  θf  f  “Y causes X”  xi  ei  yi = f (xi , ei ) i = 1, . [sent-52, score-0.403]
</p><p>28 , N  Figure 1: Observed variables are colored gray, and unobserved variables are white. [sent-55, score-0.13]
</p><p>29 (a) The basic causal discovery task: which of the two causal models gives the best explanation of the observed data D = {(xi , yi )}N ? [sent-56, score-1.557]
</p><p>30 (b) More detailed version of the graphical model for “X causes Y ”. [sent-57, score-0.104]
</p><p>31 1  Probabilistic latent variable models for causal discovery  First, we give a more precise deﬁnition of the class of models that we use for representing that X causes Y (“X → Y ”). [sent-59, score-0.971]
</p><p>32 We assume that the relationship between X and Y is not deterministic, but disturbed by unobserved noise E (effectively, the summary of all other unobserved causes of Y ). [sent-60, score-0.407]
</p><p>33 The situation is depicted in the left-hand part of Figure 1a: X and E both cause Y , but although X and Y are observed, E is not. [sent-61, score-0.23]
</p><p>34 We make the following additional assumptions: (A) There are no other causes of Y , or in other words, we assume determinism: a function f exists such that Y = f (X, E). [sent-62, score-0.104]
</p><p>35 This function will henceforth be called the causal mechanism. [sent-63, score-0.736]
</p><p>36 (C) The distribution of the cause is “independent” from the causal mechanism. [sent-67, score-0.963]
</p><p>37 2 (D) The noise has a standard-normal distribution: E ∼ N (0, 1). [sent-68, score-0.159]
</p><p>38 For these special cases, it has been shown that a model of the same (restricted) form in the reverse direction Y → X that induces the same joint distribution on (X, Y ) does not exist in general. [sent-70, score-0.081]
</p><p>39 This asymmetry can be used for inferring the causal direction. [sent-71, score-0.797]
</p><p>40 In practice, a limited model class may lead to wrong conclusions about the causal direction. [sent-72, score-0.733]
</p><p>41 For example, when assuming additive noise, it may happen that neither of the two directions provides a sufﬁciently good ﬁt to the data and hence no decision can be made. [sent-73, score-0.256]
</p><p>42 In combination with the other two assumptions (C) and (D), however, one does obtain an asymmetry that can be used to infer the causal direction. [sent-78, score-0.775]
</p><p>43 One possibility would be to interpret this independence as an algorithmic 2  This assumption may be violated in biological systems, for example, where the causal mechanisms may have been tuned to their input distributions through evolution. [sent-80, score-0.97]
</p><p>44 2  The Bayesian generative model for X → Y  The basic idea is to deﬁne non-parametric priors on the causal mechanisms and input distributions that favor functions and distributions of low complexity. [sent-89, score-0.986]
</p><p>45 Inferring the causal direction then boils down to standard Bayesian model selection, where preference is given to the model with the largest marginal likelihood. [sent-90, score-0.868]
</p><p>46 We introduce random variables xi (the cause), yi (the effect) and ei (the noise), for i = 1, . [sent-91, score-0.161]
</p><p>47 To make a Bayesian model comparison between the two models X → Y and Y → X, we need to calculate the marginal likelihoods p(x, y | X → Y ) and p(x, y | Y → X). [sent-96, score-0.153]
</p><p>48 Note how the four assumptions discussed in the previous subsection are incorporated into the model: assumption (A) results in Dirac delta distributions δ yi − f (xi , ei ) for each i = 1, . [sent-100, score-0.238]
</p><p>49 Assumption (B) is realized by the a priori independence p(x, e | θX ) = p(x | θX )pE (e). [sent-104, score-0.136]
</p><p>50 Assumption (C) is realized as the a priori independence p(f, θX ) = p(f )p(θX ). [sent-105, score-0.136]
</p><p>51 , x, y and e are random variables taking values in RN ), and use the following choices (although other choices are also possible): • For the prior distribution of the cause X, we use a Gaussian mixture model k 2 αj N (xi | µj , σj )  p(xi | θX ) = j=1  with hyperparameters θX = (k, α1 , . [sent-111, score-0.315]
</p><p>52 In the additive noise case, for example, the length scale λE is large compared to the length scale λX , as this leads to an almost linear dependence of f on e. [sent-127, score-0.446]
</p><p>53 The marginal distribution For the model of the distribution of the cause p(x), we use an asymptotic expansion based on the Minimum Message Length principle that yields the following approximation (for details, see [15]):   k N αj k N 3k − log p(x) ≈ min  log + log + − log p(x | θX ) . [sent-132, score-0.512]
</p><p>54 (6) θX 12 2 12 2 j=1 The conditional distribution For the conditional distribution p(y | x) according to the model X → Y , we start by replacing the integral over the length-scales θf by a MAP estimate: p(y | x) ≈ max p(θf )  δ y − f (x, e) pE (e)de p(f | θf )df. [sent-133, score-0.186]
</p><p>55 The next step would be to integrate over all possible causal mechanisms f (which would be an inﬁnite-dimensional integral). [sent-135, score-0.771]
</p><p>56 4 Alternatively, one could ﬁrst integrate over the causal mechanisms f , and then optimize over the noise values e, similar to what is usually done in GPLVMs [16]. [sent-143, score-0.93]
</p><p>57 However, we believe that for the purpose of causal discovery, that approach does not work well. [sent-144, score-0.705]
</p><p>58 5  After working out the details and taking the negative logarithm, the ﬁnal optimization problem becomes:    N  − log p(y | x) ≈ min − log p(θf ) − log N ( | 0, I) − log N (y | 0, K) + log Mi· K −1 y θf ,   i=1 Hyperpriors  Noise prior  GP marginal    . [sent-147, score-0.255]
</p><p>59 Interestingly, this term is not present in the additive noise case that is usually considered, as the derivative of the causal mechanism with respect to the noise equals one, and its logarithm therefore vanishes. [sent-154, score-1.36]
</p><p>60 We solve the optimization problem (6) concerning the marginal distribution numerically by means of the algorithm written by Figueiredo and Jain [15]. [sent-157, score-0.19]
</p><p>61 The optimization problem (9) concerning the conditional distribution poses more serious practical problems. [sent-159, score-0.143]
</p><p>62 Basically, since we approximate a Bayesian integral by an optimization problem, the objective function (9) still needs to be regularized: if one of the partial derivatives ∂f becomes zero, ∂e the objective function diverges. [sent-160, score-0.089]
</p><p>63 To deal with these matters, we propose the following ad-hoc solutions: • We regularize the √ numerically ill-behaving logarithm in the last term in (9) by approximating 1. [sent-162, score-0.137]
</p><p>64 it as log |x| ≈ log x2 + with • We add a small amount of N (0, σ 2 )-uncertainty to each observed yi -value, with σ 1. [sent-163, score-0.089]
</p><p>65 Further, note that in the ﬁnal optimization problem (9), the unobserved noise values can in fact also be regarded as additional hyperparameters, similar to the GPLVM model [16]. [sent-166, score-0.231]
</p><p>66 In our implementation we applied the following measures to deal with this issue: • We initialize with an additive noise model, by taking the residuals from a standard GP regression as initial values for . [sent-169, score-0.416]
</p><p>67 The reason for doing this is that in an additive noise model, all partial derivatives ∂f are positive and constant. [sent-170, score-0.421]
</p><p>68 This initialization effectively leads to a solution ∂e that satisﬁes the invertability assumption that we made in approximating the evidence. [sent-171, score-0.137]
</p><p>69 This was done ∂e to avoid sign ﬂips of these terms that would violate the invertability assumption. [sent-173, score-0.078]
</p><p>70 6  the last term in (9) by: log with  (x − )2 + + A log  (x − )2 + − log  √  1x≤  1. [sent-175, score-0.087]
</p><p>71 3  Experiments  To evaluate the ability of our method to identify causal directions, we have tested our approach on simulated and real-world data. [sent-182, score-0.756]
</p><p>72 To identify the most probable causal direction, we evaluate the marginal likelihoods corresponding to both possible causal directions (which are given by combining the results of equations (6) and (9)), choosing the model that assigns higher probability to the observed data. [sent-183, score-1.592]
</p><p>73 For comparison, we also considered the marginal likelihood using a GP covariance function that is constant with respect to e, i. [sent-185, score-0.11]
</p><p>74 For this special case, the noise values e can be integrated out analytically, resulting in standard GP regression. [sent-188, score-0.159]
</p><p>75 We also compare with the method proposed in [1], which also uses an additive noise GP regression for the conditional model, but uses a simple Gaussian model for the input distribution p(x). [sent-190, score-0.452]
</p><p>76 We complemented the marginal likelihood as selection criterion with another possible criterion for causal model selection: the independence of the cause and the estimated noise [5]. [sent-192, score-1.342]
</p><p>77 Using HSIC [17] as test criterion for independence, this approach can be applied to both the additive noise GP and the more general latent variable approach. [sent-193, score-0.464]
</p><p>78 As the marginal likelihood does not provide a significance level for the inferred causal direction, we used the ratio of the p-values of HSIC for both causal directions as prediction criterion, preferring the direction with a higher p-value (i. [sent-194, score-1.602]
</p><p>79 , with less dependence between the estimated noise and the cause). [sent-196, score-0.159]
</p><p>80 HSIC as selection criterion applied to the additive or general Gaussian process model will be referred to as AN-HSIC and GPI-HSIC respectively. [sent-197, score-0.262]
</p><p>81 We compared these methods with other related methods: IGCI [13], a method that is also based on assumption (C), although designed for the noise-free case; LINGAM [2], which assumes a linear causal mechanism; and PNL, the Post-NonLinear model [6]. [sent-198, score-0.737]
</p><p>82 The parameter α controls the type of the observation noise, interpolating between purely additive noise (α = 0) and purely multiplicative noise (α = 1). [sent-204, score-0.637]
</p><p>83 The coefﬁcient b determines the nonlinearity of the true causal model, with b = 0 corresponding to the linear case. [sent-205, score-0.705]
</p><p>84 Finally, the parameter q controls the non-Gaussianity of the input and noise distributions: q = 1 gives a Gaussian, while q > 1 and q < 1 produces super-Gaussian and sub-Gaussian distributions respectively. [sent-206, score-0.206]
</p><p>85 Encouragingly, GPI appears to be robust with respect to the type of noise, outperforming additive noise models in the full range between additive and multiplicative noise (Figure 2a). [sent-210, score-0.816]
</p><p>86 Note that the additive noise models actually yield the wrong decision for high values of α, whereas the GPI methods stay well above chance level. [sent-211, score-0.386]
</p><p>87 Figure 2b shows accuracies for a linear model and a non-Gaussian noise and input distribution. [sent-212, score-0.183]
</p><p>88 Figure 2c shows accuracies for a non-linear model with Gaussian additive noise. [sent-213, score-0.251]
</p><p>89 Further, we observe that AN-GAUSS, the method proposed in [1], only performs well for Gaussian input distributions and additive noise. [sent-215, score-0.274]
</p><p>90 9 α  1  Accuracy  (a) From additive to multiplicative noise 1 0. [sent-234, score-0.43]
</p><p>91 8  (b) Linear function, non-Gaussian additive noise AN−MML AN−HSIC AN−GAUSS GPI−MML GPI−HSIC IGCI  0 b  0. [sent-264, score-0.386]
</p><p>92 8  1  (c) Non-linear function, Gaussian additive noise  (d) Legend  Figure 2: Accuracy of recovering the true causal direction in simulated datasets. [sent-268, score-1.219]
</p><p>93 Table 1: Accuracy (in percent) of recovering the true causal direction in 68 real world datasets. [sent-270, score-0.782]
</p><p>94 AN-MML 68 ± 1  AN-HSIC 68 ± 3  AN-GAUSS 45 ± 3  GPI-MML 72 ± 2  GPI-HSIC 62 ± 4  IGCI 76 ± 1  LINGAM 62 ± 3  PNL 67 ± 4  Results on cause-effect pairs Next, we applied the same methods and selection criteria to realworld cause-effect pairs where the true causal direction is known. [sent-271, score-0.758]
</p><p>95 4  Conclusions and discussion  We proposed the ﬁrst method (to the best of our knowledge) for addressing the challenging task of distinguishing between cause and effect without an a priori restriction to a certain class of models. [sent-279, score-0.424]
</p><p>96 The method compares marginal likelihoods that penalize complex input distributions and causal mechanisms. [sent-280, score-0.933]
</p><p>97 Moreover, our framework generalizes a number of existing approaches that assume a limited class of possible causal mechanisms functions. [sent-281, score-0.799]
</p><p>98 Nevertheless, the encouraging results that we have obtained thus far conﬁrm the hypothesis that asymmetries of the joint distribution of cause and effect provide useful hints on the causal direction. [sent-283, score-1.024]
</p><p>99 A linear non-Gaussian acyclic model for a causal discovery. [sent-300, score-0.705]
</p><p>100 Distinguishing between cause and effect via kernel-based como plexity measures for conditional probability densities. [sent-317, score-0.305]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('causal', 0.705), ('cause', 0.23), ('additive', 0.227), ('noise', 0.159), ('janzing', 0.147), ('pe', 0.143), ('mpi', 0.114), ('hsic', 0.114), ('marginal', 0.11), ('gp', 0.106), ('causes', 0.104), ('gpi', 0.104), ('discovery', 0.091), ('bingen', 0.085), ('mooij', 0.078), ('igci', 0.078), ('invertability', 0.078), ('unobserved', 0.072), ('independence', 0.068), ('mechanisms', 0.066), ('ei', 0.063), ('sch', 0.061), ('distinguishing', 0.06), ('cybernetics', 0.059), ('germany', 0.059), ('hoyer', 0.059), ('complexity', 0.057), ('logarithm', 0.056), ('mechanism', 0.054), ('integral', 0.054), ('direction', 0.053), ('gplvms', 0.052), ('lingam', 0.052), ('mml', 0.052), ('biological', 0.052), ('simulated', 0.051), ('hyv', 0.051), ('inferring', 0.05), ('kolmogorov', 0.049), ('distributions', 0.047), ('gplvm', 0.046), ('figueiredo', 0.046), ('gpml', 0.046), ('pnl', 0.046), ('gaussian', 0.045), ('dirac', 0.045), ('multiplicative', 0.044), ('df', 0.044), ('priors', 0.043), ('likelihoods', 0.043), ('latent', 0.043), ('asymmetry', 0.042), ('priori', 0.04), ('algorithmically', 0.039), ('ect', 0.038), ('conditional', 0.038), ('xi', 0.038), ('effect', 0.037), ('delta', 0.037), ('bayesian', 0.037), ('hypothetical', 0.036), ('rinen', 0.036), ('versa', 0.036), ('conditionals', 0.036), ('criterion', 0.035), ('derivatives', 0.035), ('descriptions', 0.033), ('assumption', 0.032), ('yi', 0.031), ('henceforth', 0.031), ('deal', 0.03), ('length', 0.03), ('basically', 0.029), ('log', 0.029), ('variables', 0.029), ('restriction', 0.029), ('put', 0.029), ('directions', 0.029), ('penalize', 0.028), ('realized', 0.028), ('distribution', 0.028), ('aspect', 0.028), ('hyperparameters', 0.028), ('assumptions', 0.028), ('concerning', 0.028), ('class', 0.028), ('idea', 0.027), ('approximating', 0.027), ('deterministic', 0.027), ('favor', 0.026), ('accuracy', 0.026), ('serious', 0.025), ('basic', 0.025), ('accuracies', 0.024), ('vice', 0.024), ('poses', 0.024), ('encouraging', 0.024), ('recovering', 0.024), ('purely', 0.024), ('numerically', 0.024)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="218-tfidf-1" href="./nips-2010-Probabilistic_latent_variable_models_for_distinguishing_between_cause_and_effect.html">218 nips-2010-Probabilistic latent variable models for distinguishing between cause and effect</a></p>
<p>Author: Oliver Stegle, Dominik Janzing, Kun Zhang, Joris M. Mooij, Bernhard Schölkopf</p><p>Abstract: We propose a novel method for inferring whether X causes Y or vice versa from joint observations of X and Y . The basic idea is to model the observed data using probabilistic latent variable models, which incorporate the effects of unobserved noise. To this end, we consider the hypothetical effect variable to be a function of the hypothetical cause variable and an independent noise term (not necessarily additive). An important novel aspect of our work is that we do not restrict the model class, but instead put general non-parametric priors on this function and on the distribution of the cause. The causal direction can then be inferred by using standard Bayesian model selection. We evaluate our approach on synthetic data and real-world data and report encouraging results. 1</p><p>2 0.60713726 <a title="218-tfidf-2" href="./nips-2010-Causal_discovery_in_multiple_models_from_different_experiments.html">46 nips-2010-Causal discovery in multiple models from different experiments</a></p>
<p>Author: Tom Claassen, Tom Heskes</p><p>Abstract: A long-standing open research problem is how to use information from different experiments, including background knowledge, to infer causal relations. Recent developments have shown ways to use multiple data sets, provided they originate from identical experiments. We present the MCI-algorithm as the ﬁrst method that can infer provably valid causal relations in the large sample limit from different experiments. It is fast, reliable and produces very clear and easily interpretable output. It is based on a result that shows that constraint-based causal discovery is decomposable into a candidate pair identiﬁcation and subsequent elimination step that can be applied separately from different models. We test the algorithm on a variety of synthetic input model sets to assess its behavior and the quality of the output. The method shows promising signs that it can be adapted to suit causal discovery in real-world application areas as well, including large databases. 1</p><p>3 0.25423566 <a title="218-tfidf-3" href="./nips-2010-Sparse_Instrumental_Variables_%28SPIV%29_for_Genome-Wide_Studies.html">247 nips-2010-Sparse Instrumental Variables (SPIV) for Genome-Wide Studies</a></p>
<p>Author: Paul Mckeigue, Jon Krohn, Amos J. Storkey, Felix V. Agakov</p><p>Abstract: This paper describes a probabilistic framework for studying associations between multiple genotypes, biomarkers, and phenotypic traits in the presence of noise and unobserved confounders for large genetic studies. The framework builds on sparse linear methods developed for regression and modiﬁed here for inferring causal structures of richer networks with latent variables. The method is motivated by the use of genotypes as “instruments” to infer causal associations between phenotypic biomarkers and outcomes, without making the common restrictive assumptions of instrumental variable methods. The method may be used for an effective screening of potentially interesting genotype-phenotype and biomarker-phenotype associations in genome-wide studies, which may have important implications for validating biomarkers as possible proxy endpoints for early-stage clinical trials. Where the biomarkers are gene transcripts, the method can be used for ﬁne mapping of quantitative trait loci (QTLs) detected in genetic linkage studies. The method is applied for examining effects of gene transcript levels in the liver on plasma HDL cholesterol levels for a sample of sequenced mice from a heterogeneous stock, with ∼ 105 genetic instruments and ∼ 47 × 103 gene transcripts. 1</p><p>4 0.18816119 <a title="218-tfidf-4" href="./nips-2010-Block_Variable_Selection_in_Multivariate_Regression_and_High-dimensional_Causal_Inference.html">41 nips-2010-Block Variable Selection in Multivariate Regression and High-dimensional Causal Inference</a></p>
<p>Author: Vikas Sindhwani, Aurelie C. Lozano</p><p>Abstract: We consider multivariate regression problems involving high-dimensional predictor and response spaces. To efﬁciently address such problems, we propose a variable selection method, Multivariate Group Orthogonal Matching Pursuit, which extends the standard Orthogonal Matching Pursuit technique. This extension accounts for arbitrary sparsity patterns induced by domain-speciﬁc groupings over both input and output variables, while also taking advantage of the correlation that may exist between the multiple outputs. Within this framework, we then formulate the problem of inferring causal relationships over a collection of high-dimensional time series variables. When applied to time-evolving social media content, our models yield a new family of causality-based inﬂuence measures that may be seen as an alternative to the classic PageRank algorithm traditionally applied to hyperlink graphs. Theoretical guarantees, extensive simulations and empirical studies conﬁrm the generality and value of our framework.</p><p>5 0.077677339 <a title="218-tfidf-5" href="./nips-2010-Slice_sampling_covariance_hyperparameters_of_latent_Gaussian_models.html">242 nips-2010-Slice sampling covariance hyperparameters of latent Gaussian models</a></p>
<p>Author: Iain Murray, Ryan P. Adams</p><p>Abstract: The Gaussian process (GP) is a popular way to specify dependencies between random variables in a probabilistic model. In the Bayesian framework the covariance structure can be speciﬁed using unknown hyperparameters. Integrating over these hyperparameters considers diﬀerent possible explanations for the data when making predictions. This integration is often performed using Markov chain Monte Carlo (MCMC) sampling. However, with non-Gaussian observations standard hyperparameter sampling approaches require careful tuning and may converge slowly. In this paper we present a slice sampling approach that requires little tuning while mixing well in both strong- and weak-data regimes. 1</p><p>6 0.077190503 <a title="218-tfidf-6" href="./nips-2010-Gaussian_Process_Preference_Elicitation.html">100 nips-2010-Gaussian Process Preference Elicitation</a></p>
<p>7 0.06545338 <a title="218-tfidf-7" href="./nips-2010-Approximate_inference_in_continuous_time_Gaussian-Jump_processes.html">33 nips-2010-Approximate inference in continuous time Gaussian-Jump processes</a></p>
<p>8 0.062129442 <a title="218-tfidf-8" href="./nips-2010-Computing_Marginal_Distributions_over_Continuous_Markov_Networks_for_Statistical_Relational_Learning.html">49 nips-2010-Computing Marginal Distributions over Continuous Markov Networks for Statistical Relational Learning</a></p>
<p>9 0.058333673 <a title="218-tfidf-9" href="./nips-2010-Scrambled_Objects_for_Least-Squares_Regression.html">233 nips-2010-Scrambled Objects for Least-Squares Regression</a></p>
<p>10 0.053473666 <a title="218-tfidf-10" href="./nips-2010-Unsupervised_Kernel_Dimension_Reduction.html">280 nips-2010-Unsupervised Kernel Dimension Reduction</a></p>
<p>11 0.053158794 <a title="218-tfidf-11" href="./nips-2010-Factorized_Latent_Spaces_with_Structured_Sparsity.html">89 nips-2010-Factorized Latent Spaces with Structured Sparsity</a></p>
<p>12 0.052816801 <a title="218-tfidf-12" href="./nips-2010-Linear_readout_from_a_neural_population_with_partial_correlation_data.html">161 nips-2010-Linear readout from a neural population with partial correlation data</a></p>
<p>13 0.051504217 <a title="218-tfidf-13" href="./nips-2010-The_Maximal_Causes_of_Natural_Scenes_are_Edge_Filters.html">266 nips-2010-The Maximal Causes of Natural Scenes are Edge Filters</a></p>
<p>14 0.050159015 <a title="218-tfidf-14" href="./nips-2010-Efficient_Optimization_for_Discriminative_Latent_Class_Models.html">70 nips-2010-Efficient Optimization for Discriminative Latent Class Models</a></p>
<p>15 0.050147898 <a title="218-tfidf-15" href="./nips-2010-Gaussian_sampling_by_local_perturbations.html">101 nips-2010-Gaussian sampling by local perturbations</a></p>
<p>16 0.049779028 <a title="218-tfidf-16" href="./nips-2010-Tight_Sample_Complexity_of_Large-Margin_Learning.html">270 nips-2010-Tight Sample Complexity of Large-Margin Learning</a></p>
<p>17 0.048567466 <a title="218-tfidf-17" href="./nips-2010-Regularized_estimation_of_image_statistics_by_Score_Matching.html">224 nips-2010-Regularized estimation of image statistics by Score Matching</a></p>
<p>18 0.047120232 <a title="218-tfidf-18" href="./nips-2010-Sufficient_Conditions_for_Generating_Group_Level_Sparsity_in_a_Robust_Minimax_Framework.html">260 nips-2010-Sufficient Conditions for Generating Group Level Sparsity in a Robust Minimax Framework</a></p>
<p>19 0.047053531 <a title="218-tfidf-19" href="./nips-2010-Implicit_Differentiation_by_Perturbation.html">118 nips-2010-Implicit Differentiation by Perturbation</a></p>
<p>20 0.046484016 <a title="218-tfidf-20" href="./nips-2010-Heavy-Tailed_Process_Priors_for_Selective_Shrinkage.html">113 nips-2010-Heavy-Tailed Process Priors for Selective Shrinkage</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.169), (1, 0.047), (2, 0.011), (3, 0.098), (4, -0.07), (5, -0.039), (6, 0.031), (7, 0.069), (8, -0.106), (9, -0.147), (10, -0.311), (11, 0.13), (12, -0.1), (13, -0.311), (14, 0.171), (15, 0.525), (16, -0.059), (17, -0.075), (18, -0.066), (19, -0.069), (20, 0.201), (21, -0.092), (22, -0.004), (23, -0.014), (24, 0.043), (25, 0.014), (26, -0.02), (27, -0.001), (28, -0.046), (29, -0.037), (30, -0.008), (31, 0.001), (32, -0.007), (33, 0.008), (34, -0.035), (35, -0.003), (36, -0.015), (37, 0.03), (38, 0.004), (39, 0.012), (40, 0.03), (41, -0.011), (42, -0.016), (43, -0.008), (44, 0.047), (45, -0.032), (46, 0.004), (47, -0.001), (48, -0.016), (49, 0.012)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.9730832 <a title="218-lsi-1" href="./nips-2010-Causal_discovery_in_multiple_models_from_different_experiments.html">46 nips-2010-Causal discovery in multiple models from different experiments</a></p>
<p>Author: Tom Claassen, Tom Heskes</p><p>Abstract: A long-standing open research problem is how to use information from different experiments, including background knowledge, to infer causal relations. Recent developments have shown ways to use multiple data sets, provided they originate from identical experiments. We present the MCI-algorithm as the ﬁrst method that can infer provably valid causal relations in the large sample limit from different experiments. It is fast, reliable and produces very clear and easily interpretable output. It is based on a result that shows that constraint-based causal discovery is decomposable into a candidate pair identiﬁcation and subsequent elimination step that can be applied separately from different models. We test the algorithm on a variety of synthetic input model sets to assess its behavior and the quality of the output. The method shows promising signs that it can be adapted to suit causal discovery in real-world application areas as well, including large databases. 1</p><p>same-paper 2 0.94433111 <a title="218-lsi-2" href="./nips-2010-Probabilistic_latent_variable_models_for_distinguishing_between_cause_and_effect.html">218 nips-2010-Probabilistic latent variable models for distinguishing between cause and effect</a></p>
<p>Author: Oliver Stegle, Dominik Janzing, Kun Zhang, Joris M. Mooij, Bernhard Schölkopf</p><p>Abstract: We propose a novel method for inferring whether X causes Y or vice versa from joint observations of X and Y . The basic idea is to model the observed data using probabilistic latent variable models, which incorporate the effects of unobserved noise. To this end, we consider the hypothetical effect variable to be a function of the hypothetical cause variable and an independent noise term (not necessarily additive). An important novel aspect of our work is that we do not restrict the model class, but instead put general non-parametric priors on this function and on the distribution of the cause. The causal direction can then be inferred by using standard Bayesian model selection. We evaluate our approach on synthetic data and real-world data and report encouraging results. 1</p><p>3 0.84440589 <a title="218-lsi-3" href="./nips-2010-Sparse_Instrumental_Variables_%28SPIV%29_for_Genome-Wide_Studies.html">247 nips-2010-Sparse Instrumental Variables (SPIV) for Genome-Wide Studies</a></p>
<p>Author: Paul Mckeigue, Jon Krohn, Amos J. Storkey, Felix V. Agakov</p><p>Abstract: This paper describes a probabilistic framework for studying associations between multiple genotypes, biomarkers, and phenotypic traits in the presence of noise and unobserved confounders for large genetic studies. The framework builds on sparse linear methods developed for regression and modiﬁed here for inferring causal structures of richer networks with latent variables. The method is motivated by the use of genotypes as “instruments” to infer causal associations between phenotypic biomarkers and outcomes, without making the common restrictive assumptions of instrumental variable methods. The method may be used for an effective screening of potentially interesting genotype-phenotype and biomarker-phenotype associations in genome-wide studies, which may have important implications for validating biomarkers as possible proxy endpoints for early-stage clinical trials. Where the biomarkers are gene transcripts, the method can be used for ﬁne mapping of quantitative trait loci (QTLs) detected in genetic linkage studies. The method is applied for examining effects of gene transcript levels in the liver on plasma HDL cholesterol levels for a sample of sequenced mice from a heterogeneous stock, with ∼ 105 genetic instruments and ∼ 47 × 103 gene transcripts. 1</p><p>4 0.63709414 <a title="218-lsi-4" href="./nips-2010-Block_Variable_Selection_in_Multivariate_Regression_and_High-dimensional_Causal_Inference.html">41 nips-2010-Block Variable Selection in Multivariate Regression and High-dimensional Causal Inference</a></p>
<p>Author: Vikas Sindhwani, Aurelie C. Lozano</p><p>Abstract: We consider multivariate regression problems involving high-dimensional predictor and response spaces. To efﬁciently address such problems, we propose a variable selection method, Multivariate Group Orthogonal Matching Pursuit, which extends the standard Orthogonal Matching Pursuit technique. This extension accounts for arbitrary sparsity patterns induced by domain-speciﬁc groupings over both input and output variables, while also taking advantage of the correlation that may exist between the multiple outputs. Within this framework, we then formulate the problem of inferring causal relationships over a collection of high-dimensional time series variables. When applied to time-evolving social media content, our models yield a new family of causality-based inﬂuence measures that may be seen as an alternative to the classic PageRank algorithm traditionally applied to hyperlink graphs. Theoretical guarantees, extensive simulations and empirical studies conﬁrm the generality and value of our framework.</p><p>5 0.27612507 <a title="218-lsi-5" href="./nips-2010-Inference_with_Multivariate_Heavy-Tails_in_Linear_Models.html">126 nips-2010-Inference with Multivariate Heavy-Tails in Linear Models</a></p>
<p>Author: Danny Bickson, Carlos Guestrin</p><p>Abstract: Heavy-tailed distributions naturally occur in many real life problems. Unfortunately, it is typically not possible to compute inference in closed-form in graphical models which involve such heavy-tailed distributions. In this work, we propose a novel simple linear graphical model for independent latent random variables, called linear characteristic model (LCM), defined in the characteristic function domain. Using stable distributions, a heavy-tailed family of distributions which is a generalization of Cauchy, L´ vy and Gaussian distrie butions, we show for the first time, how to compute both exact and approximate inference in such a linear multivariate graphical model. LCMs are not limited to stable distributions, in fact LCMs are always defined for any random variables (discrete, continuous or a mixture of both). We provide a realistic problem from the field of computer networks to demonstrate the applicability of our construction. Other potential application is iterative decoding of linear channels with non-Gaussian noise. 1</p><p>6 0.25851882 <a title="218-lsi-6" href="./nips-2010-Evaluation_of_Rarity_of_Fingerprints_in_Forensics.html">82 nips-2010-Evaluation of Rarity of Fingerprints in Forensics</a></p>
<p>7 0.25219551 <a title="218-lsi-7" href="./nips-2010-Heavy-Tailed_Process_Priors_for_Selective_Shrinkage.html">113 nips-2010-Heavy-Tailed Process Priors for Selective Shrinkage</a></p>
<p>8 0.2399433 <a title="218-lsi-8" href="./nips-2010-Slice_sampling_covariance_hyperparameters_of_latent_Gaussian_models.html">242 nips-2010-Slice sampling covariance hyperparameters of latent Gaussian models</a></p>
<p>9 0.23051336 <a title="218-lsi-9" href="./nips-2010-Exact_inference_and_learning_for_cumulative_distribution_functions_on_loopy_graphs.html">84 nips-2010-Exact inference and learning for cumulative distribution functions on loopy graphs</a></p>
<p>10 0.22409284 <a title="218-lsi-10" href="./nips-2010-Learning_sparse_dynamic_linear_systems_using_stable_spline_kernels_and_exponential_hyperpriors.html">154 nips-2010-Learning sparse dynamic linear systems using stable spline kernels and exponential hyperpriors</a></p>
<p>11 0.22304416 <a title="218-lsi-11" href="./nips-2010-Unsupervised_Kernel_Dimension_Reduction.html">280 nips-2010-Unsupervised Kernel Dimension Reduction</a></p>
<p>12 0.22139582 <a title="218-lsi-12" href="./nips-2010-A_Bayesian_Approach_to_Concept_Drift.html">2 nips-2010-A Bayesian Approach to Concept Drift</a></p>
<p>13 0.20786519 <a title="218-lsi-13" href="./nips-2010-Approximate_inference_in_continuous_time_Gaussian-Jump_processes.html">33 nips-2010-Approximate inference in continuous time Gaussian-Jump processes</a></p>
<p>14 0.20516577 <a title="218-lsi-14" href="./nips-2010-Computing_Marginal_Distributions_over_Continuous_Markov_Networks_for_Statistical_Relational_Learning.html">49 nips-2010-Computing Marginal Distributions over Continuous Markov Networks for Statistical Relational Learning</a></p>
<p>15 0.19722925 <a title="218-lsi-15" href="./nips-2010-Gaussian_sampling_by_local_perturbations.html">101 nips-2010-Gaussian sampling by local perturbations</a></p>
<p>16 0.19673583 <a title="218-lsi-16" href="./nips-2010-Gaussian_Process_Preference_Elicitation.html">100 nips-2010-Gaussian Process Preference Elicitation</a></p>
<p>17 0.19366361 <a title="218-lsi-17" href="./nips-2010-A_Bayesian_Framework_for_Figure-Ground_Interpretation.html">3 nips-2010-A Bayesian Framework for Figure-Ground Interpretation</a></p>
<p>18 0.19272293 <a title="218-lsi-18" href="./nips-2010-Approximate_Inference_by_Compilation_to_Arithmetic_Circuits.html">32 nips-2010-Approximate Inference by Compilation to Arithmetic Circuits</a></p>
<p>19 0.19252393 <a title="218-lsi-19" href="./nips-2010-Extended_Bayesian_Information_Criteria_for_Gaussian_Graphical_Models.html">87 nips-2010-Extended Bayesian Information Criteria for Gaussian Graphical Models</a></p>
<p>20 0.19234985 <a title="218-lsi-20" href="./nips-2010-Copula_Processes.html">54 nips-2010-Copula Processes</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.04), (17, 0.017), (27, 0.099), (30, 0.05), (35, 0.017), (38, 0.202), (45, 0.238), (50, 0.064), (52, 0.038), (60, 0.03), (77, 0.053), (78, 0.021), (90, 0.053)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.86476862 <a title="218-lda-1" href="./nips-2010-Probabilistic_latent_variable_models_for_distinguishing_between_cause_and_effect.html">218 nips-2010-Probabilistic latent variable models for distinguishing between cause and effect</a></p>
<p>Author: Oliver Stegle, Dominik Janzing, Kun Zhang, Joris M. Mooij, Bernhard Schölkopf</p><p>Abstract: We propose a novel method for inferring whether X causes Y or vice versa from joint observations of X and Y . The basic idea is to model the observed data using probabilistic latent variable models, which incorporate the effects of unobserved noise. To this end, we consider the hypothetical effect variable to be a function of the hypothetical cause variable and an independent noise term (not necessarily additive). An important novel aspect of our work is that we do not restrict the model class, but instead put general non-parametric priors on this function and on the distribution of the cause. The causal direction can then be inferred by using standard Bayesian model selection. We evaluate our approach on synthetic data and real-world data and report encouraging results. 1</p><p>2 0.86126417 <a title="218-lda-2" href="./nips-2010-Optimal_learning_rates_for_Kernel_Conjugate_Gradient_regression.html">199 nips-2010-Optimal learning rates for Kernel Conjugate Gradient regression</a></p>
<p>Author: Gilles Blanchard, Nicole Krämer</p><p>Abstract: We prove rates of convergence in the statistical sense for kernel-based least squares regression using a conjugate gradient algorithm, where regularization against overﬁtting is obtained by early stopping. This method is directly related to Kernel Partial Least Squares, a regression method that combines supervised dimensionality reduction with least squares projection. The rates depend on two key quantities: ﬁrst, on the regularity of the target regression function and second, on the effective dimensionality of the data mapped into the kernel space. Lower bounds on attainable rates depending on these two quantities were established in earlier literature, and we obtain upper bounds for the considered method that match these lower bounds (up to a log factor) if the true regression function belongs to the reproducing kernel Hilbert space. If this assumption is not fulﬁlled, we obtain similar convergence rates provided additional unlabeled data are available. The order of the learning rates match state-of-the-art results that were recently obtained for least squares support vector machines and for linear regularization operators. 1</p><p>3 0.80504781 <a title="218-lda-3" href="./nips-2010-Short-term_memory_in_neuronal_networks_through_dynamical_compressed_sensing.html">238 nips-2010-Short-term memory in neuronal networks through dynamical compressed sensing</a></p>
<p>Author: Surya Ganguli, Haim Sompolinsky</p><p>Abstract: Recent proposals suggest that large, generic neuronal networks could store memory traces of past input sequences in their instantaneous state. Such a proposal raises important theoretical questions about the duration of these memory traces and their dependence on network size, connectivity and signal statistics. Prior work, in the case of gaussian input sequences and linear neuronal networks, shows that the duration of memory traces in a network cannot exceed the number of neurons (in units of the neuronal time constant), and that no network can out-perform an equivalent feedforward network. However a more ethologically relevant scenario is that of sparse input sequences. In this scenario, we show how linear neural networks can essentially perform compressed sensing (CS) of past inputs, thereby attaining a memory capacity that exceeds the number of neurons. This enhanced capacity is achieved by a class of “orthogonal” recurrent networks and not by feedforward networks or generic recurrent networks. We exploit techniques from the statistical physics of disordered systems to analytically compute the decay of memory traces in such networks as a function of network size, signal sparsity and integration time. Alternately, viewed purely from the perspective of CS, this work introduces a new ensemble of measurement matrices derived from dynamical systems, and provides a theoretical analysis of their asymptotic performance. 1</p><p>4 0.80127162 <a title="218-lda-4" href="./nips-2010-Construction_of_Dependent_Dirichlet_Processes_based_on_Poisson_Processes.html">51 nips-2010-Construction of Dependent Dirichlet Processes based on Poisson Processes</a></p>
<p>Author: Dahua Lin, Eric Grimson, John W. Fisher</p><p>Abstract: We present a novel method for constructing dependent Dirichlet processes. The approach exploits the intrinsic relationship between Dirichlet and Poisson processes in order to create a Markov chain of Dirichlet processes suitable for use as a prior over evolving mixture models. The method allows for the creation, removal, and location variation of component models over time while maintaining the property that the random measures are marginally DP distributed. Additionally, we derive a Gibbs sampling algorithm for model inference and test it on both synthetic and real data. Empirical results demonstrate that the approach is effective in estimating dynamically varying mixture models. 1</p><p>5 0.80003268 <a title="218-lda-5" href="./nips-2010-Functional_form_of_motion_priors_in_human_motion_perception.html">98 nips-2010-Functional form of motion priors in human motion perception</a></p>
<p>Author: Hongjing Lu, Tungyou Lin, Alan Lee, Luminita Vese, Alan L. Yuille</p><p>Abstract: It has been speculated that the human motion system combines noisy measurements with prior expectations in an optimal, or rational, manner. The basic goal of our work is to discover experimentally which prior distribution is used. More speciﬁcally, we seek to infer the functional form of the motion prior from the performance of human subjects on motion estimation tasks. We restricted ourselves to priors which combine three terms for motion slowness, ﬁrst-order smoothness, and second-order smoothness. We focused on two functional forms for prior distributions: L2-norm and L1-norm regularization corresponding to the Gaussian and Laplace distributions respectively. In our ﬁrst experimental session we estimate the weights of the three terms for each functional form to maximize the ﬁt to human performance. We then measured human performance for motion tasks and found that we obtained better ﬁt for the L1-norm (Laplace) than for the L2-norm (Gaussian). We note that the L1-norm is also a better ﬁt to the statistics of motion in natural environments. In addition, we found large weights for the second-order smoothness term, indicating the importance of high-order smoothness compared to slowness and lower-order smoothness. To validate our results further, we used the best ﬁt models using the L1-norm to predict human performance in a second session with different experimental setups. Our results showed excellent agreement between human performance and model prediction – ranging from 3% to 8% for ﬁve human subjects over ten experimental conditions – and give further support that the human visual system uses an L1-norm (Laplace) prior.</p><p>6 0.7995975 <a title="218-lda-6" href="./nips-2010-Two-Layer_Generalization_Analysis_for_Ranking_Using_Rademacher_Average.html">277 nips-2010-Two-Layer Generalization Analysis for Ranking Using Rademacher Average</a></p>
<p>7 0.7995593 <a title="218-lda-7" href="./nips-2010-A_biologically_plausible_network_for_the_computation_of_orientation_dominance.html">17 nips-2010-A biologically plausible network for the computation of orientation dominance</a></p>
<p>8 0.79828 <a title="218-lda-8" href="./nips-2010-Learning_via_Gaussian_Herding.html">158 nips-2010-Learning via Gaussian Herding</a></p>
<p>9 0.79794264 <a title="218-lda-9" href="./nips-2010-Object_Bank%3A_A_High-Level_Image_Representation_for_Scene_Classification_%26_Semantic_Feature_Sparsification.html">186 nips-2010-Object Bank: A High-Level Image Representation for Scene Classification & Semantic Feature Sparsification</a></p>
<p>10 0.79768836 <a title="218-lda-10" href="./nips-2010-Accounting_for_network_effects_in_neuronal_responses_using_L1_regularized_point_process_models.html">21 nips-2010-Accounting for network effects in neuronal responses using L1 regularized point process models</a></p>
<p>11 0.79593438 <a title="218-lda-11" href="./nips-2010-Brain_covariance_selection%3A_better_individual_functional_connectivity_models_using_population_prior.html">44 nips-2010-Brain covariance selection: better individual functional connectivity models using population prior</a></p>
<p>12 0.79566783 <a title="218-lda-12" href="./nips-2010-Variable_margin_losses_for_classifier_design.html">282 nips-2010-Variable margin losses for classifier design</a></p>
<p>13 0.79521334 <a title="218-lda-13" href="./nips-2010-Learning_the_context_of_a_category.html">155 nips-2010-Learning the context of a category</a></p>
<p>14 0.79464555 <a title="218-lda-14" href="./nips-2010-Distributed_Dual_Averaging_In_Networks.html">63 nips-2010-Distributed Dual Averaging In Networks</a></p>
<p>15 0.79454589 <a title="218-lda-15" href="./nips-2010-The_Neural_Costs_of_Optimal_Control.html">268 nips-2010-The Neural Costs of Optimal Control</a></p>
<p>16 0.79417181 <a title="218-lda-16" href="./nips-2010-Group_Sparse_Coding_with_a_Laplacian_Scale_Mixture_Prior.html">109 nips-2010-Group Sparse Coding with a Laplacian Scale Mixture Prior</a></p>
<p>17 0.79285848 <a title="218-lda-17" href="./nips-2010-Exact_learning_curves_for_Gaussian_process_regression_on_large_random_graphs.html">85 nips-2010-Exact learning curves for Gaussian process regression on large random graphs</a></p>
<p>18 0.79141289 <a title="218-lda-18" href="./nips-2010-Efficient_Optimization_for_Discriminative_Latent_Class_Models.html">70 nips-2010-Efficient Optimization for Discriminative Latent Class Models</a></p>
<p>19 0.79056662 <a title="218-lda-19" href="./nips-2010-Sidestepping_Intractable_Inference_with_Structured_Ensemble_Cascades.html">239 nips-2010-Sidestepping Intractable Inference with Structured Ensemble Cascades</a></p>
<p>20 0.79053891 <a title="218-lda-20" href="./nips-2010-Extended_Bayesian_Information_Criteria_for_Gaussian_Graphical_Models.html">87 nips-2010-Extended Bayesian Information Criteria for Gaussian Graphical Models</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
