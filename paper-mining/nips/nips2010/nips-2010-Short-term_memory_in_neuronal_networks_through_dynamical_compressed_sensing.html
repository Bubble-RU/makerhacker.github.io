<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>238 nips-2010-Short-term memory in neuronal networks through dynamical compressed sensing</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-238" href="#">nips2010-238</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>238 nips-2010-Short-term memory in neuronal networks through dynamical compressed sensing</h1>
<br/><p>Source: <a title="nips-2010-238-pdf" href="http://papers.nips.cc/paper/3980-short-term-memory-in-neuronal-networks-through-dynamical-compressed-sensing.pdf">pdf</a></p><p>Author: Surya Ganguli, Haim Sompolinsky</p><p>Abstract: Recent proposals suggest that large, generic neuronal networks could store memory traces of past input sequences in their instantaneous state. Such a proposal raises important theoretical questions about the duration of these memory traces and their dependence on network size, connectivity and signal statistics. Prior work, in the case of gaussian input sequences and linear neuronal networks, shows that the duration of memory traces in a network cannot exceed the number of neurons (in units of the neuronal time constant), and that no network can out-perform an equivalent feedforward network. However a more ethologically relevant scenario is that of sparse input sequences. In this scenario, we show how linear neural networks can essentially perform compressed sensing (CS) of past inputs, thereby attaining a memory capacity that exceeds the number of neurons. This enhanced capacity is achieved by a class of “orthogonal” recurrent networks and not by feedforward networks or generic recurrent networks. We exploit techniques from the statistical physics of disordered systems to analytically compute the decay of memory traces in such networks as a function of network size, signal sparsity and integration time. Alternately, viewed purely from the perspective of CS, this work introduces a new ensemble of measurement matrices derived from dynamical systems, and provides a theoretical analysis of their asymptotic performance. 1</p><p>Reference: <a title="nips-2010-238-reference" href="../nips2010_reference/nips-2010-Short-term_memory_in_neuronal_networks_through_dynamical_compressed_sensing_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Short-term memory in neuronal networks through dynamical compressed sensing  Surya Ganguli Sloan-Swartz Center for Theoretical Neurobiology, UCSF, San Francisco, CA 94143 surya@phy. [sent-1, score-1.134]
</p><p>2 il  Abstract Recent proposals suggest that large, generic neuronal networks could store memory traces of past input sequences in their instantaneous state. [sent-6, score-0.96]
</p><p>3 Such a proposal raises important theoretical questions about the duration of these memory traces and their dependence on network size, connectivity and signal statistics. [sent-7, score-0.878]
</p><p>4 Prior work, in the case of gaussian input sequences and linear neuronal networks, shows that the duration of memory traces in a network cannot exceed the number of neurons (in units of the neuronal time constant), and that no network can out-perform an equivalent feedforward network. [sent-8, score-1.169]
</p><p>5 In this scenario, we show how linear neural networks can essentially perform compressed sensing (CS) of past inputs, thereby attaining a memory capacity that exceeds the number of neurons. [sent-10, score-1.042]
</p><p>6 This enhanced capacity is achieved by a class of “orthogonal” recurrent networks and not by feedforward networks or generic recurrent networks. [sent-11, score-0.703]
</p><p>7 We exploit techniques from the statistical physics of disordered systems to analytically compute the decay of memory traces in such networks as a function of network size, signal sparsity and integration time. [sent-12, score-1.019]
</p><p>8 Alternately, viewed purely from the perspective of CS, this work introduces a new ensemble of measurement matrices derived from dynamical systems, and provides a theoretical analysis of their asymptotic performance. [sent-13, score-0.618]
</p><p>9 1  Introduction  How neuronal networks can store a memory trace for recent sequences of stimuli is a central question in theoretical neuroscience. [sent-14, score-0.723]
</p><p>10 More recent proposals [2, 3, 4] suggest that recurrent networks could store temporal sequences of inputs in their ongoing, transient activity, even if they do not have nontrivial ﬁxed points. [sent-17, score-0.478]
</p><p>11 However, the theoretical principles underlying the ability of recurrent networks to store temporal sequences in their transient dynamics are poorly understood. [sent-19, score-0.472]
</p><p>12 For example, how long can memory traces last in such networks, and how does memory capacity depend on parameters like network size, connectivity, or input statistics? [sent-20, score-1.105]
</p><p>13 Even in this simple setting, the relationship between the memory properties of a neural network and its connectivity is nonlinear, and so understanding this 1  relationship poses an interesting challenge. [sent-22, score-0.7]
</p><p>14 Jaeger [4] proved a rigorous sum-rule (reviewed in more detail below) which showed that even in the absence of noise, no recurrent network can remember inputs for an amount of time that exceeds the number of neurons (in units of the neuronal time constant) in the network. [sent-23, score-0.561]
</p><p>15 [5] showed that in the presence of noise, a special class of “orthogonal” networks, but not generic recurrent networks, could have memory that scales with network size. [sent-25, score-0.7]
</p><p>16 [6] used the theory of Fisher information to show that the memory of a recurrent network cannot exceed that of an equivalent feedforward network, at least for times up to the network size, in units of the neuronal time constant. [sent-28, score-1.009]
</p><p>17 Here we report theoretical progress on understanding the memory capacity of linear recurrent networks for an important class of nongaussian signals, namely sparse signals. [sent-31, score-0.947]
</p><p>18 We use ideas from compressed sensing (CS) to deﬁne memory curves which capture the decay of memory traces in neural networks for sparse signals, and provide methods to compute these curves analytically. [sent-33, score-1.679]
</p><p>19 We ﬁnd strikingly different properties of memory curves in the sparse setting compared to the gaussian setting. [sent-34, score-0.657]
</p><p>20 Although motivated by the problem of memory, we also contribute new results to the ﬁeld of CS itself, by introducing and analyzing new classes of CS measurement matrices derived from dynamical systems. [sent-35, score-0.493]
</p><p>21 In the next section, we begin by reviewing more quantitatively the problem of short-term memory in neuronal networks, compressed sensing, and the relation between the two. [sent-37, score-0.637]
</p><p>22 2  Short-term memory as dynamical compressed sensing. [sent-38, score-0.821]
</p><p>23 x(n) ∈ RN is the network state at time n, W is an N × N recurrent connectivity matrix, and v is a vector of feedforward connections from the signal into the network. [sent-41, score-0.555]
</p><p>24 If we think of the signal history {s0 (n − k)|k ≥ 0} as an inﬁnite dimensional temporal vector s0 whose k’th component s0 is s(n − k), then the current network state x is linearly k related to s through the effective N by ∞ measurement matrix A, i. [sent-43, score-0.474]
</p><p>25 The extent to which the dynamical system in (1) can remember the past can then be quantiﬁed by how well one can recover s0 from x [4, 5, 6]. [sent-52, score-0.44]
</p><p>26 The correlation between the estimate ˆk and the true signal s s s0 , averaged over the gaussian statistics of s0 , then deﬁnes a memory curve M (k) = ˆk s0 s0 , s k k whose decay as k increases quantiﬁes the decay of memory for past inputs in (1). [sent-54, score-1.487]
</p><p>27 Jaeger proved an ∞ important sum-rule for M (k): k=0 M (k) = N for any recurrent connectivity W and feedforward connectivity v. [sent-55, score-0.409]
</p><p>28 s k Generically, one may not hope to remember sequences lasting longer than N timesteps with only N neurons, but in the case of temporally sparse inputs, the ﬁeld of compressed sensing (CS) suggests this may be possible. [sent-57, score-0.439]
</p><p>29 We quantify the memory capabilities of a neural network for sparse signals, by assessing our ability to reconstruct the past signal using L1 minimization. [sent-68, score-0.895]
</p><p>30 Given a network state x arising from a signal history s0 through (1), we can obtain an estimate ˆ of the past using (3), where the s measurement matrix A is given by (2). [sent-69, score-0.541]
</p><p>31 We then deﬁne a memory curve E(k) = (ˆk − s0 )2 s0 , s k  (4)  namely the average reconstruction error of a signal k timesteps in the past averaged over the statistics of s0 . [sent-70, score-0.904]
</p><p>32 The rise of this error as k increases captures the decay of memory traces in (1). [sent-71, score-0.636]
</p><p>33 The central goal of this paper is to obtain a deeper understanding of the memory properties of neural networks for sparse signals by studying the memory curve E(k) and especially its dependence on W. [sent-72, score-1.222]
</p><p>34 Such networks can essentially perform compressed sensing of their past inputs. [sent-74, score-0.437]
</p><p>35 From the perspective of CS, measurement matrices A of the form in (2), henceforth referred to as dynamical CS matrices, possess several new features not considered in the existing CS literature, features which could pose severe challenges for a recurrent network W to achieve good CS performance. [sent-75, score-0.748]
</p><p>36 Third, the different columns of A can be correlated; if one thinks of Wk v as the state of the network k timesteps after a single unit input pulse, it is clear that temporal correlations in the evolving network response to this pulse are equivalent to correlations in the columns of A in (2). [sent-79, score-0.753]
</p><p>37 Nevertheless, despite all these seeming difﬁculties, in the following we show that a special class of network connectivities can indeed achieve good CS performance in which errors are controlled and memory traces can last longer than the number of neurons. [sent-81, score-0.66]
</p><p>38 3  Memory in an Annealed Approximation to a Dynamical System  In this section, we work towards an analytic understanding of the memory curve E(k) deﬁned in (4). [sent-82, score-0.515]
</p><p>39 We would like to understand its properties for ensembles of large random networks W, just as the asymptotic performance of CS was analyzed for large random measurement matrices A [12, 13, 14, 15]. [sent-84, score-0.406]
</p><p>40 However, in the dynamical setting, even if W is drawn from a simple random matrix ensemble, A in (2) will have correlations across its columns, making an analytical treatment of the memory curve difﬁcult. [sent-85, score-0.9]
</p><p>41 Here we consider an ensemble of measurement matrices A which approximate dynamical CS matrices and can be 3  treated analytically. [sent-86, score-0.648]
</p><p>42 Since we are interested in memory that lasts O(N ) timesteps, we choose ρ = e−1/τ N , with τ O(1). [sent-90, score-0.435]
</p><p>43 This so called annealed approximation (AA) to a dynamical CS matrix captures two of the salient properties of dynamical CS matrices, their inﬁnite temporal extent and the decay of successive columns, but neglects the analytically intractable correlations across columns. [sent-91, score-1.315]
</p><p>44 Such annealed CS matrices can be thought of as arising from “imaginary” dynamical systems in which network activity patterns over time in response to a pulse decay, but are somehow temporally uncorrelated. [sent-92, score-0.952]
</p><p>45 To theoretically compute the memory curve E(k), we deﬁne an energy function T  E(s) =  λ T T u A Au + |si |, 2 i=1  (5)  1 where u ≡ s − s0 is the residual, and we consider the Gibbs distribution PG (s) = Z e−βE(s) . [sent-96, score-0.488]
</p><p>46 In this limit, we can extract the memory curve E(k) as the average of (sk −s0 )2 over PG and the statistics of s0 . [sent-98, score-0.488]
</p><p>47 Although PG depends on A, for large N , the properties of k PG , including the memory curve E(k), do not depend on the detailed realization of A, but only on its statistics. [sent-99, score-0.513]
</p><p>48 Now to compute the memory curve E(k), we must take the limits λ, β, N → ∞ and complete the average over s0 . [sent-111, score-0.488]
</p><p>49 Finally the memory curve E(t) is simply the continuum limit of the averaged squared residual 2 u H M F z,s0 , and is given by k  E(t) =  η(s0 + z  et/τ q0 , et/τ ∆q) − s0  2 z,s0  . [sent-127, score-0.563]
</p><p>50 1B shows an example of a reconstruction of ˆ using s L1 minimization in (3) where the data x used in (3) was obtained from s0 using a random annealed measurement matrix with τ = 1. [sent-133, score-0.579]
</p><p>51 Clearly there are errors in the reconstruction, but remarkably, despite the decay in the columns of A, the reconstruction is well correlated with the true signal for a time up to 4 times the number of measurements. [sent-134, score-0.436]
</p><p>52 We can derive theoretical memory curves for any given f and τ by numerically solving for q0 and ∆q in (15),(16), and inserting the results into (17). [sent-135, score-0.556]
</p><p>53 As t → ∞, L1 minimization always yields a zero signal estimate, so the memory curve asymptotically approaches f for large t. [sent-138, score-0.647]
</p><p>54 A convenient measure of memory capacity is the time T1/2 at which the memory curve reaches half its asymptotic error value, i. [sent-139, score-1.01]
</p><p>55 (B) A reconstruction of s0 from the output of an annealed measurement matrix with N = 500, τ = 1. [sent-153, score-0.547]
</p><p>56 of this family of memory curves is that for any given f there is an optimal τ which maximizes T1/2 (Fig. [sent-167, score-0.515]
</p><p>57 If τ is too small, signal measurements decay too quickly, thereby preventing large memory capacity. [sent-170, score-0.731]
</p><p>58 However, if τ is too large, signals from the distant past do not decay away, thereby interfering with the measurements of more recent signals, and again degrading memory. [sent-171, score-0.407]
</p><p>59 As f decreases, long time signal interference is reduced, thereby allowing larger values of τ to be chosen without degrading memory for more recent signals. [sent-172, score-0.602]
</p><p>60 This memory capacity, again measured in units of the number of neurons, already exceeds 1 at modest values of f = 0. [sent-175, score-0.492]
</p><p>61 4  Orthogonal Dynamical Systems  We have seen in the previous section that annealed CS matrices have remarkable memory properties, but our main interest was to exhibit a dynamical CS matrix as in (2) capable of good compressed sensing, and therefore short-term √ memory, performance. [sent-183, score-1.287]
</p><p>62 Here we show that a special class of network connectivity in which W = ρO where O is any orthogonal matrix, and v is any random unit norm vector possesses memory properties remarkably close to that of the annealed matrix ensemble. [sent-184, score-1.122]
</p><p>63 2 were obtained using dynamical CS matrices of the form Aµk = (ρk/2 Ok v)µ , rather than annealed CS matrices. [sent-188, score-0.691]
</p><p>64 1 and reﬂect the theory of annealed CS matrices derived in the previous section. [sent-191, score-0.408]
</p><p>65 For small τ , we see small discrepancies between memory curves for orthogonal neural networks and the annealed theory (Fig. [sent-192, score-1.103]
</p><p>66 In particular, from the perspective of the optimal T1/2 for which larger τ is relevant, we see a remarkable match between the optimal memory capacity of orthogonal neural networks and that predicted by the annealed theory (see Fig. [sent-195, score-1.109]
</p><p>67 1 except now the blue curves and points are obtained from simulations of L1 minimization using measurement matrices derived from an orthogonal neuronal network. [sent-211, score-0.64]
</p><p>68 (G) The mean and standard deviation of σf for 5 annealed (red) and 5 orthogonal matrices (blue) with N=200 and T=3000. [sent-212, score-0.548]
</p><p>69 The key difference between the annealed and the dynamical CS matrices is that the former neglects correlations across columns that can arise in the latter. [sent-213, score-0.897]
</p><p>70 Results are shown in Fig 2 for 5 instances of annealed (red) and dynamical (blue) CS matrices. [sent-221, score-0.59]
</p><p>71 Correlations are much stronger in the dynamical ensemble, and ﬂuctuate from instance to instance, while they are weaker in the annealed ensemble, and do not ﬂuctuate (the 5 red curves are on top of each other). [sent-223, score-0.72]
</p><p>72 Given the very different statistical properties of the two ensembles, the level of agreement between the simulated memory properties of orthogonal neural networks, and the theory of annealed CS matrices is remarkable. [sent-224, score-1.033]
</p><p>73 Why do orthogonal neural networks perform so well, and can more generic networks have similar performance? [sent-225, score-0.432]
</p><p>74 The key to understanding the memory, and CS, capabilities of orthogonal neural √ networks lies in the eigenvalue spectrum of an orthogonal matrix. [sent-226, score-0.526]
</p><p>75 Good compressed sensing matrices often have columns that are random and uncorrelated. [sent-233, score-0.399]
</p><p>76 From the above considerations, it is clear that dynamical CS matrices derived from orthogonal neural networks can come close to this ideal, while those derived from generic gaussian networks cannot. [sent-234, score-0.856]
</p><p>77 5  Discussion  In this work we have made progress on the theory of short-term memory for nongaussian, sparse, temporal sequences stored in the transient dynamics of neuronal networks. [sent-235, score-0.688]
</p><p>78 We used the framework of compressed sensing, speciﬁcally L1 minimization, to reconstruct the history of the past input signal from the current network activity state. [sent-236, score-0.587]
</p><p>79 The reconstruction error as a function of time into the past then yields a well-deﬁned memory curve that reﬂects the memory capabilities of the network. [sent-237, score-1.139]
</p><p>80 We studied the properties of this memory curve and its dependence on network connectivity, and found 7  results that were qualitatively different from prior theoretical studies devoted to short-term memory in the setting of gaussian input statistics. [sent-238, score-1.118]
</p><p>81 Also, recurrent connectivity plays an essential role in allowing a network to have a memory capacity that exceeds the number of neurons. [sent-240, score-0.898]
</p><p>82 Thus purely feedforward networks, which always outperform recurrent networks (for times less than the network size) in the scenario of gaussian signals and noise [6] are no longer optimal for sparse input statistics. [sent-241, score-0.618]
</p><p>83 Finally, we exploited powerful tools from statistical mechanics to analytically compute memory curves as a function of signal sparsity and network integration time. [sent-242, score-0.808]
</p><p>84 To our knowledge, these results represent the ﬁrst theoretical calculations of short-term memory curves for sparse signals in neuronal networks. [sent-244, score-0.788]
</p><p>85 Instead we use L1 minimization in this work simply as a theoretical tool to probe the memory capabilities of neural networks. [sent-246, score-0.58]
</p><p>86 Also, we found that orthogonal neural networks, because of their eigenvalue spectrum, display remarkable memory properties, similar to that of an annealed approximation. [sent-248, score-0.941]
</p><p>87 Such special connectivity is essential for memory performance, as random gaussian networks cannot have memory similar to the annealed approximation. [sent-249, score-1.374]
</p><p>88 The ﬁrst of these, dynamical CS matrices, are the effective measurements a dynamical system makes on a continuous temporal stream of input. [sent-254, score-0.644]
</p><p>89 Dynamical CS matrices have three properties not considered in the existing CS literature: they are inﬁnite in temporal extent, have columns that decay over time and exhibit correlations between columns. [sent-255, score-0.486]
</p><p>90 We also introduce annealed CS matrices, that are also inﬁnite in extent and have decaying columns, but no correlations across columns. [sent-256, score-0.439]
</p><p>91 We show how to analytically calculate the time course of reconstruction error in the annealed ensemble and compare it to the dynamical ensemble for orthogonal dynamical systems. [sent-257, score-1.249]
</p><p>92 Our results show that orthogonal dynamical systems can perform CS even while operating with errors. [sent-258, score-0.423]
</p><p>93 Given the importance of signal statistics in determining memory capacity, it would be interesting to study memory for sparse nonnegative signals. [sent-260, score-0.993]
</p><p>94 We have found, through simulations, dramatic improvements in memory capacity in this case, and are extending the theory to explain these effects. [sent-262, score-0.492]
</p><p>95 However our theory can be extended to analyze memory in the presence of noise by working at ﬁnite λ. [sent-268, score-0.408]
</p><p>96 But most importantly, a deeper understanding of the relationship between dynamical CS matrices and their annealed counterparts would desirable. [sent-269, score-0.718]
</p><p>97 The effects of temporal correlations in the network activity patterns of orthogonal dynamical systems is central to this problem. [sent-270, score-0.772]
</p><p>98 For example, we have seen that these temporal correlations introduce strong correlations between the columns of the corresponding dynamical CS matrix (Fig. [sent-271, score-0.633]
</p><p>99 2G), yet the memory properties of these matrices agree well with our annealed theory (Fig. [sent-272, score-0.841]
</p><p>100 We leave this observation as an intriguing puzzle for the ﬁelds of short-term memory, dynamical systems, and compressed sensing. [sent-274, score-0.413]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('cs', 0.455), ('memory', 0.408), ('annealed', 0.307), ('dynamical', 0.283), ('pg', 0.157), ('orthogonal', 0.14), ('decay', 0.139), ('recurrent', 0.139), ('compressed', 0.13), ('signal', 0.127), ('network', 0.116), ('networks', 0.114), ('measurement', 0.109), ('curves', 0.107), ('reconstruction', 0.102), ('matrices', 0.101), ('correlations', 0.1), ('sensing', 0.1), ('neuronal', 0.099), ('connectivity', 0.097), ('timesteps', 0.094), ('past', 0.093), ('traces', 0.089), ('capacity', 0.084), ('signals', 0.083), ('curve', 0.08), ('sk', 0.077), ('feedforward', 0.076), ('columns', 0.068), ('replica', 0.067), ('ganguli', 0.062), ('donoho', 0.058), ('hk', 0.057), ('dz', 0.056), ('activity', 0.055), ('ensemble', 0.054), ('exceeds', 0.054), ('nongaussian', 0.053), ('inputs', 0.053), ('temporal', 0.053), ('sparse', 0.05), ('capabilities', 0.048), ('connectivities', 0.047), ('limit', 0.046), ('jaeger', 0.043), ('theoretical', 0.041), ('pnas', 0.041), ('hamiltonian', 0.04), ('gaussian', 0.04), ('history', 0.04), ('phase', 0.039), ('neurons', 0.038), ('pulse', 0.038), ('neglects', 0.038), ('generic', 0.037), ('degrading', 0.035), ('surya', 0.035), ('wk', 0.035), ('dynamics', 0.033), ('sequences', 0.033), ('candes', 0.033), ('thereby', 0.032), ('minimization', 0.032), ('extent', 0.032), ('pm', 0.032), ('remember', 0.032), ('instantaneous', 0.032), ('transient', 0.031), ('progress', 0.031), ('asymptotic', 0.03), ('eigenvalue', 0.03), ('units', 0.03), ('remarkable', 0.029), ('matrix', 0.029), ('continuum', 0.029), ('haim', 0.029), ('perfect', 0.028), ('store', 0.028), ('ensembles', 0.027), ('simulations', 0.027), ('understanding', 0.027), ('eld', 0.027), ('lasts', 0.027), ('strikingly', 0.027), ('uctuate', 0.027), ('proposals', 0.027), ('arising', 0.027), ('neural', 0.027), ('analytically', 0.026), ('reconstruct', 0.026), ('blue', 0.025), ('patterns', 0.025), ('measurements', 0.025), ('properties', 0.025), ('exceed', 0.025), ('probe', 0.024), ('mechanics', 0.024), ('nonzero', 0.024), ('mins', 0.023), ('red', 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="238-tfidf-1" href="./nips-2010-Short-term_memory_in_neuronal_networks_through_dynamical_compressed_sensing.html">238 nips-2010-Short-term memory in neuronal networks through dynamical compressed sensing</a></p>
<p>Author: Surya Ganguli, Haim Sompolinsky</p><p>Abstract: Recent proposals suggest that large, generic neuronal networks could store memory traces of past input sequences in their instantaneous state. Such a proposal raises important theoretical questions about the duration of these memory traces and their dependence on network size, connectivity and signal statistics. Prior work, in the case of gaussian input sequences and linear neuronal networks, shows that the duration of memory traces in a network cannot exceed the number of neurons (in units of the neuronal time constant), and that no network can out-perform an equivalent feedforward network. However a more ethologically relevant scenario is that of sparse input sequences. In this scenario, we show how linear neural networks can essentially perform compressed sensing (CS) of past inputs, thereby attaining a memory capacity that exceeds the number of neurons. This enhanced capacity is achieved by a class of “orthogonal” recurrent networks and not by feedforward networks or generic recurrent networks. We exploit techniques from the statistical physics of disordered systems to analytically compute the decay of memory traces in such networks as a function of network size, signal sparsity and integration time. Alternately, viewed purely from the perspective of CS, this work introduces a new ensemble of measurement matrices derived from dynamical systems, and provides a theoretical analysis of their asymptotic performance. 1</p><p>2 0.19339865 <a title="238-tfidf-2" href="./nips-2010-Deciphering_subsampled_data%3A_adaptive_compressive_sampling_as_a_principle_of_brain_communication.html">56 nips-2010-Deciphering subsampled data: adaptive compressive sampling as a principle of brain communication</a></p>
<p>Author: Guy Isely, Christopher Hillar, Fritz Sommer</p><p>Abstract: A new algorithm is proposed for a) unsupervised learning of sparse representations from subsampled measurements and b) estimating the parameters required for linearly reconstructing signals from the sparse codes. We verify that the new algorithm performs efﬁcient data compression on par with the recent method of compressive sampling. Further, we demonstrate that the algorithm performs robustly when stacked in several stages or when applied in undercomplete or overcomplete situations. The new algorithm can explain how neural populations in the brain that receive subsampled input through ﬁber bottlenecks are able to form coherent response properties. 1</p><p>3 0.14326638 <a title="238-tfidf-3" href="./nips-2010-Distributionally_Robust_Markov_Decision_Processes.html">64 nips-2010-Distributionally Robust Markov Decision Processes</a></p>
<p>Author: Huan Xu, Shie Mannor</p><p>Abstract: We consider Markov decision processes where the values of the parameters are uncertain. This uncertainty is described by a sequence of nested sets (that is, each set contains the previous one), each of which corresponds to a probabilistic guarantee for a different conﬁdence level so that a set of admissible probability distributions of the unknown parameters is speciﬁed. This formulation models the case where the decision maker is aware of and wants to exploit some (yet imprecise) a-priori information of the distribution of parameters, and arises naturally in practice where methods to estimate the conﬁdence region of parameters abound. We propose a decision criterion based on distributional robustness: the optimal policy maximizes the expected total reward under the most adversarial probability distribution over realizations of the uncertain parameters that is admissible (i.e., it agrees with the a-priori information). We show that ﬁnding the optimal distributionally robust policy can be reduced to a standard robust MDP where the parameters belong to a single uncertainty set, hence it can be computed in polynomial time under mild technical conditions.</p><p>4 0.1140322 <a title="238-tfidf-4" href="./nips-2010-Over-complete_representations_on_recurrent_neural_networks_can_support_persistent_percepts.html">200 nips-2010-Over-complete representations on recurrent neural networks can support persistent percepts</a></p>
<p>Author: Shaul Druckmann, Dmitri B. Chklovskii</p><p>Abstract: A striking aspect of cortical neural networks is the divergence of a relatively small number of input channels from the peripheral sensory apparatus into a large number of cortical neurons, an over-complete representation strategy. Cortical neurons are then connected by a sparse network of lateral synapses. Here we propose that such architecture may increase the persistence of the representation of an incoming stimulus, or a percept. We demonstrate that for a family of networks in which the receptive ﬁeld of each neuron is re-expressed by its outgoing connections, a represented percept can remain constant despite changing activity. We term this choice of connectivity REceptive FIeld REcombination (REFIRE) networks. The sparse REFIRE network may serve as a high-dimensional integrator and a biologically plausible model of the local cortical circuit. 1</p><p>5 0.11123071 <a title="238-tfidf-5" href="./nips-2010-Inferring_Stimulus_Selectivity_from_the_Spatial_Structure_of_Neural_Network_Dynamics.html">127 nips-2010-Inferring Stimulus Selectivity from the Spatial Structure of Neural Network Dynamics</a></p>
<p>Author: Kanaka Rajan, L Abbott, Haim Sompolinsky</p><p>Abstract: How are the spatial patterns of spontaneous and evoked population responses related? We study the impact of connectivity on the spatial pattern of ﬂuctuations in the input-generated response, by comparing the distribution of evoked and intrinsically generated activity across the different units of a neural network. We develop a complementary approach to principal component analysis in which separate high-variance directions are derived for each input condition. We analyze subspace angles to compute the difference between the shapes of trajectories corresponding to different network states, and the orientation of the low-dimensional subspaces that driven trajectories occupy within the full space of neuronal activity. In addition to revealing how the spatiotemporal structure of spontaneous activity affects input-evoked responses, these methods can be used to infer input selectivity induced by network dynamics from experimentally accessible measures of spontaneous activity (e.g. from voltage- or calcium-sensitive optical imaging experiments). We conclude that the absence of a detailed spatial map of afferent inputs and cortical connectivity does not limit our ability to design spatially extended stimuli that evoke strong responses. 1 1 Motivation Stimulus selectivity in neural networks was historically measured directly from input-driven responses [1], and only later were similar selectivity patterns observed in spontaneous activity across the cortical surface [2, 3]. We argue that it is possible to work in the reverse order, and show that analyzing the distribution of spontaneous activity across the different units in the network can inform us about the selectivity of evoked responses to stimulus features, even when no apparent sensory map exists. Sensory-evoked responses are typically divided into a signal component generated by the stimulus and a noise component corresponding to ongoing activity that is not directly related to the stimulus. Subsequent effort focuses on understanding how the signal depends on properties of the stimulus, while the remaining, irregular part of the response is treated as additive noise. The distinction between external stochastic processes and the noise generated deterministically as a function of intrinsic recurrence has been previously studied in chaotic neural networks [4]. It has also been suggested that internally generated noise is not additive and can be more sensitive to the frequency and amplitude of the input, compared to the signal component of the response [5 - 8]. In this paper, we demonstrate that the interaction between deterministic intrinsic noise and the spatial properties of the external stimulus is also complex and nonlinear. We study the impact of network connectivity on the spatial pattern of input-driven responses by comparing the structure of evoked and spontaneous activity, and show how the unique signature of these dynamics determines the selectivity of networks to spatial features of the stimuli driving them. 2 Model description In this section, we describe the network model and the methods we use to analyze its dynamics. Subsequent sections explore how the spatial patterns of spontaneous and evoked responses are related in terms of the distribution of the activity across the network. Finally, we show how the stimulus selectivity of the network can be inferred from its spontaneous activity patterns. 2.1 Network elements We build a ﬁring rate model of N interconnected units characterized by a statistical description of the underlying circuitry (as N → ∞, the system “self averages” making the description independent of a speciﬁc network architecture, see also [11, 12]). Each unit is characterized by an activation variable xi ∀ i = 1, 2, . . . N , and a nonlinear response function ri which relates to xi through ri = R0 + φ(xi ) where,   R0 tanh x for x ≤ 0 R0 φ(x) = (1) x  (Rmax − R0 ) tanh otherwise. Rmax −R0 Eq. 1 allows us to independently set the maximum ﬁring rate Rmax and the background rate R0 to biologically reasonable values, while retaining a maximum gradient at x = 0 to guarantee the smoothness of the transition to chaos [4]. We introduce a recurrent weight matrix with element Jij equivalent to the strength of the synapse from unit j → unit i. The individual weights are chosen independently and randomly from a Gaus2 sian distribution with mean and variance given by [Jij ]J = 0 and Jij J = g 2 /N , where square brackets are ensemble averages [9 - 11,13]. The control parameter g which scales as the variance of the synaptic weights, is particularly important in determining whether or not the network produces spontaneous activity with non-trivial dynamics (Speciﬁcally, g = 0 corresponds to a completely uncoupled network and a network with g = 1 generates non-trivial spontaneous activity [4, 9, 10]). The activation variable for each unit xi is therefore determined by the relation, N τr dxi = −xi + g Jij rj + Ii , dt j=1 with the time scale of the network set by the single-neuron time constant τr of 10 ms. 2 (2) The amplitude I of an oscillatory external input of frequency f , is always the same for each unit, but in some examples shown in this paper, we introduce a neuron-speciﬁc phase factor θi , chosen randomly from a uniform distribution between 0 and 2π, such that Ii = I cos(2πf t + θi ) ∀ i = 1, 2, . . . N. (3) In visually responsive neurons, this mimics a population of simple cells driven by a drifting grating of temporal frequency f , with the different phases arising from offsets in spatial receptive ﬁeld locations. The randomly assigned phases in our model ensure that the spatial pattern of input is not correlated with the pattern of recurrent connectivity. In our selectivity analysis however (Fig. 3), we replace the random phases with spatial input patterns that are aligned with network connectivity. 2.2 PCA redux Principal component analysis (PCA) has been applied proﬁtably to neuronal recordings (see for example [14]) but these analyses often plot activity trajectories corresponding to different network states using the ﬁxed principal component coordinates derived from combined activities under all stimulus conditions. Our analysis offers a complementary approach whereby separate principal components are derived for each stimulus condition, and the resulting principal angles reveal not only the difference between the shapes of trajectories corresponding to different network states, but also the orientation of the low-dimensional subspaces these trajectories occupy within the full N -dimensional space of neuronal activity. The instantaneous network state can be described by a point in an N -dimensional space with coordinates equal to the ﬁring rates of the N units. Over time, the network activity traverses a trajectory in this N -dimensional space and PCA can be used to delineate the subspace in which this trajectory lies. The analysis is done by diagonalizing the equal-time cross-correlation matrix of network ﬁring rates given by, Dij = (ri (t) − ri )(rj (t) − rj ) , (4) where</p><p>6 0.10516623 <a title="238-tfidf-6" href="./nips-2010-The_LASSO_risk%3A_asymptotic_results_and_real_world_examples.html">265 nips-2010-The LASSO risk: asymptotic results and real world examples</a></p>
<p>7 0.099589743 <a title="238-tfidf-7" href="./nips-2010-Linear_readout_from_a_neural_population_with_partial_correlation_data.html">161 nips-2010-Linear readout from a neural population with partial correlation data</a></p>
<p>8 0.098402739 <a title="238-tfidf-8" href="./nips-2010-Fractionally_Predictive_Spiking_Neurons.html">96 nips-2010-Fractionally Predictive Spiking Neurons</a></p>
<p>9 0.085971005 <a title="238-tfidf-9" href="./nips-2010-Brain_covariance_selection%3A_better_individual_functional_connectivity_models_using_population_prior.html">44 nips-2010-Brain covariance selection: better individual functional connectivity models using population prior</a></p>
<p>10 0.081973322 <a title="238-tfidf-10" href="./nips-2010-Attractor_Dynamics_with_Synaptic_Depression.html">34 nips-2010-Attractor Dynamics with Synaptic Depression</a></p>
<p>11 0.077044562 <a title="238-tfidf-11" href="./nips-2010-Identifying_graph-structured_activation_patterns_in_networks.html">117 nips-2010-Identifying graph-structured activation patterns in networks</a></p>
<p>12 0.067210868 <a title="238-tfidf-12" href="./nips-2010-Online_Learning_in_The_Manifold_of_Low-Rank_Matrices.html">195 nips-2010-Online Learning in The Manifold of Low-Rank Matrices</a></p>
<p>13 0.066519454 <a title="238-tfidf-13" href="./nips-2010-Group_Sparse_Coding_with_a_Laplacian_Scale_Mixture_Prior.html">109 nips-2010-Group Sparse Coding with a Laplacian Scale Mixture Prior</a></p>
<p>14 0.062728196 <a title="238-tfidf-14" href="./nips-2010-Exact_learning_curves_for_Gaussian_process_regression_on_large_random_graphs.html">85 nips-2010-Exact learning curves for Gaussian process regression on large random graphs</a></p>
<p>15 0.062394165 <a title="238-tfidf-15" href="./nips-2010-Learning_Networks_of_Stochastic_Differential_Equations.html">148 nips-2010-Learning Networks of Stochastic Differential Equations</a></p>
<p>16 0.061087891 <a title="238-tfidf-16" href="./nips-2010-Gaussian_sampling_by_local_perturbations.html">101 nips-2010-Gaussian sampling by local perturbations</a></p>
<p>17 0.060220871 <a title="238-tfidf-17" href="./nips-2010-Fast_global_convergence_rates_of_gradient_methods_for_high-dimensional_statistical_recovery.html">92 nips-2010-Fast global convergence rates of gradient methods for high-dimensional statistical recovery</a></p>
<p>18 0.059411995 <a title="238-tfidf-18" href="./nips-2010-A_rational_decision_making_framework_for_inhibitory_control.html">19 nips-2010-A rational decision making framework for inhibitory control</a></p>
<p>19 0.059280384 <a title="238-tfidf-19" href="./nips-2010-Phoneme_Recognition_with_Large_Hierarchical_Reservoirs.html">207 nips-2010-Phoneme Recognition with Large Hierarchical Reservoirs</a></p>
<p>20 0.059215765 <a title="238-tfidf-20" href="./nips-2010-Link_Discovery_using_Graph_Feature_Tracking.html">162 nips-2010-Link Discovery using Graph Feature Tracking</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.165), (1, 0.03), (2, -0.105), (3, 0.164), (4, 0.048), (5, -0.023), (6, 0.003), (7, 0.015), (8, -0.103), (9, -0.022), (10, 0.038), (11, 0.021), (12, 0.057), (13, -0.005), (14, -0.065), (15, -0.053), (16, 0.01), (17, -0.044), (18, -0.054), (19, 0.152), (20, 0.067), (21, 0.037), (22, 0.075), (23, -0.001), (24, 0.054), (25, 0.02), (26, 0.047), (27, -0.007), (28, 0.086), (29, -0.143), (30, 0.066), (31, 0.128), (32, -0.074), (33, -0.005), (34, -0.041), (35, -0.025), (36, -0.109), (37, 0.143), (38, -0.115), (39, -0.006), (40, 0.031), (41, -0.005), (42, -0.154), (43, -0.025), (44, 0.028), (45, -0.124), (46, -0.145), (47, 0.165), (48, -0.108), (49, 0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97236103 <a title="238-lsi-1" href="./nips-2010-Short-term_memory_in_neuronal_networks_through_dynamical_compressed_sensing.html">238 nips-2010-Short-term memory in neuronal networks through dynamical compressed sensing</a></p>
<p>Author: Surya Ganguli, Haim Sompolinsky</p><p>Abstract: Recent proposals suggest that large, generic neuronal networks could store memory traces of past input sequences in their instantaneous state. Such a proposal raises important theoretical questions about the duration of these memory traces and their dependence on network size, connectivity and signal statistics. Prior work, in the case of gaussian input sequences and linear neuronal networks, shows that the duration of memory traces in a network cannot exceed the number of neurons (in units of the neuronal time constant), and that no network can out-perform an equivalent feedforward network. However a more ethologically relevant scenario is that of sparse input sequences. In this scenario, we show how linear neural networks can essentially perform compressed sensing (CS) of past inputs, thereby attaining a memory capacity that exceeds the number of neurons. This enhanced capacity is achieved by a class of “orthogonal” recurrent networks and not by feedforward networks or generic recurrent networks. We exploit techniques from the statistical physics of disordered systems to analytically compute the decay of memory traces in such networks as a function of network size, signal sparsity and integration time. Alternately, viewed purely from the perspective of CS, this work introduces a new ensemble of measurement matrices derived from dynamical systems, and provides a theoretical analysis of their asymptotic performance. 1</p><p>2 0.71798259 <a title="238-lsi-2" href="./nips-2010-Deciphering_subsampled_data%3A_adaptive_compressive_sampling_as_a_principle_of_brain_communication.html">56 nips-2010-Deciphering subsampled data: adaptive compressive sampling as a principle of brain communication</a></p>
<p>Author: Guy Isely, Christopher Hillar, Fritz Sommer</p><p>Abstract: A new algorithm is proposed for a) unsupervised learning of sparse representations from subsampled measurements and b) estimating the parameters required for linearly reconstructing signals from the sparse codes. We verify that the new algorithm performs efﬁcient data compression on par with the recent method of compressive sampling. Further, we demonstrate that the algorithm performs robustly when stacked in several stages or when applied in undercomplete or overcomplete situations. The new algorithm can explain how neural populations in the brain that receive subsampled input through ﬁber bottlenecks are able to form coherent response properties. 1</p><p>3 0.6152218 <a title="238-lsi-3" href="./nips-2010-Over-complete_representations_on_recurrent_neural_networks_can_support_persistent_percepts.html">200 nips-2010-Over-complete representations on recurrent neural networks can support persistent percepts</a></p>
<p>Author: Shaul Druckmann, Dmitri B. Chklovskii</p><p>Abstract: A striking aspect of cortical neural networks is the divergence of a relatively small number of input channels from the peripheral sensory apparatus into a large number of cortical neurons, an over-complete representation strategy. Cortical neurons are then connected by a sparse network of lateral synapses. Here we propose that such architecture may increase the persistence of the representation of an incoming stimulus, or a percept. We demonstrate that for a family of networks in which the receptive ﬁeld of each neuron is re-expressed by its outgoing connections, a represented percept can remain constant despite changing activity. We term this choice of connectivity REceptive FIeld REcombination (REFIRE) networks. The sparse REFIRE network may serve as a high-dimensional integrator and a biologically plausible model of the local cortical circuit. 1</p><p>4 0.57541192 <a title="238-lsi-4" href="./nips-2010-Attractor_Dynamics_with_Synaptic_Depression.html">34 nips-2010-Attractor Dynamics with Synaptic Depression</a></p>
<p>Author: K. Wong, He Wang, Si Wu, Chi Fung</p><p>Abstract: Neuronal connection weights exhibit short-term depression (STD). The present study investigates the impact of STD on the dynamics of a continuous attractor neural network (CANN) and its potential roles in neural information processing. We ﬁnd that the network with STD can generate both static and traveling bumps, and STD enhances the performance of the network in tracking external inputs. In particular, we ﬁnd that STD endows the network with slow-decaying plateau behaviors, namely, the network being initially stimulated to an active state will decay to silence very slowly in the time scale of STD rather than that of neural signaling. We argue that this provides a mechanism for neural systems to hold short-term memory easily and shut off persistent activities naturally.</p><p>5 0.55525053 <a title="238-lsi-5" href="./nips-2010-Distributionally_Robust_Markov_Decision_Processes.html">64 nips-2010-Distributionally Robust Markov Decision Processes</a></p>
<p>Author: Huan Xu, Shie Mannor</p><p>Abstract: We consider Markov decision processes where the values of the parameters are uncertain. This uncertainty is described by a sequence of nested sets (that is, each set contains the previous one), each of which corresponds to a probabilistic guarantee for a different conﬁdence level so that a set of admissible probability distributions of the unknown parameters is speciﬁed. This formulation models the case where the decision maker is aware of and wants to exploit some (yet imprecise) a-priori information of the distribution of parameters, and arises naturally in practice where methods to estimate the conﬁdence region of parameters abound. We propose a decision criterion based on distributional robustness: the optimal policy maximizes the expected total reward under the most adversarial probability distribution over realizations of the uncertain parameters that is admissible (i.e., it agrees with the a-priori information). We show that ﬁnding the optimal distributionally robust policy can be reduced to a standard robust MDP where the parameters belong to a single uncertainty set, hence it can be computed in polynomial time under mild technical conditions.</p><p>6 0.53857732 <a title="238-lsi-6" href="./nips-2010-Inferring_Stimulus_Selectivity_from_the_Spatial_Structure_of_Neural_Network_Dynamics.html">127 nips-2010-Inferring Stimulus Selectivity from the Spatial Structure of Neural Network Dynamics</a></p>
<p>7 0.4826543 <a title="238-lsi-7" href="./nips-2010-Linear_readout_from_a_neural_population_with_partial_correlation_data.html">161 nips-2010-Linear readout from a neural population with partial correlation data</a></p>
<p>8 0.4469879 <a title="238-lsi-8" href="./nips-2010-A_rational_decision_making_framework_for_inhibitory_control.html">19 nips-2010-A rational decision making framework for inhibitory control</a></p>
<p>9 0.44325989 <a title="238-lsi-9" href="./nips-2010-The_LASSO_risk%3A_asymptotic_results_and_real_world_examples.html">265 nips-2010-The LASSO risk: asymptotic results and real world examples</a></p>
<p>10 0.42522907 <a title="238-lsi-10" href="./nips-2010-Effects_of_Synaptic_Weight_Diffusion_on_Learning_in_Decision_Making_Networks.html">68 nips-2010-Effects of Synaptic Weight Diffusion on Learning in Decision Making Networks</a></p>
<p>11 0.42450434 <a title="238-lsi-11" href="./nips-2010-Hallucinations_in_Charles_Bonnet_Syndrome_Induced_by_Homeostasis%3A_a_Deep_Boltzmann_Machine_Model.html">111 nips-2010-Hallucinations in Charles Bonnet Syndrome Induced by Homeostasis: a Deep Boltzmann Machine Model</a></p>
<p>12 0.42277941 <a title="238-lsi-12" href="./nips-2010-Improving_the_Asymptotic_Performance_of_Markov_Chain_Monte-Carlo_by_Inserting_Vortices.html">122 nips-2010-Improving the Asymptotic Performance of Markov Chain Monte-Carlo by Inserting Vortices</a></p>
<p>13 0.41822028 <a title="238-lsi-13" href="./nips-2010-b-Bit_Minwise_Hashing_for_Estimating_Three-Way_Similarities.html">289 nips-2010-b-Bit Minwise Hashing for Estimating Three-Way Similarities</a></p>
<p>14 0.41274217 <a title="238-lsi-14" href="./nips-2010-Fractionally_Predictive_Spiking_Neurons.html">96 nips-2010-Fractionally Predictive Spiking Neurons</a></p>
<p>15 0.40549722 <a title="238-lsi-15" href="./nips-2010-Identifying_graph-structured_activation_patterns_in_networks.html">117 nips-2010-Identifying graph-structured activation patterns in networks</a></p>
<p>16 0.39031693 <a title="238-lsi-16" href="./nips-2010-Learning_Networks_of_Stochastic_Differential_Equations.html">148 nips-2010-Learning Networks of Stochastic Differential Equations</a></p>
<p>17 0.38688767 <a title="238-lsi-17" href="./nips-2010-Improvements_to_the_Sequence_Memoizer.html">120 nips-2010-Improvements to the Sequence Memoizer</a></p>
<p>18 0.35492417 <a title="238-lsi-18" href="./nips-2010-On_the_Convexity_of_Latent_Social_Network_Inference.html">190 nips-2010-On the Convexity of Latent Social Network Inference</a></p>
<p>19 0.34459531 <a title="238-lsi-19" href="./nips-2010-Robust_PCA_via_Outlier_Pursuit.html">231 nips-2010-Robust PCA via Outlier Pursuit</a></p>
<p>20 0.34238136 <a title="238-lsi-20" href="./nips-2010-Phoneme_Recognition_with_Large_Hierarchical_Reservoirs.html">207 nips-2010-Phoneme Recognition with Large Hierarchical Reservoirs</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.064), (17, 0.018), (23, 0.027), (27, 0.093), (30, 0.054), (35, 0.015), (45, 0.158), (50, 0.08), (52, 0.049), (60, 0.034), (66, 0.115), (69, 0.022), (77, 0.106), (78, 0.013), (90, 0.059)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.90874708 <a title="238-lda-1" href="./nips-2010-Short-term_memory_in_neuronal_networks_through_dynamical_compressed_sensing.html">238 nips-2010-Short-term memory in neuronal networks through dynamical compressed sensing</a></p>
<p>Author: Surya Ganguli, Haim Sompolinsky</p><p>Abstract: Recent proposals suggest that large, generic neuronal networks could store memory traces of past input sequences in their instantaneous state. Such a proposal raises important theoretical questions about the duration of these memory traces and their dependence on network size, connectivity and signal statistics. Prior work, in the case of gaussian input sequences and linear neuronal networks, shows that the duration of memory traces in a network cannot exceed the number of neurons (in units of the neuronal time constant), and that no network can out-perform an equivalent feedforward network. However a more ethologically relevant scenario is that of sparse input sequences. In this scenario, we show how linear neural networks can essentially perform compressed sensing (CS) of past inputs, thereby attaining a memory capacity that exceeds the number of neurons. This enhanced capacity is achieved by a class of “orthogonal” recurrent networks and not by feedforward networks or generic recurrent networks. We exploit techniques from the statistical physics of disordered systems to analytically compute the decay of memory traces in such networks as a function of network size, signal sparsity and integration time. Alternately, viewed purely from the perspective of CS, this work introduces a new ensemble of measurement matrices derived from dynamical systems, and provides a theoretical analysis of their asymptotic performance. 1</p><p>2 0.84845781 <a title="238-lda-2" href="./nips-2010-Unsupervised_Kernel_Dimension_Reduction.html">280 nips-2010-Unsupervised Kernel Dimension Reduction</a></p>
<p>Author: Meihong Wang, Fei Sha, Michael I. Jordan</p><p>Abstract: We apply the framework of kernel dimension reduction, originally designed for supervised problems, to unsupervised dimensionality reduction. In this framework, kernel-based measures of independence are used to derive low-dimensional representations that maximally capture information in covariates in order to predict responses. We extend this idea and develop similarly motivated measures for unsupervised problems where covariates and responses are the same. Our empirical studies show that the resulting compact representation yields meaningful and appealing visualization and clustering of data. Furthermore, when used in conjunction with supervised learners for classiﬁcation, our methods lead to lower classiﬁcation errors than state-of-the-art methods, especially when embedding data in spaces of very few dimensions.</p><p>3 0.84357554 <a title="238-lda-3" href="./nips-2010-Identifying_graph-structured_activation_patterns_in_networks.html">117 nips-2010-Identifying graph-structured activation patterns in networks</a></p>
<p>Author: James Sharpnack, Aarti Singh</p><p>Abstract: We consider the problem of identifying an activation pattern in a complex, largescale network that is embedded in very noisy measurements. This problem is relevant to several applications, such as identifying traces of a biochemical spread by a sensor network, expression levels of genes, and anomalous activity or congestion in the Internet. Extracting such patterns is a challenging task specially if the network is large (pattern is very high-dimensional) and the noise is so excessive that it masks the activity at any single node. However, typically there are statistical dependencies in the network activation process that can be leveraged to fuse the measurements of multiple nodes and enable reliable extraction of highdimensional noisy patterns. In this paper, we analyze an estimator based on the graph Laplacian eigenbasis, and establish the limits of mean square error recovery of noisy patterns arising from a probabilistic (Gaussian or Ising) model based on an arbitrary graph structure. We consider both deterministic and probabilistic network evolution models, and our results indicate that by leveraging the network interaction structure, it is possible to consistently recover high-dimensional patterns even when the noise variance increases with network size. 1</p><p>4 0.83290619 <a title="238-lda-4" href="./nips-2010-Variable_margin_losses_for_classifier_design.html">282 nips-2010-Variable margin losses for classifier design</a></p>
<p>Author: Hamed Masnadi-shirazi, Nuno Vasconcelos</p><p>Abstract: The problem of controlling the margin of a classiﬁer is studied. A detailed analytical study is presented on how properties of the classiﬁcation risk, such as its optimal link and minimum risk functions, are related to the shape of the loss, and its margin enforcing properties. It is shown that for a class of risks, denoted canonical risks, asymptotic Bayes consistency is compatible with simple analytical relationships between these functions. These enable a precise characterization of the loss for a popular class of link functions. It is shown that, when the risk is in canonical form and the link is inverse sigmoidal, the margin properties of the loss are determined by a single parameter. Novel families of Bayes consistent loss functions, of variable margin, are derived. These families are then used to design boosting style algorithms with explicit control of the classiﬁcation margin. The new algorithms generalize well established approaches, such as LogitBoost. Experimental results show that the proposed variable margin losses outperform the ﬁxed margin counterparts used by existing algorithms. Finally, it is shown that best performance can be achieved by cross-validating the margin parameter. 1</p><p>5 0.83158559 <a title="238-lda-5" href="./nips-2010-Over-complete_representations_on_recurrent_neural_networks_can_support_persistent_percepts.html">200 nips-2010-Over-complete representations on recurrent neural networks can support persistent percepts</a></p>
<p>Author: Shaul Druckmann, Dmitri B. Chklovskii</p><p>Abstract: A striking aspect of cortical neural networks is the divergence of a relatively small number of input channels from the peripheral sensory apparatus into a large number of cortical neurons, an over-complete representation strategy. Cortical neurons are then connected by a sparse network of lateral synapses. Here we propose that such architecture may increase the persistence of the representation of an incoming stimulus, or a percept. We demonstrate that for a family of networks in which the receptive ﬁeld of each neuron is re-expressed by its outgoing connections, a represented percept can remain constant despite changing activity. We term this choice of connectivity REceptive FIeld REcombination (REFIRE) networks. The sparse REFIRE network may serve as a high-dimensional integrator and a biologically plausible model of the local cortical circuit. 1</p><p>6 0.83124214 <a title="238-lda-6" href="./nips-2010-Inferring_Stimulus_Selectivity_from_the_Spatial_Structure_of_Neural_Network_Dynamics.html">127 nips-2010-Inferring Stimulus Selectivity from the Spatial Structure of Neural Network Dynamics</a></p>
<p>7 0.82412505 <a title="238-lda-7" href="./nips-2010-Accounting_for_network_effects_in_neuronal_responses_using_L1_regularized_point_process_models.html">21 nips-2010-Accounting for network effects in neuronal responses using L1 regularized point process models</a></p>
<p>8 0.82300204 <a title="238-lda-8" href="./nips-2010-Construction_of_Dependent_Dirichlet_Processes_based_on_Poisson_Processes.html">51 nips-2010-Construction of Dependent Dirichlet Processes based on Poisson Processes</a></p>
<p>9 0.82210582 <a title="238-lda-9" href="./nips-2010-Effects_of_Synaptic_Weight_Diffusion_on_Learning_in_Decision_Making_Networks.html">68 nips-2010-Effects of Synaptic Weight Diffusion on Learning in Decision Making Networks</a></p>
<p>10 0.82165551 <a title="238-lda-10" href="./nips-2010-A_Novel_Kernel_for_Learning_a_Neuron_Model_from_Spike_Train_Data.html">10 nips-2010-A Novel Kernel for Learning a Neuron Model from Spike Train Data</a></p>
<p>11 0.81985325 <a title="238-lda-11" href="./nips-2010-The_LASSO_risk%3A_asymptotic_results_and_real_world_examples.html">265 nips-2010-The LASSO risk: asymptotic results and real world examples</a></p>
<p>12 0.81603098 <a title="238-lda-12" href="./nips-2010-A_Theory_of_Multiclass_Boosting.html">15 nips-2010-A Theory of Multiclass Boosting</a></p>
<p>13 0.8158201 <a title="238-lda-13" href="./nips-2010-Fractionally_Predictive_Spiking_Neurons.html">96 nips-2010-Fractionally Predictive Spiking Neurons</a></p>
<p>14 0.81554008 <a title="238-lda-14" href="./nips-2010-Linear_readout_from_a_neural_population_with_partial_correlation_data.html">161 nips-2010-Linear readout from a neural population with partial correlation data</a></p>
<p>15 0.80735886 <a title="238-lda-15" href="./nips-2010-A_biologically_plausible_network_for_the_computation_of_orientation_dominance.html">17 nips-2010-A biologically plausible network for the computation of orientation dominance</a></p>
<p>16 0.80690253 <a title="238-lda-16" href="./nips-2010-Group_Sparse_Coding_with_a_Laplacian_Scale_Mixture_Prior.html">109 nips-2010-Group Sparse Coding with a Laplacian Scale Mixture Prior</a></p>
<p>17 0.80509812 <a title="238-lda-17" href="./nips-2010-Functional_form_of_motion_priors_in_human_motion_perception.html">98 nips-2010-Functional form of motion priors in human motion perception</a></p>
<p>18 0.8038094 <a title="238-lda-18" href="./nips-2010-An_Inverse_Power_Method_for_Nonlinear_Eigenproblems_with_Applications_in_1-Spectral_Clustering_and_Sparse_PCA.html">30 nips-2010-An Inverse Power Method for Nonlinear Eigenproblems with Applications in 1-Spectral Clustering and Sparse PCA</a></p>
<p>19 0.80372602 <a title="238-lda-19" href="./nips-2010-Deciphering_subsampled_data%3A_adaptive_compressive_sampling_as_a_principle_of_brain_communication.html">56 nips-2010-Deciphering subsampled data: adaptive compressive sampling as a principle of brain communication</a></p>
<p>20 0.8036741 <a title="238-lda-20" href="./nips-2010-Learning_the_context_of_a_category.html">155 nips-2010-Learning the context of a category</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
