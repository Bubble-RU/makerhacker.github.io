<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>24 nips-2010-Active Learning Applied to Patient-Adaptive Heartbeat Classification</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-24" href="#">nips2010-24</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>24 nips-2010-Active Learning Applied to Patient-Adaptive Heartbeat Classification</h1>
<br/><p>Source: <a title="nips-2010-24-pdf" href="http://papers.nips.cc/paper/4091-active-learning-applied-to-patient-adaptive-heartbeat-classification.pdf">pdf</a></p><p>Author: Jenna Wiens, John V. Guttag</p><p>Abstract: While clinicians can accurately identify different types of heartbeats in electrocardiograms (ECGs) from different patients, researchers have had limited success in applying supervised machine learning to the same task. The problem is made challenging by the variety of tasks, inter- and intra-patient differences, an often severe class imbalance, and the high cost of getting cardiologists to label data for individual patients. We address these difﬁculties using active learning to perform patient-adaptive and task-adaptive heartbeat classiﬁcation. When tested on a benchmark database of cardiologist annotated ECG recordings, our method had considerably better performance than other recently proposed methods on the two primary classiﬁcation tasks recommended by the Association for the Advancement of Medical Instrumentation. Additionally, our method required over 90% less patient-speciﬁc training data than the methods to which we compared it. 1</p><p>Reference: <a title="nips-2010-24-reference" href="../nips2010_reference/nips-2010-Active_Learning_Applied_to_Patient-Adaptive_Heartbeat_Classification_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract While clinicians can accurately identify different types of heartbeats in electrocardiograms (ECGs) from different patients, researchers have had limited success in applying supervised machine learning to the same task. [sent-6, score-0.163]
</p><p>2 We address these difﬁculties using active learning to perform patient-adaptive and task-adaptive heartbeat classiﬁcation. [sent-8, score-0.479]
</p><p>3 When tested on a benchmark database of cardiologist annotated ECG recordings, our method had considerably better performance than other recently proposed methods on the two primary classiﬁcation tasks recommended by the Association for the Advancement of Medical Instrumentation. [sent-9, score-0.162]
</p><p>4 1  Introduction  In 24 hours an electrocardiogram (ECG) can record over 100,000 heartbeats for a single patient. [sent-11, score-0.168]
</p><p>5 Automated analysis of long-term ECG recordings can help physicians understand a patient’s physiological state and his/her risk for adverse cardiovascular outcomes [1] [2]. [sent-13, score-0.148]
</p><p>6 Trained clinicians can successfully identify over a dozen different types of heartbeats in ECG recordings. [sent-16, score-0.163]
</p><p>7 The problem is made challenging by the inter-patient differences present in the morphology and timing characteristics of the ECGs produced by compromised cardiovascular systems. [sent-18, score-0.203]
</p><p>8 The variation in the physiological systems that produce the data means that a classiﬁer trained on even a large set of patients will yield unpredictable results when applied to a new cardiac patient. [sent-19, score-0.182]
</p><p>9 Hu et al was one of the ﬁrst to describe an automatic patient-adaptive ECG beat classiﬁer [4]. [sent-21, score-0.315]
</p><p>10 Similarly, de Chazal et al augmented the performance of a global heartbeat classiﬁer by including patient-speciﬁc expert knowledge for each test patient. [sent-24, score-0.603]
</p><p>11 Their local classiﬁer was trained on the ﬁrst 500 labeled beats of each record [3]. [sent-25, score-0.568]
</p><p>12 More recently, Ince et al developed a patient-adaptive classiﬁcation scheme using artiﬁcial neural networks by incorporating the ﬁrst 5 minutes of each test recording in the training set [5] . [sent-26, score-0.126]
</p><p>13 There has been some success with hand-coded rule-based algorithms for heartbeat classiﬁcation. [sent-31, score-0.391]
</p><p>14 Hamilton et al developed a rule-based algorithm for detecting one type of particularly dangerous ectopic heartbeat, the premature ventricular contraction (PVC) [6]. [sent-32, score-0.508]
</p><p>15 In this paper, we show how active learning can be successfully applied to the problems of both patient-adaptive and task-adaptive heartbeat classiﬁcation. [sent-36, score-0.479]
</p><p>16 We developed our method with a clinical setting in mind: initially it requires no labeled data, it has no user-speciﬁed parameters, and achieves good performance on an imbalanced data set. [sent-37, score-0.168]
</p><p>17 Applied to data from the MIT-BIH Arrhythmia Database our method outperforms current state-of-the-art machine learning heartbeat classiﬁcation techniques and uses less training data. [sent-38, score-0.391]
</p><p>18 Since we will consider different heartbeat classiﬁcation tasks we ﬁrst present a few examples of heartbeat classes and ECG abnormalities. [sent-42, score-0.811]
</p><p>19 1  The ECG and ECG Abnormalities  An ECG records a patient’s cardiac electrical activity by measuring the potential differences at the surface of the patient’s body. [sent-44, score-0.216]
</p><p>20 Figure 1(a) shows an example of the ECG of a normal sinus rhythm beat (N). [sent-46, score-0.336]
</p><p>21 The exact morphology and timing of the different portions of the wave depend on the patient and lead placement. [sent-47, score-0.236]
</p><p>22 5  3  (c)  Figure 1: Normal sinus rhythm beats like the ones shown in (a) originate from the pacemaker cells of the sinoatrial node. [sent-83, score-0.65]
</p><p>23 Premature ventricular contractions (b) and atrial premature beats (c) are two examples of ectopic beats. [sent-84, score-0.782]
</p><p>24 Cardiac abnormalities can disrupt the heart’s normal sinus rhythm, and, depending on their type and frequency, can vary from benign to life threatening. [sent-85, score-0.12]
</p><p>25 Examples of ectopic beats (beats that do not originate in the sinoatrial node) are shown in Figures 1(b) and 1(c). [sent-86, score-0.568]
</p><p>26 Premature ventricular contractions (PVCs), originate in the ventricles instead of in the pacemaker cells of the sinoatrial node. [sent-87, score-0.26]
</p><p>27 They are common in patients who have suffered an acute myocardial infarction [7] and may indicate that a patient is at increased risk for more serious ventricular arrhythmias and sudden cardiac death [8]. [sent-88, score-0.495]
</p><p>28 When the electrical impulse originates from the atria, an atrial premature beat is recorded by the ECG as shown in Figure 1(c). [sent-89, score-0.336]
</p><p>29 Atrial premature beats tend not to be life threatening. [sent-90, score-0.488]
</p><p>30 2  Because of their speciﬁc timing and morphology characteristics these two types of abnormal beats are generally distinguishable by trained cardiologists, but there are many exceptions. [sent-91, score-0.577]
</p><p>31 Not only can abnormalities vary from patient to patient, but the same recording may contain beats that belong to the same class but all look quite different. [sent-92, score-0.577]
</p><p>32 Figure 2: Each PVC is marked by a “V” and each normal sinus rhythm beat is marked by a “·”. [sent-94, score-0.336]
</p><p>33 The PVC morphology varies greatly among patients and even within recordings from a single patient. [sent-95, score-0.25]
</p><p>34 3  Methods  In this section we describe the two main components of our heartbeat classiﬁcation scheme. [sent-96, score-0.391]
</p><p>35 We used PhysioNet’s automated R-peak detector to detect the R-peaks of each heartbeat [9]. [sent-100, score-0.426]
</p><p>36 Once pre-processed, the data was segmented into individual heartbeats based on ﬁxed intervals before and after the R-peak, so that each beat contained the same number of samples. [sent-102, score-0.303]
</p><p>37 Our goal was to develop a feature vector that worked well not only across patients but also across different heartbeat classiﬁcation tasks. [sent-103, score-0.493]
</p><p>38 2  Classiﬁcation  Our goal was to develop a clinically useful patient-adaptive heartbeat classiﬁcation method for solving different binary heartbeat classiﬁcation problems. [sent-113, score-0.782]
</p><p>39 Cluster the data using hierarchical clustering with two different linkage criteria, yielding <= 2 ∗ k clusters. [sent-121, score-0.13]
</p><p>40 If the expert labeled all the points as belonging to the same class, stop, else k = 1. [sent-126, score-0.149]
</p><p>41 Many proposed techniques for SVM active learning assume one starts with some set of labeled data or, as in [13], the initial training examples are randomly selected. [sent-139, score-0.181]
</p><p>42 , some multi-thousand beat recordings contain less than a handful of PVCs), choosing a small or even moderate number of random samples is unlikely to be an effective approach to ﬁnding representative samples of a record. [sent-143, score-0.28]
</p><p>43 If beats from only one class are queried the algorithm could stop prematurely. [sent-145, score-0.39]
</p><p>44 More generally, the selection of the ﬁrst set of queries is independent of the binary task, and therefore the ﬁrst query should contain at least one example from each of the beat classes contained in the record. [sent-146, score-0.249]
</p><p>45 We believe this can be attributed to the fact that hierarchical clustering has the ability to produce a variety of different clusters by modifying the linkage criterion. [sent-150, score-0.177]
</p><p>46 This linkage is biased toward producing clusters with similar variances, and has the tendency to merge clusters with small variances. [sent-154, score-0.184]
</p><p>47 The second linkage criterion is Ward’s linkage [17], deﬁned in Equation 1. [sent-155, score-0.18]
</p><p>48 If presented with an outlier, Ward’s method tends to assign it to the cluster with the closest centroid, whereas the average linkage tends to assign it to the densest cluster, where it will have the smallest impact on the maximum variance [18]. [sent-158, score-0.129]
</p><p>49 We use linear SVMs because most heartbeat classiﬁcation tasks are close to linearly separable and because linear SVMs require few tuning parameters. [sent-160, score-0.42]
</p><p>50 We then query a beat from each cluster that is closest to the SVM decision boundary. [sent-162, score-0.259]
</p><p>51 , those with fusion beats - a fusion of normal and abnormal beats 4  - many beats can lie within the margin of the SVM and thus a clinician might end up labeling hundreds of beats that add little useful information. [sent-166, score-1.632]
</p><p>52 Typical ECG recordings contain beats from 2 to 5 classes but can contain more; based on this a priori knowledge, we conservatively set k = 10. [sent-173, score-0.51]
</p><p>53 To test the utility of our proposed approach for heartbeat classiﬁcation we ran a series of experiments on data from different patients, and for different classiﬁcation tasks. [sent-175, score-0.391]
</p><p>54 Next, we directly measure the impact active learning has on the classiﬁcation of heartbeats by creating our own passive learning classiﬁer using the same pre-processing and features as our proposed active learning method. [sent-177, score-0.365]
</p><p>55 We use this measure since the problem of heartbeat classiﬁcation suffers from severe class imbalance, and thus the SE (aka recall) and the PPV (aka precision) are more important than SP. [sent-181, score-0.426]
</p><p>56 The remaining 25 records, labeled 200 to 234 were selected because they contain rare clinical activity that might not have been represented had all 48 records been chosen at random. [sent-185, score-0.364]
</p><p>57 Each beat is labeled as belonging to one of 16 different classes. [sent-187, score-0.282]
</p><p>58 We consider the two main classiﬁcation tasks proposed by the Association for the Advancement of Medical Instrumentation (AAMI): detecting ventricular ectopic beats (VEBs), and detecting supraventricular ectopic beats (SVEBs). [sent-191, score-1.23]
</p><p>59 These two tasks have been the focus of other researchers investigating patient-adaptive heartbeat classiﬁcation. [sent-192, score-0.42]
</p><p>60 Recently, Ince et al [5] and de Chazal et al [3] described methods that combine global information with patient-speciﬁc information. [sent-193, score-0.282]
</p><p>61 Ince et al trained a global classiﬁer on 245 hand chosen beats from the MITDB, and then adapted the global classiﬁer by training on labeled data from the ﬁrst ﬁve minutes of each test record. [sent-194, score-0.7]
</p><p>62 Their reported results of testing on 44 of the 48 records - all records with paced beats were excluded - from the MITDB are reported in Table 2. [sent-195, score-0.757]
</p><p>63 De Chazal et al trained their global classiﬁer on all of the data from 22 patients in the MITDB, and then adapted the global classiﬁer by training on labeled data for the ﬁrst 500 beats of each test record. [sent-196, score-0.802]
</p><p>64 Their reported results of testing on 22 records -different from the ones used in the global training set- from the MITDB are also reported in Table 2. [sent-197, score-0.197]
</p><p>65 For the same two classiﬁcation tasks we tested our proposed approach and we report the results when tested on the records reported on in [5] and [3]. [sent-198, score-0.196]
</p><p>66 In these experiments we exclude the queried 5  beats from the test set, testing only on data the expert hasn’t seen. [sent-199, score-0.446]
</p><p>67 Since we query far fewer beats that the other methods, we end up testing on many more beats. [sent-201, score-0.421]
</p><p>68 VEB  SVEB  SP  PPV  F-Score  Sens  Spec  PPV  F-Score  Ince et al 84. [sent-203, score-0.126]
</p><p>69 9% Proposed2 1 for the 44 records in common 2 for the 22 records in common  87. [sent-211, score-0.334]
</p><p>70 non-VEBs, our method on average used 45 labeled beats (compared to roughly 350 beats for [5] and 500 beats for [3]) per record. [sent-237, score-1.263]
</p><p>71 For the task of detecting SVEBs, our method used even fewer labeled beats. [sent-238, score-0.132]
</p><p>72 Recognizing SVEBs is considerably more difﬁcult than detecting VEBs since the class imbalance problem is even more severe and supra-ventricular beats are harder to distinguish from normal sinus rhythm beats. [sent-239, score-0.664]
</p><p>73 1%  Classiﬁer  Hamilton et al proposed a rule-based classiﬁer for classifying PVCs vs. [sent-249, score-0.126]
</p><p>74 Their method does particularly poorly on the four records containing paced beats. [sent-254, score-0.2]
</p><p>75 Omitting these four records the F-Score increases to 91. [sent-255, score-0.167]
</p><p>76 One advantage of the rule-based algorithm is that it does not require a labeled training set, whereas on average we require 45 labeled beats per record. [sent-257, score-0.576]
</p><p>77 For each of the 48 records in the MITDB we compare a VEB vs. [sent-266, score-0.167]
</p><p>78 non-VEB classiﬁer using our approach, to a linear SVM classiﬁer trained on the ﬁrst 500 beats of each record. [sent-267, score-0.421]
</p><p>79 For each patient we record the number of queries made, as well as the performance of each classiﬁer. [sent-268, score-0.173]
</p><p>80 The column headed “#Q” gives the number of beats used for training each classiﬁer, while the column headed “TP” for true positives, gives the number of correctly labeled VEBs. [sent-270, score-0.549]
</p><p>81 The last row gives the totals across all records for each classiﬁcation method. [sent-271, score-0.2]
</p><p>82 Compared to the passive approach, active learning used over 90% less training data, and resulted in over 85% fewer misclassiﬁed heartbeats. [sent-273, score-0.163]
</p><p>83 These results emphasize that fact that active learning can be used to dramatically reduce the labor cost of producing highly accurate classiﬁers. [sent-274, score-0.154]
</p><p>84 3  TP  2148  7169  102573  47  66  24000  6540  102427  193  695  Experiments with Clinicians  To get a sense of the feasibility of using our approach in an actual clinical setting, we ran an experiment with two cardiologists and data from another cohort of patients admitted with NSTEACS. [sent-280, score-0.249]
</p><p>85 We considered 4 randomly chosen records, from a subset of patients who had experienced at least one episode of ventricular tachycardia in the 7 day period following randomization. [sent-285, score-0.249]
</p><p>86 As our algorithm chose beats to be labeled, each cardiologist was presented with an ECG plot of the heartbeat to be labeled and the beats surrounding it, like the one shown in Figure 3. [sent-288, score-1.362]
</p><p>87 Because the cardiologists made different choices about how some beats should be labeled, one was asked to label an average of 15 beats/record and the other roughly 20 beats/record. [sent-290, score-0.462]
</p><p>88 Since the records had not been previously labeled (and it seemed unreasonable to ask our experts to label all of them), we used the PVC classiﬁcation software from [6] to provide a label to which 7  1. [sent-292, score-0.26]
</p><p>89 4  Time (s)  Figure 3: The classiﬁers trained using active learning both labeled the delineated beat delineated as a PVC, whereas the rule-based algorithm labeled it as a non-PVC. [sent-304, score-0.56]
</p><p>90 Table 5: Comparison of active earning using two different experts and Hamilton et al. [sent-305, score-0.12]
</p><p>91 All Records (8230 beats total) Classiﬁer Size Training Data TP TN Expert #1 60 191 8038 Expert #2 83 192 8035 0 190 8035 Hamilton et al  FP 0 3 3  FN 1 0 2  we could compare the labels generated by our method. [sent-307, score-0.516]
</p><p>92 When all three classiﬁers agreed, we assumed that the beat was correctly classiﬁed. [sent-309, score-0.189]
</p><p>93 The problem is made challenging by the intra- and inter-patient differences present in the morphology and timing characteristics of the ECG produced by compromised cardiovascular systems and by the variability in the classiﬁcation tasks that a clinician might want to perform. [sent-313, score-0.265]
</p><p>94 We propose to address these difﬁculties with a method for using active learning to perform patient-adaptive and task-adaptive heartbeat classiﬁcation. [sent-314, score-0.479]
</p><p>95 When tested on the most widely used benchmark database of cardiologist annotated ECG recordings, our method had better performance than other recently proposed methods on the two primary classiﬁcation tasks recommended by AAMI. [sent-315, score-0.162]
</p><p>96 Both cardiologists were able to use our tool with minimal training, and achieved excellent classiﬁcation results with a small amount of labor per record. [sent-319, score-0.138]
</p><p>97 These preliminary results are highly encouraging, and suggest that active learning can be used practically in a clinical setting to not only reduce the labor cost but also garner additional improvements in performance. [sent-320, score-0.229]
</p><p>98 It may also be possible to further reduce the amount of required expert labor by starting with a global classiﬁer and then adapting it using active learning. [sent-325, score-0.24]
</p><p>99 A generic and robust system for automated patient-speciﬁc classiﬁcation of ecg signals. [sent-369, score-0.493]
</p><p>100 Prognostic value of heart rate variability and ventricular arrhythmias during 13-year follow up in patients with mild to moderate heart failure. [sent-386, score-0.368]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ecg', 0.458), ('heartbeat', 0.391), ('beats', 0.39), ('beat', 0.189), ('records', 0.167), ('ventricular', 0.147), ('classi', 0.138), ('mitdb', 0.13), ('patient', 0.119), ('heartbeats', 0.114), ('patients', 0.102), ('cardiologist', 0.098), ('chazal', 0.098), ('ectopic', 0.098), ('premature', 0.098), ('pvc', 0.098), ('al', 0.094), ('labeled', 0.093), ('linkage', 0.09), ('er', 0.088), ('active', 0.088), ('morphology', 0.086), ('ppv', 0.081), ('sinus', 0.081), ('passive', 0.075), ('clinical', 0.075), ('cardiologists', 0.072), ('ince', 0.072), ('ss', 0.067), ('labor', 0.066), ('rhythm', 0.066), ('vebs', 0.065), ('recordings', 0.062), ('hamilton', 0.062), ('se', 0.058), ('cardiovascular', 0.057), ('expert', 0.056), ('record', 0.054), ('svm', 0.054), ('imbalance', 0.053), ('rr', 0.052), ('cardiac', 0.049), ('arrhythmias', 0.049), ('atrial', 0.049), ('cardiology', 0.049), ('clinicians', 0.049), ('pvcs', 0.049), ('sinoatrial', 0.049), ('svebs', 0.049), ('veb', 0.049), ('clusters', 0.047), ('guttag', 0.043), ('mv', 0.041), ('tp', 0.041), ('clustering', 0.04), ('abnormal', 0.039), ('abnormalities', 0.039), ('detecting', 0.039), ('biomedical', 0.039), ('cluster', 0.039), ('interval', 0.038), ('nx', 0.037), ('sp', 0.037), ('ward', 0.037), ('database', 0.035), ('heart', 0.035), ('automated', 0.035), ('severe', 0.035), ('cation', 0.035), ('ers', 0.034), ('syed', 0.033), ('circulation', 0.033), ('clinician', 0.033), ('delineated', 0.033), ('disagreements', 0.033), ('ecgs', 0.033), ('headed', 0.033), ('paced', 0.033), ('pacemaker', 0.033), ('physionet', 0.033), ('refine', 0.033), ('scirica', 0.033), ('totals', 0.033), ('et', 0.032), ('morphological', 0.032), ('trained', 0.031), ('query', 0.031), ('fp', 0.031), ('originate', 0.031), ('timing', 0.031), ('global', 0.03), ('contain', 0.029), ('arrhythmia', 0.029), ('cardiol', 0.029), ('compromised', 0.029), ('myocardial', 0.029), ('physicians', 0.029), ('qr', 0.029), ('stultz', 0.029), ('tasks', 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9999994 <a title="24-tfidf-1" href="./nips-2010-Active_Learning_Applied_to_Patient-Adaptive_Heartbeat_Classification.html">24 nips-2010-Active Learning Applied to Patient-Adaptive Heartbeat Classification</a></p>
<p>Author: Jenna Wiens, John V. Guttag</p><p>Abstract: While clinicians can accurately identify different types of heartbeats in electrocardiograms (ECGs) from different patients, researchers have had limited success in applying supervised machine learning to the same task. The problem is made challenging by the variety of tasks, inter- and intra-patient differences, an often severe class imbalance, and the high cost of getting cardiologists to label data for individual patients. We address these difﬁculties using active learning to perform patient-adaptive and task-adaptive heartbeat classiﬁcation. When tested on a benchmark database of cardiologist annotated ECG recordings, our method had considerably better performance than other recently proposed methods on the two primary classiﬁcation tasks recommended by the Association for the Advancement of Medical Instrumentation. Additionally, our method required over 90% less patient-speciﬁc training data than the methods to which we compared it. 1</p><p>2 0.29083103 <a title="24-tfidf-2" href="./nips-2010-Identifying_Patients_at_Risk_of_Major_Adverse_Cardiovascular_Events_Using_Symbolic_Mismatch.html">116 nips-2010-Identifying Patients at Risk of Major Adverse Cardiovascular Events Using Symbolic Mismatch</a></p>
<p>Author: Zeeshan Syed, John V. Guttag</p><p>Abstract: Cardiovascular disease is the leading cause of death globally, resulting in 17 million deaths each year. Despite the availability of various treatment options, existing techniques based upon conventional medical knowledge often fail to identify patients who might have beneﬁted from more aggressive therapy. In this paper, we describe and evaluate a novel unsupervised machine learning approach for cardiac risk stratiﬁcation. The key idea of our approach is to avoid specialized medical knowledge, and assess patient risk using symbolic mismatch, a new metric to assess similarity in long-term time-series activity. We hypothesize that high risk patients can be identiﬁed using symbolic mismatch, as individuals in a population with unusual long-term physiological activity. We describe related approaches that build on these ideas to provide improved medical decision making for patients who have recently suffered coronary attacks. We ﬁrst describe how to compute the symbolic mismatch between pairs of long term electrocardiographic (ECG) signals. This algorithm maps the original signals into a symbolic domain, and provides a quantitative assessment of the difference between these symbolic representations of the original signals. We then show how this measure can be used with each of a one-class SVM, a nearest neighbor classiﬁer, and hierarchical clustering to improve risk stratiﬁcation. We evaluated our methods on a population of 686 cardiac patients with available long-term electrocardiographic data. In a univariate analysis, all of the methods provided a statistically signiﬁcant association with the occurrence of a major adverse cardiac event in the next 90 days. In a multivariate analysis that incorporated the most widely used clinical risk variables, the nearest neighbor and hierarchical clustering approaches were able to statistically signiﬁcantly distinguish patients with a roughly two-fold risk of suffering a major adverse cardiac event in the next 90 days. 1</p><p>3 0.088201955 <a title="24-tfidf-3" href="./nips-2010-Towards_Holistic_Scene_Understanding%3A_Feedback_Enabled_Cascaded_Classification_Models.html">272 nips-2010-Towards Holistic Scene Understanding: Feedback Enabled Cascaded Classification Models</a></p>
<p>Author: Congcong Li, Adarsh Kowdle, Ashutosh Saxena, Tsuhan Chen</p><p>Abstract: In many machine learning domains (such as scene understanding), several related sub-tasks (such as scene categorization, depth estimation, object detection) operate on the same raw data and provide correlated outputs. Each of these tasks is often notoriously hard, and state-of-the-art classiﬁers already exist for many subtasks. It is desirable to have an algorithm that can capture such correlation without requiring to make any changes to the inner workings of any classiﬁer. We propose Feedback Enabled Cascaded Classiﬁcation Models (FE-CCM), that maximizes the joint likelihood of the sub-tasks, while requiring only a ‘black-box’ interface to the original classiﬁer for each sub-task. We use a two-layer cascade of classiﬁers, which are repeated instantiations of the original ones, with the output of the ﬁrst layer fed into the second layer as input. Our training method involves a feedback step that allows later classiﬁers to provide earlier classiﬁers information about what error modes to focus on. We show that our method signiﬁcantly improves performance in all the sub-tasks in two different domains: (i) scene understanding, where we consider depth estimation, scene categorization, event categorization, object detection, geometric labeling and saliency detection, and (ii) robotic grasping, where we consider grasp point detection and object classiﬁcation. 1</p><p>4 0.074781969 <a title="24-tfidf-4" href="./nips-2010-Agnostic_Active_Learning_Without_Constraints.html">27 nips-2010-Agnostic Active Learning Without Constraints</a></p>
<p>Author: Alina Beygelzimer, John Langford, Zhang Tong, Daniel J. Hsu</p><p>Abstract: We present and analyze an agnostic active learning algorithm that works without keeping a version space. This is unlike all previous approaches where a restricted set of candidate hypotheses is maintained throughout learning, and only hypotheses from this set are ever returned. By avoiding this version space approach, our algorithm sheds the computational burden and brittleness associated with maintaining version spaces, yet still allows for substantial improvements over supervised learning for classiﬁcation. 1</p><p>5 0.074490786 <a title="24-tfidf-5" href="./nips-2010-Active_Estimation_of_F-Measures.html">22 nips-2010-Active Estimation of F-Measures</a></p>
<p>Author: Christoph Sawade, Niels Landwehr, Tobias Scheffer</p><p>Abstract: We address the problem of estimating the Fα -measure of a given model as accurately as possible on a ﬁxed labeling budget. This problem occurs whenever an estimate cannot be obtained from held-out training data; for instance, when data that have been used to train the model are held back for reasons of privacy or do not reﬂect the test distribution. In this case, new test instances have to be drawn and labeled at a cost. An active estimation procedure selects instances according to an instrumental sampling distribution. An analysis of the sources of estimation error leads to an optimal sampling distribution that minimizes estimator variance. We explore conditions under which active estimates of Fα -measures are more accurate than estimates based on instances sampled from the test distribution. 1</p><p>6 0.070256047 <a title="24-tfidf-6" href="./nips-2010-Multi-View_Active_Learning_in_the_Non-Realizable_Case.html">173 nips-2010-Multi-View Active Learning in the Non-Realizable Case</a></p>
<p>7 0.068349607 <a title="24-tfidf-7" href="./nips-2010-Active_Learning_by_Querying_Informative_and_Representative_Examples.html">25 nips-2010-Active Learning by Querying Informative and Representative Examples</a></p>
<p>8 0.063892283 <a title="24-tfidf-8" href="./nips-2010-Active_Instance_Sampling_via_Matrix_Partition.html">23 nips-2010-Active Instance Sampling via Matrix Partition</a></p>
<p>9 0.062256068 <a title="24-tfidf-9" href="./nips-2010-Online_Classification_with_Specificity_Constraints.html">192 nips-2010-Online Classification with Specificity Constraints</a></p>
<p>10 0.061456561 <a title="24-tfidf-10" href="./nips-2010-Exploiting_weakly-labeled_Web_images_to_improve_object_classification%3A_a_domain_adaptation_approach.html">86 nips-2010-Exploiting weakly-labeled Web images to improve object classification: a domain adaptation approach</a></p>
<p>11 0.056590792 <a title="24-tfidf-11" href="./nips-2010-Hashing_Hyperplane_Queries_to_Near_Points_with_Applications_to_Large-Scale_Active_Learning.html">112 nips-2010-Hashing Hyperplane Queries to Near Points with Applications to Large-Scale Active Learning</a></p>
<p>12 0.054854859 <a title="24-tfidf-12" href="./nips-2010-Multiparty_Differential_Privacy_via_Aggregation_of_Locally_Trained_Classifiers.html">175 nips-2010-Multiparty Differential Privacy via Aggregation of Locally Trained Classifiers</a></p>
<p>13 0.051987056 <a title="24-tfidf-13" href="./nips-2010-Semi-Supervised_Learning_with_Adversarially_Missing_Label_Information.html">236 nips-2010-Semi-Supervised Learning with Adversarially Missing Label Information</a></p>
<p>14 0.051735219 <a title="24-tfidf-14" href="./nips-2010-Large_Margin_Multi-Task_Metric_Learning.html">138 nips-2010-Large Margin Multi-Task Metric Learning</a></p>
<p>15 0.05170488 <a title="24-tfidf-15" href="./nips-2010-Rates_of_convergence_for_the_cluster_tree.html">223 nips-2010-Rates of convergence for the cluster tree</a></p>
<p>16 0.048961531 <a title="24-tfidf-16" href="./nips-2010-Joint_Cascade_Optimization_Using_A_Product_Of_Boosted_Classifiers.html">132 nips-2010-Joint Cascade Optimization Using A Product Of Boosted Classifiers</a></p>
<p>17 0.048010342 <a title="24-tfidf-17" href="./nips-2010-A_Theory_of_Multiclass_Boosting.html">15 nips-2010-A Theory of Multiclass Boosting</a></p>
<p>18 0.047809578 <a title="24-tfidf-18" href="./nips-2010-Supervised_Clustering.html">261 nips-2010-Supervised Clustering</a></p>
<p>19 0.046611074 <a title="24-tfidf-19" href="./nips-2010-Label_Embedding_Trees_for_Large_Multi-Class_Tasks.html">135 nips-2010-Label Embedding Trees for Large Multi-Class Tasks</a></p>
<p>20 0.046389181 <a title="24-tfidf-20" href="./nips-2010-Towards_Property-Based_Classification_of_Clustering_Paradigms.html">273 nips-2010-Towards Property-Based Classification of Clustering Paradigms</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.135), (1, 0.035), (2, 0.005), (3, -0.058), (4, 0.021), (5, 0.066), (6, -0.087), (7, -0.097), (8, 0.03), (9, -0.119), (10, 0.045), (11, 0.023), (12, 0.002), (13, -0.089), (14, 0.077), (15, -0.051), (16, -0.025), (17, 0.105), (18, -0.065), (19, -0.056), (20, -0.101), (21, 0.033), (22, -0.043), (23, 0.07), (24, -0.009), (25, -0.035), (26, 0.028), (27, 0.158), (28, 0.045), (29, 0.018), (30, -0.085), (31, 0.055), (32, -0.02), (33, -0.013), (34, -0.083), (35, -0.107), (36, -0.061), (37, -0.05), (38, 0.033), (39, -0.043), (40, 0.024), (41, 0.134), (42, -0.086), (43, 0.154), (44, -0.044), (45, -0.198), (46, -0.067), (47, -0.04), (48, -0.116), (49, -0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.87571704 <a title="24-lsi-1" href="./nips-2010-Active_Learning_Applied_to_Patient-Adaptive_Heartbeat_Classification.html">24 nips-2010-Active Learning Applied to Patient-Adaptive Heartbeat Classification</a></p>
<p>Author: Jenna Wiens, John V. Guttag</p><p>Abstract: While clinicians can accurately identify different types of heartbeats in electrocardiograms (ECGs) from different patients, researchers have had limited success in applying supervised machine learning to the same task. The problem is made challenging by the variety of tasks, inter- and intra-patient differences, an often severe class imbalance, and the high cost of getting cardiologists to label data for individual patients. We address these difﬁculties using active learning to perform patient-adaptive and task-adaptive heartbeat classiﬁcation. When tested on a benchmark database of cardiologist annotated ECG recordings, our method had considerably better performance than other recently proposed methods on the two primary classiﬁcation tasks recommended by the Association for the Advancement of Medical Instrumentation. Additionally, our method required over 90% less patient-speciﬁc training data than the methods to which we compared it. 1</p><p>2 0.87477815 <a title="24-lsi-2" href="./nips-2010-Identifying_Patients_at_Risk_of_Major_Adverse_Cardiovascular_Events_Using_Symbolic_Mismatch.html">116 nips-2010-Identifying Patients at Risk of Major Adverse Cardiovascular Events Using Symbolic Mismatch</a></p>
<p>Author: Zeeshan Syed, John V. Guttag</p><p>Abstract: Cardiovascular disease is the leading cause of death globally, resulting in 17 million deaths each year. Despite the availability of various treatment options, existing techniques based upon conventional medical knowledge often fail to identify patients who might have beneﬁted from more aggressive therapy. In this paper, we describe and evaluate a novel unsupervised machine learning approach for cardiac risk stratiﬁcation. The key idea of our approach is to avoid specialized medical knowledge, and assess patient risk using symbolic mismatch, a new metric to assess similarity in long-term time-series activity. We hypothesize that high risk patients can be identiﬁed using symbolic mismatch, as individuals in a population with unusual long-term physiological activity. We describe related approaches that build on these ideas to provide improved medical decision making for patients who have recently suffered coronary attacks. We ﬁrst describe how to compute the symbolic mismatch between pairs of long term electrocardiographic (ECG) signals. This algorithm maps the original signals into a symbolic domain, and provides a quantitative assessment of the difference between these symbolic representations of the original signals. We then show how this measure can be used with each of a one-class SVM, a nearest neighbor classiﬁer, and hierarchical clustering to improve risk stratiﬁcation. We evaluated our methods on a population of 686 cardiac patients with available long-term electrocardiographic data. In a univariate analysis, all of the methods provided a statistically signiﬁcant association with the occurrence of a major adverse cardiac event in the next 90 days. In a multivariate analysis that incorporated the most widely used clinical risk variables, the nearest neighbor and hierarchical clustering approaches were able to statistically signiﬁcantly distinguish patients with a roughly two-fold risk of suffering a major adverse cardiac event in the next 90 days. 1</p><p>3 0.48334908 <a title="24-lsi-3" href="./nips-2010-Hashing_Hyperplane_Queries_to_Near_Points_with_Applications_to_Large-Scale_Active_Learning.html">112 nips-2010-Hashing Hyperplane Queries to Near Points with Applications to Large-Scale Active Learning</a></p>
<p>Author: Prateek Jain, Sudheendra Vijayanarasimhan, Kristen Grauman</p><p>Abstract: We consider the problem of retrieving the database points nearest to a given hyperplane query without exhaustively scanning the database. We propose two hashingbased solutions. Our ﬁrst approach maps the data to two-bit binary keys that are locality-sensitive for the angle between the hyperplane normal and a database point. Our second approach embeds the data into a vector space where the Euclidean norm reﬂects the desired distance between the original points and hyperplane query. Both use hashing to retrieve near points in sub-linear time. Our ﬁrst method’s preprocessing stage is more efﬁcient, while the second has stronger accuracy guarantees. We apply both to pool-based active learning: taking the current hyperplane classiﬁer as a query, our algorithm identiﬁes those points (approximately) satisfying the well-known minimal distance-to-hyperplane selection criterion. We empirically demonstrate our methods’ tradeoffs, and show that they make it practical to perform active selection with millions of unlabeled points. 1</p><p>4 0.39886206 <a title="24-lsi-4" href="./nips-2010-Multi-View_Active_Learning_in_the_Non-Realizable_Case.html">173 nips-2010-Multi-View Active Learning in the Non-Realizable Case</a></p>
<p>Author: Wei Wang, Zhi-hua Zhou</p><p>Abstract: The sample complexity of active learning under the realizability assumption has been well-studied. The realizability assumption, however, rarely holds in practice. In this paper, we theoretically characterize the sample complexity of active learning in the non-realizable case under multi-view setting. We prove that, with unbounded Tsybakov noise, the sample complexity of multi-view active learning can be O(log 1 ), contrasting to single-view setting where the polynomial improveǫ ment is the best possible achievement. We also prove that in general multi-view setting the sample complexity of active learning with unbounded Tsybakov noise is O( 1 ), where the order of 1/ǫ is independent of the parameter in Tsybakov noise, ǫ contrasting to previous polynomial bounds where the order of 1/ǫ is related to the parameter in Tsybakov noise. 1</p><p>5 0.39070755 <a title="24-lsi-5" href="./nips-2010-Active_Estimation_of_F-Measures.html">22 nips-2010-Active Estimation of F-Measures</a></p>
<p>Author: Christoph Sawade, Niels Landwehr, Tobias Scheffer</p><p>Abstract: We address the problem of estimating the Fα -measure of a given model as accurately as possible on a ﬁxed labeling budget. This problem occurs whenever an estimate cannot be obtained from held-out training data; for instance, when data that have been used to train the model are held back for reasons of privacy or do not reﬂect the test distribution. In this case, new test instances have to be drawn and labeled at a cost. An active estimation procedure selects instances according to an instrumental sampling distribution. An analysis of the sources of estimation error leads to an optimal sampling distribution that minimizes estimator variance. We explore conditions under which active estimates of Fα -measures are more accurate than estimates based on instances sampled from the test distribution. 1</p><p>6 0.38959596 <a title="24-lsi-6" href="./nips-2010-Towards_Holistic_Scene_Understanding%3A_Feedback_Enabled_Cascaded_Classification_Models.html">272 nips-2010-Towards Holistic Scene Understanding: Feedback Enabled Cascaded Classification Models</a></p>
<p>7 0.3793399 <a title="24-lsi-7" href="./nips-2010-A_Bayesian_Approach_to_Concept_Drift.html">2 nips-2010-A Bayesian Approach to Concept Drift</a></p>
<p>8 0.37209594 <a title="24-lsi-8" href="./nips-2010-Active_Instance_Sampling_via_Matrix_Partition.html">23 nips-2010-Active Instance Sampling via Matrix Partition</a></p>
<p>9 0.36496487 <a title="24-lsi-9" href="./nips-2010-Multiparty_Differential_Privacy_via_Aggregation_of_Locally_Trained_Classifiers.html">175 nips-2010-Multiparty Differential Privacy via Aggregation of Locally Trained Classifiers</a></p>
<p>10 0.36463198 <a title="24-lsi-10" href="./nips-2010-Active_Learning_by_Querying_Informative_and_Representative_Examples.html">25 nips-2010-Active Learning by Querying Informative and Representative Examples</a></p>
<p>11 0.35559961 <a title="24-lsi-11" href="./nips-2010-Large_Margin_Multi-Task_Metric_Learning.html">138 nips-2010-Large Margin Multi-Task Metric Learning</a></p>
<p>12 0.34977159 <a title="24-lsi-12" href="./nips-2010-Decoding_Ipsilateral_Finger_Movements_from_ECoG_Signals_in_Humans.html">57 nips-2010-Decoding Ipsilateral Finger Movements from ECoG Signals in Humans</a></p>
<p>13 0.34495395 <a title="24-lsi-13" href="./nips-2010-Discriminative_Clustering_by_Regularized_Information_Maximization.html">62 nips-2010-Discriminative Clustering by Regularized Information Maximization</a></p>
<p>14 0.33661476 <a title="24-lsi-14" href="./nips-2010-A_Theory_of_Multiclass_Boosting.html">15 nips-2010-A Theory of Multiclass Boosting</a></p>
<p>15 0.33498797 <a title="24-lsi-15" href="./nips-2010-Supervised_Clustering.html">261 nips-2010-Supervised Clustering</a></p>
<p>16 0.32976943 <a title="24-lsi-16" href="./nips-2010-Global_seismic_monitoring_as_probabilistic_inference.html">107 nips-2010-Global seismic monitoring as probabilistic inference</a></p>
<p>17 0.32473743 <a title="24-lsi-17" href="./nips-2010-Variable_margin_losses_for_classifier_design.html">282 nips-2010-Variable margin losses for classifier design</a></p>
<p>18 0.32382205 <a title="24-lsi-18" href="./nips-2010-Latent_Variable_Models_for_Predicting_File_Dependencies_in_Large-Scale_Software_Development.html">139 nips-2010-Latent Variable Models for Predicting File Dependencies in Large-Scale Software Development</a></p>
<p>19 0.31633222 <a title="24-lsi-19" href="./nips-2010-Reverse_Multi-Label_Learning.html">228 nips-2010-Reverse Multi-Label Learning</a></p>
<p>20 0.31375003 <a title="24-lsi-20" href="./nips-2010-Joint_Cascade_Optimization_Using_A_Product_Of_Boosted_Classifiers.html">132 nips-2010-Joint Cascade Optimization Using A Product Of Boosted Classifiers</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.047), (17, 0.013), (27, 0.051), (30, 0.033), (31, 0.04), (35, 0.018), (45, 0.166), (50, 0.037), (52, 0.019), (60, 0.04), (70, 0.38), (77, 0.028), (78, 0.018), (90, 0.043)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.70337236 <a title="24-lda-1" href="./nips-2010-Active_Learning_Applied_to_Patient-Adaptive_Heartbeat_Classification.html">24 nips-2010-Active Learning Applied to Patient-Adaptive Heartbeat Classification</a></p>
<p>Author: Jenna Wiens, John V. Guttag</p><p>Abstract: While clinicians can accurately identify different types of heartbeats in electrocardiograms (ECGs) from different patients, researchers have had limited success in applying supervised machine learning to the same task. The problem is made challenging by the variety of tasks, inter- and intra-patient differences, an often severe class imbalance, and the high cost of getting cardiologists to label data for individual patients. We address these difﬁculties using active learning to perform patient-adaptive and task-adaptive heartbeat classiﬁcation. When tested on a benchmark database of cardiologist annotated ECG recordings, our method had considerably better performance than other recently proposed methods on the two primary classiﬁcation tasks recommended by the Association for the Advancement of Medical Instrumentation. Additionally, our method required over 90% less patient-speciﬁc training data than the methods to which we compared it. 1</p><p>2 0.5872159 <a title="24-lda-2" href="./nips-2010-Gated_Softmax_Classification.html">99 nips-2010-Gated Softmax Classification</a></p>
<p>Author: Roland Memisevic, Christopher Zach, Marc Pollefeys, Geoffrey E. Hinton</p><p>Abstract: We describe a ”log-bilinear” model that computes class probabilities by combining an input vector multiplicatively with a vector of binary latent variables. Even though the latent variables can take on exponentially many possible combinations of values, we can efﬁciently compute the exact probability of each class by marginalizing over the latent variables. This makes it possible to get the exact gradient of the log likelihood. The bilinear score-functions are deﬁned using a three-dimensional weight tensor, and we show that factorizing this tensor allows the model to encode invariances inherent in a task by learning a dictionary of invariant basis functions. Experiments on a set of benchmark problems show that this fully probabilistic model can achieve classiﬁcation performance that is competitive with (kernel) SVMs, backpropagation, and deep belief nets. 1</p><p>3 0.50576937 <a title="24-lda-3" href="./nips-2010-Identifying_Patients_at_Risk_of_Major_Adverse_Cardiovascular_Events_Using_Symbolic_Mismatch.html">116 nips-2010-Identifying Patients at Risk of Major Adverse Cardiovascular Events Using Symbolic Mismatch</a></p>
<p>Author: Zeeshan Syed, John V. Guttag</p><p>Abstract: Cardiovascular disease is the leading cause of death globally, resulting in 17 million deaths each year. Despite the availability of various treatment options, existing techniques based upon conventional medical knowledge often fail to identify patients who might have beneﬁted from more aggressive therapy. In this paper, we describe and evaluate a novel unsupervised machine learning approach for cardiac risk stratiﬁcation. The key idea of our approach is to avoid specialized medical knowledge, and assess patient risk using symbolic mismatch, a new metric to assess similarity in long-term time-series activity. We hypothesize that high risk patients can be identiﬁed using symbolic mismatch, as individuals in a population with unusual long-term physiological activity. We describe related approaches that build on these ideas to provide improved medical decision making for patients who have recently suffered coronary attacks. We ﬁrst describe how to compute the symbolic mismatch between pairs of long term electrocardiographic (ECG) signals. This algorithm maps the original signals into a symbolic domain, and provides a quantitative assessment of the difference between these symbolic representations of the original signals. We then show how this measure can be used with each of a one-class SVM, a nearest neighbor classiﬁer, and hierarchical clustering to improve risk stratiﬁcation. We evaluated our methods on a population of 686 cardiac patients with available long-term electrocardiographic data. In a univariate analysis, all of the methods provided a statistically signiﬁcant association with the occurrence of a major adverse cardiac event in the next 90 days. In a multivariate analysis that incorporated the most widely used clinical risk variables, the nearest neighbor and hierarchical clustering approaches were able to statistically signiﬁcantly distinguish patients with a roughly two-fold risk of suffering a major adverse cardiac event in the next 90 days. 1</p><p>4 0.45602027 <a title="24-lda-4" href="./nips-2010-Efficient_Optimization_for_Discriminative_Latent_Class_Models.html">70 nips-2010-Efficient Optimization for Discriminative Latent Class Models</a></p>
<p>Author: Armand Joulin, Jean Ponce, Francis R. Bach</p><p>Abstract: Dimensionality reduction is commonly used in the setting of multi-label supervised classiﬁcation to control the learning capacity and to provide a meaningful representation of the data. We introduce a simple forward probabilistic model which is a multinomial extension of reduced rank regression, and show that this model provides a probabilistic interpretation of discriminative clustering methods with added beneﬁts in terms of number of hyperparameters and optimization. While the expectation-maximization (EM) algorithm is commonly used to learn these probabilistic models, it usually leads to local maxima because it relies on a non-convex cost function. To avoid this problem, we introduce a local approximation of this cost function, which in turn leads to a quadratic non-convex optimization problem over a product of simplices. In order to maximize quadratic functions, we propose an efﬁcient algorithm based on convex relaxations and lowrank representations of the data, capable of handling large-scale problems. Experiments on text document classiﬁcation show that the new model outperforms other supervised dimensionality reduction methods, while simulations on unsupervised clustering show that our probabilistic formulation has better properties than existing discriminative clustering methods. 1</p><p>5 0.45538545 <a title="24-lda-5" href="./nips-2010-Active_Instance_Sampling_via_Matrix_Partition.html">23 nips-2010-Active Instance Sampling via Matrix Partition</a></p>
<p>Author: Yuhong Guo</p><p>Abstract: Recently, batch-mode active learning has attracted a lot of attention. In this paper, we propose a novel batch-mode active learning approach that selects a batch of queries in each iteration by maximizing a natural mutual information criterion between the labeled and unlabeled instances. By employing a Gaussian process framework, this mutual information based instance selection problem can be formulated as a matrix partition problem. Although matrix partition is an NP-hard combinatorial optimization problem, we show that a good local solution can be obtained by exploiting an effective local optimization technique on a relaxed continuous optimization problem. The proposed active learning approach is independent of employed classiﬁcation models. Our empirical studies show this approach can achieve comparable or superior performance to discriminative batch-mode active learning methods. 1</p><p>6 0.45308754 <a title="24-lda-6" href="./nips-2010-Extended_Bayesian_Information_Criteria_for_Gaussian_Graphical_Models.html">87 nips-2010-Extended Bayesian Information Criteria for Gaussian Graphical Models</a></p>
<p>7 0.45305571 <a title="24-lda-7" href="./nips-2010-Distributed_Dual_Averaging_In_Networks.html">63 nips-2010-Distributed Dual Averaging In Networks</a></p>
<p>8 0.45285186 <a title="24-lda-8" href="./nips-2010-Online_Markov_Decision_Processes_under_Bandit_Feedback.html">196 nips-2010-Online Markov Decision Processes under Bandit Feedback</a></p>
<p>9 0.45160553 <a title="24-lda-9" href="./nips-2010-Object_Bank%3A_A_High-Level_Image_Representation_for_Scene_Classification_%26_Semantic_Feature_Sparsification.html">186 nips-2010-Object Bank: A High-Level Image Representation for Scene Classification & Semantic Feature Sparsification</a></p>
<p>10 0.45134538 <a title="24-lda-10" href="./nips-2010-Variable_margin_losses_for_classifier_design.html">282 nips-2010-Variable margin losses for classifier design</a></p>
<p>11 0.45131692 <a title="24-lda-11" href="./nips-2010-A_Primal-Dual_Algorithm_for_Group_Sparse_Regularization_with_Overlapping_Groups.html">12 nips-2010-A Primal-Dual Algorithm for Group Sparse Regularization with Overlapping Groups</a></p>
<p>12 0.45061114 <a title="24-lda-12" href="./nips-2010-Optimal_learning_rates_for_Kernel_Conjugate_Gradient_regression.html">199 nips-2010-Optimal learning rates for Kernel Conjugate Gradient regression</a></p>
<p>13 0.45061097 <a title="24-lda-13" href="./nips-2010-Transduction_with_Matrix_Completion%3A_Three_Birds_with_One_Stone.html">275 nips-2010-Transduction with Matrix Completion: Three Birds with One Stone</a></p>
<p>14 0.4504931 <a title="24-lda-14" href="./nips-2010-Fast_global_convergence_rates_of_gradient_methods_for_high-dimensional_statistical_recovery.html">92 nips-2010-Fast global convergence rates of gradient methods for high-dimensional statistical recovery</a></p>
<p>15 0.45034739 <a title="24-lda-15" href="./nips-2010-Joint_Cascade_Optimization_Using_A_Product_Of_Boosted_Classifiers.html">132 nips-2010-Joint Cascade Optimization Using A Product Of Boosted Classifiers</a></p>
<p>16 0.45031765 <a title="24-lda-16" href="./nips-2010-The_LASSO_risk%3A_asymptotic_results_and_real_world_examples.html">265 nips-2010-The LASSO risk: asymptotic results and real world examples</a></p>
<p>17 0.45023197 <a title="24-lda-17" href="./nips-2010-Worst-Case_Linear_Discriminant_Analysis.html">287 nips-2010-Worst-Case Linear Discriminant Analysis</a></p>
<p>18 0.45017758 <a title="24-lda-18" href="./nips-2010-Learning_via_Gaussian_Herding.html">158 nips-2010-Learning via Gaussian Herding</a></p>
<p>19 0.45002586 <a title="24-lda-19" href="./nips-2010-Identifying_graph-structured_activation_patterns_in_networks.html">117 nips-2010-Identifying graph-structured activation patterns in networks</a></p>
<p>20 0.449763 <a title="24-lda-20" href="./nips-2010-A_Family_of_Penalty_Functions_for_Structured_Sparsity.html">7 nips-2010-A Family of Penalty Functions for Structured Sparsity</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
