<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>191 nips-2010-On the Theory of Learnining with Privileged Information</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-191" href="#">nips2010-191</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>191 nips-2010-On the Theory of Learnining with Privileged Information</h1>
<br/><p>Source: <a title="nips-2010-191-pdf" href="http://papers.nips.cc/paper/3960-on-the-theory-of-learnining-with-privileged-information.pdf">pdf</a></p><p>Author: Dmitry Pechyony, Vladimir Vapnik</p><p>Abstract: In Learning Using Privileged Information (LUPI) paradigm, along with the standard training data in the decision space, a teacher supplies a learner with the privileged information in the correcting space. The goal of the learner is to ﬁnd a classiﬁer with a low generalization error in the decision space. We consider an empirical risk minimization algorithm, called Privileged ERM, that takes into account the privileged information in order to ﬁnd a good function in the decision space. We outline the conditions on the correcting space that, if satisﬁed, allow Privileged ERM to have much faster learning rate in the decision space than the one of the regular empirical risk minimization. 1</p><p>Reference: <a title="nips-2010-191-reference" href="../nips2010_reference/nips-2010-On_the_Theory_of_Learnining_with_Privileged_Information_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 com  Abstract In Learning Using Privileged Information (LUPI) paradigm, along with the standard training data in the decision space, a teacher supplies a learner with the privileged information in the correcting space. [sent-3, score-1.306]
</p><p>2 The goal of the learner is to ﬁnd a classiﬁer with a low generalization error in the decision space. [sent-4, score-0.345]
</p><p>3 We consider an empirical risk minimization algorithm, called Privileged ERM, that takes into account the privileged information in order to ﬁnd a good function in the decision space. [sent-5, score-0.947]
</p><p>4 We outline the conditions on the correcting space that, if satisﬁed, allow Privileged ERM to have much faster learning rate in the decision space than the one of the regular empirical risk minimization. [sent-6, score-0.858]
</p><p>5 1  Introduction  In the classical supervised machine learning paradigm the learner is given a labeled training set of examples and her goal is to ﬁnd a decision function with the small generalization error on the unknown test examples. [sent-7, score-0.466]
</p><p>6 if learner’s space of decision functions contains a one with zero generalization error) then, when the training size increases, the decision function found by the learner converges quickly to the optimal one. [sent-10, score-0.571]
</p><p>7 However if the learning problem is hard and the learner’s space of decision functions is large then the convergence (or learning) rate is slow. [sent-11, score-0.342]
</p><p>8 The example of such hard learning problem is XOR when the space of decision functions is 2-dimensional hyperplanes. [sent-12, score-0.219]
</p><p>9 The obvious question is “Can we accelerate the learning rate if the learner is given an additional information about the learning problem? [sent-13, score-0.255]
</p><p>10 In LUPI paradigm, in addition to the standard training data, (x, y) ∈ X × Y , a teacher supplies the learner with a privileged information x∗ in the correcting space X ∗ . [sent-19, score-1.223]
</p><p>11 The privileged information is only available for the training examples and is never available for the test examples. [sent-20, score-0.647]
</p><p>12 The LUPI paradigm requires, given a training set {(xi , x∗ , yi )}n , to ﬁnd a decision function h : X → Y i i=1 with the small generalization error for the unknown test examples x ∈ X. [sent-21, score-0.425]
</p><p>13 The above question about accelerating the learning rate, reformulated in terms of the LUPI paradigm, is “What kind of additional information should the teacher provide to the learner in order to accelerate her learning rate? [sent-22, score-0.281]
</p><p>14 In this paper we outline the conditions for the additional information provided by the teacher that allow for fast learning rate even in the hard problems. [sent-26, score-0.266]
</p><p>15 Let h(x) = sign(w · x + b) be a decision function and φ(x∗ ) = i w∗ · x∗ + d be a correcting function. [sent-31, score-0.413]
</p><p>16 Let X (h(x), y) = 1 − y(w · x + b) be a hinge loss of the decision function h = (w, b) on the example (x, y) and X ∗ (φ(x∗ )) = [w∗ · x∗ + d]+ be a loss of the correcting function φ = (w∗ , d) on the example x∗ . [sent-37, score-0.553]
</p><p>17 ∀ 1 ≤ i ≤ n,  X (h(xi ), yi )  ≤  ∗ X ∗ (φ(xi ), yi ),  (4)  where X and X ∗ are arbitrary bounded loss functions, H is a space of decision functions and Φ is a space of correcting functions. [sent-43, score-0.734]
</p><p>18 Let C > 0 be a constant (that is deﬁned later), [t]+ = max(t, 0) and ((h, φ), (x, x∗ , y)) =  1 · C  ∗ X ∗ (φ(x ), y)  +[  X (h(x), y)  −  ∗ X ∗ (φ(x ), y)]+  (5)  be the loss of the composite hypothesis (h, φ) on the example (x, x∗ , y). [sent-44, score-0.235]
</p><p>19 In this paper we study the relaxation of (3): n  ((h, φ), (xi , x∗ , yi )), i  min  h∈H,φ∈Φ  (6)  i=1  We refer to the learning algorithm deﬁned by the optimization problem (6) as empirical risk minimization with privileged information, or abbreviated Privileged ERM. [sent-45, score-0.888]
</p><p>20 The basic assumption of Privileged ERM is that if we can achieve a small loss X ∗ (φ(x∗ ), y) in the correcting space then we should also achieve a small loss X (h(x), y) in the decision space. [sent-46, score-0.626]
</p><p>21 This assumption reﬂects the human learning process, where the teacher tells the learner what are the most important examples (the ones with the small loss in the correcting space) that the learner should take into account in order to ﬁnd a good decision rule. [sent-47, score-0.828]
</p><p>22 The regular empirical risk minimization (ERM) ﬁnds a hypothesis h ∈ H that minimizes the training n error i=1 X (h(xi ), yi ). [sent-48, score-0.563]
</p><p>23 While the regular ERM directly minimizes the training error of h, the privileged ERM minimizes the training error of h indirectly, via the minimization of the training error of the correcting function φ and the relaxation of the constraint (4). [sent-49, score-1.253]
</p><p>24 Let h∗ be the best possible decision function (in terms of generalization error) in the hypothesis space H. [sent-50, score-0.381]
</p><p>25 Suppose that for each training example xi an oracle gives us the value of the loss X (h∗ (xi ), yi ). [sent-51, score-0.235]
</p><p>26 We use these ﬁxed losses instead of X ∗ (φ(x∗ ), yi ) and ﬁnd h that satisﬁes the following system of i inequalities: ∀ 1 ≤ i ≤ n, X (h(xi ), yi ) ≤ X (h∗ (xi ), yi ). [sent-52, score-0.217]
</p><p>27 A straightforward generalization of the proof of Proposition 1 of [9] shows that the generalization error of the hypothesis h found by OracleERM converges to the one of h∗ with the rate of 1/n. [sent-54, score-0.455]
</p><p>28 This rate is much faster than the √ worst-case convergence rate 1/ n of the regular ERM [3]. [sent-55, score-0.293]
</p><p>29 1 A decision function h is uniformly better than the correcting function φ if for any example (x, x∗ , y) that has non-zero probability, X ∗ (φ(x∗ ), yi ) ≥ X (h(xi ), yi ). [sent-58, score-0.581]
</p><p>30 i Given a space H of decision functions and a space Φ of correcting functions we deﬁne Φ = {φ ∈ Φ | ∃h ∈ H that is uniformly better than φ}. [sent-59, score-0.595]
</p><p>31 Note that Φ ⊆ Φ and Φ does not contain correcting functions that are too good for H. [sent-60, score-0.318]
</p><p>32 3 There exists a correcting function φ ∈ Φ, such that for any (x, x∗ , y) that has non-zero probability, X (h∗ (xi ), yi ) = X ∗ (φ(x∗ ), yi ). [sent-65, score-0.449]
</p><p>33 i Put it another way, we assume the existence of correcting function in Φ that mimics the losses of h∗ . [sent-66, score-0.303]
</p><p>34 Let r be a learning rate of the Privileged ERM when it is ran over the joint X × X ∗ space with the space of decision and correcting functions H × Φ. [sent-67, score-0.619]
</p><p>35 We develop an upper bound for the risk of the decision function found by Privileged ERM. [sent-68, score-0.359]
</p><p>36 Under the above assumptions this bound converges to h∗ with the same rate r. [sent-69, score-0.219]
</p><p>37 This implies that if the correcting space is good, so that the Privileged ERM in the joint X × X ∗ space has a fast learning rate (e. [sent-70, score-0.483]
</p><p>38 That is true even if the√ decision space is hard and the regular ERM in the decision space has a slow learning rate (e. [sent-74, score-0.511]
</p><p>39 We illustrate this result with the artiﬁcial learning problem, where the regular ERM in the decision space √ can not learn with the rate faster than 1/ n, but the correcting space is good and Privileged ERM learns in the decision space with the rate of 1/n. [sent-77, score-0.927]
</p><p>40 In Section 3 we review the existing risk bounds that are used to derive our results. [sent-80, score-0.182]
</p><p>41 Section 4 contains the proof of the risk bound for Privileged ERM. [sent-81, score-0.215]
</p><p>42 They developed a risk bound (Proposition 2 in [9]) for the decision function found by their algorithm. [sent-87, score-0.341]
</p><p>43 The bound of [9] is tailored to the classiﬁcation setting, with 0/1-loss functions in the decision and the correcting space. [sent-89, score-0.513]
</p><p>44 By contrast, our bound holds for any bounded loss functions and allows the loss functions X and X ∗ to be different. [sent-90, score-0.291]
</p><p>45 The bound of [9] depends on generalization error of the correcting function φ found by Privileged ERM. [sent-91, score-0.467]
</p><p>46 Vapnik and Vashist [9] concluded that if we could bound the convergence rate of φ then this bound will imply the bound on the convergence rate of the decision function found by their algorithm. [sent-92, score-0.595]
</p><p>47 The spaces H and Φ of decision and correcting functions are chosen by learner. [sent-96, score-0.444]
</p><p>48 3  Let R(h) = E(x,y)∼DX { X (h(x), y)} and R(φ) = E(x∗ ,y)∼DX ∗ { X ∗ (φ(x∗ ), y)} be the generalization errors of the decision function h and the correcting function φ respectively. [sent-97, score-0.484]
</p><p>49 We denote by h∗ = arg minh∈H R(h) and φ∗ = arg minφ∈Φ R(φ) the decision and the correction function with the minimal generalization error w. [sent-100, score-0.306]
</p><p>50 the 0/1 loss and by h∗ = arg minh∈H R01 (h) the decision function in H with the minimal generalization 0/1 error. [sent-107, score-0.31]
</p><p>51 01 n 1 Let Rn (h, φ) = n i=1 ((h, φ), (xi , x∗ , yi )) and i R (h, φ) = E(x,x∗ ,y) ∼D { ((h, φ), (x, x∗ , y))}  (8)  be respectively empirical and generalization errors of the hypothesis (h, φ) w. [sent-108, score-0.302]
</p><p>52 We denote by (h, φ) = arg min(h,φ)∈H×Φ Rn (h, φ) the empirical risk minimizer and by (h , φ ) = arg  min  (h,φ)∈H×Φ  R (h, φ)  the minimizer of the generalization error w. [sent-112, score-0.366]
</p><p>53 Later on we will show how we choose the value of C that optimizes the forthcoming risk bound. [sent-132, score-0.146]
</p><p>54 The risk bounds presented in this paper are based on VC-dimension of various function classes. [sent-133, score-0.182]
</p><p>55 We say |T | that the set T = {(xi , ti )}i=1 ⊆ T (F) is shattered by F if for any T ⊆ T there exists a function f ∈ F such that for any (xi , ti ) ∈ T , |f (xi )| ≤ ti and for any (xi , ti ) ∈ T \ T , |f (xi )| > ti . [sent-138, score-0.245]
</p><p>56 3 Review of existing excess risk bounds with fast convergence rates We derive our risk bounds from generic excess risk bounds developed by Massart and Nedelec [6] and generalized by Gine and Koltchinskii [4] and Koltchinkii [5]. [sent-140, score-0.641]
</p><p>57 Let F be a space of hypotheses f : S → S , : S × {−1, +1} → R be a real-valued loss function such that 0 ≤ (f (x), y) ≤ 1 for any f ∈ F and any (x, y). [sent-142, score-0.153]
</p><p>58 Let f ∗ = 4  (a) Hypothesis space with small D  (b) Hypothesis space with large D  Figure 1: Visualization of the hypothesis spaces. [sent-143, score-0.227]
</p><p>59 The horisontal axis measures the distance (in terms of the variance) between hypothesis f and the best hypothesis f ∗ in F. [sent-144, score-0.298]
</p><p>60 The large value of D in the hypothesis space in graph (b) is caused by hypothesis A, which is signiﬁcantly different from f ∗ but has nearly-optimal error. [sent-147, score-0.34]
</p><p>61 arg minf ∈F E(x,y) { (f (x), y)}, fn = arg minf ∈F such that for any f ∈ F,  n i=1  (f (xi ), yi ) and D > 0 be a constant  Var(x,y) { (f (x), y) − (f ∗ (x), y)} ≤ D · E(x,y) { (f (x), y) − (f ∗ (x), y)}. [sent-148, score-0.201]
</p><p>62 (9)  This condition is a generalization of Tsybakov’s low-noise condition [7] to arbitrary loss functions and arbitrary hypothesis spaces. [sent-149, score-0.349]
</p><p>63 The constant D in (9) characterizes the error surface of the hypothesis space F. [sent-150, score-0.248]
</p><p>64 1 does not hold, namely if n ≤ V · D2 then we can use the following fallback risk bound: Theorem 3. [sent-162, score-0.146]
</p><p>65 For n ≤ T the bound√ (11) has a convergence rate of 1/n, and for n > T the bound (11) has a convergence rate of 1/ n. [sent-166, score-0.315]
</p><p>66 The main difference between (10) and (11) is the fast convergence rate √ of 1/n vs. [sent-167, score-0.144]
</p><p>67 Similarly, let L(H) = { X (h(·), ·) | h ∈ H} and L(Φ) = { X ∗ (φ(·), ·) | φ ∈ Φ} be the sets of loss functions that correspond to the hypotheses in H and Φ, and VL(H) and VL(Φ) be VC dimensions of L(H) and L(Φ) respectively. [sent-177, score-0.16]
</p><p>68 1 to the hypothesis space H × Φ and the loss function ((h, φ), (x, x∗ , y)) and 2 obtain that there exists a constant K > 0 such that if n > VL(H,Φ) · DH,Φ then for any δ > 0, with probability at least 1 − δ R (h, φ) ≤ R (h , φ ) +  KDH,Φ n  VL(H,Φ) ln  n 1 + ln 2 VL(H,Φ) DH,Φ δ  . [sent-183, score-0.457]
</p><p>69 C C C  (16)  We substitute (16) into (15) and obtain that there exists a constant K > 0 such that if n > VL(H,Φ) · 2 DH,Φ then for any δ > 0, with probability at least 1 − δ, R(h) ≤ R(h∗ ) +  CKDH,Φ n  VL(H,Φ) ln  n 1 + ln 2 VL(H,Φ) DH,Φ δ  . [sent-188, score-0.203]
</p><p>70 1 and obtain our ﬁnal risk bound, that is summarized in the following theorem: Theorem 4. [sent-190, score-0.146]
</p><p>71 6  n V L(H,Φ) ·  2 DH,Φ  + ln  1 δ  ,  (17)  According to this bound, R(h) converges to R(h∗ ) with the rate of 1/n. [sent-199, score-0.2]
</p><p>72 In this case the upper bound on R(h) converges to R(φ ) with the rate of 1/n. [sent-202, score-0.219]
</p><p>73 We now provide further analysis of the risk bound (17). [sent-203, score-0.215]
</p><p>74 5 When Privileged ERM is provably better than the regular ERM We show an example that demonstrates the difference between the emprical risk minimization in X space and empirical risk minimization with privileged information in the joint X × X ∗ space. [sent-218, score-1.145]
</p><p>75 2) the learning rate of the regular ERM in X space is 1/ n while the learning rate of the privileged ERM in the joint X × X ∗ space is 1/n. [sent-220, score-0.953]
</p><p>76 The hypothesis space H consists of hypotheses ht (x) = sign(x − t) and ht = −sign(x − t). [sent-227, score-0.264]
</p><p>77 The best hypothesis in H is h1 and its generalization error is 1/4 − 2 . [sent-228, score-0.252]
</p><p>78 The hypothesis space H contains also a hypothesis h3 , which is slightly worse than h1 and has generalization error of 1/4 + . [sent-229, score-0.436]
</p><p>79 In order to use the risk bound (10) with our DX and H, the condition 2 n > VH · DH = 1/(18 2 ) (21) should be satisﬁed. [sent-235, score-0.233]
</p><p>80 Hence, according to (11), for distributions DX ( ) that satisfy T (1/4 − 2 , 2, δ) ≤ 18 2 we √ ∗ obtain that R01 (h) converges to R01 (h ) with the rate of at least 1/ n. [sent-237, score-0.147]
</p><p>81 √ The following lower bound shows that R01 (h) converges to R01 (h∗ ) with the rate of at most 1/ n. [sent-238, score-0.201]
</p><p>82 By combining upper and lower bounds we obtain that the convergence rate of R01 (h) to R01 (h∗ ) is √ exactly 1/ n. [sent-244, score-0.177]
</p><p>83 Suppose that the teacher constructed the distribution DX ∗ ( ) of examples in X ∗ space in the fol∗ ∗ ∗ ∗ lowing way. [sent-246, score-0.159]
</p><p>84 The hypothesis space Φ consists of hy∗ ∗ potheses φt (x) = sign(x − t) and φt = −sign(x − t). [sent-250, score-0.184]
</p><p>85 The best hypothesis in Φ is φ2 and its generalization error is 0. [sent-251, score-0.252]
</p><p>86 The best hypothesis in Φ, among those that have uniformly better hypothesis in H, is φ1 and its generalization error is 1/4 − 2 . [sent-253, score-0.427]
</p><p>87 7 then R01 (h) converges to R01 (h∗ ) with the rate of at least 1/n. [sent-275, score-0.147]
</p><p>88 Since our bounds on DΦ and DH,Φ are independent of , the convergence rate of 1/n holds for any distribution in DX . [sent-276, score-0.179]
</p><p>89 7 < n ≤ 18 2 the upper bound (17) converges to R01 (h∗ ) with the rate of √ 1/n, while the upper bound (11) converges to R01 (h∗ ) with the rate of 1/ n. [sent-278, score-0.438]
</p><p>90 The hypothesis h3 caused the value of DH to be large and thus prevented us from 1/n convergence rate for a large range of n’s. [sent-280, score-0.279]
</p><p>91 We constructed DX ∗ ( ) and Φ in such a way that Φ does not have a hypothesis φ that has exactly the same dichotomy as the bad hypothesis h3 . [sent-281, score-0.298]
</p><p>92 With such construction any φ ∈ Φ, such that h3 is uniformly better than φ, has generalization error signiﬁcantly larger than the one of h3 . [sent-282, score-0.145]
</p><p>93 For example, the best hypothesis in Φ for which h3 is uniformly better, is φ0 and its generalization error is 1/2. [sent-283, score-0.286]
</p><p>94 6  Conclusions  We formulated the algorithm of empirical risk minimization with privileged information and derived the risk bound for it. [sent-284, score-1.036]
</p><p>95 Our risk bound outlines the conditions for the correcting space that, if satisﬁed, will allow fast learning in the decision space, even if the original learning problem in the decision space is very hard. [sent-285, score-0.861]
</p><p>96 We showed an example where the privileged information provably signiﬁcantly improves the learning rate. [sent-286, score-0.666]
</p><p>97 √ In this paper we showed that the good correcting space can improve the learning rate from 1/ n to 1/n. [sent-287, score-0.419]
</p><p>98 But, having the good correcting space, can we achieve a learning rate faster than 1/n? [sent-288, score-0.392]
</p><p>99 Finally, the important direction is to develop risk bounds for SVM+ (which is a regularized version of Privileged ERM) and show when it is provably better than SVM. [sent-291, score-0.245]
</p><p>100 2008 Saint Flour lectures: Oracle inequalities in empirical risk minimization and sparse recovery problems, 2008. [sent-315, score-0.219]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('privileged', 0.624), ('dh', 0.331), ('correcting', 0.287), ('erm', 0.28), ('vl', 0.265), ('lupi', 0.176), ('risk', 0.146), ('dx', 0.146), ('hypothesis', 0.141), ('decision', 0.126), ('learner', 0.108), ('teacher', 0.099), ('paradigm', 0.098), ('rate', 0.089), ('vh', 0.074), ('generalization', 0.071), ('loss', 0.07), ('bound', 0.069), ('ln', 0.068), ('yi', 0.067), ('regular', 0.065), ('var', 0.06), ('ckdh', 0.059), ('vashist', 0.059), ('vapnik', 0.055), ('space', 0.043), ('converges', 0.043), ('lemma', 0.043), ('xi', 0.042), ('provably', 0.042), ('hypotheses', 0.04), ('accelerate', 0.04), ('error', 0.04), ('pechyony', 0.039), ('supplies', 0.039), ('ti', 0.038), ('bounds', 0.036), ('suppose', 0.035), ('uniformly', 0.034), ('gine', 0.034), ('convergence', 0.034), ('oracle', 0.033), ('minh', 0.031), ('massart', 0.031), ('satis', 0.031), ('functions', 0.031), ('sign', 0.031), ('minimizes', 0.03), ('assumption', 0.03), ('svm', 0.03), ('minf', 0.029), ('nec', 0.029), ('veri', 0.029), ('minimization', 0.028), ('exists', 0.028), ('appendix', 0.027), ('shattered', 0.027), ('laboratories', 0.027), ('arg', 0.026), ('constant', 0.024), ('empirical', 0.023), ('derivations', 0.023), ('training', 0.023), ('inequalities', 0.022), ('version', 0.021), ('theorem', 0.021), ('fast', 0.021), ('excess', 0.02), ('ht', 0.02), ('holds', 0.02), ('outline', 0.02), ('hard', 0.019), ('let', 0.019), ('princeton', 0.018), ('condition', 0.018), ('upper', 0.018), ('assumptions', 0.018), ('additional', 0.018), ('xor', 0.017), ('hy', 0.017), ('lowing', 0.017), ('devroye', 0.017), ('nato', 0.017), ('saint', 0.017), ('minimal', 0.017), ('minimizer', 0.017), ('classi', 0.016), ('losses', 0.016), ('faster', 0.016), ('axis', 0.016), ('concluded', 0.016), ('dichotomy', 0.016), ('accelerating', 0.016), ('dmitry', 0.016), ('wellknown', 0.016), ('least', 0.015), ('annals', 0.015), ('nj', 0.015), ('caused', 0.015), ('realvalued', 0.015)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="191-tfidf-1" href="./nips-2010-On_the_Theory_of_Learnining_with_Privileged_Information.html">191 nips-2010-On the Theory of Learnining with Privileged Information</a></p>
<p>Author: Dmitry Pechyony, Vladimir Vapnik</p><p>Abstract: In Learning Using Privileged Information (LUPI) paradigm, along with the standard training data in the decision space, a teacher supplies a learner with the privileged information in the correcting space. The goal of the learner is to ﬁnd a classiﬁer with a low generalization error in the decision space. We consider an empirical risk minimization algorithm, called Privileged ERM, that takes into account the privileged information in order to ﬁnd a good function in the decision space. We outline the conditions on the correcting space that, if satisﬁed, allow Privileged ERM to have much faster learning rate in the decision space than the one of the regular empirical risk minimization. 1</p><p>2 0.20512016 <a title="191-tfidf-2" href="./nips-2010-Smoothness%2C_Low_Noise_and_Fast_Rates.html">243 nips-2010-Smoothness, Low Noise and Fast Rates</a></p>
<p>Author: Nathan Srebro, Karthik Sridharan, Ambuj Tewari</p><p>Abstract: √ ˜ We establish an excess risk bound of O HR2 + HL∗ Rn for ERM with an H-smooth loss n function and a hypothesis class with Rademacher complexity Rn , where L∗ is the best risk achievable by the hypothesis class. For typical hypothesis classes where Rn = R/n, this translates to ˜ ˜ a learning rate of O (RH/n) in the separable (L∗ = 0) case and O RH/n + L∗ RH/n more generally. We also provide similar guarantees for online and stochastic convex optimization of a smooth non-negative objective. 1</p><p>3 0.11614726 <a title="191-tfidf-3" href="./nips-2010-Tight_Sample_Complexity_of_Large-Margin_Learning.html">270 nips-2010-Tight Sample Complexity of Large-Margin Learning</a></p>
<p>Author: Sivan Sabato, Nathan Srebro, Naftali Tishby</p><p>Abstract: We obtain a tight distribution-speciﬁc characterization of the sample complexity of large-margin classiﬁcation with L2 regularization: We introduce the γ-adapted-dimension, which is a simple function of the spectrum of a distribution’s covariance matrix, and show distribution-speciﬁc upper and lower bounds on the sample complexity, both governed by the γ-adapted-dimension of the source distribution. We conclude that this new quantity tightly characterizes the true sample complexity of large-margin classiﬁcation. The bounds hold for a rich family of sub-Gaussian distributions. 1</p><p>4 0.10748369 <a title="191-tfidf-4" href="./nips-2010-Agnostic_Active_Learning_Without_Constraints.html">27 nips-2010-Agnostic Active Learning Without Constraints</a></p>
<p>Author: Alina Beygelzimer, John Langford, Zhang Tong, Daniel J. Hsu</p><p>Abstract: We present and analyze an agnostic active learning algorithm that works without keeping a version space. This is unlike all previous approaches where a restricted set of candidate hypotheses is maintained throughout learning, and only hypotheses from this set are ever returned. By avoiding this version space approach, our algorithm sheds the computational burden and brittleness associated with maintaining version spaces, yet still allows for substantial improvements over supervised learning for classiﬁcation. 1</p><p>5 0.07966274 <a title="191-tfidf-5" href="./nips-2010-Random_Walk_Approach_to_Regret_Minimization.html">222 nips-2010-Random Walk Approach to Regret Minimization</a></p>
<p>Author: Hariharan Narayanan, Alexander Rakhlin</p><p>Abstract: We propose a computationally efﬁcient random walk on a convex body which rapidly mixes to a time-varying Gibbs distribution. In the setting of online convex optimization and repeated games, the algorithm yields low regret and presents a novel efﬁcient method for implementing mixture forecasting strategies. 1</p><p>6 0.076612696 <a title="191-tfidf-6" href="./nips-2010-Bootstrapping_Apprenticeship_Learning.html">43 nips-2010-Bootstrapping Apprenticeship Learning</a></p>
<p>7 0.076001577 <a title="191-tfidf-7" href="./nips-2010-Active_Estimation_of_F-Measures.html">22 nips-2010-Active Estimation of F-Measures</a></p>
<p>8 0.075583048 <a title="191-tfidf-8" href="./nips-2010-Throttling_Poisson_Processes.html">269 nips-2010-Throttling Poisson Processes</a></p>
<p>9 0.074664973 <a title="191-tfidf-9" href="./nips-2010-Sample_Complexity_of_Testing_the_Manifold_Hypothesis.html">232 nips-2010-Sample Complexity of Testing the Manifold Hypothesis</a></p>
<p>10 0.073898666 <a title="191-tfidf-10" href="./nips-2010-Variable_margin_losses_for_classifier_design.html">282 nips-2010-Variable margin losses for classifier design</a></p>
<p>11 0.068832435 <a title="191-tfidf-11" href="./nips-2010-Empirical_Risk_Minimization_with_Approximations_of_Probabilistic_Grammars.html">75 nips-2010-Empirical Risk Minimization with Approximations of Probabilistic Grammars</a></p>
<p>12 0.066845089 <a title="191-tfidf-12" href="./nips-2010-Learning_Bounds_for_Importance_Weighting.html">142 nips-2010-Learning Bounds for Importance Weighting</a></p>
<p>13 0.06307818 <a title="191-tfidf-13" href="./nips-2010-Relaxed_Clipping%3A_A_Global_Training_Method_for_Robust_Regression_and_Classification.html">225 nips-2010-Relaxed Clipping: A Global Training Method for Robust Regression and Classification</a></p>
<p>14 0.062824719 <a title="191-tfidf-14" href="./nips-2010-Supervised_Clustering.html">261 nips-2010-Supervised Clustering</a></p>
<p>15 0.059995942 <a title="191-tfidf-15" href="./nips-2010-More_data_means_less_inference%3A_A_pseudo-max_approach_to_structured_learning.html">169 nips-2010-More data means less inference: A pseudo-max approach to structured learning</a></p>
<p>16 0.058076195 <a title="191-tfidf-16" href="./nips-2010-Permutation_Complexity_Bound_on_Out-Sample_Error.html">205 nips-2010-Permutation Complexity Bound on Out-Sample Error</a></p>
<p>17 0.054579619 <a title="191-tfidf-17" href="./nips-2010-Semi-Supervised_Learning_with_Adversarially_Missing_Label_Information.html">236 nips-2010-Semi-Supervised Learning with Adversarially Missing Label Information</a></p>
<p>18 0.051680423 <a title="191-tfidf-18" href="./nips-2010-Spectral_Regularization_for_Support_Estimation.html">250 nips-2010-Spectral Regularization for Support Estimation</a></p>
<p>19 0.051636193 <a title="191-tfidf-19" href="./nips-2010-Online_Learning%3A_Random_Averages%2C_Combinatorial_Parameters%2C_and_Learnability.html">193 nips-2010-Online Learning: Random Averages, Combinatorial Parameters, and Learnability</a></p>
<p>20 0.050915819 <a title="191-tfidf-20" href="./nips-2010-Convex_Multiple-Instance_Learning_by_Estimating_Likelihood_Ratio.html">52 nips-2010-Convex Multiple-Instance Learning by Estimating Likelihood Ratio</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.142), (1, 0.002), (2, 0.143), (3, 0.002), (4, 0.059), (5, 0.094), (6, -0.107), (7, -0.063), (8, -0.018), (9, -0.033), (10, -0.005), (11, -0.102), (12, -0.083), (13, -0.023), (14, -0.077), (15, 0.02), (16, 0.104), (17, 0.011), (18, 0.028), (19, -0.038), (20, 0.067), (21, -0.035), (22, 0.031), (23, 0.005), (24, 0.039), (25, 0.012), (26, -0.054), (27, 0.045), (28, 0.147), (29, 0.019), (30, 0.022), (31, 0.021), (32, 0.01), (33, -0.018), (34, 0.032), (35, -0.04), (36, 0.035), (37, -0.033), (38, 0.066), (39, -0.008), (40, -0.034), (41, -0.02), (42, 0.05), (43, 0.01), (44, -0.052), (45, 0.075), (46, 0.023), (47, 0.126), (48, -0.045), (49, 0.071)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92809272 <a title="191-lsi-1" href="./nips-2010-On_the_Theory_of_Learnining_with_Privileged_Information.html">191 nips-2010-On the Theory of Learnining with Privileged Information</a></p>
<p>Author: Dmitry Pechyony, Vladimir Vapnik</p><p>Abstract: In Learning Using Privileged Information (LUPI) paradigm, along with the standard training data in the decision space, a teacher supplies a learner with the privileged information in the correcting space. The goal of the learner is to ﬁnd a classiﬁer with a low generalization error in the decision space. We consider an empirical risk minimization algorithm, called Privileged ERM, that takes into account the privileged information in order to ﬁnd a good function in the decision space. We outline the conditions on the correcting space that, if satisﬁed, allow Privileged ERM to have much faster learning rate in the decision space than the one of the regular empirical risk minimization. 1</p><p>2 0.82478929 <a title="191-lsi-2" href="./nips-2010-Smoothness%2C_Low_Noise_and_Fast_Rates.html">243 nips-2010-Smoothness, Low Noise and Fast Rates</a></p>
<p>Author: Nathan Srebro, Karthik Sridharan, Ambuj Tewari</p><p>Abstract: √ ˜ We establish an excess risk bound of O HR2 + HL∗ Rn for ERM with an H-smooth loss n function and a hypothesis class with Rademacher complexity Rn , where L∗ is the best risk achievable by the hypothesis class. For typical hypothesis classes where Rn = R/n, this translates to ˜ ˜ a learning rate of O (RH/n) in the separable (L∗ = 0) case and O RH/n + L∗ RH/n more generally. We also provide similar guarantees for online and stochastic convex optimization of a smooth non-negative objective. 1</p><p>3 0.75085503 <a title="191-lsi-3" href="./nips-2010-Tight_Sample_Complexity_of_Large-Margin_Learning.html">270 nips-2010-Tight Sample Complexity of Large-Margin Learning</a></p>
<p>Author: Sivan Sabato, Nathan Srebro, Naftali Tishby</p><p>Abstract: We obtain a tight distribution-speciﬁc characterization of the sample complexity of large-margin classiﬁcation with L2 regularization: We introduce the γ-adapted-dimension, which is a simple function of the spectrum of a distribution’s covariance matrix, and show distribution-speciﬁc upper and lower bounds on the sample complexity, both governed by the γ-adapted-dimension of the source distribution. We conclude that this new quantity tightly characterizes the true sample complexity of large-margin classiﬁcation. The bounds hold for a rich family of sub-Gaussian distributions. 1</p><p>4 0.7255097 <a title="191-lsi-4" href="./nips-2010-Learning_Bounds_for_Importance_Weighting.html">142 nips-2010-Learning Bounds for Importance Weighting</a></p>
<p>Author: Corinna Cortes, Yishay Mansour, Mehryar Mohri</p><p>Abstract: This paper presents an analysis of importance weighting for learning from ﬁnite samples and gives a series of theoretical and algorithmic results. We point out simple cases where importance weighting can fail, which suggests the need for an analysis of the properties of this technique. We then give both upper and lower bounds for generalization with bounded importance weights and, more signiﬁcantly, give learning guarantees for the more common case of unbounded importance weights under the weak assumption that the second moment is bounded, a condition related to the R´ nyi divergence of the training and test distributions. e These results are based on a series of novel and general bounds we derive for unbounded loss functions, which are of independent interest. We use these bounds to guide the deﬁnition of an alternative reweighting algorithm and report the results of experiments demonstrating its beneﬁts. Finally, we analyze the properties of normalized importance weights which are also commonly used.</p><p>5 0.66760659 <a title="191-lsi-5" href="./nips-2010-Permutation_Complexity_Bound_on_Out-Sample_Error.html">205 nips-2010-Permutation Complexity Bound on Out-Sample Error</a></p>
<p>Author: Malik Magdon-Ismail</p><p>Abstract: We deﬁne a data dependent permutation complexity for a hypothesis set H, which is similar to a Rademacher complexity or maximum discrepancy. The permutation complexity is based (like the maximum discrepancy) on dependent sampling. We prove a uniform bound on the generalization error, as well as a concentration result which means that the permutation estimate can be efﬁciently estimated.</p><p>6 0.64925879 <a title="191-lsi-6" href="./nips-2010-Agnostic_Active_Learning_Without_Constraints.html">27 nips-2010-Agnostic Active Learning Without Constraints</a></p>
<p>7 0.63116866 <a title="191-lsi-7" href="./nips-2010-Sample_Complexity_of_Testing_the_Manifold_Hypothesis.html">232 nips-2010-Sample Complexity of Testing the Manifold Hypothesis</a></p>
<p>8 0.56637388 <a title="191-lsi-8" href="./nips-2010-Variable_margin_losses_for_classifier_design.html">282 nips-2010-Variable margin losses for classifier design</a></p>
<p>9 0.56596756 <a title="191-lsi-9" href="./nips-2010-Active_Estimation_of_F-Measures.html">22 nips-2010-Active Estimation of F-Measures</a></p>
<p>10 0.5473578 <a title="191-lsi-10" href="./nips-2010-Lower_Bounds_on_Rate_of_Convergence_of_Cutting_Plane_Methods.html">163 nips-2010-Lower Bounds on Rate of Convergence of Cutting Plane Methods</a></p>
<p>11 0.53370583 <a title="191-lsi-11" href="./nips-2010-Empirical_Risk_Minimization_with_Approximations_of_Probabilistic_Grammars.html">75 nips-2010-Empirical Risk Minimization with Approximations of Probabilistic Grammars</a></p>
<p>12 0.5036189 <a title="191-lsi-12" href="./nips-2010-Relaxed_Clipping%3A_A_Global_Training_Method_for_Robust_Regression_and_Classification.html">225 nips-2010-Relaxed Clipping: A Global Training Method for Robust Regression and Classification</a></p>
<p>13 0.5018658 <a title="191-lsi-13" href="./nips-2010-Multi-View_Active_Learning_in_the_Non-Realizable_Case.html">173 nips-2010-Multi-View Active Learning in the Non-Realizable Case</a></p>
<p>14 0.49214104 <a title="191-lsi-14" href="./nips-2010-Scrambled_Objects_for_Least-Squares_Regression.html">233 nips-2010-Scrambled Objects for Least-Squares Regression</a></p>
<p>15 0.47901285 <a title="191-lsi-15" href="./nips-2010-t-logistic_regression.html">290 nips-2010-t-logistic regression</a></p>
<p>16 0.47147509 <a title="191-lsi-16" href="./nips-2010-Universal_Consistency_of_Multi-Class_Support_Vector_Classification.html">278 nips-2010-Universal Consistency of Multi-Class Support Vector Classification</a></p>
<p>17 0.46577865 <a title="191-lsi-17" href="./nips-2010-Throttling_Poisson_Processes.html">269 nips-2010-Throttling Poisson Processes</a></p>
<p>18 0.46050602 <a title="191-lsi-18" href="./nips-2010-Fast_global_convergence_rates_of_gradient_methods_for_high-dimensional_statistical_recovery.html">92 nips-2010-Fast global convergence rates of gradient methods for high-dimensional statistical recovery</a></p>
<p>19 0.45180291 <a title="191-lsi-19" href="./nips-2010-Online_Learning%3A_Random_Averages%2C_Combinatorial_Parameters%2C_and_Learnability.html">193 nips-2010-Online Learning: Random Averages, Combinatorial Parameters, and Learnability</a></p>
<p>20 0.43969941 <a title="191-lsi-20" href="./nips-2010-Semi-Supervised_Learning_with_Adversarially_Missing_Label_Information.html">236 nips-2010-Semi-Supervised Learning with Adversarially Missing Label Information</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.042), (14, 0.304), (27, 0.024), (30, 0.053), (45, 0.186), (50, 0.026), (52, 0.034), (60, 0.062), (77, 0.055), (78, 0.027), (90, 0.072)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.74630094 <a title="191-lda-1" href="./nips-2010-Error_Propagation_for_Approximate_Policy_and_Value_Iteration.html">78 nips-2010-Error Propagation for Approximate Policy and Value Iteration</a></p>
<p>Author: Amir-massoud Farahmand, Csaba Szepesvári, Rémi Munos</p><p>Abstract: We address the question of how the approximation error/Bellman residual at each iteration of the Approximate Policy/Value Iteration algorithms inﬂuences the quality of the resulted policy. We quantify the performance loss as the Lp norm of the approximation error/Bellman residual at each iteration. Moreover, we show that the performance loss depends on the expectation of the squared Radon-Nikodym derivative of a certain distribution rather than its supremum – as opposed to what has been suggested by the previous results. Also our results indicate that the contribution of the approximation/Bellman error to the performance loss is more prominent in the later iterations of API/AVI, and the effect of an error term in the earlier iterations decays exponentially fast. 1</p><p>same-paper 2 0.72510517 <a title="191-lda-2" href="./nips-2010-On_the_Theory_of_Learnining_with_Privileged_Information.html">191 nips-2010-On the Theory of Learnining with Privileged Information</a></p>
<p>Author: Dmitry Pechyony, Vladimir Vapnik</p><p>Abstract: In Learning Using Privileged Information (LUPI) paradigm, along with the standard training data in the decision space, a teacher supplies a learner with the privileged information in the correcting space. The goal of the learner is to ﬁnd a classiﬁer with a low generalization error in the decision space. We consider an empirical risk minimization algorithm, called Privileged ERM, that takes into account the privileged information in order to ﬁnd a good function in the decision space. We outline the conditions on the correcting space that, if satisﬁed, allow Privileged ERM to have much faster learning rate in the decision space than the one of the regular empirical risk minimization. 1</p><p>3 0.58394533 <a title="191-lda-3" href="./nips-2010-Smoothness%2C_Low_Noise_and_Fast_Rates.html">243 nips-2010-Smoothness, Low Noise and Fast Rates</a></p>
<p>Author: Nathan Srebro, Karthik Sridharan, Ambuj Tewari</p><p>Abstract: √ ˜ We establish an excess risk bound of O HR2 + HL∗ Rn for ERM with an H-smooth loss n function and a hypothesis class with Rademacher complexity Rn , where L∗ is the best risk achievable by the hypothesis class. For typical hypothesis classes where Rn = R/n, this translates to ˜ ˜ a learning rate of O (RH/n) in the separable (L∗ = 0) case and O RH/n + L∗ RH/n more generally. We also provide similar guarantees for online and stochastic convex optimization of a smooth non-negative objective. 1</p><p>4 0.58245468 <a title="191-lda-4" href="./nips-2010-Variable_margin_losses_for_classifier_design.html">282 nips-2010-Variable margin losses for classifier design</a></p>
<p>Author: Hamed Masnadi-shirazi, Nuno Vasconcelos</p><p>Abstract: The problem of controlling the margin of a classiﬁer is studied. A detailed analytical study is presented on how properties of the classiﬁcation risk, such as its optimal link and minimum risk functions, are related to the shape of the loss, and its margin enforcing properties. It is shown that for a class of risks, denoted canonical risks, asymptotic Bayes consistency is compatible with simple analytical relationships between these functions. These enable a precise characterization of the loss for a popular class of link functions. It is shown that, when the risk is in canonical form and the link is inverse sigmoidal, the margin properties of the loss are determined by a single parameter. Novel families of Bayes consistent loss functions, of variable margin, are derived. These families are then used to design boosting style algorithms with explicit control of the classiﬁcation margin. The new algorithms generalize well established approaches, such as LogitBoost. Experimental results show that the proposed variable margin losses outperform the ﬁxed margin counterparts used by existing algorithms. Finally, it is shown that best performance can be achieved by cross-validating the margin parameter. 1</p><p>5 0.58137387 <a title="191-lda-5" href="./nips-2010-Online_Learning%3A_Random_Averages%2C_Combinatorial_Parameters%2C_and_Learnability.html">193 nips-2010-Online Learning: Random Averages, Combinatorial Parameters, and Learnability</a></p>
<p>Author: Alexander Rakhlin, Karthik Sridharan, Ambuj Tewari</p><p>Abstract: We develop a theory of online learning by deﬁning several complexity measures. Among them are analogues of Rademacher complexity, covering numbers and fatshattering dimension from statistical learning theory. Relationship among these complexity measures, their connection to online learning, and tools for bounding them are provided. We apply these results to various learning problems. We provide a complete characterization of online learnability in the supervised setting. 1</p><p>6 0.58081347 <a title="191-lda-6" href="./nips-2010-Multivariate_Dyadic_Regression_Trees_for_Sparse_Learning_Problems.html">178 nips-2010-Multivariate Dyadic Regression Trees for Sparse Learning Problems</a></p>
<p>7 0.57979381 <a title="191-lda-7" href="./nips-2010-Fast_global_convergence_rates_of_gradient_methods_for_high-dimensional_statistical_recovery.html">92 nips-2010-Fast global convergence rates of gradient methods for high-dimensional statistical recovery</a></p>
<p>8 0.57859665 <a title="191-lda-8" href="./nips-2010-Distributed_Dual_Averaging_In_Networks.html">63 nips-2010-Distributed Dual Averaging In Networks</a></p>
<p>9 0.57842535 <a title="191-lda-9" href="./nips-2010-Optimal_learning_rates_for_Kernel_Conjugate_Gradient_regression.html">199 nips-2010-Optimal learning rates for Kernel Conjugate Gradient regression</a></p>
<p>10 0.57741642 <a title="191-lda-10" href="./nips-2010-Multi-View_Active_Learning_in_the_Non-Realizable_Case.html">173 nips-2010-Multi-View Active Learning in the Non-Realizable Case</a></p>
<p>11 0.57713932 <a title="191-lda-11" href="./nips-2010-Extended_Bayesian_Information_Criteria_for_Gaussian_Graphical_Models.html">87 nips-2010-Extended Bayesian Information Criteria for Gaussian Graphical Models</a></p>
<p>12 0.57701492 <a title="191-lda-12" href="./nips-2010-The_LASSO_risk%3A_asymptotic_results_and_real_world_examples.html">265 nips-2010-The LASSO risk: asymptotic results and real world examples</a></p>
<p>13 0.5768432 <a title="191-lda-13" href="./nips-2010-Online_Markov_Decision_Processes_under_Bandit_Feedback.html">196 nips-2010-Online Markov Decision Processes under Bandit Feedback</a></p>
<p>14 0.57670963 <a title="191-lda-14" href="./nips-2010-Joint_Cascade_Optimization_Using_A_Product_Of_Boosted_Classifiers.html">132 nips-2010-Joint Cascade Optimization Using A Product Of Boosted Classifiers</a></p>
<p>15 0.57665533 <a title="191-lda-15" href="./nips-2010-Spectral_Regularization_for_Support_Estimation.html">250 nips-2010-Spectral Regularization for Support Estimation</a></p>
<p>16 0.57624245 <a title="191-lda-16" href="./nips-2010-An_analysis_on_negative_curvature_induced_by_singularity_in_multi-layer_neural-network_learning.html">31 nips-2010-An analysis on negative curvature induced by singularity in multi-layer neural-network learning</a></p>
<p>17 0.57596797 <a title="191-lda-17" href="./nips-2010-t-logistic_regression.html">290 nips-2010-t-logistic regression</a></p>
<p>18 0.57573891 <a title="191-lda-18" href="./nips-2010-Random_Walk_Approach_to_Regret_Minimization.html">222 nips-2010-Random Walk Approach to Regret Minimization</a></p>
<p>19 0.57398444 <a title="191-lda-19" href="./nips-2010-Efficient_Optimization_for_Discriminative_Latent_Class_Models.html">70 nips-2010-Efficient Optimization for Discriminative Latent Class Models</a></p>
<p>20 0.57366699 <a title="191-lda-20" href="./nips-2010-Agnostic_Active_Learning_Without_Constraints.html">27 nips-2010-Agnostic Active Learning Without Constraints</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
