<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>253 nips-2010-Spike timing-dependent plasticity as dynamic filter</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-253" href="#">nips2010-253</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>253 nips-2010-Spike timing-dependent plasticity as dynamic filter</h1>
<br/><p>Source: <a title="nips-2010-253-pdf" href="http://papers.nips.cc/paper/3917-spike-timing-dependent-plasticity-as-dynamic-filter.pdf">pdf</a></p><p>Author: Joscha Schmiedt, Christian Albers, Klaus Pawelzik</p><p>Abstract: When stimulated with complex action potential sequences synapses exhibit spike timing-dependent plasticity (STDP) with modulated pre- and postsynaptic contributions to long-term synaptic modiﬁcations. In order to investigate the functional consequences of these contribution dynamics (CD) we propose a minimal model formulated in terms of differential equations. We ﬁnd that our model reproduces data from to recent experimental studies with a small number of biophysically interpretable parameters. The model allows to investigate the susceptibility of STDP to arbitrary time courses of pre- and postsynaptic activities, i.e. its nonlinear ﬁlter properties. We demonstrate this for the simple example of small periodic modulations of pre- and postsynaptic ﬁring rates for which our model can be solved. It predicts synaptic strengthening for synchronous rate modulations. Modiﬁcations are dominant in the theta frequency range, a result which underlines the well known relevance of theta activities in hippocampus and cortex for learning. We also ﬁnd emphasis of speciﬁc baseline spike rates and suppression for high background rates. The latter suggests a mechanism of network activity regulation inherent in STDP. Furthermore, our novel formulation provides a general framework for investigating the joint dynamics of neuronal activity and the CD of STDP in both spike-based as well as rate-based neuronal network models. 1</p><p>Reference: <a title="nips-2010-253-reference" href="../nips2010_reference/nips-2010-Spike_timing-dependent_plasticity_as_dynamic_filter_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 de  Abstract When stimulated with complex action potential sequences synapses exhibit spike timing-dependent plasticity (STDP) with modulated pre- and postsynaptic contributions to long-term synaptic modiﬁcations. [sent-5, score-1.3]
</p><p>2 In order to investigate the functional consequences of these contribution dynamics (CD) we propose a minimal model formulated in terms of differential equations. [sent-6, score-0.144]
</p><p>3 The model allows to investigate the susceptibility of STDP to arbitrary time courses of pre- and postsynaptic activities, i. [sent-8, score-0.574]
</p><p>4 We demonstrate this for the simple example of small periodic modulations of pre- and postsynaptic ﬁring rates for which our model can be solved. [sent-11, score-0.699]
</p><p>5 Modiﬁcations are dominant in the theta frequency range, a result which underlines the well known relevance of theta activities in hippocampus and cortex for learning. [sent-13, score-0.55]
</p><p>6 We also ﬁnd emphasis of speciﬁc baseline spike rates and suppression for high background rates. [sent-14, score-0.39]
</p><p>7 The latter suggests a mechanism of network activity regulation inherent in STDP. [sent-15, score-0.114]
</p><p>8 Furthermore, our novel formulation provides a general framework for investigating the joint dynamics of neuronal activity and the CD of STDP in both spike-based as well as rate-based neuronal network models. [sent-16, score-0.215]
</p><p>9 1  Introduction  During the past decade the effects of exact spike timing on the change of synaptic connectivity have been studied extensively. [sent-17, score-0.706]
</p><p>10 In vitro studies have shown that the induction of long-term potentiation (LTP) requires the presynaptic input to a cell to precede the postsynaptic output and vice versa for long-term depression (LTD) (see [1, 2, 3]). [sent-18, score-0.803]
</p><p>11 This phenomenon has been termed spike timingdependent plasticity (STDP) and emphasizes the importance of a causal order in neuronal signaling. [sent-19, score-0.388]
</p><p>12 Thereby it extends pure Hebbian learning, which requires only the coincidence of pre- and postsynaptic activity. [sent-20, score-0.55]
</p><p>13 Consequently, experiments have shown an asymmetric exponential dependence on the timing of spike pairs and a molecular mechanism mostly dependent on the inﬂux of Ca2+ (see [4, 5] for reviews). [sent-21, score-0.374]
</p><p>14 Further, when induced with more complex spike trains, synaptic modiﬁcation shows nonlinearities ([6, 7, 8]) indicating the inﬂuence of short-term plasticity. [sent-22, score-0.684]
</p><p>15 Theoretical approaches to STDP cover studies using the asymmetric pair-based STDP window as a lookup table, more biophysical models based on synaptic and neuronal variables, and sophisticated kinetic models (for a review see [9]). [sent-23, score-0.492]
</p><p>16 Recently, the experimentally observed inﬂuence of the postsynaptic membrane potential (e. [sent-24, score-0.553]
</p><p>17 We extend it with a mechanism for activating learning by an increase in postsynaptic activity, because both the induction of LTP and LTD require [Ca2+ ] to exceed a threshold ([16]). [sent-29, score-0.567]
</p><p>18 Moreover, we include a mechanism for adaptive suppression on both synaptic sides, similar to the model in [7]. [sent-30, score-0.434]
</p><p>19 Finally, we for simplicity assume that both the presynaptic and the postsynaptic side function as low-pass ﬁlters; a spike leaves a fast increasing and exponentially decaying trace. [sent-31, score-0.948]
</p><p>20 Together, we propose a set of differential equations, which captures the contribution dynamics (CD) of pre- and postsynaptic activities to STDP, thereby describing synaptic plasticity as a ﬁlter. [sent-32, score-1.165]
</p><p>21 Our framework reproduces experimental ﬁndings from two recent in vitro studies in the visual cortex and the hippocampus in most details. [sent-33, score-0.367]
</p><p>22 Furthermore, it proves to be particularly suitable for the analysis of the susceptibility of STDP to pre- and postsynaptic rate modulations. [sent-34, score-0.583]
</p><p>23 This is demonstrated by an analysis of synaptic changes depending on oscillatory modulations of baseline ﬁring rates. [sent-35, score-0.618]
</p><p>24 2  Formulation of the model  We use a variant of the classical differential Hebbian learning assuming a change of synaptic connectivity w, which is dependent on the presynaptic activity trace ypre and the temporal derivative of the postsynaptic activity trace ypost : w(t) = cw ypre (t)ypost (t) . [sent-36, score-1.872]
</p><p>25 An illustration of this learning rule for pairs of spikes is given in Figure 1B. [sent-38, score-0.108]
</p><p>26 For simplicity, we assume these activity traces to be abstract low-pass ﬁltered versions of neuronal activity x in the presynaptic and postsynaptic cells, e. [sent-39, score-0.914]
</p><p>27 the concentration of Ca2+ or the amount of bound glutamate: ypre (t) τpre ypost (t) ypost (t) = upost (t)z(t) · xpost (t) − ˙ . [sent-41, score-0.563]
</p><p>28 τpost ypre (t) = upre (t) · xpre (t) − ˙  (2) (3)  The dynamics of the y’s are characterized by their respective time constants τpre and τpost . [sent-42, score-0.315]
</p><p>29 The contribution of each spike is regulated by a suppressing attenuation factor u pre- and postsynaptically. [sent-43, score-0.38]
</p><p>30 x represents neuronal activity which can be either a time-continuous ﬁring rate or spike trains given by series of δ pulses xpre, post (t) = i  δ(t − ti post ) , pre,  (4)  which allows analytical investigations of the properties of our model. [sent-46, score-0.831]
</p><p>31 We deﬁne the relative change of synaptic connectivity after after a period T from Equation (1) as ∆w =  cw w(t0 + T ) −1= w(t0 ) w(t0 )  ypre ypost dt . [sent-49, score-0.772]
</p><p>32 ˙  (5)  T  The dependence on the initial synaptic strength w(t0 ) as observed in [3, 8] shall not be discussed here, but can easily be achieved by making the learning rate cw in Equation (1) w-dependent. [sent-50, score-0.518]
</p><p>33 A: Pre- and postsynaptic activity (x, second column) is modulated (attenuated with u, activated with z, ﬁrst column) and ﬁltered (y, third column) before it contributes to differential Hebbian learning (w, fourth column). [sent-53, score-0.705]
</p><p>34 Left: a presynaptic spike trace (ypre ) preceding a postsynaptic spike trace (ypost , dotted line) yields a synaptic strengthening due to the initially positive postsynaptic contribution (ypost , solid line), which is always stronger ˙ than the following negative part. [sent-55, score-2.23]
</p><p>35 Right: for the reverse timing the positive presynaptic contribution is only multiplied with the negative postsynaptic trace (right). [sent-56, score-0.796]
</p><p>36 The importance of adaptive suppressing mechanisms for synaptic plasticity has experimentally been shown by Froemke and colleagues ([7, 6]). [sent-58, score-0.486]
</p><p>37 Therefore, we down-regulate the contribution of the spikes to the activity traces y in Equation (2) and (3) with an attenuation factor u on both pre- and postsynaptic sides: 1 (1 − upre ) − cpre upre xpre rec τpre 1 = rec (1 − upost ) − cpost (upost − u0 )xpost τpost  upre = ˙ upost ˙  (7) . [sent-59, score-1.446]
</p><p>38 (8)  This should be understood as an abstract representation of for instance the depletion of transmitters in the presynaptic bouton ([17]) or the frequency-dependent spike attenuation in dendritic spines ([18]), respectively. [sent-60, score-0.527]
</p><p>39 3  For the presynaptic side we assume in the following upre = 0, so we abbreviate u0 = upost . [sent-62, score-0.295]
</p><p>40 The 0 0 constants cpre, post ∈ [0, 1] denote the impact a spike has on the relaxed synapse. [sent-63, score-0.46]
</p><p>41 In several experiments it has been shown that a single spike is not sufﬁcient to induce synaptic modiﬁcation ([10, 8]). [sent-64, score-0.63]
</p><p>42 Therefore, we introduce a spike-induced postsynaptic activation factor z z = cact xpost z − α(z − z0 )2 , ˙  (9)  which enhances the contribution of a postsynaptic spike to the postsynaptic trace, e. [sent-65, score-2.016]
</p><p>43 by the removal of the Mg2+ block from postsynaptic NMDA receptors ([19, 5]). [sent-67, score-0.529]
</p><p>44 The activation z decays hyperbolically to a lower bound z0 and the contribution of a spike is weighted with the constant cact . [sent-69, score-0.36]
</p><p>45 3  Comparison to experiments  In order to evaluate our model we implemented experimental stimulation protocols from in vitro studies on synapses of the visual cortex ([7]) and the hippocampus ([8]) of rats. [sent-70, score-0.396]
</p><p>46 In both studies, simple pairs of spikes and more complex spike trains were artiﬁcially elicited in the presynaptic and the postsynaptic cell and the induced change of synaptic connectivity was recorded. [sent-71, score-1.523]
</p><p>47 Froemke and colleagues ([7]) focused on the effects of spike bursts on synaptic modiﬁcation in the visual cortex. [sent-72, score-0.735]
</p><p>48 4  0  1  2  3  4  5  Presynaptic spikes  1  2  3  4  5  Postsynaptic spikes  Figure 2: Differential Hebbian learning with CD reproduces synaptic modiﬁcation induced with STDP spike patterns in visual cortex. [sent-89, score-0.953]
</p><p>49 B: dependence of synaptic modiﬁcations on the frequency of 5-5 bursts with presynaptic spikes following postsynaptic spikes by 6 ms. [sent-92, score-1.369]
</p><p>50 C, D and E: synaptic modiﬁcation induced by post-n-pre, n-pre-post and post-pre-n-post 100 Hz spike trains. [sent-93, score-0.663]
</p><p>51 1 (5,5)  (10,10)  (15,5)  0  (5,15)  (5,5)  Interspike interval (ms)  (10,10)  (15,5)  (5,15)  Interspike interval (ms)  Figure 3: Differential Hebbian learning with CD reproduces synaptic modiﬁcation induced with STDP spike patterns in hippocampus. [sent-106, score-0.708]
</p><p>52 C and D: post-pre-post and pre-post-pre triplet protocol for different interspike intervals. [sent-110, score-0.104]
</p><p>53 Table 1: Parameters and evaluation results for the data sets from visual cortex ([7]) and hippocampus ([8]). [sent-111, score-0.268]
</p><p>54 E: normalized mean-square error, S: ratio of correctly predicted signs of synaptic modiﬁcation. [sent-112, score-0.368]
</p><p>55 cpre  cpost  cact  rec τpre [s]  rec τpost [s]  α  u0  z0  E  S  Visual cortex  0. [sent-113, score-0.292]
</p><p>56 16  10/11  In the hippocampal study of Wang et al. [sent-126, score-0.088]
</p><p>57 ([8]) synaptic modiﬁcation induced by triplets (pre-post-pre and post-pre-post) and quadruplets (pre-post-post-pre and post-pre-pre-post) of spikes was measured while the respective interspike intervals were varied. [sent-127, score-0.615]
</p><p>58 Next, we chose the learning rate cw in Equation (6) to ﬁt the synaptic change for the pairing protocol: (1) cw = 1. [sent-135, score-0.618]
</p><p>59 The model was then applied to the more complex stimulation protocols by solving the differential equations semi-analytically, i. [sent-139, score-0.106]
</p><p>60 separately for every spike and the following interspike interval. [sent-141, score-0.344]
</p><p>61 Additionally we counted the number of correctly predicted signs S of synaptic modiﬁcation, i. [sent-144, score-0.368]
</p><p>62 )  0  -�/2  Hippocampus x0 = 1�Hz  -�/2  -�  1  3  7  -�  20 50 100  1  3  7  20 50 100  Modulation frequency f [Hz] Figure 4: Synaptic change depending on frequency f and phase shift ∆φ of pre- and postsynaptic rate modulations for different baseline rates x0 . [sent-150, score-0.94]
</p><p>63 Note the strong suppression with increasing baseline rate for cortical synapses which is due to strong attenuation effects of pre- and postsynaptic contributions. [sent-152, score-0.801]
</p><p>64 It is weaker for hippocampal synapses because we found the postsynaptic attenuation to be bounded (u0 = 0. [sent-153, score-0.746]
</p><p>65 4  Phase, frequency and baseline rate dependence of STDP with contribution dynamics  As shown in the previous section our model can reproduce the experimental ﬁndings of synaptic weight changes in response to spike sequences surprisingly well and yields better ﬁts than former studies (e. [sent-155, score-0.923]
</p><p>66 The proposed framework, however, is not restricted to spike sequences but allows to investigate synaptic changes depending on arbitrary pre- and postsynaptic activities. [sent-158, score-1.235]
</p><p>67 For instance it could be used for investigations of the plasticity effects in simulations with inhomogeneous Poisson processes. [sent-159, score-0.094]
</p><p>68 Taking x(t) to be ﬁring rates of Poissonian spike trains our account of STDP represents a useful approximation for the expected changes of synaptic strength depending on the time courses of xpre and xpost (compare e. [sent-160, score-0.969]
</p><p>69 Therefore our model can serve also as building block in rate based network models for investigation of the joint dynamics of neuronal activities and synaptic weights. [sent-163, score-0.535]
</p><p>70 we use the equations together with the parameters from the experiments for determining the dependency of weight changes on frequency, relative phase ∆φ and baseline rates of modulated pre- and postsynaptic ﬁring rates. [sent-166, score-0.781]
</p><p>71 While for substantial modulations of ﬁring rates the nonlinearities are difﬁcult to be treated analytically, for small periodical modulations around a baseline rate x0 the corresponding synaptic changes can be calculated analytically. [sent-167, score-0.818]
</p><p>72 This is done by considering xpre (t) = x0 + ε cos(2πf t) and  xpost (t) = x0 + ε cos(2πf t − ∆φ) ,  (11)  which for small ε < x0 allows linearization of all equations from which one obtains ∆W = ∆w/(T εpre εpost ), where T = 1/f = 2π/ω is the period of the respective oscillations. [sent-168, score-0.138]
</p><p>73 Numerical simulations with ﬁnite rate modulations were found to conﬁrm these analytical predictions surprisingly well. [sent-174, score-0.152]
</p><p>74 Also for the nonlinear regime and Poissionian spike trains deviations remained moderate. [sent-175, score-0.297]
</p><p>75 Here, we here formulated a minimal, yet biologically plausible model including the dynamics of how neuronal activity contributes to STDP. [sent-178, score-0.162]
</p><p>76 We found that our model reproduces the synaptic changes in response to spike sequences in experiments in cortex and hippocampus with high accuracy. [sent-179, score-0.969]
</p><p>77 Using the corresponding parameters our model predicts weight changes depending on temporal structures in the pre- and postsynaptic activities including spike sequences and varying ﬁring rates. [sent-180, score-0.942]
</p><p>78 When applied to pre- and postsynaptic rate modulations our approach quantiﬁes synaptic changes depending on frequency and phase shifts between pre- and postsynaptic activities. [sent-181, score-1.748]
</p><p>79 A rigorous perturbation analysis of our model reveals that the dynamical ﬁlter properties of STDP make weight changes sensitively dependent on combinations of speciﬁc features of pre- and postsynaptic signals. [sent-182, score-0.608]
</p><p>80 In particular, our analysis indicates that both cortical as well as hippocampal STDP is most susceptible for modulations in the theta frequency range. [sent-183, score-0.395]
</p><p>81 It predicts the dependency of synaptic changes on pre- and postsynaptic phase relations of rate modulations. [sent-184, score-1.032]
</p><p>82 These results are in line with experimental results on the relation of theta rhythms and learning. [sent-185, score-0.108]
</p><p>83 For instance in hippocampus it is well established that theta oscillations are relevant for learning (for a recent paper see [28]). [sent-186, score-0.295]
</p><p>84 Furthermore, spike activities in hippocampus exhibit speciﬁc phase relations with the theta rhythm (for a review see [29]). [sent-187, score-0.637]
</p><p>85 Also, it has been found that during learning cortex and hippocampus tend to synchronize with particular phase relations that depend on the novelty of the item to be learned ([30]). [sent-188, score-0.289]
</p><p>86 The results presented here underline these ﬁndings and make testable predictions for the corresponding synaptic changes. [sent-189, score-0.368]
</p><p>87 Also, we ﬁnd potentiation for zero phase differences and strong attenuation of weight changes at large baseline rates which is particularly strong for cortical synapses. [sent-190, score-0.387]
</p><p>88 While for cortical synapses our analysis predicts that very low baseline activities are contributing most to weight changes, in hippocampus synaptic modiﬁcations peak at baseline ﬁring rates x0 around 5 Hz, which suggests that x0 can control learning. [sent-192, score-0.839]
</p><p>89 Our study suggests that the ﬁlter properties of STDP originating from the dynamics of pre- and postsynaptic activity contributions are in fact exploited for learning in the brain. [sent-193, score-0.638]
</p><p>90 In particular, shifts in baseline rates, as well as the frequency and the respective phases of pre- and postsynaptic rate modulations induced by theta oscillations could be tuned to match the values that make STDP most susceptible for synaptic modiﬁcations. [sent-194, score-1.307]
</p><p>91 Regulation of synaptic efﬁcacy by coincidence of postsynaptic APs and EPSPs. [sent-208, score-0.918]
</p><p>92 Synaptic modiﬁcations in cultured hippocampal neurons: dependence on spike timing, synaptic strength, and postsynaptic cell type. [sent-215, score-1.247]
</p><p>93 Contribution of individual spikes in burst-induced long-term synaptic modiﬁcation. [sent-246, score-0.476]
</p><p>94 Coactivation and timing-dependent integration of synaptic potentiation and depression. [sent-257, score-0.409]
</p><p>95 Phenomenological models of synaptic plasticity based on spike timing. [sent-263, score-0.703]
</p><p>96 Rate, timing, and cooperativity jointly o o determine cortical synaptic plasticity. [sent-272, score-0.401]
</p><p>97 How the shape of pre-and postsynaptic signals can o o inﬂuence STDP: a biophysical model. [sent-300, score-0.55]
</p><p>98 Triplets of spikes in a model of spike timing-dependent plasticity. [sent-342, score-0.37]
</p><p>99 Matching storage and recall: hippocampal spike timing-dependent plasticity and phase response curves. [sent-360, score-0.473]
</p><p>100 Environmental novelty is signaled by reduction of the hippocampal theta frequency. [sent-397, score-0.196]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('postsynaptic', 0.529), ('synaptic', 0.368), ('stdp', 0.325), ('spike', 0.262), ('post', 0.177), ('hippocampus', 0.166), ('presynaptic', 0.157), ('pre', 0.152), ('ypost', 0.151), ('hebbian', 0.135), ('ypre', 0.123), ('modulations', 0.122), ('theta', 0.108), ('spikes', 0.108), ('hz', 0.106), ('cw', 0.099), ('hippocampal', 0.088), ('attenuation', 0.084), ('interspike', 0.082), ('differential', 0.077), ('activity', 0.076), ('cortex', 0.073), ('plasticity', 0.073), ('upost', 0.069), ('upre', 0.069), ('xpost', 0.069), ('xpre', 0.069), ('ring', 0.058), ('rec', 0.055), ('bursts', 0.055), ('changes', 0.055), ('froemke', 0.055), ('neuronal', 0.053), ('baseline', 0.052), ('ms', 0.052), ('cd', 0.051), ('activities', 0.051), ('modi', 0.051), ('phase', 0.05), ('bremen', 0.048), ('rates', 0.048), ('timing', 0.045), ('synapses', 0.045), ('reproduces', 0.045), ('neuroscience', 0.045), ('frequency', 0.044), ('cact', 0.041), ('cpre', 0.041), ('ltp', 0.041), ('potentiation', 0.041), ('mechanism', 0.038), ('ltd', 0.036), ('pawelzik', 0.036), ('trains', 0.035), ('contribution', 0.034), ('induced', 0.033), ('vitro', 0.033), ('cortical', 0.033), ('dynamics', 0.033), ('connectivity', 0.031), ('trace', 0.031), ('rate', 0.03), ('protocols', 0.029), ('asymmetric', 0.029), ('visual', 0.029), ('cations', 0.028), ('suppression', 0.028), ('aip', 0.027), ('cpost', 0.027), ('mod', 0.027), ('schmiedt', 0.027), ('strengthening', 0.027), ('lter', 0.026), ('weight', 0.024), ('dendritic', 0.024), ('susceptibility', 0.024), ('str', 0.024), ('triplets', 0.024), ('experimentally', 0.024), ('traces', 0.023), ('activation', 0.023), ('modulated', 0.023), ('tsodyks', 0.022), ('depression', 0.022), ('signaling', 0.022), ('rg', 0.022), ('pairing', 0.022), ('protocol', 0.022), ('ndings', 0.022), ('studies', 0.021), ('strength', 0.021), ('constants', 0.021), ('depending', 0.021), ('investigations', 0.021), ('nonlinearities', 0.021), ('biophysical', 0.021), ('courses', 0.021), ('oscillations', 0.021), ('colleagues', 0.021), ('coincidence', 0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9999997 <a title="253-tfidf-1" href="./nips-2010-Spike_timing-dependent_plasticity_as_dynamic_filter.html">253 nips-2010-Spike timing-dependent plasticity as dynamic filter</a></p>
<p>Author: Joscha Schmiedt, Christian Albers, Klaus Pawelzik</p><p>Abstract: When stimulated with complex action potential sequences synapses exhibit spike timing-dependent plasticity (STDP) with modulated pre- and postsynaptic contributions to long-term synaptic modiﬁcations. In order to investigate the functional consequences of these contribution dynamics (CD) we propose a minimal model formulated in terms of differential equations. We ﬁnd that our model reproduces data from to recent experimental studies with a small number of biophysically interpretable parameters. The model allows to investigate the susceptibility of STDP to arbitrary time courses of pre- and postsynaptic activities, i.e. its nonlinear ﬁlter properties. We demonstrate this for the simple example of small periodic modulations of pre- and postsynaptic ﬁring rates for which our model can be solved. It predicts synaptic strengthening for synchronous rate modulations. Modiﬁcations are dominant in the theta frequency range, a result which underlines the well known relevance of theta activities in hippocampus and cortex for learning. We also ﬁnd emphasis of speciﬁc baseline spike rates and suppression for high background rates. The latter suggests a mechanism of network activity regulation inherent in STDP. Furthermore, our novel formulation provides a general framework for investigating the joint dynamics of neuronal activity and the CD of STDP in both spike-based as well as rate-based neuronal network models. 1</p><p>2 0.22354807 <a title="253-tfidf-2" href="./nips-2010-A_Novel_Kernel_for_Learning_a_Neuron_Model_from_Spike_Train_Data.html">10 nips-2010-A Novel Kernel for Learning a Neuron Model from Spike Train Data</a></p>
<p>Author: Nicholas Fisher, Arunava Banerjee</p><p>Abstract: From a functional viewpoint, a spiking neuron is a device that transforms input spike trains on its various synapses into an output spike train on its axon. We demonstrate in this paper that the function mapping underlying the device can be tractably learned based on input and output spike train data alone. We begin by posing the problem in a classiﬁcation based framework. We then derive a novel kernel for an SRM0 model that is based on PSP and AHP like functions. With the kernel we demonstrate how the learning problem can be posed as a Quadratic Program. Experimental results demonstrate the strength of our approach. 1</p><p>3 0.14243117 <a title="253-tfidf-3" href="./nips-2010-Rescaling%2C_thinning_or_complementing%3F_On_goodness-of-fit_procedures_for_point_process_models_and_Generalized_Linear_Models.html">227 nips-2010-Rescaling, thinning or complementing? On goodness-of-fit procedures for point process models and Generalized Linear Models</a></p>
<p>Author: Felipe Gerhard, Wulfram Gerstner</p><p>Abstract: Generalized Linear Models (GLMs) are an increasingly popular framework for modeling neural spike trains. They have been linked to the theory of stochastic point processes and researchers have used this relation to assess goodness-of-ﬁt using methods from point-process theory, e.g. the time-rescaling theorem. However, high neural ﬁring rates or coarse discretization lead to a breakdown of the assumptions necessary for this connection. Here, we show how goodness-of-ﬁt tests from point-process theory can still be applied to GLMs by constructing equivalent surrogate point processes out of time-series observations. Furthermore, two additional tests based on thinning and complementing point processes are introduced. They augment the instruments available for checking model adequacy of point processes as well as discretized models. 1</p><p>4 0.13240702 <a title="253-tfidf-4" href="./nips-2010-A_novel_family_of_non-parametric_cumulative_based_divergences_for_point_processes.html">18 nips-2010-A novel family of non-parametric cumulative based divergences for point processes</a></p>
<p>Author: Sohan Seth, Park Il, Austin Brockmeier, Mulugeta Semework, John Choi, Joseph Francis, Jose Principe</p><p>Abstract: Hypothesis testing on point processes has several applications such as model ﬁtting, plasticity detection, and non-stationarity detection. Standard tools for hypothesis testing include tests on mean ﬁring rate and time varying rate function. However, these statistics do not fully describe a point process, and therefore, the conclusions drawn by these tests can be misleading. In this paper, we introduce a family of non-parametric divergence measures for hypothesis testing. A divergence measure compares the full probability structure and, therefore, leads to a more robust test of hypothesis. We extend the traditional Kolmogorov–Smirnov and Cram´ r–von-Mises tests to the space of spike trains via stratiﬁcation, and e show that these statistics can be consistently estimated from data without any free parameter. We demonstrate an application of the proposed divergences as a cost function to ﬁnd optimally matched point processes. 1</p><p>5 0.12469679 <a title="253-tfidf-5" href="./nips-2010-Effects_of_Synaptic_Weight_Diffusion_on_Learning_in_Decision_Making_Networks.html">68 nips-2010-Effects of Synaptic Weight Diffusion on Learning in Decision Making Networks</a></p>
<p>Author: Kentaro Katahira, Kazuo Okanoya, Masato Okada</p><p>Abstract: When animals repeatedly choose actions from multiple alternatives, they can allocate their choices stochastically depending on past actions and outcomes. It is commonly assumed that this ability is achieved by modiﬁcations in synaptic weights related to decision making. Choice behavior has been empirically found to follow Herrnstein’s matching law. Loewenstein & Seung (2006) demonstrated that matching behavior is a steady state of learning in neural networks if the synaptic weights change proportionally to the covariance between reward and neural activities. However, their proof did not take into account the change in entire synaptic distributions. In this study, we show that matching behavior is not necessarily a steady state of the covariance-based learning rule when the synaptic strength is sufﬁciently strong so that the ﬂuctuations in input from individual sensory neurons inﬂuence the net input to output neurons. This is caused by the increasing variance in the input potential due to the diffusion of synaptic weights. This effect causes an undermatching phenomenon, which has been observed in many behavioral experiments. We suggest that the synaptic diffusion effects provide a robust neural mechanism for stochastic choice behavior.</p><p>6 0.1165459 <a title="253-tfidf-6" href="./nips-2010-Attractor_Dynamics_with_Synaptic_Depression.html">34 nips-2010-Attractor Dynamics with Synaptic Depression</a></p>
<p>7 0.11569991 <a title="253-tfidf-7" href="./nips-2010-Accounting_for_network_effects_in_neuronal_responses_using_L1_regularized_point_process_models.html">21 nips-2010-Accounting for network effects in neuronal responses using L1 regularized point process models</a></p>
<p>8 0.10110703 <a title="253-tfidf-8" href="./nips-2010-A_VLSI_Implementation_of_the_Adaptive_Exponential_Integrate-and-Fire_Neuron_Model.html">16 nips-2010-A VLSI Implementation of the Adaptive Exponential Integrate-and-Fire Neuron Model</a></p>
<p>9 0.087655567 <a title="253-tfidf-9" href="./nips-2010-Fractionally_Predictive_Spiking_Neurons.html">96 nips-2010-Fractionally Predictive Spiking Neurons</a></p>
<p>10 0.085399896 <a title="253-tfidf-10" href="./nips-2010-Switching_state_space_model_for_simultaneously_estimating_state_transitions_and_nonstationary_firing_rates.html">263 nips-2010-Switching state space model for simultaneously estimating state transitions and nonstationary firing rates</a></p>
<p>11 0.081787698 <a title="253-tfidf-11" href="./nips-2010-SpikeAnts%2C_a_spiking_neuron_network_modelling_the_emergence_of_organization_in_a_complex_system.html">252 nips-2010-SpikeAnts, a spiking neuron network modelling the emergence of organization in a complex system</a></p>
<p>12 0.081167743 <a title="253-tfidf-12" href="./nips-2010-Over-complete_representations_on_recurrent_neural_networks_can_support_persistent_percepts.html">200 nips-2010-Over-complete representations on recurrent neural networks can support persistent percepts</a></p>
<p>13 0.075900137 <a title="253-tfidf-13" href="./nips-2010-Inferring_Stimulus_Selectivity_from_the_Spatial_Structure_of_Neural_Network_Dynamics.html">127 nips-2010-Inferring Stimulus Selectivity from the Spatial Structure of Neural Network Dynamics</a></p>
<p>14 0.074984804 <a title="253-tfidf-14" href="./nips-2010-Learning_to_localise_sounds_with_spiking_neural_networks.html">157 nips-2010-Learning to localise sounds with spiking neural networks</a></p>
<p>15 0.072851278 <a title="253-tfidf-15" href="./nips-2010-Linear_readout_from_a_neural_population_with_partial_correlation_data.html">161 nips-2010-Linear readout from a neural population with partial correlation data</a></p>
<p>16 0.067211792 <a title="253-tfidf-16" href="./nips-2010-Identifying_Dendritic_Processing.html">115 nips-2010-Identifying Dendritic Processing</a></p>
<p>17 0.049916271 <a title="253-tfidf-17" href="./nips-2010-The_Neural_Costs_of_Optimal_Control.html">268 nips-2010-The Neural Costs of Optimal Control</a></p>
<p>18 0.04107387 <a title="253-tfidf-18" href="./nips-2010-Sodium_entry_efficiency_during_action_potentials%3A_A_novel_single-parameter_family_of_Hodgkin-Huxley_models.html">244 nips-2010-Sodium entry efficiency during action potentials: A novel single-parameter family of Hodgkin-Huxley models</a></p>
<p>19 0.039727397 <a title="253-tfidf-19" href="./nips-2010-Implicit_encoding_of_prior_probabilities_in_optimal_neural_populations.html">119 nips-2010-Implicit encoding of prior probabilities in optimal neural populations</a></p>
<p>20 0.038855784 <a title="253-tfidf-20" href="./nips-2010-Probabilistic_Inference_and_Differential_Privacy.html">216 nips-2010-Probabilistic Inference and Differential Privacy</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.085), (1, 0.02), (2, -0.161), (3, 0.19), (4, 0.085), (5, 0.198), (6, -0.068), (7, 0.061), (8, 0.069), (9, -0.064), (10, 0.02), (11, 0.088), (12, 0.05), (13, 0.08), (14, 0.068), (15, 0.01), (16, 0.046), (17, -0.063), (18, 0.045), (19, -0.107), (20, 0.019), (21, 0.048), (22, -0.082), (23, -0.031), (24, 0.003), (25, -0.002), (26, -0.045), (27, -0.0), (28, 0.03), (29, -0.069), (30, 0.016), (31, -0.031), (32, 0.0), (33, 0.055), (34, -0.065), (35, -0.012), (36, -0.055), (37, -0.025), (38, -0.035), (39, 0.009), (40, -0.128), (41, 0.006), (42, 0.054), (43, 0.052), (44, -0.037), (45, -0.086), (46, 0.046), (47, 0.083), (48, 0.038), (49, 0.032)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97762549 <a title="253-lsi-1" href="./nips-2010-Spike_timing-dependent_plasticity_as_dynamic_filter.html">253 nips-2010-Spike timing-dependent plasticity as dynamic filter</a></p>
<p>Author: Joscha Schmiedt, Christian Albers, Klaus Pawelzik</p><p>Abstract: When stimulated with complex action potential sequences synapses exhibit spike timing-dependent plasticity (STDP) with modulated pre- and postsynaptic contributions to long-term synaptic modiﬁcations. In order to investigate the functional consequences of these contribution dynamics (CD) we propose a minimal model formulated in terms of differential equations. We ﬁnd that our model reproduces data from to recent experimental studies with a small number of biophysically interpretable parameters. The model allows to investigate the susceptibility of STDP to arbitrary time courses of pre- and postsynaptic activities, i.e. its nonlinear ﬁlter properties. We demonstrate this for the simple example of small periodic modulations of pre- and postsynaptic ﬁring rates for which our model can be solved. It predicts synaptic strengthening for synchronous rate modulations. Modiﬁcations are dominant in the theta frequency range, a result which underlines the well known relevance of theta activities in hippocampus and cortex for learning. We also ﬁnd emphasis of speciﬁc baseline spike rates and suppression for high background rates. The latter suggests a mechanism of network activity regulation inherent in STDP. Furthermore, our novel formulation provides a general framework for investigating the joint dynamics of neuronal activity and the CD of STDP in both spike-based as well as rate-based neuronal network models. 1</p><p>2 0.80875218 <a title="253-lsi-2" href="./nips-2010-A_Novel_Kernel_for_Learning_a_Neuron_Model_from_Spike_Train_Data.html">10 nips-2010-A Novel Kernel for Learning a Neuron Model from Spike Train Data</a></p>
<p>Author: Nicholas Fisher, Arunava Banerjee</p><p>Abstract: From a functional viewpoint, a spiking neuron is a device that transforms input spike trains on its various synapses into an output spike train on its axon. We demonstrate in this paper that the function mapping underlying the device can be tractably learned based on input and output spike train data alone. We begin by posing the problem in a classiﬁcation based framework. We then derive a novel kernel for an SRM0 model that is based on PSP and AHP like functions. With the kernel we demonstrate how the learning problem can be posed as a Quadratic Program. Experimental results demonstrate the strength of our approach. 1</p><p>3 0.72222698 <a title="253-lsi-3" href="./nips-2010-SpikeAnts%2C_a_spiking_neuron_network_modelling_the_emergence_of_organization_in_a_complex_system.html">252 nips-2010-SpikeAnts, a spiking neuron network modelling the emergence of organization in a complex system</a></p>
<p>Author: Sylvain Chevallier, Hél\`ene Paugam-moisy, Michele Sebag</p><p>Abstract: Many complex systems, ranging from neural cell assemblies to insect societies, involve and rely on some division of labor. How to enforce such a division in a decentralized and distributed way, is tackled in this paper, using a spiking neuron network architecture. Speciﬁcally, a spatio-temporal model called SpikeAnts is shown to enforce the emergence of synchronized activities in an ant colony. Each ant is modelled from two spiking neurons; the ant colony is a sparsely connected spiking neuron network. Each ant makes its decision (among foraging, sleeping and self-grooming) from the competition between its two neurons, after the signals received from its neighbor ants. Interestingly, three types of temporal patterns emerge in the ant colony: asynchronous, synchronous, and synchronous periodic foraging activities − similar to the actual behavior of some living ant colonies. A phase diagram of the emergent activity patterns with respect to two control parameters, respectively accounting for ant sociability and receptivity, is presented and discussed. 1</p><p>4 0.71008891 <a title="253-lsi-4" href="./nips-2010-A_VLSI_Implementation_of_the_Adaptive_Exponential_Integrate-and-Fire_Neuron_Model.html">16 nips-2010-A VLSI Implementation of the Adaptive Exponential Integrate-and-Fire Neuron Model</a></p>
<p>Author: Sebastian Millner, Andreas Grübl, Karlheinz Meier, Johannes Schemmel, Marc-olivier Schwartz</p><p>Abstract: We describe an accelerated hardware neuron being capable of emulating the adaptive exponential integrate-and-ﬁre neuron model. Firing patterns of the membrane stimulated by a step current are analyzed in transistor level simulations and in silicon on a prototype chip. The neuron is destined to be the hardware neuron of a highly integrated wafer-scale system reaching out for new computational paradigms and opening new experimentation possibilities. As the neuron is dedicated as a universal device for neuroscientiﬁc experiments, the focus lays on parameterizability and reproduction of the analytical model. 1</p><p>5 0.65013915 <a title="253-lsi-5" href="./nips-2010-A_novel_family_of_non-parametric_cumulative_based_divergences_for_point_processes.html">18 nips-2010-A novel family of non-parametric cumulative based divergences for point processes</a></p>
<p>Author: Sohan Seth, Park Il, Austin Brockmeier, Mulugeta Semework, John Choi, Joseph Francis, Jose Principe</p><p>Abstract: Hypothesis testing on point processes has several applications such as model ﬁtting, plasticity detection, and non-stationarity detection. Standard tools for hypothesis testing include tests on mean ﬁring rate and time varying rate function. However, these statistics do not fully describe a point process, and therefore, the conclusions drawn by these tests can be misleading. In this paper, we introduce a family of non-parametric divergence measures for hypothesis testing. A divergence measure compares the full probability structure and, therefore, leads to a more robust test of hypothesis. We extend the traditional Kolmogorov–Smirnov and Cram´ r–von-Mises tests to the space of spike trains via stratiﬁcation, and e show that these statistics can be consistently estimated from data without any free parameter. We demonstrate an application of the proposed divergences as a cost function to ﬁnd optimally matched point processes. 1</p><p>6 0.60609561 <a title="253-lsi-6" href="./nips-2010-Rescaling%2C_thinning_or_complementing%3F_On_goodness-of-fit_procedures_for_point_process_models_and_Generalized_Linear_Models.html">227 nips-2010-Rescaling, thinning or complementing? On goodness-of-fit procedures for point process models and Generalized Linear Models</a></p>
<p>7 0.58547384 <a title="253-lsi-7" href="./nips-2010-Accounting_for_network_effects_in_neuronal_responses_using_L1_regularized_point_process_models.html">21 nips-2010-Accounting for network effects in neuronal responses using L1 regularized point process models</a></p>
<p>8 0.55798829 <a title="253-lsi-8" href="./nips-2010-Learning_to_localise_sounds_with_spiking_neural_networks.html">157 nips-2010-Learning to localise sounds with spiking neural networks</a></p>
<p>9 0.55401975 <a title="253-lsi-9" href="./nips-2010-Identifying_Dendritic_Processing.html">115 nips-2010-Identifying Dendritic Processing</a></p>
<p>10 0.53355932 <a title="253-lsi-10" href="./nips-2010-Effects_of_Synaptic_Weight_Diffusion_on_Learning_in_Decision_Making_Networks.html">68 nips-2010-Effects of Synaptic Weight Diffusion on Learning in Decision Making Networks</a></p>
<p>11 0.52818257 <a title="253-lsi-11" href="./nips-2010-Attractor_Dynamics_with_Synaptic_Depression.html">34 nips-2010-Attractor Dynamics with Synaptic Depression</a></p>
<p>12 0.50889277 <a title="253-lsi-12" href="./nips-2010-Fractionally_Predictive_Spiking_Neurons.html">96 nips-2010-Fractionally Predictive Spiking Neurons</a></p>
<p>13 0.4823055 <a title="253-lsi-13" href="./nips-2010-Sodium_entry_efficiency_during_action_potentials%3A_A_novel_single-parameter_family_of_Hodgkin-Huxley_models.html">244 nips-2010-Sodium entry efficiency during action potentials: A novel single-parameter family of Hodgkin-Huxley models</a></p>
<p>14 0.45651299 <a title="253-lsi-14" href="./nips-2010-Over-complete_representations_on_recurrent_neural_networks_can_support_persistent_percepts.html">200 nips-2010-Over-complete representations on recurrent neural networks can support persistent percepts</a></p>
<p>15 0.43342373 <a title="253-lsi-15" href="./nips-2010-Switching_state_space_model_for_simultaneously_estimating_state_transitions_and_nonstationary_firing_rates.html">263 nips-2010-Switching state space model for simultaneously estimating state transitions and nonstationary firing rates</a></p>
<p>16 0.38966194 <a title="253-lsi-16" href="./nips-2010-Inferring_Stimulus_Selectivity_from_the_Spatial_Structure_of_Neural_Network_Dynamics.html">127 nips-2010-Inferring Stimulus Selectivity from the Spatial Structure of Neural Network Dynamics</a></p>
<p>17 0.36757103 <a title="253-lsi-17" href="./nips-2010-Linear_readout_from_a_neural_population_with_partial_correlation_data.html">161 nips-2010-Linear readout from a neural population with partial correlation data</a></p>
<p>18 0.26499254 <a title="253-lsi-18" href="./nips-2010-Hallucinations_in_Charles_Bonnet_Syndrome_Induced_by_Homeostasis%3A_a_Deep_Boltzmann_Machine_Model.html">111 nips-2010-Hallucinations in Charles Bonnet Syndrome Induced by Homeostasis: a Deep Boltzmann Machine Model</a></p>
<p>19 0.26464897 <a title="253-lsi-19" href="./nips-2010-Switched_Latent_Force_Models_for_Movement_Segmentation.html">262 nips-2010-Switched Latent Force Models for Movement Segmentation</a></p>
<p>20 0.23369707 <a title="253-lsi-20" href="./nips-2010-Short-term_memory_in_neuronal_networks_through_dynamical_compressed_sensing.html">238 nips-2010-Short-term memory in neuronal networks through dynamical compressed sensing</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(4, 0.019), (11, 0.318), (13, 0.024), (17, 0.014), (27, 0.081), (30, 0.035), (35, 0.019), (45, 0.102), (50, 0.036), (52, 0.065), (60, 0.013), (77, 0.126), (90, 0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.78243315 <a title="253-lda-1" href="./nips-2010-Spike_timing-dependent_plasticity_as_dynamic_filter.html">253 nips-2010-Spike timing-dependent plasticity as dynamic filter</a></p>
<p>Author: Joscha Schmiedt, Christian Albers, Klaus Pawelzik</p><p>Abstract: When stimulated with complex action potential sequences synapses exhibit spike timing-dependent plasticity (STDP) with modulated pre- and postsynaptic contributions to long-term synaptic modiﬁcations. In order to investigate the functional consequences of these contribution dynamics (CD) we propose a minimal model formulated in terms of differential equations. We ﬁnd that our model reproduces data from to recent experimental studies with a small number of biophysically interpretable parameters. The model allows to investigate the susceptibility of STDP to arbitrary time courses of pre- and postsynaptic activities, i.e. its nonlinear ﬁlter properties. We demonstrate this for the simple example of small periodic modulations of pre- and postsynaptic ﬁring rates for which our model can be solved. It predicts synaptic strengthening for synchronous rate modulations. Modiﬁcations are dominant in the theta frequency range, a result which underlines the well known relevance of theta activities in hippocampus and cortex for learning. We also ﬁnd emphasis of speciﬁc baseline spike rates and suppression for high background rates. The latter suggests a mechanism of network activity regulation inherent in STDP. Furthermore, our novel formulation provides a general framework for investigating the joint dynamics of neuronal activity and the CD of STDP in both spike-based as well as rate-based neuronal network models. 1</p><p>2 0.5304929 <a title="253-lda-2" href="./nips-2010-An_Inverse_Power_Method_for_Nonlinear_Eigenproblems_with_Applications_in_1-Spectral_Clustering_and_Sparse_PCA.html">30 nips-2010-An Inverse Power Method for Nonlinear Eigenproblems with Applications in 1-Spectral Clustering and Sparse PCA</a></p>
<p>Author: Matthias Hein, Thomas Bühler</p><p>Abstract: Many problems in machine learning and statistics can be formulated as (generalized) eigenproblems. In terms of the associated optimization problem, computing linear eigenvectors amounts to ﬁnding critical points of a quadratic function subject to quadratic constraints. In this paper we show that a certain class of constrained optimization problems with nonquadratic objective and constraints can be understood as nonlinear eigenproblems. We derive a generalization of the inverse power method which is guaranteed to converge to a nonlinear eigenvector. We apply the inverse power method to 1-spectral clustering and sparse PCA which can naturally be formulated as nonlinear eigenproblems. In both applications we achieve state-of-the-art results in terms of solution quality and runtime. Moving beyond the standard eigenproblem should be useful also in many other applications and our inverse power method can be easily adapted to new problems. 1</p><p>3 0.49388179 <a title="253-lda-3" href="./nips-2010-Attractor_Dynamics_with_Synaptic_Depression.html">34 nips-2010-Attractor Dynamics with Synaptic Depression</a></p>
<p>Author: K. Wong, He Wang, Si Wu, Chi Fung</p><p>Abstract: Neuronal connection weights exhibit short-term depression (STD). The present study investigates the impact of STD on the dynamics of a continuous attractor neural network (CANN) and its potential roles in neural information processing. We ﬁnd that the network with STD can generate both static and traveling bumps, and STD enhances the performance of the network in tracking external inputs. In particular, we ﬁnd that STD endows the network with slow-decaying plateau behaviors, namely, the network being initially stimulated to an active state will decay to silence very slowly in the time scale of STD rather than that of neural signaling. We argue that this provides a mechanism for neural systems to hold short-term memory easily and shut off persistent activities naturally.</p><p>4 0.48780799 <a title="253-lda-4" href="./nips-2010-A_Theory_of_Multiclass_Boosting.html">15 nips-2010-A Theory of Multiclass Boosting</a></p>
<p>Author: Indraneel Mukherjee, Robert E. Schapire</p><p>Abstract: Boosting combines weak classiﬁers to form highly accurate predictors. Although the case of binary classiﬁcation is well understood, in the multiclass setting, the “correct” requirements on the weak classiﬁer, or the notion of the most efﬁcient boosting algorithms are missing. In this paper, we create a broad and general framework, within which we make precise and identify the optimal requirements on the weak-classiﬁer, as well as design the most effective, in a certain sense, boosting algorithms that assume such requirements. 1</p><p>5 0.48745856 <a title="253-lda-5" href="./nips-2010-A_VLSI_Implementation_of_the_Adaptive_Exponential_Integrate-and-Fire_Neuron_Model.html">16 nips-2010-A VLSI Implementation of the Adaptive Exponential Integrate-and-Fire Neuron Model</a></p>
<p>Author: Sebastian Millner, Andreas Grübl, Karlheinz Meier, Johannes Schemmel, Marc-olivier Schwartz</p><p>Abstract: We describe an accelerated hardware neuron being capable of emulating the adaptive exponential integrate-and-ﬁre neuron model. Firing patterns of the membrane stimulated by a step current are analyzed in transistor level simulations and in silicon on a prototype chip. The neuron is destined to be the hardware neuron of a highly integrated wafer-scale system reaching out for new computational paradigms and opening new experimentation possibilities. As the neuron is dedicated as a universal device for neuroscientiﬁc experiments, the focus lays on parameterizability and reproduction of the analytical model. 1</p><p>6 0.48232415 <a title="253-lda-6" href="./nips-2010-Robust_Clustering_as_Ensembles_of_Affinity_Relations.html">230 nips-2010-Robust Clustering as Ensembles of Affinity Relations</a></p>
<p>7 0.46917441 <a title="253-lda-7" href="./nips-2010-Effects_of_Synaptic_Weight_Diffusion_on_Learning_in_Decision_Making_Networks.html">68 nips-2010-Effects of Synaptic Weight Diffusion on Learning in Decision Making Networks</a></p>
<p>8 0.46444398 <a title="253-lda-8" href="./nips-2010-Over-complete_representations_on_recurrent_neural_networks_can_support_persistent_percepts.html">200 nips-2010-Over-complete representations on recurrent neural networks can support persistent percepts</a></p>
<p>9 0.4633595 <a title="253-lda-9" href="./nips-2010-Learning_Bounds_for_Importance_Weighting.html">142 nips-2010-Learning Bounds for Importance Weighting</a></p>
<p>10 0.46097836 <a title="253-lda-10" href="./nips-2010-Segmentation_as_Maximum-Weight_Independent_Set.html">234 nips-2010-Segmentation as Maximum-Weight Independent Set</a></p>
<p>11 0.45867479 <a title="253-lda-11" href="./nips-2010-A_Novel_Kernel_for_Learning_a_Neuron_Model_from_Spike_Train_Data.html">10 nips-2010-A Novel Kernel for Learning a Neuron Model from Spike Train Data</a></p>
<p>12 0.45854765 <a title="253-lda-12" href="./nips-2010-Short-term_memory_in_neuronal_networks_through_dynamical_compressed_sensing.html">238 nips-2010-Short-term memory in neuronal networks through dynamical compressed sensing</a></p>
<p>13 0.455888 <a title="253-lda-13" href="./nips-2010-Inferring_Stimulus_Selectivity_from_the_Spatial_Structure_of_Neural_Network_Dynamics.html">127 nips-2010-Inferring Stimulus Selectivity from the Spatial Structure of Neural Network Dynamics</a></p>
<p>14 0.45181316 <a title="253-lda-14" href="./nips-2010-Accounting_for_network_effects_in_neuronal_responses_using_L1_regularized_point_process_models.html">21 nips-2010-Accounting for network effects in neuronal responses using L1 regularized point process models</a></p>
<p>15 0.44464612 <a title="253-lda-15" href="./nips-2010-Sodium_entry_efficiency_during_action_potentials%3A_A_novel_single-parameter_family_of_Hodgkin-Huxley_models.html">244 nips-2010-Sodium entry efficiency during action potentials: A novel single-parameter family of Hodgkin-Huxley models</a></p>
<p>16 0.44394708 <a title="253-lda-16" href="./nips-2010-Fractionally_Predictive_Spiking_Neurons.html">96 nips-2010-Fractionally Predictive Spiking Neurons</a></p>
<p>17 0.44042853 <a title="253-lda-17" href="./nips-2010-Identifying_graph-structured_activation_patterns_in_networks.html">117 nips-2010-Identifying graph-structured activation patterns in networks</a></p>
<p>18 0.43988115 <a title="253-lda-18" href="./nips-2010-Evaluating_neuronal_codes_for_inference_using_Fisher_information.html">81 nips-2010-Evaluating neuronal codes for inference using Fisher information</a></p>
<p>19 0.43966535 <a title="253-lda-19" href="./nips-2010-SpikeAnts%2C_a_spiking_neuron_network_modelling_the_emergence_of_organization_in_a_complex_system.html">252 nips-2010-SpikeAnts, a spiking neuron network modelling the emergence of organization in a complex system</a></p>
<p>20 0.43964991 <a title="253-lda-20" href="./nips-2010-A_biologically_plausible_network_for_the_computation_of_orientation_dominance.html">17 nips-2010-A biologically plausible network for the computation of orientation dominance</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
