<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>147 nips-2010-Learning Multiple Tasks with a Sparse Matrix-Normal Penalty</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-147" href="#">nips2010-147</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>147 nips-2010-Learning Multiple Tasks with a Sparse Matrix-Normal Penalty</h1>
<br/><p>Source: <a title="nips-2010-147-pdf" href="http://papers.nips.cc/paper/4095-learning-multiple-tasks-with-a-sparse-matrix-normal-penalty.pdf">pdf</a></p><p>Author: Yi Zhang, Jeff G. Schneider</p><p>Abstract: In this paper, we propose a matrix-variate normal penalty with sparse inverse covariances to couple multiple tasks. Learning multiple (parametric) models can be viewed as estimating a matrix of parameters, where rows and columns of the matrix correspond to tasks and features, respectively. Following the matrix-variate normal density, we design a penalty that decomposes the full covariance of matrix elements into the Kronecker product of row covariance and column covariance, which characterizes both task relatedness and feature representation. Several recently proposed methods are variants of the special cases of this formulation. To address the overﬁtting issue and select meaningful task and feature structures, we include sparse covariance selection into our matrix-normal regularization via ℓ1 penalties on task and feature inverse covariances. We empirically study the proposed method and compare with related models in two real-world problems: detecting landmines in multiple ﬁelds and recognizing faces between different subjects. Experimental results show that the proposed framework provides an effective and ﬂexible way to model various different structures of multiple tasks.</p><p>Reference: <a title="nips-2010-147-reference" href="../nips2010_reference/nips-2010-Learning_Multiple_Tasks_with_a_Sparse_Matrix-Normal_Penalty_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract In this paper, we propose a matrix-variate normal penalty with sparse inverse covariances to couple multiple tasks. [sent-5, score-0.604]
</p><p>2 Learning multiple (parametric) models can be viewed as estimating a matrix of parameters, where rows and columns of the matrix correspond to tasks and features, respectively. [sent-6, score-0.44]
</p><p>3 Following the matrix-variate normal density, we design a penalty that decomposes the full covariance of matrix elements into the Kronecker product of row covariance and column covariance, which characterizes both task relatedness and feature representation. [sent-7, score-1.204]
</p><p>4 To address the overﬁtting issue and select meaningful task and feature structures, we include sparse covariance selection into our matrix-normal regularization via ℓ1 penalties on task and feature inverse covariances. [sent-9, score-1.032]
</p><p>5 We empirically study the proposed method and compare with related models in two real-world problems: detecting landmines in multiple ﬁelds and recognizing faces between different subjects. [sent-10, score-0.219]
</p><p>6 1 Introduction Learning multiple tasks has been studied for more than a decade [6, 24, 11]. [sent-12, score-0.258]
</p><p>7 Research in the following two directions has drawn considerable interest: learning a common feature representation shared by tasks [1, 12, 30, 2, 3, 9, 23], and directly inferring the relatedness of tasks [4, 26, 21, 29]. [sent-13, score-0.603]
</p><p>8 Both have a natural interpretation if we view learning multiple tasks as estimating a matrix of model parameters, where the rows and columns correspond to tasks and features. [sent-14, score-0.543]
</p><p>9 From this perspective, learning the feature structure corresponds to discovering the structure of the columns in the parameter matrix, and modeling the task relatedness aims to ﬁnd and utilize the relations among rows. [sent-15, score-0.337]
</p><p>10 Regularization methods have shown promising results in ﬁnding either feature or task structure [1, 2, 12, 21]. [sent-16, score-0.238]
</p><p>11 The key contribution is a matrix-normal penalty with sparse inverse covariances, which provides a framework for characterizing and coupling the model parameters of related tasks. [sent-18, score-0.297]
</p><p>12 Following the matrix normal density, we design a penalty that decomposes the full covariance of matrix elements into the Kronecker product of row and column covariances, which correspond to task and feature structures in multi-task learning. [sent-19, score-1.06]
</p><p>13 To address overﬁtting and select task and feature structures, we incorporate sparse covariance selection techniques into our matrix-normal regularization framework via ℓ1 penalties on task and feature inverse covariances. [sent-20, score-1.032]
</p><p>14 We compare the proposed method to related models on two real-world data sets: detecting landmines in multiple ﬁelds and recognizing faces between different subjects. [sent-21, score-0.219]
</p><p>15 For joint learning of multiple tasks, connections need to be established to couple related tasks. [sent-23, score-0.102]
</p><p>16 One direction is to ﬁnd a common feature structure shared by tasks. [sent-24, score-0.176]
</p><p>17 Along this direction, researchers proposed to infer task structure via principal components [1, 12], independent components [30] and covariance [2, 3] in the parameter space, to select a common subset of features [9, 23], as well as to use shared hidden nodes in neural networks [6, 11]. [sent-25, score-0.534]
</p><p>18 Speciﬁcally, learning a shared feature covariance for model parameters [2] is a special case of our proposed framework. [sent-26, score-0.38]
</p><p>19 On the other hand, assuming models of all tasks are equally similar is risky. [sent-27, score-0.18]
</p><p>20 Researchers recently began exploring methods to infer the relatedness of tasks. [sent-28, score-0.108]
</p><p>21 The present paper uses the matrix normal density and ℓ1-regularized sparse covariance selection to specify a structured penalty, which provides a systematic way to characterize and select both task and feature structures in multiple parametric models. [sent-30, score-0.978]
</p><p>22 Matrix normal distributions have been studied in probability and statistics for several decades [13, 16, 18] and applied to predictive modeling in the Bayesian literature. [sent-31, score-0.131]
</p><p>23 For example, the standard matrix normal can serve as a prior for Bayesian variable selection in multivariate regression [9], where MCMC is used for sampling from the resulting posterior. [sent-32, score-0.314]
</p><p>24 Recently, matrix normal distributions have also been used in nonparametric Bayesian approaches, especially in learning Gaussian Processes (GPs) for multi-output prediction [7] and collaborative ﬁltering [27, 28]. [sent-33, score-0.208]
</p><p>25 In this case, the covariance function of the GP prior is decomposed as the Kronecker product of a covariance over functions and a covariance over examples. [sent-34, score-0.777]
</p><p>26 We note that the proposed matrix-normal penalty with sparse inverse covariances in this paper can also be viewed as a new matrix-variate prior, upon which Bayesian inference can be performed. [sent-35, score-0.371]
</p><p>27 1 Deﬁnition The matrix-variate normal distribution is one of the most widely studied matrix-variate distributions [18, 13, 16]. [sent-38, score-0.131]
</p><p>28 Since we can vectorize W to be a mp × 1 vector, the normal distribution on a matrix W can be considered as a multivariate normal distribution on a vector of mp dimensions. [sent-40, score-0.594]
</p><p>29 However, such an ordinary multivariate distribution ignores the special structure of W as an m × p matrix, and as a result, the covariance characterizing the elements of W is of size mp × mp. [sent-41, score-0.425]
</p><p>30 2 Maximum likelihood estimation (MLE) Consider a set of n samples {Wi }n where each Wi is a m×p matrix generated by a matrix-variate i=1 normal distribution as eq. [sent-46, score-0.237]
</p><p>31 If (Ω∗ , Σ∗ ) is an MLE estimate for the row and column covariances, for any α > 0, 1 (αΩ∗ , α Σ∗ ) will lead to the same log density and thus is also an MLE estimate. [sent-51, score-0.136]
</p><p>32 Classical regularization penalties (for single-task learning) can be interpreted as assuming a multivariate prior distribution on the parameter vector and performing maximum-a-posterior estimation, e. [sent-55, score-0.194]
</p><p>33 , ℓ2 penalty and ℓ1 penalty correspond to multivariate Gaussian and Laplacian priors, respectively. [sent-57, score-0.321]
</p><p>34 In this section, we propose a matrix-normal penalty with sparse inverse covariances for learning multiple related tasks. [sent-59, score-0.42]
</p><p>35 1 we start with learning multiple tasks with a matrix-normal penalty. [sent-61, score-0.229]
</p><p>36 2 we study how to incorporate sparse covariance selection into our framework by further imposing ℓ1 penalties on task and feature inverse covariances. [sent-63, score-0.709]
</p><p>37 1 Learning with a Matrix Normal Penalty Consider a multi-task learning problem with m tasks in a p-dimensional feature space. [sent-68, score-0.267]
</p><p>38 The training (t) (t) sets are {Dt }m , where each set Dt contains nt examples {(xi , yi )}nt . [sent-69, score-0.15]
</p><p>39 We want to learn t=1 i=1 m models for the m tasks but appropriately share knowledge among tasks. [sent-70, score-0.212]
</p><p>40 Model parameters are represented by an m × p matrix W, where parameters for a task correspond to a row. [sent-71, score-0.223]
</p><p>41 When we ﬁx Ω = Im and Σ = Ip , the penalty term can be decomposed into standard ℓ2-norm penalties on the m rows of W. [sent-82, score-0.253]
</p><p>42 In this case, the m tasks in (5) can be learned almost independently using single-task ℓ2 regularization (but tasks are still tied by sharing the parameter λ). [sent-83, score-0.434]
</p><p>43 When we ﬁx Ω = Im , tasks are linked only by a shared feature covariance Σ. [sent-84, score-0.56]
</p><p>44 This corresponds to a multi-task feature learning framework [2, 3] which optimizes eq. [sent-85, score-0.116]
</p><p>45 When we ﬁx Σ = Ip , tasks are coupled only by a task similarity matrix Ω. [sent-90, score-0.41]
</p><p>46 W and Ω, with additional constraints on the singular values of Ω that are motivated and derived from task clustering. [sent-95, score-0.14]
</p><p>47 3  We usually do not know task and feature structures in advance. [sent-98, score-0.255]
</p><p>48 When Ω has a sparse inverse, task pairs corresponding to zero entries in Ω−1 will not be explicitly coupled in the penalty of (6). [sent-118, score-0.349]
</p><p>49 Also, note that a clustering of tasks can be expressed by block-wise sparsity of Ω−1 . [sent-120, score-0.21]
</p><p>50 Covariance selection aims to select nonzero entries in the Gaussian inverse covariance and discover conditional independence between variables (indicated by zero entries in the inverse covariance) [14, 5, 17, 15]. [sent-121, score-0.592]
</p><p>51 (6) enables us to perform sparse covariance selection to regularize and select task and feature structures. [sent-123, score-0.608]
</p><p>52 Due to the property of matrix normal distributions that only Σ ⊗ Ω is identiﬁable, we can safely reduce the complexity of choosing regularization parameters by considering the restriction: λΩ = λΣ (12) The following lemma proves that restricting λΩ and λΣ to be equal in eq. [sent-128, score-0.34]
</p><p>53 Step 2) needs to solve ℓ1 regularized covariance selection problems as (11). [sent-143, score-0.298]
</p><p>54 We use the state of the art technique [17], but more efﬁcient optimization for large covariances is still desirable. [sent-144, score-0.114]
</p><p>55 For example, off-diagonal entries of task covariance Ω characterize the task similarity; diagonal entries indicate different amounts of regularization on tasks, which may be ﬁxed as a constant if we prefer tasks to be equally regularized. [sent-154, score-0.853]
</p><p>56 As a result, the “ﬂip-ﬂop” algorithm in (11) needs to solve ℓ1 penalized covariance selection with equality constraints (15) or (16), where the dual block coordinate descent [5] and graphical lasso [17] are no longer directly applicable. [sent-171, score-0.381]
</p><p>57 We will study this direction (efﬁcient constrained sparse covariance selection) in the future work. [sent-173, score-0.3]
</p><p>58 5 Empirical Studies In this section, we present our empirical studies on a landmine detection problem and a face recognition problem, where multiple tasks correspond to detecting landmines at different landmine ﬁelds and classifying faces between different subjects, respectively. [sent-174, score-1.012]
</p><p>59 1 Data Sets and Experimental Settings The landmine detection data set from [26] contains examples collected from different landmine ﬁelds. [sent-178, score-0.476]
</p><p>60 Each example in the data set is represented by a 9-dimensional feature vector extracted from radar imaging, which includes moment-based features, correlation-based features, an energy ratio feature and a spatial variance feature. [sent-179, score-0.174]
</p><p>61 Following [26], we jointly learn 19 tasks from landmine ﬁelds 1 − 10 and 19 − 24 in the data set. [sent-181, score-0.431]
</p><p>62 As a result, the model parameters W are a 19 × 10 matrix, corresponding to 19 tasks and 10 coefﬁcients (including the intercept) for each task. [sent-182, score-0.18]
</p><p>63 Therefore, we use the average AUC (Area Under the ROC Curve) over 19 tasks as the performance measure. [sent-184, score-0.18]
</p><p>64 We vary the size of the training set for each task as 30, 40, 80 and 160. [sent-185, score-0.169]
</p><p>65 Note that we intentionally keep the training sets small because the need for cross-task learning diminishes as the training set becomes large relative to the number of parameters being learned. [sent-186, score-0.106]
</p><p>66 For each training set size, we randomly select training examples for each task and the rest is used as the testing set. [sent-187, score-0.268]
</p><p>67 The face recognition data set is the Yale face database, which contains 165 images of 15 subjects. [sent-194, score-0.183]
</p><p>68 Choice of features is important for face recognition problems. [sent-202, score-0.107]
</p><p>69 In each random run, we extract 30 orthogonal Laplacianfaces using the selected training set of all 8 subjects2 , and conduct experiments of all 28 classiﬁcation tasks in the extracted feature space. [sent-204, score-0.351]
</p><p>70 STL: learn ℓ2 regularized logistic regression for each task separately. [sent-208, score-0.148]
</p><p>71 MTL-C: clustered multi-task learning [21], which encourages task clustering in regularization. [sent-209, score-0.197]
</p><p>72 MTL-F: multi-task feature learning [2], which corresponds to ﬁxing the task covariance Ω as Im and optimizing (6) with only the feature covariance Σ. [sent-213, score-0.768]
</p><p>73 MTL(Ω&Ip; ): learn W and task covariance Ω using (9), with feature covariance Σ ﬁxed as Ip . [sent-215, score-0.713]
</p><p>74 MTL(Im &Σ): learn W and feature covariance Σ using (9), with task covariance Ω ﬁxed as Im . [sent-216, score-0.713]
</p><p>75 MTL(Ω&Σ): learn W, Ω and Σ using (9), inferring both task and feature structures. [sent-217, score-0.273]
</p><p>76 15)  Table 1: Average AUC scores (%) on landmine detection: means (and standard errors) over 30 random runs. [sent-296, score-0.219]
</p><p>77 For each column, the best model is marked with ∗ and competitive models (by paired t-tests) are shown in bold. [sent-297, score-0.112]
</p><p>78 3 Results on Landmine Detection The results on landmine detection are shown in Table 1. [sent-301, score-0.257]
</p><p>79 For small training sizes, restricted Ω and Σ (Ωii = Σjj = 1) offer better prediction; for large training size (160 per task), free Ω and Σ give the best performance. [sent-311, score-0.136]
</p><p>80 , even the simplest coupling among tasks (by sharing λ) can be helpful when the size of training data is small. [sent-315, score-0.273]
</p><p>81 Consider the performance of MTL(Ω&Ip; ) and MTL(Im &Σ), which learn either a task structure or a feature structure. [sent-316, score-0.27]
</p><p>82 , 30 or 40), coupling by task similarity is more effective, and as the training size increases, learning a common feature representation is more helpful. [sent-319, score-0.333]
</p><p>83 MTL(Ω&Σ)Ωii =1 performs similarly to MTL(Ω&Σ)Ωii =Σjj =1 , indicating no signiﬁcant variation of feature importance in this problem. [sent-323, score-0.117]
</p><p>84 4 Results on Face Recognition Empirical results on face recognition are shown in Table 2, with the best model in each column marked with ∗ and competitive models displayed in bold. [sent-325, score-0.229]
</p><p>85 One possible explanation is that, since tasks are to classify faces between different subjects, there may not be a clustered structure over tasks and thus a cluster norm will be inappropriate. [sent-327, score-0.49]
</p><p>86 In this case, using a task similarity matrix may be more appropriate than clustering over tasks. [sent-328, score-0.26]
</p><p>87 Compared to MTL(Ω&Σ), MTL(Ω&Σ)Ωii =1 imposes restrictions on diagonal entries of task covariance Ω: all tasks seem to be similarly difﬁcult and should be equally regularized. [sent-330, score-0.64]
</p><p>88 Compared to MTL(Ω&Σ)Ωii =Σjj =1 , MTL(Ω&Σ)Ωii =1 allows the diagonal entries of feature covariance Σ to capture varying degrees of importance of Laplacianfaces. [sent-331, score-0.376]
</p><p>89 34)∗  Table 2: Average classiﬁcation errors (%) on face recognition: means (and standard errors) over 30 random runs. [sent-386, score-0.111]
</p><p>90 For each column, the best model is marked with ∗ and competitive models (by paired t-tests) are shown in bold. [sent-387, score-0.112]
</p><p>91 6 Conclusion We propose a matrix-variate normal penalty with sparse inverse covariances to couple multiple tasks. [sent-388, score-0.604]
</p><p>92 The proposed framework provides an effective and ﬂexible way to characterize and select both task and feature structures for learning multiple tasks. [sent-389, score-0.378]
</p><p>93 Several recently proposed methods can be viewed as variants of the special cases of our formulation and our empirical results on landmine detection and face recognition show that we consistently outperform previous methods. [sent-390, score-0.364]
</p><p>94 The ﬁrst part is the empirical loss on training examples, depending only on W (and training data). [sent-406, score-0.162]
</p><p>95 The second part is the log-density of matrix normal distributions, which depends on W and Σ ⊗ Ω. [sent-407, score-0.232]
</p><p>96 (9) are not changed: 1) W′ = W so the ﬁrst part remains unchanged; 2) Σ′ ⊗ Ω′ = Σ ⊗ Ω so the second part of the matrix normal log-density is the same; 3) by our construction, the third part is not changed. [sent-411, score-0.28]
</p><p>97 A framework for learning predictive structures from multiple tasks and unlabeled data. [sent-417, score-0.281]
</p><p>98 Model selection through sparse maximum likelihood estimation for multivariate gaussian or binary data. [sent-443, score-0.167]
</p><p>99 Joint covariate selection and joint subspace selection for multiple classiﬁcation problems. [sent-565, score-0.167]
</p><p>100 Learning multiple related tasks using latent independent component analysis. [sent-611, score-0.229]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('mtl', 0.609), ('covariance', 0.239), ('im', 0.231), ('landmine', 0.219), ('jj', 0.191), ('tasks', 0.18), ('laplacianfaces', 0.146), ('normal', 0.131), ('obj', 0.128), ('penalty', 0.122), ('task', 0.116), ('covariances', 0.114), ('mp', 0.104), ('mle', 0.104), ('ii', 0.098), ('landmines', 0.097), ('kronecker', 0.096), ('tr', 0.089), ('feature', 0.087), ('wt', 0.079), ('op', 0.078), ('matrix', 0.077), ('face', 0.076), ('ip', 0.075), ('auc', 0.074), ('regularization', 0.074), ('inverse', 0.074), ('stl', 0.073), ('penalties', 0.073), ('nt', 0.068), ('relatedness', 0.064), ('sparse', 0.061), ('selection', 0.059), ('shared', 0.054), ('couple', 0.053), ('training', 0.053), ('structures', 0.052), ('wi', 0.051), ('clustered', 0.051), ('entries', 0.05), ('multiple', 0.049), ('multivariate', 0.047), ('select', 0.046), ('column', 0.046), ('faces', 0.044), ('infer', 0.044), ('determinant', 0.043), ('marked', 0.042), ('ec', 0.041), ('coupling', 0.04), ('bonilla', 0.039), ('detection', 0.038), ('inferring', 0.038), ('similarity', 0.037), ('paired', 0.036), ('errors', 0.035), ('glasso', 0.035), ('structure', 0.035), ('equality', 0.034), ('subjects', 0.034), ('competitive', 0.034), ('density', 0.033), ('safely', 0.033), ('avg', 0.033), ('learn', 0.032), ('loss', 0.032), ('recognition', 0.031), ('yu', 0.031), ('orthogonal', 0.031), ('tth', 0.031), ('formula', 0.031), ('decomposed', 0.031), ('per', 0.03), ('indicating', 0.03), ('restrictions', 0.03), ('clustering', 0.03), ('correspond', 0.03), ('row', 0.03), ('product', 0.029), ('yi', 0.029), ('samples', 0.029), ('detecting', 0.029), ('optimizes', 0.029), ('argyriou', 0.029), ('decade', 0.029), ('runs', 0.028), ('tresp', 0.028), ('characterize', 0.028), ('log', 0.027), ('rows', 0.027), ('bayesian', 0.027), ('elds', 0.026), ('classi', 0.025), ('lasso', 0.025), ('imposes', 0.025), ('lemma', 0.025), ('decomposes', 0.024), ('constraints', 0.024), ('part', 0.024), ('exible', 0.024)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="147-tfidf-1" href="./nips-2010-Learning_Multiple_Tasks_with_a_Sparse_Matrix-Normal_Penalty.html">147 nips-2010-Learning Multiple Tasks with a Sparse Matrix-Normal Penalty</a></p>
<p>Author: Yi Zhang, Jeff G. Schneider</p><p>Abstract: In this paper, we propose a matrix-variate normal penalty with sparse inverse covariances to couple multiple tasks. Learning multiple (parametric) models can be viewed as estimating a matrix of parameters, where rows and columns of the matrix correspond to tasks and features, respectively. Following the matrix-variate normal density, we design a penalty that decomposes the full covariance of matrix elements into the Kronecker product of row covariance and column covariance, which characterizes both task relatedness and feature representation. Several recently proposed methods are variants of the special cases of this formulation. To address the overﬁtting issue and select meaningful task and feature structures, we include sparse covariance selection into our matrix-normal regularization via ℓ1 penalties on task and feature inverse covariances. We empirically study the proposed method and compare with related models in two real-world problems: detecting landmines in multiple ﬁelds and recognizing faces between different subjects. Experimental results show that the proposed framework provides an effective and ﬂexible way to model various different structures of multiple tasks.</p><p>2 0.41986254 <a title="147-tfidf-2" href="./nips-2010-Learning_Multiple_Tasks_using_Manifold_Regularization.html">146 nips-2010-Learning Multiple Tasks using Manifold Regularization</a></p>
<p>Author: Arvind Agarwal, Samuel Gerber, Hal Daume</p><p>Abstract: We present a novel method for multitask learning (MTL) based on manifold regularization: assume that all task parameters lie on a manifold. This is the generalization of a common assumption made in the existing literature: task parameters share a common linear subspace. One proposed method uses the projection distance from the manifold to regularize the task parameters. The manifold structure and the task parameters are learned using an alternating optimization framework. When the manifold structure is ﬁxed, our method decomposes across tasks which can be learnt independently. An approximation of the manifold regularization scheme is presented that preserves the convexity of the single task learning problem, and makes the proposed MTL framework efﬁcient and easy to implement. We show the efﬁcacy of our method on several datasets. 1</p><p>3 0.23196597 <a title="147-tfidf-3" href="./nips-2010-Large_Margin_Multi-Task_Metric_Learning.html">138 nips-2010-Large Margin Multi-Task Metric Learning</a></p>
<p>Author: Shibin Parameswaran, Kilian Q. Weinberger</p><p>Abstract: Multi-task learning (MTL) improves the prediction performance on multiple, different but related, learning problems through shared parameters or representations. One of the most prominent multi-task learning algorithms is an extension to support vector machines (svm) by Evgeniou et al. [15]. Although very elegant, multi-task svm is inherently restricted by the fact that support vector machines require each class to be addressed explicitly with its own weight vector which, in a multi-task setting, requires the different learning tasks to share the same set of classes. This paper proposes an alternative formulation for multi-task learning by extending the recently published large margin nearest neighbor (lmnn) algorithm to the MTL paradigm. Instead of relying on separating hyperplanes, its decision function is based on the nearest neighbor rule which inherently extends to many classes and becomes a natural ﬁt for multi-task learning. We evaluate the resulting multi-task lmnn on real-world insurance data and speech classiﬁcation problems and show that it consistently outperforms single-task kNN under several metrics and state-of-the-art MTL classiﬁers. 1</p><p>4 0.16409305 <a title="147-tfidf-4" href="./nips-2010-Probabilistic_Multi-Task_Feature_Selection.html">217 nips-2010-Probabilistic Multi-Task Feature Selection</a></p>
<p>Author: Yu Zhang, Dit-Yan Yeung, Qian Xu</p><p>Abstract: Recently, some variants of the đ?&lsquo;&trade;1 norm, particularly matrix norms such as the đ?&lsquo;&trade;1,2 and đ?&lsquo;&trade;1,â&circ;ž norms, have been widely used in multi-task learning, compressed sensing and other related areas to enforce sparsity via joint regularization. In this paper, we unify the đ?&lsquo;&trade;1,2 and đ?&lsquo;&trade;1,â&circ;ž norms by considering a family of đ?&lsquo;&trade;1,đ?&lsquo;ž norms for 1 < đ?&lsquo;ž â&permil;¤ â&circ;ž and study the problem of determining the most appropriate sparsity enforcing norm to use in the context of multi-task feature selection. Using the generalized normal distribution, we provide a probabilistic interpretation of the general multi-task feature selection problem using the đ?&lsquo;&trade;1,đ?&lsquo;ž norm. Based on this probabilistic interpretation, we develop a probabilistic model using the noninformative Jeffreys prior. We also extend the model to learn and exploit more general types of pairwise relationships between tasks. For both versions of the model, we devise expectation-maximization (EM) algorithms to learn all model parameters, including đ?&lsquo;ž, automatically. Experiments have been conducted on two cancer classiďŹ cation applications using microarray gene expression data. 1</p><p>5 0.12430516 <a title="147-tfidf-5" href="./nips-2010-Multitask_Learning_without_Label_Correspondences.html">177 nips-2010-Multitask Learning without Label Correspondences</a></p>
<p>Author: Novi Quadrianto, James Petterson, Tibério S. Caetano, Alex J. Smola, S.v.n. Vishwanathan</p><p>Abstract: We propose an algorithm to perform multitask learning where each task has potentially distinct label sets and label correspondences are not readily available. This is in contrast with existing methods which either assume that the label sets shared by different tasks are the same or that there exists a label mapping oracle. Our method directly maximizes the mutual information among the labels, and we show that the resulting objective function can be efﬁciently optimized using existing algorithms. Our proposed approach has a direct application for data integration with different label spaces, such as integrating Yahoo! and DMOZ web directories. 1</p><p>6 0.08658056 <a title="147-tfidf-6" href="./nips-2010-Extended_Bayesian_Information_Criteria_for_Gaussian_Graphical_Models.html">87 nips-2010-Extended Bayesian Information Criteria for Gaussian Graphical Models</a></p>
<p>7 0.083225578 <a title="147-tfidf-7" href="./nips-2010-Brain_covariance_selection%3A_better_individual_functional_connectivity_models_using_population_prior.html">44 nips-2010-Brain covariance selection: better individual functional connectivity models using population prior</a></p>
<p>8 0.076369494 <a title="147-tfidf-8" href="./nips-2010-A_Family_of_Penalty_Functions_for_Structured_Sparsity.html">7 nips-2010-A Family of Penalty Functions for Structured Sparsity</a></p>
<p>9 0.076042011 <a title="147-tfidf-9" href="./nips-2010-Sparse_Coding_for_Learning_Interpretable_Spatio-Temporal_Primitives.html">246 nips-2010-Sparse Coding for Learning Interpretable Spatio-Temporal Primitives</a></p>
<p>10 0.075716011 <a title="147-tfidf-10" href="./nips-2010-Collaborative_Filtering_in_a_Non-Uniform_World%3A_Learning_with_the_Weighted_Trace_Norm.html">48 nips-2010-Collaborative Filtering in a Non-Uniform World: Learning with the Weighted Trace Norm</a></p>
<p>11 0.073725037 <a title="147-tfidf-11" href="./nips-2010-Worst-Case_Linear_Discriminant_Analysis.html">287 nips-2010-Worst-Case Linear Discriminant Analysis</a></p>
<p>12 0.072603188 <a title="147-tfidf-12" href="./nips-2010-Towards_Holistic_Scene_Understanding%3A_Feedback_Enabled_Cascaded_Classification_Models.html">272 nips-2010-Towards Holistic Scene Understanding: Feedback Enabled Cascaded Classification Models</a></p>
<p>13 0.069970898 <a title="147-tfidf-13" href="./nips-2010-Link_Discovery_using_Graph_Feature_Tracking.html">162 nips-2010-Link Discovery using Graph Feature Tracking</a></p>
<p>14 0.069276661 <a title="147-tfidf-14" href="./nips-2010-Generating_more_realistic_images_using_gated_MRF%27s.html">103 nips-2010-Generating more realistic images using gated MRF's</a></p>
<p>15 0.069180928 <a title="147-tfidf-15" href="./nips-2010-Slice_sampling_covariance_hyperparameters_of_latent_Gaussian_models.html">242 nips-2010-Slice sampling covariance hyperparameters of latent Gaussian models</a></p>
<p>16 0.068990469 <a title="147-tfidf-16" href="./nips-2010-A_Dirty_Model_for_Multi-task_Learning.html">5 nips-2010-A Dirty Model for Multi-task Learning</a></p>
<p>17 0.068638898 <a title="147-tfidf-17" href="./nips-2010-Efficient_Optimization_for_Discriminative_Latent_Class_Models.html">70 nips-2010-Efficient Optimization for Discriminative Latent Class Models</a></p>
<p>18 0.06698031 <a title="147-tfidf-18" href="./nips-2010-Efficient_and_Robust_Feature_Selection_via_Joint_%E2%84%932%2C1-Norms_Minimization.html">73 nips-2010-Efficient and Robust Feature Selection via Joint ℓ2,1-Norms Minimization</a></p>
<p>19 0.065195926 <a title="147-tfidf-19" href="./nips-2010-Active_Instance_Sampling_via_Matrix_Partition.html">23 nips-2010-Active Instance Sampling via Matrix Partition</a></p>
<p>20 0.064086974 <a title="147-tfidf-20" href="./nips-2010-Large_Margin_Learning_of_Upstream_Scene_Understanding_Models.html">137 nips-2010-Large Margin Learning of Upstream Scene Understanding Models</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.231), (1, 0.066), (2, 0.047), (3, -0.012), (4, 0.041), (5, -0.081), (6, 0.048), (7, -0.003), (8, -0.193), (9, -0.068), (10, 0.029), (11, 0.094), (12, 0.202), (13, -0.004), (14, 0.121), (15, 0.015), (16, 0.022), (17, -0.093), (18, -0.018), (19, 0.015), (20, -0.335), (21, -0.193), (22, 0.023), (23, 0.121), (24, -0.077), (25, -0.085), (26, -0.208), (27, -0.063), (28, 0.116), (29, 0.147), (30, -0.025), (31, -0.003), (32, 0.073), (33, -0.035), (34, 0.01), (35, -0.037), (36, -0.063), (37, -0.016), (38, -0.024), (39, -0.067), (40, -0.039), (41, -0.054), (42, 0.069), (43, -0.081), (44, -0.034), (45, 0.029), (46, -0.101), (47, 0.042), (48, 0.047), (49, 0.085)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92616993 <a title="147-lsi-1" href="./nips-2010-Learning_Multiple_Tasks_with_a_Sparse_Matrix-Normal_Penalty.html">147 nips-2010-Learning Multiple Tasks with a Sparse Matrix-Normal Penalty</a></p>
<p>Author: Yi Zhang, Jeff G. Schneider</p><p>Abstract: In this paper, we propose a matrix-variate normal penalty with sparse inverse covariances to couple multiple tasks. Learning multiple (parametric) models can be viewed as estimating a matrix of parameters, where rows and columns of the matrix correspond to tasks and features, respectively. Following the matrix-variate normal density, we design a penalty that decomposes the full covariance of matrix elements into the Kronecker product of row covariance and column covariance, which characterizes both task relatedness and feature representation. Several recently proposed methods are variants of the special cases of this formulation. To address the overﬁtting issue and select meaningful task and feature structures, we include sparse covariance selection into our matrix-normal regularization via ℓ1 penalties on task and feature inverse covariances. We empirically study the proposed method and compare with related models in two real-world problems: detecting landmines in multiple ﬁelds and recognizing faces between different subjects. Experimental results show that the proposed framework provides an effective and ﬂexible way to model various different structures of multiple tasks.</p><p>2 0.90280545 <a title="147-lsi-2" href="./nips-2010-Learning_Multiple_Tasks_using_Manifold_Regularization.html">146 nips-2010-Learning Multiple Tasks using Manifold Regularization</a></p>
<p>Author: Arvind Agarwal, Samuel Gerber, Hal Daume</p><p>Abstract: We present a novel method for multitask learning (MTL) based on manifold regularization: assume that all task parameters lie on a manifold. This is the generalization of a common assumption made in the existing literature: task parameters share a common linear subspace. One proposed method uses the projection distance from the manifold to regularize the task parameters. The manifold structure and the task parameters are learned using an alternating optimization framework. When the manifold structure is ﬁxed, our method decomposes across tasks which can be learnt independently. An approximation of the manifold regularization scheme is presented that preserves the convexity of the single task learning problem, and makes the proposed MTL framework efﬁcient and easy to implement. We show the efﬁcacy of our method on several datasets. 1</p><p>3 0.63715589 <a title="147-lsi-3" href="./nips-2010-Probabilistic_Multi-Task_Feature_Selection.html">217 nips-2010-Probabilistic Multi-Task Feature Selection</a></p>
<p>Author: Yu Zhang, Dit-Yan Yeung, Qian Xu</p><p>Abstract: Recently, some variants of the đ?&lsquo;&trade;1 norm, particularly matrix norms such as the đ?&lsquo;&trade;1,2 and đ?&lsquo;&trade;1,â&circ;ž norms, have been widely used in multi-task learning, compressed sensing and other related areas to enforce sparsity via joint regularization. In this paper, we unify the đ?&lsquo;&trade;1,2 and đ?&lsquo;&trade;1,â&circ;ž norms by considering a family of đ?&lsquo;&trade;1,đ?&lsquo;ž norms for 1 < đ?&lsquo;ž â&permil;¤ â&circ;ž and study the problem of determining the most appropriate sparsity enforcing norm to use in the context of multi-task feature selection. Using the generalized normal distribution, we provide a probabilistic interpretation of the general multi-task feature selection problem using the đ?&lsquo;&trade;1,đ?&lsquo;ž norm. Based on this probabilistic interpretation, we develop a probabilistic model using the noninformative Jeffreys prior. We also extend the model to learn and exploit more general types of pairwise relationships between tasks. For both versions of the model, we devise expectation-maximization (EM) algorithms to learn all model parameters, including đ?&lsquo;ž, automatically. Experiments have been conducted on two cancer classiďŹ cation applications using microarray gene expression data. 1</p><p>4 0.60545766 <a title="147-lsi-4" href="./nips-2010-Large_Margin_Multi-Task_Metric_Learning.html">138 nips-2010-Large Margin Multi-Task Metric Learning</a></p>
<p>Author: Shibin Parameswaran, Kilian Q. Weinberger</p><p>Abstract: Multi-task learning (MTL) improves the prediction performance on multiple, different but related, learning problems through shared parameters or representations. One of the most prominent multi-task learning algorithms is an extension to support vector machines (svm) by Evgeniou et al. [15]. Although very elegant, multi-task svm is inherently restricted by the fact that support vector machines require each class to be addressed explicitly with its own weight vector which, in a multi-task setting, requires the different learning tasks to share the same set of classes. This paper proposes an alternative formulation for multi-task learning by extending the recently published large margin nearest neighbor (lmnn) algorithm to the MTL paradigm. Instead of relying on separating hyperplanes, its decision function is based on the nearest neighbor rule which inherently extends to many classes and becomes a natural ﬁt for multi-task learning. We evaluate the resulting multi-task lmnn on real-world insurance data and speech classiﬁcation problems and show that it consistently outperforms single-task kNN under several metrics and state-of-the-art MTL classiﬁers. 1</p><p>5 0.59402138 <a title="147-lsi-5" href="./nips-2010-Multitask_Learning_without_Label_Correspondences.html">177 nips-2010-Multitask Learning without Label Correspondences</a></p>
<p>Author: Novi Quadrianto, James Petterson, Tibério S. Caetano, Alex J. Smola, S.v.n. Vishwanathan</p><p>Abstract: We propose an algorithm to perform multitask learning where each task has potentially distinct label sets and label correspondences are not readily available. This is in contrast with existing methods which either assume that the label sets shared by different tasks are the same or that there exists a label mapping oracle. Our method directly maximizes the mutual information among the labels, and we show that the resulting objective function can be efﬁciently optimized using existing algorithms. Our proposed approach has a direct application for data integration with different label spaces, such as integrating Yahoo! and DMOZ web directories. 1</p><p>6 0.49402642 <a title="147-lsi-6" href="./nips-2010-Humans_Learn_Using_Manifolds%2C_Reluctantly.html">114 nips-2010-Humans Learn Using Manifolds, Reluctantly</a></p>
<p>7 0.41789216 <a title="147-lsi-7" href="./nips-2010-Efficient_and_Robust_Feature_Selection_via_Joint_%E2%84%932%2C1-Norms_Minimization.html">73 nips-2010-Efficient and Robust Feature Selection via Joint ℓ2,1-Norms Minimization</a></p>
<p>8 0.41029653 <a title="147-lsi-8" href="./nips-2010-A_Dirty_Model_for_Multi-task_Learning.html">5 nips-2010-A Dirty Model for Multi-task Learning</a></p>
<p>9 0.37554032 <a title="147-lsi-9" href="./nips-2010-Decoding_Ipsilateral_Finger_Movements_from_ECoG_Signals_in_Humans.html">57 nips-2010-Decoding Ipsilateral Finger Movements from ECoG Signals in Humans</a></p>
<p>10 0.37548539 <a title="147-lsi-10" href="./nips-2010-Adaptive_Multi-Task_Lasso%3A_with_Application_to_eQTL_Detection.html">26 nips-2010-Adaptive Multi-Task Lasso: with Application to eQTL Detection</a></p>
<p>11 0.37248567 <a title="147-lsi-11" href="./nips-2010-Sparse_Inverse_Covariance_Selection_via_Alternating_Linearization_Methods.html">248 nips-2010-Sparse Inverse Covariance Selection via Alternating Linearization Methods</a></p>
<p>12 0.36107326 <a title="147-lsi-12" href="./nips-2010-Block_Variable_Selection_in_Multivariate_Regression_and_High-dimensional_Causal_Inference.html">41 nips-2010-Block Variable Selection in Multivariate Regression and High-dimensional Causal Inference</a></p>
<p>13 0.35852313 <a title="147-lsi-13" href="./nips-2010-Extended_Bayesian_Information_Criteria_for_Gaussian_Graphical_Models.html">87 nips-2010-Extended Bayesian Information Criteria for Gaussian Graphical Models</a></p>
<p>14 0.35464677 <a title="147-lsi-14" href="./nips-2010-Worst-Case_Linear_Discriminant_Analysis.html">287 nips-2010-Worst-Case Linear Discriminant Analysis</a></p>
<p>15 0.34925288 <a title="147-lsi-15" href="./nips-2010-Gated_Softmax_Classification.html">99 nips-2010-Gated Softmax Classification</a></p>
<p>16 0.34726191 <a title="147-lsi-16" href="./nips-2010-Online_Learning_in_The_Manifold_of_Low-Rank_Matrices.html">195 nips-2010-Online Learning in The Manifold of Low-Rank Matrices</a></p>
<p>17 0.32849583 <a title="147-lsi-17" href="./nips-2010-Discriminative_Clustering_by_Regularized_Information_Maximization.html">62 nips-2010-Discriminative Clustering by Regularized Information Maximization</a></p>
<p>18 0.32247373 <a title="147-lsi-18" href="./nips-2010-Graph-Valued_Regression.html">108 nips-2010-Graph-Valued Regression</a></p>
<p>19 0.31560296 <a title="147-lsi-19" href="./nips-2010-Towards_Holistic_Scene_Understanding%3A_Feedback_Enabled_Cascaded_Classification_Models.html">272 nips-2010-Towards Holistic Scene Understanding: Feedback Enabled Cascaded Classification Models</a></p>
<p>20 0.31343842 <a title="147-lsi-20" href="./nips-2010-Learning_via_Gaussian_Herding.html">158 nips-2010-Learning via Gaussian Herding</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.099), (17, 0.012), (27, 0.044), (30, 0.038), (35, 0.026), (45, 0.176), (50, 0.434), (52, 0.027), (60, 0.023), (77, 0.019), (90, 0.03)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.92737997 <a title="147-lda-1" href="./nips-2010-Improvements_to_the_Sequence_Memoizer.html">120 nips-2010-Improvements to the Sequence Memoizer</a></p>
<p>Author: Jan Gasthaus, Yee W. Teh</p><p>Abstract: The sequence memoizer is a model for sequence data with state-of-the-art performance on language modeling and compression. We propose a number of improvements to the model and inference algorithm, including an enlarged range of hyperparameters, a memory-efﬁcient representation, and inference algorithms operating on the new representation. Our derivations are based on precise deﬁnitions of the various processes that will also allow us to provide an elementary proof of the “mysterious” coagulation and fragmentation properties used in the original paper on the sequence memoizer by Wood et al. (2009). We present some experimental results supporting our improvements. 1</p><p>2 0.92624557 <a title="147-lda-2" href="./nips-2010-Inference_with_Multivariate_Heavy-Tails_in_Linear_Models.html">126 nips-2010-Inference with Multivariate Heavy-Tails in Linear Models</a></p>
<p>Author: Danny Bickson, Carlos Guestrin</p><p>Abstract: Heavy-tailed distributions naturally occur in many real life problems. Unfortunately, it is typically not possible to compute inference in closed-form in graphical models which involve such heavy-tailed distributions. In this work, we propose a novel simple linear graphical model for independent latent random variables, called linear characteristic model (LCM), defined in the characteristic function domain. Using stable distributions, a heavy-tailed family of distributions which is a generalization of Cauchy, L´ vy and Gaussian distrie butions, we show for the first time, how to compute both exact and approximate inference in such a linear multivariate graphical model. LCMs are not limited to stable distributions, in fact LCMs are always defined for any random variables (discrete, continuous or a mixture of both). We provide a realistic problem from the field of computer networks to demonstrate the applicability of our construction. Other potential application is iterative decoding of linear channels with non-Gaussian noise. 1</p><p>3 0.91062987 <a title="147-lda-3" href="./nips-2010-Gaussian_sampling_by_local_perturbations.html">101 nips-2010-Gaussian sampling by local perturbations</a></p>
<p>Author: George Papandreou, Alan L. Yuille</p><p>Abstract: We present a technique for exact simulation of Gaussian Markov random ﬁelds (GMRFs), which can be interpreted as locally injecting noise to each Gaussian factor independently, followed by computing the mean/mode of the perturbed GMRF. Coupled with standard iterative techniques for the solution of symmetric positive deﬁnite systems, this yields a very efﬁcient sampling algorithm with essentially linear complexity in terms of speed and memory requirements, well suited to extremely large scale probabilistic models. Apart from synthesizing data under a Gaussian model, the proposed technique directly leads to an efﬁcient unbiased estimator of marginal variances. Beyond Gaussian models, the proposed algorithm is also very useful for handling highly non-Gaussian continuously-valued MRFs such as those arising in statistical image modeling or in the ﬁrst layer of deep belief networks describing real-valued data, where the non-quadratic potentials coupling different sites can be represented as ﬁnite or inﬁnite mixtures of Gaussians with the help of local or distributed latent mixture assignment variables. The Bayesian treatment of such models most naturally involves a block Gibbs sampler which alternately draws samples of the conditionally independent latent mixture assignments and the conditionally multivariate Gaussian continuous vector and we show that it can directly beneﬁt from the proposed methods. 1</p><p>4 0.89169759 <a title="147-lda-4" href="./nips-2010-Boosting_Classifier_Cascades.html">42 nips-2010-Boosting Classifier Cascades</a></p>
<p>Author: Nuno Vasconcelos, Mohammad J. Saberian</p><p>Abstract: The problem of optimal and automatic design of a detector cascade is considered. A novel mathematical model is introduced for a cascaded detector. This model is analytically tractable, leads to recursive computation, and accounts for both classiﬁcation and complexity. A boosting algorithm, FCBoost, is proposed for fully automated cascade design. It exploits the new cascade model, minimizes a Lagrangian cost that accounts for both classiﬁcation risk and complexity. It searches the space of cascade conﬁgurations to automatically determine the optimal number of stages and their predictors, and is compatible with bootstrapping of negative examples and cost sensitive learning. Experiments show that the resulting cascades have state-of-the-art performance in various computer vision problems. 1</p><p>same-paper 5 0.87361223 <a title="147-lda-5" href="./nips-2010-Learning_Multiple_Tasks_with_a_Sparse_Matrix-Normal_Penalty.html">147 nips-2010-Learning Multiple Tasks with a Sparse Matrix-Normal Penalty</a></p>
<p>Author: Yi Zhang, Jeff G. Schneider</p><p>Abstract: In this paper, we propose a matrix-variate normal penalty with sparse inverse covariances to couple multiple tasks. Learning multiple (parametric) models can be viewed as estimating a matrix of parameters, where rows and columns of the matrix correspond to tasks and features, respectively. Following the matrix-variate normal density, we design a penalty that decomposes the full covariance of matrix elements into the Kronecker product of row covariance and column covariance, which characterizes both task relatedness and feature representation. Several recently proposed methods are variants of the special cases of this formulation. To address the overﬁtting issue and select meaningful task and feature structures, we include sparse covariance selection into our matrix-normal regularization via ℓ1 penalties on task and feature inverse covariances. We empirically study the proposed method and compare with related models in two real-world problems: detecting landmines in multiple ﬁelds and recognizing faces between different subjects. Experimental results show that the proposed framework provides an effective and ﬂexible way to model various different structures of multiple tasks.</p><p>6 0.80491865 <a title="147-lda-6" href="./nips-2010-Approximate_inference_in_continuous_time_Gaussian-Jump_processes.html">33 nips-2010-Approximate inference in continuous time Gaussian-Jump processes</a></p>
<p>7 0.66370684 <a title="147-lda-7" href="./nips-2010-Construction_of_Dependent_Dirichlet_Processes_based_on_Poisson_Processes.html">51 nips-2010-Construction of Dependent Dirichlet Processes based on Poisson Processes</a></p>
<p>8 0.66346759 <a title="147-lda-8" href="./nips-2010-Size_Matters%3A_Metric_Visual_Search_Constraints_from_Monocular_Metadata.html">241 nips-2010-Size Matters: Metric Visual Search Constraints from Monocular Metadata</a></p>
<p>9 0.65819782 <a title="147-lda-9" href="./nips-2010-Copula_Processes.html">54 nips-2010-Copula Processes</a></p>
<p>10 0.64608341 <a title="147-lda-10" href="./nips-2010-Heavy-Tailed_Process_Priors_for_Selective_Shrinkage.html">113 nips-2010-Heavy-Tailed Process Priors for Selective Shrinkage</a></p>
<p>11 0.64396781 <a title="147-lda-11" href="./nips-2010-Slice_sampling_covariance_hyperparameters_of_latent_Gaussian_models.html">242 nips-2010-Slice sampling covariance hyperparameters of latent Gaussian models</a></p>
<p>12 0.6293416 <a title="147-lda-12" href="./nips-2010-Short-term_memory_in_neuronal_networks_through_dynamical_compressed_sensing.html">238 nips-2010-Short-term memory in neuronal networks through dynamical compressed sensing</a></p>
<p>13 0.62574077 <a title="147-lda-13" href="./nips-2010-Computing_Marginal_Distributions_over_Continuous_Markov_Networks_for_Statistical_Relational_Learning.html">49 nips-2010-Computing Marginal Distributions over Continuous Markov Networks for Statistical Relational Learning</a></p>
<p>14 0.62002712 <a title="147-lda-14" href="./nips-2010-Fractionally_Predictive_Spiking_Neurons.html">96 nips-2010-Fractionally Predictive Spiking Neurons</a></p>
<p>15 0.62001097 <a title="147-lda-15" href="./nips-2010-Probabilistic_Multi-Task_Feature_Selection.html">217 nips-2010-Probabilistic Multi-Task Feature Selection</a></p>
<p>16 0.61819208 <a title="147-lda-16" href="./nips-2010-Group_Sparse_Coding_with_a_Laplacian_Scale_Mixture_Prior.html">109 nips-2010-Group Sparse Coding with a Laplacian Scale Mixture Prior</a></p>
<p>17 0.6062535 <a title="147-lda-17" href="./nips-2010-Improving_the_Asymptotic_Performance_of_Markov_Chain_Monte-Carlo_by_Inserting_Vortices.html">122 nips-2010-Improving the Asymptotic Performance of Markov Chain Monte-Carlo by Inserting Vortices</a></p>
<p>18 0.60149109 <a title="147-lda-18" href="./nips-2010-Learning_via_Gaussian_Herding.html">158 nips-2010-Learning via Gaussian Herding</a></p>
<p>19 0.60035515 <a title="147-lda-19" href="./nips-2010-Identifying_graph-structured_activation_patterns_in_networks.html">117 nips-2010-Identifying graph-structured activation patterns in networks</a></p>
<p>20 0.59782612 <a title="147-lda-20" href="./nips-2010-Structured_Determinantal_Point_Processes.html">257 nips-2010-Structured Determinantal Point Processes</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
