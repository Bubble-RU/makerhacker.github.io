<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>180 nips-2010-Near-Optimal Bayesian Active Learning with Noisy Observations</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-180" href="#">nips2010-180</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>180 nips-2010-Near-Optimal Bayesian Active Learning with Noisy Observations</h1>
<br/><p>Source: <a title="nips-2010-180-pdf" href="http://papers.nips.cc/paper/4073-near-optimal-bayesian-active-learning-with-noisy-observations.pdf">pdf</a></p><p>Author: Daniel Golovin, Andreas Krause, Debajyoti Ray</p><p>Abstract: We tackle the fundamental problem of Bayesian active learning with noise, where we need to adaptively select from a number of expensive tests in order to identify an unknown hypothesis sampled from a known prior distribution. In the case of noise–free observations, a greedy algorithm called generalized binary search (GBS) is known to perform near–optimally. We show that if the observations are noisy, perhaps surprisingly, GBS can perform very poorly. We develop EC2 , a novel, greedy active learning algorithm and prove that it is competitive with the optimal policy, thus obtaining the ﬁrst competitiveness guarantees for Bayesian active learning with noisy observations. Our bounds rely on a recently discovered diminishing returns property called adaptive submodularity, generalizing the classical notion of submodular set functions to adaptive policies. Our results hold even if the tests have non–uniform cost and their noise is correlated. We also propose E FF ECXTIVE , a particularly fast approximation of EC 2 , and evaluate it on a Bayesian experimental design problem involving human subjects, intended to tease apart competing economic theories of how people make decisions under uncertainty. 1</p><p>Reference: <a title="nips-2010-180-reference" href="../nips2010_reference/nips-2010-Near-Optimal_Bayesian_Active_Learning_with_Noisy_Observations_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 We develop EC2 , a novel, greedy active learning algorithm and prove that it is competitive with the optimal policy, thus obtaining the ﬁrst competitiveness guarantees for Bayesian active learning with noisy observations. [sent-4, score-0.379]
</p><p>2 Our bounds rely on a recently discovered diminishing returns property called adaptive submodularity, generalizing the classical notion of submodular set functions to adaptive policies. [sent-5, score-0.2]
</p><p>3 Our results hold even if the tests have non–uniform cost and their noise is correlated. [sent-6, score-0.33]
</p><p>4 We also propose E FF ECXTIVE , a particularly fast approximation of EC 2 , and evaluate it on a Bayesian experimental design problem involving human subjects, intended to tease apart competing economic theories of how people make decisions under uncertainty. [sent-7, score-0.278]
</p><p>5 In all these applications, we have to sequentially select among a set of noisy, expensive observations (outcomes of experiments, medical tests, expert labels) in order to determine which hypothesis (theory, diagnosis, classiﬁer) is most accurate. [sent-9, score-0.214]
</p><p>6 One way to formalize such active learning problems is Bayesian experimental design [6], where one assumes a prior on the hypotheses, as well as probabilistic assumptions on the outcomes of tests. [sent-11, score-0.268]
</p><p>7 The goal then is to determine the correct hypothesis while minimizing the cost of the experimentation. [sent-12, score-0.165]
</p><p>8 Unfortunately, ﬁnding this optimal policy is not just NP-hard, but also hard to approximate [5]. [sent-13, score-0.12]
</p><p>9 While there are some recent positive results in understanding the label complexity of noisy active learning [19, 1], to our knowledge, so far there are no algorithms that are provably competitive with the optimal sequential policy, except in very restricted settings [16]. [sent-19, score-0.202]
</p><p>10 GBS greedily selects tests to maximize, in expectation over the test outcomes, the prior probability mass of eliminated hypotheses (i. [sent-21, score-0.529]
</p><p>11 2  1  introduce a general formulation of Bayesian active learning with noisy observations that we call the Equivalence Class Determination problem. [sent-27, score-0.251]
</p><p>12 We show that, perhaps surprisingly, generalized binary search performs poorly in this setting, as do greedily (myopically) maximizing the information gain (measured w. [sent-28, score-0.153]
</p><p>13 the distribution on equivalence classes) or the decision-theoretic value of information. [sent-31, score-0.125]
</p><p>14 This motivates us to introduce a novel active learning criterion, and use it to develop a greedy active learning algorithm called the Equivalence Class Edge Cutting algorithm (EC2 ), whose expected cost is competitive to that of the optimal policy. [sent-32, score-0.37]
</p><p>15 Our key insight is that our new objective function satisﬁes adaptive submodularity [9], a natural diminishing returns property that generalizes the classical notion of submodularity to adaptive policies. [sent-33, score-0.256]
</p><p>16 Our results also allow us to relax the common assumption that the outcomes of the tests are conditionally independent given the true hypothesis. [sent-34, score-0.403]
</p><p>17 Our results from human subject experiments further reveal that E FF ECX TIVE can be used as a real-time tool to classify people according to the economic theory that best describes their behaviour in ﬁnancial decision-making, and reveal some interesting heterogeneity in the population. [sent-37, score-0.19]
</p><p>18 2  Bayesian Active Learning in the Noiseless Case  In the Bayesian active learning problem, we would like to distinguish among a given set of hypotheses H = {h1 , . [sent-38, score-0.275]
</p><p>19 Running test t incurs a cost of c(t) and produces an outcome from a ﬁnite set of outcomes X = {1, 2, . [sent-45, score-0.282]
</p><p>20 We let H denote the random variable which equals the true hypothesis, and model the outcome of each test t by a random variable Xt taking values in X . [sent-49, score-0.139]
</p><p>21 In the noiseless case, we assume that the outcome of each test is deterministic given the true hypothesis, i. [sent-55, score-0.209]
</p><p>22 Thus, each hypothesis h is associated with a particular vector of test outcomes. [sent-61, score-0.115]
</p><p>23 , that no two hypotheses lead to the same outcomes for all tests. [sent-66, score-0.229]
</p><p>24 Our goal is to ﬁnd an adaptive policy for running tests that allows us to determine the value of H while minimizing the cost of the tests performed. [sent-69, score-0.862]
</p><p>25 Formally, a policy π (also called a conditional plan) is a partial mapping π from partial observation vectors xA to tests, specifying which test to run next (or whether we should stop testing) for any observation vector xA . [sent-70, score-0.154]
</p><p>26 Hereby, xA ∈ X A is a vector of outcomes indexed by a set of tests A ⊆ T that we have performed so far 3 (e. [sent-71, score-0.403]
</p><p>27 , the set of labeled examples in active learning, or outcomes of a set of medical tests that we ran). [sent-73, score-0.527]
</p><p>28 We denote the set of hypotheses consistent with event Λ (often called the version space associated with Λ) by V(Λ) := {h ∈ H : P (h | Λ) > 0}. [sent-75, score-0.121]
</p><p>29 We call a policy feasible if it is guaranteed to uniquely determine the correct hypothesis. [sent-76, score-0.212]
</p><p>30 We can deﬁne the expected cost of a policy π by c(π) :=  P (h)c(T (π, h)) h  where T (π, h) ⊆ T is the set of tests run by policy π in case H = h. [sent-78, score-0.604]
</p><p>31 Our goal is to ﬁnd a feasible policy π ∗ of minimum expected cost, i. [sent-79, score-0.154]
</p><p>32 1)  π  A policy π can be naturally represented as a decision tree T , and thus problem (2. [sent-82, score-0.184]
</p><p>33 Unfortunately, obtaining an approximate policy π for which c(π) ≤ c(π ∗ ) · o(log(n)) is NP-hard [5]. [sent-84, score-0.12]
</p><p>34 Two of the most popular heuristics are to select tests greedily to maximize the information gain (IG) 3  Formally we also require that (xt )t∈B ∈ dom(π) and A ⊆ B, implies (xt )t∈A ∈ dom(π) (c. [sent-86, score-0.505]
</p><p>35 Both heuristics are greedy, and after having made observations xA will select t∗ = arg max ∆Alg (t | xA ) /c(t), t∈T  where Alg ∈ {IG, GBS}. [sent-90, score-0.134]
</p><p>36 Thus, both heuristics greedily chooses the test that maximizes the beneﬁt-cost ratio, measured with respect to their particular beneﬁt functions. [sent-92, score-0.163]
</p><p>37 They stop after running a set of tests A such that |V(xA )| = 1, i. [sent-93, score-0.295]
</p><p>38 The result above is proved by exploiting the fact that fGBS (S, h) := 1 − P (V(xS (h))) + P (h) is adaptive submodular and strongly adaptively monotone [9]. [sent-99, score-0.233]
</p><p>39 A function f : 2T × H is called adaptive submodular w. [sent-102, score-0.132]
</p><p>40 Thus, f is adaptive submodular if the expected marginal beneﬁts ∆ (t | xA ) of adding a new test t can only decrease as we gather more observations. [sent-106, score-0.2]
</p><p>41 / The performance guarantee for GBS follows from the following general result about the greedy algorithm for adaptive submodular functions (applied with Q = 1 and η = pmin ): Theorem 1 (Theorem 10 of [9] with α = 1). [sent-112, score-0.217]
</p><p>42 Suppose f : 2T × H → R≥0 is adaptive submodular and strongly adaptively monotone with respect to P and there exists Q such that f (T , h) = Q for all h. [sent-113, score-0.233]
</p><p>43 Let η be any value such that f (S, h) > Q − η implies f (S, h) = Q for all sets S and hypotheses h. [sent-114, score-0.121]
</p><p>44 Then for self–certifying instances the adaptive greedy policy π satisﬁes c(π) ≤ c(π ∗ ) ln  Q η  +1 . [sent-115, score-0.241]
</p><p>45 The technical requirement that instances be self–certifying means that the policy will have proof that it has obtained the maximum possible objective value, Q, immediately upon doing so. [sent-116, score-0.12]
</p><p>46 In the following sections, we will use the concept of adaptive submodularity to provide the ﬁrst approximation guarantees for Bayesian active learning with noisy observations. [sent-119, score-0.33]
</p><p>47 3  The Equivalence Class Determination Problem and the EC2 Algorithm  We now wish to consider the Bayesian active learning problem where tests can have noisy outcomes. [sent-120, score-0.497]
</p><p>48 Our general strategy is to reduce the problem of noisy observations to the noiseless setting. [sent-121, score-0.197]
</p><p>49 To gain intuition, consider a simple model where tests have binary outcomes, and we know that the outcome of exactly one test, chosen uniformly at random unbeknown to us, is ﬂipped. [sent-122, score-0.446]
</p><p>50 If any pair of hypotheses h = h differs by the outcome of at least three tests, we can still uniquely determine the correct hypothesis after running all tests. [sent-123, score-0.399]
</p><p>51 In this case we can reduce the noisy active learning problem to the noiseless setting by, for each hypothesis, creating N “noisy” copies, each obtained by ﬂipping the outcome of one of the N tests. [sent-124, score-0.377]
</p><p>52 Thus, each hypothesis hi in the original problem is now associated with a set Hi of hypotheses in the modiﬁed problem instance. [sent-127, score-0.468]
</p><p>53 However, instead of selecting tests to determine which noisy copy has been realized, we only care which set Hi is realized. [sent-128, score-0.422]
</p><p>54 More generally, we introduce the Equivalence Class Determination problem4 , where our set of hypotheses H is partitioned into a set m of m equivalence classes {H1 , . [sent-130, score-0.277]
</p><p>55 , Hm } so that H = i=1 Hi , and the goal is to determine which class Hi the true hypothesis lies in. [sent-133, score-0.13]
</p><p>56 As with the ODT problem, the goal is to minimize the expected cost of the tests, where the expectation is taken over the true hypothesis sampled from P . [sent-135, score-0.15]
</p><p>57 , hn , and two equivalence classes H1 := {hi : 1 ≤ i < n} and H2 := {hn }. [sent-142, score-0.189]
</p><p>58 , n} such that hi (t) = 1[i = t], all of unit cost. [sent-146, score-0.266]
</p><p>59 In this case, the optimal policy only needs to select test n, however GBS may select tests 1, 2, . [sent-148, score-0.519]
</p><p>60 Given our uniform prior, it takes n/2 tests in expectation until this happens, so that GBS pays, in expectation, n/2 times the optimal expected cost in this instance. [sent-152, score-0.364]
</p><p>61 The poor performance of GBS in this instance may be attributed to its lack of consideration for the equivalence classes. [sent-153, score-0.125]
</p><p>62 Another natural heuristic would be to run the greedy information gain policy, only with the entropy measured with respect to the probability distribution on equivalence classes rather than hypotheses. [sent-154, score-0.255]
</p><p>63 It is clearly aware of the equivalence classes, as it adaptively and myopically selects tests to reduce the uncertainty of the realized class, measured w. [sent-156, score-0.567]
</p><p>64 The reason why πIG fails is that there are complementarities among tests; a set of tests can be far better than the sum of its parts. [sent-164, score-0.295]
</p><p>65 We adopt a very elegant idea from Dasgupta [8], and deﬁne weighted edges between hypotheses that we aim to distinguish between. [sent-166, score-0.186]
</p><p>66 However, instead of introducing edges between arbitrary pairs of hypotheses (as done in [8]), we only introduce edges between hypotheses in different classes. [sent-167, score-0.312]
</p><p>67 Tests will allow us to cut edges inconsistent with their outcomes, and we aim to eliminate all inconsistent edges while minimizing the expected cost incurred. [sent-168, score-0.209]
</p><p>68 If all tests have unit cost, by using a modiﬁed prior [15] the approximation factor can be improved to O (log |H| + log | supp(Θ)|) as in the case of Theorem 3. [sent-171, score-0.295]
</p><p>69 In this case reducing Bayesian active learning with noise to Equivalence Class Determination results in instances with exponentially-large equivalence classes. [sent-174, score-0.249]
</p><p>70 This makes running EC2 on them challenging, since explicitly keeping track of the equivalence classes is impractical. [sent-175, score-0.156]
</p><p>71 1), and consider the weight of edges between distinct equivalence classes Hi and Hj : w(Hi ×Hj ) =  P (xT )P (xT ) =  P (xT ) = P (XT ∈ Hi )P (XT ∈ Hj ). [sent-181, score-0.191]
</p><p>72 Here, we focus on the case where, upon observing all tests, the hypothesis is uniquely determined, i. [sent-184, score-0.124]
</p><p>73 In this case, it holds that P (XT ∈ Hi ) = P (H = hi ). [sent-187, score-0.266]
</p><p>74 Input: Set of hypotheses H; Set of tests T ; prior distribution P ; function f . [sent-195, score-0.416]
</p><p>75 5  Experiments  Several economic theories make claims to explain how people make decisions when the payoffs are uncertain. [sent-197, score-0.263]
</p><p>76 Here we use human subject experiments to compare four key theories proposed in literature. [sent-198, score-0.152]
</p><p>77 The uncertainty of the payoff in a given situation is represented by a lottery L, which is simply a random variable with a range of payoffs L := { 1 , . [sent-199, score-0.198]
</p><p>78 The four theories posit distinct utility functions, with agents preferring larger utility lotteries. [sent-205, score-0.182]
</p><p>79 The parameters ΘP T = {ρ, λ, α} represent risk aversion, i < 0, and w(pi ) = e loss aversion and probability weighing factor respectively. [sent-209, score-0.149]
</p><p>80 In Constant Relative Risk Aversion theory [20], there is a parameter ΘCRRA = a representing the level of risk aversion, and the utility posited is UCRRA (L) = i pi 1−a /(1 − a) if a = 1, and UCRRA (L) = i pi log( i ), if a = 1. [sent-211, score-0.143]
</p><p>81 i The goal is to adaptively select a sequence of tests to present to a human subject in order to distinguish which of the four theories best explains the subject’s responses. [sent-212, score-0.583]
</p><p>82 Based on the theory that represents behaviour, one of the lotteries would be 1 2 preferred to the other, denoted by a binary response xt ∈ {1, 2}. [sent-214, score-0.253]
</p><p>83 The possible payoffs were ﬁxed to L = {−10, 0, 10} (in dollars), and the distribution (p1 , p2 , p3 ) over the payoffs was varied, where pi ∈ {0. [sent-215, score-0.145]
</p><p>84 We compare six algorithms: E FF ECX TIVE, greedily maximizing Information Gain (IG), Value of Information (VOI), Uncertainty Sampling5 (US), Generalized Binary Search (GBS), and tests selected at Random. [sent-225, score-0.374]
</p><p>85 We chose parameter values for the theories such that they made distinct predictions and were consistent with the values proposed in literature [14]. [sent-227, score-0.124]
</p><p>86 Responses were generated using a softmax function, with the t t probability of response xt = 1 given by P (xt = 1) = 1/(1 + eU (L2 )−U (L1 ) ). [sent-235, score-0.198]
</p><p>87 5  Uncertainty sampling greedily selects the test whose outcome distribution has maximum Shannon entropy. [sent-240, score-0.218]
</p><p>88 2 0  5  10 15 20 Number of tests  25  (a) Fixed parameters  30  0. [sent-256, score-0.295]
</p><p>89 After obtaining informed consent according to a protocol approved by the Institutional Review Board of Caltech, we tested 11 human subjects to determine which model ﬁt their behaviour best. [sent-287, score-0.148]
</p><p>90 Subjects were presented 30 tests using E FF ECX TIVE. [sent-289, score-0.295]
</p><p>91 To incentivise the subjects, one of these tests was picked at random, and subjects received payment based the outcome of their chosen lottery. [sent-290, score-0.468]
</p><p>92 2 subjects were best described by prospect theory since they exhibited a high degree of loss aversion and risk aversion. [sent-294, score-0.282]
</p><p>93 Although we need a larger sample to make signiﬁcant claims of the validity of different economic theories, our preliminary results indicate that subject types can be identiﬁed and there is heterogeneity in the population. [sent-297, score-0.131]
</p><p>94 6  Conclusions  In this paper, we considered the problem of adaptively selecting which noisy tests to perform in order to identify an unknown hypothesis sampled from a known prior distribution. [sent-299, score-0.525]
</p><p>95 We studied the Equivalence Class Determination problem as a means to reduce the case of noisy observations to the classic, noiseless case. [sent-300, score-0.197]
</p><p>96 We introduced EC2 , an adaptive greedy algorithm that is guaranteed to choose the same hypothesis as if it had observed the outcome of all tests, and incurs near-minimal expected cost among all policies with this guarantee. [sent-301, score-0.376]
</p><p>97 EC2 works by greedily optimizing an objective tailored to differentiate between sets of observations that lead to different decisions. [sent-306, score-0.128]
</p><p>98 We believe that our results provide an interesting direction towards providing a theoretical foundation for practical active learning and experimental design problems. [sent-310, score-0.16]
</p><p>99 Adaptive submodularity: Theory and applications in active learning and stochastic optimization. [sent-358, score-0.124]
</p><p>100 Efﬁcient test selection in active diagnosis via entropy approximation. [sent-424, score-0.193]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('xa', 0.403), ('gbs', 0.356), ('tests', 0.295), ('hi', 0.266), ('ecx', 0.258), ('ff', 0.198), ('xt', 0.198), ('tive', 0.193), ('equivalence', 0.125), ('theories', 0.124), ('active', 0.124), ('hypotheses', 0.121), ('policy', 0.12), ('aversion', 0.113), ('outcomes', 0.108), ('outcome', 0.105), ('eff', 0.097), ('hypothesis', 0.081), ('infogain', 0.081), ('ig', 0.079), ('greedily', 0.079), ('noisy', 0.078), ('adaptively', 0.071), ('noiseless', 0.07), ('subjects', 0.068), ('adaptive', 0.068), ('hj', 0.066), ('voi', 0.065), ('lottery', 0.065), ('prospect', 0.065), ('submodular', 0.064), ('caltech', 0.06), ('submodularity', 0.06), ('determination', 0.06), ('economic', 0.058), ('crra', 0.055), ('ecd', 0.055), ('lotteries', 0.055), ('odt', 0.055), ('xb', 0.055), ('greedy', 0.053), ('payoffs', 0.053), ('heuristics', 0.05), ('observations', 0.049), ('determine', 0.049), ('golovin', 0.048), ('econometrica', 0.048), ('shannon', 0.048), ('bayesian', 0.046), ('gain', 0.046), ('heterogeneity', 0.045), ('uncertainty', 0.044), ('uniquely', 0.043), ('andreas', 0.042), ('eh', 0.042), ('cutting', 0.039), ('pi', 0.039), ('xs', 0.038), ('certifying', 0.037), ('debajyoti', 0.037), ('dollars', 0.037), ('effecxtive', 0.037), ('mvs', 0.037), ('ucrra', 0.037), ('uncertaintysampling', 0.037), ('payoff', 0.036), ('design', 0.036), ('risk', 0.036), ('cost', 0.035), ('edges', 0.035), ('select', 0.035), ('inconsistent', 0.035), ('diagnosis', 0.035), ('termination', 0.035), ('krause', 0.035), ('expected', 0.034), ('test', 0.034), ('corr', 0.034), ('tree', 0.033), ('hn', 0.033), ('bellala', 0.032), ('bhavnani', 0.032), ('clayton', 0.032), ('gowtham', 0.032), ('pmin', 0.032), ('tease', 0.032), ('myopically', 0.032), ('portfolio', 0.032), ('behaviour', 0.031), ('classes', 0.031), ('decision', 0.031), ('distinguish', 0.03), ('monotone', 0.03), ('dom', 0.03), ('alg', 0.03), ('utility', 0.029), ('subject', 0.028), ('people', 0.028), ('generalized', 0.028), ('posits', 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="180-tfidf-1" href="./nips-2010-Near-Optimal_Bayesian_Active_Learning_with_Noisy_Observations.html">180 nips-2010-Near-Optimal Bayesian Active Learning with Noisy Observations</a></p>
<p>Author: Daniel Golovin, Andreas Krause, Debajyoti Ray</p><p>Abstract: We tackle the fundamental problem of Bayesian active learning with noise, where we need to adaptively select from a number of expensive tests in order to identify an unknown hypothesis sampled from a known prior distribution. In the case of noise–free observations, a greedy algorithm called generalized binary search (GBS) is known to perform near–optimally. We show that if the observations are noisy, perhaps surprisingly, GBS can perform very poorly. We develop EC2 , a novel, greedy active learning algorithm and prove that it is competitive with the optimal policy, thus obtaining the ﬁrst competitiveness guarantees for Bayesian active learning with noisy observations. Our bounds rely on a recently discovered diminishing returns property called adaptive submodularity, generalizing the classical notion of submodular set functions to adaptive policies. Our results hold even if the tests have non–uniform cost and their noise is correlated. We also propose E FF ECXTIVE , a particularly fast approximation of EC 2 , and evaluate it on a Bayesian experimental design problem involving human subjects, intended to tease apart competing economic theories of how people make decisions under uncertainty. 1</p><p>2 0.31223473 <a title="180-tfidf-2" href="./nips-2010-Extensions_of_Generalized_Binary_Search_to_Group_Identification_and_Exponential_Costs.html">88 nips-2010-Extensions of Generalized Binary Search to Group Identification and Exponential Costs</a></p>
<p>Author: Gowtham Bellala, Suresh Bhavnani, Clayton Scott</p><p>Abstract: Generalized Binary Search (GBS) is a well known greedy algorithm for identifying an unknown object while minimizing the number of “yes” or “no” questions posed about that object, and arises in problems such as active learning and active diagnosis. Here, we provide a coding-theoretic interpretation for GBS and show that GBS can be viewed as a top-down algorithm that greedily minimizes the expected number of queries required to identify an object. This interpretation is then used to extend GBS in two ways. First, we consider the case where the objects are partitioned into groups, and the objective is to identify only the group to which the object belongs. Then, we consider the case where the cost of identifying an object grows exponentially in the number of queries. In each case, we present an exact formula for the objective function involving Shannon or R´ nyi entropy, and e develop a greedy algorithm for minimizing it. 1</p><p>3 0.14223392 <a title="180-tfidf-3" href="./nips-2010-Structured_sparsity-inducing_norms_through_submodular_functions.html">258 nips-2010-Structured sparsity-inducing norms through submodular functions</a></p>
<p>Author: Francis R. Bach</p><p>Abstract: Sparse methods for supervised learning aim at ﬁnding good linear predictors from as few variables as possible, i.e., with small cardinality of their supports. This combinatorial selection problem is often turned into a convex optimization problem by replacing the cardinality function by its convex envelope (tightest convex lower bound), in this case the ℓ1 -norm. In this paper, we investigate more general set-functions than the cardinality, that may incorporate prior knowledge or structural constraints which are common in many applications: namely, we show that for nondecreasing submodular set-functions, the corresponding convex envelope can be obtained from its Lov´ sz extension, a common tool in submodua lar analysis. This deﬁnes a family of polyhedral norms, for which we provide generic algorithmic tools (subgradients and proximal operators) and theoretical results (conditions for support recovery or high-dimensional inference). By selecting speciﬁc submodular functions, we can give a new interpretation to known norms, such as those based on rank-statistics or grouped norms with potentially overlapping groups; we also deﬁne new norms, in particular ones that can be used as non-factorial priors for supervised learning.</p><p>4 0.11735377 <a title="180-tfidf-4" href="./nips-2010-Supervised_Clustering.html">261 nips-2010-Supervised Clustering</a></p>
<p>Author: Pranjal Awasthi, Reza B. Zadeh</p><p>Abstract: Despite the ubiquity of clustering as a tool in unsupervised learning, there is not yet a consensus on a formal theory, and the vast majority of work in this direction has focused on unsupervised clustering. We study a recently proposed framework for supervised clustering where there is access to a teacher. We give an improved generic algorithm to cluster any concept class in that model. Our algorithm is query-efﬁcient in the sense that it involves only a small amount of interaction with the teacher. We also present and study two natural generalizations of the model. The model assumes that the teacher response to the algorithm is perfect. We eliminate this limitation by proposing a noisy model and give an algorithm for clustering the class of intervals in this noisy model. We also propose a dynamic model where the teacher sees a random subset of the points. Finally, for datasets satisfying a spectrum of weak to strong properties, we give query bounds, and show that a class of clustering functions containing Single-Linkage will ﬁnd the target clustering under the strongest property.</p><p>5 0.10619117 <a title="180-tfidf-5" href="./nips-2010-On_a_Connection_between_Importance_Sampling_and_the_Likelihood_Ratio_Policy_Gradient.html">189 nips-2010-On a Connection between Importance Sampling and the Likelihood Ratio Policy Gradient</a></p>
<p>Author: Tang Jie, Pieter Abbeel</p><p>Abstract: Likelihood ratio policy gradient methods have been some of the most successful reinforcement learning algorithms, especially for learning on physical systems. We describe how the likelihood ratio policy gradient can be derived from an importance sampling perspective. This derivation highlights how likelihood ratio methods under-use past experience by (i) using the past experience to estimate only the gradient of the expected return U (θ) at the current policy parameterization θ, rather than to obtain a more complete estimate of U (θ), and (ii) using past experience under the current policy only rather than using all past experience to improve the estimates. We present a new policy search method, which leverages both of these observations as well as generalized baselines—a new technique which generalizes commonly used baseline techniques for policy gradient methods. Our algorithm outperforms standard likelihood ratio policy gradient algorithms on several testbeds. 1</p><p>6 0.1038917 <a title="180-tfidf-6" href="./nips-2010-Agnostic_Active_Learning_Without_Constraints.html">27 nips-2010-Agnostic Active Learning Without Constraints</a></p>
<p>7 0.10093101 <a title="180-tfidf-7" href="./nips-2010-Multi-View_Active_Learning_in_the_Non-Realizable_Case.html">173 nips-2010-Multi-View Active Learning in the Non-Realizable Case</a></p>
<p>8 0.098462716 <a title="180-tfidf-8" href="./nips-2010-Learning_from_Logged_Implicit_Exploration_Data.html">152 nips-2010-Learning from Logged Implicit Exploration Data</a></p>
<p>9 0.098403633 <a title="180-tfidf-9" href="./nips-2010-A_Computational_Decision_Theory_for_Interactive_Assistants.html">4 nips-2010-A Computational Decision Theory for Interactive Assistants</a></p>
<p>10 0.09755259 <a title="180-tfidf-10" href="./nips-2010-Effects_of_Synaptic_Weight_Diffusion_on_Learning_in_Decision_Making_Networks.html">68 nips-2010-Effects of Synaptic Weight Diffusion on Learning in Decision Making Networks</a></p>
<p>11 0.094517961 <a title="180-tfidf-11" href="./nips-2010-Nonparametric_Density_Estimation_for_Stochastic_Optimization_with_an_Observable_State_Variable.html">185 nips-2010-Nonparametric Density Estimation for Stochastic Optimization with an Observable State Variable</a></p>
<p>12 0.093434945 <a title="180-tfidf-12" href="./nips-2010-Online_Markov_Decision_Processes_under_Bandit_Feedback.html">196 nips-2010-Online Markov Decision Processes under Bandit Feedback</a></p>
<p>13 0.086736232 <a title="180-tfidf-13" href="./nips-2010-Linear_Complementarity_for_Regularized_Policy_Evaluation_and_Improvement.html">160 nips-2010-Linear Complementarity for Regularized Policy Evaluation and Improvement</a></p>
<p>14 0.083705239 <a title="180-tfidf-14" href="./nips-2010-Efficient_Minimization_of_Decomposable_Submodular_Functions.html">69 nips-2010-Efficient Minimization of Decomposable Submodular Functions</a></p>
<p>15 0.083236255 <a title="180-tfidf-15" href="./nips-2010-Predictive_State_Temporal_Difference_Learning.html">212 nips-2010-Predictive State Temporal Difference Learning</a></p>
<p>16 0.081718855 <a title="180-tfidf-16" href="./nips-2010-Nonparametric_Bayesian_Policy_Priors_for_Reinforcement_Learning.html">184 nips-2010-Nonparametric Bayesian Policy Priors for Reinforcement Learning</a></p>
<p>17 0.081451893 <a title="180-tfidf-17" href="./nips-2010-Self-Paced_Learning_for_Latent_Variable_Models.html">235 nips-2010-Self-Paced Learning for Latent Variable Models</a></p>
<p>18 0.081288263 <a title="180-tfidf-18" href="./nips-2010-Policy_gradients_in_linearly-solvable_MDPs.html">208 nips-2010-Policy gradients in linearly-solvable MDPs</a></p>
<p>19 0.081216969 <a title="180-tfidf-19" href="./nips-2010-LSTD_with_Random_Projections.html">134 nips-2010-LSTD with Random Projections</a></p>
<p>20 0.080219753 <a title="180-tfidf-20" href="./nips-2010-A_Reduction_from_Apprenticeship_Learning_to_Classification.html">14 nips-2010-A Reduction from Apprenticeship Learning to Classification</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.19), (1, -0.11), (2, 0.059), (3, 0.015), (4, -0.025), (5, -0.024), (6, -0.102), (7, -0.008), (8, 0.119), (9, -0.084), (10, 0.128), (11, 0.101), (12, -0.108), (13, -0.106), (14, -0.037), (15, 0.058), (16, -0.082), (17, -0.056), (18, -0.041), (19, 0.074), (20, -0.063), (21, 0.182), (22, 0.041), (23, -0.064), (24, -0.106), (25, -0.112), (26, -0.019), (27, 0.098), (28, -0.011), (29, -0.039), (30, -0.095), (31, 0.039), (32, 0.054), (33, 0.13), (34, 0.125), (35, -0.052), (36, -0.081), (37, -0.181), (38, -0.238), (39, -0.091), (40, -0.151), (41, 0.024), (42, 0.06), (43, -0.01), (44, 0.021), (45, 0.061), (46, 0.038), (47, -0.004), (48, -0.073), (49, -0.009)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94368851 <a title="180-lsi-1" href="./nips-2010-Near-Optimal_Bayesian_Active_Learning_with_Noisy_Observations.html">180 nips-2010-Near-Optimal Bayesian Active Learning with Noisy Observations</a></p>
<p>Author: Daniel Golovin, Andreas Krause, Debajyoti Ray</p><p>Abstract: We tackle the fundamental problem of Bayesian active learning with noise, where we need to adaptively select from a number of expensive tests in order to identify an unknown hypothesis sampled from a known prior distribution. In the case of noise–free observations, a greedy algorithm called generalized binary search (GBS) is known to perform near–optimally. We show that if the observations are noisy, perhaps surprisingly, GBS can perform very poorly. We develop EC2 , a novel, greedy active learning algorithm and prove that it is competitive with the optimal policy, thus obtaining the ﬁrst competitiveness guarantees for Bayesian active learning with noisy observations. Our bounds rely on a recently discovered diminishing returns property called adaptive submodularity, generalizing the classical notion of submodular set functions to adaptive policies. Our results hold even if the tests have non–uniform cost and their noise is correlated. We also propose E FF ECXTIVE , a particularly fast approximation of EC 2 , and evaluate it on a Bayesian experimental design problem involving human subjects, intended to tease apart competing economic theories of how people make decisions under uncertainty. 1</p><p>2 0.73921698 <a title="180-lsi-2" href="./nips-2010-Extensions_of_Generalized_Binary_Search_to_Group_Identification_and_Exponential_Costs.html">88 nips-2010-Extensions of Generalized Binary Search to Group Identification and Exponential Costs</a></p>
<p>Author: Gowtham Bellala, Suresh Bhavnani, Clayton Scott</p><p>Abstract: Generalized Binary Search (GBS) is a well known greedy algorithm for identifying an unknown object while minimizing the number of “yes” or “no” questions posed about that object, and arises in problems such as active learning and active diagnosis. Here, we provide a coding-theoretic interpretation for GBS and show that GBS can be viewed as a top-down algorithm that greedily minimizes the expected number of queries required to identify an object. This interpretation is then used to extend GBS in two ways. First, we consider the case where the objects are partitioned into groups, and the objective is to identify only the group to which the object belongs. Then, we consider the case where the cost of identifying an object grows exponentially in the number of queries. In each case, we present an exact formula for the objective function involving Shannon or R´ nyi entropy, and e develop a greedy algorithm for minimizing it. 1</p><p>3 0.41098112 <a title="180-lsi-3" href="./nips-2010-Random_Conic_Pursuit_for_Semidefinite_Programming.html">219 nips-2010-Random Conic Pursuit for Semidefinite Programming</a></p>
<p>Author: Ariel Kleiner, Ali Rahimi, Michael I. Jordan</p><p>Abstract: We present a novel algorithm, Random Conic Pursuit, that solves semideﬁnite programs (SDPs) via repeated optimization over randomly selected two-dimensional subcones of the PSD cone. This scheme is simple, easily implemented, applicable to very general SDPs, scalable, and theoretically interesting. Its advantages are realized at the expense of an ability to readily compute highly exact solutions, though useful approximate solutions are easily obtained. This property renders Random Conic Pursuit of particular interest for machine learning applications, in which the relevant SDPs are generally based upon random data and so exact minima are often not a priority. Indeed, we present empirical results to this effect for various SDPs encountered in machine learning; these experiments demonstrate the potential practical usefulness of Random Conic Pursuit. We also provide a preliminary analysis that yields insight into the theoretical properties and convergence of the algorithm. 1</p><p>4 0.36771718 <a title="180-lsi-4" href="./nips-2010-Agnostic_Active_Learning_Without_Constraints.html">27 nips-2010-Agnostic Active Learning Without Constraints</a></p>
<p>Author: Alina Beygelzimer, John Langford, Zhang Tong, Daniel J. Hsu</p><p>Abstract: We present and analyze an agnostic active learning algorithm that works without keeping a version space. This is unlike all previous approaches where a restricted set of candidate hypotheses is maintained throughout learning, and only hypotheses from this set are ever returned. By avoiding this version space approach, our algorithm sheds the computational burden and brittleness associated with maintaining version spaces, yet still allows for substantial improvements over supervised learning for classiﬁcation. 1</p><p>5 0.36535114 <a title="180-lsi-5" href="./nips-2010-Multi-View_Active_Learning_in_the_Non-Realizable_Case.html">173 nips-2010-Multi-View Active Learning in the Non-Realizable Case</a></p>
<p>Author: Wei Wang, Zhi-hua Zhou</p><p>Abstract: The sample complexity of active learning under the realizability assumption has been well-studied. The realizability assumption, however, rarely holds in practice. In this paper, we theoretically characterize the sample complexity of active learning in the non-realizable case under multi-view setting. We prove that, with unbounded Tsybakov noise, the sample complexity of multi-view active learning can be O(log 1 ), contrasting to single-view setting where the polynomial improveǫ ment is the best possible achievement. We also prove that in general multi-view setting the sample complexity of active learning with unbounded Tsybakov noise is O( 1 ), where the order of 1/ǫ is independent of the parameter in Tsybakov noise, ǫ contrasting to previous polynomial bounds where the order of 1/ǫ is related to the parameter in Tsybakov noise. 1</p><p>6 0.35960376 <a title="180-lsi-6" href="./nips-2010-Optimal_Bayesian_Recommendation_Sets_and_Myopically_Optimal_Choice_Query_Sets.html">197 nips-2010-Optimal Bayesian Recommendation Sets and Myopically Optimal Choice Query Sets</a></p>
<p>7 0.34066215 <a title="180-lsi-7" href="./nips-2010-Hashing_Hyperplane_Queries_to_Near_Points_with_Applications_to_Large-Scale_Active_Learning.html">112 nips-2010-Hashing Hyperplane Queries to Near Points with Applications to Large-Scale Active Learning</a></p>
<p>8 0.33853298 <a title="180-lsi-8" href="./nips-2010-Effects_of_Synaptic_Weight_Diffusion_on_Learning_in_Decision_Making_Networks.html">68 nips-2010-Effects of Synaptic Weight Diffusion on Learning in Decision Making Networks</a></p>
<p>9 0.33234292 <a title="180-lsi-9" href="./nips-2010-A_rational_decision_making_framework_for_inhibitory_control.html">19 nips-2010-A rational decision making framework for inhibitory control</a></p>
<p>10 0.33122644 <a title="180-lsi-10" href="./nips-2010-Structured_sparsity-inducing_norms_through_submodular_functions.html">258 nips-2010-Structured sparsity-inducing norms through submodular functions</a></p>
<p>11 0.32570726 <a title="180-lsi-11" href="./nips-2010-Block_Variable_Selection_in_Multivariate_Regression_and_High-dimensional_Causal_Inference.html">41 nips-2010-Block Variable Selection in Multivariate Regression and High-dimensional Causal Inference</a></p>
<p>12 0.31936368 <a title="180-lsi-12" href="./nips-2010-Batch_Bayesian_Optimization_via_Simulation_Matching.html">38 nips-2010-Batch Bayesian Optimization via Simulation Matching</a></p>
<p>13 0.30810815 <a title="180-lsi-13" href="./nips-2010-A_Computational_Decision_Theory_for_Interactive_Assistants.html">4 nips-2010-A Computational Decision Theory for Interactive Assistants</a></p>
<p>14 0.30360037 <a title="180-lsi-14" href="./nips-2010-Active_Estimation_of_F-Measures.html">22 nips-2010-Active Estimation of F-Measures</a></p>
<p>15 0.30176935 <a title="180-lsi-15" href="./nips-2010-Nonparametric_Density_Estimation_for_Stochastic_Optimization_with_an_Observable_State_Variable.html">185 nips-2010-Nonparametric Density Estimation for Stochastic Optimization with an Observable State Variable</a></p>
<p>16 0.30084419 <a title="180-lsi-16" href="./nips-2010-Linear_Complementarity_for_Regularized_Policy_Evaluation_and_Improvement.html">160 nips-2010-Linear Complementarity for Regularized Policy Evaluation and Improvement</a></p>
<p>17 0.29793659 <a title="180-lsi-17" href="./nips-2010-Error_Propagation_for_Approximate_Policy_and_Value_Iteration.html">78 nips-2010-Error Propagation for Approximate Policy and Value Iteration</a></p>
<p>18 0.2973299 <a title="180-lsi-18" href="./nips-2010-On_a_Connection_between_Importance_Sampling_and_the_Likelihood_Ratio_Policy_Gradient.html">189 nips-2010-On a Connection between Importance Sampling and the Likelihood Ratio Policy Gradient</a></p>
<p>19 0.2933082 <a title="180-lsi-19" href="./nips-2010-Efficient_Minimization_of_Decomposable_Submodular_Functions.html">69 nips-2010-Efficient Minimization of Decomposable Submodular Functions</a></p>
<p>20 0.29275119 <a title="180-lsi-20" href="./nips-2010-Predictive_State_Temporal_Difference_Learning.html">212 nips-2010-Predictive State Temporal Difference Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.043), (17, 0.011), (26, 0.267), (27, 0.07), (30, 0.053), (35, 0.012), (45, 0.201), (50, 0.044), (52, 0.052), (53, 0.024), (60, 0.043), (77, 0.042), (78, 0.027), (90, 0.024)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.79229742 <a title="180-lda-1" href="./nips-2010-Near-Optimal_Bayesian_Active_Learning_with_Noisy_Observations.html">180 nips-2010-Near-Optimal Bayesian Active Learning with Noisy Observations</a></p>
<p>Author: Daniel Golovin, Andreas Krause, Debajyoti Ray</p><p>Abstract: We tackle the fundamental problem of Bayesian active learning with noise, where we need to adaptively select from a number of expensive tests in order to identify an unknown hypothesis sampled from a known prior distribution. In the case of noise–free observations, a greedy algorithm called generalized binary search (GBS) is known to perform near–optimally. We show that if the observations are noisy, perhaps surprisingly, GBS can perform very poorly. We develop EC2 , a novel, greedy active learning algorithm and prove that it is competitive with the optimal policy, thus obtaining the ﬁrst competitiveness guarantees for Bayesian active learning with noisy observations. Our bounds rely on a recently discovered diminishing returns property called adaptive submodularity, generalizing the classical notion of submodular set functions to adaptive policies. Our results hold even if the tests have non–uniform cost and their noise is correlated. We also propose E FF ECXTIVE , a particularly fast approximation of EC 2 , and evaluate it on a Bayesian experimental design problem involving human subjects, intended to tease apart competing economic theories of how people make decisions under uncertainty. 1</p><p>2 0.74588257 <a title="180-lda-2" href="./nips-2010-Transduction_with_Matrix_Completion%3A_Three_Birds_with_One_Stone.html">275 nips-2010-Transduction with Matrix Completion: Three Birds with One Stone</a></p>
<p>Author: Andrew Goldberg, Ben Recht, Junming Xu, Robert Nowak, Xiaojin Zhu</p><p>Abstract: We pose transductive classiﬁcation as a matrix completion problem. By assuming the underlying matrix has a low rank, our formulation is able to handle three problems simultaneously: i) multi-label learning, where each item has more than one label, ii) transduction, where most of these labels are unspeciﬁed, and iii) missing data, where a large number of features are missing. We obtained satisfactory results on several real-world tasks, suggesting that the low rank assumption may not be as restrictive as it seems. Our method allows for different loss functions to apply on the feature and label entries of the matrix. The resulting nuclear norm minimization problem is solved with a modiﬁed ﬁxed-point continuation method that is guaranteed to ﬁnd the global optimum. 1</p><p>3 0.72054511 <a title="180-lda-3" href="./nips-2010-Efficient_Optimization_for_Discriminative_Latent_Class_Models.html">70 nips-2010-Efficient Optimization for Discriminative Latent Class Models</a></p>
<p>Author: Armand Joulin, Jean Ponce, Francis R. Bach</p><p>Abstract: Dimensionality reduction is commonly used in the setting of multi-label supervised classiﬁcation to control the learning capacity and to provide a meaningful representation of the data. We introduce a simple forward probabilistic model which is a multinomial extension of reduced rank regression, and show that this model provides a probabilistic interpretation of discriminative clustering methods with added beneﬁts in terms of number of hyperparameters and optimization. While the expectation-maximization (EM) algorithm is commonly used to learn these probabilistic models, it usually leads to local maxima because it relies on a non-convex cost function. To avoid this problem, we introduce a local approximation of this cost function, which in turn leads to a quadratic non-convex optimization problem over a product of simplices. In order to maximize quadratic functions, we propose an efﬁcient algorithm based on convex relaxations and lowrank representations of the data, capable of handling large-scale problems. Experiments on text document classiﬁcation show that the new model outperforms other supervised dimensionality reduction methods, while simulations on unsupervised clustering show that our probabilistic formulation has better properties than existing discriminative clustering methods. 1</p><p>4 0.67114222 <a title="180-lda-4" href="./nips-2010-Structured_sparsity-inducing_norms_through_submodular_functions.html">258 nips-2010-Structured sparsity-inducing norms through submodular functions</a></p>
<p>Author: Francis R. Bach</p><p>Abstract: Sparse methods for supervised learning aim at ﬁnding good linear predictors from as few variables as possible, i.e., with small cardinality of their supports. This combinatorial selection problem is often turned into a convex optimization problem by replacing the cardinality function by its convex envelope (tightest convex lower bound), in this case the ℓ1 -norm. In this paper, we investigate more general set-functions than the cardinality, that may incorporate prior knowledge or structural constraints which are common in many applications: namely, we show that for nondecreasing submodular set-functions, the corresponding convex envelope can be obtained from its Lov´ sz extension, a common tool in submodua lar analysis. This deﬁnes a family of polyhedral norms, for which we provide generic algorithmic tools (subgradients and proximal operators) and theoretical results (conditions for support recovery or high-dimensional inference). By selecting speciﬁc submodular functions, we can give a new interpretation to known norms, such as those based on rank-statistics or grouped norms with potentially overlapping groups; we also deﬁne new norms, in particular ones that can be used as non-factorial priors for supervised learning.</p><p>5 0.65773511 <a title="180-lda-5" href="./nips-2010-Distributed_Dual_Averaging_In_Networks.html">63 nips-2010-Distributed Dual Averaging In Networks</a></p>
<p>Author: Alekh Agarwal, Martin J. Wainwright, John C. Duchi</p><p>Abstract: The goal of decentralized optimization over a network is to optimize a global objective formed by a sum of local (possibly nonsmooth) convex functions using only local computation and communication. We develop and analyze distributed algorithms based on dual averaging of subgradients, and provide sharp bounds on their convergence rates as a function of the network size and topology. Our analysis clearly separates the convergence of the optimization algorithm itself from the effects of communication constraints arising from the network structure. We show that the number of iterations required by our algorithm scales inversely in the spectral gap of the network. The sharpness of this prediction is conﬁrmed both by theoretical lower bounds and simulations for various networks. 1</p><p>6 0.65767711 <a title="180-lda-6" href="./nips-2010-Short-term_memory_in_neuronal_networks_through_dynamical_compressed_sensing.html">238 nips-2010-Short-term memory in neuronal networks through dynamical compressed sensing</a></p>
<p>7 0.65640599 <a title="180-lda-7" href="./nips-2010-Two-Layer_Generalization_Analysis_for_Ranking_Using_Rademacher_Average.html">277 nips-2010-Two-Layer Generalization Analysis for Ranking Using Rademacher Average</a></p>
<p>8 0.65622592 <a title="180-lda-8" href="./nips-2010-Fast_global_convergence_rates_of_gradient_methods_for_high-dimensional_statistical_recovery.html">92 nips-2010-Fast global convergence rates of gradient methods for high-dimensional statistical recovery</a></p>
<p>9 0.65437716 <a title="180-lda-9" href="./nips-2010-A_Family_of_Penalty_Functions_for_Structured_Sparsity.html">7 nips-2010-A Family of Penalty Functions for Structured Sparsity</a></p>
<p>10 0.65347558 <a title="180-lda-10" href="./nips-2010-Learning_the_context_of_a_category.html">155 nips-2010-Learning the context of a category</a></p>
<p>11 0.65337217 <a title="180-lda-11" href="./nips-2010-Worst-Case_Linear_Discriminant_Analysis.html">287 nips-2010-Worst-Case Linear Discriminant Analysis</a></p>
<p>12 0.65328246 <a title="180-lda-12" href="./nips-2010-Construction_of_Dependent_Dirichlet_Processes_based_on_Poisson_Processes.html">51 nips-2010-Construction of Dependent Dirichlet Processes based on Poisson Processes</a></p>
<p>13 0.65305066 <a title="180-lda-13" href="./nips-2010-Learning_via_Gaussian_Herding.html">158 nips-2010-Learning via Gaussian Herding</a></p>
<p>14 0.65272319 <a title="180-lda-14" href="./nips-2010-Unsupervised_Kernel_Dimension_Reduction.html">280 nips-2010-Unsupervised Kernel Dimension Reduction</a></p>
<p>15 0.65206063 <a title="180-lda-15" href="./nips-2010-Learning_Networks_of_Stochastic_Differential_Equations.html">148 nips-2010-Learning Networks of Stochastic Differential Equations</a></p>
<p>16 0.65202892 <a title="180-lda-16" href="./nips-2010-Group_Sparse_Coding_with_a_Laplacian_Scale_Mixture_Prior.html">109 nips-2010-Group Sparse Coding with a Laplacian Scale Mixture Prior</a></p>
<p>17 0.65194273 <a title="180-lda-17" href="./nips-2010-The_LASSO_risk%3A_asymptotic_results_and_real_world_examples.html">265 nips-2010-The LASSO risk: asymptotic results and real world examples</a></p>
<p>18 0.65162635 <a title="180-lda-18" href="./nips-2010-Fast_Large-scale_Mixture_Modeling_with_Component-specific_Data_Partitions.html">90 nips-2010-Fast Large-scale Mixture Modeling with Component-specific Data Partitions</a></p>
<p>19 0.65147257 <a title="180-lda-19" href="./nips-2010-Computing_Marginal_Distributions_over_Continuous_Markov_Networks_for_Statistical_Relational_Learning.html">49 nips-2010-Computing Marginal Distributions over Continuous Markov Networks for Statistical Relational Learning</a></p>
<p>20 0.65140301 <a title="180-lda-20" href="./nips-2010-Extended_Bayesian_Information_Criteria_for_Gaussian_Graphical_Models.html">87 nips-2010-Extended Bayesian Information Criteria for Gaussian Graphical Models</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
