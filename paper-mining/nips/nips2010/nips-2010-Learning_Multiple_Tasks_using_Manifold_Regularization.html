<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>146 nips-2010-Learning Multiple Tasks using Manifold Regularization</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-146" href="#">nips2010-146</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>146 nips-2010-Learning Multiple Tasks using Manifold Regularization</h1>
<br/><p>Source: <a title="nips-2010-146-pdf" href="http://papers.nips.cc/paper/4163-learning-multiple-tasks-using-manifold-regularization.pdf">pdf</a></p><p>Author: Arvind Agarwal, Samuel Gerber, Hal Daume</p><p>Abstract: We present a novel method for multitask learning (MTL) based on manifold regularization: assume that all task parameters lie on a manifold. This is the generalization of a common assumption made in the existing literature: task parameters share a common linear subspace. One proposed method uses the projection distance from the manifold to regularize the task parameters. The manifold structure and the task parameters are learned using an alternating optimization framework. When the manifold structure is ﬁxed, our method decomposes across tasks which can be learnt independently. An approximation of the manifold regularization scheme is presented that preserves the convexity of the single task learning problem, and makes the proposed MTL framework efﬁcient and easy to implement. We show the efﬁcacy of our method on several datasets. 1</p><p>Reference: <a title="nips-2010-146-reference" href="../nips2010_reference/nips-2010-Learning_Multiple_Tasks_using_Manifold_Regularization_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract We present a novel method for multitask learning (MTL) based on manifold regularization: assume that all task parameters lie on a manifold. [sent-7, score-0.849]
</p><p>2 This is the generalization of a common assumption made in the existing literature: task parameters share a common linear subspace. [sent-8, score-0.242]
</p><p>3 One proposed method uses the projection distance from the manifold to regularize the task parameters. [sent-9, score-0.846]
</p><p>4 The manifold structure and the task parameters are learned using an alternating optimization framework. [sent-10, score-0.734]
</p><p>5 When the manifold structure is ﬁxed, our method decomposes across tasks which can be learnt independently. [sent-11, score-0.747]
</p><p>6 An approximation of the manifold regularization scheme is presented that preserves the convexity of the single task learning problem, and makes the proposed MTL framework efﬁcient and easy to implement. [sent-12, score-0.713]
</p><p>7 1  Introduction  Recently, it has been shown that learning multiple tasks together helps learning [8, 19, 9] when the tasks are related, and one is able to use an appropriate notion of task relatedness. [sent-14, score-0.471]
</p><p>8 This notion of relatedness is usually incorporated in the form of a regularizer [4, 16, 13] or a prior [15, 22, 21]. [sent-17, score-0.256]
</p><p>9 In this work we present a novel approach for multitask learning (MTL) that considers a notion of relatedness based on ideas from manifold regularization1 . [sent-18, score-0.78]
</p><p>10 Our approach is based on the assumption that the parameters of related tasks can not vary arbitrarily but rather lie on a low dimensional manifold. [sent-19, score-0.271]
</p><p>11 A similar idea underlies the standard manifold learning problems: the data does not change arbitrarily, but instead follows a manifold structure. [sent-20, score-1.012]
</p><p>12 Our assumption is also a generalization of the assumption made in [1] which assumes that all tasks share a linear subspace, and a learning framework consists of learning this linear subspace and task parameters simultaneously. [sent-21, score-0.533]
</p><p>13 In our proposed approach we learn the task parameters and the task-manifold alternatively, learning one while keeping the other ﬁxed, similar to [4]. [sent-23, score-0.235]
</p><p>14 First, we learn all task parameters using a single task learning (STL) method, and then use these task parameters to learn the initial task manifold. [sent-24, score-0.716]
</p><p>15 The task-manifold is then used to relearn the task parameters using manifold regularization. [sent-25, score-0.737]
</p><p>16 Learning of manifold and task parameters is repeated until convergence. [sent-26, score-0.684]
</p><p>17 We emphasize that when we learn the task parameters (keeping the manifold structure ﬁxed), the MTL framework decomposes across the ∗  This work was done at School of Computing, University of Utah, Salt Lake City, Utah It is not to be confused with the manifold regularization presented in [7]. [sent-27, score-1.373]
</p><p>18 Note that unlike most manifold learning algorithms, our framework learns an explicit representation of the manifold and naturally extends to new tasks. [sent-32, score-1.039]
</p><p>19 Whenever a new task arrives, one can simply use the existing manifold to learn the parameters of the new task. [sent-33, score-0.722]
</p><p>20 Given a black box for manifold learning, STL algorithms can be adapted to the proposed MTL setting. [sent-36, score-0.506]
</p><p>21 2  Related Work  In MTL, task relatedness is a fundamental question and models differ in the ways they answer this question. [sent-40, score-0.305]
</p><p>22 Like our method, most of the existing methods ﬁrst assume a structure that deﬁnes the task relatedness, and then incorporate this structure in the MTL framework in the form of a regularizer [4, 16, 13]. [sent-41, score-0.291]
</p><p>23 One plausible approach is to assume that all task parameters lie in a subspace [1]. [sent-42, score-0.282]
</p><p>24 The tasks are learned by forcing the parameters to lie in a common linear subspace therefore exploiting the assumed relatedness in the model. [sent-43, score-0.505]
</p><p>25 In this work, the relatedness structure is forced by applying a function F on a covariance matrix D which yields a regularization of the form tr(F (D)W W T ) on the parameters W . [sent-47, score-0.261]
</p><p>26 Here, the function F can model different kind of relatedness structures among tasks including the linear subspace structure [1]. [sent-48, score-0.429]
</p><p>27 Given a function F , this framework learns both, the relatedness matrix D and the task parameters W . [sent-49, score-0.368]
</p><p>28 Our framework generalizes the linear framework by introducing the nonlinearity through the manifold structure learned automatically from the data, and thus avoids the need of any external function. [sent-52, score-0.668]
</p><p>29 This method in spirit is very similar to our method except that we learn an explicit manifold therefore our method is naturally extensible to new tasks. [sent-56, score-0.649]
</p><p>30 Another work that models the task relatedness in the form of proximity of the parameters is [16] which assumes that task parameters wt for each task is close to some common task w0 with some variance vt . [sent-57, score-0.867]
</p><p>31 The task parameters are learned under this cluster assumption by minimizing a combination of different penalty functions. [sent-60, score-0.226]
</p><p>32 There is another line of work [10], where task relatedness is modeled in term of a matrix B which needs to be provided externally. [sent-61, score-0.305]
</p><p>33 There is also a large body of work on multitask learning that ﬁnd the shared structure in the tasks using Bayesian inference [23, 24, 9], which in spirit, is similar to the above approaches, but done in a Bayesian way. [sent-62, score-0.271]
</p><p>34 As mentioned earlier, our framework assumes that the tasks parameters lie on a manifold which is a step further to the assumption made in [1] i. [sent-66, score-0.784]
</p><p>35 , the task parameters lie on a linear subspace or share a common set of features. [sent-68, score-0.324]
</p><p>36 Similar to the linear subspace algorithm [1] that learns the task parameters (and the shared subspace) by regularizing the STL framework with the orthogonal projections of the task parameters onto the subspace, we propose to learn the task parameters (and non-linear subspace i. [sent-69, score-0.842]
</p><p>37 , task-manifold) by 2  regularizing the STL with the projection distance of the task parameters from this task-manifold (see Figure 1). [sent-71, score-0.36]
</p><p>38 Now for each task t, let θt be the parameter vector, referred as the task parameter. [sent-88, score-0.284]
</p><p>39 Restricting ft to the functions in the RKHS and denoting it by f (x, θt ) = θt , φ(x) , single task learning solves the following optimization problem: 2  L(f (x; θt ), y) + λ ||ft ||Hk ,  ∗ θt = arg min θt  (1)  x∈Xt  here λ is a regularization parameter. [sent-95, score-0.24]
</p><p>40 w  w∗  Figure 1: Projection of the estimated parameters w of the task in hand on the manifold learned from all tasks parameters. [sent-98, score-0.865]
</p><p>41 In MTL, tasks are related, this notion of relatedness is incorporated through a regularizer. [sent-101, score-0.337]
</p><p>42 For example, for the assumption that the task parameters are close to a common task θ0 , regularizer would just be θt − θ0 2 . [sent-113, score-0.416]
</p><p>43 , θT ) into T different regularizers u(θt , M) such that u(θt , M) regularizes the parameter of task t while considering the effect of other tasks through the manifold M. [sent-117, score-0.803]
</p><p>44 If manifold structure M is ﬁxed then the above optimization problem decomposes into T independent optimization problems. [sent-126, score-0.557]
</p><p>45 In our approach, the regularizer depends on the structure of the manifold constructed from the task parameters {θ1 , . [sent-127, score-0.782]
</p><p>46 Now one can use this projection distance as a regularizer u(θt , M) in the cost function since all task parameters are assumed to lie on the task manifold M. [sent-132, score-1.101]
</p><p>47 H  (4)  x∈Xt  Since the manifold structure is not known, the cost function (4) needs to be optimized simultaneously for the task parameters (θ1 . [sent-134, score-0.708]
</p><p>48 Next, we ﬁx the manifold M, and learn the task parameters by minimizing (4). [sent-140, score-0.722]
</p><p>49 an expression for computing the projection distance of task parameters from the manifold. [sent-143, score-0.341]
</p><p>50 1  Manifold Regularization  Our approach relies heavily on the capability to learn a manifold, and to be able to compute the gradient of the projection distances onto the manifold. [sent-146, score-0.219]
</p><p>51 Much recent work in manifold learning focused on uncovering low dimensional representation [18, 6, 17, 20] of the data. [sent-147, score-0.526]
</p><p>52 Recent work [11] addresses this issues and proposes a manifold learning algorithm, based on the idea of principal surfaces [12]. [sent-151, score-0.548]
</p><p>53 It explicitly represents the manifold in the ambient space as a parametric surface which can be used to compute the projection distance and its gradient. [sent-152, score-0.669]
</p><p>54 The method is based on minimizing the expected reconstruction error E[g(h(θ)) − θ] of the task parameter θ onto the manifold M. [sent-154, score-0.709]
</p><p>55 Here h is the mapping from the manifold to the lower dimensional Euclidean space and g is the mapping from the lower dimensional Euclidean space to the manifold. [sent-155, score-0.546]
</p><p>56 Thus, the composition g ◦ h maps a point belonging to manifold to the manifold, using the mapping to the Euclidean space as an intermediate step. [sent-156, score-0.506]
</p><p>57 These mappings g and h can be formulated in terms of kernel regressions over the data points: h(θ) =  T X j=1  Kθ (θ − θj ) zj PT l=1 Kθ (θ − θl )  (5)  with Kθ a kernel function and zj a set of parameters to be estimated in the manifold learning process. [sent-158, score-0.673]
</p><p>58 In [11] it is shown that in the limit, as the number of samples to learn from increases, h indeed yields an orthogonal projection onto g. [sent-166, score-0.233]
</p><p>59 the manifold learning, can be done through gradient descent on the sample mean of the projection distance T 1 i=1 g(h(θi )) − θi using a global manifold learning approach for initialization. [sent-169, score-1.206]
</p><p>60 Once h is estiT mated, the projection distance is immediate by PM = θ − g(h(θ))  2  = θ − θM  2  (7)  For the optimization of (4) we need the gradient of the projection distance which is dPM (θ) dg(r) dh(θ) = 2(g(h(θ)) − θ) |r=h(θ) . [sent-170, score-0.357]
</p><p>61 dθ dr dθ  (8)  The projection distance for a single task parameters is O(n) due to the deﬁnition of h and g as kernel regressions which show up in the projection distance gradient in dg(r) |r=h(θ) and dh(θ) . [sent-171, score-0.652]
</p><p>62 dr dθ This is fairly expensive therefore we propose an approximation, justiﬁed by the convergence to an orthogonal projection of h, to the exact projection gradient. [sent-172, score-0.332]
</p><p>63 end while The proposed manifold regularization approximation allows to use any STL method without much change in the optimization of the STL problem. [sent-196, score-0.579]
</p><p>64 The proposed method for MTL pipelines manifold learning with the STL. [sent-197, score-0.541]
</p><p>65 , one does not have to worry about moving the projection of the point on the manifold during the gradient step. [sent-201, score-0.661]
</p><p>66 This approximation allows one to treat the manifold regularizer similar to the RKHS regularizer θt 2 and solve the generalized learning problem ˜M (4) with non-linear kernels. [sent-203, score-0.654]
</p><p>67 In the learning framework (4), the loss function is L(x, y, wt ) = (y − wt , x )2 with linear kernel k(x, y) = x, y . [sent-208, score-0.229]
</p><p>68 The cost function for linear regression can now be written as: CP =  T X“ X t=1  (y − wt , x )2 +  x∈Xt  ” λ ||wt ||2 + γPM (wt ) 2  (11)  This cost function may be convex or non-convex depending upon the manifold terms PM (wt ). [sent-210, score-0.616]
</p><p>69 wt is the orthogonal projection of w on the manifold. [sent-214, score-0.233]
</p><p>70 3  Algorithm Description  The algorithm for MTL with manifold regularization is straightforward and shown in Algorithm 1. [sent-216, score-0.544]
</p><p>71 Keeping the manifold structure ﬁxed, we relearn all task parameters using manifold regularization. [sent-221, score-1.267]
</p><p>72 Equation (9) is used to compute the gradient of the projection distance used in relearning the parameters. [sent-222, score-0.225]
</p><p>73 Once the parameters for all tasks are learned, the manifold is re-estimated based on the updated task parameters. [sent-225, score-0.839]
</p><p>74 This data is generated from the task parameters sampled from a known manifold (swiss roll). [sent-231, score-0.684]
</p><p>75 The data is generated by ﬁrst sampling the points from the 3-dimensional swiss roll, and then using these points as the task parameters to generate the examples using the linear regression model. [sent-232, score-0.299]
</p><p>76 First, the task at hand (this is linear) is a relatively easy task and more number of examples give a nearly perfect regression model with the STL method itself, leaving almost no room for improvement. [sent-235, score-0.388]
</p><p>77 Blue dots denote the MTL performance of our method while green crosses denote the performance of the baseline method [4]. [sent-244, score-0.239]
</p><p>78 It is clear from Figure 2(a) that our method is able to use the manifold information therefore outperform both STL and MTL-baseline methods. [sent-247, score-0.566]
</p><p>79 2  Real Regression Dataset  We now evaluate our method on two real datasets school dataset and computer survey dataset [14], the same datasets as used in the baseline model [4]. [sent-258, score-0.462]
</p><p>80 Moreover they have also been used in previous MTL studies, for example, school dataset in [5, 10] and computer dataset in [14]. [sent-259, score-0.252]
</p><p>81 Green crosses are the baseline method and blue dots are the manifold method. [sent-303, score-0.691]
</p><p>82 Similar to the synthetic dataset, hyperparameters of the baseline method and manifold method (γ and λ) were tuned on a small validation dataset picked randomly from the training set. [sent-328, score-0.845]
</p><p>83 In order to see if learning tasks simultaneously helps, we did not consider the zero value while tuning the hyperparameters of MTL to avoid the reduction of MTL method to STL ones. [sent-332, score-0.228]
</p><p>84 Figure 3(a) and Figure 3(b) shows the taskwise performance of the computer and school datasets respectively. [sent-333, score-0.227]
</p><p>85 For the school dataset, we perform better than both STL and the baseline method though relative performance improvement is not as signiﬁcant as in the computer dataset. [sent-338, score-0.297]
</p><p>86 On the school dataset, the baseline method has a mixed behavior relative to the STL method, performing good on some tasks while performing worse on others. [sent-339, score-0.401]
</p><p>87 We emphasize that the baseline method has two parameters 7  that are very important, the regularization parameter and the P . [sent-345, score-0.249]
</p><p>88 6  0  50  100  150  200  0  50  100  150  Number of tasks  Number of tasks  (a)  (b)  Figure 4: RMSE Vs number of tasks for (a) computer dataset (b) school dataset Now we show the performance variation with respect to the number of training examples. [sent-358, score-0.717]
</p><p>89 Note that when the number of examples is relatively low, the baseline method outperforms our method because we do not have enough examples to estimate the parameters of the task which is used for the manifold construction. [sent-361, score-0.953]
</p><p>90 But as we increase the number of examples, we get better estimate of the parameters, hence better manifold regularization. [sent-362, score-0.506]
</p><p>91 Variation of the performance with n is not shown for the computer dataset because computer dataset has only 20 examples per task. [sent-364, score-0.22]
</p><p>92 Performance variation with respect to the number of tasks for school and computer datasets is shown in Figure 4. [sent-365, score-0.311]
</p><p>93 We outperform STL method and the baseline method for the computer dataset while perform better/equal on the school dataset. [sent-366, score-0.394]
</p><p>94 It suggests that tasks in school datasets are related linearly (Manifold and baseline methods have the same performance 4 ) while tasks in the computer dataset are related non-linearly, which is why baseline method performs poor compared to the STL method. [sent-368, score-0.787]
</p><p>95 This is especially true for the computer dataset since it only has 13 features and only a few tasks are required to learn the task relatedness structure. [sent-371, score-0.586]
</p><p>96 In summary, our method improves the performance over STL in all of these datasets (no negative transfer), while baseline method performs comparatively on the school dataset and performs worse on the computer dataset. [sent-372, score-0.42]
</p><p>97 5  Conclusion  We have presented a novel method for multitask learning based on a natural and intuitive assumption about the task relatedness. [sent-373, score-0.291]
</p><p>98 We have used the manifold assumption to enforce the task relatedness which is a generalization of the previous notions of relatedness. [sent-374, score-0.852]
</p><p>99 We emphasize that unlike the baseline method, we improve over single task learning in almost all cases and do not encounter the negative transfer. [sent-380, score-0.301]
</p><p>100 This is the reason we perform equal on the school dataset when the number of tasks is high. [sent-383, score-0.319]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('manifold', 0.506), ('mtl', 0.469), ('stl', 0.455), ('rmse', 0.204), ('relatedness', 0.163), ('tasks', 0.155), ('task', 0.142), ('projection', 0.124), ('baseline', 0.111), ('school', 0.1), ('multitask', 0.092), ('regularizer', 0.074), ('pm', 0.074), ('argyriou', 0.074), ('taskwise', 0.071), ('subspace', 0.066), ('dataset', 0.064), ('wt', 0.064), ('xt', 0.062), ('ft', 0.06), ('utah', 0.057), ('dg', 0.057), ('kernel', 0.053), ('avgbaseline', 0.053), ('avgmanifold', 0.053), ('relearn', 0.053), ('rkhs', 0.048), ('avg', 0.048), ('orthogonal', 0.045), ('examples', 0.044), ('micchelli', 0.042), ('students', 0.04), ('kr', 0.04), ('distance', 0.039), ('dh', 0.039), ('evgeniou', 0.039), ('dr', 0.039), ('lie', 0.038), ('regularization', 0.038), ('learn', 0.038), ('external', 0.037), ('parameters', 0.036), ('gerber', 0.035), ('method', 0.035), ('synthetic', 0.033), ('belkin', 0.033), ('datasets', 0.032), ('salt', 0.031), ('dpm', 0.031), ('relearning', 0.031), ('swiss', 0.031), ('gradient', 0.031), ('cp', 0.03), ('emphasize', 0.029), ('lake', 0.029), ('roll', 0.029), ('carin', 0.029), ('transfer', 0.027), ('improvement', 0.027), ('framework', 0.027), ('decomposes', 0.027), ('learned', 0.026), ('giving', 0.026), ('euclidean', 0.026), ('onto', 0.026), ('outperform', 0.025), ('examination', 0.025), ('liao', 0.025), ('regressions', 0.025), ('rated', 0.025), ('regression', 0.025), ('computer', 0.024), ('daum', 0.024), ('structure', 0.024), ('yt', 0.023), ('tuned', 0.023), ('principal', 0.023), ('representer', 0.022), ('hal', 0.022), ('pontil', 0.022), ('assumption', 0.022), ('share', 0.021), ('linear', 0.021), ('dimensional', 0.02), ('dots', 0.02), ('nt', 0.02), ('crosses', 0.019), ('regularizing', 0.019), ('dimensionality', 0.019), ('hyperparameters', 0.019), ('reduction', 0.019), ('keeping', 0.019), ('surfaces', 0.019), ('picked', 0.019), ('negative', 0.019), ('enforce', 0.019), ('notion', 0.019), ('green', 0.019), ('clustered', 0.018), ('city', 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999964 <a title="146-tfidf-1" href="./nips-2010-Learning_Multiple_Tasks_using_Manifold_Regularization.html">146 nips-2010-Learning Multiple Tasks using Manifold Regularization</a></p>
<p>Author: Arvind Agarwal, Samuel Gerber, Hal Daume</p><p>Abstract: We present a novel method for multitask learning (MTL) based on manifold regularization: assume that all task parameters lie on a manifold. This is the generalization of a common assumption made in the existing literature: task parameters share a common linear subspace. One proposed method uses the projection distance from the manifold to regularize the task parameters. The manifold structure and the task parameters are learned using an alternating optimization framework. When the manifold structure is ﬁxed, our method decomposes across tasks which can be learnt independently. An approximation of the manifold regularization scheme is presented that preserves the convexity of the single task learning problem, and makes the proposed MTL framework efﬁcient and easy to implement. We show the efﬁcacy of our method on several datasets. 1</p><p>2 0.41986254 <a title="146-tfidf-2" href="./nips-2010-Learning_Multiple_Tasks_with_a_Sparse_Matrix-Normal_Penalty.html">147 nips-2010-Learning Multiple Tasks with a Sparse Matrix-Normal Penalty</a></p>
<p>Author: Yi Zhang, Jeff G. Schneider</p><p>Abstract: In this paper, we propose a matrix-variate normal penalty with sparse inverse covariances to couple multiple tasks. Learning multiple (parametric) models can be viewed as estimating a matrix of parameters, where rows and columns of the matrix correspond to tasks and features, respectively. Following the matrix-variate normal density, we design a penalty that decomposes the full covariance of matrix elements into the Kronecker product of row covariance and column covariance, which characterizes both task relatedness and feature representation. Several recently proposed methods are variants of the special cases of this formulation. To address the overﬁtting issue and select meaningful task and feature structures, we include sparse covariance selection into our matrix-normal regularization via ℓ1 penalties on task and feature inverse covariances. We empirically study the proposed method and compare with related models in two real-world problems: detecting landmines in multiple ﬁelds and recognizing faces between different subjects. Experimental results show that the proposed framework provides an effective and ﬂexible way to model various different structures of multiple tasks.</p><p>3 0.20131718 <a title="146-tfidf-3" href="./nips-2010-Sample_Complexity_of_Testing_the_Manifold_Hypothesis.html">232 nips-2010-Sample Complexity of Testing the Manifold Hypothesis</a></p>
<p>Author: Hariharan Narayanan, Sanjoy Mitter</p><p>Abstract: The hypothesis that high dimensional data tends to lie in the vicinity of a low dimensional manifold is the basis of a collection of methodologies termed Manifold Learning. In this paper, we study statistical aspects of the question of ﬁtting a manifold with a nearly optimal least squared error. Given upper bounds on the dimension, volume, and curvature, we show that Empirical Risk Minimization can produce a nearly optimal manifold using a number of random samples that is independent of the ambient dimension of the space in which data lie. We obtain an upper bound on the required number of samples that depends polynomially on the curvature, exponentially on the intrinsic dimension, and linearly on the intrinsic volume. For constant error, we prove a matching minimax lower bound on the sample complexity that shows that this dependence on intrinsic dimension, volume log 1 and curvature is unavoidable. Whether the known lower bound of O( k + 2 δ ) 2 for the sample complexity of Empirical Risk minimization on k−means applied to data in a unit ball of arbitrary dimension is tight, has been an open question since 1997 [3]. Here is the desired bound on the error and δ is a bound on the probability of failure. We improve the best currently known upper bound [14] of 2 log 1 log4 k log 1 O( k2 + 2 δ ) to O k min k, 2 + 2 δ . Based on these results, we 2 devise a simple algorithm for k−means and another that uses a family of convex programs to ﬁt a piecewise linear curve of a speciﬁed length to high dimensional data, where the sample complexity is independent of the ambient dimension. 1</p><p>4 0.19166465 <a title="146-tfidf-4" href="./nips-2010-Large_Margin_Multi-Task_Metric_Learning.html">138 nips-2010-Large Margin Multi-Task Metric Learning</a></p>
<p>Author: Shibin Parameswaran, Kilian Q. Weinberger</p><p>Abstract: Multi-task learning (MTL) improves the prediction performance on multiple, different but related, learning problems through shared parameters or representations. One of the most prominent multi-task learning algorithms is an extension to support vector machines (svm) by Evgeniou et al. [15]. Although very elegant, multi-task svm is inherently restricted by the fact that support vector machines require each class to be addressed explicitly with its own weight vector which, in a multi-task setting, requires the different learning tasks to share the same set of classes. This paper proposes an alternative formulation for multi-task learning by extending the recently published large margin nearest neighbor (lmnn) algorithm to the MTL paradigm. Instead of relying on separating hyperplanes, its decision function is based on the nearest neighbor rule which inherently extends to many classes and becomes a natural ﬁt for multi-task learning. We evaluate the resulting multi-task lmnn on real-world insurance data and speech classiﬁcation problems and show that it consistently outperforms single-task kNN under several metrics and state-of-the-art MTL classiﬁers. 1</p><p>5 0.15924658 <a title="146-tfidf-5" href="./nips-2010-Online_Learning_in_The_Manifold_of_Low-Rank_Matrices.html">195 nips-2010-Online Learning in The Manifold of Low-Rank Matrices</a></p>
<p>Author: Uri Shalit, Daphna Weinshall, Gal Chechik</p><p>Abstract: When learning models that are represented in matrix forms, enforcing a low-rank constraint can dramatically improve the memory and run time complexity, while providing a natural regularization of the model. However, naive approaches for minimizing functions over the set of low-rank matrices are either prohibitively time consuming (repeated singular value decomposition of the matrix) or numerically unstable (optimizing a factored representation of the low rank matrix). We build on recent advances in optimization over manifolds, and describe an iterative online learning procedure, consisting of a gradient step, followed by a second-order retraction back to the manifold. While the ideal retraction is hard to compute, and so is the projection operator that approximates it, we describe another second-order retraction that can be computed efﬁciently, with run time and memory complexity of O ((n + m)k) for a rank-k matrix of dimension m × n, given rank-one gradients. We use this algorithm, LORETA, to learn a matrixform similarity measure over pairs of documents represented as high dimensional vectors. LORETA improves the mean average precision over a passive- aggressive approach in a factorized model, and also improves over a full model trained over pre-selected features using the same memory requirements. LORETA also showed consistent improvement over standard methods in a large (1600 classes) multi-label image classiﬁcation task. 1</p><p>6 0.1569379 <a title="146-tfidf-6" href="./nips-2010-Multitask_Learning_without_Label_Correspondences.html">177 nips-2010-Multitask Learning without Label Correspondences</a></p>
<p>7 0.13427962 <a title="146-tfidf-7" href="./nips-2010-Humans_Learn_Using_Manifolds%2C_Reluctantly.html">114 nips-2010-Humans Learn Using Manifolds, Reluctantly</a></p>
<p>8 0.074925311 <a title="146-tfidf-8" href="./nips-2010-Spectral_Regularization_for_Support_Estimation.html">250 nips-2010-Spectral Regularization for Support Estimation</a></p>
<p>9 0.073773548 <a title="146-tfidf-9" href="./nips-2010-Probabilistic_Multi-Task_Feature_Selection.html">217 nips-2010-Probabilistic Multi-Task Feature Selection</a></p>
<p>10 0.072998747 <a title="146-tfidf-10" href="./nips-2010-Inductive_Regularized_Learning_of_Kernel_Functions.html">124 nips-2010-Inductive Regularized Learning of Kernel Functions</a></p>
<p>11 0.069814786 <a title="146-tfidf-11" href="./nips-2010-New_Adaptive_Algorithms_for_Online_Classification.html">182 nips-2010-New Adaptive Algorithms for Online Classification</a></p>
<p>12 0.062041838 <a title="146-tfidf-12" href="./nips-2010-Random_Projection_Trees_Revisited.html">220 nips-2010-Random Projection Trees Revisited</a></p>
<p>13 0.058069091 <a title="146-tfidf-13" href="./nips-2010-Unsupervised_Kernel_Dimension_Reduction.html">280 nips-2010-Unsupervised Kernel Dimension Reduction</a></p>
<p>14 0.057053741 <a title="146-tfidf-14" href="./nips-2010-Decoding_Ipsilateral_Finger_Movements_from_ECoG_Signals_in_Humans.html">57 nips-2010-Decoding Ipsilateral Finger Movements from ECoG Signals in Humans</a></p>
<p>15 0.055630669 <a title="146-tfidf-15" href="./nips-2010-Auto-Regressive_HMM_Inference_with_Incomplete_Data_for_Short-Horizon_Wind_Forecasting.html">35 nips-2010-Auto-Regressive HMM Inference with Incomplete Data for Short-Horizon Wind Forecasting</a></p>
<p>16 0.051986579 <a title="146-tfidf-16" href="./nips-2010-Kernel_Descriptors_for_Visual_Recognition.html">133 nips-2010-Kernel Descriptors for Visual Recognition</a></p>
<p>17 0.051792875 <a title="146-tfidf-17" href="./nips-2010-Towards_Holistic_Scene_Understanding%3A_Feedback_Enabled_Cascaded_Classification_Models.html">272 nips-2010-Towards Holistic Scene Understanding: Feedback Enabled Cascaded Classification Models</a></p>
<p>18 0.050836258 <a title="146-tfidf-18" href="./nips-2010-Efficient_Optimization_for_Discriminative_Latent_Class_Models.html">70 nips-2010-Efficient Optimization for Discriminative Latent Class Models</a></p>
<p>19 0.050358985 <a title="146-tfidf-19" href="./nips-2010-Deep_Coding_Network.html">59 nips-2010-Deep Coding Network</a></p>
<p>20 0.049999479 <a title="146-tfidf-20" href="./nips-2010-Parallelized_Stochastic_Gradient_Descent.html">202 nips-2010-Parallelized Stochastic Gradient Descent</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.163), (1, 0.038), (2, 0.077), (3, -0.045), (4, 0.093), (5, -0.002), (6, 0.091), (7, -0.044), (8, -0.18), (9, -0.012), (10, 0.08), (11, 0.025), (12, 0.197), (13, -0.021), (14, 0.131), (15, 0.04), (16, 0.052), (17, -0.236), (18, -0.052), (19, 0.01), (20, -0.328), (21, -0.202), (22, 0.017), (23, 0.051), (24, -0.065), (25, -0.092), (26, -0.319), (27, -0.097), (28, 0.055), (29, 0.144), (30, -0.008), (31, 0.042), (32, 0.159), (33, -0.001), (34, -0.062), (35, -0.146), (36, -0.031), (37, 0.039), (38, -0.071), (39, -0.051), (40, 0.012), (41, -0.007), (42, 0.064), (43, -0.078), (44, 0.011), (45, -0.02), (46, -0.097), (47, 0.068), (48, 0.07), (49, 0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96325004 <a title="146-lsi-1" href="./nips-2010-Learning_Multiple_Tasks_using_Manifold_Regularization.html">146 nips-2010-Learning Multiple Tasks using Manifold Regularization</a></p>
<p>Author: Arvind Agarwal, Samuel Gerber, Hal Daume</p><p>Abstract: We present a novel method for multitask learning (MTL) based on manifold regularization: assume that all task parameters lie on a manifold. This is the generalization of a common assumption made in the existing literature: task parameters share a common linear subspace. One proposed method uses the projection distance from the manifold to regularize the task parameters. The manifold structure and the task parameters are learned using an alternating optimization framework. When the manifold structure is ﬁxed, our method decomposes across tasks which can be learnt independently. An approximation of the manifold regularization scheme is presented that preserves the convexity of the single task learning problem, and makes the proposed MTL framework efﬁcient and easy to implement. We show the efﬁcacy of our method on several datasets. 1</p><p>2 0.74970376 <a title="146-lsi-2" href="./nips-2010-Learning_Multiple_Tasks_with_a_Sparse_Matrix-Normal_Penalty.html">147 nips-2010-Learning Multiple Tasks with a Sparse Matrix-Normal Penalty</a></p>
<p>Author: Yi Zhang, Jeff G. Schneider</p><p>Abstract: In this paper, we propose a matrix-variate normal penalty with sparse inverse covariances to couple multiple tasks. Learning multiple (parametric) models can be viewed as estimating a matrix of parameters, where rows and columns of the matrix correspond to tasks and features, respectively. Following the matrix-variate normal density, we design a penalty that decomposes the full covariance of matrix elements into the Kronecker product of row covariance and column covariance, which characterizes both task relatedness and feature representation. Several recently proposed methods are variants of the special cases of this formulation. To address the overﬁtting issue and select meaningful task and feature structures, we include sparse covariance selection into our matrix-normal regularization via ℓ1 penalties on task and feature inverse covariances. We empirically study the proposed method and compare with related models in two real-world problems: detecting landmines in multiple ﬁelds and recognizing faces between different subjects. Experimental results show that the proposed framework provides an effective and ﬂexible way to model various different structures of multiple tasks.</p><p>3 0.61628956 <a title="146-lsi-3" href="./nips-2010-Humans_Learn_Using_Manifolds%2C_Reluctantly.html">114 nips-2010-Humans Learn Using Manifolds, Reluctantly</a></p>
<p>Author: Tim Rogers, Chuck Kalish, Joseph Harrison, Xiaojin Zhu, Bryan R. Gibson</p><p>Abstract: When the distribution of unlabeled data in feature space lies along a manifold, the information it provides may be used by a learner to assist classiﬁcation in a semi-supervised setting. While manifold learning is well-known in machine learning, the use of manifolds in human learning is largely unstudied. We perform a set of experiments which test a human’s ability to use a manifold in a semisupervised learning task, under varying conditions. We show that humans may be encouraged into using the manifold, overcoming the strong preference for a simple, axis-parallel linear boundary. 1</p><p>4 0.49576554 <a title="146-lsi-4" href="./nips-2010-Large_Margin_Multi-Task_Metric_Learning.html">138 nips-2010-Large Margin Multi-Task Metric Learning</a></p>
<p>Author: Shibin Parameswaran, Kilian Q. Weinberger</p><p>Abstract: Multi-task learning (MTL) improves the prediction performance on multiple, different but related, learning problems through shared parameters or representations. One of the most prominent multi-task learning algorithms is an extension to support vector machines (svm) by Evgeniou et al. [15]. Although very elegant, multi-task svm is inherently restricted by the fact that support vector machines require each class to be addressed explicitly with its own weight vector which, in a multi-task setting, requires the different learning tasks to share the same set of classes. This paper proposes an alternative formulation for multi-task learning by extending the recently published large margin nearest neighbor (lmnn) algorithm to the MTL paradigm. Instead of relying on separating hyperplanes, its decision function is based on the nearest neighbor rule which inherently extends to many classes and becomes a natural ﬁt for multi-task learning. We evaluate the resulting multi-task lmnn on real-world insurance data and speech classiﬁcation problems and show that it consistently outperforms single-task kNN under several metrics and state-of-the-art MTL classiﬁers. 1</p><p>5 0.48405507 <a title="146-lsi-5" href="./nips-2010-Multitask_Learning_without_Label_Correspondences.html">177 nips-2010-Multitask Learning without Label Correspondences</a></p>
<p>Author: Novi Quadrianto, James Petterson, Tibério S. Caetano, Alex J. Smola, S.v.n. Vishwanathan</p><p>Abstract: We propose an algorithm to perform multitask learning where each task has potentially distinct label sets and label correspondences are not readily available. This is in contrast with existing methods which either assume that the label sets shared by different tasks are the same or that there exists a label mapping oracle. Our method directly maximizes the mutual information among the labels, and we show that the resulting objective function can be efﬁciently optimized using existing algorithms. Our proposed approach has a direct application for data integration with different label spaces, such as integrating Yahoo! and DMOZ web directories. 1</p><p>6 0.45352334 <a title="146-lsi-6" href="./nips-2010-Online_Learning_in_The_Manifold_of_Low-Rank_Matrices.html">195 nips-2010-Online Learning in The Manifold of Low-Rank Matrices</a></p>
<p>7 0.3970516 <a title="146-lsi-7" href="./nips-2010-Random_Projection_Trees_Revisited.html">220 nips-2010-Random Projection Trees Revisited</a></p>
<p>8 0.39474386 <a title="146-lsi-8" href="./nips-2010-Sample_Complexity_of_Testing_the_Manifold_Hypothesis.html">232 nips-2010-Sample Complexity of Testing the Manifold Hypothesis</a></p>
<p>9 0.36472288 <a title="146-lsi-9" href="./nips-2010-Probabilistic_Multi-Task_Feature_Selection.html">217 nips-2010-Probabilistic Multi-Task Feature Selection</a></p>
<p>10 0.2770645 <a title="146-lsi-10" href="./nips-2010-Decoding_Ipsilateral_Finger_Movements_from_ECoG_Signals_in_Humans.html">57 nips-2010-Decoding Ipsilateral Finger Movements from ECoG Signals in Humans</a></p>
<p>11 0.25825393 <a title="146-lsi-11" href="./nips-2010-Inductive_Regularized_Learning_of_Kernel_Functions.html">124 nips-2010-Inductive Regularized Learning of Kernel Functions</a></p>
<p>12 0.24163733 <a title="146-lsi-12" href="./nips-2010-Sparse_Inverse_Covariance_Selection_via_Alternating_Linearization_Methods.html">248 nips-2010-Sparse Inverse Covariance Selection via Alternating Linearization Methods</a></p>
<p>13 0.23625827 <a title="146-lsi-13" href="./nips-2010-Unsupervised_Kernel_Dimension_Reduction.html">280 nips-2010-Unsupervised Kernel Dimension Reduction</a></p>
<p>14 0.23367836 <a title="146-lsi-14" href="./nips-2010-Collaborative_Filtering_in_a_Non-Uniform_World%3A_Learning_with_the_Weighted_Trace_Norm.html">48 nips-2010-Collaborative Filtering in a Non-Uniform World: Learning with the Weighted Trace Norm</a></p>
<p>15 0.23277555 <a title="146-lsi-15" href="./nips-2010-Random_Conic_Pursuit_for_Semidefinite_Programming.html">219 nips-2010-Random Conic Pursuit for Semidefinite Programming</a></p>
<p>16 0.22904912 <a title="146-lsi-16" href="./nips-2010-Towards_Holistic_Scene_Understanding%3A_Feedback_Enabled_Cascaded_Classification_Models.html">272 nips-2010-Towards Holistic Scene Understanding: Feedback Enabled Cascaded Classification Models</a></p>
<p>17 0.22896472 <a title="146-lsi-17" href="./nips-2010-Gated_Softmax_Classification.html">99 nips-2010-Gated Softmax Classification</a></p>
<p>18 0.21597554 <a title="146-lsi-18" href="./nips-2010-Discriminative_Clustering_by_Regularized_Information_Maximization.html">62 nips-2010-Discriminative Clustering by Regularized Information Maximization</a></p>
<p>19 0.21412048 <a title="146-lsi-19" href="./nips-2010-Auto-Regressive_HMM_Inference_with_Incomplete_Data_for_Short-Horizon_Wind_Forecasting.html">35 nips-2010-Auto-Regressive HMM Inference with Incomplete Data for Short-Horizon Wind Forecasting</a></p>
<p>20 0.21016395 <a title="146-lsi-20" href="./nips-2010-A_Dirty_Model_for_Multi-task_Learning.html">5 nips-2010-A Dirty Model for Multi-task Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.474), (17, 0.013), (27, 0.032), (30, 0.039), (35, 0.02), (45, 0.181), (50, 0.049), (52, 0.023), (60, 0.018), (77, 0.034), (90, 0.024)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.9376567 <a title="146-lda-1" href="./nips-2010-Subgraph_Detection_Using_Eigenvector_L1_Norms.html">259 nips-2010-Subgraph Detection Using Eigenvector L1 Norms</a></p>
<p>Author: Benjamin Miller, Nadya Bliss, Patrick J. Wolfe</p><p>Abstract: When working with network datasets, the theoretical framework of detection theory for Euclidean vector spaces no longer applies. Nevertheless, it is desirable to determine the detectability of small, anomalous graphs embedded into background networks with known statistical properties. Casting the problem of subgraph detection in a signal processing context, this article provides a framework and empirical results that elucidate a “detection theory” for graph-valued data. Its focus is the detection of anomalies in unweighted, undirected graphs through L1 properties of the eigenvectors of the graph’s so-called modularity matrix. This metric is observed to have relatively low variance for certain categories of randomly-generated graphs, and to reveal the presence of an anomalous subgraph with reasonable reliability when the anomaly is not well-correlated with stronger portions of the background graph. An analysis of subgraphs in real network datasets conﬁrms the efﬁcacy of this approach. 1</p><p>2 0.89281744 <a title="146-lda-2" href="./nips-2010-Online_Classification_with_Specificity_Constraints.html">192 nips-2010-Online Classification with Specificity Constraints</a></p>
<p>Author: Andrey Bernstein, Shie Mannor, Nahum Shimkin</p><p>Abstract: We consider the online binary classiﬁcation problem, where we are given m classiﬁers. At each stage, the classiﬁers map the input to the probability that the input belongs to the positive class. An online classiﬁcation meta-algorithm is an algorithm that combines the outputs of the classiﬁers in order to attain a certain goal, without having prior knowledge on the form and statistics of the input, and without prior knowledge on the performance of the given classiﬁers. In this paper, we use sensitivity and speciﬁcity as the performance metrics of the meta-algorithm. In particular, our goal is to design an algorithm that satisﬁes the following two properties (asymptotically): (i) its average false positive rate (fp-rate) is under some given threshold; and (ii) its average true positive rate (tp-rate) is not worse than the tp-rate of the best convex combination of the m given classiﬁers that satisﬁes fprate constraint, in hindsight. We show that this problem is in fact a special case of the regret minimization problem with constraints, and therefore the above goal is not attainable. Hence, we pose a relaxed goal and propose a corresponding practical online learning meta-algorithm that attains it. In the case of two classiﬁers, we show that this algorithm takes a very simple form. To our best knowledge, this is the ﬁrst algorithm that addresses the problem of the average tp-rate maximization under average fp-rate constraints in the online setting. 1</p><p>3 0.8748219 <a title="146-lda-3" href="./nips-2010-CUR_from_a_Sparse_Optimization_Viewpoint.html">45 nips-2010-CUR from a Sparse Optimization Viewpoint</a></p>
<p>Author: Jacob Bien, Ya Xu, Michael W. Mahoney</p><p>Abstract: The CUR decomposition provides an approximation of a matrix X that has low reconstruction error and that is sparse in the sense that the resulting approximation lies in the span of only a few columns of X. In this regard, it appears to be similar to many sparse PCA methods. However, CUR takes a randomized algorithmic approach, whereas most sparse PCA methods are framed as convex optimization problems. In this paper, we try to understand CUR from a sparse optimization viewpoint. We show that CUR is implicitly optimizing a sparse regression objective and, furthermore, cannot be directly cast as a sparse PCA method. We also observe that the sparsity attained by CUR possesses an interesting structure, which leads us to formulate a sparse PCA method that achieves a CUR-like sparsity.</p><p>same-paper 4 0.84807646 <a title="146-lda-4" href="./nips-2010-Learning_Multiple_Tasks_using_Manifold_Regularization.html">146 nips-2010-Learning Multiple Tasks using Manifold Regularization</a></p>
<p>Author: Arvind Agarwal, Samuel Gerber, Hal Daume</p><p>Abstract: We present a novel method for multitask learning (MTL) based on manifold regularization: assume that all task parameters lie on a manifold. This is the generalization of a common assumption made in the existing literature: task parameters share a common linear subspace. One proposed method uses the projection distance from the manifold to regularize the task parameters. The manifold structure and the task parameters are learned using an alternating optimization framework. When the manifold structure is ﬁxed, our method decomposes across tasks which can be learnt independently. An approximation of the manifold regularization scheme is presented that preserves the convexity of the single task learning problem, and makes the proposed MTL framework efﬁcient and easy to implement. We show the efﬁcacy of our method on several datasets. 1</p><p>5 0.83282739 <a title="146-lda-5" href="./nips-2010-Variational_bounds_for_mixed-data_factor_analysis.html">284 nips-2010-Variational bounds for mixed-data factor analysis</a></p>
<p>Author: Mohammad E. Khan, Guillaume Bouchard, Kevin P. Murphy, Benjamin M. Marlin</p><p>Abstract: We propose a new variational EM algorithm for ﬁtting factor analysis models with mixed continuous and categorical observations. The algorithm is based on a simple quadratic bound to the log-sum-exp function. In the special case of fully observed binary data, the bound we propose is signiﬁcantly faster than previous variational methods. We show that EM is signiﬁcantly more robust in the presence of missing data compared to treating the latent factors as parameters, which is the approach used by exponential family PCA and other related matrix-factorization methods. A further beneﬁt of the variational approach is that it can easily be extended to the case of mixtures of factor analyzers, as we show. We present results on synthetic and real data sets demonstrating several desirable properties of our proposed method. 1</p><p>6 0.82406425 <a title="146-lda-6" href="./nips-2010-Random_Projections_for_%24k%24-means_Clustering.html">221 nips-2010-Random Projections for $k$-means Clustering</a></p>
<p>7 0.8101837 <a title="146-lda-7" href="./nips-2010-Supervised_Clustering.html">261 nips-2010-Supervised Clustering</a></p>
<p>8 0.73154813 <a title="146-lda-8" href="./nips-2010-Switched_Latent_Force_Models_for_Movement_Segmentation.html">262 nips-2010-Switched Latent Force Models for Movement Segmentation</a></p>
<p>9 0.71541929 <a title="146-lda-9" href="./nips-2010-Large-Scale_Matrix_Factorization_with_Missing_Data_under_Additional_Constraints.html">136 nips-2010-Large-Scale Matrix Factorization with Missing Data under Additional Constraints</a></p>
<p>10 0.65574223 <a title="146-lda-10" href="./nips-2010-Factorized_Latent_Spaces_with_Structured_Sparsity.html">89 nips-2010-Factorized Latent Spaces with Structured Sparsity</a></p>
<p>11 0.65201926 <a title="146-lda-11" href="./nips-2010-Practical_Large-Scale_Optimization_for_Max-norm_Regularization.html">210 nips-2010-Practical Large-Scale Optimization for Max-norm Regularization</a></p>
<p>12 0.6336115 <a title="146-lda-12" href="./nips-2010-Repeated_Games_against_Budgeted_Adversaries.html">226 nips-2010-Repeated Games against Budgeted Adversaries</a></p>
<p>13 0.62481725 <a title="146-lda-13" href="./nips-2010-Guaranteed_Rank_Minimization_via_Singular_Value_Projection.html">110 nips-2010-Guaranteed Rank Minimization via Singular Value Projection</a></p>
<p>14 0.62013763 <a title="146-lda-14" href="./nips-2010-An_Inverse_Power_Method_for_Nonlinear_Eigenproblems_with_Applications_in_1-Spectral_Clustering_and_Sparse_PCA.html">30 nips-2010-An Inverse Power Method for Nonlinear Eigenproblems with Applications in 1-Spectral Clustering and Sparse PCA</a></p>
<p>15 0.61678416 <a title="146-lda-15" href="./nips-2010-Minimum_Average_Cost_Clustering.html">166 nips-2010-Minimum Average Cost Clustering</a></p>
<p>16 0.61338848 <a title="146-lda-16" href="./nips-2010-Sparse_Coding_for_Learning_Interpretable_Spatio-Temporal_Primitives.html">246 nips-2010-Sparse Coding for Learning Interpretable Spatio-Temporal Primitives</a></p>
<p>17 0.60587299 <a title="146-lda-17" href="./nips-2010-Online_Markov_Decision_Processes_under_Bandit_Feedback.html">196 nips-2010-Online Markov Decision Processes under Bandit Feedback</a></p>
<p>18 0.60568851 <a title="146-lda-18" href="./nips-2010-Online_Learning_in_The_Manifold_of_Low-Rank_Matrices.html">195 nips-2010-Online Learning in The Manifold of Low-Rank Matrices</a></p>
<p>19 0.60265946 <a title="146-lda-19" href="./nips-2010-New_Adaptive_Algorithms_for_Online_Classification.html">182 nips-2010-New Adaptive Algorithms for Online Classification</a></p>
<p>20 0.60191178 <a title="146-lda-20" href="./nips-2010-Identifying_graph-structured_activation_patterns_in_networks.html">117 nips-2010-Identifying graph-structured activation patterns in networks</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
