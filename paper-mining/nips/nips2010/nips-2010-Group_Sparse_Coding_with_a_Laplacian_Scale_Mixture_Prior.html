<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>109 nips-2010-Group Sparse Coding with a Laplacian Scale Mixture Prior</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-109" href="#">nips2010-109</a> knowledge-graph by maker-knowledge-mining</p><h1>109 nips-2010-Group Sparse Coding with a Laplacian Scale Mixture Prior</h1>
<br/><p>Source: <a title="nips-2010-109-pdf" href="http://papers.nips.cc/paper/3997-group-sparse-coding-with-a-laplacian-scale-mixture-prior.pdf">pdf</a></p><p>Author: Pierre Garrigues, Bruno A. Olshausen</p><p>Abstract: We propose a class of sparse coding models that utilizes a Laplacian Scale Mixture (LSM) prior to model dependencies among coefﬁcients. Each coefﬁcient is modeled as a Laplacian distribution with a variable scale parameter, with a Gamma distribution prior over the scale parameter. We show that, due to the conjugacy of the Gamma prior, it is possible to derive efﬁcient inference procedures for both the coefﬁcients and the scale parameter. When the scale parameters of a group of coefﬁcients are combined into a single variable, it is possible to describe the dependencies that occur due to common amplitude ﬂuctuations among coefﬁcients, which have been shown to constitute a large fraction of the redundancy in natural images [1]. We show that, as a consequence of this group sparse coding, the resulting inference of the coefﬁcients follows a divisive normalization rule, and that this may be efﬁciently implemented in a network architecture similar to that which has been proposed to occur in primary visual cortex. We also demonstrate improvements in image coding and compressive sensing recovery using the LSM model. 1</p><p>Reference: <a title="nips-2010-109-reference" href="../nips2010_reference/nips-2010-Group_Sparse_Coding_with_a_Laplacian_Scale_Mixture_Prior_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('lsm', 0.617), ('si', 0.308), ('coef', 0.272), ('bp', 0.231), ('laplac', 0.228), ('bpdn', 0.18), ('spars', 0.175), ('gamm', 0.169), ('rwbp', 0.16), ('nk', 0.136), ('compress', 0.12), ('group', 0.108), ('topograph', 0.107), ('recovery', 0.096), ('cod', 0.095), ('pri', 0.092), ('dict', 0.09), ('im', 0.085), ('mixt', 0.079), ('gsm', 0.069)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9999997 <a title="109-tfidf-1" href="./nips-2010-Group_Sparse_Coding_with_a_Laplacian_Scale_Mixture_Prior.html">109 nips-2010-Group Sparse Coding with a Laplacian Scale Mixture Prior</a></p>
<p>2 0.12799448 <a title="109-tfidf-2" href="./nips-2010-Deciphering_subsampled_data%3A_adaptive_compressive_sampling_as_a_principle_of_brain_communication.html">56 nips-2010-Deciphering subsampled data: adaptive compressive sampling as a principle of brain communication</a></p>
<p>3 0.11782163 <a title="109-tfidf-3" href="./nips-2010-Over-complete_representations_on_recurrent_neural_networks_can_support_persistent_percepts.html">200 nips-2010-Over-complete representations on recurrent neural networks can support persistent percepts</a></p>
<p>4 0.11604347 <a title="109-tfidf-4" href="./nips-2010-Deep_Coding_Network.html">59 nips-2010-Deep Coding Network</a></p>
<p>5 0.11308108 <a title="109-tfidf-5" href="./nips-2010-Factorized_Latent_Spaces_with_Structured_Sparsity.html">89 nips-2010-Factorized Latent Spaces with Structured Sparsity</a></p>
<p>6 0.11095157 <a title="109-tfidf-6" href="./nips-2010-Learning_Convolutional_Feature_Hierarchies_for_Visual_Recognition.html">143 nips-2010-Learning Convolutional Feature Hierarchies for Visual Recognition</a></p>
<p>7 0.10848437 <a title="109-tfidf-7" href="./nips-2010-Probabilistic_Multi-Task_Feature_Selection.html">217 nips-2010-Probabilistic Multi-Task Feature Selection</a></p>
<p>8 0.099340163 <a title="109-tfidf-8" href="./nips-2010-Identifying_graph-structured_activation_patterns_in_networks.html">117 nips-2010-Identifying graph-structured activation patterns in networks</a></p>
<p>9 0.093211845 <a title="109-tfidf-9" href="./nips-2010-Nonparametric_Density_Estimation_for_Stochastic_Optimization_with_an_Observable_State_Variable.html">185 nips-2010-Nonparametric Density Estimation for Stochastic Optimization with an Observable State Variable</a></p>
<p>10 0.092381164 <a title="109-tfidf-10" href="./nips-2010-A_Family_of_Penalty_Functions_for_Structured_Sparsity.html">7 nips-2010-A Family of Penalty Functions for Structured Sparsity</a></p>
<p>11 0.090771735 <a title="109-tfidf-11" href="./nips-2010-Network_Flow_Algorithms_for_Structured_Sparsity.html">181 nips-2010-Network Flow Algorithms for Structured Sparsity</a></p>
<p>12 0.090338759 <a title="109-tfidf-12" href="./nips-2010-Sufficient_Conditions_for_Generating_Group_Level_Sparsity_in_a_Robust_Minimax_Framework.html">260 nips-2010-Sufficient Conditions for Generating Group Level Sparsity in a Robust Minimax Framework</a></p>
<p>13 0.089686505 <a title="109-tfidf-13" href="./nips-2010-Gaussian_sampling_by_local_perturbations.html">101 nips-2010-Gaussian sampling by local perturbations</a></p>
<p>14 0.084524773 <a title="109-tfidf-14" href="./nips-2010-A_Primal-Dual_Algorithm_for_Group_Sparse_Regularization_with_Overlapping_Groups.html">12 nips-2010-A Primal-Dual Algorithm for Group Sparse Regularization with Overlapping Groups</a></p>
<p>15 0.076580755 <a title="109-tfidf-15" href="./nips-2010-The_Maximal_Causes_of_Natural_Scenes_are_Edge_Filters.html">266 nips-2010-The Maximal Causes of Natural Scenes are Edge Filters</a></p>
<p>16 0.075613268 <a title="109-tfidf-16" href="./nips-2010-Object_Bank%3A_A_High-Level_Image_Representation_for_Scene_Classification_%26_Semantic_Feature_Sparsification.html">186 nips-2010-Object Bank: A High-Level Image Representation for Scene Classification & Semantic Feature Sparsification</a></p>
<p>17 0.072783791 <a title="109-tfidf-17" href="./nips-2010-Sparse_Coding_for_Learning_Interpretable_Spatio-Temporal_Primitives.html">246 nips-2010-Sparse Coding for Learning Interpretable Spatio-Temporal Primitives</a></p>
<p>18 0.072579287 <a title="109-tfidf-18" href="./nips-2010-Divisive_Normalization%3A_Justification_and_Effectiveness_as_Efficient_Coding_Transform.html">65 nips-2010-Divisive Normalization: Justification and Effectiveness as Efficient Coding Transform</a></p>
<p>19 0.071986817 <a title="109-tfidf-19" href="./nips-2010-Fast_global_convergence_rates_of_gradient_methods_for_high-dimensional_statistical_recovery.html">92 nips-2010-Fast global convergence rates of gradient methods for high-dimensional statistical recovery</a></p>
<p>20 0.071393192 <a title="109-tfidf-20" href="./nips-2010-Learning_the_context_of_a_category.html">155 nips-2010-Learning the context of a category</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.193), (1, -0.068), (2, -0.022), (3, 0.011), (4, 0.076), (5, 0.155), (6, 0.063), (7, -0.013), (8, -0.11), (9, -0.062), (10, 0.102), (11, -0.018), (12, -0.03), (13, -0.051), (14, 0.083), (15, -0.045), (16, 0.009), (17, 0.097), (18, -0.007), (19, 0.04), (20, -0.061), (21, 0.034), (22, 0.054), (23, -0.058), (24, 0.048), (25, -0.073), (26, 0.106), (27, 0.017), (28, -0.038), (29, 0.022), (30, 0.023), (31, -0.086), (32, 0.063), (33, -0.044), (34, -0.008), (35, 0.004), (36, -0.037), (37, -0.095), (38, 0.03), (39, 0.003), (40, 0.022), (41, -0.007), (42, 0.168), (43, 0.041), (44, 0.027), (45, 0.048), (46, 0.099), (47, 0.036), (48, 0.032), (49, -0.034)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94083089 <a title="109-lsi-1" href="./nips-2010-Group_Sparse_Coding_with_a_Laplacian_Scale_Mixture_Prior.html">109 nips-2010-Group Sparse Coding with a Laplacian Scale Mixture Prior</a></p>
<p>2 0.76022875 <a title="109-lsi-2" href="./nips-2010-Sparse_Coding_for_Learning_Interpretable_Spatio-Temporal_Primitives.html">246 nips-2010-Sparse Coding for Learning Interpretable Spatio-Temporal Primitives</a></p>
<p>3 0.73524481 <a title="109-lsi-3" href="./nips-2010-Deciphering_subsampled_data%3A_adaptive_compressive_sampling_as_a_principle_of_brain_communication.html">56 nips-2010-Deciphering subsampled data: adaptive compressive sampling as a principle of brain communication</a></p>
<p>4 0.66555756 <a title="109-lsi-4" href="./nips-2010-Energy_Disaggregation_via_Discriminative_Sparse_Coding.html">76 nips-2010-Energy Disaggregation via Discriminative Sparse Coding</a></p>
<p>5 0.64362311 <a title="109-lsi-5" href="./nips-2010-Over-complete_representations_on_recurrent_neural_networks_can_support_persistent_percepts.html">200 nips-2010-Over-complete representations on recurrent neural networks can support persistent percepts</a></p>
<p>6 0.61230993 <a title="109-lsi-6" href="./nips-2010-Factorized_Latent_Spaces_with_Structured_Sparsity.html">89 nips-2010-Factorized Latent Spaces with Structured Sparsity</a></p>
<p>7 0.60739571 <a title="109-lsi-7" href="./nips-2010-The_Maximal_Causes_of_Natural_Scenes_are_Edge_Filters.html">266 nips-2010-The Maximal Causes of Natural Scenes are Edge Filters</a></p>
<p>8 0.59333026 <a title="109-lsi-8" href="./nips-2010-Learning_Convolutional_Feature_Hierarchies_for_Visual_Recognition.html">143 nips-2010-Learning Convolutional Feature Hierarchies for Visual Recognition</a></p>
<p>9 0.58086979 <a title="109-lsi-9" href="./nips-2010-CUR_from_a_Sparse_Optimization_Viewpoint.html">45 nips-2010-CUR from a Sparse Optimization Viewpoint</a></p>
<p>10 0.57910955 <a title="109-lsi-10" href="./nips-2010-Network_Flow_Algorithms_for_Structured_Sparsity.html">181 nips-2010-Network Flow Algorithms for Structured Sparsity</a></p>
<p>11 0.56789649 <a title="109-lsi-11" href="./nips-2010-A_Family_of_Penalty_Functions_for_Structured_Sparsity.html">7 nips-2010-A Family of Penalty Functions for Structured Sparsity</a></p>
<p>12 0.56191117 <a title="109-lsi-12" href="./nips-2010-Deep_Coding_Network.html">59 nips-2010-Deep Coding Network</a></p>
<p>13 0.55036002 <a title="109-lsi-13" href="./nips-2010-A_Primal-Dual_Algorithm_for_Group_Sparse_Regularization_with_Overlapping_Groups.html">12 nips-2010-A Primal-Dual Algorithm for Group Sparse Regularization with Overlapping Groups</a></p>
<p>14 0.52471739 <a title="109-lsi-14" href="./nips-2010-A_Dirty_Model_for_Multi-task_Learning.html">5 nips-2010-A Dirty Model for Multi-task Learning</a></p>
<p>15 0.51502818 <a title="109-lsi-15" href="./nips-2010-Sparse_Inverse_Covariance_Selection_via_Alternating_Linearization_Methods.html">248 nips-2010-Sparse Inverse Covariance Selection via Alternating Linearization Methods</a></p>
<p>16 0.51150441 <a title="109-lsi-16" href="./nips-2010-Adaptive_Multi-Task_Lasso%3A_with_Application_to_eQTL_Detection.html">26 nips-2010-Adaptive Multi-Task Lasso: with Application to eQTL Detection</a></p>
<p>17 0.48451278 <a title="109-lsi-17" href="./nips-2010-Sufficient_Conditions_for_Generating_Group_Level_Sparsity_in_a_Robust_Minimax_Framework.html">260 nips-2010-Sufficient Conditions for Generating Group Level Sparsity in a Robust Minimax Framework</a></p>
<p>18 0.48143876 <a title="109-lsi-18" href="./nips-2010-Short-term_memory_in_neuronal_networks_through_dynamical_compressed_sensing.html">238 nips-2010-Short-term memory in neuronal networks through dynamical compressed sensing</a></p>
<p>19 0.48074475 <a title="109-lsi-19" href="./nips-2010-Probabilistic_Multi-Task_Feature_Selection.html">217 nips-2010-Probabilistic Multi-Task Feature Selection</a></p>
<p>20 0.47613275 <a title="109-lsi-20" href="./nips-2010-Multi-Stage_Dantzig_Selector.html">172 nips-2010-Multi-Stage Dantzig Selector</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(7, 0.22), (30, 0.042), (32, 0.124), (34, 0.087), (36, 0.03), (42, 0.125), (45, 0.077), (68, 0.184)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93183208 <a title="109-lda-1" href="./nips-2010-Group_Sparse_Coding_with_a_Laplacian_Scale_Mixture_Prior.html">109 nips-2010-Group Sparse Coding with a Laplacian Scale Mixture Prior</a></p>
<p>2 0.92509633 <a title="109-lda-2" href="./nips-2010-Gaussian_sampling_by_local_perturbations.html">101 nips-2010-Gaussian sampling by local perturbations</a></p>
<p>3 0.9189921 <a title="109-lda-3" href="./nips-2010-MAP_Estimation_for_Graphical_Models_by_Likelihood_Maximization.html">164 nips-2010-MAP Estimation for Graphical Models by Likelihood Maximization</a></p>
<p>4 0.91840345 <a title="109-lda-4" href="./nips-2010-Joint_Analysis_of_Time-Evolving_Binary_Matrices_and_Associated_Documents.html">131 nips-2010-Joint Analysis of Time-Evolving Binary Matrices and Associated Documents</a></p>
<p>5 0.91746891 <a title="109-lda-5" href="./nips-2010-Regularized_estimation_of_image_statistics_by_Score_Matching.html">224 nips-2010-Regularized estimation of image statistics by Score Matching</a></p>
<p>6 0.91491252 <a title="109-lda-6" href="./nips-2010-Construction_of_Dependent_Dirichlet_Processes_based_on_Poisson_Processes.html">51 nips-2010-Construction of Dependent Dirichlet Processes based on Poisson Processes</a></p>
<p>7 0.91246271 <a title="109-lda-7" href="./nips-2010-Supervised_Clustering.html">261 nips-2010-Supervised Clustering</a></p>
<p>8 0.91225648 <a title="109-lda-8" href="./nips-2010-Rates_of_convergence_for_the_cluster_tree.html">223 nips-2010-Rates of convergence for the cluster tree</a></p>
<p>9 0.91205931 <a title="109-lda-9" href="./nips-2010-Random_Projection_Trees_Revisited.html">220 nips-2010-Random Projection Trees Revisited</a></p>
<p>10 0.91111463 <a title="109-lda-10" href="./nips-2010-Fast_Large-scale_Mixture_Modeling_with_Component-specific_Data_Partitions.html">90 nips-2010-Fast Large-scale Mixture Modeling with Component-specific Data Partitions</a></p>
<p>11 0.90923136 <a title="109-lda-11" href="./nips-2010-Causal_discovery_in_multiple_models_from_different_experiments.html">46 nips-2010-Causal discovery in multiple models from different experiments</a></p>
<p>12 0.90872133 <a title="109-lda-12" href="./nips-2010-Tree-Structured_Stick_Breaking_for_Hierarchical_Data.html">276 nips-2010-Tree-Structured Stick Breaking for Hierarchical Data</a></p>
<p>13 0.90850174 <a title="109-lda-13" href="./nips-2010-A_Dirty_Model_for_Multi-task_Learning.html">5 nips-2010-A Dirty Model for Multi-task Learning</a></p>
<p>14 0.90836614 <a title="109-lda-14" href="./nips-2010-Learning_the_context_of_a_category.html">155 nips-2010-Learning the context of a category</a></p>
<p>15 0.90589333 <a title="109-lda-15" href="./nips-2010-Slice_sampling_covariance_hyperparameters_of_latent_Gaussian_models.html">242 nips-2010-Slice sampling covariance hyperparameters of latent Gaussian models</a></p>
<p>16 0.90481514 <a title="109-lda-16" href="./nips-2010-Stability_Approach_to_Regularization_Selection_%28StARS%29_for_High_Dimensional_Graphical_Models.html">254 nips-2010-Stability Approach to Regularization Selection (StARS) for High Dimensional Graphical Models</a></p>
<p>17 0.90477717 <a title="109-lda-17" href="./nips-2010-Probabilistic_Inference_and_Differential_Privacy.html">216 nips-2010-Probabilistic Inference and Differential Privacy</a></p>
<p>18 0.9046464 <a title="109-lda-18" href="./nips-2010-Exact_learning_curves_for_Gaussian_process_regression_on_large_random_graphs.html">85 nips-2010-Exact learning curves for Gaussian process regression on large random graphs</a></p>
<p>19 0.90385807 <a title="109-lda-19" href="./nips-2010-Graph-Valued_Regression.html">108 nips-2010-Graph-Valued Regression</a></p>
<p>20 0.90370798 <a title="109-lda-20" href="./nips-2010-Cross_Species_Expression_Analysis_using_a_Dirichlet_Process_Mixture_Model_with_Latent_Matchings.html">55 nips-2010-Cross Species Expression Analysis using a Dirichlet Process Mixture Model with Latent Matchings</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
