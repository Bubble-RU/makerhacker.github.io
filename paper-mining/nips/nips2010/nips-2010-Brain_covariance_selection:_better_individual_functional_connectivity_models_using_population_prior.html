<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>44 nips-2010-Brain covariance selection: better individual functional connectivity models using population prior</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-44" href="#">nips2010-44</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>44 nips-2010-Brain covariance selection: better individual functional connectivity models using population prior</h1>
<br/><p>Source: <a title="nips-2010-44-pdf" href="http://papers.nips.cc/paper/4080-brain-covariance-selection-better-individual-functional-connectivity-models-using-population-prior.pdf">pdf</a></p><p>Author: Gael Varoquaux, Alexandre Gramfort, Jean-baptiste Poline, Bertrand Thirion</p><p>Abstract: Spontaneous brain activity, as observed in functional neuroimaging, has been shown to display reproducible structure that expresses brain architecture and carries markers of brain pathologies. An important view of modern neuroscience is that such large-scale structure of coherent activity reﬂects modularity properties of brain connectivity graphs. However, to date, there has been no demonstration that the limited and noisy data available in spontaneous activity observations could be used to learn full-brain probabilistic models that generalize to new data. Learning such models entails two main challenges: i) modeling full brain connectivity is a difﬁcult estimation problem that faces the curse of dimensionality and ii) variability between subjects, coupled with the variability of functional signals between experimental runs, makes the use of multiple datasets challenging. We describe subject-level brain functional connectivity structure as a multivariate Gaussian process and introduce a new strategy to estimate it from group data, by imposing a common structure on the graphical model in the population. We show that individual models learned from functional Magnetic Resonance Imaging (fMRI) data using this population prior generalize better to unseen data than models based on alternative regularization schemes. To our knowledge, this is the ﬁrst report of a cross-validated model of spontaneous brain activity. Finally, we use the estimated graphical model to explore the large-scale characteristics of functional architecture and show for the ﬁrst time that known cognitive networks appear as the integrated communities of functional connectivity graph. 1</p><p>Reference: <a title="nips-2010-44-reference" href="../nips2010_reference/nips-2010-Brain_covariance_selection%3A_better_individual_functional_connectivity_models_using_population_prior_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Brain covariance selection: better individual functional connectivity models using population prior  Alexandre Gramfort Parietal, INRIA NeuroSpin, CEA, France alexandre. [sent-1, score-0.828]
</p><p>2 fr  Abstract Spontaneous brain activity, as observed in functional neuroimaging, has been shown to display reproducible structure that expresses brain architecture and carries markers of brain pathologies. [sent-8, score-1.729]
</p><p>3 An important view of modern neuroscience is that such large-scale structure of coherent activity reﬂects modularity properties of brain connectivity graphs. [sent-9, score-0.999]
</p><p>4 We describe subject-level brain functional connectivity structure as a multivariate Gaussian process and introduce a new strategy to estimate it from group data, by imposing a common structure on the graphical model in the population. [sent-12, score-1.187]
</p><p>5 We show that individual models learned from functional Magnetic Resonance Imaging (fMRI) data using this population prior generalize better to unseen data than models based on alternative regularization schemes. [sent-13, score-0.45]
</p><p>6 To our knowledge, this is the ﬁrst report of a cross-validated model of spontaneous brain activity. [sent-14, score-0.573]
</p><p>7 Finally, we use the estimated graphical model to explore the large-scale characteristics of functional architecture and show for the ﬁrst time that known cognitive networks appear as the integrated communities of functional connectivity graph. [sent-15, score-1.455]
</p><p>8 These experimental results are consistent with the view that the local neuronal systems in the brain group together to form large-scale distributed networks [5]. [sent-19, score-0.588]
</p><p>9 However, the link between large-scale networks corresponding to a known cognitive function and segregation into functional connectivity subgraphs has never been established. [sent-20, score-0.88]
</p><p>10 At the individual level, the different brain functional networks are attractive as their coherence, as manifested in their correlation structure, appears impacted by brain pathologies, such as schizophrenia [6], neurodegenerative diseases –e. [sent-21, score-1.41]
</p><p>11 Alzheimer’s disease–[7, 8], or in the study of brain lesions [9]. [sent-23, score-0.469]
</p><p>12 From the clinical standpoint, there is a strong interest in spontaneous-activity data to study and diagnose brain pathologies because they can be recorded even on severely impaired subjects [10]. [sent-24, score-0.615]
</p><p>13 FMRI is the tool of choice to study large-scale functional connectivity, as it relies on wide expertise gained through decades of brain mapping, and MRI scanners are widely available in brain research institutes and hospitals. [sent-25, score-1.214]
</p><p>14 For clinical applications as well as inference of brain fundamental architecture, the quantitative characterization of spontaneous activity has to rely on a probabilistic model of the signal. [sent-27, score-0.685]
</p><p>15 The question of the robustness of covariance estimation procedures to observation noise as well as inter-individual variability is thus fundamental, and has not been addressed so far. [sent-28, score-0.253]
</p><p>16 The focus of this work is the estimation of a large-scale Gaussian model to give a probabilistic description of brain functional signals. [sent-29, score-0.837]
</p><p>17 We show that the resulting covariance model yields easily interpretable structures, and in particular we provide the ﬁrst experimental evidence that the functionally integrated communities of brain connectivity graphs correspond to known cognitive networks. [sent-32, score-1.297]
</p><p>18 To our knowledge, this is the ﬁrst experiment that assesses quantitatively the goodness of ﬁt of a full-brain functional connectivity model to new data. [sent-33, score-0.584]
</p><p>19 [13] have applied with success a similar framework to modeling task-driven brain activity. [sent-36, score-0.469]
</p><p>20 Second, we detail how we extract activity time-series for various brain regions from fMRI data. [sent-39, score-0.593]
</p><p>21 Finally, we study the graph communities of the learnt connectivity model as well as the integration and segregation processes between these communities. [sent-41, score-0.961]
</p><p>22 The present work opens the way to a systematic use of Gaussian graphical Models for the analysis of functional connectivity data. [sent-42, score-0.669]
</p><p>23 2  Theoretical background: estimating Gaussian graphical models  From a statistical estimation standpoint, the challenge to address is to estimate a covariance or a correlation matrix giving a good description of the brain activation data. [sent-43, score-0.756]
</p><p>24 In multivariate Gaussian models, conditional independence between variables is given by the zeros in the precision (inverse covariance) matrix K. [sent-53, score-0.267]
</p><p>25 Covariance selection can thus be achieved by imposing a sparse support for the estimated precision matrix, i. [sent-54, score-0.279]
</p><p>26 In order to tackle this problem with more than tens of variables, it can be relaxed into a convex problem using a penalization based on the 1 norm of the precision matrix, that is known to promote sparsity on the estimates [15]. [sent-60, score-0.335]
</p><p>27 Imposing a common sparsity structure In the application targeted by this contribution, the problem is to estimate the precision matrices in a group of subjects among which one can assume that all the individual precision matrices share the same structure of conditional independence, i. [sent-67, score-0.738]
</p><p>28 , the zeros in the different precision matrices should be at the same positions. [sent-69, score-0.255]
</p><p>29 Let us denote K(s) the precision for subject s in a population of S subjects. [sent-73, score-0.362]
</p><p>30 It consists in regularizing the estimate of the precision matrix by adding a diagonal matrix to the sample covariance before computing its inverse. [sent-93, score-0.34]
</p><p>31 Unlike 1 penalization, 2 downplays uniformly connections between variables, and is thus of less interest for the study of brain structure. [sent-95, score-0.517]
</p><p>32 3  Probing brain functional covariance with fMRI  Inter-individual variability of resting-state fMRI We are interested in modeling spontaneous brain activity, also called resting state data, recorded with fMRI. [sent-97, score-1.518]
</p><p>33 Although such data require complex strategies to provide quantitative information on brain function, they are known to reveal intrinsic features of brain functional anatomy, such as cognitive networks [1, 23, 3] or connectivity topology [4, 2]. [sent-98, score-1.664]
</p><p>34 A well-known challenge with brain imaging data is that no two brains are alike. [sent-99, score-0.505]
</p><p>35 In addition to anatomical variability, within a population of subjects, cognitive networks may recruit slightly different regions. [sent-101, score-0.359]
</p><p>36 Our estimation strategy is based on the hypothesis that although the strength of correlation between connected brain region may vary across subjects, many of the conditional independence relationship will be preserved, as they reﬂect the structural wiring. [sent-102, score-0.63]
</p><p>37 The data at hand: multi-subject brain activation time series 20 healthy subjects were scanned twice in a resting task, eyes closed, resulting in a set of 244 brain volumes per session acquired with a repetition time of 2. [sent-103, score-1.114]
</p><p>38 As in [8], after standard neuroimaging pre-processing, we extract brain fMRI time series and average them based on an atlas that subdivides the gray matter tissues into standard regions. [sent-105, score-0.661]
</p><p>39 Depending on whether the atlas oversegments brain lobes into regions smaller than subject-to-subject anatomical variability or captures this variability, cross-validation scores vary signiﬁcantly. [sent-107, score-0.846]
</p><p>40 Unlike previous studies [4, 8], we choose to rely on an inter-subject probabilistic atlas of anatomical structures. [sent-108, score-0.314]
</p><p>41 This atlas covers 122 landmarks spread throughout the whole cortex and matches naturally their anatomical variability in terms of position, shape, and spread. [sent-110, score-0.326]
</p><p>42 Finally, as the fMRI signals contributing to functional connectivity have been found to lie in frequencies below 0. [sent-117, score-0.63]
</p><p>43 4  Learning a better model for a subject’s spontaneous activity  Model-selection settings Given a subject’s resting-state fMRI dataset, our goal is to estimate the best multivariate normal model describing this subject’s functional connectivity. [sent-128, score-0.453]
</p><p>44 Second, we use the combined data of the subject’s training session as well as the population, using the same estimators: we concatenate the data of the population and of the train session to estimate the covariance. [sent-135, score-0.243]
</p><p>45 As this estimation strategy yields a different correlation matrix for each subject, we use the precision corresponding to the singled-out subject to test –i. [sent-138, score-0.366]
</p><p>46 In addition, an example of estimated precision matrices can be seen in Figure 1. [sent-142, score-0.301]
</p><p>47 On the other hand, the population’s sample precision is well-conditioned due to the high number of samples at the group level and generalizes much better than the subject-level sample precision or the corresponding 2 -penalized estimate. [sent-145, score-0.507]
</p><p>48 In particular, the 1 -penalized subject-level precision matrix outperforms the precision matrices learned from the group (p < 10−5 ). [sent-147, score-0.501]
</p><p>49 Although each individual dataset is different and generalization scores vary from subject to subject, compared to the second-best performing estimator the 21 -penalized estimator gives a net gain for each subject of at least 1. [sent-151, score-0.278]
</p><p>50 Graphs estimated As can be seen from Figure 1, precision matrices corresponding to models that do not generalize well display a lot of background noise whereas in models that generalize well, a sparse structure stands out. [sent-153, score-0.337]
</p><p>51 Although an 1 penalization is sparsity inducing, the optimal graphs estimated with such estimators are not very sparse (see table 1): a ﬁlling factor of 50% amounts to 5 000 edges. [sent-154, score-0.32]
</p><p>52 As a result, the corresponding graphs are not interpretable without thresholding  Generalization likelihood Filling factor Number of communities Modularity  MLE 33. [sent-155, score-0.337]
</p><p>53 To interpret dense brain connectivity graphs, previous work relied on extracting a connectivity backbone using a maximal spanning tree [27], or graph statistics on thresholded adjacency matrices [2]. [sent-177, score-1.282]
</p><p>54 Adequate penalization serves as a replacement to backbone extraction; moreover it corresponds to a theoretically wellgrounded and accurate model of brain connectivity. [sent-179, score-0.641]
</p><p>55 After embedding in 3D anatomical space, the estimated graph is very symmetric (see Figure 2). [sent-180, score-0.281]
</p><p>56 In addition, the connectivity model displays strong fronto-parietal connections, while the visual system is globally singled out into one cluster, connected to the rest of the cortex mostly via the middle-temporal area. [sent-182, score-0.368]
</p><p>57 5  An application: graph communities to describe functional networks  Even very sparse, high-dimensional functional connectivity graphs are hard to interpret. [sent-183, score-1.372]
</p><p>58 Indeed, there is evidence from the study of the fault-resilient structure of anatomical connections in the nervous systems that ensembles of neurones cluster together to form communities that are specialized to a cognitive task [5, 4, 27]. [sent-185, score-0.571]
</p><p>59 This process, known as functional integration goes along with a reduction of between-community connections, called segregation. [sent-186, score-0.394]
</p><p>60 So far, studies of full-brain connectivity graphs have focused on the analysis of their statistical properties, namely their small-world characteristics related to the emergence of strongly-connected communities in neural system. [sent-187, score-0.683]
</p><p>61 Given that our graphical description generalizes well to unseen data, it should reﬂect the intrinsic properties of brain functional connectivity better than the sample correlation matrices previously used [4]. [sent-191, score-1.307]
</p><p>62 In this section, we study these properties on the optimal precision matrices describing a representative individual as estimated above. [sent-192, score-0.347]
</p><p>63 Finding communities to maximize modularity Graph communities are a concept originally introduced in social networks: communities are groups of densely-connected nodes with little between-group connections. [sent-193, score-0.977]
</p><p>64 Choosing the partition to optimize modularity is a NP-hard problem, but Smyth and White formulate it as a graph partitioning problem, and give an algorithm [31] based on a convex approximation leading to spectral embedding and k-means clustering. [sent-195, score-0.254]
</p><p>65 Brain functional-connectivity communities We apply Smyth and White’s algorithm on the brain connectivity graphs. [sent-197, score-1.053]
</p><p>66 We ﬁnd that using the 21 -penalized precision matrices yields a higher number of communities, and higher modularity values (Table 1) then the other estimation strategies. [sent-198, score-0.457]
</p><p>67 The communities extracted from the sample precision matrix are mostly spread throughout the brain, while the graph estimated with 1 penalization on individual data yields communities centered on anatomo-functional regions such as the visual system (ﬁgures in supplementary materials). [sent-200, score-1.227]
</p><p>68 The communities extracted on the 21 -penalized precision exhibit ﬁner anatomo-functional structures, but also extract some known functional networks that are commonly found while studying spontaneous as well as task-related activity [3]. [sent-201, score-0.996]
</p><p>69 In Figure 2, we display the resulting communities, making use, when possible, of the same denominations as the functional networks described in [3]. [sent-202, score-0.346]
</p><p>70 6  Subject sample precision 40 30 20 10 0 10 20 30 40  Subject precision l1 4. [sent-204, score-0.426]
</p><p>71 The precision matrix is shown in false colors in the background and its support is shown in black and white in an inset. [sent-237, score-0.24]
</p><p>72 The regions comprising the communities for the 1 -penalized graph are detailed in the supplementary materials. [sent-243, score-0.432]
</p><p>73 7  Integration and segregation in the graph communities These functionally-specialized networks are thought to be the expression of integration and segregation processes in the brain circuits architecture. [sent-244, score-1.346]
</p><p>74 [29] on the estimated graphs to quantify this integration and segregation, namely Gaussian entropy of the functional networks, and mutual information. [sent-246, score-0.543]
</p><p>75 We ﬁnd that the former is much sparser than the latter, reﬂecting a higher large segregation in between the communities estimated. [sent-251, score-0.43]
</p><p>76 The default mode and the fronto-parietal networks appear as hubs, connecting different networks with different functions, such as the visual streams, but also the motor areas, as well as the frontal regions. [sent-254, score-0.304]
</p><p>77 6  Conclusion  We have presented a strategy to overcome the challenge of subject-to-subject variability and learn a detailed model of an individual’s full-brain functional connectivity using population data. [sent-255, score-0.76]
</p><p>78 The learnt graphical model is sparse and reveals the interaction structure between functional modules via conditional independence relationships that generalize to new data. [sent-256, score-0.467]
</p><p>79 As far as we can tell, this is the ﬁrst time an unsupervised model of brain functional connectivity is backed by cross-validation. [sent-257, score-1.053]
</p><p>80 Also, from a machine learning perspective, this work is the ﬁrst demonstration, to our knowledge, of joint estimation of multiple graphical models in a model-selection setting, and the ﬁrst time it is shown to improve a prediction score for individual graphical models. [sent-258, score-0.269]
</p><p>81 From a neuroscience perspective, learning high-dimensional functional connectivity probabilistic models opens the door to new studies of brain architecture. [sent-259, score-1.13]
</p><p>82 In particular, the models estimated with our strategy are well suited to exploring the graph-community structure resulting from the functional integration, specialization, and segregation of distributed networks. [sent-260, score-0.476]
</p><p>83 Our preliminary work suggests that a mesoscopic description of neural ensembles via high-dimensional graphical models can establish the link between the functional networks observed in brain imaging and the fundamental nervous-system assembly principles. [sent-261, score-0.97]
</p><p>84 Finally, subject-level Gaussian probabilistic models of functional connectivity between a few regions have proved useful for statistically-controlled interindividual comparisons on resting-state, with medical applications [9]. [sent-262, score-0.674]
</p><p>85 Extending such studies to full-brain analysis, that have been so-far limited by the amount of data available on individual subjects, clears the way to new insights in brain pathologies [6, 8]. [sent-263, score-0.601]
</p><p>86 Raichle: Spontaneous ﬂuctuations in brain activity observed with functional magnetic resonance imaging. [sent-266, score-0.928]
</p><p>87 Sporns: Complex brain networks: graph theoretical analysis of structural and functional systems. [sent-269, score-0.85]
</p><p>88 : Correspondence of the brain’s functional architecture during activation and rest. [sent-272, score-0.322]
</p><p>89 : A resilient, low-frequency, small-world human brain functional network with highly connected association cortical hubs. [sent-275, score-0.828]
</p><p>90 : Organization, development and function of complex brain networks. [sent-278, score-0.469]
</p><p>91 : Learning brain connectivity of Alzheimer’s disease from neuroimaging data. [sent-288, score-0.825]
</p><p>92 : Detection of brain functional-connectivity difference in post-stroke patients using group-level covariance modeling. [sent-292, score-0.58]
</p><p>93 Gonzalez-Lima: Structural equation modeling and its application to network analysis in functional brain imaging. [sent-298, score-0.777]
</p><p>94 Tibshirani: Sparse inverse covariance estimation with the graphical lasso. [sent-323, score-0.249]
</p><p>95 Smith: Probabilistic independent component analysis for functional magnetic resonance imaging. [sent-347, score-0.386]
</p><p>96 : Mapping functionally related regions of brain with functional connectivity MR imaging. [sent-358, score-1.104]
</p><p>97 Edelman: A measure for brain complexity: relating functional segregation and integration in the nervous system. [sent-368, score-1.062]
</p><p>98 Edelman: Theoretical neuroanatomy: relating anatomical and functional connectivity in graphs and cortical connection matrices. [sent-372, score-0.826]
</p><p>99 Smyth: A spectral clustering approach to ﬁnding communities in graphs. [sent-375, score-0.276]
</p><p>100 : Conditional integration as a way of measuring mediated interactions between largescale brain networks in functional MRI. [sent-379, score-0.933]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('brain', 0.469), ('connectivity', 0.308), ('communities', 0.276), ('functional', 0.276), ('precision', 0.197), ('fmri', 0.156), ('segregation', 0.154), ('modularity', 0.149), ('penalization', 0.138), ('anatomical', 0.13), ('integration', 0.118), ('covariance', 0.111), ('atlas', 0.107), ('graph', 0.105), ('spontaneous', 0.104), ('subjects', 0.098), ('variability', 0.089), ('population', 0.087), ('graphical', 0.085), ('neurospin', 0.085), ('session', 0.078), ('subject', 0.078), ('cea', 0.074), ('sporns', 0.074), ('activity', 0.073), ('cognitive', 0.072), ('networks', 0.07), ('graphs', 0.061), ('visual', 0.06), ('matrices', 0.058), ('precisions', 0.058), ('tononi', 0.056), ('kij', 0.056), ('resonance', 0.056), ('magnetic', 0.054), ('estimation', 0.053), ('regions', 0.051), ('lw', 0.051), ('cortical', 0.051), ('group', 0.049), ('neuroimaging', 0.048), ('pathologies', 0.048), ('connections', 0.048), ('signals', 0.046), ('estimated', 0.046), ('individual', 0.046), ('architecture', 0.046), ('nervous', 0.045), ('white', 0.043), ('argmink', 0.042), ('girvan', 0.042), ('ledoit', 0.042), ('neurodegenerative', 0.042), ('sulci', 0.042), ('varoquaux', 0.042), ('et', 0.042), ('mutual', 0.042), ('rev', 0.042), ('parietal', 0.042), ('unseen', 0.041), ('france', 0.041), ('default', 0.04), ('amounts', 0.039), ('ect', 0.039), ('neurosci', 0.039), ('smyth', 0.039), ('mle', 0.039), ('probabilistic', 0.039), ('estimator', 0.038), ('correlation', 0.038), ('studies', 0.038), ('penalizing', 0.038), ('csf', 0.037), ('edelman', 0.037), ('matter', 0.037), ('imaging', 0.036), ('sparse', 0.036), ('cients', 0.035), ('gaussian', 0.035), ('independence', 0.035), ('inria', 0.035), ('conditional', 0.035), ('neuroscienti', 0.034), ('ventral', 0.034), ('assembly', 0.034), ('backbone', 0.034), ('confound', 0.034), ('occipital', 0.034), ('coef', 0.034), ('inferior', 0.033), ('mode', 0.032), ('sample', 0.032), ('alzheimer', 0.032), ('stat', 0.032), ('dorsal', 0.032), ('pole', 0.032), ('standpoint', 0.032), ('network', 0.032), ('motor', 0.032), ('det', 0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="44-tfidf-1" href="./nips-2010-Brain_covariance_selection%3A_better_individual_functional_connectivity_models_using_population_prior.html">44 nips-2010-Brain covariance selection: better individual functional connectivity models using population prior</a></p>
<p>Author: Gael Varoquaux, Alexandre Gramfort, Jean-baptiste Poline, Bertrand Thirion</p><p>Abstract: Spontaneous brain activity, as observed in functional neuroimaging, has been shown to display reproducible structure that expresses brain architecture and carries markers of brain pathologies. An important view of modern neuroscience is that such large-scale structure of coherent activity reﬂects modularity properties of brain connectivity graphs. However, to date, there has been no demonstration that the limited and noisy data available in spontaneous activity observations could be used to learn full-brain probabilistic models that generalize to new data. Learning such models entails two main challenges: i) modeling full brain connectivity is a difﬁcult estimation problem that faces the curse of dimensionality and ii) variability between subjects, coupled with the variability of functional signals between experimental runs, makes the use of multiple datasets challenging. We describe subject-level brain functional connectivity structure as a multivariate Gaussian process and introduce a new strategy to estimate it from group data, by imposing a common structure on the graphical model in the population. We show that individual models learned from functional Magnetic Resonance Imaging (fMRI) data using this population prior generalize better to unseen data than models based on alternative regularization schemes. To our knowledge, this is the ﬁrst report of a cross-validated model of spontaneous brain activity. Finally, we use the estimated graphical model to explore the large-scale characteristics of functional architecture and show for the ﬁrst time that known cognitive networks appear as the integrated communities of functional connectivity graph. 1</p><p>2 0.41491026 <a title="44-tfidf-2" href="./nips-2010-Infinite_Relational_Modeling_of_Functional_Connectivity_in_Resting_State_fMRI.html">128 nips-2010-Infinite Relational Modeling of Functional Connectivity in Resting State fMRI</a></p>
<p>Author: Morten Mørup, Kristoffer Madsen, Anne-marie Dogonowski, Hartwig Siebner, Lars K. Hansen</p><p>Abstract: Functional magnetic resonance imaging (fMRI) can be applied to study the functional connectivity of the neural elements which form complex network at a whole brain level. Most analyses of functional resting state networks (RSN) have been based on the analysis of correlation between the temporal dynamics of various regions of the brain. While these models can identify coherently behaving groups in terms of correlation they give little insight into how these groups interact. In this paper we take a different view on the analysis of functional resting state networks. Starting from the deﬁnition of resting state as functional coherent groups we search for functional units of the brain that communicate with other parts of the brain in a coherent manner as measured by mutual information. We use the inﬁnite relational model (IRM) to quantify functional coherent groups of resting state networks and demonstrate how the extracted component interactions can be used to discriminate between functional resting state activity in multiple sclerosis and normal subjects. 1</p><p>3 0.3900249 <a title="44-tfidf-3" href="./nips-2010-Functional_Geometry_Alignment_and_Localization_of_Brain_Areas.html">97 nips-2010-Functional Geometry Alignment and Localization of Brain Areas</a></p>
<p>Author: Georg Langs, Yanmei Tie, Laura Rigolo, Alexandra Golby, Polina Golland</p><p>Abstract: Matching functional brain regions across individuals is a challenging task, largely due to the variability in their location and extent. It is particularly difﬁcult, but highly relevant, for patients with pathologies such as brain tumors, which can cause substantial reorganization of functional systems. In such cases spatial registration based on anatomical data is only of limited value if the goal is to establish correspondences of functional areas among different individuals, or to localize potentially displaced active regions. Rather than rely on spatial alignment, we propose to perform registration in an alternative space whose geometry is governed by the functional interaction patterns in the brain. We ﬁrst embed each brain into a functional map that reﬂects connectivity patterns during a fMRI experiment. The resulting functional maps are then registered, and the obtained correspondences are propagated back to the two brains. In application to a language fMRI experiment, our preliminary results suggest that the proposed method yields improved functional correspondences across subjects. This advantage is pronounced for subjects with tumors that affect the language areas and thus cause spatial reorganization of the functional regions. 1</p><p>4 0.31326887 <a title="44-tfidf-4" href="./nips-2010-Individualized_ROI_Optimization_via_Maximization_of_Group-wise_Consistency_of_Structural_and_Functional_Profiles.html">123 nips-2010-Individualized ROI Optimization via Maximization of Group-wise Consistency of Structural and Functional Profiles</a></p>
<p>Author: Kaiming Li, Lei Guo, Carlos Faraco, Dajiang Zhu, Fan Deng, Tuo Zhang, Xi Jiang, Degang Zhang, Hanbo Chen, Xintao Hu, Steve Miller, Tianming Liu</p><p>Abstract: Functional segregation and integration are fundamental characteristics of the human brain. Studying the connectivity among segregated regions and the dynamics of integrated brain networks has drawn increasing interest. A very controversial, yet fundamental issue in these studies is how to determine the best functional brain regions or ROIs (regions of interests) for individuals. Essentially, the computed connectivity patterns and dynamics of brain networks are very sensitive to the locations, sizes, and shapes of the ROIs. This paper presents a novel methodology to optimize the locations of an individual's ROIs in the working memory system. Our strategy is to formulate the individual ROI optimization as a group variance minimization problem, in which group-wise functional and structural connectivity patterns, and anatomic profiles are defined as optimization constraints. The optimization problem is solved via the simulated annealing approach. Our experimental results show that the optimized ROIs have significantly improved consistency in structural and functional profiles across subjects, and have more reasonable localizations and more consistent morphological and anatomic profiles. 1 Int ro ducti o n The human brainâ&euro;&trade;s function is segregated into distinct regions and integrated via axonal fibers [1]. Studying the connectivity among these regions and modeling their dynamics and interactions has drawn increasing interest and effort from the brain imaging and neuroscience communities [2-6]. For example, recently, the Human Connectome Project [7] and the 1000 Functional Connectomes Project [8] have embarked to elucidate large-scale connectivity patterns in the human brain. For traditional connectivity analysis, a variety of models including DCM (dynamics causal modeling), GCM (Granger causality modeling) and MVA (multivariate autoregressive modeling) are proposed [6, 9-10] to model the interactions of the ROIs. A fundamental issue in these studies is how to accurately identify the ROIs, which are the structural substrates for measuring connectivity. Currently, this is still an open, urgent, yet challenging problem in many brain imaging applications. From our perspective, the major challenges come from uncertainties in ROI boundary definition, the tremendous variability across individuals, and high nonlinearities within and around ROIs. Current approaches for identifying brain ROIs can be broadly classified into four categories. The first is manual labeling by experts using their domain knowledge. The second is a data-driven clustering of ROIs from the brain image itself. For instance, the ReHo (regional homogeneity) algorithm [11] has been used to identify regional homogeneous regions as ROIs. The third is to predefine ROIs in a template brain, and warp them back to the individual space using image registration [12]. Lastly, ROIs can be defined from the activated regions observed during a task-based fMRI paradigm. While fruitful results have been achieved using these approaches, there are various limitations. For instance, manual labeling is difficult to implement for large datasets and may be vulnerable to inter-subject and intra-subject variation; it is difficult to build correspondence across subjects using data-driven clustering methods; warping template ROIs back to individual space is subject to the accuracy of warping techniques and the anatomical variability across subjects. Even identifying ROIs using task-based fMRI paradigms, which is regarded as the standard approach for ROI identification, is still an open question. It was reported in [13] that many imaging-related variables including scanner vender, RF coil characteristics (phase array vs. volume coil), k-space acquisition trajectory, reconstruction algorithms, susceptibility -induced signal dropout, as well as field strength differences, contribute to variations in ROI identification. Other researchers reported that spatial smoothing, a common preprocessing technique in fMRI analysis to enhance SNR, may introduce artificial localization shift s (up to 12.1mm for Gaussian kernel volumetric smoothing) [14] or generate overly smoothed activation maps that may obscure important details [15]. For example, as shown in Fig.1a, the local maximum of the ROI was shifted by 4mm due to the spatial smoothing process. Additionally, its structural profile (Fig.1b) was significantly altered. Furthermore, group-based activation maps may show different patterns from an individual's activation map; Fig.1c depicts such differences. The top panel is the group activation map from a working memory study, while the bottom panel is the activation map of one subject in the study. As we can see from the highlighted boxes, the subject has less activated regions than the group analysis result. In conclusion, standard analysis of task-based fMRI paradigm data is inadequate to accurately localize ROIs for each individual. Fig.1. (a): Local activation map maxima (marked by the cross) shift of one ROI due to spatial volumetric smoothing. The top one was detected using unsmoothed data while the bottom one used smoothed data (FWHM: 6.875mm). (b): The corresponding fibers for the ROIs in (a). The ROIs are presented using a sphere (radius: 5mm). (c): Activation map differences between the group (top) and one subject (bottom). The highlighted boxes show two of the missing activated ROIs found from the group analysis. Without accurate and reliable individualized ROIs, the validity of brain connectivity analysis, and computational modeling of dynamics and interactions among brain networks , would be questionable. In response to this fundamental issue, this paper presents a novel computational methodology to optimize the locations of an individual's ROIs initialized from task-based fMRI. We use the ROIs identified in a block-based working memory paradigm as a test bed application to develop and evaluate our methodology. The optimization of ROI locations was formulated as an energy minimization problem, with the goal of jointly maximizing the group-wise consistency of functional and structural connectivity patterns and anatomic profiles. The optimization problem is solved via the well-established simulated annealing approach. Our experimental results show that the optimized ROIs achieved our optimization objectives and demonstrated promising results. 2 Mat eria l s a nd Metho ds 2.1 Data acquisition and preprocessing Twenty-five university students were recruited to participate in this study. Each participant performed an fMRI modified version of the OSPAN task (3 block types: OSPAN, Arithmetic, and Baseline) while fMRI data was acquired. DTI scans were also acquired for each participant. FMRI and DTI scans were acquired on a 3T GE Signa scanner. Acquisition parameters were as follows : fMRI: 64x64 matrix, 4mm slice thickness, 220mm FOV, 30 slices, TR=1.5s, TE=25ms, ASSET=2; DTI: 128x128 matrix, 2mm slice thickness, 256mm FOV, 60 slices, TR=15100ms, TE= variable, ASSET=2, 3 B0 images, 30 optimized gradient directions, b-value=1000). Each participantâ&euro;&trade;s fMRI data was analyzed using FSL. Individual activation map Fig.2. working memory reflecting the OSPAN (OSPAN > Baseline) contrast was used. In ROIs mapped on a total, we identified the 16 highest activated ROIs, including left WM/GM surface and right insula, left and right medial frontal gyrus, left and right precentral gyrus, left and right paracingulate gyrus, left and right dorsolateral prefrontal cortex, left and right inferior parietal lobule, left occipital pole, right frontal pole, right lateral occipital gyrus, and left and right precuneus. Fig.2 shows the 16 ROIs mapped onto a WM(white matter)/GM(gray matter) cortical surface. For some individuals, there may be missing ROIs on their activation maps. Under such condition, we adapted the group activation map as a guide to find these ROIs using linear registration. DTI pre-processing consisted of skull removal, motion correction, and eddy current correction. After the pre-processing, fiber tracking was performed using MEDINRIA (FA threshold: 0.2; minimum fiber length: 20). Fibers were extended along their tangent directions to reach into the gray matter when necessary. Brain tissue segmentation was conducted on DTI data by the method in [16] and the cortical surface was reconstructed from the tissue maps using the marching cubes algorithm. The cortical surface was parcellated into anatomical regions using the HAMMER tool [17]. DTI space was used as the standard space from which to generate the GM (gray matter) segmentation and from which to report the ROI locations on the cortical surface. Since the fMRI and DTI sequences are both EPI (echo planar imaging) sequences, their distortions tend to be similar and the misalignment between DTI and fMRI images is much less than that between T1 and fMRI images [18]. Co-registration between DTI and fMRI data was performed using FSL FLIRT [12]. The activated ROIs and tracked fibers were then mapped onto the cortical surface for joint modeling. 2.2 Joint modeling of anatomical, structural and functional profiles Despite the high degree of variability across subjects, there are several aspects of regularity on which we base the proposed solution. Firstly, across subjects, the functional ROIs should have similar anatomical locations, e.g., similar locations in the atlas space. Secondly, these ROIs should have similar structural connectivity profiles across subjects. In other words, fibers penetrating the same functional ROIs should have at least similar target regions across subjects. Lastly, individual networks identified by task-based paradigms, like the working memory network we adapted as a test bed in this paper, should have similar functional connectivity pattern across subjects. The neuroscience bases of the above premises include: 1) structural and functional brain connectivity are closely related [19], and cortical gyrification and axongenesis processes are closely coupled [20]; Hence, it is reasonable to put these three types of information in a joint modeling framework. 2) Extensive studies have already demonstrated the existence of a common structural and functional architecture of the human brain [21, 22], and it makes sense to assume that the working memory network has similar structural and functional connectivity patterns across individuals. Based on these premises, we proposed to optimize the locations of individual functional ROIs by jointly modeling anatomic profiles, structural connectivity patterns, and functional connectivity patterns, as illustrated in Fig 3. The Fig.3. ROIs optimization scheme. goal was to minimize the group-wise variance (or maximize group-wise consistency) of these jointly modeled profiles. Mathematically, we modeled the group-wise variance as energy E as follows. A ROI from fMRI analysis was mapped onto the surface, and is represented by a center vertex and its neighborhood. Suppose đ?&lsquo;&hellip; đ?&lsquo;&ndash;đ?&lsquo;&mdash; is the ROI region j on the cortical surface of subject i identified in Section 2.1; we find a corresponding surface ROI region đ?&lsquo;&dagger; đ?&lsquo;&ndash;đ?&lsquo;&mdash; so that the energy E (contains energy from n subjects, each with m ROIs) is minimized: đ??¸ = đ??¸ đ?&lsquo;Ž (đ?&oelig;&dagger; đ??¸ đ?&lsquo;? â&circ;&rsquo;đ?&lsquo;&euro; đ??¸ đ?&lsquo;? đ?&oelig;Ž đ??¸đ?&lsquo;? + (1 â&circ;&rsquo; đ?&oelig;&dagger;) đ??¸ đ?&lsquo;&ldquo; â&circ;&rsquo;đ?&lsquo;&euro; đ??¸ đ?&lsquo;&ldquo; đ?&oelig;Žđ??¸đ?&lsquo;&ldquo; ) (1) where Ea is the anatomical constraint; Ec is the structural connectivity constraint, M Ec and ď ł E are the mean and standard deviation of Ec in the searching space; E f is the functional c connectivity constraint, M E f and ď ł E f are the mean and standard deviation of E f respectively; and ď Ź is a weighting parameter between 0 and 1. If not specified, and m is the number of ROIs in this paper. The details of these energy terms are provided in the following sections. 2.2.1 n is the number of subjects, Anatomical constraint energy Anatomical constraint energy Ea is defined to ensure that the optimized ROIs have similar anatomical locations in the atlas space (Fig.4 shows an example of ROIs of 15 randomly selected subjects in the atlas space). We model the locations for all ROIs in the atlas space using a Gaussian model (mean: đ?&lsquo;&euro; đ?&lsquo;&lsaquo; đ?&lsquo;&mdash; ,and standard deviation: ď ł X j for ROI j ). The model parameters were estimated using the initial locations obtained from Section 2.1. Let X ij be the center coordinate of region Sij in the atlas space, then Ea is expressed as đ??¸đ?&lsquo;Ž = { 1 đ?&lsquo;&rsquo; đ?&lsquo;&lsquo;đ?&lsquo;&scaron;đ?&lsquo;Žđ?&lsquo;Ľâ&circ;&rsquo;1 Fig.4. ROI distributions in Atlas space. (đ?&lsquo;&lsquo;đ?&lsquo;&scaron;đ?&lsquo;Žđ?&lsquo;Ľâ&permil;¤1) (đ?&lsquo;&lsquo;đ?&lsquo;&scaron;đ?&lsquo;Žđ?&lsquo;Ľ>1) (2) â&euro;&ndash; , 1 â&permil;¤ đ?&lsquo;&ndash; â&permil;¤ đ?&lsquo;&rsaquo;; 1 â&permil;¤ đ?&lsquo;&mdash; â&permil;¤ đ?&lsquo;&scaron;. } (3) where đ?&lsquo;&lsquo;đ?&lsquo;&scaron;đ?&lsquo;Žđ?&lsquo;Ľ = đ?&lsquo;&euro;đ?&lsquo;Žđ?&lsquo;Ľ { â&euro;&ndash; đ?&lsquo;&lsaquo; đ?&lsquo;&ndash;đ?&lsquo;&mdash; â&circ;&rsquo;đ?&lsquo;&euro; đ?&lsquo;&lsaquo; đ?&lsquo;&mdash; 3đ?&oelig;Ž đ?&lsquo;&lsaquo; đ?&lsquo;&mdash; Under the above definition, if any X ij is within the range of 3s X from the distribution model j center M X , the anatomical constraint energy will always be one; if not, there will be an j exponential increase of the energy which punishes the possible involvement of outliers. In other words, this energy factor will ensure the optimized ROIs will not significantly deviate away from the original ROIs. 2.2.2 Structural connectivity constraint energy Structural connectivity constraint energy Ec is defined to ensure the group has similar structural connectivity profiles for each functional ROI, since similar functional regions should have the similar structural connectivity patterns [19], n m Ec ď&euro;˝ ď&fnof;Ľď&fnof;Ľ (Cij ď&euro;­ M C j )Covc ď&euro;­1 (Ci j ď&euro;­ M C j )T (4) i ď&euro;˝1 j ď&euro;˝1 where Cij is the connectivity pattern vector for ROI j of subject i , M C j is the group mean ď&euro;­1 for ROI j , and Covc is the inverse of the covariance matrix. The connectivity pattern vector Cij is a fiber target region distribution histogram. To obtain this histogram, we first parcellate all the cortical surfaces into nine regions ( as shown in Fig.5a, four lobes for each hemisphere, and the subcortical region) using the HAMMER algorithm [17]. A finer parcellation is available but not used due to the relatively lower parcellation accuracy, which might render the histogram too sensitive to the parcellation result. Then, we extract fibers penetrating region Sij , and calculate the distribution of the fibersâ&euro;&trade; target cortical regions. Fig.5 illustrates the ideas. Fig.5. Structural connectivity pattern descriptor. (a): Cortical surface parcellation using HAMMER [17]; (b): Joint visualization of the cortical surface, two ROIs (blue and green spheres), and fibers penetrating the ROIs (in red and yellow, respectively); (c): Corresponding target region distribution histogram of ROIs in Fig.5b. There are nine bins corresponding to the nine cortical regions. Each bin contains the number of fibers that penetrate the ROI and are connected to the corresponding cortical region. Fiber numbers are normalized across subjects. 2.2.3 Functional connectivity constraint energy Functional connectivity constraint energy E f is defined to ensure each individual has similar functional connectivity patterns for the working memory system, assuming the human brain has similar functional architecture across individuals [21]. đ?&lsquo;&rsaquo; đ??¸ đ?&lsquo;&ldquo; = â&circ;&lsquo; đ?&lsquo;&ndash;=1â&euro;&ndash;đ??šđ?&lsquo;&ndash; â&circ;&rsquo; đ?&lsquo;&euro; đ??š â&euro;&ndash; (5) Here, Fi is the functional connectivity matrix for subject i , and M F is the group mean of the dataset. The connectivity between each pair of ROIs is defined using the Pearson correlation. The matrix distance used here is the Frobenius norm. 2.3 Energy minimization solution The minimization of the energy defined in Section 2.2 is known as a combinatorial optimization problem. Traditional optimization methods may not fit this problem, since there are two noticeable characteristics in this application. First, we do not know how the energy changes with the varying locations of ROIs. Therefore, techniques like Newtonâ&euro;&trade;s method cannot be used. Second, the structure of search space is not smooth, which may lead to multiple local minima during optimization. To address this problem, we adopt the simulated annealing (SA) algorithm [23] for the energy minimization. The idea of the SA algorithm is based on random walk through the space for lower energies. In these random walks, the probability of taking a step is determined by the Boltzmann distribution, - (E - E )/ ( KT ) p = e i+ 1 i (6) if Ei ď&euro;Ť1 ď&euro;ž Ei , and p ď&euro;˝ 1 when Ei ď&euro;Ť1 ď&sbquo;Ł Ei . Here, đ??¸ đ?&lsquo;&ndash; and đ??¸ đ?&lsquo;&ndash;+1 are the system energies at solution configuration đ?&lsquo;&ndash; and đ?&lsquo;&ndash; + 1 respectively; đ??ž is the Boltzmann constant; and đ?&lsquo;&Dagger; is the system temperature. In other words, a step will be taken when a lower energy is found. A step will also be taken with probability p if a higher energy is found. This helps avoid the local minima in the search space. 3 R esult s Compared to structural and functional connectivity patterns, anatomical profiles are more easily affected by variability across individuals. Therefore, the anatomical constraint energy is designed to provide constraint only to ROIs that are obviously far away from reasonableness. The reasonable range was statistically modeled by the localizations of ROIs warped into the atlas space in Section 2.2.1. Our focus in this paper is the structural and functional profiles. 3.1 Optimization using anatomical and structural connectivity profile s In this section, we use only anatomical and structural connectivity profiles to optimize the locations of ROIs. The goal is to check whether the structural constraint energy Ec works as expected. Fig.6 shows the fibers penetrating the right precuneus for eight subjects before (top panel) and after optimization (bottom panel). The ROI is highlighted in a red sphere for each subject. As we can see from the figure (please refer to the highlighted yellow arrows), after optimization, the third and sixth subjects have significantly improved consistency with the rest of the group than before optimization, which proves the validity of the energy function Eq.(4). Fig.6. Comparison of structural profiles before and after optimization. Each column shows the corresponding before-optimization (top) and after-optimization (bottom) fibers of one subject. The ROI (right precuneus) is presented by the red sphere. 3.2 Optimization using anatomical and functional connectivity profiles In this section, we optimize the locations of ROIs using anatomical and functional profiles, aiming to validate the definition of functional connectivity constraint energy E f . If this energy constraint worked well, the functional connectivity variance of the working memory system across subjects would decrease. Fig.7 shows the comparison of the standard derivation for functional connectivity before (left) and after (right) optimization. As we can see, the variance is significantly reduced after optimization. This demonstrated the effectiveness of the defined functional connectivity constraint energy. Fig.7. Comparison of the standard derivation for functional connectivity before and after the optimization. Lower values mean more consistent connectivity pattern cross subjects. 3.3 Consistency between optimization of functional profiles and structural profiles Fig.8. Optimization consistency between functional and structural profiles. Top: Functional profile energy drop along with structural profile optimization; Bottom: Structural profile energy drop along with functional profile optimization. Each experiment was repeated 15 times with random initial ROI locations that met the anatomical constraint. The relationship between structure and function has been extensively studied [24], and it is widely believed that they are closely related. In this section, we study the relationship between functional profiles and structural profiles by looking at how the energy for one of them changes while the energy of the other decreases. The optimization processes in Section 3.1 and 3.2 were repeated 15 times respectively with random initial ROI locations that met the anatomical constraint. As shown in Fig.8, in general, the functional profile energies and structural profile energies are closely related in such a way that the functional profile energies tend to decrease along with the structural profile optimization process, while the structural profile energies also tend to decrease as the functional profile is optimized. This positively correlated decrease of functional profile energy and structural profile energy not only proves the close relationship between functional and structural profiles, but also demonstrates the consistency between functional and structural optimization, laying down the foundation of the joint optimiza tion, whose results are detailed in the following section. 3.4 Optimization connectivity profiles using anatomical, structural and functional In this section, we used all the constraints in Eq. (1) to optimize the individual locations of all ROIs in the working memory system. Ten runs of the optimization were performed using random initial ROI locations that met the anatomical constraint. Weighting parameter ď Ź equaled 0.5 for all these runs. Starting and ending temperatures for the simulated annealing algorithm are 8 and 0.05; Boltzmann constant K ď&euro;˝ 1 . As we can see from Fig.9, most runs started to converge at step 24, and the convergence energy is quite close for all runs. This indicates that the simulated annealing algorithm provides a valid solution to our problem. By visual inspection, most of the ROIs move to more reasonable and consistent locations after the joint optimization. As an example, Fig.10 depicts the location movements of the ROI in Fig. 6 for eight subjects. As we can see, the ROIs for these subjects share a similar anatomical landmark, which appears to be the tip of the upper bank of the parieto-occipital sulcus. If the initial ROI was not at this landmark, it moved to the landmark after the optimization, which was the case for subjects 1, 4 and 7. The structural profiles of these ROIs are very similar to Fig.6. The results in Fig. 10 indicate the significant improvement of ROI locations achieved by the joint optimization procedure. Fig.9. Convergence performance of the simulated annealing . Each run has 28 temperature conditions. Fig.10. The movement of right precuneus before (in red sphere) and after (in green sphere) optimization for eight subjects. The</p><p>5 0.23464441 <a title="44-tfidf-5" href="./nips-2010-Spatial_and_anatomical_regularization_of_SVM_for_brain_image_analysis.html">249 nips-2010-Spatial and anatomical regularization of SVM for brain image analysis</a></p>
<p>Author: Remi Cuingnet, Marie Chupin, Habib Benali, Olivier Colliot</p><p>Abstract: Support vector machines (SVM) are increasingly used in brain image analyses since they allow capturing complex multivariate relationships in the data. Moreover, when the kernel is linear, SVMs can be used to localize spatial patterns of discrimination between two groups of subjects. However, the features’ spatial distribution is not taken into account. As a consequence, the optimal margin hyperplane is often scattered and lacks spatial coherence, making its anatomical interpretation difﬁcult. This paper introduces a framework to spatially regularize SVM for brain image analysis. We show that Laplacian regularization provides a ﬂexible framework to integrate various types of constraints and can be applied to both cortical surfaces and 3D brain images. The proposed framework is applied to the classiﬁcation of MR images based on gray matter concentration maps and cortical thickness measures from 30 patients with Alzheimer’s disease and 30 elderly controls. The results demonstrate that the proposed method enables natural spatial and anatomical regularization of the classiﬁer. 1</p><p>6 0.13732213 <a title="44-tfidf-6" href="./nips-2010-Inferring_Stimulus_Selectivity_from_the_Spatial_Structure_of_Neural_Network_Dynamics.html">127 nips-2010-Inferring Stimulus Selectivity from the Spatial Structure of Neural Network Dynamics</a></p>
<p>7 0.11355907 <a title="44-tfidf-7" href="./nips-2010-Subgraph_Detection_Using_Eigenvector_L1_Norms.html">259 nips-2010-Subgraph Detection Using Eigenvector L1 Norms</a></p>
<p>8 0.11290777 <a title="44-tfidf-8" href="./nips-2010-Over-complete_representations_on_recurrent_neural_networks_can_support_persistent_percepts.html">200 nips-2010-Over-complete representations on recurrent neural networks can support persistent percepts</a></p>
<p>9 0.10352466 <a title="44-tfidf-9" href="./nips-2010-The_Neural_Costs_of_Optimal_Control.html">268 nips-2010-The Neural Costs of Optimal Control</a></p>
<p>10 0.10040824 <a title="44-tfidf-10" href="./nips-2010-Decoding_Ipsilateral_Finger_Movements_from_ECoG_Signals_in_Humans.html">57 nips-2010-Decoding Ipsilateral Finger Movements from ECoG Signals in Humans</a></p>
<p>11 0.099170014 <a title="44-tfidf-11" href="./nips-2010-Epitome_driven_3-D_Diffusion_Tensor_image_segmentation%3A_on_extracting_specific_structures.html">77 nips-2010-Epitome driven 3-D Diffusion Tensor image segmentation: on extracting specific structures</a></p>
<p>12 0.097405575 <a title="44-tfidf-12" href="./nips-2010-Linear_readout_from_a_neural_population_with_partial_correlation_data.html">161 nips-2010-Linear readout from a neural population with partial correlation data</a></p>
<p>13 0.093995653 <a title="44-tfidf-13" href="./nips-2010-Link_Discovery_using_Graph_Feature_Tracking.html">162 nips-2010-Link Discovery using Graph Feature Tracking</a></p>
<p>14 0.090440288 <a title="44-tfidf-14" href="./nips-2010-Accounting_for_network_effects_in_neuronal_responses_using_L1_regularized_point_process_models.html">21 nips-2010-Accounting for network effects in neuronal responses using L1 regularized point process models</a></p>
<p>15 0.089583158 <a title="44-tfidf-15" href="./nips-2010-Stability_Approach_to_Regularization_Selection_%28StARS%29_for_High_Dimensional_Graphical_Models.html">254 nips-2010-Stability Approach to Regularization Selection (StARS) for High Dimensional Graphical Models</a></p>
<p>16 0.088814303 <a title="44-tfidf-16" href="./nips-2010-Functional_form_of_motion_priors_in_human_motion_perception.html">98 nips-2010-Functional form of motion priors in human motion perception</a></p>
<p>17 0.085971005 <a title="44-tfidf-17" href="./nips-2010-Short-term_memory_in_neuronal_networks_through_dynamical_compressed_sensing.html">238 nips-2010-Short-term memory in neuronal networks through dynamical compressed sensing</a></p>
<p>18 0.083225578 <a title="44-tfidf-18" href="./nips-2010-Learning_Multiple_Tasks_with_a_Sparse_Matrix-Normal_Penalty.html">147 nips-2010-Learning Multiple Tasks with a Sparse Matrix-Normal Penalty</a></p>
<p>19 0.078290731 <a title="44-tfidf-19" href="./nips-2010-Beyond_Actions%3A_Discriminative_Models_for_Contextual_Group_Activities.html">40 nips-2010-Beyond Actions: Discriminative Models for Contextual Group Activities</a></p>
<p>20 0.077668034 <a title="44-tfidf-20" href="./nips-2010-Implicit_encoding_of_prior_probabilities_in_optimal_neural_populations.html">119 nips-2010-Implicit encoding of prior probabilities in optimal neural populations</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.219), (1, 0.103), (2, -0.226), (3, 0.261), (4, -0.0), (5, -0.228), (6, 0.025), (7, -0.494), (8, -0.038), (9, 0.007), (10, 0.011), (11, 0.109), (12, 0.002), (13, 0.028), (14, -0.105), (15, 0.042), (16, 0.013), (17, 0.059), (18, 0.038), (19, -0.012), (20, 0.0), (21, -0.047), (22, -0.017), (23, -0.025), (24, -0.032), (25, 0.011), (26, -0.018), (27, -0.034), (28, 0.052), (29, 0.036), (30, 0.009), (31, -0.039), (32, -0.006), (33, 0.045), (34, 0.028), (35, 0.044), (36, 0.015), (37, -0.038), (38, -0.016), (39, 0.016), (40, -0.02), (41, -0.019), (42, 0.032), (43, -0.016), (44, 0.037), (45, -0.028), (46, -0.058), (47, 0.012), (48, -0.035), (49, 0.004)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96877855 <a title="44-lsi-1" href="./nips-2010-Brain_covariance_selection%3A_better_individual_functional_connectivity_models_using_population_prior.html">44 nips-2010-Brain covariance selection: better individual functional connectivity models using population prior</a></p>
<p>Author: Gael Varoquaux, Alexandre Gramfort, Jean-baptiste Poline, Bertrand Thirion</p><p>Abstract: Spontaneous brain activity, as observed in functional neuroimaging, has been shown to display reproducible structure that expresses brain architecture and carries markers of brain pathologies. An important view of modern neuroscience is that such large-scale structure of coherent activity reﬂects modularity properties of brain connectivity graphs. However, to date, there has been no demonstration that the limited and noisy data available in spontaneous activity observations could be used to learn full-brain probabilistic models that generalize to new data. Learning such models entails two main challenges: i) modeling full brain connectivity is a difﬁcult estimation problem that faces the curse of dimensionality and ii) variability between subjects, coupled with the variability of functional signals between experimental runs, makes the use of multiple datasets challenging. We describe subject-level brain functional connectivity structure as a multivariate Gaussian process and introduce a new strategy to estimate it from group data, by imposing a common structure on the graphical model in the population. We show that individual models learned from functional Magnetic Resonance Imaging (fMRI) data using this population prior generalize better to unseen data than models based on alternative regularization schemes. To our knowledge, this is the ﬁrst report of a cross-validated model of spontaneous brain activity. Finally, we use the estimated graphical model to explore the large-scale characteristics of functional architecture and show for the ﬁrst time that known cognitive networks appear as the integrated communities of functional connectivity graph. 1</p><p>2 0.94501263 <a title="44-lsi-2" href="./nips-2010-Functional_Geometry_Alignment_and_Localization_of_Brain_Areas.html">97 nips-2010-Functional Geometry Alignment and Localization of Brain Areas</a></p>
<p>Author: Georg Langs, Yanmei Tie, Laura Rigolo, Alexandra Golby, Polina Golland</p><p>Abstract: Matching functional brain regions across individuals is a challenging task, largely due to the variability in their location and extent. It is particularly difﬁcult, but highly relevant, for patients with pathologies such as brain tumors, which can cause substantial reorganization of functional systems. In such cases spatial registration based on anatomical data is only of limited value if the goal is to establish correspondences of functional areas among different individuals, or to localize potentially displaced active regions. Rather than rely on spatial alignment, we propose to perform registration in an alternative space whose geometry is governed by the functional interaction patterns in the brain. We ﬁrst embed each brain into a functional map that reﬂects connectivity patterns during a fMRI experiment. The resulting functional maps are then registered, and the obtained correspondences are propagated back to the two brains. In application to a language fMRI experiment, our preliminary results suggest that the proposed method yields improved functional correspondences across subjects. This advantage is pronounced for subjects with tumors that affect the language areas and thus cause spatial reorganization of the functional regions. 1</p><p>3 0.94269013 <a title="44-lsi-3" href="./nips-2010-Individualized_ROI_Optimization_via_Maximization_of_Group-wise_Consistency_of_Structural_and_Functional_Profiles.html">123 nips-2010-Individualized ROI Optimization via Maximization of Group-wise Consistency of Structural and Functional Profiles</a></p>
<p>Author: Kaiming Li, Lei Guo, Carlos Faraco, Dajiang Zhu, Fan Deng, Tuo Zhang, Xi Jiang, Degang Zhang, Hanbo Chen, Xintao Hu, Steve Miller, Tianming Liu</p><p>Abstract: Functional segregation and integration are fundamental characteristics of the human brain. Studying the connectivity among segregated regions and the dynamics of integrated brain networks has drawn increasing interest. A very controversial, yet fundamental issue in these studies is how to determine the best functional brain regions or ROIs (regions of interests) for individuals. Essentially, the computed connectivity patterns and dynamics of brain networks are very sensitive to the locations, sizes, and shapes of the ROIs. This paper presents a novel methodology to optimize the locations of an individual's ROIs in the working memory system. Our strategy is to formulate the individual ROI optimization as a group variance minimization problem, in which group-wise functional and structural connectivity patterns, and anatomic profiles are defined as optimization constraints. The optimization problem is solved via the simulated annealing approach. Our experimental results show that the optimized ROIs have significantly improved consistency in structural and functional profiles across subjects, and have more reasonable localizations and more consistent morphological and anatomic profiles. 1 Int ro ducti o n The human brainâ&euro;&trade;s function is segregated into distinct regions and integrated via axonal fibers [1]. Studying the connectivity among these regions and modeling their dynamics and interactions has drawn increasing interest and effort from the brain imaging and neuroscience communities [2-6]. For example, recently, the Human Connectome Project [7] and the 1000 Functional Connectomes Project [8] have embarked to elucidate large-scale connectivity patterns in the human brain. For traditional connectivity analysis, a variety of models including DCM (dynamics causal modeling), GCM (Granger causality modeling) and MVA (multivariate autoregressive modeling) are proposed [6, 9-10] to model the interactions of the ROIs. A fundamental issue in these studies is how to accurately identify the ROIs, which are the structural substrates for measuring connectivity. Currently, this is still an open, urgent, yet challenging problem in many brain imaging applications. From our perspective, the major challenges come from uncertainties in ROI boundary definition, the tremendous variability across individuals, and high nonlinearities within and around ROIs. Current approaches for identifying brain ROIs can be broadly classified into four categories. The first is manual labeling by experts using their domain knowledge. The second is a data-driven clustering of ROIs from the brain image itself. For instance, the ReHo (regional homogeneity) algorithm [11] has been used to identify regional homogeneous regions as ROIs. The third is to predefine ROIs in a template brain, and warp them back to the individual space using image registration [12]. Lastly, ROIs can be defined from the activated regions observed during a task-based fMRI paradigm. While fruitful results have been achieved using these approaches, there are various limitations. For instance, manual labeling is difficult to implement for large datasets and may be vulnerable to inter-subject and intra-subject variation; it is difficult to build correspondence across subjects using data-driven clustering methods; warping template ROIs back to individual space is subject to the accuracy of warping techniques and the anatomical variability across subjects. Even identifying ROIs using task-based fMRI paradigms, which is regarded as the standard approach for ROI identification, is still an open question. It was reported in [13] that many imaging-related variables including scanner vender, RF coil characteristics (phase array vs. volume coil), k-space acquisition trajectory, reconstruction algorithms, susceptibility -induced signal dropout, as well as field strength differences, contribute to variations in ROI identification. Other researchers reported that spatial smoothing, a common preprocessing technique in fMRI analysis to enhance SNR, may introduce artificial localization shift s (up to 12.1mm for Gaussian kernel volumetric smoothing) [14] or generate overly smoothed activation maps that may obscure important details [15]. For example, as shown in Fig.1a, the local maximum of the ROI was shifted by 4mm due to the spatial smoothing process. Additionally, its structural profile (Fig.1b) was significantly altered. Furthermore, group-based activation maps may show different patterns from an individual's activation map; Fig.1c depicts such differences. The top panel is the group activation map from a working memory study, while the bottom panel is the activation map of one subject in the study. As we can see from the highlighted boxes, the subject has less activated regions than the group analysis result. In conclusion, standard analysis of task-based fMRI paradigm data is inadequate to accurately localize ROIs for each individual. Fig.1. (a): Local activation map maxima (marked by the cross) shift of one ROI due to spatial volumetric smoothing. The top one was detected using unsmoothed data while the bottom one used smoothed data (FWHM: 6.875mm). (b): The corresponding fibers for the ROIs in (a). The ROIs are presented using a sphere (radius: 5mm). (c): Activation map differences between the group (top) and one subject (bottom). The highlighted boxes show two of the missing activated ROIs found from the group analysis. Without accurate and reliable individualized ROIs, the validity of brain connectivity analysis, and computational modeling of dynamics and interactions among brain networks , would be questionable. In response to this fundamental issue, this paper presents a novel computational methodology to optimize the locations of an individual's ROIs initialized from task-based fMRI. We use the ROIs identified in a block-based working memory paradigm as a test bed application to develop and evaluate our methodology. The optimization of ROI locations was formulated as an energy minimization problem, with the goal of jointly maximizing the group-wise consistency of functional and structural connectivity patterns and anatomic profiles. The optimization problem is solved via the well-established simulated annealing approach. Our experimental results show that the optimized ROIs achieved our optimization objectives and demonstrated promising results. 2 Mat eria l s a nd Metho ds 2.1 Data acquisition and preprocessing Twenty-five university students were recruited to participate in this study. Each participant performed an fMRI modified version of the OSPAN task (3 block types: OSPAN, Arithmetic, and Baseline) while fMRI data was acquired. DTI scans were also acquired for each participant. FMRI and DTI scans were acquired on a 3T GE Signa scanner. Acquisition parameters were as follows : fMRI: 64x64 matrix, 4mm slice thickness, 220mm FOV, 30 slices, TR=1.5s, TE=25ms, ASSET=2; DTI: 128x128 matrix, 2mm slice thickness, 256mm FOV, 60 slices, TR=15100ms, TE= variable, ASSET=2, 3 B0 images, 30 optimized gradient directions, b-value=1000). Each participantâ&euro;&trade;s fMRI data was analyzed using FSL. Individual activation map Fig.2. working memory reflecting the OSPAN (OSPAN > Baseline) contrast was used. In ROIs mapped on a total, we identified the 16 highest activated ROIs, including left WM/GM surface and right insula, left and right medial frontal gyrus, left and right precentral gyrus, left and right paracingulate gyrus, left and right dorsolateral prefrontal cortex, left and right inferior parietal lobule, left occipital pole, right frontal pole, right lateral occipital gyrus, and left and right precuneus. Fig.2 shows the 16 ROIs mapped onto a WM(white matter)/GM(gray matter) cortical surface. For some individuals, there may be missing ROIs on their activation maps. Under such condition, we adapted the group activation map as a guide to find these ROIs using linear registration. DTI pre-processing consisted of skull removal, motion correction, and eddy current correction. After the pre-processing, fiber tracking was performed using MEDINRIA (FA threshold: 0.2; minimum fiber length: 20). Fibers were extended along their tangent directions to reach into the gray matter when necessary. Brain tissue segmentation was conducted on DTI data by the method in [16] and the cortical surface was reconstructed from the tissue maps using the marching cubes algorithm. The cortical surface was parcellated into anatomical regions using the HAMMER tool [17]. DTI space was used as the standard space from which to generate the GM (gray matter) segmentation and from which to report the ROI locations on the cortical surface. Since the fMRI and DTI sequences are both EPI (echo planar imaging) sequences, their distortions tend to be similar and the misalignment between DTI and fMRI images is much less than that between T1 and fMRI images [18]. Co-registration between DTI and fMRI data was performed using FSL FLIRT [12]. The activated ROIs and tracked fibers were then mapped onto the cortical surface for joint modeling. 2.2 Joint modeling of anatomical, structural and functional profiles Despite the high degree of variability across subjects, there are several aspects of regularity on which we base the proposed solution. Firstly, across subjects, the functional ROIs should have similar anatomical locations, e.g., similar locations in the atlas space. Secondly, these ROIs should have similar structural connectivity profiles across subjects. In other words, fibers penetrating the same functional ROIs should have at least similar target regions across subjects. Lastly, individual networks identified by task-based paradigms, like the working memory network we adapted as a test bed in this paper, should have similar functional connectivity pattern across subjects. The neuroscience bases of the above premises include: 1) structural and functional brain connectivity are closely related [19], and cortical gyrification and axongenesis processes are closely coupled [20]; Hence, it is reasonable to put these three types of information in a joint modeling framework. 2) Extensive studies have already demonstrated the existence of a common structural and functional architecture of the human brain [21, 22], and it makes sense to assume that the working memory network has similar structural and functional connectivity patterns across individuals. Based on these premises, we proposed to optimize the locations of individual functional ROIs by jointly modeling anatomic profiles, structural connectivity patterns, and functional connectivity patterns, as illustrated in Fig 3. The Fig.3. ROIs optimization scheme. goal was to minimize the group-wise variance (or maximize group-wise consistency) of these jointly modeled profiles. Mathematically, we modeled the group-wise variance as energy E as follows. A ROI from fMRI analysis was mapped onto the surface, and is represented by a center vertex and its neighborhood. Suppose đ?&lsquo;&hellip; đ?&lsquo;&ndash;đ?&lsquo;&mdash; is the ROI region j on the cortical surface of subject i identified in Section 2.1; we find a corresponding surface ROI region đ?&lsquo;&dagger; đ?&lsquo;&ndash;đ?&lsquo;&mdash; so that the energy E (contains energy from n subjects, each with m ROIs) is minimized: đ??¸ = đ??¸ đ?&lsquo;Ž (đ?&oelig;&dagger; đ??¸ đ?&lsquo;? â&circ;&rsquo;đ?&lsquo;&euro; đ??¸ đ?&lsquo;? đ?&oelig;Ž đ??¸đ?&lsquo;? + (1 â&circ;&rsquo; đ?&oelig;&dagger;) đ??¸ đ?&lsquo;&ldquo; â&circ;&rsquo;đ?&lsquo;&euro; đ??¸ đ?&lsquo;&ldquo; đ?&oelig;Žđ??¸đ?&lsquo;&ldquo; ) (1) where Ea is the anatomical constraint; Ec is the structural connectivity constraint, M Ec and ď ł E are the mean and standard deviation of Ec in the searching space; E f is the functional c connectivity constraint, M E f and ď ł E f are the mean and standard deviation of E f respectively; and ď Ź is a weighting parameter between 0 and 1. If not specified, and m is the number of ROIs in this paper. The details of these energy terms are provided in the following sections. 2.2.1 n is the number of subjects, Anatomical constraint energy Anatomical constraint energy Ea is defined to ensure that the optimized ROIs have similar anatomical locations in the atlas space (Fig.4 shows an example of ROIs of 15 randomly selected subjects in the atlas space). We model the locations for all ROIs in the atlas space using a Gaussian model (mean: đ?&lsquo;&euro; đ?&lsquo;&lsaquo; đ?&lsquo;&mdash; ,and standard deviation: ď ł X j for ROI j ). The model parameters were estimated using the initial locations obtained from Section 2.1. Let X ij be the center coordinate of region Sij in the atlas space, then Ea is expressed as đ??¸đ?&lsquo;Ž = { 1 đ?&lsquo;&rsquo; đ?&lsquo;&lsquo;đ?&lsquo;&scaron;đ?&lsquo;Žđ?&lsquo;Ľâ&circ;&rsquo;1 Fig.4. ROI distributions in Atlas space. (đ?&lsquo;&lsquo;đ?&lsquo;&scaron;đ?&lsquo;Žđ?&lsquo;Ľâ&permil;¤1) (đ?&lsquo;&lsquo;đ?&lsquo;&scaron;đ?&lsquo;Žđ?&lsquo;Ľ>1) (2) â&euro;&ndash; , 1 â&permil;¤ đ?&lsquo;&ndash; â&permil;¤ đ?&lsquo;&rsaquo;; 1 â&permil;¤ đ?&lsquo;&mdash; â&permil;¤ đ?&lsquo;&scaron;. } (3) where đ?&lsquo;&lsquo;đ?&lsquo;&scaron;đ?&lsquo;Žđ?&lsquo;Ľ = đ?&lsquo;&euro;đ?&lsquo;Žđ?&lsquo;Ľ { â&euro;&ndash; đ?&lsquo;&lsaquo; đ?&lsquo;&ndash;đ?&lsquo;&mdash; â&circ;&rsquo;đ?&lsquo;&euro; đ?&lsquo;&lsaquo; đ?&lsquo;&mdash; 3đ?&oelig;Ž đ?&lsquo;&lsaquo; đ?&lsquo;&mdash; Under the above definition, if any X ij is within the range of 3s X from the distribution model j center M X , the anatomical constraint energy will always be one; if not, there will be an j exponential increase of the energy which punishes the possible involvement of outliers. In other words, this energy factor will ensure the optimized ROIs will not significantly deviate away from the original ROIs. 2.2.2 Structural connectivity constraint energy Structural connectivity constraint energy Ec is defined to ensure the group has similar structural connectivity profiles for each functional ROI, since similar functional regions should have the similar structural connectivity patterns [19], n m Ec ď&euro;˝ ď&fnof;Ľď&fnof;Ľ (Cij ď&euro;­ M C j )Covc ď&euro;­1 (Ci j ď&euro;­ M C j )T (4) i ď&euro;˝1 j ď&euro;˝1 where Cij is the connectivity pattern vector for ROI j of subject i , M C j is the group mean ď&euro;­1 for ROI j , and Covc is the inverse of the covariance matrix. The connectivity pattern vector Cij is a fiber target region distribution histogram. To obtain this histogram, we first parcellate all the cortical surfaces into nine regions ( as shown in Fig.5a, four lobes for each hemisphere, and the subcortical region) using the HAMMER algorithm [17]. A finer parcellation is available but not used due to the relatively lower parcellation accuracy, which might render the histogram too sensitive to the parcellation result. Then, we extract fibers penetrating region Sij , and calculate the distribution of the fibersâ&euro;&trade; target cortical regions. Fig.5 illustrates the ideas. Fig.5. Structural connectivity pattern descriptor. (a): Cortical surface parcellation using HAMMER [17]; (b): Joint visualization of the cortical surface, two ROIs (blue and green spheres), and fibers penetrating the ROIs (in red and yellow, respectively); (c): Corresponding target region distribution histogram of ROIs in Fig.5b. There are nine bins corresponding to the nine cortical regions. Each bin contains the number of fibers that penetrate the ROI and are connected to the corresponding cortical region. Fiber numbers are normalized across subjects. 2.2.3 Functional connectivity constraint energy Functional connectivity constraint energy E f is defined to ensure each individual has similar functional connectivity patterns for the working memory system, assuming the human brain has similar functional architecture across individuals [21]. đ?&lsquo;&rsaquo; đ??¸ đ?&lsquo;&ldquo; = â&circ;&lsquo; đ?&lsquo;&ndash;=1â&euro;&ndash;đ??šđ?&lsquo;&ndash; â&circ;&rsquo; đ?&lsquo;&euro; đ??š â&euro;&ndash; (5) Here, Fi is the functional connectivity matrix for subject i , and M F is the group mean of the dataset. The connectivity between each pair of ROIs is defined using the Pearson correlation. The matrix distance used here is the Frobenius norm. 2.3 Energy minimization solution The minimization of the energy defined in Section 2.2 is known as a combinatorial optimization problem. Traditional optimization methods may not fit this problem, since there are two noticeable characteristics in this application. First, we do not know how the energy changes with the varying locations of ROIs. Therefore, techniques like Newtonâ&euro;&trade;s method cannot be used. Second, the structure of search space is not smooth, which may lead to multiple local minima during optimization. To address this problem, we adopt the simulated annealing (SA) algorithm [23] for the energy minimization. The idea of the SA algorithm is based on random walk through the space for lower energies. In these random walks, the probability of taking a step is determined by the Boltzmann distribution, - (E - E )/ ( KT ) p = e i+ 1 i (6) if Ei ď&euro;Ť1 ď&euro;ž Ei , and p ď&euro;˝ 1 when Ei ď&euro;Ť1 ď&sbquo;Ł Ei . Here, đ??¸ đ?&lsquo;&ndash; and đ??¸ đ?&lsquo;&ndash;+1 are the system energies at solution configuration đ?&lsquo;&ndash; and đ?&lsquo;&ndash; + 1 respectively; đ??ž is the Boltzmann constant; and đ?&lsquo;&Dagger; is the system temperature. In other words, a step will be taken when a lower energy is found. A step will also be taken with probability p if a higher energy is found. This helps avoid the local minima in the search space. 3 R esult s Compared to structural and functional connectivity patterns, anatomical profiles are more easily affected by variability across individuals. Therefore, the anatomical constraint energy is designed to provide constraint only to ROIs that are obviously far away from reasonableness. The reasonable range was statistically modeled by the localizations of ROIs warped into the atlas space in Section 2.2.1. Our focus in this paper is the structural and functional profiles. 3.1 Optimization using anatomical and structural connectivity profile s In this section, we use only anatomical and structural connectivity profiles to optimize the locations of ROIs. The goal is to check whether the structural constraint energy Ec works as expected. Fig.6 shows the fibers penetrating the right precuneus for eight subjects before (top panel) and after optimization (bottom panel). The ROI is highlighted in a red sphere for each subject. As we can see from the figure (please refer to the highlighted yellow arrows), after optimization, the third and sixth subjects have significantly improved consistency with the rest of the group than before optimization, which proves the validity of the energy function Eq.(4). Fig.6. Comparison of structural profiles before and after optimization. Each column shows the corresponding before-optimization (top) and after-optimization (bottom) fibers of one subject. The ROI (right precuneus) is presented by the red sphere. 3.2 Optimization using anatomical and functional connectivity profiles In this section, we optimize the locations of ROIs using anatomical and functional profiles, aiming to validate the definition of functional connectivity constraint energy E f . If this energy constraint worked well, the functional connectivity variance of the working memory system across subjects would decrease. Fig.7 shows the comparison of the standard derivation for functional connectivity before (left) and after (right) optimization. As we can see, the variance is significantly reduced after optimization. This demonstrated the effectiveness of the defined functional connectivity constraint energy. Fig.7. Comparison of the standard derivation for functional connectivity before and after the optimization. Lower values mean more consistent connectivity pattern cross subjects. 3.3 Consistency between optimization of functional profiles and structural profiles Fig.8. Optimization consistency between functional and structural profiles. Top: Functional profile energy drop along with structural profile optimization; Bottom: Structural profile energy drop along with functional profile optimization. Each experiment was repeated 15 times with random initial ROI locations that met the anatomical constraint. The relationship between structure and function has been extensively studied [24], and it is widely believed that they are closely related. In this section, we study the relationship between functional profiles and structural profiles by looking at how the energy for one of them changes while the energy of the other decreases. The optimization processes in Section 3.1 and 3.2 were repeated 15 times respectively with random initial ROI locations that met the anatomical constraint. As shown in Fig.8, in general, the functional profile energies and structural profile energies are closely related in such a way that the functional profile energies tend to decrease along with the structural profile optimization process, while the structural profile energies also tend to decrease as the functional profile is optimized. This positively correlated decrease of functional profile energy and structural profile energy not only proves the close relationship between functional and structural profiles, but also demonstrates the consistency between functional and structural optimization, laying down the foundation of the joint optimiza tion, whose results are detailed in the following section. 3.4 Optimization connectivity profiles using anatomical, structural and functional In this section, we used all the constraints in Eq. (1) to optimize the individual locations of all ROIs in the working memory system. Ten runs of the optimization were performed using random initial ROI locations that met the anatomical constraint. Weighting parameter ď Ź equaled 0.5 for all these runs. Starting and ending temperatures for the simulated annealing algorithm are 8 and 0.05; Boltzmann constant K ď&euro;˝ 1 . As we can see from Fig.9, most runs started to converge at step 24, and the convergence energy is quite close for all runs. This indicates that the simulated annealing algorithm provides a valid solution to our problem. By visual inspection, most of the ROIs move to more reasonable and consistent locations after the joint optimization. As an example, Fig.10 depicts the location movements of the ROI in Fig. 6 for eight subjects. As we can see, the ROIs for these subjects share a similar anatomical landmark, which appears to be the tip of the upper bank of the parieto-occipital sulcus. If the initial ROI was not at this landmark, it moved to the landmark after the optimization, which was the case for subjects 1, 4 and 7. The structural profiles of these ROIs are very similar to Fig.6. The results in Fig. 10 indicate the significant improvement of ROI locations achieved by the joint optimization procedure. Fig.9. Convergence performance of the simulated annealing . Each run has 28 temperature conditions. Fig.10. The movement of right precuneus before (in red sphere) and after (in green sphere) optimization for eight subjects. The</p><p>4 0.92400515 <a title="44-lsi-4" href="./nips-2010-Infinite_Relational_Modeling_of_Functional_Connectivity_in_Resting_State_fMRI.html">128 nips-2010-Infinite Relational Modeling of Functional Connectivity in Resting State fMRI</a></p>
<p>Author: Morten Mørup, Kristoffer Madsen, Anne-marie Dogonowski, Hartwig Siebner, Lars K. Hansen</p><p>Abstract: Functional magnetic resonance imaging (fMRI) can be applied to study the functional connectivity of the neural elements which form complex network at a whole brain level. Most analyses of functional resting state networks (RSN) have been based on the analysis of correlation between the temporal dynamics of various regions of the brain. While these models can identify coherently behaving groups in terms of correlation they give little insight into how these groups interact. In this paper we take a different view on the analysis of functional resting state networks. Starting from the deﬁnition of resting state as functional coherent groups we search for functional units of the brain that communicate with other parts of the brain in a coherent manner as measured by mutual information. We use the inﬁnite relational model (IRM) to quantify functional coherent groups of resting state networks and demonstrate how the extracted component interactions can be used to discriminate between functional resting state activity in multiple sclerosis and normal subjects. 1</p><p>5 0.71327037 <a title="44-lsi-5" href="./nips-2010-Spatial_and_anatomical_regularization_of_SVM_for_brain_image_analysis.html">249 nips-2010-Spatial and anatomical regularization of SVM for brain image analysis</a></p>
<p>Author: Remi Cuingnet, Marie Chupin, Habib Benali, Olivier Colliot</p><p>Abstract: Support vector machines (SVM) are increasingly used in brain image analyses since they allow capturing complex multivariate relationships in the data. Moreover, when the kernel is linear, SVMs can be used to localize spatial patterns of discrimination between two groups of subjects. However, the features’ spatial distribution is not taken into account. As a consequence, the optimal margin hyperplane is often scattered and lacks spatial coherence, making its anatomical interpretation difﬁcult. This paper introduces a framework to spatially regularize SVM for brain image analysis. We show that Laplacian regularization provides a ﬂexible framework to integrate various types of constraints and can be applied to both cortical surfaces and 3D brain images. The proposed framework is applied to the classiﬁcation of MR images based on gray matter concentration maps and cortical thickness measures from 30 patients with Alzheimer’s disease and 30 elderly controls. The results demonstrate that the proposed method enables natural spatial and anatomical regularization of the classiﬁer. 1</p><p>6 0.4773975 <a title="44-lsi-6" href="./nips-2010-Decoding_Ipsilateral_Finger_Movements_from_ECoG_Signals_in_Humans.html">57 nips-2010-Decoding Ipsilateral Finger Movements from ECoG Signals in Humans</a></p>
<p>7 0.43109182 <a title="44-lsi-7" href="./nips-2010-Epitome_driven_3-D_Diffusion_Tensor_image_segmentation%3A_on_extracting_specific_structures.html">77 nips-2010-Epitome driven 3-D Diffusion Tensor image segmentation: on extracting specific structures</a></p>
<p>8 0.3836771 <a title="44-lsi-8" href="./nips-2010-Over-complete_representations_on_recurrent_neural_networks_can_support_persistent_percepts.html">200 nips-2010-Over-complete representations on recurrent neural networks can support persistent percepts</a></p>
<p>9 0.38279888 <a title="44-lsi-9" href="./nips-2010-Inferring_Stimulus_Selectivity_from_the_Spatial_Structure_of_Neural_Network_Dynamics.html">127 nips-2010-Inferring Stimulus Selectivity from the Spatial Structure of Neural Network Dynamics</a></p>
<p>10 0.34316689 <a title="44-lsi-10" href="./nips-2010-Accounting_for_network_effects_in_neuronal_responses_using_L1_regularized_point_process_models.html">21 nips-2010-Accounting for network effects in neuronal responses using L1 regularized point process models</a></p>
<p>11 0.34240934 <a title="44-lsi-11" href="./nips-2010-Subgraph_Detection_Using_Eigenvector_L1_Norms.html">259 nips-2010-Subgraph Detection Using Eigenvector L1 Norms</a></p>
<p>12 0.32064331 <a title="44-lsi-12" href="./nips-2010-Hallucinations_in_Charles_Bonnet_Syndrome_Induced_by_Homeostasis%3A_a_Deep_Boltzmann_Machine_Model.html">111 nips-2010-Hallucinations in Charles Bonnet Syndrome Induced by Homeostasis: a Deep Boltzmann Machine Model</a></p>
<p>13 0.30319366 <a title="44-lsi-13" href="./nips-2010-Identifying_graph-structured_activation_patterns_in_networks.html">117 nips-2010-Identifying graph-structured activation patterns in networks</a></p>
<p>14 0.30131668 <a title="44-lsi-14" href="./nips-2010-Block_Variable_Selection_in_Multivariate_Regression_and_High-dimensional_Causal_Inference.html">41 nips-2010-Block Variable Selection in Multivariate Regression and High-dimensional Causal Inference</a></p>
<p>15 0.29898572 <a title="44-lsi-15" href="./nips-2010-Link_Discovery_using_Graph_Feature_Tracking.html">162 nips-2010-Link Discovery using Graph Feature Tracking</a></p>
<p>16 0.29425284 <a title="44-lsi-16" href="./nips-2010-Short-term_memory_in_neuronal_networks_through_dynamical_compressed_sensing.html">238 nips-2010-Short-term memory in neuronal networks through dynamical compressed sensing</a></p>
<p>17 0.28789094 <a title="44-lsi-17" href="./nips-2010-Stability_Approach_to_Regularization_Selection_%28StARS%29_for_High_Dimensional_Graphical_Models.html">254 nips-2010-Stability Approach to Regularization Selection (StARS) for High Dimensional Graphical Models</a></p>
<p>18 0.28630894 <a title="44-lsi-18" href="./nips-2010-Estimation_of_Renyi_Entropy_and_Mutual_Information_Based_on_Generalized_Nearest-Neighbor_Graphs.html">80 nips-2010-Estimation of Renyi Entropy and Mutual Information Based on Generalized Nearest-Neighbor Graphs</a></p>
<p>19 0.2859191 <a title="44-lsi-19" href="./nips-2010-Linear_readout_from_a_neural_population_with_partial_correlation_data.html">161 nips-2010-Linear readout from a neural population with partial correlation data</a></p>
<p>20 0.27376661 <a title="44-lsi-20" href="./nips-2010-Penalized_Principal_Component_Regression_on_Graphs_for_Analysis_of_Subnetworks.html">204 nips-2010-Penalized Principal Component Regression on Graphs for Analysis of Subnetworks</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.044), (17, 0.019), (27, 0.208), (30, 0.046), (35, 0.061), (45, 0.186), (50, 0.053), (51, 0.171), (52, 0.04), (60, 0.016), (77, 0.04), (78, 0.01), (90, 0.036)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.86190379 <a title="44-lda-1" href="./nips-2010-Brain_covariance_selection%3A_better_individual_functional_connectivity_models_using_population_prior.html">44 nips-2010-Brain covariance selection: better individual functional connectivity models using population prior</a></p>
<p>Author: Gael Varoquaux, Alexandre Gramfort, Jean-baptiste Poline, Bertrand Thirion</p><p>Abstract: Spontaneous brain activity, as observed in functional neuroimaging, has been shown to display reproducible structure that expresses brain architecture and carries markers of brain pathologies. An important view of modern neuroscience is that such large-scale structure of coherent activity reﬂects modularity properties of brain connectivity graphs. However, to date, there has been no demonstration that the limited and noisy data available in spontaneous activity observations could be used to learn full-brain probabilistic models that generalize to new data. Learning such models entails two main challenges: i) modeling full brain connectivity is a difﬁcult estimation problem that faces the curse of dimensionality and ii) variability between subjects, coupled with the variability of functional signals between experimental runs, makes the use of multiple datasets challenging. We describe subject-level brain functional connectivity structure as a multivariate Gaussian process and introduce a new strategy to estimate it from group data, by imposing a common structure on the graphical model in the population. We show that individual models learned from functional Magnetic Resonance Imaging (fMRI) data using this population prior generalize better to unseen data than models based on alternative regularization schemes. To our knowledge, this is the ﬁrst report of a cross-validated model of spontaneous brain activity. Finally, we use the estimated graphical model to explore the large-scale characteristics of functional architecture and show for the ﬁrst time that known cognitive networks appear as the integrated communities of functional connectivity graph. 1</p><p>2 0.84505552 <a title="44-lda-2" href="./nips-2010-Bayesian_Action-Graph_Games.html">39 nips-2010-Bayesian Action-Graph Games</a></p>
<p>Author: Albert X. Jiang, Kevin Leyton-brown</p><p>Abstract: Games of incomplete information, or Bayesian games, are an important gametheoretic model and have many applications in economics. We propose Bayesian action-graph games (BAGGs), a novel graphical representation for Bayesian games. BAGGs can represent arbitrary Bayesian games, and furthermore can compactly express Bayesian games exhibiting commonly encountered types of structure including symmetry, action- and type-speciﬁc utility independence, and probabilistic independence of type distributions. We provide an algorithm for computing expected utility in BAGGs, and discuss conditions under which the algorithm runs in polynomial time. Bayes-Nash equilibria of BAGGs can be computed by adapting existing algorithms for complete-information normal form games and leveraging our expected utility algorithm. We show both theoretically and empirically that our approaches improve signiﬁcantly on the state of the art. 1</p><p>3 0.84481734 <a title="44-lda-3" href="./nips-2010-Improving_Human_Judgments_by_Decontaminating_Sequential_Dependencies.html">121 nips-2010-Improving Human Judgments by Decontaminating Sequential Dependencies</a></p>
<p>Author: Harold Pashler, Matthew Wilder, Robert Lindsey, Matt Jones, Michael C. Mozer, Michael P. Holmes</p><p>Abstract: For over half a century, psychologists have been struck by how poor people are at expressing their internal sensations, impressions, and evaluations via rating scales. When individuals make judgments, they are incapable of using an absolute rating scale, and instead rely on reference points from recent experience. This relativity of judgment limits the usefulness of responses provided by individuals to surveys, questionnaires, and evaluation forms. Fortunately, the cognitive processes that transform internal states to responses are not simply noisy, but rather are inﬂuenced by recent experience in a lawful manner. We explore techniques to remove sequential dependencies, and thereby decontaminate a series of ratings to obtain more meaningful human judgments. In our formulation, decontamination is fundamentally a problem of inferring latent states (internal sensations) which, because of the relativity of judgment, have temporal dependencies. We propose a decontamination solution using a conditional random ﬁeld with constraints motivated by psychological theories of relative judgment. Our exploration of decontamination models is supported by two experiments we conducted to obtain ground-truth rating data on a simple length estimation task. Our decontamination techniques yield an over 20% reduction in the error of human judgments. 1</p><p>4 0.84123087 <a title="44-lda-4" href="./nips-2010-The_Maximal_Causes_of_Natural_Scenes_are_Edge_Filters.html">266 nips-2010-The Maximal Causes of Natural Scenes are Edge Filters</a></p>
<p>Author: Jose Puertas, Joerg Bornschein, Joerg Luecke</p><p>Abstract: We study the application of a strongly non-linear generative model to image patches. As in standard approaches such as Sparse Coding or Independent Component Analysis, the model assumes a sparse prior with independent hidden variables. However, in the place where standard approaches use the sum to combine basis functions we use the maximum. To derive tractable approximations for parameter estimation we apply a novel approach based on variational Expectation Maximization. The derived learning algorithm can be applied to large-scale problems with hundreds of observed and hidden variables. Furthermore, we can infer all model parameters including observation noise and the degree of sparseness. In applications to image patches we ﬁnd that Gabor-like basis functions are obtained. Gabor-like functions are thus not a feature exclusive to approaches assuming linear superposition. Quantitatively, the inferred basis functions show a large diversity of shapes with many strongly elongated and many circular symmetric functions. The distribution of basis function shapes reﬂects properties of simple cell receptive ﬁelds that are not reproduced by standard linear approaches. In the study of natural image statistics, the implications of using different superposition assumptions have so far not been investigated systematically because models with strong non-linearities have been found analytically and computationally challenging. The presented algorithm represents the ﬁrst large-scale application of such an approach. 1</p><p>5 0.84019691 <a title="44-lda-5" href="./nips-2010-Evaluating_neuronal_codes_for_inference_using_Fisher_information.html">81 nips-2010-Evaluating neuronal codes for inference using Fisher information</a></p>
<p>Author: Haefner Ralf, Matthias Bethge</p><p>Abstract: Many studies have explored the impact of response variability on the quality of sensory codes. The source of this variability is almost always assumed to be intrinsic to the brain. However, when inferring a particular stimulus property, variability associated with other stimulus attributes also effectively act as noise. Here we study the impact of such stimulus-induced response variability for the case of binocular disparity inference. We characterize the response distribution for the binocular energy model in response to random dot stereograms and ﬁnd it to be very different from the Poisson-like noise usually assumed. We then compute the Fisher information with respect to binocular disparity, present in the monocular inputs to the standard model of early binocular processing, and thereby obtain an upper bound on how much information a model could theoretically extract from them. Then we analyze the information loss incurred by the different ways of combining those inputs to produce a scalar single-neuron response. We ﬁnd that in the case of depth inference, monocular stimulus variability places a greater limit on the extractable information than intrinsic neuronal noise for typical spike counts. Furthermore, the largest loss of information is incurred by the standard model for position disparity neurons (tuned-excitatory), that are the most ubiquitous in monkey primary visual cortex, while more information from the inputs is preserved in phase-disparity neurons (tuned-near or tuned-far) primarily found in higher cortical regions. 1</p><p>6 0.83880621 <a title="44-lda-6" href="./nips-2010-Linear_readout_from_a_neural_population_with_partial_correlation_data.html">161 nips-2010-Linear readout from a neural population with partial correlation data</a></p>
<p>7 0.83563894 <a title="44-lda-7" href="./nips-2010-Infinite_Relational_Modeling_of_Functional_Connectivity_in_Resting_State_fMRI.html">128 nips-2010-Infinite Relational Modeling of Functional Connectivity in Resting State fMRI</a></p>
<p>8 0.83361262 <a title="44-lda-8" href="./nips-2010-Deterministic_Single-Pass_Algorithm_for_LDA.html">60 nips-2010-Deterministic Single-Pass Algorithm for LDA</a></p>
<p>9 0.82523906 <a title="44-lda-9" href="./nips-2010-Accounting_for_network_effects_in_neuronal_responses_using_L1_regularized_point_process_models.html">21 nips-2010-Accounting for network effects in neuronal responses using L1 regularized point process models</a></p>
<p>10 0.82076079 <a title="44-lda-10" href="./nips-2010-Functional_Geometry_Alignment_and_Localization_of_Brain_Areas.html">97 nips-2010-Functional Geometry Alignment and Localization of Brain Areas</a></p>
<p>11 0.81067318 <a title="44-lda-11" href="./nips-2010-Implicit_encoding_of_prior_probabilities_in_optimal_neural_populations.html">119 nips-2010-Implicit encoding of prior probabilities in optimal neural populations</a></p>
<p>12 0.80859679 <a title="44-lda-12" href="./nips-2010-A_Discriminative_Latent_Model_of_Image_Region_and_Object_Tag_Correspondence.html">6 nips-2010-A Discriminative Latent Model of Image Region and Object Tag Correspondence</a></p>
<p>13 0.80713612 <a title="44-lda-13" href="./nips-2010-Functional_form_of_motion_priors_in_human_motion_perception.html">98 nips-2010-Functional form of motion priors in human motion perception</a></p>
<p>14 0.80352825 <a title="44-lda-14" href="./nips-2010-Individualized_ROI_Optimization_via_Maximization_of_Group-wise_Consistency_of_Structural_and_Functional_Profiles.html">123 nips-2010-Individualized ROI Optimization via Maximization of Group-wise Consistency of Structural and Functional Profiles</a></p>
<p>15 0.7969619 <a title="44-lda-15" href="./nips-2010-Online_Learning_for_Latent_Dirichlet_Allocation.html">194 nips-2010-Online Learning for Latent Dirichlet Allocation</a></p>
<p>16 0.7969569 <a title="44-lda-16" href="./nips-2010-The_Neural_Costs_of_Optimal_Control.html">268 nips-2010-The Neural Costs of Optimal Control</a></p>
<p>17 0.78761911 <a title="44-lda-17" href="./nips-2010-A_biologically_plausible_network_for_the_computation_of_orientation_dominance.html">17 nips-2010-A biologically plausible network for the computation of orientation dominance</a></p>
<p>18 0.78710926 <a title="44-lda-18" href="./nips-2010-Over-complete_representations_on_recurrent_neural_networks_can_support_persistent_percepts.html">200 nips-2010-Over-complete representations on recurrent neural networks can support persistent percepts</a></p>
<p>19 0.78560889 <a title="44-lda-19" href="./nips-2010-Inferring_Stimulus_Selectivity_from_the_Spatial_Structure_of_Neural_Network_Dynamics.html">127 nips-2010-Inferring Stimulus Selectivity from the Spatial Structure of Neural Network Dynamics</a></p>
<p>20 0.77896196 <a title="44-lda-20" href="./nips-2010-Deciphering_subsampled_data%3A_adaptive_compressive_sampling_as_a_principle_of_brain_communication.html">56 nips-2010-Deciphering subsampled data: adaptive compressive sampling as a principle of brain communication</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
