<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>163 nips-2010-Lower Bounds on Rate of Convergence of Cutting Plane Methods</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-163" href="#">nips2010-163</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>163 nips-2010-Lower Bounds on Rate of Convergence of Cutting Plane Methods</h1>
<br/><p>Source: <a title="nips-2010-163-pdf" href="http://papers.nips.cc/paper/4144-lower-bounds-on-rate-of-convergence-of-cutting-plane-methods.pdf">pdf</a></p><p>Author: Xinhua Zhang, Ankan Saha, S.v.n. Vishwanathan</p><p>Abstract: In a recent paper Joachims [1] presented SVM-Perf, a cutting plane method (CPM) for training linear Support Vector Machines (SVMs) which converges to an accurate solution in O(1/ 2 ) iterations. By tightening the analysis, Teo et al. [2] showed that O(1/ ) iterations sufﬁce. Given the impressive convergence speed of CPM on a number of practical problems, it was conjectured that these rates could be further improved. In this paper we disprove this conjecture. We present counter examples which are not only applicable for training linear SVMs with hinge loss, but also hold for support vector methods which optimize a multivariate performance score. However, surprisingly, these problems are not inherently hard. By exploiting the structure of the objective function we can devise an algo√ rithm that converges in O(1/ ) iterations. 1</p><p>Reference: <a title="nips-2010-163-reference" href="../nips2010_reference/nips-2010-Lower_Bounds_on_Rate_of_Convergence_of_Cutting_Plane_Methods_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract In a recent paper Joachims [1] presented SVM-Perf, a cutting plane method (CPM) for training linear Support Vector Machines (SVMs) which converges to an accurate solution in O(1/ 2 ) iterations. [sent-13, score-0.158]
</p><p>2 Given the impressive convergence speed of CPM on a number of practical problems, it was conjectured that these rates could be further improved. [sent-16, score-0.102]
</p><p>3 We present counter examples which are not only applicable for training linear SVMs with hinge loss, but also hold for support vector methods which optimize a multivariate performance score. [sent-18, score-0.103]
</p><p>4 At the heart of SVMs is the following regularized risk minimization problem: n λ 1 2 min J(w) := w + Remp (w) with Remp (w) := max(0, 1 − yi w, xi ). [sent-23, score-0.315]
</p><p>5 (1) w 2 n i=1 regularizer  empirical risk  Here we assume access to a training set of n labeled examples {(xi , yi )}n where xi ∈ Rd and yi ∈ i=1 2 2 {−1, +1}, and use the square Euclidean norm w = i wi as the regularizer. [sent-24, score-0.458]
</p><p>6 There has been signiﬁcant research devoted to developing specialized optimizers which minimize J(w) efﬁciently. [sent-26, score-0.072]
</p><p>7 In an award winning paper, Joachims [1] presented a cutting plane method (CPM)1 , SVM-Perf, which was shown to converge to an accurate solution of (1) in O(1/ 2 ) iterations, with each iteration requiring O(nd) effort. [sent-27, score-0.25]
</p><p>8 , yn ) and a candidate ¯ labeling y (to be concretized later), the Remp for the multivariate measure is formulated by [3] as 1 In this paper we use the term cutting plane methods to denote specialized solvers employed in machine learning. [sent-35, score-0.234]
</p><p>9 While clearly related, they must not be confused with cutting plane methods used in optimization. [sent-36, score-0.119]
</p><p>10 1  Remp (w) =  max  ¯ y∈{−1,1}n  ¯ ∆(y, y) +  1 n  n  w, xi (¯i − yi ) . [sent-37, score-0.188]
</p><p>11 y  (2)  i=1  In another award winning paper by Joachims [3], the regularized risk minimization problems corresponding to these measures are optimized by using a CPM. [sent-38, score-0.127]
</p><p>12 Given the widespread use of CPM in machine learning, it is important to understand their convergence guarantees in terms of the upper and lower bounds on the number of iterations needed to converge to an accurate solution. [sent-39, score-0.376]
</p><p>13 The tightest, O(1/ ), upper bounds on the convergence speed of CPM is due to Teo et al. [sent-40, score-0.188]
</p><p>14 Therefore, it had been conjectured that the upper bounds might be further tightened via a more reﬁned analysis. [sent-43, score-0.225]
</p><p>15 In this paper we construct counter examples for both decomposable Remp like in equation (1) and non-decomposable Remp like in equation (2), on which CPM requires Ω(1/ ) iterations to converge, thus disproving this conjecture2 . [sent-44, score-0.092]
</p><p>16 Our results lead to the following natural question: Do the lower bounds hold because regularized risk minimization problems are fundamentally hard, or is it an inherent limitation of CPM? [sent-48, score-0.269]
</p><p>17 To understand our contribution one needs to understand the two standard assumptions that are made when proving convergence rates: • A1: The data points xi lie inside a L2 (Euclidean) ball of radius R, that is, xi ≤ R. [sent-51, score-0.152]
</p><p>18 Finding a fast optimizer under assumption A2 remains an open problem. [sent-57, score-0.14]
</p><p>19 , w, µ) denote vectors, wi denotes the i-th component of w, 0 refers to the vector with all zero components, ei is the i-th coordinate vector (all 0’s except 1 at the i-th coordinate) and ∆k refers to the k dimensional simplex. [sent-60, score-0.142]
</p><p>20 Unless speciﬁed otherwise, ·, · denotes the Euclidean dot product x, w = i xi wi , and · refers to the Euclidean norm 1/2 w := ( w, w ) . [sent-61, score-0.134]
</p><p>21 Two types of lower bounds are subsequently deﬁned in Section 3, and Section 4 contains descriptions of various counter examples that we construct. [sent-68, score-0.222]
</p><p>22 In Section 5 we describe an algorithm which provably converges to an √ accurate solution of (1) in O(1/ ) iterations under assumption A1. [sent-69, score-0.108]
</p><p>23 2  BMRM  cp At every iteration, BMRM replaces Remp by a piecewise linear lower bound Rk and optimizes [2] λ cp cp min Jk (w) := w 2 + Rk (w), where Rk (w) := max w, ai + bi , (3) w 1≤i≤k 2  to obtain the next iterate wk . [sent-72, score-0.761]
</p><p>24 Here ai ∈ ∂Remp (wi−1 ) denotes an arbitrary subgradient of Remp at wi−1 and bi = Remp (wi−1 ) − wi−1 , ai . [sent-73, score-0.257]
</p><p>25 The piecewise linear lower bound is successively tightened until the gap (4) k := min J(wt ) − Jk (wk ) 0≤t≤k falls below a predeﬁned tolerance . [sent-74, score-0.188]
</p><p>26 1 2: αk ← argmax − 2λ Ak α  2  + α, bk  Require: Previous subgradients {ai }i=1 and k intercepts {bi }i=1 . [sent-87, score-0.183]
</p><p>27 Note that Ak and bk in (5) are deﬁned in Algorithm 1. [sent-102, score-0.089]
</p><p>28 Note that at iteration k the dual Dk (α) is a QP with k variables. [sent-105, score-0.078]
</p><p>29 Then for any < 4G2 /λ, both ls-bmrm and qpbmrm converge to an accurate solution of (1) as measured by (4) after at most the following number of steps: λJ(0) 8G2 + − 1. [sent-112, score-0.076]
</p><p>30 3  Upper and Lower Bounds  Since most rates of convergence discussed in the machine learning community are upper bounds, it is important to rigorously deﬁne the meaning of a lower bound with respect to , and to study its relationship with the upper bounds. [sent-118, score-0.247]
</p><p>31 Instead of minimizing the objective function J(w) deﬁned in (1), if we minimize a scaled version cJ(w) this scales the approximation gap (4) by c. [sent-120, score-0.087]
</p><p>32 Deﬁne T ( ; f, A) as the ﬁrst step index k when wk becomes an accurate solution3 : T ( ; f, A) = min {k : f (wk ) − minw f (w) ≤ } . [sent-123, score-0.567]
</p><p>33 (6) Upper and lower bounds are both properties for a pair of F and A. [sent-124, score-0.171]
</p><p>34 A function g( ) is called an upper bound of (F, A) if for all functions f ∈ F and all > 0, it takes at most order g( ) steps for A to reduce the gap to less than , i. [sent-125, score-0.139]
</p><p>35 (7) On the other hand, lower bounds can be deﬁned in two different ways depending on how the above two universal qualiﬁers are ﬂipped to existential qualiﬁers. [sent-128, score-0.171]
</p><p>36 3  Algorithms ls-bmrm qp-bmrm Nesterov  UB  Assuming A1 SLB  Assuming A2 UB SLB WLB  WLB  O(1/ ) O(1/ ) √ O(1/ )  Ω(1/ ) open √ Ω(1/ )  Ω(1/ ) open √ Ω(1/ )  O(1/ ) O(1/ ) n/a  Ω(1/ ) open n/a  Ω(1/ ) Ω(1/ ) n/a  Table 1: Summary of the known upper bounds and our lower bounds. [sent-132, score-0.366]
</p><p>37 ˜ • Strong lower bounds (SLB) h( ) is called a SLB of (F, A) if there exists a function f ∈ F, ˜ such that for all > 0 it takes at least h( ) steps for A to ﬁnd an accurate solution of f : ˜ ˜ (SLB) ∃ f ∈ F, s. [sent-136, score-0.244]
</p><p>38 (8) • Weak lower bound (WLB) h( ) is called a WLB of (F, A) if for any > 0, there exists a function f ∈ F depending on , such that it takes at least h( ) steps for A to ﬁnd an accurate solution of f : (WLB) ∀ > 0, ∃ f ∈ F, s. [sent-139, score-0.144]
</p><p>39 Fortunately, WLBs are sufﬁcient to refute upper bounds or to establish their tightness. [sent-144, score-0.154]
</p><p>40 The size of the function class F affects the upper and lower bounds in opposite ways. [sent-145, score-0.225]
</p><p>41 lower) bounds on (F , A) is usually easier (resp. [sent-148, score-0.1]
</p><p>42 4  Constructing Lower Bounds  Letting the minimizer of J(w) be w∗ , we are interested in bounding the primal gap of the iterates wk : J(wk ) − J(w∗ ). [sent-151, score-0.611]
</p><p>43 Datasets will be constructed explicitly whose resulting objective J(w) will be shown to attain the lower bounds of the algorithms. [sent-152, score-0.207]
</p><p>44 1  Strong Lower Bounds for Solving Linear SVMs using ls-bmrm  We ﬁrst prove the Ω(1/ ) lower bound for ls-bmrm on SVM problems under assumption A1. [sent-156, score-0.099]
</p><p>45 Setting λ = 16 , the regularized risk (1) can be written as (using w instead of w as it is now a scalar): min J(w) = w∈R  1 2 1 w w + 1− 32 2 2  + +  1 [1 − w]+ . [sent-158, score-0.127]
</p><p>46 These recursive relations allow us to derive the convergence rate of α2k−1,1 and wk (see proof in [7, Appendix C]): Lemma 4 limk→∞ kα2k−1,1 = 1 . [sent-169, score-0.529]
</p><p>47 Combining with (11), we get limk→∞ k|2 − wk | = 2. [sent-170, score-0.442]
</p><p>48 4 Now that wk approaches 2 at the rate of O(1/k), it is ﬁnally straightforward to translate it into the rate at which J(wk ) approaches J(w∗ ). [sent-171, score-0.494]
</p><p>49 2  Weak Lower Bounds for Solving Linear SVMs using qp-bmrm  Theorem 1 gives an upper bound on the convergence rate of qp-bmrm, assuming that Remp satisﬁes the assumption A2. [sent-174, score-0.142]
</p><p>50 In this section we further demonstrate that this O(1/ ) rate is also a WLB (hence tight) even when the Remp is specialized to SVM objectives satisfying A2. [sent-175, score-0.091]
</p><p>51 n  Given > 0, deﬁne n = 1/ and construct a dataset {(xi , yi )}i=1 as yi = (−1)i and xi = √ (−1)i (nei+1 + ne1 ) ∈ Rn+1 . [sent-176, score-0.331]
</p><p>52 Then the corresponding objective function (1) is J(w) =  w 2  n  2  +Remp (w), where Remp (w) =  n  √ 1 1 [1−yi w, xi ]+ = [1− nw1 −nwi+1 ]+ . [sent-177, score-0.081]
</p><p>53 , n ) and J(w∗ ) = 2  check that yi w∗ , xi = 1, so ∂J(w∗ ) = setting all αi =  1 2n  w∗ −  1 √ n  n i=1  αi , α1 , . [sent-181, score-0.188]
</p><p>54 Suppose running qp-bmrm on the objective function (13) 2 produces iterates w1 , . [sent-191, score-0.078]
</p><p>55 Then it takes qp-bmrm at least 3 steps to ﬁnd an accurate solution. [sent-198, score-0.073]
</p><p>56 2k 4n 3 i∈[k] i∈[k]  Indeed, after taking n steps, wn will cut a subgradient an+1 = 0 and bn+1 = 0, and then the minimizer of Jn+1 (w) gives exactly w∗ . [sent-200, score-0.144]
</p><p>57 n  ,  n i=1  −1 n  Proof Since Remp (w0 ) = 0 and ∂Remp (w0 ) =  αi yi xi : αi ∈ [0, 1] , we can choose  b1 = Remp (w0 ) − a1 , w0 = 0 +  1 1 = , and n n  1 1 1 1 2 w − √ w1 − w2 + = √ , 1, 0, . [sent-204, score-0.188]
</p><p>58 2 n n n In general, we claim that the k-th iterate wk produced by qp-bmrm is given by w1 = argmin w  k copies  1 1 1 √ , , . [sent-208, score-0.579]
</p><p>59 , k, then it is n easy to check that Remp (wk ) = 0 and ∂Remp (wk ) = −1 i=k+1 αi yi xi : αi ∈ [0, 1] . [sent-219, score-0.188]
</p><p>60 Thus we n can again choose 1 1 ak+1 = − yk+1 xk+1 , and bk+1 = Remp (wk ) − ak+1 , wk = , so n n wk =  k+1 copies  wk+1 = argmin w  1 w 2  2  + max { ai , w + bi } 1≤i≤k+1  =  1 1 1 √ , ,. [sent-220, score-1.109]
</p><p>61 1 2k  5  +  1 2n  while J(w  ∗  i∈[k+1] αi ai 1 ) = 4n from  ,  : α ∈ ∆k+1 which it follows  √ As an aside, the subgradient of the Remp in (13) does have Euclidean norm 2n at w = 0. [sent-228, score-0.143]
</p><p>62 In fact, having a bounded subgradient of Remp at all wk is sufﬁcient for qp-bmrm to converge at the rate in Theorem 1. [sent-235, score-0.576]
</p><p>63 However when we assume A1 which is more restrictive than A2, it remains an open question to determine whether the O(1/ ) rates are optimal for qp-bmrm on SVM objectives. [sent-236, score-0.133]
</p><p>64 y n Given > 0, deﬁne n = 1/ +1 and construct a dataset {(xi , yi )}i=1 as n follows: xi = − 2√3 e1 − n ei+1 ∈ Rn+1 with yi = −1 for all i ∈ [n−1], 2  y =1 ¯ y = −1 ¯  √  3n and xn = 2 e1 + n en+1 ∈ Rn+1 with yn = +1. [sent-240, score-0.359]
</p><p>65 Then the corresponding objective function is  J(w) =  1 w 2  2  ¯ + max 1 − F1 (y, y) + ¯ y  1 n  yi w, xi (yi yi − 1) . [sent-242, score-0.367]
</p><p>66 Then qp-bmrm takes at least 1 3 3  w  y = 1 y = −1 a b c d  (14)  steps to ﬁnd an accurate solution. [sent-245, score-0.073]
</p><p>67 Then at step k + 1 we have  1   1 + 2k if i ∈ [k] 6 1 y i wk , x i = 1 if k + 1 ≤ i ≤ n − 1 . [sent-260, score-0.442]
</p><p>68 6 n 1  if i = n wk =  (15)  (16)  2  For convenience, deﬁne the term in the max in (14) as ¯ Υk (¯ ) := 1 − F1 (y, y) + y  1 n  n  yi wk , xi (yi yi − 1). [sent-261, score-1.215]
</p><p>69 If y misclassiﬁes the positive training example, ¯ then F1 (y, y) = 0 and by (16) we have n−1  Υk (¯ ) = 1−0 + y  k  1 1 k+3 1 yi wk , xi (yi yi −1)+ (−1−1) = ¯ (yi yi −1)+ ¯ n i=1 2 6k i=1 6  n−1  (yi yi −1) ≤ 0. [sent-270, score-1.059]
</p><p>70 Then F1 (y, y) = 2+t2+t2 , and 1 Υk (¯ ) = 1 − y =  2 + 2 + t1 + t2  t1 + t2 − 2 + t1 + t2  1 1 + 6 2k  1 1 + 3 k  k  (yi yi − 1) + ¯ i=1  1 6  n−1  (yi yi − 1) ¯ i=k+1  1 t − t2 t1 − t2 ≤ ≤0 3 3(2 + t) 6  (t := t1 + t2 ). [sent-278, score-0.286]
</p><p>71 k copies  n−k−1 copies  ¯ So we can pick y as (−1, . [sent-279, score-0.15]
</p><p>72 , −1, +1) which only misclassiﬁes xk+1 , and get ak+1 =  −2 1 yk+1 xk+1 = − √ e1 − ek+2 , n 3  bk+1 = Remp (wk ) − ak+1 , wk = 0 +  :=Jk+1 (w)  wk+1 = argmin w  1 w 2  2  αi =  1 k+1 ). [sent-285, score-0.478]
</p><p>73 k+1 copies  + max { ai , w + bi } = i∈[k+1]  which can be veriﬁed by ∂Jk+1 (wk+1 ) =  1 1 = , 3 3  wk+1 +  1 1 1 √ , ,. [sent-286, score-0.189]
</p><p>74 1 1 1 All that remains is to observe that J(wk ) = 1 ( 1 + k ) while minw J(w) ≤ J(wn−1 ) = 2 ( 1 + n−1 ) 2 3 3 1 1 1 from which it follows that J(wk ) − minw J(w) ≥ 2 ( k − n−1 ) as claimed in Theorem 6. [sent-295, score-0.139]
</p><p>75 5  √ An O(nd/ ) Algorithm for Training Binary Linear SVMs  The lower bounds we proved above show that CPM such as BMRM require Ω(1/ ) iterations to converge. [sent-296, score-0.212]
</p><p>76 To demonstrate this, we will show that one can devise an algorithm for problems (1) and (2) which √ will converge in O(1/ ) iterations. [sent-298, score-0.072]
</p><p>77 However, thanks to [7, Theorem 7 in Appendix A], the Fenchel dual of (1) is a convex smooth function with a Lipschitz continuous gradient, which are easy to optimize. [sent-300, score-0.088]
</p><p>78 To formalize the idea of using the Fenchel dual, we can abstract from the objectives (1) and (2) a composite form of objective functions used in machine learning with linear models: min J(w) = f (w) + g (Aw),  where Q1 is a closed convex set. [sent-301, score-0.161]
</p><p>79 w∈Q1  (17)  Here, f (w) is a strongly convex function corresponding to the regularizer, Aw stands for the output of a linear model, and g encodes the empirical risk measuring the discrepancy between the correct labels and the output of the linear model. [sent-302, score-0.1]
</p><p>80 , xn ), f (w) = λ w , g (u) = minb∈R n i=1 [1 + ui − yi b]+ which corresponds to 2 g(α) = − i αi . [sent-316, score-0.143]
</p><p>81 Then the adjoint form turns out to be the well known SVM dual objective function: αi −  D(α) = i  1 α Y X XY α, 2λ  α ∈ Q2 = α ∈ [0, n−1 ]n :  yi αi = 0 . [sent-317, score-0.288]
</p><p>82 Denote A as a 2n -by-d matrix where the y-th row is n n 2 1 ¯ ¯ xi (¯i − yi ) for each y ∈ {−1, +1} , f (w) = λ w , g (u) = maxy ∆(y, y) + n uy y ¯ ¯ i=1 2 ¯ ¯ which corresponds to g(α) = −n y ∆(y, y)αy , we recover the primal objective (2) for multi¯ variate performance measure. [sent-319, score-0.264]
</p><p>83 (20) n  In a series of papers [6, 9, 10], Nesterov developed optimal gradient based methods for minimizing the composite objectives with primal (17) and adjoint (18). [sent-321, score-0.157]
</p><p>84 A sequence of wk and αk is produced such that under√ assumption A1 the duality gap J(wk ) − D(αk ) is reduced to less than after at most k = O(1/ ) steps. [sent-322, score-0.521]
</p><p>85 Given a differentiable convex function F on Q2 , a point α, and a direction g, we can deﬁne the Bregman projection as: ¯ ¯ V (α, g) := argmin F (α) − F (α) − g, α . [sent-336, score-0.098]
</p><p>86 Then the application of the algorithm in [9] will endow a distribution over all possible labelings: p(¯ ; w) ∝ exp c∆(¯ , y) + y y ai xi , w yi , where c and ai are constant scalars. [sent-338, score-0.332]
</p><p>87 ¯ (21) i  The solver will request the expectation Ey [ i ai xi yi ] which in turn requires that marginal distri¯ ¯ bution of p(¯i ). [sent-339, score-0.288]
</p><p>88 Fortunately, for multivariate scores deﬁned by contingency tables, it is possible to compute the marginals in O(n2 ) time by using dynamic programming, and this cost is similar to the algorithm proposed by [3]. [sent-341, score-0.115]
</p><p>89 While upper bounds on their rates of convergence were known, lower bounds were not studied before. [sent-345, score-0.393]
</p><p>90 In this paper we set out to ﬁll this gap by exhibiting counter examples in binary classiﬁcation on which CPM require Ω(1/ ) iterations. [sent-346, score-0.102]
</p><p>91 The Ω(1/ ) lower bound is a fundamental lim√ itation of these algorithms and not an artifact of the problem. [sent-348, score-0.096]
</p><p>92 Devising a O(1/ ) algorithm under the less restrictive assumption A2 remains an open problem. [sent-351, score-0.127]
</p><p>93 While the dependence on is still Ω(1/ ) or worse [18], one gets bounds independent of n. [sent-361, score-0.1]
</p><p>94 On the other hand, one can employ coordinate descent in the dual as is done in the Sequential Minimal Optimization (SMO) algorithm of [19]. [sent-363, score-0.079]
</p><p>95 However, as [20] show, if the kernel matrix obtained by stacking xi into a matrix X and X X is not strictly positive deﬁnite, then SMO requires O(n/ ) iterations with each iteration costing O(nd) effort. [sent-364, score-0.112]
</p><p>96 A method for unconstrained convex minimization problem with the rate of convergence O(1/k 2 ). [sent-407, score-0.096]
</p><p>97 Lower bounds on rate of convergence of cutting plane methods (long version). [sent-415, score-0.279]
</p><p>98 An algorithm for singly constrained class of quadratic programs subject to upper and lower bounds. [sent-472, score-0.157]
</p><p>99 New algorithms for singly linearly constrained quadratic programs subject to lower and upper bounds. [sent-478, score-0.157]
</p><p>100 Information-theoretic lower bounds on the oracle complexity of convex optimization. [sent-505, score-0.207]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('remp', 0.523), ('wk', 0.442), ('cpm', 0.294), ('bmrm', 0.258), ('slb', 0.21), ('wlb', 0.168), ('yi', 0.143), ('ak', 0.134), ('bounds', 0.1), ('teo', 0.095), ('svms', 0.089), ('bk', 0.089), ('jk', 0.077), ('copies', 0.075), ('ai', 0.072), ('subgradient', 0.071), ('lower', 0.071), ('cutting', 0.067), ('risk', 0.064), ('ub', 0.063), ('ankan', 0.063), ('contingency', 0.063), ('wi', 0.063), ('joachims', 0.057), ('nesterov', 0.057), ('adjoint', 0.057), ('minw', 0.057), ('xinhua', 0.055), ('upper', 0.054), ('dual', 0.052), ('multivariate', 0.052), ('plane', 0.052), ('counter', 0.051), ('gap', 0.051), ('saha', 0.051), ('quali', 0.051), ('euclidean', 0.049), ('dk', 0.049), ('xk', 0.048), ('limk', 0.048), ('open', 0.047), ('xi', 0.045), ('appendix', 0.043), ('iterates', 0.042), ('intercepts', 0.042), ('bi', 0.042), ('iterations', 0.041), ('optimizer', 0.04), ('primal', 0.04), ('accurate', 0.039), ('wn', 0.037), ('qp', 0.037), ('converge', 0.037), ('misclassify', 0.037), ('optimizers', 0.037), ('tightened', 0.037), ('objective', 0.036), ('argmin', 0.036), ('minimizer', 0.036), ('convex', 0.036), ('cp', 0.035), ('devise', 0.035), ('specialized', 0.035), ('convergence', 0.034), ('steps', 0.034), ('rates', 0.034), ('outlook', 0.034), ('devising', 0.034), ('conjectured', 0.034), ('regularized', 0.034), ('bregman', 0.032), ('singly', 0.032), ('objectives', 0.03), ('composite', 0.03), ('misclassi', 0.029), ('winning', 0.029), ('nemirovski', 0.029), ('min', 0.029), ('yn', 0.028), ('solver', 0.028), ('assumption', 0.028), ('proving', 0.028), ('fenchel', 0.028), ('coordinate', 0.027), ('argmax', 0.027), ('recursive', 0.027), ('restrictive', 0.027), ('refers', 0.026), ('projection', 0.026), ('rate', 0.026), ('aw', 0.026), ('iteration', 0.026), ('claim', 0.026), ('artifact', 0.025), ('subgradients', 0.025), ('smo', 0.025), ('remains', 0.025), ('bundle', 0.024), ('projections', 0.024), ('programming', 0.024)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="163-tfidf-1" href="./nips-2010-Lower_Bounds_on_Rate_of_Convergence_of_Cutting_Plane_Methods.html">163 nips-2010-Lower Bounds on Rate of Convergence of Cutting Plane Methods</a></p>
<p>Author: Xinhua Zhang, Ankan Saha, S.v.n. Vishwanathan</p><p>Abstract: In a recent paper Joachims [1] presented SVM-Perf, a cutting plane method (CPM) for training linear Support Vector Machines (SVMs) which converges to an accurate solution in O(1/ 2 ) iterations. By tightening the analysis, Teo et al. [2] showed that O(1/ ) iterations sufﬁce. Given the impressive convergence speed of CPM on a number of practical problems, it was conjectured that these rates could be further improved. In this paper we disprove this conjecture. We present counter examples which are not only applicable for training linear SVMs with hinge loss, but also hold for support vector methods which optimize a multivariate performance score. However, surprisingly, these problems are not inherently hard. By exploiting the structure of the objective function we can devise an algo√ rithm that converges in O(1/ ) iterations. 1</p><p>2 0.11076254 <a title="163-tfidf-2" href="./nips-2010-Discriminative_Clustering_by_Regularized_Information_Maximization.html">62 nips-2010-Discriminative Clustering by Regularized Information Maximization</a></p>
<p>Author: Andreas Krause, Pietro Perona, Ryan G. Gomes</p><p>Abstract: Is there a principled way to learn a probabilistic discriminative classiﬁer from an unlabeled data set? We present a framework that simultaneously clusters the data and trains a discriminative classiﬁer. We call it Regularized Information Maximization (RIM). RIM optimizes an intuitive information-theoretic objective function which balances class separation, class balance and classiﬁer complexity. The approach can ﬂexibly incorporate different likelihood functions, express prior assumptions about the relative size of different classes and incorporate partial labels for semi-supervised learning. In particular, we instantiate the framework to unsupervised, multi-class kernelized logistic regression. Our empirical evaluation indicates that RIM outperforms existing methods on several real data sets, and demonstrates that RIM is an effective model selection method. 1</p><p>3 0.10394668 <a title="163-tfidf-3" href="./nips-2010-Practical_Large-Scale_Optimization_for_Max-norm_Regularization.html">210 nips-2010-Practical Large-Scale Optimization for Max-norm Regularization</a></p>
<p>Author: Jason Lee, Ben Recht, Nathan Srebro, Joel Tropp, Ruslan Salakhutdinov</p><p>Abstract: The max-norm was proposed as a convex matrix regularizer in [1] and was shown to be empirically superior to the trace-norm for collaborative ﬁltering problems. Although the max-norm can be computed in polynomial time, there are currently no practical algorithms for solving large-scale optimization problems that incorporate the max-norm. The present work uses a factorization technique of Burer and Monteiro [2] to devise scalable ﬁrst-order algorithms for convex programs involving the max-norm. These algorithms are applied to solve huge collaborative ﬁltering, graph cut, and clustering problems. Empirically, the new methods outperform mature techniques from all three areas. 1</p><p>4 0.10355358 <a title="163-tfidf-4" href="./nips-2010-Distributed_Dual_Averaging_In_Networks.html">63 nips-2010-Distributed Dual Averaging In Networks</a></p>
<p>Author: Alekh Agarwal, Martin J. Wainwright, John C. Duchi</p><p>Abstract: The goal of decentralized optimization over a network is to optimize a global objective formed by a sum of local (possibly nonsmooth) convex functions using only local computation and communication. We develop and analyze distributed algorithms based on dual averaging of subgradients, and provide sharp bounds on their convergence rates as a function of the network size and topology. Our analysis clearly separates the convergence of the optimization algorithm itself from the effects of communication constraints arising from the network structure. We show that the number of iterations required by our algorithm scales inversely in the spectral gap of the network. The sharpness of this prediction is conﬁrmed both by theoretical lower bounds and simulations for various networks. 1</p><p>5 0.094590589 <a title="163-tfidf-5" href="./nips-2010-An_Approximate_Inference_Approach_to_Temporal_Optimization_in_Optimal_Control.html">29 nips-2010-An Approximate Inference Approach to Temporal Optimization in Optimal Control</a></p>
<p>Author: Konrad Rawlik, Marc Toussaint, Sethu Vijayakumar</p><p>Abstract: Algorithms based on iterative local approximations present a practical approach to optimal control in robotic systems. However, they generally require the temporal parameters (for e.g. the movement duration or the time point of reaching an intermediate goal) to be speciﬁed a priori. Here, we present a methodology that is capable of jointly optimizing the temporal parameters in addition to the control command proﬁles. The presented approach is based on a Bayesian canonical time formulation of the optimal control problem, with the temporal mapping from canonical to real time parametrised by an additional control variable. An approximate EM algorithm is derived that efﬁciently optimizes both the movement duration and control commands offering, for the ﬁrst time, a practical approach to tackling generic via point problems in a systematic way under the optimal control framework. The proposed approach, which is applicable to plants with non-linear dynamics as well as arbitrary state dependent and quadratic control costs, is evaluated on realistic simulations of a redundant robotic plant.</p><p>6 0.094421141 <a title="163-tfidf-6" href="./nips-2010-More_data_means_less_inference%3A_A_pseudo-max_approach_to_structured_learning.html">169 nips-2010-More data means less inference: A pseudo-max approach to structured learning</a></p>
<p>7 0.094110243 <a title="163-tfidf-7" href="./nips-2010-Smoothness%2C_Low_Noise_and_Fast_Rates.html">243 nips-2010-Smoothness, Low Noise and Fast Rates</a></p>
<p>8 0.088671163 <a title="163-tfidf-8" href="./nips-2010-t-logistic_regression.html">290 nips-2010-t-logistic regression</a></p>
<p>9 0.087608568 <a title="163-tfidf-9" href="./nips-2010-Tight_Sample_Complexity_of_Large-Margin_Learning.html">270 nips-2010-Tight Sample Complexity of Large-Margin Learning</a></p>
<p>10 0.081012063 <a title="163-tfidf-10" href="./nips-2010-A_Primal-Dual_Message-Passing_Algorithm_for_Approximated_Large_Scale_Structured_Prediction.html">13 nips-2010-A Primal-Dual Message-Passing Algorithm for Approximated Large Scale Structured Prediction</a></p>
<p>11 0.080698922 <a title="163-tfidf-11" href="./nips-2010-Fast_global_convergence_rates_of_gradient_methods_for_high-dimensional_statistical_recovery.html">92 nips-2010-Fast global convergence rates of gradient methods for high-dimensional statistical recovery</a></p>
<p>12 0.076074265 <a title="163-tfidf-12" href="./nips-2010-Multiple_Kernel_Learning_and_the_SMO_Algorithm.html">176 nips-2010-Multiple Kernel Learning and the SMO Algorithm</a></p>
<p>13 0.076013967 <a title="163-tfidf-13" href="./nips-2010-Label_Embedding_Trees_for_Large_Multi-Class_Tasks.html">135 nips-2010-Label Embedding Trees for Large Multi-Class Tasks</a></p>
<p>14 0.07381352 <a title="163-tfidf-14" href="./nips-2010-Efficient_Optimization_for_Discriminative_Latent_Class_Models.html">70 nips-2010-Efficient Optimization for Discriminative Latent Class Models</a></p>
<p>15 0.071635671 <a title="163-tfidf-15" href="./nips-2010-Sample_Complexity_of_Testing_the_Manifold_Hypothesis.html">232 nips-2010-Sample Complexity of Testing the Manifold Hypothesis</a></p>
<p>16 0.071354054 <a title="163-tfidf-16" href="./nips-2010-Computing_Marginal_Distributions_over_Continuous_Markov_Networks_for_Statistical_Relational_Learning.html">49 nips-2010-Computing Marginal Distributions over Continuous Markov Networks for Statistical Relational Learning</a></p>
<p>17 0.066816323 <a title="163-tfidf-17" href="./nips-2010-Reverse_Multi-Label_Learning.html">228 nips-2010-Reverse Multi-Label Learning</a></p>
<p>18 0.066614017 <a title="163-tfidf-18" href="./nips-2010-Structured_Determinantal_Point_Processes.html">257 nips-2010-Structured Determinantal Point Processes</a></p>
<p>19 0.06587448 <a title="163-tfidf-19" href="./nips-2010-Link_Discovery_using_Graph_Feature_Tracking.html">162 nips-2010-Link Discovery using Graph Feature Tracking</a></p>
<p>20 0.064132325 <a title="163-tfidf-20" href="./nips-2010-Active_Estimation_of_F-Measures.html">22 nips-2010-Active Estimation of F-Measures</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.18), (1, 0.041), (2, 0.142), (3, -0.01), (4, 0.049), (5, 0.004), (6, -0.026), (7, 0.004), (8, 0.018), (9, -0.019), (10, -0.027), (11, -0.068), (12, 0.064), (13, 0.056), (14, -0.024), (15, -0.018), (16, 0.012), (17, 0.025), (18, 0.033), (19, -0.042), (20, 0.079), (21, -0.061), (22, 0.082), (23, -0.001), (24, 0.015), (25, -0.02), (26, -0.109), (27, -0.012), (28, 0.087), (29, -0.076), (30, 0.006), (31, 0.011), (32, 0.053), (33, -0.052), (34, -0.088), (35, 0.1), (36, 0.044), (37, -0.073), (38, -0.012), (39, 0.033), (40, 0.056), (41, -0.068), (42, 0.063), (43, 0.027), (44, 0.08), (45, 0.053), (46, 0.077), (47, -0.078), (48, -0.075), (49, -0.015)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92735529 <a title="163-lsi-1" href="./nips-2010-Lower_Bounds_on_Rate_of_Convergence_of_Cutting_Plane_Methods.html">163 nips-2010-Lower Bounds on Rate of Convergence of Cutting Plane Methods</a></p>
<p>Author: Xinhua Zhang, Ankan Saha, S.v.n. Vishwanathan</p><p>Abstract: In a recent paper Joachims [1] presented SVM-Perf, a cutting plane method (CPM) for training linear Support Vector Machines (SVMs) which converges to an accurate solution in O(1/ 2 ) iterations. By tightening the analysis, Teo et al. [2] showed that O(1/ ) iterations sufﬁce. Given the impressive convergence speed of CPM on a number of practical problems, it was conjectured that these rates could be further improved. In this paper we disprove this conjecture. We present counter examples which are not only applicable for training linear SVMs with hinge loss, but also hold for support vector methods which optimize a multivariate performance score. However, surprisingly, these problems are not inherently hard. By exploiting the structure of the objective function we can devise an algo√ rithm that converges in O(1/ ) iterations. 1</p><p>2 0.72937721 <a title="163-lsi-2" href="./nips-2010-Sparse_Inverse_Covariance_Selection_via_Alternating_Linearization_Methods.html">248 nips-2010-Sparse Inverse Covariance Selection via Alternating Linearization Methods</a></p>
<p>Author: Katya Scheinberg, Shiqian Ma, Donald Goldfarb</p><p>Abstract: Gaussian graphical models are of great interest in statistical learning. Because the conditional independencies between different nodes correspond to zero entries in the inverse covariance matrix of the Gaussian distribution, one can learn the structure of the graph by estimating a sparse inverse covariance matrix from sample data, by solving a convex maximum likelihood problem with an ℓ1 -regularization term. In this paper, we propose a ﬁrst-order method based on an alternating linearization technique that exploits the problem’s special structure; in particular, the subproblems solved in each iteration have closed-form solutions. Moreover, our algorithm obtains an ϵ-optimal solution in O(1/ϵ) iterations. Numerical experiments on both synthetic and real data from gene association networks show that a practical version of this algorithm outperforms other competitive algorithms. 1</p><p>3 0.65429163 <a title="163-lsi-3" href="./nips-2010-A_Primal-Dual_Message-Passing_Algorithm_for_Approximated_Large_Scale_Structured_Prediction.html">13 nips-2010-A Primal-Dual Message-Passing Algorithm for Approximated Large Scale Structured Prediction</a></p>
<p>Author: Tamir Hazan, Raquel Urtasun</p><p>Abstract: In this paper we propose an approximated structured prediction framework for large scale graphical models and derive message-passing algorithms for learning their parameters efﬁciently. We ﬁrst relate CRFs and structured SVMs and show that in CRFs a variant of the log-partition function, known as the soft-max, smoothly approximates the hinge loss function of structured SVMs. We then propose an intuitive approximation for the structured prediction problem, using duality, based on a local entropy approximation and derive an efﬁcient messagepassing algorithm that is guaranteed to converge. Unlike existing approaches, this allows us to learn efﬁciently graphical models with cycles and very large number of parameters. 1</p><p>4 0.62421882 <a title="163-lsi-4" href="./nips-2010-Fast_global_convergence_rates_of_gradient_methods_for_high-dimensional_statistical_recovery.html">92 nips-2010-Fast global convergence rates of gradient methods for high-dimensional statistical recovery</a></p>
<p>Author: Alekh Agarwal, Sahand Negahban, Martin J. Wainwright</p><p>Abstract: Many statistical M -estimators are based on convex optimization problems formed by the weighted sum of a loss function with a norm-based regularizer. We analyze the convergence rates of ﬁrst-order gradient methods for solving such problems within a high-dimensional framework that allows the data dimension d to grow with (and possibly exceed) the sample size n. This high-dimensional structure precludes the usual global assumptions— namely, strong convexity and smoothness conditions—that underlie classical optimization analysis. We deﬁne appropriately restricted versions of these conditions, and show that they are satisﬁed with high probability for various statistical models. Under these conditions, our theory guarantees that Nesterov’s ﬁrst-order method [12] has a globally geometric rate of convergence up to the statistical precision of the model, meaning the typical Euclidean distance between the true unknown parameter θ∗ and the optimal solution θ. This globally linear rate is substantially faster than previous analyses of global convergence for speciﬁc methods that yielded only sublinear rates. Our analysis applies to a wide range of M -estimators and statistical models, including sparse linear regression using Lasso ( 1 regularized regression), group Lasso, block sparsity, and low-rank matrix recovery using nuclear norm regularization. Overall, this result reveals an interesting connection between statistical precision and computational eﬃciency in high-dimensional estimation. 1</p><p>5 0.6176793 <a title="163-lsi-5" href="./nips-2010-An_Approximate_Inference_Approach_to_Temporal_Optimization_in_Optimal_Control.html">29 nips-2010-An Approximate Inference Approach to Temporal Optimization in Optimal Control</a></p>
<p>Author: Konrad Rawlik, Marc Toussaint, Sethu Vijayakumar</p><p>Abstract: Algorithms based on iterative local approximations present a practical approach to optimal control in robotic systems. However, they generally require the temporal parameters (for e.g. the movement duration or the time point of reaching an intermediate goal) to be speciﬁed a priori. Here, we present a methodology that is capable of jointly optimizing the temporal parameters in addition to the control command proﬁles. The presented approach is based on a Bayesian canonical time formulation of the optimal control problem, with the temporal mapping from canonical to real time parametrised by an additional control variable. An approximate EM algorithm is derived that efﬁciently optimizes both the movement duration and control commands offering, for the ﬁrst time, a practical approach to tackling generic via point problems in a systematic way under the optimal control framework. The proposed approach, which is applicable to plants with non-linear dynamics as well as arbitrary state dependent and quadratic control costs, is evaluated on realistic simulations of a redundant robotic plant.</p><p>6 0.60724688 <a title="163-lsi-6" href="./nips-2010-Parallelized_Stochastic_Gradient_Descent.html">202 nips-2010-Parallelized Stochastic Gradient Descent</a></p>
<p>7 0.58938116 <a title="163-lsi-7" href="./nips-2010-Practical_Large-Scale_Optimization_for_Max-norm_Regularization.html">210 nips-2010-Practical Large-Scale Optimization for Max-norm Regularization</a></p>
<p>8 0.58298934 <a title="163-lsi-8" href="./nips-2010-Decomposing_Isotonic_Regression_for_Efficiently_Solving_Large_Problems.html">58 nips-2010-Decomposing Isotonic Regression for Efficiently Solving Large Problems</a></p>
<p>9 0.56535923 <a title="163-lsi-9" href="./nips-2010-Smoothness%2C_Low_Noise_and_Fast_Rates.html">243 nips-2010-Smoothness, Low Noise and Fast Rates</a></p>
<p>10 0.56055516 <a title="163-lsi-10" href="./nips-2010-Distributed_Dual_Averaging_In_Networks.html">63 nips-2010-Distributed Dual Averaging In Networks</a></p>
<p>11 0.55048901 <a title="163-lsi-11" href="./nips-2010-On_the_Theory_of_Learnining_with_Privileged_Information.html">191 nips-2010-On the Theory of Learnining with Privileged Information</a></p>
<p>12 0.54459745 <a title="163-lsi-12" href="./nips-2010-Tight_Sample_Complexity_of_Large-Margin_Learning.html">270 nips-2010-Tight Sample Complexity of Large-Margin Learning</a></p>
<p>13 0.54196882 <a title="163-lsi-13" href="./nips-2010-Static_Analysis_of_Binary_Executables_Using_Structural_SVMs.html">255 nips-2010-Static Analysis of Binary Executables Using Structural SVMs</a></p>
<p>14 0.53970915 <a title="163-lsi-14" href="./nips-2010-More_data_means_less_inference%3A_A_pseudo-max_approach_to_structured_learning.html">169 nips-2010-More data means less inference: A pseudo-max approach to structured learning</a></p>
<p>15 0.53051013 <a title="163-lsi-15" href="./nips-2010-t-logistic_regression.html">290 nips-2010-t-logistic regression</a></p>
<p>16 0.51594037 <a title="163-lsi-16" href="./nips-2010-Sample_Complexity_of_Testing_the_Manifold_Hypothesis.html">232 nips-2010-Sample Complexity of Testing the Manifold Hypothesis</a></p>
<p>17 0.50341731 <a title="163-lsi-17" href="./nips-2010-Learning_Bounds_for_Importance_Weighting.html">142 nips-2010-Learning Bounds for Importance Weighting</a></p>
<p>18 0.49317533 <a title="163-lsi-18" href="./nips-2010-Implicit_Differentiation_by_Perturbation.html">118 nips-2010-Implicit Differentiation by Perturbation</a></p>
<p>19 0.47906071 <a title="163-lsi-19" href="./nips-2010-Structured_Determinantal_Point_Processes.html">257 nips-2010-Structured Determinantal Point Processes</a></p>
<p>20 0.47783241 <a title="163-lsi-20" href="./nips-2010-Self-Paced_Learning_for_Latent_Variable_Models.html">235 nips-2010-Self-Paced Learning for Latent Variable Models</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.052), (17, 0.019), (27, 0.037), (30, 0.093), (35, 0.032), (45, 0.197), (50, 0.041), (52, 0.031), (53, 0.247), (60, 0.079), (77, 0.034), (78, 0.027), (90, 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.84903669 <a title="163-lda-1" href="./nips-2010-Repeated_Games_against_Budgeted_Adversaries.html">226 nips-2010-Repeated Games against Budgeted Adversaries</a></p>
<p>Author: Jacob D. Abernethy, Manfred K. Warmuth</p><p>Abstract: We study repeated zero-sum games against an adversary on a budget. Given that an adversary has some constraint on the sequence of actions that he plays, we consider what ought to be the player’s best mixed strategy with knowledge of this budget. We show that, for a general class of normal-form games, the minimax strategy is indeed efﬁciently computable and relies on a “random playout” technique. We give three diverse applications of this new algorithmic template: a cost-sensitive “Hedge” setting, a particular problem in Metrical Task Systems, and the design of combinatorial prediction markets. 1</p><p>2 0.80462784 <a title="163-lda-2" href="./nips-2010-A_Bayesian_Approach_to_Concept_Drift.html">2 nips-2010-A Bayesian Approach to Concept Drift</a></p>
<p>Author: Stephen Bach, Mark Maloof</p><p>Abstract: To cope with concept drift, we placed a probability distribution over the location of the most-recent drift point. We used Bayesian model comparison to update this distribution from the predictions of models trained on blocks of consecutive observations and pruned potential drift points with low probability. We compare our approach to a non-probabilistic method for drift and a probabilistic method for change-point detection. In our experiments, our approach generally yielded improved accuracy and/or speed over these other methods. 1</p><p>same-paper 3 0.79793102 <a title="163-lda-3" href="./nips-2010-Lower_Bounds_on_Rate_of_Convergence_of_Cutting_Plane_Methods.html">163 nips-2010-Lower Bounds on Rate of Convergence of Cutting Plane Methods</a></p>
<p>Author: Xinhua Zhang, Ankan Saha, S.v.n. Vishwanathan</p><p>Abstract: In a recent paper Joachims [1] presented SVM-Perf, a cutting plane method (CPM) for training linear Support Vector Machines (SVMs) which converges to an accurate solution in O(1/ 2 ) iterations. By tightening the analysis, Teo et al. [2] showed that O(1/ ) iterations sufﬁce. Given the impressive convergence speed of CPM on a number of practical problems, it was conjectured that these rates could be further improved. In this paper we disprove this conjecture. We present counter examples which are not only applicable for training linear SVMs with hinge loss, but also hold for support vector methods which optimize a multivariate performance score. However, surprisingly, these problems are not inherently hard. By exploiting the structure of the objective function we can devise an algo√ rithm that converges in O(1/ ) iterations. 1</p><p>4 0.77960932 <a title="163-lda-4" href="./nips-2010-Fast_Large-scale_Mixture_Modeling_with_Component-specific_Data_Partitions.html">90 nips-2010-Fast Large-scale Mixture Modeling with Component-specific Data Partitions</a></p>
<p>Author: Bo Thiesson, Chong Wang</p><p>Abstract: Remarkably easy implementation and guaranteed convergence has made the EM algorithm one of the most used algorithms for mixture modeling. On the downside, the E-step is linear in both the sample size and the number of mixture components, making it impractical for large-scale data. Based on the variational EM framework, we propose a fast alternative that uses component-speciﬁc data partitions to obtain a sub-linear E-step in sample size, while the algorithm still maintains provable convergence. Our approach builds on previous work, but is signiﬁcantly faster and scales much better in the number of mixture components. We demonstrate this speedup by experiments on large-scale synthetic and real data. 1</p><p>5 0.7768746 <a title="163-lda-5" href="./nips-2010-Policy_gradients_in_linearly-solvable_MDPs.html">208 nips-2010-Policy gradients in linearly-solvable MDPs</a></p>
<p>Author: Emanuel Todorov</p><p>Abstract: We present policy gradient results within the framework of linearly-solvable MDPs. For the ﬁrst time, compatible function approximators and natural policy gradients are obtained by estimating the cost-to-go function, rather than the (much larger) state-action advantage function as is necessary in traditional MDPs. We also develop the ﬁrst compatible function approximators and natural policy gradients for continuous-time stochastic systems.</p><p>6 0.70007163 <a title="163-lda-6" href="./nips-2010-Online_Markov_Decision_Processes_under_Bandit_Feedback.html">196 nips-2010-Online Markov Decision Processes under Bandit Feedback</a></p>
<p>7 0.696729 <a title="163-lda-7" href="./nips-2010-Random_Walk_Approach_to_Regret_Minimization.html">222 nips-2010-Random Walk Approach to Regret Minimization</a></p>
<p>8 0.69079512 <a title="163-lda-8" href="./nips-2010-Sufficient_Conditions_for_Generating_Group_Level_Sparsity_in_a_Robust_Minimax_Framework.html">260 nips-2010-Sufficient Conditions for Generating Group Level Sparsity in a Robust Minimax Framework</a></p>
<p>9 0.68916768 <a title="163-lda-9" href="./nips-2010-Tight_Sample_Complexity_of_Large-Margin_Learning.html">270 nips-2010-Tight Sample Complexity of Large-Margin Learning</a></p>
<p>10 0.68852997 <a title="163-lda-10" href="./nips-2010-Online_Learning%3A_Random_Averages%2C_Combinatorial_Parameters%2C_and_Learnability.html">193 nips-2010-Online Learning: Random Averages, Combinatorial Parameters, and Learnability</a></p>
<p>11 0.68749195 <a title="163-lda-11" href="./nips-2010-Smoothness%2C_Low_Noise_and_Fast_Rates.html">243 nips-2010-Smoothness, Low Noise and Fast Rates</a></p>
<p>12 0.68729144 <a title="163-lda-12" href="./nips-2010-A_Computational_Decision_Theory_for_Interactive_Assistants.html">4 nips-2010-A Computational Decision Theory for Interactive Assistants</a></p>
<p>13 0.68638742 <a title="163-lda-13" href="./nips-2010-Extensions_of_Generalized_Binary_Search_to_Group_Identification_and_Exponential_Costs.html">88 nips-2010-Extensions of Generalized Binary Search to Group Identification and Exponential Costs</a></p>
<p>14 0.6855849 <a title="163-lda-14" href="./nips-2010-Extended_Bayesian_Information_Criteria_for_Gaussian_Graphical_Models.html">87 nips-2010-Extended Bayesian Information Criteria for Gaussian Graphical Models</a></p>
<p>15 0.68499541 <a title="163-lda-15" href="./nips-2010-The_LASSO_risk%3A_asymptotic_results_and_real_world_examples.html">265 nips-2010-The LASSO risk: asymptotic results and real world examples</a></p>
<p>16 0.6849001 <a title="163-lda-16" href="./nips-2010-Distributed_Dual_Averaging_In_Networks.html">63 nips-2010-Distributed Dual Averaging In Networks</a></p>
<p>17 0.68403101 <a title="163-lda-17" href="./nips-2010-Empirical_Risk_Minimization_with_Approximations_of_Probabilistic_Grammars.html">75 nips-2010-Empirical Risk Minimization with Approximations of Probabilistic Grammars</a></p>
<p>18 0.68362731 <a title="163-lda-18" href="./nips-2010-Near-Optimal_Bayesian_Active_Learning_with_Noisy_Observations.html">180 nips-2010-Near-Optimal Bayesian Active Learning with Noisy Observations</a></p>
<p>19 0.68268067 <a title="163-lda-19" href="./nips-2010-Error_Propagation_for_Approximate_Policy_and_Value_Iteration.html">78 nips-2010-Error Propagation for Approximate Policy and Value Iteration</a></p>
<p>20 0.68103188 <a title="163-lda-20" href="./nips-2010-Unsupervised_Kernel_Dimension_Reduction.html">280 nips-2010-Unsupervised Kernel Dimension Reduction</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
