<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>279 nips-2010-Universal Kernels on Non-Standard Input Spaces</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-279" href="#">nips2010-279</a> knowledge-graph by maker-knowledge-mining</p><h1>279 nips-2010-Universal Kernels on Non-Standard Input Spaces</h1>
<br/><p>Source: <a title="nips-2010-279-pdf" href="http://papers.nips.cc/paper/4168-universal-kernels-on-non-standard-input-spaces.pdf">pdf</a></p><p>Author: Andreas Christmann, Ingo Steinwart</p><p>Abstract: During the last years support vector machines (SVMs) have been successfully applied in situations where the input space X is not necessarily a subset of Rd . Examples include SVMs for the analysis of histograms or colored images, SVMs for text classiÄ?Ĺš cation and web mining, and SVMs for applications from computational biology using, e.g., kernels for trees and graphs. Moreover, SVMs are known to be consistent to the Bayes risk, if either the input space is a complete separable metric space and the reproducing kernel Hilbert space (RKHS) H Ă˘&Scaron;&sbquo; Lp (PX ) is dense, or if the SVM uses a universal kernel k. So far, however, there are no kernels of practical interest known that satisfy these assumptions, if X Ă˘&Scaron;&sbquo; Rd . We close this gap by providing a general technique based on Taylor-type kernels to explicitly construct universal kernels on compact metric spaces which are not subset of Rd . We apply this technique for the following special cases: universal kernels on the set of probability measures, universal kernels based on Fourier transforms, and universal kernels for signal processing. 1</p><p>Reference: <a title="nips-2010-279-reference" href="../nips2010_reference/nips-2010-Universal_Kernels_on_Non-Standard_Input_Spaces_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('kernel', 0.454), ('compact', 0.327), ('hw', 0.309), ('rkhs', 0.196), ('rb', 0.194), ('cj', 0.172), ('rd', 0.166), ('kw', 0.165), ('hilbert', 0.164), ('met', 0.163), ('svms', 0.153), ('kx', 0.151), ('nn', 0.147), ('rbf', 0.136), ('hx', 0.135), ('isomet', 0.123), ('fukumizu', 0.116), ('isomorph', 0.112), ('inject', 0.098), ('tayl', 0.097)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="279-tfidf-1" href="./nips-2010-Universal_Kernels_on_Non-Standard_Input_Spaces.html">279 nips-2010-Universal Kernels on Non-Standard Input Spaces</a></p>
<p>2 0.37673885 <a title="279-tfidf-2" href="./nips-2010-Spectral_Regularization_for_Support_Estimation.html">250 nips-2010-Spectral Regularization for Support Estimation</a></p>
<p>3 0.34325382 <a title="279-tfidf-3" href="./nips-2010-Inductive_Regularized_Learning_of_Kernel_Functions.html">124 nips-2010-Inductive Regularized Learning of Kernel Functions</a></p>
<p>4 0.29008195 <a title="279-tfidf-4" href="./nips-2010-Kernel_Descriptors_for_Visual_Recognition.html">133 nips-2010-Kernel Descriptors for Visual Recognition</a></p>
<p>5 0.25486043 <a title="279-tfidf-5" href="./nips-2010-Learning_Kernels_with_Radiuses_of_Minimum_Enclosing_Balls.html">145 nips-2010-Learning Kernels with Radiuses of Minimum Enclosing Balls</a></p>
<p>6 0.20100075 <a title="279-tfidf-6" href="./nips-2010-Multi-label_Multiple_Kernel_Learning_by_Stochastic_Approximation%3A_Application_to_Visual_Object_Recognition.html">174 nips-2010-Multi-label Multiple Kernel Learning by Stochastic Approximation: Application to Visual Object Recognition</a></p>
<p>7 0.19000684 <a title="279-tfidf-7" href="./nips-2010-Unsupervised_Kernel_Dimension_Reduction.html">280 nips-2010-Unsupervised Kernel Dimension Reduction</a></p>
<p>8 0.13067006 <a title="279-tfidf-8" href="./nips-2010-Multiple_Kernel_Learning_and_the_SMO_Algorithm.html">176 nips-2010-Multiple Kernel Learning and the SMO Algorithm</a></p>
<p>9 0.12949252 <a title="279-tfidf-9" href="./nips-2010-Generative_Local_Metric_Learning_for_Nearest_Neighbor_Classification.html">104 nips-2010-Generative Local Metric Learning for Nearest Neighbor Classification</a></p>
<p>10 0.12525894 <a title="279-tfidf-10" href="./nips-2010-Optimal_learning_rates_for_Kernel_Conjugate_Gradient_regression.html">199 nips-2010-Optimal learning rates for Kernel Conjugate Gradient regression</a></p>
<p>11 0.11561092 <a title="279-tfidf-11" href="./nips-2010-Universal_Consistency_of_Multi-Class_Support_Vector_Classification.html">278 nips-2010-Universal Consistency of Multi-Class Support Vector Classification</a></p>
<p>12 0.10709901 <a title="279-tfidf-12" href="./nips-2010-Scrambled_Objects_for_Least-Squares_Regression.html">233 nips-2010-Scrambled Objects for Least-Squares Regression</a></p>
<p>13 0.10635111 <a title="279-tfidf-13" href="./nips-2010-Spatial_and_anatomical_regularization_of_SVM_for_brain_image_analysis.html">249 nips-2010-Spatial and anatomical regularization of SVM for brain image analysis</a></p>
<p>14 0.10606769 <a title="279-tfidf-14" href="./nips-2010-A_Family_of_Penalty_Functions_for_Structured_Sparsity.html">7 nips-2010-A Family of Penalty Functions for Structured Sparsity</a></p>
<p>15 0.10519037 <a title="279-tfidf-15" href="./nips-2010-Tight_Sample_Complexity_of_Large-Margin_Learning.html">270 nips-2010-Tight Sample Complexity of Large-Margin Learning</a></p>
<p>16 0.091272511 <a title="279-tfidf-16" href="./nips-2010-Efficient_algorithms_for_learning_kernels_from_multiple_similarity_matrices_with_general_convex_loss_functions.html">72 nips-2010-Efficient algorithms for learning kernels from multiple similarity matrices with general convex loss functions</a></p>
<p>17 0.090371415 <a title="279-tfidf-17" href="./nips-2010-Fractionally_Predictive_Spiking_Neurons.html">96 nips-2010-Fractionally Predictive Spiking Neurons</a></p>
<p>18 0.086731739 <a title="279-tfidf-18" href="./nips-2010-Nonparametric_Density_Estimation_for_Stochastic_Optimization_with_an_Observable_State_Variable.html">185 nips-2010-Nonparametric Density Estimation for Stochastic Optimization with an Observable State Variable</a></p>
<p>19 0.081707969 <a title="279-tfidf-19" href="./nips-2010-Factorized_Latent_Spaces_with_Structured_Sparsity.html">89 nips-2010-Factorized Latent Spaces with Structured Sparsity</a></p>
<p>20 0.079433039 <a title="279-tfidf-20" href="./nips-2010-Sample_Complexity_of_Testing_the_Manifold_Hypothesis.html">232 nips-2010-Sample Complexity of Testing the Manifold Hypothesis</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.22), (1, -0.085), (2, 0.044), (3, -0.046), (4, -0.47), (5, 0.198), (6, -0.142), (7, 0.001), (8, 0.015), (9, 0.05), (10, -0.036), (11, 0.034), (12, 0.045), (13, -0.002), (14, 0.082), (15, 0.007), (16, 0.116), (17, -0.036), (18, 0.063), (19, -0.089), (20, -0.053), (21, -0.06), (22, 0.076), (23, 0.069), (24, -0.026), (25, 0.044), (26, -0.021), (27, -0.06), (28, 0.006), (29, -0.002), (30, 0.076), (31, -0.034), (32, 0.113), (33, -0.02), (34, -0.079), (35, -0.126), (36, -0.043), (37, 0.004), (38, 0.011), (39, 0.006), (40, 0.04), (41, -0.02), (42, -0.086), (43, 0.047), (44, 0.043), (45, -0.03), (46, -0.056), (47, 0.023), (48, 0.068), (49, 0.01)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97967124 <a title="279-lsi-1" href="./nips-2010-Universal_Kernels_on_Non-Standard_Input_Spaces.html">279 nips-2010-Universal Kernels on Non-Standard Input Spaces</a></p>
<p>2 0.90791512 <a title="279-lsi-2" href="./nips-2010-Spectral_Regularization_for_Support_Estimation.html">250 nips-2010-Spectral Regularization for Support Estimation</a></p>
<p>3 0.88697863 <a title="279-lsi-3" href="./nips-2010-Inductive_Regularized_Learning_of_Kernel_Functions.html">124 nips-2010-Inductive Regularized Learning of Kernel Functions</a></p>
<p>4 0.84209394 <a title="279-lsi-4" href="./nips-2010-Unsupervised_Kernel_Dimension_Reduction.html">280 nips-2010-Unsupervised Kernel Dimension Reduction</a></p>
<p>5 0.80008423 <a title="279-lsi-5" href="./nips-2010-Learning_Kernels_with_Radiuses_of_Minimum_Enclosing_Balls.html">145 nips-2010-Learning Kernels with Radiuses of Minimum Enclosing Balls</a></p>
<p>6 0.75768578 <a title="279-lsi-6" href="./nips-2010-Kernel_Descriptors_for_Visual_Recognition.html">133 nips-2010-Kernel Descriptors for Visual Recognition</a></p>
<p>7 0.71080345 <a title="279-lsi-7" href="./nips-2010-Optimal_learning_rates_for_Kernel_Conjugate_Gradient_regression.html">199 nips-2010-Optimal learning rates for Kernel Conjugate Gradient regression</a></p>
<p>8 0.69781864 <a title="279-lsi-8" href="./nips-2010-Multi-label_Multiple_Kernel_Learning_by_Stochastic_Approximation%3A_Application_to_Visual_Object_Recognition.html">174 nips-2010-Multi-label Multiple Kernel Learning by Stochastic Approximation: Application to Visual Object Recognition</a></p>
<p>9 0.63643026 <a title="279-lsi-9" href="./nips-2010-Multiple_Kernel_Learning_and_the_SMO_Algorithm.html">176 nips-2010-Multiple Kernel Learning and the SMO Algorithm</a></p>
<p>10 0.57755756 <a title="279-lsi-10" href="./nips-2010-Universal_Consistency_of_Multi-Class_Support_Vector_Classification.html">278 nips-2010-Universal Consistency of Multi-Class Support Vector Classification</a></p>
<p>11 0.56256533 <a title="279-lsi-11" href="./nips-2010-Efficient_algorithms_for_learning_kernels_from_multiple_similarity_matrices_with_general_convex_loss_functions.html">72 nips-2010-Efficient algorithms for learning kernels from multiple similarity matrices with general convex loss functions</a></p>
<p>12 0.5531261 <a title="279-lsi-12" href="./nips-2010-Scrambled_Objects_for_Least-Squares_Regression.html">233 nips-2010-Scrambled Objects for Least-Squares Regression</a></p>
<p>13 0.5067299 <a title="279-lsi-13" href="./nips-2010-Learning_sparse_dynamic_linear_systems_using_stable_spline_kernels_and_exponential_hyperpriors.html">154 nips-2010-Learning sparse dynamic linear systems using stable spline kernels and exponential hyperpriors</a></p>
<p>14 0.46432951 <a title="279-lsi-14" href="./nips-2010-Generative_Local_Metric_Learning_for_Nearest_Neighbor_Classification.html">104 nips-2010-Generative Local Metric Learning for Nearest Neighbor Classification</a></p>
<p>15 0.46428663 <a title="279-lsi-15" href="./nips-2010-Getting_lost_in_space%3A_Large_sample_analysis_of_the_resistance_distance.html">105 nips-2010-Getting lost in space: Large sample analysis of the resistance distance</a></p>
<p>16 0.44516131 <a title="279-lsi-16" href="./nips-2010-Spatial_and_anatomical_regularization_of_SVM_for_brain_image_analysis.html">249 nips-2010-Spatial and anatomical regularization of SVM for brain image analysis</a></p>
<p>17 0.43935007 <a title="279-lsi-17" href="./nips-2010-Heavy-Tailed_Process_Priors_for_Selective_Shrinkage.html">113 nips-2010-Heavy-Tailed Process Priors for Selective Shrinkage</a></p>
<p>18 0.36657318 <a title="279-lsi-18" href="./nips-2010-Fractionally_Predictive_Spiking_Neurons.html">96 nips-2010-Fractionally Predictive Spiking Neurons</a></p>
<p>19 0.35106453 <a title="279-lsi-19" href="./nips-2010-Nonparametric_Density_Estimation_for_Stochastic_Optimization_with_an_Observable_State_Variable.html">185 nips-2010-Nonparametric Density Estimation for Stochastic Optimization with an Observable State Variable</a></p>
<p>20 0.33771837 <a title="279-lsi-20" href="./nips-2010-Worst-Case_Linear_Discriminant_Analysis.html">287 nips-2010-Worst-Case Linear Discriminant Analysis</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(7, 0.163), (9, 0.034), (30, 0.054), (32, 0.106), (34, 0.129), (45, 0.13), (59, 0.185), (68, 0.106)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.85865468 <a title="279-lda-1" href="./nips-2010-A_novel_family_of_non-parametric_cumulative_based_divergences_for_point_processes.html">18 nips-2010-A novel family of non-parametric cumulative based divergences for point processes</a></p>
<p>same-paper 2 0.84447223 <a title="279-lda-2" href="./nips-2010-Universal_Kernels_on_Non-Standard_Input_Spaces.html">279 nips-2010-Universal Kernels on Non-Standard Input Spaces</a></p>
<p>3 0.83747274 <a title="279-lda-3" href="./nips-2010-Stability_Approach_to_Regularization_Selection_%28StARS%29_for_High_Dimensional_Graphical_Models.html">254 nips-2010-Stability Approach to Regularization Selection (StARS) for High Dimensional Graphical Models</a></p>
<p>4 0.83220577 <a title="279-lda-4" href="./nips-2010-Distributed_Dual_Averaging_In_Networks.html">63 nips-2010-Distributed Dual Averaging In Networks</a></p>
<p>5 0.82789791 <a title="279-lda-5" href="./nips-2010-Decomposing_Isotonic_Regression_for_Efficiently_Solving_Large_Problems.html">58 nips-2010-Decomposing Isotonic Regression for Efficiently Solving Large Problems</a></p>
<p>6 0.82339263 <a title="279-lda-6" href="./nips-2010-Lower_Bounds_on_Rate_of_Convergence_of_Cutting_Plane_Methods.html">163 nips-2010-Lower Bounds on Rate of Convergence of Cutting Plane Methods</a></p>
<p>7 0.82098567 <a title="279-lda-7" href="./nips-2010-Learning_concept_graphs_from_text_with_stick-breaking_priors.html">150 nips-2010-Learning concept graphs from text with stick-breaking priors</a></p>
<p>8 0.81601846 <a title="279-lda-8" href="./nips-2010-A_Family_of_Penalty_Functions_for_Structured_Sparsity.html">7 nips-2010-A Family of Penalty Functions for Structured Sparsity</a></p>
<p>9 0.8152436 <a title="279-lda-9" href="./nips-2010-Random_Walk_Approach_to_Regret_Minimization.html">222 nips-2010-Random Walk Approach to Regret Minimization</a></p>
<p>10 0.81506282 <a title="279-lda-10" href="./nips-2010-Improving_the_Asymptotic_Performance_of_Markov_Chain_Monte-Carlo_by_Inserting_Vortices.html">122 nips-2010-Improving the Asymptotic Performance of Markov Chain Monte-Carlo by Inserting Vortices</a></p>
<p>11 0.8133167 <a title="279-lda-11" href="./nips-2010-Probabilistic_Belief_Revision_with_Structural_Constraints.html">214 nips-2010-Probabilistic Belief Revision with Structural Constraints</a></p>
<p>12 0.81271976 <a title="279-lda-12" href="./nips-2010-Random_Conic_Pursuit_for_Semidefinite_Programming.html">219 nips-2010-Random Conic Pursuit for Semidefinite Programming</a></p>
<p>13 0.81134588 <a title="279-lda-13" href="./nips-2010-Construction_of_Dependent_Dirichlet_Processes_based_on_Poisson_Processes.html">51 nips-2010-Construction of Dependent Dirichlet Processes based on Poisson Processes</a></p>
<p>14 0.81081289 <a title="279-lda-14" href="./nips-2010-Spectral_Regularization_for_Support_Estimation.html">250 nips-2010-Spectral Regularization for Support Estimation</a></p>
<p>15 0.81034374 <a title="279-lda-15" href="./nips-2010-Moreau-Yosida_Regularization_for_Grouped_Tree_Structure_Learning.html">170 nips-2010-Moreau-Yosida Regularization for Grouped Tree Structure Learning</a></p>
<p>16 0.80870652 <a title="279-lda-16" href="./nips-2010-Fast_global_convergence_rates_of_gradient_methods_for_high-dimensional_statistical_recovery.html">92 nips-2010-Fast global convergence rates of gradient methods for high-dimensional statistical recovery</a></p>
<p>17 0.80759245 <a title="279-lda-17" href="./nips-2010-Tree-Structured_Stick_Breaking_for_Hierarchical_Data.html">276 nips-2010-Tree-Structured Stick Breaking for Hierarchical Data</a></p>
<p>18 0.80731446 <a title="279-lda-18" href="./nips-2010-Two-Layer_Generalization_Analysis_for_Ranking_Using_Rademacher_Average.html">277 nips-2010-Two-Layer Generalization Analysis for Ranking Using Rademacher Average</a></p>
<p>19 0.80585849 <a title="279-lda-19" href="./nips-2010-Structured_sparsity-inducing_norms_through_submodular_functions.html">258 nips-2010-Structured sparsity-inducing norms through submodular functions</a></p>
<p>20 0.80580032 <a title="279-lda-20" href="./nips-2010-The_LASSO_risk%3A_asymptotic_results_and_real_world_examples.html">265 nips-2010-The LASSO risk: asymptotic results and real world examples</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
