<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>118 nips-2010-Implicit Differentiation by Perturbation</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-118" href="#">nips2010-118</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>118 nips-2010-Implicit Differentiation by Perturbation</h1>
<br/><p>Source: <a title="nips-2010-118-pdf" href="http://papers.nips.cc/paper/4107-implicit-differentiation-by-perturbation.pdf">pdf</a></p><p>Author: Justin Domke</p><p>Abstract: This paper proposes a simple and eﬃcient ﬁnite diﬀerence method for implicit diﬀerentiation of marginal inference results in discrete graphical models. Given an arbitrary loss function, deﬁned on marginals, we show that the derivatives of this loss with respect to model parameters can be obtained by running the inference procedure twice, on slightly perturbed model parameters. This method can be used with approximate inference, with a loss function over approximate marginals. Convenient choices of loss functions make it practical to ﬁt graphical models with hidden variables, high treewidth and/or model misspeciﬁcation. 1</p><p>Reference: <a title="nips-2010-118-reference" href="../nips2010_reference/nips-2010-Implicit_Differentiation_by_Perturbation_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract This paper proposes a simple and eﬃcient ﬁnite diﬀerence method for implicit diﬀerentiation of marginal inference results in discrete graphical models. [sent-3, score-0.358]
</p><p>2 Given an arbitrary loss function, deﬁned on marginals, we show that the derivatives of this loss with respect to model parameters can be obtained by running the inference procedure twice, on slightly perturbed model parameters. [sent-4, score-0.49]
</p><p>3 This method can be used with approximate inference, with a loss function over approximate marginals. [sent-5, score-0.219]
</p><p>4 Convenient choices of loss functions make it practical to ﬁt graphical models with hidden variables, high treewidth and/or model misspeciﬁcation. [sent-6, score-0.222]
</p><p>5 Though the likelihood and conditional likelihood are the most widespread training objectives, these are sometimes undesirable and/or infeasible in real applications. [sent-8, score-0.275]
</p><p>6 With low treewidth, if the data is truly distributed according to the chosen graphical model with some parameters, any consistent loss function will recover those true parameters in the high-data limit, and so one might select a loss function according to statistical convergence rates [1]. [sent-9, score-0.312]
</p><p>7 In this case, diﬀerent loss functions lead to diﬀerent asymptotic parameter estimates. [sent-11, score-0.113]
</p><p>8 For lowtreewidth graphs, several loss functions have been proposed that prioritize diﬀerent types of accuracy (section 2. [sent-13, score-0.113]
</p><p>9 For parameters θ, these loss functions are given as a function ∂L L(µ(θ)) of marginals µ(θ). [sent-15, score-0.305]
</p><p>10 The likelihood may also be infeasible to optimize, due to the computational intractability of computing the log-partition function or its derivatives in high treewidth graphs. [sent-18, score-0.211]
</p><p>11 On the other hand, if an approximate inference algorithm will be used at test time, it is logical to design the loss function to compensate for defects in inference. [sent-19, score-0.279]
</p><p>12 The surrogate likelihood (the likelihood with an approximate partition function) can give superior results to the true likelihood, when approximate inference is used at test time[4]. [sent-20, score-0.611]
</p><p>13 If µ(θ) is the function mapping parameters to (approximate) marginals, and there is some loss function L(µ) deﬁned on those marginals, we desire to recover dL . [sent-22, score-0.144]
</p><p>14 This enables the use of the marginal-based loss functions mentioned dθ previously, but deﬁned on approximate marginals. [sent-23, score-0.166]
</p><p>15 The major disadvantage of this approach is that standard linear solvers can perform poorly on large 1  True (y)  Noisy (x)  Surrogate likelihood  Clique likelihood  Univariate likelihood  Smooth class. [sent-26, score-0.425]
</p><p>16 error  Figure 1: Example images from the Berkeley dataset, along with marginals for a conditional random ﬁeld ﬁt with various loss functions. [sent-27, score-0.342]
</p><p>17 graphs, meaning that calculating this gradient can be more expensive than performing inference (Section 4). [sent-28, score-0.21]
</p><p>18 However, it is tied to a speciﬁc entropy approximation (Bethe) and algorithm (Loopy Belief Propagation). [sent-33, score-0.258]
</p><p>19 Extension to similar message-passing algorithms appears possible, but extension to more complex inference algorithms [7, 8, 9] is unclear. [sent-34, score-0.113]
</p><p>20 Here, we observe that the loss gradient can be calculated by far more straightforward means. [sent-35, score-0.171]
</p><p>21 This result follows from, ﬁrst, the well-known trick of approximating Jacobianvector products by ﬁnite diﬀerences and, second, the special property that for marginal dµ inference, the Jacobian matrix dθT is symmetric. [sent-37, score-0.106]
</p><p>22 This result applies when marginal inference takes place over the local polytope with an entropy that is concave and obeys a minor technical condition. [sent-38, score-0.614]
</p><p>23 It can also be used with non-concave entropies, with some assumptions on how inference recovers diﬀerent local optima. [sent-39, score-0.145]
</p><p>24 It is easy to use this to compute the gradient of essentially any diﬀerentiable loss function deﬁned on marginals. [sent-40, score-0.171]
</p><p>25 Eﬀectively, all one needs to do is re-run the inference procedure on a set of parameters slightly "perturbed" in the direction ∂L . [sent-41, score-0.113]
</p><p>26 Aside from this, like the matrix inversion approach, it is independent of the algorithm used to perform independence, and applicable to a variety of diﬀerent inference approximations. [sent-44, score-0.144]
</p><p>27 1  Background Marginal Inference  This section brieﬂy reviews the aspects of graphical models and marginal inference that are required for the rest of the paper. [sent-47, score-0.274]
</p><p>28 (2)  Marginal inference means recovering the expected value of f or, equivalently, the marginal probability that each factor or variable have a particular value. [sent-56, score-0.219]
</p><p>29 µ(θ) =  p(x; θ)f (x)  (3)  x  Though marginals could, in principle, be computed by the brute-force sum in Eq. [sent-57, score-0.192]
</p><p>30 3, it is useful to consider the paired variational representation [10, Chapter 3] A(θ) = µ(θ) =  dA dθ  =  max θ · µ + H(µ)  (4)  arg max θ · µ + H(µ),  (5)  µ∈M  µ∈M  in which A and µ can both be recovered from solving the same optimization problem. [sent-58, score-0.128]
</p><p>31 Here, M = {µ(θ)|θ ∈ ℜn } is the marginal polytope– those marginals µ resulting from some parameter vector θ. [sent-59, score-0.298]
</p><p>32 Similarly, H(µ) is the entropy of p(x; θ ′ ), where θ′ is the vector of parameters that produces the marginals µ. [sent-60, score-0.389]
</p><p>33 A variety of approximate inference methods can be seen as solving a modiﬁcation of Eqs. [sent-64, score-0.166]
</p><p>34 4 and 5, with the marginal polytope and entropy replaced with tractable approximations. [sent-65, score-0.412]
</p><p>35 Notice that these are also paired; the approximate µ is the exact gradient of the approximate A. [sent-66, score-0.164]
</p><p>36 The commonest relaxation of M is the local polytope L = {µ ≥ 0 | µ(xi ) =  µ(xi ) = 1}. [sent-67, score-0.141]
</p><p>37 µ(xα ), xα\i  (6)  xi  This underlies loopy belief propagation, as well as tree-reweighted belief propagation. [sent-68, score-0.346]
</p><p>38 Since a valid set of marginals must obey these constraints, L ⊇ M. [sent-69, score-0.226]
</p><p>39 The Bethe approximation implicit in loopy belief propagation [11] is non-concave in general, which results in sometimes failing to achieve the global optimum. [sent-72, score-0.359]
</p><p>40 Concave entropy functions include the tree-reweighted entropy [12], convexiﬁed Bethe entropies [13], and the class of entropies obeying Heskes’ conditions [14]. [sent-73, score-0.628]
</p><p>41 The (negative) likelihood is the classic loss function for training graphical models. [sent-77, score-0.287]
</p><p>42 The surrogate likelihood [4] is simply the likelihood as in Eq. [sent-85, score-0.392]
</p><p>43 Unlike the losses below, the surrogate likelihood is convex when based on a concave inference method. [sent-89, score-0.443]
</p><p>44 [15] for a variant of this for inference with local optima. [sent-91, score-0.145]
</p><p>45 If the application will only make use of univariate marginals at test time, one might ﬁt parameters speciﬁcally to make these univariate marginals accurate. [sent-93, score-0.846]
</p><p>46 [3] proposed the loss L(ˆ ; θ) = − x  log µ(ˆi ; θ). [sent-95, score-0.113]
</p><p>47 x  (11)  i  This can be computed in treelike graphs, after running belief propagation to compute marginals. [sent-96, score-0.252]
</p><p>48 [2] considered the loss L(ˆ ; θ) = x i  S max µ(xi ; θ) − µ(ˆi ; θ) , x xi =ˆi x  (12)  where S is the step function. [sent-101, score-0.201]
</p><p>49 This loss measures the number of incorrect components of ˆ x if each is predicted to be the “max marginal”. [sent-102, score-0.113]
</p><p>50 As with the univariate likelihood, this loss can be computed if exact marginals are available. [sent-105, score-0.536]
</p><p>51 One can easily deﬁne clique versions of the previous two loss functions, where the summations are over α, rather than i. [sent-108, score-0.25]
</p><p>52 These measure the accuracy of clique-wise marginals, rather than univariate marginals. [sent-109, score-0.231]
</p><p>53 7, the equality constraints in the local polytope are linear, and hence when the positivity constraint can be disregarded, approximate marginal inference algorithms can be seen as solving the optimization µ(θ) = arg maxµ,Bµ=d θ · µ + H(µ). [sent-112, score-0.482]
</p><p>54 Domke showed[5], in our notation, that dL dL = D−1 B T (BD−1 B T )−1 BD−1 − D−1 , dθ dµ where D =  ∂2H ∂µ∂µT  (13)  is the (diagonal) Hessian of the entropy approximation. [sent-113, score-0.197]
</p><p>55 Nonlinear and tied parameters are easily dealt with by considering θ(φ) to be a function of the “true” 4  Algorithm 1 Calculating loss derivatives (two-sided). [sent-122, score-0.212]
</p><p>56 ∂L µ+ ← arg max (θ + r ) · µ + H(µ) µ∈M ∂µ  µ− ← arg max (θ − r µ∈M  ∂L ) · µ + H(µ) ∂µ  1 + dL ← (µ − µ− ) dθ 2r  5. [sent-131, score-0.138]
</p><p>57 (14) dφ dφ dθ Conditional training is similar: deﬁne a distribution over a random variable y, parametrized by θ(φ; x), the derivative on a particular pair (x, y) is given again by Eq. [sent-135, score-0.088]
</p><p>58 3  Implicit Diﬀerentiation by Perturbation  This section shows that when µ(θ) = arg maxµ∈L θ · µ + H(µ), the loss gradient can be computed by Alg. [sent-138, score-0.21]
</p><p>59 1 for a concave entropy approximation of the form H(µ) =  −  cα α  xα  µ(xα ) log µ(xα ) −  µ(xi ) log µ(xi ),  ci i  (15)  xi  when the counting numbers c obey (as is true of most proposed entropies) (16)  cα > 0. [sent-139, score-0.407]
</p><p>60 cα > 0, ci + α,i∈α  For intuition, the following Lemma uses notation (µ, θ, H) suggesting the application to marginal inference. [sent-140, score-0.167]
</p><p>61 t  arg max µ · θ + H(µ)  (17)  Bµ − d = 0,  (18)  µ  where H(µ) is strictly convex and twice diﬀerentiable, then  dµ exists and is symmetric. [sent-144, score-0.105]
</p><p>62 θ + ∂H(µ)/∂µ + B T λ Bµ − d 5  =  0 0  (20)  Recall the general implicit function theorem. [sent-148, score-0.084]
</p><p>63 Again, this uses notation suggesting the application to implicit diﬀerentiation and marginal inference, but holds true for any functions satisfying the stated conditions. [sent-155, score-0.19]
</p><p>64 1 follows from applying this theorem to marginal inference. [sent-165, score-0.106]
</p><p>65 If H(µ) = α cα H(µc ) + i ci H(µi ), and µ∗ is a (possibly local) maximum of θ · µ + H(µ), under the local polytope L, then cα > 0, ci + α,i∈α  cα > 0 −→ µ∗ > 0. [sent-169, score-0.263]
</p><p>66 With a non-concave entropy this condition is still valid, not not unique, since there can be local optima. [sent-176, score-0.229]
</p><p>67 BBP essentially calculates this 6  3  10  Bethe entropy  2  2  10  running time (s)  running time (s)  Bethe entropy  3  10  1  10  0  10  −1  10  10  1  10  0  10  pert−BP symmlq BBP direct BP  −1  10  −2  −2  10  10  8  32  128  0. [sent-177, score-0.606]
</p><p>68 5  512  grid size 3  10  TRW entropy  2  TRW entropy  3  10  2  2  10  running time (s)  running time (s)  1 interaction strength  1  10  0  10  −1  10  10  1  10  0  10  pert−TRWS symmlq direct TRWS  −1  10  −2  −2  10  10  8  32  128  0. [sent-178, score-0.718]
</p><p>69 5  512  grid size  1 interaction strength  2  Figure 2: Times to compute dL/dθ by perturbation, Back Belief Propagation (BBP), sparse matrix factorization (direct) and the iterative symmetric-LQ method (symmlq). [sent-179, score-0.112]
</p><p>70 As these results use two-sided diﬀerences, perturbation always takes twice the running time of the base inference algorithm. [sent-181, score-0.362]
</p><p>71 , 5}, with univariate terms θ(xi ) taken uniformly from [−1, +1] and interaction strengths θ(xi , xj ) from [−a, +a] for varying a. [sent-186, score-0.352]
</p><p>72 Top Left: Bethe entropy for varying grid sizes, with a = 1. [sent-187, score-0.311]
</p><p>73 Top Right: Bethe entropy with a grid size of 32 and varying interaction strengths a. [sent-189, score-0.397]
</p><p>74 Bottom Left: Varying grid sizes with the TRW entropy. [sent-191, score-0.079]
</p><p>75 Bottom Right: TRW entropy with a grid size of 32 and varying interactions. [sent-192, score-0.311]
</p><p>76 If perturbed beliefs are calculated from constant initial messages with a small step, one obtains the same result. [sent-194, score-0.133]
</p><p>77 Thus, BBP and perturbation give the same gradient for the Bethe approximation. [sent-195, score-0.177]
</p><p>78 ∂µ  4  Experiments  For inference, we used either loopy belief propagation, or tree-reweighted belief propagation. [sent-200, score-0.288]
</p><p>79 Base code was implemented in Python, with C++ extensions for inference algorithms for eﬃciency. [sent-205, score-0.113]
</p><p>80 14-25] to be much slower than the more sophisticated SEQ_FIX mode, based on sequential updates [6, extended 7  Table 1: Binary denoising results, comparing the surrogate likelihood against three loss functions ﬁt by implicit diﬀerentiation. [sent-212, score-0.47]
</p><p>81 All loss functions are per-pixel, based on treereweighted belief propagation with edge inclusion probabilities of . [sent-213, score-0.318]
</p><p>82 The “Best Published” results are the lowest previously reported pixelwise test errors using essentially loopy-belief propagation based surrogate likelihood. [sent-215, score-0.25]
</p><p>83 ) Test Loss Training Loss Surrogate likelihood Clique likelihood Univariate likelihood Smooth Class. [sent-217, score-0.357]
</p><p>84 Error likelihood likelihood likelihood Error  Train Test  Train Test  Train Test  Train Test  Train Test  Train Test  . [sent-221, score-0.357]
</p><p>85 With the Bethe approximation, perturbation performs similarly to BBP. [sent-286, score-0.119]
</p><p>86 Enforcing translation invariance gives a total of eight free parameters: four for a(yi , yj ), and two for b(yi ), and c(yi )1 . [sent-293, score-0.103]
</p><p>87 14, recover derivatives with respect to tied dθ parameters2. [sent-295, score-0.13]
</p><p>88 These are binarized by setting yi = 1 if a pixel is above the image mean, and yi = 0 1. [sent-298, score-0.206]
</p><p>89 The noisy values xi are created by setting xi = yi (1 − t1. [sent-300, score-0.219]
</p><p>90 The surrogate likelihood performs well, in fact beating the best reported results on the bimodal and Gaussian data. [sent-305, score-0.348]
</p><p>91 However, the univariate and clique loss functions provide better univariate accuracy. [sent-306, score-0.682]
</p><p>92 The surrogate likelihood (which is convex), was used to initialize the univariate and clique likelihood, while the univariate likelihood was used to initialize the smooth classiﬁcation error. [sent-309, score-0.961]
</p><p>93 Belief optimization for binary networks: A stable alternative to loopy belief propagation. [sent-332, score-0.179]
</p><p>94 CCCP algorithms to minimize the Bethe and Kikuchi free energies: Convergent alternatives to belief propagation. [sent-338, score-0.16]
</p><p>95 Constructing free energy approximations and generalized belief propagation algorithms. [sent-347, score-0.256]
</p><p>96 Convexity arguments for eﬃcient minimization of the bethe and kikuchi free energies. [sent-356, score-0.424]
</p><p>97 Constrained approximate maximum entropy learning of markov random ﬁelds. [sent-363, score-0.25]
</p><p>98 Convergent message-passing algorithms for inference over general graphs with convex free energies. [sent-366, score-0.197]
</p><p>99 Exploiting inference for approximate parameter learning in discriminative ﬁelds: An empirical study. [sent-386, score-0.166]
</p><p>100 Accelerated training of conditional random ﬁelds with stochastic gradient methods. [sent-395, score-0.095]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('dl', 0.333), ('bethe', 0.323), ('bbp', 0.257), ('univariate', 0.231), ('di', 0.215), ('entropy', 0.197), ('marginals', 0.192), ('erentiation', 0.171), ('trw', 0.171), ('surrogate', 0.154), ('trws', 0.143), ('perturbation', 0.119), ('likelihood', 0.119), ('entropies', 0.117), ('loss', 0.113), ('inference', 0.113), ('belief', 0.109), ('polytope', 0.109), ('clique', 0.107), ('marginal', 0.106), ('yi', 0.103), ('erent', 0.102), ('erentiable', 0.1), ('propagation', 0.096), ('symmlq', 0.086), ('implicit', 0.084), ('grid', 0.079), ('bimodal', 0.075), ('heskes', 0.075), ('loopy', 0.07), ('perturbed', 0.066), ('bp', 0.064), ('uai', 0.062), ('convergent', 0.061), ('tied', 0.061), ('ci', 0.061), ('xi', 0.058), ('gradient', 0.058), ('concave', 0.057), ('domke', 0.057), ('libdai', 0.057), ('pert', 0.057), ('sanjiv', 0.057), ('bd', 0.056), ('graphical', 0.055), ('treewidth', 0.054), ('approximate', 0.053), ('strengths', 0.053), ('yj', 0.052), ('free', 0.051), ('kikuchi', 0.05), ('base', 0.047), ('running', 0.047), ('justin', 0.046), ('derivative', 0.045), ('misspeci', 0.043), ('gross', 0.043), ('erence', 0.043), ('erences', 0.043), ('martial', 0.043), ('parametrized', 0.043), ('ganapathi', 0.041), ('message', 0.04), ('whye', 0.039), ('yee', 0.039), ('calculating', 0.039), ('arg', 0.039), ('solvers', 0.038), ('train', 0.038), ('derivatives', 0.038), ('calls', 0.038), ('conditional', 0.037), ('martin', 0.036), ('twice', 0.036), ('varying', 0.035), ('beliefs', 0.035), ('da', 0.035), ('inde', 0.035), ('amir', 0.035), ('yair', 0.035), ('obey', 0.034), ('graphs', 0.033), ('interaction', 0.033), ('globerson', 0.033), ('berkeley', 0.033), ('messages', 0.032), ('direct', 0.032), ('local', 0.032), ('tom', 0.031), ('recover', 0.031), ('inversion', 0.031), ('equality', 0.03), ('versions', 0.03), ('alan', 0.03), ('max', 0.03), ('poorly', 0.03), ('extremely', 0.03), ('paired', 0.029), ('kumar', 0.029), ('kakade', 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999988 <a title="118-tfidf-1" href="./nips-2010-Implicit_Differentiation_by_Perturbation.html">118 nips-2010-Implicit Differentiation by Perturbation</a></p>
<p>Author: Justin Domke</p><p>Abstract: This paper proposes a simple and eﬃcient ﬁnite diﬀerence method for implicit diﬀerentiation of marginal inference results in discrete graphical models. Given an arbitrary loss function, deﬁned on marginals, we show that the derivatives of this loss with respect to model parameters can be obtained by running the inference procedure twice, on slightly perturbed model parameters. This method can be used with approximate inference, with a loss function over approximate marginals. Convenient choices of loss functions make it practical to ﬁt graphical models with hidden variables, high treewidth and/or model misspeciﬁcation. 1</p><p>2 0.14345311 <a title="118-tfidf-2" href="./nips-2010-A_Primal-Dual_Message-Passing_Algorithm_for_Approximated_Large_Scale_Structured_Prediction.html">13 nips-2010-A Primal-Dual Message-Passing Algorithm for Approximated Large Scale Structured Prediction</a></p>
<p>Author: Tamir Hazan, Raquel Urtasun</p><p>Abstract: In this paper we propose an approximated structured prediction framework for large scale graphical models and derive message-passing algorithms for learning their parameters efﬁciently. We ﬁrst relate CRFs and structured SVMs and show that in CRFs a variant of the log-partition function, known as the soft-max, smoothly approximates the hinge loss function of structured SVMs. We then propose an intuitive approximation for the structured prediction problem, using duality, based on a local entropy approximation and derive an efﬁcient messagepassing algorithm that is guaranteed to converge. Unlike existing approaches, this allows us to learn efﬁciently graphical models with cycles and very large number of parameters. 1</p><p>3 0.12920478 <a title="118-tfidf-3" href="./nips-2010-Slice_sampling_covariance_hyperparameters_of_latent_Gaussian_models.html">242 nips-2010-Slice sampling covariance hyperparameters of latent Gaussian models</a></p>
<p>Author: Iain Murray, Ryan P. Adams</p><p>Abstract: The Gaussian process (GP) is a popular way to specify dependencies between random variables in a probabilistic model. In the Bayesian framework the covariance structure can be speciﬁed using unknown hyperparameters. Integrating over these hyperparameters considers diﬀerent possible explanations for the data when making predictions. This integration is often performed using Markov chain Monte Carlo (MCMC) sampling. However, with non-Gaussian observations standard hyperparameter sampling approaches require careful tuning and may converge slowly. In this paper we present a slice sampling approach that requires little tuning while mixing well in both strong- and weak-data regimes. 1</p><p>4 0.12462141 <a title="118-tfidf-4" href="./nips-2010-Learning_Efficient_Markov_Networks.html">144 nips-2010-Learning Efficient Markov Networks</a></p>
<p>Author: Vibhav Gogate, William Webb, Pedro Domingos</p><p>Abstract: We present an algorithm for learning high-treewidth Markov networks where inference is still tractable. This is made possible by exploiting context-speciﬁc independence and determinism in the domain. The class of models our algorithm can learn has the same desirable properties as thin junction trees: polynomial inference, closed-form weight learning, etc., but is much broader. Our algorithm searches for a feature that divides the state space into subspaces where the remaining variables decompose into independent subsets (conditioned on the feature and its negation) and recurses on each subspace/subset of variables until no useful new features can be found. We provide probabilistic performance guarantees for our algorithm under the assumption that the maximum feature length is bounded by a constant k (the treewidth can be much larger) and dependences are of bounded strength. We also propose a greedy version of the algorithm that, while forgoing these guarantees, is much more efﬁcient. Experiments on a variety of domains show that our approach outperforms many state-of-the-art Markov network structure learners. 1</p><p>5 0.11747117 <a title="118-tfidf-5" href="./nips-2010-Computing_Marginal_Distributions_over_Continuous_Markov_Networks_for_Statistical_Relational_Learning.html">49 nips-2010-Computing Marginal Distributions over Continuous Markov Networks for Statistical Relational Learning</a></p>
<p>Author: Matthias Broecheler, Lise Getoor</p><p>Abstract: Continuous Markov random ﬁelds are a general formalism to model joint probability distributions over events with continuous outcomes. We prove that marginal computation for constrained continuous MRFs is #P-hard in general and present a polynomial-time approximation scheme under mild assumptions on the structure of the random ﬁeld. Moreover, we introduce a sampling algorithm to compute marginal distributions and develop novel techniques to increase its efﬁciency. Continuous MRFs are a general purpose probabilistic modeling tool and we demonstrate how they can be applied to statistical relational learning. On the problem of collective classiﬁcation, we evaluate our algorithm and show that the standard deviation of marginals serves as a useful measure of conﬁdence. 1</p><p>6 0.11156607 <a title="118-tfidf-6" href="./nips-2010-Sidestepping_Intractable_Inference_with_Structured_Ensemble_Cascades.html">239 nips-2010-Sidestepping Intractable Inference with Structured Ensemble Cascades</a></p>
<p>7 0.10905297 <a title="118-tfidf-7" href="./nips-2010-Variational_Inference_over_Combinatorial_Spaces.html">283 nips-2010-Variational Inference over Combinatorial Spaces</a></p>
<p>8 0.098431095 <a title="118-tfidf-8" href="./nips-2010-Structured_Determinantal_Point_Processes.html">257 nips-2010-Structured Determinantal Point Processes</a></p>
<p>9 0.094414301 <a title="118-tfidf-9" href="./nips-2010-More_data_means_less_inference%3A_A_pseudo-max_approach_to_structured_learning.html">169 nips-2010-More data means less inference: A pseudo-max approach to structured learning</a></p>
<p>10 0.090644389 <a title="118-tfidf-10" href="./nips-2010-Fast_global_convergence_rates_of_gradient_methods_for_high-dimensional_statistical_recovery.html">92 nips-2010-Fast global convergence rates of gradient methods for high-dimensional statistical recovery</a></p>
<p>11 0.085507311 <a title="118-tfidf-11" href="./nips-2010-Relaxed_Clipping%3A_A_Global_Training_Method_for_Robust_Regression_and_Classification.html">225 nips-2010-Relaxed Clipping: A Global Training Method for Robust Regression and Classification</a></p>
<p>12 0.08101584 <a title="118-tfidf-12" href="./nips-2010-Copula_Bayesian_Networks.html">53 nips-2010-Copula Bayesian Networks</a></p>
<p>13 0.079878889 <a title="118-tfidf-13" href="./nips-2010-Convex_Multiple-Instance_Learning_by_Estimating_Likelihood_Ratio.html">52 nips-2010-Convex Multiple-Instance Learning by Estimating Likelihood Ratio</a></p>
<p>14 0.078046724 <a title="118-tfidf-14" href="./nips-2010-Inference_with_Multivariate_Heavy-Tails_in_Linear_Models.html">126 nips-2010-Inference with Multivariate Heavy-Tails in Linear Models</a></p>
<p>15 0.076489545 <a title="118-tfidf-15" href="./nips-2010-Gaussian_sampling_by_local_perturbations.html">101 nips-2010-Gaussian sampling by local perturbations</a></p>
<p>16 0.075677298 <a title="118-tfidf-16" href="./nips-2010-Multitask_Learning_without_Label_Correspondences.html">177 nips-2010-Multitask Learning without Label Correspondences</a></p>
<p>17 0.073604159 <a title="118-tfidf-17" href="./nips-2010-Approximate_inference_in_continuous_time_Gaussian-Jump_processes.html">33 nips-2010-Approximate inference in continuous time Gaussian-Jump processes</a></p>
<p>18 0.073381826 <a title="118-tfidf-18" href="./nips-2010-Estimation_of_Renyi_Entropy_and_Mutual_Information_Based_on_Generalized_Nearest-Neighbor_Graphs.html">80 nips-2010-Estimation of Renyi Entropy and Mutual Information Based on Generalized Nearest-Neighbor Graphs</a></p>
<p>19 0.072199076 <a title="118-tfidf-19" href="./nips-2010-Approximate_Inference_by_Compilation_to_Arithmetic_Circuits.html">32 nips-2010-Approximate Inference by Compilation to Arithmetic Circuits</a></p>
<p>20 0.070637897 <a title="118-tfidf-20" href="./nips-2010-Evidence-Specific_Structures_for_Rich_Tractable_CRFs.html">83 nips-2010-Evidence-Specific Structures for Rich Tractable CRFs</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.206), (1, 0.053), (2, 0.054), (3, 0.006), (4, -0.085), (5, 0.006), (6, -0.033), (7, 0.052), (8, 0.054), (9, -0.026), (10, -0.196), (11, -0.066), (12, 0.09), (13, 0.005), (14, -0.089), (15, -0.033), (16, -0.001), (17, 0.03), (18, 0.053), (19, -0.012), (20, -0.025), (21, -0.033), (22, 0.082), (23, -0.124), (24, -0.055), (25, -0.14), (26, 0.083), (27, -0.114), (28, 0.101), (29, 0.018), (30, 0.014), (31, -0.073), (32, -0.031), (33, 0.0), (34, -0.023), (35, 0.032), (36, -0.144), (37, -0.044), (38, 0.04), (39, -0.051), (40, 0.015), (41, 0.009), (42, 0.002), (43, -0.034), (44, 0.09), (45, -0.057), (46, 0.004), (47, -0.016), (48, 0.026), (49, -0.083)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94181228 <a title="118-lsi-1" href="./nips-2010-Implicit_Differentiation_by_Perturbation.html">118 nips-2010-Implicit Differentiation by Perturbation</a></p>
<p>Author: Justin Domke</p><p>Abstract: This paper proposes a simple and eﬃcient ﬁnite diﬀerence method for implicit diﬀerentiation of marginal inference results in discrete graphical models. Given an arbitrary loss function, deﬁned on marginals, we show that the derivatives of this loss with respect to model parameters can be obtained by running the inference procedure twice, on slightly perturbed model parameters. This method can be used with approximate inference, with a loss function over approximate marginals. Convenient choices of loss functions make it practical to ﬁt graphical models with hidden variables, high treewidth and/or model misspeciﬁcation. 1</p><p>2 0.75133079 <a title="118-lsi-2" href="./nips-2010-A_Primal-Dual_Message-Passing_Algorithm_for_Approximated_Large_Scale_Structured_Prediction.html">13 nips-2010-A Primal-Dual Message-Passing Algorithm for Approximated Large Scale Structured Prediction</a></p>
<p>Author: Tamir Hazan, Raquel Urtasun</p><p>Abstract: In this paper we propose an approximated structured prediction framework for large scale graphical models and derive message-passing algorithms for learning their parameters efﬁciently. We ﬁrst relate CRFs and structured SVMs and show that in CRFs a variant of the log-partition function, known as the soft-max, smoothly approximates the hinge loss function of structured SVMs. We then propose an intuitive approximation for the structured prediction problem, using duality, based on a local entropy approximation and derive an efﬁcient messagepassing algorithm that is guaranteed to converge. Unlike existing approaches, this allows us to learn efﬁciently graphical models with cycles and very large number of parameters. 1</p><p>3 0.69014442 <a title="118-lsi-3" href="./nips-2010-Variational_Inference_over_Combinatorial_Spaces.html">283 nips-2010-Variational Inference over Combinatorial Spaces</a></p>
<p>Author: Alexandre Bouchard-côté, Michael I. Jordan</p><p>Abstract: Since the discovery of sophisticated fully polynomial randomized algorithms for a range of #P problems [1, 2, 3], theoretical work on approximate inference in combinatorial spaces has focused on Markov chain Monte Carlo methods. Despite their strong theoretical guarantees, the slow running time of many of these randomized algorithms and the restrictive assumptions on the potentials have hindered the applicability of these algorithms to machine learning. Because of this, in applications to combinatorial spaces simple exact models are often preferred to more complex models that require approximate inference [4]. Variational inference would appear to provide an appealing alternative, given the success of variational methods for graphical models [5]; unfortunately, however, it is not obvious how to develop variational approximations for combinatorial objects such as matchings, partial orders, plane partitions and sequence alignments. We propose a new framework that extends variational inference to a wide range of combinatorial spaces. Our method is based on a simple assumption: the existence of a tractable measure factorization, which we show holds in many examples. Simulations on a range of matching models show that the algorithm is more general and empirically faster than a popular fully polynomial randomized algorithm. We also apply the framework to the problem of multiple alignment of protein sequences, obtaining state-of-the-art results on the BAliBASE dataset [6]. 1</p><p>4 0.6651575 <a title="118-lsi-4" href="./nips-2010-Approximate_Inference_by_Compilation_to_Arithmetic_Circuits.html">32 nips-2010-Approximate Inference by Compilation to Arithmetic Circuits</a></p>
<p>Author: Daniel Lowd, Pedro Domingos</p><p>Abstract: Arithmetic circuits (ACs) exploit context-speciﬁc independence and determinism to allow exact inference even in networks with high treewidth. In this paper, we introduce the ﬁrst ever approximate inference methods using ACs, for domains where exact inference remains intractable. We propose and evaluate a variety of techniques based on exact compilation, forward sampling, AC structure learning, Markov network parameter learning, variational inference, and Gibbs sampling. In experiments on eight challenging real-world domains, we ﬁnd that the methods based on sampling and learning work best: one such method (AC2 -F) is faster and usually more accurate than loopy belief propagation, mean ﬁeld, and Gibbs sampling; another (AC2 -G) has a running time similar to Gibbs sampling but is consistently more accurate than all baselines. 1</p><p>5 0.65693724 <a title="118-lsi-5" href="./nips-2010-Inference_with_Multivariate_Heavy-Tails_in_Linear_Models.html">126 nips-2010-Inference with Multivariate Heavy-Tails in Linear Models</a></p>
<p>Author: Danny Bickson, Carlos Guestrin</p><p>Abstract: Heavy-tailed distributions naturally occur in many real life problems. Unfortunately, it is typically not possible to compute inference in closed-form in graphical models which involve such heavy-tailed distributions. In this work, we propose a novel simple linear graphical model for independent latent random variables, called linear characteristic model (LCM), defined in the characteristic function domain. Using stable distributions, a heavy-tailed family of distributions which is a generalization of Cauchy, L´ vy and Gaussian distrie butions, we show for the first time, how to compute both exact and approximate inference in such a linear multivariate graphical model. LCMs are not limited to stable distributions, in fact LCMs are always defined for any random variables (discrete, continuous or a mixture of both). We provide a realistic problem from the field of computer networks to demonstrate the applicability of our construction. Other potential application is iterative decoding of linear channels with non-Gaussian noise. 1</p><p>6 0.60828394 <a title="118-lsi-6" href="./nips-2010-Sidestepping_Intractable_Inference_with_Structured_Ensemble_Cascades.html">239 nips-2010-Sidestepping Intractable Inference with Structured Ensemble Cascades</a></p>
<p>7 0.60536361 <a title="118-lsi-7" href="./nips-2010-Exact_inference_and_learning_for_cumulative_distribution_functions_on_loopy_graphs.html">84 nips-2010-Exact inference and learning for cumulative distribution functions on loopy graphs</a></p>
<p>8 0.5955497 <a title="118-lsi-8" href="./nips-2010-Structured_Determinantal_Point_Processes.html">257 nips-2010-Structured Determinantal Point Processes</a></p>
<p>9 0.57355946 <a title="118-lsi-9" href="./nips-2010-Lifted_Inference_Seen_from_the_Other_Side_%3A_The_Tractable_Features.html">159 nips-2010-Lifted Inference Seen from the Other Side : The Tractable Features</a></p>
<p>10 0.56196815 <a title="118-lsi-10" href="./nips-2010-Computing_Marginal_Distributions_over_Continuous_Markov_Networks_for_Statistical_Relational_Learning.html">49 nips-2010-Computing Marginal Distributions over Continuous Markov Networks for Statistical Relational Learning</a></p>
<p>11 0.55792046 <a title="118-lsi-11" href="./nips-2010-More_data_means_less_inference%3A_A_pseudo-max_approach_to_structured_learning.html">169 nips-2010-More data means less inference: A pseudo-max approach to structured learning</a></p>
<p>12 0.5541001 <a title="118-lsi-12" href="./nips-2010-Evidence-Specific_Structures_for_Rich_Tractable_CRFs.html">83 nips-2010-Evidence-Specific Structures for Rich Tractable CRFs</a></p>
<p>13 0.54946339 <a title="118-lsi-13" href="./nips-2010-Direct_Loss_Minimization_for_Structured_Prediction.html">61 nips-2010-Direct Loss Minimization for Structured Prediction</a></p>
<p>14 0.54763407 <a title="118-lsi-14" href="./nips-2010-Static_Analysis_of_Binary_Executables_Using_Structural_SVMs.html">255 nips-2010-Static Analysis of Binary Executables Using Structural SVMs</a></p>
<p>15 0.53535426 <a title="118-lsi-15" href="./nips-2010-Heavy-Tailed_Process_Priors_for_Selective_Shrinkage.html">113 nips-2010-Heavy-Tailed Process Priors for Selective Shrinkage</a></p>
<p>16 0.53404367 <a title="118-lsi-16" href="./nips-2010-Approximate_inference_in_continuous_time_Gaussian-Jump_processes.html">33 nips-2010-Approximate inference in continuous time Gaussian-Jump processes</a></p>
<p>17 0.50102317 <a title="118-lsi-17" href="./nips-2010-Parallelized_Stochastic_Gradient_Descent.html">202 nips-2010-Parallelized Stochastic Gradient Descent</a></p>
<p>18 0.49891832 <a title="118-lsi-18" href="./nips-2010-Copula_Bayesian_Networks.html">53 nips-2010-Copula Bayesian Networks</a></p>
<p>19 0.49627772 <a title="118-lsi-19" href="./nips-2010-Copula_Processes.html">54 nips-2010-Copula Processes</a></p>
<p>20 0.47792566 <a title="118-lsi-20" href="./nips-2010-Learning_Efficient_Markov_Networks.html">144 nips-2010-Learning Efficient Markov Networks</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.035), (17, 0.041), (27, 0.038), (30, 0.086), (45, 0.249), (46, 0.244), (50, 0.087), (52, 0.034), (60, 0.045), (77, 0.047), (90, 0.015)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.83824652 <a title="118-lda-1" href="./nips-2010-Tiled_convolutional_neural_networks.html">271 nips-2010-Tiled convolutional neural networks</a></p>
<p>Author: Jiquan Ngiam, Zhenghao Chen, Daniel Chia, Pang W. Koh, Quoc V. Le, Andrew Y. Ng</p><p>Abstract: Convolutional neural networks (CNNs) have been successfully applied to many tasks such as digit and object recognition. Using convolutional (tied) weights signiﬁcantly reduces the number of parameters that have to be learned, and also allows translational invariance to be hard-coded into the architecture. In this paper, we consider the problem of learning invariances, rather than relying on hardcoding. We propose tiled convolution neural networks (Tiled CNNs), which use a regular “tiled” pattern of tied weights that does not require that adjacent hidden units share identical weights, but instead requires only that hidden units k steps away from each other to have tied weights. By pooling over neighboring units, this architecture is able to learn complex invariances (such as scale and rotational invariance) beyond translational invariance. Further, it also enjoys much of CNNs’ advantage of having a relatively small number of learned parameters (such as ease of learning and greater scalability). We provide an efﬁcient learning algorithm for Tiled CNNs based on Topographic ICA, and show that learning complex invariant features allows us to achieve highly competitive results for both the NORB and CIFAR-10 datasets. 1</p><p>same-paper 2 0.82216996 <a title="118-lda-2" href="./nips-2010-Implicit_Differentiation_by_Perturbation.html">118 nips-2010-Implicit Differentiation by Perturbation</a></p>
<p>Author: Justin Domke</p><p>Abstract: This paper proposes a simple and eﬃcient ﬁnite diﬀerence method for implicit diﬀerentiation of marginal inference results in discrete graphical models. Given an arbitrary loss function, deﬁned on marginals, we show that the derivatives of this loss with respect to model parameters can be obtained by running the inference procedure twice, on slightly perturbed model parameters. This method can be used with approximate inference, with a loss function over approximate marginals. Convenient choices of loss functions make it practical to ﬁt graphical models with hidden variables, high treewidth and/or model misspeciﬁcation. 1</p><p>3 0.75433707 <a title="118-lda-3" href="./nips-2010-Computing_Marginal_Distributions_over_Continuous_Markov_Networks_for_Statistical_Relational_Learning.html">49 nips-2010-Computing Marginal Distributions over Continuous Markov Networks for Statistical Relational Learning</a></p>
<p>Author: Matthias Broecheler, Lise Getoor</p><p>Abstract: Continuous Markov random ﬁelds are a general formalism to model joint probability distributions over events with continuous outcomes. We prove that marginal computation for constrained continuous MRFs is #P-hard in general and present a polynomial-time approximation scheme under mild assumptions on the structure of the random ﬁeld. Moreover, we introduce a sampling algorithm to compute marginal distributions and develop novel techniques to increase its efﬁciency. Continuous MRFs are a general purpose probabilistic modeling tool and we demonstrate how they can be applied to statistical relational learning. On the problem of collective classiﬁcation, we evaluate our algorithm and show that the standard deviation of marginals serves as a useful measure of conﬁdence. 1</p><p>4 0.75068635 <a title="118-lda-4" href="./nips-2010-Extended_Bayesian_Information_Criteria_for_Gaussian_Graphical_Models.html">87 nips-2010-Extended Bayesian Information Criteria for Gaussian Graphical Models</a></p>
<p>Author: Rina Foygel, Mathias Drton</p><p>Abstract: Gaussian graphical models with sparsity in the inverse covariance matrix are of signiﬁcant interest in many modern applications. For the problem of recovering the graphical structure, information criteria provide useful optimization objectives for algorithms searching through sets of graphs or for selection of tuning parameters of other methods such as the graphical lasso, which is a likelihood penalization technique. In this paper we establish the consistency of an extended Bayesian information criterion for Gaussian graphical models in a scenario where both the number of variables p and the sample size n grow. Compared to earlier work on the regression case, our treatment allows for growth in the number of non-zero parameters in the true model, which is necessary in order to cover connected graphs. We demonstrate the performance of this criterion on simulated data when used in conjunction with the graphical lasso, and verify that the criterion indeed performs better than either cross-validation or the ordinary Bayesian information criterion when p and the number of non-zero parameters q both scale with n. 1</p><p>5 0.74894387 <a title="118-lda-5" href="./nips-2010-Learning_the_context_of_a_category.html">155 nips-2010-Learning the context of a category</a></p>
<p>Author: Dan Navarro</p><p>Abstract: This paper outlines a hierarchical Bayesian model for human category learning that learns both the organization of objects into categories, and the context in which this knowledge should be applied. The model is ﬁt to multiple data sets, and provides a parsimonious method for describing how humans learn context speciﬁc conceptual representations.</p><p>6 0.74871296 <a title="118-lda-6" href="./nips-2010-Distributed_Dual_Averaging_In_Networks.html">63 nips-2010-Distributed Dual Averaging In Networks</a></p>
<p>7 0.74866939 <a title="118-lda-7" href="./nips-2010-Structured_Determinantal_Point_Processes.html">257 nips-2010-Structured Determinantal Point Processes</a></p>
<p>8 0.74755168 <a title="118-lda-8" href="./nips-2010-Learning_Networks_of_Stochastic_Differential_Equations.html">148 nips-2010-Learning Networks of Stochastic Differential Equations</a></p>
<p>9 0.74661815 <a title="118-lda-9" href="./nips-2010-Worst-Case_Linear_Discriminant_Analysis.html">287 nips-2010-Worst-Case Linear Discriminant Analysis</a></p>
<p>10 0.7464425 <a title="118-lda-10" href="./nips-2010-Parallelized_Stochastic_Gradient_Descent.html">202 nips-2010-Parallelized Stochastic Gradient Descent</a></p>
<p>11 0.74545401 <a title="118-lda-11" href="./nips-2010-Smoothness%2C_Low_Noise_and_Fast_Rates.html">243 nips-2010-Smoothness, Low Noise and Fast Rates</a></p>
<p>12 0.7441262 <a title="118-lda-12" href="./nips-2010-Fast_global_convergence_rates_of_gradient_methods_for_high-dimensional_statistical_recovery.html">92 nips-2010-Fast global convergence rates of gradient methods for high-dimensional statistical recovery</a></p>
<p>13 0.74242795 <a title="118-lda-13" href="./nips-2010-Exact_learning_curves_for_Gaussian_process_regression_on_large_random_graphs.html">85 nips-2010-Exact learning curves for Gaussian process regression on large random graphs</a></p>
<p>14 0.74220675 <a title="118-lda-14" href="./nips-2010-Sidestepping_Intractable_Inference_with_Structured_Ensemble_Cascades.html">239 nips-2010-Sidestepping Intractable Inference with Structured Ensemble Cascades</a></p>
<p>15 0.74209392 <a title="118-lda-15" href="./nips-2010-A_Primal-Dual_Message-Passing_Algorithm_for_Approximated_Large_Scale_Structured_Prediction.html">13 nips-2010-A Primal-Dual Message-Passing Algorithm for Approximated Large Scale Structured Prediction</a></p>
<p>16 0.7415123 <a title="118-lda-16" href="./nips-2010-Probabilistic_Inference_and_Differential_Privacy.html">216 nips-2010-Probabilistic Inference and Differential Privacy</a></p>
<p>17 0.74112576 <a title="118-lda-17" href="./nips-2010-Construction_of_Dependent_Dirichlet_Processes_based_on_Poisson_Processes.html">51 nips-2010-Construction of Dependent Dirichlet Processes based on Poisson Processes</a></p>
<p>18 0.74036574 <a title="118-lda-18" href="./nips-2010-MAP_Estimation_for_Graphical_Models_by_Likelihood_Maximization.html">164 nips-2010-MAP Estimation for Graphical Models by Likelihood Maximization</a></p>
<p>19 0.74029368 <a title="118-lda-19" href="./nips-2010-PAC-Bayesian_Model_Selection_for_Reinforcement_Learning.html">201 nips-2010-PAC-Bayesian Model Selection for Reinforcement Learning</a></p>
<p>20 0.73980653 <a title="118-lda-20" href="./nips-2010-t-logistic_regression.html">290 nips-2010-t-logistic regression</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
