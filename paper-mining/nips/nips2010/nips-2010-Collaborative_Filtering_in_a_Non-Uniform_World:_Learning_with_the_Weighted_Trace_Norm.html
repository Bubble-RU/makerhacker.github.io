<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>48 nips-2010-Collaborative Filtering in a Non-Uniform World: Learning with the Weighted Trace Norm</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-48" href="#">nips2010-48</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>48 nips-2010-Collaborative Filtering in a Non-Uniform World: Learning with the Weighted Trace Norm</h1>
<br/><p>Source: <a title="nips-2010-48-pdf" href="http://papers.nips.cc/paper/4102-collaborative-filtering-in-a-non-uniform-world-learning-with-the-weighted-trace-norm.pdf">pdf</a></p><p>Author: Nathan Srebro, Ruslan Salakhutdinov</p><p>Abstract: We show that matrix completion with trace-norm regularization can be signiﬁcantly hurt when entries of the matrix are sampled non-uniformly, but that a properly weighted version of the trace-norm regularizer works well with non-uniform sampling. We show that the weighted trace-norm regularization indeed yields signiﬁcant gains on the highly non-uniformly sampled Netﬂix dataset.</p><p>Reference: <a title="nips-2010-48-reference" href="../nips2010_reference/nips-2010-Collaborative_Filtering_in_a_Non-Uniform_World%3A_Learning_with_the_Weighted_Trace_Norm_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('tc', 0.601), ('ys', 0.364), ('tr', 0.219), ('na', 0.212), ('rank', 0.172), ('xb', 0.17), ('ix', 0.166), ('movy', 0.142), ('shat', 0.136), ('xa', 0.118), ('net', 0.117), ('nb', 0.111), ('tcpq', 0.11), ('weim', 0.097), ('collab', 0.094), ('unweight', 0.089), ('matrix', 0.088), ('entry', 0.088), ('detery', 0.084), ('xs', 0.081)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="48-tfidf-1" href="./nips-2010-Collaborative_Filtering_in_a_Non-Uniform_World%3A_Learning_with_the_Weighted_Trace_Norm.html">48 nips-2010-Collaborative Filtering in a Non-Uniform World: Learning with the Weighted Trace Norm</a></p>
<p>Author: Nathan Srebro, Ruslan Salakhutdinov</p><p>Abstract: We show that matrix completion with trace-norm regularization can be signiﬁcantly hurt when entries of the matrix are sampled non-uniformly, but that a properly weighted version of the trace-norm regularizer works well with non-uniform sampling. We show that the weighted trace-norm regularization indeed yields signiﬁcant gains on the highly non-uniformly sampled Netﬂix dataset.</p><p>2 0.1459884 <a title="48-tfidf-2" href="./nips-2010-Practical_Large-Scale_Optimization_for_Max-norm_Regularization.html">210 nips-2010-Practical Large-Scale Optimization for Max-norm Regularization</a></p>
<p>Author: Jason Lee, Ben Recht, Nathan Srebro, Joel Tropp, Ruslan Salakhutdinov</p><p>Abstract: The max-norm was proposed as a convex matrix regularizer in [1] and was shown to be empirically superior to the trace-norm for collaborative ﬁltering problems. Although the max-norm can be computed in polynomial time, there are currently no practical algorithms for solving large-scale optimization problems that incorporate the max-norm. The present work uses a factorization technique of Burer and Monteiro [2] to devise scalable ﬁrst-order algorithms for convex programs involving the max-norm. These algorithms are applied to solve huge collaborative ﬁltering, graph cut, and clustering problems. Empirically, the new methods outperform mature techniques from all three areas. 1</p><p>3 0.11620295 <a title="48-tfidf-3" href="./nips-2010-Worst-Case_Linear_Discriminant_Analysis.html">287 nips-2010-Worst-Case Linear Discriminant Analysis</a></p>
<p>Author: Yu Zhang, Dit-Yan Yeung</p><p>Abstract: Dimensionality reduction is often needed in many applications due to the high dimensionality of the data involved. In this paper, we ďŹ rst analyze the scatter measures used in the conventional linear discriminant analysis (LDA) model and note that the formulation is based on the average-case view. Based on this analysis, we then propose a new dimensionality reduction method called worst-case linear discriminant analysis (WLDA) by deďŹ ning new between-class and within-class scatter measures. This new model adopts the worst-case view which arguably is more suitable for applications such as classiďŹ cation. When the number of training data points or the number of features is not very large, we relax the optimization problem involved and formulate it as a metric learning problem. Otherwise, we take a greedy approach by ďŹ nding one direction of the transformation at a time. Moreover, we also analyze a special case of WLDA to show its relationship with conventional LDA. Experiments conducted on several benchmark datasets demonstrate the effectiveness of WLDA when compared with some related dimensionality reduction methods. 1</p><p>4 0.11520976 <a title="48-tfidf-4" href="./nips-2010-Link_Discovery_using_Graph_Feature_Tracking.html">162 nips-2010-Link Discovery using Graph Feature Tracking</a></p>
<p>Author: Emile Richard, Nicolas Baskiotis, Theodoros Evgeniou, Nicolas Vayatis</p><p>Abstract: We consider the problem of discovering links of an evolving undirected graph given a series of past snapshots of that graph. The graph is observed through the time sequence of its adjacency matrix and only the presence of edges is observed. The absence of an edge on a certain snapshot cannot be distinguished from a missing entry in the adjacency matrix. Additional information can be provided by examining the dynamics of the graph through a set of topological features, such as the degrees of the vertices. We develop a novel methodology by building on both static matrix completion methods and the estimation of the future state of relevant graph features. Our procedure relies on the formulation of an optimization problem which can be approximately solved by a fast alternating linearized algorithm whose properties are examined. We show experiments with both simulated and real data which reveal the interest of our methodology. 1</p><p>5 0.10213328 <a title="48-tfidf-5" href="./nips-2010-Tight_Sample_Complexity_of_Large-Margin_Learning.html">270 nips-2010-Tight Sample Complexity of Large-Margin Learning</a></p>
<p>Author: Sivan Sabato, Nathan Srebro, Naftali Tishby</p><p>Abstract: We obtain a tight distribution-speciﬁc characterization of the sample complexity of large-margin classiﬁcation with L2 regularization: We introduce the γ-adapted-dimension, which is a simple function of the spectrum of a distribution’s covariance matrix, and show distribution-speciﬁc upper and lower bounds on the sample complexity, both governed by the γ-adapted-dimension of the source distribution. We conclude that this new quantity tightly characterizes the true sample complexity of large-margin classiﬁcation. The bounds hold for a rich family of sub-Gaussian distributions. 1</p><p>6 0.088165216 <a title="48-tfidf-6" href="./nips-2010-Online_Learning_in_The_Manifold_of_Low-Rank_Matrices.html">195 nips-2010-Online Learning in The Manifold of Low-Rank Matrices</a></p>
<p>7 0.086627655 <a title="48-tfidf-7" href="./nips-2010-Transduction_with_Matrix_Completion%3A_Three_Birds_with_One_Stone.html">275 nips-2010-Transduction with Matrix Completion: Three Birds with One Stone</a></p>
<p>8 0.082878791 <a title="48-tfidf-8" href="./nips-2010-Active_Learning_by_Querying_Informative_and_Representative_Examples.html">25 nips-2010-Active Learning by Querying Informative and Representative Examples</a></p>
<p>9 0.080923893 <a title="48-tfidf-9" href="./nips-2010-Near-Optimal_Bayesian_Active_Learning_with_Noisy_Observations.html">180 nips-2010-Near-Optimal Bayesian Active Learning with Noisy Observations</a></p>
<p>10 0.079573534 <a title="48-tfidf-10" href="./nips-2010-Learning_Multiple_Tasks_with_a_Sparse_Matrix-Normal_Penalty.html">147 nips-2010-Learning Multiple Tasks with a Sparse Matrix-Normal Penalty</a></p>
<p>11 0.070914574 <a title="48-tfidf-11" href="./nips-2010-Simultaneous_Object_Detection_and_Ranking_with_Weak_Supervision.html">240 nips-2010-Simultaneous Object Detection and Ranking with Weak Supervision</a></p>
<p>12 0.070313253 <a title="48-tfidf-12" href="./nips-2010-Sample_Complexity_of_Testing_the_Manifold_Hypothesis.html">232 nips-2010-Sample Complexity of Testing the Manifold Hypothesis</a></p>
<p>13 0.069654435 <a title="48-tfidf-13" href="./nips-2010-Optimal_learning_rates_for_Kernel_Conjugate_Gradient_regression.html">199 nips-2010-Optimal learning rates for Kernel Conjugate Gradient regression</a></p>
<p>14 0.067707159 <a title="48-tfidf-14" href="./nips-2010-Efficient_Optimization_for_Discriminative_Latent_Class_Models.html">70 nips-2010-Efficient Optimization for Discriminative Latent Class Models</a></p>
<p>15 0.066641919 <a title="48-tfidf-15" href="./nips-2010-An_analysis_on_negative_curvature_induced_by_singularity_in_multi-layer_neural-network_learning.html">31 nips-2010-An analysis on negative curvature induced by singularity in multi-layer neural-network learning</a></p>
<p>16 0.064677589 <a title="48-tfidf-16" href="./nips-2010-Large-Scale_Matrix_Factorization_with_Missing_Data_under_Additional_Constraints.html">136 nips-2010-Large-Scale Matrix Factorization with Missing Data under Additional Constraints</a></p>
<p>17 0.063616611 <a title="48-tfidf-17" href="./nips-2010-Inductive_Regularized_Learning_of_Kernel_Functions.html">124 nips-2010-Inductive Regularized Learning of Kernel Functions</a></p>
<p>18 0.063602462 <a title="48-tfidf-18" href="./nips-2010-Worst-case_bounds_on_the_quality_of_max-product_fixed-points.html">288 nips-2010-Worst-case bounds on the quality of max-product fixed-points</a></p>
<p>19 0.062650613 <a title="48-tfidf-19" href="./nips-2010-Identifying_graph-structured_activation_patterns_in_networks.html">117 nips-2010-Identifying graph-structured activation patterns in networks</a></p>
<p>20 0.062309895 <a title="48-tfidf-20" href="./nips-2010-Infinite_Relational_Modeling_of_Functional_Connectivity_in_Resting_State_fMRI.html">128 nips-2010-Infinite Relational Modeling of Functional Connectivity in Resting State fMRI</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.17), (1, -0.049), (2, 0.032), (3, -0.07), (4, -0.006), (5, 0.037), (6, 0.031), (7, -0.004), (8, 0.022), (9, -0.072), (10, 0.027), (11, 0.009), (12, -0.013), (13, -0.069), (14, -0.11), (15, 0.054), (16, -0.036), (17, -0.002), (18, 0.047), (19, 0.112), (20, -0.06), (21, 0.129), (22, 0.038), (23, 0.079), (24, 0.13), (25, 0.085), (26, 0.017), (27, -0.006), (28, -0.0), (29, 0.004), (30, -0.127), (31, 0.066), (32, -0.024), (33, -0.047), (34, -0.053), (35, 0.048), (36, -0.018), (37, 0.082), (38, -0.008), (39, 0.013), (40, -0.085), (41, 0.121), (42, -0.08), (43, -0.027), (44, 0.051), (45, -0.076), (46, 0.035), (47, -0.157), (48, 0.067), (49, 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.91069132 <a title="48-lsi-1" href="./nips-2010-Collaborative_Filtering_in_a_Non-Uniform_World%3A_Learning_with_the_Weighted_Trace_Norm.html">48 nips-2010-Collaborative Filtering in a Non-Uniform World: Learning with the Weighted Trace Norm</a></p>
<p>Author: Nathan Srebro, Ruslan Salakhutdinov</p><p>Abstract: We show that matrix completion with trace-norm regularization can be signiﬁcantly hurt when entries of the matrix are sampled non-uniformly, but that a properly weighted version of the trace-norm regularizer works well with non-uniform sampling. We show that the weighted trace-norm regularization indeed yields signiﬁcant gains on the highly non-uniformly sampled Netﬂix dataset.</p><p>2 0.7945385 <a title="48-lsi-2" href="./nips-2010-Guaranteed_Rank_Minimization_via_Singular_Value_Projection.html">110 nips-2010-Guaranteed Rank Minimization via Singular Value Projection</a></p>
<p>Author: Prateek Jain, Raghu Meka, Inderjit S. Dhillon</p><p>Abstract: Minimizing the rank of a matrix subject to afﬁne constraints is a fundamental problem with many important applications in machine learning and statistics. In this paper we propose a simple and fast algorithm SVP (Singular Value Projection) for rank minimization under afﬁne constraints (ARMP) and show that SVP recovers the minimum rank solution for afﬁne constraints that satisfy a restricted isometry property (RIP). Our method guarantees geometric convergence rate even in the presence of noise and requires strictly weaker assumptions on the RIP constants than the existing methods. We also introduce a Newton-step for our SVP framework to speed-up the convergence with substantial empirical gains. Next, we address a practically important application of ARMP - the problem of lowrank matrix completion, for which the deﬁning afﬁne constraints do not directly obey RIP, hence the guarantees of SVP do not hold. However, we provide partial progress towards a proof of exact recovery for our algorithm by showing a more restricted isometry property and observe empirically that our algorithm recovers low-rank incoherent matrices from an almost optimal number of uniformly sampled entries. We also demonstrate empirically that our algorithms outperform existing methods, such as those of [5, 18, 14], for ARMP and the matrix completion problem by an order of magnitude and are also more robust to noise and sampling schemes. In particular, results show that our SVP-Newton method is signiﬁcantly robust to noise and performs impressively on a more realistic power-law sampling scheme for the matrix completion problem. 1</p><p>3 0.73972666 <a title="48-lsi-3" href="./nips-2010-Large-Scale_Matrix_Factorization_with_Missing_Data_under_Additional_Constraints.html">136 nips-2010-Large-Scale Matrix Factorization with Missing Data under Additional Constraints</a></p>
<p>Author: Kaushik Mitra, Sameer Sheorey, Rama Chellappa</p><p>Abstract: Matrix factorization in the presence of missing data is at the core of many computer vision problems such as structure from motion (SfM), non-rigid SfM and photometric stereo. We formulate the problem of matrix factorization with missing data as a low-rank semideﬁnite program (LRSDP) with the advantage that: 1) an efﬁcient quasi-Newton implementation of the LRSDP enables us to solve large-scale factorization problems, and 2) additional constraints such as orthonormality, required in orthographic SfM, can be directly incorporated in the new formulation. Our empirical evaluations suggest that, under the conditions of matrix completion theory, the proposed algorithm ﬁnds the optimal solution, and also requires fewer observations compared to the current state-of-the-art algorithms. We further demonstrate the effectiveness of the proposed algorithm in solving the afﬁne SfM problem, non-rigid SfM and photometric stereo problems.</p><p>4 0.61302304 <a title="48-lsi-4" href="./nips-2010-Online_Learning_in_The_Manifold_of_Low-Rank_Matrices.html">195 nips-2010-Online Learning in The Manifold of Low-Rank Matrices</a></p>
<p>Author: Uri Shalit, Daphna Weinshall, Gal Chechik</p><p>Abstract: When learning models that are represented in matrix forms, enforcing a low-rank constraint can dramatically improve the memory and run time complexity, while providing a natural regularization of the model. However, naive approaches for minimizing functions over the set of low-rank matrices are either prohibitively time consuming (repeated singular value decomposition of the matrix) or numerically unstable (optimizing a factored representation of the low rank matrix). We build on recent advances in optimization over manifolds, and describe an iterative online learning procedure, consisting of a gradient step, followed by a second-order retraction back to the manifold. While the ideal retraction is hard to compute, and so is the projection operator that approximates it, we describe another second-order retraction that can be computed efﬁciently, with run time and memory complexity of O ((n + m)k) for a rank-k matrix of dimension m × n, given rank-one gradients. We use this algorithm, LORETA, to learn a matrixform similarity measure over pairs of documents represented as high dimensional vectors. LORETA improves the mean average precision over a passive- aggressive approach in a factorized model, and also improves over a full model trained over pre-selected features using the same memory requirements. LORETA also showed consistent improvement over standard methods in a large (1600 classes) multi-label image classiﬁcation task. 1</p><p>5 0.59636122 <a title="48-lsi-5" href="./nips-2010-Link_Discovery_using_Graph_Feature_Tracking.html">162 nips-2010-Link Discovery using Graph Feature Tracking</a></p>
<p>Author: Emile Richard, Nicolas Baskiotis, Theodoros Evgeniou, Nicolas Vayatis</p><p>Abstract: We consider the problem of discovering links of an evolving undirected graph given a series of past snapshots of that graph. The graph is observed through the time sequence of its adjacency matrix and only the presence of edges is observed. The absence of an edge on a certain snapshot cannot be distinguished from a missing entry in the adjacency matrix. Additional information can be provided by examining the dynamics of the graph through a set of topological features, such as the degrees of the vertices. We develop a novel methodology by building on both static matrix completion methods and the estimation of the future state of relevant graph features. Our procedure relies on the formulation of an optimization problem which can be approximately solved by a fast alternating linearized algorithm whose properties are examined. We show experiments with both simulated and real data which reveal the interest of our methodology. 1</p><p>6 0.57780468 <a title="48-lsi-6" href="./nips-2010-Practical_Large-Scale_Optimization_for_Max-norm_Regularization.html">210 nips-2010-Practical Large-Scale Optimization for Max-norm Regularization</a></p>
<p>7 0.57663012 <a title="48-lsi-7" href="./nips-2010-An_analysis_on_negative_curvature_induced_by_singularity_in_multi-layer_neural-network_learning.html">31 nips-2010-An analysis on negative curvature induced by singularity in multi-layer neural-network learning</a></p>
<p>8 0.5626635 <a title="48-lsi-8" href="./nips-2010-Robust_PCA_via_Outlier_Pursuit.html">231 nips-2010-Robust PCA via Outlier Pursuit</a></p>
<p>9 0.54773533 <a title="48-lsi-9" href="./nips-2010-A_New_Probabilistic_Model_for_Rank_Aggregation.html">9 nips-2010-A New Probabilistic Model for Rank Aggregation</a></p>
<p>10 0.54128945 <a title="48-lsi-10" href="./nips-2010-Worst-Case_Linear_Discriminant_Analysis.html">287 nips-2010-Worst-Case Linear Discriminant Analysis</a></p>
<p>11 0.49346137 <a title="48-lsi-11" href="./nips-2010-Learning_Networks_of_Stochastic_Differential_Equations.html">148 nips-2010-Learning Networks of Stochastic Differential Equations</a></p>
<p>12 0.49239928 <a title="48-lsi-12" href="./nips-2010-Transduction_with_Matrix_Completion%3A_Three_Birds_with_One_Stone.html">275 nips-2010-Transduction with Matrix Completion: Three Birds with One Stone</a></p>
<p>13 0.48439357 <a title="48-lsi-13" href="./nips-2010-Fast_global_convergence_rates_of_gradient_methods_for_high-dimensional_statistical_recovery.html">92 nips-2010-Fast global convergence rates of gradient methods for high-dimensional statistical recovery</a></p>
<p>14 0.46586266 <a title="48-lsi-14" href="./nips-2010-Global_Analytic_Solution_for_Variational_Bayesian_Matrix_Factorization.html">106 nips-2010-Global Analytic Solution for Variational Bayesian Matrix Factorization</a></p>
<p>15 0.43780708 <a title="48-lsi-15" href="./nips-2010-The_LASSO_risk%3A_asymptotic_results_and_real_world_examples.html">265 nips-2010-The LASSO risk: asymptotic results and real world examples</a></p>
<p>16 0.43545854 <a title="48-lsi-16" href="./nips-2010-Effects_of_Synaptic_Weight_Diffusion_on_Learning_in_Decision_Making_Networks.html">68 nips-2010-Effects of Synaptic Weight Diffusion on Learning in Decision Making Networks</a></p>
<p>17 0.43489689 <a title="48-lsi-17" href="./nips-2010-CUR_from_a_Sparse_Optimization_Viewpoint.html">45 nips-2010-CUR from a Sparse Optimization Viewpoint</a></p>
<p>18 0.42969576 <a title="48-lsi-18" href="./nips-2010-Tight_Sample_Complexity_of_Large-Margin_Learning.html">270 nips-2010-Tight Sample Complexity of Large-Margin Learning</a></p>
<p>19 0.42712873 <a title="48-lsi-19" href="./nips-2010-Sparse_Inverse_Covariance_Selection_via_Alternating_Linearization_Methods.html">248 nips-2010-Sparse Inverse Covariance Selection via Alternating Linearization Methods</a></p>
<p>20 0.42261484 <a title="48-lsi-20" href="./nips-2010-Efficient_and_Robust_Feature_Selection_via_Joint_%E2%84%932%2C1-Norms_Minimization.html">73 nips-2010-Efficient and Robust Feature Selection via Joint ℓ2,1-Norms Minimization</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(7, 0.109), (30, 0.456), (32, 0.071), (34, 0.12), (45, 0.051), (54, 0.01), (68, 0.081)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.82385468 <a title="48-lda-1" href="./nips-2010-Approximate_inference_in_continuous_time_Gaussian-Jump_processes.html">33 nips-2010-Approximate inference in continuous time Gaussian-Jump processes</a></p>
<p>Author: Manfred Opper, Andreas Ruttor, Guido Sanguinetti</p><p>Abstract: We present a novel approach to inference in conditionally Gaussian continuous time stochastic processes, where the latent process is a Markovian jump process. We ﬁrst consider the case of jump-diffusion processes, where the drift of a linear stochastic differential equation can jump at arbitrary time points. We derive partial differential equations for exact inference and present a very efﬁcient mean ﬁeld approximation. By introducing a novel lower bound on the free energy, we then generalise our approach to Gaussian processes with arbitrary covariance, such as the non-Markovian RBF covariance. We present results on both simulated and real data, showing that the approach is very accurate in capturing latent dynamics and can be useful in a number of real data modelling tasks.</p><p>same-paper 2 0.79690206 <a title="48-lda-2" href="./nips-2010-Collaborative_Filtering_in_a_Non-Uniform_World%3A_Learning_with_the_Weighted_Trace_Norm.html">48 nips-2010-Collaborative Filtering in a Non-Uniform World: Learning with the Weighted Trace Norm</a></p>
<p>Author: Nathan Srebro, Ruslan Salakhutdinov</p><p>Abstract: We show that matrix completion with trace-norm regularization can be signiﬁcantly hurt when entries of the matrix are sampled non-uniformly, but that a properly weighted version of the trace-norm regularizer works well with non-uniform sampling. We show that the weighted trace-norm regularization indeed yields signiﬁcant gains on the highly non-uniformly sampled Netﬂix dataset.</p><p>3 0.7828154 <a title="48-lda-3" href="./nips-2010-Learning_Networks_of_Stochastic_Differential_Equations.html">148 nips-2010-Learning Networks of Stochastic Differential Equations</a></p>
<p>Author: José Pereira, Morteza Ibrahimi, Andrea Montanari</p><p>Abstract: We consider linear models for stochastic dynamics. To any such model can be associated a network (namely a directed graph) describing which degrees of freedom interact under the dynamics. We tackle the problem of learning such a network from observation of the system trajectory over a time interval T . We analyze the ℓ1 -regularized least squares algorithm and, in the setting in which the underlying network is sparse, we prove performance guarantees that are uniform in the sampling rate as long as this is sufﬁciently high. This result substantiates the notion of a well deﬁned ‘time complexity’ for the network inference problem. keywords: Gaussian processes, model selection and structure learning, graphical models, sparsity and feature selection. 1 Introduction and main results Let G = (V, E) be a directed graph with weight A0 ∈ R associated to the directed edge (j, i) from ij j ∈ V to i ∈ V . To each node i ∈ V in this network is associated an independent standard Brownian motion bi and a variable xi taking values in R and evolving according to A0 xj (t) dt + dbi (t) , ij dxi (t) = j∈∂+ i where ∂+ i = {j ∈ V : (j, i) ∈ E} is the set of ‘parents’ of i. Without loss of generality we shall take V = [p] ≡ {1, . . . , p}. In words, the rate of change of xi is given by a weighted sum of the current values of its neighbors, corrupted by white noise. In matrix notation, the same system is then represented by dx(t) = A0 x(t) dt + db(t) , p (1) 0 p×p with x(t) ∈ R , b(t) a p-dimensional standard Brownian motion and A ∈ R a matrix with entries {A0 }i,j∈[p] whose sparsity pattern is given by the graph G. We assume that the linear system ij x(t) = A0 x(t) is stable (i.e. that the spectrum of A0 is contained in {z ∈ C : Re(z) < 0}). Further, ˙ we assume that x(t = 0) is in its stationary state. More precisely, x(0) is a Gaussian random variable 1 independent of b(t), distributed according to the invariant measure. Under the stability assumption, this a mild restriction, since the system converges exponentially to stationarity. A portion of time length T of the system trajectory {x(t)}t∈[0,T ] is observed and we ask under which conditions these data are sufﬁcient to reconstruct the graph G (i.e., the sparsity pattern of A0 ). We are particularly interested in computationally efﬁcient procedures, and in characterizing the scaling of the learning time for large networks. Can the network structure be learnt in a time scaling linearly with the number of its degrees of freedom? As an example application, chemical reactions can be conveniently modeled by systems of nonlinear stochastic differential equations, whose variables encode the densities of various chemical species [1, 2]. Complex biological networks might involve hundreds of such species [3], and learning stochastic models from data is an important (and challenging) computational task [4]. Considering one such chemical reaction network in proximity of an equilibrium point, the model (1) can be used to trace ﬂuctuations of the species counts with respect to the equilibrium values. The network G would represent in this case the interactions between different chemical factors. Work in this area focused so-far on low-dimensional networks, i.e. on methods that are guaranteed to be correct for ﬁxed p, as T → ∞, while we will tackle here the regime in which both p and T diverge. Before stating our results, it is useful to stress a few important differences with respect to classical graphical model learning problems: (i) Samples are not independent. This can (and does) increase the sample complexity. (ii) On the other hand, inﬁnitely many samples are given as data (in fact a collection indexed by the continuous parameter t ∈ [0, T ]). Of course one can select a ﬁnite subsample, for instance at regularly spaced times {x(i η)}i=0,1,... . This raises the question as to whether the learning performances depend on the choice of the spacing η. (iii) In particular, one expects that choosing η sufﬁciently large as to make the conﬁgurations in the subsample approximately independent can be harmful. Indeed, the matrix A0 contains more information than the stationary distribution of the above process (1), and only the latter can be learned from independent samples. (iv) On the other hand, letting η → 0, one can produce an arbitrarily large number of distinct samples. However, samples become more dependent, and intuitively one expects that there is limited information to be harnessed from a given time interval T . Our results conﬁrm in a detailed and quantitative way these intuitions. 1.1 Results: Regularized least squares Regularized least squares is an efﬁcient and well-studied method for support recovery. We will discuss relations with existing literature in Section 1.3. In the present case, the algorithm reconstructs independently each row of the matrix A0 . The rth row, A0 , is estimated by solving the following convex optimization problem for Ar ∈ Rp r minimize L(Ar ; {x(t)}t∈[0,T ] ) + λ Ar 1 , (2) where the likelihood function L is deﬁned by L(Ar ; {x(t)}t∈[0,T ] ) = 1 2T T 0 (A∗ x(t))2 dt − r 1 T T 0 (A∗ x(t)) dxr (t) . r (3) (Here and below M ∗ denotes the transpose of matrix/vector M .) To see that this likelihood function is indeed related to least squares, one can formally write xr (t) = dxr (t)/dt and complete the square ˙ for the right hand side of Eq. (3), thus getting the integral (A∗ x(t) − xr (t))2 dt − xr (t)2 dt. ˙ ˙ r The ﬁrst term is a sum of square residuals, and the second is independent of A. Finally the ℓ1 regularization term in Eq. (2) has the role of shrinking to 0 a subset of the entries Aij thus effectively selecting the structure. Let S 0 be the support of row A0 , and assume |S 0 | ≤ k. We will refer to the vector sign(A0 ) as to r r the signed support of A0 (where sign(0) = 0 by convention). Let λmax (M ) and λmin (M ) stand for r 2 the maximum and minimum eigenvalue of a square matrix M respectively. Further, denote by Amin the smallest absolute value among the non-zero entries of row A0 . r When stable, the diffusion process (1) has a unique stationary measure which is Gaussian with covariance Q0 ∈ Rp×p given by the solution of Lyapunov’s equation [5] A0 Q0 + Q0 (A0 )∗ + I = 0. (4) Our guarantee for regularized least squares is stated in terms of two properties of the covariance Q0 and one assumption on ρmin (A0 ) (given a matrix M , we denote by ML,R its submatrix ML,R ≡ (Mij )i∈L,j∈R ): (a) We denote by Cmin ≡ λmin (Q0 0 ,S 0 ) the minimum eigenvalue of the restriction of Q0 to S the support S 0 and assume Cmin > 0. (b) We deﬁne the incoherence parameter α by letting |||Q0 (S 0 )C ,S 0 Q0 S 0 ,S 0 and assume α > 0. (Here ||| · |||∞ is the operator sup norm.) −1 |||∞ = 1 − α, ∗ (c) We deﬁne ρmin (A0 ) = −λmax ((A0 + A0 )/2) and assume ρmin (A0 ) > 0. Note this is a stronger form of stability assumption. Our main result is to show that there exists a well deﬁned time complexity, i.e. a minimum time interval T such that, observing the system for time T enables us to reconstruct the network with high probability. This result is stated in the following theorem. Theorem 1.1. Consider the problem of learning the support S 0 of row A0 of the matrix A0 from a r sample trajectory {x(t)}t∈[0,T ] distributed according to the model (1). If T > 104 k 2 (k ρmin (A0 )−2 + A−2 ) 4pk min log , 2 α2 ρmin (A0 )Cmin δ (5) then there exists λ such that ℓ1 -regularized least squares recovers the signed support of A0 with r probability larger than 1 − δ. This is achieved by taking λ = 36 log(4p/δ)/(T α2 ρmin (A0 )) . The time complexity is logarithmic in the number of variables and polynomial in the support size. Further, it is roughly inversely proportional to ρmin (A0 ), which is quite satisfying conceptually, since ρmin (A0 )−1 controls the relaxation time of the mixes. 1.2 Overview of other results So far we focused on continuous-time dynamics. While, this is useful in order to obtain elegant statements, much of the paper is in fact devoted to the analysis of the following discrete-time dynamics, with parameter η > 0: x(t) = x(t − 1) + ηA0 x(t − 1) + w(t), t ∈ N0 . (6) Here x(t) ∈ Rp is the vector collecting the dynamical variables, A0 ∈ Rp×p speciﬁes the dynamics as above, and {w(t)}t≥0 is a sequence of i.i.d. normal vectors with covariance η Ip×p (i.e. with independent components of variance η). We assume that consecutive samples {x(t)}0≤t≤n are given and will ask under which conditions regularized least squares reconstructs the support of A0 . The parameter η has the meaning of a time-step size. The continuous-time model (1) is recovered, in a sense made precise below, by letting η → 0. Indeed we will prove reconstruction guarantees that are uniform in this limit as long as the product nη (which corresponds to the time interval T in the previous section) is kept constant. For a formal statement we refer to Theorem 3.1. Theorem 1.1 is indeed proved by carefully controlling this limit. The mathematical challenge in this problem is related to the fundamental fact that the samples {x(t)}0≤t≤n are dependent (and strongly dependent as η → 0). Discrete time models of the form (6) can arise either because the system under study evolves by discrete steps, or because we are subsampling a continuous time system modeled as in Eq. (1). Notice that in the latter case the matrices A0 appearing in Eq. (6) and (1) coincide only to the zeroth order in η. Neglecting this technical complication, the uniformity of our reconstruction guarantees as η → 0 has an appealing interpretation already mentioned above. Whenever the samples spacing is not too large, the time complexity (i.e. the product nη) is roughly independent of the spacing itself. 3 1.3 Related work A substantial amount of work has been devoted to the analysis of ℓ1 regularized least squares, and its variants [6, 7, 8, 9, 10]. The most closely related results are the one concerning high-dimensional consistency for support recovery [11, 12]. Our proof follows indeed the line of work developed in these papers, with two important challenges. First, the design matrix is in our case produced by a stochastic diffusion, and it does not necessarily satisﬁes the irrepresentability conditions used by these works. Second, the observations are not corrupted by i.i.d. noise (since successive conﬁgurations are correlated) and therefore elementary concentration inequalities are not sufﬁcient. Learning sparse graphical models via ℓ1 regularization is also a topic with signiﬁcant literature. In the Gaussian case, the graphical LASSO was proposed to reconstruct the model from i.i.d. samples [13]. In the context of binary pairwise graphical models, Ref. [11] proves high-dimensional consistency of regularized logistic regression for structural learning, under a suitable irrepresentability conditions on a modiﬁed covariance. Also this paper focuses on i.i.d. samples. Most of these proofs builds on the technique of [12]. A naive adaptation to the present case allows to prove some performance guarantee for the discrete-time setting. However the resulting bounds are not uniform as η → 0 for nη = T ﬁxed. In particular, they do not allow to prove an analogous of our continuous time result, Theorem 1.1. A large part of our effort is devoted to producing more accurate probability estimates that capture the correct scaling for small η. Similar issues were explored in the study of stochastic differential equations, whereby one is often interested in tracking some slow degrees of freedom while ‘averaging out’ the fast ones [14]. The relevance of this time-scale separation for learning was addressed in [15]. Let us however emphasize that these works focus once more on system with a ﬁxed (small) number of dimensions p. Finally, the related topic of learning graphical models for autoregressive processes was studied recently in [16, 17]. The convex relaxation proposed in these papers is different from the one developed here. Further, no model selection guarantee was proved in [16, 17]. 2 Illustration of the main results It might be difﬁcult to get a clear intuition of Theorem 1.1, mainly because of conditions (a) and (b), which introduce parameters Cmin and α. The same difﬁculty arises with analogous results on the high-dimensional consistency of the LASSO [11, 12]. In this section we provide concrete illustration both via numerical simulations, and by checking the condition on speciﬁc classes of graphs. 2.1 Learning the laplacian of graphs with bounded degree Given a simple graph G = (V, E) on vertex set V = [p], its laplacian ∆G is the symmetric p × p matrix which is equal to the adjacency matrix of G outside the diagonal, and with entries ∆G = ii −deg(i) on the diagonal [18]. (Here deg(i) denotes the degree of vertex i.) It is well known that ∆G is negative semideﬁnite, with one eigenvalue equal to 0, whose multiplicity is equal to the number of connected components of G. The matrix A0 = −m I + ∆G ﬁts into the setting of Theorem 1.1 for m > 0. The corresponding model (1.1) describes the over-damped dynamics of a network of masses connected by springs of unit strength, and connected by a spring of strength m to the origin. We obtain the following result. Theorem 2.1. Let G be a simple connected graph of maximum vertex degree k and consider the model (1.1) with A0 = −m I + ∆G where ∆G is the laplacian of G and m > 0. If k+m 5 4pk T ≥ 2 · 105 k 2 , (7) (k + m2 ) log m δ then there exists λ such that ℓ1 -regularized least squares recovers the signed support of A0 with r probability larger than 1 − δ. This is achieved by taking λ = 36(k + m)2 log(4p/δ)/(T m3 ). In other words, for m bounded away from 0 and ∞, regularized least squares regression correctly reconstructs the graph G from a trajectory of time length which is polynomial in the degree and logarithmic in the system size. Notice that once the graph is known, the laplacian ∆G is uniquely determined. Also, the proof technique used for this example is generalizable to other graphs as well. 4 2800 Min. # of samples for success prob. = 0.9 1 0.9 p = 16 p = 32 0.8 Probability of success p = 64 0.7 p = 128 p = 256 0.6 p = 512 0.5 0.4 0.3 0.2 0.1 0 0 50 100 150 200 250 300 T=nη 350 400 2600 2400 2200 2000 1800 1600 1400 1200 1 10 450 2 3 10 10 p Figure 1: (left) Probability of success vs. length of the observation interval nη. (right) Sample complexity for 90% probability of success vs. p. 2.2 Numerical illustrations In this section we present numerical validation of the proposed method on synthetic data. The results conﬁrm our observations in Theorems 1.1 and 3.1, below, namely that the time complexity scales logarithmically with the number of nodes in the network p, given a constant maximum degree. Also, the time complexity is roughly independent of the sampling rate. In Fig. 1 and 2 we consider the discrete-time setting, generating data as follows. We draw A0 as a random sparse matrix in {0, 1}p×p with elements chosen independently at random with P(A0 = 1) = k/p, k = 5. The ij process xn ≡ {x(t)}0≤t≤n is then generated according to Eq. (6). We solve the regularized least 0 square problem (the cost function is given explicitly in Eq. (8) for the discrete-time case) for different values of n, the number of observations, and record if the correct support is recovered for a random row r using the optimum value of the parameter λ. An estimate of the probability of successful recovery is obtained by repeating this experiment. Note that we are estimating here an average probability of success over randomly generated matrices. The left plot in Fig.1 depicts the probability of success vs. nη for η = 0.1 and different values of p. Each curve is obtained using 211 instances, and each instance is generated using a new random matrix A0 . The right plot in Fig.1 is the corresponding curve of the sample complexity vs. p where sample complexity is deﬁned as the minimum value of nη with probability of success of 90%. As predicted by Theorem 2.1 the curve shows the logarithmic scaling of the sample complexity with p. In Fig. 2 we turn to the continuous-time model (1). Trajectories are generated by discretizing this stochastic differential equation with step δ much smaller than the sampling rate η. We draw random matrices A0 as above and plot the probability of success for p = 16, k = 4 and different values of η, as a function of T . We used 211 instances for each curve. As predicted by Theorem 1.1, for a ﬁxed observation interval T , the probability of success converges to some limiting value as η → 0. 3 Discrete-time model: Statement of the results Consider a system evolving in discrete time according to the model (6), and let xn ≡ {x(t)}0≤t≤n 0 be the observed portion of the trajectory. The rth row A0 is estimated by solving the following r convex optimization problem for Ar ∈ Rp minimize L(Ar ; xn ) + λ Ar 0 where L(Ar ; xn ) ≡ 0 1 2η 2 n 1 , (8) n−1 2 t=0 {xr (t + 1) − xr (t) − η A∗ x(t)} . r (9) Apart from an additive constant, the η → 0 limit of this cost function can be shown to coincide with the cost function in the continuous time case, cf. Eq. (3). Indeed the proof of Theorem 1.1 will amount to a more precise version of this statement. Furthermore, L(Ar ; xn ) is easily seen to be the 0 log-likelihood of Ar within model (6). 5 1 1 0.9 0.95 0.9 0.7 Probability of success Probability of success 0.8 η = 0.04 η = 0.06 0.6 η = 0.08 0.5 η = 0.1 0.4 η = 0.14 0.3 η = 0.22 η = 0.18 0.85 0.8 0.75 0.7 0.65 0.2 0.6 0.1 0 50 100 150 T=nη 200 0.55 0.04 250 0.06 0.08 0.1 0.12 η 0.14 0.16 0.18 0.2 0.22 Figure 2: (right)Probability of success vs. length of the observation interval nη for different values of η. (left) Probability of success vs. η for a ﬁxed length of the observation interval, (nη = 150) . The process is generated for a small value of η and sampled at different rates. As before, we let S 0 be the support of row A0 , and assume |S 0 | ≤ k. Under the model (6) x(t) has r a Gaussian stationary state distribution with covariance Q0 determined by the following modiﬁed Lyapunov equation A0 Q0 + Q0 (A0 )∗ + ηA0 Q0 (A0 )∗ + I = 0 . (10) It will be clear from the context whether A0 /Q0 refers to the dynamics/stationary matrix from the continuous or discrete time system. We assume conditions (a) and (b) introduced in Section 1.1, and adopt the notations already introduced there. We use as a shorthand notation σmax ≡ σmax (I +η A0 ) where σmax (.) is the maximum singular value. Also deﬁne D ≡ 1 − σmax /η . We will assume D > 0. As in the previous section, we assume the model (6) is initiated in the stationary state. Theorem 3.1. Consider the problem of learning the support S 0 of row A0 from the discrete-time r trajectory {x(t)}0≤t≤n . If nη > 4pk 104 k 2 (kD−2 + A−2 ) min log , 2 DC 2 α δ min (11) then there exists λ such that ℓ1 -regularized least squares recovers the signed support of A0 with r probability larger than 1 − δ. This is achieved by taking λ = (36 log(4p/δ))/(Dα2 nη). In other words the discrete-time sample complexity, n, is logarithmic in the model dimension, polynomial in the maximum network degree and inversely proportional to the time spacing between samples. The last point is particularly important. It enables us to derive the bound on the continuoustime sample complexity as the limit η → 0 of the discrete-time sample complexity. It also conﬁrms our intuition mentioned in the Introduction: although one can produce an arbitrary large number of samples by sampling the continuous process with ﬁner resolutions, there is limited amount of information that can be harnessed from a given time interval [0, T ]. 4 Proofs In the following we denote by X ∈ Rn×p the matrix whose (t + 1)th column corresponds to the conﬁguration x(t), i.e. X = [x(0), x(1), . . . , x(n − 1)]. Further ∆X ∈ Rn×p is the matrix containing conﬁguration changes, namely ∆X = [x(1) − x(0), . . . , x(n) − x(n − 1)]. Finally we write W = [w(1), . . . , w(n − 1)] for the matrix containing the Gaussian noise realization. Equivalently, The r th row of W is denoted by Wr . W = ∆X − ηA X . In order to lighten the notation, we will omit the reference to xn in the likelihood function (9) and 0 simply write L(Ar ). We deﬁne its normalized gradient and Hessian by G = −∇L(A0 ) = r 1 ∗ XWr , nη Q = ∇2 L(A0 ) = r 6 1 XX ∗ . n (12) 4.1 Discrete time In this Section we outline our prove for our main result for discrete-time dynamics, i.e., Theorem 3.1. We start by stating a set of sufﬁcient conditions for regularized least squares to work. Then we present a series of concentration lemmas to be used to prove the validity of these conditions, and ﬁnally we sketch the outline of the proof. As mentioned, the proof strategy, and in particular the following proposition which provides a compact set of sufﬁcient conditions for the support to be recovered correctly is analogous to the one in [12]. A proof of this proposition can be found in the supplementary material. Proposition 4.1. Let α, Cmin > 0 be be deﬁned by λmin (Q0 0 ,S 0 ) ≡ Cmin , S |||Q0 0 )C ,S 0 Q0 0 ,S 0 S (S −1 |||∞ ≡ 1 − α . (13) If the following conditions hold then the regularized least square solution (8) correctly recover the signed support sign(A0 ): r λα Amin Cmin G ∞≤ , GS 0 ∞ ≤ − λ, (14) 3 4k α Cmin α Cmin √ , √ . |||QS 0 ,S 0 − Q0 0 ,S 0 |||∞ ≤ (15) |||Q(S 0 )C ,S 0 − Q0 0 )C ,S 0 |||∞ ≤ S (S 12 k 12 k Further the same statement holds for the continuous model 3, provided G and Q are the gradient and the hessian of the likelihood (3). The proof of Theorem 3.1 consists in checking that, under the hypothesis (11) on the number of consecutive conﬁgurations, conditions (14) to (15) will hold with high probability. Checking these conditions can be regarded in turn as concentration-of-measure statements. Indeed, if expectation is taken with respect to a stationary trajectory, we have E{G} = 0, E{Q} = Q0 . 4.1.1 Technical lemmas In this section we will state the necessary concentration lemmas for proving Theorem 3.1. These are non-trivial because G, Q are quadratic functions of dependent random variables the samples {x(t)}0≤t≤n . The proofs of Proposition 4.2, of Proposition 4.3, and Corollary 4.4 can be found in the supplementary material provided. Our ﬁrst Proposition implies concentration of G around 0. Proposition 4.2. Let S ⊆ [p] be any set of vertices and ǫ < 1/2. If σmax ≡ σmax (I + η A0 ) < 1, then 2 P GS ∞ > ǫ ≤ 2|S| e−n(1−σmax ) ǫ /4 . (16) We furthermore need to bound the matrix norms as per (15) in proposition 4.1. First we relate bounds on |||QJS − Q0 JS |||∞ with bounds on |Qij − Q0 |, (i ∈ J, i ∈ S) where J and S are any ij subsets of {1, ..., p}. We have, P(|||QJS − Q0 )|||∞ > ǫ) ≤ |J||S| max P(|Qij − Q0 | > ǫ/|S|). JS ij i,j∈J (17) Then, we bound |Qij − Q0 | using the following proposition ij Proposition 4.3. Let i, j ∈ {1, ..., p}, σmax ≡ σmax (I + ηA0 ) < 1, T = ηn > 3/D and 0 < ǫ < 2/D where D = (1 − σmax )/η then, P(|Qij − Q0 )| > ǫ) ≤ 2e ij n − 32η2 (1−σmax )3 ǫ2 . (18) Finally, the next corollary follows from Proposition 4.3 and Eq. (17). Corollary 4.4. Let J, S (|S| ≤ k) be any two subsets of {1, ..., p} and σmax ≡ σmax (I + ηA0 ) < 1, ǫ < 2k/D and nη > 3/D (where D = (1 − σmax )/η) then, P(|||QJS − Q0 |||∞ > ǫ) ≤ 2|J|ke JS 7 n − 32k2 η2 (1−σmax )3 ǫ2 . (19) 4.1.2 Outline of the proof of Theorem 3.1 With these concentration bounds we can now easily prove Theorem 3.1. All we need to do is to compute the probability that the conditions given by Proposition 4.1 hold. From the statement of the theorem we have that the ﬁrst two conditions (α, Cmin > 0) of Proposition 4.1 hold. In order to make the ﬁrst condition on G imply the second condition on G we assume that λα/3 ≤ (Amin Cmin )/(4k) − λ which is guaranteed to hold if λ ≤ Amin Cmin /8k. (20) We also combine the two last conditions on Q, thus obtaining the following |||Q[p],S 0 − Q0 0 |||∞ ≤ [p],S α Cmin √ , 12 k (21) since [p] = S 0 ∪ (S 0 )C . We then impose that both the probability of the condition on Q failing and the probability of the condition on G failing are upper bounded by δ/2 using Proposition 4.2 and Corollary 4.4. It is shown in the supplementary material that this is satisﬁed if condition (11) holds. 4.2 Outline of the proof of Theorem 1.1 To prove Theorem 1.1 we recall that Proposition 4.1 holds provided the appropriate continuous time expressions are used for G and Q, namely G = −∇L(A0 ) = r 1 T T x(t) dbr (t) , 0 Q = ∇2 L(A0 ) = r 1 T T x(t)x(t)∗ dt . (22) 0 These are of course random variables. In order to distinguish these from the discrete time version, we will adopt the notation Gn , Qn for the latter. We claim that these random variables can be coupled (i.e. deﬁned on the same probability space) in such a way that Gn → G and Qn → Q almost surely as n → ∞ for ﬁxed T . Under assumption (5), it is easy to show that (11) holds for all n > n0 with n0 a sufﬁciently large constant (for a proof see the provided supplementary material). Therefore, by the proof of Theorem 3.1, the conditions in Proposition 4.1 hold for gradient Gn and hessian Qn for any n ≥ n0 , with probability larger than 1 − δ. But by the claimed convergence Gn → G and Qn → Q, they hold also for G and Q with probability at least 1 − δ which proves the theorem. We are left with the task of showing that the discrete and continuous time processes can be coupled in such a way that Gn → G and Qn → Q. With slight abuse of notation, the state of the discrete time system (6) will be denoted by x(i) where i ∈ N and the state of continuous time system (1) by x(t) where t ∈ R. We denote by Q0 the solution of (4) and by Q0 (η) the solution of (10). It is easy to check that Q0 (η) → Q0 as η → 0 by the uniqueness of stationary state distribution. The initial state of the continuous time system x(t = 0) is a N(0, Q0 ) random variable independent of b(t) and the initial state of the discrete time system is deﬁned to be x(i = 0) = (Q0 (η))1/2 (Q0 )−1/2 x(t = 0). At subsequent times, x(i) and x(t) are assumed are generated by the respective dynamical systems using the same matrix A0 using common randomness provided by the standard Brownian motion {b(t)}0≤t≤T in Rp . In order to couple x(t) and x(i), we construct w(i), the noise driving the discrete time system, by letting w(i) ≡ (b(T i/n) − b(T (i − 1)/n)). The almost sure convergence Gn → G and Qn → Q follows then from standard convergence of random walk to Brownian motion. Acknowledgments This work was partially supported by a Terman fellowship, the NSF CAREER award CCF-0743978 and the NSF grant DMS-0806211 and by a Portuguese Doctoral FCT fellowship. 8 References [1] D.T. Gillespie. Stochastic simulation of chemical kinetics. Annual Review of Physical Chemistry, 58:35–55, 2007. [2] D. Higham. Modeling and Simulating Chemical Reactions. SIAM Review, 50:347–368, 2008. [3] N.D.Lawrence et al., editor. Learning and Inference in Computational Systems Biology. MIT Press, 2010. [4] T. Toni, D. Welch, N. Strelkova, A. Ipsen, and M.P.H. Stumpf. Modeling and Simulating Chemical Reactions. J. R. Soc. Interface, 6:187–202, 2009. [5] K. Zhou, J.C. Doyle, and K. Glover. Robust and optimal control. Prentice Hall, 1996. [6] R. Tibshirani. Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society. Series B (Methodological), 58(1):267–288, 1996. [7] D.L. Donoho. For most large underdetermined systems of equations, the minimal l1-norm near-solution approximates the sparsest near-solution. Communications on Pure and Applied Mathematics, 59(7):907–934, 2006. [8] D.L. Donoho. For most large underdetermined systems of linear equations the minimal l1norm solution is also the sparsest solution. Communications on Pure and Applied Mathematics, 59(6):797–829, 2006. [9] T. Zhang. Some sharp performance bounds for least squares regression with L1 regularization. Annals of Statistics, 37:2109–2144, 2009. [10] M.J. Wainwright. Sharp thresholds for high-dimensional and noisy sparsity recovery using l1constrained quadratic programming (Lasso). IEEE Trans. Information Theory, 55:2183–2202, 2009. [11] M.J. Wainwright, P. Ravikumar, and J.D. Lafferty. High-Dimensional Graphical Model Selection Using l-1-Regularized Logistic Regression. Advances in Neural Information Processing Systems, 19:1465, 2007. [12] P. Zhao and B. Yu. On model selection consistency of Lasso. The Journal of Machine Learning Research, 7:2541–2563, 2006. [13] J. Friedman, T. Hastie, and R. Tibshirani. Sparse inverse covariance estimation with the graphical lasso. Biostatistics, 9(3):432, 2008. [14] K. Ball, T.G. Kurtz, L. Popovic, and G. Rempala. Modeling and Simulating Chemical Reactions. Ann. Appl. Prob., 16:1925–1961, 2006. [15] G.A. Pavliotis and A.M. Stuart. Parameter estimation for multiscale diffusions. J. Stat. Phys., 127:741–781, 2007. [16] J. Songsiri, J. Dahl, and L. Vandenberghe. Graphical models of autoregressive processes. pages 89–116, 2010. [17] J. Songsiri and L. Vandenberghe. Topology selection in graphical models of autoregressive processes. Journal of Machine Learning Research, 2010. submitted. [18] F.R.K. Chung. Spectral Graph Theory. CBMS Regional Conference Series in Mathematics, 1997. [19] P. Ravikumar, M.J. Wainwright, and J. Lafferty. High-dimensional Ising model selection using l1-regularized logistic regression. Annals of Statistics, 2008. 9</p><p>4 0.74438739 <a title="48-lda-4" href="./nips-2010-Computing_Marginal_Distributions_over_Continuous_Markov_Networks_for_Statistical_Relational_Learning.html">49 nips-2010-Computing Marginal Distributions over Continuous Markov Networks for Statistical Relational Learning</a></p>
<p>Author: Matthias Broecheler, Lise Getoor</p><p>Abstract: Continuous Markov random ﬁelds are a general formalism to model joint probability distributions over events with continuous outcomes. We prove that marginal computation for constrained continuous MRFs is #P-hard in general and present a polynomial-time approximation scheme under mild assumptions on the structure of the random ﬁeld. Moreover, we introduce a sampling algorithm to compute marginal distributions and develop novel techniques to increase its efﬁciency. Continuous MRFs are a general purpose probabilistic modeling tool and we demonstrate how they can be applied to statistical relational learning. On the problem of collective classiﬁcation, we evaluate our algorithm and show that the standard deviation of marginals serves as a useful measure of conﬁdence. 1</p><p>5 0.62721282 <a title="48-lda-5" href="./nips-2010-A_unified_model_of_short-range_and_long-range_motion_perception.html">20 nips-2010-A unified model of short-range and long-range motion perception</a></p>
<p>Author: Shuang Wu, Xuming He, Hongjing Lu, Alan L. Yuille</p><p>Abstract: The human vision system is able to effortlessly perceive both short-range and long-range motion patterns in complex dynamic scenes. Previous work has assumed that two different mechanisms are involved in processing these two types of motion. In this paper, we propose a hierarchical model as a uniﬁed framework for modeling both short-range and long-range motion perception. Our model consists of two key components: a data likelihood that proposes multiple motion hypotheses using nonlinear matching, and a hierarchical prior that imposes slowness and spatial smoothness constraints on the motion ﬁeld at multiple scales. We tested our model on two types of stimuli, random dot kinematograms and multiple-aperture stimuli, both commonly used in human vision research. We demonstrate that the hierarchical model adequately accounts for human performance in psychophysical experiments.</p><p>6 0.60316515 <a title="48-lda-6" href="./nips-2010-Generalized_roof_duality_and_bisubmodular_functions.html">102 nips-2010-Generalized roof duality and bisubmodular functions</a></p>
<p>7 0.6005004 <a title="48-lda-7" href="./nips-2010-Functional_form_of_motion_priors_in_human_motion_perception.html">98 nips-2010-Functional form of motion priors in human motion perception</a></p>
<p>8 0.56722659 <a title="48-lda-8" href="./nips-2010-A_Log-Domain_Implementation_of_the_Diffusion_Network_in_Very_Large_Scale_Integration.html">8 nips-2010-A Log-Domain Implementation of the Diffusion Network in Very Large Scale Integration</a></p>
<p>9 0.56382293 <a title="48-lda-9" href="./nips-2010-A_Bayesian_Approach_to_Concept_Drift.html">2 nips-2010-A Bayesian Approach to Concept Drift</a></p>
<p>10 0.55963594 <a title="48-lda-10" href="./nips-2010-Rescaling%2C_thinning_or_complementing%3F_On_goodness-of-fit_procedures_for_point_process_models_and_Generalized_Linear_Models.html">227 nips-2010-Rescaling, thinning or complementing? On goodness-of-fit procedures for point process models and Generalized Linear Models</a></p>
<p>11 0.55537653 <a title="48-lda-11" href="./nips-2010-Getting_lost_in_space%3A_Large_sample_analysis_of_the_resistance_distance.html">105 nips-2010-Getting lost in space: Large sample analysis of the resistance distance</a></p>
<p>12 0.55189365 <a title="48-lda-12" href="./nips-2010-Learning_Bounds_for_Importance_Weighting.html">142 nips-2010-Learning Bounds for Importance Weighting</a></p>
<p>13 0.54838532 <a title="48-lda-13" href="./nips-2010-Effects_of_Synaptic_Weight_Diffusion_on_Learning_in_Decision_Making_Networks.html">68 nips-2010-Effects of Synaptic Weight Diffusion on Learning in Decision Making Networks</a></p>
<p>14 0.54404163 <a title="48-lda-14" href="./nips-2010-Attractor_Dynamics_with_Synaptic_Depression.html">34 nips-2010-Attractor Dynamics with Synaptic Depression</a></p>
<p>15 0.54362071 <a title="48-lda-15" href="./nips-2010-Occlusion_Detection_and_Motion_Estimation_with_Convex_Optimization.html">187 nips-2010-Occlusion Detection and Motion Estimation with Convex Optimization</a></p>
<p>16 0.54329038 <a title="48-lda-16" href="./nips-2010-MAP_estimation_in_Binary_MRFs_via_Bipartite_Multi-cuts.html">165 nips-2010-MAP estimation in Binary MRFs via Bipartite Multi-cuts</a></p>
<p>17 0.54192019 <a title="48-lda-17" href="./nips-2010-Improving_the_Asymptotic_Performance_of_Markov_Chain_Monte-Carlo_by_Inserting_Vortices.html">122 nips-2010-Improving the Asymptotic Performance of Markov Chain Monte-Carlo by Inserting Vortices</a></p>
<p>18 0.54106635 <a title="48-lda-18" href="./nips-2010-Construction_of_Dependent_Dirichlet_Processes_based_on_Poisson_Processes.html">51 nips-2010-Construction of Dependent Dirichlet Processes based on Poisson Processes</a></p>
<p>19 0.54063243 <a title="48-lda-19" href="./nips-2010-An_analysis_on_negative_curvature_induced_by_singularity_in_multi-layer_neural-network_learning.html">31 nips-2010-An analysis on negative curvature induced by singularity in multi-layer neural-network learning</a></p>
<p>20 0.53710502 <a title="48-lda-20" href="./nips-2010-Learning_via_Gaussian_Herding.html">158 nips-2010-Learning via Gaussian Herding</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
