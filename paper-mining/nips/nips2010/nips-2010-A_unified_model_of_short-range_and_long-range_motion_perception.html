<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>20 nips-2010-A unified model of short-range and long-range motion perception</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-20" href="#">nips2010-20</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>20 nips-2010-A unified model of short-range and long-range motion perception</h1>
<br/><p>Source: <a title="nips-2010-20-pdf" href="http://papers.nips.cc/paper/3910-a-unified-model-of-short-range-and-long-range-motion-perception.pdf">pdf</a></p><p>Author: Shuang Wu, Xuming He, Hongjing Lu, Alan L. Yuille</p><p>Abstract: The human vision system is able to effortlessly perceive both short-range and long-range motion patterns in complex dynamic scenes. Previous work has assumed that two different mechanisms are involved in processing these two types of motion. In this paper, we propose a hierarchical model as a uniﬁed framework for modeling both short-range and long-range motion perception. Our model consists of two key components: a data likelihood that proposes multiple motion hypotheses using nonlinear matching, and a hierarchical prior that imposes slowness and spatial smoothness constraints on the motion ﬁeld at multiple scales. We tested our model on two types of stimuli, random dot kinematograms and multiple-aperture stimuli, both commonly used in human vision research. We demonstrate that the hierarchical model adequately accounts for human performance in psychophysical experiments.</p><p>Reference: <a title="nips-2010-20-reference" href="../nips2010_reference/nips-2010-A_unified_model_of_short-range_and_long-range_motion_perception_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 A uniﬁed model of short-range and long-range motion perception  Shuang Wu Department of Statistics UCLA Los Angeles , CA 90095 shuangw@stat. [sent-1, score-0.765]
</p><p>2 edu  Abstract The human vision system is able to effortlessly perceive both short-range and long-range motion patterns in complex dynamic scenes. [sent-8, score-0.847]
</p><p>3 In this paper, we propose a hierarchical model as a uniﬁed framework for modeling both short-range and long-range motion perception. [sent-10, score-0.755]
</p><p>4 Our model consists of two key components: a data likelihood that proposes multiple motion hypotheses using nonlinear matching, and a hierarchical prior that imposes slowness and spatial smoothness constraints on the motion ﬁeld at multiple scales. [sent-11, score-1.719]
</p><p>5 We tested our model on two types of stimuli, random dot kinematograms and multiple-aperture stimuli, both commonly used in human vision research. [sent-12, score-0.308]
</p><p>6 As illustrated by the motion sequence depicted in Figure 1, humans readily perceive the baseball player’s body movements and the fastermoving baseball simultaneously. [sent-15, score-0.928]
</p><p>7 Separate motion systems have been proposed to explain human perception in scenarios like this example. [sent-19, score-0.83]
</p><p>8 In particular, Braddick [1] proposed that there is a short-range motion system which is responsible for perceiving movements with relatively small displacements (e. [sent-20, score-0.829]
</p><p>9 , the player’s movement), and a long-range motion system which perceives motion with large displacements (e. [sent-22, score-1.406]
</p><p>10 Lu and Sperling [2] have further argued for the existence of three motion systems in human vision. [sent-25, score-0.734]
</p><p>11 The ﬁrst and secondorder systems conduct motion analysis on luminance and texture information respectively, while the third-order system uses a feature-tracking strategy. [sent-26, score-0.694]
</p><p>12 In the baseball example, the ﬁrst-order motion system would be used to perceive the player’s movements, but the third-order system would be required for perceiving the faster motion of the baseball. [sent-27, score-1.595]
</p><p>13 Short-range motion and ﬁrst-order motion appear to apply to the same class of phenomena, and can be modeled using computational theories that are based on motion energy or related techniques. [sent-28, score-2.113]
</p><p>14 However, long-range motion and third-order 1  Figure 1: Left panel: Short-range and long-range motion: two frames from a baseball sequence where the ball moves with much faster speed than the other objects. [sent-29, score-0.788]
</p><p>15 Each node represents motion at different location and scales. [sent-31, score-0.716]
</p><p>16 A child node can have multiple parents, and the prior constraints on motion are expressed by parent-child interactions. [sent-32, score-0.81]
</p><p>17 motion employ qualitatively different computational strategies involving tracking features over time, which may require attention-driven processes. [sent-33, score-0.669]
</p><p>18 In contrast to these previous multi-system theories [2, 3], we develop a uniﬁed single-system framework to account for these phenomena of human motion perception. [sent-34, score-0.756]
</p><p>19 We model motion estimation as an inference problem which uses ﬂexible prior assumptions about motion ﬂows and statistical models for quantifying the uncertainty in motion measurement. [sent-35, score-2.063]
</p><p>20 First, the prior model is deﬁned over a hierarchical graph, see Figure 1, where the nodes of the graph represent the motion at different scales. [sent-37, score-0.912]
</p><p>21 Such a representation makes it possible to deﬁne motion priors and contextual effects at a range of different scales, and so differs from other models of motion perception based on motion priors [5, 6]. [sent-39, score-2.126]
</p><p>22 This model connects lower level nodes to multiple coarser-level nodes, resulting in a loopy graph structure, which imposes a more ﬂexible prior than tree-structured models (eg. [sent-40, score-0.245]
</p><p>23 We deﬁne a probability distribution on this graph using potentials deﬁned over the graph cliques to capture spatial smoothness constraints [10] at different scales and slowness constraints [5, 11, 12, 13]. [sent-42, score-0.3]
</p><p>24 , the likelihood term allows many possible motions) which is resolved in our model by imposing the hierarchical motion prior. [sent-46, score-0.779]
</p><p>25 Instead we use a bottom-up compositional/hierarchical approach where local hypotheses about the motion are combined to form hypotheses for larger regions of the image. [sent-48, score-0.727]
</p><p>26 We tested our model using two types of stimuli commonly used in human vision research. [sent-50, score-0.28]
</p><p>27 The ﬁrst stimulus type are random dot kinematograms (RDKs), where some of the dots (the signal) move coherently with large displacements, whereas other dots (the noise) move randomly. [sent-51, score-0.594]
</p><p>28 RDKs are one of the most important stimuli used in both physiological and psychophysical studies of motion perception. [sent-52, score-0.88]
</p><p>29 For example, electrophysiological studies have used RDKs to analyze the neuronal basis of motion perception, identifying a functional link between the activity of motion-selective neurons and behavioral judgments of motion perception [15]. [sent-53, score-1.434]
</p><p>30 Psychophysical studies have used RDKs to measure the sensitivity of the human visual system for perceiving coherent motion, and also to infer how motion information is integrated to perceive global motion under different viewing conditions [16]. [sent-54, score-1.698]
</p><p>31 We used two-frame RDKs as an example of a long-range motion stimulus. [sent-55, score-0.669]
</p><p>32 The second stimulus type are moving gratings or plaids. [sent-56, score-0.282]
</p><p>33 For example, when randomly orientated lines or grating elements drift behind apertures, the perceived direction of motion is heavily biased by the orientation of the lines/gratings, as well as by the shape and contrast of the apertures [17, 18, 19]. [sent-58, score-0.873]
</p><p>34 Multiple-aperture stimuli have also recently been used to study coherent motion perception with short-range motion stimulus [20, 21]. [sent-59, score-1.768]
</p><p>35 For both types of stimuli we compared the model predictions with human performance across various experimental conditions. [sent-60, score-0.25]
</p><p>36 2  2 Hierarchical Model for Motion Estimation Our hierarchical model represents a motion ﬁeld using a graph G = (V, E), which has L + 1 hierarchical levels, i. [sent-61, score-0.891]
</p><p>37 The edges E of the graph connect nodes at each level of the hierarchy to nodes in the neighboring levels. [sent-84, score-0.35]
</p><p>38 Speciﬁcally, edges connect node ν l (i, j) at level l to a set of child nodes Chl (i, j) = {ν l−1 (i , j )} at level l − 1 satisfying 2i − d ≤ i ≤ 2i + d, 2j − d ≤ j ≤ 2j + d. [sent-85, score-0.317]
</p><p>39 To apply the model to motion estimation, we deﬁne state variable ul (i, j) at each node to represent the motion, and connect the 0th level nodes to two consecutive image frames, D = (It (x), It+1 (x)). [sent-89, score-1.284]
</p><p>40 The problem of motion estimation is to estimate the 2D motion ﬁeld u(x) at time t for every pixel site x from input D. [sent-90, score-1.369]
</p><p>41 For simplicity, we use ul to denote the motion instead of ul (i, j) in the i following sections. [sent-91, score-1.453]
</p><p>42 This robust norm helps deal with the measurement noise that often occur at motion boundary and to prevent over-smoothing at the higher levels. [sent-95, score-0.693]
</p><p>43 The second i term imposes a slowness prior on the motion which is weighted by the coefﬁcient α. [sent-100, score-0.821]
</p><p>44 These similarity scores at x gives conﬁdence for different local motion hypotheses: higher similarity means the motion is more likely while lower means it is less likely. [sent-102, score-1.338]
</p><p>45 l 2) The Hierarchical Prior {Eu }  We deﬁne a hierarchical prior on the slowness and spatial smoothness of motion ﬁelds. [sent-103, score-0.984]
</p><p>46 The ﬁrst term of this prior is expressed by energy terms between nodes at different levels of the hierarchy and enforces a smoothness preference for their states u – that the motion of a child node is similar to the motion of its parent. [sent-104, score-1.828]
</p><p>47 This imposes weak smoothness on the motion ﬁeld and allows abrupt change on motion boundaries. [sent-106, score-1.464]
</p><p>48 The second term is a L1 norm of motion velocities that encourages the slowness. [sent-107, score-0.669]
</p><p>49 Note that our hierarchical smoothness prior differs from conventional smoothness constraints, e. [sent-116, score-0.316]
</p><p>50 , [10], because they impose smoothness ’sideways’ between neighboring pixels at the same resolution level, which requires that the motion is similar between neighboring sites at the pixel level only. [sent-118, score-0.939]
</p><p>51 By contrast, we impose smoothness by requiring that child nodes have similar motions to their parent nodes. [sent-121, score-0.321]
</p><p>52 2 Motion Estimation ˆ We estimate the motion ﬁeld by computing the most probable motion U = arg maxU P (U |D), where P (U |D) was deﬁned as a Gibbs distribution in equation (1). [sent-124, score-1.338]
</p><p>53 Performing inference on this model is challenging since the energy is deﬁned over a hierarchical graph structure with many closed loops, the state variables U are continuous-valued, and the energy function is non-convex. [sent-125, score-0.331]
</p><p>54 Our strategy is to convert this into a discrete optimization problem by quantizing the motion state space. [sent-126, score-0.669]
</p><p>55 For example, we estimate the motion at an integer-valued resolution if the accuracy is sufﬁcient for certain experimental settings. [sent-127, score-0.669]
</p><p>56 We ﬁrst approximate the hierarchial graph with a tree-structured model by making multiple copies of child nodes such that each child node has a single parent (see [23]). [sent-133, score-0.347]
</p><p>57 More ˜ speciﬁcally, we compute an approximate energy function E(U ) recursively by exploiting the tree 4  structure:  ˜ E(ul+1 ) = i  l ˜ j min[Eu (ul+1 , ul ) + E(ul )] j i j∈Chl+1 (i)  ul j  ˜ where E(u0 ) at the bottom level is the data energy Ed (u0 ; D). [sent-135, score-1.027]
</p><p>58 Given the top-level motion (ˆL ), we then compute the optimal motion conui ﬁguration for other levels using the following top-down procedure. [sent-138, score-1.376]
</p><p>59 We minimize the following energy function recursively for each node: ˆj ul = arg min[ ul j  l ˜ j Eu (ˆ l+1 ; ul ) + E(ul )] ui j  i∈P al (j)  where P al (j) is the set of parents of level-l node j. [sent-140, score-1.352]
</p><p>60 In the top-down pass, the spatial smoothness is imposed to the motion estimates at higher levels which provide context information to disambiguate the motion estimated at lower levels. [sent-141, score-1.533]
</p><p>61 1 The stimuli and simulation procedures Random dot kinematogram (RDK) stimuli consist of two image frames with N dots in each frame [1, 16, 6]. [sent-146, score-0.67]
</p><p>62 The difﬁculty of perceiving coherent motion in RDK stimuli is due to the large correspondence uncertainty introduced by the noise dots as shown in rightmost panel in ﬁgure (3). [sent-152, score-1.279]
</p><p>63 Figure 3: The left three panels show coherent stimuli with N = 20, C = 0. [sent-153, score-0.264]
</p><p>64 The arrows show the motion of those dots which are moving coherently. [sent-158, score-0.83]
</p><p>65 Correspondence noise is illustrated by the rightmost panel showing that a dot in the ﬁrst frame has many candidate matches in the second frame. [sent-159, score-0.317]
</p><p>66 Barlow and Tripathy [16] used RDK stimuli to investigate how dot density can affect human performance in a global motion discrimination task. [sent-160, score-1.037]
</p><p>67 They found that human performance (measured by the coherence threshold) vary little with dot density. [sent-161, score-0.33]
</p><p>68 We tested our model on the same task to judge 5  Figure 4: Estimated motion ﬁelds for random dot kinematograms. [sent-162, score-0.797]
</p><p>69 First row: 50 dots in the RDK stimulus; Second row: 100 dots in the RDK stimulus; Column-wise, coherence ratio C = 0. [sent-163, score-0.454]
</p><p>70 The arrows indicate the motion estimated for each dot. [sent-168, score-0.691]
</p><p>71 the global motion direction using RDK motion stimulus as the input image. [sent-169, score-1.495]
</p><p>72 We applied our model to estimate motion ﬁelds and used the average velocity to indicate the global motion direction (to the left or to the right). [sent-170, score-1.392]
</p><p>73 The dot number varies with N = 40, 80, 100, 200, 400, 800 respectively, corresponding to a wide range of dot densities. [sent-172, score-0.256]
</p><p>74 The model performance was computed for each coherence ratio to ﬁt psychometric functions and to ﬁnd the coherence threshold at which model performance can reach 75% accuracy. [sent-173, score-0.354]
</p><p>75 2 The Results Figure (4) shows examples of the estimated motion ﬁeld for various values of dot number N and coherence ratio C. [sent-175, score-0.993]
</p><p>76 The model outputs provide visually coherent motion estimates when the coherence ratio was greater than 0. [sent-176, score-0.941]
</p><p>77 With the increase of coherence ratio, the estimated motion ﬂow appears to be more coherent. [sent-178, score-0.828]
</p><p>78 The coherence threshold, using the criterion of 75% accuracy, showed that model performance varied little with the increase of dot density, which is consistent with human performance reported in psychophysical experiments [16, 6]. [sent-181, score-0.387]
</p><p>79 Two types of elements were used in our simulations: (i) drifting sine-wave gratings with random orientation, and (ii) plaids which includes two gratings with orthogonal orientations. [sent-184, score-0.501]
</p><p>80 For the CN signal gratings, the motion vi was set to a ﬁxed value v. [sent-190, score-0.692]
</p><p>81 005 0 40  80 100  200 N  400  800  Figure 5: Left panel: Figure 2 in [16] showing that the coherence ratio threshold varies very little with dot density. [sent-201, score-0.302]
</p><p>82 The plaid elements combine two gratings with orthogonal orientations (each grating has the same speed but can have a different motion direction). [sent-208, score-0.986]
</p><p>83 1  Figure 7: Left two panels: Estimated motion ﬁelds of grating and plaids stimuli. [sent-227, score-0.904]
</p><p>84 Rightmost panel: Psychometric functions of gratings and plaids stimuli. [sent-228, score-0.288]
</p><p>85 2 Simulation procedures and results The left two panels in Figure (7) show the estimated motion ﬁelds for the two types of stimulus we studied with the same coherence ratios 0. [sent-230, score-0.995]
</p><p>86 Plaids stimuli produce more coherent estimated motion ﬁeld than grating stimuli, which is understandable. [sent-232, score-1.027]
</p><p>87 We tested our model in an 8-direction discrimination task for estimating global motion direction [20]. [sent-234, score-0.723]
</p><p>88 We ran 300 trials for each stimulus type, and used the direction of the average motion to predict the global motion direction. [sent-236, score-1.495]
</p><p>89 the number of times our model predicted the correct motion direction from 8 alternatives – was calculated at different coherence ratio levels. [sent-239, score-0.876]
</p><p>90 This difference between gratings and plaids is shown in the rightmost panel of Figure (7), where the psychometric function of plaids stimuli is always above that of grating stimuli, indicating better performance. [sent-240, score-0.846]
</p><p>91 It differs from traditional motion energy models because it does not use spatiotemporal ﬁltering. [sent-243, score-0.776]
</p><p>92 Note that it was shown in [6] that motion energy models are not well suited to the long-range motion stimuli studied in this paper. [sent-244, score-1.576]
</p><p>93 The local ambiguities of motion are resolved by a novel hierarchical prior which combines slowness and smoothness at a range of different scales. [sent-245, score-1.014]
</p><p>94 Our model accounts well for human perception of both short-range and long-range motion using the two standard stimulus types (RDKs and gratings). [sent-246, score-0.964]
</p><p>95 It also has the computational motivation of being able to represent prior knowledge about motion at different scales and to allow efﬁcient computation. [sent-248, score-0.698]
</p><p>96 Three-systems theory of human visual motion perception: review and update. [sent-260, score-0.785]
</p><p>97 Cortical dynamics of visual motion perception: short-range and long-range apparent motion. [sent-319, score-0.744]
</p><p>98 The inﬂuence of terminators on motion integration across space. [sent-395, score-0.669]
</p><p>99 Adaptive pooling of visual motion signals by the human visual system revealed with a novel multi-element stimulus. [sent-409, score-0.861]
</p><p>100 A comparison of global motion perception using a multiple-aperture stimulus. [sent-415, score-0.786]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('motion', 0.669), ('ul', 0.392), ('gratings', 0.158), ('stimuli', 0.154), ('rdk', 0.143), ('dots', 0.14), ('coherence', 0.137), ('plaids', 0.13), ('dot', 0.128), ('rdks', 0.107), ('grating', 0.105), ('stimulus', 0.103), ('perception', 0.096), ('smoothness', 0.089), ('eu', 0.087), ('baseball', 0.086), ('slowness', 0.086), ('hierarchical', 0.086), ('energy', 0.084), ('panel', 0.081), ('nodes', 0.078), ('coherent', 0.077), ('human', 0.065), ('child', 0.065), ('motions', 0.064), ('perceiving', 0.063), ('perceive', 0.058), ('psychophysical', 0.057), ('sin', 0.055), ('ucla', 0.054), ('kinematograms', 0.054), ('plaid', 0.054), ('level', 0.051), ('displacement', 0.051), ('visual', 0.051), ('graph', 0.05), ('node', 0.047), ('chl', 0.047), ('rightmost', 0.045), ('player', 0.044), ('angeles', 0.044), ('pp', 0.044), ('displacements', 0.043), ('psychometric', 0.043), ('copies', 0.042), ('optical', 0.041), ('los', 0.04), ('lu', 0.04), ('frame', 0.039), ('levels', 0.038), ('imposes', 0.037), ('ratio', 0.037), ('neighboring', 0.037), ('apertures', 0.036), ('yuille', 0.035), ('eld', 0.035), ('lattice', 0.034), ('frames', 0.033), ('direction', 0.033), ('panels', 0.033), ('ambiguities', 0.031), ('hongjing', 0.031), ('sideways', 0.031), ('hierarchy', 0.031), ('pixel', 0.031), ('types', 0.031), ('orientation', 0.03), ('vision', 0.03), ('hypotheses', 0.029), ('movements', 0.029), ('barlow', 0.029), ('coherently', 0.029), ('prior', 0.029), ('cn', 0.029), ('enforces', 0.029), ('ambiguous', 0.027), ('inference', 0.027), ('cos', 0.026), ('uni', 0.026), ('correspondence', 0.026), ('spatial', 0.025), ('impose', 0.025), ('connect', 0.025), ('system', 0.025), ('drifting', 0.024), ('resolved', 0.024), ('apparent', 0.024), ('noise', 0.024), ('recursively', 0.024), ('enables', 0.024), ('vi', 0.023), ('differs', 0.023), ('estimated', 0.022), ('image', 0.022), ('theories', 0.022), ('parents', 0.021), ('global', 0.021), ('estimates', 0.021), ('moved', 0.021), ('moving', 0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000007 <a title="20-tfidf-1" href="./nips-2010-A_unified_model_of_short-range_and_long-range_motion_perception.html">20 nips-2010-A unified model of short-range and long-range motion perception</a></p>
<p>Author: Shuang Wu, Xuming He, Hongjing Lu, Alan L. Yuille</p><p>Abstract: The human vision system is able to effortlessly perceive both short-range and long-range motion patterns in complex dynamic scenes. Previous work has assumed that two different mechanisms are involved in processing these two types of motion. In this paper, we propose a hierarchical model as a uniﬁed framework for modeling both short-range and long-range motion perception. Our model consists of two key components: a data likelihood that proposes multiple motion hypotheses using nonlinear matching, and a hierarchical prior that imposes slowness and spatial smoothness constraints on the motion ﬁeld at multiple scales. We tested our model on two types of stimuli, random dot kinematograms and multiple-aperture stimuli, both commonly used in human vision research. We demonstrate that the hierarchical model adequately accounts for human performance in psychophysical experiments.</p><p>2 0.5753926 <a title="20-tfidf-2" href="./nips-2010-Functional_form_of_motion_priors_in_human_motion_perception.html">98 nips-2010-Functional form of motion priors in human motion perception</a></p>
<p>Author: Hongjing Lu, Tungyou Lin, Alan Lee, Luminita Vese, Alan L. Yuille</p><p>Abstract: It has been speculated that the human motion system combines noisy measurements with prior expectations in an optimal, or rational, manner. The basic goal of our work is to discover experimentally which prior distribution is used. More speciﬁcally, we seek to infer the functional form of the motion prior from the performance of human subjects on motion estimation tasks. We restricted ourselves to priors which combine three terms for motion slowness, ﬁrst-order smoothness, and second-order smoothness. We focused on two functional forms for prior distributions: L2-norm and L1-norm regularization corresponding to the Gaussian and Laplace distributions respectively. In our ﬁrst experimental session we estimate the weights of the three terms for each functional form to maximize the ﬁt to human performance. We then measured human performance for motion tasks and found that we obtained better ﬁt for the L1-norm (Laplace) than for the L2-norm (Gaussian). We note that the L1-norm is also a better ﬁt to the statistics of motion in natural environments. In addition, we found large weights for the second-order smoothness term, indicating the importance of high-order smoothness compared to slowness and lower-order smoothness. To validate our results further, we used the best ﬁt models using the L1-norm to predict human performance in a second session with different experimental setups. Our results showed excellent agreement between human performance and model prediction – ranging from 3% to 8% for ﬁve human subjects over ten experimental conditions – and give further support that the human visual system uses an L1-norm (Laplace) prior.</p><p>3 0.23476093 <a title="20-tfidf-3" href="./nips-2010-Occlusion_Detection_and_Motion_Estimation_with_Convex_Optimization.html">187 nips-2010-Occlusion Detection and Motion Estimation with Convex Optimization</a></p>
<p>Author: Alper Ayvaci, Michalis Raptis, Stefano Soatto</p><p>Abstract: We tackle the problem of simultaneously detecting occlusions and estimating optical ﬂow. We show that, under standard assumptions of Lambertian reﬂection and static illumination, the task can be posed as a convex minimization problem. Therefore, the solution, computed using efﬁcient algorithms, is guaranteed to be globally optimal, for any number of independently moving objects, and any number of occlusion layers. We test the proposed algorithm on benchmark datasets, expanded to enable evaluation of occlusion detection performance. 1</p><p>4 0.1951317 <a title="20-tfidf-4" href="./nips-2010-Layered_image_motion_with_explicit_occlusions%2C_temporal_consistency%2C_and_depth_ordering.html">141 nips-2010-Layered image motion with explicit occlusions, temporal consistency, and depth ordering</a></p>
<p>Author: Deqing Sun, Erik B. Sudderth, Michael J. Black</p><p>Abstract: Layered models are a powerful way of describing natural scenes containing smooth surfaces that may overlap and occlude each other. For image motion estimation, such models have a long history but have not achieved the wide use or accuracy of non-layered methods. We present a new probabilistic model of optical ﬂow in layers that addresses many of the shortcomings of previous approaches. In particular, we deﬁne a probabilistic graphical model that explicitly captures: 1) occlusions and disocclusions; 2) depth ordering of the layers; 3) temporal consistency of the layer segmentation. Additionally the optical ﬂow in each layer is modeled by a combination of a parametric model and a smooth deviation based on an MRF with a robust spatial prior; the resulting model allows roughness in layers. Finally, a key contribution is the formulation of the layers using an imagedependent hidden ﬁeld prior based on recent models for static scene segmentation. The method achieves state-of-the-art results on the Middlebury benchmark and produces meaningful scene segmentations as well as detected occlusion regions.</p><p>5 0.10308354 <a title="20-tfidf-5" href="./nips-2010-Moreau-Yosida_Regularization_for_Grouped_Tree_Structure_Learning.html">170 nips-2010-Moreau-Yosida Regularization for Grouped Tree Structure Learning</a></p>
<p>Author: Jun Liu, Jieping Ye</p><p>Abstract: We consider the tree structured group Lasso where the structure over the features can be represented as a tree with leaf nodes as features and internal nodes as clusters of the features. The structured regularization with a pre-deﬁned tree structure is based on a group-Lasso penalty, where one group is deﬁned for each node in the tree. Such a regularization can help uncover the structured sparsity, which is desirable for applications with some meaningful tree structures on the features. However, the tree structured group Lasso is challenging to solve due to the complex regularization. In this paper, we develop an efﬁcient algorithm for the tree structured group Lasso. One of the key steps in the proposed algorithm is to solve the Moreau-Yosida regularization associated with the grouped tree structure. The main technical contributions of this paper include (1) we show that the associated Moreau-Yosida regularization admits an analytical solution, and (2) we develop an efﬁcient algorithm for determining the effective interval for the regularization parameter. Our experimental results on the AR and JAFFE face data sets demonstrate the efﬁciency and effectiveness of the proposed algorithm.</p><p>6 0.10023946 <a title="20-tfidf-6" href="./nips-2010-Sparse_Coding_for_Learning_Interpretable_Spatio-Temporal_Primitives.html">246 nips-2010-Sparse Coding for Learning Interpretable Spatio-Temporal Primitives</a></p>
<p>7 0.069272757 <a title="20-tfidf-7" href="./nips-2010-Implicit_encoding_of_prior_probabilities_in_optimal_neural_populations.html">119 nips-2010-Implicit encoding of prior probabilities in optimal neural populations</a></p>
<p>8 0.067617252 <a title="20-tfidf-8" href="./nips-2010-Space-Variant_Single-Image_Blind_Deconvolution_for_Removing_Camera_Shake.html">245 nips-2010-Space-Variant Single-Image Blind Deconvolution for Removing Camera Shake</a></p>
<p>9 0.06564635 <a title="20-tfidf-9" href="./nips-2010-Mixture_of_time-warped_trajectory_models_for_movement_decoding.html">167 nips-2010-Mixture of time-warped trajectory models for movement decoding</a></p>
<p>10 0.063979879 <a title="20-tfidf-10" href="./nips-2010-Inferring_Stimulus_Selectivity_from_the_Spatial_Structure_of_Neural_Network_Dynamics.html">127 nips-2010-Inferring Stimulus Selectivity from the Spatial Structure of Neural Network Dynamics</a></p>
<p>11 0.062238172 <a title="20-tfidf-11" href="./nips-2010-Tree-Structured_Stick_Breaking_for_Hierarchical_Data.html">276 nips-2010-Tree-Structured Stick Breaking for Hierarchical Data</a></p>
<p>12 0.061536592 <a title="20-tfidf-12" href="./nips-2010-Feature_Transitions_with_Saccadic_Search%3A_Size%2C_Color%2C_and_Orientation_Are_Not_Alike.html">95 nips-2010-Feature Transitions with Saccadic Search: Size, Color, and Orientation Are Not Alike</a></p>
<p>13 0.061164383 <a title="20-tfidf-13" href="./nips-2010-Probabilistic_Belief_Revision_with_Structural_Constraints.html">214 nips-2010-Probabilistic Belief Revision with Structural Constraints</a></p>
<p>14 0.060963765 <a title="20-tfidf-14" href="./nips-2010-Learning_To_Count_Objects_in_Images.html">149 nips-2010-Learning To Count Objects in Images</a></p>
<p>15 0.053414594 <a title="20-tfidf-15" href="./nips-2010-Movement_extraction_by_detecting_dynamics_switches_and_repetitions.html">171 nips-2010-Movement extraction by detecting dynamics switches and repetitions</a></p>
<p>16 0.053396881 <a title="20-tfidf-16" href="./nips-2010-A_biologically_plausible_network_for_the_computation_of_orientation_dominance.html">17 nips-2010-A biologically plausible network for the computation of orientation dominance</a></p>
<p>17 0.052057847 <a title="20-tfidf-17" href="./nips-2010-Accounting_for_network_effects_in_neuronal_responses_using_L1_regularized_point_process_models.html">21 nips-2010-Accounting for network effects in neuronal responses using L1 regularized point process models</a></p>
<p>18 0.051660635 <a title="20-tfidf-18" href="./nips-2010-Linear_readout_from_a_neural_population_with_partial_correlation_data.html">161 nips-2010-Linear readout from a neural population with partial correlation data</a></p>
<p>19 0.050750423 <a title="20-tfidf-19" href="./nips-2010-Learning_concept_graphs_from_text_with_stick-breaking_priors.html">150 nips-2010-Learning concept graphs from text with stick-breaking priors</a></p>
<p>20 0.05067623 <a title="20-tfidf-20" href="./nips-2010-The_Neural_Costs_of_Optimal_Control.html">268 nips-2010-The Neural Costs of Optimal Control</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.146), (1, 0.056), (2, -0.191), (3, 0.063), (4, -0.033), (5, -0.153), (6, -0.059), (7, 0.059), (8, 0.017), (9, 0.051), (10, 0.12), (11, -0.448), (12, -0.157), (13, 0.203), (14, 0.143), (15, 0.219), (16, -0.255), (17, 0.091), (18, -0.059), (19, -0.012), (20, -0.166), (21, -0.111), (22, 0.0), (23, -0.064), (24, 0.014), (25, 0.044), (26, 0.047), (27, 0.045), (28, 0.019), (29, -0.03), (30, 0.014), (31, -0.005), (32, -0.038), (33, 0.049), (34, 0.119), (35, -0.026), (36, 0.002), (37, 0.026), (38, -0.028), (39, -0.055), (40, -0.014), (41, 0.012), (42, 0.089), (43, 0.069), (44, -0.001), (45, 0.062), (46, -0.003), (47, 0.109), (48, 0.001), (49, -0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98984832 <a title="20-lsi-1" href="./nips-2010-A_unified_model_of_short-range_and_long-range_motion_perception.html">20 nips-2010-A unified model of short-range and long-range motion perception</a></p>
<p>Author: Shuang Wu, Xuming He, Hongjing Lu, Alan L. Yuille</p><p>Abstract: The human vision system is able to effortlessly perceive both short-range and long-range motion patterns in complex dynamic scenes. Previous work has assumed that two different mechanisms are involved in processing these two types of motion. In this paper, we propose a hierarchical model as a uniﬁed framework for modeling both short-range and long-range motion perception. Our model consists of two key components: a data likelihood that proposes multiple motion hypotheses using nonlinear matching, and a hierarchical prior that imposes slowness and spatial smoothness constraints on the motion ﬁeld at multiple scales. We tested our model on two types of stimuli, random dot kinematograms and multiple-aperture stimuli, both commonly used in human vision research. We demonstrate that the hierarchical model adequately accounts for human performance in psychophysical experiments.</p><p>2 0.9600895 <a title="20-lsi-2" href="./nips-2010-Functional_form_of_motion_priors_in_human_motion_perception.html">98 nips-2010-Functional form of motion priors in human motion perception</a></p>
<p>Author: Hongjing Lu, Tungyou Lin, Alan Lee, Luminita Vese, Alan L. Yuille</p><p>Abstract: It has been speculated that the human motion system combines noisy measurements with prior expectations in an optimal, or rational, manner. The basic goal of our work is to discover experimentally which prior distribution is used. More speciﬁcally, we seek to infer the functional form of the motion prior from the performance of human subjects on motion estimation tasks. We restricted ourselves to priors which combine three terms for motion slowness, ﬁrst-order smoothness, and second-order smoothness. We focused on two functional forms for prior distributions: L2-norm and L1-norm regularization corresponding to the Gaussian and Laplace distributions respectively. In our ﬁrst experimental session we estimate the weights of the three terms for each functional form to maximize the ﬁt to human performance. We then measured human performance for motion tasks and found that we obtained better ﬁt for the L1-norm (Laplace) than for the L2-norm (Gaussian). We note that the L1-norm is also a better ﬁt to the statistics of motion in natural environments. In addition, we found large weights for the second-order smoothness term, indicating the importance of high-order smoothness compared to slowness and lower-order smoothness. To validate our results further, we used the best ﬁt models using the L1-norm to predict human performance in a second session with different experimental setups. Our results showed excellent agreement between human performance and model prediction – ranging from 3% to 8% for ﬁve human subjects over ten experimental conditions – and give further support that the human visual system uses an L1-norm (Laplace) prior.</p><p>3 0.70582891 <a title="20-lsi-3" href="./nips-2010-Occlusion_Detection_and_Motion_Estimation_with_Convex_Optimization.html">187 nips-2010-Occlusion Detection and Motion Estimation with Convex Optimization</a></p>
<p>Author: Alper Ayvaci, Michalis Raptis, Stefano Soatto</p><p>Abstract: We tackle the problem of simultaneously detecting occlusions and estimating optical ﬂow. We show that, under standard assumptions of Lambertian reﬂection and static illumination, the task can be posed as a convex minimization problem. Therefore, the solution, computed using efﬁcient algorithms, is guaranteed to be globally optimal, for any number of independently moving objects, and any number of occlusion layers. We test the proposed algorithm on benchmark datasets, expanded to enable evaluation of occlusion detection performance. 1</p><p>4 0.61940712 <a title="20-lsi-4" href="./nips-2010-Layered_image_motion_with_explicit_occlusions%2C_temporal_consistency%2C_and_depth_ordering.html">141 nips-2010-Layered image motion with explicit occlusions, temporal consistency, and depth ordering</a></p>
<p>Author: Deqing Sun, Erik B. Sudderth, Michael J. Black</p><p>Abstract: Layered models are a powerful way of describing natural scenes containing smooth surfaces that may overlap and occlude each other. For image motion estimation, such models have a long history but have not achieved the wide use or accuracy of non-layered methods. We present a new probabilistic model of optical ﬂow in layers that addresses many of the shortcomings of previous approaches. In particular, we deﬁne a probabilistic graphical model that explicitly captures: 1) occlusions and disocclusions; 2) depth ordering of the layers; 3) temporal consistency of the layer segmentation. Additionally the optical ﬂow in each layer is modeled by a combination of a parametric model and a smooth deviation based on an MRF with a robust spatial prior; the resulting model allows roughness in layers. Finally, a key contribution is the formulation of the layers using an imagedependent hidden ﬁeld prior based on recent models for static scene segmentation. The method achieves state-of-the-art results on the Middlebury benchmark and produces meaningful scene segmentations as well as detected occlusion regions.</p><p>5 0.37299198 <a title="20-lsi-5" href="./nips-2010-Space-Variant_Single-Image_Blind_Deconvolution_for_Removing_Camera_Shake.html">245 nips-2010-Space-Variant Single-Image Blind Deconvolution for Removing Camera Shake</a></p>
<p>Author: Stefan Harmeling, Hirsch Michael, Bernhard Schölkopf</p><p>Abstract: Modelling camera shake as a space-invariant convolution simpliﬁes the problem of removing camera shake, but often insufﬁciently models actual motion blur such as those due to camera rotation and movements outside the sensor plane or when objects in the scene have different distances to the camera. In an effort to address these limitations, (i) we introduce a taxonomy of camera shakes, (ii) we build on a recently introduced framework for space-variant ﬁltering by Hirsch et al. and a fast algorithm for single image blind deconvolution for space-invariant ﬁlters by Cho and Lee to construct a method for blind deconvolution in the case of space-variant blur, and (iii), we present an experimental setup for evaluation that allows us to take images with real camera shake while at the same time recording the spacevariant point spread function corresponding to that blur. Finally, we demonstrate that our method is able to deblur images degraded by spatially-varying blur originating from real camera shake, even without using additionally motion sensor information. 1</p><p>6 0.36658713 <a title="20-lsi-6" href="./nips-2010-A_Bayesian_Framework_for_Figure-Ground_Interpretation.html">3 nips-2010-A Bayesian Framework for Figure-Ground Interpretation</a></p>
<p>7 0.3604261 <a title="20-lsi-7" href="./nips-2010-Probabilistic_Belief_Revision_with_Structural_Constraints.html">214 nips-2010-Probabilistic Belief Revision with Structural Constraints</a></p>
<p>8 0.33886099 <a title="20-lsi-8" href="./nips-2010-Sparse_Coding_for_Learning_Interpretable_Spatio-Temporal_Primitives.html">246 nips-2010-Sparse Coding for Learning Interpretable Spatio-Temporal Primitives</a></p>
<p>9 0.27817312 <a title="20-lsi-9" href="./nips-2010-Improving_Human_Judgments_by_Decontaminating_Sequential_Dependencies.html">121 nips-2010-Improving Human Judgments by Decontaminating Sequential Dependencies</a></p>
<p>10 0.26086795 <a title="20-lsi-10" href="./nips-2010-Feature_Transitions_with_Saccadic_Search%3A_Size%2C_Color%2C_and_Orientation_Are_Not_Alike.html">95 nips-2010-Feature Transitions with Saccadic Search: Size, Color, and Orientation Are Not Alike</a></p>
<p>11 0.25094745 <a title="20-lsi-11" href="./nips-2010-Movement_extraction_by_detecting_dynamics_switches_and_repetitions.html">171 nips-2010-Movement extraction by detecting dynamics switches and repetitions</a></p>
<p>12 0.24814999 <a title="20-lsi-12" href="./nips-2010-Mixture_of_time-warped_trajectory_models_for_movement_decoding.html">167 nips-2010-Mixture of time-warped trajectory models for movement decoding</a></p>
<p>13 0.20821257 <a title="20-lsi-13" href="./nips-2010-Evaluating_neuronal_codes_for_inference_using_Fisher_information.html">81 nips-2010-Evaluating neuronal codes for inference using Fisher information</a></p>
<p>14 0.20195536 <a title="20-lsi-14" href="./nips-2010-Learning_the_context_of_a_category.html">155 nips-2010-Learning the context of a category</a></p>
<p>15 0.19990595 <a title="20-lsi-15" href="./nips-2010-Linear_readout_from_a_neural_population_with_partial_correlation_data.html">161 nips-2010-Linear readout from a neural population with partial correlation data</a></p>
<p>16 0.19976166 <a title="20-lsi-16" href="./nips-2010-Switched_Latent_Force_Models_for_Movement_Segmentation.html">262 nips-2010-Switched Latent Force Models for Movement Segmentation</a></p>
<p>17 0.19771448 <a title="20-lsi-17" href="./nips-2010-Global_seismic_monitoring_as_probabilistic_inference.html">107 nips-2010-Global seismic monitoring as probabilistic inference</a></p>
<p>18 0.18717226 <a title="20-lsi-18" href="./nips-2010-Hallucinations_in_Charles_Bonnet_Syndrome_Induced_by_Homeostasis%3A_a_Deep_Boltzmann_Machine_Model.html">111 nips-2010-Hallucinations in Charles Bonnet Syndrome Induced by Homeostasis: a Deep Boltzmann Machine Model</a></p>
<p>19 0.18470922 <a title="20-lsi-19" href="./nips-2010-Random_Projections_for_%24k%24-means_Clustering.html">221 nips-2010-Random Projections for $k$-means Clustering</a></p>
<p>20 0.17951727 <a title="20-lsi-20" href="./nips-2010-Structured_Determinantal_Point_Processes.html">257 nips-2010-Structured Determinantal Point Processes</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.031), (17, 0.021), (27, 0.133), (30, 0.054), (35, 0.051), (43, 0.252), (45, 0.19), (50, 0.05), (52, 0.027), (60, 0.015), (77, 0.053), (78, 0.016), (90, 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.83397353 <a title="20-lda-1" href="./nips-2010-Word_Features_for_Latent_Dirichlet_Allocation.html">286 nips-2010-Word Features for Latent Dirichlet Allocation</a></p>
<p>Author: James Petterson, Wray Buntine, Shravan M. Narayanamurthy, Tibério S. Caetano, Alex J. Smola</p><p>Abstract: We extend Latent Dirichlet Allocation (LDA) by explicitly allowing for the encoding of side information in the distribution over words. This results in a variety of new capabilities, such as improved estimates for infrequently occurring words, as well as the ability to leverage thesauri and dictionaries in order to boost topic cohesion within and across languages. We present experiments on multi-language topic synchronisation where dictionary information is used to bias corresponding words towards similar topics. Results indicate that our model substantially improves topic cohesion when compared to the standard LDA model. 1</p><p>same-paper 2 0.80234635 <a title="20-lda-2" href="./nips-2010-A_unified_model_of_short-range_and_long-range_motion_perception.html">20 nips-2010-A unified model of short-range and long-range motion perception</a></p>
<p>Author: Shuang Wu, Xuming He, Hongjing Lu, Alan L. Yuille</p><p>Abstract: The human vision system is able to effortlessly perceive both short-range and long-range motion patterns in complex dynamic scenes. Previous work has assumed that two different mechanisms are involved in processing these two types of motion. In this paper, we propose a hierarchical model as a uniﬁed framework for modeling both short-range and long-range motion perception. Our model consists of two key components: a data likelihood that proposes multiple motion hypotheses using nonlinear matching, and a hierarchical prior that imposes slowness and spatial smoothness constraints on the motion ﬁeld at multiple scales. We tested our model on two types of stimuli, random dot kinematograms and multiple-aperture stimuli, both commonly used in human vision research. We demonstrate that the hierarchical model adequately accounts for human performance in psychophysical experiments.</p><p>3 0.72909391 <a title="20-lda-3" href="./nips-2010-Functional_form_of_motion_priors_in_human_motion_perception.html">98 nips-2010-Functional form of motion priors in human motion perception</a></p>
<p>Author: Hongjing Lu, Tungyou Lin, Alan Lee, Luminita Vese, Alan L. Yuille</p><p>Abstract: It has been speculated that the human motion system combines noisy measurements with prior expectations in an optimal, or rational, manner. The basic goal of our work is to discover experimentally which prior distribution is used. More speciﬁcally, we seek to infer the functional form of the motion prior from the performance of human subjects on motion estimation tasks. We restricted ourselves to priors which combine three terms for motion slowness, ﬁrst-order smoothness, and second-order smoothness. We focused on two functional forms for prior distributions: L2-norm and L1-norm regularization corresponding to the Gaussian and Laplace distributions respectively. In our ﬁrst experimental session we estimate the weights of the three terms for each functional form to maximize the ﬁt to human performance. We then measured human performance for motion tasks and found that we obtained better ﬁt for the L1-norm (Laplace) than for the L2-norm (Gaussian). We note that the L1-norm is also a better ﬁt to the statistics of motion in natural environments. In addition, we found large weights for the second-order smoothness term, indicating the importance of high-order smoothness compared to slowness and lower-order smoothness. To validate our results further, we used the best ﬁt models using the L1-norm to predict human performance in a second session with different experimental setups. Our results showed excellent agreement between human performance and model prediction – ranging from 3% to 8% for ﬁve human subjects over ten experimental conditions – and give further support that the human visual system uses an L1-norm (Laplace) prior.</p><p>4 0.70266467 <a title="20-lda-4" href="./nips-2010-Accounting_for_network_effects_in_neuronal_responses_using_L1_regularized_point_process_models.html">21 nips-2010-Accounting for network effects in neuronal responses using L1 regularized point process models</a></p>
<p>Author: Ryan Kelly, Matthew Smith, Robert Kass, Tai S. Lee</p><p>Abstract: Activity of a neuron, even in the early sensory areas, is not simply a function of its local receptive ﬁeld or tuning properties, but depends on global context of the stimulus, as well as the neural context. This suggests the activity of the surrounding neurons and global brain states can exert considerable inﬂuence on the activity of a neuron. In this paper we implemented an L1 regularized point process model to assess the contribution of multiple factors to the ﬁring rate of many individual units recorded simultaneously from V1 with a 96-electrode “Utah” array. We found that the spikes of surrounding neurons indeed provide strong predictions of a neuron’s response, in addition to the neuron’s receptive ﬁeld transfer function. We also found that the same spikes could be accounted for with the local ﬁeld potentials, a surrogate measure of global network states. This work shows that accounting for network ﬂuctuations can improve estimates of single trial ﬁring rate and stimulus-response transfer functions. 1</p><p>5 0.70050156 <a title="20-lda-5" href="./nips-2010-Linear_readout_from_a_neural_population_with_partial_correlation_data.html">161 nips-2010-Linear readout from a neural population with partial correlation data</a></p>
<p>Author: Adrien Wohrer, Ranulfo Romo, Christian K. Machens</p><p>Abstract: How much information does a neural population convey about a stimulus? Answers to this question are known to strongly depend on the correlation of response variability in neural populations. These noise correlations, however, are essentially immeasurable as the number of parameters in a noise correlation matrix grows quadratically with population size. Here, we suggest to bypass this problem by imposing a parametric model on a noise correlation matrix. Our basic assumption is that noise correlations arise due to common inputs between neurons. On average, noise correlations will therefore reﬂect signal correlations, which can be measured in neural populations. We suggest an explicit parametric dependency between signal and noise correlations. We show how this dependency can be used to ”ﬁll the gaps” in noise correlations matrices using an iterative application of the Wishart distribution over positive deﬁnitive matrices. We apply our method to data from the primary somatosensory cortex of monkeys performing a two-alternativeforced choice task. We compare the discrimination thresholds read out from the population of recorded neurons with the discrimination threshold of the monkey and show that our method predicts different results than simpler, average schemes of noise correlations. 1</p><p>6 0.6922496 <a title="20-lda-6" href="./nips-2010-The_Neural_Costs_of_Optimal_Control.html">268 nips-2010-The Neural Costs of Optimal Control</a></p>
<p>7 0.69208527 <a title="20-lda-7" href="./nips-2010-Over-complete_representations_on_recurrent_neural_networks_can_support_persistent_percepts.html">200 nips-2010-Over-complete representations on recurrent neural networks can support persistent percepts</a></p>
<p>8 0.69196361 <a title="20-lda-8" href="./nips-2010-Brain_covariance_selection%3A_better_individual_functional_connectivity_models_using_population_prior.html">44 nips-2010-Brain covariance selection: better individual functional connectivity models using population prior</a></p>
<p>9 0.69186449 <a title="20-lda-9" href="./nips-2010-Evaluating_neuronal_codes_for_inference_using_Fisher_information.html">81 nips-2010-Evaluating neuronal codes for inference using Fisher information</a></p>
<p>10 0.68767565 <a title="20-lda-10" href="./nips-2010-A_biologically_plausible_network_for_the_computation_of_orientation_dominance.html">17 nips-2010-A biologically plausible network for the computation of orientation dominance</a></p>
<p>11 0.6863063 <a title="20-lda-11" href="./nips-2010-Functional_Geometry_Alignment_and_Localization_of_Brain_Areas.html">97 nips-2010-Functional Geometry Alignment and Localization of Brain Areas</a></p>
<p>12 0.68454981 <a title="20-lda-12" href="./nips-2010-Online_Learning_for_Latent_Dirichlet_Allocation.html">194 nips-2010-Online Learning for Latent Dirichlet Allocation</a></p>
<p>13 0.68415612 <a title="20-lda-13" href="./nips-2010-Group_Sparse_Coding_with_a_Laplacian_Scale_Mixture_Prior.html">109 nips-2010-Group Sparse Coding with a Laplacian Scale Mixture Prior</a></p>
<p>14 0.68248844 <a title="20-lda-14" href="./nips-2010-Individualized_ROI_Optimization_via_Maximization_of_Group-wise_Consistency_of_Structural_and_Functional_Profiles.html">123 nips-2010-Individualized ROI Optimization via Maximization of Group-wise Consistency of Structural and Functional Profiles</a></p>
<p>15 0.6813615 <a title="20-lda-15" href="./nips-2010-A_Discriminative_Latent_Model_of_Image_Region_and_Object_Tag_Correspondence.html">6 nips-2010-A Discriminative Latent Model of Image Region and Object Tag Correspondence</a></p>
<p>16 0.68030179 <a title="20-lda-16" href="./nips-2010-Cross_Species_Expression_Analysis_using_a_Dirichlet_Process_Mixture_Model_with_Latent_Matchings.html">55 nips-2010-Cross Species Expression Analysis using a Dirichlet Process Mixture Model with Latent Matchings</a></p>
<p>17 0.6773361 <a title="20-lda-17" href="./nips-2010-Deciphering_subsampled_data%3A_adaptive_compressive_sampling_as_a_principle_of_brain_communication.html">56 nips-2010-Deciphering subsampled data: adaptive compressive sampling as a principle of brain communication</a></p>
<p>18 0.67682779 <a title="20-lda-18" href="./nips-2010-Bayesian_Action-Graph_Games.html">39 nips-2010-Bayesian Action-Graph Games</a></p>
<p>19 0.67556781 <a title="20-lda-19" href="./nips-2010-Short-term_memory_in_neuronal_networks_through_dynamical_compressed_sensing.html">238 nips-2010-Short-term memory in neuronal networks through dynamical compressed sensing</a></p>
<p>20 0.67516237 <a title="20-lda-20" href="./nips-2010-The_Maximal_Causes_of_Natural_Scenes_are_Edge_Filters.html">266 nips-2010-The Maximal Causes of Natural Scenes are Edge Filters</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
