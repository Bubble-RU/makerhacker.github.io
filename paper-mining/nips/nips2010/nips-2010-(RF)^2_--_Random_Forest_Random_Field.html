<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1 nips-2010-(RF)^2 -- Random Forest Random Field</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-1" href="#">nips2010-1</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1 nips-2010-(RF)^2 -- Random Forest Random Field</h1>
<br/><p>Source: <a title="nips-2010-1-pdf" href="http://papers.nips.cc/paper/4140-rf2-random-forest-random-field.pdf">pdf</a></p><p>Author: Nadia Payet, Sinisa Todorovic</p><p>Abstract: We combine random forest (RF) and conditional random ﬁeld (CRF) into a new computational framework, called random forest random ﬁeld (RF)2 . Inference of (RF)2 uses the Swendsen-Wang cut algorithm, characterized by MetropolisHastings jumps. A jump from one state to another depends on the ratio of the proposal distributions, and on the ratio of the posterior distributions of the two states. Prior work typically resorts to a parametric estimation of these four distributions, and then computes their ratio. Our key idea is to instead directly estimate these ratios using RF. RF collects in leaf nodes of each decision tree the class histograms of training examples. We use these class histograms for a nonparametric estimation of the distribution ratios. We derive the theoretical error bounds of a two-class (RF)2 . (RF)2 is applied to a challenging task of multiclass object recognition and segmentation over a random ﬁeld of input image regions. In our empirical evaluation, we use only the visual information provided by image regions (e.g., color, texture, spatial layout), whereas the competing methods additionally use higher-level cues about the horizon location and 3D layout of surfaces in the scene. Nevertheless, (RF)2 outperforms the state of the art on benchmark datasets, in terms of accuracy and computation time.</p><p>Reference: <a title="nips-2010-1-reference" href="../nips2010_reference/nips-2010-%28RF%29%5E2_--_Random_Forest_Random_Field_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 A jump from one state to another depends on the ratio of the proposal distributions, and on the ratio of the posterior distributions of the two states. [sent-7, score-0.316]
</p><p>2 RF collects in leaf nodes of each decision tree the class histograms of training examples. [sent-10, score-0.421]
</p><p>3 (RF)2 is applied to a challenging task of multiclass object recognition and segmentation over a random ﬁeld of input image regions. [sent-13, score-0.269]
</p><p>4 In our empirical evaluation, we use only the visual information provided by image regions (e. [sent-14, score-0.122]
</p><p>5 We derive theoretical performance bounds of (RF)2 , and demonstrate its utility on a challenging task of conjoint object recognition and segmentation. [sent-19, score-0.171]
</p><p>6 Identifying subimage ownership among occurrences of distinct object classes in an image is a fundamental, and one of the most actively pursued problem in computer vision, machine learning, and artiﬁcial intelligence [1–11]. [sent-20, score-0.203]
</p><p>7 Thus, we derive a uniﬁed framework for combined object recognition and segmentation, as a graph-structured prediction of all random variables in a single, consistent model of the scene. [sent-26, score-0.143]
</p><p>8 The graphical model we use is Conditional Random Field (CRF) [12]—one of the most popular models for structured inference over pixels [2, 3], patches [4, 5], or image regions [6–8], for object recognition and segmentation. [sent-27, score-0.305]
</p><p>9 The jumps between the states are reversible, and governed by a proposal density q(Y (t) → Y (t+1) ). [sent-41, score-0.168]
</p><p>10 The proposal is accepted if the acceptance rate, α, drawn from U (0, 1), satisﬁes (t+1)  (t)  (t+1)  →Y |X) α< min{1, q(Y (t) →Y (t+1) ) p(Y (t) |X) }. [sent-42, score-0.151]
</p><p>11 As can be seen, the entire inference process is regulated by ratios of the proposal and posterior distributions. [sent-44, score-0.324]
</p><p>12 Our key idea is to directly estimate the ratios of the proposal and posterior distributions, instead of computing each individual distribution for conducting MH jumps. [sent-46, score-0.284]
</p><p>13 We view the trees as a way of discriminatively structuring evidence about the class distributions in the training set. [sent-51, score-0.187]
</p><p>14 In particular, each leaf of each tree in RF stores a histogram of the number of training examples from each class that reached that leaf. [sent-52, score-0.343]
</p><p>15 When a new example is encountered, it is “dropped” down each of the trees in the forest, until it reaches a leaf in every tree. [sent-53, score-0.237]
</p><p>16 The class histograms stored in all these leaves can then be used as a robust estimate of the ratio of that example’s posterior distributions. [sent-54, score-0.213]
</p><p>17 This is related to recent work on Hough forests for object detection and localization [14], where leaves collect information on locations and sizes of bounding boxes of objects in training images. [sent-55, score-0.386]
</p><p>18 However, they use this evidence to predict a spatial distribution of bounding boxes in a test image, whereas we use the evidence stored in tree leaves to predict the distribution ratios. [sent-56, score-0.321]
</p><p>19 Evidence trees are also used in [15], but only as a ﬁrst stage of a stacked-classiﬁer architecture which replaces the standard majority voting of RF. [sent-57, score-0.15]
</p><p>20 We are not aware of any theoretical analysis of RF as an estimator of ratios of posterior distributions. [sent-61, score-0.21]
</p><p>21 Learning is efﬁciently conducted by RF which collects the class histograms of training examples in leaf nodes of each decision tree. [sent-63, score-0.373]
</p><p>22 This evidence is then used for the non-parametric estimation of the ratios of the proposal and posterior distributions, required by MH-based inference of (RF)2 . [sent-64, score-0.374]
</p><p>23 We derive the theoretical error bounds of estimating distribution ratios by a two-class RF, which is then used to derive the theoretical performance bounds of a two-class (RF)2 . [sent-65, score-0.168]
</p><p>24 2  2 CRF Model We formulate multiclass object recognition and segmentation as the MAP inference of a CRF, deﬁned over a set of multiscale image regions. [sent-68, score-0.352]
</p><p>25 Regions are used as image features, because they are dimensionally matched with 2D object occurrences in the image, and thus facilitate modeling of various perceptual-organization and contextual cues (e. [sent-69, score-0.2]
</p><p>26 Access to regions is provided by the state-ofthe-art, multiscale segmentation algorithm of [17], which detects and closes object (and object-part) boundaries using the domain knowledge. [sent-72, score-0.312]
</p><p>27 Since the right scale at which objects occur is unknown, we use all regions from all scales. [sent-73, score-0.116]
</p><p>28 The extracted regions are organized in a graph, G = (V, E), with V and E are sets of nodes and edges. [sent-74, score-0.149]
</p><p>29 Each node i is characterized by a descriptor vector, xi , whose elements describe photometric and geometric properties of the corresponding region (e. [sent-79, score-0.144]
</p><p>30 Since the segmentation algorithm of [17] is strictly hierarchical, region i is descendent of region j, if i is fully embedded as subregion within ancestor j. [sent-83, score-0.206]
</p><p>31 Each edge (i, j) is associated with a tag, eij , indicating the relationship type between i and j. [sent-87, score-0.123]
</p><p>32 Let pi = p(yi |xi ) and pij = p(yi , yj |xi , xj , eij ) denote the posterior distributions over nodes and pairs of nodes. [sent-93, score-0.416]
</p><p>33 Then, we deﬁne CRF as (1) p(Y |G) = i∈V p(yi |xi ) (i,j)∈E p(yi , yj |xi , xj , eij ) = i∈V pi (i,j)∈E pij . [sent-94, score-0.249]
</p><p>34 SWcut iterates the Metropolis-Hastings (MH) reversible jumps through the following two steps. [sent-98, score-0.119]
</p><p>35 (1) Graph clustering: SW-cut probabilistically samples connected components, CC’s, where each CC represents a subset of nodes with the same color. [sent-99, score-0.133]
</p><p>36 This is done by probabilistically cutting edges between all graph nodes that have the same color based on their posterior distributions pij = p(yi , yj |xi , xj , eij ). [sent-100, score-0.599]
</p><p>37 (2) Graph relabeling: SW-cut randomly selects one of the CC’s obtained in step (1), and randomly ﬂips the color of all nodes in that CC, and cuts their edges with the rest of the graph nodes having that same color. [sent-101, score-0.251]
</p><p>38 If i and j have the same label, their edge is probabilistically sampled according to posterior distribution pij . [sent-111, score-0.217]
</p><p>39 To separate the re-colored CC from the rest of the graph, we cut existing edges that connect CC to the rest of the graph nodes with that same color. [sent-115, score-0.192]
</p><p>40 Let q(A → B) be the proposal probability for moving from state A to B, and let q(B → A) denote the converse. [sent-118, score-0.141]
</p><p>41 Also, the ratio p(Y =B|G) p(Y =A|G) accounts only for the recolored nodes in CC – not the entire graph G, since all other probabilities have not changed from state A to state B. [sent-122, score-0.204]
</p><p>42 (1), the ratios of the proposal and posterior distributions characterizing states A and B can be speciﬁed as B pB p(Y = B|G) pB q(B→A) (i,j)∈CutB (1−pij ) ij i , and = = · . [sent-124, score-0.354]
</p><p>43 (3) q(A→B) p(Y = A|G) (1−pA ) pA pA ij ij (i,j)∈CutA i∈CC i j∈N (i)  where CutA and CutB denote the sets of “cut” edges in states A and B, and N (i) is the set of neighbors of node i, N (i) = {j : j ∈ V, (i, j) ∈ E}. [sent-125, score-0.154]
</p><p>44 4 Learning RF can be used for estimating the ratios of the proposal and posterior distributions, given by Eq. [sent-130, score-0.284]
</p><p>45 If region i falls within the bounding box of an object in class y ∈ {1, 2, . [sent-135, score-0.204]
</p><p>46 If i covers a number of bounding boxes of different classes then i is added to the training set multiple times to account for all distinct class labels it covers. [sent-139, score-0.185]
</p><p>47 , M } is used to learn an ensemble of T decision trees representing RF. [sent-144, score-0.12]
</p><p>48 In particular, each training sample is passed through every decision tree from the ensemble until it reaches a leaf node. [sent-145, score-0.296]
</p><p>49 Each leaf l records a class histogram, Φl = {φl (y) : y = 1, . [sent-146, score-0.165]
</p><p>50 , K; e = 1, 2, 3}, where ψll′ (y, y ′ , e) counts the number of pairs of training examples belonging to classes y and y ′ that reached leaves l and l′ , and also have the relationship type e – namely, ascendent/descendent, touching, or far relationship. [sent-154, score-0.159]
</p><p>51 Given Φl and Ψll′ , we in a position to estimate the ratios of the proposal and posterior distributions, deﬁned in (3), which control the Metropolis-Hastings jumps in the SW-cut. [sent-155, score-0.35]
</p><p>52 Suppose two regions, A A B B represented by their descriptors xi and xj , are labeled as yi and yj in state A, and yi and yj in state B of one iteration of the SW-cut. [sent-156, score-0.288]
</p><p>53 Also, after passing xi and xj through T decision trees of the t t learned RF, suppose they reached leaves li and lj in each tree t = 1, . [sent-157, score-0.263]
</p><p>54 Then, we compute pB i = pA i  T B t=1 φlt (yi ) i , T A t=1 φlt (yi ) i  pB ij = pA ij  T B B t=1 ψlt lt (yi , yj , eij ) i j , T A A t=1 ψlt lt (yi , yj , eij ) i j  To estimate the ratio of the proposal distributions,  q(B→A) q(A→B) ,  for estimating  p(Y = B|G) . [sent-161, score-0.695]
</p><p>55 Thus, we compute pij =  T t=1 ψlt lt (yi , yj , eij ) i j T Φl t t=1 Φlt i j  for estimating  q(B→A) . [sent-163, score-0.325]
</p><p>56 5 Results (RF)2 is evaluated on the task of object recognition and segmentation on two benchmark datasets. [sent-165, score-0.229]
</p><p>57 Second, the Street-Scene dataset consists of 3547 images of urban environments, and has manually annotated regions [6, 19]. [sent-168, score-0.12]
</p><p>58 Both datasets provide labels of bounding boxes around object occurrences as ground truth. [sent-170, score-0.255]
</p><p>59 Images are segmented using the multiscale segmentation algorithm of [17], which uses the perceptual signiﬁcance of a region boundary, Pb ∈ [0, 100], as an input parameter. [sent-171, score-0.189]
</p><p>60 If a region covers a number of bounding boxes of different classes, it is added to the training set multiple times to account for each distinct label. [sent-176, score-0.181]
</p><p>61 We use the standard random splits of training data to train 100 decision trees of RF, constructed in the top-down way. [sent-177, score-0.155]
</p><p>62 The growth of each tree is constrained so its depth is less than 30, and its every leaf node contains at least 20 training examples. [sent-178, score-0.276]
</p><p>63 To recognize and segment objects in a new test image, we ﬁrst extract a hierarchy of regions from the image by the segmentation algorithm of [17]. [sent-179, score-0.242]
</p><p>64 We examine the following three variants of (RF)2 : (RF)2 -1 — The spatial relationships of regions, eij , are not accounted for when computing pij in Eq. [sent-183, score-0.239]
</p><p>65 (5); (RF)2 -2 — The region relationships touching and far are considered, while the ascendent/descendent relationship is not captured; and (RF)2 -3 — All three types of region layout and structural relationships are modeled. [sent-185, score-0.286]
</p><p>66 Note that considering region layouts and structure changes only the class histograms recorded by leaf nodes of the learned decision trees, but it does not increase complexity. [sent-187, score-0.371]
</p><p>67 This metric is suitable, because it does not favor object classes that occur in images more frequently. [sent-189, score-0.168]
</p><p>68 The additional consideration of the region relationships touching and far increases performance relative to that of (RF)2 -1, as expected. [sent-195, score-0.156]
</p><p>69 Note that the methods of [6,21] additionally use higher-level cues about the horizon location and 3D scene layout in their object recognition and segmentation. [sent-198, score-0.215]
</p><p>70 Our segmentation results on example MSRC and Street-Scene images are shown in Fig. [sent-200, score-0.124]
</p><p>71 Labels of the ﬁnest-scale regions are depicted using distinct colors, since pixels get labels of the ﬁnest-scale regions. [sent-202, score-0.117]
</p><p>72 (RF)2 yields the best performance for all object classes except one. [sent-206, score-0.13]
</p><p>73 5  Figure 1: Our object recognition and segmentation results on example images from the MSRC dataset (top two rows), and the Street-Scene dataset (bottom two rows). [sent-207, score-0.267]
</p><p>74 The ﬁgure depicts boundaries of the ﬁnest-scale regions found by the multiscale algorithm of [17], and the color-coded labels of these regions inferred by (RF)2 . [sent-208, score-0.242]
</p><p>75 An MH jump between states A and B is controlled by the acceptance rate α(A→B) which depends on 6  the ratios of the proposal and posterior distributions, q(B→A)p(Y =B|G) . [sent-251, score-0.358]
</p><p>76 1 An Upper Error Bound of (RF)2 An error occurs along MH jumps when a balanced reversible jump is encountered, i. [sent-255, score-0.144]
</p><p>77 , when there q(B→A) is no preference between jumping from state A to state B and reverse, q(A→B) =1, and RF wrongly predicts that the posterior distribution of state B is larger than that of A, p(Y =B|G) ≥1. [sent-257, score-0.187]
</p><p>78 We consider a binary classiﬁcation problem, for simplicity, where training and test instances may have positive and negative labels. [sent-281, score-0.121]
</p><p>79 Instead, we assume that the learned decision trees have the following properties. [sent-286, score-0.12]
</p><p>80 Each leaf node of a decision tree: (i) stores a total of C training instances that reach the leaf; and (ii) has a probabilistic margin γ ∈ [0, 1/2). [sent-287, score-0.362]
</p><p>81 By margin, we mean that in every leaf reached by C training instances a fraction of 1/2 + γ of the training instances will belong to one class (e. [sent-288, score-0.394]
</p><p>82 We say that a leaf is positive if a majority of the training instances collected by the leaf is positive, or otherwise, we say that the leaf is negative. [sent-293, score-0.59]
</p><p>83 It is straightforward to show that when a positive instance is dropped through one of the decision trees in RF, it will 7  reach a positive leaf with probability 1/2 + γ, and a negative leaf with probability 1/2 − γ [15]. [sent-294, score-0.53]
</p><p>84 A new test instance is classiﬁed by dropping it through T decision trees, and taking a majority vote of the labels of all C · T training instances stored in the leaves reached by the test instance. [sent-296, score-0.366]
</p><p>85 We refer to this classiﬁcation procedure as evidence voting [15], as opposed to decision voting over the leaf labels in the standard RF [13]. [sent-297, score-0.454]
</p><p>86 The following proposition states that the probability that evidence voting misclassiﬁes an instance, P (ǫ1 ), is upper bounded. [sent-298, score-0.164]
</p><p>87 The probability that RF with T trees, where every leaf stores C training instances, incorrectly classiﬁes an instance is upper bounded, P (ǫ1 )≤ exp(−8CT γ 4 ). [sent-300, score-0.253]
</p><p>88 Evidence voting for labeling an instance can be formalized as drawing a total of C·T independent Bernoulli random variables, with the success rate p1 , whose outcomes are {−1, +1}, where +1 is received for correct, and −1 for incorrect labeling of the instance. [sent-302, score-0.209]
</p><p>89 Evidence voting is also used for labeling pairs of instances. [sent-311, score-0.117]
</p><p>90 The probability that evidence voting misclassiﬁes a pair of test instances, P (ǫ2 ), is upper bounded, as stated in Proposition 2. [sent-312, score-0.128]
</p><p>91 Evidence voting for labeling a pair of instances can be formalized as drawing a total of C 2 T independent Bernoulli random variables, with success rate p2 , whose outcomes are {−1, +1}, where +1 is received for correct, and −1 for incorrect labeling of the instance pair. [sent-316, score-0.269]
</p><p>92 From Proposition 1, it follows that the probability that RF makes a wrong prediction about the posterior ratio of an instance is upper bounded, P (Zi ≥ 1) = P (ǫ1 ) = exp(−8CT γ 4), ∀i ∈ CC. [sent-320, score-0.156]
</p><p>93 In addition, From Proposition 2, it follows that the probability that RF makes a wrong prediction about the posterior ratio of a pair of instances is upper bounded, P (Wij ≥ 1) = P (ǫ2 ) = exp(−8C 2 T π 4 γ 8 ), ∀i ∈ CC and j ∈ N (i). [sent-322, score-0.189]
</p><p>94 Our key idea is to employ RF to directly compute the ratios of the proposal and posterior distributions of states visited along the Metropolis-Hastings reversible jumps, instead of estimating each individual distribution, and thus improve the convergence rate and accuracy of the CRF inference. [sent-330, score-0.367]
</p><p>95 Such a non-parametric formulation of CRF and its inference has been demonstrated to outperform, in terms of computation time and accuracy, existing parametric CRF models on the task of multiclass object recognition and segmentation. [sent-331, score-0.183]
</p><p>96 Fei-Fei, “Towards total scene understanding: Classiﬁcation, annotation and segmentation in an automatic framework,” in CVPR, 2009. [sent-337, score-0.123]
</p><p>97 Criminisi, “Textonboost: Joint appearance, shape and context modeling for multi-class object recognition and segmentation,” in ECCV, 2006, pp. [sent-349, score-0.143]
</p><p>98 Koller, “Region-based segmentation and object detection,” in NIPS, 2009. [sent-363, score-0.187]
</p><p>99 Lempitsky, “Class-speciﬁc hough forests for object detection,” in CVPR, 2009. [sent-408, score-0.2]
</p><p>100 Lanckriet, “Multi-class object localization by combining local contextual interactions,” in CVPR, 2010. [sent-446, score-0.127]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('rf', 0.744), ('crf', 0.239), ('cc', 0.182), ('leaf', 0.165), ('msrc', 0.154), ('eij', 0.123), ('ratios', 0.112), ('proposal', 0.102), ('mh', 0.101), ('object', 0.101), ('pb', 0.097), ('segmentation', 0.086), ('regions', 0.082), ('pij', 0.081), ('voting', 0.078), ('lt', 0.076), ('forests', 0.074), ('trees', 0.072), ('posterior', 0.07), ('nodes', 0.067), ('probabilistically', 0.066), ('jumps', 0.066), ('touching', 0.061), ('wij', 0.06), ('instances', 0.06), ('region', 0.06), ('leaves', 0.056), ('fz', 0.054), ('todorovic', 0.054), ('forest', 0.053), ('reversible', 0.053), ('evidence', 0.05), ('acceptance', 0.049), ('decision', 0.048), ('tree', 0.048), ('edges', 0.046), ('yc', 0.046), ('yi', 0.046), ('cuta', 0.046), ('cutb', 0.046), ('payet', 0.046), ('cut', 0.045), ('yj', 0.045), ('fw', 0.044), ('multiscale', 0.043), ('boxes', 0.043), ('bounding', 0.043), ('recognition', 0.042), ('image', 0.04), ('ij', 0.04), ('inference', 0.04), ('cvpr', 0.039), ('labeling', 0.039), ('state', 0.039), ('reached', 0.039), ('pa', 0.039), ('images', 0.038), ('color', 0.037), ('scene', 0.037), ('proposition', 0.036), ('layout', 0.035), ('labels', 0.035), ('training', 0.035), ('dropping', 0.035), ('relationships', 0.035), ('wrong', 0.034), ('objects', 0.034), ('graph', 0.034), ('zi', 0.033), ('occurrences', 0.033), ('descriptor', 0.031), ('stored', 0.031), ('bernoulli', 0.031), ('histograms', 0.031), ('bessel', 0.031), ('fwij', 0.031), ('fzi', 0.031), ('histogram', 0.03), ('exp', 0.03), ('distributions', 0.03), ('classes', 0.029), ('theoretical', 0.028), ('node', 0.028), ('labeled', 0.028), ('ll', 0.028), ('dropped', 0.027), ('instance', 0.027), ('arbelaez', 0.027), ('collects', 0.027), ('sinisa', 0.027), ('contextual', 0.026), ('stores', 0.026), ('negative', 0.026), ('success', 0.026), ('ratio', 0.025), ('iccv', 0.025), ('jump', 0.025), ('galleguillos', 0.025), ('hough', 0.025), ('photometric', 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999946 <a title="1-tfidf-1" href="./nips-2010-%28RF%29%5E2_--_Random_Forest_Random_Field.html">1 nips-2010-(RF)^2 -- Random Forest Random Field</a></p>
<p>Author: Nadia Payet, Sinisa Todorovic</p><p>Abstract: We combine random forest (RF) and conditional random ﬁeld (CRF) into a new computational framework, called random forest random ﬁeld (RF)2 . Inference of (RF)2 uses the Swendsen-Wang cut algorithm, characterized by MetropolisHastings jumps. A jump from one state to another depends on the ratio of the proposal distributions, and on the ratio of the posterior distributions of the two states. Prior work typically resorts to a parametric estimation of these four distributions, and then computes their ratio. Our key idea is to instead directly estimate these ratios using RF. RF collects in leaf nodes of each decision tree the class histograms of training examples. We use these class histograms for a nonparametric estimation of the distribution ratios. We derive the theoretical error bounds of a two-class (RF)2 . (RF)2 is applied to a challenging task of multiclass object recognition and segmentation over a random ﬁeld of input image regions. In our empirical evaluation, we use only the visual information provided by image regions (e.g., color, texture, spatial layout), whereas the competing methods additionally use higher-level cues about the horizon location and 3D layout of surfaces in the scene. Nevertheless, (RF)2 outperforms the state of the art on benchmark datasets, in terms of accuracy and computation time.</p><p>2 0.1548252 <a title="1-tfidf-2" href="./nips-2010-Evidence-Specific_Structures_for_Rich_Tractable_CRFs.html">83 nips-2010-Evidence-Specific Structures for Rich Tractable CRFs</a></p>
<p>Author: Anton Chechetka, Carlos Guestrin</p><p>Abstract: We present a simple and effective approach to learning tractable conditional random ﬁelds with structure that depends on the evidence. Our approach retains the advantages of tractable discriminative models, namely efﬁcient exact inference and arbitrarily accurate parameter learning in polynomial time. At the same time, our algorithm does not suffer a large expressive power penalty inherent to ﬁxed tractable structures. On real-life relational datasets, our approach matches or exceeds state of the art accuracy of the dense models, and at the same time provides an order of magnitude speedup. 1</p><p>3 0.12236846 <a title="1-tfidf-3" href="./nips-2010-Simultaneous_Object_Detection_and_Ranking_with_Weak_Supervision.html">240 nips-2010-Simultaneous Object Detection and Ranking with Weak Supervision</a></p>
<p>Author: Matthew Blaschko, Andrea Vedaldi, Andrew Zisserman</p><p>Abstract: A standard approach to learning object category detectors is to provide strong supervision in the form of a region of interest (ROI) specifying each instance of the object in the training images [17]. In this work are goal is to learn from heterogeneous labels, in which some images are only weakly supervised, specifying only the presence or absence of the object or a weak indication of object location, whilst others are fully annotated. To this end we develop a discriminative learning approach and make two contributions: (i) we propose a structured output formulation for weakly annotated images where full annotations are treated as latent variables; and (ii) we propose to optimize a ranking objective function, allowing our method to more effectively use negatively labeled images to improve detection average precision performance. The method is demonstrated on the benchmark INRIA pedestrian detection dataset of Dalal and Triggs [14] and the PASCAL VOC dataset [17], and it is shown that for a signiﬁcant proportion of weakly supervised images the performance achieved is very similar to the fully supervised (state of the art) results. 1</p><p>4 0.097764678 <a title="1-tfidf-4" href="./nips-2010-Size_Matters%3A_Metric_Visual_Search_Constraints_from_Monocular_Metadata.html">241 nips-2010-Size Matters: Metric Visual Search Constraints from Monocular Metadata</a></p>
<p>Author: Mario Fritz, Kate Saenko, Trevor Darrell</p><p>Abstract: Metric constraints are known to be highly discriminative for many objects, but if training is limited to data captured from a particular 3-D sensor the quantity of training data may be severly limited. In this paper, we show how a crucial aspect of 3-D information–object and feature absolute size–can be added to models learned from commonly available online imagery, without use of any 3-D sensing or reconstruction at training time. Such models can be utilized at test time together with explicit 3-D sensing to perform robust search. Our model uses a “2.1D” local feature, which combines traditional appearance gradient statistics with an estimate of average absolute depth within the local window. We show how category size information can be obtained from online images by exploiting relatively unbiquitous metadata ﬁelds specifying camera intrinstics. We develop an efﬁcient metric branch-and-bound algorithm for our search task, imposing 3-D size constraints as part of an optimal search for a set of features which indicate the presence of a category. Experiments on test scenes captured with a traditional stereo rig are shown, exploiting training data from from purely monocular sources with associated EXIF metadata. 1</p><p>5 0.097015664 <a title="1-tfidf-5" href="./nips-2010-Label_Embedding_Trees_for_Large_Multi-Class_Tasks.html">135 nips-2010-Label Embedding Trees for Large Multi-Class Tasks</a></p>
<p>Author: Samy Bengio, Jason Weston, David Grangier</p><p>Abstract: Multi-class classiﬁcation becomes challenging at test time when the number of classes is very large and testing against every possible class can become computationally infeasible. This problem can be alleviated by imposing (or learning) a structure over the set of classes. We propose an algorithm for learning a treestructure of classiﬁers which, by optimizing the overall tree loss, provides superior accuracy to existing tree labeling methods. We also propose a method that learns to embed labels in a low dimensional space that is faster than non-embedding approaches and has superior accuracy to existing embedding approaches. Finally we combine the two ideas resulting in the label embedding tree that outperforms alternative methods including One-vs-Rest while being orders of magnitude faster. 1</p><p>6 0.096500367 <a title="1-tfidf-6" href="./nips-2010-Efficient_Minimization_of_Decomposable_Submodular_Functions.html">69 nips-2010-Efficient Minimization of Decomposable Submodular Functions</a></p>
<p>7 0.094850317 <a title="1-tfidf-7" href="./nips-2010-Evaluating_neuronal_codes_for_inference_using_Fisher_information.html">81 nips-2010-Evaluating neuronal codes for inference using Fisher information</a></p>
<p>8 0.092901982 <a title="1-tfidf-8" href="./nips-2010-Object_Bank%3A_A_High-Level_Image_Representation_for_Scene_Classification_%26_Semantic_Feature_Sparsification.html">186 nips-2010-Object Bank: A High-Level Image Representation for Scene Classification & Semantic Feature Sparsification</a></p>
<p>9 0.091262273 <a title="1-tfidf-9" href="./nips-2010-Inter-time_segment_information_sharing_for_non-homogeneous_dynamic_Bayesian_networks.html">129 nips-2010-Inter-time segment information sharing for non-homogeneous dynamic Bayesian networks</a></p>
<p>10 0.087020136 <a title="1-tfidf-10" href="./nips-2010-Towards_Holistic_Scene_Understanding%3A_Feedback_Enabled_Cascaded_Classification_Models.html">272 nips-2010-Towards Holistic Scene Understanding: Feedback Enabled Cascaded Classification Models</a></p>
<p>11 0.085586965 <a title="1-tfidf-11" href="./nips-2010-Learning_To_Count_Objects_in_Images.html">149 nips-2010-Learning To Count Objects in Images</a></p>
<p>12 0.084565505 <a title="1-tfidf-12" href="./nips-2010-Epitome_driven_3-D_Diffusion_Tensor_image_segmentation%3A_on_extracting_specific_structures.html">77 nips-2010-Epitome driven 3-D Diffusion Tensor image segmentation: on extracting specific structures</a></p>
<p>13 0.076527826 <a title="1-tfidf-13" href="./nips-2010-Estimating_Spatial_Layout_of_Rooms_using_Volumetric_Reasoning_about_Objects_and_Surfaces.html">79 nips-2010-Estimating Spatial Layout of Rooms using Volumetric Reasoning about Objects and Surfaces</a></p>
<p>14 0.076330811 <a title="1-tfidf-14" href="./nips-2010-A_Discriminative_Latent_Model_of_Image_Region_and_Object_Tag_Correspondence.html">6 nips-2010-A Discriminative Latent Model of Image Region and Object Tag Correspondence</a></p>
<p>15 0.074687265 <a title="1-tfidf-15" href="./nips-2010-Worst-case_bounds_on_the_quality_of_max-product_fixed-points.html">288 nips-2010-Worst-case bounds on the quality of max-product fixed-points</a></p>
<p>16 0.073182032 <a title="1-tfidf-16" href="./nips-2010-Large_Margin_Learning_of_Upstream_Scene_Understanding_Models.html">137 nips-2010-Large Margin Learning of Upstream Scene Understanding Models</a></p>
<p>17 0.072686948 <a title="1-tfidf-17" href="./nips-2010-Improving_Human_Judgments_by_Decontaminating_Sequential_Dependencies.html">121 nips-2010-Improving Human Judgments by Decontaminating Sequential Dependencies</a></p>
<p>18 0.071476266 <a title="1-tfidf-18" href="./nips-2010-Segmentation_as_Maximum-Weight_Independent_Set.html">234 nips-2010-Segmentation as Maximum-Weight Independent Set</a></p>
<p>19 0.07143303 <a title="1-tfidf-19" href="./nips-2010-Tree-Structured_Stick_Breaking_for_Hierarchical_Data.html">276 nips-2010-Tree-Structured Stick Breaking for Hierarchical Data</a></p>
<p>20 0.071230918 <a title="1-tfidf-20" href="./nips-2010-Extensions_of_Generalized_Binary_Search_to_Group_Identification_and_Exponential_Costs.html">88 nips-2010-Extensions of Generalized Binary Search to Group Identification and Exponential Costs</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.191), (1, 0.08), (2, -0.058), (3, -0.116), (4, -0.072), (5, -0.034), (6, -0.083), (7, -0.005), (8, 0.11), (9, 0.024), (10, -0.081), (11, 0.01), (12, -0.054), (13, 0.063), (14, -0.022), (15, -0.041), (16, -0.002), (17, -0.122), (18, 0.024), (19, 0.049), (20, -0.003), (21, 0.008), (22, 0.089), (23, -0.028), (24, 0.008), (25, 0.084), (26, -0.016), (27, -0.016), (28, -0.084), (29, -0.004), (30, -0.034), (31, -0.004), (32, -0.15), (33, -0.125), (34, -0.02), (35, -0.013), (36, 0.038), (37, 0.013), (38, -0.064), (39, -0.072), (40, 0.075), (41, 0.048), (42, -0.025), (43, -0.04), (44, -0.058), (45, 0.046), (46, -0.004), (47, 0.013), (48, -0.095), (49, -0.082)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92759705 <a title="1-lsi-1" href="./nips-2010-%28RF%29%5E2_--_Random_Forest_Random_Field.html">1 nips-2010-(RF)^2 -- Random Forest Random Field</a></p>
<p>Author: Nadia Payet, Sinisa Todorovic</p><p>Abstract: We combine random forest (RF) and conditional random ﬁeld (CRF) into a new computational framework, called random forest random ﬁeld (RF)2 . Inference of (RF)2 uses the Swendsen-Wang cut algorithm, characterized by MetropolisHastings jumps. A jump from one state to another depends on the ratio of the proposal distributions, and on the ratio of the posterior distributions of the two states. Prior work typically resorts to a parametric estimation of these four distributions, and then computes their ratio. Our key idea is to instead directly estimate these ratios using RF. RF collects in leaf nodes of each decision tree the class histograms of training examples. We use these class histograms for a nonparametric estimation of the distribution ratios. We derive the theoretical error bounds of a two-class (RF)2 . (RF)2 is applied to a challenging task of multiclass object recognition and segmentation over a random ﬁeld of input image regions. In our empirical evaluation, we use only the visual information provided by image regions (e.g., color, texture, spatial layout), whereas the competing methods additionally use higher-level cues about the horizon location and 3D layout of surfaces in the scene. Nevertheless, (RF)2 outperforms the state of the art on benchmark datasets, in terms of accuracy and computation time.</p><p>2 0.60113603 <a title="1-lsi-2" href="./nips-2010-Evidence-Specific_Structures_for_Rich_Tractable_CRFs.html">83 nips-2010-Evidence-Specific Structures for Rich Tractable CRFs</a></p>
<p>Author: Anton Chechetka, Carlos Guestrin</p><p>Abstract: We present a simple and effective approach to learning tractable conditional random ﬁelds with structure that depends on the evidence. Our approach retains the advantages of tractable discriminative models, namely efﬁcient exact inference and arbitrarily accurate parameter learning in polynomial time. At the same time, our algorithm does not suffer a large expressive power penalty inherent to ﬁxed tractable structures. On real-life relational datasets, our approach matches or exceeds state of the art accuracy of the dense models, and at the same time provides an order of magnitude speedup. 1</p><p>3 0.55771661 <a title="1-lsi-3" href="./nips-2010-Simultaneous_Object_Detection_and_Ranking_with_Weak_Supervision.html">240 nips-2010-Simultaneous Object Detection and Ranking with Weak Supervision</a></p>
<p>Author: Matthew Blaschko, Andrea Vedaldi, Andrew Zisserman</p><p>Abstract: A standard approach to learning object category detectors is to provide strong supervision in the form of a region of interest (ROI) specifying each instance of the object in the training images [17]. In this work are goal is to learn from heterogeneous labels, in which some images are only weakly supervised, specifying only the presence or absence of the object or a weak indication of object location, whilst others are fully annotated. To this end we develop a discriminative learning approach and make two contributions: (i) we propose a structured output formulation for weakly annotated images where full annotations are treated as latent variables; and (ii) we propose to optimize a ranking objective function, allowing our method to more effectively use negatively labeled images to improve detection average precision performance. The method is demonstrated on the benchmark INRIA pedestrian detection dataset of Dalal and Triggs [14] and the PASCAL VOC dataset [17], and it is shown that for a signiﬁcant proportion of weakly supervised images the performance achieved is very similar to the fully supervised (state of the art) results. 1</p><p>4 0.53462893 <a title="1-lsi-4" href="./nips-2010-Segmentation_as_Maximum-Weight_Independent_Set.html">234 nips-2010-Segmentation as Maximum-Weight Independent Set</a></p>
<p>Author: William Brendel, Sinisa Todorovic</p><p>Abstract: Given an ensemble of distinct, low-level segmentations of an image, our goal is to identify visually “meaningful” segments in the ensemble. Knowledge about any speciﬁc objects and surfaces present in the image is not available. The selection of image regions occupied by objects is formalized as the maximum-weight independent set (MWIS) problem. MWIS is the heaviest subset of mutually non-adjacent nodes of an attributed graph. We construct such a graph from all segments in the ensemble. Then, MWIS selects maximally distinctive segments that together partition the image. A new MWIS algorithm is presented. The algorithm seeks a solution directly in the discrete domain, instead of relaxing MWIS to a continuous problem, as common in previous work. It iteratively ﬁnds a candidate discrete solution of the Taylor series expansion of the original MWIS objective function around the previous solution. The algorithm is shown to converge to an optimum. Our empirical evaluation on the benchmark Berkeley segmentation dataset shows that the new algorithm eliminates the need for hand-picking optimal input parameters of the state-of-the-art segmenters, and outperforms their best, manually optimized results.</p><p>5 0.52640831 <a title="1-lsi-5" href="./nips-2010-Size_Matters%3A_Metric_Visual_Search_Constraints_from_Monocular_Metadata.html">241 nips-2010-Size Matters: Metric Visual Search Constraints from Monocular Metadata</a></p>
<p>Author: Mario Fritz, Kate Saenko, Trevor Darrell</p><p>Abstract: Metric constraints are known to be highly discriminative for many objects, but if training is limited to data captured from a particular 3-D sensor the quantity of training data may be severly limited. In this paper, we show how a crucial aspect of 3-D information–object and feature absolute size–can be added to models learned from commonly available online imagery, without use of any 3-D sensing or reconstruction at training time. Such models can be utilized at test time together with explicit 3-D sensing to perform robust search. Our model uses a “2.1D” local feature, which combines traditional appearance gradient statistics with an estimate of average absolute depth within the local window. We show how category size information can be obtained from online images by exploiting relatively unbiquitous metadata ﬁelds specifying camera intrinstics. We develop an efﬁcient metric branch-and-bound algorithm for our search task, imposing 3-D size constraints as part of an optimal search for a set of features which indicate the presence of a category. Experiments on test scenes captured with a traditional stereo rig are shown, exploiting training data from from purely monocular sources with associated EXIF metadata. 1</p><p>6 0.50590563 <a title="1-lsi-6" href="./nips-2010-Learning_To_Count_Objects_in_Images.html">149 nips-2010-Learning To Count Objects in Images</a></p>
<p>7 0.49432665 <a title="1-lsi-7" href="./nips-2010-Improving_Human_Judgments_by_Decontaminating_Sequential_Dependencies.html">121 nips-2010-Improving Human Judgments by Decontaminating Sequential Dependencies</a></p>
<p>8 0.49038947 <a title="1-lsi-8" href="./nips-2010-Epitome_driven_3-D_Diffusion_Tensor_image_segmentation%3A_on_extracting_specific_structures.html">77 nips-2010-Epitome driven 3-D Diffusion Tensor image segmentation: on extracting specific structures</a></p>
<p>9 0.48612586 <a title="1-lsi-9" href="./nips-2010-Learning_Efficient_Markov_Networks.html">144 nips-2010-Learning Efficient Markov Networks</a></p>
<p>10 0.48196831 <a title="1-lsi-10" href="./nips-2010-Learning_invariant_features_using_the_Transformed_Indian_Buffet_Process.html">153 nips-2010-Learning invariant features using the Transformed Indian Buffet Process</a></p>
<p>11 0.46973175 <a title="1-lsi-11" href="./nips-2010-Object_Bank%3A_A_High-Level_Image_Representation_for_Scene_Classification_%26_Semantic_Feature_Sparsification.html">186 nips-2010-Object Bank: A High-Level Image Representation for Scene Classification & Semantic Feature Sparsification</a></p>
<p>12 0.46917069 <a title="1-lsi-12" href="./nips-2010-A_Bayesian_Framework_for_Figure-Ground_Interpretation.html">3 nips-2010-A Bayesian Framework for Figure-Ground Interpretation</a></p>
<p>13 0.46215388 <a title="1-lsi-13" href="./nips-2010-A_Discriminative_Latent_Model_of_Image_Region_and_Object_Tag_Correspondence.html">6 nips-2010-A Discriminative Latent Model of Image Region and Object Tag Correspondence</a></p>
<p>14 0.45997697 <a title="1-lsi-14" href="./nips-2010-Efficient_Relational_Learning_with_Hidden_Variable_Detection.html">71 nips-2010-Efficient Relational Learning with Hidden Variable Detection</a></p>
<p>15 0.45799017 <a title="1-lsi-15" href="./nips-2010-Inter-time_segment_information_sharing_for_non-homogeneous_dynamic_Bayesian_networks.html">129 nips-2010-Inter-time segment information sharing for non-homogeneous dynamic Bayesian networks</a></p>
<p>16 0.45675367 <a title="1-lsi-16" href="./nips-2010-Estimating_Spatial_Layout_of_Rooms_using_Volumetric_Reasoning_about_Objects_and_Surfaces.html">79 nips-2010-Estimating Spatial Layout of Rooms using Volumetric Reasoning about Objects and Surfaces</a></p>
<p>17 0.45076773 <a title="1-lsi-17" href="./nips-2010-Evaluating_neuronal_codes_for_inference_using_Fisher_information.html">81 nips-2010-Evaluating neuronal codes for inference using Fisher information</a></p>
<p>18 0.44583249 <a title="1-lsi-18" href="./nips-2010-A_Primal-Dual_Message-Passing_Algorithm_for_Approximated_Large_Scale_Structured_Prediction.html">13 nips-2010-A Primal-Dual Message-Passing Algorithm for Approximated Large Scale Structured Prediction</a></p>
<p>19 0.44465068 <a title="1-lsi-19" href="./nips-2010-Static_Analysis_of_Binary_Executables_Using_Structural_SVMs.html">255 nips-2010-Static Analysis of Binary Executables Using Structural SVMs</a></p>
<p>20 0.4367322 <a title="1-lsi-20" href="./nips-2010-A_Bayesian_Approach_to_Concept_Drift.html">2 nips-2010-A Bayesian Approach to Concept Drift</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.027), (16, 0.167), (17, 0.027), (27, 0.095), (30, 0.061), (35, 0.015), (45, 0.242), (50, 0.053), (52, 0.033), (60, 0.036), (72, 0.029), (77, 0.046), (78, 0.031), (90, 0.043)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.91358644 <a title="1-lda-1" href="./nips-2010-Movement_extraction_by_detecting_dynamics_switches_and_repetitions.html">171 nips-2010-Movement extraction by detecting dynamics switches and repetitions</a></p>
<p>Author: Silvia Chiappa, Jan R. Peters</p><p>Abstract: Many time-series such as human movement data consist of a sequence of basic actions, e.g., forehands and backhands in tennis. Automatically extracting and characterizing such actions is an important problem for a variety of different applications. In this paper, we present a probabilistic segmentation approach in which an observed time-series is modeled as a concatenation of segments corresponding to different basic actions. Each segment is generated through a noisy transformation of one of a few hidden trajectories representing different types of movement, with possible time re-scaling. We analyze three different approximation methods for dealing with model intractability, and demonstrate how the proposed approach can successfully segment table tennis movements recorded using a robot arm as haptic input device. 1</p><p>2 0.90434921 <a title="1-lda-2" href="./nips-2010-Random_Conic_Pursuit_for_Semidefinite_Programming.html">219 nips-2010-Random Conic Pursuit for Semidefinite Programming</a></p>
<p>Author: Ariel Kleiner, Ali Rahimi, Michael I. Jordan</p><p>Abstract: We present a novel algorithm, Random Conic Pursuit, that solves semideﬁnite programs (SDPs) via repeated optimization over randomly selected two-dimensional subcones of the PSD cone. This scheme is simple, easily implemented, applicable to very general SDPs, scalable, and theoretically interesting. Its advantages are realized at the expense of an ability to readily compute highly exact solutions, though useful approximate solutions are easily obtained. This property renders Random Conic Pursuit of particular interest for machine learning applications, in which the relevant SDPs are generally based upon random data and so exact minima are often not a priority. Indeed, we present empirical results to this effect for various SDPs encountered in machine learning; these experiments demonstrate the potential practical usefulness of Random Conic Pursuit. We also provide a preliminary analysis that yields insight into the theoretical properties and convergence of the algorithm. 1</p><p>same-paper 3 0.90408981 <a title="1-lda-3" href="./nips-2010-%28RF%29%5E2_--_Random_Forest_Random_Field.html">1 nips-2010-(RF)^2 -- Random Forest Random Field</a></p>
<p>Author: Nadia Payet, Sinisa Todorovic</p><p>Abstract: We combine random forest (RF) and conditional random ﬁeld (CRF) into a new computational framework, called random forest random ﬁeld (RF)2 . Inference of (RF)2 uses the Swendsen-Wang cut algorithm, characterized by MetropolisHastings jumps. A jump from one state to another depends on the ratio of the proposal distributions, and on the ratio of the posterior distributions of the two states. Prior work typically resorts to a parametric estimation of these four distributions, and then computes their ratio. Our key idea is to instead directly estimate these ratios using RF. RF collects in leaf nodes of each decision tree the class histograms of training examples. We use these class histograms for a nonparametric estimation of the distribution ratios. We derive the theoretical error bounds of a two-class (RF)2 . (RF)2 is applied to a challenging task of multiclass object recognition and segmentation over a random ﬁeld of input image regions. In our empirical evaluation, we use only the visual information provided by image regions (e.g., color, texture, spatial layout), whereas the competing methods additionally use higher-level cues about the horizon location and 3D layout of surfaces in the scene. Nevertheless, (RF)2 outperforms the state of the art on benchmark datasets, in terms of accuracy and computation time.</p><p>4 0.89988285 <a title="1-lda-4" href="./nips-2010-Large-Scale_Matrix_Factorization_with_Missing_Data_under_Additional_Constraints.html">136 nips-2010-Large-Scale Matrix Factorization with Missing Data under Additional Constraints</a></p>
<p>Author: Kaushik Mitra, Sameer Sheorey, Rama Chellappa</p><p>Abstract: Matrix factorization in the presence of missing data is at the core of many computer vision problems such as structure from motion (SfM), non-rigid SfM and photometric stereo. We formulate the problem of matrix factorization with missing data as a low-rank semideﬁnite program (LRSDP) with the advantage that: 1) an efﬁcient quasi-Newton implementation of the LRSDP enables us to solve large-scale factorization problems, and 2) additional constraints such as orthonormality, required in orthographic SfM, can be directly incorporated in the new formulation. Our empirical evaluations suggest that, under the conditions of matrix completion theory, the proposed algorithm ﬁnds the optimal solution, and also requires fewer observations compared to the current state-of-the-art algorithms. We further demonstrate the effectiveness of the proposed algorithm in solving the afﬁne SfM problem, non-rigid SfM and photometric stereo problems.</p><p>5 0.87497175 <a title="1-lda-5" href="./nips-2010-Predictive_State_Temporal_Difference_Learning.html">212 nips-2010-Predictive State Temporal Difference Learning</a></p>
<p>Author: Byron Boots, Geoffrey J. Gordon</p><p>Abstract: We propose a new approach to value function approximation which combines linear temporal difference reinforcement learning with subspace identiﬁcation. In practical applications, reinforcement learning (RL) is complicated by the fact that state is either high-dimensional or partially observable. Therefore, RL methods are designed to work with features of state rather than state itself, and the success or failure of learning is often determined by the suitability of the selected features. By comparison, subspace identiﬁcation (SSID) methods are designed to select a feature set which preserves as much information as possible about state. In this paper we connect the two approaches, looking at the problem of reinforcement learning with a large set of features, each of which may only be marginally useful for value function approximation. We introduce a new algorithm for this situation, called Predictive State Temporal Difference (PSTD) learning. As in SSID for predictive state representations, PSTD ﬁnds a linear compression operator that projects a large set of features down to a small set that preserves the maximum amount of predictive information. As in RL, PSTD then uses a Bellman recursion to estimate a value function. We discuss the connection between PSTD and prior approaches in RL and SSID. We prove that PSTD is statistically consistent, perform several experiments that illustrate its properties, and demonstrate its potential on a difﬁcult optimal stopping problem. 1</p><p>6 0.84557098 <a title="1-lda-6" href="./nips-2010-Two-Layer_Generalization_Analysis_for_Ranking_Using_Rademacher_Average.html">277 nips-2010-Two-Layer Generalization Analysis for Ranking Using Rademacher Average</a></p>
<p>7 0.84222305 <a title="1-lda-7" href="./nips-2010-Learning_the_context_of_a_category.html">155 nips-2010-Learning the context of a category</a></p>
<p>8 0.83917058 <a title="1-lda-8" href="./nips-2010-The_Neural_Costs_of_Optimal_Control.html">268 nips-2010-The Neural Costs of Optimal Control</a></p>
<p>9 0.83892465 <a title="1-lda-9" href="./nips-2010-Variable_margin_losses_for_classifier_design.html">282 nips-2010-Variable margin losses for classifier design</a></p>
<p>10 0.83796775 <a title="1-lda-10" href="./nips-2010-A_biologically_plausible_network_for_the_computation_of_orientation_dominance.html">17 nips-2010-A biologically plausible network for the computation of orientation dominance</a></p>
<p>11 0.83731371 <a title="1-lda-11" href="./nips-2010-Distributed_Dual_Averaging_In_Networks.html">63 nips-2010-Distributed Dual Averaging In Networks</a></p>
<p>12 0.83690906 <a title="1-lda-12" href="./nips-2010-Construction_of_Dependent_Dirichlet_Processes_based_on_Poisson_Processes.html">51 nips-2010-Construction of Dependent Dirichlet Processes based on Poisson Processes</a></p>
<p>13 0.83644038 <a title="1-lda-13" href="./nips-2010-Short-term_memory_in_neuronal_networks_through_dynamical_compressed_sensing.html">238 nips-2010-Short-term memory in neuronal networks through dynamical compressed sensing</a></p>
<p>14 0.83571273 <a title="1-lda-14" href="./nips-2010-Learning_via_Gaussian_Herding.html">158 nips-2010-Learning via Gaussian Herding</a></p>
<p>15 0.8356483 <a title="1-lda-15" href="./nips-2010-Object_Bank%3A_A_High-Level_Image_Representation_for_Scene_Classification_%26_Semantic_Feature_Sparsification.html">186 nips-2010-Object Bank: A High-Level Image Representation for Scene Classification & Semantic Feature Sparsification</a></p>
<p>16 0.83534473 <a title="1-lda-16" href="./nips-2010-Inter-time_segment_information_sharing_for_non-homogeneous_dynamic_Bayesian_networks.html">129 nips-2010-Inter-time segment information sharing for non-homogeneous dynamic Bayesian networks</a></p>
<p>17 0.83467472 <a title="1-lda-17" href="./nips-2010-Functional_form_of_motion_priors_in_human_motion_perception.html">98 nips-2010-Functional form of motion priors in human motion perception</a></p>
<p>18 0.8341369 <a title="1-lda-18" href="./nips-2010-Brain_covariance_selection%3A_better_individual_functional_connectivity_models_using_population_prior.html">44 nips-2010-Brain covariance selection: better individual functional connectivity models using population prior</a></p>
<p>19 0.83361638 <a title="1-lda-19" href="./nips-2010-Exact_learning_curves_for_Gaussian_process_regression_on_large_random_graphs.html">85 nips-2010-Exact learning curves for Gaussian process regression on large random graphs</a></p>
<p>20 0.83357209 <a title="1-lda-20" href="./nips-2010-Extended_Bayesian_Information_Criteria_for_Gaussian_Graphical_Models.html">87 nips-2010-Extended Bayesian Information Criteria for Gaussian Graphical Models</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
