<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>143 nips-2010-Learning Convolutional Feature Hierarchies for Visual Recognition</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-143" href="#">nips2010-143</a> knowledge-graph by maker-knowledge-mining</p><h1>143 nips-2010-Learning Convolutional Feature Hierarchies for Visual Recognition</h1>
<br/><p>Source: <a title="nips-2010-143-pdf" href="http://papers.nips.cc/paper/4133-learning-convolutional-feature-hierarchies-for-visual-recognition.pdf">pdf</a></p><p>Author: Koray Kavukcuoglu, Pierre Sermanet, Y-lan Boureau, Karol Gregor, Michael Mathieu, Yann L. Cun</p><p>Abstract: We propose an unsupervised method for learning multi-stage hierarchies of sparse convolutional features. While sparse coding has become an increasingly popular method for learning visual features, it is most often trained at the patch level. Applying the resulting ﬁlters convolutionally results in highly redundant codes because overlapping patches are encoded in isolation. By training convolutionally over large image windows, our method reduces the redudancy between feature vectors at neighboring locations and improves the efﬁciency of the overall representation. In addition to a linear decoder that reconstructs the image from sparse features, our method trains an efﬁcient feed-forward encoder that predicts quasisparse features from the input. While patch-based training rarely produces anything but oriented edge detectors, we show that convolutional training produces highly diverse ﬁlters, including center-surround ﬁlters, corner detectors, cross detectors, and oriented grating detectors. We show that using these ﬁlters in multistage convolutional network architecture improves performance on a number of visual recognition and detection tasks. 1</p><p>Reference: <a title="nips-2010-143-reference" href="../nips2010_reference/nips-2010-Learning_Convolutional_Feature_Hierarchies_for_Visual_Recognition_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('convolv', 0.613), ('dict', 0.307), ('pedest', 0.2), ('sdtanh', 0.18), ('cod', 0.167), ('lay', 0.156), ('unsuperv', 0.152), ('encod', 0.149), ('patch', 0.149), ('lter', 0.139), ('spars', 0.137), ('cdshrink', 0.113), ('train', 0.104), ('architect', 0.104), ('im', 0.097), ('feat', 0.096), ('stag', 0.096), ('lecun', 0.091), ('zkpq', 0.09), ('tanh', 0.086)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="143-tfidf-1" href="./nips-2010-Learning_Convolutional_Feature_Hierarchies_for_Visual_Recognition.html">143 nips-2010-Learning Convolutional Feature Hierarchies for Visual Recognition</a></p>
<p>2 0.2838501 <a title="143-tfidf-2" href="./nips-2010-Pose-Sensitive_Embedding_by_Nonlinear_NCA_Regression.html">209 nips-2010-Pose-Sensitive Embedding by Nonlinear NCA Regression</a></p>
<p>3 0.21436745 <a title="143-tfidf-3" href="./nips-2010-Deep_Coding_Network.html">59 nips-2010-Deep Coding Network</a></p>
<p>4 0.1974059 <a title="143-tfidf-4" href="./nips-2010-Factorized_Latent_Spaces_with_Structured_Sparsity.html">89 nips-2010-Factorized Latent Spaces with Structured Sparsity</a></p>
<p>5 0.17455089 <a title="143-tfidf-5" href="./nips-2010-Layer-wise_analysis_of_deep_networks_with_Gaussian_kernels.html">140 nips-2010-Layer-wise analysis of deep networks with Gaussian kernels</a></p>
<p>6 0.16484398 <a title="143-tfidf-6" href="./nips-2010-Kernel_Descriptors_for_Visual_Recognition.html">133 nips-2010-Kernel Descriptors for Visual Recognition</a></p>
<p>7 0.16222723 <a title="143-tfidf-7" href="./nips-2010-Generating_more_realistic_images_using_gated_MRF%27s.html">103 nips-2010-Generating more realistic images using gated MRF's</a></p>
<p>8 0.15409209 <a title="143-tfidf-8" href="./nips-2010-Tiled_convolutional_neural_networks.html">271 nips-2010-Tiled convolutional neural networks</a></p>
<p>9 0.15049659 <a title="143-tfidf-9" href="./nips-2010-Simultaneous_Object_Detection_and_Ranking_with_Weak_Supervision.html">240 nips-2010-Simultaneous Object Detection and Ranking with Weak Supervision</a></p>
<p>10 0.14836589 <a title="143-tfidf-10" href="./nips-2010-The_Neural_Costs_of_Optimal_Control.html">268 nips-2010-The Neural Costs of Optimal Control</a></p>
<p>11 0.14462663 <a title="143-tfidf-11" href="./nips-2010-Deciphering_subsampled_data%3A_adaptive_compressive_sampling_as_a_principle_of_brain_communication.html">56 nips-2010-Deciphering subsampled data: adaptive compressive sampling as a principle of brain communication</a></p>
<p>12 0.13453563 <a title="143-tfidf-12" href="./nips-2010-Over-complete_representations_on_recurrent_neural_networks_can_support_persistent_percepts.html">200 nips-2010-Over-complete representations on recurrent neural networks can support persistent percepts</a></p>
<p>13 0.13402636 <a title="143-tfidf-13" href="./nips-2010-Layered_image_motion_with_explicit_occlusions%2C_temporal_consistency%2C_and_depth_ordering.html">141 nips-2010-Layered image motion with explicit occlusions, temporal consistency, and depth ordering</a></p>
<p>14 0.12767419 <a title="143-tfidf-14" href="./nips-2010-The_Maximal_Causes_of_Natural_Scenes_are_Edge_Filters.html">266 nips-2010-The Maximal Causes of Natural Scenes are Edge Filters</a></p>
<p>15 0.12675753 <a title="143-tfidf-15" href="./nips-2010-Size_Matters%3A_Metric_Visual_Search_Constraints_from_Monocular_Metadata.html">241 nips-2010-Size Matters: Metric Visual Search Constraints from Monocular Metadata</a></p>
<p>16 0.12432711 <a title="143-tfidf-16" href="./nips-2010-Sparse_Coding_for_Learning_Interpretable_Spatio-Temporal_Primitives.html">246 nips-2010-Sparse Coding for Learning Interpretable Spatio-Temporal Primitives</a></p>
<p>17 0.11701527 <a title="143-tfidf-17" href="./nips-2010-Towards_Holistic_Scene_Understanding%3A_Feedback_Enabled_Cascaded_Classification_Models.html">272 nips-2010-Towards Holistic Scene Understanding: Feedback Enabled Cascaded Classification Models</a></p>
<p>18 0.11676495 <a title="143-tfidf-18" href="./nips-2010-Object_Bank%3A_A_High-Level_Image_Representation_for_Scene_Classification_%26_Semantic_Feature_Sparsification.html">186 nips-2010-Object Bank: A High-Level Image Representation for Scene Classification & Semantic Feature Sparsification</a></p>
<p>19 0.11095157 <a title="143-tfidf-19" href="./nips-2010-Group_Sparse_Coding_with_a_Laplacian_Scale_Mixture_Prior.html">109 nips-2010-Group Sparse Coding with a Laplacian Scale Mixture Prior</a></p>
<p>20 0.10908744 <a title="143-tfidf-20" href="./nips-2010-Space-Variant_Single-Image_Blind_Deconvolution_for_Removing_Camera_Shake.html">245 nips-2010-Space-Variant Single-Image Blind Deconvolution for Removing Camera Shake</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.249), (1, -0.122), (2, -0.052), (3, 0.276), (4, -0.008), (5, 0.123), (6, 0.112), (7, -0.006), (8, -0.098), (9, 0.01), (10, 0.215), (11, 0.099), (12, 0.071), (13, -0.024), (14, -0.041), (15, -0.167), (16, -0.03), (17, 0.042), (18, -0.088), (19, -0.012), (20, -0.115), (21, -0.046), (22, 0.057), (23, -0.022), (24, 0.014), (25, -0.064), (26, -0.011), (27, -0.029), (28, -0.079), (29, 0.038), (30, 0.039), (31, -0.019), (32, -0.092), (33, -0.02), (34, -0.046), (35, -0.072), (36, 0.006), (37, -0.102), (38, 0.016), (39, -0.074), (40, 0.013), (41, 0.001), (42, 0.061), (43, -0.02), (44, -0.13), (45, 0.038), (46, 0.094), (47, 0.087), (48, 0.035), (49, -0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93850297 <a title="143-lsi-1" href="./nips-2010-Learning_Convolutional_Feature_Hierarchies_for_Visual_Recognition.html">143 nips-2010-Learning Convolutional Feature Hierarchies for Visual Recognition</a></p>
<p>2 0.84549797 <a title="143-lsi-2" href="./nips-2010-Deep_Coding_Network.html">59 nips-2010-Deep Coding Network</a></p>
<p>3 0.73142689 <a title="143-lsi-3" href="./nips-2010-Tiled_convolutional_neural_networks.html">271 nips-2010-Tiled convolutional neural networks</a></p>
<p>4 0.70383394 <a title="143-lsi-4" href="./nips-2010-Pose-Sensitive_Embedding_by_Nonlinear_NCA_Regression.html">209 nips-2010-Pose-Sensitive Embedding by Nonlinear NCA Regression</a></p>
<p>5 0.65320849 <a title="143-lsi-5" href="./nips-2010-Hallucinations_in_Charles_Bonnet_Syndrome_Induced_by_Homeostasis%3A_a_Deep_Boltzmann_Machine_Model.html">111 nips-2010-Hallucinations in Charles Bonnet Syndrome Induced by Homeostasis: a Deep Boltzmann Machine Model</a></p>
<p>6 0.64377731 <a title="143-lsi-6" href="./nips-2010-Sparse_Coding_for_Learning_Interpretable_Spatio-Temporal_Primitives.html">246 nips-2010-Sparse Coding for Learning Interpretable Spatio-Temporal Primitives</a></p>
<p>7 0.64180404 <a title="143-lsi-7" href="./nips-2010-Energy_Disaggregation_via_Discriminative_Sparse_Coding.html">76 nips-2010-Energy Disaggregation via Discriminative Sparse Coding</a></p>
<p>8 0.63625079 <a title="143-lsi-8" href="./nips-2010-The_Maximal_Causes_of_Natural_Scenes_are_Edge_Filters.html">266 nips-2010-The Maximal Causes of Natural Scenes are Edge Filters</a></p>
<p>9 0.63537896 <a title="143-lsi-9" href="./nips-2010-Generating_more_realistic_images_using_gated_MRF%27s.html">103 nips-2010-Generating more realistic images using gated MRF's</a></p>
<p>10 0.62617213 <a title="143-lsi-10" href="./nips-2010-Layer-wise_analysis_of_deep_networks_with_Gaussian_kernels.html">140 nips-2010-Layer-wise analysis of deep networks with Gaussian kernels</a></p>
<p>11 0.61806756 <a title="143-lsi-11" href="./nips-2010-Group_Sparse_Coding_with_a_Laplacian_Scale_Mixture_Prior.html">109 nips-2010-Group Sparse Coding with a Laplacian Scale Mixture Prior</a></p>
<p>12 0.59798747 <a title="143-lsi-12" href="./nips-2010-Over-complete_representations_on_recurrent_neural_networks_can_support_persistent_percepts.html">200 nips-2010-Over-complete representations on recurrent neural networks can support persistent percepts</a></p>
<p>13 0.58959973 <a title="143-lsi-13" href="./nips-2010-Space-Variant_Single-Image_Blind_Deconvolution_for_Removing_Camera_Shake.html">245 nips-2010-Space-Variant Single-Image Blind Deconvolution for Removing Camera Shake</a></p>
<p>14 0.58112836 <a title="143-lsi-14" href="./nips-2010-Factorized_Latent_Spaces_with_Structured_Sparsity.html">89 nips-2010-Factorized Latent Spaces with Structured Sparsity</a></p>
<p>15 0.56928164 <a title="143-lsi-15" href="./nips-2010-Learning_to_combine_foveal_glimpses_with_a_third-order_Boltzmann_machine.html">156 nips-2010-Learning to combine foveal glimpses with a third-order Boltzmann machine</a></p>
<p>16 0.55096787 <a title="143-lsi-16" href="./nips-2010-A_biologically_plausible_network_for_the_computation_of_orientation_dominance.html">17 nips-2010-A biologically plausible network for the computation of orientation dominance</a></p>
<p>17 0.55013633 <a title="143-lsi-17" href="./nips-2010-Deciphering_subsampled_data%3A_adaptive_compressive_sampling_as_a_principle_of_brain_communication.html">56 nips-2010-Deciphering subsampled data: adaptive compressive sampling as a principle of brain communication</a></p>
<p>18 0.54918742 <a title="143-lsi-18" href="./nips-2010-Gated_Softmax_Classification.html">99 nips-2010-Gated Softmax Classification</a></p>
<p>19 0.51847804 <a title="143-lsi-19" href="./nips-2010-Phone_Recognition_with_the_Mean-Covariance_Restricted_Boltzmann_Machine.html">206 nips-2010-Phone Recognition with the Mean-Covariance Restricted Boltzmann Machine</a></p>
<p>20 0.51713109 <a title="143-lsi-20" href="./nips-2010-Learning_To_Count_Objects_in_Images.html">149 nips-2010-Learning To Count Objects in Images</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(7, 0.052), (30, 0.025), (32, 0.096), (34, 0.08), (36, 0.011), (45, 0.066), (68, 0.587)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.98253083 <a title="143-lda-1" href="./nips-2010-Estimating_Spatial_Layout_of_Rooms_using_Volumetric_Reasoning_about_Objects_and_Surfaces.html">79 nips-2010-Estimating Spatial Layout of Rooms using Volumetric Reasoning about Objects and Surfaces</a></p>
<p>2 0.96310425 <a title="143-lda-2" href="./nips-2010-Switching_state_space_model_for_simultaneously_estimating_state_transitions_and_nonstationary_firing_rates.html">263 nips-2010-Switching state space model for simultaneously estimating state transitions and nonstationary firing rates</a></p>
<p>same-paper 3 0.95971811 <a title="143-lda-3" href="./nips-2010-Learning_Convolutional_Feature_Hierarchies_for_Visual_Recognition.html">143 nips-2010-Learning Convolutional Feature Hierarchies for Visual Recognition</a></p>
<p>4 0.93232214 <a title="143-lda-4" href="./nips-2010-Worst-case_bounds_on_the_quality_of_max-product_fixed-points.html">288 nips-2010-Worst-case bounds on the quality of max-product fixed-points</a></p>
<p>5 0.92989266 <a title="143-lda-5" href="./nips-2010-Towards_Holistic_Scene_Understanding%3A_Feedback_Enabled_Cascaded_Classification_Models.html">272 nips-2010-Towards Holistic Scene Understanding: Feedback Enabled Cascaded Classification Models</a></p>
<p>6 0.92052013 <a title="143-lda-6" href="./nips-2010-Learning_To_Count_Objects_in_Images.html">149 nips-2010-Learning To Count Objects in Images</a></p>
<p>7 0.89547038 <a title="143-lda-7" href="./nips-2010-Guaranteed_Rank_Minimization_via_Singular_Value_Projection.html">110 nips-2010-Guaranteed Rank Minimization via Singular Value Projection</a></p>
<p>8 0.87973249 <a title="143-lda-8" href="./nips-2010-PAC-Bayesian_Model_Selection_for_Reinforcement_Learning.html">201 nips-2010-PAC-Bayesian Model Selection for Reinforcement Learning</a></p>
<p>9 0.87770259 <a title="143-lda-9" href="./nips-2010-Layered_image_motion_with_explicit_occlusions%2C_temporal_consistency%2C_and_depth_ordering.html">141 nips-2010-Layered image motion with explicit occlusions, temporal consistency, and depth ordering</a></p>
<p>10 0.84239537 <a title="143-lda-10" href="./nips-2010-Multivariate_Dyadic_Regression_Trees_for_Sparse_Learning_Problems.html">178 nips-2010-Multivariate Dyadic Regression Trees for Sparse Learning Problems</a></p>
<p>11 0.83420736 <a title="143-lda-11" href="./nips-2010-Structural_epitome%3A_a_way_to_summarize_one%E2%80%99s_visual_experience.html">256 nips-2010-Structural epitome: a way to summarize one’s visual experience</a></p>
<p>12 0.83272612 <a title="143-lda-12" href="./nips-2010-Feature_Transitions_with_Saccadic_Search%3A_Size%2C_Color%2C_and_Orientation_Are_Not_Alike.html">95 nips-2010-Feature Transitions with Saccadic Search: Size, Color, and Orientation Are Not Alike</a></p>
<p>13 0.83212447 <a title="143-lda-13" href="./nips-2010-Pose-Sensitive_Embedding_by_Nonlinear_NCA_Regression.html">209 nips-2010-Pose-Sensitive Embedding by Nonlinear NCA Regression</a></p>
<p>14 0.8248086 <a title="143-lda-14" href="./nips-2010-Kernel_Descriptors_for_Visual_Recognition.html">133 nips-2010-Kernel Descriptors for Visual Recognition</a></p>
<p>15 0.81691843 <a title="143-lda-15" href="./nips-2010-Space-Variant_Single-Image_Blind_Deconvolution_for_Removing_Camera_Shake.html">245 nips-2010-Space-Variant Single-Image Blind Deconvolution for Removing Camera Shake</a></p>
<p>16 0.81590652 <a title="143-lda-16" href="./nips-2010-Using_body-anchored_priors_for_identifying_actions_in_single_images.html">281 nips-2010-Using body-anchored priors for identifying actions in single images</a></p>
<p>17 0.80907547 <a title="143-lda-17" href="./nips-2010-Layer-wise_analysis_of_deep_networks_with_Gaussian_kernels.html">140 nips-2010-Layer-wise analysis of deep networks with Gaussian kernels</a></p>
<p>18 0.80812794 <a title="143-lda-18" href="./nips-2010-Size_Matters%3A_Metric_Visual_Search_Constraints_from_Monocular_Metadata.html">241 nips-2010-Size Matters: Metric Visual Search Constraints from Monocular Metadata</a></p>
<p>19 0.80392992 <a title="143-lda-19" href="./nips-2010-Object_Bank%3A_A_High-Level_Image_Representation_for_Scene_Classification_%26_Semantic_Feature_Sparsification.html">186 nips-2010-Object Bank: A High-Level Image Representation for Scene Classification & Semantic Feature Sparsification</a></p>
<p>20 0.80156481 <a title="143-lda-20" href="./nips-2010-Large_Margin_Learning_of_Upstream_Scene_Understanding_Models.html">137 nips-2010-Large Margin Learning of Upstream Scene Understanding Models</a></p>
<br/><br/><br/></body>
</html>
