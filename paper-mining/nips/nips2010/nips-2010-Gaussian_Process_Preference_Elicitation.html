<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>100 nips-2010-Gaussian Process Preference Elicitation</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-100" href="#">nips2010-100</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>100 nips-2010-Gaussian Process Preference Elicitation</h1>
<br/><p>Source: <a title="nips-2010-100-pdf" href="http://papers.nips.cc/paper/4141-gaussian-process-preference-elicitation.pdf">pdf</a></p><p>Author: Shengbo Guo, Scott Sanner, Edwin V. Bonilla</p><p>Abstract: Bayesian approaches to preference elicitation (PE) are particularly attractive due to their ability to explicitly model uncertainty in users’ latent utility functions. However, previous approaches to Bayesian PE have ignored the important problem of generalizing from previous users to an unseen user in order to reduce the elicitation burden on new users. In this paper, we address this deﬁciency by introducing a Gaussian Process (GP) prior over users’ latent utility functions on the joint space of user and item features. We learn the hyper-parameters of this GP on a set of preferences of previous users and use it to aid in the elicitation process for a new user. This approach provides a ﬂexible model of a multi-user utility function, facilitates an efﬁcient value of information (VOI) heuristic query selection strategy, and provides a principled way to incorporate the elicitations of multiple users back into the model. We show the effectiveness of our method in comparison to previous work on a real dataset of user preferences over sushi types. 1</p><p>Reference: <a title="nips-2010-100-reference" href="../nips2010_reference/nips-2010-Gaussian_Process_Preference_Elicitation_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 au  Abstract Bayesian approaches to preference elicitation (PE) are particularly attractive due to their ability to explicitly model uncertainty in users’ latent utility functions. [sent-7, score-1.024]
</p><p>2 However, previous approaches to Bayesian PE have ignored the important problem of generalizing from previous users to an unseen user in order to reduce the elicitation burden on new users. [sent-8, score-1.178]
</p><p>3 In this paper, we address this deﬁciency by introducing a Gaussian Process (GP) prior over users’ latent utility functions on the joint space of user and item features. [sent-9, score-1.0]
</p><p>4 We learn the hyper-parameters of this GP on a set of preferences of previous users and use it to aid in the elicitation process for a new user. [sent-10, score-1.066]
</p><p>5 This approach provides a ﬂexible model of a multi-user utility function, facilitates an efﬁcient value of information (VOI) heuristic query selection strategy, and provides a principled way to incorporate the elicitations of multiple users back into the model. [sent-11, score-0.795]
</p><p>6 We show the effectiveness of our method in comparison to previous work on a real dataset of user preferences over sushi types. [sent-12, score-0.736]
</p><p>7 1  Introduction  Preference elicitation (PE) is an important component of interactive decision support systems that aim to make optimal recommendations to users by actively querying their preferences. [sent-13, score-0.83]
</p><p>8 While previous Bayesian PE approaches have addressed (a), (b) and (c), they appear to ignore an important aspect of (d) concerning generalization from previous users to a new unseen user in order to reduce the elicitation burden on new users. [sent-16, score-1.178]
</p><p>9 Our approach places a (correlated) Gaussian process (GP) prior over the latent utility functions on the joint space of user features (T , mnemonic for tasks) and item features (X ). [sent-18, score-1.141]
</p><p>10 User preferences over items are then seen as drawn from the comparison of these utility function values. [sent-19, score-0.704]
</p><p>11 First, due to the nonparametric Bayesian nature of GPs, we have a ﬂexible model of the user’s utility function that can handle uncertainty and incorporate evidence straightforwardly. [sent-21, score-0.348]
</p><p>12 Second, by having a GP over the joint T × X space, we can integrate prior knowledge on user similarity or item similarity, or simply have more general-purpose covariances whose parameterization can be learned from observed preferences of previous users (i. [sent-22, score-1.31]
</p><p>13 Here the required expected value of information computations can be derived in closed-form to facilitate the selection of informative queries and determine the highest utility item from the available item set as quickly as possible. [sent-26, score-1.005]
</p><p>14 1  In this paper we focus on pairwise comparison queries for PE, which are known to have low cognitive load [3, 4]. [sent-27, score-0.167]
</p><p>15 In particular, we assume a likelihood model of pairwise preferences that factorizes over users and preferences and a GP prior over the latent utility functions correlates users and items. [sent-28, score-1.65]
</p><p>16 2  Problem Formulation  Let x denote a speciﬁc item (or product) that is described by a set of features x and t denote a user (mnemonic for task) that can be characterized with features t. [sent-29, score-0.688]
</p><p>17 , tM } we are given a set of training preference pairs: (j)  (j)  D = (t(j) , xk1 (j)  xk2 )|k = 1, . [sent-36, score-0.234]
</p><p>18 , M ,  (1)  (j)  where xk1 xk2 denotes that we have observed that user j prefers item k1 over item k2 and Kj is the number of preference relations observed for user j. [sent-45, score-1.478]
</p><p>19 The preference elicitation problem is that given a new user, described by a set of features t∗ , we aim to determine (or elicit) what his/her preferences (or favourite items) are by asking a small number def of queries of the form qij = xi xj , meaning that he/she will prefer item i over item j. [sent-46, score-1.706]
</p><p>20 Ideally, we would like to obtain the best user preferences with the smallest number of possible queries. [sent-47, score-0.617]
</p><p>21 The key idea of this paper is that of learning a Gaussian process (GP) model over users’ latent utility functions and use this model in order to drive the elicitation process of a new user. [sent-48, score-0.844]
</p><p>22 Due to the non-parametric Bayesian nature of the GPs, this allows us to have a powerful model of the user’s utility function and to incorporate the evidence (i. [sent-49, score-0.322]
</p><p>23 the responses the user gives to our queries) in a principled manner. [sent-51, score-0.399]
</p><p>24 that users with similar characteristics may have similar preferences; (b) items’ similarities and (c) the value of information of obtaining a response to a query in order to elicit the preferences of the user. [sent-54, score-0.763]
</p><p>25 3  Likelihood Model  Our likelihood model considers that the users’ preference relationships are conditionally independent given the latent utility functions. [sent-55, score-0.607]
</p><p>26 ) Additionally, let f be the utility function values for all training users at all training input locations (i. [sent-64, score-0.599]
</p><p>27 , f (t(M ) , x(N ) )]T and F be the N × M matrix for which the jth column corresponds to the latent values for the jth user at all input points such that f = vec F. [sent-75, score-0.46]
</p><p>28 Hence: f ∼ N (0, Σ)  with  Σ = Kt ⊗ Kx ,  (7)  where Kt is the covariance between all the training users, Kx is the covariance between all the training input locations, and ⊗ denotes the Kronecker product. [sent-76, score-0.086]
</p><p>29 Note that dependencies between users are not arbitrarily imposed but rather they will be learned from the available data by optimizing the marginal likelihood. [sent-77, score-0.405]
</p><p>30 The Laplace method approximates the true posterior with a Gaussian: p(f |D, θ) ≈ N (f |ˆ, A−1 ), f where ˆ = argmaxf p(f |D, θ) = argmaxf p(D|f , θ)p(f |θ) and A is the Hessian of the negative f log-posterior evaluated at ˆ. [sent-82, score-0.108]
</p><p>31 1  (11)  Predictive Distribution  In order to set-up our elicitation framework we will also need the predictive distribution for a ﬁxed test user t∗ at an unseen pair x1 , x2 . [sent-87, score-0.834]
</p><p>32 This is given by: ∗ ∗ p(f∗ |D) =  p(f∗ |f )p(f |D)df  = N (f∗ |µ∗ , C∗ ),  (12) (13)  with: µ∗ = kT Σ−1 ˆ f ∗  and  C∗ = Σ∗ − kT (Σ + W−1 )−1 k∗ , ∗ 3  (14)  where Σ is deﬁned as in equation (7) and: k∗ = kt ⊗ kx ∗ ∗ kt ∗  (15)  = κt (t∗ , t(1) ),  . [sent-88, score-0.222]
</p><p>33 κt (t∗ , t∗ )κx (x2 , x1 ) κt (t∗ , t∗ )κx (x2 , x2 ) ∗ ∗ ∗ ∗  (17) (18)  Gaussian Process Preference Elicitation Framework  Now we have the main components to set up our preference elicitation framework for a test user characterized by features t∗ . [sent-98, score-1.048]
</p><p>34 Our main objective is to use the previously seen data (and the corresponding learned hyper-parameters) in order to drive the elicitation process and to incorporate the information obtained from the user’s responses back into our model in a principled manner. [sent-99, score-0.609]
</p><p>35 Our main requirement is a function that dictates the value of making a query qij . [sent-100, score-0.19]
</p><p>36 In other words, we aim at trading-off the expected actual utility of the items involved in the query and the information these items will provide regarding the user’s preferences. [sent-101, score-0.647]
</p><p>37 We can address this issue by computing the expected value of information (EVOI, [2]) of making a query involving items i and j. [sent-103, score-0.274]
</p><p>38 Let us assume that, at any point during the elicitation process we have an estimate of the utility of the best item and let us denote it by f best . [sent-109, score-1.01]
</p><p>39 2  Expected Value of Information  Now we can deﬁne the expected value of information (EVOI) as the expected gain in improvement that is obtained by adding a query involving a particular pairwise relation. [sent-114, score-0.253]
</p><p>40 As mentioned above, f best can be thought of as an estimate of the utility of the best item as its true utility is unknown. [sent-119, score-0.809]
</p><p>41 In practice we maintain our beliefs over the utilities of the items p(f |D+ ) for the training users and the test user, where D+ denotes the data extended by the set of seen relationships on the test user (which is initially empty). [sent-120, score-0.919]
</p><p>42 Hence, we can set-up f best = maxi F+ i,M +1 , where F+ is the matrix containing the mean estimates of the latent utility function distribution given by the Laplace approximation in equation (9). [sent-121, score-0.368]
</p><p>43 In order to elicit preferences on a new user we simply select a query so that it maximizes the expected value of information EVOI as deﬁned in equation (23). [sent-123, score-0.819]
</p><p>44 We note that although, in principle, one could also update the hyper-parameters based on the data provided by the new user, we avoid this in order to keep computations manageable at query time. [sent-125, score-0.114]
</p><p>45 The reasoning being that, implicitly, we have learned the utility functions over all users and we represent the utility of the test user (explicitly) on demand, updating our beliefs to incorporate the information provided by the user’s responses. [sent-126, score-1.294]
</p><p>46 7  Hyper-parameter Learning  Throughout this paper we have assumed that we have learned a Gaussian process model for the utility functions over users and items based upon previously seen preference relations. [sent-127, score-1.065]
</p><p>47 Fortunately, as in the standard GP regression framework, we can achieve this in a principled way through maximization of the marginal likelihood (or evidence). [sent-130, score-0.171]
</p><p>48 As in the case of the posterior distribution, the marginal likelihood is analytically intractable and approximations are needed. [sent-131, score-0.129]
</p><p>49 The Laplace approximation to the marginal log-likelihood is given by: 1 log p(D|θ) ≈ − log|ΣW + I| − 2  M  1 ˆT −1 ˆ f Σ f+ 2 j=1  Kj  log Φ(ˆk ) zj  (28)  k=1  j where zk = zk |ˆ , ˆ and W are deﬁned as in (10) and Σ is deﬁned as in equation (7). [sent-132, score-0.216]
</p><p>50 Note that ˆj f f computations are not carried out at all the M × N data-points but only at those locations that “support” the seen relations and hence we should write e. [sent-133, score-0.104]
</p><p>51 As we shall see in the following section, for our experiments we do not have much prior information on suitable hyper-parameter settings and therefore we have carried out hyperparameter learning by maximization of the marginal log-likelihood. [sent-138, score-0.161]
</p><p>52 The Sushi dataset contains full rankings given by 5000 Japanese users over N = 10 different types of sushi. [sent-144, score-0.33]
</p><p>53 Each sushi is associated with a set of features which include style, major group, minor group, heaviness, consumption frequency, normalized price and sell frequency. [sent-145, score-0.184]
</p><p>54 The ﬁrst three features are categorical and therefore we have created the corresponding dummy variables to be used by our method. [sent-146, score-0.085]
</p><p>55 Each user is also represented by a set of features wich include gender, age and other features that compile geographical/regional information. [sent-148, score-0.417]
</p><p>56 As with the item features, we have created dummy variables for those categorical features, which resulted into a 85-dimensional feature vector (t) for each user. [sent-149, score-0.323]
</p><p>57 As pointed out in the documentation of the dataset, Japanese food preferences are strongly correlated with geographical and regional information. [sent-150, score-0.266]
</p><p>58 Therefore, modeling user similarities may provide useful information during the elicitation process. [sent-151, score-0.817]
</p><p>59 In particular, we have subsampled 50 training users and selected about 5 training pairwise preferences drawn from each of the N = 10 available items. [sent-154, score-0.637]
</p><p>60 For the GPs we have used the squared exponential (SE) covariance functions with automatic relevance determination (ARD) for both κt and κx and have carried out hyperparameter learning via gradient-based optimization of the marginal likelihood in equation (28). [sent-155, score-0.201]
</p><p>61 In order to measure the quality of our preference elicitation approach we use the normalized loss as a function of the number of queries, where at each iteration the method provides a recommendation based on the available information. [sent-158, score-0.731]
</p><p>62 The normalized loss function is deﬁned as: (ubest − upred )/ubest , where ubest is the best utility for a speciﬁc item/user and upred is the utility achieved by the recommendation provided by the system. [sent-159, score-0.725]
</p><p>63 05  0 0  16  (a)  2  4  6 8 10 NUMBER OF QUERIES  12  14  16  (b)  Figure 1: The Normalized average loss as a function of the number of queries with 2 standard (errors of the mean) error bars. [sent-172, score-0.126]
</p><p>64 (b) The performance of our model when the hyper-parameters have been optimized via maximization of the marginal likelihood (GPPE-OPT) compared to the same GP elicitation framework when these hyper-parameters have been set to their default values (GPPE-PRIOR). [sent-174, score-0.553]
</p><p>65 The RVOI approach is also a VOI-based method but it does not leverage information from other users and it considers diagonal Gaussians as prior models of the latent utility functions. [sent-177, score-0.708]
</p><p>66 The B&L; heuristic selects the current best item and the one with the largest uncertainty. [sent-178, score-0.308]
</p><p>67 Both baselines have been shown to be competitive methods for preference elicitation (see [7] for more details). [sent-179, score-0.664]
</p><p>68 Additionally, we compare our method when the hyper-parameters have been learned on the set of previously seen users with the same GP elicitation approach when the hyper-parameters have been set to the initial values described above. [sent-180, score-0.823]
</p><p>69 This allows us to show that, indeed, when prior information on user and item similarity is not available, our model does learn sensible settings of the hyper-parameters, which lead to better quality elicitation outcomes. [sent-181, score-1.144]
</p><p>70 3  Results  Figure 1(a) shows the normalized average loss across all 5000 users as a function of the number of queries. [sent-183, score-0.362]
</p><p>71 As can be seen, on average, all competing methods reduce the expected loss as the number of queries increases. [sent-184, score-0.163]
</p><p>72 This demonstrates that our approach exploits the inter-relations between users and items effectively in order to enhance the elicitation process on a new user. [sent-186, score-0.954]
</p><p>73 9  Related Work  Preference elicitation (PE) is an important component of recommender systems and market research. [sent-190, score-0.43]
</p><p>74 We can categorize different PE frameworks in terms of query types. [sent-192, score-0.107]
</p><p>75 In [8], the authors propose to model 7  utilities as random variables, and reﬁnes utility uncertainty by using standard gamble queries. [sent-193, score-0.38]
</p><p>76 However, standard gamble queries are difﬁcult for users to respond to, and naturally lead to noisy responses. [sent-195, score-0.496]
</p><p>77 Our work also adopts simple pairwise comparison queries, but it differs from [7] in that it makes use of users’ preferences that have been seen before and does not assume additive independent utilities. [sent-198, score-0.347]
</p><p>78 In the machine learning community preference learning has received substantial interest over the past few years. [sent-199, score-0.234]
</p><p>79 For example, one the most recent approaches to preference learning is presented in [10], where a multi-task learning approach to the problem of modeling human preferences is adopted by extending the model in [11] to deal with preference data. [sent-200, score-0.734]
</p><p>80 Their model is different to ours in that they consider the dual representation of the GPs as they do not generalize over user features. [sent-202, score-0.351]
</p><p>81 Furthermore, they do not address the elicitation problem, which is the main concern of this paper. [sent-203, score-0.43]
</p><p>82 Extensions of the Gaussian process formalism to model ordinal data and user preferences are given in [12] and [13]. [sent-204, score-0.685]
</p><p>83 Both their prior and their likelihood models can be seen as single-user (task) speciﬁcations of our model. [sent-205, score-0.123]
</p><p>84 More importantly, an elicitation framework for actively querying the user is not presented in such works. [sent-207, score-0.828]
</p><p>85 [14] proposes an active preference learning method for discrete choice data. [sent-208, score-0.234]
</p><p>86 Unlike our approach they do not leverage information from seen preferences on previous users and hence their active preference learning process on a new user starts from scratch. [sent-210, score-1.261]
</p><p>87 This leads to the problem of either relying on good prior information on the covariance function or on hyper-parameter updating during the active learning process, which is computationally too expensive to be used in practice. [sent-211, score-0.087]
</p><p>88 10  Conclusions & Future Work  In this paper we have presented a Gaussian process approach to the problem of preference elicitation. [sent-213, score-0.274]
</p><p>89 One of the crucial characteristics of our method is that it exploits user-similarity via a (correlated) Gaussian process prior over the users’ latent utility functions. [sent-214, score-0.443]
</p><p>90 These similarities are “learned” from preferences on previous users. [sent-215, score-0.302]
</p><p>91 Our method maintains a ﬂexible representation of the user’s latent utility function, handles uncertainty in a principled manner and allows the incorporation of prior knowledge from different sources. [sent-216, score-0.482]
</p><p>92 The required expected value of information computations can be derived in closed-form to facilitate the selection of informative queries and determine the highest utility item from the available item set as quickly as possible. [sent-217, score-1.005]
</p><p>93 We have shown the beneﬁts of our method on a real dataset of 5000 users with preferences over 10 sushi types. [sent-218, score-0.715]
</p><p>94 In future work we aim at investigating other elicitation problems such as those involving a Likert scale [15] where our approach may be effective. [sent-219, score-0.455]
</p><p>95 The main practical constraint is that in order to carry out the evaluation (but not the application) of our method on real data we require the full set of preferences of the users over a set of items. [sent-220, score-0.596]
</p><p>96 However, [10] has shown that this method is a good approximation to the posterior in the context of the preference learning problem. [sent-222, score-0.272]
</p><p>97 We intend to investigate other approximation methods to the posterior and marginal likelihood and their joint application with sparse approximation methods within our framework (see e. [sent-223, score-0.129]
</p><p>98 [16]), which will be required if the number of training users is large. [sent-225, score-0.33]
</p><p>99 Real-time multiattribute Bayesian preference elicitation with pairwise comparison queries. [sent-261, score-0.705]
</p><p>100 Multi-task preference learning with an application to hearing aid personalization. [sent-273, score-0.234]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('elicitation', 0.43), ('user', 0.351), ('users', 0.33), ('item', 0.271), ('utility', 0.269), ('preferences', 0.266), ('preference', 0.234), ('pe', 0.169), ('items', 0.129), ('queries', 0.126), ('evoi', 0.121), ('gp', 0.121), ('sushi', 0.119), ('gppe', 0.099), ('rvoi', 0.099), ('mei', 0.096), ('query', 0.083), ('gps', 0.078), ('qij', 0.075), ('kj', 0.073), ('kt', 0.068), ('zk', 0.065), ('latent', 0.065), ('marginal', 0.052), ('kx', 0.052), ('laplace', 0.048), ('elicit', 0.048), ('principled', 0.048), ('utilities', 0.045), ('df', 0.044), ('prior', 0.044), ('covariance', 0.043), ('pairwise', 0.041), ('process', 0.04), ('ei', 0.04), ('seen', 0.04), ('edwin', 0.04), ('gamble', 0.04), ('itrue', 0.04), ('ubest', 0.04), ('upred', 0.04), ('urszula', 0.04), ('likelihood', 0.039), ('gaussian', 0.039), ('posterior', 0.038), ('burden', 0.038), ('expected', 0.037), ('heuristic', 0.037), ('similarities', 0.036), ('recommendation', 0.035), ('argmaxf', 0.035), ('chajewska', 0.035), ('mnemonic', 0.035), ('shengbo', 0.035), ('equation', 0.034), ('features', 0.033), ('carried', 0.033), ('maximization', 0.032), ('normalized', 0.032), ('eliciting', 0.032), ('bonilla', 0.032), ('dictates', 0.032), ('computations', 0.031), ('improvement', 0.03), ('dummy', 0.03), ('incorporation', 0.03), ('recommending', 0.03), ('unseen', 0.029), ('ordinal', 0.028), ('japanese', 0.028), ('nicta', 0.028), ('bayesian', 0.028), ('incorporate', 0.028), ('chu', 0.027), ('uncertainty', 0.026), ('exible', 0.026), ('similarity', 0.025), ('pomdp', 0.025), ('tm', 0.025), ('guo', 0.025), ('querying', 0.025), ('exploits', 0.025), ('involving', 0.025), ('evidence', 0.025), ('beliefs', 0.024), ('frameworks', 0.024), ('cdf', 0.024), ('predictive', 0.024), ('learned', 0.023), ('sensible', 0.023), ('recommendations', 0.023), ('actively', 0.022), ('jth', 0.022), ('wei', 0.022), ('categorical', 0.022), ('australian', 0.022), ('koller', 0.022), ('daphne', 0.022), ('zoubin', 0.022), ('scott', 0.022)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="100-tfidf-1" href="./nips-2010-Gaussian_Process_Preference_Elicitation.html">100 nips-2010-Gaussian Process Preference Elicitation</a></p>
<p>Author: Shengbo Guo, Scott Sanner, Edwin V. Bonilla</p><p>Abstract: Bayesian approaches to preference elicitation (PE) are particularly attractive due to their ability to explicitly model uncertainty in users’ latent utility functions. However, previous approaches to Bayesian PE have ignored the important problem of generalizing from previous users to an unseen user in order to reduce the elicitation burden on new users. In this paper, we address this deﬁciency by introducing a Gaussian Process (GP) prior over users’ latent utility functions on the joint space of user and item features. We learn the hyper-parameters of this GP on a set of preferences of previous users and use it to aid in the elicitation process for a new user. This approach provides a ﬂexible model of a multi-user utility function, facilitates an efﬁcient value of information (VOI) heuristic query selection strategy, and provides a principled way to incorporate the elicitations of multiple users back into the model. We show the effectiveness of our method in comparison to previous work on a real dataset of user preferences over sushi types. 1</p><p>2 0.22629565 <a title="100-tfidf-2" href="./nips-2010-Optimal_Bayesian_Recommendation_Sets_and_Myopically_Optimal_Choice_Query_Sets.html">197 nips-2010-Optimal Bayesian Recommendation Sets and Myopically Optimal Choice Query Sets</a></p>
<p>Author: Paolo Viappiani, Craig Boutilier</p><p>Abstract: Bayesian approaches to utility elicitation typically adopt (myopic) expected value of information (EVOI) as a natural criterion for selecting queries. However, EVOI-optimization is usually computationally prohibitive. In this paper, we examine EVOI optimization using choice queries, queries in which a user is ask to select her most preferred product from a set. We show that, under very general assumptions, the optimal choice query w.r.t. EVOI coincides with the optimal recommendation set, that is, a set maximizing the expected utility of the user selection. Since recommendation set optimization is a simpler, submodular problem, this can greatly reduce the complexity of both exact and approximate (greedy) computation of optimal choice queries. We also examine the case where user responses to choice queries are error-prone (using both constant and mixed multinomial logit noise models) and provide worst-case guarantees. Finally we present a local search technique for query optimization that works extremely well with large outcome spaces.</p><p>3 0.13663979 <a title="100-tfidf-3" href="./nips-2010-The_Neural_Costs_of_Optimal_Control.html">268 nips-2010-The Neural Costs of Optimal Control</a></p>
<p>Author: Samuel Gershman, Robert Wilson</p><p>Abstract: Optimal control entails combining probabilities and utilities. However, for most practical problems, probability densities can be represented only approximately. Choosing an approximation requires balancing the beneﬁts of an accurate approximation against the costs of computing it. We propose a variational framework for achieving this balance and apply it to the problem of how a neural population code should optimally represent a distribution under resource constraints. The essence of our analysis is the conjecture that population codes are organized to maximize a lower bound on the log expected utility. This theory can account for a plethora of experimental data, including the reward-modulation of sensory receptive ﬁelds, GABAergic effects on saccadic movements, and risk aversion in decisions under uncertainty. 1</p><p>4 0.086271837 <a title="100-tfidf-4" href="./nips-2010-Bayesian_Action-Graph_Games.html">39 nips-2010-Bayesian Action-Graph Games</a></p>
<p>Author: Albert X. Jiang, Kevin Leyton-brown</p><p>Abstract: Games of incomplete information, or Bayesian games, are an important gametheoretic model and have many applications in economics. We propose Bayesian action-graph games (BAGGs), a novel graphical representation for Bayesian games. BAGGs can represent arbitrary Bayesian games, and furthermore can compactly express Bayesian games exhibiting commonly encountered types of structure including symmetry, action- and type-speciﬁc utility independence, and probabilistic independence of type distributions. We provide an algorithm for computing expected utility in BAGGs, and discuss conditions under which the algorithm runs in polynomial time. Bayes-Nash equilibria of BAGGs can be computed by adapting existing algorithms for complete-information normal form games and leveraging our expected utility algorithm. We show both theoretically and empirically that our approaches improve signiﬁcantly on the state of the art. 1</p><p>5 0.079532824 <a title="100-tfidf-5" href="./nips-2010-Slice_sampling_covariance_hyperparameters_of_latent_Gaussian_models.html">242 nips-2010-Slice sampling covariance hyperparameters of latent Gaussian models</a></p>
<p>Author: Iain Murray, Ryan P. Adams</p><p>Abstract: The Gaussian process (GP) is a popular way to specify dependencies between random variables in a probabilistic model. In the Bayesian framework the covariance structure can be speciﬁed using unknown hyperparameters. Integrating over these hyperparameters considers diﬀerent possible explanations for the data when making predictions. This integration is often performed using Markov chain Monte Carlo (MCMC) sampling. However, with non-Gaussian observations standard hyperparameter sampling approaches require careful tuning and may converge slowly. In this paper we present a slice sampling approach that requires little tuning while mixing well in both strong- and weak-data regimes. 1</p><p>6 0.077542946 <a title="100-tfidf-6" href="./nips-2010-Two-Layer_Generalization_Analysis_for_Ranking_Using_Rademacher_Average.html">277 nips-2010-Two-Layer Generalization Analysis for Ranking Using Rademacher Average</a></p>
<p>7 0.077190503 <a title="100-tfidf-7" href="./nips-2010-Probabilistic_latent_variable_models_for_distinguishing_between_cause_and_effect.html">218 nips-2010-Probabilistic latent variable models for distinguishing between cause and effect</a></p>
<p>8 0.069832556 <a title="100-tfidf-8" href="./nips-2010-Approximate_inference_in_continuous_time_Gaussian-Jump_processes.html">33 nips-2010-Approximate inference in continuous time Gaussian-Jump processes</a></p>
<p>9 0.063059703 <a title="100-tfidf-9" href="./nips-2010-Transduction_with_Matrix_Completion%3A_Three_Birds_with_One_Stone.html">275 nips-2010-Transduction with Matrix Completion: Three Birds with One Stone</a></p>
<p>10 0.062219899 <a title="100-tfidf-10" href="./nips-2010-Scrambled_Objects_for_Least-Squares_Regression.html">233 nips-2010-Scrambled Objects for Least-Squares Regression</a></p>
<p>11 0.06191396 <a title="100-tfidf-11" href="./nips-2010-Learning_the_context_of_a_category.html">155 nips-2010-Learning the context of a category</a></p>
<p>12 0.059830513 <a title="100-tfidf-12" href="./nips-2010-Collaborative_Filtering_in_a_Non-Uniform_World%3A_Learning_with_the_Weighted_Trace_Norm.html">48 nips-2010-Collaborative Filtering in a Non-Uniform World: Learning with the Weighted Trace Norm</a></p>
<p>13 0.056857478 <a title="100-tfidf-13" href="./nips-2010-Extensions_of_Generalized_Binary_Search_to_Group_Identification_and_Exponential_Costs.html">88 nips-2010-Extensions of Generalized Binary Search to Group Identification and Exponential Costs</a></p>
<p>14 0.056480605 <a title="100-tfidf-14" href="./nips-2010-Link_Discovery_using_Graph_Feature_Tracking.html">162 nips-2010-Link Discovery using Graph Feature Tracking</a></p>
<p>15 0.051225584 <a title="100-tfidf-15" href="./nips-2010-Factorized_Latent_Spaces_with_Structured_Sparsity.html">89 nips-2010-Factorized Latent Spaces with Structured Sparsity</a></p>
<p>16 0.051225018 <a title="100-tfidf-16" href="./nips-2010-Heavy-Tailed_Process_Priors_for_Selective_Shrinkage.html">113 nips-2010-Heavy-Tailed Process Priors for Selective Shrinkage</a></p>
<p>17 0.051054038 <a title="100-tfidf-17" href="./nips-2010-Exact_learning_curves_for_Gaussian_process_regression_on_large_random_graphs.html">85 nips-2010-Exact learning curves for Gaussian process regression on large random graphs</a></p>
<p>18 0.050179649 <a title="100-tfidf-18" href="./nips-2010-Optimal_Web-Scale_Tiering_as_a_Flow_Problem.html">198 nips-2010-Optimal Web-Scale Tiering as a Flow Problem</a></p>
<p>19 0.049724728 <a title="100-tfidf-19" href="./nips-2010-Batch_Bayesian_Optimization_via_Simulation_Matching.html">38 nips-2010-Batch Bayesian Optimization via Simulation Matching</a></p>
<p>20 0.048273735 <a title="100-tfidf-20" href="./nips-2010-Gaussian_sampling_by_local_perturbations.html">101 nips-2010-Gaussian sampling by local perturbations</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.139), (1, 0.015), (2, 0.001), (3, 0.02), (4, -0.07), (5, 0.045), (6, 0.007), (7, 0.004), (8, -0.019), (9, -0.075), (10, -0.025), (11, -0.004), (12, -0.0), (13, -0.119), (14, 0.026), (15, 0.018), (16, -0.056), (17, 0.063), (18, 0.024), (19, 0.136), (20, -0.04), (21, 0.086), (22, -0.026), (23, -0.173), (24, 0.021), (25, -0.082), (26, -0.03), (27, -0.01), (28, -0.069), (29, 0.221), (30, 0.117), (31, -0.046), (32, 0.151), (33, -0.025), (34, 0.113), (35, 0.052), (36, 0.018), (37, 0.048), (38, 0.057), (39, -0.154), (40, -0.066), (41, 0.143), (42, -0.176), (43, -0.04), (44, 0.215), (45, 0.158), (46, 0.034), (47, -0.016), (48, 0.016), (49, 0.142)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95277792 <a title="100-lsi-1" href="./nips-2010-Gaussian_Process_Preference_Elicitation.html">100 nips-2010-Gaussian Process Preference Elicitation</a></p>
<p>Author: Shengbo Guo, Scott Sanner, Edwin V. Bonilla</p><p>Abstract: Bayesian approaches to preference elicitation (PE) are particularly attractive due to their ability to explicitly model uncertainty in users’ latent utility functions. However, previous approaches to Bayesian PE have ignored the important problem of generalizing from previous users to an unseen user in order to reduce the elicitation burden on new users. In this paper, we address this deﬁciency by introducing a Gaussian Process (GP) prior over users’ latent utility functions on the joint space of user and item features. We learn the hyper-parameters of this GP on a set of preferences of previous users and use it to aid in the elicitation process for a new user. This approach provides a ﬂexible model of a multi-user utility function, facilitates an efﬁcient value of information (VOI) heuristic query selection strategy, and provides a principled way to incorporate the elicitations of multiple users back into the model. We show the effectiveness of our method in comparison to previous work on a real dataset of user preferences over sushi types. 1</p><p>2 0.91124624 <a title="100-lsi-2" href="./nips-2010-Optimal_Bayesian_Recommendation_Sets_and_Myopically_Optimal_Choice_Query_Sets.html">197 nips-2010-Optimal Bayesian Recommendation Sets and Myopically Optimal Choice Query Sets</a></p>
<p>Author: Paolo Viappiani, Craig Boutilier</p><p>Abstract: Bayesian approaches to utility elicitation typically adopt (myopic) expected value of information (EVOI) as a natural criterion for selecting queries. However, EVOI-optimization is usually computationally prohibitive. In this paper, we examine EVOI optimization using choice queries, queries in which a user is ask to select her most preferred product from a set. We show that, under very general assumptions, the optimal choice query w.r.t. EVOI coincides with the optimal recommendation set, that is, a set maximizing the expected utility of the user selection. Since recommendation set optimization is a simpler, submodular problem, this can greatly reduce the complexity of both exact and approximate (greedy) computation of optimal choice queries. We also examine the case where user responses to choice queries are error-prone (using both constant and mixed multinomial logit noise models) and provide worst-case guarantees. Finally we present a local search technique for query optimization that works extremely well with large outcome spaces.</p><p>3 0.44254211 <a title="100-lsi-3" href="./nips-2010-Slice_sampling_covariance_hyperparameters_of_latent_Gaussian_models.html">242 nips-2010-Slice sampling covariance hyperparameters of latent Gaussian models</a></p>
<p>Author: Iain Murray, Ryan P. Adams</p><p>Abstract: The Gaussian process (GP) is a popular way to specify dependencies between random variables in a probabilistic model. In the Bayesian framework the covariance structure can be speciﬁed using unknown hyperparameters. Integrating over these hyperparameters considers diﬀerent possible explanations for the data when making predictions. This integration is often performed using Markov chain Monte Carlo (MCMC) sampling. However, with non-Gaussian observations standard hyperparameter sampling approaches require careful tuning and may converge slowly. In this paper we present a slice sampling approach that requires little tuning while mixing well in both strong- and weak-data regimes. 1</p><p>4 0.43588781 <a title="100-lsi-4" href="./nips-2010-The_Neural_Costs_of_Optimal_Control.html">268 nips-2010-The Neural Costs of Optimal Control</a></p>
<p>Author: Samuel Gershman, Robert Wilson</p><p>Abstract: Optimal control entails combining probabilities and utilities. However, for most practical problems, probability densities can be represented only approximately. Choosing an approximation requires balancing the beneﬁts of an accurate approximation against the costs of computing it. We propose a variational framework for achieving this balance and apply it to the problem of how a neural population code should optimally represent a distribution under resource constraints. The essence of our analysis is the conjecture that population codes are organized to maximize a lower bound on the log expected utility. This theory can account for a plethora of experimental data, including the reward-modulation of sensory receptive ﬁelds, GABAergic effects on saccadic movements, and risk aversion in decisions under uncertainty. 1</p><p>5 0.41284633 <a title="100-lsi-5" href="./nips-2010-Optimal_Web-Scale_Tiering_as_a_Flow_Problem.html">198 nips-2010-Optimal Web-Scale Tiering as a Flow Problem</a></p>
<p>Author: Gilbert Leung, Novi Quadrianto, Kostas Tsioutsiouliklis, Alex J. Smola</p><p>Abstract: We present a fast online solver for large scale parametric max-ﬂow problems as they occur in portfolio optimization, inventory management, computer vision, and logistics. Our algorithm solves an integer linear program in an online fashion. It exploits total unimodularity of the constraint matrix and a Lagrangian relaxation to solve the problem as a convex online game. The algorithm generates approximate solutions of max-ﬂow problems by performing stochastic gradient descent on a set of ﬂows. We apply the algorithm to optimize tier arrangement of over 84 million web pages on a layered set of caches to serve an incoming query stream optimally. 1</p><p>6 0.38540906 <a title="100-lsi-6" href="./nips-2010-Evaluation_of_Rarity_of_Fingerprints_in_Forensics.html">82 nips-2010-Evaluation of Rarity of Fingerprints in Forensics</a></p>
<p>7 0.38466701 <a title="100-lsi-7" href="./nips-2010-Two-Layer_Generalization_Analysis_for_Ranking_Using_Rademacher_Average.html">277 nips-2010-Two-Layer Generalization Analysis for Ranking Using Rademacher Average</a></p>
<p>8 0.35398659 <a title="100-lsi-8" href="./nips-2010-Scrambled_Objects_for_Least-Squares_Regression.html">233 nips-2010-Scrambled Objects for Least-Squares Regression</a></p>
<p>9 0.3532427 <a title="100-lsi-9" href="./nips-2010-Heavy-Tailed_Process_Priors_for_Selective_Shrinkage.html">113 nips-2010-Heavy-Tailed Process Priors for Selective Shrinkage</a></p>
<p>10 0.34426627 <a title="100-lsi-10" href="./nips-2010-Bayesian_Action-Graph_Games.html">39 nips-2010-Bayesian Action-Graph Games</a></p>
<p>11 0.33056694 <a title="100-lsi-11" href="./nips-2010-Exact_learning_curves_for_Gaussian_process_regression_on_large_random_graphs.html">85 nips-2010-Exact learning curves for Gaussian process regression on large random graphs</a></p>
<p>12 0.3285144 <a title="100-lsi-12" href="./nips-2010-Approximate_inference_in_continuous_time_Gaussian-Jump_processes.html">33 nips-2010-Approximate inference in continuous time Gaussian-Jump processes</a></p>
<p>13 0.28985769 <a title="100-lsi-13" href="./nips-2010-Switched_Latent_Force_Models_for_Movement_Segmentation.html">262 nips-2010-Switched Latent Force Models for Movement Segmentation</a></p>
<p>14 0.28835979 <a title="100-lsi-14" href="./nips-2010-Learning_the_context_of_a_category.html">155 nips-2010-Learning the context of a category</a></p>
<p>15 0.28750604 <a title="100-lsi-15" href="./nips-2010-Learning_sparse_dynamic_linear_systems_using_stable_spline_kernels_and_exponential_hyperpriors.html">154 nips-2010-Learning sparse dynamic linear systems using stable spline kernels and exponential hyperpriors</a></p>
<p>16 0.28547636 <a title="100-lsi-16" href="./nips-2010-Computing_Marginal_Distributions_over_Continuous_Markov_Networks_for_Statistical_Relational_Learning.html">49 nips-2010-Computing Marginal Distributions over Continuous Markov Networks for Statistical Relational Learning</a></p>
<p>17 0.27959171 <a title="100-lsi-17" href="./nips-2010-Gaussian_sampling_by_local_perturbations.html">101 nips-2010-Gaussian sampling by local perturbations</a></p>
<p>18 0.27597466 <a title="100-lsi-18" href="./nips-2010-Humans_Learn_Using_Manifolds%2C_Reluctantly.html">114 nips-2010-Humans Learn Using Manifolds, Reluctantly</a></p>
<p>19 0.26876411 <a title="100-lsi-19" href="./nips-2010-Probabilistic_Deterministic_Infinite_Automata.html">215 nips-2010-Probabilistic Deterministic Infinite Automata</a></p>
<p>20 0.26065251 <a title="100-lsi-20" href="./nips-2010-Improvements_to_the_Sequence_Memoizer.html">120 nips-2010-Improvements to the Sequence Memoizer</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.024), (17, 0.019), (27, 0.038), (30, 0.026), (45, 0.681), (50, 0.06), (52, 0.011), (60, 0.015), (77, 0.018), (90, 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99850184 <a title="100-lda-1" href="./nips-2010-Gaussian_Process_Preference_Elicitation.html">100 nips-2010-Gaussian Process Preference Elicitation</a></p>
<p>Author: Shengbo Guo, Scott Sanner, Edwin V. Bonilla</p><p>Abstract: Bayesian approaches to preference elicitation (PE) are particularly attractive due to their ability to explicitly model uncertainty in users’ latent utility functions. However, previous approaches to Bayesian PE have ignored the important problem of generalizing from previous users to an unseen user in order to reduce the elicitation burden on new users. In this paper, we address this deﬁciency by introducing a Gaussian Process (GP) prior over users’ latent utility functions on the joint space of user and item features. We learn the hyper-parameters of this GP on a set of preferences of previous users and use it to aid in the elicitation process for a new user. This approach provides a ﬂexible model of a multi-user utility function, facilitates an efﬁcient value of information (VOI) heuristic query selection strategy, and provides a principled way to incorporate the elicitations of multiple users back into the model. We show the effectiveness of our method in comparison to previous work on a real dataset of user preferences over sushi types. 1</p><p>2 0.99799263 <a title="100-lda-2" href="./nips-2010-Approximate_Inference_by_Compilation_to_Arithmetic_Circuits.html">32 nips-2010-Approximate Inference by Compilation to Arithmetic Circuits</a></p>
<p>Author: Daniel Lowd, Pedro Domingos</p><p>Abstract: Arithmetic circuits (ACs) exploit context-speciﬁc independence and determinism to allow exact inference even in networks with high treewidth. In this paper, we introduce the ﬁrst ever approximate inference methods using ACs, for domains where exact inference remains intractable. We propose and evaluate a variety of techniques based on exact compilation, forward sampling, AC structure learning, Markov network parameter learning, variational inference, and Gibbs sampling. In experiments on eight challenging real-world domains, we ﬁnd that the methods based on sampling and learning work best: one such method (AC2 -F) is faster and usually more accurate than loopy belief propagation, mean ﬁeld, and Gibbs sampling; another (AC2 -G) has a running time similar to Gibbs sampling but is consistently more accurate than all baselines. 1</p><p>3 0.99798745 <a title="100-lda-3" href="./nips-2010-Mixture_of_time-warped_trajectory_models_for_movement_decoding.html">167 nips-2010-Mixture of time-warped trajectory models for movement decoding</a></p>
<p>Author: Elaine Corbett, Eric Perreault, Konrad Koerding</p><p>Abstract: Applications of Brain-Machine-Interfaces typically estimate user intent based on biological signals that are under voluntary control. For example, we might want to estimate how a patient with a paralyzed arm wants to move based on residual muscle activity. To solve such problems it is necessary to integrate obtained information over time. To do so, state of the art approaches typically use a probabilistic model of how the state, e.g. position and velocity of the arm, evolves over time – a so-called trajectory model. We wanted to further develop this approach using two intuitive insights: (1) At any given point of time there may be a small set of likely movement targets, potentially identified by the location of objects in the workspace or by gaze information from the user. (2) The user may want to produce movements at varying speeds. We thus use a generative model with a trajectory model incorporating these insights. Approximate inference on that generative model is implemented using a mixture of extended Kalman filters. We find that the resulting algorithm allows us to decode arm movements dramatically better than when we use a trajectory model with linear dynamics. 1 In trod u cti on When patients have lost a limb or the ability to communicate with the outside world, brain machine interfaces (BMIs) are often used to enable robotic prostheses or restore communication. To achieve this, the user's intended state of the device must be decoded from biological signals. In the context of Bayesian statistics, two aspects are important for the design of an estimator of a temporally evolving state: the observation model, which describes how measured variables relate to the system’s state and the trajectory model which describes how the state changes over time in a probabilistic manner. Following this logic many recent BMI applications have relied on Bayesian estimation for a wide range of problems including the decoding of intended human [1] and animal [2] movements. In the context of BMIs, Bayesian approaches offer a principled way of formalizing the uncertainty about signals and thus often result in improvements over other signal processing techniques [1]-[3]. Most work on state estimation in dynamical systems has assumed linear dynamics and Gaussian noise. Under these circumstances, efficient algorithms result from belief propagation. The most frequent application uses the Kalman filter (KF), which recursively combines noisy state observations with the probabilistic evolution of state defined by the trajectory model to estimate the marginal distribution over states [4]. Such approaches have been used widely for applications including upper [1] and lower [5] extremity prosthetic 1 devices, functional electric stimulation [6] and human computer interactions [7]. As these algorithms are so commonly used, it seems promising to develop extensions to nonlinear trajectory models that may better describe the probabilistic distribution of movements in everyday life. One salient departure from the standard assumptions is that people tend to produce both slow and fast movements, depending on the situation. Models with linear dynamics only allow such deviation through the noise term, which makes these models poor at describing the natural variation of movement speeds during real world tasks. Explicitly incorporating movement speed into the trajectory model should lead to better movement estimates. Knowledge of the target position should also strongly affect trajectory models. After all , we tend to accelerate our arm early during movement and slow down later on. Target information can be linearly incorporated into the trajectory model, and this has greatly improved predictions [8]-[12]. Alternatively, if there are a small number of potential targets then a mixture of trajectory models approach [13] can be used. Here we are interested in the case where available data provide a prior over potential t argets but where movement targets may be anywhere. We want to incorporate target uncertainty and allow generalization to novel targets. Prior information about potential targets could come from a number of sources but would generally be noisy. For example, activity in the dorsal premotor cortex provides information about intended target location prior to movement and may be used where such recordings are available [14]. Target information may also be found noninvasively by tracking eye movements. However, such data will generally provide non-zero priors for a number of possible target locations as the subject saccades over the scene. While subjects almost always look at a target before reaching for it [15], there may be a delay of up to a second between looking at the target and the reach – a time interval over which up to 3 saccades are typically made. Each of these fixations could be the target. Hence, a probabilistic distribution of targets is appropriate when using either neural recordings or eye tracking to estimate potential reach targets Here we present an algorithm that uses a mixture of extended Kalman Filters (EKFs) to combine our insights related to the variation of movement speed and the availability of probabilistic target knowledge. Each of the mixture component s allows the speed of the movement to vary continuously over time. We tested how well we could use EMGs and eye movements to decode hand position of humans performing a three -dimensional large workspace reaching task. We find that using a trajectory model that allows for probabilistic target information and variation of speed leads to dramatic improvements in decoding quality. 2 Gen e ral Decod i n g S etti n g We wanted to test how well different decoding algorithms can decode human movement, over a wide range of dynamics. While many recent studies have looked at more restrictive, two-dimensional movements, a system to restore arm function should produce a wide range of 3D trajectories. We recorded arm kinematics and EMGs of healthy subjects during unconstrained 3D reaches to targets over a large workspace. Two healthy subjects were asked to reach at slow, normal and fast speeds, as they would in everyday life. Subjects were seated as they reached towards 16 LEDs in blocks of 150s, which were located on two planes positioned such that all targets were just reachable (Fig 1A). The target LED was lit for one second prior to an auditory go cue, at which time the subject would reach to the target at the appropriate speed. Slow, normal and fast reaches were allotted 3 s, 1.5s and 1s respectively; however, subjects determined the speed. An approximate total of 450 reaches were performed per subject. The subjects provided informed consent, and the protocol was approved by the Northwestern University Institutional Review Board. EMG signals were measured from the pectoralis major, and the three deltoid muscles of the shoulder. This represents a small subset of the muscles involved in reaching, and approximates those muscles retaining some voluntary control following mid-level cervical spinal cord injuries. 2 The EMG signals were band-pass filtered between 10 and 1,000 Hz, and subsequently anti aliased filtered. Hand, wrist, shoulder and head positions were tracked using an Optotrak motion analysis system. We simultaneously recorded eye movements with an ASL EYETRAC-6 head mounted eye tracker. Approximately 25% of the reaches were assigned to the test set, and the rest were used for training. Reaches for which either the motion capture data was incomplete, or there was visible motion artifact on the EMG were removed. As the state we used hand positions and joint angles (3 shoulder, 2 elbow, position, velocity and acceleration, 24 dimensions). Joint angles were calculated from the shoulder and wrist marker data using digitized bony landmarks which defined a coordinate system for the upper limb as detailed by Wu et al. [16]. As the motion data were sampled at 60Hz, the mean absolute value o f the EMG in the corresponding 16.7ms windows was used as an observation of the state at each time-step. Algorithm accuracy was quantified by normalizing the root -mean-squared error by the straight line distance between the first and final position of the endpoint for each reach. We compared the algorithms statistically using repeated measures ANOVAs with Tukey post -hoc tests, treating reach and subject as random effects. In the rest of the paper we will ask how well these reaching movements can be decoded from EMG and eye-tracking data. Figure 1: A Experimental setup and B sample kinematics and processed EMGs for one reach 3 Kal man Fi l ters w i th Target i n f ormati on All models that we consider in this paper assume linear observations with Gaussian noise: (1) where x is the state, y is the observation and v is the measurement noise with p(v) ~ N(0,R), and R is the observation covariance matrix. The model fitted the measured EMGs with an average r2 of 0.55. This highlights the need to integrate information over time. The standard approach also assumes linear dynamics and Gaussian process noise: (2) where, x t represents the hand and joint angle positions, w is the process noise with p(w) ~ N(0,Q), and Q is the state covariance matrix. The Kalman filter does optimal inference for this generative model. This model can effectively capture the dynamics of stereotypical reaches to a single target by appropriately tuning its parameters. However, when used to describe reaches to multiple targets, the model cannot describe target dependent aspects of reaching but boils down to a random drift model. Fast velocities are underestimated as they are unlikely under the trajectory model and there is excessive drift close to the target (Fig. 2A). 3 In many decoding applications we may know the subject’s target. A range of recent studies have addressed the issue of incorporating this information into the trajectory model [8, 13], and we might assume the effect of the target on the dynamics to be linear. This naturally suggests adding the target to the state space, which works well in practice [9, 12]. By appending the target to the state vector (KFT), the simple linear format of the KF may be retained: (3) where xTt is the vector of target positions, with dimensionality less than or equal to that of xt. This trajectory model thus allows describing both the rapid acceleration that characterizes the beginning of a reach and the stabilization towards its end. We compared the accuracy of the KF and the KFT to the Single Target Model (STM), a KF trained only on reaches to the target being tested (Fig. 2). The STM represents the best possible prediction that could be obtained with a Kalman filter. Assuming the target is perfectly known, we implemented the KFT by correctly initializing the target state xT at the beginning of the reach. We will relax this assumption below. The initial hand and joint angle positions were also assumed to be known. Figure 2: A Sample reach and predictions and B average accuracies with standard errors for KFT, KF and MTM. Consistent with the recent literature, both methods that incorporated target information produced higher prediction accuracy than the standard KF (both p<0.0001). Interestingly, there was no significant difference between the KFT and the STM (p=0.9). It seems that when we have knowledge of the target, we do not lose much by training a single model over the whole workspace rather than modeling the targets individually. This is encouraging, as we desire a BMI system that can generalize to any target within the workspace, not just specifically to those that are available in the training data. Clearly, adding the target to the state space allows the dynamics of typical movements to be modeled effectively, resulting in dramatic increases in decoding performance. 4 Ti me Warp i n g 4.1 I m p l e m e n t i n g a t i m e - w a r p e d t r a j e c t o r y mo d e l While the KFT above can capture the general reach trajectory profile, it does not allow for natural variability in the speed of movements. Depending on our task objectives, which would not directly be observed by a BMI, we might lazily reach toward a target or move a t maximal speed. We aim to change the trajectory model to explicitly incorporate a warping factor by which the average movement speed is scaled, allowing for such variability. As the movement speed will be positive in all practical cases, we model the logarithm of this factor, 4 and append it to the state vector: (4) We create a time-warped trajectory model by noting that if the average rate of a trajectory is to be scaled by a factor S, the position at time t will equal that of the original trajectory at time St. Differentiating, the velocity will be multiplied by S, and the acceleration by S 2. For simplicity, the trajectory noise is assumed to be additive and Gaussian, and the model is assumed to be stationary: (5) where Ip is the p-dimensional identity matrix and is a p p matrix of zeros. Only the terms used to predict the acceleration states need to be estimated to build the state transition matrix, and they are scaled as a nonlinear function of xs. After adding the variable movement speed to the state space the system is no longer linear. Therefore we need a different solution strategy. Instead of the typical KFT we use the Extended Kalman Filter (EKFT) to implement a nonlinear trajectory model by linearizing the dynamics around the best estimate at each time-step [17]. With this approach we add only small computational overhead to the KFT recursions. 4.2 Tr a i n i n g t h e t i m e w a r p i n g mo d e l The filter parameters were trained using a variant of the Expectation Maximization (EM) algorithm [18]. For extended Kalman filter learning the initialization for the variables may matter. S was initialized with the ground truth average reach speeds for each movement relative to the average speed across all movements. The state transition parameters were estimated using nonlinear least squares regression, while C, Q and R were estimated linearly for the new system, using the maximum likelihood solution [18] (M-step). For the E-step we used a standard extended Kalman smoother. We thus found the expected values for t he states given the current filter parameters. For this computation, and later when testing the algorithm, xs was initialized to its average value across all reaches while the remaining states were initialized to their true values. The smoothed estimate fo r xs was then used, along with the true values for the other states, to re-estimate the filter parameters in the M-step as before. We alternated between the E and M steps until the log likelihood converged (which it did in all cases). Following the training procedure, the diagonal of the state covariance matrix Q corresponding to xs was set to the variance of the smoothed xs over all reaches, according to how much this state should be allowed to change during prediction. This allowed the estimate of xs to develop over the course of the reach due to the evidence provided by the observations, better capturing the dynamics of reaches at different speeds. 4.3 P e r f o r ma n c e o f t h e t i m e - w a r p e d E K F T Incorporating time warping explicitly into the trajectory model pro duced a noticeable increase in decoding performance over the KFT. As the speed state xs is estimated throughout the course of the reach, based on the evidence provided by the observations, the trajectory model has the flexibility to follow the dynamics of the reach more accurately (Fig. 3). While at the normal self-selected speed the difference between the algorithms is small, for the slow and fast speeds, where the dynamics deviate from average, there i s a clear advantage to the time warping model. 5 Figure 3: Hand positions and predictions of the KFT and EKFT for sample reaches at A slow, B normal and C fast speeds. Note the different time scales between reaches. The models were first trained using data from all speeds (Fig. 4A). The EKFT was 1.8% more accurate on average (p<0.01), and the effect was significant at the slow (1.9%, p<0.05) and the fast (2.8%, p<0.01), but not at the normal (p=0.3) speed. We also trained the models from data using only reaches at the self-selected normal speed, as we wanted to see if there was enough variation to effectively train the EKFT (Fig. 4B). Interestingly, the performance of the EKFT was reduced by only 0.6%, and the KFT by 1.1%. The difference in performance between the EKFT and KFT was even more pronounced on aver age (2.3%, p<0.001), and for the slow and fast speeds (3.6 and 4.1%, both p< 0.0001). At the normal speed, the algorithms again were not statistically different (p=0.6). This result demonstrates that the EKFT is a practical option for a real BMI system, as it is not necessary to greatly vary the speeds while collecting training data for the model to be effective over a wide range of intended speeds. Explicitly incorporating speed information into the trajectory model helps decoding, by modeling the natural variation in volitional speed. Figure 4: Mean and standard error of EKFT and KFT accuracy at the different subjectselected speeds. Models were trained on reaches at A all speeds and B just normal speed reaches. Asterisks indicate statistically significant differences between the algorithms. 5 Mi xtu res of Target s So far, we have assumed that the targets of our reaches are perfectly known. In a real-world system, there will be uncertainty about the intended target of the reach. However, in typical applications there are a small number of possible objectives. Here we address this situation. Drawing on the recent literature, we use a mixture model to consider each of the possible targets [11, 13]. We condition the posterior probability for the state on the N possible targets, T: (6) 6 Using Bayes' Rule, this equation becomes: (7) As we are dealing with a mixture model, we perform the Kalman filter recursion for each possible target, xT, and our solution is a weighted sum of the outputs. The weights are proportional to the prior for that target, , and the likelihood of the model given that target . is independent of the target and does not need to be calculated. We tested mixtures of both algorithms, the mKFT and mEKFT, with real uncert ain priors obtained from eye-tracking in the one-second period preceding movement. As the targets were situated on two planes, the three-dimensional location of the eye gaze was found by projecting its direction onto those planes. The first, middle and last eye samples were selected, and all other samples were assigned to a group according to which of the three was closest. The mean and variance of these three groups were used to initialize three Kalman filters in the mixture model. The priors of the three groups were assigned proportional to the number of samples in them. If the subject looks at multiple positions prior to reaching, this method ensures with a high probability that the correct target was accounted for in one of the filters in the mixture. We also compared the MTM approach of Yu et al. [13], where a different KF model was generated for each target, and a mixture is performed over these models. This approach explicitly captures the dynamics of stereotypical reaches to specific targets. Given perfect target information, it would reduce to the STM described above. Priors for the MTM were found by assigning each valid eye sample to its closest two targets, and weighting the models proportional to the number of samples assigned to the corresponding target, divided by its distance from the mean of those samples. We tried other ways of assigning priors and the one presented gave the best results. We calculated the reduction in decoding quality when instead of perfect priors we provide eye-movement based noisy priors (Fig. 5). The accuracies of the mEKFT, the mKFT and the MTM were only degraded by 0.8, 1.9 and 2.1% respectively, compared to the perfect prior situation. The mEKFT was still close to 10% better than the KF. The mixture model framework is effective in accounting for uncertain priors. Figure 5: Mean and standard errors of accuracy for algorithms with perfect priors, and uncertain priors with full and partial training set. The asterisk indicates a statistically significant effects between the two training types, where real priors are used. Here, only reaches at normal speed were used to train the models, as this is a more realistic training set for a BMI application. This accounts for the degraded performance of the MTM with perfect priors relative to the STM from above (Fig. 2). With even more stereotyped training data for each target, the MTM doesn't generalize as well to new speeds. 7 We also wanted to know if the algorithms could generalize to new targets. In a real application, the available training data will generally not span the entire useable worksp ace. We compared the algorithms where reaches to all targets except the one being tested had been used to train the models. The performance of the MTM was significantly de graded unsurprisingly, as it was designed for reaches to a set of known targets. Performance of the mKFT and mEKFT degraded by about 1%, but not significantly (both p>0.7), demonstrating that the continuous approach to target information is preferable when the target could be anywhere in space, not just at locations for which training data is available. 6 Di scu ssi on and concl u si on s The goal of this work was to design a trajectory model that would improve decoding for BMIs with an application to reaching. We incorporated two features that prominently influence the dynamics of natural reach: the movement speed and the target location. Our approach is appropriate where uncertain target information is available. The model generalizes well to new regions of the workspace for which there is no training data, and across a broad range of reaching dynamics to widely spaced targets in three dimensions. The advantages over linear models in decoding precision we report here could be equally obtained using mixtures over many targets and speeds. While mixture models [11, 13] could allow for slow versus fast movements and any number of potential targets, this strategy will generally require many mixture components. Such an approach would require a lot more training data, as we have shown that it does not generalize well. It would also be run-time intensive which is problematic for prosthetic devices that rely on low power controllers. In contrast, the algorithm introduced here only takes a small amount of additional run-time in comparison to the standard KF approach. The EKF is only marginally slower than the standard KF and the algorithm will not generally need to consider more than 3 mixture components assuming the subject fixates the target within the second pre ceding the reach. In this paper we assumed that subjects always would fixate a reach target – along with other non-targets. While this is close to the way humans usually coordinate eyes and reaches [15], there might be cases where people do not fixate a reach target. Our approach could be easily extended to deal with such situations by adding a dummy mixture component that all ows the description of movements to any target. As an alternative to mixture approaches, a system can explicitly estimate the target position in the state vector [9]. This approach, however, would not straightforwardly allow for the rich target information available; we look at the target but also at other locations, strongly suggesting mixture distributions. A combination of the two approaches could further improve decoding quality. We could both estimate speed and target position for the EKFT in a continuous manner while retaining the mixture over target priors. We believe that the issues that we have addressed here are almost universal. Virtually all types of movements are executed at varying speed. A probabilistic distribution for a small number of action candidates may also be expected in most BMI applications – after all there are usually only a small number of actions that make sense in a given environment. While this work is presented in the context of decoding human reaching, it may be applied to a wide range of BMI applications including lower limb prosthetic devices and human computer interactions, as well as different signal sources such as electrode grid recordings and electroencephalograms. The increased user control in conveying their intended movements would significantly improve the functionality of a neuroprosthetic device. A c k n o w l e d g e me n t s T h e a u t h o r s t h a n k T. H a s w e l l , E . K r e p k o v i c h , a n d V. Ravichandran for assistance with experiments. This work was funded by the NSF Program in Cyber-Physical Systems. R e f e re n c e s [1] L.R. Hochberg, M.D. Serruya, G.M. Friehs, J.A. Mukand, M. Saleh, A.H. Caplan, A. Branner, D. 8 [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] [15] [16] [17] [18] Chen, R.D. Penn, and J.P. Donoghue, “Neuronal ensemble control of prosthetic devices by a human with tetraplegia,” Nature, vol. 442, 2006, pp. 164–171. W. Wu, Y. Gao, E. Bienenstock, J.P. Donoghue, and M.J. Black, “Bayesian population decoding of motor cortical activity using a Kalman filter,” Neural Computation, vol. 18, 2006, pp. 80–118. W. Wu, M.J. Black, Y. Gao, E. Bienenstock, M. Serruya, A. Shaikhouni, and J.P. Donoghue, “Neural decoding of cursor motion using a Kalman filter,” Advances in Neural Information Processing Systems 15: Proceedings of the 2002 Conference, 2003, p. 133. R.E. Kalman, “A new approach to linear filtering and prediction problems,” Journal of basic Engineering, vol. 82, 1960, pp. 35–45. G.G. Scandaroli, G.A. Borges, J.Y. Ishihara, M.H. Terra, A.F.D. Rocha, and F.A.D.O. Nascimento, “Estimation of foot orientation with respect to ground for an above knee robotic prosthesis,” Proceedings of the 2009 IEEE/RSJ international conference on Intelligent robots and systems, St. Louis, MO, USA: IEEE Press, 2009, pp. 1112-1117. I. Cikajlo, Z. Matjačić, and T. Bajd, “Efficient FES triggering applying Kalman filter during sensory supported treadmill walking,” Journal of Medical Engineering & Technology, vol. 32, 2008, pp. 133144. S. Kim, J.D. Simeral, L.R. Hochberg, J.P. Donoghue, and M.J. Black, “Neural control of computer cursor velocity by decoding motor cortical spiking activity in humans with tetraplegia,” Journal of Neural Engineering, vol. 5, 2008, pp. 455-476. L. Srinivasan, U.T. Eden, A.S. Willsky, and E.N. Brown, “A state-space analysis for reconstruction of goal-directed movements using neural signals,” Neural computation, vol. 18, 2006, pp. 2465–2494. G.H. Mulliken, S. Musallam, and R.A. Andersen, “Decoding trajectories from posterior parietal cortex ensembles,” Journal of Neuroscience, vol. 28, 2008, p. 12913. W. Wu, J.E. Kulkarni, N.G. Hatsopoulos, and L. Paninski, “Neural Decoding of Hand Motion Using a Linear State-Space Model With Hidden States,” IEEE Transactions on neural systems and rehabilitation engineering, vol. 17, 2009, p. 1. J.E. Kulkarni and L. Paninski, “State-space decoding of goal-directed movements,” IEEE Signal Processing Magazine, vol. 25, 2008, p. 78. C. Kemere and T. Meng, “Optimal estimation of feed-forward-controlled linear systems,” IEEE International Conference on Acoustics, Speech, and Signal Processing, 2005. Proceedings.(ICASSP'05), 2005. B.M. Yu, C. Kemere, G. Santhanam, A. Afshar, S.I. Ryu, T.H. Meng, M. Sahani, and K.V. Shenoy, “Mixture of trajectory models for neural decoding of goal-directed movements,” Journal of neurophysiology, vol. 97, 2007, p. 3763. N. Hatsopoulos, J. Joshi, and J.G. O'Leary, “Decoding continuous and discrete motor behaviors using motor and premotor cortical ensembles,” Journal of neurophysiology, vol. 92, 2004, p. 1165. R.S. Johansson, G. Westling, A. Backstrom, and J.R. Flanagan, “Eye-hand coordination in object manipulation,” Journal of Neuroscience, vol. 21, 2001, p. 6917. G. Wu, F.C. van der Helm, H.E.J. Veeger, M. Makhsous, P. Van Roy, C. Anglin, J. Nagels, A.R. Karduna, and K. McQuade, “ISB recommendation on definitions of joint coordinate systems of various joints for the reporting of human joint motion–Part II: shoulder, elbow, wrist and hand,” Journal of biomechanics, vol. 38, 2005, pp. 981–992. D. Simon, Optimal state estimation: Kalman, H [infinity] and nonlinear approaches, John Wiley and Sons, 2006. Z. Ghahramani and G.E. Hinton, “Parameter estimation for linear dynamical systems,” University of Toronto technical report CRG-TR-96-2, vol. 6, 1996. 9</p><p>4 0.99785942 <a title="100-lda-4" href="./nips-2010-Occlusion_Detection_and_Motion_Estimation_with_Convex_Optimization.html">187 nips-2010-Occlusion Detection and Motion Estimation with Convex Optimization</a></p>
<p>Author: Alper Ayvaci, Michalis Raptis, Stefano Soatto</p><p>Abstract: We tackle the problem of simultaneously detecting occlusions and estimating optical ﬂow. We show that, under standard assumptions of Lambertian reﬂection and static illumination, the task can be posed as a convex minimization problem. Therefore, the solution, computed using efﬁcient algorithms, is guaranteed to be globally optimal, for any number of independently moving objects, and any number of occlusion layers. We test the proposed algorithm on benchmark datasets, expanded to enable evaluation of occlusion detection performance. 1</p><p>5 0.99774158 <a title="100-lda-5" href="./nips-2010-Self-Paced_Learning_for_Latent_Variable_Models.html">235 nips-2010-Self-Paced Learning for Latent Variable Models</a></p>
<p>Author: M. P. Kumar, Benjamin Packer, Daphne Koller</p><p>Abstract: Latent variable models are a powerful tool for addressing several tasks in machine learning. However, the algorithms for learning the parameters of latent variable models are prone to getting stuck in a bad local optimum. To alleviate this problem, we build on the intuition that, rather than considering all samples simultaneously, the algorithm should be presented with the training data in a meaningful order that facilitates learning. The order of the samples is determined by how easy they are. The main challenge is that often we are not provided with a readily computable measure of the easiness of samples. We address this issue by proposing a novel, iterative self-paced learning algorithm where each iteration simultaneously selects easy samples and learns a new parameter vector. The number of samples selected is governed by a weight that is annealed until the entire training data has been considered. We empirically demonstrate that the self-paced learning algorithm outperforms the state of the art method for learning a latent structural SVM on four applications: object localization, noun phrase coreference, motif ﬁnding and handwritten digit recognition. 1</p><p>6 0.99740332 <a title="100-lda-6" href="./nips-2010-Kernel_Descriptors_for_Visual_Recognition.html">133 nips-2010-Kernel Descriptors for Visual Recognition</a></p>
<p>7 0.99727345 <a title="100-lda-7" href="./nips-2010-Static_Analysis_of_Binary_Executables_Using_Structural_SVMs.html">255 nips-2010-Static Analysis of Binary Executables Using Structural SVMs</a></p>
<p>8 0.99660546 <a title="100-lda-8" href="./nips-2010-A_POMDP_Extension_with_Belief-dependent_Rewards.html">11 nips-2010-A POMDP Extension with Belief-dependent Rewards</a></p>
<p>9 0.99392062 <a title="100-lda-9" href="./nips-2010-Graph-Valued_Regression.html">108 nips-2010-Graph-Valued Regression</a></p>
<p>10 0.9788214 <a title="100-lda-10" href="./nips-2010-Simultaneous_Object_Detection_and_Ranking_with_Weak_Supervision.html">240 nips-2010-Simultaneous Object Detection and Ranking with Weak Supervision</a></p>
<p>11 0.97740453 <a title="100-lda-11" href="./nips-2010-Evidence-Specific_Structures_for_Rich_Tractable_CRFs.html">83 nips-2010-Evidence-Specific Structures for Rich Tractable CRFs</a></p>
<p>12 0.97142106 <a title="100-lda-12" href="./nips-2010-Layered_image_motion_with_explicit_occlusions%2C_temporal_consistency%2C_and_depth_ordering.html">141 nips-2010-Layered image motion with explicit occlusions, temporal consistency, and depth ordering</a></p>
<p>13 0.97127199 <a title="100-lda-13" href="./nips-2010-More_data_means_less_inference%3A_A_pseudo-max_approach_to_structured_learning.html">169 nips-2010-More data means less inference: A pseudo-max approach to structured learning</a></p>
<p>14 0.97068191 <a title="100-lda-14" href="./nips-2010-Implicit_Differentiation_by_Perturbation.html">118 nips-2010-Implicit Differentiation by Perturbation</a></p>
<p>15 0.97017711 <a title="100-lda-15" href="./nips-2010-Learning_Efficient_Markov_Networks.html">144 nips-2010-Learning Efficient Markov Networks</a></p>
<p>16 0.96998006 <a title="100-lda-16" href="./nips-2010-Optimal_Bayesian_Recommendation_Sets_and_Myopically_Optimal_Choice_Query_Sets.html">197 nips-2010-Optimal Bayesian Recommendation Sets and Myopically Optimal Choice Query Sets</a></p>
<p>17 0.96971887 <a title="100-lda-17" href="./nips-2010-Predictive_State_Temporal_Difference_Learning.html">212 nips-2010-Predictive State Temporal Difference Learning</a></p>
<p>18 0.96771574 <a title="100-lda-18" href="./nips-2010-Feature_Set_Embedding_for_Incomplete_Data.html">94 nips-2010-Feature Set Embedding for Incomplete Data</a></p>
<p>19 0.96414846 <a title="100-lda-19" href="./nips-2010-Direct_Loss_Minimization_for_Structured_Prediction.html">61 nips-2010-Direct Loss Minimization for Structured Prediction</a></p>
<p>20 0.96357733 <a title="100-lda-20" href="./nips-2010-Feature_Construction_for_Inverse_Reinforcement_Learning.html">93 nips-2010-Feature Construction for Inverse Reinforcement Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
