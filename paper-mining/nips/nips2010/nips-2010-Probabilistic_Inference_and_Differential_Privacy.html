<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>216 nips-2010-Probabilistic Inference and Differential Privacy</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-216" href="#">nips2010-216</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>216 nips-2010-Probabilistic Inference and Differential Privacy</h1>
<br/><p>Source: <a title="nips-2010-216-pdf" href="http://papers.nips.cc/paper/3897-probabilistic-inference-and-differential-privacy.pdf">pdf</a></p><p>Author: Oliver Williams, Frank Mcsherry</p><p>Abstract: We identify and investigate a strong connection between probabilistic inference and differential privacy, the latter being a recent privacy deﬁnition that permits only indirect observation of data through noisy measurement. Previous research on differential privacy has focused on designing measurement processes whose output is likely to be useful on its own. We consider the potential of applying probabilistic inference to the measurements and measurement process to derive posterior distributions over the data sets and model parameters thereof. We ﬁnd that probabilistic inference can improve accuracy, integrate multiple observations, measure uncertainty, and even provide posterior distributions over quantities that were not directly measured. 1</p><p>Reference: <a title="nips-2010-216-reference" href="../nips2010_reference/nips-2010-Probabilistic_Inference_and_Differential_Privacy_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 com  Abstract We identify and investigate a strong connection between probabilistic inference and differential privacy, the latter being a recent privacy deﬁnition that permits only indirect observation of data through noisy measurement. [sent-3, score-1.221]
</p><p>2 Previous research on differential privacy has focused on designing measurement processes whose output is likely to be useful on its own. [sent-4, score-1.027]
</p><p>3 We consider the potential of applying probabilistic inference to the measurements and measurement process to derive posterior distributions over the data sets and model parameters thereof. [sent-5, score-0.564]
</p><p>4 We ﬁnd that probabilistic inference can improve accuracy, integrate multiple observations, measure uncertainty, and even provide posterior distributions over quantities that were not directly measured. [sent-6, score-0.316]
</p><p>5 1  Introduction  There has recently been signiﬁcant interest in the analysis of data sets whose individual records are too sensitive to expose directly, examples of which include medical information, ﬁnancial data, and personal data from social networking sites. [sent-7, score-0.274]
</p><p>6 Although agencies with the resources to collate such data are unable to grant outside parties direct access to them, they may be able to safely release aggregate statistics of the data set. [sent-9, score-0.145]
</p><p>7 Progress in this area has so far been driven by researchers inventing sophisticated learning algorithms which are applied directly to the data and output model parameters which can be proven to respect the privacy of the data set. [sent-10, score-0.814]
</p><p>8 Proving these privacy properties requires an intricate analysis of each algorithm on a case-by-case basis. [sent-11, score-0.688]
</p><p>9 While this does result in many valuable algorithms and results, it is not a scalable solution for two reasons: ﬁrst, to solve a new learning problem, one must invent and analyze a new privacy-preserving algorithm; second, one must then convince the owner of the data to run this algorithm. [sent-12, score-0.225]
</p><p>10 In this paper, we show a natural connection between differential privacy, one of the leading privacy deﬁnitions, and probabilistic inference. [sent-14, score-1.007]
</p><p>11 Speciﬁcally, differential privacy exposes the conditional distribution of its observable outputs given any input data set. [sent-15, score-1.059]
</p><p>12 Combining the conditional distributions of differentially-private observations with generative models for the data permits new inferences about the data without the need to invent and analyze new differentially-private computations. [sent-16, score-0.243]
</p><p>13 In some cases, one can rely on previously reported differentially private measurements. [sent-17, score-0.301]
</p><p>14 As well as this ﬂexibility, probabilistic inference can improve the accuracy of existing approaches, provide a measure of uncertainty in any predictions made, combine multiple observations in a principled way, and integrate prior knowledge about the data or parameters. [sent-19, score-0.334]
</p><p>15 In Section 3 we explore the marginal likelihood of the differentially-private observations given generative model parameters for the data. [sent-21, score-0.151]
</p><p>16 Section 4 shows several experimental results validating our hypothesis that probabilistic inference can be fruitfully applied to differentially-private computation. [sent-23, score-0.206]
</p><p>17 In particular, we show how the application of principled, probabilistic inference to measurements made by an existing, heuristic algorithm for logistic regression improves performance, as well as providing conﬁdence on the predictions made. [sent-24, score-0.49]
</p><p>18 1  Related work  There is a substantial amount of research on privacy, and differential privacy in particular, connected with machine learning and statistics. [sent-26, score-0.902]
</p><p>19 Nonetheless, we are unaware of any research that uses exact knowledge of the conditional distribution over outputs given inputs to perform inference over model parameters, or other features of the data. [sent-27, score-0.127]
</p><p>20 Chaudhuri and Monteleoni [5, 6] introduced the NIPS community to the problem of differentiallyprivate logistic regression. [sent-31, score-0.151]
</p><p>21 Although we will also consider the problem of logistic regression (and compare our ﬁndings with theirs) we should stress that the aim of the paper is not speciﬁcally to attack the problem of logistic regression. [sent-32, score-0.195]
</p><p>22 Rather, the problem serves as a good example where prior work on differentially-private logistic regression can be improved through probabilistic inference. [sent-33, score-0.198]
</p><p>23 2  Differential Privacy  Differential privacy [7] applies to randomized computations executed against a dataset and returning an aggregate result for the entire set. [sent-34, score-0.763]
</p><p>24 It prevents inference about speciﬁc records by requiring that the result of the computation yield nearly identical distributions for similar data sets. [sent-35, score-0.295]
</p><p>25 Formally, a randomized computation M satisﬁes -differential privacy if for any two possible input data sets A and B, and any subset of possible outputs S, P (M (A) ∈ S) ≤ P (M (B) ∈ S) × exp( × |A  B|) ,  (1)  where A B is the set of records in A or B, but not both. [sent-36, score-0.948]
</p><p>26 When A B is small, the relative bound on probabilities limits the inference an attacker can make about whether the true underlying data were actually A or B. [sent-37, score-0.253]
</p><p>27 Inferences about the presence, absence, or speciﬁc values of individual records are strongly constrained. [sent-38, score-0.154]
</p><p>28 One example of a differentially private computation is the exponential mechanism[8], characterized by a function φ : Dn × R → R scoring each pair of data set and possible result with a real value. [sent-39, score-0.413]
</p><p>29 While any differentially-private mechanism can be expressed as a φ function, verifying that a function φ satisﬁes the constraint | ln φ(z, A) − ln φ(z, B)| ≤ |A B| is generally not easy, and requires some form of proof on a case by case basis. [sent-41, score-0.228]
</p><p>30 This subclass is useful practically, as data providers can ensure differential privacy by clamping each φ(z, x) value to the range [e−1 , e+1 ], without having to understand the φ function. [sent-43, score-1.04]
</p><p>31 We will refer to this subclass as the factored exponential mechanism. [sent-44, score-0.232]
</p><p>32 As we can see from the deﬁnition of the exponential mechanism, a differentially-private mechanism draws its guarantees from its inherent randomness, rather than from secrecy about its speciﬁcation. [sent-45, score-0.246]
</p><p>33 Although differential privacy has many other redeeming features, it is this feature alone that we 2  i=1. [sent-46, score-0.902]
</p><p>34 (a) If the data X = {xi } are directly observable (shaded nodes), the canonical learning task is to infer the posterior over θ given a model relating X and θ. [sent-51, score-0.242]
</p><p>35 (b) In the private setting, the data are not observable; instead we observe the private measurement z, related to X by a known measurement process. [sent-52, score-0.64]
</p><p>36 By the same token, although there are many other privacy deﬁnitions with varying guarantees, we can apply inference to any deﬁnition exhibiting one key feature: an explicit probabilistic relationship between the input data sets and output observations. [sent-54, score-1.024]
</p><p>37 3  Inference and privacy  Differential privacy limits what can be inferred about a single record in a data set, but does not directly limit inference about larger scale, aggregate properties of data sets. [sent-55, score-1.685]
</p><p>38 For example, many tasks in machine learning and statistics infer global parameters describing a model of the data set without explicit dependence on any single record, and we may still expect to be see a meaningful relationship between differentially-private measurements and model parameters. [sent-56, score-0.154]
</p><p>39 One way to model a data set is to propose a generative probabilistic model for the data p(X|θ). [sent-57, score-0.185]
</p><p>40 (3)  Armed with the marginal likelihood, it is possible to bring all the techniques of probabilistic inference to bear. [sent-62, score-0.271]
</p><p>41 This will generally include adding a prior distribution over θ, and combining multiple measurements to form a posterior p(zj |θ)  p(θ|z1 . [sent-63, score-0.175]
</p><p>42 Therefore, the remainder of this section is devoted to the development of several bounds on the marginal likelihood for cases in which the measurement is generated via the factored exponential mechanism. [sent-69, score-0.479]
</p><p>43 1  Factored exponential mechanism  The factored exponential mechanism of Section 2 is a special case of differentially-private mechanism that admits efﬁcient approximation of the marginal likelihood. [sent-72, score-0.775]
</p><p>44 We will be able to use the independence in p(X|θ) = i p(xi |θ) and φ(z, X) = i φ(z, xi ) to factorize lower and upper 3  bounds on the integral (3), resulting in a small number of integrals over only the domain of records, rather than the domain of data sets. [sent-73, score-0.266]
</p><p>45 φ(z , x) dx p(x|θ) φ(z, x)  p(z|θ) ≥ z ∈Z  p(z|θ) ≤ e−H[q]  n  −1  (5a)  φ(z, x) z ∈Z φ(z , x)  dx p(x|θ)  n  (5b)  q(z )  where the upper bound is deﬁned in terms of a variational distribution q(z) [9] such that z∈ q(z) = 1. [sent-75, score-0.41]
</p><p>46 Notice that the integrations appearing in either bound are over the space of a single record in a data set and not over the entire dataset as they were in (3). [sent-77, score-0.169]
</p><p>47 Proof of lower bound To prove the lower bound, we will apply Jensen’s inequality with the function f (x) = 1/x to the marginal likelihood of the exponential mechanism. [sent-78, score-0.342]
</p><p>48 p(xi |θ)  dxn i  φ(z , xi ) φ(z, xi )  dxi p(xi |θ)  = i  =  dx p(x|θ)  φ(z , xi ) φ(z, xi )  φ(z , x) φ(z, x)  n  . [sent-82, score-0.347]
</p><p>49 Proof of upper bound We can lower bound the normalizing term z ∈Z φ(z , X) in (2) by introducing a variational distribution q(z), and applying Jensen’s inequality with the function f (x) = log x. [sent-83, score-0.272]
</p><p>50 z ∈Z  Applying this bound to the marginal likelihood gives us the bound dX p(X|θ)  φ(z, X) ≤ e−H[q] z ∈Z φ(z , X)  dX p(X|θ)  = e−H[q]  p(xi |θ)  dX i  = e−H[q]  φ(z, X) z ∈Z φ(z , X)  dx p(x|θ)  q(z )  φ(z, xi ) z ∈Z φ(z , xi )  φ(z, x) z ∈Z φ(z , x)  q(z ) n  q(z )  . [sent-85, score-0.487]
</p><p>51 While the upper bound is true for any q distribution, the tightest bound is found for the q which minimizes the bound. [sent-86, score-0.186]
</p><p>52 4  Upper bound Lower bound  Actual  p(z|theta)  0. [sent-87, score-0.132]
</p><p>53 8  theta (b)  Figure 2: Error in upper and lower bounds for coin-ﬂipping problem. [sent-99, score-0.218]
</p><p>54 (a) For each epsilon, we plot the maximum across all θ of the error between the true distribution and each of the upper and lower bounds is plotted. [sent-100, score-0.197]
</p><p>55 5, we show the shape of the upper bound, lower bound, and true distribution when differentially-private measurement returned was z = 0. [sent-102, score-0.225]
</p><p>56 1  Chosing a φ function  The upper and lower bounds in (5) are true for any admissible φ function, but leave unanswered the question of what to chose in this rˆ le. [sent-106, score-0.204]
</p><p>57 In the absence of privacy we might try to ﬁnd a good ﬁt for o the parameters θ by maximum likelihood. [sent-107, score-0.688]
</p><p>58 In the private setting this is not possible because the data are not directly observable, but the output of the factored exponential mechanism has a very similar form: Max likelihood: Exp. [sent-108, score-0.617]
</p><p>59 mechanism:  θ∗ = arg max θ∈Θ  p(xi |θ)  z ∗ = noisy max z∈Z  (6a)  i  φ(z, xi )  (6b)  i  f (z) where noisy maxz∈Z f (z) samples from . [sent-109, score-0.146]
</p><p>60 By making the analogy between (6a) and (6b), z ∈Z f (z ) we might let z range over elements of Θ (or a ﬁnite subset), and take φ(z, xi ) to be the likelihood of xi under parameters z. [sent-110, score-0.167]
</p><p>61 The exponential mechanism is then likely to choose parameters z that ﬁt the data well, informing us that the posterior over θ is likely in the vicinity of z. [sent-111, score-0.35]
</p><p>62 For φ to be admissible, we must clamp very small values of φ up to 1/e, limiting the ability of very poorly ﬁt records to inﬂuence our decisions strongly. [sent-112, score-0.154]
</p><p>63 2  Evaluation of the bounds  To demonstrate the effectiveness of these bounds we consider a problem in which it is possible to analytically compute the marginal likelihood. [sent-114, score-0.213]
</p><p>64 We see in ﬁgure 2a that the error in both the upper and lower bounds, across the entire density function, is essentially zero for small epsilon. [sent-122, score-0.123]
</p><p>65 As epsilon increases the bounds deteriorate, but we are most interested in the case of small values of epsilon, where privacy guarantees are meaningfully strong. [sent-123, score-0.979]
</p><p>66 Figure 2b shows the shape of the two bounds, and the true density between, for epsilon = 0. [sent-124, score-0.193]
</p><p>67 This large value was chosen as it is in the region for which the bounds are less tight and the difference between the bounds and the truth can be seen. [sent-126, score-0.148]
</p><p>68 5  The upper bound is deﬁned in terms of a variational distribution q. [sent-127, score-0.164]
</p><p>69 In general, however, these (and other) test show that both bounds are equally good for reasonable values of and we therefore use the lower bound for the experiments in this paper, since it is simpler to compute. [sent-129, score-0.182]
</p><p>70 First, we consider applying probabilistic inference to an existing differentially-private computation, speciﬁcally a logistic regression heuristic taken from a suite of differentially-private algorithms. [sent-131, score-0.401]
</p><p>71 The heuristic is not representable in the factored exponential mechanism, and as such we must attempt to approximate the full integral over the space of data sets directly. [sent-132, score-0.364]
</p><p>72 In our second experiment, we choose a problem and measurement process appropriate for the factored exponential mechanism, principal components analysis, previously only ever addressed through noisy observation of the covariance matrix. [sent-133, score-0.356]
</p><p>73 1  Logistic Regression  To examine the potential of probabilistic inference to improve the quality of existing differentiallyprivate computations, we consider a heuristic algorithm for logistic regression included in the Privacy Integrated Queries distribution [10]. [sent-135, score-0.483]
</p><p>74 This heuristic uses a noisy sum primitive to repeatedly compute and step in the direction of an approximate gradient. [sent-136, score-0.185]
</p><p>75 When the number of records is large compared to the noise introduced, the approximate gradient is relatively accurate, and the algorithm performs well. [sent-137, score-0.178]
</p><p>76 When the records are fewer or the privacy requirements demand more noise, its performance suffers. [sent-138, score-0.842]
</p><p>77 Probabilistic inference has the potential to improve performance by properly integrating the information extracted from the data across the multiple gradient measurements and managing the uncertainty associated with the noisy measurements. [sent-139, score-0.329]
</p><p>78 We test our proposals against three synthetic data sets (CM1 and CM2 from [5] and one of our own: SYNTH) and two data sets from the UCI repository (PIMA and ADULT) [11]. [sent-140, score-0.189]
</p><p>79 SYNTH Records Dimensions Positive examples Test set records  CM1  CM2  PIMA  ADULT  1000 4 497 1000  17500 10 8770 17500  17500 10 8694 17500  691 8 237 767*  16000 6 7841 8000  Table 1: Data sets used and their statistics. [sent-144, score-0.194]
</p><p>80 PIMA and ADULT are standard data sets [11] containing diabetes records, and census data respectively, both of which correspond to the types of data one might expect to be protected by differential privacy. [sent-147, score-0.374]
</p><p>81 1  Error Rates and Log-Likelihood  Tables 2 and 3 report the classiﬁcation accuracy of several approaches when the privacy parameter is set to 0. [sent-151, score-0.715]
</p><p>82 These results are computed from 50 executions of the heuristic gradient descent algorithm. [sent-154, score-0.17]
</p><p>83 We can see a trend of general improvement from the heuristic approach to the probabilistic inference, both in terms of the average error rate and the standard deviation. [sent-155, score-0.234]
</p><p>84 1 All measurements are in per cent; errors are reported as the mean ± one standard deviation computed from 50 independent executions with random starting points. [sent-188, score-0.133]
</p><p>85 Benchmark is the best maximum likelihood solution found by gradient ascent when the data are directly observable and forms a baseline for expected performance. [sent-191, score-0.248]
</p><p>86 Each colored path describes an execution with a ﬁxed level of accuracy in each iteration, and all are plotted on the common scale of total privacy consumption. [sent-226, score-0.715]
</p><p>87 Even with very few additional examples, probabilistic inference is capable of exploiting this information and performance improves dramatically. [sent-234, score-0.206]
</p><p>88 2  Principal components  To demonstrate inference on another model, and to highlight the applicability of the factored exponential mechanism, we consider the problem of probabilistically ﬁnding the ﬁrst principal compo7  0. [sent-236, score-0.309]
</p><p>89 (b) Incorporating non-private observations A compelling beneﬁt of probabilistic inference is how easily alternate sources of information are added. [sent-246, score-0.237]
</p><p>90 The horizontal line indicates the performance of the benchmark maximum likelihood solution computed from the data without privacy. [sent-247, score-0.133]
</p><p>91 1  Figure 4: Posterior distribution as a function of The same synthetic data set under differentiallyprivate measurements with varying epsilon. [sent-251, score-0.239]
</p><p>92 The posterior is noticeably more concentrated and accurate as epsilon increases. [sent-253, score-0.279]
</p><p>93 nent of a data set where we model the data as iid draws from a Gaussian p(x|θ) = N (0, θθT + σ 2 I). [sent-254, score-0.128]
</p><p>94 Figure 4 demonstrates three instances of inference applied to the same data set with three different values of . [sent-256, score-0.141]
</p><p>95 We stress that the posterior and its concentration are returned to the analyst; each image is the result of a single differentially-private measurement, rather than a visualization of multiple runs. [sent-258, score-0.178]
</p><p>96 5  Conclusions  Most work in the area of learning from private data forms an intrinsic analysis. [sent-262, score-0.237]
</p><p>97 That is, a complex algorithm is run by the owner of the data, directly on that data, and a single output is produced which appropriately indicates the desired parameters (modulo noise). [sent-263, score-0.126]
</p><p>98 In contrast, this paper has shown that it is possible to do a great deal with an extrinsic analysis, where standard, primitive, measurements are made against the data, and a posterior over model parameters is inferred post hoc. [sent-264, score-0.199]
</p><p>99 This paper brings together two complementary lines of research: the design and analysis of differentially-private algorithms, and probabilistic inference. [sent-265, score-0.129]
</p><p>100 Our primary goal is not to weigh-in on new differentially-private algorithms, nor to ﬁnd new methods for probabilistic inferences – it is to present the observation that the two approaches are complementary in way that can be mutually enriching. [sent-266, score-0.178]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('privacy', 0.688), ('differential', 0.214), ('private', 0.197), ('epsilon', 0.193), ('synth', 0.165), ('records', 0.154), ('mechanism', 0.152), ('pima', 0.124), ('dx', 0.123), ('factored', 0.11), ('probabilistic', 0.105), ('differentially', 0.104), ('measurement', 0.103), ('heuristic', 0.102), ('inference', 0.101), ('adult', 0.098), ('mcsherry', 0.096), ('measurements', 0.089), ('posterior', 0.086), ('differentiallyprivate', 0.082), ('bounds', 0.074), ('exponential', 0.072), ('logistic', 0.069), ('observable', 0.067), ('bound', 0.066), ('marginal', 0.065), ('xi', 0.056), ('cent', 0.055), ('invent', 0.055), ('owner', 0.055), ('likelihood', 0.055), ('chaudhuri', 0.054), ('upper', 0.054), ('subclass', 0.05), ('inferences', 0.049), ('monteleoni', 0.048), ('theta', 0.048), ('noisy', 0.045), ('dwork', 0.044), ('executions', 0.044), ('variational', 0.044), ('aggregate', 0.043), ('lower', 0.042), ('sets', 0.04), ('data', 0.04), ('record', 0.039), ('ln', 0.038), ('ascent', 0.038), ('benchmark', 0.038), ('primitive', 0.038), ('mountain', 0.036), ('admissible', 0.034), ('concentration', 0.033), ('stress', 0.033), ('computations', 0.032), ('jensen', 0.032), ('observations', 0.031), ('integration', 0.031), ('uncertainty', 0.03), ('rates', 0.03), ('repository', 0.029), ('varying', 0.028), ('permits', 0.028), ('accuracy', 0.027), ('error', 0.027), ('principal', 0.026), ('valuable', 0.026), ('returned', 0.026), ('iid', 0.026), ('graphical', 0.026), ('outputs', 0.026), ('infer', 0.025), ('run', 0.025), ('directly', 0.024), ('paths', 0.024), ('permitted', 0.024), ('exposes', 0.024), ('clamping', 0.024), ('convince', 0.024), ('multiples', 0.024), ('integrations', 0.024), ('calibrating', 0.024), ('nissim', 0.024), ('owners', 0.024), ('armed', 0.024), ('attacker', 0.024), ('extrinsic', 0.024), ('meaningfully', 0.024), ('oliver', 0.024), ('providers', 0.024), ('gradient', 0.024), ('complementary', 0.024), ('regression', 0.024), ('concerned', 0.023), ('output', 0.022), ('draws', 0.022), ('uci', 0.022), ('limits', 0.022), ('collate', 0.022), ('protection', 0.022)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000006 <a title="216-tfidf-1" href="./nips-2010-Probabilistic_Inference_and_Differential_Privacy.html">216 nips-2010-Probabilistic Inference and Differential Privacy</a></p>
<p>Author: Oliver Williams, Frank Mcsherry</p><p>Abstract: We identify and investigate a strong connection between probabilistic inference and differential privacy, the latter being a recent privacy deﬁnition that permits only indirect observation of data through noisy measurement. Previous research on differential privacy has focused on designing measurement processes whose output is likely to be useful on its own. We consider the potential of applying probabilistic inference to the measurements and measurement process to derive posterior distributions over the data sets and model parameters thereof. We ﬁnd that probabilistic inference can improve accuracy, integrate multiple observations, measure uncertainty, and even provide posterior distributions over quantities that were not directly measured. 1</p><p>2 0.34919572 <a title="216-tfidf-2" href="./nips-2010-Multiparty_Differential_Privacy_via_Aggregation_of_Locally_Trained_Classifiers.html">175 nips-2010-Multiparty Differential Privacy via Aggregation of Locally Trained Classifiers</a></p>
<p>Author: Manas Pathak, Shantanu Rane, Bhiksha Raj</p><p>Abstract: As increasing amounts of sensitive personal information ﬁnds its way into data repositories, it is important to develop analysis mechanisms that can derive aggregate information from these repositories without revealing information about individual data instances. Though the differential privacy model provides a framework to analyze such mechanisms for databases belonging to a single party, this framework has not yet been considered in a multi-party setting. In this paper, we propose a privacy-preserving protocol for composing a differentially private aggregate classiﬁer using classiﬁers trained locally by separate mutually untrusting parties. The protocol allows these parties to interact with an untrusted curator to construct additive shares of a perturbed aggregate classiﬁer. We also present a detailed theoretical analysis containing a proof of differential privacy of the perturbed aggregate classiﬁer and a bound on the excess risk introduced by the perturbation. We verify the bound with an experimental evaluation on a real dataset. 1</p><p>3 0.095496155 <a title="216-tfidf-3" href="./nips-2010-Tight_Sample_Complexity_of_Large-Margin_Learning.html">270 nips-2010-Tight Sample Complexity of Large-Margin Learning</a></p>
<p>Author: Sivan Sabato, Nathan Srebro, Naftali Tishby</p><p>Abstract: We obtain a tight distribution-speciﬁc characterization of the sample complexity of large-margin classiﬁcation with L2 regularization: We introduce the γ-adapted-dimension, which is a simple function of the spectrum of a distribution’s covariance matrix, and show distribution-speciﬁc upper and lower bounds on the sample complexity, both governed by the γ-adapted-dimension of the source distribution. We conclude that this new quantity tightly characterizes the true sample complexity of large-margin classiﬁcation. The bounds hold for a rich family of sub-Gaussian distributions. 1</p><p>4 0.092896104 <a title="216-tfidf-4" href="./nips-2010-Factorized_Latent_Spaces_with_Structured_Sparsity.html">89 nips-2010-Factorized Latent Spaces with Structured Sparsity</a></p>
<p>Author: Yangqing Jia, Mathieu Salzmann, Trevor Darrell</p><p>Abstract: Recent approaches to multi-view learning have shown that factorizing the information into parts that are shared across all views and parts that are private to each view could effectively account for the dependencies and independencies between the different input modalities. Unfortunately, these approaches involve minimizing non-convex objective functions. In this paper, we propose an approach to learning such factorized representations inspired by sparse coding techniques. In particular, we show that structured sparsity allows us to address the multiview learning problem by alternately solving two convex optimization problems. Furthermore, the resulting factorized latent spaces generalize over existing approaches in that they allow having latent dimensions shared between any subset of the views instead of between all the views only. We show that our approach outperforms state-of-the-art methods on the task of human pose estimation. 1</p><p>5 0.076978229 <a title="216-tfidf-5" href="./nips-2010-Approximate_inference_in_continuous_time_Gaussian-Jump_processes.html">33 nips-2010-Approximate inference in continuous time Gaussian-Jump processes</a></p>
<p>Author: Manfred Opper, Andreas Ruttor, Guido Sanguinetti</p><p>Abstract: We present a novel approach to inference in conditionally Gaussian continuous time stochastic processes, where the latent process is a Markovian jump process. We ﬁrst consider the case of jump-diffusion processes, where the drift of a linear stochastic differential equation can jump at arbitrary time points. We derive partial differential equations for exact inference and present a very efﬁcient mean ﬁeld approximation. By introducing a novel lower bound on the free energy, we then generalise our approach to Gaussian processes with arbitrary covariance, such as the non-Markovian RBF covariance. We present results on both simulated and real data, showing that the approach is very accurate in capturing latent dynamics and can be useful in a number of real data modelling tasks.</p><p>6 0.059771847 <a title="216-tfidf-6" href="./nips-2010-The_Neural_Costs_of_Optimal_Control.html">268 nips-2010-The Neural Costs of Optimal Control</a></p>
<p>7 0.059486713 <a title="216-tfidf-7" href="./nips-2010-t-logistic_regression.html">290 nips-2010-t-logistic regression</a></p>
<p>8 0.057792764 <a title="216-tfidf-8" href="./nips-2010-Computing_Marginal_Distributions_over_Continuous_Markov_Networks_for_Statistical_Relational_Learning.html">49 nips-2010-Computing Marginal Distributions over Continuous Markov Networks for Statistical Relational Learning</a></p>
<p>9 0.057064027 <a title="216-tfidf-9" href="./nips-2010-Variational_bounds_for_mixed-data_factor_analysis.html">284 nips-2010-Variational bounds for mixed-data factor analysis</a></p>
<p>10 0.056655128 <a title="216-tfidf-10" href="./nips-2010-The_LASSO_risk%3A_asymptotic_results_and_real_world_examples.html">265 nips-2010-The LASSO risk: asymptotic results and real world examples</a></p>
<p>11 0.056275528 <a title="216-tfidf-11" href="./nips-2010-Gated_Softmax_Classification.html">99 nips-2010-Gated Softmax Classification</a></p>
<p>12 0.056014661 <a title="216-tfidf-12" href="./nips-2010-Gaussian_sampling_by_local_perturbations.html">101 nips-2010-Gaussian sampling by local perturbations</a></p>
<p>13 0.054870028 <a title="216-tfidf-13" href="./nips-2010-Probabilistic_Multi-Task_Feature_Selection.html">217 nips-2010-Probabilistic Multi-Task Feature Selection</a></p>
<p>14 0.05310861 <a title="216-tfidf-14" href="./nips-2010-Learning_Networks_of_Stochastic_Differential_Equations.html">148 nips-2010-Learning Networks of Stochastic Differential Equations</a></p>
<p>15 0.051381003 <a title="216-tfidf-15" href="./nips-2010-Implicit_Differentiation_by_Perturbation.html">118 nips-2010-Implicit Differentiation by Perturbation</a></p>
<p>16 0.049891334 <a title="216-tfidf-16" href="./nips-2010-Slice_sampling_covariance_hyperparameters_of_latent_Gaussian_models.html">242 nips-2010-Slice sampling covariance hyperparameters of latent Gaussian models</a></p>
<p>17 0.04866584 <a title="216-tfidf-17" href="./nips-2010-Sample_Complexity_of_Testing_the_Manifold_Hypothesis.html">232 nips-2010-Sample Complexity of Testing the Manifold Hypothesis</a></p>
<p>18 0.0454899 <a title="216-tfidf-18" href="./nips-2010-Extended_Bayesian_Information_Criteria_for_Gaussian_Graphical_Models.html">87 nips-2010-Extended Bayesian Information Criteria for Gaussian Graphical Models</a></p>
<p>19 0.045218319 <a title="216-tfidf-19" href="./nips-2010-Active_Estimation_of_F-Measures.html">22 nips-2010-Active Estimation of F-Measures</a></p>
<p>20 0.044920765 <a title="216-tfidf-20" href="./nips-2010-Variational_Inference_over_Combinatorial_Spaces.html">283 nips-2010-Variational Inference over Combinatorial Spaces</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.165), (1, 0.028), (2, 0.032), (3, 0.016), (4, -0.039), (5, 0.062), (6, -0.037), (7, 0.012), (8, -0.053), (9, -0.054), (10, -0.063), (11, -0.053), (12, 0.016), (13, -0.063), (14, -0.069), (15, 0.021), (16, 0.041), (17, 0.107), (18, 0.076), (19, 0.021), (20, -0.036), (21, -0.039), (22, -0.086), (23, -0.032), (24, 0.039), (25, -0.025), (26, -0.0), (27, 0.109), (28, -0.044), (29, -0.097), (30, 0.237), (31, -0.165), (32, -0.054), (33, -0.125), (34, -0.078), (35, -0.074), (36, 0.106), (37, -0.03), (38, -0.194), (39, -0.156), (40, -0.248), (41, -0.169), (42, -0.061), (43, 0.096), (44, -0.104), (45, -0.042), (46, -0.091), (47, -0.208), (48, 0.13), (49, 0.006)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.91366684 <a title="216-lsi-1" href="./nips-2010-Probabilistic_Inference_and_Differential_Privacy.html">216 nips-2010-Probabilistic Inference and Differential Privacy</a></p>
<p>Author: Oliver Williams, Frank Mcsherry</p><p>Abstract: We identify and investigate a strong connection between probabilistic inference and differential privacy, the latter being a recent privacy deﬁnition that permits only indirect observation of data through noisy measurement. Previous research on differential privacy has focused on designing measurement processes whose output is likely to be useful on its own. We consider the potential of applying probabilistic inference to the measurements and measurement process to derive posterior distributions over the data sets and model parameters thereof. We ﬁnd that probabilistic inference can improve accuracy, integrate multiple observations, measure uncertainty, and even provide posterior distributions over quantities that were not directly measured. 1</p><p>2 0.82684028 <a title="216-lsi-2" href="./nips-2010-Multiparty_Differential_Privacy_via_Aggregation_of_Locally_Trained_Classifiers.html">175 nips-2010-Multiparty Differential Privacy via Aggregation of Locally Trained Classifiers</a></p>
<p>Author: Manas Pathak, Shantanu Rane, Bhiksha Raj</p><p>Abstract: As increasing amounts of sensitive personal information ﬁnds its way into data repositories, it is important to develop analysis mechanisms that can derive aggregate information from these repositories without revealing information about individual data instances. Though the differential privacy model provides a framework to analyze such mechanisms for databases belonging to a single party, this framework has not yet been considered in a multi-party setting. In this paper, we propose a privacy-preserving protocol for composing a differentially private aggregate classiﬁer using classiﬁers trained locally by separate mutually untrusting parties. The protocol allows these parties to interact with an untrusted curator to construct additive shares of a perturbed aggregate classiﬁer. We also present a detailed theoretical analysis containing a proof of differential privacy of the perturbed aggregate classiﬁer and a bound on the excess risk introduced by the perturbation. We verify the bound with an experimental evaluation on a real dataset. 1</p><p>3 0.40815827 <a title="216-lsi-3" href="./nips-2010-Variational_bounds_for_mixed-data_factor_analysis.html">284 nips-2010-Variational bounds for mixed-data factor analysis</a></p>
<p>Author: Mohammad E. Khan, Guillaume Bouchard, Kevin P. Murphy, Benjamin M. Marlin</p><p>Abstract: We propose a new variational EM algorithm for ﬁtting factor analysis models with mixed continuous and categorical observations. The algorithm is based on a simple quadratic bound to the log-sum-exp function. In the special case of fully observed binary data, the bound we propose is signiﬁcantly faster than previous variational methods. We show that EM is signiﬁcantly more robust in the presence of missing data compared to treating the latent factors as parameters, which is the approach used by exponential family PCA and other related matrix-factorization methods. A further beneﬁt of the variational approach is that it can easily be extended to the case of mixtures of factor analyzers, as we show. We present results on synthetic and real data sets demonstrating several desirable properties of our proposed method. 1</p><p>4 0.35266834 <a title="216-lsi-4" href="./nips-2010-Computing_Marginal_Distributions_over_Continuous_Markov_Networks_for_Statistical_Relational_Learning.html">49 nips-2010-Computing Marginal Distributions over Continuous Markov Networks for Statistical Relational Learning</a></p>
<p>Author: Matthias Broecheler, Lise Getoor</p><p>Abstract: Continuous Markov random ﬁelds are a general formalism to model joint probability distributions over events with continuous outcomes. We prove that marginal computation for constrained continuous MRFs is #P-hard in general and present a polynomial-time approximation scheme under mild assumptions on the structure of the random ﬁeld. Moreover, we introduce a sampling algorithm to compute marginal distributions and develop novel techniques to increase its efﬁciency. Continuous MRFs are a general purpose probabilistic modeling tool and we demonstrate how they can be applied to statistical relational learning. On the problem of collective classiﬁcation, we evaluate our algorithm and show that the standard deviation of marginals serves as a useful measure of conﬁdence. 1</p><p>5 0.35191178 <a title="216-lsi-5" href="./nips-2010-Approximate_inference_in_continuous_time_Gaussian-Jump_processes.html">33 nips-2010-Approximate inference in continuous time Gaussian-Jump processes</a></p>
<p>Author: Manfred Opper, Andreas Ruttor, Guido Sanguinetti</p><p>Abstract: We present a novel approach to inference in conditionally Gaussian continuous time stochastic processes, where the latent process is a Markovian jump process. We ﬁrst consider the case of jump-diffusion processes, where the drift of a linear stochastic differential equation can jump at arbitrary time points. We derive partial differential equations for exact inference and present a very efﬁcient mean ﬁeld approximation. By introducing a novel lower bound on the free energy, we then generalise our approach to Gaussian processes with arbitrary covariance, such as the non-Markovian RBF covariance. We present results on both simulated and real data, showing that the approach is very accurate in capturing latent dynamics and can be useful in a number of real data modelling tasks.</p><p>6 0.34164256 <a title="216-lsi-6" href="./nips-2010-Factorized_Latent_Spaces_with_Structured_Sparsity.html">89 nips-2010-Factorized Latent Spaces with Structured Sparsity</a></p>
<p>7 0.33694226 <a title="216-lsi-7" href="./nips-2010-Slice_sampling_covariance_hyperparameters_of_latent_Gaussian_models.html">242 nips-2010-Slice sampling covariance hyperparameters of latent Gaussian models</a></p>
<p>8 0.32657999 <a title="216-lsi-8" href="./nips-2010-Inference_and_communication_in_the_game_of_Password.html">125 nips-2010-Inference and communication in the game of Password</a></p>
<p>9 0.32382908 <a title="216-lsi-9" href="./nips-2010-Permutation_Complexity_Bound_on_Out-Sample_Error.html">205 nips-2010-Permutation Complexity Bound on Out-Sample Error</a></p>
<p>10 0.31966588 <a title="216-lsi-10" href="./nips-2010-Switched_Latent_Force_Models_for_Movement_Segmentation.html">262 nips-2010-Switched Latent Force Models for Movement Segmentation</a></p>
<p>11 0.31694224 <a title="216-lsi-11" href="./nips-2010-Inference_with_Multivariate_Heavy-Tails_in_Linear_Models.html">126 nips-2010-Inference with Multivariate Heavy-Tails in Linear Models</a></p>
<p>12 0.30653015 <a title="216-lsi-12" href="./nips-2010-Auto-Regressive_HMM_Inference_with_Incomplete_Data_for_Short-Horizon_Wind_Forecasting.html">35 nips-2010-Auto-Regressive HMM Inference with Incomplete Data for Short-Horizon Wind Forecasting</a></p>
<p>13 0.29989448 <a title="216-lsi-13" href="./nips-2010-A_New_Probabilistic_Model_for_Rank_Aggregation.html">9 nips-2010-A New Probabilistic Model for Rank Aggregation</a></p>
<p>14 0.29312259 <a title="216-lsi-14" href="./nips-2010-Tight_Sample_Complexity_of_Large-Margin_Learning.html">270 nips-2010-Tight Sample Complexity of Large-Margin Learning</a></p>
<p>15 0.2898567 <a title="216-lsi-15" href="./nips-2010-Predictive_Subspace_Learning_for_Multi-view_Data%3A_a_Large_Margin_Approach.html">213 nips-2010-Predictive Subspace Learning for Multi-view Data: a Large Margin Approach</a></p>
<p>16 0.28782007 <a title="216-lsi-16" href="./nips-2010-Evaluation_of_Rarity_of_Fingerprints_in_Forensics.html">82 nips-2010-Evaluation of Rarity of Fingerprints in Forensics</a></p>
<p>17 0.28104377 <a title="216-lsi-17" href="./nips-2010-PAC-Bayesian_Model_Selection_for_Reinforcement_Learning.html">201 nips-2010-PAC-Bayesian Model Selection for Reinforcement Learning</a></p>
<p>18 0.26283395 <a title="216-lsi-18" href="./nips-2010-A_Bayesian_Approach_to_Concept_Drift.html">2 nips-2010-A Bayesian Approach to Concept Drift</a></p>
<p>19 0.26049122 <a title="216-lsi-19" href="./nips-2010-Learning_Networks_of_Stochastic_Differential_Equations.html">148 nips-2010-Learning Networks of Stochastic Differential Equations</a></p>
<p>20 0.25703081 <a title="216-lsi-20" href="./nips-2010-Multi-View_Active_Learning_in_the_Non-Realizable_Case.html">173 nips-2010-Multi-View Active Learning in the Non-Realizable Case</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.047), (17, 0.014), (20, 0.239), (27, 0.047), (30, 0.074), (45, 0.207), (50, 0.101), (52, 0.03), (60, 0.039), (77, 0.051), (78, 0.02), (90, 0.052)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.86805058 <a title="216-lda-1" href="./nips-2010-Auto-Regressive_HMM_Inference_with_Incomplete_Data_for_Short-Horizon_Wind_Forecasting.html">35 nips-2010-Auto-Regressive HMM Inference with Incomplete Data for Short-Horizon Wind Forecasting</a></p>
<p>Author: Chris Barber, Joseph Bockhorst, Paul Roebber</p><p>Abstract: Accurate short-term wind forecasts (STWFs), with time horizons from 0.5 to 6 hours, are essential for efﬁcient integration of wind power to the electrical power grid. Physical models based on numerical weather predictions are currently not competitive, and research on machine learning approaches is ongoing. Two major challenges confronting these efforts are missing observations and weather-regime induced dependency shifts among wind variables. In this paper we introduce approaches that address both of these challenges. We describe a new regime-aware approach to STWF that use auto-regressive hidden Markov models (AR-HMM), a subclass of conditional linear Gaussian (CLG) models. Although AR-HMMs are a natural representation for weather regimes, as with CLG models in general, exact inference is NP-hard when observations are missing (Lerner and Parr, 2001). We introduce a simple approximate inference method for AR-HMMs, which we believe has applications in other problem domains. In an empirical evaluation on publicly available wind data from two geographically distinct regions, our approach makes signiﬁcantly more accurate predictions than baseline models, and uncovers meteorologically relevant regimes. 1</p><p>same-paper 2 0.79373318 <a title="216-lda-2" href="./nips-2010-Probabilistic_Inference_and_Differential_Privacy.html">216 nips-2010-Probabilistic Inference and Differential Privacy</a></p>
<p>Author: Oliver Williams, Frank Mcsherry</p><p>Abstract: We identify and investigate a strong connection between probabilistic inference and differential privacy, the latter being a recent privacy deﬁnition that permits only indirect observation of data through noisy measurement. Previous research on differential privacy has focused on designing measurement processes whose output is likely to be useful on its own. We consider the potential of applying probabilistic inference to the measurements and measurement process to derive posterior distributions over the data sets and model parameters thereof. We ﬁnd that probabilistic inference can improve accuracy, integrate multiple observations, measure uncertainty, and even provide posterior distributions over quantities that were not directly measured. 1</p><p>3 0.72123915 <a title="216-lda-3" href="./nips-2010-Construction_of_Dependent_Dirichlet_Processes_based_on_Poisson_Processes.html">51 nips-2010-Construction of Dependent Dirichlet Processes based on Poisson Processes</a></p>
<p>Author: Dahua Lin, Eric Grimson, John W. Fisher</p><p>Abstract: We present a novel method for constructing dependent Dirichlet processes. The approach exploits the intrinsic relationship between Dirichlet and Poisson processes in order to create a Markov chain of Dirichlet processes suitable for use as a prior over evolving mixture models. The method allows for the creation, removal, and location variation of component models over time while maintaining the property that the random measures are marginally DP distributed. Additionally, we derive a Gibbs sampling algorithm for model inference and test it on both synthetic and real data. Empirical results demonstrate that the approach is effective in estimating dynamically varying mixture models. 1</p><p>4 0.7187503 <a title="216-lda-4" href="./nips-2010-Computing_Marginal_Distributions_over_Continuous_Markov_Networks_for_Statistical_Relational_Learning.html">49 nips-2010-Computing Marginal Distributions over Continuous Markov Networks for Statistical Relational Learning</a></p>
<p>Author: Matthias Broecheler, Lise Getoor</p><p>Abstract: Continuous Markov random ﬁelds are a general formalism to model joint probability distributions over events with continuous outcomes. We prove that marginal computation for constrained continuous MRFs is #P-hard in general and present a polynomial-time approximation scheme under mild assumptions on the structure of the random ﬁeld. Moreover, we introduce a sampling algorithm to compute marginal distributions and develop novel techniques to increase its efﬁciency. Continuous MRFs are a general purpose probabilistic modeling tool and we demonstrate how they can be applied to statistical relational learning. On the problem of collective classiﬁcation, we evaluate our algorithm and show that the standard deviation of marginals serves as a useful measure of conﬁdence. 1</p><p>5 0.71765995 <a title="216-lda-5" href="./nips-2010-Short-term_memory_in_neuronal_networks_through_dynamical_compressed_sensing.html">238 nips-2010-Short-term memory in neuronal networks through dynamical compressed sensing</a></p>
<p>Author: Surya Ganguli, Haim Sompolinsky</p><p>Abstract: Recent proposals suggest that large, generic neuronal networks could store memory traces of past input sequences in their instantaneous state. Such a proposal raises important theoretical questions about the duration of these memory traces and their dependence on network size, connectivity and signal statistics. Prior work, in the case of gaussian input sequences and linear neuronal networks, shows that the duration of memory traces in a network cannot exceed the number of neurons (in units of the neuronal time constant), and that no network can out-perform an equivalent feedforward network. However a more ethologically relevant scenario is that of sparse input sequences. In this scenario, we show how linear neural networks can essentially perform compressed sensing (CS) of past inputs, thereby attaining a memory capacity that exceeds the number of neurons. This enhanced capacity is achieved by a class of “orthogonal” recurrent networks and not by feedforward networks or generic recurrent networks. We exploit techniques from the statistical physics of disordered systems to analytically compute the decay of memory traces in such networks as a function of network size, signal sparsity and integration time. Alternately, viewed purely from the perspective of CS, this work introduces a new ensemble of measurement matrices derived from dynamical systems, and provides a theoretical analysis of their asymptotic performance. 1</p><p>6 0.71761405 <a title="216-lda-6" href="./nips-2010-Extended_Bayesian_Information_Criteria_for_Gaussian_Graphical_Models.html">87 nips-2010-Extended Bayesian Information Criteria for Gaussian Graphical Models</a></p>
<p>7 0.71602505 <a title="216-lda-7" href="./nips-2010-Distributed_Dual_Averaging_In_Networks.html">63 nips-2010-Distributed Dual Averaging In Networks</a></p>
<p>8 0.71545428 <a title="216-lda-8" href="./nips-2010-Learning_Networks_of_Stochastic_Differential_Equations.html">148 nips-2010-Learning Networks of Stochastic Differential Equations</a></p>
<p>9 0.71238893 <a title="216-lda-9" href="./nips-2010-Identifying_graph-structured_activation_patterns_in_networks.html">117 nips-2010-Identifying graph-structured activation patterns in networks</a></p>
<p>10 0.71179211 <a title="216-lda-10" href="./nips-2010-Random_Walk_Approach_to_Regret_Minimization.html">222 nips-2010-Random Walk Approach to Regret Minimization</a></p>
<p>11 0.71103144 <a title="216-lda-11" href="./nips-2010-Smoothness%2C_Low_Noise_and_Fast_Rates.html">243 nips-2010-Smoothness, Low Noise and Fast Rates</a></p>
<p>12 0.71065962 <a title="216-lda-12" href="./nips-2010-Fast_global_convergence_rates_of_gradient_methods_for_high-dimensional_statistical_recovery.html">92 nips-2010-Fast global convergence rates of gradient methods for high-dimensional statistical recovery</a></p>
<p>13 0.7106176 <a title="216-lda-13" href="./nips-2010-Joint_Cascade_Optimization_Using_A_Product_Of_Boosted_Classifiers.html">132 nips-2010-Joint Cascade Optimization Using A Product Of Boosted Classifiers</a></p>
<p>14 0.70985556 <a title="216-lda-14" href="./nips-2010-Approximate_inference_in_continuous_time_Gaussian-Jump_processes.html">33 nips-2010-Approximate inference in continuous time Gaussian-Jump processes</a></p>
<p>15 0.70976782 <a title="216-lda-15" href="./nips-2010-Learning_via_Gaussian_Herding.html">158 nips-2010-Learning via Gaussian Herding</a></p>
<p>16 0.70937556 <a title="216-lda-16" href="./nips-2010-Parallelized_Stochastic_Gradient_Descent.html">202 nips-2010-Parallelized Stochastic Gradient Descent</a></p>
<p>17 0.70899916 <a title="216-lda-17" href="./nips-2010-Improving_the_Asymptotic_Performance_of_Markov_Chain_Monte-Carlo_by_Inserting_Vortices.html">122 nips-2010-Improving the Asymptotic Performance of Markov Chain Monte-Carlo by Inserting Vortices</a></p>
<p>18 0.70891482 <a title="216-lda-18" href="./nips-2010-Optimal_learning_rates_for_Kernel_Conjugate_Gradient_regression.html">199 nips-2010-Optimal learning rates for Kernel Conjugate Gradient regression</a></p>
<p>19 0.70865726 <a title="216-lda-19" href="./nips-2010-Variable_margin_losses_for_classifier_design.html">282 nips-2010-Variable margin losses for classifier design</a></p>
<p>20 0.7081269 <a title="216-lda-20" href="./nips-2010-Learning_the_context_of_a_category.html">155 nips-2010-Learning the context of a category</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
