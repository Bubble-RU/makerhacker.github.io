<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>77 nips-2010-Epitome driven 3-D Diffusion Tensor image segmentation: on extracting specific structures</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-77" href="#">nips2010-77</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>77 nips-2010-Epitome driven 3-D Diffusion Tensor image segmentation: on extracting specific structures</h1>
<br/><p>Source: <a title="nips-2010-77-pdf" href="http://papers.nips.cc/paper/3955-epitome-driven-3-d-diffusion-tensor-image-segmentation-on-extracting-specific-structures.pdf">pdf</a></p><p>Author: Kamiya Motwani, Nagesh Adluru, Chris Hinrichs, Andrew Alexander, Vikas Singh</p><p>Abstract: We study the problem of segmenting speciﬁc white matter structures of interest from Diffusion Tensor (DT-MR) images of the human brain. This is an important requirement in many Neuroimaging studies: for instance, to evaluate whether a brain structure exhibits group level differences as a function of disease in a set of images. Typically, interactive expert guided segmentation has been the method of choice for such applications, but this is tedious for large datasets common today. To address this problem, we endow an image segmentation algorithm with “advice” encoding some global characteristics of the region(s) we want to extract. This is accomplished by constructing (using expert-segmented images) an epitome of a speciﬁc region – as a histogram over a bag of ‘words’ (e.g., suitable feature descriptors). Now, given such a representation, the problem reduces to segmenting a new brain image with additional constraints that enforce consistency between the segmented foreground and the pre-speciﬁed histogram over features. We present combinatorial approximation algorithms to incorporate such domain speciﬁc constraints for Markov Random Field (MRF) segmentation. Making use of recent results on image co-segmentation, we derive effective solution strategies for our problem. We provide an analysis of solution quality, and present promising experimental evidence showing that many structures of interest in Neuroscience can be extracted reliably from 3-D brain image volumes using our algorithm. 1</p><p>Reference: <a title="nips-2010-77-reference" href="../nips2010_reference/nips-2010-Epitome_driven_3-D_Diffusion_Tensor_image_segmentation%3A_on_extracting_specific_structures_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract We study the problem of segmenting speciﬁc white matter structures of interest from Diffusion Tensor (DT-MR) images of the human brain. [sent-4, score-0.392]
</p><p>2 Typically, interactive expert guided segmentation has been the method of choice for such applications, but this is tedious for large datasets common today. [sent-6, score-0.505]
</p><p>3 To address this problem, we endow an image segmentation algorithm with “advice” encoding some global characteristics of the region(s) we want to extract. [sent-7, score-0.432]
</p><p>4 This is accomplished by constructing (using expert-segmented images) an epitome of a speciﬁc region – as a histogram over a bag of ‘words’ (e. [sent-8, score-0.296]
</p><p>5 Now, given such a representation, the problem reduces to segmenting a new brain image with additional constraints that enforce consistency between the segmented foreground and the pre-speciﬁed histogram over features. [sent-11, score-0.604]
</p><p>6 We provide an analysis of solution quality, and present promising experimental evidence showing that many structures of interest in Neuroscience can be extracted reliably from 3-D brain image volumes using our algorithm. [sent-14, score-0.426]
</p><p>7 , segment) speciﬁc structures of interest from DT-MR image volumes, so that these regions can then be analyzed to evaluate variations between clinically disparate groups. [sent-22, score-0.279]
</p><p>8 This paper focuses on efﬁcient algorithms for this application – that is, 3-D image segmentation with side constraints to preserve ﬁdelity of the extracted foreground with a given epitome of the brain region of interest. [sent-23, score-0.963]
</p><p>9 DTI data are represented as a 3 × 3 positive semideﬁnite tensor at each image voxel. [sent-24, score-0.269]
</p><p>10 In general, standard segmentation methods yield reasonable results in separating white matter (WM) from gray-matter (GM), see [3]. [sent-31, score-0.497]
</p><p>11 While some of these algorithms make use of the tensor ﬁeld directly [4], others utilize ‘maps’ of certain scalar-valued anisotropy measures calculated from tensors to partition WM/GM regions [5], see Fig. [sent-32, score-0.345]
</p><p>12 But different pathways play different functional roles; hence it is more meaningful to evaluate group differences in a population at the level of speciﬁc white matter structures (e. [sent-34, score-0.234]
</p><p>13 Part of the reason is that even signiﬁcant volume differences in small structures may be overwhelmed in a pair-wise t-test using volume measures of the entire white matter (obtained via WM/GM segmentation [6]). [sent-37, score-0.578]
</p><p>14 To analyze variations in speciﬁc regions, we require segmentation of such structures as a ﬁrst step. [sent-38, score-0.425]
</p><p>15 Unsupervised segmentation of speciﬁc regions of interest from DTI is difﬁcult. [sent-39, score-0.454]
</p><p>16 Even interactive segmentation (based on gray-level fractional anisotropy maps) leads to unsatisfactory results unless guided by a neuroanatomical expert – that is, specialized knowledge of the global appearance of the structure is essential in this process. [sent-40, score-0.676]
</p><p>17 Part of the reason is that the local spatial context at each tensor voxel, while useful, is not sufﬁciently discriminative. [sent-45, score-0.221]
</p><p>18 In fact, the likelihood of a voxel to be assigned as part of the foreground (structure of interest) depends on whether the set of all foreground voxels (in entirety) match an ‘appearance model’ of the structure, in addition to being perceptually homogeneous. [sent-46, score-1.022]
</p><p>19 One strategy to model the ﬁrst requirement is to extract features, generate a codebook dictionary of feature descriptors, and ask that distribution over the codebook (for foreground voxels) be consistent with the distribution induced by the expert-segmented foreground (on the same codebook). [sent-47, score-0.747]
</p><p>20 Putting this together with the homogeneity requirement serves to deﬁne the problem: segment a given DTI image (using MRFs, normalized cuts), while ensuring that the extracted foreground matches a known appearance model (over a bag of codebook features). [sent-48, score-0.511]
</p><p>21 The goal is related to recent work on simultaneous segmentation of two images called Cosegmentation [8, 9, 10, 11]. [sent-49, score-0.42]
</p><p>22 In the following sections, we formalize the problem and then present efﬁcient segmentation methods. [sent-50, score-0.344]
</p><p>23 The key contributions of this paper are: (i) We propose a new algorithm for epitome-based graph-cuts segmentation, one which permits introduction of a bias to favor solutions that match a given epitome for regions of interest. [sent-51, score-0.314]
</p><p>24 (ii) We present an application to segmentation of speciﬁc structures in Diffusion Tensor Images of the human brain and provide experimental evidence that many structures of interest in Neuroscience can be extracted reliably from large 3-D DTI images. [sent-52, score-0.682]
</p><p>25 2  Preliminaries  We provide a short overview of how image segmentation is expressed as ﬁnding the maximum likelihood solution to a Conditional or Markov Random Field function. [sent-55, score-0.432]
</p><p>26 Later, we extend the model to include an additional bias (or regularizer) so that the conﬁgurations that are consistent with an epitome of a structure of interest turn out to be more likely (than other possibly lower energy solutions). [sent-56, score-0.28]
</p><p>27 Figure 1: Speciﬁc white matter structures such as Corpus Callosum, Interior Capsules, and Cingulum Bundle are shown in 3D (left), within the entire white matter (center), and overlaid on a Fractional Anisotropy (FA) image slice (right). [sent-57, score-0.58]
</p><p>28 Note that FA is a scalar anisotropy measure often used directly for WM/GM segmentation, since anisotropy is higher in white matter. [sent-59, score-0.261]
</p><p>29 1  Markov Random Fields (MRF)  Markov Random Field based image segmentation approaches are quite popular in computer vision [12, 13] and neuroimaging [14]. [sent-61, score-0.553]
</p><p>30 Labels represent distinct image segments; each conﬁguration gives a segmentation, and the desired segmentation is the least energy MRF conﬁguration. [sent-66, score-0.471]
</p><p>31 The variable zij = 1 indicates that voxels i and j are assigned to different labels and x provides the assignment of voxel to labels (i. [sent-70, score-0.637]
</p><p>32 Next, we discuss an interesting extension of MRF segmentation, namely Cosegmentation, which deals with the simultaneous segmentation of multiple images. [sent-77, score-0.344]
</p><p>33 Therefore, one may perform a concurrent segmentation of the images with a global constraint that enforces consistency between histograms of only the foreground voxels. [sent-80, score-0.667]
</p><p>34 , using RGB intensities) for images I (1) and I (2) ; the histograms on this dictionary are: (1)  (1)  (2)  (2)  H(1) = {H1 , · · · , Hβ } and H(2) = {H1 , · · · , Hβ } (b indexes the histogram bins), (u)  such that Hb (j) = 1 if voxel j ∈ I (u) is most similar to codeword Fb , where u ∈ {1, 2}. [sent-83, score-0.505]
</p><p>35 If x(1) (1) and x(2) denote the segmentation solutions, and xj = 1 assigns voxel j of I (1) to the foreground, a measure of consistency between the foreground regions (after segmentation) is given by: β X  Ψ  “  (1)  (2)  Hb , x(1) , Hb , x(2)  b=1  ”  . [sent-84, score-1.01]
</p><p>36 (4) (u)  n  (u)  (u)  where Ψ(·, ·) is a suitable similarity (or distance) function and Hb , x(u) = j=1 Hb (j)xj , a count of the number of voxels in I (u) (from Fb ) assigned to the foreground for u ∈ {1, 2}. [sent-85, score-0.516]
</p><p>37 Using (4) to regularize the segmentation objective (1) biases the model to favor solutions where the foregrounds match (w. [sent-86, score-0.389]
</p><p>38 3  Optimization Model  We start by using the sum of squared differences (SSD) as in [9] to bias the objective function and incorporate epitome awareness within the MRF energy in (1). [sent-95, score-0.239]
</p><p>39 However, unlike [9], where one 3  seeks a segmentation of both images, here we are provided the second histogram – the epitome (representation) of the speciﬁc region of interest. [sent-96, score-0.64]
</p><p>40 Unfortunately, it remains computationally intractable for high resolution 3-D image volumes (2562 × 128) we consider here (the images are much larger than what is solvable by state of the art LP software, as in [9]). [sent-98, score-0.28]
</p><p>41 In addition, the term wj0 (and wj1 ) denote the unary cost of assigning voxel j to the background (and foreground), and λ is a user-speciﬁed tunable parameter to control the inﬂuence of the histogram variation. [sent-105, score-0.484]
</p><p>42 This yields min x,z  X  cij zij +  wj0 (1 − xj ) +  j=1  i∼j  subject to  n X  |xi − xj | ≤ zij  n X  wj1 xj + λ  j=1  β X  1  0 @ Hb , x  2  ˆ − 2 H b , x Hb +  b=1  ˆ2 Hb A |{z}  constant  ∀(i ∼ j) where i, j ∈ {1, · · · , n}, and  x, z is binary,  (5)  The last term in (5) is constant. [sent-106, score-0.635]
</p><p>43 X i∼j  cij zij +  n X j=1  |xi − xj | ≤ zij  wj0 (1 − xj ) +  n X  wj1 xj + λ  j=1  β n n X XX b=1  Hb (j)Hb (l)xj xl − 2  j=1 l=1  ∀(i ∼ j) where i, j ∈ {1, · · · , n}, and  n X  ! [sent-109, score-0.635]
</p><p>44 If the cardinality of S is no more than two, the corresponding form is Γ(x1 , x2 , · · · , xn ) =  X j  φj xj +  X  φij xi xj  (i,j)  These functions are called Quadratic Pseudo-Boolean functions (QPB). [sent-112, score-0.182]
</p><p>45 We represent each variable as a pair of literals, xj and xj , which cor¯ responds to a pair of nodes in a graph G. [sent-118, score-0.231]
</p><p>46 Depending on how the nodes for a pair of literals are partitioned, we either get “persistent” integral solutions (same as in optimal) and/or obtain variables 1 assigned 2 (half integral) values and need additional rounding to obtain a {0, 1} solution. [sent-123, score-0.256]
</p><p>47 More specifically, we express the energy by collecting the unary and pairwise costs in (6) as the coefﬁcients of the linear and quadratic variables. [sent-125, score-0.262]
</p><p>48 For a voxel j, we denote the unary coefﬁcient as Φj and for a pair of voxels (i, j) we give their corresponding coefﬁcients as Φij . [sent-126, score-0.589]
</p><p>49 spatial adjacency as i ∼ j, and if i and j share a bin in the histogram we denote it as i ∼ j, i. [sent-128, score-0.197]
</p><p>50  Φj =  wj0 if j is assigned to background ˆ wj1 + λ − 2λHb if j is assigned to foreground and ∃b : Hb (i) = 1  (8)  With the reparameterization given as Φ = s 1w [Φj Φij ]T done, we follow the recipe in 1 (w + λ − 2λH ) ˆb 2 j0 [18, 22] to construct a graph (brieﬂy sum2 j1 marized below). [sent-135, score-0.432]
</p><p>51 For each voxel j ∈ I, we introduce two nodes, vj and vj . [sent-136, score-0.513]
</p><p>52 We connect ¯ I I each node to the source and/or the sink 1λ based on the unary costs, assuming that the 2 source (and sink) partitions correspond to foreground (and background). [sent-139, score-0.458]
</p><p>53 The source 1c is connected to the node vj with weight, 1 1 1c 2 ji 2 cij 2 ij 1 ˆ b ), and to node vj with 2 cji (wj1 + λ − 2λH ¯ 2 1w weight 1 wj0 . [sent-140, score-0.398]
</p><p>54 Nodes vj and vj are in turn ¯ ˆ t 1 (wj1 + λ − 2λHb) 2 j0 2 2 1 connected to the sink with costs 2 wj0 and 1 ˆ 2 (wj1 + λ − 2λHb ) respectively. [sent-141, score-0.385]
</p><p>55 These bin neighbors spatial neighbors any voxel j edges, if saturated in a max-ﬂow, count towards the node’s unary cost. [sent-142, score-0.621]
</p><p>56 Nodes in the left box ¯ tween node pairs (except source and sink) represents vj ; nodes in the right box represent vj . [sent-144, score-0.254]
</p><p>57 These indicate spatial neighbors (orange) or bin neighbors (green). [sent-146, score-0.233]
</p><p>58 edge weights (see Table1) quantify all possible relationships of pairwise voxels and label assignments (Fig. [sent-147, score-0.246]
</p><p>59 8 < 0 1 xj = : 1 2  if vj ∈ s, vj ∈ t ¯ if vj ∈ t, vj ∈ s ¯ otherwise  (9)  A property of the solution obtained by (9) is that the variables assigned {0, 1} values are “persistent”, i. [sent-154, score-0.667]
</p><p>60 , we can 2 solve for and obtain a segmentation for only the 1 -valued variables without the additional bias). [sent-162, score-0.344]
</p><p>61 A 2-approximation for the objective function (without the epitome bias) is known [16, 12]. [sent-166, score-0.2]
</p><p>62 Note that general-purpose white matter segmentation methods do not extract speciﬁc regions (which is often obtained via intensive interactive methods instead). [sent-174, score-0.692]
</p><p>63 (ii) Does segmentation with a bias for ﬁdelity with epitomes offer advantages over training a classiﬁer on the same features? [sent-176, score-0.461]
</p><p>64 Clearly, the latter scheme will work nicely if the similarity between foreground/background voxels is sufﬁciently discriminative. [sent-177, score-0.201]
</p><p>65 (iii) Finally, we evaluate the advantages of our method in terms of relative effort expended by a user performing interactive extraction of CC and IC from 3-D volumes. [sent-179, score-0.184]
</p><p>66 We acquired 25 Diffusion Tensor brain images in 12 non-collinear diffusion encoding directions (and one b = 0 reference image) with diffusion weighting factor of b = 1000s/mm2 . [sent-181, score-0.402]
</p><p>67 From this data, the tensor elements were estimated using standard toolboxes (Camino [23]). [sent-183, score-0.212]
</p><p>68 Epitomes were constructed using training data (by averaging tensor volumes and generating feature codeword dictionaries), and then speciﬁc structures in the hold out image were segmented using our model. [sent-186, score-0.522]
</p><p>69 Codewords used for the epitome also served to train a SVM classiﬁer (on training data), which was then used to label voxels as foreground (part of structure of interest) or background, in the hold-out image. [sent-187, score-0.648]
</p><p>70 We present the mean of segmentation accuracy over 25 realizations. [sent-188, score-0.344]
</p><p>71 Certain recent works [26] have reported success in identifying structures such as the cingulum bundle if a good population speciﬁc atlas is available (here, one initializes the segmentation by a sophisticated registration procedure). [sent-195, score-0.515]
</p><p>72 2) is essential to modulate the segmentation (with an uninformative histogram, the process degenerates to a ordinary segmentation without epitomes). [sent-200, score-0.688]
</p><p>73 While general purpose feature extractors or interest-point detectors from Vision cannot be directly applied to tensor data, our simple scheme below is derived from these ideas. [sent-202, score-0.181]
</p><p>74 Similar to Histogram of Oriented Gradients or SIFT, each neighboring voxel casts a vote for the primary eigen vector orientation (weighted by its eigen value), which encodes the distribution of tensor orientations in a local neighborhood around the voxel, as a feature vector. [sent-204, score-0.602]
</p><p>75 These feature vectors are then clustered, and each voxel is ‘assigned’ to its closest codeword/feature to give H(u) . [sent-205, score-0.259]
</p><p>76 Certain adjustments are needed for structurally sparse regions close to periphery of the brain surface, where we use all primary eigen vectors in a (larger) neighborhood window. [sent-206, score-0.249]
</p><p>77 The unary terms for the MRF component were calculated as the least DTI-TK metric distance between the voxel and a set of labels (generated by sampling from foreground in the training data). [sent-214, score-0.635]
</p><p>78 1  Results: User guided interactive segmentation, Segmentation with Epitomes and SVMs  User study for interactive segmentation. [sent-218, score-0.222]
</p><p>79 To assess the amount of effort expended in obtaining a good segmentation of the regions of interest in an interactive manner, we set up a user study with two users who were familiar with (but not experts in) neuroanatomy. [sent-219, score-0.638]
</p><p>80 The user provided “scribbles” denoting foreground/background regions, which were incorporated into the segmentation via must-link/cannotlink constraints. [sent-221, score-0.396]
</p><p>81 For training, feature vectors for foreground/background voxels from the training images were used, and the learnt function was used to classify voxels in the hold-out image. [sent-227, score-0.478]
</p><p>82 4–5 where as the SVM results seem to oversegment, undersegment or pick up erroneous regions with similar contextual appearance to some voxels in the epitome. [sent-231, score-0.312]
</p><p>83 It is true that such a classiﬁcation experiment with better (more discriminative) features will likely perform better; however, it is not clear how to reliably extract good quality features from tensor valued images. [sent-232, score-0.264]
</p><p>84 The results also suggest that our model exploits the epitome of such features rather well within a segmentation criterion. [sent-233, score-0.544]
</p><p>85 For quantitative evaluations, we computed the Dice Similarity coefﬁcient 2(A∩B) between the segmentation solutions A and the expert segmentation B, given as |A|+|B| . [sent-235, score-0.766]
</p><p>86 The corresponding values for the SVM segmentation were 0. [sent-241, score-0.344]
</p><p>87 The running time of our algorithm was comparable to the running times of SVM using Shogun (a subset of voxels were used for training). [sent-248, score-0.201]
</p><p>88 Our goal is to segment the structure while maintaining consistency with an epitome of the structure, generated from expert segmented images (note that this is different from top-down segmentation approaches [27], and algorithms which use a parametric prior [28, 11]). [sent-252, score-0.74]
</p><p>89 Our derived model can be optimized using a network ﬂow pro7  Figure 4: A segmentation of the Corpus Callosum overlaid on FA maps. [sent-254, score-0.416]
</p><p>90 Figure 5: A segmentation of the Interior Capsules overlaid on FA maps. [sent-261, score-0.416]
</p><p>91 The model may serve to incorporate epitomes for general segmentation problems on other images as well. [sent-272, score-0.537]
</p><p>92 In summary, our approach shows that many structures of interest in neuroimaging can be accurately extracted from DTI data. [sent-273, score-0.208]
</p><p>93 Structural disconnectivity in schizophrenia: a diffusion tensor magnetic resonance imaging study. [sent-279, score-0.351]
</p><p>94 DTI segmentation using an information theoretic tensor dissimilarity measure. [sent-296, score-0.525]
</p><p>95 Structure-speciﬁc statistical mapping of white matter tracts using the continuous medial representation. [sent-308, score-0.186]
</p><p>96 Atlas based segmentation of white matter tracts of the human brain using diffusion tensor tractography and comparison with classical dissection. [sent-315, score-0.916]
</p><p>97 Cosegmentation of image pairs by histogram matching: Incorporating a global constraint into MRFs. [sent-332, score-0.184]
</p><p>98 Deformable registration of diffusion tensor MR images with explicit orientation optimization. [sent-453, score-0.41]
</p><p>99 Level set and region based surface propagation for diffusion tensor MRI segmentation. [sent-459, score-0.302]
</p><p>100 A fuzzy, nonparametric segmentation framework for DTI and MRI analysis with applications to DTI tract extraction. [sent-473, score-0.382]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('segmentation', 0.344), ('hb', 0.302), ('dti', 0.3), ('voxel', 0.259), ('foreground', 0.247), ('voxels', 0.201), ('epitome', 0.2), ('tensor', 0.181), ('cij', 0.144), ('unary', 0.129), ('vj', 0.127), ('diffusion', 0.121), ('epitomes', 0.117), ('cosegmentation', 0.114), ('zij', 0.109), ('histogram', 0.096), ('codebook', 0.095), ('anisotropy', 0.095), ('interactive', 0.094), ('xj', 0.091), ('image', 0.088), ('neuroimaging', 0.086), ('brain', 0.084), ('matter', 0.082), ('sink', 0.082), ('volumes', 0.081), ('structures', 0.081), ('rounding', 0.077), ('images', 0.076), ('callosum', 0.076), ('qpb', 0.076), ('overlaid', 0.072), ('white', 0.071), ('regions', 0.069), ('assigned', 0.068), ('neighbors', 0.066), ('mrf', 0.065), ('eigen', 0.065), ('bin', 0.061), ('fa', 0.06), ('wm', 0.058), ('cingulum', 0.057), ('user', 0.052), ('reliably', 0.051), ('neuroimage', 0.05), ('graph', 0.049), ('costs', 0.049), ('imaging', 0.049), ('kolmogorov', 0.048), ('segmented', 0.048), ('solutions', 0.045), ('pairwise', 0.045), ('axial', 0.043), ('codeword', 0.043), ('appearance', 0.042), ('mrfs', 0.042), ('interest', 0.041), ('segmenting', 0.041), ('spatial', 0.04), ('energy', 0.039), ('segment', 0.039), ('svm', 0.039), ('adluru', 0.038), ('capsules', 0.038), ('expended', 0.038), ('hinrichs', 0.038), ('tract', 0.038), ('uw', 0.038), ('xjk', 0.038), ('yushkevich', 0.038), ('cc', 0.037), ('rother', 0.037), ('wisconsin', 0.037), ('mins', 0.037), ('singh', 0.036), ('vision', 0.035), ('corpus', 0.035), ('ic', 0.035), ('solvable', 0.035), ('lk', 0.035), ('guided', 0.034), ('fractional', 0.034), ('medical', 0.033), ('ssd', 0.033), ('literals', 0.033), ('pseudoboolean', 0.033), ('sagittal', 0.033), ('tracts', 0.033), ('bundle', 0.033), ('slice', 0.033), ('expert', 0.033), ('integral', 0.033), ('combinatorial', 0.032), ('orientation', 0.032), ('extract', 0.032), ('dictionary', 0.031), ('adjustments', 0.031), ('fb', 0.031), ('toolboxes', 0.031), ('boykov', 0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="77-tfidf-1" href="./nips-2010-Epitome_driven_3-D_Diffusion_Tensor_image_segmentation%3A_on_extracting_specific_structures.html">77 nips-2010-Epitome driven 3-D Diffusion Tensor image segmentation: on extracting specific structures</a></p>
<p>Author: Kamiya Motwani, Nagesh Adluru, Chris Hinrichs, Andrew Alexander, Vikas Singh</p><p>Abstract: We study the problem of segmenting speciﬁc white matter structures of interest from Diffusion Tensor (DT-MR) images of the human brain. This is an important requirement in many Neuroimaging studies: for instance, to evaluate whether a brain structure exhibits group level differences as a function of disease in a set of images. Typically, interactive expert guided segmentation has been the method of choice for such applications, but this is tedious for large datasets common today. To address this problem, we endow an image segmentation algorithm with “advice” encoding some global characteristics of the region(s) we want to extract. This is accomplished by constructing (using expert-segmented images) an epitome of a speciﬁc region – as a histogram over a bag of ‘words’ (e.g., suitable feature descriptors). Now, given such a representation, the problem reduces to segmenting a new brain image with additional constraints that enforce consistency between the segmented foreground and the pre-speciﬁed histogram over features. We present combinatorial approximation algorithms to incorporate such domain speciﬁc constraints for Markov Random Field (MRF) segmentation. Making use of recent results on image co-segmentation, we derive effective solution strategies for our problem. We provide an analysis of solution quality, and present promising experimental evidence showing that many structures of interest in Neuroscience can be extracted reliably from 3-D brain image volumes using our algorithm. 1</p><p>2 0.21482569 <a title="77-tfidf-2" href="./nips-2010-Spatial_and_anatomical_regularization_of_SVM_for_brain_image_analysis.html">249 nips-2010-Spatial and anatomical regularization of SVM for brain image analysis</a></p>
<p>Author: Remi Cuingnet, Marie Chupin, Habib Benali, Olivier Colliot</p><p>Abstract: Support vector machines (SVM) are increasingly used in brain image analyses since they allow capturing complex multivariate relationships in the data. Moreover, when the kernel is linear, SVMs can be used to localize spatial patterns of discrimination between two groups of subjects. However, the features’ spatial distribution is not taken into account. As a consequence, the optimal margin hyperplane is often scattered and lacks spatial coherence, making its anatomical interpretation difﬁcult. This paper introduces a framework to spatially regularize SVM for brain image analysis. We show that Laplacian regularization provides a ﬂexible framework to integrate various types of constraints and can be applied to both cortical surfaces and 3D brain images. The proposed framework is applied to the classiﬁcation of MR images based on gray matter concentration maps and cortical thickness measures from 30 patients with Alzheimer’s disease and 30 elderly controls. The results demonstrate that the proposed method enables natural spatial and anatomical regularization of the classiﬁer. 1</p><p>3 0.1794489 <a title="77-tfidf-3" href="./nips-2010-Structural_epitome%3A_a_way_to_summarize_one%E2%80%99s_visual_experience.html">256 nips-2010-Structural epitome: a way to summarize one’s visual experience</a></p>
<p>Author: Nebojsa Jojic, Alessandro Perina, Vittorio Murino</p><p>Abstract: In order to study the properties of total visual input in humans, a single subject wore a camera for two weeks capturing, on average, an image every 20 seconds. The resulting new dataset contains a mix of indoor and outdoor scenes as well as numerous foreground objects. Our ﬁrst goal is to create a visual summary of the subject’s two weeks of life using unsupervised algorithms that would automatically discover recurrent scenes, familiar faces or common actions. Direct application of existing algorithms, such as panoramic stitching (e.g., Photosynth) or appearance-based clustering models (e.g., the epitome), is impractical due to either the large dataset size or the dramatic variations in the lighting conditions. As a remedy to these problems, we introduce a novel image representation, the ”structural element (stel) epitome,” and an associated efﬁcient learning algorithm. In our model, each image or image patch is characterized by a hidden mapping T which, as in previous epitome models, deﬁnes a mapping between the image coordinates and the coordinates in the large ”all-I-have-seen” epitome matrix. The limited epitome real-estate forces the mappings of different images to overlap which indicates image similarity. However, the image similarity no longer depends on direct pixel-to-pixel intensity/color/feature comparisons as in previous epitome models, but on spatial conﬁguration of scene or object parts, as the model is based on the palette-invariant stel models. As a result, stel epitomes capture structure that is invariant to non-structural changes, such as illumination changes, that tend to uniformly affect pixels belonging to a single scene or object part. 1</p><p>4 0.16153277 <a title="77-tfidf-4" href="./nips-2010-Infinite_Relational_Modeling_of_Functional_Connectivity_in_Resting_State_fMRI.html">128 nips-2010-Infinite Relational Modeling of Functional Connectivity in Resting State fMRI</a></p>
<p>Author: Morten Mørup, Kristoffer Madsen, Anne-marie Dogonowski, Hartwig Siebner, Lars K. Hansen</p><p>Abstract: Functional magnetic resonance imaging (fMRI) can be applied to study the functional connectivity of the neural elements which form complex network at a whole brain level. Most analyses of functional resting state networks (RSN) have been based on the analysis of correlation between the temporal dynamics of various regions of the brain. While these models can identify coherently behaving groups in terms of correlation they give little insight into how these groups interact. In this paper we take a different view on the analysis of functional resting state networks. Starting from the deﬁnition of resting state as functional coherent groups we search for functional units of the brain that communicate with other parts of the brain in a coherent manner as measured by mutual information. We use the inﬁnite relational model (IRM) to quantify functional coherent groups of resting state networks and demonstrate how the extracted component interactions can be used to discriminate between functional resting state activity in multiple sclerosis and normal subjects. 1</p><p>5 0.11524326 <a title="77-tfidf-5" href="./nips-2010-Segmentation_as_Maximum-Weight_Independent_Set.html">234 nips-2010-Segmentation as Maximum-Weight Independent Set</a></p>
<p>Author: William Brendel, Sinisa Todorovic</p><p>Abstract: Given an ensemble of distinct, low-level segmentations of an image, our goal is to identify visually “meaningful” segments in the ensemble. Knowledge about any speciﬁc objects and surfaces present in the image is not available. The selection of image regions occupied by objects is formalized as the maximum-weight independent set (MWIS) problem. MWIS is the heaviest subset of mutually non-adjacent nodes of an attributed graph. We construct such a graph from all segments in the ensemble. Then, MWIS selects maximally distinctive segments that together partition the image. A new MWIS algorithm is presented. The algorithm seeks a solution directly in the discrete domain, instead of relaxing MWIS to a continuous problem, as common in previous work. It iteratively ﬁnds a candidate discrete solution of the Taylor series expansion of the original MWIS objective function around the previous solution. The algorithm is shown to converge to an optimum. Our empirical evaluation on the benchmark Berkeley segmentation dataset shows that the new algorithm eliminates the need for hand-picking optimal input parameters of the state-of-the-art segmenters, and outperforms their best, manually optimized results.</p><p>6 0.11210594 <a title="77-tfidf-6" href="./nips-2010-A_Discriminative_Latent_Model_of_Image_Region_and_Object_Tag_Correspondence.html">6 nips-2010-A Discriminative Latent Model of Image Region and Object Tag Correspondence</a></p>
<p>7 0.10433774 <a title="77-tfidf-7" href="./nips-2010-Functional_Geometry_Alignment_and_Localization_of_Brain_Areas.html">97 nips-2010-Functional Geometry Alignment and Localization of Brain Areas</a></p>
<p>8 0.099170014 <a title="77-tfidf-8" href="./nips-2010-Brain_covariance_selection%3A_better_individual_functional_connectivity_models_using_population_prior.html">44 nips-2010-Brain covariance selection: better individual functional connectivity models using population prior</a></p>
<p>9 0.096793801 <a title="77-tfidf-9" href="./nips-2010-Smoothness%2C_Low_Noise_and_Fast_Rates.html">243 nips-2010-Smoothness, Low Noise and Fast Rates</a></p>
<p>10 0.095860586 <a title="77-tfidf-10" href="./nips-2010-Worst-case_bounds_on_the_quality_of_max-product_fixed-points.html">288 nips-2010-Worst-case bounds on the quality of max-product fixed-points</a></p>
<p>11 0.092866987 <a title="77-tfidf-11" href="./nips-2010-Individualized_ROI_Optimization_via_Maximization_of_Group-wise_Consistency_of_Structural_and_Functional_Profiles.html">123 nips-2010-Individualized ROI Optimization via Maximization of Group-wise Consistency of Structural and Functional Profiles</a></p>
<p>12 0.089953288 <a title="77-tfidf-12" href="./nips-2010-Learning_To_Count_Objects_in_Images.html">149 nips-2010-Learning To Count Objects in Images</a></p>
<p>13 0.088755593 <a title="77-tfidf-13" href="./nips-2010-Layered_image_motion_with_explicit_occlusions%2C_temporal_consistency%2C_and_depth_ordering.html">141 nips-2010-Layered image motion with explicit occlusions, temporal consistency, and depth ordering</a></p>
<p>14 0.087487735 <a title="77-tfidf-14" href="./nips-2010-Network_Flow_Algorithms_for_Structured_Sparsity.html">181 nips-2010-Network Flow Algorithms for Structured Sparsity</a></p>
<p>15 0.087344207 <a title="77-tfidf-15" href="./nips-2010-Synergies_in_learning_words_and_their_referents.html">264 nips-2010-Synergies in learning words and their referents</a></p>
<p>16 0.084565505 <a title="77-tfidf-16" href="./nips-2010-%28RF%29%5E2_--_Random_Forest_Random_Field.html">1 nips-2010-(RF)^2 -- Random Forest Random Field</a></p>
<p>17 0.07446067 <a title="77-tfidf-17" href="./nips-2010-Simultaneous_Object_Detection_and_Ranking_with_Weak_Supervision.html">240 nips-2010-Simultaneous Object Detection and Ranking with Weak Supervision</a></p>
<p>18 0.07187961 <a title="77-tfidf-18" href="./nips-2010-Size_Matters%3A_Metric_Visual_Search_Constraints_from_Monocular_Metadata.html">241 nips-2010-Size Matters: Metric Visual Search Constraints from Monocular Metadata</a></p>
<p>19 0.069787748 <a title="77-tfidf-19" href="./nips-2010-Generating_more_realistic_images_using_gated_MRF%27s.html">103 nips-2010-Generating more realistic images using gated MRF's</a></p>
<p>20 0.067737564 <a title="77-tfidf-20" href="./nips-2010-Static_Analysis_of_Binary_Executables_Using_Structural_SVMs.html">255 nips-2010-Static Analysis of Binary Executables Using Structural SVMs</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.198), (1, 0.083), (2, -0.137), (3, -0.014), (4, -0.038), (5, -0.143), (6, -0.012), (7, -0.176), (8, 0.065), (9, 0.065), (10, -0.022), (11, 0.018), (12, -0.023), (13, 0.049), (14, -0.113), (15, -0.002), (16, -0.001), (17, -0.037), (18, 0.076), (19, -0.081), (20, 0.064), (21, 0.024), (22, -0.085), (23, -0.0), (24, 0.001), (25, -0.079), (26, -0.039), (27, 0.024), (28, -0.147), (29, 0.079), (30, 0.017), (31, 0.087), (32, 0.009), (33, -0.079), (34, -0.1), (35, -0.101), (36, 0.036), (37, -0.063), (38, 0.106), (39, -0.053), (40, 0.036), (41, -0.032), (42, -0.104), (43, 0.075), (44, -0.141), (45, 0.044), (46, -0.043), (47, 0.075), (48, 0.072), (49, 0.008)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9389317 <a title="77-lsi-1" href="./nips-2010-Epitome_driven_3-D_Diffusion_Tensor_image_segmentation%3A_on_extracting_specific_structures.html">77 nips-2010-Epitome driven 3-D Diffusion Tensor image segmentation: on extracting specific structures</a></p>
<p>Author: Kamiya Motwani, Nagesh Adluru, Chris Hinrichs, Andrew Alexander, Vikas Singh</p><p>Abstract: We study the problem of segmenting speciﬁc white matter structures of interest from Diffusion Tensor (DT-MR) images of the human brain. This is an important requirement in many Neuroimaging studies: for instance, to evaluate whether a brain structure exhibits group level differences as a function of disease in a set of images. Typically, interactive expert guided segmentation has been the method of choice for such applications, but this is tedious for large datasets common today. To address this problem, we endow an image segmentation algorithm with “advice” encoding some global characteristics of the region(s) we want to extract. This is accomplished by constructing (using expert-segmented images) an epitome of a speciﬁc region – as a histogram over a bag of ‘words’ (e.g., suitable feature descriptors). Now, given such a representation, the problem reduces to segmenting a new brain image with additional constraints that enforce consistency between the segmented foreground and the pre-speciﬁed histogram over features. We present combinatorial approximation algorithms to incorporate such domain speciﬁc constraints for Markov Random Field (MRF) segmentation. Making use of recent results on image co-segmentation, we derive effective solution strategies for our problem. We provide an analysis of solution quality, and present promising experimental evidence showing that many structures of interest in Neuroscience can be extracted reliably from 3-D brain image volumes using our algorithm. 1</p><p>2 0.73274505 <a title="77-lsi-2" href="./nips-2010-Segmentation_as_Maximum-Weight_Independent_Set.html">234 nips-2010-Segmentation as Maximum-Weight Independent Set</a></p>
<p>Author: William Brendel, Sinisa Todorovic</p><p>Abstract: Given an ensemble of distinct, low-level segmentations of an image, our goal is to identify visually “meaningful” segments in the ensemble. Knowledge about any speciﬁc objects and surfaces present in the image is not available. The selection of image regions occupied by objects is formalized as the maximum-weight independent set (MWIS) problem. MWIS is the heaviest subset of mutually non-adjacent nodes of an attributed graph. We construct such a graph from all segments in the ensemble. Then, MWIS selects maximally distinctive segments that together partition the image. A new MWIS algorithm is presented. The algorithm seeks a solution directly in the discrete domain, instead of relaxing MWIS to a continuous problem, as common in previous work. It iteratively ﬁnds a candidate discrete solution of the Taylor series expansion of the original MWIS objective function around the previous solution. The algorithm is shown to converge to an optimum. Our empirical evaluation on the benchmark Berkeley segmentation dataset shows that the new algorithm eliminates the need for hand-picking optimal input parameters of the state-of-the-art segmenters, and outperforms their best, manually optimized results.</p><p>3 0.69495243 <a title="77-lsi-3" href="./nips-2010-Structural_epitome%3A_a_way_to_summarize_one%E2%80%99s_visual_experience.html">256 nips-2010-Structural epitome: a way to summarize one’s visual experience</a></p>
<p>Author: Nebojsa Jojic, Alessandro Perina, Vittorio Murino</p><p>Abstract: In order to study the properties of total visual input in humans, a single subject wore a camera for two weeks capturing, on average, an image every 20 seconds. The resulting new dataset contains a mix of indoor and outdoor scenes as well as numerous foreground objects. Our ﬁrst goal is to create a visual summary of the subject’s two weeks of life using unsupervised algorithms that would automatically discover recurrent scenes, familiar faces or common actions. Direct application of existing algorithms, such as panoramic stitching (e.g., Photosynth) or appearance-based clustering models (e.g., the epitome), is impractical due to either the large dataset size or the dramatic variations in the lighting conditions. As a remedy to these problems, we introduce a novel image representation, the ”structural element (stel) epitome,” and an associated efﬁcient learning algorithm. In our model, each image or image patch is characterized by a hidden mapping T which, as in previous epitome models, deﬁnes a mapping between the image coordinates and the coordinates in the large ”all-I-have-seen” epitome matrix. The limited epitome real-estate forces the mappings of different images to overlap which indicates image similarity. However, the image similarity no longer depends on direct pixel-to-pixel intensity/color/feature comparisons as in previous epitome models, but on spatial conﬁguration of scene or object parts, as the model is based on the palette-invariant stel models. As a result, stel epitomes capture structure that is invariant to non-structural changes, such as illumination changes, that tend to uniformly affect pixels belonging to a single scene or object part. 1</p><p>4 0.62853247 <a title="77-lsi-4" href="./nips-2010-Spatial_and_anatomical_regularization_of_SVM_for_brain_image_analysis.html">249 nips-2010-Spatial and anatomical regularization of SVM for brain image analysis</a></p>
<p>Author: Remi Cuingnet, Marie Chupin, Habib Benali, Olivier Colliot</p><p>Abstract: Support vector machines (SVM) are increasingly used in brain image analyses since they allow capturing complex multivariate relationships in the data. Moreover, when the kernel is linear, SVMs can be used to localize spatial patterns of discrimination between two groups of subjects. However, the features’ spatial distribution is not taken into account. As a consequence, the optimal margin hyperplane is often scattered and lacks spatial coherence, making its anatomical interpretation difﬁcult. This paper introduces a framework to spatially regularize SVM for brain image analysis. We show that Laplacian regularization provides a ﬂexible framework to integrate various types of constraints and can be applied to both cortical surfaces and 3D brain images. The proposed framework is applied to the classiﬁcation of MR images based on gray matter concentration maps and cortical thickness measures from 30 patients with Alzheimer’s disease and 30 elderly controls. The results demonstrate that the proposed method enables natural spatial and anatomical regularization of the classiﬁer. 1</p><p>5 0.53736788 <a title="77-lsi-5" href="./nips-2010-Learning_To_Count_Objects_in_Images.html">149 nips-2010-Learning To Count Objects in Images</a></p>
<p>Author: Victor Lempitsky, Andrew Zisserman</p><p>Abstract: We propose a new supervised learning framework for visual object counting tasks, such as estimating the number of cells in a microscopic image or the number of humans in surveillance video frames. We focus on the practically-attractive case when the training images are annotated with dots (one dot per object). Our goal is to accurately estimate the count. However, we evade the hard task of learning to detect and localize individual object instances. Instead, we cast the problem as that of estimating an image density whose integral over any image region gives the count of objects within that region. Learning to infer such density can be formulated as a minimization of a regularized risk quadratic cost function. We introduce a new loss function, which is well-suited for such learning, and at the same time can be computed efﬁciently via a maximum subarray algorithm. The learning can then be posed as a convex quadratic program solvable with cutting-plane optimization. The proposed framework is very ﬂexible as it can accept any domain-speciﬁc visual features. Once trained, our system provides accurate object counts and requires a very small time overhead over the feature extraction step, making it a good candidate for applications involving real-time processing or dealing with huge amount of visual data. 1</p><p>6 0.51513779 <a title="77-lsi-6" href="./nips-2010-Functional_Geometry_Alignment_and_Localization_of_Brain_Areas.html">97 nips-2010-Functional Geometry Alignment and Localization of Brain Areas</a></p>
<p>7 0.50657564 <a title="77-lsi-7" href="./nips-2010-Individualized_ROI_Optimization_via_Maximization_of_Group-wise_Consistency_of_Structural_and_Functional_Profiles.html">123 nips-2010-Individualized ROI Optimization via Maximization of Group-wise Consistency of Structural and Functional Profiles</a></p>
<p>8 0.49525574 <a title="77-lsi-8" href="./nips-2010-Infinite_Relational_Modeling_of_Functional_Connectivity_in_Resting_State_fMRI.html">128 nips-2010-Infinite Relational Modeling of Functional Connectivity in Resting State fMRI</a></p>
<p>9 0.48146799 <a title="77-lsi-9" href="./nips-2010-Space-Variant_Single-Image_Blind_Deconvolution_for_Removing_Camera_Shake.html">245 nips-2010-Space-Variant Single-Image Blind Deconvolution for Removing Camera Shake</a></p>
<p>10 0.47260422 <a title="77-lsi-10" href="./nips-2010-Brain_covariance_selection%3A_better_individual_functional_connectivity_models_using_population_prior.html">44 nips-2010-Brain covariance selection: better individual functional connectivity models using population prior</a></p>
<p>11 0.45123374 <a title="77-lsi-11" href="./nips-2010-Generating_more_realistic_images_using_gated_MRF%27s.html">103 nips-2010-Generating more realistic images using gated MRF's</a></p>
<p>12 0.43871495 <a title="77-lsi-12" href="./nips-2010-Worst-case_bounds_on_the_quality_of_max-product_fixed-points.html">288 nips-2010-Worst-case bounds on the quality of max-product fixed-points</a></p>
<p>13 0.42734632 <a title="77-lsi-13" href="./nips-2010-%28RF%29%5E2_--_Random_Forest_Random_Field.html">1 nips-2010-(RF)^2 -- Random Forest Random Field</a></p>
<p>14 0.42172512 <a title="77-lsi-14" href="./nips-2010-A_Discriminative_Latent_Model_of_Image_Region_and_Object_Tag_Correspondence.html">6 nips-2010-A Discriminative Latent Model of Image Region and Object Tag Correspondence</a></p>
<p>15 0.41020179 <a title="77-lsi-15" href="./nips-2010-Network_Flow_Algorithms_for_Structured_Sparsity.html">181 nips-2010-Network Flow Algorithms for Structured Sparsity</a></p>
<p>16 0.38780066 <a title="77-lsi-16" href="./nips-2010-Layered_image_motion_with_explicit_occlusions%2C_temporal_consistency%2C_and_depth_ordering.html">141 nips-2010-Layered image motion with explicit occlusions, temporal consistency, and depth ordering</a></p>
<p>17 0.38077056 <a title="77-lsi-17" href="./nips-2010-The_Multidimensional_Wisdom_of_Crowds.html">267 nips-2010-The Multidimensional Wisdom of Crowds</a></p>
<p>18 0.37967139 <a title="77-lsi-18" href="./nips-2010-Static_Analysis_of_Binary_Executables_Using_Structural_SVMs.html">255 nips-2010-Static Analysis of Binary Executables Using Structural SVMs</a></p>
<p>19 0.37608114 <a title="77-lsi-19" href="./nips-2010-Evaluation_of_Rarity_of_Fingerprints_in_Forensics.html">82 nips-2010-Evaluation of Rarity of Fingerprints in Forensics</a></p>
<p>20 0.36998472 <a title="77-lsi-20" href="./nips-2010-MAP_estimation_in_Binary_MRFs_via_Bipartite_Multi-cuts.html">165 nips-2010-MAP estimation in Binary MRFs via Bipartite Multi-cuts</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.028), (17, 0.019), (27, 0.121), (30, 0.065), (35, 0.039), (45, 0.208), (49, 0.237), (50, 0.037), (52, 0.028), (60, 0.04), (72, 0.014), (77, 0.04), (78, 0.016), (90, 0.03)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.84515578 <a title="77-lda-1" href="./nips-2010-Estimation_of_Renyi_Entropy_and_Mutual_Information_Based_on_Generalized_Nearest-Neighbor_Graphs.html">80 nips-2010-Estimation of Renyi Entropy and Mutual Information Based on Generalized Nearest-Neighbor Graphs</a></p>
<p>Author: Barnabás Póczos, Csaba Szepesvári, David Tax</p><p>Abstract: We present simple and computationally efﬁcient nonparametric estimators of R´ nyi entropy and mutual information based on an i.i.d. sample drawn from an e unknown, absolutely continuous distribution over Rd . The estimators are calculated as the sum of p-th powers of the Euclidean lengths of the edges of the ‘generalized nearest-neighbor’ graph of the sample and the empirical copula of the sample respectively. For the ﬁrst time, we prove the almost sure consistency of these estimators and upper bounds on their rates of convergence, the latter of which under the assumption that the density underlying the sample is Lipschitz continuous. Experiments demonstrate their usefulness in independent subspace analysis. 1</p><p>same-paper 2 0.81972134 <a title="77-lda-2" href="./nips-2010-Epitome_driven_3-D_Diffusion_Tensor_image_segmentation%3A_on_extracting_specific_structures.html">77 nips-2010-Epitome driven 3-D Diffusion Tensor image segmentation: on extracting specific structures</a></p>
<p>Author: Kamiya Motwani, Nagesh Adluru, Chris Hinrichs, Andrew Alexander, Vikas Singh</p><p>Abstract: We study the problem of segmenting speciﬁc white matter structures of interest from Diffusion Tensor (DT-MR) images of the human brain. This is an important requirement in many Neuroimaging studies: for instance, to evaluate whether a brain structure exhibits group level differences as a function of disease in a set of images. Typically, interactive expert guided segmentation has been the method of choice for such applications, but this is tedious for large datasets common today. To address this problem, we endow an image segmentation algorithm with “advice” encoding some global characteristics of the region(s) we want to extract. This is accomplished by constructing (using expert-segmented images) an epitome of a speciﬁc region – as a histogram over a bag of ‘words’ (e.g., suitable feature descriptors). Now, given such a representation, the problem reduces to segmenting a new brain image with additional constraints that enforce consistency between the segmented foreground and the pre-speciﬁed histogram over features. We present combinatorial approximation algorithms to incorporate such domain speciﬁc constraints for Markov Random Field (MRF) segmentation. Making use of recent results on image co-segmentation, we derive effective solution strategies for our problem. We provide an analysis of solution quality, and present promising experimental evidence showing that many structures of interest in Neuroscience can be extracted reliably from 3-D brain image volumes using our algorithm. 1</p><p>3 0.80060387 <a title="77-lda-3" href="./nips-2010-Sufficient_Conditions_for_Generating_Group_Level_Sparsity_in_a_Robust_Minimax_Framework.html">260 nips-2010-Sufficient Conditions for Generating Group Level Sparsity in a Robust Minimax Framework</a></p>
<p>Author: Hongbo Zhou, Qiang Cheng</p><p>Abstract: Regularization technique has become a principled tool for statistics and machine learning research and practice. However, in most situations, these regularization terms are not well interpreted, especially on how they are related to the loss function and data. In this paper, we propose a robust minimax framework to interpret the relationship between data and regularization terms for a large class of loss functions. We show that various regularization terms are essentially corresponding to different distortions to the original data matrix. This minimax framework includes ridge regression, lasso, elastic net, fused lasso, group lasso, local coordinate coding, multiple kernel learning, etc., as special cases. Within this minimax framework, we further give mathematically exact deﬁnition for a novel representation called sparse grouping representation (SGR), and prove a set of sufﬁcient conditions for generating such group level sparsity. Under these sufﬁcient conditions, a large set of consistent regularization terms can be designed. This SGR is essentially different from group lasso in the way of using class or group information, and it outperforms group lasso when there appears group label noise. We also provide some generalization bounds in a classiﬁcation setting. 1</p><p>4 0.76817584 <a title="77-lda-4" href="./nips-2010-t-logistic_regression.html">290 nips-2010-t-logistic regression</a></p>
<p>Author: Nan Ding, S.v.n. Vishwanathan</p><p>Abstract: We extend logistic regression by using t-exponential families which were introduced recently in statistical physics. This gives rise to a regularized risk minimization problem with a non-convex loss function. An efﬁcient block coordinate descent optimization scheme can be derived for estimating the parameters. Because of the nature of the loss function, our algorithm is tolerant to label noise. Furthermore, unlike other algorithms which employ non-convex loss functions, our algorithm is fairly robust to the choice of initial values. We verify both these observations empirically on a number of synthetic and real datasets. 1</p><p>5 0.73285693 <a title="77-lda-5" href="./nips-2010-The_Neural_Costs_of_Optimal_Control.html">268 nips-2010-The Neural Costs of Optimal Control</a></p>
<p>Author: Samuel Gershman, Robert Wilson</p><p>Abstract: Optimal control entails combining probabilities and utilities. However, for most practical problems, probability densities can be represented only approximately. Choosing an approximation requires balancing the beneﬁts of an accurate approximation against the costs of computing it. We propose a variational framework for achieving this balance and apply it to the problem of how a neural population code should optimally represent a distribution under resource constraints. The essence of our analysis is the conjecture that population codes are organized to maximize a lower bound on the log expected utility. This theory can account for a plethora of experimental data, including the reward-modulation of sensory receptive ﬁelds, GABAergic effects on saccadic movements, and risk aversion in decisions under uncertainty. 1</p><p>6 0.72838831 <a title="77-lda-6" href="./nips-2010-Accounting_for_network_effects_in_neuronal_responses_using_L1_regularized_point_process_models.html">21 nips-2010-Accounting for network effects in neuronal responses using L1 regularized point process models</a></p>
<p>7 0.72605836 <a title="77-lda-7" href="./nips-2010-Functional_form_of_motion_priors_in_human_motion_perception.html">98 nips-2010-Functional form of motion priors in human motion perception</a></p>
<p>8 0.72562456 <a title="77-lda-8" href="./nips-2010-Linear_readout_from_a_neural_population_with_partial_correlation_data.html">161 nips-2010-Linear readout from a neural population with partial correlation data</a></p>
<p>9 0.72559202 <a title="77-lda-9" href="./nips-2010-Brain_covariance_selection%3A_better_individual_functional_connectivity_models_using_population_prior.html">44 nips-2010-Brain covariance selection: better individual functional connectivity models using population prior</a></p>
<p>10 0.72262138 <a title="77-lda-10" href="./nips-2010-A_biologically_plausible_network_for_the_computation_of_orientation_dominance.html">17 nips-2010-A biologically plausible network for the computation of orientation dominance</a></p>
<p>11 0.72072995 <a title="77-lda-11" href="./nips-2010-Online_Learning_for_Latent_Dirichlet_Allocation.html">194 nips-2010-Online Learning for Latent Dirichlet Allocation</a></p>
<p>12 0.72057575 <a title="77-lda-12" href="./nips-2010-A_Discriminative_Latent_Model_of_Image_Region_and_Object_Tag_Correspondence.html">6 nips-2010-A Discriminative Latent Model of Image Region and Object Tag Correspondence</a></p>
<p>13 0.71846354 <a title="77-lda-13" href="./nips-2010-Over-complete_representations_on_recurrent_neural_networks_can_support_persistent_percepts.html">200 nips-2010-Over-complete representations on recurrent neural networks can support persistent percepts</a></p>
<p>14 0.71769112 <a title="77-lda-14" href="./nips-2010-Learning_the_context_of_a_category.html">155 nips-2010-Learning the context of a category</a></p>
<p>15 0.71677518 <a title="77-lda-15" href="./nips-2010-Cross_Species_Expression_Analysis_using_a_Dirichlet_Process_Mixture_Model_with_Latent_Matchings.html">55 nips-2010-Cross Species Expression Analysis using a Dirichlet Process Mixture Model with Latent Matchings</a></p>
<p>16 0.71522278 <a title="77-lda-16" href="./nips-2010-Group_Sparse_Coding_with_a_Laplacian_Scale_Mixture_Prior.html">109 nips-2010-Group Sparse Coding with a Laplacian Scale Mixture Prior</a></p>
<p>17 0.71411133 <a title="77-lda-17" href="./nips-2010-A_unified_model_of_short-range_and_long-range_motion_perception.html">20 nips-2010-A unified model of short-range and long-range motion perception</a></p>
<p>18 0.71323168 <a title="77-lda-18" href="./nips-2010-Individualized_ROI_Optimization_via_Maximization_of_Group-wise_Consistency_of_Structural_and_Functional_Profiles.html">123 nips-2010-Individualized ROI Optimization via Maximization of Group-wise Consistency of Structural and Functional Profiles</a></p>
<p>19 0.71206987 <a title="77-lda-19" href="./nips-2010-Learning_concept_graphs_from_text_with_stick-breaking_priors.html">150 nips-2010-Learning concept graphs from text with stick-breaking priors</a></p>
<p>20 0.71137965 <a title="77-lda-20" href="./nips-2010-Two-Layer_Generalization_Analysis_for_Ranking_Using_Rademacher_Average.html">277 nips-2010-Two-Layer Generalization Analysis for Ranking Using Rademacher Average</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
