<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>98 nips-2010-Functional form of motion priors in human motion perception</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-98" href="#">nips2010-98</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>98 nips-2010-Functional form of motion priors in human motion perception</h1>
<br/><p>Source: <a title="nips-2010-98-pdf" href="http://papers.nips.cc/paper/3948-functional-form-of-motion-priors-in-human-motion-perception.pdf">pdf</a></p><p>Author: Hongjing Lu, Tungyou Lin, Alan Lee, Luminita Vese, Alan L. Yuille</p><p>Abstract: It has been speculated that the human motion system combines noisy measurements with prior expectations in an optimal, or rational, manner. The basic goal of our work is to discover experimentally which prior distribution is used. More speciﬁcally, we seek to infer the functional form of the motion prior from the performance of human subjects on motion estimation tasks. We restricted ourselves to priors which combine three terms for motion slowness, ﬁrst-order smoothness, and second-order smoothness. We focused on two functional forms for prior distributions: L2-norm and L1-norm regularization corresponding to the Gaussian and Laplace distributions respectively. In our ﬁrst experimental session we estimate the weights of the three terms for each functional form to maximize the ﬁt to human performance. We then measured human performance for motion tasks and found that we obtained better ﬁt for the L1-norm (Laplace) than for the L2-norm (Gaussian). We note that the L1-norm is also a better ﬁt to the statistics of motion in natural environments. In addition, we found large weights for the second-order smoothness term, indicating the importance of high-order smoothness compared to slowness and lower-order smoothness. To validate our results further, we used the best ﬁt models using the L1-norm to predict human performance in a second session with different experimental setups. Our results showed excellent agreement between human performance and model prediction – ranging from 3% to 8% for ﬁve human subjects over ten experimental conditions – and give further support that the human visual system uses an L1-norm (Laplace) prior.</p><p>Reference: <a title="nips-2010-98-reference" href="../nips2010_reference/nips-2010-Functional_form_of_motion_priors_in_human_motion_perception_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Functional form of motion priors in human motion perception  Hongjing Lu 1,2 hongjing@ucla. [sent-1, score-1.597]
</p><p>2 edu Department of Psychology1, Statistics2 , Mathematics3 and Computer Science4 , UCLA  Abstract It has been speculated that the human motion system combines noisy measurements with prior expectations in an optimal, or rational, manner. [sent-11, score-0.985]
</p><p>3 More speciﬁcally, we seek to infer the functional form of the motion prior from the performance of human subjects on motion estimation tasks. [sent-13, score-1.676]
</p><p>4 We restricted ourselves to priors which combine three terms for motion slowness, ﬁrst-order smoothness, and second-order smoothness. [sent-14, score-0.69]
</p><p>5 In our ﬁrst experimental session we estimate the weights of the three terms for each functional form to maximize the ﬁt to human performance. [sent-16, score-0.585]
</p><p>6 We then measured human performance for motion tasks and found that we obtained better ﬁt for the L1-norm (Laplace) than for the L2-norm (Gaussian). [sent-17, score-0.84]
</p><p>7 We note that the L1-norm is also a better ﬁt to the statistics of motion in natural environments. [sent-18, score-0.63]
</p><p>8 In addition, we found large weights for the second-order smoothness term, indicating the importance of high-order smoothness compared to slowness and lower-order smoothness. [sent-19, score-0.448]
</p><p>9 To validate our results further, we used the best ﬁt models using the L1-norm to predict human performance in a second session with different experimental setups. [sent-20, score-0.522]
</p><p>10 Our results showed excellent agreement between human performance and model prediction – ranging from 3% to 8% for ﬁve human subjects over ten experimental conditions – and give further support that the human visual system uses an L1-norm (Laplace) prior. [sent-21, score-0.893]
</p><p>11 Your visual system can readily perceive the walking person against the apparently moving background using only the motion signals visible through these holes. [sent-23, score-0.855]
</p><p>12 But this task is far from trivial due to the inherent local ambiguity of motion stimuli, often referred to as the aperture problem. [sent-24, score-0.709]
</p><p>13 More precisely, if you view a line segment through an aperture then you can easily estimate the motion component normal to the line but it is impossible to estimate the tangential component. [sent-25, score-0.678]
</p><p>14 So there are an inﬁnite number of possible interpretations of the local motion signal. [sent-26, score-0.661]
</p><p>15 One way to overcome this local ambiguity is to integrate local motion measurements across space to infer the ”true” motion ﬁeld. [sent-27, score-1.418]
</p><p>16 Then the visual system integrates these local motion measurements to form global motion perception [4, 5]. [sent-29, score-1.562]
</p><p>17 Psychophysicists have identiﬁed a variety of phenomena, such as motion capture and motion cooperativity, which appear to be consequences of motion spatial integration [1, 2, 3]. [sent-30, score-1.951]
</p><p>18 From the computational perspective, a number of Bayesian models have been proposed to explain these effects by hypothesizing prior assumptions about the motion ﬁelds that occur in natural environments. [sent-31, score-0.695]
</p><p>19 In particular, it has been shown that a prior which is biased to slow-and-smooth motion can account for a range of experimental results [6, 7, 8, 9, 10]. [sent-32, score-0.721]
</p><p>20 But although evidence from physiology and psychophysics supports the existence of an integration stage, it remains unclear exactly what motion priors are used to resolve the measurement ambiguities. [sent-33, score-0.73]
</p><p>21 In the walking example described above (see ﬁgure 1), the visual system needs to integrate the local measurements in the two regions within the red boxes in order to perceive a coherently moving background. [sent-34, score-0.35]
</p><p>22 Hence the motion priors used by the human visual system must have a functional form which enables ﬂexible and robust integration. [sent-36, score-1.069]
</p><p>23 We aim to determine the functional form of the motion priors which underly human perception, and to validate how well these priors can inﬂuence human perception in various motion tasks. [sent-37, score-1.927]
</p><p>24 Our approach is to combine parametric modeling of the motion priors with psychophysical experiments to estimate the model parameters that provide the best ﬁt to human performance across a range of stimulus conditions. [sent-38, score-1.041]
</p><p>25 The visual system needs to integrate motion measurements from the two regions in the red boxes in order to perceive the motion of the background. [sent-45, score-1.521]
</p><p>26 2 Functional form of motion priors Many models have proposed that the human visual system uses prior knowledge of probable motions, but the functional form for this prior remains unclear. [sent-49, score-1.199]
</p><p>27 For example, several well-established computational models employ Gaussian priors to encode the bias towards slow and spatially smooth motion ﬁelds. [sent-50, score-0.69]
</p><p>28 Researchers have used motion sequences in real scenes to measure the spatial and temporal statistics of motion ﬁelds [11, 12]. [sent-53, score-1.281]
</p><p>29 These natural statistics show that the magnitude of the motion (speed) falls off in a manner similar to a Laplacian distribution ( L1-norm regularization), which has heavier tails than Gaussian distributions (see the left plot in ﬁgure 2). [sent-54, score-0.727]
</p><p>30 A similar distribution pattern was also found for spatial derivatives of the motion ﬂow, showing that non-smooth motion ﬁelds can also happen in natural environments. [sent-56, score-1.281]
</p><p>31 This statistical ﬁnding is not surprising since motion discontinuities can arise in the natural environment due to the relative motion of objects, foreground/background segmentation, and occlusion. [sent-57, score-1.26]
</p><p>32 Stocker and Simoncelli [10] conducted a pioneering study to infer the functional form of the slowness motion prior. [sent-58, score-0.873]
</p><p>33 More speciﬁcally, they used human subject responses in a speed discrimination task to infer the shape of the slowness prior distribution. [sent-59, score-0.483]
</p><p>34 They showed that a motion model using this inferred prior provided an adequate ﬁt to human data for a wide range of stimuli. [sent-61, score-0.93]
</p><p>35 We illustrate this for motion estimation by the example in the right panel of ﬁgure 2. [sent-69, score-0.652]
</p><p>36 If there is a motion boundary in the true motion ﬁeld, then a model using L2-norm regularization (Gaussian priors) tends to impose strong smoothing over the two distinct motion ﬁelds which blurs the motion across discontinuity. [sent-70, score-2.575]
</p><p>37 But the model with an L1-norm (Laplace prior) preserves the motion discontinuity and gives smooth motion ﬂow on both sides of it. [sent-71, score-1.285]
</p><p>38 3 Mathematical Model The input data is speciﬁed by local motion measurements rq , of form uq = (u1 q , u2 q ), at a discrete set of positions rq , q = 1, . [sent-74, score-1.052]
</p><p>39 The goal is to ﬁnd a smooth motion ﬁeld v deﬁned at all positions r in the image domain, estimated from the local motion measurements. [sent-78, score-1.291]
</p><p>40 The motion ﬁeld v can be thought of as an interpolation of the data which obeys a slowness and smoothness prior and which agrees approximately with the local motion measurements. [sent-79, score-1.649]
</p><p>41 Recall that u the visual system can only observe the local motion in the directions nq = |uq | (sometimes called q component motion) because of the aperture problem. [sent-80, score-0.964]
</p><p>42 Hence approximate agreement with local measurements reduces to the constraints: v(rq ) · nq − uq · nq ≈ 0. [sent-81, score-0.419]
</p><p>43 As illustrated in ﬁgure 3, we consider three motion prior terms which quantify the preference for slowness, ﬁrst-order smoothness and second-order smoothness respectively. [sent-82, score-0.959]
</p><p>44 More precisely, we initialize ∂t ∂v(r,t) v(r, 0) at random, and solve the update equation for t > 0: ∂vk (r, t) ∂t  = −λ|v|α−2 vk + µdiv | v|β−2 vk − η  | v|γ−2 vk  p−1  − c v(rq ) · nq − uq · nq  nk q δr,rq ,  where k = 1, 2, δr,rq = 1 if r = rq and δr,rq = 0 if r = rq . [sent-97, score-1.641]
</p><p>45 4 Experiments We compared two possible functional forms for the motion prior: (1) the Laplace distribution with L1-norm regularization, with α = β = γ = 1, (2) the Gaussian distribution with L2-norm regularization, with α = β = γ = 2. [sent-110, score-0.69]
</p><p>46 Since the main goal of this work is to discover motion priors, we employed the same likelihood term with p = 2 for both models. [sent-111, score-0.63]
</p><p>47 We used the performance of human subjects in the ﬁrst experimental session to estimate the weights of the three prior terms, λ, µ, η, for each functional form. [sent-112, score-0.709]
</p><p>48 We then validated the predictions of the model by comparing them with human performance in a second experimental session which uses different stimulus parameters. [sent-113, score-0.646]
</p><p>49 The motion stimulus included 20 time frames which were presented within 267 ms. [sent-121, score-0.712]
</p><p>50 Second, a global motion (also called 2D motion, with the speed of 1 deg/sec) direction was chosen. [sent-124, score-0.698]
</p><p>51 Third, a certain proportion of elements (signal elements) were assigned with the predetermined 2D motion , while each of the remaining elements (noise elements) was assigned a random 2D motion. [sent-125, score-0.678]
</p><p>52 Finally, with its orientation and 2D motion velocity, the drifting speed for each element was computed so that the local (or component) drifting velocity was consistent with the assigned 2D motion velocity. [sent-126, score-1.39]
</p><p>53 As shown in ﬁgure 4 the global motion strength was controlled by varying the proportion of signal elements in the stimulus (i. [sent-127, score-0.779]
</p><p>54 The goal of session 1 was parameter estimation: to estimate the weights of the three prior terms – slowness, ﬁrst-order smoothness and second-order smoothness, – for each model. [sent-132, score-0.486]
</p><p>55 Session 2 was for model validation: using the weights estimated from session 1 to predict subject performance for different experimental conditions. [sent-133, score-0.36]
</p><p>56 the blue and green arrows indicate the 2D motion directions assigned for signal and noise elements, respectively. [sent-138, score-0.738]
</p><p>57 On each trial of the ﬁrst session, observers were presented with two motion patterns, one after another. [sent-143, score-0.805]
</p><p>58 The ﬁrst one was the reference motion pattern, which always moved upward (0 degree), and the second one was the test motion pattern, whose global motion direction was either tilted towards the left or the right relative to the reference pattern. [sent-144, score-2.025]
</p><p>59 The observer’s task was to determine whether the global motion direction of the test pattern was more towards the left or right relative to the reference pattern. [sent-146, score-0.719]
</p><p>60 In order to make sure observers understood the task and were able to perceive the global motion, before the beginning of the ﬁrst session, observers passed a test session in which they achieved 90% accuracy in 40 consecutive trials with 80% coherence and 20 (or 45) degrees of angular difference. [sent-147, score-0.996]
</p><p>61 To allow observers to familiarize themselves with the task, before each experimental session observers went through a practice session with 10 blocks of 25 trials. [sent-148, score-0.937]
</p><p>62 The angular difference between the reference and test motion was ﬁxed for each observer in the entire session (2 degrees for observers AL, MW and AE; 45 degrees for OQ and CC). [sent-157, score-1.372]
</p><p>63 The second session was identical to the ﬁrst one, except that the coherence ratio was ﬁxed at 0. [sent-158, score-0.5]
</p><p>64 7, and the angular difference between the global motion directions of the reference and the test patterns was varied across blocks (ten angular differences: 1, 5, 10, . [sent-159, score-0.983]
</p><p>65 2 Results We implemented motion models with the Laplace prior distribution (termed ”L1 model”) and the Gaussian prior (termed ”L2 model”). [sent-164, score-0.76]
</p><p>66 As the ﬁrst step, exhaustive search was conducted to ﬁnd a set of weights for the prior terms that provided the best ﬁt to the human psychometric performance in experimental session 1. [sent-165, score-0.59]
</p><p>67 However, across all ﬁve subjects, large weight values were found for the second-order smoothness terms, indicating the contribution from higher-order smoothness preference is important in perceiving global motion from multiple-aperture stimulus. [sent-168, score-0.937]
</p><p>68 In general,humans appear to be sensitive to the inclusion of noise elements, and perform 6  Table 1: Estimated weights λ, µ, η of slowness, ﬁrst-order smoothness and second-order smoothness prior terms, for L1 and L2-norm model Subjects  L1 λ  L1 µ  L1 η  L2 λ  L2 µ  L2 η  AE AL CC MW OQ  0. [sent-171, score-0.377]
</p><p>69 In experimental session 2, the two models predicted performance as a function of angular difference between the reference motion and the test motion. [sent-184, score-1.079]
</p><p>70 This result illustrates the power of the L1 model in predicting human performance in motion tasks different from the tasks used for estimating model parameters. [sent-186, score-0.89]
</p><p>71 08  0  Coherence ratio  AL  AE  CC  MW  OQ  Figure 5: Comparison between human performance and model predictions in session 1. [sent-226, score-0.594]
</p><p>72 05  45  0  AL  AE  CC  MW  OQ  Figure 6: Comparison between human performance and model predictions in session 1. [sent-248, score-0.538]
</p><p>73 Left two plots, accuracy as a function of angular difference between the reference and the test motion for two representative subjects. [sent-249, score-0.787]
</p><p>74 Less errors from L1 model indicate that L1 model consistently ﬁts human performance better than L2 model for all subjects 4. [sent-253, score-0.366]
</p><p>75 3 Experiment 2 The results of Experiment 1 clearly support the conclusion that the motion model with Laplace prior (L1-norm regularization) ﬁts human performance better than does the model with Gaussian prior 7  (L2 model). [sent-254, score-1.02]
</p><p>76 In Experiment 2, we compared human motion judgment with predictions of the L1 model on each trial, rather than using the average performance as in Experiment 1. [sent-255, score-0.952]
</p><p>77 Such a detailed comparison can provide quantitative measures of how well the L1 model is able to predict human motion judgment for speciﬁc stimuli. [sent-256, score-0.935]
</p><p>78 In Experiment 2, the ﬁrst session was identical to that in Experiment 1, in which angular difference in the two global motion directions were ﬁxed (45 degrees for all observers) while the coherence ratio was varied. [sent-257, score-1.352]
</p><p>79 In the second session, observers were presented with one motion stimulus on each trial. [sent-258, score-0.887]
</p><p>80 The global motion direction of the pattern was randomly selected from 24 possible directions (with a 15-degree difference between two adjacent directions). [sent-259, score-0.73]
</p><p>81 Observers reported their perceived global motion directions by rotating a line after the motion stimulus disappeared from the screen. [sent-260, score-1.42]
</p><p>82 A two-pass design was used to let each observer run the identical session twice in order to measure the reliability of the observer’s judgments. [sent-267, score-0.39]
</p><p>83 We used human performance in session 1 to estimate model parameters: weights λ, µ, η for slowness, ﬁrst-order smoothness and second-order smoothness prior terms for each individual participant. [sent-268, score-0.853]
</p><p>84 Since identical stimuli were used in the two runs of session 2, we can quantify the reliability of the observer’s judgment by computing the response correlation across trials in these two runs. [sent-269, score-0.478]
</p><p>85 As shown in the left plot of ﬁgure 7, human observers’ responses were signiﬁcantly correlated in the two runs, even in the condition of random motion (coherence ratio is close to 0). [sent-270, score-0.935]
</p><p>86 The correlated responses in these subthreshold conditions suggest that human observers are able to provide consistent interpretation of motion ﬂow, even when the motion is random. [sent-271, score-1.645]
</p><p>87 The right plot of ﬁgure 7 shows the trial-by-trial correlation between human motion judgments with model-predicted global motion direction. [sent-272, score-1.622]
</p><p>88 Even in the random motion condition (where the coherence ratio is 0), the correlation between the model and human judgments is greater than 0. [sent-274, score-1.148]
</p><p>89 We also noticed that the correlation between human and L2 model was around 8 percent worse than the human self-correlation and the correlation between the L1 model and humans. [sent-276, score-0.562]
</p><p>90 9  Coherence ratio  Coherence ratio  Figure 7: Comparison between human performance and model predictions using trial-by-trial correlation. [sent-312, score-0.384]
</p><p>91 Left plot, human self correlation between two runs of identical experimental sessions. [sent-313, score-0.325]
</p><p>92 Right plot, correlation between human motion judgement and model predicted global motion direction. [sent-314, score-1.584]
</p><p>93 The signiﬁcant correlation between human and the model indicates the L1 model is able to predict human motion judgment for speciﬁc stimuli, even in the random display, i. [sent-315, score-1.216]
</p><p>94 5 Conclusions We found that a motion prior in the form of the Laplace distribution with L1-norm regularization provided signiﬁcantly better agreement with human performance than did Gaussian priors with L2norm. [sent-318, score-1.018]
</p><p>95 We also showed that humans weighted second-order motion smoothness much higher than ﬁrst-order smoothness and slowness. [sent-319, score-0.894]
</p><p>96 Furthermore, model predictions using this Laplace prior were consistent with human perception of coherent motion, even for random displays. [sent-320, score-0.43]
</p><p>97 Overall our results suggest that human motion perception for these types of stimuli can be well modeled using Laplace priors. [sent-321, score-0.977]
</p><p>98 How MT cells analyze the motion of visual patterns. [sent-368, score-0.711]
</p><p>99 Noise characteristics and prior expectations in human visual speed perception. [sent-411, score-0.381]
</p><p>100 Adaptive pooling of visual motion signals by the human visual system revealed with a novel multi-element stimulus. [sent-434, score-1.03]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('motion', 0.63), ('vk', 0.36), ('session', 0.266), ('human', 0.21), ('observers', 0.175), ('slowness', 0.161), ('coherence', 0.157), ('smoothness', 0.132), ('ci', 0.128), ('rq', 0.124), ('nq', 0.111), ('laplace', 0.098), ('uq', 0.091), ('angular', 0.089), ('ae', 0.088), ('stimulus', 0.082), ('visual', 0.081), ('observer', 0.078), ('walker', 0.073), ('oq', 0.072), ('cc', 0.071), ('stimuli', 0.07), ('perception', 0.067), ('prior', 0.065), ('priors', 0.06), ('functional', 0.06), ('subjects', 0.059), ('perceive', 0.058), ('ratio', 0.056), ('mw', 0.055), ('idk', 0.054), ('measurements', 0.052), ('judgment', 0.05), ('aperture', 0.048), ('yuille', 0.048), ('correlation', 0.046), ('reference', 0.046), ('global', 0.043), ('integration', 0.04), ('intercept', 0.039), ('plot', 0.039), ('drifting', 0.037), ('predictions', 0.037), ('punch', 0.036), ('grating', 0.036), ('directions', 0.035), ('moving', 0.035), ('psychophysical', 0.034), ('simoncelli', 0.034), ('degrees', 0.033), ('tails', 0.033), ('motions', 0.032), ('gure', 0.032), ('energy', 0.032), ('hongjing', 0.032), ('local', 0.031), ('regularization', 0.03), ('ms', 0.03), ('al', 0.03), ('experiment', 0.03), ('blocks', 0.029), ('neuroscience', 0.029), ('stocker', 0.029), ('pdes', 0.029), ('system', 0.028), ('sessions', 0.027), ('equations', 0.026), ('coherent', 0.026), ('experimental', 0.026), ('gaussian', 0.026), ('blue', 0.026), ('exponents', 0.026), ('green', 0.025), ('model', 0.025), ('speed', 0.025), ('reliability', 0.025), ('heavier', 0.025), ('participant', 0.025), ('sg', 0.025), ('elements', 0.024), ('bi', 0.024), ('judgments', 0.024), ('exhibited', 0.024), ('agreement', 0.023), ('weights', 0.023), ('walking', 0.023), ('panel', 0.022), ('difference', 0.022), ('discretization', 0.022), ('self', 0.022), ('indicate', 0.022), ('integrate', 0.022), ('infer', 0.022), ('ow', 0.021), ('spatial', 0.021), ('identical', 0.021), ('ten', 0.021), ('predict', 0.02), ('boxes', 0.02), ('lu', 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="98-tfidf-1" href="./nips-2010-Functional_form_of_motion_priors_in_human_motion_perception.html">98 nips-2010-Functional form of motion priors in human motion perception</a></p>
<p>Author: Hongjing Lu, Tungyou Lin, Alan Lee, Luminita Vese, Alan L. Yuille</p><p>Abstract: It has been speculated that the human motion system combines noisy measurements with prior expectations in an optimal, or rational, manner. The basic goal of our work is to discover experimentally which prior distribution is used. More speciﬁcally, we seek to infer the functional form of the motion prior from the performance of human subjects on motion estimation tasks. We restricted ourselves to priors which combine three terms for motion slowness, ﬁrst-order smoothness, and second-order smoothness. We focused on two functional forms for prior distributions: L2-norm and L1-norm regularization corresponding to the Gaussian and Laplace distributions respectively. In our ﬁrst experimental session we estimate the weights of the three terms for each functional form to maximize the ﬁt to human performance. We then measured human performance for motion tasks and found that we obtained better ﬁt for the L1-norm (Laplace) than for the L2-norm (Gaussian). We note that the L1-norm is also a better ﬁt to the statistics of motion in natural environments. In addition, we found large weights for the second-order smoothness term, indicating the importance of high-order smoothness compared to slowness and lower-order smoothness. To validate our results further, we used the best ﬁt models using the L1-norm to predict human performance in a second session with different experimental setups. Our results showed excellent agreement between human performance and model prediction – ranging from 3% to 8% for ﬁve human subjects over ten experimental conditions – and give further support that the human visual system uses an L1-norm (Laplace) prior.</p><p>2 0.5753926 <a title="98-tfidf-2" href="./nips-2010-A_unified_model_of_short-range_and_long-range_motion_perception.html">20 nips-2010-A unified model of short-range and long-range motion perception</a></p>
<p>Author: Shuang Wu, Xuming He, Hongjing Lu, Alan L. Yuille</p><p>Abstract: The human vision system is able to effortlessly perceive both short-range and long-range motion patterns in complex dynamic scenes. Previous work has assumed that two different mechanisms are involved in processing these two types of motion. In this paper, we propose a hierarchical model as a uniﬁed framework for modeling both short-range and long-range motion perception. Our model consists of two key components: a data likelihood that proposes multiple motion hypotheses using nonlinear matching, and a hierarchical prior that imposes slowness and spatial smoothness constraints on the motion ﬁeld at multiple scales. We tested our model on two types of stimuli, random dot kinematograms and multiple-aperture stimuli, both commonly used in human vision research. We demonstrate that the hierarchical model adequately accounts for human performance in psychophysical experiments.</p><p>3 0.21113299 <a title="98-tfidf-3" href="./nips-2010-Occlusion_Detection_and_Motion_Estimation_with_Convex_Optimization.html">187 nips-2010-Occlusion Detection and Motion Estimation with Convex Optimization</a></p>
<p>Author: Alper Ayvaci, Michalis Raptis, Stefano Soatto</p><p>Abstract: We tackle the problem of simultaneously detecting occlusions and estimating optical ﬂow. We show that, under standard assumptions of Lambertian reﬂection and static illumination, the task can be posed as a convex minimization problem. Therefore, the solution, computed using efﬁcient algorithms, is guaranteed to be globally optimal, for any number of independently moving objects, and any number of occlusion layers. We test the proposed algorithm on benchmark datasets, expanded to enable evaluation of occlusion detection performance. 1</p><p>4 0.19877 <a title="98-tfidf-4" href="./nips-2010-Random_Projections_for_%24k%24-means_Clustering.html">221 nips-2010-Random Projections for $k$-means Clustering</a></p>
<p>Author: Christos Boutsidis, Anastasios Zouzias, Petros Drineas</p><p>Abstract: This paper discusses the topic of dimensionality reduction for k-means clustering. We prove that any set of n points in d dimensions (rows in a matrix A ∈ Rn×d ) can be projected into t = Ω(k/ε2 ) dimensions, for any ε ∈ (0, 1/3), in O(nd⌈ε−2 k/ log(d)⌉) time, such that with constant probability the optimal k-partition of the point set is preserved within a factor of 2 + √ The projection is done ε. √ by post-multiplying A with a d × t random matrix R having entries +1/ t or −1/ t with equal probability. A numerical implementation of our technique and experiments on a large face images dataset verify the speed and the accuracy of our theoretical results.</p><p>5 0.17819068 <a title="98-tfidf-5" href="./nips-2010-Layered_image_motion_with_explicit_occlusions%2C_temporal_consistency%2C_and_depth_ordering.html">141 nips-2010-Layered image motion with explicit occlusions, temporal consistency, and depth ordering</a></p>
<p>Author: Deqing Sun, Erik B. Sudderth, Michael J. Black</p><p>Abstract: Layered models are a powerful way of describing natural scenes containing smooth surfaces that may overlap and occlude each other. For image motion estimation, such models have a long history but have not achieved the wide use or accuracy of non-layered methods. We present a new probabilistic model of optical ﬂow in layers that addresses many of the shortcomings of previous approaches. In particular, we deﬁne a probabilistic graphical model that explicitly captures: 1) occlusions and disocclusions; 2) depth ordering of the layers; 3) temporal consistency of the layer segmentation. Additionally the optical ﬂow in each layer is modeled by a combination of a parametric model and a smooth deviation based on an MRF with a robust spatial prior; the resulting model allows roughness in layers. Finally, a key contribution is the formulation of the layers using an imagedependent hidden ﬁeld prior based on recent models for static scene segmentation. The method achieves state-of-the-art results on the Middlebury benchmark and produces meaningful scene segmentations as well as detected occlusion regions.</p><p>6 0.10892656 <a title="98-tfidf-6" href="./nips-2010-Structured_Determinantal_Point_Processes.html">257 nips-2010-Structured Determinantal Point Processes</a></p>
<p>7 0.10041041 <a title="98-tfidf-7" href="./nips-2010-Sparse_Coding_for_Learning_Interpretable_Spatio-Temporal_Primitives.html">246 nips-2010-Sparse Coding for Learning Interpretable Spatio-Temporal Primitives</a></p>
<p>8 0.094284706 <a title="98-tfidf-8" href="./nips-2010-Error_Propagation_for_Approximate_Policy_and_Value_Iteration.html">78 nips-2010-Error Propagation for Approximate Policy and Value Iteration</a></p>
<p>9 0.088814303 <a title="98-tfidf-9" href="./nips-2010-Brain_covariance_selection%3A_better_individual_functional_connectivity_models_using_population_prior.html">44 nips-2010-Brain covariance selection: better individual functional connectivity models using population prior</a></p>
<p>10 0.078025699 <a title="98-tfidf-10" href="./nips-2010-Robust_Clustering_as_Ensembles_of_Affinity_Relations.html">230 nips-2010-Robust Clustering as Ensembles of Affinity Relations</a></p>
<p>11 0.077793278 <a title="98-tfidf-11" href="./nips-2010-Infinite_Relational_Modeling_of_Functional_Connectivity_in_Resting_State_fMRI.html">128 nips-2010-Infinite Relational Modeling of Functional Connectivity in Resting State fMRI</a></p>
<p>12 0.073233217 <a title="98-tfidf-12" href="./nips-2010-Fast_global_convergence_rates_of_gradient_methods_for_high-dimensional_statistical_recovery.html">92 nips-2010-Fast global convergence rates of gradient methods for high-dimensional statistical recovery</a></p>
<p>13 0.070328057 <a title="98-tfidf-13" href="./nips-2010-Implicit_encoding_of_prior_probabilities_in_optimal_neural_populations.html">119 nips-2010-Implicit encoding of prior probabilities in optimal neural populations</a></p>
<p>14 0.0688117 <a title="98-tfidf-14" href="./nips-2010-Mixture_of_time-warped_trajectory_models_for_movement_decoding.html">167 nips-2010-Mixture of time-warped trajectory models for movement decoding</a></p>
<p>15 0.066100322 <a title="98-tfidf-15" href="./nips-2010-Cross_Species_Expression_Analysis_using_a_Dirichlet_Process_Mixture_Model_with_Latent_Matchings.html">55 nips-2010-Cross Species Expression Analysis using a Dirichlet Process Mixture Model with Latent Matchings</a></p>
<p>16 0.065503433 <a title="98-tfidf-16" href="./nips-2010-Linear_readout_from_a_neural_population_with_partial_correlation_data.html">161 nips-2010-Linear readout from a neural population with partial correlation data</a></p>
<p>17 0.061079767 <a title="98-tfidf-17" href="./nips-2010-Space-Variant_Single-Image_Blind_Deconvolution_for_Removing_Camera_Shake.html">245 nips-2010-Space-Variant Single-Image Blind Deconvolution for Removing Camera Shake</a></p>
<p>18 0.060644872 <a title="98-tfidf-18" href="./nips-2010-Natural_Policy_Gradient_Methods_with_Parameter-based_Exploration_for_Control_Tasks.html">179 nips-2010-Natural Policy Gradient Methods with Parameter-based Exploration for Control Tasks</a></p>
<p>19 0.056775067 <a title="98-tfidf-19" href="./nips-2010-Accounting_for_network_effects_in_neuronal_responses_using_L1_regularized_point_process_models.html">21 nips-2010-Accounting for network effects in neuronal responses using L1 regularized point process models</a></p>
<p>20 0.056454021 <a title="98-tfidf-20" href="./nips-2010-Feature_Transitions_with_Saccadic_Search%3A_Size%2C_Color%2C_and_Orientation_Are_Not_Alike.html">95 nips-2010-Feature Transitions with Saccadic Search: Size, Color, and Orientation Are Not Alike</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.16), (1, 0.038), (2, -0.186), (3, 0.076), (4, -0.008), (5, -0.173), (6, -0.041), (7, 0.019), (8, 0.011), (9, 0.014), (10, 0.155), (11, -0.475), (12, -0.096), (13, 0.197), (14, 0.204), (15, 0.24), (16, -0.204), (17, 0.138), (18, -0.015), (19, 0.012), (20, -0.133), (21, -0.093), (22, 0.0), (23, -0.059), (24, -0.024), (25, 0.05), (26, 0.043), (27, -0.045), (28, 0.042), (29, -0.057), (30, 0.033), (31, -0.056), (32, -0.08), (33, 0.091), (34, 0.171), (35, -0.026), (36, 0.046), (37, 0.008), (38, -0.031), (39, -0.09), (40, -0.015), (41, -0.005), (42, 0.122), (43, 0.057), (44, 0.034), (45, 0.026), (46, 0.028), (47, 0.081), (48, -0.038), (49, -0.039)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99005187 <a title="98-lsi-1" href="./nips-2010-Functional_form_of_motion_priors_in_human_motion_perception.html">98 nips-2010-Functional form of motion priors in human motion perception</a></p>
<p>Author: Hongjing Lu, Tungyou Lin, Alan Lee, Luminita Vese, Alan L. Yuille</p><p>Abstract: It has been speculated that the human motion system combines noisy measurements with prior expectations in an optimal, or rational, manner. The basic goal of our work is to discover experimentally which prior distribution is used. More speciﬁcally, we seek to infer the functional form of the motion prior from the performance of human subjects on motion estimation tasks. We restricted ourselves to priors which combine three terms for motion slowness, ﬁrst-order smoothness, and second-order smoothness. We focused on two functional forms for prior distributions: L2-norm and L1-norm regularization corresponding to the Gaussian and Laplace distributions respectively. In our ﬁrst experimental session we estimate the weights of the three terms for each functional form to maximize the ﬁt to human performance. We then measured human performance for motion tasks and found that we obtained better ﬁt for the L1-norm (Laplace) than for the L2-norm (Gaussian). We note that the L1-norm is also a better ﬁt to the statistics of motion in natural environments. In addition, we found large weights for the second-order smoothness term, indicating the importance of high-order smoothness compared to slowness and lower-order smoothness. To validate our results further, we used the best ﬁt models using the L1-norm to predict human performance in a second session with different experimental setups. Our results showed excellent agreement between human performance and model prediction – ranging from 3% to 8% for ﬁve human subjects over ten experimental conditions – and give further support that the human visual system uses an L1-norm (Laplace) prior.</p><p>2 0.9498632 <a title="98-lsi-2" href="./nips-2010-A_unified_model_of_short-range_and_long-range_motion_perception.html">20 nips-2010-A unified model of short-range and long-range motion perception</a></p>
<p>Author: Shuang Wu, Xuming He, Hongjing Lu, Alan L. Yuille</p><p>Abstract: The human vision system is able to effortlessly perceive both short-range and long-range motion patterns in complex dynamic scenes. Previous work has assumed that two different mechanisms are involved in processing these two types of motion. In this paper, we propose a hierarchical model as a uniﬁed framework for modeling both short-range and long-range motion perception. Our model consists of two key components: a data likelihood that proposes multiple motion hypotheses using nonlinear matching, and a hierarchical prior that imposes slowness and spatial smoothness constraints on the motion ﬁeld at multiple scales. We tested our model on two types of stimuli, random dot kinematograms and multiple-aperture stimuli, both commonly used in human vision research. We demonstrate that the hierarchical model adequately accounts for human performance in psychophysical experiments.</p><p>3 0.64416111 <a title="98-lsi-3" href="./nips-2010-Occlusion_Detection_and_Motion_Estimation_with_Convex_Optimization.html">187 nips-2010-Occlusion Detection and Motion Estimation with Convex Optimization</a></p>
<p>Author: Alper Ayvaci, Michalis Raptis, Stefano Soatto</p><p>Abstract: We tackle the problem of simultaneously detecting occlusions and estimating optical ﬂow. We show that, under standard assumptions of Lambertian reﬂection and static illumination, the task can be posed as a convex minimization problem. Therefore, the solution, computed using efﬁcient algorithms, is guaranteed to be globally optimal, for any number of independently moving objects, and any number of occlusion layers. We test the proposed algorithm on benchmark datasets, expanded to enable evaluation of occlusion detection performance. 1</p><p>4 0.53595227 <a title="98-lsi-4" href="./nips-2010-Layered_image_motion_with_explicit_occlusions%2C_temporal_consistency%2C_and_depth_ordering.html">141 nips-2010-Layered image motion with explicit occlusions, temporal consistency, and depth ordering</a></p>
<p>Author: Deqing Sun, Erik B. Sudderth, Michael J. Black</p><p>Abstract: Layered models are a powerful way of describing natural scenes containing smooth surfaces that may overlap and occlude each other. For image motion estimation, such models have a long history but have not achieved the wide use or accuracy of non-layered methods. We present a new probabilistic model of optical ﬂow in layers that addresses many of the shortcomings of previous approaches. In particular, we deﬁne a probabilistic graphical model that explicitly captures: 1) occlusions and disocclusions; 2) depth ordering of the layers; 3) temporal consistency of the layer segmentation. Additionally the optical ﬂow in each layer is modeled by a combination of a parametric model and a smooth deviation based on an MRF with a robust spatial prior; the resulting model allows roughness in layers. Finally, a key contribution is the formulation of the layers using an imagedependent hidden ﬁeld prior based on recent models for static scene segmentation. The method achieves state-of-the-art results on the Middlebury benchmark and produces meaningful scene segmentations as well as detected occlusion regions.</p><p>5 0.36043057 <a title="98-lsi-5" href="./nips-2010-Random_Projections_for_%24k%24-means_Clustering.html">221 nips-2010-Random Projections for $k$-means Clustering</a></p>
<p>Author: Christos Boutsidis, Anastasios Zouzias, Petros Drineas</p><p>Abstract: This paper discusses the topic of dimensionality reduction for k-means clustering. We prove that any set of n points in d dimensions (rows in a matrix A ∈ Rn×d ) can be projected into t = Ω(k/ε2 ) dimensions, for any ε ∈ (0, 1/3), in O(nd⌈ε−2 k/ log(d)⌉) time, such that with constant probability the optimal k-partition of the point set is preserved within a factor of 2 + √ The projection is done ε. √ by post-multiplying A with a d × t random matrix R having entries +1/ t or −1/ t with equal probability. A numerical implementation of our technique and experiments on a large face images dataset verify the speed and the accuracy of our theoretical results.</p><p>6 0.35506657 <a title="98-lsi-6" href="./nips-2010-Space-Variant_Single-Image_Blind_Deconvolution_for_Removing_Camera_Shake.html">245 nips-2010-Space-Variant Single-Image Blind Deconvolution for Removing Camera Shake</a></p>
<p>7 0.35397214 <a title="98-lsi-7" href="./nips-2010-Probabilistic_Belief_Revision_with_Structural_Constraints.html">214 nips-2010-Probabilistic Belief Revision with Structural Constraints</a></p>
<p>8 0.3379674 <a title="98-lsi-8" href="./nips-2010-Sparse_Coding_for_Learning_Interpretable_Spatio-Temporal_Primitives.html">246 nips-2010-Sparse Coding for Learning Interpretable Spatio-Temporal Primitives</a></p>
<p>9 0.32850391 <a title="98-lsi-9" href="./nips-2010-A_Bayesian_Framework_for_Figure-Ground_Interpretation.html">3 nips-2010-A Bayesian Framework for Figure-Ground Interpretation</a></p>
<p>10 0.28340352 <a title="98-lsi-10" href="./nips-2010-Structured_Determinantal_Point_Processes.html">257 nips-2010-Structured Determinantal Point Processes</a></p>
<p>11 0.26925743 <a title="98-lsi-11" href="./nips-2010-Improving_Human_Judgments_by_Decontaminating_Sequential_Dependencies.html">121 nips-2010-Improving Human Judgments by Decontaminating Sequential Dependencies</a></p>
<p>12 0.25755322 <a title="98-lsi-12" href="./nips-2010-CUR_from_a_Sparse_Optimization_Viewpoint.html">45 nips-2010-CUR from a Sparse Optimization Viewpoint</a></p>
<p>13 0.25051689 <a title="98-lsi-13" href="./nips-2010-Feature_Transitions_with_Saccadic_Search%3A_Size%2C_Color%2C_and_Orientation_Are_Not_Alike.html">95 nips-2010-Feature Transitions with Saccadic Search: Size, Color, and Orientation Are Not Alike</a></p>
<p>14 0.24960558 <a title="98-lsi-14" href="./nips-2010-Mixture_of_time-warped_trajectory_models_for_movement_decoding.html">167 nips-2010-Mixture of time-warped trajectory models for movement decoding</a></p>
<p>15 0.21799572 <a title="98-lsi-15" href="./nips-2010-Cross_Species_Expression_Analysis_using_a_Dirichlet_Process_Mixture_Model_with_Latent_Matchings.html">55 nips-2010-Cross Species Expression Analysis using a Dirichlet Process Mixture Model with Latent Matchings</a></p>
<p>16 0.20940378 <a title="98-lsi-16" href="./nips-2010-Switched_Latent_Force_Models_for_Movement_Segmentation.html">262 nips-2010-Switched Latent Force Models for Movement Segmentation</a></p>
<p>17 0.20476377 <a title="98-lsi-17" href="./nips-2010-Evaluating_neuronal_codes_for_inference_using_Fisher_information.html">81 nips-2010-Evaluating neuronal codes for inference using Fisher information</a></p>
<p>18 0.20442872 <a title="98-lsi-18" href="./nips-2010-Movement_extraction_by_detecting_dynamics_switches_and_repetitions.html">171 nips-2010-Movement extraction by detecting dynamics switches and repetitions</a></p>
<p>19 0.20133977 <a title="98-lsi-19" href="./nips-2010-Linear_readout_from_a_neural_population_with_partial_correlation_data.html">161 nips-2010-Linear readout from a neural population with partial correlation data</a></p>
<p>20 0.19887453 <a title="98-lsi-20" href="./nips-2010-Brain_covariance_selection%3A_better_individual_functional_connectivity_models_using_population_prior.html">44 nips-2010-Brain covariance selection: better individual functional connectivity models using population prior</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.012), (13, 0.06), (27, 0.19), (30, 0.044), (35, 0.014), (43, 0.064), (45, 0.203), (50, 0.068), (52, 0.035), (60, 0.019), (75, 0.074), (77, 0.06), (78, 0.015), (90, 0.034)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93584919 <a title="98-lda-1" href="./nips-2010-Functional_form_of_motion_priors_in_human_motion_perception.html">98 nips-2010-Functional form of motion priors in human motion perception</a></p>
<p>Author: Hongjing Lu, Tungyou Lin, Alan Lee, Luminita Vese, Alan L. Yuille</p><p>Abstract: It has been speculated that the human motion system combines noisy measurements with prior expectations in an optimal, or rational, manner. The basic goal of our work is to discover experimentally which prior distribution is used. More speciﬁcally, we seek to infer the functional form of the motion prior from the performance of human subjects on motion estimation tasks. We restricted ourselves to priors which combine three terms for motion slowness, ﬁrst-order smoothness, and second-order smoothness. We focused on two functional forms for prior distributions: L2-norm and L1-norm regularization corresponding to the Gaussian and Laplace distributions respectively. In our ﬁrst experimental session we estimate the weights of the three terms for each functional form to maximize the ﬁt to human performance. We then measured human performance for motion tasks and found that we obtained better ﬁt for the L1-norm (Laplace) than for the L2-norm (Gaussian). We note that the L1-norm is also a better ﬁt to the statistics of motion in natural environments. In addition, we found large weights for the second-order smoothness term, indicating the importance of high-order smoothness compared to slowness and lower-order smoothness. To validate our results further, we used the best ﬁt models using the L1-norm to predict human performance in a second session with different experimental setups. Our results showed excellent agreement between human performance and model prediction – ranging from 3% to 8% for ﬁve human subjects over ten experimental conditions – and give further support that the human visual system uses an L1-norm (Laplace) prior.</p><p>2 0.93308604 <a title="98-lda-2" href="./nips-2010-Linear_readout_from_a_neural_population_with_partial_correlation_data.html">161 nips-2010-Linear readout from a neural population with partial correlation data</a></p>
<p>Author: Adrien Wohrer, Ranulfo Romo, Christian K. Machens</p><p>Abstract: How much information does a neural population convey about a stimulus? Answers to this question are known to strongly depend on the correlation of response variability in neural populations. These noise correlations, however, are essentially immeasurable as the number of parameters in a noise correlation matrix grows quadratically with population size. Here, we suggest to bypass this problem by imposing a parametric model on a noise correlation matrix. Our basic assumption is that noise correlations arise due to common inputs between neurons. On average, noise correlations will therefore reﬂect signal correlations, which can be measured in neural populations. We suggest an explicit parametric dependency between signal and noise correlations. We show how this dependency can be used to ”ﬁll the gaps” in noise correlations matrices using an iterative application of the Wishart distribution over positive deﬁnitive matrices. We apply our method to data from the primary somatosensory cortex of monkeys performing a two-alternativeforced choice task. We compare the discrimination thresholds read out from the population of recorded neurons with the discrimination threshold of the monkey and show that our method predicts different results than simpler, average schemes of noise correlations. 1</p><p>3 0.92672455 <a title="98-lda-3" href="./nips-2010-Evaluating_neuronal_codes_for_inference_using_Fisher_information.html">81 nips-2010-Evaluating neuronal codes for inference using Fisher information</a></p>
<p>Author: Haefner Ralf, Matthias Bethge</p><p>Abstract: Many studies have explored the impact of response variability on the quality of sensory codes. The source of this variability is almost always assumed to be intrinsic to the brain. However, when inferring a particular stimulus property, variability associated with other stimulus attributes also effectively act as noise. Here we study the impact of such stimulus-induced response variability for the case of binocular disparity inference. We characterize the response distribution for the binocular energy model in response to random dot stereograms and ﬁnd it to be very different from the Poisson-like noise usually assumed. We then compute the Fisher information with respect to binocular disparity, present in the monocular inputs to the standard model of early binocular processing, and thereby obtain an upper bound on how much information a model could theoretically extract from them. Then we analyze the information loss incurred by the different ways of combining those inputs to produce a scalar single-neuron response. We ﬁnd that in the case of depth inference, monocular stimulus variability places a greater limit on the extractable information than intrinsic neuronal noise for typical spike counts. Furthermore, the largest loss of information is incurred by the standard model for position disparity neurons (tuned-excitatory), that are the most ubiquitous in monkey primary visual cortex, while more information from the inputs is preserved in phase-disparity neurons (tuned-near or tuned-far) primarily found in higher cortical regions. 1</p><p>4 0.92261362 <a title="98-lda-4" href="./nips-2010-The_Maximal_Causes_of_Natural_Scenes_are_Edge_Filters.html">266 nips-2010-The Maximal Causes of Natural Scenes are Edge Filters</a></p>
<p>Author: Jose Puertas, Joerg Bornschein, Joerg Luecke</p><p>Abstract: We study the application of a strongly non-linear generative model to image patches. As in standard approaches such as Sparse Coding or Independent Component Analysis, the model assumes a sparse prior with independent hidden variables. However, in the place where standard approaches use the sum to combine basis functions we use the maximum. To derive tractable approximations for parameter estimation we apply a novel approach based on variational Expectation Maximization. The derived learning algorithm can be applied to large-scale problems with hundreds of observed and hidden variables. Furthermore, we can infer all model parameters including observation noise and the degree of sparseness. In applications to image patches we ﬁnd that Gabor-like basis functions are obtained. Gabor-like functions are thus not a feature exclusive to approaches assuming linear superposition. Quantitatively, the inferred basis functions show a large diversity of shapes with many strongly elongated and many circular symmetric functions. The distribution of basis function shapes reﬂects properties of simple cell receptive ﬁelds that are not reproduced by standard linear approaches. In the study of natural image statistics, the implications of using different superposition assumptions have so far not been investigated systematically because models with strong non-linearities have been found analytically and computationally challenging. The presented algorithm represents the ﬁrst large-scale application of such an approach. 1</p><p>5 0.9211908 <a title="98-lda-5" href="./nips-2010-Bayesian_Action-Graph_Games.html">39 nips-2010-Bayesian Action-Graph Games</a></p>
<p>Author: Albert X. Jiang, Kevin Leyton-brown</p><p>Abstract: Games of incomplete information, or Bayesian games, are an important gametheoretic model and have many applications in economics. We propose Bayesian action-graph games (BAGGs), a novel graphical representation for Bayesian games. BAGGs can represent arbitrary Bayesian games, and furthermore can compactly express Bayesian games exhibiting commonly encountered types of structure including symmetry, action- and type-speciﬁc utility independence, and probabilistic independence of type distributions. We provide an algorithm for computing expected utility in BAGGs, and discuss conditions under which the algorithm runs in polynomial time. Bayes-Nash equilibria of BAGGs can be computed by adapting existing algorithms for complete-information normal form games and leveraging our expected utility algorithm. We show both theoretically and empirically that our approaches improve signiﬁcantly on the state of the art. 1</p><p>6 0.91991341 <a title="98-lda-6" href="./nips-2010-Accounting_for_network_effects_in_neuronal_responses_using_L1_regularized_point_process_models.html">21 nips-2010-Accounting for network effects in neuronal responses using L1 regularized point process models</a></p>
<p>7 0.91424304 <a title="98-lda-7" href="./nips-2010-Improving_Human_Judgments_by_Decontaminating_Sequential_Dependencies.html">121 nips-2010-Improving Human Judgments by Decontaminating Sequential Dependencies</a></p>
<p>8 0.90688205 <a title="98-lda-8" href="./nips-2010-Word_Features_for_Latent_Dirichlet_Allocation.html">286 nips-2010-Word Features for Latent Dirichlet Allocation</a></p>
<p>9 0.90399688 <a title="98-lda-9" href="./nips-2010-Online_Learning_for_Latent_Dirichlet_Allocation.html">194 nips-2010-Online Learning for Latent Dirichlet Allocation</a></p>
<p>10 0.9021399 <a title="98-lda-10" href="./nips-2010-A_Discriminative_Latent_Model_of_Image_Region_and_Object_Tag_Correspondence.html">6 nips-2010-A Discriminative Latent Model of Image Region and Object Tag Correspondence</a></p>
<p>11 0.90196067 <a title="98-lda-11" href="./nips-2010-Deterministic_Single-Pass_Algorithm_for_LDA.html">60 nips-2010-Deterministic Single-Pass Algorithm for LDA</a></p>
<p>12 0.89615005 <a title="98-lda-12" href="./nips-2010-A_unified_model_of_short-range_and_long-range_motion_perception.html">20 nips-2010-A unified model of short-range and long-range motion perception</a></p>
<p>13 0.89436603 <a title="98-lda-13" href="./nips-2010-Infinite_Relational_Modeling_of_Functional_Connectivity_in_Resting_State_fMRI.html">128 nips-2010-Infinite Relational Modeling of Functional Connectivity in Resting State fMRI</a></p>
<p>14 0.89409178 <a title="98-lda-14" href="./nips-2010-Brain_covariance_selection%3A_better_individual_functional_connectivity_models_using_population_prior.html">44 nips-2010-Brain covariance selection: better individual functional connectivity models using population prior</a></p>
<p>15 0.89300013 <a title="98-lda-15" href="./nips-2010-The_Neural_Costs_of_Optimal_Control.html">268 nips-2010-The Neural Costs of Optimal Control</a></p>
<p>16 0.89231634 <a title="98-lda-16" href="./nips-2010-A_biologically_plausible_network_for_the_computation_of_orientation_dominance.html">17 nips-2010-A biologically plausible network for the computation of orientation dominance</a></p>
<p>17 0.89026195 <a title="98-lda-17" href="./nips-2010-Effects_of_Synaptic_Weight_Diffusion_on_Learning_in_Decision_Making_Networks.html">68 nips-2010-Effects of Synaptic Weight Diffusion on Learning in Decision Making Networks</a></p>
<p>18 0.8839975 <a title="98-lda-18" href="./nips-2010-Inferring_Stimulus_Selectivity_from_the_Spatial_Structure_of_Neural_Network_Dynamics.html">127 nips-2010-Inferring Stimulus Selectivity from the Spatial Structure of Neural Network Dynamics</a></p>
<p>19 0.88097894 <a title="98-lda-19" href="./nips-2010-Over-complete_representations_on_recurrent_neural_networks_can_support_persistent_percepts.html">200 nips-2010-Over-complete representations on recurrent neural networks can support persistent percepts</a></p>
<p>20 0.87792802 <a title="98-lda-20" href="./nips-2010-A_rational_decision_making_framework_for_inhibitory_control.html">19 nips-2010-A rational decision making framework for inhibitory control</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
