<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>200 nips-2010-Over-complete representations on recurrent neural networks can support persistent percepts</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-200" href="#">nips2010-200</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>200 nips-2010-Over-complete representations on recurrent neural networks can support persistent percepts</h1>
<br/><p>Source: <a title="nips-2010-200-pdf" href="http://papers.nips.cc/paper/4020-over-complete-representations-on-recurrent-neural-networks-can-support-persistent-percepts.pdf">pdf</a></p><p>Author: Shaul Druckmann, Dmitri B. Chklovskii</p><p>Abstract: A striking aspect of cortical neural networks is the divergence of a relatively small number of input channels from the peripheral sensory apparatus into a large number of cortical neurons, an over-complete representation strategy. Cortical neurons are then connected by a sparse network of lateral synapses. Here we propose that such architecture may increase the persistence of the representation of an incoming stimulus, or a percept. We demonstrate that for a family of networks in which the receptive ﬁeld of each neuron is re-expressed by its outgoing connections, a represented percept can remain constant despite changing activity. We term this choice of connectivity REceptive FIeld REcombination (REFIRE) networks. The sparse REFIRE network may serve as a high-dimensional integrator and a biologically plausible model of the local cortical circuit. 1</p><p>Reference: <a title="nips-2010-200-reference" href="../nips2010_reference/nips-2010-Over-complete_representations_on_recurrent_neural_networks_can_support_persistent_percepts_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Over-complete representations on recurrent neural networks can support persistent percepts  Dmitri B. [sent-1, score-0.495]
</p><p>2 org  Abstract A striking aspect of cortical neural networks is the divergence of a relatively small number of input channels from the peripheral sensory apparatus into a large number of cortical neurons, an over-complete representation strategy. [sent-6, score-0.473]
</p><p>3 Cortical neurons are then connected by a sparse network of lateral synapses. [sent-7, score-0.584]
</p><p>4 We demonstrate that for a family of networks in which the receptive ﬁeld of each neuron is re-expressed by its outgoing connections, a represented percept can remain constant despite changing activity. [sent-9, score-0.525]
</p><p>5 The sparse REFIRE network may serve as a high-dimensional integrator and a biologically plausible model of the local cortical circuit. [sent-11, score-0.459]
</p><p>6 1  Introduction  Two salient features of cortical networks are the numerous recurrent lateral connections within a cortical area and the high ratio of cortical cells to sensory input channels. [sent-12, score-0.87]
</p><p>7 In their seminal study [1], Olshausen and Field argued that such architecture may subserve sparse over-complete representations, which maximize representation accuracy while minimizing the metabolic cost of spiking. [sent-13, score-0.206]
</p><p>8 In this framework, lateral connections between neurons with correlated receptive ﬁelds mediate explaining away of the sensory input features[2]. [sent-14, score-0.586]
</p><p>9 With the exception of an Ising-like generative model for the lateral connections [3] and a mutual information maximization approach [4], most theoretical work on lateral connections did not focus on the representation over-completeness [5] and references therein. [sent-15, score-0.606]
</p><p>10 Here, we propose that over-complete representations on recurrently connected networks offer a solution to a long-standing puzzle in neuroscience, that of maintaining a stable sensory percept in the absence of time-invariant persistent activity (rate of action potential discharge). [sent-16, score-0.838]
</p><p>11 In order for sensory percepts to guide actions, their duration must extend to behavioral time scales, hundreds of milliseconds or seconds if not more. [sent-17, score-0.304]
</p><p>12 However, many cortical neurons exhibit time-varying activity even during working memory tasks [6, 7] and references therein. [sent-18, score-0.434]
</p><p>13 If each neuron codes for orthogonal directions in stimulus space, any change in the activity of neurons would cause a distortion in the network representation, implying that a percept cannot be maintained. [sent-19, score-0.817]
</p><p>14 We point out that, in an over-complete representation, network activity can change without any change in the percept, allowing persistent percepts to be maintained in face of variable neuronal activity. [sent-20, score-0.812]
</p><p>15 This results from the fact that the activity space has a higher dimensionality than that of the stimulus space. [sent-21, score-0.242]
</p><p>16 When the activity changes in a direction nulled by the projection onto stimulus space, the percept remains invariant. [sent-22, score-0.487]
</p><p>17 1  What lateral connectivity can support persistent percepts, even in the face of changing neuronal activity? [sent-23, score-0.593]
</p><p>18 We derive the condition on lateral connection weights for networks to maintain persistent percepts, thus deﬁning a family of REceptive FIeld REcombination networks. [sent-24, score-0.43]
</p><p>19 Furthermore, we propose that minimizing synaptic volume cost favors sparse REFIRE networks, whose properties are remarkably similar to that of the cortex. [sent-25, score-0.217]
</p><p>20 2  Model  We consider n sensory neurons, their activity marked by s in Rn which project to a layer of m cortical neurons, where m > n. [sent-27, score-0.446]
</p><p>21 The activity of the m neurons, marked by a in Rm , at any given time represents a percept of a certain stimulus. [sent-28, score-0.448]
</p><p>22 The represented percept s is a linear superposition of feature vectors, stacked as columns of matrix D, weighted by the neuronal activity a: s = Da. [sent-29, score-0.588]
</p><p>23 (1)  For instance, s could represent the intensity level of pixels in a patch of the visual ﬁeld and the columns of D a dictionary chosen to represent the patches, e. [sent-30, score-0.238]
</p><p>24 Since m > n, the columns of dictionary D cannot be orthogonal and hence deﬁne a frame rather than a basis [9]. [sent-33, score-0.264]
</p><p>25 The mapping between the activity space Rm and the sensory space Rn is accomplished by the synthesis operator, D. [sent-36, score-0.324]
</p><p>26 The adjoint operator DT is called the analysis operator and their composition the frame operator DDT . [sent-37, score-0.199]
</p><p>27 As a consequence of columns of D being a frame, a given vector in the space of percepts can be represented non-uniquely, i. [sent-38, score-0.224]
</p><p>28 These can be computed by Matching Pursuit [10], Basis Pursuit [11] or LASSO [12], or by the dynamics of a neural network with feedforward and lateral connections [13]. [sent-46, score-0.528]
</p><p>29 In summary, the neural activity is an over-complete representation of the sensory percepts, the m columns of D acting as a frame for the space of sensory percepts. [sent-47, score-0.663]
</p><p>30 2  Persistent percepts and lateral connectivity  Now, we derive a necessary and sufﬁcient condition on the lateral connections L such that for every a the percept represented by Equation (1) persists. [sent-49, score-0.993]
</p><p>31 We focus on the dynamics of a following a transient presentation of the sensory stimulus. [sent-50, score-0.249]
</p><p>32 The dynamics of a network with lateral connectivity matrix L is given by: a = −a + La, ˙ (3) where time is measured in units of the neuronal membrane time constant. [sent-51, score-0.648]
</p><p>33 Requiring time-invariant persistent activity amounts to a = 0 or ˙ a = La. [sent-52, score-0.38]
</p><p>34 (4) However, this is not necessary if we require only the percept represented by the network to be ﬁxed. [sent-53, score-0.395]
</p><p>35 (6)  If we require persistent percepts for any a, then: D = DL 2  (7)  Equation (7) has a trivial solution L = I, which corresponds to a network with no actual lateral connections and only autapses. [sent-55, score-0.782]
</p><p>36 The intuition behind the derivation of Equation (7) is as follows: as the activity of each neuron changes due to the ﬁrst term in the rhs of Equation (5) its contribution to the percept may change. [sent-59, score-0.519]
</p><p>37 To compensate for this change without necessarily keeping the activity ﬁxed, we require that the other neurons adjust their activity according to Equation (6). [sent-60, score-0.515]
</p><p>38 For each neuron j the sum of its post-synaptic partners receptive ﬁelds, weighted by the synaptic efﬁcacy from neuron j to the other neurons equals to the receptive ﬁeld of neuron j. [sent-62, score-0.563]
</p><p>39 Equation (7) and its non-trivial solutions that maintain persistent percepts are the main results of the present study. [sent-64, score-0.36]
</p><p>40 Some patterns of activity satisfying Equation (4) will remain time-invariant themselves. [sent-66, score-0.236]
</p><p>41 3  An example: the Mercedes-Benz frame  In order to present a more intuitive view of the concept of persistent percepts we consider the Mercedes-Benz frame [17]. [sent-78, score-0.59]
</p><p>42 √This simple frame spans the R2 plane with three frame elements: √ [0 1], [− 3/2 − 1/2], [ 3/2 − 1/2]. [sent-79, score-0.261]
</p><p>43 In this case, the frame operator DDT has a particularly simple form, being proportional to the identity matrix, indicating that the frame is tight. [sent-80, score-0.258]
</p><p>44 This new activity vector represents 3  exactly the same point on the plane: Da = [0 1]. [sent-84, score-0.203]
</p><p>45 Note that some patterns of activity will remain strictly persistent themselves. [sent-86, score-0.413]
</p><p>46 4  The sparse REFIRE network  Which members of the family of REFIRE networks obeying equation (7) are most likely to model cortical networks? [sent-90, score-0.505]
</p><p>47 In the cortex, the connectivity is sparse and the synaptic weights are distributed exponentially [18, 19]. [sent-91, score-0.329]
</p><p>48 Motivated by these observations, we choose each column of L as a sparse representation of each individual dictionary element by every other element. [sent-93, score-0.314]
</p><p>49 The connectivity of our model network is given by ˜ ˜ L = [β1 , β2 , . [sent-104, score-0.262]
</p><p>50 Similar networks were previously constructed on the raw data (or image patches) [20, 21], while sparse REFIRE networks reﬂect the relationship among dictionary elements. [sent-109, score-0.376]
</p><p>51 We study the properties of the resulting sparse REFIRE network and compare them with experimentally established properties of cortical networks. [sent-112, score-0.416]
</p><p>52 1  Constructing the sparse REFIRE network for visual cortex  We learn the sparse REFIRE network from a standard set of natural images [8]. [sent-114, score-0.665]
</p><p>53 The sparse REFIRE network was then learned from the dictionary using the same toolbox. [sent-122, score-0.402]
</p><p>54 The distribution of synaptic weights in the network, Figure 3 left, shows a strong bias to zero valued connections and a heavier than gaussian tail as does the cortical data [25]. [sent-126, score-0.286]
</p><p>55 Remarkably, the real part of all eigenvalues is less than or equal to one, Figure 3 right, indicating stability of network dynamics. [sent-129, score-0.201]
</p><p>56 Left: the patches corresponding to columns of D sorted by variance. [sent-140, score-0.178]
</p><p>57 In general, the sparse REFIRE network is unlikely to be symmetric because the connection weights between a pair of neurons are not decided based solely on the identity of the neurons in the pair but are dependent on other connections of the same pre-synaptic neuron. [sent-144, score-0.629]
</p><p>58 2  Connection weight  Figure 3: Properties of lateral connections. [sent-158, score-0.181]
</p><p>59 Right: scatter plot of eigenvalues of the lateral connectivity matrix. [sent-161, score-0.413]
</p><p>60 Histogram shown below plot Numerical simulations of the dynamics of a recurrent network with connectivity matrix L conﬁrm that the percept remains stable during the network dynamics. [sent-163, score-0.873]
</p><p>61 We chose an image patch at random and simulated the network dynamics. [sent-164, score-0.249]
</p><p>62 As can be seen in Figure 4 left, despite signiﬁcant changes in the activity of the neurons, the percept encoded by the network remained stable, PSNR between original image and image after dynamics lasting 100 neuronal time constants: 45. [sent-165, score-0.912]
</p><p>63 The dynamics of the network desparsiﬁed the representation (Figure 4 right). [sent-167, score-0.318]
</p><p>64 Averaged across multiple patches, the value of each coefﬁcient in the sparse representation was 0. [sent-168, score-0.206]
</p><p>65 0704, while after the network dynamics this increased to 0. [sent-169, score-0.256]
</p><p>66 2  Computational advantages of the sparse REFIRE network  In this section, we consider possible computational advantages for the de-coupling between the sensory percept and it representation by neuronal activity. [sent-173, score-0.821]
</p><p>67 Figure 4: Evolution of neuronal activity in time. [sent-185, score-0.302]
</p><p>68 Top shows the original percept (framed in black) and plotted left to right patches taken from consecutive points in the dynamics. [sent-187, score-0.482]
</p><p>69 To arrive at a sparse approximation of the stimuli either one of the dictionary elements could potentially be used, but due to the high cost of non-sparseness both of them together are not likely to be chosen in a given representation. [sent-190, score-0.252]
</p><p>70 The dynamics of the sparse REFIRE network improve the robustness of the coefﬁcient values in the face of noise. [sent-192, score-0.433]
</p><p>71 We train one of classiﬁer on the sparse representation and the other on the representation following the dynamics of the sparse REFIRE network. [sent-208, score-0.518]
</p><p>72 We ﬁnd that the generalization of the classiﬁer learned following the dynamics was indeed higher, providing 92% accuracy, while the sparse coefﬁcient trained classiﬁer scored 83% accuracy. [sent-209, score-0.25]
</p><p>73 We then demonstrate the computational advantages of the sparse REFIRE network in a more realistic scenario, encoding a set of patches extracted from an image by shifting the patch one pixel at a time. [sent-210, score-0.53]
</p><p>74 For each of the patches we calculate the sparse approximation coefﬁcients and then determine the dot product between the representation of consecutive patches. [sent-213, score-0.457]
</p><p>75 We then take the same coefﬁcients, evolve them through the dynamics of the sparse REFIRE network network and compute the dot product between these new coefﬁcients. [sent-214, score-0.618]
</p><p>76 Figure 5 right bottom shows the normalized dot product, the value of the dot product between the coefﬁcients of two consecutive patches after the sparse REFIRE network dynamics, divided by the same dot product between the original coefﬁcients. [sent-215, score-0.711]
</p><p>77 5 0  5  10  15  Coefficient One  Figure 5: Sparse REFIRE network dynamics enhances the robustness of representation. [sent-219, score-0.289]
</p><p>78 Followed by the coefﬁcient of each of the patch in the representation of the different noisy image instantiations and a scatter plot of the coefﬁcient values before recurrent dynamics (red) and following (blue) recurrent dynamics. [sent-221, score-0.466]
</p><p>79 Right: an example of the patches in the sliding frame (top) and the normalized dot product between consecutive patches. [sent-222, score-0.366]
</p><p>80 Clusters of patches obtained by a three-way sparse REFIRE network partitioning by normalized cut. [sent-224, score-0.463]
</p><p>81 Note the mainly horizontal orientation of the ﬁrst set of patches and the vertical orientation of the second. [sent-225, score-0.222]
</p><p>82 The sparse REFIRE network encodes useful information regarding the relation between the different dictionary elements. [sent-226, score-0.402]
</p><p>83 Thus, subspaces can be learned directly from partitioning on the sparse REFIRE network offering a complementary approach to learning structured models directly from the data [26, 27]. [sent-230, score-0.346]
</p><p>84 Finally, the sparse REFIRE network serves as an integrator of the sensory input. [sent-231, score-0.458]
</p><p>85 Eigenspace of the unit eigenvalue is a multi-dimensional generalization of the line attractor used to model persistent activity [16]. [sent-232, score-0.44]
</p><p>86 However, unlike the persistent activity theory, which focuses on dynamics along the line attractor, we emphasize the transient dynamics approaching the unitary eigenspace. [sent-233, score-0.614]
</p><p>87 First, we propose and demonstrate that in an over-complete representation certain types of network connectivity allow the percept, i. [sent-235, score-0.324]
</p><p>88 the stimulus represented by the network activity, to remain ﬁxed in time despite changing neuronal activity. [sent-237, score-0.367]
</p><p>89 Second, we propose the sparse REFIRE network as a biologically plausible model for cortical lateral connections that enables such persistent percepts. [sent-238, score-0.865]
</p><p>90 Third, we point out that the ability to manipulate activity without affecting the accuracy of representation can be exploited in order to achieve computational goals. [sent-239, score-0.265]
</p><p>91 As an example, we show that the sparse REFIRE network dynamics, though causing the representation to be less sparse, alleviates the problem of representation non-robustness. [sent-240, score-0.418]
</p><p>92 Although this study focused on sensory representation in the visual cortex, the framework can be extended to other sensory modalities, motor cortex and, perhaps, even higher cognitive areas such as prefrontal cortex or hippocampus. [sent-241, score-0.436]
</p><p>93 02  0 0  20  40  60  80  Figure 7: sparse REFIRE network structure. [sent-245, score-0.294]
</p><p>94 The sparse REFIRE network model bears an important relation to the family of sparse subspace models, which have been suggested to improve the robustness of sparse representations[26, 27]. [sent-252, score-0.615]
</p><p>95 The optimal way to leverage the information embodied in the sparse REFIRE network to learn subspace-like models is a subject of ongoing work with promising results as is the study of different matrices L that allow persistent percepts. [sent-254, score-0.471]
</p><p>96 Field, “Emergence of simple-cell receptive ﬁeld properties by learning a sparse code for natural images,” Nature, vol. [sent-260, score-0.228]
</p><p>97 Sommer, “A network that uses few active neurones to code visual input predicts the diverse shapes of cortical receptive ﬁelds,” Journal of Computational Neuroscience, vol. [sent-265, score-0.378]
</p><p>98 Olshausen, “Learning horizontal connections in a sparse coding model of natural images,” Advances in Neural Information Processing Systems, vol. [sent-274, score-0.256]
</p><p>99 Shamma, “A proposed neural network for the integrator of the oculomotor system,” Biological Cybernetics, vol. [sent-348, score-0.193]
</p><p>100 Chklovskii, “Highly nonrandom features o o of synaptic connectivity in local cortical circuits,” PLoS Biol, vol. [sent-421, score-0.307]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('refire', 0.646), ('percept', 0.245), ('activity', 0.203), ('percepts', 0.183), ('lateral', 0.181), ('persistent', 0.177), ('network', 0.15), ('sparse', 0.144), ('patches', 0.137), ('coef', 0.122), ('cortical', 0.122), ('sensory', 0.121), ('frame', 0.115), ('connectivity', 0.112), ('neurons', 0.109), ('dictionary', 0.108), ('dynamics', 0.106), ('neuronal', 0.099), ('chklovskii', 0.095), ('connections', 0.091), ('cients', 0.09), ('receptive', 0.084), ('ddt', 0.076), ('synaptic', 0.073), ('neuron', 0.071), ('dot', 0.068), ('patch', 0.067), ('recurrent', 0.065), ('representation', 0.062), ('cortex', 0.055), ('olshausen', 0.052), ('dj', 0.052), ('eigenvalues', 0.051), ('field', 0.048), ('da', 0.047), ('networks', 0.046), ('scatter', 0.046), ('consecutive', 0.046), ('integrator', 0.043), ('equation', 0.043), ('columns', 0.041), ('imaginary', 0.041), ('stimulus', 0.039), ('eigenvalue', 0.038), ('ashburn', 0.038), ('autapses', 0.038), ('coefficient', 0.038), ('corrupt', 0.038), ('janelia', 0.038), ('koulakov', 0.038), ('varshney', 0.038), ('mismatch', 0.036), ('dl', 0.035), ('rm', 0.034), ('ickering', 0.033), ('str', 0.033), ('remain', 0.033), ('pursuit', 0.033), ('robustness', 0.033), ('image', 0.032), ('orientation', 0.032), ('partitioning', 0.032), ('plane', 0.031), ('campus', 0.031), ('farm', 0.031), ('recombination', 0.031), ('hughes', 0.031), ('inset', 0.031), ('summed', 0.031), ('eigenvectors', 0.03), ('right', 0.03), ('howard', 0.029), ('operator', 0.028), ('mallat', 0.027), ('survival', 0.027), ('frames', 0.026), ('connection', 0.026), ('va', 0.026), ('reconstruction', 0.026), ('dt', 0.025), ('sapiro', 0.025), ('middle', 0.025), ('left', 0.024), ('red', 0.024), ('representations', 0.024), ('changing', 0.024), ('interests', 0.023), ('remained', 0.023), ('plot', 0.023), ('hu', 0.023), ('visual', 0.022), ('stable', 0.022), ('despite', 0.022), ('circuits', 0.022), ('transient', 0.022), ('attractor', 0.022), ('competition', 0.021), ('mairal', 0.021), ('horizontal', 0.021), ('subspaces', 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="200-tfidf-1" href="./nips-2010-Over-complete_representations_on_recurrent_neural_networks_can_support_persistent_percepts.html">200 nips-2010-Over-complete representations on recurrent neural networks can support persistent percepts</a></p>
<p>Author: Shaul Druckmann, Dmitri B. Chklovskii</p><p>Abstract: A striking aspect of cortical neural networks is the divergence of a relatively small number of input channels from the peripheral sensory apparatus into a large number of cortical neurons, an over-complete representation strategy. Cortical neurons are then connected by a sparse network of lateral synapses. Here we propose that such architecture may increase the persistence of the representation of an incoming stimulus, or a percept. We demonstrate that for a family of networks in which the receptive ﬁeld of each neuron is re-expressed by its outgoing connections, a represented percept can remain constant despite changing activity. We term this choice of connectivity REceptive FIeld REcombination (REFIRE) networks. The sparse REFIRE network may serve as a high-dimensional integrator and a biologically plausible model of the local cortical circuit. 1</p><p>2 0.16555066 <a title="200-tfidf-2" href="./nips-2010-Inferring_Stimulus_Selectivity_from_the_Spatial_Structure_of_Neural_Network_Dynamics.html">127 nips-2010-Inferring Stimulus Selectivity from the Spatial Structure of Neural Network Dynamics</a></p>
<p>Author: Kanaka Rajan, L Abbott, Haim Sompolinsky</p><p>Abstract: How are the spatial patterns of spontaneous and evoked population responses related? We study the impact of connectivity on the spatial pattern of ﬂuctuations in the input-generated response, by comparing the distribution of evoked and intrinsically generated activity across the different units of a neural network. We develop a complementary approach to principal component analysis in which separate high-variance directions are derived for each input condition. We analyze subspace angles to compute the difference between the shapes of trajectories corresponding to different network states, and the orientation of the low-dimensional subspaces that driven trajectories occupy within the full space of neuronal activity. In addition to revealing how the spatiotemporal structure of spontaneous activity affects input-evoked responses, these methods can be used to infer input selectivity induced by network dynamics from experimentally accessible measures of spontaneous activity (e.g. from voltage- or calcium-sensitive optical imaging experiments). We conclude that the absence of a detailed spatial map of afferent inputs and cortical connectivity does not limit our ability to design spatially extended stimuli that evoke strong responses. 1 1 Motivation Stimulus selectivity in neural networks was historically measured directly from input-driven responses [1], and only later were similar selectivity patterns observed in spontaneous activity across the cortical surface [2, 3]. We argue that it is possible to work in the reverse order, and show that analyzing the distribution of spontaneous activity across the different units in the network can inform us about the selectivity of evoked responses to stimulus features, even when no apparent sensory map exists. Sensory-evoked responses are typically divided into a signal component generated by the stimulus and a noise component corresponding to ongoing activity that is not directly related to the stimulus. Subsequent effort focuses on understanding how the signal depends on properties of the stimulus, while the remaining, irregular part of the response is treated as additive noise. The distinction between external stochastic processes and the noise generated deterministically as a function of intrinsic recurrence has been previously studied in chaotic neural networks [4]. It has also been suggested that internally generated noise is not additive and can be more sensitive to the frequency and amplitude of the input, compared to the signal component of the response [5 - 8]. In this paper, we demonstrate that the interaction between deterministic intrinsic noise and the spatial properties of the external stimulus is also complex and nonlinear. We study the impact of network connectivity on the spatial pattern of input-driven responses by comparing the structure of evoked and spontaneous activity, and show how the unique signature of these dynamics determines the selectivity of networks to spatial features of the stimuli driving them. 2 Model description In this section, we describe the network model and the methods we use to analyze its dynamics. Subsequent sections explore how the spatial patterns of spontaneous and evoked responses are related in terms of the distribution of the activity across the network. Finally, we show how the stimulus selectivity of the network can be inferred from its spontaneous activity patterns. 2.1 Network elements We build a ﬁring rate model of N interconnected units characterized by a statistical description of the underlying circuitry (as N → ∞, the system “self averages” making the description independent of a speciﬁc network architecture, see also [11, 12]). Each unit is characterized by an activation variable xi ∀ i = 1, 2, . . . N , and a nonlinear response function ri which relates to xi through ri = R0 + φ(xi ) where,   R0 tanh x for x ≤ 0 R0 φ(x) = (1) x  (Rmax − R0 ) tanh otherwise. Rmax −R0 Eq. 1 allows us to independently set the maximum ﬁring rate Rmax and the background rate R0 to biologically reasonable values, while retaining a maximum gradient at x = 0 to guarantee the smoothness of the transition to chaos [4]. We introduce a recurrent weight matrix with element Jij equivalent to the strength of the synapse from unit j → unit i. The individual weights are chosen independently and randomly from a Gaus2 sian distribution with mean and variance given by [Jij ]J = 0 and Jij J = g 2 /N , where square brackets are ensemble averages [9 - 11,13]. The control parameter g which scales as the variance of the synaptic weights, is particularly important in determining whether or not the network produces spontaneous activity with non-trivial dynamics (Speciﬁcally, g = 0 corresponds to a completely uncoupled network and a network with g = 1 generates non-trivial spontaneous activity [4, 9, 10]). The activation variable for each unit xi is therefore determined by the relation, N τr dxi = −xi + g Jij rj + Ii , dt j=1 with the time scale of the network set by the single-neuron time constant τr of 10 ms. 2 (2) The amplitude I of an oscillatory external input of frequency f , is always the same for each unit, but in some examples shown in this paper, we introduce a neuron-speciﬁc phase factor θi , chosen randomly from a uniform distribution between 0 and 2π, such that Ii = I cos(2πf t + θi ) ∀ i = 1, 2, . . . N. (3) In visually responsive neurons, this mimics a population of simple cells driven by a drifting grating of temporal frequency f , with the different phases arising from offsets in spatial receptive ﬁeld locations. The randomly assigned phases in our model ensure that the spatial pattern of input is not correlated with the pattern of recurrent connectivity. In our selectivity analysis however (Fig. 3), we replace the random phases with spatial input patterns that are aligned with network connectivity. 2.2 PCA redux Principal component analysis (PCA) has been applied proﬁtably to neuronal recordings (see for example [14]) but these analyses often plot activity trajectories corresponding to different network states using the ﬁxed principal component coordinates derived from combined activities under all stimulus conditions. Our analysis offers a complementary approach whereby separate principal components are derived for each stimulus condition, and the resulting principal angles reveal not only the difference between the shapes of trajectories corresponding to different network states, but also the orientation of the low-dimensional subspaces these trajectories occupy within the full N -dimensional space of neuronal activity. The instantaneous network state can be described by a point in an N -dimensional space with coordinates equal to the ﬁring rates of the N units. Over time, the network activity traverses a trajectory in this N -dimensional space and PCA can be used to delineate the subspace in which this trajectory lies. The analysis is done by diagonalizing the equal-time cross-correlation matrix of network ﬁring rates given by, Dij = (ri (t) − ri )(rj (t) − rj ) , (4) where</p><p>3 0.1162459 <a title="200-tfidf-3" href="./nips-2010-Group_Sparse_Coding_with_a_Laplacian_Scale_Mixture_Prior.html">109 nips-2010-Group Sparse Coding with a Laplacian Scale Mixture Prior</a></p>
<p>Author: Pierre Garrigues, Bruno A. Olshausen</p><p>Abstract: We propose a class of sparse coding models that utilizes a Laplacian Scale Mixture (LSM) prior to model dependencies among coefﬁcients. Each coefﬁcient is modeled as a Laplacian distribution with a variable scale parameter, with a Gamma distribution prior over the scale parameter. We show that, due to the conjugacy of the Gamma prior, it is possible to derive efﬁcient inference procedures for both the coefﬁcients and the scale parameter. When the scale parameters of a group of coefﬁcients are combined into a single variable, it is possible to describe the dependencies that occur due to common amplitude ﬂuctuations among coefﬁcients, which have been shown to constitute a large fraction of the redundancy in natural images [1]. We show that, as a consequence of this group sparse coding, the resulting inference of the coefﬁcients follows a divisive normalization rule, and that this may be efﬁciently implemented in a network architecture similar to that which has been proposed to occur in primary visual cortex. We also demonstrate improvements in image coding and compressive sensing recovery using the LSM model. 1</p><p>4 0.1140322 <a title="200-tfidf-4" href="./nips-2010-Short-term_memory_in_neuronal_networks_through_dynamical_compressed_sensing.html">238 nips-2010-Short-term memory in neuronal networks through dynamical compressed sensing</a></p>
<p>Author: Surya Ganguli, Haim Sompolinsky</p><p>Abstract: Recent proposals suggest that large, generic neuronal networks could store memory traces of past input sequences in their instantaneous state. Such a proposal raises important theoretical questions about the duration of these memory traces and their dependence on network size, connectivity and signal statistics. Prior work, in the case of gaussian input sequences and linear neuronal networks, shows that the duration of memory traces in a network cannot exceed the number of neurons (in units of the neuronal time constant), and that no network can out-perform an equivalent feedforward network. However a more ethologically relevant scenario is that of sparse input sequences. In this scenario, we show how linear neural networks can essentially perform compressed sensing (CS) of past inputs, thereby attaining a memory capacity that exceeds the number of neurons. This enhanced capacity is achieved by a class of “orthogonal” recurrent networks and not by feedforward networks or generic recurrent networks. We exploit techniques from the statistical physics of disordered systems to analytically compute the decay of memory traces in such networks as a function of network size, signal sparsity and integration time. Alternately, viewed purely from the perspective of CS, this work introduces a new ensemble of measurement matrices derived from dynamical systems, and provides a theoretical analysis of their asymptotic performance. 1</p><p>5 0.11290777 <a title="200-tfidf-5" href="./nips-2010-Brain_covariance_selection%3A_better_individual_functional_connectivity_models_using_population_prior.html">44 nips-2010-Brain covariance selection: better individual functional connectivity models using population prior</a></p>
<p>Author: Gael Varoquaux, Alexandre Gramfort, Jean-baptiste Poline, Bertrand Thirion</p><p>Abstract: Spontaneous brain activity, as observed in functional neuroimaging, has been shown to display reproducible structure that expresses brain architecture and carries markers of brain pathologies. An important view of modern neuroscience is that such large-scale structure of coherent activity reﬂects modularity properties of brain connectivity graphs. However, to date, there has been no demonstration that the limited and noisy data available in spontaneous activity observations could be used to learn full-brain probabilistic models that generalize to new data. Learning such models entails two main challenges: i) modeling full brain connectivity is a difﬁcult estimation problem that faces the curse of dimensionality and ii) variability between subjects, coupled with the variability of functional signals between experimental runs, makes the use of multiple datasets challenging. We describe subject-level brain functional connectivity structure as a multivariate Gaussian process and introduce a new strategy to estimate it from group data, by imposing a common structure on the graphical model in the population. We show that individual models learned from functional Magnetic Resonance Imaging (fMRI) data using this population prior generalize better to unseen data than models based on alternative regularization schemes. To our knowledge, this is the ﬁrst report of a cross-validated model of spontaneous brain activity. Finally, we use the estimated graphical model to explore the large-scale characteristics of functional architecture and show for the ﬁrst time that known cognitive networks appear as the integrated communities of functional connectivity graph. 1</p><p>6 0.10831404 <a title="200-tfidf-6" href="./nips-2010-Accounting_for_network_effects_in_neuronal_responses_using_L1_regularized_point_process_models.html">21 nips-2010-Accounting for network effects in neuronal responses using L1 regularized point process models</a></p>
<p>7 0.10269023 <a title="200-tfidf-7" href="./nips-2010-Learning_Convolutional_Feature_Hierarchies_for_Visual_Recognition.html">143 nips-2010-Learning Convolutional Feature Hierarchies for Visual Recognition</a></p>
<p>8 0.097114109 <a title="200-tfidf-8" href="./nips-2010-The_Maximal_Causes_of_Natural_Scenes_are_Edge_Filters.html">266 nips-2010-The Maximal Causes of Natural Scenes are Edge Filters</a></p>
<p>9 0.095718667 <a title="200-tfidf-9" href="./nips-2010-Beyond_Actions%3A_Discriminative_Models_for_Contextual_Group_Activities.html">40 nips-2010-Beyond Actions: Discriminative Models for Contextual Group Activities</a></p>
<p>10 0.094701044 <a title="200-tfidf-10" href="./nips-2010-Linear_readout_from_a_neural_population_with_partial_correlation_data.html">161 nips-2010-Linear readout from a neural population with partial correlation data</a></p>
<p>11 0.093643144 <a title="200-tfidf-11" href="./nips-2010-Deciphering_subsampled_data%3A_adaptive_compressive_sampling_as_a_principle_of_brain_communication.html">56 nips-2010-Deciphering subsampled data: adaptive compressive sampling as a principle of brain communication</a></p>
<p>12 0.092927873 <a title="200-tfidf-12" href="./nips-2010-Attractor_Dynamics_with_Synaptic_Depression.html">34 nips-2010-Attractor Dynamics with Synaptic Depression</a></p>
<p>13 0.087708525 <a title="200-tfidf-13" href="./nips-2010-The_Neural_Costs_of_Optimal_Control.html">268 nips-2010-The Neural Costs of Optimal Control</a></p>
<p>14 0.085691139 <a title="200-tfidf-14" href="./nips-2010-Implicit_encoding_of_prior_probabilities_in_optimal_neural_populations.html">119 nips-2010-Implicit encoding of prior probabilities in optimal neural populations</a></p>
<p>15 0.081167743 <a title="200-tfidf-15" href="./nips-2010-Spike_timing-dependent_plasticity_as_dynamic_filter.html">253 nips-2010-Spike timing-dependent plasticity as dynamic filter</a></p>
<p>16 0.070238374 <a title="200-tfidf-16" href="./nips-2010-Divisive_Normalization%3A_Justification_and_Effectiveness_as_Efficient_Coding_Transform.html">65 nips-2010-Divisive Normalization: Justification and Effectiveness as Efficient Coding Transform</a></p>
<p>17 0.067331649 <a title="200-tfidf-17" href="./nips-2010-A_VLSI_Implementation_of_the_Adaptive_Exponential_Integrate-and-Fire_Neuron_Model.html">16 nips-2010-A VLSI Implementation of the Adaptive Exponential Integrate-and-Fire Neuron Model</a></p>
<p>18 0.06723664 <a title="200-tfidf-18" href="./nips-2010-Fractionally_Predictive_Spiking_Neurons.html">96 nips-2010-Fractionally Predictive Spiking Neurons</a></p>
<p>19 0.066368088 <a title="200-tfidf-19" href="./nips-2010-Hallucinations_in_Charles_Bonnet_Syndrome_Induced_by_Homeostasis%3A_a_Deep_Boltzmann_Machine_Model.html">111 nips-2010-Hallucinations in Charles Bonnet Syndrome Induced by Homeostasis: a Deep Boltzmann Machine Model</a></p>
<p>20 0.065330647 <a title="200-tfidf-20" href="./nips-2010-Infinite_Relational_Modeling_of_Functional_Connectivity_in_Resting_State_fMRI.html">128 nips-2010-Infinite Relational Modeling of Functional Connectivity in Resting State fMRI</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.161), (1, 0.068), (2, -0.221), (3, 0.159), (4, 0.08), (5, -0.025), (6, -0.026), (7, 0.022), (8, -0.05), (9, -0.006), (10, 0.066), (11, 0.041), (12, 0.013), (13, -0.02), (14, -0.07), (15, -0.093), (16, -0.013), (17, -0.04), (18, -0.088), (19, 0.044), (20, 0.091), (21, -0.046), (22, 0.062), (23, 0.026), (24, -0.022), (25, 0.024), (26, 0.038), (27, 0.041), (28, 0.059), (29, -0.039), (30, 0.085), (31, 0.038), (32, 0.023), (33, 0.04), (34, -0.071), (35, 0.017), (36, -0.138), (37, 0.034), (38, -0.029), (39, 0.035), (40, -0.097), (41, -0.023), (42, 0.031), (43, -0.004), (44, -0.109), (45, -0.106), (46, 0.048), (47, 0.098), (48, 0.044), (49, 0.057)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96147579 <a title="200-lsi-1" href="./nips-2010-Over-complete_representations_on_recurrent_neural_networks_can_support_persistent_percepts.html">200 nips-2010-Over-complete representations on recurrent neural networks can support persistent percepts</a></p>
<p>Author: Shaul Druckmann, Dmitri B. Chklovskii</p><p>Abstract: A striking aspect of cortical neural networks is the divergence of a relatively small number of input channels from the peripheral sensory apparatus into a large number of cortical neurons, an over-complete representation strategy. Cortical neurons are then connected by a sparse network of lateral synapses. Here we propose that such architecture may increase the persistence of the representation of an incoming stimulus, or a percept. We demonstrate that for a family of networks in which the receptive ﬁeld of each neuron is re-expressed by its outgoing connections, a represented percept can remain constant despite changing activity. We term this choice of connectivity REceptive FIeld REcombination (REFIRE) networks. The sparse REFIRE network may serve as a high-dimensional integrator and a biologically plausible model of the local cortical circuit. 1</p><p>2 0.76129818 <a title="200-lsi-2" href="./nips-2010-Inferring_Stimulus_Selectivity_from_the_Spatial_Structure_of_Neural_Network_Dynamics.html">127 nips-2010-Inferring Stimulus Selectivity from the Spatial Structure of Neural Network Dynamics</a></p>
<p>Author: Kanaka Rajan, L Abbott, Haim Sompolinsky</p><p>Abstract: How are the spatial patterns of spontaneous and evoked population responses related? We study the impact of connectivity on the spatial pattern of ﬂuctuations in the input-generated response, by comparing the distribution of evoked and intrinsically generated activity across the different units of a neural network. We develop a complementary approach to principal component analysis in which separate high-variance directions are derived for each input condition. We analyze subspace angles to compute the difference between the shapes of trajectories corresponding to different network states, and the orientation of the low-dimensional subspaces that driven trajectories occupy within the full space of neuronal activity. In addition to revealing how the spatiotemporal structure of spontaneous activity affects input-evoked responses, these methods can be used to infer input selectivity induced by network dynamics from experimentally accessible measures of spontaneous activity (e.g. from voltage- or calcium-sensitive optical imaging experiments). We conclude that the absence of a detailed spatial map of afferent inputs and cortical connectivity does not limit our ability to design spatially extended stimuli that evoke strong responses. 1 1 Motivation Stimulus selectivity in neural networks was historically measured directly from input-driven responses [1], and only later were similar selectivity patterns observed in spontaneous activity across the cortical surface [2, 3]. We argue that it is possible to work in the reverse order, and show that analyzing the distribution of spontaneous activity across the different units in the network can inform us about the selectivity of evoked responses to stimulus features, even when no apparent sensory map exists. Sensory-evoked responses are typically divided into a signal component generated by the stimulus and a noise component corresponding to ongoing activity that is not directly related to the stimulus. Subsequent effort focuses on understanding how the signal depends on properties of the stimulus, while the remaining, irregular part of the response is treated as additive noise. The distinction between external stochastic processes and the noise generated deterministically as a function of intrinsic recurrence has been previously studied in chaotic neural networks [4]. It has also been suggested that internally generated noise is not additive and can be more sensitive to the frequency and amplitude of the input, compared to the signal component of the response [5 - 8]. In this paper, we demonstrate that the interaction between deterministic intrinsic noise and the spatial properties of the external stimulus is also complex and nonlinear. We study the impact of network connectivity on the spatial pattern of input-driven responses by comparing the structure of evoked and spontaneous activity, and show how the unique signature of these dynamics determines the selectivity of networks to spatial features of the stimuli driving them. 2 Model description In this section, we describe the network model and the methods we use to analyze its dynamics. Subsequent sections explore how the spatial patterns of spontaneous and evoked responses are related in terms of the distribution of the activity across the network. Finally, we show how the stimulus selectivity of the network can be inferred from its spontaneous activity patterns. 2.1 Network elements We build a ﬁring rate model of N interconnected units characterized by a statistical description of the underlying circuitry (as N → ∞, the system “self averages” making the description independent of a speciﬁc network architecture, see also [11, 12]). Each unit is characterized by an activation variable xi ∀ i = 1, 2, . . . N , and a nonlinear response function ri which relates to xi through ri = R0 + φ(xi ) where,   R0 tanh x for x ≤ 0 R0 φ(x) = (1) x  (Rmax − R0 ) tanh otherwise. Rmax −R0 Eq. 1 allows us to independently set the maximum ﬁring rate Rmax and the background rate R0 to biologically reasonable values, while retaining a maximum gradient at x = 0 to guarantee the smoothness of the transition to chaos [4]. We introduce a recurrent weight matrix with element Jij equivalent to the strength of the synapse from unit j → unit i. The individual weights are chosen independently and randomly from a Gaus2 sian distribution with mean and variance given by [Jij ]J = 0 and Jij J = g 2 /N , where square brackets are ensemble averages [9 - 11,13]. The control parameter g which scales as the variance of the synaptic weights, is particularly important in determining whether or not the network produces spontaneous activity with non-trivial dynamics (Speciﬁcally, g = 0 corresponds to a completely uncoupled network and a network with g = 1 generates non-trivial spontaneous activity [4, 9, 10]). The activation variable for each unit xi is therefore determined by the relation, N τr dxi = −xi + g Jij rj + Ii , dt j=1 with the time scale of the network set by the single-neuron time constant τr of 10 ms. 2 (2) The amplitude I of an oscillatory external input of frequency f , is always the same for each unit, but in some examples shown in this paper, we introduce a neuron-speciﬁc phase factor θi , chosen randomly from a uniform distribution between 0 and 2π, such that Ii = I cos(2πf t + θi ) ∀ i = 1, 2, . . . N. (3) In visually responsive neurons, this mimics a population of simple cells driven by a drifting grating of temporal frequency f , with the different phases arising from offsets in spatial receptive ﬁeld locations. The randomly assigned phases in our model ensure that the spatial pattern of input is not correlated with the pattern of recurrent connectivity. In our selectivity analysis however (Fig. 3), we replace the random phases with spatial input patterns that are aligned with network connectivity. 2.2 PCA redux Principal component analysis (PCA) has been applied proﬁtably to neuronal recordings (see for example [14]) but these analyses often plot activity trajectories corresponding to different network states using the ﬁxed principal component coordinates derived from combined activities under all stimulus conditions. Our analysis offers a complementary approach whereby separate principal components are derived for each stimulus condition, and the resulting principal angles reveal not only the difference between the shapes of trajectories corresponding to different network states, but also the orientation of the low-dimensional subspaces these trajectories occupy within the full N -dimensional space of neuronal activity. The instantaneous network state can be described by a point in an N -dimensional space with coordinates equal to the ﬁring rates of the N units. Over time, the network activity traverses a trajectory in this N -dimensional space and PCA can be used to delineate the subspace in which this trajectory lies. The analysis is done by diagonalizing the equal-time cross-correlation matrix of network ﬁring rates given by, Dij = (ri (t) − ri )(rj (t) − rj ) , (4) where</p><p>3 0.72506875 <a title="200-lsi-3" href="./nips-2010-Attractor_Dynamics_with_Synaptic_Depression.html">34 nips-2010-Attractor Dynamics with Synaptic Depression</a></p>
<p>Author: K. Wong, He Wang, Si Wu, Chi Fung</p><p>Abstract: Neuronal connection weights exhibit short-term depression (STD). The present study investigates the impact of STD on the dynamics of a continuous attractor neural network (CANN) and its potential roles in neural information processing. We ﬁnd that the network with STD can generate both static and traveling bumps, and STD enhances the performance of the network in tracking external inputs. In particular, we ﬁnd that STD endows the network with slow-decaying plateau behaviors, namely, the network being initially stimulated to an active state will decay to silence very slowly in the time scale of STD rather than that of neural signaling. We argue that this provides a mechanism for neural systems to hold short-term memory easily and shut off persistent activities naturally.</p><p>4 0.6454761 <a title="200-lsi-4" href="./nips-2010-Short-term_memory_in_neuronal_networks_through_dynamical_compressed_sensing.html">238 nips-2010-Short-term memory in neuronal networks through dynamical compressed sensing</a></p>
<p>Author: Surya Ganguli, Haim Sompolinsky</p><p>Abstract: Recent proposals suggest that large, generic neuronal networks could store memory traces of past input sequences in their instantaneous state. Such a proposal raises important theoretical questions about the duration of these memory traces and their dependence on network size, connectivity and signal statistics. Prior work, in the case of gaussian input sequences and linear neuronal networks, shows that the duration of memory traces in a network cannot exceed the number of neurons (in units of the neuronal time constant), and that no network can out-perform an equivalent feedforward network. However a more ethologically relevant scenario is that of sparse input sequences. In this scenario, we show how linear neural networks can essentially perform compressed sensing (CS) of past inputs, thereby attaining a memory capacity that exceeds the number of neurons. This enhanced capacity is achieved by a class of “orthogonal” recurrent networks and not by feedforward networks or generic recurrent networks. We exploit techniques from the statistical physics of disordered systems to analytically compute the decay of memory traces in such networks as a function of network size, signal sparsity and integration time. Alternately, viewed purely from the perspective of CS, this work introduces a new ensemble of measurement matrices derived from dynamical systems, and provides a theoretical analysis of their asymptotic performance. 1</p><p>5 0.61677891 <a title="200-lsi-5" href="./nips-2010-Hallucinations_in_Charles_Bonnet_Syndrome_Induced_by_Homeostasis%3A_a_Deep_Boltzmann_Machine_Model.html">111 nips-2010-Hallucinations in Charles Bonnet Syndrome Induced by Homeostasis: a Deep Boltzmann Machine Model</a></p>
<p>Author: Peggy Series, David P. Reichert, Amos J. Storkey</p><p>Abstract: The Charles Bonnet Syndrome (CBS) is characterized by complex vivid visual hallucinations in people with, primarily, eye diseases and no other neurological pathology. We present a Deep Boltzmann Machine model of CBS, exploring two core hypotheses: First, that the visual cortex learns a generative or predictive model of sensory input, thus explaining its capability to generate internal imagery. And second, that homeostatic mechanisms stabilize neuronal activity levels, leading to hallucinations being formed when input is lacking. We reproduce a variety of qualitative ﬁndings in CBS. We also introduce a modiﬁcation to the DBM that allows us to model a possible role of acetylcholine in CBS as mediating the balance of feed-forward and feed-back processing. Our model might provide new insights into CBS and also demonstrates that generative frameworks are promising as hypothetical models of cortical learning and perception. 1</p><p>6 0.58793908 <a title="200-lsi-6" href="./nips-2010-Deciphering_subsampled_data%3A_adaptive_compressive_sampling_as_a_principle_of_brain_communication.html">56 nips-2010-Deciphering subsampled data: adaptive compressive sampling as a principle of brain communication</a></p>
<p>7 0.57232797 <a title="200-lsi-7" href="./nips-2010-Accounting_for_network_effects_in_neuronal_responses_using_L1_regularized_point_process_models.html">21 nips-2010-Accounting for network effects in neuronal responses using L1 regularized point process models</a></p>
<p>8 0.54008913 <a title="200-lsi-8" href="./nips-2010-Spike_timing-dependent_plasticity_as_dynamic_filter.html">253 nips-2010-Spike timing-dependent plasticity as dynamic filter</a></p>
<p>9 0.53181666 <a title="200-lsi-9" href="./nips-2010-Effects_of_Synaptic_Weight_Diffusion_on_Learning_in_Decision_Making_Networks.html">68 nips-2010-Effects of Synaptic Weight Diffusion on Learning in Decision Making Networks</a></p>
<p>10 0.52928716 <a title="200-lsi-10" href="./nips-2010-Group_Sparse_Coding_with_a_Laplacian_Scale_Mixture_Prior.html">109 nips-2010-Group Sparse Coding with a Laplacian Scale Mixture Prior</a></p>
<p>11 0.50739992 <a title="200-lsi-11" href="./nips-2010-Linear_readout_from_a_neural_population_with_partial_correlation_data.html">161 nips-2010-Linear readout from a neural population with partial correlation data</a></p>
<p>12 0.48345315 <a title="200-lsi-12" href="./nips-2010-SpikeAnts%2C_a_spiking_neuron_network_modelling_the_emergence_of_organization_in_a_complex_system.html">252 nips-2010-SpikeAnts, a spiking neuron network modelling the emergence of organization in a complex system</a></p>
<p>13 0.47393087 <a title="200-lsi-13" href="./nips-2010-The_Maximal_Causes_of_Natural_Scenes_are_Edge_Filters.html">266 nips-2010-The Maximal Causes of Natural Scenes are Edge Filters</a></p>
<p>14 0.46278942 <a title="200-lsi-14" href="./nips-2010-Learning_to_localise_sounds_with_spiking_neural_networks.html">157 nips-2010-Learning to localise sounds with spiking neural networks</a></p>
<p>15 0.45226365 <a title="200-lsi-15" href="./nips-2010-Sparse_Coding_for_Learning_Interpretable_Spatio-Temporal_Primitives.html">246 nips-2010-Sparse Coding for Learning Interpretable Spatio-Temporal Primitives</a></p>
<p>16 0.43518409 <a title="200-lsi-16" href="./nips-2010-A_biologically_plausible_network_for_the_computation_of_orientation_dominance.html">17 nips-2010-A biologically plausible network for the computation of orientation dominance</a></p>
<p>17 0.43472058 <a title="200-lsi-17" href="./nips-2010-On_the_Convexity_of_Latent_Social_Network_Inference.html">190 nips-2010-On the Convexity of Latent Social Network Inference</a></p>
<p>18 0.42892641 <a title="200-lsi-18" href="./nips-2010-Identifying_graph-structured_activation_patterns_in_networks.html">117 nips-2010-Identifying graph-structured activation patterns in networks</a></p>
<p>19 0.42598563 <a title="200-lsi-19" href="./nips-2010-Beyond_Actions%3A_Discriminative_Models_for_Contextual_Group_Activities.html">40 nips-2010-Beyond Actions: Discriminative Models for Contextual Group Activities</a></p>
<p>20 0.42159441 <a title="200-lsi-20" href="./nips-2010-Learning_Convolutional_Feature_Hierarchies_for_Visual_Recognition.html">143 nips-2010-Learning Convolutional Feature Hierarchies for Visual Recognition</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.036), (17, 0.031), (27, 0.14), (30, 0.067), (35, 0.045), (45, 0.142), (50, 0.036), (52, 0.036), (57, 0.223), (60, 0.017), (77, 0.1), (90, 0.034)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.8157897 <a title="200-lda-1" href="./nips-2010-Over-complete_representations_on_recurrent_neural_networks_can_support_persistent_percepts.html">200 nips-2010-Over-complete representations on recurrent neural networks can support persistent percepts</a></p>
<p>Author: Shaul Druckmann, Dmitri B. Chklovskii</p><p>Abstract: A striking aspect of cortical neural networks is the divergence of a relatively small number of input channels from the peripheral sensory apparatus into a large number of cortical neurons, an over-complete representation strategy. Cortical neurons are then connected by a sparse network of lateral synapses. Here we propose that such architecture may increase the persistence of the representation of an incoming stimulus, or a percept. We demonstrate that for a family of networks in which the receptive ﬁeld of each neuron is re-expressed by its outgoing connections, a represented percept can remain constant despite changing activity. We term this choice of connectivity REceptive FIeld REcombination (REFIRE) networks. The sparse REFIRE network may serve as a high-dimensional integrator and a biologically plausible model of the local cortical circuit. 1</p><p>2 0.79123372 <a title="200-lda-2" href="./nips-2010-A_Bayesian_Framework_for_Figure-Ground_Interpretation.html">3 nips-2010-A Bayesian Framework for Figure-Ground Interpretation</a></p>
<p>Author: Vicky Froyen, Jacob Feldman, Manish Singh</p><p>Abstract: Figure/ground assignment, in which the visual image is divided into nearer (ﬁgural) and farther (ground) surfaces, is an essential step in visual processing, but its underlying computational mechanisms are poorly understood. Figural assignment (often referred to as border ownership) can vary along a contour, suggesting a spatially distributed process whereby local and global cues are combined to yield local estimates of border ownership. In this paper we model ﬁgure/ground estimation in a Bayesian belief network, attempting to capture the propagation of border ownership across the image as local cues (contour curvature and T-junctions) interact with more global cues to yield a ﬁgure/ground assignment. Our network includes as a nonlocal factor skeletal (medial axis) structure, under the hypothesis that medial structure “draws” border ownership so that borders are owned by the skeletal hypothesis that best explains them. We also brieﬂy present a psychophysical experiment in which we measured local border ownership along a contour at various distances from an inducing cue (a T-junction). Both the human subjects and the network show similar patterns of performance, converging rapidly to a similar pattern of spatial variation in border ownership along contours. Figure/ground assignment (further referred to as f/g), in which the visual image is divided into nearer (ﬁgural) and farther (ground) surfaces, is an essential step in visual processing. A number of factors are known to affect f/g assignment, including region size [9], convexity [7, 16], and symmetry [1, 7, 11]. Figural assignment (often referred to as border ownership, under the assumption that the ﬁgural side “owns” the border) is usually studied globally, meaning that entire surfaces and their enclosing boundaries are assumed to receive a globally consistent ﬁgural status. But recent psychophysical ﬁndings [8] have suggested that border ownership can vary locally along a boundary, even leading to a globally inconsistent ﬁgure/ground assignment—broadly consistent with electrophysiological evidence showing local coding for border ownership in area V2 as early as 68 msec after image onset [20]. This suggests a spatially distributed and potentially competitive process of ﬁgural assignment [15], in which adjacent surfaces compete to own their common boundary, with ﬁgural status propagating across the image as this competition proceeds. But both the principles and computational mechanisms underlying this process are poorly understood. ∗ V.F. was supported by a Fullbright Honorary fellowship and by the Rutgers NSF IGERT program in Perceptual Science, NSF DGE 0549115, J.F. by NIH R01 EY15888, and M.S. by NSF CCF-0541185 1 In this paper we consider how border ownership might propagate over both space and time—that is, across the image as well as over the progression of computation. Following Weiss et al. [18] we adopt a Bayesian belief network architecture, with nodes along boundaries representing estimated border ownership, and connections arranged so that both neighboring nodes and nonlocal integrating nodes combine to inﬂuence local estimates of border ownership. Our model is novel in two particular respects: (a) we combine both local and global inﬂuences on border ownership in an integrated and principled way; and (b) we include as a nonlocal factor skeletal (medial axis) inﬂuences on f/g assignment. Skeletal structure has not been previously considered as a factor on border ownership, but its relevance follows from a model [4] in which shapes are conceived of as generated by or “grown” from an internal skeleton, with the consequence that their boundaries are perceptually “owned” by the skeletal side. We also briey present a psychophysical experiment in which we measured local border ownership along a contour, at several distances from a strong local f/g inducing cue, and at several time delays after the onset of the cue. The results show measurable spatial differences in judged border ownership, with judgments varying with distance from the inducer; but no temporal effect, with essentially asymptotic judgments even after very brief exposures. Both results are consistent with the behavior of the network, which converges quickly to an asymptotic but spatially nonuniform f/g assignment. 1 The Model The Network. For simplicity, we take an edge map as input for the model, assuming that edges and T-junctions have already been detected. From this edge map we then create a Bayesian belief network consisting of four hierarchical levels. At the input level the model receives evidence E from the image, consisting of local contour curvature and T-junctions. The nodes for this level are placed at equidistant locations along the contour. At the ﬁrst level the model estimates local border ownership. The border ownership, or B-nodes at this level are at the same locations as the E-nodes, but are connected to their nearest neighbors, and are the parent of the E-node at their location. (As a simplifying assumption, such connections are broken at T-junctions in such a way that the occluded contour is disconnected from the occluder.) The highest level has skeletal nodes, S, whose positions are deﬁned by the circumcenters of the Delaunay triangulation on all the E-nodes, creating a coarse medial axis skeleton [13]. Because of the structure of the Delaunay, each S-node is connected to exactly three E-nodes from which they receive information about the position and the local tangent of the contour. In the current state of the model the S-nodes are “passive”, meaning their posteriors are computed before the model is initiated. Between the S nodes and the B nodes are the grouping nodes G. They have the same positions as the S-nodes and the same Delaunay connections, but to B-nodes that have the same image positions as the E-nodes. They will integrate information from distant B-nodes, applying an interiority cue that is inﬂuenced by the local strength of skeletal axes as computed by the S-nodes (Fig. 1). Although this is a multiply connected network, we have found that given reasonable parameters the model converges to intuitive posteriors for a variety of shapes (see below). Updating. Our goal is to compute the posterior p(Bi |I), where I is the whole image. Bi is a binary variable coding for the local direction of border ownership, that is, the side that owns the border. In order for border ownership estimates to be inﬂuenced by image structure elsewhere in the image, information has to propagate throughout the network. To achieve this propagation, we use standard equations for node updating [14, 12]. However while to all other connections being directed, connections at the B-node level are undirected, causing each node to be child and parent node at the same time. Considering only the B-node level, a node Bi is only separated from the rest of the network by its two neighbors. Hence the Markovian property applies, in that Bi only needs to get iterative information from its neighbors to eventually compute p(Bi |I). So considering the whole network, at each iteration t, Bi receives information from both its child, Ei and from its parents—that is neigbouring nodes (Bi+1 and Bi−1 )—as well as all grouping nodes connected to it (Gj , ..., Gm ). The latter encode for interiority versus exteriority, interiority meaning that the B-node’s estimated gural direction points towards the G-node in question, exteriority meaning that it points away. Integrating all this information creates a multidimensional likelihood function: p(Bi |Bi−1 , Bi+1 , Gj , ..., Gm ). Because of its complexity we choose to approximate it (assuming all nodes are marginally independent of each other when conditioned on Bi ) by 2 Figure 1: Basic network structure of the model. Both skeletal (S-nodes) and border-ownerhsip nodes (B-nodes) get evidence from E-nodes, though different types. S-nodes receive mere positional information, while B-nodes receive information about local curvature and the presence of T-junctions. Because of the structure of the Delaunay triangulation S-nodes and G-nodes (grouping nodes) always get input from exactly three nodes, respectively E and B-nodes. The gray color depicts the fact that this part of the network is computed before the model is initiated and does not thereafter interact with the dynamics of the model. m p(Bi |Pj , ..., Pm ) ∝ p(Bi |Pj ) (1) j where the Pj ’s are the parents of Bi . Given this, at each iteration, each node Bi performs the following computation: Bel(Bi ) ← cλ(Bi )π(Bi )α(Bi )β(Bi ) (2) where conceptually λ stands for bottom-up information, π for top down information and α and β for information received from within the same level. More formally, λ(Bi ) ← p(E|Bi ) (3) m π(Bi ) ← p(Bi |Gj )πGj (Bi ) j (4) Gj and analogously to equation 4 for α(Bi ) and β(Bi ), which compute information coming from Bi−1 and Bi+1 respectively. For these πBi−1 (Bi ), πBi+1 (Bi ), and πGj (Bi ): πGj (Bi ) ← c π(G) λBk (Gj ) (5) k=i πBi−1 (Bi ) ← c β(Bi−1 )λ(Bi−1 )π(Bi−1 ) 3 (6) and πBi+1 (Bi ) is analogous to πBi−1 (Bi ), with c and c being normalization constants. Finally for the G-nodes: Bel(Gi ) ← cλ(Gi )π(Gi ) λ(Gi ) ← (7) λBj (Gi ) (8) j m λBj (Gi ) ← λ(Bj )p(Bi |Gj )[α(Bj )β(Bj ) Bj p(Bi |Gk )πGk (Bi )] (9) k=i Gk The posteriors of the S-nodes are used to compute the π(Gi ). This posterior computes how well the S-node at each position explains the contour—that is, how well it accounts for the cues ﬂowing from the E-nodes it is connected to. Each Delaunay connection between S- and E-nodes can be seen as a rib that sprouts from the skeleton. More speciﬁcally each rib sprouts in a direction that is normal (perpendicular) to the tangent of the contour at the E-node plus a random error φi chosen independently for each rib from a von Mises distribution centered on zero, i.e. φi ∼ V (0, κS ) with spread parameter κS [4]. The rib lengths are drawn from an exponential decreasing density function p(ρi ) ∝ e−λS ρi [4]. We can now express how well this node “explains” the three E-nodes it is connected to via the probability that this S-node deserves to be a skeletal node or not, p(S = true|E1 , E2 , E3 ) ∝ p(ρi )p(φi ) (10) i with S = true depicting that this S-node deserves to be a skeletal node. From this we then compute the prior π(Gi ) in such a way that good (high posterior) skeletal nodes induce a high interiority bias, hence a stronger tendency to induce ﬁgural status. Conversely, bad (low posterior) skeletal nodes create a prior close to indifferent (uniform) and thus have less (or no) inﬂuence on ﬁgural status. Likelihood functions Finally we need to express the likelihood function necessary for the updating rules described above. The ﬁrst two likelihood functions are part of p(Ei |Bi ), one for each of the local cues. The ﬁrst one, reﬂecting local curvature, gives the probability of the orientations of the two vectors inherent to Ei (α1 and α2 ) given both direction of ﬁgure (θ) encoded in Bi as a von Mises density centered on θ, i.e. αi ∼ V (θ, κEB ). The second likelihood function, reﬂecting the presence of a T-junction, simply assumes a ﬁxed likelihood when a T-junction is present—that is p(T-junction = true|Bi ) = θT , where Bi places the direction of ﬁgure in the direction of the occluder. This likelihood function is only in effect when a T-junction is present, replacing the curvature cue at that node. The third likelihood function serves to keep consistency between nodes of the ﬁrst level. This function p(Bi |Bi−1 ) or p(Bi |Bi+1 ) is used to compute α(B) and β(B) and is deﬁned 2x2 conditional probability matrix with a single free parameter, θBB (the probability that ﬁgural direction at both B-nodes are the same). A fourth and ﬁnal likelihood function p(Bi |Gj ) serves to propagate information between level one and two. This likelihood function is 2x2 conditional probability matrix matrix with one free parameter, θBG . In this case θBG encodes the probability that the ﬁgural direction of the B-node is in the direction of the exterior or interior preference of the G-node. In total this brings us to six free parameters in the model: κS , λS , κEB , θT , θBB , and θBG . 2 Basic Simulations To evaluate the performance of the model, we ﬁrst tested it on several basic stimulus conﬁgurations in which the desired outcome is intuitively clear: a convex shape, a concave shape, a pair of overlapping shapes, and a pair of non-overlapping shapes (Fig. 2,3). The convex shape is the simplest in that curvature never changes sign. The concave shape includes a region with oppositely signed curvature. (The shape is naturally described as predominantly positively curved with a region of negative curvature, i.e. a concavity. But note that it can also be interpreted as predominantly negatively curved “window” with a region of positive curvature, although this is not the intuitive interpretation.) 4 The overlapping pair of shapes consists of two convex shapes with one partly occluding the other, creating a competition between the two shapes for the ownership of the common borderline. Finally the non-overlapping shapes comprise two simple convex shapes that do not touch—again setting up a competition for ownership of the two inner boundaries (i.e. between each shape and the ground space between them). Fig. 2 shows the network structures for each of these four cases. Figure 2: Network structure for the four shape categories (left to right: convex, concave, overlapping, non-overlapping shapes). Blue depict the locations of the B-nodes (and also the E-nodes), the red connections are the connections between B-nodes, the green connections are connections between B-nodes and G-nodes, and the G-nodes (and also the S-nodes) go from orange to dark red. This colour code depicts low (orange) to high (dark red) probability that this is a skeletal node, and hence the strength of the interiority cue. Running our model with hand-estimated parameter values yields highly intuitive posteriors (Fig. 3), an essential “sanity check” to ensure that the network approximates human judgments in simple cases. For the convex shape the model assigns ﬁgure to the interior just as one would expect even based solely on local curvature (Fig. 3A). In the concave ﬁgure (Fig. 3B), estimated border ownership begins to reverse inside the deep concavity. This may seem surprising, but actually closely matches empirical results obtained when local border ownership is probed psychophysically inside a similarly deep concavity, i.e. a “negative part” in which f/g seems to partly reverse [8]. For the overlapping shapes posteriors were also intuitive, with the occluding shape interpreted as in front and owning the common border (Fig. 3C). Finally, for the two non-overlapping shapes the model computed border-ownership just as one would expect if each shape were run separately, with each shape treated as ﬁgural along its entire boundary (Fig. 3D). That is, even though there is skeletal structure in the ground-region between the two shapes (see Fig. 2D), its posterior is weak compared to the skeletal structure inside the shapes, which thus loses the competition to own the boundary between them. For all these conﬁgurations, the model not only converged to intuitive estimates but did so rapidly (Fig. 4), always in fewer cycles than would be expected by pure lateral propagation, niterations < Nnodes [18] (with these parameters, typically about ﬁve times faster). Figure 3: Posteriors after convergence for the four shape categories (left to right: convex, concave, overlapping, non-overlapping). Arrows indicate estimated border ownership, with direction pointing to the perceived ﬁgural side, and length proportional to the magnitude of the posterior. All four simulations used the same parameters. 5 Figure 4: Convergence of the model for the basic shape categories. The vertical lines represent the point of convergence for each of the three shape categories. The posterior change is calculated as |p(Bi = 1|I)t − p(Bi = 1|I)t−1 | at each iteration. 3 Comparison to human data Beyond the simple cases reviewed above, we wished to submit our network to a more ﬁne-grained comparison with human data. To this end we compared its performance to that of human subjects in an experiment we conducted (to be presented in more detail in a future paper). Brieﬂy, our experiment involved ﬁnding evidence for propagation of f/g signals across the image. Subjects were ﬁrst shown a stimulus in which the f/g conﬁguration was globally and locally unambiguous and consistent: a smaller rectangle partly occluding a larger one (Fig. 5A), meaning that the smaller (front) one owns the common border. Then this conﬁguration was perturbed by adding two bars, of which one induced a local f/g reversal—making it now appear locally that the larger rectangle owned the border (Fig. 5B). (The other bar in the display does not alter f/g interpretation, but was included to control for the attentional affects of introducing a bar in the image.) The inducing bar creates T-junctions that serve as strong local f/g cues, in this case tending to reverse the prior global interpretation of the ﬁgure. We then measured subjective border ownership along the central contour at various distances from the inducing bar, and at different times after the onset of the bar (25ms, 100ms and 250ms). We measured border ownership locally using a method introduced in [8] in which a local motion probe is introduced at a point on the boundary between two color regions of different colors, and the subject is asked which color appeared to move. Because the ﬁgural side “owns” the border, the response reﬂects perceived ﬁgural status. The goal of the experiment was to actually measure the progression of the inﬂuence of the inducing T-junction as it (hypothetically) propagated along the boundary. Brieﬂy, we found no evidence of temporal differences, meaning that f/g judgments were essentially constant over time, suggesting rapid convergence of local f/g assignment. (This is consistent with the very rapid convergence of our network, which would suggest a lack of measurable temporal differences except at much shorter time scales than we measured.) But we did ﬁnd a progressive reduction of f/g reversal with increasing distance from the inducer—that is, the inﬂuence of the T-junction decayed with distance. Mean responses aggregated over subjects (shortest delay only) are shown in Fig. 6. In order to run our model on this stimulus (which has a much more complex structure than the simple ﬁgures tested above) we had to make some adjustments. We removed the bars from the edge map, leaving only the T-junctions as underlying cues. This was a necessary ﬁrst step because our model is not yet able to cope with skeletons that are split up by occluders. (The larger rectangle’s skeleton has been split up by the lower bar.) In this way all contours except those created by the bars were used to create the network (Fig. 7). Given this network we ran the model using hand-picked parameters that 6 Figure 5: Stimuli used in the experiment. A. Initial stimulus with locally and globally consistent and unambiguous f/g. B. Subsequently bars were added of which one (the top bar in this case) created a local reversal of f/g. C. Positions at which local f/g judgments of subjects were probed. Figure 6: Results from our experiment aggregated for all 7 subjects (shortest delay only) are shown in red. The x-axis shows distance from the inducing bar at which f/g judgment was probed. The y-axis shows the proportion of trials on which subjects judged the smaller rectangle to own the boundary. As can be seen, the further from the T-junction, the lower the f/g reversal. The ﬁtted model (green curve) shows very similar pattern. Horizontal black line indicates chance performance (ambiguous f/g). gave us the best possible qualitative similarity to the human data. The parameters used never entailed total elimination of the inﬂuence of any likelihood function (κS = 16, λS = .025, κEB = .5, θT = .9, θBB = .9, and θBG = .6). As can be seen in Fig. 6 the border-ownership estimates at the locations where we had data show compelling similarities to human judgments. Furthermore along the entire contour the model converged to intuitive border-ownership estimates (Fig. 7) very rapidly (within 36 iterations). The fact that our model yielded intuitive estimates for the current network in which not all contours were completed shows another strength of our model. Because our model included grouping nodes, it did not require contours to be amodally completed [6] in order for information to propagate. 4 Conclusion In this paper we proposed a model rooted in Bayesian belief networks to compute ﬁgure/ground. The model uses both local and global cues, combined in a principled way, to achieve a stable and apparently psychologically reasonable estimate of border ownership. Local cues included local curvature and T-junctions, both well-established cues to f/g. Global cues included skeletal structure, 7 Figure 7: (left) Node structure for the experimental stimulus. (right) The model’s local borderownership estimates after convergence. a novel cue motivated by the idea that strongly axial shapes tend to be ﬁgural and thus own their boundaries. We successfully tested this model on both simple displays, in which it gave intuitive results, and on a more complex experimental stimulus, in which it gave a close match to the pattern of f/g propagation found in our subjects. Speciﬁcally, the model, like the human subjects rapidly converged to a stable local f/g interpretation. Our model’s structure shows several interesting parallels to properties of neural coding of border ownership in visual cortex. Some cortical cells (end-stopped cells) appear to code for local curvature [3] and T-junctions [5]. The B-nodes in our model could be seen as corresponding to cells that code for border ownership [20]. Furthermore, some authors [2] have suggested that recurrent feedback loops between border ownership cells in V2 and cells in V4 (corresponding to G-nodes in our model) play a role in the rapid computation of border ownership. The very rapid convergence we observed in our model likewise appears to be due to the connections between B-nodes and G-nodes. Finally scale-invariant shape representations (such as, speculatively, those based on skeletons) are thought to be present in higher cortical regions such as IT [17], which project down to earlier areas in ways that are not yet understood. A number of parallels to past models of f/g should be mentioned. Weiss [18] pioneered the application of belief networks to the f/g problem, though their network only considered a more restricted set of local cues and no global ones, such that information only propagated along the contour. Furthermore it has not been systematically compared to human judgments. Kogo et al. [10] proposed an exponential decay of f/g signals as they spread throughout the image. Our model has a similar decay for information going through the G-nodes, though it is also inﬂuenced by an angular factor deﬁned by the position of the skeletal node. Like the model by Li Zhaoping [19], our model includes horizontal propagation between B-nodes, analogous to border-ownership cells in her model. A neurophysiological model by Craft et al. [2] deﬁnes grouping cells coding for an interiority preference that decays with the size of the receptive ﬁelds of these grouping cells. Our model takes this a step further by including shape (skeletal) structure as a factor in interiority estimates, rather than simply size of receptive ﬁelds (which is similar to the rib lengths in our model). Currently, our use of skeletons as shape representations is still limited to medial axis skeletons and surfaces that are not split up by occluders. Our future goals including integrating skeletons in a more robust way following the probabilistic account suggested by Feldman and Singh [4]. Eventually, we hope to fully integrate skeleton computation with f/g computation so that the more general problem of shape and surface estimation can be approached in a coherent and uniﬁed fashion. 8 References [1] P. Bahnsen. Eine untersuchung uber symmetrie und assymmetrie bei visuellen wahrnehmungen. Zeitschrift fur psychology, 108:129–154, 1928. [2] E. Craft, H. Sch¨ tze, E. Niebur, and R. von der Heydt. A neural model of ﬁgure-ground u organization. Journal of Neurophysiology, 97:4310–4326, 2007. [3] A. Dobbins, S. W. Zucker, and M. S. Cyander. Endstopping and curvature. Vision Research, 29:1371–1387, 1989. [4] J. Feldman and M. Singh. Bayesian estimation of the shape skeleton. Proceedings of the National Academy of Sciences, 103:18014–18019, 2006. [5] B. Heider, V. Meskenaite, and E. Peterhans. Anatomy and physiology of a neural mechanism deﬁning depth order and contrast polarity at illusory contours. European Journal of Neuroscience, 12:4117–4130, 2000. [6] G. Kanizsa. Organization inVision. New York: Praeger, 1979. [7] G. Kanizsa and W. Gerbino. Vision and Artifact, chapter Convexity and symmetry in ﬁgureground organisation, pages 25–32. New York: Springer, 1976. [8] S. Kim and J. Feldman. Globally inconsistent ﬁgure/ground relations induced by a negative part. Journal of Vision, 9:1534–7362, 2009. [9] K. Koffka. Principles of Gestalt Psychology. Lund Humphries, London, 1935. [10] N. Kogo, C. Strecha, L. Van Gool, and J. Wagemans. Surface construction by a 2-d differentiation-integration process: a neurocomputational model for perceived border ownership, depth, and lightness in kanizsa ﬁgures. Psychological Review, 117:406–439, 2010. [11] B. Machielsen, M. Pauwels, and J. Wagemans. The role of vertical mirror-symmetry in visual shape detection. Journal of Vision, 9:1–11, 2009. [12] K. Murphy, Y. Weiss, and M.I. Jordan. Loopy belief propagation for approximate inference: an empirical study. Proceedings of Uncertainty in AI, pages 467–475, 1999. [13] R. L. Ogniewicz and O. K¨ bler. Hierarchic Voronoi skeletons. Pattern Recognition, 28:343– u 359, 1995. [14] J. Pearl. Probabilistic reasoning in intelligent systems: networks of plausible inference. Morgan Kaufmann, 1988. [15] M. A. Peterson and E. Skow. Inhibitory competition between shape properties in ﬁgureground perception. Journal of Experimental Psychology: Human Perception and Performance, 34:251–267, 2008. [16] K. A. Stevens and A. Brookes. The concave cusp as a determiner of ﬁgure-ground. Perception, 17:35–42, 1988. [17] K. Tanaka, H. Saito, Y. Fukada, and M. Moriya. Coding visual images of object in the inferotemporal cortex of the macaque monkey. Journal of Neurophysiology, 66:170–189, 1991. [18] Y. Weiss. Interpreting images by propagating Bayesian beliefs. Adv. in Neural Information Processing Systems, 9:908915, 1997. [19] L. Zhaoping. Border ownership from intracortical interactions in visual area V2. Neuron, 47(1):143–153, Jul 2005. [20] H. Zhou, H. S. Friedman, and R. von der Heydt. Coding of border ownerschip in monkey visual cortex. The Journal of Neuroscience, 20:6594–6611, 2000. 9</p><p>3 0.69443792 <a title="200-lda-3" href="./nips-2010-Evaluating_neuronal_codes_for_inference_using_Fisher_information.html">81 nips-2010-Evaluating neuronal codes for inference using Fisher information</a></p>
<p>Author: Haefner Ralf, Matthias Bethge</p><p>Abstract: Many studies have explored the impact of response variability on the quality of sensory codes. The source of this variability is almost always assumed to be intrinsic to the brain. However, when inferring a particular stimulus property, variability associated with other stimulus attributes also effectively act as noise. Here we study the impact of such stimulus-induced response variability for the case of binocular disparity inference. We characterize the response distribution for the binocular energy model in response to random dot stereograms and ﬁnd it to be very different from the Poisson-like noise usually assumed. We then compute the Fisher information with respect to binocular disparity, present in the monocular inputs to the standard model of early binocular processing, and thereby obtain an upper bound on how much information a model could theoretically extract from them. Then we analyze the information loss incurred by the different ways of combining those inputs to produce a scalar single-neuron response. We ﬁnd that in the case of depth inference, monocular stimulus variability places a greater limit on the extractable information than intrinsic neuronal noise for typical spike counts. Furthermore, the largest loss of information is incurred by the standard model for position disparity neurons (tuned-excitatory), that are the most ubiquitous in monkey primary visual cortex, while more information from the inputs is preserved in phase-disparity neurons (tuned-near or tuned-far) primarily found in higher cortical regions. 1</p><p>4 0.6915825 <a title="200-lda-4" href="./nips-2010-Linear_readout_from_a_neural_population_with_partial_correlation_data.html">161 nips-2010-Linear readout from a neural population with partial correlation data</a></p>
<p>Author: Adrien Wohrer, Ranulfo Romo, Christian K. Machens</p><p>Abstract: How much information does a neural population convey about a stimulus? Answers to this question are known to strongly depend on the correlation of response variability in neural populations. These noise correlations, however, are essentially immeasurable as the number of parameters in a noise correlation matrix grows quadratically with population size. Here, we suggest to bypass this problem by imposing a parametric model on a noise correlation matrix. Our basic assumption is that noise correlations arise due to common inputs between neurons. On average, noise correlations will therefore reﬂect signal correlations, which can be measured in neural populations. We suggest an explicit parametric dependency between signal and noise correlations. We show how this dependency can be used to ”ﬁll the gaps” in noise correlations matrices using an iterative application of the Wishart distribution over positive deﬁnitive matrices. We apply our method to data from the primary somatosensory cortex of monkeys performing a two-alternativeforced choice task. We compare the discrimination thresholds read out from the population of recorded neurons with the discrimination threshold of the monkey and show that our method predicts different results than simpler, average schemes of noise correlations. 1</p><p>5 0.6912114 <a title="200-lda-5" href="./nips-2010-Accounting_for_network_effects_in_neuronal_responses_using_L1_regularized_point_process_models.html">21 nips-2010-Accounting for network effects in neuronal responses using L1 regularized point process models</a></p>
<p>Author: Ryan Kelly, Matthew Smith, Robert Kass, Tai S. Lee</p><p>Abstract: Activity of a neuron, even in the early sensory areas, is not simply a function of its local receptive ﬁeld or tuning properties, but depends on global context of the stimulus, as well as the neural context. This suggests the activity of the surrounding neurons and global brain states can exert considerable inﬂuence on the activity of a neuron. In this paper we implemented an L1 regularized point process model to assess the contribution of multiple factors to the ﬁring rate of many individual units recorded simultaneously from V1 with a 96-electrode “Utah” array. We found that the spikes of surrounding neurons indeed provide strong predictions of a neuron’s response, in addition to the neuron’s receptive ﬁeld transfer function. We also found that the same spikes could be accounted for with the local ﬁeld potentials, a surrogate measure of global network states. This work shows that accounting for network ﬂuctuations can improve estimates of single trial ﬁring rate and stimulus-response transfer functions. 1</p><p>6 0.68566132 <a title="200-lda-6" href="./nips-2010-Inferring_Stimulus_Selectivity_from_the_Spatial_Structure_of_Neural_Network_Dynamics.html">127 nips-2010-Inferring Stimulus Selectivity from the Spatial Structure of Neural Network Dynamics</a></p>
<p>7 0.67437053 <a title="200-lda-7" href="./nips-2010-Functional_Geometry_Alignment_and_Localization_of_Brain_Areas.html">97 nips-2010-Functional Geometry Alignment and Localization of Brain Areas</a></p>
<p>8 0.6708377 <a title="200-lda-8" href="./nips-2010-The_Neural_Costs_of_Optimal_Control.html">268 nips-2010-The Neural Costs of Optimal Control</a></p>
<p>9 0.66927469 <a title="200-lda-9" href="./nips-2010-Bayesian_Action-Graph_Games.html">39 nips-2010-Bayesian Action-Graph Games</a></p>
<p>10 0.66675478 <a title="200-lda-10" href="./nips-2010-Functional_form_of_motion_priors_in_human_motion_perception.html">98 nips-2010-Functional form of motion priors in human motion perception</a></p>
<p>11 0.66616338 <a title="200-lda-11" href="./nips-2010-Short-term_memory_in_neuronal_networks_through_dynamical_compressed_sensing.html">238 nips-2010-Short-term memory in neuronal networks through dynamical compressed sensing</a></p>
<p>12 0.66553289 <a title="200-lda-12" href="./nips-2010-A_biologically_plausible_network_for_the_computation_of_orientation_dominance.html">17 nips-2010-A biologically plausible network for the computation of orientation dominance</a></p>
<p>13 0.66221207 <a title="200-lda-13" href="./nips-2010-A_Primal-Dual_Algorithm_for_Group_Sparse_Regularization_with_Overlapping_Groups.html">12 nips-2010-A Primal-Dual Algorithm for Group Sparse Regularization with Overlapping Groups</a></p>
<p>14 0.66098529 <a title="200-lda-14" href="./nips-2010-Improving_Human_Judgments_by_Decontaminating_Sequential_Dependencies.html">121 nips-2010-Improving Human Judgments by Decontaminating Sequential Dependencies</a></p>
<p>15 0.65697616 <a title="200-lda-15" href="./nips-2010-Deciphering_subsampled_data%3A_adaptive_compressive_sampling_as_a_principle_of_brain_communication.html">56 nips-2010-Deciphering subsampled data: adaptive compressive sampling as a principle of brain communication</a></p>
<p>16 0.65599608 <a title="200-lda-16" href="./nips-2010-The_Maximal_Causes_of_Natural_Scenes_are_Edge_Filters.html">266 nips-2010-The Maximal Causes of Natural Scenes are Edge Filters</a></p>
<p>17 0.65546489 <a title="200-lda-17" href="./nips-2010-A_rational_decision_making_framework_for_inhibitory_control.html">19 nips-2010-A rational decision making framework for inhibitory control</a></p>
<p>18 0.65493649 <a title="200-lda-18" href="./nips-2010-Brain_covariance_selection%3A_better_individual_functional_connectivity_models_using_population_prior.html">44 nips-2010-Brain covariance selection: better individual functional connectivity models using population prior</a></p>
<p>19 0.65215474 <a title="200-lda-19" href="./nips-2010-Individualized_ROI_Optimization_via_Maximization_of_Group-wise_Consistency_of_Structural_and_Functional_Profiles.html">123 nips-2010-Individualized ROI Optimization via Maximization of Group-wise Consistency of Structural and Functional Profiles</a></p>
<p>20 0.65177155 <a title="200-lda-20" href="./nips-2010-Identifying_graph-structured_activation_patterns_in_networks.html">117 nips-2010-Identifying graph-structured activation patterns in networks</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
