<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>156 nips-2009-Monte Carlo Sampling for Regret Minimization in Extensive Games</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-156" href="../nips2009/nips-2009-Monte_Carlo_Sampling_for_Regret_Minimization_in_Extensive_Games.html">nips2009-156</a> <a title="nips-2009-156-reference" href="#">nips2009-156-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>156 nips-2009-Monte Carlo Sampling for Regret Minimization in Extensive Games</h1>
<br/><p>Source: <a title="nips-2009-156-pdf" href="http://papers.nips.cc/paper/3713-monte-carlo-sampling-for-regret-minimization-in-extensive-games.pdf">pdf</a></p><p>Author: Marc Lanctot, Kevin Waugh, Martin Zinkevich, Michael Bowling</p><p>Abstract: Sequential decision-making with multiple agents and imperfect information is commonly modeled as an extensive game. One efﬁcient method for computing Nash equilibria in large, zero-sum, imperfect information games is counterfactual regret minimization (CFR). In the domain of poker, CFR has proven effective, particularly when using a domain-speciﬁc augmentation involving chance outcome sampling. In this paper, we describe a general family of domain-independent CFR sample-based algorithms called Monte Carlo counterfactual regret minimization (MCCFR) of which the original and poker-speciﬁc versions are special cases. We start by showing that MCCFR performs the same regret updates as CFR on expectation. Then, we introduce two sampling schemes: outcome sampling and external sampling, showing that both have bounded overall regret with high probability. Thus, they can compute an approximate equilibrium using self-play. Finally, we prove a new tighter bound on the regret for the original CFR algorithm and relate this new bound to MCCFR’s bounds. We show empirically that, although the sample-based algorithms require more iterations, their lower cost per iteration can lead to dramatically faster convergence in various games. 1</p><br/>
<h2>reference text</h2><p>[1] Martin Zinkevich, Michael Johanson, Michael Bowling, and Carmelo Piccione. Regret minimization in games with incomplete information. In Advances in Neural Information Processing Systems 20 (NIPS), 2008.</p>
<p>[2] Andrew Gilpin, Samid Hoda, Javier Pe˜ a, and Tuomas Sandholm. Gradient-based algorithms n for ﬁnding Nash equilibria in extensive form games. In 3rd International Workshop on Internet and Network Economics (WINE’07), 2007.</p>
<p>[3] D. Koller, N. Megiddo, and B. von Stengel. Fast algorithms for ﬁnding randomized strategies in game trees. In Proceedings of the 26th ACM Symposium on Theory of Computing (STOC ’94), pages 750–759, 1994.</p>
<p>[4] Martin Zinkevich, Michael Johanson, Michael Bowling, and Carmelo Piccione. Regret minimization in game with incomplete information. Technical Report TR07-14, University of Alberta, 2007. http://www.cs.ualberta.ca/research/techreports/2007/ TR07-14.php.</p>
<p>[5] Geoffrey J. Gordon. No-regret algorithms for online convex programs. In In Neural Information Processing Systems 19, 2007.</p>
<p>[6] Martin J. Osborne and Ariel Rubinstein. A Course in Game Theory. MIT Press, 1994.</p>
<p>[7] Sergiu Hart and Andreu Mas-Colell. A simple adaptive procedure leading to correlated equilibrium. Econometrica, 68(5):1127–1150, September 2000.</p>
<p>[8] D. Blackwell. An analog of the minimax theorem for vector payoffs. Paciﬁc Journal of Mathematics, 6:1–8, 1956.</p>
<p>[9] Peter Auer, Nicol` Cesa-Bianchi, Yoav Freund, and Robert E. Schapire. Gambling in a rigged o casino: The adversarial multi-arm bandit problem. In 36th Annual Symposium on Foundations of Computer Science, pages 322–331, 1995.</p>
<p>[10] Marc Lanctot, Kevin Waugh, Martin Zinkevich, and Michael Bowling. Monte carlo sampling for regret minimization in extensive games. Technical Report TR09-15, University of Alberta, 2009. http://www.cs.ualberta.ca/research/techreports/2009/ TR09-15.php.</p>
<p>[11] S. M. Ross. Goofspiel — the game of pure strategy. Journal of Applied Probability, 8(3):621– 625, 1971.</p>
<p>[12] Geoffrey J. Gordon. No-regret algorithms for structured prediction problems. Technical Report CMU-CALD-05-112, Carnegie Mellon University, 2005.</p>
<p>[13] H. W. Kuhn. Simpliﬁed two-person poker. Contributions to the Theory of Games, 1:97–103, 1950.</p>
<p>[14] Rufus Isaacs. Differential Games: A Mathematical Theory with Applications to Warfare and Pursuit, Control and Optimization. John Wiley & Sons, 1965.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
