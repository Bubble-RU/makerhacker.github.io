<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>179 nips-2009-On the Algorithmics and Applications of a Mixed-norm based Kernel Learning Formulation</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-179" href="../nips2009/nips-2009-On_the_Algorithmics_and_Applications_of_a_Mixed-norm_based_Kernel_Learning_Formulation.html">nips2009-179</a> <a title="nips-2009-179-reference" href="#">nips2009-179-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>179 nips-2009-On the Algorithmics and Applications of a Mixed-norm based Kernel Learning Formulation</h1>
<br/><p>Source: <a title="nips-2009-179-pdf" href="http://papers.nips.cc/paper/3880-on-the-algorithmics-and-applications-of-a-mixed-norm-based-kernel-learning-formulation.pdf">pdf</a></p><p>Author: Saketha N. Jagarlapudi, Dinesh G, Raman S, Chiranjib Bhattacharyya, Aharon Ben-tal, Ramakrishnan K.r.</p><p>Abstract: Motivated from real world problems, like object categorization, we study a particular mixed-norm regularization for Multiple Kernel Learning (MKL). It is assumed that the given set of kernels are grouped into distinct components where each component is crucial for the learning task at hand. The formulation hence employs l∞ regularization for promoting combinations at the component level and l1 regularization for promoting sparsity among kernels in each component. While previous attempts have formulated this as a non-convex problem, the formulation given here is an instance of non-smooth convex optimization problem which admits an efﬁcient Mirror-Descent (MD) based procedure. The MD procedure optimizes over product of simplexes, which is not a well-studied case in literature. Results on real-world datasets show that the new MKL formulation is well-suited for object categorization tasks and that the MD based algorithm outperforms stateof-the-art MKL solvers like simpleMKL in terms of computational effort. 1</p><br/>
<h2>reference text</h2><p>[1] F. Bach, G. R. G. Lanckriet, and M. I. Jordan. Multiple Kernel Learning, Conic Duality, and the SMO Algorithm. In International Conference on Machine Learning, 2004.</p>
<p>[2] Amir Beck and Marc Teboulle. Mirror descent and nonlinear projected subgradient methods for convex optimization. Operations Research Letters, 31:167–175, 2003.</p>
<p>[3] Aharon Ben-Tal, Tamar Margalit, and Arkadi Nemirovski. The Ordered Subsets Mirror Descent Optimization Method with Applications to Tomography. SIAM Journal of Optimization, 12(1):79–108, 2001.</p>
<p>[4] Aharon Ben-Tal and Arkadi Nemirovski. Non-euclidean Restricted Memory Level Method for Large-scale Convex Optimization. Mathematical Programming, 102(3):407–456, 2005.</p>
<p>[5] O. Chapelle, V. Vapnik, O. Bousquet, and S. Mukerjhee. Choosing multiple parameters for SVM. Machine Learning, 46:131–159, 2002.</p>
<p>[6] R. Fergus, P. Perona, and A. Zisserman. Object class recognition by unsupervised scaleinvariant learning. In IEEE Computer Society Conference on Computer Vision and Pattern Recognition, volume 2, 2003.</p>
<p>[7] R. Fergus L. Fei-Fei and P. Perona. Learning generative visual models from few training examples: an incremental bayesian approach tested on 101 object categories. In IEEE. CVPR 2004, Workshop on Generative-Model Based Vision., 2004.</p>
<p>[8] G.R.G. Lanckriet, N. Cristianini, P. Bartlett, L. El Ghaoui, and M.I. Jordan. Learning the Kernel Matrix with Semideﬁnite Programming. Journal of Machine Learning Research, 5:27– 72, 2004.</p>
<p>[9] Arkadi Nemirovski. Lectures on modern convex optimization (chp.5.4). Available at www2. isye.gatech.edu/˜nemirovs/Lect_ModConvOpt.pdf.</p>
<p>[10] M-E. Nilsback and A. Zisserman. A visual vocabulary for ﬂower classiﬁcation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2006.</p>
<p>[11] M-E. Nilsback and A Zisserman. Automated ﬂower classiﬁcation over a large number of classes. In Proceedings of the Indian Conference on Computer Vision, Graphics and Image Processing, 2008.</p>
<p>[12] Maria-Elena Nilsback and Andrew Zisserman. A Visual Vocabulary for Flower Classiﬁcation. In Proceedings of the 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, volume 2, pages 1447–1454, 2006.</p>
<p>[13] Maria-Elena Nilsback and Andrew Zisserman. Automated Flower Classiﬁcation over a Large Number of Classes. In Proceedings of the Sixth Indian Conference on Computer Vision, Graphics & Image Processing, 2008.</p>
<p>[14] A. Rakotomamonjy, F. Bach, S. Canu, and Y Grandvalet. SimpleMKL. Journal of Machine Learning Research, 9:2491–2521, 2008.</p>
<p>[15] R. T. Rockafellar. Convex Analysis. Princeton University Press, 1970.</p>
<p>[16] Soren Sonnenburg, Gunnar Ratsch, Christin Schafer, and Bernhard Scholkopf. Large Scale Multiple Kernel Learning. Journal of Machine Learning Research, 7:1531–1565, 2006.</p>
<p>[17] M. Szafranski, Y. Grandvalet, and A. Rakotomamonjy. Composite Kernel Learning. In Proceedings of the Twenty-ﬁfth International Conference on Machine Learning (ICML), 2008.</p>
<p>[18] Vladimir Vapnik. Statistical Learning Theory. Wiley-Interscience, 1998.</p>
<p>[19] M. Varma and D. Ray. Learning the Discriminative Power Invariance Trade-off. In Proceedings of the International Conference on Computer Vision, 2007.</p>
<p>[20] Zenglin Xu, Rong Jin, Irwin King, and Michael R. Lyu. An Extended Level Method for Multiple Kernel Learning. In Advances in Neural Information Processing Systems, 2008.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
