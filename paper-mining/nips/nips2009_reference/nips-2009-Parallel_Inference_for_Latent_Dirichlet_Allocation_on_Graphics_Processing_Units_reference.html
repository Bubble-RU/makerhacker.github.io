<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>186 nips-2009-Parallel Inference for Latent Dirichlet Allocation on Graphics Processing Units</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-186" href="../nips2009/nips-2009-Parallel_Inference_for_Latent_Dirichlet_Allocation_on_Graphics_Processing_Units.html">nips2009-186</a> <a title="nips-2009-186-reference" href="#">nips2009-186-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>186 nips-2009-Parallel Inference for Latent Dirichlet Allocation on Graphics Processing Units</h1>
<br/><p>Source: <a title="nips-2009-186-pdf" href="http://papers.nips.cc/paper/3788-parallel-inference-for-latent-dirichlet-allocation-on-graphics-processing-units.pdf">pdf</a></p><p>Author: Feng Yan, Ningyi Xu, Yuan Qi</p><p>Abstract: The recent emergence of Graphics Processing Units (GPUs) as general-purpose parallel computing devices provides us with new opportunities to develop scalable learning methods for massive data. In this work, we consider the problem of parallelizing two inference methods on GPUs for latent Dirichlet Allocation (LDA) models, collapsed Gibbs sampling (CGS) and collapsed variational Bayesian (CVB). To address limited memory constraints on GPUs, we propose a novel data partitioning scheme that effectively reduces the memory cost. This partitioning scheme also balances the computational cost on each multiprocessor and enables us to easily avoid memory access conﬂicts. We use data streaming to handle extremely large datasets. Extensive experiments showed that our parallel inference methods consistently produced LDA models with the same predictive power as sequential training methods did but with 26x speedup for CGS and 196x speedup for CVB on a GPU with 30 multiprocessors. The proposed partitioning scheme and data streaming make our approach scalable with more multiprocessors. Furthermore, they can be used as general techniques to parallelize other machine learning models. 1</p><br/>
<h2>reference text</h2><p>[1] A. Asuncion, P. Smyth, and M. Welling. Asynchronous distributed learning of topic models. In D. Koller, D. Schuurmans, Y. Bengio, and L. Bottou, editors, NIPS, pages 81–88. MIT Press, 2008.</p>
<p>[2] A. Asuncion, M. Welling, P. Smyth, and Y. W. Teh. On smoothing and inference for topic models. In Proceedings of the International Conference on Uncertainty in Artiﬁcial Intelligence, 2009.</p>
<p>[3] S. Boyd and L. Vandenberghe. Convex Optimization. Cambridge University Press, March 2004.</p>
<p>[4] T. L. Grifﬁths and M. Steyvers. Finding scientiﬁc topics. Proceedings of the National Academy Science, 101 (suppl. 1):5228–5235, April 2004.</p>
<p>[5] F. Labonte, P. Mattson, W. Thies, I. Buck, C. Kozyrakis, and M. Horowitz. The stream virtual machine. In PACT ’04: Proceedings of the 13th International Conference on Parallel Architectures and Compilation Techniques, pages 267–277, Washington, DC, USA, 2004. IEEE Computer Society.</p>
<p>[6] T. Masada, T. Hamada, Y. Shibata, and K. Oguri. Accelerating collapsed variational bayesian inference for latent Dirichlet allocation with Nvidia CUDA compatible devices. In IEA-AIE, 2009.</p>
<p>[7] R. Nallapati, W. Cohen, and J. Lafferty. Parallelized variational EM for latent Dirichlet allocation: An experimental evaluation of speed and scalability. 2007.</p>
<p>[8] D. Newman, A. Asuncion, P. Smyth, and M. Welling. Distributed inference for latent Dirichlet allocation. In NIPS, 2007.</p>
<p>[9] Y. W. Teh, D. Newman, and M. Welling. A collapsed variational Bayesian inference algorithm for Latent Dirichlet allocation. In B. Sch¨ lkopf, J. C. Platt, and T. Hoffman, editors, NIPS, pages o 1353–1360. MIT Press, 2006.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
