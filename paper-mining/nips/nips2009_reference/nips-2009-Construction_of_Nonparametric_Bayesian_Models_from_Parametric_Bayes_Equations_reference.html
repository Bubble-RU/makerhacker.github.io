<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>59 nips-2009-Construction of Nonparametric Bayesian Models from Parametric Bayes Equations</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-59" href="../nips2009/nips-2009-Construction_of_Nonparametric_Bayesian_Models_from_Parametric_Bayes_Equations.html">nips2009-59</a> <a title="nips-2009-59-reference" href="#">nips2009-59-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>59 nips-2009-Construction of Nonparametric Bayesian Models from Parametric Bayes Equations</h1>
<br/><p>Source: <a title="nips-2009-59-pdf" href="http://papers.nips.cc/paper/3737-construction-of-nonparametric-bayesian-models-from-parametric-bayes-equations.pdf">pdf</a></p><p>Author: Peter Orbanz</p><p>Abstract: We consider the general problem of constructing nonparametric Bayesian models on inﬁnite-dimensional random objects, such as functions, inﬁnite graphs or inﬁnite permutations. The problem has generated much interest in machine learning, where it is treated heuristically, but has not been studied in full generality in nonparametric Bayesian statistics, which tends to focus on models over probability distributions. Our approach applies a standard tool of stochastic process theory, the construction of stochastic processes from their ﬁnite-dimensional marginal distributions. The main contribution of the paper is a generalization of the classic Kolmogorov extension theorem to conditional probabilities. This extension allows a rigorous construction of nonparametric Bayesian models from systems of ﬁnitedimensional, parametric Bayes equations. Using this approach, we show (i) how existence of a conjugate posterior for the nonparametric model can be guaranteed by choosing conjugate ﬁnite-dimensional models in the construction, (ii) how the mapping to the posterior parameters of the nonparametric model can be explicitly determined, and (iii) that the construction of conjugate models in essence requires the ﬁnite-dimensional models to be in the exponential family. As an application of our constructive framework, we derive a model on inﬁnite permutations, the nonparametric Bayesian analogue of a model recently proposed for the analysis of rank data. 1</p><br/>
<h2>reference text</h2><p>[1] H. Bauer. Probability Theory. W. de Gruyter, 1996.</p>
<p>[2] M. J. Beal, Z. Ghahramani, and C. E. Rasmussen. The inﬁnite hidden Markov model. In Advances in Neural Information Processing Systems, 2001.</p>
<p>[3] P. Billingsley. Probability and measure, 1995.</p>
<p>[4] S. R. Dalal and W. J. Hall. Approximating priors by mixtures of natural conjugate priors. Annals of Statistics, 45(2):278–286, 1983.</p>
<p>[5] T. S. Ferguson. A Bayesian analysis of some nonparametric problems. Annals of Statistics, 1(2), 1973.</p>
<p>[6] M. A. Fligner and J. S. Verducci. Distance based ranking models. Journal of the Royal Statistical Society B, 48(3):359–369, 1986.</p>
<p>[7] J. K. Ghosh and R. V. Ramamoorthi. Bayesian Nonparametrics. Springer, 2002.</p>
<p>[8] T. L. Grifﬁths and Z. Ghahramani. Inﬁnite latent feature models and the Indian buffet process. In Advances in Neural Information Processing Systems, 2005.</p>
<p>[9] M. Meil˘ and L. Bao. Estimation and clustering with inﬁnite rankings. In Uncertainty in a Artiﬁcial Intelligence, 2008.</p>
<p>[10] M. M. Rao. Conditional Measures and Applications. Chapman & Hall, second edition, 2005.</p>
<p>[11] C. E. Rasmussen and C. K. I. Williams. Gaussian Processes for Machine Learning. MIT Press, 2006.</p>
<p>[12] C. P. Robert. The Bayesian Choice. Springer, 1994.</p>
<p>[13] D. M. Roy and Y. W. Teh. The Mondrian process. In Advances in Neural Information Processing Systems, 2009.</p>
<p>[14] M. J. Schervish. Theory of Statistics. Springer, 1995.</p>
<p>[15] Y. W. Teh, M. I. Jordan, M. J. Beal, and D. M. Blei. Hierarchical Dirichlet processes. Journal of the American Statistical Association, (476):1566–1581, 2006.</p>
<p>[16] S. G. Walker, P. Damien, P. W. Laud, and A. F. M. Smith. Bayesian nonparametric inference for random distributions and related functions. Journal of the Royal Statistical Society B, 61(3):485–527, 1999.</p>
<p>[17] L. Wasserman. All of Nonparametric Statistics. Springer, 2006.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
