<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>14 nips-2009-A Parameter-free Hedging Algorithm</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-14" href="../nips2009/nips-2009-A_Parameter-free_Hedging_Algorithm.html">nips2009-14</a> <a title="nips-2009-14-reference" href="#">nips2009-14-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>14 nips-2009-A Parameter-free Hedging Algorithm</h1>
<br/><p>Source: <a title="nips-2009-14-pdf" href="http://papers.nips.cc/paper/3883-a-parameter-free-hedging-algorithm.pdf">pdf</a></p><p>Author: Kamalika Chaudhuri, Yoav Freund, Daniel J. Hsu</p><p>Abstract: We study the problem of decision-theoretic online learning (DTOL). Motivated by practical applications, we focus on DTOL when the number of actions is very large. Previous algorithms for learning in this framework have a tunable learning rate parameter, and a barrier to using online-learning in practical applications is that it is not understood how to set this parameter optimally, particularly when the number of actions is large. In this paper, we offer a clean solution by proposing a novel and completely parameter-free algorithm for DTOL. We introduce a new notion of regret, which is more natural for applications with a large number of actions. We show that our algorithm achieves good performance with respect to this new notion of regret; in addition, it also achieves performance close to that of the best bounds achieved by previous algorithms with optimally-tuned parameters, according to previous notions of regret. 1</p><br/>
<h2>reference text</h2><p>[1] Y. Freund and R. E. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. Journal of Computer and System Sciences, 55:119–139, 1997.</p>
<p>[2] N. Littlestone and M. Warmuth. The weighted majority algorithm. Information and Computation, 108:212–261, 1994.</p>
<p>[3] V. Vovk. A game of prediction witih expert advice. Journal of Computer and System Sciences, 56(2):153– 173, 1998.</p>
<p>[4] K. Chaudhuri, Y. Freund, and D. Hsu. arXiv:0903.2862.  Tracking using explanation-based modeling, 2009.</p>
<p>[5] Y. Freund and R. E. Schapire. Adaptive game playing using multiplicative weights. Games and Economic Behavior, 29:79–103, 1999.</p>
<p>[6] P. Auer, N. Cesa-Bianchi, and C. Gentile. Adaptive and self-conﬁdent on-line learning algorithms. Journal of Computer and System Sciences, 64(1), 2002.</p>
<p>[7] N. Cesa-Bianchi, Y. Mansour, and G. Stoltz. Improved second-order bounds for prediction with expert advice. Machine Learning, 66(2–3):321–352, 2007.</p>
<p>[8] N. Cesa-Bianchi and G. Lugosi. Potential-based algorithms in on-line prediction and game theory. Machine Learning, 51:239–261, 2003.</p>
<p>[9] N. Cesa-Bianchi and G. Lugosi. Prediction, Learning and Games. Cambridge University Press, 2006.</p>
<p>[10] E. Hazan and S. Kale. Extracting certainty from uncertainty: Regret bounded by variation in costs. In COLT, 2008.</p>
<p>[11] C. Gentile. The robustness of p-norm algorithms. Machine Learning, 53(3):265–299, 2003.</p>
<p>[12] A. J. Grove, N. Littlestone, and D. Schuurmans. General convergence results for linear discriminant updates. Machine Learning, 43(3):173–210, 2001.</p>
<p>[13] N. Cesa-Bianchi, Y. Freund, D. Haussler, D. P. Hembold, R. E. Schapire, and M. Warmuth. How to use expert advice. Journal of the ACM, 44(3):427–485, 1997.</p>
<p>[14] R. Yaroshinsky, R. El-Yaniv, , and S. Seiden. How to better use expert advice. Machine Learning, 55(3):271–309, 2004.</p>
<p>[15] M. Hutter and J. Poland. Adaptive online prediction by following the perturbed leader. Journal of Machine Learning Research, 6:639–660, 2005.</p>
<p>[16] J. Hannan. Approximation to bayes risk in repeated play. Contributions to the Theory of Games, 3:97– 139, 1957.</p>
<p>[17] A. Kalai and S. Vempala. Efﬁcient algorithms for the online optimization. Journal of Computer and System Sciences, 71(3):291–307, 2005.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
