<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>57 nips-2009-Conditional Random Fields with High-Order Features for Sequence Labeling</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-57" href="../nips2009/nips-2009-Conditional_Random_Fields_with_High-Order_Features_for_Sequence_Labeling.html">nips2009-57</a> <a title="nips-2009-57-reference" href="#">nips2009-57-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>57 nips-2009-Conditional Random Fields with High-Order Features for Sequence Labeling</h1>
<br/><p>Source: <a title="nips-2009-57-pdf" href="http://papers.nips.cc/paper/3815-conditional-random-fields-with-high-order-features-for-sequence-labeling.pdf">pdf</a></p><p>Author: Nan Ye, Wee S. Lee, Hai L. Chieu, Dan Wu</p><p>Abstract: Dependencies among neighbouring labels in a sequence is an important source of information for sequence labeling problems. However, only dependencies between adjacent labels are commonly exploited in practice because of the high computational complexity of typical inference algorithms when longer distance dependencies are taken into account. In this paper, we show that it is possible to design efﬁcient inference algorithms for a conditional random ﬁeld using features that depend on long consecutive label sequences (high-order features), as long as the number of distinct label sequences used in the features is small. This leads to efﬁcient learning algorithms for these conditional random ﬁelds. We show experimentally that exploiting dependencies using high-order features can lead to substantial performance improvements for some problems and discuss conditions under which high-order features can be effective. 1</p><br/>
<h2>reference text</h2><p>[1] B. A. Cipra, “The Ising model is NP-complete,” SIAM News, vol. 33, no. 6, 2000.</p>
<p>[2] A. Culotta, D. Kulp, and A. McCallum, “Gene prediction with conditional random ﬁelds,” University of Massachusetts, Amherst, Tech. Rep. UM-CS-2005-028, 2005.</p>
<p>[3] T. G. Dietterich, A. Ashenfelter, and Y. Bulatov, “Training conditional random ﬁelds via gradient tree boosting,” in Proceedings of the Twenty-First International Conference on Machine Learning, 2004.</p>
<p>[4] S. Fine, Y. Singer, and N. Tishby, “The hierarchical hidden markov model: Analysis and applications,” Machine Learning, vol. 32, no. 1, pp. 41–62, 1998.</p>
<p>[5] C. Huang and A. Darwiche, “Inference in belief networks: A procedural guide,” International Journal of Approximate Reasoning, vol. 15, no. 3, pp. 225–263, 1996.</p>
<p>[6] F. Jelinek, J. D. Lafferty, and R. L. Mercer, “Basic methods of probabilistic context free grammars,” in Speech Recognition and Understanding. Recent Advances, Trends, and Applications. Springer Verlag, 1992.</p>
<p>[7] R. H. Kassel, “A comparison of approaches to on-line handwritten character recognition,” Ph.D. dissertation, Massachusetts Institute of Technology, Cambridge, MA, USA, 1995.</p>
<p>[8] J. Lafferty, A. McCallum, and F. Pereira, “Conditional random ﬁelds: Probabilistic models for segmenting and labeling sequence data,” in Proceedings of the Eighteenth International Conference on Machine Learning, 2001, pp. 282–289.</p>
<p>[9] Linguistic Data Consortium, “ACE (Automatic Content Extraction) English Annotation Guidelines for Entities,” 2005.</p>
<p>[10] K. P. Murphy and M. A. Paskin, “Linear-time inference in hierarchical HMMs,” in Advances in Neural Information Processing Systems 14, vol. 14, 2002.</p>
<p>[11] X. Qian, X. Jiang, Q. Zhang, X. Huang, and L. Wu, “Sparse higher order conditional random ﬁelds for improved sequence labeling,” in ICML, 2009, p. 107.</p>
<p>[12] L. R. Rabiner, A tutorial on hidden Markov models and selected applications in speech recognition. San Francisco, CA, USA: Morgan Kaufmann Publishers Inc., 1990.</p>
<p>[13] S. Sarawagi and W. W. Cohen, “Semi-Markov conditional random ﬁelds for information extraction,” in Advances in Neural Information Processing Systems 17. Cambridge, MA: MIT Press, 2005, pp. 1185–1192.</p>
<p>[14] F. Sha and F. Pereira, “Shallow parsing with conditional random ﬁelds,” in Proceedings of the Twentieth International Conference on Machine Learning, 2003, pp. 282–289.</p>
<p>[15] B. Taskar, C. Guestrin, and D. Koller, “Max-margin Markov networks,” in Advances in Neural Information Processing Systems 16. Cambridge, MA: MIT Press, 2004.</p>
<p>[16] E. Tjong and F. D. Meulder, “Introduction to the CoNLL-2003 shared task: Languageindependent named entity recognition,” in Proceedings of Conference on Computational Natural Language Learning, 2003.</p>
<p>[17] T. T. Tran, D. Phung, H. Bui, and S. Venkatesh, “Hierarchical semi-Markov conditional random ﬁelds for recursive sequential data,” in NIPS’08: Advances in Neural Information Processing Systems 20. Cambridge, MA: MIT Press, 2008, pp. 1657–1664.</p>
<p>[18] I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun, “Support vector machine learning for interdependent and structured output spaces,” in Proceedings of the Twenty-First international conference on Machine learning, 2004, pp. 104–112.</p>
<p>[19] G. Wahba, Spline models for observational data, ser. CBMS-NSF Regional Conference Series in Applied Mathematics. Philadelphia, PA: Society for Industrial and Applied Mathematics (SIAM), 1990, vol. 59.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
