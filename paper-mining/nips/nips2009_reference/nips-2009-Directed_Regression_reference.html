<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>67 nips-2009-Directed Regression</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-67" href="../nips2009/nips-2009-Directed_Regression.html">nips2009-67</a> <a title="nips-2009-67-reference" href="#">nips2009-67-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>67 nips-2009-Directed Regression</h1>
<br/><p>Source: <a title="nips-2009-67-pdf" href="http://papers.nips.cc/paper/3686-directed-regression.pdf">pdf</a></p><p>Author: Yi-hao Kao, Benjamin V. Roy, Xiang Yan</p><p>Abstract: When used to guide decisions, linear regression analysis typically involves estimation of regression coefﬁcients via ordinary least squares and their subsequent use to make decisions. When there are multiple response variables and features do not perfectly capture their relationships, it is beneﬁcial to account for the decision objective when computing regression coefﬁcients. Empirical optimization does so but sacriﬁces performance when features are well-chosen or training data are insufﬁcient. We propose directed regression, an efﬁcient algorithm that combines merits of ordinary least squares and empirical optimization. We demonstrate through a computational study that directed regression can generate signiﬁcant performance gains over either alternative. We also develop a theory that motivates the algorithm. 1</p><br/>
<h2>reference text</h2><p>[1] J.-Y. Audibert. Aggregated estimators and empirical complexity for least square regression. Annales de l’Institut Henri Poincare Probability and Statistics, 40(6):685–736, 2004.</p>
<p>[2] P. L. Bartlett and S. Mendelson. Empirical minimization. Probability Theory and Related Fields, 135(3):311–334, 2006.</p>
<p>[3] D. Bertsimas and A. Thiele. Robust and data-driven optimization: Modern decision-making under uncertainty. In Tutorials on Operations Research. INFORMS, 2006.</p>
<p>[4] O. Besbes, R. Philips, and A. Zeevi. Testing the validity of a demand model: An operations perspective. 2007.</p>
<p>[5] F. Bunea, A. B. Tsybakov, and M. H. Wegkamp. Aggregation for Gaussian regression. The Annals of Statistics, 35(4):1674–1697, 2007.</p>
<p>[6] D. Haussler. Decision theoretic generalizations of the PAC model for neural net and other learning applications. Information and Computation, 100:78–150, 1992.</p>
<p>[7] K. Kim and N. Timm. Univariate and Multivariate General Linear Models: Theory and Applications with SAS. Chapman & Hall/CRC, 2006.</p>
<p>[8] K. E. Muller and P. W. Stewart. Linear Model Theory: Univariate, Multivariate, and Mixed Models. Wiley, 2006.</p>
<p>[9] R. S. Sutton and A. G. Barto. Reinforcement Learning: An Introduction. MIT Press, Cambridge, MA, 1998.</p>
<p>[10] R. Tibshirani. Regression shrinkage and selection via the lasso. Journal of Royal Statistical Society, 1996.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
