<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>172 nips-2009-Nonparametric Bayesian Texture Learning and Synthesis</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-172" href="../nips2009/nips-2009-Nonparametric_Bayesian_Texture_Learning_and_Synthesis.html">nips2009-172</a> <a title="nips-2009-172-reference" href="#">nips2009-172-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>172 nips-2009-Nonparametric Bayesian Texture Learning and Synthesis</h1>
<br/><p>Source: <a title="nips-2009-172-pdf" href="http://papers.nips.cc/paper/3729-nonparametric-bayesian-texture-learning-and-synthesis.pdf">pdf</a></p><p>Author: Long Zhu, Yuanahao Chen, Bill Freeman, Antonio Torralba</p><p>Abstract: We present a nonparametric Bayesian method for texture learning and synthesis. A texture image is represented by a 2D Hidden Markov Model (2DHMM) where the hidden states correspond to the cluster labeling of textons and the transition matrix encodes their spatial layout (the compatibility between adjacent textons). The 2DHMM is coupled with the Hierarchical Dirichlet process (HDP) which allows the number of textons and the complexity of transition matrix grow as the input texture becomes irregular. The HDP makes use of Dirichlet process prior which favors regular textures by penalizing the model complexity. This framework (HDP-2DHMM) learns the texton vocabulary and their spatial layout jointly and automatically. The HDP-2DHMM results in a compact representation of textures which allows fast texture synthesis with comparable rendering quality over the state-of-the-art patch-based rendering methods. We also show that the HDP2DHMM can be applied to perform image segmentation and synthesis. The preliminary results suggest that HDP-2DHMM is generally useful for further applications in low-level vision problems. 1</p><br/>
<h2>reference text</h2><p>[1] Y. N. Wu, S. C. Zhu, and C.-e. Guo, “Statistical modeling of texture sketch,” in ECCV ’02: Proceedings of the 7th European Conference on Computer Vision-Part III, 2002, pp. 240–254.</p>
<p>[2] S.-C. Zhu, C.-E. Guo, Y. Wang, and Z. Xu, “What are textons?” International Journal of Computer Vision, vol. 62, no. 1-2, pp. 121–143, 2005.</p>
<p>[3] A. A. Efros and W. T. Freeman, “Image quilting for texture synthesis and transfer,” in Siggraph, 2001.</p>
<p>[4] A. Efros and T. Leung, “Texture synthesis by non-parametric sampling,” in International Conference on Computer Vision, 1999, pp. 1033–1038.</p>
<p>[5] Y. W. Teh, M. I. Jordan, M. J. Beal, and D. M. Blei, “Hierarchical dirichlet processes,” Journal of the American Statistical Association, 2006.</p>
<p>[6] M. J. Beal, Z. Ghahramani, and C. E. Rasmussen, “The inﬁnite hidden markov model,” in NIPS, 2002.</p>
<p>[7] S. C. Zhu, Y. Wu, and D. Mumford, “Filters, random ﬁelds and maximum entropy (frame): Towards a uniﬁed theory for texture modeling,” International Journal of Computer Vision, vol. 27, pp. 1–20, 1998.</p>
<p>[8] A. Criminisi, P. Perez, and K. Toyama, “Region ﬁlling and object removal by exemplar-based inpainting,” IEEE Trans. on Image Processing, 2004.</p>
<p>[9] J. Malik, S. Belongie, J. Shi, and T. Leung, “Textons, contours and regions: Cue integration in image segmentation,” IEEE International Conference on Computer Vision, vol. 2, 1999.</p>
<p>[10] T. Leung and J. Malik, “Representing and recognizing the visual appearance of materials using three-dimensional textons,” International Journal of Computer Vision, vol. 43, pp. 29–44, 2001.</p>
<p>[11] M. Varma and A. Zisserman, “Texture classiﬁcation: Are ﬁlter banks necessary?” IEEE Computer Society Conference on Computer Vision and Pattern Recognition, vol. 2, 2003.</p>
<p>[12] Y. Liu, W.-C. Lin, and J. H. Hays, “Near regular texture analysis and manipulation,” ACM Transactions on Graphics (SIGGRAPH 2004), vol. 23, no. 1, pp. 368 – 376, August 2004.</p>
<p>[13] J. Hays, M. Leordeanu, A. A. Efros, and Y. Liu, “Discovering texture regularity as a higherorder correspondence problem,” in 9th European Conference on Computer Vision, May 2006.</p>
<p>[14] N. Jojic, B. J. Frey, and A. Kannan, “Epitomic analysis of appearance and shape,” in In ICCV, 2003, pp. 34–41.</p>
<p>[15] A. Kannan, J. Winn, and C. Rother, “Clustering appearance and shape by learning jigsaws,” in In Advances in Neural Information Processing Systems. MIT Press, 2007.</p>
<p>[16] J. J. Kivinen, E. B. Sudderth, and M. I. Jordan, “Learning multiscale representations of natural scenes using dirichlet processes,” IEEE International Conference on Computer Vision, vol. 0, 2007.</p>
<p>[17] J. Domke, A. Karapurkar, and Y. Aloimonos, “Who killed the directed model?” in IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2008.</p>
<p>[18] L. Cao and L. Fei-Fei, “Spatially coherent latent topic model for concurrent object segmentation and classiﬁcation,” in Proceedings of IEEE International Conference on Computer Vision, 2007.</p>
<p>[19] X. Wang and E. Grimson, “Spatial latent dirichlet allocation,” in NIPS, 2007.</p>
<p>[20] L.-Y. Wei and M. Levoy, “Fast texture synthesis using tree-structured vector quantization,” in SIGGRAPH ’00: Proceedings of the 27th annual conference on Computer graphics and interactive techniques, 2000, pp. 479–488.</p>
<p>[21] J. Winn, A. Criminisi, and T. Minka, “Object categorization by learned universal visual dictionary,” in Proceedings of the Tenth IEEE International Conference on Computer Vision, 2005.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
