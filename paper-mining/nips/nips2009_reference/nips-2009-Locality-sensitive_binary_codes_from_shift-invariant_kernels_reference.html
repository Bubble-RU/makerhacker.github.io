<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>142 nips-2009-Locality-sensitive binary codes from shift-invariant kernels</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-142" href="../nips2009/nips-2009-Locality-sensitive_binary_codes_from_shift-invariant_kernels.html">nips2009-142</a> <a title="nips-2009-142-reference" href="#">nips2009-142-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>142 nips-2009-Locality-sensitive binary codes from shift-invariant kernels</h1>
<br/><p>Source: <a title="nips-2009-142-pdf" href="http://papers.nips.cc/paper/3749-locality-sensitive-binary-codes-from-shift-invariant-kernels.pdf">pdf</a></p><p>Author: Maxim Raginsky, Svetlana Lazebnik</p><p>Abstract: This paper addresses the problem of designing binary codes for high-dimensional data such that vectors that are similar in the original space map to similar binary strings. We introduce a simple distribution-free encoding scheme based on random projections, such that the expected Hamming distance between the binary codes of two vectors is related to the value of a shift-invariant kernel (e.g., a Gaussian kernel) between the vectors. We present a full theoretical analysis of the convergence properties of the proposed scheme, and report favorable experimental performance as compared to a recent state-of-the-art method, spectral hashing.</p><br/>
<h2>reference text</h2><p>[1] A. Andoni and P. Indyk. Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions. Commun. ACM, 51(1):117–122, 2008.</p>
<p>[2] K. Clarkson. Nearest-neighbor searching and metric space dimensions. In Nearest-Neighbor Methods for Learning and Vision: Theory and Practice, pages 15–59. MIT Press, 2006.</p>
<p>[3] S. Dasgupta and Y. Freund. Random projection trees and low dimensional manifolds. In STOC, 2008.</p>
<p>[4] S. Dasgupta and A. Gupta. An elementary proof of a theorem of Johnson and Lindenstrauss. Random Struct. Alg., 22(1):60–65, 2003.</p>
<p>[5] J. Heinonen. Lectures on Analysis on Metric Spaces. Springer, New York, 2001.</p>
<p>[6] P. Indyk and A. Naor. Nearest-neighbor-preserving embeddings. ACM Trans. Algorithms, 3(3):Art. 31, 2007.</p>
<p>[7] A. Oliva and A. Torralba. Modeling the shape of the scene: a holistic representation of the spatial envelope. Int. J. Computer Vision, 42(3):145–175, 2001.</p>
<p>[8] A. Rahimi and B. Recht. Random features for large-scale kernel machines. In NIPS, 2007.</p>
<p>[9] M. Reed and B. Simon. Methods of Modern Mathematical Physics II: Fourier Analysis, Self-Adjointness. Academic Press, 1975.</p>
<p>[10] B. Russell, A. Torralba, K. Murphy, and W. T. Freeman. LabelMe: a database and web-based tool for image annotation. Int. J. Computer Vision, 77:157–173, 2008.</p>
<p>[11] R. Salakhutdinov and G. Hinton. Semantic hashing. In SIGIR Workshop on Inf. Retrieval and App. of Graphical Models, 2007.</p>
<p>[12] B. Sch¨ lkopf and A. J. Smola. Learning With Kernels. MIT Press, 2002. o</p>
<p>[13] A. Torralba, R. Fergus, and Y. Weiss. Small codes and large databases for recognition. In CVPR, 2008.</p>
<p>[14] A. W. van der Vaart and J. A. Wellner. Weak Convergence and Empirical Processes. Springer, 1996.</p>
<p>[15] Y. Weiss, A. Torralba, and R. Fergus. Spectral hashing. In NIPS, 2008.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
