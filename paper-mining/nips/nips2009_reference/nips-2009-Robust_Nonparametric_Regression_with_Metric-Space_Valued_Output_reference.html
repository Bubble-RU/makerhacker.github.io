<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>207 nips-2009-Robust Nonparametric Regression with Metric-Space Valued Output</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-207" href="../nips2009/nips-2009-Robust_Nonparametric_Regression_with_Metric-Space_Valued_Output.html">nips2009-207</a> <a title="nips-2009-207-reference" href="#">nips2009-207-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>207 nips-2009-Robust Nonparametric Regression with Metric-Space Valued Output</h1>
<br/><p>Source: <a title="nips-2009-207-pdf" href="http://papers.nips.cc/paper/3649-robust-nonparametric-regression-with-metric-space-valued-output.pdf">pdf</a></p><p>Author: Matthias Hein</p><p>Abstract: Motivated by recent developments in manifold-valued regression we propose a family of nonparametric kernel-smoothing estimators with metric-space valued output including several robust versions. Depending on the choice of the output space and the metric the estimator reduces to partially well-known procedures for multi-class classiﬁcation, multivariate regression in Euclidean space, regression with manifold-valued output and even some cases of structured output learning. In this paper we focus on the case of regression with manifold-valued input and output. We show pointwise and Bayes consistency for all estimators in the family for the case of manifold-valued output and illustrate the robustness properties of the estimators with experiments. 1</p><br/>
<h2>reference text</h2><p>[1] I. Tsochantaridis, T. Joachims, T. Hofmann, and Y. Altun. Large margin methods for structured and interdependent output variables. JMLR, 6:1453–1484, 2005.</p>
<p>[2] J. Weston, G. BakIr, O. Bousquet, B. Sch¨ lkopf, T. Mann, and W. S. Noble. Joint kernel maps. o In Predicting Structured Data, pages 67–84. MIT Press, 2007.</p>
<p>[3] E. Ricci, T. De Bie, and N. Cristianini. Magic moments for structured output prediction. JMLR, 9:2803–2846, 2008.</p>
<p>[4] K.V. Mardia and P.E. Jupp. Directional statistics. Wiley New York, 2000.</p>
<p>[5] Inam Ur Rahman, Iddo Drori, Victoria C. Stodden, David L. Donoho, and Peter Schroder. Multiscale representations for manifold-valued data. Multiscale Modeling and Simulation, 4(4):1201–1232, 2005.</p>
<p>[6] B. C. Davis, P. T. Fletcher, E. Bullitt, and S. Joshi. Population shape regression from random design data. Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference on, pages 1–7, 2007.</p>
<p>[7] F. Steinke and M. Hein. Non-parametric regression between Riemannian manifolds. In Advances in Neural Information Processing Systems (NIPS) 21, pages 1561 – 1568, 2009.</p>
<p>[8] P. T. Fletcher, S. Venkatasubramanian, and S. Joshi. The geometric median on Riemannian manifolds with application to robust atlas estimation. NeuroImage, 45:143 – 152, 2009.</p>
<p>[9] C. G. Small. A survey of multidimensional medians. International Statistical Review, 58:263– 277, 1990.</p>
<p>[10] D. Blackwell and M. Maitra. Factorization of probability measures and absolutely measurable sets. Proc. Amer. Math. Soc., 92(2):251–254, 1984.</p>
<p>[11] R. Bhattacharya and V. Patrangenaru. Large sample theory of intrinsic and extrinsic sample means on manifolds I. Ann. Stat., 31(1):1–29, 2003.</p>
<p>[12] H. Karcher. Riemannian center of mass and molliﬁer smoothing. Communications on Pure and Applied Mathematics, 30:509–541, 1977.</p>
<p>[13] W. Kendall. Probability, convexity, and harmonic maps with small image. I. Uniqueness and ﬁne existence. Proc. London Math. Soc., 61(2):371–406, 1990.</p>
<p>[14] P. Indyk. Sublinear time algorithms for metric space problems. In Proceedings of the 31st Symposium on Theory of computing (STOC), pages 428 – 434, 1999.</p>
<p>[15] L. Gy¨ rﬁ, M. Kohler, A. Krzy˙ ak, and H. Walk. A Distribution-Free Theory of Nonparametric o z Regression. Springer, New York, 2004.</p>
<p>[16] W. Greblicki and M. Pawlak. Nonparametric System Identiﬁcation. Cambridge University Press, Cambrige, 2008.</p>
<p>[17] B. Pelletier. Nonparametric regression estimation on closed Riemannian manifolds. J. of Nonparametric Stat., 18:57–67, 2006.</p>
<p>[18] S. Dabo-Niang and N. Rhomari. Estimation non parametrique de la regression avec variable explicative dans un espace metrique. C. R. Math. Acad. Sci. Paris, 1:75–80, 2003.</p>
<p>[19] D. P. Bertsekas. Nonlinear Programming. Athena Scientiﬁc, Belmont, Mass., 1999.</p>
<p>[20] M. Hein. Uniform convergence of adaptive graph-based regularization. In G. Lugosi and H. Simon, editors, Proc. of the 19th Conf. on Learning Theory (COLT), pages 50–64, Berlin, 2006. Springer.</p>
<p>[21] N. Glick. Consistency conditions for probability estimators and integrals of density estimators. Utilitas Math., 6:61–74, 1974.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
