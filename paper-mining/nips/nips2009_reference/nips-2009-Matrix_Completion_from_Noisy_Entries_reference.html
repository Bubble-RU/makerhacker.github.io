<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>147 nips-2009-Matrix Completion from Noisy Entries</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-147" href="../nips2009/nips-2009-Matrix_Completion_from_Noisy_Entries.html">nips2009-147</a> <a title="nips-2009-147-reference" href="#">nips2009-147-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>147 nips-2009-Matrix Completion from Noisy Entries</h1>
<br/><p>Source: <a title="nips-2009-147-pdf" href="http://papers.nips.cc/paper/3777-matrix-completion-from-noisy-entries.pdf">pdf</a></p><p>Author: Raghunandan Keshavan, Andrea Montanari, Sewoong Oh</p><p>Abstract: Given a matrix M of low-rank, we consider the problem of reconstructing it from noisy observations of a small, random subset of its entries. The problem arises in a variety of applications, from collaborative ﬁltering (the ‘Netﬂix problem’) to structure-from-motion and positioning. We study a low complexity algorithm introduced in [1], based on a combination of spectral techniques and manifold optimization, that we call here O PT S PACE. We prove performance guarantees that are order-optimal in a number of circumstances. 1</p><br/>
<h2>reference text</h2><p>[1] R. H. Keshavan, A. Montanari, and S. Oh. Matrix completion from a few entries. arXiv:0901.3150, January 2009.</p>
<p>[2] A. Frieze, R. Kannan, and S. Vempala. Fast monte-carlo algorithms for ﬁnding low-rank approximations. J. ACM, 51(6):1025–1041, 2004.</p>
<p>[3] E. J. Cand` s and B. Recht. e Exact matrix completion via convex optimization. arxiv:0805.4471, 2008.</p>
<p>[4] M. Fazel. Matrix Rank Minimization with Applications. PhD thesis, Stanford University, 2002.</p>
<p>[5] E. J. Cand` s and T. Tao. The power of convex relaxation: Near-optimal matrix completion. e arXiv:0903.1476, 2009.</p>
<p>[6] J-F Cai, E. J. Cand` s, and Z. Shen. A singular value thresholding algorithm for matrix come pletion. arXiv:0810.3286, 2008.</p>
<p>[7] S. Ma, D. Goldfarb, and L. Chen. Fixed point and Bregman iterative methods for matrix rank minimization. arXiv:0905.1643, 2009.</p>
<p>[8] K. Toh and S. Yun. An accelerated proximal gradient algorithm for nuclear norm regularized least squares problems. http://www.math.nus.edu.sg/∼matys, 2009.</p>
<p>[9] J. Wright, A. Ganesh, S. Rao, and Y. Ma. Robust principal component analysis: Exact recovery of corrupted low-rank matrices. arXiv:0905.0233, 2009.</p>
<p>[10] K. Lee and Y. Bresler. Admira: Atomic decomposition for minimum rank approximation. arXiv:0905.0044, 2009.</p>
<p>[11] E. J. Cand` s and Y. Plan. Matrix completion with noise. arXiv:0903.3131, 2009. e</p>
<p>[12] A. Edelman, T. A. Arias, and S. T. Smith. The geometry of algorithms with orthogonality constraints. SIAM J. Matr. Anal. Appl., 20:303–353, 1999.</p>
<p>[13] P.-A. Absil, R. Mahony, and R. Sepulchrer. Optimization Algorithms on Matrix Manifolds. Princeton University Press, 2008.</p>
<p>[14] D. Achlioptas and F. McSherry. Fast computation of low-rank matrix approximations. J. ACM, 54(2):9, 2007.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
