<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>139 nips-2009-Linear-time Algorithms for Pairwise Statistical Problems</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-139" href="../nips2009/nips-2009-Linear-time_Algorithms_for_Pairwise_Statistical_Problems.html">nips2009-139</a> <a title="nips-2009-139-reference" href="#">nips2009-139-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>139 nips-2009-Linear-time Algorithms for Pairwise Statistical Problems</h1>
<br/><p>Source: <a title="nips-2009-139-pdf" href="http://papers.nips.cc/paper/3796-linear-time-algorithms-for-pairwise-statistical-problems.pdf">pdf</a></p><p>Author: Parikshit Ram, Dongryeol Lee, William March, Alexander G. Gray</p><p>Abstract: Several key computational bottlenecks in machine learning involve pairwise distance computations, including all-nearest-neighbors (ďŹ nding the nearest neighbor(s) for each point, e.g. in manifold learning) and kernel summations (e.g. in kernel density estimation or kernel machines). We consider the general, bichromatic case for these problems, in addition to the scientiďŹ c problem of N-body simulation. In this paper we show for the ďŹ rst time O(đ?&lsquo;  ) worst case runtimes for practical algorithms for these problems based on the cover tree data structure [1]. 1</p><br/>
<h2>reference text</h2><p>[1] A. Beygelzimer, S. Kakade, and J.C. Langford. Cover Trees for Nearest Neighbor. Proceedings of the 23rd International Conference on Machine learning, pages 97â&euro;&ldquo;104, 2006.</p>
<p>[2] J. H. Freidman, J. L. Bentley, and R. A. Finkel. An Algorithm for Finding Best Matches in Logarithmic Expected Time. ACM Trans. Math. Softw., 3(3):209â&euro;&ldquo;226, September 1977.</p>
<p>[3] K. Deng and A. W. Moore. Multiresolution Instance-Based Learning. pages 1233â&euro;&ldquo;1242.</p>
<p>[4] D. Lee and A. G. Gray. Faster Gaussian Summation: Theory and Experiment. In Proceedings of the Twenty-second Conference on Uncertainty in ArtiďŹ cial Intelligence. 2006.</p>
<p>[5] J. Barnes and P. Hut. A Hierarchical đ?&lsquo;&sbquo;(đ?&lsquo;  log đ?&lsquo;  ) Force-Calculation Algorithm. Nature, 324, 1986.</p>
<p>[6] D. R. Karger and M. Ruhl. Finding Nearest Neighbors in Growth-Restricted Metrics. Proceedings of the Thiry-Fourth Annual ACM Symposium on Theory of Computing, pages 741â&euro;&ldquo;750, 2002.</p>
<p>[7] L. Greengard and V. Rokhlin. A Fast Algorithm for Particle Simulations. Journal of Computational Physics, 73:325â&euro;&ldquo;248, 1987.</p>
<p>[8] A. G. Gray and A. W. Moore. â&euro;&tilde;đ?&lsquo;  -Bodyâ&euro;&trade; Problems in Statistical Learning. In NIPS, volume 4, pages 521â&euro;&ldquo;527, 2000.</p>
<p>[9] A. G. Gray and A. W. Moore. Nonparametric Density Estimation: Toward Computational Tractability. In SIAM International Conference on Data Mining, 2003.</p>
<p>[10] D. Lee, A. G. Gray, and A. W. Moore. Dual-Tree Fast Gauss Transforms. In Y. Weiss, B. SchÂ¨ lkopf, and J. Platt, editors, Advances in Neural Information Processing Systems 18, o pages 747â&euro;&ldquo;754. MIT Press, Cambridge, MA, 2006.</p>
<p>[11] D. Lee and A. G. Gray. Fast High-dimensional Kernel Summations Using the Monte Carlo Multipole Method. In To appear in Advances in Neural Information Processing Systems 21. 2009.</p>
<p>[12] S. Aluru, G. M. Prabhu, and J. Gustafson. Truly distribution-independent algorithms for the N-body problem. In Proceedings of the 1994 conference on Supercomputing, pages 420â&euro;&ldquo;428. IEEE Computer Society Press Los Alamitos, CA, USA, 1994.</p>
<p>[13] P. B. Callahan. Dealing with Higher Dimensions: the Well-Separated Pair Decomposition and its applications. PhD thesis, Johns Hopkins University, Baltimore, Maryland, 1995.</p>
<p>[14] P. B. Callahan and S. R. Kosaraju. A Decomposition of Multidimensional Point Sets with Applications to k-Nearest-Neighbors and n-body Potential Fields. Journal of the ACM, 62(1):67â&euro;&ldquo; 90, January 1995.</p>
<p>[15] A. Beygelzimer, S. Kakade, and J.C. Langford. Cover trees for Nearest Neighbor. 2006. http://hunch.net/Ë&oelig;jl/projects/cover tree/paper/paper.ps.</p>
<p>[16] R. D. Skeel, I. Tezcan, and D. J. Hardy. Multiple Grid Methods for Classical Molecular Dynamics. Journal of Computational Chemistry, 23(6):673â&euro;&ldquo;684, 2002.</p>
<p>[17] A. G. Gray and A. W. Moore. Rapid Evaluation of Multiple Density Models. In ArtiďŹ cial Intelligence and Statistics 2003, 2003.</p>
<p>[18] A. G. Gray and A. W. Moore. Very Fast Multivariate Kernel Density Estimation via Computational Geometry. In Joint Statistical Meeting 2003, 2003. to be submitted to JASA.</p>
<p>[19] R. Krauthgamer and J. R. Lee. Navigating Nets: Simple Algorithms for Proximity Search. 15th Annual ACM-SIAM Symposium on Discrete Algorithms, pages 791â&euro;&ldquo;801, 2004.</p>
<p>[20] K. Clarkson. Fast Algorithms for the All Nearest Neighbors Problem. In Proceedings of the Twenty-fourth Annual IEEE Symposium on the Foundations of Computer Science, pages 226â&euro;&ldquo;232, 1983.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
