<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>23 nips-2009-Accelerating Bayesian Structural Inference for Non-Decomposable Gaussian Graphical Models</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-23" href="../nips2009/nips-2009-Accelerating_Bayesian_Structural_Inference_for_Non-Decomposable_Gaussian_Graphical_Models.html">nips2009-23</a> <a title="nips-2009-23-reference" href="#">nips2009-23-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>23 nips-2009-Accelerating Bayesian Structural Inference for Non-Decomposable Gaussian Graphical Models</h1>
<br/><p>Source: <a title="nips-2009-23-pdf" href="http://papers.nips.cc/paper/3827-accelerating-bayesian-structural-inference-for-non-decomposable-gaussian-graphical-models.pdf">pdf</a></p><p>Author: Baback Moghaddam, Emtiyaz Khan, Kevin P. Murphy, Benjamin M. Marlin</p><p>Abstract: We make several contributions in accelerating approximate Bayesian structural inference for non-decomposable GGMs. Our ﬁrst contribution is to show how to efﬁciently compute a BIC or Laplace approximation to the marginal likelihood of non-decomposable graphs using convex methods for precision matrix estimation. This optimization technique can be used as a fast scoring function inside standard Stochastic Local Search (SLS) for generating posterior samples. Our second contribution is a novel framework for efﬁciently generating large sets of high-quality graph topologies without performing local search. This graph proposal method, which we call “Neighborhood Fusion” (NF), samples candidate Markov blankets at each node using sparse regression techniques. Our third contribution is a hybrid method combining the complementary strengths of NF and SLS. Experimental results in structural recovery and prediction tasks demonstrate that NF and hybrid NF/SLS out-perform state-of-the-art local search methods, on both synthetic and real-world datasets, when realistic computational limits are imposed.</p><br/>
<h2>reference text</h2><p>[1] H. Armstrong. Bayesian Estimation of Decomposable GGMs. PhD thesis, UNSW, 2005.</p>
<p>[2] H. Armstrong, C. Carter, K. Wong, and R. Kohn. Bayesian covariance matrix estimation using a mixture of decomposable graphical models. Statistics and Computing, 2008.</p>
<p>[3] A. Atay-Kayis and H. Massam. A Monte Carlo method for computing the marginal likelihood in nondecomposable Gaussian graphical models. Biometrika, 92, 2005.</p>
<p>[4] O. Banerjee, L. El Ghaoui, A. d’Aspremont, and G. Natsoulis. Convex optimization techniques for ﬁtting sparse Gaussian graphical models. In Intl. Conf. on Machine Learning, 2006.</p>
<p>[5] J. Besag. Efﬁciency of pseudo-likelihood estimation for simple Gaussian ﬁelds. Biometrika, 1977.</p>
<p>[6] R. Byrd, P. Lu, J. Nocedal, and C. Zhu. A limited memory algorithm for bound constrained optimization. SIAM J. of Scientiﬁc & Statistical Computing, 16(5), 1995.</p>
<p>[7] C. Chow and C. Liu. Approximating discrete probability distributions with dependence trees. IEEE Trans. on Info. Theory, 14, 1968.</p>
<p>[8] P. Dellaportas, P. Giudici, and G. Roberts. Bayesian inference for nondecomposable graphical Gaussian models. Sankhya, Ser. A, 65, 2003.</p>
<p>[9] A. Dempster. Covariance selection. Biometrics, 28(1), 1972.</p>
<p>[10] P. Diaconis and D. Ylvisaker. Conjugate priors for exponential families. Annals of statistics, 7(2), 1979.</p>
<p>[11] D. Dobra, C. Hans, B. Jones, J. Nevins, G. Yao, and M. West. Sparse graphical models for exploring gene expression data. J. Multivariate analysis, 90, 2004.</p>
<p>[12] J. Domke, A. Karapurkar, and Y. Aloimonos. Who killed the directed model? In CVPR, 2008.</p>
<p>[13] J. Duchi, S. Gould, and D. Koller. Projected subgradients for learning sparse Gaussians. In UAI, 2008.</p>
<p>[14] D. Eaton and K. Murphy. Bayesian structure learning using DP and MCMC. In UAI, 2007.</p>
<p>[15] J. Friedman, T. Hastie, and R. Tibshirani. Sparse inverse covariance estimation in Glasso. Biostats, 2007.</p>
<p>[16] N. Friedman and D. Koller. Being Bayesian about network structure: A Bayesian approach to structure discovery in Bayesian networks. Machine Learning, 50, 2003.</p>
<p>[17] P. Giudici and P. Green. Decomposable graphical Gaussian model determination. Biometrika, 1999.</p>
<p>[18] T. Hastie, R. Tibshirani, and J. Friedman. The Elements of Statistical Learning. Springer, 2009.</p>
<p>[19] D. Heckerman, D. Geiger, and M. Chickering. Learning Bayesian networks: the combination of knowledge and statistical data. Machine Learning, 20(3), 1995.</p>
<p>[20] B. Jones, C. Carvalho, A. Dobra, C. Hans, C. Carter, and M. West. Experiments in stochastic computation for high-dimensional graphical models. Statistical Science, 20, 2005.</p>
<p>[21] A. Lenkoski and A. Dobra. Bayesian structural learning and estimation in Gaussian graphical models. Technical Report 545, Department of Statistics, University of Washington, 2008.</p>
<p>[22] D. Madigan and A. Raftery. Model selection and accounting for model uncertainty in graphical models using Occam’s window. J. of the Am. Stat. Assoc., 89, 1994.</p>
<p>[23] N. Meinshausen and P. Buhlmann. High dimensional graphs and variable selection with the Lasso. The Annals of Statistics, 2006.</p>
<p>[24] B. Moghaddam, A. Gruber, Y. Weiss, and S. Avidan. Sparse regression as a sparse eigenvalue problem. In Information Theory & Applications Workshop (ITA’08), 2008.</p>
<p>[25] B. Moghaddam, Y. Weiss, and S. Avidan. Spectral bounds for sparse PCA: Exact & greedy algorithms. In NIPS, 2006.</p>
<p>[26] A. Raftery. Bayesian model selection in social research. Sociological Methodology, 25, 1995.</p>
<p>[27] A. Roverato. Hyper inverse Wishart distribution for non-decomposable graphs and its application to Bayesian inference for Gaussian graphical models. Scand. J. Statistics, 29, 2002.</p>
<p>[28] M. Schmidt, A Niculescu-Mizil, and K Murphy. Learning graphical model structure using l 1 regularization paths. In AAAI, 2007.</p>
<p>[29] J. Scott and C. Carvalho. Feature-inclusion stochastic search for Gaussian graphical models. J. of Computational and Graphical Statistics, 17(4), 2008.</p>
<p>[30] T. Speed and H. Kiiveri. Gaussian Markov distributions over ﬁnite graphs. Annals of Statistics, 1986.</p>
<p>[31] F. Wong, C. Carter, and R. Kohn. Efﬁcient estimation of covariance selection models. Biometrika, 2003.</p>
<p>[32] M. Yuan and Yi Lin. Model selection and estimation in the GGM. Biometrika, 94(1), 2007.</p>
<p>[33] T. Zhang. Adaptive forward-backward greedy algorithm for sparse learning. In NIPS, 2008.</p>
<p>[34] H. Zou, T. Hastie, and R. Tibshirani. On the ”degrees of freedom” of Lasso. Annals of Statistics, 2007.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
