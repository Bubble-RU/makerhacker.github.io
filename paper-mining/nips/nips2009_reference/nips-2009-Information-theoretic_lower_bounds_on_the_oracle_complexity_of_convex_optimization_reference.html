<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>116 nips-2009-Information-theoretic lower bounds on the oracle complexity of convex optimization</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-116" href="../nips2009/nips-2009-Information-theoretic_lower_bounds_on_the_oracle_complexity_of_convex_optimization.html">nips2009-116</a> <a title="nips-2009-116-reference" href="#">nips2009-116-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>116 nips-2009-Information-theoretic lower bounds on the oracle complexity of convex optimization</h1>
<br/><p>Source: <a title="nips-2009-116-pdf" href="http://papers.nips.cc/paper/3689-information-theoretic-lower-bounds-on-the-oracle-complexity-of-convex-optimization.pdf">pdf</a></p><p>Author: Alekh Agarwal, Martin J. Wainwright, Peter L. Bartlett, Pradeep K. Ravikumar</p><p>Abstract: Despite a large literature on upper bounds on complexity of convex optimization, relatively less attention has been paid to the fundamental hardness of these problems. Given the extensive use of convex optimization in machine learning and statistics, gaining a understanding of these complexity-theoretic issues is important. In this paper, we study the complexity of stochastic convex optimization in an oracle model of computation. We improve upon known results and obtain tight minimax complexity estimates for various function classes. We also discuss implications of these results for the understanding the inherent complexity of large-scale learning and estimation problems. 1</p><br/>
<h2>reference text</h2><p>[1] D.P. Bertsekas. Nonlinear programming. Athena Scientiﬁc, Belmont, MA, 1995.</p>
<p>[2] L. Birg´ . Approximation dans les espaces metriques et theorie de l’estimation. Z. Wahrsch. e verw. Gebiete, 65:181–327, 1983.</p>
<p>[3] L. Bottou and O. Bousquet. The tradeoffs of large scale learning. In NIPS. 2008.</p>
<p>[4] S. Boyd and L. Vandenberghe. Convex optimization. Cambridge University Press, Cambridge, UK, 2004. 8</p>
<p>[5] R. Z. Has’minskii. A lower bound on the risks of nonparametric estimates of densities in the uniform metric. Theory Prob. Appl., 23:794–798, 1978.</p>
<p>[6] J. Matousek. Lectures on discrete geometry. Springer-Verlag, New York, 2002.</p>
<p>[7] A. S. Nemirovski. Efﬁcient methods in convex programming. Lecture notes.</p>
<p>[8] A. S. Nemirovski and D. B. Yudin. Problem Complexity and Method Efﬁciency in Optimization. John Wiley UK/USA, 1983.</p>
<p>[9] S. Shalev-Shwartz and N. Srebro. SVM optimization: inverse dependence on training set size. In ICML, 2008.</p>
<p>[10] Nesterov Y. Introductory lectures on convex optimization: Basic course. Kluwer Academic Publishers, 2004.</p>
<p>[11] B. Yu. Assouad, Fano and Le Cam. In Festschrift in Honor of L. Le Cam on his 70th Birthday. Springer-Verlag, 1993.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
