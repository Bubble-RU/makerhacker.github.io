<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>150 nips-2009-Maximum likelihood trajectories for continuous-time Markov chains</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-150" href="../nips2009/nips-2009-Maximum_likelihood_trajectories_for_continuous-time_Markov_chains.html">nips2009-150</a> <a title="nips-2009-150-reference" href="#">nips2009-150-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>150 nips-2009-Maximum likelihood trajectories for continuous-time Markov chains</h1>
<br/><p>Source: <a title="nips-2009-150-pdf" href="http://papers.nips.cc/paper/3859-maximum-likelihood-trajectories-for-continuous-time-markov-chains.pdf">pdf</a></p><p>Author: Theodore J. Perkins</p><p>Abstract: Continuous-time Markov chains are used to model systems in which transitions between states as well as the time the system spends in each state are random. Many computational problems related to such chains have been solved, including determining state distributions as a function of time, parameter estimation, and control. However, the problem of inferring most likely trajectories, where a trajectory is a sequence of states as well as the amount of time spent in each state, appears unsolved. We study three versions of this problem: (i) an initial value problem, in which an initial state is given and we seek the most likely trajectory until a given ﬁnal time, (ii) a boundary value problem, in which initial and ﬁnal states and times are given, and we seek the most likely trajectory connecting them, and (iii) trajectory inference under partial observability, analogous to ﬁnding maximum likelihood trajectories for hidden Markov models. We show that maximum likelihood trajectories are not always well-deﬁned, and describe a polynomial time test for well-deﬁnedness. When well-deﬁnedness holds, we show that each of the three problems can be solved in polynomial time, and we develop efﬁcient dynamic programming algorithms for doing so. 1</p><br/>
<h2>reference text</h2><p>[1] FG Ball and JA Rice. Stochastic models for ion channels: introduction and bibliography. Mathematical biosciences, 112(2):189, 1992.</p>
<p>[2] D.J. Wilkinson. Stochastic modelling for systems biology. Chapman & Hall/CRC, 2006.</p>
<p>[3] M. Holder and P.O. Lewis. Phylogeny estimation: traditional and Bayesian approaches. Nature Reviews Genetics, 4(4):275–284, 2003.</p>
<p>[4] H.M. Taylor and S. Karlin. An introduction to stochastic modeling. Academic Press, 1998.</p>
<p>[5] D.R. Fredkin and J.A. Rice. Maximum likelihood estimation and identiﬁcation directly from single-channel recordings. Proceedings: Biological Sciences, pages 125–132, 1992.</p>
<p>[6] R. Rosales, J.A. Stark, W.J. Fitzgerald, and S.B. Hladky. Bayesian restoration of ion channel records using hidden Markov models. Biophysical Journal, 80(3):1088–1103, 2001.</p>
<p>[7] M.A. Suchard, R.E. Weiss, and J.S. Sinsheimer. Bayesian selection of continuous-time Markov chain evolutionary models. Molecular Biology and Evolution, 18(6):1001–1013, 2001.</p>
<p>[8] DT Crommelin and E. Vanden-Eijnden. Fitting timeseries by continuous-time Markov chains: A quadratic programming approach. Journal of Computational Physics, 217(2):782–805, 2006.</p>
<p>[9] M. L. Puterman. Markov Decision Processes: Discrete Stochastic Dynamic Programming. John Wiley and Sons, New York, 1994.</p>
<p>[10] S. Hedlund and A. Rantzer. Optimal control of hybrid systems. In Decision and Control, 1999. Proceedings of the 38th IEEE Conference on, volume 4, 1999.</p>
<p>[11] D.P. Bertsekas. Dynamic programming and optimal control. Athena Scientiﬁc Belmont, Mass, 1995.</p>
<p>[12] NG Van Kampen. Stochastic processes in physics and chemistry. North-Holland, 2007.</p>
<p>[13] D. T. Gillespie. Exact stochastic simulation of coupled chemical reactions. Journal of Physical Chemistry, 81:2340–2361, 1977.</p>
<p>[14] A. Hordijk, D.L. Iglehart, and R. Schassberger. Discrete time methods for simulating continuous time Markov chains. Advances in Applied Probability, pages 772–788, 1976.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
