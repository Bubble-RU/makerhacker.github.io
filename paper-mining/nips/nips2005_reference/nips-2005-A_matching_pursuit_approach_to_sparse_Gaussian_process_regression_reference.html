<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>16 nips-2005-A matching pursuit approach to sparse Gaussian process regression</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2005" href="../home/nips2005_home.html">nips2005</a> <a title="nips-2005-16" href="../nips2005/nips-2005-A_matching_pursuit_approach_to_sparse_Gaussian_process_regression.html">nips2005-16</a> <a title="nips-2005-16-reference" href="#">nips2005-16-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>16 nips-2005-A matching pursuit approach to sparse Gaussian process regression</h1>
<br/><p>Source: <a title="nips-2005-16-pdf" href="http://papers.nips.cc/paper/2862-a-matching-pursuit-approach-to-sparse-gaussian-process-regression.pdf">pdf</a></p><p>Author: Sathiya Keerthi, Wei Chu</p><p>Abstract: In this paper we propose a new basis selection criterion for building sparse GP regression models that provides promising gains in accuracy as well as efﬁciency over previous methods. Our algorithm is much faster than that of Smola and Bartlett, while, in generalization it greatly outperforms the information gain approach proposed by Seeger et al, especially on the quality of predictive distributions. 1</p><br/>
<h2>reference text</h2><p>Adler, J., B. D. Rao, and K. Kreutz-Delgado. Comparison of basis selection methods. In Proceedings of the 30th Asilomar conference on signals, systems and computers, pages 252–257, 1996. Candela, J. Q. Learning with uncertainty - Gaussian processes and relevance vector machines. PhD thesis, Technical University of Denmark, 2004. Csat´ , L. and M. Opper. Sparse online Gaussian processes. Neural Computation, The MIT o Press, 14:641–668, 2002. Seeger, M. Bayesian Gaussian process models: PAC-Bayesian generalisation error bounds and sparse approximations. PhD thesis, University of Edinburgh, July 2003. Seeger, M., C. K. I. Williams, and N. Lawrence. Fast forward selection to speed up sparse Gaussian process regression. In Workshop on AI and Statistics 9, 2003. Smola, A. J. and P. Bartlett. Sparse greedy Gaussian process regression. In Leen, T. K., T. G. Dietterich, and V. Tresp, editors, Advances in Neural Information Processing Systems 13, pages 619–625. MIT Press, 2001. Vincent, P. and Y. Bengio. Kernel matching pursuit. Machine Learning, 48:165–187, 2002. Williams, C. K. I. and M. Seeger. Using the Nystr¨ m method to speed up kernel machines. o In Leen, T. K., T. G. Dietterich, and V. Tresp, editors, Advances in Neural Information Processing Systems 13, pages 682–688. MIT Press, 2001. 3  These datasets are vailable at http://www.liacc.up.pt/∼ltorgo/Regression/DataSets.html. The dataset and the results contributed by other participants can be found at the web site of the challenge http://predict.kyb.tuebingen.mpg.de/. 4</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
