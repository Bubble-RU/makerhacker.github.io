<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>119 nips-2005-Learning to Control an Octopus Arm with Gaussian Process Temporal Difference Methods</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2005" href="../home/nips2005_home.html">nips2005</a> <a title="nips-2005-119" href="../nips2005/nips-2005-Learning_to_Control_an_Octopus_Arm_with_Gaussian_Process_Temporal_Difference_Methods.html">nips2005-119</a> <a title="nips-2005-119-reference" href="#">nips2005-119-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>119 nips-2005-Learning to Control an Octopus Arm with Gaussian Process Temporal Difference Methods</h1>
<br/><p>Source: <a title="nips-2005-119-pdf" href="http://papers.nips.cc/paper/2785-learning-to-control-an-octopus-arm-with-gaussian-process-temporal-difference-methods.pdf">pdf</a></p><p>Author: Yaakov Engel, Peter Szabo, Dmitry Volkinshtein</p><p>Abstract: The Octopus arm is a highly versatile and complex limb. How the Octopus controls such a hyper-redundant arm (not to mention eight of them!) is as yet unknown. Robotic arms based on the same mechanical principles may render present day robotic arms obsolete. In this paper, we tackle this control problem using an online reinforcement learning algorithm, based on a Bayesian approach to policy evaluation known as Gaussian process temporal difference (GPTD) learning. Our substitute for the real arm is a computer simulation of a 2-dimensional model of an Octopus arm. Even with the simpliﬁcations inherent to this model, the state space we face is a high-dimensional one. We apply a GPTDbased algorithm to this domain, and demonstrate its operation on several learning tasks of varying degrees of difﬁculty. 1</p><br/>
<h2>reference text</h2><p>[1] G. Fiorito, C. V. Planta, and P. Scotto. Problem solving ability of Octopus Vulgaris Lamarck (Mollusca, Cephalopoda). Behavioral and Neural Biology, 53 (2):217–230, 1990.</p>
<p>[2] W.M. Kier and K.K. Smith. Tongues, tentacles and trunks: The biomechanics of movement in muscular-hydrostats. Zoological Journal of the Linnean Society, 83:307–324, 1985.</p>
<p>[3] Y. Gutfreund, T. Flash, Y. Yarom, G. Fiorito, I. Segev, and B. Hochner. Organization of Octopus arm movements: A model system for studying the control of ﬂexible arms. The journal of Neuroscience, 16:7297–7307, 1996.</p>
<p>[4] Y. Yekutieli, R. Sagiv-Zohar, R. Aharonov, Y. Engel, B. Hochner, and T. Flash. A dynamic model of the Octopus arm. I. Biomechanics of the Octopus reaching movement. Journal of Neurophysiology (in press), 2005.</p>
<p>[5] Y. Bar-Cohen, editor. Electroactive Polymer (EAP) Actuators as Artiﬁcial Muscles - Reality, Potential and Challenges. SPIE Press, 2nd edition, 2004.</p>
<p>[6] Y. Engel, S. Mannor, and R. Meir. Bayes meets Bellman: The Gaussian process approach to temporal difference learning. In Proc. of the 20th International Conference on Machine Learning, 2003.</p>
<p>[7] Y. Engel, S. Mannor, and R. Meir. Reinforcement learning with Gaussian processes. In Proc. of the 22nd International Conference on Machine Learning, 2005.</p>
<p>[8] Y. Engel. Algorithms and Representations for Reinforcement Learning. PhD thesis, The Hebrew University of Jerusalem, 2005. www.cs.ualberta.ca/∼yaki/papers/thesis.ps.</p>
<p>[9] R. Aharonov, Y. Engel, B. Hochner, and T. Flash. A dynamical model of the octopus arm. In Neuroscience letters. Supl. 48. Proceedings of the 6th annual meeting of the Israeli Neuroscience Society, 1997.</p>
<p>[10] D.P. Bertsekas and J.N. Tsitsiklis. Neuro-Dynamic Programming. Athena Scientiﬁc, 1996.</p>
<p>[11] R.S. Sutton and Andrew G. Barto. Reinforcement Learning: An Introduction. MIT Press, 1998.</p>
<p>[12] J. Shawe-Taylor and N. Cristianini. Kernel Methods for Pattern Analysis. Cambridge University Press, Cambridge, England, 2004.</p>
<p>[13] Y. Engel, P. Szabo, and D. Volkinshtein. Learning to control an Octopus arm with Gaussian process temporal difference methods. Technical report, Technion Institute of Technology, 2005. www.cs.ualberta.ca/∼yaki/reports/octopus.pdf.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
