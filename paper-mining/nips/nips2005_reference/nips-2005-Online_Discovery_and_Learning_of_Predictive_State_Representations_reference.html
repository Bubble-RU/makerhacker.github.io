<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>148 nips-2005-Online Discovery and Learning of Predictive State Representations</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2005" href="../home/nips2005_home.html">nips2005</a> <a title="nips-2005-148" href="../nips2005/nips-2005-Online_Discovery_and_Learning_of_Predictive_State_Representations.html">nips2005-148</a> <a title="nips-2005-148-reference" href="#">nips2005-148-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>148 nips-2005-Online Discovery and Learning of Predictive State Representations</h1>
<br/><p>Source: <a title="nips-2005-148-pdf" href="http://papers.nips.cc/paper/2883-online-discovery-and-learning-of-predictive-state-representations.pdf">pdf</a></p><p>Author: Peter Mccracken, Michael Bowling</p><p>Abstract: Predictive state representations (PSRs) are a method of modeling dynamical systems using only observable data, such as actions and observations, to describe their model. PSRs use predictions about the outcome of future tests to summarize the system state. The best existing techniques for discovery and learning of PSRs use a Monte Carlo approach to explicitly estimate these outcome probabilities. In this paper, we present a new algorithm for discovery and learning of PSRs that uses a gradient descent approach to compute the predictions for the current state. The algorithm takes advantage of the large amount of structure inherent in a valid prediction matrix to constrain its predictions. Furthermore, the algorithm can be used online by an agent to constantly improve its prediction quality; something that current state of the art discovery and learning algorithms are unable to do. We give empirical results to show that our constrained gradient algorithm is able to discover core tests using very small amounts of data, and with larger amounts of data can compute accurate predictions of the system dynamics. 1</p><br/>
<h2>reference text</h2><p>[1] Herbert Jaeger. Observable operator models for discrete stochastic time series. Neural Computation, 12(6):1371–1398, 2000.</p>
<p>[2] Michael Littman, Richard Sutton, and Satinder Singh. Predictive representations of state. In Advances in Neural Information Processing Systems 14 (NIPS), pages 1555–1561, 2002.</p>
<p>[3] Satinder Singh, Michael R. James, and Matthew R. Rudary. Predictive state representations: A new theory for modeling dynamical systems. In Uncertainty in Artiﬁcial Intelligence: Proceedings of the Twentieth Conference (UAI), pages 512–519, 2004.</p>
<p>[4] Richard Sutton and Brian Tanner. Temporal-difference networks. In Advances in Neural Information Processing Systems 17, pages 1377–1384, 2005.</p>
<p>[5] Matthew Rosencrantz, Geoff Gordon, and Sebastian Thrun. Learning low dimensional predictive representations. In Twenty-First International Conference on Machine Learning (ICML), 2004.</p>
<p>[6] Michael R. James and Satinder Singh. Learning and discovery of predictive state representations in dynamical systems with reset. In Twenty-First International Conference on Machine Learning (ICML), 2004.</p>
<p>[7] Britton Wolfe, Michael R. James, and Satinder Singh. Learning predictive state representations in dynamical systems without reset. In Twenty-Second International Conference on Machine Learning (ICML), 2005.</p>
<p>[8] Satinder Singh, Michael Littman, Nicholas Jong, David Pardoe, and Peter Stone. Learning predictive state representations. In Twentieth International Conference on Machine Learning (ICML), pages 712–719, 2003.</p>
<p>[9] Peter McCracken. An online algorithm for discovery and learning of prediction state representations. Master’s thesis, University of Alberta, 2005.</p>
<p>[10] Eric Wiewiora. Learning predictive representations from a history. In Twenty-Second International Conference on Machine Learning (ICML), 2005.</p>
<p>[11] Anthony Cassandra. Tony’s POMDP ﬁle repository page. research/ai/pomdp/examples/index.html, 1999.  http://www.cs.brown.edu/-</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
