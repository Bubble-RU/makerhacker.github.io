<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>96 nips-2005-Inference with Minimal Communication: a Decision-Theoretic Variational Approach</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2005" href="../home/nips2005_home.html">nips2005</a> <a title="nips-2005-96" href="../nips2005/nips-2005-Inference_with_Minimal_Communication%3A_a_Decision-Theoretic_Variational_Approach.html">nips2005-96</a> <a title="nips-2005-96-reference" href="#">nips2005-96-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>96 nips-2005-Inference with Minimal Communication: a Decision-Theoretic Variational Approach</h1>
<br/><p>Source: <a title="nips-2005-96-pdf" href="http://papers.nips.cc/paper/2811-inference-with-minimal-communication-a-decision-theoretic-variational-approach.pdf">pdf</a></p><p>Author: O. P. Kreidl, Alan S. Willsky</p><p>Abstract: Given a directed graphical model with binary-valued hidden nodes and real-valued noisy observations, consider deciding upon the maximum a-posteriori (MAP) or the maximum posterior-marginal (MPM) assignment under the restriction that each node broadcasts only to its children exactly one single-bit message. We present a variational formulation, viewing the processing rules local to all nodes as degrees-of-freedom, that minimizes the loss in expected (MAP or MPM) performance subject to such online communication constraints. The approach leads to a novel message-passing algorithm to be executed ofﬂine, or before observations are realized, which mitigates the performance loss by iteratively coupling all rules in a manner implicitly driven by global statistics. We also provide (i) illustrative examples, (ii) assumptions that guarantee convergence and efﬁciency and (iii) connections to active research areas. 1</p><br/>
<h2>reference text</h2><p>[1] J. Pearl. Probabilistic Reasoning in Intelligent Systems. Morgan Kaufmann, 1988.</p>
<p>[2] L. Chen, et al. Data association based on optimization in graphical models with application to sensor networks. Mathematical and Computer Modeling, 2005. To appear.</p>
<p>[3] A. T. Ihler, et al. Message errors in belief propagation. Advances in NIPS 17, MIT Press, 2005.</p>
<p>[4] M. I. Jordan, et al. An introduction to variational methods for graphical models. Learning in Graphical Models, pp. 105–161, MIT Press, 1999.</p>
<p>[5] J. N. Tsitsiklis. Decentralized detection. Adv. in Stat. Sig. Proc., pp. 297–344, JAI Press, 1993.</p>
<p>[6] P. K. Varshney. Distributed Detection and Data Fusion. Springer-Verlag, 1997.</p>
<p>[7] J. Marschak and R. Radner. The Economic Theory of Teams. Yale University Press, 1972.</p>
<p>[8] O. P. Kreidl and A. S. Willsky. Posterior assignment in directed graphical models with minimal online communication. Available: http://web.mit.edu/opk/www/res.html</p>
<p>[9] D. P. Bertsekas. Nonlinear Programming. Athena Scientiﬁc, 1995.</p>
<p>[10] S. Kakade, et al. Correlated equilibria in graphical games. ACM-CEC, pp. 42–47, 2003.</p>
<p>[11] J. Lafferty, et al. Conditional random ﬁelds: Probabilistic models for segmenting and labeling sequence data. ICML, 2001.</p>
<p>[12] X. Nguyen, et al. Decentralized detection and classiﬁcation using kernel methods. ICML,2004.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
