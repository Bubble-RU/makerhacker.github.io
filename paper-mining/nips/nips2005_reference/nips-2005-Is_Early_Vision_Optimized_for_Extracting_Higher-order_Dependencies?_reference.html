<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>101 nips-2005-Is Early Vision Optimized for Extracting Higher-order Dependencies?</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2005" href="../home/nips2005_home.html">nips2005</a> <a title="nips-2005-101" href="../nips2005/nips-2005-Is_Early_Vision_Optimized_for_Extracting_Higher-order_Dependencies%3F.html">nips2005-101</a> <a title="nips-2005-101-reference" href="#">nips2005-101-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>101 nips-2005-Is Early Vision Optimized for Extracting Higher-order Dependencies?</h1>
<br/><p>Source: <a title="nips-2005-101-pdf" href="http://papers.nips.cc/paper/2901-is-early-vision-optimized-for-extracting-higher-order-dependencies.pdf">pdf</a></p><p>Author: Yan Karklin, Michael S. Lewicki</p><p>Abstract: Linear implementations of the efﬁcient coding hypothesis, such as independent component analysis (ICA) and sparse coding models, have provided functional explanations for properties of simple cells in V1 [1, 2]. These models, however, ignore the non-linear behavior of neurons and fail to match individual and population properties of neural receptive ﬁelds in subtle but important ways. Hierarchical models, including Gaussian Scale Mixtures [3, 4] and other generative statistical models [5, 6], can capture higher-order regularities in natural images and explain nonlinear aspects of neural processing such as normalization and context effects [6,7]. Previously, it had been assumed that the lower level representation is independent of the hierarchy, and had been ﬁxed when training these models. Here we examine the optimal lower-level representations derived in the context of a hierarchical model and ﬁnd that the resulting representations are strikingly different from those based on linear models. Unlike the the basis functions and ﬁlters learned by ICA or sparse coding, these functions individually more closely resemble simple cell receptive ﬁelds and collectively span a broad range of spatial scales. Our work uniﬁes several related approaches and observations about natural image structure and suggests that hierarchical models might yield better representations of image structure throughout the hierarchy.</p><br/>
<h2>reference text</h2><p>[1] A. J. Bell and T. J. Sejnowski. The ’independent components’ of natural scenes are edge ﬁlters. Vision Research, 37(23):3327–3338, 1997.</p>
<p>[2] B. A. Olshausen and D. J. Field. Emergence of simple-cell receptive-ﬁeld properties by learning a sparse code for natural images. Nature, 381:607–609, 1996.</p>
<p>[3] D. F. Andrews and C. L. Mallows. Scale mixtures of normal distributions. Journal of the Royal Statistical Society B, 36(1):99–102, 1974.</p>
<p>[4] M. J. Wainwright, E. P. Simoncelli, and A. S. Willsky. Random cascades on wavelet trees and their use in analyzing and modeling natural images. Applied Computational and Harmonic Analysis, 11:89–123, 2001.</p>
<p>[5] A. Hyv¨ rinen, P. O. Hoyer, and M. Inki. Topographic independent component analysis. Neural a Computation, 13:1527–1558, 2001.</p>
<p>[6] Y. Karklin and M.S. Lewicki. A hierarchical bayesian model for learning non-linear statistical regularities in non-stationary natural signals. Neural Computation, 17:397–423, 2005.</p>
<p>[7] O. Schwartz and E. P. Simoncelli. Natural signal statistics and sensory gain control. Nat. Neurosci., 4:819–825, 2001.</p>
<p>[8] D. Field. What is the goal of sensory coding. Neural Computation, 6:559–601, 1994.</p>
<p>[9] D. R. Ruderman and W. Bialek. Statistics of natural images: Scaling in the woods. Physical Review Letters, 73(6):814–818, 1994.</p>
<p>[10] J. H. van Hateren and A. van der Schaaf. Independent component ﬁlters of natural images compared with simple cells in primary visual cortex. Proceedings of the Royal Society, London B, 265:359–366, 1998.</p>
<p>[11] J. P. Jones and L. A. Palmer. An evaluation of the two-dimensional gabor ﬁlter model of simple receptive ﬁelds in cat striate cortex. Journal of Neurophysiology, 58(6):1233–1258, 1987.</p>
<p>[12] E. Doi and M. S. Lewicki. Sparse coding of natural images using an overcomplete set of limited capacity units. In Advances in Neural Processing Information Systems 18, 2004.</p>
<p>[13] R. L. De Valois, D. G. Albrecht, and L. G. Thorell. Spatial frequency selectivity of cells in macaque visual cortex. Vision Research, 22:545–559, 1982.</p>
<p>[14] D. L. Ringach. Spatial structure and symmetry of simple-cell receptive ﬁelds in macaque primary visual cortex. Journal of Neurophysiology, 88:455–463, 2002.</p>
<p>[15] J. Portilla, V. Strela, M. J. Wainwright, and E.P. Simoncelli. Image denoising using Gaussian scale mixtures in the wavelet domain. IEEE Transactions on Image Processing, 12:1338–1351, 2003.</p>
<p>[16] Y. Karklin and M.S. Lewicki. Learning higher-order structures in natural images. Network: Computation in Neural Systems, 14:483–499, 2003.</p>
<p>[17] C. Zetzsche and G. Krieger. Nonlinear neurons and highorder statistics: New approaches to human vision and electronic image processing. In B. Rogowitz and T.V. Pappas, editors, Proc. SPIE on Human Vision and Electronic Imaging IV, volume 3644, pages 2–33, 1999.</p>
<p>[18] M. S. Lewicki and B. A. Olshausen. A probabilistic framework for the adaptation and comparison of image codes. Journal of the Optical Society of America A, 16(7):1587–1601, 1999.</p>
<p>[19] B. A. Olshausen and D. J. Field. Sparse coding with an overcomplete basis set: A strategy employed by V1? Vision Research, 37(23), 1997.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
