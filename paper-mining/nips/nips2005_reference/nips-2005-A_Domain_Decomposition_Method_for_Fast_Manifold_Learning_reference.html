<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>9 nips-2005-A Domain Decomposition Method for Fast Manifold Learning</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2005" href="../home/nips2005_home.html">nips2005</a> <a title="nips-2005-9" href="../nips2005/nips-2005-A_Domain_Decomposition_Method_for_Fast_Manifold_Learning.html">nips2005-9</a> <a title="nips-2005-9-reference" href="#">nips2005-9-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>9 nips-2005-A Domain Decomposition Method for Fast Manifold Learning</h1>
<br/><p>Source: <a title="nips-2005-9-pdf" href="http://papers.nips.cc/paper/2818-a-domain-decomposition-method-for-fast-manifold-learning.pdf">pdf</a></p><p>Author: Zhenyue Zhang, Hongyuan Zha</p><p>Abstract: We propose a fast manifold learning algorithm based on the methodology of domain decomposition. Starting with the set of sample points partitioned into two subdomains, we develop the solution of the interface problem that can glue the embeddings on the two subdomains into an embedding on the whole domain. We provide a detailed analysis to assess the errors produced by the gluing process using matrix perturbation theory. Numerical examples are given to illustrate the efﬁciency and effectiveness of the proposed methods. 1</p><br/>
<h2>reference text</h2><p>[1] M. Brand. Charting a manifold. Advances in Neural Information Processing Systems 15, MIT Press, 2003.</p>
<p>[2] D. Donoho and C. Grimes. Hessian Eigenmaps: new tools for nonlinear dimensionality reduction. Proceedings of National Academy of Science, 5591-5596, 2003.</p>
<p>[3] M. Fiedler. A property of eigenvectors of nonnegative symmetric matrices and its application to graph theory. Czech. Math. J. 25:619–637, 1975.</p>
<p>[4] A. George and J. W. Liu. Computer Solution of Large Sparse Positive Deﬁnite Matrices. Prentice Hall, 1981.</p>
<p>[5] METIS. http://www-users.cs.umn.edu/∼karypis/metis/.</p>
<p>[6] S. Roweis and L. Saul. Nonlinear dimensionality reduction by locally linear embedding. Science, 290: 2323–2326, 2000.</p>
<p>[7] B. Smith, P. Bjorstad and W. Gropp Domain Decomposition, Parallel Multilevel Methods for Elliptic Partial Differential Equations. Cambridge University Press, 1996.</p>
<p>[8] G.W. Stewart and J.G. Sun. Matrix Perturbation Theory. Academic Press, New York, 1990.</p>
<p>[9] J. Tenenbaum, V. De Silva and J. Langford. A global geometric framework for nonlinear dimension reduction. Science, 290:2319–2323, 2000.</p>
<p>[10] A. Toselli and O. Widlund. Domain Decomposition Methods - Algorithms and Theory. Springer, 2004.</p>
<p>[11] H. Zha and Z. Zhang. Spectral analysis of alignment in manifold learning. Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing, (ICASSP), 2005.</p>
<p>[12] Z. Zhang and H. Zha. Principal manifolds and nonlinear dimensionality reduction via tangent space alignment. SIAM J. Scientiﬁc Computing. 26:313-338, 2005.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
