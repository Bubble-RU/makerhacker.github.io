<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>5 nips-2005-A Computational Model of Eye Movements during Object Class Detection</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2005" href="../home/nips2005_home.html">nips2005</a> <a title="nips-2005-5" href="../nips2005/nips-2005-A_Computational_Model_of_Eye_Movements_during_Object_Class_Detection.html">nips2005-5</a> <a title="nips-2005-5-reference" href="#">nips2005-5-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>5 nips-2005-A Computational Model of Eye Movements during Object Class Detection</h1>
<br/><p>Source: <a title="nips-2005-5-pdf" href="http://papers.nips.cc/paper/2949-a-computational-model-of-eye-movements-during-object-class-detection.pdf">pdf</a></p><p>Author: Wei Zhang, Hyejin Yang, Dimitris Samaras, Gregory J. Zelinsky</p><p>Abstract: We present a computational model of human eye movements in an object class detection task. The model combines state-of-the-art computer vision object class detection methods (SIFT features trained using AdaBoost) with a biologically plausible model of human eye movement to produce a sequence of simulated ﬁxations, culminating with the acquisition of a target. We validated the model by comparing its behavior to the behavior of human observers performing the identical object class detection task (looking for a teddy bear among visually complex nontarget objects). We found considerable agreement between the model and human data in multiple eye movement measures, including number of ﬁxations, cumulative probability of ﬁxating the target, and scanpath distance.</p><br/>
<h2>reference text</h2><p>[1] M. F. Land and D. N. Lee. Where we look when we steer. Nature, 369(6483):742–744, 1994.</p>
<p>[2] M. F. Land and M. Hayhoe. In what ways do eye movements contribute to everyday activities. Vision Research, 41(25-36):3559–3565, 2001.</p>
<p>[3] G. Zelinsky, R. Rao, M. Hayhoe, and D. Ballard. Eye movements reveal the spatio-temporal dynamics of visual search. Psychological Science, 8:448–453, 1997.</p>
<p>[4] J. Wolfe. Visual search. In H. Pashler (Ed.), Attention, pages 13–71. London: University College London Press, 1997.</p>
<p>[5] E. Weichselgartner and G. Sperling. Dynamics of automatic and controlled visual attention. Science, 238(4828):778–780, 1987.</p>
<p>[6] H. Schneiderman and T. Kanade. A statistical method for 3d object detection applied to faces and cars. In CVPR, volume I, pages 746–751, 2000.</p>
<p>[7] P. Viola and M.J. Jones. Rapid object detection using a boosted cascade of simple features. In CVPR, volume I, pages 511–518, 2001.</p>
<p>[8] S. Agarwal and D. Roth. Learning a sparse representation for object detection. In ECCV, volume IV, page 113, 2002.</p>
<p>[9] Wolf Kienzle, G¨ khan H. Bakır, Matthias O. Franz, and Bernhard Sch¨ lkopf. Face detection o o efﬁcient and rank deﬁcient. In NIPS, 2004.</p>
<p>[10] R. Fergus, P. Perona, and A. Zisserman. Object class recognition by unsupervised scaleinvariant learning. In CVPR03, volume II, pages 264–271, 2003.</p>
<p>[11] A. Opelt, M. Fussenegger, A. Pinz, and P. Auer. Weak hypotheses and boosting for generic object detection and recognition. In ECCV04, volume II, pages 71–84, 2004.</p>
<p>[12] W. Zhang, B. Yu, G. Zelinsky, and D. Samaras. Object class recognition using multiple layer boosting with multiple features. In CVPR, 2005.</p>
<p>[13] L. Itti and C. Koch. A saliency-based search mechanism for overt and covert shifts of visual attention. Vision Research, 40:1489–1506, 2000.</p>
<p>[14] R. Rao, G. Zelinsky, M. Hayhoe, and D. Ballard. Eye movements in iconic visual search. Vision Research, 42:1447–1463, 2002.</p>
<p>[15] D. T. Levin, Y. Takarae, A. G. Miner, and F. Keil. Efﬁcient visual search by category: Specifying the features that mark the difference between artifacts and animal in preattentive vision. Perception and Psychophysics, 63(4):676–697, 2001.</p>
<p>[16] P. Cockrill. The teddy bear encyclopedia. New York: DK Publishing, Inc., 2001.</p>
<p>[17] R. Rao, G. Zelinsky, M. Hayhoe, and D. Ballard. Modeling saccadic targeting in visual search. In NIPS, 1995.</p>
<p>[18] G. Zelinsky. Itti, L., Rees, G. and Tsotos, J.(Eds.), Neurobiology of attention, chapter Specifying the components of attention in a visual search task, pages 395–400. Elsevier, 2005.</p>
<p>[19] W.S. Geisler and J.S. Perry. A real-time foveated multi-resolution system for low-bandwidth video communications. In Human Vision and Electronic Imaging, SPIE Proceddings, volume 3299, pages 294–305, 1998.</p>
<p>[20] J.S. Perry and W.S. Geisler. Gaze-contingent real-time simulation of arbitrary visual ﬁelds. In SPIE, 2002.</p>
<p>[21] M.J. Swain and D.H. Ballard. Color indexing. IJCV, 7(1):11–32, November 1991.</p>
<p>[22] D.G. Lowe. Distinctive image features from scale-invariant keypoints. IJCV, 60(2):91–110, November 2004.</p>
<p>[23] Y. Freund and R.E. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. Journal of Computer and System Sciences, 55(1):119–139, 1997.</p>
<p>[24] K. Yamada and G. Cottrell. A model of scan paths applied to face recognition. In Seventeenth Annual Cognitive Science Conference, pages 55–60, 1995.</p>
<p>[25] C. M. Privitera and L. W. Stark. Algorithms for deﬁning visual regions-of-interest: comparison with eye ﬁxations. PAMI, 22:970–982, 2000.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
