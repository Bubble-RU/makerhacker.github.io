<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>115 nips-2005-Learning Shared Latent Structure for Image Synthesis and Robotic Imitation</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2005" href="../home/nips2005_home.html">nips2005</a> <a title="nips-2005-115" href="../nips2005/nips-2005-Learning_Shared_Latent_Structure_for_Image_Synthesis_and_Robotic_Imitation.html">nips2005-115</a> <a title="nips-2005-115-reference" href="#">nips2005-115-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>115 nips-2005-Learning Shared Latent Structure for Image Synthesis and Robotic Imitation</h1>
<br/><p>Source: <a title="nips-2005-115-pdf" href="http://papers.nips.cc/paper/2751-learning-shared-latent-structure-for-image-synthesis-and-robotic-imitation.pdf">pdf</a></p><p>Author: Aaron Shon, Keith Grochow, Aaron Hertzmann, Rajesh P. Rao</p><p>Abstract: We propose an algorithm that uses Gaussian process regression to learn common hidden structure shared between corresponding sets of heterogenous observations. The observation spaces are linked via a single, reduced-dimensionality latent variable space. We present results from two datasets demonstrating the algorithms’s ability to synthesize novel data from learned correspondences. We ﬁrst show that the method can learn the nonlinear mapping between corresponding views of objects, ﬁlling in missing data as needed to synthesize novel views. We then show that the method can learn a mapping between human degrees of freedom and robotic degrees of freedom for a humanoid robot, allowing robotic imitation of human poses from motion capture data. 1</p><br/>
<h2>reference text</h2><p>[1] K. Grochow, S. L. Martin, A. Hertzmann, and Z. Popovi´ . Style-based inverse kinematics. In c Proc. SIGGRAPH, 2004.</p>
<p>[2] J. Ham, D. Lee, and L. Saul. Semisupervised alignment of manifolds. In AISTATS, 2004.</p>
<p>[3] P. L. Lai and C. Fyfe. Kernel and nonlinear canonical correlation analysis. Int. J. Neural Sys., 10(5):365–377, 2000.  Figure 4: Learning shared latent structure for robotic imitation of human actions: The plot in 2 the center shows the latent training points (red circles) and model precision 1/σZ for the robot model (grayscale plot), with examples of recovered latent points for testing data (blue diamonds). Model precision is qualitatively similar for the human model. Inset panels show the pose of the human motion capture skeleton, the simulated robot skeleton, and the humanoid robot for each example latent point. The model correctly infers robot poses from the human walking data (inset panels).</p>
<p>[4] N. D. Lawrence. Gaussian process models for visualization of high dimensional data. In S. Thrun, L. Saul, and B. Sch¨ lkopf, editors, Advances in NIPS 16. o</p>
<p>[5] N. D. Lawrence, M. Seeger, and R. Herbrich. Fast sparse Gaussian process methods: the informative vector machine. In S. Becker, S. Thrun, and K. Obermayer, editors, Advances in NIPS 15, 2003.</p>
<p>[6] A. N. Meltzoff. Elements of a developmental theory of imitation. In A. N. Meltzoff and W. Prinz, editors, The imitative mind: Development, evolution, and brain bases, pages 19–41. Cambridge: Cambridge University Press, 2002.</p>
<p>[7] C. Nehaniv and K. Dautenhahn. The correspondence problem. In Imitation in Animals and Artifacts. MIT Press, 2002.</p>
<p>[8] A. O’Hagan. On curve ﬁtting and optimal design for regression. Journal of the Royal Statistical Society B, 40:1–42, 1978.</p>
<p>[9] C. E. Rasmussen. Evaluation of Gaussian Processes and other Methods for Non-Linear Regression. PhD thesis, University of Toronto, 1996.</p>
<p>[10] S. Roweis and L. Saul. Nonlinear dimensionality reduction by locally linear embedding. Science, 290(5500):2323–2326, 2000.</p>
<p>[11] S. Schaal, A. Ijspeert, and A. Billard. Computational approaches to motor learning by imitation. Phil. Trans. Royal Soc. London: Series B, 358:537–547, 2003.</p>
<p>[12] A. P. Shon, D. B. Grimes, C. L. Baker, and R. P. N. Rao. A probabilistic framework for modelbased imitation learning. In Proc. 26th Ann. Mtg. Cog. Sci. Soc., 2004.</p>
<p>[13] J. B. Tenenbaum, V. de Silva, and J. C. Langford. A global geometric framework for nonlinear dimensionality reduction. Science, 290(5500):2319–2323, 2000.</p>
<p>[14] J. J. Verbeek, S. T. Roweis, and N. Vlassis. Non-linear CCA and PCA by alignment of local models. In Advances in NIPS 16, pages 297–304. 2003.</p>
<p>[15] C. K. I. Williams. Computing with inﬁnite networks. In M. C. Mozer, M. I. Jordan, and T. Petsche, editors, Advances in NIPS 9. Cambridge, MA: MIT Press, 1996.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
