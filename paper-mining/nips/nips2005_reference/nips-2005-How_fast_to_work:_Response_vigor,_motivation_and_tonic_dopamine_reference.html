<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>91 nips-2005-How fast to work: Response vigor, motivation and tonic dopamine</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2005" href="../home/nips2005_home.html">nips2005</a> <a title="nips-2005-91" href="../nips2005/nips-2005-How_fast_to_work%3A_Response_vigor%2C_motivation_and_tonic_dopamine.html">nips2005-91</a> <a title="nips-2005-91-reference" href="#">nips2005-91-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>91 nips-2005-How fast to work: Response vigor, motivation and tonic dopamine</h1>
<br/><p>Source: <a title="nips-2005-91-pdf" href="http://papers.nips.cc/paper/2842-how-fast-to-work-response-vigor-motivation-and-tonic-dopamine.pdf">pdf</a></p><p>Author: Yael Niv, Nathaniel D. Daw, Peter Dayan</p><p>Abstract: Reinforcement learning models have long promised to unify computational, psychological and neural accounts of appetitively conditioned behavior. However, the bulk of data on animal conditioning comes from free-operant experiments measuring how fast animals will work for reinforcement. Existing reinforcement learning (RL) models are silent about these tasks, because they lack any notion of vigor. They thus fail to address the simple observation that hungrier animals will work harder for food, as well as stranger facts such as their sometimes greater productivity even when working for irrelevant outcomes such as water. Here, we develop an RL framework for free-operant behavior, suggesting that subjects choose how vigorously to perform selected actions by optimally balancing the costs and beneﬁts of quick responding. Motivational states such as hunger shift these factors, skewing the tradeoff. This accounts normatively for the effects of motivation on response rates, as well as many other classic ﬁndings. Finally, we suggest that tonic levels of dopamine may be involved in the computation linking motivational state to optimal responding, thereby explaining the complex vigor-related effects of pharmacological manipulation of dopamine. 1</p><br/>
<h2>reference text</h2><p>[1] Dickinson A. and Balleine B.W. The role of learning in the operation of motivational systems. Steven’s Handbook of Experimental Psychology Volume 3, pages 497–533. John Wiley & Sons, New York, 2002.</p>
<p>[2] Hull C.L. Principles of behavior: An introduction to behavior theory. Appleton-Century-Crofts, New York, 1943. ´</p>
<p>[3] B´ langer D. and T´ treau B. L’inﬂuence d’une motivation inappropriate sur le comportement du rat et sa fr equence e e cardiaque. Can. J. of Psych., 15:6–14, 1961.</p>
<p>[4] Salamone J.D. and Correa M. Motivational views of reinforcement: implications for understanding the behavioral functions of nucleus accumbens dopamine. Behavioural Brain Research, 137:3–25, 2002.</p>
<p>[5] Ikemoto S. and Panksepp J. The role of nucleus accumbens dopamine in motivated behavior: a unifying interpretation with special reference to reward-seeking. Brain Res. Rev., 31:6–41, 1999.</p>
<p>[6] Schultz W. Predictive reward signal of dopamine neurons. J. Neurophys., 80:1–27, 1998.</p>
<p>[7] Domjan M. The principles of learning and behavior. Brooks/Cole, Paciﬁc Grove, California, 3rd edition, 1993.</p>
<p>[8] R. S. Sutton and A. G. Barto. Reinforcement learning: An introduction. MIT Press, 1998.</p>
<p>[9] Herrnstein R.J. On the law of effect. J. of the Exp. Anal. of Behav., 13(2):243–266, 1970.</p>
<p>[10] Dawson G.R. and Dickinson A. Performance on ratio and interval schedules with matched reinforcement rates. Q. J. of Exp. Psych. B, 42:225–239, 1990.</p>
<p>[11] Niv Y., Daw N.D., Joel D., and Dayan P. Motivational effects on behavior: Towards a reinforcement learning model of rates of responding. In CoSyNe, Salt Lake City, Utah, 2005.</p>
<p>[12] Aberman J.E. and Salamone J.D. Nucleus accumbens dopamine depletions make rats more sensitive to high ratio requirements but do not impair primary food reinforcement. Neuroscience, 92(2):545–552, 1999.</p>
<p>[13] Foster T.M., Blackman K.A., and Temple W. Open versus closed economies: performance of domestic hens under ﬁxed-ratio schedules. J. of the Exp. Anal. of Behav., 67:67–89, 1997.</p>
<p>[14] Staddon J.E.R. Adaptive dynamics. MIT Press, Cambridge, Mass., 2001.</p>
<p>[15] Mahadevan S. Average reward reinforcement learning: Foundations, algorithms and empirical results. Machine Learning, 22:1–38, 1996.</p>
<p>[16] Daw N.D., Kakade S., and Dayan P. Opponent interactions between serotonin and dopamine. Neural Networks, 15(4-6):603–616, 2002.</p>
<p>[17] Bolles R.C. Theory of Motivation. Harper & Row, 1967.</p>
<p>[18] Carr G.D. and White N.M. Effects of systemic and intracranial amphetamine injections on behavior in the open ﬁeld: a detailed analysis. Pharmacol. Biochem. Behav., 27:113–122, 1987.</p>
<p>[19] Jackson D.M., Anden N., and Dahlstrom A. A functional effect of dopamine in the nucleus accumbens and in some other dopamine-rich parts of the rat brain. Psychopharmacologia, 45:139–149, 1975.</p>
<p>[20] Dayan P. and Balleine B.W. Reward, motivation and reinforcement learning. Neuron, 36:285–298, 2002.</p>
<p>[21] McClure S.M., Daw N.D., and Montague P.R. A computational substrate for incentive salience. Trends in Neurosc., 26(8):423–428, 2003.</p>
<p>[22] Daw N.D., Niv Y., and Dayan P. Uncertainty based competition between prefrontal and dorsolateral striatal systems for behavioral control. Nature Neuroscience, 8(12):1704–1711, 2005.</p>
<p>[23] Dickinson A., Balleine B., Watt A., Gonzalez F., and Boakes R.A. Motivational control after extended instrumental training. Anim. Learn. and Behav., 23(2):197–206, 1995.</p>
<p>[24] Montague P.R., Dayan P., and Sejnowski T.J. A framework for mesencephalic dopamine systems based on predictive hebbian learning. J. of Neurosci., 16(5):1936–1947, 1996.</p>
<p>[25] Satoh T., Nakai S., Sato T., and Kimura M. Correlated coding of motivation and outcome of decision by dopamine neurons. J. of Neurosci., 23(30):9913–9923, 2003.</p>
<p>[26] Daw N.D., Courville A.C., and Touretzky D.S. Timing and partial observability in the dopamine system. In T.G. Dietterich, S. Becker, and Z. Ghahramani, editors, NIPS, volume 14, Cambridge, MA, 2002. MIT Press.</p>
<p>[27] Gallistel C.R. and Gibbon J. Time, rate and conditioning. Psych. Rev., 107:289–344, 2000.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
