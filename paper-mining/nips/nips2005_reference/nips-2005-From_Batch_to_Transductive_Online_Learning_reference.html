<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>76 nips-2005-From Batch to Transductive Online Learning</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2005" href="../home/nips2005_home.html">nips2005</a> <a title="nips-2005-76" href="../nips2005/nips-2005-From_Batch_to_Transductive_Online_Learning.html">nips2005-76</a> <a title="nips-2005-76-reference" href="#">nips2005-76-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>76 nips-2005-From Batch to Transductive Online Learning</h1>
<br/><p>Source: <a title="nips-2005-76-pdf" href="http://papers.nips.cc/paper/2755-from-batch-to-transductive-online-learning.pdf">pdf</a></p><p>Author: Sham Kakade, Adam Tauman Kalai</p><p>Abstract: It is well-known that everything that is learnable in the difﬁcult online setting, where an arbitrary sequences of examples must be labeled one at a time, is also learnable in the batch setting, where examples are drawn independently from a distribution. We show a result in the opposite direction. We give an efﬁcient conversion algorithm from batch to online that is transductive: it uses future unlabeled data. This demonstrates the equivalence between what is properly and efﬁciently learnable in a batch model and a transductive online model.</p><br/>
<h2>reference text</h2><p>[1] B. Awerbuch and R. Kleinberg. Adaptive routing with end-to-end feedback: Distributed learning and geometric approaches. In Proc. of the 36th ACM Symposium on Theory of Computing, 2004.</p>
<p>[2] S. Ben-David, E. Kushilevitz, and Y. Mansour. Online learning versus ofﬂine learning. Machine Learning 29:45-63, 1997.</p>
<p>[3] A. Blum. Separating Distribution-Free and Mistake-Bound Learning Models over the Boolean Domain. SIAM Journal on Computing 23(5): 990-1000, 1994.</p>
<p>[4] A. Blum, J. Hartline. Near-Optimal Online Auctions. In Proceedings of the Proceedings of the Sixteenth Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), 2005.</p>
<p>[5] J. Hannan. Approximation to Bayes Risk in Repeated Plays. In M. Dresher, A. Tucker, and P. Wolfe editors, Contributions to the Theory of Games, Volume 3, p. 97-139, Princeton University Press, 1957.</p>
<p>[6] A. Kalai and S. Vempala. Efﬁcient algorithms for the online decision problem. In Proceedings of the 16th Conference on Computational Learning Theory, 2003.</p>
<p>[7] M. Kearns, R. Schapire, and L. Sellie. Toward Efﬁcient Agnostic Learning. Machine Learning, 17(2/3):115–141, 1994.</p>
<p>[8] N. Littlestone. From On-Line to Batch Learning. In Proceedings of the 2nd Workshop on Computational Learning Theory, p. 269-284, 1989.</p>
<p>[9] N. Littlestone and M. Warmuth. The Weighted Majority Algorithm. Information and Computation, 108:212-261, 1994.</p>
<p>[10] H. Brendan McMahan and Avrim Blum. Online Geometric Optimization in the Bandit Setting Against an Adaptive Adversary. In Proceedings of the 17th Annual Conference on Learning Theory, COLT 2004.</p>
<p>[11] N. Sauer. On the Densities of Families of Sets. Journal of Combinatorial Theory, Series A, 13, p 145-147, 1972.</p>
<p>[12] V. N. Vapnik. Estimation of Dependencies Based on Empirical Data, New York: Springer Verlag, 1982.</p>
<p>[13] V. N. Vapnik. Statistical Learning Theory, New York: Wiley Interscience, 1998.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
