<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>82 nips-2005-Generalization Error Bounds for Aggregation by Mirror Descent with Averaging</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2005" href="../home/nips2005_home.html">nips2005</a> <a title="nips-2005-82" href="../nips2005/nips-2005-Generalization_Error_Bounds_for_Aggregation_by_Mirror_Descent_with_Averaging.html">nips2005-82</a> <a title="nips-2005-82-reference" href="#">nips2005-82-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>82 nips-2005-Generalization Error Bounds for Aggregation by Mirror Descent with Averaging</h1>
<br/><p>Source: <a title="nips-2005-82-pdf" href="http://papers.nips.cc/paper/2779-generalization-error-bounds-for-aggregation-by-mirror-descent-with-averaging.pdf">pdf</a></p><p>Author: Anatoli Juditsky, Alexander Nazin, Alexandre Tsybakov, Nicolas Vayatis</p><p>Abstract: We consider the problem of constructing an aggregated estimator from a ﬁnite class of base functions which approximately minimizes a convex risk functional under the ℓ1 constraint. For this purpose, we propose a stochastic procedure, the mirror descent, which performs gradient descent in the dual space. The generated estimates are additionally averaged in a recursive fashion with speciﬁc weights. Mirror descent algorithms have been developed in different contexts and they are known to be particularly efﬁcient in high dimensional problems. Moreover their implementation is adapted to the online setting. The main result of the paper is the upper bound on the convergence rate for the generalization error. 1</p><br/>
<h2>reference text</h2><p>[1] Beck, A. & Teboulle, M. (2003) Mirror descent and nonlinear projected subgradient methods for convex optimization. Operations Research Letters, 31:167–175.</p>
<p>[2] Ben-Tal, A., Margalit, T. & Nemirovski, A. (2001) The Ordered Subsets Mirror Descent optimization method and its use for the Positron Emission Tomography reconstruction problem. SIAM J. on Optimization, 12:79–108.</p>
<p>[3] Ben-Tal, A. & Nemirovski, A.S. (1999) The conjugate barrier mirror descent method for non-smooth convex optimization. MINERVA Optimization Center Report, Technion Institute of Technology. Available at http://iew3.technion.ac.il/Labs/Opt/opt/Pap/CP MD.pdf</p>
<p>[4] Cesa-Bianchi, N. & Gentile, C. (2005) Improved risk tail bounds for on-line algorithms. Submitted.</p>
<p>[5] Cesa-Bianchi, N., Conconi, A. & Gentile, C. (2004) On the generalization ability of on-line learning algorithms. IEEE Transactions on Information Theory, 50(9):2050– 2057.</p>
<p>[6] Helmbold, D.P., Kivinen, J. & Warmuth, M.K. (1999) Relative loss bounds for single neurons. IEEE Trans. on Neural Networks, 10(6):1291–1304.</p>
<p>[7] Juditsky, A. & Nemirovski, A. (2000) Functional aggregation for nonparametric estimation. Annals of Statistics, 28(3): 681–712.</p>
<p>[8] Juditsky, A.B., Nazin, A.V., Tsybakov, A.B. & Vayatis N. (2005) Recursive Aggregation of Estimators via the Mirror Descent Algorithm with Averaging. Technical Report LPMA, Universit´ Paris 6. e Available at http://www.proba.jussieu.fr/pageperso/vayatis/publication.html</p>
<p>[9] Kiwiel, K.C. (1997) Proximal minimization methods with generalized Bregman functions. SIAM J. Control Optim., 35:1142–1168.</p>
<p>[10] Kivinen J. & Warmuth M.K. (1997) Additive versus exponentiated gradient updates for linear prediction. Information and Computation, Vol.132(1): 1–64.</p>
<p>[11] Lugosi, G. & Vayatis, N. (2004) On the Bayes-risk consistency of regularized boosting methods (with discussion). Annals of Statitics, 32(1): 30–55.</p>
<p>[12] Nemirovski, A.S. & Yudin, D.B. (1983) Problem Complexity and Method Efﬁciency in Optimization. Wiley-Interscience.</p>
<p>[13] Polyak, B.T. & Juditsky, A.B. (1992) Acceleration of stochastic approximation by averaging. SIAM J. Control Optim., 30:838–855.</p>
<p>[14] Scovel, J.C. & Steinwart, I. (2005) Fast Rates for Support Vector Machines. In Proceedings of the 18th Conference on Learning Theory (COLT 2005), Bertinoro, Italy.</p>
<p>[15] Tarigan, B. & van de Geer, S. (2004) Adaptivity of Support Vector Machines with ℓ1 Penalty. Preprint, University of Leiden.</p>
<p>[16] Tsybakov, A. (2003) Optimal Rates of Aggregation. Proceedings of COLT’03, LNCS, Springer, Vol. 2777:303–313.</p>
<p>[17] Tsybakov, A. (2004) Optimal aggregation of classiﬁers in statistical learning. Annals of Statistics, 32(1):135–166.</p>
<p>[18] Zhang, T. (2004) Statistical behavior and consistency of classiﬁcation methods based on convex risk minimization (with discussion). Annals of Statistics, 32(1):56–85.</p>
<p>[19] Zhang, T. (2004) Solving large scale linear prediction problems using stochastic gradient descent algorithms. In Proceedings of ICML’04.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
