<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>87 nips-2005-Goal-Based Imitation as Probabilistic Inference over Graphical Models</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2005" href="../home/nips2005_home.html">nips2005</a> <a title="nips-2005-87" href="../nips2005/nips-2005-Goal-Based_Imitation_as_Probabilistic_Inference_over_Graphical_Models.html">nips2005-87</a> <a title="nips-2005-87-reference" href="#">nips2005-87-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>87 nips-2005-Goal-Based Imitation as Probabilistic Inference over Graphical Models</h1>
<br/><p>Source: <a title="nips-2005-87-pdf" href="http://papers.nips.cc/paper/2956-goal-based-imitation-as-probabilistic-inference-over-graphical-models.pdf">pdf</a></p><p>Author: Deepak Verma, Rajesh P. Rao</p><p>Abstract: Humans are extremely adept at learning new skills by imitating the actions of others. A progression of imitative abilities has been observed in children, ranging from imitation of simple body movements to goalbased imitation based on inferring intent. In this paper, we show that the problem of goal-based imitation can be formulated as one of inferring goals and selecting actions using a learned probabilistic graphical model of the environment. We ﬁrst describe algorithms for planning actions to achieve a goal state using probabilistic inference. We then describe how planning can be used to bootstrap the learning of goal-dependent policies by utilizing feedback from the environment. The resulting graphical model is then shown to be powerful enough to allow goal-based imitation. Using a simple maze navigation task, we illustrate how an agent can infer the goals of an observed teacher and imitate the teacher even when the goals are uncertain and the demonstration is incomplete.</p><br/>
<h2>reference text</h2><p>[1] A. N. Meltzoff and M. K. Moore. Newborn infants imitate adult facial gestures. Child Development, 54:702–709, 1983.</p>
<p>[2] L. Fogassi G. Rizzolatti, L. Fadiga and V. Gallese. From mirror neurons to imitation, facts, and speculations. In A. N. Meltzoff and W. Prinz (Eds.), The imitative mind: Development, evolution, and brain bases, pages 247–266, 2002.</p>
<p>[3] A. N. Meltzoff. Understanding the intentions of others: Re-enactment of intended acts by 18-month-old children. Developmental Psychology, 31:838–850, 1995.</p>
<p>[4] A. N. Meltzoff. Imitation of televised models by infants. Child Development, 59:1221–1229, 1988a.</p>
<p>[5] C. Boutilier, T. Dean, and S. Hanks. Decision-theoretic planning: Structural assumptions and computational leverage. Journal of AI Research, 11:1–94, 1999.</p>
<p>[6] R. S. Sutton and A. Barto. Reinforcement Learning: An Introduction. MIT Press, Cambridge, MA, 1998.</p>
<p>[7] H. Attias. Planning by probabilistic inference. In Proceedings of the 9th Int. Workshop on AI and Statistics, 2003.</p>
<p>[8] R. P. N. Rao, A. P. Shon, and A. N. Meltzoff. A Bayesian model of imitation in infants and robots. In Imitation and Social Learning in Robots, Humans, and Animals. Cambridge University Press, 2004.</p>
<p>[9] G. Theocharous, K. Murphy, and L. P. Kaelbling. Representing hierarchical POMDPs as DBNs for multi-scale robot localization. ICRA, 2004.</p>
<p>[10] S. Fine, Y. Singer, and N. Tishby. The hierarchical hidden Markov model: Analysis and applications. Mach. Learn., 32(1):41–62, 1998.</p>
<p>[11] H. Bui, D. Phung, and S. Venkatesh. Hierarchical hidden Markov models with general state hierarchy. In AAAI 2004, 2004.</p>
<p>[12] G. Hayes and J. Demiris. A robot controller using learning by imitation. Proceedings of the 2nd International Symposium on Intelligent Robotic Systems, Grenoble, France,, pages 198– 204, 1994.</p>
<p>[13] M. J. Mataric and M. Pomplun. Fixation behavior in observation and imitation of human movement. Cognitive Brain Research, 7:191–202, 1998.</p>
<p>[14] S. Schaal. Is imitation learning the route to humanoid robots? Trends in Cognitive Sciences, 3:233–242, 1999.</p>
<p>[15] A. Billard and K. Dautenhahn. Experiments in social robotics- grounding and use of communication in robotic agents. Adaptive Behavior, 7:3–4, 2000.</p>
<p>[16] C. Breazeal and B. Scassellati. Challenges in building robots that imitate people. In K. Dautenhahn and C. L. Nehaniv (Eds.), Imitation in animals and artifacts, pages 363–390, 2002.</p>
<p>[17] K. Dautenhahn and C. Nehaniv. Imitation in Animals and Artifacts. Cambridge, MA: MIT Press, 2002.</p>
<p>[18] B. A. Olshausen R. P. N. Rao and M. S. Lewicki (Eds.). Probabilistic Models of the Brain: Perception and Neural Function. Cambridge, MA: MIT Press, 2002.</p>
<p>[19] KP. Krding and D. Wolpert. Bayesian integration in sensorimotor learning. Nature, 427:244– 247, 2004.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
