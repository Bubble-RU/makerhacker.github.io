<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>134 nips-2012-Finite Sample Convergence Rates of Zero-Order Stochastic Optimization Methods</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-134" href="#">nips2012-134</a> knowledge-graph by maker-knowledge-mining</p><h1>134 nips-2012-Finite Sample Convergence Rates of Zero-Order Stochastic Optimization Methods</h1>
<br/><p>Source: <a title="nips-2012-134-pdf" href="http://papers.nips.cc/paper/4550-finite-sample-convergence-rates-of-zero-order-stochastic-optimization-methods.pdf">pdf</a></p><p>Author: Andre Wibisono, Martin J. Wainwright, Michael I. Jordan, John C. Duchi</p><p>Abstract: We consider derivative-free algorithms for stochastic optimization problems that use only noisy function values rather than gradients, analyzing their ﬁnite-sample convergence rates. We show that if pairs of function values are available, algorithms that √ gradient estimates based on random perturbations suffer a factor use of at most d in convergence rate over traditional stochastic gradient methods, where d is the problem dimension. We complement our algorithmic development with information-theoretic lower bounds on the minimax convergence rate of such problems, which show that our bounds are sharp with respect to all problemdependent quantities: they cannot be improved by more than constant factors. 1</p><p>Reference: <a title="nips-2012-134-reference" href="../nips2012_reference/nips-2012-Finite_Sample_Convergence_Rates_of_Zero-Order_Stochastic_Optimization_Methods_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('fv', 0.448), ('fg', 0.377), ('mir', 0.254), ('grady', 0.198), ('rg', 0.195), ('minimax', 0.195), ('pv', 0.174), ('agarw', 0.162), ('stochast', 0.157), ('bandit', 0.149), ('desc', 0.14), ('fw', 0.135), ('zz', 0.13), ('corol', 0.127), ('rd', 0.117), ('convex', 0.111), ('proxim', 0.11), ('ut', 0.109), ('subgrady', 0.106), ('rat', 0.103)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="134-tfidf-1" href="./nips-2012-Finite_Sample_Convergence_Rates_of_Zero-Order_Stochastic_Optimization_Methods.html">134 nips-2012-Finite Sample Convergence Rates of Zero-Order Stochastic Optimization Methods</a></p>
<p>2 0.22605145 <a title="134-tfidf-2" href="./nips-2012-Optimal_Regularized_Dual_Averaging_Methods_for_Stochastic_Optimization.html">263 nips-2012-Optimal Regularized Dual Averaging Methods for Stochastic Optimization</a></p>
<p>3 0.21084037 <a title="134-tfidf-3" href="./nips-2012-Stochastic_optimization_and_sparse_statistical_recovery%3A_Optimal_algorithms_for_high_dimensions.html">325 nips-2012-Stochastic optimization and sparse statistical recovery: Optimal algorithms for high dimensions</a></p>
<p>4 0.18640521 <a title="134-tfidf-4" href="./nips-2012-A_Stochastic_Gradient_Method_with_an_Exponential_Convergence__Rate_for_Finite_Training_Sets.html">20 nips-2012-A Stochastic Gradient Method with an Exponential Convergence  Rate for Finite Training Sets</a></p>
<p>5 0.17632042 <a title="134-tfidf-5" href="./nips-2012-The_Perturbed_Variation.html">338 nips-2012-The Perturbed Variation</a></p>
<p>6 0.15428279 <a title="134-tfidf-6" href="./nips-2012-Mirror_Descent_Meets_Fixed_Share_%28and_feels_no_regret%29.html">216 nips-2012-Mirror Descent Meets Fixed Share (and feels no regret)</a></p>
<p>7 0.15358642 <a title="134-tfidf-7" href="./nips-2012-Privacy_Aware_Learning.html">275 nips-2012-Privacy Aware Learning</a></p>
<p>8 0.14710879 <a title="134-tfidf-8" href="./nips-2012-Scaled_Gradients_on_Grassmann_Manifolds_for_Matrix_Completion.html">301 nips-2012-Scaled Gradients on Grassmann Manifolds for Matrix Completion</a></p>
<p>9 0.12473702 <a title="134-tfidf-9" href="./nips-2012-Stochastic_Gradient_Descent_with_Only_One_Projection.html">324 nips-2012-Stochastic Gradient Descent with Only One Projection</a></p>
<p>10 0.12143077 <a title="134-tfidf-10" href="./nips-2012-Proximal_Newton-type_methods_for_convex_optimization.html">282 nips-2012-Proximal Newton-type methods for convex optimization</a></p>
<p>11 0.12055304 <a title="134-tfidf-11" href="./nips-2012-Iterative_Thresholding_Algorithm_for_Sparse_Inverse_Covariance_Estimation.html">164 nips-2012-Iterative Thresholding Algorithm for Sparse Inverse Covariance Estimation</a></p>
<p>12 0.11112876 <a title="134-tfidf-12" href="./nips-2012-A_Convex_Formulation_for_Learning_Scale-Free_Networks_via_Submodular_Relaxation.html">6 nips-2012-A Convex Formulation for Learning Scale-Free Networks via Submodular Relaxation</a></p>
<p>13 0.10736198 <a title="134-tfidf-13" href="./nips-2012-No-Regret_Algorithms_for_Unconstrained_Online_Convex_Optimization.html">241 nips-2012-No-Regret Algorithms for Unconstrained Online Convex Optimization</a></p>
<p>14 0.10550245 <a title="134-tfidf-14" href="./nips-2012-A_quasi-Newton_proximal_splitting_method.html">27 nips-2012-A quasi-Newton proximal splitting method</a></p>
<p>15 0.10324939 <a title="134-tfidf-15" href="./nips-2012-Provable_ICA_with_Unknown_Gaussian_Noise%2C_with_Implications_for_Gaussian_Mixtures_and_Autoencoders.html">281 nips-2012-Provable ICA with Unknown Gaussian Noise, with Implications for Gaussian Mixtures and Autoencoders</a></p>
<p>16 0.10238883 <a title="134-tfidf-16" href="./nips-2012-Globally_Convergent_Dual_MAP_LP_Relaxation_Solvers_using_Fenchel-Young_Margins.html">143 nips-2012-Globally Convergent Dual MAP LP Relaxation Solvers using Fenchel-Young Margins</a></p>
<p>17 0.1021826 <a title="134-tfidf-17" href="./nips-2012-Convergence_Rate_Analysis_of_MAP_Coordinate_Minimization_Algorithms.html">84 nips-2012-Convergence Rate Analysis of MAP Coordinate Minimization Algorithms</a></p>
<p>18 0.098071478 <a title="134-tfidf-18" href="./nips-2012-Mixability_in_Statistical_Learning.html">217 nips-2012-Mixability in Statistical Learning</a></p>
<p>19 0.095678076 <a title="134-tfidf-19" href="./nips-2012-Regularized_Off-Policy_TD-Learning.html">292 nips-2012-Regularized Off-Policy TD-Learning</a></p>
<p>20 0.08983051 <a title="134-tfidf-20" href="./nips-2012-Online_allocation_and_homogeneous_partitioning_for_piecewise_constant_mean-approximation.html">261 nips-2012-Online allocation and homogeneous partitioning for piecewise constant mean-approximation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.218), (1, 0.029), (2, 0.118), (3, -0.136), (4, 0.04), (5, 0.171), (6, -0.049), (7, -0.047), (8, -0.032), (9, 0.042), (10, -0.046), (11, 0.044), (12, 0.166), (13, 0.035), (14, 0.043), (15, 0.019), (16, 0.053), (17, 0.064), (18, -0.131), (19, -0.099), (20, 0.029), (21, -0.016), (22, -0.07), (23, 0.095), (24, 0.074), (25, -0.119), (26, -0.021), (27, 0.006), (28, -0.045), (29, -0.054), (30, -0.0), (31, -0.104), (32, 0.061), (33, 0.039), (34, 0.082), (35, 0.047), (36, 0.165), (37, 0.035), (38, -0.097), (39, 0.003), (40, 0.071), (41, -0.07), (42, -0.06), (43, 0.053), (44, -0.01), (45, -0.001), (46, 0.098), (47, 0.063), (48, -0.012), (49, 0.043)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94749063 <a title="134-lsi-1" href="./nips-2012-Finite_Sample_Convergence_Rates_of_Zero-Order_Stochastic_Optimization_Methods.html">134 nips-2012-Finite Sample Convergence Rates of Zero-Order Stochastic Optimization Methods</a></p>
<p>2 0.83375734 <a title="134-lsi-2" href="./nips-2012-Stochastic_optimization_and_sparse_statistical_recovery%3A_Optimal_algorithms_for_high_dimensions.html">325 nips-2012-Stochastic optimization and sparse statistical recovery: Optimal algorithms for high dimensions</a></p>
<p>3 0.83166385 <a title="134-lsi-3" href="./nips-2012-Optimal_Regularized_Dual_Averaging_Methods_for_Stochastic_Optimization.html">263 nips-2012-Optimal Regularized Dual Averaging Methods for Stochastic Optimization</a></p>
<p>4 0.81390882 <a title="134-lsi-4" href="./nips-2012-A_Stochastic_Gradient_Method_with_an_Exponential_Convergence__Rate_for_Finite_Training_Sets.html">20 nips-2012-A Stochastic Gradient Method with an Exponential Convergence  Rate for Finite Training Sets</a></p>
<p>5 0.72023225 <a title="134-lsi-5" href="./nips-2012-Query_Complexity_of_Derivative-Free_Optimization.html">285 nips-2012-Query Complexity of Derivative-Free Optimization</a></p>
<p>6 0.70314854 <a title="134-lsi-6" href="./nips-2012-Communication-Efficient_Algorithms_for_Statistical_Optimization.html">76 nips-2012-Communication-Efficient Algorithms for Statistical Optimization</a></p>
<p>7 0.69723743 <a title="134-lsi-7" href="./nips-2012-Interpreting_prediction_markets%3A_a_stochastic_approach.html">161 nips-2012-Interpreting prediction markets: a stochastic approach</a></p>
<p>8 0.66546559 <a title="134-lsi-8" href="./nips-2012-No-Regret_Algorithms_for_Unconstrained_Online_Convex_Optimization.html">241 nips-2012-No-Regret Algorithms for Unconstrained Online Convex Optimization</a></p>
<p>9 0.62745553 <a title="134-lsi-9" href="./nips-2012-Mixability_in_Statistical_Learning.html">217 nips-2012-Mixability in Statistical Learning</a></p>
<p>10 0.6195581 <a title="134-lsi-10" href="./nips-2012-Mirror_Descent_Meets_Fixed_Share_%28and_feels_no_regret%29.html">216 nips-2012-Mirror Descent Meets Fixed Share (and feels no regret)</a></p>
<p>11 0.59588397 <a title="134-lsi-11" href="./nips-2012-Fast_Variational_Inference_in_the_Conjugate_Exponential_Family.html">129 nips-2012-Fast Variational Inference in the Conjugate Exponential Family</a></p>
<p>12 0.57929868 <a title="134-lsi-12" href="./nips-2012-Stochastic_Gradient_Descent_with_Only_One_Projection.html">324 nips-2012-Stochastic Gradient Descent with Only One Projection</a></p>
<p>13 0.56300426 <a title="134-lsi-13" href="./nips-2012-Majorization_for_CRFs_and_Latent_Likelihoods.html">206 nips-2012-Majorization for CRFs and Latent Likelihoods</a></p>
<p>14 0.55959356 <a title="134-lsi-14" href="./nips-2012-Privacy_Aware_Learning.html">275 nips-2012-Privacy Aware Learning</a></p>
<p>15 0.53835428 <a title="134-lsi-15" href="./nips-2012-Accelerated_Training_for_Matrix-norm_Regularization%3A_A_Boosting_Approach.html">29 nips-2012-Accelerated Training for Matrix-norm Regularization: A Boosting Approach</a></p>
<p>16 0.5323202 <a title="134-lsi-16" href="./nips-2012-Convergence_Rate_Analysis_of_MAP_Coordinate_Minimization_Algorithms.html">84 nips-2012-Convergence Rate Analysis of MAP Coordinate Minimization Algorithms</a></p>
<p>17 0.53155231 <a title="134-lsi-17" href="./nips-2012-Iterative_Thresholding_Algorithm_for_Sparse_Inverse_Covariance_Estimation.html">164 nips-2012-Iterative Thresholding Algorithm for Sparse Inverse Covariance Estimation</a></p>
<p>18 0.531268 <a title="134-lsi-18" href="./nips-2012-Synchronization_can_Control_Regularization_in_Neural_Systems_via_Correlated_Noise_Processes.html">333 nips-2012-Synchronization can Control Regularization in Neural Systems via Correlated Noise Processes</a></p>
<p>19 0.52589595 <a title="134-lsi-19" href="./nips-2012-Efficient_Reinforcement_Learning_for_High_Dimensional_Linear_Quadratic_Systems.html">110 nips-2012-Efficient Reinforcement Learning for High Dimensional Linear Quadratic Systems</a></p>
<p>20 0.50765502 <a title="134-lsi-20" href="./nips-2012-A_quasi-Newton_proximal_splitting_method.html">27 nips-2012-A quasi-Newton proximal splitting method</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(11, 0.069), (47, 0.11), (64, 0.253), (67, 0.038), (70, 0.117), (85, 0.072), (94, 0.156), (99, 0.102)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.89134926 <a title="134-lda-1" href="./nips-2012-Multiplicative_Forests_for_Continuous-Time_Processes.html">232 nips-2012-Multiplicative Forests for Continuous-Time Processes</a></p>
<p>2 0.88873899 <a title="134-lda-2" href="./nips-2012-Identification_of_Recurrent_Patterns_in_the_Activation_of_Brain_Networks.html">157 nips-2012-Identification of Recurrent Patterns in the Activation of Brain Networks</a></p>
<p>3 0.88080102 <a title="134-lda-3" href="./nips-2012-Compressive_Sensing_MRI_with_Wavelet_Tree_Sparsity.html">78 nips-2012-Compressive Sensing MRI with Wavelet Tree Sparsity</a></p>
<p>4 0.82670689 <a title="134-lda-4" href="./nips-2012-Emergence_of_Object-Selective_Features_in_Unsupervised_Feature_Learning.html">116 nips-2012-Emergence of Object-Selective Features in Unsupervised Feature Learning</a></p>
<p>5 0.82670641 <a title="134-lda-5" href="./nips-2012-Burn-in%2C_bias%2C_and_the_rationality_of_anchoring.html">62 nips-2012-Burn-in, bias, and the rationality of anchoring</a></p>
<p>6 0.80763847 <a title="134-lda-6" href="./nips-2012-Nonparametric_Max-Margin_Matrix_Factorization_for_Collaborative_Prediction.html">246 nips-2012-Nonparametric Max-Margin Matrix Factorization for Collaborative Prediction</a></p>
<p>same-paper 7 0.78860402 <a title="134-lda-7" href="./nips-2012-Finite_Sample_Convergence_Rates_of_Zero-Order_Stochastic_Optimization_Methods.html">134 nips-2012-Finite Sample Convergence Rates of Zero-Order Stochastic Optimization Methods</a></p>
<p>8 0.75112075 <a title="134-lda-8" href="./nips-2012-The_Perturbed_Variation.html">338 nips-2012-The Perturbed Variation</a></p>
<p>9 0.74527884 <a title="134-lda-9" href="./nips-2012-Learning_visual_motion_in_recurrent_neural_networks.html">195 nips-2012-Learning visual motion in recurrent neural networks</a></p>
<p>10 0.73285532 <a title="134-lda-10" href="./nips-2012-Privacy_Aware_Learning.html">275 nips-2012-Privacy Aware Learning</a></p>
<p>11 0.72814828 <a title="134-lda-11" href="./nips-2012-A_lattice_filter_model_of_the_visual_pathway.html">23 nips-2012-A lattice filter model of the visual pathway</a></p>
<p>12 0.72760463 <a title="134-lda-12" href="./nips-2012-Wavelet_based_multi-scale_shape_features_on_arbitrary_surfaces_for_cortical_thickness_discrimination.html">363 nips-2012-Wavelet based multi-scale shape features on arbitrary surfaces for cortical thickness discrimination</a></p>
<p>13 0.72530937 <a title="134-lda-13" href="./nips-2012-Collaborative_Ranking_With_17_Parameters.html">75 nips-2012-Collaborative Ranking With 17 Parameters</a></p>
<p>14 0.71699643 <a title="134-lda-14" href="./nips-2012-Efficient_and_direct_estimation_of_a_neural_subunit_model_for_sensory_coding.html">113 nips-2012-Efficient and direct estimation of a neural subunit model for sensory coding</a></p>
<p>15 0.71674758 <a title="134-lda-15" href="./nips-2012-Complex_Inference_in_Neural_Circuits_with_Probabilistic_Population_Codes_and_Topic_Models.html">77 nips-2012-Complex Inference in Neural Circuits with Probabilistic Population Codes and Topic Models</a></p>
<p>16 0.71600211 <a title="134-lda-16" href="./nips-2012-Hierarchical_Optimistic_Region_Selection_driven_by_Curiosity.html">149 nips-2012-Hierarchical Optimistic Region Selection driven by Curiosity</a></p>
<p>17 0.71446866 <a title="134-lda-17" href="./nips-2012-Weighted_Likelihood_Policy_Search_with_Model_Selection.html">364 nips-2012-Weighted Likelihood Policy Search with Model Selection</a></p>
<p>18 0.7143501 <a title="134-lda-18" href="./nips-2012-Approximate_Message_Passing_with_Consistent_Parameter_Estimation_and_Applications_to_Sparse_Learning.html">43 nips-2012-Approximate Message Passing with Consistent Parameter Estimation and Applications to Sparse Learning</a></p>
<p>19 0.71418369 <a title="134-lda-19" href="./nips-2012-Random_Utility_Theory_for_Social_Choice.html">286 nips-2012-Random Utility Theory for Social Choice</a></p>
<p>20 0.71359062 <a title="134-lda-20" href="./nips-2012-Perfect_Dimensionality_Recovery_by_Variational_Bayesian_PCA.html">268 nips-2012-Perfect Dimensionality Recovery by Variational Bayesian PCA</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
