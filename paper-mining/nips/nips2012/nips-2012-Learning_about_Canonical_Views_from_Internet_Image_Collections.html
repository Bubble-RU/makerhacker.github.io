<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>185 nips-2012-Learning about Canonical Views from Internet Image Collections</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-185" href="#">nips2012-185</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>185 nips-2012-Learning about Canonical Views from Internet Image Collections</h1>
<br/><p>Source: <a title="nips-2012-185-pdf" href="http://papers.nips.cc/paper/4827-learning-about-canonical-views-from-internet-image-collections.pdf">pdf</a></p><p>Author: Elad Mezuman, Yair Weiss</p><p>Abstract: Although human object recognition is supposedly robust to viewpoint, much research on human perception indicates that there is a preferred or “canonical” view of objects. This phenomenon was discovered more than 30 years ago but the canonical view of only a small number of categories has been validated experimentally. Moreover, the explanation for why humans prefer the canonical view over other views remains elusive. In this paper we ask: Can we use Internet image collections to learn more about canonical views? We start by manually ﬁnding the most common view in the results returned by Internet search engines when queried with the objects used in psychophysical experiments. Our results clearly show that the most likely view in the search engine corresponds to the same view preferred by human subjects in experiments. We also present a simple method to ﬁnd the most likely view in an image collection and apply it to hundreds of categories. Using the new data we have collected we present strong evidence against the two most prominent formal theories of canonical views and provide novel constraints for new theories. 1</p><p>Reference: <a title="nips-2012-185-reference" href="../nips2012_reference/nips-2012-Learning_about_Canonical_Views_from_Internet_Image_Collections_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('canon', 0.509), ('view', 0.364), ('gist', 0.319), ('im', 0.294), ('categ', 0.2), ('palm', 0.18), ('frequ', 0.174), ('psychophys', 0.145), ('internet', 0.141), ('rosch', 0.139), ('hors', 0.135), ('parz', 0.134), ('photograph', 0.113), ('prefer', 0.108), ('hum', 0.097), ('imagenet', 0.096), ('icon', 0.092), ('hundr', 0.077), ('googl', 0.071), ('viewpoint', 0.069)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="185-tfidf-1" href="./nips-2012-Learning_about_Canonical_Views_from_Internet_Image_Collections.html">185 nips-2012-Learning about Canonical Views from Internet Image Collections</a></p>
<p>2 0.18882482 <a title="185-tfidf-2" href="./nips-2012-Memorability_of_Image_Regions.html">210 nips-2012-Memorability of Image Regions</a></p>
<p>3 0.16287243 <a title="185-tfidf-3" href="./nips-2012-Timely_Object_Recognition.html">344 nips-2012-Timely Object Recognition</a></p>
<p>4 0.12931019 <a title="185-tfidf-4" href="./nips-2012-Deep_Representations_and_Codes_for_Image_Auto-Annotation.html">92 nips-2012-Deep Representations and Codes for Image Auto-Annotation</a></p>
<p>5 0.10627876 <a title="185-tfidf-5" href="./nips-2012-ImageNet_Classification_with_Deep_Convolutional_Neural_Networks.html">158 nips-2012-ImageNet Classification with Deep Convolutional Neural Networks</a></p>
<p>6 0.095677614 <a title="185-tfidf-6" href="./nips-2012-Shifting_Weights%3A_Adapting_Object_Detectors_from_Image_to_Video.html">311 nips-2012-Shifting Weights: Adapting Object Detectors from Image to Video</a></p>
<p>7 0.090146124 <a title="185-tfidf-7" href="./nips-2012-Semi-Crowdsourced_Clustering%3A_Generalizing_Crowd_Labeling_by_Robust_Distance_Metric_Learning.html">307 nips-2012-Semi-Crowdsourced Clustering: Generalizing Crowd Labeling by Robust Distance Metric Learning</a></p>
<p>8 0.086821668 <a title="185-tfidf-8" href="./nips-2012-Analyzing_3D_Objects_in_Cluttered_Images.html">40 nips-2012-Analyzing 3D Objects in Cluttered Images</a></p>
<p>9 0.080024227 <a title="185-tfidf-9" href="./nips-2012-Learning_to_Align_from_Scratch.html">193 nips-2012-Learning to Align from Scratch</a></p>
<p>10 0.079591408 <a title="185-tfidf-10" href="./nips-2012-Deep_Learning_of_Invariant_Features_via_Simulated_Fixations_in_Video.html">90 nips-2012-Deep Learning of Invariant Features via Simulated Fixations in Video</a></p>
<p>11 0.077085242 <a title="185-tfidf-11" href="./nips-2012-A_Spectral_Algorithm_for_Latent_Dirichlet_Allocation.html">19 nips-2012-A Spectral Algorithm for Latent Dirichlet Allocation</a></p>
<p>12 0.076876357 <a title="185-tfidf-12" href="./nips-2012-A_Generative_Model_for_Parts-based_Object_Segmentation.html">8 nips-2012-A Generative Model for Parts-based Object Segmentation</a></p>
<p>13 0.075840458 <a title="185-tfidf-13" href="./nips-2012-Localizing_3D_cuboids_in_single-view_images.html">201 nips-2012-Localizing 3D cuboids in single-view images</a></p>
<p>14 0.07540819 <a title="185-tfidf-14" href="./nips-2012-Unsupervised_Template_Learning_for_Fine-Grained_Object_Recognition.html">357 nips-2012-Unsupervised Template Learning for Fine-Grained Object Recognition</a></p>
<p>15 0.072094373 <a title="185-tfidf-15" href="./nips-2012-Context-Sensitive_Decision_Forests_for_Object_Detection.html">81 nips-2012-Context-Sensitive Decision Forests for Object Detection</a></p>
<p>16 0.070610002 <a title="185-tfidf-16" href="./nips-2012-Visual_Recognition_using_Embedded_Feature_Selection_for_Curvature_Self-Similarity.html">360 nips-2012-Visual Recognition using Embedded Feature Selection for Curvature Self-Similarity</a></p>
<p>17 0.070010103 <a title="185-tfidf-17" href="./nips-2012-Natural_Images%2C_Gaussian_Mixtures_and_Dead_Leaves.html">235 nips-2012-Natural Images, Gaussian Mixtures and Dead Leaves</a></p>
<p>18 0.069081768 <a title="185-tfidf-18" href="./nips-2012-Small-Variance_Asymptotics_for_Exponential_Family_Dirichlet_Process_Mixture_Models.html">316 nips-2012-Small-Variance Asymptotics for Exponential Family Dirichlet Process Mixture Models</a></p>
<p>19 0.0676497 <a title="185-tfidf-19" href="./nips-2012-Image_Denoising_and_Inpainting_with_Deep_Neural_Networks.html">159 nips-2012-Image Denoising and Inpainting with Deep Neural Networks</a></p>
<p>20 0.067536071 <a title="185-tfidf-20" href="./nips-2012-3D_Object_Detection_and_Viewpoint_Estimation_with_a_Deformable_3D_Cuboid_Model.html">1 nips-2012-3D Object Detection and Viewpoint Estimation with a Deformable 3D Cuboid Model</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.161), (1, -0.046), (2, -0.05), (3, 0.168), (4, -0.134), (5, 0.017), (6, -0.026), (7, 0.015), (8, 0.004), (9, 0.027), (10, 0.034), (11, 0.03), (12, -0.042), (13, 0.031), (14, -0.006), (15, 0.07), (16, 0.057), (17, 0.067), (18, -0.036), (19, 0.083), (20, -0.012), (21, -0.01), (22, -0.017), (23, -0.059), (24, 0.043), (25, 0.019), (26, 0.052), (27, -0.026), (28, 0.046), (29, 0.056), (30, 0.021), (31, -0.06), (32, 0.081), (33, -0.014), (34, 0.007), (35, -0.018), (36, 0.035), (37, 0.083), (38, -0.098), (39, 0.129), (40, 0.017), (41, -0.006), (42, -0.025), (43, 0.02), (44, 0.02), (45, 0.089), (46, 0.036), (47, 0.005), (48, -0.074), (49, 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98114467 <a title="185-lsi-1" href="./nips-2012-Learning_about_Canonical_Views_from_Internet_Image_Collections.html">185 nips-2012-Learning about Canonical Views from Internet Image Collections</a></p>
<p>2 0.85859209 <a title="185-lsi-2" href="./nips-2012-Memorability_of_Image_Regions.html">210 nips-2012-Memorability of Image Regions</a></p>
<p>3 0.83956671 <a title="185-lsi-3" href="./nips-2012-Unsupervised_Template_Learning_for_Fine-Grained_Object_Recognition.html">357 nips-2012-Unsupervised Template Learning for Fine-Grained Object Recognition</a></p>
<p>4 0.75190026 <a title="185-lsi-4" href="./nips-2012-Discriminatively_Trained_Sparse_Code_Gradients_for_Contour_Detection.html">101 nips-2012-Discriminatively Trained Sparse Code Gradients for Contour Detection</a></p>
<p>5 0.72377837 <a title="185-lsi-5" href="./nips-2012-Deep_Representations_and_Codes_for_Image_Auto-Annotation.html">92 nips-2012-Deep Representations and Codes for Image Auto-Annotation</a></p>
<p>6 0.70715684 <a title="185-lsi-6" href="./nips-2012-Locally_Uniform_Comparison_Image_Descriptor.html">202 nips-2012-Locally Uniform Comparison Image Descriptor</a></p>
<p>7 0.6987012 <a title="185-lsi-7" href="./nips-2012-Image_Denoising_and_Inpainting_with_Deep_Neural_Networks.html">159 nips-2012-Image Denoising and Inpainting with Deep Neural Networks</a></p>
<p>8 0.69172466 <a title="185-lsi-8" href="./nips-2012-Natural_Images%2C_Gaussian_Mixtures_and_Dead_Leaves.html">235 nips-2012-Natural Images, Gaussian Mixtures and Dead Leaves</a></p>
<p>9 0.68738276 <a title="185-lsi-9" href="./nips-2012-A_Generative_Model_for_Parts-based_Object_Segmentation.html">8 nips-2012-A Generative Model for Parts-based Object Segmentation</a></p>
<p>10 0.67995697 <a title="185-lsi-10" href="./nips-2012-Graphical_Gaussian_Vector_for_Image_Categorization.html">146 nips-2012-Graphical Gaussian Vector for Image Categorization</a></p>
<p>11 0.6455735 <a title="185-lsi-11" href="./nips-2012-A_systematic_approach_to_extracting_semantic_information_from_functional_MRI_data.html">28 nips-2012-A systematic approach to extracting semantic information from functional MRI data</a></p>
<p>12 0.63996315 <a title="185-lsi-12" href="./nips-2012-Learning_to_Align_from_Scratch.html">193 nips-2012-Learning to Align from Scratch</a></p>
<p>13 0.63735598 <a title="185-lsi-13" href="./nips-2012-Learning_Image_Descriptors_with_the_Boosting-Trick.html">176 nips-2012-Learning Image Descriptors with the Boosting-Trick</a></p>
<p>14 0.61801618 <a title="185-lsi-14" href="./nips-2012-Context-Sensitive_Decision_Forests_for_Object_Detection.html">81 nips-2012-Context-Sensitive Decision Forests for Object Detection</a></p>
<p>15 0.59004337 <a title="185-lsi-15" href="./nips-2012-Localizing_3D_cuboids_in_single-view_images.html">201 nips-2012-Localizing 3D cuboids in single-view images</a></p>
<p>16 0.58364636 <a title="185-lsi-16" href="./nips-2012-Compressive_Sensing_MRI_with_Wavelet_Tree_Sparsity.html">78 nips-2012-Compressive Sensing MRI with Wavelet Tree Sparsity</a></p>
<p>17 0.57952219 <a title="185-lsi-17" href="./nips-2012-Timely_Object_Recognition.html">344 nips-2012-Timely Object Recognition</a></p>
<p>18 0.56480241 <a title="185-lsi-18" href="./nips-2012-3D_Social_Saliency_from_Head-mounted_Cameras.html">2 nips-2012-3D Social Saliency from Head-mounted Cameras</a></p>
<p>19 0.557477 <a title="185-lsi-19" href="./nips-2012-Semantic_Kernel_Forests_from_Multiple_Taxonomies.html">306 nips-2012-Semantic Kernel Forests from Multiple Taxonomies</a></p>
<p>20 0.549981 <a title="185-lsi-20" href="./nips-2012-Searching_for_objects_driven_by_context.html">303 nips-2012-Searching for objects driven by context</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(11, 0.595), (47, 0.048), (67, 0.054), (70, 0.046), (85, 0.055), (94, 0.054), (99, 0.05)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.963162 <a title="185-lda-1" href="./nips-2012-Learning_about_Canonical_Views_from_Internet_Image_Collections.html">185 nips-2012-Learning about Canonical Views from Internet Image Collections</a></p>
<p>2 0.94007361 <a title="185-lda-2" href="./nips-2012-Controlled_Recognition_Bounds_for_Visual_Learning_and_Exploration.html">83 nips-2012-Controlled Recognition Bounds for Visual Learning and Exploration</a></p>
<p>3 0.90000403 <a title="185-lda-3" href="./nips-2012-Learning_curves_for_multi-task_Gaussian_process_regression.html">187 nips-2012-Learning curves for multi-task Gaussian process regression</a></p>
<p>4 0.82180536 <a title="185-lda-4" href="./nips-2012-Pointwise_Tracking_the_Optimal_Regression_Function.html">271 nips-2012-Pointwise Tracking the Optimal Regression Function</a></p>
<p>5 0.81366104 <a title="185-lda-5" href="./nips-2012-FastEx%3A_Hash_Clustering_with_Exponential_Families.html">126 nips-2012-FastEx: Hash Clustering with Exponential Families</a></p>
<p>6 0.68908942 <a title="185-lda-6" href="./nips-2012-On_the_connections_between_saliency_and_tracking.html">256 nips-2012-On the connections between saliency and tracking</a></p>
<p>7 0.67166531 <a title="185-lda-7" href="./nips-2012-Clustering_Aggregation_as_Maximum-Weight_Independent_Set.html">68 nips-2012-Clustering Aggregation as Maximum-Weight Independent Set</a></p>
<p>8 0.65051943 <a title="185-lda-8" href="./nips-2012-Action-Model_Based_Multi-agent_Plan_Recognition.html">31 nips-2012-Action-Model Based Multi-agent Plan Recognition</a></p>
<p>9 0.64098543 <a title="185-lda-9" href="./nips-2012-Dip-means%3A_an_incremental_clustering_method_for_estimating_the_number_of_clusters.html">99 nips-2012-Dip-means: an incremental clustering method for estimating the number of clusters</a></p>
<p>10 0.63959277 <a title="185-lda-10" href="./nips-2012-Learning_Multiple_Tasks_using_Shared_Hypotheses.html">181 nips-2012-Learning Multiple Tasks using Shared Hypotheses</a></p>
<p>11 0.63223732 <a title="185-lda-11" href="./nips-2012-Bandit_Algorithms_boost_Brain_Computer_Interfaces_for_motor-task_selection_of_a_brain-controlled_button.html">50 nips-2012-Bandit Algorithms boost Brain Computer Interfaces for motor-task selection of a brain-controlled button</a></p>
<p>12 0.63176072 <a title="185-lda-12" href="./nips-2012-Searching_for_objects_driven_by_context.html">303 nips-2012-Searching for objects driven by context</a></p>
<p>13 0.62611419 <a title="185-lda-13" href="./nips-2012-Visual_Recognition_using_Embedded_Feature_Selection_for_Curvature_Self-Similarity.html">360 nips-2012-Visual Recognition using Embedded Feature Selection for Curvature Self-Similarity</a></p>
<p>14 0.62525553 <a title="185-lda-14" href="./nips-2012-Active_Comparison_of_Prediction_Models.html">32 nips-2012-Active Comparison of Prediction Models</a></p>
<p>15 0.61202192 <a title="185-lda-15" href="./nips-2012-Locally_Uniform_Comparison_Image_Descriptor.html">202 nips-2012-Locally Uniform Comparison Image Descriptor</a></p>
<p>16 0.6042648 <a title="185-lda-16" href="./nips-2012-Diffusion_Decision_Making_for_Adaptive_k-Nearest_Neighbor_Classification.html">97 nips-2012-Diffusion Decision Making for Adaptive k-Nearest Neighbor Classification</a></p>
<p>17 0.60280335 <a title="185-lda-17" href="./nips-2012-Minimax_Multi-Task_Learning_and_a_Generalized_Loss-Compositional_Paradigm_for_MTL.html">212 nips-2012-Minimax Multi-Task Learning and a Generalized Loss-Compositional Paradigm for MTL</a></p>
<p>18 0.60067809 <a title="185-lda-18" href="./nips-2012-Transferring_Expectations_in_Model-based_Reinforcement_Learning.html">353 nips-2012-Transferring Expectations in Model-based Reinforcement Learning</a></p>
<p>19 0.60041165 <a title="185-lda-19" href="./nips-2012-Synchronization_can_Control_Regularization_in_Neural_Systems_via_Correlated_Noise_Processes.html">333 nips-2012-Synchronization can Control Regularization in Neural Systems via Correlated Noise Processes</a></p>
<p>20 0.59638464 <a title="185-lda-20" href="./nips-2012-Timely_Object_Recognition.html">344 nips-2012-Timely Object Recognition</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
