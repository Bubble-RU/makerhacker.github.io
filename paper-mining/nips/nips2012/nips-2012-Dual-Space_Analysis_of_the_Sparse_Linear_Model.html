<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>104 nips-2012-Dual-Space Analysis of the Sparse Linear Model</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-104" href="#">nips2012-104</a> knowledge-graph by maker-knowledge-mining</p><h1>104 nips-2012-Dual-Space Analysis of the Sparse Linear Model</h1>
<br/><p>Source: <a title="nips-2012-104-pdf" href="http://papers.nips.cc/paper/4507-dual-space-analysis-of-the-sparse-linear-model.pdf">pdf</a></p><p>Author: Yi Wu, David P. Wipf</p><p>Abstract: Sparse linear (or generalized linear) models combine a standard likelihood function with a sparse prior on the unknown coefﬁcients. These priors can conveniently be expressed as a maximization over zero-mean Gaussians with different variance hyperparameters. Standard MAP estimation (Type I) involves maximizing over both the hyperparameters and coefﬁcients, while an empirical Bayesian alternative (Type II) ﬁrst marginalizes the coefﬁcients and then maximizes over the hyperparameters, leading to a tractable posterior approximation. The underlying cost functions can be related via a dual-space framework from [22], which allows both the Type I or Type II objectives to be expressed in either coefﬁcient or hyperparmeter space. This perspective is useful because some analyses or extensions are more conducive to development in one space or the other. Herein we consider the estimation of a trade-off parameter balancing sparsity and data ﬁt. As this parameter is effectively a variance, natural estimators exist by assessing the problem in hyperparameter (variance) space, transitioning natural ideas from Type II to solve what is much less intuitive for Type I. In contrast, for analyses of update rules and sparsity properties of local and global solutions, as well as extensions to more general likelihood models, we can leverage coefﬁcient-space techniques developed for Type I and apply them to Type II. For example, this allows us to prove that Type II-inspired techniques can be successful recovering sparse coefﬁcients when unfavorable restricted isometry properties (RIP) lead to failure of popular ℓ1 reconstructions. It also facilitates the analysis of Type II when non-Gaussian likelihood models lead to intractable integrations. 1</p><p>Reference: <a title="nips-2012-104-reference" href="../nips2012_reference/nips-2012-Dual-Space_Analysis_of_the_Sparse_Linear_Model_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ii', 0.401), ('dict', 0.303), ('rvm', 0.292), ('reweight', 0.259), ('spars', 0.251), ('concav', 0.197), ('rip', 0.16), ('wipf', 0.126), ('coef', 0.126), ('typ', 0.118), ('nonzero', 0.113), ('penal', 0.107), ('arg', 0.105), ('rao', 0.102), ('hyperpry', 0.101), ('jeffrey', 0.101), ('mse', 0.1), ('bayes', 0.086), ('uncor', 0.083), ('pri', 0.079)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="104-tfidf-1" href="./nips-2012-Dual-Space_Analysis_of_the_Sparse_Linear_Model.html">104 nips-2012-Dual-Space Analysis of the Sparse Linear Model</a></p>
<p>2 0.18242343 <a title="104-tfidf-2" href="./nips-2012-Online_L1-Dictionary_Learning_with_Application_to_Novel_Document_Detection.html">258 nips-2012-Online L1-Dictionary Learning with Application to Novel Document Detection</a></p>
<p>3 0.16260046 <a title="104-tfidf-3" href="./nips-2012-Compressive_neural_representation_of_sparse%2C_high-dimensional_probabilities.html">79 nips-2012-Compressive neural representation of sparse, high-dimensional probabilities</a></p>
<p>4 0.15132865 <a title="104-tfidf-4" href="./nips-2012-A_Convex_Formulation_for_Learning_Scale-Free_Networks_via_Submodular_Relaxation.html">6 nips-2012-A Convex Formulation for Learning Scale-Free Networks via Submodular Relaxation</a></p>
<p>5 0.13892619 <a title="104-tfidf-5" href="./nips-2012-Fast_Bayesian_Inference_for_Non-Conjugate_Gaussian_Process_Regression.html">127 nips-2012-Fast Bayesian Inference for Non-Conjugate Gaussian Process Regression</a></p>
<p>6 0.12736534 <a title="104-tfidf-6" href="./nips-2012-Simultaneously_Leveraging_Output_and_Task_Structures_for_Multiple-Output_Regression.html">312 nips-2012-Simultaneously Leveraging Output and Task Structures for Multiple-Output Regression</a></p>
<p>7 0.12723126 <a title="104-tfidf-7" href="./nips-2012-Fused_sparsity_and_robust_estimation_for_linear_models_with_unknown_variance.html">139 nips-2012-Fused sparsity and robust estimation for linear models with unknown variance</a></p>
<p>8 0.1269604 <a title="104-tfidf-8" href="./nips-2012-Recovery_of_Sparse_Probability_Measures_via_Convex_Programming.html">290 nips-2012-Recovery of Sparse Probability Measures via Convex Programming</a></p>
<p>9 0.12410969 <a title="104-tfidf-9" href="./nips-2012-Probabilistic_Low-Rank_Subspace_Clustering.html">277 nips-2012-Probabilistic Low-Rank Subspace Clustering</a></p>
<p>10 0.12029766 <a title="104-tfidf-10" href="./nips-2012-Nonconvex_Penalization_Using_Laplace_Exponents_and_Concave_Conjugates.html">244 nips-2012-Nonconvex Penalization Using Laplace Exponents and Concave Conjugates</a></p>
<p>11 0.1151351 <a title="104-tfidf-11" href="./nips-2012-Clustering_Sparse_Graphs.html">69 nips-2012-Clustering Sparse Graphs</a></p>
<p>12 0.11473144 <a title="104-tfidf-12" href="./nips-2012-Learning_Manifolds_with_K-Means_and_K-Flats.html">179 nips-2012-Learning Manifolds with K-Means and K-Flats</a></p>
<p>13 0.11027484 <a title="104-tfidf-13" href="./nips-2012-Exact_and_Stable_Recovery_of_Sequences_of_Signals_with_Sparse_Increments_via_Differential__1-Minimization.html">120 nips-2012-Exact and Stable Recovery of Sequences of Signals with Sparse Increments via Differential  1-Minimization</a></p>
<p>14 0.10381767 <a title="104-tfidf-14" href="./nips-2012-Multilabel_Classification_using_Bayesian_Compressed_Sensing.html">228 nips-2012-Multilabel Classification using Bayesian Compressed Sensing</a></p>
<p>15 0.1013901 <a title="104-tfidf-15" href="./nips-2012-Iterative_Thresholding_Algorithm_for_Sparse_Inverse_Covariance_Estimation.html">164 nips-2012-Iterative Thresholding Algorithm for Sparse Inverse Covariance Estimation</a></p>
<p>16 0.10063677 <a title="104-tfidf-16" href="./nips-2012-Training_sparse_natural_image_models_with_a_fast_Gibbs_sampler_of_an_extended_state_space.html">349 nips-2012-Training sparse natural image models with a fast Gibbs sampler of an extended state space</a></p>
<p>17 0.097981453 <a title="104-tfidf-17" href="./nips-2012-Ensemble_weighted_kernel_estimators_for_multivariate_entropy_estimation.html">117 nips-2012-Ensemble weighted kernel estimators for multivariate entropy estimation</a></p>
<p>18 0.096385419 <a title="104-tfidf-18" href="./nips-2012-Value_Pursuit_Iteration.html">358 nips-2012-Value Pursuit Iteration</a></p>
<p>19 0.093511641 <a title="104-tfidf-19" href="./nips-2012-Link_Prediction_in_Graphs_with_Autoregressive_Features.html">199 nips-2012-Link Prediction in Graphs with Autoregressive Features</a></p>
<p>20 0.093012489 <a title="104-tfidf-20" href="./nips-2012-A_Polynomial-time_Form_of_Robust_Regression.html">16 nips-2012-A Polynomial-time Form of Robust Regression</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.286), (1, -0.042), (2, 0.079), (3, -0.0), (4, 0.086), (5, 0.025), (6, -0.046), (7, 0.021), (8, 0.016), (9, -0.042), (10, 0.089), (11, -0.004), (12, 0.04), (13, 0.039), (14, 0.081), (15, 0.027), (16, -0.02), (17, -0.003), (18, 0.066), (19, 0.151), (20, 0.078), (21, 0.008), (22, -0.017), (23, 0.006), (24, -0.071), (25, -0.028), (26, 0.105), (27, 0.025), (28, 0.024), (29, 0.104), (30, 0.07), (31, 0.113), (32, 0.076), (33, -0.076), (34, 0.127), (35, -0.007), (36, -0.071), (37, -0.003), (38, -0.008), (39, 0.035), (40, 0.021), (41, -0.018), (42, -0.056), (43, 0.037), (44, 0.059), (45, 0.121), (46, 0.005), (47, 0.033), (48, -0.073), (49, -0.089)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94756651 <a title="104-lsi-1" href="./nips-2012-Dual-Space_Analysis_of_the_Sparse_Linear_Model.html">104 nips-2012-Dual-Space Analysis of the Sparse Linear Model</a></p>
<p>2 0.81681865 <a title="104-lsi-2" href="./nips-2012-CPRL_--_An_Extension_of_Compressive_Sensing_to_the_Phase_Retrieval_Problem.html">63 nips-2012-CPRL -- An Extension of Compressive Sensing to the Phase Retrieval Problem</a></p>
<p>3 0.78898281 <a title="104-lsi-3" href="./nips-2012-Compressive_neural_representation_of_sparse%2C_high-dimensional_probabilities.html">79 nips-2012-Compressive neural representation of sparse, high-dimensional probabilities</a></p>
<p>4 0.69157654 <a title="104-lsi-4" href="./nips-2012-Approximate_Message_Passing_with_Consistent_Parameter_Estimation_and_Applications_to_Sparse_Learning.html">43 nips-2012-Approximate Message Passing with Consistent Parameter Estimation and Applications to Sparse Learning</a></p>
<p>5 0.68850219 <a title="104-lsi-5" href="./nips-2012-Fused_sparsity_and_robust_estimation_for_linear_models_with_unknown_variance.html">139 nips-2012-Fused sparsity and robust estimation for linear models with unknown variance</a></p>
<p>6 0.68697804 <a title="104-lsi-6" href="./nips-2012-Sparse_Prediction_with_the_%24k%24-Support_Norm.html">319 nips-2012-Sparse Prediction with the $k$-Support Norm</a></p>
<p>7 0.64384705 <a title="104-lsi-7" href="./nips-2012-Active_Learning_of_Multi-Index_Function_Models.html">34 nips-2012-Active Learning of Multi-Index Function Models</a></p>
<p>8 0.64286566 <a title="104-lsi-8" href="./nips-2012-Why_MCA%3F_Nonlinear_sparse_coding_with_spike-and-slab_prior_for_neurally_plausible_image_encoding.html">365 nips-2012-Why MCA? Nonlinear sparse coding with spike-and-slab prior for neurally plausible image encoding</a></p>
<p>9 0.63884097 <a title="104-lsi-9" href="./nips-2012-Nonconvex_Penalization_Using_Laplace_Exponents_and_Concave_Conjugates.html">244 nips-2012-Nonconvex Penalization Using Laplace Exponents and Concave Conjugates</a></p>
<p>10 0.63401407 <a title="104-lsi-10" href="./nips-2012-Recovery_of_Sparse_Probability_Measures_via_Convex_Programming.html">290 nips-2012-Recovery of Sparse Probability Measures via Convex Programming</a></p>
<p>11 0.6300801 <a title="104-lsi-11" href="./nips-2012-Perfect_Dimensionality_Recovery_by_Variational_Bayesian_PCA.html">268 nips-2012-Perfect Dimensionality Recovery by Variational Bayesian PCA</a></p>
<p>12 0.62606913 <a title="104-lsi-12" href="./nips-2012-Compressive_Sensing_MRI_with_Wavelet_Tree_Sparsity.html">78 nips-2012-Compressive Sensing MRI with Wavelet Tree Sparsity</a></p>
<p>13 0.61688673 <a title="104-lsi-13" href="./nips-2012-Factoring_nonnegative_matrices_with_linear_programs.html">125 nips-2012-Factoring nonnegative matrices with linear programs</a></p>
<p>14 0.61022735 <a title="104-lsi-14" href="./nips-2012-Learning_the_Dependency_Structure_of_Latent_Factors.html">192 nips-2012-Learning the Dependency Structure of Latent Factors</a></p>
<p>15 0.60958207 <a title="104-lsi-15" href="./nips-2012-Bayesian_Probabilistic_Co-Subspace_Addition.html">54 nips-2012-Bayesian Probabilistic Co-Subspace Addition</a></p>
<p>16 0.59587443 <a title="104-lsi-16" href="./nips-2012-Multi-Stage_Multi-Task_Feature_Learning.html">221 nips-2012-Multi-Stage Multi-Task Feature Learning</a></p>
<p>17 0.59545773 <a title="104-lsi-17" href="./nips-2012-Meta-Gaussian_Information_Bottleneck.html">211 nips-2012-Meta-Gaussian Information Bottleneck</a></p>
<p>18 0.59168947 <a title="104-lsi-18" href="./nips-2012-Affine_Independent_Variational_Inference.html">37 nips-2012-Affine Independent Variational Inference</a></p>
<p>19 0.58254582 <a title="104-lsi-19" href="./nips-2012-Matrix_reconstruction_with_the_local_max_norm.html">208 nips-2012-Matrix reconstruction with the local max norm</a></p>
<p>20 0.58149779 <a title="104-lsi-20" href="./nips-2012-Online_L1-Dictionary_Learning_with_Application_to_Novel_Document_Detection.html">258 nips-2012-Online L1-Dictionary Learning with Application to Novel Document Detection</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(11, 0.092), (31, 0.16), (47, 0.198), (64, 0.018), (67, 0.068), (70, 0.063), (85, 0.122), (94, 0.128), (99, 0.072)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.9389286 <a title="104-lda-1" href="./nips-2012-Analog_readout_for_optical_reservoir_computers.html">39 nips-2012-Analog readout for optical reservoir computers</a></p>
<p>2 0.92934972 <a title="104-lda-2" href="./nips-2012-Near-optimal_Differentially_Private_Principal_Components.html">237 nips-2012-Near-optimal Differentially Private Principal Components</a></p>
<p>same-paper 3 0.88825309 <a title="104-lda-3" href="./nips-2012-Dual-Space_Analysis_of_the_Sparse_Linear_Model.html">104 nips-2012-Dual-Space Analysis of the Sparse Linear Model</a></p>
<p>4 0.86548483 <a title="104-lda-4" href="./nips-2012-Active_Learning_of_Model_Evidence_Using_Bayesian_Quadrature.html">33 nips-2012-Active Learning of Model Evidence Using Bayesian Quadrature</a></p>
<p>5 0.86491287 <a title="104-lda-5" href="./nips-2012-Spectral_learning_of_linear_dynamics_from_generalised-linear_observations_with_application_to_neural_population_data.html">321 nips-2012-Spectral learning of linear dynamics from generalised-linear observations with application to neural population data</a></p>
<p>6 0.86383557 <a title="104-lda-6" href="./nips-2012-Repulsive_Mixtures.html">294 nips-2012-Repulsive Mixtures</a></p>
<p>7 0.86284679 <a title="104-lda-7" href="./nips-2012-Efficient_and_direct_estimation_of_a_neural_subunit_model_for_sensory_coding.html">113 nips-2012-Efficient and direct estimation of a neural subunit model for sensory coding</a></p>
<p>8 0.85950369 <a title="104-lda-8" href="./nips-2012-Hierarchical_spike_coding_of_sound.html">150 nips-2012-Hierarchical spike coding of sound</a></p>
<p>9 0.85946393 <a title="104-lda-9" href="./nips-2012-A_Neural_Autoregressive_Topic_Model.html">12 nips-2012-A Neural Autoregressive Topic Model</a></p>
<p>10 0.85942966 <a title="104-lda-10" href="./nips-2012-Projection_Retrieval_for_Classification.html">279 nips-2012-Projection Retrieval for Classification</a></p>
<p>11 0.85853916 <a title="104-lda-11" href="./nips-2012-Expectation_Propagation_in_Gaussian_Process_Dynamical_Systems.html">121 nips-2012-Expectation Propagation in Gaussian Process Dynamical Systems</a></p>
<p>12 0.85784751 <a title="104-lda-12" href="./nips-2012-Learning_Label_Trees_for_Probabilistic_Modelling_of_Implicit_Feedback.html">178 nips-2012-Learning Label Trees for Probabilistic Modelling of Implicit Feedback</a></p>
<p>13 0.85772401 <a title="104-lda-13" href="./nips-2012-The_Time-Marginalized_Coalescent_Prior_for_Hierarchical_Clustering.html">339 nips-2012-The Time-Marginalized Coalescent Prior for Hierarchical Clustering</a></p>
<p>14 0.8575266 <a title="104-lda-14" href="./nips-2012-Unsupervised_Structure_Discovery_for_Semantic_Analysis_of_Audio.html">356 nips-2012-Unsupervised Structure Discovery for Semantic Analysis of Audio</a></p>
<p>15 0.85741889 <a title="104-lda-15" href="./nips-2012-A_nonparametric_variable_clustering_model.html">26 nips-2012-A nonparametric variable clustering model</a></p>
<p>16 0.85714978 <a title="104-lda-16" href="./nips-2012-Collaborative_Gaussian_Processes_for_Preference_Learning.html">74 nips-2012-Collaborative Gaussian Processes for Preference Learning</a></p>
<p>17 0.85684305 <a title="104-lda-17" href="./nips-2012-Phoneme_Classification_using_Constrained_Variational_Gaussian_Process_Dynamical_System.html">270 nips-2012-Phoneme Classification using Constrained Variational Gaussian Process Dynamical System</a></p>
<p>18 0.8565433 <a title="104-lda-18" href="./nips-2012-Slice_Normalized_Dynamic_Markov_Logic_Networks.html">314 nips-2012-Slice Normalized Dynamic Markov Logic Networks</a></p>
<p>19 0.85646409 <a title="104-lda-19" href="./nips-2012-Bayesian_Probabilistic_Co-Subspace_Addition.html">54 nips-2012-Bayesian Probabilistic Co-Subspace Addition</a></p>
<p>20 0.85639149 <a title="104-lda-20" href="./nips-2012-Augmented-SVM%3A_Automatic_space_partitioning_for_combining_multiple_non-linear_dynamics.html">48 nips-2012-Augmented-SVM: Automatic space partitioning for combining multiple non-linear dynamics</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
