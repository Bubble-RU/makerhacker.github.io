<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>264 nips-2012-Optimal kernel choice for large-scale two-sample tests</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-264" href="#">nips2012-264</a> knowledge-graph by maker-knowledge-mining</p><h1>264 nips-2012-Optimal kernel choice for large-scale two-sample tests</h1>
<br/><p>Source: <a title="nips-2012-264-pdf" href="http://papers.nips.cc/paper/4727-optimal-kernel-choice-for-large-scale-two-sample-tests.pdf">pdf</a></p><p>Author: Arthur Gretton, Dino Sejdinovic, Heiko Strathmann, Sivaraman Balakrishnan, Massimiliano Pontil, Kenji Fukumizu, Bharath K. Sriperumbudur</p><p>Abstract: Given samples from distributions p and q, a two-sample test determines whether to reject the null hypothesis that p = q, based on the value of a test statistic measuring the distance between the samples. One choice of test statistic is the maximum mean discrepancy (MMD), which is a distance between embeddings of the probability distributions in a reproducing kernel Hilbert space. The kernel used in obtaining these embeddings is critical in ensuring the test has high power, and correctly distinguishes unlike distributions with high probability. A means of parameter selection for the two-sample test based on the MMD is proposed. For a given test level (an upper bound on the probability of making a Type I error), the kernel is chosen so as to maximize the test power, and minimize the probability of making a Type II error. The test statistic, test threshold, and optimization over the kernel parameters are obtained with cost linear in the sample size. These properties make the kernel selection and test procedures suited to data streams, where the observations cannot all be stored in memory. In experiments, the new kernel selection approach yields a more powerful test than earlier kernel selection heuristics.</p><p>Reference: <a title="nips-2012-264-reference" href="../nips2012_reference/nips-2012-Optimal_kernel_choice_for_large-scale_two-sample_tests_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('mmd', 0.528), ('kernel', 0.413), ('ku', 0.349), ('supk', 0.171), ('hk', 0.166), ('nul', 0.155), ('sup', 0.149), ('asymptot', 0.122), ('fk', 0.114), ('discrep', 0.111), ('hypothes', 0.105), ('fukumizu', 0.105), ('gretton', 0.104), ('rkhs', 0.102), ('amplitud', 0.092), ('test', 0.092), ('xval', 0.09), ('tk', 0.082), ('bandwid', 0.075), ('opt', 0.074)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="264-tfidf-1" href="./nips-2012-Optimal_kernel_choice_for_large-scale_two-sample_tests.html">264 nips-2012-Optimal kernel choice for large-scale two-sample tests</a></p>
<p>2 0.23262984 <a title="264-tfidf-2" href="./nips-2012-Learning_from_Distributions_via_Support_Measure_Machines.html">188 nips-2012-Learning from Distributions via Support Measure Machines</a></p>
<p>3 0.18575612 <a title="264-tfidf-3" href="./nips-2012-Q-MKL%3A_Matrix-induced_Regularization_in_Multi-Kernel_Learning_with_Applications_to_Neuroimaging.html">284 nips-2012-Q-MKL: Matrix-induced Regularization in Multi-Kernel Learning with Applications to Neuroimaging</a></p>
<p>4 0.18407977 <a title="264-tfidf-4" href="./nips-2012-Multiple_Operator-valued_Kernel_Learning.html">231 nips-2012-Multiple Operator-valued Kernel Learning</a></p>
<p>5 0.15311264 <a title="264-tfidf-5" href="./nips-2012-Active_Comparison_of_Prediction_Models.html">32 nips-2012-Active Comparison of Prediction Models</a></p>
<p>6 0.14491819 <a title="264-tfidf-6" href="./nips-2012-Ensemble_weighted_kernel_estimators_for_multivariate_entropy_estimation.html">117 nips-2012-Ensemble weighted kernel estimators for multivariate entropy estimation</a></p>
<p>7 0.13353059 <a title="264-tfidf-7" href="./nips-2012-Persistent_Homology_for_Learning_Densities_with_Bounded_Support.html">269 nips-2012-Persistent Homology for Learning Densities with Bounded Support</a></p>
<p>8 0.12926163 <a title="264-tfidf-8" href="./nips-2012-The_Perturbed_Variation.html">338 nips-2012-The Perturbed Variation</a></p>
<p>9 0.12336997 <a title="264-tfidf-9" href="./nips-2012-The_representer_theorem_for_Hilbert_spaces%3A_a_necessary_and_sufficient_condition.html">340 nips-2012-The representer theorem for Hilbert spaces: a necessary and sufficient condition</a></p>
<p>10 0.11673933 <a title="264-tfidf-10" href="./nips-2012-Learning_High-Density_Regions_for_a_Generalized_Kolmogorov-Smirnov_Test_in_High-Dimensional_Data.html">175 nips-2012-Learning High-Density Regions for a Generalized Kolmogorov-Smirnov Test in High-Dimensional Data</a></p>
<p>11 0.11327545 <a title="264-tfidf-11" href="./nips-2012-Nystr%C3%B6m_Method_vs_Random_Fourier_Features%3A_A_Theoretical_and_Empirical_Comparison.html">249 nips-2012-Nyström Method vs Random Fourier Features: A Theoretical and Empirical Comparison</a></p>
<p>12 0.11109102 <a title="264-tfidf-12" href="./nips-2012-Kernel_Latent_SVM_for_Visual_Recognition.html">168 nips-2012-Kernel Latent SVM for Visual Recognition</a></p>
<p>13 0.11059623 <a title="264-tfidf-13" href="./nips-2012-Reducing_statistical_time-series_problems_to_binary_classification.html">291 nips-2012-Reducing statistical time-series problems to binary classification</a></p>
<p>14 0.10931752 <a title="264-tfidf-14" href="./nips-2012-A_Nonparametric_Conjugate_Prior_Distribution_for_the_Maximizing_Argument_of_a_Noisy_Function.html">13 nips-2012-A Nonparametric Conjugate Prior Distribution for the Maximizing Argument of a Noisy Function</a></p>
<p>15 0.10069317 <a title="264-tfidf-15" href="./nips-2012-Supervised_Learning_with_Similarity_Functions.html">330 nips-2012-Supervised Learning with Similarity Functions</a></p>
<p>16 0.098429933 <a title="264-tfidf-16" href="./nips-2012-Learning_Halfspaces_with_the_Zero-One_Loss%3A_Time-Accuracy_Tradeoffs.html">174 nips-2012-Learning Halfspaces with the Zero-One Loss: Time-Accuracy Tradeoffs</a></p>
<p>17 0.098063983 <a title="264-tfidf-17" href="./nips-2012-Gradient-based_kernel_method_for_feature_extraction_and_variable_selection.html">144 nips-2012-Gradient-based kernel method for feature extraction and variable selection</a></p>
<p>18 0.097079538 <a title="264-tfidf-18" href="./nips-2012-Pointwise_Tracking_the_Optimal_Regression_Function.html">271 nips-2012-Pointwise Tracking the Optimal Regression Function</a></p>
<p>19 0.092384897 <a title="264-tfidf-19" href="./nips-2012-Learning_Multiple_Tasks_using_Shared_Hypotheses.html">181 nips-2012-Learning Multiple Tasks using Shared Hypotheses</a></p>
<p>20 0.091303185 <a title="264-tfidf-20" href="./nips-2012-Kernel_Hyperalignment.html">167 nips-2012-Kernel Hyperalignment</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.201), (1, -0.022), (2, 0.055), (3, 0.013), (4, -0.003), (5, 0.113), (6, 0.049), (7, -0.042), (8, -0.018), (9, -0.194), (10, 0.133), (11, 0.095), (12, -0.179), (13, 0.085), (14, -0.059), (15, -0.155), (16, -0.066), (17, -0.098), (18, 0.032), (19, -0.038), (20, -0.002), (21, -0.267), (22, 0.012), (23, 0.056), (24, 0.07), (25, 0.015), (26, -0.022), (27, -0.008), (28, 0.006), (29, -0.06), (30, -0.04), (31, -0.077), (32, -0.062), (33, 0.115), (34, -0.052), (35, -0.02), (36, -0.019), (37, 0.063), (38, -0.032), (39, 0.037), (40, -0.044), (41, -0.136), (42, -0.039), (43, -0.039), (44, 0.004), (45, 0.055), (46, 0.018), (47, -0.001), (48, 0.027), (49, -0.061)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95898038 <a title="264-lsi-1" href="./nips-2012-Optimal_kernel_choice_for_large-scale_two-sample_tests.html">264 nips-2012-Optimal kernel choice for large-scale two-sample tests</a></p>
<p>2 0.86997867 <a title="264-lsi-2" href="./nips-2012-Multiple_Operator-valued_Kernel_Learning.html">231 nips-2012-Multiple Operator-valued Kernel Learning</a></p>
<p>3 0.86008173 <a title="264-lsi-3" href="./nips-2012-Learning_from_Distributions_via_Support_Measure_Machines.html">188 nips-2012-Learning from Distributions via Support Measure Machines</a></p>
<p>4 0.82621944 <a title="264-lsi-4" href="./nips-2012-Q-MKL%3A_Matrix-induced_Regularization_in_Multi-Kernel_Learning_with_Applications_to_Neuroimaging.html">284 nips-2012-Q-MKL: Matrix-induced Regularization in Multi-Kernel Learning with Applications to Neuroimaging</a></p>
<p>5 0.80002135 <a title="264-lsi-5" href="./nips-2012-Nystr%C3%B6m_Method_vs_Random_Fourier_Features%3A_A_Theoretical_and_Empirical_Comparison.html">249 nips-2012-Nyström Method vs Random Fourier Features: A Theoretical and Empirical Comparison</a></p>
<p>6 0.72850871 <a title="264-lsi-6" href="./nips-2012-Kernel_Hyperalignment.html">167 nips-2012-Kernel Hyperalignment</a></p>
<p>7 0.66791034 <a title="264-lsi-7" href="./nips-2012-Gradient-based_kernel_method_for_feature_extraction_and_variable_selection.html">144 nips-2012-Gradient-based kernel method for feature extraction and variable selection</a></p>
<p>8 0.65129393 <a title="264-lsi-8" href="./nips-2012-Semantic_Kernel_Forests_from_Multiple_Taxonomies.html">306 nips-2012-Semantic Kernel Forests from Multiple Taxonomies</a></p>
<p>9 0.64530182 <a title="264-lsi-9" href="./nips-2012-The_representer_theorem_for_Hilbert_spaces%3A_a_necessary_and_sufficient_condition.html">340 nips-2012-The representer theorem for Hilbert spaces: a necessary and sufficient condition</a></p>
<p>10 0.63893789 <a title="264-lsi-10" href="./nips-2012-Persistent_Homology_for_Learning_Densities_with_Bounded_Support.html">269 nips-2012-Persistent Homology for Learning Densities with Bounded Support</a></p>
<p>11 0.63872659 <a title="264-lsi-11" href="./nips-2012-Density-Difference_Estimation.html">95 nips-2012-Density-Difference Estimation</a></p>
<p>12 0.61863768 <a title="264-lsi-12" href="./nips-2012-Ensemble_weighted_kernel_estimators_for_multivariate_entropy_estimation.html">117 nips-2012-Ensemble weighted kernel estimators for multivariate entropy estimation</a></p>
<p>13 0.60290176 <a title="264-lsi-13" href="./nips-2012-Learning_High-Density_Regions_for_a_Generalized_Kolmogorov-Smirnov_Test_in_High-Dimensional_Data.html">175 nips-2012-Learning High-Density Regions for a Generalized Kolmogorov-Smirnov Test in High-Dimensional Data</a></p>
<p>14 0.575818 <a title="264-lsi-14" href="./nips-2012-Kernel_Latent_SVM_for_Visual_Recognition.html">168 nips-2012-Kernel Latent SVM for Visual Recognition</a></p>
<p>15 0.57300115 <a title="264-lsi-15" href="./nips-2012-Learning_Halfspaces_with_the_Zero-One_Loss%3A_Time-Accuracy_Tradeoffs.html">174 nips-2012-Learning Halfspaces with the Zero-One Loss: Time-Accuracy Tradeoffs</a></p>
<p>16 0.52250665 <a title="264-lsi-16" href="./nips-2012-Phoneme_Classification_using_Constrained_Variational_Gaussian_Process_Dynamical_System.html">270 nips-2012-Phoneme Classification using Constrained Variational Gaussian Process Dynamical System</a></p>
<p>17 0.52186257 <a title="264-lsi-17" href="./nips-2012-Supervised_Learning_with_Similarity_Functions.html">330 nips-2012-Supervised Learning with Similarity Functions</a></p>
<p>18 0.520401 <a title="264-lsi-18" href="./nips-2012-Learning_Invariant_Representations_of_Molecules_for_Atomization_Energy_Prediction.html">177 nips-2012-Learning Invariant Representations of Molecules for Atomization Energy Prediction</a></p>
<p>19 0.5170415 <a title="264-lsi-19" href="./nips-2012-Slice_sampling_normalized_kernel-weighted_completely_random_measure_mixture_models.html">315 nips-2012-Slice sampling normalized kernel-weighted completely random measure mixture models</a></p>
<p>20 0.50510746 <a title="264-lsi-20" href="./nips-2012-Exponential_Concentration_for_Mutual_Information_Estimation_with_Application_to_Forests.html">123 nips-2012-Exponential Concentration for Mutual Information Estimation with Application to Forests</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(11, 0.095), (14, 0.228), (47, 0.12), (67, 0.076), (70, 0.118), (85, 0.045), (94, 0.143), (99, 0.074)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.82958752 <a title="264-lda-1" href="./nips-2012-Optimal_kernel_choice_for_large-scale_two-sample_tests.html">264 nips-2012-Optimal kernel choice for large-scale two-sample tests</a></p>
<p>2 0.77410442 <a title="264-lda-2" href="./nips-2012-Bayesian_nonparametric_models_for_ranked_data.html">60 nips-2012-Bayesian nonparametric models for ranked data</a></p>
<p>3 0.75056857 <a title="264-lda-3" href="./nips-2012-Clustering_by_Nonnegative_Matrix_Factorization_Using_Graph_Random_Walk.html">70 nips-2012-Clustering by Nonnegative Matrix Factorization Using Graph Random Walk</a></p>
<p>4 0.74951339 <a title="264-lda-4" href="./nips-2012-Hierarchical_Optimistic_Region_Selection_driven_by_Curiosity.html">149 nips-2012-Hierarchical Optimistic Region Selection driven by Curiosity</a></p>
<p>5 0.74804407 <a title="264-lda-5" href="./nips-2012-Timely_Object_Recognition.html">344 nips-2012-Timely Object Recognition</a></p>
<p>6 0.74567682 <a title="264-lda-6" href="./nips-2012-Diffusion_Decision_Making_for_Adaptive_k-Nearest_Neighbor_Classification.html">97 nips-2012-Diffusion Decision Making for Adaptive k-Nearest Neighbor Classification</a></p>
<p>7 0.74560261 <a title="264-lda-7" href="./nips-2012-Label_Ranking_with_Partial_Abstention_based_on_Thresholded_Probabilistic_Models.html">169 nips-2012-Label Ranking with Partial Abstention based on Thresholded Probabilistic Models</a></p>
<p>8 0.74471819 <a title="264-lda-8" href="./nips-2012-The_Perturbed_Variation.html">338 nips-2012-The Perturbed Variation</a></p>
<p>9 0.74447161 <a title="264-lda-9" href="./nips-2012-Active_Comparison_of_Prediction_Models.html">32 nips-2012-Active Comparison of Prediction Models</a></p>
<p>10 0.74382716 <a title="264-lda-10" href="./nips-2012-Generalization_Bounds_for_Domain_Adaptation.html">142 nips-2012-Generalization Bounds for Domain Adaptation</a></p>
<p>11 0.74378186 <a title="264-lda-11" href="./nips-2012-Collaborative_Ranking_With_17_Parameters.html">75 nips-2012-Collaborative Ranking With 17 Parameters</a></p>
<p>12 0.74365813 <a title="264-lda-12" href="./nips-2012-Multiclass_Learning_Approaches%3A_A_Theoretical_Comparison_with_Implications.html">226 nips-2012-Multiclass Learning Approaches: A Theoretical Comparison with Implications</a></p>
<p>13 0.74219263 <a title="264-lda-13" href="./nips-2012-Online_allocation_and_homogeneous_partitioning_for_piecewise_constant_mean-approximation.html">261 nips-2012-Online allocation and homogeneous partitioning for piecewise constant mean-approximation</a></p>
<p>14 0.74171311 <a title="264-lda-14" href="./nips-2012-Multiple_Choice_Learning%3A_Learning_to_Produce_Multiple_Structured_Outputs.html">230 nips-2012-Multiple Choice Learning: Learning to Produce Multiple Structured Outputs</a></p>
<p>15 0.74139649 <a title="264-lda-15" href="./nips-2012-Reducing_statistical_time-series_problems_to_binary_classification.html">291 nips-2012-Reducing statistical time-series problems to binary classification</a></p>
<p>16 0.74131298 <a title="264-lda-16" href="./nips-2012-Transferring_Expectations_in_Model-based_Reinforcement_Learning.html">353 nips-2012-Transferring Expectations in Model-based Reinforcement Learning</a></p>
<p>17 0.74001437 <a title="264-lda-17" href="./nips-2012-Learning_from_Distributions_via_Support_Measure_Machines.html">188 nips-2012-Learning from Distributions via Support Measure Machines</a></p>
<p>18 0.73996687 <a title="264-lda-18" href="./nips-2012-ImageNet_Classification_with_Deep_Convolutional_Neural_Networks.html">158 nips-2012-ImageNet Classification with Deep Convolutional Neural Networks</a></p>
<p>19 0.73967558 <a title="264-lda-19" href="./nips-2012-Nonparametric_Reduced_Rank_Regression.html">247 nips-2012-Nonparametric Reduced Rank Regression</a></p>
<p>20 0.73839653 <a title="264-lda-20" href="./nips-2012-Dynamic_Pruning_of_Factor_Graphs_for_Maximum_Marginal_Prediction.html">105 nips-2012-Dynamic Pruning of Factor Graphs for Maximum Marginal Prediction</a></p>
<br/><br/><br/></body>
</html>
