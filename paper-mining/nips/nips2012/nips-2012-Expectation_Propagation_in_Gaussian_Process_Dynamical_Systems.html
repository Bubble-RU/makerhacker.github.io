<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>121 nips-2012-Expectation Propagation in Gaussian Process Dynamical Systems</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-121" href="#">nips2012-121</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>121 nips-2012-Expectation Propagation in Gaussian Process Dynamical Systems</h1>
<br/><p>Source: <a title="nips-2012-121-pdf" href="http://papers.nips.cc/paper/4707-expectation-propagation-in-gaussian-process-dynamical-systems.pdf">pdf</a></p><p>Author: Marc Deisenroth, Shakir Mohamed</p><p>Abstract: Rich and complex time-series data, such as those generated from engineering systems, ﬁnancial markets, videos, or neural recordings are now a common feature of modern data analysis. Explaining the phenomena underlying these diverse data sets requires ﬂexible and accurate models. In this paper, we promote Gaussian process dynamical systems as a rich model class that is appropriate for such an analysis. We present a new approximate message-passing algorithm for Bayesian state estimation and inference in Gaussian process dynamical systems, a nonparametric probabilistic generalization of commonly used state-space models. We derive our message-passing algorithm using Expectation Propagation and provide a unifying perspective on message passing in general state-space models. We show that existing Gaussian ﬁlters and smoothers appear as special cases within our inference framework, and that these existing approaches can be improved upon using iterated message passing. Using both synthetic and real-world data, we demonstrate that iterated message passing can improve inference in a wide range of tasks in Bayesian state estimation, thus leading to improved predictions and more effective decision making. 1</p><p>Reference: <a title="nips-2012-121-reference" href="../nips2012_reference/nips-2012-Expectation_Propagation_in_Gaussian_Process_Dynamical_Systems_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 In this paper, we promote Gaussian process dynamical systems as a rich model class that is appropriate for such an analysis. [sent-3, score-0.209]
</p><p>2 We present a new approximate message-passing algorithm for Bayesian state estimation and inference in Gaussian process dynamical systems, a nonparametric probabilistic generalization of commonly used state-space models. [sent-4, score-0.339]
</p><p>3 We derive our message-passing algorithm using Expectation Propagation and provide a unifying perspective on message passing in general state-space models. [sent-5, score-0.189]
</p><p>4 We show that existing Gaussian ﬁlters and smoothers appear as special cases within our inference framework, and that these existing approaches can be improved upon using iterated message passing. [sent-6, score-0.329]
</p><p>5 Using both synthetic and real-world data, we demonstrate that iterated message passing can improve inference in a wide range of tasks in Bayesian state estimation, thus leading to improved predictions and more effective decision making. [sent-7, score-0.349]
</p><p>6 However, in practice, time series often have an unknown dynamical structure, and they are high dimensional and noisy, violating many of the assumptions made in established approaches for state estimation. [sent-10, score-0.215]
</p><p>7 In this paper, we look beyond traditional linear dynamical systems and advance the state-of the-art in state estimation by developing novel inference algorithms for the class of nonlinear Gaussian process dynamical systems (GPDS). [sent-11, score-0.537]
</p><p>8 GPDSs are non-parametric generalizations of state-space models that allow for inference in time series, using Gaussian process (GP) probability distributions over nonlinear transition and measurement dynamics. [sent-12, score-0.276]
</p><p>9 GPDSs are thus able to capture complex dynamical structure with few assumptions, making them of broad interest. [sent-13, score-0.188]
</p><p>10 (2) We show that the general message-passing framework recovers the EP updates for existing dynamical systems as a special case and expose the implicit modeling assumptions made in these models. [sent-16, score-0.257]
</p><p>11 1  2  Gaussian Process Dynamical Systems  Gaussian process dynamical systems are a general class of discrete-time state-space models with xt = h(xt−1 ) + wt , wt ∼ N (0, Q) , h ∼ GP h , (1) z t = g(xt ) + v t , v t ∼ N (0, R) , g ∼ GP g , (2)  where t = 1, . [sent-19, score-0.806]
</p><p>12 The central feature of this model class is that both the measurement function g and the transition function h are not explicitly known or parametrically speciﬁed, but instead described by probability distributions over these functions. [sent-28, score-0.158]
</p><p>13 Since the GP is a non-parametric model, its use in GPDSs is desirable as it results in fewer restrictive model assumptions, compared to dynamical systems based on parametric function approximators for the transition and measurement functions (1)–(2). [sent-39, score-0.322]
</p><p>14 As covariance functions kh and kg we use squared- exponential covariance functions with automatic relevance determination plus a noise covariance function to account for the noise in (1)–(2). [sent-44, score-0.157]
</p><p>15 Existing work for learning GPDSs includes the Gaussian process dynamical model (GPDM) [20], which tackles the challenging task of analyzing human motion in (high-dimensional) video sequences. [sent-45, score-0.237]
</p><p>16 We thus make use of approximations to infer the posterior distributions p(xt |Z) over latent states xt , t = 1, . [sent-50, score-0.792]
</p><p>17 Existing approximate inference approaches for ﬁltering and forward-backward smoothing are based on either linearization, particle representations, or moment matching as approximation strategies [8, 3, 5]. [sent-54, score-0.255]
</p><p>18 A principled incorporation of the posterior GP model uncertainty into inference in GPDSs is necessary, but introduces additional uncertainty. [sent-55, score-0.184]
</p><p>19 In this paper, we address this problem and propose approximate message passing based on EP for more accurate inference. [sent-57, score-0.241]
</p><p>20 We will show that forward-backward smoothing in GPDSs [5] beneﬁts from the iterative reﬁnement scheme of EP, leading to more accurate posterior distributions over the latent state and, hence, to more informative predictions and improved decision making. [sent-58, score-0.358]
</p><p>21 EP is derived using a factor-graph, in which the distribution over the latent state p(xt |Z) is represented as the product of factors fi (xt ), i. [sent-60, score-0.164]
</p><p>22 EP then speciﬁes an iterative message passing algorithm in which p(xt |Z) is approximated by a distribution q(xt ) = i qi (xt ), using approximate messages qi (xt ). [sent-63, score-0.581]
</p><p>23 In EP, q and the messages qi are members of the exponential family, and q is determined such that the the KL-divergence KL(p||q) is minimized. [sent-64, score-0.217]
</p><p>24 In the context of the dynamical system (1)–(2), we consider factor graphs of the form of Fig. [sent-67, score-0.188]
</p><p>25 For EP inference, we assume a fully-factored graph, using which we compute the marginal posterior distributions p(x1 |Z), . [sent-72, score-0.143]
</p><p>26 Both the states xt and measurements z t are continuous variables and the messages qi are unnormalized Gaussians, i. [sent-79, score-0.862]
</p><p>27 1 describes the main steps of Gaussian EP for dynamical systems. [sent-83, score-0.168]
</p><p>28 For each node xt in the fully-factored factor graph in Fig. [sent-84, score-0.617]
</p><p>29 The EP algorithm updates the marginal q(xt ) and the messages qi (xt ) in three steps. [sent-86, score-0.279]
</p><p>30 First, the cavity distribution q \i (xt ) is computed (step 5 in Alg. [sent-87, score-0.122]
</p><p>31 1) by removing qi (xt ) from the marginal q(xt ). [sent-88, score-0.143]
</p><p>32 Second, in the projection step, the moments of fi (xt )q \i (xt ) are computed (step 6), where fi is the true factor. [sent-89, score-0.246]
</p><p>33 In the exponential family, the required moments can be computed using the derivatives of the log-partition function (normalizing constant) log Zi of fi (xt )q \i (xt ) [10, 11, 12]. [sent-90, score-0.266]
</p><p>34 Third, the moments of the marginal q(xt ) are set to the moments of fi (xt )q \i (xt ), and the message qi (xt ) is updated (step 7). [sent-91, score-0.572]
</p><p>35 We apply this procedure repeatedly to all latent states xt , t = 1, . [sent-92, score-0.674]
</p><p>36 EP does not directly ﬁt a Gaussian approximation qi to the non-Gaussian factor fi . [sent-96, score-0.2]
</p><p>37 Instead, EP determines the moments of qi in the context of the cavity distribution such that qi = proj[fi q \i ]/q \i , where proj[·] is the projection operator, returning the moments of its argument. [sent-97, score-0.58]
</p><p>38 To update the posterior q(xt ) and the messages qi (xt ), EP computes the log-partition function log Zi in (4) to complete the projection step. [sent-98, score-0.38]
</p><p>39 However, for nonlinear transition and measurement models 3  in (1)–(2), computing Zi involves solving integrals of the form p(a) =  p(a|xt )p(xt )dxt =  N (a | m(xt ), S(xt ))N (xt | b, B)dxt ,  (8)  where a = z t for the measurement message, or a = xt+1 for the forward and backward messages. [sent-99, score-0.367]
</p><p>40 In nonlinear dynamical systems m(xt ) is a nonlinear measurement or transition function. [sent-100, score-0.376]
</p><p>41 In GPDSs, m(xt ) and S(xt ) are the corresponding predictive GP means and covariances, respectively, which are nonlinearly related to xt . [sent-101, score-0.626]
</p><p>42 Because of the nonlinear dependencies between a and xt , solving (8) is analytically intractable. [sent-102, score-0.646]
</p><p>43 This Gaussian approximation is only correct for a linear relationship a = J xt , where J is independent of xt . [sent-104, score-1.194]
</p><p>44 Hence, the Gaussian approximation is an implicit linearization of the functional relationship between a and xt , effectively linearizing either the transition or the measurement models. [sent-105, score-0.873]
</p><p>45 When computing EP updates using the derivatives m and s according to (5), it is crucial to explicitly account for the implicit linearization assumption in the derivatives—otherwise, the EP updates are inconsistent. [sent-106, score-0.315]
</p><p>46 For example, in the measurement and the backward message, we directly i ˜ ˜ ˜ approximate the partition functions Zi , i ∈ { , } by Gaussians Zi (a) = N (µi , Σ ). [sent-107, score-0.22]
</p><p>47 Note that with the implicit linear model a = J xt , ˜i ˜ ˜ the derivatives ∂ µi /∂Σ\i and ∂ Σ /∂µ\i vanish. [sent-109, score-0.713]
</p><p>48 However, even if µi and Σ are general functions ˜ inﬂuences the computation of J = ∂(µ ˜i ˜ of µ\i and Σ\i , the derivatives ∂ µi /∂µ\i and ∂ Σ /∂Σ\i must equal the corresponding partial i ˜ ˜ derivatives in (11), and ∂ µi /∂Σ\i and ∂ Σ /∂µ\i must be set to 0. [sent-111, score-0.164]
</p><p>49 Hence, the implicit linearization ˜ expressed by the Gaussian approximation Zi must be explicitly taken into account in the derivatives to guarantee consistent EP updates. [sent-112, score-0.241]
</p><p>50 2  Messages in Gaussian Process Dynamical Systems  We now describe each of the messages needed for inference in GPDSs, and outline the approximations required to compute the partition function in (4). [sent-114, score-0.188]
</p><p>51 Updating a message requires a projection to compute the moments of the new posterior marginal q(xt ), followed by a Gaussian division to update the message itself. [sent-115, score-0.564]
</p><p>52 Using the derivatives d log Zi /dµt and d log Zi /dΣt , we update the marginal q(xt ), see (5). [sent-117, score-0.174]
</p><p>53 In (12), we made it explicit that Z depends on the moments \ \ µt and Σt of the cavity distribution q\ (xt ). [sent-119, score-0.222]
</p><p>54 However, the mean and covariance of a Gaussian approximation ˜ Z to Z can be computed analytically: either using exact moment matching [14, 3], or approximately by expected linearization of the posterior GP [8]; details are given in [4]. [sent-121, score-0.32]
</p><p>55 The moments of 4  \ \ ˜ Z are also functions of the mean µt and variance Σt of the cavity distribution. [sent-122, score-0.222]
</p><p>56 By taking the linearization assumption of the Gaussian approximation into account explicitly (here, we implicitly linearize GP g ) when computing the derivatives, the EP updates remain consistent, see Sec. [sent-123, score-0.162]
</p><p>57 Backward Message To update the backward message q (xt ), we require the partition function \  \  Z (µt , Σt ) = f (xt ) =  f (xt )q\ (xt )dxt ∝  p(xt+1 |xt )q\ (xt+1 )dxt+1 =  \  \  f (xt )N (xt | µt , Σt )dxt ,  (14)  N (xt+1 | µh (xt ), Σh (xt ))q\ (xt+1 )dxt+1 . [sent-126, score-0.253]
</p><p>58 (15)  Here, the true factor f (xt ) in (15) takes into account the coupling between xt and xt+1 , which was lost in assuming the full factorization in Fig. [sent-127, score-0.636]
</p><p>59 Now, (16) can be computed analytically, and \ \ ˜\ ˜ ˜ we obtain a Gaussian approximation Z = N (µt+1 | µ\ , Σ + Σt+1 ) of Z that allows us to update the moments of q(xt ) and the message q (xt ). [sent-134, score-0.272]
</p><p>60 With this approximation we do not update the forward message in context, i. [sent-143, score-0.21]
</p><p>61 Moreover, the cavity distribution q\ (xt ) corresponds to the time update p(xt |z 1:t−1 ). [sent-149, score-0.145]
</p><p>62 In the backward sweep, the marginal q(xt ) is the smoothing distribution p(xt |Z), ˜ incorporating the measurements of the entire time series. [sent-150, score-0.186]
</p><p>63 Updating the moments of the posterior q(xt ) via the derivatives of the log-partition function recovers exactly the standard Gaussian EP updates in dynamical systems described by Qi and Minka [13]. [sent-152, score-0.501]
</p><p>64 For example, when incorporating an updated measurement message, the moments in (5) can also be xz\ \ \ \ zx\ , respectively, where Σt = written as µt = µt + K(z t − µz ) and Σt = Σt − KΣt \ \ xz\ \ \ −1 \ cov[xt , z t ] and K = Σt (Σz ) . [sent-153, score-0.224]
</p><p>65 Here, µz = E[g(xt )] and Σz = cov[g(xt )], where xt ∼ q\ (xt ). [sent-154, score-0.597]
</p><p>66 Similarly, the updated moments of q(xt ) with a new backward message via (5) \  \  \  correspond to the updates [13] µt = µt + L(µt+1 − µt+1 ) and Σt = Σt + L(Σt+1 − Σt+1 )L , \ \ \ \ \ where L = cov[xt , xt+1 ](Σt+1 )−1 . [sent-155, score-0.364]
</p><p>67 Here, we deﬁned µt+1 = E[h(xt )] and Σt+1 = cov[h(xt )], where xt ∼ q\ (xt ). [sent-156, score-0.597]
</p><p>68 1 provides an EP-based generalization and a unifying view of existing approaches for smoothing in dynamical systems, e. [sent-195, score-0.243]
</p><p>69 , (Extended/Unscented/ Cubature) Kalman smoothing and the corresponding GPDS smoothers [5]. [sent-197, score-0.142]
</p><p>70 Computing the messages ˜ via the derivatives of the approximate log-partition functions log Zi recovers not only standard EP updates in dynamical systems [13], but also the standard Kalman smoothing updates [1]. [sent-198, score-0.571]
</p><p>71 This inﬂuences the computation of log Zi and its derivatives with respect to the moments of the cavity distribution, see (9)–(10). [sent-202, score-0.326]
</p><p>72 4  Experimental Results  We evaluated our proposed EP-based message passing algorithm on three data sets: a synthetic data set, a low-dimensional simulated mechanical system with control inputs, and a high-dimensional motion-capture data set. [sent-204, score-0.189]
</p><p>73 We compared to existing state-of-the-art forward-backward smoothers in GPDSs, speciﬁcally the GPEKS [8], which is based on the expected linearization of the GP models, and the GPADS [5], which uses moment-matching. [sent-205, score-0.173]
</p><p>74 Whenever available, we also compared the inferred posterior distribution q(X) ≈ p(X|Z) of the latent states with the underlying ground truth using the average negative log-likelihood (NLLx ) and Mean Absolute Errors (MAEx ). [sent-212, score-0.221]
</p><p>75 1  Synthetic Data  We considered the nonlinear dynamical system xt+1 = 4 sin(xt ) + w ,  w ∼ N (0, 0. [sent-215, score-0.195]
</p><p>76 We assumed access to the latent state and trained the dynamics and measurement GPs using 30 randomly generated points, resulting in a model with a substantial amount of posterior model uncertainty. [sent-219, score-0.304]
</p><p>77 1 reports the quality of the inferred posterior distributions of the latent state trajectories using the average NLLx , MAEx , and NLLz (with standard errors), averaged over 10 independent scenarios. [sent-222, score-0.267]
</p><p>78 Both inference methods make use of the known transition and measurement mappings h and g, respectively. [sent-224, score-0.204]
</p><p>79 Iterated forward-backward smoothing with EP (EP-EKS, EP-GPEKS, EPGPADS) improved the smoothing posteriors using a single sweep only (EKS, GPEKS, GPADS). [sent-225, score-0.201]
</p><p>80 By iterating forward-backward smoothing using EP (EP-GPADS), the posteriors p(xt |Z) were iteratively reﬁned, and the latent state could be followed closely as indicated by both the small blue error bars in Fig. [sent-230, score-0.177]
</p><p>81 EP smoothing typically required a small number of iterations for the inferred posterior distribution to closely track the true state, Fig. [sent-233, score-0.222]
</p><p>82 6  Average NLL per data point  5 Latent State  2  True state Posterior state distribution (EP−GPADS) Posterior state distribution (GPADS)  0  −5 2  4  6  8  10 12 Time step  14  16  18  20  1 GPADS EP−GPADS  0 −1 −2 5  (a) Example trajectory distributions with 95% conﬁdence bounds. [sent-236, score-0.181]
</p><p>83 Figure 2: (a) Posterior latent state distributions using EP-GPADS (blue) and the GPADS (gray). [sent-238, score-0.124]
</p><p>84 The GPADS quickly loses track of the period of the state revealed by the large posterior uncertainty. [sent-240, score-0.165]
</p><p>85 EP with moment matching (EP-GPADS) in the GPDS iteratively reﬁnes the GPADS posterior and can closely follow the true latent state trajectory. [sent-241, score-0.277]
</p><p>86 (b) Average NLLx per data point in latent space with standard errors of the posterior state distributions computed by the GPADS and the EP-GPADS as a function of EP iterations. [sent-242, score-0.22]
</p><p>87 2  Pendulum Tracking  We considered a pendulum tracking problem to demonstrate GPDS inference in multidimensional settings, as well as the ability to handle control inputs. [sent-244, score-0.121]
</p><p>88 In about 20% of the test cases, the inference methods based on explicit linearization of the posterior mean function (GPEKS and EP-GPEKS) ran into numerical problems typical of linearizations [5], i. [sent-288, score-0.301]
</p><p>89 The inference algorithms based on moment matching (GPADS and EP-GPADS) were numerically stable as their predictions are typically more coherent due to conservative approximations of moment matching. [sent-293, score-0.196]
</p><p>90 For trials 1–7 (403 data points), we used the GPDM [20] to learn MAP estimates of the latent states xt ∈ R3 . [sent-300, score-0.695]
</p><p>91 Trials 8–10 were used as test 7  Figure 3: Latent space posterior distribution (95% conﬁdence ellipsoids) of a test trajectory of the golf-swing motion capture data. [sent-302, score-0.18]
</p><p>92 3 summarizes the results of inference on the golf data set in all test trials: Iterating forwardbackward smoothing by means of EP improved the inferred posterior distributions over the latent states. [sent-312, score-0.411]
</p><p>93 The posterior distributions in latent space inferred by the EP-GPEKS were tighter than the ones inferred by the EP-GPADS. [sent-313, score-0.231]
</p><p>94 The computational demand the two Table 3: Average inference performance (NLLz , motion inference methods for GPDSs we capture data set). [sent-317, score-0.202]
</p><p>95 Highdimensional approximate inference Test trial GPEKS EP-GPEKS GPADS EP-GPADS Trial 8 14. [sent-320, score-0.132]
</p><p>96 42 Trial 10 about two orders of magnitude slower than approximate inference based on linearization of the posterior GP mean (EP-GPEKS): For updating the posterior and the messages for a single time slice, the EP-GPEKS required less than 0. [sent-332, score-0.498]
</p><p>97 Hence, numerical stability and more coherent posterior inference with the EP-GPADS trade off against computational demands. [sent-334, score-0.164]
</p><p>98 5  Conclusion  We have presented an approximate message passing algorithm based on EP for improved inference and Bayesian state estimation in GP dynamical systems. [sent-335, score-0.525]
</p><p>99 This generalization allows for improved predictions and comprises existing methods for inference in the wider theory for dynamical systems as a special case. [sent-337, score-0.274]
</p><p>100 Future work includes investigating alternatives to linearization and moment matching when computing messages, and the more general problem of learning in Gaussian process dynamical systems. [sent-339, score-0.376]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('xt', 0.597), ('gpads', 0.275), ('ep', 0.255), ('gp', 0.248), ('gpdss', 0.245), ('dxt', 0.187), ('dynamical', 0.168), ('gpds', 0.153), ('message', 0.149), ('cavity', 0.122), ('gpeks', 0.122), ('zi', 0.119), ('qi', 0.118), ('nllx', 0.107), ('linearization', 0.106), ('measurement', 0.106), ('moments', 0.1), ('messages', 0.099), ('posterior', 0.096), ('nllz', 0.092), ('derivatives', 0.082), ('smoothing', 0.075), ('inference', 0.068), ('smoothers', 0.067), ('gaussian', 0.064), ('deisenroth', 0.062), ('fi', 0.062), ('eks', 0.061), ('maex', 0.061), ('backward', 0.06), ('propagation', 0.058), ('latent', 0.055), ('kalman', 0.053), ('moment', 0.049), ('state', 0.047), ('ellipsoids', 0.046), ('golf', 0.046), ('motion', 0.046), ('gpdm', 0.04), ('unscented', 0.04), ('passing', 0.04), ('covariance', 0.039), ('forward', 0.038), ('overcon', 0.037), ('updates', 0.037), ('pendulum', 0.035), ('implicit', 0.034), ('approximate', 0.033), ('kf', 0.032), ('cov', 0.032), ('bayesian', 0.032), ('trial', 0.031), ('sweep', 0.031), ('linearizations', 0.031), ('linearizes', 0.031), ('matching', 0.03), ('transition', 0.03), ('predictive', 0.029), ('inferred', 0.029), ('gps', 0.029), ('expectation', 0.029), ('xz', 0.027), ('nonlinear', 0.027), ('filtering', 0.026), ('measurements', 0.026), ('iterated', 0.025), ('upright', 0.025), ('proj', 0.025), ('marginal', 0.025), ('iterative', 0.024), ('sin', 0.024), ('process', 0.023), ('update', 0.023), ('projection', 0.022), ('distributions', 0.022), ('states', 0.022), ('log', 0.022), ('analytically', 0.022), ('track', 0.022), ('kg', 0.021), ('partition', 0.021), ('trials', 0.021), ('capture', 0.02), ('improved', 0.02), ('uncertainty', 0.02), ('factor', 0.02), ('ltering', 0.019), ('huber', 0.019), ('suffered', 0.019), ('ground', 0.019), ('turner', 0.019), ('accurate', 0.019), ('account', 0.019), ('lters', 0.018), ('tracking', 0.018), ('trajectories', 0.018), ('systems', 0.018), ('trajectory', 0.018), ('updated', 0.018), ('nement', 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999988 <a title="121-tfidf-1" href="./nips-2012-Expectation_Propagation_in_Gaussian_Process_Dynamical_Systems.html">121 nips-2012-Expectation Propagation in Gaussian Process Dynamical Systems</a></p>
<p>Author: Marc Deisenroth, Shakir Mohamed</p><p>Abstract: Rich and complex time-series data, such as those generated from engineering systems, ﬁnancial markets, videos, or neural recordings are now a common feature of modern data analysis. Explaining the phenomena underlying these diverse data sets requires ﬂexible and accurate models. In this paper, we promote Gaussian process dynamical systems as a rich model class that is appropriate for such an analysis. We present a new approximate message-passing algorithm for Bayesian state estimation and inference in Gaussian process dynamical systems, a nonparametric probabilistic generalization of commonly used state-space models. We derive our message-passing algorithm using Expectation Propagation and provide a unifying perspective on message passing in general state-space models. We show that existing Gaussian ﬁlters and smoothers appear as special cases within our inference framework, and that these existing approaches can be improved upon using iterated message passing. Using both synthetic and real-world data, we demonstrate that iterated message passing can improve inference in a wide range of tasks in Bayesian state estimation, thus leading to improved predictions and more effective decision making. 1</p><p>2 0.41432828 <a title="121-tfidf-2" href="./nips-2012-Stochastic_Gradient_Descent_with_Only_One_Projection.html">324 nips-2012-Stochastic Gradient Descent with Only One Projection</a></p>
<p>Author: Mehrdad Mahdavi, Tianbao Yang, Rong Jin, Shenghuo Zhu, Jinfeng Yi</p><p>Abstract: Although many variants of stochastic gradient descent have been proposed for large-scale convex optimization, most of them require projecting the solution at each iteration to ensure that the obtained solution stays within the feasible domain. For complex domains (e.g., positive semideﬁnite cone), the projection step can be computationally expensive, making stochastic gradient descent unattractive for large-scale optimization problems. We address this limitation by developing novel stochastic optimization algorithms that do not need intermediate projections. Instead, only one projection at the last iteration is needed to obtain a feasible solution in the given domain. Our theoretical analysis shows that with a high probability, √ the proposed algorithms achieve an O(1/ T ) convergence rate for general convex optimization, and an O(ln T /T ) rate for strongly convex optimization under mild conditions about the domain and the objective function. 1</p><p>3 0.2256541 <a title="121-tfidf-3" href="./nips-2012-A_Nonparametric_Conjugate_Prior_Distribution_for_the_Maximizing_Argument_of_a_Noisy_Function.html">13 nips-2012-A Nonparametric Conjugate Prior Distribution for the Maximizing Argument of a Noisy Function</a></p>
<p>Author: Pedro Ortega, Jordi Grau-moya, Tim Genewein, David Balduzzi, Daniel Braun</p><p>Abstract: We propose a novel Bayesian approach to solve stochastic optimization problems that involve ﬁnding extrema of noisy, nonlinear functions. Previous work has focused on representing possible functions explicitly, which leads to a two-step procedure of ﬁrst, doing inference over the function space and second, ﬁnding the extrema of these functions. Here we skip the representation step and directly model the distribution over extrema. To this end, we devise a non-parametric conjugate prior based on a kernel regressor. The resulting posterior distribution directly captures the uncertainty over the maximum of the unknown function. Given t observations of the function, the posterior can be evaluated efﬁciently in time O(t2 ) up to a multiplicative constant. Finally, we show how to apply our model to optimize a noisy, non-convex, high-dimensional objective function.</p><p>4 0.21379836 <a title="121-tfidf-4" href="./nips-2012-Mixing_Properties_of_Conditional_Markov_Chains_with_Unbounded_Feature_Functions.html">218 nips-2012-Mixing Properties of Conditional Markov Chains with Unbounded Feature Functions</a></p>
<p>Author: Mathieu Sinn, Bei Chen</p><p>Abstract: Conditional Markov Chains (also known as Linear-Chain Conditional Random Fields in the literature) are a versatile class of discriminative models for the distribution of a sequence of hidden states conditional on a sequence of observable variables. Large-sample properties of Conditional Markov Chains have been ﬁrst studied in [1]. The paper extends this work in two directions: ﬁrst, mixing properties of models with unbounded feature functions are being established; second, necessary conditions for model identiﬁability and the uniqueness of maximum likelihood estimates are being given. 1</p><p>5 0.19394943 <a title="121-tfidf-5" href="./nips-2012-Relax_and_Randomize_%3A_From_Value_to_Algorithms.html">293 nips-2012-Relax and Randomize : From Value to Algorithms</a></p>
<p>Author: Sasha Rakhlin, Ohad Shamir, Karthik Sridharan</p><p>Abstract: We show a principled way of deriving online learning algorithms from a minimax analysis. Various upper bounds on the minimax value, previously thought to be non-constructive, are shown to yield algorithms. This allows us to seamlessly recover known methods and to derive new ones, also capturing such “unorthodox” methods as Follow the Perturbed Leader and the R2 forecaster. Understanding the inherent complexity of the learning problem thus leads to the development of algorithms. To illustrate our approach, we present several new algorithms, including a family of randomized methods that use the idea of a “random playout”. New versions of the Follow-the-Perturbed-Leader algorithms are presented, as well as methods based on the Littlestone’s dimension, efﬁcient methods for matrix completion with trace norm, and algorithms for the problems of transductive learning and prediction with static experts. 1</p><p>6 0.18388912 <a title="121-tfidf-6" href="./nips-2012-Practical_Bayesian_Optimization_of_Machine_Learning_Algorithms.html">272 nips-2012-Practical Bayesian Optimization of Machine Learning Algorithms</a></p>
<p>7 0.16667128 <a title="121-tfidf-7" href="./nips-2012-Active_Learning_of_Model_Evidence_Using_Bayesian_Quadrature.html">33 nips-2012-Active Learning of Model Evidence Using Bayesian Quadrature</a></p>
<p>8 0.14526454 <a title="121-tfidf-8" href="./nips-2012-Ancestor_Sampling_for_Particle_Gibbs.html">41 nips-2012-Ancestor Sampling for Particle Gibbs</a></p>
<p>9 0.1437079 <a title="121-tfidf-9" href="./nips-2012-Selective_Labeling_via_Error_Bound_Minimization.html">305 nips-2012-Selective Labeling via Error Bound Minimization</a></p>
<p>10 0.13953878 <a title="121-tfidf-10" href="./nips-2012-Collaborative_Gaussian_Processes_for_Preference_Learning.html">74 nips-2012-Collaborative Gaussian Processes for Preference Learning</a></p>
<p>11 0.13810095 <a title="121-tfidf-11" href="./nips-2012-On_Multilabel_Classification_and_Ranking_with_Partial_Feedback.html">252 nips-2012-On Multilabel Classification and Ranking with Partial Feedback</a></p>
<p>12 0.13740301 <a title="121-tfidf-12" href="./nips-2012-Regularized_Off-Policy_TD-Learning.html">292 nips-2012-Regularized Off-Policy TD-Learning</a></p>
<p>13 0.13714467 <a title="121-tfidf-13" href="./nips-2012-Learning_visual_motion_in_recurrent_neural_networks.html">195 nips-2012-Learning visual motion in recurrent neural networks</a></p>
<p>14 0.13565676 <a title="121-tfidf-14" href="./nips-2012-Multiresolution_Gaussian_Processes.html">233 nips-2012-Multiresolution Gaussian Processes</a></p>
<p>15 0.12812893 <a title="121-tfidf-15" href="./nips-2012-Fully_Bayesian_inference_for_neural_models_with_negative-binomial_spiking.html">138 nips-2012-Fully Bayesian inference for neural models with negative-binomial spiking</a></p>
<p>16 0.12131404 <a title="121-tfidf-16" href="./nips-2012-Clustering_Aggregation_as_Maximum-Weight_Independent_Set.html">68 nips-2012-Clustering Aggregation as Maximum-Weight Independent Set</a></p>
<p>17 0.11816142 <a title="121-tfidf-17" href="./nips-2012-Learning_curves_for_multi-task_Gaussian_process_regression.html">187 nips-2012-Learning curves for multi-task Gaussian process regression</a></p>
<p>18 0.11722178 <a title="121-tfidf-18" href="./nips-2012-Fast_Bayesian_Inference_for_Non-Conjugate_Gaussian_Process_Regression.html">127 nips-2012-Fast Bayesian Inference for Non-Conjugate Gaussian Process Regression</a></p>
<p>19 0.11662927 <a title="121-tfidf-19" href="./nips-2012-Minimization_of_Continuous_Bethe_Approximations%3A_A_Positive_Variation.html">213 nips-2012-Minimization of Continuous Bethe Approximations: A Positive Variation</a></p>
<p>20 0.10088385 <a title="121-tfidf-20" href="./nips-2012-A_lattice_filter_model_of_the_visual_pathway.html">23 nips-2012-A lattice filter model of the visual pathway</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.218), (1, 0.015), (2, 0.169), (3, 0.304), (4, -0.041), (5, -0.12), (6, -0.008), (7, -0.067), (8, -0.015), (9, -0.232), (10, -0.124), (11, -0.076), (12, -0.067), (13, 0.13), (14, -0.024), (15, 0.11), (16, -0.064), (17, 0.065), (18, -0.054), (19, 0.066), (20, -0.064), (21, -0.123), (22, -0.01), (23, -0.182), (24, -0.047), (25, 0.051), (26, -0.039), (27, 0.159), (28, 0.005), (29, 0.008), (30, -0.077), (31, -0.119), (32, 0.085), (33, -0.07), (34, -0.098), (35, -0.023), (36, -0.047), (37, -0.047), (38, 0.041), (39, 0.033), (40, -0.153), (41, -0.037), (42, -0.078), (43, -0.078), (44, -0.002), (45, -0.026), (46, -0.086), (47, -0.006), (48, 0.018), (49, -0.043)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98139501 <a title="121-lsi-1" href="./nips-2012-Expectation_Propagation_in_Gaussian_Process_Dynamical_Systems.html">121 nips-2012-Expectation Propagation in Gaussian Process Dynamical Systems</a></p>
<p>Author: Marc Deisenroth, Shakir Mohamed</p><p>Abstract: Rich and complex time-series data, such as those generated from engineering systems, ﬁnancial markets, videos, or neural recordings are now a common feature of modern data analysis. Explaining the phenomena underlying these diverse data sets requires ﬂexible and accurate models. In this paper, we promote Gaussian process dynamical systems as a rich model class that is appropriate for such an analysis. We present a new approximate message-passing algorithm for Bayesian state estimation and inference in Gaussian process dynamical systems, a nonparametric probabilistic generalization of commonly used state-space models. We derive our message-passing algorithm using Expectation Propagation and provide a unifying perspective on message passing in general state-space models. We show that existing Gaussian ﬁlters and smoothers appear as special cases within our inference framework, and that these existing approaches can be improved upon using iterated message passing. Using both synthetic and real-world data, we demonstrate that iterated message passing can improve inference in a wide range of tasks in Bayesian state estimation, thus leading to improved predictions and more effective decision making. 1</p><p>2 0.78821498 <a title="121-lsi-2" href="./nips-2012-Stochastic_Gradient_Descent_with_Only_One_Projection.html">324 nips-2012-Stochastic Gradient Descent with Only One Projection</a></p>
<p>Author: Mehrdad Mahdavi, Tianbao Yang, Rong Jin, Shenghuo Zhu, Jinfeng Yi</p><p>Abstract: Although many variants of stochastic gradient descent have been proposed for large-scale convex optimization, most of them require projecting the solution at each iteration to ensure that the obtained solution stays within the feasible domain. For complex domains (e.g., positive semideﬁnite cone), the projection step can be computationally expensive, making stochastic gradient descent unattractive for large-scale optimization problems. We address this limitation by developing novel stochastic optimization algorithms that do not need intermediate projections. Instead, only one projection at the last iteration is needed to obtain a feasible solution in the given domain. Our theoretical analysis shows that with a high probability, √ the proposed algorithms achieve an O(1/ T ) convergence rate for general convex optimization, and an O(ln T /T ) rate for strongly convex optimization under mild conditions about the domain and the objective function. 1</p><p>3 0.69626522 <a title="121-lsi-3" href="./nips-2012-A_Marginalized_Particle_Gaussian_Process_Regression.html">11 nips-2012-A Marginalized Particle Gaussian Process Regression</a></p>
<p>Author: Yali Wang, Brahim Chaib-draa</p><p>Abstract: We present a novel marginalized particle Gaussian process (MPGP) regression, which provides a fast, accurate online Bayesian ﬁltering framework to model the latent function. Using a state space model established by the data construction procedure, our MPGP recursively ﬁlters out the estimation of hidden function values by a Gaussian mixture. Meanwhile, it provides a new online method for training hyperparameters with a number of weighted particles. We demonstrate the estimated performance of our MPGP on both simulated and real large data sets. The results show that our MPGP is a robust estimation algorithm with high computational efﬁciency, which outperforms other state-of-art sparse GP methods. 1</p><p>4 0.68272537 <a title="121-lsi-4" href="./nips-2012-Selective_Labeling_via_Error_Bound_Minimization.html">305 nips-2012-Selective Labeling via Error Bound Minimization</a></p>
<p>Author: Quanquan Gu, Tong Zhang, Jiawei Han, Chris H. Ding</p><p>Abstract: In many practical machine learning problems, the acquisition of labeled data is often expensive and/or time consuming. This motivates us to study a problem as follows: given a label budget, how to select data points to label such that the learning performance is optimized. We propose a selective labeling method by analyzing the out-of-sample error of Laplacian regularized Least Squares (LapRLS). In particular, we derive a deterministic out-of-sample error bound for LapRLS trained on subsampled data, and propose to select a subset of data points to label by minimizing this upper bound. Since the minimization is a combinational problem, we relax it into continuous domain and solve it by projected gradient descent. Experiments on benchmark datasets show that the proposed method outperforms the state-of-the-art methods.</p><p>5 0.67164791 <a title="121-lsi-5" href="./nips-2012-Relax_and_Randomize_%3A_From_Value_to_Algorithms.html">293 nips-2012-Relax and Randomize : From Value to Algorithms</a></p>
<p>Author: Sasha Rakhlin, Ohad Shamir, Karthik Sridharan</p><p>Abstract: We show a principled way of deriving online learning algorithms from a minimax analysis. Various upper bounds on the minimax value, previously thought to be non-constructive, are shown to yield algorithms. This allows us to seamlessly recover known methods and to derive new ones, also capturing such “unorthodox” methods as Follow the Perturbed Leader and the R2 forecaster. Understanding the inherent complexity of the learning problem thus leads to the development of algorithms. To illustrate our approach, we present several new algorithms, including a family of randomized methods that use the idea of a “random playout”. New versions of the Follow-the-Perturbed-Leader algorithms are presented, as well as methods based on the Littlestone’s dimension, efﬁcient methods for matrix completion with trace norm, and algorithms for the problems of transductive learning and prediction with static experts. 1</p><p>6 0.63745803 <a title="121-lsi-6" href="./nips-2012-A_Nonparametric_Conjugate_Prior_Distribution_for_the_Maximizing_Argument_of_a_Noisy_Function.html">13 nips-2012-A Nonparametric Conjugate Prior Distribution for the Maximizing Argument of a Noisy Function</a></p>
<p>7 0.57729185 <a title="121-lsi-7" href="./nips-2012-Regularized_Off-Policy_TD-Learning.html">292 nips-2012-Regularized Off-Policy TD-Learning</a></p>
<p>8 0.55683929 <a title="121-lsi-8" href="./nips-2012-Causal_discovery_with_scale-mixture_model_for_spatiotemporal_variance_dependencies.html">66 nips-2012-Causal discovery with scale-mixture model for spatiotemporal variance dependencies</a></p>
<p>9 0.50913495 <a title="121-lsi-9" href="./nips-2012-Mixing_Properties_of_Conditional_Markov_Chains_with_Unbounded_Feature_Functions.html">218 nips-2012-Mixing Properties of Conditional Markov Chains with Unbounded Feature Functions</a></p>
<p>10 0.4998374 <a title="121-lsi-10" href="./nips-2012-Learning_visual_motion_in_recurrent_neural_networks.html">195 nips-2012-Learning visual motion in recurrent neural networks</a></p>
<p>11 0.48532677 <a title="121-lsi-11" href="./nips-2012-Bayesian_Warped_Gaussian_Processes.html">55 nips-2012-Bayesian Warped Gaussian Processes</a></p>
<p>12 0.4802908 <a title="121-lsi-12" href="./nips-2012-Active_Learning_of_Model_Evidence_Using_Bayesian_Quadrature.html">33 nips-2012-Active Learning of Model Evidence Using Bayesian Quadrature</a></p>
<p>13 0.47511661 <a title="121-lsi-13" href="./nips-2012-Practical_Bayesian_Optimization_of_Machine_Learning_Algorithms.html">272 nips-2012-Practical Bayesian Optimization of Machine Learning Algorithms</a></p>
<p>14 0.47362432 <a title="121-lsi-14" href="./nips-2012-Semi-supervised_Eigenvectors_for_Locally-biased_Learning.html">309 nips-2012-Semi-supervised Eigenvectors for Locally-biased Learning</a></p>
<p>15 0.47042763 <a title="121-lsi-15" href="./nips-2012-Fully_Bayesian_inference_for_neural_models_with_negative-binomial_spiking.html">138 nips-2012-Fully Bayesian inference for neural models with negative-binomial spiking</a></p>
<p>16 0.45233372 <a title="121-lsi-16" href="./nips-2012-Ancestor_Sampling_for_Particle_Gibbs.html">41 nips-2012-Ancestor Sampling for Particle Gibbs</a></p>
<p>17 0.44063592 <a title="121-lsi-17" href="./nips-2012-A_lattice_filter_model_of_the_visual_pathway.html">23 nips-2012-A lattice filter model of the visual pathway</a></p>
<p>18 0.43731517 <a title="121-lsi-18" href="./nips-2012-Minimization_of_Continuous_Bethe_Approximations%3A_A_Positive_Variation.html">213 nips-2012-Minimization of Continuous Bethe Approximations: A Positive Variation</a></p>
<p>19 0.43718269 <a title="121-lsi-19" href="./nips-2012-No-Regret_Algorithms_for_Unconstrained_Online_Convex_Optimization.html">241 nips-2012-No-Regret Algorithms for Unconstrained Online Convex Optimization</a></p>
<p>20 0.41414499 <a title="121-lsi-20" href="./nips-2012-Bayesian_active_learning_with_localized_priors_for_fast_receptive_field_characterization.html">56 nips-2012-Bayesian active learning with localized priors for fast receptive field characterization</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.061), (17, 0.011), (21, 0.017), (38, 0.083), (39, 0.03), (42, 0.049), (54, 0.031), (55, 0.015), (74, 0.034), (76, 0.14), (80, 0.18), (83, 0.197), (92, 0.049)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.85784626 <a title="121-lda-1" href="./nips-2012-Expectation_Propagation_in_Gaussian_Process_Dynamical_Systems.html">121 nips-2012-Expectation Propagation in Gaussian Process Dynamical Systems</a></p>
<p>Author: Marc Deisenroth, Shakir Mohamed</p><p>Abstract: Rich and complex time-series data, such as those generated from engineering systems, ﬁnancial markets, videos, or neural recordings are now a common feature of modern data analysis. Explaining the phenomena underlying these diverse data sets requires ﬂexible and accurate models. In this paper, we promote Gaussian process dynamical systems as a rich model class that is appropriate for such an analysis. We present a new approximate message-passing algorithm for Bayesian state estimation and inference in Gaussian process dynamical systems, a nonparametric probabilistic generalization of commonly used state-space models. We derive our message-passing algorithm using Expectation Propagation and provide a unifying perspective on message passing in general state-space models. We show that existing Gaussian ﬁlters and smoothers appear as special cases within our inference framework, and that these existing approaches can be improved upon using iterated message passing. Using both synthetic and real-world data, we demonstrate that iterated message passing can improve inference in a wide range of tasks in Bayesian state estimation, thus leading to improved predictions and more effective decision making. 1</p><p>2 0.79615021 <a title="121-lda-2" href="./nips-2012-Graphical_Gaussian_Vector_for_Image_Categorization.html">146 nips-2012-Graphical Gaussian Vector for Image Categorization</a></p>
<p>Author: Tatsuya Harada, Yasuo Kuniyoshi</p><p>Abstract: This paper proposes a novel image representation called a Graphical Gaussian Vector (GGV), which is a counterpart of the codebook and local feature matching approaches. We model the distribution of local features as a Gaussian Markov Random Field (GMRF) which can efﬁciently represent the spatial relationship among local features. Using concepts of information geometry, proper parameters and a metric from the GMRF can be obtained. Then we deﬁne a new image feature by embedding the proper metric into the parameters, which can be directly applied to scalable linear classiﬁers. We show that the GGV obtains better performance over the state-of-the-art methods in the standard object recognition datasets and comparable performance in the scene dataset. 1</p><p>3 0.7631216 <a title="121-lda-3" href="./nips-2012-Discriminative_Learning_of_Sum-Product_Networks.html">100 nips-2012-Discriminative Learning of Sum-Product Networks</a></p>
<p>Author: Robert Gens, Pedro Domingos</p><p>Abstract: Sum-product networks are a new deep architecture that can perform fast, exact inference on high-treewidth models. Only generative methods for training SPNs have been proposed to date. In this paper, we present the ﬁrst discriminative training algorithms for SPNs, combining the high accuracy of the former with the representational power and tractability of the latter. We show that the class of tractable discriminative SPNs is broader than the class of tractable generative ones, and propose an efﬁcient backpropagation-style algorithm for computing the gradient of the conditional log likelihood. Standard gradient descent suffers from the diffusion problem, but networks with many layers can be learned reliably using “hard” gradient descent, where marginal inference is replaced by MPE inference (i.e., inferring the most probable state of the non-evidence variables). The resulting updates have a simple and intuitive form. We test discriminative SPNs on standard image classiﬁcation tasks. We obtain the best results to date on the CIFAR-10 dataset, using fewer features than prior methods with an SPN architecture that learns local image structure discriminatively. We also report the highest published test accuracy on STL-10 even though we only use the labeled portion of the dataset. 1</p><p>4 0.76099843 <a title="121-lda-4" href="./nips-2012-Mixing_Properties_of_Conditional_Markov_Chains_with_Unbounded_Feature_Functions.html">218 nips-2012-Mixing Properties of Conditional Markov Chains with Unbounded Feature Functions</a></p>
<p>Author: Mathieu Sinn, Bei Chen</p><p>Abstract: Conditional Markov Chains (also known as Linear-Chain Conditional Random Fields in the literature) are a versatile class of discriminative models for the distribution of a sequence of hidden states conditional on a sequence of observable variables. Large-sample properties of Conditional Markov Chains have been ﬁrst studied in [1]. The paper extends this work in two directions: ﬁrst, mixing properties of models with unbounded feature functions are being established; second, necessary conditions for model identiﬁability and the uniqueness of maximum likelihood estimates are being given. 1</p><p>5 0.76035017 <a title="121-lda-5" href="./nips-2012-Local_Supervised_Learning_through_Space_Partitioning.html">200 nips-2012-Local Supervised Learning through Space Partitioning</a></p>
<p>Author: Joseph Wang, Venkatesh Saligrama</p><p>Abstract: We develop a novel approach for supervised learning based on adaptively partitioning the feature space into different regions and learning local region-speciﬁc classiﬁers. We formulate an empirical risk minimization problem that incorporates both partitioning and classiﬁcation in to a single global objective. We show that space partitioning can be equivalently reformulated as a supervised learning problem and consequently any discriminative learning method can be utilized in conjunction with our approach. Nevertheless, we consider locally linear schemes by learning linear partitions and linear region classiﬁers. Locally linear schemes can not only approximate complex decision boundaries and ensure low training error but also provide tight control on over-ﬁtting and generalization error. We train locally linear classiﬁers by using LDA, logistic regression and perceptrons, and so our scheme is scalable to large data sizes and high-dimensions. We present experimental results demonstrating improved performance over state of the art classiﬁcation techniques on benchmark datasets. We also show improved robustness to label noise.</p><p>6 0.76011282 <a title="121-lda-6" href="./nips-2012-Learning_with_Recursive_Perceptual_Representations.html">197 nips-2012-Learning with Recursive Perceptual Representations</a></p>
<p>7 0.75805569 <a title="121-lda-7" href="./nips-2012-On_Lifting_the_Gibbs_Sampling_Algorithm.html">251 nips-2012-On Lifting the Gibbs Sampling Algorithm</a></p>
<p>8 0.75547647 <a title="121-lda-8" href="./nips-2012-Latent_Coincidence_Analysis%3A_A_Hidden_Variable_Model_for_Distance_Metric_Learning.html">171 nips-2012-Latent Coincidence Analysis: A Hidden Variable Model for Distance Metric Learning</a></p>
<p>9 0.7538532 <a title="121-lda-9" href="./nips-2012-A_Nonparametric_Conjugate_Prior_Distribution_for_the_Maximizing_Argument_of_a_Noisy_Function.html">13 nips-2012-A Nonparametric Conjugate Prior Distribution for the Maximizing Argument of a Noisy Function</a></p>
<p>10 0.75149059 <a title="121-lda-10" href="./nips-2012-Projection_Retrieval_for_Classification.html">279 nips-2012-Projection Retrieval for Classification</a></p>
<p>11 0.75080401 <a title="121-lda-11" href="./nips-2012-The_Bethe_Partition_Function_of_Log-supermodular_Graphical_Models.html">335 nips-2012-The Bethe Partition Function of Log-supermodular Graphical Models</a></p>
<p>12 0.7465111 <a title="121-lda-12" href="./nips-2012-Slice_Normalized_Dynamic_Markov_Logic_Networks.html">314 nips-2012-Slice Normalized Dynamic Markov Logic Networks</a></p>
<p>13 0.74312353 <a title="121-lda-13" href="./nips-2012-Slice_sampling_normalized_kernel-weighted_completely_random_measure_mixture_models.html">315 nips-2012-Slice sampling normalized kernel-weighted completely random measure mixture models</a></p>
<p>14 0.74293888 <a title="121-lda-14" href="./nips-2012-Provable_ICA_with_Unknown_Gaussian_Noise%2C_with_Implications_for_Gaussian_Mixtures_and_Autoencoders.html">281 nips-2012-Provable ICA with Unknown Gaussian Noise, with Implications for Gaussian Mixtures and Autoencoders</a></p>
<p>15 0.73993641 <a title="121-lda-15" href="./nips-2012-Classification_Calibration_Dimension_for_General_Multiclass_Losses.html">67 nips-2012-Classification Calibration Dimension for General Multiclass Losses</a></p>
<p>16 0.73959166 <a title="121-lda-16" href="./nips-2012-Multimodal_Learning_with_Deep_Boltzmann_Machines.html">229 nips-2012-Multimodal Learning with Deep Boltzmann Machines</a></p>
<p>17 0.73916578 <a title="121-lda-17" href="./nips-2012-Multilabel_Classification_using_Bayesian_Compressed_Sensing.html">228 nips-2012-Multilabel Classification using Bayesian Compressed Sensing</a></p>
<p>18 0.73885351 <a title="121-lda-18" href="./nips-2012-Fully_Bayesian_inference_for_neural_models_with_negative-binomial_spiking.html">138 nips-2012-Fully Bayesian inference for neural models with negative-binomial spiking</a></p>
<p>19 0.73882437 <a title="121-lda-19" href="./nips-2012-Truncation-free_Online_Variational_Inference_for_Bayesian_Nonparametric_Models.html">355 nips-2012-Truncation-free Online Variational Inference for Bayesian Nonparametric Models</a></p>
<p>20 0.73562866 <a title="121-lda-20" href="./nips-2012-Kernel_Latent_SVM_for_Visual_Recognition.html">168 nips-2012-Kernel Latent SVM for Visual Recognition</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
