<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>80 nips-2012-Confusion-Based Online Learning and a Passive-Aggressive Scheme</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-80" href="#">nips2012-80</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>80 nips-2012-Confusion-Based Online Learning and a Passive-Aggressive Scheme</h1>
<br/><p>Source: <a title="nips-2012-80-pdf" href="http://papers.nips.cc/paper/4676-confusion-based-online-learning-and-a-passive-aggressive-scheme.pdf">pdf</a></p><p>Author: Liva Ralaivola</p><p>Abstract: This paper provides the ﬁrst —to the best of our knowledge— analysis of online learning algorithms for multiclass problems when the confusion matrix is taken as a performance measure. The work builds upon recent and elegant results on noncommutative concentration inequalities, i.e. concentration inequalities that apply to matrices, and, more precisely, to matrix martingales. We do establish generalization bounds for online learning algorithms and show how the theoretical study motivates the proposition of a new confusion-friendly learning procedure. This learning algorithm, called COPA (for COnfusion Passive-Aggressive) is a passive-aggressive learning algorithm; it is shown that the update equations for COPA can be computed analytically and, henceforth, there is no need to recourse to any optimization package to implement it. 1</p><p>Reference: <a title="nips-2012-80-reference" href="../nips2012_reference/nips-2012-Confusion-Based_Online_Learning_and_a_Passive-Aggressive_Scheme_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 fr  Abstract This paper provides the ﬁrst —to the best of our knowledge— analysis of online learning algorithms for multiclass problems when the confusion matrix is taken as a performance measure. [sent-4, score-0.77]
</p><p>2 The work builds upon recent and elegant results on noncommutative concentration inequalities, i. [sent-5, score-0.056]
</p><p>3 concentration inequalities that apply to matrices, and, more precisely, to matrix martingales. [sent-7, score-0.06]
</p><p>4 We do establish generalization bounds for online learning algorithms and show how the theoretical study motivates the proposition of a new confusion-friendly learning procedure. [sent-8, score-0.119]
</p><p>5 This learning algorithm, called COPA (for COnfusion Passive-Aggressive) is a passive-aggressive learning algorithm; it is shown that the update equations for COPA can be computed analytically and, henceforth, there is no need to recourse to any optimization package to implement it. [sent-9, score-0.066]
</p><p>6 This way, we step aside the more widespread viewpoint of relying on the misclassiﬁcation rate —the probability of misclassifying a point— as a performance measure for multiclass predictors. [sent-11, score-0.096]
</p><p>7 First, the confusion information is a ﬁner-grain information than the misclassiﬁcation rate, as it allows one to precisely identify the types of error made by a classiﬁer. [sent-13, score-0.621]
</p><p>8 Finally, there are many application domains such as medicine, bioinformatics, information retrieval, where the confusion matrix (or an estimate thereof) is precisely the object of interest for an expert who wants to assess the relevance of an automatic prediction procedure. [sent-15, score-0.642]
</p><p>9 On the one hand, we provide a statistical analysis for the generalization ability of online learning algorithms producing predictors that aim at optimizing the confusion. [sent-18, score-0.11]
</p><p>10 This requires us to introduce relevant statistical quantities that are taken advantage of via a concentration inequality for matrix martingales proposed by [8]. [sent-19, score-0.06]
</p><p>11 Motivated by our statistical analysis, we propose an online learning algorithm from the family of passive aggressive learning algorithms [2]: this algorithm is inherently designed to optimize the confusion matrix and numerical simulations are provided that show it reaches its goal. [sent-20, score-0.795]
</p><p>12 Section 2 formalizes our pursued objective of targetting a small confusion error. [sent-22, score-0.622]
</p><p>13 Section 3 provides our results regarding the ability of online confusion-aware learning 1  procedures to achieve a small confusion together with the update equations for COPA, a new passiveaggressive learning procedure designed to control the confusion risk. [sent-23, score-1.296]
</p><p>14 Section 4 reports numerical results that should be viewed as a proof of concept for the effectiveness of our algorithm. [sent-24, score-0.057]
</p><p>15 1  Problem and Motivation Notation  We focus on the problem of multiclass classiﬁcation: the input space is denoted by X and the target space is Y = {1, . [sent-26, score-0.076]
</p><p>16 The training sequence Z = {Zt = (Xt , Yt )}T is made of T identically t=1 and independently random pairs Zt = (Xt , Yt ) distributed according to some unknown distribution D over X × Y. [sent-30, score-0.067]
</p><p>17 The sequence of input data will be referred to as X = {Xt }T and the sequence t=1 of corresponding labels Y = {Yt }T . [sent-31, score-0.096]
</p><p>18 We use DX|y for the conditional t=1 τ distribution on X given that Y = y; therefore, for a given sequence y = (y1 , . [sent-34, score-0.065]
</p><p>19 For a sequence y of labels, T (y) = [T1 (y) · · · TQ (y)] ∈ NQ is such that Tq (y) is the number of times label q appears in y. [sent-42, score-0.048]
</p><p>20 H ⊆ {f : f : X → R}Q ), and A designates an online learning algorithm that produces hypothesis ht ∈ H when it encounters a new example Zt . [sent-47, score-0.31]
</p><p>21 Finally, = ( q|p )1≤p,q≤Q is a family of class-dependent loss functionals q|p : H × X → R+ . [sent-48, score-0.054]
</p><p>22 For a point x ∈ X of class y ∈ Y, q|y (h, x) is the cost of h’s favoring class q over y for x. [sent-49, score-0.038]
</p><p>23 The family of (cost-sensitive) misclassiﬁcation losses is deﬁned as . [sent-51, score-0.093]
</p><p>24 misclass (h, x) = χ[h(x)=q] Cyq , q|y where Cpq ∈ R+ , ∀p, q ∈ Y and χ[E] = 1 if E is true and 0 otherwise. [sent-52, score-0.08]
</p><p>25 The family of multiclass hinge losses hinge is such that, given W = {w1 , . [sent-54, score-0.271]
</p><p>26 , wQ } ∈ X Q with wq = 0 and hypothesis hW such that hW (x) = [ w1 , x · · · wQ , x ] hinge q|y (hW , x)  2. [sent-57, score-0.463]
</p><p>27 class-imbalanced datasets, it is important not to measure the quality of a predictor h based upon its classiﬁcation rate . [sent-63, score-0.043]
</p><p>28 A more informative object is the confusion matrix C(h) ∈ RQ×Q of h, which is deﬁned as: . [sent-66, score-0.622]
</p><p>29 Let us now abuse the notation and denote C(h) the confusion matrix where the diagonal entries are zeroed. [sent-69, score-0.622]
</p><p>30 This says that, with little additional information, the misclassiﬁcation rate might be obtained from the confusion matrix, while the converse is not true. [sent-72, score-0.601]
</p><p>31 Is is clear that having the confusion matrix C(h) be zero means that h is a perfect predictor. [sent-73, score-0.622]
</p><p>32 When such situation is not possible (if the data are corrupted by noise, for instance), a valuable objective might be to look for a classiﬁer h having a confusion matrix as close to zero as possible. [sent-74, score-0.622]
</p><p>33 Here, we choose to measure the closeness to zero of matrices through the operator norm · , deﬁned as: Mv 2 . [sent-75, score-0.115]
</p><p>34 M = max , v=0 v 2  (5)  where · 2 is the standard Euclidean norm — M is merely the largest singular value of M . [sent-76, score-0.057]
</p><p>35 In addition to being a valid norm, the operator norm has the following nice property, that will be of help to us. [sent-77, score-0.084]
</p><p>36 Given two matrices A = (aij ) and B = (bij ) of the same dimensions 0 ≤ aij ≤ bij , ∀i, j ⇒ A ≤ B . [sent-78, score-0.077]
</p><p>37 (6)  Given the equivalence between norms and the deﬁnition of the operator norm, it is easy to see that R(h) ≤  Q C(h) ,  and targetting a small confusion matrix for h may have the consequence of implying a small misclassiﬁcation risk R(h). [sent-79, score-0.805]
</p><p>38 The discussion conducted so far brings us to a natural goal of multiclass learning, that of minimizing the norm of the confusion matrix, i. [sent-80, score-0.715]
</p><p>39 In order to deal with the latter problem and prepare the ground for tackling the former one from a theoretical point of view, we now introduce and discuss the confusion risk, which is parameterized by a family of loss functions that may be surrogate for the indicator loss χ[] . [sent-85, score-0.689]
</p><p>40 The confusion risk C (h) of h is deﬁned as C (h) = cpq  1≤p,q≤Q  . [sent-87, score-0.743]
</p><p>41 ∈ RQ×Q , with cpq =  EX|p 0  q|p (h, X)  if p = q, otherwise. [sent-88, score-0.08]
</p><p>42 (7)  Observe that if the family misclass of losses from Example 1 is retained, and Cpq = 1 for all p, q then C misclass (h) is precisely the confusion matrix discussed above (with the diagonal set to zero). [sent-89, score-0.895]
</p><p>43 This says that if we recourse to surrogate that upper bounds the 0-1 indicator function then the norm of the confusion risk is always larger than the norm of the confusion matrix. [sent-96, score-1.468]
</p><p>44 Armed with the confusion risk and the last lemma, we may now turn towards the legitimate objective min C (h) ,  h∈H  a small value of C (h) implying a small value of C(h) (which was our primary goal). [sent-97, score-0.681]
</p><p>45 However, as already evoked, it is possible to derive learning strategies based on empirical estimates of the confusion risk, that ensures C (h) will be small. [sent-99, score-0.582]
</p><p>46 1  (Empirical) Online Confusion Risk  Assume an online learning algorithm A that outputs hypotheses from a family H: run on the traning sequence Z ∼ DT , A outputs hypotheses h = {h0 , . [sent-102, score-0.279]
</p><p>47 Let For h ∈ H and x ∈ X , we deﬁne L|p (h, x) = (luv )1≤u,v≤Q ∈ RQ×Q ,  =(  q|p )  be a family of losses and let p ∈ Y. [sent-107, score-0.093]
</p><p>48 0  (8)  The matrix L|p (h) ∈ RQ×Q is naturally given by L|p (h) = EX|p L|p (h, X). [sent-110, score-0.04]
</p><p>49 Let y ∈ Y T be a ﬁxed sequence of labels and Y a random sequence of T labels. [sent-114, score-0.096]
</p><p>50 The conditional and non-conditional confusion risks C C  ,y (h)  . [sent-119, score-0.635]
</p><p>51 In order to provide our generalization bounds, it will be more convenient for us to work with the conditional confusion C ,y (h). [sent-124, score-0.62]
</p><p>52 A simple argument will then allow us to provide generalization bounds for C ,Y (h). [sent-125, score-0.064]
</p><p>53 , hT −1 } be the hypotheses output by A when run on Z y = {(Xt , yt )}T , such that Xt is distributed according to DX|yt . [sent-131, score-0.302]
</p><p>54 t=1 The (non-)conditional empirical online confusion risks C C  ,y (h, X)  T  . [sent-132, score-0.69]
</p><p>55 Consider a sequence {Uk } of d1 × d2 random matrices, and a ﬁxed sequence of scalars {Mk } such that EUk |U1 . [sent-139, score-0.096]
</p><p>56 k  New Results  This subsection reports our main results. [sent-146, score-0.061]
</p><p>57 Suppose that the losses in are such that 0 ≤ q|p ≤ M for some M > 0. [sent-148, score-0.056]
</p><p>58 , hT −1 } is the set of hypotheses output by A when provided with {(Xt , yt )}T . [sent-153, score-0.302]
</p><p>59 where we used that the only row of Ut not to be zero is its yt th row (see Remark 1), the fact that supv: v ≤1 v · u = u 2 and the assumption 0 ≤ q|p ≤ M , which gives that |∆t,q | ≤ M . [sent-162, score-0.288]
</p><p>60 √ Using Corollary 1 on the matrix martingale {Ut }, where Ut ≤ M Q/Tyt almost surely, gives P  t  Ut ≥ ε ≤ 2Q exp −  ε2 2M 2 Q  1 2 t Ty t  Setting the right hand side to δ gives that, with probability at least 1 − δ  t  t  −2 Tyt =  p  Ut ≤ M  2Q  t  2Q 1 ln . [sent-163, score-0.081]
</p><p>61 Indeed, it provides a bound on the norm of the average confusion risks of hypotheses h0 , . [sent-167, score-0.727]
</p><p>62 , hT −1 , which, from a practical point of view, does not say much about the norm of the confusion risk of a speciﬁc hypothesis. [sent-170, score-0.72]
</p><p>63 In fact, as is usual in online learning [1], it provides a bound on the confusion risk of the Gibbs classiﬁer, which uniformly samples over h0 , . [sent-171, score-0.735]
</p><p>64 (14)  In that case, we may show the following theorem, that is much more compatible with the stated goal of trying to ﬁnd a hypothesis that has small (or at least, controlled) confusion risk. [sent-178, score-0.644]
</p><p>65 In addition to the assumptions of Theorem 1 we now assume that losses (as deﬁned in (14)). [sent-180, score-0.056]
</p><p>66 5  (15)  It is now time to give the argument allowing us to state results for the non-conditional online confusion risks. [sent-185, score-0.671]
</p><p>67 In light of the generic results of this subsection, we are now ready to motivate and derive a new online learning algorithm that aims at a small confusion risk. [sent-188, score-0.674]
</p><p>68 3  Online Learning with COPA  This subsection presents a new online algorithm, COPA (for COnfusion Passive-Aggressive learning). [sent-190, score-0.098]
</p><p>69 A ﬁrst message from Theorem 2 is that, provided the functions considered are convex, it is relevant to use the average hypothesis h as a predictor. [sent-192, score-0.048]
</p><p>70 We indeed know by (15) that the confusion risk of h is bounded by C ,y (h, X) , plus some quantity directly related to the number of training data encountered. [sent-193, score-0.681]
</p><p>71 The second message from the theorem is that the focus naturally comes to C ,y (h, X) and the question as to how minimize this quantity. [sent-194, score-0.067]
</p><p>72 According to Deﬁnition 4, C ,y (h, X) is the sum of instantaneous confusion matrices L|yt (ht−1 , Xt )/Tyt . [sent-195, score-0.632]
</p><p>73 h Tyt However, as remarked before, L|yt has only one nonzero row, its yt th. [sent-197, score-0.25]
</p><p>74 Therefore, the operator norm of L|yt (h, Xt )/Tyt is simply the Euclidean norm of its yt th row. [sent-198, score-0.391]
</p><p>75 Trying to minimize the square Euclidean norm of this row might be written as min h  1 2 Tyt  2 q|yt (h, Xt ). [sent-199, score-0.094]
</p><p>76 The hypothesis space H is made of linear classiﬁers, so that a sequence of vectors W = {w1 , . [sent-202, score-0.099]
</p><p>77 The family COPA builds upon is q|p (hW , x)  = wq , x +  1 Q−1  , ∀p, q ∈ Y. [sent-206, score-0.453]
</p><p>78 , wQ }, using (16), and implementing a passive-aggressive learning strategy [2], the new set of vectors Wt+1 is searched as the solution of  W,  1 min wq =0 2 q  Q t wq − wq  2 2  +  q=1  C 2 2Ty  wq , x + q=y  2  1 Q−1  . [sent-212, score-1.52]
</p><p>79 (17)  +  It turns out that it is possible to ﬁnd the solution of this optimization problem without having to recourse to any involved optimization procedure. [sent-213, score-0.046]
</p><p>80 This is akin to a result obtained by [6], which applies for another family of loss functions. [sent-214, score-0.054]
</p><p>81 We indeed prove the following theorem (proof in supplementary material). [sent-215, score-0.051]
</p><p>82 Suppose we want to solve  W,  1 min wq =0 2 q  Q t wq − wq  2 2  +  q=1  6  C 2  wq , x + q=y  1 Q−1  2  . [sent-217, score-1.52]
</p><p>83 +  (18)  Algorithm 1 COPA Input: z = {(xt , yt )}T training set (realization of Z), R number of epochs over z, C cost t=1 Output: W = {w1 , . [sent-218, score-0.271]
</p><p>84 = wQ for r=1 to R do for t=1 to T do receive (xt , yt ) compute α∗ according to (20) τ τ ∗ ∀q, perform the update: wq +1 ← wq − αq − τ ←τ +1 end for end for τ 1 k ∀q, wq ← τ k=1 wq  Let  t q  be deﬁned as t q  I∗ q=1  1 Q  ∗ αq xt  . [sent-224, score-1.877]
</p><p>85 4  Numerical Simulations  We here report results of preliminary simulations of COPA on a toy dataset. [sent-251, score-0.042]
</p><p>86 We compare the results of COPA to that of a simple multiclass perceptron procedure (the number of epochs for each algorithm is set to 5). [sent-260, score-0.141]
</p><p>87 The essential ﬁnding of these simulations is that COPA and the perceptron achieve similar rate of classiﬁcation accuracy, 0. [sent-262, score-0.086]
</p><p>88 86, respectively but the norm of the confusion matrix of COPA is 0. [sent-264, score-0.679]
</p><p>89 This means COPA indeed does its job in trying to minimize the confusion risk. [sent-267, score-0.648]
</p><p>90 7  5  Conclusion  In this paper, we have provided new bounds for online learning algorithms aiming at controlling their confusion risk. [sent-268, score-0.68]
</p><p>91 Preliminary numerical simulations tend to support the effectiveness of COPA. [sent-271, score-0.064]
</p><p>92 First, we would like to know whether efﬁcient update equation can be derived if a simple hinge, instead of a square hinge is used. [sent-273, score-0.071]
</p><p>93 Also, we are interested in comparing the merits of our theoretical results with those recently proposed in [5] and [7], which propose to address learning with the confusion matrix from the algorithmic stability and the PAC-Bayesian viewpoints. [sent-275, score-0.64]
</p><p>94 Finally, we would like to see how the proposed material can be of some use in the realm of structure prediction and by extension, in the case where the confusion matrix to consider is inﬁnite-dimensional. [sent-276, score-0.622]
</p><p>95 Consider a ﬁnite sequence {Xk } of self-adjoint matrices in dimension d, and a ﬁxed sequence {Ak } of self-adjoint matrices that satisfy Ek−1 Xk = 0 and 2 Xk A2 , and Ak Xk = Xk Ak , almost surely. [sent-280, score-0.175]
</p><p>96 To prove the result, it sufﬁces to make use of the dilation technique and apply Theorem 4. [sent-283, score-0.049]
</p><p>97 The self-adjoint dilation D(U ) of a matrix U ∈ Rd1 ×d2 is the self-adjoint matrix D(U ) of order d1 + d2 deﬁned by 0 U D(U ) = U∗ 0 where U ∗ is the adjoint of U (as U has only real coefﬁcient here, U ∗ is the transpose of U ). [sent-284, score-0.129]
</p><p>98 Considering Uk , we get that, almost surely: D2 (Uk )  2 Mk I,  and since dilation is a linear operator, we have that EUk |U1 ···Uk−1 D(Uk ) = 0. [sent-286, score-0.066]
</p><p>99 The sequence of matrices {D(Uk )} is therefore a matrix martingale that veriﬁes the assumption of Theorem 4, the application of which gives P λmax with σ 2 =  k  k  D(Uk ) ≥ t ≤ (d1 + d2 ) exp −  t2 2σ 2  ,  2 Mk . [sent-287, score-0.143]
</p><p>100 Exact passiveaggressive algorithm for multiclass classiﬁcation using support class. [sent-319, score-0.116]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('confusion', 0.582), ('copa', 0.398), ('wq', 0.38), ('tyt', 0.258), ('yt', 0.25), ('ht', 0.206), ('xt', 0.107), ('uk', 0.088), ('ut', 0.082), ('risk', 0.081), ('cpq', 0.08), ('misclass', 0.08), ('hw', 0.076), ('multiclass', 0.076), ('online', 0.072), ('misclassi', 0.071), ('ext', 0.065), ('norm', 0.057), ('dx', 0.056), ('losses', 0.056), ('mk', 0.054), ('tq', 0.053), ('hypotheses', 0.052), ('rq', 0.051), ('hinge', 0.051), ('dilation', 0.049), ('sequence', 0.048), ('recourse', 0.046), ('perceptron', 0.044), ('tp', 0.043), ('simulations', 0.042), ('matrix', 0.04), ('hmaj', 0.04), ('luv', 0.04), ('passiveaggressive', 0.04), ('targetting', 0.04), ('xk', 0.038), ('family', 0.037), ('risks', 0.036), ('euk', 0.035), ('multicategory', 0.035), ('reports', 0.035), ('theorem', 0.033), ('hypothesis', 0.032), ('matrices', 0.031), ('trying', 0.03), ('corollary', 0.03), ('ex', 0.029), ('classi', 0.029), ('operator', 0.027), ('pb', 0.027), ('bounds', 0.026), ('ak', 0.026), ('subsection', 0.026), ('bij', 0.025), ('zt', 0.025), ('martingale', 0.024), ('predictor', 0.024), ('numerical', 0.022), ('generalization', 0.021), ('epochs', 0.021), ('aij', 0.021), ('precisely', 0.02), ('surely', 0.02), ('relying', 0.02), ('ready', 0.02), ('update', 0.02), ('concentration', 0.02), ('remark', 0.02), ('upon', 0.019), ('class', 0.019), ('cation', 0.019), ('made', 0.019), ('instantaneous', 0.019), ('says', 0.019), ('row', 0.019), ('minimize', 0.018), ('indeed', 0.018), ('implying', 0.018), ('surrogate', 0.018), ('shimizu', 0.018), ('asap', 0.018), ('infrequent', 0.018), ('liva', 0.018), ('marseille', 0.018), ('merits', 0.018), ('prepare', 0.018), ('ralaivola', 0.018), ('satellite', 0.018), ('traning', 0.018), ('yoshida', 0.018), ('loss', 0.017), ('argument', 0.017), ('almost', 0.017), ('predictors', 0.017), ('consequence', 0.017), ('conditional', 0.017), ('builds', 0.017), ('euclidean', 0.017), ('message', 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000006 <a title="80-tfidf-1" href="./nips-2012-Confusion-Based_Online_Learning_and_a_Passive-Aggressive_Scheme.html">80 nips-2012-Confusion-Based Online Learning and a Passive-Aggressive Scheme</a></p>
<p>Author: Liva Ralaivola</p><p>Abstract: This paper provides the ﬁrst —to the best of our knowledge— analysis of online learning algorithms for multiclass problems when the confusion matrix is taken as a performance measure. The work builds upon recent and elegant results on noncommutative concentration inequalities, i.e. concentration inequalities that apply to matrices, and, more precisely, to matrix martingales. We do establish generalization bounds for online learning algorithms and show how the theoretical study motivates the proposition of a new confusion-friendly learning procedure. This learning algorithm, called COPA (for COnfusion Passive-Aggressive) is a passive-aggressive learning algorithm; it is shown that the update equations for COPA can be computed analytically and, henceforth, there is no need to recourse to any optimization package to implement it. 1</p><p>2 0.24753529 <a title="80-tfidf-2" href="./nips-2012-Mixing_Properties_of_Conditional_Markov_Chains_with_Unbounded_Feature_Functions.html">218 nips-2012-Mixing Properties of Conditional Markov Chains with Unbounded Feature Functions</a></p>
<p>Author: Mathieu Sinn, Bei Chen</p><p>Abstract: Conditional Markov Chains (also known as Linear-Chain Conditional Random Fields in the literature) are a versatile class of discriminative models for the distribution of a sequence of hidden states conditional on a sequence of observable variables. Large-sample properties of Conditional Markov Chains have been ﬁrst studied in [1]. The paper extends this work in two directions: ﬁrst, mixing properties of models with unbounded feature functions are being established; second, necessary conditions for model identiﬁability and the uniqueness of maximum likelihood estimates are being given. 1</p><p>3 0.22349802 <a title="80-tfidf-3" href="./nips-2012-On_Multilabel_Classification_and_Ranking_with_Partial_Feedback.html">252 nips-2012-On Multilabel Classification and Ranking with Partial Feedback</a></p>
<p>Author: Claudio Gentile, Francesco Orabona</p><p>Abstract: We present a novel multilabel/ranking algorithm working in partial information settings. The algorithm is based on 2nd-order descent methods, and relies on upper-conﬁdence bounds to trade-off exploration and exploitation. We analyze this algorithm in a partial adversarial setting, where covariates can be adversarial, but multilabel probabilities are ruled by (generalized) linear models. We show O(T 1/2 log T ) regret bounds, which improve in several ways on the existing results. We test the effectiveness of our upper-conﬁdence scheme by contrasting against full-information baselines on real-world multilabel datasets, often obtaining comparable performance. 1</p><p>4 0.19241241 <a title="80-tfidf-4" href="./nips-2012-A_Nonparametric_Conjugate_Prior_Distribution_for_the_Maximizing_Argument_of_a_Noisy_Function.html">13 nips-2012-A Nonparametric Conjugate Prior Distribution for the Maximizing Argument of a Noisy Function</a></p>
<p>Author: Pedro Ortega, Jordi Grau-moya, Tim Genewein, David Balduzzi, Daniel Braun</p><p>Abstract: We propose a novel Bayesian approach to solve stochastic optimization problems that involve ﬁnding extrema of noisy, nonlinear functions. Previous work has focused on representing possible functions explicitly, which leads to a two-step procedure of ﬁrst, doing inference over the function space and second, ﬁnding the extrema of these functions. Here we skip the representation step and directly model the distribution over extrema. To this end, we devise a non-parametric conjugate prior based on a kernel regressor. The resulting posterior distribution directly captures the uncertainty over the maximum of the unknown function. Given t observations of the function, the posterior can be evaluated efﬁciently in time O(t2 ) up to a multiplicative constant. Finally, we show how to apply our model to optimize a noisy, non-convex, high-dimensional objective function.</p><p>5 0.12788592 <a title="80-tfidf-5" href="./nips-2012-Learning_visual_motion_in_recurrent_neural_networks.html">195 nips-2012-Learning visual motion in recurrent neural networks</a></p>
<p>Author: Marius Pachitariu, Maneesh Sahani</p><p>Abstract: We present a dynamic nonlinear generative model for visual motion based on a latent representation of binary-gated Gaussian variables. Trained on sequences of images, the model learns to represent different movement directions in different variables. We use an online approximate inference scheme that can be mapped to the dynamics of networks of neurons. Probed with drifting grating stimuli and moving bars of light, neurons in the model show patterns of responses analogous to those of direction-selective simple cells in primary visual cortex. Most model neurons also show speed tuning and respond equally well to a range of motion directions and speeds aligned to the constraint line of their respective preferred speed. We show how these computations are enabled by a speciﬁc pattern of recurrent connections learned by the model. 1</p><p>6 0.12351439 <a title="80-tfidf-6" href="./nips-2012-Slice_Normalized_Dynamic_Markov_Logic_Networks.html">314 nips-2012-Slice Normalized Dynamic Markov Logic Networks</a></p>
<p>7 0.1153986 <a title="80-tfidf-7" href="./nips-2012-Relax_and_Randomize_%3A_From_Value_to_Algorithms.html">293 nips-2012-Relax and Randomize : From Value to Algorithms</a></p>
<p>8 0.10757679 <a title="80-tfidf-8" href="./nips-2012-Fully_Bayesian_inference_for_neural_models_with_negative-binomial_spiking.html">138 nips-2012-Fully Bayesian inference for neural models with negative-binomial spiking</a></p>
<p>9 0.10530928 <a title="80-tfidf-9" href="./nips-2012-Controlled_Recognition_Bounds_for_Visual_Learning_and_Exploration.html">83 nips-2012-Controlled Recognition Bounds for Visual Learning and Exploration</a></p>
<p>10 0.099261172 <a title="80-tfidf-10" href="./nips-2012-Regularized_Off-Policy_TD-Learning.html">292 nips-2012-Regularized Off-Policy TD-Learning</a></p>
<p>11 0.098277189 <a title="80-tfidf-11" href="./nips-2012-Stochastic_Gradient_Descent_with_Only_One_Projection.html">324 nips-2012-Stochastic Gradient Descent with Only One Projection</a></p>
<p>12 0.085584387 <a title="80-tfidf-12" href="./nips-2012-Mirror_Descent_Meets_Fixed_Share_%28and_feels_no_regret%29.html">216 nips-2012-Mirror Descent Meets Fixed Share (and feels no regret)</a></p>
<p>13 0.082509868 <a title="80-tfidf-13" href="./nips-2012-Kernel_Latent_SVM_for_Visual_Recognition.html">168 nips-2012-Kernel Latent SVM for Visual Recognition</a></p>
<p>14 0.082298785 <a title="80-tfidf-14" href="./nips-2012-Learning_Halfspaces_with_the_Zero-One_Loss%3A_Time-Accuracy_Tradeoffs.html">174 nips-2012-Learning Halfspaces with the Zero-One Loss: Time-Accuracy Tradeoffs</a></p>
<p>15 0.078300752 <a title="80-tfidf-15" href="./nips-2012-Multiclass_Learning_with_Simplex_Coding.html">227 nips-2012-Multiclass Learning with Simplex Coding</a></p>
<p>16 0.073435485 <a title="80-tfidf-16" href="./nips-2012-Expectation_Propagation_in_Gaussian_Process_Dynamical_Systems.html">121 nips-2012-Expectation Propagation in Gaussian Process Dynamical Systems</a></p>
<p>17 0.070843831 <a title="80-tfidf-17" href="./nips-2012-Multiclass_Learning_Approaches%3A_A_Theoretical_Comparison_with_Implications.html">226 nips-2012-Multiclass Learning Approaches: A Theoretical Comparison with Implications</a></p>
<p>18 0.070453994 <a title="80-tfidf-18" href="./nips-2012-Classification_Calibration_Dimension_for_General_Multiclass_Losses.html">67 nips-2012-Classification Calibration Dimension for General Multiclass Losses</a></p>
<p>19 0.067689314 <a title="80-tfidf-19" href="./nips-2012-Searching_for_objects_driven_by_context.html">303 nips-2012-Searching for objects driven by context</a></p>
<p>20 0.064326964 <a title="80-tfidf-20" href="./nips-2012-Stochastic_optimization_and_sparse_statistical_recovery%3A_Optimal_algorithms_for_high_dimensions.html">325 nips-2012-Stochastic optimization and sparse statistical recovery: Optimal algorithms for high dimensions</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.161), (1, -0.014), (2, 0.152), (3, 0.238), (4, 0.146), (5, -0.103), (6, 0.0), (7, 0.012), (8, -0.001), (9, 0.022), (10, 0.042), (11, 0.028), (12, 0.064), (13, 0.014), (14, 0.02), (15, -0.016), (16, 0.037), (17, 0.035), (18, 0.034), (19, 0.033), (20, -0.048), (21, 0.023), (22, 0.045), (23, 0.055), (24, 0.027), (25, -0.006), (26, 0.018), (27, -0.037), (28, -0.011), (29, 0.027), (30, -0.027), (31, 0.06), (32, -0.092), (33, 0.021), (34, 0.032), (35, 0.039), (36, -0.016), (37, 0.012), (38, -0.056), (39, -0.077), (40, -0.005), (41, 0.022), (42, 0.001), (43, 0.026), (44, 0.031), (45, 0.028), (46, 0.041), (47, 0.014), (48, 0.006), (49, 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93381238 <a title="80-lsi-1" href="./nips-2012-Confusion-Based_Online_Learning_and_a_Passive-Aggressive_Scheme.html">80 nips-2012-Confusion-Based Online Learning and a Passive-Aggressive Scheme</a></p>
<p>Author: Liva Ralaivola</p><p>Abstract: This paper provides the ﬁrst —to the best of our knowledge— analysis of online learning algorithms for multiclass problems when the confusion matrix is taken as a performance measure. The work builds upon recent and elegant results on noncommutative concentration inequalities, i.e. concentration inequalities that apply to matrices, and, more precisely, to matrix martingales. We do establish generalization bounds for online learning algorithms and show how the theoretical study motivates the proposition of a new confusion-friendly learning procedure. This learning algorithm, called COPA (for COnfusion Passive-Aggressive) is a passive-aggressive learning algorithm; it is shown that the update equations for COPA can be computed analytically and, henceforth, there is no need to recourse to any optimization package to implement it. 1</p><p>2 0.87459898 <a title="80-lsi-2" href="./nips-2012-On_Multilabel_Classification_and_Ranking_with_Partial_Feedback.html">252 nips-2012-On Multilabel Classification and Ranking with Partial Feedback</a></p>
<p>Author: Claudio Gentile, Francesco Orabona</p><p>Abstract: We present a novel multilabel/ranking algorithm working in partial information settings. The algorithm is based on 2nd-order descent methods, and relies on upper-conﬁdence bounds to trade-off exploration and exploitation. We analyze this algorithm in a partial adversarial setting, where covariates can be adversarial, but multilabel probabilities are ruled by (generalized) linear models. We show O(T 1/2 log T ) regret bounds, which improve in several ways on the existing results. We test the effectiveness of our upper-conﬁdence scheme by contrasting against full-information baselines on real-world multilabel datasets, often obtaining comparable performance. 1</p><p>3 0.85107887 <a title="80-lsi-3" href="./nips-2012-Mixing_Properties_of_Conditional_Markov_Chains_with_Unbounded_Feature_Functions.html">218 nips-2012-Mixing Properties of Conditional Markov Chains with Unbounded Feature Functions</a></p>
<p>Author: Mathieu Sinn, Bei Chen</p><p>Abstract: Conditional Markov Chains (also known as Linear-Chain Conditional Random Fields in the literature) are a versatile class of discriminative models for the distribution of a sequence of hidden states conditional on a sequence of observable variables. Large-sample properties of Conditional Markov Chains have been ﬁrst studied in [1]. The paper extends this work in two directions: ﬁrst, mixing properties of models with unbounded feature functions are being established; second, necessary conditions for model identiﬁability and the uniqueness of maximum likelihood estimates are being given. 1</p><p>4 0.72583759 <a title="80-lsi-4" href="./nips-2012-Slice_Normalized_Dynamic_Markov_Logic_Networks.html">314 nips-2012-Slice Normalized Dynamic Markov Logic Networks</a></p>
<p>Author: Tivadar Papai, Henry Kautz, Daniel Stefankovic</p><p>Abstract: Markov logic is a widely used tool in statistical relational learning, which uses a weighted ﬁrst-order logic knowledge base to specify a Markov random ﬁeld (MRF) or a conditional random ﬁeld (CRF). In many applications, a Markov logic network (MLN) is trained in one domain, but used in a different one. This paper focuses on dynamic Markov logic networks, where the size of the discretized time-domain typically varies between training and testing. It has been previously pointed out that the marginal probabilities of truth assignments to ground atoms can change if one extends or reduces the domains of predicates in an MLN. We show that in addition to this problem, the standard way of unrolling a Markov logic theory into a MRF may result in time-inhomogeneity of the underlying Markov chain. Furthermore, even if these representational problems are not signiﬁcant for a given domain, we show that the more practical problem of generating samples in a sequential conditional random ﬁeld for the next slice relying on the samples from the previous slice has high computational cost in the general case, due to the need to estimate a normalization factor for each sample. We propose a new discriminative model, slice normalized dynamic Markov logic networks (SN-DMLN), that suffers from none of these issues. It supports efﬁcient online inference, and can directly model inﬂuences between variables within a time slice that do not have a causal direction, in contrast with fully directed models (e.g., DBNs). Experimental results show an improvement in accuracy over previous approaches to online inference in dynamic Markov logic networks. 1</p><p>5 0.72302645 <a title="80-lsi-5" href="./nips-2012-Relax_and_Randomize_%3A_From_Value_to_Algorithms.html">293 nips-2012-Relax and Randomize : From Value to Algorithms</a></p>
<p>Author: Sasha Rakhlin, Ohad Shamir, Karthik Sridharan</p><p>Abstract: We show a principled way of deriving online learning algorithms from a minimax analysis. Various upper bounds on the minimax value, previously thought to be non-constructive, are shown to yield algorithms. This allows us to seamlessly recover known methods and to derive new ones, also capturing such “unorthodox” methods as Follow the Perturbed Leader and the R2 forecaster. Understanding the inherent complexity of the learning problem thus leads to the development of algorithms. To illustrate our approach, we present several new algorithms, including a family of randomized methods that use the idea of a “random playout”. New versions of the Follow-the-Perturbed-Leader algorithms are presented, as well as methods based on the Littlestone’s dimension, efﬁcient methods for matrix completion with trace norm, and algorithms for the problems of transductive learning and prediction with static experts. 1</p><p>6 0.68366528 <a title="80-lsi-6" href="./nips-2012-A_Nonparametric_Conjugate_Prior_Distribution_for_the_Maximizing_Argument_of_a_Noisy_Function.html">13 nips-2012-A Nonparametric Conjugate Prior Distribution for the Maximizing Argument of a Noisy Function</a></p>
<p>7 0.68030971 <a title="80-lsi-7" href="./nips-2012-Putting_Bayes_to_sleep.html">283 nips-2012-Putting Bayes to sleep</a></p>
<p>8 0.60412425 <a title="80-lsi-8" href="./nips-2012-Regularized_Off-Policy_TD-Learning.html">292 nips-2012-Regularized Off-Policy TD-Learning</a></p>
<p>9 0.58537823 <a title="80-lsi-9" href="./nips-2012-Controlled_Recognition_Bounds_for_Visual_Learning_and_Exploration.html">83 nips-2012-Controlled Recognition Bounds for Visual Learning and Exploration</a></p>
<p>10 0.54879415 <a title="80-lsi-10" href="./nips-2012-Fully_Bayesian_inference_for_neural_models_with_negative-binomial_spiking.html">138 nips-2012-Fully Bayesian inference for neural models with negative-binomial spiking</a></p>
<p>11 0.51712084 <a title="80-lsi-11" href="./nips-2012-Causal_discovery_with_scale-mixture_model_for_spatiotemporal_variance_dependencies.html">66 nips-2012-Causal discovery with scale-mixture model for spatiotemporal variance dependencies</a></p>
<p>12 0.51405233 <a title="80-lsi-12" href="./nips-2012-Learning_Halfspaces_with_the_Zero-One_Loss%3A_Time-Accuracy_Tradeoffs.html">174 nips-2012-Learning Halfspaces with the Zero-One Loss: Time-Accuracy Tradeoffs</a></p>
<p>13 0.48828384 <a title="80-lsi-13" href="./nips-2012-Cocktail_Party_Processing_via_Structured_Prediction.html">72 nips-2012-Cocktail Party Processing via Structured Prediction</a></p>
<p>14 0.48709369 <a title="80-lsi-14" href="./nips-2012-Multi-Task_Averaging.html">222 nips-2012-Multi-Task Averaging</a></p>
<p>15 0.46661648 <a title="80-lsi-15" href="./nips-2012-Searching_for_objects_driven_by_context.html">303 nips-2012-Searching for objects driven by context</a></p>
<p>16 0.43847802 <a title="80-lsi-16" href="./nips-2012-Minimax_Multi-Task_Learning_and_a_Generalized_Loss-Compositional_Paradigm_for_MTL.html">212 nips-2012-Minimax Multi-Task Learning and a Generalized Loss-Compositional Paradigm for MTL</a></p>
<p>17 0.43408582 <a title="80-lsi-17" href="./nips-2012-A_Marginalized_Particle_Gaussian_Process_Regression.html">11 nips-2012-A Marginalized Particle Gaussian Process Regression</a></p>
<p>18 0.3975971 <a title="80-lsi-18" href="./nips-2012-Mixability_in_Statistical_Learning.html">217 nips-2012-Mixability in Statistical Learning</a></p>
<p>19 0.38548473 <a title="80-lsi-19" href="./nips-2012-Stochastic_Gradient_Descent_with_Only_One_Projection.html">324 nips-2012-Stochastic Gradient Descent with Only One Projection</a></p>
<p>20 0.38505501 <a title="80-lsi-20" href="./nips-2012-Interpreting_prediction_markets%3A_a_stochastic_approach.html">161 nips-2012-Interpreting prediction markets: a stochastic approach</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.019), (21, 0.044), (27, 0.312), (38, 0.135), (42, 0.023), (54, 0.021), (55, 0.029), (74, 0.028), (76, 0.098), (80, 0.139), (92, 0.038)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.84751701 <a title="80-lda-1" href="./nips-2012-Analog_readout_for_optical_reservoir_computers.html">39 nips-2012-Analog readout for optical reservoir computers</a></p>
<p>Author: Anteo Smerieri, François Duport, Yvon Paquot, Benjamin Schrauwen, Marc Haelterman, Serge Massar</p><p>Abstract: Reservoir computing is a new, powerful and ﬂexible machine learning technique that is easily implemented in hardware. Recently, by using a timemultiplexed architecture, hardware reservoir computers have reached performance comparable to digital implementations. Operating speeds allowing for real time information operation have been reached using optoelectronic systems. At present the main performance bottleneck is the readout layer which uses slow, digital postprocessing. We have designed an analog readout suitable for time-multiplexed optoelectronic reservoir computers, capable of working in real time. The readout has been built and tested experimentally on a standard benchmark task. Its performance is better than non-reservoir methods, with ample room for further improvement. The present work thereby overcomes one of the major limitations for the future development of hardware reservoir computers. 1</p><p>2 0.78286666 <a title="80-lda-2" href="./nips-2012-Efficient_Monte_Carlo_Counterfactual_Regret_Minimization_in_Games_with_Many_Player_Actions.html">109 nips-2012-Efficient Monte Carlo Counterfactual Regret Minimization in Games with Many Player Actions</a></p>
<p>Author: Neil Burch, Marc Lanctot, Duane Szafron, Richard G. Gibson</p><p>Abstract: Counterfactual Regret Minimization (CFR) is a popular, iterative algorithm for computing strategies in extensive-form games. The Monte Carlo CFR (MCCFR) variants reduce the per iteration time cost of CFR by traversing a smaller, sampled portion of the tree. The previous most effective instances of MCCFR can still be very slow in games with many player actions since they sample every action for a given player. In this paper, we present a new MCCFR algorithm, Average Strategy Sampling (AS), that samples a subset of the player’s actions according to the player’s average strategy. Our new algorithm is inspired by a new, tighter bound on the number of iterations required by CFR to converge to a given solution quality. In addition, we prove a similar, tighter bound for AS and other popular MCCFR variants. Finally, we validate our work by demonstrating that AS converges faster than previous MCCFR algorithms in both no-limit poker and Bluff. 1</p><p>same-paper 3 0.76154542 <a title="80-lda-3" href="./nips-2012-Confusion-Based_Online_Learning_and_a_Passive-Aggressive_Scheme.html">80 nips-2012-Confusion-Based Online Learning and a Passive-Aggressive Scheme</a></p>
<p>Author: Liva Ralaivola</p><p>Abstract: This paper provides the ﬁrst —to the best of our knowledge— analysis of online learning algorithms for multiclass problems when the confusion matrix is taken as a performance measure. The work builds upon recent and elegant results on noncommutative concentration inequalities, i.e. concentration inequalities that apply to matrices, and, more precisely, to matrix martingales. We do establish generalization bounds for online learning algorithms and show how the theoretical study motivates the proposition of a new confusion-friendly learning procedure. This learning algorithm, called COPA (for COnfusion Passive-Aggressive) is a passive-aggressive learning algorithm; it is shown that the update equations for COPA can be computed analytically and, henceforth, there is no need to recourse to any optimization package to implement it. 1</p><p>4 0.68558538 <a title="80-lda-4" href="./nips-2012-Learning_as_MAP_Inference_in_Discrete_Graphical_Models.html">186 nips-2012-Learning as MAP Inference in Discrete Graphical Models</a></p>
<p>Author: Xianghang Liu, James Petterson, Tibério S. Caetano</p><p>Abstract: We present a new formulation for binary classiﬁcation. Instead of relying on convex losses and regularizers such as in SVMs, logistic regression and boosting, or instead non-convex but continuous formulations such as those encountered in neural networks and deep belief networks, our framework entails a non-convex but discrete formulation, where estimation amounts to ﬁnding a MAP conﬁguration in a graphical model whose potential functions are low-dimensional discrete surrogates for the misclassiﬁcation loss. We argue that such a discrete formulation can naturally account for a number of issues that are typically encountered in either the convex or the continuous non-convex approaches, or both. By reducing the learning problem to a MAP inference problem, we can immediately translate the guarantees available for many inference settings to the learning problem itself. We empirically demonstrate in a number of experiments that this approach is promising in dealing with issues such as severe label noise, while still having global optimality guarantees. Due to the discrete nature of the formulation, it also allows for direct regularization through cardinality-based penalties, such as the 0 pseudo-norm, thus providing the ability to perform feature selection and trade-oﬀ interpretability and predictability in a principled manner. We also outline a number of open problems arising from the formulation. 1</p><p>5 0.66804594 <a title="80-lda-5" href="./nips-2012-Active_Comparison_of_Prediction_Models.html">32 nips-2012-Active Comparison of Prediction Models</a></p>
<p>Author: Christoph Sawade, Niels Landwehr, Tobias Scheffer</p><p>Abstract: We address the problem of comparing the risks of two given predictive models—for instance, a baseline model and a challenger—as conﬁdently as possible on a ﬁxed labeling budget. This problem occurs whenever models cannot be compared on held-out training data, possibly because the training data are unavailable or do not reﬂect the desired test distribution. In this case, new test instances have to be drawn and labeled at a cost. We devise an active comparison method that selects instances according to an instrumental sampling distribution. We derive the sampling distribution that maximizes the power of a statistical test applied to the observed empirical risks, and thereby minimizes the likelihood of choosing the inferior model. Empirically, we investigate model selection problems on several classiﬁcation and regression tasks and study the accuracy of the resulting p-values. 1</p><p>6 0.58744681 <a title="80-lda-6" href="./nips-2012-Tractable_Objectives_for_Robust_Policy_Optimization.html">348 nips-2012-Tractable Objectives for Robust Policy Optimization</a></p>
<p>7 0.57849765 <a title="80-lda-7" href="./nips-2012-Provable_ICA_with_Unknown_Gaussian_Noise%2C_with_Implications_for_Gaussian_Mixtures_and_Autoencoders.html">281 nips-2012-Provable ICA with Unknown Gaussian Noise, with Implications for Gaussian Mixtures and Autoencoders</a></p>
<p>8 0.57845241 <a title="80-lda-8" href="./nips-2012-Mixing_Properties_of_Conditional_Markov_Chains_with_Unbounded_Feature_Functions.html">218 nips-2012-Mixing Properties of Conditional Markov Chains with Unbounded Feature Functions</a></p>
<p>9 0.57480419 <a title="80-lda-9" href="./nips-2012-Bayesian_active_learning_with_localized_priors_for_fast_receptive_field_characterization.html">56 nips-2012-Bayesian active learning with localized priors for fast receptive field characterization</a></p>
<p>10 0.57402945 <a title="80-lda-10" href="./nips-2012-On_Multilabel_Classification_and_Ranking_with_Partial_Feedback.html">252 nips-2012-On Multilabel Classification and Ranking with Partial Feedback</a></p>
<p>11 0.57307559 <a title="80-lda-11" href="./nips-2012-Relax_and_Randomize_%3A_From_Value_to_Algorithms.html">293 nips-2012-Relax and Randomize : From Value to Algorithms</a></p>
<p>12 0.57152712 <a title="80-lda-12" href="./nips-2012-Cardinality_Restricted_Boltzmann_Machines.html">65 nips-2012-Cardinality Restricted Boltzmann Machines</a></p>
<p>13 0.5712316 <a title="80-lda-13" href="./nips-2012-Mirror_Descent_Meets_Fixed_Share_%28and_feels_no_regret%29.html">216 nips-2012-Mirror Descent Meets Fixed Share (and feels no regret)</a></p>
<p>14 0.57078844 <a title="80-lda-14" href="./nips-2012-Local_Supervised_Learning_through_Space_Partitioning.html">200 nips-2012-Local Supervised Learning through Space Partitioning</a></p>
<p>15 0.5669809 <a title="80-lda-15" href="./nips-2012-Controlled_Recognition_Bounds_for_Visual_Learning_and_Exploration.html">83 nips-2012-Controlled Recognition Bounds for Visual Learning and Exploration</a></p>
<p>16 0.56616104 <a title="80-lda-16" href="./nips-2012-Multiclass_Learning_with_Simplex_Coding.html">227 nips-2012-Multiclass Learning with Simplex Coding</a></p>
<p>17 0.56614202 <a title="80-lda-17" href="./nips-2012-Complex_Inference_in_Neural_Circuits_with_Probabilistic_Population_Codes_and_Topic_Models.html">77 nips-2012-Complex Inference in Neural Circuits with Probabilistic Population Codes and Topic Models</a></p>
<p>18 0.56484544 <a title="80-lda-18" href="./nips-2012-Multiple_Choice_Learning%3A_Learning_to_Produce_Multiple_Structured_Outputs.html">230 nips-2012-Multiple Choice Learning: Learning to Produce Multiple Structured Outputs</a></p>
<p>19 0.56361532 <a title="80-lda-19" href="./nips-2012-Synchronization_can_Control_Regularization_in_Neural_Systems_via_Correlated_Noise_Processes.html">333 nips-2012-Synchronization can Control Regularization in Neural Systems via Correlated Noise Processes</a></p>
<p>20 0.56352335 <a title="80-lda-20" href="./nips-2012-Truncation-free_Online_Variational_Inference_for_Bayesian_Nonparametric_Models.html">355 nips-2012-Truncation-free Online Variational Inference for Bayesian Nonparametric Models</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
