<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>67 nips-2012-Classification Calibration Dimension for General Multiclass Losses</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-67" href="#">nips2012-67</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>67 nips-2012-Classification Calibration Dimension for General Multiclass Losses</h1>
<br/><p>Source: <a title="nips-2012-67-pdf" href="http://papers.nips.cc/paper/4528-classification-calibration-dimension-for-general-multiclass-losses.pdf">pdf</a></p><p>Author: Harish G. Ramaswamy, Shivani Agarwal</p><p>Abstract: We study consistency properties of surrogate loss functions for general multiclass classiﬁcation problems, deﬁned by a general loss matrix. We extend the notion of classiﬁcation calibration, which has been studied for binary and multiclass 0-1 classiﬁcation problems (and for certain other speciﬁc learning problems), to the general multiclass setting, and derive necessary and sufﬁcient conditions for a surrogate loss to be classiﬁcation calibrated with respect to a loss matrix in this setting. We then introduce the notion of classiﬁcation calibration dimension of a multiclass loss matrix, which measures the smallest ‘size’ of a prediction space for which it is possible to design a convex surrogate that is classiﬁcation calibrated with respect to the loss matrix. We derive both upper and lower bounds on this quantity, and use these results to analyze various loss matrices. In particular, as one application, we provide a different route from the recent result of Duchi et al. (2010) for analyzing the difﬁculty of designing ‘low-dimensional’ convex surrogates that are consistent with respect to pairwise subset ranking losses. We anticipate the classiﬁcation calibration dimension may prove to be a useful tool in the study and design of surrogate losses for general multiclass learning problems. 1</p><p>Reference: <a title="nips-2012-67-reference" href="../nips2012_reference/nips-2012-Classification_Calibration_Dimension_for_General_Multiclass_Losses_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('calibr', 0.524), ('surrog', 0.446), ('loss', 0.285), ('ccdim', 0.276), ('multiclass', 0.24), ('ns', 0.199), ('cc', 0.149), ('qord', 0.138), ('relint', 0.138), ('lham', 0.115), ('rn', 0.108), ('nul', 0.097), ('pred', 0.095), ('qpair', 0.092), ('convex', 0.091), ('abstain', 0.088), ('argmint', 0.081), ('rank', 0.078), ('rd', 0.073), ('wsy', 0.069)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999952 <a title="67-tfidf-1" href="./nips-2012-Classification_Calibration_Dimension_for_General_Multiclass_Losses.html">67 nips-2012-Classification Calibration Dimension for General Multiclass Losses</a></p>
<p>2 0.20261043 <a title="67-tfidf-2" href="./nips-2012-Multiclass_Learning_with_Simplex_Coding.html">227 nips-2012-Multiclass Learning with Simplex Coding</a></p>
<p>3 0.18825409 <a title="67-tfidf-3" href="./nips-2012-Local_Supervised_Learning_through_Space_Partitioning.html">200 nips-2012-Local Supervised Learning through Space Partitioning</a></p>
<p>4 0.1799598 <a title="67-tfidf-4" href="./nips-2012-Learning_as_MAP_Inference_in_Discrete_Graphical_Models.html">186 nips-2012-Learning as MAP Inference in Discrete Graphical Models</a></p>
<p>5 0.16956779 <a title="67-tfidf-5" href="./nips-2012-Statistical_Consistency_of_Ranking_Methods_in_A_Rank-Differentiable_Probability_Space.html">323 nips-2012-Statistical Consistency of Ranking Methods in A Rank-Differentiable Probability Space</a></p>
<p>6 0.14929801 <a title="67-tfidf-6" href="./nips-2012-Proper_losses_for_learning_from_partial_labels.html">280 nips-2012-Proper losses for learning from partial labels</a></p>
<p>7 0.14112228 <a title="67-tfidf-7" href="./nips-2012-Learning_Halfspaces_with_the_Zero-One_Loss%3A_Time-Accuracy_Tradeoffs.html">174 nips-2012-Learning Halfspaces with the Zero-One Loss: Time-Accuracy Tradeoffs</a></p>
<p>8 0.13078457 <a title="67-tfidf-8" href="./nips-2012-Calibrated_Elastic_Regularization_in_Matrix_Completion.html">64 nips-2012-Calibrated Elastic Regularization in Matrix Completion</a></p>
<p>9 0.11858867 <a title="67-tfidf-9" href="./nips-2012-A_Polynomial-time_Form_of_Robust_Regression.html">16 nips-2012-A Polynomial-time Form of Robust Regression</a></p>
<p>10 0.11174186 <a title="67-tfidf-10" href="./nips-2012-On_Multilabel_Classification_and_Ranking_with_Partial_Feedback.html">252 nips-2012-On Multilabel Classification and Ranking with Partial Feedback</a></p>
<p>11 0.10272827 <a title="67-tfidf-11" href="./nips-2012-A_Scalable_CUR_Matrix_Decomposition_Algorithm%3A_Lower_Time_Complexity_and_Tighter_Bound.html">17 nips-2012-A Scalable CUR Matrix Decomposition Algorithm: Lower Time Complexity and Tighter Bound</a></p>
<p>12 0.099759586 <a title="67-tfidf-12" href="./nips-2012-Active_Comparison_of_Prediction_Models.html">32 nips-2012-Active Comparison of Prediction Models</a></p>
<p>13 0.088620171 <a title="67-tfidf-13" href="./nips-2012-Hamming_Distance_Metric_Learning.html">148 nips-2012-Hamming Distance Metric Learning</a></p>
<p>14 0.088052496 <a title="67-tfidf-14" href="./nips-2012-Imitation_Learning_by_Coaching.html">160 nips-2012-Imitation Learning by Coaching</a></p>
<p>15 0.087378629 <a title="67-tfidf-15" href="./nips-2012-Pointwise_Tracking_the_Optimal_Regression_Function.html">271 nips-2012-Pointwise Tracking the Optimal Regression Function</a></p>
<p>16 0.085970283 <a title="67-tfidf-16" href="./nips-2012-Accuracy_at_the_Top.html">30 nips-2012-Accuracy at the Top</a></p>
<p>17 0.080532342 <a title="67-tfidf-17" href="./nips-2012-Accelerated_Training_for_Matrix-norm_Regularization%3A_A_Boosting_Approach.html">29 nips-2012-Accelerated Training for Matrix-norm Regularization: A Boosting Approach</a></p>
<p>18 0.079929046 <a title="67-tfidf-18" href="./nips-2012-Multiclass_Learning_Approaches%3A_A_Theoretical_Comparison_with_Implications.html">226 nips-2012-Multiclass Learning Approaches: A Theoretical Comparison with Implications</a></p>
<p>19 0.079928599 <a title="67-tfidf-19" href="./nips-2012-Link_Prediction_in_Graphs_with_Autoregressive_Features.html">199 nips-2012-Link Prediction in Graphs with Autoregressive Features</a></p>
<p>20 0.078303486 <a title="67-tfidf-20" href="./nips-2012-Mixability_in_Statistical_Learning.html">217 nips-2012-Mixability in Statistical Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.172), (1, 0.002), (2, 0.095), (3, -0.052), (4, -0.016), (5, 0.087), (6, 0.07), (7, -0.111), (8, -0.064), (9, -0.101), (10, -0.088), (11, 0.113), (12, -0.03), (13, 0.02), (14, 0.084), (15, 0.004), (16, -0.044), (17, -0.011), (18, 0.047), (19, 0.009), (20, -0.03), (21, 0.265), (22, 0.081), (23, 0.05), (24, -0.017), (25, 0.063), (26, -0.056), (27, 0.065), (28, -0.038), (29, -0.02), (30, -0.002), (31, -0.096), (32, -0.033), (33, -0.106), (34, -0.02), (35, -0.054), (36, 0.078), (37, 0.049), (38, 0.004), (39, -0.003), (40, 0.078), (41, -0.003), (42, 0.098), (43, -0.011), (44, 0.03), (45, -0.014), (46, 0.015), (47, 0.009), (48, 0.095), (49, -0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95694196 <a title="67-lsi-1" href="./nips-2012-Classification_Calibration_Dimension_for_General_Multiclass_Losses.html">67 nips-2012-Classification Calibration Dimension for General Multiclass Losses</a></p>
<p>2 0.79682302 <a title="67-lsi-2" href="./nips-2012-Proper_losses_for_learning_from_partial_labels.html">280 nips-2012-Proper losses for learning from partial labels</a></p>
<p>3 0.78973472 <a title="67-lsi-3" href="./nips-2012-Multiclass_Learning_with_Simplex_Coding.html">227 nips-2012-Multiclass Learning with Simplex Coding</a></p>
<p>4 0.73529738 <a title="67-lsi-4" href="./nips-2012-Statistical_Consistency_of_Ranking_Methods_in_A_Rank-Differentiable_Probability_Space.html">323 nips-2012-Statistical Consistency of Ranking Methods in A Rank-Differentiable Probability Space</a></p>
<p>5 0.67860556 <a title="67-lsi-5" href="./nips-2012-A_Polynomial-time_Form_of_Robust_Regression.html">16 nips-2012-A Polynomial-time Form of Robust Regression</a></p>
<p>6 0.66782147 <a title="67-lsi-6" href="./nips-2012-Learning_Halfspaces_with_the_Zero-One_Loss%3A_Time-Accuracy_Tradeoffs.html">174 nips-2012-Learning Halfspaces with the Zero-One Loss: Time-Accuracy Tradeoffs</a></p>
<p>7 0.61534524 <a title="67-lsi-7" href="./nips-2012-Accelerated_Training_for_Matrix-norm_Regularization%3A_A_Boosting_Approach.html">29 nips-2012-Accelerated Training for Matrix-norm Regularization: A Boosting Approach</a></p>
<p>8 0.61168092 <a title="67-lsi-8" href="./nips-2012-Learning_as_MAP_Inference_in_Discrete_Graphical_Models.html">186 nips-2012-Learning as MAP Inference in Discrete Graphical Models</a></p>
<p>9 0.59840119 <a title="67-lsi-9" href="./nips-2012-Label_Ranking_with_Partial_Abstention_based_on_Thresholded_Probabilistic_Models.html">169 nips-2012-Label Ranking with Partial Abstention based on Thresholded Probabilistic Models</a></p>
<p>10 0.59236801 <a title="67-lsi-10" href="./nips-2012-Volume_Regularization_for_Binary_Classification.html">361 nips-2012-Volume Regularization for Binary Classification</a></p>
<p>11 0.57880461 <a title="67-lsi-11" href="./nips-2012-Mixability_in_Statistical_Learning.html">217 nips-2012-Mixability in Statistical Learning</a></p>
<p>12 0.55445606 <a title="67-lsi-12" href="./nips-2012-A_Polylog_Pivot_Steps_Simplex_Algorithm_for_Classification.html">15 nips-2012-A Polylog Pivot Steps Simplex Algorithm for Classification</a></p>
<p>13 0.5467518 <a title="67-lsi-13" href="./nips-2012-Pointwise_Tracking_the_Optimal_Regression_Function.html">271 nips-2012-Pointwise Tracking the Optimal Regression Function</a></p>
<p>14 0.53193492 <a title="67-lsi-14" href="./nips-2012-Calibrated_Elastic_Regularization_in_Matrix_Completion.html">64 nips-2012-Calibrated Elastic Regularization in Matrix Completion</a></p>
<p>15 0.51712584 <a title="67-lsi-15" href="./nips-2012-Multiple_Choice_Learning%3A_Learning_to_Produce_Multiple_Structured_Outputs.html">230 nips-2012-Multiple Choice Learning: Learning to Produce Multiple Structured Outputs</a></p>
<p>16 0.50135505 <a title="67-lsi-16" href="./nips-2012-Local_Supervised_Learning_through_Space_Partitioning.html">200 nips-2012-Local Supervised Learning through Space Partitioning</a></p>
<p>17 0.49564749 <a title="67-lsi-17" href="./nips-2012-Hamming_Distance_Metric_Learning.html">148 nips-2012-Hamming Distance Metric Learning</a></p>
<p>18 0.48106021 <a title="67-lsi-18" href="./nips-2012-Accuracy_at_the_Top.html">30 nips-2012-Accuracy at the Top</a></p>
<p>19 0.47723153 <a title="67-lsi-19" href="./nips-2012-Minimax_Multi-Task_Learning_and_a_Generalized_Loss-Compositional_Paradigm_for_MTL.html">212 nips-2012-Minimax Multi-Task Learning and a Generalized Loss-Compositional Paradigm for MTL</a></p>
<p>20 0.47416407 <a title="67-lsi-20" href="./nips-2012-Nonparametric_Reduced_Rank_Regression.html">247 nips-2012-Nonparametric Reduced Rank Regression</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.021), (11, 0.054), (28, 0.01), (47, 0.08), (67, 0.068), (70, 0.084), (73, 0.27), (85, 0.048), (94, 0.185), (99, 0.062)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.88570464 <a title="67-lda-1" href="./nips-2012-Submodular-Bregman_and_the_Lov%C3%A1sz-Bregman_Divergences_with_Applications.html">328 nips-2012-Submodular-Bregman and the Lovász-Bregman Divergences with Applications</a></p>
<p>2 0.75832248 <a title="67-lda-2" href="./nips-2012-Scaled_Gradients_on_Grassmann_Manifolds_for_Matrix_Completion.html">301 nips-2012-Scaled Gradients on Grassmann Manifolds for Matrix Completion</a></p>
<p>3 0.75300431 <a title="67-lda-3" href="./nips-2012-A_latent_factor_model_for_highly_multi-relational_data.html">22 nips-2012-A latent factor model for highly multi-relational data</a></p>
<p>4 0.73385763 <a title="67-lda-4" href="./nips-2012-Communication-Efficient_Algorithms_for_Statistical_Optimization.html">76 nips-2012-Communication-Efficient Algorithms for Statistical Optimization</a></p>
<p>same-paper 5 0.7310794 <a title="67-lda-5" href="./nips-2012-Classification_Calibration_Dimension_for_General_Multiclass_Losses.html">67 nips-2012-Classification Calibration Dimension for General Multiclass Losses</a></p>
<p>6 0.70781446 <a title="67-lda-6" href="./nips-2012-Nonparanormal_Belief_Propagation_%28NPNBP%29.html">248 nips-2012-Nonparanormal Belief Propagation (NPNBP)</a></p>
<p>7 0.66588104 <a title="67-lda-7" href="./nips-2012-Multiclass_Learning_with_Simplex_Coding.html">227 nips-2012-Multiclass Learning with Simplex Coding</a></p>
<p>8 0.66581827 <a title="67-lda-8" href="./nips-2012-Optimal_Regularized_Dual_Averaging_Methods_for_Stochastic_Optimization.html">263 nips-2012-Optimal Regularized Dual Averaging Methods for Stochastic Optimization</a></p>
<p>9 0.66461653 <a title="67-lda-9" href="./nips-2012-Query_Complexity_of_Derivative-Free_Optimization.html">285 nips-2012-Query Complexity of Derivative-Free Optimization</a></p>
<p>10 0.66152757 <a title="67-lda-10" href="./nips-2012-Privacy_Aware_Learning.html">275 nips-2012-Privacy Aware Learning</a></p>
<p>11 0.66128242 <a title="67-lda-11" href="./nips-2012-Online_L1-Dictionary_Learning_with_Application_to_Novel_Document_Detection.html">258 nips-2012-Online L1-Dictionary Learning with Application to Novel Document Detection</a></p>
<p>12 0.66053981 <a title="67-lda-12" href="./nips-2012-Convex_Multi-view_Subspace_Learning.html">86 nips-2012-Convex Multi-view Subspace Learning</a></p>
<p>13 0.66025764 <a title="67-lda-13" href="./nips-2012-Hamming_Distance_Metric_Learning.html">148 nips-2012-Hamming Distance Metric Learning</a></p>
<p>14 0.65911406 <a title="67-lda-14" href="./nips-2012-Finite_Sample_Convergence_Rates_of_Zero-Order_Stochastic_Optimization_Methods.html">134 nips-2012-Finite Sample Convergence Rates of Zero-Order Stochastic Optimization Methods</a></p>
<p>15 0.65867066 <a title="67-lda-15" href="./nips-2012-Adaptive_Stratified_Sampling_for_Monte-Carlo_integration_of_Differentiable_functions.html">36 nips-2012-Adaptive Stratified Sampling for Monte-Carlo integration of Differentiable functions</a></p>
<p>16 0.65801501 <a title="67-lda-16" href="./nips-2012-Accelerated_Training_for_Matrix-norm_Regularization%3A_A_Boosting_Approach.html">29 nips-2012-Accelerated Training for Matrix-norm Regularization: A Boosting Approach</a></p>
<p>17 0.65740722 <a title="67-lda-17" href="./nips-2012-Scalable_nonconvex_inexact_proximal_splitting.html">300 nips-2012-Scalable nonconvex inexact proximal splitting</a></p>
<p>18 0.65705997 <a title="67-lda-18" href="./nips-2012-Random_Utility_Theory_for_Social_Choice.html">286 nips-2012-Random Utility Theory for Social Choice</a></p>
<p>19 0.65692794 <a title="67-lda-19" href="./nips-2012-Learning_from_Distributions_via_Support_Measure_Machines.html">188 nips-2012-Learning from Distributions via Support Measure Machines</a></p>
<p>20 0.65686166 <a title="67-lda-20" href="./nips-2012-Online_allocation_and_homogeneous_partitioning_for_piecewise_constant_mean-approximation.html">261 nips-2012-Online allocation and homogeneous partitioning for piecewise constant mean-approximation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
