<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>363 nips-2012-Wavelet based multi-scale shape features on arbitrary surfaces for cortical thickness discrimination</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-363" href="#">nips2012-363</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>363 nips-2012-Wavelet based multi-scale shape features on arbitrary surfaces for cortical thickness discrimination</h1>
<br/><p>Source: <a title="nips-2012-363-pdf" href="http://papers.nips.cc/paper/4796-wavelet-based-multi-scale-shape-features-on-arbitrary-surfaces-for-cortical-thickness-discrimination.pdf">pdf</a></p><p>Author: Won H. Kim, Deepti Pachauri, Charles Hatt, Moo. K. Chung, Sterling Johnson, Vikas Singh</p><p>Abstract: Hypothesis testing on signals deﬁned on surfaces (such as the cortical surface) is a fundamental component of a variety of studies in Neuroscience. The goal here is to identify regions that exhibit changes as a function of the clinical condition under study. As the clinical questions of interest move towards identifying very early signs of diseases, the corresponding statistical differences at the group level invariably become weaker and increasingly hard to identify. Indeed, after a multiple comparisons correction is adopted (to account for correlated statistical tests over all surface points), very few regions may survive. In contrast to hypothesis tests on point-wise measurements, in this paper, we make the case for performing statistical analysis on multi-scale shape descriptors that characterize the local topological context of the signal around each surface vertex. Our descriptors are based on recent results from harmonic analysis, that show how wavelet theory extends to non-Euclidean settings (i.e., irregular weighted graphs). We provide strong evidence that these descriptors successfully pick up group-wise differences, where traditional methods either fail or yield unsatisfactory results. Other than this primary application, we show how the framework allows performing cortical surface smoothing in the native space without mappint to a unit sphere. 1</p><p>Reference: <a title="nips-2012-363-reference" href="../nips2012_reference/nips-2012-Wavelet_based_multi-scale_shape_features_on_arbitrary_surfaces_for_cortical_thickness_discrimination_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Wavelet based multi-scale shape features on arbitrary surfaces for cortical thickness discrimination Won Hwa Kim†¶∗ Deepti Pachauri† Charles Hatt‡ Moo K. [sent-1, score-0.944]
</p><p>2 edu  Abstract Hypothesis testing on signals deﬁned on surfaces (such as the cortical surface) is a fundamental component of a variety of studies in Neuroscience. [sent-15, score-0.589]
</p><p>3 As the clinical questions of interest move towards identifying very early signs of diseases, the corresponding statistical differences at the group level invariably become weaker and increasingly hard to identify. [sent-17, score-0.167]
</p><p>4 Indeed, after a multiple comparisons correction is adopted (to account for correlated statistical tests over all surface points), very few regions may survive. [sent-18, score-0.42]
</p><p>5 In contrast to hypothesis tests on point-wise measurements, in this paper, we make the case for performing statistical analysis on multi-scale shape descriptors that characterize the local topological context of the signal around each surface vertex. [sent-19, score-0.497]
</p><p>6 Our descriptors are based on recent results from harmonic analysis, that show how wavelet theory extends to non-Euclidean settings (i. [sent-20, score-0.411]
</p><p>7 Other than this primary application, we show how the framework allows performing cortical surface smoothing in the native space without mappint to a unit sphere. [sent-24, score-0.762]
</p><p>8 1  Introduction  Cortical thickness measures the distance between the outer and inner cortical surfaces (see Fig. [sent-25, score-0.938]
</p><p>9 Since 2011, more than 1000 articles (from a search on Google Scholar and/or Pubmed) tie cortical thickness to conditions ranging from Alzheimer’s disease (AD), to Schizophrenia and Traumatic Brain injury (TBI) [9, 14, 13]. [sent-28, score-0.835]
</p><p>10 Many of these results show how cortical thickness also correlates with brain growth (and atrophy) during adolescence (and aging) respectively [22, 20, 7]. [sent-29, score-0.885]
</p><p>11 Given that brain function and pathology manifest strongly as changes in the cortical thickness, the statistical analysis of such data (to ﬁnd group level differences in clinically disparate populations) plays a central role in structural neuroimaging studies. [sent-30, score-0.761]
</p><p>12 In typical cortical thickness studies, magnetic resonance images (MRI) are acquired for two populations: clinical and normal. [sent-31, score-0.791]
</p><p>13 A sequence of image processing steps are performed to segment the cortical surfaces and establish vertex-to-vertex correspondence across surface meshes [15]. [sent-32, score-0.867]
</p><p>14 That is, we can ask if there are statistically signiﬁcant differences in the signal between the two groups. [sent-34, score-0.175]
</p><p>15 , differences are strong enough), the analysis will reveal a set of discriminative cortical surface regions, which may be positively or negatively correlated with the clinical condition of interest. [sent-38, score-0.754]
</p><p>16 For instance, we may be interested in identifying early signs of dementia by analyzing cortical surfaces (e. [sent-41, score-0.559]
</p><p>17 In this regime, the differences are weaker, and the cortical differences may be too subtle to be detected. [sent-44, score-0.541]
</p><p>18 In a statistically under-powered cortical thickness analysis, few vertices may survive the multiple comparisons correction. [sent-45, score-0.876]
</p><p>19 Another aspect that makes this task challenging is that the cortical thickness data (obtained from state of the art tools) is still inherently noisy. [sent-46, score-0.756]
</p><p>20 The standard approach for ﬁltering cortical sur- Figure 1: Cortical thickness illusface noise is to adopt an appropriate parameterization to model tration: the outer cortical surface (in yellow) and the inner cortical surthe signal followed by a diffusion-type smoothing [6]. [sent-47, score-2.059]
</p><p>21 The distance between mary difﬁculty is that most (if not all) widely used parameteri- the two surfaces is the cortical thickzations operate in a spherical coordinate system using spherical ness. [sent-49, score-0.789]
</p><p>22 As a result, one must ﬁrst project the signal on the surface to a unit sphere. [sent-51, score-0.353]
</p><p>23 , Gibbs phenomena) when used to ﬁt rapidly changing localized cortical measurements [10]. [sent-55, score-0.482]
</p><p>24 Third, SPHARM uses global basis functions which typically requires a large number of terms in the expansion to model cortical surface signals to high ﬁdelity. [sent-56, score-0.766]
</p><p>25 Subsequently, even if the globally-based coefﬁcients exhibit statistical differences, interpreting which brain regions contribute to these variations is difﬁcult. [sent-57, score-0.215]
</p><p>26 As a result, the coefﬁcients of the model cannot be used directly in localizing variations in the cortical signal. [sent-58, score-0.438]
</p><p>27 This paper is motivated by the simple observation that statistical inference on surface based signals should be based not on a single scalar measurement but on multivariate descriptors that characterize the topologically localized context around each point sample. [sent-59, score-0.431]
</p><p>28 This view insures against signal noise at individual vertices, and should offer the tools to meaningfully compare the behavior of the signal at multiple resolutions of the topological feature, across multiple subjects. [sent-60, score-0.222]
</p><p>29 In our neuroimaging application, samples are not drawn on a regular grid, instead governed entirely by the underlying cortical surface mesh of the participant. [sent-65, score-0.786]
</p><p>30 To get around this difﬁculty, we make use of some recent results from the harmonic analysis literature [8] – which suggests how wavelet analysis can be extended to arbitrary weighted graphs with irregular topology. [sent-66, score-0.404]
</p><p>31 We show how these ideas can be used to derive a wavelet multi-scale descriptor for statistical analysis of signals deﬁned on surfaces. [sent-67, score-0.415]
</p><p>32 We derive wavelet based multi-scale representations of surface based signals. [sent-70, score-0.536]
</p><p>33 (i) We show how the new model signiﬁcantly extends the operating range of analysis of cortical surface signals (such as cortical thickness). [sent-73, score-1.127]
</p><p>34 At a pre-speciﬁed signiﬁcance level, we can detect a much stronger signal showing group differences that are barely detectable using existing approaches. [sent-74, score-0.214]
</p><p>35 (ii) We illustrate how the procedure of smoothing of cortical surfaces (and shapes) can completely bypass the mapping on to a sphere, since smoothing can now be performed in the native space. [sent-76, score-0.696]
</p><p>36 The construction of wavelets is deﬁned by a wavelet function ψ (called an analyzing wavelet or a mother wavelet) and a scaling function φ. [sent-79, score-0.813]
</p><p>37 Here, ψ serves as a band-pass ﬁlter and φ operates as a low-pass ﬁlter covering the low frequency components of the signal which cannot be tackled by the band-pass ﬁlters. [sent-80, score-0.174]
</p><p>38 When the band-pass ﬁlter is transformed back by the inverse transform and translated, it becomes a localized oscillating function with ﬁnite duration, providing very compact (local) support in the original domain [21]. [sent-81, score-0.19]
</p><p>39 The function ψs,a (x) forms a basis for the signal and can be used with other bases at different scales to decompose a signal, similar to Fourier transform. [sent-85, score-0.228]
</p><p>40 The wavelet transform of a signal f (x) is deﬁned as the inner product of the wavelet and signal and can be represented as Wf (s, a) = f, ψ =  1 a  f (x)ψ ∗ (  x−a )dx s  (2)  where Wf (s, a) is the wavelet coefﬁcient at scale s and at location a. [sent-86, score-1.234]
</p><p>41 Such a transform is invertible, that is f (x) =  1 Cψ  Wf (s, a)ψs,a (x)da ds  (3)  2  where Cψ = |Ψ(jω)| dω is called the admissibility condition constant, and Ψ is the Fourier |ω| transform of the wavelet [21], and the ω is the domain of frequency. [sent-88, score-0.486]
</p><p>42 As mentioned earlier, the scale parameter s controls the dilation of the basis and can be used to produce both short and long basis functions. [sent-89, score-0.193]
</p><p>43 While short basis functions correspond to high frequency components and are useful to isolate signal discontinuities, longer basis functions corresponding to lower frequencies, are also required to to obtain detailed frequency analysis. [sent-90, score-0.341]
</p><p>44 Indeed, wavelets transforms have an inﬁnite set of possible basis functions, unlike the single set of basis functions (sine and cosine) in the Fourier transform. [sent-91, score-0.329]
</p><p>45 Before concluding this section, we note that while wavelets based analysis for image processing is a mature ﬁeld, most of these results are not directly applicable to non-uniform topologies such as those encountered in shape meshes and surfaces in Fig. [sent-92, score-0.514]
</p><p>46 3  Deﬁning Wavelets on Arbitrary Graphs  Note that the topology of a brain surface is naturally modeled as a weighted graph. [sent-94, score-0.371]
</p><p>47 However, the application of wavelets to this setting is not straightforward, as wavelets have traditionally been limited to the Euclidean space setting. [sent-95, score-0.45]
</p><p>48 Extending the notion of wavelets to a non-Euclidean setting, particularly to weighted graphs, requires deriving a multi-scale representation of a function deﬁned on the vertices. [sent-96, score-0.225]
</p><p>49 Higher powers of T (given as T t ) induce a dilation (or scaling) process on the function to which it is applied, and describes the behavior of the diffusion at varying time scales (t). [sent-103, score-0.166]
</p><p>50 In fact, the powers of T are low rank (since the spectrum of T decays), and this ties back to the compressibility behavior of classical wavelets used in image processing applications (e. [sent-106, score-0.255]
</p><p>51 These issues are critical in practice, especially when adopting this framework for analysis of surface meshes with ∼ 200, 000 vertices with a wide spectum of frequencies (which can beneﬁt from ﬁner control over scale). [sent-114, score-0.453]
</p><p>52 The solution proposed in [11] discards repeated application of the diffusion operator T , and instead relies on the graph Laplacian to derive a spectral graph wavelet transform (SGWT). [sent-115, score-0.488]
</p><p>53 To do this, [11] uses a form of the wavelet operator in the Fourier domain, and generalizes it to graphs. [sent-116, score-0.294]
</p><p>54 The formalization is shown to preserve the localization properties at ﬁne scales as well as other wavelets speciﬁc properties. [sent-118, score-0.29]
</p><p>55 But beyond constructing the transform, the operator-valued functions of the Laplacian are very useful to derive a powerful multiscale shape descriptor localized at different frequencies which performs very well in experiments. [sent-119, score-0.257]
</p><p>56 This provides a multiresolution view of the signal localized at m. [sent-123, score-0.18]
</p><p>57 And for a speciﬁc scale s, we can now construct band-pass ﬁlters g in the frequency domain which suppresses the inﬂuence of scales s = s. [sent-126, score-0.209]
</p><p>58 Repeating this process for multiple scales, the set of coefﬁcients obtained for S scales comprises our multiscale descriptor for that vertex. [sent-128, score-0.183]
</p><p>59 Since the transformed impulse function in the frequency domain is equivalent to a unit function, the wavelet ψ localized at vertex n is deﬁned as, N −1  g(sλl )χ∗ (n)χl (m) l  ψs,n (m) =  (5)  l=0  where m is a vertex index on the graph. [sent-131, score-0.64]
</p><p>60 We will discuss shortly how many of the low-level processes in obtaining wavelet coefﬁcients can be expressed as linear algebra primitives that can be translated on to the CUDA architecture. [sent-136, score-0.294]
</p><p>61 In this context, we ﬁrst test if the multi-scale shape descriptors can drive signiﬁcant improvements in the statistical analysis of cortical surface measurements. [sent-139, score-0.761]
</p><p>62 Then, we use these ideas to perform smoothing of cortical surface meshes without ﬁrst projecting them onto a spherical coordinate system (the conventional approach). [sent-140, score-0.956]
</p><p>63 1  Cortical Thickness Discrimination: Group Analysis for Alzheimer’s disease (AD) studies  As we brieﬂy discussed in Section 1, the identiﬁcation of group differences between cortical surface signals is based on comparing the distribution of the signal across the two groups at each vertex. [sent-142, score-1.007]
</p><p>64 This can be done either by using the signal (cortical thickness) obtained from the segmentation directly, or by using a spherical harmonic (SPHARM) or spherical wavelet approach to ﬁrst parameterize and then smooth the signal, followed by a vertex-wise T −test on the smoothed signal. [sent-143, score-0.685]
</p><p>65 In contrast, our multi-scale descriptor is well deﬁned for characterizing the shape (and the signal) on the native graph domain itself. [sent-145, score-0.245]
</p><p>66 We employ hypothesis testing using the original cortical thickness and SPHARM as the two baselines for comparison when presenting our experiments below. [sent-146, score-0.756]
</p><p>67 Our data included brain images from 356 participants: 160 Alzheimer’s disease subjects (AD) and 196 healthy controls (CN). [sent-149, score-0.245]
</p><p>68 This dataset was pre-processed using a stan- Table 1: Demographic details and baseline cognitive stadard image processing pipeline, and the tus measure of the ADNI dataset Freesurfer algorithm [18] was used to segADNI data ment the cortical surfaces, calculate the corCategory AD (mean) AD (s. [sent-151, score-0.413]
</p><p>69 ) # of Subjects 160 196 tical thickness values, and provide vertex to Age 75. [sent-155, score-0.412]
</p><p>70 We constructed WMDs for each vertex on the template cortical surface at 6 different scales, and used Hotelling’s T 2 −test for group analysis. [sent-169, score-0.791]
</p><p>71 The same procedure was repeated using the cortical thickness measurements (from Freesurfer) and the smoothed signal obtained from SPHARM. [sent-170, score-0.867]
</p><p>72 The ﬁrst row corresponds to group analysis using the original cortical thickness values (CT). [sent-174, score-0.822]
</p><p>73 Figure 2: Normalized log scale p-values after FDR correction at q = 10−5 , projected back on a brain mesh and displayed. [sent-190, score-0.308]
</p><p>74 Row 1: Original cortical thickness, Row 2: SPHARM, Row 3: Wavelet Multiscale descriptor. [sent-191, score-0.413]
</p><p>75 With FDR set to 10−3 , 10−5 and 10−7 , the number of vertices that survives the correction threshold decreases to 51929, 28606 and 13226 respectively. [sent-199, score-0.17]
</p><p>76 When we compare two clinically different groups of brain subjects at the opposite ends of the disease spectrum (AD versus controls), the tests help identify which brain regions are severely affected. [sent-206, score-0.532]
</p><p>77 6  Figure 4: Normalized log scale p-values after FDR correction on the left hemisphere with q = 10−7 on cortical thickness (left column) , SPHARM (middle column), WMD (right column) repectively, showing both inner and outer sides of the hemisphere. [sent-210, score-0.978]
</p><p>78 Figure 5: Normalized log scale p-values showing the effect of FDR correction on the template left hemisphere using WMD with FDR q = 10−3 (left column), q = 10−5 (middle column) and q = 10−7 (right column) repectively, showing both inner and outer sides of the hemisphere. [sent-211, score-0.25]
</p><p>79 2  Cortical Surface Smoothing without Sphere Mapping  Existing methods for smoothing cortical surfaces and the signal deﬁned on it, such as spherical harmonics, explicitly represent the cortical surface as a combination of basis functions deﬁned over regular Euclidean spaces. [sent-213, score-1.519]
</p><p>80 Our goal was to evaluate whether the ideas introduced here can avoid this compromise by being able to represent (and smooth) the signal deﬁned on any arbitrarily shaped mesh using the basis in Section 3. [sent-215, score-0.232]
</p><p>81 We used wavelets of varying scales to localize the structure of the brain mesh. [sent-218, score-0.419]
</p><p>82 An inverse wavelet transformation of the resultant function provides the smooth estimate of the cortical surface at various scales. [sent-219, score-0.949]
</p><p>83 The same process can be applied to the signal deﬁned on the surface as well. [sent-220, score-0.353]
</p><p>84 At ﬁner scale, the complete spectrum is used and recovers the original surface to high ﬁdelity. [sent-227, score-0.272]
</p><p>85 6 where we illustrate the process of reconstructing the surface of a brain mesh (and the cortical thickness signal) from a coarse to ﬁner scales. [sent-230, score-1.196]
</p><p>86 7  The ﬁnal reconstruction of the sample brain surface from inverse transformation using ﬁve scales of wavelets and one scaling function returns total error of 2. [sent-231, score-0.661]
</p><p>87 Top row: Structural smoothing from coarse to ﬁner scales, Bottom row: Smoothed cortical thickness displayed on the surface. [sent-239, score-0.815]
</p><p>88 Processing large surface meshes with ∼ 200000 vertices is computationally intensive. [sent-241, score-0.428]
</p><p>89 Using the cusparse and cublas libraries, we derived a specialized procedure for computing the wavelet transform, which makes heavy use of commodity graphics-card hardware. [sent-245, score-0.294]
</p><p>90 7 provides a comparison of our results to the serial MATLAB implementation and code using the commercial Jacket toolbox, for processing one brain with 166367 vertices over 6 wavelet scales as a function of polynomial degree. [sent-247, score-0.579]
</p><p>91 We see that a dataset Figure 7: Running times to process a single can be processed in less than 10 seconds (even with high brain dataset using native MATLAB code, Jacket, and our own implementation polynomial order) using our implementation. [sent-248, score-0.177]
</p><p>92 5  Conclusions  We showed that shape descriptors based on multi-scale representations of surface based signals are a powerful tool for performing multivariate analysis of such data at various resolutions. [sent-249, score-0.407]
</p><p>93 Using a large and well characterized neuroimaging dataset, we showed how the framework improves statistical power in hypothesis testing of cortical thickness signals. [sent-250, score-0.818]
</p><p>94 We also demonstrated how the idea is applicable to cortical surface smoothing and yield competitive results without a spherical coordinate transformation. [sent-253, score-0.861]
</p><p>95 Postmortem evidence of structural brain changes in Schizophrenia differences in brain weight, temporal horn area, and parahippocampal gyrus compared with affective disorder. [sent-273, score-0.347]
</p><p>96 A theory for multiresolution signal decomposition: the wavelet representation. [sent-327, score-0.405]
</p><p>97 Short communication: Diffuse changes in cortical thickness in pediatric moderate-to-severe traumatic brain injury. [sent-334, score-0.921]
</p><p>98 Mapping cortical thickness and gray matter concentration in ﬁrst episode Schizophrenia. [sent-340, score-0.756]
</p><p>99 Intellectual ability and cortical development in children and adolescents. [sent-376, score-0.413]
</p><p>100 Longitudinal mapping of cortical thickness and brain growth in normal children. [sent-388, score-0.885]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('cortical', 0.413), ('thickness', 0.343), ('wavelet', 0.294), ('surface', 0.242), ('fdr', 0.233), ('spharm', 0.233), ('wavelets', 0.225), ('wmd', 0.179), ('alzheimer', 0.156), ('brain', 0.129), ('fourier', 0.119), ('surfaces', 0.117), ('spherical', 0.112), ('signal', 0.111), ('meshes', 0.095), ('vertices', 0.091), ('correction', 0.079), ('disease', 0.079), ('ad', 0.077), ('wf', 0.073), ('transform', 0.071), ('localized', 0.069), ('vertex', 0.069), ('mesh', 0.069), ('scales', 0.065), ('differences', 0.064), ('frequency', 0.063), ('neuroimaging', 0.062), ('wisconsin', 0.062), ('descriptor', 0.062), ('regions', 0.061), ('descriptors', 0.061), ('signals', 0.059), ('smoothing', 0.059), ('dilation', 0.058), ('madison', 0.058), ('ct', 0.058), ('harmonic', 0.056), ('multiscale', 0.056), ('pachauri', 0.054), ('repectively', 0.054), ('sgwt', 0.054), ('basis', 0.052), ('domain', 0.05), ('native', 0.048), ('hemisphere', 0.047), ('bonferroni', 0.047), ('laplacian', 0.047), ('chung', 0.046), ('shape', 0.045), ('diffusion', 0.043), ('adni', 0.041), ('graph', 0.04), ('group', 0.039), ('tests', 0.038), ('subjects', 0.037), ('outer', 0.037), ('ner', 0.037), ('ctrl', 0.036), ('freesurfer', 0.036), ('hatt', 0.036), ('jacket', 0.036), ('traumatic', 0.036), ('uncorrected', 0.036), ('wmds', 0.036), ('clinical', 0.035), ('coordinate', 0.035), ('walk', 0.034), ('cients', 0.032), ('mature', 0.032), ('implicated', 0.032), ('preclinical', 0.032), ('neurotrophic', 0.032), ('orthonormalization', 0.032), ('uw', 0.032), ('schizophrenia', 0.032), ('scale', 0.031), ('spectrum', 0.03), ('survive', 0.029), ('dementia', 0.029), ('invariably', 0.029), ('clinically', 0.029), ('graphs', 0.028), ('template', 0.028), ('inner', 0.028), ('compression', 0.027), ('coarser', 0.027), ('eigenmaps', 0.027), ('multiplications', 0.027), ('coef', 0.027), ('row', 0.027), ('impulse', 0.026), ('diseases', 0.026), ('irregular', 0.026), ('discrimination', 0.026), ('wi', 0.026), ('translation', 0.026), ('variations', 0.025), ('frequencies', 0.025), ('structural', 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999958 <a title="363-tfidf-1" href="./nips-2012-Wavelet_based_multi-scale_shape_features_on_arbitrary_surfaces_for_cortical_thickness_discrimination.html">363 nips-2012-Wavelet based multi-scale shape features on arbitrary surfaces for cortical thickness discrimination</a></p>
<p>Author: Won H. Kim, Deepti Pachauri, Charles Hatt, Moo. K. Chung, Sterling Johnson, Vikas Singh</p><p>Abstract: Hypothesis testing on signals deﬁned on surfaces (such as the cortical surface) is a fundamental component of a variety of studies in Neuroscience. The goal here is to identify regions that exhibit changes as a function of the clinical condition under study. As the clinical questions of interest move towards identifying very early signs of diseases, the corresponding statistical differences at the group level invariably become weaker and increasingly hard to identify. Indeed, after a multiple comparisons correction is adopted (to account for correlated statistical tests over all surface points), very few regions may survive. In contrast to hypothesis tests on point-wise measurements, in this paper, we make the case for performing statistical analysis on multi-scale shape descriptors that characterize the local topological context of the signal around each surface vertex. Our descriptors are based on recent results from harmonic analysis, that show how wavelet theory extends to non-Euclidean settings (i.e., irregular weighted graphs). We provide strong evidence that these descriptors successfully pick up group-wise differences, where traditional methods either fail or yield unsatisfactory results. Other than this primary application, we show how the framework allows performing cortical surface smoothing in the native space without mappint to a unit sphere. 1</p><p>2 0.21633875 <a title="363-tfidf-2" href="./nips-2012-Multiresolution_analysis_on_the_symmetric_group.html">234 nips-2012-Multiresolution analysis on the symmetric group</a></p>
<p>Author: Risi Kondor, Walter Dempsey</p><p>Abstract: There is no generally accepted way to deﬁne wavelets on permutations. We address this issue by introducing the notion of coset based multiresolution analysis (CMRA) on the symmetric group, ﬁnd the corresponding wavelet functions, and describe a fast wavelet transform for sparse signals. We discuss potential applications in ranking, sparse approximation, and multi-object tracking. 1</p><p>3 0.17154312 <a title="363-tfidf-3" href="./nips-2012-Compressive_Sensing_MRI_with_Wavelet_Tree_Sparsity.html">78 nips-2012-Compressive Sensing MRI with Wavelet Tree Sparsity</a></p>
<p>Author: Chen Chen, Junzhou Huang</p><p>Abstract: In Compressive Sensing Magnetic Resonance Imaging (CS-MRI), one can reconstruct a MR image with good quality from only a small number of measurements. This can signiﬁcantly reduce MR scanning time. According to structured sparsity theory, the measurements can be further reduced to O(K + log n) for tree-sparse data instead of O(K + K log n) for standard K-sparse data with length n. However, few of existing algorithms have utilized this for CS-MRI, while most of them model the problem with total variation and wavelet sparse regularization. On the other side, some algorithms have been proposed for tree sparse regularization, but few of them have validated the beneﬁt of wavelet tree structure in CS-MRI. In this paper, we propose a fast convex optimization algorithm to improve CS-MRI. Wavelet sparsity, gradient sparsity and tree sparsity are all considered in our model for real MR images. The original complex problem is decomposed into three simpler subproblems then each of the subproblems can be efﬁciently solved with an iterative scheme. Numerous experiments have been conducted and show that the proposed algorithm outperforms the state-of-the-art CS-MRI algorithms, and gain better reconstructions results on real MR images than general tree based solvers or algorithms. 1</p><p>4 0.10042726 <a title="363-tfidf-4" href="./nips-2012-High-Order_Multi-Task_Feature_Learning_to_Identify_Longitudinal_Phenotypic_Markers_for_Alzheimer%27s_Disease_Progression_Prediction.html">151 nips-2012-High-Order Multi-Task Feature Learning to Identify Longitudinal Phenotypic Markers for Alzheimer's Disease Progression Prediction</a></p>
<p>Author: Hua Wang, Feiping Nie, Heng Huang, Jingwen Yan, Sungeun Kim, Shannon Risacher, Andrew Saykin, Li Shen</p><p>Abstract: Alzheimer’s disease (AD) is a neurodegenerative disorder characterized by progressive impairment of memory and other cognitive functions. Regression analysis has been studied to relate neuroimaging measures to cognitive status. However, whether these measures have further predictive power to infer a trajectory of cognitive performance over time is still an under-explored but important topic in AD research. We propose a novel high-order multi-task learning model to address this issue. The proposed model explores the temporal correlations existing in imaging and cognitive data by structured sparsity-inducing norms. The sparsity of the model enables the selection of a small number of imaging measures while maintaining high prediction accuracy. The empirical studies, using the longitudinal imaging and cognitive data of the ADNI cohort, have yielded promising results.</p><p>5 0.09297739 <a title="363-tfidf-5" href="./nips-2012-From_Deformations_to_Parts%3A_Motion-based_Segmentation_of_3D_Objects.html">137 nips-2012-From Deformations to Parts: Motion-based Segmentation of 3D Objects</a></p>
<p>Author: Soumya Ghosh, Matthew Loper, Erik B. Sudderth, Michael J. Black</p><p>Abstract: We develop a method for discovering the parts of an articulated object from aligned meshes of the object in various three-dimensional poses. We adapt the distance dependent Chinese restaurant process (ddCRP) to allow nonparametric discovery of a potentially unbounded number of parts, while simultaneously guaranteeing a spatially connected segmentation. To allow analysis of datasets in which object instances have varying 3D shapes, we model part variability across poses via afﬁne transformations. By placing a matrix normal-inverse-Wishart prior on these afﬁne transformations, we develop a ddCRP Gibbs sampler which tractably marginalizes over transformation uncertainty. Analyzing a dataset of humans captured in dozens of poses, we infer parts which provide quantitatively better deformation predictions than conventional clustering methods.</p><p>6 0.092912547 <a title="363-tfidf-6" href="./nips-2012-Q-MKL%3A_Matrix-induced_Regularization_in_Multi-Kernel_Learning_with_Applications_to_Neuroimaging.html">284 nips-2012-Q-MKL: Matrix-induced Regularization in Multi-Kernel Learning with Applications to Neuroimaging</a></p>
<p>7 0.087713473 <a title="363-tfidf-7" href="./nips-2012-Probabilistic_Event_Cascades_for_Alzheimer%27s_disease.html">276 nips-2012-Probabilistic Event Cascades for Alzheimer's disease</a></p>
<p>8 0.074553862 <a title="363-tfidf-8" href="./nips-2012-Identification_of_Recurrent_Patterns_in_the_Activation_of_Brain_Networks.html">157 nips-2012-Identification of Recurrent Patterns in the Activation of Brain Networks</a></p>
<p>9 0.072743572 <a title="363-tfidf-9" href="./nips-2012-Nystr%C3%B6m_Method_vs_Random_Fourier_Features%3A_A_Theoretical_and_Empirical_Comparison.html">249 nips-2012-Nyström Method vs Random Fourier Features: A Theoretical and Empirical Comparison</a></p>
<p>10 0.061588299 <a title="363-tfidf-10" href="./nips-2012-Neuronal_Spike_Generation_Mechanism_as_an_Oversampling%2C_Noise-shaping_A-to-D_converter.html">239 nips-2012-Neuronal Spike Generation Mechanism as an Oversampling, Noise-shaping A-to-D converter</a></p>
<p>11 0.058158692 <a title="363-tfidf-11" href="./nips-2012-Learning_Image_Descriptors_with_the_Boosting-Trick.html">176 nips-2012-Learning Image Descriptors with the Boosting-Trick</a></p>
<p>12 0.058045812 <a title="363-tfidf-12" href="./nips-2012-Compressive_neural_representation_of_sparse%2C_high-dimensional_probabilities.html">79 nips-2012-Compressive neural representation of sparse, high-dimensional probabilities</a></p>
<p>13 0.05711551 <a title="363-tfidf-13" href="./nips-2012-A_systematic_approach_to_extracting_semantic_information_from_functional_MRI_data.html">28 nips-2012-A systematic approach to extracting semantic information from functional MRI data</a></p>
<p>14 0.054135043 <a title="363-tfidf-14" href="./nips-2012-Online_Sum-Product_Computation_Over_Trees.html">260 nips-2012-Online Sum-Product Computation Over Trees</a></p>
<p>15 0.052458111 <a title="363-tfidf-15" href="./nips-2012-The_topographic_unsupervised_learning_of_natural_sounds_in_the_auditory_cortex.html">341 nips-2012-The topographic unsupervised learning of natural sounds in the auditory cortex</a></p>
<p>16 0.051441293 <a title="363-tfidf-16" href="./nips-2012-The_Coloured_Noise_Expansion_and_Parameter_Estimation_of_Diffusion_Processes.html">336 nips-2012-The Coloured Noise Expansion and Parameter Estimation of Diffusion Processes</a></p>
<p>17 0.051010326 <a title="363-tfidf-17" href="./nips-2012-Learning_visual_motion_in_recurrent_neural_networks.html">195 nips-2012-Learning visual motion in recurrent neural networks</a></p>
<p>18 0.049733028 <a title="363-tfidf-18" href="./nips-2012-Hierarchical_spike_coding_of_sound.html">150 nips-2012-Hierarchical spike coding of sound</a></p>
<p>19 0.046838783 <a title="363-tfidf-19" href="./nips-2012-Bayesian_Pedigree_Analysis_using_Measure_Factorization.html">53 nips-2012-Bayesian Pedigree Analysis using Measure Factorization</a></p>
<p>20 0.045894835 <a title="363-tfidf-20" href="./nips-2012-Synchronization_can_Control_Regularization_in_Neural_Systems_via_Correlated_Noise_Processes.html">333 nips-2012-Synchronization can Control Regularization in Neural Systems via Correlated Noise Processes</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.139), (1, 0.035), (2, -0.057), (3, -0.001), (4, 0.021), (5, 0.058), (6, -0.007), (7, -0.005), (8, -0.043), (9, 0.019), (10, -0.009), (11, -0.063), (12, 0.025), (13, -0.054), (14, 0.009), (15, 0.007), (16, 0.008), (17, 0.034), (18, 0.035), (19, -0.1), (20, 0.038), (21, 0.119), (22, -0.084), (23, -0.106), (24, 0.035), (25, 0.023), (26, -0.149), (27, 0.185), (28, -0.103), (29, 0.173), (30, 0.068), (31, -0.072), (32, -0.031), (33, -0.121), (34, 0.038), (35, -0.136), (36, 0.027), (37, 0.107), (38, -0.137), (39, 0.002), (40, -0.094), (41, -0.008), (42, 0.082), (43, 0.019), (44, 0.153), (45, -0.002), (46, -0.05), (47, 0.015), (48, -0.006), (49, -0.14)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95908225 <a title="363-lsi-1" href="./nips-2012-Wavelet_based_multi-scale_shape_features_on_arbitrary_surfaces_for_cortical_thickness_discrimination.html">363 nips-2012-Wavelet based multi-scale shape features on arbitrary surfaces for cortical thickness discrimination</a></p>
<p>Author: Won H. Kim, Deepti Pachauri, Charles Hatt, Moo. K. Chung, Sterling Johnson, Vikas Singh</p><p>Abstract: Hypothesis testing on signals deﬁned on surfaces (such as the cortical surface) is a fundamental component of a variety of studies in Neuroscience. The goal here is to identify regions that exhibit changes as a function of the clinical condition under study. As the clinical questions of interest move towards identifying very early signs of diseases, the corresponding statistical differences at the group level invariably become weaker and increasingly hard to identify. Indeed, after a multiple comparisons correction is adopted (to account for correlated statistical tests over all surface points), very few regions may survive. In contrast to hypothesis tests on point-wise measurements, in this paper, we make the case for performing statistical analysis on multi-scale shape descriptors that characterize the local topological context of the signal around each surface vertex. Our descriptors are based on recent results from harmonic analysis, that show how wavelet theory extends to non-Euclidean settings (i.e., irregular weighted graphs). We provide strong evidence that these descriptors successfully pick up group-wise differences, where traditional methods either fail or yield unsatisfactory results. Other than this primary application, we show how the framework allows performing cortical surface smoothing in the native space without mappint to a unit sphere. 1</p><p>2 0.7906009 <a title="363-lsi-2" href="./nips-2012-Multiresolution_analysis_on_the_symmetric_group.html">234 nips-2012-Multiresolution analysis on the symmetric group</a></p>
<p>Author: Risi Kondor, Walter Dempsey</p><p>Abstract: There is no generally accepted way to deﬁne wavelets on permutations. We address this issue by introducing the notion of coset based multiresolution analysis (CMRA) on the symmetric group, ﬁnd the corresponding wavelet functions, and describe a fast wavelet transform for sparse signals. We discuss potential applications in ranking, sparse approximation, and multi-object tracking. 1</p><p>3 0.60495251 <a title="363-lsi-3" href="./nips-2012-Compressive_Sensing_MRI_with_Wavelet_Tree_Sparsity.html">78 nips-2012-Compressive Sensing MRI with Wavelet Tree Sparsity</a></p>
<p>Author: Chen Chen, Junzhou Huang</p><p>Abstract: In Compressive Sensing Magnetic Resonance Imaging (CS-MRI), one can reconstruct a MR image with good quality from only a small number of measurements. This can signiﬁcantly reduce MR scanning time. According to structured sparsity theory, the measurements can be further reduced to O(K + log n) for tree-sparse data instead of O(K + K log n) for standard K-sparse data with length n. However, few of existing algorithms have utilized this for CS-MRI, while most of them model the problem with total variation and wavelet sparse regularization. On the other side, some algorithms have been proposed for tree sparse regularization, but few of them have validated the beneﬁt of wavelet tree structure in CS-MRI. In this paper, we propose a fast convex optimization algorithm to improve CS-MRI. Wavelet sparsity, gradient sparsity and tree sparsity are all considered in our model for real MR images. The original complex problem is decomposed into three simpler subproblems then each of the subproblems can be efﬁciently solved with an iterative scheme. Numerous experiments have been conducted and show that the proposed algorithm outperforms the state-of-the-art CS-MRI algorithms, and gain better reconstructions results on real MR images than general tree based solvers or algorithms. 1</p><p>4 0.47544211 <a title="363-lsi-4" href="./nips-2012-Probabilistic_Event_Cascades_for_Alzheimer%27s_disease.html">276 nips-2012-Probabilistic Event Cascades for Alzheimer's disease</a></p>
<p>Author: Jonathan Huang, Daniel Alexander</p><p>Abstract: Accurate and detailed models of neurodegenerative disease progression are crucially important for reliable early diagnosis and the determination of effective treatments. We introduce the ALPACA (Alzheimer’s disease Probabilistic Cascades) model, a generative model linking latent Alzheimer’s progression dynamics to observable biomarker data. In contrast with previous works which model disease progression as a ﬁxed event ordering, we explicitly model the variability over such orderings among patients which is more realistic, particularly for highly detailed progression models. We describe efﬁcient learning algorithms for ALPACA and discuss promising experimental results on a real cohort of Alzheimer’s patients from the Alzheimer’s Disease Neuroimaging Initiative. 1</p><p>5 0.46996897 <a title="363-lsi-5" href="./nips-2012-Assessing_Blinding_in_Clinical_Trials.html">46 nips-2012-Assessing Blinding in Clinical Trials</a></p>
<p>Author: Ognjen Arandjelovic</p><p>Abstract: The interaction between the patient’s expected outcome of an intervention and the inherent effects of that intervention can have extraordinary effects. Thus in clinical trials an effort is made to conceal the nature of the administered intervention from the participants in the trial i.e. to blind it. Yet, in practice perfect blinding is impossible to ensure or even verify. The current standard is follow up the trial with an auxiliary questionnaire, which allows trial participants to express their belief concerning the assigned intervention and which is used to compute a measure of the extent of blinding in the trial. If the estimated extent of blinding exceeds a threshold the trial is deemed sufﬁciently blinded; otherwise, the trial is deemed to have failed. In this paper we make several important contributions. Firstly, we identify a series of fundamental problems of the aforesaid practice and discuss them in context of the most commonly used blinding measures. Secondly, motivated by the highlighted problems, we formulate a novel method for handling imperfectly blinded trials. We too adopt a post-trial feedback questionnaire but interpret the collected data using an original approach, fundamentally different from those previously proposed. Unlike previous approaches, ours is void of any ad hoc free parameters, is robust to small changes in auxiliary data and is not predicated on any strong assumptions used to interpret participants’ feedback. 1</p><p>6 0.45786086 <a title="363-lsi-6" href="./nips-2012-Identification_of_Recurrent_Patterns_in_the_Activation_of_Brain_Networks.html">157 nips-2012-Identification of Recurrent Patterns in the Activation of Brain Networks</a></p>
<p>7 0.45228502 <a title="363-lsi-7" href="./nips-2012-High-Order_Multi-Task_Feature_Learning_to_Identify_Longitudinal_Phenotypic_Markers_for_Alzheimer%27s_Disease_Progression_Prediction.html">151 nips-2012-High-Order Multi-Task Feature Learning to Identify Longitudinal Phenotypic Markers for Alzheimer's Disease Progression Prediction</a></p>
<p>8 0.44891131 <a title="363-lsi-8" href="./nips-2012-Bayesian_Pedigree_Analysis_using_Measure_Factorization.html">53 nips-2012-Bayesian Pedigree Analysis using Measure Factorization</a></p>
<p>9 0.40172985 <a title="363-lsi-9" href="./nips-2012-Fast_Resampling_Weighted_v-Statistics.html">128 nips-2012-Fast Resampling Weighted v-Statistics</a></p>
<p>10 0.39796042 <a title="363-lsi-10" href="./nips-2012-From_Deformations_to_Parts%3A_Motion-based_Segmentation_of_3D_Objects.html">137 nips-2012-From Deformations to Parts: Motion-based Segmentation of 3D Objects</a></p>
<p>11 0.39420339 <a title="363-lsi-11" href="./nips-2012-A_systematic_approach_to_extracting_semantic_information_from_functional_MRI_data.html">28 nips-2012-A systematic approach to extracting semantic information from functional MRI data</a></p>
<p>12 0.36114502 <a title="363-lsi-12" href="./nips-2012-CPRL_--_An_Extension_of_Compressive_Sensing_to_the_Phase_Retrieval_Problem.html">63 nips-2012-CPRL -- An Extension of Compressive Sensing to the Phase Retrieval Problem</a></p>
<p>13 0.35932347 <a title="363-lsi-13" href="./nips-2012-Predicting_Action_Content_On-Line_and_in_Real_Time_before_Action_Onset_%E2%80%93_an_Intracranial_Human_Study.html">273 nips-2012-Predicting Action Content On-Line and in Real Time before Action Onset – an Intracranial Human Study</a></p>
<p>14 0.34356654 <a title="363-lsi-14" href="./nips-2012-Locally_Uniform_Comparison_Image_Descriptor.html">202 nips-2012-Locally Uniform Comparison Image Descriptor</a></p>
<p>15 0.31468198 <a title="363-lsi-15" href="./nips-2012-Multi-scale_Hyper-time_Hardware_Emulation_of_Human_Motor_Nervous_System_Based_on_Spiking_Neurons_using_FPGA.html">224 nips-2012-Multi-scale Hyper-time Hardware Emulation of Human Motor Nervous System Based on Spiking Neurons using FPGA</a></p>
<p>16 0.30633247 <a title="363-lsi-16" href="./nips-2012-Online_Sum-Product_Computation_Over_Trees.html">260 nips-2012-Online Sum-Product Computation Over Trees</a></p>
<p>17 0.30462357 <a title="363-lsi-17" href="./nips-2012-Kernel_Hyperalignment.html">167 nips-2012-Kernel Hyperalignment</a></p>
<p>18 0.30385235 <a title="363-lsi-18" href="./nips-2012-Compressive_neural_representation_of_sparse%2C_high-dimensional_probabilities.html">79 nips-2012-Compressive neural representation of sparse, high-dimensional probabilities</a></p>
<p>19 0.30184561 <a title="363-lsi-19" href="./nips-2012-Q-MKL%3A_Matrix-induced_Regularization_in_Multi-Kernel_Learning_with_Applications_to_Neuroimaging.html">284 nips-2012-Q-MKL: Matrix-induced Regularization in Multi-Kernel Learning with Applications to Neuroimaging</a></p>
<p>20 0.29278767 <a title="363-lsi-20" href="./nips-2012-Nystr%C3%B6m_Method_vs_Random_Fourier_Features%3A_A_Theoretical_and_Empirical_Comparison.html">249 nips-2012-Nyström Method vs Random Fourier Features: A Theoretical and Empirical Comparison</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.042), (11, 0.025), (17, 0.025), (21, 0.033), (26, 0.231), (38, 0.076), (39, 0.032), (42, 0.016), (54, 0.035), (55, 0.017), (64, 0.015), (74, 0.064), (76, 0.138), (80, 0.07), (86, 0.013), (92, 0.055), (94, 0.034)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.79958642 <a title="363-lda-1" href="./nips-2012-Wavelet_based_multi-scale_shape_features_on_arbitrary_surfaces_for_cortical_thickness_discrimination.html">363 nips-2012-Wavelet based multi-scale shape features on arbitrary surfaces for cortical thickness discrimination</a></p>
<p>Author: Won H. Kim, Deepti Pachauri, Charles Hatt, Moo. K. Chung, Sterling Johnson, Vikas Singh</p><p>Abstract: Hypothesis testing on signals deﬁned on surfaces (such as the cortical surface) is a fundamental component of a variety of studies in Neuroscience. The goal here is to identify regions that exhibit changes as a function of the clinical condition under study. As the clinical questions of interest move towards identifying very early signs of diseases, the corresponding statistical differences at the group level invariably become weaker and increasingly hard to identify. Indeed, after a multiple comparisons correction is adopted (to account for correlated statistical tests over all surface points), very few regions may survive. In contrast to hypothesis tests on point-wise measurements, in this paper, we make the case for performing statistical analysis on multi-scale shape descriptors that characterize the local topological context of the signal around each surface vertex. Our descriptors are based on recent results from harmonic analysis, that show how wavelet theory extends to non-Euclidean settings (i.e., irregular weighted graphs). We provide strong evidence that these descriptors successfully pick up group-wise differences, where traditional methods either fail or yield unsatisfactory results. Other than this primary application, we show how the framework allows performing cortical surface smoothing in the native space without mappint to a unit sphere. 1</p><p>2 0.63284504 <a title="363-lda-2" href="./nips-2012-Max-Margin_Structured_Output_Regression_for_Spatio-Temporal_Action_Localization.html">209 nips-2012-Max-Margin Structured Output Regression for Spatio-Temporal Action Localization</a></p>
<p>Author: Du Tran, Junsong Yuan</p><p>Abstract: Structured output learning has been successfully applied to object localization, where the mapping between an image and an object bounding box can be well captured. Its extension to action localization in videos, however, is much more challenging, because we need to predict the locations of the action patterns both spatially and temporally, i.e., identifying a sequence of bounding boxes that track the action in video. The problem becomes intractable due to the exponentially large size of the structured video space where actions could occur. We propose a novel structured learning approach for spatio-temporal action localization. The mapping between a video and a spatio-temporal action trajectory is learned. The intractable inference and learning problems are addressed by leveraging an efﬁcient Max-Path search method, thus making it feasible to optimize the model over the whole structured space. Experiments on two challenging benchmark datasets show that our proposed method outperforms the state-of-the-art methods. 1</p><p>3 0.62953109 <a title="363-lda-3" href="./nips-2012-Unsupervised_Template_Learning_for_Fine-Grained_Object_Recognition.html">357 nips-2012-Unsupervised Template Learning for Fine-Grained Object Recognition</a></p>
<p>Author: Shulin Yang, Liefeng Bo, Jue Wang, Linda G. Shapiro</p><p>Abstract: Fine-grained recognition refers to a subordinate level of recognition, such as recognizing different species of animals and plants. It differs from recognition of basic categories, such as humans, tables, and computers, in that there are global similarities in shape and structure shared cross different categories, and the differences are in the details of object parts. We suggest that the key to identifying the ﬁne-grained differences lies in ﬁnding the right alignment of image regions that contain the same object parts. We propose a template model for the purpose, which captures common shape patterns of object parts, as well as the cooccurrence relation of the shape patterns. Once the image regions are aligned, extracted features are used for classiﬁcation. Learning of the template model is efﬁcient, and the recognition results we achieve signiﬁcantly outperform the stateof-the-art algorithms. 1</p><p>4 0.6257214 <a title="363-lda-4" href="./nips-2012-Deep_Learning_of_Invariant_Features_via_Simulated_Fixations_in_Video.html">90 nips-2012-Deep Learning of Invariant Features via Simulated Fixations in Video</a></p>
<p>Author: Will Zou, Shenghuo Zhu, Kai Yu, Andrew Y. Ng</p><p>Abstract: We apply salient feature detection and tracking in videos to simulate ﬁxations and smooth pursuit in human vision. With tracked sequences as input, a hierarchical network of modules learns invariant features using a temporal slowness constraint. The network encodes invariance which are increasingly complex with hierarchy. Although learned from videos, our features are spatial instead of spatial-temporal, and well suited for extracting features from still images. We applied our features to four datasets (COIL-100, Caltech 101, STL-10, PubFig), and observe a consistent improvement of 4% to 5% in classiﬁcation accuracy. With this approach, we achieve state-of-the-art recognition accuracy 61% on STL-10 dataset. 1</p><p>5 0.62540275 <a title="363-lda-5" href="./nips-2012-Compressive_neural_representation_of_sparse%2C_high-dimensional_probabilities.html">79 nips-2012-Compressive neural representation of sparse, high-dimensional probabilities</a></p>
<p>Author: Xaq Pitkow</p><p>Abstract: This paper shows how sparse, high-dimensional probability distributions could be represented by neurons with exponential compression. The representation is a novel application of compressive sensing to sparse probability distributions rather than to the usual sparse signals. The compressive measurements correspond to expected values of nonlinear functions of the probabilistically distributed variables. When these expected values are estimated by sampling, the quality of the compressed representation is limited only by the quality of sampling. Since the compression preserves the geometric structure of the space of sparse probability distributions, probabilistic computation can be performed in the compressed domain. Interestingly, functions satisfying the requirements of compressive sensing can be implemented as simple perceptrons. If we use perceptrons as a simple model of feedforward computation by neurons, these results show that the mean activity of a relatively small number of neurons can accurately represent a highdimensional joint distribution implicitly, even without accounting for any noise correlations. This comprises a novel hypothesis for how neurons could encode probabilities in the brain. 1</p><p>6 0.62498665 <a title="363-lda-6" href="./nips-2012-Clustering_Aggregation_as_Maximum-Weight_Independent_Set.html">68 nips-2012-Clustering Aggregation as Maximum-Weight Independent Set</a></p>
<p>7 0.6246078 <a title="363-lda-7" href="./nips-2012-Searching_for_objects_driven_by_context.html">303 nips-2012-Searching for objects driven by context</a></p>
<p>8 0.62350327 <a title="363-lda-8" href="./nips-2012-Memorability_of_Image_Regions.html">210 nips-2012-Memorability of Image Regions</a></p>
<p>9 0.62257862 <a title="363-lda-9" href="./nips-2012-Learning_with_Recursive_Perceptual_Representations.html">197 nips-2012-Learning with Recursive Perceptual Representations</a></p>
<p>10 0.62048018 <a title="363-lda-10" href="./nips-2012-From_Deformations_to_Parts%3A_Motion-based_Segmentation_of_3D_Objects.html">137 nips-2012-From Deformations to Parts: Motion-based Segmentation of 3D Objects</a></p>
<p>11 0.61993903 <a title="363-lda-11" href="./nips-2012-Truly_Nonparametric_Online_Variational_Inference_for_Hierarchical_Dirichlet_Processes.html">354 nips-2012-Truly Nonparametric Online Variational Inference for Hierarchical Dirichlet Processes</a></p>
<p>12 0.61990201 <a title="363-lda-12" href="./nips-2012-Discriminatively_Trained_Sparse_Code_Gradients_for_Contour_Detection.html">101 nips-2012-Discriminatively Trained Sparse Code Gradients for Contour Detection</a></p>
<p>13 0.61970216 <a title="363-lda-13" href="./nips-2012-Learning_to_Align_from_Scratch.html">193 nips-2012-Learning to Align from Scratch</a></p>
<p>14 0.61967903 <a title="363-lda-14" href="./nips-2012-Learning_from_Distributions_via_Support_Measure_Machines.html">188 nips-2012-Learning from Distributions via Support Measure Machines</a></p>
<p>15 0.61881089 <a title="363-lda-15" href="./nips-2012-Stochastic_optimization_and_sparse_statistical_recovery%3A_Optimal_algorithms_for_high_dimensions.html">325 nips-2012-Stochastic optimization and sparse statistical recovery: Optimal algorithms for high dimensions</a></p>
<p>16 0.61862719 <a title="363-lda-16" href="./nips-2012-Kernel_Latent_SVM_for_Visual_Recognition.html">168 nips-2012-Kernel Latent SVM for Visual Recognition</a></p>
<p>17 0.61855966 <a title="363-lda-17" href="./nips-2012-Isotropic_Hashing.html">163 nips-2012-Isotropic Hashing</a></p>
<p>18 0.6184935 <a title="363-lda-18" href="./nips-2012-Deep_Representations_and_Codes_for_Image_Auto-Annotation.html">92 nips-2012-Deep Representations and Codes for Image Auto-Annotation</a></p>
<p>19 0.61798197 <a title="363-lda-19" href="./nips-2012-Dynamical_And-Or_Graph_Learning_for_Object_Shape_Modeling_and_Detection.html">106 nips-2012-Dynamical And-Or Graph Learning for Object Shape Modeling and Detection</a></p>
<p>20 0.61695439 <a title="363-lda-20" href="./nips-2012-Efficient_Sampling_for_Bipartite_Matching_Problems.html">111 nips-2012-Efficient Sampling for Bipartite Matching Problems</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
