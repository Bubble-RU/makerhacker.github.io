<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>136 nips-2012-Forward-Backward Activation Algorithm for Hierarchical Hidden Markov Models</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-136" href="#">nips2012-136</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>136 nips-2012-Forward-Backward Activation Algorithm for Hierarchical Hidden Markov Models</h1>
<br/><p>Source: <a title="nips-2012-136-pdf" href="http://papers.nips.cc/paper/4628-forward-backward-activation-algorithm-for-hierarchical-hidden-markov-models.pdf">pdf</a></p><p>Author: Kei Wakabayashi, Takao Miura</p><p>Abstract: Hierarchical Hidden Markov Models (HHMMs) are sophisticated stochastic models that enable us to capture a hierarchical context characterization of sequence data. However, existing HHMM parameter estimation methods require large computations of time complexity O(T N 2D ) at least for model inference, where D is the depth of the hierarchy, N is the number of states in each level, and T is the sequence length. In this paper, we propose a new inference method of HHMMs for which the time complexity is O(T N D+1 ). A key idea of our algorithm is application of the forward-backward algorithm to state activation probabilities. The notion of a state activation, which offers a simple formalization of the hierarchical transition behavior of HHMMs, enables us to conduct model inference efﬁciently. We present some experiments to demonstrate that our proposed method works more efﬁciently to estimate HHMM parameters than do some existing methods such as the ﬂattening method and Gibbs sampling method. 1</p><p>Reference: <a title="nips-2012-136-reference" href="../nips2012_reference/nips-2012-Forward-Backward_Activation_Algorithm_for_Hierarchical_Hidden_Markov_Models_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('hhmms', 0.384), ('hhmm', 0.351), ('bd', 0.336), ('fba', 0.301), ('ftd', 0.25), ('sib', 0.25), ('zt', 0.234), ('ft', 0.186), ('minsr', 0.184), ('adid', 0.15), ('nul', 0.141), ('fb', 0.139), ('qd', 0.136), ('dgs', 0.134), ('ffb', 0.117), ('ot', 0.112), ('transit', 0.097), ('gadid', 0.083), ('gbiv', 0.083), ('termin', 0.082)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="136-tfidf-1" href="./nips-2012-Forward-Backward_Activation_Algorithm_for_Hierarchical_Hidden_Markov_Models.html">136 nips-2012-Forward-Backward Activation Algorithm for Hierarchical Hidden Markov Models</a></p>
<p>Author: Kei Wakabayashi, Takao Miura</p><p>Abstract: Hierarchical Hidden Markov Models (HHMMs) are sophisticated stochastic models that enable us to capture a hierarchical context characterization of sequence data. However, existing HHMM parameter estimation methods require large computations of time complexity O(T N 2D ) at least for model inference, where D is the depth of the hierarchy, N is the number of states in each level, and T is the sequence length. In this paper, we propose a new inference method of HHMMs for which the time complexity is O(T N D+1 ). A key idea of our algorithm is application of the forward-backward algorithm to state activation probabilities. The notion of a state activation, which offers a simple formalization of the hierarchical transition behavior of HHMMs, enables us to conduct model inference efﬁciently. We present some experiments to demonstrate that our proposed method works more efﬁciently to estimate HHMM parameters than do some existing methods such as the ﬂattening method and Gibbs sampling method. 1</p><p>2 0.18320687 <a title="136-tfidf-2" href="./nips-2012-Bayesian_Nonparametric_Modeling_of_Suicide_Attempts.html">52 nips-2012-Bayesian Nonparametric Modeling of Suicide Attempts</a></p>
<p>Author: Francisco Ruiz, Isabel Valera, Carlos Blanco, Fernando Pérez-Cruz</p><p>Abstract: The National Epidemiologic Survey on Alcohol and Related Conditions (NESARC) database contains a large amount of information, regarding the way of life, medical conditions, etc., of a representative sample of the U.S. population. In this paper, we are interested in seeking the hidden causes behind the suicide attempts, for which we propose to model the subjects using a nonparametric latent model based on the Indian Buffet Process (IBP). Due to the nature of the data, we need to adapt the observation model for discrete random variables. We propose a generative model in which the observations are drawn from a multinomial-logit distribution given the IBP matrix. The implementation of an efﬁcient Gibbs sampler is accomplished using the Laplace approximation, which allows integrating out the weighting factors of the multinomial-logit likelihood model. Finally, the experiments over the NESARC database show that our model properly captures some of the hidden causes that model suicide attempts. 1</p><p>3 0.095116474 <a title="136-tfidf-3" href="./nips-2012-Synchronization_can_Control_Regularization_in_Neural_Systems_via_Correlated_Noise_Processes.html">333 nips-2012-Synchronization can Control Regularization in Neural Systems via Correlated Noise Processes</a></p>
<p>Author: Jake Bouvrie, Jean-jeacques Slotine</p><p>Abstract: To learn reliable rules that can generalize to novel situations, the brain must be capable of imposing some form of regularization. Here we suggest, through theoretical and computational arguments, that the combination of noise with synchronization provides a plausible mechanism for regularization in the nervous system. The functional role of regularization is considered in a general context in which coupled computational systems receive inputs corrupted by correlated noise. Noise on the inputs is shown to impose regularization, and when synchronization upstream induces time-varying correlations across noise variables, the degree of regularization can be calibrated over time. The resulting qualitative behavior matches experimental data from visual cortex. 1</p><p>4 0.07675112 <a title="136-tfidf-4" href="./nips-2012-The_variational_hierarchical_EM_algorithm_for_clustering_hidden_Markov_models.html">342 nips-2012-The variational hierarchical EM algorithm for clustering hidden Markov models</a></p>
<p>Author: Emanuele Coviello, Gert R. Lanckriet, Antoni B. Chan</p><p>Abstract: In this paper, we derive a novel algorithm to cluster hidden Markov models (HMMs) according to their probability distributions. We propose a variational hierarchical EM algorithm that i) clusters a given collection of HMMs into groups of HMMs that are similar, in terms of the distributions they represent, and ii) characterizes each group by a “cluster center”, i.e., a novel HMM that is representative for the group. We illustrate the beneﬁts of the proposed algorithm on hierarchical clustering of motion capture sequences as well as on automatic music tagging. 1</p><p>5 0.073394224 <a title="136-tfidf-5" href="./nips-2012-A_Divide-and-Conquer_Method_for_Sparse_Inverse_Covariance_Estimation.html">7 nips-2012-A Divide-and-Conquer Method for Sparse Inverse Covariance Estimation</a></p>
<p>Author: Cho-jui Hsieh, Arindam Banerjee, Inderjit S. Dhillon, Pradeep K. Ravikumar</p><p>Abstract: We consider the composite log-determinant optimization problem, arising from the 1 regularized Gaussian maximum likelihood estimator of a sparse inverse covariance matrix, in a high-dimensional setting with a very large number of variables. Recent work has shown this estimator to have strong statistical guarantees in recovering the true structure of the sparse inverse covariance matrix, or alternatively the underlying graph structure of the corresponding Gaussian Markov Random Field, even in very high-dimensional regimes with a limited number of samples. In this paper, we are concerned with the computational cost in solving the above optimization problem. Our proposed algorithm partitions the problem into smaller sub-problems, and uses the solutions of the sub-problems to build a good approximation for the original problem. Our key idea for the divide step to obtain a sub-problem partition is as follows: we ﬁrst derive a tractable bound on the quality of the approximate solution obtained from solving the corresponding sub-divided problems. Based on this bound, we propose a clustering algorithm that attempts to minimize this bound, in order to ﬁnd effective partitions of the variables. For the conquer step, we use the approximate solution, i.e., solution resulting from solving the sub-problems, as an initial point to solve the original problem, and thereby achieve a much faster computational procedure. 1</p><p>6 0.07171382 <a title="136-tfidf-6" href="./nips-2012-Fully_Bayesian_inference_for_neural_models_with_negative-binomial_spiking.html">138 nips-2012-Fully Bayesian inference for neural models with negative-binomial spiking</a></p>
<p>7 0.063479103 <a title="136-tfidf-7" href="./nips-2012-Ancestor_Sampling_for_Particle_Gibbs.html">41 nips-2012-Ancestor Sampling for Particle Gibbs</a></p>
<p>8 0.060286243 <a title="136-tfidf-8" href="./nips-2012-Active_Comparison_of_Prediction_Models.html">32 nips-2012-Active Comparison of Prediction Models</a></p>
<p>9 0.058517434 <a title="136-tfidf-9" href="./nips-2012-Bayesian_models_for_Large-scale_Hierarchical_Classification.html">58 nips-2012-Bayesian models for Large-scale Hierarchical Classification</a></p>
<p>10 0.055262335 <a title="136-tfidf-10" href="./nips-2012-Fast_Bayesian_Inference_for_Non-Conjugate_Gaussian_Process_Regression.html">127 nips-2012-Fast Bayesian Inference for Non-Conjugate Gaussian Process Regression</a></p>
<p>11 0.049171153 <a title="136-tfidf-11" href="./nips-2012-Training_sparse_natural_image_models_with_a_fast_Gibbs_sampler_of_an_extended_state_space.html">349 nips-2012-Training sparse natural image models with a fast Gibbs sampler of an extended state space</a></p>
<p>12 0.048698403 <a title="136-tfidf-12" href="./nips-2012-A_lattice_filter_model_of_the_visual_pathway.html">23 nips-2012-A lattice filter model of the visual pathway</a></p>
<p>13 0.046947319 <a title="136-tfidf-13" href="./nips-2012-Continuous_Relaxations_for_Discrete_Hamiltonian_Monte_Carlo.html">82 nips-2012-Continuous Relaxations for Discrete Hamiltonian Monte Carlo</a></p>
<p>14 0.045606032 <a title="136-tfidf-14" href="./nips-2012-Scalable_nonconvex_inexact_proximal_splitting.html">300 nips-2012-Scalable nonconvex inexact proximal splitting</a></p>
<p>15 0.04413899 <a title="136-tfidf-15" href="./nips-2012-Optimal_Regularized_Dual_Averaging_Methods_for_Stochastic_Optimization.html">263 nips-2012-Optimal Regularized Dual Averaging Methods for Stochastic Optimization</a></p>
<p>16 0.04392435 <a title="136-tfidf-16" href="./nips-2012-Causal_discovery_with_scale-mixture_model_for_spatiotemporal_variance_dependencies.html">66 nips-2012-Causal discovery with scale-mixture model for spatiotemporal variance dependencies</a></p>
<p>17 0.043379776 <a title="136-tfidf-17" href="./nips-2012-Efficient_high_dimensional_maximum_entropy_modeling_via_symmetric_partition_functions.html">115 nips-2012-Efficient high dimensional maximum entropy modeling via symmetric partition functions</a></p>
<p>18 0.040839992 <a title="136-tfidf-18" href="./nips-2012-How_They_Vote%3A_Issue-Adjusted_Models_of_Legislative_Behavior.html">154 nips-2012-How They Vote: Issue-Adjusted Models of Legislative Behavior</a></p>
<p>19 0.040366586 <a title="136-tfidf-19" href="./nips-2012-Efficient_Sampling_for_Bipartite_Matching_Problems.html">111 nips-2012-Efficient Sampling for Bipartite Matching Problems</a></p>
<p>20 0.039819319 <a title="136-tfidf-20" href="./nips-2012-Relax_and_Randomize_%3A_From_Value_to_Algorithms.html">293 nips-2012-Relax and Randomize : From Value to Algorithms</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.101), (1, 0.005), (2, -0.011), (3, -0.014), (4, -0.008), (5, -0.056), (6, 0.007), (7, 0.018), (8, 0.042), (9, -0.0), (10, 0.008), (11, -0.025), (12, 0.039), (13, 0.052), (14, -0.029), (15, -0.011), (16, -0.012), (17, -0.028), (18, -0.005), (19, 0.0), (20, 0.06), (21, 0.051), (22, -0.027), (23, 0.017), (24, 0.038), (25, 0.034), (26, -0.044), (27, -0.013), (28, 0.007), (29, -0.052), (30, -0.025), (31, 0.025), (32, 0.022), (33, 0.034), (34, -0.076), (35, 0.045), (36, -0.036), (37, -0.044), (38, 0.005), (39, 0.049), (40, -0.077), (41, 0.074), (42, -0.019), (43, 0.068), (44, 0.115), (45, -0.052), (46, -0.038), (47, 0.01), (48, -0.023), (49, -0.178)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.86624283 <a title="136-lsi-1" href="./nips-2012-Forward-Backward_Activation_Algorithm_for_Hierarchical_Hidden_Markov_Models.html">136 nips-2012-Forward-Backward Activation Algorithm for Hierarchical Hidden Markov Models</a></p>
<p>Author: Kei Wakabayashi, Takao Miura</p><p>Abstract: Hierarchical Hidden Markov Models (HHMMs) are sophisticated stochastic models that enable us to capture a hierarchical context characterization of sequence data. However, existing HHMM parameter estimation methods require large computations of time complexity O(T N 2D ) at least for model inference, where D is the depth of the hierarchy, N is the number of states in each level, and T is the sequence length. In this paper, we propose a new inference method of HHMMs for which the time complexity is O(T N D+1 ). A key idea of our algorithm is application of the forward-backward algorithm to state activation probabilities. The notion of a state activation, which offers a simple formalization of the hierarchical transition behavior of HHMMs, enables us to conduct model inference efﬁciently. We present some experiments to demonstrate that our proposed method works more efﬁciently to estimate HHMM parameters than do some existing methods such as the ﬂattening method and Gibbs sampling method. 1</p><p>2 0.63170022 <a title="136-lsi-2" href="./nips-2012-Bayesian_Nonparametric_Modeling_of_Suicide_Attempts.html">52 nips-2012-Bayesian Nonparametric Modeling of Suicide Attempts</a></p>
<p>Author: Francisco Ruiz, Isabel Valera, Carlos Blanco, Fernando Pérez-Cruz</p><p>Abstract: The National Epidemiologic Survey on Alcohol and Related Conditions (NESARC) database contains a large amount of information, regarding the way of life, medical conditions, etc., of a representative sample of the U.S. population. In this paper, we are interested in seeking the hidden causes behind the suicide attempts, for which we propose to model the subjects using a nonparametric latent model based on the Indian Buffet Process (IBP). Due to the nature of the data, we need to adapt the observation model for discrete random variables. We propose a generative model in which the observations are drawn from a multinomial-logit distribution given the IBP matrix. The implementation of an efﬁcient Gibbs sampler is accomplished using the Laplace approximation, which allows integrating out the weighting factors of the multinomial-logit likelihood model. Finally, the experiments over the NESARC database show that our model properly captures some of the hidden causes that model suicide attempts. 1</p><p>3 0.55035794 <a title="136-lsi-3" href="./nips-2012-Training_sparse_natural_image_models_with_a_fast_Gibbs_sampler_of_an_extended_state_space.html">349 nips-2012-Training sparse natural image models with a fast Gibbs sampler of an extended state space</a></p>
<p>Author: Lucas Theis, Jascha Sohl-dickstein, Matthias Bethge</p><p>Abstract: We present a new learning strategy based on an efﬁcient blocked Gibbs sampler for sparse overcomplete linear models. Particular emphasis is placed on statistical image modeling, where overcomplete models have played an important role in discovering sparse representations. Our Gibbs sampler is faster than general purpose sampling schemes while also requiring no tuning as it is free of parameters. Using the Gibbs sampler and a persistent variant of expectation maximization, we are able to extract highly sparse distributions over latent sources from data. When applied to natural images, our algorithm learns source distributions which resemble spike-and-slab distributions. We evaluate the likelihood and quantitatively compare the performance of the overcomplete linear model to its complete counterpart as well as a product of experts model, which represents another overcomplete generalization of the complete linear model. In contrast to previous claims, we ﬁnd that overcomplete representations lead to signiﬁcant improvements, but that the overcomplete linear model still underperforms other models. 1</p><p>4 0.48054236 <a title="136-lsi-4" href="./nips-2012-Effective_Split-Merge_Monte_Carlo_Methods_for_Nonparametric_Models_of_Sequential_Data.html">107 nips-2012-Effective Split-Merge Monte Carlo Methods for Nonparametric Models of Sequential Data</a></p>
<p>Author: Michael C. Hughes, Erik B. Sudderth, Emily B. Fox</p><p>Abstract: Applications of Bayesian nonparametric methods require learning and inference algorithms which efﬁciently explore models of unbounded complexity. We develop new Markov chain Monte Carlo methods for the beta process hidden Markov model (BP-HMM), enabling discovery of shared activity patterns in large video and motion capture databases. By introducing split-merge moves based on sequential allocation, we allow large global changes in the shared feature structure. We also develop data-driven reversible jump moves which more reliably discover rare or unique behaviors. Our proposals apply to any choice of conjugate likelihood for observed data, and we show success with multinomial, Gaussian, and autoregressive emission models. Together, these innovations allow tractable analysis of hundreds of time series, where previous inference required clever initialization and lengthy burn-in periods for just six sequences. 1</p><p>5 0.47496212 <a title="136-lsi-5" href="./nips-2012-Unsupervised_Structure_Discovery_for_Semantic_Analysis_of_Audio.html">356 nips-2012-Unsupervised Structure Discovery for Semantic Analysis of Audio</a></p>
<p>Author: Sourish Chaudhuri, Bhiksha Raj</p><p>Abstract: Approaches to audio classiﬁcation and retrieval tasks largely rely on detectionbased discriminative models. We submit that such models make a simplistic assumption in mapping acoustics directly to semantics, whereas the actual process is likely more complex. We present a generative model that maps acoustics in a hierarchical manner to increasingly higher-level semantics. Our model has two layers with the ﬁrst layer modeling generalized sound units with no clear semantic associations, while the second layer models local patterns over these sound units. We evaluate our model on a large-scale retrieval task from TRECVID 2011, and report signiﬁcant improvements over standard baselines. 1</p><p>6 0.46071976 <a title="136-lsi-6" href="./nips-2012-How_They_Vote%3A_Issue-Adjusted_Models_of_Legislative_Behavior.html">154 nips-2012-How They Vote: Issue-Adjusted Models of Legislative Behavior</a></p>
<p>7 0.44964558 <a title="136-lsi-7" href="./nips-2012-Why_MCA%3F_Nonlinear_sparse_coding_with_spike-and-slab_prior_for_neurally_plausible_image_encoding.html">365 nips-2012-Why MCA? Nonlinear sparse coding with spike-and-slab prior for neurally plausible image encoding</a></p>
<p>8 0.44130778 <a title="136-lsi-8" href="./nips-2012-Ancestor_Sampling_for_Particle_Gibbs.html">41 nips-2012-Ancestor Sampling for Particle Gibbs</a></p>
<p>9 0.43910185 <a title="136-lsi-9" href="./nips-2012-Dynamic_Pruning_of_Factor_Graphs_for_Maximum_Marginal_Prediction.html">105 nips-2012-Dynamic Pruning of Factor Graphs for Maximum Marginal Prediction</a></p>
<p>10 0.42395431 <a title="136-lsi-10" href="./nips-2012-Continuous_Relaxations_for_Discrete_Hamiltonian_Monte_Carlo.html">82 nips-2012-Continuous Relaxations for Discrete Hamiltonian Monte Carlo</a></p>
<p>11 0.41767228 <a title="136-lsi-11" href="./nips-2012-Phoneme_Classification_using_Constrained_Variational_Gaussian_Process_Dynamical_System.html">270 nips-2012-Phoneme Classification using Constrained Variational Gaussian Process Dynamical System</a></p>
<p>12 0.41183689 <a title="136-lsi-12" href="./nips-2012-The_variational_hierarchical_EM_algorithm_for_clustering_hidden_Markov_models.html">342 nips-2012-The variational hierarchical EM algorithm for clustering hidden Markov models</a></p>
<p>13 0.40545851 <a title="136-lsi-13" href="./nips-2012-Efficient_high_dimensional_maximum_entropy_modeling_via_symmetric_partition_functions.html">115 nips-2012-Efficient high dimensional maximum entropy modeling via symmetric partition functions</a></p>
<p>14 0.40443319 <a title="136-lsi-14" href="./nips-2012-Bayesian_models_for_Large-scale_Hierarchical_Classification.html">58 nips-2012-Bayesian models for Large-scale Hierarchical Classification</a></p>
<p>15 0.40423456 <a title="136-lsi-15" href="./nips-2012-Bayesian_Pedigree_Analysis_using_Measure_Factorization.html">53 nips-2012-Bayesian Pedigree Analysis using Measure Factorization</a></p>
<p>16 0.40317073 <a title="136-lsi-16" href="./nips-2012-Assessing_Blinding_in_Clinical_Trials.html">46 nips-2012-Assessing Blinding in Clinical Trials</a></p>
<p>17 0.40074721 <a title="136-lsi-17" href="./nips-2012-The_Time-Marginalized_Coalescent_Prior_for_Hierarchical_Clustering.html">339 nips-2012-The Time-Marginalized Coalescent Prior for Hierarchical Clustering</a></p>
<p>18 0.39949965 <a title="136-lsi-18" href="./nips-2012-Causal_discovery_with_scale-mixture_model_for_spatiotemporal_variance_dependencies.html">66 nips-2012-Causal discovery with scale-mixture model for spatiotemporal variance dependencies</a></p>
<p>19 0.38507023 <a title="136-lsi-19" href="./nips-2012-Learning_Partially_Observable_Models_Using_Temporally_Abstract_Decision_Trees.html">183 nips-2012-Learning Partially Observable Models Using Temporally Abstract Decision Trees</a></p>
<p>20 0.38454333 <a title="136-lsi-20" href="./nips-2012-Monte_Carlo_Methods_for_Maximum_Margin_Supervised_Topic_Models.html">220 nips-2012-Monte Carlo Methods for Maximum Margin Supervised Topic Models</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(11, 0.044), (47, 0.09), (57, 0.434), (70, 0.054), (85, 0.107), (94, 0.072), (99, 0.073)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.59949595 <a title="136-lda-1" href="./nips-2012-Forward-Backward_Activation_Algorithm_for_Hierarchical_Hidden_Markov_Models.html">136 nips-2012-Forward-Backward Activation Algorithm for Hierarchical Hidden Markov Models</a></p>
<p>Author: Kei Wakabayashi, Takao Miura</p><p>Abstract: Hierarchical Hidden Markov Models (HHMMs) are sophisticated stochastic models that enable us to capture a hierarchical context characterization of sequence data. However, existing HHMM parameter estimation methods require large computations of time complexity O(T N 2D ) at least for model inference, where D is the depth of the hierarchy, N is the number of states in each level, and T is the sequence length. In this paper, we propose a new inference method of HHMMs for which the time complexity is O(T N D+1 ). A key idea of our algorithm is application of the forward-backward algorithm to state activation probabilities. The notion of a state activation, which offers a simple formalization of the hierarchical transition behavior of HHMMs, enables us to conduct model inference efﬁciently. We present some experiments to demonstrate that our proposed method works more efﬁciently to estimate HHMM parameters than do some existing methods such as the ﬂattening method and Gibbs sampling method. 1</p><p>2 0.45639655 <a title="136-lda-2" href="./nips-2012-Kernel_Latent_SVM_for_Visual_Recognition.html">168 nips-2012-Kernel Latent SVM for Visual Recognition</a></p>
<p>Author: Weilong Yang, Yang Wang, Arash Vahdat, Greg Mori</p><p>Abstract: Latent SVMs (LSVMs) are a class of powerful tools that have been successfully applied to many applications in computer vision. However, a limitation of LSVMs is that they rely on linear models. For many computer vision tasks, linear models are suboptimal and nonlinear models learned with kernels typically perform much better. Therefore it is desirable to develop the kernel version of LSVM. In this paper, we propose kernel latent SVM (KLSVM) – a new learning framework that combines latent SVMs and kernel methods. We develop an iterative training algorithm to learn the model parameters. We demonstrate the effectiveness of KLSVM using three different applications in visual recognition. Our KLSVM formulation is very general and can be applied to solve a wide range of applications in computer vision and machine learning. 1</p><p>3 0.4393076 <a title="136-lda-3" href="./nips-2012-Efficient_Bayes-Adaptive_Reinforcement_Learning_using_Sample-Based_Search.html">108 nips-2012-Efficient Bayes-Adaptive Reinforcement Learning using Sample-Based Search</a></p>
<p>Author: Arthur Guez, David Silver, Peter Dayan</p><p>Abstract: Bayesian model-based reinforcement learning is a formally elegant approach to learning optimal behaviour under model uncertainty, trading off exploration and exploitation in an ideal way. Unfortunately, ﬁnding the resulting Bayes-optimal policies is notoriously taxing, since the search space becomes enormous. In this paper we introduce a tractable, sample-based method for approximate Bayesoptimal planning which exploits Monte-Carlo tree search. Our approach outperformed prior Bayesian model-based RL algorithms by a signiﬁcant margin on several well-known benchmark problems – because it avoids expensive applications of Bayes rule within the search tree by lazily sampling models from the current beliefs. We illustrate the advantages of our approach by showing it working in an inﬁnite state space domain which is qualitatively out of reach of almost all previous work in Bayesian exploration. 1</p><p>4 0.41923749 <a title="136-lda-4" href="./nips-2012-Active_Learning_of_Multi-Index_Function_Models.html">34 nips-2012-Active Learning of Multi-Index Function Models</a></p>
<p>Author: Tyagi Hemant, Volkan Cevher</p><p>Abstract: We consider the problem of actively learning multi-index functions of the form k f (x) = g(Ax) = i=1 gi (aT x) from point evaluations of f . We assume that i the function f is deﬁned on an 2 -ball in Rd , g is twice continuously differentiable almost everywhere, and A ∈ Rk×d is a rank k matrix, where k d. We propose a randomized, active sampling scheme for estimating such functions with uniform approximation guarantees. Our theoretical developments leverage recent techniques from low rank matrix recovery, which enables us to derive an estimator of the function f along with sample complexity bounds. We also characterize the noise robustness of the scheme, and provide empirical evidence that the highdimensional scaling of our sample complexity bounds are quite accurate. 1</p><p>5 0.38009256 <a title="136-lda-5" href="./nips-2012-On_the_Sample_Complexity_of_Robust_PCA.html">254 nips-2012-On the Sample Complexity of Robust PCA</a></p>
<p>Author: Matthew Coudron, Gilad Lerman</p><p>Abstract: We estimate the rate of convergence and sample complexity of a recent robust estimator for a generalized version of the inverse covariance matrix. This estimator is used in a convex algorithm for robust subspace recovery (i.e., robust PCA). Our model assumes a sub-Gaussian underlying distribution and an i.i.d. sample from it. Our main result shows with high probability that the norm of the difference between the generalized inverse covariance of the underlying distribution and its estimator from an i.i.d. sample of size N is of order O(N −0.5+ ) for arbitrarily small > 0 (affecting the probabilistic estimate); this rate of convergence is close to the one of direct covariance estimation, i.e., O(N −0.5 ). Our precise probabilistic estimate implies for some natural settings that the sample complexity of the generalized inverse covariance estimation when using the Frobenius norm is O(D2+δ ) for arbitrarily small δ > 0 (whereas the sample complexity of direct covariance estimation with Frobenius norm is O(D2 )). These results provide similar rates of convergence and sample complexity for the corresponding robust subspace recovery algorithm. To the best of our knowledge, this is the only work analyzing the sample complexity of any robust PCA algorithm. 1</p><p>6 0.37809214 <a title="136-lda-6" href="./nips-2012-Expectation_Propagation_in_Gaussian_Process_Dynamical_Systems.html">121 nips-2012-Expectation Propagation in Gaussian Process Dynamical Systems</a></p>
<p>7 0.37692913 <a title="136-lda-7" href="./nips-2012-Learning_from_the_Wisdom_of_Crowds_by_Minimax_Entropy.html">189 nips-2012-Learning from the Wisdom of Crowds by Minimax Entropy</a></p>
<p>8 0.376638 <a title="136-lda-8" href="./nips-2012-Multiresolution_Gaussian_Processes.html">233 nips-2012-Multiresolution Gaussian Processes</a></p>
<p>9 0.37459385 <a title="136-lda-9" href="./nips-2012-Ensemble_weighted_kernel_estimators_for_multivariate_entropy_estimation.html">117 nips-2012-Ensemble weighted kernel estimators for multivariate entropy estimation</a></p>
<p>10 0.37414566 <a title="136-lda-10" href="./nips-2012-Bayesian_nonparametric_models_for_ranked_data.html">60 nips-2012-Bayesian nonparametric models for ranked data</a></p>
<p>11 0.37409282 <a title="136-lda-11" href="./nips-2012-Bayesian_active_learning_with_localized_priors_for_fast_receptive_field_characterization.html">56 nips-2012-Bayesian active learning with localized priors for fast receptive field characterization</a></p>
<p>12 0.37310022 <a title="136-lda-12" href="./nips-2012-The_Time-Marginalized_Coalescent_Prior_for_Hierarchical_Clustering.html">339 nips-2012-The Time-Marginalized Coalescent Prior for Hierarchical Clustering</a></p>
<p>13 0.37279496 <a title="136-lda-13" href="./nips-2012-Spectral_learning_of_linear_dynamics_from_generalised-linear_observations_with_application_to_neural_population_data.html">321 nips-2012-Spectral learning of linear dynamics from generalised-linear observations with application to neural population data</a></p>
<p>14 0.37224695 <a title="136-lda-14" href="./nips-2012-Human_memory_search_as_a_random_walk_in_a_semantic_network.html">155 nips-2012-Human memory search as a random walk in a semantic network</a></p>
<p>15 0.37210283 <a title="136-lda-15" href="./nips-2012-CPRL_--_An_Extension_of_Compressive_Sensing_to_the_Phase_Retrieval_Problem.html">63 nips-2012-CPRL -- An Extension of Compressive Sensing to the Phase Retrieval Problem</a></p>
<p>16 0.37192246 <a title="136-lda-16" href="./nips-2012-How_Prior_Probability_Influences_Decision_Making%3A_A_Unifying_Probabilistic_Model.html">153 nips-2012-How Prior Probability Influences Decision Making: A Unifying Probabilistic Model</a></p>
<p>17 0.37164429 <a title="136-lda-17" href="./nips-2012-Locating_Changes_in_Highly_Dependent_Data_with_Unknown_Number_of_Change_Points.html">203 nips-2012-Locating Changes in Highly Dependent Data with Unknown Number of Change Points</a></p>
<p>18 0.37019509 <a title="136-lda-18" href="./nips-2012-Coding_efficiency_and_detectability_of_rate_fluctuations_with_non-Poisson_neuronal_firing.html">73 nips-2012-Coding efficiency and detectability of rate fluctuations with non-Poisson neuronal firing</a></p>
<p>19 0.36981148 <a title="136-lda-19" href="./nips-2012-Efficient_Spike-Coding_with_Multiplicative_Adaptation_in_a_Spike_Response_Model.html">112 nips-2012-Efficient Spike-Coding with Multiplicative Adaptation in a Spike Response Model</a></p>
<p>20 0.36899728 <a title="136-lda-20" href="./nips-2012-The_variational_hierarchical_EM_algorithm_for_clustering_hidden_Markov_models.html">342 nips-2012-The variational hierarchical EM algorithm for clustering hidden Markov models</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
