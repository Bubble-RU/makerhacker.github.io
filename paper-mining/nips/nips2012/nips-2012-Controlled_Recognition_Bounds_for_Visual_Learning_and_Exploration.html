<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>83 nips-2012-Controlled Recognition Bounds for Visual Learning and Exploration</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-83" href="#">nips2012-83</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>83 nips-2012-Controlled Recognition Bounds for Visual Learning and Exploration</h1>
<br/><p>Source: <a title="nips-2012-83-pdf" href="http://papers.nips.cc/paper/4594-controlled-recognition-bounds-for-visual-learning-and-exploration.pdf">pdf</a></p><p>Author: Vasiliy Karasev, Alessandro Chiuso, Stefano Soatto</p><p>Abstract: We describe the tradeoff between the performance in a visual recognition problem and the control authority that the agent can exercise on the sensing process. We focus on the problem of “visual search” of an object in an otherwise known and static scene, propose a measure of control authority, and relate it to the expected risk and its proxy (conditional entropy of the posterior density). We show this analytically, as well as empirically by simulation using the simplest known model that captures the phenomenology of image formation, including scaling and occlusions. We show that a “passive” agent given a training set can provide no guarantees on performance beyond what is afforded by the priors, and that an “omnipotent” agent, capable of inﬁnite control authority, can achieve arbitrarily good performance (asymptotically). In between these limiting cases, the tradeoff can be characterized empirically. 1</p><p>Reference: <a title="nips-2012-83-reference" href="../nips2012_reference/nips-2012-Controlled_Recognition_Bounds_for_Visual_Learning_and_Exploration_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 We focus on the problem of “visual search” of an object in an otherwise known and static scene, propose a measure of control authority, and relate it to the expected risk and its proxy (conditional entropy of the posterior density). [sent-2, score-0.683]
</p><p>2 We show that a “passive” agent given a training set can provide no guarantees on performance beyond what is afforded by the priors, and that an “omnipotent” agent, capable of inﬁnite control authority, can achieve arbitrarily good performance (asymptotically). [sent-4, score-0.376]
</p><p>3 1  Introduction  We are interested in visual learning for recognition of objects and scenes embedded in physical space. [sent-6, score-0.235]
</p><p>4 Rather than using datasets consisting of collections of isolated snapshots, however, we wish to actively control the sensing process during learning. [sent-7, score-0.296]
</p><p>5 Visual learning is thus a process of discovery, literally uncovering occluded portions of an object or scene, and viewing it from close enough that all structural details are revealed. [sent-9, score-0.306]
</p><p>6 1 We call this phase of learning exploration or mapping, accomplished by actively controlling the sensor motion within a scene, or by manipulating an object so as to discover all aspects. [sent-10, score-0.445]
</p><p>7 2 Once exploration has been performed, one has a model (or “map” or “representation”) of the scene or object of interest. [sent-11, score-0.505]
</p><p>8 One can then attempt to detect, localize or recognize a particular object or scene, or a class of them, provided intra-class variability has been exposed during exploration. [sent-12, score-0.27]
</p><p>9 This phase can yield localization – where one wishes to recognize a portion of a mapped scene and, as a byproduct, infer the pose relative to the map – or search where a particular object mapped during the exploration phase is detected and localized within an otherwise known scene. [sent-13, score-0.684]
</p><p>10 2 Note that we are not suggesting that one should construct a three-dimensional (3-D) model of an object or a scene for recognition, as opposed to using collections of 2-D images. [sent-16, score-0.418]
</p><p>11 The multiple images must portray the same scene or object, lest one cannot attribute the variability in the data to nuisance factors as opposed to intrinsic variability of the object of interest. [sent-19, score-0.493]
</p><p>12 1  where a known object is sought in an unknown map, exploration and search have to be conducted simultaneously. [sent-22, score-0.459]
</p><p>13 Within this scenario, exploration and search can be framed as optimal control and optimal stopping time problems. [sent-23, score-0.358]
</p><p>14 In this manuscript we consider the problem of detecting and estimating discrete parameters of an unknown object in a known environment. [sent-26, score-0.285]
</p><p>15 Discuss the tradeoff between performance in a visual decision task and the control authority that the explorer possesses. [sent-31, score-0.85]
</p><p>16 This tradeoff is akin the tradeoff between rate and distortion in a communication system, but it pertains to decision and control tasks, as opposed to the transmission of data. [sent-32, score-0.349]
</p><p>17 We characterize this tradeoff for the simple case of a static environment, where control authority relates to reachability and energy. [sent-33, score-0.62]
</p><p>18 Discuss and test algorithms for visual search based on the maximization of the conditional entropy of future measurements and the proxies of this quantity. [sent-35, score-0.452]
</p><p>19 These algorithms can be used to locate an unknown object in unknown position of a known environment, or to perform change detection in an otherwise known map, for the purpose of updating it. [sent-36, score-0.331]
</p><p>20 1  Related prior work  Active search and recognition of objects in the scene has been one of the mainstays of Active Perception in the eighties [2, 3], and has recently resurged (see [4] and references therein). [sent-40, score-0.39]
</p><p>21 Active recognition using next-best-view generation and object appearance is discussed in [6] where authors use PCA to embed object images in a linear, low dimensional space. [sent-42, score-0.558]
</p><p>22 More recently, information driven sensor control for object recognition was used in [7, 8, 9], who deal with visual and sonar sensors, but take features (e. [sent-44, score-0.639]
</p><p>23 A utility function that accounts for occlusions, viewing angle, and distance to the object is proposed in [10] who aim to actively learn object classiﬁers during the training stage. [sent-47, score-0.548]
</p><p>24 Exploration and learning of 3D object surface models by robotic manipulation is discussed in [11]. [sent-48, score-0.282]
</p><p>25 The case of object localization (and tracking if object is moving) is discussed in [12]; information-theoretic approach for solving this problem using a sensor network is described in [13]. [sent-49, score-0.564]
</p><p>26 With regards to models, our work is different in several aspects: instead of choosing the next best view on a sphere centered at the object, we model a cluttered environment where the object of interest occupies a negligible volume and is therefore fully occluded when viewed from most locations. [sent-52, score-0.419]
</p><p>27 Third, given the signiﬁcance of quantization-scale and occlusions in a visual recognition task, we model the sensing process such that it accounts for both. [sent-54, score-0.246]
</p><p>28 We use the problem of visual search (ﬁnding a not previously seen object in a scene) as a motivation. [sent-64, score-0.407]
</p><p>29 Constraints on the controller enter through f ; photometric nuisances, quantization and occlusions enter through the measurement map h. [sent-67, score-0.297]
</p><p>30 1  Signal models  The simplest model that includes both scaling and occlusion nuisances is the “cartoon ﬂatland”, where a bounded subset of R2 is populated by self-luminous line segments, corresponding to clutter objects. [sent-70, score-0.401]
</p><p>31 The number of objects in the scene C is the clutter density parameter that can possibly grow to be inﬁnite in the limit. [sent-75, score-0.499]
</p><p>32 Each object is described by its center (ck ), length (lk ), binary orientation (ok ), and radiance function supported on the segment ⇢k . [sent-76, score-0.358]
</p><p>33 R+ ]  (3)  An agent can move continuously throughout the search domain. [sent-78, score-0.249]
</p><p>34 We take the state gt 2 R2 to be its current position, ut 2 R2 the currently exerted move, and assume trivial dynamics: gt+1 = gt + ut . [sent-79, score-0.942]
</p><p>35 More complex agents where gt 2 SE(3) can be incorporated without conceptual difﬁculties. [sent-80, score-0.234]
</p><p>36 The measurement model is that of an omnidirectional m-pixel camera, with each entry of yt 2 Rm in (2) given by: Z (i+ 1 ) 2⇡ Z 1 2 m yt (i) = ⇢`(✓,gt ) (z)d✓d⌧ + nt (i), with z = (⌧ cos(✓), ⌧ sin(✓)) (4) (i  1 2⇡ 2) m  0  where is the angle subtended by each pixel. [sent-81, score-0.666]
</p><p>37 The index of the object (clutter or object of interest) that contributes to the image is denoted by `(✓, gt ) and is deﬁned as: ✓ ◆ n o l k lk ok `(✓, gt ) = arg min k 9(sk , k ) 2 [ , ] ⇥ R+ s. [sent-84, score-1.128]
</p><p>38 ck , lk , and ok ˆ are k-th segment center, length, and orientation. [sent-87, score-0.251]
</p><p>39 In order to design control sequences to minimize risk, we need to evaluate the uncertainty of future measurements, those we have not yet measured, which are a function of the control action to be taken. [sent-95, score-0.4]
</p><p>40 3  We ﬁrst describe the general case of visual exploration where the environment is unknown. [sent-97, score-0.287]
</p><p>41 The density can be decomposed as a product of likelihoods since knowledge of environment (⇠) and location (gt ) is sufﬁcient to predict measurement yt up to Gaussian noise. [sent-107, score-0.554]
</p><p>42 In this paper we focus on visual search of a particular object in an otherwise known environment, so marginalization is only performed with respect to a single object in the environment, x, whose parameters are discrete, but otherwise analogous to (6): p(x) = U {0, . [sent-109, score-0.677]
</p><p>43 , |X | object with parameters (ci , li , oi , ⇢i ) and write ⇠i = (xi , 1 , . [sent-118, score-0.239]
</p><p>44 , C ) to denote the scene with known clutter objects 1 , . [sent-121, score-0.448]
</p><p>45 This depends upon whether ut is sufﬁciently exciting, a “richness” condition that has been extensively used in the identiﬁcation and adaptive control literature [17, 18], which guarantees that the state trajectory g t explores the space of interest. [sent-130, score-0.421]
</p><p>46 Under this scenario it is easy to prove that, averaging over the possible scenes and initial agent locations, the probability of error approaches chance (i. [sent-134, score-0.225]
</p><p>47 that given by the prior distribution) as clutter density and/or the environment volume increase. [sent-136, score-0.395]
</p><p>48 Full control on g t : if the control action can take the “omnipotent agent” anywhere, and inﬁnite time is available to collect measurements, then the conditional entropy H(x|y t ) decreases asymptotically to zero thus providing arbitrarily good recognition rate in the limit. [sent-138, score-0.659]
</p><p>49 yt+T )  4  In general, there is a tradeoff between the ability to gather new information through suitable control actions, which we name “control authority”, and the recognition rate. [sent-151, score-0.294]
</p><p>50 In the sequel we shall propose a measure for the “control authority” over the sensing process; later in the paper we will consider conditional entropy as a proxy (upper bound) on probability of error and evaluate empirically how control authority affects the conditional entropy decrease. [sent-152, score-1.092]
</p><p>51 1  Control authority  Unlike the passive case, in the controlled scenario time plays an important role. [sent-154, score-0.446]
</p><p>52 If objects in the scene move, this can be done only at an expense in energy, and achieving asymptotic performance may not be possible under control limitations. [sent-157, score-0.438]
</p><p>53 Control authority depends on (i) the controller u, as measured for instance by a norm5 kuk : U [0, T ] ! [sent-160, score-0.501]
</p><p>54 We propose to measure control authority in the following manner: associate to each pair of locations in the state space (go , gf ) and a given time horizon T the cost kuk required to move from go at time t = 0 to gf at time t = T along a minimum cost path i. [sent-162, score-1.218]
</p><p>55 J⇠ (go , gf , T ) = inf kuk (13) u : gu (0)=go ,gu (T )=gf ⇠  where gu (t) is the state vector at time t under control u. [sent-165, score-0.503]
</p><p>56 If gf is not reachable from go in time T we set J⇠ (go , gf , T ) = 1. [sent-166, score-0.662]
</p><p>57 This will depend on the dynamical properties of the agent g = f (g, u) (or ˙ gt+1 = f (gt , ut ) for discrete time) as well as on the scene ⇠ where the agent has to navigate through while avoiding obstacles. [sent-167, score-0.74]
</p><p>58 The control authority (CA) can be measured via the volume of the reachable space for ﬁxed control cost, and will be a function of the initial conﬁguration g0 and of the scene ⇠, i. [sent-168, score-1.095]
</p><p>59 CA(k, go , ⇠) = V ol{gf : J⇠ (g0 , gf , k)  1} (14) If instead one is interested in average performance (e. [sent-171, score-0.319]
</p><p>60 the possible scene distributions with ﬁxed clutter density), a reasonable measure is the average of smallest volume (as g0 varies) of the reachable space with a unit cost input ⇥ ⇤ . [sent-176, score-0.546]
</p><p>61 CA(k) = E⇠ inf CA(k, go , ⇠) (15) go  If planning on an indeﬁnitely long time horizon is allowed, then one would minimize J(go , gf , T ) over time T : . [sent-177, score-0.515]
</p><p>62 J(go , gf ) = inf J(go , gf , T ) (16) T  with  0  . [sent-178, score-0.435]
</p><p>63 CA1 = inf (V ol{gf : J(go , gf )  1}) go  (17)  The ﬁgures CA(k, go , ⇠) in (14), CA(k) and CA1 in (17) are proxies of the exploration ability which, in turn, is related to the ability to gather new information on the task at hand. [sent-179, score-0.588]
</p><p>64 The data acquisition process can be regarded as an experiment design problem [16] where the choice of the control signal guides the experiment. [sent-180, score-0.216]
</p><p>65 More control authority corresponds to more freedom in the choice of which samples one is taking (from which location and at which scale). [sent-183, score-0.603]
</p><p>66 Therefore the risk, considered against CA(k) in (15), CA(k, go , ⇠) in (14) or CA1 in (17) will follow a surface that depends on the clutter: For any given clutter (or clutter density), the risk will be a monotonically non-increasing function of control authority CA(k). [sent-184, score-1.117]
</p><p>67 As is standard, we can settle for the greedy k = 1 case: Z u⇤ = arg min p(yt+1 |y t , ut ) 1 max p(xi |y t , yt+1 , ut ) dyt+1 t ut  i  (19)  but it is still often impractical. [sent-189, score-0.747]
</p><p>68 H(yt+1 |y t , ut ) is the entropy of a Gaussian mixture distribution which can be easily approximated by Monte Carlo, and for which both lower [20] and upper bounds [21] are known. [sent-191, score-0.449]
</p><p>69 is unable to traverse the environment in one step, optimization is taken over a small ball in R2 centered at current location gt . [sent-194, score-0.426]
</p><p>70 Since this location is typically not reachable in a single step, one can adopt a “stubborn” strategy that follows the planned path to the target location before choosing next action, and an “indecisive” – that replans as soon as additional information becomes available as a consequence of motion. [sent-197, score-0.336]
</p><p>71 We demonstrate the characteristics of conditional entropy as a criterion for planning in Fig. [sent-198, score-0.255]
</p><p>72 To test average performance of these strategies, we consider search in 100 environment instances, each containing 40 known clutter objects and one unknown object. [sent-204, score-0.521]
</p><p>73 Clutter objects are sampled from the continuous prior distribution (6) and unknown object is chosen from the prior (10) discretized to |X | ⇡ 9000. [sent-205, score-0.394]
</p><p>74 Agent’s sensor has m = 30 pixels, with additive noise set to half of the difference between object colors. [sent-206, score-0.325]
</p><p>75 Search is terminated once residual entropy falls below a threshold value: H(x|y t ) < 0. [sent-208, score-0.225]
</p><p>76 In all cases, the agent is at the bottom of the environment, and a small unknown object is at the top. [sent-212, score-0.447]
</p><p>77 The agent has made one measurement (y1 ) and must now determine the best location to visit. [sent-213, score-0.279]
</p><p>78 The left three panels demonstrate a case of scaling: object is seen, but due to noise and quantization its parameters are uncertain. [sent-214, score-0.269]
</p><p>79 Agent gains information if putative object location (top) is approached. [sent-215, score-0.283]
</p><p>80 Middle three panels demonstrate partial occlusion: a part of the object has been seen, and there is now a region (bottom right corner) that is uninformative – measurements taken there are predictable. [sent-216, score-0.282]
</p><p>81 The object has not been seen (due to occluder in the middle of the environment) and the best action is to visit new area. [sent-218, score-0.271]
</p><p>82 Objects are colored according to their radiance and the unknown object is shown as a thick line. [sent-223, score-0.354]
</p><p>83 we deﬁne as the excess fraction of the minimum energy path to the center of the unknown object (c0 ) . [sent-230, score-0.38]
</p><p>84 Because it is not always necessary to reach the object to recognize it (viewing it closely from multiple viewpoints may be sufﬁcient), this quantity is an approximation to minimum search effort. [sent-232, score-0.357]
</p><p>85 “Random-walk” strategy was unable to ﬁnd the object unless it was visible initially or became visible by chance. [sent-241, score-0.268]
</p><p>86 We next  indecisive stubborn  Average search duration max-ent max-var max-p(x|y t ) 28. [sent-242, score-0.407]
</p><p>87 prior entropy  environment volume reachable volume without clutter  Figure 4: Left: Control authority. [sent-258, score-0.691]
</p><p>88 Right: Residual entropy H(x|y t ), as a function of control authority and clutter density. [sent-261, score-0.927]
</p><p>89 Lines correspond to residual entropy for a given control authority averaged over the test suite; markers – to residual entropy on a speciﬁc problem instance. [sent-263, score-1.009]
</p><p>90 For certain scenes, agent is unable to signiﬁcantly reduce entropy because the object never becomes unoccluded (once object is seen, there is a sharp drop in residual entropy, as shown in Fig. [sent-264, score-0.894]
</p><p>91 empirically evaluated explorer’s exploration ability under ﬁnite control authority. [sent-266, score-0.301]
</p><p>92 Reachable volume was computed by Monte Carlo sampling, following (14)-(15) for several clutter density values. [sent-267, score-0.276]
</p><p>93 For each clutter density, we generated 40 scene instances and tested ”indecisive” max-entropy strategy with respect to control authority. [sent-268, score-0.557]
</p><p>94 We have then related the amount of “control authority” the agent can exercise during the data acquisition process with the performance in the visual search task. [sent-273, score-0.393]
</p><p>95 In the limit of inﬁnite control authority, arbitrarily good decision performance can be attained. [sent-275, score-0.227]
</p><p>96 In between, we have empirically characterized the tradeoff between decision performance and control authority. [sent-276, score-0.318]
</p><p>97 Active perception and scene modeling by planning with probabilistic 6d object poses. [sent-315, score-0.463]
</p><p>98 Robotic object detection: Learning to improve the classiﬁers using sparse graphs for path planning. [sent-335, score-0.293]
</p><p>99 Autonomous generation of complete 3d object models using next best view manipulation planning. [sent-341, score-0.239]
</p><p>100 Mobile sensor network control using mutual information methods and particle ﬁlters. [sent-356, score-0.27]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('authority', 0.375), ('yt', 0.267), ('object', 0.239), ('ut', 0.237), ('gt', 0.234), ('gf', 0.201), ('clutter', 0.194), ('control', 0.184), ('scene', 0.179), ('entropy', 0.174), ('stubborn', 0.17), ('agent', 0.162), ('indecisive', 0.15), ('reachable', 0.142), ('environment', 0.119), ('go', 0.118), ('explorer', 0.106), ('search', 0.087), ('exploration', 0.087), ('sensor', 0.086), ('active', 0.085), ('ok', 0.085), ('occlusion', 0.085), ('kuk', 0.085), ('visual', 0.081), ('objects', 0.075), ('nuisances', 0.075), ('measurement', 0.073), ('ca', 0.07), ('radiance', 0.069), ('occlusions', 0.067), ('lk', 0.061), ('tradeoff', 0.061), ('nt', 0.059), ('photometric', 0.056), ('ck', 0.055), ('path', 0.054), ('risk', 0.052), ('regret', 0.052), ('planned', 0.052), ('density', 0.051), ('residual', 0.051), ('robotics', 0.05), ('segment', 0.05), ('sensing', 0.049), ('snapshots', 0.049), ('recognition', 0.049), ('simplest', 0.047), ('unknown', 0.046), ('planning', 0.045), ('nuisance', 0.044), ('location', 0.044), ('decision', 0.043), ('measurements', 0.043), ('robotic', 0.043), ('pomdp', 0.043), ('atland', 0.042), ('cartoon', 0.042), ('finish', 0.042), ('omnipotent', 0.042), ('unmodeled', 0.042), ('controller', 0.041), ('energy', 0.041), ('ber', 0.039), ('nc', 0.039), ('upper', 0.038), ('passive', 0.038), ('dyt', 0.038), ('mobility', 0.038), ('traveled', 0.038), ('viewing', 0.037), ('conditional', 0.036), ('arg', 0.036), ('phenomenology', 0.035), ('designer', 0.035), ('ol', 0.035), ('discretized', 0.034), ('proxy', 0.034), ('actively', 0.033), ('scenario', 0.033), ('inf', 0.033), ('acquisition', 0.032), ('action', 0.032), ('images', 0.031), ('recognize', 0.031), ('wishes', 0.031), ('exercise', 0.031), ('suite', 0.031), ('proxies', 0.031), ('marginalization', 0.031), ('volume', 0.031), ('scenes', 0.03), ('quantization', 0.03), ('map', 0.03), ('occluded', 0.03), ('mobile', 0.03), ('afforded', 0.03), ('empirically', 0.03), ('wish', 0.03), ('unable', 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000006 <a title="83-tfidf-1" href="./nips-2012-Controlled_Recognition_Bounds_for_Visual_Learning_and_Exploration.html">83 nips-2012-Controlled Recognition Bounds for Visual Learning and Exploration</a></p>
<p>Author: Vasiliy Karasev, Alessandro Chiuso, Stefano Soatto</p><p>Abstract: We describe the tradeoff between the performance in a visual recognition problem and the control authority that the agent can exercise on the sensing process. We focus on the problem of “visual search” of an object in an otherwise known and static scene, propose a measure of control authority, and relate it to the expected risk and its proxy (conditional entropy of the posterior density). We show this analytically, as well as empirically by simulation using the simplest known model that captures the phenomenology of image formation, including scaling and occlusions. We show that a “passive” agent given a training set can provide no guarantees on performance beyond what is afforded by the priors, and that an “omnipotent” agent, capable of inﬁnite control authority, can achieve arbitrarily good performance (asymptotically). In between these limiting cases, the tradeoff can be characterized empirically. 1</p><p>2 0.22061239 <a title="83-tfidf-2" href="./nips-2012-Mixing_Properties_of_Conditional_Markov_Chains_with_Unbounded_Feature_Functions.html">218 nips-2012-Mixing Properties of Conditional Markov Chains with Unbounded Feature Functions</a></p>
<p>Author: Mathieu Sinn, Bei Chen</p><p>Abstract: Conditional Markov Chains (also known as Linear-Chain Conditional Random Fields in the literature) are a versatile class of discriminative models for the distribution of a sequence of hidden states conditional on a sequence of observable variables. Large-sample properties of Conditional Markov Chains have been ﬁrst studied in [1]. The paper extends this work in two directions: ﬁrst, mixing properties of models with unbounded feature functions are being established; second, necessary conditions for model identiﬁability and the uniqueness of maximum likelihood estimates are being given. 1</p><p>3 0.21688068 <a title="83-tfidf-3" href="./nips-2012-On_Multilabel_Classification_and_Ranking_with_Partial_Feedback.html">252 nips-2012-On Multilabel Classification and Ranking with Partial Feedback</a></p>
<p>Author: Claudio Gentile, Francesco Orabona</p><p>Abstract: We present a novel multilabel/ranking algorithm working in partial information settings. The algorithm is based on 2nd-order descent methods, and relies on upper-conﬁdence bounds to trade-off exploration and exploitation. We analyze this algorithm in a partial adversarial setting, where covariates can be adversarial, but multilabel probabilities are ruled by (generalized) linear models. We show O(T 1/2 log T ) regret bounds, which improve in several ways on the existing results. We test the effectiveness of our upper-conﬁdence scheme by contrasting against full-information baselines on real-world multilabel datasets, often obtaining comparable performance. 1</p><p>4 0.19661753 <a title="83-tfidf-4" href="./nips-2012-Mirror_Descent_Meets_Fixed_Share_%28and_feels_no_regret%29.html">216 nips-2012-Mirror Descent Meets Fixed Share (and feels no regret)</a></p>
<p>Author: Nicolò Cesa-bianchi, Pierre Gaillard, Gabor Lugosi, Gilles Stoltz</p><p>Abstract: Mirror descent with an entropic regularizer is known to achieve shifting regret bounds that are logarithmic in the dimension. This is done using either a carefully designed projection or by a weight sharing technique. Via a novel uniﬁed analysis, we show that these two approaches deliver essentially equivalent bounds on a notion of regret generalizing shifting, adaptive, discounted, and other related regrets. Our analysis also captures and extends the generalized weight sharing technique of Bousquet and Warmuth, and can be reﬁned in several ways, including improvements for small losses and adaptive tuning of parameters. 1</p><p>5 0.16567409 <a title="83-tfidf-5" href="./nips-2012-A_Nonparametric_Conjugate_Prior_Distribution_for_the_Maximizing_Argument_of_a_Noisy_Function.html">13 nips-2012-A Nonparametric Conjugate Prior Distribution for the Maximizing Argument of a Noisy Function</a></p>
<p>Author: Pedro Ortega, Jordi Grau-moya, Tim Genewein, David Balduzzi, Daniel Braun</p><p>Abstract: We propose a novel Bayesian approach to solve stochastic optimization problems that involve ﬁnding extrema of noisy, nonlinear functions. Previous work has focused on representing possible functions explicitly, which leads to a two-step procedure of ﬁrst, doing inference over the function space and second, ﬁnding the extrema of these functions. Here we skip the representation step and directly model the distribution over extrema. To this end, we devise a non-parametric conjugate prior based on a kernel regressor. The resulting posterior distribution directly captures the uncertainty over the maximum of the unknown function. Given t observations of the function, the posterior can be evaluated efﬁciently in time O(t2 ) up to a multiplicative constant. Finally, we show how to apply our model to optimize a noisy, non-convex, high-dimensional objective function.</p><p>6 0.14601739 <a title="83-tfidf-6" href="./nips-2012-Searching_for_objects_driven_by_context.html">303 nips-2012-Searching for objects driven by context</a></p>
<p>7 0.13449308 <a title="83-tfidf-7" href="./nips-2012-Slice_Normalized_Dynamic_Markov_Logic_Networks.html">314 nips-2012-Slice Normalized Dynamic Markov Logic Networks</a></p>
<p>8 0.13194093 <a title="83-tfidf-8" href="./nips-2012-Timely_Object_Recognition.html">344 nips-2012-Timely Object Recognition</a></p>
<p>9 0.11896458 <a title="83-tfidf-9" href="./nips-2012-Bayesian_nonparametric_models_for_ranked_data.html">60 nips-2012-Bayesian nonparametric models for ranked data</a></p>
<p>10 0.11601961 <a title="83-tfidf-10" href="./nips-2012-No-Regret_Algorithms_for_Unconstrained_Online_Convex_Optimization.html">241 nips-2012-No-Regret Algorithms for Unconstrained Online Convex Optimization</a></p>
<p>11 0.11419262 <a title="83-tfidf-11" href="./nips-2012-Exploration_in_Model-based_Reinforcement_Learning_by_Empirically_Estimating_Learning_Progress.html">122 nips-2012-Exploration in Model-based Reinforcement Learning by Empirically Estimating Learning Progress</a></p>
<p>12 0.10530928 <a title="83-tfidf-12" href="./nips-2012-Confusion-Based_Online_Learning_and_a_Passive-Aggressive_Scheme.html">80 nips-2012-Confusion-Based Online Learning and a Passive-Aggressive Scheme</a></p>
<p>13 0.10326348 <a title="83-tfidf-13" href="./nips-2012-Fully_Bayesian_inference_for_neural_models_with_negative-binomial_spiking.html">138 nips-2012-Fully Bayesian inference for neural models with negative-binomial spiking</a></p>
<p>14 0.10200167 <a title="83-tfidf-14" href="./nips-2012-Provable_ICA_with_Unknown_Gaussian_Noise%2C_with_Implications_for_Gaussian_Mixtures_and_Autoencoders.html">281 nips-2012-Provable ICA with Unknown Gaussian Noise, with Implications for Gaussian Mixtures and Autoencoders</a></p>
<p>15 0.093618125 <a title="83-tfidf-15" href="./nips-2012-Active_Comparison_of_Prediction_Models.html">32 nips-2012-Active Comparison of Prediction Models</a></p>
<p>16 0.092722617 <a title="83-tfidf-16" href="./nips-2012-Regularized_Off-Policy_TD-Learning.html">292 nips-2012-Regularized Off-Policy TD-Learning</a></p>
<p>17 0.08973515 <a title="83-tfidf-17" href="./nips-2012-Relax_and_Randomize_%3A_From_Value_to_Algorithms.html">293 nips-2012-Relax and Randomize : From Value to Algorithms</a></p>
<p>18 0.088215709 <a title="83-tfidf-18" href="./nips-2012-Bayesian_active_learning_with_localized_priors_for_fast_receptive_field_characterization.html">56 nips-2012-Bayesian active learning with localized priors for fast receptive field characterization</a></p>
<p>19 0.085018359 <a title="83-tfidf-19" href="./nips-2012-Link_Prediction_in_Graphs_with_Autoregressive_Features.html">199 nips-2012-Link Prediction in Graphs with Autoregressive Features</a></p>
<p>20 0.08453095 <a title="83-tfidf-20" href="./nips-2012-Analyzing_3D_Objects_in_Cluttered_Images.html">40 nips-2012-Analyzing 3D Objects in Cluttered Images</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.247), (1, -0.103), (2, 0.009), (3, 0.197), (4, 0.123), (5, -0.13), (6, -0.001), (7, -0.03), (8, 0.009), (9, 0.025), (10, -0.015), (11, 0.041), (12, 0.041), (13, -0.148), (14, -0.02), (15, 0.058), (16, 0.055), (17, -0.021), (18, -0.051), (19, -0.069), (20, 0.04), (21, 0.042), (22, 0.024), (23, 0.144), (24, 0.077), (25, 0.023), (26, 0.046), (27, -0.049), (28, 0.09), (29, 0.012), (30, 0.047), (31, 0.094), (32, 0.011), (33, 0.043), (34, 0.009), (35, -0.042), (36, 0.102), (37, 0.059), (38, -0.048), (39, -0.048), (40, 0.031), (41, 0.029), (42, 0.078), (43, 0.038), (44, 0.015), (45, -0.007), (46, 0.142), (47, 0.022), (48, -0.103), (49, 0.005)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96185774 <a title="83-lsi-1" href="./nips-2012-Controlled_Recognition_Bounds_for_Visual_Learning_and_Exploration.html">83 nips-2012-Controlled Recognition Bounds for Visual Learning and Exploration</a></p>
<p>Author: Vasiliy Karasev, Alessandro Chiuso, Stefano Soatto</p><p>Abstract: We describe the tradeoff between the performance in a visual recognition problem and the control authority that the agent can exercise on the sensing process. We focus on the problem of “visual search” of an object in an otherwise known and static scene, propose a measure of control authority, and relate it to the expected risk and its proxy (conditional entropy of the posterior density). We show this analytically, as well as empirically by simulation using the simplest known model that captures the phenomenology of image formation, including scaling and occlusions. We show that a “passive” agent given a training set can provide no guarantees on performance beyond what is afforded by the priors, and that an “omnipotent” agent, capable of inﬁnite control authority, can achieve arbitrarily good performance (asymptotically). In between these limiting cases, the tradeoff can be characterized empirically. 1</p><p>2 0.67660242 <a title="83-lsi-2" href="./nips-2012-Putting_Bayes_to_sleep.html">283 nips-2012-Putting Bayes to sleep</a></p>
<p>Author: Dmitry Adamskiy, Manfred K. Warmuth, Wouter M. Koolen</p><p>Abstract: We consider sequential prediction algorithms that are given the predictions from a set of models as inputs. If the nature of the data is changing over time in that different models predict well on different segments of the data, then adaptivity is typically achieved by mixing into the weights in each round a bit of the initial prior (kind of like a weak restart). However, what if the favored models in each segment are from a small subset, i.e. the data is likely to be predicted well by models that predicted well before? Curiously, ﬁtting such “sparse composite models” is achieved by mixing in a bit of all the past posteriors. This self-referential updating method is rather peculiar, but it is efﬁcient and gives superior performance on many natural data sets. Also it is important because it introduces a long-term memory: any model that has done well in the past can be recovered quickly. While Bayesian interpretations can be found for mixing in a bit of the initial prior, no Bayesian interpretation is known for mixing in past posteriors. We build atop the “specialist” framework from the online learning literature to give the Mixing Past Posteriors update a proper Bayesian foundation. We apply our method to a well-studied multitask learning problem and obtain a new intriguing efﬁcient update that achieves a signiﬁcantly better bound. 1</p><p>3 0.61140531 <a title="83-lsi-3" href="./nips-2012-Searching_for_objects_driven_by_context.html">303 nips-2012-Searching for objects driven by context</a></p>
<p>Author: Bogdan Alexe, Nicolas Heess, Yee W. Teh, Vittorio Ferrari</p><p>Abstract: The dominant visual search paradigm for object class detection is sliding windows. Although simple and effective, it is also wasteful, unnatural and rigidly hardwired. We propose strategies to search for objects which intelligently explore the space of windows by making sequential observations at locations decided based on previous observations. Our strategies adapt to the class being searched and to the content of a particular test image, exploiting context as the statistical relation between the appearance of a window and its location relative to the object, as observed in the training set. In addition to being more elegant than sliding windows, we demonstrate experimentally on the PASCAL VOC 2010 dataset that our strategies evaluate two orders of magnitude fewer windows while achieving higher object detection performance. 1</p><p>4 0.60891336 <a title="83-lsi-4" href="./nips-2012-On_Multilabel_Classification_and_Ranking_with_Partial_Feedback.html">252 nips-2012-On Multilabel Classification and Ranking with Partial Feedback</a></p>
<p>Author: Claudio Gentile, Francesco Orabona</p><p>Abstract: We present a novel multilabel/ranking algorithm working in partial information settings. The algorithm is based on 2nd-order descent methods, and relies on upper-conﬁdence bounds to trade-off exploration and exploitation. We analyze this algorithm in a partial adversarial setting, where covariates can be adversarial, but multilabel probabilities are ruled by (generalized) linear models. We show O(T 1/2 log T ) regret bounds, which improve in several ways on the existing results. We test the effectiveness of our upper-conﬁdence scheme by contrasting against full-information baselines on real-world multilabel datasets, often obtaining comparable performance. 1</p><p>5 0.60032523 <a title="83-lsi-5" href="./nips-2012-Slice_Normalized_Dynamic_Markov_Logic_Networks.html">314 nips-2012-Slice Normalized Dynamic Markov Logic Networks</a></p>
<p>Author: Tivadar Papai, Henry Kautz, Daniel Stefankovic</p><p>Abstract: Markov logic is a widely used tool in statistical relational learning, which uses a weighted ﬁrst-order logic knowledge base to specify a Markov random ﬁeld (MRF) or a conditional random ﬁeld (CRF). In many applications, a Markov logic network (MLN) is trained in one domain, but used in a different one. This paper focuses on dynamic Markov logic networks, where the size of the discretized time-domain typically varies between training and testing. It has been previously pointed out that the marginal probabilities of truth assignments to ground atoms can change if one extends or reduces the domains of predicates in an MLN. We show that in addition to this problem, the standard way of unrolling a Markov logic theory into a MRF may result in time-inhomogeneity of the underlying Markov chain. Furthermore, even if these representational problems are not signiﬁcant for a given domain, we show that the more practical problem of generating samples in a sequential conditional random ﬁeld for the next slice relying on the samples from the previous slice has high computational cost in the general case, due to the need to estimate a normalization factor for each sample. We propose a new discriminative model, slice normalized dynamic Markov logic networks (SN-DMLN), that suffers from none of these issues. It supports efﬁcient online inference, and can directly model inﬂuences between variables within a time slice that do not have a causal direction, in contrast with fully directed models (e.g., DBNs). Experimental results show an improvement in accuracy over previous approaches to online inference in dynamic Markov logic networks. 1</p><p>6 0.5669412 <a title="83-lsi-6" href="./nips-2012-Confusion-Based_Online_Learning_and_a_Passive-Aggressive_Scheme.html">80 nips-2012-Confusion-Based Online Learning and a Passive-Aggressive Scheme</a></p>
<p>7 0.53825629 <a title="83-lsi-7" href="./nips-2012-Mixing_Properties_of_Conditional_Markov_Chains_with_Unbounded_Feature_Functions.html">218 nips-2012-Mixing Properties of Conditional Markov Chains with Unbounded Feature Functions</a></p>
<p>8 0.52662987 <a title="83-lsi-8" href="./nips-2012-A_Nonparametric_Conjugate_Prior_Distribution_for_the_Maximizing_Argument_of_a_Noisy_Function.html">13 nips-2012-A Nonparametric Conjugate Prior Distribution for the Maximizing Argument of a Noisy Function</a></p>
<p>9 0.5152967 <a title="83-lsi-9" href="./nips-2012-Multi-Task_Averaging.html">222 nips-2012-Multi-Task Averaging</a></p>
<p>10 0.48625439 <a title="83-lsi-10" href="./nips-2012-Max-Margin_Structured_Output_Regression_for_Spatio-Temporal_Action_Localization.html">209 nips-2012-Max-Margin Structured Output Regression for Spatio-Temporal Action Localization</a></p>
<p>11 0.48276252 <a title="83-lsi-11" href="./nips-2012-Exploration_in_Model-based_Reinforcement_Learning_by_Empirically_Estimating_Learning_Progress.html">122 nips-2012-Exploration in Model-based Reinforcement Learning by Empirically Estimating Learning Progress</a></p>
<p>12 0.47447965 <a title="83-lsi-12" href="./nips-2012-Timely_Object_Recognition.html">344 nips-2012-Timely Object Recognition</a></p>
<p>13 0.46669337 <a title="83-lsi-13" href="./nips-2012-Transferring_Expectations_in_Model-based_Reinforcement_Learning.html">353 nips-2012-Transferring Expectations in Model-based Reinforcement Learning</a></p>
<p>14 0.46414319 <a title="83-lsi-14" href="./nips-2012-Approximate_Message_Passing_with_Consistent_Parameter_Estimation_and_Applications_to_Sparse_Learning.html">43 nips-2012-Approximate Message Passing with Consistent Parameter Estimation and Applications to Sparse Learning</a></p>
<p>15 0.46051326 <a title="83-lsi-15" href="./nips-2012-Cocktail_Party_Processing_via_Structured_Prediction.html">72 nips-2012-Cocktail Party Processing via Structured Prediction</a></p>
<p>16 0.45906439 <a title="83-lsi-16" href="./nips-2012-Multi-criteria_Anomaly_Detection_using_Pareto_Depth_Analysis.html">223 nips-2012-Multi-criteria Anomaly Detection using Pareto Depth Analysis</a></p>
<p>17 0.44336677 <a title="83-lsi-17" href="./nips-2012-Mirror_Descent_Meets_Fixed_Share_%28and_feels_no_regret%29.html">216 nips-2012-Mirror Descent Meets Fixed Share (and feels no regret)</a></p>
<p>18 0.4379375 <a title="83-lsi-18" href="./nips-2012-3D_Social_Saliency_from_Head-mounted_Cameras.html">2 nips-2012-3D Social Saliency from Head-mounted Cameras</a></p>
<p>19 0.43555143 <a title="83-lsi-19" href="./nips-2012-Efficient_Bayes-Adaptive_Reinforcement_Learning_using_Sample-Based_Search.html">108 nips-2012-Efficient Bayes-Adaptive Reinforcement Learning using Sample-Based Search</a></p>
<p>20 0.43068835 <a title="83-lsi-20" href="./nips-2012-Bayesian_Hierarchical_Reinforcement_Learning.html">51 nips-2012-Bayesian Hierarchical Reinforcement Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.048), (21, 0.053), (38, 0.114), (39, 0.018), (42, 0.026), (54, 0.069), (55, 0.025), (73, 0.109), (74, 0.091), (76, 0.12), (78, 0.039), (80, 0.11), (92, 0.051)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.89095372 <a title="83-lda-1" href="./nips-2012-Controlled_Recognition_Bounds_for_Visual_Learning_and_Exploration.html">83 nips-2012-Controlled Recognition Bounds for Visual Learning and Exploration</a></p>
<p>Author: Vasiliy Karasev, Alessandro Chiuso, Stefano Soatto</p><p>Abstract: We describe the tradeoff between the performance in a visual recognition problem and the control authority that the agent can exercise on the sensing process. We focus on the problem of “visual search” of an object in an otherwise known and static scene, propose a measure of control authority, and relate it to the expected risk and its proxy (conditional entropy of the posterior density). We show this analytically, as well as empirically by simulation using the simplest known model that captures the phenomenology of image formation, including scaling and occlusions. We show that a “passive” agent given a training set can provide no guarantees on performance beyond what is afforded by the priors, and that an “omnipotent” agent, capable of inﬁnite control authority, can achieve arbitrarily good performance (asymptotically). In between these limiting cases, the tradeoff can be characterized empirically. 1</p><p>2 0.87658024 <a title="83-lda-2" href="./nips-2012-Distributed_Probabilistic_Learning_for_Camera_Networks_with_Missing_Data.html">103 nips-2012-Distributed Probabilistic Learning for Camera Networks with Missing Data</a></p>
<p>Author: Sejong Yoon, Vladimir Pavlovic</p><p>Abstract: Probabilistic approaches to computer vision typically assume a centralized setting, with the algorithm granted access to all observed data points. However, many problems in wide-area surveillance can beneﬁt from distributed modeling, either because of physical or computational constraints. Most distributed models to date use algebraic approaches (such as distributed SVD) and as a result cannot explicitly deal with missing data. In this work we present an approach to estimation and learning of generative probabilistic models in a distributed context where certain sensor data can be missing. In particular, we show how traditional centralized models, such as probabilistic PCA and missing-data PPCA, can be learned when the data is distributed across a network of sensors. We demonstrate the utility of this approach on the problem of distributed afﬁne structure from motion. Our experiments suggest that the accuracy of the learned probabilistic structure and motion models rivals that of traditional centralized factorization methods while being able to handle challenging situations such as missing or noisy observations. 1</p><p>3 0.87204033 <a title="83-lda-3" href="./nips-2012-Augment-and-Conquer_Negative_Binomial_Processes.html">47 nips-2012-Augment-and-Conquer Negative Binomial Processes</a></p>
<p>Author: Mingyuan Zhou, Lawrence Carin</p><p>Abstract: By developing data augmentation methods unique to the negative binomial (NB) distribution, we unite seemingly disjoint count and mixture models under the NB process framework. We develop fundamental properties of the models and derive efﬁcient Gibbs sampling inference. We show that the gamma-NB process can be reduced to the hierarchical Dirichlet process with normalization, highlighting its unique theoretical, structural and computational advantages. A variety of NB processes with distinct sharing mechanisms are constructed and applied to topic modeling, with connections to existing algorithms, showing the importance of inferring both the NB dispersion and probability parameters. 1</p><p>4 0.84736151 <a title="83-lda-4" href="./nips-2012-Timely_Object_Recognition.html">344 nips-2012-Timely Object Recognition</a></p>
<p>Author: Sergey Karayev, Tobias Baumgartner, Mario Fritz, Trevor Darrell</p><p>Abstract: In a large visual multi-class detection framework, the timeliness of results can be crucial. Our method for timely multi-class detection aims to give the best possible performance at any single point after a start time; it is terminated at a deadline time. Toward this goal, we formulate a dynamic, closed-loop policy that infers the contents of the image in order to decide which detector to deploy next. In contrast to previous work, our method signiﬁcantly diverges from the predominant greedy strategies, and is able to learn to take actions with deferred values. We evaluate our method with a novel timeliness measure, computed as the area under an Average Precision vs. Time curve. Experiments are conducted on the PASCAL VOC object detection dataset. If execution is stopped when only half the detectors have been run, our method obtains 66% better AP than a random ordering, and 14% better performance than an intelligent baseline. On the timeliness measure, our method obtains at least 11% better performance. Our method is easily extensible, as it treats detectors and classiﬁers as black boxes and learns from execution traces using reinforcement learning. 1</p><p>5 0.8469795 <a title="83-lda-5" href="./nips-2012-Kernel_Latent_SVM_for_Visual_Recognition.html">168 nips-2012-Kernel Latent SVM for Visual Recognition</a></p>
<p>Author: Weilong Yang, Yang Wang, Arash Vahdat, Greg Mori</p><p>Abstract: Latent SVMs (LSVMs) are a class of powerful tools that have been successfully applied to many applications in computer vision. However, a limitation of LSVMs is that they rely on linear models. For many computer vision tasks, linear models are suboptimal and nonlinear models learned with kernels typically perform much better. Therefore it is desirable to develop the kernel version of LSVM. In this paper, we propose kernel latent SVM (KLSVM) – a new learning framework that combines latent SVMs and kernel methods. We develop an iterative training algorithm to learn the model parameters. We demonstrate the effectiveness of KLSVM using three different applications in visual recognition. Our KLSVM formulation is very general and can be applied to solve a wide range of applications in computer vision and machine learning. 1</p><p>6 0.84524363 <a title="83-lda-6" href="./nips-2012-Priors_for_Diversity_in_Generative_Latent_Variable_Models.html">274 nips-2012-Priors for Diversity in Generative Latent Variable Models</a></p>
<p>7 0.84424704 <a title="83-lda-7" href="./nips-2012-Random_function_priors_for_exchangeable_arrays_with_applications_to_graphs_and_relational_data.html">287 nips-2012-Random function priors for exchangeable arrays with applications to graphs and relational data</a></p>
<p>8 0.84338439 <a title="83-lda-8" href="./nips-2012-Learned_Prioritization_for_Trading_Off_Accuracy_and_Speed.html">173 nips-2012-Learned Prioritization for Trading Off Accuracy and Speed</a></p>
<p>9 0.84257799 <a title="83-lda-9" href="./nips-2012-Efficient_Bayes-Adaptive_Reinforcement_Learning_using_Sample-Based_Search.html">108 nips-2012-Efficient Bayes-Adaptive Reinforcement Learning using Sample-Based Search</a></p>
<p>10 0.83932704 <a title="83-lda-10" href="./nips-2012-Learning_Invariant_Representations_of_Molecules_for_Atomization_Energy_Prediction.html">177 nips-2012-Learning Invariant Representations of Molecules for Atomization Energy Prediction</a></p>
<p>11 0.83910549 <a title="83-lda-11" href="./nips-2012-Algorithms_for_Learning_Markov_Field_Policies.html">38 nips-2012-Algorithms for Learning Markov Field Policies</a></p>
<p>12 0.83833981 <a title="83-lda-12" href="./nips-2012-Inverse_Reinforcement_Learning_through_Structured_Classification.html">162 nips-2012-Inverse Reinforcement Learning through Structured Classification</a></p>
<p>13 0.83614618 <a title="83-lda-13" href="./nips-2012-Learning_with_Recursive_Perceptual_Representations.html">197 nips-2012-Learning with Recursive Perceptual Representations</a></p>
<p>14 0.83593047 <a title="83-lda-14" href="./nips-2012-Truncation-free_Online_Variational_Inference_for_Bayesian_Nonparametric_Models.html">355 nips-2012-Truncation-free Online Variational Inference for Bayesian Nonparametric Models</a></p>
<p>15 0.83400202 <a title="83-lda-15" href="./nips-2012-Multimodal_Learning_with_Deep_Boltzmann_Machines.html">229 nips-2012-Multimodal Learning with Deep Boltzmann Machines</a></p>
<p>16 0.8337546 <a title="83-lda-16" href="./nips-2012-Learning_to_Align_from_Scratch.html">193 nips-2012-Learning to Align from Scratch</a></p>
<p>17 0.83371544 <a title="83-lda-17" href="./nips-2012-Multiresolution_analysis_on_the_symmetric_group.html">234 nips-2012-Multiresolution analysis on the symmetric group</a></p>
<p>18 0.833561 <a title="83-lda-18" href="./nips-2012-Efficient_Spike-Coding_with_Multiplicative_Adaptation_in_a_Spike_Response_Model.html">112 nips-2012-Efficient Spike-Coding with Multiplicative Adaptation in a Spike Response Model</a></p>
<p>19 0.8329547 <a title="83-lda-19" href="./nips-2012-Searching_for_objects_driven_by_context.html">303 nips-2012-Searching for objects driven by context</a></p>
<p>20 0.83233911 <a title="83-lda-20" href="./nips-2012-Augmented-SVM%3A_Automatic_space_partitioning_for_combining_multiple_non-linear_dynamics.html">48 nips-2012-Augmented-SVM: Automatic space partitioning for combining multiple non-linear dynamics</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
