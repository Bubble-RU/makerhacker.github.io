<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>50 nips-2012-Bandit Algorithms boost Brain Computer Interfaces for motor-task selection of a brain-controlled button</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-50" href="#">nips2012-50</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>50 nips-2012-Bandit Algorithms boost Brain Computer Interfaces for motor-task selection of a brain-controlled button</h1>
<br/><p>Source: <a title="nips-2012-50-pdf" href="http://papers.nips.cc/paper/4616-bandit-algorithms-boost-brain-computer-interfaces-for-motor-task-selection-of-a-brain-controlled-button.pdf">pdf</a></p><p>Author: Joan Fruitet, Alexandra Carpentier, Maureen Clerc, Rémi Munos</p><p>Abstract: Brain-computer interfaces (BCI) allow users to “communicate” with a computer without using their muscles. BCI based on sensori-motor rhythms use imaginary motor tasks, such as moving the right or left hand, to send control signals. The performances of a BCI can vary greatly across users but also depend on the tasks used, making the problem of appropriate task selection an important issue. This study presents a new procedure to automatically select as fast as possible a discriminant motor task for a brain-controlled button. We develop for this purpose an adaptive algorithm, UCB-classif , based on the stochastic bandit theory. This shortens the training stage, thereby allowing the exploration of a greater variety of tasks. By not wasting time on inefﬁcient tasks, and focusing on the most promising ones, this algorithm results in a faster task selection and a more efﬁcient use of the BCI training session. Comparing the proposed method to the standard practice in task selection, for a ﬁxed time budget, UCB-classif leads to an improved classiﬁcation rate, and for a ﬁxed classiﬁcation rate, to a reduction of the time spent in training by 50%. 1</p><p>Reference: <a title="nips-2012-50-reference" href="../nips2012_reference/nips-2012-Bandit_Algorithms_boost_Brain_Computer_Interfaces_for_motor-task_selection_of_a_brain-controlled_button_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 BCI based on sensori-motor rhythms use imaginary motor tasks, such as moving the right or left hand, to send control signals. [sent-12, score-0.831]
</p><p>2 The performances of a BCI can vary greatly across users but also depend on the tasks used, making the problem of appropriate task selection an important issue. [sent-13, score-0.322]
</p><p>3 This study presents a new procedure to automatically select as fast as possible a discriminant motor task for a brain-controlled button. [sent-14, score-0.29]
</p><p>4 We develop for this purpose an adaptive algorithm, UCB-classif , based on the stochastic bandit theory. [sent-15, score-0.21]
</p><p>5 By not wasting time on inefﬁcient tasks, and focusing on the most promising ones, this algorithm results in a faster task selection and a more efﬁcient use of the BCI training session. [sent-17, score-0.204]
</p><p>6 A possible way of communicating through the BCI is by using sensori-motor rhythms (SMR), which are modulated in the course of movement execution or movement imagination. [sent-23, score-0.697]
</p><p>7 The SMR corresponding to movement imagination can be detected after pre-processing the EEG, which is corrupted by important noise, and after training (see [1, 2, 3]). [sent-24, score-0.356]
</p><p>8 A well-trained classiﬁer can then use features of the SMR in order to discriminate periods of imagined movement from resting periods, when the user is idle. [sent-25, score-0.567]
</p><p>9 This paper deals with training a BCI corresponding to a single brain-controlled button (see [2, 4]), in which a button is pressed (and instantaneously released) when a certain imagined movement is detected. [sent-27, score-0.665]
</p><p>10 The important steps are thus to ﬁnd a suitable imaginary motor task, and to train a 1  classiﬁer. [sent-28, score-0.707]
</p><p>11 The setting up of such a brain-controlled button can be very time consuming, given that many training examples need to be acquired for each of the imaginary motor task to be tested. [sent-30, score-0.967]
</p><p>12 The usual training protocol for a brain-controlled button is to display sequentially to the user a set of images, that serve as prompts to perform the corresponding imaginary movements. [sent-31, score-0.828]
</p><p>13 The collected data are used to train the classiﬁer, and to select the imaginary movement that seems to provide the highest classiﬁcation rate (compared to the background resting state). [sent-32, score-1.03]
</p><p>14 We refer to this imaginary movement as the “best imaginary movement”. [sent-33, score-1.394]
</p><p>15 In this paper, we focus on the part of the training phase that consists in efﬁciently ﬁnding this best imaginary movement. [sent-34, score-0.691]
</p><p>16 This is an important problem, since the SMR collected by the EEG are heterogeneously noisy: some imaginary motor tasks will provide higher classiﬁcation rates than others. [sent-35, score-0.812]
</p><p>17 In the literature, ﬁnding such imaginary motor tasks is deemed an essential issue (see [5, 6, 7]), but, to the best of our knowledge, no automatized protocol has yet been proposed to deal with it. [sent-36, score-0.882]
</p><p>18 We believe that enhancing the efﬁciency of the training phase is made even more essential by the facts that (i) the best imaginary movement differs from one user to another, e. [sent-37, score-1.053]
</p><p>19 the best imaginary movement for one user could be to imagine moving the right hand, and for the next, to imagine moving both feet (see [8]) and (ii) using a BCI requires much concentration, and a long training phase exhausts the user. [sent-39, score-1.393]
</p><p>20 If an “oracle” were able to state what the best imaginary movement is, then the training phase would consist only in requiring the user to perform this imaginary movement. [sent-40, score-1.596]
</p><p>21 The training set for the classiﬁer on this imaginary movement would be large, and no training time would be wasted in asking the user to perform sub-optimal and thus useless imaginary movements. [sent-41, score-1.544]
</p><p>22 The best imaginary movement is however not known in advance, and so the commonly used strategy (which we will refer to as uniform) consists in asking the user to perform all the movements a ﬁxed number of times. [sent-42, score-1.131]
</p><p>23 An alternative strategy is to learn while building the training set what imaginary movements seem the most promising, and ask the classiﬁer to perform these more often. [sent-43, score-0.779]
</p><p>24 Contributions This paper builds on ideas of Bandit Theory, in order to propose an efﬁcient method to select the best imaginary movement for the activation of a brain-controlled button. [sent-46, score-0.954]
</p><p>25 • We design a BCI experiment for imaginary motor task selection, and collect data on several subjects, for different imaginary motor tasks, in the aim of testing our methods. [sent-48, score-1.574]
</p><p>26 • We provide a bandit algorithm (which is strongly inspired by the Upper Conﬁdence Bound Algorithm of [10]) adapted to this classiﬁcation problem. [sent-49, score-0.21]
</p><p>27 In Section 3, we model the task selection as a bandit problem, which is solved using an Upper Conﬁdence Bound algorithm. [sent-55, score-0.339]
</p><p>28 1 Here, the actions are images displayed to the BCI user as prompts to perform the corresponding imaginary tasks. [sent-59, score-0.734]
</p><p>29 2  2  Material and protocol  BCI systems based on SMR rely on the users’ ability to control their SMR in the mu (8-13Hz) and/or beta (16-24Hz) frequency bands [1, 2, 3]. [sent-60, score-0.247]
</p><p>30 Indeed, these rhythms are naturally modulated during real and imagined motor action. [sent-61, score-0.316]
</p><p>31 BCI based on the control of SMR generally use movements lasting several seconds, that enable continuous control of multidimensional interfaces [1]. [sent-64, score-0.201]
</p><p>32 On the contrary this work targets a braincontrolled button that can be rapidly triggered by a short motor task [2, 4]. [sent-65, score-0.407]
</p><p>33 A vast variety of motor tasks can be used in this context, like imagining rapidly moving the hand, grasping an object, or kicking an imaginary ball. [sent-66, score-0.915]
</p><p>34 We remind that the best imaginary movement differs from one user to another (see [8]). [sent-67, score-0.943]
</p><p>35 In the case of a BCI managing a brain-controlled button through SMR, this training phase consists in displaying to the user a sequence of images corresponding to movements, that he/she must imagine performing. [sent-69, score-0.345]
</p><p>36 By processing the EEG, the SMR associated to the imaginary movements and to idle periods can be extracted. [sent-70, score-0.774]
</p><p>37 The imaginary movement with highest classiﬁcation rate is then selected to activate the button in the actual use of the BCI. [sent-72, score-1.085]
</p><p>38 1 The EEG experiment The EEG experiment was similar to the training of a brain-controlled button: we presented, at random timing, cue images during which the subjects were asked to perform 2 second long motor tasks (intended to activate the button). [sent-75, score-0.577]
</p><p>39 EEG was recorded dat a sampling rate of 512Hz via 11 scalp electrodes of a 64-channel cap and ampliﬁed with a TMSI ampliﬁer (see Figure 1). [sent-78, score-0.193]
</p><p>40 Each cue image was a prompt for the subject to perform or imagine the corresponding motor action during 2 seconds, namely moving the right or left hand, the feet or the tongue. [sent-85, score-0.592]
</p><p>41 2 Feature extraction In the case of short motor tasks, the movement (real or imagined) produces an ERD in the mu and beta bands during the task, and is followed by a strong ERS [4] (sometimes called beta rebound as it is most easily seen in the beta frequency band). [sent-87, score-0.858]
</p><p>42 We extracted features of the mu and beta bands during the 2-second windows of the motor action and in the subsequent 1. [sent-88, score-0.588]
</p><p>43 Figure 1 shows a time-frequency map on which the movement and rebound windows are indicated. [sent-90, score-0.388]
</p><p>44 One may observe that, during the movement, the power in the mu and beta bands decreases (ERD) and that, approximately 1 second after the movement, it increases to reach a higher level than in the resting state (ERS). [sent-91, score-0.289]
</p><p>45 Thus, 6 features are extracted during the movement and 6 during the rebound. [sent-93, score-0.369]
</p><p>46 The lengths and positions of the windows and the frequency bands were chosen according to a preliminary study with one of the subjects and were deliberately kept ﬁxed for the other subjects. [sent-94, score-0.222]
</p><p>47 To demonstrate the usefulness of our method for a larger number of tasks, we decided to create artiﬁcial (degraded) tasks by mixing the features of one of the real tasks (the feet) with different proportions of the features extracted during the resting period. [sent-97, score-0.377]
</p><p>48 B: Time-frequency map of the signal recorded on electrode C3, for a right hand movement lasting 2 seconds (subject 1). [sent-100, score-0.403]
</p><p>49 3 Evaluation of performances For each task k, we can classify between when the subject is inactive and when he/she is performing task k. [sent-103, score-0.269]
</p><p>50 Consider a sample (X, Y ) ∼ Dk where Dk is the distribution of the data restricted to task k and the idle task (task 0), X is the feature set, and Y is the label (1 if the sample corresponds to task k and 0 otherwise). [sent-104, score-0.36]
</p><p>51 Deﬁne the theoretical loss rk of a task k as the probability ∗ of labeling incorrectly a new data drawn from Dk with the best classiﬁer h∗ , that is to say rk = k 1 − P(X,Y )∼D (h∗ (X) �= Y ). [sent-107, score-0.261]
</p><p>52 i=1  Since during our experiments we collect, between each imaginary task, a sample of idle condition, we have T0,t � Tk,t . [sent-111, score-0.624]
</p><p>53 We will use in the next Section the results of Equation 1, in order to select as fast as possible the ∗ task with highest rk and collect as many samples from it as possible. [sent-123, score-0.252]
</p><p>54 4  3  A bandit algorithms for optimal task selection  In order to improve the efﬁciency of the training phase, it is important to ﬁnd out as fast as possible ∗ what are the most promising imaginary tasks (i. [sent-124, score-1.062]
</p><p>55 Indeed, it is important to collect as many samples as possible from the best imaginary movement, so that the classiﬁer built for this task is as precise as possible. [sent-127, score-0.707]
</p><p>56 1 Modeling the problem by a multi-armed bandit Let K denote the number of different tasks2 and N the total number of rounds (the budget) of the training stage. [sent-130, score-0.258]
</p><p>57 most discriminative imaginary movement, with highest classiﬁcation rate in generalization). [sent-141, score-0.615]
</p><p>58 Note that, in order to learn an efﬁcient classiﬁer, we need as many training data as possible, so our presentation strategy should rapidly focus on the most promising tasks in order to obtain more samples from these rather than from the ones with small classiﬁcation rate. [sent-142, score-0.304]
</p><p>59 This issue is relatively close to the stochastic bandit problem [9]. [sent-143, score-0.21]
</p><p>60 The classical stochastic bandit problem is deﬁned by a set of K actions (pulling different arms of bandit machines) and to each action is assigned a reward distribution, initially unknown to the learner. [sent-144, score-0.612]
</p><p>61 , K}, we receive a reward sample drawn independently from the distribution of the corresponding action kt . [sent-151, score-0.192]
</p><p>62 We model the K different images to be displayed as the K possible actions, and we deﬁne the reward as the classiﬁcation rate of the corresponding motor action. [sent-153, score-0.294]
</p><p>63 In the bandit problem, pulling a bandit arm directly gives a stochastic reward which is used to estimate the distribution of this arm. [sent-154, score-0.477]
</p><p>64 In our case, when we display a new image, we obtain a new data sample for the selected imaginary movement, which provides one more data sample to train or test the corresponding classiﬁer and thus obtain a more accurate performance. [sent-155, score-0.543]
</p><p>65 The main difference is that for the stochastic bandit problem, the goal is to maximize the sum of obtained rewards, whereas ours is to maximize the performance of the ﬁnal classiﬁer. [sent-156, score-0.21]
</p><p>66 2 The UCB-classif algorithm The task presentation strategy is a close variant of the Upper Conﬁdence Bound (UCB) algorithm of [10], which builds high probability Upper Conﬁdence Bounds (UCB) on the mean reward value of each action, and selects at each time step the action with highest bound. [sent-160, score-0.356]
</p><p>67 Writing rk the classiﬁcation rate for the optimal linear SVM classiﬁer (which would be obtained by using a inﬁnite number of samples), we have the property that Bk,t is a high ∗ ∗ probability upper bound on rk : P(Bk,t < rk ) decreases to zero polynomially fast (with N ). [sent-164, score-0.239]
</p><p>68 It is indeed important to 2 The tasks correspond to the imaginary movements of moving the feet, tongue, right hand, and left hand, plus 4 additional degraded tasks (so a total of K = 8 actions). [sent-169, score-0.952]
</p><p>69 gather as much data as possible from the best action in order to build the best possible classiﬁer. [sent-181, score-0.187]
</p><p>70 The UCB-classif algorithm guarantees that the non-optimal tasks are chosen only a negligible fraction of times (O(log N ) times out of a total budget N ). [sent-182, score-0.237]
</p><p>71 Indeed, the unadaptive optimal strategy is to sample each action N/K times, and thus the best task is only sampled N/K times (and not N − O(log N )). [sent-185, score-0.337]
</p><p>72 ) and if a ≥ 5(d + 1) we have that the number of times that the image of the best ∗ imaginary movement is displayed by algorithm UCB-classif is such that (where r∗ = maxk rk ) ∗ TN ≥ N −  � a log(8N K) 8 ∗ . [sent-192, score-0.982]
</p><p>73 We brieﬂy describe two other settings, and explain how ideas from the bandit setting can be used to adapt to these different scenarios. [sent-197, score-0.242]
</p><p>74 With ideas very similar to those developed in [16] (and extended for bandit problems in e. [sent-200, score-0.242]
</p><p>75 Then using ideas similar to those presented in [17], an efﬁcient algorithm will at time t select the action that � � ˆ ˆ maximizes Bk,t = rk,t + a log(N K/δ) and will stop at the ﬁrst time T when there is an action Tk,t−1 � � � ˆ ˆ k ∗ such that ∀k �= k ∗ , Bkˆ∗ ,T − Bk,T > � + 2 a log(N K/δ) . [sent-204, score-0.287]
</p><p>76 Choice of the best action with a limited budget: Another question that could be of interest for the practitioner is to ﬁnd the best action with a ﬁxed budget (and not train the classiﬁer at the same time). [sent-206, score-0.477]
</p><p>77 By selecting at each time t the action that � �� maximizes Bk,t = rk,t + a(N −K) , we attain this objective in the sense that we guarantee that the ˆ Tk,t−1 probability of choosing a non-optimal action decreases exponentially fast with N . [sent-208, score-0.222]
</p><p>78 1 Performances of the different tasks The images that were displayed to the subjects correspond to movements of both feet, of the tongue, of the right hand, and of the left hand (4 actions in total). [sent-221, score-0.469]
</p><p>79 Six right-handed subjects went through the experiment with real movements and three of them went through an additional shorter experiment with imaginary movements. [sent-222, score-0.896]
</p><p>80 For four of the six subjects, the best performance for the real movement was achieved with the right hand, whereas the two other subjects’ best tasks corresponded to the left hand and the feet. [sent-223, score-0.531]
</p><p>81 In order to have a larger number of tasks and place ourselves in a more realistic situation, we created some articicial tasks (see below). [sent-226, score-0.21]
</p><p>82 Surprisingly, two of the subjects who went through the imaginary experiment obtained better results while imagining moving their left hand than their right hand, which was the best task during the real movements experiment. [sent-228, score-1.073]
</p><p>83 For the third subject who did the imaginary experiment, the best task was the feet, as for the real movement experiment. [sent-229, score-1.01]
</p><p>84 2, for this study we chose to use a very small set of ﬁxed features (12 features, extracted from 3 electrodes, 2 frequency bands and 2 time-windows), calibrated on only one of the six subjects during a preliminary experiment. [sent-231, score-0.246]
</p><p>85 Although for all the subjects, the best task achieved a classiﬁcation accuracy above 85%, this accuracy could further be improved by using a larger set of subject-speciﬁc features [21] and more advanced techniques (like the CSP [22] or feature selection [23]). [sent-235, score-0.199]
</p><p>86 2 Performances of the bandit algorithm We compare the performance of the UCB-classif sampling strategy to a uniform strategy, i. [sent-237, score-0.324]
</p><p>87 Feet X% is a mixture of the features measured during feet movement and during the resting condition, with a X/100-X proportion. [sent-265, score-0.598]
</p><p>88 More precisely, for each chosen budget N , for the UCB-classif strategy and the uniform strategy, we simulated 500 online BCI experiments by randomly sampling from the acquired data of each action. [sent-268, score-0.246]
</p><p>89 Table 2 shows, for one subject and for a ﬁxed budget of N = 70, the average number of presentations of each task Tk , and its standard deviation, across the 500 simulated experiments. [sent-269, score-0.324]
</p><p>90 It also contains the off-line classiﬁcation rate of each task to give an idea of the performances of the different tasks for this subject. [sent-270, score-0.297]
</p><p>91 We can see that very little budget is allocated to the tongue movement and to the most degraded feet 20% tasks, which are the less discriminative actions, and that most of the budget is devoted to the right hand, thus enabling a more efﬁcient training. [sent-271, score-0.855]
</p><p>92 For a budget N > 70 the UCB-classif could not be used for all the subjects because there was not enough data for the best action (One subject only underwent a session of 5 blocks and so only 50 samples of each motor task were recorded. [sent-274, score-0.661]
</p><p>93 If we try to simulate an on-line experiment using the UCB-classif with a budget higher than N = 70 it is likely to ask for a 51th presentation of the best task, which has not been recorded). [sent-275, score-0.231]
</p><p>94 Indeed, Table 3 shows that, to achieve a classiﬁcation rate of 85% the UCB-classif only requires a budget of N = 70 whereas the uniform strategy needs N = 180. [sent-302, score-0.29]
</p><p>95 UCB-classif is a new adaptive algorithm that allows to automatically select a motor task in view of a brain-controlled button. [sent-307, score-0.29]
</p><p>96 By rapidly eliminating non-efﬁcient motor tasks and focusing on the most promising ones, it enables a better task selection procedure than a uniform strategy. [sent-308, score-0.504]
</p><p>97 This algorithm enables to shorten the training period, or equivalently, to allow for a larger set of possible movements among which to select the best. [sent-310, score-0.235]
</p><p>98 Preliminary study for an hybrid BCI using sensorimotor rhythms and beta rebound. [sent-343, score-0.192]
</p><p>99 Electrocorticograms in man: Effect of voluntary movement upon the electrical activity of the precentral gyrus. [sent-404, score-0.308]
</p><p>100 Automatic motor task selection via a bandit algorithm for a brain-controlled button. [sent-456, score-0.503]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('imaginary', 0.543), ('bci', 0.329), ('movement', 0.308), ('bandit', 0.21), ('feet', 0.184), ('eeg', 0.177), ('motor', 0.164), ('smr', 0.146), ('budget', 0.132), ('movements', 0.122), ('button', 0.119), ('action', 0.111), ('tasks', 0.105), ('classi', 0.095), ('subjects', 0.095), ('er', 0.094), ('task', 0.093), ('bands', 0.09), ('idle', 0.081), ('rhythms', 0.081), ('interfaces', 0.079), ('resting', 0.074), ('presentations', 0.071), ('imagined', 0.071), ('strategy', 0.066), ('antipolis', 0.065), ('fruitet', 0.065), ('sophia', 0.065), ('tongue', 0.065), ('rk', 0.065), ('beta', 0.064), ('electrodes', 0.062), ('phase', 0.062), ('mu', 0.061), ('performances', 0.055), ('user', 0.054), ('kt', 0.05), ('actions', 0.05), ('adaptative', 0.049), ('clerc', 0.049), ('dobrea', 0.049), ('sujet', 0.049), ('training', 0.048), ('uniform', 0.048), ('practitioner', 0.047), ('sensorimotor', 0.047), ('ucb', 0.045), ('rate', 0.044), ('moving', 0.043), ('activate', 0.043), ('pfurtscheller', 0.043), ('rebound', 0.043), ('hand', 0.042), ('mcfarland', 0.04), ('best', 0.038), ('windows', 0.037), ('minh', 0.037), ('selection', 0.036), ('erd', 0.035), ('imagine', 0.035), ('went', 0.034), ('degraded', 0.034), ('experiment', 0.034), ('brain', 0.033), ('collect', 0.033), ('select', 0.033), ('users', 0.033), ('classification', 0.033), ('protocol', 0.032), ('lucioles', 0.032), ('prompts', 0.032), ('scalp', 0.032), ('shorten', 0.032), ('tkt', 0.032), ('ideas', 0.032), ('features', 0.032), ('rapidly', 0.031), ('reward', 0.031), ('extracted', 0.029), ('cation', 0.029), ('dk', 0.029), ('budgets', 0.029), ('unadaptive', 0.029), ('cap', 0.029), ('imagining', 0.029), ('highest', 0.028), ('displayed', 0.028), ('dence', 0.028), ('periods', 0.028), ('material', 0.028), ('subject', 0.028), ('exploitation', 0.027), ('images', 0.027), ('promising', 0.027), ('cue', 0.027), ('seconds', 0.027), ('presentation', 0.027), ('recorded', 0.026), ('pulling', 0.026), ('communication', 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="50-tfidf-1" href="./nips-2012-Bandit_Algorithms_boost_Brain_Computer_Interfaces_for_motor-task_selection_of_a_brain-controlled_button.html">50 nips-2012-Bandit Algorithms boost Brain Computer Interfaces for motor-task selection of a brain-controlled button</a></p>
<p>Author: Joan Fruitet, Alexandra Carpentier, Maureen Clerc, Rémi Munos</p><p>Abstract: Brain-computer interfaces (BCI) allow users to “communicate” with a computer without using their muscles. BCI based on sensori-motor rhythms use imaginary motor tasks, such as moving the right or left hand, to send control signals. The performances of a BCI can vary greatly across users but also depend on the tasks used, making the problem of appropriate task selection an important issue. This study presents a new procedure to automatically select as fast as possible a discriminant motor task for a brain-controlled button. We develop for this purpose an adaptive algorithm, UCB-classif , based on the stochastic bandit theory. This shortens the training stage, thereby allowing the exploration of a greater variety of tasks. By not wasting time on inefﬁcient tasks, and focusing on the most promising ones, this algorithm results in a faster task selection and a more efﬁcient use of the BCI training session. Comparing the proposed method to the standard practice in task selection, for a ﬁxed time budget, UCB-classif leads to an improved classiﬁcation rate, and for a ﬁxed classiﬁcation rate, to a reduction of the time spent in training by 50%. 1</p><p>2 0.16356587 <a title="50-tfidf-2" href="./nips-2012-Predicting_Action_Content_On-Line_and_in_Real_Time_before_Action_Onset_%E2%80%93_an_Intracranial_Human_Study.html">273 nips-2012-Predicting Action Content On-Line and in Real Time before Action Onset – an Intracranial Human Study</a></p>
<p>Author: Uri Maoz, Shengxuan Ye, Ian Ross, Adam Mamelak, Christof Koch</p><p>Abstract: The ability to predict action content from neural signals in real time before the action occurs has been long sought in the neuroscientiﬁc study of decision-making, agency and volition. On-line real-time (ORT) prediction is important for understanding the relation between neural correlates of decision-making and conscious, voluntary action as well as for brain-machine interfaces. Here, epilepsy patients, implanted with intracranial depth microelectrodes or subdural grid electrodes for clinical purposes, participated in a “matching-pennies” game against an opponent. In each trial, subjects were given a 5 s countdown, after which they had to raise their left or right hand immediately as the “go” signal appeared on a computer screen. They won a ﬁxed amount of money if they raised a different hand than their opponent and lost that amount otherwise. The question we here studied was the extent to which neural precursors of the subjects’ decisions can be detected in intracranial local ﬁeld potentials (LFP) prior to the onset of the action. We found that combined low-frequency (0.1–5 Hz) LFP signals from 10 electrodes were predictive of the intended left-/right-hand movements before the onset of the go signal. Our ORT system predicted which hand the patient would raise 0.5 s before the go signal with 68±3% accuracy in two patients. Based on these results, we constructed an ORT system that tracked up to 30 electrodes simultaneously, and tested it on retrospective data from 7 patients. On average, we could predict the correct hand choice in 83% of the trials, which rose to 92% if we let the system drop 3/10 of the trials on which it was less conﬁdent. Our system demonstrates— for the ﬁrst time—the feasibility of accurately predicting a binary action on single trials in real time for patients with intracranial recordings, well before the action occurs. 1 1</p><p>3 0.14295116 <a title="50-tfidf-3" href="./nips-2012-Learning_with_Target_Prior.html">198 nips-2012-Learning with Target Prior</a></p>
<p>Author: Zuoguan Wang, Siwei Lyu, Gerwin Schalk, Qiang Ji</p><p>Abstract: In the conventional approaches for supervised parametric learning, relations between data and target variables are provided through training sets consisting of pairs of corresponded data and target variables. In this work, we describe a new learning scheme for parametric learning, in which the target variables y can be modeled with a prior model p(y) and the relations between data and target variables are estimated with p(y) and a set of uncorresponded data X in training. We term this method as learning with target priors (LTP). Speciﬁcally, LTP learning seeks parameter θ that maximizes the log likelihood of fθ (X) on a uncorresponded training set with regards to p(y). Compared to the conventional (semi)supervised learning approach, LTP can make efﬁcient use of prior knowledge of the target variables in the form of probabilistic distributions, and thus removes/reduces the reliance on training data in learning. Compared to the Bayesian approach, the learned parametric regressor in LTP can be more efﬁciently implemented and deployed in tasks where running efﬁciency is critical. We demonstrate the effectiveness of the proposed approach on parametric regression tasks for BCI signal decoding and pose estimation from video. 1</p><p>4 0.12678133 <a title="50-tfidf-4" href="./nips-2012-A_P300_BCI_for_the_Masses%3A_Prior_Information_Enables_Instant_Unsupervised_Spelling.html">14 nips-2012-A P300 BCI for the Masses: Prior Information Enables Instant Unsupervised Spelling</a></p>
<p>Author: Pieter-jan Kindermans, Hannes Verschore, David Verstraeten, Benjamin Schrauwen</p><p>Abstract: The usability of Brain Computer Interfaces (BCI) based on the P300 speller is severely hindered by the need for long training times and many repetitions of the same stimulus. In this contribution we introduce a set of unsupervised hierarchical probabilistic models that tackle both problems simultaneously by incorporating prior knowledge from two sources: information from other training subjects (through transfer learning) and information about the words being spelled (through language models). We show, that due to this prior knowledge, the performance of the unsupervised models parallels and in some cases even surpasses that of supervised models, while eliminating the tedious training session. 1</p><p>5 0.11025884 <a title="50-tfidf-5" href="./nips-2012-Multiple_Operator-valued_Kernel_Learning.html">231 nips-2012-Multiple Operator-valued Kernel Learning</a></p>
<p>Author: Hachem Kadri, Alain Rakotomamonjy, Philippe Preux, Francis R. Bach</p><p>Abstract: Positive deﬁnite operator-valued kernels generalize the well-known notion of reproducing kernels, and are naturally adapted to multi-output learning situations. This paper addresses the problem of learning a ﬁnite linear combination of inﬁnite-dimensional operator-valued kernels which are suitable for extending functional data analysis methods to nonlinear contexts. We study this problem in the case of kernel ridge regression for functional responses with an r -norm constraint on the combination coefﬁcients (r ≥ 1). The resulting optimization problem is more involved than those of multiple scalar-valued kernel learning since operator-valued kernels pose more technical and theoretical issues. We propose a multiple operator-valued kernel learning algorithm based on solving a system of linear operator equations by using a block coordinate-descent procedure. We experimentally validate our approach on a functional regression task in the context of ﬁnger movement prediction in brain-computer interfaces. 1</p><p>6 0.095391907 <a title="50-tfidf-6" href="./nips-2012-Risk-Aversion_in_Multi-armed_Bandits.html">295 nips-2012-Risk-Aversion in Multi-armed Bandits</a></p>
<p>7 0.081075236 <a title="50-tfidf-7" href="./nips-2012-Timely_Object_Recognition.html">344 nips-2012-Timely Object Recognition</a></p>
<p>8 0.08087673 <a title="50-tfidf-8" href="./nips-2012-Local_Supervised_Learning_through_Space_Partitioning.html">200 nips-2012-Local Supervised Learning through Space Partitioning</a></p>
<p>9 0.079339407 <a title="50-tfidf-9" href="./nips-2012-Best_Arm_Identification%3A_A_Unified_Approach_to_Fixed_Budget_and_Fixed_Confidence.html">61 nips-2012-Best Arm Identification: A Unified Approach to Fixed Budget and Fixed Confidence</a></p>
<p>10 0.070508726 <a title="50-tfidf-10" href="./nips-2012-Multi-scale_Hyper-time_Hardware_Emulation_of_Human_Motor_Nervous_System_Based_on_Spiking_Neurons_using_FPGA.html">224 nips-2012-Multi-scale Hyper-time Hardware Emulation of Human Motor Nervous System Based on Spiking Neurons using FPGA</a></p>
<p>11 0.065357722 <a title="50-tfidf-11" href="./nips-2012-Dimensionality_Dependent_PAC-Bayes_Margin_Bound.html">98 nips-2012-Dimensionality Dependent PAC-Bayes Margin Bound</a></p>
<p>12 0.065038294 <a title="50-tfidf-12" href="./nips-2012-Max-Margin_Structured_Output_Regression_for_Spatio-Temporal_Action_Localization.html">209 nips-2012-Max-Margin Structured Output Regression for Spatio-Temporal Action Localization</a></p>
<p>13 0.064085864 <a title="50-tfidf-13" href="./nips-2012-Learning_Multiple_Tasks_using_Shared_Hypotheses.html">181 nips-2012-Learning Multiple Tasks using Shared Hypotheses</a></p>
<p>14 0.06351386 <a title="50-tfidf-14" href="./nips-2012-How_Prior_Probability_Influences_Decision_Making%3A_A_Unifying_Probabilistic_Model.html">153 nips-2012-How Prior Probability Influences Decision Making: A Unifying Probabilistic Model</a></p>
<p>15 0.062832393 <a title="50-tfidf-15" href="./nips-2012-Neurally_Plausible_Reinforcement_Learning_of_Working_Memory_Tasks.html">238 nips-2012-Neurally Plausible Reinforcement Learning of Working Memory Tasks</a></p>
<p>16 0.062721655 <a title="50-tfidf-16" href="./nips-2012-Learning_curves_for_multi-task_Gaussian_process_regression.html">187 nips-2012-Learning curves for multi-task Gaussian process regression</a></p>
<p>17 0.06062318 <a title="50-tfidf-17" href="./nips-2012-Online_Regret_Bounds_for_Undiscounted_Continuous_Reinforcement_Learning.html">259 nips-2012-Online Regret Bounds for Undiscounted Continuous Reinforcement Learning</a></p>
<p>18 0.057417899 <a title="50-tfidf-18" href="./nips-2012-Searching_for_objects_driven_by_context.html">303 nips-2012-Searching for objects driven by context</a></p>
<p>19 0.056926426 <a title="50-tfidf-19" href="./nips-2012-Learned_Prioritization_for_Trading_Off_Accuracy_and_Speed.html">173 nips-2012-Learned Prioritization for Trading Off Accuracy and Speed</a></p>
<p>20 0.054684993 <a title="50-tfidf-20" href="./nips-2012-Transferring_Expectations_in_Model-based_Reinforcement_Learning.html">353 nips-2012-Transferring Expectations in Model-based Reinforcement Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.142), (1, -0.067), (2, -0.055), (3, 0.005), (4, 0.054), (5, 0.013), (6, 0.013), (7, 0.098), (8, -0.059), (9, -0.024), (10, -0.004), (11, 0.052), (12, -0.003), (13, -0.05), (14, -0.006), (15, -0.01), (16, -0.107), (17, 0.058), (18, -0.091), (19, -0.042), (20, 0.054), (21, -0.012), (22, -0.115), (23, -0.052), (24, 0.058), (25, -0.16), (26, 0.04), (27, -0.004), (28, 0.056), (29, 0.058), (30, -0.009), (31, 0.139), (32, 0.01), (33, -0.005), (34, -0.05), (35, -0.062), (36, -0.013), (37, -0.045), (38, -0.062), (39, 0.026), (40, 0.009), (41, -0.229), (42, 0.1), (43, 0.033), (44, -0.135), (45, -0.004), (46, -0.048), (47, 0.034), (48, 0.098), (49, -0.101)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.90598565 <a title="50-lsi-1" href="./nips-2012-Bandit_Algorithms_boost_Brain_Computer_Interfaces_for_motor-task_selection_of_a_brain-controlled_button.html">50 nips-2012-Bandit Algorithms boost Brain Computer Interfaces for motor-task selection of a brain-controlled button</a></p>
<p>Author: Joan Fruitet, Alexandra Carpentier, Maureen Clerc, Rémi Munos</p><p>Abstract: Brain-computer interfaces (BCI) allow users to “communicate” with a computer without using their muscles. BCI based on sensori-motor rhythms use imaginary motor tasks, such as moving the right or left hand, to send control signals. The performances of a BCI can vary greatly across users but also depend on the tasks used, making the problem of appropriate task selection an important issue. This study presents a new procedure to automatically select as fast as possible a discriminant motor task for a brain-controlled button. We develop for this purpose an adaptive algorithm, UCB-classif , based on the stochastic bandit theory. This shortens the training stage, thereby allowing the exploration of a greater variety of tasks. By not wasting time on inefﬁcient tasks, and focusing on the most promising ones, this algorithm results in a faster task selection and a more efﬁcient use of the BCI training session. Comparing the proposed method to the standard practice in task selection, for a ﬁxed time budget, UCB-classif leads to an improved classiﬁcation rate, and for a ﬁxed classiﬁcation rate, to a reduction of the time spent in training by 50%. 1</p><p>2 0.84259003 <a title="50-lsi-2" href="./nips-2012-Predicting_Action_Content_On-Line_and_in_Real_Time_before_Action_Onset_%E2%80%93_an_Intracranial_Human_Study.html">273 nips-2012-Predicting Action Content On-Line and in Real Time before Action Onset – an Intracranial Human Study</a></p>
<p>Author: Uri Maoz, Shengxuan Ye, Ian Ross, Adam Mamelak, Christof Koch</p><p>Abstract: The ability to predict action content from neural signals in real time before the action occurs has been long sought in the neuroscientiﬁc study of decision-making, agency and volition. On-line real-time (ORT) prediction is important for understanding the relation between neural correlates of decision-making and conscious, voluntary action as well as for brain-machine interfaces. Here, epilepsy patients, implanted with intracranial depth microelectrodes or subdural grid electrodes for clinical purposes, participated in a “matching-pennies” game against an opponent. In each trial, subjects were given a 5 s countdown, after which they had to raise their left or right hand immediately as the “go” signal appeared on a computer screen. They won a ﬁxed amount of money if they raised a different hand than their opponent and lost that amount otherwise. The question we here studied was the extent to which neural precursors of the subjects’ decisions can be detected in intracranial local ﬁeld potentials (LFP) prior to the onset of the action. We found that combined low-frequency (0.1–5 Hz) LFP signals from 10 electrodes were predictive of the intended left-/right-hand movements before the onset of the go signal. Our ORT system predicted which hand the patient would raise 0.5 s before the go signal with 68±3% accuracy in two patients. Based on these results, we constructed an ORT system that tracked up to 30 electrodes simultaneously, and tested it on retrospective data from 7 patients. On average, we could predict the correct hand choice in 83% of the trials, which rose to 92% if we let the system drop 3/10 of the trials on which it was less conﬁdent. Our system demonstrates— for the ﬁrst time—the feasibility of accurately predicting a binary action on single trials in real time for patients with intracranial recordings, well before the action occurs. 1 1</p><p>3 0.75703347 <a title="50-lsi-3" href="./nips-2012-A_P300_BCI_for_the_Masses%3A_Prior_Information_Enables_Instant_Unsupervised_Spelling.html">14 nips-2012-A P300 BCI for the Masses: Prior Information Enables Instant Unsupervised Spelling</a></p>
<p>Author: Pieter-jan Kindermans, Hannes Verschore, David Verstraeten, Benjamin Schrauwen</p><p>Abstract: The usability of Brain Computer Interfaces (BCI) based on the P300 speller is severely hindered by the need for long training times and many repetitions of the same stimulus. In this contribution we introduce a set of unsupervised hierarchical probabilistic models that tackle both problems simultaneously by incorporating prior knowledge from two sources: information from other training subjects (through transfer learning) and information about the words being spelled (through language models). We show, that due to this prior knowledge, the performance of the unsupervised models parallels and in some cases even surpasses that of supervised models, while eliminating the tedious training session. 1</p><p>4 0.68625027 <a title="50-lsi-4" href="./nips-2012-Learning_with_Target_Prior.html">198 nips-2012-Learning with Target Prior</a></p>
<p>Author: Zuoguan Wang, Siwei Lyu, Gerwin Schalk, Qiang Ji</p><p>Abstract: In the conventional approaches for supervised parametric learning, relations between data and target variables are provided through training sets consisting of pairs of corresponded data and target variables. In this work, we describe a new learning scheme for parametric learning, in which the target variables y can be modeled with a prior model p(y) and the relations between data and target variables are estimated with p(y) and a set of uncorresponded data X in training. We term this method as learning with target priors (LTP). Speciﬁcally, LTP learning seeks parameter θ that maximizes the log likelihood of fθ (X) on a uncorresponded training set with regards to p(y). Compared to the conventional (semi)supervised learning approach, LTP can make efﬁcient use of prior knowledge of the target variables in the form of probabilistic distributions, and thus removes/reduces the reliance on training data in learning. Compared to the Bayesian approach, the learned parametric regressor in LTP can be more efﬁciently implemented and deployed in tasks where running efﬁciency is critical. We demonstrate the effectiveness of the proposed approach on parametric regression tasks for BCI signal decoding and pose estimation from video. 1</p><p>5 0.63938016 <a title="50-lsi-5" href="./nips-2012-A_systematic_approach_to_extracting_semantic_information_from_functional_MRI_data.html">28 nips-2012-A systematic approach to extracting semantic information from functional MRI data</a></p>
<p>Author: Francisco Pereira, Matthew Botvinick</p><p>Abstract: This paper introduces a novel classiﬁcation method for functional magnetic resonance imaging datasets with tens of classes. The method is designed to make predictions using information from as many brain locations as possible, instead of resorting to feature selection, and does this by decomposing the pattern of brain activation into differently informative sub-regions. We provide results over a complex semantic processing dataset that show that the method is competitive with state-of-the-art feature selection and also suggest how the method may be used to perform group or exploratory analyses of complex class structure. 1</p><p>6 0.50685763 <a title="50-lsi-6" href="./nips-2012-Recognizing_Activities_by_Attribute_Dynamics.html">289 nips-2012-Recognizing Activities by Attribute Dynamics</a></p>
<p>7 0.4534114 <a title="50-lsi-7" href="./nips-2012-Efficient_Monte_Carlo_Counterfactual_Regret_Minimization_in_Games_with_Many_Player_Actions.html">109 nips-2012-Efficient Monte Carlo Counterfactual Regret Minimization in Games with Many Player Actions</a></p>
<p>8 0.43920028 <a title="50-lsi-8" href="./nips-2012-Local_Supervised_Learning_through_Space_Partitioning.html">200 nips-2012-Local Supervised Learning through Space Partitioning</a></p>
<p>9 0.4386425 <a title="50-lsi-9" href="./nips-2012-On_the_connections_between_saliency_and_tracking.html">256 nips-2012-On the connections between saliency and tracking</a></p>
<p>10 0.4375729 <a title="50-lsi-10" href="./nips-2012-Action-Model_Based_Multi-agent_Plan_Recognition.html">31 nips-2012-Action-Model Based Multi-agent Plan Recognition</a></p>
<p>11 0.41211975 <a title="50-lsi-11" href="./nips-2012-Max-Margin_Structured_Output_Regression_for_Spatio-Temporal_Action_Localization.html">209 nips-2012-Max-Margin Structured Output Regression for Spatio-Temporal Action Localization</a></p>
<p>12 0.410377 <a title="50-lsi-12" href="./nips-2012-Learning_Multiple_Tasks_using_Shared_Hypotheses.html">181 nips-2012-Learning Multiple Tasks using Shared Hypotheses</a></p>
<p>13 0.40386811 <a title="50-lsi-13" href="./nips-2012-Kernel_Hyperalignment.html">167 nips-2012-Kernel Hyperalignment</a></p>
<p>14 0.39103577 <a title="50-lsi-14" href="./nips-2012-Projection_Retrieval_for_Classification.html">279 nips-2012-Projection Retrieval for Classification</a></p>
<p>15 0.38479248 <a title="50-lsi-15" href="./nips-2012-Patient_Risk_Stratification_for_Hospital-Associated_C._diff_as_a_Time-Series_Classification_Task.html">266 nips-2012-Patient Risk Stratification for Hospital-Associated C. diff as a Time-Series Classification Task</a></p>
<p>16 0.38127229 <a title="50-lsi-16" href="./nips-2012-Assessing_Blinding_in_Clinical_Trials.html">46 nips-2012-Assessing Blinding in Clinical Trials</a></p>
<p>17 0.37949023 <a title="50-lsi-17" href="./nips-2012-Shifting_Weights%3A_Adapting_Object_Detectors_from_Image_to_Video.html">311 nips-2012-Shifting Weights: Adapting Object Detectors from Image to Video</a></p>
<p>18 0.37530118 <a title="50-lsi-18" href="./nips-2012-Dimensionality_Dependent_PAC-Bayes_Margin_Bound.html">98 nips-2012-Dimensionality Dependent PAC-Bayes Margin Bound</a></p>
<p>19 0.3729887 <a title="50-lsi-19" href="./nips-2012-Multiple_Operator-valued_Kernel_Learning.html">231 nips-2012-Multiple Operator-valued Kernel Learning</a></p>
<p>20 0.37156671 <a title="50-lsi-20" href="./nips-2012-Feature-aware_Label_Space_Dimension_Reduction_for_Multi-label_Classification.html">130 nips-2012-Feature-aware Label Space Dimension Reduction for Multi-label Classification</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.018), (17, 0.034), (21, 0.026), (36, 0.039), (38, 0.115), (42, 0.026), (48, 0.012), (53, 0.012), (54, 0.028), (55, 0.026), (74, 0.048), (76, 0.103), (78, 0.316), (80, 0.067), (92, 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.69937891 <a title="50-lda-1" href="./nips-2012-Bandit_Algorithms_boost_Brain_Computer_Interfaces_for_motor-task_selection_of_a_brain-controlled_button.html">50 nips-2012-Bandit Algorithms boost Brain Computer Interfaces for motor-task selection of a brain-controlled button</a></p>
<p>Author: Joan Fruitet, Alexandra Carpentier, Maureen Clerc, Rémi Munos</p><p>Abstract: Brain-computer interfaces (BCI) allow users to “communicate” with a computer without using their muscles. BCI based on sensori-motor rhythms use imaginary motor tasks, such as moving the right or left hand, to send control signals. The performances of a BCI can vary greatly across users but also depend on the tasks used, making the problem of appropriate task selection an important issue. This study presents a new procedure to automatically select as fast as possible a discriminant motor task for a brain-controlled button. We develop for this purpose an adaptive algorithm, UCB-classif , based on the stochastic bandit theory. This shortens the training stage, thereby allowing the exploration of a greater variety of tasks. By not wasting time on inefﬁcient tasks, and focusing on the most promising ones, this algorithm results in a faster task selection and a more efﬁcient use of the BCI training session. Comparing the proposed method to the standard practice in task selection, for a ﬁxed time budget, UCB-classif leads to an improved classiﬁcation rate, and for a ﬁxed classiﬁcation rate, to a reduction of the time spent in training by 50%. 1</p><p>2 0.49651122 <a title="50-lda-2" href="./nips-2012-Best_Arm_Identification%3A_A_Unified_Approach_to_Fixed_Budget_and_Fixed_Confidence.html">61 nips-2012-Best Arm Identification: A Unified Approach to Fixed Budget and Fixed Confidence</a></p>
<p>Author: Victor Gabillon, Mohammad Ghavamzadeh, Alessandro Lazaric</p><p>Abstract: We study the problem of identifying the best arm(s) in the stochastic multi-armed bandit setting. This problem has been studied in the literature from two different perspectives: ﬁxed budget and ﬁxed conﬁdence. We propose a unifying approach that leads to a meta-algorithm called uniﬁed gap-based exploration (UGapE), with a common structure and similar theoretical analysis for these two settings. We prove a performance bound for the two versions of the algorithm showing that the two problems are characterized by the same notion of complexity. We also show how the UGapE algorithm as well as its theoretical analysis can be extended to take into account the variance of the arms and to multiple bandits. Finally, we evaluate the performance of UGapE and compare it with a number of existing ﬁxed budget and ﬁxed conﬁdence algorithms. 1</p><p>3 0.49562091 <a title="50-lda-3" href="./nips-2012-Clustering_Sparse_Graphs.html">69 nips-2012-Clustering Sparse Graphs</a></p>
<p>Author: Yudong Chen, Sujay Sanghavi, Huan Xu</p><p>Abstract: We develop a new algorithm to cluster sparse unweighted graphs – i.e. partition the nodes into disjoint clusters so that there is higher density within clusters, and low across clusters. By sparsity we mean the setting where both the in-cluster and across cluster edge densities are very small, possibly vanishing in the size of the graph. Sparsity makes the problem noisier, and hence more difﬁcult to solve. Any clustering involves a tradeoff between minimizing two kinds of errors: missing edges within clusters and present edges across clusters. Our insight is that in the sparse case, these must be penalized differently. We analyze our algorithm’s performance on the natural, classical and widely studied “planted partition” model (also called the stochastic block model); we show that our algorithm can cluster sparser graphs, and with smaller clusters, than all previous methods. This is seen empirically as well. 1</p><p>4 0.4952853 <a title="50-lda-4" href="./nips-2012-Controlled_Recognition_Bounds_for_Visual_Learning_and_Exploration.html">83 nips-2012-Controlled Recognition Bounds for Visual Learning and Exploration</a></p>
<p>Author: Vasiliy Karasev, Alessandro Chiuso, Stefano Soatto</p><p>Abstract: We describe the tradeoff between the performance in a visual recognition problem and the control authority that the agent can exercise on the sensing process. We focus on the problem of “visual search” of an object in an otherwise known and static scene, propose a measure of control authority, and relate it to the expected risk and its proxy (conditional entropy of the posterior density). We show this analytically, as well as empirically by simulation using the simplest known model that captures the phenomenology of image formation, including scaling and occlusions. We show that a “passive” agent given a training set can provide no guarantees on performance beyond what is afforded by the priors, and that an “omnipotent” agent, capable of inﬁnite control authority, can achieve arbitrarily good performance (asymptotically). In between these limiting cases, the tradeoff can be characterized empirically. 1</p><p>5 0.49303171 <a title="50-lda-5" href="./nips-2012-Efficient_and_direct_estimation_of_a_neural_subunit_model_for_sensory_coding.html">113 nips-2012-Efficient and direct estimation of a neural subunit model for sensory coding</a></p>
<p>Author: Brett Vintch, Andrew Zaharia, J Movshon, Hhmi) Hhmi), Eero P. Simoncelli</p><p>Abstract: Many visual and auditory neurons have response properties that are well explained by pooling the rectiﬁed responses of a set of spatially shifted linear ﬁlters. These ﬁlters cannot be estimated using spike-triggered averaging (STA). Subspace methods such as spike-triggered covariance (STC) can recover multiple ﬁlters, but require substantial amounts of data, and recover an orthogonal basis for the subspace in which the ﬁlters reside rather than the ﬁlters themselves. Here, we assume a linear-nonlinear–linear-nonlinear (LN-LN) cascade model in which the ﬁrst linear stage is a set of shifted (‘convolutional’) copies of a common ﬁlter, and the ﬁrst nonlinear stage consists of rectifying scalar nonlinearities that are identical for all ﬁlter outputs. We refer to these initial LN elements as the ‘subunits’ of the receptive ﬁeld. The second linear stage then computes a weighted sum of the responses of the rectiﬁed subunits. We present a method for directly ﬁtting this model to spike data, and apply it to both simulated and real neuronal data from primate V1. The subunit model signiﬁcantly outperforms STA and STC in terms of cross-validated accuracy and efﬁciency. 1</p><p>6 0.49231416 <a title="50-lda-6" href="./nips-2012-Inverse_Reinforcement_Learning_through_Structured_Classification.html">162 nips-2012-Inverse Reinforcement Learning through Structured Classification</a></p>
<p>7 0.49227735 <a title="50-lda-7" href="./nips-2012-Algorithms_for_Learning_Markov_Field_Policies.html">38 nips-2012-Algorithms for Learning Markov Field Policies</a></p>
<p>8 0.4918032 <a title="50-lda-8" href="./nips-2012-Forging_The_Graphs%3A_A_Low_Rank_and_Positive_Semidefinite_Graph_Learning_Approach.html">135 nips-2012-Forging The Graphs: A Low Rank and Positive Semidefinite Graph Learning Approach</a></p>
<p>9 0.49176362 <a title="50-lda-9" href="./nips-2012-Synchronization_can_Control_Regularization_in_Neural_Systems_via_Correlated_Noise_Processes.html">333 nips-2012-Synchronization can Control Regularization in Neural Systems via Correlated Noise Processes</a></p>
<p>10 0.49167457 <a title="50-lda-10" href="./nips-2012-Efficient_Spike-Coding_with_Multiplicative_Adaptation_in_a_Spike_Response_Model.html">112 nips-2012-Efficient Spike-Coding with Multiplicative Adaptation in a Spike Response Model</a></p>
<p>11 0.49013618 <a title="50-lda-11" href="./nips-2012-Link_Prediction_in_Graphs_with_Autoregressive_Features.html">199 nips-2012-Link Prediction in Graphs with Autoregressive Features</a></p>
<p>12 0.48974621 <a title="50-lda-12" href="./nips-2012-Structure_estimation_for_discrete_graphical_models%3A_Generalized_covariance_matrices_and_their_inverses.html">326 nips-2012-Structure estimation for discrete graphical models: Generalized covariance matrices and their inverses</a></p>
<p>13 0.48962954 <a title="50-lda-13" href="./nips-2012-Transferring_Expectations_in_Model-based_Reinforcement_Learning.html">353 nips-2012-Transferring Expectations in Model-based Reinforcement Learning</a></p>
<p>14 0.48935339 <a title="50-lda-14" href="./nips-2012-Rational_inference_of_relative_preferences.html">288 nips-2012-Rational inference of relative preferences</a></p>
<p>15 0.48890868 <a title="50-lda-15" href="./nips-2012-Hierarchical_Optimistic_Region_Selection_driven_by_Curiosity.html">149 nips-2012-Hierarchical Optimistic Region Selection driven by Curiosity</a></p>
<p>16 0.4887999 <a title="50-lda-16" href="./nips-2012-Matrix_reconstruction_with_the_local_max_norm.html">208 nips-2012-Matrix reconstruction with the local max norm</a></p>
<p>17 0.48832032 <a title="50-lda-17" href="./nips-2012-Near-Optimal_MAP_Inference_for_Determinantal_Point_Processes.html">236 nips-2012-Near-Optimal MAP Inference for Determinantal Point Processes</a></p>
<p>18 0.48821372 <a title="50-lda-18" href="./nips-2012-Small-Variance_Asymptotics_for_Exponential_Family_Dirichlet_Process_Mixture_Models.html">316 nips-2012-Small-Variance Asymptotics for Exponential Family Dirichlet Process Mixture Models</a></p>
<p>19 0.48778403 <a title="50-lda-19" href="./nips-2012-Hamming_Distance_Metric_Learning.html">148 nips-2012-Hamming Distance Metric Learning</a></p>
<p>20 0.48767257 <a title="50-lda-20" href="./nips-2012-Risk-Aversion_in_Multi-armed_Bandits.html">295 nips-2012-Risk-Aversion in Multi-armed Bandits</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
