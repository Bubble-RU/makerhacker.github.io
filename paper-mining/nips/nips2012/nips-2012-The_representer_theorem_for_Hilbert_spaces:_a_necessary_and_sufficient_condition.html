<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>340 nips-2012-The representer theorem for Hilbert spaces: a necessary and sufficient condition</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-340" href="#">nips2012-340</a> knowledge-graph by maker-knowledge-mining</p><h1>340 nips-2012-The representer theorem for Hilbert spaces: a necessary and sufficient condition</h1>
<br/><p>Source: <a title="nips-2012-340-pdf" href="http://papers.nips.cc/paper/4646-on-the-non-existence-of-convex-calibrated-surrogate-losses-for-ranking.pdf">pdf</a></p><p>Author: Francesco Dinuzzo, Bernhard Schölkopf</p><p>Abstract: The representer theorem is a property that lies at the foundation of regularization theory and kernel methods. A class of regularization functionals is said to admit a linear representer theorem if every member of the class admits minimizers that lie in the ﬁnite dimensional subspace spanned by the representers of the data. A recent characterization states that certain classes of regularization functionals with differentiable regularization term admit a linear representer theorem for any choice of the data if and only if the regularization term is a radial nondecreasing function. In this paper, we extend such result by weakening the assumptions on the regularization term. In particular, the main result of this paper implies that, for a sufﬁciently large family of regularization functionals, radial nondecreasing functions are the only lower semicontinuous regularization terms that guarantee existence of a representer theorem for any choice of the data. 1</p><p>Reference: <a title="nips-2012-340-reference" href="../nips2012_reference/nips-2012-The_representer_theorem_for_Hilbert_spaces%3A_a_necessary_and_sufficient_condition_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('semicontinu', 0.427), ('nondecreas', 0.325), ('sc', 0.285), ('xk', 0.277), ('admit', 0.26), ('regul', 0.244), ('hilbert', 0.213), ('theorem', 0.178), ('rkhs', 0.149), ('rad', 0.144), ('reproduc', 0.12), ('jp', 0.118), ('ak', 0.113), ('kx', 0.107), ('uk', 0.105), ('famy', 0.099), ('li', 0.094), ('kernel', 0.092), ('xn', 0.09), ('yi', 0.089)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="340-tfidf-1" href="./nips-2012-The_representer_theorem_for_Hilbert_spaces%3A_a_necessary_and_sufficient_condition.html">340 nips-2012-The representer theorem for Hilbert spaces: a necessary and sufficient condition</a></p>
<p>2 0.24904475 <a title="340-tfidf-2" href="./nips-2012-Scalable_nonconvex_inexact_proximal_splitting.html">300 nips-2012-Scalable nonconvex inexact proximal splitting</a></p>
<p>3 0.20828286 <a title="340-tfidf-3" href="./nips-2012-Exact_and_Stable_Recovery_of_Sequences_of_Signals_with_Sparse_Increments_via_Differential__1-Minimization.html">120 nips-2012-Exact and Stable Recovery of Sequences of Signals with Sparse Increments via Differential  1-Minimization</a></p>
<p>4 0.16645476 <a title="340-tfidf-4" href="./nips-2012-The_Bethe_Partition_Function_of_Log-supermodular_Graphical_Models.html">335 nips-2012-The Bethe Partition Function of Log-supermodular Graphical Models</a></p>
<p>5 0.16457742 <a title="340-tfidf-5" href="./nips-2012-Proximal_Newton-type_methods_for_convex_optimization.html">282 nips-2012-Proximal Newton-type methods for convex optimization</a></p>
<p>6 0.12769316 <a title="340-tfidf-6" href="./nips-2012-A_Polynomial-time_Form_of_Robust_Regression.html">16 nips-2012-A Polynomial-time Form of Robust Regression</a></p>
<p>7 0.12709817 <a title="340-tfidf-7" href="./nips-2012-Learning_from_Distributions_via_Support_Measure_Machines.html">188 nips-2012-Learning from Distributions via Support Measure Machines</a></p>
<p>8 0.12336997 <a title="340-tfidf-8" href="./nips-2012-Optimal_kernel_choice_for_large-scale_two-sample_tests.html">264 nips-2012-Optimal kernel choice for large-scale two-sample tests</a></p>
<p>9 0.10985883 <a title="340-tfidf-9" href="./nips-2012-Gradient-based_kernel_method_for_feature_extraction_and_variable_selection.html">144 nips-2012-Gradient-based kernel method for feature extraction and variable selection</a></p>
<p>10 0.1042929 <a title="340-tfidf-10" href="./nips-2012-A_quasi-Newton_proximal_splitting_method.html">27 nips-2012-A quasi-Newton proximal splitting method</a></p>
<p>11 0.1023429 <a title="340-tfidf-11" href="./nips-2012-Multiple_Operator-valued_Kernel_Learning.html">231 nips-2012-Multiple Operator-valued Kernel Learning</a></p>
<p>12 0.087929592 <a title="340-tfidf-12" href="./nips-2012-Learning_Halfspaces_with_the_Zero-One_Loss%3A_Time-Accuracy_Tradeoffs.html">174 nips-2012-Learning Halfspaces with the Zero-One Loss: Time-Accuracy Tradeoffs</a></p>
<p>13 0.086454302 <a title="340-tfidf-13" href="./nips-2012-Q-MKL%3A_Matrix-induced_Regularization_in_Multi-Kernel_Learning_with_Applications_to_Neuroimaging.html">284 nips-2012-Q-MKL: Matrix-induced Regularization in Multi-Kernel Learning with Applications to Neuroimaging</a></p>
<p>14 0.086334184 <a title="340-tfidf-14" href="./nips-2012-Stochastic_optimization_and_sparse_statistical_recovery%3A_Optimal_algorithms_for_high_dimensions.html">325 nips-2012-Stochastic optimization and sparse statistical recovery: Optimal algorithms for high dimensions</a></p>
<p>15 0.082024492 <a title="340-tfidf-15" href="./nips-2012-A_Nonparametric_Conjugate_Prior_Distribution_for_the_Maximizing_Argument_of_a_Noisy_Function.html">13 nips-2012-A Nonparametric Conjugate Prior Distribution for the Maximizing Argument of a Noisy Function</a></p>
<p>16 0.078664578 <a title="340-tfidf-16" href="./nips-2012-Learning_Manifolds_with_K-Means_and_K-Flats.html">179 nips-2012-Learning Manifolds with K-Means and K-Flats</a></p>
<p>17 0.076886557 <a title="340-tfidf-17" href="./nips-2012-Pointwise_Tracking_the_Optimal_Regression_Function.html">271 nips-2012-Pointwise Tracking the Optimal Regression Function</a></p>
<p>18 0.075188778 <a title="340-tfidf-18" href="./nips-2012-Learning_as_MAP_Inference_in_Discrete_Graphical_Models.html">186 nips-2012-Learning as MAP Inference in Discrete Graphical Models</a></p>
<p>19 0.075126179 <a title="340-tfidf-19" href="./nips-2012-A_Stochastic_Gradient_Method_with_an_Exponential_Convergence__Rate_for_Finite_Training_Sets.html">20 nips-2012-A Stochastic Gradient Method with an Exponential Convergence  Rate for Finite Training Sets</a></p>
<p>20 0.074834786 <a title="340-tfidf-20" href="./nips-2012-Recovery_of_Sparse_Probability_Measures_via_Convex_Programming.html">290 nips-2012-Recovery of Sparse Probability Measures via Convex Programming</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.195), (1, -0.024), (2, 0.115), (3, -0.043), (4, 0.05), (5, 0.205), (6, -0.006), (7, -0.008), (8, -0.06), (9, 0.053), (10, 0.15), (11, -0.029), (12, -0.114), (13, 0.101), (14, -0.083), (15, -0.112), (16, -0.038), (17, -0.137), (18, 0.002), (19, -0.017), (20, -0.026), (21, -0.058), (22, 0.067), (23, -0.002), (24, 0.015), (25, 0.115), (26, -0.068), (27, 0.053), (28, 0.007), (29, 0.056), (30, 0.031), (31, 0.003), (32, -0.045), (33, 0.07), (34, 0.06), (35, -0.069), (36, -0.004), (37, -0.07), (38, -0.055), (39, -0.034), (40, -0.023), (41, -0.045), (42, -0.065), (43, 0.015), (44, -0.074), (45, -0.016), (46, 0.025), (47, -0.006), (48, 0.042), (49, -0.078)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92278671 <a title="340-lsi-1" href="./nips-2012-The_representer_theorem_for_Hilbert_spaces%3A_a_necessary_and_sufficient_condition.html">340 nips-2012-The representer theorem for Hilbert spaces: a necessary and sufficient condition</a></p>
<p>2 0.76451623 <a title="340-lsi-2" href="./nips-2012-Scalable_nonconvex_inexact_proximal_splitting.html">300 nips-2012-Scalable nonconvex inexact proximal splitting</a></p>
<p>3 0.73285639 <a title="340-lsi-3" href="./nips-2012-Exact_and_Stable_Recovery_of_Sequences_of_Signals_with_Sparse_Increments_via_Differential__1-Minimization.html">120 nips-2012-Exact and Stable Recovery of Sequences of Signals with Sparse Increments via Differential  1-Minimization</a></p>
<p>4 0.66466731 <a title="340-lsi-4" href="./nips-2012-Proximal_Newton-type_methods_for_convex_optimization.html">282 nips-2012-Proximal Newton-type methods for convex optimization</a></p>
<p>5 0.62151676 <a title="340-lsi-5" href="./nips-2012-The_Bethe_Partition_Function_of_Log-supermodular_Graphical_Models.html">335 nips-2012-The Bethe Partition Function of Log-supermodular Graphical Models</a></p>
<p>6 0.60594761 <a title="340-lsi-6" href="./nips-2012-A_quasi-Newton_proximal_splitting_method.html">27 nips-2012-A quasi-Newton proximal splitting method</a></p>
<p>7 0.59413069 <a title="340-lsi-7" href="./nips-2012-Optimal_kernel_choice_for_large-scale_two-sample_tests.html">264 nips-2012-Optimal kernel choice for large-scale two-sample tests</a></p>
<p>8 0.5832957 <a title="340-lsi-8" href="./nips-2012-Multiple_Operator-valued_Kernel_Learning.html">231 nips-2012-Multiple Operator-valued Kernel Learning</a></p>
<p>9 0.57911122 <a title="340-lsi-9" href="./nips-2012-Learning_from_Distributions_via_Support_Measure_Machines.html">188 nips-2012-Learning from Distributions via Support Measure Machines</a></p>
<p>10 0.56567156 <a title="340-lsi-10" href="./nips-2012-Nystr%C3%B6m_Method_vs_Random_Fourier_Features%3A_A_Theoretical_and_Empirical_Comparison.html">249 nips-2012-Nyström Method vs Random Fourier Features: A Theoretical and Empirical Comparison</a></p>
<p>11 0.55851758 <a title="340-lsi-11" href="./nips-2012-Gradient-based_kernel_method_for_feature_extraction_and_variable_selection.html">144 nips-2012-Gradient-based kernel method for feature extraction and variable selection</a></p>
<p>12 0.53124136 <a title="340-lsi-12" href="./nips-2012-Q-MKL%3A_Matrix-induced_Regularization_in_Multi-Kernel_Learning_with_Applications_to_Neuroimaging.html">284 nips-2012-Q-MKL: Matrix-induced Regularization in Multi-Kernel Learning with Applications to Neuroimaging</a></p>
<p>13 0.52162254 <a title="340-lsi-13" href="./nips-2012-Learning_Halfspaces_with_the_Zero-One_Loss%3A_Time-Accuracy_Tradeoffs.html">174 nips-2012-Learning Halfspaces with the Zero-One Loss: Time-Accuracy Tradeoffs</a></p>
<p>14 0.51484847 <a title="340-lsi-14" href="./nips-2012-Kernel_Hyperalignment.html">167 nips-2012-Kernel Hyperalignment</a></p>
<p>15 0.51312387 <a title="340-lsi-15" href="./nips-2012-A_Stochastic_Gradient_Method_with_an_Exponential_Convergence__Rate_for_Finite_Training_Sets.html">20 nips-2012-A Stochastic Gradient Method with an Exponential Convergence  Rate for Finite Training Sets</a></p>
<p>16 0.50694019 <a title="340-lsi-16" href="./nips-2012-Active_Learning_of_Multi-Index_Function_Models.html">34 nips-2012-Active Learning of Multi-Index Function Models</a></p>
<p>17 0.45652926 <a title="340-lsi-17" href="./nips-2012-Approximating_Concavely_Parameterized_Optimization_Problems.html">44 nips-2012-Approximating Concavely Parameterized Optimization Problems</a></p>
<p>18 0.45130411 <a title="340-lsi-18" href="./nips-2012-Gradient_Weights_help_Nonparametric_Regressors.html">145 nips-2012-Gradient Weights help Nonparametric Regressors</a></p>
<p>19 0.44806838 <a title="340-lsi-19" href="./nips-2012-Recovery_of_Sparse_Probability_Measures_via_Convex_Programming.html">290 nips-2012-Recovery of Sparse Probability Measures via Convex Programming</a></p>
<p>20 0.44015133 <a title="340-lsi-20" href="./nips-2012-A_Polynomial-time_Form_of_Robust_Regression.html">16 nips-2012-A Polynomial-time Form of Robust Regression</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(11, 0.054), (47, 0.064), (67, 0.027), (70, 0.059), (85, 0.022), (94, 0.622), (99, 0.063)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98591435 <a title="340-lda-1" href="./nips-2012-The_representer_theorem_for_Hilbert_spaces%3A_a_necessary_and_sufficient_condition.html">340 nips-2012-The representer theorem for Hilbert spaces: a necessary and sufficient condition</a></p>
<p>2 0.97850502 <a title="340-lda-2" href="./nips-2012-A_new_metric_on_the_manifold_of_kernel_matrices_with_application_to_matrix_geometric_means.html">25 nips-2012-A new metric on the manifold of kernel matrices with application to matrix geometric means</a></p>
<p>3 0.97163612 <a title="340-lda-3" href="./nips-2012-Scalable_Inference_of_Overlapping_Communities.html">298 nips-2012-Scalable Inference of Overlapping Communities</a></p>
<p>4 0.96081728 <a title="340-lda-4" href="./nips-2012-Spectral_Learning_of_General_Weighted_Automata_via_Constrained_Matrix_Completion.html">320 nips-2012-Spectral Learning of General Weighted Automata via Constrained Matrix Completion</a></p>
<p>5 0.95959908 <a title="340-lda-5" href="./nips-2012-Towards_a_learning-theoretic_analysis_of_spike-timing_dependent_plasticity.html">347 nips-2012-Towards a learning-theoretic analysis of spike-timing dependent plasticity</a></p>
<p>6 0.95587373 <a title="340-lda-6" href="./nips-2012-Learning_as_MAP_Inference_in_Discrete_Graphical_Models.html">186 nips-2012-Learning as MAP Inference in Discrete Graphical Models</a></p>
<p>7 0.93885267 <a title="340-lda-7" href="./nips-2012-Accuracy_at_the_Top.html">30 nips-2012-Accuracy at the Top</a></p>
<p>8 0.9373551 <a title="340-lda-8" href="./nips-2012-Monte_Carlo_Methods_for_Maximum_Margin_Supervised_Topic_Models.html">220 nips-2012-Monte Carlo Methods for Maximum Margin Supervised Topic Models</a></p>
<p>9 0.89691132 <a title="340-lda-9" href="./nips-2012-Scalable_nonconvex_inexact_proximal_splitting.html">300 nips-2012-Scalable nonconvex inexact proximal splitting</a></p>
<p>10 0.89604861 <a title="340-lda-10" href="./nips-2012-Learning_optimal_spike-based_representations.html">190 nips-2012-Learning optimal spike-based representations</a></p>
<p>11 0.89409041 <a title="340-lda-11" href="./nips-2012-Proximal_Newton-type_methods_for_convex_optimization.html">282 nips-2012-Proximal Newton-type methods for convex optimization</a></p>
<p>12 0.87255114 <a title="340-lda-12" href="./nips-2012-Convergence_and_Energy_Landscape_for_Cheeger_Cut_Clustering.html">85 nips-2012-Convergence and Energy Landscape for Cheeger Cut Clustering</a></p>
<p>13 0.86840641 <a title="340-lda-13" href="./nips-2012-Query_Complexity_of_Derivative-Free_Optimization.html">285 nips-2012-Query Complexity of Derivative-Free Optimization</a></p>
<p>14 0.86582643 <a title="340-lda-14" href="./nips-2012-Learning_the_Dependency_Structure_of_Latent_Factors.html">192 nips-2012-Learning the Dependency Structure of Latent Factors</a></p>
<p>15 0.86571676 <a title="340-lda-15" href="./nips-2012-Multiple_Operator-valued_Kernel_Learning.html">231 nips-2012-Multiple Operator-valued Kernel Learning</a></p>
<p>16 0.86487579 <a title="340-lda-16" href="./nips-2012-Stochastic_Gradient_Descent_with_Only_One_Projection.html">324 nips-2012-Stochastic Gradient Descent with Only One Projection</a></p>
<p>17 0.86422294 <a title="340-lda-17" href="./nips-2012-Finite_Sample_Convergence_Rates_of_Zero-Order_Stochastic_Optimization_Methods.html">134 nips-2012-Finite Sample Convergence Rates of Zero-Order Stochastic Optimization Methods</a></p>
<p>18 0.86290574 <a title="340-lda-18" href="./nips-2012-Scaling_MPE_Inference_for_Constrained_Continuous_Markov_Random_Fields_with_Consensus_Optimization.html">302 nips-2012-Scaling MPE Inference for Constrained Continuous Markov Random Fields with Consensus Optimization</a></p>
<p>19 0.86159563 <a title="340-lda-19" href="./nips-2012-Parametric_Local_Metric_Learning_for_Nearest_Neighbor_Classification.html">265 nips-2012-Parametric Local Metric Learning for Nearest Neighbor Classification</a></p>
<p>20 0.86087966 <a title="340-lda-20" href="./nips-2012-Optimal_Regularized_Dual_Averaging_Methods_for_Stochastic_Optimization.html">263 nips-2012-Optimal Regularized Dual Averaging Methods for Stochastic Optimization</a></p>
<br/><br/><br/></body>
</html>
