<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>236 nips-2012-Near-Optimal MAP Inference for Determinantal Point Processes</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-236" href="#">nips2012-236</a> knowledge-graph by maker-knowledge-mining</p><h1>236 nips-2012-Near-Optimal MAP Inference for Determinantal Point Processes</h1>
<br/><p>Source: <a title="nips-2012-236-pdf" href="http://papers.nips.cc/paper/4577-near-optimal-map-inference-for-determinantal-point-processes.pdf">pdf</a></p><p>Author: Jennifer Gillenwater, Alex Kulesza, Ben Taskar</p><p>Abstract: Determinantal point processes (DPPs) have recently been proposed as computationally efﬁcient probabilistic models of diverse sets for a variety of applications, including document summarization, image search, and pose estimation. Many DPP inference operations, including normalization and sampling, are tractable; however, ﬁnding the most likely conﬁguration (MAP), which is often required in practice for decoding, is NP-hard, so we must resort to approximate inference. This optimization problem, which also arises in experimental design and sensor placement, involves ﬁnding the largest principal minor of a positive semideﬁnite matrix. Because the objective is log-submodular, greedy algorithms have been used in the past with some empirical success; however, these methods only give approximation guarantees in the special case of monotone objectives, which correspond to a restricted class of DPPs. In this paper we propose a new algorithm for approximating the MAP problem based on continuous techniques for submodular function maximization. Our method involves a novel continuous relaxation of the log-probability function, which, in contrast to the multilinear extension used for general submodular functions, can be evaluated and differentiated exactly and efﬁciently. We obtain a practical algorithm with a 1/4-approximation guarantee for a more general class of non-monotone DPPs; our algorithm also extends to MAP inference under complex polytope constraints, making it possible to combine DPPs with Markov random ﬁelds, weighted matchings, and other models. We demonstrate that our approach outperforms standard and recent methods on both synthetic and real-world data. 1</p><p>Reference: <a title="nips-2012-236-reference" href="../nips2012_reference/nips-2012-Near-Optimal_MAP_Inference_for_Determinantal_Point_Processes_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('dpp', 0.446), ('submodul', 0.367), ('dpps', 0.361), ('ly', 0.313), ('det', 0.26), ('polytop', 0.26), ('quot', 0.211), ('multilinear', 0.202), ('greedy', 0.192), ('round', 0.112), ('softmax', 0.11), ('unconstrain', 0.08), ('kulesz', 0.078), ('divers', 0.069), ('candid', 0.065), ('pip', 0.064), ('ratio', 0.059), ('wolsey', 0.059), ('feldm', 0.055), ('naor', 0.055)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="236-tfidf-1" href="./nips-2012-Near-Optimal_MAP_Inference_for_Determinantal_Point_Processes.html">236 nips-2012-Near-Optimal MAP Inference for Determinantal Point Processes</a></p>
<p>2 0.36651787 <a title="236-tfidf-2" href="./nips-2012-Priors_for_Diversity_in_Generative_Latent_Variable_Models.html">274 nips-2012-Priors for Diversity in Generative Latent Variable Models</a></p>
<p>3 0.28975478 <a title="236-tfidf-3" href="./nips-2012-Selecting_Diverse_Features_via_Spectral_Regularization.html">304 nips-2012-Selecting Diverse Features via Spectral Regularization</a></p>
<p>4 0.2282715 <a title="236-tfidf-4" href="./nips-2012-A_Convex_Formulation_for_Learning_Scale-Free_Networks_via_Submodular_Relaxation.html">6 nips-2012-A Convex Formulation for Learning Scale-Free Networks via Submodular Relaxation</a></p>
<p>5 0.22394791 <a title="236-tfidf-5" href="./nips-2012-Submodular-Bregman_and_the_Lov%C3%A1sz-Bregman_Divergences_with_Applications.html">328 nips-2012-Submodular-Bregman and the Lovász-Bregman Divergences with Applications</a></p>
<p>6 0.12722673 <a title="236-tfidf-6" href="./nips-2012-Minimizing_Sparse_High-Order_Energies_by_Submodular_Vertex-Cover.html">214 nips-2012-Minimizing Sparse High-Order Energies by Submodular Vertex-Cover</a></p>
<p>7 0.11346065 <a title="236-tfidf-7" href="./nips-2012-A_Divide-and-Conquer_Method_for_Sparse_Inverse_Covariance_Estimation.html">7 nips-2012-A Divide-and-Conquer Method for Sparse Inverse Covariance Estimation</a></p>
<p>8 0.10483433 <a title="236-tfidf-8" href="./nips-2012-A_Polylog_Pivot_Steps_Simplex_Algorithm_for_Classification.html">15 nips-2012-A Polylog Pivot Steps Simplex Algorithm for Classification</a></p>
<p>9 0.09482047 <a title="236-tfidf-9" href="./nips-2012-A_new_metric_on_the_manifold_of_kernel_matrices_with_application_to_matrix_geometric_means.html">25 nips-2012-A new metric on the manifold of kernel matrices with application to matrix geometric means</a></p>
<p>10 0.086670563 <a title="236-tfidf-10" href="./nips-2012-Convergence_Rate_Analysis_of_MAP_Coordinate_Minimization_Algorithms.html">84 nips-2012-Convergence Rate Analysis of MAP Coordinate Minimization Algorithms</a></p>
<p>11 0.080376625 <a title="236-tfidf-11" href="./nips-2012-Learning_as_MAP_Inference_in_Discrete_Graphical_Models.html">186 nips-2012-Learning as MAP Inference in Discrete Graphical Models</a></p>
<p>12 0.069931455 <a title="236-tfidf-12" href="./nips-2012-GenDeR%3A_A_Generic_Diversified_Ranking_Algorithm.html">141 nips-2012-GenDeR: A Generic Diversified Ranking Algorithm</a></p>
<p>13 0.066511579 <a title="236-tfidf-13" href="./nips-2012-Iterative_Thresholding_Algorithm_for_Sparse_Inverse_Covariance_Estimation.html">164 nips-2012-Iterative Thresholding Algorithm for Sparse Inverse Covariance Estimation</a></p>
<p>14 0.05889535 <a title="236-tfidf-14" href="./nips-2012-A_Neural_Autoregressive_Topic_Model.html">12 nips-2012-A Neural Autoregressive Topic Model</a></p>
<p>15 0.054262497 <a title="236-tfidf-15" href="./nips-2012-Efficient_Sampling_for_Bipartite_Matching_Problems.html">111 nips-2012-Efficient Sampling for Bipartite Matching Problems</a></p>
<p>16 0.052776076 <a title="236-tfidf-16" href="./nips-2012-A_Polynomial-time_Form_of_Robust_Regression.html">16 nips-2012-A Polynomial-time Form of Robust Regression</a></p>
<p>17 0.049613953 <a title="236-tfidf-17" href="./nips-2012-MAP_Inference_in_Chains_using_Column_Generation.html">204 nips-2012-MAP Inference in Chains using Column Generation</a></p>
<p>18 0.049233761 <a title="236-tfidf-18" href="./nips-2012-Multiple_Choice_Learning%3A_Learning_to_Produce_Multiple_Structured_Outputs.html">230 nips-2012-Multiple Choice Learning: Learning to Produce Multiple Structured Outputs</a></p>
<p>19 0.048167553 <a title="236-tfidf-19" href="./nips-2012-Timely_Object_Recognition.html">344 nips-2012-Timely Object Recognition</a></p>
<p>20 0.047768261 <a title="236-tfidf-20" href="./nips-2012-Probabilistic_n-Choose-k_Models_for_Classification_and_Ranking.html">278 nips-2012-Probabilistic n-Choose-k Models for Classification and Ranking</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.168), (1, -0.011), (2, 0.078), (3, 0.023), (4, 0.079), (5, 0.027), (6, 0.003), (7, -0.019), (8, 0.043), (9, 0.029), (10, -0.048), (11, -0.003), (12, -0.023), (13, 0.026), (14, 0.251), (15, 0.071), (16, -0.011), (17, 0.149), (18, 0.163), (19, -0.152), (20, 0.112), (21, -0.195), (22, 0.138), (23, -0.236), (24, -0.139), (25, 0.024), (26, -0.051), (27, 0.121), (28, -0.08), (29, 0.033), (30, -0.041), (31, -0.013), (32, 0.037), (33, 0.148), (34, -0.101), (35, -0.002), (36, -0.062), (37, 0.016), (38, 0.07), (39, -0.021), (40, -0.001), (41, -0.001), (42, -0.013), (43, -0.002), (44, -0.044), (45, 0.047), (46, 0.073), (47, 0.038), (48, -0.048), (49, 0.01)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.84779936 <a title="236-lsi-1" href="./nips-2012-Near-Optimal_MAP_Inference_for_Determinantal_Point_Processes.html">236 nips-2012-Near-Optimal MAP Inference for Determinantal Point Processes</a></p>
<p>2 0.80456823 <a title="236-lsi-2" href="./nips-2012-Submodular-Bregman_and_the_Lov%C3%A1sz-Bregman_Divergences_with_Applications.html">328 nips-2012-Submodular-Bregman and the Lovász-Bregman Divergences with Applications</a></p>
<p>3 0.75973433 <a title="236-lsi-3" href="./nips-2012-Selecting_Diverse_Features_via_Spectral_Regularization.html">304 nips-2012-Selecting Diverse Features via Spectral Regularization</a></p>
<p>4 0.62924838 <a title="236-lsi-4" href="./nips-2012-Minimizing_Sparse_High-Order_Energies_by_Submodular_Vertex-Cover.html">214 nips-2012-Minimizing Sparse High-Order Energies by Submodular Vertex-Cover</a></p>
<p>5 0.51267219 <a title="236-lsi-5" href="./nips-2012-A_Convex_Formulation_for_Learning_Scale-Free_Networks_via_Submodular_Relaxation.html">6 nips-2012-A Convex Formulation for Learning Scale-Free Networks via Submodular Relaxation</a></p>
<p>6 0.49753925 <a title="236-lsi-6" href="./nips-2012-Priors_for_Diversity_in_Generative_Latent_Variable_Models.html">274 nips-2012-Priors for Diversity in Generative Latent Variable Models</a></p>
<p>7 0.41913611 <a title="236-lsi-7" href="./nips-2012-GenDeR%3A_A_Generic_Diversified_Ranking_Algorithm.html">141 nips-2012-GenDeR: A Generic Diversified Ranking Algorithm</a></p>
<p>8 0.33249751 <a title="236-lsi-8" href="./nips-2012-Variational_Inference_for_Crowdsourcing.html">359 nips-2012-Variational Inference for Crowdsourcing</a></p>
<p>9 0.30059209 <a title="236-lsi-9" href="./nips-2012-CPRL_--_An_Extension_of_Compressive_Sensing_to_the_Phase_Retrieval_Problem.html">63 nips-2012-CPRL -- An Extension of Compressive Sensing to the Phase Retrieval Problem</a></p>
<p>10 0.29803208 <a title="236-lsi-10" href="./nips-2012-A_Polylog_Pivot_Steps_Simplex_Algorithm_for_Classification.html">15 nips-2012-A Polylog Pivot Steps Simplex Algorithm for Classification</a></p>
<p>11 0.26789063 <a title="236-lsi-11" href="./nips-2012-Accuracy_at_the_Top.html">30 nips-2012-Accuracy at the Top</a></p>
<p>12 0.26267406 <a title="236-lsi-12" href="./nips-2012-Non-parametric_Approximate_Dynamic_Programming_via_the_Kernel_Method.html">243 nips-2012-Non-parametric Approximate Dynamic Programming via the Kernel Method</a></p>
<p>13 0.26126269 <a title="236-lsi-13" href="./nips-2012-Convergence_and_Energy_Landscape_for_Cheeger_Cut_Clustering.html">85 nips-2012-Convergence and Energy Landscape for Cheeger Cut Clustering</a></p>
<p>14 0.25962827 <a title="236-lsi-14" href="./nips-2012-Scaling_MPE_Inference_for_Constrained_Continuous_Markov_Random_Fields_with_Consensus_Optimization.html">302 nips-2012-Scaling MPE Inference for Constrained Continuous Markov Random Fields with Consensus Optimization</a></p>
<p>15 0.25804982 <a title="236-lsi-15" href="./nips-2012-Value_Pursuit_Iteration.html">358 nips-2012-Value Pursuit Iteration</a></p>
<p>16 0.25757429 <a title="236-lsi-16" href="./nips-2012-Spectral_Learning_of_General_Weighted_Automata_via_Constrained_Matrix_Completion.html">320 nips-2012-Spectral Learning of General Weighted Automata via Constrained Matrix Completion</a></p>
<p>17 0.25713587 <a title="236-lsi-17" href="./nips-2012-A_new_metric_on_the_manifold_of_kernel_matrices_with_application_to_matrix_geometric_means.html">25 nips-2012-A new metric on the manifold of kernel matrices with application to matrix geometric means</a></p>
<p>18 0.25654137 <a title="236-lsi-18" href="./nips-2012-Factorial_LDA%3A_Sparse_Multi-Dimensional_Text_Models.html">124 nips-2012-Factorial LDA: Sparse Multi-Dimensional Text Models</a></p>
<p>19 0.2534841 <a title="236-lsi-19" href="./nips-2012-A_Neural_Autoregressive_Topic_Model.html">12 nips-2012-A Neural Autoregressive Topic Model</a></p>
<p>20 0.25186315 <a title="236-lsi-20" href="./nips-2012-Multi-Stage_Multi-Task_Feature_Learning.html">221 nips-2012-Multi-Stage Multi-Task Feature Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(11, 0.079), (47, 0.173), (61, 0.247), (64, 0.011), (67, 0.057), (70, 0.072), (85, 0.058), (86, 0.01), (94, 0.153), (99, 0.037)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.81528312 <a title="236-lda-1" href="./nips-2012-Near-Optimal_MAP_Inference_for_Determinantal_Point_Processes.html">236 nips-2012-Near-Optimal MAP Inference for Determinantal Point Processes</a></p>
<p>2 0.80247283 <a title="236-lda-2" href="./nips-2012-A_Neural_Autoregressive_Topic_Model.html">12 nips-2012-A Neural Autoregressive Topic Model</a></p>
<p>3 0.79485762 <a title="236-lda-3" href="./nips-2012-Parametric_Local_Metric_Learning_for_Nearest_Neighbor_Classification.html">265 nips-2012-Parametric Local Metric Learning for Nearest Neighbor Classification</a></p>
<p>4 0.75892639 <a title="236-lda-4" href="./nips-2012-Active_Comparison_of_Prediction_Models.html">32 nips-2012-Active Comparison of Prediction Models</a></p>
<p>5 0.73116761 <a title="236-lda-5" href="./nips-2012-Dual-Space_Analysis_of_the_Sparse_Linear_Model.html">104 nips-2012-Dual-Space Analysis of the Sparse Linear Model</a></p>
<p>6 0.73045188 <a title="236-lda-6" href="./nips-2012-Convergence_Rate_Analysis_of_MAP_Coordinate_Minimization_Algorithms.html">84 nips-2012-Convergence Rate Analysis of MAP Coordinate Minimization Algorithms</a></p>
<p>7 0.72980583 <a title="236-lda-7" href="./nips-2012-Clustering_Sparse_Graphs.html">69 nips-2012-Clustering Sparse Graphs</a></p>
<p>8 0.72971404 <a title="236-lda-8" href="./nips-2012-Multi-Stage_Multi-Task_Feature_Learning.html">221 nips-2012-Multi-Stage Multi-Task Feature Learning</a></p>
<p>9 0.72931015 <a title="236-lda-9" href="./nips-2012-Collaborative_Gaussian_Processes_for_Preference_Learning.html">74 nips-2012-Collaborative Gaussian Processes for Preference Learning</a></p>
<p>10 0.72815895 <a title="236-lda-10" href="./nips-2012-Probabilistic_n-Choose-k_Models_for_Classification_and_Ranking.html">278 nips-2012-Probabilistic n-Choose-k Models for Classification and Ranking</a></p>
<p>11 0.72756279 <a title="236-lda-11" href="./nips-2012-Recovery_of_Sparse_Probability_Measures_via_Convex_Programming.html">290 nips-2012-Recovery of Sparse Probability Measures via Convex Programming</a></p>
<p>12 0.7274918 <a title="236-lda-12" href="./nips-2012-Learning_Mixtures_of_Tree_Graphical_Models.html">180 nips-2012-Learning Mixtures of Tree Graphical Models</a></p>
<p>13 0.72732818 <a title="236-lda-13" href="./nips-2012-Link_Prediction_in_Graphs_with_Autoregressive_Features.html">199 nips-2012-Link Prediction in Graphs with Autoregressive Features</a></p>
<p>14 0.72730076 <a title="236-lda-14" href="./nips-2012-Training_sparse_natural_image_models_with_a_fast_Gibbs_sampler_of_an_extended_state_space.html">349 nips-2012-Training sparse natural image models with a fast Gibbs sampler of an extended state space</a></p>
<p>15 0.72724628 <a title="236-lda-15" href="./nips-2012-Learning_with_Target_Prior.html">198 nips-2012-Learning with Target Prior</a></p>
<p>16 0.72714287 <a title="236-lda-16" href="./nips-2012-Latent_Graphical_Model_Selection%3A_Efficient_Methods_for_Locally_Tree-like_Graphs.html">172 nips-2012-Latent Graphical Model Selection: Efficient Methods for Locally Tree-like Graphs</a></p>
<p>17 0.72703201 <a title="236-lda-17" href="./nips-2012-Topology_Constraints_in_Graphical_Models.html">346 nips-2012-Topology Constraints in Graphical Models</a></p>
<p>18 0.72658587 <a title="236-lda-18" href="./nips-2012-Repulsive_Mixtures.html">294 nips-2012-Repulsive Mixtures</a></p>
<p>19 0.72595727 <a title="236-lda-19" href="./nips-2012-A_Scalable_CUR_Matrix_Decomposition_Algorithm%3A_Lower_Time_Complexity_and_Tighter_Bound.html">17 nips-2012-A Scalable CUR Matrix Decomposition Algorithm: Lower Time Complexity and Tighter Bound</a></p>
<p>20 0.72567475 <a title="236-lda-20" href="./nips-2012-Sketch-Based_Linear_Value_Function_Approximation.html">313 nips-2012-Sketch-Based Linear Value Function Approximation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
