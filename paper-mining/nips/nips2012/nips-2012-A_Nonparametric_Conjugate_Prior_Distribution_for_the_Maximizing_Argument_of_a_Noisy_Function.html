<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>13 nips-2012-A Nonparametric Conjugate Prior Distribution for the Maximizing Argument of a Noisy Function</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-13" href="#">nips2012-13</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>13 nips-2012-A Nonparametric Conjugate Prior Distribution for the Maximizing Argument of a Noisy Function</h1>
<br/><p>Source: <a title="nips-2012-13-pdf" href="http://papers.nips.cc/paper/4536-a-nonparametric-conjugate-prior-distribution-for-the-maximizing-argument-of-a-noisy-function.pdf">pdf</a></p><p>Author: Pedro Ortega, Jordi Grau-moya, Tim Genewein, David Balduzzi, Daniel Braun</p><p>Abstract: We propose a novel Bayesian approach to solve stochastic optimization problems that involve ﬁnding extrema of noisy, nonlinear functions. Previous work has focused on representing possible functions explicitly, which leads to a two-step procedure of ﬁrst, doing inference over the function space and second, ﬁnding the extrema of these functions. Here we skip the representation step and directly model the distribution over extrema. To this end, we devise a non-parametric conjugate prior based on a kernel regressor. The resulting posterior distribution directly captures the uncertainty over the maximum of the unknown function. Given t observations of the function, the posterior can be evaluated efﬁciently in time O(t2 ) up to a multiplicative constant. Finally, we show how to apply our model to optimize a noisy, non-convex, high-dimensional objective function.</p><p>Reference: <a title="nips-2012-13-reference" href="../nips2012_reference/nips-2012-A_Nonparametric_Conjugate_Prior_Distribution_for_the_Maximizing_Argument_of_a_Noisy_Function_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 de  Abstract We propose a novel Bayesian approach to solve stochastic optimization problems that involve ﬁnding extrema of noisy, nonlinear functions. [sent-22, score-0.189]
</p><p>2 To this end, we devise a non-parametric conjugate prior based on a kernel regressor. [sent-25, score-0.298]
</p><p>3 The resulting posterior distribution directly captures the uncertainty over the maximum of the unknown function. [sent-26, score-0.189]
</p><p>4 Given t observations of the function, the posterior can be evaluated efﬁciently in time O(t2 ) up to a multiplicative constant. [sent-27, score-0.242]
</p><p>5 1 Introduction Historically, the ﬁelds of statistical inference and stochastic optimization have often developed their own speciﬁc methods and approaches. [sent-29, score-0.121]
</p><p>6 Here we consider stochastic optimization problems where we observe noise-contaminated values from an unknown nonlinear function and we want to ﬁnd the input that maximizes the expected value of this function. [sent-31, score-0.121]
</p><p>7 Consider a stochastic function f :X R mapping a test point x ∈ X to real values y ∈ R characterized by the conditional pdf P (y|x). [sent-34, score-0.235]
</p><p>8 (1)  The goal consists in modeling the optimal test point ¯ x∗ := arg max{f (x)}. [sent-36, score-0.107]
</p><p>9 5  3  ¯ Figure 1: a) Given an estimate h of the mean function f (left), a simple probability density function over the location of the maximum x∗ is obtained using the transformation P (x∗ ) ∝ exp{αh(x∗ )}, where α > 0 plays the role of the precision (right). [sent-47, score-0.426]
</p><p>10 b) Illustration of the Gramian matrix for different test locations. [sent-48, score-0.074]
</p><p>11 Within the context of statistical inference, Bayesian optimization methods have been developed where a prior distribution over the space of functions is assumed and uncertainty is tracked during the entire optimization process [6, 7]. [sent-51, score-0.253]
</p><p>12 In particular, non-parametric Bayesian approaches such as Gaussian Processes have been applied for derivative-free optimization [8, 9], also within the context of the continuum-armed bandit problem [10]. [sent-52, score-0.101]
</p><p>13 Typically, these Bayesian approaches aim to explicitly represent the unknown objective function of (1) by entertaining a posterior distribution over the space of objective functions. [sent-53, score-0.189]
</p><p>14 Let h(x) : X → R be an estimate ¯ of the mean f (x) constructed from data Dt := {(xi , yi )}t (Figure 1a, left). [sent-56, score-0.108]
</p><p>15 This estimate can i=1 easily be converted into a posterior pdf over the location of the maximum by ﬁrst multiplying it with a precision parameter α > 0 and then taking the normalized exponential (Figure 1a, right) P (x∗ |Dt ) ∝ exp{α · h(x∗ )}. [sent-57, score-0.63]
</p><p>16 In this transformation, the precision parameter α controls the certainty we have over our estimate of the maximizing argument: α ≈ 0 expresses almost no certainty, while α → ∞ expresses certainty. [sent-58, score-0.497]
</p><p>17 The rationale for the precision is: the more distinct inputs we test, the higher the precision—testing the same (or similar) inputs only provides local information and therefore should not increase our knowledge about the global maximum. [sent-59, score-0.359]
</p><p>18 ¯ In (3), the mean function f is estimated with a kernel regressor [11] that combines the function observations with a prior estimate of the function, and the total effective number of locations is calculated as the sum of the prior locations ξ and the number of distinct locations in the data Dt . [sent-61, score-1.115]
</p><p>19 The latter is estimated by multiplying the number of data points t with the coefﬁcient i i 1  K(xi , xi ) ∈ (0, 1], j K(xi , xj )  Implementations can be downloaded from http://www. [sent-62, score-0.188]
</p><p>20 5  3  Figure 2: Illustration of the posterior distribution over the maximizing argument for 10, 100 and 1000 observations drawn from a function with varying noise. [sent-85, score-0.422]
</p><p>21 The top-left panel illustrates the function and the variance bounds (one standard deviation). [sent-86, score-0.13]
</p><p>22 It can be seen that the prior gets progressively washed out with more observations. [sent-89, score-0.131]
</p><p>23 Inputs that are very close to each other will have overlapping kernels, resulting in large off-diagonal entries of the Gramian matrix—hence decreasing the number of distinct locations (Figure 1b). [sent-93, score-0.22]
</p><p>24 For example, if we have t observations from n ≪ t locations, and each location has t/n observations, then the coefﬁcient (4) is equal to n/t and hence the number of distinct locations is exactly n, as expected. [sent-94, score-0.362]
</p><p>25 Figure 2 illustrates the behavior of the posterior distribution. [sent-95, score-0.224]
</p><p>26 The expression for the posterior can be calculated up to a constant factor in O(t) time. [sent-96, score-0.226]
</p><p>27 Therefore, our proposed posterior can be easily combined with Markov chain Monte Carlo methods (MCMC) to implement stochastic optimizers as will be illustrated in Section 4. [sent-98, score-0.311]
</p><p>28 1 Function-Based, Indirect Model Our ﬁrst task is to derive an indirect Bayesian model for the optimal test point that builds its estimate via the underlying function space. [sent-100, score-0.274]
</p><p>29 Let G be the set of hypotheses, and assume that each hypothesis g ∈ G corresponds to a stochastic mapping g : X R. [sent-101, score-0.139]
</p><p>30 Let P (g) be the prior2 over G and let the likelihood be P ({yt }|g, {xt }) = t P (yt |g, xt ). [sent-102, score-0.384]
</p><p>31 Then, the posterior of g is given by P (g) t P (yt |g, xt ) P (g)P ({yt }|g, {xt }) P (g|{yt }, {xt }) = = . [sent-103, score-0.49]
</p><p>32 Note that we assume that the mean function g is bounded and that it has a unique maximizing test point. [sent-107, score-0.239]
</p><p>33 2 Domain-Based, Direct Model We want to arrive at a Bayesian model that bypasses the integration step suggested by (6) and directly models the location of optimal test point x∗ . [sent-109, score-0.23]
</p><p>34 The Bayesian model for the optimal test point x∗ is given by P (x∗ ) =  P (g) dg  (prior)  G(x∗ )  P (yt |x∗ , xt , Dt−1 ) =  G(x∗ )  P (yt |g, xt )P (g) G(x∗ )  P (g)  t−1 k=1  t−1 k=1  P (yk |g, xk ) dg  P (yk |g, xk ) dg  ,  (likelihood)  where Dt := {(xk , yk )}t is the set of past tests. [sent-112, score-1.367]
</p><p>35 Using Bayes’ rule, the posterior distribution P (x∗ |{yt }, {xt }) can be rewritten as P (x∗ )  P (yt |x∗ , xt , Dt−1 ) . [sent-114, score-0.49]
</p><p>36 P ({yt }|{xt }) t  (7)  Since this posterior is equal to (6), one concludes (using (5)) that P (x∗ )  P (yt |x∗ , xt , Dt−1 ) =  P (g) G(x∗ )  t  P (yt |g, xt ) dg. [sent-115, score-0.791]
</p><p>37 t  Note that this expression corresponds to the joint P (x∗ , {yt }|{xt }). [sent-116, score-0.075]
</p><p>38 The likelihood is obtained as the fraction P (yt |x∗ , xt , Dt−1 ) =  P (x∗ , {yk }t |{xk }t ) k=1 k=1 , P (x∗ , {yk }t−1 |{xk }t−1 ) k=1 k=1  where it shall be noted that the denominator P (x∗ , {yk }t−1 |{xk }t−1 ) doesn’t change if we add the k=1 k=1 condition xt . [sent-118, score-0.685]
</p><p>39 From Theorem 1 it is seen that although the likelihood model P (yt |g, xt ) for the indirect model is i. [sent-119, score-0.495]
</p><p>40 at each test point, the likelihood model P (yt |x∗ , xt , Dt−1 ) for the direct model depends on the past tests Dt−1 , that is, it is adaptive. [sent-122, score-0.529]
</p><p>41 More critically though, the likelihood function’s internal structure of the direct model corresponds to an integration over function space as well— thus inheriting all the difﬁculties of the indirect model. [sent-123, score-0.297]
</p><p>42 Then, the crucial insight consists in realizing that the value of the mean function g inside ¯ a sufﬁciently small neighborhood of x∗ is larger than the value outside of it (see Figure 3a). [sent-127, score-0.214]
</p><p>43 / ¯ ¯ Furthermore, we impose a symmetry condition on the likelihood function. [sent-133, score-0.083]
</p><p>44 There is no reason for them to 1 2 be very different: in fact, they should virtually be indistinguishable outside of the neighborhoods of x∗ and x∗ . [sent-135, score-0.098]
</p><p>45 It is only inside of the neighborhood of x∗ when G(x∗ ) becomes distinguishable from 1 2 1 1 the other equivalence classes because the functions in G(x∗ ) systematically predict higher values 1 4  a)  c)  b)  0  Figure 3: Illustration of assumptions. [sent-136, score-0.106]
</p><p>46 b) Schematic representation of the likelihood function of x∗ ∈ X conditioned on a few observations. [sent-139, score-0.083]
</p><p>47 The curve corresponds to the mean and the shaded area to the conﬁdence bounds. [sent-140, score-0.183]
</p><p>48 The density inside of the neighborhood is unique to the hypothesis x∗ , while the density outside is shared amongst all the hypotheses. [sent-141, score-0.281]
</p><p>49 c) The log-likelihood ratio of the hypotheses x∗ and 1 x∗ as a function of the test point x. [sent-142, score-0.174]
</p><p>50 In fact, taking the log-likelihood ratio of two competing hypotheses P (yt |x∗ , xt , Dt−1 ) 1 log P (yt |x∗ , xt , Dt−1 ) 2 for a given test location xt should give a value equal to zero unless xt is inside of the vicinity of x∗ 1 or x∗ (see Figure 3c). [sent-146, score-1.489]
</p><p>51 In other words, the amount of evidence a hypothesis gets when the test point 2 is outside of its neighborhood is essentially zero (i. [sent-147, score-0.255]
</p><p>52 4 Likelihood and Conjugate Prior Following our previous discussion, we propose the following likelihood model. [sent-151, score-0.083]
</p><p>53 We have chosen the precision αt as i  αt := ρ · ξ + i  K(xi , xi ) j K(xi , xj )  where ρ > 0 is a scaling parameter; ξ > 0 is a parameter representing the number prior locations tested; and K : X × X → R+ is a symmetric kernel function4. [sent-153, score-0.701]
</p><p>54 For the estimate ht , we have chosen a Naradaya-Watson kernel regressor [11] ht (x∗ ) :=  t i=1  K(xi , x∗ )yi + K0 (x∗ )y0 (x∗ ) t i=1  K(xi , x∗ ) + K0 (x∗ )  . [sent-154, score-0.508]
</p><p>55 ¯ In the last expression, y0 corresponds to a prior estimate of f with prior precision K0 . [sent-155, score-0.546]
</p><p>56 Inspecting (8), we see that the likelihood model favours positive changes to the estimated mean function from new, unseen test locations. [sent-156, score-0.277]
</p><p>57 We propose the conjugate prior P (x∗ ) = 4  1 1 exp{α0 · g0 (x∗ )} = exp{ξ · y0 (x∗ )}. [sent-159, score-0.199]
</p><p>58 Z0 Z0  We refer the reader to the kernel regression literature for an analysis of the choice of kernel functions. [sent-160, score-0.198]
</p><p>59 5  (9)  The conjugate prior just encodes a prior estimate of the mean function. [sent-161, score-0.438]
</p><p>60 In a practical optimization application, it serves the purpose of guiding the exploration of the domain, as locations x∗ with high prior value y0 (x∗ ) are more likely to contain the maximizing argument. [sent-162, score-0.495]
</p><p>61 exp αt · ht (x′ ) dx′  =  (10)  Thus, the particular choice of the likelihood function guarantees an analytically compact posterior expression. [sent-164, score-0.482]
</p><p>62 In general, the normalizing constant in (10) is intractable, which is why the expression is only practical for relative comparisons of test locations. [sent-165, score-0.155]
</p><p>63 Substituting the precision αt and the mean function estimate ht yields P (x∗ |Dt ) ∝ exp ρ · ξ + t ·  i i  K(xi , xi ) j K(xi , xj )  ·  i  K(xi , x∗ )yi + K0 (x∗ )y0 (x∗ ) . [sent-166, score-0.628]
</p><p>64 We have investigated the inﬂuence of the parameters on the resulting posterior probability distribution. [sent-169, score-0.189]
</p><p>65 We have used the Gaussian kernel K(x, x∗ ) = exp −  1 (x − x∗ )2 . [sent-170, score-0.158]
</p><p>66 (12) 2 The prior precision K0 and the prior estimate of the mean function y0 were chosen as K0 (x) = 1  and  y0 (x) = −  1 2 2 (x − µ0 ) , 2σ0  (13)  where the latter corresponds to the logarithm of a Gaussian with mean µ0 = 1. [sent-173, score-0.65]
</p><p>67 Figure 4 shows how the choice of the precision scale ρ and the kernel width σ affect the shape of the posterior probability density. [sent-176, score-0.54]
</p><p>68 Here, it is seen that a larger kernel width σ increases the region of inﬂuence of a particular data point, and hence produce smoother posterior densities. [sent-177, score-0.35]
</p><p>69 The precision scale parameter ρ controls the precision per distinct data point: higher values for ρ lead to sharper updates of the posterior distribution. [sent-178, score-0.628]
</p><p>70 The main motivation behind our proposed model is its application to the optimization of noisy functions. [sent-181, score-0.169]
</p><p>71 Because of the noise, choosing new test locations requires carefully balancing explorative and exploitative tests—a problem well known in the multiarmed bandits literature. [sent-182, score-0.235]
</p><p>72 To overcome this, one can apply the Bayesian control rule/Thompson sampling [12, 13]: the next test location is chosen by sampling it from the posterior. [sent-183, score-0.163]
</p><p>73 6  a)  b)  c)  Figure 4: Effect of the change of parameters on the posterior density over the location of the maximizing test point. [sent-185, score-0.504]
</p><p>74 Panel (a) shows the 7 data points drawn from the noisy function (solid curve). [sent-186, score-0.138]
</p><p>75 Panel (b) shows the effect of increasing the width of the kernel (here, Gaussian). [sent-187, score-0.161]
</p><p>76 Panel (c) shows the effect of diminishing the precision on the posterior, where solid and shaded curves correspond to ρ = 0. [sent-191, score-0.295]
</p><p>77 5  −2 0  50  100 150 # of samples  −2 0  200  50  100 150 # of samples  200  Figure 5: Observation values obtained by sampling from the posterior over the maximizing argument (left panel) and according to GP-UCB (right panel). [sent-202, score-0.369]
</p><p>78 The solid blue curve corresponds to the timeaveraged function value, averaged over ten runs. [sent-203, score-0.219]
</p><p>79 The gray area corresponds to the error bounds (1 standard deviation), and the dashed curve in red shows the time-average of a single run. [sent-204, score-0.084]
</p><p>80 This is done by sampling the next test point xt directly from the posterior density over the optimum location P (x∗ |Dt ), and then using the resulting pair (xt , yt ) to recursively update the model. [sent-207, score-1.123]
</p><p>81 We have implemented our proposed method with a Gaussian kernel as in (11) with width σ 2 = 0. [sent-215, score-0.161]
</p><p>82 The prior sufﬁcient statistics are exactly as in (13). [sent-217, score-0.131]
</p><p>83 We show the timeaveraged observation values y of the noisy function evaluated at test locations sampled from the posterior. [sent-221, score-0.45]
</p><p>84 To test our proposed method on a challenging problem, we have designed a non-convex, high-dimensional noisy function with multiple local optima. [sent-224, score-0.182]
</p><p>85 This Noisy Ripples function is deﬁned as 1 f (x) = − 1000 x − µ  2  2 + cos( 3 π x − µ )  where µ ∈ X is the location of the global maximum, and where observations have additive Gaussian noise with zero mean and variance 0. [sent-225, score-0.24]
</p><p>86 b) The time-averaged value and the regret obtained by the optimization algorithm on a 50-dimensional version of the Noisy Ripples function. [sent-229, score-0.108]
</p><p>87 This function is difﬁcult to optimize because it requires averaging the noisy observations and smoothing the ridged landscape in order to detect the underlying quadratic form. [sent-231, score-0.161]
</p><p>88 We optimized the 50-dimensional version of this function using a Metropolis-Hastings scheme to sample the next test locations from the posterior over the maximizing argument. [sent-232, score-0.537]
</p><p>89 07 before the point was used as an actual test location. [sent-234, score-0.107]
</p><p>90 For the arg-max prior, we used a Gaussian kernel with lengthscale l = 2, precision factor ρ = 1. [sent-235, score-0.289]
</p><p>91 5, prior precision K0 (x∗ ) = 1 and prior mean 2 estimate y0 (x∗ ) = − 1000 x + 5 2 . [sent-236, score-0.56]
</p><p>92 Crucial for this success was the choice of a kernel that is wide enough to accurately estimate the mean function. [sent-240, score-0.207]
</p><p>93 5 Conclusions Our goal was to design a probabilistic model over the maximizing argument that is algorithmically efﬁcient and statistically robust even for large, high-dimensional noisy functions. [sent-242, score-0.288]
</p><p>94 To this end, we have derived a Bayesian model that directly captures the uncertainty over the maximizing argument, thereby bypassing having to model the underlying function space—a much harder problem. [sent-243, score-0.147]
</p><p>95 Our proposed model is computationally very efﬁcient when compared to Gaussian process-based (which have cubic time complexity) or models based on upper conﬁdence bounds (which require ﬁnding the input maximizing the bound—a generally intractable operation). [sent-244, score-0.148]
</p><p>96 In our model, evaluating the posterior up to a constant factor scales quadratically with the size of the data. [sent-245, score-0.189]
</p><p>97 As in any kernel-based estimation method, choosing the appropriate kernel bandwidth can signiﬁcantly change the estimate and affect the performance of optimizers that rely on the model. [sent-247, score-0.217]
</p><p>98 A tutorial on bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning. [sent-254, score-0.141]
</p><p>99 Application of bayesian approach to numerical methods of global and stochastic optimization. [sent-283, score-0.186]
</p><p>100 Gaussian process optimization in the bandit setting: No regret and experimental design. [sent-310, score-0.148]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('yt', 0.398), ('dt', 0.347), ('xt', 0.301), ('planck', 0.2), ('precision', 0.19), ('posterior', 0.189), ('locations', 0.161), ('ht', 0.151), ('yk', 0.137), ('prior', 0.131), ('xk', 0.121), ('gramian', 0.115), ('ripples', 0.115), ('maximizing', 0.113), ('indirect', 0.111), ('noisy', 0.108), ('kernel', 0.099), ('panel', 0.095), ('dg', 0.093), ('location', 0.089), ('cybernetics', 0.085), ('likelihood', 0.083), ('bayesian', 0.08), ('xi', 0.079), ('intelligent', 0.077), ('timeaveraged', 0.077), ('test', 0.074), ('institute', 0.072), ('hk', 0.071), ('pdf', 0.068), ('conjugate', 0.068), ('dk', 0.068), ('extrema', 0.068), ('favours', 0.068), ('ortega', 0.068), ('hypotheses', 0.067), ('argument', 0.067), ('obs', 0.062), ('optimizers', 0.062), ('width', 0.062), ('optimization', 0.061), ('stochastic', 0.06), ('exp', 0.059), ('distinct', 0.059), ('solid', 0.058), ('estimate', 0.056), ('outside', 0.056), ('inside', 0.055), ('observations', 0.053), ('mean', 0.052), ('culties', 0.051), ('regressor', 0.051), ('neighborhood', 0.051), ('gaussian', 0.05), ('certainty', 0.048), ('regret', 0.047), ('shaded', 0.047), ('curve', 0.046), ('global', 0.046), ('expresses', 0.045), ('normalizing', 0.044), ('virtually', 0.042), ('hypothesis', 0.041), ('dx', 0.041), ('xj', 0.041), ('tests', 0.04), ('bandit', 0.04), ('cos', 0.039), ('density', 0.039), ('illustration', 0.038), ('corresponds', 0.038), ('multiplying', 0.038), ('max', 0.037), ('expression', 0.037), ('illustrates', 0.035), ('intractable', 0.035), ('located', 0.034), ('bypassing', 0.034), ('balduzzi', 0.034), ('blackbox', 0.034), ('bypasses', 0.034), ('garnett', 0.034), ('inheriting', 0.034), ('neglect', 0.034), ('point', 0.033), ('dence', 0.033), ('inputs', 0.032), ('ance', 0.031), ('braun', 0.031), ('bristol', 0.031), ('brochu', 0.031), ('cora', 0.031), ('rawlik', 0.031), ('srinivas', 0.031), ('direct', 0.031), ('points', 0.03), ('observation', 0.03), ('guiding', 0.029), ('inspecting', 0.029), ('kappen', 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000006 <a title="13-tfidf-1" href="./nips-2012-A_Nonparametric_Conjugate_Prior_Distribution_for_the_Maximizing_Argument_of_a_Noisy_Function.html">13 nips-2012-A Nonparametric Conjugate Prior Distribution for the Maximizing Argument of a Noisy Function</a></p>
<p>Author: Pedro Ortega, Jordi Grau-moya, Tim Genewein, David Balduzzi, Daniel Braun</p><p>Abstract: We propose a novel Bayesian approach to solve stochastic optimization problems that involve ﬁnding extrema of noisy, nonlinear functions. Previous work has focused on representing possible functions explicitly, which leads to a two-step procedure of ﬁrst, doing inference over the function space and second, ﬁnding the extrema of these functions. Here we skip the representation step and directly model the distribution over extrema. To this end, we devise a non-parametric conjugate prior based on a kernel regressor. The resulting posterior distribution directly captures the uncertainty over the maximum of the unknown function. Given t observations of the function, the posterior can be evaluated efﬁciently in time O(t2 ) up to a multiplicative constant. Finally, we show how to apply our model to optimize a noisy, non-convex, high-dimensional objective function.</p><p>2 0.42752248 <a title="13-tfidf-2" href="./nips-2012-Mixing_Properties_of_Conditional_Markov_Chains_with_Unbounded_Feature_Functions.html">218 nips-2012-Mixing Properties of Conditional Markov Chains with Unbounded Feature Functions</a></p>
<p>Author: Mathieu Sinn, Bei Chen</p><p>Abstract: Conditional Markov Chains (also known as Linear-Chain Conditional Random Fields in the literature) are a versatile class of discriminative models for the distribution of a sequence of hidden states conditional on a sequence of observable variables. Large-sample properties of Conditional Markov Chains have been ﬁrst studied in [1]. The paper extends this work in two directions: ﬁrst, mixing properties of models with unbounded feature functions are being established; second, necessary conditions for model identiﬁability and the uniqueness of maximum likelihood estimates are being given. 1</p><p>3 0.37940043 <a title="13-tfidf-3" href="./nips-2012-On_Multilabel_Classification_and_Ranking_with_Partial_Feedback.html">252 nips-2012-On Multilabel Classification and Ranking with Partial Feedback</a></p>
<p>Author: Claudio Gentile, Francesco Orabona</p><p>Abstract: We present a novel multilabel/ranking algorithm working in partial information settings. The algorithm is based on 2nd-order descent methods, and relies on upper-conﬁdence bounds to trade-off exploration and exploitation. We analyze this algorithm in a partial adversarial setting, where covariates can be adversarial, but multilabel probabilities are ruled by (generalized) linear models. We show O(T 1/2 log T ) regret bounds, which improve in several ways on the existing results. We test the effectiveness of our upper-conﬁdence scheme by contrasting against full-information baselines on real-world multilabel datasets, often obtaining comparable performance. 1</p><p>4 0.25663713 <a title="13-tfidf-4" href="./nips-2012-Stochastic_Gradient_Descent_with_Only_One_Projection.html">324 nips-2012-Stochastic Gradient Descent with Only One Projection</a></p>
<p>Author: Mehrdad Mahdavi, Tianbao Yang, Rong Jin, Shenghuo Zhu, Jinfeng Yi</p><p>Abstract: Although many variants of stochastic gradient descent have been proposed for large-scale convex optimization, most of them require projecting the solution at each iteration to ensure that the obtained solution stays within the feasible domain. For complex domains (e.g., positive semideﬁnite cone), the projection step can be computationally expensive, making stochastic gradient descent unattractive for large-scale optimization problems. We address this limitation by developing novel stochastic optimization algorithms that do not need intermediate projections. Instead, only one projection at the last iteration is needed to obtain a feasible solution in the given domain. Our theoretical analysis shows that with a high probability, √ the proposed algorithms achieve an O(1/ T ) convergence rate for general convex optimization, and an O(ln T /T ) rate for strongly convex optimization under mild conditions about the domain and the objective function. 1</p><p>5 0.2256541 <a title="13-tfidf-5" href="./nips-2012-Expectation_Propagation_in_Gaussian_Process_Dynamical_Systems.html">121 nips-2012-Expectation Propagation in Gaussian Process Dynamical Systems</a></p>
<p>Author: Marc Deisenroth, Shakir Mohamed</p><p>Abstract: Rich and complex time-series data, such as those generated from engineering systems, ﬁnancial markets, videos, or neural recordings are now a common feature of modern data analysis. Explaining the phenomena underlying these diverse data sets requires ﬂexible and accurate models. In this paper, we promote Gaussian process dynamical systems as a rich model class that is appropriate for such an analysis. We present a new approximate message-passing algorithm for Bayesian state estimation and inference in Gaussian process dynamical systems, a nonparametric probabilistic generalization of commonly used state-space models. We derive our message-passing algorithm using Expectation Propagation and provide a unifying perspective on message passing in general state-space models. We show that existing Gaussian ﬁlters and smoothers appear as special cases within our inference framework, and that these existing approaches can be improved upon using iterated message passing. Using both synthetic and real-world data, we demonstrate that iterated message passing can improve inference in a wide range of tasks in Bayesian state estimation, thus leading to improved predictions and more effective decision making. 1</p><p>6 0.22405356 <a title="13-tfidf-6" href="./nips-2012-Fully_Bayesian_inference_for_neural_models_with_negative-binomial_spiking.html">138 nips-2012-Fully Bayesian inference for neural models with negative-binomial spiking</a></p>
<p>7 0.22360305 <a title="13-tfidf-7" href="./nips-2012-Slice_Normalized_Dynamic_Markov_Logic_Networks.html">314 nips-2012-Slice Normalized Dynamic Markov Logic Networks</a></p>
<p>8 0.22179282 <a title="13-tfidf-8" href="./nips-2012-Bayesian_active_learning_with_localized_priors_for_fast_receptive_field_characterization.html">56 nips-2012-Bayesian active learning with localized priors for fast receptive field characterization</a></p>
<p>9 0.21139567 <a title="13-tfidf-9" href="./nips-2012-Relax_and_Randomize_%3A_From_Value_to_Algorithms.html">293 nips-2012-Relax and Randomize : From Value to Algorithms</a></p>
<p>10 0.19241241 <a title="13-tfidf-10" href="./nips-2012-Confusion-Based_Online_Learning_and_a_Passive-Aggressive_Scheme.html">80 nips-2012-Confusion-Based Online Learning and a Passive-Aggressive Scheme</a></p>
<p>11 0.18045515 <a title="13-tfidf-11" href="./nips-2012-Regularized_Off-Policy_TD-Learning.html">292 nips-2012-Regularized Off-Policy TD-Learning</a></p>
<p>12 0.16567409 <a title="13-tfidf-12" href="./nips-2012-Controlled_Recognition_Bounds_for_Visual_Learning_and_Exploration.html">83 nips-2012-Controlled Recognition Bounds for Visual Learning and Exploration</a></p>
<p>13 0.1572894 <a title="13-tfidf-13" href="./nips-2012-Learning_visual_motion_in_recurrent_neural_networks.html">195 nips-2012-Learning visual motion in recurrent neural networks</a></p>
<p>14 0.12336375 <a title="13-tfidf-14" href="./nips-2012-Kernel_Latent_SVM_for_Visual_Recognition.html">168 nips-2012-Kernel Latent SVM for Visual Recognition</a></p>
<p>15 0.11803151 <a title="13-tfidf-15" href="./nips-2012-Scalable_nonconvex_inexact_proximal_splitting.html">300 nips-2012-Scalable nonconvex inexact proximal splitting</a></p>
<p>16 0.11760175 <a title="13-tfidf-16" href="./nips-2012-Searching_for_objects_driven_by_context.html">303 nips-2012-Searching for objects driven by context</a></p>
<p>17 0.11730887 <a title="13-tfidf-17" href="./nips-2012-Putting_Bayes_to_sleep.html">283 nips-2012-Putting Bayes to sleep</a></p>
<p>18 0.11100668 <a title="13-tfidf-18" href="./nips-2012-The_Time-Marginalized_Coalescent_Prior_for_Hierarchical_Clustering.html">339 nips-2012-The Time-Marginalized Coalescent Prior for Hierarchical Clustering</a></p>
<p>19 0.10803243 <a title="13-tfidf-19" href="./nips-2012-Proximal_Newton-type_methods_for_convex_optimization.html">282 nips-2012-Proximal Newton-type methods for convex optimization</a></p>
<p>20 0.10709167 <a title="13-tfidf-20" href="./nips-2012-A_quasi-Newton_proximal_splitting_method.html">27 nips-2012-A quasi-Newton proximal splitting method</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.322), (1, 0.001), (2, 0.215), (3, 0.432), (4, 0.09), (5, -0.161), (6, -0.003), (7, -0.064), (8, 0.077), (9, -0.051), (10, -0.081), (11, -0.028), (12, 0.126), (13, -0.019), (14, -0.009), (15, -0.033), (16, 0.027), (17, 0.037), (18, -0.009), (19, 0.044), (20, -0.039), (21, -0.005), (22, 0.107), (23, 0.023), (24, 0.049), (25, -0.015), (26, 0.032), (27, -0.032), (28, 0.059), (29, 0.017), (30, -0.056), (31, -0.029), (32, -0.049), (33, -0.018), (34, -0.008), (35, -0.032), (36, -0.033), (37, 0.026), (38, 0.072), (39, -0.009), (40, -0.009), (41, 0.04), (42, 0.033), (43, 0.012), (44, 0.037), (45, -0.024), (46, -0.003), (47, -0.045), (48, -0.012), (49, -0.034)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95630521 <a title="13-lsi-1" href="./nips-2012-A_Nonparametric_Conjugate_Prior_Distribution_for_the_Maximizing_Argument_of_a_Noisy_Function.html">13 nips-2012-A Nonparametric Conjugate Prior Distribution for the Maximizing Argument of a Noisy Function</a></p>
<p>Author: Pedro Ortega, Jordi Grau-moya, Tim Genewein, David Balduzzi, Daniel Braun</p><p>Abstract: We propose a novel Bayesian approach to solve stochastic optimization problems that involve ﬁnding extrema of noisy, nonlinear functions. Previous work has focused on representing possible functions explicitly, which leads to a two-step procedure of ﬁrst, doing inference over the function space and second, ﬁnding the extrema of these functions. Here we skip the representation step and directly model the distribution over extrema. To this end, we devise a non-parametric conjugate prior based on a kernel regressor. The resulting posterior distribution directly captures the uncertainty over the maximum of the unknown function. Given t observations of the function, the posterior can be evaluated efﬁciently in time O(t2 ) up to a multiplicative constant. Finally, we show how to apply our model to optimize a noisy, non-convex, high-dimensional objective function.</p><p>2 0.86557657 <a title="13-lsi-2" href="./nips-2012-Mixing_Properties_of_Conditional_Markov_Chains_with_Unbounded_Feature_Functions.html">218 nips-2012-Mixing Properties of Conditional Markov Chains with Unbounded Feature Functions</a></p>
<p>Author: Mathieu Sinn, Bei Chen</p><p>Abstract: Conditional Markov Chains (also known as Linear-Chain Conditional Random Fields in the literature) are a versatile class of discriminative models for the distribution of a sequence of hidden states conditional on a sequence of observable variables. Large-sample properties of Conditional Markov Chains have been ﬁrst studied in [1]. The paper extends this work in two directions: ﬁrst, mixing properties of models with unbounded feature functions are being established; second, necessary conditions for model identiﬁability and the uniqueness of maximum likelihood estimates are being given. 1</p><p>3 0.80922574 <a title="13-lsi-3" href="./nips-2012-On_Multilabel_Classification_and_Ranking_with_Partial_Feedback.html">252 nips-2012-On Multilabel Classification and Ranking with Partial Feedback</a></p>
<p>Author: Claudio Gentile, Francesco Orabona</p><p>Abstract: We present a novel multilabel/ranking algorithm working in partial information settings. The algorithm is based on 2nd-order descent methods, and relies on upper-conﬁdence bounds to trade-off exploration and exploitation. We analyze this algorithm in a partial adversarial setting, where covariates can be adversarial, but multilabel probabilities are ruled by (generalized) linear models. We show O(T 1/2 log T ) regret bounds, which improve in several ways on the existing results. We test the effectiveness of our upper-conﬁdence scheme by contrasting against full-information baselines on real-world multilabel datasets, often obtaining comparable performance. 1</p><p>4 0.78664201 <a title="13-lsi-4" href="./nips-2012-Confusion-Based_Online_Learning_and_a_Passive-Aggressive_Scheme.html">80 nips-2012-Confusion-Based Online Learning and a Passive-Aggressive Scheme</a></p>
<p>Author: Liva Ralaivola</p><p>Abstract: This paper provides the ﬁrst —to the best of our knowledge— analysis of online learning algorithms for multiclass problems when the confusion matrix is taken as a performance measure. The work builds upon recent and elegant results on noncommutative concentration inequalities, i.e. concentration inequalities that apply to matrices, and, more precisely, to matrix martingales. We do establish generalization bounds for online learning algorithms and show how the theoretical study motivates the proposition of a new confusion-friendly learning procedure. This learning algorithm, called COPA (for COnfusion Passive-Aggressive) is a passive-aggressive learning algorithm; it is shown that the update equations for COPA can be computed analytically and, henceforth, there is no need to recourse to any optimization package to implement it. 1</p><p>5 0.75605822 <a title="13-lsi-5" href="./nips-2012-Relax_and_Randomize_%3A_From_Value_to_Algorithms.html">293 nips-2012-Relax and Randomize : From Value to Algorithms</a></p>
<p>Author: Sasha Rakhlin, Ohad Shamir, Karthik Sridharan</p><p>Abstract: We show a principled way of deriving online learning algorithms from a minimax analysis. Various upper bounds on the minimax value, previously thought to be non-constructive, are shown to yield algorithms. This allows us to seamlessly recover known methods and to derive new ones, also capturing such “unorthodox” methods as Follow the Perturbed Leader and the R2 forecaster. Understanding the inherent complexity of the learning problem thus leads to the development of algorithms. To illustrate our approach, we present several new algorithms, including a family of randomized methods that use the idea of a “random playout”. New versions of the Follow-the-Perturbed-Leader algorithms are presented, as well as methods based on the Littlestone’s dimension, efﬁcient methods for matrix completion with trace norm, and algorithms for the problems of transductive learning and prediction with static experts. 1</p><p>6 0.74888009 <a title="13-lsi-6" href="./nips-2012-Fully_Bayesian_inference_for_neural_models_with_negative-binomial_spiking.html">138 nips-2012-Fully Bayesian inference for neural models with negative-binomial spiking</a></p>
<p>7 0.73263586 <a title="13-lsi-7" href="./nips-2012-Slice_Normalized_Dynamic_Markov_Logic_Networks.html">314 nips-2012-Slice Normalized Dynamic Markov Logic Networks</a></p>
<p>8 0.69710565 <a title="13-lsi-8" href="./nips-2012-Regularized_Off-Policy_TD-Learning.html">292 nips-2012-Regularized Off-Policy TD-Learning</a></p>
<p>9 0.6756525 <a title="13-lsi-9" href="./nips-2012-Causal_discovery_with_scale-mixture_model_for_spatiotemporal_variance_dependencies.html">66 nips-2012-Causal discovery with scale-mixture model for spatiotemporal variance dependencies</a></p>
<p>10 0.64652443 <a title="13-lsi-10" href="./nips-2012-Expectation_Propagation_in_Gaussian_Process_Dynamical_Systems.html">121 nips-2012-Expectation Propagation in Gaussian Process Dynamical Systems</a></p>
<p>11 0.63315809 <a title="13-lsi-11" href="./nips-2012-A_Marginalized_Particle_Gaussian_Process_Regression.html">11 nips-2012-A Marginalized Particle Gaussian Process Regression</a></p>
<p>12 0.62827462 <a title="13-lsi-12" href="./nips-2012-Putting_Bayes_to_sleep.html">283 nips-2012-Putting Bayes to sleep</a></p>
<p>13 0.62336934 <a title="13-lsi-13" href="./nips-2012-Bayesian_active_learning_with_localized_priors_for_fast_receptive_field_characterization.html">56 nips-2012-Bayesian active learning with localized priors for fast receptive field characterization</a></p>
<p>14 0.61620188 <a title="13-lsi-14" href="./nips-2012-Controlled_Recognition_Bounds_for_Visual_Learning_and_Exploration.html">83 nips-2012-Controlled Recognition Bounds for Visual Learning and Exploration</a></p>
<p>15 0.55961555 <a title="13-lsi-15" href="./nips-2012-Stochastic_Gradient_Descent_with_Only_One_Projection.html">324 nips-2012-Stochastic Gradient Descent with Only One Projection</a></p>
<p>16 0.53323478 <a title="13-lsi-16" href="./nips-2012-Selective_Labeling_via_Error_Bound_Minimization.html">305 nips-2012-Selective Labeling via Error Bound Minimization</a></p>
<p>17 0.50935596 <a title="13-lsi-17" href="./nips-2012-Spectral_learning_of_linear_dynamics_from_generalised-linear_observations_with_application_to_neural_population_data.html">321 nips-2012-Spectral learning of linear dynamics from generalised-linear observations with application to neural population data</a></p>
<p>18 0.50454956 <a title="13-lsi-18" href="./nips-2012-Learning_visual_motion_in_recurrent_neural_networks.html">195 nips-2012-Learning visual motion in recurrent neural networks</a></p>
<p>19 0.45909518 <a title="13-lsi-19" href="./nips-2012-A_lattice_filter_model_of_the_visual_pathway.html">23 nips-2012-A lattice filter model of the visual pathway</a></p>
<p>20 0.45594341 <a title="13-lsi-20" href="./nips-2012-Ancestor_Sampling_for_Particle_Gibbs.html">41 nips-2012-Ancestor Sampling for Particle Gibbs</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.027), (17, 0.016), (21, 0.035), (36, 0.015), (38, 0.165), (39, 0.015), (42, 0.041), (54, 0.042), (55, 0.016), (74, 0.047), (76, 0.197), (80, 0.151), (83, 0.125), (92, 0.052)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.94163668 <a title="13-lda-1" href="./nips-2012-Graphical_Gaussian_Vector_for_Image_Categorization.html">146 nips-2012-Graphical Gaussian Vector for Image Categorization</a></p>
<p>Author: Tatsuya Harada, Yasuo Kuniyoshi</p><p>Abstract: This paper proposes a novel image representation called a Graphical Gaussian Vector (GGV), which is a counterpart of the codebook and local feature matching approaches. We model the distribution of local features as a Gaussian Markov Random Field (GMRF) which can efﬁciently represent the spatial relationship among local features. Using concepts of information geometry, proper parameters and a metric from the GMRF can be obtained. Then we deﬁne a new image feature by embedding the proper metric into the parameters, which can be directly applied to scalable linear classiﬁers. We show that the GGV obtains better performance over the state-of-the-art methods in the standard object recognition datasets and comparable performance in the scene dataset. 1</p><p>2 0.93890733 <a title="13-lda-2" href="./nips-2012-The_Bethe_Partition_Function_of_Log-supermodular_Graphical_Models.html">335 nips-2012-The Bethe Partition Function of Log-supermodular Graphical Models</a></p>
<p>Author: Nicholas Ruozzi</p><p>Abstract: Sudderth, Wainwright, and Willsky conjectured that the Bethe approximation corresponding to any ﬁxed point of the belief propagation algorithm over an attractive, pairwise binary graphical model provides a lower bound on the true partition function. In this work, we resolve this conjecture in the afﬁrmative by demonstrating that, for any graphical model with binary variables whose potential functions (not necessarily pairwise) are all log-supermodular, the Bethe partition function always lower bounds the true partition function. The proof of this result follows from a new variant of the “four functions” theorem that may be of independent interest. 1</p><p>same-paper 3 0.93515843 <a title="13-lda-3" href="./nips-2012-A_Nonparametric_Conjugate_Prior_Distribution_for_the_Maximizing_Argument_of_a_Noisy_Function.html">13 nips-2012-A Nonparametric Conjugate Prior Distribution for the Maximizing Argument of a Noisy Function</a></p>
<p>Author: Pedro Ortega, Jordi Grau-moya, Tim Genewein, David Balduzzi, Daniel Braun</p><p>Abstract: We propose a novel Bayesian approach to solve stochastic optimization problems that involve ﬁnding extrema of noisy, nonlinear functions. Previous work has focused on representing possible functions explicitly, which leads to a two-step procedure of ﬁrst, doing inference over the function space and second, ﬁnding the extrema of these functions. Here we skip the representation step and directly model the distribution over extrema. To this end, we devise a non-parametric conjugate prior based on a kernel regressor. The resulting posterior distribution directly captures the uncertainty over the maximum of the unknown function. Given t observations of the function, the posterior can be evaluated efﬁciently in time O(t2 ) up to a multiplicative constant. Finally, we show how to apply our model to optimize a noisy, non-convex, high-dimensional objective function.</p><p>4 0.93073553 <a title="13-lda-4" href="./nips-2012-Expectation_Propagation_in_Gaussian_Process_Dynamical_Systems.html">121 nips-2012-Expectation Propagation in Gaussian Process Dynamical Systems</a></p>
<p>Author: Marc Deisenroth, Shakir Mohamed</p><p>Abstract: Rich and complex time-series data, such as those generated from engineering systems, ﬁnancial markets, videos, or neural recordings are now a common feature of modern data analysis. Explaining the phenomena underlying these diverse data sets requires ﬂexible and accurate models. In this paper, we promote Gaussian process dynamical systems as a rich model class that is appropriate for such an analysis. We present a new approximate message-passing algorithm for Bayesian state estimation and inference in Gaussian process dynamical systems, a nonparametric probabilistic generalization of commonly used state-space models. We derive our message-passing algorithm using Expectation Propagation and provide a unifying perspective on message passing in general state-space models. We show that existing Gaussian ﬁlters and smoothers appear as special cases within our inference framework, and that these existing approaches can be improved upon using iterated message passing. Using both synthetic and real-world data, we demonstrate that iterated message passing can improve inference in a wide range of tasks in Bayesian state estimation, thus leading to improved predictions and more effective decision making. 1</p><p>5 0.91666448 <a title="13-lda-5" href="./nips-2012-On_Multilabel_Classification_and_Ranking_with_Partial_Feedback.html">252 nips-2012-On Multilabel Classification and Ranking with Partial Feedback</a></p>
<p>Author: Claudio Gentile, Francesco Orabona</p><p>Abstract: We present a novel multilabel/ranking algorithm working in partial information settings. The algorithm is based on 2nd-order descent methods, and relies on upper-conﬁdence bounds to trade-off exploration and exploitation. We analyze this algorithm in a partial adversarial setting, where covariates can be adversarial, but multilabel probabilities are ruled by (generalized) linear models. We show O(T 1/2 log T ) regret bounds, which improve in several ways on the existing results. We test the effectiveness of our upper-conﬁdence scheme by contrasting against full-information baselines on real-world multilabel datasets, often obtaining comparable performance. 1</p><p>6 0.91609502 <a title="13-lda-6" href="./nips-2012-Bayesian_active_learning_with_localized_priors_for_fast_receptive_field_characterization.html">56 nips-2012-Bayesian active learning with localized priors for fast receptive field characterization</a></p>
<p>7 0.91385949 <a title="13-lda-7" href="./nips-2012-Projection_Retrieval_for_Classification.html">279 nips-2012-Projection Retrieval for Classification</a></p>
<p>8 0.91328484 <a title="13-lda-8" href="./nips-2012-Local_Supervised_Learning_through_Space_Partitioning.html">200 nips-2012-Local Supervised Learning through Space Partitioning</a></p>
<p>9 0.91155356 <a title="13-lda-9" href="./nips-2012-Truncation-free_Online_Variational_Inference_for_Bayesian_Nonparametric_Models.html">355 nips-2012-Truncation-free Online Variational Inference for Bayesian Nonparametric Models</a></p>
<p>10 0.91146708 <a title="13-lda-10" href="./nips-2012-Transferring_Expectations_in_Model-based_Reinforcement_Learning.html">353 nips-2012-Transferring Expectations in Model-based Reinforcement Learning</a></p>
<p>11 0.91134089 <a title="13-lda-11" href="./nips-2012-Regularized_Off-Policy_TD-Learning.html">292 nips-2012-Regularized Off-Policy TD-Learning</a></p>
<p>12 0.91110706 <a title="13-lda-12" href="./nips-2012-Controlled_Recognition_Bounds_for_Visual_Learning_and_Exploration.html">83 nips-2012-Controlled Recognition Bounds for Visual Learning and Exploration</a></p>
<p>13 0.91000879 <a title="13-lda-13" href="./nips-2012-Learning_with_Recursive_Perceptual_Representations.html">197 nips-2012-Learning with Recursive Perceptual Representations</a></p>
<p>14 0.90963268 <a title="13-lda-14" href="./nips-2012-Mixing_Properties_of_Conditional_Markov_Chains_with_Unbounded_Feature_Functions.html">218 nips-2012-Mixing Properties of Conditional Markov Chains with Unbounded Feature Functions</a></p>
<p>15 0.90949994 <a title="13-lda-15" href="./nips-2012-Small-Variance_Asymptotics_for_Exponential_Family_Dirichlet_Process_Mixture_Models.html">316 nips-2012-Small-Variance Asymptotics for Exponential Family Dirichlet Process Mixture Models</a></p>
<p>16 0.90901178 <a title="13-lda-16" href="./nips-2012-Latent_Coincidence_Analysis%3A_A_Hidden_Variable_Model_for_Distance_Metric_Learning.html">171 nips-2012-Latent Coincidence Analysis: A Hidden Variable Model for Distance Metric Learning</a></p>
<p>17 0.90857613 <a title="13-lda-17" href="./nips-2012-Weighted_Likelihood_Policy_Search_with_Model_Selection.html">364 nips-2012-Weighted Likelihood Policy Search with Model Selection</a></p>
<p>18 0.90692198 <a title="13-lda-18" href="./nips-2012-Proper_losses_for_learning_from_partial_labels.html">280 nips-2012-Proper losses for learning from partial labels</a></p>
<p>19 0.90627015 <a title="13-lda-19" href="./nips-2012-Dual-Space_Analysis_of_the_Sparse_Linear_Model.html">104 nips-2012-Dual-Space Analysis of the Sparse Linear Model</a></p>
<p>20 0.90603459 <a title="13-lda-20" href="./nips-2012-Probabilistic_Low-Rank_Subspace_Clustering.html">277 nips-2012-Probabilistic Low-Rank Subspace Clustering</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
