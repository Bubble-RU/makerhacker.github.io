<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>314 nips-2012-Slice Normalized Dynamic Markov Logic Networks</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-314" href="#">nips2012-314</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>314 nips-2012-Slice Normalized Dynamic Markov Logic Networks</h1>
<br/><p>Source: <a title="nips-2012-314-pdf" href="http://papers.nips.cc/paper/4554-slice-normalized-dynamic-markov-logic-networks.pdf">pdf</a></p><p>Author: Tivadar Papai, Henry Kautz, Daniel Stefankovic</p><p>Abstract: Markov logic is a widely used tool in statistical relational learning, which uses a weighted ﬁrst-order logic knowledge base to specify a Markov random ﬁeld (MRF) or a conditional random ﬁeld (CRF). In many applications, a Markov logic network (MLN) is trained in one domain, but used in a different one. This paper focuses on dynamic Markov logic networks, where the size of the discretized time-domain typically varies between training and testing. It has been previously pointed out that the marginal probabilities of truth assignments to ground atoms can change if one extends or reduces the domains of predicates in an MLN. We show that in addition to this problem, the standard way of unrolling a Markov logic theory into a MRF may result in time-inhomogeneity of the underlying Markov chain. Furthermore, even if these representational problems are not signiﬁcant for a given domain, we show that the more practical problem of generating samples in a sequential conditional random ﬁeld for the next slice relying on the samples from the previous slice has high computational cost in the general case, due to the need to estimate a normalization factor for each sample. We propose a new discriminative model, slice normalized dynamic Markov logic networks (SN-DMLN), that suffers from none of these issues. It supports efﬁcient online inference, and can directly model inﬂuences between variables within a time slice that do not have a causal direction, in contrast with fully directed models (e.g., DBNs). Experimental results show an improvement in accuracy over previous approaches to online inference in dynamic Markov logic networks. 1</p><p>Reference: <a title="nips-2012-314-reference" href="../nips2012_reference/nips-2012-Slice_Normalized_Dynamic_Markov_Logic_Networks_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract Markov logic is a widely used tool in statistical relational learning, which uses a weighted ﬁrst-order logic knowledge base to specify a Markov random ﬁeld (MRF) or a conditional random ﬁeld (CRF). [sent-3, score-0.805]
</p><p>2 In many applications, a Markov logic network (MLN) is trained in one domain, but used in a different one. [sent-4, score-0.328]
</p><p>3 This paper focuses on dynamic Markov logic networks, where the size of the discretized time-domain typically varies between training and testing. [sent-5, score-0.391]
</p><p>4 It has been previously pointed out that the marginal probabilities of truth assignments to ground atoms can change if one extends or reduces the domains of predicates in an MLN. [sent-6, score-0.23]
</p><p>5 We show that in addition to this problem, the standard way of unrolling a Markov logic theory into a MRF may result in time-inhomogeneity of the underlying Markov chain. [sent-7, score-0.443]
</p><p>6 We propose a new discriminative model, slice normalized dynamic Markov logic networks (SN-DMLN), that suffers from none of these issues. [sent-9, score-0.525]
</p><p>7 It supports efﬁcient online inference, and can directly model inﬂuences between variables within a time slice that do not have a causal direction, in contrast with fully directed models (e. [sent-10, score-0.2]
</p><p>8 Experimental results show an improvement in accuracy over previous approaches to online inference in dynamic Markov logic networks. [sent-13, score-0.443]
</p><p>9 1  Introduction  Markov logic [1] is a language for statistical relational learning, which employs weighted ﬁrst-order logic formulas to compactly represent a Markov random ﬁeld (MRF) or a conditional random ﬁeld (CRF). [sent-14, score-0.965]
</p><p>10 A Markov logic theory where each predicate can take an argument representing a time point is called a dynamic Markov logic network (DMLN). [sent-15, score-0.774]
</p><p>11 We will focus on two-slice dynamic Markov logic networks, i. [sent-16, score-0.391]
</p><p>12 DMLNs are the undirected analogue of dynamic Bayesian networks (DBN) [13] and akin to dynamic conditional random ﬁelds [19]. [sent-19, score-0.202]
</p><p>13 DMLNs have been shown useful for relational inference in complex dynamic domains; for example, [17] employed DMLNs for reasoning about the movements and strategies of 14-player games of Capture the Flag. [sent-20, score-0.145]
</p><p>14 The usual method for performing ofﬂine inference in a DMLN is to simply unroll it into a CRF and employ a general MLN or CRF inference algorithm. [sent-21, score-0.137]
</p><p>15 We will show, however, that the standard unrolling approach has a number of undesirable properties. [sent-22, score-0.115]
</p><p>16 First, as one increases the number of time points in the domain, the marginals can ﬂuctuate, even if the observations have little or no inﬂuence on the hidden variables. [sent-24, score-0.115]
</p><p>17 Second, the model can become time-inhomogeneous, even if the ground weighted formulas between the time slices originate from the same weighted ﬁrst-order logic formulas. [sent-25, score-0.669]
</p><p>18 In domains where there are a large number of variables within each slice dynamic programming based exact inference cannot be used. [sent-27, score-0.318]
</p><p>19 When 1  the number of time steps is high and/or online inference is required, unrolling the entire sequence (perhaps repeatedly) becomes prohibitively expensive. [sent-28, score-0.167]
</p><p>20 Sequential Monte Carlo methods, or particle ﬁlters, are perhaps the most popular methods for online inference in high-dimensional sequential models. [sent-33, score-0.166]
</p><p>21 , the Gaussian distributions used in [11], sampling from a two-slice CRF model can become expensive, due to the need to evaluate a partition function for each particle (see Sec. [sent-36, score-0.129]
</p><p>22 As a solution to all of these concerns, we propose a novel way of unrolling a Markov logic theory such that in the resulting probabilistic model a smaller CRF is embedded into a larger CRF making the clique potentials between adjacent slices normalized. [sent-38, score-0.56]
</p><p>23 We call this model slice normalized dynamic Markov logic network (SN-DMLN). [sent-39, score-0.525]
</p><p>24 Because of the embedded CRF and the undirected components in our proposed model, the distribution represented by a SN-DMLN cannot be compactly captured by conventional chain graph [10], DBN or CRF graph representations, as we will explain in Sec. [sent-40, score-0.127]
</p><p>25 The SN-DMLN has none of the negative theoretical or practical properties outlined above, and for accuracy and/or speed of inference matches or outperforms unrolled CRFs and the slice-by-slice approximate inference methods. [sent-42, score-0.234]
</p><p>26 2  Background  Probabilistic graphical models compactly represent probability distributions using a graph structure that expresses conditional independences among the variables. [sent-44, score-0.082]
</p><p>27 , they model the joint distribution of the hidden variables and the observations, and during training the joint probability of the training data is maximized. [sent-47, score-0.078]
</p><p>28 Hidden Markov models are the prototypical directed models used for sequential data with hidden and observable parts. [sent-48, score-0.177]
</p><p>29 It has been demonstrated that for classiﬁcation problems, discriminative models, which model the conditional probability of the hidden variables given the observations, can outperform generative models [12]. [sent-49, score-0.119]
</p><p>30 Markov logic [1] is a ﬁrst-order probabilistic language that allows one to deﬁne template features that apply to whole classes of objects at once. [sent-54, score-0.328]
</p><p>31 A Markov logic network is a set of weighted ﬁrst-order logic formulas and a ﬁnite set of constants C = {c1 , c2 , . [sent-55, score-0.853]
</p><p>32 , c|C| } which together deﬁne a Markov network ML,C that contains a binary node for each possible grounding of each predicate (ground atom) and a binary valued feature for each grounding of each ﬁrst-order logic formula. [sent-58, score-0.507]
</p><p>33 We will also call the ground atoms variables (since they are random variables). [sent-59, score-0.145]
</p><p>34 Ground atoms share the same weight if they are groundings of the same weighted ﬁrstorder logic formula, and (1) could be expressed in terms of ni (x, y) = j fi,j (x, y). [sent-65, score-0.451]
</p><p>35 Dynamic MLNs [7] are MLNs with distinguished arguments in every predicate representing the ﬂow of time or some other sequential quantity. [sent-67, score-0.129]
</p><p>36 In our settings, Yt and Xt will denote the set of hidden and observable random variables, respectively, at time t, and Y1:t and X1:t from time step 1 to t. [sent-68, score-0.091]
</p><p>37 Each set can contain many variables, and we should note that their distribution will be represented compactly by weighted ﬁrst-order logic formulas. [sent-69, score-0.407]
</p><p>38 The formulas in the knowledge base can be partitioned into 2  two sets. [sent-70, score-0.199]
</p><p>39 The transitions part contains the formulas for which it is true that for any grounding of each formula, there is a t such that the grounding shares variables only with Yt and Yt+1 . [sent-71, score-0.344]
</p><p>40 The emission part represents the formulas which connect the hidden and observable variables, i. [sent-72, score-0.287]
</p><p>41 We will use P (Yt , Yt+1 ) (or P (Yt:t+1 )) and P (Yt , Xt ) to denote the product of the potentials corresponding to weighted ground formulas at time t of the transition and the observation formulas, respectively. [sent-75, score-0.344]
</p><p>42 Since some ground formulas may contain only variables from Yt ( i. [sent-76, score-0.245]
</p><p>43 , deﬁned over hidden variables within the same slice), in order to count the corresponding potentials exactly once, ˜ ˜ we always include their potentials P (Yt , Yt−1 ), and for t = 1 we have a separate P (Y1 ). [sent-78, score-0.168]
</p><p>44 , when the knowledge base is unrolled into a CRF: 1. [sent-82, score-0.17]
</p><p>45 As one increases the number of time points the marginals can ﬂuctuate, even if all the clique ˜ potentials P (Yi = yi , Xi = xi ) in (2) are uninformative. [sent-83, score-0.48]
</p><p>46 The transition probability Pr(Yi+1 |Yi ) can be dependent on i, even if every P (Yi = yi , Xi = xi ) is uninformative and we use the same weighted ﬁrst-order logic formula responsible for the ground formulas covering the transitions between every i and i + 1. [sent-85, score-1.142]
</p><p>47 ˜ ˜ Saying that P (Yi = yi , Xi = xi ) is uninformative is equivalent to saying that P (Yi = yi , Xi = xi ) ˜ is constant. [sent-90, score-0.745]
</p><p>48 , for some q and r P (Yi = yi , Xi = xi ) = ˜ r(yi )q(xi ) then q could be marginalized out and r(Yi ) could be snapped to P (Yi , Yi−1 ) in (2). [sent-93, score-0.398]
</p><p>49 ) To demonstrate Property 1, consider an unrolled MRF with the temporal domain T = {1, . [sent-94, score-0.155]
</p><p>50 , T }, with only predicate P (t) (t ∈ T ) and with the weighted formulas (+∞, P (t) ⇔ P (t + 1)) (hard constraint) and (w, P (t)) (soft constraint). [sent-97, score-0.252]
</p><p>51 Consequently, we have diverging marginals as T → +∞. [sent-108, score-0.105]
</p><p>52 , an MLN with a single ﬁrst-order logic formula P (t) ∨ P (t + 1) with weight w. [sent-113, score-0.375]
</p><p>53 1+exp(w) The unrolled MRF deﬁnes a distribution where Pr(¬P (3)|¬P (2)) = 1+2exp(w)+exp(2w) which is not equal to Pr(¬P (2)|¬P (1)) =  1+exp(w) 1+exp(w)+2 exp(2w)  for an arbitrary choice of w. [sent-115, score-0.13]
</p><p>54 , N is an enumeration of the all the possible truth assignments within each slice and N is the number of the possible truth assignments in the slice. [sent-123, score-0.208]
</p><p>55 ,yT i=1 P (Yi = yi , Yi+1 = yi+1 ), where Z(Y1:T ) = i=1 P (Yi = Z(Y1:T ) yi , Yi+1 = yi+1 ). [sent-130, score-0.588]
</p><p>56 The issue of diverging marginals and time-inhomogeneity has not been previously recognized as a practical problem. [sent-143, score-0.105]
</p><p>57 This proposition can serve as an explanation why in practice we do not encounter diverging marginals in linear chain type CRFsand why except for a ﬁnite number of transitions the model becomes time-homogeneous. [sent-147, score-0.192]
</p><p>58 , in a hidden Markov model), following standard particle ﬁlter design, having sampled s1:t−1 ∼ Pr(Y1:t−1 = s1:t−1 |X1:t−1 = x1:t−1 ), and then using s1:t−1 one would sample st ∼ Pr(Yt , Y1:t−1 = s1:t−1 |X1:t−1 ). [sent-151, score-0.179]
</p><p>59 Since Pr(Y1:t = s1:t |X1:t−1 = x1:t−1 ) = Pr(Yt = st |Yt−1 = st−1 )Pr(Y1:t−1 = s1:t−1 |X1:t−1 = x1:t−1 ) (4) we do not have any difﬁculty performing this sampling step, and all that is left is to re-sample the collection of s1:t with importance weights Pr(Yt = st |Xt = xt ). [sent-152, score-0.191]
</p><p>60 1 Although several algorithms have been proposed to estimate partition functions [16, 18], the partition function estimation can increase both the running time of the sampling algorithm signiﬁcantly and the error of the approximation of the sampling algorithm. [sent-156, score-0.12]
</p><p>61 , when we have three weighted formulas in the previously used toy domain, namely, w : ¬P (Yt ) ∨ ¬P (Yt+1 ), −w : P (Yt ) ∧ ¬P (Yt+1 ) and w′ : P (Yt ) ↔ ¬P (Yt+1 ), where w > 0 and w′ < 0. [sent-160, score-0.197]
</p><p>62 4  Slice normalized DMLNs  As we demonstrated in Section 3, the root cause of the weaknesses of an ordinarily unrolled CRF ˜ ˜ lies in that P (Yt = yt , Yt−1 = yt−1 ) is unnormalized, i. [sent-162, score-0.592]
</p><p>63 In that case we would directly represent Pr(Yt |Xt , Yt−1 ), hence we could implement a sequential Monte Carlo algorithm simply directly sampling st ∼ Pr(Yt |Xt = xt , Yt−1 = st−1 ) from slice to slice. [sent-166, score-0.339]
</p><p>64 i=2  P (Yt = yt |Yt−1 = yt−1 ) is deﬁned by a two-slice Markov logic network (CRF), which describes the state transitions probabilities in a compact way. [sent-181, score-0.797]
</p><p>65 If we hide the details of this nested CRF component and treat it as one potential, we could represent the distribution in (6) by regular chain graphs or CRFs; however we would lose then the compactness the nested CRF provides for describing the distribution. [sent-182, score-0.077]
</p><p>66 Similarly, we could collapse the variables at every time slice into one and could use a DBN (or again a chain graph), but it would need exponentially more entries in its conditional probability ˜ tables. [sent-183, score-0.332]
</p><p>67 Furthermore, we do not have to compute the partition function ˜ between the slices, because equation (5) shows, drawing a sample yt ∼ P (Yt , Yt−1 = yt−1 ) while keeping the value yt−1 ﬁxed is equivalent to sampling from P (Yt |Yt−1 = yt−1 ), the quantity present in equation (6). [sent-185, score-0.493]
</p><p>68 We will partition the weights (parameters) of our model based on whether they belong to transition or to emission part of the model. [sent-190, score-0.112]
</p><p>69 an emission parameter we (to which feature ne belongs) is: ∂Ld = ∂we  t  t  ne (yi , xi ) − EP r(Y |X=x) i=1  ne (Yi , xi )  ,  (7)  i=1  which is analogous to what one would expect for CRFs. [sent-197, score-0.141]
</p><p>70 However, for a transition parameter wtr (belonging to feature ntr ) we get something different: ∂Ld = ∂wtr  t−1  t  EP (Yi+1 |yi ) [ntr (Yi+1 , Yi = yi )]  ntr (yi+1 , yi ) −  (8)  i=1  i=1  t−1  t−1  − EP r(Y |X=x)  ˜ EP (Yi+1 |Yi ) ntr (Yi+1 , Yi ) ˜  ntr (Yi+1 , Yi ) −  . [sent-198, score-1.214]
</p><p>71 , when the transition parameters are kept ﬁxed, allowing the transition parameters to vary makes Ld no longer concave. [sent-204, score-0.082]
</p><p>72 ) In (8) the ﬁrst 2 ˜ Note that, in the SN-DMLN model the uniformity of P (Yi = yi , Xi = xi ) is a stronger assumption than the independence of Xi and Yi . [sent-205, score-0.346]
</p><p>73 , when the model simpliﬁes to a Markov chain with a compactly represented transition probability distribution. [sent-209, score-0.133]
</p><p>74 The ˜ rationale behind our heuristic is that if P (Yi = yi , Xi = xi ) had truly no information content, then for α = 0 we would ﬁnd the global optimum, and as we increase α we are taking into account that the observations are correlated with the hidden variables with an increasing weight. [sent-221, score-0.45]
</p><p>75 5  Experiments  For our experiments we extended the Probabilistic Consistency Engine (PCE) [3], a Markov logic implementation that has been used effectively in different problem domains. [sent-222, score-0.328]
</p><p>76 For training, we used 10000 samples for the unrolled CRF and 100 particles and 100 samples for approximating the conditional expectations in (9) for the SN-DMLN to estimate the gradients. [sent-223, score-0.202]
</p><p>77 For inference we used 10000 samples for the CRF and 10000 particles for the mixed model. [sent-224, score-0.083]
</p><p>78 The hidden predicates in our knowledge base were Smokes(person, time), F riends(person1 , person2 , time) and the observable was Hangout(person, group, time). [sent-227, score-0.16]
</p><p>79 The goal of inference was to predict which people could potentially be friends, based on the similarity in their smoking habits, which similarity could be inferred based on the groups the individuals hang out. [sent-228, score-0.454]
</p><p>80 Initially 2 people were randomly chosen to be smokers and 2 to be non-smokers. [sent-230, score-0.109]
</p><p>81 People with the same smoking habits can become friends at any time step with probability 1 − 0. [sent-231, score-0.35]
</p><p>82 Every 5th time step (starting with t = 0) people hang out in groups and for each person the probability of joining one of the groups is 1 − 0. [sent-234, score-0.177]
</p><p>83 05α, everyone spends time with the group reﬂecting their smoking habits, and with probability 0. [sent-237, score-0.173]
</p><p>84 , a smoker stays a smoker and a non-smoker stays a non-smoker at the next time step with probability 1 − 0. [sent-242, score-0.15]
</p><p>85 The weights of the clauses we learned using the SN-DMLN and the CRF unrolled models are in Table 1. [sent-245, score-0.157]
</p><p>86 In our experiments we compared three types of inference, and measured the prediction quality for the hidden predicate F riends by assigning true to every ground atom the marginal probability of which was greater than 6  length  5 10 20 40  SN 1. [sent-248, score-0.399]
</p><p>87 t to smoking and not smoking, and from the observations we could only tell that certain pairs of people have similar or different smoking habits, but not who smokes and who does not. [sent-301, score-0.707]
</p><p>88 The inference over the entire test set, took approximately 6 minutes for SN and MAR in every test case, while UNR required 5, 8, 12 and 40 minutes for the different test cases. [sent-305, score-0.137]
</p><p>89 The performance of SN and MAR stays the same as we increase the length of the chain while the performance of UNR degrades. [sent-309, score-0.121]
</p><p>90 This can be explained by that MC-SAT requires more sampling steps to maintain the same performance as the chain length increases. [sent-311, score-0.115]
</p><p>91 2 that SN outperforms both UNR and MAR as the chain length increases. [sent-316, score-0.089]
</p><p>92 Moreover, UNR’s performance is clearly decreasing as the length of the chain increases. [sent-317, score-0.089]
</p><p>93 6  Conclusion  In this paper, we explored the theoretical and practical questions of unrolling a sequential Markov logic knowledge base into different probabilistic models. [sent-318, score-0.528]
</p><p>94 The theoretical issues arising in a CRF7  (a) α = 0  (b) α = 1  Figure 2: F-score of models trained and tested on different length of data based MLN unrolling are a warning that unexpected results may occur if the observations are weakly correlated with the hidden variables. [sent-319, score-0.206]
</p><p>95 We demonstrated that the CRF based unrolling can be outperformed by a model that mixes directed and undirected components (the proposed model does not suffer from any of the theoretical weaknesses, nor from the label-bias problem). [sent-321, score-0.217]
</p><p>96 These savings are due to that we do not have to unroll a new CRF at every time step, or estimate a partition function which is responsible for normalizing the product of clique potentials appearing in two consecutive slices. [sent-323, score-0.168]
</p><p>97 The previously used approximate inference methods in dynamic MLNs either relied on belief propagation or assumed that approximating the distribution at every time step by the product of the marginals would not cause any error. [sent-324, score-0.23]
</p><p>98 Although training the mixed model might have a higher computational cost than training a conditional random ﬁeld, but this cost is amortized over time, since in applications inference is performed many times, while weight learning only once. [sent-327, score-0.093]
</p><p>99 Machine reading using markov logic networks for collective probabilistic inference. [sent-339, score-0.41]
</p><p>100 Maximum entropy markov models for information extraction and segmentation. [sent-384, score-0.082]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('yt', 0.433), ('logic', 0.328), ('yi', 0.294), ('crf', 0.271), ('smokes', 0.259), ('smoking', 0.173), ('riends', 0.163), ('formulas', 0.159), ('pr', 0.152), ('habits', 0.147), ('unr', 0.147), ('slice', 0.134), ('ntr', 0.13), ('unrolled', 0.13), ('mar', 0.123), ('unrolling', 0.115), ('hang', 0.101), ('dmlns', 0.098), ('mln', 0.086), ('markov', 0.082), ('hangout', 0.082), ('prt', 0.082), ('sn', 0.078), ('people', 0.076), ('mlns', 0.072), ('particle', 0.069), ('crfs', 0.066), ('wtr', 0.065), ('dynamic', 0.063), ('grounding', 0.062), ('marginals', 0.062), ('mrf', 0.062), ('ground', 0.061), ('atoms', 0.059), ('st', 0.057), ('predicate', 0.055), ('hidden', 0.053), ('inference', 0.052), ('xi', 0.052), ('xt', 0.051), ('chain', 0.051), ('ld', 0.048), ('limt', 0.047), ('formula', 0.047), ('slices', 0.045), ('sequential', 0.045), ('potentials', 0.045), ('ep', 0.044), ('domains', 0.044), ('diverging', 0.043), ('smoker', 0.043), ('conditional', 0.041), ('compactly', 0.041), ('transition', 0.041), ('directed', 0.041), ('zt', 0.04), ('base', 0.04), ('length', 0.038), ('weighted', 0.038), ('observable', 0.038), ('truth', 0.037), ('emission', 0.037), ('transitions', 0.036), ('undirected', 0.035), ('partition', 0.034), ('dmln', 0.033), ('geier', 0.033), ('pce', 0.033), ('smokers', 0.033), ('unroll', 0.033), ('dbn', 0.032), ('stays', 0.032), ('particles', 0.031), ('pedro', 0.031), ('relational', 0.03), ('friends', 0.03), ('elds', 0.029), ('climbing', 0.029), ('weaknesses', 0.029), ('predicates', 0.029), ('every', 0.029), ('uninformative', 0.028), ('minutes', 0.028), ('clique', 0.027), ('nath', 0.027), ('clauses', 0.027), ('suffer', 0.026), ('heuristic', 0.026), ('sampling', 0.026), ('could', 0.026), ('days', 0.025), ('exp', 0.025), ('saying', 0.025), ('kersting', 0.025), ('rochester', 0.025), ('domingos', 0.025), ('variables', 0.025), ('domain', 0.025), ('belief', 0.024), ('normalization', 0.024)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="314-tfidf-1" href="./nips-2012-Slice_Normalized_Dynamic_Markov_Logic_Networks.html">314 nips-2012-Slice Normalized Dynamic Markov Logic Networks</a></p>
<p>Author: Tivadar Papai, Henry Kautz, Daniel Stefankovic</p><p>Abstract: Markov logic is a widely used tool in statistical relational learning, which uses a weighted ﬁrst-order logic knowledge base to specify a Markov random ﬁeld (MRF) or a conditional random ﬁeld (CRF). In many applications, a Markov logic network (MLN) is trained in one domain, but used in a different one. This paper focuses on dynamic Markov logic networks, where the size of the discretized time-domain typically varies between training and testing. It has been previously pointed out that the marginal probabilities of truth assignments to ground atoms can change if one extends or reduces the domains of predicates in an MLN. We show that in addition to this problem, the standard way of unrolling a Markov logic theory into a MRF may result in time-inhomogeneity of the underlying Markov chain. Furthermore, even if these representational problems are not signiﬁcant for a given domain, we show that the more practical problem of generating samples in a sequential conditional random ﬁeld for the next slice relying on the samples from the previous slice has high computational cost in the general case, due to the need to estimate a normalization factor for each sample. We propose a new discriminative model, slice normalized dynamic Markov logic networks (SN-DMLN), that suffers from none of these issues. It supports efﬁcient online inference, and can directly model inﬂuences between variables within a time slice that do not have a causal direction, in contrast with fully directed models (e.g., DBNs). Experimental results show an improvement in accuracy over previous approaches to online inference in dynamic Markov logic networks. 1</p><p>2 0.38947511 <a title="314-tfidf-2" href="./nips-2012-Mixing_Properties_of_Conditional_Markov_Chains_with_Unbounded_Feature_Functions.html">218 nips-2012-Mixing Properties of Conditional Markov Chains with Unbounded Feature Functions</a></p>
<p>Author: Mathieu Sinn, Bei Chen</p><p>Abstract: Conditional Markov Chains (also known as Linear-Chain Conditional Random Fields in the literature) are a versatile class of discriminative models for the distribution of a sequence of hidden states conditional on a sequence of observable variables. Large-sample properties of Conditional Markov Chains have been ﬁrst studied in [1]. The paper extends this work in two directions: ﬁrst, mixing properties of models with unbounded feature functions are being established; second, necessary conditions for model identiﬁability and the uniqueness of maximum likelihood estimates are being given. 1</p><p>3 0.33410904 <a title="314-tfidf-3" href="./nips-2012-On_Multilabel_Classification_and_Ranking_with_Partial_Feedback.html">252 nips-2012-On Multilabel Classification and Ranking with Partial Feedback</a></p>
<p>Author: Claudio Gentile, Francesco Orabona</p><p>Abstract: We present a novel multilabel/ranking algorithm working in partial information settings. The algorithm is based on 2nd-order descent methods, and relies on upper-conﬁdence bounds to trade-off exploration and exploitation. We analyze this algorithm in a partial adversarial setting, where covariates can be adversarial, but multilabel probabilities are ruled by (generalized) linear models. We show O(T 1/2 log T ) regret bounds, which improve in several ways on the existing results. We test the effectiveness of our upper-conﬁdence scheme by contrasting against full-information baselines on real-world multilabel datasets, often obtaining comparable performance. 1</p><p>4 0.22360305 <a title="314-tfidf-4" href="./nips-2012-A_Nonparametric_Conjugate_Prior_Distribution_for_the_Maximizing_Argument_of_a_Noisy_Function.html">13 nips-2012-A Nonparametric Conjugate Prior Distribution for the Maximizing Argument of a Noisy Function</a></p>
<p>Author: Pedro Ortega, Jordi Grau-moya, Tim Genewein, David Balduzzi, Daniel Braun</p><p>Abstract: We propose a novel Bayesian approach to solve stochastic optimization problems that involve ﬁnding extrema of noisy, nonlinear functions. Previous work has focused on representing possible functions explicitly, which leads to a two-step procedure of ﬁrst, doing inference over the function space and second, ﬁnding the extrema of these functions. Here we skip the representation step and directly model the distribution over extrema. To this end, we devise a non-parametric conjugate prior based on a kernel regressor. The resulting posterior distribution directly captures the uncertainty over the maximum of the unknown function. Given t observations of the function, the posterior can be evaluated efﬁciently in time O(t2 ) up to a multiplicative constant. Finally, we show how to apply our model to optimize a noisy, non-convex, high-dimensional objective function.</p><p>5 0.19592947 <a title="314-tfidf-5" href="./nips-2012-On_Lifting_the_Gibbs_Sampling_Algorithm.html">251 nips-2012-On Lifting the Gibbs Sampling Algorithm</a></p>
<p>Author: Deepak Venugopal, Vibhav Gogate</p><p>Abstract: First-order probabilistic models combine the power of ﬁrst-order logic, the de facto tool for handling relational structure, with probabilistic graphical models, the de facto tool for handling uncertainty. Lifted probabilistic inference algorithms for them have been the subject of much recent research. The main idea in these algorithms is to improve the accuracy and scalability of existing graphical models’ inference algorithms by exploiting symmetry in the ﬁrst-order representation. In this paper, we consider blocked Gibbs sampling, an advanced MCMC scheme, and lift it to the ﬁrst-order level. We propose to achieve this by partitioning the ﬁrst-order atoms in the model into a set of disjoint clusters such that exact lifted inference is polynomial in each cluster given an assignment to all other atoms not in the cluster. We propose an approach for constructing the clusters and show how it can be used to trade accuracy with computational complexity in a principled manner. Our experimental evaluation shows that lifted Gibbs sampling is superior to the propositional algorithm in terms of accuracy, scalability and convergence.</p><p>6 0.17011862 <a title="314-tfidf-6" href="./nips-2012-Fully_Bayesian_inference_for_neural_models_with_negative-binomial_spiking.html">138 nips-2012-Fully Bayesian inference for neural models with negative-binomial spiking</a></p>
<p>7 0.14748119 <a title="314-tfidf-7" href="./nips-2012-Relax_and_Randomize_%3A_From_Value_to_Algorithms.html">293 nips-2012-Relax and Randomize : From Value to Algorithms</a></p>
<p>8 0.13967903 <a title="314-tfidf-8" href="./nips-2012-Regularized_Off-Policy_TD-Learning.html">292 nips-2012-Regularized Off-Policy TD-Learning</a></p>
<p>9 0.13834348 <a title="314-tfidf-9" href="./nips-2012-Cocktail_Party_Processing_via_Structured_Prediction.html">72 nips-2012-Cocktail Party Processing via Structured Prediction</a></p>
<p>10 0.13449308 <a title="314-tfidf-10" href="./nips-2012-Controlled_Recognition_Bounds_for_Visual_Learning_and_Exploration.html">83 nips-2012-Controlled Recognition Bounds for Visual Learning and Exploration</a></p>
<p>11 0.12351439 <a title="314-tfidf-11" href="./nips-2012-Confusion-Based_Online_Learning_and_a_Passive-Aggressive_Scheme.html">80 nips-2012-Confusion-Based Online Learning and a Passive-Aggressive Scheme</a></p>
<p>12 0.10287363 <a title="314-tfidf-12" href="./nips-2012-Putting_Bayes_to_sleep.html">283 nips-2012-Putting Bayes to sleep</a></p>
<p>13 0.099462546 <a title="314-tfidf-13" href="./nips-2012-Searching_for_objects_driven_by_context.html">303 nips-2012-Searching for objects driven by context</a></p>
<p>14 0.09809877 <a title="314-tfidf-14" href="./nips-2012-Slice_sampling_normalized_kernel-weighted_completely_random_measure_mixture_models.html">315 nips-2012-Slice sampling normalized kernel-weighted completely random measure mixture models</a></p>
<p>15 0.094750471 <a title="314-tfidf-15" href="./nips-2012-Multiple_Choice_Learning%3A_Learning_to_Produce_Multiple_Structured_Outputs.html">230 nips-2012-Multiple Choice Learning: Learning to Produce Multiple Structured Outputs</a></p>
<p>16 0.086220093 <a title="314-tfidf-16" href="./nips-2012-The_Time-Marginalized_Coalescent_Prior_for_Hierarchical_Clustering.html">339 nips-2012-The Time-Marginalized Coalescent Prior for Hierarchical Clustering</a></p>
<p>17 0.082562342 <a title="314-tfidf-17" href="./nips-2012-How_Prior_Probability_Influences_Decision_Making%3A_A_Unifying_Probabilistic_Model.html">153 nips-2012-How Prior Probability Influences Decision Making: A Unifying Probabilistic Model</a></p>
<p>18 0.079360582 <a title="314-tfidf-18" href="./nips-2012-Density_Propagation_and_Improved_Bounds_on_the_Partition_Function.html">96 nips-2012-Density Propagation and Improved Bounds on the Partition Function</a></p>
<p>19 0.078617901 <a title="314-tfidf-19" href="./nips-2012-Ancestor_Sampling_for_Particle_Gibbs.html">41 nips-2012-Ancestor Sampling for Particle Gibbs</a></p>
<p>20 0.076989956 <a title="314-tfidf-20" href="./nips-2012-Stochastic_optimization_and_sparse_statistical_recovery%3A_Optimal_algorithms_for_high_dimensions.html">325 nips-2012-Stochastic optimization and sparse statistical recovery: Optimal algorithms for high dimensions</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.213), (1, -0.016), (2, 0.125), (3, 0.327), (4, 0.032), (5, -0.213), (6, -0.01), (7, -0.061), (8, 0.007), (9, 0.069), (10, -0.011), (11, -0.056), (12, 0.09), (13, 0.06), (14, 0.037), (15, -0.119), (16, 0.038), (17, -0.074), (18, 0.124), (19, -0.051), (20, 0.004), (21, 0.04), (22, -0.003), (23, 0.079), (24, 0.046), (25, -0.017), (26, 0.031), (27, -0.107), (28, -0.037), (29, 0.11), (30, 0.067), (31, 0.094), (32, -0.037), (33, 0.124), (34, -0.012), (35, -0.048), (36, 0.003), (37, -0.009), (38, -0.032), (39, -0.032), (40, 0.028), (41, -0.037), (42, -0.006), (43, 0.089), (44, -0.017), (45, 0.054), (46, 0.082), (47, -0.038), (48, -0.012), (49, 0.054)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96178317 <a title="314-lsi-1" href="./nips-2012-Slice_Normalized_Dynamic_Markov_Logic_Networks.html">314 nips-2012-Slice Normalized Dynamic Markov Logic Networks</a></p>
<p>Author: Tivadar Papai, Henry Kautz, Daniel Stefankovic</p><p>Abstract: Markov logic is a widely used tool in statistical relational learning, which uses a weighted ﬁrst-order logic knowledge base to specify a Markov random ﬁeld (MRF) or a conditional random ﬁeld (CRF). In many applications, a Markov logic network (MLN) is trained in one domain, but used in a different one. This paper focuses on dynamic Markov logic networks, where the size of the discretized time-domain typically varies between training and testing. It has been previously pointed out that the marginal probabilities of truth assignments to ground atoms can change if one extends or reduces the domains of predicates in an MLN. We show that in addition to this problem, the standard way of unrolling a Markov logic theory into a MRF may result in time-inhomogeneity of the underlying Markov chain. Furthermore, even if these representational problems are not signiﬁcant for a given domain, we show that the more practical problem of generating samples in a sequential conditional random ﬁeld for the next slice relying on the samples from the previous slice has high computational cost in the general case, due to the need to estimate a normalization factor for each sample. We propose a new discriminative model, slice normalized dynamic Markov logic networks (SN-DMLN), that suffers from none of these issues. It supports efﬁcient online inference, and can directly model inﬂuences between variables within a time slice that do not have a causal direction, in contrast with fully directed models (e.g., DBNs). Experimental results show an improvement in accuracy over previous approaches to online inference in dynamic Markov logic networks. 1</p><p>2 0.79807079 <a title="314-lsi-2" href="./nips-2012-Mixing_Properties_of_Conditional_Markov_Chains_with_Unbounded_Feature_Functions.html">218 nips-2012-Mixing Properties of Conditional Markov Chains with Unbounded Feature Functions</a></p>
<p>Author: Mathieu Sinn, Bei Chen</p><p>Abstract: Conditional Markov Chains (also known as Linear-Chain Conditional Random Fields in the literature) are a versatile class of discriminative models for the distribution of a sequence of hidden states conditional on a sequence of observable variables. Large-sample properties of Conditional Markov Chains have been ﬁrst studied in [1]. The paper extends this work in two directions: ﬁrst, mixing properties of models with unbounded feature functions are being established; second, necessary conditions for model identiﬁability and the uniqueness of maximum likelihood estimates are being given. 1</p><p>3 0.79588127 <a title="314-lsi-3" href="./nips-2012-On_Multilabel_Classification_and_Ranking_with_Partial_Feedback.html">252 nips-2012-On Multilabel Classification and Ranking with Partial Feedback</a></p>
<p>Author: Claudio Gentile, Francesco Orabona</p><p>Abstract: We present a novel multilabel/ranking algorithm working in partial information settings. The algorithm is based on 2nd-order descent methods, and relies on upper-conﬁdence bounds to trade-off exploration and exploitation. We analyze this algorithm in a partial adversarial setting, where covariates can be adversarial, but multilabel probabilities are ruled by (generalized) linear models. We show O(T 1/2 log T ) regret bounds, which improve in several ways on the existing results. We test the effectiveness of our upper-conﬁdence scheme by contrasting against full-information baselines on real-world multilabel datasets, often obtaining comparable performance. 1</p><p>4 0.74469352 <a title="314-lsi-4" href="./nips-2012-Putting_Bayes_to_sleep.html">283 nips-2012-Putting Bayes to sleep</a></p>
<p>Author: Dmitry Adamskiy, Manfred K. Warmuth, Wouter M. Koolen</p><p>Abstract: We consider sequential prediction algorithms that are given the predictions from a set of models as inputs. If the nature of the data is changing over time in that different models predict well on different segments of the data, then adaptivity is typically achieved by mixing into the weights in each round a bit of the initial prior (kind of like a weak restart). However, what if the favored models in each segment are from a small subset, i.e. the data is likely to be predicted well by models that predicted well before? Curiously, ﬁtting such “sparse composite models” is achieved by mixing in a bit of all the past posteriors. This self-referential updating method is rather peculiar, but it is efﬁcient and gives superior performance on many natural data sets. Also it is important because it introduces a long-term memory: any model that has done well in the past can be recovered quickly. While Bayesian interpretations can be found for mixing in a bit of the initial prior, no Bayesian interpretation is known for mixing in past posteriors. We build atop the “specialist” framework from the online learning literature to give the Mixing Past Posteriors update a proper Bayesian foundation. We apply our method to a well-studied multitask learning problem and obtain a new intriguing efﬁcient update that achieves a signiﬁcantly better bound. 1</p><p>5 0.67290068 <a title="314-lsi-5" href="./nips-2012-Confusion-Based_Online_Learning_and_a_Passive-Aggressive_Scheme.html">80 nips-2012-Confusion-Based Online Learning and a Passive-Aggressive Scheme</a></p>
<p>Author: Liva Ralaivola</p><p>Abstract: This paper provides the ﬁrst —to the best of our knowledge— analysis of online learning algorithms for multiclass problems when the confusion matrix is taken as a performance measure. The work builds upon recent and elegant results on noncommutative concentration inequalities, i.e. concentration inequalities that apply to matrices, and, more precisely, to matrix martingales. We do establish generalization bounds for online learning algorithms and show how the theoretical study motivates the proposition of a new confusion-friendly learning procedure. This learning algorithm, called COPA (for COnfusion Passive-Aggressive) is a passive-aggressive learning algorithm; it is shown that the update equations for COPA can be computed analytically and, henceforth, there is no need to recourse to any optimization package to implement it. 1</p><p>6 0.6273964 <a title="314-lsi-6" href="./nips-2012-Cocktail_Party_Processing_via_Structured_Prediction.html">72 nips-2012-Cocktail Party Processing via Structured Prediction</a></p>
<p>7 0.6082623 <a title="314-lsi-7" href="./nips-2012-Fully_Bayesian_inference_for_neural_models_with_negative-binomial_spiking.html">138 nips-2012-Fully Bayesian inference for neural models with negative-binomial spiking</a></p>
<p>8 0.60663903 <a title="314-lsi-8" href="./nips-2012-A_Nonparametric_Conjugate_Prior_Distribution_for_the_Maximizing_Argument_of_a_Noisy_Function.html">13 nips-2012-A Nonparametric Conjugate Prior Distribution for the Maximizing Argument of a Noisy Function</a></p>
<p>9 0.56969595 <a title="314-lsi-9" href="./nips-2012-Controlled_Recognition_Bounds_for_Visual_Learning_and_Exploration.html">83 nips-2012-Controlled Recognition Bounds for Visual Learning and Exploration</a></p>
<p>10 0.55434817 <a title="314-lsi-10" href="./nips-2012-Causal_discovery_with_scale-mixture_model_for_spatiotemporal_variance_dependencies.html">66 nips-2012-Causal discovery with scale-mixture model for spatiotemporal variance dependencies</a></p>
<p>11 0.53059101 <a title="314-lsi-11" href="./nips-2012-Spectral_learning_of_linear_dynamics_from_generalised-linear_observations_with_application_to_neural_population_data.html">321 nips-2012-Spectral learning of linear dynamics from generalised-linear observations with application to neural population data</a></p>
<p>12 0.52424061 <a title="314-lsi-12" href="./nips-2012-Relax_and_Randomize_%3A_From_Value_to_Algorithms.html">293 nips-2012-Relax and Randomize : From Value to Algorithms</a></p>
<p>13 0.49700364 <a title="314-lsi-13" href="./nips-2012-Regularized_Off-Policy_TD-Learning.html">292 nips-2012-Regularized Off-Policy TD-Learning</a></p>
<p>14 0.43635511 <a title="314-lsi-14" href="./nips-2012-Searching_for_objects_driven_by_context.html">303 nips-2012-Searching for objects driven by context</a></p>
<p>15 0.4057503 <a title="314-lsi-15" href="./nips-2012-On_Lifting_the_Gibbs_Sampling_Algorithm.html">251 nips-2012-On Lifting the Gibbs Sampling Algorithm</a></p>
<p>16 0.38710731 <a title="314-lsi-16" href="./nips-2012-A_Marginalized_Particle_Gaussian_Process_Regression.html">11 nips-2012-A Marginalized Particle Gaussian Process Regression</a></p>
<p>17 0.38309887 <a title="314-lsi-17" href="./nips-2012-Forward-Backward_Activation_Algorithm_for_Hierarchical_Hidden_Markov_Models.html">136 nips-2012-Forward-Backward Activation Algorithm for Hierarchical Hidden Markov Models</a></p>
<p>18 0.38081431 <a title="314-lsi-18" href="./nips-2012-The_Time-Marginalized_Coalescent_Prior_for_Hierarchical_Clustering.html">339 nips-2012-The Time-Marginalized Coalescent Prior for Hierarchical Clustering</a></p>
<p>19 0.37431109 <a title="314-lsi-19" href="./nips-2012-Multi-Task_Averaging.html">222 nips-2012-Multi-Task Averaging</a></p>
<p>20 0.36988586 <a title="314-lsi-20" href="./nips-2012-Ancestor_Sampling_for_Particle_Gibbs.html">41 nips-2012-Ancestor Sampling for Particle Gibbs</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.027), (21, 0.024), (22, 0.011), (38, 0.069), (42, 0.025), (54, 0.02), (55, 0.014), (74, 0.03), (76, 0.11), (80, 0.556), (92, 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95474249 <a title="314-lda-1" href="./nips-2012-Slice_Normalized_Dynamic_Markov_Logic_Networks.html">314 nips-2012-Slice Normalized Dynamic Markov Logic Networks</a></p>
<p>Author: Tivadar Papai, Henry Kautz, Daniel Stefankovic</p><p>Abstract: Markov logic is a widely used tool in statistical relational learning, which uses a weighted ﬁrst-order logic knowledge base to specify a Markov random ﬁeld (MRF) or a conditional random ﬁeld (CRF). In many applications, a Markov logic network (MLN) is trained in one domain, but used in a different one. This paper focuses on dynamic Markov logic networks, where the size of the discretized time-domain typically varies between training and testing. It has been previously pointed out that the marginal probabilities of truth assignments to ground atoms can change if one extends or reduces the domains of predicates in an MLN. We show that in addition to this problem, the standard way of unrolling a Markov logic theory into a MRF may result in time-inhomogeneity of the underlying Markov chain. Furthermore, even if these representational problems are not signiﬁcant for a given domain, we show that the more practical problem of generating samples in a sequential conditional random ﬁeld for the next slice relying on the samples from the previous slice has high computational cost in the general case, due to the need to estimate a normalization factor for each sample. We propose a new discriminative model, slice normalized dynamic Markov logic networks (SN-DMLN), that suffers from none of these issues. It supports efﬁcient online inference, and can directly model inﬂuences between variables within a time slice that do not have a causal direction, in contrast with fully directed models (e.g., DBNs). Experimental results show an improvement in accuracy over previous approaches to online inference in dynamic Markov logic networks. 1</p><p>2 0.95269507 <a title="314-lda-2" href="./nips-2012-Fully_Bayesian_inference_for_neural_models_with_negative-binomial_spiking.html">138 nips-2012-Fully Bayesian inference for neural models with negative-binomial spiking</a></p>
<p>Author: James Scott, Jonathan W. Pillow</p><p>Abstract: Characterizing the information carried by neural populations in the brain requires accurate statistical models of neural spike responses. The negative-binomial distribution provides a convenient model for over-dispersed spike counts, that is, responses with greater-than-Poisson variability. Here we describe a powerful data-augmentation framework for fully Bayesian inference in neural models with negative-binomial spiking. Our approach relies on a recently described latentvariable representation of the negative-binomial distribution, which equates it to a Polya-gamma mixture of normals. This framework provides a tractable, conditionally Gaussian representation of the posterior that can be used to design efﬁcient EM and Gibbs sampling based algorithms for inference in regression and dynamic factor models. We apply the model to neural data from primate retina and show that it substantially outperforms Poisson regression on held-out data, and reveals latent structure underlying spike count correlations in simultaneously recorded spike trains. 1</p><p>3 0.95242345 <a title="314-lda-3" href="./nips-2012-Multilabel_Classification_using_Bayesian_Compressed_Sensing.html">228 nips-2012-Multilabel Classification using Bayesian Compressed Sensing</a></p>
<p>Author: Ashish Kapoor, Raajay Viswanathan, Prateek Jain</p><p>Abstract: In this paper, we present a Bayesian framework for multilabel classiďŹ cation using compressed sensing. The key idea in compressed sensing for multilabel classiďŹ cation is to ďŹ rst project the label vector to a lower dimensional space using a random transformation and then learn regression functions over these projections. Our approach considers both of these components in a single probabilistic model, thereby jointly optimizing over compression as well as learning tasks. We then derive an efďŹ cient variational inference scheme that provides joint posterior distribution over all the unobserved labels. The two key beneďŹ ts of the model are that a) it can naturally handle datasets that have missing labels and b) it can also measure uncertainty in prediction. The uncertainty estimate provided by the model allows for active learning paradigms where an oracle provides information about labels that promise to be maximally informative for the prediction task. Our experiments show signiďŹ cant boost over prior methods in terms of prediction performance over benchmark datasets, both in the fully labeled and the missing labels case. Finally, we also highlight various useful active learning scenarios that are enabled by the probabilistic model. 1</p><p>4 0.94997549 <a title="314-lda-4" href="./nips-2012-MAP_Inference_in_Chains_using_Column_Generation.html">204 nips-2012-MAP Inference in Chains using Column Generation</a></p>
<p>Author: David Belanger, Alexandre Passos, Sebastian Riedel, Andrew McCallum</p><p>Abstract: Linear chains and trees are basic building blocks in many applications of graphical models, and they admit simple exact maximum a-posteriori (MAP) inference algorithms based on message passing. However, in many cases this computation is prohibitively expensive, due to quadratic dependence on variables’ domain sizes. The standard algorithms are inefﬁcient because they compute scores for hypotheses for which there is strong negative local evidence. For this reason there has been signiﬁcant previous interest in beam search and its variants; however, these methods provide only approximate results. This paper presents new exact inference algorithms based on the combination of column generation and pre-computed bounds on terms of the model’s scoring function. While we do not improve worst-case performance, our method substantially speeds real-world, typical-case inference in chains and trees. Experiments show our method to be twice as fast as exact Viterbi for Wall Street Journal part-of-speech tagging and over thirteen times faster for a joint part-of-speed and named-entity-recognition task. Our algorithm is also extendable to new techniques for approximate inference, to faster 0/1 loss oracles, and new opportunities for connections between inference and learning. We encourage further exploration of high-level reasoning about the optimization problem implicit in dynamic programs. 1</p><p>5 0.92342782 <a title="314-lda-5" href="./nips-2012-Discriminative_Learning_of_Sum-Product_Networks.html">100 nips-2012-Discriminative Learning of Sum-Product Networks</a></p>
<p>Author: Robert Gens, Pedro Domingos</p><p>Abstract: Sum-product networks are a new deep architecture that can perform fast, exact inference on high-treewidth models. Only generative methods for training SPNs have been proposed to date. In this paper, we present the ﬁrst discriminative training algorithms for SPNs, combining the high accuracy of the former with the representational power and tractability of the latter. We show that the class of tractable discriminative SPNs is broader than the class of tractable generative ones, and propose an efﬁcient backpropagation-style algorithm for computing the gradient of the conditional log likelihood. Standard gradient descent suffers from the diffusion problem, but networks with many layers can be learned reliably using “hard” gradient descent, where marginal inference is replaced by MPE inference (i.e., inferring the most probable state of the non-evidence variables). The resulting updates have a simple and intuitive form. We test discriminative SPNs on standard image classiﬁcation tasks. We obtain the best results to date on the CIFAR-10 dataset, using fewer features than prior methods with an SPN architecture that learns local image structure discriminatively. We also report the highest published test accuracy on STL-10 even though we only use the labeled portion of the dataset. 1</p><p>6 0.90680093 <a title="314-lda-6" href="./nips-2012-Classification_Calibration_Dimension_for_General_Multiclass_Losses.html">67 nips-2012-Classification Calibration Dimension for General Multiclass Losses</a></p>
<p>7 0.8121348 <a title="314-lda-7" href="./nips-2012-Expectation_Propagation_in_Gaussian_Process_Dynamical_Systems.html">121 nips-2012-Expectation Propagation in Gaussian Process Dynamical Systems</a></p>
<p>8 0.78091228 <a title="314-lda-8" href="./nips-2012-Mixing_Properties_of_Conditional_Markov_Chains_with_Unbounded_Feature_Functions.html">218 nips-2012-Mixing Properties of Conditional Markov Chains with Unbounded Feature Functions</a></p>
<p>9 0.75295937 <a title="314-lda-9" href="./nips-2012-On_Lifting_the_Gibbs_Sampling_Algorithm.html">251 nips-2012-On Lifting the Gibbs Sampling Algorithm</a></p>
<p>10 0.74280596 <a title="314-lda-10" href="./nips-2012-Provable_ICA_with_Unknown_Gaussian_Noise%2C_with_Implications_for_Gaussian_Mixtures_and_Autoencoders.html">281 nips-2012-Provable ICA with Unknown Gaussian Noise, with Implications for Gaussian Mixtures and Autoencoders</a></p>
<p>11 0.73264366 <a title="314-lda-11" href="./nips-2012-Latent_Coincidence_Analysis%3A_A_Hidden_Variable_Model_for_Distance_Metric_Learning.html">171 nips-2012-Latent Coincidence Analysis: A Hidden Variable Model for Distance Metric Learning</a></p>
<p>12 0.73126668 <a title="314-lda-12" href="./nips-2012-Local_Supervised_Learning_through_Space_Partitioning.html">200 nips-2012-Local Supervised Learning through Space Partitioning</a></p>
<p>13 0.72521222 <a title="314-lda-13" href="./nips-2012-Relax_and_Randomize_%3A_From_Value_to_Algorithms.html">293 nips-2012-Relax and Randomize : From Value to Algorithms</a></p>
<p>14 0.71115464 <a title="314-lda-14" href="./nips-2012-Mandatory_Leaf_Node_Prediction_in_Hierarchical_Multilabel_Classification.html">207 nips-2012-Mandatory Leaf Node Prediction in Hierarchical Multilabel Classification</a></p>
<p>15 0.70606214 <a title="314-lda-15" href="./nips-2012-Learning_with_Recursive_Perceptual_Representations.html">197 nips-2012-Learning with Recursive Perceptual Representations</a></p>
<p>16 0.70383084 <a title="314-lda-16" href="./nips-2012-Projection_Retrieval_for_Classification.html">279 nips-2012-Projection Retrieval for Classification</a></p>
<p>17 0.69327074 <a title="314-lda-17" href="./nips-2012-Slice_sampling_normalized_kernel-weighted_completely_random_measure_mixture_models.html">315 nips-2012-Slice sampling normalized kernel-weighted completely random measure mixture models</a></p>
<p>18 0.69212091 <a title="314-lda-18" href="./nips-2012-Bayesian_active_learning_with_localized_priors_for_fast_receptive_field_characterization.html">56 nips-2012-Bayesian active learning with localized priors for fast receptive field characterization</a></p>
<p>19 0.68010008 <a title="314-lda-19" href="./nips-2012-Kernel_Latent_SVM_for_Visual_Recognition.html">168 nips-2012-Kernel Latent SVM for Visual Recognition</a></p>
<p>20 0.67590606 <a title="314-lda-20" href="./nips-2012-On_Multilabel_Classification_and_Ranking_with_Partial_Feedback.html">252 nips-2012-On Multilabel Classification and Ranking with Partial Feedback</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
