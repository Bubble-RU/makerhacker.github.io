<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>82 nips-2012-Continuous Relaxations for Discrete Hamiltonian Monte Carlo</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-82" href="#">nips2012-82</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>82 nips-2012-Continuous Relaxations for Discrete Hamiltonian Monte Carlo</h1>
<br/><p>Source: <a title="nips-2012-82-pdf" href="http://papers.nips.cc/paper/4652-continuous-relaxations-for-discrete-hamiltonian-monte-carlo.pdf">pdf</a></p><p>Author: Yichuan Zhang, Zoubin Ghahramani, Amos J. Storkey, Charles A. Sutton</p><p>Abstract: Continuous relaxations play an important role in discrete optimization, but have not seen much use in approximate probabilistic inference. Here we show that a general form of the Gaussian Integral Trick makes it possible to transform a wide class of discrete variable undirected models into fully continuous systems. The continuous representation allows the use of gradient-based Hamiltonian Monte Carlo for inference, results in new ways of estimating normalization constants (partition functions), and in general opens up a number of new avenues for inference in difﬁcult discrete systems. We demonstrate some of these continuous relaxation inference algorithms on a number of illustrative problems. 1</p><p>Reference: <a title="nips-2012-82-reference" href="../nips2012_reference/nips-2012-Continuous_Relaxations_for_Discrete_Hamiltonian_Monte_Carlo_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 uk  Abstract Continuous relaxations play an important role in discrete optimization, but have not seen much use in approximate probabilistic inference. [sent-14, score-0.204]
</p><p>2 Here we show that a general form of the Gaussian Integral Trick makes it possible to transform a wide class of discrete variable undirected models into fully continuous systems. [sent-15, score-0.34]
</p><p>3 The continuous representation allows the use of gradient-based Hamiltonian Monte Carlo for inference, results in new ways of estimating normalization constants (partition functions), and in general opens up a number of new avenues for inference in difﬁcult discrete systems. [sent-16, score-0.472]
</p><p>4 We demonstrate some of these continuous relaxation inference algorithms on a number of illustrative problems. [sent-17, score-0.191]
</p><p>5 Although sophisticated inference algorithms exist for these models, including both exact algorithms and variational approximations, it has proven more difﬁcult to develop discrete Markov chain Monte Carlo (MCMC) methods. [sent-19, score-0.27]
</p><p>6 Despite much work and many recent advances [3], the most commonly used MCMC methods in practice for discrete models are based on MetropolisHastings, the effectiveness of which is strongly dependent on the choice of proposal distribution. [sent-20, score-0.134]
</p><p>7 An appealing idea is to relax the constraint that the random variables of interest take integral values. [sent-21, score-0.17]
</p><p>8 Continuous problems are appealing because the gradient is on your side: Unlike discrete probability mass functions, in the continuous setting, densities have derivatives, contours, and curvature that can be used to inform sampling algorithms [6, 16, 18, 20, 27]. [sent-23, score-0.287]
</p><p>9 For this reason, continuous relaxations are widespread in combinatorial optimization, and likewise a major appeal of variational methods is that they convert discrete inference problems into continuous optimization problems. [sent-24, score-0.506]
</p><p>10 In this paper we provide a method for relaxing a discrete model into a continuous one, using a technique from statistical physics that Hertz et al. [sent-26, score-0.326]
</p><p>11 [8] call the “Gaussian integral trick,” and that we present in a more general form than is typical. [sent-27, score-0.17]
</p><p>12 This trick is also known as the Hubbard-Stratonovich transform [10]. [sent-28, score-0.282]
</p><p>13 Starting with a discrete Markov random ﬁeld (MRF), the trick introduces an auxiliary Gaussian variable in such a way that the discrete dependencies cancel out. [sent-29, score-0.576]
</p><p>14 This allows the discrete variables to be summed away, leaving a continuous problem. [sent-30, score-0.279]
</p><p>15 The continuous representation allows the use of gradient-based Hamiltonian Monte Carlo for inference, highlights an equivalence between Boltzmann machines and the Gaussian-Bernoulli harmonium model [25], and in general opens up a number of new avenues for inference in difﬁcult discrete 1  systems. [sent-31, score-0.59]
</p><p>16 On synthetic problems and a real world problem in text processing, we show that HMC in the continuous relaxation can be much more accurate than standard MCMC methods on the discrete distribution. [sent-32, score-0.293]
</p><p>17 The only previous work of which we are aware that uses the Gaussian integral trick for inference in graphical models is Martens and Sutskever [12]. [sent-33, score-0.533]
</p><p>18 They use the trick to transform an arbitrary MRF into an equivalent restricted Boltzmann machine (RBM), on which they then do block Gibbs sampling. [sent-34, score-0.41]
</p><p>19 They show that this transformation is useful when each block Gibbs step can be performed in parallel. [sent-35, score-0.128]
</p><p>20 However, unlike the current work, they do not sum out the discrete variables, so they do not perform a full continuous relaxation. [sent-36, score-0.245]
</p><p>21 Every discrete undirected model can be converted into a pairwise model at the cost of expanding the state space. [sent-52, score-0.271]
</p><p>22 The undirected pairwise graphical model can be written in the form 1 p(s) = exp(−Eij (si , sj )) (1) Z (i,j)∈G  where Z is a normalisation term, and is a sum over all valid states of (s1 , s2 , . [sent-53, score-0.214]
</p><p>23 Equivalently we can set Eij (si , sj ) to be very large when si and sj are derived from the same variable tk (for some k and i = j, and expanding G to include (i, j)), making the resulting product for the terms that break the 1 of Ki constraints to be exponentially small. [sent-57, score-0.344]
</p><p>24 The normalization function is 1 Z= exp aT s + sT W s . [sent-60, score-0.114]
</p><p>25 (3) 2 s  3  Gaussian Integral Trick  Inference in Boltzmann machines (which is equivalent to inference in Ising models) has always been a challenging problem. [sent-61, score-0.12]
</p><p>26 Typically Markov chain Monte Carlo procedures such as Gibbs sampling have been used, but the high levels of connectivity in Boltzmann machines can cause trouble and result in slow mixing in many situations. [sent-62, score-0.176]
</p><p>27 Furthermore for frustrated systems, such models are highly multimodal [1], often with large potential barriers between the different modes. [sent-63, score-0.219]
</p><p>28 For this reason, we choose to work with a real valued augmentation of the Boltzmann machine using the Gaussian integral trick. [sent-65, score-0.256]
</p><p>29 We generalise the standard form of the Gaussian integral trick by using the following form for the conditional distribution of the auxiliary variable x: p(x|s) = N (x; A(W + D)s, A(W + D)AT ) (4) for any choice of invertible matrix A and any diagonal matrix D for which W + D is positive deﬁnite. [sent-67, score-0.521]
</p><p>30 Then the marginal density is 1 p(x) ∝ exp − xT A−1 (W + D)−1 (A−1 )T x 2  1 + exp αx;i + ai − i  di 2  . [sent-74, score-0.405]
</p><p>31 We have now converted the discrete distribution p(s) into a corresponding continuous distribution p(x). [sent-79, score-0.283]
</p><p>32 First, all of the si are independent given x, because s appears only log-linearly in (6). [sent-81, score-0.176]
</p><p>33 Using the sigmoid σ(z) = (1 + exp{−z})−1 , this is p(si |x) = σ −αx;i − ai +  di 2  1−si  σ αx;i + ai −  si  di 2  (8)  Two choices for A are of particular interest because they introduce additional independence rela1 tionships into the augmented model. [sent-82, score-0.576]
</p><p>34 First, if A = Λ− 2 V T for the eigendecomposition W + D = V ΛV T , then the result is an undirected bipartite graphical model in the joint space of (x, s): 1 1 1 p(x, s) ∝ exp − xT x + sT V Λ 2 x + (a − d)T s . [sent-83, score-0.141]
</p><p>35 2 2  (9)  This is a Gaussian-Bernoulli form of exponential family harmonium [25]. [sent-84, score-0.147]
</p><p>36 Hence we see that the Gaussian-Bernoulli harmonium is equivalent to a general Boltzmann machine over the discrete variables only. [sent-85, score-0.281]
</p><p>37 A given xi determines the Bernoulli probabilities for the variable si , independent of the states of any of the other variables. [sent-87, score-0.209]
</p><p>38 Then, conditioned on x, the log odds of si = 1 is a recentered version of xi , in particular, xi − ai − di /2. [sent-89, score-0.42]
</p><p>39 The different versions of the Gaussian integral trick can be compactly summarized by the independence relations that they introduce. [sent-90, score-0.454]
</p><p>40 All versions of Gaussian integral trick give us that all si and sj are independent given x. [sent-91, score-0.696]
</p><p>41 Finally if we instead take A = I, we get that si and sj are independent given only xi and xj . [sent-93, score-0.275]
</p><p>42 3  x  x  x  s  s  s  p(s)  Original MRF  A = ⇤ 1/2 V T [MS10; HKP91]  General A  A=I  Current Approach  Figure 1: Graphical depiction of the different versions of the Gaussian integral trick. [sent-95, score-0.204]
</p><p>43 In all of the models here si ∈ {0, 1} while xi ∈ R. [sent-96, score-0.209]
</p><p>44 1  Convexity of Log Density  Because probabilistic inference is NP-hard, it is too much to expect that the continuous transformation will always help. [sent-99, score-0.191]
</p><p>45 Sometimes difﬁcult discrete distributions will be converted into difﬁcult continuous ones. [sent-100, score-0.283]
</p><p>46 Experimentally we have noticed that highly frustrated systems typically result in multimodal p(x). [sent-101, score-0.219]
</p><p>47 It is Hx :=  2 x  log p(x) = Cx − (W + D)−1  (13)  where Cx is a diagonal matrix with elements cii = σ(−ai − xi + di )(1 − σ(−ai − xi + di )). [sent-120, score-0.238]
</p><p>48 2  MCMC in the Continuous Relaxation  Now we discuss how to perform inference in the augmented distribution resulting from the trick. [sent-130, score-0.124]
</p><p>49 Therefore one can sample the joint distribution p(x, s) in a block Gibbs style that switches sampling between p(x|s) and p(s|x). [sent-133, score-0.17]
</p><p>50 In spite of the simplicity of this method, it has the potential difﬁculty that it may generate highly correlated samples, due to the coupling between discrete and continuous samples. [sent-134, score-0.281]
</p><p>51 To overcome the drawbacks of block Gibbs sampling, we propose running MCMC directly on the marginal p(x). [sent-135, score-0.229]
</p><p>52 We refer to the use of HMC on p(x) as discrete Hamiltonian Monte Carlo (DHMC). [sent-139, score-0.134]
</p><p>53 3  Estimating Marginal Probabilities  Given a set of samples that are approximately distributed from p(x) we can estimate the marginal distribution over any subset Sq ⊆ S of the discrete variables. [sent-142, score-0.275]
</p><p>54 The marginal probability p(sq ) can be estimated as p(sq ) ≈  M  1 M  p(Sq |x(m) ) = m=1  1 M  M  p(si |x(m) )  x(m) ∼ p(x)  m=1 si ∈Sq  This gives us a Rao-Blackwellized estimate of p(sq ) without needing to sample s directly. [sent-145, score-0.277]
</p><p>55 4  Normalizing Constants  Because the normalizing factor Z −1 of the Boltzmann machine is equal to the probability p(s = 0), we can estimate the normalizing factor using the technique from the previous section Z  −1  1 = p(s = 0) ≈ M  M  p(s = 0|x(m) ) x(m) ∼ p(x). [sent-148, score-0.112]
</p><p>56 Using the identity Z −1 = Z −1 dx q(x) we have Z −1 = Z −1  dx q(x)  p∗ (x) = p∗ (x)  dx  q(x) p(x), p∗ (x)  (m)  1 ˆ A Monte Carlo estimate of this integral is Z −1 = M m pq(x (m))) for x(m) ∼ p(x). [sent-158, score-0.263]
</p><p>57 This importance trick is well known in the statistics literature, e. [sent-165, score-0.25]
</p><p>58 The Ising model was studied as a model of physical spin systems, and so the dynamics used were typically representative of the physics, with Glauber dynamics [7] being a common model, e. [sent-171, score-0.24]
</p><p>59 In the context of stochastic neural models, though, there was the potential to examine other dynamics that did not match the standard 5  physics of spin systems. [sent-174, score-0.228]
</p><p>60 The Gaussian integral trick is also known as the Hubbard-Stratonovich transformation in physics[10]. [sent-178, score-0.42]
</p><p>61 In the area of neural modelling, the Gaussian integral trick was also common for theoretical reasons rather than as a practical augmentation strategy [8]. [sent-179, score-0.488]
</p><p>62 The Gaussian integral trick formed a critical part of replica-theoretical analysis [8] for phase analysis of spin systems, as it enabled ensemble averaging of the spin components, leading to saddle-point equations in the continuous domain. [sent-180, score-0.701]
</p><p>63 The Gaussian integral trick relates the general Boltzmann machines to exponential family harmoniums [25], which generalise the restricted Boltzmann machines. [sent-182, score-0.555]
</p><p>64 The speciﬁc Gaussian-Bernoulli harmonium is in common use, but where the real valued variables are visible units and the binary variables are hidden variables [9]. [sent-183, score-0.198]
</p><p>65 The only work of which we are aware that uses the Gaussian integral trick for probabilistic inference is that of Martens and Sutskever [12]. [sent-185, score-0.5]
</p><p>66 This work also considers inference in MRFs, using the special 1 case of the Gaussian integral trick in which A = Λ− 2 V T . [sent-186, score-0.5]
</p><p>67 Instead they perform inference directly in the resulting harmonium, using block Gibbs sampling alternating between s and x. [sent-188, score-0.25]
</p><p>68 On serial computers, they do not ﬁnd that this expanded representation offers much beneﬁt over performing single-site Gibbs in the discrete space. [sent-189, score-0.134]
</p><p>69 Indeed they ﬁnd that the sampler in the augmented model is actually slightly slower than the one in the original discrete space. [sent-190, score-0.276]
</p><p>70 We evaluate both the estimation of node marginal and of the normalisation factor estimation on two synthetic models. [sent-193, score-0.253]
</p><p>71 We compare the accuracy of the discrete HMC sampler to Gibbs sampling in the original discrete model p(s) and to block Gibbs sampling the augmented model p(x, s). [sent-194, score-0.622]
</p><p>72 The Gibbs sampler resamples one node at a time from p(si |s−i ). [sent-196, score-0.15]
</p><p>73 The node marginal probability p(si ) is estimated by the empirical probability of the samples. [sent-197, score-0.153]
</p><p>74 The block Gibbs sampler over p(x, s) we use is based on [12]. [sent-199, score-0.226]
</p><p>75 This comparison is designed to evaluate the beneﬁts of summing away the discrete variables. [sent-200, score-0.134]
</p><p>76 To estimate the node marginals, we use the block Gibbs sampler to generate samples of x and then apply the Rao-Blackwellized estimators from Sections 3. [sent-201, score-0.354]
</p><p>77 HMC can generate better samples while a large number of leapfrog steps is used, but this requires much more computation time. [sent-206, score-0.194]
</p><p>78 For a ﬁxed computational budget, using more leapfrog steps causes fewer samples to be generated, which can also undermine the accuracy of the estimator. [sent-207, score-0.158]
</p><p>79 So, we empirically pick 5 leapfrog steps and tuning the leapfrog step size so that acceptance rate is around 90%. [sent-208, score-0.236]
</p><p>80 5  25  20  biases scale  biases scale  biases scale  3  2. [sent-219, score-0.861]
</p><p>81 5  3  weights scale  Figure 2: Performance of samplers on synthetic grid-structured Boltzmann machines. [sent-260, score-0.294]
</p><p>82 The top row shows error in the normalization constant, while the bottom row shows average error in the single-mode marginal distributions. [sent-262, score-0.17]
</p><p>83 In the standard case, for each node si , the biases are generated as ai ∼ c1 N (0, 4). [sent-265, score-0.52]
</p><p>84 The parameters c1 and c2 deﬁne the scales of the biases and weights and determine how hard the problem is. [sent-267, score-0.276]
</p><p>85 In the frustrated case, we shift the weights to make the problem more difﬁcult. [sent-268, score-0.252]
</p><p>86 We still generate the weights as wij ∼ c2 N (0, 4) but now we generate the biases as ai ∼ c1 N ( i wij , 4). [sent-269, score-0.53]
</p><p>87 We report the MSE of the node marginal estimate and the log normalising constant estimate averaged over 10 runs. [sent-273, score-0.225]
</p><p>88 DHMC beats Gibbs on p(s) at the normalization constant and beats block Gibbs on p(x, s) at marginal estimation. [sent-278, score-0.384]
</p><p>89 The frustrated graphs (Figure 3) are signiﬁcantly more difﬁcult for DHMC, as expected. [sent-279, score-0.176]
</p><p>90 All three samplers seem to have trouble in the same area of model space, although DHMC suffers somewhat worse than the other methods in marginal error, while still beating Chib’s method for normalization constants. [sent-280, score-0.291]
</p><p>91 We observe that in both cases block Gibbs of p(x, s) performs roughly the same at marginal estimation as Gibbs on p(s). [sent-283, score-0.229]
</p><p>92 5  biases scale  biases scale  biases scale  90  2  1. [sent-295, score-0.861]
</p><p>93 5  3  weights scale  Figure 3: Performance of samplers on a set of highly frustrated grid-structured Boltzmann machines. [sent-336, score-0.422]
</p><p>94 The top row shows error in the normalization constant, while the bottom row shows average error in the single-mode marginal distributions. [sent-338, score-0.17]
</p><p>95 We see that the HMC sampler is much more accurate than either of the other samplers at estimating single-node marginals. [sent-344, score-0.181]
</p><p>96 The block Gibbs sampler yields both worse estimates of the marginals and a signiﬁcantly worse estimate of the normalization constant. [sent-346, score-0.328]
</p><p>97 We described a continuum of different versions of the trick that have different properties. [sent-354, score-0.284]
</p><p>98 Although we illustrated the beneﬁts of the continuous setting by using Hamiltonian Monte Carlo, in future work other inference methods such as elliptical slice sampling or more advanced HMC methods may prove superior. [sent-355, score-0.274]
</p><p>99 Bayesian inference for PCFGs via Markov chain Monte Carlo. [sent-446, score-0.136]
</p><p>100 An efﬁcient Markov chain Monte Carlo method for distributions with intractable normalising constants. [sent-467, score-0.128]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('hamiltonian', 0.348), ('trick', 0.25), ('gibbs', 0.225), ('hmc', 0.214), ('dhmc', 0.206), ('biases', 0.2), ('boltzmann', 0.192), ('frustrated', 0.176), ('si', 0.176), ('integral', 0.17), ('harmonium', 0.147), ('sq', 0.138), ('discrete', 0.134), ('monte', 0.13), ('block', 0.128), ('leapfrog', 0.118), ('continuous', 0.111), ('mcmc', 0.108), ('carlo', 0.102), ('marginal', 0.101), ('sampler', 0.098), ('ai', 0.092), ('scale', 0.087), ('di', 0.086), ('spin', 0.085), ('ising', 0.083), ('samplers', 0.083), ('inference', 0.08), ('martens', 0.078), ('weights', 0.076), ('normalising', 0.072), ('hop', 0.072), ('relaxations', 0.07), ('cx', 0.07), ('normalization', 0.069), ('gaussian', 0.068), ('sj', 0.066), ('st', 0.065), ('mrf', 0.064), ('undirected', 0.063), ('dynamics', 0.061), ('auxiliary', 0.058), ('chain', 0.056), ('normalizing', 0.056), ('hx', 0.055), ('messages', 0.054), ('estimator', 0.054), ('node', 0.052), ('normalisation', 0.052), ('harmoniums', 0.052), ('valued', 0.051), ('ki', 0.051), ('axes', 0.051), ('physics', 0.049), ('synthetic', 0.048), ('chib', 0.048), ('hertz', 0.048), ('murray', 0.046), ('exp', 0.045), ('wij', 0.045), ('avenues', 0.045), ('augmented', 0.044), ('markov', 0.043), ('eij', 0.043), ('beats', 0.043), ('generalise', 0.043), ('multimodal', 0.043), ('gaussians', 0.043), ('sampling', 0.042), ('sutton', 0.042), ('sutskever', 0.041), ('elliptical', 0.041), ('kingdom', 0.041), ('machines', 0.04), ('samples', 0.04), ('modes', 0.039), ('trouble', 0.038), ('converted', 0.038), ('extraction', 0.037), ('generate', 0.036), ('welling', 0.036), ('expanding', 0.036), ('density', 0.036), ('augmentation', 0.035), ('versions', 0.034), ('summed', 0.034), ('physical', 0.033), ('marginals', 0.033), ('xi', 0.033), ('zoubin', 0.033), ('opens', 0.033), ('xt', 0.033), ('graphical', 0.033), ('neural', 0.033), ('dif', 0.033), ('relaxing', 0.032), ('crf', 0.032), ('cult', 0.032), ('transform', 0.032), ('dx', 0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="82-tfidf-1" href="./nips-2012-Continuous_Relaxations_for_Discrete_Hamiltonian_Monte_Carlo.html">82 nips-2012-Continuous Relaxations for Discrete Hamiltonian Monte Carlo</a></p>
<p>Author: Yichuan Zhang, Zoubin Ghahramani, Amos J. Storkey, Charles A. Sutton</p><p>Abstract: Continuous relaxations play an important role in discrete optimization, but have not seen much use in approximate probabilistic inference. Here we show that a general form of the Gaussian Integral Trick makes it possible to transform a wide class of discrete variable undirected models into fully continuous systems. The continuous representation allows the use of gradient-based Hamiltonian Monte Carlo for inference, results in new ways of estimating normalization constants (partition functions), and in general opens up a number of new avenues for inference in difﬁcult discrete systems. We demonstrate some of these continuous relaxation inference algorithms on a number of illustrative problems. 1</p><p>2 0.22229247 <a title="82-tfidf-2" href="./nips-2012-Training_sparse_natural_image_models_with_a_fast_Gibbs_sampler_of_an_extended_state_space.html">349 nips-2012-Training sparse natural image models with a fast Gibbs sampler of an extended state space</a></p>
<p>Author: Lucas Theis, Jascha Sohl-dickstein, Matthias Bethge</p><p>Abstract: We present a new learning strategy based on an efﬁcient blocked Gibbs sampler for sparse overcomplete linear models. Particular emphasis is placed on statistical image modeling, where overcomplete models have played an important role in discovering sparse representations. Our Gibbs sampler is faster than general purpose sampling schemes while also requiring no tuning as it is free of parameters. Using the Gibbs sampler and a persistent variant of expectation maximization, we are able to extract highly sparse distributions over latent sources from data. When applied to natural images, our algorithm learns source distributions which resemble spike-and-slab distributions. We evaluate the likelihood and quantitatively compare the performance of the overcomplete linear model to its complete counterpart as well as a product of experts model, which represents another overcomplete generalization of the complete linear model. In contrast to previous claims, we ﬁnd that overcomplete representations lead to signiﬁcant improvements, but that the overcomplete linear model still underperforms other models. 1</p><p>3 0.13957424 <a title="82-tfidf-3" href="./nips-2012-Dynamic_Pruning_of_Factor_Graphs_for_Maximum_Marginal_Prediction.html">105 nips-2012-Dynamic Pruning of Factor Graphs for Maximum Marginal Prediction</a></p>
<p>Author: Christoph H. Lampert</p><p>Abstract: We study the problem of maximum marginal prediction (MMP) in probabilistic graphical models, a task that occurs, for example, as the Bayes optimal decision rule under a Hamming loss. MMP is typically performed as a two-stage procedure: one estimates each variable’s marginal probability and then forms a prediction from the states of maximal probability. In this work we propose a simple yet effective technique for accelerating MMP when inference is sampling-based: instead of the above two-stage procedure we directly estimate the posterior probability of each decision variable. This allows us to identify the point of time when we are sufﬁciently certain about any individual decision. Whenever this is the case, we dynamically prune the variables we are conﬁdent about from the underlying factor graph. Consequently, at any time only samples of variables whose decision is still uncertain need to be created. Experiments in two prototypical scenarios, multi-label classiﬁcation and image inpainting, show that adaptive sampling can drastically accelerate MMP without sacriﬁcing prediction accuracy. 1</p><p>4 0.11847179 <a title="82-tfidf-4" href="./nips-2012-Sparse_Approximate_Manifolds_for_Differential_Geometric_MCMC.html">318 nips-2012-Sparse Approximate Manifolds for Differential Geometric MCMC</a></p>
<p>Author: Ben Calderhead, Mátyás A. Sustik</p><p>Abstract: One of the enduring challenges in Markov chain Monte Carlo methodology is the development of proposal mechanisms to make moves distant from the current point, that are accepted with high probability and at low computational cost. The recent introduction of locally adaptive MCMC methods based on the natural underlying Riemannian geometry of such models goes some way to alleviating these problems for certain classes of models for which the metric tensor is analytically tractable, however computational efﬁciency is not assured due to the necessity of potentially high-dimensional matrix operations at each iteration. In this paper we ﬁrstly investigate a sampling-based approach for approximating the metric tensor and suggest a valid MCMC algorithm that extends the applicability of Riemannian Manifold MCMC methods to statistical models that do not admit an analytically computable metric tensor. Secondly, we show how the approximation scheme we consider naturally motivates the use of 1 regularisation to improve estimates and obtain a sparse approximate inverse of the metric, which enables stable and sparse approximations of the local geometry to be made. We demonstrate the application of this algorithm for inferring the parameters of a realistic system of ordinary differential equations using a biologically motivated robust Student-t error model, for which the Expected Fisher Information is analytically intractable. 1</p><p>5 0.11706315 <a title="82-tfidf-5" href="./nips-2012-Efficient_Sampling_for_Bipartite_Matching_Problems.html">111 nips-2012-Efficient Sampling for Bipartite Matching Problems</a></p>
<p>Author: Maksims Volkovs, Richard S. Zemel</p><p>Abstract: Bipartite matching problems characterize many situations, ranging from ranking in information retrieval to correspondence in vision. Exact inference in realworld applications of these problems is intractable, making efﬁcient approximation methods essential for learning and inference. In this paper we propose a novel sequential matching sampler based on a generalization of the PlackettLuce model, which can effectively make large moves in the space of matchings. This allows the sampler to match the difﬁcult target distributions common in these problems: highly multimodal distributions with well separated modes. We present experimental results with bipartite matching problems—ranking and image correspondence—which show that the sequential matching sampler efﬁciently approximates the target distribution, signiﬁcantly outperforming other sampling approaches. 1</p><p>6 0.10855456 <a title="82-tfidf-6" href="./nips-2012-Small-Variance_Asymptotics_for_Exponential_Family_Dirichlet_Process_Mixture_Models.html">316 nips-2012-Small-Variance Asymptotics for Exponential Family Dirichlet Process Mixture Models</a></p>
<p>7 0.10809717 <a title="82-tfidf-7" href="./nips-2012-Learning_as_MAP_Inference_in_Discrete_Graphical_Models.html">186 nips-2012-Learning as MAP Inference in Discrete Graphical Models</a></p>
<p>8 0.10214404 <a title="82-tfidf-8" href="./nips-2012-Ancestor_Sampling_for_Particle_Gibbs.html">41 nips-2012-Ancestor Sampling for Particle Gibbs</a></p>
<p>9 0.10045412 <a title="82-tfidf-9" href="./nips-2012-Structure_estimation_for_discrete_graphical_models%3A_Generalized_covariance_matrices_and_their_inverses.html">326 nips-2012-Structure estimation for discrete graphical models: Generalized covariance matrices and their inverses</a></p>
<p>10 0.098005377 <a title="82-tfidf-10" href="./nips-2012-On_Lifting_the_Gibbs_Sampling_Algorithm.html">251 nips-2012-On Lifting the Gibbs Sampling Algorithm</a></p>
<p>11 0.096554741 <a title="82-tfidf-11" href="./nips-2012-Convergence_Rate_Analysis_of_MAP_Coordinate_Minimization_Algorithms.html">84 nips-2012-Convergence Rate Analysis of MAP Coordinate Minimization Algorithms</a></p>
<p>12 0.093845777 <a title="82-tfidf-12" href="./nips-2012-Slice_sampling_normalized_kernel-weighted_completely_random_measure_mixture_models.html">315 nips-2012-Slice sampling normalized kernel-weighted completely random measure mixture models</a></p>
<p>13 0.092908531 <a title="82-tfidf-13" href="./nips-2012-Active_Learning_of_Model_Evidence_Using_Bayesian_Quadrature.html">33 nips-2012-Active Learning of Model Evidence Using Bayesian Quadrature</a></p>
<p>14 0.089087352 <a title="82-tfidf-14" href="./nips-2012-Algorithms_for_Learning_Markov_Field_Policies.html">38 nips-2012-Algorithms for Learning Markov Field Policies</a></p>
<p>15 0.088011041 <a title="82-tfidf-15" href="./nips-2012-FastEx%3A_Hash_Clustering_with_Exponential_Families.html">126 nips-2012-FastEx: Hash Clustering with Exponential Families</a></p>
<p>16 0.082847685 <a title="82-tfidf-16" href="./nips-2012-Fully_Bayesian_inference_for_neural_models_with_negative-binomial_spiking.html">138 nips-2012-Fully Bayesian inference for neural models with negative-binomial spiking</a></p>
<p>17 0.082440302 <a title="82-tfidf-17" href="./nips-2012-The_Coloured_Noise_Expansion_and_Parameter_Estimation_of_Diffusion_Processes.html">336 nips-2012-The Coloured Noise Expansion and Parameter Estimation of Diffusion Processes</a></p>
<p>18 0.081809394 <a title="82-tfidf-18" href="./nips-2012-Affine_Independent_Variational_Inference.html">37 nips-2012-Affine Independent Variational Inference</a></p>
<p>19 0.08047878 <a title="82-tfidf-19" href="./nips-2012-Graphical_Models_via_Generalized_Linear_Models.html">147 nips-2012-Graphical Models via Generalized Linear Models</a></p>
<p>20 0.079731978 <a title="82-tfidf-20" href="./nips-2012-Density_Propagation_and_Improved_Bounds_on_the_Partition_Function.html">96 nips-2012-Density Propagation and Improved Bounds on the Partition Function</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.242), (1, 0.034), (2, 0.016), (3, 0.009), (4, -0.173), (5, -0.019), (6, -0.011), (7, -0.048), (8, -0.019), (9, -0.043), (10, -0.041), (11, -0.055), (12, -0.011), (13, 0.032), (14, -0.058), (15, -0.137), (16, -0.026), (17, -0.184), (18, 0.044), (19, -0.025), (20, 0.176), (21, -0.065), (22, -0.075), (23, 0.032), (24, -0.086), (25, 0.042), (26, 0.016), (27, 0.011), (28, 0.029), (29, -0.027), (30, -0.027), (31, 0.004), (32, -0.063), (33, 0.057), (34, -0.009), (35, -0.077), (36, -0.045), (37, -0.052), (38, -0.025), (39, -0.058), (40, 0.08), (41, -0.018), (42, 0.006), (43, -0.024), (44, 0.012), (45, 0.06), (46, -0.015), (47, 0.038), (48, -0.014), (49, -0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95961857 <a title="82-lsi-1" href="./nips-2012-Continuous_Relaxations_for_Discrete_Hamiltonian_Monte_Carlo.html">82 nips-2012-Continuous Relaxations for Discrete Hamiltonian Monte Carlo</a></p>
<p>Author: Yichuan Zhang, Zoubin Ghahramani, Amos J. Storkey, Charles A. Sutton</p><p>Abstract: Continuous relaxations play an important role in discrete optimization, but have not seen much use in approximate probabilistic inference. Here we show that a general form of the Gaussian Integral Trick makes it possible to transform a wide class of discrete variable undirected models into fully continuous systems. The continuous representation allows the use of gradient-based Hamiltonian Monte Carlo for inference, results in new ways of estimating normalization constants (partition functions), and in general opens up a number of new avenues for inference in difﬁcult discrete systems. We demonstrate some of these continuous relaxation inference algorithms on a number of illustrative problems. 1</p><p>2 0.84943914 <a title="82-lsi-2" href="./nips-2012-Training_sparse_natural_image_models_with_a_fast_Gibbs_sampler_of_an_extended_state_space.html">349 nips-2012-Training sparse natural image models with a fast Gibbs sampler of an extended state space</a></p>
<p>Author: Lucas Theis, Jascha Sohl-dickstein, Matthias Bethge</p><p>Abstract: We present a new learning strategy based on an efﬁcient blocked Gibbs sampler for sparse overcomplete linear models. Particular emphasis is placed on statistical image modeling, where overcomplete models have played an important role in discovering sparse representations. Our Gibbs sampler is faster than general purpose sampling schemes while also requiring no tuning as it is free of parameters. Using the Gibbs sampler and a persistent variant of expectation maximization, we are able to extract highly sparse distributions over latent sources from data. When applied to natural images, our algorithm learns source distributions which resemble spike-and-slab distributions. We evaluate the likelihood and quantitatively compare the performance of the overcomplete linear model to its complete counterpart as well as a product of experts model, which represents another overcomplete generalization of the complete linear model. In contrast to previous claims, we ﬁnd that overcomplete representations lead to signiﬁcant improvements, but that the overcomplete linear model still underperforms other models. 1</p><p>3 0.73534811 <a title="82-lsi-3" href="./nips-2012-Dynamic_Pruning_of_Factor_Graphs_for_Maximum_Marginal_Prediction.html">105 nips-2012-Dynamic Pruning of Factor Graphs for Maximum Marginal Prediction</a></p>
<p>Author: Christoph H. Lampert</p><p>Abstract: We study the problem of maximum marginal prediction (MMP) in probabilistic graphical models, a task that occurs, for example, as the Bayes optimal decision rule under a Hamming loss. MMP is typically performed as a two-stage procedure: one estimates each variable’s marginal probability and then forms a prediction from the states of maximal probability. In this work we propose a simple yet effective technique for accelerating MMP when inference is sampling-based: instead of the above two-stage procedure we directly estimate the posterior probability of each decision variable. This allows us to identify the point of time when we are sufﬁciently certain about any individual decision. Whenever this is the case, we dynamically prune the variables we are conﬁdent about from the underlying factor graph. Consequently, at any time only samples of variables whose decision is still uncertain need to be created. Experiments in two prototypical scenarios, multi-label classiﬁcation and image inpainting, show that adaptive sampling can drastically accelerate MMP without sacriﬁcing prediction accuracy. 1</p><p>4 0.70934922 <a title="82-lsi-4" href="./nips-2012-Nonparanormal_Belief_Propagation_%28NPNBP%29.html">248 nips-2012-Nonparanormal Belief Propagation (NPNBP)</a></p>
<p>Author: Gal Elidan, Cobi Cario</p><p>Abstract: The empirical success of the belief propagation approximate inference algorithm has inspired numerous theoretical and algorithmic advances. Yet, for continuous non-Gaussian domains performing belief propagation remains a challenging task: recent innovations such as nonparametric or kernel belief propagation, while useful, come with a substantial computational cost and offer little theoretical guarantees, even for tree structured models. In this work we present Nonparanormal BP for performing efﬁcient inference on distributions parameterized by a Gaussian copulas network and any univariate marginals. For tree structured networks, our approach is guaranteed to be exact for this powerful class of non-Gaussian models. Importantly, the method is as efﬁcient as standard Gaussian BP, and its convergence properties do not depend on the complexity of the univariate marginals, even when a nonparametric representation is used. 1</p><p>5 0.66365427 <a title="82-lsi-5" href="./nips-2012-Efficient_Sampling_for_Bipartite_Matching_Problems.html">111 nips-2012-Efficient Sampling for Bipartite Matching Problems</a></p>
<p>Author: Maksims Volkovs, Richard S. Zemel</p><p>Abstract: Bipartite matching problems characterize many situations, ranging from ranking in information retrieval to correspondence in vision. Exact inference in realworld applications of these problems is intractable, making efﬁcient approximation methods essential for learning and inference. In this paper we propose a novel sequential matching sampler based on a generalization of the PlackettLuce model, which can effectively make large moves in the space of matchings. This allows the sampler to match the difﬁcult target distributions common in these problems: highly multimodal distributions with well separated modes. We present experimental results with bipartite matching problems—ranking and image correspondence—which show that the sequential matching sampler efﬁciently approximates the target distribution, signiﬁcantly outperforming other sampling approaches. 1</p><p>6 0.65306944 <a title="82-lsi-6" href="./nips-2012-MCMC_for_continuous-time_discrete-state_systems.html">205 nips-2012-MCMC for continuous-time discrete-state systems</a></p>
<p>7 0.64002144 <a title="82-lsi-7" href="./nips-2012-On_Lifting_the_Gibbs_Sampling_Algorithm.html">251 nips-2012-On Lifting the Gibbs Sampling Algorithm</a></p>
<p>8 0.60988766 <a title="82-lsi-8" href="./nips-2012-Density_Propagation_and_Improved_Bounds_on_the_Partition_Function.html">96 nips-2012-Density Propagation and Improved Bounds on the Partition Function</a></p>
<p>9 0.60042351 <a title="82-lsi-9" href="./nips-2012-Forward-Backward_Activation_Algorithm_for_Hierarchical_Hidden_Markov_Models.html">136 nips-2012-Forward-Backward Activation Algorithm for Hierarchical Hidden Markov Models</a></p>
<p>10 0.58293039 <a title="82-lsi-10" href="./nips-2012-Effective_Split-Merge_Monte_Carlo_Methods_for_Nonparametric_Models_of_Sequential_Data.html">107 nips-2012-Effective Split-Merge Monte Carlo Methods for Nonparametric Models of Sequential Data</a></p>
<p>11 0.57830459 <a title="82-lsi-11" href="./nips-2012-Ancestor_Sampling_for_Particle_Gibbs.html">41 nips-2012-Ancestor Sampling for Particle Gibbs</a></p>
<p>12 0.56438732 <a title="82-lsi-12" href="./nips-2012-Bayesian_Nonparametric_Modeling_of_Suicide_Attempts.html">52 nips-2012-Bayesian Nonparametric Modeling of Suicide Attempts</a></p>
<p>13 0.55552524 <a title="82-lsi-13" href="./nips-2012-Affine_Independent_Variational_Inference.html">37 nips-2012-Affine Independent Variational Inference</a></p>
<p>14 0.55419111 <a title="82-lsi-14" href="./nips-2012-Slice_sampling_normalized_kernel-weighted_completely_random_measure_mixture_models.html">315 nips-2012-Slice sampling normalized kernel-weighted completely random measure mixture models</a></p>
<p>15 0.54111868 <a title="82-lsi-15" href="./nips-2012-The_Coloured_Noise_Expansion_and_Parameter_Estimation_of_Diffusion_Processes.html">336 nips-2012-The Coloured Noise Expansion and Parameter Estimation of Diffusion Processes</a></p>
<p>16 0.53408915 <a title="82-lsi-16" href="./nips-2012-Random_function_priors_for_exchangeable_arrays_with_applications_to_graphs_and_relational_data.html">287 nips-2012-Random function priors for exchangeable arrays with applications to graphs and relational data</a></p>
<p>17 0.5259887 <a title="82-lsi-17" href="./nips-2012-Entangled_Monte_Carlo.html">118 nips-2012-Entangled Monte Carlo</a></p>
<p>18 0.52457756 <a title="82-lsi-18" href="./nips-2012-Cardinality_Restricted_Boltzmann_Machines.html">65 nips-2012-Cardinality Restricted Boltzmann Machines</a></p>
<p>19 0.52233464 <a title="82-lsi-19" href="./nips-2012-FastEx%3A_Hash_Clustering_with_Exponential_Families.html">126 nips-2012-FastEx: Hash Clustering with Exponential Families</a></p>
<p>20 0.51254481 <a title="82-lsi-20" href="./nips-2012-Sparse_Approximate_Manifolds_for_Differential_Geometric_MCMC.html">318 nips-2012-Sparse Approximate Manifolds for Differential Geometric MCMC</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.023), (21, 0.018), (38, 0.098), (42, 0.024), (54, 0.023), (55, 0.014), (74, 0.031), (76, 0.148), (80, 0.104), (92, 0.439)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.91719192 <a title="82-lda-1" href="./nips-2012-Convolutional-Recursive_Deep_Learning_for_3D_Object_Classification.html">87 nips-2012-Convolutional-Recursive Deep Learning for 3D Object Classification</a></p>
<p>Author: Richard Socher, Brody Huval, Bharath Bath, Christopher D. Manning, Andrew Y. Ng</p><p>Abstract: Recent advances in 3D sensing technologies make it possible to easily record color and depth images which together can improve object recognition. Most current methods rely on very well-designed features for this new 3D modality. We introduce a model based on a combination of convolutional and recursive neural networks (CNN and RNN) for learning features and classifying RGB-D images. The CNN layer learns low-level translationally invariant features which are then given as inputs to multiple, ﬁxed-tree RNNs in order to compose higher order features. RNNs can be seen as combining convolution and pooling into one efﬁcient, hierarchical operation. Our main result is that even RNNs with random weights compose powerful features. Our model obtains state of the art performance on a standard RGB-D object dataset while being more accurate and faster during training and testing than comparable architectures such as two-layer CNNs. 1</p><p>2 0.90527666 <a title="82-lda-2" href="./nips-2012-Approximating_Concavely_Parameterized_Optimization_Problems.html">44 nips-2012-Approximating Concavely Parameterized Optimization Problems</a></p>
<p>Author: Joachim Giesen, Jens Mueller, Soeren Laue, Sascha Swiercy</p><p>Abstract: We consider an abstract class of optimization problems that are parameterized concavely in a single parameter, and show that the solution path along the √ parameter can always be approximated with accuracy ε > 0 by a set of size O(1/ ε). A √ lower bound of size Ω(1/ ε) shows that the upper bound is tight up to a constant factor. We also devise an algorithm that calls a step-size oracle and computes an √ approximate path of size O(1/ ε). Finally, we provide an implementation of the oracle for soft-margin support vector machines, and a parameterized semi-deﬁnite program for matrix completion. 1</p><p>same-paper 3 0.9028511 <a title="82-lda-3" href="./nips-2012-Continuous_Relaxations_for_Discrete_Hamiltonian_Monte_Carlo.html">82 nips-2012-Continuous Relaxations for Discrete Hamiltonian Monte Carlo</a></p>
<p>Author: Yichuan Zhang, Zoubin Ghahramani, Amos J. Storkey, Charles A. Sutton</p><p>Abstract: Continuous relaxations play an important role in discrete optimization, but have not seen much use in approximate probabilistic inference. Here we show that a general form of the Gaussian Integral Trick makes it possible to transform a wide class of discrete variable undirected models into fully continuous systems. The continuous representation allows the use of gradient-based Hamiltonian Monte Carlo for inference, results in new ways of estimating normalization constants (partition functions), and in general opens up a number of new avenues for inference in difﬁcult discrete systems. We demonstrate some of these continuous relaxation inference algorithms on a number of illustrative problems. 1</p><p>4 0.89718676 <a title="82-lda-4" href="./nips-2012-Angular_Quantization-based_Binary_Codes_for_Fast_Similarity_Search.html">42 nips-2012-Angular Quantization-based Binary Codes for Fast Similarity Search</a></p>
<p>Author: Yunchao Gong, Sanjiv Kumar, Vishal Verma, Svetlana Lazebnik</p><p>Abstract: This paper focuses on the problem of learning binary codes for efﬁcient retrieval of high-dimensional non-negative data that arises in vision and text applications where counts or frequencies are used as features. The similarity of such feature vectors is commonly measured using the cosine of the angle between them. In this work, we introduce a novel angular quantization-based binary coding (AQBC) technique for such data and analyze its properties. In its most basic form, AQBC works by mapping each non-negative feature vector onto the vertex of the binary hypercube with which it has the smallest angle. Even though the number of vertices (quantization landmarks) in this scheme grows exponentially with data dimensionality d, we propose a method for mapping feature vectors to their smallest-angle binary vertices that scales as O(d log d). Further, we propose a method for learning a linear transformation of the data to minimize the quantization error, and show that it results in improved binary codes. Experiments on image and text datasets show that the proposed AQBC method outperforms the state of the art. 1</p><p>5 0.87141979 <a title="82-lda-5" href="./nips-2012-Training_sparse_natural_image_models_with_a_fast_Gibbs_sampler_of_an_extended_state_space.html">349 nips-2012-Training sparse natural image models with a fast Gibbs sampler of an extended state space</a></p>
<p>Author: Lucas Theis, Jascha Sohl-dickstein, Matthias Bethge</p><p>Abstract: We present a new learning strategy based on an efﬁcient blocked Gibbs sampler for sparse overcomplete linear models. Particular emphasis is placed on statistical image modeling, where overcomplete models have played an important role in discovering sparse representations. Our Gibbs sampler is faster than general purpose sampling schemes while also requiring no tuning as it is free of parameters. Using the Gibbs sampler and a persistent variant of expectation maximization, we are able to extract highly sparse distributions over latent sources from data. When applied to natural images, our algorithm learns source distributions which resemble spike-and-slab distributions. We evaluate the likelihood and quantitatively compare the performance of the overcomplete linear model to its complete counterpart as well as a product of experts model, which represents another overcomplete generalization of the complete linear model. In contrast to previous claims, we ﬁnd that overcomplete representations lead to signiﬁcant improvements, but that the overcomplete linear model still underperforms other models. 1</p><p>6 0.85076118 <a title="82-lda-6" href="./nips-2012-Efficient_Reinforcement_Learning_for_High_Dimensional_Linear_Quadratic_Systems.html">110 nips-2012-Efficient Reinforcement Learning for High Dimensional Linear Quadratic Systems</a></p>
<p>7 0.68266314 <a title="82-lda-7" href="./nips-2012-Super-Bit_Locality-Sensitive_Hashing.html">329 nips-2012-Super-Bit Locality-Sensitive Hashing</a></p>
<p>8 0.6749413 <a title="82-lda-8" href="./nips-2012-Discriminatively_Trained_Sparse_Code_Gradients_for_Contour_Detection.html">101 nips-2012-Discriminatively Trained Sparse Code Gradients for Contour Detection</a></p>
<p>9 0.66106331 <a title="82-lda-9" href="./nips-2012-Multimodal_Learning_with_Deep_Boltzmann_Machines.html">229 nips-2012-Multimodal Learning with Deep Boltzmann Machines</a></p>
<p>10 0.63214654 <a title="82-lda-10" href="./nips-2012-Cardinality_Restricted_Boltzmann_Machines.html">65 nips-2012-Cardinality Restricted Boltzmann Machines</a></p>
<p>11 0.63166177 <a title="82-lda-11" href="./nips-2012-Learning_with_Recursive_Perceptual_Representations.html">197 nips-2012-Learning with Recursive Perceptual Representations</a></p>
<p>12 0.63008577 <a title="82-lda-12" href="./nips-2012-Deep_Learning_of_Invariant_Features_via_Simulated_Fixations_in_Video.html">90 nips-2012-Deep Learning of Invariant Features via Simulated Fixations in Video</a></p>
<p>13 0.62906921 <a title="82-lda-13" href="./nips-2012-Natural_Images%2C_Gaussian_Mixtures_and_Dead_Leaves.html">235 nips-2012-Natural Images, Gaussian Mixtures and Dead Leaves</a></p>
<p>14 0.62479609 <a title="82-lda-14" href="./nips-2012-Isotropic_Hashing.html">163 nips-2012-Isotropic Hashing</a></p>
<p>15 0.62478268 <a title="82-lda-15" href="./nips-2012-Online_Sum-Product_Computation_Over_Trees.html">260 nips-2012-Online Sum-Product Computation Over Trees</a></p>
<p>16 0.61569101 <a title="82-lda-16" href="./nips-2012-Delay_Compensation_with_Dynamical_Synapses.html">94 nips-2012-Delay Compensation with Dynamical Synapses</a></p>
<p>17 0.61547112 <a title="82-lda-17" href="./nips-2012-A_mechanistic_model_of_early_sensory_processing_based_on_subtracting_sparse_representations.html">24 nips-2012-A mechanistic model of early sensory processing based on subtracting sparse representations</a></p>
<p>18 0.61450398 <a title="82-lda-18" href="./nips-2012-On_Lifting_the_Gibbs_Sampling_Algorithm.html">251 nips-2012-On Lifting the Gibbs Sampling Algorithm</a></p>
<p>19 0.61270422 <a title="82-lda-19" href="./nips-2012-Ancestor_Sampling_for_Particle_Gibbs.html">41 nips-2012-Ancestor Sampling for Particle Gibbs</a></p>
<p>20 0.61202085 <a title="82-lda-20" href="./nips-2012-A_Better_Way_to_Pretrain_Deep_Boltzmann_Machines.html">4 nips-2012-A Better Way to Pretrain Deep Boltzmann Machines</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
