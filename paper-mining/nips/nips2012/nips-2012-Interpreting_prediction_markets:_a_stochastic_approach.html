<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>161 nips-2012-Interpreting prediction markets: a stochastic approach</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-161" href="#">nips2012-161</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>161 nips-2012-Interpreting prediction markets: a stochastic approach</h1>
<br/><p>Source: <a title="nips-2012-161-pdf" href="http://papers.nips.cc/paper/4529-interpreting-prediction-markets-a-stochastic-approach.pdf">pdf</a></p><p>Author: Nicolas D. Penna, Mark D. Reid, Rafael M. Frongillo</p><p>Abstract: We strengthen recent connections between prediction markets and learning by showing that a natural class of market makers can be understood as performing stochastic mirror descent when trader demands are sequentially drawn from a ﬁxed distribution. This provides new insights into how market prices (and price paths) may be interpreted as a summary of the market’s belief distribution by relating them to the optimization problem being solved. In particular, we show that under certain conditions the stationary point of the stochastic process of prices generated by the market is equal to the market’s Walrasian equilibrium of classic market analysis. Together, these results suggest how traditional market making mechanisms might be replaced with general purpose learning algorithms while still retaining guarantees about their behaviour. 1 Introduction and literature review This paper is part of an ongoing line of research, spanning several authors, into formal connections between markets and machine learning. In [5] an equivalence is shown between the theoretically popular prediction market makers based on sequences of proper scoring rules and follow the regularised leader, a form of no-regret online learning. By modelling the traders that demand the assets the market maker is oﬀering we are able to extend the equivalence to stochastic mirror decent. The dynamics of wealth transfer is studied in [3], for a sequence of markets between agents that behave as Kelly bettors (i.e. have log utilities), and an equivalence to stochastic gradient decent is analysed. More broadly, [9, 2] have analysed how a wide range of machine learning models can be implemented in terms of market equilibria. The literature on the interpretation of prediction market prices [7, 11] has had the goal of relating the equilibrium prices to the distribution of the beliefs of traders. More recent work [8] has looked at a stochastic model, and studied the behavior of simple agents sequentially interacting with the market. We continue this latter path of research, motivated by the observation that the equilibrium price may be a poor predictor of the behavior in a volitile prediction market. As such, we seek a more detailed understanding of the market than the equilibrium point – we would like to know what the “stationary distribution” of the price is, as time goes to inﬁnity. 1 As is standard in the literature, we assume a ﬁxed (product) distribution over traders’ beliefs and wealth. Our model features an automated market maker, following the framework of [1] is becoming a standard framework in the ﬁeld. We obtain two results. First, we prove that under certain conditions the stationary point of our stochastic process deﬁned by the market maker and a belief distribution of traders converges to the Walrasian equilibrium of the market as the market liquidity increases. This result, stated in Theorem 1, is general in the sense that only technical convergence conditions are placed on the demand functions of the traders – as such, we believe it is a generalisation of the stochastic result of [8] to cases where agents are are not limited to linear demands, and leave this precise connection to future work. Second, we show in Corollary 1 that when traders are Kelly bettors, the resulting stochastic market process is equivalent to stochastic mirror descent; see e.g. [6]. This result adds to the growing literature which relates prediction markets, and automated market makers in general, to online learning; see e.g. [1], [5], [3] . This connection to mirror descent seems to suggest that the prices in a prediction market at any given time may be meaningless, as the ﬁnal point in stochastic mirror descent often has poor convergence guarantees. However, standard results suggest that a prudent way to form a “consensus estimate” from a prediction market is to average the prices. The average price, assuming our market model is reasonable, is provably close to the stationary price. In Section 5 we give a natural example that exhibits this behavior. Beyond this, however, Theorem 2 gives us insight into the relationship between the market liquidity and the convergence of prices; in particular it suggests that we should increase liquidity at a rate √ of t if we wish the price to settle down at the right rate. 2 Model Our market model will follow the automated market maker framework of [1]. We will equip our market maker with a strictly convex function C : Rn → R which is twice continuously diﬀerentiable. For brevity we will write ϕ := C. The outcome space is Ω, and the contracts are determined by a payoﬀ function φ : Ω → Rn such that Π := ϕ(Rn ) = ConvHull(φ(Ω)). That is, the derivative space Π of C (the “instantaneous prices”) must be the convex hull of the payoﬀs. A trader purchasing shares at the current prices π ∈ Rn pays C(ϕ−1 (π) + r) − C(ϕ−1 (π)) for the bundle of contracts r ∈ Rn . Note that our dependence solely on π limits our model slightly, since in general the share space (domain of C) may contain more information than the current prices (cf. [1]). The bundle r is determined by an agent’s demand function d(C, π) which speciﬁes the bundle to buy given the price π and the cost function C. Our market dynamics are the following. The market maker posts the current price πt , and at each time t = 1 . . . T , a trader is chosen with demand function d drawn i.i.d. from some demand distribution D. Intuitively, these demands are parameterized by latent variables such as the agent’s belief p ∈ ∆Ω and total wealth W . The price is then updated to πt+1 = ϕ(ϕ−1 (πt ) + d(C, πt )). (1) After update T , the outcome is revealed and payout φ(ω)i is given for each contract i ∈ {1, . . . , n}. 3 Stationarity and equilibrium We ﬁrst would like to relate our stochastic model (1) to the standard notion of market equilibrium from the Economics literature, which we call the Walrasian equilibrium to avoid confusion. Here prices are ﬁxed, and the equilibrium price is one that clears the market, meaning that the sum of the demands r is 0 ∈ Rn . In fact, we will show that the stationary point of our process approaches the Walrasian equilibrium point as the liquidity of the market approaches inﬁnity. 2 First, we must add a liquidity parameter to our market. Following the LMSR (the cost function C(s) = b ln i esi /b ), we deﬁne Cb (s) := b C(s/b). (2) This transformation of a convex function is called a perspective function and is known to preserve convexity [4]. Observe that ϕb (s) := Cb (s) = C(s/b) = ϕ(s/b), meaning that the price under Cb at s is the same as the price under C at s/b. As with the LMSR, we call b the liquidity parameter ; this terminology is justiﬁed by noting that one deﬁnition of liquidity, 1/λmax 2 Cb (s) = b/λmax 2 C(s/b) (cf. [1]). In the following, we will consider the limit as b → ∞. Second, in order to connect to the Walrasian equilibrium, we need a notion of a ﬁxed-price demand function: if a trader has demand d(C, ·) given C, what would the same trader’s demand be under a market where prices are ﬁxed and do not “change” during a trade? For the sake of generality, we restrict our allowable demand functions to the ones for which the limit d(F, π) := lim d(Cb , π) (3) b→∞ exists; this demand d(F, ·) will be the corresponding ﬁxed-price demand for d. We now deﬁne the Walrasion equilibrium point π ∗ , which is simply the price at which the market clears when traders have demands distributed by D. Formally, this is the following condition:1 d(F, π ∗ ) dD(d) = 0 (4) D Note that 0 ∈ Rn ; the demand for each contract should be balanced. s The stationary point of our stochastic process, on the other hand, is the price πb for which the expected price ﬂuctuation is 0. Formally, we have s s E [∆(πb , d(Cb , πb ))] = 0, (5) d∼D where ∆(π, d) := ϕ(ϕ−1 (π) + d) − π is the price ﬂuctuation. We now consider the limit of our stochastic process as the market liquidity approaches ∞. Theorem 1. Let C be a strictly convex and α-smooth2 cost function, and assume that ∂ ∂b d(Cb , π) = o(1/b) uniformly in π and all d ∈ D. If furthermore the limit (3) is uniform s in π and d, then limb→∞ πb = π ∗ . s Proof. Note that by the stationarity condition (5) we may deﬁne π ∗ and πb to be the roots of the following “excess demand” functions, respectively: Z(π) := s Zb (π) := b E [∆(π, d(Cb , π))], d(F, π) dD(d), d∼D D where we scale the latter by b so that −1 Let s = ϕ s Zb does not limit to the zero function. (π) be the current share vector. Then we have lim b∆(π, d(Cb , π)) = lim b ϕ ϕ−1 (π) + d(Cb , π)/b − π b→∞ b→∞ ϕ s + a d(C1/a , π) − π a ∂ = lim ϕ s + a d(C1/a , π) d(C1/a , π) + a ∂a d(C1/a , π) = lim a→0 a→0 = lim ϕ s+ = lim 2 b→∞ b→∞ 1 b d(Cb , π) C(s) d(Cb , π) = d(Cb , π) + 2 2 1 ∂ b ∂b d(Cb , π)(−b ) C(s) d(F, π), 1 Here and throughout we ignore technical issues of uniqueness. One may simply restrict to the class of demands for which uniqueness is satisﬁed. 2 C is α-smooth if λmax 2 C ≤ α 3 where we apply L’Hopital’s rule for the third equality. Crucially, the above limit is uniform with respect to both d ∈ D and π ∈ Π; uniformity in d is by assumption, and uniformity in π follows from α-smoothness of C, since C is dominated by a quadratic. Since the limit is uniform with respect to D, we now have s lim Zb (π) = lim b E [∆(π, d(Cb , π))] = E b→∞ b→∞ = 2 d∼D d∼D C(s) E [d(F, π)] = 2 lim b∆(π, d(Cb , π)) b→∞ C(s) Z(π). d∼D s As 2 C(s) is positive deﬁnite by assumption on C, we can conclude that limb→∞ Zb and Z share the same zeroes. Since Z has compact domain and is assumed continuous with a unique zero π ∗ , for each ∈ (0, max ) there must be some δ > 0 s.t. |Z(π)| > for all π s.t. π − π ∗ > δ (otherwise there would be a sequence of πn → π s.t. f (π ) = 0 but π = π ∗ ). s By uniform convergence there must be a B > 0 s.t. for all b > B we have Zb − Z ∞ < /2. s s In particular, for π s.t. π − π ∗ > δ, |Zb (π)| > /2. Thus, the corresponding zeros πb must ∗ s ∗ 3 be within δ of π . Hence limb→∞ πb = π . 3.1 Utility-based demands Maximum Expected Utility (MEU) demand functions are a particular kind of demand function derived by assuming a trader has some belief p ∈ ∆n over the outcomes in Ω, some wealth W ≥ 0, and a monotonically increasing utility function of money u : R → R. If such a trader buys a bundle r of contracts from a market maker with cost function C and price π, her wealth after ω occurs is Υω (C, W, π, r) := W +φ(ω)·r−[C(ϕ−1 (π)+r)−C(ϕ−1 (π))]. We ensure traders do not go into debt by requiring that traders only make demands such that this ﬁnal wealth is nonnegative: ∀ω Υω (C, π, r) ≥ 0. The set of debt-free bundles for wealth W and market C at price π is denoted S(C, W, π) := {r ∈ Rn : minω Υω (C, W, π, r) ≥ 0}. A continuous MEU demand function du (C, π) is then just the demand that maximizes a W,p trader’s expected utility subject to the debt-free constraint. That is, du (C, π) := argmax W,p E [u (Υω (C, W, π, r))] . (6) r∈S(C,W,π) ω∼p We also deﬁne a ﬁxed-price MEU demand function du (F, π) similarly, where W,p Υω (F, W, π, r) := W + φ(ω) · r − π · r and S(F, W, π) := {r ∈ Rn : minω Υω (F, W, π, r) ≥ 0} are the ﬁxed price analogues to the continuously priced versions above. Using the notation bS := {b r | r ∈ S}, the following relationships between the continuous and ﬁxed price versions of Υ, SW , and the expected utility are a consequence of the convexity of C. Their main purpose is to highlight the relationship between wealth and liquidity in MEU demands. In particular, they show that scaling up of liquidity is equivalent to a scaling down of wealth and that the continuously priced constraints and wealth functions monotonically approach the ﬁxed priced versions. Lemma 1. For any strictly convex cost function C, wealth W > 0, price π, demand r, and liquidity parameter b > 0 the following properties hold: 1. Υω (Cb , W, π, r) = b Υω (C, W/b, π, r/b); 2. S(Cb , W, π) = b S(C, W/b, π); 3. S(C, W, π) is convex for all C; 4. S(C, W, π) ⊆ S(Cb , W, π) ⊆ S(F, W, π) for all b ≥ 1. 5. For monotone utilities u, Eω∼p [u (Υω (F, W, π, r))] ≥ Eω∼p [u (Υω (C, W, π, r))]. Proof. Property (1) follows from a simple computation: Υω (Cb , W, π, r) = W + φ(ω) · r − b C(ϕ−1 (π) + r/b) + b C(ϕ−1 (π)) = b W/b + φ(ω) · (r/b) − C(ϕ−1 (π) + r/b) + C(ϕ−1 (π)) , which equals b Υω (C, W/b, π, r/b) by deﬁnition. We now can see property (2) as well: S(Cb , W, π) = {r : min b Υω (C, W/b, π, r/b) ≥ 0} = {b r : min Υω (C, W/b, π, r) ≥ 0}. ω 3 ω We thank Avraham Ruderman for a helpful discussion regarding this proof. 4 For (3), deﬁne fC,s,ω (r) = C(s + r) − C(s) − φ(ω) · r, which is the ex-post cost of purchasing bundle r. As C is convex, and fC,s,ω is a shifted and translated version of C plus a linear term, fC,s,ω is convex also. The constraint Υω (C, W, π, r) ≥ 0 then translates to fC,s,ω (r) ≤ W , and thus the set of r which satisfy the constraint is convex as a sublevel set of a convex function. Now S(C, W, π) is convex as an intersection of convex sets, proving (3). For (4) suppose r satisﬁes fC,s,ω (r) ≤ W . Note that fC,s,ω (0) = 0 always. Then by convexity we have for f := fC,s,ω we have f (r/b) = f 1 r + b−1 0 ≤ 1 f (r) + b−1 0 ≤ W/b, b b b b which implies S(C, W, π) ⊆ S(Cb , W, π) when considering (3). To complete (4) note that fC,s,ω dominates fF,s : r → (ϕ(s) − φ(ω)) · r by convexity of C: C(s + r) − C(s) ≥ C(s) · r. Finally, proof of (5) is obtained by noting that the convexity of C means that C(ϕ−1 (π) + r) − C(ϕ−1 (π)) ≥ C(ϕ−1 (π)) · r = π · r and exploting the monotonicty of u. Lemma 1 shows us that MEU demands have a lot of structure, and in particular, properties (4) and (5) suggest that they may satisfy the conditions of Theorem 1; we leave this as an open question for future work. Another interesting aspect of Lemma 1 is the relationship between markets with cost function Cb and wealths W and markets with cost function C and wealths W/b – indeed, properties (1) and (2) suggest that the liquidity limit should in some sense be equivalent to a wealth limit, in that increasing liquidity by a factor b should yield similar dynamics to decreasing the wealths by b. This would relate our model to that of [8], where the authors essentially show a wealth-limit version of Theorem 1 for a binary-outcome market where traders have linear utilities (a special case of (6)). We leave this precise connection for future work. 4 Market making as mirror descent We now explore the surprising relationship between our stochastic price update and standard stochastic optimization techniques. In particular, we will relate our model to a stochastic mirror descent of the form xt+1 = argmin{η x · F (xt ; ξ) + DR (x, xt )}, (7) x∈R where at each step ξ ∼ Ξ are i.i.d. and R is some strictly convex function. We will refer to an algorithm of the form (7) a stochastic mirror descent of f (x) := Eξ∼Ξ [F (x; ξ)]. Theorem 2. If for all d ∈ D we have some F (· ; d) : Rn → Rn such that d(R∗ , π) = − F (π; d), then the stochastic update of our model (1) is exactly a stochastic mirror descent of f (π) = Ed∼D [F (π; d)]. Proof. By standard arguments, the mirror descent update (7) can be rewritten as xt+1 = R∗ ( R(xt ) − F (xt ; ξ)), where R∗ is the conjugate dual of R. Take R = C ∗ , and let ξ = d ∼ D. By assumption, we have F (x; d) = −d(R∗ , x) = −d(C, x) for all d. As R∗ = C = ϕ, we have ϕ−1 = ( R∗ )−1 = R by duality, and thus our update becomes xt+1 = ϕ ϕ−1 (xt ) + d(C, xt ) , which exactly matches the stochastic update of our model (1). As an example, consider Kelly betters, which correspond to ﬁxed-price demands d(C, π) := dlog (F, π) with utility u(x) = log x as deﬁned in (3). A simple calculation shows that our W,p update becomes W p−π πt+1 = ϕ ϕ−1 (πt ) + , (8) π 1−π where W and p are drawn (independently) from P and W. Corollary 1. The stochastic update for ﬁxed-price Kelly betters (8) is exactly a stochastic mirror descent of f (π) = W · KL(p, π), where p and W are the means of P and W, respectively. 5 Proof. We take F (x; dlog ) = W · (KL(p, x) + H(p)). Then W,p F (x; dlog ) = W W,p −p p − 1 + x 1−x =− W p−x = −dlog (F, x). W,p x 1−x Hence, by Theorem 2 our update is a stochastic mirror descent of: f (x) := E[F (x; dlog )] = E[W p log x + W (1 − p) log(1 − x)] = W · (KL(p, x) + H(p)) , W,p which of course is equivalent to W · KL(p, x) as the entropy term does not depend on x. Note that while this last result is quite compelling, we have mixed ﬁxed-price demands with a continuous-price market model – see Section 3.1. One could interpret this combination as a model in which the market maker can only adjust the prices after a trade, according to a ﬁxed convex cost function C. This of course diﬀers from the standard model, which adjusts the price continuously during a trade. 4.1 Leveraging existing learning results Theorem 2 not only identiﬁes a fascinating connection between machine learning and our stochastic prediction market model, but it also allows us to use powerful existing techniques to make broad conclusions about the behavior of our model. Consider the following result: ≤ G2 for all p, π, and R is σ-strongly convex, then log 1 δ . Price Avg price Avg belief 0.70 In our context, Proposition 1 says that the average of the prices will be a very good estimate of the minimizer of f , which as suggested by happens to be the underlying mean belief p of the traders! Moreover, as the Kelly demands are linear in both p and W , it is easy to see from Theorem 1 that p is also the stationary point and the Walrasian equilibrium point (the latter was also shown by [11]). On the other hand, as we demonstrate next, it is not hard to come up with an example where the instantaneous price πt is quite far from the equilibrium at any given time period. 1+4 0.65 π D2 G2 η + ηT 2σ 0.60 f (π T ) ≤ min f (π) + Price of contract 1 2 0.55 F (π; p) 0.50 Proposition 1 ([6]). If with probability 1 − δ, 0 500 1000 1500 2000 Trade number Before moving to our empirical work, we make one Figure 1: Price movement for Kelly ﬁnal point. The above relationship between our betters with binomial(q = 0.6, n = 6, stochastic market model and mirror descent sheds α = 0.5) beliefs in the LMSR market light on an important question: how might an auto- with liquidity b = 10. mated market maker adjust the liquidity so that the market actually converges to the mean of the traders’ beliefs? The learning parameter η can be thought of as the inverse of the liquidity, and as such, Proposition 1 suggests that √ increasing the liquidity as t may cause the mean price to converge to the mean belief (assuming a ﬁxed underlying belief distribution). 5 Empirical work Example: biased coin Consider a classic Bayesian setting where a coin has unknown bias Pr[heads] = q, and traders have a prior β(α, α) over q (i.e., traders are α-conﬁdent that the coin is fair). Now suppose each trader independently observes n ﬂips from the coin, and updates her belief; upon seeing k heads, a trader would have posterior β(α + k, α + n − k). When presented with a prediction market with contracts for a single toss of the coin, where and contract 0 pays $1 for tails and contract 1 pays $1 for heads, a trader would purchase 6 0 20 40 60 Trades 80 100 b = 10 Instant Averaged 0.06 Loss 0.04 0.02 0.00 0.02 0.04 Loss 0.06 0.08 Instant Averaged 0.00 0.00 0.02 0.04 Loss 0.06 0.08 Instant Averaged Square loss of price to mean belief for State 9 b=3 0.08 b=1 0.10 Square loss of price to mean belief for State 9 0.10 0.10 Square loss of price to mean belief for State 9 0 20 40 60 Trades 80 100 0 20 40 60 80 100 Trades Figure 2: Mean square loss of average and instantaneous prices relative to the mean belief of 0.26 over 20 simulations for State 9 for b = 1 (left), b = 3 (middle), and b = 10 (right). Bars show standard deviation. contracts as if according to the mean of their posterior. Hence, the belief distribution P of the market assigns weight P(p) = n q k (1 − q)n−k to belief p = (α + k)/(2α + n), yielding k a biased mean belief of (α + nq)/(2α + n). We show a typical simulation of this market in Figure 1, where traders behave as Kelly betters in the ﬁxed-price LMSR. Clearly, after almost every trade, the market price is quite far from the equilibrium/stationary point, and hence the classical supply and demand analysis of this market yields a poor description of the actual behavior, and in particular, of the predictive quality of the price at any given time. However, the mean price is consistently close to the mean belief of the traders, which in turn is quite close to the true parameter q. Election Survey Data We now compare the quality of the running average price versus the instantaneous price as a predictor of the mean belief of a market. We do so by simulating a market maker interacting with traders with unit wealth, log utility, and beliefs drawn from a ﬁxed distribution. The belief distributions are derived from the Princeton election survey data[10]. For each of the 50 US states, participants in the survey were asked to estimate the probability that one of two possible candidates were going to win that state.4 We use these 50 sets of estimates as 50 diﬀerent empirical distributions from which to draw trader beliefs. A simulation is conﬁgured by choosing one of the 50 empirical belief distributions S, a market liquidity parameter b to deﬁne the LMSR cost function C(s) = b ln i esi /b , and an initial market position vector of (0, 0) – that is, no contracts for either outcome. A conﬁgured simulation is run for T trades. At each trade, a belief p is drawn from S uniformly and with replacement. This belief is used to determine the demand of the trader relative to the current market pricing. The trader purchase a bundle of contracts according to its demand and the market moves its position and price accordingly. The complete price path πt for t t = 1, . . . , T of the market is recorded as well as a running average price πt := 1 i=1 πt for ¯ t t = 1 . . . , T . For each of the 50 empirical belief distributions we conﬁgured 9 markets with b ∈ {1, 2, 3, 5, 10, 15, 20, 30, 50} and ran 20 independent simulations of T = 100 trades. We present a portion of the results for the empirical distributions for states 9 and 11. States 9 and 11 have, respectively, sample sizes of 2,717 and 2,709; means 0.26 and 0.9; and variances 0.04 and 0.02. These are chosen as being representative of the rest of the simulation results: State 9 with mean oﬀ-center and a spread of beliefs (high uncertainty) and State 11 with highly concentrated beliefs around a single outcome (low uncertainty). The results are summarised in Figures 2, 3, and 4. The ﬁrst show the square loss of the average and instaneous prices relative to the mean belief for high uncertainty State 9 for b = 1, 3, 10. Clearly, the average price is a much more reliable estimator of the mean belief for low liquidity (b = 1) and is only outperformed by the instaneous price for higher liquidity (b = 10), but then only early in trading. Similar plots for State 11 are shown in Figure 3 where the advantage of using the average price is signiﬁcantly diminished. 4 The original dataset contains conjunctions of wins as well as conditional statements but we only use the single variable results of the survey. 7 0 20 40 60 80 100 b = 10 Instant Averaged 0.06 Loss 0.04 0.02 0.00 0.02 0.04 Loss 0.06 0.08 Instant Averaged 0.00 0.00 0.02 0.04 Loss 0.06 0.08 Instant Averaged Square loss of price to mean belief for State 11 b=3 0.08 b=1 0.10 Square loss of price to mean belief for State 11 0.10 0.10 Square loss of price to mean belief for State 11 0 20 40 Trades 60 80 100 0 20 40 Trades 60 80 100 Trades Figure 3: Mean square loss of average and instantaneous prices relative to the mean belief of 0.9 over 20 simulations for State 11 for b = 1 (left), b = 3 (middle), and b = 10 (right). Bars show standard deviation. Figure 4 shows the improvement the average price has over the instantaneous price in square loss relative to the mean belief for all liquidity settings and highlights that average prices work better in low liquidity settings, consistent with the theory. Similar trends were observed for all the other States, depending on whether they had high uncertainty – in which case average price was a much better estimator – or low uncertainty – in which case instanteous price was better. Improvement of Average over Instant Prices for State 9 Improvement of Average over Instant Prices for State 11 0.06 0.02 0.00 0.04 Loss Di fference fference -0.04 0.00 -0.06 -0.02 -0.08 10 20 100 80 80 30 40 40 30 60 Tra des b 60 Tra des 10 20 100 20 b Loss Di -0.02 0.02 40 40 20 50 50 Figure 4: An overview of the results for States 9 (left) and 11 (right). For each trade and choice of b, the vertical value shows the improvement of the average price over the instantaneous price as measure by square loss relative to the mean. 6 Conclusion and future work As noted in Section 3.1, there are several open questions with regard to maximum expected utility demands and Theorem 1, as well as the relationship between trader wealth and market liquidity. It would also be interesting to have a application of Theorem 2 to a continuousprice model, which yields a natural minimization as in Corollary 1. The equivalence to mirror decent stablished in Theorem 2 may also lead to a better understanding of the optimal manner in which a automated prediction market ought to increase liquidity so as to maximise eﬃciency. Acknowledgments This work was supported by the Australian Research Council (ARC). NICTA is funded by the Australian Government as represented by the Department of Broadband, Communications and the Digital Economy and the ARC through the ICT Centre of Excellence program. The ﬁrst author was partially supported by NSF grant CC-0964033 and by a Google University Research Award. 8 References [1] J. Abernethy, Y. Chen, and J.W. Vaughan. An optimization-based framework for automated market-making. In Proceedings of the 11th ACM conference on Electronic Commerce (EC’11), 2011. [2] A. Barbu and N. Lay. An introduction to artiﬁcial prediction markets for classiﬁcation. Arxiv preprint arXiv:1102.1465, 2011. [3] A. Beygelzimer, J. Langford, and D. Pennock. Learning Performance of Prediction Markets with Kelly Bettors. 2012. [4] S. Boyd and L. Vandenberghe. Convex optimization. Cambridge University Press, 2004. [5] Y. Chen and J.W. Vaughan. A new understanding of prediction markets via no-regret learning, pages 189–198. 2010. [6] J. Duchi, S. Shalev-Shwartz, Y. Singer, and A. Tewari. Composite objective mirror descent. COLT, 2010. [7] C.F. Manski. Interpreting the predictions of prediction markets. Technical report, National Bureau of Economic Research, 2004. [8] A. Othman and T. Sandholm. When do markets with simple agents fail? In Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems: volume 1-Volume 1, pages 865–872. International Foundation for Autonomous Agents and Multiagent Systems, 2010. [9] A. Storkey. Machine learning markets. AISTATS, 2012. [10] G. Wang, S.R. Kulkarni, H.V. Poor, and D.N. Osherson. Aggregating large sets of probabilistic forecasts by weighted coherent adjustment. Decision Analysis, 8(2):128, 2011. [11] J. Wolfers and E. Zitzewitz. Interpreting prediction market prices as probabilities. Technical report, National Bureau of Economic Research, 2006. 9</p><p>Reference: <a title="nips-2012-161-reference" href="../nips2012_reference/nips-2012-Interpreting_prediction_markets%3A_a_stochastic_approach_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('market', 0.529), ('pric', 0.492), ('liquid', 0.327), ('trad', 0.29), ('cb', 0.24), ('demand', 0.233), ('weal', 0.152), ('equilibr', 0.117), ('walras', 0.113), ('believ', 0.112), ('mir', 0.112), ('kel', 0.09), ('contract', 0.087), ('meu', 0.081), ('bundl', 0.076), ('dlog', 0.071), ('zb', 0.07), ('lmsr', 0.064), ('stochast', 0.058), ('lim', 0.055)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="161-tfidf-1" href="./nips-2012-Interpreting_prediction_markets%3A_a_stochastic_approach.html">161 nips-2012-Interpreting prediction markets: a stochastic approach</a></p>
<p>Author: Nicolas D. Penna, Mark D. Reid, Rafael M. Frongillo</p><p>Abstract: We strengthen recent connections between prediction markets and learning by showing that a natural class of market makers can be understood as performing stochastic mirror descent when trader demands are sequentially drawn from a ﬁxed distribution. This provides new insights into how market prices (and price paths) may be interpreted as a summary of the market’s belief distribution by relating them to the optimization problem being solved. In particular, we show that under certain conditions the stationary point of the stochastic process of prices generated by the market is equal to the market’s Walrasian equilibrium of classic market analysis. Together, these results suggest how traditional market making mechanisms might be replaced with general purpose learning algorithms while still retaining guarantees about their behaviour. 1 Introduction and literature review This paper is part of an ongoing line of research, spanning several authors, into formal connections between markets and machine learning. In [5] an equivalence is shown between the theoretically popular prediction market makers based on sequences of proper scoring rules and follow the regularised leader, a form of no-regret online learning. By modelling the traders that demand the assets the market maker is oﬀering we are able to extend the equivalence to stochastic mirror decent. The dynamics of wealth transfer is studied in [3], for a sequence of markets between agents that behave as Kelly bettors (i.e. have log utilities), and an equivalence to stochastic gradient decent is analysed. More broadly, [9, 2] have analysed how a wide range of machine learning models can be implemented in terms of market equilibria. The literature on the interpretation of prediction market prices [7, 11] has had the goal of relating the equilibrium prices to the distribution of the beliefs of traders. More recent work [8] has looked at a stochastic model, and studied the behavior of simple agents sequentially interacting with the market. We continue this latter path of research, motivated by the observation that the equilibrium price may be a poor predictor of the behavior in a volitile prediction market. As such, we seek a more detailed understanding of the market than the equilibrium point – we would like to know what the “stationary distribution” of the price is, as time goes to inﬁnity. 1 As is standard in the literature, we assume a ﬁxed (product) distribution over traders’ beliefs and wealth. Our model features an automated market maker, following the framework of [1] is becoming a standard framework in the ﬁeld. We obtain two results. First, we prove that under certain conditions the stationary point of our stochastic process deﬁned by the market maker and a belief distribution of traders converges to the Walrasian equilibrium of the market as the market liquidity increases. This result, stated in Theorem 1, is general in the sense that only technical convergence conditions are placed on the demand functions of the traders – as such, we believe it is a generalisation of the stochastic result of [8] to cases where agents are are not limited to linear demands, and leave this precise connection to future work. Second, we show in Corollary 1 that when traders are Kelly bettors, the resulting stochastic market process is equivalent to stochastic mirror descent; see e.g. [6]. This result adds to the growing literature which relates prediction markets, and automated market makers in general, to online learning; see e.g. [1], [5], [3] . This connection to mirror descent seems to suggest that the prices in a prediction market at any given time may be meaningless, as the ﬁnal point in stochastic mirror descent often has poor convergence guarantees. However, standard results suggest that a prudent way to form a “consensus estimate” from a prediction market is to average the prices. The average price, assuming our market model is reasonable, is provably close to the stationary price. In Section 5 we give a natural example that exhibits this behavior. Beyond this, however, Theorem 2 gives us insight into the relationship between the market liquidity and the convergence of prices; in particular it suggests that we should increase liquidity at a rate √ of t if we wish the price to settle down at the right rate. 2 Model Our market model will follow the automated market maker framework of [1]. We will equip our market maker with a strictly convex function C : Rn → R which is twice continuously diﬀerentiable. For brevity we will write ϕ := C. The outcome space is Ω, and the contracts are determined by a payoﬀ function φ : Ω → Rn such that Π := ϕ(Rn ) = ConvHull(φ(Ω)). That is, the derivative space Π of C (the “instantaneous prices”) must be the convex hull of the payoﬀs. A trader purchasing shares at the current prices π ∈ Rn pays C(ϕ−1 (π) + r) − C(ϕ−1 (π)) for the bundle of contracts r ∈ Rn . Note that our dependence solely on π limits our model slightly, since in general the share space (domain of C) may contain more information than the current prices (cf. [1]). The bundle r is determined by an agent’s demand function d(C, π) which speciﬁes the bundle to buy given the price π and the cost function C. Our market dynamics are the following. The market maker posts the current price πt , and at each time t = 1 . . . T , a trader is chosen with demand function d drawn i.i.d. from some demand distribution D. Intuitively, these demands are parameterized by latent variables such as the agent’s belief p ∈ ∆Ω and total wealth W . The price is then updated to πt+1 = ϕ(ϕ−1 (πt ) + d(C, πt )). (1) After update T , the outcome is revealed and payout φ(ω)i is given for each contract i ∈ {1, . . . , n}. 3 Stationarity and equilibrium We ﬁrst would like to relate our stochastic model (1) to the standard notion of market equilibrium from the Economics literature, which we call the Walrasian equilibrium to avoid confusion. Here prices are ﬁxed, and the equilibrium price is one that clears the market, meaning that the sum of the demands r is 0 ∈ Rn . In fact, we will show that the stationary point of our process approaches the Walrasian equilibrium point as the liquidity of the market approaches inﬁnity. 2 First, we must add a liquidity parameter to our market. Following the LMSR (the cost function C(s) = b ln i esi /b ), we deﬁne Cb (s) := b C(s/b). (2) This transformation of a convex function is called a perspective function and is known to preserve convexity [4]. Observe that ϕb (s) := Cb (s) = C(s/b) = ϕ(s/b), meaning that the price under Cb at s is the same as the price under C at s/b. As with the LMSR, we call b the liquidity parameter ; this terminology is justiﬁed by noting that one deﬁnition of liquidity, 1/λmax 2 Cb (s) = b/λmax 2 C(s/b) (cf. [1]). In the following, we will consider the limit as b → ∞. Second, in order to connect to the Walrasian equilibrium, we need a notion of a ﬁxed-price demand function: if a trader has demand d(C, ·) given C, what would the same trader’s demand be under a market where prices are ﬁxed and do not “change” during a trade? For the sake of generality, we restrict our allowable demand functions to the ones for which the limit d(F, π) := lim d(Cb , π) (3) b→∞ exists; this demand d(F, ·) will be the corresponding ﬁxed-price demand for d. We now deﬁne the Walrasion equilibrium point π ∗ , which is simply the price at which the market clears when traders have demands distributed by D. Formally, this is the following condition:1 d(F, π ∗ ) dD(d) = 0 (4) D Note that 0 ∈ Rn ; the demand for each contract should be balanced. s The stationary point of our stochastic process, on the other hand, is the price πb for which the expected price ﬂuctuation is 0. Formally, we have s s E [∆(πb , d(Cb , πb ))] = 0, (5) d∼D where ∆(π, d) := ϕ(ϕ−1 (π) + d) − π is the price ﬂuctuation. We now consider the limit of our stochastic process as the market liquidity approaches ∞. Theorem 1. Let C be a strictly convex and α-smooth2 cost function, and assume that ∂ ∂b d(Cb , π) = o(1/b) uniformly in π and all d ∈ D. If furthermore the limit (3) is uniform s in π and d, then limb→∞ πb = π ∗ . s Proof. Note that by the stationarity condition (5) we may deﬁne π ∗ and πb to be the roots of the following “excess demand” functions, respectively: Z(π) := s Zb (π) := b E [∆(π, d(Cb , π))], d(F, π) dD(d), d∼D D where we scale the latter by b so that −1 Let s = ϕ s Zb does not limit to the zero function. (π) be the current share vector. Then we have lim b∆(π, d(Cb , π)) = lim b ϕ ϕ−1 (π) + d(Cb , π)/b − π b→∞ b→∞ ϕ s + a d(C1/a , π) − π a ∂ = lim ϕ s + a d(C1/a , π) d(C1/a , π) + a ∂a d(C1/a , π) = lim a→0 a→0 = lim ϕ s+ = lim 2 b→∞ b→∞ 1 b d(Cb , π) C(s) d(Cb , π) = d(Cb , π) + 2 2 1 ∂ b ∂b d(Cb , π)(−b ) C(s) d(F, π), 1 Here and throughout we ignore technical issues of uniqueness. One may simply restrict to the class of demands for which uniqueness is satisﬁed. 2 C is α-smooth if λmax 2 C ≤ α 3 where we apply L’Hopital’s rule for the third equality. Crucially, the above limit is uniform with respect to both d ∈ D and π ∈ Π; uniformity in d is by assumption, and uniformity in π follows from α-smoothness of C, since C is dominated by a quadratic. Since the limit is uniform with respect to D, we now have s lim Zb (π) = lim b E [∆(π, d(Cb , π))] = E b→∞ b→∞ = 2 d∼D d∼D C(s) E [d(F, π)] = 2 lim b∆(π, d(Cb , π)) b→∞ C(s) Z(π). d∼D s As 2 C(s) is positive deﬁnite by assumption on C, we can conclude that limb→∞ Zb and Z share the same zeroes. Since Z has compact domain and is assumed continuous with a unique zero π ∗ , for each ∈ (0, max ) there must be some δ > 0 s.t. |Z(π)| > for all π s.t. π − π ∗ > δ (otherwise there would be a sequence of πn → π s.t. f (π ) = 0 but π = π ∗ ). s By uniform convergence there must be a B > 0 s.t. for all b > B we have Zb − Z ∞ < /2. s s In particular, for π s.t. π − π ∗ > δ, |Zb (π)| > /2. Thus, the corresponding zeros πb must ∗ s ∗ 3 be within δ of π . Hence limb→∞ πb = π . 3.1 Utility-based demands Maximum Expected Utility (MEU) demand functions are a particular kind of demand function derived by assuming a trader has some belief p ∈ ∆n over the outcomes in Ω, some wealth W ≥ 0, and a monotonically increasing utility function of money u : R → R. If such a trader buys a bundle r of contracts from a market maker with cost function C and price π, her wealth after ω occurs is Υω (C, W, π, r) := W +φ(ω)·r−[C(ϕ−1 (π)+r)−C(ϕ−1 (π))]. We ensure traders do not go into debt by requiring that traders only make demands such that this ﬁnal wealth is nonnegative: ∀ω Υω (C, π, r) ≥ 0. The set of debt-free bundles for wealth W and market C at price π is denoted S(C, W, π) := {r ∈ Rn : minω Υω (C, W, π, r) ≥ 0}. A continuous MEU demand function du (C, π) is then just the demand that maximizes a W,p trader’s expected utility subject to the debt-free constraint. That is, du (C, π) := argmax W,p E [u (Υω (C, W, π, r))] . (6) r∈S(C,W,π) ω∼p We also deﬁne a ﬁxed-price MEU demand function du (F, π) similarly, where W,p Υω (F, W, π, r) := W + φ(ω) · r − π · r and S(F, W, π) := {r ∈ Rn : minω Υω (F, W, π, r) ≥ 0} are the ﬁxed price analogues to the continuously priced versions above. Using the notation bS := {b r | r ∈ S}, the following relationships between the continuous and ﬁxed price versions of Υ, SW , and the expected utility are a consequence of the convexity of C. Their main purpose is to highlight the relationship between wealth and liquidity in MEU demands. In particular, they show that scaling up of liquidity is equivalent to a scaling down of wealth and that the continuously priced constraints and wealth functions monotonically approach the ﬁxed priced versions. Lemma 1. For any strictly convex cost function C, wealth W > 0, price π, demand r, and liquidity parameter b > 0 the following properties hold: 1. Υω (Cb , W, π, r) = b Υω (C, W/b, π, r/b); 2. S(Cb , W, π) = b S(C, W/b, π); 3. S(C, W, π) is convex for all C; 4. S(C, W, π) ⊆ S(Cb , W, π) ⊆ S(F, W, π) for all b ≥ 1. 5. For monotone utilities u, Eω∼p [u (Υω (F, W, π, r))] ≥ Eω∼p [u (Υω (C, W, π, r))]. Proof. Property (1) follows from a simple computation: Υω (Cb , W, π, r) = W + φ(ω) · r − b C(ϕ−1 (π) + r/b) + b C(ϕ−1 (π)) = b W/b + φ(ω) · (r/b) − C(ϕ−1 (π) + r/b) + C(ϕ−1 (π)) , which equals b Υω (C, W/b, π, r/b) by deﬁnition. We now can see property (2) as well: S(Cb , W, π) = {r : min b Υω (C, W/b, π, r/b) ≥ 0} = {b r : min Υω (C, W/b, π, r) ≥ 0}. ω 3 ω We thank Avraham Ruderman for a helpful discussion regarding this proof. 4 For (3), deﬁne fC,s,ω (r) = C(s + r) − C(s) − φ(ω) · r, which is the ex-post cost of purchasing bundle r. As C is convex, and fC,s,ω is a shifted and translated version of C plus a linear term, fC,s,ω is convex also. The constraint Υω (C, W, π, r) ≥ 0 then translates to fC,s,ω (r) ≤ W , and thus the set of r which satisfy the constraint is convex as a sublevel set of a convex function. Now S(C, W, π) is convex as an intersection of convex sets, proving (3). For (4) suppose r satisﬁes fC,s,ω (r) ≤ W . Note that fC,s,ω (0) = 0 always. Then by convexity we have for f := fC,s,ω we have f (r/b) = f 1 r + b−1 0 ≤ 1 f (r) + b−1 0 ≤ W/b, b b b b which implies S(C, W, π) ⊆ S(Cb , W, π) when considering (3). To complete (4) note that fC,s,ω dominates fF,s : r → (ϕ(s) − φ(ω)) · r by convexity of C: C(s + r) − C(s) ≥ C(s) · r. Finally, proof of (5) is obtained by noting that the convexity of C means that C(ϕ−1 (π) + r) − C(ϕ−1 (π)) ≥ C(ϕ−1 (π)) · r = π · r and exploting the monotonicty of u. Lemma 1 shows us that MEU demands have a lot of structure, and in particular, properties (4) and (5) suggest that they may satisfy the conditions of Theorem 1; we leave this as an open question for future work. Another interesting aspect of Lemma 1 is the relationship between markets with cost function Cb and wealths W and markets with cost function C and wealths W/b – indeed, properties (1) and (2) suggest that the liquidity limit should in some sense be equivalent to a wealth limit, in that increasing liquidity by a factor b should yield similar dynamics to decreasing the wealths by b. This would relate our model to that of [8], where the authors essentially show a wealth-limit version of Theorem 1 for a binary-outcome market where traders have linear utilities (a special case of (6)). We leave this precise connection for future work. 4 Market making as mirror descent We now explore the surprising relationship between our stochastic price update and standard stochastic optimization techniques. In particular, we will relate our model to a stochastic mirror descent of the form xt+1 = argmin{η x · F (xt ; ξ) + DR (x, xt )}, (7) x∈R where at each step ξ ∼ Ξ are i.i.d. and R is some strictly convex function. We will refer to an algorithm of the form (7) a stochastic mirror descent of f (x) := Eξ∼Ξ [F (x; ξ)]. Theorem 2. If for all d ∈ D we have some F (· ; d) : Rn → Rn such that d(R∗ , π) = − F (π; d), then the stochastic update of our model (1) is exactly a stochastic mirror descent of f (π) = Ed∼D [F (π; d)]. Proof. By standard arguments, the mirror descent update (7) can be rewritten as xt+1 = R∗ ( R(xt ) − F (xt ; ξ)), where R∗ is the conjugate dual of R. Take R = C ∗ , and let ξ = d ∼ D. By assumption, we have F (x; d) = −d(R∗ , x) = −d(C, x) for all d. As R∗ = C = ϕ, we have ϕ−1 = ( R∗ )−1 = R by duality, and thus our update becomes xt+1 = ϕ ϕ−1 (xt ) + d(C, xt ) , which exactly matches the stochastic update of our model (1). As an example, consider Kelly betters, which correspond to ﬁxed-price demands d(C, π) := dlog (F, π) with utility u(x) = log x as deﬁned in (3). A simple calculation shows that our W,p update becomes W p−π πt+1 = ϕ ϕ−1 (πt ) + , (8) π 1−π where W and p are drawn (independently) from P and W. Corollary 1. The stochastic update for ﬁxed-price Kelly betters (8) is exactly a stochastic mirror descent of f (π) = W · KL(p, π), where p and W are the means of P and W, respectively. 5 Proof. We take F (x; dlog ) = W · (KL(p, x) + H(p)). Then W,p F (x; dlog ) = W W,p −p p − 1 + x 1−x =− W p−x = −dlog (F, x). W,p x 1−x Hence, by Theorem 2 our update is a stochastic mirror descent of: f (x) := E[F (x; dlog )] = E[W p log x + W (1 − p) log(1 − x)] = W · (KL(p, x) + H(p)) , W,p which of course is equivalent to W · KL(p, x) as the entropy term does not depend on x. Note that while this last result is quite compelling, we have mixed ﬁxed-price demands with a continuous-price market model – see Section 3.1. One could interpret this combination as a model in which the market maker can only adjust the prices after a trade, according to a ﬁxed convex cost function C. This of course diﬀers from the standard model, which adjusts the price continuously during a trade. 4.1 Leveraging existing learning results Theorem 2 not only identiﬁes a fascinating connection between machine learning and our stochastic prediction market model, but it also allows us to use powerful existing techniques to make broad conclusions about the behavior of our model. Consider the following result: ≤ G2 for all p, π, and R is σ-strongly convex, then log 1 δ . Price Avg price Avg belief 0.70 In our context, Proposition 1 says that the average of the prices will be a very good estimate of the minimizer of f , which as suggested by happens to be the underlying mean belief p of the traders! Moreover, as the Kelly demands are linear in both p and W , it is easy to see from Theorem 1 that p is also the stationary point and the Walrasian equilibrium point (the latter was also shown by [11]). On the other hand, as we demonstrate next, it is not hard to come up with an example where the instantaneous price πt is quite far from the equilibrium at any given time period. 1+4 0.65 π D2 G2 η + ηT 2σ 0.60 f (π T ) ≤ min f (π) + Price of contract 1 2 0.55 F (π; p) 0.50 Proposition 1 ([6]). If with probability 1 − δ, 0 500 1000 1500 2000 Trade number Before moving to our empirical work, we make one Figure 1: Price movement for Kelly ﬁnal point. The above relationship between our betters with binomial(q = 0.6, n = 6, stochastic market model and mirror descent sheds α = 0.5) beliefs in the LMSR market light on an important question: how might an auto- with liquidity b = 10. mated market maker adjust the liquidity so that the market actually converges to the mean of the traders’ beliefs? The learning parameter η can be thought of as the inverse of the liquidity, and as such, Proposition 1 suggests that √ increasing the liquidity as t may cause the mean price to converge to the mean belief (assuming a ﬁxed underlying belief distribution). 5 Empirical work Example: biased coin Consider a classic Bayesian setting where a coin has unknown bias Pr[heads] = q, and traders have a prior β(α, α) over q (i.e., traders are α-conﬁdent that the coin is fair). Now suppose each trader independently observes n ﬂips from the coin, and updates her belief; upon seeing k heads, a trader would have posterior β(α + k, α + n − k). When presented with a prediction market with contracts for a single toss of the coin, where and contract 0 pays $1 for tails and contract 1 pays $1 for heads, a trader would purchase 6 0 20 40 60 Trades 80 100 b = 10 Instant Averaged 0.06 Loss 0.04 0.02 0.00 0.02 0.04 Loss 0.06 0.08 Instant Averaged 0.00 0.00 0.02 0.04 Loss 0.06 0.08 Instant Averaged Square loss of price to mean belief for State 9 b=3 0.08 b=1 0.10 Square loss of price to mean belief for State 9 0.10 0.10 Square loss of price to mean belief for State 9 0 20 40 60 Trades 80 100 0 20 40 60 80 100 Trades Figure 2: Mean square loss of average and instantaneous prices relative to the mean belief of 0.26 over 20 simulations for State 9 for b = 1 (left), b = 3 (middle), and b = 10 (right). Bars show standard deviation. contracts as if according to the mean of their posterior. Hence, the belief distribution P of the market assigns weight P(p) = n q k (1 − q)n−k to belief p = (α + k)/(2α + n), yielding k a biased mean belief of (α + nq)/(2α + n). We show a typical simulation of this market in Figure 1, where traders behave as Kelly betters in the ﬁxed-price LMSR. Clearly, after almost every trade, the market price is quite far from the equilibrium/stationary point, and hence the classical supply and demand analysis of this market yields a poor description of the actual behavior, and in particular, of the predictive quality of the price at any given time. However, the mean price is consistently close to the mean belief of the traders, which in turn is quite close to the true parameter q. Election Survey Data We now compare the quality of the running average price versus the instantaneous price as a predictor of the mean belief of a market. We do so by simulating a market maker interacting with traders with unit wealth, log utility, and beliefs drawn from a ﬁxed distribution. The belief distributions are derived from the Princeton election survey data[10]. For each of the 50 US states, participants in the survey were asked to estimate the probability that one of two possible candidates were going to win that state.4 We use these 50 sets of estimates as 50 diﬀerent empirical distributions from which to draw trader beliefs. A simulation is conﬁgured by choosing one of the 50 empirical belief distributions S, a market liquidity parameter b to deﬁne the LMSR cost function C(s) = b ln i esi /b , and an initial market position vector of (0, 0) – that is, no contracts for either outcome. A conﬁgured simulation is run for T trades. At each trade, a belief p is drawn from S uniformly and with replacement. This belief is used to determine the demand of the trader relative to the current market pricing. The trader purchase a bundle of contracts according to its demand and the market moves its position and price accordingly. The complete price path πt for t t = 1, . . . , T of the market is recorded as well as a running average price πt := 1 i=1 πt for ¯ t t = 1 . . . , T . For each of the 50 empirical belief distributions we conﬁgured 9 markets with b ∈ {1, 2, 3, 5, 10, 15, 20, 30, 50} and ran 20 independent simulations of T = 100 trades. We present a portion of the results for the empirical distributions for states 9 and 11. States 9 and 11 have, respectively, sample sizes of 2,717 and 2,709; means 0.26 and 0.9; and variances 0.04 and 0.02. These are chosen as being representative of the rest of the simulation results: State 9 with mean oﬀ-center and a spread of beliefs (high uncertainty) and State 11 with highly concentrated beliefs around a single outcome (low uncertainty). The results are summarised in Figures 2, 3, and 4. The ﬁrst show the square loss of the average and instaneous prices relative to the mean belief for high uncertainty State 9 for b = 1, 3, 10. Clearly, the average price is a much more reliable estimator of the mean belief for low liquidity (b = 1) and is only outperformed by the instaneous price for higher liquidity (b = 10), but then only early in trading. Similar plots for State 11 are shown in Figure 3 where the advantage of using the average price is signiﬁcantly diminished. 4 The original dataset contains conjunctions of wins as well as conditional statements but we only use the single variable results of the survey. 7 0 20 40 60 80 100 b = 10 Instant Averaged 0.06 Loss 0.04 0.02 0.00 0.02 0.04 Loss 0.06 0.08 Instant Averaged 0.00 0.00 0.02 0.04 Loss 0.06 0.08 Instant Averaged Square loss of price to mean belief for State 11 b=3 0.08 b=1 0.10 Square loss of price to mean belief for State 11 0.10 0.10 Square loss of price to mean belief for State 11 0 20 40 Trades 60 80 100 0 20 40 Trades 60 80 100 Trades Figure 3: Mean square loss of average and instantaneous prices relative to the mean belief of 0.9 over 20 simulations for State 11 for b = 1 (left), b = 3 (middle), and b = 10 (right). Bars show standard deviation. Figure 4 shows the improvement the average price has over the instantaneous price in square loss relative to the mean belief for all liquidity settings and highlights that average prices work better in low liquidity settings, consistent with the theory. Similar trends were observed for all the other States, depending on whether they had high uncertainty – in which case average price was a much better estimator – or low uncertainty – in which case instanteous price was better. Improvement of Average over Instant Prices for State 9 Improvement of Average over Instant Prices for State 11 0.06 0.02 0.00 0.04 Loss Di fference fference -0.04 0.00 -0.06 -0.02 -0.08 10 20 100 80 80 30 40 40 30 60 Tra des b 60 Tra des 10 20 100 20 b Loss Di -0.02 0.02 40 40 20 50 50 Figure 4: An overview of the results for States 9 (left) and 11 (right). For each trade and choice of b, the vertical value shows the improvement of the average price over the instantaneous price as measure by square loss relative to the mean. 6 Conclusion and future work As noted in Section 3.1, there are several open questions with regard to maximum expected utility demands and Theorem 1, as well as the relationship between trader wealth and market liquidity. It would also be interesting to have a application of Theorem 2 to a continuousprice model, which yields a natural minimization as in Corollary 1. The equivalence to mirror decent stablished in Theorem 2 may also lead to a better understanding of the optimal manner in which a automated prediction market ought to increase liquidity so as to maximise eﬃciency. Acknowledgments This work was supported by the Australian Research Council (ARC). NICTA is funded by the Australian Government as represented by the Department of Broadband, Communications and the Digital Economy and the ARC through the ICT Centre of Excellence program. The ﬁrst author was partially supported by NSF grant CC-0964033 and by a Google University Research Award. 8 References [1] J. Abernethy, Y. Chen, and J.W. Vaughan. An optimization-based framework for automated market-making. In Proceedings of the 11th ACM conference on Electronic Commerce (EC’11), 2011. [2] A. Barbu and N. Lay. An introduction to artiﬁcial prediction markets for classiﬁcation. Arxiv preprint arXiv:1102.1465, 2011. [3] A. Beygelzimer, J. Langford, and D. Pennock. Learning Performance of Prediction Markets with Kelly Bettors. 2012. [4] S. Boyd and L. Vandenberghe. Convex optimization. Cambridge University Press, 2004. [5] Y. Chen and J.W. Vaughan. A new understanding of prediction markets via no-regret learning, pages 189–198. 2010. [6] J. Duchi, S. Shalev-Shwartz, Y. Singer, and A. Tewari. Composite objective mirror descent. COLT, 2010. [7] C.F. Manski. Interpreting the predictions of prediction markets. Technical report, National Bureau of Economic Research, 2004. [8] A. Othman and T. Sandholm. When do markets with simple agents fail? In Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems: volume 1-Volume 1, pages 865–872. International Foundation for Autonomous Agents and Multiagent Systems, 2010. [9] A. Storkey. Machine learning markets. AISTATS, 2012. [10] G. Wang, S.R. Kulkarni, H.V. Poor, and D.N. Osherson. Aggregating large sets of probabilistic forecasts by weighted coherent adjustment. Decision Analysis, 8(2):128, 2011. [11] J. Wolfers and E. Zitzewitz. Interpreting prediction market prices as probabilities. Technical report, National Bureau of Economic Research, 2006. 9</p><p>2 0.063508622 <a title="161-tfidf-2" href="./nips-2012-Finite_Sample_Convergence_Rates_of_Zero-Order_Stochastic_Optimization_Methods.html">134 nips-2012-Finite Sample Convergence Rates of Zero-Order Stochastic Optimization Methods</a></p>
<p>Author: Andre Wibisono, Martin J. Wainwright, Michael I. Jordan, John C. Duchi</p><p>Abstract: We consider derivative-free algorithms for stochastic optimization problems that use only noisy function values rather than gradients, analyzing their ﬁnite-sample convergence rates. We show that if pairs of function values are available, algorithms that √ gradient estimates based on random perturbations suffer a factor use of at most d in convergence rate over traditional stochastic gradient methods, where d is the problem dimension. We complement our algorithmic development with information-theoretic lower bounds on the minimax convergence rate of such problems, which show that our bounds are sharp with respect to all problemdependent quantities: they cannot be improved by more than constant factors. 1</p><p>3 0.062571213 <a title="161-tfidf-3" href="./nips-2012-Link_Prediction_in_Graphs_with_Autoregressive_Features.html">199 nips-2012-Link Prediction in Graphs with Autoregressive Features</a></p>
<p>Author: Emile Richard, Stephane Gaiffas, Nicolas Vayatis</p><p>Abstract: In the paper, we consider the problem of link prediction in time-evolving graphs. We assume that certain graph features, such as the node degree, follow a vector autoregressive (VAR) model and we propose to use this information to improve the accuracy of prediction. Our strategy involves a joint optimization procedure over the space of adjacency matrices and VAR matrices which takes into account both sparsity and low rank properties of the matrices. Oracle inequalities are derived and illustrate the trade-offs in the choice of smoothing parameters when modeling the joint effect of sparsity and low rank property. The estimate is computed efﬁciently using proximal methods through a generalized forward-backward agorithm. 1</p><p>4 0.05539567 <a title="161-tfidf-4" href="./nips-2012-Stochastic_Gradient_Descent_with_Only_One_Projection.html">324 nips-2012-Stochastic Gradient Descent with Only One Projection</a></p>
<p>Author: Mehrdad Mahdavi, Tianbao Yang, Rong Jin, Shenghuo Zhu, Jinfeng Yi</p><p>Abstract: Although many variants of stochastic gradient descent have been proposed for large-scale convex optimization, most of them require projecting the solution at each iteration to ensure that the obtained solution stays within the feasible domain. For complex domains (e.g., positive semideﬁnite cone), the projection step can be computationally expensive, making stochastic gradient descent unattractive for large-scale optimization problems. We address this limitation by developing novel stochastic optimization algorithms that do not need intermediate projections. Instead, only one projection at the last iteration is needed to obtain a feasible solution in the given domain. Our theoretical analysis shows that with a high probability, √ the proposed algorithms achieve an O(1/ T ) convergence rate for general convex optimization, and an O(ln T /T ) rate for strongly convex optimization under mild conditions about the domain and the objective function. 1</p><p>5 0.053179476 <a title="161-tfidf-5" href="./nips-2012-Learning_as_MAP_Inference_in_Discrete_Graphical_Models.html">186 nips-2012-Learning as MAP Inference in Discrete Graphical Models</a></p>
<p>Author: Xianghang Liu, James Petterson, Tibério S. Caetano</p><p>Abstract: We present a new formulation for binary classiﬁcation. Instead of relying on convex losses and regularizers such as in SVMs, logistic regression and boosting, or instead non-convex but continuous formulations such as those encountered in neural networks and deep belief networks, our framework entails a non-convex but discrete formulation, where estimation amounts to ﬁnding a MAP conﬁguration in a graphical model whose potential functions are low-dimensional discrete surrogates for the misclassiﬁcation loss. We argue that such a discrete formulation can naturally account for a number of issues that are typically encountered in either the convex or the continuous non-convex approaches, or both. By reducing the learning problem to a MAP inference problem, we can immediately translate the guarantees available for many inference settings to the learning problem itself. We empirically demonstrate in a number of experiments that this approach is promising in dealing with issues such as severe label noise, while still having global optimality guarantees. Due to the discrete nature of the formulation, it also allows for direct regularization through cardinality-based penalties, such as the 0 pseudo-norm, thus providing the ability to perform feature selection and trade-oﬀ interpretability and predictability in a principled manner. We also outline a number of open problems arising from the formulation. 1</p><p>6 0.051843435 <a title="161-tfidf-6" href="./nips-2012-Optimal_Regularized_Dual_Averaging_Methods_for_Stochastic_Optimization.html">263 nips-2012-Optimal Regularized Dual Averaging Methods for Stochastic Optimization</a></p>
<p>7 0.049992137 <a title="161-tfidf-7" href="./nips-2012-Probabilistic_Low-Rank_Subspace_Clustering.html">277 nips-2012-Probabilistic Low-Rank Subspace Clustering</a></p>
<p>8 0.047726955 <a title="161-tfidf-8" href="./nips-2012-Stochastic_optimization_and_sparse_statistical_recovery%3A_Optimal_algorithms_for_high_dimensions.html">325 nips-2012-Stochastic optimization and sparse statistical recovery: Optimal algorithms for high dimensions</a></p>
<p>9 0.047671229 <a title="161-tfidf-9" href="./nips-2012-Rational_inference_of_relative_preferences.html">288 nips-2012-Rational inference of relative preferences</a></p>
<p>10 0.046041988 <a title="161-tfidf-10" href="./nips-2012-Approximating_Equilibria_in_Sequential_Auctions_with_Incomplete_Information_and_Multi-Unit_Demand.html">45 nips-2012-Approximating Equilibria in Sequential Auctions with Incomplete Information and Multi-Unit Demand</a></p>
<p>11 0.045326076 <a title="161-tfidf-11" href="./nips-2012-Multiclass_Learning_with_Simplex_Coding.html">227 nips-2012-Multiclass Learning with Simplex Coding</a></p>
<p>12 0.044412851 <a title="161-tfidf-12" href="./nips-2012-Causal_discovery_with_scale-mixture_model_for_spatiotemporal_variance_dependencies.html">66 nips-2012-Causal discovery with scale-mixture model for spatiotemporal variance dependencies</a></p>
<p>13 0.04154668 <a title="161-tfidf-13" href="./nips-2012-Efficient_Reinforcement_Learning_for_High_Dimensional_Linear_Quadratic_Systems.html">110 nips-2012-Efficient Reinforcement Learning for High Dimensional Linear Quadratic Systems</a></p>
<p>14 0.040900722 <a title="161-tfidf-14" href="./nips-2012-Topology_Constraints_in_Graphical_Models.html">346 nips-2012-Topology Constraints in Graphical Models</a></p>
<p>15 0.040758852 <a title="161-tfidf-15" href="./nips-2012-Mixability_in_Statistical_Learning.html">217 nips-2012-Mixability in Statistical Learning</a></p>
<p>16 0.040124599 <a title="161-tfidf-16" href="./nips-2012-Transelliptical_Component_Analysis.html">351 nips-2012-Transelliptical Component Analysis</a></p>
<p>17 0.03769261 <a title="161-tfidf-17" href="./nips-2012-Dynamic_Pruning_of_Factor_Graphs_for_Maximum_Marginal_Prediction.html">105 nips-2012-Dynamic Pruning of Factor Graphs for Maximum Marginal Prediction</a></p>
<p>18 0.037554979 <a title="161-tfidf-18" href="./nips-2012-The_Bethe_Partition_Function_of_Log-supermodular_Graphical_Models.html">335 nips-2012-The Bethe Partition Function of Log-supermodular Graphical Models</a></p>
<p>19 0.034588184 <a title="161-tfidf-19" href="./nips-2012-Globally_Convergent_Dual_MAP_LP_Relaxation_Solvers_using_Fenchel-Young_Margins.html">143 nips-2012-Globally Convergent Dual MAP LP Relaxation Solvers using Fenchel-Young Margins</a></p>
<p>20 0.034457892 <a title="161-tfidf-20" href="./nips-2012-Expectation_Propagation_in_Gaussian_Process_Dynamical_Systems.html">121 nips-2012-Expectation Propagation in Gaussian Process Dynamical Systems</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.091), (1, 0.019), (2, 0.029), (3, -0.049), (4, 0.003), (5, 0.023), (6, -0.001), (7, -0.001), (8, -0.001), (9, 0.003), (10, -0.046), (11, 0.007), (12, 0.031), (13, -0.004), (14, 0.011), (15, -0.018), (16, 0.003), (17, -0.004), (18, -0.015), (19, 0.0), (20, 0.022), (21, 0.024), (22, -0.018), (23, -0.009), (24, 0.04), (25, -0.018), (26, -0.023), (27, -0.018), (28, -0.013), (29, -0.033), (30, -0.014), (31, -0.006), (32, 0.042), (33, -0.054), (34, 0.036), (35, 0.025), (36, 0.026), (37, 0.002), (38, -0.071), (39, 0.001), (40, 0.003), (41, 0.024), (42, -0.041), (43, 0.004), (44, 0.031), (45, 0.001), (46, 0.045), (47, 0.024), (48, -0.077), (49, -0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.90893227 <a title="161-lsi-1" href="./nips-2012-Interpreting_prediction_markets%3A_a_stochastic_approach.html">161 nips-2012-Interpreting prediction markets: a stochastic approach</a></p>
<p>Author: Nicolas D. Penna, Mark D. Reid, Rafael M. Frongillo</p><p>Abstract: We strengthen recent connections between prediction markets and learning by showing that a natural class of market makers can be understood as performing stochastic mirror descent when trader demands are sequentially drawn from a ﬁxed distribution. This provides new insights into how market prices (and price paths) may be interpreted as a summary of the market’s belief distribution by relating them to the optimization problem being solved. In particular, we show that under certain conditions the stationary point of the stochastic process of prices generated by the market is equal to the market’s Walrasian equilibrium of classic market analysis. Together, these results suggest how traditional market making mechanisms might be replaced with general purpose learning algorithms while still retaining guarantees about their behaviour. 1 Introduction and literature review This paper is part of an ongoing line of research, spanning several authors, into formal connections between markets and machine learning. In [5] an equivalence is shown between the theoretically popular prediction market makers based on sequences of proper scoring rules and follow the regularised leader, a form of no-regret online learning. By modelling the traders that demand the assets the market maker is oﬀering we are able to extend the equivalence to stochastic mirror decent. The dynamics of wealth transfer is studied in [3], for a sequence of markets between agents that behave as Kelly bettors (i.e. have log utilities), and an equivalence to stochastic gradient decent is analysed. More broadly, [9, 2] have analysed how a wide range of machine learning models can be implemented in terms of market equilibria. The literature on the interpretation of prediction market prices [7, 11] has had the goal of relating the equilibrium prices to the distribution of the beliefs of traders. More recent work [8] has looked at a stochastic model, and studied the behavior of simple agents sequentially interacting with the market. We continue this latter path of research, motivated by the observation that the equilibrium price may be a poor predictor of the behavior in a volitile prediction market. As such, we seek a more detailed understanding of the market than the equilibrium point – we would like to know what the “stationary distribution” of the price is, as time goes to inﬁnity. 1 As is standard in the literature, we assume a ﬁxed (product) distribution over traders’ beliefs and wealth. Our model features an automated market maker, following the framework of [1] is becoming a standard framework in the ﬁeld. We obtain two results. First, we prove that under certain conditions the stationary point of our stochastic process deﬁned by the market maker and a belief distribution of traders converges to the Walrasian equilibrium of the market as the market liquidity increases. This result, stated in Theorem 1, is general in the sense that only technical convergence conditions are placed on the demand functions of the traders – as such, we believe it is a generalisation of the stochastic result of [8] to cases where agents are are not limited to linear demands, and leave this precise connection to future work. Second, we show in Corollary 1 that when traders are Kelly bettors, the resulting stochastic market process is equivalent to stochastic mirror descent; see e.g. [6]. This result adds to the growing literature which relates prediction markets, and automated market makers in general, to online learning; see e.g. [1], [5], [3] . This connection to mirror descent seems to suggest that the prices in a prediction market at any given time may be meaningless, as the ﬁnal point in stochastic mirror descent often has poor convergence guarantees. However, standard results suggest that a prudent way to form a “consensus estimate” from a prediction market is to average the prices. The average price, assuming our market model is reasonable, is provably close to the stationary price. In Section 5 we give a natural example that exhibits this behavior. Beyond this, however, Theorem 2 gives us insight into the relationship between the market liquidity and the convergence of prices; in particular it suggests that we should increase liquidity at a rate √ of t if we wish the price to settle down at the right rate. 2 Model Our market model will follow the automated market maker framework of [1]. We will equip our market maker with a strictly convex function C : Rn → R which is twice continuously diﬀerentiable. For brevity we will write ϕ := C. The outcome space is Ω, and the contracts are determined by a payoﬀ function φ : Ω → Rn such that Π := ϕ(Rn ) = ConvHull(φ(Ω)). That is, the derivative space Π of C (the “instantaneous prices”) must be the convex hull of the payoﬀs. A trader purchasing shares at the current prices π ∈ Rn pays C(ϕ−1 (π) + r) − C(ϕ−1 (π)) for the bundle of contracts r ∈ Rn . Note that our dependence solely on π limits our model slightly, since in general the share space (domain of C) may contain more information than the current prices (cf. [1]). The bundle r is determined by an agent’s demand function d(C, π) which speciﬁes the bundle to buy given the price π and the cost function C. Our market dynamics are the following. The market maker posts the current price πt , and at each time t = 1 . . . T , a trader is chosen with demand function d drawn i.i.d. from some demand distribution D. Intuitively, these demands are parameterized by latent variables such as the agent’s belief p ∈ ∆Ω and total wealth W . The price is then updated to πt+1 = ϕ(ϕ−1 (πt ) + d(C, πt )). (1) After update T , the outcome is revealed and payout φ(ω)i is given for each contract i ∈ {1, . . . , n}. 3 Stationarity and equilibrium We ﬁrst would like to relate our stochastic model (1) to the standard notion of market equilibrium from the Economics literature, which we call the Walrasian equilibrium to avoid confusion. Here prices are ﬁxed, and the equilibrium price is one that clears the market, meaning that the sum of the demands r is 0 ∈ Rn . In fact, we will show that the stationary point of our process approaches the Walrasian equilibrium point as the liquidity of the market approaches inﬁnity. 2 First, we must add a liquidity parameter to our market. Following the LMSR (the cost function C(s) = b ln i esi /b ), we deﬁne Cb (s) := b C(s/b). (2) This transformation of a convex function is called a perspective function and is known to preserve convexity [4]. Observe that ϕb (s) := Cb (s) = C(s/b) = ϕ(s/b), meaning that the price under Cb at s is the same as the price under C at s/b. As with the LMSR, we call b the liquidity parameter ; this terminology is justiﬁed by noting that one deﬁnition of liquidity, 1/λmax 2 Cb (s) = b/λmax 2 C(s/b) (cf. [1]). In the following, we will consider the limit as b → ∞. Second, in order to connect to the Walrasian equilibrium, we need a notion of a ﬁxed-price demand function: if a trader has demand d(C, ·) given C, what would the same trader’s demand be under a market where prices are ﬁxed and do not “change” during a trade? For the sake of generality, we restrict our allowable demand functions to the ones for which the limit d(F, π) := lim d(Cb , π) (3) b→∞ exists; this demand d(F, ·) will be the corresponding ﬁxed-price demand for d. We now deﬁne the Walrasion equilibrium point π ∗ , which is simply the price at which the market clears when traders have demands distributed by D. Formally, this is the following condition:1 d(F, π ∗ ) dD(d) = 0 (4) D Note that 0 ∈ Rn ; the demand for each contract should be balanced. s The stationary point of our stochastic process, on the other hand, is the price πb for which the expected price ﬂuctuation is 0. Formally, we have s s E [∆(πb , d(Cb , πb ))] = 0, (5) d∼D where ∆(π, d) := ϕ(ϕ−1 (π) + d) − π is the price ﬂuctuation. We now consider the limit of our stochastic process as the market liquidity approaches ∞. Theorem 1. Let C be a strictly convex and α-smooth2 cost function, and assume that ∂ ∂b d(Cb , π) = o(1/b) uniformly in π and all d ∈ D. If furthermore the limit (3) is uniform s in π and d, then limb→∞ πb = π ∗ . s Proof. Note that by the stationarity condition (5) we may deﬁne π ∗ and πb to be the roots of the following “excess demand” functions, respectively: Z(π) := s Zb (π) := b E [∆(π, d(Cb , π))], d(F, π) dD(d), d∼D D where we scale the latter by b so that −1 Let s = ϕ s Zb does not limit to the zero function. (π) be the current share vector. Then we have lim b∆(π, d(Cb , π)) = lim b ϕ ϕ−1 (π) + d(Cb , π)/b − π b→∞ b→∞ ϕ s + a d(C1/a , π) − π a ∂ = lim ϕ s + a d(C1/a , π) d(C1/a , π) + a ∂a d(C1/a , π) = lim a→0 a→0 = lim ϕ s+ = lim 2 b→∞ b→∞ 1 b d(Cb , π) C(s) d(Cb , π) = d(Cb , π) + 2 2 1 ∂ b ∂b d(Cb , π)(−b ) C(s) d(F, π), 1 Here and throughout we ignore technical issues of uniqueness. One may simply restrict to the class of demands for which uniqueness is satisﬁed. 2 C is α-smooth if λmax 2 C ≤ α 3 where we apply L’Hopital’s rule for the third equality. Crucially, the above limit is uniform with respect to both d ∈ D and π ∈ Π; uniformity in d is by assumption, and uniformity in π follows from α-smoothness of C, since C is dominated by a quadratic. Since the limit is uniform with respect to D, we now have s lim Zb (π) = lim b E [∆(π, d(Cb , π))] = E b→∞ b→∞ = 2 d∼D d∼D C(s) E [d(F, π)] = 2 lim b∆(π, d(Cb , π)) b→∞ C(s) Z(π). d∼D s As 2 C(s) is positive deﬁnite by assumption on C, we can conclude that limb→∞ Zb and Z share the same zeroes. Since Z has compact domain and is assumed continuous with a unique zero π ∗ , for each ∈ (0, max ) there must be some δ > 0 s.t. |Z(π)| > for all π s.t. π − π ∗ > δ (otherwise there would be a sequence of πn → π s.t. f (π ) = 0 but π = π ∗ ). s By uniform convergence there must be a B > 0 s.t. for all b > B we have Zb − Z ∞ < /2. s s In particular, for π s.t. π − π ∗ > δ, |Zb (π)| > /2. Thus, the corresponding zeros πb must ∗ s ∗ 3 be within δ of π . Hence limb→∞ πb = π . 3.1 Utility-based demands Maximum Expected Utility (MEU) demand functions are a particular kind of demand function derived by assuming a trader has some belief p ∈ ∆n over the outcomes in Ω, some wealth W ≥ 0, and a monotonically increasing utility function of money u : R → R. If such a trader buys a bundle r of contracts from a market maker with cost function C and price π, her wealth after ω occurs is Υω (C, W, π, r) := W +φ(ω)·r−[C(ϕ−1 (π)+r)−C(ϕ−1 (π))]. We ensure traders do not go into debt by requiring that traders only make demands such that this ﬁnal wealth is nonnegative: ∀ω Υω (C, π, r) ≥ 0. The set of debt-free bundles for wealth W and market C at price π is denoted S(C, W, π) := {r ∈ Rn : minω Υω (C, W, π, r) ≥ 0}. A continuous MEU demand function du (C, π) is then just the demand that maximizes a W,p trader’s expected utility subject to the debt-free constraint. That is, du (C, π) := argmax W,p E [u (Υω (C, W, π, r))] . (6) r∈S(C,W,π) ω∼p We also deﬁne a ﬁxed-price MEU demand function du (F, π) similarly, where W,p Υω (F, W, π, r) := W + φ(ω) · r − π · r and S(F, W, π) := {r ∈ Rn : minω Υω (F, W, π, r) ≥ 0} are the ﬁxed price analogues to the continuously priced versions above. Using the notation bS := {b r | r ∈ S}, the following relationships between the continuous and ﬁxed price versions of Υ, SW , and the expected utility are a consequence of the convexity of C. Their main purpose is to highlight the relationship between wealth and liquidity in MEU demands. In particular, they show that scaling up of liquidity is equivalent to a scaling down of wealth and that the continuously priced constraints and wealth functions monotonically approach the ﬁxed priced versions. Lemma 1. For any strictly convex cost function C, wealth W > 0, price π, demand r, and liquidity parameter b > 0 the following properties hold: 1. Υω (Cb , W, π, r) = b Υω (C, W/b, π, r/b); 2. S(Cb , W, π) = b S(C, W/b, π); 3. S(C, W, π) is convex for all C; 4. S(C, W, π) ⊆ S(Cb , W, π) ⊆ S(F, W, π) for all b ≥ 1. 5. For monotone utilities u, Eω∼p [u (Υω (F, W, π, r))] ≥ Eω∼p [u (Υω (C, W, π, r))]. Proof. Property (1) follows from a simple computation: Υω (Cb , W, π, r) = W + φ(ω) · r − b C(ϕ−1 (π) + r/b) + b C(ϕ−1 (π)) = b W/b + φ(ω) · (r/b) − C(ϕ−1 (π) + r/b) + C(ϕ−1 (π)) , which equals b Υω (C, W/b, π, r/b) by deﬁnition. We now can see property (2) as well: S(Cb , W, π) = {r : min b Υω (C, W/b, π, r/b) ≥ 0} = {b r : min Υω (C, W/b, π, r) ≥ 0}. ω 3 ω We thank Avraham Ruderman for a helpful discussion regarding this proof. 4 For (3), deﬁne fC,s,ω (r) = C(s + r) − C(s) − φ(ω) · r, which is the ex-post cost of purchasing bundle r. As C is convex, and fC,s,ω is a shifted and translated version of C plus a linear term, fC,s,ω is convex also. The constraint Υω (C, W, π, r) ≥ 0 then translates to fC,s,ω (r) ≤ W , and thus the set of r which satisfy the constraint is convex as a sublevel set of a convex function. Now S(C, W, π) is convex as an intersection of convex sets, proving (3). For (4) suppose r satisﬁes fC,s,ω (r) ≤ W . Note that fC,s,ω (0) = 0 always. Then by convexity we have for f := fC,s,ω we have f (r/b) = f 1 r + b−1 0 ≤ 1 f (r) + b−1 0 ≤ W/b, b b b b which implies S(C, W, π) ⊆ S(Cb , W, π) when considering (3). To complete (4) note that fC,s,ω dominates fF,s : r → (ϕ(s) − φ(ω)) · r by convexity of C: C(s + r) − C(s) ≥ C(s) · r. Finally, proof of (5) is obtained by noting that the convexity of C means that C(ϕ−1 (π) + r) − C(ϕ−1 (π)) ≥ C(ϕ−1 (π)) · r = π · r and exploting the monotonicty of u. Lemma 1 shows us that MEU demands have a lot of structure, and in particular, properties (4) and (5) suggest that they may satisfy the conditions of Theorem 1; we leave this as an open question for future work. Another interesting aspect of Lemma 1 is the relationship between markets with cost function Cb and wealths W and markets with cost function C and wealths W/b – indeed, properties (1) and (2) suggest that the liquidity limit should in some sense be equivalent to a wealth limit, in that increasing liquidity by a factor b should yield similar dynamics to decreasing the wealths by b. This would relate our model to that of [8], where the authors essentially show a wealth-limit version of Theorem 1 for a binary-outcome market where traders have linear utilities (a special case of (6)). We leave this precise connection for future work. 4 Market making as mirror descent We now explore the surprising relationship between our stochastic price update and standard stochastic optimization techniques. In particular, we will relate our model to a stochastic mirror descent of the form xt+1 = argmin{η x · F (xt ; ξ) + DR (x, xt )}, (7) x∈R where at each step ξ ∼ Ξ are i.i.d. and R is some strictly convex function. We will refer to an algorithm of the form (7) a stochastic mirror descent of f (x) := Eξ∼Ξ [F (x; ξ)]. Theorem 2. If for all d ∈ D we have some F (· ; d) : Rn → Rn such that d(R∗ , π) = − F (π; d), then the stochastic update of our model (1) is exactly a stochastic mirror descent of f (π) = Ed∼D [F (π; d)]. Proof. By standard arguments, the mirror descent update (7) can be rewritten as xt+1 = R∗ ( R(xt ) − F (xt ; ξ)), where R∗ is the conjugate dual of R. Take R = C ∗ , and let ξ = d ∼ D. By assumption, we have F (x; d) = −d(R∗ , x) = −d(C, x) for all d. As R∗ = C = ϕ, we have ϕ−1 = ( R∗ )−1 = R by duality, and thus our update becomes xt+1 = ϕ ϕ−1 (xt ) + d(C, xt ) , which exactly matches the stochastic update of our model (1). As an example, consider Kelly betters, which correspond to ﬁxed-price demands d(C, π) := dlog (F, π) with utility u(x) = log x as deﬁned in (3). A simple calculation shows that our W,p update becomes W p−π πt+1 = ϕ ϕ−1 (πt ) + , (8) π 1−π where W and p are drawn (independently) from P and W. Corollary 1. The stochastic update for ﬁxed-price Kelly betters (8) is exactly a stochastic mirror descent of f (π) = W · KL(p, π), where p and W are the means of P and W, respectively. 5 Proof. We take F (x; dlog ) = W · (KL(p, x) + H(p)). Then W,p F (x; dlog ) = W W,p −p p − 1 + x 1−x =− W p−x = −dlog (F, x). W,p x 1−x Hence, by Theorem 2 our update is a stochastic mirror descent of: f (x) := E[F (x; dlog )] = E[W p log x + W (1 − p) log(1 − x)] = W · (KL(p, x) + H(p)) , W,p which of course is equivalent to W · KL(p, x) as the entropy term does not depend on x. Note that while this last result is quite compelling, we have mixed ﬁxed-price demands with a continuous-price market model – see Section 3.1. One could interpret this combination as a model in which the market maker can only adjust the prices after a trade, according to a ﬁxed convex cost function C. This of course diﬀers from the standard model, which adjusts the price continuously during a trade. 4.1 Leveraging existing learning results Theorem 2 not only identiﬁes a fascinating connection between machine learning and our stochastic prediction market model, but it also allows us to use powerful existing techniques to make broad conclusions about the behavior of our model. Consider the following result: ≤ G2 for all p, π, and R is σ-strongly convex, then log 1 δ . Price Avg price Avg belief 0.70 In our context, Proposition 1 says that the average of the prices will be a very good estimate of the minimizer of f , which as suggested by happens to be the underlying mean belief p of the traders! Moreover, as the Kelly demands are linear in both p and W , it is easy to see from Theorem 1 that p is also the stationary point and the Walrasian equilibrium point (the latter was also shown by [11]). On the other hand, as we demonstrate next, it is not hard to come up with an example where the instantaneous price πt is quite far from the equilibrium at any given time period. 1+4 0.65 π D2 G2 η + ηT 2σ 0.60 f (π T ) ≤ min f (π) + Price of contract 1 2 0.55 F (π; p) 0.50 Proposition 1 ([6]). If with probability 1 − δ, 0 500 1000 1500 2000 Trade number Before moving to our empirical work, we make one Figure 1: Price movement for Kelly ﬁnal point. The above relationship between our betters with binomial(q = 0.6, n = 6, stochastic market model and mirror descent sheds α = 0.5) beliefs in the LMSR market light on an important question: how might an auto- with liquidity b = 10. mated market maker adjust the liquidity so that the market actually converges to the mean of the traders’ beliefs? The learning parameter η can be thought of as the inverse of the liquidity, and as such, Proposition 1 suggests that √ increasing the liquidity as t may cause the mean price to converge to the mean belief (assuming a ﬁxed underlying belief distribution). 5 Empirical work Example: biased coin Consider a classic Bayesian setting where a coin has unknown bias Pr[heads] = q, and traders have a prior β(α, α) over q (i.e., traders are α-conﬁdent that the coin is fair). Now suppose each trader independently observes n ﬂips from the coin, and updates her belief; upon seeing k heads, a trader would have posterior β(α + k, α + n − k). When presented with a prediction market with contracts for a single toss of the coin, where and contract 0 pays $1 for tails and contract 1 pays $1 for heads, a trader would purchase 6 0 20 40 60 Trades 80 100 b = 10 Instant Averaged 0.06 Loss 0.04 0.02 0.00 0.02 0.04 Loss 0.06 0.08 Instant Averaged 0.00 0.00 0.02 0.04 Loss 0.06 0.08 Instant Averaged Square loss of price to mean belief for State 9 b=3 0.08 b=1 0.10 Square loss of price to mean belief for State 9 0.10 0.10 Square loss of price to mean belief for State 9 0 20 40 60 Trades 80 100 0 20 40 60 80 100 Trades Figure 2: Mean square loss of average and instantaneous prices relative to the mean belief of 0.26 over 20 simulations for State 9 for b = 1 (left), b = 3 (middle), and b = 10 (right). Bars show standard deviation. contracts as if according to the mean of their posterior. Hence, the belief distribution P of the market assigns weight P(p) = n q k (1 − q)n−k to belief p = (α + k)/(2α + n), yielding k a biased mean belief of (α + nq)/(2α + n). We show a typical simulation of this market in Figure 1, where traders behave as Kelly betters in the ﬁxed-price LMSR. Clearly, after almost every trade, the market price is quite far from the equilibrium/stationary point, and hence the classical supply and demand analysis of this market yields a poor description of the actual behavior, and in particular, of the predictive quality of the price at any given time. However, the mean price is consistently close to the mean belief of the traders, which in turn is quite close to the true parameter q. Election Survey Data We now compare the quality of the running average price versus the instantaneous price as a predictor of the mean belief of a market. We do so by simulating a market maker interacting with traders with unit wealth, log utility, and beliefs drawn from a ﬁxed distribution. The belief distributions are derived from the Princeton election survey data[10]. For each of the 50 US states, participants in the survey were asked to estimate the probability that one of two possible candidates were going to win that state.4 We use these 50 sets of estimates as 50 diﬀerent empirical distributions from which to draw trader beliefs. A simulation is conﬁgured by choosing one of the 50 empirical belief distributions S, a market liquidity parameter b to deﬁne the LMSR cost function C(s) = b ln i esi /b , and an initial market position vector of (0, 0) – that is, no contracts for either outcome. A conﬁgured simulation is run for T trades. At each trade, a belief p is drawn from S uniformly and with replacement. This belief is used to determine the demand of the trader relative to the current market pricing. The trader purchase a bundle of contracts according to its demand and the market moves its position and price accordingly. The complete price path πt for t t = 1, . . . , T of the market is recorded as well as a running average price πt := 1 i=1 πt for ¯ t t = 1 . . . , T . For each of the 50 empirical belief distributions we conﬁgured 9 markets with b ∈ {1, 2, 3, 5, 10, 15, 20, 30, 50} and ran 20 independent simulations of T = 100 trades. We present a portion of the results for the empirical distributions for states 9 and 11. States 9 and 11 have, respectively, sample sizes of 2,717 and 2,709; means 0.26 and 0.9; and variances 0.04 and 0.02. These are chosen as being representative of the rest of the simulation results: State 9 with mean oﬀ-center and a spread of beliefs (high uncertainty) and State 11 with highly concentrated beliefs around a single outcome (low uncertainty). The results are summarised in Figures 2, 3, and 4. The ﬁrst show the square loss of the average and instaneous prices relative to the mean belief for high uncertainty State 9 for b = 1, 3, 10. Clearly, the average price is a much more reliable estimator of the mean belief for low liquidity (b = 1) and is only outperformed by the instaneous price for higher liquidity (b = 10), but then only early in trading. Similar plots for State 11 are shown in Figure 3 where the advantage of using the average price is signiﬁcantly diminished. 4 The original dataset contains conjunctions of wins as well as conditional statements but we only use the single variable results of the survey. 7 0 20 40 60 80 100 b = 10 Instant Averaged 0.06 Loss 0.04 0.02 0.00 0.02 0.04 Loss 0.06 0.08 Instant Averaged 0.00 0.00 0.02 0.04 Loss 0.06 0.08 Instant Averaged Square loss of price to mean belief for State 11 b=3 0.08 b=1 0.10 Square loss of price to mean belief for State 11 0.10 0.10 Square loss of price to mean belief for State 11 0 20 40 Trades 60 80 100 0 20 40 Trades 60 80 100 Trades Figure 3: Mean square loss of average and instantaneous prices relative to the mean belief of 0.9 over 20 simulations for State 11 for b = 1 (left), b = 3 (middle), and b = 10 (right). Bars show standard deviation. Figure 4 shows the improvement the average price has over the instantaneous price in square loss relative to the mean belief for all liquidity settings and highlights that average prices work better in low liquidity settings, consistent with the theory. Similar trends were observed for all the other States, depending on whether they had high uncertainty – in which case average price was a much better estimator – or low uncertainty – in which case instanteous price was better. Improvement of Average over Instant Prices for State 9 Improvement of Average over Instant Prices for State 11 0.06 0.02 0.00 0.04 Loss Di fference fference -0.04 0.00 -0.06 -0.02 -0.08 10 20 100 80 80 30 40 40 30 60 Tra des b 60 Tra des 10 20 100 20 b Loss Di -0.02 0.02 40 40 20 50 50 Figure 4: An overview of the results for States 9 (left) and 11 (right). For each trade and choice of b, the vertical value shows the improvement of the average price over the instantaneous price as measure by square loss relative to the mean. 6 Conclusion and future work As noted in Section 3.1, there are several open questions with regard to maximum expected utility demands and Theorem 1, as well as the relationship between trader wealth and market liquidity. It would also be interesting to have a application of Theorem 2 to a continuousprice model, which yields a natural minimization as in Corollary 1. The equivalence to mirror decent stablished in Theorem 2 may also lead to a better understanding of the optimal manner in which a automated prediction market ought to increase liquidity so as to maximise eﬃciency. Acknowledgments This work was supported by the Australian Research Council (ARC). NICTA is funded by the Australian Government as represented by the Department of Broadband, Communications and the Digital Economy and the ARC through the ICT Centre of Excellence program. The ﬁrst author was partially supported by NSF grant CC-0964033 and by a Google University Research Award. 8 References [1] J. Abernethy, Y. Chen, and J.W. Vaughan. An optimization-based framework for automated market-making. In Proceedings of the 11th ACM conference on Electronic Commerce (EC’11), 2011. [2] A. Barbu and N. Lay. An introduction to artiﬁcial prediction markets for classiﬁcation. Arxiv preprint arXiv:1102.1465, 2011. [3] A. Beygelzimer, J. Langford, and D. Pennock. Learning Performance of Prediction Markets with Kelly Bettors. 2012. [4] S. Boyd and L. Vandenberghe. Convex optimization. Cambridge University Press, 2004. [5] Y. Chen and J.W. Vaughan. A new understanding of prediction markets via no-regret learning, pages 189–198. 2010. [6] J. Duchi, S. Shalev-Shwartz, Y. Singer, and A. Tewari. Composite objective mirror descent. COLT, 2010. [7] C.F. Manski. Interpreting the predictions of prediction markets. Technical report, National Bureau of Economic Research, 2004. [8] A. Othman and T. Sandholm. When do markets with simple agents fail? In Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems: volume 1-Volume 1, pages 865–872. International Foundation for Autonomous Agents and Multiagent Systems, 2010. [9] A. Storkey. Machine learning markets. AISTATS, 2012. [10] G. Wang, S.R. Kulkarni, H.V. Poor, and D.N. Osherson. Aggregating large sets of probabilistic forecasts by weighted coherent adjustment. Decision Analysis, 8(2):128, 2011. [11] J. Wolfers and E. Zitzewitz. Interpreting prediction market prices as probabilities. Technical report, National Bureau of Economic Research, 2006. 9</p><p>2 0.65731996 <a title="161-lsi-2" href="./nips-2012-Finite_Sample_Convergence_Rates_of_Zero-Order_Stochastic_Optimization_Methods.html">134 nips-2012-Finite Sample Convergence Rates of Zero-Order Stochastic Optimization Methods</a></p>
<p>Author: Andre Wibisono, Martin J. Wainwright, Michael I. Jordan, John C. Duchi</p><p>Abstract: We consider derivative-free algorithms for stochastic optimization problems that use only noisy function values rather than gradients, analyzing their ﬁnite-sample convergence rates. We show that if pairs of function values are available, algorithms that √ gradient estimates based on random perturbations suffer a factor use of at most d in convergence rate over traditional stochastic gradient methods, where d is the problem dimension. We complement our algorithmic development with information-theoretic lower bounds on the minimax convergence rate of such problems, which show that our bounds are sharp with respect to all problemdependent quantities: they cannot be improved by more than constant factors. 1</p><p>3 0.63693321 <a title="161-lsi-3" href="./nips-2012-Optimal_Regularized_Dual_Averaging_Methods_for_Stochastic_Optimization.html">263 nips-2012-Optimal Regularized Dual Averaging Methods for Stochastic Optimization</a></p>
<p>Author: Xi Chen, Qihang Lin, Javier Pena</p><p>Abstract: This paper considers a wide spectrum of regularized stochastic optimization problems where both the loss function and regularizer can be non-smooth. We develop a novel algorithm based on the regularized dual averaging (RDA) method, that can simultaneously achieve the optimal convergence rates for both convex and strongly convex loss. In particular, for strongly convex loss, it achieves the opti1 1 mal rate of O( N + N 2 ) for N iterations, which improves the rate O( log N ) for preN vious regularized dual averaging algorithms. In addition, our method constructs the ﬁnal solution directly from the proximal mapping instead of averaging of all previous iterates. For widely used sparsity-inducing regularizers (e.g., 1 -norm), it has the advantage of encouraging sparser solutions. We further develop a multistage extension using the proposed algorithm as a subroutine, which achieves the 1 uniformly-optimal rate O( N + exp{−N }) for strongly convex loss. 1</p><p>4 0.63653189 <a title="161-lsi-4" href="./nips-2012-Stochastic_optimization_and_sparse_statistical_recovery%3A_Optimal_algorithms_for_high_dimensions.html">325 nips-2012-Stochastic optimization and sparse statistical recovery: Optimal algorithms for high dimensions</a></p>
<p>Author: Alekh Agarwal, Sahand Negahban, Martin J. Wainwright</p><p>Abstract: We develop and analyze stochastic optimization algorithms for problems in which the expected loss is strongly convex, and the optimum is (approximately) sparse. Previous approaches are able to exploit only one of these two structures, yielding a O(d/T ) convergence rate for strongly convex objectives in d dimensions and O( s(log d)/T ) convergence rate when the optimum is s-sparse. Our algorithm is based on successively solving a series of ℓ1 -regularized optimization problems using Nesterov’s dual averaging algorithm. We establish that the error of our solution after T iterations is at most O(s(log d)/T ), with natural extensions to approximate sparsity. Our results apply to locally Lipschitz losses including the logistic, exponential, hinge and least-squares losses. By recourse to statistical minimax results, we show that our convergence rates are optimal up to constants. The effectiveness of our approach is also conﬁrmed in numerical simulations where we compare to several baselines on a least-squares regression problem.</p><p>5 0.62574798 <a title="161-lsi-5" href="./nips-2012-Mixability_in_Statistical_Learning.html">217 nips-2012-Mixability in Statistical Learning</a></p>
<p>Author: Tim V. Erven, Peter Grünwald, Mark D. Reid, Robert C. Williamson</p><p>Abstract: Statistical learning and sequential prediction are two different but related formalisms to study the quality of predictions. Mapping out their relations and transferring ideas is an active area of investigation. We provide another piece of the puzzle by showing that an important concept in sequential prediction, the mixability of a loss, has a natural counterpart in the statistical setting, which we call stochastic mixability. Just as ordinary mixability characterizes fast rates for the worst-case regret in sequential prediction, stochastic mixability characterizes fast rates in statistical learning. We show that, in the special case of log-loss, stochastic mixability reduces to a well-known (but usually unnamed) martingale condition, which is used in existing convergence theorems for minimum description length and Bayesian inference. In the case of 0/1-loss, it reduces to the margin condition of Mammen and Tsybakov, and in the case that the model under consideration contains all possible predictors, it is equivalent to ordinary mixability. 1</p><p>6 0.6025033 <a title="161-lsi-6" href="./nips-2012-Communication-Efficient_Algorithms_for_Statistical_Optimization.html">76 nips-2012-Communication-Efficient Algorithms for Statistical Optimization</a></p>
<p>7 0.56758827 <a title="161-lsi-7" href="./nips-2012-Query_Complexity_of_Derivative-Free_Optimization.html">285 nips-2012-Query Complexity of Derivative-Free Optimization</a></p>
<p>8 0.5545072 <a title="161-lsi-8" href="./nips-2012-Synchronization_can_Control_Regularization_in_Neural_Systems_via_Correlated_Noise_Processes.html">333 nips-2012-Synchronization can Control Regularization in Neural Systems via Correlated Noise Processes</a></p>
<p>9 0.53908509 <a title="161-lsi-9" href="./nips-2012-A_Stochastic_Gradient_Method_with_an_Exponential_Convergence__Rate_for_Finite_Training_Sets.html">20 nips-2012-A Stochastic Gradient Method with an Exponential Convergence  Rate for Finite Training Sets</a></p>
<p>10 0.53386253 <a title="161-lsi-10" href="./nips-2012-Efficient_Reinforcement_Learning_for_High_Dimensional_Linear_Quadratic_Systems.html">110 nips-2012-Efficient Reinforcement Learning for High Dimensional Linear Quadratic Systems</a></p>
<p>11 0.52712733 <a title="161-lsi-11" href="./nips-2012-Minimax_Multi-Task_Learning_and_a_Generalized_Loss-Compositional_Paradigm_for_MTL.html">212 nips-2012-Minimax Multi-Task Learning and a Generalized Loss-Compositional Paradigm for MTL</a></p>
<p>12 0.5210343 <a title="161-lsi-12" href="./nips-2012-Sparse_Prediction_with_the_%24k%24-Support_Norm.html">319 nips-2012-Sparse Prediction with the $k$-Support Norm</a></p>
<p>13 0.51725078 <a title="161-lsi-13" href="./nips-2012-No-Regret_Algorithms_for_Unconstrained_Online_Convex_Optimization.html">241 nips-2012-No-Regret Algorithms for Unconstrained Online Convex Optimization</a></p>
<p>14 0.5071367 <a title="161-lsi-14" href="./nips-2012-Link_Prediction_in_Graphs_with_Autoregressive_Features.html">199 nips-2012-Link Prediction in Graphs with Autoregressive Features</a></p>
<p>15 0.50460589 <a title="161-lsi-15" href="./nips-2012-Regularized_Off-Policy_TD-Learning.html">292 nips-2012-Regularized Off-Policy TD-Learning</a></p>
<p>16 0.50175947 <a title="161-lsi-16" href="./nips-2012-Dynamic_Pruning_of_Factor_Graphs_for_Maximum_Marginal_Prediction.html">105 nips-2012-Dynamic Pruning of Factor Graphs for Maximum Marginal Prediction</a></p>
<p>17 0.49507675 <a title="161-lsi-17" href="./nips-2012-Approximating_Equilibria_in_Sequential_Auctions_with_Incomplete_Information_and_Multi-Unit_Demand.html">45 nips-2012-Approximating Equilibria in Sequential Auctions with Incomplete Information and Multi-Unit Demand</a></p>
<p>18 0.49026293 <a title="161-lsi-18" href="./nips-2012-Learning_as_MAP_Inference_in_Discrete_Graphical_Models.html">186 nips-2012-Learning as MAP Inference in Discrete Graphical Models</a></p>
<p>19 0.48982295 <a title="161-lsi-19" href="./nips-2012-How_Prior_Probability_Influences_Decision_Making%3A_A_Unifying_Probabilistic_Model.html">153 nips-2012-How Prior Probability Influences Decision Making: A Unifying Probabilistic Model</a></p>
<p>20 0.48146364 <a title="161-lsi-20" href="./nips-2012-Rational_inference_of_relative_preferences.html">288 nips-2012-Rational inference of relative preferences</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.366), (11, 0.088), (47, 0.099), (60, 0.015), (67, 0.022), (70, 0.064), (85, 0.053), (94, 0.139), (99, 0.037)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.74365193 <a title="161-lda-1" href="./nips-2012-Interpreting_prediction_markets%3A_a_stochastic_approach.html">161 nips-2012-Interpreting prediction markets: a stochastic approach</a></p>
<p>Author: Nicolas D. Penna, Mark D. Reid, Rafael M. Frongillo</p><p>Abstract: We strengthen recent connections between prediction markets and learning by showing that a natural class of market makers can be understood as performing stochastic mirror descent when trader demands are sequentially drawn from a ﬁxed distribution. This provides new insights into how market prices (and price paths) may be interpreted as a summary of the market’s belief distribution by relating them to the optimization problem being solved. In particular, we show that under certain conditions the stationary point of the stochastic process of prices generated by the market is equal to the market’s Walrasian equilibrium of classic market analysis. Together, these results suggest how traditional market making mechanisms might be replaced with general purpose learning algorithms while still retaining guarantees about their behaviour. 1 Introduction and literature review This paper is part of an ongoing line of research, spanning several authors, into formal connections between markets and machine learning. In [5] an equivalence is shown between the theoretically popular prediction market makers based on sequences of proper scoring rules and follow the regularised leader, a form of no-regret online learning. By modelling the traders that demand the assets the market maker is oﬀering we are able to extend the equivalence to stochastic mirror decent. The dynamics of wealth transfer is studied in [3], for a sequence of markets between agents that behave as Kelly bettors (i.e. have log utilities), and an equivalence to stochastic gradient decent is analysed. More broadly, [9, 2] have analysed how a wide range of machine learning models can be implemented in terms of market equilibria. The literature on the interpretation of prediction market prices [7, 11] has had the goal of relating the equilibrium prices to the distribution of the beliefs of traders. More recent work [8] has looked at a stochastic model, and studied the behavior of simple agents sequentially interacting with the market. We continue this latter path of research, motivated by the observation that the equilibrium price may be a poor predictor of the behavior in a volitile prediction market. As such, we seek a more detailed understanding of the market than the equilibrium point – we would like to know what the “stationary distribution” of the price is, as time goes to inﬁnity. 1 As is standard in the literature, we assume a ﬁxed (product) distribution over traders’ beliefs and wealth. Our model features an automated market maker, following the framework of [1] is becoming a standard framework in the ﬁeld. We obtain two results. First, we prove that under certain conditions the stationary point of our stochastic process deﬁned by the market maker and a belief distribution of traders converges to the Walrasian equilibrium of the market as the market liquidity increases. This result, stated in Theorem 1, is general in the sense that only technical convergence conditions are placed on the demand functions of the traders – as such, we believe it is a generalisation of the stochastic result of [8] to cases where agents are are not limited to linear demands, and leave this precise connection to future work. Second, we show in Corollary 1 that when traders are Kelly bettors, the resulting stochastic market process is equivalent to stochastic mirror descent; see e.g. [6]. This result adds to the growing literature which relates prediction markets, and automated market makers in general, to online learning; see e.g. [1], [5], [3] . This connection to mirror descent seems to suggest that the prices in a prediction market at any given time may be meaningless, as the ﬁnal point in stochastic mirror descent often has poor convergence guarantees. However, standard results suggest that a prudent way to form a “consensus estimate” from a prediction market is to average the prices. The average price, assuming our market model is reasonable, is provably close to the stationary price. In Section 5 we give a natural example that exhibits this behavior. Beyond this, however, Theorem 2 gives us insight into the relationship between the market liquidity and the convergence of prices; in particular it suggests that we should increase liquidity at a rate √ of t if we wish the price to settle down at the right rate. 2 Model Our market model will follow the automated market maker framework of [1]. We will equip our market maker with a strictly convex function C : Rn → R which is twice continuously diﬀerentiable. For brevity we will write ϕ := C. The outcome space is Ω, and the contracts are determined by a payoﬀ function φ : Ω → Rn such that Π := ϕ(Rn ) = ConvHull(φ(Ω)). That is, the derivative space Π of C (the “instantaneous prices”) must be the convex hull of the payoﬀs. A trader purchasing shares at the current prices π ∈ Rn pays C(ϕ−1 (π) + r) − C(ϕ−1 (π)) for the bundle of contracts r ∈ Rn . Note that our dependence solely on π limits our model slightly, since in general the share space (domain of C) may contain more information than the current prices (cf. [1]). The bundle r is determined by an agent’s demand function d(C, π) which speciﬁes the bundle to buy given the price π and the cost function C. Our market dynamics are the following. The market maker posts the current price πt , and at each time t = 1 . . . T , a trader is chosen with demand function d drawn i.i.d. from some demand distribution D. Intuitively, these demands are parameterized by latent variables such as the agent’s belief p ∈ ∆Ω and total wealth W . The price is then updated to πt+1 = ϕ(ϕ−1 (πt ) + d(C, πt )). (1) After update T , the outcome is revealed and payout φ(ω)i is given for each contract i ∈ {1, . . . , n}. 3 Stationarity and equilibrium We ﬁrst would like to relate our stochastic model (1) to the standard notion of market equilibrium from the Economics literature, which we call the Walrasian equilibrium to avoid confusion. Here prices are ﬁxed, and the equilibrium price is one that clears the market, meaning that the sum of the demands r is 0 ∈ Rn . In fact, we will show that the stationary point of our process approaches the Walrasian equilibrium point as the liquidity of the market approaches inﬁnity. 2 First, we must add a liquidity parameter to our market. Following the LMSR (the cost function C(s) = b ln i esi /b ), we deﬁne Cb (s) := b C(s/b). (2) This transformation of a convex function is called a perspective function and is known to preserve convexity [4]. Observe that ϕb (s) := Cb (s) = C(s/b) = ϕ(s/b), meaning that the price under Cb at s is the same as the price under C at s/b. As with the LMSR, we call b the liquidity parameter ; this terminology is justiﬁed by noting that one deﬁnition of liquidity, 1/λmax 2 Cb (s) = b/λmax 2 C(s/b) (cf. [1]). In the following, we will consider the limit as b → ∞. Second, in order to connect to the Walrasian equilibrium, we need a notion of a ﬁxed-price demand function: if a trader has demand d(C, ·) given C, what would the same trader’s demand be under a market where prices are ﬁxed and do not “change” during a trade? For the sake of generality, we restrict our allowable demand functions to the ones for which the limit d(F, π) := lim d(Cb , π) (3) b→∞ exists; this demand d(F, ·) will be the corresponding ﬁxed-price demand for d. We now deﬁne the Walrasion equilibrium point π ∗ , which is simply the price at which the market clears when traders have demands distributed by D. Formally, this is the following condition:1 d(F, π ∗ ) dD(d) = 0 (4) D Note that 0 ∈ Rn ; the demand for each contract should be balanced. s The stationary point of our stochastic process, on the other hand, is the price πb for which the expected price ﬂuctuation is 0. Formally, we have s s E [∆(πb , d(Cb , πb ))] = 0, (5) d∼D where ∆(π, d) := ϕ(ϕ−1 (π) + d) − π is the price ﬂuctuation. We now consider the limit of our stochastic process as the market liquidity approaches ∞. Theorem 1. Let C be a strictly convex and α-smooth2 cost function, and assume that ∂ ∂b d(Cb , π) = o(1/b) uniformly in π and all d ∈ D. If furthermore the limit (3) is uniform s in π and d, then limb→∞ πb = π ∗ . s Proof. Note that by the stationarity condition (5) we may deﬁne π ∗ and πb to be the roots of the following “excess demand” functions, respectively: Z(π) := s Zb (π) := b E [∆(π, d(Cb , π))], d(F, π) dD(d), d∼D D where we scale the latter by b so that −1 Let s = ϕ s Zb does not limit to the zero function. (π) be the current share vector. Then we have lim b∆(π, d(Cb , π)) = lim b ϕ ϕ−1 (π) + d(Cb , π)/b − π b→∞ b→∞ ϕ s + a d(C1/a , π) − π a ∂ = lim ϕ s + a d(C1/a , π) d(C1/a , π) + a ∂a d(C1/a , π) = lim a→0 a→0 = lim ϕ s+ = lim 2 b→∞ b→∞ 1 b d(Cb , π) C(s) d(Cb , π) = d(Cb , π) + 2 2 1 ∂ b ∂b d(Cb , π)(−b ) C(s) d(F, π), 1 Here and throughout we ignore technical issues of uniqueness. One may simply restrict to the class of demands for which uniqueness is satisﬁed. 2 C is α-smooth if λmax 2 C ≤ α 3 where we apply L’Hopital’s rule for the third equality. Crucially, the above limit is uniform with respect to both d ∈ D and π ∈ Π; uniformity in d is by assumption, and uniformity in π follows from α-smoothness of C, since C is dominated by a quadratic. Since the limit is uniform with respect to D, we now have s lim Zb (π) = lim b E [∆(π, d(Cb , π))] = E b→∞ b→∞ = 2 d∼D d∼D C(s) E [d(F, π)] = 2 lim b∆(π, d(Cb , π)) b→∞ C(s) Z(π). d∼D s As 2 C(s) is positive deﬁnite by assumption on C, we can conclude that limb→∞ Zb and Z share the same zeroes. Since Z has compact domain and is assumed continuous with a unique zero π ∗ , for each ∈ (0, max ) there must be some δ > 0 s.t. |Z(π)| > for all π s.t. π − π ∗ > δ (otherwise there would be a sequence of πn → π s.t. f (π ) = 0 but π = π ∗ ). s By uniform convergence there must be a B > 0 s.t. for all b > B we have Zb − Z ∞ < /2. s s In particular, for π s.t. π − π ∗ > δ, |Zb (π)| > /2. Thus, the corresponding zeros πb must ∗ s ∗ 3 be within δ of π . Hence limb→∞ πb = π . 3.1 Utility-based demands Maximum Expected Utility (MEU) demand functions are a particular kind of demand function derived by assuming a trader has some belief p ∈ ∆n over the outcomes in Ω, some wealth W ≥ 0, and a monotonically increasing utility function of money u : R → R. If such a trader buys a bundle r of contracts from a market maker with cost function C and price π, her wealth after ω occurs is Υω (C, W, π, r) := W +φ(ω)·r−[C(ϕ−1 (π)+r)−C(ϕ−1 (π))]. We ensure traders do not go into debt by requiring that traders only make demands such that this ﬁnal wealth is nonnegative: ∀ω Υω (C, π, r) ≥ 0. The set of debt-free bundles for wealth W and market C at price π is denoted S(C, W, π) := {r ∈ Rn : minω Υω (C, W, π, r) ≥ 0}. A continuous MEU demand function du (C, π) is then just the demand that maximizes a W,p trader’s expected utility subject to the debt-free constraint. That is, du (C, π) := argmax W,p E [u (Υω (C, W, π, r))] . (6) r∈S(C,W,π) ω∼p We also deﬁne a ﬁxed-price MEU demand function du (F, π) similarly, where W,p Υω (F, W, π, r) := W + φ(ω) · r − π · r and S(F, W, π) := {r ∈ Rn : minω Υω (F, W, π, r) ≥ 0} are the ﬁxed price analogues to the continuously priced versions above. Using the notation bS := {b r | r ∈ S}, the following relationships between the continuous and ﬁxed price versions of Υ, SW , and the expected utility are a consequence of the convexity of C. Their main purpose is to highlight the relationship between wealth and liquidity in MEU demands. In particular, they show that scaling up of liquidity is equivalent to a scaling down of wealth and that the continuously priced constraints and wealth functions monotonically approach the ﬁxed priced versions. Lemma 1. For any strictly convex cost function C, wealth W > 0, price π, demand r, and liquidity parameter b > 0 the following properties hold: 1. Υω (Cb , W, π, r) = b Υω (C, W/b, π, r/b); 2. S(Cb , W, π) = b S(C, W/b, π); 3. S(C, W, π) is convex for all C; 4. S(C, W, π) ⊆ S(Cb , W, π) ⊆ S(F, W, π) for all b ≥ 1. 5. For monotone utilities u, Eω∼p [u (Υω (F, W, π, r))] ≥ Eω∼p [u (Υω (C, W, π, r))]. Proof. Property (1) follows from a simple computation: Υω (Cb , W, π, r) = W + φ(ω) · r − b C(ϕ−1 (π) + r/b) + b C(ϕ−1 (π)) = b W/b + φ(ω) · (r/b) − C(ϕ−1 (π) + r/b) + C(ϕ−1 (π)) , which equals b Υω (C, W/b, π, r/b) by deﬁnition. We now can see property (2) as well: S(Cb , W, π) = {r : min b Υω (C, W/b, π, r/b) ≥ 0} = {b r : min Υω (C, W/b, π, r) ≥ 0}. ω 3 ω We thank Avraham Ruderman for a helpful discussion regarding this proof. 4 For (3), deﬁne fC,s,ω (r) = C(s + r) − C(s) − φ(ω) · r, which is the ex-post cost of purchasing bundle r. As C is convex, and fC,s,ω is a shifted and translated version of C plus a linear term, fC,s,ω is convex also. The constraint Υω (C, W, π, r) ≥ 0 then translates to fC,s,ω (r) ≤ W , and thus the set of r which satisfy the constraint is convex as a sublevel set of a convex function. Now S(C, W, π) is convex as an intersection of convex sets, proving (3). For (4) suppose r satisﬁes fC,s,ω (r) ≤ W . Note that fC,s,ω (0) = 0 always. Then by convexity we have for f := fC,s,ω we have f (r/b) = f 1 r + b−1 0 ≤ 1 f (r) + b−1 0 ≤ W/b, b b b b which implies S(C, W, π) ⊆ S(Cb , W, π) when considering (3). To complete (4) note that fC,s,ω dominates fF,s : r → (ϕ(s) − φ(ω)) · r by convexity of C: C(s + r) − C(s) ≥ C(s) · r. Finally, proof of (5) is obtained by noting that the convexity of C means that C(ϕ−1 (π) + r) − C(ϕ−1 (π)) ≥ C(ϕ−1 (π)) · r = π · r and exploting the monotonicty of u. Lemma 1 shows us that MEU demands have a lot of structure, and in particular, properties (4) and (5) suggest that they may satisfy the conditions of Theorem 1; we leave this as an open question for future work. Another interesting aspect of Lemma 1 is the relationship between markets with cost function Cb and wealths W and markets with cost function C and wealths W/b – indeed, properties (1) and (2) suggest that the liquidity limit should in some sense be equivalent to a wealth limit, in that increasing liquidity by a factor b should yield similar dynamics to decreasing the wealths by b. This would relate our model to that of [8], where the authors essentially show a wealth-limit version of Theorem 1 for a binary-outcome market where traders have linear utilities (a special case of (6)). We leave this precise connection for future work. 4 Market making as mirror descent We now explore the surprising relationship between our stochastic price update and standard stochastic optimization techniques. In particular, we will relate our model to a stochastic mirror descent of the form xt+1 = argmin{η x · F (xt ; ξ) + DR (x, xt )}, (7) x∈R where at each step ξ ∼ Ξ are i.i.d. and R is some strictly convex function. We will refer to an algorithm of the form (7) a stochastic mirror descent of f (x) := Eξ∼Ξ [F (x; ξ)]. Theorem 2. If for all d ∈ D we have some F (· ; d) : Rn → Rn such that d(R∗ , π) = − F (π; d), then the stochastic update of our model (1) is exactly a stochastic mirror descent of f (π) = Ed∼D [F (π; d)]. Proof. By standard arguments, the mirror descent update (7) can be rewritten as xt+1 = R∗ ( R(xt ) − F (xt ; ξ)), where R∗ is the conjugate dual of R. Take R = C ∗ , and let ξ = d ∼ D. By assumption, we have F (x; d) = −d(R∗ , x) = −d(C, x) for all d. As R∗ = C = ϕ, we have ϕ−1 = ( R∗ )−1 = R by duality, and thus our update becomes xt+1 = ϕ ϕ−1 (xt ) + d(C, xt ) , which exactly matches the stochastic update of our model (1). As an example, consider Kelly betters, which correspond to ﬁxed-price demands d(C, π) := dlog (F, π) with utility u(x) = log x as deﬁned in (3). A simple calculation shows that our W,p update becomes W p−π πt+1 = ϕ ϕ−1 (πt ) + , (8) π 1−π where W and p are drawn (independently) from P and W. Corollary 1. The stochastic update for ﬁxed-price Kelly betters (8) is exactly a stochastic mirror descent of f (π) = W · KL(p, π), where p and W are the means of P and W, respectively. 5 Proof. We take F (x; dlog ) = W · (KL(p, x) + H(p)). Then W,p F (x; dlog ) = W W,p −p p − 1 + x 1−x =− W p−x = −dlog (F, x). W,p x 1−x Hence, by Theorem 2 our update is a stochastic mirror descent of: f (x) := E[F (x; dlog )] = E[W p log x + W (1 − p) log(1 − x)] = W · (KL(p, x) + H(p)) , W,p which of course is equivalent to W · KL(p, x) as the entropy term does not depend on x. Note that while this last result is quite compelling, we have mixed ﬁxed-price demands with a continuous-price market model – see Section 3.1. One could interpret this combination as a model in which the market maker can only adjust the prices after a trade, according to a ﬁxed convex cost function C. This of course diﬀers from the standard model, which adjusts the price continuously during a trade. 4.1 Leveraging existing learning results Theorem 2 not only identiﬁes a fascinating connection between machine learning and our stochastic prediction market model, but it also allows us to use powerful existing techniques to make broad conclusions about the behavior of our model. Consider the following result: ≤ G2 for all p, π, and R is σ-strongly convex, then log 1 δ . Price Avg price Avg belief 0.70 In our context, Proposition 1 says that the average of the prices will be a very good estimate of the minimizer of f , which as suggested by happens to be the underlying mean belief p of the traders! Moreover, as the Kelly demands are linear in both p and W , it is easy to see from Theorem 1 that p is also the stationary point and the Walrasian equilibrium point (the latter was also shown by [11]). On the other hand, as we demonstrate next, it is not hard to come up with an example where the instantaneous price πt is quite far from the equilibrium at any given time period. 1+4 0.65 π D2 G2 η + ηT 2σ 0.60 f (π T ) ≤ min f (π) + Price of contract 1 2 0.55 F (π; p) 0.50 Proposition 1 ([6]). If with probability 1 − δ, 0 500 1000 1500 2000 Trade number Before moving to our empirical work, we make one Figure 1: Price movement for Kelly ﬁnal point. The above relationship between our betters with binomial(q = 0.6, n = 6, stochastic market model and mirror descent sheds α = 0.5) beliefs in the LMSR market light on an important question: how might an auto- with liquidity b = 10. mated market maker adjust the liquidity so that the market actually converges to the mean of the traders’ beliefs? The learning parameter η can be thought of as the inverse of the liquidity, and as such, Proposition 1 suggests that √ increasing the liquidity as t may cause the mean price to converge to the mean belief (assuming a ﬁxed underlying belief distribution). 5 Empirical work Example: biased coin Consider a classic Bayesian setting where a coin has unknown bias Pr[heads] = q, and traders have a prior β(α, α) over q (i.e., traders are α-conﬁdent that the coin is fair). Now suppose each trader independently observes n ﬂips from the coin, and updates her belief; upon seeing k heads, a trader would have posterior β(α + k, α + n − k). When presented with a prediction market with contracts for a single toss of the coin, where and contract 0 pays $1 for tails and contract 1 pays $1 for heads, a trader would purchase 6 0 20 40 60 Trades 80 100 b = 10 Instant Averaged 0.06 Loss 0.04 0.02 0.00 0.02 0.04 Loss 0.06 0.08 Instant Averaged 0.00 0.00 0.02 0.04 Loss 0.06 0.08 Instant Averaged Square loss of price to mean belief for State 9 b=3 0.08 b=1 0.10 Square loss of price to mean belief for State 9 0.10 0.10 Square loss of price to mean belief for State 9 0 20 40 60 Trades 80 100 0 20 40 60 80 100 Trades Figure 2: Mean square loss of average and instantaneous prices relative to the mean belief of 0.26 over 20 simulations for State 9 for b = 1 (left), b = 3 (middle), and b = 10 (right). Bars show standard deviation. contracts as if according to the mean of their posterior. Hence, the belief distribution P of the market assigns weight P(p) = n q k (1 − q)n−k to belief p = (α + k)/(2α + n), yielding k a biased mean belief of (α + nq)/(2α + n). We show a typical simulation of this market in Figure 1, where traders behave as Kelly betters in the ﬁxed-price LMSR. Clearly, after almost every trade, the market price is quite far from the equilibrium/stationary point, and hence the classical supply and demand analysis of this market yields a poor description of the actual behavior, and in particular, of the predictive quality of the price at any given time. However, the mean price is consistently close to the mean belief of the traders, which in turn is quite close to the true parameter q. Election Survey Data We now compare the quality of the running average price versus the instantaneous price as a predictor of the mean belief of a market. We do so by simulating a market maker interacting with traders with unit wealth, log utility, and beliefs drawn from a ﬁxed distribution. The belief distributions are derived from the Princeton election survey data[10]. For each of the 50 US states, participants in the survey were asked to estimate the probability that one of two possible candidates were going to win that state.4 We use these 50 sets of estimates as 50 diﬀerent empirical distributions from which to draw trader beliefs. A simulation is conﬁgured by choosing one of the 50 empirical belief distributions S, a market liquidity parameter b to deﬁne the LMSR cost function C(s) = b ln i esi /b , and an initial market position vector of (0, 0) – that is, no contracts for either outcome. A conﬁgured simulation is run for T trades. At each trade, a belief p is drawn from S uniformly and with replacement. This belief is used to determine the demand of the trader relative to the current market pricing. The trader purchase a bundle of contracts according to its demand and the market moves its position and price accordingly. The complete price path πt for t t = 1, . . . , T of the market is recorded as well as a running average price πt := 1 i=1 πt for ¯ t t = 1 . . . , T . For each of the 50 empirical belief distributions we conﬁgured 9 markets with b ∈ {1, 2, 3, 5, 10, 15, 20, 30, 50} and ran 20 independent simulations of T = 100 trades. We present a portion of the results for the empirical distributions for states 9 and 11. States 9 and 11 have, respectively, sample sizes of 2,717 and 2,709; means 0.26 and 0.9; and variances 0.04 and 0.02. These are chosen as being representative of the rest of the simulation results: State 9 with mean oﬀ-center and a spread of beliefs (high uncertainty) and State 11 with highly concentrated beliefs around a single outcome (low uncertainty). The results are summarised in Figures 2, 3, and 4. The ﬁrst show the square loss of the average and instaneous prices relative to the mean belief for high uncertainty State 9 for b = 1, 3, 10. Clearly, the average price is a much more reliable estimator of the mean belief for low liquidity (b = 1) and is only outperformed by the instaneous price for higher liquidity (b = 10), but then only early in trading. Similar plots for State 11 are shown in Figure 3 where the advantage of using the average price is signiﬁcantly diminished. 4 The original dataset contains conjunctions of wins as well as conditional statements but we only use the single variable results of the survey. 7 0 20 40 60 80 100 b = 10 Instant Averaged 0.06 Loss 0.04 0.02 0.00 0.02 0.04 Loss 0.06 0.08 Instant Averaged 0.00 0.00 0.02 0.04 Loss 0.06 0.08 Instant Averaged Square loss of price to mean belief for State 11 b=3 0.08 b=1 0.10 Square loss of price to mean belief for State 11 0.10 0.10 Square loss of price to mean belief for State 11 0 20 40 Trades 60 80 100 0 20 40 Trades 60 80 100 Trades Figure 3: Mean square loss of average and instantaneous prices relative to the mean belief of 0.9 over 20 simulations for State 11 for b = 1 (left), b = 3 (middle), and b = 10 (right). Bars show standard deviation. Figure 4 shows the improvement the average price has over the instantaneous price in square loss relative to the mean belief for all liquidity settings and highlights that average prices work better in low liquidity settings, consistent with the theory. Similar trends were observed for all the other States, depending on whether they had high uncertainty – in which case average price was a much better estimator – or low uncertainty – in which case instanteous price was better. Improvement of Average over Instant Prices for State 9 Improvement of Average over Instant Prices for State 11 0.06 0.02 0.00 0.04 Loss Di fference fference -0.04 0.00 -0.06 -0.02 -0.08 10 20 100 80 80 30 40 40 30 60 Tra des b 60 Tra des 10 20 100 20 b Loss Di -0.02 0.02 40 40 20 50 50 Figure 4: An overview of the results for States 9 (left) and 11 (right). For each trade and choice of b, the vertical value shows the improvement of the average price over the instantaneous price as measure by square loss relative to the mean. 6 Conclusion and future work As noted in Section 3.1, there are several open questions with regard to maximum expected utility demands and Theorem 1, as well as the relationship between trader wealth and market liquidity. It would also be interesting to have a application of Theorem 2 to a continuousprice model, which yields a natural minimization as in Corollary 1. The equivalence to mirror decent stablished in Theorem 2 may also lead to a better understanding of the optimal manner in which a automated prediction market ought to increase liquidity so as to maximise eﬃciency. Acknowledgments This work was supported by the Australian Research Council (ARC). NICTA is funded by the Australian Government as represented by the Department of Broadband, Communications and the Digital Economy and the ARC through the ICT Centre of Excellence program. The ﬁrst author was partially supported by NSF grant CC-0964033 and by a Google University Research Award. 8 References [1] J. Abernethy, Y. Chen, and J.W. Vaughan. An optimization-based framework for automated market-making. In Proceedings of the 11th ACM conference on Electronic Commerce (EC’11), 2011. [2] A. Barbu and N. Lay. An introduction to artiﬁcial prediction markets for classiﬁcation. Arxiv preprint arXiv:1102.1465, 2011. [3] A. Beygelzimer, J. Langford, and D. Pennock. Learning Performance of Prediction Markets with Kelly Bettors. 2012. [4] S. Boyd and L. Vandenberghe. Convex optimization. Cambridge University Press, 2004. [5] Y. Chen and J.W. Vaughan. A new understanding of prediction markets via no-regret learning, pages 189–198. 2010. [6] J. Duchi, S. Shalev-Shwartz, Y. Singer, and A. Tewari. Composite objective mirror descent. COLT, 2010. [7] C.F. Manski. Interpreting the predictions of prediction markets. Technical report, National Bureau of Economic Research, 2004. [8] A. Othman and T. Sandholm. When do markets with simple agents fail? In Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems: volume 1-Volume 1, pages 865–872. International Foundation for Autonomous Agents and Multiagent Systems, 2010. [9] A. Storkey. Machine learning markets. AISTATS, 2012. [10] G. Wang, S.R. Kulkarni, H.V. Poor, and D.N. Osherson. Aggregating large sets of probabilistic forecasts by weighted coherent adjustment. Decision Analysis, 8(2):128, 2011. [11] J. Wolfers and E. Zitzewitz. Interpreting prediction market prices as probabilities. Technical report, National Bureau of Economic Research, 2006. 9</p><p>2 0.68276972 <a title="161-lda-2" href="./nips-2012-Bayesian_Nonparametric_Modeling_of_Suicide_Attempts.html">52 nips-2012-Bayesian Nonparametric Modeling of Suicide Attempts</a></p>
<p>Author: Francisco Ruiz, Isabel Valera, Carlos Blanco, Fernando Pérez-Cruz</p><p>Abstract: The National Epidemiologic Survey on Alcohol and Related Conditions (NESARC) database contains a large amount of information, regarding the way of life, medical conditions, etc., of a representative sample of the U.S. population. In this paper, we are interested in seeking the hidden causes behind the suicide attempts, for which we propose to model the subjects using a nonparametric latent model based on the Indian Buffet Process (IBP). Due to the nature of the data, we need to adapt the observation model for discrete random variables. We propose a generative model in which the observations are drawn from a multinomial-logit distribution given the IBP matrix. The implementation of an efﬁcient Gibbs sampler is accomplished using the Laplace approximation, which allows integrating out the weighting factors of the multinomial-logit likelihood model. Finally, the experiments over the NESARC database show that our model properly captures some of the hidden causes that model suicide attempts. 1</p><p>3 0.49928838 <a title="161-lda-3" href="./nips-2012-Link_Prediction_in_Graphs_with_Autoregressive_Features.html">199 nips-2012-Link Prediction in Graphs with Autoregressive Features</a></p>
<p>Author: Emile Richard, Stephane Gaiffas, Nicolas Vayatis</p><p>Abstract: In the paper, we consider the problem of link prediction in time-evolving graphs. We assume that certain graph features, such as the node degree, follow a vector autoregressive (VAR) model and we propose to use this information to improve the accuracy of prediction. Our strategy involves a joint optimization procedure over the space of adjacency matrices and VAR matrices which takes into account both sparsity and low rank properties of the matrices. Oracle inequalities are derived and illustrate the trade-offs in the choice of smoothing parameters when modeling the joint effect of sparsity and low rank property. The estimate is computed efﬁciently using proximal methods through a generalized forward-backward agorithm. 1</p><p>4 0.49821389 <a title="161-lda-4" href="./nips-2012-Semi-Crowdsourced_Clustering%3A_Generalizing_Crowd_Labeling_by_Robust_Distance_Metric_Learning.html">307 nips-2012-Semi-Crowdsourced Clustering: Generalizing Crowd Labeling by Robust Distance Metric Learning</a></p>
<p>Author: Jinfeng Yi, Rong Jin, Shaili Jain, Tianbao Yang, Anil K. Jain</p><p>Abstract: One of the main challenges in data clustering is to deﬁne an appropriate similarity measure between two objects. Crowdclustering addresses this challenge by deﬁning the pairwise similarity based on the manual annotations obtained through crowdsourcing. Despite its encouraging results, a key limitation of crowdclustering is that it can only cluster objects when their manual annotations are available. To address this limitation, we propose a new approach for clustering, called semi-crowdsourced clustering that effectively combines the low-level features of objects with the manual annotations of a subset of the objects obtained via crowdsourcing. The key idea is to learn an appropriate similarity measure, based on the low-level features of objects and from the manual annotations of only a small portion of the data to be clustered. One difﬁculty in learning the pairwise similarity measure is that there is a signiﬁcant amount of noise and inter-worker variations in the manual annotations obtained via crowdsourcing. We address this difﬁculty by developing a metric learning algorithm based on the matrix completion method. Our empirical study with two real-world image data sets shows that the proposed algorithm outperforms state-of-the-art distance metric learning algorithms in both clustering accuracy and computational efﬁciency. 1</p><p>5 0.49725536 <a title="161-lda-5" href="./nips-2012-A_Polynomial-time_Form_of_Robust_Regression.html">16 nips-2012-A Polynomial-time Form of Robust Regression</a></p>
<p>Author: Ozlem Aslan, Dale Schuurmans, Yao-liang Yu</p><p>Abstract: Despite the variety of robust regression methods that have been developed, current regression formulations are either NP-hard, or allow unbounded response to even a single leverage point. We present a general formulation for robust regression—Variational M-estimation—that uniﬁes a number of robust regression methods while allowing a tractable approximation strategy. We develop an estimator that requires only polynomial-time, while achieving certain robustness and consistency guarantees. An experimental evaluation demonstrates the effectiveness of the new estimation approach compared to standard methods. 1</p><p>6 0.49677885 <a title="161-lda-6" href="./nips-2012-Efficient_Sampling_for_Bipartite_Matching_Problems.html">111 nips-2012-Efficient Sampling for Bipartite Matching Problems</a></p>
<p>7 0.49573332 <a title="161-lda-7" href="./nips-2012-A_Scalable_CUR_Matrix_Decomposition_Algorithm%3A_Lower_Time_Complexity_and_Tighter_Bound.html">17 nips-2012-A Scalable CUR Matrix Decomposition Algorithm: Lower Time Complexity and Tighter Bound</a></p>
<p>8 0.49559245 <a title="161-lda-8" href="./nips-2012-Small-Variance_Asymptotics_for_Exponential_Family_Dirichlet_Process_Mixture_Models.html">316 nips-2012-Small-Variance Asymptotics for Exponential Family Dirichlet Process Mixture Models</a></p>
<p>9 0.495276 <a title="161-lda-9" href="./nips-2012-Probabilistic_n-Choose-k_Models_for_Classification_and_Ranking.html">278 nips-2012-Probabilistic n-Choose-k Models for Classification and Ranking</a></p>
<p>10 0.49511114 <a title="161-lda-10" href="./nips-2012-Rational_inference_of_relative_preferences.html">288 nips-2012-Rational inference of relative preferences</a></p>
<p>11 0.49508443 <a title="161-lda-11" href="./nips-2012-Practical_Bayesian_Optimization_of_Machine_Learning_Algorithms.html">272 nips-2012-Practical Bayesian Optimization of Machine Learning Algorithms</a></p>
<p>12 0.49501827 <a title="161-lda-12" href="./nips-2012-Fast_Bayesian_Inference_for_Non-Conjugate_Gaussian_Process_Regression.html">127 nips-2012-Fast Bayesian Inference for Non-Conjugate Gaussian Process Regression</a></p>
<p>13 0.49470723 <a title="161-lda-13" href="./nips-2012-The_Coloured_Noise_Expansion_and_Parameter_Estimation_of_Diffusion_Processes.html">336 nips-2012-The Coloured Noise Expansion and Parameter Estimation of Diffusion Processes</a></p>
<p>14 0.49449211 <a title="161-lda-14" href="./nips-2012-Majorization_for_CRFs_and_Latent_Likelihoods.html">206 nips-2012-Majorization for CRFs and Latent Likelihoods</a></p>
<p>15 0.49439296 <a title="161-lda-15" href="./nips-2012-Fast_Variational_Inference_in_the_Conjugate_Exponential_Family.html">129 nips-2012-Fast Variational Inference in the Conjugate Exponential Family</a></p>
<p>16 0.49438015 <a title="161-lda-16" href="./nips-2012-Communication-Efficient_Algorithms_for_Statistical_Optimization.html">76 nips-2012-Communication-Efficient Algorithms for Statistical Optimization</a></p>
<p>17 0.4942407 <a title="161-lda-17" href="./nips-2012-Efficient_Bayes-Adaptive_Reinforcement_Learning_using_Sample-Based_Search.html">108 nips-2012-Efficient Bayes-Adaptive Reinforcement Learning using Sample-Based Search</a></p>
<p>18 0.49420291 <a title="161-lda-18" href="./nips-2012-Density_Propagation_and_Improved_Bounds_on_the_Partition_Function.html">96 nips-2012-Density Propagation and Improved Bounds on the Partition Function</a></p>
<p>19 0.49310595 <a title="161-lda-19" href="./nips-2012-Active_Learning_of_Multi-Index_Function_Models.html">34 nips-2012-Active Learning of Multi-Index Function Models</a></p>
<p>20 0.49252194 <a title="161-lda-20" href="./nips-2012-On_Multilabel_Classification_and_Ranking_with_Partial_Feedback.html">252 nips-2012-On Multilabel Classification and Ranking with Partial Feedback</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
