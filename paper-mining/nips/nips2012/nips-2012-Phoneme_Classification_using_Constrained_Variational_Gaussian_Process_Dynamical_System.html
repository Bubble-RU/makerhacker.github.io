<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>270 nips-2012-Phoneme Classification using Constrained Variational Gaussian Process Dynamical System</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-270" href="#">nips2012-270</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>270 nips-2012-Phoneme Classification using Constrained Variational Gaussian Process Dynamical System</h1>
<br/><p>Source: <a title="nips-2012-270-pdf" href="http://papers.nips.cc/paper/4587-phoneme-classification-using-constrained-variational-gaussian-process-dynamical-system.pdf">pdf</a></p><p>Author: Hyunsin Park, Sungrack Yun, Sanghyuk Park, Jongmin Kim, Chang D. Yoo</p><p>Abstract: For phoneme classiﬁcation, this paper describes an acoustic model based on the variational Gaussian process dynamical system (VGPDS). The nonlinear and nonparametric acoustic model is adopted to overcome the limitations of classical hidden Markov models (HMMs) in modeling speech. The Gaussian process prior on the dynamics and emission functions respectively enable the complex dynamic structure and long-range dependency of speech to be better represented than that by an HMM. In addition, a variance constraint in the VGPDS is introduced to eliminate the sparse approximation error in the kernel matrix. The effectiveness of the proposed model is demonstrated with three experimental results, including parameter estimation and classiﬁcation performance, on the synthetic and benchmark datasets. 1</p><p>Reference: <a title="nips-2012-270-reference" href="../nips2012_reference/nips-2012-Phoneme_Classification_using_Constrained_Variational_Gaussian_Process_Dynamical_System_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 kr  Abstract For phoneme classiﬁcation, this paper describes an acoustic model based on the variational Gaussian process dynamical system (VGPDS). [sent-12, score-0.807]
</p><p>2 The nonlinear and nonparametric acoustic model is adopted to overcome the limitations of classical hidden Markov models (HMMs) in modeling speech. [sent-13, score-0.415]
</p><p>3 The Gaussian process prior on the dynamics and emission functions respectively enable the complex dynamic structure and long-range dependency of speech to be better represented than that by an HMM. [sent-14, score-0.608]
</p><p>4 In addition, a variance constraint in the VGPDS is introduced to eliminate the sparse approximation error in the kernel matrix. [sent-15, score-0.203]
</p><p>5 The effectiveness of the proposed model is demonstrated with three experimental results, including parameter estimation and classiﬁcation performance, on the synthetic and benchmark datasets. [sent-16, score-0.127]
</p><p>6 1  Introduction  Automatic speech recognition (ASR), the process of automatically translating spoken words into text, has been an important research topic for several decades owing to its wide array of potential applications in the area of human-computer interaction (HCI). [sent-17, score-0.336]
</p><p>7 The state-of-the-art ASR systems typically use hidden Markov models (HMMs) [1] to model the sequential articulator structure of speech signals. [sent-18, score-0.24]
</p><p>8 1) An HMM with a ﬁrst-order Markovian structure is suitable for capturing short-range dependency in observations and speech requires a more ﬂexible model that can capture long-range dependency in speech. [sent-20, score-0.486]
</p><p>9 For example, the stochastic segment model [2] is a well-known generalization of the HMM that represents long-range dependency over observations using a time-dependent emission function. [sent-24, score-0.452]
</p><p>10 And the hidden dynamical model [3] is used for modeling the complex nonlinear dynamics of a physiological articulator. [sent-25, score-0.311]
</p><p>11 Another promising research direction is to consider a nonparametric Bayesian model for nonlinear probabilistic modeling of speech. [sent-26, score-0.125]
</p><p>12 Owing to the fact that nonparametric models do not assume any 1  ﬁxed model structure, they are generally more ﬂexible than parametric models and can allow dependency among observations naturally. [sent-27, score-0.222]
</p><p>13 The Gaussian process (GP) [4], a stochastic process over a real-valued function, has been a key ingredient in solving such problems as nonlinear regression and classiﬁcation. [sent-28, score-0.114]
</p><p>14 As a standard supervised learning task using the GP, Gaussian process regression (GPR) offers a nonparametric Bayesian framework to infer the nonlinear latent function relating the input and the output data. [sent-29, score-0.211]
</p><p>15 Recently, researchers have begun focusing on applying the GP to unsupervised learning tasks with high-dimensional data, such as the Gaussian process latent variable model (GP-LVM) for reduction of dimensionality [5-6]. [sent-30, score-0.131]
</p><p>16 The variational approach is one of the sparse approximation approaches [8]. [sent-32, score-0.098]
</p><p>17 The framework was extended to the variational Gaussian process dynamical system (VGPDS) in [9] by augmenting latent dynamics for modeling high-dimensional time series data. [sent-33, score-0.371]
</p><p>18 However, no previous work has considered the GP-based approach for speech recognition tasks that involve high-dimensional time series data. [sent-35, score-0.222]
</p><p>19 In this paper, we propose a GP-based acoustic model for phoneme classiﬁcation. [sent-36, score-0.628]
</p><p>20 The proposed model is based on the assumption that the continuous dynamics and nonlinearity of the VGPDS can be better represent the statistical characteristic of real speech than an HMM. [sent-37, score-0.304]
</p><p>21 The GP prior over the emission function allows the model to represent long-range dependency over the observations of speech, while the HMM does not. [sent-38, score-0.354]
</p><p>22 Furthermore, the GP prior over the dynamics function enables the model to capture the nonlinear dynamics of a physiological articulator. [sent-39, score-0.262]
</p><p>23 1  Acoustic modeling using Gaussian Processes Variational Gaussian Process Dynamical System  The VGPDS [9] models time series data by assuming that there exist latent states that govern the data. [sent-44, score-0.104]
</p><p>24 Although the Gaussian process dynamical model (GPDM) [10], which involves an auto-regressive dynamics function, is also a GP-based model for time-series, it is not considered in this paper. [sent-51, score-0.228]
</p><p>25 2  (2)  Figure 1: Graphical representations of (left) the left-to-right HMM and (right) the VGPDS: In the left ﬁgure, yn ∈ RD and xn ∈ {1, · · · , C} are observations and discrete latent states. [sent-53, score-0.162]
</p><p>26 In the right ﬁgure, yni , fni , xnj , gnj , and tn are observations, emission function points, latent states, dynamics function points, and times, respectively. [sent-54, score-0.464]
</p><p>27 (2) is not tractable, a variational method is used by introducing a variational distribution q(X). [sent-57, score-0.158]
</p><p>28 (4)  i=1  In [9], a variational approach which involves sparse approximation of the covariance matrix obtained from GP is proposed. [sent-61, score-0.125]
</p><p>29 Here, Ki ∈ RM ×M is a kernel matrix calcu1i ˜ lated using the i-th kernel function and inducing input variables X ∈ RM ×Q that are used for sparse approximation of the full kernel matrix Ki . [sent-63, score-0.423]
</p><p>30 The closed-form of the statistics {ψ0i , Ψ1i , Ψ2i }D , i=1 which are functions of variational parameters and inducing points, can be found in [9]. [sent-64, score-0.195]
</p><p>31 (3), p(X|t) = j=1 p(xj ) and q(X) = n j=1 N (µnj , snj ) are the prior for the latent state and the variational distribution that is used for approximating the posterior of the latent state, respectively. [sent-66, score-0.229]
</p><p>32 2  Acoustic modeling using VGPDS  For several decades, HMM has been the predominant model for acoustic speech modeling. [sent-70, score-0.408]
</p><p>33 However, as we mentioned in Section 1, the model suffers from two major limitations: discrete state variables and ﬁrst-order Markovian structure which can model short-range dependency over the observations. [sent-71, score-0.142]
</p><p>34 3  To overcome such limitations of the HMM, we propose an acoustic speech model based on the VGPDS, which is a nonlinear and nonparametric model that can be used to represent the complex dynamic structure of speech and long-range dependency over observations of speech. [sent-72, score-0.936]
</p><p>35 In addition, to ﬁt the model to large-scale speech data, we describe various implementation issues. [sent-73, score-0.216]
</p><p>36 1  Time scale modiﬁcation  The time length of each phoneme segment in an utterance varies with various conditions such as position of the phoneme segment in the utterance, emotion, gender, and other speaker and environment conditions. [sent-76, score-1.12]
</p><p>37 To incorporate this fact into the proposed acoustic model, the time points tn are modiﬁed as follows: n−1 tn = , (6) N −1 where n and N are the observation index and the number of observations in a phoneme segment, respectively. [sent-77, score-0.842]
</p><p>38 This time scale modiﬁcation makes all phoneme signals have unit time length. [sent-78, score-0.445]
</p><p>39 We use the radial basis function (RBF) kernel for the emission function f as follows:   Q  f  f ωj (xj − xj )2  ,  f  k (x, x ) = α exp −  (7)  j=1 f where αf and ωj are the RBF kernel variance and the j-th inverse length scale, respectively. [sent-83, score-0.406]
</p><p>40 The RBF kernel function is adopted for representing smoothness of speech. [sent-84, score-0.114]
</p><p>41 For the dynamics function g, the following kernel function is used:  k g (t, t ) = αg exp −ω g (t − t )2 + λtt + b,  (8)  where λ and b are linear kernel variance and bias, respectively. [sent-85, score-0.328]
</p><p>42 The above dynamics kernel, which consists of both linear and nonlinear components, is used for representing the complex dynamics of the articulator. [sent-86, score-0.238]
</p><p>43 However, this extensive sharing of the hyperparameters is unsuitable for speech modeling. [sent-89, score-0.295]
</p><p>44 To handle this problem, this paper considers each dimension to be modeled independently using different kernel function parameters. [sent-91, score-0.118]
</p><p>45 3  Priors on the hyperparameters  In the parameter estimation of the VGPDS, the SCG algorithm does not guarantee the optimal solution. [sent-95, score-0.103]
</p><p>46 To overcome this problem, we place the following prior on the hyperparameters of the kernel functions as given below p(γ) ∝ exp(−γ 2 /¯ ), γ f  (9)  g  where γ ∈ {θ , θ } and γ are the hyper-parameter and the model parameter of the prior, respec¯ tively. [sent-96, score-0.214]
</p><p>47 In this paper, γ is set to the sample variance for the hyperparameters of the emission kernel ¯ functions, and γ is set to 1 for the hyperparameters of the dynamics kernel functions. [sent-97, score-0.648]
</p><p>48 (5), the second term on the right-hand side is the regularization term that represents the sparse approximation error of the full kernel matrix Ki . [sent-102, score-0.107]
</p><p>49 Note that with more inducing 4  input points, approximation error becomes smaller. [sent-103, score-0.14]
</p><p>50 However, only a small number of inducing input points can be used owing to the limited availability of computational power, which increases the effect of the regularization term. [sent-104, score-0.243]
</p><p>51 This constraint is designed so that the variance of each observation calculated from the estimated model is equal to the sample variance. [sent-106, score-0.145]
</p><p>52 1, the effectiveness of the variance constraint is demonstrated empirically. [sent-110, score-0.128]
</p><p>53 Parameter estimation: validating the effectiveness of the proposed variance constraint (Section 2. [sent-116, score-0.128]
</p><p>54 Two-class classiﬁcation using synthetic data: demonstrating explicitly the advantages of the proposed model over the HMM with respect to the degree of dependency over the observations 3. [sent-119, score-0.258]
</p><p>55 Phoneme classiﬁcation: evaluating the performance of the proposed model on real speech data Each experiment is described in detail in the following subsections. [sent-120, score-0.216]
</p><p>56 1  Parameter estimation  In this subsection, the experiments of parameter estimation on synthetic data are described. [sent-123, score-0.101]
</p><p>57 Synthetic data are generated by using a phoneme model that is selected from the trained models in Section 3. [sent-124, score-0.465]
</p><p>58 The RBF kernel variances of the emission functions and the emission noise variances are modiﬁed from the selected model. [sent-126, score-0.573]
</p><p>59 In this experiment, the emission noise variances and inducing input points are estimated, while all other parameters are ﬁxed to the true values used in generating the data. [sent-127, score-0.423]
</p><p>60 The estimates of the 39-dimensional noise variance of the emission functions are shown with the true noise variances, the true RBF kernel variances, and the sample variances of the synthetic data. [sent-130, score-0.484]
</p><p>61 The top row denotes the estimation results without the variance constraint, and the bottom row with the variance constraint. [sent-131, score-0.154]
</p><p>62 Remarkably, the estimation result of the CVGPDS with M = 5 inducing input points is much better than the result of the VGPDS with M = 30. [sent-136, score-0.193]
</p><p>63 2  Two-class classiﬁcation using synthetic data  This section aims to show that when there is strong dependency over the observations, the proposed CVGPDS is a more appropriate model than the HMM for the classiﬁcation task. [sent-141, score-0.171]
</p><p>64 To this end, we ﬁrst generated several sets of two-class classiﬁcation datasets with different degrees of dependency over the observations. [sent-142, score-0.125]
</p><p>65 The considered classiﬁcation task is to map each input segment to one of two class labels. [sent-143, score-0.122]
</p><p>66 , S} as the segment index, the synthetic dataset D = {Ys , ts , ls }S s=1 consists of S segments, where the s-th segment has Ns samples. [sent-147, score-0.357]
</p><p>67 Here, Ys ∈ RNs ×D , ts ∈ RNs , and ls are the observation data, time, and class label of the s-th segment, respectively. [sent-148, score-0.116]
</p><p>68 i i Note that parameter ωi controls the degree of dependency over the observations. [sent-169, score-0.123]
</p><p>69 For instance, if ωi decreases, the off-diagonal terms of the emission kernel matrix Kf increase, which means stronger i correlations over the observations. [sent-170, score-0.254]
</p><p>70 The synthesized dataset consists of 200 segments in total (100 segments per class). [sent-172, score-0.181]
</p><p>71 The dimensions of the latent space and observation space are set to Q = 2 and D = 5, respectively. [sent-173, score-0.104]
</p><p>72 We use 6(= Zi ) components for the mean function of the emission kernel function. [sent-174, score-0.254]
</p><p>73 As a result, the degree of correlation between the observations is the only factor that distinguishes the two classes. [sent-178, score-0.115]
</p><p>74 Apparently, the HMM failed to distinguish the two classes with different degree of dependency over the observations. [sent-202, score-0.123]
</p><p>75 In contrast, the proposed CVGPDS distinguishes the two classes more effectively by capturing the different degrees of inter-dependencies over the observations incorporated in each class. [sent-203, score-0.117]
</p><p>76 3  Phoneme classiﬁcation  In this section, phoneme classiﬁcation experiments is described on real speech data from the TIMIT database. [sent-205, score-0.641]
</p><p>77 The TIMIT database contains a total of 6300 phonetically rich utterances, each of which is manually segmented based on 61 phoneme transcriptions. [sent-206, score-0.445]
</p><p>78 Following the standard regrouping of phoneme labels [11], 61 phonemes are reduced to 48 phonemes selected for modeling. [sent-207, score-0.613]
</p><p>79 As observations, 39-dimensional Mel-frequency cepstral coefﬁcients (MFCCs) (13 static coefﬁcients, ∆, and 7  ∆∆) extracted from the speech signals with standard 25 ms frame size, and 10 ms frame shifts are used. [sent-208, score-0.196]
</p><p>80 The dimension of the latent space is set to Q = 2. [sent-209, score-0.105]
</p><p>81 For the ﬁrst phoneme classiﬁcation experiment, 100 segments per phoneme are randomly selected using the phoneme boundary provided information in the TIMIT database. [sent-210, score-1.4]
</p><p>82 The number of inducing input points is set to M = 10. [sent-211, score-0.167]
</p><p>83 Table 2: Classiﬁcation accuracy on the 48-phoneme dataset (10-fold CV average [%]): 100 segments are used for training and testing each phoneme model HMM  VGPDS  CVGPDS  49. [sent-214, score-0.555]
</p><p>84 For the second phoneme classiﬁcation experiment, the TIMIT core test set consisting of 192 sentences is used for evaluation. [sent-219, score-0.466]
</p><p>85 We use the same 100 segments for training the phoneme models as in the ﬁrst phoneme classiﬁcation experiment. [sent-220, score-0.955]
</p><p>86 When evaluating the models, we merge the labels of 48 phonemes into the commonly used 39 phonemes [11]. [sent-222, score-0.168]
</p><p>87 Given speech observations with boundary information, a sequence of log-likelihoods is obtained, and then a bigram is constructed to incorporate linguistic information into the classiﬁcation score. [sent-223, score-0.262]
</p><p>88 In this experiment, the number of inducing input points is set to M = 5. [sent-224, score-0.167]
</p><p>89 Table 3: Classiﬁcation accuracy on the TIMIT core test set [%]: 100 segments are used for training each phoneme model HMM  VGPDS  CVGPDS  57. [sent-225, score-0.551]
</p><p>90 54  Table 3 shows the experimental results of phoneme classiﬁcation for the TIMIT core test set. [sent-228, score-0.466]
</p><p>91 However, the classiﬁcation accuracies in Table 3 are lower than the state-of-the-art phoneme classiﬁcation results [12-13]. [sent-230, score-0.445]
</p><p>92 The reasons for low accuracy are as follows: 1) insufﬁcient amount of data is used for training the model owing to limited availability of computational power; 2) a mixture model for the emission is not considered. [sent-231, score-0.282]
</p><p>93 4  Conclusion  In this paper, a VGPDS-based acoustic model for phoneme classiﬁcation was considered. [sent-233, score-0.628]
</p><p>94 The proposed acoustic model can represent the nonlinear latent dynamics and dependency among observations by GP priors. [sent-234, score-0.556]
</p><p>95 Although the proposed model could not achieve the state-of-the-art performance of phoneme classiﬁcation, the experimental results showed that the proposed acoustic model has potential for speech modeling. [sent-236, score-0.844]
</p><p>96 Jelinek, “Continuous speech recognition by statistical methods,” Proceedings of the IEEE, Vol. [sent-241, score-0.222]
</p><p>97 Rohlicek, “From HMMs to segment models: A uniﬁed view of stochastic modeling for speech recognition,” IEEE Trans. [sent-247, score-0.323]
</p><p>98 Lawrence, “Probabilistic non-linear principal component analysis with Gaussian process latent variable models,” Journal of Machine Learning Research (JMLR), Vol. [sent-266, score-0.111]
</p><p>99 Lawrence, “Learning for larger datasets with the Gaussian process latent variable model,” International Conference on Artiﬁcial Intelligence and Statistics (AISTATS), pp. [sent-271, score-0.111]
</p><p>100 Saul, “Large margin hidden markov models for automatic speech recognition,” Advances in Neural Information Processing Systems (NIPS), 2007. [sent-320, score-0.22]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('vgpds', 0.462), ('phoneme', 0.445), ('cvgpds', 0.357), ('hmm', 0.262), ('speech', 0.196), ('emission', 0.166), ('acoustic', 0.163), ('korea', 0.117), ('inducing', 0.116), ('ki', 0.11), ('gp', 0.102), ('dependency', 0.102), ('segment', 0.098), ('timit', 0.096), ('kernel', 0.088), ('dynamics', 0.088), ('phonemes', 0.084), ('variational', 0.079), ('hyperparameters', 0.077), ('south', 0.076), ('latent', 0.075), ('kaist', 0.074), ('daejeon', 0.074), ('asr', 0.074), ('classi', 0.066), ('observations', 0.066), ('segments', 0.065), ('rbf', 0.064), ('variance', 0.064), ('dynamical', 0.064), ('variances', 0.063), ('rns', 0.063), ('owing', 0.056), ('tn', 0.056), ('ys', 0.053), ('xs', 0.053), ('ee', 0.05), ('synthetic', 0.049), ('ls', 0.049), ('ns', 0.049), ('gj', 0.049), ('limitations', 0.048), ('hmms', 0.048), ('gaussian', 0.046), ('kf', 0.044), ('fi', 0.042), ('sungrack', 0.042), ('yni', 0.042), ('cation', 0.042), ('nonlinear', 0.042), ('ts', 0.038), ('lawrence', 0.037), ('scg', 0.037), ('wz', 0.037), ('xnj', 0.037), ('process', 0.036), ('mz', 0.034), ('utterance', 0.034), ('nonparametric', 0.034), ('effectiveness', 0.032), ('constraint', 0.032), ('dimension', 0.03), ('audio', 0.03), ('dx', 0.03), ('bj', 0.03), ('observation', 0.029), ('kg', 0.029), ('kj', 0.029), ('overcome', 0.029), ('modeling', 0.029), ('distinguishes', 0.028), ('noise', 0.027), ('titsias', 0.027), ('covariance', 0.027), ('points', 0.027), ('adopted', 0.026), ('recognition', 0.026), ('estimation', 0.026), ('synthesized', 0.026), ('dataset', 0.025), ('nj', 0.025), ('input', 0.024), ('physiological', 0.024), ('hidden', 0.024), ('degrees', 0.023), ('cv', 0.023), ('rasmussen', 0.022), ('decades', 0.022), ('extensive', 0.022), ('yn', 0.021), ('degree', 0.021), ('markovian', 0.021), ('remarkably', 0.021), ('core', 0.021), ('modi', 0.021), ('complex', 0.02), ('park', 0.02), ('model', 0.02), ('availability', 0.02), ('sparse', 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="270-tfidf-1" href="./nips-2012-Phoneme_Classification_using_Constrained_Variational_Gaussian_Process_Dynamical_System.html">270 nips-2012-Phoneme Classification using Constrained Variational Gaussian Process Dynamical System</a></p>
<p>Author: Hyunsin Park, Sungrack Yun, Sanghyuk Park, Jongmin Kim, Chang D. Yoo</p><p>Abstract: For phoneme classiﬁcation, this paper describes an acoustic model based on the variational Gaussian process dynamical system (VGPDS). The nonlinear and nonparametric acoustic model is adopted to overcome the limitations of classical hidden Markov models (HMMs) in modeling speech. The Gaussian process prior on the dynamics and emission functions respectively enable the complex dynamic structure and long-range dependency of speech to be better represented than that by an HMM. In addition, a variance constraint in the VGPDS is introduced to eliminate the sparse approximation error in the kernel matrix. The effectiveness of the proposed model is demonstrated with three experimental results, including parameter estimation and classiﬁcation performance, on the synthetic and benchmark datasets. 1</p><p>2 0.19975181 <a title="270-tfidf-2" href="./nips-2012-The_variational_hierarchical_EM_algorithm_for_clustering_hidden_Markov_models.html">342 nips-2012-The variational hierarchical EM algorithm for clustering hidden Markov models</a></p>
<p>Author: Emanuele Coviello, Gert R. Lanckriet, Antoni B. Chan</p><p>Abstract: In this paper, we derive a novel algorithm to cluster hidden Markov models (HMMs) according to their probability distributions. We propose a variational hierarchical EM algorithm that i) clusters a given collection of HMMs into groups of HMMs that are similar, in terms of the distributions they represent, and ii) characterizes each group by a “cluster center”, i.e., a novel HMM that is representative for the group. We illustrate the beneﬁts of the proposed algorithm on hierarchical clustering of motion capture sequences as well as on automatic music tagging. 1</p><p>3 0.1094766 <a title="270-tfidf-3" href="./nips-2012-Practical_Bayesian_Optimization_of_Machine_Learning_Algorithms.html">272 nips-2012-Practical Bayesian Optimization of Machine Learning Algorithms</a></p>
<p>Author: Jasper Snoek, Hugo Larochelle, Ryan P. Adams</p><p>Abstract: The use of machine learning algorithms frequently involves careful tuning of learning parameters and model hyperparameters. Unfortunately, this tuning is often a “black art” requiring expert experience, rules of thumb, or sometimes bruteforce search. There is therefore great appeal for automatic approaches that can optimize the performance of any given learning algorithm to the problem at hand. In this work, we consider this problem through the framework of Bayesian optimization, in which a learning algorithm’s generalization performance is modeled as a sample from a Gaussian process (GP). We show that certain choices for the nature of the GP, such as the type of kernel and the treatment of its hyperparameters, can play a crucial role in obtaining a good optimizer that can achieve expertlevel performance. We describe new algorithms that take into account the variable cost (duration) of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks. 1</p><p>4 0.10756665 <a title="270-tfidf-4" href="./nips-2012-Unsupervised_Structure_Discovery_for_Semantic_Analysis_of_Audio.html">356 nips-2012-Unsupervised Structure Discovery for Semantic Analysis of Audio</a></p>
<p>Author: Sourish Chaudhuri, Bhiksha Raj</p><p>Abstract: Approaches to audio classiﬁcation and retrieval tasks largely rely on detectionbased discriminative models. We submit that such models make a simplistic assumption in mapping acoustics directly to semantics, whereas the actual process is likely more complex. We present a generative model that maps acoustics in a hierarchical manner to increasingly higher-level semantics. Our model has two layers with the ﬁrst layer modeling generalized sound units with no clear semantic associations, while the second layer models local patterns over these sound units. We evaluate our model on a large-scale retrieval task from TRECVID 2011, and report signiﬁcant improvements over standard baselines. 1</p><p>5 0.10385366 <a title="270-tfidf-5" href="./nips-2012-Hierarchical_spike_coding_of_sound.html">150 nips-2012-Hierarchical spike coding of sound</a></p>
<p>Author: Yan Karklin, Chaitanya Ekanadham, Eero P. Simoncelli</p><p>Abstract: Natural sounds exhibit complex statistical regularities at multiple scales. Acoustic events underlying speech, for example, are characterized by precise temporal and frequency relationships, but they can also vary substantially according to the pitch, duration, and other high-level properties of speech production. Learning this structure from data while capturing the inherent variability is an important ﬁrst step in building auditory processing systems, as well as understanding the mechanisms of auditory perception. Here we develop Hierarchical Spike Coding, a two-layer probabilistic generative model for complex acoustic structure. The ﬁrst layer consists of a sparse spiking representation that encodes the sound using kernels positioned precisely in time and frequency. Patterns in the positions of ﬁrst layer spikes are learned from the data: on a coarse scale, statistical regularities are encoded by a second-layer spiking representation, while ﬁne-scale structure is captured by recurrent interactions within the ﬁrst layer. When ﬁt to speech data, the second layer acoustic features include harmonic stacks, sweeps, frequency modulations, and precise temporal onsets, which can be composed to represent complex acoustic events. Unlike spectrogram-based methods, the model gives a probability distribution over sound pressure waveforms. This allows us to use the second-layer representation to synthesize sounds directly, and to perform model-based denoising, on which we demonstrate a signiﬁcant improvement over standard methods. 1</p><p>6 0.1003546 <a title="270-tfidf-6" href="./nips-2012-Active_Learning_of_Model_Evidence_Using_Bayesian_Quadrature.html">33 nips-2012-Active Learning of Model Evidence Using Bayesian Quadrature</a></p>
<p>7 0.095579281 <a title="270-tfidf-7" href="./nips-2012-Cocktail_Party_Processing_via_Structured_Prediction.html">72 nips-2012-Cocktail Party Processing via Structured Prediction</a></p>
<p>8 0.086500585 <a title="270-tfidf-8" href="./nips-2012-Learning_with_Recursive_Perceptual_Representations.html">197 nips-2012-Learning with Recursive Perceptual Representations</a></p>
<p>9 0.085937843 <a title="270-tfidf-9" href="./nips-2012-Effective_Split-Merge_Monte_Carlo_Methods_for_Nonparametric_Models_of_Sequential_Data.html">107 nips-2012-Effective Split-Merge Monte Carlo Methods for Nonparametric Models of Sequential Data</a></p>
<p>10 0.083775699 <a title="270-tfidf-10" href="./nips-2012-Learning_curves_for_multi-task_Gaussian_process_regression.html">187 nips-2012-Learning curves for multi-task Gaussian process regression</a></p>
<p>11 0.076677978 <a title="270-tfidf-11" href="./nips-2012-Fast_Bayesian_Inference_for_Non-Conjugate_Gaussian_Process_Regression.html">127 nips-2012-Fast Bayesian Inference for Non-Conjugate Gaussian Process Regression</a></p>
<p>12 0.074115932 <a title="270-tfidf-12" href="./nips-2012-Expectation_Propagation_in_Gaussian_Process_Dynamical_Systems.html">121 nips-2012-Expectation Propagation in Gaussian Process Dynamical Systems</a></p>
<p>13 0.070508681 <a title="270-tfidf-13" href="./nips-2012-Multiresolution_Gaussian_Processes.html">233 nips-2012-Multiresolution Gaussian Processes</a></p>
<p>14 0.067623481 <a title="270-tfidf-14" href="./nips-2012-Collaborative_Gaussian_Processes_for_Preference_Learning.html">74 nips-2012-Collaborative Gaussian Processes for Preference Learning</a></p>
<p>15 0.065080546 <a title="270-tfidf-15" href="./nips-2012-Bayesian_Warped_Gaussian_Processes.html">55 nips-2012-Bayesian Warped Gaussian Processes</a></p>
<p>16 0.062581666 <a title="270-tfidf-16" href="./nips-2012-Learning_from_Distributions_via_Support_Measure_Machines.html">188 nips-2012-Learning from Distributions via Support Measure Machines</a></p>
<p>17 0.059818134 <a title="270-tfidf-17" href="./nips-2012-Symbolic_Dynamic_Programming_for_Continuous_State_and_Observation_POMDPs.html">331 nips-2012-Symbolic Dynamic Programming for Continuous State and Observation POMDPs</a></p>
<p>18 0.058399115 <a title="270-tfidf-18" href="./nips-2012-Locating_Changes_in_Highly_Dependent_Data_with_Unknown_Number_of_Change_Points.html">203 nips-2012-Locating Changes in Highly Dependent Data with Unknown Number of Change Points</a></p>
<p>19 0.055926669 <a title="270-tfidf-19" href="./nips-2012-Simultaneously_Leveraging_Output_and_Task_Structures_for_Multiple-Output_Regression.html">312 nips-2012-Simultaneously Leveraging Output and Task Structures for Multiple-Output Regression</a></p>
<p>20 0.054092191 <a title="270-tfidf-20" href="./nips-2012-Truncation-free_Online_Variational_Inference_for_Bayesian_Nonparametric_Models.html">355 nips-2012-Truncation-free Online Variational Inference for Bayesian Nonparametric Models</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.162), (1, 0.046), (2, -0.023), (3, 0.018), (4, -0.085), (5, -0.026), (6, -0.001), (7, 0.059), (8, -0.037), (9, -0.166), (10, -0.056), (11, 0.028), (12, 0.042), (13, 0.028), (14, 0.001), (15, -0.026), (16, -0.019), (17, 0.066), (18, -0.047), (19, -0.059), (20, -0.071), (21, -0.051), (22, -0.08), (23, -0.097), (24, 0.029), (25, 0.022), (26, 0.01), (27, -0.116), (28, -0.069), (29, 0.047), (30, 0.092), (31, 0.053), (32, 0.048), (33, -0.025), (34, -0.003), (35, 0.053), (36, 0.16), (37, -0.073), (38, 0.08), (39, 0.101), (40, 0.011), (41, 0.096), (42, -0.162), (43, -0.04), (44, 0.027), (45, 0.034), (46, -0.046), (47, 0.045), (48, -0.069), (49, 0.054)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.88968301 <a title="270-lsi-1" href="./nips-2012-Phoneme_Classification_using_Constrained_Variational_Gaussian_Process_Dynamical_System.html">270 nips-2012-Phoneme Classification using Constrained Variational Gaussian Process Dynamical System</a></p>
<p>Author: Hyunsin Park, Sungrack Yun, Sanghyuk Park, Jongmin Kim, Chang D. Yoo</p><p>Abstract: For phoneme classiﬁcation, this paper describes an acoustic model based on the variational Gaussian process dynamical system (VGPDS). The nonlinear and nonparametric acoustic model is adopted to overcome the limitations of classical hidden Markov models (HMMs) in modeling speech. The Gaussian process prior on the dynamics and emission functions respectively enable the complex dynamic structure and long-range dependency of speech to be better represented than that by an HMM. In addition, a variance constraint in the VGPDS is introduced to eliminate the sparse approximation error in the kernel matrix. The effectiveness of the proposed model is demonstrated with three experimental results, including parameter estimation and classiﬁcation performance, on the synthetic and benchmark datasets. 1</p><p>2 0.7160762 <a title="270-lsi-2" href="./nips-2012-Unsupervised_Structure_Discovery_for_Semantic_Analysis_of_Audio.html">356 nips-2012-Unsupervised Structure Discovery for Semantic Analysis of Audio</a></p>
<p>Author: Sourish Chaudhuri, Bhiksha Raj</p><p>Abstract: Approaches to audio classiﬁcation and retrieval tasks largely rely on detectionbased discriminative models. We submit that such models make a simplistic assumption in mapping acoustics directly to semantics, whereas the actual process is likely more complex. We present a generative model that maps acoustics in a hierarchical manner to increasingly higher-level semantics. Our model has two layers with the ﬁrst layer modeling generalized sound units with no clear semantic associations, while the second layer models local patterns over these sound units. We evaluate our model on a large-scale retrieval task from TRECVID 2011, and report signiﬁcant improvements over standard baselines. 1</p><p>3 0.63618588 <a title="270-lsi-3" href="./nips-2012-Hierarchical_spike_coding_of_sound.html">150 nips-2012-Hierarchical spike coding of sound</a></p>
<p>Author: Yan Karklin, Chaitanya Ekanadham, Eero P. Simoncelli</p><p>Abstract: Natural sounds exhibit complex statistical regularities at multiple scales. Acoustic events underlying speech, for example, are characterized by precise temporal and frequency relationships, but they can also vary substantially according to the pitch, duration, and other high-level properties of speech production. Learning this structure from data while capturing the inherent variability is an important ﬁrst step in building auditory processing systems, as well as understanding the mechanisms of auditory perception. Here we develop Hierarchical Spike Coding, a two-layer probabilistic generative model for complex acoustic structure. The ﬁrst layer consists of a sparse spiking representation that encodes the sound using kernels positioned precisely in time and frequency. Patterns in the positions of ﬁrst layer spikes are learned from the data: on a coarse scale, statistical regularities are encoded by a second-layer spiking representation, while ﬁne-scale structure is captured by recurrent interactions within the ﬁrst layer. When ﬁt to speech data, the second layer acoustic features include harmonic stacks, sweeps, frequency modulations, and precise temporal onsets, which can be composed to represent complex acoustic events. Unlike spectrogram-based methods, the model gives a probability distribution over sound pressure waveforms. This allows us to use the second-layer representation to synthesize sounds directly, and to perform model-based denoising, on which we demonstrate a signiﬁcant improvement over standard methods. 1</p><p>4 0.62713802 <a title="270-lsi-4" href="./nips-2012-The_variational_hierarchical_EM_algorithm_for_clustering_hidden_Markov_models.html">342 nips-2012-The variational hierarchical EM algorithm for clustering hidden Markov models</a></p>
<p>Author: Emanuele Coviello, Gert R. Lanckriet, Antoni B. Chan</p><p>Abstract: In this paper, we derive a novel algorithm to cluster hidden Markov models (HMMs) according to their probability distributions. We propose a variational hierarchical EM algorithm that i) clusters a given collection of HMMs into groups of HMMs that are similar, in terms of the distributions they represent, and ii) characterizes each group by a “cluster center”, i.e., a novel HMM that is representative for the group. We illustrate the beneﬁts of the proposed algorithm on hierarchical clustering of motion capture sequences as well as on automatic music tagging. 1</p><p>5 0.5547058 <a title="270-lsi-5" href="./nips-2012-Bayesian_Warped_Gaussian_Processes.html">55 nips-2012-Bayesian Warped Gaussian Processes</a></p>
<p>Author: Miguel Lázaro-gredilla</p><p>Abstract: Warped Gaussian processes (WGP) [1] model output observations in regression tasks as a parametric nonlinear transformation of a Gaussian process (GP). The use of this nonlinear transformation, which is included as part of the probabilistic model, was shown to enhance performance by providing a better prior model on several data sets. In order to learn its parameters, maximum likelihood was used. In this work we show that it is possible to use a non-parametric nonlinear transformation in WGP and variationally integrate it out. The resulting Bayesian WGP is then able to work in scenarios in which the maximum likelihood WGP failed: Low data regime, data with censored values, classiﬁcation, etc. We demonstrate the superior performance of Bayesian warped GPs on several real data sets.</p><p>6 0.5312205 <a title="270-lsi-6" href="./nips-2012-Fast_Bayesian_Inference_for_Non-Conjugate_Gaussian_Process_Regression.html">127 nips-2012-Fast Bayesian Inference for Non-Conjugate Gaussian Process Regression</a></p>
<p>7 0.53111076 <a title="270-lsi-7" href="./nips-2012-Cocktail_Party_Processing_via_Structured_Prediction.html">72 nips-2012-Cocktail Party Processing via Structured Prediction</a></p>
<p>8 0.50477749 <a title="270-lsi-8" href="./nips-2012-Recognizing_Activities_by_Attribute_Dynamics.html">289 nips-2012-Recognizing Activities by Attribute Dynamics</a></p>
<p>9 0.4819234 <a title="270-lsi-9" href="./nips-2012-Practical_Bayesian_Optimization_of_Machine_Learning_Algorithms.html">272 nips-2012-Practical Bayesian Optimization of Machine Learning Algorithms</a></p>
<p>10 0.45648527 <a title="270-lsi-10" href="./nips-2012-Spectral_learning_of_linear_dynamics_from_generalised-linear_observations_with_application_to_neural_population_data.html">321 nips-2012-Spectral learning of linear dynamics from generalised-linear observations with application to neural population data</a></p>
<p>11 0.4469853 <a title="270-lsi-11" href="./nips-2012-Multiresolution_Gaussian_Processes.html">233 nips-2012-Multiresolution Gaussian Processes</a></p>
<p>12 0.44307464 <a title="270-lsi-12" href="./nips-2012-Active_Learning_of_Model_Evidence_Using_Bayesian_Quadrature.html">33 nips-2012-Active Learning of Model Evidence Using Bayesian Quadrature</a></p>
<p>13 0.43889567 <a title="270-lsi-13" href="./nips-2012-Modelling_Reciprocating_Relationships_with_Hawkes_Processes.html">219 nips-2012-Modelling Reciprocating Relationships with Hawkes Processes</a></p>
<p>14 0.42452419 <a title="270-lsi-14" href="./nips-2012-Forward-Backward_Activation_Algorithm_for_Hierarchical_Hidden_Markov_Models.html">136 nips-2012-Forward-Backward Activation Algorithm for Hierarchical Hidden Markov Models</a></p>
<p>15 0.42026639 <a title="270-lsi-15" href="./nips-2012-Learning_curves_for_multi-task_Gaussian_process_regression.html">187 nips-2012-Learning curves for multi-task Gaussian process regression</a></p>
<p>16 0.41231209 <a title="270-lsi-16" href="./nips-2012-Bayesian_models_for_Large-scale_Hierarchical_Classification.html">58 nips-2012-Bayesian models for Large-scale Hierarchical Classification</a></p>
<p>17 0.40977514 <a title="270-lsi-17" href="./nips-2012-Causal_discovery_with_scale-mixture_model_for_spatiotemporal_variance_dependencies.html">66 nips-2012-Causal discovery with scale-mixture model for spatiotemporal variance dependencies</a></p>
<p>18 0.39833814 <a title="270-lsi-18" href="./nips-2012-Learning_from_Distributions_via_Support_Measure_Machines.html">188 nips-2012-Learning from Distributions via Support Measure Machines</a></p>
<p>19 0.39576232 <a title="270-lsi-19" href="./nips-2012-Random_function_priors_for_exchangeable_arrays_with_applications_to_graphs_and_relational_data.html">287 nips-2012-Random function priors for exchangeable arrays with applications to graphs and relational data</a></p>
<p>20 0.38577452 <a title="270-lsi-20" href="./nips-2012-Efficient_high_dimensional_maximum_entropy_modeling_via_symmetric_partition_functions.html">115 nips-2012-Efficient high dimensional maximum entropy modeling via symmetric partition functions</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.469), (17, 0.011), (21, 0.015), (38, 0.066), (42, 0.017), (54, 0.03), (55, 0.011), (74, 0.038), (76, 0.136), (80, 0.076), (92, 0.034)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.89585739 <a title="270-lda-1" href="./nips-2012-Factorial_LDA%3A_Sparse_Multi-Dimensional_Text_Models.html">124 nips-2012-Factorial LDA: Sparse Multi-Dimensional Text Models</a></p>
<p>Author: Michael Paul, Mark Dredze</p><p>Abstract: Latent variable models can be enriched with a multi-dimensional structure to consider the many latent factors in a text corpus, such as topic, author perspective and sentiment. We introduce factorial LDA, a multi-dimensional model in which a document is inﬂuenced by K different factors, and each word token depends on a K-dimensional vector of latent variables. Our model incorporates structured word priors and learns a sparse product of factors. Experiments on research abstracts show that our model can learn latent factors such as research topic, scientiﬁc discipline, and focus (methods vs. applications). Our modeling improvements reduce test perplexity and improve human interpretability of the discovered factors. 1</p><p>2 0.85659319 <a title="270-lda-2" href="./nips-2012-Learning_the_Architecture_of_Sum-Product_Networks_Using_Clustering_on_Variables.html">191 nips-2012-Learning the Architecture of Sum-Product Networks Using Clustering on Variables</a></p>
<p>Author: Aaron Dennis, Dan Ventura</p><p>Abstract: The sum-product network (SPN) is a recently-proposed deep model consisting of a network of sum and product nodes, and has been shown to be competitive with state-of-the-art deep models on certain difﬁcult tasks such as image completion. Designing an SPN network architecture that is suitable for the task at hand is an open question. We propose an algorithm for learning the SPN architecture from data. The idea is to cluster variables (as opposed to data instances) in order to identify variable subsets that strongly interact with one another. Nodes in the SPN network are then allocated towards explaining these interactions. Experimental evidence shows that learning the SPN architecture signiﬁcantly improves its performance compared to using a previously-proposed static architecture. 1</p><p>same-paper 3 0.80988097 <a title="270-lda-3" href="./nips-2012-Phoneme_Classification_using_Constrained_Variational_Gaussian_Process_Dynamical_System.html">270 nips-2012-Phoneme Classification using Constrained Variational Gaussian Process Dynamical System</a></p>
<p>Author: Hyunsin Park, Sungrack Yun, Sanghyuk Park, Jongmin Kim, Chang D. Yoo</p><p>Abstract: For phoneme classiﬁcation, this paper describes an acoustic model based on the variational Gaussian process dynamical system (VGPDS). The nonlinear and nonparametric acoustic model is adopted to overcome the limitations of classical hidden Markov models (HMMs) in modeling speech. The Gaussian process prior on the dynamics and emission functions respectively enable the complex dynamic structure and long-range dependency of speech to be better represented than that by an HMM. In addition, a variance constraint in the VGPDS is introduced to eliminate the sparse approximation error in the kernel matrix. The effectiveness of the proposed model is demonstrated with three experimental results, including parameter estimation and classiﬁcation performance, on the synthetic and benchmark datasets. 1</p><p>4 0.80577785 <a title="270-lda-4" href="./nips-2012-Multiresolution_Gaussian_Processes.html">233 nips-2012-Multiresolution Gaussian Processes</a></p>
<p>Author: David B. Dunson, Emily B. Fox</p><p>Abstract: We propose a multiresolution Gaussian process to capture long-range, nonMarkovian dependencies while allowing for abrupt changes and non-stationarity. The multiresolution GP hierarchically couples a collection of smooth GPs, each deﬁned over an element of a random nested partition. Long-range dependencies are captured by the top-level GP while the partition points deﬁne the abrupt changes. Due to the inherent conjugacy of the GPs, one can analytically marginalize the GPs and compute the marginal likelihood of the observations given the partition tree. This property allows for efﬁcient inference of the partition itself, for which we employ graph-theoretic techniques. We apply the multiresolution GP to the analysis of magnetoencephalography (MEG) recordings of brain activity.</p><p>5 0.78295815 <a title="270-lda-5" href="./nips-2012-Learning_the_Dependency_Structure_of_Latent_Factors.html">192 nips-2012-Learning the Dependency Structure of Latent Factors</a></p>
<p>Author: Yunlong He, Yanjun Qi, Koray Kavukcuoglu, Haesun Park</p><p>Abstract: In this paper, we study latent factor models with dependency structure in the latent space. We propose a general learning framework which induces sparsity on the undirected graphical model imposed on the vector of latent factors. A novel latent factor model SLFA is then proposed as a matrix factorization problem with a special regularization term that encourages collaborative reconstruction. The main beneﬁt (novelty) of the model is that we can simultaneously learn the lowerdimensional representation for data and model the pairwise relationships between latent factors explicitly. An on-line learning algorithm is devised to make the model feasible for large-scale learning problems. Experimental results on two synthetic data and two real-world data sets demonstrate that pairwise relationships and latent factors learned by our model provide a more structured way of exploring high-dimensional data, and the learned representations achieve the state-of-the-art classiﬁcation performance. 1</p><p>6 0.7826823 <a title="270-lda-6" href="./nips-2012-Proximal_Newton-type_methods_for_convex_optimization.html">282 nips-2012-Proximal Newton-type methods for convex optimization</a></p>
<p>7 0.73370546 <a title="270-lda-7" href="./nips-2012-A_Divide-and-Conquer_Method_for_Sparse_Inverse_Covariance_Estimation.html">7 nips-2012-A Divide-and-Conquer Method for Sparse Inverse Covariance Estimation</a></p>
<p>8 0.69167739 <a title="270-lda-8" href="./nips-2012-Symmetric_Correspondence_Topic_Models_for_Multilingual_Text_Analysis.html">332 nips-2012-Symmetric Correspondence Topic Models for Multilingual Text Analysis</a></p>
<p>9 0.68316442 <a title="270-lda-9" href="./nips-2012-A_Neural_Autoregressive_Topic_Model.html">12 nips-2012-A Neural Autoregressive Topic Model</a></p>
<p>10 0.61902344 <a title="270-lda-10" href="./nips-2012-The_variational_hierarchical_EM_algorithm_for_clustering_hidden_Markov_models.html">342 nips-2012-The variational hierarchical EM algorithm for clustering hidden Markov models</a></p>
<p>11 0.56657976 <a title="270-lda-11" href="./nips-2012-Truly_Nonparametric_Online_Variational_Inference_for_Hierarchical_Dirichlet_Processes.html">354 nips-2012-Truly Nonparametric Online Variational Inference for Hierarchical Dirichlet Processes</a></p>
<p>12 0.55928242 <a title="270-lda-12" href="./nips-2012-Augment-and-Conquer_Negative_Binomial_Processes.html">47 nips-2012-Augment-and-Conquer Negative Binomial Processes</a></p>
<p>13 0.54947269 <a title="270-lda-13" href="./nips-2012-A_Spectral_Algorithm_for_Latent_Dirichlet_Allocation.html">19 nips-2012-A Spectral Algorithm for Latent Dirichlet Allocation</a></p>
<p>14 0.54724234 <a title="270-lda-14" href="./nips-2012-Joint_Modeling_of_a_Matrix_with_Associated_Text_via_Latent_Binary_Features.html">166 nips-2012-Joint Modeling of a Matrix with Associated Text via Latent Binary Features</a></p>
<p>15 0.54634887 <a title="270-lda-15" href="./nips-2012-Cocktail_Party_Processing_via_Structured_Prediction.html">72 nips-2012-Cocktail Party Processing via Structured Prediction</a></p>
<p>16 0.5445013 <a title="270-lda-16" href="./nips-2012-Compressive_Sensing_MRI_with_Wavelet_Tree_Sparsity.html">78 nips-2012-Compressive Sensing MRI with Wavelet Tree Sparsity</a></p>
<p>17 0.53743178 <a title="270-lda-17" href="./nips-2012-Topic-Partitioned_Multinetwork_Embeddings.html">345 nips-2012-Topic-Partitioned Multinetwork Embeddings</a></p>
<p>18 0.53416789 <a title="270-lda-18" href="./nips-2012-Dip-means%3A_an_incremental_clustering_method_for_estimating_the_number_of_clusters.html">99 nips-2012-Dip-means: an incremental clustering method for estimating the number of clusters</a></p>
<p>19 0.53335667 <a title="270-lda-19" href="./nips-2012-Hierarchical_spike_coding_of_sound.html">150 nips-2012-Hierarchical spike coding of sound</a></p>
<p>20 0.53249073 <a title="270-lda-20" href="./nips-2012-Dual-Space_Analysis_of_the_Sparse_Linear_Model.html">104 nips-2012-Dual-Space Analysis of the Sparse Linear Model</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
