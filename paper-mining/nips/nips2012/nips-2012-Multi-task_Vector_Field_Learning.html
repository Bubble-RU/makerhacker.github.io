<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>225 nips-2012-Multi-task Vector Field Learning</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-225" href="#">nips2012-225</a> knowledge-graph by maker-knowledge-mining</p><h1>225 nips-2012-Multi-task Vector Field Learning</h1>
<br/><p>Source: <a title="nips-2012-225-pdf" href="http://papers.nips.cc/paper/4807-multi-task-vector-field-learning.pdf">pdf</a></p><p>Author: Binbin Lin, Sen Yang, Chiyuan Zhang, Jieping Ye, Xiaofei He</p><p>Abstract: Multi-task learning (MTL) aims to improve generalization performance by learning multiple related tasks simultaneously and identifying the shared information among tasks. Most of existing MTL methods focus on learning linear models under the supervised setting. We propose a novel semi-supervised and nonlinear approach for MTL using vector ﬁelds. A vector ﬁeld is a smooth mapping from the manifold to the tangent spaces which can be viewed as a directional derivative of functions on the manifold. We argue that vector ﬁelds provide a natural way to exploit the geometric structure of data as well as the shared differential structure of tasks, both of which are crucial for semi-supervised multi-task learning. In this paper, we develop multi-task vector ﬁeld learning (MTVFL) which learns the predictor functions and the vector ﬁelds simultaneously. MTVFL has the following key properties. (1) The vector ﬁelds MTVFL learns are close to the gradient ﬁelds of the predictor functions. (2) Within each task, the vector ﬁeld is required to be as parallel as possible which is expected to span a low dimensional subspace. (3) The vector ﬁelds from all tasks share a low dimensional subspace. We formalize our idea in a regularization framework and also provide a convex relaxation method to solve the original non-convex problem. The experimental results on synthetic and real data demonstrate the effectiveness of our proposed approach. 1</p><p>Reference: <a title="nips-2012-225-reference" href="../nips2012_reference/nips-2012-Multi-task_Vector_Field_Learning_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('nl', 0.378), ('vl', 0.35), ('til', 0.298), ('mtvfl', 0.25), ('fl', 0.235), ('xl', 0.232), ('eld', 0.19), ('manifold', 0.184), ('dl', 0.173), ('kaso', 0.167), ('aso', 0.146), ('txl', 0.146), ('vxl', 0.146), ('mtl', 0.143), ('tang', 0.13), ('stvfl', 0.125), ('vi', 0.112), ('landmin', 0.104), ('ih', 0.102), ('singul', 0.097)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9999997 <a title="225-tfidf-1" href="./nips-2012-Multi-task_Vector_Field_Learning.html">225 nips-2012-Multi-task Vector Field Learning</a></p>
<p>2 0.15911013 <a title="225-tfidf-2" href="./nips-2012-Selective_Labeling_via_Error_Bound_Minimization.html">305 nips-2012-Selective Labeling via Error Bound Minimization</a></p>
<p>3 0.14580435 <a title="225-tfidf-3" href="./nips-2012-Minimax_Multi-Task_Learning_and_a_Generalized_Loss-Compositional_Paradigm_for_MTL.html">212 nips-2012-Minimax Multi-Task Learning and a Generalized Loss-Compositional Paradigm for MTL</a></p>
<p>4 0.12537432 <a title="225-tfidf-4" href="./nips-2012-Scaled_Gradients_on_Grassmann_Manifolds_for_Matrix_Completion.html">301 nips-2012-Scaled Gradients on Grassmann Manifolds for Matrix Completion</a></p>
<p>5 0.11941332 <a title="225-tfidf-5" href="./nips-2012-Learning_Manifolds_with_K-Means_and_K-Flats.html">179 nips-2012-Learning Manifolds with K-Means and K-Flats</a></p>
<p>6 0.10727119 <a title="225-tfidf-6" href="./nips-2012-Sparse_Approximate_Manifolds_for_Differential_Geometric_MCMC.html">318 nips-2012-Sparse Approximate Manifolds for Differential Geometric MCMC</a></p>
<p>7 0.098345943 <a title="225-tfidf-7" href="./nips-2012-A_Geometric_take_on_Metric_Learning.html">9 nips-2012-A Geometric take on Metric Learning</a></p>
<p>8 0.089934692 <a title="225-tfidf-8" href="./nips-2012-Probabilistic_Low-Rank_Subspace_Clustering.html">277 nips-2012-Probabilistic Low-Rank Subspace Clustering</a></p>
<p>9 0.077166893 <a title="225-tfidf-9" href="./nips-2012-Learning_curves_for_multi-task_Gaussian_process_regression.html">187 nips-2012-Learning curves for multi-task Gaussian process regression</a></p>
<p>10 0.076323047 <a title="225-tfidf-10" href="./nips-2012-Deep_Representations_and_Codes_for_Image_Auto-Annotation.html">92 nips-2012-Deep Representations and Codes for Image Auto-Annotation</a></p>
<p>11 0.071752504 <a title="225-tfidf-11" href="./nips-2012-A_Scalable_CUR_Matrix_Decomposition_Algorithm%3A_Lower_Time_Complexity_and_Tighter_Bound.html">17 nips-2012-A Scalable CUR Matrix Decomposition Algorithm: Lower Time Complexity and Tighter Bound</a></p>
<p>12 0.06075415 <a title="225-tfidf-12" href="./nips-2012-Majorization_for_CRFs_and_Latent_Likelihoods.html">206 nips-2012-Majorization for CRFs and Latent Likelihoods</a></p>
<p>13 0.060677931 <a title="225-tfidf-13" href="./nips-2012-Feature_Clustering_for_Accelerating_Parallel_Coordinate_Descent.html">131 nips-2012-Feature Clustering for Accelerating Parallel Coordinate Descent</a></p>
<p>14 0.059788749 <a title="225-tfidf-14" href="./nips-2012-Simultaneously_Leveraging_Output_and_Task_Structures_for_Multiple-Output_Regression.html">312 nips-2012-Simultaneously Leveraging Output and Task Structures for Multiple-Output Regression</a></p>
<p>15 0.05801452 <a title="225-tfidf-15" href="./nips-2012-Multilabel_Classification_using_Bayesian_Compressed_Sensing.html">228 nips-2012-Multilabel Classification using Bayesian Compressed Sensing</a></p>
<p>16 0.057354238 <a title="225-tfidf-16" href="./nips-2012-Clustering_by_Nonnegative_Matrix_Factorization_Using_Graph_Random_Walk.html">70 nips-2012-Clustering by Nonnegative Matrix Factorization Using Graph Random Walk</a></p>
<p>17 0.049706198 <a title="225-tfidf-17" href="./nips-2012-Learning_as_MAP_Inference_in_Discrete_Graphical_Models.html">186 nips-2012-Learning as MAP Inference in Discrete Graphical Models</a></p>
<p>18 0.048945088 <a title="225-tfidf-18" href="./nips-2012-Proper_losses_for_learning_from_partial_labels.html">280 nips-2012-Proper losses for learning from partial labels</a></p>
<p>19 0.048187848 <a title="225-tfidf-19" href="./nips-2012-Accelerated_Training_for_Matrix-norm_Regularization%3A_A_Boosting_Approach.html">29 nips-2012-Accelerated Training for Matrix-norm Regularization: A Boosting Approach</a></p>
<p>20 0.048125818 <a title="225-tfidf-20" href="./nips-2012-Learning_with_Recursive_Perceptual_Representations.html">197 nips-2012-Learning with Recursive Perceptual Representations</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.143), (1, -0.031), (2, 0.049), (3, 0.025), (4, 0.014), (5, 0.032), (6, -0.019), (7, -0.011), (8, -0.019), (9, -0.073), (10, 0.052), (11, 0.036), (12, 0.055), (13, -0.107), (14, -0.074), (15, 0.107), (16, -0.037), (17, 0.04), (18, 0.027), (19, -0.005), (20, -0.005), (21, 0.005), (22, -0.013), (23, 0.049), (24, -0.006), (25, -0.009), (26, 0.036), (27, -0.046), (28, -0.008), (29, -0.031), (30, 0.044), (31, 0.141), (32, -0.048), (33, 0.026), (34, 0.019), (35, -0.024), (36, -0.046), (37, 0.004), (38, -0.103), (39, -0.075), (40, -0.023), (41, 0.037), (42, 0.0), (43, -0.051), (44, 0.018), (45, -0.068), (46, 0.056), (47, -0.063), (48, -0.136), (49, 0.072)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.88317782 <a title="225-lsi-1" href="./nips-2012-Multi-task_Vector_Field_Learning.html">225 nips-2012-Multi-task Vector Field Learning</a></p>
<p>2 0.70467454 <a title="225-lsi-2" href="./nips-2012-Scaled_Gradients_on_Grassmann_Manifolds_for_Matrix_Completion.html">301 nips-2012-Scaled Gradients on Grassmann Manifolds for Matrix Completion</a></p>
<p>3 0.62060678 <a title="225-lsi-3" href="./nips-2012-Sparse_Approximate_Manifolds_for_Differential_Geometric_MCMC.html">318 nips-2012-Sparse Approximate Manifolds for Differential Geometric MCMC</a></p>
<p>4 0.59925336 <a title="225-lsi-4" href="./nips-2012-A_Scalable_CUR_Matrix_Decomposition_Algorithm%3A_Lower_Time_Complexity_and_Tighter_Bound.html">17 nips-2012-A Scalable CUR Matrix Decomposition Algorithm: Lower Time Complexity and Tighter Bound</a></p>
<p>5 0.56475586 <a title="225-lsi-5" href="./nips-2012-Bayesian_Probabilistic_Co-Subspace_Addition.html">54 nips-2012-Bayesian Probabilistic Co-Subspace Addition</a></p>
<p>6 0.56324637 <a title="225-lsi-6" href="./nips-2012-Selective_Labeling_via_Error_Bound_Minimization.html">305 nips-2012-Selective Labeling via Error Bound Minimization</a></p>
<p>7 0.53544819 <a title="225-lsi-7" href="./nips-2012-Probabilistic_Low-Rank_Subspace_Clustering.html">277 nips-2012-Probabilistic Low-Rank Subspace Clustering</a></p>
<p>8 0.5240503 <a title="225-lsi-8" href="./nips-2012-A_new_metric_on_the_manifold_of_kernel_matrices_with_application_to_matrix_geometric_means.html">25 nips-2012-A new metric on the manifold of kernel matrices with application to matrix geometric means</a></p>
<p>9 0.52211839 <a title="225-lsi-9" href="./nips-2012-A_Geometric_take_on_Metric_Learning.html">9 nips-2012-A Geometric take on Metric Learning</a></p>
<p>10 0.51977319 <a title="225-lsi-10" href="./nips-2012-Factoring_nonnegative_matrices_with_linear_programs.html">125 nips-2012-Factoring nonnegative matrices with linear programs</a></p>
<p>11 0.51124012 <a title="225-lsi-11" href="./nips-2012-Learning_Manifolds_with_K-Means_and_K-Flats.html">179 nips-2012-Learning Manifolds with K-Means and K-Flats</a></p>
<p>12 0.4905656 <a title="225-lsi-12" href="./nips-2012-Projection_Retrieval_for_Classification.html">279 nips-2012-Projection Retrieval for Classification</a></p>
<p>13 0.46880147 <a title="225-lsi-13" href="./nips-2012-On_the_Sample_Complexity_of_Robust_PCA.html">254 nips-2012-On the Sample Complexity of Robust PCA</a></p>
<p>14 0.46296579 <a title="225-lsi-14" href="./nips-2012-Learning_curves_for_multi-task_Gaussian_process_regression.html">187 nips-2012-Learning curves for multi-task Gaussian process regression</a></p>
<p>15 0.46232346 <a title="225-lsi-15" href="./nips-2012-Learning_Multiple_Tasks_using_Shared_Hypotheses.html">181 nips-2012-Learning Multiple Tasks using Shared Hypotheses</a></p>
<p>16 0.46054113 <a title="225-lsi-16" href="./nips-2012-Perfect_Dimensionality_Recovery_by_Variational_Bayesian_PCA.html">268 nips-2012-Perfect Dimensionality Recovery by Variational Bayesian PCA</a></p>
<p>17 0.45853314 <a title="225-lsi-17" href="./nips-2012-Spectral_Learning_of_General_Weighted_Automata_via_Constrained_Matrix_Completion.html">320 nips-2012-Spectral Learning of General Weighted Automata via Constrained Matrix Completion</a></p>
<p>18 0.44388849 <a title="225-lsi-18" href="./nips-2012-Distributed_Probabilistic_Learning_for_Camera_Networks_with_Missing_Data.html">103 nips-2012-Distributed Probabilistic Learning for Camera Networks with Missing Data</a></p>
<p>19 0.44143397 <a title="225-lsi-19" href="./nips-2012-Minimax_Multi-Task_Learning_and_a_Generalized_Loss-Compositional_Paradigm_for_MTL.html">212 nips-2012-Minimax Multi-Task Learning and a Generalized Loss-Compositional Paradigm for MTL</a></p>
<p>20 0.43734267 <a title="225-lsi-20" href="./nips-2012-Nonparametric_Max-Margin_Matrix_Factorization_for_Collaborative_Prediction.html">246 nips-2012-Nonparametric Max-Margin Matrix Factorization for Collaborative Prediction</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(11, 0.074), (45, 0.378), (47, 0.089), (67, 0.045), (70, 0.061), (85, 0.052), (94, 0.098), (99, 0.094)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.6527254 <a title="225-lda-1" href="./nips-2012-Multi-task_Vector_Field_Learning.html">225 nips-2012-Multi-task Vector Field Learning</a></p>
<p>2 0.5869084 <a title="225-lda-2" href="./nips-2012-Joint_Modeling_of_a_Matrix_with_Associated_Text_via_Latent_Binary_Features.html">166 nips-2012-Joint Modeling of a Matrix with Associated Text via Latent Binary Features</a></p>
<p>3 0.46092463 <a title="225-lda-3" href="./nips-2012-Efficient_Bayes-Adaptive_Reinforcement_Learning_using_Sample-Based_Search.html">108 nips-2012-Efficient Bayes-Adaptive Reinforcement Learning using Sample-Based Search</a></p>
<p>4 0.45795605 <a title="225-lda-4" href="./nips-2012-Compressive_neural_representation_of_sparse%2C_high-dimensional_probabilities.html">79 nips-2012-Compressive neural representation of sparse, high-dimensional probabilities</a></p>
<p>5 0.45727113 <a title="225-lda-5" href="./nips-2012-Volume_Regularization_for_Binary_Classification.html">361 nips-2012-Volume Regularization for Binary Classification</a></p>
<p>6 0.4557296 <a title="225-lda-6" href="./nips-2012-The_variational_hierarchical_EM_algorithm_for_clustering_hidden_Markov_models.html">342 nips-2012-The variational hierarchical EM algorithm for clustering hidden Markov models</a></p>
<p>7 0.45542416 <a title="225-lda-7" href="./nips-2012-Learning_Probability_Measures_with_respect_to_Optimal_Transport_Metrics.html">184 nips-2012-Learning Probability Measures with respect to Optimal Transport Metrics</a></p>
<p>8 0.45492789 <a title="225-lda-8" href="./nips-2012-Generalization_Bounds_for_Domain_Adaptation.html">142 nips-2012-Generalization Bounds for Domain Adaptation</a></p>
<p>9 0.45488274 <a title="225-lda-9" href="./nips-2012-From_Deformations_to_Parts%3A_Motion-based_Segmentation_of_3D_Objects.html">137 nips-2012-From Deformations to Parts: Motion-based Segmentation of 3D Objects</a></p>
<p>10 0.45480546 <a title="225-lda-10" href="./nips-2012-Gradient_Weights_help_Nonparametric_Regressors.html">145 nips-2012-Gradient Weights help Nonparametric Regressors</a></p>
<p>11 0.45454693 <a title="225-lda-11" href="./nips-2012-Learning_Partially_Observable_Models_Using_Temporally_Abstract_Decision_Trees.html">183 nips-2012-Learning Partially Observable Models Using Temporally Abstract Decision Trees</a></p>
<p>12 0.4540807 <a title="225-lda-12" href="./nips-2012-Minimax_Multi-Task_Learning_and_a_Generalized_Loss-Compositional_Paradigm_for_MTL.html">212 nips-2012-Minimax Multi-Task Learning and a Generalized Loss-Compositional Paradigm for MTL</a></p>
<p>13 0.45393175 <a title="225-lda-13" href="./nips-2012-Timely_Object_Recognition.html">344 nips-2012-Timely Object Recognition</a></p>
<p>14 0.4536221 <a title="225-lda-14" href="./nips-2012-A_Geometric_take_on_Metric_Learning.html">9 nips-2012-A Geometric take on Metric Learning</a></p>
<p>15 0.45314655 <a title="225-lda-15" href="./nips-2012-Neurally_Plausible_Reinforcement_Learning_of_Working_Memory_Tasks.html">238 nips-2012-Neurally Plausible Reinforcement Learning of Working Memory Tasks</a></p>
<p>16 0.45312718 <a title="225-lda-16" href="./nips-2012-Diffusion_Decision_Making_for_Adaptive_k-Nearest_Neighbor_Classification.html">97 nips-2012-Diffusion Decision Making for Adaptive k-Nearest Neighbor Classification</a></p>
<p>17 0.45296329 <a title="225-lda-17" href="./nips-2012-Dip-means%3A_an_incremental_clustering_method_for_estimating_the_number_of_clusters.html">99 nips-2012-Dip-means: an incremental clustering method for estimating the number of clusters</a></p>
<p>18 0.45201021 <a title="225-lda-18" href="./nips-2012-Collaborative_Ranking_With_17_Parameters.html">75 nips-2012-Collaborative Ranking With 17 Parameters</a></p>
<p>19 0.45184302 <a title="225-lda-19" href="./nips-2012-Label_Ranking_with_Partial_Abstention_based_on_Thresholded_Probabilistic_Models.html">169 nips-2012-Label Ranking with Partial Abstention based on Thresholded Probabilistic Models</a></p>
<p>20 0.45183629 <a title="225-lda-20" href="./nips-2012-Max-Margin_Structured_Output_Regression_for_Spatio-Temporal_Action_Localization.html">209 nips-2012-Max-Margin Structured Output Regression for Spatio-Temporal Action Localization</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
