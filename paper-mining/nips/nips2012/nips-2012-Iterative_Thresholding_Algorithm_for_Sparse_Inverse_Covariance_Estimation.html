<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>164 nips-2012-Iterative Thresholding Algorithm for Sparse Inverse Covariance Estimation</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-164" href="#">nips2012-164</a> knowledge-graph by maker-knowledge-mining</p><h1>164 nips-2012-Iterative Thresholding Algorithm for Sparse Inverse Covariance Estimation</h1>
<br/><p>Source: <a title="nips-2012-164-pdf" href="http://papers.nips.cc/paper/4574-iterative-thresholding-algorithm-for-sparse-inverse-covariance-estimation.pdf">pdf</a></p><p>Author: Benjamin Rolfs, Bala Rajaratnam, Dominique Guillot, Ian Wong, Arian Maleki</p><p>Abstract: The 1 -regularized maximum likelihood estimation problem has recently become a topic of great interest within the machine learning, statistics, and optimization communities as a method for producing sparse inverse covariance estimators. In this paper, a proximal gradient method (G-ISTA) for performing 1 -regularized covariance matrix estimation is presented. Although numerous algorithms have been proposed for solving this problem, this simple proximal gradient method is found to have attractive theoretical and numerical properties. G-ISTA has a linear rate of convergence, resulting in an O(log ε) iteration complexity to reach a tolerance of ε. This paper gives eigenvalue bounds for the G-ISTA iterates, providing a closed-form linear convergence rate. The rate is shown to be closely related to the condition number of the optimal point. Numerical convergence results and timing comparisons for the proposed method are presented. G-ISTA is shown to perform very well, especially when the optimal point is well-conditioned. 1</p><p>Reference: <a title="nips-2012-164-reference" href="../nips2012_reference/nips-2012-Iterative_Thresholding_Algorithm_for_Sparse_Inverse_Covariance_Estimation_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('quic', 0.415), ('nnz', 0.331), ('glasso', 0.251), ('sp', 0.226), ('proxim', 0.194), ('invers', 0.163), ('dual', 0.151), ('cov', 0.145), ('det', 0.144), ('stanford', 0.139), ('spars', 0.131), ('yuri', 0.125), ('shrinkage', 0.124), ('mazumd', 0.116), ('thresholding', 0.112), ('cholesky', 0.105), ('prim', 0.105), ('ist', 0.099), ('it', 0.097), ('converg', 0.091)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="164-tfidf-1" href="./nips-2012-Iterative_Thresholding_Algorithm_for_Sparse_Inverse_Covariance_Estimation.html">164 nips-2012-Iterative Thresholding Algorithm for Sparse Inverse Covariance Estimation</a></p>
<p>2 0.27613756 <a title="164-tfidf-2" href="./nips-2012-A_Divide-and-Conquer_Method_for_Sparse_Inverse_Covariance_Estimation.html">7 nips-2012-A Divide-and-Conquer Method for Sparse Inverse Covariance Estimation</a></p>
<p>3 0.23812245 <a title="164-tfidf-3" href="./nips-2012-Newton-Like_Methods_for_Sparse_Inverse_Covariance_Estimation.html">240 nips-2012-Newton-Like Methods for Sparse Inverse Covariance Estimation</a></p>
<p>4 0.22506499 <a title="164-tfidf-4" href="./nips-2012-Proximal_Newton-type_methods_for_convex_optimization.html">282 nips-2012-Proximal Newton-type methods for convex optimization</a></p>
<p>5 0.21017902 <a title="164-tfidf-5" href="./nips-2012-A_Convex_Formulation_for_Learning_Scale-Free_Networks_via_Submodular_Relaxation.html">6 nips-2012-A Convex Formulation for Learning Scale-Free Networks via Submodular Relaxation</a></p>
<p>6 0.17913733 <a title="164-tfidf-6" href="./nips-2012-Feature_Clustering_for_Accelerating_Parallel_Coordinate_Descent.html">131 nips-2012-Feature Clustering for Accelerating Parallel Coordinate Descent</a></p>
<p>7 0.17455904 <a title="164-tfidf-7" href="./nips-2012-Optimal_Regularized_Dual_Averaging_Methods_for_Stochastic_Optimization.html">263 nips-2012-Optimal Regularized Dual Averaging Methods for Stochastic Optimization</a></p>
<p>8 0.16946872 <a title="164-tfidf-8" href="./nips-2012-Sparse_Prediction_with_the_%24k%24-Support_Norm.html">319 nips-2012-Sparse Prediction with the $k$-Support Norm</a></p>
<p>9 0.15952784 <a title="164-tfidf-9" href="./nips-2012-Structure_estimation_for_discrete_graphical_models%3A_Generalized_covariance_matrices_and_their_inverses.html">326 nips-2012-Structure estimation for discrete graphical models: Generalized covariance matrices and their inverses</a></p>
<p>10 0.15874726 <a title="164-tfidf-10" href="./nips-2012-Nonparametric_Reduced_Rank_Regression.html">247 nips-2012-Nonparametric Reduced Rank Regression</a></p>
<p>11 0.15750788 <a title="164-tfidf-11" href="./nips-2012-A_quasi-Newton_proximal_splitting_method.html">27 nips-2012-A quasi-Newton proximal splitting method</a></p>
<p>12 0.15616293 <a title="164-tfidf-12" href="./nips-2012-Globally_Convergent_Dual_MAP_LP_Relaxation_Solvers_using_Fenchel-Young_Margins.html">143 nips-2012-Globally Convergent Dual MAP LP Relaxation Solvers using Fenchel-Young Margins</a></p>
<p>13 0.15459678 <a title="164-tfidf-13" href="./nips-2012-Convergence_Rate_Analysis_of_MAP_Coordinate_Minimization_Algorithms.html">84 nips-2012-Convergence Rate Analysis of MAP Coordinate Minimization Algorithms</a></p>
<p>14 0.14036956 <a title="164-tfidf-14" href="./nips-2012-Simultaneously_Leveraging_Output_and_Task_Structures_for_Multiple-Output_Regression.html">312 nips-2012-Simultaneously Leveraging Output and Task Structures for Multiple-Output Regression</a></p>
<p>15 0.12555261 <a title="164-tfidf-15" href="./nips-2012-Stochastic_Gradient_Descent_with_Only_One_Projection.html">324 nips-2012-Stochastic Gradient Descent with Only One Projection</a></p>
<p>16 0.12055304 <a title="164-tfidf-16" href="./nips-2012-Finite_Sample_Convergence_Rates_of_Zero-Order_Stochastic_Optimization_Methods.html">134 nips-2012-Finite Sample Convergence Rates of Zero-Order Stochastic Optimization Methods</a></p>
<p>17 0.11891779 <a title="164-tfidf-17" href="./nips-2012-Stochastic_optimization_and_sparse_statistical_recovery%3A_Optimal_algorithms_for_high_dimensions.html">325 nips-2012-Stochastic optimization and sparse statistical recovery: Optimal algorithms for high dimensions</a></p>
<p>18 0.10695244 <a title="164-tfidf-18" href="./nips-2012-On_the_Sample_Complexity_of_Robust_PCA.html">254 nips-2012-On the Sample Complexity of Robust PCA</a></p>
<p>19 0.10186707 <a title="164-tfidf-19" href="./nips-2012-Fused_sparsity_and_robust_estimation_for_linear_models_with_unknown_variance.html">139 nips-2012-Fused sparsity and robust estimation for linear models with unknown variance</a></p>
<p>20 0.1013901 <a title="164-tfidf-20" href="./nips-2012-Dual-Space_Analysis_of_the_Sparse_Linear_Model.html">104 nips-2012-Dual-Space Analysis of the Sparse Linear Model</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.25), (1, -0.02), (2, 0.165), (3, -0.082), (4, 0.121), (5, 0.18), (6, -0.119), (7, 0.027), (8, 0.041), (9, 0.1), (10, 0.028), (11, -0.046), (12, 0.061), (13, -0.1), (14, 0.156), (15, 0.031), (16, -0.025), (17, 0.125), (18, 0.004), (19, 0.092), (20, 0.078), (21, -0.074), (22, -0.108), (23, 0.083), (24, 0.063), (25, -0.11), (26, -0.03), (27, -0.128), (28, 0.019), (29, -0.04), (30, -0.096), (31, 0.079), (32, -0.095), (33, -0.075), (34, -0.099), (35, 0.001), (36, -0.077), (37, 0.078), (38, 0.087), (39, 0.068), (40, -0.025), (41, -0.031), (42, -0.064), (43, 0.102), (44, 0.075), (45, -0.044), (46, -0.045), (47, 0.041), (48, -0.062), (49, 0.022)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.91872251 <a title="164-lsi-1" href="./nips-2012-Iterative_Thresholding_Algorithm_for_Sparse_Inverse_Covariance_Estimation.html">164 nips-2012-Iterative Thresholding Algorithm for Sparse Inverse Covariance Estimation</a></p>
<p>2 0.79308122 <a title="164-lsi-2" href="./nips-2012-Newton-Like_Methods_for_Sparse_Inverse_Covariance_Estimation.html">240 nips-2012-Newton-Like Methods for Sparse Inverse Covariance Estimation</a></p>
<p>3 0.70721823 <a title="164-lsi-3" href="./nips-2012-Sparse_Prediction_with_the_%24k%24-Support_Norm.html">319 nips-2012-Sparse Prediction with the $k$-Support Norm</a></p>
<p>4 0.66662329 <a title="164-lsi-4" href="./nips-2012-Feature_Clustering_for_Accelerating_Parallel_Coordinate_Descent.html">131 nips-2012-Feature Clustering for Accelerating Parallel Coordinate Descent</a></p>
<p>5 0.64445579 <a title="164-lsi-5" href="./nips-2012-A_Convex_Formulation_for_Learning_Scale-Free_Networks_via_Submodular_Relaxation.html">6 nips-2012-A Convex Formulation for Learning Scale-Free Networks via Submodular Relaxation</a></p>
<p>6 0.63977718 <a title="164-lsi-6" href="./nips-2012-A_Divide-and-Conquer_Method_for_Sparse_Inverse_Covariance_Estimation.html">7 nips-2012-A Divide-and-Conquer Method for Sparse Inverse Covariance Estimation</a></p>
<p>7 0.63759798 <a title="164-lsi-7" href="./nips-2012-Simultaneously_Leveraging_Output_and_Task_Structures_for_Multiple-Output_Regression.html">312 nips-2012-Simultaneously Leveraging Output and Task Structures for Multiple-Output Regression</a></p>
<p>8 0.6031034 <a title="164-lsi-8" href="./nips-2012-Proximal_Newton-type_methods_for_convex_optimization.html">282 nips-2012-Proximal Newton-type methods for convex optimization</a></p>
<p>9 0.59791064 <a title="164-lsi-9" href="./nips-2012-Convergence_Rate_Analysis_of_MAP_Coordinate_Minimization_Algorithms.html">84 nips-2012-Convergence Rate Analysis of MAP Coordinate Minimization Algorithms</a></p>
<p>10 0.5929262 <a title="164-lsi-10" href="./nips-2012-A_quasi-Newton_proximal_splitting_method.html">27 nips-2012-A quasi-Newton proximal splitting method</a></p>
<p>11 0.56241167 <a title="164-lsi-11" href="./nips-2012-Fused_sparsity_and_robust_estimation_for_linear_models_with_unknown_variance.html">139 nips-2012-Fused sparsity and robust estimation for linear models with unknown variance</a></p>
<p>12 0.55615473 <a title="164-lsi-12" href="./nips-2012-Globally_Convergent_Dual_MAP_LP_Relaxation_Solvers_using_Fenchel-Young_Margins.html">143 nips-2012-Globally Convergent Dual MAP LP Relaxation Solvers using Fenchel-Young Margins</a></p>
<p>13 0.55568182 <a title="164-lsi-13" href="./nips-2012-Factoring_nonnegative_matrices_with_linear_programs.html">125 nips-2012-Factoring nonnegative matrices with linear programs</a></p>
<p>14 0.55397522 <a title="164-lsi-14" href="./nips-2012-Multi-Stage_Multi-Task_Feature_Learning.html">221 nips-2012-Multi-Stage Multi-Task Feature Learning</a></p>
<p>15 0.54926074 <a title="164-lsi-15" href="./nips-2012-Accelerated_Training_for_Matrix-norm_Regularization%3A_A_Boosting_Approach.html">29 nips-2012-Accelerated Training for Matrix-norm Regularization: A Boosting Approach</a></p>
<p>16 0.54525924 <a title="164-lsi-16" href="./nips-2012-Learning_the_Dependency_Structure_of_Latent_Factors.html">192 nips-2012-Learning the Dependency Structure of Latent Factors</a></p>
<p>17 0.54267865 <a title="164-lsi-17" href="./nips-2012-Structured_Learning_of_Gaussian_Graphical_Models.html">327 nips-2012-Structured Learning of Gaussian Graphical Models</a></p>
<p>18 0.53651291 <a title="164-lsi-18" href="./nips-2012-Convex_Multi-view_Subspace_Learning.html">86 nips-2012-Convex Multi-view Subspace Learning</a></p>
<p>19 0.53449917 <a title="164-lsi-19" href="./nips-2012-Optimal_Regularized_Dual_Averaging_Methods_for_Stochastic_Optimization.html">263 nips-2012-Optimal Regularized Dual Averaging Methods for Stochastic Optimization</a></p>
<p>20 0.53129447 <a title="164-lsi-20" href="./nips-2012-Matrix_reconstruction_with_the_local_max_norm.html">208 nips-2012-Matrix reconstruction with the local max norm</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(11, 0.062), (47, 0.183), (67, 0.082), (70, 0.057), (85, 0.067), (94, 0.139), (96, 0.274), (99, 0.062)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.84506845 <a title="164-lda-1" href="./nips-2012-Angular_Quantization-based_Binary_Codes_for_Fast_Similarity_Search.html">42 nips-2012-Angular Quantization-based Binary Codes for Fast Similarity Search</a></p>
<p>same-paper 2 0.77980286 <a title="164-lda-2" href="./nips-2012-Iterative_Thresholding_Algorithm_for_Sparse_Inverse_Covariance_Estimation.html">164 nips-2012-Iterative Thresholding Algorithm for Sparse Inverse Covariance Estimation</a></p>
<p>3 0.7600497 <a title="164-lda-3" href="./nips-2012-Fast_Bayesian_Inference_for_Non-Conjugate_Gaussian_Process_Regression.html">127 nips-2012-Fast Bayesian Inference for Non-Conjugate Gaussian Process Regression</a></p>
<p>4 0.75532204 <a title="164-lda-4" href="./nips-2012-Forging_The_Graphs%3A_A_Low_Rank_and_Positive_Semidefinite_Graph_Learning_Approach.html">135 nips-2012-Forging The Graphs: A Low Rank and Positive Semidefinite Graph Learning Approach</a></p>
<p>5 0.74921554 <a title="164-lda-5" href="./nips-2012-Clustering_Aggregation_as_Maximum-Weight_Independent_Set.html">68 nips-2012-Clustering Aggregation as Maximum-Weight Independent Set</a></p>
<p>6 0.7397064 <a title="164-lda-6" href="./nips-2012-Super-Bit_Locality-Sensitive_Hashing.html">329 nips-2012-Super-Bit Locality-Sensitive Hashing</a></p>
<p>7 0.72238266 <a title="164-lda-7" href="./nips-2012-Isotropic_Hashing.html">163 nips-2012-Isotropic Hashing</a></p>
<p>8 0.70032835 <a title="164-lda-8" href="./nips-2012-Dual-Space_Analysis_of_the_Sparse_Linear_Model.html">104 nips-2012-Dual-Space Analysis of the Sparse Linear Model</a></p>
<p>9 0.69877815 <a title="164-lda-9" href="./nips-2012-Topology_Constraints_in_Graphical_Models.html">346 nips-2012-Topology Constraints in Graphical Models</a></p>
<p>10 0.69858646 <a title="164-lda-10" href="./nips-2012-Newton-Like_Methods_for_Sparse_Inverse_Covariance_Estimation.html">240 nips-2012-Newton-Like Methods for Sparse Inverse Covariance Estimation</a></p>
<p>11 0.69683897 <a title="164-lda-11" href="./nips-2012-Projection_Retrieval_for_Classification.html">279 nips-2012-Projection Retrieval for Classification</a></p>
<p>12 0.69610929 <a title="164-lda-12" href="./nips-2012-Multimodal_Learning_with_Deep_Boltzmann_Machines.html">229 nips-2012-Multimodal Learning with Deep Boltzmann Machines</a></p>
<p>13 0.69496131 <a title="164-lda-13" href="./nips-2012-Training_sparse_natural_image_models_with_a_fast_Gibbs_sampler_of_an_extended_state_space.html">349 nips-2012-Training sparse natural image models with a fast Gibbs sampler of an extended state space</a></p>
<p>14 0.69418776 <a title="164-lda-14" href="./nips-2012-Learning_Mixtures_of_Tree_Graphical_Models.html">180 nips-2012-Learning Mixtures of Tree Graphical Models</a></p>
<p>15 0.69418323 <a title="164-lda-15" href="./nips-2012-Analyzing_3D_Objects_in_Cluttered_Images.html">40 nips-2012-Analyzing 3D Objects in Cluttered Images</a></p>
<p>16 0.69418091 <a title="164-lda-16" href="./nips-2012-Learning_with_Target_Prior.html">198 nips-2012-Learning with Target Prior</a></p>
<p>17 0.69316036 <a title="164-lda-17" href="./nips-2012-Learning_to_Align_from_Scratch.html">193 nips-2012-Learning to Align from Scratch</a></p>
<p>18 0.69301218 <a title="164-lda-18" href="./nips-2012-Bayesian_Probabilistic_Co-Subspace_Addition.html">54 nips-2012-Bayesian Probabilistic Co-Subspace Addition</a></p>
<p>19 0.69228584 <a title="164-lda-19" href="./nips-2012-Repulsive_Mixtures.html">294 nips-2012-Repulsive Mixtures</a></p>
<p>20 0.69189835 <a title="164-lda-20" href="./nips-2012-Image_Denoising_and_Inpainting_with_Deep_Neural_Networks.html">159 nips-2012-Image Denoising and Inpainting with Deep Neural Networks</a></p>
<br/><br/><br/></body>
</html>
