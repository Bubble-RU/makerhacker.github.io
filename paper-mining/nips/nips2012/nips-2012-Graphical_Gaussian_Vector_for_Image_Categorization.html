<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>146 nips-2012-Graphical Gaussian Vector for Image Categorization</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-146" href="#">nips2012-146</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>146 nips-2012-Graphical Gaussian Vector for Image Categorization</h1>
<br/><p>Source: <a title="nips-2012-146-pdf" href="http://papers.nips.cc/paper/4708-graphical-gaussian-vector-for-image-categorization.pdf">pdf</a></p><p>Author: Tatsuya Harada, Yasuo Kuniyoshi</p><p>Abstract: This paper proposes a novel image representation called a Graphical Gaussian Vector (GGV), which is a counterpart of the codebook and local feature matching approaches. We model the distribution of local features as a Gaussian Markov Random Field (GMRF) which can efﬁciently represent the spatial relationship among local features. Using concepts of information geometry, proper parameters and a metric from the GMRF can be obtained. Then we deﬁne a new image feature by embedding the proper metric into the parameters, which can be directly applied to scalable linear classiﬁers. We show that the GGV obtains better performance over the state-of-the-art methods in the standard object recognition datasets and comparable performance in the scene dataset. 1</p><p>Reference: <a title="nips-2012-146-reference" href="../nips2012_reference/nips-2012-Graphical_Gaussian_Vector_for_Image_Categorization_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 jp  Abstract This paper proposes a novel image representation called a Graphical Gaussian Vector (GGV), which is a counterpart of the codebook and local feature matching approaches. [sent-11, score-0.327]
</p><p>2 We model the distribution of local features as a Gaussian Markov Random Field (GMRF) which can efﬁciently represent the spatial relationship among local features. [sent-12, score-0.379]
</p><p>3 Using concepts of information geometry, proper parameters and a metric from the GMRF can be obtained. [sent-13, score-0.111]
</p><p>4 Then we deﬁne a new image feature by embedding the proper metric into the parameters, which can be directly applied to scalable linear classiﬁers. [sent-14, score-0.292]
</p><p>5 1  Introduction  The Bag of Words (BoW) [7] is the de facto standard image feature for the image categorization. [sent-16, score-0.3]
</p><p>6 In a BoW, each local feature is assigned to the nearest codeword and an image is represented by a histogram of the quantized features. [sent-17, score-0.293]
</p><p>7 While it is well established that using a large number of codewords improves classiﬁcation performance, the drawback is that assigning local features to the nearest codeword is computationally expensive. [sent-19, score-0.228]
</p><p>8 To overcome this problem, some studies have proposed building an efﬁcient image representation with a smaller number of codewords [22], [24]. [sent-20, score-0.155]
</p><p>9 Finding an explicit correspondence between local features is another way of categorizing images using a BoW [4], [12], [26], and this approach has been improved by representing a spatial layout of local features as a graph [11], [2], [16], [8]. [sent-21, score-0.569]
</p><p>10 Explicit correspondences between features have an advantage over a BoW as information loss in the vector quantization can be avoided. [sent-22, score-0.077]
</p><p>11 Therefore, the aim of our research is to build an efﬁcient image representation without using codewords or explicit correspondences between local features, while still achieving high classiﬁcation accuracy. [sent-24, score-0.244]
</p><p>12 Since having a spatial layout of local features is important for an image to have semantic meaning, it is natural that embedding spatial information into an image feature improves classiﬁcation performance [18], [5], [14], [17]. [sent-25, score-0.742]
</p><p>13 Several approaches take advantage of this fact, ranging from local (e. [sent-26, score-0.105]
</p><p>14 Meanwhile, we will focus on the spatial layout of local features, which is the midlevel of the spatial information. [sent-31, score-0.351]
</p><p>15 In this paper, we model an image as a graph representing the spatial layout of local features and deﬁne a new image feature based on this graph, where a proper metric is embedded into the feature. [sent-32, score-0.735]
</p><p>16 Speciﬁcally, we model an image as a Gaussian Markov Random Field (GMRF) whose nodes correspond to local features and consider the GMRF parameters as the image feature. [sent-34, score-0.428]
</p><p>17 Although the GMRF is commonly used for image segmentation, it is rarely used in modern image categorization pipelines despite being an effective way of modeling the spatial layout. [sent-35, score-0.36]
</p><p>18 In order to extract the repre1  sentative feature vector from the GMRF, the choice of coordinates for the parameters and the metric between them needs to be carefully made. [sent-36, score-0.137]
</p><p>19 We deﬁne the proper coordinates and the metric from an information geometry standpoint [1] and derive an optimal feature vector. [sent-37, score-0.166]
</p><p>20 The contributions of this study are summarized as follows: 1) A novel and efﬁcient image feature is developed by utilizing the GMRF as a tool for object categorization. [sent-39, score-0.198]
</p><p>21 3) Using standard image categorization benchmarks, we demonstrate that the proposed feature has better performance over the state-of-the-art methods, even though it is not based on mainstream modules (such as codebooks and correspondence between local features). [sent-41, score-0.331]
</p><p>22 To the best of our knowledge, this is the ﬁrst image feature for the object categorization that utilizes the expectation parameters of the GMRF with its Fisher information metric, and achieves a level of accuracy comparable to that of the codebook and local feature matching approaches. [sent-42, score-0.537]
</p><p>23 ξ2  Figure 1: Overview of image feature extraction based on a multivariate GMRF. [sent-45, score-0.192]
</p><p>24 Initially, local features {xi ∈ Rd }M are i=1 extracted using a dense sampling strategy (Fig. [sent-47, score-0.182]
</p><p>25 We then use a multivariate GMRF to model the spatial relationships among local features (Fig. [sent-49, score-0.298]
</p><p>26 The GMRF is represented as a graph G(V, E), whose vertices V and edges E correspond to local features and the dependent relationships between those features, respectively. [sent-51, score-0.241]
</p><p>27 Let the vector x be a concatenation of local features in V and let ξ j be a parameter of the GMRF of an image Ij , the image Ij can be represented by a probability distribution p(x; ξ j ) of the GMRF (Fig. [sent-52, score-0.408]
</p><p>28 We consider the parameter ξj of the GMRF to be a feature vector of the image Ij (Fig. [sent-54, score-0.168]
</p><p>29 However, because the space spanned by parameters of a probability distribution is not a Euclidean space, we have to be very careful when choosing parameters for the probability distribution and the metric among them. [sent-58, score-0.123]
</p><p>30 We make use of concepts from the information geometry [1] and extract proper parameters and a metric from the GMRF. [sent-59, score-0.131]
</p><p>31 Finally, we deﬁne the new image feature by embedding the metric into the extracted parameters to build an image categorization system with a scalable linear classiﬁer. [sent-60, score-0.438]
</p><p>32 2  Image Model and Parameters  Given M local features {xi ∈ Rd }M , the aim is to model a probability distribution of the local i=1 features representing the spatial layout of the image using the multivariate GMRF G = (V, E). [sent-63, score-0.655]
</p><p>33 First, a vector x is built by concatenating the local features corresponding to the vertices V of the GMRF. [sent-64, score-0.235]
</p><p>34 Let {xi }n are local features that we are focusing on, we obtain the concatenated vector as i=1 x = (x1 · · · xn ) (e. [sent-65, score-0.182]
</p><p>35 Note that the dimensionality of x is nd and does not depend on the number of local features M , the image size, or the aspect ratio. [sent-69, score-0.378]
</p><p>36 However, since all results valid for a scalar local feature are also valid for a multivariate local feature, in this section we consider the dimensionality of local features is 1 (d = 1) for simplicity. [sent-70, score-0.554]
</p><p>37 The expectation parameters are obtained as [15]: ηi = μi , ηii = Pii + μ2 , ηjk = Pjk + μj μk , (i ∈ V, {j, k} ∈ E). [sent-77, score-0.083]
</p><p>38 (4) i The natural and expectation parameters can be transformed into each other [1]. [sent-78, score-0.083]
</p><p>39 If we take the natural parameters or the expectation parameters as a coordinate system for an exponential family, a ﬂat structure can be realized [1]. [sent-81, score-0.124]
</p><p>40 Those spaces are similar to a Euclidean space, but we need to be careful that the spaces spanned by the natural or expectation parameters are different from a Euclidean space, as the metrics vary for different parameters. [sent-84, score-0.104]
</p><p>41 To summarize this section, the natural and expectation parameters are similar and interchangeable through the FIMs. [sent-89, score-0.083]
</p><p>42 Although it does not matter whether we choose natural or expectation parameters, we use expectation parameters (Eq. [sent-91, score-0.146]
</p><p>43 (4)) as feature vectors because they can be calculated directly from the mean and covariance of local features. [sent-92, score-0.183]
</p><p>44 3  Calculation of Expectation Parameters  In this section, we describe the calculations of the expectation parameters of the multivariate GMRF. [sent-95, score-0.124]
</p><p>45 While a graph having more neighbors is obviously able to represent richer spatial information, the compact structure is preferable for efﬁciency. [sent-101, score-0.119]
</p><p>46 2(c), which represents the vertical and horizontal relationships among local features, and Fig. [sent-103, score-0.138]
</p><p>47 rk + a 2 rk + a 3 rk + a 4 rk + a 2 rk + a1 rk  (a)  (b)  rk + a1 rk  (c)  (d)  Figure 2: Structures of the GMRF. [sent-105, score-0.432]
</p><p>48 Next, we show a method for estimating the expectation parameters of each image. [sent-106, score-0.083]
</p><p>49 (4) in a multivariate case can be determined by calculating the local auto-correlations of local 3  features. [sent-108, score-0.234]
</p><p>50 Let x(r k ) ∈ Rd be the local feature at a reference point rk and let ai and aj be the displacement vectors, which are deﬁned by the structure of the GMRF. [sent-112, score-0.252]
</p><p>51 Then, the local auto-correlation matrices 1 are obtained as: Ci,j = NJ k∈J x(r k +ai )x(r k +aj ) , where NJ is the number of local features 1 in the image region J. [sent-113, score-0.4]
</p><p>52 Let a vector concatenating local features in the vertices at the reference point rk be xk = (x(r k ) x(r k + a1 ) x(r k + a2 ) ), P + μμ is calculated to be: P + μμ =  1 NJ  xk xk = k∈J  C0,0 C1,0 C2,0  C0,1 C1,1 C2,1  C0,2 C1,2 C2,2  . [sent-115, score-0.312]
</p><p>53 (5)  The expectation parameters of the GMRF depicted in Fig. [sent-116, score-0.083]
</p><p>54 Note that C1,2 is omitted, because there is no edge between the vertices at rk + a1 and rk + a2 . [sent-118, score-0.14]
</p><p>55 The dimensionality of η is: nd + n(d + 1)d/2 + (n − 1)d2 , where d is the dimensionality of the local feature. [sent-121, score-0.271]
</p><p>56 2(e)), if we have enough local features, the means {μi }n−1 i=0 and covariance matrices {Ci,i }n−1 of local features in the region J come to the vector μ0 and matrix i=0 C0,0 , respectively. [sent-124, score-0.287]
</p><p>57 We now derive a metric between the expectation parameters [1]. [sent-138, score-0.145]
</p><p>58 (8)  Thus, the FIM is a proper metric for the feature vectors (the expectation parameters) obtained from the GMRF. [sent-144, score-0.209]
</p><p>59 5  Implementation of Graphical Gaussian Vector  At ﬁrst, we build the concatenated vector as x = (x1 · · · xn ) , where each xi corresponds to the local feature of the vertex i. [sent-149, score-0.16]
</p><p>60 The dimensionality of the local features is 2 (x = (x1 , x2 ) , y = (y1 , y2 ) , z = (z1 , z2 ) ). [sent-151, score-0.265]
</p><p>61 A vector concatenating the local features in V is v = (x1 , x2 , y1 , y2 , z1 , z2 ) . [sent-152, score-0.203]
</p><p>62 Using μ and J, the Fisher information matrix of the full Gaussian family can be calculated as in (b), whose rows and columns correspond to the elements of the expectation parameters. [sent-154, score-0.086]
</p><p>63 In order to embed the proper metric into the expectation parameters, we multiply G∗ (η c )1/2 by η: ζ=  ∗ ∗ ∗ FG,G (η c ) − FG,\G (η c ) F\G,\G (η c )  −1  ∗ F\G,G (η c )  1/2  η. [sent-169, score-0.174]
</p><p>64 In practice, since using all training data is infeasible to estimate the FIM, we use a subset of local features randomly sampled from training data. [sent-176, score-0.182]
</p><p>65 Input: An image region J, and the Fisher information matrix of the GMRF G∗ (η c ) Output: GGV ζ 1. [sent-179, score-0.113]
</p><p>66 Calculate local auto-correlations of local features: 1 1 μi = NJ k∈J x(r k + ai ), Ci,j = NJ k∈J x(r k + ai )x(r k + aj ) 2. [sent-180, score-0.269]
</p><p>67 Embed the Fisher information metric into the expectation parameters: 1/2 ζ = (G∗ (η c )) η  3  Experiment  We tested our method on the standard object and scene datasets (Caltech101, Caltech256, and 15-Scenes). [sent-182, score-0.178]
</p><p>68 2(c) (GGV, n = 3), which models a horizontal and vertical spatial layout of the local features. [sent-190, score-0.292]
</p><p>69 2(d) (GGV, n = 5), which adds diagonal spatial layouts of the features ˆ to Fig. [sent-192, score-0.169]
</p><p>70 To embed the global spatial information, we used the spatial pyramid representation with a 1 × 1 + 2 × 2 + 3 × 3 pyramid structure. [sent-197, score-0.293]
</p><p>71 Table 1: The relationships between GLC, LAC, GG, and GGV in terms of spatial information and Fisher information metrics. [sent-198, score-0.092]
</p><p>72 Method GLC LAC GG GGV (proposed)  Spatial information √ √  Fisher information metric √ √  In the second experiment, we compared GGVs with the Improved Fisher kernel (IFK) [24], [25], which is the best image representation available at the time of writing. [sent-199, score-0.175]
</p><p>73 In this experiment, we used the spatial pyramid representation with a 1 × 1 + 2 × 2 + 3 × 1 structure. [sent-200, score-0.128]
</p><p>74 For all datasets, SIFT features were densely sampled and were described for 16 × 16 patches. [sent-203, score-0.077]
</p><p>75 As the aforementioned features depend on the dimensionality of the local feature, we reduced its dimensionality using PCA and compared performance as a function of its new dimensionality. [sent-205, score-0.348]
</p><p>76 Before comparison between GGVs and the baselines, we evaluate the sensitivities of the sampling step of local features. [sent-212, score-0.105]
</p><p>77 The sampling step is one of the important parameters of GGV, because GGV calculates auto-correlations of the neighboring local features. [sent-213, score-0.125]
</p><p>78 In this preliminary experiment, we ﬁx the number of vertices is 5 (n = 5) and the dimensionality of local feature is 32. [sent-214, score-0.275]
</p><p>79 Therefore in the following experiments, we use 6 pixels sampling step for local feature extraction. [sent-224, score-0.186]
</p><p>80 Figure 4 (left) shows the classiﬁcation accuracies as a function of the dimensionality of the local features. [sent-225, score-0.225]
</p><p>81 A large dimensionality yielded better performance, and the proposed method (GGV) outperformed the other methods (GLC, LAC, and GG). [sent-226, score-0.099]
</p><p>82 By comparing GGV with LAC, and GG with GLC, it is clear that embedding the Fisher information metric improved the classiﬁcation accuracy signiﬁcantly. [sent-227, score-0.095]
</p><p>83 By comparing GGV with GG, as well as LAC with GLC, it can also be seen that embedding the spatial layout of local features also improved the accuracy. [sent-228, score-0.369]
</p><p>84 4 (right) shows the classiﬁcation accuracy as a function of the dimensionality of the image features which are converted from the results shown in Fig. [sent-238, score-0.273]
</p><p>85 We see that GGVs achieved higher accuracy for a lower dimensionality of image features. [sent-240, score-0.196]
</p><p>86 3 % when the dimensionality of the local feature is 32 and the number of vertices is 5. [sent-246, score-0.275]
</p><p>87 5 (center) and (right) show comparisons of the L2 normalized GGVs and IFKs using the Caltech256 dataset with respect to the dimensionality of local features and image features, respectively. [sent-256, score-0.378]
</p><p>88 It is known that using multi-scale local features improves classiﬁcation accuracies (e. [sent-264, score-0.219]
</p><p>89 In the second experiment, the results with respect to the dimensionality of local features and image features are shown in Figs. [sent-280, score-0.455]
</p><p>90 As the leading method, the spatial Fisher kernel [17] reported the highest score (88. [sent-285, score-0.092]
</p><p>91 4  Conclusion  In this paper, we proposed an efﬁcient image feature called a Graphical Gaussian Vector, which uses neither codebook nor local feature matching. [sent-288, score-0.377]
</p><p>92 In the proposed method, spatial information about local features and the Fisher information metric are embedded into a feature by modeling the image as the Gaussian Markov Random Field (GMRF). [sent-289, score-0.52]
</p><p>93 The proposed image feature calculates the expectation parameters of the GMRF simply and effectively while maintaining a high classiﬁcation rate. [sent-291, score-0.267]
</p><p>94 Improving local descriptors by embedding global and local spatial information. [sent-385, score-0.373]
</p><p>95 Asymmetric region-to-image matching for comparing images with generic object categories. [sent-394, score-0.075]
</p><p>96 Modeling spatial layout with ﬁsher vectors for image categorization. [sent-400, score-0.267]
</p><p>97 Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories. [sent-406, score-0.096]
</p><p>98 Global gaussian approach for scene categorization using information geometry. [sent-418, score-0.091]
</p><p>99 Linear spatial pyramid matching using sparse coding for image classiﬁcation. [sent-469, score-0.262]
</p><p>100 Image classiﬁcation using super-vector coding of local image descriptors. [sent-477, score-0.218]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ggv', 0.683), ('ifk', 0.41), ('gmrf', 0.283), ('fim', 0.174), ('glc', 0.161), ('lac', 0.149), ('gg', 0.141), ('ggvs', 0.124), ('image', 0.113), ('local', 0.105), ('mgmrf', 0.099), ('spatial', 0.092), ('dimensionality', 0.083), ('fisher', 0.079), ('features', 0.077), ('classification', 0.075), ('pq', 0.067), ('expectation', 0.063), ('layout', 0.062), ('harada', 0.062), ('metric', 0.062), ('feature', 0.055), ('fg', 0.054), ('rk', 0.054), ('bow', 0.047), ('sift', 0.046), ('cvpr', 0.043), ('norm', 0.042), ('categorization', 0.042), ('classi', 0.04), ('accuracies', 0.037), ('ifks', 0.037), ('jpr', 0.037), ('nakayama', 0.037), ('pyramid', 0.036), ('pp', 0.035), ('calculation', 0.035), ('nj', 0.034), ('embedding', 0.033), ('codebook', 0.033), ('ij', 0.033), ('vertices', 0.032), ('auto', 0.03), ('object', 0.03), ('scored', 0.029), ('proper', 0.029), ('field', 0.028), ('graph', 0.027), ('perronnin', 0.027), ('rr', 0.027), ('gaussian', 0.026), ('eccv', 0.026), ('codewords', 0.026), ('pixels', 0.026), ('center', 0.025), ('csurka', 0.025), ('fgg', 0.025), ('hongo', 0.025), ('jkp', 0.025), ('jpi', 0.025), ('multivariate', 0.024), ('images', 0.024), ('calculated', 0.023), ('scene', 0.023), ('tokyo', 0.023), ('fifteen', 0.022), ('dance', 0.022), ('spanned', 0.021), ('matching', 0.021), ('ai', 0.021), ('concatenating', 0.021), ('descriptors', 0.021), ('graphical', 0.021), ('coordinate', 0.021), ('jij', 0.02), ('nchez', 0.02), ('submatrices', 0.02), ('codeword', 0.02), ('vocabularies', 0.02), ('embed', 0.02), ('correlation', 0.02), ('fergus', 0.02), ('parameters', 0.02), ('geometry', 0.02), ('jk', 0.019), ('facto', 0.019), ('gij', 0.018), ('visual', 0.018), ('cation', 0.018), ('calculations', 0.017), ('llc', 0.017), ('sher', 0.017), ('gmms', 0.017), ('aj', 0.017), ('global', 0.017), ('vertical', 0.017), ('horizontal', 0.016), ('rate', 0.016), ('bags', 0.016), ('proposed', 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999988 <a title="146-tfidf-1" href="./nips-2012-Graphical_Gaussian_Vector_for_Image_Categorization.html">146 nips-2012-Graphical Gaussian Vector for Image Categorization</a></p>
<p>Author: Tatsuya Harada, Yasuo Kuniyoshi</p><p>Abstract: This paper proposes a novel image representation called a Graphical Gaussian Vector (GGV), which is a counterpart of the codebook and local feature matching approaches. We model the distribution of local features as a Gaussian Markov Random Field (GMRF) which can efﬁciently represent the spatial relationship among local features. Using concepts of information geometry, proper parameters and a metric from the GMRF can be obtained. Then we deﬁne a new image feature by embedding the proper metric into the parameters, which can be directly applied to scalable linear classiﬁers. We show that the GGV obtains better performance over the state-of-the-art methods in the standard object recognition datasets and comparable performance in the scene dataset. 1</p><p>2 0.066536166 <a title="146-tfidf-2" href="./nips-2012-Deep_Representations_and_Codes_for_Image_Auto-Annotation.html">92 nips-2012-Deep Representations and Codes for Image Auto-Annotation</a></p>
<p>Author: Ryan Kiros, Csaba Szepesvári</p><p>Abstract: The task of image auto-annotation, namely assigning a set of relevant tags to an image, is challenging due to the size and variability of tag vocabularies. Consequently, most existing algorithms focus on tag assignment and ﬁx an often large number of hand-crafted features to describe image characteristics. In this paper we introduce a hierarchical model for learning representations of standard sized color images from the pixel level, removing the need for engineered feature representations and subsequent feature selection for annotation. We benchmark our model on the STL-10 recognition dataset, achieving state-of-the-art performance. When our features are combined with TagProp (Guillaumin et al.), we compete with or outperform existing annotation approaches that use over a dozen distinct handcrafted image descriptors. Furthermore, using 256-bit codes and Hamming distance for training TagProp, we exchange only a small reduction in performance for efﬁcient storage and fast comparisons. Self-taught learning is used in all of our experiments and deeper architectures always outperform shallow ones. 1</p><p>3 0.0623735 <a title="146-tfidf-3" href="./nips-2012-Learning_Image_Descriptors_with_the_Boosting-Trick.html">176 nips-2012-Learning Image Descriptors with the Boosting-Trick</a></p>
<p>Author: Tomasz Trzcinski, Mario Christoudias, Vincent Lepetit, Pascal Fua</p><p>Abstract: In this paper we apply boosting to learn complex non-linear local visual feature representations, drawing inspiration from its successful application to visual object detection. The main goal of local feature descriptors is to distinctively represent a salient image region while remaining invariant to viewpoint and illumination changes. This representation can be improved using machine learning, however, past approaches have been mostly limited to learning linear feature mappings in either the original input or a kernelized input feature space. While kernelized methods have proven somewhat effective for learning non-linear local feature descriptors, they rely heavily on the choice of an appropriate kernel function whose selection is often difﬁcult and non-intuitive. We propose to use the boosting-trick to obtain a non-linear mapping of the input to a high-dimensional feature space. The non-linear feature mapping obtained with the boosting-trick is highly intuitive. We employ gradient-based weak learners resulting in a learned descriptor that closely resembles the well-known SIFT. As demonstrated in our experiments, the resulting descriptor can be learned directly from intensity patches achieving state-of-the-art performance. 1</p><p>4 0.057768479 <a title="146-tfidf-4" href="./nips-2012-Unsupervised_Template_Learning_for_Fine-Grained_Object_Recognition.html">357 nips-2012-Unsupervised Template Learning for Fine-Grained Object Recognition</a></p>
<p>Author: Shulin Yang, Liefeng Bo, Jue Wang, Linda G. Shapiro</p><p>Abstract: Fine-grained recognition refers to a subordinate level of recognition, such as recognizing different species of animals and plants. It differs from recognition of basic categories, such as humans, tables, and computers, in that there are global similarities in shape and structure shared cross different categories, and the differences are in the details of object parts. We suggest that the key to identifying the ﬁne-grained differences lies in ﬁnding the right alignment of image regions that contain the same object parts. We propose a template model for the purpose, which captures common shape patterns of object parts, as well as the cooccurrence relation of the shape patterns. Once the image regions are aligned, extracted features are used for classiﬁcation. Learning of the template model is efﬁcient, and the recognition results we achieve signiﬁcantly outperform the stateof-the-art algorithms. 1</p><p>5 0.05553114 <a title="146-tfidf-5" href="./nips-2012-Parametric_Local_Metric_Learning_for_Nearest_Neighbor_Classification.html">265 nips-2012-Parametric Local Metric Learning for Nearest Neighbor Classification</a></p>
<p>Author: Jun Wang, Alexandros Kalousis, Adam Woznica</p><p>Abstract: We study the problem of learning local metrics for nearest neighbor classiﬁcation. Most previous works on local metric learning learn a number of local unrelated metrics. While this ”independence” approach delivers an increased ﬂexibility its downside is the considerable risk of overﬁtting. We present a new parametric local metric learning method in which we learn a smooth metric matrix function over the data manifold. Using an approximation error bound of the metric matrix function we learn local metrics as linear combinations of basis metrics deﬁned on anchor points over different regions of the instance space. We constrain the metric matrix function by imposing on the linear combinations manifold regularization which makes the learned metric matrix function vary smoothly along the geodesics of the data manifold. Our metric learning method has excellent performance both in terms of predictive power and scalability. We experimented with several largescale classiﬁcation problems, tens of thousands of instances, and compared it with several state of the art metric learning methods, both global and local, as well as to SVM with automatic kernel selection, all of which it outperforms in a signiﬁcant manner. 1</p><p>6 0.052864932 <a title="146-tfidf-6" href="./nips-2012-Memorability_of_Image_Regions.html">210 nips-2012-Memorability of Image Regions</a></p>
<p>7 0.052804664 <a title="146-tfidf-7" href="./nips-2012-A_Geometric_take_on_Metric_Learning.html">9 nips-2012-A Geometric take on Metric Learning</a></p>
<p>8 0.049674407 <a title="146-tfidf-8" href="./nips-2012-Visual_Recognition_using_Embedded_Feature_Selection_for_Curvature_Self-Similarity.html">360 nips-2012-Visual Recognition using Embedded Feature Selection for Curvature Self-Similarity</a></p>
<p>9 0.049561922 <a title="146-tfidf-9" href="./nips-2012-Timely_Object_Recognition.html">344 nips-2012-Timely Object Recognition</a></p>
<p>10 0.048088271 <a title="146-tfidf-10" href="./nips-2012-Deep_Learning_of_Invariant_Features_via_Simulated_Fixations_in_Video.html">90 nips-2012-Deep Learning of Invariant Features via Simulated Fixations in Video</a></p>
<p>11 0.047144454 <a title="146-tfidf-11" href="./nips-2012-A_Divide-and-Conquer_Method_for_Sparse_Inverse_Covariance_Estimation.html">7 nips-2012-A Divide-and-Conquer Method for Sparse Inverse Covariance Estimation</a></p>
<p>12 0.046541356 <a title="146-tfidf-12" href="./nips-2012-Learning_with_Recursive_Perceptual_Representations.html">197 nips-2012-Learning with Recursive Perceptual Representations</a></p>
<p>13 0.044354141 <a title="146-tfidf-13" href="./nips-2012-Locally_Uniform_Comparison_Image_Descriptor.html">202 nips-2012-Locally Uniform Comparison Image Descriptor</a></p>
<p>14 0.044016685 <a title="146-tfidf-14" href="./nips-2012-Dynamical_And-Or_Graph_Learning_for_Object_Shape_Modeling_and_Detection.html">106 nips-2012-Dynamical And-Or Graph Learning for Object Shape Modeling and Detection</a></p>
<p>15 0.042947885 <a title="146-tfidf-15" href="./nips-2012-Semi-Crowdsourced_Clustering%3A_Generalizing_Crowd_Labeling_by_Robust_Distance_Metric_Learning.html">307 nips-2012-Semi-Crowdsourced Clustering: Generalizing Crowd Labeling by Robust Distance Metric Learning</a></p>
<p>16 0.042480208 <a title="146-tfidf-16" href="./nips-2012-Graphical_Models_via_Generalized_Linear_Models.html">147 nips-2012-Graphical Models via Generalized Linear Models</a></p>
<p>17 0.041899312 <a title="146-tfidf-17" href="./nips-2012-Sparse_Approximate_Manifolds_for_Differential_Geometric_MCMC.html">318 nips-2012-Sparse Approximate Manifolds for Differential Geometric MCMC</a></p>
<p>18 0.041338395 <a title="146-tfidf-18" href="./nips-2012-Local_Supervised_Learning_through_Space_Partitioning.html">200 nips-2012-Local Supervised Learning through Space Partitioning</a></p>
<p>19 0.040891059 <a title="146-tfidf-19" href="./nips-2012-Volume_Regularization_for_Binary_Classification.html">361 nips-2012-Volume Regularization for Binary Classification</a></p>
<p>20 0.038681429 <a title="146-tfidf-20" href="./nips-2012-Analyzing_3D_Objects_in_Cluttered_Images.html">40 nips-2012-Analyzing 3D Objects in Cluttered Images</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.11), (1, 0.033), (2, -0.072), (3, -0.044), (4, 0.068), (5, -0.032), (6, -0.004), (7, -0.007), (8, 0.016), (9, -0.022), (10, 0.014), (11, -0.013), (12, 0.032), (13, -0.006), (14, -0.011), (15, 0.026), (16, 0.003), (17, -0.018), (18, 0.032), (19, 0.012), (20, 0.014), (21, -0.074), (22, -0.001), (23, -0.007), (24, 0.003), (25, -0.006), (26, -0.002), (27, 0.024), (28, 0.004), (29, 0.026), (30, -0.043), (31, 0.036), (32, 0.001), (33, -0.065), (34, 0.046), (35, 0.061), (36, 0.021), (37, 0.002), (38, 0.006), (39, 0.004), (40, 0.061), (41, -0.035), (42, -0.026), (43, -0.035), (44, 0.068), (45, -0.0), (46, 0.033), (47, 0.006), (48, 0.114), (49, -0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.89260143 <a title="146-lsi-1" href="./nips-2012-Graphical_Gaussian_Vector_for_Image_Categorization.html">146 nips-2012-Graphical Gaussian Vector for Image Categorization</a></p>
<p>Author: Tatsuya Harada, Yasuo Kuniyoshi</p><p>Abstract: This paper proposes a novel image representation called a Graphical Gaussian Vector (GGV), which is a counterpart of the codebook and local feature matching approaches. We model the distribution of local features as a Gaussian Markov Random Field (GMRF) which can efﬁciently represent the spatial relationship among local features. Using concepts of information geometry, proper parameters and a metric from the GMRF can be obtained. Then we deﬁne a new image feature by embedding the proper metric into the parameters, which can be directly applied to scalable linear classiﬁers. We show that the GGV obtains better performance over the state-of-the-art methods in the standard object recognition datasets and comparable performance in the scene dataset. 1</p><p>2 0.75956106 <a title="146-lsi-2" href="./nips-2012-Learning_Image_Descriptors_with_the_Boosting-Trick.html">176 nips-2012-Learning Image Descriptors with the Boosting-Trick</a></p>
<p>Author: Tomasz Trzcinski, Mario Christoudias, Vincent Lepetit, Pascal Fua</p><p>Abstract: In this paper we apply boosting to learn complex non-linear local visual feature representations, drawing inspiration from its successful application to visual object detection. The main goal of local feature descriptors is to distinctively represent a salient image region while remaining invariant to viewpoint and illumination changes. This representation can be improved using machine learning, however, past approaches have been mostly limited to learning linear feature mappings in either the original input or a kernelized input feature space. While kernelized methods have proven somewhat effective for learning non-linear local feature descriptors, they rely heavily on the choice of an appropriate kernel function whose selection is often difﬁcult and non-intuitive. We propose to use the boosting-trick to obtain a non-linear mapping of the input to a high-dimensional feature space. The non-linear feature mapping obtained with the boosting-trick is highly intuitive. We employ gradient-based weak learners resulting in a learned descriptor that closely resembles the well-known SIFT. As demonstrated in our experiments, the resulting descriptor can be learned directly from intensity patches achieving state-of-the-art performance. 1</p><p>3 0.71313286 <a title="146-lsi-3" href="./nips-2012-Memorability_of_Image_Regions.html">210 nips-2012-Memorability of Image Regions</a></p>
<p>Author: Aditya Khosla, Jianxiong Xiao, Antonio Torralba, Aude Oliva</p><p>Abstract: While long term human visual memory can store a remarkable amount of visual information, it tends to degrade over time. Recent works have shown that image memorability is an intrinsic property of an image that can be reliably estimated using state-of-the-art image features and machine learning algorithms. However, the class of features and image information that is forgotten has not been explored yet. In this work, we propose a probabilistic framework that models how and which local regions from an image may be forgotten using a data-driven approach that combines local and global images features. The model automatically discovers memorability maps of individual images without any human annotation. We incorporate multiple image region attributes in our algorithm, leading to improved memorability prediction of images as compared to previous works. 1</p><p>4 0.6880545 <a title="146-lsi-4" href="./nips-2012-Locally_Uniform_Comparison_Image_Descriptor.html">202 nips-2012-Locally Uniform Comparison Image Descriptor</a></p>
<p>Author: Andrew Ziegler, Eric Christiansen, David Kriegman, Serge J. Belongie</p><p>Abstract: Keypoint matching between pairs of images using popular descriptors like SIFT or a faster variant called SURF is at the heart of many computer vision algorithms including recognition, mosaicing, and structure from motion. However, SIFT and SURF do not perform well for real-time or mobile applications. As an alternative very fast binary descriptors like BRIEF and related methods use pairwise comparisons of pixel intensities in an image patch. We present an analysis of BRIEF and related approaches revealing that they are hashing schemes on the ordinal correlation metric Kendall’s tau. Here, we introduce Locally Uniform Comparison Image Descriptor (LUCID), a simple description method based on linear time permutation distances between the ordering of RGB values of two image patches. LUCID is computable in linear time with respect to the number of pixels and does not require ﬂoating point computation. 1</p><p>5 0.63672328 <a title="146-lsi-5" href="./nips-2012-Deep_Representations_and_Codes_for_Image_Auto-Annotation.html">92 nips-2012-Deep Representations and Codes for Image Auto-Annotation</a></p>
<p>Author: Ryan Kiros, Csaba Szepesvári</p><p>Abstract: The task of image auto-annotation, namely assigning a set of relevant tags to an image, is challenging due to the size and variability of tag vocabularies. Consequently, most existing algorithms focus on tag assignment and ﬁx an often large number of hand-crafted features to describe image characteristics. In this paper we introduce a hierarchical model for learning representations of standard sized color images from the pixel level, removing the need for engineered feature representations and subsequent feature selection for annotation. We benchmark our model on the STL-10 recognition dataset, achieving state-of-the-art performance. When our features are combined with TagProp (Guillaumin et al.), we compete with or outperform existing annotation approaches that use over a dozen distinct handcrafted image descriptors. Furthermore, using 256-bit codes and Hamming distance for training TagProp, we exchange only a small reduction in performance for efﬁcient storage and fast comparisons. Self-taught learning is used in all of our experiments and deeper architectures always outperform shallow ones. 1</p><p>6 0.63470578 <a title="146-lsi-6" href="./nips-2012-Learning_about_Canonical_Views_from_Internet_Image_Collections.html">185 nips-2012-Learning about Canonical Views from Internet Image Collections</a></p>
<p>7 0.60015821 <a title="146-lsi-7" href="./nips-2012-Unsupervised_Template_Learning_for_Fine-Grained_Object_Recognition.html">357 nips-2012-Unsupervised Template Learning for Fine-Grained Object Recognition</a></p>
<p>8 0.59755796 <a title="146-lsi-8" href="./nips-2012-Deep_Neural_Networks_Segment_Neuronal_Membranes_in_Electron_Microscopy_Images.html">91 nips-2012-Deep Neural Networks Segment Neuronal Membranes in Electron Microscopy Images</a></p>
<p>9 0.58495557 <a title="146-lsi-9" href="./nips-2012-Visual_Recognition_using_Embedded_Feature_Selection_for_Curvature_Self-Similarity.html">360 nips-2012-Visual Recognition using Embedded Feature Selection for Curvature Self-Similarity</a></p>
<p>10 0.5638113 <a title="146-lsi-10" href="./nips-2012-Image_Denoising_and_Inpainting_with_Deep_Neural_Networks.html">159 nips-2012-Image Denoising and Inpainting with Deep Neural Networks</a></p>
<p>11 0.55179274 <a title="146-lsi-11" href="./nips-2012-Convolutional-Recursive_Deep_Learning_for_3D_Object_Classification.html">87 nips-2012-Convolutional-Recursive Deep Learning for 3D Object Classification</a></p>
<p>12 0.54665929 <a title="146-lsi-12" href="./nips-2012-ImageNet_Classification_with_Deep_Convolutional_Neural_Networks.html">158 nips-2012-ImageNet Classification with Deep Convolutional Neural Networks</a></p>
<p>13 0.54056036 <a title="146-lsi-13" href="./nips-2012-Discriminatively_Trained_Sparse_Code_Gradients_for_Contour_Detection.html">101 nips-2012-Discriminatively Trained Sparse Code Gradients for Contour Detection</a></p>
<p>14 0.53765863 <a title="146-lsi-14" href="./nips-2012-A_Generative_Model_for_Parts-based_Object_Segmentation.html">8 nips-2012-A Generative Model for Parts-based Object Segmentation</a></p>
<p>15 0.52721435 <a title="146-lsi-15" href="./nips-2012-Searching_for_objects_driven_by_context.html">303 nips-2012-Searching for objects driven by context</a></p>
<p>16 0.50343001 <a title="146-lsi-16" href="./nips-2012-Deep_Learning_of_Invariant_Features_via_Simulated_Fixations_in_Video.html">90 nips-2012-Deep Learning of Invariant Features via Simulated Fixations in Video</a></p>
<p>17 0.49765283 <a title="146-lsi-17" href="./nips-2012-A_systematic_approach_to_extracting_semantic_information_from_functional_MRI_data.html">28 nips-2012-A systematic approach to extracting semantic information from functional MRI data</a></p>
<p>18 0.49114338 <a title="146-lsi-18" href="./nips-2012-Learning_to_Align_from_Scratch.html">193 nips-2012-Learning to Align from Scratch</a></p>
<p>19 0.48680705 <a title="146-lsi-19" href="./nips-2012-Natural_Images%2C_Gaussian_Mixtures_and_Dead_Leaves.html">235 nips-2012-Natural Images, Gaussian Mixtures and Dead Leaves</a></p>
<p>20 0.46835163 <a title="146-lsi-20" href="./nips-2012-Semantic_Kernel_Forests_from_Multiple_Taxonomies.html">306 nips-2012-Semantic Kernel Forests from Multiple Taxonomies</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.024), (21, 0.02), (38, 0.098), (42, 0.05), (54, 0.026), (55, 0.032), (74, 0.101), (76, 0.108), (80, 0.045), (83, 0.333), (92, 0.042)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.68450755 <a title="146-lda-1" href="./nips-2012-Graphical_Gaussian_Vector_for_Image_Categorization.html">146 nips-2012-Graphical Gaussian Vector for Image Categorization</a></p>
<p>Author: Tatsuya Harada, Yasuo Kuniyoshi</p><p>Abstract: This paper proposes a novel image representation called a Graphical Gaussian Vector (GGV), which is a counterpart of the codebook and local feature matching approaches. We model the distribution of local features as a Gaussian Markov Random Field (GMRF) which can efﬁciently represent the spatial relationship among local features. Using concepts of information geometry, proper parameters and a metric from the GMRF can be obtained. Then we deﬁne a new image feature by embedding the proper metric into the parameters, which can be directly applied to scalable linear classiﬁers. We show that the GGV obtains better performance over the state-of-the-art methods in the standard object recognition datasets and comparable performance in the scene dataset. 1</p><p>2 0.56367505 <a title="146-lda-2" href="./nips-2012-The_Bethe_Partition_Function_of_Log-supermodular_Graphical_Models.html">335 nips-2012-The Bethe Partition Function of Log-supermodular Graphical Models</a></p>
<p>Author: Nicholas Ruozzi</p><p>Abstract: Sudderth, Wainwright, and Willsky conjectured that the Bethe approximation corresponding to any ﬁxed point of the belief propagation algorithm over an attractive, pairwise binary graphical model provides a lower bound on the true partition function. In this work, we resolve this conjecture in the afﬁrmative by demonstrating that, for any graphical model with binary variables whose potential functions (not necessarily pairwise) are all log-supermodular, the Bethe partition function always lower bounds the true partition function. The proof of this result follows from a new variant of the “four functions” theorem that may be of independent interest. 1</p><p>3 0.51339018 <a title="146-lda-3" href="./nips-2012-Expectation_Propagation_in_Gaussian_Process_Dynamical_Systems.html">121 nips-2012-Expectation Propagation in Gaussian Process Dynamical Systems</a></p>
<p>Author: Marc Deisenroth, Shakir Mohamed</p><p>Abstract: Rich and complex time-series data, such as those generated from engineering systems, ﬁnancial markets, videos, or neural recordings are now a common feature of modern data analysis. Explaining the phenomena underlying these diverse data sets requires ﬂexible and accurate models. In this paper, we promote Gaussian process dynamical systems as a rich model class that is appropriate for such an analysis. We present a new approximate message-passing algorithm for Bayesian state estimation and inference in Gaussian process dynamical systems, a nonparametric probabilistic generalization of commonly used state-space models. We derive our message-passing algorithm using Expectation Propagation and provide a unifying perspective on message passing in general state-space models. We show that existing Gaussian ﬁlters and smoothers appear as special cases within our inference framework, and that these existing approaches can be improved upon using iterated message passing. Using both synthetic and real-world data, we demonstrate that iterated message passing can improve inference in a wide range of tasks in Bayesian state estimation, thus leading to improved predictions and more effective decision making. 1</p><p>4 0.49584591 <a title="146-lda-4" href="./nips-2012-A_Nonparametric_Conjugate_Prior_Distribution_for_the_Maximizing_Argument_of_a_Noisy_Function.html">13 nips-2012-A Nonparametric Conjugate Prior Distribution for the Maximizing Argument of a Noisy Function</a></p>
<p>Author: Pedro Ortega, Jordi Grau-moya, Tim Genewein, David Balduzzi, Daniel Braun</p><p>Abstract: We propose a novel Bayesian approach to solve stochastic optimization problems that involve ﬁnding extrema of noisy, nonlinear functions. Previous work has focused on representing possible functions explicitly, which leads to a two-step procedure of ﬁrst, doing inference over the function space and second, ﬁnding the extrema of these functions. Here we skip the representation step and directly model the distribution over extrema. To this end, we devise a non-parametric conjugate prior based on a kernel regressor. The resulting posterior distribution directly captures the uncertainty over the maximum of the unknown function. Given t observations of the function, the posterior can be evaluated efﬁciently in time O(t2 ) up to a multiplicative constant. Finally, we show how to apply our model to optimize a noisy, non-convex, high-dimensional objective function.</p><p>5 0.49133945 <a title="146-lda-5" href="./nips-2012-Learning_Image_Descriptors_with_the_Boosting-Trick.html">176 nips-2012-Learning Image Descriptors with the Boosting-Trick</a></p>
<p>Author: Tomasz Trzcinski, Mario Christoudias, Vincent Lepetit, Pascal Fua</p><p>Abstract: In this paper we apply boosting to learn complex non-linear local visual feature representations, drawing inspiration from its successful application to visual object detection. The main goal of local feature descriptors is to distinctively represent a salient image region while remaining invariant to viewpoint and illumination changes. This representation can be improved using machine learning, however, past approaches have been mostly limited to learning linear feature mappings in either the original input or a kernelized input feature space. While kernelized methods have proven somewhat effective for learning non-linear local feature descriptors, they rely heavily on the choice of an appropriate kernel function whose selection is often difﬁcult and non-intuitive. We propose to use the boosting-trick to obtain a non-linear mapping of the input to a high-dimensional feature space. The non-linear feature mapping obtained with the boosting-trick is highly intuitive. We employ gradient-based weak learners resulting in a learned descriptor that closely resembles the well-known SIFT. As demonstrated in our experiments, the resulting descriptor can be learned directly from intensity patches achieving state-of-the-art performance. 1</p><p>6 0.48942924 <a title="146-lda-6" href="./nips-2012-A_Bayesian_Approach_for_Policy_Learning_from_Trajectory_Preference_Queries.html">3 nips-2012-A Bayesian Approach for Policy Learning from Trajectory Preference Queries</a></p>
<p>7 0.48799741 <a title="146-lda-7" href="./nips-2012-Memorability_of_Image_Regions.html">210 nips-2012-Memorability of Image Regions</a></p>
<p>8 0.48656294 <a title="146-lda-8" href="./nips-2012-Natural_Images%2C_Gaussian_Mixtures_and_Dead_Leaves.html">235 nips-2012-Natural Images, Gaussian Mixtures and Dead Leaves</a></p>
<p>9 0.4837245 <a title="146-lda-9" href="./nips-2012-Priors_for_Diversity_in_Generative_Latent_Variable_Models.html">274 nips-2012-Priors for Diversity in Generative Latent Variable Models</a></p>
<p>10 0.48280749 <a title="146-lda-10" href="./nips-2012-Localizing_3D_cuboids_in_single-view_images.html">201 nips-2012-Localizing 3D cuboids in single-view images</a></p>
<p>11 0.48232588 <a title="146-lda-11" href="./nips-2012-Learning_about_Canonical_Views_from_Internet_Image_Collections.html">185 nips-2012-Learning about Canonical Views from Internet Image Collections</a></p>
<p>12 0.48124915 <a title="146-lda-12" href="./nips-2012-Unsupervised_Template_Learning_for_Fine-Grained_Object_Recognition.html">357 nips-2012-Unsupervised Template Learning for Fine-Grained Object Recognition</a></p>
<p>13 0.48122543 <a title="146-lda-13" href="./nips-2012-The_Lov%C3%A1sz_%CF%91_function%2C_SVMs_and_finding_large_dense_subgraphs.html">337 nips-2012-The Lovász ϑ function, SVMs and finding large dense subgraphs</a></p>
<p>14 0.48038319 <a title="146-lda-14" href="./nips-2012-The_Time-Marginalized_Coalescent_Prior_for_Hierarchical_Clustering.html">339 nips-2012-The Time-Marginalized Coalescent Prior for Hierarchical Clustering</a></p>
<p>15 0.47925988 <a title="146-lda-15" href="./nips-2012-A_Generative_Model_for_Parts-based_Object_Segmentation.html">8 nips-2012-A Generative Model for Parts-based Object Segmentation</a></p>
<p>16 0.47900385 <a title="146-lda-16" href="./nips-2012-Searching_for_objects_driven_by_context.html">303 nips-2012-Searching for objects driven by context</a></p>
<p>17 0.47894847 <a title="146-lda-17" href="./nips-2012-Discriminatively_Trained_Sparse_Code_Gradients_for_Contour_Detection.html">101 nips-2012-Discriminatively Trained Sparse Code Gradients for Contour Detection</a></p>
<p>18 0.47831589 <a title="146-lda-18" href="./nips-2012-Online_Sum-Product_Computation_Over_Trees.html">260 nips-2012-Online Sum-Product Computation Over Trees</a></p>
<p>19 0.47744319 <a title="146-lda-19" href="./nips-2012-Deep_Learning_of_Invariant_Features_via_Simulated_Fixations_in_Video.html">90 nips-2012-Deep Learning of Invariant Features via Simulated Fixations in Video</a></p>
<p>20 0.47608832 <a title="146-lda-20" href="./nips-2012-Max-Margin_Structured_Output_Regression_for_Spatio-Temporal_Action_Localization.html">209 nips-2012-Max-Margin Structured Output Regression for Spatio-Temporal Action Localization</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
