<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>336 nips-2012-The Coloured Noise Expansion and Parameter Estimation of Diffusion Processes</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-336" href="#">nips2012-336</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>336 nips-2012-The Coloured Noise Expansion and Parameter Estimation of Diffusion Processes</h1>
<br/><p>Source: <a title="nips-2012-336-pdf" href="http://papers.nips.cc/paper/4743-the-coloured-noise-expansion-and-parameter-estimation-of-diffusion-processes.pdf">pdf</a></p><p>Author: Simon Lyons, Amos J. Storkey, Simo Särkkä</p><p>Abstract: Stochastic differential equations (SDE) are a natural tool for modelling systems that are inherently noisy or contain uncertainties that can be modelled as stochastic processes. Crucial to the process of using SDE to build mathematical models is the ability to estimate parameters of those models from observed data. Over the past few decades, signiﬁcant progress has been made on this problem, but we are still far from having a deﬁnitive solution. We describe a novel method of approximating a diffusion process that we show to be useful in Markov chain Monte-Carlo (MCMC) inference algorithms. We take the ‘white’ noise that drives a diffusion process and decompose it into two terms. The ﬁrst is a ‘coloured noise’ term that can be deterministically controlled by a set of auxilliary variables. The second term is small and enables us to form a linear Gaussian ‘small noise’ approximation. The decomposition allows us to take a diffusion process of interest and cast it in a form that is amenable to sampling by MCMC methods. We explain why many state-of-the-art inference methods fail on highly nonlinear inference problems, and we demonstrate experimentally that our method performs well in such situations. Our results show that this method is a promising new tool for use in inference and parameter estimation problems. 1</p><p>Reference: <a title="nips-2012-336-reference" href="../nips2012_reference/nips-2012-The_Coloured_Noise_Expansion_and_Parameter_Estimation_of_Diffusion_Processes_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 uk  Abstract Stochastic differential equations (SDE) are a natural tool for modelling systems that are inherently noisy or contain uncertainties that can be modelled as stochastic processes. [sent-13, score-0.34]
</p><p>2 We describe a novel method of approximating a diffusion process that we show to be useful in Markov chain Monte-Carlo (MCMC) inference algorithms. [sent-16, score-0.581]
</p><p>3 We take the ‘white’ noise that drives a diffusion process and decompose it into two terms. [sent-17, score-0.626]
</p><p>4 The decomposition allows us to take a diffusion process of interest and cast it in a form that is amenable to sampling by MCMC methods. [sent-20, score-0.536]
</p><p>5 We explain why many state-of-the-art inference methods fail on highly nonlinear inference problems, and we demonstrate experimentally that our method performs well in such situations. [sent-21, score-0.202]
</p><p>6 1  Introduction  Diffusion processes are a ﬂexible and useful tool in stochastic modelling. [sent-23, score-0.176]
</p><p>7 Many important real world systems are currently modelled and best understood in terms of stochastic differential equations in general and diffusions in particular. [sent-24, score-0.428]
</p><p>8 The analysis of diffusions dates back to Feller and Kolmogorov, who studied them as the scaling limits of certain Markov processes (see [8]). [sent-26, score-0.185]
</p><p>9 The theory of diffusion processes was revolutionised by Itˆ , who interpreted a diffusion process as the solution to a stochastic differential equation [9, o 10]. [sent-27, score-1.328]
</p><p>10 This viewpoint allows one to see a diffusion process as the randomised counterpart of an ordinary differential equation. [sent-28, score-0.712]
</p><p>11 One can argue that stochastic differential equations are the natural 1  tool for modelling continuously evolving systems of real valued quantities that are subject to noise or stochastic inﬂuences. [sent-29, score-0.472]
</p><p>12 These equations are goverened by a set of input parameters (for example particle masses, reaction rates, or more general constants of proportionality) that determine the behaviour of the system. [sent-31, score-0.233]
</p><p>13 We would like to know what the nature of this diffusion is. [sent-35, score-0.467]
</p><p>14 In practice, this is computationally prohibitive: it is necessary to solve a partial differential equation known as the Fokker-Planck equation (see [11]) in order to ﬁnd the transition density of the diffusion of interest. [sent-38, score-0.693]
</p><p>15 In this paper, we propose a novel approximation for a nonlinear diffusion process X. [sent-40, score-0.692]
</p><p>16 One heuristic way of thinking about a diffusion is as an ordinary differential equation that is perturbed by white noise. [sent-41, score-0.757]
</p><p>17 We demonstrate that one can replace the white noise by a ‘coloured’ approximation without inducing much error. [sent-42, score-0.207]
</p><p>18 The nature of the coloured noise expansion method enables us to control the behaviour of the diffusion over various length-scales. [sent-43, score-1.004]
</p><p>19 This allows us to produce samples from the diffusion process that are consistent with observed data. [sent-44, score-0.536]
</p><p>20 The main contributions of this paper are: • Novel development of a method for sampling from the time-t marginal distribution of a diffusion process based on a ‘coloured’ approximation of white noise. [sent-46, score-0.653]
</p><p>21 • Demonstration that this approximation is a powerful and scalable tool for making parameter estimation feasible for general diffusions at minimal cost. [sent-47, score-0.235]
</p><p>22 In Section 4, we discuss the coloured noise expansion and its use in controlling the behaviour of a diffusion process. [sent-50, score-1.004]
</p><p>23 2  Parametric Diffusion Processes  In this section we develop the basic notation and formalism for the diffusion processes used in this work. [sent-53, score-0.528]
</p><p>24 First, we assume our data are generated by observing a k-dimensional diffusion processes with dynamics dXt = aθ (Xt )dt + Bθ dWt , X0 ∼ p(x0 ), (1) where the initial condition is drawn from some known distribution. [sent-54, score-0.528]
</p><p>25 The driving noise W is a d-dimensional Brownian motion, and the equation is interpreted in the Itˆ sense. [sent-62, score-0.166]
</p><p>26 That is, Yti = Xti + ti , (2) ti ∼ N (0, Σi ) We use the notation X to refer to the entire sample path of the diffusion, and Xt to denote the value of the process at time t. [sent-64, score-0.355]
</p><p>27 In situations where this is not explicitly the case, one can often hope to reduce a diffusion to this form via the Lamperti transform. [sent-71, score-0.467]
</p><p>28 A¨t-Sahalia [12] characterises ı the set of multivariate diffusions to which this transform can be applied. [sent-73, score-0.15]
</p><p>29 2  3  Background Work  Most approaches to parameter estimation of diffusion processes rely on the Monte-Carlo approximation. [sent-74, score-0.559]
</p><p>30 [13] [14] employ a method based on rejection sampling to estimate parameters without introducing any discretisation error. [sent-76, score-0.213]
</p><p>31 Roughly speaking, Gibbs samplers that exist in the literature alternate between drawing samples from some representation of the diffusion process X conditional on parameters θ, and samples from θ conditional on the current sample path of X. [sent-79, score-0.646]
</p><p>32 The usual approach to the consistency issue is to make a proposal by conditioning a linear diffusion to hit some neighbourhood of the observation Yk , then to make a correction via a rejection sampling [18] or a Metropolis-Hastings [16] step. [sent-81, score-0.767]
</p><p>33 However, as the inter-observation time grows, the qualitative difference between linear and nonlinear diffusions gets progressively more pronounced, and the rate of rejection grows accordingly. [sent-82, score-0.314]
</p><p>34 Figure 1 shows the disparity between a sample from a nonlinear process and a sample from the linear proposal. [sent-83, score-0.181]
</p><p>35 Sample path with noisy observations  Nonlinear sample path and proposal  2 1  1  X(t)  X(t)  0 −1  0 −1  −2  −2 −3 0  1  2  −3 0  3  5  t  10 t  15  20  (a) (b) Figure 1: (a) Sample path of a double well process (see equation (18)) with α = 2, γ = 2. [sent-87, score-0.483]
</p><p>36 Current Gibbs samplers use linear proposals (dashed red line) with a rejection step to draw conditioned nonlinear paths. [sent-89, score-0.34]
</p><p>37 In this case, the behaviour of the proposal is very different to that of the target, and the rate of rejection is high. [sent-90, score-0.269]
</p><p>38 (b) Sample path of a double well process (solid blue line) with noisy observations (red dots). [sent-91, score-0.207]
</p><p>39 Other approaches include variational methods [23, 24] that can compute continuous time Gaussian process approximations to more general stochastic differential systems, as well as various non-linear Kalman ﬁltering and smoothing based approximations [25, 26, 27] . [sent-100, score-0.292]
</p><p>40 4  Coloured Noise Expansions and Brownian Motion  We now introduce a method of approximating a nonlinear diffusion that allows us to gain a considerable amount of control over the behaviour of the process. [sent-101, score-0.655]
</p><p>41 Similar methods have been used 3  for stratiﬁed sampling of diffusion processes [28] and the solution of stochastic partial differential equations [29] . [sent-102, score-0.795]
</p><p>42 One of the major challenges of using MCMC methods for parameter estimation in the present context is that it is typically very difﬁcult to draw samples from a diffusion process conditional on observed data. [sent-103, score-0.6]
</p><p>43 Our approximation separates the diffusion process X into the sum of a linear and nonlinear component. [sent-106, score-0.692]
</p><p>44 Heuristically, one can think of the random process that drives the process deﬁned in equation (1) as white noise. [sent-110, score-0.252]
</p><p>45 In our approximation, we project this white noise into an N -dimensional subspace of L2 [0, T ], the Hilbert space of square-integrable functions deﬁned on the interval [0, T ]. [sent-111, score-0.163]
</p><p>46 This gives a ‘coloured noise’ process that approaches white noise asymptotically as N → ∞. [sent-112, score-0.232]
</p><p>47 The coloured noise process is then used to drive an approximation of (1). [sent-113, score-0.485]
</p><p>48 We can choose the space into which to project the white noise in such a way that we will gain some control over its behaviour. [sent-114, score-0.163]
</p><p>49 This is analagous to the way that Fourier analysis allows us to manipulate properties of signals Recall that a standard Brownian motion on the interval [0, T ] is a one-dimentional Gaussian process with zero mean and covariance function k(s, t) = min{s, t}. [sent-115, score-0.152]
</p><p>50 We can substitute this approximation into equation (1), which gives dXNL t = aθ (XNL ) + Bθ t dt  N  Φi Zi ,  XNL ∼ p(x0 ), 0  (7)  i=1  where Φi is the diagonal d × d matrix with entries (φi1 , . [sent-129, score-0.17]
</p><p>51 This derivation is useful because equation (7) gives us an alternative to the Euler-Maruyama discretisation for sampling approximately from the time-t marginal distribution of a diffusion process. [sent-136, score-0.602]
</p><p>52 We 4  draw coefﬁcients Zij from a standard normal distribution, and solve the appropriate vector-valued ordinary differential equation. [sent-137, score-0.209]
</p><p>53 While the Euler discretisation is the de facto standard method for numerical approximation of SDE, other methods do exist. [sent-138, score-0.172]
</p><p>54 One must typically employ a ﬁne discretisation to get a good approximation to the true diffusion process. [sent-141, score-0.646]
</p><p>55 Empirically, we ﬁnd that one needs far fewer Gaussian inputs Zi for an accurate representation of XT using the coloured noise approximation. [sent-142, score-0.408]
</p><p>56 For example, Corlay and Pages [28] employ related ideas to conduct stratiﬁed sampling of a diffusion process. [sent-144, score-0.508]
</p><p>57 The seperation of behaviours across coefﬁcients gives us a means to obtain ﬁne-grained control over the behaviour of a diffusion process within a Metropolis-Hastings algorithm. [sent-149, score-0.612]
</p><p>58 t t  (9)  Taylor expanding the drift term around XNL , we see that to ﬁrst order, dXt ≈ =  aθ XNL + Ja (XNL )XC dt + Bθ dWt t t t ˆ ˆ aθ XNL + Bθ dWt dt + Ja (XNL )XC dt + Bθ dWt − dWt . [sent-154, score-0.282]
</p><p>59 The dynamics of XL satisfy dXL = Ja (XNL )XL dt + Bθ dRt , t t t  XL = 0, 0  (11)  ˆ where the driving noise is the ‘residual’ term R = W − W. [sent-158, score-0.21]
</p><p>60 First, we compute a numerical approximation to the solution of the homogenous matrix-valued equation d Ψ(t) = Ja (XNL )Ψ(t), t dt  Ψ(0) = In . [sent-160, score-0.204]
</p><p>61 (14)  0  0  The process XNL is designed to capture the most signiﬁcant nonlinear features of the original diffusion X, while the linear process XL corrects for the truncation of the sum (6), and can be understood using tools from the theory of Gaussian processes. [sent-164, score-0.717]
</p><p>62 One can think of the linear term as the result of a ‘small-noise’ expansion about the nonlinear trajectory. [sent-165, score-0.201]
</p><p>63 5  Parameter Estimation  In this section, we describe a novel modiﬁcation of the Gibbs sampler that does not suffer the drawbacks of the linear proposal strategy. [sent-169, score-0.147]
</p><p>64 In Section 6, we demonstrate that for highly nonlinear problems it will perform signiﬁcantly better than standard methods because of the nonlinear component of our approximation. [sent-170, score-0.224]
</p><p>65 Suppose for now that we make a single noiseless observation at time t1 = T (for ease of notation, we will assume that observations are uniformly spaced through time with ti+1 − ti = T , though this is not necessary). [sent-171, score-0.15]
</p><p>66 We draw Z(i)∗ from the proposal distribution, and compute XNL∗ i ∗ with initial condition Yi−1 . [sent-180, score-0.148]
</p><p>67 The acceptance probability for this move is n  α=1∧  ∗ N (Yi | XNL∗ , ki (T, T ))p(θ∗ )p(θ∗ → θ) i , N (Yi | XNL , ki (T, T ))p(θ)p(θ → θ∗ ) i i=1  (17)  ∗ where XNL∗ and ki (T, T ) are computed using the proposed value of θ∗ . [sent-183, score-0.168]
</p><p>68 i  We noted earlier that when j is large, Zj governs the small-time oscillations of the diffusion process. [sent-184, score-0.505]
</p><p>69 For this reason, we employ a Gaussian random walk proposal in Z1 with stepsize σRW = . [sent-187, score-0.196]
</p><p>70 If the variance of the observation noise is high, it may be more efﬁcient to target the joint posterior distribution p θ, {Zi , XL } | Y1:n . [sent-197, score-0.164]
</p><p>71 i 1:N  6  Numerical Experiments  The double-well diffusion is a widely-used benchmark for nonlinear inference problems [24, 32, 33, 34]. [sent-198, score-0.624]
</p><p>72 It possesses nonlinear features that are sufﬁcient to demonstrate the shortcomings of some existing inference methods, and how our approach overcomes these issues. [sent-200, score-0.157]
</p><p>73 The dynamics of the process are given by 2 dXt = αXt γ 2 − Xt dt + BdWt . [sent-201, score-0.154]
</p><p>74 Figure 1(b) shows a trajectory of a double-well diffusion over 20 units of time, with observations at times {1, 2, . [sent-205, score-0.504]
</p><p>75 As we mentioned earlier, particle MCMC performs well in low-dimensional inference problems. [sent-212, score-0.158]
</p><p>76 For this reason, the results of a particle MCMC inference algorithm (with N = 1, 000) particles are used as ’ground truth’. [sent-213, score-0.185]
</p><p>77 We compare our Gibbs sampler to that of Golightly and Wilkinson [15], for which we use an Euler discretisation with stepsize ∆t = . [sent-216, score-0.166]
</p><p>78 The broken red line is the output of the linear proposal method, and the broken and dotted blue line is the density estimate from the coloured noise expansion method. [sent-238, score-0.636]
</p><p>79 Gibbs samplers that have been used in the past rely on making proposals by conditioning a linear diffusion to hit a target, and subsequently accepting or rejecting those proposals. [sent-240, score-0.617]
</p><p>80 We make noisy observations with ti − ti−1 = 3 and Σ = . [sent-245, score-0.15]
</p><p>81 From our previous discussion, one might expect the linear proposal strategy to perform poorly in this more nonlinear setting. [sent-248, score-0.227]
</p><p>82 As in the previous experiment, we used a linear proposal Gibbs sampler with Euler stepsize dt = 0. [sent-250, score-0.272]
</p><p>83 On the other hand, the coloured noise expansion method used N = 7 Gaussian inputs with a linear correction and was able to approximate the posterior accurately. [sent-254, score-0.617]
</p><p>84 5  0 1  3  (b) Coloured noise expansion method  1. [sent-269, score-0.179]
</p><p>85 5  3  (c) Linear proposal method  Figure 3: p(γ|Y1:10 , B, α) after ten observations with a relatively large inter-observation time. [sent-271, score-0.152]
</p><p>86 The coloured noise expansion method matches the ground truth, whereas the linear proposal method is inconsistent with the data. [sent-274, score-0.603]
</p><p>87 Our inference method avoids the linear correction step, instead targeting the posterior over input variables directly. [sent-276, score-0.165]
</p><p>88 We used a Taylor expansion to compute the covariance of the correction term. [sent-285, score-0.19]
</p><p>89 In this paper, we restricted our attention to processes with a state-independent diffusion coefﬁcient so that the covariance of the correction term could be computed. [sent-287, score-0.629]
</p><p>90 We may be able to extend this methodology to process with state-dependent noise - certainly one could achieve this by taking a 0-th order Taylor expansion about XNL . [sent-288, score-0.248]
</p><p>91 Variational Bayesian identiﬁcation and prediction of stochastic nonlinear dynamic causal models. [sent-325, score-0.191]
</p><p>92 Monte-Carlo maximum likelihood estimation for discretely observed diffusion processes. [sent-362, score-0.554]
</p><p>93 Exact and computationally efﬁcient likelihood-based estimation for discretely observed diffusion processes (with discussion). [sent-370, score-0.615]
</p><p>94 Bayesian inference for nonlinear multivariate diffusion models observed with error. [sent-376, score-0.65]
</p><p>95 Numerical techniques for maximum likelihood estimation of continuoustime diffusion processes (with comments). [sent-396, score-0.559]
</p><p>96 Retrospective exact simulation of diffusion sample paths with applications. [sent-403, score-0.467]
</p><p>97 Particle ﬁlters for stochastic differential equations of nonlinear diffusions. [sent-410, score-0.379]
</p><p>98 Wiener chaos expansion and numerical solutions of stochastic partial differential equations. [sent-462, score-0.346]
</p><p>99 A new adaptive Runge-Kutta method for stochastic differential equations. [sent-475, score-0.223]
</p><p>100 Parameter estimation of nonlinear stochastic differential equations: simulated maximum likelihood versus extended Kalman ﬁlter and Itˆ -Taylor expansion. [sent-488, score-0.366]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('xnl', 0.512), ('diffusion', 0.467), ('coloured', 0.282), ('differential', 0.144), ('xl', 0.124), ('diffusions', 0.124), ('brownian', 0.119), ('proposal', 0.115), ('particle', 0.113), ('ti', 0.113), ('dwt', 0.113), ('nonlinear', 0.112), ('discretisation', 0.094), ('noise', 0.09), ('expansion', 0.089), ('ja', 0.087), ('dws', 0.085), ('dt', 0.085), ('stochastic', 0.079), ('rejection', 0.078), ('behaviour', 0.076), ('beskos', 0.075), ('correction', 0.074), ('white', 0.073), ('zi', 0.071), ('dxt', 0.069), ('process', 0.069), ('proposals', 0.067), ('cornford', 0.064), ('xc', 0.063), ('processes', 0.061), ('path', 0.06), ('gibbs', 0.059), ('mcmc', 0.057), ('papaspiliopoulos', 0.056), ('golightly', 0.056), ('discretely', 0.056), ('sde', 0.056), ('motion', 0.056), ('ki', 0.056), ('opper', 0.055), ('archambeau', 0.052), ('euler', 0.052), ('edinburgh', 0.051), ('samplers', 0.05), ('chemical', 0.049), ('du', 0.047), ('posterior', 0.046), ('inference', 0.045), ('strati', 0.045), ('approximation', 0.044), ('equations', 0.044), ('expansions', 0.043), ('corlay', 0.043), ('crichton', 0.043), ('kloeden', 0.043), ('lyons', 0.043), ('wti', 0.043), ('double', 0.041), ('equation', 0.041), ('employ', 0.041), ('stepsize', 0.04), ('rkk', 0.038), ('oscillations', 0.038), ('wilkinson', 0.038), ('observations', 0.037), ('modelled', 0.037), ('kalman', 0.037), ('gaussian', 0.036), ('inputs', 0.036), ('tool', 0.036), ('physics', 0.036), ('yi', 0.036), ('chib', 0.035), ('driving', 0.035), ('numerical', 0.034), ('draw', 0.033), ('street', 0.033), ('weather', 0.033), ('hit', 0.033), ('ordinary', 0.032), ('sampler', 0.032), ('durham', 0.031), ('estimation', 0.031), ('fourier', 0.03), ('zj', 0.03), ('wt', 0.03), ('drew', 0.03), ('broken', 0.03), ('increments', 0.03), ('orthonormal', 0.03), ('target', 0.028), ('proportionality', 0.028), ('covariance', 0.027), ('ltering', 0.027), ('particles', 0.027), ('drift', 0.027), ('ground', 0.027), ('multivariate', 0.026), ('taylor', 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000007 <a title="336-tfidf-1" href="./nips-2012-The_Coloured_Noise_Expansion_and_Parameter_Estimation_of_Diffusion_Processes.html">336 nips-2012-The Coloured Noise Expansion and Parameter Estimation of Diffusion Processes</a></p>
<p>Author: Simon Lyons, Amos J. Storkey, Simo Särkkä</p><p>Abstract: Stochastic differential equations (SDE) are a natural tool for modelling systems that are inherently noisy or contain uncertainties that can be modelled as stochastic processes. Crucial to the process of using SDE to build mathematical models is the ability to estimate parameters of those models from observed data. Over the past few decades, signiﬁcant progress has been made on this problem, but we are still far from having a deﬁnitive solution. We describe a novel method of approximating a diffusion process that we show to be useful in Markov chain Monte-Carlo (MCMC) inference algorithms. We take the ‘white’ noise that drives a diffusion process and decompose it into two terms. The ﬁrst is a ‘coloured noise’ term that can be deterministically controlled by a set of auxilliary variables. The second term is small and enables us to form a linear Gaussian ‘small noise’ approximation. The decomposition allows us to take a diffusion process of interest and cast it in a form that is amenable to sampling by MCMC methods. We explain why many state-of-the-art inference methods fail on highly nonlinear inference problems, and we demonstrate experimentally that our method performs well in such situations. Our results show that this method is a promising new tool for use in inference and parameter estimation problems. 1</p><p>2 0.20507306 <a title="336-tfidf-2" href="./nips-2012-Diffusion_Decision_Making_for_Adaptive_k-Nearest_Neighbor_Classification.html">97 nips-2012-Diffusion Decision Making for Adaptive k-Nearest Neighbor Classification</a></p>
<p>Author: Yung-kyun Noh, Frank Park, Daniel D. Lee</p><p>Abstract: This paper sheds light on some fundamental connections of the diffusion decision making model of neuroscience and cognitive psychology with k-nearest neighbor classiﬁcation. We show that conventional k-nearest neighbor classiﬁcation can be viewed as a special problem of the diffusion decision model in the asymptotic situation. By applying the optimal strategy associated with the diffusion decision model, an adaptive rule is developed for determining appropriate values of k in knearest neighbor classiﬁcation. Making use of the sequential probability ratio test (SPRT) and Bayesian analysis, we propose ﬁve different criteria for adaptively acquiring nearest neighbors. Experiments with both synthetic and real datasets demonstrate the effectiveness of our classiﬁcation criteria. 1</p><p>3 0.16732825 <a title="336-tfidf-3" href="./nips-2012-Learning_Networks_of_Heterogeneous_Influence.html">182 nips-2012-Learning Networks of Heterogeneous Influence</a></p>
<p>Author: Nan Du, Le Song, Ming Yuan, Alex J. Smola</p><p>Abstract: Information, disease, and inﬂuence diffuse over networks of entities in both natural systems and human society. Analyzing these transmission networks plays an important role in understanding the diffusion processes and predicting future events. However, the underlying transmission networks are often hidden and incomplete, and we observe only the time stamps when cascades of events happen. In this paper, we address the challenging problem of uncovering the hidden network only from the cascades. The structure discovery problem is complicated by the fact that the inﬂuence between networked entities is heterogeneous, which can not be described by a simple parametric model. Therefore, we propose a kernelbased method which can capture a diverse range of different types of inﬂuence without any prior assumption. In both synthetic and real cascade data, we show that our model can better recover the underlying diffusion network and drastically improve the estimation of the transmission functions among networked entities. 1</p><p>4 0.13553545 <a title="336-tfidf-4" href="./nips-2012-Sparse_Approximate_Manifolds_for_Differential_Geometric_MCMC.html">318 nips-2012-Sparse Approximate Manifolds for Differential Geometric MCMC</a></p>
<p>Author: Ben Calderhead, Mátyás A. Sustik</p><p>Abstract: One of the enduring challenges in Markov chain Monte Carlo methodology is the development of proposal mechanisms to make moves distant from the current point, that are accepted with high probability and at low computational cost. The recent introduction of locally adaptive MCMC methods based on the natural underlying Riemannian geometry of such models goes some way to alleviating these problems for certain classes of models for which the metric tensor is analytically tractable, however computational efﬁciency is not assured due to the necessity of potentially high-dimensional matrix operations at each iteration. In this paper we ﬁrstly investigate a sampling-based approach for approximating the metric tensor and suggest a valid MCMC algorithm that extends the applicability of Riemannian Manifold MCMC methods to statistical models that do not admit an analytically computable metric tensor. Secondly, we show how the approximation scheme we consider naturally motivates the use of 1 regularisation to improve estimates and obtain a sparse approximate inverse of the metric, which enables stable and sparse approximations of the local geometry to be made. We demonstrate the application of this algorithm for inferring the parameters of a realistic system of ordinary differential equations using a biologically motivated robust Student-t error model, for which the Expected Fisher Information is analytically intractable. 1</p><p>5 0.11794846 <a title="336-tfidf-5" href="./nips-2012-Ancestor_Sampling_for_Particle_Gibbs.html">41 nips-2012-Ancestor Sampling for Particle Gibbs</a></p>
<p>Author: Fredrik Lindsten, Thomas Schön, Michael I. Jordan</p><p>Abstract: We present a novel method in the family of particle MCMC methods that we refer to as particle Gibbs with ancestor sampling (PG-AS). Similarly to the existing PG with backward simulation (PG-BS) procedure, we use backward sampling to (considerably) improve the mixing of the PG kernel. Instead of using separate forward and backward sweeps as in PG-BS, however, we achieve the same effect in a single forward sweep. We apply the PG-AS framework to the challenging class of non-Markovian state-space models. We develop a truncation strategy of these models that is applicable in principle to any backward-simulation-based method, but which is particularly well suited to the PG-AS framework. In particular, as we show in a simulation study, PG-AS can yield an order-of-magnitude improved accuracy relative to PG-BS due to its robustness to the truncation error. Several application examples are discussed, including Rao-Blackwellized particle smoothing and inference in degenerate state-space models. 1</p><p>6 0.11594381 <a title="336-tfidf-6" href="./nips-2012-Synchronization_can_Control_Regularization_in_Neural_Systems_via_Correlated_Noise_Processes.html">333 nips-2012-Synchronization can Control Regularization in Neural Systems via Correlated Noise Processes</a></p>
<p>7 0.10896727 <a title="336-tfidf-7" href="./nips-2012-The_Time-Marginalized_Coalescent_Prior_for_Hierarchical_Clustering.html">339 nips-2012-The Time-Marginalized Coalescent Prior for Hierarchical Clustering</a></p>
<p>8 0.0972303 <a title="336-tfidf-8" href="./nips-2012-Entangled_Monte_Carlo.html">118 nips-2012-Entangled Monte Carlo</a></p>
<p>9 0.092739053 <a title="336-tfidf-9" href="./nips-2012-A_Nonparametric_Conjugate_Prior_Distribution_for_the_Maximizing_Argument_of_a_Noisy_Function.html">13 nips-2012-A Nonparametric Conjugate Prior Distribution for the Maximizing Argument of a Noisy Function</a></p>
<p>10 0.090033263 <a title="336-tfidf-10" href="./nips-2012-FastEx%3A_Hash_Clustering_with_Exponential_Families.html">126 nips-2012-FastEx: Hash Clustering with Exponential Families</a></p>
<p>11 0.085617028 <a title="336-tfidf-11" href="./nips-2012-MCMC_for_continuous-time_discrete-state_systems.html">205 nips-2012-MCMC for continuous-time discrete-state systems</a></p>
<p>12 0.082440302 <a title="336-tfidf-12" href="./nips-2012-Continuous_Relaxations_for_Discrete_Hamiltonian_Monte_Carlo.html">82 nips-2012-Continuous Relaxations for Discrete Hamiltonian Monte Carlo</a></p>
<p>13 0.081913643 <a title="336-tfidf-13" href="./nips-2012-Bayesian_active_learning_with_localized_priors_for_fast_receptive_field_characterization.html">56 nips-2012-Bayesian active learning with localized priors for fast receptive field characterization</a></p>
<p>14 0.077640764 <a title="336-tfidf-14" href="./nips-2012-Fusion_with_Diffusion_for_Robust_Visual_Tracking.html">140 nips-2012-Fusion with Diffusion for Robust Visual Tracking</a></p>
<p>15 0.077296957 <a title="336-tfidf-15" href="./nips-2012-Truncation-free_Online_Variational_Inference_for_Bayesian_Nonparametric_Models.html">355 nips-2012-Truncation-free Online Variational Inference for Bayesian Nonparametric Models</a></p>
<p>16 0.076778434 <a title="336-tfidf-16" href="./nips-2012-Coding_efficiency_and_detectability_of_rate_fluctuations_with_non-Poisson_neuronal_firing.html">73 nips-2012-Coding efficiency and detectability of rate fluctuations with non-Poisson neuronal firing</a></p>
<p>17 0.075551398 <a title="336-tfidf-17" href="./nips-2012-Expectation_Propagation_in_Gaussian_Process_Dynamical_Systems.html">121 nips-2012-Expectation Propagation in Gaussian Process Dynamical Systems</a></p>
<p>18 0.072928049 <a title="336-tfidf-18" href="./nips-2012-Effective_Split-Merge_Monte_Carlo_Methods_for_Nonparametric_Models_of_Sequential_Data.html">107 nips-2012-Effective Split-Merge Monte Carlo Methods for Nonparametric Models of Sequential Data</a></p>
<p>19 0.065471947 <a title="336-tfidf-19" href="./nips-2012-Stochastic_optimization_and_sparse_statistical_recovery%3A_Optimal_algorithms_for_high_dimensions.html">325 nips-2012-Stochastic optimization and sparse statistical recovery: Optimal algorithms for high dimensions</a></p>
<p>20 0.064327218 <a title="336-tfidf-20" href="./nips-2012-Selective_Labeling_via_Error_Bound_Minimization.html">305 nips-2012-Selective Labeling via Error Bound Minimization</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.179), (1, 0.024), (2, 0.02), (3, 0.065), (4, -0.115), (5, 0.009), (6, -0.003), (7, 0.022), (8, 0.003), (9, -0.048), (10, -0.067), (11, -0.089), (12, 0.029), (13, -0.082), (14, -0.093), (15, -0.015), (16, -0.105), (17, -0.146), (18, 0.082), (19, -0.034), (20, 0.131), (21, 0.085), (22, -0.028), (23, 0.004), (24, -0.049), (25, -0.114), (26, -0.058), (27, -0.004), (28, -0.1), (29, -0.14), (30, -0.035), (31, -0.007), (32, 0.045), (33, -0.054), (34, -0.017), (35, 0.035), (36, -0.012), (37, 0.063), (38, 0.054), (39, 0.223), (40, -0.035), (41, 0.02), (42, 0.026), (43, 0.061), (44, 0.051), (45, -0.054), (46, 0.055), (47, -0.031), (48, -0.033), (49, -0.027)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93126637 <a title="336-lsi-1" href="./nips-2012-The_Coloured_Noise_Expansion_and_Parameter_Estimation_of_Diffusion_Processes.html">336 nips-2012-The Coloured Noise Expansion and Parameter Estimation of Diffusion Processes</a></p>
<p>Author: Simon Lyons, Amos J. Storkey, Simo Särkkä</p><p>Abstract: Stochastic differential equations (SDE) are a natural tool for modelling systems that are inherently noisy or contain uncertainties that can be modelled as stochastic processes. Crucial to the process of using SDE to build mathematical models is the ability to estimate parameters of those models from observed data. Over the past few decades, signiﬁcant progress has been made on this problem, but we are still far from having a deﬁnitive solution. We describe a novel method of approximating a diffusion process that we show to be useful in Markov chain Monte-Carlo (MCMC) inference algorithms. We take the ‘white’ noise that drives a diffusion process and decompose it into two terms. The ﬁrst is a ‘coloured noise’ term that can be deterministically controlled by a set of auxilliary variables. The second term is small and enables us to form a linear Gaussian ‘small noise’ approximation. The decomposition allows us to take a diffusion process of interest and cast it in a form that is amenable to sampling by MCMC methods. We explain why many state-of-the-art inference methods fail on highly nonlinear inference problems, and we demonstrate experimentally that our method performs well in such situations. Our results show that this method is a promising new tool for use in inference and parameter estimation problems. 1</p><p>2 0.7347396 <a title="336-lsi-2" href="./nips-2012-MCMC_for_continuous-time_discrete-state_systems.html">205 nips-2012-MCMC for continuous-time discrete-state systems</a></p>
<p>Author: Vinayak Rao, Yee W. Teh</p><p>Abstract: We propose a simple and novel framework for MCMC inference in continuoustime discrete-state systems with pure jump trajectories. We construct an exact MCMC sampler for such systems by alternately sampling a random discretization of time given a trajectory of the system, and then a new trajectory given the discretization. The ﬁrst step can be performed efﬁciently using properties of the Poisson process, while the second step can avail of discrete-time MCMC techniques based on the forward-backward algorithm. We show the advantage of our approach compared to particle MCMC and a uniformization-based sampler. 1</p><p>3 0.64115953 <a title="336-lsi-3" href="./nips-2012-Diffusion_Decision_Making_for_Adaptive_k-Nearest_Neighbor_Classification.html">97 nips-2012-Diffusion Decision Making for Adaptive k-Nearest Neighbor Classification</a></p>
<p>Author: Yung-kyun Noh, Frank Park, Daniel D. Lee</p><p>Abstract: This paper sheds light on some fundamental connections of the diffusion decision making model of neuroscience and cognitive psychology with k-nearest neighbor classiﬁcation. We show that conventional k-nearest neighbor classiﬁcation can be viewed as a special problem of the diffusion decision model in the asymptotic situation. By applying the optimal strategy associated with the diffusion decision model, an adaptive rule is developed for determining appropriate values of k in knearest neighbor classiﬁcation. Making use of the sequential probability ratio test (SPRT) and Bayesian analysis, we propose ﬁve different criteria for adaptively acquiring nearest neighbors. Experiments with both synthetic and real datasets demonstrate the effectiveness of our classiﬁcation criteria. 1</p><p>4 0.63214386 <a title="336-lsi-4" href="./nips-2012-Entangled_Monte_Carlo.html">118 nips-2012-Entangled Monte Carlo</a></p>
<p>Author: Seong-hwan Jun, Liangliang Wang, Alexandre Bouchard-côté</p><p>Abstract: We propose a novel method for scalable parallelization of SMC algorithms, Entangled Monte Carlo simulation (EMC). EMC avoids the transmission of particles between nodes, and instead reconstructs them from the particle genealogy. In particular, we show that we can reduce the communication to the particle weights for each machine while efﬁciently maintaining implicit global coherence of the parallel simulation. We explain methods to efﬁciently maintain a genealogy of particles from which any particle can be reconstructed. We demonstrate using examples from Bayesian phylogenetic that the computational gain from parallelization using EMC signiﬁcantly outweighs the cost of particle reconstruction. The timing experiments show that reconstruction of particles is indeed much more efﬁcient as compared to transmission of particles. 1</p><p>5 0.62877899 <a title="336-lsi-5" href="./nips-2012-Learning_Networks_of_Heterogeneous_Influence.html">182 nips-2012-Learning Networks of Heterogeneous Influence</a></p>
<p>Author: Nan Du, Le Song, Ming Yuan, Alex J. Smola</p><p>Abstract: Information, disease, and inﬂuence diffuse over networks of entities in both natural systems and human society. Analyzing these transmission networks plays an important role in understanding the diffusion processes and predicting future events. However, the underlying transmission networks are often hidden and incomplete, and we observe only the time stamps when cascades of events happen. In this paper, we address the challenging problem of uncovering the hidden network only from the cascades. The structure discovery problem is complicated by the fact that the inﬂuence between networked entities is heterogeneous, which can not be described by a simple parametric model. Therefore, we propose a kernelbased method which can capture a diverse range of different types of inﬂuence without any prior assumption. In both synthetic and real cascade data, we show that our model can better recover the underlying diffusion network and drastically improve the estimation of the transmission functions among networked entities. 1</p><p>6 0.57536942 <a title="336-lsi-6" href="./nips-2012-Ancestor_Sampling_for_Particle_Gibbs.html">41 nips-2012-Ancestor Sampling for Particle Gibbs</a></p>
<p>7 0.53441012 <a title="336-lsi-7" href="./nips-2012-Coding_efficiency_and_detectability_of_rate_fluctuations_with_non-Poisson_neuronal_firing.html">73 nips-2012-Coding efficiency and detectability of rate fluctuations with non-Poisson neuronal firing</a></p>
<p>8 0.4937295 <a title="336-lsi-8" href="./nips-2012-Bayesian_active_learning_with_localized_priors_for_fast_receptive_field_characterization.html">56 nips-2012-Bayesian active learning with localized priors for fast receptive field characterization</a></p>
<p>9 0.48980087 <a title="336-lsi-9" href="./nips-2012-Fusion_with_Diffusion_for_Robust_Visual_Tracking.html">140 nips-2012-Fusion with Diffusion for Robust Visual Tracking</a></p>
<p>10 0.47431099 <a title="336-lsi-10" href="./nips-2012-Synchronization_can_Control_Regularization_in_Neural_Systems_via_Correlated_Noise_Processes.html">333 nips-2012-Synchronization can Control Regularization in Neural Systems via Correlated Noise Processes</a></p>
<p>11 0.46631172 <a title="336-lsi-11" href="./nips-2012-Modelling_Reciprocating_Relationships_with_Hawkes_Processes.html">219 nips-2012-Modelling Reciprocating Relationships with Hawkes Processes</a></p>
<p>12 0.43425283 <a title="336-lsi-12" href="./nips-2012-Dynamic_Pruning_of_Factor_Graphs_for_Maximum_Marginal_Prediction.html">105 nips-2012-Dynamic Pruning of Factor Graphs for Maximum Marginal Prediction</a></p>
<p>13 0.42967024 <a title="336-lsi-13" href="./nips-2012-Continuous_Relaxations_for_Discrete_Hamiltonian_Monte_Carlo.html">82 nips-2012-Continuous Relaxations for Discrete Hamiltonian Monte Carlo</a></p>
<p>14 0.42145476 <a title="336-lsi-14" href="./nips-2012-Fast_Resampling_Weighted_v-Statistics.html">128 nips-2012-Fast Resampling Weighted v-Statistics</a></p>
<p>15 0.42031687 <a title="336-lsi-15" href="./nips-2012-Multiplicative_Forests_for_Continuous-Time_Processes.html">232 nips-2012-Multiplicative Forests for Continuous-Time Processes</a></p>
<p>16 0.41389534 <a title="336-lsi-16" href="./nips-2012-Affine_Independent_Variational_Inference.html">37 nips-2012-Affine Independent Variational Inference</a></p>
<p>17 0.4121044 <a title="336-lsi-17" href="./nips-2012-Sparse_Approximate_Manifolds_for_Differential_Geometric_MCMC.html">318 nips-2012-Sparse Approximate Manifolds for Differential Geometric MCMC</a></p>
<p>18 0.41164973 <a title="336-lsi-18" href="./nips-2012-Nonconvex_Penalization_Using_Laplace_Exponents_and_Concave_Conjugates.html">244 nips-2012-Nonconvex Penalization Using Laplace Exponents and Concave Conjugates</a></p>
<p>19 0.41105905 <a title="336-lsi-19" href="./nips-2012-Training_sparse_natural_image_models_with_a_fast_Gibbs_sampler_of_an_extended_state_space.html">349 nips-2012-Training sparse natural image models with a fast Gibbs sampler of an extended state space</a></p>
<p>20 0.40915608 <a title="336-lsi-20" href="./nips-2012-Efficient_high_dimensional_maximum_entropy_modeling_via_symmetric_partition_functions.html">115 nips-2012-Efficient high dimensional maximum entropy modeling via symmetric partition functions</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.035), (17, 0.012), (21, 0.044), (38, 0.096), (39, 0.01), (42, 0.04), (54, 0.027), (55, 0.02), (65, 0.243), (74, 0.05), (76, 0.172), (80, 0.095), (83, 0.011), (92, 0.069)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.81501204 <a title="336-lda-1" href="./nips-2012-The_Coloured_Noise_Expansion_and_Parameter_Estimation_of_Diffusion_Processes.html">336 nips-2012-The Coloured Noise Expansion and Parameter Estimation of Diffusion Processes</a></p>
<p>Author: Simon Lyons, Amos J. Storkey, Simo Särkkä</p><p>Abstract: Stochastic differential equations (SDE) are a natural tool for modelling systems that are inherently noisy or contain uncertainties that can be modelled as stochastic processes. Crucial to the process of using SDE to build mathematical models is the ability to estimate parameters of those models from observed data. Over the past few decades, signiﬁcant progress has been made on this problem, but we are still far from having a deﬁnitive solution. We describe a novel method of approximating a diffusion process that we show to be useful in Markov chain Monte-Carlo (MCMC) inference algorithms. We take the ‘white’ noise that drives a diffusion process and decompose it into two terms. The ﬁrst is a ‘coloured noise’ term that can be deterministically controlled by a set of auxilliary variables. The second term is small and enables us to form a linear Gaussian ‘small noise’ approximation. The decomposition allows us to take a diffusion process of interest and cast it in a form that is amenable to sampling by MCMC methods. We explain why many state-of-the-art inference methods fail on highly nonlinear inference problems, and we demonstrate experimentally that our method performs well in such situations. Our results show that this method is a promising new tool for use in inference and parameter estimation problems. 1</p><p>2 0.75863636 <a title="336-lda-2" href="./nips-2012-Convergence_and_Energy_Landscape_for_Cheeger_Cut_Clustering.html">85 nips-2012-Convergence and Energy Landscape for Cheeger Cut Clustering</a></p>
<p>Author: Xavier Bresson, Thomas Laurent, David Uminsky, James V. Brecht</p><p>Abstract: This paper provides both theoretical and algorithmic results for the 1 -relaxation of the Cheeger cut problem. The 2 -relaxation, known as spectral clustering, only loosely relates to the Cheeger cut; however, it is convex and leads to a simple optimization problem. The 1 -relaxation, in contrast, is non-convex but is provably equivalent to the original problem. The 1 -relaxation therefore trades convexity for exactness, yielding improved clustering results at the cost of a more challenging optimization. The ﬁrst challenge is understanding convergence of algorithms. This paper provides the ﬁrst complete proof of convergence for algorithms that minimize the 1 -relaxation. The second challenge entails comprehending the 1 energy landscape, i.e. the set of possible points to which an algorithm might converge. We show that 1 -algorithms can get trapped in local minima that are not globally optimal and we provide a classiﬁcation theorem to interpret these local minima. This classiﬁcation gives meaning to these suboptimal solutions and helps to explain, in terms of graph structure, when the 1 -relaxation provides the solution of the original Cheeger cut problem. 1</p><p>3 0.73650795 <a title="336-lda-3" href="./nips-2012-Fast_Bayesian_Inference_for_Non-Conjugate_Gaussian_Process_Regression.html">127 nips-2012-Fast Bayesian Inference for Non-Conjugate Gaussian Process Regression</a></p>
<p>Author: Emtiyaz Khan, Shakir Mohamed, Kevin P. Murphy</p><p>Abstract: We present a new variational inference algorithm for Gaussian process regression with non-conjugate likelihood functions, with application to a wide array of problems including binary and multi-class classiﬁcation, and ordinal regression. Our method constructs a concave lower bound that is optimized using an efﬁcient ﬁxed-point updating algorithm. We show that the new algorithm has highly competitive computational complexity, matching that of alternative approximate inference methods. We also prove that the use of concave variational bounds provides stable and guaranteed convergence – a property not available to other approaches. We show empirically for both binary and multi-class classiﬁcation that our new algorithm converges much faster than existing variational methods, and without any degradation in performance. 1</p><p>4 0.71078336 <a title="336-lda-4" href="./nips-2012-Dual-Space_Analysis_of_the_Sparse_Linear_Model.html">104 nips-2012-Dual-Space Analysis of the Sparse Linear Model</a></p>
<p>Author: Yi Wu, David P. Wipf</p><p>Abstract: Sparse linear (or generalized linear) models combine a standard likelihood function with a sparse prior on the unknown coefﬁcients. These priors can conveniently be expressed as a maximization over zero-mean Gaussians with different variance hyperparameters. Standard MAP estimation (Type I) involves maximizing over both the hyperparameters and coefﬁcients, while an empirical Bayesian alternative (Type II) ﬁrst marginalizes the coefﬁcients and then maximizes over the hyperparameters, leading to a tractable posterior approximation. The underlying cost functions can be related via a dual-space framework from [22], which allows both the Type I or Type II objectives to be expressed in either coefﬁcient or hyperparmeter space. This perspective is useful because some analyses or extensions are more conducive to development in one space or the other. Herein we consider the estimation of a trade-off parameter balancing sparsity and data ﬁt. As this parameter is effectively a variance, natural estimators exist by assessing the problem in hyperparameter (variance) space, transitioning natural ideas from Type II to solve what is much less intuitive for Type I. In contrast, for analyses of update rules and sparsity properties of local and global solutions, as well as extensions to more general likelihood models, we can leverage coefﬁcient-space techniques developed for Type I and apply them to Type II. For example, this allows us to prove that Type II-inspired techniques can be successful recovering sparse coefﬁcients when unfavorable restricted isometry properties (RIP) lead to failure of popular ℓ1 reconstructions. It also facilitates the analysis of Type II when non-Gaussian likelihood models lead to intractable integrations. 1</p><p>5 0.69059157 <a title="336-lda-5" href="./nips-2012-Learning_with_Recursive_Perceptual_Representations.html">197 nips-2012-Learning with Recursive Perceptual Representations</a></p>
<p>Author: Oriol Vinyals, Yangqing Jia, Li Deng, Trevor Darrell</p><p>Abstract: Linear Support Vector Machines (SVMs) have become very popular in vision as part of state-of-the-art object recognition and other classiﬁcation tasks but require high dimensional feature spaces for good performance. Deep learning methods can ﬁnd more compact representations but current methods employ multilayer perceptrons that require solving a difﬁcult, non-convex optimization problem. We propose a deep non-linear classiﬁer whose layers are SVMs and which incorporates random projection as its core stacking element. Our method learns layers of linear SVMs recursively transforming the original data manifold through a random projection of the weak prediction computed from each layer. Our method scales as linear SVMs, does not rely on any kernel computations or nonconvex optimization, and exhibits better generalization ability than kernel-based SVMs. This is especially true when the number of training samples is smaller than the dimensionality of data, a common scenario in many real-world applications. The use of random projections is key to our method, as we show in the experiments section, in which we observe a consistent improvement over previous –often more complicated– methods on several vision and speech benchmarks. 1</p><p>6 0.6880917 <a title="336-lda-6" href="./nips-2012-Learning_from_Distributions_via_Support_Measure_Machines.html">188 nips-2012-Learning from Distributions via Support Measure Machines</a></p>
<p>7 0.68667549 <a title="336-lda-7" href="./nips-2012-Deep_Learning_of_Invariant_Features_via_Simulated_Fixations_in_Video.html">90 nips-2012-Deep Learning of Invariant Features via Simulated Fixations in Video</a></p>
<p>8 0.68540889 <a title="336-lda-8" href="./nips-2012-Sparse_Approximate_Manifolds_for_Differential_Geometric_MCMC.html">318 nips-2012-Sparse Approximate Manifolds for Differential Geometric MCMC</a></p>
<p>9 0.68492615 <a title="336-lda-9" href="./nips-2012-Spectral_learning_of_linear_dynamics_from_generalised-linear_observations_with_application_to_neural_population_data.html">321 nips-2012-Spectral learning of linear dynamics from generalised-linear observations with application to neural population data</a></p>
<p>10 0.68480861 <a title="336-lda-10" href="./nips-2012-Multimodal_Learning_with_Deep_Boltzmann_Machines.html">229 nips-2012-Multimodal Learning with Deep Boltzmann Machines</a></p>
<p>11 0.6847592 <a title="336-lda-11" href="./nips-2012-Max-Margin_Structured_Output_Regression_for_Spatio-Temporal_Action_Localization.html">209 nips-2012-Max-Margin Structured Output Regression for Spatio-Temporal Action Localization</a></p>
<p>12 0.68368196 <a title="336-lda-12" href="./nips-2012-Super-Bit_Locality-Sensitive_Hashing.html">329 nips-2012-Super-Bit Locality-Sensitive Hashing</a></p>
<p>13 0.68366998 <a title="336-lda-13" href="./nips-2012-Projection_Retrieval_for_Classification.html">279 nips-2012-Projection Retrieval for Classification</a></p>
<p>14 0.6832695 <a title="336-lda-14" href="./nips-2012-Ancestor_Sampling_for_Particle_Gibbs.html">41 nips-2012-Ancestor Sampling for Particle Gibbs</a></p>
<p>15 0.68299913 <a title="336-lda-15" href="./nips-2012-Collaborative_Gaussian_Processes_for_Preference_Learning.html">74 nips-2012-Collaborative Gaussian Processes for Preference Learning</a></p>
<p>16 0.68293309 <a title="336-lda-16" href="./nips-2012-Small-Variance_Asymptotics_for_Exponential_Family_Dirichlet_Process_Mixture_Models.html">316 nips-2012-Small-Variance Asymptotics for Exponential Family Dirichlet Process Mixture Models</a></p>
<p>17 0.68177116 <a title="336-lda-17" href="./nips-2012-Locating_Changes_in_Highly_Dependent_Data_with_Unknown_Number_of_Change_Points.html">203 nips-2012-Locating Changes in Highly Dependent Data with Unknown Number of Change Points</a></p>
<p>18 0.68070197 <a title="336-lda-18" href="./nips-2012-Isotropic_Hashing.html">163 nips-2012-Isotropic Hashing</a></p>
<p>19 0.67994207 <a title="336-lda-19" href="./nips-2012-Distributed_Probabilistic_Learning_for_Camera_Networks_with_Missing_Data.html">103 nips-2012-Distributed Probabilistic Learning for Camera Networks with Missing Data</a></p>
<p>20 0.67987621 <a title="336-lda-20" href="./nips-2012-FastEx%3A_Hash_Clustering_with_Exponential_Families.html">126 nips-2012-FastEx: Hash Clustering with Exponential Families</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
