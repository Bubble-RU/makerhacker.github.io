<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>289 nips-2012-Recognizing Activities by Attribute Dynamics</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-289" href="#">nips2012-289</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>289 nips-2012-Recognizing Activities by Attribute Dynamics</h1>
<br/><p>Source: <a title="nips-2012-289-pdf" href="http://papers.nips.cc/paper/4656-recognizing-activities-by-attribute-dynamics.pdf">pdf</a></p><p>Author: Weixin Li, Nuno Vasconcelos</p><p>Abstract: In this work, we consider the problem of modeling the dynamic structure of human activities in the attributes space. A video sequence is Ä?Ĺš rst represented in a semantic feature space, where each feature encodes the probability of occurrence of an activity attribute at a given time. A generative model, denoted the binary dynamic system (BDS), is proposed to learn both the distribution and dynamics of different activities in this space. The BDS is a non-linear dynamic system, which extends both the binary principal component analysis (PCA) and classical linear dynamic systems (LDS), by combining binary observation variables with a hidden Gauss-Markov state process. In this way, it integrates the representation power of semantic modeling with the ability of dynamic systems to capture the temporal structure of time-varying processes. An algorithm for learning BDS parameters, inspired by a popular LDS learning method from dynamic textures, is proposed. A similarity measure between BDSs, which generalizes the BinetCauchy kernel for LDS, is then introduced and used to design activity classiÄ?Ĺš ers. The proposed method is shown to outperform similar classiÄ?Ĺš ers derived from the kernel dynamic system (KDS) and state-of-the-art approaches for dynamics-based or attribute-based action recognition. 1</p><p>Reference: <a title="nips-2012-289-reference" href="../nips2012_reference/nips-2012-Recognizing_Activities_by_Attribute_Dynamics_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract In this work, we consider the problem of modeling the dynamic structure of human activities in the attributes space. [sent-2, score-0.513]
</p><p>2 Ĺš rst represented in a semantic feature space, where each feature encodes the probability of occurrence of an activity attribute at a given time. [sent-4, score-0.751]
</p><p>3 A generative model, denoted the binary dynamic system (BDS), is proposed to learn both the distribution and dynamics of different activities in this space. [sent-5, score-0.49]
</p><p>4 The BDS is a non-linear dynamic system, which extends both the binary principal component analysis (PCA) and classical linear dynamic systems (LDS), by combining binary observation variables with a hidden Gauss-Markov state process. [sent-6, score-0.465]
</p><p>5 In this way, it integrates the representation power of semantic modeling with the ability of dynamic systems to capture the temporal structure of time-varying processes. [sent-7, score-0.363]
</p><p>6 A similarity measure between BDSs, which generalizes the BinetCauchy kernel for LDS, is then introduced and used to design activity classiÄ? [sent-9, score-0.255]
</p><p>7 Ĺš ers derived from the kernel dynamic system (KDS) and state-of-the-art approaches for dynamics-based or attribute-based action recognition. [sent-12, score-0.341]
</p><p>8 1  Introduction  Human activity understanding has been a research topic of substantial interest in computer vision [1]. [sent-13, score-0.238]
</p><p>9 Ĺš cation problems, it is frequently based on the characterization of video as a collection of orderless spatiotemporal features [2, 3]. [sent-15, score-0.185]
</p><p>10 While desirable, modeling action dynamics can be a complex proposition, and this can sometimes compromise the robustness of recognition algorithms, or sacriÄ? [sent-21, score-0.323]
</p><p>11 Ĺš cation [9, 10], is to represent actions in terms of intermediate-level semantic concepts, or attributes [11, 12]. [sent-27, score-0.379]
</p><p>12 This consists of modeling the dynamics of human activities in the attributes space. [sent-32, score-0.54]
</p><p>13 For example, the activity Ă˘&euro;&oelig;storing an object in a boxĂ˘&euro;? [sent-35, score-0.221]
</p><p>14 Ĺš ned as the sequence of the action attributes Ă˘&euro;&oelig;remove (hand from box)Ă˘&euro;? [sent-37, score-0.313]
</p><p>15 The representation of 1  the action as a sequence of these attributes makes the characterization of the Ă˘&euro;&oelig;storing object in boxĂ˘&euro;? [sent-42, score-0.378]
</p><p>16 activity more robust (to confounding factors such as diversity of grabbing styles, hand motion speeds, or camera motions) than dynamic representations based on low-level features. [sent-43, score-0.373]
</p><p>17 It is also more discriminant than semantic representations that ignore dynamics, i. [sent-44, score-0.184]
</p><p>18 , that simply record the occurrence (or frequency) of the action attributes Ă˘&euro;&oelig;removeĂ˘&euro;? [sent-46, score-0.3]
</p><p>19 In the absence of information about the sequence in which these attributes occur, the Ă˘&euro;&oelig;store object in boxĂ˘&euro;? [sent-51, score-0.264]
</p><p>20 activity cannot be distinguished from the Ă˘&euro;&oelig;retrieve object from boxĂ˘&euro;? [sent-52, score-0.221]
</p><p>21 In summary, the modeling of attribute dynamics is 1) more robust and Ä? [sent-59, score-0.581]
</p><p>22 Ĺš&sbquo;exible than the modeling of visual (lowlevel) dynamics, and 2) more discriminant than the modeling of attribute frequencies. [sent-60, score-0.533]
</p><p>23 In this work, we address the problem of modeling attribute dynamics for activities. [sent-61, score-0.581]
</p><p>24 As is usual in semantics-based recognition [11], we start by representing video in a semantic feature space, where each feature encodes the probability of occurrence of an action attribute in the video, at a given time. [sent-62, score-0.812]
</p><p>25 We then propose a generative model, denoted the binary dynamic system (BDS), to learn both the distribution and dynamics of different activities in this space. [sent-63, score-0.49]
</p><p>26 The BDS is a non-linear dynamic system, which combines binary observation variables with a hidden Gauss-Markov state process. [sent-64, score-0.259]
</p><p>27 It can be interpreted as either 1) a generalization of binary principal component analysis (binary PCA) [14], which accounts for data dynamics, or 2) an extension of the classical linear dynamic system (LDS), which operates on a binary observation space. [sent-65, score-0.345]
</p><p>28 For activity recognition, the BDS has the appeal of accounting for the two distinguishing properties of the semantic activity representation: 1) that semantic vectors deÄ? [sent-66, score-0.606]
</p><p>29 Its advantages over previous representations are illustrated by the introduction of BDSbased activity classiÄ? [sent-69, score-0.227]
</p><p>30 Ĺš cient BDS learning algorithm, which combines binary PCA and a least squares problem, inspired by the learning procedure in dynamic textures [15]. [sent-72, score-0.238]
</p><p>31 Ĺš ers derived from the kernel dynamic systems (KDS) [6], and state-of-the-art approaches for dynamics-based [4] and attribute-based [11] action recognition. [sent-77, score-0.315]
</p><p>32 2  Prior Work  One of the most popular representations for activity recognition is the BoF, which reduces video to an collection of orderless spatiotemporal descriptors [2, 3]. [sent-78, score-0.464]
</p><p>33 model a combination of object contexts and action sequences with a dynamic Bayesian network [5], while Gaidon et al. [sent-93, score-0.28]
</p><p>34 reduce each activity to three atomic actions and model their temporal distributions [7]. [sent-94, score-0.37]
</p><p>35 combine dynamic textures [15] and local binary patterns [19], Li et al. [sent-99, score-0.238]
</p><p>36 perform a discriminant canonical correlation analysis on the space of action dynamics [8], and Chaudhry et al. [sent-100, score-0.247]
</p><p>37 Recent research in image recognition has shown that various limitations of the BoF can be overcome with representations of higher semantic level [10]. [sent-102, score-0.216]
</p><p>38 These concepts can be object attributes [9], object classes [20, 21], contextual classes [13], or generic visual concepts [22]. [sent-106, score-0.455]
</p><p>39 Lately, semantic attributes have also been used for action recognition [11], demonstrating the beneÄ? [sent-107, score-0.443]
</p><p>40 (bottom); Right: attribute transition probabilities of the two activities (Ă˘&euro;&oelig;hurdle raceĂ˘&euro;? [sent-161, score-0.534]
</p><p>41 The work also suggests that, for action categorization, supervised attribute learning is far more useful than unsupervised learning, resembling a similar observation from image recognition [20]. [sent-167, score-0.575]
</p><p>42 However, all of these representations are BoF-like, in the sense that they represent actions as orderless feature collections, reducing an entire video sequence to an attribute vector. [sent-168, score-0.707]
</p><p>43 For this reason, we denote them holistic attribute representations. [sent-169, score-0.513]
</p><p>44 The temporal evolution of semantic concepts, throughout a video sequence, has not yet been exploited as a cue for action understanding. [sent-170, score-0.371]
</p><p>45 Two representatives are the dynamic topic model (DTM) [23] and the topic over time (TOT) model [24]. [sent-172, score-0.223]
</p><p>46 Although modeling topic dynamics, these models are not necessarily applicable to semantic action recognition. [sent-173, score-0.306]
</p><p>47 Second, the joint goal of topic discovery and modeling topic dynamics requires a complex graphical model. [sent-175, score-0.294]
</p><p>48 3  Modeling the Dynamics of Activity Attributes  In this section, we introduce a new model, the binary dynamic system, for joint representation of the distribution and dynamics of activities in action attribute space. [sent-178, score-0.975]
</p><p>49 Ĺš ers maps the video to a semantic space S, according to Ä&#x17D;&euro; : X Ă˘&dagger;&rsquo; S = [0, 1]K , Ä&#x17D;&euro;(v) = (Ä&#x17D;&euro;1 (v), Ă&sbquo;Ë&Dagger; Ă&sbquo;Ë&Dagger; Ă&sbquo;Ë&Dagger; , Ä&#x17D;&euro;K (v))T , where Ä&#x17D;&euro;i (v) is the conÄ? [sent-188, score-0.297]
</p><p>50 As the video sequence v progresses with time t, the semantic encoding deÄ? [sent-196, score-0.267]
</p><p>51 Ĺš ts of semantic representations for recognition, namely a higher level of abstraction (which leads to better generalization than appearance-based representations), substantial robustness to the performance of the visual classiÄ? [sent-199, score-0.214]
</p><p>52 No attention has, however, been devoted to modeling the dynamics of semantic encodings of video. [sent-201, score-0.304]
</p><p>53 Figure 1 motivates the importance of such modeling for action recognition, by considering two activity categories (Ă˘&euro;&oelig;long jumpĂ˘&euro;? [sent-202, score-0.341]
</p><p>54 Ĺš dence scores {Ä&#x17D;&euro; t } produced by a set of K attribute classiÄ? [sent-220, score-0.456]
</p><p>55 Ĺš ers (and not a sample of binary attribute vectors per se). [sent-221, score-0.543]
</p><p>56 By maximizing the expected log-likelihood (4), the optimal projection {Ă&#x17D;Â¸ Ă˘&circ;&mdash; } of the attribute score vectors {Ä&#x17D;&euro; t } on the subspace of (3) also minimizes the t KL divergence of (8). [sent-230, score-0.514]
</p><p>57 While the LDS parameters 4  Algorithm 1: Learning a binary dynamic system Input : a sequence of attribute score vectors {Ä&#x17D;&euro; t }Ä&#x17D;&bdquo; , state space dimension n. [sent-240, score-0.737]
</p><p>58 As in binary PCA, for attribute-based recognition the binary observations y t are replaced by the attribute scores Ä&#x17D;&euro; t , their log-likelihood under (10) by the expected log-likelihood, and the optimal solution minimizes the approximation of (5) for the most natural deÄ? [sent-251, score-0.656]
</p><p>59 , kernel dynamic systems (KDS) that rely on a non-linear kernel PCA (KPCA) [27] of the observation space but still assume an Euclidean measure (Gaussian noise) [28, 6], do not share this property. [sent-256, score-0.238]
</p><p>60 We will see, in the experimental section, that the BDS is a better model of attribute dynamics. [sent-257, score-0.397]
</p><p>61 Ĺš ers that account for attribute dynamics requires the ability to quantify similarity between BDSs. [sent-274, score-0.638]
</p><p>62 5  Experiments  Several experiments were conducted to evaluate the BDS as a model of activity attribute dynamics. [sent-284, score-0.58]
</p><p>63 A codebook of 3000 visual words was learned via k-means, from the entire training set, and a binary SVM with histogram intersection kernel (HIK) and probability outputs [29] trained to detect each attribute using the attribute deÄ? [sent-286, score-0.939]
</p><p>64 The probability for attribute k at time t was used as attribute score Ä&#x17D;&euro;tk , which was computed over a window of 20 frames, sliding across a video. [sent-288, score-0.846]
</p><p>65 Ĺš rst used complex activity sequences synthesized from the Weizmann dataset [17]. [sent-291, score-0.225]
</p><p>66 The row of images at the top of Figure 2 presents an example of an activity sequence of degree 5. [sent-300, score-0.225]
</p><p>67 Ĺš ned per degree n (total of 120 activity categories) and a dataset was assembled per category, containing one activity sequence per person (9 people, 1080 sequences in total). [sent-314, score-0.45]
</p><p>68 Overall, the activity sequences differ in the number, category, and temporal order of atomic actions. [sent-315, score-0.337]
</p><p>69 Since the attribute ground truth is available for all atomic actions in this dataset, it is possible to train clean attribute models. [sent-316, score-0.922]
</p><p>70 Figure 3: Log KL-divergence between original and reconstructed attribute scores, v. [sent-326, score-0.397]
</p><p>71 number of PCA components n, on Weizmann activities for PCA, kernel PCA, and binary PCA. [sent-328, score-0.254]
</p><p>72 To gain some more insight on the different models, a KDS and a BDS were learned from the 30 dimensional attribute score vectors of the activity sequence in Figure 2. [sent-349, score-0.674]
</p><p>73 A new set of attribute score vectors were then sampled from each model. [sent-350, score-0.449]
</p><p>74 Note how the scores sampled from the BDS approximate the original attribute scores better than those sampled from the KDS, which is conÄ? [sent-354, score-0.515]
</p><p>75 Ĺš rmed by the KL-divergences between the original attribute scores and those sampled from the two models (also shown in the Ä? [sent-355, score-0.456]
</p><p>76 Ĺš er that ignores attribute dynamics (using a single attribute score vector computed from the entire video sequence) and the dynamic topic models DTM [23] and TOT [24] from the text literature. [sent-363, score-1.308]
</p><p>77 For the latter, the topics were equated to the activity attributes and learned with supervision (using the SVMs discussed above). [sent-364, score-0.367]
</p><p>78 X 2 distance was used for the BoF and holistic attribute classiÄ? [sent-370, score-0.513]
</p><p>79 BDS and KDS had the best performance, followed by the dynamic topic models, and the dynamics insensitive methods (BoF and holistic). [sent-375, score-0.308]
</p><p>80 , discrimination between activities composed of similar actions executed in different sequence, requires modeling of attribute dynamics. [sent-384, score-0.681]
</p><p>81 Since attribute labels are only available for whole sequences, the training sets of the attribute classiÄ? [sent-421, score-0.794]
</p><p>82 First, the noisy attributes make the dynamics harder to model. [sent-431, score-0.324]
</p><p>83 Ĺš ne grained discrimination is not needed for all categories, attribute dynamics are not always necessary. [sent-435, score-0.565]
</p><p>84 Overall, despite the attribute noise and the fact that dynamics are not always required for discrimination, the BDS achieves the best performance on this dataset. [sent-447, score-0.537]
</p><p>85 Ĺš cation with the BoF [3], dynamic representations [4], and attributes [11], were selected as benchmarks. [sent-452, score-0.341]
</p><p>86 These were compared to our implementation of BoF (kernel using only word histograms), attributes (the holistic classiÄ? [sent-453, score-0.3]
</p><p>87 Ĺš ers combining 1) BoF and attributes (B+A), and 2) BoF, attributes, and dynamics (B+A+D). [sent-456, score-0.396]
</p><p>88 Ĺš es BoF histograms and hollistic attribute vectors with a latent SVM. [sent-464, score-0.421]
</p><p>89 [4]), which accounts for the dynamics of the BoF but not action attributes. [sent-468, score-0.227]
</p><p>90 This holds despite the fact that our attribute categories (only 40 speciÄ? [sent-469, score-0.424]
</p><p>91 The use of a stronger attribute detection architecture could potentially further improve these results. [sent-474, score-0.397]
</p><p>92 Note also that the addition of the BDS kernel to the simple attribute representation (B+A+D) far outperforms the use of the more sophisticated attribute classiÄ? [sent-475, score-0.864]
</p><p>93 Ĺš er of [11], which does not account for attribute dynamics. [sent-476, score-0.446]
</p><p>94 The combination of BoF, attributes, and attribute dynamics achieves the overall best performance on this dataset. [sent-479, score-0.537]
</p><p>95 We also thank Jingen Liu for providing the attribute annotations. [sent-481, score-0.397]
</p><p>96 Fei-Fei, Ă˘&euro;&oelig;Modeling temporal structure of decomposable motion segments for activity classiÄ? [sent-508, score-0.275]
</p><p>97 Kriegman, Ă˘&euro;&oelig;Leveraging temporal, contextual and ordering constraints for recognizing complex activities in video,Ă˘&euro;? [sent-514, score-0.193]
</p><p>98 Harmeling, Ă˘&euro;&oelig;Learning to detect unseen object classes by between-class attribute transfer,Ă˘&euro;? [sent-540, score-0.461]
</p><p>99 Forsyth, Ă˘&euro;&oelig;Searching for complex human activities with no visual examples,Ă˘&euro;? [sent-608, score-0.2]
</p><p>100 PietikĂ&sbquo;Â¨ inen, Ă˘&euro;&oelig;Human activity recognition using a dynamic texture based a method,Ă˘&euro;? [sent-617, score-0.348]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('bds', 0.498), ('attribute', 0.397), ('bof', 0.272), ('lds', 0.207), ('attributes', 0.184), ('activity', 0.183), ('kds', 0.176), ('kt', 0.175), ('pca', 0.16), ('dynamics', 0.14), ('activities', 0.137), ('ykt', 0.129), ('semantic', 0.12), ('holistic', 0.116), ('dynamic', 0.113), ('video', 0.105), ('olympic', 0.103), ('action', 0.087), ('weizmann', 0.078), ('actions', 0.075), ('binary', 0.074), ('bdss', 0.073), ('dtm', 0.073), ('kpca', 0.073), ('ers', 0.072), ('classi', 0.07), ('sports', 0.069), ('vasconcelos', 0.061), ('temporal', 0.059), ('scores', 0.059), ('tot', 0.059), ('kl', 0.058), ('topic', 0.055), ('atomic', 0.053), ('score', 0.052), ('recognition', 0.052), ('textures', 0.051), ('cvpr', 0.051), ('box', 0.049), ('er', 0.049), ('niebles', 0.048), ('cxt', 0.045), ('representations', 0.044), ('binetcauchy', 0.044), ('grab', 0.044), ('orderless', 0.044), ('rasiwasia', 0.044), ('snatch', 0.044), ('modeling', 0.044), ('kernel', 0.043), ('concepts', 0.042), ('sequences', 0.042), ('sequence', 0.042), ('jump', 0.041), ('hurdle', 0.039), ('observation', 0.039), ('object', 0.038), ('spatiotemporal', 0.036), ('human', 0.035), ('race', 0.034), ('subspace', 0.034), ('motion', 0.033), ('state', 0.033), ('laptev', 0.032), ('wt', 0.031), ('contextual', 0.031), ('bernoulli', 0.031), ('divergence', 0.031), ('insert', 0.029), ('logit', 0.029), ('chaudhry', 0.029), ('dbc', 0.029), ('gaidon', 0.029), ('kellokumpu', 0.029), ('laxton', 0.029), ('occurrence', 0.029), ('similarity', 0.029), ('int', 0.028), ('discrimination', 0.028), ('visual', 0.028), ('ey', 0.028), ('representation', 0.027), ('categories', 0.027), ('xt', 0.026), ('classes', 0.026), ('system', 0.026), ('recognizing', 0.025), ('histograms', 0.024), ('ts', 0.022), ('vidal', 0.022), ('encodes', 0.022), ('land', 0.021), ('axt', 0.021), ('frames', 0.021), ('underlies', 0.02), ('discriminant', 0.02), ('ev', 0.02), ('scatter', 0.02), ('motions', 0.02), ('principal', 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="289-tfidf-1" href="./nips-2012-Recognizing_Activities_by_Attribute_Dynamics.html">289 nips-2012-Recognizing Activities by Attribute Dynamics</a></p>
<p>Author: Weixin Li, Nuno Vasconcelos</p><p>Abstract: In this work, we consider the problem of modeling the dynamic structure of human activities in the attributes space. A video sequence is Ä?Ĺš rst represented in a semantic feature space, where each feature encodes the probability of occurrence of an activity attribute at a given time. A generative model, denoted the binary dynamic system (BDS), is proposed to learn both the distribution and dynamics of different activities in this space. The BDS is a non-linear dynamic system, which extends both the binary principal component analysis (PCA) and classical linear dynamic systems (LDS), by combining binary observation variables with a hidden Gauss-Markov state process. In this way, it integrates the representation power of semantic modeling with the ability of dynamic systems to capture the temporal structure of time-varying processes. An algorithm for learning BDS parameters, inspired by a popular LDS learning method from dynamic textures, is proposed. A similarity measure between BDSs, which generalizes the BinetCauchy kernel for LDS, is then introduced and used to design activity classiÄ?Ĺš ers. The proposed method is shown to outperform similar classiÄ?Ĺš ers derived from the kernel dynamic system (KDS) and state-of-the-art approaches for dynamics-based or attribute-based action recognition. 1</p><p>2 0.11675564 <a title="289-tfidf-2" href="./nips-2012-Max-Margin_Structured_Output_Regression_for_Spatio-Temporal_Action_Localization.html">209 nips-2012-Max-Margin Structured Output Regression for Spatio-Temporal Action Localization</a></p>
<p>Author: Du Tran, Junsong Yuan</p><p>Abstract: Structured output learning has been successfully applied to object localization, where the mapping between an image and an object bounding box can be well captured. Its extension to action localization in videos, however, is much more challenging, because we need to predict the locations of the action patterns both spatially and temporally, i.e., identifying a sequence of bounding boxes that track the action in video. The problem becomes intractable due to the exponentially large size of the structured video space where actions could occur. We propose a novel structured learning approach for spatio-temporal action localization. The mapping between a video and a spatio-temporal action trajectory is learned. The intractable inference and learning problems are addressed by leveraging an efﬁcient Max-Path search method, thus making it feasible to optimize the model over the whole structured space. Experiments on two challenging benchmark datasets show that our proposed method outperforms the state-of-the-art methods. 1</p><p>3 0.10568232 <a title="289-tfidf-3" href="./nips-2012-Timely_Object_Recognition.html">344 nips-2012-Timely Object Recognition</a></p>
<p>Author: Sergey Karayev, Tobias Baumgartner, Mario Fritz, Trevor Darrell</p><p>Abstract: In a large visual multi-class detection framework, the timeliness of results can be crucial. Our method for timely multi-class detection aims to give the best possible performance at any single point after a start time; it is terminated at a deadline time. Toward this goal, we formulate a dynamic, closed-loop policy that infers the contents of the image in order to decide which detector to deploy next. In contrast to previous work, our method signiﬁcantly diverges from the predominant greedy strategies, and is able to learn to take actions with deferred values. We evaluate our method with a novel timeliness measure, computed as the area under an Average Precision vs. Time curve. Experiments are conducted on the PASCAL VOC object detection dataset. If execution is stopped when only half the detectors have been run, our method obtains 66% better AP than a random ordering, and 14% better performance than an intelligent baseline. On the timeliness measure, our method obtains at least 11% better performance. Our method is easily extensible, as it treats detectors and classiﬁers as black boxes and learns from execution traces using reinforcement learning. 1</p><p>4 0.10539838 <a title="289-tfidf-4" href="./nips-2012-Semantic_Kernel_Forests_from_Multiple_Taxonomies.html">306 nips-2012-Semantic Kernel Forests from Multiple Taxonomies</a></p>
<p>Author: Sung J. Hwang, Kristen Grauman, Fei Sha</p><p>Abstract: When learning features for complex visual recognition problems, labeled image exemplars alone can be insufﬁcient. While an object taxonomy specifying the categories’ semantic relationships could bolster the learning process, not all relationships are relevant to a given visual classiﬁcation task, nor does a single taxonomy capture all ties that are relevant. In light of these issues, we propose a discriminative feature learning approach that leverages multiple hierarchical taxonomies representing different semantic views of the object categories (e.g., for animal classes, one taxonomy could reﬂect their phylogenic ties, while another could reﬂect their habitats). For each taxonomy, we ﬁrst learn a tree of semantic kernels, where each node has a Mahalanobis kernel optimized to distinguish between the classes in its children nodes. Then, using the resulting semantic kernel forest, we learn class-speciﬁc kernel combinations to select only those relationships relevant to recognize each object class. To learn the weights, we introduce a novel hierarchical regularization term that further exploits the taxonomies’ structure. We demonstrate our method on challenging object recognition datasets, and show that interleaving multiple taxonomic views yields signiﬁcant accuracy improvements.</p><p>5 0.10492373 <a title="289-tfidf-5" href="./nips-2012-Kernel_Latent_SVM_for_Visual_Recognition.html">168 nips-2012-Kernel Latent SVM for Visual Recognition</a></p>
<p>Author: Weilong Yang, Yang Wang, Arash Vahdat, Greg Mori</p><p>Abstract: Latent SVMs (LSVMs) are a class of powerful tools that have been successfully applied to many applications in computer vision. However, a limitation of LSVMs is that they rely on linear models. For many computer vision tasks, linear models are suboptimal and nonlinear models learned with kernels typically perform much better. Therefore it is desirable to develop the kernel version of LSVM. In this paper, we propose kernel latent SVM (KLSVM) – a new learning framework that combines latent SVMs and kernel methods. We develop an iterative training algorithm to learn the model parameters. We demonstrate the effectiveness of KLSVM using three different applications in visual recognition. Our KLSVM formulation is very general and can be applied to solve a wide range of applications in computer vision and machine learning. 1</p><p>6 0.1000863 <a title="289-tfidf-6" href="./nips-2012-Shifting_Weights%3A_Adapting_Object_Detectors_from_Image_to_Video.html">311 nips-2012-Shifting Weights: Adapting Object Detectors from Image to Video</a></p>
<p>7 0.084194295 <a title="289-tfidf-7" href="./nips-2012-Local_Supervised_Learning_through_Space_Partitioning.html">200 nips-2012-Local Supervised Learning through Space Partitioning</a></p>
<p>8 0.076282561 <a title="289-tfidf-8" href="./nips-2012-Complex_Inference_in_Neural_Circuits_with_Probabilistic_Population_Codes_and_Topic_Models.html">77 nips-2012-Complex Inference in Neural Circuits with Probabilistic Population Codes and Topic Models</a></p>
<p>9 0.075793378 <a title="289-tfidf-9" href="./nips-2012-Deep_Learning_of_Invariant_Features_via_Simulated_Fixations_in_Video.html">90 nips-2012-Deep Learning of Invariant Features via Simulated Fixations in Video</a></p>
<p>10 0.062494513 <a title="289-tfidf-10" href="./nips-2012-Learning_with_Recursive_Perceptual_Representations.html">197 nips-2012-Learning with Recursive Perceptual Representations</a></p>
<p>11 0.06134209 <a title="289-tfidf-11" href="./nips-2012-A_mechanistic_model_of_early_sensory_processing_based_on_subtracting_sparse_representations.html">24 nips-2012-A mechanistic model of early sensory processing based on subtracting sparse representations</a></p>
<p>12 0.054433122 <a title="289-tfidf-12" href="./nips-2012-Searching_for_objects_driven_by_context.html">303 nips-2012-Searching for objects driven by context</a></p>
<p>13 0.053546775 <a title="289-tfidf-13" href="./nips-2012-Memorability_of_Image_Regions.html">210 nips-2012-Memorability of Image Regions</a></p>
<p>14 0.053232305 <a title="289-tfidf-14" href="./nips-2012-Efficient_high_dimensional_maximum_entropy_modeling_via_symmetric_partition_functions.html">115 nips-2012-Efficient high dimensional maximum entropy modeling via symmetric partition functions</a></p>
<p>15 0.052379981 <a title="289-tfidf-15" href="./nips-2012-Latent_Coincidence_Analysis%3A_A_Hidden_Variable_Model_for_Distance_Metric_Learning.html">171 nips-2012-Latent Coincidence Analysis: A Hidden Variable Model for Distance Metric Learning</a></p>
<p>16 0.052058693 <a title="289-tfidf-16" href="./nips-2012-Stochastic_optimization_and_sparse_statistical_recovery%3A_Optimal_algorithms_for_high_dimensions.html">325 nips-2012-Stochastic optimization and sparse statistical recovery: Optimal algorithms for high dimensions</a></p>
<p>17 0.051815569 <a title="289-tfidf-17" href="./nips-2012-Transferring_Expectations_in_Model-based_Reinforcement_Learning.html">353 nips-2012-Transferring Expectations in Model-based Reinforcement Learning</a></p>
<p>18 0.051358994 <a title="289-tfidf-18" href="./nips-2012-Dynamical_And-Or_Graph_Learning_for_Object_Shape_Modeling_and_Detection.html">106 nips-2012-Dynamical And-Or Graph Learning for Object Shape Modeling and Detection</a></p>
<p>19 0.051205177 <a title="289-tfidf-19" href="./nips-2012-Augmented-SVM%3A_Automatic_space_partitioning_for_combining_multiple_non-linear_dynamics.html">48 nips-2012-Augmented-SVM: Automatic space partitioning for combining multiple non-linear dynamics</a></p>
<p>20 0.050230514 <a title="289-tfidf-20" href="./nips-2012-Action-Model_Based_Multi-agent_Plan_Recognition.html">31 nips-2012-Action-Model Based Multi-agent Plan Recognition</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.165), (1, -0.016), (2, -0.116), (3, 0.017), (4, 0.039), (5, -0.028), (6, 0.008), (7, 0.021), (8, 0.008), (9, -0.036), (10, 0.012), (11, 0.028), (12, 0.087), (13, -0.06), (14, 0.053), (15, 0.055), (16, 0.002), (17, 0.005), (18, -0.006), (19, 0.01), (20, -0.023), (21, -0.029), (22, -0.094), (23, -0.103), (24, -0.001), (25, -0.089), (26, -0.011), (27, 0.0), (28, 0.002), (29, 0.024), (30, 0.012), (31, 0.09), (32, 0.041), (33, -0.051), (34, -0.064), (35, 0.054), (36, 0.036), (37, -0.078), (38, 0.07), (39, 0.045), (40, 0.064), (41, -0.026), (42, 0.011), (43, 0.012), (44, -0.085), (45, 0.001), (46, 0.001), (47, 0.019), (48, -0.026), (49, 0.049)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9300198 <a title="289-lsi-1" href="./nips-2012-Recognizing_Activities_by_Attribute_Dynamics.html">289 nips-2012-Recognizing Activities by Attribute Dynamics</a></p>
<p>Author: Weixin Li, Nuno Vasconcelos</p><p>Abstract: In this work, we consider the problem of modeling the dynamic structure of human activities in the attributes space. A video sequence is Ä?Ĺš rst represented in a semantic feature space, where each feature encodes the probability of occurrence of an activity attribute at a given time. A generative model, denoted the binary dynamic system (BDS), is proposed to learn both the distribution and dynamics of different activities in this space. The BDS is a non-linear dynamic system, which extends both the binary principal component analysis (PCA) and classical linear dynamic systems (LDS), by combining binary observation variables with a hidden Gauss-Markov state process. In this way, it integrates the representation power of semantic modeling with the ability of dynamic systems to capture the temporal structure of time-varying processes. An algorithm for learning BDS parameters, inspired by a popular LDS learning method from dynamic textures, is proposed. A similarity measure between BDSs, which generalizes the BinetCauchy kernel for LDS, is then introduced and used to design activity classiÄ?Ĺš ers. The proposed method is shown to outperform similar classiÄ?Ĺš ers derived from the kernel dynamic system (KDS) and state-of-the-art approaches for dynamics-based or attribute-based action recognition. 1</p><p>2 0.750346 <a title="289-lsi-2" href="./nips-2012-Max-Margin_Structured_Output_Regression_for_Spatio-Temporal_Action_Localization.html">209 nips-2012-Max-Margin Structured Output Regression for Spatio-Temporal Action Localization</a></p>
<p>Author: Du Tran, Junsong Yuan</p><p>Abstract: Structured output learning has been successfully applied to object localization, where the mapping between an image and an object bounding box can be well captured. Its extension to action localization in videos, however, is much more challenging, because we need to predict the locations of the action patterns both spatially and temporally, i.e., identifying a sequence of bounding boxes that track the action in video. The problem becomes intractable due to the exponentially large size of the structured video space where actions could occur. We propose a novel structured learning approach for spatio-temporal action localization. The mapping between a video and a spatio-temporal action trajectory is learned. The intractable inference and learning problems are addressed by leveraging an efﬁcient Max-Path search method, thus making it feasible to optimize the model over the whole structured space. Experiments on two challenging benchmark datasets show that our proposed method outperforms the state-of-the-art methods. 1</p><p>3 0.70066959 <a title="289-lsi-3" href="./nips-2012-Shifting_Weights%3A_Adapting_Object_Detectors_from_Image_to_Video.html">311 nips-2012-Shifting Weights: Adapting Object Detectors from Image to Video</a></p>
<p>Author: Kevin Tang, Vignesh Ramanathan, Li Fei-fei, Daphne Koller</p><p>Abstract: Typical object detectors trained on images perform poorly on video, as there is a clear distinction in domain between the two types of data. In this paper, we tackle the problem of adapting object detectors learned from images to work well on videos. We treat the problem as one of unsupervised domain adaptation, in which we are given labeled data from the source domain (image), but only unlabeled data from the target domain (video). Our approach, self-paced domain adaptation, seeks to iteratively adapt the detector by re-training the detector with automatically discovered target domain examples, starting with the easiest ﬁrst. At each iteration, the algorithm adapts by considering an increased number of target domain examples, and a decreased number of source domain examples. To discover target domain examples from the vast amount of video data, we introduce a simple, robust approach that scores trajectory tracks instead of bounding boxes. We also show how rich and expressive features speciﬁc to the target domain can be incorporated under the same framework. We show promising results on the 2011 TRECVID Multimedia Event Detection [1] and LabelMe Video [2] datasets that illustrate the beneﬁt of our approach to adapt object detectors to video. 1</p><p>4 0.6724509 <a title="289-lsi-4" href="./nips-2012-Action-Model_Based_Multi-agent_Plan_Recognition.html">31 nips-2012-Action-Model Based Multi-agent Plan Recognition</a></p>
<p>Author: Hankz H. Zhuo, Qiang Yang, Subbarao Kambhampati</p><p>Abstract: Multi-Agent Plan Recognition (MAPR) aims to recognize dynamic team structures and team behaviors from the observed team traces (activity sequences) of a set of intelligent agents. Previous MAPR approaches required a library of team activity sequences (team plans) be given as input. However, collecting a library of team plans to ensure adequate coverage is often difﬁcult and costly. In this paper, we relax this constraint, so that team plans are not required to be provided beforehand. We assume instead that a set of action models are available. Such models are often already created to describe domain physics; i.e., the preconditions and effects of effects actions. We propose a novel approach for recognizing multi-agent team plans based on such action models rather than libraries of team plans. We encode the resulting MAPR problem as a satisﬁability problem and solve the problem using a state-of-the-art weighted MAX-SAT solver. Our approach also allows for incompleteness in the observed plan traces. Our empirical studies demonstrate that our algorithm is both effective and efﬁcient in comparison to state-of-the-art MAPR methods based on plan libraries. 1</p><p>5 0.63861632 <a title="289-lsi-5" href="./nips-2012-Learning_with_Target_Prior.html">198 nips-2012-Learning with Target Prior</a></p>
<p>Author: Zuoguan Wang, Siwei Lyu, Gerwin Schalk, Qiang Ji</p><p>Abstract: In the conventional approaches for supervised parametric learning, relations between data and target variables are provided through training sets consisting of pairs of corresponded data and target variables. In this work, we describe a new learning scheme for parametric learning, in which the target variables y can be modeled with a prior model p(y) and the relations between data and target variables are estimated with p(y) and a set of uncorresponded data X in training. We term this method as learning with target priors (LTP). Speciﬁcally, LTP learning seeks parameter θ that maximizes the log likelihood of fθ (X) on a uncorresponded training set with regards to p(y). Compared to the conventional (semi)supervised learning approach, LTP can make efﬁcient use of prior knowledge of the target variables in the form of probabilistic distributions, and thus removes/reduces the reliance on training data in learning. Compared to the Bayesian approach, the learned parametric regressor in LTP can be more efﬁciently implemented and deployed in tasks where running efﬁciency is critical. We demonstrate the effectiveness of the proposed approach on parametric regression tasks for BCI signal decoding and pose estimation from video. 1</p><p>6 0.63221467 <a title="289-lsi-6" href="./nips-2012-Timely_Object_Recognition.html">344 nips-2012-Timely Object Recognition</a></p>
<p>7 0.57965106 <a title="289-lsi-7" href="./nips-2012-A_P300_BCI_for_the_Masses%3A_Prior_Information_Enables_Instant_Unsupervised_Spelling.html">14 nips-2012-A P300 BCI for the Masses: Prior Information Enables Instant Unsupervised Spelling</a></p>
<p>8 0.57339126 <a title="289-lsi-8" href="./nips-2012-Bandit_Algorithms_boost_Brain_Computer_Interfaces_for_motor-task_selection_of_a_brain-controlled_button.html">50 nips-2012-Bandit Algorithms boost Brain Computer Interfaces for motor-task selection of a brain-controlled button</a></p>
<p>9 0.55578625 <a title="289-lsi-9" href="./nips-2012-Unsupervised_Structure_Discovery_for_Semantic_Analysis_of_Audio.html">356 nips-2012-Unsupervised Structure Discovery for Semantic Analysis of Audio</a></p>
<p>10 0.55118954 <a title="289-lsi-10" href="./nips-2012-Visual_Recognition_using_Embedded_Feature_Selection_for_Curvature_Self-Similarity.html">360 nips-2012-Visual Recognition using Embedded Feature Selection for Curvature Self-Similarity</a></p>
<p>11 0.54580706 <a title="289-lsi-11" href="./nips-2012-Phoneme_Classification_using_Constrained_Variational_Gaussian_Process_Dynamical_System.html">270 nips-2012-Phoneme Classification using Constrained Variational Gaussian Process Dynamical System</a></p>
<p>12 0.53917849 <a title="289-lsi-12" href="./nips-2012-Semantic_Kernel_Forests_from_Multiple_Taxonomies.html">306 nips-2012-Semantic Kernel Forests from Multiple Taxonomies</a></p>
<p>13 0.53672755 <a title="289-lsi-13" href="./nips-2012-On_the_connections_between_saliency_and_tracking.html">256 nips-2012-On the connections between saliency and tracking</a></p>
<p>14 0.53557861 <a title="289-lsi-14" href="./nips-2012-Kernel_Latent_SVM_for_Visual_Recognition.html">168 nips-2012-Kernel Latent SVM for Visual Recognition</a></p>
<p>15 0.52480906 <a title="289-lsi-15" href="./nips-2012-A_systematic_approach_to_extracting_semantic_information_from_functional_MRI_data.html">28 nips-2012-A systematic approach to extracting semantic information from functional MRI data</a></p>
<p>16 0.50776273 <a title="289-lsi-16" href="./nips-2012-Deep_Learning_of_Invariant_Features_via_Simulated_Fixations_in_Video.html">90 nips-2012-Deep Learning of Invariant Features via Simulated Fixations in Video</a></p>
<p>17 0.50270295 <a title="289-lsi-17" href="./nips-2012-Transferring_Expectations_in_Model-based_Reinforcement_Learning.html">353 nips-2012-Transferring Expectations in Model-based Reinforcement Learning</a></p>
<p>18 0.50214136 <a title="289-lsi-18" href="./nips-2012-Graphical_Gaussian_Vector_for_Image_Categorization.html">146 nips-2012-Graphical Gaussian Vector for Image Categorization</a></p>
<p>19 0.48740557 <a title="289-lsi-19" href="./nips-2012-Searching_for_objects_driven_by_context.html">303 nips-2012-Searching for objects driven by context</a></p>
<p>20 0.48493314 <a title="289-lsi-20" href="./nips-2012-Predicting_Action_Content_On-Line_and_in_Real_Time_before_Action_Onset_%E2%80%93_an_Intracranial_Human_Study.html">273 nips-2012-Predicting Action Content On-Line and in Real Time before Action Onset – an Intracranial Human Study</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.033), (21, 0.041), (38, 0.067), (42, 0.403), (54, 0.039), (55, 0.036), (74, 0.057), (76, 0.11), (80, 0.061), (92, 0.05)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.83506638 <a title="289-lda-1" href="./nips-2012-Recognizing_Activities_by_Attribute_Dynamics.html">289 nips-2012-Recognizing Activities by Attribute Dynamics</a></p>
<p>Author: Weixin Li, Nuno Vasconcelos</p><p>Abstract: In this work, we consider the problem of modeling the dynamic structure of human activities in the attributes space. A video sequence is Ä?Ĺš rst represented in a semantic feature space, where each feature encodes the probability of occurrence of an activity attribute at a given time. A generative model, denoted the binary dynamic system (BDS), is proposed to learn both the distribution and dynamics of different activities in this space. The BDS is a non-linear dynamic system, which extends both the binary principal component analysis (PCA) and classical linear dynamic systems (LDS), by combining binary observation variables with a hidden Gauss-Markov state process. In this way, it integrates the representation power of semantic modeling with the ability of dynamic systems to capture the temporal structure of time-varying processes. An algorithm for learning BDS parameters, inspired by a popular LDS learning method from dynamic textures, is proposed. A similarity measure between BDSs, which generalizes the BinetCauchy kernel for LDS, is then introduced and used to design activity classiÄ?Ĺš ers. The proposed method is shown to outperform similar classiÄ?Ĺš ers derived from the kernel dynamic system (KDS) and state-of-the-art approaches for dynamics-based or attribute-based action recognition. 1</p><p>2 0.79758418 <a title="289-lda-2" href="./nips-2012-Modelling_Reciprocating_Relationships_with_Hawkes_Processes.html">219 nips-2012-Modelling Reciprocating Relationships with Hawkes Processes</a></p>
<p>Author: Charles Blundell, Jeff Beck, Katherine A. Heller</p><p>Abstract: We present a Bayesian nonparametric model that discovers implicit social structure from interaction time-series data. Social groups are often formed implicitly, through actions among members of groups. Yet many models of social networks use explicitly declared relationships to infer social structure. We consider a particular class of Hawkes processes, a doubly stochastic point process, that is able to model reciprocity between groups of individuals. We then extend the Inﬁnite Relational Model by using these reciprocating Hawkes processes to parameterise its edges, making events associated with edges co-dependent through time. Our model outperforms general, unstructured Hawkes processes as well as structured Poisson process-based models at predicting verbal and email turn-taking, and military conﬂicts among nations. 1</p><p>3 0.79459685 <a title="289-lda-3" href="./nips-2012-Non-linear_Metric_Learning.html">242 nips-2012-Non-linear Metric Learning</a></p>
<p>Author: Dor Kedem, Stephen Tyree, Fei Sha, Gert R. Lanckriet, Kilian Q. Weinberger</p><p>Abstract: In this paper, we introduce two novel metric learning algorithms, χ2 -LMNN and GB-LMNN, which are explicitly designed to be non-linear and easy-to-use. The two approaches achieve this goal in fundamentally different ways: χ2 -LMNN inherits the computational beneﬁts of a linear mapping from linear metric learning, but uses a non-linear χ2 -distance to explicitly capture similarities within histogram data sets; GB-LMNN applies gradient-boosting to learn non-linear mappings directly in function space and takes advantage of this approach’s robustness, speed, parallelizability and insensitivity towards the single additional hyperparameter. On various benchmark data sets, we demonstrate these methods not only match the current state-of-the-art in terms of kNN classiﬁcation error, but in the case of χ2 -LMNN, obtain best results in 19 out of 20 learning settings. 1</p><p>4 0.74109811 <a title="289-lda-4" href="./nips-2012-Non-parametric_Approximate_Dynamic_Programming_via_the_Kernel_Method.html">243 nips-2012-Non-parametric Approximate Dynamic Programming via the Kernel Method</a></p>
<p>Author: Nikhil Bhat, Vivek Farias, Ciamac C. Moallemi</p><p>Abstract: This paper presents a novel non-parametric approximate dynamic programming (ADP) algorithm that enjoys graceful approximation and sample complexity guarantees. In particular, we establish both theoretically and computationally that our proposal can serve as a viable alternative to state-of-the-art parametric ADP algorithms, freeing the designer from carefully specifying an approximation architecture. We accomplish this by developing a kernel-based mathematical program for ADP. Via a computational study on a controlled queueing network, we show that our procedure is competitive with parametric ADP approaches. 1</p><p>5 0.72460538 <a title="289-lda-5" href="./nips-2012-Finite_Sample_Convergence_Rates_of_Zero-Order_Stochastic_Optimization_Methods.html">134 nips-2012-Finite Sample Convergence Rates of Zero-Order Stochastic Optimization Methods</a></p>
<p>Author: Andre Wibisono, Martin J. Wainwright, Michael I. Jordan, John C. Duchi</p><p>Abstract: We consider derivative-free algorithms for stochastic optimization problems that use only noisy function values rather than gradients, analyzing their ﬁnite-sample convergence rates. We show that if pairs of function values are available, algorithms that √ gradient estimates based on random perturbations suffer a factor use of at most d in convergence rate over traditional stochastic gradient methods, where d is the problem dimension. We complement our algorithmic development with information-theoretic lower bounds on the minimax convergence rate of such problems, which show that our bounds are sharp with respect to all problemdependent quantities: they cannot be improved by more than constant factors. 1</p><p>6 0.54516947 <a title="289-lda-6" href="./nips-2012-Dimensionality_Dependent_PAC-Bayes_Margin_Bound.html">98 nips-2012-Dimensionality Dependent PAC-Bayes Margin Bound</a></p>
<p>7 0.53035933 <a title="289-lda-7" href="./nips-2012-Inverse_Reinforcement_Learning_through_Structured_Classification.html">162 nips-2012-Inverse Reinforcement Learning through Structured Classification</a></p>
<p>8 0.52377796 <a title="289-lda-8" href="./nips-2012-Privacy_Aware_Learning.html">275 nips-2012-Privacy Aware Learning</a></p>
<p>9 0.51411021 <a title="289-lda-9" href="./nips-2012-Parametric_Local_Metric_Learning_for_Nearest_Neighbor_Classification.html">265 nips-2012-Parametric Local Metric Learning for Nearest Neighbor Classification</a></p>
<p>10 0.50497586 <a title="289-lda-10" href="./nips-2012-A_Geometric_take_on_Metric_Learning.html">9 nips-2012-A Geometric take on Metric Learning</a></p>
<p>11 0.50418228 <a title="289-lda-11" href="./nips-2012-Query_Complexity_of_Derivative-Free_Optimization.html">285 nips-2012-Query Complexity of Derivative-Free Optimization</a></p>
<p>12 0.50392717 <a title="289-lda-12" href="./nips-2012-Natural_Images%2C_Gaussian_Mixtures_and_Dead_Leaves.html">235 nips-2012-Natural Images, Gaussian Mixtures and Dead Leaves</a></p>
<p>13 0.50141478 <a title="289-lda-13" href="./nips-2012-Optimal_Regularized_Dual_Averaging_Methods_for_Stochastic_Optimization.html">263 nips-2012-Optimal Regularized Dual Averaging Methods for Stochastic Optimization</a></p>
<p>14 0.49881935 <a title="289-lda-14" href="./nips-2012-Stochastic_optimization_and_sparse_statistical_recovery%3A_Optimal_algorithms_for_high_dimensions.html">325 nips-2012-Stochastic optimization and sparse statistical recovery: Optimal algorithms for high dimensions</a></p>
<p>15 0.49692461 <a title="289-lda-15" href="./nips-2012-Provable_ICA_with_Unknown_Gaussian_Noise%2C_with_Implications_for_Gaussian_Mixtures_and_Autoencoders.html">281 nips-2012-Provable ICA with Unknown Gaussian Noise, with Implications for Gaussian Mixtures and Autoencoders</a></p>
<p>16 0.49642137 <a title="289-lda-16" href="./nips-2012-Latent_Coincidence_Analysis%3A_A_Hidden_Variable_Model_for_Distance_Metric_Learning.html">171 nips-2012-Latent Coincidence Analysis: A Hidden Variable Model for Distance Metric Learning</a></p>
<p>17 0.49305156 <a title="289-lda-17" href="./nips-2012-Regularized_Off-Policy_TD-Learning.html">292 nips-2012-Regularized Off-Policy TD-Learning</a></p>
<p>18 0.4874168 <a title="289-lda-18" href="./nips-2012-Semi-Crowdsourced_Clustering%3A_Generalizing_Crowd_Labeling_by_Robust_Distance_Metric_Learning.html">307 nips-2012-Semi-Crowdsourced Clustering: Generalizing Crowd Labeling by Robust Distance Metric Learning</a></p>
<p>19 0.48655918 <a title="289-lda-19" href="./nips-2012-Identification_of_Recurrent_Patterns_in_the_Activation_of_Brain_Networks.html">157 nips-2012-Identification of Recurrent Patterns in the Activation of Brain Networks</a></p>
<p>20 0.48629647 <a title="289-lda-20" href="./nips-2012-Deep_Learning_of_Invariant_Features_via_Simulated_Fixations_in_Video.html">90 nips-2012-Deep Learning of Invariant Features via Simulated Fixations in Video</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
