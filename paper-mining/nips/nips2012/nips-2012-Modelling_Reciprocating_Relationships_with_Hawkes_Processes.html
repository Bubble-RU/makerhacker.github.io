<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>219 nips-2012-Modelling Reciprocating Relationships with Hawkes Processes</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-219" href="#">nips2012-219</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>219 nips-2012-Modelling Reciprocating Relationships with Hawkes Processes</h1>
<br/><p>Source: <a title="nips-2012-219-pdf" href="http://papers.nips.cc/paper/4834-modelling-reciprocating-relationships-with-hawkes-processes.pdf">pdf</a></p><p>Author: Charles Blundell, Jeff Beck, Katherine A. Heller</p><p>Abstract: We present a Bayesian nonparametric model that discovers implicit social structure from interaction time-series data. Social groups are often formed implicitly, through actions among members of groups. Yet many models of social networks use explicitly declared relationships to infer social structure. We consider a particular class of Hawkes processes, a doubly stochastic point process, that is able to model reciprocity between groups of individuals. We then extend the Inﬁnite Relational Model by using these reciprocating Hawkes processes to parameterise its edges, making events associated with edges co-dependent through time. Our model outperforms general, unstructured Hawkes processes as well as structured Poisson process-based models at predicting verbal and email turn-taking, and military conﬂicts among nations. 1</p><p>Reference: <a title="nips-2012-219-reference" href="../nips2012_reference/nips-2012-Modelling_Reciprocating_Relationships_with_Hawkes_Processes_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract We present a Bayesian nonparametric model that discovers implicit social structure from interaction time-series data. [sent-11, score-0.156]
</p><p>2 Social groups are often formed implicitly, through actions among members of groups. [sent-12, score-0.098]
</p><p>3 Yet many models of social networks use explicitly declared relationships to infer social structure. [sent-13, score-0.303]
</p><p>4 We consider a particular class of Hawkes processes, a doubly stochastic point process, that is able to model reciprocity between groups of individuals. [sent-14, score-0.124]
</p><p>5 We then extend the Inﬁnite Relational Model by using these reciprocating Hawkes processes to parameterise its edges, making events associated with edges co-dependent through time. [sent-15, score-0.426]
</p><p>6 Our model outperforms general, unstructured Hawkes processes as well as structured Poisson process-based models at predicting verbal and email turn-taking, and military conﬂicts among nations. [sent-16, score-0.301]
</p><p>7 1  Introduction  As social animals, people constantly organise themselves into social groups. [sent-17, score-0.256]
</p><p>8 These social groups can revolve around particular activities, such as sports teams, particular roles, such as store managers, or general social alliances, like gang members. [sent-18, score-0.271]
</p><p>9 Understanding the dynamics of group interactions is a difﬁcult problem that social scientists strive to address. [sent-19, score-0.168]
</p><p>10 One basic problem in understanding group behaviour is that groups are often not explicitly deﬁned, and the members must be inferred. [sent-20, score-0.12]
</p><p>11 How can we predict future interactions among individuals based on these inferred groups? [sent-22, score-0.197]
</p><p>12 A common approach is to infer groups, or clusters, of people based upon a declared relationship between pairs of individuals [1, 2, 3, 4]. [sent-23, score-0.237]
</p><p>13 For example, data from social networks, where two people declare that they are “friends” or in each others’ social “neighbourhood”, can potentially be used. [sent-24, score-0.256]
</p><p>14 However these declared relationships are not necessarily readily available, truthful, or pertinent to inferring the social group structure of interest. [sent-25, score-0.195]
</p><p>15 In this paper we instead propose an approach to inferring social groups based directly on a set of real interactions between people. [sent-26, score-0.199]
</p><p>16 If we are interested in capturing groups that best reﬂect human behaviour we should be determining the groups from instances of that same behaviour. [sent-28, score-0.131]
</p><p>17 We develop a model which can learn social group structure based on interactions data. [sent-29, score-0.168]
</p><p>18 As examples, the actions we consider are that of one person sending an email to another, one person speaking to another, or one country engaging in military action towards another. [sent-31, score-0.21]
</p><p>19 The key property that we leverage to infer social groups is reciprocity. [sent-32, score-0.183]
</p><p>20 Reciprocity is a common social norm, where one person’s actions towards another increases the probability of the same type of action being returned. [sent-33, score-0.109]
</p><p>21 For example, if Bob emails Alice, it increases the probability that Alice will email Bob in the near future. [sent-34, score-0.093]
</p><p>22 When multiple people show a similar pattern of reciprocity, our model will place these people in their own group. [sent-36, score-0.076]
</p><p>23 The Bayesian nonparametric model we use on these time-series data is generative and accounts for the rate of events between clusters of individuals. [sent-37, score-0.334]
</p><p>24 It is built upon mutually-exciting point processes, known as Hawkes processes [5, 6]. [sent-38, score-0.113]
</p><p>25 Pairs of mutually-exciting Hawkes processes are able to capture the causal nature of reciprocal interactions. [sent-39, score-0.169]
</p><p>26 Here the processes excite one another through their actualised events. [sent-40, score-0.113]
</p><p>27 Since Poisson processes are a special case of Hawkes processes, our model is also able to capture simpler one-way, non-reciprocal, relationships as well. [sent-41, score-0.134]
</p><p>28 The IRM typically assumes that there is a ﬁxed graph, or social network, which is observed. [sent-43, score-0.109]
</p><p>29 Here we are interested in inferring the implicit social structure based only on the occurrences of interactions between vertices in the graph. [sent-44, score-0.167]
</p><p>30 We apply our model to reciprocal behaviour in verbal and email conversations and to military conﬂicts among nations. [sent-45, score-0.27]
</p><p>31 The remainder of the paper is organised as follows: section 2 discusses using Poisson processes together with the IRM. [sent-46, score-0.113]
</p><p>32 2  Poisson processes with the Inﬁnite Relational Model  The Inﬁnite Relational Model (IRM) [1, 2] was developed to model relationships among entities as graphs, based upon previously declared relationships. [sent-49, score-0.202]
</p><p>33 Let V denote the vertices of the graph, corresponding to individuals, and let euv denote the presence or absence of a relationship between vertices u and v, corresponding to an edge in the graph. [sent-50, score-0.091]
</p><p>34 Hence vertex u belongs to the cluster given by π(u), and consequently, the clusters in π are given by range(π). [sent-52, score-0.125]
</p><p>35 Often in interaction data there are many instances of interactions between the same pair of individuals–this cannot be modelled by the IRM. [sent-54, score-0.117]
</p><p>36 Unfortunately, a vanilla Gamma-Poisson observation model does not allow us to predict events into the future, outside the observed time window. [sent-56, score-0.256]
</p><p>37 We shall consider Poisson processes on [0, ∞), such that the number of events in any interval [s, s ) of the real-half line, denoted N [s, s ), is Poisson distributed with rate λ(s − s). [sent-60, score-0.397]
</p><p>38 The graph in the top left shows the clusters and edge weights learned by our model from the data in the bottom right plot. [sent-68, score-0.097]
</p><p>39 The top right plot shows the rates of interaction events between clusters. [sent-69, score-0.303]
</p><p>40 In the graph, the width and temperature (how red the colour is) denotes the expected rate of events between pairs of clusters (using equations (9) and (10)). [sent-71, score-0.356]
</p><p>41 While in plots on the right, line colours indicates the identity of cluster pairs, and box colours indicate the originator of the event: Alice (red), Bob (blue), Mallory (black). [sent-72, score-0.121]
</p><p>42 Only after many events caused by Mallory do Alice or Bob respond, and when they do respond they both, similarly, respond more sparsely. [sent-75, score-0.306]
</p><p>43 Inference proceeds by conditioning on, Nuv [0, T ) = nuv where nuv is the total number of events directed from u to v in the given time interval. [sent-77, score-0.568]
</p><p>44 There are two notable deﬁciencies of this model: the rate of events on each edge is independent of every other edge, and conditioned on the time interval containing all observed events, the times of these events are uniformly distributed. [sent-79, score-0.564]
</p><p>45 If I send an email to someone, it is more likely that I will receive an email from them than had I not sent an email, and the probability of receiving a reply decreases as time advances. [sent-81, score-0.186]
</p><p>46 These processes are intuitively similar to Poisson processes, but unlike Poisson processes, the rates of Hawkes processes depend upon their own historic events and those of other processes in an excitatory fashion. [sent-84, score-0.595]
</p><p>47 We shall consider an array of K × K Hawkes processes, where K is the number of clusters in a partition drawn from a CRP restricted to the individuals V . [sent-85, score-0.185]
</p><p>48 As in the IRM, the CRP allows the 3  number of processes to grow in an unconstrained manner as the number of individuals in the graph grows. [sent-86, score-0.271]
</p><p>49 However, unlike the IRM, these Hawkes processes will be pairwise-dependent: the Hawkes process governing events from cluster p to cluster q, will depend upon the Hawkes process governing events from cluster q to cluster p. [sent-87, score-1.041]
</p><p>50 Each Hawkes process is a point process whose rate at time t is given by: t  gpq (t − s)dNqp (s)  λpq (t) = γpq np nq +  (7)  −∞  where γpq is the base rate of the counting measure of the Hawkes, process, Npq . [sent-89, score-0.315]
</p><p>51 np and nq are the number of individuals in cluster p and q respectively, and gpq is a non-negative function such that ∞ gpq (s)ds < 1, ensuring that Npq is stationary. [sent-90, score-0.45]
</p><p>52 Nqp is the counting measure of the reciprocating 0 Hawkes process of Npq . [sent-91, score-0.124]
</p><p>53 Intuitively, if Npq governs events from cluster p to cluster q, then Nqp governs events from cluster q to cluster p. [sent-92, score-0.812]
</p><p>54 Equation (7) shows how the rates of events in these two processes are intimately intertwined. [sent-93, score-0.369]
</p><p>55 Since Nqp is an atomic measure, whose atoms correspond to the times of events, we can express the rate of Npq given in (7), by conditioning on the events of its reciprocating processes Nqp , as: gpq (t − tqp ) i  λpq (t) = γpq np nq +  (8)  i:tqp  < 1 for the process to be stationary. [sent-94, score-0.703]
</p><p>56 Henceforth we will use uniform thinning—each event in Npq (·) is assigned uniformly at random among all Nuv (·) where p = π(u) and q = π(v)—but in principle any thinning scheme may be used. [sent-97, score-0.094]
</p><p>57 For a Hawkes process Npq , the rate at which no events occurs in the interval [s, s ) is: e−  s s  λpq (t)dt  (15)  Suppose we observe the times of all the events in [0, T ), {tuv }nuv for process Nuv (nuv being the i i=1 total number of events from u to v in [0, T )). [sent-98, score-0.87]
</p><p>58 Suppose that individual u is in cluster p and that individual v is in cluster q. [sent-99, score-0.15]
</p><p>59 Furthermore, assume there are no events before time 0. [sent-100, score-0.256]
</p><p>60 The likelihood of each edge between individuals u and v is thus: n  qp p({tuv }nuv |θpq , {tqp }i=1 ) = e i i=1 i  − np1 q n  T 0  nuv λpq (t)dt i=1  λpq (tuv ) i np nq  (16)  n  qp where θpq = (γpq , βpq , τpq ), {tqp }i=1 are the times of the reciprocal events. [sent-101, score-0.419]
</p><p>61 To infer the partition of individuals π, the concentration parameter α, and the parameters of each Hawkes process θpq = (γpq , βpq , τpq ), we use Algorithm 5 [11] adapted to the IRM and slice sampling [12] to draw samples from the posterior. [sent-106, score-0.22]
</p><p>62 pq pq  6  Related work  Several authors have considered modelling occurrence events [13, 14, 15] using piecewise constant rate Markov point processes for known number of event types. [sent-110, score-1.194]
</p><p>63 Our work directly models interaction 5  events (where an event is structured to have a sender and recipient) and the number of possible events types is not limited. [sent-111, score-0.63]
</p><p>64 [16] describes a model of occurrence events as a discrete time-series using a latent ﬁrst-order Markov model. [sent-112, score-0.256]
</p><p>65 Our model differs in that it considers interaction events in continuous time and requires no ﬁrst-order assumption. [sent-113, score-0.303]
</p><p>66 The model in Section 2 relates the work of [17] to the IRM [1], yielding a version of their model that learns the number of clusters whilst maintaining conjugacy. [sent-114, score-0.078]
</p><p>67 However our model does not use a Poisson process to model event times, instead using processes which have a time-varying rate. [sent-115, score-0.186]
</p><p>68 Hawkes processes are also the basis of this work, however our work does not use side-channel information to group individuals by imposing ﬁxed marks on the process; instead we learn structure among several co-dependent Hawkes processes and use Bayesian inference for the parameters and structure. [sent-117, score-0.408]
</p><p>69 The interest is in modelling the activation and co-activation of neurons and as such they do not directly model cluster structure among the neurons, while our model does model this structure. [sent-119, score-0.121]
</p><p>70 We compared these models quantitatively by comparing their log predictive densities (with respect to the space of ordered sequences of events) on events falling in the ﬁnal 10% of the total time of the data (Table 2). [sent-127, score-0.256]
</p><p>71 We normalised the times of all events such that the ﬁrst 90% of total time lay in the interval [0, 1]. [sent-128, score-0.256]
</p><p>72 The data involves three individuals and is plotted in Figure 1. [sent-131, score-0.135]
</p><p>73 The Poisson IRM is uncertain how to cluster individuals as it cannot model the temporal dependence between individuals, while the Hawkes IRM can and so performs better at prediction as well. [sent-133, score-0.21]
</p><p>74 A single Hawkes process does not model the structure among individuals and so performs worse than the Hawkes IRM, although it is able to model dependence among events. [sent-134, score-0.222]
</p><p>75 Enron email threads We took the ﬁve longest threads from the Enron 2009 data set [21]. [sent-135, score-0.171]
</p><p>76 All of these threads involve two different people so there is little scope for learning much group structure in these data: either both people are in the same cluster, or they are in two separate clusters. [sent-137, score-0.137]
</p><p>77 However as can be seen in Table 2 these data suggest a predictive advantage to using mutually-exciting Hawkes processes, as automatically determined by our model, instead of a single self-exciting Hawkes process and of both of these approaches over their corresponding Poisson processes model. [sent-138, score-0.15]
</p><p>78 A self-exciting Hawkes process is unable to mark the sender and receiver of events as differing, whilst Poisson process-based models are unable to model the causal structure of events. [sent-139, score-0.378]
</p><p>79 These con6  Gran$ Rose$  Dan$  KUW$ USA$ Pa,$  Bern$ X$ Cher$ Paul$$ Many$ Dere$ Kare$  AFG$ TAW$  IRQ$  RUS$ CHN$  Figure 2: Graphs of clusters of individuals inferred by our model. [sent-142, score-0.185]
</p><p>80 Edge width and temperature (how red the colour is) denotes the expected rate of events between pairs of clusters (using equations (9) and (10); edges whose marginal rate is below 1 are not included). [sent-143, score-0.384]
</p><p>81 On the left is the graph inferred on the “SB conv 26” data set. [sent-144, score-0.127]
</p><p>82 versations cover a variety of social situations: questions during a university lecture (12), a book discussion group (23), a meeting among city ofﬁcials (26), a family argument/discussion (33), and a conversation at a family birthday party (49). [sent-146, score-0.237]
</p><p>83 We modelled the turn-taking behaviour of these groups by taking the times of when one speaker switched to the next. [sent-147, score-0.111]
</p><p>84 In Figure 2(left) we show the cluster graph found by our model for conversation 26, involving city ofﬁcials discussing a grant application. [sent-148, score-0.156]
</p><p>85 Incidents vary from diplomatic threats of military force to the actual deployment of military force against another state. [sent-154, score-0.098]
</p><p>86 For exposition purposes, we show the graph (in Figure 2(right)) on part of the MID data set, by restricting to events among the USA, Kuwait, Afghanistan, Taiwan, Russia, China, and Iraq. [sent-158, score-0.304]
</p><p>87 Thicker and redder lines between clusters (computed from equations 9 and 10) reﬂect a higher rate of incidents directed between the countries along the edge. [sent-159, score-0.225]
</p><p>88 There were three main conﬂicts involving the countries we modelled during the time period this data covers. [sent-161, score-0.109]
</p><p>89 1) Revolved mostly around border disputes coming out of the Soviet war in Afghanistan, and incidents sometimes involved using former Soviet countries as proxies. [sent-163, score-0.246]
</p><p>90 It is interesting to note that groups involving smaller countries were found to be more likely to initiate incidents with larger countries in a dispute (e. [sent-166, score-0.304]
</p><p>91 7  Synthetic Small MID Full MID Enron 0 Enron 1 Enron 2 Enron 3 Enron 4 SB conv 23 SB conv 26 SB conv 12 SB conv 49 SB conv 33  N 3 7 82 2 2 2 2 2 18 11 12 11 10  T 239 57 412 896 204 122 117 85 832 95 133 620 499  Hawkes IRM E[K] log probability 2. [sent-170, score-0.52]
</p><p>92 N denotes the number of individuals in the data set. [sent-249, score-0.135]
</p><p>93 T denotes the total number of events in the data set. [sent-250, score-0.256]
</p><p>94 Synthetic Small MID Full MID Enron 0 Enron 1 Enron 2 Enron 3 Enron 4 SB conv 23 SB conv 26 SB conv 12 SB conv 49 SB conv 33  Hawkes IRM 43. [sent-253, score-0.52]
</p><p>95 The intuition behind why our model works well is that it captures part of the reciprocal nature of interactions among individuals in social situations, which in turn requires modelling some of the causal relationship of events. [sent-358, score-0.383]
</p><p>96 For example, individuals might contribute to groups differently to one another. [sent-361, score-0.188]
</p><p>97 There may be different kinds of events between individuals and other side-channel information. [sent-362, score-0.391]
</p><p>98 It would be interesting to consider other parameterisations of gpq (·) that, for example, include periods of delay between reciprocation; the exponential parameterisation lends itself to efﬁcient computation [10] whilst other parameterisations do not necessarily have this property. [sent-364, score-0.189]
</p><p>99 But different choices of gpq (·) may yield better statistical models. [sent-365, score-0.085]
</p><p>100 Another interesting avenue is to explore other structure amongst interaction events using Hawkes processes, beyond reciprocity. [sent-366, score-0.303]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('hawkes', 0.566), ('pq', 0.37), ('events', 0.256), ('irm', 0.25), ('alice', 0.187), ('mallory', 0.17), ('bob', 0.161), ('nuv', 0.156), ('poisson', 0.143), ('enron', 0.141), ('individuals', 0.135), ('npq', 0.113), ('processes', 0.113), ('sb', 0.11), ('social', 0.109), ('conv', 0.104), ('mid', 0.099), ('email', 0.093), ('gpq', 0.085), ('countries', 0.076), ('cluster', 0.075), ('incidents', 0.071), ('reciprocity', 0.071), ('icts', 0.058), ('conversation', 0.058), ('afghanistan', 0.057), ('disputes', 0.057), ('kuwait', 0.057), ('nqp', 0.057), ('reciprocating', 0.057), ('tqp', 0.057), ('groups', 0.053), ('clusters', 0.05), ('military', 0.049), ('crp', 0.049), ('interaction', 0.047), ('relational', 0.046), ('declared', 0.043), ('tuv', 0.042), ('war', 0.042), ('nq', 0.041), ('threads', 0.039), ('people', 0.038), ('russia', 0.037), ('iraq', 0.037), ('barbara', 0.037), ('process', 0.037), ('interactions', 0.037), ('event', 0.036), ('sender', 0.035), ('person', 0.034), ('reciprocal', 0.034), ('modelled', 0.033), ('ict', 0.033), ('santa', 0.033), ('taiwan', 0.033), ('thinning', 0.033), ('counting', 0.03), ('np', 0.029), ('cials', 0.028), ('dispute', 0.028), ('gran', 0.028), ('parameterisations', 0.028), ('rate', 0.028), ('whilst', 0.028), ('correlates', 0.028), ('slice', 0.027), ('david', 0.027), ('behaviour', 0.025), ('euv', 0.025), ('soviet', 0.025), ('dubois', 0.025), ('simma', 0.025), ('usa', 0.025), ('among', 0.025), ('respond', 0.025), ('edge', 0.024), ('corpus', 0.024), ('graph', 0.023), ('meeting', 0.023), ('colours', 0.023), ('conversations', 0.023), ('alan', 0.023), ('charles', 0.022), ('causal', 0.022), ('colour', 0.022), ('rochester', 0.022), ('liam', 0.022), ('group', 0.022), ('modelling', 0.021), ('china', 0.021), ('relationships', 0.021), ('infer', 0.021), ('governing', 0.021), ('verbal', 0.021), ('vertices', 0.021), ('members', 0.02), ('parameterisation', 0.02), ('recipient', 0.02), ('chair', 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="219-tfidf-1" href="./nips-2012-Modelling_Reciprocating_Relationships_with_Hawkes_Processes.html">219 nips-2012-Modelling Reciprocating Relationships with Hawkes Processes</a></p>
<p>Author: Charles Blundell, Jeff Beck, Katherine A. Heller</p><p>Abstract: We present a Bayesian nonparametric model that discovers implicit social structure from interaction time-series data. Social groups are often formed implicitly, through actions among members of groups. Yet many models of social networks use explicitly declared relationships to infer social structure. We consider a particular class of Hawkes processes, a doubly stochastic point process, that is able to model reciprocity between groups of individuals. We then extend the Inﬁnite Relational Model by using these reciprocating Hawkes processes to parameterise its edges, making events associated with edges co-dependent through time. Our model outperforms general, unstructured Hawkes processes as well as structured Poisson process-based models at predicting verbal and email turn-taking, and military conﬂicts among nations. 1</p><p>2 0.13266297 <a title="219-tfidf-2" href="./nips-2012-Minimizing_Uncertainty_in_Pipelines.html">215 nips-2012-Minimizing Uncertainty in Pipelines</a></p>
<p>Author: Nilesh Dalvi, Aditya Parameswaran, Vibhor Rastogi</p><p>Abstract: In this paper, we consider the problem of debugging large pipelines by human labeling. We represent the execution of a pipeline using a directed acyclic graph of AND and OR nodes, where each node represents a data item produced by some operator in the pipeline. We assume that each operator assigns a conﬁdence to each of its output data. We want to reduce the uncertainty in the output by issuing queries to a human, where a query consists of checking if a given data item is correct. In this paper, we consider the problem of asking the optimal set of queries to minimize the resulting output uncertainty. We perform a detailed evaluation of the complexity of the problem for various classes of graphs. We give efﬁcient algorithms for the problem for trees, and show that, for a general dag, the problem is intractable. 1</p><p>3 0.076605499 <a title="219-tfidf-3" href="./nips-2012-Unsupervised_Structure_Discovery_for_Semantic_Analysis_of_Audio.html">356 nips-2012-Unsupervised Structure Discovery for Semantic Analysis of Audio</a></p>
<p>Author: Sourish Chaudhuri, Bhiksha Raj</p><p>Abstract: Approaches to audio classiﬁcation and retrieval tasks largely rely on detectionbased discriminative models. We submit that such models make a simplistic assumption in mapping acoustics directly to semantics, whereas the actual process is likely more complex. We present a generative model that maps acoustics in a hierarchical manner to increasingly higher-level semantics. Our model has two layers with the ﬁrst layer modeling generalized sound units with no clear semantic associations, while the second layer models local patterns over these sound units. We evaluate our model on a large-scale retrieval task from TRECVID 2011, and report signiﬁcant improvements over standard baselines. 1</p><p>4 0.074872874 <a title="219-tfidf-4" href="./nips-2012-Probabilistic_Event_Cascades_for_Alzheimer%27s_disease.html">276 nips-2012-Probabilistic Event Cascades for Alzheimer's disease</a></p>
<p>Author: Jonathan Huang, Daniel Alexander</p><p>Abstract: Accurate and detailed models of neurodegenerative disease progression are crucially important for reliable early diagnosis and the determination of effective treatments. We introduce the ALPACA (Alzheimer’s disease Probabilistic Cascades) model, a generative model linking latent Alzheimer’s progression dynamics to observable biomarker data. In contrast with previous works which model disease progression as a ﬁxed event ordering, we explicitly model the variability over such orderings among patients which is more realistic, particularly for highly detailed progression models. We describe efﬁcient learning algorithms for ALPACA and discuss promising experimental results on a real cohort of Alzheimer’s patients from the Alzheimer’s Disease Neuroimaging Initiative. 1</p><p>5 0.074864723 <a title="219-tfidf-5" href="./nips-2012-Topic-Partitioned_Multinetwork_Embeddings.html">345 nips-2012-Topic-Partitioned Multinetwork Embeddings</a></p>
<p>Author: Peter Krafft, Juston Moore, Bruce Desmarais, Hanna M. Wallach</p><p>Abstract: We introduce a new Bayesian admixture model intended for exploratory analysis of communication networks—speciﬁcally, the discovery and visualization of topic-speciﬁc subnetworks in email data sets. Our model produces principled visualizations of email networks, i.e., visualizations that have precise mathematical interpretations in terms of our model and its relationship to the observed data. We validate our modeling assumptions by demonstrating that our model achieves better link prediction performance than three state-of-the-art network models and exhibits topic coherence comparable to that of latent Dirichlet allocation. We showcase our model’s ability to discover and visualize topic-speciﬁc communication patterns using a new email data set: the New Hanover County email network. We provide an extensive analysis of these communication patterns, leading us to recommend our model for any exploratory analysis of email networks or other similarly-structured communication data. Finally, we advocate for principled visualization as a primary objective in the development of new network models. 1</p><p>6 0.072663195 <a title="219-tfidf-6" href="./nips-2012-MCMC_for_continuous-time_discrete-state_systems.html">205 nips-2012-MCMC for continuous-time discrete-state systems</a></p>
<p>7 0.059932012 <a title="219-tfidf-7" href="./nips-2012-Clustering_Sparse_Graphs.html">69 nips-2012-Clustering Sparse Graphs</a></p>
<p>8 0.057387214 <a title="219-tfidf-8" href="./nips-2012-Scalable_imputation_of_genetic_data_with_a_discrete_fragmentation-coagulation_process.html">299 nips-2012-Scalable imputation of genetic data with a discrete fragmentation-coagulation process</a></p>
<p>9 0.056543656 <a title="219-tfidf-9" href="./nips-2012-Fully_Bayesian_inference_for_neural_models_with_negative-binomial_spiking.html">138 nips-2012-Fully Bayesian inference for neural models with negative-binomial spiking</a></p>
<p>10 0.056269586 <a title="219-tfidf-10" href="./nips-2012-FastEx%3A_Hash_Clustering_with_Exponential_Families.html">126 nips-2012-FastEx: Hash Clustering with Exponential Families</a></p>
<p>11 0.047312792 <a title="219-tfidf-11" href="./nips-2012-Slice_sampling_normalized_kernel-weighted_completely_random_measure_mixture_models.html">315 nips-2012-Slice sampling normalized kernel-weighted completely random measure mixture models</a></p>
<p>12 0.047220781 <a title="219-tfidf-12" href="./nips-2012-Small-Variance_Asymptotics_for_Exponential_Family_Dirichlet_Process_Mixture_Models.html">316 nips-2012-Small-Variance Asymptotics for Exponential Family Dirichlet Process Mixture Models</a></p>
<p>13 0.04717467 <a title="219-tfidf-13" href="./nips-2012-Random_function_priors_for_exchangeable_arrays_with_applications_to_graphs_and_relational_data.html">287 nips-2012-Random function priors for exchangeable arrays with applications to graphs and relational data</a></p>
<p>14 0.041908868 <a title="219-tfidf-14" href="./nips-2012-Efficient_high_dimensional_maximum_entropy_modeling_via_symmetric_partition_functions.html">115 nips-2012-Efficient high dimensional maximum entropy modeling via symmetric partition functions</a></p>
<p>15 0.040982462 <a title="219-tfidf-15" href="./nips-2012-Diffusion_Decision_Making_for_Adaptive_k-Nearest_Neighbor_Classification.html">97 nips-2012-Diffusion Decision Making for Adaptive k-Nearest Neighbor Classification</a></p>
<p>16 0.04038265 <a title="219-tfidf-16" href="./nips-2012-Dip-means%3A_an_incremental_clustering_method_for_estimating_the_number_of_clusters.html">99 nips-2012-Dip-means: an incremental clustering method for estimating the number of clusters</a></p>
<p>17 0.039717417 <a title="219-tfidf-17" href="./nips-2012-Learning_Networks_of_Heterogeneous_Influence.html">182 nips-2012-Learning Networks of Heterogeneous Influence</a></p>
<p>18 0.039474703 <a title="219-tfidf-18" href="./nips-2012-Augment-and-Conquer_Negative_Binomial_Processes.html">47 nips-2012-Augment-and-Conquer Negative Binomial Processes</a></p>
<p>19 0.03807044 <a title="219-tfidf-19" href="./nips-2012-Bayesian_nonparametric_models_for_bipartite_graphs.html">59 nips-2012-Bayesian nonparametric models for bipartite graphs</a></p>
<p>20 0.037893757 <a title="219-tfidf-20" href="./nips-2012-Clustering_Aggregation_as_Maximum-Weight_Independent_Set.html">68 nips-2012-Clustering Aggregation as Maximum-Weight Independent Set</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.094), (1, 0.02), (2, -0.018), (3, 0.014), (4, -0.083), (5, -0.012), (6, -0.011), (7, -0.01), (8, -0.025), (9, 0.058), (10, 0.009), (11, -0.048), (12, -0.018), (13, -0.048), (14, 0.016), (15, -0.043), (16, -0.046), (17, -0.002), (18, -0.015), (19, -0.057), (20, -0.012), (21, 0.013), (22, -0.023), (23, -0.026), (24, -0.007), (25, -0.053), (26, 0.019), (27, 0.011), (28, -0.066), (29, -0.055), (30, 0.047), (31, 0.041), (32, -0.001), (33, 0.039), (34, -0.025), (35, 0.024), (36, 0.121), (37, -0.014), (38, 0.065), (39, 0.052), (40, -0.112), (41, 0.095), (42, -0.006), (43, 0.033), (44, -0.034), (45, 0.033), (46, -0.018), (47, 0.018), (48, 0.041), (49, -0.024)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92993915 <a title="219-lsi-1" href="./nips-2012-Modelling_Reciprocating_Relationships_with_Hawkes_Processes.html">219 nips-2012-Modelling Reciprocating Relationships with Hawkes Processes</a></p>
<p>Author: Charles Blundell, Jeff Beck, Katherine A. Heller</p><p>Abstract: We present a Bayesian nonparametric model that discovers implicit social structure from interaction time-series data. Social groups are often formed implicitly, through actions among members of groups. Yet many models of social networks use explicitly declared relationships to infer social structure. We consider a particular class of Hawkes processes, a doubly stochastic point process, that is able to model reciprocity between groups of individuals. We then extend the Inﬁnite Relational Model by using these reciprocating Hawkes processes to parameterise its edges, making events associated with edges co-dependent through time. Our model outperforms general, unstructured Hawkes processes as well as structured Poisson process-based models at predicting verbal and email turn-taking, and military conﬂicts among nations. 1</p><p>2 0.62274653 <a title="219-lsi-2" href="./nips-2012-Learning_Networks_of_Heterogeneous_Influence.html">182 nips-2012-Learning Networks of Heterogeneous Influence</a></p>
<p>Author: Nan Du, Le Song, Ming Yuan, Alex J. Smola</p><p>Abstract: Information, disease, and inﬂuence diffuse over networks of entities in both natural systems and human society. Analyzing these transmission networks plays an important role in understanding the diffusion processes and predicting future events. However, the underlying transmission networks are often hidden and incomplete, and we observe only the time stamps when cascades of events happen. In this paper, we address the challenging problem of uncovering the hidden network only from the cascades. The structure discovery problem is complicated by the fact that the inﬂuence between networked entities is heterogeneous, which can not be described by a simple parametric model. Therefore, we propose a kernelbased method which can capture a diverse range of different types of inﬂuence without any prior assumption. In both synthetic and real cascade data, we show that our model can better recover the underlying diffusion network and drastically improve the estimation of the transmission functions among networked entities. 1</p><p>3 0.55051291 <a title="219-lsi-3" href="./nips-2012-Unsupervised_Structure_Discovery_for_Semantic_Analysis_of_Audio.html">356 nips-2012-Unsupervised Structure Discovery for Semantic Analysis of Audio</a></p>
<p>Author: Sourish Chaudhuri, Bhiksha Raj</p><p>Abstract: Approaches to audio classiﬁcation and retrieval tasks largely rely on detectionbased discriminative models. We submit that such models make a simplistic assumption in mapping acoustics directly to semantics, whereas the actual process is likely more complex. We present a generative model that maps acoustics in a hierarchical manner to increasingly higher-level semantics. Our model has two layers with the ﬁrst layer modeling generalized sound units with no clear semantic associations, while the second layer models local patterns over these sound units. We evaluate our model on a large-scale retrieval task from TRECVID 2011, and report signiﬁcant improvements over standard baselines. 1</p><p>4 0.53621006 <a title="219-lsi-4" href="./nips-2012-Bayesian_nonparametric_models_for_bipartite_graphs.html">59 nips-2012-Bayesian nonparametric models for bipartite graphs</a></p>
<p>Author: Francois Caron</p><p>Abstract: We develop a novel Bayesian nonparametric model for random bipartite graphs. The model is based on the theory of completely random measures and is able to handle a potentially inﬁnite number of nodes. We show that the model has appealing properties and in particular it may exhibit a power-law behavior. We derive a posterior characterization, a generative process for network growth, and a simple Gibbs sampler for posterior simulation. Our model is shown to be well ﬁtted to several real-world social networks. 1</p><p>5 0.53255153 <a title="219-lsi-5" href="./nips-2012-Probabilistic_Event_Cascades_for_Alzheimer%27s_disease.html">276 nips-2012-Probabilistic Event Cascades for Alzheimer's disease</a></p>
<p>Author: Jonathan Huang, Daniel Alexander</p><p>Abstract: Accurate and detailed models of neurodegenerative disease progression are crucially important for reliable early diagnosis and the determination of effective treatments. We introduce the ALPACA (Alzheimer’s disease Probabilistic Cascades) model, a generative model linking latent Alzheimer’s progression dynamics to observable biomarker data. In contrast with previous works which model disease progression as a ﬁxed event ordering, we explicitly model the variability over such orderings among patients which is more realistic, particularly for highly detailed progression models. We describe efﬁcient learning algorithms for ALPACA and discuss promising experimental results on a real cohort of Alzheimer’s patients from the Alzheimer’s Disease Neuroimaging Initiative. 1</p><p>6 0.51841086 <a title="219-lsi-6" href="./nips-2012-Scalable_imputation_of_genetic_data_with_a_discrete_fragmentation-coagulation_process.html">299 nips-2012-Scalable imputation of genetic data with a discrete fragmentation-coagulation process</a></p>
<p>7 0.47206062 <a title="219-lsi-7" href="./nips-2012-MCMC_for_continuous-time_discrete-state_systems.html">205 nips-2012-MCMC for continuous-time discrete-state systems</a></p>
<p>8 0.45837146 <a title="219-lsi-8" href="./nips-2012-Nonconvex_Penalization_Using_Laplace_Exponents_and_Concave_Conjugates.html">244 nips-2012-Nonconvex Penalization Using Laplace Exponents and Concave Conjugates</a></p>
<p>9 0.45219713 <a title="219-lsi-9" href="./nips-2012-Coding_efficiency_and_detectability_of_rate_fluctuations_with_non-Poisson_neuronal_firing.html">73 nips-2012-Coding efficiency and detectability of rate fluctuations with non-Poisson neuronal firing</a></p>
<p>10 0.42788818 <a title="219-lsi-10" href="./nips-2012-Learning_with_Partially_Absorbing_Random_Walks.html">196 nips-2012-Learning with Partially Absorbing Random Walks</a></p>
<p>11 0.42507958 <a title="219-lsi-11" href="./nips-2012-Bayesian_Pedigree_Analysis_using_Measure_Factorization.html">53 nips-2012-Bayesian Pedigree Analysis using Measure Factorization</a></p>
<p>12 0.42182127 <a title="219-lsi-12" href="./nips-2012-Clustering_Sparse_Graphs.html">69 nips-2012-Clustering Sparse Graphs</a></p>
<p>13 0.42177129 <a title="219-lsi-13" href="./nips-2012-Augment-and-Conquer_Negative_Binomial_Processes.html">47 nips-2012-Augment-and-Conquer Negative Binomial Processes</a></p>
<p>14 0.4211551 <a title="219-lsi-14" href="./nips-2012-The_variational_hierarchical_EM_algorithm_for_clustering_hidden_Markov_models.html">342 nips-2012-The variational hierarchical EM algorithm for clustering hidden Markov models</a></p>
<p>15 0.42033842 <a title="219-lsi-15" href="./nips-2012-The_Coloured_Noise_Expansion_and_Parameter_Estimation_of_Diffusion_Processes.html">336 nips-2012-The Coloured Noise Expansion and Parameter Estimation of Diffusion Processes</a></p>
<p>16 0.41698799 <a title="219-lsi-16" href="./nips-2012-Human_memory_search_as_a_random_walk_in_a_semantic_network.html">155 nips-2012-Human memory search as a random walk in a semantic network</a></p>
<p>17 0.38984725 <a title="219-lsi-17" href="./nips-2012-Hierarchical_spike_coding_of_sound.html">150 nips-2012-Hierarchical spike coding of sound</a></p>
<p>18 0.38434488 <a title="219-lsi-18" href="./nips-2012-Minimizing_Uncertainty_in_Pipelines.html">215 nips-2012-Minimizing Uncertainty in Pipelines</a></p>
<p>19 0.38366872 <a title="219-lsi-19" href="./nips-2012-Learning_to_Discover_Social_Circles_in_Ego_Networks.html">194 nips-2012-Learning to Discover Social Circles in Ego Networks</a></p>
<p>20 0.38348505 <a title="219-lsi-20" href="./nips-2012-Bayesian_nonparametric_models_for_ranked_data.html">60 nips-2012-Bayesian nonparametric models for ranked data</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.051), (21, 0.025), (38, 0.052), (41, 0.013), (42, 0.43), (53, 0.01), (54, 0.019), (55, 0.012), (74, 0.037), (76, 0.136), (80, 0.081), (92, 0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.82519948 <a title="219-lda-1" href="./nips-2012-Recognizing_Activities_by_Attribute_Dynamics.html">289 nips-2012-Recognizing Activities by Attribute Dynamics</a></p>
<p>Author: Weixin Li, Nuno Vasconcelos</p><p>Abstract: In this work, we consider the problem of modeling the dynamic structure of human activities in the attributes space. A video sequence is Ä?Ĺš rst represented in a semantic feature space, where each feature encodes the probability of occurrence of an activity attribute at a given time. A generative model, denoted the binary dynamic system (BDS), is proposed to learn both the distribution and dynamics of different activities in this space. The BDS is a non-linear dynamic system, which extends both the binary principal component analysis (PCA) and classical linear dynamic systems (LDS), by combining binary observation variables with a hidden Gauss-Markov state process. In this way, it integrates the representation power of semantic modeling with the ability of dynamic systems to capture the temporal structure of time-varying processes. An algorithm for learning BDS parameters, inspired by a popular LDS learning method from dynamic textures, is proposed. A similarity measure between BDSs, which generalizes the BinetCauchy kernel for LDS, is then introduced and used to design activity classiÄ?Ĺš ers. The proposed method is shown to outperform similar classiÄ?Ĺš ers derived from the kernel dynamic system (KDS) and state-of-the-art approaches for dynamics-based or attribute-based action recognition. 1</p><p>same-paper 2 0.80965996 <a title="219-lda-2" href="./nips-2012-Modelling_Reciprocating_Relationships_with_Hawkes_Processes.html">219 nips-2012-Modelling Reciprocating Relationships with Hawkes Processes</a></p>
<p>Author: Charles Blundell, Jeff Beck, Katherine A. Heller</p><p>Abstract: We present a Bayesian nonparametric model that discovers implicit social structure from interaction time-series data. Social groups are often formed implicitly, through actions among members of groups. Yet many models of social networks use explicitly declared relationships to infer social structure. We consider a particular class of Hawkes processes, a doubly stochastic point process, that is able to model reciprocity between groups of individuals. We then extend the Inﬁnite Relational Model by using these reciprocating Hawkes processes to parameterise its edges, making events associated with edges co-dependent through time. Our model outperforms general, unstructured Hawkes processes as well as structured Poisson process-based models at predicting verbal and email turn-taking, and military conﬂicts among nations. 1</p><p>3 0.79745078 <a title="219-lda-3" href="./nips-2012-Non-linear_Metric_Learning.html">242 nips-2012-Non-linear Metric Learning</a></p>
<p>Author: Dor Kedem, Stephen Tyree, Fei Sha, Gert R. Lanckriet, Kilian Q. Weinberger</p><p>Abstract: In this paper, we introduce two novel metric learning algorithms, χ2 -LMNN and GB-LMNN, which are explicitly designed to be non-linear and easy-to-use. The two approaches achieve this goal in fundamentally different ways: χ2 -LMNN inherits the computational beneﬁts of a linear mapping from linear metric learning, but uses a non-linear χ2 -distance to explicitly capture similarities within histogram data sets; GB-LMNN applies gradient-boosting to learn non-linear mappings directly in function space and takes advantage of this approach’s robustness, speed, parallelizability and insensitivity towards the single additional hyperparameter. On various benchmark data sets, we demonstrate these methods not only match the current state-of-the-art in terms of kNN classiﬁcation error, but in the case of χ2 -LMNN, obtain best results in 19 out of 20 learning settings. 1</p><p>4 0.73582059 <a title="219-lda-4" href="./nips-2012-Non-parametric_Approximate_Dynamic_Programming_via_the_Kernel_Method.html">243 nips-2012-Non-parametric Approximate Dynamic Programming via the Kernel Method</a></p>
<p>Author: Nikhil Bhat, Vivek Farias, Ciamac C. Moallemi</p><p>Abstract: This paper presents a novel non-parametric approximate dynamic programming (ADP) algorithm that enjoys graceful approximation and sample complexity guarantees. In particular, we establish both theoretically and computationally that our proposal can serve as a viable alternative to state-of-the-art parametric ADP algorithms, freeing the designer from carefully specifying an approximation architecture. We accomplish this by developing a kernel-based mathematical program for ADP. Via a computational study on a controlled queueing network, we show that our procedure is competitive with parametric ADP approaches. 1</p><p>5 0.7213909 <a title="219-lda-5" href="./nips-2012-Finite_Sample_Convergence_Rates_of_Zero-Order_Stochastic_Optimization_Methods.html">134 nips-2012-Finite Sample Convergence Rates of Zero-Order Stochastic Optimization Methods</a></p>
<p>Author: Andre Wibisono, Martin J. Wainwright, Michael I. Jordan, John C. Duchi</p><p>Abstract: We consider derivative-free algorithms for stochastic optimization problems that use only noisy function values rather than gradients, analyzing their ﬁnite-sample convergence rates. We show that if pairs of function values are available, algorithms that √ gradient estimates based on random perturbations suffer a factor use of at most d in convergence rate over traditional stochastic gradient methods, where d is the problem dimension. We complement our algorithmic development with information-theoretic lower bounds on the minimax convergence rate of such problems, which show that our bounds are sharp with respect to all problemdependent quantities: they cannot be improved by more than constant factors. 1</p><p>6 0.53476316 <a title="219-lda-6" href="./nips-2012-Dimensionality_Dependent_PAC-Bayes_Margin_Bound.html">98 nips-2012-Dimensionality Dependent PAC-Bayes Margin Bound</a></p>
<p>7 0.51951754 <a title="219-lda-7" href="./nips-2012-Privacy_Aware_Learning.html">275 nips-2012-Privacy Aware Learning</a></p>
<p>8 0.51448894 <a title="219-lda-8" href="./nips-2012-Parametric_Local_Metric_Learning_for_Nearest_Neighbor_Classification.html">265 nips-2012-Parametric Local Metric Learning for Nearest Neighbor Classification</a></p>
<p>9 0.51188421 <a title="219-lda-9" href="./nips-2012-Inverse_Reinforcement_Learning_through_Structured_Classification.html">162 nips-2012-Inverse Reinforcement Learning through Structured Classification</a></p>
<p>10 0.50576711 <a title="219-lda-10" href="./nips-2012-A_Geometric_take_on_Metric_Learning.html">9 nips-2012-A Geometric take on Metric Learning</a></p>
<p>11 0.50555462 <a title="219-lda-11" href="./nips-2012-Semi-Crowdsourced_Clustering%3A_Generalizing_Crowd_Labeling_by_Robust_Distance_Metric_Learning.html">307 nips-2012-Semi-Crowdsourced Clustering: Generalizing Crowd Labeling by Robust Distance Metric Learning</a></p>
<p>12 0.50544578 <a title="219-lda-12" href="./nips-2012-Latent_Coincidence_Analysis%3A_A_Hidden_Variable_Model_for_Distance_Metric_Learning.html">171 nips-2012-Latent Coincidence Analysis: A Hidden Variable Model for Distance Metric Learning</a></p>
<p>13 0.49878541 <a title="219-lda-13" href="./nips-2012-Provable_ICA_with_Unknown_Gaussian_Noise%2C_with_Implications_for_Gaussian_Mixtures_and_Autoencoders.html">281 nips-2012-Provable ICA with Unknown Gaussian Noise, with Implications for Gaussian Mixtures and Autoencoders</a></p>
<p>14 0.49589404 <a title="219-lda-14" href="./nips-2012-Optimal_Regularized_Dual_Averaging_Methods_for_Stochastic_Optimization.html">263 nips-2012-Optimal Regularized Dual Averaging Methods for Stochastic Optimization</a></p>
<p>15 0.49304584 <a title="219-lda-15" href="./nips-2012-Stochastic_optimization_and_sparse_statistical_recovery%3A_Optimal_algorithms_for_high_dimensions.html">325 nips-2012-Stochastic optimization and sparse statistical recovery: Optimal algorithms for high dimensions</a></p>
<p>16 0.49190602 <a title="219-lda-16" href="./nips-2012-Query_Complexity_of_Derivative-Free_Optimization.html">285 nips-2012-Query Complexity of Derivative-Free Optimization</a></p>
<p>17 0.48342633 <a title="219-lda-17" href="./nips-2012-Regularized_Off-Policy_TD-Learning.html">292 nips-2012-Regularized Off-Policy TD-Learning</a></p>
<p>18 0.48175758 <a title="219-lda-18" href="./nips-2012-Identification_of_Recurrent_Patterns_in_the_Activation_of_Brain_Networks.html">157 nips-2012-Identification of Recurrent Patterns in the Activation of Brain Networks</a></p>
<p>19 0.48030162 <a title="219-lda-19" href="./nips-2012-Mixability_in_Statistical_Learning.html">217 nips-2012-Mixability in Statistical Learning</a></p>
<p>20 0.48000666 <a title="219-lda-20" href="./nips-2012-A_Nonparametric_Conjugate_Prior_Distribution_for_the_Maximizing_Argument_of_a_Noisy_Function.html">13 nips-2012-A Nonparametric Conjugate Prior Distribution for the Maximizing Argument of a Noisy Function</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
