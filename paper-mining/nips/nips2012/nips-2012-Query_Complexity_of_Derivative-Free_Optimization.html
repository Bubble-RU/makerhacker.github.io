<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>285 nips-2012-Query Complexity of Derivative-Free Optimization</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-285" href="#">nips2012-285</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>285 nips-2012-Query Complexity of Derivative-Free Optimization</h1>
<br/><p>Source: <a title="nips-2012-285-pdf" href="http://papers.nips.cc/paper/4509-query-complexity-of-derivative-free-optimization.pdf">pdf</a></p><p>Author: Ben Recht, Kevin G. Jamieson, Robert Nowak</p><p>Abstract: This paper provides lower bounds on the convergence rate of Derivative Free Optimization (DFO) with noisy function evaluations, exposing a fundamental and unavoidable gap between the performance of algorithms with access to gradients and those with access to only function evaluations. However, there are situations in which DFO is unavoidable, and for such situations we propose a new DFO algorithm that is proved to be near optimal for the class of strongly convex objective functions. A distinctive feature of the algorithm is that it uses only Boolean-valued function comparisons, rather than function evaluations. This makes the algorithm useful in an even wider range of applications, such as optimization based on paired comparisons from human subjects, for example. We also show that regardless of whether DFO is based on noisy function evaluations or Boolean-valued function comparisons, the convergence rate is the same. 1</p><p>Reference: <a title="nips-2012-285-reference" href="../nips2012_reference/nips-2012-Query_Complexity_of_Derivative-Free_Optimization_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract This paper provides lower bounds on the convergence rate of Derivative Free Optimization (DFO) with noisy function evaluations, exposing a fundamental and unavoidable gap between the performance of algorithms with access to gradients and those with access to only function evaluations. [sent-8, score-0.606]
</p><p>2 However, there are situations in which DFO is unavoidable, and for such situations we propose a new DFO algorithm that is proved to be near optimal for the class of strongly convex objective functions. [sent-9, score-0.301]
</p><p>3 A distinctive feature of the algorithm is that it uses only Boolean-valued function comparisons, rather than function evaluations. [sent-10, score-0.085]
</p><p>4 This makes the algorithm useful in an even wider range of applications, such as optimization based on paired comparisons from human subjects, for example. [sent-11, score-0.366]
</p><p>5 We also show that regardless of whether DFO is based on noisy function evaluations or Boolean-valued function comparisons, the convergence rate is the same. [sent-12, score-0.328]
</p><p>6 With training data or simulations one can evaluate the relative merit, or incurred loss, of different parameter settings, but it may be unclear how each parameter inﬂuences the overall objective function. [sent-14, score-0.051]
</p><p>7 In such cases, derivatives of the objective function with respect to the parameters are unavailable. [sent-15, score-0.029]
</p><p>8 When function evaluations are noiseless, DFO methods can achieve the same rates of convergence as noiseless gradient methods up to a small factor depending on a low-order polynomial of the dimension [9, 5, 10]. [sent-17, score-0.443]
</p><p>9 This leads one to wonder if the same equivalence can be extended to the case when function evaluations and gradients are noisy. [sent-18, score-0.286]
</p><p>10 We show that when function evaluations are noisy, the optip mization error of any DFO is ⌦( 1/T ), where T is the number of evaluations. [sent-20, score-0.224]
</p><p>11 This lower bound holds even for strongly convex functions. [sent-21, score-0.241]
</p><p>12 In contrast, noisy gradient methods exhibit ⇥(1/T ) error scaling for strongly convex functions [9, 11]. [sent-22, score-0.264]
</p><p>13 A consequence of our theory is that ﬁnite differencing cannot achieve the rates of gradient methods when the function evaluations are noisy. [sent-23, score-0.336]
</p><p>14 On the positive side, we also present a new derivative-free algorithm that achieves this lower bound with near optimal dimension dependence. [sent-24, score-0.14]
</p><p>15 Moreover, the algorithm uses only boolean comparisons of function values, not actual function values. [sent-25, score-0.25]
</p><p>16 This makes the algorithm applicable to situations in which the optimization is only able to probably correctly decide if the value of one conﬁguration is better than the value of another. [sent-26, score-0.111]
</p><p>17 This is especially interesting in optimization based on human subject feedback, where paired comparisons are often used instead of numerical scoring. [sent-27, score-0.338]
</p><p>18 The convergence rate of the new algorithm is optimal in terms of T and near-optimal in terms of its dependence on the ambient dimension. [sent-28, score-0.134]
</p><p>19 Surprisingly, our lower bounds show that this new algorithm that uses only function comparisons achieves the same rate in terms of T as any algorithm that has access to function evaluations. [sent-29, score-0.451]
</p><p>20 1  2  Problem formulation and background  We now formalize the notation and conventions for our analysis of DFO. [sent-30, score-0.043]
</p><p>21 A function f is strongly convex with constant ⌧ on a convex set B ⇢ Rd if there exists a constant ⌧ > 0 such that ⌧ f (y) f (x) + hrf (x), y xi + ||x y||2 2 for all x, y 2 B. [sent-31, score-0.286]
</p><p>22 The gradient of f , if it exists, denoted rf , is Lipschitz with constant L if ||rf (x) rf (y)||  L||x y|| for some L > 0. [sent-32, score-0.246]
</p><p>23 The class of strongly convex functions with Lipschitz gradients deﬁned on a nonempty, convex set B ⇢ Rn which take their minimum in B with parameters ⌧ and L is denoted by F⌧,L,B . [sent-33, score-0.298]
</p><p>24 The problem we consider is minimizing a function f 2 F⌧,L,B . [sent-34, score-0.029]
</p><p>25 An optimization procedure may only query the function in one of the following two ways. [sent-36, score-0.141]
</p><p>26 Function Evaluation Oracle: For any point x 2 B an optimization procedure can observe Ef (x) = f (x) + w where w 2 R is a random variable with E[w] = 0 and E[w2 ] = 2 . [sent-37, score-0.057]
</p><p>27 Function Comparison Oracle: For any pair of points x, y 2 B an optimization procedure can observe a binary random variable Cf (x, y) satisfying 1 + min 0 , µ|f (y) f (x)| 1 (1) 2 for some 0 < 0  1/2, µ > 0 and  1. [sent-38, score-0.057]
</p><p>28 Note  = 1 implies that the comparison oracle is correct with a probability that is greater than 1/2 and independent of x, y. [sent-40, score-0.499]
</p><p>29 If  > 1, then the oracle’s reliability decreases as the difference between f (x) and f (y) decreases. [sent-41, score-0.029]
</p><p>30 P (Cf (x, y) = sign{f (y)  f (x)})  To illustrate how the function comparison oracle and function evaluation oracles relate to each other, suppose Cf (x, y) = sign{Ef (y) Ef (x)} where Ef (x) is a function evaluation oracle with additive noise w. [sent-42, score-1.309]
</p><p>31 In fact, this choice of w corresponds to Thurston’s law of comparative judgment which is a popular model for outcomes of pairwise comparisons from human subjects [12]. [sent-44, score-0.406]
</p><p>32 If w is a “spikier” distribution such as a two-sided Gamma distribution with shape parameter in the range of (0, 1] then all values of  2 (1, 2] can be realized (see supplementary materials). [sent-45, score-0.03]
</p><p>33 Interest in the function comparison oracle is motivated by certain popular derivative-free optimization procedures that use only comparisons of function evaluations (e. [sent-46, score-0.932]
</p><p>34 [7]) and by optimization problems involving human subjects making paired comparisons (for instance, getting ﬁtted for prescription lenses or a hearing aid where unknown parameters speciﬁc to each person are tuned with the familiar queries “better or worse? [sent-48, score-0.761]
</p><p>35 Pairwise comparisons have also been suggested as a novel way to tune web-search algorithms [13]. [sent-50, score-0.187]
</p><p>36 Pairwise comparison strategies have previously been analyzed in the ﬁnite setting where the task is to identify the best alternative among a ﬁnite set of alternatives (sometimes referred to as the dueling-bandit problem) [13, 14]. [sent-51, score-0.105]
</p><p>37 The function comparison oracle presented in this work and its analysis are novel. [sent-52, score-0.528]
</p><p>38 While there are known theoretical results for DFO in the noiseless setting [15, 5, 10], to the best of our knowledge we are the ﬁrst to characterize lower bounds for DFO in the stochastic setting. [sent-55, score-0.307]
</p><p>39 Moreover, we believe we are the ﬁrst to show a novel upper bound for stochastic DFO using a function comparison oracle (which also applies to the function evaluation oracle). [sent-56, score-0.764]
</p><p>40 However, there are algorithms with upper bounds on the rates of convergence for stochastic 2  DFO with the function evaluation oracle [15, 16]. [sent-57, score-0.788]
</p><p>41 We discuss the relevant results in the next section following the lower bounds . [sent-58, score-0.158]
</p><p>42 While there remains many open problems in stochastic DFO (see Section 6), rates of convergence with a stochastic gradient oracle are well known and were ﬁrst lower bounded by Nemirovski and Yudin [15]. [sent-59, score-0.738]
</p><p>43 These classic results were recently tightened to show a dependence on the dimension of the problem [17]. [sent-60, score-0.155]
</p><p>44 And then tightened again to show a better dependence on the noise [11] which matches the upper bound achieved by stochastic gradient descent [9]. [sent-61, score-0.382]
</p><p>45 The aim of this work is to start ﬁlling in the knowledge gaps of stochastic DFO so that it is as well understood as the stochastic gradient oracle. [sent-62, score-0.214]
</p><p>46 Our bounds are based on simple techniques borrowed from the statistical learning literature that use natural functions and oracles in the same spirit of [11]. [sent-63, score-0.281]
</p><p>47 3  Main results  The results below are presented with simplifying constants that encompass many factors to aid in exposition. [sent-64, score-0.166]
</p><p>48 Explicit constants are given in the proofs in Sections 4 and 5. [sent-65, score-0.043]
</p><p>49 The expectation in the bounds is with respect to the noise in the oracle f queries and (possible) optimization algorithm randomization. [sent-67, score-0.717]
</p><p>50 1  Query complexity of the function comparison oracle  Theorem 1. [sent-69, score-0.528]
</p><p>51 For every f 2 F⌧,L,B let Cf be a function comparison oracle with parameters (, µ, 0 ). [sent-70, score-0.528]
</p><p>52 The constants c1 , c2 , c3 depend the oracle and function class parameters, as well as the geometry of B, but are independent of T and n. [sent-72, score-0.49]
</p><p>53 For upper bounds we propose a speciﬁc algorithm based on coordinate-descent in Section 5 and prove the following theorem for the case of unconstrained optimization, that is, B = Rn . [sent-73, score-0.134]
</p><p>54 For every f 2 F⌧,L,B with B = Rn let Cf be a function comparison oracle with parameters (, µ, 0 ). [sent-75, score-0.528]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('dfo', 0.688), ('oracle', 0.418), ('comparisons', 0.161), ('evaluations', 0.157), ('cf', 0.146), ('oracles', 0.14), ('bounds', 0.103), ('madison', 0.103), ('queries', 0.096), ('rf', 0.094), ('tightened', 0.093), ('wisconsin', 0.092), ('noiseless', 0.088), ('strongly', 0.087), ('lipschitz', 0.084), ('comparison', 0.081), ('paired', 0.074), ('convex', 0.073), ('unavoidable', 0.071), ('nowak', 0.066), ('subjects', 0.066), ('gradients', 0.065), ('evaluation', 0.061), ('stochastic', 0.061), ('aid', 0.06), ('gradient', 0.058), ('optimization', 0.057), ('query', 0.055), ('materials', 0.055), ('lower', 0.055), ('situations', 0.054), ('access', 0.047), ('yudin', 0.047), ('differencing', 0.047), ('exposing', 0.047), ('noisy', 0.046), ('wi', 0.046), ('human', 0.046), ('rates', 0.045), ('constants', 0.043), ('conventions', 0.043), ('prescription', 0.043), ('brecht', 0.043), ('judgment', 0.043), ('noise', 0.043), ('pairwise', 0.042), ('hearing', 0.04), ('merit', 0.04), ('convergence', 0.04), ('usa', 0.04), ('borrowed', 0.038), ('mization', 0.038), ('dependence', 0.036), ('rn', 0.036), ('wonder', 0.035), ('nonempty', 0.035), ('encompass', 0.035), ('matches', 0.034), ('gaps', 0.034), ('lling', 0.034), ('involving', 0.033), ('near', 0.033), ('recht', 0.032), ('sign', 0.032), ('upper', 0.031), ('nemirovski', 0.031), ('familiar', 0.031), ('mum', 0.031), ('ambient', 0.031), ('derivative', 0.031), ('free', 0.031), ('boolean', 0.031), ('uences', 0.03), ('realized', 0.03), ('function', 0.029), ('reliability', 0.029), ('getting', 0.029), ('presence', 0.029), ('benjamin', 0.028), ('applies', 0.028), ('simplifying', 0.028), ('wider', 0.028), ('supremum', 0.028), ('rate', 0.027), ('kevin', 0.027), ('merely', 0.027), ('distinctive', 0.027), ('feedback', 0.027), ('bound', 0.026), ('tune', 0.026), ('incurred', 0.026), ('dimension', 0.026), ('person', 0.025), ('unclear', 0.025), ('tted', 0.025), ('outcomes', 0.024), ('proves', 0.024), ('exists', 0.024), ('alternatives', 0.024), ('comparative', 0.024)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999988 <a title="285-tfidf-1" href="./nips-2012-Query_Complexity_of_Derivative-Free_Optimization.html">285 nips-2012-Query Complexity of Derivative-Free Optimization</a></p>
<p>Author: Ben Recht, Kevin G. Jamieson, Robert Nowak</p><p>Abstract: This paper provides lower bounds on the convergence rate of Derivative Free Optimization (DFO) with noisy function evaluations, exposing a fundamental and unavoidable gap between the performance of algorithms with access to gradients and those with access to only function evaluations. However, there are situations in which DFO is unavoidable, and for such situations we propose a new DFO algorithm that is proved to be near optimal for the class of strongly convex objective functions. A distinctive feature of the algorithm is that it uses only Boolean-valued function comparisons, rather than function evaluations. This makes the algorithm useful in an even wider range of applications, such as optimization based on paired comparisons from human subjects, for example. We also show that regardless of whether DFO is based on noisy function evaluations or Boolean-valued function comparisons, the convergence rate is the same. 1</p><p>2 0.14680368 <a title="285-tfidf-2" href="./nips-2012-Imitation_Learning_by_Coaching.html">160 nips-2012-Imitation Learning by Coaching</a></p>
<p>Author: He He, Jason Eisner, Hal Daume</p><p>Abstract: Imitation Learning has been shown to be successful in solving many challenging real-world problems. Some recent approaches give strong performance guarantees by training the policy iteratively. However, it is important to note that these guarantees depend on how well the policy we found can imitate the oracle on the training data. When there is a substantial difference between the oracle’s ability and the learner’s policy space, we may fail to ﬁnd a policy that has low error on the training set. In such cases, we propose to use a coach that demonstrates easy-to-learn actions for the learner and gradually approaches the oracle. By a reduction of learning by demonstration to online learning, we prove that coaching can yield a lower regret bound than using the oracle. We apply our algorithm to cost-sensitive dynamic feature selection, a hard decision problem that considers a user-speciﬁed accuracy-cost trade-off. Experimental results on UCI datasets show that our method outperforms state-of-the-art imitation learning methods in dynamic feature selection and two static feature selection methods. 1</p><p>3 0.1125403 <a title="285-tfidf-3" href="./nips-2012-Finite_Sample_Convergence_Rates_of_Zero-Order_Stochastic_Optimization_Methods.html">134 nips-2012-Finite Sample Convergence Rates of Zero-Order Stochastic Optimization Methods</a></p>
<p>Author: Andre Wibisono, Martin J. Wainwright, Michael I. Jordan, John C. Duchi</p><p>Abstract: We consider derivative-free algorithms for stochastic optimization problems that use only noisy function values rather than gradients, analyzing their ﬁnite-sample convergence rates. We show that if pairs of function values are available, algorithms that √ gradient estimates based on random perturbations suffer a factor use of at most d in convergence rate over traditional stochastic gradient methods, where d is the problem dimension. We complement our algorithmic development with information-theoretic lower bounds on the minimax convergence rate of such problems, which show that our bounds are sharp with respect to all problemdependent quantities: they cannot be improved by more than constant factors. 1</p><p>4 0.10955525 <a title="285-tfidf-4" href="./nips-2012-Link_Prediction_in_Graphs_with_Autoregressive_Features.html">199 nips-2012-Link Prediction in Graphs with Autoregressive Features</a></p>
<p>Author: Emile Richard, Stephane Gaiffas, Nicolas Vayatis</p><p>Abstract: In the paper, we consider the problem of link prediction in time-evolving graphs. We assume that certain graph features, such as the node degree, follow a vector autoregressive (VAR) model and we propose to use this information to improve the accuracy of prediction. Our strategy involves a joint optimization procedure over the space of adjacency matrices and VAR matrices which takes into account both sparsity and low rank properties of the matrices. Oracle inequalities are derived and illustrate the trade-offs in the choice of smoothing parameters when modeling the joint effect of sparsity and low rank property. The estimate is computed efﬁciently using proximal methods through a generalized forward-backward agorithm. 1</p><p>5 0.083637282 <a title="285-tfidf-5" href="./nips-2012-Learned_Prioritization_for_Trading_Off_Accuracy_and_Speed.html">173 nips-2012-Learned Prioritization for Trading Off Accuracy and Speed</a></p>
<p>Author: Jiarong Jiang, Adam Teichert, Jason Eisner, Hal Daume</p><p>Abstract: Users want inference to be both fast and accurate, but quality often comes at the cost of speed. The ﬁeld has experimented with approximate inference algorithms that make different speed-accuracy tradeoffs (for particular problems and datasets). We aim to explore this space automatically, focusing here on the case of agenda-based syntactic parsing [12]. Unfortunately, off-the-shelf reinforcement learning techniques fail to learn good policies: the state space is simply too large to explore naively. An attempt to counteract this by applying imitation learning algorithms also fails: the “teacher” follows a far better policy than anything in our learner’s policy space, free of the speed-accuracy tradeoff that arises when oracle information is unavailable, and thus largely insensitive to the known reward functﬁon. We propose a hybrid reinforcement/apprenticeship learning algorithm that learns to speed up an initial policy, trading off accuracy for speed according to various settings of a speed term in the loss function. 1</p><p>6 0.076939426 <a title="285-tfidf-6" href="./nips-2012-Stochastic_optimization_and_sparse_statistical_recovery%3A_Optimal_algorithms_for_high_dimensions.html">325 nips-2012-Stochastic optimization and sparse statistical recovery: Optimal algorithms for high dimensions</a></p>
<p>7 0.074838892 <a title="285-tfidf-7" href="./nips-2012-Stochastic_Gradient_Descent_with_Only_One_Projection.html">324 nips-2012-Stochastic Gradient Descent with Only One Projection</a></p>
<p>8 0.067598626 <a title="285-tfidf-8" href="./nips-2012-Adaptive_Stratified_Sampling_for_Monte-Carlo_integration_of_Differentiable_functions.html">36 nips-2012-Adaptive Stratified Sampling for Monte-Carlo integration of Differentiable functions</a></p>
<p>9 0.062034734 <a title="285-tfidf-9" href="./nips-2012-Iterative_ranking_from_pair-wise_comparisons.html">165 nips-2012-Iterative ranking from pair-wise comparisons</a></p>
<p>10 0.061185591 <a title="285-tfidf-10" href="./nips-2012-Online_allocation_and_homogeneous_partitioning_for_piecewise_constant_mean-approximation.html">261 nips-2012-Online allocation and homogeneous partitioning for piecewise constant mean-approximation</a></p>
<p>11 0.058522906 <a title="285-tfidf-11" href="./nips-2012-Accelerated_Training_for_Matrix-norm_Regularization%3A_A_Boosting_Approach.html">29 nips-2012-Accelerated Training for Matrix-norm Regularization: A Boosting Approach</a></p>
<p>12 0.058319796 <a title="285-tfidf-12" href="./nips-2012-Fused_sparsity_and_robust_estimation_for_linear_models_with_unknown_variance.html">139 nips-2012-Fused sparsity and robust estimation for linear models with unknown variance</a></p>
<p>13 0.057206981 <a title="285-tfidf-13" href="./nips-2012-MAP_Inference_in_Chains_using_Column_Generation.html">204 nips-2012-MAP Inference in Chains using Column Generation</a></p>
<p>14 0.055913553 <a title="285-tfidf-14" href="./nips-2012-Iterative_Thresholding_Algorithm_for_Sparse_Inverse_Covariance_Estimation.html">164 nips-2012-Iterative Thresholding Algorithm for Sparse Inverse Covariance Estimation</a></p>
<p>15 0.055824 <a title="285-tfidf-15" href="./nips-2012-Automatic_Feature_Induction_for_Stagewise_Collaborative_Filtering.html">49 nips-2012-Automatic Feature Induction for Stagewise Collaborative Filtering</a></p>
<p>16 0.054128833 <a title="285-tfidf-16" href="./nips-2012-Bayesian_active_learning_with_localized_priors_for_fast_receptive_field_characterization.html">56 nips-2012-Bayesian active learning with localized priors for fast receptive field characterization</a></p>
<p>17 0.053882524 <a title="285-tfidf-17" href="./nips-2012-Approximating_Concavely_Parameterized_Optimization_Problems.html">44 nips-2012-Approximating Concavely Parameterized Optimization Problems</a></p>
<p>18 0.0503335 <a title="285-tfidf-18" href="./nips-2012-Optimal_Regularized_Dual_Averaging_Methods_for_Stochastic_Optimization.html">263 nips-2012-Optimal Regularized Dual Averaging Methods for Stochastic Optimization</a></p>
<p>19 0.048710745 <a title="285-tfidf-19" href="./nips-2012-Practical_Bayesian_Optimization_of_Machine_Learning_Algorithms.html">272 nips-2012-Practical Bayesian Optimization of Machine Learning Algorithms</a></p>
<p>20 0.047690611 <a title="285-tfidf-20" href="./nips-2012-Learning_as_MAP_Inference_in_Discrete_Graphical_Models.html">186 nips-2012-Learning as MAP Inference in Discrete Graphical Models</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.129), (1, -0.026), (2, 0.059), (3, -0.026), (4, 0.057), (5, 0.048), (6, -0.005), (7, 0.026), (8, -0.0), (9, 0.007), (10, -0.013), (11, 0.061), (12, -0.078), (13, 0.02), (14, -0.003), (15, 0.062), (16, -0.034), (17, -0.045), (18, 0.044), (19, 0.058), (20, -0.022), (21, -0.018), (22, 0.019), (23, -0.033), (24, -0.023), (25, -0.034), (26, -0.041), (27, 0.069), (28, 0.035), (29, -0.089), (30, 0.087), (31, 0.066), (32, -0.01), (33, -0.071), (34, -0.012), (35, -0.013), (36, -0.006), (37, -0.037), (38, 0.105), (39, -0.026), (40, -0.006), (41, 0.001), (42, -0.035), (43, 0.047), (44, 0.041), (45, -0.043), (46, -0.076), (47, 0.096), (48, 0.096), (49, -0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.91436291 <a title="285-lsi-1" href="./nips-2012-Query_Complexity_of_Derivative-Free_Optimization.html">285 nips-2012-Query Complexity of Derivative-Free Optimization</a></p>
<p>Author: Ben Recht, Kevin G. Jamieson, Robert Nowak</p><p>Abstract: This paper provides lower bounds on the convergence rate of Derivative Free Optimization (DFO) with noisy function evaluations, exposing a fundamental and unavoidable gap between the performance of algorithms with access to gradients and those with access to only function evaluations. However, there are situations in which DFO is unavoidable, and for such situations we propose a new DFO algorithm that is proved to be near optimal for the class of strongly convex objective functions. A distinctive feature of the algorithm is that it uses only Boolean-valued function comparisons, rather than function evaluations. This makes the algorithm useful in an even wider range of applications, such as optimization based on paired comparisons from human subjects, for example. We also show that regardless of whether DFO is based on noisy function evaluations or Boolean-valued function comparisons, the convergence rate is the same. 1</p><p>2 0.62595546 <a title="285-lsi-2" href="./nips-2012-Finite_Sample_Convergence_Rates_of_Zero-Order_Stochastic_Optimization_Methods.html">134 nips-2012-Finite Sample Convergence Rates of Zero-Order Stochastic Optimization Methods</a></p>
<p>Author: Andre Wibisono, Martin J. Wainwright, Michael I. Jordan, John C. Duchi</p><p>Abstract: We consider derivative-free algorithms for stochastic optimization problems that use only noisy function values rather than gradients, analyzing their ﬁnite-sample convergence rates. We show that if pairs of function values are available, algorithms that √ gradient estimates based on random perturbations suffer a factor use of at most d in convergence rate over traditional stochastic gradient methods, where d is the problem dimension. We complement our algorithmic development with information-theoretic lower bounds on the minimax convergence rate of such problems, which show that our bounds are sharp with respect to all problemdependent quantities: they cannot be improved by more than constant factors. 1</p><p>3 0.59724343 <a title="285-lsi-3" href="./nips-2012-Optimal_Regularized_Dual_Averaging_Methods_for_Stochastic_Optimization.html">263 nips-2012-Optimal Regularized Dual Averaging Methods for Stochastic Optimization</a></p>
<p>Author: Xi Chen, Qihang Lin, Javier Pena</p><p>Abstract: This paper considers a wide spectrum of regularized stochastic optimization problems where both the loss function and regularizer can be non-smooth. We develop a novel algorithm based on the regularized dual averaging (RDA) method, that can simultaneously achieve the optimal convergence rates for both convex and strongly convex loss. In particular, for strongly convex loss, it achieves the opti1 1 mal rate of O( N + N 2 ) for N iterations, which improves the rate O( log N ) for preN vious regularized dual averaging algorithms. In addition, our method constructs the ﬁnal solution directly from the proximal mapping instead of averaging of all previous iterates. For widely used sparsity-inducing regularizers (e.g., 1 -norm), it has the advantage of encouraging sparser solutions. We further develop a multistage extension using the proposed algorithm as a subroutine, which achieves the 1 uniformly-optimal rate O( N + exp{−N }) for strongly convex loss. 1</p><p>4 0.56220818 <a title="285-lsi-4" href="./nips-2012-Stochastic_optimization_and_sparse_statistical_recovery%3A_Optimal_algorithms_for_high_dimensions.html">325 nips-2012-Stochastic optimization and sparse statistical recovery: Optimal algorithms for high dimensions</a></p>
<p>Author: Alekh Agarwal, Sahand Negahban, Martin J. Wainwright</p><p>Abstract: We develop and analyze stochastic optimization algorithms for problems in which the expected loss is strongly convex, and the optimum is (approximately) sparse. Previous approaches are able to exploit only one of these two structures, yielding a O(d/T ) convergence rate for strongly convex objectives in d dimensions and O( s(log d)/T ) convergence rate when the optimum is s-sparse. Our algorithm is based on successively solving a series of ℓ1 -regularized optimization problems using Nesterov’s dual averaging algorithm. We establish that the error of our solution after T iterations is at most O(s(log d)/T ), with natural extensions to approximate sparsity. Our results apply to locally Lipschitz losses including the logistic, exponential, hinge and least-squares losses. By recourse to statistical minimax results, we show that our convergence rates are optimal up to constants. The effectiveness of our approach is also conﬁrmed in numerical simulations where we compare to several baselines on a least-squares regression problem.</p><p>5 0.55738252 <a title="285-lsi-5" href="./nips-2012-Imitation_Learning_by_Coaching.html">160 nips-2012-Imitation Learning by Coaching</a></p>
<p>Author: He He, Jason Eisner, Hal Daume</p><p>Abstract: Imitation Learning has been shown to be successful in solving many challenging real-world problems. Some recent approaches give strong performance guarantees by training the policy iteratively. However, it is important to note that these guarantees depend on how well the policy we found can imitate the oracle on the training data. When there is a substantial difference between the oracle’s ability and the learner’s policy space, we may fail to ﬁnd a policy that has low error on the training set. In such cases, we propose to use a coach that demonstrates easy-to-learn actions for the learner and gradually approaches the oracle. By a reduction of learning by demonstration to online learning, we prove that coaching can yield a lower regret bound than using the oracle. We apply our algorithm to cost-sensitive dynamic feature selection, a hard decision problem that considers a user-speciﬁed accuracy-cost trade-off. Experimental results on UCI datasets show that our method outperforms state-of-the-art imitation learning methods in dynamic feature selection and two static feature selection methods. 1</p><p>6 0.55153334 <a title="285-lsi-6" href="./nips-2012-Communication-Efficient_Algorithms_for_Statistical_Optimization.html">76 nips-2012-Communication-Efficient Algorithms for Statistical Optimization</a></p>
<p>7 0.5302915 <a title="285-lsi-7" href="./nips-2012-Mixability_in_Statistical_Learning.html">217 nips-2012-Mixability in Statistical Learning</a></p>
<p>8 0.51862699 <a title="285-lsi-8" href="./nips-2012-Link_Prediction_in_Graphs_with_Autoregressive_Features.html">199 nips-2012-Link Prediction in Graphs with Autoregressive Features</a></p>
<p>9 0.50591153 <a title="285-lsi-9" href="./nips-2012-Privacy_Aware_Learning.html">275 nips-2012-Privacy Aware Learning</a></p>
<p>10 0.49709141 <a title="285-lsi-10" href="./nips-2012-Adaptive_Stratified_Sampling_for_Monte-Carlo_integration_of_Differentiable_functions.html">36 nips-2012-Adaptive Stratified Sampling for Monte-Carlo integration of Differentiable functions</a></p>
<p>11 0.49269316 <a title="285-lsi-11" href="./nips-2012-A_Stochastic_Gradient_Method_with_an_Exponential_Convergence__Rate_for_Finite_Training_Sets.html">20 nips-2012-A Stochastic Gradient Method with an Exponential Convergence  Rate for Finite Training Sets</a></p>
<p>12 0.49065107 <a title="285-lsi-12" href="./nips-2012-Online_allocation_and_homogeneous_partitioning_for_piecewise_constant_mean-approximation.html">261 nips-2012-Online allocation and homogeneous partitioning for piecewise constant mean-approximation</a></p>
<p>13 0.47564653 <a title="285-lsi-13" href="./nips-2012-Generalization_Bounds_for_Domain_Adaptation.html">142 nips-2012-Generalization Bounds for Domain Adaptation</a></p>
<p>14 0.47217557 <a title="285-lsi-14" href="./nips-2012-Stochastic_Gradient_Descent_with_Only_One_Projection.html">324 nips-2012-Stochastic Gradient Descent with Only One Projection</a></p>
<p>15 0.46491396 <a title="285-lsi-15" href="./nips-2012-Accelerated_Training_for_Matrix-norm_Regularization%3A_A_Boosting_Approach.html">29 nips-2012-Accelerated Training for Matrix-norm Regularization: A Boosting Approach</a></p>
<p>16 0.45623353 <a title="285-lsi-16" href="./nips-2012-Accuracy_at_the_Top.html">30 nips-2012-Accuracy at the Top</a></p>
<p>17 0.41898185 <a title="285-lsi-17" href="./nips-2012-Fused_sparsity_and_robust_estimation_for_linear_models_with_unknown_variance.html">139 nips-2012-Fused sparsity and robust estimation for linear models with unknown variance</a></p>
<p>18 0.41672963 <a title="285-lsi-18" href="./nips-2012-Hierarchical_Optimistic_Region_Selection_driven_by_Curiosity.html">149 nips-2012-Hierarchical Optimistic Region Selection driven by Curiosity</a></p>
<p>19 0.40001866 <a title="285-lsi-19" href="./nips-2012-Spectral_Learning_of_General_Weighted_Automata_via_Constrained_Matrix_Completion.html">320 nips-2012-Spectral Learning of General Weighted Automata via Constrained Matrix Completion</a></p>
<p>20 0.39954871 <a title="285-lsi-20" href="./nips-2012-Volume_Regularization_for_Binary_Classification.html">361 nips-2012-Volume Regularization for Binary Classification</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.038), (34, 0.191), (38, 0.214), (42, 0.054), (54, 0.018), (55, 0.013), (74, 0.056), (76, 0.172), (80, 0.097), (92, 0.039)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.95340854 <a title="285-lda-1" href="./nips-2012-Spiking_and_saturating_dendrites_differentially_expand_single_neuron_computation_capacity.html">322 nips-2012-Spiking and saturating dendrites differentially expand single neuron computation capacity</a></p>
<p>Author: Romain Cazé, Mark Humphries, Boris S. Gutkin</p><p>Abstract: The integration of excitatory inputs in dendrites is non-linear: multiple excitatory inputs can produce a local depolarization departing from the arithmetic sum of each input’s response taken separately. If this depolarization is bigger than the arithmetic sum, the dendrite is spiking; if the depolarization is smaller, the dendrite is saturating. Decomposing a dendritic tree into independent dendritic spiking units greatly extends its computational capacity, as the neuron then maps onto a two layer neural network, enabling it to compute linearly non-separable Boolean functions (lnBFs). How can these lnBFs be implemented by dendritic architectures in practise? And can saturating dendrites equally expand computational capacity? To address these questions we use a binary neuron model and Boolean algebra. First, we conﬁrm that spiking dendrites enable a neuron to compute lnBFs using an architecture based on the disjunctive normal form (DNF). Second, we prove that saturating dendrites as well as spiking dendrites enable a neuron to compute lnBFs using an architecture based on the conjunctive normal form (CNF). Contrary to a DNF-based architecture, in a CNF-based architecture, dendritic unit tunings do not imply the neuron tuning, as has been observed experimentally. Third, we show that one cannot use a DNF-based architecture with saturating dendrites. Consequently, we show that an important family of lnBFs implemented with a CNF-architecture can require an exponential number of saturating dendritic units, whereas the same family implemented with either a DNF-architecture or a CNF-architecture always require a linear number of spiking dendritic units. This minimization could explain why a neuron spends energetic resources to make its dendrites spike. 1</p><p>same-paper 2 0.88726807 <a title="285-lda-2" href="./nips-2012-Query_Complexity_of_Derivative-Free_Optimization.html">285 nips-2012-Query Complexity of Derivative-Free Optimization</a></p>
<p>Author: Ben Recht, Kevin G. Jamieson, Robert Nowak</p><p>Abstract: This paper provides lower bounds on the convergence rate of Derivative Free Optimization (DFO) with noisy function evaluations, exposing a fundamental and unavoidable gap between the performance of algorithms with access to gradients and those with access to only function evaluations. However, there are situations in which DFO is unavoidable, and for such situations we propose a new DFO algorithm that is proved to be near optimal for the class of strongly convex objective functions. A distinctive feature of the algorithm is that it uses only Boolean-valued function comparisons, rather than function evaluations. This makes the algorithm useful in an even wider range of applications, such as optimization based on paired comparisons from human subjects, for example. We also show that regardless of whether DFO is based on noisy function evaluations or Boolean-valued function comparisons, the convergence rate is the same. 1</p><p>3 0.83894664 <a title="285-lda-3" href="./nips-2012-Locating_Changes_in_Highly_Dependent_Data_with_Unknown_Number_of_Change_Points.html">203 nips-2012-Locating Changes in Highly Dependent Data with Unknown Number of Change Points</a></p>
<p>Author: Azadeh Khaleghi, Daniil Ryabko</p><p>Abstract: The problem of multiple change point estimation is considered for sequences with unknown number of change points. A consistency framework is suggested that is suitable for highly dependent time-series, and an asymptotically consistent algorithm is proposed. In order for the consistency to be established the only assumption required is that the data is generated by stationary ergodic time-series distributions. No modeling, independence or parametric assumptions are made; the data are allowed to be dependent and the dependence can be of arbitrary form. The theoretical results are complemented with experimental evaluations. 1</p><p>4 0.83799201 <a title="285-lda-4" href="./nips-2012-Learning_Manifolds_with_K-Means_and_K-Flats.html">179 nips-2012-Learning Manifolds with K-Means and K-Flats</a></p>
<p>Author: Guillermo Canas, Tomaso Poggio, Lorenzo Rosasco</p><p>Abstract: We study the problem of estimating a manifold from random samples. In particular, we consider piecewise constant and piecewise linear estimators induced by k-means and k-ﬂats, and analyze their performance. We extend previous results for k-means in two separate directions. First, we provide new results for k-means reconstruction on manifolds and, secondly, we prove reconstruction bounds for higher-order approximation (k-ﬂats), for which no known results were previously available. While the results for k-means are novel, some of the technical tools are well-established in the literature. In the case of k-ﬂats, both the results and the mathematical tools are new. 1</p><p>5 0.83728188 <a title="285-lda-5" href="./nips-2012-Stochastic_optimization_and_sparse_statistical_recovery%3A_Optimal_algorithms_for_high_dimensions.html">325 nips-2012-Stochastic optimization and sparse statistical recovery: Optimal algorithms for high dimensions</a></p>
<p>Author: Alekh Agarwal, Sahand Negahban, Martin J. Wainwright</p><p>Abstract: We develop and analyze stochastic optimization algorithms for problems in which the expected loss is strongly convex, and the optimum is (approximately) sparse. Previous approaches are able to exploit only one of these two structures, yielding a O(d/T ) convergence rate for strongly convex objectives in d dimensions and O( s(log d)/T ) convergence rate when the optimum is s-sparse. Our algorithm is based on successively solving a series of ℓ1 -regularized optimization problems using Nesterov’s dual averaging algorithm. We establish that the error of our solution after T iterations is at most O(s(log d)/T ), with natural extensions to approximate sparsity. Our results apply to locally Lipschitz losses including the logistic, exponential, hinge and least-squares losses. By recourse to statistical minimax results, we show that our convergence rates are optimal up to constants. The effectiveness of our approach is also conﬁrmed in numerical simulations where we compare to several baselines on a least-squares regression problem.</p><p>6 0.83722794 <a title="285-lda-6" href="./nips-2012-Link_Prediction_in_Graphs_with_Autoregressive_Features.html">199 nips-2012-Link Prediction in Graphs with Autoregressive Features</a></p>
<p>7 0.83695304 <a title="285-lda-7" href="./nips-2012-Dimensionality_Dependent_PAC-Bayes_Margin_Bound.html">98 nips-2012-Dimensionality Dependent PAC-Bayes Margin Bound</a></p>
<p>8 0.83691669 <a title="285-lda-8" href="./nips-2012-Near-Optimal_MAP_Inference_for_Determinantal_Point_Processes.html">236 nips-2012-Near-Optimal MAP Inference for Determinantal Point Processes</a></p>
<p>9 0.83587223 <a title="285-lda-9" href="./nips-2012-Multiclass_Learning_Approaches%3A_A_Theoretical_Comparison_with_Implications.html">226 nips-2012-Multiclass Learning Approaches: A Theoretical Comparison with Implications</a></p>
<p>10 0.83575767 <a title="285-lda-10" href="./nips-2012-Learning_Label_Trees_for_Probabilistic_Modelling_of_Implicit_Feedback.html">178 nips-2012-Learning Label Trees for Probabilistic Modelling of Implicit Feedback</a></p>
<p>11 0.8357141 <a title="285-lda-11" href="./nips-2012-Learning_curves_for_multi-task_Gaussian_process_regression.html">187 nips-2012-Learning curves for multi-task Gaussian process regression</a></p>
<p>12 0.83528739 <a title="285-lda-12" href="./nips-2012-A_Polylog_Pivot_Steps_Simplex_Algorithm_for_Classification.html">15 nips-2012-A Polylog Pivot Steps Simplex Algorithm for Classification</a></p>
<p>13 0.83520234 <a title="285-lda-13" href="./nips-2012-Volume_Regularization_for_Binary_Classification.html">361 nips-2012-Volume Regularization for Binary Classification</a></p>
<p>14 0.83494645 <a title="285-lda-14" href="./nips-2012-A_Polynomial-time_Form_of_Robust_Regression.html">16 nips-2012-A Polynomial-time Form of Robust Regression</a></p>
<p>15 0.83480793 <a title="285-lda-15" href="./nips-2012-Value_Pursuit_Iteration.html">358 nips-2012-Value Pursuit Iteration</a></p>
<p>16 0.83458823 <a title="285-lda-16" href="./nips-2012-Optimal_Regularized_Dual_Averaging_Methods_for_Stochastic_Optimization.html">263 nips-2012-Optimal Regularized Dual Averaging Methods for Stochastic Optimization</a></p>
<p>17 0.83418602 <a title="285-lda-17" href="./nips-2012-Convex_Multi-view_Subspace_Learning.html">86 nips-2012-Convex Multi-view Subspace Learning</a></p>
<p>18 0.83359039 <a title="285-lda-18" href="./nips-2012-Majorization_for_CRFs_and_Latent_Likelihoods.html">206 nips-2012-Majorization for CRFs and Latent Likelihoods</a></p>
<p>19 0.833368 <a title="285-lda-19" href="./nips-2012-Active_Learning_of_Multi-Index_Function_Models.html">34 nips-2012-Active Learning of Multi-Index Function Models</a></p>
<p>20 0.83325869 <a title="285-lda-20" href="./nips-2012-Privacy_Aware_Learning.html">275 nips-2012-Privacy Aware Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
