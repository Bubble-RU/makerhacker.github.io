<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>122 nips-2010-Improving the Asymptotic Performance of Markov Chain Monte-Carlo by Inserting Vortices</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-122" href="../nips2010/nips-2010-Improving_the_Asymptotic_Performance_of_Markov_Chain_Monte-Carlo_by_Inserting_Vortices.html">nips2010-122</a> <a title="nips-2010-122-reference" href="#">nips2010-122-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>122 nips-2010-Improving the Asymptotic Performance of Markov Chain Monte-Carlo by Inserting Vortices</h1>
<br/><p>Source: <a title="nips-2010-122-pdf" href="http://papers.nips.cc/paper/4037-improving-the-asymptotic-performance-of-markov-chain-monte-carlo-by-inserting-vortices.pdf">pdf</a></p><p>Author: Yi Sun, Jürgen Schmidhuber, Faustino J. Gomez</p><p>Abstract: We present a new way of converting a reversible ﬁnite Markov chain into a nonreversible one, with a theoretical guarantee that the asymptotic variance of the MCMC estimator based on the non-reversible chain is reduced. The method is applicable to any reversible chain whose states are not connected through a tree, and can be interpreted graphically as inserting vortices into the state transition graph. Our result conﬁrms that non-reversible chains are fundamentally better than reversible ones in terms of asymptotic performance, and suggests interesting directions for further improving MCMC. 1</p><br/>
<h2>reference text</h2><p>[1] R.P. Wen, ”Properties of the Matrix Inequality”, Journal of Taiyuan Teachers College, 2005.</p>
<p>[2] R. Mathias, ”Matrices With Positive Deﬁnite Hermitian Part: Inequalities And Linear Systems”, http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10. 1.1.33.1768, 1992.</p>
<p>[3] L.H. Li, ”A New Proof of Peskun’s and Tierney’s Theorems using Matrix Method”, Joint Graduate Students Seminar of Department of Statistics and Department of Biostatistics, Univ. of Toronto, 2005.</p>
<p>[4] R.M. Neal, ”Improving asymptotic variance of MCMC estimators: Non-reversible chains are better”, Technical Report No. 0406, Department of Statistics, Univ. of Toronto, 2004.</p>
<p>[5] I. Murray, ”Advances in Markov chain Monte Carlo methods”, M. Sci. thesis, University College London, 2007.</p>
<p>[6] R.M. Neal, ”Bayesian Learning for Neural Networks”, Springer, 1996.</p>
<p>[7] J. Kenney and E.S. Keeping, ”Mathematics of Statistics”, van Nostrand, 1963.</p>
<p>[8] C. Andrieu, N. de Freitas, A. Doucet, and M.I. Jordan, ”An Introduction to MCMC for Machine Learning”, Machine Learning, 50, 5-43, 2003.</p>
<p>[9] Szakdolgozat, ”The Mixing Rate of Markov Chain Monte Carlo Methods and some Applications of MCMC Simulation in Bioinformatics”, M.Sci. thesis, Eotvos Lorand University, 2006.</p>
<p>[10] P.H. Peskun, ”Optimum Monte-Carlo sampling using Markov chains”, Biometrika, vol. 60, pp. 607-612, 1973.</p>
<p>[11] L. Tierney, ”A note on Metropolis Hastings kernels for general state spaces”, Ann. Appl. Probab. 8, 1-9, 1998.</p>
<p>[12] S. Duane, A.D. Kennedy, B.J. Pendleton and D. Roweth, ”Hybrid Monte Carlo”, Physics Letters B, vol.195-2, 1987.</p>
<p>[13] J.S. Liu, ”Peskun’s theorem and a modiﬁed discrete-state Gibbs sampler”, Biometria, vol.83, pp.681-682, 1996.  9</p>
<br/>
<br/><br/><br/></body>
</html>
