<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>41 nips-2010-Block Variable Selection in Multivariate Regression and High-dimensional Causal Inference</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-41" href="../nips2010/nips-2010-Block_Variable_Selection_in_Multivariate_Regression_and_High-dimensional_Causal_Inference.html">nips2010-41</a> <a title="nips-2010-41-reference" href="#">nips2010-41-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>41 nips-2010-Block Variable Selection in Multivariate Regression and High-dimensional Causal Inference</h1>
<br/><p>Source: <a title="nips-2010-41-pdf" href="http://papers.nips.cc/paper/3993-block-variable-selection-in-multivariate-regression-and-high-dimensional-causal-inference.pdf">pdf</a></p><p>Author: Vikas Sindhwani, Aurelie C. Lozano</p><p>Abstract: We consider multivariate regression problems involving high-dimensional predictor and response spaces. To efﬁciently address such problems, we propose a variable selection method, Multivariate Group Orthogonal Matching Pursuit, which extends the standard Orthogonal Matching Pursuit technique. This extension accounts for arbitrary sparsity patterns induced by domain-speciﬁc groupings over both input and output variables, while also taking advantage of the correlation that may exist between the multiple outputs. Within this framework, we then formulate the problem of inferring causal relationships over a collection of high-dimensional time series variables. When applied to time-evolving social media content, our models yield a new family of causality-based inﬂuence measures that may be seen as an alternative to the classic PageRank algorithm traditionally applied to hyperlink graphs. Theoretical guarantees, extensive simulations and empirical studies conﬁrm the generality and value of our framework.</p><br/>
<h2>reference text</h2><p>[1] Andreas Argyriou, Theodoros Evgeniou, and Massimiliano Pontil. Convex multi-task feature learning. Machine Learning, 73(3):243–272, 2008.</p>
<p>[2] Leo Breiman and Jerome H Friedman. Predicting multivariate responses in multiple linear regression. Journal of the Royal Statistical Society: Series B, (1):1369–7412, 1997.</p>
<p>[3] M. Elad. Sparse and Redundant Representations: From Theory to Applications in Signal and Image Processing. Springer,2010</p>
<p>[4] Ildiko E. Frank and Jerome H. Friedman. A statistical view of some chemometrics regression tools. Technometrics, 35(2):109–135, 1993.</p>
<p>[5] J. Friedman, T. Hastie, and R. Tibshirani. Sparse inverse covariance estimation with the graphical lasso. Biostatistics, 9(3):432–441, July 2008.</p>
<p>[6] M. Gomez-Rodriguez and J. Leskovec and A. Krause. Inferring Networks of Diffusion and Inﬂuence, KDD 2010.</p>
<p>[7] C. Granger. Testing for causality: A personal viewpoint. Journal of Economic Dynamics and Control, 2:329–352, 1980.</p>
<p>[8] D. Harville. Matrix Algebra from a Statistician’s Perspective. Springer, 1997.</p>
<p>[9] J. Huang, T. Zhang, and D. Metaxas D. Learning with structured sparsity, ICML 2009.</p>
<p>[10] T. Joachims. Structured output prediction with support vector machines. In Joint IAPR International Workshops on Structural and Syntactic Pattern Recognition (SSPR) and Statistical Techniques in Pattern Recognition (SPR), pages 1–7, 2006.</p>
<p>[11] Jon M. Kleinberg. Authoritative sources in a hyperlinked environment. Journal of the ACM, 46:668–677, 1999.</p>
<p>[12] A.C. Lozano, G. Swirszcz, and N. Abe. Grouped orthogonal matching pursuit for variable selection and prediction. Advances in Neural Information Processing Systems 22, 2009.</p>
<p>[13] S. Mallat and Z. Zhang. Matching pursuits with time-frequency dictionaries. IEEE Transactions on Signal Processing, 1993.</p>
<p>[14] P. Melville, K. Subbian, C. Perlich, R. Lawrence and E. Meliksetian. A Predictive Perspective on Measures of Inﬂuence in Networks Workshop on Information in Networks (WIN-10), New York, September, 2010.</p>
<p>[15] Charles A. Micchelli and Massimiliano Pontil. Kernels for multi–task learning. In NIPS, 2004.</p>
<p>[16] G. Obozinski, B. Taskar, and M. Jordan. Multi-task feature selection. Technical report, 2006.</p>
<p>[17] L. Page, S. Brin, R. Motwani, and T. Winograd. The pagerank citation ranking: Bringing order to the web. Technical Report, Stanford Digital Libraries, 1998.</p>
<p>[18] Elisa Ricci, Tijl De Bie, and Nello Cristianini. Magic moments for structured output prediction. Journal of Machine Learning Research, 9:2803–2846, December 2008.</p>
<p>[19] R. Tibshirani. Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society, Series B, 58:267–288, 1994.</p>
<p>[20] A.N. Tikhonov. Regularization of incorrectly posed problems. Sov. Math. Dokl, 4:16241627, 1963.</p>
<p>[21] J.A. Tropp, A.C. Gilbert, and M.J. Strauss. Algorithms for simultaneous sparse approximation: part i: Greedy pursuit. Sig. Proc., 86(3):572–588, 2006.</p>
<p>[22] I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun. Support vector machine learning for interdependent and structured output spaces. In International Conference on Machine Learning (ICML), pages 104–112, 2004.</p>
<p>[23] M. Yuan and Y. Lin. Model selection and estimation in regression with grouped variables. Journal of the Royal Statistical Society, Series B, 68:49–67, 2006.</p>
<p>[24] Ming Yuan, Ali Ekici, Zhaosong Lu, and Renato Monteiro. Dimension reduction and coefﬁcient estimation in multivariate linear regression. Journal Of The Royal Statistical Society Series B, 69(3):329–346, 2007.  9</p>
<br/>
<br/><br/><br/></body>
</html>
