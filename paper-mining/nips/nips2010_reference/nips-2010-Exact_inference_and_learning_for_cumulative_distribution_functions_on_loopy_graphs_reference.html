<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>84 nips-2010-Exact inference and learning for cumulative distribution functions on loopy graphs</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-84" href="../nips2010/nips-2010-Exact_inference_and_learning_for_cumulative_distribution_functions_on_loopy_graphs.html">nips2010-84</a> <a title="nips-2010-84-reference" href="#">nips2010-84-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>84 nips-2010-Exact inference and learning for cumulative distribution functions on loopy graphs</h1>
<br/><p>Source: <a title="nips-2010-84-pdf" href="http://papers.nips.cc/paper/3899-exact-inference-and-learning-for-cumulative-distribution-functions-on-loopy-graphs.pdf">pdf</a></p><p>Author: Nebojsa Jojic, Chris Meek, Jim C. Huang</p><p>Abstract: Many problem domains including climatology and epidemiology require models that can capture both heavy-tailed statistics and local dependencies. Specifying such distributions using graphical models for probability density functions (PDFs) generally lead to intractable inference and learning. Cumulative distribution networks (CDNs) provide a means to tractably specify multivariate heavy-tailed models as a product of cumulative distribution functions (CDFs). Existing algorithms for inference and learning in CDNs are limited to those with tree-structured (nonloopy) graphs. In this paper, we develop inference and learning algorithms for CDNs with arbitrary topology. Our approach to inference and learning relies on recursively decomposing the computation of mixed derivatives based on a junction trees over the cumulative distribution functions. We demonstrate that our systematic approach to utilizing the sparsity represented by the junction tree yields signiďŹ cant performance improvements over the general symbolic differentiation programs Mathematica and D*. Using two real-world datasets, we demonstrate that non-tree structured (loopy) CDNs are able to provide signiďŹ cantly better ďŹ ts to the data as compared to tree-structured and unstructured CDNs and other heavy-tailed multivariate distributions such as the multivariate copula and logistic models.</p><br/>
<h2>reference text</h2><p>[1] Colizza, V., Barrat, A., Barthelemy, M. and Vespignani, A. (2006) Prediction and predictability of global epidemics: the role of the airline transportation network. Proceedings of the National Academy of Sciences USA (PNAS) 103, 2015-2020.</p>
<p>[2] de Haan, L. and Ferreira, A. (2006) Extreme value theory. Springer.</p>
<p>[3] Drton, M. and Richardson, T.S. (2004) Iterative conditional ďŹ tting for Gaussian ancestral graph models. Proceedings of the Twentieth Conference on Uncertainty in ArtiďŹ cial Intelligence (UAI), 130-137.</p>
<p>[4] Guenter, B. (2007) EfďŹ cient symbolic differentiation for graphics applications. ACM Transactions on Graphics 26(3).</p>
<p>[5] Hardy, M. (2006) Combinatorics of partial derivatives. Electronic Journal of Combinatorics 13.</p>
<p>[6] Huang, J.C. and Frey, B.J. (2008) Cumulative distribution networks and the derivative-sumproduct algorithm. Proceedings of the Twenty-Fourth Conference on Uncertainty in ArtiďŹ cial Intelligence (UAI), 290-297.</p>
<p>[7] Huang, J.C. (2009) Cumulative distribution networks: Inference, estimation and applications of graphical models for cumulative distribution functions. University of Toronto Ph.D. thesis. http://hdl.handle.net/1807/19194</p>
<p>[8] Huang, J.C. and Jojic, N. (2010) Maximum-likelihood learning of cumulative distribution functions on graphs. Journal of Machine Learning Research W&CP; Series 9, 342-349.</p>
<p>[9] Kirschner, S. (2007) Learning with tree-averaged densities and distributions. Advances in Neural Information Systems Processing (NIPS) 20, 761-768.</p>
<p>[10] Koller, D. and Friedman, N. (2009). Probabilistic Graphical Models: Principles and Techniques, MIT Press.</p>
<p>[11] Liu, H., Lafferty, J. and Wasserman, L. (2009) The nonparanormal: Semiparametric estimation of high dimensional undirected graphs. Journal of Machine Learning Research (JMLR) 10, 22952328.</p>
<p>[12] Lauritzen, S.L. and Spiegelhalter, D.J. (1988) Local computations with probabilities on graphical structures and their application to expert systems. Journal of the Royal Statistical Society Series B (Methodological) 50(2), 157224.</p>
<p>[13] Malik, H.J. and Abraham, B. (1978) Multivariate logistic distributions. Annals of Statistics 1(3), 588-590.</p>
<p>[14] Murphy, K.P. (2001) The Bayes Net Toolbox for MATLAB. Computing science and statistics.</p>
<p>[15] Speed, T.S. and Kiiveri, H.T. (1986) Gaussian Markov distributions over ďŹ nite graphs. Annals of Statistics 14(1), 138-150.</p>
<p>[16] Wolfram Research, Inc. (2008) Mathematica, Version 7.0. Champaign, IL.  9</p>
<br/>
<br/><br/><br/></body>
</html>
