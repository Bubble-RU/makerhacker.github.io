<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>186 nips-2010-Object Bank: A High-Level Image Representation for Scene Classification & Semantic Feature Sparsification</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-186" href="../nips2010/nips-2010-Object_Bank%3A_A_High-Level_Image_Representation_for_Scene_Classification_%26_Semantic_Feature_Sparsification.html">nips2010-186</a> <a title="nips-2010-186-reference" href="#">nips2010-186-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>186 nips-2010-Object Bank: A High-Level Image Representation for Scene Classification & Semantic Feature Sparsification</h1>
<br/><p>Source: <a title="nips-2010-186-pdf" href="http://papers.nips.cc/paper/4008-object-bank-a-high-level-image-representation-for-scene-classification-semantic-feature-sparsification.pdf">pdf</a></p><p>Author: Li-jia Li, Hao Su, Li Fei-fei, Eric P. Xing</p><p>Abstract: Robust low-level image features have been proven to be effective representations for a variety of visual recognition tasks such as object recognition and scene classiﬁcation; but pixels, or even local image patches, carry little semantic meanings. For high level visual tasks, such low-level image representations are potentially not enough. In this paper, we propose a high-level image representation, called the Object Bank, where an image is represented as a scale-invariant response map of a large number of pre-trained generic object detectors, blind to the testing dataset or visual task. Leveraging on the Object Bank representation, superior performances on high level visual recognition tasks can be achieved with simple off-the-shelf classiﬁers such as logistic regression and linear SVM. Sparsity algorithms make our representation more efﬁcient and scalable for large scene datasets, and reveal semantically meaningful feature patterns.</p><br/>
<h2>reference text</h2><p>[1] S. Belongie, J. Malik, and J. Puzicha. Shape matching and object recognition using shape contexts. IEEE PAMI, pages 509–522, 2002.  8  r  he  s as gr  r ca  r ca  e  tre  y sk  g  ap cr  in ild  bu  ys sk  le  r he ot ng i ild bu  ud  n  ai  nt  op  r ca  clo  pe  k  e  c ro  ou m  tre  y sk  scene class. Selected objects correspond to  Knowing the important objects learned by the compres- non-zero β values learned by LRG. sion algorithm, we further investigate the discriminative dimensions within the object level. We use LRG1 to examine the learned weights within an object. In Sec.3, we introduce that each feature dimension in the OB representation is directly related to a speciﬁc scale, geometric location and object identity. Hence, the weights in β OF reﬂects the importance of an object at a certain scale and location. To verify the hypothesis, we examine the importance of objects across scales by summing up the weights of related spatial locations and pyramid resolutions. We show one representative object in a scene and visualize the feature patterns within the object group. As it is shown in Fig.6(Top), LRG1 has achieved joint object/feature sparsiﬁcation by zero-out less relevant scales, thus only the most discriminative scales are retained. To analyze how β OF reﬂects the geometric location, we further project the learned coefﬁcient back to the image space by reversing the OB representation extraction procedure. In Fig.6(Middle), we observe that the regions with high intensities are also the locations where the object frequently appears. For example, cloud usually appears in the upper half of a scene in the beach class.</p>
<p>[2] L. Bourdev and J. Malik. Poselets: Body Part Detectors Trained Using 3D Human Pose Annotations. ICCV, 2009.</p>
<p>[3] G. Csurka, C. Bray, C. Dance, and L. Fan. Visual categorization with bags of keypoints. Workshop on Statistical Learning in Computer Vision, ECCV, 2004.</p>
<p>[4] N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. CVPR, 2005.</p>
<p>[5] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. ImageNet: A Large-Scale Hierarchical Image Database. CVPR, 2009.</p>
<p>[6] L. Fei-Fei, R. Fergus, and P. Perona. One-Shot learning of object categories. TPAMI, 2006.</p>
<p>[7] L. Fei-Fei, R. Fergus, and A. Torralba. Recognizing and learning object categories. Short Course CVPR</p>
<p>[8] A. Farhadi, I. Endres, D. Hoiem and D. Forsyth. Describing objects by their attributes. CVPR, 2009.</p>
<p>[9] P. Felzenszwalb, R. Girshick, D. McAllester, and D. Ramanan. Object Detection with Discriminatively Trained Part Based Models. JAIR, 29, 2007.</p>
<p>[10] W.T. Freeman and E.H. Adelson. The design and use of steerable ﬁlters. IEEE PAMI, 1991.</p>
<p>[11] G. Grifﬁn, A. Holub, and P. Perona. Caltech-256 Object Category Dataset. 2007.</p>
<p>[12] A. Hauptmann, R. Yan, W. Lin, M. Christel, and H. Wactlar. Can high-level concepts ﬁll the semantic gap in video retrieval? a case study with broadcast news. IEEE TMM, 9(5):958, 2007.</p>
<p>[13] D. Hoiem, A.A. Efros, and M. Hebert. Automatic photo pop-up. SIGGRAPH 2005, 24(3):577–584, 2005.</p>
<p>[14] D. Hoiem, A.A. Efros, and M. Hebert. Putting Objects in Perspective. CVPR, 2006.</p>
<p>[15] T. Kadir and M. Brady. Scale, saliency and image description. IJCV, 45(2):83–105, 2001.</p>
<p>[16] N. Kumar, A. C. Berg, P. N. Belhumeur and S. K. Nayar. Attribute and Simile Classiﬁers for Face Veriﬁcation. ICCV, 2009.</p>
<p>[17] C.H. Lampert, H. Nickisch and S. Harmeling. Learning to detect unseen object classes by between-class attribute transfer. CVPR, 2009.</p>
<p>[18] C.H. Lampert, M.B. Blaschko, T. Hofmann, and S. Zurich. Beyond sliding windows: Object localization by efﬁcient subwindow search. CVPR, 2008.</p>
<p>[19] S. Lazebnik, C. Schmid, and J. Ponce. Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories. CVPR, 2006.</p>
<p>[20] H.Lee, R.Grosse, R.Ranganath and A. Y. Ng. Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations. ICML, 2009.</p>
<p>[21] D.Lewis. Naive (Bayes) at Forty: The Independence Assumption in Information Retrieval. ECML, 1998.</p>
<p>[22] L-J. Li and L. Fei-Fei. What, where and who? classifying events by scene and object recognition. ICCV, 2007.</p>
<p>[23] D. Lowe. Object recognition from local scale-invariant features. ICCV, 1999.</p>
<p>[24] K. Mikolajczyk and C. Schmid. An afﬁne invariant interest point detector. ECCV, 2002.</p>
<p>[25] A. Oliva and A. Torralba. Modeling the shape of the scene: a holistic representation of the spatial envelope. IJCV, 42, 2001.</p>
<p>[26] P. Perona and J. Malik. Scale-space and edge detection using anisotropic diffusion. PAMI, 1990.</p>
<p>[27] A. Quattoni and A. Torralba. Recognizing indoor scenes. CVPR, 2009.</p>
<p>[28] A. Rabinovich, A. Vedaldi, C. Galleguillos, E. Wiewiora and S. Belongie. Objects in context. ICCV, 2007.</p>
<p>[29] D. Ramanan C. Desai and C. Fowlkes. Discriminative models for multi-class object layout. ICCV, 2009.</p>
<p>[30] B.C. Russell, A. Torralba, K.P. Murphy, and W.T. Freeman. Labelme: a database and web-based tool for image annotation. MIT AI Lab Memo, 2005.</p>
<p>[31] L. Von Ahn. Games with a purpose. Computer, 39(6):92–94, 2006.</p>
<p>[32] C. Wang, D. Blei, and L. Fei-Fei. Simultaneous image classiﬁcation and annotation. CVPR, 2009.</p>
<p>[33] L. Torresani, M. Szummer, and A. Fitzgibbon. Efﬁcient Object Category Recognition Using Classemes. European Conference of Computer Vision 2010, pages 776–789, 2010.</p>
<p>[34] P.Ravikumar, M.Wainwright, J.Lafferty. High-Dimensional Ising Model Selection Using L1-Regularized Logistic Regression. Annals of Statistics, 2009.</p>
<p>[35] J. Vogel and B. Schiele. Semantic modeling of natural scenes for content-based image retrieval. International Journal of Computer Vision, 2007.</p>
<p>[36] M. Yuan and Y. Lin. Model selection and estimation in regression with grouped variables. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 2006.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
