<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>241 nips-2010-Size Matters: Metric Visual Search Constraints from Monocular Metadata</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-241" href="../nips2010/nips-2010-Size_Matters%3A_Metric_Visual_Search_Constraints_from_Monocular_Metadata.html">nips2010-241</a> <a title="nips-2010-241-reference" href="#">nips2010-241-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>241 nips-2010-Size Matters: Metric Visual Search Constraints from Monocular Metadata</h1>
<br/><p>Source: <a title="nips-2010-241-pdf" href="http://papers.nips.cc/paper/4104-size-matters-metric-visual-search-constraints-from-monocular-metadata.pdf">pdf</a></p><p>Author: Mario Fritz, Kate Saenko, Trevor Darrell</p><p>Abstract: Metric constraints are known to be highly discriminative for many objects, but if training is limited to data captured from a particular 3-D sensor the quantity of training data may be severly limited. In this paper, we show how a crucial aspect of 3-D information–object and feature absolute size–can be added to models learned from commonly available online imagery, without use of any 3-D sensing or reconstruction at training time. Such models can be utilized at test time together with explicit 3-D sensing to perform robust search. Our model uses a “2.1D” local feature, which combines traditional appearance gradient statistics with an estimate of average absolute depth within the local window. We show how category size information can be obtained from online images by exploiting relatively unbiquitous metadata ﬁelds specifying camera intrinstics. We develop an efﬁcient metric branch-and-bound algorithm for our search task, imposing 3-D size constraints as part of an optimal search for a set of features which indicate the presence of a category. Experiments on test scenes captured with a traditional stereo rig are shown, exploiting training data from from purely monocular sources with associated EXIF metadata. 1</p><br/>
<h2>reference text</h2><p>[1] O. Boiman, E. Shechtman, and M. Irani, In defense of Nearest-Neighbor based image classiﬁcation, In Proceedings of Computer Vision and Pattern Recognition, 2008.</p>
<p>[2] C. Wu, B. Clipp, X. Li, J.-M. Frahm, and M. Pollefeys, 3D model matching with ViewpointInvariant Patches (VIP), In Proceedings of Computer Vision and Pattern Recognition, 2008.</p>
<p>[3] P. Scovanner, S. Ali, M. Shah, A 3-dimensional SIFT descriptor and its application to action recognition, In Proceedings of the 15th international conference on Multimedia, 2007.</p>
<p>[4] M. Kortgen, G. J. Park, M. Novotni, R. Klein, 3D Shape Matching with 3D Shape Contexts, In the 7th Central European Seminar on Computer Graphics, 2003.</p>
<p>[5] A. Frome, D. Huber, R. Kolluri, T. Bulow, and J. Malik. Recognizing objects in range data using regional point descriptors, In Proceedings of the 8th European Conference on Computer Vision, 2004.</p>
<p>[6] A. Oliva, and A. Torralba, Building the Gist of a Scene: The Role of Global Image Features in Recognition, In Visual Perception, Progress in Brain Research, vol 155, 2006.</p>
<p>[7] D. Hoiem, A. Efros, M. Hebert, Geometric Context from a Single Image, In Proceedings of the Tenth IEEE International Conference on Computer Vision, 2005.</p>
<p>[8] T. Darrell and K. Wohn, Pyramid based depth from focus, In Proceedings of Computer Vision and Pattern Recognition, 1988.</p>
<p>[9] D. Lowe, Distinctive Image Features from Scale-Invariant Keypoints, International Journal of Computer Vision, 2004.</p>
<p>[10] J. Matas, O. Chum, and M. Urban, and T. Pajdla, Robust wide baseline stereo from maximally stable extremal regions. In British Machine Vision Conference, 2002.</p>
<p>[11] A. Saxena, M. Sun, A. Y. Ng, Make3D: Learning 3-D Scene Structure from a Single Still Image, In IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), 2008.</p>
<p>[12] A. Levin, R. Fergus, F. Durand, Fr´ do, and W.T. Freeman, Image and depth from a convene tional camera with a coded aperture, ACM Transactions on Graphics, 2007.</p>
<p>[13] Bastian Leibe and Ales Leonardis and Bernt Schiele, Combined Object Categorization and Segmentation With An Implicit Shape Model In ECCV workshop on statistical learning in computer vision, 2004</p>
<p>[14] Krystian Mikolajczyk and Cordelia Schmid, A Performance Evaluation of Local Descriptors, In PAMI, 2005.</p>
<p>[15] R. Ewerth, M. Schwalb, Martin, and B. Freisleben, Using depth features to retrieve monocular video shots, In Proceedings of the 6th ACM international conference on image and video retrieval, 2007.</p>
<p>[16] E. Sudderth, A. Torralba, W. T. Freeman, and A. Wilsky, Depth from Familiar Objects: A Hierarchical Model for 3D Scenes, In Proceedings of Computer Vision and Pattern Recognition, 2006.</p>
<p>[17] A. Wedel, U. Franke, J. Klappstein, T. Brox, and D. Cremers, Realtime Depth Estimation and Obstacle Detection from Monocular Video, DAGM-Symposium, 2006.</p>
<p>[18] Junsong Yuan, Zicheng Liu and Ying Wu, Discriminative Subvolume Search for Efﬁcient Action Detection, In Proceedings of Computer Vision and Pattern Recognition, 2009.</p>
<p>[19] Christoph H. Lampert and Matthew B. Blaschko and Thomas Hofmann, Efﬁcient Subwindow Search: A Branch and Bound Framework for Object Localization, In Transactions on Pattern Analysis and Machine Intelligence (PAMI), 2009.</p>
<p>[20] Tom Yeh, John Lee and Trevor Darrell, Fast Concurrent Object Localization and Recognition, In CVPR 2009.</p>
<p>[21] Junsong Yuan and Zicheng Liu and Ying Wu, Discriminative Subvolume Search for Efﬁcient Action Detection, In CVPR 2009.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
