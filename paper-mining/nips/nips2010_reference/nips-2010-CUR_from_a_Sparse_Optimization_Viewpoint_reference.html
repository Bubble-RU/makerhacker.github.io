<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>45 nips-2010-CUR from a Sparse Optimization Viewpoint</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-45" href="../nips2010/nips-2010-CUR_from_a_Sparse_Optimization_Viewpoint.html">nips2010-45</a> <a title="nips-2010-45-reference" href="#">nips2010-45-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>45 nips-2010-CUR from a Sparse Optimization Viewpoint</h1>
<br/><p>Source: <a title="nips-2010-45-pdf" href="http://papers.nips.cc/paper/3890-cur-from-a-sparse-optimization-viewpoint.pdf">pdf</a></p><p>Author: Jacob Bien, Ya Xu, Michael W. Mahoney</p><p>Abstract: The CUR decomposition provides an approximation of a matrix X that has low reconstruction error and that is sparse in the sense that the resulting approximation lies in the span of only a few columns of X. In this regard, it appears to be similar to many sparse PCA methods. However, CUR takes a randomized algorithmic approach, whereas most sparse PCA methods are framed as convex optimization problems. In this paper, we try to understand CUR from a sparse optimization viewpoint. We show that CUR is implicitly optimizing a sparse regression objective and, furthermore, cannot be directly cast as a sparse PCA method. We also observe that the sparsity attained by CUR possesses an interesting structure, which leads us to formulate a sparse PCA method that achieves a CUR-like sparsity.</p><br/>
<h2>reference text</h2><p>[1] M.-A. Belabbas and P.J. Wolfe. Fast low-rank approximation for covariance matrices. In Second IEEE International Workshop on Computational Advances in Multi-Sensor Adaptive Processing, pages 293–296, 2007.</p>
<p>[2] A. d’Aspremont, L. El Ghaoui, M. I. Jordan, and G. R. G. Lanckriet. A direct formulation for sparse PCA using semideﬁnite programming. SIAM Review, 49(3):434–448, 2007.</p>
<p>[3] P. Drineas, R. Kannan, and M.W. Mahoney. Fast Monte Carlo algorithms for matrices III: Computing a compressed approximate matrix decomposition. SIAM Journal on Computing, 36:184–206, 2006.</p>
<p>[4] P. Drineas, M.W. Mahoney, and S. Muthukrishnan. Relative-error CUR matrix decompositions. SIAM Journal on Matrix Analysis and Applications, 30:844–881, 2008.</p>
<p>[5] S.A. Goreinov and E.E. Tyrtyshnikov. The maximum-volume concept in approximation by low-rank matrices. Contemporary Mathematics, 280:47–51, 2001.</p>
<p>[6] T. Hastie, R. Tibshirani, and J. Friedman. Applications of the lasso and grouped lasso to the estimation of sparse graphical models. Manuscript. Submitted. 2010.</p>
<p>[7] T. Hastie, R. Tibshirani, and J. Friedman. The Elements of Statistical Learning. SpringerVerlag, New York, 2003.</p>
<p>[8] D.C. Hoaglin and R.E. Welsch. The hat matrix in regression and ANOVA. The American Statistician, 32(1):17–22, 1978.</p>
<p>[9] R. Jenatton, G. Obozinski, and F. Bach. Structured sparse principal component analysis. Technical report. Preprint: arXiv:0909.1440 (2009).</p>
<p>[10] I. T. Jolliffe, N. T. Trendaﬁlov, and M. Uddin. A modiﬁed principal component technique based on the LASSO. Journal of Computational and Graphical Statistics, 12(3):531–547, 2003.</p>
<p>[11] S. Kumar, M. Mohri, and A. Talwalkar. Ensemble Nystr¨ m method. In Annual Advances in o Neural Information Processing Systems 22: Proceedings of the 2009 Conference, 2009.</p>
<p>[12] M.W. Mahoney and P. Drineas. CUR matrix decompositions for improved data analysis. Proc. Natl. Acad. Sci. USA, 106:697–702, 2009.</p>
<p>[13] T. Nielsen, R.B. West, S.C. Linn, O. Alter, M.A. Knowling, J. O’Connell, S. Zhu, M. Fero, G. Sherlock, J.R. Pollack, P.O. Brown, D. Botstein, and M. van de Rijn. Molecular characterisation of soft tissue tumours: a gene expression study. Lancet, 359(9314):1301–1307, 2002.</p>
<p>[14] P. Paschou, E. Ziv, E.G. Burchard, S. Choudhry, W. Rodriguez-Cintron, M.W. Mahoney, and P. Drineas. PCA-correlated SNPs for structure identiﬁcation in worldwide human populations. PLoS Genetics, 3:1672–1686, 2007.</p>
<p>[15] J. Peng, P. Wang, N. Zhou, and J. Zhu. Partial correlation estimation by joint sparse regression models. Journal of the American Statistical Association, 104:735–746, 2009.</p>
<p>[16] A. Subramanian, P. Tamayo, V. K. Mootha, S. Mukherjee, B. L. Ebert, M. A. Gillette, A. Paulovich, S. L. Pomeroy, T. R. Golub, E. S. Lander, and J. P. Mesirov. Gene set enrichment analysis: A knowledge-based approach for interpreting genome-wide expression proﬁles. Proc. Natl. Acad. Sci. USA, 102(43):15545–15550, 2005.</p>
<p>[17] J. Sun, Y. Xie, H. Zhang, and C. Faloutsos. Less is more: Compact matrix decomposition for large sparse graphs. In Proceedings of the 7th SIAM International Conference on Data Mining, 2007.</p>
<p>[18] R. Tibshirani. Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society: Series B, 58(1):267–288, 1996.</p>
<p>[19] D. M. Witten, R. Tibshirani, and T. Hastie. A penalized matrix decomposition, with applications to sparse principal components and canonical correlation analysis. Biostatistics, 10(3):515–534, 2009.</p>
<p>[20] M. Yuan and Y. Lin. Model selection and estimation in regression with grouped variables. Journal of the Royal Statistical Society: Series B, 68(1):49–67, 2006.</p>
<p>[21] H. Zou, T. Hastie, and R. Tibshirani. Sparse principal component analysis. Journal of Computational and Graphical Statistics, 15(2):262–286, 2006. 9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
