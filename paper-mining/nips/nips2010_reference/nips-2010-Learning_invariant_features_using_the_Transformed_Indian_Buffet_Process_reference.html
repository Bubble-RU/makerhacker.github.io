<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>153 nips-2010-Learning invariant features using the Transformed Indian Buffet Process</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-153" href="../nips2010/nips-2010-Learning_invariant_features_using_the_Transformed_Indian_Buffet_Process.html">nips2010-153</a> <a title="nips-2010-153-reference" href="#">nips2010-153-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>153 nips-2010-Learning invariant features using the Transformed Indian Buffet Process</h1>
<br/><p>Source: <a title="nips-2010-153-pdf" href="http://papers.nips.cc/paper/4049-learning-invariant-features-using-the-transformed-indian-buffet-process.pdf">pdf</a></p><p>Author: Joseph L. Austerweil, Thomas L. Griffiths</p><p>Abstract: Identifying the features of objects becomes a challenge when those features can change in their appearance. We introduce the Transformed Indian Buffet Process (tIBP), and use it to deﬁne a nonparametric Bayesian model that infers features that can transform across instantiations. We show that this model can identify features that are location invariant by modeling a previous experiment on human feature learning. However, allowing features to transform adds new kinds of ambiguity: Are two parts of an object the same feature with different transformations or two unique features? What transformations can features undergo? We present two new experiments in which we explore how people resolve these questions, showing that the tIBP model demonstrates a similar sensitivity to context to that shown by human learners when determining the invariant aspects of features. 1</p><br/>
<h2>reference text</h2><p>[1] S. E. Palmer. Vision Science. MIT Press, Cambridge, MA, 1999.</p>
<p>[2] H. Barlow. Unsupervised learning. Neural Computation, 1:295–311, 1989.</p>
<p>[3] Z. Ghahramani. Factorial learning and the EM algorithm. In Advances in Neural Information Processing Systems, volume 7, pages 617–624, Cambridge, MA, 1995. MIT Press.</p>
<p>[4] T. L. Grifﬁths and Z. Ghahramani. Inﬁnite latent feature models and the Indian buffet process. Technical Report 2005-001, Gatsby Computational Neuroscience Unit, 2005.</p>
<p>[5] J. L. Austerweil and T. L. Grifﬁths. Analyzing human feature learning as nonparametric Bayesian inference. In Daphne Koller, Yoshua Bengio, Dale Schuurmans, and L´ on Bottou, e editors, Advances in Neural Information Processing Systems, volume 21, Cambridge, MA, 2009. MIT Press.</p>
<p>[6] J. Fiser and R. N. Aslin. Unsupervised statistical learning of higher-order spatial structures from visual scenes. Psychological Science, 12(6), 2001.</p>
<p>[7] E. Sudderth, A. Torralba, W. Freeman, and A. Willsky. Describing visual scenes using transformed Dirichlet processes. In Advances in Neural Information Processing Systems 18, Cambridge, MA, 2006. MIT Press.</p>
<p>[8] E. Mach. The analysis of sensations. Open Court, Chicago, 1914/1959.</p>
<p>[9] M. I. Jordan. Bayesian nonparametric learning: Expressive priors for intelligent systems. In Heuristics, Probability and Causality: A Tribute to Judea Pearl. College Publications, 2010.</p>
<p>[10] F. Wood, T. L. Grifﬁths, and Z. Ghahramani. A non-parametric Bayesian method for inferring hidden causes. In Proceeding of the 22nd Conference on Uncertainty in Artiﬁcial Intelligence, 2006.</p>
<p>[11] S. Geman and D. Geman. Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. IEEE Transactions on Pattern Analysis and Machine Intelligence, 6:721–741, 1984.</p>
<p>[12] G. Orban, J. Fiser, R. N. Aslin, and M. Lengyel. Bayesian learning of visual chunks by human observers. Proceedings of the National Academy of Sciences, 105(7):2745–2750, 2008.</p>
<p>[13] J. L. Austerweil and T. L. Grifﬁths. The effect of distributional information on feature learning. In Proceedings of the Thirty-First Annual Conference of the Cognitive Science Society. 2009.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
