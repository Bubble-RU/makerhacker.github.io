<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>48 nips-2010-Collaborative Filtering in a Non-Uniform World: Learning with the Weighted Trace Norm</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-48" href="../nips2010/nips-2010-Collaborative_Filtering_in_a_Non-Uniform_World%3A_Learning_with_the_Weighted_Trace_Norm.html">nips2010-48</a> <a title="nips-2010-48-reference" href="#">nips2010-48-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>48 nips-2010-Collaborative Filtering in a Non-Uniform World: Learning with the Weighted Trace Norm</h1>
<br/><p>Source: <a title="nips-2010-48-pdf" href="http://papers.nips.cc/paper/4102-collaborative-filtering-in-a-non-uniform-world-learning-with-the-weighted-trace-norm.pdf">pdf</a></p><p>Author: Nathan Srebro, Ruslan Salakhutdinov</p><p>Abstract: We show that matrix completion with trace-norm regularization can be signiﬁcantly hurt when entries of the matrix are sampled non-uniformly, but that a properly weighted version of the trace-norm regularizer works well with non-uniform sampling. We show that the weighted trace-norm regularization indeed yields signiﬁcant gains on the highly non-uniformly sampled Netﬂix dataset.</p><br/>
<h2>reference text</h2><p>[1] J. Abernethy, F. Bach, T. Evgeniou, and J.P. Vert. A new approach to collaborative ﬁltering: Operator estimation with spectral regularization. Journal of Machine Learning Research, 10:803–826, 2009.</p>
<p>[2] S. Burer and R.D.C. Monteiro. Local minima and convergence in low-rank semideﬁnite programming. Mathematical Programming, 103(3):427–444, 2005.</p>
<p>[3] J.F. Cai, E.J. Cand` s, and Z. Shen. A Singular Value Thresholding Algorithm for Matrix e Completion. SIAM Journal on Optimization, 20:1956, 2010.</p>
<p>[4] E.J. Candes and Y. Plan. Matrix completion with noise. Proceedings of the IEEE (to appear), 2009.</p>
<p>[5] E.J. Candes and B. Recht. Exact matrix completion via convex optimization. Foundations of Computational Mathematics, 9, 2009.</p>
<p>[6] E.J. Candes and T. Tao. The power of convex relaxation: Near-optimal matrix completion. IEEE Trans. Inform. Theory (to appear), 2009.</p>
<p>[7] M. Fazel, H. Hindi, and S.P. Boyd. A rank minimization heuristic with application to minimum order system approximation. In Proceedings American Control Conference, volume 6, 2001.</p>
<p>[8] Yehuda Koren. Factorization meets the neighborhood: a multifaceted collaborative ﬁltering model. In ACM SIGKDD, pages 426–434, 2008.</p>
<p>[9] Z. Liu and L. Vandenberghe. Interior-point method for nuclear norm approximation with application to system identiﬁcation. SIAM Journal on Matrix Analysis and Applications, 31(3):1235–1256, 2009.</p>
<p>[10] S. Ma, D. Goldfarb, and L. Chen. Fixed point and Bregman iterative methods for matrix rank minimization. Mathematical Programming, pages 1–33, 2009.</p>
<p>[11] R. Mazumder, T. Hastie, and R. Tibshirani. Spectral Regularization Algorithms for Learning Large Incomplete Matrices. Journal of Machine Learning Research, 11:2287–2322, 2010.</p>
<p>[12] R. Meka, P. Jain, and I. S. Dhillon. Matrix completion from power-law distributed samples. In Advances in Neural Information Processing Systems, volume 21, 2009.</p>
<p>[13] B. Recht. A simpler approach to matrix completion. preprint, available from author’s webpage, 2009.</p>
<p>[14] J.D.M. Rennie and N. Srebro. Fast maximum margin matrix factorization for collaborative prediction. In ICML, page 719, 2005.</p>
<p>[15] Ruslan Salakhutdinov and Andriy Mnih. Probabilistic matrix factorization. In Advances in Neural Information Processing Systems, volume 20, 2008.</p>
<p>[16] N. Srebro, N. Alon, and T. Jaakkola. Generalization error bounds for collaborative prediction with low-rank matrices. In Advances In Neural Information Processing Systems 17, 2005.</p>
<p>[17] N. Srebro, J. Rennie, and T. Jaakkola. Maximum margin matrix factorization. In Advances In Neural Information Processing Systems 17, 2005.</p>
<p>[18] N. Srebro and A. Shraibman. Rank, trace-norm and max-norm. In COLT, 2005.</p>
<p>[19] G´ bor Tak´ cs, Istv´ n Pil´ szy, Botty´ n N´ meth, and Domonkos Tikk. Scalable collaborative a a a a a e ﬁltering approaches for large recommender systems. Journal of Machine Learning Research, 10:623–656, 2009.</p>
<p>[20] R. Tomioka, T. Suzuki, M. Sugiyama, and H. Kashima. A fast augmented lagrangian algorithm for learning low-rank matrices. In ICML, pages 1087–1094, 2010.</p>
<p>[21] M. Weimer, A. Karatzoglou, and A. Smola. Improving maximum margin matrix factorization. Machine Learning, 72(3):263–276, 2008.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
