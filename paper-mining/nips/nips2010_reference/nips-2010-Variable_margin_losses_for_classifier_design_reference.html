<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>282 nips-2010-Variable margin losses for classifier design</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-282" href="../nips2010/nips-2010-Variable_margin_losses_for_classifier_design.html">nips2010-282</a> <a title="nips-2010-282-reference" href="#">nips2010-282-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>282 nips-2010-Variable margin losses for classifier design</h1>
<br/><p>Source: <a title="nips-2010-282-pdf" href="http://papers.nips.cc/paper/4024-variable-margin-losses-for-classifier-design.pdf">pdf</a></p><p>Author: Hamed Masnadi-shirazi, Nuno Vasconcelos</p><p>Abstract: The problem of controlling the margin of a classiﬁer is studied. A detailed analytical study is presented on how properties of the classiﬁcation risk, such as its optimal link and minimum risk functions, are related to the shape of the loss, and its margin enforcing properties. It is shown that for a class of risks, denoted canonical risks, asymptotic Bayes consistency is compatible with simple analytical relationships between these functions. These enable a precise characterization of the loss for a popular class of link functions. It is shown that, when the risk is in canonical form and the link is inverse sigmoidal, the margin properties of the loss are determined by a single parameter. Novel families of Bayes consistent loss functions, of variable margin, are derived. These families are then used to design boosting style algorithms with explicit control of the classiﬁcation margin. The new algorithms generalize well established approaches, such as LogitBoost. Experimental results show that the proposed variable margin losses outperform the ﬁxed margin counterparts used by existing algorithms. Finally, it is shown that best performance can be achieved by cross-validating the margin parameter. 1</p><br/>
<h2>reference text</h2><p>[1] V. N. Vapnik, Statistical Learning Theory.  John Wiley Sons Inc, 1998.</p>
<p>[2] J. Friedman, T. Hastie, and R. Tibshirani, “Additive logistic regression: A statistical view of boosting,” Annals of Statistics, 2000.</p>
<p>[3] H. Masnadi-Shirazi and N. Vasconcelos, “On the design of loss functions for classiﬁcation: theory, robustness to outliers, and savageboost,” in NIPS, 2008, pp. 1049–1056.</p>
<p>[4] L. J. Savage, “The elicitation of personal probabilities and expectations,” Journal of the American Statistical Association, vol. 66, pp. 783–801, 1971.</p>
<p>[5] C. Leistner, A. Saffari, P. M. Roth, and H. Bischof, “On robustness of on-line boosting - a competitive study,” in IEEE ICCV Workshop on On-line Computer Vision, 2009.</p>
<p>[6] A. Buja, W. Stuetzle, and Y. Shen, “Loss functions for binary class probability estimation and classiﬁcation: Structure and applications,” 2006.</p>
<p>[7] T. Zhang, “Statistical behavior and consistency of classiﬁcation methods based on convex risk minimization,” Annals of Statistics, 2004.</p>
<p>[8] J. H. Friedman, “Greedy function approximation: A gradient boosting machine,” The Annals of Statistics, vol. 29, no. 5, pp. 1189–1232, 2001.</p>
<p>[9] J. Demˇar, “Statistical comparisons of classiﬁers over multiple data sets,” The Journal of Machine Learning s Research, vol. 7, pp. 1–30, 2006.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
