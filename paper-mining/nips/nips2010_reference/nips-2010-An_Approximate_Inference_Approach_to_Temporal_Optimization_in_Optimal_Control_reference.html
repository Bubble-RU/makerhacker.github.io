<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>29 nips-2010-An Approximate Inference Approach to Temporal Optimization in Optimal Control</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-29" href="../nips2010/nips-2010-An_Approximate_Inference_Approach_to_Temporal_Optimization_in_Optimal_Control.html">nips2010-29</a> <a title="nips-2010-29-reference" href="#">nips2010-29-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>29 nips-2010-An Approximate Inference Approach to Temporal Optimization in Optimal Control</h1>
<br/><p>Source: <a title="nips-2010-29-pdf" href="http://papers.nips.cc/paper/4018-an-approximate-inference-approach-to-temporal-optimization-in-optimal-control.pdf">pdf</a></p><p>Author: Konrad Rawlik, Marc Toussaint, Sethu Vijayakumar</p><p>Abstract: Algorithms based on iterative local approximations present a practical approach to optimal control in robotic systems. However, they generally require the temporal parameters (for e.g. the movement duration or the time point of reaching an intermediate goal) to be speciﬁed a priori. Here, we present a methodology that is capable of jointly optimizing the temporal parameters in addition to the control command proﬁles. The presented approach is based on a Bayesian canonical time formulation of the optimal control problem, with the temporal mapping from canonical to real time parametrised by an additional control variable. An approximate EM algorithm is derived that efﬁciently optimizes both the movement duration and control commands offering, for the ﬁrst time, a practical approach to tackling generic via point problems in a systematic way under the optimal control framework. The proposed approach, which is applicable to plants with non-linear dynamics as well as arbitrary state dependent and quadratic control costs, is evaluated on realistic simulations of a redundant robotic plant.</p><br/>
<h2>reference text</h2><p>[1] David Barber and Tom Furmston. Solving deterministic policy (PO)MDPs using expectationmaximisation and antifreeze. In European Conference on Machine Learning (LEMIR workshop), 2009.</p>
<p>[2] Marc Peter Deisenroth, Carl Edward Rasmussen, and Jan Peters. Gaussian process dynamic programming. Neurocomputing, 72(7-9):1508 – 1524, 2009.</p>
<p>[3] Yu-Yi Fu, Chia-Ju Wu, Kuo-Lan Su, and Chia-Nan Ko. A time-scaling method for near-timeoptimal control of an omni-directional robot along speciﬁed paths. Artiﬁcial Life and Robotics, 13(1):350–354, 2008.</p>
<p>[4] Z Ghahramani and G Hinton. Parameter estimation for linear dynamical systems. Technical Report CRG-TR-96-2, University of Toronto, 1996.</p>
<p>[5] Z Ghahramani and S Roweis. Learning nonlinear dynamical systems using an em algorithm. In Advances in Neural Information Processing Systems, volume 11, Nov 1999.</p>
<p>[6] D Jacobson and D Mayne. Differential Dynamic Programming. Elsevier, 1970.</p>
<p>[7] Hilbert J. Kappen. A linear theory for control of non-linear stochastic systems. Physical Review Letters, 95(20):200201, 2005.</p>
<p>[8] Donald E. Kirk. Optimal Control Theory - An Introduction. Prentice-Hall, 1970.</p>
<p>[9] Weiwei Li and Emanuel Todorov. An iterative optimal control and estimation design for nonlinear stochastic system. In Proc. of the 45th IEEE Conference on Decision and Control, 2006.</p>
<p>[10] Djordje Mitrovic, Sho Nagashima, Stefan Klanke, Takamitsu Matsubara, and Sethu Vijayakumar. Optimal feedback control for anthropomorphic manipulators. In Proc. IEEE International Conference on Robotics and Automation (ICRA 2010), 2010.</p>
<p>[11] Peter Pastor, Heiko Hoffmann, Tamim Asfour, and Stefan Schaal. Learning and generalization of motor skills by learning from demonstration. In Proc. IEEE International Conference on Robotics and Automation (ICRA 2010), Feb 2010.</p>
<p>[12] Gideon Sahar and John M. Hollerbach. Planning of minimum- time trajectories for robot arms. The International Journal of Robotics Research, 5(3):90–100, 1986.</p>
<p>[13] Robert F. Stengel. Optimal Control and Estimation. Dover Publications, 1986.</p>
<p>[14] Emanuel Todorov. Compositionality of optimal control laws. In Advances in Neural Information Processing Systems, volume 22, 2009.</p>
<p>[15] Emanuel Todorov and Michael Jordan. Optimal feedback control as a theory of motor coordination. Nature Neuroscience, 5(11):1226–1235, 2002.</p>
<p>[16] Marc Toussaint. Robot trajectory optimization using approximate inference. In Proc. of the 26 th International Conference on Machine Learning (ICML 2009), 2009.</p>
<p>[17] Marc Toussaint and Amos Storkey. Probabilistic inference for solving discrete and continuous state Markov Decision Processes. In Proc. of the 23nd Int. Conf. on Machine Learning (ICML 2006), pages 945–952, 2006.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
