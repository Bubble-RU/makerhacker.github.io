<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>141 nips-2010-Layered image motion with explicit occlusions, temporal consistency, and depth ordering</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-141" href="../nips2010/nips-2010-Layered_image_motion_with_explicit_occlusions%2C_temporal_consistency%2C_and_depth_ordering.html">nips2010-141</a> <a title="nips-2010-141-reference" href="#">nips2010-141-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>141 nips-2010-Layered image motion with explicit occlusions, temporal consistency, and depth ordering</h1>
<br/><p>Source: <a title="nips-2010-141-pdf" href="http://papers.nips.cc/paper/4030-layered-image-motion-with-explicit-occlusions-temporal-consistency-and-depth-ordering.pdf">pdf</a></p><p>Author: Deqing Sun, Erik B. Sudderth, Michael J. Black</p><p>Abstract: Layered models are a powerful way of describing natural scenes containing smooth surfaces that may overlap and occlude each other. For image motion estimation, such models have a long history but have not achieved the wide use or accuracy of non-layered methods. We present a new probabilistic model of optical ﬂow in layers that addresses many of the shortcomings of previous approaches. In particular, we deﬁne a probabilistic graphical model that explicitly captures: 1) occlusions and disocclusions; 2) depth ordering of the layers; 3) temporal consistency of the layer segmentation. Additionally the optical ﬂow in each layer is modeled by a combination of a parametric model and a smooth deviation based on an MRF with a robust spatial prior; the resulting model allows roughness in layers. Finally, a key contribution is the formulation of the layers using an imagedependent hidden ﬁeld prior based on recent models for static scene segmentation. The method achieves state-of-the-art results on the Middlebury benchmark and produces meaningful scene segmentations as well as detected occlusion regions.</p><br/>
<h2>reference text</h2><p>[1] S. Ayer and H. S. Sawhney. Layered representation of motion video using robust maximum-likelihood estimation of mixture models and MDL encoding. In ICCV, pages 777–784, Jun 1995.</p>
<p>[2] S. Baker, D. Scharstein, J. P. Lewis, S. Roth, M. J. Black, and R. Szeliski. A database and evaluation methodology for optical ﬂow. IJCV, to appear.</p>
<p>[3] S. Birchﬁeld and C. Tomasi. Multiway cut for stereo and motion with slanted surfaces. In ICCV, pages 489–495, 1999.</p>
<p>[4] M. J. Black and P. Anandan. Robust dynamic motion estimation over time. In CVPR, pages 296–302, 1991.</p>
<p>[5] M. J. Black and P. Anandan. The robust estimation of multiple motions: Parametric and piecewise-smooth ﬂow ﬁelds. CVIU, 63:75–104, 1996.</p>
<p>[6] M. J. Black and A. D. Jepson. Estimating optical-ﬂow in segmented images using variable-order parametric models with local deformations. PAMI, 18(10):972–986, October 1996.</p>
<p>[7] T. Darrell and A. Pentland. Robust estimation of a multi-layered motion representation. In Workshop on Visual Motion, pages 173–178, 1991.</p>
<p>[8] T. Darrell and A. Pentland. Cooperative robust estimation using layers of support. PAMI, 17(5):474–487, 1995.</p>
<p>[9] B. Glocker, T. H. Heibel, N. Navab, P. Kohli, and C. Rother. Triangleﬂow: Optical ﬂow with triangulationbased higher-order likelihoods. In ECCV, pages 272–285, 2010.</p>
<p>[10] M. Irani, P. Anandan, and D. Weinshall. From reference frames to reference planes: Multi-view parallax geometry and applications. In ECCV, 1998.</p>
<p>[11] A. Jepson and M. J. Black. Mixture models for optical ﬂow computation. In CVPR, 1993.</p>
<p>[12] N. Jojic and B. Frey. Learning ﬂexible sprites in video layers. In CVPR, pages I:199–206, 2001.</p>
<p>[13] A. Kannan, B. Frey, and N. Jojic. A generative model of dense optical ﬂow in layers. Technical Report TR PSI-2001-11, University of Toronto, Aug. 2001.</p>
<p>[14] R. Kumar, P. Anandan, and K. Hanna. Shape recovery from multiple views: A parallax based approach. In Proc 12th ICPR, 1994.</p>
<p>[15] R. D. Morris, X. Descombes, and J. Zerubia. The Ising/Potts model is not well suited to segmentation tasks. In Proceedings of the IEEE Digital Signal Processing Workshop, 1996.</p>
<p>[16] M. Nicolescu and G. Medioni. Motion segmentation with accurate boundaries - a tensor voting approach. In CVPR, pages 382–389, 2003.</p>
<p>[17] M. P. Kumar, P. H. Torr, and A. Zisserman. Learning layered motion segmentations of video. IJCV, 76(3):301–319, 2008.</p>
<p>[18] S. Roth and M. J. Black. On the spatial statistics of optical ﬂow. IJCV, 74(1):33–50, August 2007.</p>
<p>[19] H. S. Sawhney. 3D geometry from planar parallax. In CVPR, pages 929–934, 1994.</p>
<p>[20] T. Schoenemann and D. Cremers. High resolution motion layer decomposition using dual-space graph cuts. In CVPR, pages 1–7, June 2008.</p>
<p>[21] E. Sudderth and M. Jordan. Shared segmentation of natural scenes using dependent Pitman-Yor processes. In NIPS, pages 1585–1592, 2009.</p>
<p>[22] D. Sun, S. Roth, and M. J. Black. Secrets of optical ﬂow estimation and their principles. In CVPR, 2010.</p>
<p>[23] D. Sun, S. Roth, J. P. Lewis, and M. J. Black. Learning optical ﬂow. In ECCV, pages 83–97, 2008.</p>
<p>[24] P. Torr, R. Szeliski, and P. Anandan. An integrated Bayesian approach to layer extraction from image sequences. PAMI, 23(3):297–303, Mar 2001.</p>
<p>[25] J. Y. A. Wang and E. H. Adelson. Representing moving images with layers. IEEE Transactions on Image Processing, 3(5):625–638, Sept. 1994.</p>
<p>[26] Y. Weiss. Smoothness in layers: Motion segmentation using nonparametric mixture estimation. In CVPR, pages 520–526, Jun 1997.</p>
<p>[27] Y. Weiss and E. Adelson. A uniﬁed mixture framework for motion segmentation: Incorporating spatial coherence and estimating the number of models. In CVPR, pages 321–326, Jun 1996.</p>
<p>[28] M. Werlberger, T. Pock, and H. Bischof. Motion estimation with non-local total variation regularization. In CVPR, 2010.</p>
<p>[29] H. Yalcin, M. J. Black, and R. Fablet. The dense estimation of motion and appearance in layers. In IEEE Workshop on Image and Video Registration, pages 777–784, Jun 2004.</p>
<p>[30] Y. Zhou and H. Tao. Background layer model for object tracking through occlusion. In ICCV, volume 2, pages 1079–1085, 2003.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
