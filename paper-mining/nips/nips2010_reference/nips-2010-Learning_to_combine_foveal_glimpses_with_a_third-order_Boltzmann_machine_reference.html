<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>156 nips-2010-Learning to combine foveal glimpses with a third-order Boltzmann machine</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-156" href="../nips2010/nips-2010-Learning_to_combine_foveal_glimpses_with_a_third-order_Boltzmann_machine.html">nips2010-156</a> <a title="nips-2010-156-reference" href="#">nips2010-156-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>156 nips-2010-Learning to combine foveal glimpses with a third-order Boltzmann machine</h1>
<br/><p>Source: <a title="nips-2010-156-pdf" href="http://papers.nips.cc/paper/4089-learning-to-combine-foveal-glimpses-with-a-third-order-boltzmann-machine.pdf">pdf</a></p><p>Author: Hugo Larochelle, Geoffrey E. Hinton</p><p>Abstract: We describe a model based on a Boltzmann machine with third-order connections that can learn how to accumulate information about a shape over several ﬁxations. The model uses a retina that only has enough high resolution pixels to cover a small area of the image, so it must decide on a sequence of ﬁxations and it must combine the “glimpse” at each ﬁxation with the location of the ﬁxation before integrating the information with information from other glimpses of the same object. We evaluate this model on a synthetic dataset and two image classiﬁcation datasets, showing that it can perform at least as well as a model trained on whole images. 1</p><br/>
<h2>reference text</h2><p>[1] Hermann von Helmholtz. Treatise on physiological optics. Dover Publications, New York, 1962. z(i, j) were initialized in a topographic manner (i.e. each component of z(i, j) is 0 only in a small region of the image). Finally, to avoid overﬁtting, exponentially decaying averages of the parameters of the model were maintained throughout training and were used as the values of the model at test time. 8 This simpliﬁcation of the retinal transformation makes it more convenient to estimate the percentage of high-resolution pixels used by the multi-ﬁxation RBM and contrast it with the SVM trained on the full image.  8</p>
<p>[2] Arash Fazl, Stephen Grossberg, and Ennio Mingolla. View-invariant object category learning, recognition, and search: how spatial and object attention are coordinated using surface-based attentional shrouds. Cogn Psychol, 58(1):1–48, 2009.</p>
<p>[3] Roland Memisevic and Geoffrey E. Hinton. Unsupervised learning of image transformations. In In Computer Vision and Pattern Recognition. IEEE Computer Society, 2007.</p>
<p>[4] Urs K¨ ster and Aapo Hyv¨ rinen. A two-layer ica-like model estimated by score matching. In ICANN’07: o a Proceedings of the 17th international conference on Artiﬁcial neural networks, pages 798–807, Berlin, Heidelberg, 2007. Springer-Verlag.</p>
<p>[5] Geoffrey E. Hinton. Learning to represent visual input. Phil. Trans. R. Soc., 365(1537):177–84, 2010.</p>
<p>[6] Roland Memisevic and Geoffrey E. Hinton. Learning to represent spatial transformations with factored higher-order boltzmann machines. Neural Computation, 22:1473–1492, 2010.</p>
<p>[7] Geoffrey E. Hinton and Ruslan Salakhutdinov. Reducing the dimensionality of data with neural networks. Science, 313(5786):504–507, July 2006.</p>
<p>[8] Graham W. Taylor and Geoffrey E. Hinton. Factored conditional restricted boltzmann machines for modeling motion style. In ICML ’09: Proceedings of the 26th Annual International Conference on Machine Learning, pages 1025–1032, New York, NY, USA, 2009. ACM.</p>
<p>[9] Hugo Larochelle and Yoshua Bengio. Classiﬁcation using discriminative restricted boltzmann machines. In ICML ’08: Proceedings of the 25th international conference on Machine learning, pages 536–543, New York, NY, USA, 2008. ACM.</p>
<p>[10] Geoffrey E. Hinton. Training products of experts by minimizing contrastive divergence. Neural Computation, 14:1771–1800, 2002.</p>
<p>[11] Rajesh P.N. Rao, Gregory J. Zelinsky, Mary M. Hayhoe, and Dana H. Ballard. Modeling saccadic targeting in visual search. In David S. Touretzky, Michael Mozer, and Michael E. Hasselmo, editors, Advances in Neural Information Processing Systems 8, pages 830–836. MIT Press, 1996.</p>
<p>[12] Laura Walker Renninger, James M. Coughlan, Preeti Verghese, and Jitendra Malik. An information maximization model of eye movements. In Lawrence K. Saul, Yair Weiss, and L´ on Bottou, editors, e Advances in Neural Information Processing Systems 17, pages 1121–1128. MIT Press, Cambridge, MA, 2005.</p>
<p>[13] Wei Zhang, Hyejin Yang, Dimitris Samaras, and Gregory Zelinsky. A computational model of eye movements during object class detection. In Y. Weiss, B. Sch¨ lkopf, and J. Platt, editors, Advances in Neural o Information Processing Systems 18, pages 1609–1616. MIT Press, Cambridge, MA, 2006.</p>
<p>[14] Antonio Torralba, Monica S. Castelhano, Aude Oliva, and John M. Henderson. Contextual guidance of eye movements and attention in real-world scenes: the role of global features in object search. Psychological Review, 113:2006, 2006.</p>
<p>[15] Laurent Itti, Christof Koch, and Ernst Niebur. A model of saliency-based visual attention for rapid scene analysis. IEEE Trans. Pattern Anal. Mach. Intell., 20(11):1254–1259, 1998.</p>
<p>[16] Laurent Itti and Christof Koch. Computational modelling of visual attention. Nature Reviews Neuroscience, 2(3):194–203, 2001.</p>
<p>[17] Lucas Paletta, Gerald Fritz, and Christin Seifert. Q-learning of sequential attention for visual object recognition from informative local descriptors. In ICML ’05: Proceedings of the 22nd international conference on Machine learning, pages 649–656, New York, NY, USA, 2005. ACM.</p>
<p>[18] Ethem Alpaydin. Selective attention for handwritten digit recognition. In David S. Touretzky, Michael Mozer, and Michael E. Hasselmo, editors, Advances in Neural Information Processing Systems 8, pages 771–777. MIT Press, 1996.</p>
<p>[19] Christopher Kanan and Garrison Cottrell. Robust classiﬁcation of objects, faces, and ﬂowers using natural image statistics. In CVPR, 2010.</p>
<p>[20] Stephen Gould, Joakim Arfvidsson, Adrian Kaehler, Benjamin Sapp, Marius Messner, Gary Bradski, Paul Baumstarck, Sukwon Chung, and Andrew Y. Ng. Peripheral-foveal vision for real-time object recognition and tracking in video. In In International Joint Conference on Artiﬁcial Intelligence (IJCAI, 2007.</p>
<p>[21] Hugo Larochelle, Dumitru Erhan, Aaron Courville, James Bergstra, and Yoshua Bengio. An empirical evaluation of deep architectures on problems with many factors of variation. In ICML ’07: Proceedings of the 24th international conference on Machine learning, pages 473–480, New York, NY, USA, 2007. ACM.</p>
<p>[22] Hugo Larochelle, Yoshua Bengio, Jerome Louradour, and Pascal Lamblin. Exploring strategies for training deep neural networks. Journal of Machine Learning Research, 10:1–40, 2009.</p>
<p>[23] Josh M. Susskind, Adam K. Anderson, and Geoffrey E. Hinton. The toronto face database. Technical Report UTML TR 2010-001, Dept. of Computer Science, University of Toronto, 2010.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
