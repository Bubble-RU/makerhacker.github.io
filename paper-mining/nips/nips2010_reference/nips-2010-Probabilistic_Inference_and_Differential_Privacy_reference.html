<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>216 nips-2010-Probabilistic Inference and Differential Privacy</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-216" href="../nips2010/nips-2010-Probabilistic_Inference_and_Differential_Privacy.html">nips2010-216</a> <a title="nips-2010-216-reference" href="#">nips2010-216-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>216 nips-2010-Probabilistic Inference and Differential Privacy</h1>
<br/><p>Source: <a title="nips-2010-216-pdf" href="http://papers.nips.cc/paper/3897-probabilistic-inference-and-differential-privacy.pdf">pdf</a></p><p>Author: Oliver Williams, Frank Mcsherry</p><p>Abstract: We identify and investigate a strong connection between probabilistic inference and differential privacy, the latter being a recent privacy deﬁnition that permits only indirect observation of data through noisy measurement. Previous research on differential privacy has focused on designing measurement processes whose output is likely to be useful on its own. We consider the potential of applying probabilistic inference to the measurements and measurement process to derive posterior distributions over the data sets and model parameters thereof. We ﬁnd that probabilistic inference can improve accuracy, integrate multiple observations, measure uncertainty, and even provide posterior distributions over quantities that were not directly measured. 1</p><br/>
<h2>reference text</h2><p>[1] A. Smith. Efﬁcient, differentially private point estimators. 2008. arXiv:0809.4794.</p>
<p>[2] A. Slavkovic and D. Vu. Differential privacy for clinical trial data: Preliminary evaluations. In Proceedings of the International workshop on Privacy Aspects of Data Mining, PADM09, 2009.</p>
<p>[3] L. Wasserman and S. Zhou. A statistical framework for differential privacy. Journal of the American Statistical Association, 105(489):375–389, 2010.</p>
<p>[4] C. Dwork and J. Lei. Differential privacy and robust statistics. In STOC, 2009.</p>
<p>[5] K. Chaudhuri and C. Monteleoni. Privacy-preserving logistic regression. In NIPS, pages 289– 296, 2008.</p>
<p>[6] K. Chaudhuri, C. Monteleoni, and A.D. Sarwate. Differentially private empirical risk minimization. 2010.</p>
<p>[7] C. Dwork, F. McSherry, K. Nissim, and A. Smith. Calibrating noise to sensitivity in private data analysis. In TCC, pages 265–284, 2006.</p>
<p>[8] F. McSherry and K. Talwar. Differential privacy via mechanism design. In FOCS, 2007.</p>
<p>[9] M.I. Jordan, Z. Ghahramani, T. Jaakkola, and L.K. Saul. An introduction to variational methods for graphical models. Machine Learning, 37(2):183–233, 1999.</p>
<p>[10] F. McSherry. Privacy integrated queries. In ACM SIGMOD, 2009.</p>
<p>[11] A. Asuncion and D.J. Newman. UCI machine learning repository, 2007.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
