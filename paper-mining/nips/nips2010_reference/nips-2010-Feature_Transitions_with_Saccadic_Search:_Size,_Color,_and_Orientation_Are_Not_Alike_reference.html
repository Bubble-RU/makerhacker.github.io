<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>95 nips-2010-Feature Transitions with Saccadic Search: Size, Color, and Orientation Are Not Alike</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-95" href="../nips2010/nips-2010-Feature_Transitions_with_Saccadic_Search%3A_Size%2C_Color%2C_and_Orientation_Are_Not_Alike.html">nips2010-95</a> <a title="nips-2010-95-reference" href="#">nips2010-95-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>95 nips-2010-Feature Transitions with Saccadic Search: Size, Color, and Orientation Are Not Alike</h1>
<br/><p>Source: <a title="nips-2010-95-pdf" href="http://papers.nips.cc/paper/4112-feature-transitions-with-saccadic-search-size-color-and-orientation-are-not-alike.pdf">pdf</a></p><p>Author: Stella X. Yu</p><p>Abstract: Size, color, and orientation have long been considered elementary features whose attributes are extracted in parallel and available to guide the deployment of attention. If each is processed in the same fashion with simply a different set of local detectors, one would expect similar search behaviours on localizing an equivalent ﬂickering change among identically laid out disks. We analyze feature transitions associated with saccadic search and ﬁnd out that size, color, and orientation are not alike in dynamic attribute processing over time. The Markovian feature transition is attractive for size, repulsive for color, and largely reversible for orientation. 1</p><br/>
<h2>reference text</h2><p>[1] G. Fuggetta, S. Lanfranchi, and G. Campana. Attention has memory: priming for the size of the attentional focus. Spatial Vision, 22(2):147–59, 2009.</p>
<p>[2] J. Grimes. On the failure ot detect changes in scenes across saccades. 2, 1996.</p>
<p>[3] L. Itti and C. Koch. Computational modelling of visual attention. Nature Neuroscience, pages 194–203, 2001.</p>
<p>[4] D. G. Lowe. Distinctive image features from scale-invariant keypoints. 2003.</p>
<p>[5] J. Malik, S. Belongie, T. Leung, and J. Shi. Contour and texture analysis for image segmentation. International Journal of Computer Vision, 2001.</p>
<p>[6] J. H. R. Maunsell and W. T. Newsome. Visual processing in monkey extrastriate cortex. Annual Review of Neuroscience, 10:363–401, 1987.</p>
<p>[7] D. G. Pelli, M. Palomares, and N. J. Majaj. Crowding is unlike ordinary masking: distinguishing feature integration from detection. Journal of Vision, 4(12):1136–69, 2004.</p>
<p>[8] R. Rensink. Visual search for change: A probe into the nature of attentional processing. Visual Cognition, 7:345–76, 2000.</p>
<p>[9] R. A. Rensink, J. K. O’Regan, and J. J. Clark. Image ﬂicker is as good as saccades in making large scene changes invisible. 24, pages 26–8, 1995.</p>
<p>[10] M. Riesenhuber and T. Poggio. Hierarchical models of object recognition in cortex. Nature Neuroscience, 2(11):1019–25, 1999.</p>
<p>[11] T. Serre, A. Oliva, and T. Poggio. A feedforward architecture accounts for rapid categorization. Proceedings of National Academy of Sciences, 104(15):6424–9, 2007.</p>
<p>[12] A. Torralba. Contextual inﬂuences on saliency. In L. Itti, G. Rees, and J. Tsotsos, editors, Neurobiology of Attention, pages 586–93. Academic Press, 2004.</p>
<p>[13] A. Treisman. The perception of features and objects. In R. D. Wright, editor, Visual Attention. Oxford University Press, 1998.</p>
<p>[14] A. Treisman and G. Gelade. A feature-integration theory of atttention. Cognitive Psychology, 12(1):97–136, 1980.</p>
<p>[15] R. van den Berg, J. B. T. M. Roerdink, and F. W. Cornelissen. On the generality of crowding: visual crowding in size, saturation, and hue compared to orientation. Journal of Vision, 7(2):1– 11, 2007.</p>
<p>[16] J. M. Wolfe. Asymmetries in visual search: an introduction. Perception and Psychophysics, 63:381–9, 2001.</p>
<p>[17] J. M. Wolfe and T. S. Horowitz. What attributes guide the deployment of visual attention and how do they do it? Nature Neuroscience, 5, 2004.</p>
<p>[18] J. M. Wolfe, A. Reinecke, and P. Brawn. Why don’t we see changes? the role of attentional bottlenecks and limited visual memory. Visual Cognition, 19(4-8):749–80, 2006.</p>
<p>[19] Y. Yeshurun and M. Carrasco. The effects of transient attention on spatial resolution and the size of the attentional cue. Perception and Psychophysics, 70(1):104–13, 2008.</p>
<p>[20] H. Zhang, A. C. Berg, M. Maire, and J. Malik. SVM-KNN: Discriminative nearest neighbor classiﬁcation for visual category recognition. In IEEE Conference on Computer Vision and Pattern Recognition, pages 2126–36, 2006.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
