<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>266 nips-2010-The Maximal Causes of Natural Scenes are Edge Filters</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-266" href="../nips2010/nips-2010-The_Maximal_Causes_of_Natural_Scenes_are_Edge_Filters.html">nips2010-266</a> <a title="nips-2010-266-reference" href="#">nips2010-266-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>266 nips-2010-The Maximal Causes of Natural Scenes are Edge Filters</h1>
<br/><p>Source: <a title="nips-2010-266-pdf" href="http://papers.nips.cc/paper/4132-the-maximal-causes-of-natural-scenes-are-edge-filters.pdf">pdf</a></p><p>Author: Jose Puertas, Joerg Bornschein, Joerg Luecke</p><p>Abstract: We study the application of a strongly non-linear generative model to image patches. As in standard approaches such as Sparse Coding or Independent Component Analysis, the model assumes a sparse prior with independent hidden variables. However, in the place where standard approaches use the sum to combine basis functions we use the maximum. To derive tractable approximations for parameter estimation we apply a novel approach based on variational Expectation Maximization. The derived learning algorithm can be applied to large-scale problems with hundreds of observed and hidden variables. Furthermore, we can infer all model parameters including observation noise and the degree of sparseness. In applications to image patches we ﬁnd that Gabor-like basis functions are obtained. Gabor-like functions are thus not a feature exclusive to approaches assuming linear superposition. Quantitatively, the inferred basis functions show a large diversity of shapes with many strongly elongated and many circular symmetric functions. The distribution of basis function shapes reﬂects properties of simple cell receptive ﬁelds that are not reproduced by standard linear approaches. In the study of natural image statistics, the implications of using different superposition assumptions have so far not been investigated systematically because models with strong non-linearities have been found analytically and computationally challenging. The presented algorithm represents the ﬁrst large-scale application of such an approach. 1</p><br/>
<h2>reference text</h2><p>[1] B. A. Olshausen, D. J. Field. Emergence of simple-cell receptive ﬁeld properties by learning a sparse code for natural images. Nature, 381:607 – 609, 1996.</p>
<p>[2] P. Comon. Independent component analysis, a new concept? Signal Proc, 36(3):287–314, 1994.</p>
<p>[3] A. J. Bell, T. J. Sejnowski. The “independent components” of natural scenes are edge ﬁlters. Vision Research, 37(23):3327 – 38, 1997.</p>
<p>[4] A. Hyv¨ rinen, E. Oja. A fast ﬁxed-point algorithm for independent component analysis. Neural Compua tation, 9(7):1483–1492, 1997.</p>
<p>[5] H. Lee, A. Battle, R. Raina, A. Ng. Efﬁcient sparse coding algorithms. NIPS 22, 801–808, 2007.</p>
<p>[6] M. W. Seeger. Bayesian Inference and Optimal Design for the Sparse Linear Model. Journal of Machine Learning Research, 759–813, 2008.</p>
<p>[7] P. Dayan, L. F. Abbott. Theoretical Neuroscience. MIT Press, Cambridge, 2001.</p>
<p>[8] P. Berkes, R. Turner, M. Sahani. On sparsity and overcompleteness in image models. NIPS 20, 2008.</p>
<p>[9] B. A. Olshausen, K. J. Millman. Learning sparse codes with a mixture-of-Gaussians prior. NIPS 12, 841–847, 2000.</p>
<p>[10] M. Rehn, F. T. Sommer. A network that uses few active neurones to code visual input predicts the diverse shapes of cortical receptive ﬁelds. J Comp Neurosci, 22(2):135–146, 2007.</p>
<p>[11] A. Hyv¨ rinen, P. Hoyer. Emergence of phase-and shift-invariant features by decomposition of natural a images into independent feature subspaces. Neural Computation, 12(7):1705–1720, 2000.</p>
<p>[12] F. Sinz, E. P. Simoncelli, M. Bethge. Hierarchical modeling of local image features through Lp-nested symmetric distributions. NIPS 22, 1696–1704, 2009.</p>
<p>[13] D. Zoran, Y. Weiss. The ”Tree-Dependent Components” of Natural Images are Edge Filters. NIPS 22, 2340–2348, 2009.</p>
<p>[14] B. S. Everitt. An Introduction to Latent Variable Models. Chapman and Hall, 1984.</p>
<p>[15] D. D. Lee, H. S. Seung. Learning the parts of objects by non-negative matrix factorization. Nature, 401(6755):788–91, 1999.</p>
<p>[16] P. Dayan, R. S. Zemel. Competition and multiple cause models. Neural Computation, 7:565-579, 1995.</p>
<p>[17] E. Saund. A multiple cause mixture model for unsupervised learning. Neural Computation, 7:51-71, 1995.</p>
<p>[18] H. Lappalainen, X. Giannakopoulos, A. Honkela, J. Karhunen. Nonlinear independent component analysis using ensemble learning: Experiments and discussion. Proc. ICA, 2000.</p>
<p>[19] J. L¨ cke, M. Sahani. Maximal causes for non-linear component extraction. Journal of Machine Learning u Research, 9:1227 – 1267, 2008.</p>
<p>[20] N. Jojic, B. Frey. Learning ﬂexible sprites in video layers. CVPR, 199–206, 2001.</p>
<p>[21] N. Le Roux, N. Heess, J. Shotton, J. Winn. Learning a generative model of images by factoring appearance and shape. Technical Report, Microsoft Research, 2010.</p>
<p>[22] R. Neal, G. Hinton. A view of the EM algorithm that justiﬁes incremental, sparse, and other variants. M. I. Jordan, editor, Learning in Graphical Models. Kluwer, 1998.</p>
<p>[23] J. L¨ cke, R. Turner, M. Sahani, M. Henniges. Occlusive Components Analysis. NIPS, 1069-1077, 2009. u</p>
<p>[24] P. O. Hoyer. Non-negative matrix factorization with sparseness constraints. Journal of Machine Learning Research, 5:1457–1469, 2004.</p>
<p>[25] J. P. Jones, L. A. Palmer. An evaluation of the two-dimensional gabor ﬁlter model of simple receptive ﬁelds in cat striate cortex. Journal of Neurophysiology, 58(6):1233 – 1258, 1987.</p>
<p>[26] P. Berkes, B.L. White, J. Fiser. No evidence for active sparsiﬁcation in the visual cortex. NIPS 22, 2009.</p>
<p>[27] J. L¨ cke. Receptive ﬁeld self-organization in a model of the ﬁne-structure in V1 cortical columns. Neural u Computation, 21(10):2805–2845, 2009.</p>
<p>[28] J. H. van Hateren, A. van der Schaaf. Independent component ﬁlters of natural images compared with simple cells in primary visual cortex. Proc Roy Soc London B, 265:359 – 366, 1998.</p>
<p>[29] D. C. Somers, S. B. Nelson, M. Sur. An emergent model of orientation selectivity in cat visual cortical simple cells. The Journal of Neuroscience, 15:5448 – 5465, 1995.</p>
<p>[30] J. L¨ cke. Learning of representations in a canonical model of cortical columns. Cosyne 2006, 100, 2006. u</p>
<p>[31] S. Osindero, M. Welling, G. E. Hinton. Topographic product models applied to natural scene statistics. Neural Computation, 18:381 – 414, 2006.</p>
<p>[32] D. Arathorn, B. Olshausen, J. DiCarlo. Functional requirements of a visual theory. Workshop Cosyne. www.cosyne.org/c/index.php?title=Functional requirements of a visual theory, 2007.</p>
<p>[33] D. L. Ringach. Spatial structure and symmetry of simple-cell receptive ﬁelds in macaque primary visual cortex. Journal of Neurophysiology, 88:455 – 463, 2002. Data retrieved 2006 from manuelita.psych.ucla.edu/∼dario.</p>
<p>[34] B. A. Olshausen, D. J. Field. Sparse coding with an overcomplete basis set: A strategy employed by V1? Vision Research, 37(23):3311–3325, 1997.</p>
<p>[35] S. Den´ ve, T. Lochmann, U. Ernst. Spike based inference in a network with divisive inhibition. Neurale Comp, Marseille, 2008.  9</p>
<br/>
<br/><br/><br/></body>
</html>
