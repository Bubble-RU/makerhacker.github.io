<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>6 nips-2010-A Discriminative Latent Model of Image Region and Object Tag Correspondence</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-6" href="../nips2010/nips-2010-A_Discriminative_Latent_Model_of_Image_Region_and_Object_Tag_Correspondence.html">nips2010-6</a> <a title="nips-2010-6-reference" href="#">nips2010-6-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>6 nips-2010-A Discriminative Latent Model of Image Region and Object Tag Correspondence</h1>
<br/><p>Source: <a title="nips-2010-6-pdf" href="http://papers.nips.cc/paper/3968-a-discriminative-latent-model-of-image-region-and-object-tag-correspondence.pdf">pdf</a></p><p>Author: Yang Wang, Greg Mori</p><p>Abstract: We propose a discriminative latent model for annotating images with unaligned object-level textual annotations. Instead of using the bag-of-words image representation currently popular in the computer vision community, our model explicitly captures more intricate relationships underlying visual and textual information. In particular, we model the mapping that translates image regions to annotations. This mapping allows us to relate image regions to their corresponding annotation terms. We also model the overall scene label as latent information. This allows us to cluster test images. Our training data consist of images and their associated annotations. But we do not have access to the ground-truth regionto-annotation mapping or the overall scene label. We develop a novel variant of the latent SVM framework to model them as latent variables. Our experimental results demonstrate the effectiveness of the proposed model compared with other baseline methods.</p><br/>
<h2>reference text</h2><p>[1] K. Barnard, P. Duygulu, D. Forsyth, N. de Freitas, D. M. Blei, and M. I. Jordan. Matching words and pictures. Journal of Machine Learning Research, 3:1107–1135, 2003.</p>
<p>[2] K. Barnard and Q. Fan. Reducing correspondence ambibuity in loosely labeled training data. In IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2007.</p>
<p>[3] T. L. Berg, A. C. Berg, J. Edwards, and D. Forsyth. Who’s in the picture. In Advances in Neural Information Processing Systems, volume 17, pages 137–144. MIT Press, 2004.</p>
<p>[4] C. Desai, D. Ramanan, and C. Fowlkes. Discriminative models for static human-object interactions. In Workshop on Structured Models in Computer Vision, 2010.</p>
<p>[5] T.-M.-T. Do and T. Artieres. Large margin training for hidden markov models with partially observed states. In International Conference on Machine Learning, 2009.</p>
<p>[6] M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman. The PASCAL visual object classes (VOC) challenge. International Journal of Computer Vision, 88(2):303–338, 2010.</p>
<p>[7] P. F. Felzenszwalb, R. B. Girshick, D. McAllester, and D. Ramanan. Object detection with discriminatively trained part based models. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2009.</p>
<p>[8] P. F. Felzenszwalb and D. P. Huttenlocher. Efﬁcient graph-based image segmentation. International Journal of Computer Vision, 2004.</p>
<p>[9] T. Lan, Y. Wang, W. Yang, and G. Mori. Beyond actions: Discriminative models for contextual group activities. In Advances in Neural Information Processing Systems. MIT Press, 2010.</p>
<p>[10] J. Li and J. Z. Wang. Automatic linguistic indexing of pictures by a statistical modeling approach. IEEE Transactions on Pattern Analysis and Machine Intelligence, 25(9):1075–1088, September 2003.</p>
<p>[11] L.-J. Li and L. Fei-Fei. What, where and who? classifying events by scene and object recognition. In IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2007.</p>
<p>[12] L.-J. Li, R. Socher, and L. Fei-Fei. Towards total scene understanding: Classiﬁcation, annotation and segmentation in an automatic framework. In IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2009.</p>
<p>[13] N. Loeff and A. Farhadi. Scene discovery by matrix factorization. In European Conference on Computer Vision, 2008.</p>
<p>[14] T. Malisiewicz and A. A. Efros. Recognition by association via learning per-exemplar distances. In IEEE Computer Society Conference on Computer Vision and Pattern Recongition, 2008.</p>
<p>[15] C. D. Manning. Introduction to Information Retrieval. Cambridge University Press, 2008.</p>
<p>[16] J. C. Niebles, C.-W. Chen, and L. Fei-Fei. Modeling temporal structure of decomposable motion segments for activity classiﬁcation. In European Conference on Computer Vision, 2010.</p>
<p>[17] R. Socher and L. Fei-Fei. Connecting modalities: Semi-supervised segmentation and annotation of images using unaligned text corpora. In IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2010.</p>
<p>[18] B. Taskar, C. Guestrin, and D. Koller. Max-margin markov networks. In Advances in Neural Information Processing Systems, volume 16. MIT Press, 2004.</p>
<p>[19] I. Tsochantaridis, T. Joachims, T. Hofmann, and Y. Altun. Large margin methods for structured and interdependent output variables. Journal of Machine Learning Research, 6:1453–1484, 2005.</p>
<p>[20] A. Vedaldi and A. Zisserman. Structured output regression for detection with partial truncation. In Advances in Neural Information Processing Systems. MIT Press, 2009.</p>
<p>[21] C. Wang, D. Blei, and L. Fei-Fei. Simultaneous image classiﬁcation and annotation. In IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2009.</p>
<p>[22] Y. Wang and G. Mori. Max-margin hidden conditional random ﬁelds for human action recognition. In IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2009.</p>
<p>[23] Y. Wang and G. Mori. A discriminative latent model of object classes and attributes. In European Conference on Computer Vision, 2010.</p>
<p>[24] W. Yang, Y. Wang, and G. Mori. Recognizing human actions from still images with latent poses. In IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2010.</p>
<p>[25] C.-N. Yu and T. Joachims. Learning structural SVMs with latent variables. In International Conference on Machine Learning, 2009.  9</p>
<br/>
<br/><br/><br/></body>
</html>
