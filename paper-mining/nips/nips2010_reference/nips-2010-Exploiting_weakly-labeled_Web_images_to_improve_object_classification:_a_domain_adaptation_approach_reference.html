<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>86 nips-2010-Exploiting weakly-labeled Web images to improve object classification: a domain adaptation approach</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-86" href="../nips2010/nips-2010-Exploiting_weakly-labeled_Web_images_to_improve_object_classification%3A_a_domain_adaptation_approach.html">nips2010-86</a> <a title="nips-2010-86-reference" href="#">nips2010-86-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>86 nips-2010-Exploiting weakly-labeled Web images to improve object classification: a domain adaptation approach</h1>
<br/><p>Source: <a title="nips-2010-86-pdf" href="http://papers.nips.cc/paper/4064-exploiting-weakly-labeled-web-images-to-improve-object-classification-a-domain-adaptation-approach.pdf">pdf</a></p><p>Author: Alessandro Bergamo, Lorenzo Torresani</p><p>Abstract: Most current image categorization methods require large collections of manually annotated training examples to learn accurate visual recognition models. The time-consuming human labeling effort effectively limits these approaches to recognition problems involving a small number of different object classes. In order to address this shortcoming, in recent years several authors have proposed to learn object classiﬁers from weakly-labeled Internet images, such as photos retrieved by keyword-based image search engines. While this strategy eliminates the need for human supervision, the recognition accuracies of these methods are considerably lower than those obtained with fully-supervised approaches, because of the noisy nature of the labels associated to Web data. In this paper we investigate and compare methods that learn image classiﬁers by combining very few manually annotated examples (e.g., 1-10 images per class) and a large number of weakly-labeled Web photos retrieved using keyword-based image search. We cast this as a domain adaptation problem: given a few stronglylabeled examples in a target domain (the manually annotated examples) and many source domain examples (the weakly-labeled Web photos), learn classiﬁers yielding small generalization error on the target domain. Our experiments demonstrate that, for the same number of strongly-labeled examples, our domain adaptation approach produces signiﬁcant recognition rate improvements over the best published results (e.g., 65% better when using 5 labeled training examples per class) and that our classiﬁers are one order of magnitude faster to learn and to evaluate than the best competing method, despite our use of large weakly-labeled data sets.</p><br/>
<h2>reference text</h2><p>[1] http://vlg.cs.dartmouth.edu/projects/domainadapt.</p>
<p>[2] T. L. Berg and D. A. Forsyth. Animals on the web. In CVPR, pages 1463–1470, 2006.</p>
<p>[3] I. Bierderman. Recognition-by-components: A theory of human image understanding. Psychological Review, 94(2):115–147, 1987.</p>
<p>[4] J. Blitzer, K. Crammer, A. Kulesza, F. Pereira, and J. Wortman. Learning bounds for domain adaptation. In NIPS, 2007.</p>
<p>[5] H. Daume III. Frustratingly easy domain adaptation. In ACL, 2007.</p>
<p>[6] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. ImageNet: A Large-Scale Hierarchical Image Database. In CVPR, 2009.</p>
<p>[7] M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman. The PASCAL Visual Object Classes Challenge 2010 (VOC2010) Results.</p>
<p>[8] L. Fei-Fei, R. Fergus, and P. Perona. One-shot learning of object categories. IEEE Trans. Pattern Anal. Mach. Intell., 28(4):594–611, 2006.</p>
<p>[9] R. Fergus, L. Fei-Fei, P. Perona, and A. Zisserman. Learning object categories from google’s image search. In ICCV, pages 1816–1823, 2005.</p>
<p>[10] R. Fergus, P. Perona, and A. Zisserman. A visual category ﬁlter for google images. In ECCV, 2004.</p>
<p>[11] R. Fergus, Y. Weiss, and A. Torralba. Semi-supervised learning in gigantic image collections. In Y. Bengio, D. Schuurmans, J. Lafferty, C. K. I. Williams, and A. Culotta, editors, NIPS 22, 2009.</p>
<p>[12] J. R. Finkel and C. D. Manning. Hierarchical bayesian domain adaptation. In Proceedings of the North American Association of Computational Linguistics (NAACL 2009), 2009.</p>
<p>[13] P. V. Gehler and S. Nowozin. On feature combination for multiclass object classiﬁcation. In IEEE International Conference on Computer Vision (ICCV), 2009.</p>
<p>[14] G. Grifﬁn, A. Holub, and P. Perona. Caltech-256 object category dataset. Technical Report 7694, California Institute of Technology, 2007.</p>
<p>[15] A. Holub, M. Welling, and P. Perona. Exploiting unlabelled data for hybrid object classiﬁcation. In NIPS, Interclass transfer workshop, 2005.</p>
<p>[16] J. Huang, A. J. Smola, A. Gretton, K. M. Borgwardt, and B. Sch¨ lkopf. Correcting sample selection bias o by unlabeled data. In NIPS, pages 601–608, 2006.</p>
<p>[17] T. Joachims. Transductive inference for text classiﬁcation using support vector machines. In ICML, pages 200–209, 1999.</p>
<p>[18] S. S. Keerthi and D. DeCoste. A modiﬁed ﬁnite newton method for fast solution of large scale linear svms. Journal of Machine Learning Research, 6:341–361, 2005.</p>
<p>[19] C. Leistner, H. Grabner, and H. Bischof. Semi-supervised boosting using visual similarity learning. In CVPR, 2008.</p>
<p>[20] L. Li and L. Fei-Fei. Optimol: Automatic online picture collection via incremental model learning. Intl. Jrnl. of Computer Vision, 88(2):147–168, 2010.</p>
<p>[21] E. G. Miller, N. E. Matsakis, and P. A. Viola. Learning from one example through shared densities on transforms. In CVPR, 2000.</p>
<p>[22] A. Quattoni, M. Collins, and T. Darrell. Transfer learning for image classiﬁcation with sparse prototype representations. In CVPR, 2008.</p>
<p>[23] B. C. Russell, A. B. Torralba, K. P. Murphy, and W. T. Freeman. Labelme: A database and web-based tool for image annotation. International Journal of Computer Vision, 77(1-3):157–173, 2008.</p>
<p>[24] K. Saenko, B. Kulis, M. Fritz, and T. Darrell. Adapting visual category models to new domains. In European Conference on Computer Vision (ECCV), Sept. 2010.</p>
<p>[25] F. Schroff, A. Criminisi, and A. Zisserman. Harvesting image databases from the web. In ICCV, 2007.</p>
<p>[26] G. Schweikert, C. Widmer, B. Sch¨ lkopf, and G. R¨ tsch. An empirical analysis of domain adaptation o a algorithms for genomic sequence analysis. In NIPS, pages 1433–1440, 2008.</p>
<p>[27] V. Sindhwani and S. S. Keerthi. Large scale semi-supervised linear svms. In SIGIR, pages 477–484, 2006.</p>
<p>[28] L. Torresani, M. Szummer, and A. Fitzgibbon. Efﬁcient object category recognition using classemes. In European Conference on Computer Vision (ECCV), pages 776–789, Sept. 2010.</p>
<p>[29] S. Vijayanarasimhan and K. Grauman. Keywords to visual categories: Multiple-instance learning forweakly supervised object categorization. In CVPR, 2008.</p>
<p>[30] L. von Ahn. Games with a purpose. IEEE Computer, 39(6):92–94, 2006.  9</p>
<br/>
<br/><br/><br/></body>
</html>
