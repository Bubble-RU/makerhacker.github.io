<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>52 nips-2010-Convex Multiple-Instance Learning by Estimating Likelihood Ratio</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-52" href="../nips2010/nips-2010-Convex_Multiple-Instance_Learning_by_Estimating_Likelihood_Ratio.html">nips2010-52</a> <a title="nips-2010-52-reference" href="#">nips2010-52-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>52 nips-2010-Convex Multiple-Instance Learning by Estimating Likelihood Ratio</h1>
<br/><p>Source: <a title="nips-2010-52-pdf" href="http://papers.nips.cc/paper/3926-convex-multiple-instance-learning-by-estimating-likelihood-ratio.pdf">pdf</a></p><p>Author: Fuxin Li, Cristian Sminchisescu</p><p>Abstract: We propose an approach to multiple-instance learning that reformulates the problem as a convex optimization on the likelihood ratio between the positive and the negative class for each training instance. This is casted as joint estimation of both a likelihood ratio predictor and the target (likelihood ratio variable) for instances. Theoretically, we prove a quantitative relationship between the risk estimated under the 0-1 classiﬁcation loss, and under a loss function for likelihood ratio. It is shown that likelihood ratio estimation is generally a good surrogate for the 0-1 loss, and separates positive and negative instances well. The likelihood ratio estimates provide a ranking of instances within a bag and are used as input features to learn a linear classiﬁer on bags of instances. Instance-level classiﬁcation is achieved from the bag-level predictions and the individual likelihood ratios. Experiments on synthetic and real datasets demonstrate the competitiveness of the approach.</p><br/>
<h2>reference text</h2><p>[1] Dietterich, T.G., Lathrop, R.H., Lozano-Perez, T.: Solving the multiple-instance problem with axis-parallel rectangles. Artiﬁcial Intelligence 89 (1997) 31–71</p>
<p>[2] Andrews, S., Tsochantaridis, I., Hofmann, T.: Support vector machines for multiple-instance learning. In: NIPS. (2003) 561–568</p>
<p>[3] Maron, O., Lozano-P´ rez, T.: A framework for multiple-instance learning. In: NIPS. (1998) e 570–576</p>
<p>[4] Felzenszwalb, P.F., McAllester, D.A., Ramanan, D.: A discriminatively trained, multiscale, deformable part model. In: CVPR. (2008)</p>
<p>[5] Russell, B.C., Torralba, A., Murphy, K.P., Freeman, W.T.: Labelme: A database and webbased tool for image annotation. IJCV 77(1-3) (2008) 157–173</p>
<p>[6] Cour, T., Sapp, B., Nagle, A., Taskar, B.: Talking pictures: Temporal grouping and dialogsupervised person recognition. In: CVPR. (2010)</p>
<p>[7] Zeisl, B., Leistner, C., Saffari, A., Bischof, H.: On-line semi-supervised multiple-instance boosting. In: CVPR. (2010)</p>
<p>[8] G¨ rtner, T., Flach, P.A., Kowalczyk, A., Smola, A.J.: Multi-instance kernels. In: ICML. a (2002)</p>
<p>[9] Tao, Q., Scott, S., Vinodchandran, N.V., Osugi, T.T.: Svm-based generalized multiple-instance learning via approximate box counting. In: ICML. (2004)</p>
<p>[10] Zhou, Z.H., Sun, Y.Y., Li, Y.F.: Multi-instance learning by treating instances as non-i.i.d. samples. In: ICML. (2009)</p>
<p>[11] Cheung, P.M., Kwok, J.T.: A regularization framework for multiple-instance learning. In: ICML. (2006) 193–200</p>
<p>[12] Fung, G., Dandar, M., Krishnapuram, B., Rao, R.B.: Multiple instance learning for computer aided diagnosis. In: NIPS. (2007)</p>
<p>[13] Mangasarian, O., Wild, E.: Multiple instance classiﬁcation via successive linear programming. Journal of Optimization Theory and Applications 137 (2008) 555–568</p>
<p>[14] Zhang, Q., Goldman, S.A., Yu, W., Fritts, J.E.: Content-based image retrieval using multipleinstance learning. In: ICML. (2002) 682–689</p>
<p>[15] Gehler, P., Chapelle, O.: Deterministic annealing for multiple-instance learning. In: AISTATS. (2007)</p>
<p>[16] Doll´ r, P., Babenko, B., Belongie, S., Perona, P., Tu, Z.: Multiple component learning for a object detection. In: ECCV. (2008)</p>
<p>[17] Li, Y.F., Kwok, J.T., Tsang, I.W., Zhou, Z.H.: A convex method for locating regions of interest with multi-instance learning. In: ECML. (2009)</p>
<p>[18] Mammen, E., Tsybakov, A.B.: Smooth discrimination analysis. Annals of Statistics 27 (1999) 1808–1829</p>
<p>[19] Tsybakov, A.B.: Optimal aggregation of classiﬁers in statistical learning. Annals of Statistics 32 (2004) 135–166</p>
<p>[20] Bartlett, P., Jordan, M.I., McAulliffe, J.: Convexity, classiﬁcation and risk bounds. Journal of American Statistical Association 101 (2006) 138–156</p>
<p>[21] Li, F., Sminchisescu, C.: Convex multiple instance learning by estimating likelihood ratio. Technical report, Institute for Numerical Simulation, University of Bonn (November 2010)</p>
<p>[22] Nguyen, X., Wainwright, M., Jordan, M.I.: Estimating divergence functionals and the likelihood ratio by penalized convex risk minimization. In: NIPS. (2007)</p>
<p>[23] Liese, F., Vajda, I.: Convex Statistical Distances. Teubner VG (1987)</p>
<p>[24] Hofmann, T., Sch¨ lkopf, B., Smola, A.J.: Kernel methods in machine learning. The Annals of o Statistics 36 (2008) 1171–1220  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
