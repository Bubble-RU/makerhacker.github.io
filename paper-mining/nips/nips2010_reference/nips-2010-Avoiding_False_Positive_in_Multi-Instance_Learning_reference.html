<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>36 nips-2010-Avoiding False Positive in Multi-Instance Learning</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-36" href="../nips2010/nips-2010-Avoiding_False_Positive_in_Multi-Instance_Learning.html">nips2010-36</a> <a title="nips-2010-36-reference" href="#">nips2010-36-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>36 nips-2010-Avoiding False Positive in Multi-Instance Learning</h1>
<br/><p>Source: <a title="nips-2010-36-pdf" href="http://papers.nips.cc/paper/3941-avoiding-false-positive-in-multi-instance-learning.pdf">pdf</a></p><p>Author: Yanjun Han, Qing Tao, Jue Wang</p><p>Abstract: In multi-instance learning, there are two kinds of prediction failure, i.e., false negative and false positive. Current research mainly focus on avoiding the former. We attempt to utilize the geometric distribution of instances inside positive bags to avoid both the former and the latter. Based on kernel principal component analysis, we deﬁne a projection constraint for each positive bag to classify its constituent instances far away from the separating hyperplane while place positive instances and negative instances at opposite sides. We apply the Constrained Concave-Convex Procedure to solve the resulted problem. Empirical results demonstrate that our approach offers improved generalization performance.</p><br/>
<h2>reference text</h2><p>[1] T. G. Dietterich, R. H. Lathrop, and T. Lozano-P´ rez. Solving the multiple-instance problem with axise parallel rectangles. Artiﬁcial Intelligence, 89(1-2):31–71, 1997.</p>
<p>[2] O. Maron and T. Lozano-P´ rez. A framework for multiple-instance learning. Advances in neural infore mation processing systems, pages 570–576, 1998.</p>
<p>[3] J. Wang and J.D. Zucker. Solving the multiple-instance problem: A lazy learning approach. In Proceedings of the Seventeenth International Conference on Machine Learning, pages 1119–1126. Citeseer, 2000.</p>
<p>[4] S. Andrews, I. Tsochantaridis, and T. Hofmann. Support vector machines for multiple-instance learning. Advances in neural information processing systems, pages 577–584, 2003.</p>
<p>[5] T. G¨ rtner, P.A. Flach, A. Kowalczyk, and A.J. Smola. Multi-instance kernels. In Proceedings of the a Nineteenth International Conference on Machine Learning, pages 179–186. Citeseer, 2002.</p>
<p>[6] P.M. Cheung and J.T. Kwok. A regularization framework for multiple-instance learning. In Proceedings of the 23rd international conference on Machine learning, page 200. ACM, 2006.</p>
<p>[7] Z.H. Zhou and J.M. Xu. On the relation between multi-instance learning and semi-supervised learning. In Proceedings of the 24th international conference on Machine learning, page 1174. ACM, 2007.</p>
<p>[8] R.C. Bunescu and R.J. Mooney. Multiple instance learning for sparse positive bags. In Proceedings of the 24th international conference on Machine learning, page 112. ACM, 2007.</p>
<p>[9] H.Y. Wang, Q. Yang, and H. Zha. Adaptive p-posterior mixture-model kernels for multiple instance learning. In Proceedings of the 25th international conference on Machine learning, pages 1136–1143. ACM, 2008.</p>
<p>[10] Z. H. Zhou, Y. Y. Sun, and Yu. F. Li. Multi-instance learning by treating instances as non-I.I.D. samples. In L´ on Bottou and Michael Littman, editors, Proceedings of the 26th International Conference on Machine e Learning, pages 1249–1256, Montreal, June 2009. test, Omnipress.</p>
<p>[11] Y. Chen and J.Z. Wang. Image categorization by learning and reasoning with regions. The Journal of Machine Learning Research, 5:913–939, 2004.</p>
<p>[12] B. Settles, M. Craven, and S. Ray. Multiple-instance active learning. Advances in Neural Information Processing Systems (NIPS), 20:1289–1296, 2008.</p>
<p>[13] G. Fung, M. Dundar, B. Krishnapuram, and R.B. Rao. Multiple instance learning for computer aided diagnosis. In NIPS2007, page 425. The MIT Press, 2007.</p>
<p>[14] A.J. Smola, SVN Vishwanathan, and T. Hofmann. Kernel methods for missing variables. In Proceedings of the Tenth International Workshop on Artiﬁcial Intelligence and Statistics. Citeseer, 2005.</p>
<p>[15] R.O. Duda, P.E. Hart, and D.G. Stork. Pattern classiﬁcation. John Wiley & Sons, 2001.</p>
<p>[16] B. Sch¨ lkopf and A.J. Smola. Learning with kernels. Citeseer, 2002. o</p>
<p>[17] Q. Tao, D.J. Chu, and J. Wang. Recursive support vector machines for dimensionality reduction. IEEE Transactions on Neural Networks, 19(1):189–193, 2008.</p>
<p>[18] S.P. Boyd and L. Vandenberghe. Convex optimization. Cambridge Univ Pr, 2004.</p>
<p>[19] Q. Zhang and S.A. Goldman. Em-dd: An improved multiple-instance learning technique. Advances in neural information processing systems, 2:1073–1080, 2002.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
