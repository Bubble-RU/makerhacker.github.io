<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>150 nips-2010-Learning concept graphs from text with stick-breaking priors</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-150" href="../nips2010/nips-2010-Learning_concept_graphs_from_text_with_stick-breaking_priors.html">nips2010-150</a> <a title="nips-2010-150-reference" href="#">nips2010-150-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>150 nips-2010-Learning concept graphs from text with stick-breaking priors</h1>
<br/><p>Source: <a title="nips-2010-150-pdf" href="http://papers.nips.cc/paper/3963-learning-concept-graphs-from-text-with-stick-breaking-priors.pdf">pdf</a></p><p>Author: America Chambers, Padhraic Smyth, Mark Steyvers</p><p>Abstract: We present a generative probabilistic model for learning general graph structures, which we term concept graphs, from text. Concept graphs provide a visual summary of the thematic content of a collection of documents—a task that is difﬁcult to accomplish using only keyword search. The proposed model can learn different types of concept graph structures and is capable of utilizing partial prior knowledge about graph structure as well as labeled documents. We describe a generative model that is based on a stick-breaking process for graphs, and a Markov Chain Monte Carlo inference procedure. Experiments on simulated data show that the model can recover known graph structure when learning in both unsupervised and semi-supervised modes. We also show that the proposed model is competitive in terms of empirical log likelihood with existing structure-based topic models (hPAM and hLDA) on real-world text data sets. Finally, we illustrate the application of the model to the problem of updating Wikipedia category graphs. 1</p><br/>
<h2>reference text</h2><p>[1] David Blei, Andrew Ng, and Michael Jordan. Latent dirichlet allocation. Journal of Machine Learning Research, 3:993–1022, 2003.</p>
<p>[2] David M. Blei, Thomas L. Grifﬁths, and Michael I. Jordan. The nested chinese restaurant process and bayesian nonparametric inference of topic hierarchies. Journal of the Acm, 57, 2010.</p>
<p>[3] David Mimno, Wei Li, and Andrew McCallum. mixtures of hierarchical topics with pachinko allocation. In Proceedings of the 21st Intl. Conf. on Machine Learning, 2007.</p>
<p>[4] Wei Li, David Blei, and Andrew McCallum. Nonparametric bayes pachinko allocation. In Proceedings of the Twenty-Third Annual Conference on Uncertainty in Artiﬁcial Intelligence (UAI-07), pages 243–250, 2007.</p>
<p>[5] Blaz Fortuna, Marko Grobelnki, and Dunja Mladenic. Ontogen: Semi-automatic ontology editor. In Proceedings of theHuman Computer Interaction International Conference, volume 4558, pages 309–318, 2007.</p>
<p>[6] S. Bloehdorn, P. Cimiano, and A. Hotho. Learning ontologies to improve text clustering and classiﬁcation. In From Data and Inf. Analysis to Know. Eng.: Proc. of the 29th Annual Conf. the German Classiﬁcation Society (GfKl ’05), volume 30 of Studies in Classiﬁcation, Data Analysis and Know. Org., pages 334–341. Springer, Feb. 2005.</p>
<p>[7] P. Cimiano, A. Hotho, and S. Staab. Learning concept hierarchies from text using formal concept analysis. J. Artiﬁcial Intelligence Research (JAIR), 24:305–339, 2005.</p>
<p>[8] Hemant Ishwaran and Lancelot F. James. Gibbs sampling methods for stick-breaking priors. Journal of the American Statistical Association, 96(453):161–173, March 2001.</p>
<p>[9] Tom Grifﬁths and Mark Steyvers. Finding scientiﬁc topics. Proceedings of the Natl. Academy of the Sciences of the U.S.A., 101 Suppl 1:5228–5235, 2004.</p>
<p>[10] Ian Porteous, Alex Ihler, Padhraic Smyth, and Max Welling. Gibbs sampling for coupled inﬁnite mixture models in the stick-breaking representation. In Proceedings of UAI 2006, pages 385–392, July 2006.</p>
<p>[11] Andrew Kachites McCallum. http://mallet.cs.umass.edu, 2002.  Mallet:  A machine learning for language toolkit.</p>
<p>[12] Hanna M. Wallach, Iain Murray, Ruslan Salakhutdinov, and David Mimno. Evaluation methods for topic models. In Proceedings of the 26th Intl. Conf. on Machine Learning (ICML 2009), 2009.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
