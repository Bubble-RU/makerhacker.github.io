<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>56 nips-2010-Deciphering subsampled data: adaptive compressive sampling as a principle of brain communication</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-56" href="../nips2010/nips-2010-Deciphering_subsampled_data%3A_adaptive_compressive_sampling_as_a_principle_of_brain_communication.html">nips2010-56</a> <a title="nips-2010-56-reference" href="#">nips2010-56-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>56 nips-2010-Deciphering subsampled data: adaptive compressive sampling as a principle of brain communication</h1>
<br/><p>Source: <a title="nips-2010-56-pdf" href="http://papers.nips.cc/paper/4093-deciphering-subsampled-data-adaptive-compressive-sampling-as-a-principle-of-brain-communication.pdf">pdf</a></p><p>Author: Guy Isely, Christopher Hillar, Fritz Sommer</p><p>Abstract: A new algorithm is proposed for a) unsupervised learning of sparse representations from subsampled measurements and b) estimating the parameters required for linearly reconstructing signals from the sparse codes. We verify that the new algorithm performs efﬁcient data compression on par with the recent method of compressive sampling. Further, we demonstrate that the algorithm performs robustly when stacked in several stages or when applied in undercomplete or overcomplete situations. The new algorithm can explain how neural populations in the brain that receive subsampled input through ﬁber bottlenecks are able to form coherent response properties. 1</p><br/>
<h2>reference text</h2><p>[1] A. Bell and T. Sejnowski. Learning the higher-order structure of a natural sound. Network: Computation in Neural Systems, 7(2):261–266, 1996.</p>
<p>[2] E.J. Cand` s. Compressive sampling. In Proceedings of the International Congress of Mathee maticians, volume 3, pages 1433–1452. Citeseer, 2006.</p>
<p>[3] M. Elad. Optimized projections for compressed sensing. IEEE Transactions on Signal Processing, 55(12):5695–5702, 2007.</p>
<p>[4] S. Gleichman and Y.C. Eldar. Blind Compressed Sensing. preprint, 2010.</p>
<p>[5] H. Lee, A. Battle, R. Raina, and A.Y. Ng. Efﬁcient sparse coding algorithms. Advances in neural information processing systems, 19:801, 2007.</p>
<p>[6] B.A. Olshausen and D.J. Field. Emergence of simple-cell receptive ﬁeld properties by learning a sparse code for natural images. Nature, 381(6583):607–609, 1996.</p>
<p>[7] M. Rehn and F.T. Sommer. A network that uses few active neurones to code visual input predicts the diverse shapes of cortical receptive ﬁelds. Journal of Computational Neuroscience, 22(2):135–146, 2007.</p>
<p>[8] C.J. Rozell, D.H. Johnson, R.G. Baraniuk, and B.A. Olshausen. Sparse coding via thresholding and local competition in neural circuits. Neural computation, 20(10):2526–2563, 2008.</p>
<p>[9] D.L. Ruderman and W. Bialek. Statistics of natural images: Scaling in the woods. Physical Review Letters, 73(6):814–817, 1994.</p>
<p>[10] A. Sch¨ z, D. Chaimow, D. Liewald, and M. Dortenman. Quantitative aspects of corticocortical u connections: a tracer study in the mouse. Cerebral Cortex, 16(10):1474, 2006.</p>
<p>[11] E.C. Smith and M.S. Lewicki. Efﬁcient auditory coding. Nature, 439(7079):978–982, 2006.</p>
<p>[12] M. Sur, P.E. Garraghty, and A.W. Roe. Experimentally induced visual projections into auditory thalamus and cortex. Science(Washington), 242(4884):1437–1437, 1988.</p>
<p>[13] F.E. Theunissen, S.V. David, N.C. Singh, A. Hsu, W.E. Vinje, and J.L. Gallant. Estimating spatio-temporal receptive ﬁelds of auditory and visual neurons from their responses to natural stimuli. Network: Computation in Neural Systems, 12(3):289–316, 2001.</p>
<p>[14] D.C. Van Essen, C.H. Anderson, and D.J. Felleman. Information processing in the primate visual system: an integrated systems perspective. Science, 255(5043):419–423, 1992.</p>
<p>[15] M.J. Wainwright. Sharp thresholds for high-dimensional and noisy sparsity recovery using ell1 -constrained quadratic programming (Lasso). IEEE Trans. Information Theory, pages 2183–2202, 2009.</p>
<p>[16] Y. Weiss, H. Chang, and W. Freeman. Learning compressed sensing. In Snowbird Learning Workshop, Allerton, CA. Citeseer, 2007.</p>
<p>[17] R.J. Wyman and J.B. Thomas. What genes are necessary to make an identiﬁed synapse? In Cold Spring Harbor Symposia on Quantitative Biology, volume 48, page 641. Cold Spring Harbor Laboratory Press, 1983.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
