<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>210 nips-2010-Practical Large-Scale Optimization for Max-norm Regularization</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-210" href="../nips2010/nips-2010-Practical_Large-Scale_Optimization_for_Max-norm_Regularization.html">nips2010-210</a> <a title="nips-2010-210-reference" href="#">nips2010-210-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>210 nips-2010-Practical Large-Scale Optimization for Max-norm Regularization</h1>
<br/><p>Source: <a title="nips-2010-210-pdf" href="http://papers.nips.cc/paper/4124-practical-large-scale-optimization-for-max-norm-regularization.pdf">pdf</a></p><p>Author: Jason Lee, Ben Recht, Nathan Srebro, Joel Tropp, Ruslan Salakhutdinov</p><p>Abstract: The max-norm was proposed as a convex matrix regularizer in [1] and was shown to be empirically superior to the trace-norm for collaborative ﬁltering problems. Although the max-norm can be computed in polynomial time, there are currently no practical algorithms for solving large-scale optimization problems that incorporate the max-norm. The present work uses a factorization technique of Burer and Monteiro [2] to devise scalable ﬁrst-order algorithms for convex programs involving the max-norm. These algorithms are applied to solve huge collaborative ﬁltering, graph cut, and clustering problems. Empirically, the new methods outperform mature techniques from all three areas. 1</p><br/>
<h2>reference text</h2><p>[1] Nathan Srebro, Jason Rennie, and Tommi Jaakkola. Maximum margin matrix factorization. In Advances in Neural Information Processing Systems, 2004.</p>
<p>[2] Samuel Burer and R. D. C. Monteiro. A nonlinear programming algorithm for solving semideﬁnite programs via low-rank factorization. Mathematical Programming (Series B), 95:329–357, 2003.</p>
<p>[3] Benjamin Recht, Maryam Fazel, and Pablo Parrilo. Guaranteed minimum rank solutions of matrix equations via nuclear norm minimization. SIAM Review, 2007. To appear. Preprint Available at http://pages.cs.wisc.edu/˜brecht/publications.html.</p>
<p>[4] Francis R. Bach, Julien Marial, and Jean Ponce. Convex sparse matrix factorizations. Preprint available at arxiv.org/abs/0812.1869, 2008.</p>
<p>[5] Nathan Srebro and Adi Shraibman. Rank, trace-norm and max-norm. In 18th Annual Conference on Learning Theory (COLT), 2005.</p>
<p>[6] G. J. O. Jameson. Summing and Nuclear Norms in Banach Space Theory. Number 8 in London Mathematical Society Student Texts. Cambridge University Press, Cambridge, UK, 1987.</p>
<p>[7] Ruslan Salakhutdinov and Nathan Srebro. Collaborative ﬁltering in a non-uniform world: Learning with the weighted trace norm. Preprint available at arxiv.org/abs/1002.2780, 2010.</p>
<p>[8] Masao Fukushima and Hisashi Mine. A generalized proximal point algorithm for certain non-convex minimization problems. International Journal of Systems Science, 12(8):989–1000, 1981.</p>
<p>[9] Samuel Burer and Changhui Choi. Computational enhancements in low-rank semideﬁnite programming. Optimization Methods and Software, 21(3):493–512, 2006.</p>
<p>[10] Dimitri P. Bertsekas. Nonlinear Programming. Athena Scientiﬁc, Belmont, MA, 2nd edition, 1999.</p>
<p>[11] T Hale, W Yin, and Y Zhang. A ﬁxed-point continuation method for l 1-regularized minimization with applications to compressed sensing. Dept. Computat. Appl. Math., Rice Univ., Houston, TX, Tech. Rep. TR07-07, 2007.</p>
<p>[12] Stephen J. Wright, Robert Nowak, and M´ rio A. T. Figueiredo. Sparse reconstruction by separable apa proximation. Journal version, to appear in IEEE Transactions on Signal Processing. Preprint available at http:http://www.optimization-online.org/DB_HTML/2007/10/1813.html, 2007.</p>
<p>[13] Jian-Feng Cai, Emmanuel J. Cand` s, and Zuowei Shen. A singular value thresholding algorithm for e matrix completion. To appear in SIAM J. on Optimization. Preprint available at http://arxiv.org/ abs/0810.3286, 2008.</p>
<p>[14] Shiqian Ma, Donald Goldfarb, and Lifeng Chen. Fixed point and Bregman iterative methods for matrix rank minimization. Preprint available at http://www.optimization-online.org/DB_HTML/ 2008/11/2151.html, 2008.</p>
<p>[15] Yurii Nesterov. Gradient methods for minimizing composite objective function. To appear. Preprint Available at http://www.optimization-online.org/DB_HTML/2007/09/1784.html, September 2007.</p>
<p>[16] M. X. Goemans and D. P. Williamson. Improved approximation algorithms for maximum cut and satisﬁability problems using semideﬁnite programming. Journal of the ACM, 42:1115–1145, 1995.</p>
<p>[17] The Gset is available for download at http://www.stanford.edu/˜yyye/yyye/Gset/.</p>
<p>[18] Samuel Burer. Sdplr. Software available at http://dollar.biz.uiowa.edu/˜sburer/www/ doku.php?id=software#sdplr.</p>
<p>[19] Arthur Szlam and Xavier Bresson. A total variation-based graph clustering algorithm for cheeger ratio cuts. To appear in ICML 2010. Preprint available at ftp://ftp.math.ucla.edu/pub/ camreport/cam09-68.pdf, 2010.</p>
<p>[20] Jianbo Shi and Jitendra Malik. Normalized cuts and image segmentation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(8):888–905, 2000.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
