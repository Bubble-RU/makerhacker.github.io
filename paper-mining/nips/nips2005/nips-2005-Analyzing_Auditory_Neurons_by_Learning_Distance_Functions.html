<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>28 nips-2005-Analyzing Auditory Neurons by Learning Distance Functions</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2005" href="../home/nips2005_home.html">nips2005</a> <a title="nips-2005-28" href="#">nips2005-28</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>28 nips-2005-Analyzing Auditory Neurons by Learning Distance Functions</h1>
<br/><p>Source: <a title="nips-2005-28-pdf" href="http://papers.nips.cc/paper/2893-analyzing-auditory-neurons-by-learning-distance-functions.pdf">pdf</a></p><p>Author: Inna Weiner, Tomer Hertz, Israel Nelken, Daphna Weinshall</p><p>Abstract: We present a novel approach to the characterization of complex sensory neurons. One of the main goals of characterizing sensory neurons is to characterize dimensions in stimulus space to which the neurons are highly sensitive (causing large gradients in the neural responses) or alternatively dimensions in stimulus space to which the neuronal response are invariant (deﬁning iso-response manifolds). We formulate this problem as that of learning a geometry on stimulus space that is compatible with the neural responses: the distance between stimuli should be large when the responses they evoke are very different, and small when the responses they evoke are similar. Here we show how to successfully train such distance functions using rather limited amount of information. The data consisted of the responses of neurons in primary auditory cortex (A1) of anesthetized cats to 32 stimuli derived from natural sounds. For each neuron, a subset of all pairs of stimuli was selected such that the responses of the two stimuli in a pair were either very similar or very dissimilar. The distance function was trained to ﬁt these constraints. The resulting distance functions generalized to predict the distances between the responses of a test stimulus and the trained stimuli. 1</p><p>Reference: <a title="nips-2005-28-reference" href="../nips2005_reference/nips-2005-Analyzing_Auditory_Neurons_by_Learning_Distance_Functions_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 We formulate this problem as that of learning a geometry on stimulus space that is compatible with the neural responses: the distance between stimuli should be large when the responses they evoke are very different, and small when the responses they evoke are similar. [sent-9, score-1.616]
</p><p>2 Here we show how to successfully train such distance functions using rather limited amount of information. [sent-10, score-0.223]
</p><p>3 The data consisted of the responses of neurons in primary auditory cortex (A1) of anesthetized cats to 32 stimuli derived from natural sounds. [sent-11, score-1.358]
</p><p>4 For each neuron, a subset of all pairs of stimuli was selected such that the responses of the two stimuli in a pair were either very similar or very dissimilar. [sent-12, score-1.306]
</p><p>5 The resulting distance functions generalized to predict the distances between the responses of a test stimulus and the trained stimuli. [sent-14, score-0.895]
</p><p>6 1  Introduction  A major challenge in auditory neuroscience is to understand how cortical neurons represent the acoustic environment. [sent-15, score-0.637]
</p><p>7 Neural responses to complex sounds are idiosyncratic, and small perturbations in the stimuli may give rise to large changes in the responses. [sent-16, score-0.877]
</p><p>8 The dominant approach to the functional characterization of sensory neurons attempts to predict the response of the cortical neuron to a novel stimulus. [sent-18, score-0.506]
</p><p>9 Prediction is usually estimated from a set of known responses of a given neuron to a set of stimuli (sounds). [sent-19, score-0.861]
</p><p>10 The most popular approach computes the spectrotemporal receptive ﬁeld (STRF) of each neuron, and uses this linear model to predict neuronal responses. [sent-20, score-0.253]
</p><p>11 In this paper we take a different approach to the characterization of auditory cortical neurons. [sent-22, score-0.472]
</p><p>12 Our approach attempts to learn the non-linear warping of stimulus space that is in-  duced by the neuronal responses. [sent-23, score-0.351]
</p><p>13 This approach is motivated by our previous observations [3] that different neurons impose different partitions of the stimulus space, which are not necessarily simply related to the spectro-temporal structure of the stimuli. [sent-24, score-0.405]
</p><p>14 More speciﬁcally, we characterize a neuron by learning a pairwise distance function over the stimulus domain that will be consistent with the similarities between the responses to different stimuli, see Section 2. [sent-25, score-0.845]
</p><p>15 Intuitively a good distance function would assign small values to pairs of stimuli that elicit a similar neuronal response, and large values to pairs of stimuli that elicit different neuronal responses. [sent-26, score-1.551]
</p><p>16 Second, unlike most functional characterizations that are limited to linear or weakly non-linear models, distance learning can approximate functions that are highly non-linear. [sent-28, score-0.25]
</p><p>17 Finally, we explicitly learn a distance function on stimulus space; by examining the properties of such a function, it may be possible to determine the stimulus features that most strongly inﬂuence the responses of a cortical neuron. [sent-29, score-1.081]
</p><p>18 In this paper we therefore focus on two questions: (1) Can we learn distance functions over the stimulus domain for single cells using information extracted from their neuronal responses? [sent-31, score-0.713]
</p><p>19 and (2) What is the predictive power of these cell speciﬁc distance functions when presented with novel stimuli? [sent-33, score-0.495]
</p><p>20 In order to address these questions we used extracellular recordings from 22 cells in the auditory cortex of cats in response to natural bird chirps and some modiﬁed versions of these chirps [1]. [sent-34, score-0.793]
</p><p>21 To estimate the distance between responses, we used a normalized distance measure between the peri-stimulus time histograms of the responses to the different stimuli. [sent-35, score-0.73]
</p><p>22 Our results, described in Section 4, show that we can learn compatible distance functions on the stimulus domain with relatively low training errors. [sent-36, score-0.452]
</p><p>23 This result is interesting by itself as a possible characterization of cortical auditory neurons, a goal which eluded many previous studies [3]. [sent-37, score-0.472]
</p><p>24 Using cross validation, we measure the test error (or predictive power) of our method, and report generalization power which is signiﬁcantly higher than previously reported for natural stimuli [10]. [sent-38, score-0.586]
</p><p>25 We then show that performance can be further improved by learning a distance function using information from pairs of related neurons. [sent-39, score-0.259]
</p><p>26 Finally, we show better generalization performance for wide-band stimuli as compared to narrow-band stimuli. [sent-40, score-0.433]
</p><p>27 These latter two contributions may have some interesting biological implications regarding the nature of the computations done by auditory cortical neurons. [sent-41, score-0.419]
</p><p>28 Related work Recently, considerable attention has been focused on spectrotemporal receptive ﬁelds (STRFs) as characterizations of the function of auditory cortical neurons [8, 4, 2, 11, 16]. [sent-42, score-0.76]
</p><p>29 It can be interpreted both as providing the neuron’s most efﬁcient stimulus (in the time-frequency domain), and also as the spectro-temporal impulse response of the neuron [10, 12]. [sent-44, score-0.367]
</p><p>30 Furthermore, when STRFs are used to predict neuronal responses to natural stimuli they often fail to predict the correct responses [10, 6]. [sent-47, score-1.284]
</p><p>31 Similar results were also reported in [14], who found that STRF models  account for only 18 − 40% (on average) of the stimulus related power in auditory cortical neural responses to dynamic random chord stimuli. [sent-50, score-1.018]
</p><p>32 Various other studies have shown that there are signiﬁcant and relevant non-linearities in auditory cortical responses to natural stimuli [13, 1, 9, 10]. [sent-51, score-1.237]
</p><p>33 al [1] have shown that auditory neurons are extremely sensitive to small perturbations in the (natural) acoustic context. [sent-53, score-0.531]
</p><p>34 2  Formalizing the problem as a distance learning problem  Our approach is based on the idea of learning a cell-speciﬁc distance function over the space of all possible stimuli, relying on partial information extracted from the neuronal responses of the cell. [sent-55, score-0.812]
</p><p>35 The initial data consists of stimuli and the resulting neural responses. [sent-56, score-0.433]
</p><p>36 We use the neuronal responses to identify pairs of stimuli to which the neuron responded similarly and pairs to which the neuron responded very differently. [sent-57, score-1.341]
</p><p>37 These pairs can be formally described by equivalence constraints. [sent-58, score-0.227]
</p><p>38 Equivalence constraints are relations between pairs of datapoints, which indicate whether the points in the pair belong to the same category or not. [sent-59, score-0.196]
</p><p>39 In this setting the goal of the algorithm is to learn a distance function that attempts to comply with the equivalence constraints. [sent-61, score-0.286]
</p><p>40 Speciﬁcally, we combine equivalence constraints gathered from pairs of cells which have similar responses, and train a single distance function for both cells. [sent-63, score-0.661]
</p><p>41 Our results demonstrate that this approach improves prediction results of the “weaker” cell, and almost always improves the result of the “stronger” cell in each pair. [sent-64, score-0.333]
</p><p>42 Another interesting result of this formalism is the ability to classify stimuli based on the responses of the total recorded cortical cell ensemble. [sent-65, score-1.22]
</p><p>43 For some stimuli, the predictive performance based on the learned inter-stimuli distance was very good, whereas for other stimuli it was rather poor. [sent-66, score-0.621]
</p><p>44 These differences were correlated with the acoustic structure of the stimuli, partitioning them into narrowband and wideband stimuli. [sent-67, score-0.358]
</p><p>45 3  Methods  Experimental setup Extracellular recordings were made in primary auditory cortex of nine halothane-anesthetized cats. [sent-68, score-0.356]
</p><p>46 Single neurons were recorded using metal microelectrodes and an online spike sorter (MSD, alpha-omega). [sent-72, score-0.193]
</p><p>47 Four stimuli, each of length 60-100 ms, consisted of a main tonal component with frequency and amplitude modulation and of a background noise consisting of echoes and unrelated components. [sent-77, score-0.192]
</p><p>48 Each of these stimuli was further modiﬁed by separating the main tonal component from the noise, and by further separating the noise into echoes and background. [sent-78, score-0.529]
</p><p>49 In total, 8 versions of each stimulus were used, and therefore each neuron had a dataset consisting of 32 datapoints. [sent-80, score-0.313]
</p><p>50 Each stimulus was represented using the ﬁrst d real Cepstral coefﬁcients. [sent-84, score-0.225]
</p><p>51 Neuronal responses were represented by creating PeriStimulus Time Histograms (PSTHs) using 20 repetitions recorded for each stimuli. [sent-87, score-0.382]
</p><p>52 Obtaining equivalence constraints over stimuli pairs The distances between responses were measured using a normalized χ2 distance measure. [sent-89, score-1.356]
</p><p>53 All responses to both stimuli (40 responses in total) were superimposed to generate a single high-resolution PSTH. [sent-90, score-1.113]
</p><p>54 The same bins were then used to generate the PSTHs of the responses to the two stimuli separately. [sent-92, score-0.773]
</p><p>55 The (r i −r i )2 N i i distance between pairs of histograms is given by: χ2 (r1 , r2 ) = i=1 (ri1+ri2)/2 /(N − 1). [sent-95, score-0.331]
</p><p>56 1  2  In order to identify pairs (or small groups) of similar responses, we computed the normalized χ2 distance matrix over all pairs of responses, and used the complete-linkage algorithm to cluster the responses into 8 − 12 clusters. [sent-96, score-0.735]
</p><p>57 In order to obtain negative equivalence constraints, for each cluster ci we used the 2−3 furthest clusters from it to deﬁne negative constraints. [sent-98, score-0.247]
</p><p>58 Distance learning method In this paper, we use the DistBoost algorithm [7], which is a semi-supervised boosting learning algorithm that learns a distance function using unlabeled datapoints and equivalence constraints. [sent-100, score-0.347]
</p><p>59 Evaluation methods In order to evaluate the quality of the learned distance function, we measured the correlation between the distances computed by our distance learning algorithm to those induced by the χ2 distance over the responses. [sent-103, score-0.704]
</p><p>60 For each stimulus we measured the distances to all other stimuli using the learnt distance function. [sent-104, score-0.981]
</p><p>61 We then computed the rank-order (Spearman) correlation coefﬁcient between these learnt distances in the stimulus domain and the χ2 distances between the appropriate responses. [sent-105, score-0.583]
</p><p>62 This procedure produced a single correlation coefﬁcient for each of the 32 stimuli, and the average correlation coefﬁcient across all stimuli was used as the overall performance measure. [sent-106, score-0.631]
</p><p>63 The optimal cell speciﬁc parameters were determined using this approach. [sent-111, score-0.273]
</p><p>64 , xn ), xk ∈ X A set of equivalence constraints: (xi1 , xi2 , yi ), where yi ∈ {−1, 1} Unlabeled pairs of points: (xi1 , xi2 , yi = ∗), implicitly deﬁned by all unconstrained pairs of points 1 • Initialize Wi1 i2 = 1/(n2 ) i1 , i2 = 1, . [sent-115, score-0.432]
</p><p>65 Generate a weak “ hypothesis ht :” X × X → [−1, 1] and deﬁne a weak distance function as 1 ˜ ht (xi , xj ) = 2 1 − ht (xi , xj ) ∈ [0, 1] 3. [sent-126, score-0.519]
</p><p>66 In each run, we removed a single stimulus from the dataset, trained our algorithm on the remaining 31 stimuli, and then tested its performance on the datapoint that was left out (see Fig. [sent-140, score-0.298]
</p><p>67 As can be seen, on some cells our algorithm obtains correlations that are as high as 0. [sent-143, score-0.227]
</p><p>68 41, while for other cells the average test correlation is less then 0. [sent-144, score-0.286]
</p><p>69 Boosting the performance of weak cells In order to boost the performance of cells with low average correlations, we constructed the following experiment: We clustered the responses of each cell, using the complete-linkage algorithm over the χ2 distances with 4 1 clusters. [sent-156, score-0.791]
</p><p>70 This measure was used to identify pairs of cells whose partition of the stimuli was most similar to each other. [sent-159, score-0.675]
</p><p>71 In our experiment we took the four cells with the lowest  Cell 13  All cells  Cell 18  30  30  25  25  20  20  15  15  10  10  5 −1  −0. [sent-160, score-0.284]
</p><p>72 The  Mean Test Rank−Order Correlation  rank-order correlations were computed between the learnt distances and the distances between the recorded responses for each single stimulus (N = 22 ∗ 32). [sent-167, score-0.918]
</p><p>73 The distribution of train and test correlations is displayed as histograms on the top and on the right respectively. [sent-191, score-0.266]
</p><p>74 Right: Test rankorder correlations when training using constraints extracted from each cell separately, and when using the intersection of the constraints extracted from a pair of cells. [sent-192, score-0.589]
</p><p>75 This procedure always improves the performance of the weaker cell, and usually also improves the performance of the stronger cell 1 performance (right column of Fig 3), and for each of them used the F 2 score to retrieve the most similar cell. [sent-193, score-0.369]
</p><p>76 For each of these pairs, we trained our algorithm once more, using the constraints obtained by intersecting the constraints derived from the two cells in the pair, in the LOU paradigm. [sent-194, score-0.34]
</p><p>77 Interestingly and counter-intuitively, when training the better performing cell in each pair using the intersection of its constraints with those from the poorly performing cell, results deteriorated only for one of the four better performing cells. [sent-197, score-0.379]
</p><p>78 Stimulus classiﬁcation The cross-validation results induced a partition of the stimulus space into narrowband and wideband stimuli. [sent-198, score-0.516]
</p><p>79 We measured the predictability of each stimulus by averaging the LOU test results obtained for the stimulus across all cells (see Fig. [sent-199, score-0.754]
</p><p>80 Our analysis shows that wideband stimuli are more predictable than narrowband stimuli, despite the fact that the neuronal responses to these two groups are not different as a whole. [sent-201, score-1.19]
</p><p>81 5  Discussion  In the standard approach to auditory modeling, a linear or weakly non-linear model is ﬁtted to the data, and neuronal properties are read from the resulting model. [sent-203, score-0.468]
</p><p>82 The usefulness of this approach is limited however by the weak predictability of A1 responses when using such models. [sent-204, score-0.496]
</p><p>83 5  1  1  Figure 3: Histograms of cell speciﬁc test rank-order correlations for the 22 cells in the dataset. [sent-251, score-0.545]
</p><p>84 The rank-order correlations compare the predicted distances to the distances between the recorded responses, measured on a single stimulus which was left out during the training stage. [sent-252, score-0.612]
</p><p>85 For visualization purposes, cells are ordered (columns) by their average test correlation per stimulus in descending order. [sent-253, score-0.511]
</p><p>86 We use the neural data as a guide for training a highly non-linear distance function on stimulus space, which is compatible with the neural responses. [sent-256, score-0.419]
</p><p>87 First, we demonstrated that we can improve the test performance of a distance function by using constraints on the similarity or dissimilarity between stimuli derived from the responses of multiple neurons. [sent-259, score-1.046]
</p><p>88 Thus, it is possible that intersecting constraints derived from multiple neurons uncover regularities that are hard to extract from individual neurons. [sent-261, score-0.278]
</p><p>89 Second, it turned out that some stimuli consistently behaved better than others across the neuronal population. [sent-262, score-0.559]
</p><p>90 This difference was correlated with the acoustic structure of the stimuli: those stimuli that contained the weak background component (wideband stimuli) were generally predicted better. [sent-263, score-0.64]
</p><p>91 This result is surprising both because background component is substantially weaker than the other acoustic components in the stimuli (by as much as 35-40 dB). [sent-264, score-0.567]
</p><p>92 It may mean that the relationships between physical structure (as characterized by the Cepstral parameters) and the neuronal responses becomes simpler in the presence of the background component, but is much more idiosyncratic when this component is absent. [sent-265, score-0.539]
</p><p>93 This result underscores the importance of interactions between narrow and wideband stimuli for understanding the complexity of cortical processing. [sent-266, score-0.767]
</p><p>94 One major problem during an experiment is that of stimulus selection: choosing the best set of stimuli for characterizing the responses of a neuron. [sent-269, score-0.998]
</p><p>95 The predictability of wideband stimuli is clearly better than that of the narrowband stimuli. [sent-287, score-0.808]
</p><p>96 ﬁnd surprising stimuli: either stimuli that are very different in terms of physical structure but that would result in responses that are similar to those already measured, or stimuli that are very similar to already tested stimuli but that are predicted to give rise to very different responses. [sent-288, score-1.676]
</p><p>97 Group redundancy measures reveal redundancy reduction in the auditory pathway. [sent-313, score-0.287]
</p><p>98 Analysis of dynamic spectra in ferret primary auditory cortex. [sent-357, score-0.365]
</p><p>99 Processing of complex stimuli and natural scenes in the auditory cortex. [sent-394, score-0.765]
</p><p>100 Relating cluster and population responses to natural sounds and tonal stimuli in cat primary auditory cortex. [sent-400, score-1.323]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('stimuli', 0.433), ('responses', 0.34), ('auditory', 0.287), ('cell', 0.273), ('stimulus', 0.225), ('strfs', 0.19), ('wideband', 0.165), ('distance', 0.159), ('neurons', 0.151), ('cells', 0.142), ('cortical', 0.132), ('equivalence', 0.127), ('narrowband', 0.126), ('neuronal', 0.126), ('pairs', 0.1), ('correlation', 0.099), ('distances', 0.095), ('neuron', 0.088), ('correlations', 0.085), ('distboost', 0.084), ('lou', 0.084), ('predictability', 0.084), ('strf', 0.084), ('khz', 0.078), ('sounds', 0.078), ('histograms', 0.072), ('weak', 0.072), ('ht', 0.072), ('constraints', 0.069), ('acoustic', 0.067), ('receptive', 0.064), ('train', 0.064), ('characterizations', 0.063), ('chirps', 0.063), ('spectrotemporal', 0.063), ('tonal', 0.063), ('neurophysiol', 0.062), ('response', 0.054), ('characterization', 0.053), ('fields', 0.051), ('ms', 0.051), ('bird', 0.047), ('test', 0.045), ('natural', 0.045), ('cepstral', 0.042), ('datapoint', 0.042), ('depireux', 0.042), ('evoke', 0.042), ('idiosyncratic', 0.042), ('machens', 0.042), ('psths', 0.042), ('rotman', 0.042), ('ste', 0.042), ('recorded', 0.042), ('primary', 0.041), ('frequency', 0.039), ('intersection', 0.037), ('narrow', 0.037), ('elicit', 0.037), ('ferret', 0.037), ('predicted', 0.037), ('cluster', 0.036), ('weaker', 0.036), ('learnt', 0.036), ('bin', 0.035), ('compatible', 0.035), ('power', 0.034), ('cats', 0.033), ('responded', 0.033), ('echoes', 0.033), ('rt', 0.033), ('measured', 0.033), ('domain', 0.033), ('clusters', 0.032), ('trained', 0.031), ('blake', 0.031), ('datapoints', 0.031), ('extracellular', 0.031), ('background', 0.031), ('improves', 0.03), ('boosting', 0.03), ('intersecting', 0.029), ('uncover', 0.029), ('predictive', 0.029), ('partitions', 0.029), ('extracted', 0.028), ('cortex', 0.028), ('sensory', 0.028), ('neurobiology', 0.028), ('weakly', 0.028), ('histogram', 0.028), ('coef', 0.028), ('points', 0.027), ('read', 0.027), ('band', 0.027), ('hertz', 0.027), ('yi', 0.026), ('modulation', 0.026), ('perturbations', 0.026), ('negative', 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="28-tfidf-1" href="./nips-2005-Analyzing_Auditory_Neurons_by_Learning_Distance_Functions.html">28 nips-2005-Analyzing Auditory Neurons by Learning Distance Functions</a></p>
<p>Author: Inna Weiner, Tomer Hertz, Israel Nelken, Daphna Weinshall</p><p>Abstract: We present a novel approach to the characterization of complex sensory neurons. One of the main goals of characterizing sensory neurons is to characterize dimensions in stimulus space to which the neurons are highly sensitive (causing large gradients in the neural responses) or alternatively dimensions in stimulus space to which the neuronal response are invariant (deﬁning iso-response manifolds). We formulate this problem as that of learning a geometry on stimulus space that is compatible with the neural responses: the distance between stimuli should be large when the responses they evoke are very different, and small when the responses they evoke are similar. Here we show how to successfully train such distance functions using rather limited amount of information. The data consisted of the responses of neurons in primary auditory cortex (A1) of anesthetized cats to 32 stimuli derived from natural sounds. For each neuron, a subset of all pairs of stimuli was selected such that the responses of the two stimuli in a pair were either very similar or very dissimilar. The distance function was trained to ﬁt these constraints. The resulting distance functions generalized to predict the distances between the responses of a test stimulus and the trained stimuli. 1</p><p>2 0.21197939 <a title="28-tfidf-2" href="./nips-2005-Learning_Cue-Invariant_Visual_Responses.html">109 nips-2005-Learning Cue-Invariant Visual Responses</a></p>
<p>Author: Jarmo Hurri</p><p>Abstract: Multiple visual cues are used by the visual system to analyze a scene; achromatic cues include luminance, texture, contrast and motion. Singlecell recordings have shown that the mammalian visual cortex contains neurons that respond similarly to scene structure (e.g., orientation of a boundary), regardless of the cue type conveying this information. This paper shows that cue-invariant response properties of simple- and complex-type cells can be learned from natural image data in an unsupervised manner. In order to do this, we also extend a previous conceptual model of cue invariance so that it can be applied to model simple- and complex-cell responses. Our results relate cue-invariant response properties to natural image statistics, thereby showing how the statistical modeling approach can be used to model processing beyond the elemental response properties visual neurons. This work also demonstrates how to learn, from natural image data, more sophisticated feature detectors than those based on changes in mean luminance, thereby paving the way for new data-driven approaches to image processing and computer vision. 1</p><p>3 0.14825793 <a title="28-tfidf-3" href="./nips-2005-An_aVLSI_Cricket_Ear_Model.html">25 nips-2005-An aVLSI Cricket Ear Model</a></p>
<p>Author: Andre V. Schaik, Richard Reeve, Craig Jin, Tara Hamilton</p><p>Abstract: Female crickets can locate males by phonotaxis to the mating song they produce. The behaviour and underlying physiology has been studied in some depth showing that the cricket auditory system solves this complex problem in a unique manner. We present an analogue very large scale integrated (aVLSI) circuit model of this process and show that results from testing the circuit agree with simulation and what is known from the behaviour and physiology of the cricket auditory system. The aVLSI circuitry is now being extended to use on a robot along with previously modelled neural circuitry to better understand the complete sensorimotor pathway. 1 In trod u ction Understanding how insects carry out complex sensorimotor tasks can help in the design of simple sensory and robotic systems. Often insect sensors have evolved into intricate filters matched to extract highly specific data from the environment which solves a particular problem directly with little or no need for further processing [1]. Examples include head stabilisation in the fly, which uses vision amongst other senses to estimate self-rotation and thus to stabilise its head in flight, and phonotaxis in the cricket. Because of the narrowness of the cricket body (only a few millimetres), the Interaural Time Difference (ITD) for sounds arriving at the two sides of the head is very small (10–20µs). Even with the tympanal membranes (eardrums) located, as they are, on the forelegs of the cricket, the ITD only reaches about 40µs, which is too low to detect directly from timings of neural spikes. Because the wavelength of the cricket calling song is significantly greater than the width of the cricket body the Interaural Intensity Difference (IID) is also very low. In the absence of ITD or IID information, the cricket uses phase to determine direction. This is possible because the male cricket produces an almost pure tone for its calling song. * School of Electrical and Information Engineering, Institute of Perception, Action and Behaviour. + Figure 1: The cricket auditory system. Four acoustic inputs channel sounds directly or through tracheal tubes onto two tympanal membranes. Sound from contralateral inputs has to pass a (double) central membrane (the medial septum), inducing a phase delay and reduction in gain. The sound transmission from the contralateral tympanum is very weak, making each eardrum effectively a 3 input system. The physics of the cricket auditory system is well understood [2]; the system (see Figure 1) uses a pair of sound receivers with four acoustic inputs, two on the forelegs, which are the external surfaces of the tympana, and two on the body, the prothoracic or acoustic spiracles [3]. The connecting tracheal tubes are such that interference occurs as sounds travel inside the cricket, producing a directional response at the tympana to frequencies near to that of the calling song. The amplitude of vibration of the tympana, and hence the firing rate of the auditory afferent neurons attached to them, vary as a sound source is moved around the cricket and the sounds from the different inputs move in and out of phase. The outputs of the two tympana match when the sound is straight ahead, and the inputs are bilaterally symmetric with respect to the sound source. However, when sound at the calling song frequency is off-centre the phase of signals on the closer side comes better into alignment, and the signal increases on that side, and conversely decreases on the other. It is that crossover of tympanal vibration amplitudes which allows the cricket to track a sound source (see Figure 6 for example). A simplified version of the auditory system using only two acoustic inputs was implemented in hardware [4], and a simple 8-neuron network was all that was required to then direct a robot to carry out phonotaxis towards a species-specific calling song [5]. A simple simulator was also created to model the behaviour of the auditory system of Figure 1 at different frequencies [6]. Data from Michelsen et al. [2] (Figures 5 and 6) were digitised, and used together with average and “typical” values from the paper to choose gains and delays for the simulation. Figure 2 shows the model of the internal auditory system of the cricket from sound arriving at the acoustic inputs through to transmission down auditory receptor fibres. The simulator implements this model up to the summing of the delayed inputs, as well as modelling the external sound transmission. Results from the simulator were used to check the directionality of the system at different frequencies, and to gain a better understanding of its response. It was impractical to check the effect of leg movements or of complex sounds in the simulator due to the necessity of simulating the sound production and transmission. An aVLSI chip was designed to implement the same model, both allowing more complex experiments, such as leg movements to be run, and experiments to be run in the real world. Figure 2: A model of the auditory system of the cricket, used to build the simulator and the aVLSI implementation (shown in boxes). These experiments with the simulator and the circuits are being published in [6] and the reader is referred to those papers for more details. In the present paper we present the details of the circuits used for the aVLSI implementation. 2 Circuits The chip, implementing the aVLSI box in Figure 2, comprises two all-pass delay filters, three gain circuits, a second-order narrow-band band-pass filter, a first-order wide-band band-pass filter, a first-order high-pass filter, as well as supporting circuitry (including reference voltages, currents, etc.). A single aVLSI chip (MOSIS tiny-chip) thus includes half the necessary circuitry to model the complete auditory system of a cricket. The complete model of the auditory system can be obtained by using two appropriately connected chips. Only two all-pass delay filters need to be implemented instead of three as suggested by Figure 2, because it is only the relative delay between the three pathways arriving at the one summing node that counts. The delay circuits were implemented with fully-differential gm-C filters. In order to extend the frequency range of the delay, a first-order all-pass delay circuit was cascaded with a second-order all-pass delay circuit. The resulting addition of the first-order delay and the second-order delay allowed for an approximately flat delay response for a wider bandwidth as the decreased delay around the corner frequency of the first-order filter cancelled with the increased delay of the second-order filter around its resonant frequency. Figure 3 shows the first- and second-order sections of the all-pass delay circuit. Two of these circuits were used and, based on data presented in [2], were designed with delays of 28µs and 62µs, by way of bias current manipulation. The operational transconductance amplifier (OTA) in figure 3 is a standard OTA which includes the common-mode feedback necessary for fully differential designs. The buffers (Figure 3) are simple, cascoded differential pairs. V+ V- II+ V+ V- II+ V+ V- II+ V+ V- II+ V+ V- II+ V+ V- II+ Figure 3: The first-order all-pass delay circuit (left) and the second-order all-pass delay (right). The differential output of the delay circuits is converted into a current which is multiplied by a variable gain implemented as shown in Figure 4. The gain cell includes a differential pair with source degeneration via transistors N4 and N5. The source degeneration improves the linearity of the current. The three gain cells implemented on the aVLSI have default gains of 2, 3 and 0.91 which are set by holding the default input high and appropriately ratioing the bias currents through the value of vbiasp. To correct any on-chip mismatches and/or explore other gain configurations a current splitter cell [7] (p-splitter, figure 4) allows the gain to be programmed by digital means post fabrication. The current splitter takes an input current (Ibias, figure 4) and divides it into branches which recursively halve the current, i.e., the first branch gives ½ Ibias, the second branch ¼ Ibias, the third branch 1/8 Ibias and so on. These currents can be used together with digitally controlled switches as a Digital-to-Analogue converter. By holding default low and setting C5:C0 appropriately, any gain – from 4 to 0.125 – can be set. To save on output pins the program bits (C5:C0) for each of the three gain cells are set via a single 18-bit shift register in bit-serial fashion. Summing the output of the three gain circuits in the current domain simply involves connecting three wires together. Therefore, a natural option for the filters that follow is to use current domain filters. In our case we have chosen to implement log-domain filters using MOS transistors operating in weak inversion. Figure 5 shows the basic building blocks for the filters – the Tau Cell [8] and the multiplier cell – and block diagrams showing how these blocks were connected to create the necessary filtering blocks. The Tau Cell is a log-domain filter which has the firstorder response: I out 1 , = I in sτ + 1 where τ = nC aVT Ia and n = the slope factor, VT = thermal voltage, Ca = capacitance, and Ia = bias current. In figure 5, the input currents to the Tau Cell, Imult and A*Ia, are only used when building a second-order filter. The multiplier cell is simply a translinear loop where: I out1 ∗ I mult = I out 2 ∗ AI a or Imult = AIaIout2/Iout1. The configurations of the Tau Cell to get particular responses are covered in [8] along with the corresponding equations. The high frequency filter of Figure 2 is implemented by the high-pass filter in Figure 5 with a corner frequency of 17kHz. The low frequency filter, however, is divided into two parts since the biological filter’s response (see for example Figure 3A in [9]) separates well into a narrow second-order band-pass filter with a 10kHz resonant frequency and a wide band-pass filter made from a first-order high-pass filter with a 3kHz corner frequency followed by a first-order low-pass filter with a 12kHz corner frequency. These filters are then added together to reproduce the biological filter. The filters’ responses can be adjusted post fabrication via their bias currents. This allows for compensation due to processing and matching errors. Figure 4: The Gain Cell above is used to convert the differential voltage input from the delay cells into a single-ended current output. The gain of each cell is controllable via a programmable current cell (p_splitter). An on-chip bias generator [7] was used to create all the necessary current biases on the chip. All the main blocks (delays, gain cells and filters), however, can have their on-chip bias currents overridden through external pins on the chip. The chip was fabricated using the MOSIS AMI 1.6µm technology and designed using the Cadence Custom IC Design Tools (5.0.33). 3 Methods The chip was tested using sound generated on a computer and played through a soundcard to the chip. Responses from the chip were recorded by an oscilloscope, and uploaded back to the computer on completion. Given that the output from the chip and the gain circuits is a current, an external current-sense circuit built with discrete components was used to enable the output to be probed by the oscilloscope. Figure 5: The circuit diagrams for the log-domain filter building blocks – The Tau Cell and The Multiplier – along with the block diagrams for the three filters used in the aVLSI model. Initial experiments were performed to tune the delays and gains. After that, recordings were taken of the directional frequency responses. Sounds were generated by computer for each chip input to simulate moving the forelegs by delaying the sound by the appropriate amount of time; this was a much simpler solution than using microphones and moving them using motors. 4 Results The aVLSI chip was tested to measure its gains and delays, which were successfully tuned to the appropriate values. The chip was then compared with the simulation to check that it was faithfully modelling the system. A result of this test at 4kHz (approximately the cricket calling-song frequency) is shown in Figure 6. Apart from a drop in amplitude of the signal, the response of the circuit was very similar to that of the simulator. The differences were expected because the aVLSI circuit has to deal with real-world noise, whereas the simulated version has perfect signals. Examples of the gain versus frequency response of the two log-domain band-pass filters are shown in Figure 7. Note that the narrow-band filter peaks at 6kHz, which is significantly above the mating song frequency of the cricket which is around 4.5kHz. This is not a mistake, but is observed in real crickets as well. As stated in the introduction, a range of further testing results with both the circuit and the simulator are being published in [6]. 5 D i s c u s s i on The aVLSI auditory sensor in this research models the hearing of the field cricket Gryllus bimaculatus. It is a more faithful model of the cricket auditory system than was previously built in [4], reproducing all the acoustic inputs, as well as the responses to frequencies of both the co specific calling song and bat echolocation chirps. It also generates outputs corresponding to the two sets of behaviourally relevant auditory receptor fibres. Results showed that it matched the biological data well, though there were some inconsistencies due to an error in the specification that will be addressed in a future iteration of the design. A more complete implementation across all frequencies was impractical because of complexity and size issues as well as serving no clear behavioural purpose. Figure 6: Vibration amplitude of the left (dotted) and right (solid) virtual tympana measured in decibels in response to a 4kHz tone in simulation (left) and on the aVLSI chip (right). The plot shows the amplitude of the tympanal responses as the sound source is rotated around the cricket. Figure 7: Frequency-Gain curves for the narrow-band and wide-band bandpass filters. The long-term aim of this work is to better understand simple sensorimotor control loops in crickets and other insects. The next step is to mount this circuitry on a robot to carry out behavioural experiments, which we will compare with existing and new behavioural data (such as that in [10]). This will allow us to refine our models of the neural circuitry involved. Modelling the sensory afferent neurons in hardware is necessary in order to reduce processor load on our robot, so the next revision will include these either onboard, or on a companion chip as we have done before [11]. We will also move both sides of the auditory system onto a single chip to conserve space on the robot. It is our belief and experience that, as a result of this intelligent pre-processing carried out at the sensor level, the neural circuits necessary to accurately model the behaviour will remain simple. Acknowledgments The authors thank the Institute of Neuromorphic Engineering and the UK Biotechnology and Biological Sciences Research Council for funding the research in this paper. References [1] R. Wehner. Matched ﬁlters – neural models of the external world. J Comp Physiol A, 161: 511–531, 1987. [2] A. Michelsen, A. V. Popov, and B. Lewis. Physics of directional hearing in the cricket Gryllus bimaculatus. Journal of Comparative Physiology A, 175:153–164, 1994. [3] A. Michelsen. The tuned cricket. News Physiol. Sci., 13:32–38, 1998. [4] H. H. Lund, B. Webb, and J. Hallam. A robot attracted to the cricket species Gryllus bimaculatus. In P. Husbands and I. Harvey, editors, Proceedings of 4th European Conference on Artiﬁcial Life, pages 246–255. MIT Press/Bradford Books, MA., 1997. [5] R Reeve and B. Webb. New neural circuits for robot phonotaxis. Phil. Trans. R. Soc. Lond. A, 361:2245–2266, August 2003. [6] R. Reeve, A. van Schaik, C. Jin, T. Hamilton, B. Torben-Nielsen and B. Webb Directional hearing in a silicon cricket. Biosystems, (in revision), 2005b [7] T. Delbrück and A. van Schaik, Bias Current Generators with Wide Dynamic Range, Analog Integrated Circuits and Signal Processing 42(2), 2005 [8] A. van Schaik and C. Jin, The Tau Cell: A New Method for the Implementation of Arbitrary Differential Equations, IEEE International Symposium on Circuits and Systems (ISCAS) 2003 [9] Kazuo Imaizumi and Gerald S. Pollack. Neural coding of sound frequency by cricket auditory receptors. The Journal of Neuroscience, 19(4):1508– 1516, 1999. [10] Berthold Hedwig and James F.A. Poulet. Complex auditory behaviour emerges from simple reactive steering. Nature, 430:781–785, 2004. [11] R. Reeve, B. Webb, A. Horchler, G. Indiveri, and R. Quinn. New technologies for testing a model of cricket phonotaxis on an outdoor robot platform. Robotics and Autonomous Systems, 51(1):41-54, 2005.</p><p>4 0.14449938 <a title="28-tfidf-4" href="./nips-2005-Identifying_Distributed_Object_Representations_in_Human_Extrastriate_Visual_Cortex.html">94 nips-2005-Identifying Distributed Object Representations in Human Extrastriate Visual Cortex</a></p>
<p>Author: Rory Sayres, David Ress, Kalanit Grill-spector</p><p>Abstract: The category of visual stimuli has been reliably decoded from patterns of neural activity in extrastriate visual cortex [1]. It has yet to be seen whether object identity can be inferred from this activity. We present fMRI data measuring responses in human extrastriate cortex to a set of 12 distinct object images. We use a simple winner-take-all classifier, using half the data from each recording session as a training set, to evaluate encoding of object identity across fMRI voxels. Since this approach is sensitive to the inclusion of noisy voxels, we describe two methods for identifying subsets of voxels in the data which optimally distinguish object identity. One method characterizes the reliability of each voxel within subsets of the data, while another estimates the mutual information of each voxel with the stimulus set. We find that both metrics can identify subsets of the data which reliably encode object identity, even when noisy measurements are artificially added to the data. The mutual information metric is less efficient at this task, likely due to constraints in fMRI data. 1</p><p>5 0.13750961 <a title="28-tfidf-5" href="./nips-2005-Neural_mechanisms_of_contrast_dependent_receptive_field_size_in_V1.html">134 nips-2005-Neural mechanisms of contrast dependent receptive field size in V1</a></p>
<p>Author: Jim Wielaard, Paul Sajda</p><p>Abstract: Based on a large scale spiking neuron model of the input layers 4Cα and β of macaque, we identify neural mechanisms for the observed contrast dependent receptive ﬁeld size of V1 cells. We observe a rich variety of mechanisms for the phenomenon and analyze them based on the relative gain of excitatory and inhibitory synaptic inputs. We observe an average growth in the spatial extent of excitation and inhibition for low contrast, as predicted from phenomenological models. However, contrary to phenomenological models, our simulation results suggest this is neither sufﬁcient nor necessary to explain the phenomenon.</p><p>6 0.10804006 <a title="28-tfidf-6" href="./nips-2005-Visual_Encoding_with_Jittering_Eyes.html">203 nips-2005-Visual Encoding with Jittering Eyes</a></p>
<p>7 0.10688017 <a title="28-tfidf-7" href="./nips-2005-Spiking_Inputs_to_a_Winner-take-all_Network.html">181 nips-2005-Spiking Inputs to a Winner-take-all Network</a></p>
<p>8 0.10687026 <a title="28-tfidf-8" href="./nips-2005-Integrate-and-Fire_models_with_adaptation_are_good_enough.html">99 nips-2005-Integrate-and-Fire models with adaptation are good enough</a></p>
<p>9 0.10633906 <a title="28-tfidf-9" href="./nips-2005-Modeling_Neural_Population_Spiking_Activity_with_Gibbs_Distributions.html">129 nips-2005-Modeling Neural Population Spiking Activity with Gibbs Distributions</a></p>
<p>10 0.10582394 <a title="28-tfidf-10" href="./nips-2005-Norepinephrine_and_Neural_Interrupts.html">141 nips-2005-Norepinephrine and Neural Interrupts</a></p>
<p>11 0.09137699 <a title="28-tfidf-11" href="./nips-2005-A_Criterion_for_the_Convergence_of_Learning_with_Spike_Timing_Dependent_Plasticity.html">8 nips-2005-A Criterion for the Convergence of Learning with Spike Timing Dependent Plasticity</a></p>
<p>12 0.08657968 <a title="28-tfidf-12" href="./nips-2005-Principles_of_real-time_computing_with_feedback_applied_to_cortical_microcircuit_models.html">157 nips-2005-Principles of real-time computing with feedback applied to cortical microcircuit models</a></p>
<p>13 0.077885695 <a title="28-tfidf-13" href="./nips-2005-An_exploration-exploitation_model_based_on_norepinepherine_and_dopamine_activity.html">26 nips-2005-An exploration-exploitation model based on norepinepherine and dopamine activity</a></p>
<p>14 0.075865701 <a title="28-tfidf-14" href="./nips-2005-Efficient_estimation_of_hidden_state_dynamics_from_spike_trains.html">64 nips-2005-Efficient estimation of hidden state dynamics from spike trains</a></p>
<p>15 0.074854389 <a title="28-tfidf-15" href="./nips-2005-Distance_Metric_Learning_for_Large_Margin_Nearest_Neighbor_Classification.html">57 nips-2005-Distance Metric Learning for Large Margin Nearest Neighbor Classification</a></p>
<p>16 0.074738376 <a title="28-tfidf-16" href="./nips-2005-Representing_Part-Whole_Relationships_in_Recurrent_Neural_Networks.html">164 nips-2005-Representing Part-Whole Relationships in Recurrent Neural Networks</a></p>
<p>17 0.074163795 <a title="28-tfidf-17" href="./nips-2005-Measuring_Shared_Information_and_Coordinated_Activity_in_Neuronal_Networks.html">124 nips-2005-Measuring Shared Information and Coordinated Activity in Neuronal Networks</a></p>
<p>18 0.073478118 <a title="28-tfidf-18" href="./nips-2005-Silicon_growth_cones_map_silicon_retina.html">176 nips-2005-Silicon growth cones map silicon retina</a></p>
<p>19 0.07261233 <a title="28-tfidf-19" href="./nips-2005-Nonparametric_inference_of_prior_probabilities_from_Bayes-optimal_behavior.html">140 nips-2005-Nonparametric inference of prior probabilities from Bayes-optimal behavior</a></p>
<p>20 0.072134569 <a title="28-tfidf-20" href="./nips-2005-Extracting_Dynamical_Structure_Embedded_in_Neural_Activity.html">67 nips-2005-Extracting Dynamical Structure Embedded in Neural Activity</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2005_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.209), (1, -0.195), (2, -0.056), (3, 0.061), (4, -0.042), (5, 0.101), (6, -0.019), (7, -0.166), (8, -0.072), (9, 0.079), (10, -0.07), (11, -0.103), (12, -0.057), (13, -0.109), (14, -0.092), (15, 0.019), (16, 0.205), (17, -0.048), (18, -0.17), (19, 0.182), (20, -0.082), (21, 0.185), (22, 0.064), (23, -0.049), (24, -0.029), (25, -0.034), (26, -0.023), (27, -0.072), (28, -0.002), (29, -0.009), (30, -0.056), (31, 0.012), (32, 0.136), (33, -0.001), (34, 0.014), (35, 0.03), (36, 0.17), (37, 0.108), (38, -0.002), (39, 0.094), (40, -0.04), (41, 0.063), (42, 0.064), (43, -0.057), (44, -0.06), (45, -0.022), (46, -0.059), (47, -0.116), (48, 0.044), (49, 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98218226 <a title="28-lsi-1" href="./nips-2005-Analyzing_Auditory_Neurons_by_Learning_Distance_Functions.html">28 nips-2005-Analyzing Auditory Neurons by Learning Distance Functions</a></p>
<p>Author: Inna Weiner, Tomer Hertz, Israel Nelken, Daphna Weinshall</p><p>Abstract: We present a novel approach to the characterization of complex sensory neurons. One of the main goals of characterizing sensory neurons is to characterize dimensions in stimulus space to which the neurons are highly sensitive (causing large gradients in the neural responses) or alternatively dimensions in stimulus space to which the neuronal response are invariant (deﬁning iso-response manifolds). We formulate this problem as that of learning a geometry on stimulus space that is compatible with the neural responses: the distance between stimuli should be large when the responses they evoke are very different, and small when the responses they evoke are similar. Here we show how to successfully train such distance functions using rather limited amount of information. The data consisted of the responses of neurons in primary auditory cortex (A1) of anesthetized cats to 32 stimuli derived from natural sounds. For each neuron, a subset of all pairs of stimuli was selected such that the responses of the two stimuli in a pair were either very similar or very dissimilar. The distance function was trained to ﬁt these constraints. The resulting distance functions generalized to predict the distances between the responses of a test stimulus and the trained stimuli. 1</p><p>2 0.70293766 <a title="28-lsi-2" href="./nips-2005-Learning_Cue-Invariant_Visual_Responses.html">109 nips-2005-Learning Cue-Invariant Visual Responses</a></p>
<p>Author: Jarmo Hurri</p><p>Abstract: Multiple visual cues are used by the visual system to analyze a scene; achromatic cues include luminance, texture, contrast and motion. Singlecell recordings have shown that the mammalian visual cortex contains neurons that respond similarly to scene structure (e.g., orientation of a boundary), regardless of the cue type conveying this information. This paper shows that cue-invariant response properties of simple- and complex-type cells can be learned from natural image data in an unsupervised manner. In order to do this, we also extend a previous conceptual model of cue invariance so that it can be applied to model simple- and complex-cell responses. Our results relate cue-invariant response properties to natural image statistics, thereby showing how the statistical modeling approach can be used to model processing beyond the elemental response properties visual neurons. This work also demonstrates how to learn, from natural image data, more sophisticated feature detectors than those based on changes in mean luminance, thereby paving the way for new data-driven approaches to image processing and computer vision. 1</p><p>3 0.68282861 <a title="28-lsi-3" href="./nips-2005-Identifying_Distributed_Object_Representations_in_Human_Extrastriate_Visual_Cortex.html">94 nips-2005-Identifying Distributed Object Representations in Human Extrastriate Visual Cortex</a></p>
<p>Author: Rory Sayres, David Ress, Kalanit Grill-spector</p><p>Abstract: The category of visual stimuli has been reliably decoded from patterns of neural activity in extrastriate visual cortex [1]. It has yet to be seen whether object identity can be inferred from this activity. We present fMRI data measuring responses in human extrastriate cortex to a set of 12 distinct object images. We use a simple winner-take-all classifier, using half the data from each recording session as a training set, to evaluate encoding of object identity across fMRI voxels. Since this approach is sensitive to the inclusion of noisy voxels, we describe two methods for identifying subsets of voxels in the data which optimally distinguish object identity. One method characterizes the reliability of each voxel within subsets of the data, while another estimates the mutual information of each voxel with the stimulus set. We find that both metrics can identify subsets of the data which reliably encode object identity, even when noisy measurements are artificially added to the data. The mutual information metric is less efficient at this task, likely due to constraints in fMRI data. 1</p><p>4 0.65877581 <a title="28-lsi-4" href="./nips-2005-Visual_Encoding_with_Jittering_Eyes.html">203 nips-2005-Visual Encoding with Jittering Eyes</a></p>
<p>Author: Michele Rucci</p><p>Abstract: Under natural viewing conditions, small movements of the eye and body prevent the maintenance of a steady direction of gaze. It is known that stimuli tend to fade when they are stabilized on the retina for several seconds. However, it is unclear whether the physiological self-motion of the retinal image serves a visual purpose during the brief periods of natural visual ﬁxation. This study examines the impact of ﬁxational instability on the statistics of visual input to the retina and on the structure of neural activity in the early visual system. Fixational instability introduces ﬂuctuations in the retinal input signals that, in the presence of natural images, lack spatial correlations. These input ﬂuctuations strongly inﬂuence neural activity in a model of the LGN. They decorrelate cell responses, even if the contrast sensitivity functions of simulated cells are not perfectly tuned to counter-balance the power-law spectrum of natural images. A decorrelation of neural activity has been proposed to be beneﬁcial for discarding statistical redundancies in the input signals. Fixational instability might, therefore, contribute to establishing efﬁcient representations of natural stimuli. 1</p><p>5 0.58024347 <a title="28-lsi-5" href="./nips-2005-An_aVLSI_Cricket_Ear_Model.html">25 nips-2005-An aVLSI Cricket Ear Model</a></p>
<p>Author: Andre V. Schaik, Richard Reeve, Craig Jin, Tara Hamilton</p><p>Abstract: Female crickets can locate males by phonotaxis to the mating song they produce. The behaviour and underlying physiology has been studied in some depth showing that the cricket auditory system solves this complex problem in a unique manner. We present an analogue very large scale integrated (aVLSI) circuit model of this process and show that results from testing the circuit agree with simulation and what is known from the behaviour and physiology of the cricket auditory system. The aVLSI circuitry is now being extended to use on a robot along with previously modelled neural circuitry to better understand the complete sensorimotor pathway. 1 In trod u ction Understanding how insects carry out complex sensorimotor tasks can help in the design of simple sensory and robotic systems. Often insect sensors have evolved into intricate filters matched to extract highly specific data from the environment which solves a particular problem directly with little or no need for further processing [1]. Examples include head stabilisation in the fly, which uses vision amongst other senses to estimate self-rotation and thus to stabilise its head in flight, and phonotaxis in the cricket. Because of the narrowness of the cricket body (only a few millimetres), the Interaural Time Difference (ITD) for sounds arriving at the two sides of the head is very small (10–20µs). Even with the tympanal membranes (eardrums) located, as they are, on the forelegs of the cricket, the ITD only reaches about 40µs, which is too low to detect directly from timings of neural spikes. Because the wavelength of the cricket calling song is significantly greater than the width of the cricket body the Interaural Intensity Difference (IID) is also very low. In the absence of ITD or IID information, the cricket uses phase to determine direction. This is possible because the male cricket produces an almost pure tone for its calling song. * School of Electrical and Information Engineering, Institute of Perception, Action and Behaviour. + Figure 1: The cricket auditory system. Four acoustic inputs channel sounds directly or through tracheal tubes onto two tympanal membranes. Sound from contralateral inputs has to pass a (double) central membrane (the medial septum), inducing a phase delay and reduction in gain. The sound transmission from the contralateral tympanum is very weak, making each eardrum effectively a 3 input system. The physics of the cricket auditory system is well understood [2]; the system (see Figure 1) uses a pair of sound receivers with four acoustic inputs, two on the forelegs, which are the external surfaces of the tympana, and two on the body, the prothoracic or acoustic spiracles [3]. The connecting tracheal tubes are such that interference occurs as sounds travel inside the cricket, producing a directional response at the tympana to frequencies near to that of the calling song. The amplitude of vibration of the tympana, and hence the firing rate of the auditory afferent neurons attached to them, vary as a sound source is moved around the cricket and the sounds from the different inputs move in and out of phase. The outputs of the two tympana match when the sound is straight ahead, and the inputs are bilaterally symmetric with respect to the sound source. However, when sound at the calling song frequency is off-centre the phase of signals on the closer side comes better into alignment, and the signal increases on that side, and conversely decreases on the other. It is that crossover of tympanal vibration amplitudes which allows the cricket to track a sound source (see Figure 6 for example). A simplified version of the auditory system using only two acoustic inputs was implemented in hardware [4], and a simple 8-neuron network was all that was required to then direct a robot to carry out phonotaxis towards a species-specific calling song [5]. A simple simulator was also created to model the behaviour of the auditory system of Figure 1 at different frequencies [6]. Data from Michelsen et al. [2] (Figures 5 and 6) were digitised, and used together with average and “typical” values from the paper to choose gains and delays for the simulation. Figure 2 shows the model of the internal auditory system of the cricket from sound arriving at the acoustic inputs through to transmission down auditory receptor fibres. The simulator implements this model up to the summing of the delayed inputs, as well as modelling the external sound transmission. Results from the simulator were used to check the directionality of the system at different frequencies, and to gain a better understanding of its response. It was impractical to check the effect of leg movements or of complex sounds in the simulator due to the necessity of simulating the sound production and transmission. An aVLSI chip was designed to implement the same model, both allowing more complex experiments, such as leg movements to be run, and experiments to be run in the real world. Figure 2: A model of the auditory system of the cricket, used to build the simulator and the aVLSI implementation (shown in boxes). These experiments with the simulator and the circuits are being published in [6] and the reader is referred to those papers for more details. In the present paper we present the details of the circuits used for the aVLSI implementation. 2 Circuits The chip, implementing the aVLSI box in Figure 2, comprises two all-pass delay filters, three gain circuits, a second-order narrow-band band-pass filter, a first-order wide-band band-pass filter, a first-order high-pass filter, as well as supporting circuitry (including reference voltages, currents, etc.). A single aVLSI chip (MOSIS tiny-chip) thus includes half the necessary circuitry to model the complete auditory system of a cricket. The complete model of the auditory system can be obtained by using two appropriately connected chips. Only two all-pass delay filters need to be implemented instead of three as suggested by Figure 2, because it is only the relative delay between the three pathways arriving at the one summing node that counts. The delay circuits were implemented with fully-differential gm-C filters. In order to extend the frequency range of the delay, a first-order all-pass delay circuit was cascaded with a second-order all-pass delay circuit. The resulting addition of the first-order delay and the second-order delay allowed for an approximately flat delay response for a wider bandwidth as the decreased delay around the corner frequency of the first-order filter cancelled with the increased delay of the second-order filter around its resonant frequency. Figure 3 shows the first- and second-order sections of the all-pass delay circuit. Two of these circuits were used and, based on data presented in [2], were designed with delays of 28µs and 62µs, by way of bias current manipulation. The operational transconductance amplifier (OTA) in figure 3 is a standard OTA which includes the common-mode feedback necessary for fully differential designs. The buffers (Figure 3) are simple, cascoded differential pairs. V+ V- II+ V+ V- II+ V+ V- II+ V+ V- II+ V+ V- II+ V+ V- II+ Figure 3: The first-order all-pass delay circuit (left) and the second-order all-pass delay (right). The differential output of the delay circuits is converted into a current which is multiplied by a variable gain implemented as shown in Figure 4. The gain cell includes a differential pair with source degeneration via transistors N4 and N5. The source degeneration improves the linearity of the current. The three gain cells implemented on the aVLSI have default gains of 2, 3 and 0.91 which are set by holding the default input high and appropriately ratioing the bias currents through the value of vbiasp. To correct any on-chip mismatches and/or explore other gain configurations a current splitter cell [7] (p-splitter, figure 4) allows the gain to be programmed by digital means post fabrication. The current splitter takes an input current (Ibias, figure 4) and divides it into branches which recursively halve the current, i.e., the first branch gives ½ Ibias, the second branch ¼ Ibias, the third branch 1/8 Ibias and so on. These currents can be used together with digitally controlled switches as a Digital-to-Analogue converter. By holding default low and setting C5:C0 appropriately, any gain – from 4 to 0.125 – can be set. To save on output pins the program bits (C5:C0) for each of the three gain cells are set via a single 18-bit shift register in bit-serial fashion. Summing the output of the three gain circuits in the current domain simply involves connecting three wires together. Therefore, a natural option for the filters that follow is to use current domain filters. In our case we have chosen to implement log-domain filters using MOS transistors operating in weak inversion. Figure 5 shows the basic building blocks for the filters – the Tau Cell [8] and the multiplier cell – and block diagrams showing how these blocks were connected to create the necessary filtering blocks. The Tau Cell is a log-domain filter which has the firstorder response: I out 1 , = I in sτ + 1 where τ = nC aVT Ia and n = the slope factor, VT = thermal voltage, Ca = capacitance, and Ia = bias current. In figure 5, the input currents to the Tau Cell, Imult and A*Ia, are only used when building a second-order filter. The multiplier cell is simply a translinear loop where: I out1 ∗ I mult = I out 2 ∗ AI a or Imult = AIaIout2/Iout1. The configurations of the Tau Cell to get particular responses are covered in [8] along with the corresponding equations. The high frequency filter of Figure 2 is implemented by the high-pass filter in Figure 5 with a corner frequency of 17kHz. The low frequency filter, however, is divided into two parts since the biological filter’s response (see for example Figure 3A in [9]) separates well into a narrow second-order band-pass filter with a 10kHz resonant frequency and a wide band-pass filter made from a first-order high-pass filter with a 3kHz corner frequency followed by a first-order low-pass filter with a 12kHz corner frequency. These filters are then added together to reproduce the biological filter. The filters’ responses can be adjusted post fabrication via their bias currents. This allows for compensation due to processing and matching errors. Figure 4: The Gain Cell above is used to convert the differential voltage input from the delay cells into a single-ended current output. The gain of each cell is controllable via a programmable current cell (p_splitter). An on-chip bias generator [7] was used to create all the necessary current biases on the chip. All the main blocks (delays, gain cells and filters), however, can have their on-chip bias currents overridden through external pins on the chip. The chip was fabricated using the MOSIS AMI 1.6µm technology and designed using the Cadence Custom IC Design Tools (5.0.33). 3 Methods The chip was tested using sound generated on a computer and played through a soundcard to the chip. Responses from the chip were recorded by an oscilloscope, and uploaded back to the computer on completion. Given that the output from the chip and the gain circuits is a current, an external current-sense circuit built with discrete components was used to enable the output to be probed by the oscilloscope. Figure 5: The circuit diagrams for the log-domain filter building blocks – The Tau Cell and The Multiplier – along with the block diagrams for the three filters used in the aVLSI model. Initial experiments were performed to tune the delays and gains. After that, recordings were taken of the directional frequency responses. Sounds were generated by computer for each chip input to simulate moving the forelegs by delaying the sound by the appropriate amount of time; this was a much simpler solution than using microphones and moving them using motors. 4 Results The aVLSI chip was tested to measure its gains and delays, which were successfully tuned to the appropriate values. The chip was then compared with the simulation to check that it was faithfully modelling the system. A result of this test at 4kHz (approximately the cricket calling-song frequency) is shown in Figure 6. Apart from a drop in amplitude of the signal, the response of the circuit was very similar to that of the simulator. The differences were expected because the aVLSI circuit has to deal with real-world noise, whereas the simulated version has perfect signals. Examples of the gain versus frequency response of the two log-domain band-pass filters are shown in Figure 7. Note that the narrow-band filter peaks at 6kHz, which is significantly above the mating song frequency of the cricket which is around 4.5kHz. This is not a mistake, but is observed in real crickets as well. As stated in the introduction, a range of further testing results with both the circuit and the simulator are being published in [6]. 5 D i s c u s s i on The aVLSI auditory sensor in this research models the hearing of the field cricket Gryllus bimaculatus. It is a more faithful model of the cricket auditory system than was previously built in [4], reproducing all the acoustic inputs, as well as the responses to frequencies of both the co specific calling song and bat echolocation chirps. It also generates outputs corresponding to the two sets of behaviourally relevant auditory receptor fibres. Results showed that it matched the biological data well, though there were some inconsistencies due to an error in the specification that will be addressed in a future iteration of the design. A more complete implementation across all frequencies was impractical because of complexity and size issues as well as serving no clear behavioural purpose. Figure 6: Vibration amplitude of the left (dotted) and right (solid) virtual tympana measured in decibels in response to a 4kHz tone in simulation (left) and on the aVLSI chip (right). The plot shows the amplitude of the tympanal responses as the sound source is rotated around the cricket. Figure 7: Frequency-Gain curves for the narrow-band and wide-band bandpass filters. The long-term aim of this work is to better understand simple sensorimotor control loops in crickets and other insects. The next step is to mount this circuitry on a robot to carry out behavioural experiments, which we will compare with existing and new behavioural data (such as that in [10]). This will allow us to refine our models of the neural circuitry involved. Modelling the sensory afferent neurons in hardware is necessary in order to reduce processor load on our robot, so the next revision will include these either onboard, or on a companion chip as we have done before [11]. We will also move both sides of the auditory system onto a single chip to conserve space on the robot. It is our belief and experience that, as a result of this intelligent pre-processing carried out at the sensor level, the neural circuits necessary to accurately model the behaviour will remain simple. Acknowledgments The authors thank the Institute of Neuromorphic Engineering and the UK Biotechnology and Biological Sciences Research Council for funding the research in this paper. References [1] R. Wehner. Matched ﬁlters – neural models of the external world. J Comp Physiol A, 161: 511–531, 1987. [2] A. Michelsen, A. V. Popov, and B. Lewis. Physics of directional hearing in the cricket Gryllus bimaculatus. Journal of Comparative Physiology A, 175:153–164, 1994. [3] A. Michelsen. The tuned cricket. News Physiol. Sci., 13:32–38, 1998. [4] H. H. Lund, B. Webb, and J. Hallam. A robot attracted to the cricket species Gryllus bimaculatus. In P. Husbands and I. Harvey, editors, Proceedings of 4th European Conference on Artiﬁcial Life, pages 246–255. MIT Press/Bradford Books, MA., 1997. [5] R Reeve and B. Webb. New neural circuits for robot phonotaxis. Phil. Trans. R. Soc. Lond. A, 361:2245–2266, August 2003. [6] R. Reeve, A. van Schaik, C. Jin, T. Hamilton, B. Torben-Nielsen and B. Webb Directional hearing in a silicon cricket. Biosystems, (in revision), 2005b [7] T. Delbrück and A. van Schaik, Bias Current Generators with Wide Dynamic Range, Analog Integrated Circuits and Signal Processing 42(2), 2005 [8] A. van Schaik and C. Jin, The Tau Cell: A New Method for the Implementation of Arbitrary Differential Equations, IEEE International Symposium on Circuits and Systems (ISCAS) 2003 [9] Kazuo Imaizumi and Gerald S. Pollack. Neural coding of sound frequency by cricket auditory receptors. The Journal of Neuroscience, 19(4):1508– 1516, 1999. [10] Berthold Hedwig and James F.A. Poulet. Complex auditory behaviour emerges from simple reactive steering. Nature, 430:781–785, 2004. [11] R. Reeve, B. Webb, A. Horchler, G. Indiveri, and R. Quinn. New technologies for testing a model of cricket phonotaxis on an outdoor robot platform. Robotics and Autonomous Systems, 51(1):41-54, 2005.</p><p>6 0.56954223 <a title="28-lsi-6" href="./nips-2005-Neural_mechanisms_of_contrast_dependent_receptive_field_size_in_V1.html">134 nips-2005-Neural mechanisms of contrast dependent receptive field size in V1</a></p>
<p>7 0.49469957 <a title="28-lsi-7" href="./nips-2005-Principles_of_real-time_computing_with_feedback_applied_to_cortical_microcircuit_models.html">157 nips-2005-Principles of real-time computing with feedback applied to cortical microcircuit models</a></p>
<p>8 0.4238925 <a title="28-lsi-8" href="./nips-2005-Modeling_Neural_Population_Spiking_Activity_with_Gibbs_Distributions.html">129 nips-2005-Modeling Neural Population Spiking Activity with Gibbs Distributions</a></p>
<p>9 0.3845098 <a title="28-lsi-9" href="./nips-2005-Bayesian_Surprise_Attracts_Human_Attention.html">34 nips-2005-Bayesian Surprise Attracts Human Attention</a></p>
<p>10 0.37722552 <a title="28-lsi-10" href="./nips-2005-An_exploration-exploitation_model_based_on_norepinepherine_and_dopamine_activity.html">26 nips-2005-An exploration-exploitation model based on norepinepherine and dopamine activity</a></p>
<p>11 0.33982888 <a title="28-lsi-11" href="./nips-2005-Is_Early_Vision_Optimized_for_Extracting_Higher-order_Dependencies%3F.html">101 nips-2005-Is Early Vision Optimized for Extracting Higher-order Dependencies?</a></p>
<p>12 0.33587003 <a title="28-lsi-12" href="./nips-2005-Integrate-and-Fire_models_with_adaptation_are_good_enough.html">99 nips-2005-Integrate-and-Fire models with adaptation are good enough</a></p>
<p>13 0.33230507 <a title="28-lsi-13" href="./nips-2005-Norepinephrine_and_Neural_Interrupts.html">141 nips-2005-Norepinephrine and Neural Interrupts</a></p>
<p>14 0.32895818 <a title="28-lsi-14" href="./nips-2005-Response_Analysis_of_Neuronal_Population_with_Synaptic_Depression.html">165 nips-2005-Response Analysis of Neuronal Population with Synaptic Depression</a></p>
<p>15 0.32329312 <a title="28-lsi-15" href="./nips-2005-Measuring_Shared_Information_and_Coordinated_Activity_in_Neuronal_Networks.html">124 nips-2005-Measuring Shared Information and Coordinated Activity in Neuronal Networks</a></p>
<p>16 0.31641522 <a title="28-lsi-16" href="./nips-2005-Modeling_Neuronal_Interactivity_using_Dynamic_Bayesian_Networks.html">130 nips-2005-Modeling Neuronal Interactivity using Dynamic Bayesian Networks</a></p>
<p>17 0.30272144 <a title="28-lsi-17" href="./nips-2005-Prediction_and_Change_Detection.html">156 nips-2005-Prediction and Change Detection</a></p>
<p>18 0.29399619 <a title="28-lsi-18" href="./nips-2005-Fast_biped_walking_with_a_reflexive_controller_and_real-time_policy_searching.html">73 nips-2005-Fast biped walking with a reflexive controller and real-time policy searching</a></p>
<p>19 0.29238936 <a title="28-lsi-19" href="./nips-2005-Distance_Metric_Learning_for_Large_Margin_Nearest_Neighbor_Classification.html">57 nips-2005-Distance Metric Learning for Large Margin Nearest Neighbor Classification</a></p>
<p>20 0.28465039 <a title="28-lsi-20" href="./nips-2005-Stimulus_Evoked_Independent_Factor_Analysis_of_MEG_Data_with_Large_Background_Activity.html">183 nips-2005-Stimulus Evoked Independent Factor Analysis of MEG Data with Large Background Activity</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2005_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.047), (10, 0.034), (12, 0.277), (27, 0.039), (31, 0.036), (34, 0.091), (39, 0.05), (41, 0.011), (44, 0.018), (55, 0.018), (57, 0.012), (60, 0.055), (69, 0.057), (73, 0.03), (88, 0.077), (91, 0.044)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.95993322 <a title="28-lda-1" href="./nips-2005-Neuronal_Fiber_Delineation_in_Area_of_Edema_from_Diffusion_Weighted_MRI.html">135 nips-2005-Neuronal Fiber Delineation in Area of Edema from Diffusion Weighted MRI</a></p>
<p>Author: Ofer Pasternak, Nathan Intrator, Nir Sochen, Yaniv Assaf</p><p>Abstract: Diffusion Tensor Magnetic Resonance Imaging (DT-MRI) is a non invasive method for brain neuronal ﬁbers delineation. Here we show a modiﬁcation for DT-MRI that allows delineation of neuronal ﬁbers which are inﬁltrated by edema. We use the Muliple Tensor Variational (MTV) framework which replaces the diffusion model of DT-MRI with a multiple component model and ﬁts it to the signal attenuation with a variational regularization mechanism. In order to reduce free water contamination we estimate the free water compartment volume fraction in each voxel, remove it, and then calculate the anisotropy of the remaining compartment. The variational framework was applied on data collected with conventional clinical parameters, containing only six diffusion directions. By using the variational framework we were able to overcome the highly ill posed ﬁtting. The results show that we were able to ﬁnd ﬁbers that were not found by DT-MRI.</p><p>2 0.81014252 <a title="28-lda-2" href="./nips-2005-Generalized_Nonnegative_Matrix_Approximations_with_Bregman_Divergences.html">86 nips-2005-Generalized Nonnegative Matrix Approximations with Bregman Divergences</a></p>
<p>Author: Suvrit Sra, Inderjit S. Dhillon</p><p>Abstract: Nonnegative matrix approximation (NNMA) is a recent technique for dimensionality reduction and data analysis that yields a parts based, sparse nonnegative representation for nonnegative input data. NNMA has found a wide variety of applications, including text analysis, document clustering, face/image recognition, language modeling, speech processing and many others. Despite these numerous applications, the algorithmic development for computing the NNMA factors has been relatively deﬁcient. This paper makes algorithmic progress by modeling and solving (using multiplicative updates) new generalized NNMA problems that minimize Bregman divergences between the input matrix and its lowrank approximation. The multiplicative update formulae in the pioneering work by Lee and Seung [11] arise as a special case of our algorithms. In addition, the paper shows how to use penalty functions for incorporating constraints other than nonnegativity into the problem. Further, some interesting extensions to the use of “link” functions for modeling nonlinear relationships are also discussed. 1</p><p>3 0.79299295 <a title="28-lda-3" href="./nips-2005-Learning_Topology_with_the_Generative_Gaussian_Graph_and_the_EM_Algorithm.html">116 nips-2005-Learning Topology with the Generative Gaussian Graph and the EM Algorithm</a></p>
<p>Author: Michaël Aupetit</p><p>Abstract: Given a set of points and a set of prototypes representing them, how to create a graph of the prototypes whose topology accounts for that of the points? This problem had not yet been explored in the framework of statistical learning theory. In this work, we propose a generative model based on the Delaunay graph of the prototypes and the ExpectationMaximization algorithm to learn the parameters. This work is a ﬁrst step towards the construction of a topological model of a set of points grounded on statistics. 1 1.1</p><p>same-paper 4 0.77902234 <a title="28-lda-4" href="./nips-2005-Analyzing_Auditory_Neurons_by_Learning_Distance_Functions.html">28 nips-2005-Analyzing Auditory Neurons by Learning Distance Functions</a></p>
<p>Author: Inna Weiner, Tomer Hertz, Israel Nelken, Daphna Weinshall</p><p>Abstract: We present a novel approach to the characterization of complex sensory neurons. One of the main goals of characterizing sensory neurons is to characterize dimensions in stimulus space to which the neurons are highly sensitive (causing large gradients in the neural responses) or alternatively dimensions in stimulus space to which the neuronal response are invariant (deﬁning iso-response manifolds). We formulate this problem as that of learning a geometry on stimulus space that is compatible with the neural responses: the distance between stimuli should be large when the responses they evoke are very different, and small when the responses they evoke are similar. Here we show how to successfully train such distance functions using rather limited amount of information. The data consisted of the responses of neurons in primary auditory cortex (A1) of anesthetized cats to 32 stimuli derived from natural sounds. For each neuron, a subset of all pairs of stimuli was selected such that the responses of the two stimuli in a pair were either very similar or very dissimilar. The distance function was trained to ﬁt these constraints. The resulting distance functions generalized to predict the distances between the responses of a test stimulus and the trained stimuli. 1</p><p>5 0.51980335 <a title="28-lda-5" href="./nips-2005-Identifying_Distributed_Object_Representations_in_Human_Extrastriate_Visual_Cortex.html">94 nips-2005-Identifying Distributed Object Representations in Human Extrastriate Visual Cortex</a></p>
<p>Author: Rory Sayres, David Ress, Kalanit Grill-spector</p><p>Abstract: The category of visual stimuli has been reliably decoded from patterns of neural activity in extrastriate visual cortex [1]. It has yet to be seen whether object identity can be inferred from this activity. We present fMRI data measuring responses in human extrastriate cortex to a set of 12 distinct object images. We use a simple winner-take-all classifier, using half the data from each recording session as a training set, to evaluate encoding of object identity across fMRI voxels. Since this approach is sensitive to the inclusion of noisy voxels, we describe two methods for identifying subsets of voxels in the data which optimally distinguish object identity. One method characterizes the reliability of each voxel within subsets of the data, while another estimates the mutual information of each voxel with the stimulus set. We find that both metrics can identify subsets of the data which reliably encode object identity, even when noisy measurements are artificially added to the data. The mutual information metric is less efficient at this task, likely due to constraints in fMRI data. 1</p><p>6 0.50589818 <a title="28-lda-6" href="./nips-2005-Analyzing_Coupled_Brain_Sources%3A_Distinguishing_True_from_Spurious_Interaction.html">29 nips-2005-Analyzing Coupled Brain Sources: Distinguishing True from Spurious Interaction</a></p>
<p>7 0.50396544 <a title="28-lda-7" href="./nips-2005-Non-Local_Manifold_Parzen_Windows.html">138 nips-2005-Non-Local Manifold Parzen Windows</a></p>
<p>8 0.48327884 <a title="28-lda-8" href="./nips-2005-A_Criterion_for_the_Convergence_of_Learning_with_Spike_Timing_Dependent_Plasticity.html">8 nips-2005-A Criterion for the Convergence of Learning with Spike Timing Dependent Plasticity</a></p>
<p>9 0.48232782 <a title="28-lda-9" href="./nips-2005-A_Probabilistic_Interpretation_of_SVMs_with_an_Application_to_Unbalanced_Classification.html">14 nips-2005-A Probabilistic Interpretation of SVMs with an Application to Unbalanced Classification</a></p>
<p>10 0.48208588 <a title="28-lda-10" href="./nips-2005-An_exploration-exploitation_model_based_on_norepinepherine_and_dopamine_activity.html">26 nips-2005-An exploration-exploitation model based on norepinepherine and dopamine activity</a></p>
<p>11 0.4794848 <a title="28-lda-11" href="./nips-2005-Measuring_Shared_Information_and_Coordinated_Activity_in_Neuronal_Networks.html">124 nips-2005-Measuring Shared Information and Coordinated Activity in Neuronal Networks</a></p>
<p>12 0.4782953 <a title="28-lda-12" href="./nips-2005-Hyperparameter_and_Kernel_Learning_for_Graph_Based_Semi-Supervised_Classification.html">92 nips-2005-Hyperparameter and Kernel Learning for Graph Based Semi-Supervised Classification</a></p>
<p>13 0.47737575 <a title="28-lda-13" href="./nips-2005-Assessing_Approximations_for_Gaussian_Process_Classification.html">30 nips-2005-Assessing Approximations for Gaussian Process Classification</a></p>
<p>14 0.47692654 <a title="28-lda-14" href="./nips-2005-Structured_Prediction_via_the_Extragradient_Method.html">184 nips-2005-Structured Prediction via the Extragradient Method</a></p>
<p>15 0.47692555 <a title="28-lda-15" href="./nips-2005-Nearest_Neighbor_Based_Feature_Selection_for_Regression_and_its_Application_to_Neural_Activity.html">132 nips-2005-Nearest Neighbor Based Feature Selection for Regression and its Application to Neural Activity</a></p>
<p>16 0.47642353 <a title="28-lda-16" href="./nips-2005-Convex_Neural_Networks.html">50 nips-2005-Convex Neural Networks</a></p>
<p>17 0.47569823 <a title="28-lda-17" href="./nips-2005-Pattern_Recognition_from_One_Example_by_Chopping.html">151 nips-2005-Pattern Recognition from One Example by Chopping</a></p>
<p>18 0.47553656 <a title="28-lda-18" href="./nips-2005-Infinite_latent_feature_models_and_the_Indian_buffet_process.html">98 nips-2005-Infinite latent feature models and the Indian buffet process</a></p>
<p>19 0.47356558 <a title="28-lda-19" href="./nips-2005-Off-policy_Learning_with_Options_and_Recognizers.html">144 nips-2005-Off-policy Learning with Options and Recognizers</a></p>
<p>20 0.47055811 <a title="28-lda-20" href="./nips-2005-Variable_KD-Tree_Algorithms_for_Spatial_Pattern_Search_and_Discovery.html">200 nips-2005-Variable KD-Tree Algorithms for Spatial Pattern Search and Discovery</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
