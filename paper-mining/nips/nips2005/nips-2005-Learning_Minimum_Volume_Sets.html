<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>112 nips-2005-Learning Minimum Volume Sets</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2005" href="../home/nips2005_home.html">nips2005</a> <a title="nips-2005-112" href="#">nips2005-112</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>112 nips-2005-Learning Minimum Volume Sets</h1>
<br/><p>Source: <a title="nips-2005-112-pdf" href="http://papers.nips.cc/paper/2851-learning-minimum-volume-sets.pdf">pdf</a></p><p>Author: Clayton Scott, Robert Nowak</p><p>Abstract: Given a probability measure P and a reference measure µ, one is often interested in the minimum µ-measure set with P -measure at least α. Minimum volume sets of this type summarize the regions of greatest probability mass of P , and are useful for detecting anomalies and constructing conﬁdence regions. This paper addresses the problem of estimating minimum volume sets based on independent samples distributed according to P . Other than these samples, no other information is available regarding P , but the reference measure µ is assumed to be known. We introduce rules for estimating minimum volume sets that parallel the empirical risk minimization and structural risk minimization principles in classiﬁcation. As in classiﬁcation, we show that the performances of our estimators are controlled by the rate of uniform convergence of empirical to true probabilities over the class from which the estimator is drawn. Thus we obtain ﬁnite sample size performance bounds in terms of VC dimension and related quantities. We also demonstrate strong universal consistency and an oracle inequality. Estimators based on histograms and dyadic partitions illustrate the proposed rules. 1</p><p>Reference: <a title="nips-2005-112-reference" href="../nips2005_reference/nips-2005-Learning_Minimum_Volume_Sets_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('gg', 0.891), ('volum', 0.142), ('dyad', 0.141), ('penal', 0.14), ('mass', 0.127), ('orac', 0.118), ('risk', 0.086), ('vc', 0.075), ('erm', 0.074), ('occam', 0.067), ('nowak', 0.067), ('ineq', 0.055), ('theorem', 0.046), ('partit', 0.046), ('pn', 0.045), ('rademach', 0.044), ('scot', 0.044), ('minim', 0.044), ('empir', 0.044), ('cscott', 0.042)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999988 <a title="112-tfidf-1" href="./nips-2005-Learning_Minimum_Volume_Sets.html">112 nips-2005-Learning Minimum Volume Sets</a></p>
<p>2 0.10578448 <a title="112-tfidf-2" href="./nips-2005-Consistency_of_one-class_SVM_and_related_algorithms.html">47 nips-2005-Consistency of one-class SVM and related algorithms</a></p>
<p>3 0.0776648 <a title="112-tfidf-3" href="./nips-2005-Faster_Rates_in_Regression_via_Active_Learning.html">74 nips-2005-Faster Rates in Regression via Active Learning</a></p>
<p>4 0.069688834 <a title="112-tfidf-4" href="./nips-2005-Generalization_to_Unseen_Cases.html">85 nips-2005-Generalization to Unseen Cases</a></p>
<p>5 0.069048412 <a title="112-tfidf-5" href="./nips-2005-Generalization_error_bounds_for_classifiers_trained_with_interdependent_data.html">83 nips-2005-Generalization error bounds for classifiers trained with interdependent data</a></p>
<p>6 0.065562636 <a title="112-tfidf-6" href="./nips-2005-Improved_risk_tail_bounds_for_on-line_algorithms.html">95 nips-2005-Improved risk tail bounds for on-line algorithms</a></p>
<p>7 0.055858199 <a title="112-tfidf-7" href="./nips-2005-Generalization_Error_Bounds_for_Aggregation_by_Mirror_Descent_with_Averaging.html">82 nips-2005-Generalization Error Bounds for Aggregation by Mirror Descent with Averaging</a></p>
<p>8 0.05300289 <a title="112-tfidf-8" href="./nips-2005-A_Bayes_Rule_for_Density_Matrices.html">2 nips-2005-A Bayes Rule for Density Matrices</a></p>
<p>9 0.051697623 <a title="112-tfidf-9" href="./nips-2005-Coarse_sample_complexity_bounds_for_active_learning.html">41 nips-2005-Coarse sample complexity bounds for active learning</a></p>
<p>10 0.051256195 <a title="112-tfidf-10" href="./nips-2005-Inference_with_Minimal_Communication%3A_a_Decision-Theoretic_Variational_Approach.html">96 nips-2005-Inference with Minimal Communication: a Decision-Theoretic Variational Approach</a></p>
<p>11 0.046050813 <a title="112-tfidf-11" href="./nips-2005-Divergences%2C_surrogate_loss_functions_and_experimental_design.html">58 nips-2005-Divergences, surrogate loss functions and experimental design</a></p>
<p>12 0.040890988 <a title="112-tfidf-12" href="./nips-2005-TD%280%29_Leads_to_Better_Policies_than_Approximate_Value_Iteration.html">186 nips-2005-TD(0) Leads to Better Policies than Approximate Value Iteration</a></p>
<p>13 0.04006042 <a title="112-tfidf-13" href="./nips-2005-Convergence_and_Consistency_of_Regularized_Boosting_Algorithms_with_Stationary_B-Mixing_Observations.html">49 nips-2005-Convergence and Consistency of Regularized Boosting Algorithms with Stationary B-Mixing Observations</a></p>
<p>14 0.038893435 <a title="112-tfidf-14" href="./nips-2005-Two_view_learning%3A_SVM-2K%2C_Theory_and_Practice.html">196 nips-2005-Two view learning: SVM-2K, Theory and Practice</a></p>
<p>15 0.037249696 <a title="112-tfidf-15" href="./nips-2005-A_PAC-Bayes_approach_to_the_Set_Covering_Machine.html">12 nips-2005-A PAC-Bayes approach to the Set Covering Machine</a></p>
<p>16 0.034962155 <a title="112-tfidf-16" href="./nips-2005-Analysis_of_Spectral_Kernel_Design_based_Semi-supervised_Learning.html">27 nips-2005-Analysis of Spectral Kernel Design based Semi-supervised Learning</a></p>
<p>17 0.03465613 <a title="112-tfidf-17" href="./nips-2005-Learning_Multiple_Related_Tasks_using_Latent_Independent_Component_Analysis.html">113 nips-2005-Learning Multiple Related Tasks using Latent Independent Component Analysis</a></p>
<p>18 0.034019053 <a title="112-tfidf-18" href="./nips-2005-Fusion_of_Similarity_Data_in_Clustering.html">79 nips-2005-Fusion of Similarity Data in Clustering</a></p>
<p>19 0.033492062 <a title="112-tfidf-19" href="./nips-2005-A_Probabilistic_Interpretation_of_SVMs_with_an_Application_to_Unbalanced_Classification.html">14 nips-2005-A Probabilistic Interpretation of SVMs with an Application to Unbalanced Classification</a></p>
<p>20 0.03312711 <a title="112-tfidf-20" href="./nips-2005-Estimation_of_Intrinsic_Dimensionality_Using_High-Rate_Vector_Quantization.html">66 nips-2005-Estimation of Intrinsic Dimensionality Using High-Rate Vector Quantization</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2005_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.115), (1, -0.042), (2, -0.009), (3, 0.043), (4, -0.057), (5, 0.028), (6, -0.094), (7, -0.015), (8, 0.036), (9, -0.047), (10, -0.108), (11, 0.011), (12, -0.029), (13, 0.032), (14, 0.031), (15, 0.068), (16, 0.084), (17, -0.033), (18, -0.023), (19, -0.022), (20, 0.042), (21, 0.028), (22, 0.055), (23, -0.004), (24, -0.051), (25, -0.003), (26, -0.001), (27, -0.062), (28, 0.06), (29, -0.014), (30, -0.008), (31, 0.026), (32, 0.042), (33, 0.035), (34, -0.009), (35, 0.04), (36, -0.029), (37, -0.044), (38, -0.058), (39, -0.072), (40, 0.02), (41, 0.054), (42, 0.037), (43, -0.012), (44, 0.003), (45, -0.052), (46, -0.011), (47, 0.017), (48, 0.091), (49, 0.062)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.88662833 <a title="112-lsi-1" href="./nips-2005-Learning_Minimum_Volume_Sets.html">112 nips-2005-Learning Minimum Volume Sets</a></p>
<p>2 0.77428347 <a title="112-lsi-2" href="./nips-2005-Generalization_to_Unseen_Cases.html">85 nips-2005-Generalization to Unseen Cases</a></p>
<p>3 0.70809585 <a title="112-lsi-3" href="./nips-2005-Generalization_error_bounds_for_classifiers_trained_with_interdependent_data.html">83 nips-2005-Generalization error bounds for classifiers trained with interdependent data</a></p>
<p>4 0.67803991 <a title="112-lsi-4" href="./nips-2005-Improved_risk_tail_bounds_for_on-line_algorithms.html">95 nips-2005-Improved risk tail bounds for on-line algorithms</a></p>
<p>5 0.6728068 <a title="112-lsi-5" href="./nips-2005-Faster_Rates_in_Regression_via_Active_Learning.html">74 nips-2005-Faster Rates in Regression via Active Learning</a></p>
<p>6 0.64115369 <a title="112-lsi-6" href="./nips-2005-Consistency_of_one-class_SVM_and_related_algorithms.html">47 nips-2005-Consistency of one-class SVM and related algorithms</a></p>
<p>7 0.63974154 <a title="112-lsi-7" href="./nips-2005-Convergence_and_Consistency_of_Regularized_Boosting_Algorithms_with_Stationary_B-Mixing_Observations.html">49 nips-2005-Convergence and Consistency of Regularized Boosting Algorithms with Stationary B-Mixing Observations</a></p>
<p>8 0.63711202 <a title="112-lsi-8" href="./nips-2005-Learning_from_Data_of_Variable_Quality.html">117 nips-2005-Learning from Data of Variable Quality</a></p>
<p>9 0.52548093 <a title="112-lsi-9" href="./nips-2005-Divergences%2C_surrogate_loss_functions_and_experimental_design.html">58 nips-2005-Divergences, surrogate loss functions and experimental design</a></p>
<p>10 0.52436233 <a title="112-lsi-10" href="./nips-2005-Non-Gaussian_Component_Analysis%3A_a_Semi-parametric_Framework_for_Linear_Dimension_Reduction.html">137 nips-2005-Non-Gaussian Component Analysis: a Semi-parametric Framework for Linear Dimension Reduction</a></p>
<p>11 0.51093125 <a title="112-lsi-11" href="./nips-2005-Correcting_sample_selection_bias_in_maximum_entropy_density_estimation.html">51 nips-2005-Correcting sample selection bias in maximum entropy density estimation</a></p>
<p>12 0.50414568 <a title="112-lsi-12" href="./nips-2005-Generalization_Error_Bounds_for_Aggregation_by_Mirror_Descent_with_Averaging.html">82 nips-2005-Generalization Error Bounds for Aggregation by Mirror Descent with Averaging</a></p>
<p>13 0.5010277 <a title="112-lsi-13" href="./nips-2005-TD%280%29_Leads_to_Better_Policies_than_Approximate_Value_Iteration.html">186 nips-2005-TD(0) Leads to Better Policies than Approximate Value Iteration</a></p>
<p>14 0.48651162 <a title="112-lsi-14" href="./nips-2005-Worst-Case_Bounds_for_Gaussian_Process_Models.html">205 nips-2005-Worst-Case Bounds for Gaussian Process Models</a></p>
<p>15 0.4815433 <a title="112-lsi-15" href="./nips-2005-Preconditioner_Approximations_for_Probabilistic_Graphical_Models.html">154 nips-2005-Preconditioner Approximations for Probabilistic Graphical Models</a></p>
<p>16 0.46189862 <a title="112-lsi-16" href="./nips-2005-A_PAC-Bayes_approach_to_the_Set_Covering_Machine.html">12 nips-2005-A PAC-Bayes approach to the Set Covering Machine</a></p>
<p>17 0.45356998 <a title="112-lsi-17" href="./nips-2005-Two_view_learning%3A_SVM-2K%2C_Theory_and_Practice.html">196 nips-2005-Two view learning: SVM-2K, Theory and Practice</a></p>
<p>18 0.44976616 <a title="112-lsi-18" href="./nips-2005-On_the_Convergence_of_Eigenspaces_in_Kernel_Principal_Component_Analysis.html">147 nips-2005-On the Convergence of Eigenspaces in Kernel Principal Component Analysis</a></p>
<p>19 0.43482122 <a title="112-lsi-19" href="./nips-2005-Active_Learning_For_Identifying_Function_Threshold_Boundaries.html">18 nips-2005-Active Learning For Identifying Function Threshold Boundaries</a></p>
<p>20 0.43333724 <a title="112-lsi-20" href="./nips-2005-Estimation_of_Intrinsic_Dimensionality_Using_High-Rate_Vector_Quantization.html">66 nips-2005-Estimation of Intrinsic Dimensionality Using High-Rate Vector Quantization</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2005_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.039), (17, 0.015), (27, 0.25), (54, 0.085), (58, 0.05), (71, 0.17), (74, 0.014), (88, 0.117), (89, 0.038), (92, 0.079)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.77878004 <a title="112-lda-1" href="./nips-2005-From_Lasso_regression_to_Feature_vector_machine.html">77 nips-2005-From Lasso regression to Feature vector machine</a></p>
<p>same-paper 2 0.76336253 <a title="112-lda-2" href="./nips-2005-Learning_Minimum_Volume_Sets.html">112 nips-2005-Learning Minimum Volume Sets</a></p>
<p>3 0.75845242 <a title="112-lda-3" href="./nips-2005-Comparing_the_Effects_of_Different_Weight_Distributions_on_Finding_Sparse_Representations.html">43 nips-2005-Comparing the Effects of Different Weight Distributions on Finding Sparse Representations</a></p>
<p>4 0.6617837 <a title="112-lda-4" href="./nips-2005-Divergences%2C_surrogate_loss_functions_and_experimental_design.html">58 nips-2005-Divergences, surrogate loss functions and experimental design</a></p>
<p>5 0.66053176 <a title="112-lda-5" href="./nips-2005-Faster_Rates_in_Regression_via_Active_Learning.html">74 nips-2005-Faster Rates in Regression via Active Learning</a></p>
<p>6 0.65710223 <a title="112-lda-6" href="./nips-2005-Generalization_error_bounds_for_classifiers_trained_with_interdependent_data.html">83 nips-2005-Generalization error bounds for classifiers trained with interdependent data</a></p>
<p>7 0.65365142 <a title="112-lda-7" href="./nips-2005-Generalization_Error_Bounds_for_Aggregation_by_Mirror_Descent_with_Averaging.html">82 nips-2005-Generalization Error Bounds for Aggregation by Mirror Descent with Averaging</a></p>
<p>8 0.65333593 <a title="112-lda-8" href="./nips-2005-Beyond_Gaussian_Processes%3A_On_the_Distributions_of_Infinite_Networks.html">38 nips-2005-Beyond Gaussian Processes: On the Distributions of Infinite Networks</a></p>
<p>9 0.65279192 <a title="112-lda-9" href="./nips-2005-Coarse_sample_complexity_bounds_for_active_learning.html">41 nips-2005-Coarse sample complexity bounds for active learning</a></p>
<p>10 0.6506933 <a title="112-lda-10" href="./nips-2005-Convergence_and_Consistency_of_Regularized_Boosting_Algorithms_with_Stationary_B-Mixing_Observations.html">49 nips-2005-Convergence and Consistency of Regularized Boosting Algorithms with Stationary B-Mixing Observations</a></p>
<p>11 0.64930558 <a title="112-lda-11" href="./nips-2005-A_Bayes_Rule_for_Density_Matrices.html">2 nips-2005-A Bayes Rule for Density Matrices</a></p>
<p>12 0.64696914 <a title="112-lda-12" href="./nips-2005-Sensory_Adaptation_within_a_Bayesian_Framework_for_Perception.html">173 nips-2005-Sensory Adaptation within a Bayesian Framework for Perception</a></p>
<p>13 0.64575404 <a title="112-lda-13" href="./nips-2005-Generalization_to_Unseen_Cases.html">85 nips-2005-Generalization to Unseen Cases</a></p>
<p>14 0.64482874 <a title="112-lda-14" href="./nips-2005-Dynamical_Synapses_Give_Rise_to_a_Power-Law_Distribution_of_Neuronal_Avalanches.html">61 nips-2005-Dynamical Synapses Give Rise to a Power-Law Distribution of Neuronal Avalanches</a></p>
<p>15 0.64302397 <a title="112-lda-15" href="./nips-2005-A_Criterion_for_the_Convergence_of_Learning_with_Spike_Timing_Dependent_Plasticity.html">8 nips-2005-A Criterion for the Convergence of Learning with Spike Timing Dependent Plasticity</a></p>
<p>16 0.64083964 <a title="112-lda-16" href="./nips-2005-Non-Gaussian_Component_Analysis%3A_a_Semi-parametric_Framework_for_Linear_Dimension_Reduction.html">137 nips-2005-Non-Gaussian Component Analysis: a Semi-parametric Framework for Linear Dimension Reduction</a></p>
<p>17 0.64056003 <a title="112-lda-17" href="./nips-2005-Fast_Information_Value_for_Graphical_Models.html">70 nips-2005-Fast Information Value for Graphical Models</a></p>
<p>18 0.63990027 <a title="112-lda-18" href="./nips-2005-Variational_Bayesian_Stochastic_Complexity_of_Mixture_Models.html">201 nips-2005-Variational Bayesian Stochastic Complexity of Mixture Models</a></p>
<p>19 0.63932538 <a title="112-lda-19" href="./nips-2005-Analyzing_Coupled_Brain_Sources%3A_Distinguishing_True_from_Spurious_Interaction.html">29 nips-2005-Analyzing Coupled Brain Sources: Distinguishing True from Spurious Interaction</a></p>
<p>20 0.63848835 <a title="112-lda-20" href="./nips-2005-Consistency_of_one-class_SVM_and_related_algorithms.html">47 nips-2005-Consistency of one-class SVM and related algorithms</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
