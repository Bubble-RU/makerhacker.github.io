<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>135 nips-2005-Neuronal Fiber Delineation in Area of Edema from Diffusion Weighted MRI</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2005" href="../home/nips2005_home.html">nips2005</a> <a title="nips-2005-135" href="#">nips2005-135</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>135 nips-2005-Neuronal Fiber Delineation in Area of Edema from Diffusion Weighted MRI</h1>
<br/><p>Source: <a title="nips-2005-135-pdf" href="http://papers.nips.cc/paper/2917-neuronal-fiber-delineation-in-area-of-edema-from-diffusion-weighted-mri.pdf">pdf</a></p><p>Author: Ofer Pasternak, Nathan Intrator, Nir Sochen, Yaniv Assaf</p><p>Abstract: Diffusion Tensor Magnetic Resonance Imaging (DT-MRI) is a non invasive method for brain neuronal ﬁbers delineation. Here we show a modiﬁcation for DT-MRI that allows delineation of neuronal ﬁbers which are inﬁltrated by edema. We use the Muliple Tensor Variational (MTV) framework which replaces the diffusion model of DT-MRI with a multiple component model and ﬁts it to the signal attenuation with a variational regularization mechanism. In order to reduce free water contamination we estimate the free water compartment volume fraction in each voxel, remove it, and then calculate the anisotropy of the remaining compartment. The variational framework was applied on data collected with conventional clinical parameters, containing only six diffusion directions. By using the variational framework we were able to overcome the highly ill posed ﬁtting. The results show that we were able to ﬁnd ﬁbers that were not found by DT-MRI.</p><p>Reference: <a title="nips-2005-135-reference" href="../nips2005_reference/nips-2005-Neuronal_Fiber_Delineation_in_Area_of_Edema_from_Diffusion_Weighted_MRI_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 il  Abstract Diffusion Tensor Magnetic Resonance Imaging (DT-MRI) is a non invasive method for brain neuronal ﬁbers delineation. [sent-13, score-0.218]
</p><p>2 Here we show a modiﬁcation for DT-MRI that allows delineation of neuronal ﬁbers which are inﬁltrated by edema. [sent-14, score-0.162]
</p><p>3 We use the Muliple Tensor Variational (MTV) framework which replaces the diffusion model of DT-MRI with a multiple component model and ﬁts it to the signal attenuation with a variational regularization mechanism. [sent-15, score-0.652]
</p><p>4 In order to reduce free water contamination we estimate the free water compartment volume fraction in each voxel, remove it, and then calculate the anisotropy of the remaining compartment. [sent-16, score-0.734]
</p><p>5 The variational framework was applied on data collected with conventional clinical parameters, containing only six diffusion directions. [sent-17, score-0.634]
</p><p>6 By using the variational framework we were able to overcome the highly ill posed ﬁtting. [sent-18, score-0.108]
</p><p>7 1 Introduction Diffusion weighted Magnetic Resonance Imaging (DT-MRI) enables the measurement of the apparent water self-diffusion along a speciﬁed direction [1]. [sent-20, score-0.137]
</p><p>8 Using a series of Diffusion Weighted Images (DWIs) DT-MRI can extract quantitative measures of water molecule diffusion anisotropy which characterize tissue microstructure [2]. [sent-21, score-0.748]
</p><p>9 Such measures are in particular useful for the segmentation of neuronal ﬁbers from other brain tissue which then allows a noninvasive delineation and visualization of major brain neuronal ﬁber bundles in vivo [3]. [sent-22, score-0.665]
</p><p>10 Based on the assumptions that each voxel can be represented by a single diffusion compartment and that the diffusion within this compartment has a Gaussian distribution ∗  http://www. [sent-23, score-1.602]
</p><p>11 il/∼oferpas  DT-MRI states the relation between the signal attenuation, E, and the diffusion tensor, D, as follows [4, 5, 6]: A(qk ) T E(qk ) = = exp(−bqk Dqk ) , (1) A(0) where A(qk ) is the DWI for the k’th applied diffusion gradient direction qk . [sent-27, score-1.069]
</p><p>12 The notation A(0) is for the non weighted image and b is a constant reﬂecting the experimental diffusion weighting [2]. [sent-28, score-0.539]
</p><p>13 , a 3 × 3 positive semideﬁnite matrix, that requires at least 6 DWIs from different non-collinear applied gradient directions to uniquely determine it. [sent-31, score-0.026]
</p><p>14 The symmetric diffusion tensor has a spectral decomposition for three eigenvectors U a and three positive eigenvalues λa . [sent-32, score-0.892]
</p><p>15 The relation between the eigenvalues determines the diffusion anisotropy using measures such as Fractional Anisotropy (FA) [5]: FA =  3((λ1 − D )2 + (λ2 − D )2 + (λ3 − D )2 ) , 2(λ2 + λ2 + λ2 ) 1 2 3  (2)  where D = (λ1 + λ2 + λ3 )/3. [sent-33, score-0.573]
</p><p>16 FA is relatively high in neuronal ﬁber bundles (white matter), where the cylindrical geometry of ﬁbers causes the diffusion perpendicular to the ﬁbers be much smaller than parallel to them. [sent-34, score-0.637]
</p><p>17 Other brain tissues, such as gray matter and Cerebro-Spinal Fluid (CSF), are less conﬁned with diffusion direction and exhibit isotropic diffusion. [sent-35, score-0.667]
</p><p>18 In cases of partial volume where neuronal ﬁbers reside other tissue type in the same voxel, or present complex architecture, the diffusion has no longer a single pronounced orientation and therefore the FA value of the ﬁtted tensor is decreased. [sent-36, score-1.13]
</p><p>19 The decreased FA values causes errors in segmentation and in any proceeding ﬁber analysis. [sent-37, score-0.018]
</p><p>20 In this paper we focus on the case where partial volume occurs when ﬁber bundles are inﬁltrated with edema. [sent-38, score-0.175]
</p><p>21 Edema might occur in response to brain trauma, or surrounding a tumor. [sent-39, score-0.129]
</p><p>22 The brain tissue accumulate water which creates pressure and might change the ﬁber architecture, or inﬁltrate it. [sent-40, score-0.292]
</p><p>23 Since the edema consists mostly of relatively free diffusing water molecules, the diffusion attenuation increases and the anisotropy decreases. [sent-41, score-0.936]
</p><p>24 We chose to reduce the effect of edema by changing the diffusion model to a dual compartment model, assuming an isotropic compartment added to a tensor compartment. [sent-42, score-1.919]
</p><p>25 2 Theory The method we offer is based on the dual compartment model which was already demonstrated as able to reduce CSF contamination [7], where it required a large number of diffusion measurement with different diffusion times. [sent-43, score-1.457]
</p><p>26 Here we require the conventional DT-MRI data of only six diffusion measurement, and apply it on the edema case. [sent-44, score-0.786]
</p><p>27 1 The Dual Compartment Model The dual compartment model is described as follows: T E(qk ) = f exp(−bqk D1 qk ) + (1 − f ) exp(−bD2 ) . [sent-46, score-0.498]
</p><p>28 (3)  The diffusion tensor for the tensor compartment is denoted by D1 , and the diffusion coefﬁcient of the isotropic water compartment is denoted by D2 . [sent-47, score-2.466]
</p><p>29 The compartments have relative volume of f and 1−f . [sent-48, score-0.124]
</p><p>30 Finding the best ﬁtting parameters D1 , D2 and f is highly ill-posed, especially in the case of six measurement, where for any arbitrarily chosen isotropic compartment there could be found a tensor compartment which exactly ﬁts the data. [sent-49, score-1.126]
</p><p>31 In addition to the DWI data, MTV uses the T2 image to initialize f . [sent-51, score-0.029]
</p><p>32 The initial orientation for the tensor compartment are those that DT-MRI calculated. [sent-52, score-0.7]
</p><p>33 2 The Variational Framework In order to stabilize the ﬁtting process we chose to use the Multiple Tensor Variational (MTV) framework [8] which was previously used to resolve partial volume caused by complex ﬁber architecture [9], and to reduce CSF contamination in cases of hydrocephalus [10]. [sent-54, score-0.385]
</p><p>34 We note that the dual compartment model is a special case of the more general multiple tensor model, where the number of the compartments is restricted to 2 and one of the compartments is restricted to equal eigenvalues (isotropy). [sent-55, score-0.93]
</p><p>35 Therefore the MTV framework adapted for separation of ﬁber compartments from edema is composed of the following functional, whose minima should provide the wanted diffusion parameters: d  S(f, D1 , D2 ) =  Ω  α  ˆ (E(qk ) − E(qk ))2 + φ(|∇Ui1 |) dΩ . [sent-56, score-0.851]
</p><p>36 (4)  k=1  ˆ The notation E is for the observed diffusion signal attenuation and E is calculated using (3) for d different acquisition directions. [sent-57, score-0.514]
</p><p>37 Ω is the image domain with 3D axis (x, y, z), ∂I ∂I ∂I |∇I| = ( ∂x )2 + ( ∂y )2 + ( ∂z )2 is deﬁned as the vector gradient norm. [sent-58, score-0.055]
</p><p>38 The notation Ui1 stands for the principal eigenvector of the i’th diffusion tensor. [sent-59, score-0.458]
</p><p>39 The ﬁxed parameters α is set to keep the solution closer to the observed diffusion signal. [sent-60, score-0.458]
</p><p>40 The function φ is a diffusion ﬂow function, which controls the regularization behavior. [sent-61, score-0.488]
</p><p>41 Here we chose to use φi (s) = s2 1 + K 2 which lead to anisotropic diffusion-like ﬂow while preserving discontinuities i [11]. [sent-62, score-0.025]
</p><p>42 The regularized ﬁtting allows the identiﬁcation of smoothed ﬁber compartments and reduces noise. [sent-63, score-0.074]
</p><p>43 The minimum of (4) solves the Euler-Lagrange equations, and can be found by the gradient descent scheme. [sent-64, score-0.026]
</p><p>44 3 Initialization Scheme Since the functional space is highly irregular (not enough measurements), the minimization process requires initial guess (ﬁgure 1), which is as close as possible to the global minimum. [sent-66, score-0.035]
</p><p>45 In order to apriori estimate the relative volume of the isotropic compartment we used a normalized diffusion non-weighted image, where high contrast correlates to larger ﬂuid volume. [sent-67, score-0.935]
</p><p>46 In order to apriori estimate the parameters of D1 we used the result of conventional DT-MRI ﬁtting on the original data. [sent-68, score-0.069]
</p><p>47 The DT-MRI results were spectrally decomposed and the eigenvectors were used as initial guess for the eigenvectors of D1 . [sent-69, score-0.098]
</p><p>48 The initial guess for  the eigenvalues of D1 were set to λ1 = 1. [sent-70, score-0.063]
</p><p>49 3 methods We demonstrate how partial volume of neuronal ﬁber and edema can be reduced by applying the modiﬁed MTV framework on a brain slice taken from a patient with sever edema surrounding a brain tumor. [sent-73, score-1.073]
</p><p>50 The experimental parameters were as follows: T R/T E = 10000/98ms, ∆/δ = 31/25ms, b = 1000s/mm2 with six diffusion gradient directions. [sent-77, score-0.518]
</p><p>51 48 slices with thickness of 3mm and no gap were acquired covering the whole brain with FOV of 240mm2 and matrix of 128x128. [sent-78, score-0.106]
</p><p>52 Head movement and image distortions were corrected using a mutual information based registration algorithm [12]. [sent-80, score-0.073]
</p><p>53 The corrected DWIs were ﬁtted to the dual compartment model via the modiﬁed MTV framework, then the isotropic compartment was omitted. [sent-81, score-0.79]
</p><p>54 FA was calculated for the remaining tensor for which FA higher than 0. [sent-82, score-0.383]
</p><p>55 We compared these results to single component DT-MRI with no regularization, which was also used for initialization of the MTV ﬁtting. [sent-84, score-0.027]
</p><p>56 4 Results and Discussion  Figure 2: A single slice of a patient with edema. [sent-85, score-0.067]
</p><p>57 (A) a non diffusion weighted image with ROI marked. [sent-86, score-0.539]
</p><p>58 Showing the tumor in black surrounded by sever edema which appear bright. [sent-87, score-0.3]
</p><p>59 A much larger part of the corpus callosum is revealed Figure (2) shows the Edema case, where DTI was unable to delineate large parts of the corpus callosum. [sent-95, score-0.233]
</p><p>60 Since the corpus callosum is one of the largest ﬁber bundles in the brain  it was highly unlikely that the ﬁbers were disconnected or disappeared. [sent-96, score-0.324]
</p><p>61 The expected FA should have been on the same order as on the opposite side of the brain, where the corpus callosum shows high FA values. [sent-97, score-0.139]
</p><p>62 Applying the MTV on the slice and mapping the FA value of the tensor compartment reveals considerably much more pixels of higher FA in the area of the corpus callosum. [sent-98, score-0.796]
</p><p>63 In general the FA values of most pixels were increased, which was predicted, since by removing any size of a sphere (isotropic compartment) we should be left with a shape which is less spherical, and therefore with increased FA. [sent-99, score-0.021]
</p><p>64 The beneﬁt of using the MTV framework over an overall reduce of FA threshold in recognizing neuronal ﬁber voxels is that the amount of FA increase is not uniform in all tissue types. [sent-100, score-0.304]
</p><p>65 In areas where the partial volume was not big due to the edema, the increase was much lower than in areas contaminated with edema. [sent-101, score-0.114]
</p><p>66 This keeps the nice contrast reﬂected by FA values between neuronal ﬁbers and other tissue types. [sent-102, score-0.193]
</p><p>67 Reducing the FA threshold on original DT-MRI results would cause a less clear separation between the ﬁber bundles and other tissue types. [sent-103, score-0.216]
</p><p>68 This tool could be used for ﬁber tracking in the vicinity of brain tumors, or with stroke, where edema contaminates the ﬁbers and prevents ﬁber delineation with the conventional DT-MRI. [sent-104, score-0.497]
</p><p>69 5 Conclusions We show that by modifying the MTV framework to ﬁt the dual compartment model we can reduce the contamination of edema, and delineate much larger ﬁber bundle areas. [sent-105, score-0.569]
</p><p>70 By using the MTV framework we stabilize the ﬁtting process, and also include some biological constraints, such as the piece-wise smoothness nature of neuronal ﬁbers in the brain. [sent-106, score-0.15]
</p><p>71 There is no doubt that using a much larger number of diffusion measurements should increase the stabilization of the process, and will increase its accuracy. [sent-107, score-0.518]
</p><p>72 However, more measurement require much more scan time, which might not be available in some cases. [sent-108, score-0.04]
</p><p>73 The variational framework is a powerful tool for the modeling and regularization of various mappings. [sent-109, score-0.138]
</p><p>74 It is applied, with great success, to scalar and vector ﬁelds in image processing and computer vision. [sent-110, score-0.029]
</p><p>75 Recently it has been generalized to deal with tensor ﬁelds which are of great interest to brain research via the analysis of DWIs and DT-MRI. [sent-111, score-0.489]
</p><p>76 We show that the more realistic model of multi-compartment voxels conjugated with the variational framework provides much improved results. [sent-112, score-0.138]
</p><p>77 Spin diffusion measurements: Spin echoes in the presence of a time-dependant ﬁeld gradient. [sent-115, score-0.458]
</p><p>78 Microstructural and physiological features of tissues elucidated by quantitative-diffusion-tensor MRI. [sent-150, score-0.04]
</p><p>79 Removing CSF contamination in brain DT-MRIs by using a two-compartment tensor model. [sent-165, score-0.589]
</p><p>80 International Society for Magnetic Resonance in Medicine 12th Scientiﬁc meeting ISMRM04, page 1215, Kyoto, Japan, 2004. [sent-167, score-0.066]
</p><p>81 Separation of white matter fascicles from diffusion MRI using φ-functional regularization. [sent-181, score-0.507]
</p><p>82 In Proceedings of 12th Annual Meeting of the ISMRM, page 1227, 2004. [sent-182, score-0.032]
</p><p>83 CSF partial volume reduction in hydrocephalus using a variational framework. [sent-187, score-0.211]
</p><p>84 In Proceedings of 13th Annual Meeting of the ISMRM, page 1100, 2005. [sent-188, score-0.032]
</p><p>85 Mathematical Problems in Image Processing: Partial Differential Equations and the Calculus of Variations, volume 147 of Applied Mathematical Sciences. [sent-192, score-0.05]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('diffusion', 0.458), ('tensor', 0.383), ('compartment', 0.317), ('fa', 0.265), ('edema', 0.26), ('mtv', 0.24), ('ber', 0.222), ('bers', 0.175), ('qk', 0.127), ('tissue', 0.111), ('brain', 0.106), ('contamination', 0.1), ('csf', 0.1), ('sochen', 0.1), ('resonance', 0.089), ('magnetic', 0.089), ('anisotropy', 0.087), ('neuronal', 0.082), ('basser', 0.08), ('callosum', 0.08), ('delineation', 0.08), ('dwis', 0.08), ('pasternak', 0.08), ('bundles', 0.079), ('variational', 0.075), ('isotropic', 0.075), ('water', 0.075), ('compartments', 0.074), ('mri', 0.059), ('corpus', 0.059), ('attenuation', 0.056), ('imaging', 0.055), ('dual', 0.054), ('voxel', 0.052), ('volume', 0.05), ('partial', 0.046), ('barnett', 0.04), ('bqk', 0.04), ('dwi', 0.04), ('fiber', 0.04), ('hydrocephalus', 0.04), ('ismrm', 0.04), ('ltrated', 0.04), ('oferpas', 0.04), ('pierpaoli', 0.04), ('sever', 0.04), ('tissues', 0.04), ('measurement', 0.04), ('slice', 0.037), ('guess', 0.035), ('stabilize', 0.035), ('roi', 0.035), ('apriori', 0.035), ('delineate', 0.035), ('conventional', 0.034), ('six', 0.034), ('meeting', 0.034), ('framework', 0.033), ('page', 0.032), ('mr', 0.032), ('israel', 0.031), ('tting', 0.031), ('reduce', 0.03), ('non', 0.03), ('regularization', 0.03), ('patient', 0.03), ('voxels', 0.03), ('image', 0.029), ('eigenvalues', 0.028), ('matter', 0.028), ('initialization', 0.027), ('corrected', 0.027), ('spin', 0.027), ('gradient', 0.026), ('architecture', 0.026), ('separation', 0.026), ('medicine', 0.025), ('chose', 0.025), ('measurements', 0.024), ('eigenvectors', 0.023), ('ow', 0.023), ('surrounding', 0.023), ('weighted', 0.022), ('white', 0.021), ('removing', 0.021), ('visualization', 0.019), ('tted', 0.019), ('increase', 0.018), ('causes', 0.018), ('tracking', 0.017), ('hagen', 0.017), ('fluid', 0.017), ('adams', 0.017), ('mori', 0.017), ('spectrally', 0.017), ('microstructure', 0.017), ('clark', 0.017), ('distortions', 0.017), ('je', 0.017), ('molecules', 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="135-tfidf-1" href="./nips-2005-Neuronal_Fiber_Delineation_in_Area_of_Edema_from_Diffusion_Weighted_MRI.html">135 nips-2005-Neuronal Fiber Delineation in Area of Edema from Diffusion Weighted MRI</a></p>
<p>Author: Ofer Pasternak, Nathan Intrator, Nir Sochen, Yaniv Assaf</p><p>Abstract: Diffusion Tensor Magnetic Resonance Imaging (DT-MRI) is a non invasive method for brain neuronal ﬁbers delineation. Here we show a modiﬁcation for DT-MRI that allows delineation of neuronal ﬁbers which are inﬁltrated by edema. We use the Muliple Tensor Variational (MTV) framework which replaces the diffusion model of DT-MRI with a multiple component model and ﬁts it to the signal attenuation with a variational regularization mechanism. In order to reduce free water contamination we estimate the free water compartment volume fraction in each voxel, remove it, and then calculate the anisotropy of the remaining compartment. The variational framework was applied on data collected with conventional clinical parameters, containing only six diffusion directions. By using the variational framework we were able to overcome the highly ill posed ﬁtting. The results show that we were able to ﬁnd ﬁbers that were not found by DT-MRI.</p><p>2 0.24565256 <a title="135-tfidf-2" href="./nips-2005-Diffusion_Maps%2C_Spectral_Clustering_and_Eigenfunctions_of_Fokker-Planck_Operators.html">56 nips-2005-Diffusion Maps, Spectral Clustering and Eigenfunctions of Fokker-Planck Operators</a></p>
<p>Author: Boaz Nadler, Stephane Lafon, Ioannis Kevrekidis, Ronald R. Coifman</p><p>Abstract: This paper presents a diffusion based probabilistic interpretation of spectral clustering and dimensionality reduction algorithms that use the eigenvectors of the normalized graph Laplacian. Given the pairwise adjacency matrix of all points, we deﬁne a diffusion distance between any two data points and show that the low dimensional representation of the data by the ﬁrst few eigenvectors of the corresponding Markov matrix is optimal under a certain mean squared error criterion. Furthermore, assuming that data points are random samples from a density p(x) = e−U (x) we identify these eigenvectors as discrete approximations of eigenfunctions of a Fokker-Planck operator in a potential 2U (x) with reﬂecting boundary conditions. Finally, applying known results regarding the eigenvalues and eigenfunctions of the continuous Fokker-Planck operator, we provide a mathematical justiﬁcation for the success of spectral clustering and dimensional reduction algorithms based on these ﬁrst few eigenvectors. This analysis elucidates, in terms of the characteristics of diffusion processes, many empirical ﬁndings regarding spectral clustering algorithms. Keywords: Algorithms and architectures, learning theory. 1</p><p>3 0.19576272 <a title="135-tfidf-3" href="./nips-2005-Value_Function_Approximation_with_Diffusion_Wavelets_and_Laplacian_Eigenfunctions.html">199 nips-2005-Value Function Approximation with Diffusion Wavelets and Laplacian Eigenfunctions</a></p>
<p>Author: Sridhar Mahadevan, Mauro Maggioni</p><p>Abstract: We investigate the problem of automatically constructing efﬁcient representations or basis functions for approximating value functions based on analyzing the structure and topology of the state space. In particular, two novel approaches to value function approximation are explored based on automatically constructing basis functions on state spaces that can be represented as graphs or manifolds: one approach uses the eigenfunctions of the Laplacian, in effect performing a global Fourier analysis on the graph; the second approach is based on diffusion wavelets, which generalize classical wavelets to graphs using multiscale dilations induced by powers of a diffusion operator or random walk on the graph. Together, these approaches form the foundation of a new generation of methods for solving large Markov decision processes, in which the underlying representation and policies are simultaneously learned.</p><p>4 0.14545535 <a title="135-tfidf-4" href="./nips-2005-Tensor_Subspace_Analysis.html">189 nips-2005-Tensor Subspace Analysis</a></p>
<p>Author: Xiaofei He, Deng Cai, Partha Niyogi</p><p>Abstract: Previous work has demonstrated that the image variations of many objects (human faces in particular) under variable lighting can be effectively modeled by low dimensional linear spaces. The typical linear subspace learning algorithms include Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA), and Locality Preserving Projection (LPP). All of these methods consider an n1 × n2 image as a high dimensional vector in Rn1 ×n2 , while an image represented in the plane is intrinsically a matrix. In this paper, we propose a new algorithm called Tensor Subspace Analysis (TSA). TSA considers an image as the second order tensor in Rn1 ⊗ Rn2 , where Rn1 and Rn2 are two vector spaces. The relationship between the column vectors of the image matrix and that between the row vectors can be naturally characterized by TSA. TSA detects the intrinsic local geometrical structure of the tensor space by learning a lower dimensional tensor subspace. We compare our proposed approach with PCA, LDA and LPP methods on two standard databases. Experimental results demonstrate that TSA achieves better recognition rate, while being much more efﬁcient. 1</p><p>5 0.071504459 <a title="135-tfidf-5" href="./nips-2005-Estimation_of_Intrinsic_Dimensionality_Using_High-Rate_Vector_Quantization.html">66 nips-2005-Estimation of Intrinsic Dimensionality Using High-Rate Vector Quantization</a></p>
<p>Author: Maxim Raginsky, Svetlana Lazebnik</p><p>Abstract: We introduce a technique for dimensionality estimation based on the notion of quantization dimension, which connects the asymptotic optimal quantization error for a probability distribution on a manifold to its intrinsic dimension. The deﬁnition of quantization dimension yields a family of estimation algorithms, whose limiting case is equivalent to a recent method based on packing numbers. Using the formalism of high-rate vector quantization, we address issues of statistical consistency and analyze the behavior of our scheme in the presence of noise.</p><p>6 0.062432379 <a title="135-tfidf-6" href="./nips-2005-Large-scale_biophysical_parameter_estimation_in_single_neurons_via_constrained_linear_regression.html">106 nips-2005-Large-scale biophysical parameter estimation in single neurons via constrained linear regression</a></p>
<p>7 0.062246379 <a title="135-tfidf-7" href="./nips-2005-An_Application_of_Markov_Random_Fields_to_Range_Sensing.html">23 nips-2005-An Application of Markov Random Fields to Range Sensing</a></p>
<p>8 0.059695333 <a title="135-tfidf-8" href="./nips-2005-Modeling_Neuronal_Interactivity_using_Dynamic_Bayesian_Networks.html">130 nips-2005-Modeling Neuronal Interactivity using Dynamic Bayesian Networks</a></p>
<p>9 0.053992316 <a title="135-tfidf-9" href="./nips-2005-Identifying_Distributed_Object_Representations_in_Human_Extrastriate_Visual_Cortex.html">94 nips-2005-Identifying Distributed Object Representations in Human Extrastriate Visual Cortex</a></p>
<p>10 0.047243662 <a title="135-tfidf-10" href="./nips-2005-Gaussian_Processes_for_Multiuser_Detection_in_CDMA_receivers.html">81 nips-2005-Gaussian Processes for Multiuser Detection in CDMA receivers</a></p>
<p>11 0.047213752 <a title="135-tfidf-11" href="./nips-2005-Variational_EM_Algorithms_for_Non-Gaussian_Latent_Variable_Models.html">202 nips-2005-Variational EM Algorithms for Non-Gaussian Latent Variable Models</a></p>
<p>12 0.045611877 <a title="135-tfidf-12" href="./nips-2005-Modeling_Memory_Transfer_and_Saving_in_Cerebellar_Motor_Learning.html">128 nips-2005-Modeling Memory Transfer and Saving in Cerebellar Motor Learning</a></p>
<p>13 0.036585283 <a title="135-tfidf-13" href="./nips-2005-Norepinephrine_and_Neural_Interrupts.html">141 nips-2005-Norepinephrine and Neural Interrupts</a></p>
<p>14 0.036174908 <a title="135-tfidf-14" href="./nips-2005-Variational_Bayesian_Stochastic_Complexity_of_Mixture_Models.html">201 nips-2005-Variational Bayesian Stochastic Complexity of Mixture Models</a></p>
<p>15 0.034014974 <a title="135-tfidf-15" href="./nips-2005-Correlated_Topic_Models.html">52 nips-2005-Correlated Topic Models</a></p>
<p>16 0.033419181 <a title="135-tfidf-16" href="./nips-2005-Analyzing_Coupled_Brain_Sources%3A_Distinguishing_True_from_Spurious_Interaction.html">29 nips-2005-Analyzing Coupled Brain Sources: Distinguishing True from Spurious Interaction</a></p>
<p>17 0.030189674 <a title="135-tfidf-17" href="./nips-2005-Combining_Graph_Laplacians_for_Semi--Supervised_Learning.html">42 nips-2005-Combining Graph Laplacians for Semi--Supervised Learning</a></p>
<p>18 0.029239729 <a title="135-tfidf-18" href="./nips-2005-Optimizing_spatio-temporal_filters_for_improving_Brain-Computer_Interfacing.html">150 nips-2005-Optimizing spatio-temporal filters for improving Brain-Computer Interfacing</a></p>
<p>19 0.028990928 <a title="135-tfidf-19" href="./nips-2005-Learning_to_Control_an_Octopus_Arm_with_Gaussian_Process_Temporal_Difference_Methods.html">119 nips-2005-Learning to Control an Octopus Arm with Gaussian Process Temporal Difference Methods</a></p>
<p>20 0.027244169 <a title="135-tfidf-20" href="./nips-2005-Radial_Basis_Function_Network_for_Multi-task_Learning.html">161 nips-2005-Radial Basis Function Network for Multi-task Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2005_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.1), (1, 0.016), (2, -0.005), (3, 0.016), (4, -0.147), (5, -0.029), (6, -0.041), (7, -0.173), (8, 0.094), (9, -0.136), (10, 0.133), (11, 0.076), (12, 0.067), (13, -0.193), (14, -0.161), (15, -0.107), (16, -0.249), (17, -0.117), (18, 0.102), (19, -0.021), (20, -0.038), (21, 0.074), (22, 0.175), (23, -0.09), (24, -0.233), (25, 0.096), (26, 0.028), (27, 0.186), (28, 0.12), (29, 0.053), (30, -0.024), (31, -0.052), (32, 0.015), (33, -0.037), (34, -0.057), (35, 0.033), (36, 0.112), (37, 0.014), (38, 0.023), (39, 0.055), (40, -0.058), (41, -0.01), (42, 0.124), (43, -0.038), (44, 0.104), (45, 0.055), (46, -0.032), (47, 0.0), (48, -0.071), (49, 0.052)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98344797 <a title="135-lsi-1" href="./nips-2005-Neuronal_Fiber_Delineation_in_Area_of_Edema_from_Diffusion_Weighted_MRI.html">135 nips-2005-Neuronal Fiber Delineation in Area of Edema from Diffusion Weighted MRI</a></p>
<p>Author: Ofer Pasternak, Nathan Intrator, Nir Sochen, Yaniv Assaf</p><p>Abstract: Diffusion Tensor Magnetic Resonance Imaging (DT-MRI) is a non invasive method for brain neuronal ﬁbers delineation. Here we show a modiﬁcation for DT-MRI that allows delineation of neuronal ﬁbers which are inﬁltrated by edema. We use the Muliple Tensor Variational (MTV) framework which replaces the diffusion model of DT-MRI with a multiple component model and ﬁts it to the signal attenuation with a variational regularization mechanism. In order to reduce free water contamination we estimate the free water compartment volume fraction in each voxel, remove it, and then calculate the anisotropy of the remaining compartment. The variational framework was applied on data collected with conventional clinical parameters, containing only six diffusion directions. By using the variational framework we were able to overcome the highly ill posed ﬁtting. The results show that we were able to ﬁnd ﬁbers that were not found by DT-MRI.</p><p>2 0.64482599 <a title="135-lsi-2" href="./nips-2005-Diffusion_Maps%2C_Spectral_Clustering_and_Eigenfunctions_of_Fokker-Planck_Operators.html">56 nips-2005-Diffusion Maps, Spectral Clustering and Eigenfunctions of Fokker-Planck Operators</a></p>
<p>Author: Boaz Nadler, Stephane Lafon, Ioannis Kevrekidis, Ronald R. Coifman</p><p>Abstract: This paper presents a diffusion based probabilistic interpretation of spectral clustering and dimensionality reduction algorithms that use the eigenvectors of the normalized graph Laplacian. Given the pairwise adjacency matrix of all points, we deﬁne a diffusion distance between any two data points and show that the low dimensional representation of the data by the ﬁrst few eigenvectors of the corresponding Markov matrix is optimal under a certain mean squared error criterion. Furthermore, assuming that data points are random samples from a density p(x) = e−U (x) we identify these eigenvectors as discrete approximations of eigenfunctions of a Fokker-Planck operator in a potential 2U (x) with reﬂecting boundary conditions. Finally, applying known results regarding the eigenvalues and eigenfunctions of the continuous Fokker-Planck operator, we provide a mathematical justiﬁcation for the success of spectral clustering and dimensional reduction algorithms based on these ﬁrst few eigenvectors. This analysis elucidates, in terms of the characteristics of diffusion processes, many empirical ﬁndings regarding spectral clustering algorithms. Keywords: Algorithms and architectures, learning theory. 1</p><p>3 0.61159611 <a title="135-lsi-3" href="./nips-2005-Value_Function_Approximation_with_Diffusion_Wavelets_and_Laplacian_Eigenfunctions.html">199 nips-2005-Value Function Approximation with Diffusion Wavelets and Laplacian Eigenfunctions</a></p>
<p>Author: Sridhar Mahadevan, Mauro Maggioni</p><p>Abstract: We investigate the problem of automatically constructing efﬁcient representations or basis functions for approximating value functions based on analyzing the structure and topology of the state space. In particular, two novel approaches to value function approximation are explored based on automatically constructing basis functions on state spaces that can be represented as graphs or manifolds: one approach uses the eigenfunctions of the Laplacian, in effect performing a global Fourier analysis on the graph; the second approach is based on diffusion wavelets, which generalize classical wavelets to graphs using multiscale dilations induced by powers of a diffusion operator or random walk on the graph. Together, these approaches form the foundation of a new generation of methods for solving large Markov decision processes, in which the underlying representation and policies are simultaneously learned.</p><p>4 0.35105234 <a title="135-lsi-4" href="./nips-2005-Tensor_Subspace_Analysis.html">189 nips-2005-Tensor Subspace Analysis</a></p>
<p>Author: Xiaofei He, Deng Cai, Partha Niyogi</p><p>Abstract: Previous work has demonstrated that the image variations of many objects (human faces in particular) under variable lighting can be effectively modeled by low dimensional linear spaces. The typical linear subspace learning algorithms include Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA), and Locality Preserving Projection (LPP). All of these methods consider an n1 × n2 image as a high dimensional vector in Rn1 ×n2 , while an image represented in the plane is intrinsically a matrix. In this paper, we propose a new algorithm called Tensor Subspace Analysis (TSA). TSA considers an image as the second order tensor in Rn1 ⊗ Rn2 , where Rn1 and Rn2 are two vector spaces. The relationship between the column vectors of the image matrix and that between the row vectors can be naturally characterized by TSA. TSA detects the intrinsic local geometrical structure of the tensor space by learning a lower dimensional tensor subspace. We compare our proposed approach with PCA, LDA and LPP methods on two standard databases. Experimental results demonstrate that TSA achieves better recognition rate, while being much more efﬁcient. 1</p><p>5 0.27173278 <a title="135-lsi-5" href="./nips-2005-Modeling_Neuronal_Interactivity_using_Dynamic_Bayesian_Networks.html">130 nips-2005-Modeling Neuronal Interactivity using Dynamic Bayesian Networks</a></p>
<p>Author: Lei Zhang, Dimitris Samaras, Nelly Alia-klein, Nora Volkow, Rita Goldstein</p><p>Abstract: Functional Magnetic Resonance Imaging (fMRI) has enabled scientists to look into the active brain. However, interactivity between functional brain regions, is still little studied. In this paper, we contribute a novel framework for modeling the interactions between multiple active brain regions, using Dynamic Bayesian Networks (DBNs) as generative models for brain activation patterns. This framework is applied to modeling of neuronal circuits associated with reward. The novelty of our framework from a Machine Learning perspective lies in the use of DBNs to reveal the brain connectivity and interactivity. Such interactivity models which are derived from fMRI data are then validated through a group classiﬁcation task. We employ and compare four different types of DBNs: Parallel Hidden Markov Models, Coupled Hidden Markov Models, Fully-linked Hidden Markov Models and Dynamically MultiLinked HMMs (DML-HMM). Moreover, we propose and compare two schemes of learning DML-HMMs. Experimental results show that by using DBNs, group classiﬁcation can be performed even if the DBNs are constructed from as few as 5 brain regions. We also demonstrate that, by using the proposed learning algorithms, different DBN structures characterize drug addicted subjects vs. control subjects. This ﬁnding provides an independent test for the effect of psychopathology on brain function. In general, we demonstrate that incorporation of computer science principles into functional neuroimaging clinical studies provides a novel approach for probing human brain function.</p><p>6 0.25408828 <a title="135-lsi-6" href="./nips-2005-Modeling_Memory_Transfer_and_Saving_in_Cerebellar_Motor_Learning.html">128 nips-2005-Modeling Memory Transfer and Saving in Cerebellar Motor Learning</a></p>
<p>7 0.23332234 <a title="135-lsi-7" href="./nips-2005-Fast_Krylov_Methods_for_N-Body_Learning.html">71 nips-2005-Fast Krylov Methods for N-Body Learning</a></p>
<p>8 0.21944743 <a title="135-lsi-8" href="./nips-2005-Identifying_Distributed_Object_Representations_in_Human_Extrastriate_Visual_Cortex.html">94 nips-2005-Identifying Distributed Object Representations in Human Extrastriate Visual Cortex</a></p>
<p>9 0.2188632 <a title="135-lsi-9" href="./nips-2005-Gaussian_Processes_for_Multiuser_Detection_in_CDMA_receivers.html">81 nips-2005-Gaussian Processes for Multiuser Detection in CDMA receivers</a></p>
<p>10 0.19521332 <a title="135-lsi-10" href="./nips-2005-Large-scale_biophysical_parameter_estimation_in_single_neurons_via_constrained_linear_regression.html">106 nips-2005-Large-scale biophysical parameter estimation in single neurons via constrained linear regression</a></p>
<p>11 0.1684224 <a title="135-lsi-11" href="./nips-2005-Stimulus_Evoked_Independent_Factor_Analysis_of_MEG_Data_with_Large_Background_Activity.html">183 nips-2005-Stimulus Evoked Independent Factor Analysis of MEG Data with Large Background Activity</a></p>
<p>12 0.14704378 <a title="135-lsi-12" href="./nips-2005-Radial_Basis_Function_Network_for_Multi-task_Learning.html">161 nips-2005-Radial Basis Function Network for Multi-task Learning</a></p>
<p>13 0.14702435 <a title="135-lsi-13" href="./nips-2005-An_Approximate_Inference_Approach_for_the_PCA_Reconstruction_Error.html">24 nips-2005-An Approximate Inference Approach for the PCA Reconstruction Error</a></p>
<p>14 0.14204727 <a title="135-lsi-14" href="./nips-2005-A_Bayesian_Spatial_Scan_Statistic.html">4 nips-2005-A Bayesian Spatial Scan Statistic</a></p>
<p>15 0.13910842 <a title="135-lsi-15" href="./nips-2005-Off-Road_Obstacle_Avoidance_through_End-to-End_Learning.html">143 nips-2005-Off-Road Obstacle Avoidance through End-to-End Learning</a></p>
<p>16 0.13837738 <a title="135-lsi-16" href="./nips-2005-Temporally_changing_synaptic_plasticity.html">188 nips-2005-Temporally changing synaptic plasticity</a></p>
<p>17 0.13641199 <a title="135-lsi-17" href="./nips-2005-Estimation_of_Intrinsic_Dimensionality_Using_High-Rate_Vector_Quantization.html">66 nips-2005-Estimation of Intrinsic Dimensionality Using High-Rate Vector Quantization</a></p>
<p>18 0.1336751 <a title="135-lsi-18" href="./nips-2005-Factorial_Switching_Kalman_Filters_for_Condition_Monitoring_in_Neonatal_Intensive_Care.html">68 nips-2005-Factorial Switching Kalman Filters for Condition Monitoring in Neonatal Intensive Care</a></p>
<p>19 0.13185495 <a title="135-lsi-19" href="./nips-2005-Analyzing_Coupled_Brain_Sources%3A_Distinguishing_True_from_Spurious_Interaction.html">29 nips-2005-Analyzing Coupled Brain Sources: Distinguishing True from Spurious Interaction</a></p>
<p>20 0.13111074 <a title="135-lsi-20" href="./nips-2005-An_Application_of_Markov_Random_Fields_to_Range_Sensing.html">23 nips-2005-An Application of Markov Random Fields to Range Sensing</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2005_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.029), (10, 0.031), (12, 0.51), (27, 0.021), (31, 0.035), (34, 0.058), (39, 0.013), (41, 0.016), (55, 0.027), (69, 0.032), (73, 0.022), (88, 0.05), (91, 0.022)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.87214535 <a title="135-lda-1" href="./nips-2005-Neuronal_Fiber_Delineation_in_Area_of_Edema_from_Diffusion_Weighted_MRI.html">135 nips-2005-Neuronal Fiber Delineation in Area of Edema from Diffusion Weighted MRI</a></p>
<p>Author: Ofer Pasternak, Nathan Intrator, Nir Sochen, Yaniv Assaf</p><p>Abstract: Diffusion Tensor Magnetic Resonance Imaging (DT-MRI) is a non invasive method for brain neuronal ﬁbers delineation. Here we show a modiﬁcation for DT-MRI that allows delineation of neuronal ﬁbers which are inﬁltrated by edema. We use the Muliple Tensor Variational (MTV) framework which replaces the diffusion model of DT-MRI with a multiple component model and ﬁts it to the signal attenuation with a variational regularization mechanism. In order to reduce free water contamination we estimate the free water compartment volume fraction in each voxel, remove it, and then calculate the anisotropy of the remaining compartment. The variational framework was applied on data collected with conventional clinical parameters, containing only six diffusion directions. By using the variational framework we were able to overcome the highly ill posed ﬁtting. The results show that we were able to ﬁnd ﬁbers that were not found by DT-MRI.</p><p>2 0.6400485 <a title="135-lda-2" href="./nips-2005-Generalized_Nonnegative_Matrix_Approximations_with_Bregman_Divergences.html">86 nips-2005-Generalized Nonnegative Matrix Approximations with Bregman Divergences</a></p>
<p>Author: Suvrit Sra, Inderjit S. Dhillon</p><p>Abstract: Nonnegative matrix approximation (NNMA) is a recent technique for dimensionality reduction and data analysis that yields a parts based, sparse nonnegative representation for nonnegative input data. NNMA has found a wide variety of applications, including text analysis, document clustering, face/image recognition, language modeling, speech processing and many others. Despite these numerous applications, the algorithmic development for computing the NNMA factors has been relatively deﬁcient. This paper makes algorithmic progress by modeling and solving (using multiplicative updates) new generalized NNMA problems that minimize Bregman divergences between the input matrix and its lowrank approximation. The multiplicative update formulae in the pioneering work by Lee and Seung [11] arise as a special case of our algorithms. In addition, the paper shows how to use penalty functions for incorporating constraints other than nonnegativity into the problem. Further, some interesting extensions to the use of “link” functions for modeling nonlinear relationships are also discussed. 1</p><p>3 0.60290271 <a title="135-lda-3" href="./nips-2005-Learning_Topology_with_the_Generative_Gaussian_Graph_and_the_EM_Algorithm.html">116 nips-2005-Learning Topology with the Generative Gaussian Graph and the EM Algorithm</a></p>
<p>Author: Michaël Aupetit</p><p>Abstract: Given a set of points and a set of prototypes representing them, how to create a graph of the prototypes whose topology accounts for that of the points? This problem had not yet been explored in the framework of statistical learning theory. In this work, we propose a generative model based on the Delaunay graph of the prototypes and the ExpectationMaximization algorithm to learn the parameters. This work is a ﬁrst step towards the construction of a topological model of a set of points grounded on statistics. 1 1.1</p><p>4 0.52549511 <a title="135-lda-4" href="./nips-2005-Analyzing_Auditory_Neurons_by_Learning_Distance_Functions.html">28 nips-2005-Analyzing Auditory Neurons by Learning Distance Functions</a></p>
<p>Author: Inna Weiner, Tomer Hertz, Israel Nelken, Daphna Weinshall</p><p>Abstract: We present a novel approach to the characterization of complex sensory neurons. One of the main goals of characterizing sensory neurons is to characterize dimensions in stimulus space to which the neurons are highly sensitive (causing large gradients in the neural responses) or alternatively dimensions in stimulus space to which the neuronal response are invariant (deﬁning iso-response manifolds). We formulate this problem as that of learning a geometry on stimulus space that is compatible with the neural responses: the distance between stimuli should be large when the responses they evoke are very different, and small when the responses they evoke are similar. Here we show how to successfully train such distance functions using rather limited amount of information. The data consisted of the responses of neurons in primary auditory cortex (A1) of anesthetized cats to 32 stimuli derived from natural sounds. For each neuron, a subset of all pairs of stimuli was selected such that the responses of the two stimuli in a pair were either very similar or very dissimilar. The distance function was trained to ﬁt these constraints. The resulting distance functions generalized to predict the distances between the responses of a test stimulus and the trained stimuli. 1</p><p>5 0.23398368 <a title="135-lda-5" href="./nips-2005-Identifying_Distributed_Object_Representations_in_Human_Extrastriate_Visual_Cortex.html">94 nips-2005-Identifying Distributed Object Representations in Human Extrastriate Visual Cortex</a></p>
<p>Author: Rory Sayres, David Ress, Kalanit Grill-spector</p><p>Abstract: The category of visual stimuli has been reliably decoded from patterns of neural activity in extrastriate visual cortex [1]. It has yet to be seen whether object identity can be inferred from this activity. We present fMRI data measuring responses in human extrastriate cortex to a set of 12 distinct object images. We use a simple winner-take-all classifier, using half the data from each recording session as a training set, to evaluate encoding of object identity across fMRI voxels. Since this approach is sensitive to the inclusion of noisy voxels, we describe two methods for identifying subsets of voxels in the data which optimally distinguish object identity. One method characterizes the reliability of each voxel within subsets of the data, while another estimates the mutual information of each voxel with the stimulus set. We find that both metrics can identify subsets of the data which reliably encode object identity, even when noisy measurements are artificially added to the data. The mutual information metric is less efficient at this task, likely due to constraints in fMRI data. 1</p><p>6 0.20154217 <a title="135-lda-6" href="./nips-2005-Preconditioner_Approximations_for_Probabilistic_Graphical_Models.html">154 nips-2005-Preconditioner Approximations for Probabilistic Graphical Models</a></p>
<p>7 0.20147455 <a title="135-lda-7" href="./nips-2005-Off-policy_Learning_with_Options_and_Recognizers.html">144 nips-2005-Off-policy Learning with Options and Recognizers</a></p>
<p>8 0.20069069 <a title="135-lda-8" href="./nips-2005-From_Weighted_Classification_to_Policy_Search.html">78 nips-2005-From Weighted Classification to Policy Search</a></p>
<p>9 0.20031314 <a title="135-lda-9" href="./nips-2005-An_Application_of_Markov_Random_Fields_to_Range_Sensing.html">23 nips-2005-An Application of Markov Random Fields to Range Sensing</a></p>
<p>10 0.20018961 <a title="135-lda-10" href="./nips-2005-Structured_Prediction_via_the_Extragradient_Method.html">184 nips-2005-Structured Prediction via the Extragradient Method</a></p>
<p>11 0.19955763 <a title="135-lda-11" href="./nips-2005-Nearest_Neighbor_Based_Feature_Selection_for_Regression_and_its_Application_to_Neural_Activity.html">132 nips-2005-Nearest Neighbor Based Feature Selection for Regression and its Application to Neural Activity</a></p>
<p>12 0.19856539 <a title="135-lda-12" href="./nips-2005-Size_Regularized_Cut_for_Data_Clustering.html">177 nips-2005-Size Regularized Cut for Data Clustering</a></p>
<p>13 0.19736198 <a title="135-lda-13" href="./nips-2005-Convex_Neural_Networks.html">50 nips-2005-Convex Neural Networks</a></p>
<p>14 0.19702539 <a title="135-lda-14" href="./nips-2005-Comparing_the_Effects_of_Different_Weight_Distributions_on_Finding_Sparse_Representations.html">43 nips-2005-Comparing the Effects of Different Weight Distributions on Finding Sparse Representations</a></p>
<p>15 0.19684345 <a title="135-lda-15" href="./nips-2005-Inference_with_Minimal_Communication%3A_a_Decision-Theoretic_Variational_Approach.html">96 nips-2005-Inference with Minimal Communication: a Decision-Theoretic Variational Approach</a></p>
<p>16 0.19680184 <a title="135-lda-16" href="./nips-2005-Variable_KD-Tree_Algorithms_for_Spatial_Pattern_Search_and_Discovery.html">200 nips-2005-Variable KD-Tree Algorithms for Spatial Pattern Search and Discovery</a></p>
<p>17 0.19627692 <a title="135-lda-17" href="./nips-2005-Hyperparameter_and_Kernel_Learning_for_Graph_Based_Semi-Supervised_Classification.html">92 nips-2005-Hyperparameter and Kernel Learning for Graph Based Semi-Supervised Classification</a></p>
<p>18 0.19577406 <a title="135-lda-18" href="./nips-2005-Fast_Online_Policy_Gradient_Learning_with_SMD_Gain_Vector_Adaptation.html">72 nips-2005-Fast Online Policy Gradient Learning with SMD Gain Vector Adaptation</a></p>
<p>19 0.19566236 <a title="135-lda-19" href="./nips-2005-Assessing_Approximations_for_Gaussian_Process_Classification.html">30 nips-2005-Assessing Approximations for Gaussian Process Classification</a></p>
<p>20 0.19541207 <a title="135-lda-20" href="./nips-2005-Hot_Coupling%3A_A_Particle_Approach_to_Inference_and_Normalization_on_Pairwise_Undirected_Graphs.html">90 nips-2005-Hot Coupling: A Particle Approach to Inference and Normalization on Pairwise Undirected Graphs</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
