<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>82 nips-2005-Generalization Error Bounds for Aggregation by Mirror Descent with Averaging</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2005" href="../home/nips2005_home.html">nips2005</a> <a title="nips-2005-82" href="#">nips2005-82</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>82 nips-2005-Generalization Error Bounds for Aggregation by Mirror Descent with Averaging</h1>
<br/><p>Source: <a title="nips-2005-82-pdf" href="http://papers.nips.cc/paper/2779-generalization-error-bounds-for-aggregation-by-mirror-descent-with-averaging.pdf">pdf</a></p><p>Author: Anatoli Juditsky, Alexander Nazin, Alexandre Tsybakov, Nicolas Vayatis</p><p>Abstract: We consider the problem of constructing an aggregated estimator from a ﬁnite class of base functions which approximately minimizes a convex risk functional under the ℓ1 constraint. For this purpose, we propose a stochastic procedure, the mirror descent, which performs gradient descent in the dual space. The generated estimates are additionally averaged in a recursive fashion with speciﬁc weights. Mirror descent algorithms have been developed in different contexts and they are known to be particularly efﬁcient in high dimensional problems. Moreover their implementation is adapted to the online setting. The main result of the paper is the upper bound on the convergence rate for the generalization error. 1</p><p>Reference: <a title="nips-2005-82-reference" href="../nips2005_reference/nips-2005-Generalization_Error_Bounds_for_Aggregation_by_Mirror_Descent_with_Averaging_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 ru Alexandre Tsybakov Laboratoire de Probabilit´ s et Mod` les Al´ atoires - Universit´ Paris VI e e e e 4, place Jussieu, 75252 Paris Cedex, France tsybakov@ccr. [sent-8, score-0.146]
</p><p>2 fr Nicolas Vayatis Laboratoire de Probabilit´ s et Mod` les Al´ atoires - Universit´ Paris VI e e e e 4, place Jussieu, 75252 Paris Cedex, France vayatis@ccr. [sent-10, score-0.146]
</p><p>3 fr  Abstract We consider the problem of constructing an aggregated estimator from a ﬁnite class of base functions which approximately minimizes a convex risk functional under the ℓ1 constraint. [sent-12, score-0.541]
</p><p>4 For this purpose, we propose a stochastic procedure, the mirror descent, which performs gradient descent in the dual space. [sent-13, score-1.014]
</p><p>5 The generated estimates are additionally averaged in a recursive fashion with speciﬁc weights. [sent-14, score-0.08]
</p><p>6 Mirror descent algorithms have been developed in different contexts and they are known to be particularly efﬁcient in high dimensional problems. [sent-15, score-0.325]
</p><p>7 Moreover their implementation is adapted to the online setting. [sent-16, score-0.035]
</p><p>8 The main result of the paper is the upper bound on the convergence rate for the generalization error. [sent-17, score-0.124]
</p><p>9 1  Introduction  We consider the aggregation problem (cf. [sent-18, score-0.16]
</p><p>10 [16]) where we have at hand a ﬁnite class of M predictors which are to be combined linearly under an ℓ1 constraint θ 1 = λ on the vector θ ∈ RM that determines the coefﬁcients of the linear combination. [sent-19, score-0.12]
</p><p>11 In order to exhibit such a combination, we focus on the strategy of penalized convex risk minimization which  is motivated by recent statistical studies of boosting and SVM algorithms [11, 14, 18]. [sent-20, score-0.51]
</p><p>12 Moreover, we take a stochastic approximation approach which is particularly relevant in the online setting since it leads to recursive algorithms where the update uses a single data observation per iteration step. [sent-21, score-0.377]
</p><p>13 In this paper, we consider a general setting for which we propose a novel stochastic gradient algorithm and show tight upper bounds on its expected accuracy. [sent-22, score-0.413]
</p><p>14 Our algorithm builds on the ideas of mirror descent methods, ﬁrst introduced by Nemirovski and Yudin [12], which consider updates of the gradient in the dual space. [sent-23, score-0.954]
</p><p>15 The mirror descent algorithm has been successfully applied in high dimensional problems both in deterministic and stochastic settings [2, 7]. [sent-24, score-0.814]
</p><p>16 In the present work, we describe a particular instance of the algorithm with an entropy-like proxy function. [sent-25, score-0.224]
</p><p>17 This method presents similarities with the exponentiated gradient descent algorithm which was derived under different motivations in [10]. [sent-26, score-0.593]
</p><p>18 A crucial distinction between the two is the additional averaging step in our version which guarantees statistical performance. [sent-27, score-0.073]
</p><p>19 The idea of averaging recursive procedures is well-known (see e. [sent-28, score-0.207]
</p><p>20 [13] and the references therein) and it has been invoked recently by Zhang [19] for the standard stochastic gradient descent (taking place in the initial parameter space). [sent-30, score-0.629]
</p><p>21 Also it is worth noticing that most of the existing online methods are evaluated in terms of relative loss bounds which are related to the empirical risk while we focus on generalization error bounds (see [4, 5, 10] for insights on connections between the two types of criteria). [sent-31, score-0.551]
</p><p>22 We ﬁrst introduce the setup (Section 2), then we describe the algorithm and state the main convergence result (Section 3). [sent-33, score-0.12]
</p><p>23 2  Setup and notations  Let Z be a random variable with values in a measurable space (Z, A). [sent-36, score-0.041]
</p><p>24 (1)  Now we introduce the loss function Q : Θ × Z → R+ such that the random function Q(· , Z) : Θ → R+ is convex for almost all Z and deﬁne the convex risk function A : Θ → R+ to be minimized as follows: A(θ) = E Q(θ, Z) . [sent-42, score-0.696]
</p><p>25 We propose to minimize the convex target function A over the decision set Θ on the basis of the stochastic sub-gradients of Q: ui (θ) = ∇θ Q(θ, Zi ) ,  i = 1, 2, . [sent-51, score-0.544]
</p><p>26 ,  (3)  Note that the expectations E ui (·) belong to the sub-differential of A(·). [sent-54, score-0.212]
</p><p>27 , Zt−1 ) ∈ Θ of the minimizer of A by the excess risk: E A(θt ) − min A(θ) θ∈Θ  where the expectation is taken over the sample (Z1 , . [sent-58, score-0.127]
</p><p>28 (4)  We now introduce the notation that is necessary to present the algorithm in the next section. [sent-62, score-0.075]
</p><p>29 , z (M ) z  def 1  =  M j=1  ∈ RM , deﬁne the norms  |z (j) | ,  def  z  The space RM equipped with the norm space equipped with the dual norm ·  ∞  ·  ∞  = max z T θ = θ  1 =1  max |z (j) | . [sent-66, score-0.412]
</p><p>30 ,M  1 is called the primal space E and the same is called the dual space E ∗ . [sent-70, score-0.084]
</p><p>31 Introduce a so-called entropic proxy function: ∀ θ ∈ Θ,  M  V (θ) = λ ln (M/λ) +  j=1  θ(j) ln θ(j) ,  (5)  which has its minimum at θ0 = (λ/M, . [sent-71, score-0.551]
</p><p>32 It is easy to check that this function is α-strongly convex with respect to the norm · 1 with parameter α = 1/λ , i. [sent-75, score-0.258]
</p><p>33 We call β-conjugate of V the following convex transform: def  ∀ z ∈ RM ,  Wβ (z) = sup −z T θ − βV (θ) . [sent-79, score-0.33]
</p><p>34 θ∈Θ  As it straightforwardly follows from (5), the β-conjugate is given here by: Wβ (z) = λ β ln  1 M  M k=1  e−z  which has a Lipschitz-continuous gradient w. [sent-80, score-0.288]
</p><p>35 ˜  (8)  Though we will focus on a particular algorithm based on the entropic proxy function, our results apply for a generic algorithmic scheme which takes advantage of the general properties of convex transforms (see [8] for details). [sent-84, score-0.616]
</p><p>36 3  Algorithm and main result  The mirror descent algorithm is a stochastic gradient algorithm in the dual space. [sent-86, score-1.088]
</p><p>37 At each iteration i, a new data point (Xi , Yi ) is observed and there are two updates: one is the value ζi as the result of the stochastic gradient descent in the dual space, the other is the update of the parameter θi which is the ”mirror image” of ζi . [sent-87, score-0.752]
</p><p>38 In order to tune the algorithm properly, we need two ﬁxed positive sequences (γi )i≥1 (stepsize) and (βi )i≥1 (temperature) such that βi ≥ βi−1 . [sent-88, score-0.037]
</p><p>39 The mirror descent algorithm with averaging is as follows: Algorithm. [sent-89, score-0.738]
</p><p>40 , t − 1, do ζi  = ζi−1 + γi ui (θi−1 ) ,  θi  = −∇Wβi (ζi ) . [sent-94, score-0.177]
</p><p>41 (9)  • Output at iteration t the following convex combination: ˆ θt =  t  i=1  γi θi−1  t  j=1  γj . [sent-95, score-0.26]
</p><p>42 (10)  At this point, we actually have described a class of algorithms. [sent-96, score-0.034]
</p><p>43 Given the observations of the stochastic sub-gradient (3), particular choices of the proxy function V , of the stepsize and temperature parameters, will determine the algorithm completely. [sent-97, score-0.573]
</p><p>44 In this paper, we focus on the entropic proxy function and consider a nearly optimal choice for the stepsize and temperature parameters which is the following: √ (11) γi ≡ 1 , βi = β0 i + 1 , i = 1, 2, . [sent-99, score-0.521]
</p><p>45 Assume that the loss function Q satisﬁes the following boundedness condition: √ Fix also β0 = L/ ln M . [sent-105, score-0.255]
</p><p>46 (12)  Then, for any integer t ≥ 1, the excess risk of the estimate θt described above satisﬁes the following bound: √ t+1 1/2 E A(θt ) − min A(θ) ≤ 2 Lλ ( ln M ) . [sent-107, score-0.471]
</p><p>47 Consider the setting of supervised learning where the data are modelled by a pair (X, Y ) with X ∈ X being an observation vector and Y a label, either integer (classiﬁcation) or real-valued (regression). [sent-109, score-0.044]
</p><p>48 Boosting and SVM algorithms are related to the minimization of a functional R(f ) = Eϕ(Y f (X)) where ϕ is a convex non-negative cost function (typically exponential, logit or hinge loss) and f belongs to a given class of combined predictors. [sent-110, score-0.369]
</p><p>49 The aggregation problem consists in ﬁnding the best linear combination of elements from a ﬁnite set of predictors {h1 , . [sent-111, score-0.246]
</p><p>50 Taking compact notations, it means that we search for f of the form f = θT H with H denoting the vector-valued function whose components are these base predictors: T H(x) = (h1 (x), . [sent-115, score-0.129]
</p><p>51 , hM (x)) , and θ belonging in a decision set Θ = ΘM,λ . [sent-118, score-0.032]
</p><p>52 1  Heuristics  Suppose that we want to minimize a convex function θ → A(θ) over a convex set Θ. [sent-123, score-0.436]
</p><p>53 , θt−1 are the available search points at iteration t, we can provide the afﬁne approximations φi of the function A deﬁned, for θ ∈ Θ, by φi (θ) = A(θi−1 ) + (θ − θi−1 )T ∇A(θi−1 ),  i = 1, . [sent-127, score-0.089]
</p><p>54 Taking a convex combination of the φi ’s, we obtain an averaged approximation of A(θ): t i=1  ¯ φt (θ) =  γi A(θi−1 ) + (θ − θi−1 )T ∇A(θi−1 ) t i=1  γi  . [sent-132, score-0.257]
</p><p>55 At ﬁrst glance, it would seem reasonable to choose as the next search point a vector θ ∈ Θ ¯ minimizing the approximation φt , i. [sent-133, score-0.117]
</p><p>56 , t  ¯ θt = arg min φt (θ) = arg min θT θ∈Θ  θ∈Θ  i=1  γi ∇A(θi−1 ) . [sent-135, score-0.256]
</p><p>57 (14)  However, this does not make any progress, because our approximation is “good” only in the vicinity of search points θ0 , . [sent-136, score-0.086]
</p><p>58 Therefore, it is necessary to modify the criterion, for instance, by adding a special penalty Bt (θ, θt−1 ) to the target function in order to keep the next search point θt in the desired region. [sent-140, score-0.123]
</p><p>59 Thus, one chooses the point: t  θt = arg min θT θ∈Θ  γi ∇A(θi−1 )  i=1  + Bt (θ, θt−1 ) . [sent-141, score-0.128]
</p><p>60 (15)  Our algorithm corresponds to a speciﬁc type of penalty Bt (θ, θt−1 ) = βt V (θ), where V is the proxy function. [sent-142, score-0.269]
</p><p>61 Therefore, we replace in (15) the unknown gradients ∇A(θi−1 ) by the observed stochastic sub-gradients ui (θi−1 ). [sent-144, score-0.326]
</p><p>62 This yields a new deﬁnition of the t-th search point: t  θt = arg min θT θ∈Θ  T + βt V (θ) = arg max −ζt θ − βt V (θ) , (16)  γi ui (θi−1 )  θ∈Θ  i=1 t  where ζt = i=1 γi ui (θi−1 ). [sent-145, score-0.596]
</p><p>63 [3]), the solution to this problem reads as −∇Wβt (ζt ) and it is now easy to deduce the iterative scheme (9) of the mirror descent algorithm. [sent-148, score-0.71]
</p><p>64 2  Comparison with previous work  The versions of mirror descent method proposed in [12] are somewhat different from our iterative scheme (9). [sent-150, score-0.71]
</p><p>65 It is based on the recursive relation θi = −∇W1 − ∇V (θi−1 ) + γi ui (θi−1 ) ,  i = 1, 2, . [sent-152, score-0.257]
</p><p>66 ,  (17)  where the function V is strongly convex with respect to the norm of initial space E (which is not necessarily the space ℓM ) and W1 is the 1-conjugate function to V . [sent-155, score-0.258]
</p><p>67 1 2  θ 2 , the scheme of (17) coincides with the ordinary gradient 2  For the unit simplex Θ = ΘM,1 and the entropy type proxy function V from (5) with (j) λ = 1, the coordinates θi of vector θi from (17) are: i (j)  ∀j = 1, . [sent-157, score-0.388]
</p><p>68 (18)  γm um, k (θm−1 ) m=1  The algorithm is also known as the exponentiated gradient (EG) method [10]. [sent-161, score-0.262]
</p><p>69 The convergence properties of the EG method (18) have been studied in a deterministic setting [6]. [sent-163, score-0.045]
</p><p>70 If this constant is small enough, these results show that the EG method provides good numerical minimizers of the empirical risk At . [sent-165, score-0.165]
</p><p>71 The averaging step allows the use of the results provided in [5] to derive generalization error bounds from relative loss bounds. [sent-166, score-0.246]
</p><p>72 This technique leads to rates of convergence of the order (ln M )/t as well but with suboptimal multiplicative factor in λ. [sent-167, score-0.045]
</p><p>73 Finally, we point out that the algorithm (17) may be deduced from the ideas mentioned in Subsection 4. [sent-168, score-0.068]
</p><p>74 1 and which are studied in the literature on proximal methods within the ﬁeld of convex optimization (see, e. [sent-169, score-0.275]
</p><p>75 The rate of convergence of order ln M / t is typical without low noise assumptions (as they are introduced in [17]). [sent-175, score-0.18]
</p><p>76 Batch procedures based on minimization of the empirical convex risk functional present a similar rate. [sent-176, score-0.554]
</p><p>77 From the statistical point of view, there is no remarkable difference between batch and our mirror-descent procedure. [sent-177, score-0.119]
</p><p>78 On the other hand, from the computational point of view, our procedure is quite comparable with the direct stochastic gradient descent. [sent-178, score-0.333]
</p><p>79 Using the techniques of [7] and [16] it is not hard to prove minimax lower bound on the excess risk E A(θt ) − minθ∈ΘM,λ A(θ) having the √ order (ln M )1/2 / t for M ≥ t1/2+δ with some δ > 0. [sent-181, score-0.268]
</p><p>80 This indicates that the upper bound of the Theorem is rate optimal for such values of M . [sent-182, score-0.037]
</p><p>81 We point out that the good behaviour of this method crucially relies on the choice of the base class of functions {hj }1≤j≤M . [sent-184, score-0.187]
</p><p>82 For example, one can take hj ’s as the eigenfunctions associated to some positive deﬁnite kernel. [sent-186, score-0.077]
</p><p>83 The choice of λ can be motivated by similar considerations. [sent-188, score-0.04]
</p><p>84 In fact, to minimize the approximation error it might be useful to take λ depending on the sample size t and tending to inﬁnity with some slow rate as in [11]. [sent-189, score-0.039]
</p><p>85 A balance between the stochastic error as given in the Theorem and the approximation error would then determine the optimal choice of λ. [sent-190, score-0.228]
</p><p>86 5  Proof of the Theorem  Introduce the notation ∇A(θ) = Eui (θ) and ξi (θ) = ui (θ) − ∇A(θ). [sent-191, score-0.177]
</p><p>87 Put vi = ui (θi−1 ) which gives ζi −ζi−1 = γi vi . [sent-192, score-0.639]
</p><p>88 By continuous differentiability of Wβt−1 and by (8) we have: Wβi−1 (ζi )  T = Wβi−1 (ζi−1 ) + γi vi ∇Wβi−1 (ζi−1 ) 1  +γi 0  T vi ∇Wβi−1 (τ ζi + (1 − τ )ζi−1 ) − ∇Wβi−1 (ζi−1 ) dτ  T ≤ Wβi−1 (ζi−1 ) + γi vi ∇Wβi−1 (ζi−1 ) +  2 λγi vi 2 ∞ . [sent-193, score-0.924]
</p><p>89 2βi−1  Then, using the fact that (βi )i≥1 is a non-decreasing sequence and that, for z ﬁxed, β → Wβ (z) is a non-increasing function, we get T Wβi (ζi ) ≤ Wβi−1 (ζi ) ≤ Wβi−1 (ζi−1 ) − γi θi−1 vi +  2 λγi vi 2 ∞ . [sent-194, score-0.462]
</p><p>90 2βi−1  t i=1  γi vi , we get:  Summing up over the i’s and using the representation ζt = ∀θ ∈ Θ,  t i=1  T γi (θi−1 − θ)T vi ≤ −Wβt (ζt ) − ζt θ +  t i=1  2 λγi vi 2 ∞ 2βi−1  since Wβ0 (ζ0 ) = 0. [sent-195, score-0.693]
</p><p>91 Finally, since vi = ∇A(θi−1 ) + ξi (θi−1 ), we get t i=1  t  γi (θi−1 − θ)T ∇A(θi−1 ) ≤ βt V (θ) −  t  i=1  γi (θi−1 − θ)T ξi (θi−1 ) +  i=1  2 λγi vi 2 ∞ . [sent-197, score-0.462]
</p><p>92 ∞ Noticing that V ∗ = λ ln M and optimizing this bound in β0 > 0, we obtain the result. [sent-200, score-0.172]
</p><p>93 Acknowledgments We thank Nicol` Cesa-Bianchi for sharing with us his expertise on relative loss bounds. [sent-201, score-0.057]
</p><p>94 (2003) Mirror descent and nonlinear projected subgradient methods for convex optimization. [sent-204, score-0.511]
</p><p>95 (1999) The conjugate barrier mirror descent method for non-smooth convex optimization. [sent-215, score-0.846]
</p><p>96 (2004) On the generalization ability of on-line learning algorithms. [sent-228, score-0.042]
</p><p>97 (1997) Additive versus exponentiated gradient updates for linear prediction. [sent-264, score-0.277]
</p><p>98 (2004) On the Bayes-risk consistency of regularized boosting methods (with discussion). [sent-269, score-0.084]
</p><p>99 (2004) Statistical behavior and consistency of classiﬁcation methods based on convex risk minimization (with discussion). [sent-302, score-0.49]
</p><p>100 (2004) Solving large scale linear prediction problems using stochastic gradient descent algorithms. [sent-305, score-0.595]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('mirror', 0.335), ('descent', 0.293), ('vi', 0.231), ('convex', 0.218), ('proxy', 0.187), ('nemirovski', 0.18), ('ui', 0.177), ('risk', 0.165), ('aggregation', 0.16), ('tsybakov', 0.157), ('gradient', 0.153), ('stochastic', 0.149), ('rm', 0.136), ('ln', 0.135), ('juditsky', 0.125), ('stepsize', 0.125), ('paris', 0.119), ('vayatis', 0.114), ('laboratoire', 0.094), ('entropic', 0.094), ('batch', 0.088), ('predictors', 0.086), ('universit', 0.085), ('dual', 0.084), ('base', 0.082), ('recursive', 0.08), ('def', 0.08), ('hj', 0.077), ('minimization', 0.075), ('temperature', 0.075), ('bounds', 0.074), ('averaging', 0.073), ('atoires', 0.072), ('jussieu', 0.072), ('nazin', 0.072), ('noticing', 0.072), ('yudin', 0.072), ('exponentiated', 0.072), ('eg', 0.069), ('mod', 0.069), ('bt', 0.069), ('arg', 0.067), ('excess', 0.066), ('zt', 0.063), ('boundedness', 0.063), ('grenoble', 0.063), ('france', 0.061), ('min', 0.061), ('annals', 0.059), ('loss', 0.057), ('gentile', 0.057), ('probabilit', 0.057), ('proximal', 0.057), ('procedures', 0.054), ('kivinen', 0.053), ('warmuth', 0.053), ('cedex', 0.053), ('hm', 0.053), ('updates', 0.052), ('boosting', 0.052), ('bregman', 0.05), ('scheme', 0.048), ('search', 0.047), ('siam', 0.046), ('um', 0.046), ('convergence', 0.045), ('penalty', 0.045), ('equipped', 0.044), ('therein', 0.044), ('zhang', 0.044), ('integer', 0.044), ('functional', 0.042), ('iteration', 0.042), ('generalization', 0.042), ('notations', 0.041), ('norm', 0.04), ('choice', 0.04), ('fix', 0.04), ('cardinality', 0.04), ('les', 0.04), ('approximation', 0.039), ('presents', 0.038), ('introduce', 0.038), ('algorithm', 0.037), ('bound', 0.037), ('colt', 0.036), ('inf', 0.035), ('expectations', 0.035), ('online', 0.035), ('iterative', 0.034), ('place', 0.034), ('class', 0.034), ('algorithmic', 0.032), ('insights', 0.032), ('belonging', 0.032), ('sup', 0.032), ('consistency', 0.032), ('particularly', 0.032), ('point', 0.031), ('beck', 0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999958 <a title="82-tfidf-1" href="./nips-2005-Generalization_Error_Bounds_for_Aggregation_by_Mirror_Descent_with_Averaging.html">82 nips-2005-Generalization Error Bounds for Aggregation by Mirror Descent with Averaging</a></p>
<p>Author: Anatoli Juditsky, Alexander Nazin, Alexandre Tsybakov, Nicolas Vayatis</p><p>Abstract: We consider the problem of constructing an aggregated estimator from a ﬁnite class of base functions which approximately minimizes a convex risk functional under the ℓ1 constraint. For this purpose, we propose a stochastic procedure, the mirror descent, which performs gradient descent in the dual space. The generated estimates are additionally averaged in a recursive fashion with speciﬁc weights. Mirror descent algorithms have been developed in different contexts and they are known to be particularly efﬁcient in high dimensional problems. Moreover their implementation is adapted to the online setting. The main result of the paper is the upper bound on the convergence rate for the generalization error. 1</p><p>2 0.18978633 <a title="82-tfidf-2" href="./nips-2005-Convex_Neural_Networks.html">50 nips-2005-Convex Neural Networks</a></p>
<p>Author: Yoshua Bengio, Nicolas L. Roux, Pascal Vincent, Olivier Delalleau, Patrice Marcotte</p><p>Abstract: Convexity has recently received a lot of attention in the machine learning community, and the lack of convexity has been seen as a major disadvantage of many learning algorithms, such as multi-layer artiﬁcial neural networks. We show that training multi-layer neural networks in which the number of hidden units is learned can be viewed as a convex optimization problem. This problem involves an inﬁnite number of variables, but can be solved by incrementally inserting a hidden unit at a time, each time ﬁnding a linear classiﬁer that minimizes a weighted sum of errors. 1</p><p>3 0.18332314 <a title="82-tfidf-3" href="./nips-2005-Consistency_of_one-class_SVM_and_related_algorithms.html">47 nips-2005-Consistency of one-class SVM and related algorithms</a></p>
<p>Author: Régis Vert, Jean-philippe Vert</p><p>Abstract: We determine the asymptotic limit of the function computed by support vector machines (SVM) and related algorithms that minimize a regularized empirical convex loss function in the reproducing kernel Hilbert space of the Gaussian RBF kernel, in the situation where the number of examples tends to inﬁnity, the bandwidth of the Gaussian kernel tends to 0, and the regularization parameter is held ﬁxed. Non-asymptotic convergence bounds to this limit in the L2 sense are provided, together with upper bounds on the classiﬁcation error that is shown to converge to the Bayes risk, therefore proving the Bayes-consistency of a variety of methods although the regularization term does not vanish. These results are particularly relevant to the one-class SVM, for which the regularization can not vanish by construction, and which is shown for the ﬁrst time to be a consistent density level set estimator. 1</p><p>4 0.14058192 <a title="82-tfidf-4" href="./nips-2005-Improved_risk_tail_bounds_for_on-line_algorithms.html">95 nips-2005-Improved risk tail bounds for on-line algorithms</a></p>
<p>Author: NicolĂ˛ Cesa-bianchi, Claudio Gentile</p><p>Abstract: We prove the strongest known bound for the risk of hypotheses selected from the ensemble generated by running a learning algorithm incrementally on the training data. Our result is based on proof techniques that are remarkably different from the standard risk analysis based on uniform convergence arguments.</p><p>5 0.13858396 <a title="82-tfidf-5" href="./nips-2005-Divergences%2C_surrogate_loss_functions_and_experimental_design.html">58 nips-2005-Divergences, surrogate loss functions and experimental design</a></p>
<p>Author: Xuanlong Nguyen, Martin J. Wainwright, Michael I. Jordan</p><p>Abstract: In this paper, we provide a general theorem that establishes a correspondence between surrogate loss functions in classiﬁcation and the family of f -divergences. Moreover, we provide constructive procedures for determining the f -divergence induced by a given surrogate loss, and conversely for ﬁnding all surrogate loss functions that realize a given f -divergence. Next we introduce the notion of universal equivalence among loss functions and corresponding f -divergences, and provide necessary and sufﬁcient conditions for universal equivalence to hold. These ideas have applications to classiﬁcation problems that also involve a component of experiment design; in particular, we leverage our results to prove consistency of a procedure for learning a classiﬁer under decentralization requirements. 1</p><p>6 0.1173673 <a title="82-tfidf-6" href="./nips-2005-Combining_Graph_Laplacians_for_Semi--Supervised_Learning.html">42 nips-2005-Combining Graph Laplacians for Semi--Supervised Learning</a></p>
<p>7 0.10044789 <a title="82-tfidf-7" href="./nips-2005-Variational_EM_Algorithms_for_Non-Gaussian_Latent_Variable_Models.html">202 nips-2005-Variational EM Algorithms for Non-Gaussian Latent Variable Models</a></p>
<p>8 0.098171085 <a title="82-tfidf-8" href="./nips-2005-Generalization_error_bounds_for_classifiers_trained_with_interdependent_data.html">83 nips-2005-Generalization error bounds for classifiers trained with interdependent data</a></p>
<p>9 0.096709117 <a title="82-tfidf-9" href="./nips-2005-Metric_Learning_by_Collapsing_Classes.html">126 nips-2005-Metric Learning by Collapsing Classes</a></p>
<p>10 0.092769556 <a title="82-tfidf-10" href="./nips-2005-Soft_Clustering_on_Graphs.html">178 nips-2005-Soft Clustering on Graphs</a></p>
<p>11 0.091271445 <a title="82-tfidf-11" href="./nips-2005-A_PAC-Bayes_approach_to_the_Set_Covering_Machine.html">12 nips-2005-A PAC-Bayes approach to the Set Covering Machine</a></p>
<p>12 0.090813294 <a title="82-tfidf-12" href="./nips-2005-Data-Driven_Online_to_Batch_Conversions.html">54 nips-2005-Data-Driven Online to Batch Conversions</a></p>
<p>13 0.089202493 <a title="82-tfidf-13" href="./nips-2005-TD%280%29_Leads_to_Better_Policies_than_Approximate_Value_Iteration.html">186 nips-2005-TD(0) Leads to Better Policies than Approximate Value Iteration</a></p>
<p>14 0.087196939 <a title="82-tfidf-14" href="./nips-2005-Convergence_and_Consistency_of_Regularized_Boosting_Algorithms_with_Stationary_B-Mixing_Observations.html">49 nips-2005-Convergence and Consistency of Regularized Boosting Algorithms with Stationary B-Mixing Observations</a></p>
<p>15 0.084194265 <a title="82-tfidf-15" href="./nips-2005-Fast_Online_Policy_Gradient_Learning_with_SMD_Gain_Vector_Adaptation.html">72 nips-2005-Fast Online Policy Gradient Learning with SMD Gain Vector Adaptation</a></p>
<p>16 0.081392974 <a title="82-tfidf-16" href="./nips-2005-Estimating_the_wrong_Markov_random_field%3A_Benefits_in_the_computation-limited_setting.html">65 nips-2005-Estimating the wrong Markov random field: Benefits in the computation-limited setting</a></p>
<p>17 0.080795974 <a title="82-tfidf-17" href="./nips-2005-From_Batch_to_Transductive_Online_Learning.html">76 nips-2005-From Batch to Transductive Online Learning</a></p>
<p>18 0.079745196 <a title="82-tfidf-18" href="./nips-2005-Robust_design_of_biological_experiments.html">167 nips-2005-Robust design of biological experiments</a></p>
<p>19 0.078518182 <a title="82-tfidf-19" href="./nips-2005-A_Probabilistic_Interpretation_of_SVMs_with_an_Application_to_Unbalanced_Classification.html">14 nips-2005-A Probabilistic Interpretation of SVMs with an Application to Unbalanced Classification</a></p>
<p>20 0.074107498 <a title="82-tfidf-20" href="./nips-2005-An_Approximate_Inference_Approach_for_the_PCA_Reconstruction_Error.html">24 nips-2005-An Approximate Inference Approach for the PCA Reconstruction Error</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2005_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.247), (1, 0.121), (2, -0.018), (3, -0.156), (4, 0.133), (5, 0.101), (6, -0.118), (7, -0.038), (8, -0.086), (9, -0.133), (10, -0.076), (11, 0.073), (12, -0.154), (13, -0.001), (14, 0.123), (15, 0.006), (16, 0.021), (17, -0.083), (18, -0.061), (19, -0.029), (20, -0.158), (21, 0.043), (22, -0.061), (23, -0.056), (24, -0.025), (25, 0.077), (26, 0.074), (27, 0.067), (28, 0.02), (29, 0.086), (30, -0.004), (31, -0.105), (32, -0.039), (33, 0.104), (34, 0.086), (35, 0.095), (36, -0.022), (37, -0.034), (38, 0.041), (39, 0.056), (40, 0.028), (41, -0.05), (42, 0.153), (43, 0.082), (44, -0.02), (45, -0.036), (46, 0.045), (47, -0.01), (48, 0.045), (49, -0.068)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96002823 <a title="82-lsi-1" href="./nips-2005-Generalization_Error_Bounds_for_Aggregation_by_Mirror_Descent_with_Averaging.html">82 nips-2005-Generalization Error Bounds for Aggregation by Mirror Descent with Averaging</a></p>
<p>Author: Anatoli Juditsky, Alexander Nazin, Alexandre Tsybakov, Nicolas Vayatis</p><p>Abstract: We consider the problem of constructing an aggregated estimator from a ﬁnite class of base functions which approximately minimizes a convex risk functional under the ℓ1 constraint. For this purpose, we propose a stochastic procedure, the mirror descent, which performs gradient descent in the dual space. The generated estimates are additionally averaged in a recursive fashion with speciﬁc weights. Mirror descent algorithms have been developed in different contexts and they are known to be particularly efﬁcient in high dimensional problems. Moreover their implementation is adapted to the online setting. The main result of the paper is the upper bound on the convergence rate for the generalization error. 1</p><p>2 0.68482012 <a title="82-lsi-2" href="./nips-2005-Improved_risk_tail_bounds_for_on-line_algorithms.html">95 nips-2005-Improved risk tail bounds for on-line algorithms</a></p>
<p>Author: NicolĂ˛ Cesa-bianchi, Claudio Gentile</p><p>Abstract: We prove the strongest known bound for the risk of hypotheses selected from the ensemble generated by running a learning algorithm incrementally on the training data. Our result is based on proof techniques that are remarkably different from the standard risk analysis based on uniform convergence arguments.</p><p>3 0.67893916 <a title="82-lsi-3" href="./nips-2005-Divergences%2C_surrogate_loss_functions_and_experimental_design.html">58 nips-2005-Divergences, surrogate loss functions and experimental design</a></p>
<p>Author: Xuanlong Nguyen, Martin J. Wainwright, Michael I. Jordan</p><p>Abstract: In this paper, we provide a general theorem that establishes a correspondence between surrogate loss functions in classiﬁcation and the family of f -divergences. Moreover, we provide constructive procedures for determining the f -divergence induced by a given surrogate loss, and conversely for ﬁnding all surrogate loss functions that realize a given f -divergence. Next we introduce the notion of universal equivalence among loss functions and corresponding f -divergences, and provide necessary and sufﬁcient conditions for universal equivalence to hold. These ideas have applications to classiﬁcation problems that also involve a component of experiment design; in particular, we leverage our results to prove consistency of a procedure for learning a classiﬁer under decentralization requirements. 1</p><p>4 0.58996469 <a title="82-lsi-4" href="./nips-2005-Convex_Neural_Networks.html">50 nips-2005-Convex Neural Networks</a></p>
<p>Author: Yoshua Bengio, Nicolas L. Roux, Pascal Vincent, Olivier Delalleau, Patrice Marcotte</p><p>Abstract: Convexity has recently received a lot of attention in the machine learning community, and the lack of convexity has been seen as a major disadvantage of many learning algorithms, such as multi-layer artiﬁcial neural networks. We show that training multi-layer neural networks in which the number of hidden units is learned can be viewed as a convex optimization problem. This problem involves an inﬁnite number of variables, but can be solved by incrementally inserting a hidden unit at a time, each time ﬁnding a linear classiﬁer that minimizes a weighted sum of errors. 1</p><p>5 0.57820839 <a title="82-lsi-5" href="./nips-2005-Consistency_of_one-class_SVM_and_related_algorithms.html">47 nips-2005-Consistency of one-class SVM and related algorithms</a></p>
<p>Author: Régis Vert, Jean-philippe Vert</p><p>Abstract: We determine the asymptotic limit of the function computed by support vector machines (SVM) and related algorithms that minimize a regularized empirical convex loss function in the reproducing kernel Hilbert space of the Gaussian RBF kernel, in the situation where the number of examples tends to inﬁnity, the bandwidth of the Gaussian kernel tends to 0, and the regularization parameter is held ﬁxed. Non-asymptotic convergence bounds to this limit in the L2 sense are provided, together with upper bounds on the classiﬁcation error that is shown to converge to the Bayes risk, therefore proving the Bayes-consistency of a variety of methods although the regularization term does not vanish. These results are particularly relevant to the one-class SVM, for which the regularization can not vanish by construction, and which is shown for the ﬁrst time to be a consistent density level set estimator. 1</p><p>6 0.50012326 <a title="82-lsi-6" href="./nips-2005-Learning_Minimum_Volume_Sets.html">112 nips-2005-Learning Minimum Volume Sets</a></p>
<p>7 0.47448218 <a title="82-lsi-7" href="./nips-2005-Fast_Online_Policy_Gradient_Learning_with_SMD_Gain_Vector_Adaptation.html">72 nips-2005-Fast Online Policy Gradient Learning with SMD Gain Vector Adaptation</a></p>
<p>8 0.45929727 <a title="82-lsi-8" href="./nips-2005-Data-Driven_Online_to_Batch_Conversions.html">54 nips-2005-Data-Driven Online to Batch Conversions</a></p>
<p>9 0.45316619 <a title="82-lsi-9" href="./nips-2005-Augmented_Rescorla-Wagner_and_Maximum_Likelihood_Estimation.html">32 nips-2005-Augmented Rescorla-Wagner and Maximum Likelihood Estimation</a></p>
<p>10 0.44904083 <a title="82-lsi-10" href="./nips-2005-Convergence_and_Consistency_of_Regularized_Boosting_Algorithms_with_Stationary_B-Mixing_Observations.html">49 nips-2005-Convergence and Consistency of Regularized Boosting Algorithms with Stationary B-Mixing Observations</a></p>
<p>11 0.41943267 <a title="82-lsi-11" href="./nips-2005-TD%280%29_Leads_to_Better_Policies_than_Approximate_Value_Iteration.html">186 nips-2005-TD(0) Leads to Better Policies than Approximate Value Iteration</a></p>
<p>12 0.40019932 <a title="82-lsi-12" href="./nips-2005-From_Batch_to_Transductive_Online_Learning.html">76 nips-2005-From Batch to Transductive Online Learning</a></p>
<p>13 0.39892358 <a title="82-lsi-13" href="./nips-2005-Worst-Case_Bounds_for_Gaussian_Process_Models.html">205 nips-2005-Worst-Case Bounds for Gaussian Process Models</a></p>
<p>14 0.39857519 <a title="82-lsi-14" href="./nips-2005-Affine_Structure_From_Sound.html">20 nips-2005-Affine Structure From Sound</a></p>
<p>15 0.39767742 <a title="82-lsi-15" href="./nips-2005-Robust_design_of_biological_experiments.html">167 nips-2005-Robust design of biological experiments</a></p>
<p>16 0.39183226 <a title="82-lsi-16" href="./nips-2005-Metric_Learning_by_Collapsing_Classes.html">126 nips-2005-Metric Learning by Collapsing Classes</a></p>
<p>17 0.38507107 <a title="82-lsi-17" href="./nips-2005-Robust_Fisher_Discriminant_Analysis.html">166 nips-2005-Robust Fisher Discriminant Analysis</a></p>
<p>18 0.38454658 <a title="82-lsi-18" href="./nips-2005-Comparing_the_Effects_of_Different_Weight_Distributions_on_Finding_Sparse_Representations.html">43 nips-2005-Comparing the Effects of Different Weight Distributions on Finding Sparse Representations</a></p>
<p>19 0.38393307 <a title="82-lsi-19" href="./nips-2005-Generalization_error_bounds_for_classifiers_trained_with_interdependent_data.html">83 nips-2005-Generalization error bounds for classifiers trained with interdependent data</a></p>
<p>20 0.38283518 <a title="82-lsi-20" href="./nips-2005-A_General_and_Efficient_Multiple_Kernel_Learning_Algorithm.html">10 nips-2005-A General and Efficient Multiple Kernel Learning Algorithm</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2005_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.072), (5, 0.013), (10, 0.028), (27, 0.018), (31, 0.035), (34, 0.106), (41, 0.01), (55, 0.484), (69, 0.035), (73, 0.029), (88, 0.053), (91, 0.044)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.954943 <a title="82-lda-1" href="./nips-2005-Fast_Information_Value_for_Graphical_Models.html">70 nips-2005-Fast Information Value for Graphical Models</a></p>
<p>Author: Brigham S. Anderson, Andrew W. Moore</p><p>Abstract: Calculations that quantify the dependencies between variables are vital to many operations with graphical models, e.g., active learning and sensitivity analysis. Previously, pairwise information gain calculation has involved a cost quadratic in network size. In this work, we show how to perform a similar computation with cost linear in network size. The loss function that allows this is of a form amenable to computation by dynamic programming. The message-passing algorithm that results is described and empirical results demonstrate large speedups without decrease in accuracy. In the cost-sensitive domains examined, superior accuracy is achieved.</p><p>same-paper 2 0.928886 <a title="82-lda-2" href="./nips-2005-Generalization_Error_Bounds_for_Aggregation_by_Mirror_Descent_with_Averaging.html">82 nips-2005-Generalization Error Bounds for Aggregation by Mirror Descent with Averaging</a></p>
<p>Author: Anatoli Juditsky, Alexander Nazin, Alexandre Tsybakov, Nicolas Vayatis</p><p>Abstract: We consider the problem of constructing an aggregated estimator from a ﬁnite class of base functions which approximately minimizes a convex risk functional under the ℓ1 constraint. For this purpose, we propose a stochastic procedure, the mirror descent, which performs gradient descent in the dual space. The generated estimates are additionally averaged in a recursive fashion with speciﬁc weights. Mirror descent algorithms have been developed in different contexts and they are known to be particularly efﬁcient in high dimensional problems. Moreover their implementation is adapted to the online setting. The main result of the paper is the upper bound on the convergence rate for the generalization error. 1</p><p>3 0.92569208 <a title="82-lda-3" href="./nips-2005-The_Information-Form_Data_Association_Filter.html">192 nips-2005-The Information-Form Data Association Filter</a></p>
<p>Author: Brad Schumitsch, Sebastian Thrun, Gary Bradski, Kunle Olukotun</p><p>Abstract: This paper presents a new ﬁlter for online data association problems in high-dimensional spaces. The key innovation is a representation of the data association posterior in information form, in which the “proximity” of objects and tracks are expressed by numerical links. Updating these links requires linear time, compared to exponential time required for computing the exact posterior probabilities. The paper derives the algorithm formally and provides comparative results using data obtained by a real-world camera array and by a large-scale sensor network simulation.</p><p>4 0.56318641 <a title="82-lda-4" href="./nips-2005-Inference_with_Minimal_Communication%3A_a_Decision-Theoretic_Variational_Approach.html">96 nips-2005-Inference with Minimal Communication: a Decision-Theoretic Variational Approach</a></p>
<p>Author: O. P. Kreidl, Alan S. Willsky</p><p>Abstract: Given a directed graphical model with binary-valued hidden nodes and real-valued noisy observations, consider deciding upon the maximum a-posteriori (MAP) or the maximum posterior-marginal (MPM) assignment under the restriction that each node broadcasts only to its children exactly one single-bit message. We present a variational formulation, viewing the processing rules local to all nodes as degrees-of-freedom, that minimizes the loss in expected (MAP or MPM) performance subject to such online communication constraints. The approach leads to a novel message-passing algorithm to be executed ofﬂine, or before observations are realized, which mitigates the performance loss by iteratively coupling all rules in a manner implicitly driven by global statistics. We also provide (i) illustrative examples, (ii) assumptions that guarantee convergence and efﬁciency and (iii) connections to active research areas. 1</p><p>5 0.53867531 <a title="82-lda-5" href="./nips-2005-Fast_Online_Policy_Gradient_Learning_with_SMD_Gain_Vector_Adaptation.html">72 nips-2005-Fast Online Policy Gradient Learning with SMD Gain Vector Adaptation</a></p>
<p>Author: Jin Yu, Douglas Aberdeen, Nicol N. Schraudolph</p><p>Abstract: Reinforcement learning by direct policy gradient estimation is attractive in theory but in practice leads to notoriously ill-behaved optimization problems. We improve its robustness and speed of convergence with stochastic meta-descent, a gain vector adaptation method that employs fast Hessian-vector products. In our experiments the resulting algorithms outperform previously employed online stochastic, ofﬂine conjugate, and natural policy gradient methods. 1</p><p>6 0.53618616 <a title="82-lda-6" href="./nips-2005-Affine_Structure_From_Sound.html">20 nips-2005-Affine Structure From Sound</a></p>
<p>7 0.51042402 <a title="82-lda-7" href="./nips-2005-Consensus_Propagation.html">46 nips-2005-Consensus Propagation</a></p>
<p>8 0.50730711 <a title="82-lda-8" href="./nips-2005-Divergences%2C_surrogate_loss_functions_and_experimental_design.html">58 nips-2005-Divergences, surrogate loss functions and experimental design</a></p>
<p>9 0.49659073 <a title="82-lda-9" href="./nips-2005-Generalized_Nonnegative_Matrix_Approximations_with_Bregman_Divergences.html">86 nips-2005-Generalized Nonnegative Matrix Approximations with Bregman Divergences</a></p>
<p>10 0.48957378 <a title="82-lda-10" href="./nips-2005-Message_passing_for_task_redistribution_on_sparse_graphs.html">125 nips-2005-Message passing for task redistribution on sparse graphs</a></p>
<p>11 0.48751268 <a title="82-lda-11" href="./nips-2005-Convex_Neural_Networks.html">50 nips-2005-Convex Neural Networks</a></p>
<p>12 0.48371825 <a title="82-lda-12" href="./nips-2005-Consistency_of_one-class_SVM_and_related_algorithms.html">47 nips-2005-Consistency of one-class SVM and related algorithms</a></p>
<p>13 0.47952572 <a title="82-lda-13" href="./nips-2005-Sensory_Adaptation_within_a_Bayesian_Framework_for_Perception.html">173 nips-2005-Sensory Adaptation within a Bayesian Framework for Perception</a></p>
<p>14 0.47850123 <a title="82-lda-14" href="./nips-2005-Convergence_and_Consistency_of_Regularized_Boosting_Algorithms_with_Stationary_B-Mixing_Observations.html">49 nips-2005-Convergence and Consistency of Regularized Boosting Algorithms with Stationary B-Mixing Observations</a></p>
<p>15 0.46754959 <a title="82-lda-15" href="./nips-2005-Unbiased_Estimator_of_Shape_Parameter_for_Spiking_Irregularities_under_Changing_Environments.html">197 nips-2005-Unbiased Estimator of Shape Parameter for Spiking Irregularities under Changing Environments</a></p>
<p>16 0.46279508 <a title="82-lda-16" href="./nips-2005-Variational_Bayesian_Stochastic_Complexity_of_Mixture_Models.html">201 nips-2005-Variational Bayesian Stochastic Complexity of Mixture Models</a></p>
<p>17 0.46027735 <a title="82-lda-17" href="./nips-2005-Nearest_Neighbor_Based_Feature_Selection_for_Regression_and_its_Application_to_Neural_Activity.html">132 nips-2005-Nearest Neighbor Based Feature Selection for Regression and its Application to Neural Activity</a></p>
<p>18 0.46022514 <a title="82-lda-18" href="./nips-2005-Fast_Gaussian_Process_Regression_using_KD-Trees.html">69 nips-2005-Fast Gaussian Process Regression using KD-Trees</a></p>
<p>19 0.46012059 <a title="82-lda-19" href="./nips-2005-Soft_Clustering_on_Graphs.html">178 nips-2005-Soft Clustering on Graphs</a></p>
<p>20 0.45704377 <a title="82-lda-20" href="./nips-2005-Location-based_activity_recognition.html">121 nips-2005-Location-based activity recognition</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
