<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>29 nips-2005-Analyzing Coupled Brain Sources: Distinguishing True from Spurious Interaction</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2005" href="../home/nips2005_home.html">nips2005</a> <a title="nips-2005-29" href="#">nips2005-29</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>29 nips-2005-Analyzing Coupled Brain Sources: Distinguishing True from Spurious Interaction</h1>
<br/><p>Source: <a title="nips-2005-29-pdf" href="http://papers.nips.cc/paper/2781-analyzing-coupled-brain-sources-distinguishing-true-from-spurious-interaction.pdf">pdf</a></p><p>Author: Guido Nolte, Andreas Ziehe, Frank Meinecke, Klaus-Robert Müller</p><p>Abstract: When trying to understand the brain, it is of fundamental importance to analyse (e.g. from EEG/MEG measurements) what parts of the cortex interact with each other in order to infer more accurate models of brain activity. Common techniques like Blind Source Separation (BSS) can estimate brain sources and single out artifacts by using the underlying assumption of source signal independence. However, physiologically interesting brain sources typically interact, so BSS will—by construction— fail to characterize them properly. Noting that there are truly interacting sources and signals that only seemingly interact due to effects of volume conduction, this work aims to contribute by distinguishing these effects. For this a new BSS technique is proposed that uses anti-symmetrized cross-correlation matrices and subsequent diagonalization. The resulting decomposition consists of the truly interacting brain sources and suppresses any spurious interaction stemming from volume conduction. Our new concept of interacting source analysis (ISA) is successfully demonstrated on MEG data. 1</p><p>Reference: <a title="nips-2005-29-reference" href="../nips2005_reference/nips-2005-Analyzing_Coupled_Brain_Sources%3A_Distinguishing_True_from_Spurious_Interaction_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 de  Abstract When trying to understand the brain, it is of fundamental importance to analyse (e. [sent-8, score-0.037]
</p><p>2 from EEG/MEG measurements) what parts of the cortex interact with each other in order to infer more accurate models of brain activity. [sent-10, score-0.318]
</p><p>3 Common techniques like Blind Source Separation (BSS) can estimate brain sources and single out artifacts by using the underlying assumption of source signal independence. [sent-11, score-0.603]
</p><p>4 However, physiologically interesting brain sources typically interact, so BSS will—by construction— fail to characterize them properly. [sent-12, score-0.524]
</p><p>5 Noting that there are truly interacting sources and signals that only seemingly interact due to effects of volume conduction, this work aims to contribute by distinguishing these effects. [sent-13, score-1.125]
</p><p>6 For this a new BSS technique is proposed that uses anti-symmetrized cross-correlation matrices and subsequent diagonalization. [sent-14, score-0.158]
</p><p>7 The resulting decomposition consists of the truly interacting brain sources and suppresses any spurious interaction stemming from volume conduction. [sent-15, score-1.317]
</p><p>8 Our new concept of interacting source analysis (ISA) is successfully demonstrated on MEG data. [sent-16, score-0.599]
</p><p>9 1  Introduction  Interaction between brain sources, phase synchrony or coherent states of brain activity are believed to be fundamental for neural information processing (e. [sent-17, score-0.447]
</p><p>10 So it is an important topic to devise new methods that can more reliably characterize interacting sources in the brain. [sent-20, score-0.779]
</p><p>11 The macroscopic nature and the high temporal resolution of electroencephalography (EEG) and magnetoencephalography (MEG) in the millisecond range makes these measurement technologies ideal candidates to study brain interactions. [sent-21, score-0.278]
</p><p>12 However, interpreting data from EEG/MEG channels in terms of connections between brain sources is largely hampered by artifacts of volume conduction, i. [sent-22, score-0.651]
</p><p>13 the fact that activities of single sources are observable as superposition in all channels (with varying amplitude). [sent-24, score-0.435]
</p><p>14 So ideally one would like to discard all—due to volume conduction—seemingly interacting signals and retain only truly linked brain source activity. [sent-25, score-0.956]
</p><p>15 So far neither existing source separation methods nor typical phase synchronization anal-  ysis (e. [sent-26, score-0.25]
</p><p>16 [1, 5] and references therein) can adequately handle signals when the sources are both superimposed and interacting i. [sent-28, score-0.846]
</p><p>17 It is here where we contribute in this paper by proposing a new algorithm to distinguish true from spurious interaction. [sent-32, score-0.157]
</p><p>18 A prerequisite to achieve this goal was recently established by [4]: as a consequence of instantaneous and linear volume conduction, the cross-spectra of independent sources are real-valued, regardless of the speciﬁcs of the volume conductor, number of sources or source conﬁguration. [sent-33, score-0.778]
</p><p>19 Hence, a non-vanishing imaginary part of the cross-spectra must necessarily reﬂect a true interaction. [sent-34, score-0.237]
</p><p>20 A recent different approach by [3] uses BSS as preprocessing step before phase synchronization is measured. [sent-36, score-0.112]
</p><p>21 The drawback of this method is the assumption that there are not more sources than sensors, which is often heavily violated because, e. [sent-37, score-0.282]
</p><p>22 , channel noise trivially consists of as many sources as channels, and, furthermore, brain noise can be very well modelled by assuming thousands of randomly distributed and independent dipoles. [sent-39, score-0.504]
</p><p>23 To avoid the drawbacks of either method we will formulate an algorithm called interacting source analysis (ISA) which is technically based on BSS using second order statistics but is only sensitive to interacting sources and, thus, can be applied to systems with arbitrary noise structure. [sent-40, score-1.422]
</p><p>24 In the next section, after giving a short introduction to BSS as used for this paper, we will derive some fundamental properties of our new method. [sent-41, score-0.037]
</p><p>25 In section 3 we will show in simulated data and real MEG examples that the ISA procedure ﬁnds the interacting components and separates interacting subsystems which are independent of each other. [sent-42, score-1.29]
</p><p>26 2  Theory  The fundamental assumption of ICA is that a data matrix X, without loss of generality assumed to be zero mean, originates from a superposition of independent sources S such that X = AS (1) where A is called the mixing matrix which is assumed to be invertible. [sent-43, score-0.597]
</p><p>27 The task is to ﬁnd A and hence S (apart from meaningless ordering and scale transformations of the columns of A and the rows of S) by merely exploiting statistical independence of the sources. [sent-44, score-0.099]
</p><p>28 Since independence implies that the sources are uncorrelated we may choose W , the estimated inverse mixing matrix, such that the covariance matrix of ˆ S ≡ WX  (2)  is equal to the identity matrix. [sent-45, score-0.466]
</p><p>29 This, however, does not uniquely determine W because for any such W also U W , where U is an arbitrary orthogonal matrix, leads to a unit covariance ˆ matrix of S. [sent-46, score-0.067]
</p><p>30 Uniqueness can be restored if we require that W not only diagonalizes the covariance matrix but also cross-correlation matrices for various delays τ , i. [sent-47, score-0.268]
</p><p>31 In doing so we exploit that neuronal interactions necessarily take some time which is well above the typical time resolution of EEG/MEG measurements. [sent-57, score-0.07]
</p><p>32 It is now our goal to identify one or many interacting systems from a suitable spatial transformation which corresponds to a demixing of the systems rather than individual sources. [sent-58, score-0.837]
</p><p>33 Although we concentrate on those components which explicitly violate the independence assumption we will use the technique of simultaneous diagonalization to achieve this goal. [sent-59, score-0.263]
</p><p>34 We ﬁrst note that a diagonalization of D(τ ) using a real-valued W is meaningless since with D(τ ) also W D(τ )W † is anti-symmetric and always has vanishing diagonal elements. [sent-60, score-0.309]
</p><p>35 Hence D(τ ) can only be diagonalized with a complex-valued W with subsequent interpretation of it in terms of a real-valued transformation. [sent-61, score-0.161]
</p><p>36 We will here discuss the case where all interacting systems consist of pairs of neuronal sources. [sent-62, score-0.497]
</p><p>37 Properties of systems with more than two interacting systems will be discussed below. [sent-63, score-0.497]
</p><p>38 Then a realvalued spatial transformation W1 exists such that the set of D(τ ) becomes decomposed into K = N/2 blocks of size 2 × 2   0 1 0 0  α1 (τ ) −1 0      † . [sent-65, score-0.088]
</p><p>39 0 0     0 1 0 0 αK (τ ) −1 0 Each block can be diagonalized e. [sent-68, score-0.142]
</p><p>40 with ˜ W2 = and with  1 −i 1 i  ˜ W2 = idK×K ⊗ W2  (9)  (10)  we get † † W2 W1 D(τ )W1 W2 = diag (11) From a simultaneous diagonalization of D(τ ) we obtain an estimate of the demixing matrix −1 ˆ W of the true demixing matrix W = W2 W1 . [sent-70, score-0.899]
</p><p>41 We are interested in the columns of W1 which correspond to the spatial patterns of the interacting sources. [sent-71, score-0.638]
</p><p>42 Let us denote the N × 2  submatrix of a matrix B consisting of the (2k − 1). [sent-72, score-0.067]
</p><p>43 Then we can write −1 ˜ (W1 )k ∼ (W −1 )k W2  (12)  and hence the desired spatial patterns of the k. [sent-75, score-0.141]
</p><p>44 th system are a complex linear superposition of the (2k − 1). [sent-76, score-0.059]
</p><p>45 The latter would indeed be impossible because all we analyze are anti-symmetric matrices which are, for each system, constructed as anti-symmetric outer products of the two respective ﬁeld patterns. [sent-80, score-0.203]
</p><p>46 These anti-symmetric matrices are, apart from an irrelevant global scale, invariant with respect to a linear and real-valued mixing of the sources within each system. [sent-81, score-0.475]
</p><p>47 From the data construct anti-symmetric cross-correlation matrices as deﬁned in Eq. [sent-84, score-0.108]
</p><p>48 Find a complex matrix W such that W D(τ )W † is approximately diagonal for all τ. [sent-87, score-0.114]
</p><p>49 If the system consists of subsystems of paired interactions (and indeed, according to our own experience, very much in practice) the diagonal elements in W D(τ )W † come in pairs in the form ±iλ. [sent-89, score-0.313]
</p><p>50 The corresponding two columns in W −1 , with separated real and imaginary parts, form an N × 4 matrix V with rank 2. [sent-91, score-0.276]
</p><p>51 The span of V coincides with the space spanned by the respective system. [sent-92, score-0.159]
</p><p>52 Instead of analyzing V in the above way it is also possible to simply take the real and imaginary part of either one of the two columns. [sent-95, score-0.282]
</p><p>53 Similar to the spatial analysis, it is not possible to separate the time-courses of two interacting sources within one subsystem. [sent-97, score-0.867]
</p><p>54 In general, two estimated time-courses, say s1 (t) and s2 (t), are an unknown linear combination of the true source activaˆ ˆ tions s1 (t) and s2 (t). [sent-98, score-0.132]
</p><p>55 To understand the type of interaction it is still recommended to look at the power and autocorrelation functions. [sent-99, score-0.188]
</p><p>56 Invariant with respect to linear mixing with one subsystem is the anti-symmetrized cross-correlation between s1 (t) and s2 (t) and, equivalently, the imaginary part of the cross-spectral density. [sent-100, score-0.359]
</p><p>57 th diagonal λk (τ ) and their respective Fourier transforms. [sent-103, score-0.11]
</p><p>58 While (approximate) simultaneous diagonalization of D(τ ) using complex demixing matrices is always possible with pairwise interactions we can expect only block-diagonal structure if a larger number of sources are interacting within one or more subsystems. [sent-104, score-1.44]
</p><p>59 We will show below for simulated data that the algorithm still ﬁnds these blocks although the actual goal, i. [sent-105, score-0.036]
</p><p>60 1  Results Simulated data  Matrices were approximately simultaneously diagonalized with the DOMUNG-algorithm [7], which was generalized to the complex domain. [sent-109, score-0.111]
</p><p>61 Here, an initial guess for the demixing matrix W is successively optimized using a natural gradient approach combined with line search according to the requirement that the off-diagonals are minimal under the constraint det(W ) = 1. [sent-110, score-0.352]
</p><p>62 , W ∗ diagonalizes as well as W ) the initial guess may not be set to a real-valued matrix because then the component of the gradient in imaginary direction will be zero and W will converge to a real-valued saddle point. [sent-114, score-0.333]
</p><p>63 We simulated two random interacting subsystems of dimensions NA and NB which were assumed to be mutually independent. [sent-115, score-0.729]
</p><p>64 The two subsystems were mapped into N = NA + NB channels with a random mixture matrix. [sent-116, score-0.29]
</p><p>65 The anti-symmetrized cross-correlation matrices read DA (τ ) 0  D(τ ) = A  0 DB (τ )  A†  (14)  where A is a random real-valued N × N matrix, and DA (τ ) (DB (τ )), with τ = 1. [sent-117, score-0.108]
</p><p>66 As expected, we have found that if one of the subsystems is two-dimensional the respective block can always be diagonalized exactly for any number of τ s. [sent-122, score-0.401]
</p><p>67 We have also seen, that the diagonalization procedure always perfectly separates the two subsystems even if a diagonalization within a subsystem is not possible. [sent-123, score-0.685]
</p><p>68 In the left panel we show the average of the absolute value of correlation matrices before spatial mixing. [sent-126, score-0.259]
</p><p>69 In the middle panel we show the respective result after random spatial mixture and subsequent demixing, and in the right panel we show W1 A where W1 is the estimated real version of the demixing matrix as explained in the preceding section. [sent-127, score-0.616]
</p><p>70 We note again, that also for the two-dimensional block, which can always be diagonalized exactly, one can only recover the corresponding two-dimensional subspace and not the source components themselves. [sent-128, score-0.258]
</p><p>71 2  Real MEG data  We applied our method to real data gathered in 93 MEG channels during triggered ﬁnger movements of the right or left hand. [sent-132, score-0.126]
</p><p>72 We recall that for each interacting component we get two results: a) the 2D subspace spanned by the two components and b) the diagonals of the demixed system, say ±iλk (τ ). [sent-133, score-0.692]
</p><p>73 To visualize the 2D subspace in a unique way we construct from the two patterns of the k. [sent-134, score-0.098]
</p><p>74 th system, say x1 and x2 , the anti-symmetric outer product D k ≡ x 1 xT − x 2 xT 2 1  (15)  Indeed, the k. [sent-135, score-0.032]
</p><p>75 th subsystem contributes this matrix to the anti-symmetrized crosscorrelations D(τ ) with varying amplitude for all τ . [sent-136, score-0.134]
</p><p>76 The matrix Dk is now visualized as shown in Figs. [sent-137, score-0.067]
</p><p>77 th row of Dk corresponds to the interaction of the i. [sent-140, score-0.156]
</p><p>78 th channel to all others and this interaction is represented by the contour-plot within the i. [sent-141, score-0.192]
</p><p>79 In this example, the observed structure clearly corresponds to the interaction between eye-blinks and visual cortex since occipital channels interact with channels close to the eyes and vice versa. [sent-143, score-0.549]
</p><p>80 2 we show the corresponding temporal and spectral structures of this interaction, represented by λk (τ ), and its Fourier transform, respectively. [sent-145, score-0.03]
</p><p>81 We observe in the temporal domain a peak at a delay around 120 ms (indicated by the arrow) which corresponds well to the response time of the primary visual cortex to visual input. [sent-146, score-0.238]
</p><p>82 2 we show the temporal and spectral pattern of another interacting component with a clear peak in the alpha range (10 Hz). [sent-148, score-0.643]
</p><p>83 4 0  200  400 600 time in msec  800  0 0  1000  10  20 30 frequency in Hz  40  50  10  20 30 frequency in Hz  40  50  1  1  power in a. [sent-165, score-0.131]
</p><p>84 5  0  200  400 600 time in msec  800  0 0  Figure 2: Diagonals of demixed antisymmetric correlation matrices as a function of delay τ (left panels) and, after Fourier transformation, as a function of frequency (right panels). [sent-175, score-0.349]
</p><p>85 Top: interaction of eye-blinks and visual cortex; bottom: interaction of alpha generators. [sent-176, score-0.425]
</p><p>86 Figure 3: Spatial pattern corresponding to the interaction between eye-blinks and visual cortex. [sent-177, score-0.196]
</p><p>87 4  Conclusion  When analyzing interaction between brain sources from macroscopic measurements like EEG/MEG it is important to distinguish physiologically reasonable patterns of interaction and spurious ones. [sent-178, score-1.083]
</p><p>88 In particular, volume conduction effects make large parts of the cortex seemingly interact although in reality such contributions are purely artifactual. [sent-179, score-0.355]
</p><p>89 Existing BSS methods that have been used with success for artifact removal and for estimation of brain sources will by construction fail when attempting to separate interacting i. [sent-180, score-0.965]
</p><p>90 In this work we have proposed a new BSS algorithm that uses anti-symmetrized cross-correlation matrices and subsequent diagonalization and can thus reliably extract meaningful interaction while ignoring all spurious effects. [sent-183, score-0.598]
</p><p>91 Experiments using our interacting source analysis (ISA) reveal interesting relationships that are found blindly, e. [sent-184, score-0.599]
</p><p>92 inferring a component that links both eyes with visual cortex activity in a self-paced ﬁnger movement experiment. [sent-186, score-0.13]
</p><p>93 A more detailed look at the spectrum exhibits a peak at the typing frequency, and, in fact going back to the original MEG traces, eye-blinks were strongly coupled with the typing speed. [sent-187, score-0.155]
</p><p>94 This simple ﬁnding exempliﬁes that ISA is a powerful new technique for analyzing dynamical correlations in macroscopic brain measurements. [sent-188, score-0.291]
</p><p>95 Future studies will therefore apply ISA to other neurophysiological paradigms in order to gain insights into the coherence and synchronicity patterns of cortical dynamics. [sent-189, score-0.053]
</p><p>96 It is especially of high interest to explore the possibilities of using true brain interactions as revealed by the imaginary part of cross-spectra as complementing information to improve the performance of brain computer interfaces. [sent-190, score-0.679]
</p><p>97 This work was supported in part by the IST Programme of the European Community, under PASCAL Network  Figure 4: Spatial pattern corresponding to the interaction between alpha generators. [sent-194, score-0.259]
</p><p>98 Identifying true brain interaction from eeg data using the imaginary part of coherency. [sent-218, score-0.618]
</p><p>99 Puntonet and Alberto Prieto, editors, Lecture Notes in Computer Science, volume 3195, pages 89–96, Granada, 2004. [sent-237, score-0.056]
</p><p>100 TDSEP – an efﬁcient algorithm for blind separation using u time structure. [sent-245, score-0.07]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('interacting', 0.497), ('sources', 0.282), ('demixing', 0.252), ('subsystems', 0.196), ('bss', 0.195), ('diagonalization', 0.195), ('brain', 0.186), ('imaginary', 0.177), ('isa', 0.168), ('interaction', 0.156), ('meg', 0.146), ('conduction', 0.111), ('diagonalized', 0.111), ('matrices', 0.108), ('source', 0.102), ('nb', 0.098), ('channels', 0.094), ('spurious', 0.089), ('spatial', 0.088), ('mixing', 0.085), ('interact', 0.075), ('synchronization', 0.074), ('alpha', 0.073), ('ziehe', 0.073), ('na', 0.072), ('interactions', 0.07), ('matrix', 0.067), ('subsystem', 0.067), ('meaningless', 0.067), ('respective', 0.063), ('macroscopic', 0.062), ('superposition', 0.059), ('cortex', 0.057), ('volume', 0.056), ('antisymmetric', 0.056), ('demixed', 0.056), ('diagonalizes', 0.056), ('nger', 0.056), ('nolte', 0.056), ('physiologically', 0.056), ('tdsep', 0.056), ('typing', 0.056), ('seemingly', 0.056), ('panels', 0.055), ('berlin', 0.054), ('patterns', 0.053), ('truly', 0.051), ('subsequent', 0.05), ('spanned', 0.05), ('diagonal', 0.047), ('ica', 0.046), ('fourier', 0.046), ('span', 0.046), ('subspace', 0.045), ('diagonals', 0.044), ('andreas', 0.044), ('drawbacks', 0.044), ('peak', 0.043), ('analyzing', 0.043), ('potsdam', 0.041), ('ac', 0.041), ('msec', 0.041), ('visual', 0.04), ('germany', 0.04), ('hz', 0.04), ('eeg', 0.039), ('contribute', 0.038), ('phase', 0.038), ('delays', 0.037), ('distinguishing', 0.037), ('da', 0.037), ('frank', 0.037), ('fundamental', 0.037), ('simulated', 0.036), ('separation', 0.036), ('channel', 0.036), ('simultaneous', 0.036), ('blind', 0.034), ('dk', 0.034), ('superimposed', 0.034), ('artifacts', 0.033), ('eyes', 0.033), ('guess', 0.033), ('signals', 0.033), ('real', 0.032), ('power', 0.032), ('panel', 0.032), ('independence', 0.032), ('outer', 0.032), ('separates', 0.032), ('correlation', 0.031), ('block', 0.031), ('ideally', 0.031), ('part', 0.03), ('true', 0.03), ('temporal', 0.03), ('cs', 0.03), ('frequency', 0.029), ('db', 0.029), ('delay', 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999923 <a title="29-tfidf-1" href="./nips-2005-Analyzing_Coupled_Brain_Sources%3A_Distinguishing_True_from_Spurious_Interaction.html">29 nips-2005-Analyzing Coupled Brain Sources: Distinguishing True from Spurious Interaction</a></p>
<p>Author: Guido Nolte, Andreas Ziehe, Frank Meinecke, Klaus-Robert Müller</p><p>Abstract: When trying to understand the brain, it is of fundamental importance to analyse (e.g. from EEG/MEG measurements) what parts of the cortex interact with each other in order to infer more accurate models of brain activity. Common techniques like Blind Source Separation (BSS) can estimate brain sources and single out artifacts by using the underlying assumption of source signal independence. However, physiologically interesting brain sources typically interact, so BSS will—by construction— fail to characterize them properly. Noting that there are truly interacting sources and signals that only seemingly interact due to effects of volume conduction, this work aims to contribute by distinguishing these effects. For this a new BSS technique is proposed that uses anti-symmetrized cross-correlation matrices and subsequent diagonalization. The resulting decomposition consists of the truly interacting brain sources and suppresses any spurious interaction stemming from volume conduction. Our new concept of interacting source analysis (ISA) is successfully demonstrated on MEG data. 1</p><p>2 0.12904045 <a title="29-tfidf-2" href="./nips-2005-Gradient_Flow_Independent_Component_Analysis_in_Micropower_VLSI.html">88 nips-2005-Gradient Flow Independent Component Analysis in Micropower VLSI</a></p>
<p>Author: Abdullah Celik, Milutin Stanacevic, Gert Cauwenberghs</p><p>Abstract: We present micropower mixed-signal VLSI hardware for real-time blind separation and localization of acoustic sources. Gradient ﬂow representation of the traveling wave signals acquired over a miniature (1cm diameter) array of four microphones yields linearly mixed instantaneous observations of the time-differentiated sources, separated and localized by independent component analysis (ICA). The gradient ﬂow and ICA processors each measure 3mm × 3mm in 0.5 µm CMOS, and consume 54 µW and 180 µW power, respectively, from a 3 V supply at 16 ks/s sampling rate. Experiments demonstrate perceptually clear (12dB) separation and precise localization of two speech sources presented through speakers positioned at 1.5m from the array on a conference room table. Analysis of the multipath residuals shows that they are spectrally diffuse, and void of the direct path.</p><p>3 0.12353242 <a title="29-tfidf-3" href="./nips-2005-Stimulus_Evoked_Independent_Factor_Analysis_of_MEG_Data_with_Large_Background_Activity.html">183 nips-2005-Stimulus Evoked Independent Factor Analysis of MEG Data with Large Background Activity</a></p>
<p>Author: Kenneth Hild, Kensuke Sekihara, Hagai T. Attias, Srikantan S. Nagarajan</p><p>Abstract: This paper presents a novel technique for analyzing electromagnetic imaging data obtained using the stimulus evoked experimental paradigm. The technique is based on a probabilistic graphical model, which describes the data in terms of underlying evoked and interference sources, and explicitly models the stimulus evoked paradigm. A variational Bayesian EM algorithm infers the model from data, suppresses interference sources, and reconstructs the activity of separated individual brain sources. The new algorithm outperforms existing techniques on two real datasets, as well as on simulated data. 1</p><p>4 0.12060732 <a title="29-tfidf-4" href="./nips-2005-Optimizing_spatio-temporal_filters_for_improving_Brain-Computer_Interfacing.html">150 nips-2005-Optimizing spatio-temporal filters for improving Brain-Computer Interfacing</a></p>
<p>Author: Guido Dornhege, Benjamin Blankertz, Matthias Krauledat, Florian Losch, Gabriel Curio, Klaus-Robert Müller</p><p>Abstract: Brain-Computer Interface (BCI) systems create a novel communication channel from the brain to an output device by bypassing conventional motor output pathways of nerves and muscles. Therefore they could provide a new communication and control option for paralyzed patients. Modern BCI technology is essentially based on techniques for the classiﬁcation of single-trial brain signals. Here we present a novel technique that allows the simultaneous optimization of a spatial and a spectral ﬁlter enhancing discriminability of multi-channel EEG single-trials. The evaluation of 60 experiments involving 22 different subjects demonstrates the superiority of the proposed algorithm. Apart from the enhanced classiﬁcation, the spatial and/or the spectral ﬁlter that are determined by the algorithm can also be used for further analysis of the data, e.g., for source localization of the respective brain rhythms.</p><p>5 0.10770849 <a title="29-tfidf-5" href="./nips-2005-Learning_Multiple_Related_Tasks_using_Latent_Independent_Component_Analysis.html">113 nips-2005-Learning Multiple Related Tasks using Latent Independent Component Analysis</a></p>
<p>Author: Jian Zhang, Zoubin Ghahramani, Yiming Yang</p><p>Abstract: We propose a probabilistic model based on Independent Component Analysis for learning multiple related tasks. In our model the task parameters are assumed to be generated from independent sources which account for the relatedness of the tasks. We use Laplace distributions to model hidden sources which makes it possible to identify the hidden, independent components instead of just modeling correlations. Furthermore, our model enjoys a sparsity property which makes it both parsimonious and robust. We also propose efﬁcient algorithms for both empirical Bayes method and point estimation. Our experimental results on two multi-label text classiﬁcation data sets show that the proposed approach is promising.</p><p>6 0.085748799 <a title="29-tfidf-6" href="./nips-2005-Modeling_Neuronal_Interactivity_using_Dynamic_Bayesian_Networks.html">130 nips-2005-Modeling Neuronal Interactivity using Dynamic Bayesian Networks</a></p>
<p>7 0.083295859 <a title="29-tfidf-7" href="./nips-2005-Large-scale_biophysical_parameter_estimation_in_single_neurons_via_constrained_linear_regression.html">106 nips-2005-Large-scale biophysical parameter estimation in single neurons via constrained linear regression</a></p>
<p>8 0.072476789 <a title="29-tfidf-8" href="./nips-2005-Fusion_of_Similarity_Data_in_Clustering.html">79 nips-2005-Fusion of Similarity Data in Clustering</a></p>
<p>9 0.070735551 <a title="29-tfidf-9" href="./nips-2005-Scaling_Laws_in_Natural_Scenes_and_the_Inference_of_3D_Shape.html">170 nips-2005-Scaling Laws in Natural Scenes and the Inference of 3D Shape</a></p>
<p>10 0.066162042 <a title="29-tfidf-10" href="./nips-2005-Phase_Synchrony_Rate_for_the_Recognition_of_Motor_Imagery_in_Brain-Computer_Interface.html">152 nips-2005-Phase Synchrony Rate for the Recognition of Motor Imagery in Brain-Computer Interface</a></p>
<p>11 0.058345854 <a title="29-tfidf-11" href="./nips-2005-Measuring_Shared_Information_and_Coordinated_Activity_in_Neuronal_Networks.html">124 nips-2005-Measuring Shared Information and Coordinated Activity in Neuronal Networks</a></p>
<p>12 0.056675937 <a title="29-tfidf-12" href="./nips-2005-A_Cortically-Plausible_Inverse_Problem_Solving_Method_Applied_to_Recognizing_Static_and_Kinematic_3D_Objects.html">7 nips-2005-A Cortically-Plausible Inverse Problem Solving Method Applied to Recognizing Static and Kinematic 3D Objects</a></p>
<p>13 0.05105105 <a title="29-tfidf-13" href="./nips-2005-Is_Early_Vision_Optimized_for_Extracting_Higher-order_Dependencies%3F.html">101 nips-2005-Is Early Vision Optimized for Extracting Higher-order Dependencies?</a></p>
<p>14 0.05000617 <a title="29-tfidf-14" href="./nips-2005-Beyond_Pair-Based_STDP%3A_a_Phenomenological_Rule_for_Spike_Triplet_and_Frequency_Effects.html">39 nips-2005-Beyond Pair-Based STDP: a Phenomenological Rule for Spike Triplet and Frequency Effects</a></p>
<p>15 0.049652584 <a title="29-tfidf-15" href="./nips-2005-Visual_Encoding_with_Jittering_Eyes.html">203 nips-2005-Visual Encoding with Jittering Eyes</a></p>
<p>16 0.048954654 <a title="29-tfidf-16" href="./nips-2005-Recovery_of_Jointly_Sparse_Signals_from_Few_Random_Projections.html">163 nips-2005-Recovery of Jointly Sparse Signals from Few Random Projections</a></p>
<p>17 0.0476555 <a title="29-tfidf-17" href="./nips-2005-A_Bayes_Rule_for_Density_Matrices.html">2 nips-2005-A Bayes Rule for Density Matrices</a></p>
<p>18 0.044261497 <a title="29-tfidf-18" href="./nips-2005-Extracting_Dynamical_Structure_Embedded_in_Neural_Activity.html">67 nips-2005-Extracting Dynamical Structure Embedded in Neural Activity</a></p>
<p>19 0.043067884 <a title="29-tfidf-19" href="./nips-2005-Noise_and_the_two-thirds_power_Law.html">136 nips-2005-Noise and the two-thirds power Law</a></p>
<p>20 0.041800216 <a title="29-tfidf-20" href="./nips-2005-Non-iterative_Estimation_with_Perturbed_Gaussian_Markov_Processes.html">139 nips-2005-Non-iterative Estimation with Perturbed Gaussian Markov Processes</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2005_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.154), (1, -0.06), (2, -0.015), (3, 0.086), (4, -0.032), (5, -0.01), (6, -0.111), (7, -0.081), (8, 0.083), (9, -0.01), (10, -0.144), (11, -0.123), (12, 0.023), (13, -0.138), (14, 0.09), (15, 0.057), (16, -0.114), (17, -0.066), (18, 0.106), (19, 0.032), (20, -0.081), (21, -0.071), (22, 0.095), (23, 0.034), (24, 0.032), (25, -0.123), (26, 0.036), (27, -0.116), (28, -0.075), (29, -0.013), (30, 0.184), (31, 0.132), (32, -0.01), (33, -0.202), (34, 0.019), (35, 0.068), (36, 0.055), (37, -0.051), (38, 0.027), (39, -0.04), (40, -0.01), (41, -0.014), (42, -0.014), (43, 0.066), (44, 0.032), (45, -0.01), (46, -0.002), (47, 0.158), (48, -0.058), (49, -0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97184801 <a title="29-lsi-1" href="./nips-2005-Analyzing_Coupled_Brain_Sources%3A_Distinguishing_True_from_Spurious_Interaction.html">29 nips-2005-Analyzing Coupled Brain Sources: Distinguishing True from Spurious Interaction</a></p>
<p>Author: Guido Nolte, Andreas Ziehe, Frank Meinecke, Klaus-Robert Müller</p><p>Abstract: When trying to understand the brain, it is of fundamental importance to analyse (e.g. from EEG/MEG measurements) what parts of the cortex interact with each other in order to infer more accurate models of brain activity. Common techniques like Blind Source Separation (BSS) can estimate brain sources and single out artifacts by using the underlying assumption of source signal independence. However, physiologically interesting brain sources typically interact, so BSS will—by construction— fail to characterize them properly. Noting that there are truly interacting sources and signals that only seemingly interact due to effects of volume conduction, this work aims to contribute by distinguishing these effects. For this a new BSS technique is proposed that uses anti-symmetrized cross-correlation matrices and subsequent diagonalization. The resulting decomposition consists of the truly interacting brain sources and suppresses any spurious interaction stemming from volume conduction. Our new concept of interacting source analysis (ISA) is successfully demonstrated on MEG data. 1</p><p>2 0.75906199 <a title="29-lsi-2" href="./nips-2005-Stimulus_Evoked_Independent_Factor_Analysis_of_MEG_Data_with_Large_Background_Activity.html">183 nips-2005-Stimulus Evoked Independent Factor Analysis of MEG Data with Large Background Activity</a></p>
<p>Author: Kenneth Hild, Kensuke Sekihara, Hagai T. Attias, Srikantan S. Nagarajan</p><p>Abstract: This paper presents a novel technique for analyzing electromagnetic imaging data obtained using the stimulus evoked experimental paradigm. The technique is based on a probabilistic graphical model, which describes the data in terms of underlying evoked and interference sources, and explicitly models the stimulus evoked paradigm. A variational Bayesian EM algorithm infers the model from data, suppresses interference sources, and reconstructs the activity of separated individual brain sources. The new algorithm outperforms existing techniques on two real datasets, as well as on simulated data. 1</p><p>3 0.59747314 <a title="29-lsi-3" href="./nips-2005-Gradient_Flow_Independent_Component_Analysis_in_Micropower_VLSI.html">88 nips-2005-Gradient Flow Independent Component Analysis in Micropower VLSI</a></p>
<p>Author: Abdullah Celik, Milutin Stanacevic, Gert Cauwenberghs</p><p>Abstract: We present micropower mixed-signal VLSI hardware for real-time blind separation and localization of acoustic sources. Gradient ﬂow representation of the traveling wave signals acquired over a miniature (1cm diameter) array of four microphones yields linearly mixed instantaneous observations of the time-differentiated sources, separated and localized by independent component analysis (ICA). The gradient ﬂow and ICA processors each measure 3mm × 3mm in 0.5 µm CMOS, and consume 54 µW and 180 µW power, respectively, from a 3 V supply at 16 ks/s sampling rate. Experiments demonstrate perceptually clear (12dB) separation and precise localization of two speech sources presented through speakers positioned at 1.5m from the array on a conference room table. Analysis of the multipath residuals shows that they are spectrally diffuse, and void of the direct path.</p><p>4 0.55100793 <a title="29-lsi-4" href="./nips-2005-Optimizing_spatio-temporal_filters_for_improving_Brain-Computer_Interfacing.html">150 nips-2005-Optimizing spatio-temporal filters for improving Brain-Computer Interfacing</a></p>
<p>Author: Guido Dornhege, Benjamin Blankertz, Matthias Krauledat, Florian Losch, Gabriel Curio, Klaus-Robert Müller</p><p>Abstract: Brain-Computer Interface (BCI) systems create a novel communication channel from the brain to an output device by bypassing conventional motor output pathways of nerves and muscles. Therefore they could provide a new communication and control option for paralyzed patients. Modern BCI technology is essentially based on techniques for the classiﬁcation of single-trial brain signals. Here we present a novel technique that allows the simultaneous optimization of a spatial and a spectral ﬁlter enhancing discriminability of multi-channel EEG single-trials. The evaluation of 60 experiments involving 22 different subjects demonstrates the superiority of the proposed algorithm. Apart from the enhanced classiﬁcation, the spatial and/or the spectral ﬁlter that are determined by the algorithm can also be used for further analysis of the data, e.g., for source localization of the respective brain rhythms.</p><p>5 0.48649427 <a title="29-lsi-5" href="./nips-2005-Separation_of_Music_Signals_by_Harmonic_Structure_Modeling.html">174 nips-2005-Separation of Music Signals by Harmonic Structure Modeling</a></p>
<p>Author: Yun-gang Zhang, Chang-shui Zhang</p><p>Abstract: Separation of music signals is an interesting but difﬁcult problem. It is helpful for many other music researches such as audio content analysis. In this paper, a new music signal separation method is proposed, which is based on harmonic structure modeling. The main idea of harmonic structure modeling is that the harmonic structure of a music signal is stable, so a music signal can be represented by a harmonic structure model. Accordingly, a corresponding separation algorithm is proposed. The main idea is to learn a harmonic structure model for each music signal in the mixture, and then separate signals by using these models to distinguish harmonic structures of different signals. Experimental results show that the algorithm can separate signals and obtain not only a very high Signalto-Noise Ratio (SNR) but also a rather good subjective audio quality. 1</p><p>6 0.46733558 <a title="29-lsi-6" href="./nips-2005-Learning_Multiple_Related_Tasks_using_Latent_Independent_Component_Analysis.html">113 nips-2005-Learning Multiple Related Tasks using Latent Independent Component Analysis</a></p>
<p>7 0.45337525 <a title="29-lsi-7" href="./nips-2005-Modeling_Neuronal_Interactivity_using_Dynamic_Bayesian_Networks.html">130 nips-2005-Modeling Neuronal Interactivity using Dynamic Bayesian Networks</a></p>
<p>8 0.4092885 <a title="29-lsi-8" href="./nips-2005-Phase_Synchrony_Rate_for_the_Recognition_of_Motor_Imagery_in_Brain-Computer_Interface.html">152 nips-2005-Phase Synchrony Rate for the Recognition of Motor Imagery in Brain-Computer Interface</a></p>
<p>9 0.34627426 <a title="29-lsi-9" href="./nips-2005-Visual_Encoding_with_Jittering_Eyes.html">203 nips-2005-Visual Encoding with Jittering Eyes</a></p>
<p>10 0.33057958 <a title="29-lsi-10" href="./nips-2005-A_Bayes_Rule_for_Density_Matrices.html">2 nips-2005-A Bayes Rule for Density Matrices</a></p>
<p>11 0.32761297 <a title="29-lsi-11" href="./nips-2005-A_Cortically-Plausible_Inverse_Problem_Solving_Method_Applied_to_Recognizing_Static_and_Kinematic_3D_Objects.html">7 nips-2005-A Cortically-Plausible Inverse Problem Solving Method Applied to Recognizing Static and Kinematic 3D Objects</a></p>
<p>12 0.32613039 <a title="29-lsi-12" href="./nips-2005-Large-scale_biophysical_parameter_estimation_in_single_neurons_via_constrained_linear_regression.html">106 nips-2005-Large-scale biophysical parameter estimation in single neurons via constrained linear regression</a></p>
<p>13 0.32134104 <a title="29-lsi-13" href="./nips-2005-Non-Gaussian_Component_Analysis%3A_a_Semi-parametric_Framework_for_Linear_Dimension_Reduction.html">137 nips-2005-Non-Gaussian Component Analysis: a Semi-parametric Framework for Linear Dimension Reduction</a></p>
<p>14 0.3203707 <a title="29-lsi-14" href="./nips-2005-Recovery_of_Jointly_Sparse_Signals_from_Few_Random_Projections.html">163 nips-2005-Recovery of Jointly Sparse Signals from Few Random Projections</a></p>
<p>15 0.2788952 <a title="29-lsi-15" href="./nips-2005-The_Information-Form_Data_Association_Filter.html">192 nips-2005-The Information-Form Data Association Filter</a></p>
<p>16 0.26886126 <a title="29-lsi-16" href="./nips-2005-Affine_Structure_From_Sound.html">20 nips-2005-Affine Structure From Sound</a></p>
<p>17 0.2598041 <a title="29-lsi-17" href="./nips-2005-Non-iterative_Estimation_with_Perturbed_Gaussian_Markov_Processes.html">139 nips-2005-Non-iterative Estimation with Perturbed Gaussian Markov Processes</a></p>
<p>18 0.25170261 <a title="29-lsi-18" href="./nips-2005-Factorial_Switching_Kalman_Filters_for_Condition_Monitoring_in_Neonatal_Intensive_Care.html">68 nips-2005-Factorial Switching Kalman Filters for Condition Monitoring in Neonatal Intensive Care</a></p>
<p>19 0.24612394 <a title="29-lsi-19" href="./nips-2005-Logic_and_MRF_Circuitry_for_Labeling_Occluding_and_Thinline_Visual_Contours.html">122 nips-2005-Logic and MRF Circuitry for Labeling Occluding and Thinline Visual Contours</a></p>
<p>20 0.24564271 <a title="29-lsi-20" href="./nips-2005-Measuring_Shared_Information_and_Coordinated_Activity_in_Neuronal_Networks.html">124 nips-2005-Measuring Shared Information and Coordinated Activity in Neuronal Networks</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2005_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.039), (10, 0.03), (27, 0.051), (31, 0.038), (34, 0.095), (39, 0.024), (41, 0.013), (50, 0.011), (55, 0.021), (57, 0.033), (60, 0.369), (69, 0.047), (73, 0.028), (88, 0.083), (91, 0.029), (92, 0.011)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.92113167 <a title="29-lda-1" href="./nips-2005-Neural_mechanisms_of_contrast_dependent_receptive_field_size_in_V1.html">134 nips-2005-Neural mechanisms of contrast dependent receptive field size in V1</a></p>
<p>Author: Jim Wielaard, Paul Sajda</p><p>Abstract: Based on a large scale spiking neuron model of the input layers 4Cα and β of macaque, we identify neural mechanisms for the observed contrast dependent receptive ﬁeld size of V1 cells. We observe a rich variety of mechanisms for the phenomenon and analyze them based on the relative gain of excitatory and inhibitory synaptic inputs. We observe an average growth in the spatial extent of excitation and inhibition for low contrast, as predicted from phenomenological models. However, contrary to phenomenological models, our simulation results suggest this is neither sufﬁcient nor necessary to explain the phenomenon.</p><p>2 0.85574752 <a title="29-lda-2" href="./nips-2005-An_exploration-exploitation_model_based_on_norepinepherine_and_dopamine_activity.html">26 nips-2005-An exploration-exploitation model based on norepinepherine and dopamine activity</a></p>
<p>Author: Samuel M. McClure, Mark S. Gilzenrat, Jonathan D. Cohen</p><p>Abstract: We propose a model by which dopamine (DA) and norepinepherine (NE) combine to alternate behavior between relatively exploratory and exploitative modes. The model is developed for a target detection task for which there is extant single neuron recording data available from locus coeruleus (LC) NE neurons. An exploration-exploitation trade-off is elicited by regularly switching which of the two stimuli are rewarded. DA functions within the model to change synaptic weights according to a reinforcement learning algorithm. Exploration is mediated by the state of LC firing, with higher tonic and lower phasic activity producing greater response variability. The opposite state of LC function, with lower baseline firing rate and greater phasic responses, favors exploitative behavior. Changes in LC firing mode result from combined measures of response conflict and reward rate, where response conflict is monitored using models of anterior cingulate cortex (ACC). Increased long-term response conflict and decreased reward rate, which occurs following reward contingency switch, favors the higher tonic state of LC function and NE release. This increases exploration, and facilitates discovery of the new target. 1 In t rod u ct i on A central problem in reinforcement learning is determining how to adaptively move between exploitative and exploratory behaviors in changing environments. We propose a set of neurophysiologic mechanisms whose interaction may mediate this behavioral shift. Empirical work on the midbrain dopamine (DA) system has suggested that this system is particularly well suited for guiding exploitative behaviors. This hypothesis has been reified by a number of studies showing that a temporal difference (TD) learning algorithm accounts for activity in these neurons in a wide variety of behavioral tasks [1,2]. DA release is believed to encode a reward prediction error signal that acts to change synaptic weights relevant for producing behaviors [3]. Through learning, this allows neural pathways to predict future expected reward through the relative strength of their synaptic connections [1]. Decision-making procedures based on these value estimates are necessarily greedy. Including reward bonuses for exploratory choices supports non-greedy actions [4] and accounts for additional data derived from DA neurons [5]. We show that combining a DA learning algorithm with models of response conflict detection [6] and NE function [7] produces an effective annealing procedure for alternating between exploration and exploitation. NE neurons within the LC alternate between two firing modes [8]. In the first mode, known as the phasic mode, NE neurons fire at a low baseline rate but have relatively robust phasic responses to behaviorally salient stimuli. The second mode, called the tonic mode, is associated with a higher baseline firing and absent or attenuated phasic responses. The effects of NE on efferent areas are modulatory in nature, and are well captured as a change in the gain of efferent inputs so that neuronal responses are potentiated in the presence of NE [9]. Thus, in phasic mode, the LC provides transient facilitation in processing, time-locked to the presence of behaviorally salient information in motor or decision areas. Conversely, in tonic mode, higher overall LC discharge rate increases gain generally and hence increases the probability of arbitrary responding. Consistent with this account, for periods when NE neurons are in the phasic mode, monkey performance is nearly perfect. However, when NE neurons are in the tonic mode, performance is more erratic, with increased response times and error rate [8]. These findings have led to a recent characterization of the LC as a dynamic temporal filter, adjusting the system's relative responsivity to salient and irrelevant information [8]. In this way, the LC is ideally positioned to mediate the shift between exploitative and exploratory behavior. The parameters that underlie changes in LC firing mode remain largely unexplored. Based on data from a target detection task by Aston-Jones and colleagues [10], we propose that LC firing mode is determined in part by measures of response conflict and reward rate as calculated by the ACC and OFC, respectively [8]. Together, the ACC and OFC are the principle sources of cortical input to the LC [8]. Activity in the ACC is known, largely through human neuroimaging experiments, to change in accord with response conflict [6]. In brief, relatively equal activity in competing behavioral responses (reflecting uncertainty) produces high conflict. Low conflict results when one behavioral response predominates. We propose that increased long-term response conflict biases the LC towards a tonic firing mode. Increased conflict necessarily follows changes in reward contingency. As the previously rewarded target no longer produces reward, there will be a relative increase in response ambiguity and hence conflict. This relationship between conflict and LC firing is analogous to other modeling work [11], which proposes that increased tonic firing reflects increased environmental uncertainty. As a final component to our model, we hypothesize that the OFC maintains an ongoing estimate in reward rate, and that this estimate of reward rate also influences LC firing mode. As reward rate increases, we assume that the OFC tends to bias the LC in favor of phasic firing to target stimuli. We have aimed to fix model parameters based on previous work using simpler networks. We use parameters derived primarily from a previous model of the LC by Gilzenrat and colleagues [7]. Integration of response conflict by the ACC and its influence on LC firing was borrowed from unpublished work by Gilzenrat and colleagues in which they fit human behavioral data in a diminishing utilities task. Given this approach, we interpret our observed improvement in model performance with combined NE and DA function as validation of a mechanism for automatically switching between exploitative and exploratory action selection. 2 G o- No- G o Task and Core Mod el We have modeled an experiment in which monkeys performed a target detection task [10]. In the task, monkeys were shown either a vertical bar or a horizontal bar and were required to make or omit a motor response appropriately. Initially, the vertical bar was the target stimulus and correctly responding was rewarded with a squirt of fruit juice (r=1 in the model). Responding to the non-target horizontal stimulus resulted in time out punishment (r=-.1; Figure 1A). No responses to either the target or non-target gave zero reward. After the monkeys had fully acquired the task, the experimenters periodically switched the reward contingency such that the previously rewarded stimulus (target) became the distractor, and vice versa. Following such reversals, LC neurons were observed to change from emitting phasic bursts of firing to the target, to tonic firing following the switch, and slowly back to phasic firing for the new target as the new response criteria was obtained [10]. Figure 1: Task and model design. (A) Responses were required for targets in order to obtain reward. Responses to distractors resulted in a minor punishment. No responses gave zero reward. (B) In the model, vertical and horizontal bar inputs (I1 and I 2 ) fed to integrator neurons (X1 and X2 ) which then drove response units (Y1 and Y2 ). Responses were made if Y 1 or Y2 crossed a threshold while input units were active. We have previously modeled this task [7,12] with a three-layer connectionist network in which two input units, I1 and I 2 , corresponding to the vertical and horizontal bars, drive two mutually inhibitory integrator units, X1 and X2 . The integrator units subsequently feed two response units, Y1 and Y2 (Figure 1B). Responses are made whenever output from Y1 or Y2 crosses a threshold level of activity, θ. Relatively weak cross connections from each input unit to the opposite integrator unit (I1 to X2 and I 2 to X1 ) are intended to model stimulus similarity. Both the integrator and response units were modeled as noisy, leaky accumulators: ˙ X i =</p><p>same-paper 3 0.8460179 <a title="29-lda-3" href="./nips-2005-Analyzing_Coupled_Brain_Sources%3A_Distinguishing_True_from_Spurious_Interaction.html">29 nips-2005-Analyzing Coupled Brain Sources: Distinguishing True from Spurious Interaction</a></p>
<p>Author: Guido Nolte, Andreas Ziehe, Frank Meinecke, Klaus-Robert Müller</p><p>Abstract: When trying to understand the brain, it is of fundamental importance to analyse (e.g. from EEG/MEG measurements) what parts of the cortex interact with each other in order to infer more accurate models of brain activity. Common techniques like Blind Source Separation (BSS) can estimate brain sources and single out artifacts by using the underlying assumption of source signal independence. However, physiologically interesting brain sources typically interact, so BSS will—by construction— fail to characterize them properly. Noting that there are truly interacting sources and signals that only seemingly interact due to effects of volume conduction, this work aims to contribute by distinguishing these effects. For this a new BSS technique is proposed that uses anti-symmetrized cross-correlation matrices and subsequent diagonalization. The resulting decomposition consists of the truly interacting brain sources and suppresses any spurious interaction stemming from volume conduction. Our new concept of interacting source analysis (ISA) is successfully demonstrated on MEG data. 1</p><p>4 0.67997193 <a title="29-lda-4" href="./nips-2005-Non-Local_Manifold_Parzen_Windows.html">138 nips-2005-Non-Local Manifold Parzen Windows</a></p>
<p>Author: Yoshua Bengio, Hugo Larochelle, Pascal Vincent</p><p>Abstract: To escape from the curse of dimensionality, we claim that one can learn non-local functions, in the sense that the value and shape of the learned function at x must be inferred using examples that may be far from x. With this objective, we present a non-local non-parametric density estimator. It builds upon previously proposed Gaussian mixture models with regularized covariance matrices to take into account the local shape of the manifold. It also builds upon recent work on non-local estimators of the tangent plane of a manifold, which are able to generalize in places with little training data, unlike traditional, local, non-parametric models.</p><p>5 0.50883883 <a title="29-lda-5" href="./nips-2005-Identifying_Distributed_Object_Representations_in_Human_Extrastriate_Visual_Cortex.html">94 nips-2005-Identifying Distributed Object Representations in Human Extrastriate Visual Cortex</a></p>
<p>Author: Rory Sayres, David Ress, Kalanit Grill-spector</p><p>Abstract: The category of visual stimuli has been reliably decoded from patterns of neural activity in extrastriate visual cortex [1]. It has yet to be seen whether object identity can be inferred from this activity. We present fMRI data measuring responses in human extrastriate cortex to a set of 12 distinct object images. We use a simple winner-take-all classifier, using half the data from each recording session as a training set, to evaluate encoding of object identity across fMRI voxels. Since this approach is sensitive to the inclusion of noisy voxels, we describe two methods for identifying subsets of voxels in the data which optimally distinguish object identity. One method characterizes the reliability of each voxel within subsets of the data, while another estimates the mutual information of each voxel with the stimulus set. We find that both metrics can identify subsets of the data which reliably encode object identity, even when noisy measurements are artificially added to the data. The mutual information metric is less efficient at this task, likely due to constraints in fMRI data. 1</p><p>6 0.50736767 <a title="29-lda-6" href="./nips-2005-Analyzing_Auditory_Neurons_by_Learning_Distance_Functions.html">28 nips-2005-Analyzing Auditory Neurons by Learning Distance Functions</a></p>
<p>7 0.50078082 <a title="29-lda-7" href="./nips-2005-Learning_Cue-Invariant_Visual_Responses.html">109 nips-2005-Learning Cue-Invariant Visual Responses</a></p>
<p>8 0.469154 <a title="29-lda-8" href="./nips-2005-Spiking_Inputs_to_a_Winner-take-all_Network.html">181 nips-2005-Spiking Inputs to a Winner-take-all Network</a></p>
<p>9 0.45493317 <a title="29-lda-9" href="./nips-2005-Optimizing_spatio-temporal_filters_for_improving_Brain-Computer_Interfacing.html">150 nips-2005-Optimizing spatio-temporal filters for improving Brain-Computer Interfacing</a></p>
<p>10 0.44411409 <a title="29-lda-10" href="./nips-2005-Stimulus_Evoked_Independent_Factor_Analysis_of_MEG_Data_with_Large_Background_Activity.html">183 nips-2005-Stimulus Evoked Independent Factor Analysis of MEG Data with Large Background Activity</a></p>
<p>11 0.43900126 <a title="29-lda-11" href="./nips-2005-Principles_of_real-time_computing_with_feedback_applied_to_cortical_microcircuit_models.html">157 nips-2005-Principles of real-time computing with feedback applied to cortical microcircuit models</a></p>
<p>12 0.42903262 <a title="29-lda-12" href="./nips-2005-The_Curse_of_Highly_Variable_Functions_for_Local_Kernel_Machines.html">190 nips-2005-The Curse of Highly Variable Functions for Local Kernel Machines</a></p>
<p>13 0.42731541 <a title="29-lda-13" href="./nips-2005-Visual_Encoding_with_Jittering_Eyes.html">203 nips-2005-Visual Encoding with Jittering Eyes</a></p>
<p>14 0.42288771 <a title="29-lda-14" href="./nips-2005-Modeling_Neural_Population_Spiking_Activity_with_Gibbs_Distributions.html">129 nips-2005-Modeling Neural Population Spiking Activity with Gibbs Distributions</a></p>
<p>15 0.41651365 <a title="29-lda-15" href="./nips-2005-Extracting_Dynamical_Structure_Embedded_in_Neural_Activity.html">67 nips-2005-Extracting Dynamical Structure Embedded in Neural Activity</a></p>
<p>16 0.4122771 <a title="29-lda-16" href="./nips-2005-Convex_Neural_Networks.html">50 nips-2005-Convex Neural Networks</a></p>
<p>17 0.41201052 <a title="29-lda-17" href="./nips-2005-Sensory_Adaptation_within_a_Bayesian_Framework_for_Perception.html">173 nips-2005-Sensory Adaptation within a Bayesian Framework for Perception</a></p>
<p>18 0.41086614 <a title="29-lda-18" href="./nips-2005-Modeling_Neuronal_Interactivity_using_Dynamic_Bayesian_Networks.html">130 nips-2005-Modeling Neuronal Interactivity using Dynamic Bayesian Networks</a></p>
<p>19 0.41023687 <a title="29-lda-19" href="./nips-2005-Measuring_Shared_Information_and_Coordinated_Activity_in_Neuronal_Networks.html">124 nips-2005-Measuring Shared Information and Coordinated Activity in Neuronal Networks</a></p>
<p>20 0.40941659 <a title="29-lda-20" href="./nips-2005-Integrate-and-Fire_models_with_adaptation_are_good_enough.html">99 nips-2005-Integrate-and-Fire models with adaptation are good enough</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
