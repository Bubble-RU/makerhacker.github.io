<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>65 nips-2005-Estimating the wrong Markov random field: Benefits in the computation-limited setting</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2005" href="../home/nips2005_home.html">nips2005</a> <a title="nips-2005-65" href="#">nips2005-65</a> knowledge-graph by maker-knowledge-mining</p><h1>65 nips-2005-Estimating the wrong Markov random field: Benefits in the computation-limited setting</h1>
<br/><p>Source: <a title="nips-2005-65-pdf" href="http://papers.nips.cc/paper/2925-estimating-the-wrong-markov-random-field-benefits-in-the-computation-limited-setting.pdf">pdf</a></p><p>Author: Martin J. Wainwright</p><p>Abstract: Consider the problem of joint parameter estimation and prediction in a Markov random ﬁeld: i.e., the model parameters are estimated on the basis of an initial set of data, and then the ﬁtted model is used to perform prediction (e.g., smoothing, denoising, interpolation) on a new noisy observation. Working in the computation-limited setting, we analyze a joint method in which the same convex variational relaxation is used to construct an M-estimator for ﬁtting parameters, and to perform approximate marginalization for the prediction step. The key result of this paper is that in the computation-limited setting, using an inconsistent parameter estimator (i.e., an estimator that returns the “wrong” model even in the inﬁnite data limit) is provably beneﬁcial, since the resulting errors can partially compensate for errors made by using an approximate prediction technique. En route to this result, we analyze the asymptotic properties of M-estimators based on convex variational relaxations, and establish a Lipschitz stability property that holds for a broad class of variational methods. We show that joint estimation/prediction based on the reweighted sum-product algorithm substantially outperforms a commonly used heuristic based on ordinary sum-product. 1 Keywords: Markov random ﬁelds; variational method; message-passing algorithms; sum-product; belief propagation; parameter estimation; learning. 1</p><p>Reference: <a title="nips-2005-65-reference" href="../nips2005_reference/nips-2005-Estimating_the_wrong_Markov_random_field%3A_Benefits_in_the_computation-limited_setting_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('xs', 0.501), ('surrog', 0.418), ('convex', 0.217), ('mse', 0.21), ('trw', 0.197), ('snr', 0.177), ('zs', 0.176), ('st', 0.154), ('marg', 0.151), ('bp', 0.147), ('reweight', 0.13), ('pseudomargin', 0.126), ('coupl', 0.114), ('inconsist', 0.112), ('ys', 0.111), ('rd', 0.11), ('relax', 0.103), ('rout', 0.103), ('strength', 0.099), ('predict', 0.093)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="65-tfidf-1" href="./nips-2005-Estimating_the_wrong_Markov_random_field%3A_Benefits_in_the_computation-limited_setting.html">65 nips-2005-Estimating the wrong Markov random field: Benefits in the computation-limited setting</a></p>
<p>2 0.32897371 <a title="65-tfidf-2" href="./nips-2005-Divergences%2C_surrogate_loss_functions_and_experimental_design.html">58 nips-2005-Divergences, surrogate loss functions and experimental design</a></p>
<p>3 0.17039943 <a title="65-tfidf-3" href="./nips-2005-Variational_EM_Algorithms_for_Non-Gaussian_Latent_Variable_Models.html">202 nips-2005-Variational EM Algorithms for Non-Gaussian Latent Variable Models</a></p>
<p>4 0.16724016 <a title="65-tfidf-4" href="./nips-2005-A_Theoretical_Analysis_of_Robust_Coding_over_Noisy_Overcomplete_Channels.html">15 nips-2005-A Theoretical Analysis of Robust Coding over Noisy Overcomplete Channels</a></p>
<p>5 0.14340898 <a title="65-tfidf-5" href="./nips-2005-Using_%60%60epitomes%27%27_to_model_genetic_diversity%3A_Rational_design_of_HIV_vaccine_cocktails.html">198 nips-2005-Using ``epitomes'' to model genetic diversity: Rational design of HIV vaccine cocktails</a></p>
<p>6 0.14027219 <a title="65-tfidf-6" href="./nips-2005-Consistency_of_one-class_SVM_and_related_algorithms.html">47 nips-2005-Consistency of one-class SVM and related algorithms</a></p>
<p>7 0.12247289 <a title="65-tfidf-7" href="./nips-2005-Convex_Neural_Networks.html">50 nips-2005-Convex Neural Networks</a></p>
<p>8 0.094696037 <a title="65-tfidf-8" href="./nips-2005-Combining_Graph_Laplacians_for_Semi--Supervised_Learning.html">42 nips-2005-Combining Graph Laplacians for Semi--Supervised Learning</a></p>
<p>9 0.094305836 <a title="65-tfidf-9" href="./nips-2005-Generalization_Error_Bounds_for_Aggregation_by_Mirror_Descent_with_Averaging.html">82 nips-2005-Generalization Error Bounds for Aggregation by Mirror Descent with Averaging</a></p>
<p>10 0.089086927 <a title="65-tfidf-10" href="./nips-2005-Learning_Influence_among_Interacting_Markov_Chains.html">111 nips-2005-Learning Influence among Interacting Markov Chains</a></p>
<p>11 0.081328772 <a title="65-tfidf-11" href="./nips-2005-Non-iterative_Estimation_with_Perturbed_Gaussian_Markov_Processes.html">139 nips-2005-Non-iterative Estimation with Perturbed Gaussian Markov Processes</a></p>
<p>12 0.079539604 <a title="65-tfidf-12" href="./nips-2005-Inference_with_Minimal_Communication%3A_a_Decision-Theoretic_Variational_Approach.html">96 nips-2005-Inference with Minimal Communication: a Decision-Theoretic Variational Approach</a></p>
<p>13 0.077732183 <a title="65-tfidf-13" href="./nips-2005-Learning_Multiple_Related_Tasks_using_Latent_Independent_Component_Analysis.html">113 nips-2005-Learning Multiple Related Tasks using Latent Independent Component Analysis</a></p>
<p>14 0.073377185 <a title="65-tfidf-14" href="./nips-2005-Consensus_Propagation.html">46 nips-2005-Consensus Propagation</a></p>
<p>15 0.073215365 <a title="65-tfidf-15" href="./nips-2005-Metric_Learning_by_Collapsing_Classes.html">126 nips-2005-Metric Learning by Collapsing Classes</a></p>
<p>16 0.072144523 <a title="65-tfidf-16" href="./nips-2005-Nearest_Neighbor_Based_Feature_Selection_for_Regression_and_its_Application_to_Neural_Activity.html">132 nips-2005-Nearest Neighbor Based Feature Selection for Regression and its Application to Neural Activity</a></p>
<p>17 0.071165502 <a title="65-tfidf-17" href="./nips-2005-Nonparametric_inference_of_prior_probabilities_from_Bayes-optimal_behavior.html">140 nips-2005-Nonparametric inference of prior probabilities from Bayes-optimal behavior</a></p>
<p>18 0.071098618 <a title="65-tfidf-18" href="./nips-2005-Preconditioner_Approximations_for_Probabilistic_Graphical_Models.html">154 nips-2005-Preconditioner Approximations for Probabilistic Graphical Models</a></p>
<p>19 0.065837912 <a title="65-tfidf-19" href="./nips-2005-Fusion_of_Similarity_Data_in_Clustering.html">79 nips-2005-Fusion of Similarity Data in Clustering</a></p>
<p>20 0.064356178 <a title="65-tfidf-20" href="./nips-2005-Robust_Fisher_Discriminant_Analysis.html">166 nips-2005-Robust Fisher Discriminant Analysis</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2005_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.217), (1, -0.097), (2, -0.004), (3, 0.073), (4, -0.128), (5, 0.076), (6, -0.069), (7, -0.099), (8, 0.197), (9, 0.002), (10, -0.192), (11, 0.007), (12, 0.163), (13, -0.003), (14, -0.074), (15, -0.193), (16, -0.124), (17, 0.059), (18, -0.113), (19, -0.041), (20, 0.179), (21, -0.08), (22, 0.028), (23, 0.158), (24, 0.012), (25, -0.055), (26, -0.088), (27, 0.02), (28, -0.064), (29, 0.129), (30, -0.01), (31, 0.009), (32, -0.13), (33, -0.091), (34, 0.198), (35, 0.118), (36, 0.066), (37, 0.093), (38, -0.106), (39, 0.022), (40, -0.015), (41, -0.166), (42, -0.055), (43, 0.107), (44, -0.029), (45, -0.082), (46, -0.03), (47, -0.112), (48, -0.016), (49, -0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.88818002 <a title="65-lsi-1" href="./nips-2005-Estimating_the_wrong_Markov_random_field%3A_Benefits_in_the_computation-limited_setting.html">65 nips-2005-Estimating the wrong Markov random field: Benefits in the computation-limited setting</a></p>
<p>2 0.72026575 <a title="65-lsi-2" href="./nips-2005-Divergences%2C_surrogate_loss_functions_and_experimental_design.html">58 nips-2005-Divergences, surrogate loss functions and experimental design</a></p>
<p>3 0.6471616 <a title="65-lsi-3" href="./nips-2005-Using_%60%60epitomes%27%27_to_model_genetic_diversity%3A_Rational_design_of_HIV_vaccine_cocktails.html">198 nips-2005-Using ``epitomes'' to model genetic diversity: Rational design of HIV vaccine cocktails</a></p>
<p>4 0.46774963 <a title="65-lsi-4" href="./nips-2005-Variational_EM_Algorithms_for_Non-Gaussian_Latent_Variable_Models.html">202 nips-2005-Variational EM Algorithms for Non-Gaussian Latent Variable Models</a></p>
<p>5 0.45355842 <a title="65-lsi-5" href="./nips-2005-A_Theoretical_Analysis_of_Robust_Coding_over_Noisy_Overcomplete_Channels.html">15 nips-2005-A Theoretical Analysis of Robust Coding over Noisy Overcomplete Channels</a></p>
<p>6 0.39887124 <a title="65-lsi-6" href="./nips-2005-Consistency_of_one-class_SVM_and_related_algorithms.html">47 nips-2005-Consistency of one-class SVM and related algorithms</a></p>
<p>7 0.39663973 <a title="65-lsi-7" href="./nips-2005-Generalization_Error_Bounds_for_Aggregation_by_Mirror_Descent_with_Averaging.html">82 nips-2005-Generalization Error Bounds for Aggregation by Mirror Descent with Averaging</a></p>
<p>8 0.37627625 <a title="65-lsi-8" href="./nips-2005-Learning_Influence_among_Interacting_Markov_Chains.html">111 nips-2005-Learning Influence among Interacting Markov Chains</a></p>
<p>9 0.37027541 <a title="65-lsi-9" href="./nips-2005-Convex_Neural_Networks.html">50 nips-2005-Convex Neural Networks</a></p>
<p>10 0.3369852 <a title="65-lsi-10" href="./nips-2005-Factorial_Switching_Kalman_Filters_for_Condition_Monitoring_in_Neonatal_Intensive_Care.html">68 nips-2005-Factorial Switching Kalman Filters for Condition Monitoring in Neonatal Intensive Care</a></p>
<p>11 0.32246324 <a title="65-lsi-11" href="./nips-2005-Non-iterative_Estimation_with_Perturbed_Gaussian_Markov_Processes.html">139 nips-2005-Non-iterative Estimation with Perturbed Gaussian Markov Processes</a></p>
<p>12 0.31413177 <a title="65-lsi-12" href="./nips-2005-Improved_risk_tail_bounds_for_on-line_algorithms.html">95 nips-2005-Improved risk tail bounds for on-line algorithms</a></p>
<p>13 0.30934814 <a title="65-lsi-13" href="./nips-2005-Spectral_Bounds_for_Sparse_PCA%3A_Exact_and_Greedy_Algorithms.html">180 nips-2005-Spectral Bounds for Sparse PCA: Exact and Greedy Algorithms</a></p>
<p>14 0.30585253 <a title="65-lsi-14" href="./nips-2005-Comparing_the_Effects_of_Different_Weight_Distributions_on_Finding_Sparse_Representations.html">43 nips-2005-Comparing the Effects of Different Weight Distributions on Finding Sparse Representations</a></p>
<p>15 0.30375466 <a title="65-lsi-15" href="./nips-2005-Learning_Topology_with_the_Generative_Gaussian_Graph_and_the_EM_Algorithm.html">116 nips-2005-Learning Topology with the Generative Gaussian Graph and the EM Algorithm</a></p>
<p>16 0.2953352 <a title="65-lsi-16" href="./nips-2005-Preconditioner_Approximations_for_Probabilistic_Graphical_Models.html">154 nips-2005-Preconditioner Approximations for Probabilistic Graphical Models</a></p>
<p>17 0.29386905 <a title="65-lsi-17" href="./nips-2005-A_Probabilistic_Interpretation_of_SVMs_with_an_Application_to_Unbalanced_Classification.html">14 nips-2005-A Probabilistic Interpretation of SVMs with an Application to Unbalanced Classification</a></p>
<p>18 0.28943127 <a title="65-lsi-18" href="./nips-2005-Robust_design_of_biological_experiments.html">167 nips-2005-Robust design of biological experiments</a></p>
<p>19 0.28061286 <a title="65-lsi-19" href="./nips-2005-Robust_Fisher_Discriminant_Analysis.html">166 nips-2005-Robust Fisher Discriminant Analysis</a></p>
<p>20 0.27080169 <a title="65-lsi-20" href="./nips-2005-TD%280%29_Leads_to_Better_Policies_than_Approximate_Value_Iteration.html">186 nips-2005-TD(0) Leads to Better Policies than Approximate Value Iteration</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2005_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.074), (12, 0.011), (17, 0.073), (18, 0.016), (54, 0.086), (58, 0.011), (71, 0.128), (87, 0.218), (88, 0.095), (89, 0.065), (92, 0.13)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.78788823 <a title="65-lda-1" href="./nips-2005-Estimating_the_wrong_Markov_random_field%3A_Benefits_in_the_computation-limited_setting.html">65 nips-2005-Estimating the wrong Markov random field: Benefits in the computation-limited setting</a></p>
<p>2 0.72920918 <a title="65-lda-2" href="./nips-2005-Gaussian_Process_Dynamical_Models.html">80 nips-2005-Gaussian Process Dynamical Models</a></p>
<p>3 0.72114962 <a title="65-lda-3" href="./nips-2005-TD%280%29_Leads_to_Better_Policies_than_Approximate_Value_Iteration.html">186 nips-2005-TD(0) Leads to Better Policies than Approximate Value Iteration</a></p>
<p>4 0.72094804 <a title="65-lda-4" href="./nips-2005-The_Role_of_Top-down_and_Bottom-up_Processes_in_Guiding_Eye_Movements_during_Visual_Search.html">193 nips-2005-The Role of Top-down and Bottom-up Processes in Guiding Eye Movements during Visual Search</a></p>
<p>5 0.71275884 <a title="65-lda-5" href="./nips-2005-Preconditioner_Approximations_for_Probabilistic_Graphical_Models.html">154 nips-2005-Preconditioner Approximations for Probabilistic Graphical Models</a></p>
<p>6 0.70985711 <a title="65-lda-6" href="./nips-2005-Generalization_Error_Bounds_for_Aggregation_by_Mirror_Descent_with_Averaging.html">82 nips-2005-Generalization Error Bounds for Aggregation by Mirror Descent with Averaging</a></p>
<p>7 0.70332927 <a title="65-lda-7" href="./nips-2005-Improved_risk_tail_bounds_for_on-line_algorithms.html">95 nips-2005-Improved risk tail bounds for on-line algorithms</a></p>
<p>8 0.69602442 <a title="65-lda-8" href="./nips-2005-Size_Regularized_Cut_for_Data_Clustering.html">177 nips-2005-Size Regularized Cut for Data Clustering</a></p>
<p>9 0.69442755 <a title="65-lda-9" href="./nips-2005-From_Weighted_Classification_to_Policy_Search.html">78 nips-2005-From Weighted Classification to Policy Search</a></p>
<p>10 0.69171083 <a title="65-lda-10" href="./nips-2005-Computing_the_Solution_Path_for_the_Regularized_Support_Vector_Regression.html">44 nips-2005-Computing the Solution Path for the Regularized Support Vector Regression</a></p>
<p>11 0.69084644 <a title="65-lda-11" href="./nips-2005-A_General_and_Efficient_Multiple_Kernel_Learning_Algorithm.html">10 nips-2005-A General and Efficient Multiple Kernel Learning Algorithm</a></p>
<p>12 0.69049656 <a title="65-lda-12" href="./nips-2005-Generalization_to_Unseen_Cases.html">85 nips-2005-Generalization to Unseen Cases</a></p>
<p>13 0.68424904 <a title="65-lda-13" href="./nips-2005-Generalization_error_bounds_for_classifiers_trained_with_interdependent_data.html">83 nips-2005-Generalization error bounds for classifiers trained with interdependent data</a></p>
<p>14 0.68378055 <a title="65-lda-14" href="./nips-2005-Divergences%2C_surrogate_loss_functions_and_experimental_design.html">58 nips-2005-Divergences, surrogate loss functions and experimental design</a></p>
<p>15 0.68338519 <a title="65-lda-15" href="./nips-2005-Spectral_Bounds_for_Sparse_PCA%3A_Exact_and_Greedy_Algorithms.html">180 nips-2005-Spectral Bounds for Sparse PCA: Exact and Greedy Algorithms</a></p>
<p>16 0.68297118 <a title="65-lda-16" href="./nips-2005-Variational_Bayesian_Stochastic_Complexity_of_Mixture_Models.html">201 nips-2005-Variational Bayesian Stochastic Complexity of Mixture Models</a></p>
<p>17 0.68221146 <a title="65-lda-17" href="./nips-2005-Augmented_Rescorla-Wagner_and_Maximum_Likelihood_Estimation.html">32 nips-2005-Augmented Rescorla-Wagner and Maximum Likelihood Estimation</a></p>
<p>18 0.68216884 <a title="65-lda-18" href="./nips-2005-Convex_Neural_Networks.html">50 nips-2005-Convex Neural Networks</a></p>
<p>19 0.68002415 <a title="65-lda-19" href="./nips-2005-Infinite_latent_feature_models_and_the_Indian_buffet_process.html">98 nips-2005-Infinite latent feature models and the Indian buffet process</a></p>
<p>20 0.68000984 <a title="65-lda-20" href="./nips-2005-Selecting_Landmark_Points_for_Sparse_Manifold_Learning.html">172 nips-2005-Selecting Landmark Points for Sparse Manifold Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
