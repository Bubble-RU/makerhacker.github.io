<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>111 nips-2005-Learning Influence among Interacting Markov Chains</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2005" href="../home/nips2005_home.html">nips2005</a> <a title="nips-2005-111" href="#">nips2005-111</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>111 nips-2005-Learning Influence among Interacting Markov Chains</h1>
<br/><p>Source: <a title="nips-2005-111-pdf" href="http://papers.nips.cc/paper/2918-learning-influence-among-interacting-markov-chains.pdf">pdf</a></p><p>Author: Dong Zhang, Daniel Gatica-perez, Samy Bengio, Deb Roy</p><p>Abstract: We present a model that learns the inﬂuence of interacting Markov chains within a team. The proposed model is a dynamic Bayesian network (DBN) with a two-level structure: individual-level and group-level. Individual level models actions of each player, and the group-level models actions of the team as a whole. Experiments on synthetic multi-player games and a multi-party meeting corpus show the effectiveness of the proposed model. 1</p><p>Reference: <a title="nips-2005-111-reference" href="../nips2005_reference/nips-2005-Learning_Influence_among_Interacting_Markov_Chains_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('st', 0.449), ('team', 0.381), ('play', 0.379), ('uent', 0.372), ('audio', 0.198), ('meet', 0.194), ('plsa', 0.178), ('gam', 0.166), ('annot', 0.152), ('langu', 0.135), ('ns', 0.124), ('speak', 0.111), ('par', 0.11), ('particip', 0.11), ('dsts', 0.089), ('individ', 0.086), ('kl', 0.079), ('sil', 0.071), ('diverg', 0.065), ('switch', 0.062)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="111-tfidf-1" href="./nips-2005-Learning_Influence_among_Interacting_Markov_Chains.html">111 nips-2005-Learning Influence among Interacting Markov Chains</a></p>
<p>Author: Dong Zhang, Daniel Gatica-perez, Samy Bengio, Deb Roy</p><p>Abstract: We present a model that learns the inﬂuence of interacting Markov chains within a team. The proposed model is a dynamic Bayesian network (DBN) with a two-level structure: individual-level and group-level. Individual level models actions of each player, and the group-level models actions of the team as a whole. Experiments on synthetic multi-player games and a multi-party meeting corpus show the effectiveness of the proposed model. 1</p><p>2 0.17101334 <a title="111-tfidf-2" href="./nips-2005-Cyclic_Equilibria_in_Markov_Games.html">53 nips-2005-Cyclic Equilibria in Markov Games</a></p>
<p>Author: Martin Zinkevich, Amy Greenwald, Michael L. Littman</p><p>Abstract: Although variants of value iteration have been proposed for ﬁnding Nash or correlated equilibria in general-sum Markov games, these variants have not been shown to be effective in general. In this paper, we demonstrate by construction that existing variants of value iteration cannot ﬁnd stationary equilibrium policies in arbitrary general-sum Markov games. Instead, we propose an alternative interpretation of the output of value iteration based on a new (non-stationary) equilibrium concept that we call “cyclic equilibria.” We prove that value iteration identiﬁes cyclic equilibria in a class of games in which it fails to ﬁnd stationary equilibria. We also demonstrate empirically that value iteration ﬁnds cyclic equilibria in nearly all examples drawn from a random distribution of Markov games. 1</p><p>3 0.1178544 <a title="111-tfidf-3" href="./nips-2005-On_Local_Rewards_and_Scaling_Distributed_Reinforcement_Learning.html">145 nips-2005-On Local Rewards and Scaling Distributed Reinforcement Learning</a></p>
<p>Author: Drew Bagnell, Andrew Y. Ng</p><p>Abstract: We consider the scaling of the number of examples necessary to achieve good performance in distributed, cooperative, multi-agent reinforcement learning, as a function of the the number of agents n. We prove a worstcase lower bound showing that algorithms that rely solely on a global reward signal to learn policies confront a fundamental limit: They require a number of real-world examples that scales roughly linearly in the number of agents. For settings of interest with a very large number of agents, this is impractical. We demonstrate, however, that there is a class of algorithms that, by taking advantage of local reward signals in large distributed Markov Decision Processes, are able to ensure good performance with a number of samples that scales as O(log n). This makes them applicable even in settings with a very large number of agents n. 1</p><p>4 0.099130794 <a title="111-tfidf-4" href="./nips-2005-Factorial_Switching_Kalman_Filters_for_Condition_Monitoring_in_Neonatal_Intensive_Care.html">68 nips-2005-Factorial Switching Kalman Filters for Condition Monitoring in Neonatal Intensive Care</a></p>
<p>Author: Christopher Williams, John Quinn, Neil Mcintosh</p><p>Abstract: The observed physiological dynamics of an infant receiving intensive care are affected by many possible factors, including interventions to the baby, the operation of the monitoring equipment and the state of health. The Factorial Switching Kalman Filter can be used to infer the presence of such factors from a sequence of observations, and to estimate the true values where these observations have been corrupted. We apply this model to clinical time series data and show it to be effective in identifying a number of artifactual and physiological patterns. 1</p><p>5 0.092312984 <a title="111-tfidf-5" href="./nips-2005-Goal-Based_Imitation_as_Probabilistic_Inference_over_Graphical_Models.html">87 nips-2005-Goal-Based Imitation as Probabilistic Inference over Graphical Models</a></p>
<p>Author: Deepak Verma, Rajesh P. Rao</p><p>Abstract: Humans are extremely adept at learning new skills by imitating the actions of others. A progression of imitative abilities has been observed in children, ranging from imitation of simple body movements to goalbased imitation based on inferring intent. In this paper, we show that the problem of goal-based imitation can be formulated as one of inferring goals and selecting actions using a learned probabilistic graphical model of the environment. We ﬁrst describe algorithms for planning actions to achieve a goal state using probabilistic inference. We then describe how planning can be used to bootstrap the learning of goal-dependent policies by utilizing feedback from the environment. The resulting graphical model is then shown to be powerful enough to allow goal-based imitation. Using a simple maze navigation task, we illustrate how an agent can infer the goals of an observed teacher and imitate the teacher even when the goals are uncertain and the demonstration is incomplete.</p><p>6 0.089086927 <a title="111-tfidf-6" href="./nips-2005-Estimating_the_wrong_Markov_random_field%3A_Benefits_in_the_computation-limited_setting.html">65 nips-2005-Estimating the wrong Markov random field: Benefits in the computation-limited setting</a></p>
<p>7 0.083378345 <a title="111-tfidf-7" href="./nips-2005-Learning_Multiple_Related_Tasks_using_Latent_Independent_Component_Analysis.html">113 nips-2005-Learning Multiple Related Tasks using Latent Independent Component Analysis</a></p>
<p>8 0.076356821 <a title="111-tfidf-8" href="./nips-2005-Group_and_Topic_Discovery_from_Relations_and_Their_Attributes.html">89 nips-2005-Group and Topic Discovery from Relations and Their Attributes</a></p>
<p>9 0.076306082 <a title="111-tfidf-9" href="./nips-2005-Bayesian_models_of_human_action_understanding.html">36 nips-2005-Bayesian models of human action understanding</a></p>
<p>10 0.076271519 <a title="111-tfidf-10" href="./nips-2005-Modeling_Neuronal_Interactivity_using_Dynamic_Bayesian_Networks.html">130 nips-2005-Modeling Neuronal Interactivity using Dynamic Bayesian Networks</a></p>
<p>11 0.075199172 <a title="111-tfidf-11" href="./nips-2005-Norepinephrine_and_Neural_Interrupts.html">141 nips-2005-Norepinephrine and Neural Interrupts</a></p>
<p>12 0.069146179 <a title="111-tfidf-12" href="./nips-2005-Oblivious_Equilibrium%3A_A_Mean_Field_Approximation_for_Large-Scale_Dynamic_Games.html">142 nips-2005-Oblivious Equilibrium: A Mean Field Approximation for Large-Scale Dynamic Games</a></p>
<p>13 0.063168891 <a title="111-tfidf-13" href="./nips-2005-Interpolating_between_types_and_tokens_by_estimating_power-law_generators.html">100 nips-2005-Interpolating between types and tokens by estimating power-law generators</a></p>
<p>14 0.05903459 <a title="111-tfidf-14" href="./nips-2005-Searching_for_Character_Models.html">171 nips-2005-Searching for Character Models</a></p>
<p>15 0.057982333 <a title="111-tfidf-15" href="./nips-2005-Learning_vehicular_dynamics%2C_with_application_to_modeling_helicopters.html">120 nips-2005-Learning vehicular dynamics, with application to modeling helicopters</a></p>
<p>16 0.056873213 <a title="111-tfidf-16" href="./nips-2005-Context_as_Filtering.html">48 nips-2005-Context as Filtering</a></p>
<p>17 0.055457927 <a title="111-tfidf-17" href="./nips-2005-The_Curse_of_Highly_Variable_Functions_for_Local_Kernel_Machines.html">190 nips-2005-The Curse of Highly Variable Functions for Local Kernel Machines</a></p>
<p>18 0.051267561 <a title="111-tfidf-18" href="./nips-2005-Temporally_changing_synaptic_plasticity.html">188 nips-2005-Temporally changing synaptic plasticity</a></p>
<p>19 0.049959328 <a title="111-tfidf-19" href="./nips-2005-Policy-Gradient_Methods_for_Planning.html">153 nips-2005-Policy-Gradient Methods for Planning</a></p>
<p>20 0.048815958 <a title="111-tfidf-20" href="./nips-2005-Off-policy_Learning_with_Options_and_Recognizers.html">144 nips-2005-Off-policy Learning with Options and Recognizers</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2005_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.149), (1, -0.01), (2, 0.141), (3, 0.002), (4, 0.011), (5, -0.01), (6, 0.012), (7, -0.105), (8, -0.013), (9, -0.049), (10, -0.018), (11, 0.089), (12, 0.006), (13, -0.117), (14, 0.042), (15, -0.023), (16, -0.009), (17, 0.039), (18, -0.185), (19, 0.113), (20, 0.184), (21, -0.014), (22, -0.069), (23, 0.084), (24, 0.117), (25, 0.132), (26, 0.102), (27, -0.062), (28, -0.065), (29, 0.196), (30, -0.034), (31, 0.052), (32, -0.106), (33, -0.1), (34, -0.005), (35, 0.058), (36, 0.023), (37, 0.199), (38, 0.018), (39, -0.054), (40, -0.037), (41, -0.095), (42, 0.107), (43, 0.06), (44, 0.142), (45, 0.076), (46, -0.048), (47, 0.107), (48, -0.026), (49, -0.068)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97240293 <a title="111-lsi-1" href="./nips-2005-Learning_Influence_among_Interacting_Markov_Chains.html">111 nips-2005-Learning Influence among Interacting Markov Chains</a></p>
<p>Author: Dong Zhang, Daniel Gatica-perez, Samy Bengio, Deb Roy</p><p>Abstract: We present a model that learns the inﬂuence of interacting Markov chains within a team. The proposed model is a dynamic Bayesian network (DBN) with a two-level structure: individual-level and group-level. Individual level models actions of each player, and the group-level models actions of the team as a whole. Experiments on synthetic multi-player games and a multi-party meeting corpus show the effectiveness of the proposed model. 1</p><p>2 0.67686969 <a title="111-lsi-2" href="./nips-2005-Cyclic_Equilibria_in_Markov_Games.html">53 nips-2005-Cyclic Equilibria in Markov Games</a></p>
<p>Author: Martin Zinkevich, Amy Greenwald, Michael L. Littman</p><p>Abstract: Although variants of value iteration have been proposed for ﬁnding Nash or correlated equilibria in general-sum Markov games, these variants have not been shown to be effective in general. In this paper, we demonstrate by construction that existing variants of value iteration cannot ﬁnd stationary equilibrium policies in arbitrary general-sum Markov games. Instead, we propose an alternative interpretation of the output of value iteration based on a new (non-stationary) equilibrium concept that we call “cyclic equilibria.” We prove that value iteration identiﬁes cyclic equilibria in a class of games in which it fails to ﬁnd stationary equilibria. We also demonstrate empirically that value iteration ﬁnds cyclic equilibria in nearly all examples drawn from a random distribution of Markov games. 1</p><p>3 0.63875782 <a title="111-lsi-3" href="./nips-2005-Factorial_Switching_Kalman_Filters_for_Condition_Monitoring_in_Neonatal_Intensive_Care.html">68 nips-2005-Factorial Switching Kalman Filters for Condition Monitoring in Neonatal Intensive Care</a></p>
<p>Author: Christopher Williams, John Quinn, Neil Mcintosh</p><p>Abstract: The observed physiological dynamics of an infant receiving intensive care are affected by many possible factors, including interventions to the baby, the operation of the monitoring equipment and the state of health. The Factorial Switching Kalman Filter can be used to infer the presence of such factors from a sequence of observations, and to estimate the true values where these observations have been corrupted. We apply this model to clinical time series data and show it to be effective in identifying a number of artifactual and physiological patterns. 1</p><p>4 0.55322397 <a title="111-lsi-4" href="./nips-2005-Oblivious_Equilibrium%3A_A_Mean_Field_Approximation_for_Large-Scale_Dynamic_Games.html">142 nips-2005-Oblivious Equilibrium: A Mean Field Approximation for Large-Scale Dynamic Games</a></p>
<p>Author: Gabriel Y. Weintraub, Lanier Benkard, Benjamin Van Roy</p><p>Abstract: We propose a mean-ﬁeld approximation that dramatically reduces the computational complexity of solving stochastic dynamic games. We provide conditions that guarantee our method approximates an equilibrium as the number of agents grow. We then derive a performance bound to assess how well the approximation performs for any given number of agents. We apply our method to an important class of problems in applied microeconomics. We show with numerical experiments that we are able to greatly expand the set of economic problems that can be analyzed computationally. 1</p><p>5 0.40572655 <a title="111-lsi-5" href="./nips-2005-Using_%60%60epitomes%27%27_to_model_genetic_diversity%3A_Rational_design_of_HIV_vaccine_cocktails.html">198 nips-2005-Using ``epitomes'' to model genetic diversity: Rational design of HIV vaccine cocktails</a></p>
<p>Author: Nebojsa Jojic, Vladimir Jojic, Christopher Meek, David Heckerman, Brendan J. Frey</p><p>Abstract: We introduce a new model of genetic diversity which summarizes a large input dataset into an epitome, a short sequence or a small set of short sequences of probability distributions capturing many overlapping subsequences from the dataset. The epitome as a representation has already been used in modeling real-valued signals, such as images and audio. The discrete sequence model we introduce in this paper targets applications in genetics, from multiple alignment to recombination and mutation inference. In our experiments, we concentrate on modeling the diversity of HIV where the epitome emerges as a natural model for producing relatively small vaccines covering a large number of immune system targets known as epitopes. Our experiments show that the epitome includes more epitopes than other vaccine designs of similar length, including cocktails of consensus strains, phylogenetic tree centers, and observed strains. We also discuss epitome designs that take into account uncertainty about Tcell cross reactivity and epitope presentation. In our experiments, we ﬁnd that vaccine optimization is fairly robust to these uncertainties. 1</p><p>6 0.38610482 <a title="111-lsi-6" href="./nips-2005-Modeling_Neuronal_Interactivity_using_Dynamic_Bayesian_Networks.html">130 nips-2005-Modeling Neuronal Interactivity using Dynamic Bayesian Networks</a></p>
<p>7 0.37962174 <a title="111-lsi-7" href="./nips-2005-Group_and_Topic_Discovery_from_Relations_and_Their_Attributes.html">89 nips-2005-Group and Topic Discovery from Relations and Their Attributes</a></p>
<p>8 0.36285013 <a title="111-lsi-8" href="./nips-2005-Searching_for_Character_Models.html">171 nips-2005-Searching for Character Models</a></p>
<p>9 0.35456607 <a title="111-lsi-9" href="./nips-2005-Estimating_the_wrong_Markov_random_field%3A_Benefits_in_the_computation-limited_setting.html">65 nips-2005-Estimating the wrong Markov random field: Benefits in the computation-limited setting</a></p>
<p>10 0.33809811 <a title="111-lsi-10" href="./nips-2005-Separation_of_Music_Signals_by_Harmonic_Structure_Modeling.html">174 nips-2005-Separation of Music Signals by Harmonic Structure Modeling</a></p>
<p>11 0.33354777 <a title="111-lsi-11" href="./nips-2005-Learning_vehicular_dynamics%2C_with_application_to_modeling_helicopters.html">120 nips-2005-Learning vehicular dynamics, with application to modeling helicopters</a></p>
<p>12 0.32565641 <a title="111-lsi-12" href="./nips-2005-On_Local_Rewards_and_Scaling_Distributed_Reinforcement_Learning.html">145 nips-2005-On Local Rewards and Scaling Distributed Reinforcement Learning</a></p>
<p>13 0.31546828 <a title="111-lsi-13" href="./nips-2005-Goal-Based_Imitation_as_Probabilistic_Inference_over_Graphical_Models.html">87 nips-2005-Goal-Based Imitation as Probabilistic Inference over Graphical Models</a></p>
<p>14 0.31491217 <a title="111-lsi-14" href="./nips-2005-Interpolating_between_types_and_tokens_by_estimating_power-law_generators.html">100 nips-2005-Interpolating between types and tokens by estimating power-law generators</a></p>
<p>15 0.31476343 <a title="111-lsi-15" href="./nips-2005-Efficient_Estimation_of_OOMs.html">62 nips-2005-Efficient Estimation of OOMs</a></p>
<p>16 0.30716714 <a title="111-lsi-16" href="./nips-2005-Bayesian_models_of_human_action_understanding.html">36 nips-2005-Bayesian models of human action understanding</a></p>
<p>17 0.29916978 <a title="111-lsi-17" href="./nips-2005-Bayesian_Surprise_Attracts_Human_Attention.html">34 nips-2005-Bayesian Surprise Attracts Human Attention</a></p>
<p>18 0.28308302 <a title="111-lsi-18" href="./nips-2005-Bayesian_model_learning_in_human_visual_perception.html">35 nips-2005-Bayesian model learning in human visual perception</a></p>
<p>19 0.26874477 <a title="111-lsi-19" href="./nips-2005-Context_as_Filtering.html">48 nips-2005-Context as Filtering</a></p>
<p>20 0.25557011 <a title="111-lsi-20" href="./nips-2005-Norepinephrine_and_Neural_Interrupts.html">141 nips-2005-Norepinephrine and Neural Interrupts</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2005_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.07), (9, 0.015), (12, 0.021), (17, 0.011), (39, 0.31), (44, 0.018), (54, 0.015), (69, 0.019), (71, 0.107), (88, 0.109), (89, 0.045), (92, 0.142)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.74463177 <a title="111-lda-1" href="./nips-2005-Learning_Influence_among_Interacting_Markov_Chains.html">111 nips-2005-Learning Influence among Interacting Markov Chains</a></p>
<p>Author: Dong Zhang, Daniel Gatica-perez, Samy Bengio, Deb Roy</p><p>Abstract: We present a model that learns the inﬂuence of interacting Markov chains within a team. The proposed model is a dynamic Bayesian network (DBN) with a two-level structure: individual-level and group-level. Individual level models actions of each player, and the group-level models actions of the team as a whole. Experiments on synthetic multi-player games and a multi-party meeting corpus show the effectiveness of the proposed model. 1</p><p>2 0.56178999 <a title="111-lda-2" href="./nips-2005-Size_Regularized_Cut_for_Data_Clustering.html">177 nips-2005-Size Regularized Cut for Data Clustering</a></p>
<p>Author: Yixin Chen, Ya Zhang, Xiang Ji</p><p>Abstract: We present a novel spectral clustering method that enables users to incorporate prior knowledge of the size of clusters into the clustering process. The cost function, which is named size regularized cut (SRcut), is deﬁned as the sum of the inter-cluster similarity and a regularization term measuring the relative size of two clusters. Finding a partition of the data set to minimize SRcut is proved to be NP-complete. An approximation algorithm is proposed to solve a relaxed version of the optimization problem as an eigenvalue problem. Evaluations over different data sets demonstrate that the method is not sensitive to outliers and performs better than normalized cut. 1</p><p>3 0.56101435 <a title="111-lda-3" href="./nips-2005-Principles_of_real-time_computing_with_feedback_applied_to_cortical_microcircuit_models.html">157 nips-2005-Principles of real-time computing with feedback applied to cortical microcircuit models</a></p>
<p>Author: Wolfgang Maass, Prashant Joshi, Eduardo D. Sontag</p><p>Abstract: The network topology of neurons in the brain exhibits an abundance of feedback connections, but the computational function of these feedback connections is largely unknown. We present a computational theory that characterizes the gain in computational power achieved through feedback in dynamical systems with fading memory. It implies that many such systems acquire through feedback universal computational capabilities for analog computing with a non-fading memory. In particular, we show that feedback enables such systems to process time-varying input streams in diverse ways according to rules that are implemented through internal states of the dynamical system. In contrast to previous attractor-based computational models for neural networks, these ﬂexible internal states are high-dimensional attractors of the circuit dynamics, that still allow the circuit state to absorb new information from online input streams. In this way one arrives at novel models for working memory, integration of evidence, and reward expectation in cortical circuits. We show that they are applicable to circuits of conductance-based Hodgkin-Huxley (HH) neurons with high levels of noise that reﬂect experimental data on invivo conditions. 1</p><p>4 0.56021345 <a title="111-lda-4" href="./nips-2005-From_Weighted_Classification_to_Policy_Search.html">78 nips-2005-From Weighted Classification to Policy Search</a></p>
<p>Author: Doron Blatt, Alfred O. Hero</p><p>Abstract: This paper proposes an algorithm to convert a T -stage stochastic decision problem with a continuous state space to a sequence of supervised learning problems. The optimization problem associated with the trajectory tree and random trajectory methods of Kearns, Mansour, and Ng, 2000, is solved using the Gauss-Seidel method. The algorithm breaks a multistage reinforcement learning problem into a sequence of single-stage reinforcement learning subproblems, each of which is solved via an exact reduction to a weighted-classiﬁcation problem that can be solved using off-the-self methods. Thus the algorithm converts a reinforcement learning problem into simpler supervised learning subproblems. It is shown that the method converges in a ﬁnite number of steps to a solution that cannot be further improved by componentwise optimization. The implication of the proposed algorithm is that a plethora of classiﬁcation methods can be applied to ﬁnd policies in the reinforcement learning problem. 1</p><p>5 0.55987149 <a title="111-lda-5" href="./nips-2005-Fast_Krylov_Methods_for_N-Body_Learning.html">71 nips-2005-Fast Krylov Methods for N-Body Learning</a></p>
<p>Author: Nando D. Freitas, Yang Wang, Maryam Mahdaviani, Dustin Lang</p><p>Abstract: This paper addresses the issue of numerical computation in machine learning domains based on similarity metrics, such as kernel methods, spectral techniques and Gaussian processes. It presents a general solution strategy based on Krylov subspace iteration and fast N-body learning methods. The experiments show signiﬁcant gains in computation and storage on datasets arising in image segmentation, object detection and dimensionality reduction. The paper also presents theoretical bounds on the stability of these methods.</p><p>6 0.55795383 <a title="111-lda-6" href="./nips-2005-Dynamic_Social_Network_Analysis_using_Latent_Space_Models.html">60 nips-2005-Dynamic Social Network Analysis using Latent Space Models</a></p>
<p>7 0.55787009 <a title="111-lda-7" href="./nips-2005-Noise_and_the_two-thirds_power_Law.html">136 nips-2005-Noise and the two-thirds power Law</a></p>
<p>8 0.55777645 <a title="111-lda-8" href="./nips-2005-Variable_KD-Tree_Algorithms_for_Spatial_Pattern_Search_and_Discovery.html">200 nips-2005-Variable KD-Tree Algorithms for Spatial Pattern Search and Discovery</a></p>
<p>9 0.55632126 <a title="111-lda-9" href="./nips-2005-A_Hierarchical_Compositional_System_for_Rapid_Object_Detection.html">11 nips-2005-A Hierarchical Compositional System for Rapid Object Detection</a></p>
<p>10 0.55539298 <a title="111-lda-10" href="./nips-2005-Off-policy_Learning_with_Options_and_Recognizers.html">144 nips-2005-Off-policy Learning with Options and Recognizers</a></p>
<p>11 0.55525887 <a title="111-lda-11" href="./nips-2005-Predicting_EMG_Data_from_M1_Neurons_with_Variational_Bayesian_Least_Squares.html">155 nips-2005-Predicting EMG Data from M1 Neurons with Variational Bayesian Least Squares</a></p>
<p>12 0.55346543 <a title="111-lda-12" href="./nips-2005-A_Probabilistic_Approach_for_Optimizing_Spectral_Clustering.html">13 nips-2005-A Probabilistic Approach for Optimizing Spectral Clustering</a></p>
<p>13 0.55338961 <a title="111-lda-13" href="./nips-2005-Multiple_Instance_Boosting_for_Object_Detection.html">131 nips-2005-Multiple Instance Boosting for Object Detection</a></p>
<p>14 0.55302763 <a title="111-lda-14" href="./nips-2005-Message_passing_for_task_redistribution_on_sparse_graphs.html">125 nips-2005-Message passing for task redistribution on sparse graphs</a></p>
<p>15 0.55180442 <a title="111-lda-15" href="./nips-2005-Efficient_Estimation_of_OOMs.html">62 nips-2005-Efficient Estimation of OOMs</a></p>
<p>16 0.55132806 <a title="111-lda-16" href="./nips-2005-A_Connectionist_Model_for_Constructive_Modal_Reasoning.html">6 nips-2005-A Connectionist Model for Constructive Modal Reasoning</a></p>
<p>17 0.55127573 <a title="111-lda-17" href="./nips-2005-Logic_and_MRF_Circuitry_for_Labeling_Occluding_and_Thinline_Visual_Contours.html">122 nips-2005-Logic and MRF Circuitry for Labeling Occluding and Thinline Visual Contours</a></p>
<p>18 0.54999375 <a title="111-lda-18" href="./nips-2005-Extracting_Dynamical_Structure_Embedded_in_Neural_Activity.html">67 nips-2005-Extracting Dynamical Structure Embedded in Neural Activity</a></p>
<p>19 0.54982769 <a title="111-lda-19" href="./nips-2005-Ideal_Observers_for_Detecting_Motion%3A_Correspondence_Noise.html">93 nips-2005-Ideal Observers for Detecting Motion: Correspondence Noise</a></p>
<p>20 0.54966456 <a title="111-lda-20" href="./nips-2005-A_Computational_Model_of_Eye_Movements_during_Object_Class_Detection.html">5 nips-2005-A Computational Model of Eye Movements during Object Class Detection</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
