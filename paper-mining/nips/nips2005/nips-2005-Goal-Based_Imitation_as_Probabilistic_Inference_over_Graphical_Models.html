<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>87 nips-2005-Goal-Based Imitation as Probabilistic Inference over Graphical Models</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2005" href="../home/nips2005_home.html">nips2005</a> <a title="nips-2005-87" href="#">nips2005-87</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>87 nips-2005-Goal-Based Imitation as Probabilistic Inference over Graphical Models</h1>
<br/><p>Source: <a title="nips-2005-87-pdf" href="http://papers.nips.cc/paper/2956-goal-based-imitation-as-probabilistic-inference-over-graphical-models.pdf">pdf</a></p><p>Author: Deepak Verma, Rajesh P. Rao</p><p>Abstract: Humans are extremely adept at learning new skills by imitating the actions of others. A progression of imitative abilities has been observed in children, ranging from imitation of simple body movements to goalbased imitation based on inferring intent. In this paper, we show that the problem of goal-based imitation can be formulated as one of inferring goals and selecting actions using a learned probabilistic graphical model of the environment. We ﬁrst describe algorithms for planning actions to achieve a goal state using probabilistic inference. We then describe how planning can be used to bootstrap the learning of goal-dependent policies by utilizing feedback from the environment. The resulting graphical model is then shown to be powerful enough to allow goal-based imitation. Using a simple maze navigation task, we illustrate how an agent can infer the goals of an observed teacher and imitate the teacher even when the goals are uncertain and the demonstration is incomplete.</p><p>Reference: <a title="nips-2005-87-reference" href="../nips2005_reference/nips-2005-Goal-Based_Imitation_as_Probabilistic_Inference_over_Graphical_Models_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('imit', 0.685), ('teach', 0.331), ('policy', 0.3), ('goal', 0.205), ('mpe', 0.168), ('st', 0.146), ('maz', 0.138), ('plan', 0.137), ('ag', 0.13), ('rt', 0.11), ('gt', 0.11), ('inf', 0.101), ('reach', 0.099), ('execut', 0.086), ('pomdp', 0.077), ('sa', 0.073), ('mdp', 0.066), ('graph', 0.065), ('act', 0.065), ('robot', 0.063)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000006 <a title="87-tfidf-1" href="./nips-2005-Goal-Based_Imitation_as_Probabilistic_Inference_over_Graphical_Models.html">87 nips-2005-Goal-Based Imitation as Probabilistic Inference over Graphical Models</a></p>
<p>Author: Deepak Verma, Rajesh P. Rao</p><p>Abstract: Humans are extremely adept at learning new skills by imitating the actions of others. A progression of imitative abilities has been observed in children, ranging from imitation of simple body movements to goalbased imitation based on inferring intent. In this paper, we show that the problem of goal-based imitation can be formulated as one of inferring goals and selecting actions using a learned probabilistic graphical model of the environment. We ﬁrst describe algorithms for planning actions to achieve a goal state using probabilistic inference. We then describe how planning can be used to bootstrap the learning of goal-dependent policies by utilizing feedback from the environment. The resulting graphical model is then shown to be powerful enough to allow goal-based imitation. Using a simple maze navigation task, we illustrate how an agent can infer the goals of an observed teacher and imitate the teacher even when the goals are uncertain and the demonstration is incomplete.</p><p>2 0.29899552 <a title="87-tfidf-2" href="./nips-2005-Bayesian_models_of_human_action_understanding.html">36 nips-2005-Bayesian models of human action understanding</a></p>
<p>Author: Chris Baker, Rebecca Saxe, Joshua B. Tenenbaum</p><p>Abstract: We present a Bayesian framework for explaining how people reason about and predict the actions of an intentional agent, based on observing its behavior. Action-understanding is cast as a problem of inverting a probabilistic generative model, which assumes that agents tend to act rationally in order to achieve their goals given the constraints of their environment. Working in a simple sprite-world domain, we show how this model can be used to infer the goal of an agent and predict how the agent will act in novel situations or when environmental constraints change. The model provides a qualitative account of several kinds of inferences that preverbal infants have been shown to perform, and also ﬁts quantitative predictions that adult observers make in a new experiment.</p><p>3 0.28780049 <a title="87-tfidf-3" href="./nips-2005-Learning_Shared_Latent_Structure_for_Image_Synthesis_and_Robotic_Imitation.html">115 nips-2005-Learning Shared Latent Structure for Image Synthesis and Robotic Imitation</a></p>
<p>Author: Aaron Shon, Keith Grochow, Aaron Hertzmann, Rajesh P. Rao</p><p>Abstract: We propose an algorithm that uses Gaussian process regression to learn common hidden structure shared between corresponding sets of heterogenous observations. The observation spaces are linked via a single, reduced-dimensionality latent variable space. We present results from two datasets demonstrating the algorithms’s ability to synthesize novel data from learned correspondences. We ﬁrst show that the method can learn the nonlinear mapping between corresponding views of objects, ﬁlling in missing data as needed to synthesize novel views. We then show that the method can learn a mapping between human degrees of freedom and robotic degrees of freedom for a humanoid robot, allowing robotic imitation of human poses from motion capture data. 1</p><p>4 0.265194 <a title="87-tfidf-4" href="./nips-2005-From_Weighted_Classification_to_Policy_Search.html">78 nips-2005-From Weighted Classification to Policy Search</a></p>
<p>Author: Doron Blatt, Alfred O. Hero</p><p>Abstract: This paper proposes an algorithm to convert a T -stage stochastic decision problem with a continuous state space to a sequence of supervised learning problems. The optimization problem associated with the trajectory tree and random trajectory methods of Kearns, Mansour, and Ng, 2000, is solved using the Gauss-Seidel method. The algorithm breaks a multistage reinforcement learning problem into a sequence of single-stage reinforcement learning subproblems, each of which is solved via an exact reduction to a weighted-classiﬁcation problem that can be solved using off-the-self methods. Thus the algorithm converts a reinforcement learning problem into simpler supervised learning subproblems. It is shown that the method converges in a ﬁnite number of steps to a solution that cannot be further improved by componentwise optimization. The implication of the proposed algorithm is that a plethora of classiﬁcation methods can be applied to ﬁnd policies in the reinforcement learning problem. 1</p><p>5 0.26005322 <a title="87-tfidf-5" href="./nips-2005-Policy-Gradient_Methods_for_Planning.html">153 nips-2005-Policy-Gradient Methods for Planning</a></p>
<p>Author: Douglas Aberdeen</p><p>Abstract: Probabilistic temporal planning attempts to ﬁnd good policies for acting in domains with concurrent durative tasks, multiple uncertain outcomes, and limited resources. These domains are typically modelled as Markov decision problems and solved using dynamic programming methods. This paper demonstrates the application of reinforcement learning — in the form of a policy-gradient method — to these domains. Our emphasis is large domains that are infeasible for dynamic programming. Our approach is to construct simple policies, or agents, for each planning task. The result is a general probabilistic temporal planner, named the Factored Policy-Gradient Planner (FPG-Planner), which can handle hundreds of tasks, optimising for probability of success, duration, and resource use. 1</p><p>6 0.23263742 <a title="87-tfidf-6" href="./nips-2005-Off-policy_Learning_with_Options_and_Recognizers.html">144 nips-2005-Off-policy Learning with Options and Recognizers</a></p>
<p>7 0.20184958 <a title="87-tfidf-7" href="./nips-2005-On_Local_Rewards_and_Scaling_Distributed_Reinforcement_Learning.html">145 nips-2005-On Local Rewards and Scaling Distributed Reinforcement Learning</a></p>
<p>8 0.15344167 <a title="87-tfidf-8" href="./nips-2005-TD%280%29_Leads_to_Better_Policies_than_Approximate_Value_Iteration.html">186 nips-2005-TD(0) Leads to Better Policies than Approximate Value Iteration</a></p>
<p>9 0.12351132 <a title="87-tfidf-9" href="./nips-2005-Fast_Online_Policy_Gradient_Learning_with_SMD_Gain_Vector_Adaptation.html">72 nips-2005-Fast Online Policy Gradient Learning with SMD Gain Vector Adaptation</a></p>
<p>10 0.10283072 <a title="87-tfidf-10" href="./nips-2005-Temporal_Abstraction_in_Temporal-difference_Networks.html">187 nips-2005-Temporal Abstraction in Temporal-difference Networks</a></p>
<p>11 0.10228412 <a title="87-tfidf-11" href="./nips-2005-Oblivious_Equilibrium%3A_A_Mean_Field_Approximation_for_Large-Scale_Dynamic_Games.html">142 nips-2005-Oblivious Equilibrium: A Mean Field Approximation for Large-Scale Dynamic Games</a></p>
<p>12 0.092312984 <a title="87-tfidf-12" href="./nips-2005-Learning_Influence_among_Interacting_Markov_Chains.html">111 nips-2005-Learning Influence among Interacting Markov Chains</a></p>
<p>13 0.090288647 <a title="87-tfidf-13" href="./nips-2005-Value_Function_Approximation_with_Diffusion_Wavelets_and_Laplacian_Eigenfunctions.html">199 nips-2005-Value Function Approximation with Diffusion Wavelets and Laplacian Eigenfunctions</a></p>
<p>14 0.081947878 <a title="87-tfidf-14" href="./nips-2005-Cyclic_Equilibria_in_Markov_Games.html">53 nips-2005-Cyclic Equilibria in Markov Games</a></p>
<p>15 0.071049929 <a title="87-tfidf-15" href="./nips-2005-Learning_to_Control_an_Octopus_Arm_with_Gaussian_Process_Temporal_Difference_Methods.html">119 nips-2005-Learning to Control an Octopus Arm with Gaussian Process Temporal Difference Methods</a></p>
<p>16 0.063924171 <a title="87-tfidf-16" href="./nips-2005-Online_Discovery_and_Learning_of_Predictive_State_Representations.html">148 nips-2005-Online Discovery and Learning of Predictive State Representations</a></p>
<p>17 0.061419874 <a title="87-tfidf-17" href="./nips-2005-Noise_and_the_two-thirds_power_Law.html">136 nips-2005-Noise and the two-thirds power Law</a></p>
<p>18 0.058874723 <a title="87-tfidf-18" href="./nips-2005-Extracting_Dynamical_Structure_Embedded_in_Neural_Activity.html">67 nips-2005-Extracting Dynamical Structure Embedded in Neural Activity</a></p>
<p>19 0.058435138 <a title="87-tfidf-19" href="./nips-2005-Modeling_Neuronal_Interactivity_using_Dynamic_Bayesian_Networks.html">130 nips-2005-Modeling Neuronal Interactivity using Dynamic Bayesian Networks</a></p>
<p>20 0.057761211 <a title="87-tfidf-20" href="./nips-2005-Group_and_Topic_Discovery_from_Relations_and_Their_Attributes.html">89 nips-2005-Group and Topic Discovery from Relations and Their Attributes</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2005_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.182), (1, -0.027), (2, 0.448), (3, 0.105), (4, 0.076), (5, -0.092), (6, 0.105), (7, 0.002), (8, -0.068), (9, -0.025), (10, -0.01), (11, -0.052), (12, 0.084), (13, -0.006), (14, -0.067), (15, 0.039), (16, 0.051), (17, -0.013), (18, -0.131), (19, 0.082), (20, 0.121), (21, 0.002), (22, -0.03), (23, -0.112), (24, -0.01), (25, 0.093), (26, -0.083), (27, -0.05), (28, 0.017), (29, -0.092), (30, -0.059), (31, 0.034), (32, 0.043), (33, -0.002), (34, 0.18), (35, 0.071), (36, 0.082), (37, -0.126), (38, 0.055), (39, 0.059), (40, 0.041), (41, 0.027), (42, 0.011), (43, 0.048), (44, -0.048), (45, -0.045), (46, -0.126), (47, -0.028), (48, -0.127), (49, -0.07)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9455961 <a title="87-lsi-1" href="./nips-2005-Goal-Based_Imitation_as_Probabilistic_Inference_over_Graphical_Models.html">87 nips-2005-Goal-Based Imitation as Probabilistic Inference over Graphical Models</a></p>
<p>Author: Deepak Verma, Rajesh P. Rao</p><p>Abstract: Humans are extremely adept at learning new skills by imitating the actions of others. A progression of imitative abilities has been observed in children, ranging from imitation of simple body movements to goalbased imitation based on inferring intent. In this paper, we show that the problem of goal-based imitation can be formulated as one of inferring goals and selecting actions using a learned probabilistic graphical model of the environment. We ﬁrst describe algorithms for planning actions to achieve a goal state using probabilistic inference. We then describe how planning can be used to bootstrap the learning of goal-dependent policies by utilizing feedback from the environment. The resulting graphical model is then shown to be powerful enough to allow goal-based imitation. Using a simple maze navigation task, we illustrate how an agent can infer the goals of an observed teacher and imitate the teacher even when the goals are uncertain and the demonstration is incomplete.</p><p>2 0.75294173 <a title="87-lsi-2" href="./nips-2005-Bayesian_models_of_human_action_understanding.html">36 nips-2005-Bayesian models of human action understanding</a></p>
<p>Author: Chris Baker, Rebecca Saxe, Joshua B. Tenenbaum</p><p>Abstract: We present a Bayesian framework for explaining how people reason about and predict the actions of an intentional agent, based on observing its behavior. Action-understanding is cast as a problem of inverting a probabilistic generative model, which assumes that agents tend to act rationally in order to achieve their goals given the constraints of their environment. Working in a simple sprite-world domain, we show how this model can be used to infer the goal of an agent and predict how the agent will act in novel situations or when environmental constraints change. The model provides a qualitative account of several kinds of inferences that preverbal infants have been shown to perform, and also ﬁts quantitative predictions that adult observers make in a new experiment.</p><p>3 0.67801398 <a title="87-lsi-3" href="./nips-2005-Policy-Gradient_Methods_for_Planning.html">153 nips-2005-Policy-Gradient Methods for Planning</a></p>
<p>Author: Douglas Aberdeen</p><p>Abstract: Probabilistic temporal planning attempts to ﬁnd good policies for acting in domains with concurrent durative tasks, multiple uncertain outcomes, and limited resources. These domains are typically modelled as Markov decision problems and solved using dynamic programming methods. This paper demonstrates the application of reinforcement learning — in the form of a policy-gradient method — to these domains. Our emphasis is large domains that are infeasible for dynamic programming. Our approach is to construct simple policies, or agents, for each planning task. The result is a general probabilistic temporal planner, named the Factored Policy-Gradient Planner (FPG-Planner), which can handle hundreds of tasks, optimising for probability of success, duration, and resource use. 1</p><p>4 0.60290492 <a title="87-lsi-4" href="./nips-2005-On_Local_Rewards_and_Scaling_Distributed_Reinforcement_Learning.html">145 nips-2005-On Local Rewards and Scaling Distributed Reinforcement Learning</a></p>
<p>Author: Drew Bagnell, Andrew Y. Ng</p><p>Abstract: We consider the scaling of the number of examples necessary to achieve good performance in distributed, cooperative, multi-agent reinforcement learning, as a function of the the number of agents n. We prove a worstcase lower bound showing that algorithms that rely solely on a global reward signal to learn policies confront a fundamental limit: They require a number of real-world examples that scales roughly linearly in the number of agents. For settings of interest with a very large number of agents, this is impractical. We demonstrate, however, that there is a class of algorithms that, by taking advantage of local reward signals in large distributed Markov Decision Processes, are able to ensure good performance with a number of samples that scales as O(log n). This makes them applicable even in settings with a very large number of agents n. 1</p><p>5 0.541637 <a title="87-lsi-5" href="./nips-2005-Learning_Shared_Latent_Structure_for_Image_Synthesis_and_Robotic_Imitation.html">115 nips-2005-Learning Shared Latent Structure for Image Synthesis and Robotic Imitation</a></p>
<p>Author: Aaron Shon, Keith Grochow, Aaron Hertzmann, Rajesh P. Rao</p><p>Abstract: We propose an algorithm that uses Gaussian process regression to learn common hidden structure shared between corresponding sets of heterogenous observations. The observation spaces are linked via a single, reduced-dimensionality latent variable space. We present results from two datasets demonstrating the algorithms’s ability to synthesize novel data from learned correspondences. We ﬁrst show that the method can learn the nonlinear mapping between corresponding views of objects, ﬁlling in missing data as needed to synthesize novel views. We then show that the method can learn a mapping between human degrees of freedom and robotic degrees of freedom for a humanoid robot, allowing robotic imitation of human poses from motion capture data. 1</p><p>6 0.53963834 <a title="87-lsi-6" href="./nips-2005-Off-policy_Learning_with_Options_and_Recognizers.html">144 nips-2005-Off-policy Learning with Options and Recognizers</a></p>
<p>7 0.49469918 <a title="87-lsi-7" href="./nips-2005-From_Weighted_Classification_to_Policy_Search.html">78 nips-2005-From Weighted Classification to Policy Search</a></p>
<p>8 0.47176933 <a title="87-lsi-8" href="./nips-2005-Learning_to_Control_an_Octopus_Arm_with_Gaussian_Process_Temporal_Difference_Methods.html">119 nips-2005-Learning to Control an Octopus Arm with Gaussian Process Temporal Difference Methods</a></p>
<p>9 0.44596344 <a title="87-lsi-9" href="./nips-2005-Temporal_Abstraction_in_Temporal-difference_Networks.html">187 nips-2005-Temporal Abstraction in Temporal-difference Networks</a></p>
<p>10 0.4086836 <a title="87-lsi-10" href="./nips-2005-Oblivious_Equilibrium%3A_A_Mean_Field_Approximation_for_Large-Scale_Dynamic_Games.html">142 nips-2005-Oblivious Equilibrium: A Mean Field Approximation for Large-Scale Dynamic Games</a></p>
<p>11 0.39396814 <a title="87-lsi-11" href="./nips-2005-Fast_Online_Policy_Gradient_Learning_with_SMD_Gain_Vector_Adaptation.html">72 nips-2005-Fast Online Policy Gradient Learning with SMD Gain Vector Adaptation</a></p>
<p>12 0.36229989 <a title="87-lsi-12" href="./nips-2005-Fast_biped_walking_with_a_reflexive_controller_and_real-time_policy_searching.html">73 nips-2005-Fast biped walking with a reflexive controller and real-time policy searching</a></p>
<p>13 0.35996416 <a title="87-lsi-13" href="./nips-2005-TD%280%29_Leads_to_Better_Policies_than_Approximate_Value_Iteration.html">186 nips-2005-TD(0) Leads to Better Policies than Approximate Value Iteration</a></p>
<p>14 0.34809896 <a title="87-lsi-14" href="./nips-2005-Bayesian_model_learning_in_human_visual_perception.html">35 nips-2005-Bayesian model learning in human visual perception</a></p>
<p>15 0.33788487 <a title="87-lsi-15" href="./nips-2005-Off-Road_Obstacle_Avoidance_through_End-to-End_Learning.html">143 nips-2005-Off-Road Obstacle Avoidance through End-to-End Learning</a></p>
<p>16 0.2959615 <a title="87-lsi-16" href="./nips-2005-Factorial_Switching_Kalman_Filters_for_Condition_Monitoring_in_Neonatal_Intensive_Care.html">68 nips-2005-Factorial Switching Kalman Filters for Condition Monitoring in Neonatal Intensive Care</a></p>
<p>17 0.28779083 <a title="87-lsi-17" href="./nips-2005-Learning_Influence_among_Interacting_Markov_Chains.html">111 nips-2005-Learning Influence among Interacting Markov Chains</a></p>
<p>18 0.28292704 <a title="87-lsi-18" href="./nips-2005-Prediction_and_Change_Detection.html">156 nips-2005-Prediction and Change Detection</a></p>
<p>19 0.2779434 <a title="87-lsi-19" href="./nips-2005-Cyclic_Equilibria_in_Markov_Games.html">53 nips-2005-Cyclic Equilibria in Markov Games</a></p>
<p>20 0.27302828 <a title="87-lsi-20" href="./nips-2005-Value_Function_Approximation_with_Diffusion_Wavelets_and_Laplacian_Eigenfunctions.html">199 nips-2005-Value Function Approximation with Diffusion Wavelets and Laplacian Eigenfunctions</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2005_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.059), (12, 0.042), (17, 0.015), (54, 0.01), (71, 0.085), (74, 0.014), (88, 0.051), (89, 0.026), (92, 0.593)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.97671986 <a title="87-lda-1" href="./nips-2005-A_Cortically-Plausible_Inverse_Problem_Solving_Method_Applied_to_Recognizing_Static_and_Kinematic_3D_Objects.html">7 nips-2005-A Cortically-Plausible Inverse Problem Solving Method Applied to Recognizing Static and Kinematic 3D Objects</a></p>
<p>Author: David Arathorn</p><p>Abstract: Recent neurophysiological evidence suggests the ability to interpret biological motion is facilitated by a neuronal</p><p>2 0.96952534 <a title="87-lda-2" href="./nips-2005-Active_Bidirectional_Coupling_in_a_Cochlear_Chip.html">17 nips-2005-Active Bidirectional Coupling in a Cochlear Chip</a></p>
<p>Author: Bo Wen, Kwabena A. Boahen</p><p>Abstract: We present a novel cochlear model implemented in analog very large scale integration (VLSI) technology that emulates nonlinear active cochlear behavior. This silicon cochlea includes outer hair cell (OHC) electromotility through active bidirectional coupling (ABC), a mechanism we proposed in which OHC motile forces, through the microanatomical organization of the organ of Corti, realize the cochlear ampliﬁer. Our chip measurements demonstrate that frequency responses become larger and more sharply tuned when ABC is turned on; the degree of the enhancement decreases with input intensity as ABC includes saturation of OHC forces. 1 Silicon Cochleae Cochlear models, mathematical and physical, with the shared goal of emulating nonlinear active cochlear behavior, shed light on how the cochlea works if based on cochlear micromechanics. Among the modeling efforts, silicon cochleae have promise in meeting the need for real-time performance and low power consumption. Lyon and Mead developed the ﬁrst analog electronic cochlea [1], which employed a cascade of second-order ﬁlters with exponentially decreasing resonant frequencies. However, the cascade structure suffers from delay and noise accumulation and lacks fault-tolerance. Modeling the cochlea more faithfully, Watts built a two-dimensional (2D) passive cochlea that addressed these shortcomings by incorporating the cochlear ﬂuid using a resistive network [2]. This parallel structure, however, has its own problem: response gain is diminished by interference among the second-order sections’ outputs due to the large phase change at resonance [3]. Listening more to biology, our silicon cochlea aims to overcome the shortcomings of existing architectures by mimicking the cochlear micromechanics while including outer hair cell (OHC) electromotility. Although how exactly OHC motile forces boost the basilar membrane’s (BM) vibration remains a mystery, cochlear microanatomy provides clues. Based on these clues, we previously proposed a novel mechanism, active bidirectional coupling (ABC), for the cochlear ampliﬁer [4]. Here, we report an analog VLSI chip that implements this mechanism. In essence, our implementation is the ﬁrst silicon cochlea that employs stimulus enhancement (i.e., active behavior) instead of undamping (i.e., high ﬁlter Q [5]). The paper is organized as follows. In Section 2, we present the hypothesized mechanism (ABC), ﬁrst described in [4]. In Section 3, we provide a mathematical formulation of the Oval window organ of Corti BM Round window IHC RL A OHC PhP DC BM Basal @ Stereocilia i -1 i i+1 Apical B Figure 1: The inner ear. A Cutaway showing cochlear ducts (adapted from [6]). B Longitudinal view of cochlear partition (CP) (modiﬁed from [7]-[8]). Each outer hair cell (OHC) tilts toward the base while the Deiter’s cell (DC) on which it sits extends a phalangeal process (PhP) toward the apex. The OHCs’ stereocilia and the PhPs’ apical ends form the reticular lamina (RL). d is the tilt distance, and the segment size. IHC: inner hair cell. model as the basis of cochlear circuit design. Then we proceed in Section 4 to synthesize the circuit for the cochlear chip. Last, we present chip measurements in Section 5 that demonstrate nonlinear active cochlear behavior. 2 Active Bidirectional Coupling The cochlea actively ampliﬁes acoustic signals as it performs spectral analysis. The movement of the stapes sets the cochlear ﬂuid into motion, which passes the stimulus energy onto a certain region of the BM, the main vibrating organ in the cochlea (Figure 1A). From the base to the apex, BM ﬁbers increase in width and decrease in thickness, resulting in an exponential decrease in stiffness which, in turn, gives rise to the passive frequency tuning of the cochlea. The OHCs’ electromotility is widely thought to account for the cochlea’s exquisite sensitivity and discriminability. The exact way that OHC motile forces enhance the BM’s motion, however, remains unresolved. We propose that the triangular mechanical unit formed by an OHC, a phalangeal process (PhP) extended from the Deiter’s cell (DC) on which the OHC sits, and a portion of the reticular lamina (RL), between the OHC’s stereocilia end and the PhP’s apical tip, plays an active role in enhancing the BM’s responses (Figure 1B). The cochlear partition (CP) is divided into a number of segments longitudinally. Each segment includes one DC, one PhP’s apical tip and one OHC’s stereocilia end, both attached to the RL. Approximating the anatomy, we assume that when an OHC’s stereocilia end lies in segment i − 1, its basolateral end lies in the immediately apical segment i. Furthermore, the DC in segment i extends a PhP that angles toward the apex of the cochlea, with its apical end inserted just behind the stereocilia end of the OHC in segment i + 1. Our hypothesis (ABC) includes both feedforward and feedbackward interactions. On one hand, the feedforward mechanism, proposed in [9], hypothesized that the force resulting from OHC contraction or elongation is exerted onto an adjacent downstream BM segment due to the OHC’s basal tilt. On the other hand, the novel insight of the feedbackward mechanism is that the OHC force is delivered onto an adjacent upstream BM segment due to the apical tilt of the PhP extending from the DC’s main trunk. In a nutshell, the OHC motile forces, through the microanatomy of the CP, feed forward and backward, in harmony with each other, resulting in bidirectional coupling between BM segments in the longitudinal direction. Speciﬁcally, due to the opposite action of OHC S x M x Re Zm 1 0.5 0 0.2 0 A 5 10 15 20 Distance from stapes mm 25 B Figure 2: Wave propagation (WP) and basilar membrane (BM) impedance in the active cochlear model with a 2kHz pure tone (α = 0.15, γ = 0.3). A WP in ﬂuid and BM. B BM impedance Zm (i.e., pressure divided by velocity), normalized by S(x)M (x). Only the resistive component is shown; dot marks peak location. forces on the BM and the RL, the motion of BM segment i − 1 reinforces that of segment i while the motion of segment i + 1 opposes that of segment i, as described in detail in [4]. 3 The 2D Nonlinear Active Model To provide a blueprint for the cochlear circuit design, we formulate a 2D model of the cochlea that includes ABC. Both the cochlea’s length (BM) and height (cochlear ducts) are discretized into a number of segments, with the original aspect ratio of the cochlea maintained. In the following expressions, x represents the distance from the stapes along the CP, with x = 0 at the base (or the stapes) and x = L (uncoiled cochlear duct length) at the apex; y represents the vertical distance from the BM, with y = 0 at the BM and y = ±h (cochlear duct radius) at the bottom/top wall. Providing that the assumption of ﬂuid incompressibility holds, the velocity potential φ of the ﬂuids is required to satisfy 2 φ(x, y, t) = 0, where 2 denotes the Laplacian operator. By deﬁnition, this potential is related to ﬂuid velocities in the x and y directions: Vx = −∂φ/∂x and Vy = −∂φ/∂y. The BM is driven by the ﬂuid pressure difference across it. Hence, the BM’s vertical motion (with downward displacement being positive) can be described as follows. ˙ ¨ Pd (x) + FOHC (x) = S(x)δ(x) + β(x)δ(x) + M (x)δ(x), (1) where S(x) is the stiffness, β(x) is the damping, and M (x) is the mass, per unit area, of the BM; δ is the BM’s downward displacement. Pd = ρ ∂(φSV (x, y, t) − φST (x, y, t))/∂t is the pressure difference between the two ﬂuid ducts (the scala vestibuli (SV) and the scala tympani (ST)), evaluated at the BM (y = 0); ρ is the ﬂuid density. The FOHC(x) term combines feedforward and feedbackward OHC forces, described by FOHC (x) = s0 tanh(αγS(x)δ(x − d)/s0 ) − tanh(αS(x)δ(x + d)/s0 ) , (2) where α denotes the OHC motility, expressed as a fraction of the BM stiffness, and γ is the ratio of feedforward to feedbackward coupling, representing relative strengths of the OHC forces exerted on the BM segment through the DC, directly and via the tilted PhP. d denotes the tilt distance, which is the horizontal displacement between the source and the recipient of the OHC force, assumed to be equal for the forward and backward cases. We use the hyperbolic tangent function to model saturation of the OHC forces, the nonlinearity that is evident in physiological measurements [8]; s0 determines the saturation level. We observed wave propagation in the model and computed the BM’s impedance (i.e., the ratio of driving pressure to velocity). Following the semi-analytical approach in [2], we simulated a linear version of the model (without saturation). The traveling wave transitions from long-wave to short-wave before the BM vibration peaks; the wavelength around the characteristic place is comparable to the tilt distance (Figure 2A). The BM impedance’s real part (i.e., the resistive component) becomes negative before the peak (Figure 2B). On the whole, inclusion of OHC motility through ABC boosts the traveling wave by pumping energy onto the BM when the wavelength matches the tilt of the OHC and PhP. 4 Analog VLSI Design and Implementation Based on our mathematical model, which produces realistic responses, we implemented a 2D nonlinear active cochlear circuit in analog VLSI, taking advantage of the 2D nature of silicon chips. We ﬁrst synthesize a circuit analog of the mathematical model, and then we implement the circuit in the log-domain. We start by synthesizing a passive model, and then extend it to a nonlinear active one by including ABC with saturation. 4.1 Synthesizing the BM Circuit The model consists of two fundamental parts: the cochlear ﬂuid and the BM. First, we design the ﬂuid element and thus the ﬂuid network. In discrete form, the ﬂuids can be viewed as a grid of elements with a speciﬁc resistance that corresponds to the ﬂuid density or mass. Since charge is conserved for a small sheet of resistance and so are particles for a small volume of ﬂuid, we use current to simulate ﬂuid velocity. At the transistor level, the current ﬂowing through the channel of a MOS transistor, operating subthreshold as a diffusive element, can be used for this purpose. Therefore, following the approach in [10], we implement the cochlear ﬂuid network using a diffusor network formed by a 2D grid of nMOS transistors. Second, we design the BM element and thus the BM. As current represents velocity, we rewrite the BM boundary condition (Equation 1, without the FOHC term): ˙ Iin = S(x) Imem dt + β(x)Imem + M (x)I˙mem , (3) where Iin , obtained by applying the voltage from the diffusor network to the gate of a pMOS transistor, represents the velocity potential scaled by the ﬂuid density. In turn, Imem ˙ drives the diffusor network to match the ﬂuid velocity with the BM velocity, δ. The FOHC term is dealt with in Section 4.2. Implementing this second-order system requires two state-space variables, which we name Is and Io . And with s = jω, our synthesized BM design (passive) is τ1 Is s + Is τ2 Io s + Io Imem = −Iin + Io , = Iin − bIs , = Iin + Is − Io , (4) (5) (6) where the two ﬁrst-order systems are both low-pass ﬁlters (LPFs), with time constants τ1 and τ2 , respectively; b is a gain factor. Thus, Iin can be expressed in terms of Imem as: Iin s2 = (b + 1)/τ1 τ2 + ((τ1 + τ2 )/τ1 τ2)s + s2 Imem . Comparing this expression with the design target (Equation 3) yields the circuit analogs: S(x) = (b + 1)/τ1τ2 , β(x) = (τ1 + τ2 )/τ1 τ2 , and M (x) = 1. Note that the mass M (x) is a constant (i.e., 1), which was also the case in our mathematical model simulation. These analogies require that τ1 and τ2 increase exponentially to Half LPF ( ) + Iout- Iin+ Iout+ Iout Vq Iin+ Iin- C+ B Iin- A Iin+ + - - Iin- + + + C To neighbors Is- Is+ > + > + IT+ IT- + - + From neighbors Io- Io+ + + + + - - + + LPF Iout+ Iout- BM Imem+ Imem- Figure 3: Low-pass ﬁlter (LPF) and second-order section circuit design. A Half-LPF circuit. B Complete LPF circuit formed by two half-LPF circuits. C Basilar membrane (BM) circuit. It consists of two LPFs and connects to its neighbors through Is and IT . simulate the exponentially decreasing BM stiffness (and damping); b allows us to achieve a reasonable stiffness for a practical choice of τ1 and τ2 (capacitor size is limited by silicon area). 4.2 Adding Active Bidirectional Coupling To include ABC in the BM boundary condition, we replace δ in Equation 2 with Imem dt to obtain FOHC = rﬀ S(x)T Imem (x − d)dt − rfb S(x)T Imem (x + d)dt , where rﬀ = αγ and rfb = α denote the feedforward and feedbackward OHC motility factors, and T denotes saturation. The saturation is applied to the displacement, instead of the force, as this simpliﬁes the implementation. We obtain the integrals by observing that, in the passive design, the state variable Is = −Imem /sτ1 . Thus, Imem (x − d)dt = −τ1f Isf and Imem (x + d)dt = −τ1b Isb . Here, Isf and Isb represent the outputs of the ﬁrst LPF in the upstream and downstream BM segments, respectively; τ1f and τ1b represent their respective time constants. To reduce complexity in implementation, we use τ1 to approximate both τ1f and τ1b as the longitudinal span is small. We obtain the active BM design by replacing Equation 5 with the synthesis result: τ2 Ios + Io = Iin − bIs + rfb (b + 1)T (−Isb ) − rﬀ (b + 1)T (−Isf ). Note that, to implement ABC, we only need to add two currents to the second LPF in the passive system. These currents, Isf and Isb , come from the upstream and downstream neighbors of each segment. ISV Fluid Base BM IST Apex Fluid A IT + IT Is+ Is- + Vsat Imem Iin+ Imem- Iin- Is+ Is+ Is- IsBM IT + IT + - I IT T Vsat IT + IT Is+ Is- B Figure 4: Cochlear chip. A Architecture: Two diffusive grids with embedded BM circuits model the cochlea. B Detail. BM circuits exchange currents with their neighbors. 4.3 Class AB Log-domain Implementation We employ the log-domain ﬁltering technique [11] to realize current-mode operation. In addition, following the approach proposed in [12], we implement the circuit in Class AB to increase dynamic range, reduce the effect of mismatch and lower power consumption. This differential signaling is inspired by the way the biological cochlea works—the vibration of BM is driven by the pressure difference across it. Taking a bottom-up strategy, we start by designing a Class AB LPF, a building block for the BM circuit. It is described by + − + − + − + − + − 2 τ (Iout − Iout )s + (Iout − Iout ) = Iin − Iin and τ Iout Iout s + Iout Iout = Iq , where Iq sets the geometric mean of the positive and negative components of the output current, and τ sets the time constant. Combining the common-mode constraint with the differential design equation yields the nodal equation for the positive path (the negative path has superscripts + and − swapped): + − + + + − 2 ˙+ C Vout = Iτ (Iin − Iin ) + (Iq /Iout − Iout ) /(Iout + Iout ). + This nodal equation suggests the half-LPF circuit shown in Figure 3A. Vout , the voltage on + the positive capacitor (C ), gates a pMOS transistor to produce the corresponding current + − − signal, Iout (Vout and Iout are similarly related). The bias Vq sets the quiescent current Iq while Vτ determines the current Iτ , which is related to the time constant by τ = CuT/κIτ (κ is the subthreshold slope coefﬁcient and uT is the thermal voltage). Two of these subcircuits, connected in push–pull, form a complete LPF (Figure 3B). The BM circuit is implemented using two LPFs interacting in accordance with the synthesized design equations (Figure 3C). Imem is the combination of three currents, Iin , Is , and Io . Each BM sends out Is and receives IT , a saturated version of its neighbor’s Is . The saturation is accomplished by a current-limiting transistor (see Figure 4B), which yields IT = T (Is ) = Is Isat /(Is + Isat ), where Isat is set by a bias voltage Vsat. 4.4 Chip Architecture We fabricated a version of our cochlear chip architecture (Figure 4) with 360 BM circuits and two 4680-element ﬂuid grids (360 ×13). This chip occupies 10.9mm2 of silicon area in 0.25µm CMOS technology. Differential input signals are applied at the base while the two ﬂuid grids are connected at the apex through a ﬂuid element that represents the helicotrema. 5 Chip Measurements We carried out two measurements that demonstrate the desired ampliﬁcation by ABC, and the compressive growth of BM responses due to saturation. To obtain sinusoidal current as the input to the BM subcircuits, we set the voltages applied at the base to be the logarithm of a half-wave rectiﬁed sinusoid. We ﬁrst investigated BM-velocity frequency responses at six linearly spaced cochlear positions (Figure 5). The frequency that maximally excites the ﬁrst position (Stage 30), deﬁned as its characteristic frequency (CF), is 12.1kHz. The remaining ﬁve CFs, from early to later stages, are 8.2k, 1.7k, 905, 366, and 218Hz, respectively. Phase accumulation at the CFs ranges from 0.56 to 2.67π radians, comparable to 1.67π radians in the mammalian cochlea [13]. Q10 factor (the ratio of the CF to the bandwidth 10dB below the peak) ranges from 1.25 to 2.73, comparable to 2.55 at mid-sound intensity in biology (computed from [13]). The cutoff slope ranges from -20 to -54dB/octave, as compared to -85dB/octave in biology (computed from [13]). BM Velocity Amplitude dB 40 Stage 0 230 190 150 110 70 30 30 20 10 0 BM Velocity Phase Π radians 50 2 4 10 0.1 0.2 0.5 1 2 5 Frequency kHz A 10 20 0.1 0.2 0.5 1 2 5 Frequency kHz 10 20 B Figure 5: Measured BM-velocity frequency responses at six locations. A Amplitude. B Phase. Dashed lines: Biological data (adapted from [13]). Dots mark peaks. We then explored the longitudinal pattern of BM-velocity responses and the effect of ABC. Stimulating the chip using four different pure tones, we obtained responses in which a 4kHz input elicits a peak around Stage 85 while 500Hz sound travels all the way to Stage 178 and peaks there (Figure 6A). We varied the input voltage level and obtained frequency responses at Stage 100 (Figure 6B). Input voltage level increases linearly such that the current increases exponentially; the input current level (in dB) was estimated based on the measured κ for this chip. As expected, we observed linearly increasing responses at low frequencies in the logarithmic plot. In contrast, the responses around the CF increase less and become broader with increasing input level as saturation takes effect in that region (resembling a passive cochlea). We observed 24dB compression as compared to 27 to 47dB in biology [13]. At the highest intensities, compression also occurs at low frequencies. These chip measurements demonstrate that inclusion of ABC, simply through coupling neighboring BM elements, transforms a passive cochlea into an active one. This active cochlear model’s nonlinear responses are qualitatively comparable to physiological data. 6 Conclusions We presented an analog VLSI implementation of a 2D nonlinear cochlear model that utilizes a novel active mechanism, ABC, which we proposed to account for the cochlear ampliﬁer. ABC was shown to pump energy into the traveling wave. Rather than detecting the wave’s amplitude and implementing an automatic-gain-control loop, our biomorphic model accomplishes this simply by nonlinear interactions between adjacent neighbors. Im- 60 Frequency 4k 2k 1k 500 Hz BM Velocity Amplitude dB BM Velocity Amplitude dB 20 10 0 Input Level 40 48 dB 20 Stage 100 32 dB 16 dB 0 0 dB 10 0 50 100 150 Stage Number A 200 0.2 0.5 1 2 5 Frequency kHz 10 20 B Figure 6: Measured BM-velocity responses (cont’d). A Longitudinal responses (20-stage moving average). Peak shifts to earlier (basal) stages as input frequency increases from 500 to 4kHz. B Effects of increasing input intensity. Responses become broader and show compressive growth. plemented in the log-domain, with Class AB operation, our silicon cochlea shows enhanced frequency responses, with compressive behavior around the CF, when ABC is turned on. These features are desirable in prosthetic applications and automatic speech recognition systems as they capture the properties of the biological cochlea. References [1] Lyon, R.F. & Mead, C.A. (1988) An analog electronic cochlea. IEEE Trans. Acoust. Speech and Signal Proc., 36: 1119-1134. [2] Watts, L. (1993) Cochlear Mechanics: Analysis and Analog VLSI . Ph.D. thesis, Pasadena, CA: California Institute of Technology. [3] Fragni`re, E. (2005) A 100-Channel analog CMOS auditory ﬁlter bank for speech recognition. e IEEE International Solid-State Circuits Conference (ISSCC 2005) , pp. 140-141. [4] Wen, B. & Boahen, K. (2003) A linear cochlear model with active bi-directional coupling. The 25th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC 2003), pp. 2013-2016. [5] Sarpeshkar, R., Lyon, R.F., & Mead, C.A. (1996) An analog VLSI cochlear model with new transconductance ampliﬁer and nonlinear gain control. Proceedings of the IEEE Symposium on Circuits and Systems (ISCAS 1996) , 3: 292-295. [6] Mead, C.A. (1989) Analog VLSI and Neural Systems . Reading, MA: Addison-Wesley. [7] Russell, I.J. & Nilsen, K.E. (1997) The location of the cochlear ampliﬁer: Spatial representation of a single tone on the guinea pig basilar membrane. Proc. Natl. Acad. Sci. USA, 94: 2660-2664. [8] Geisler, C.D. (1998) From sound to synapse: physiology of the mammalian ear . Oxford University Press. [9] Geisler, C.D. & Sang, C. (1995) A cochlear model using feed-forward outer-hair-cell forces. Hearing Research , 86: 132-146. [10] Boahen, K.A. & Andreou, A.G. (1992) A contrast sensitive silicon retina with reciprocal synapses. In Moody, J.E. and Lippmann, R.P. (eds.), Advances in Neural Information Processing Systems 4 (NIPS 1992) , pp. 764-772, Morgan Kaufmann, San Mateo, CA. [11] Frey, D.R. (1993) Log-domain ﬁltering: an approach to current-mode ﬁltering. IEE Proc. G, Circuits Devices Syst., 140 (6): 406-416. [12] Zaghloul, K. & Boahen, K.A. (2005) An On-Off log-domain circuit that recreates adaptive ﬁltering in the retina. IEEE Transactions on Circuits and Systems I: Regular Papers , 52 (1): 99-107. [13] Ruggero, M.A., Rich, N.C., Narayan, S.S., & Robles, L. (1997) Basilar membrane responses to tones at the base of the chinchilla cochlea. J. Acoust. Soc. Am., 101 (4): 2151-2163.</p><p>3 0.95376641 <a title="87-lda-3" href="./nips-2005-The_Forgetron%3A_A_Kernel-Based_Perceptron_on_a_Fixed_Budget.html">191 nips-2005-The Forgetron: A Kernel-Based Perceptron on a Fixed Budget</a></p>
<p>Author: Ofer Dekel, Shai Shalev-shwartz, Yoram Singer</p><p>Abstract: The Perceptron algorithm, despite its simplicity, often performs well on online classiﬁcation tasks. The Perceptron becomes especially effective when it is used in conjunction with kernels. However, a common difﬁculty encountered when implementing kernel-based online algorithms is the amount of memory required to store the online hypothesis, which may grow unboundedly. In this paper we present and analyze the Forgetron algorithm for kernel-based online learning on a ﬁxed memory budget. To our knowledge, this is the ﬁrst online learning algorithm which, on one hand, maintains a strict limit on the number of examples it stores while, on the other hand, entertains a relative mistake bound. In addition to the formal results, we also present experiments with real datasets which underscore the merits of our approach.</p><p>same-paper 4 0.95120579 <a title="87-lda-4" href="./nips-2005-Goal-Based_Imitation_as_Probabilistic_Inference_over_Graphical_Models.html">87 nips-2005-Goal-Based Imitation as Probabilistic Inference over Graphical Models</a></p>
<p>Author: Deepak Verma, Rajesh P. Rao</p><p>Abstract: Humans are extremely adept at learning new skills by imitating the actions of others. A progression of imitative abilities has been observed in children, ranging from imitation of simple body movements to goalbased imitation based on inferring intent. In this paper, we show that the problem of goal-based imitation can be formulated as one of inferring goals and selecting actions using a learned probabilistic graphical model of the environment. We ﬁrst describe algorithms for planning actions to achieve a goal state using probabilistic inference. We then describe how planning can be used to bootstrap the learning of goal-dependent policies by utilizing feedback from the environment. The resulting graphical model is then shown to be powerful enough to allow goal-based imitation. Using a simple maze navigation task, we illustrate how an agent can infer the goals of an observed teacher and imitate the teacher even when the goals are uncertain and the demonstration is incomplete.</p><p>5 0.92082018 <a title="87-lda-5" href="./nips-2005-Nonparametric_inference_of_prior_probabilities_from_Bayes-optimal_behavior.html">140 nips-2005-Nonparametric inference of prior probabilities from Bayes-optimal behavior</a></p>
<p>Author: Liam Paninski</p><p>Abstract: We discuss a method for obtaining a subject’s a priori beliefs from his/her behavior in a psychophysics context, under the assumption that the behavior is (nearly) optimal from a Bayesian perspective. The method is nonparametric in the sense that we do not assume that the prior belongs to any ﬁxed class of distributions (e.g., Gaussian). Despite this increased generality, the method is relatively simple to implement, being based in the simplest case on a linear programming algorithm, and more generally on a straightforward maximum likelihood or maximum a posteriori formulation, which turns out to be a convex optimization problem (with no non-global local maxima) in many important cases. In addition, we develop methods for analyzing the uncertainty of these estimates. We demonstrate the accuracy of the method in a simple simulated coin-ﬂipping setting; in particular, the method is able to precisely track the evolution of the subject’s posterior distribution as more and more data are observed. We close by brieﬂy discussing an interesting connection to recent models of neural population coding.</p><p>6 0.91292328 <a title="87-lda-6" href="./nips-2005-Soft_Clustering_on_Graphs.html">178 nips-2005-Soft Clustering on Graphs</a></p>
<p>7 0.85051483 <a title="87-lda-7" href="./nips-2005-Bayesian_models_of_human_action_understanding.html">36 nips-2005-Bayesian models of human action understanding</a></p>
<p>8 0.83925521 <a title="87-lda-8" href="./nips-2005-Off-policy_Learning_with_Options_and_Recognizers.html">144 nips-2005-Off-policy Learning with Options and Recognizers</a></p>
<p>9 0.8219251 <a title="87-lda-9" href="./nips-2005-A_Probabilistic_Approach_for_Optimizing_Spectral_Clustering.html">13 nips-2005-A Probabilistic Approach for Optimizing Spectral Clustering</a></p>
<p>10 0.81604546 <a title="87-lda-10" href="./nips-2005-Size_Regularized_Cut_for_Data_Clustering.html">177 nips-2005-Size Regularized Cut for Data Clustering</a></p>
<p>11 0.80860806 <a title="87-lda-11" href="./nips-2005-Mixture_Modeling_by_Affinity_Propagation.html">127 nips-2005-Mixture Modeling by Affinity Propagation</a></p>
<p>12 0.80683482 <a title="87-lda-12" href="./nips-2005-From_Weighted_Classification_to_Policy_Search.html">78 nips-2005-From Weighted Classification to Policy Search</a></p>
<p>13 0.80482256 <a title="87-lda-13" href="./nips-2005-Logic_and_MRF_Circuitry_for_Labeling_Occluding_and_Thinline_Visual_Contours.html">122 nips-2005-Logic and MRF Circuitry for Labeling Occluding and Thinline Visual Contours</a></p>
<p>14 0.80078709 <a title="87-lda-14" href="./nips-2005-Data-Driven_Online_to_Batch_Conversions.html">54 nips-2005-Data-Driven Online to Batch Conversions</a></p>
<p>15 0.79452622 <a title="87-lda-15" href="./nips-2005-Norepinephrine_and_Neural_Interrupts.html">141 nips-2005-Norepinephrine and Neural Interrupts</a></p>
<p>16 0.76198792 <a title="87-lda-16" href="./nips-2005-Improved_risk_tail_bounds_for_on-line_algorithms.html">95 nips-2005-Improved risk tail bounds for on-line algorithms</a></p>
<p>17 0.75854707 <a title="87-lda-17" href="./nips-2005-Extracting_Dynamical_Structure_Embedded_in_Neural_Activity.html">67 nips-2005-Extracting Dynamical Structure Embedded in Neural Activity</a></p>
<p>18 0.7548371 <a title="87-lda-18" href="./nips-2005-Principles_of_real-time_computing_with_feedback_applied_to_cortical_microcircuit_models.html">157 nips-2005-Principles of real-time computing with feedback applied to cortical microcircuit models</a></p>
<p>19 0.75156397 <a title="87-lda-19" href="./nips-2005-Ideal_Observers_for_Detecting_Motion%3A_Correspondence_Noise.html">93 nips-2005-Ideal Observers for Detecting Motion: Correspondence Noise</a></p>
<p>20 0.74953967 <a title="87-lda-20" href="./nips-2005-Predicting_EMG_Data_from_M1_Neurons_with_Variational_Bayesian_Least_Squares.html">155 nips-2005-Predicting EMG Data from M1 Neurons with Variational Bayesian Least Squares</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
