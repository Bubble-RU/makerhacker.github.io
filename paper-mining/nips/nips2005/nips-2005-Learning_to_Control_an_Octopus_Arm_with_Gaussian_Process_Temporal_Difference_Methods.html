<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>119 nips-2005-Learning to Control an Octopus Arm with Gaussian Process Temporal Difference Methods</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2005" href="../home/nips2005_home.html">nips2005</a> <a title="nips-2005-119" href="#">nips2005-119</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>119 nips-2005-Learning to Control an Octopus Arm with Gaussian Process Temporal Difference Methods</h1>
<br/><p>Source: <a title="nips-2005-119-pdf" href="http://papers.nips.cc/paper/2785-learning-to-control-an-octopus-arm-with-gaussian-process-temporal-difference-methods.pdf">pdf</a></p><p>Author: Yaakov Engel, Peter Szabo, Dmitry Volkinshtein</p><p>Abstract: The Octopus arm is a highly versatile and complex limb. How the Octopus controls such a hyper-redundant arm (not to mention eight of them!) is as yet unknown. Robotic arms based on the same mechanical principles may render present day robotic arms obsolete. In this paper, we tackle this control problem using an online reinforcement learning algorithm, based on a Bayesian approach to policy evaluation known as Gaussian process temporal difference (GPTD) learning. Our substitute for the real arm is a computer simulation of a 2-dimensional model of an Octopus arm. Even with the simpliﬁcations inherent to this model, the state space we face is a high-dimensional one. We apply a GPTDbased algorithm to this domain, and demonstrate its operation on several learning tasks of varying degrees of difﬁculty. 1</p><p>Reference: <a title="nips-2005-119-reference" href="../nips2005_reference/nips-2005-Learning_to_Control_an_Octopus_Arm_with_Gaussian_Process_Temporal_Difference_Methods_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('arm', 0.635), ('gptd', 0.397), ('octop', 0.36), ('musc', 0.265), ('episod', 0.23), ('grav', 0.137), ('policy', 0.102), ('rl', 0.092), ('spring', 0.09), ('forc', 0.089), ('muscul', 0.086), ('reward', 0.085), ('engel', 0.082), ('compart', 0.077), ('reach', 0.076), ('hydrost', 0.069), ('robot', 0.057), ('obstac', 0.051), ('contract', 0.046), ('transvers', 0.045)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999946 <a title="119-tfidf-1" href="./nips-2005-Learning_to_Control_an_Octopus_Arm_with_Gaussian_Process_Temporal_Difference_Methods.html">119 nips-2005-Learning to Control an Octopus Arm with Gaussian Process Temporal Difference Methods</a></p>
<p>2 0.12415569 <a title="119-tfidf-2" href="./nips-2005-From_Weighted_Classification_to_Policy_Search.html">78 nips-2005-From Weighted Classification to Policy Search</a></p>
<p>3 0.099301636 <a title="119-tfidf-3" href="./nips-2005-Policy-Gradient_Methods_for_Planning.html">153 nips-2005-Policy-Gradient Methods for Planning</a></p>
<p>4 0.09272103 <a title="119-tfidf-4" href="./nips-2005-On_Local_Rewards_and_Scaling_Distributed_Reinforcement_Learning.html">145 nips-2005-On Local Rewards and Scaling Distributed Reinforcement Learning</a></p>
<p>5 0.092379183 <a title="119-tfidf-5" href="./nips-2005-Noise_and_the_two-thirds_power_Law.html">136 nips-2005-Noise and the two-thirds power Law</a></p>
<p>6 0.081040561 <a title="119-tfidf-6" href="./nips-2005-Off-policy_Learning_with_Options_and_Recognizers.html">144 nips-2005-Off-policy Learning with Options and Recognizers</a></p>
<p>7 0.071049929 <a title="119-tfidf-7" href="./nips-2005-Goal-Based_Imitation_as_Probabilistic_Inference_over_Graphical_Models.html">87 nips-2005-Goal-Based Imitation as Probabilistic Inference over Graphical Models</a></p>
<p>8 0.07093811 <a title="119-tfidf-8" href="./nips-2005-TD%280%29_Leads_to_Better_Policies_than_Approximate_Value_Iteration.html">186 nips-2005-TD(0) Leads to Better Policies than Approximate Value Iteration</a></p>
<p>9 0.066698968 <a title="119-tfidf-9" href="./nips-2005-How_fast_to_work%3A_Response_vigor%2C_motivation_and_tonic_dopamine.html">91 nips-2005-How fast to work: Response vigor, motivation and tonic dopamine</a></p>
<p>10 0.065965176 <a title="119-tfidf-10" href="./nips-2005-Predicting_EMG_Data_from_M1_Neurons_with_Variational_Bayesian_Least_Squares.html">155 nips-2005-Predicting EMG Data from M1 Neurons with Variational Bayesian Least Squares</a></p>
<p>11 0.057109505 <a title="119-tfidf-11" href="./nips-2005-Off-Road_Obstacle_Avoidance_through_End-to-End_Learning.html">143 nips-2005-Off-Road Obstacle Avoidance through End-to-End Learning</a></p>
<p>12 0.054343488 <a title="119-tfidf-12" href="./nips-2005-Bayesian_models_of_human_action_understanding.html">36 nips-2005-Bayesian models of human action understanding</a></p>
<p>13 0.050121285 <a title="119-tfidf-13" href="./nips-2005-Group_and_Topic_Discovery_from_Relations_and_Their_Attributes.html">89 nips-2005-Group and Topic Discovery from Relations and Their Attributes</a></p>
<p>14 0.049888726 <a title="119-tfidf-14" href="./nips-2005-Inferring_Motor_Programs_from_Images_of_Handwritten_Digits.html">97 nips-2005-Inferring Motor Programs from Images of Handwritten Digits</a></p>
<p>15 0.04912727 <a title="119-tfidf-15" href="./nips-2005-Fast_biped_walking_with_a_reflexive_controller_and_real-time_policy_searching.html">73 nips-2005-Fast biped walking with a reflexive controller and real-time policy searching</a></p>
<p>16 0.048772268 <a title="119-tfidf-16" href="./nips-2005-Temporal_Abstraction_in_Temporal-difference_Networks.html">187 nips-2005-Temporal Abstraction in Temporal-difference Networks</a></p>
<p>17 0.047595032 <a title="119-tfidf-17" href="./nips-2005-Modeling_Neural_Population_Spiking_Activity_with_Gibbs_Distributions.html">129 nips-2005-Modeling Neural Population Spiking Activity with Gibbs Distributions</a></p>
<p>18 0.044244286 <a title="119-tfidf-18" href="./nips-2005-Fast_Online_Policy_Gradient_Learning_with_SMD_Gain_Vector_Adaptation.html">72 nips-2005-Fast Online Policy Gradient Learning with SMD Gain Vector Adaptation</a></p>
<p>19 0.043709319 <a title="119-tfidf-19" href="./nips-2005-An_exploration-exploitation_model_based_on_norepinepherine_and_dopamine_activity.html">26 nips-2005-An exploration-exploitation model based on norepinepherine and dopamine activity</a></p>
<p>20 0.041597277 <a title="119-tfidf-20" href="./nips-2005-Learning_Shared_Latent_Structure_for_Image_Synthesis_and_Robotic_Imitation.html">115 nips-2005-Learning Shared Latent Structure for Image Synthesis and Robotic Imitation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2005_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.12), (1, -0.009), (2, 0.177), (3, 0.031), (4, 0.02), (5, -0.032), (6, 0.047), (7, 0.011), (8, -0.004), (9, 0.019), (10, 0.03), (11, 0.001), (12, -0.027), (13, 0.021), (14, -0.045), (15, 0.008), (16, 0.075), (17, -0.007), (18, 0.022), (19, -0.013), (20, 0.012), (21, 0.003), (22, -0.013), (23, -0.01), (24, -0.117), (25, -0.146), (26, -0.054), (27, -0.026), (28, -0.007), (29, 0.001), (30, -0.01), (31, -0.029), (32, -0.065), (33, 0.07), (34, -0.015), (35, 0.018), (36, 0.002), (37, -0.065), (38, 0.102), (39, -0.08), (40, -0.012), (41, -0.034), (42, -0.019), (43, 0.007), (44, 0.011), (45, 0.103), (46, -0.094), (47, 0.003), (48, 0.048), (49, 0.155)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.87357473 <a title="119-lsi-1" href="./nips-2005-Learning_to_Control_an_Octopus_Arm_with_Gaussian_Process_Temporal_Difference_Methods.html">119 nips-2005-Learning to Control an Octopus Arm with Gaussian Process Temporal Difference Methods</a></p>
<p>2 0.56551081 <a title="119-lsi-2" href="./nips-2005-Noise_and_the_two-thirds_power_Law.html">136 nips-2005-Noise and the two-thirds power Law</a></p>
<p>3 0.53980297 <a title="119-lsi-3" href="./nips-2005-How_fast_to_work%3A_Response_vigor%2C_motivation_and_tonic_dopamine.html">91 nips-2005-How fast to work: Response vigor, motivation and tonic dopamine</a></p>
<p>4 0.51769394 <a title="119-lsi-4" href="./nips-2005-On_Local_Rewards_and_Scaling_Distributed_Reinforcement_Learning.html">145 nips-2005-On Local Rewards and Scaling Distributed Reinforcement Learning</a></p>
<p>5 0.5039295 <a title="119-lsi-5" href="./nips-2005-From_Weighted_Classification_to_Policy_Search.html">78 nips-2005-From Weighted Classification to Policy Search</a></p>
<p>6 0.4517611 <a title="119-lsi-6" href="./nips-2005-Predicting_EMG_Data_from_M1_Neurons_with_Variational_Bayesian_Least_Squares.html">155 nips-2005-Predicting EMG Data from M1 Neurons with Variational Bayesian Least Squares</a></p>
<p>7 0.42759281 <a title="119-lsi-7" href="./nips-2005-Policy-Gradient_Methods_for_Planning.html">153 nips-2005-Policy-Gradient Methods for Planning</a></p>
<p>8 0.42191559 <a title="119-lsi-8" href="./nips-2005-Fast_Online_Policy_Gradient_Learning_with_SMD_Gain_Vector_Adaptation.html">72 nips-2005-Fast Online Policy Gradient Learning with SMD Gain Vector Adaptation</a></p>
<p>9 0.40286499 <a title="119-lsi-9" href="./nips-2005-Active_Bidirectional_Coupling_in_a_Cochlear_Chip.html">17 nips-2005-Active Bidirectional Coupling in a Cochlear Chip</a></p>
<p>10 0.39381993 <a title="119-lsi-10" href="./nips-2005-Fast_biped_walking_with_a_reflexive_controller_and_real-time_policy_searching.html">73 nips-2005-Fast biped walking with a reflexive controller and real-time policy searching</a></p>
<p>11 0.39128014 <a title="119-lsi-11" href="./nips-2005-Goal-Based_Imitation_as_Probabilistic_Inference_over_Graphical_Models.html">87 nips-2005-Goal-Based Imitation as Probabilistic Inference over Graphical Models</a></p>
<p>12 0.3741951 <a title="119-lsi-12" href="./nips-2005-An_exploration-exploitation_model_based_on_norepinepherine_and_dopamine_activity.html">26 nips-2005-An exploration-exploitation model based on norepinepherine and dopamine activity</a></p>
<p>13 0.36725986 <a title="119-lsi-13" href="./nips-2005-TD%280%29_Leads_to_Better_Policies_than_Approximate_Value_Iteration.html">186 nips-2005-TD(0) Leads to Better Policies than Approximate Value Iteration</a></p>
<p>14 0.35116878 <a title="119-lsi-14" href="./nips-2005-Off-policy_Learning_with_Options_and_Recognizers.html">144 nips-2005-Off-policy Learning with Options and Recognizers</a></p>
<p>15 0.33829373 <a title="119-lsi-15" href="./nips-2005-Modeling_Memory_Transfer_and_Saving_in_Cerebellar_Motor_Learning.html">128 nips-2005-Modeling Memory Transfer and Saving in Cerebellar Motor Learning</a></p>
<p>16 0.33613667 <a title="119-lsi-16" href="./nips-2005-Active_Learning_for_Misspecified_Models.html">19 nips-2005-Active Learning for Misspecified Models</a></p>
<p>17 0.3104921 <a title="119-lsi-17" href="./nips-2005-Off-Road_Obstacle_Avoidance_through_End-to-End_Learning.html">143 nips-2005-Off-Road Obstacle Avoidance through End-to-End Learning</a></p>
<p>18 0.30741483 <a title="119-lsi-18" href="./nips-2005-Inferring_Motor_Programs_from_Images_of_Handwritten_Digits.html">97 nips-2005-Inferring Motor Programs from Images of Handwritten Digits</a></p>
<p>19 0.29939529 <a title="119-lsi-19" href="./nips-2005-Generalized_Nonnegative_Matrix_Approximations_with_Bregman_Divergences.html">86 nips-2005-Generalized Nonnegative Matrix Approximations with Bregman Divergences</a></p>
<p>20 0.29570827 <a title="119-lsi-20" href="./nips-2005-Learning_Shared_Latent_Structure_for_Image_Synthesis_and_Robotic_Imitation.html">115 nips-2005-Learning Shared Latent Structure for Image Synthesis and Robotic Imitation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2005_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.048), (9, 0.013), (12, 0.058), (17, 0.023), (32, 0.012), (54, 0.014), (71, 0.11), (85, 0.367), (88, 0.054), (89, 0.029), (92, 0.147)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.70006943 <a title="119-lda-1" href="./nips-2005-Learning_to_Control_an_Octopus_Arm_with_Gaussian_Process_Temporal_Difference_Methods.html">119 nips-2005-Learning to Control an Octopus Arm with Gaussian Process Temporal Difference Methods</a></p>
<p>2 0.4876163 <a title="119-lda-2" href="./nips-2005-Off-policy_Learning_with_Options_and_Recognizers.html">144 nips-2005-Off-policy Learning with Options and Recognizers</a></p>
<p>3 0.48451072 <a title="119-lda-3" href="./nips-2005-From_Weighted_Classification_to_Policy_Search.html">78 nips-2005-From Weighted Classification to Policy Search</a></p>
<p>4 0.48362643 <a title="119-lda-4" href="./nips-2005-Policy-Gradient_Methods_for_Planning.html">153 nips-2005-Policy-Gradient Methods for Planning</a></p>
<p>5 0.48124102 <a title="119-lda-5" href="./nips-2005-Bayesian_models_of_human_action_understanding.html">36 nips-2005-Bayesian models of human action understanding</a></p>
<p>6 0.47623 <a title="119-lda-6" href="./nips-2005-On_Local_Rewards_and_Scaling_Distributed_Reinforcement_Learning.html">145 nips-2005-On Local Rewards and Scaling Distributed Reinforcement Learning</a></p>
<p>7 0.47292316 <a title="119-lda-7" href="./nips-2005-Size_Regularized_Cut_for_Data_Clustering.html">177 nips-2005-Size Regularized Cut for Data Clustering</a></p>
<p>8 0.47000474 <a title="119-lda-8" href="./nips-2005-Soft_Clustering_on_Graphs.html">178 nips-2005-Soft Clustering on Graphs</a></p>
<p>9 0.46952519 <a title="119-lda-9" href="./nips-2005-Variable_KD-Tree_Algorithms_for_Spatial_Pattern_Search_and_Discovery.html">200 nips-2005-Variable KD-Tree Algorithms for Spatial Pattern Search and Discovery</a></p>
<p>10 0.46839207 <a title="119-lda-10" href="./nips-2005-Logic_and_MRF_Circuitry_for_Labeling_Occluding_and_Thinline_Visual_Contours.html">122 nips-2005-Logic and MRF Circuitry for Labeling Occluding and Thinline Visual Contours</a></p>
<p>11 0.46800023 <a title="119-lda-11" href="./nips-2005-Noise_and_the_two-thirds_power_Law.html">136 nips-2005-Noise and the two-thirds power Law</a></p>
<p>12 0.46747988 <a title="119-lda-12" href="./nips-2005-Fast_Online_Policy_Gradient_Learning_with_SMD_Gain_Vector_Adaptation.html">72 nips-2005-Fast Online Policy Gradient Learning with SMD Gain Vector Adaptation</a></p>
<p>13 0.46674258 <a title="119-lda-13" href="./nips-2005-A_Probabilistic_Approach_for_Optimizing_Spectral_Clustering.html">13 nips-2005-A Probabilistic Approach for Optimizing Spectral Clustering</a></p>
<p>14 0.46640095 <a title="119-lda-14" href="./nips-2005-Online_Discovery_and_Learning_of_Predictive_State_Representations.html">148 nips-2005-Online Discovery and Learning of Predictive State Representations</a></p>
<p>15 0.46596575 <a title="119-lda-15" href="./nips-2005-Layered_Dynamic_Textures.html">108 nips-2005-Layered Dynamic Textures</a></p>
<p>16 0.46565515 <a title="119-lda-16" href="./nips-2005-Extracting_Dynamical_Structure_Embedded_in_Neural_Activity.html">67 nips-2005-Extracting Dynamical Structure Embedded in Neural Activity</a></p>
<p>17 0.46508747 <a title="119-lda-17" href="./nips-2005-A_Hierarchical_Compositional_System_for_Rapid_Object_Detection.html">11 nips-2005-A Hierarchical Compositional System for Rapid Object Detection</a></p>
<p>18 0.46413666 <a title="119-lda-18" href="./nips-2005-Temporal_Abstraction_in_Temporal-difference_Networks.html">187 nips-2005-Temporal Abstraction in Temporal-difference Networks</a></p>
<p>19 0.46391559 <a title="119-lda-19" href="./nips-2005-Mixture_Modeling_by_Affinity_Propagation.html">127 nips-2005-Mixture Modeling by Affinity Propagation</a></p>
<p>20 0.46167463 <a title="119-lda-20" href="./nips-2005-Predicting_EMG_Data_from_M1_Neurons_with_Variational_Bayesian_Least_Squares.html">155 nips-2005-Predicting EMG Data from M1 Neurons with Variational Bayesian Least Squares</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
