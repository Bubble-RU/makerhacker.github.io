<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>191 nips-2005-The Forgetron: A Kernel-Based Perceptron on a Fixed Budget</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2005" href="../home/nips2005_home.html">nips2005</a> <a title="nips-2005-191" href="#">nips2005-191</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>191 nips-2005-The Forgetron: A Kernel-Based Perceptron on a Fixed Budget</h1>
<br/><p>Source: <a title="nips-2005-191-pdf" href="http://papers.nips.cc/paper/2806-the-forgetron-a-kernel-based-perceptron-on-a-fixed-budget.pdf">pdf</a></p><p>Author: Ofer Dekel, Shai Shalev-shwartz, Yoram Singer</p><p>Abstract: The Perceptron algorithm, despite its simplicity, often performs well on online classiﬁcation tasks. The Perceptron becomes especially effective when it is used in conjunction with kernels. However, a common difﬁculty encountered when implementing kernel-based online algorithms is the amount of memory required to store the online hypothesis, which may grow unboundedly. In this paper we present and analyze the Forgetron algorithm for kernel-based online learning on a ﬁxed memory budget. To our knowledge, this is the ﬁrst online learning algorithm which, on one hand, maintains a strict limit on the number of examples it stores while, on the other hand, entertains a relative mistake bound. In addition to the formal results, we also present experiments with real datasets which underscore the merits of our approach.</p><p>Reference: <a title="nips-2005-191-reference" href="../nips2005_reference/nips-2005-The_Forgetron%3A_A_Kernel-Based_Perceptron_on_a_Fixed_Budget_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 However, a common difﬁculty encountered when implementing kernel-based online algorithms is the amount of memory required to store the online hypothesis, which may grow unboundedly. [sent-6, score-0.536]
</p><p>2 In this paper we present and analyze the Forgetron algorithm for kernel-based online learning on a ﬁxed memory budget. [sent-7, score-0.32]
</p><p>3 To our knowledge, this is the ﬁrst online learning algorithm which, on one hand, maintains a strict limit on the number of examples it stores while, on the other hand, entertains a relative mistake bound. [sent-8, score-0.702]
</p><p>4 This set of stored examples is the online equivalent of the support set of SVMs, however in contrast to the support, it continually changes as learning progresses. [sent-15, score-0.302]
</p><p>5 In this paper, we call this set the active set, as it includes those examples that actively deﬁne the current classiﬁer. [sent-16, score-0.238]
</p><p>6 Typically, an example is added to the active set every time the online algorithm makes a prediction mistake, or when its conﬁdence in a prediction is inadequately low. [sent-17, score-0.684]
</p><p>7 Naturally, since computing devices have bounded memory resources, there is the danger that an online algorithm would require more memory than is physically available. [sent-19, score-0.397]
</p><p>8 This problem becomes especially eminent in cases where the online algorithm is implemented as part of a specialized hardware system with a small memory, such as a mobile telephone or an au-  tonomous robot. [sent-20, score-0.267]
</p><p>9 Moreover, an excessively large active set can lead to unacceptably long running times, as the time-complexity of each online round scales linearly with the size of the active set. [sent-21, score-0.855]
</p><p>10 Crammer, Kandola, and Singer [2] ﬁrst addressed this problem by describing an online kernel-based modiﬁcation of the Perceptron algorithm in which the active set does not exceed a predeﬁned budget. [sent-22, score-0.456]
</p><p>11 Their algorithm removes redundant examples from the active set so as to make the best use of the limited memory resource. [sent-23, score-0.349]
</p><p>12 Weston, Bordes and Bottou [9] followed with their own online kernel machine on a budget. [sent-24, score-0.268]
</p><p>13 In this paper we present the Forgetron algorithm for online kernel-based classiﬁcation. [sent-26, score-0.267]
</p><p>14 To the best of our knowledge, the Forgetron is the ﬁrst online algorithm with a ﬁxed memory budget which also entertains a formal worst-case mistake bound. [sent-27, score-0.994]
</p><p>15 We name our algorithm the Forgetron since its update builds on that of the Perceptron and since it gradually forgets active examples as learning progresses. [sent-28, score-0.313]
</p><p>16 2 we begin with a more formal presentation of our problem and discuss some difﬁculties in proving mistake bounds for kernel-methods on a budget. [sent-31, score-0.42]
</p><p>17 3 we present an algorithmic framework for online prediction with a predeﬁned budget of active examples. [sent-33, score-0.744]
</p><p>18 On round t the online algorithm observes an instance xt , which is drawn from some predeﬁned instance domain X . [sent-40, score-0.66]
</p><p>19 The predictions of the online algorithm are determined by a hypothesis which is stored in its internal memory and is updated from round to round. [sent-44, score-0.693]
</p><p>20 Our focus in this paper is on margin based hypotheses, namely, ft is a function from X to R where sign(ft (xt )) constitutes the actual binary prediction and |ft (xt )| is the conﬁdence in this prediction. [sent-46, score-0.466]
</p><p>21 First, we can check whether the hypothesis makes a prediction mistake, namely determine whether y = sign(f (x)) or not. [sent-49, score-0.26]
</p><p>22 Throughout this paper, we use M to denote the number of prediction mistakes made by an online algorithm on a sequence of examples (x1 , y1 ), . [sent-50, score-0.56]
</p><p>23 That is, the hypothesis used on round t takes the form, ft (x) = i∈It αi K(xi , x), where It is a subset of {1, . [sent-72, score-0.652]
</p><p>24 , (t-1)} and xi is the example observed by the algorithm on round i. [sent-75, score-0.285]
</p><p>25 As stated above, It is called the active set, and we say that example xi is active on round t if i ∈ It . [sent-76, score-0.679]
</p><p>26 Perhaps the most well known online algorithm for binary classiﬁcation is the Perceptron [6]. [sent-77, score-0.298]
</p><p>27 Stated in the form of a kernel method, the hypotheses generated by the Perceptron take the form ft (x) = i∈It yi K(xi , x). [sent-78, score-0.396]
</p><p>28 Namely, the weight assigned to each active example is either +1 or −1, depending on the label of that example. [sent-79, score-0.244]
</p><p>29 It then updates its hypothesis only on rounds where a prediction mistake is made. [sent-81, score-0.615]
</p><p>30 Concretely, on round t, if ft (xt ) = yt then the index t is inserted into the active set. [sent-82, score-0.832]
</p><p>31 As a consequence, the size of the active set on round t equals the number of prediction mistakes made on previous rounds. [sent-83, score-0.669]
</p><p>32 A relative mistake bound can be proven for the Perceptron algorithm. [sent-84, score-0.416]
</p><p>33 The bound holds for any sequence of instance-label pairs, and compares the number of mistakes made by the Perceptron with the cumulative hinge-loss of any ﬁxed hypothesis g ∈ HK , even one deﬁned with prior knowledge of the sequence. [sent-85, score-0.378]
</p><p>34 , (xT , yT ) be a sequence of examples such that K(xt , xt ) ≤ 1 for all t. [sent-90, score-0.239]
</p><p>35 Then the number of prediction mistakes made by the Perceptron ˆ on this sequence is bounded by, M ≤ g 2 + 2 T ℓt . [sent-92, score-0.268]
</p><p>36 t=1 Although the Perceptron is guaranteed to be competitive with any ﬁxed hypothesis g ∈ HK , the fact that its active set can grow without a bound poses a serious computational problem. [sent-93, score-0.416]
</p><p>37 In fact, this problem is common to most kernel-based online methods that do not explicitly monitor the size of It . [sent-94, score-0.253]
</p><p>38 As discussed above, our goal is to derive and analyze an online prediction algorithm which resolves these problems by enforcing a ﬁxed bound on the size of the active set. [sent-95, score-0.628]
</p><p>39 Formally, let B be a positive integer, which we refer to as the budget parameter. [sent-96, score-0.262]
</p><p>40 We would like to devise an algorithm which enforces the constraint |It | ≤ B on every round t. [sent-97, score-0.364]
</p><p>41 Furthermore, we would like to prove a relative mistake bound for this algorithm, analogous to the bound stated in Thm. [sent-98, score-0.533]
</p><p>42 We show this inherent limitation by presenting a simple counterexample which applies to any online algorithm which uses a prediction function of the form given in Eq. [sent-101, score-0.383]
</p><p>43 In this example, we show a hypothesis g ∈ HK and an arbitrarily long sequence of examples such that the algorithm makes a prediction mistake on every single round whereas g suffers no loss at all. [sent-103, score-0.97]
</p><p>44 Now for every t, ft is a linear combination of at most B vectors from X . [sent-106, score-0.337]
</p><p>45 Since |X | = B + 1, there exists a vector xt ∈ X which is currently not in the active set. [sent-107, score-0.339]
</p><p>46 Furthermore, xt is orthogonal to all of the active vectors and therefore ft (xt ) = 0. [sent-108, score-0.64]
</p><p>47 Assume without loss of generality that the online algorithm we  are using predicts yt to be −1 when ft (x) = 0. [sent-109, score-0.664]
</p><p>48 If on every round we were to present the online algorithm with the example (xt , +1) then the online algorithm would make a B+1 prediction mistake on every round. [sent-110, score-1.266]
</p><p>49 We have found a sequence of examples and a ﬁxed hypothesis (which is indeed deﬁned by more than B vectors from X ) that attains a cumulative loss of zero on this sequence, while the number of mistakes made by the online algorithm equals the number of rounds. [sent-112, score-0.659]
</p><p>50 Formally, we wish to devise an online algorithm which is competitive with every hypothesis g ∈ HK for which g ≤ U , for some constant U . [sent-117, score-0.487]
</p><p>51 Our counterexample indicates that we cannot prove a relative mistake bound with U set to at √ least B + 1, since that was the norm of g in our counterexample. [sent-118, score-0.482]
</p><p>52 In this paper we come ¯ close to this upper bound by proving that our algorithms can compete with any hypothesis 1 with a norm bounded by 4 (B + 1)/ log(B + 1). [sent-119, score-0.317]
</p><p>53 Recall that whenever the Perceptron makes a prediction mistake, it updates its hypothesis by adding the element t to It . [sent-121, score-0.259]
</p><p>54 Thus, on any given round, the size of its active set equals the number of prediction mistakes it has made so far. [sent-122, score-0.445]
</p><p>55 This implies that the Perceptron may violate the budget constraint |It | ≤ B. [sent-123, score-0.262]
</p><p>56 We can solve this problem by removing an example from the active set whenever its size exceeds B. [sent-124, score-0.263]
</p><p>57 One simple strategy is to remove the oldest example in the active set whenever |It | > B. [sent-125, score-0.298]
</p><p>58 Let t be a round on which the Perceptron makes a prediction mistake. [sent-126, score-0.331]
</p><p>59 Otherwise, we apply a removal step by ﬁnding the ′ ′ oldest example in the active set, rt = min It , and setting It+1 = It \ {rt }. [sent-131, score-0.546]
</p><p>60 The resulting algorithm is a simple modiﬁcation of the kernel Perceptron, which conforms with a ﬁxed budget constraint. [sent-132, score-0.312]
</p><p>61 While we are unable to prove a mistake bound for this algorithm, it is nonetheless an important milestone on the path to an algorithm with a ﬁxed budget and a formal mistake bound. [sent-133, score-1.091]
</p><p>62 The removal of the oldest active example from It may signiﬁcantly change the hypothesis and effect its accuracy. [sent-134, score-0.519]
</p><p>63 By controlling the weight of the oldest active example, we can guarantee that the removal step will not signiﬁcantly effect the accuracy of our predictions. [sent-136, score-0.456]
</p><p>64 More formally, we redeﬁne our hypothesis to be, ft = i∈It  σi,t yi K(xi , ·) ,  where each σi,t is a weight in (0, 1]. [sent-137, score-0.457]
</p><p>65 On round t, if a prediction mistake occurs, a three step update is performed. [sent-141, score-0.734]
</p><p>66 The ﬁrst step is the standard Perceptron update, namely, the index t is inserted into the active set and the ′ weight σt,t is set to be 1. [sent-142, score-0.275]
</p><p>67 Let It denote the active set which results from this update, and let ft′ denote the resulting hypothesis, ft′ (x) = ft (x) + yt K(xt , x). [sent-143, score-0.609]
</p><p>68 The second step of the update is a shrinking step in which we scale f ′ by a coefﬁcient φt ∈ (0, 1]. [sent-144, score-0.309]
</p><p>69 If the shrinking coefﬁcients φt are sufﬁciently small, then the example weights σi,t decrease rapidly with t, and particularly the weight of the oldest active example can be made arbitrarily small. [sent-152, score-0.529]
</p><p>70 Alas, aggressively shrinking the online hypothesis with every update might itself degrade the performance of the online hypothesis and therefore φt should not be set too small. [sent-154, score-0.991]
</p><p>71 To formalize this tradeoff, we begin with the mistake bound in Thm. [sent-156, score-0.416]
</p><p>72 1 and investigate how it is effected by the shrinking and removal steps. [sent-157, score-0.319]
</p><p>73 Let J denote the set of rounds on which the Forgetron makes a prediction mistake and deﬁne the function, Ψ(σ , φ , µ) = (σ φ)2 + 2 σ φ(1 − φ µ) . [sent-159, score-0.51]
</p><p>74 On this round, example rt is removed from the active set. [sent-161, score-0.338]
</p><p>75 Let µt = yrt ft′ (xrt ) be the signed margin attained by ft′ on the active example being removed. [sent-162, score-0.238]
</p><p>76 Lemma 1 below states that removing example rt from the active set on round t increases the mistake bound by Ψt . [sent-164, score-0.975]
</p><p>77 In addition, it is clear from the deﬁnition of Ψt that µt also plays a key role in determining whether xrt can be safely removed from the active set. [sent-166, score-0.254]
</p><p>78 We note in passing that [2] used a heuristic criterion similar to µt to dynamically choose which active example to remove on each online round. [sent-167, score-0.42]
</p><p>79 Turning to the shrinking step, for every t ∈ J we deﬁne,  if ft+1 ≥ U  1 φt if ft′ ≤ U ∧ ft+1 < U Φt =  φt ft′ if ft′ > U ∧ ft+1 < U U  . [sent-168, score-0.236]
</p><p>80 Lemma 1 below also states that applying the shrinking step on round t increases the mistake bound by U 2 log(1/Φt ). [sent-169, score-0.875]
</p><p>81 Note that if ft+1 ≥ U then Φt = 1 and the shrinking step on round t has no effect on our mistake bound. [sent-170, score-0.81]
</p><p>82 Intuitively, this is due to the fact that, in this case, the shrinking step does not make the norm of ft+1 smaller than the norm of our competitor, g. [sent-171, score-0.305]
</p><p>83 , (xT , yT ) be a sequence of examples such that K(xt , xt ) ≤ 1 for all t and assume that this sequence is presented to the Forgetron with a budget constraint ˆ B. [sent-176, score-0.541]
</p><p>84 The ﬁrst term in the bound of Lemma 1 is identical to the mistake bound of the standard Perceptron, given in Thm. [sent-179, score-0.481]
</p><p>85 The second term is the consequence of the removal and shrinking steps. [sent-181, score-0.319]
</p><p>86 If we set the shrinking coefﬁcients in such a way that the second term is at ˆ most M , then the bound in Lemma 1 reduces to M ≤ g 2 + 2 t ℓt + M . [sent-182, score-0.265]
</p><p>87 In the next section, we deﬁne the speciﬁc mechanism used by the Forgetron algorithm to choose the shrinking coefﬁcients φt . [sent-188, score-0.236]
</p><p>88 Then, we conclude our analysis by arguing that this choice satisﬁes the sufﬁcient conditions stated in Lemma 2, and obtain a mistake bound as described above. [sent-189, score-0.468]
</p><p>89 In words, Jt is the set of rounds on which the algorithm made a mistake up until round t, and Mt is the size of this set. [sent-193, score-0.712]
</p><p>90 Let i denote a round on which the algorithm makes a prediction mistake and on which an example must be removed from 15 the active set. [sent-201, score-0.937]
</p><p>91 To prove a mistake bound it sufﬁces to show that the two conditions stated in Lemma 2 hold. [sent-210, score-0.468]
</p><p>92 I NPUT: Mercer kernel K(·, ·) ; budget parameter B > 0 I NITIALIZE : I1 = ∅ ; f1 ≡ 0 ; Q1 = 0 ; M0 = 0 For t = 1, 2, . [sent-214, score-0.276]
</p><p>93 , (xT , yT ) be a sequence of examples such that K(xt , xt ) ≤ 1 for all t. [sent-222, score-0.239]
</p><p>94 Then, the number of prediction 4 mistakes made by the Forgetron on this sequence is at most, T  M ≤ 2 g  2  ˆ ℓt  + 4 t=1  5 Experiments and Discussion In this section we present preliminary experimental results which demonstrate the merits of the Forgetron algorithm. [sent-226, score-0.27]
</p><p>95 When the CKS algorithm exceeds its budget, it removes the active example whose margin would be the largest after the removal. [sent-228, score-0.296]
</p><p>96 For each budget value, we ran the two algorithms on all 126 binary problems and averaged the results. [sent-232, score-0.291]
</p><p>97 05 1000  2000  3000  4000  budget size − B  5000  6000  200  400  600  800 1000 1200 1400 1600 1800  budget size − B  Figure 2: The error of different budget algorithms as a function of the budget size B on the censusincome (adult) dataset (left) and on the MNIST dataset (right). [sent-249, score-1.105]
</p><p>98 In this paper we described the Forgetron algorithm which is a kernel-based online learning algorithm with a ﬁxed memory budget. [sent-259, score-0.356]
</p><p>99 We 4 further argued that no algorithm with a√ budget of B active examples can be competitive with every hypothesis whose norm is B + 1, on every input sequence. [sent-261, score-0.782]
</p><p>100 The analysis presented in this paper can be used to derive a family of online algorithms of which the Forgetron is only one special case. [sent-263, score-0.252]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('forgetron', 0.462), ('mistake', 0.351), ('ft', 0.301), ('perceptron', 0.266), ('budget', 0.239), ('online', 0.231), ('round', 0.224), ('shrinking', 0.2), ('active', 0.189), ('xt', 0.15), ('hypothesis', 0.127), ('rt', 0.119), ('removal', 0.119), ('cks', 0.106), ('yt', 0.096), ('lemma', 0.093), ('hk', 0.092), ('mistakes', 0.092), ('mt', 0.086), ('prediction', 0.085), ('oldest', 0.084), ('qt', 0.07), ('bound', 0.065), ('jt', 0.062), ('hypotheses', 0.058), ('yf', 0.053), ('memory', 0.053), ('rounds', 0.052), ('stated', 0.052), ('margin', 0.049), ('examples', 0.049), ('formal', 0.049), ('sequence', 0.04), ('qi', 0.04), ('mercer', 0.039), ('update', 0.039), ('classi', 0.038), ('kernel', 0.037), ('every', 0.036), ('algorithm', 0.036), ('sign', 0.036), ('entertains', 0.035), ('initializes', 0.035), ('xrt', 0.035), ('mnist', 0.035), ('step', 0.035), ('norm', 0.035), ('competitive', 0.035), ('crammer', 0.032), ('ei', 0.031), ('binary', 0.031), ('innerproduct', 0.031), ('fth', 0.031), ('bordes', 0.031), ('dekel', 0.031), ('rb', 0.031), ('counterexample', 0.031), ('dataset', 0.031), ('equals', 0.03), ('prede', 0.03), ('removed', 0.03), ('weight', 0.029), ('cation', 0.029), ('mi', 0.027), ('removing', 0.027), ('made', 0.027), ('cumulative', 0.027), ('label', 0.026), ('claims', 0.026), ('kandola', 0.026), ('merits', 0.026), ('abbreviate', 0.026), ('namely', 0.026), ('xi', 0.025), ('whenever', 0.025), ('compete', 0.025), ('bounded', 0.024), ('enforces', 0.023), ('constraint', 0.023), ('datasets', 0.023), ('coef', 0.023), ('let', 0.023), ('ready', 0.022), ('devise', 0.022), ('adult', 0.022), ('removes', 0.022), ('labels', 0.022), ('stored', 0.022), ('formally', 0.022), ('makes', 0.022), ('size', 0.022), ('inserted', 0.022), ('cients', 0.021), ('algorithms', 0.021), ('zj', 0.021), ('weston', 0.02), ('proving', 0.02), ('ji', 0.02), ('observes', 0.019), ('hebrew', 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="191-tfidf-1" href="./nips-2005-The_Forgetron%3A_A_Kernel-Based_Perceptron_on_a_Fixed_Budget.html">191 nips-2005-The Forgetron: A Kernel-Based Perceptron on a Fixed Budget</a></p>
<p>Author: Ofer Dekel, Shai Shalev-shwartz, Yoram Singer</p><p>Abstract: The Perceptron algorithm, despite its simplicity, often performs well on online classiﬁcation tasks. The Perceptron becomes especially effective when it is used in conjunction with kernels. However, a common difﬁculty encountered when implementing kernel-based online algorithms is the amount of memory required to store the online hypothesis, which may grow unboundedly. In this paper we present and analyze the Forgetron algorithm for kernel-based online learning on a ﬁxed memory budget. To our knowledge, this is the ﬁrst online learning algorithm which, on one hand, maintains a strict limit on the number of examples it stores while, on the other hand, entertains a relative mistake bound. In addition to the formal results, we also present experiments with real datasets which underscore the merits of our approach.</p><p>2 0.16877653 <a title="191-tfidf-2" href="./nips-2005-From_Batch_to_Transductive_Online_Learning.html">76 nips-2005-From Batch to Transductive Online Learning</a></p>
<p>Author: Sham Kakade, Adam Tauman Kalai</p><p>Abstract: It is well-known that everything that is learnable in the difﬁcult online setting, where an arbitrary sequences of examples must be labeled one at a time, is also learnable in the batch setting, where examples are drawn independently from a distribution. We show a result in the opposite direction. We give an efﬁcient conversion algorithm from batch to online that is transductive: it uses future unlabeled data. This demonstrates the equivalence between what is properly and efﬁciently learnable in a batch model and a transductive online model.</p><p>3 0.16353661 <a title="191-tfidf-3" href="./nips-2005-Data-Driven_Online_to_Batch_Conversions.html">54 nips-2005-Data-Driven Online to Batch Conversions</a></p>
<p>Author: Ofer Dekel, Yoram Singer</p><p>Abstract: Online learning algorithms are typically fast, memory efﬁcient, and simple to implement. However, many common learning problems ﬁt more naturally in the batch learning setting. The power of online learning algorithms can be exploited in batch settings by using online-to-batch conversions techniques which build a new batch algorithm from an existing online algorithm. We ﬁrst give a uniﬁed overview of three existing online-to-batch conversion techniques which do not use training data in the conversion process. We then build upon these data-independent conversions to derive and analyze data-driven conversions. Our conversions ﬁnd hypotheses with a small risk by explicitly minimizing datadependent generalization bounds. We experimentally demonstrate the usefulness of our approach and in particular show that the data-driven conversions consistently outperform the data-independent conversions.</p><p>4 0.13363706 <a title="191-tfidf-4" href="./nips-2005-Coarse_sample_complexity_bounds_for_active_learning.html">41 nips-2005-Coarse sample complexity bounds for active learning</a></p>
<p>Author: Sanjoy Dasgupta</p><p>Abstract: We characterize the sample complexity of active learning problems in terms of a parameter which takes into account the distribution over the input space, the speciﬁc target hypothesis, and the desired accuracy.</p><p>5 0.1140236 <a title="191-tfidf-5" href="./nips-2005-Convex_Neural_Networks.html">50 nips-2005-Convex Neural Networks</a></p>
<p>Author: Yoshua Bengio, Nicolas L. Roux, Pascal Vincent, Olivier Delalleau, Patrice Marcotte</p><p>Abstract: Convexity has recently received a lot of attention in the machine learning community, and the lack of convexity has been seen as a major disadvantage of many learning algorithms, such as multi-layer artiﬁcial neural networks. We show that training multi-layer neural networks in which the number of hidden units is learned can be viewed as a convex optimization problem. This problem involves an inﬁnite number of variables, but can be solved by incrementally inserting a hidden unit at a time, each time ﬁnding a linear classiﬁer that minimizes a weighted sum of errors. 1</p><p>6 0.097612403 <a title="191-tfidf-6" href="./nips-2005-Improved_risk_tail_bounds_for_on-line_algorithms.html">95 nips-2005-Improved risk tail bounds for on-line algorithms</a></p>
<p>7 0.096195348 <a title="191-tfidf-7" href="./nips-2005-Faster_Rates_in_Regression_via_Active_Learning.html">74 nips-2005-Faster Rates in Regression via Active Learning</a></p>
<p>8 0.084962428 <a title="191-tfidf-8" href="./nips-2005-Dynamic_Social_Network_Analysis_using_Latent_Space_Models.html">60 nips-2005-Dynamic Social Network Analysis using Latent Space Models</a></p>
<p>9 0.077364117 <a title="191-tfidf-9" href="./nips-2005-Conditional_Visual_Tracking_in_Kernel_Space.html">45 nips-2005-Conditional Visual Tracking in Kernel Space</a></p>
<p>10 0.067450434 <a title="191-tfidf-10" href="./nips-2005-Online_Discovery_and_Learning_of_Predictive_State_Representations.html">148 nips-2005-Online Discovery and Learning of Predictive State Representations</a></p>
<p>11 0.066877626 <a title="191-tfidf-11" href="./nips-2005-Active_Learning_for_Misspecified_Models.html">19 nips-2005-Active Learning for Misspecified Models</a></p>
<p>12 0.064535365 <a title="191-tfidf-12" href="./nips-2005-Off-policy_Learning_with_Options_and_Recognizers.html">144 nips-2005-Off-policy Learning with Options and Recognizers</a></p>
<p>13 0.064490855 <a title="191-tfidf-13" href="./nips-2005-Gaussian_Process_Dynamical_Models.html">80 nips-2005-Gaussian Process Dynamical Models</a></p>
<p>14 0.063996404 <a title="191-tfidf-14" href="./nips-2005-Learning_from_Data_of_Variable_Quality.html">117 nips-2005-Learning from Data of Variable Quality</a></p>
<p>15 0.061581515 <a title="191-tfidf-15" href="./nips-2005-Query_by_Committee_Made_Real.html">160 nips-2005-Query by Committee Made Real</a></p>
<p>16 0.0596736 <a title="191-tfidf-16" href="./nips-2005-Distance_Metric_Learning_for_Large_Margin_Nearest_Neighbor_Classification.html">57 nips-2005-Distance Metric Learning for Large Margin Nearest Neighbor Classification</a></p>
<p>17 0.057250481 <a title="191-tfidf-17" href="./nips-2005-Generalization_to_Unseen_Cases.html">85 nips-2005-Generalization to Unseen Cases</a></p>
<p>18 0.056946043 <a title="191-tfidf-18" href="./nips-2005-Maximum_Margin_Semi-Supervised_Learning_for_Structured_Variables.html">123 nips-2005-Maximum Margin Semi-Supervised Learning for Structured Variables</a></p>
<p>19 0.055682819 <a title="191-tfidf-19" href="./nips-2005-Laplacian_Score_for_Feature_Selection.html">104 nips-2005-Laplacian Score for Feature Selection</a></p>
<p>20 0.054538801 <a title="191-tfidf-20" href="./nips-2005-Analysis_of_Spectral_Kernel_Design_based_Semi-supervised_Learning.html">27 nips-2005-Analysis of Spectral Kernel Design based Semi-supervised Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2005_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.172), (1, 0.054), (2, 0.014), (3, -0.082), (4, 0.127), (5, 0.106), (6, 0.068), (7, 0.086), (8, -0.065), (9, 0.13), (10, -0.146), (11, 0.278), (12, -0.011), (13, -0.127), (14, 0.021), (15, -0.158), (16, -0.093), (17, 0.001), (18, -0.049), (19, 0.005), (20, -0.045), (21, 0.046), (22, 0.058), (23, 0.005), (24, 0.124), (25, -0.022), (26, 0.002), (27, 0.003), (28, 0.03), (29, -0.057), (30, -0.037), (31, 0.01), (32, -0.0), (33, -0.059), (34, 0.018), (35, -0.05), (36, 0.093), (37, 0.023), (38, -0.05), (39, -0.044), (40, -0.016), (41, 0.001), (42, -0.045), (43, -0.029), (44, 0.102), (45, 0.069), (46, 0.058), (47, 0.007), (48, -0.015), (49, 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96121657 <a title="191-lsi-1" href="./nips-2005-The_Forgetron%3A_A_Kernel-Based_Perceptron_on_a_Fixed_Budget.html">191 nips-2005-The Forgetron: A Kernel-Based Perceptron on a Fixed Budget</a></p>
<p>Author: Ofer Dekel, Shai Shalev-shwartz, Yoram Singer</p><p>Abstract: The Perceptron algorithm, despite its simplicity, often performs well on online classiﬁcation tasks. The Perceptron becomes especially effective when it is used in conjunction with kernels. However, a common difﬁculty encountered when implementing kernel-based online algorithms is the amount of memory required to store the online hypothesis, which may grow unboundedly. In this paper we present and analyze the Forgetron algorithm for kernel-based online learning on a ﬁxed memory budget. To our knowledge, this is the ﬁrst online learning algorithm which, on one hand, maintains a strict limit on the number of examples it stores while, on the other hand, entertains a relative mistake bound. In addition to the formal results, we also present experiments with real datasets which underscore the merits of our approach.</p><p>2 0.82807404 <a title="191-lsi-2" href="./nips-2005-Data-Driven_Online_to_Batch_Conversions.html">54 nips-2005-Data-Driven Online to Batch Conversions</a></p>
<p>Author: Ofer Dekel, Yoram Singer</p><p>Abstract: Online learning algorithms are typically fast, memory efﬁcient, and simple to implement. However, many common learning problems ﬁt more naturally in the batch learning setting. The power of online learning algorithms can be exploited in batch settings by using online-to-batch conversions techniques which build a new batch algorithm from an existing online algorithm. We ﬁrst give a uniﬁed overview of three existing online-to-batch conversion techniques which do not use training data in the conversion process. We then build upon these data-independent conversions to derive and analyze data-driven conversions. Our conversions ﬁnd hypotheses with a small risk by explicitly minimizing datadependent generalization bounds. We experimentally demonstrate the usefulness of our approach and in particular show that the data-driven conversions consistently outperform the data-independent conversions.</p><p>3 0.76878083 <a title="191-lsi-3" href="./nips-2005-From_Batch_to_Transductive_Online_Learning.html">76 nips-2005-From Batch to Transductive Online Learning</a></p>
<p>Author: Sham Kakade, Adam Tauman Kalai</p><p>Abstract: It is well-known that everything that is learnable in the difﬁcult online setting, where an arbitrary sequences of examples must be labeled one at a time, is also learnable in the batch setting, where examples are drawn independently from a distribution. We show a result in the opposite direction. We give an efﬁcient conversion algorithm from batch to online that is transductive: it uses future unlabeled data. This demonstrates the equivalence between what is properly and efﬁciently learnable in a batch model and a transductive online model.</p><p>4 0.64908302 <a title="191-lsi-4" href="./nips-2005-Coarse_sample_complexity_bounds_for_active_learning.html">41 nips-2005-Coarse sample complexity bounds for active learning</a></p>
<p>Author: Sanjoy Dasgupta</p><p>Abstract: We characterize the sample complexity of active learning problems in terms of a parameter which takes into account the distribution over the input space, the speciﬁc target hypothesis, and the desired accuracy.</p><p>5 0.56003928 <a title="191-lsi-5" href="./nips-2005-Improved_risk_tail_bounds_for_on-line_algorithms.html">95 nips-2005-Improved risk tail bounds for on-line algorithms</a></p>
<p>Author: NicolĂ˛ Cesa-bianchi, Claudio Gentile</p><p>Abstract: We prove the strongest known bound for the risk of hypotheses selected from the ensemble generated by running a learning algorithm incrementally on the training data. Our result is based on proof techniques that are remarkably different from the standard risk analysis based on uniform convergence arguments.</p><p>6 0.4257606 <a title="191-lsi-6" href="./nips-2005-Query_by_Committee_Made_Real.html">160 nips-2005-Query by Committee Made Real</a></p>
<p>7 0.39478493 <a title="191-lsi-7" href="./nips-2005-Faster_Rates_in_Regression_via_Active_Learning.html">74 nips-2005-Faster Rates in Regression via Active Learning</a></p>
<p>8 0.37909776 <a title="191-lsi-8" href="./nips-2005-Learning_from_Data_of_Variable_Quality.html">117 nips-2005-Learning from Data of Variable Quality</a></p>
<p>9 0.37090024 <a title="191-lsi-9" href="./nips-2005-Conditional_Visual_Tracking_in_Kernel_Space.html">45 nips-2005-Conditional Visual Tracking in Kernel Space</a></p>
<p>10 0.36307901 <a title="191-lsi-10" href="./nips-2005-Online_Discovery_and_Learning_of_Predictive_State_Representations.html">148 nips-2005-Online Discovery and Learning of Predictive State Representations</a></p>
<p>11 0.36180335 <a title="191-lsi-11" href="./nips-2005-Convex_Neural_Networks.html">50 nips-2005-Convex Neural Networks</a></p>
<p>12 0.34840599 <a title="191-lsi-12" href="./nips-2005-Active_Learning_for_Misspecified_Models.html">19 nips-2005-Active Learning for Misspecified Models</a></p>
<p>13 0.34624273 <a title="191-lsi-13" href="./nips-2005-Generalization_to_Unseen_Cases.html">85 nips-2005-Generalization to Unseen Cases</a></p>
<p>14 0.34532076 <a title="191-lsi-14" href="./nips-2005-Factorial_Switching_Kalman_Filters_for_Condition_Monitoring_in_Neonatal_Intensive_Care.html">68 nips-2005-Factorial Switching Kalman Filters for Condition Monitoring in Neonatal Intensive Care</a></p>
<p>15 0.33479187 <a title="191-lsi-15" href="./nips-2005-Maximum_Margin_Semi-Supervised_Learning_for_Structured_Variables.html">123 nips-2005-Maximum Margin Semi-Supervised Learning for Structured Variables</a></p>
<p>16 0.31902632 <a title="191-lsi-16" href="./nips-2005-Dynamic_Social_Network_Analysis_using_Latent_Space_Models.html">60 nips-2005-Dynamic Social Network Analysis using Latent Space Models</a></p>
<p>17 0.31541139 <a title="191-lsi-17" href="./nips-2005-Fast_Online_Policy_Gradient_Learning_with_SMD_Gain_Vector_Adaptation.html">72 nips-2005-Fast Online Policy Gradient Learning with SMD Gain Vector Adaptation</a></p>
<p>18 0.31367835 <a title="191-lsi-18" href="./nips-2005-Gaussian_Processes_for_Multiuser_Detection_in_CDMA_receivers.html">81 nips-2005-Gaussian Processes for Multiuser Detection in CDMA receivers</a></p>
<p>19 0.29869324 <a title="191-lsi-19" href="./nips-2005-Off-policy_Learning_with_Options_and_Recognizers.html">144 nips-2005-Off-policy Learning with Options and Recognizers</a></p>
<p>20 0.28810847 <a title="191-lsi-20" href="./nips-2005-A_PAC-Bayes_approach_to_the_Set_Covering_Machine.html">12 nips-2005-A PAC-Bayes approach to the Set Covering Machine</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2005_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.094), (10, 0.048), (13, 0.277), (27, 0.03), (31, 0.026), (34, 0.104), (41, 0.01), (55, 0.038), (69, 0.047), (73, 0.037), (88, 0.097), (91, 0.076)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.80553997 <a title="191-lda-1" href="./nips-2005-The_Forgetron%3A_A_Kernel-Based_Perceptron_on_a_Fixed_Budget.html">191 nips-2005-The Forgetron: A Kernel-Based Perceptron on a Fixed Budget</a></p>
<p>Author: Ofer Dekel, Shai Shalev-shwartz, Yoram Singer</p><p>Abstract: The Perceptron algorithm, despite its simplicity, often performs well on online classiﬁcation tasks. The Perceptron becomes especially effective when it is used in conjunction with kernels. However, a common difﬁculty encountered when implementing kernel-based online algorithms is the amount of memory required to store the online hypothesis, which may grow unboundedly. In this paper we present and analyze the Forgetron algorithm for kernel-based online learning on a ﬁxed memory budget. To our knowledge, this is the ﬁrst online learning algorithm which, on one hand, maintains a strict limit on the number of examples it stores while, on the other hand, entertains a relative mistake bound. In addition to the formal results, we also present experiments with real datasets which underscore the merits of our approach.</p><p>2 0.58137351 <a title="191-lda-2" href="./nips-2005-Learning_Minimum_Volume_Sets.html">112 nips-2005-Learning Minimum Volume Sets</a></p>
<p>Author: Clayton Scott, Robert Nowak</p><p>Abstract: Given a probability measure P and a reference measure µ, one is often interested in the minimum µ-measure set with P -measure at least α. Minimum volume sets of this type summarize the regions of greatest probability mass of P , and are useful for detecting anomalies and constructing conﬁdence regions. This paper addresses the problem of estimating minimum volume sets based on independent samples distributed according to P . Other than these samples, no other information is available regarding P , but the reference measure µ is assumed to be known. We introduce rules for estimating minimum volume sets that parallel the empirical risk minimization and structural risk minimization principles in classiﬁcation. As in classiﬁcation, we show that the performances of our estimators are controlled by the rate of uniform convergence of empirical to true probabilities over the class from which the estimator is drawn. Thus we obtain ﬁnite sample size performance bounds in terms of VC dimension and related quantities. We also demonstrate strong universal consistency and an oracle inequality. Estimators based on histograms and dyadic partitions illustrate the proposed rules. 1</p><p>3 0.57422048 <a title="191-lda-3" href="./nips-2005-Faster_Rates_in_Regression_via_Active_Learning.html">74 nips-2005-Faster Rates in Regression via Active Learning</a></p>
<p>Author: Rebecca Willett, Robert Nowak, Rui M. Castro</p><p>Abstract: This paper presents a rigorous statistical analysis characterizing regimes in which active learning signiﬁcantly outperforms classical passive learning. Active learning algorithms are able to make queries or select sample locations in an online fashion, depending on the results of the previous queries. In some regimes, this extra ﬂexibility leads to signiﬁcantly faster rates of error decay than those possible in classical passive learning settings. The nature of these regimes is explored by studying fundamental performance limits of active and passive learning in two illustrative nonparametric function classes. In addition to examining the theoretical potential of active learning, this paper describes a practical algorithm capable of exploiting the extra ﬂexibility of the active setting and provably improving upon the classical passive techniques. Our active learning theory and methods show promise in a number of applications, including ﬁeld estimation using wireless sensor networks and fault line detection. 1</p><p>4 0.57348007 <a title="191-lda-4" href="./nips-2005-Convergence_and_Consistency_of_Regularized_Boosting_Algorithms_with_Stationary_B-Mixing_Observations.html">49 nips-2005-Convergence and Consistency of Regularized Boosting Algorithms with Stationary B-Mixing Observations</a></p>
<p>Author: Aurelie C. Lozano, Sanjeev R. Kulkarni, Robert E. Schapire</p><p>Abstract: We study the statistical convergence and consistency of regularized Boosting methods, where the samples are not independent and identically distributed (i.i.d.) but come from empirical processes of stationary β-mixing sequences. Utilizing a technique that constructs a sequence of independent blocks close in distribution to the original samples, we prove the consistency of the composite classiﬁers resulting from a regularization achieved by restricting the 1-norm of the base classiﬁers’ weights. When compared to the i.i.d. case, the nature of sampling manifests in the consistency result only through generalization of the original condition on the growth of the regularization parameter.</p><p>5 0.57278442 <a title="191-lda-5" href="./nips-2005-Size_Regularized_Cut_for_Data_Clustering.html">177 nips-2005-Size Regularized Cut for Data Clustering</a></p>
<p>Author: Yixin Chen, Ya Zhang, Xiang Ji</p><p>Abstract: We present a novel spectral clustering method that enables users to incorporate prior knowledge of the size of clusters into the clustering process. The cost function, which is named size regularized cut (SRcut), is deﬁned as the sum of the inter-cluster similarity and a regularization term measuring the relative size of two clusters. Finding a partition of the data set to minimize SRcut is proved to be NP-complete. An approximation algorithm is proposed to solve a relaxed version of the optimization problem as an eigenvalue problem. Evaluations over different data sets demonstrate that the method is not sensitive to outliers and performs better than normalized cut. 1</p><p>6 0.57218236 <a title="191-lda-6" href="./nips-2005-Convex_Neural_Networks.html">50 nips-2005-Convex Neural Networks</a></p>
<p>7 0.56966704 <a title="191-lda-7" href="./nips-2005-Coarse_sample_complexity_bounds_for_active_learning.html">41 nips-2005-Coarse sample complexity bounds for active learning</a></p>
<p>8 0.56843513 <a title="191-lda-8" href="./nips-2005-Non-Gaussian_Component_Analysis%3A_a_Semi-parametric_Framework_for_Linear_Dimension_Reduction.html">137 nips-2005-Non-Gaussian Component Analysis: a Semi-parametric Framework for Linear Dimension Reduction</a></p>
<p>9 0.56769174 <a title="191-lda-9" href="./nips-2005-Query_by_Committee_Made_Real.html">160 nips-2005-Query by Committee Made Real</a></p>
<p>10 0.56766355 <a title="191-lda-10" href="./nips-2005-Hyperparameter_and_Kernel_Learning_for_Graph_Based_Semi-Supervised_Classification.html">92 nips-2005-Hyperparameter and Kernel Learning for Graph Based Semi-Supervised Classification</a></p>
<p>11 0.56581533 <a title="191-lda-11" href="./nips-2005-Augmented_Rescorla-Wagner_and_Maximum_Likelihood_Estimation.html">32 nips-2005-Augmented Rescorla-Wagner and Maximum Likelihood Estimation</a></p>
<p>12 0.56467783 <a title="191-lda-12" href="./nips-2005-Consistency_of_one-class_SVM_and_related_algorithms.html">47 nips-2005-Consistency of one-class SVM and related algorithms</a></p>
<p>13 0.56450796 <a title="191-lda-13" href="./nips-2005-Comparing_the_Effects_of_Different_Weight_Distributions_on_Finding_Sparse_Representations.html">43 nips-2005-Comparing the Effects of Different Weight Distributions on Finding Sparse Representations</a></p>
<p>14 0.56361109 <a title="191-lda-14" href="./nips-2005-An_Approximate_Inference_Approach_for_the_PCA_Reconstruction_Error.html">24 nips-2005-An Approximate Inference Approach for the PCA Reconstruction Error</a></p>
<p>15 0.56283087 <a title="191-lda-15" href="./nips-2005-Divergences%2C_surrogate_loss_functions_and_experimental_design.html">58 nips-2005-Divergences, surrogate loss functions and experimental design</a></p>
<p>16 0.56270909 <a title="191-lda-16" href="./nips-2005-Data-Driven_Online_to_Batch_Conversions.html">54 nips-2005-Data-Driven Online to Batch Conversions</a></p>
<p>17 0.5625639 <a title="191-lda-17" href="./nips-2005-Preconditioner_Approximations_for_Probabilistic_Graphical_Models.html">154 nips-2005-Preconditioner Approximations for Probabilistic Graphical Models</a></p>
<p>18 0.56051183 <a title="191-lda-18" href="./nips-2005-Variational_Bayesian_Stochastic_Complexity_of_Mixture_Models.html">201 nips-2005-Variational Bayesian Stochastic Complexity of Mixture Models</a></p>
<p>19 0.56013018 <a title="191-lda-19" href="./nips-2005-Nearest_Neighbor_Based_Feature_Selection_for_Regression_and_its_Application_to_Neural_Activity.html">132 nips-2005-Nearest Neighbor Based Feature Selection for Regression and its Application to Neural Activity</a></p>
<p>20 0.5591405 <a title="191-lda-20" href="./nips-2005-Estimation_of_Intrinsic_Dimensionality_Using_High-Rate_Vector_Quantization.html">66 nips-2005-Estimation of Intrinsic Dimensionality Using High-Rate Vector Quantization</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
