<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>55 nips-2005-Describing Visual Scenes using Transformed Dirichlet Processes</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2005" href="../home/nips2005_home.html">nips2005</a> <a title="nips-2005-55" href="#">nips2005-55</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>55 nips-2005-Describing Visual Scenes using Transformed Dirichlet Processes</h1>
<br/><p>Source: <a title="nips-2005-55-pdf" href="http://papers.nips.cc/paper/2772-describing-visual-scenes-using-transformed-dirichlet-processes.pdf">pdf</a></p><p>Author: Antonio Torralba, Alan S. Willsky, Erik B. Sudderth, William T. Freeman</p><p>Abstract: Motivated by the problem of learning to detect and recognize objects with minimal supervision, we develop a hierarchical probabilistic model for the spatial structure of visual scenes. In contrast with most existing models, our approach explicitly captures uncertainty in the number of object instances depicted in a given image. Our scene model is based on the transformed Dirichlet process (TDP), a novel extension of the hierarchical DP in which a set of stochastically transformed mixture components are shared between multiple groups of data. For visual scenes, mixture components describe the spatial structure of visual features in an object–centered coordinate frame, while transformations model the object positions in a particular image. Learning and inference in the TDP, which has many potential applications beyond computer vision, is based on an empirically effective Gibbs sampler. Applied to a dataset of partially labeled street scenes, we show that the TDP’s inclusion of spatial structure improves detection performance, ﬂexibly exploiting partially labeled training images. 1</p><p>Reference: <a title="nips-2005-55-reference" href="../nips2005_reference/nips-2005-Describing_Visual_Scenes_using_Transformed_Dirichlet_Processes_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract Motivated by the problem of learning to detect and recognize objects with minimal supervision, we develop a hierarchical probabilistic model for the spatial structure of visual scenes. [sent-9, score-0.335]
</p><p>2 In contrast with most existing models, our approach explicitly captures uncertainty in the number of object instances depicted in a given image. [sent-10, score-0.159]
</p><p>3 Our scene model is based on the transformed Dirichlet process (TDP), a novel extension of the hierarchical DP in which a set of stochastically transformed mixture components are shared between multiple groups of data. [sent-11, score-0.705]
</p><p>4 For visual scenes, mixture components describe the spatial structure of visual features in an object–centered coordinate frame, while transformations model the object positions in a particular image. [sent-12, score-0.575]
</p><p>5 1  Introduction  In this paper, we develop methods for analyzing the features composing a visual scene, thereby localizing and categorizing the objects in an image. [sent-15, score-0.216]
</p><p>6 We would like to design learning algorithms that exploit relationships among multiple, partially labeled object categories during training. [sent-16, score-0.253]
</p><p>7 Working towards this goal, we propose a hierarchical probabilistic model for the expected spatial locations of objects, and the appearance of visual features corresponding to each object. [sent-17, score-0.298]
</p><p>8 In contrast, generative approaches can discover large, visually salient categories (such as foliage and buildings [2]) without supervision. [sent-21, score-0.17]
</p><p>9 Partial segmentations can then be used to learn semantically interesting categories (such as cars and pedestrians) which are less visually distinctive, or present in fewer training images. [sent-22, score-0.164]
</p><p>10 Moreover, generative models provide a natural framework for learning contextual relationships between objects, and transferring knowledge between related, but distinct, visual scenes. [sent-23, score-0.136]
</p><p>11 Constellation  LDA  Transformed DP  Figure 1: A scene with faces as described by three generative models. [sent-24, score-0.127]
</p><p>12 Note: The LDA and TDP images are sampled from models learned from training images, while the Constellation image is a hand-constructed illustration. [sent-28, score-0.132]
</p><p>13 The principal challenge in developing hierarchical models for scenes is specifying tractable, scalable methods for handling uncertainty in the number of objects. [sent-29, score-0.204]
</p><p>14 We address this problem using Dirichlet processes [3], a tool from nonparametric Bayesian analysis for learning mixture models whose number of components is not ﬁxed, but instead estimated from data. [sent-31, score-0.132]
</p><p>15 In particular, we extend the recently proposed hierarchical Dirichlet process (HDP) [4, 5] framework to allow more ﬂexible sharing of mixture components between images. [sent-32, score-0.228]
</p><p>16 The resulting transformed Dirichlet process (TDP) is naturally suited to our scene understanding application, as well as many other domains where “style and content” are combined to produce the observed data [6]. [sent-33, score-0.235]
</p><p>17 2 by reviewing several related generative models for objects and scenes. [sent-35, score-0.15]
</p><p>18 5 by demonstrating object recognition and segmentation in street scenes. [sent-40, score-0.238]
</p><p>19 2  Generative Models for Objects and Scenes  Constellation models [7] describe single objects via the appearance of a ﬁxed, and typically small, set of spatially constrained parts (see Fig. [sent-41, score-0.159]
</p><p>20 Although they can successfully recognize objects in cluttered backgrounds, they do not directly provide a mechanism for detecting multiple object instances. [sent-43, score-0.293]
</p><p>21 In addition, it seems difﬁcult to generalize the ﬁxed set of constellation parts to problems where the number of objects is uncertain. [sent-44, score-0.163]
</p><p>22 More recently, distributions over hierarchical tree–structured partitions of image pixels have been used to segment simple scenes [9, 10]. [sent-46, score-0.256]
</p><p>23 In addition, an image parsing [11] framework has been proposed which explains an image using a set of regions generated by generic or object–speciﬁc processes. [sent-47, score-0.136]
</p><p>24 Inspired by techniques from the text analysis literature, several recent papers analyze scenes using a spatially unstructured bag of features extracted from local image patches (see Fig. [sent-51, score-0.232]
</p><p>25 In particular, latent Dirichlet allocation (LDA) [13] describes the features xji in image j using a K component mixture model with parameters θk . [sent-53, score-0.36]
</p><p>26 Each image reuses these same mixture parameters in different proportions πj (see the graphical model of Fig. [sent-54, score-0.199]
</p><p>27 By appropriately deﬁning these shared mixtures, LDA may be used to discover object cat-  egories from images of single objects [2], categorize natural scenes [14], and (with a slight extension) parse presegmented captioned images [15]. [sent-56, score-0.524]
</p><p>28 While these LDA models are sometimes effective, their neglect of spatial structure ignores valuable information which is critical in challenging object detection tasks. [sent-57, score-0.231]
</p><p>29 We recently proposed a hierarchical extension of LDA which learns shared parts describing the internal structure of objects, and contextual relationships among known groups of objects [16]. [sent-58, score-0.423]
</p><p>30 The transformed Dirichlet process (TDP) addresses a key limitation of this model by allowing uncertainty in the number and identity of the objects depicted in each image. [sent-59, score-0.258]
</p><p>31 1, the TDP effectively provides a textural model in which locally unstructured clumps of features are given global spatial structure by the inferred set of objects underlying each scene. [sent-62, score-0.278]
</p><p>32 We then introduce the transformed Dirichlet process (TDP) (Sec. [sent-68, score-0.148]
</p><p>33 Computationally, this process is conveniently described by a set z of independently sampled variables zi ∼ Mult(β) indicating the component of the mixture G(θ) (see eq. [sent-83, score-0.176]
</p><p>34 This process is sometimes described by analogy to a Chinese restaurant in which the (inﬁnite collection of) tables correspond to the mixture components θk , and customers to observations xi [4]. [sent-90, score-0.385]
</p><p>35 Customers are social, tending to sit at tables with many other customers (observations), and each table shares a single dish (parameter). [sent-91, score-0.336]
</p><p>36 For example, in this paper’s applications each group is an image, and the data are visual features composing a scene. [sent-94, score-0.164]
</p><p>37 , xjnj ) denote the nj exchangeable data points in group j. [sent-98, score-0.155]
</p><p>38 LDA directly assigns observations xji to clusters via indicators zji . [sent-103, score-0.34]
</p><p>39 HDP and TDP models use “table” indicators tji as an intermediary between observations and assignments kjt to an inﬁnite global mixture with weights β. [sent-104, score-0.743]
</p><p>40 Specializing the TDP to visual scenes (right), we model the position yji and appearance wji of features using distributions ηo indexed by unobserved object categories oji . [sent-106, score-0.778]
</p><p>41 To construct an HDP, a global probability measure G0 ∼ DP(γ, H) is ﬁrst chosen to deﬁne a set of shared mixture components. [sent-108, score-0.181]
</p><p>42 The generative process underlying HDPs may be understood in terms of an extension of the DP analogy known as the Chinese restaurant franchise [4]. [sent-112, score-0.204]
</p><p>43 Each group deﬁnes a separate restaurant in which customers (observations) xji sit at tables tji . [sent-113, score-0.689]
</p><p>44 Each table shares a single dish (parameter) θ, which is ordered from a menu G0 shared among restaurants (groups). [sent-114, score-0.202]
</p><p>45 Letting kjt indicate the parameter θkjt assigned to table t in group j, we may integrate over G0 and Gj (as in eq. [sent-115, score-0.442]
</p><p>46 As before, customers prefer tables t at which many customers njt are already seated (eq. [sent-126, score-0.27]
</p><p>47 Each new table is assigned a dish kj t according to eq. [sent-128, score-0.203]
</p><p>48 Given the assignments tj and kj for group j, observations are sampled as xji ∼ F (θzji ), where zji = kjtji indexes the shared parameters assigned to the table associated with xji . [sent-133, score-0.802]
</p><p>49 2, the group distributions Gj are derived from the global distribution G0 by resampling the mixture weights from a Dirichlet process (see eq. [sent-136, score-0.204]
</p><p>50 Consider, for example,  a Gaussian distribution describing the location at which object features are detected in an image. [sent-139, score-0.24]
</p><p>51 While the covariance of that distribution may stay relatively constant across object instances, the mean will change dramatically from image to image (group to group), depending on the objects’ position relative to the camera. [sent-140, score-0.263]
</p><p>52 Motivated by these difﬁculties, we propose the Transformed Dirichlet Process (TDP), an extension of the HDP in which global mixture components undergo a set of random transformations before being reused in each group. [sent-141, score-0.333]
</p><p>53 (1) to create a global measure describing both parameters and transformations: ∞  βk δ(θ, θk )q(ρ | φk )  G0 (θ, ρ) =  θk ∼ H  φk ∼ R  (6)  k=1  As before, β is sampled from a stick–breaking process with parameter γ. [sent-144, score-0.139]
</p><p>54 Marginalizing over transformations ρ, Gj (θ) reuses parameters from G0 (θ) exactly as in eq. [sent-146, score-0.129]
</p><p>55 Conditioning on θk , it can be shown that Gj (ρ | θk ) ∼ DP(αβk , Q(φk )), so that the proportions ω jk of features associated with each transformation of θk follow a stick–breaking process with parameter αβk . [sent-149, score-0.17]
</p><p>56 ¯ ¯ Each observation xji is now generated by sampling (θji , ρji ) ∼ Gj , and then choosing ¯ ¯ ¯ xji ∼ F (θji , ρji ) from a distribution which transforms θji by ρji . [sent-150, score-0.366]
</p><p>57 Although the global ¯ family of transformation distributions Q(φ) is typically non–atomic, the discreteness of Gj ensures that transformations are shared between observations within group j. [sent-151, score-0.29]
</p><p>58 Computationally, the TDP is more conveniently described via an extension of the Chinese restaurant franchise analogy (see Fig. [sent-152, score-0.138]
</p><p>59 As before, customers (observations) xji sit at tables tji according to the clustering bias of eq. [sent-154, score-0.589]
</p><p>60 (4), and new tables choose dishes according to their popularity across the franchise (eq. [sent-155, score-0.143]
</p><p>61 Now, however, the dish (parameter) θkjt at table t is seasoned (transformed) according to ρjt ∼ q(ρjt | φkjt ). [sent-157, score-0.141]
</p><p>62 The simplest implementation samples table assignments t, cluster assignments k, transformations ρ, and parameters θ, φ. [sent-161, score-0.327]
</p><p>63 Let t−ji denote all table assignments excluding tji , and deﬁne k−jt , ρ−jt similarly. [sent-162, score-0.31]
</p><p>64 2), we have p tji = t | t−ji , k, ρ, θ, x ∝ p t | t−ji f xji | θkjt , ρjt (8) The ﬁrst term is given by eq. [sent-164, score-0.394]
</p><p>65 For a ﬁxed set of transformations ρ, the second term is a simple likelihood evaluation for existing tables, while new tables may be evaluated by marginalizing over possible cluster assignments (eq. [sent-166, score-0.3]
</p><p>66 Right: Global TDP distribution G0 (θ, ρ) over both clusters θ (solid) and translations ρ of those clusters (dashed). [sent-173, score-0.136]
</p><p>67 Conditioned on kjt , we again use conjugacy to sample ρjt . [sent-175, score-0.316]
</p><p>68 For the moment, we assume that the observed data xji = (oji , yji ), where yji is the position of a feature corresponding to object category oji , and the number of object categories O is known (see Fig. [sent-182, score-0.962]
</p><p>69 We then choose cluster parameters θk = (¯k , µk , Λk ) to describe the mean µk and o covariance Λk of a Gaussian distribution over feature positions, as well as the single object category ok assigned to all observations sampled from that cluster. [sent-184, score-0.39]
</p><p>70 Although this cluster ¯ parameterization does not capture contextual relationships between object categories, the results of Sec. [sent-185, score-0.259]
</p><p>71 5 demonstrate that it nevertheless provides an effective model of the spatial variability of individual categories across many different scenes. [sent-186, score-0.141]
</p><p>72 Density models for spatial transformations have been previously used to recognize isolated objects [17], and estimate layered decompositions of video sequences [18]. [sent-189, score-0.28]
</p><p>73 In contrast, the proposed TDP models the variability of object positions across scenes, and couples this with a nonparametric prior allowing uncertainty in the number of objects. [sent-190, score-0.159]
</p><p>74 To ensure that the TDP scene model is identiﬁable, we deﬁne p (ρjt | kj , φ) to be a zero– mean Gaussian with covariance φkjt . [sent-191, score-0.143]
</p><p>75 The parameter prior R is uniform across object categories, while R and H both use inverse–Wishart position distributions, weakly biased towards moderate covariances. [sent-192, score-0.159]
</p><p>76 3 shows a 2D synthetic example based on a single object category (O = 1). [sent-194, score-0.226]
</p><p>77 In contrast, the learned HDP uses a large set of global clusters to discretize the transformations underlying the data, and thus generalizes poorly to new translations. [sent-196, score-0.21]
</p><p>78 1 to images, we must learn the relationship between object categories and visual features. [sent-200, score-0.311]
</p><p>79 We assume that the appearance wji of each detected feature is independently sampled conditioned on the underlying object category oji (see Fig. [sent-204, score-0.484]
</p><p>80 Placing a symmetric Dirichlet prior, with parameter λ, on each category’s multinomial appearance distribution ηo , p wji = b | oji = o, w−ji , t, k, θ ∝ cbo + λ (10) where cbo is the number of times feature b is currently assigned to object o. [sent-206, score-0.476]
</p><p>81 Because a single object category is associated with each cluster, the Gibbs sampler of Sec. [sent-207, score-0.279]
</p><p>82 5  Analyzing Street Scenes  To demonstrate the potential of our TDP scene model, we consider a set of street scene images (250 training, 75 test) from the MIT-CSAIL database. [sent-211, score-0.265]
</p><p>83 All categories were labeled in 112 images, while in the remainder only cars were segmented. [sent-213, score-0.132]
</p><p>84 Training from semi–supervised data is accomplished by restricting object category assignments for segmented features. [sent-214, score-0.293]
</p><p>85 4 shows the four global object clusters learned following 100 Gibbs sampling iterations. [sent-216, score-0.27]
</p><p>86 There is one elongated car cluster, one large building cluster, and two road clusters with differing shapes. [sent-217, score-0.267]
</p><p>87 Interestingly, the model has automatically determined that building features occur in large homogeneous patches, while road features are sparse and better described by many smaller transformed clusters. [sent-218, score-0.321]
</p><p>88 4 shows segmentations produced by averaging these samples, as well as transformed clusters from the ﬁnal iteration. [sent-221, score-0.222]
</p><p>89 Qualitatively, results are typically good, although foliage is often mislabeled as road due to the textural similarities with features detected in shadows across roads. [sent-222, score-0.156]
</p><p>90 For comparison, we also trained an LDA model based solely on feature appearance, allowing three topics per object category and again using object labels to restrict the Gibbs sampler’s assignments [16]. [sent-223, score-0.452]
</p><p>91 4, our TDP model of spatial scene structure signiﬁcantly improves segmentation performance. [sent-225, score-0.165]
</p><p>92 In addition, through the set of transformed car clusters generated by the Gibbs sampler, the TDP explicitly estimates the number of object instances underlying each image. [sent-226, score-0.409]
</p><p>93 These detections, which are not possible using LDA, are based on a single global parsing of the scene which automatically estimates object locations without a “sliding window” [1]. [sent-227, score-0.321]
</p><p>94 6  Discussion  We have developed the transformed Dirichlet process, a hierarchical model which shares a set of stochastically transformed clusters among groups of data. [sent-228, score-0.498]
</p><p>95 Applied to visual scenes, TDPs provide a model of spatial structure which allows the number of objects generating an image to be automatically inferred, and lead to improved detection performance. [sent-229, score-0.292]
</p><p>96 8  1  Figure 4: TDP analysis of street scenes containing cars (red), buildings (green), and roads (blue). [sent-262, score-0.23]
</p><p>97 Top right: Global model G0 describing object shape (solid) and expected transformations (dashed). [sent-263, score-0.291]
</p><p>98 Left: Four test images (ﬁrst row), estimated segmentations of features into object categories (second row), transformed global clusters associated with each image interpretation (third row), and features assigned to different instances of the transformed car cluster (fourth row). [sent-265, score-0.989]
</p><p>99 A Bayesian approach to unsupervised one-shot learning of object categories. [sent-313, score-0.159]
</p><p>100 A Bayesian hierarchical model for learning natural scene categories. [sent-370, score-0.183]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('tdp', 0.527), ('kjt', 0.316), ('jt', 0.275), ('tji', 0.211), ('dirichlet', 0.199), ('xji', 0.183), ('hdp', 0.166), ('object', 0.159), ('lda', 0.141), ('dp', 0.128), ('transformed', 0.122), ('oji', 0.12), ('objects', 0.11), ('scenes', 0.108), ('transformations', 0.099), ('hierarchical', 0.096), ('categories', 0.094), ('gj', 0.091), ('yji', 0.09), ('scene', 0.087), ('ji', 0.085), ('customers', 0.084), ('dish', 0.079), ('road', 0.078), ('gibbs', 0.077), ('mixture', 0.077), ('tables', 0.072), ('clusters', 0.068), ('category', 0.067), ('assignments', 0.067), ('cluster', 0.062), ('shared', 0.061), ('reused', 0.06), ('zji', 0.06), ('car', 0.06), ('stick', 0.06), ('groups', 0.06), ('group', 0.058), ('visual', 0.058), ('jk', 0.056), ('kj', 0.056), ('sampler', 0.053), ('constellation', 0.053), ('wji', 0.052), ('image', 0.052), ('appearance', 0.049), ('features', 0.048), ('street', 0.048), ('spatial', 0.047), ('blog', 0.045), ('dps', 0.045), ('franchise', 0.045), ('hdps', 0.045), ('tdps', 0.045), ('global', 0.043), ('images', 0.043), ('restaurant', 0.042), ('generative', 0.04), ('breaking', 0.04), ('proportions', 0.04), ('sit', 0.039), ('contextual', 0.038), ('cars', 0.038), ('sampled', 0.037), ('zi', 0.036), ('elongated', 0.036), ('buildings', 0.036), ('torralba', 0.036), ('assigned', 0.036), ('nj', 0.035), ('iccv', 0.034), ('chinese', 0.033), ('describing', 0.033), ('table', 0.032), ('parsing', 0.032), ('exchangeable', 0.032), ('segmentations', 0.032), ('segmentation', 0.031), ('cbo', 0.03), ('njt', 0.03), ('reuses', 0.03), ('seasoned', 0.03), ('sudderth', 0.03), ('textural', 0.03), ('unlocalized', 0.03), ('xjnj', 0.03), ('shares', 0.03), ('components', 0.029), ('observations', 0.029), ('dishes', 0.026), ('processes', 0.026), ('process', 0.026), ('analogy', 0.026), ('building', 0.025), ('extension', 0.025), ('detection', 0.025), ('face', 0.024), ('recognize', 0.024), ('descriptors', 0.024), ('bag', 0.024)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999952 <a title="55-tfidf-1" href="./nips-2005-Describing_Visual_Scenes_using_Transformed_Dirichlet_Processes.html">55 nips-2005-Describing Visual Scenes using Transformed Dirichlet Processes</a></p>
<p>Author: Antonio Torralba, Alan S. Willsky, Erik B. Sudderth, William T. Freeman</p><p>Abstract: Motivated by the problem of learning to detect and recognize objects with minimal supervision, we develop a hierarchical probabilistic model for the spatial structure of visual scenes. In contrast with most existing models, our approach explicitly captures uncertainty in the number of object instances depicted in a given image. Our scene model is based on the transformed Dirichlet process (TDP), a novel extension of the hierarchical DP in which a set of stochastically transformed mixture components are shared between multiple groups of data. For visual scenes, mixture components describe the spatial structure of visual features in an object–centered coordinate frame, while transformations model the object positions in a particular image. Learning and inference in the TDP, which has many potential applications beyond computer vision, is based on an empirically effective Gibbs sampler. Applied to a dataset of partially labeled street scenes, we show that the TDP’s inclusion of spatial structure improves detection performance, ﬂexibly exploiting partially labeled training images. 1</p><p>2 0.16336299 <a title="55-tfidf-2" href="./nips-2005-Infinite_latent_feature_models_and_the_Indian_buffet_process.html">98 nips-2005-Infinite latent feature models and the Indian buffet process</a></p>
<p>Author: Zoubin Ghahramani, Thomas L. Griffiths</p><p>Abstract: We deﬁne a probability distribution over equivalence classes of binary matrices with a ﬁnite number of rows and an unbounded number of columns. This distribution is suitable for use as a prior in probabilistic models that represent objects using a potentially inﬁnite array of features. We identify a simple generative process that results in the same distribution over equivalence classes, which we call the Indian buffet process. We illustrate the use of this distribution as a prior in an inﬁnite latent feature model, deriving a Markov chain Monte Carlo algorithm for inference in this model and applying the algorithm to an image dataset. 1</p><p>3 0.13708827 <a title="55-tfidf-3" href="./nips-2005-Context_as_Filtering.html">48 nips-2005-Context as Filtering</a></p>
<p>Author: Daichi Mochihashi, Yuji Matsumoto</p><p>Abstract: Long-distance language modeling is important not only in speech recognition and machine translation, but also in high-dimensional discrete sequence modeling in general. However, the problem of context length has almost been neglected so far and a na¨ve bag-of-words history has been ı employed in natural language processing. In contrast, in this paper we view topic shifts within a text as a latent stochastic process to give an explicit probabilistic generative model that has partial exchangeability. We propose an online inference algorithm using particle ﬁlters to recognize topic shifts to employ the most appropriate length of context automatically. Experiments on the BNC corpus showed consistent improvement over previous methods involving no chronological order. 1</p><p>4 0.13104293 <a title="55-tfidf-4" href="./nips-2005-Efficient_Unsupervised_Learning_for_Localization_and_Detection_in_Object_Categories.html">63 nips-2005-Efficient Unsupervised Learning for Localization and Detection in Object Categories</a></p>
<p>Author: Nicolas Loeff, Himanshu Arora, Alexander Sorokin, David Forsyth</p><p>Abstract: We describe a novel method for learning templates for recognition and localization of objects drawn from categories. A generative model represents the conﬁguration of multiple object parts with respect to an object coordinate system; these parts in turn generate image features. The complexity of the model in the number of features is low, meaning our model is much more efﬁcient to train than comparative methods. Moreover, a variational approximation is introduced that allows learning to be orders of magnitude faster than previous approaches while incorporating many more features. This results in both accuracy and localization improvements. Our model has been carefully tested on standard datasets; we compare with a number of recent template models. In particular, we demonstrate state-of-the-art results for detection and localization. 1</p><p>5 0.12170541 <a title="55-tfidf-5" href="./nips-2005-A_Computational_Model_of_Eye_Movements_during_Object_Class_Detection.html">5 nips-2005-A Computational Model of Eye Movements during Object Class Detection</a></p>
<p>Author: Wei Zhang, Hyejin Yang, Dimitris Samaras, Gregory J. Zelinsky</p><p>Abstract: We present a computational model of human eye movements in an object class detection task. The model combines state-of-the-art computer vision object class detection methods (SIFT features trained using AdaBoost) with a biologically plausible model of human eye movement to produce a sequence of simulated ﬁxations, culminating with the acquisition of a target. We validated the model by comparing its behavior to the behavior of human observers performing the identical object class detection task (looking for a teddy bear among visually complex nontarget objects). We found considerable agreement between the model and human data in multiple eye movement measures, including number of ﬁxations, cumulative probability of ﬁxating the target, and scanpath distance.</p><p>6 0.096638918 <a title="55-tfidf-6" href="./nips-2005-Correlated_Topic_Models.html">52 nips-2005-Correlated Topic Models</a></p>
<p>7 0.085480951 <a title="55-tfidf-7" href="./nips-2005-A_Hierarchical_Compositional_System_for_Rapid_Object_Detection.html">11 nips-2005-A Hierarchical Compositional System for Rapid Object Detection</a></p>
<p>8 0.079965882 <a title="55-tfidf-8" href="./nips-2005-Pattern_Recognition_from_One_Example_by_Chopping.html">151 nips-2005-Pattern Recognition from One Example by Chopping</a></p>
<p>9 0.079900064 <a title="55-tfidf-9" href="./nips-2005-An_Alternative_Infinite_Mixture_Of_Gaussian_Process_Experts.html">21 nips-2005-An Alternative Infinite Mixture Of Gaussian Process Experts</a></p>
<p>10 0.077767409 <a title="55-tfidf-10" href="./nips-2005-Multiple_Instance_Boosting_for_Object_Detection.html">131 nips-2005-Multiple Instance Boosting for Object Detection</a></p>
<p>11 0.077637166 <a title="55-tfidf-11" href="./nips-2005-Scaling_Laws_in_Natural_Scenes_and_the_Inference_of_3D_Shape.html">170 nips-2005-Scaling Laws in Natural Scenes and the Inference of 3D Shape</a></p>
<p>12 0.076730572 <a title="55-tfidf-12" href="./nips-2005-Is_Early_Vision_Optimized_for_Extracting_Higher-order_Dependencies%3F.html">101 nips-2005-Is Early Vision Optimized for Extracting Higher-order Dependencies?</a></p>
<p>13 0.076725066 <a title="55-tfidf-13" href="./nips-2005-Interpolating_between_types_and_tokens_by_estimating_power-law_generators.html">100 nips-2005-Interpolating between types and tokens by estimating power-law generators</a></p>
<p>14 0.07122273 <a title="55-tfidf-14" href="./nips-2005-A_Cortically-Plausible_Inverse_Problem_Solving_Method_Applied_to_Recognizing_Static_and_Kinematic_3D_Objects.html">7 nips-2005-A Cortically-Plausible Inverse Problem Solving Method Applied to Recognizing Static and Kinematic 3D Objects</a></p>
<p>15 0.065293156 <a title="55-tfidf-15" href="./nips-2005-Fusion_of_Similarity_Data_in_Clustering.html">79 nips-2005-Fusion of Similarity Data in Clustering</a></p>
<p>16 0.062804602 <a title="55-tfidf-16" href="./nips-2005-Learning_Shared_Latent_Structure_for_Image_Synthesis_and_Robotic_Imitation.html">115 nips-2005-Learning Shared Latent Structure for Image Synthesis and Robotic Imitation</a></p>
<p>17 0.061091505 <a title="55-tfidf-17" href="./nips-2005-Soft_Clustering_on_Graphs.html">178 nips-2005-Soft Clustering on Graphs</a></p>
<p>18 0.059167162 <a title="55-tfidf-18" href="./nips-2005-Group_and_Topic_Discovery_from_Relations_and_Their_Attributes.html">89 nips-2005-Group and Topic Discovery from Relations and Their Attributes</a></p>
<p>19 0.057660375 <a title="55-tfidf-19" href="./nips-2005-Learning_Depth_from_Single_Monocular_Images.html">110 nips-2005-Learning Depth from Single Monocular Images</a></p>
<p>20 0.057502788 <a title="55-tfidf-20" href="./nips-2005-Layered_Dynamic_Textures.html">108 nips-2005-Layered Dynamic Textures</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2005_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.169), (1, 0.015), (2, -0.02), (3, 0.224), (4, -0.048), (5, -0.089), (6, 0.073), (7, 0.201), (8, -0.102), (9, -0.156), (10, -0.049), (11, -0.016), (12, 0.082), (13, -0.047), (14, -0.1), (15, 0.107), (16, -0.029), (17, -0.033), (18, -0.013), (19, 0.015), (20, -0.028), (21, 0.091), (22, -0.115), (23, 0.062), (24, -0.002), (25, 0.009), (26, 0.025), (27, -0.084), (28, -0.024), (29, -0.059), (30, -0.051), (31, -0.08), (32, -0.004), (33, -0.044), (34, -0.052), (35, 0.015), (36, 0.012), (37, 0.03), (38, 0.022), (39, 0.068), (40, -0.03), (41, -0.031), (42, 0.066), (43, 0.089), (44, -0.028), (45, -0.071), (46, -0.015), (47, 0.065), (48, -0.046), (49, -0.01)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95445013 <a title="55-lsi-1" href="./nips-2005-Describing_Visual_Scenes_using_Transformed_Dirichlet_Processes.html">55 nips-2005-Describing Visual Scenes using Transformed Dirichlet Processes</a></p>
<p>Author: Antonio Torralba, Alan S. Willsky, Erik B. Sudderth, William T. Freeman</p><p>Abstract: Motivated by the problem of learning to detect and recognize objects with minimal supervision, we develop a hierarchical probabilistic model for the spatial structure of visual scenes. In contrast with most existing models, our approach explicitly captures uncertainty in the number of object instances depicted in a given image. Our scene model is based on the transformed Dirichlet process (TDP), a novel extension of the hierarchical DP in which a set of stochastically transformed mixture components are shared between multiple groups of data. For visual scenes, mixture components describe the spatial structure of visual features in an object–centered coordinate frame, while transformations model the object positions in a particular image. Learning and inference in the TDP, which has many potential applications beyond computer vision, is based on an empirically effective Gibbs sampler. Applied to a dataset of partially labeled street scenes, we show that the TDP’s inclusion of spatial structure improves detection performance, ﬂexibly exploiting partially labeled training images. 1</p><p>2 0.76514292 <a title="55-lsi-2" href="./nips-2005-Infinite_latent_feature_models_and_the_Indian_buffet_process.html">98 nips-2005-Infinite latent feature models and the Indian buffet process</a></p>
<p>Author: Zoubin Ghahramani, Thomas L. Griffiths</p><p>Abstract: We deﬁne a probability distribution over equivalence classes of binary matrices with a ﬁnite number of rows and an unbounded number of columns. This distribution is suitable for use as a prior in probabilistic models that represent objects using a potentially inﬁnite array of features. We identify a simple generative process that results in the same distribution over equivalence classes, which we call the Indian buffet process. We illustrate the use of this distribution as a prior in an inﬁnite latent feature model, deriving a Markov chain Monte Carlo algorithm for inference in this model and applying the algorithm to an image dataset. 1</p><p>3 0.68427777 <a title="55-lsi-3" href="./nips-2005-Efficient_Unsupervised_Learning_for_Localization_and_Detection_in_Object_Categories.html">63 nips-2005-Efficient Unsupervised Learning for Localization and Detection in Object Categories</a></p>
<p>Author: Nicolas Loeff, Himanshu Arora, Alexander Sorokin, David Forsyth</p><p>Abstract: We describe a novel method for learning templates for recognition and localization of objects drawn from categories. A generative model represents the conﬁguration of multiple object parts with respect to an object coordinate system; these parts in turn generate image features. The complexity of the model in the number of features is low, meaning our model is much more efﬁcient to train than comparative methods. Moreover, a variational approximation is introduced that allows learning to be orders of magnitude faster than previous approaches while incorporating many more features. This results in both accuracy and localization improvements. Our model has been carefully tested on standard datasets; we compare with a number of recent template models. In particular, we demonstrate state-of-the-art results for detection and localization. 1</p><p>4 0.61728042 <a title="55-lsi-4" href="./nips-2005-A_Hierarchical_Compositional_System_for_Rapid_Object_Detection.html">11 nips-2005-A Hierarchical Compositional System for Rapid Object Detection</a></p>
<p>Author: Long Zhu, Alan L. Yuille</p><p>Abstract: We describe a hierarchical compositional system for detecting deformable objects in images. Objects are represented by graphical models. The algorithm uses a hierarchical tree where the root of the tree corresponds to the full object and lower-level elements of the tree correspond to simpler features. The algorithm proceeds by passing simple messages up and down the tree. The method works rapidly, in under a second, on 320 × 240 images. We demonstrate the approach on detecting cats, horses, and hands. The method works in the presence of background clutter and occlusions. Our approach is contrasted with more traditional methods such as dynamic programming and belief propagation. 1</p><p>5 0.60027629 <a title="55-lsi-5" href="./nips-2005-Context_as_Filtering.html">48 nips-2005-Context as Filtering</a></p>
<p>Author: Daichi Mochihashi, Yuji Matsumoto</p><p>Abstract: Long-distance language modeling is important not only in speech recognition and machine translation, but also in high-dimensional discrete sequence modeling in general. However, the problem of context length has almost been neglected so far and a na¨ve bag-of-words history has been ı employed in natural language processing. In contrast, in this paper we view topic shifts within a text as a latent stochastic process to give an explicit probabilistic generative model that has partial exchangeability. We propose an online inference algorithm using particle ﬁlters to recognize topic shifts to employ the most appropriate length of context automatically. Experiments on the BNC corpus showed consistent improvement over previous methods involving no chronological order. 1</p><p>6 0.59680605 <a title="55-lsi-6" href="./nips-2005-Interpolating_between_types_and_tokens_by_estimating_power-law_generators.html">100 nips-2005-Interpolating between types and tokens by estimating power-law generators</a></p>
<p>7 0.57852209 <a title="55-lsi-7" href="./nips-2005-Pattern_Recognition_from_One_Example_by_Chopping.html">151 nips-2005-Pattern Recognition from One Example by Chopping</a></p>
<p>8 0.46734992 <a title="55-lsi-8" href="./nips-2005-Fusion_of_Similarity_Data_in_Clustering.html">79 nips-2005-Fusion of Similarity Data in Clustering</a></p>
<p>9 0.45353252 <a title="55-lsi-9" href="./nips-2005-Correlated_Topic_Models.html">52 nips-2005-Correlated Topic Models</a></p>
<p>10 0.45231697 <a title="55-lsi-10" href="./nips-2005-A_Computational_Model_of_Eye_Movements_during_Object_Class_Detection.html">5 nips-2005-A Computational Model of Eye Movements during Object Class Detection</a></p>
<p>11 0.40966544 <a title="55-lsi-11" href="./nips-2005-Bayesian_model_learning_in_human_visual_perception.html">35 nips-2005-Bayesian model learning in human visual perception</a></p>
<p>12 0.39774665 <a title="55-lsi-12" href="./nips-2005-Identifying_Distributed_Object_Representations_in_Human_Extrastriate_Visual_Cortex.html">94 nips-2005-Identifying Distributed Object Representations in Human Extrastriate Visual Cortex</a></p>
<p>13 0.39045915 <a title="55-lsi-13" href="./nips-2005-Multiple_Instance_Boosting_for_Object_Detection.html">131 nips-2005-Multiple Instance Boosting for Object Detection</a></p>
<p>14 0.37919515 <a title="55-lsi-14" href="./nips-2005-A_Cortically-Plausible_Inverse_Problem_Solving_Method_Applied_to_Recognizing_Static_and_Kinematic_3D_Objects.html">7 nips-2005-A Cortically-Plausible Inverse Problem Solving Method Applied to Recognizing Static and Kinematic 3D Objects</a></p>
<p>15 0.35720763 <a title="55-lsi-15" href="./nips-2005-Learning_Shared_Latent_Structure_for_Image_Synthesis_and_Robotic_Imitation.html">115 nips-2005-Learning Shared Latent Structure for Image Synthesis and Robotic Imitation</a></p>
<p>16 0.34990332 <a title="55-lsi-16" href="./nips-2005-An_Alternative_Infinite_Mixture_Of_Gaussian_Process_Experts.html">21 nips-2005-An Alternative Infinite Mixture Of Gaussian Process Experts</a></p>
<p>17 0.34685785 <a title="55-lsi-17" href="./nips-2005-Searching_for_Character_Models.html">171 nips-2005-Searching for Character Models</a></p>
<p>18 0.3447738 <a title="55-lsi-18" href="./nips-2005-Learning_Depth_from_Single_Monocular_Images.html">110 nips-2005-Learning Depth from Single Monocular Images</a></p>
<p>19 0.32342443 <a title="55-lsi-19" href="./nips-2005-Scaling_Laws_in_Natural_Scenes_and_the_Inference_of_3D_Shape.html">170 nips-2005-Scaling Laws in Natural Scenes and the Inference of 3D Shape</a></p>
<p>20 0.32136008 <a title="55-lsi-20" href="./nips-2005-Correcting_sample_selection_bias_in_maximum_entropy_density_estimation.html">51 nips-2005-Correcting sample selection bias in maximum entropy density estimation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2005_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.045), (10, 0.031), (27, 0.035), (31, 0.057), (34, 0.047), (39, 0.038), (47, 0.024), (55, 0.017), (57, 0.011), (69, 0.054), (73, 0.439), (88, 0.073), (91, 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.92296422 <a title="55-lda-1" href="./nips-2005-Laplacian_Score_for_Feature_Selection.html">104 nips-2005-Laplacian Score for Feature Selection</a></p>
<p>Author: Xiaofei He, Deng Cai, Partha Niyogi</p><p>Abstract: In supervised learning scenarios, feature selection has been studied widely in the literature. Selecting features in unsupervised learning scenarios is a much harder problem, due to the absence of class labels that would guide the search for relevant information. And, almost all of previous unsupervised feature selection methods are “wrapper” techniques that require a learning algorithm to evaluate the candidate feature subsets. In this paper, we propose a “ﬁlter” method for feature selection which is independent of any learning algorithm. Our method can be performed in either supervised or unsupervised fashion. The proposed method is based on the observation that, in many real world classiﬁcation problems, data from the same class are often close to each other. The importance of a feature is evaluated by its power of locality preserving, or, Laplacian Score. We compare our method with data variance (unsupervised) and Fisher score (supervised) on two data sets. Experimental results demonstrate the effectiveness and efﬁciency of our algorithm. 1</p><p>2 0.91050869 <a title="55-lda-2" href="./nips-2005-Fast_Krylov_Methods_for_N-Body_Learning.html">71 nips-2005-Fast Krylov Methods for N-Body Learning</a></p>
<p>Author: Nando D. Freitas, Yang Wang, Maryam Mahdaviani, Dustin Lang</p><p>Abstract: This paper addresses the issue of numerical computation in machine learning domains based on similarity metrics, such as kernel methods, spectral techniques and Gaussian processes. It presents a general solution strategy based on Krylov subspace iteration and fast N-body learning methods. The experiments show signiﬁcant gains in computation and storage on datasets arising in image segmentation, object detection and dimensionality reduction. The paper also presents theoretical bounds on the stability of these methods.</p><p>same-paper 3 0.90289271 <a title="55-lda-3" href="./nips-2005-Describing_Visual_Scenes_using_Transformed_Dirichlet_Processes.html">55 nips-2005-Describing Visual Scenes using Transformed Dirichlet Processes</a></p>
<p>Author: Antonio Torralba, Alan S. Willsky, Erik B. Sudderth, William T. Freeman</p><p>Abstract: Motivated by the problem of learning to detect and recognize objects with minimal supervision, we develop a hierarchical probabilistic model for the spatial structure of visual scenes. In contrast with most existing models, our approach explicitly captures uncertainty in the number of object instances depicted in a given image. Our scene model is based on the transformed Dirichlet process (TDP), a novel extension of the hierarchical DP in which a set of stochastically transformed mixture components are shared between multiple groups of data. For visual scenes, mixture components describe the spatial structure of visual features in an object–centered coordinate frame, while transformations model the object positions in a particular image. Learning and inference in the TDP, which has many potential applications beyond computer vision, is based on an empirically effective Gibbs sampler. Applied to a dataset of partially labeled street scenes, we show that the TDP’s inclusion of spatial structure improves detection performance, ﬂexibly exploiting partially labeled training images. 1</p><p>4 0.83437598 <a title="55-lda-4" href="./nips-2005-Using_%60%60epitomes%27%27_to_model_genetic_diversity%3A_Rational_design_of_HIV_vaccine_cocktails.html">198 nips-2005-Using ``epitomes'' to model genetic diversity: Rational design of HIV vaccine cocktails</a></p>
<p>Author: Nebojsa Jojic, Vladimir Jojic, Christopher Meek, David Heckerman, Brendan J. Frey</p><p>Abstract: We introduce a new model of genetic diversity which summarizes a large input dataset into an epitome, a short sequence or a small set of short sequences of probability distributions capturing many overlapping subsequences from the dataset. The epitome as a representation has already been used in modeling real-valued signals, such as images and audio. The discrete sequence model we introduce in this paper targets applications in genetics, from multiple alignment to recombination and mutation inference. In our experiments, we concentrate on modeling the diversity of HIV where the epitome emerges as a natural model for producing relatively small vaccines covering a large number of immune system targets known as epitopes. Our experiments show that the epitome includes more epitopes than other vaccine designs of similar length, including cocktails of consensus strains, phylogenetic tree centers, and observed strains. We also discuss epitome designs that take into account uncertainty about Tcell cross reactivity and epitope presentation. In our experiments, we ﬁnd that vaccine optimization is fairly robust to these uncertainties. 1</p><p>5 0.81837112 <a title="55-lda-5" href="./nips-2005-Analysis_of_Spectral_Kernel_Design_based_Semi-supervised_Learning.html">27 nips-2005-Analysis of Spectral Kernel Design based Semi-supervised Learning</a></p>
<p>Author: Tong Zhang, Rie Kubota Ando</p><p>Abstract: We consider a framework for semi-supervised learning using spectral decomposition based un-supervised kernel design. This approach subsumes a class of previously proposed semi-supervised learning methods on data graphs. We examine various theoretical properties of such methods. In particular, we derive a generalization performance bound, and obtain the optimal kernel design by minimizing the bound. Based on the theoretical analysis, we are able to demonstrate why spectral kernel design based methods can often improve the predictive performance. Experiments are used to illustrate the main consequences of our analysis.</p><p>6 0.63368398 <a title="55-lda-6" href="./nips-2005-Kernelized_Infomax_Clustering.html">102 nips-2005-Kernelized Infomax Clustering</a></p>
<p>7 0.57865804 <a title="55-lda-7" href="./nips-2005-A_Probabilistic_Approach_for_Optimizing_Spectral_Clustering.html">13 nips-2005-A Probabilistic Approach for Optimizing Spectral Clustering</a></p>
<p>8 0.56018966 <a title="55-lda-8" href="./nips-2005-Tensor_Subspace_Analysis.html">189 nips-2005-Tensor Subspace Analysis</a></p>
<p>9 0.55548197 <a title="55-lda-9" href="./nips-2005-Nearest_Neighbor_Based_Feature_Selection_for_Regression_and_its_Application_to_Neural_Activity.html">132 nips-2005-Nearest Neighbor Based Feature Selection for Regression and its Application to Neural Activity</a></p>
<p>10 0.53665459 <a title="55-lda-10" href="./nips-2005-Generalization_in_Clustering_with_Unobserved_Features.html">84 nips-2005-Generalization in Clustering with Unobserved Features</a></p>
<p>11 0.52320993 <a title="55-lda-11" href="./nips-2005-Infinite_latent_feature_models_and_the_Indian_buffet_process.html">98 nips-2005-Infinite latent feature models and the Indian buffet process</a></p>
<p>12 0.51601863 <a title="55-lda-12" href="./nips-2005-Diffusion_Maps%2C_Spectral_Clustering_and_Eigenfunctions_of_Fokker-Planck_Operators.html">56 nips-2005-Diffusion Maps, Spectral Clustering and Eigenfunctions of Fokker-Planck Operators</a></p>
<p>13 0.50986004 <a title="55-lda-13" href="./nips-2005-Soft_Clustering_on_Graphs.html">178 nips-2005-Soft Clustering on Graphs</a></p>
<p>14 0.49742812 <a title="55-lda-14" href="./nips-2005-From_Lasso_regression_to_Feature_vector_machine.html">77 nips-2005-From Lasso regression to Feature vector machine</a></p>
<p>15 0.49547225 <a title="55-lda-15" href="./nips-2005-Efficient_Unsupervised_Learning_for_Localization_and_Detection_in_Object_Categories.html">63 nips-2005-Efficient Unsupervised Learning for Localization and Detection in Object Categories</a></p>
<p>16 0.49434045 <a title="55-lda-16" href="./nips-2005-Size_Regularized_Cut_for_Data_Clustering.html">177 nips-2005-Size Regularized Cut for Data Clustering</a></p>
<p>17 0.47863841 <a title="55-lda-17" href="./nips-2005-Correcting_sample_selection_bias_in_maximum_entropy_density_estimation.html">51 nips-2005-Correcting sample selection bias in maximum entropy density estimation</a></p>
<p>18 0.47525913 <a title="55-lda-18" href="./nips-2005-A_Domain_Decomposition_Method_for_Fast_Manifold_Learning.html">9 nips-2005-A Domain Decomposition Method for Fast Manifold Learning</a></p>
<p>19 0.47310331 <a title="55-lda-19" href="./nips-2005-Non-Gaussian_Component_Analysis%3A_a_Semi-parametric_Framework_for_Linear_Dimension_Reduction.html">137 nips-2005-Non-Gaussian Component Analysis: a Semi-parametric Framework for Linear Dimension Reduction</a></p>
<p>20 0.47278279 <a title="55-lda-20" href="./nips-2005-Context_as_Filtering.html">48 nips-2005-Context as Filtering</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
