<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>73 nips-2005-Fast biped walking with a reflexive controller and real-time policy searching</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2005" href="../home/nips2005_home.html">nips2005</a> <a title="nips-2005-73" href="#">nips2005-73</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>73 nips-2005-Fast biped walking with a reflexive controller and real-time policy searching</h1>
<br/><p>Source: <a title="nips-2005-73-pdf" href="http://papers.nips.cc/paper/2769-fast-biped-walking-with-a-reflexive-controller-and-real-time-policy-searching.pdf">pdf</a></p><p>Author: Tao Geng, Bernd Porr, Florentin Wörgötter</p><p>Abstract: In this paper, we present our design and experiments of a planar biped robot (“RunBot”) under pure reﬂexive neuronal control. The goal of this study is to combine neuronal mechanisms with biomechanics to obtain very fast speed and the on-line learning of circuit parameters. Our controller is built with biologically inspired sensor- and motor-neuron models, including local reﬂexes and not employing any kind of position or trajectory-tracking control algorithm. Instead, this reﬂexive controller allows RunBot to exploit its own natural dynamics during critical stages of its walking gait cycle. To our knowledge, this is the ﬁrst time that dynamic biped walking is achieved using only a pure reﬂexive controller. In addition, this structure allows using a policy gradient reinforcement learning algorithm to tune the parameters of the reﬂexive controller in real-time during walking. This way RunBot can reach a relative speed of 3.5 leg-lengths per second after a few minutes of online learning, which is faster than that of any other biped robot, and is also comparable to the fastest relative speed of human walking. In addition, the stability domain of stable walking is quite large supporting this design strategy. 1</p><p>Reference: <a title="nips-2005-73-reference" href="../nips2005_reference/nips-2005-Fast_biped_walking_with_a_reflexive_controller_and_real-time_policy_searching_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Fast biped walking with a reﬂexive controller and real-time policy searching  3  Tao Geng1 , Bernd Porr2 and Florentin W¨ rg¨ tter1,3 o o 1 Dept. [sent-1, score-0.978]
</p><p>2 de  Abstract In this paper, we present our design and experiments of a planar biped robot (“RunBot”) under pure reﬂexive neuronal control. [sent-13, score-0.634]
</p><p>3 Our controller is built with biologically inspired sensor- and motor-neuron models, including local reﬂexes and not employing any kind of position or trajectory-tracking control algorithm. [sent-15, score-0.361]
</p><p>4 Instead, this reﬂexive controller allows RunBot to exploit its own natural dynamics during critical stages of its walking gait cycle. [sent-16, score-0.752]
</p><p>5 To our knowledge, this is the ﬁrst time that dynamic biped walking is achieved using only a pure reﬂexive controller. [sent-17, score-0.784]
</p><p>6 In addition, this structure allows using a policy gradient reinforcement learning algorithm to tune the parameters of the reﬂexive controller in real-time during walking. [sent-18, score-0.274]
</p><p>7 5 leg-lengths per second after a few minutes of online learning, which is faster than that of any other biped robot, and is also comparable to the fastest relative speed of human walking. [sent-20, score-0.455]
</p><p>8 In addition, the stability domain of stable walking is quite large supporting this design strategy. [sent-21, score-0.424]
</p><p>9 1  Introduction  Building and controlling fast biped robots demands a deeper understanding of biped walking than for slow robots. [sent-22, score-1.255]
</p><p>10 While slow robots may walk statically, fast biped walking has to be dynamically balanced and more robust as less time is available to recover from disturbances [1]. [sent-23, score-0.92]
</p><p>11 Although many biped robots have been developed using various technologies in the past 20 years, their walking speeds are still not comparable to that of their counterpart in nature, humans. [sent-24, score-0.842]
</p><p>12 Most of the successful biped robots have commonly used the ZMP (Zero Moment Point, [2]) as the criterion for stability control and motion generation. [sent-25, score-0.608]
</p><p>13 To ensure  an appropriate stability margin, the foot has to be ﬂat and large, which will deteriorate the robot’s performance and pose great difﬁculty during fast walking. [sent-29, score-0.245]
</p><p>14 Second, the ZMP criterion does not permit rotation of the stance foot at the heel or the toe, which, however, can amount to up to eighty percent of a normal human walking gait, and is important and inevitable in fast biped walking. [sent-31, score-1.014]
</p><p>15 On the other hand, sometimes dynamic biped walking can be achieved without considering any stability criterion such as the ZMP. [sent-32, score-0.817]
</p><p>16 For example, passive biped robots can walk down a shallow slope without sensing or control. [sent-33, score-0.589]
</p><p>17 Some researchers have proposed approaches to equip a passive biped with actuators to improve its performance and drive it to walk on the ﬂat ground [3] [4]. [sent-34, score-0.55]
</p><p>18 Nevertheless, these passive bipeds excessively depend on their natural dynamics for gait generation, which, while making their gaits efﬁcient in energy, also limits their walking rate to be very slow. [sent-35, score-0.685]
</p><p>19 In this study, we will show that, with a properly designed mechanical structure, a novel, pure reﬂexive controller, and an online policy gradient reinforcement learning algorithm, our biped robot can attain a fast walking speed of 3. [sent-36, score-1.267]
</p><p>20 This makes it faster than any other biped robot we know. [sent-38, score-0.6]
</p><p>21 Though not a passive biped, it exploits its own natural dynamics during some stages of its walking gait, greatly simplifying the necessary control structures. [sent-39, score-0.549]
</p><p>22 A hard mechanical stop is installed on the knee joints, preventing it from going into hyperextension. [sent-44, score-0.179]
</p><p>23 Each foot is equipped with a modiﬁed piezo transducer to sense ground contact events. [sent-45, score-0.335]
</p><p>24 Similar to other approaches [1], we constrain the robot only in the sagittal plane by a boom of one meter length freely rotating in its joints (planar robot). [sent-46, score-0.424]
</p><p>25 C) A series of sequential frames of a walking gait cycle. [sent-51, score-0.494]
</p><p>26 Note that, during the time between frame (8) and frame (13), which is nearly one third of the duration of a step, the motor voltage of all four joints remain to be zero, and the whole robot is moving passively. [sent-53, score-0.418]
</p><p>27 At the time of frame (13), the swing leg touches the ﬂoor and a next step begins. [sent-54, score-0.184]
</p><p>28 Since we intended to exploit RunBot’s natural dynamics during some stages of its gait  cycle; similar to passive bipeds; its foot bottom is also curved with a radius equal to half the leg-length (with a too large radius, the tip of the foot may strike the ground during its swing phase). [sent-55, score-0.717]
</p><p>29 During the stance phase of such a curved foot, always only one point touches the ground, thus allowing the robot to roll passively around the contact point, which is similar to the rolling action of human feet facilitating fast walking. [sent-56, score-0.641]
</p><p>30 The most important consideration in the mechanical design of our robot is the location of its center of mass. [sent-57, score-0.271]
</p><p>31 The parts of the trunk are assembled in such a way that its center of mass is located before the hip axis (Fig. [sent-59, score-0.251]
</p><p>32 As shown, one walking step includes two stages, the ﬁrst from (1) to (2), the second from (2) to (3). [sent-63, score-0.357]
</p><p>33 During the ﬁrst stage, the robot has to use its own momentum to rise up on the stance leg. [sent-64, score-0.329]
</p><p>34 When walking at a low speed, the robot may have not enough momentum to do this. [sent-65, score-0.607]
</p><p>35 In the second stage, the robot just falls forward naturally and catches itself on the next stance leg. [sent-67, score-0.308]
</p><p>36 The ﬁgure also shows clearly the rolling movement of the curved foot of the stance leg. [sent-69, score-0.298]
</p><p>37 A stance phase begins with the heel touching ground, and terminates with the toe leaving ground. [sent-70, score-0.171]
</p><p>38 3  The neural structure of our reﬂexive controller  The reﬂexive walking controller of RunBot follows a hierarchical structure (Fig. [sent-72, score-0.737]
</p><p>39 The bottom level is the reﬂex circuit local to the joints, including motor-neurons and angle sensor neurons involved in the joint reﬂexes. [sent-74, score-0.324]
</p><p>40 The top level is a distributed neural network consisting of hip stretch receptors and ground contact sensor neurons, which modulate the local reﬂexes of the bottom level. [sent-75, score-0.795]
</p><p>41 Neurons are modelled as non-spiking neurons simulated on a Linux PC, and communicated to the robot via the DA/AD board. [sent-76, score-0.284]
</p><p>42 1  Model neuron circuit of the top level  The joint coordination mechanism in the top level is implemented with the neuron circuit illustrated in Fig. [sent-79, score-0.34]
</p><p>43 Furthermore, the function of the stretch receptor on our robot is only to trigger the extensor reﬂex on the knee joint of the same leg, rather than to implicitly reset the phase relations between different legs as in the case of Cruse’s model. [sent-82, score-0.775]
</p><p>44 This  Figure 2: The neuron model of reﬂexive controller on RunBot. [sent-84, score-0.27]
</p><p>45 model is inspired by a sensor neuron model presented in [5] that is thought capable of emulating the response characteristics of populations of sensor neurons in animals. [sent-85, score-0.388]
</p><p>46 Another kind of sensor neuron incorporated in the top level is the ground contact sensor neuron, which is active when the foot is in contact with the ground. [sent-86, score-0.716]
</p><p>47 2  Neural circuit of the bottom level  The bottom-level reﬂex system of our robot consists of reﬂexes local to each joint (Fig. [sent-89, score-0.349]
</p><p>48 The neuron module for one reﬂex is composed of one angle sensor neuron and the motorneuron it contacts. [sent-91, score-0.309]
</p><p>49 Each joint is equipped with two reﬂexes, extensor reﬂex and ﬂexor reﬂex, both are modelled as a monosynaptic reﬂex, that is, whenever its threshold is exceeded, the angle sensor neuron directly excites the corresponding motor-neuron. [sent-92, score-0.432]
</p><p>50 This direct connection between angle sensor neuron and motor-neuron is inspired by a reﬂex described in cockroach locomotion [6]. [sent-93, score-0.361]
</p><p>51 Each joint has two angle sensor neurons, one for the extensor reﬂex, and the other for the ﬂexor reﬂex (Fig. [sent-95, score-0.352]
</p><p>52 Their models are similar to that of the stretch receptors described above. [sent-97, score-0.249]
</p><p>53 The extensor angle sensor neuron changes its output according to: ρES = 1 + eαES (ΘES −φ)  −1  (5)  where φ is the real time angular position obtained from the potentiometer of the joint. [sent-98, score-0.444]
</p><p>54 Likewise, the output of  Table 1: Parameters of neurons for hip- and knee joints. [sent-100, score-0.192]
</p><p>55 Hip Joints Knee Joints  ΘEM 5 5  ΘF M 5 5  αES 2 2  αF S 2 2  Table 2: Parameters of stretch receptors and ground contact sensor neurons. [sent-103, score-0.523]
</p><p>56 ΘGL (v) 2  ΘGR (v) 2  ΘAL (deg) = ΘES  ΘAR (deg) = ΘES  αGL 2  αGR 2  αAL 2  αAR 2  the ﬂexor sensor neuron is modelled as: ρF S = (1 + eαF S (φ−ΘF S ) )−1  (6)  with ΘF S and αF S similar as above. [sent-104, score-0.184]
</p><p>57 The direction of extensor on both hip and knee joints is forward while that of ﬂexors is backward. [sent-105, score-0.631]
</p><p>58 The motor-neuron model is adapted from one used in the neural controller of a hexapod simulating insect locomotion [7]. [sent-107, score-0.334]
</p><p>59 τ is a time constant associated with the passive properties of the cell membrane [8], ωX represents the connection strength from the sensor neurons and stretch receptors to the motor-neuron neuron (Fig. [sent-110, score-0.556]
</p><p>60 ρX represents the output of the sensor-neurons and stretch receptors that contact this motor-neuron (e. [sent-112, score-0.344]
</p><p>61 4  Robot walking experiments  The model neuron parameters chosen jointly for all experiments are listed in Tables 1 and 2. [sent-120, score-0.437]
</p><p>62 9GM,h  the inhibitory connections are set to -10, except those between sensor-neurons and motorneurons, which are -30, and those between stretch receptors and ﬂexor motor-neurons, which are -15. [sent-124, score-0.249]
</p><p>63 The weights of all excitatory connections are 10, except those between stretch receptors and extensor motor-neurons, which are 15. [sent-125, score-0.392]
</p><p>64 Because the movements of the knee joints is needed mainly for timely ground clearance without big contributions to the walking speed, we set their neuron parameters to ﬁxed values (see Table 3 ). [sent-126, score-0.801]
</p><p>65 So, in the experiments described below, we only need to tune the two parameters of the hip joints, the threshold of the extensor sensor neurons (ΘES,h ) and the gain of the motor-neurons (GM,h ), which work together to determine the walking speed and the important gait properties of RunBot. [sent-128, score-1.104]
</p><p>66 In RunBot, ΘES,h determines roughly the stride length (not exactly, because the hip joint moves passively after passing ΘES,h ), while GM,h is proportional to the angular velocity of the motor on the hip joint. [sent-129, score-0.643]
</p><p>67 In experiments of walking on a ﬂat ﬂoor, surprisingly, we have found that stable gaits can appear in a considerably large range of the parameters ΘES,h and GM,h (Fig. [sent-130, score-0.414]
</p><p>68 5 (higher value will destroy the motor of the hip joint). [sent-134, score-0.257]
</p><p>69 (B), Phase diagrams of hip joint position and knee joint position of one leg during the whole learning process. [sent-136, score-0.667]
</p><p>70 (C), The walking speed of RunBot during the learning process. [sent-138, score-0.441]
</p><p>71 In RunBot, passive movements appear on two levels, at the single joint level and at the whole robot level. [sent-139, score-0.409]
</p><p>72 Due to the high gear ratio of the joint motors, the passive movement of each joint is not very large. [sent-140, score-0.188]
</p><p>73 Whereas the effects of passive movements at the whole robot level can be clearly seen especially when RunBot is walking at a medium or slow speed (Fig. [sent-141, score-0.79]
</p><p>74 1  Policy gradient searching for fast walking gaits  In order to get a fast walking speed, the biped robot should have a long stride length, a short swing time, and a short double support phase [1]. [sent-144, score-1.635]
</p><p>75 In RunBot, because the phase-switching of its legs is triggered immediately by ground contact signals, its double support phase is so short (usually less than 30 ms) that it is negligible. [sent-145, score-0.25]
</p><p>76 Because there are no position or trajectory tracking control in RunBot, it is impossible to control its walking speed directly or explicitly. [sent-147, score-0.595]
</p><p>77 However, knowing that runBot’s walking gait is determined by only two parameters, ΘES,h and GM,h (Fig. [sent-148, score-0.494]
</p><p>78 3A), we formulate RunBot’s fast walking control as a policy gradient reinforcement learning problem by considering each point in the the parameter space (Fig. [sent-149, score-0.539]
</p><p>79 The evaluation of each policy generates a score that is a measure of the speed of the gait described by that policy. [sent-153, score-0.281]
</p><p>80 RunBot starts its walking with the parameters corresponding to point S in Fig. [sent-162, score-0.357]
</p><p>81 After 240 seconds of continuous walking with the learning algorithm and no any human intervention, RunBot attains a walking speed of about 80 cm/s (see Fig. [sent-165, score-0.798]
</p><p>82 To compare the walking speed of various biped robots whose sizes are quite different from each other, we use the relative speed, speed divided by the leg-length. [sent-169, score-1.01]
</p><p>83 We know of no other biped robot attaining such a fast relative speed. [sent-170, score-0.642]
</p><p>84 The world record of human walking race is equivalent to about 4. [sent-171, score-0.357]
</p><p>85 So, RunBot’s highest walking speed is comparable to that of humans. [sent-174, score-0.441]
</p><p>86 uk/˜tgeng/nips Although there is no speciﬁcally designed controller in charge of the sensing and control of the transient stages of policy changing (speed changing), the natural dynamics of the robot itself ensures the stability during the changes. [sent-179, score-0.67]
</p><p>87 By exploiting the natural dynamics, the reﬂexive controller is robust to its parameter variation as shown in Fig. [sent-180, score-0.19]
</p><p>88 Up to date, however, no real biped robot has existed that depends exclusively on reﬂexive controllers. [sent-183, score-0.6]
</p><p>89 This may be because of the intrinsic instability speciﬁc to biped-walking, which makes the dynamic stability of biped robots much more difﬁcult to control than that of multi-legged robots. [sent-184, score-0.63]
</p><p>90 To our knowledge, our RunBot is the ﬁrst dynamic biped exclusively controlled by a pure reﬂexive controller. [sent-185, score-0.427]
</p><p>91 Although such a pure reﬂexive controller itself involves no explicit mechanisms for the global stability control of the biped, its coupling with the properly designed mechanics of RunBot has substantially ensured the considerably large stable domain of the dynamic biped gaits. [sent-186, score-0.764]
</p><p>92 Our reﬂexive controller has some evident differences from Cruse’s model. [sent-187, score-0.19]
</p><p>93 Whereas our reﬂexive controller presented here uses only GC and AEA signals to coordinate the movements of the joints. [sent-189, score-0.215]
</p><p>94 Moreover, the AEA signal of one hip in RunBot only acts on the knee joint belonging to the same leg, not functioning on the leg-level as the AEP and PEP did in Cruse’s model. [sent-190, score-0.421]
</p><p>95 The use of fewer phasic feedback signals has further simpliﬁed the controller structure in RunBot. [sent-191, score-0.19]
</p><p>96 In order to achieve real time walking gait in a real world, even biological inspired robots often have to depend on some kinds of position- or trajectory tracking control on their joints [6, 11, 12]. [sent-192, score-0.836]
</p><p>97 The neural structure of our reﬂexive controller does not depend on, or ensure the tracking of, any desired position. [sent-194, score-0.19]
</p><p>98 Indeed, it is this approximate nature of our reﬂexive controller that allows the physical properties of the robot itself to contribute implicitly to generation of overall gait trajectories. [sent-195, score-0.556]
</p><p>99 The effectiveness of this hybrid neuro-mechanical system is also reﬂected in the fact that real-time learning of parameters was possible, where sometimes the speed of the robot changes quite strongly (see movie) without tripping it. [sent-196, score-0.313]
</p><p>100 Adaptive dynamic walking of a quadruped robot on irregular terrain based on biological concepts. [sent-266, score-0.608]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('runbot', 0.386), ('biped', 0.371), ('walking', 0.357), ('robot', 0.229), ('hip', 0.224), ('exive', 0.215), ('controller', 0.19), ('stretch', 0.149), ('extensor', 0.143), ('knee', 0.137), ('gait', 0.137), ('foot', 0.136), ('joints', 0.127), ('robots', 0.114), ('sensor', 0.104), ('leg', 0.102), ('ex', 0.101), ('exor', 0.1), ('receptors', 0.1), ('contact', 0.095), ('gr', 0.087), ('locomotion', 0.087), ('cruse', 0.086), ('speed', 0.084), ('neuron', 0.08), ('gl', 0.08), ('re', 0.079), ('stance', 0.079), ('ground', 0.075), ('exes', 0.071), ('zmp', 0.071), ('passive', 0.068), ('stability', 0.067), ('ar', 0.061), ('joint', 0.06), ('policy', 0.06), ('al', 0.058), ('aea', 0.057), ('gaits', 0.057), ('hexapod', 0.057), ('swing', 0.057), ('control', 0.056), ('neurons', 0.055), ('angle', 0.045), ('inspired', 0.045), ('aep', 0.043), ('boom', 0.043), ('rolling', 0.043), ('stride', 0.043), ('uem', 0.043), ('deg', 0.042), ('mechanical', 0.042), ('fast', 0.042), ('position', 0.042), ('curved', 0.04), ('servo', 0.037), ('beer', 0.037), ('pep', 0.037), ('dynamics', 0.037), ('walk', 0.036), ('pure', 0.034), ('phase', 0.034), ('circuit', 0.033), ('motor', 0.033), ('vr', 0.032), ('stages', 0.031), ('angular', 0.03), ('anterior', 0.03), ('vl', 0.03), ('voltage', 0.029), ('robotics', 0.029), ('bipedal', 0.029), ('bipeds', 0.029), ('heel', 0.029), ('mam', 0.029), ('motors', 0.029), ('passively', 0.029), ('piezo', 0.029), ('toe', 0.029), ('biologically', 0.028), ('level', 0.027), ('mass', 0.027), ('movements', 0.025), ('touches', 0.025), ('feet', 0.025), ('gm', 0.025), ('sagittal', 0.025), ('uf', 0.025), ('extreme', 0.024), ('reinforcement', 0.024), ('properly', 0.024), ('short', 0.023), ('sem', 0.023), ('legs', 0.023), ('gc', 0.023), ('oor', 0.023), ('sf', 0.023), ('dynamic', 0.022), ('modulate', 0.021), ('momentum', 0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="73-tfidf-1" href="./nips-2005-Fast_biped_walking_with_a_reflexive_controller_and_real-time_policy_searching.html">73 nips-2005-Fast biped walking with a reflexive controller and real-time policy searching</a></p>
<p>Author: Tao Geng, Bernd Porr, Florentin Wörgötter</p><p>Abstract: In this paper, we present our design and experiments of a planar biped robot (“RunBot”) under pure reﬂexive neuronal control. The goal of this study is to combine neuronal mechanisms with biomechanics to obtain very fast speed and the on-line learning of circuit parameters. Our controller is built with biologically inspired sensor- and motor-neuron models, including local reﬂexes and not employing any kind of position or trajectory-tracking control algorithm. Instead, this reﬂexive controller allows RunBot to exploit its own natural dynamics during critical stages of its walking gait cycle. To our knowledge, this is the ﬁrst time that dynamic biped walking is achieved using only a pure reﬂexive controller. In addition, this structure allows using a policy gradient reinforcement learning algorithm to tune the parameters of the reﬂexive controller in real-time during walking. This way RunBot can reach a relative speed of 3.5 leg-lengths per second after a few minutes of online learning, which is faster than that of any other biped robot, and is also comparable to the fastest relative speed of human walking. In addition, the stability domain of stable walking is quite large supporting this design strategy. 1</p><p>2 0.095903337 <a title="73-tfidf-2" href="./nips-2005-Off-Road_Obstacle_Avoidance_through_End-to-End_Learning.html">143 nips-2005-Off-Road Obstacle Avoidance through End-to-End Learning</a></p>
<p>Author: Urs Muller, Jan Ben, Eric Cosatto, Beat Flepp, Yann L. Cun</p><p>Abstract: We describe a vision-based obstacle avoidance system for off-road mobile robots. The system is trained from end to end to map raw input images to steering angles. It is trained in supervised mode to predict the steering angles provided by a human driver during training runs collected in a wide variety of terrains, weather conditions, lighting conditions, and obstacle types. The robot is a 50cm off-road truck, with two forwardpointing wireless color cameras. A remote computer processes the video and controls the robot via radio. The learning system is a large 6-layer convolutional network whose input is a single left/right pair of unprocessed low-resolution images. The robot exhibits an excellent ability to detect obstacles and navigate around them in real time at speeds of 2 m/s.</p><p>3 0.071426369 <a title="73-tfidf-3" href="./nips-2005-Spiking_Inputs_to_a_Winner-take-all_Network.html">181 nips-2005-Spiking Inputs to a Winner-take-all Network</a></p>
<p>Author: Matthias Oster, Shih-Chii Liu</p><p>Abstract: Recurrent networks that perform a winner-take-all computation have been studied extensively. Although some of these studies include spiking networks, they consider only analog input rates. We present results of this winner-take-all computation on a network of integrate-and-ﬁre neurons which receives spike trains as inputs. We show how we can conﬁgure the connectivity in the network so that the winner is selected after a pre-determined number of input spikes. We discuss spiking inputs with both regular frequencies and Poisson-distributed rates. The robustness of the computation was tested by implementing the winner-take-all network on an analog VLSI array of 64 integrate-and-ﬁre neurons which have an innate variance in their operating parameters. 1</p><p>4 0.070246562 <a title="73-tfidf-4" href="./nips-2005-Learning_Shared_Latent_Structure_for_Image_Synthesis_and_Robotic_Imitation.html">115 nips-2005-Learning Shared Latent Structure for Image Synthesis and Robotic Imitation</a></p>
<p>Author: Aaron Shon, Keith Grochow, Aaron Hertzmann, Rajesh P. Rao</p><p>Abstract: We propose an algorithm that uses Gaussian process regression to learn common hidden structure shared between corresponding sets of heterogenous observations. The observation spaces are linked via a single, reduced-dimensionality latent variable space. We present results from two datasets demonstrating the algorithms’s ability to synthesize novel data from learned correspondences. We ﬁrst show that the method can learn the nonlinear mapping between corresponding views of objects, ﬁlling in missing data as needed to synthesize novel views. We then show that the method can learn a mapping between human degrees of freedom and robotic degrees of freedom for a humanoid robot, allowing robotic imitation of human poses from motion capture data. 1</p><p>5 0.060781147 <a title="73-tfidf-5" href="./nips-2005-Soft_Clustering_on_Graphs.html">178 nips-2005-Soft Clustering on Graphs</a></p>
<p>Author: Kai Yu, Shipeng Yu, Volker Tresp</p><p>Abstract: We propose a simple clustering framework on graphs encoding pairwise data similarities. Unlike usual similarity-based methods, the approach softly assigns data to clusters in a probabilistic way. More importantly, a hierarchical clustering is naturally derived in this framework to gradually merge lower-level clusters into higher-level ones. A random walk analysis indicates that the algorithm exposes clustering structures in various resolutions, i.e., a higher level statistically models a longer-term diffusion on graphs and thus discovers a more global clustering structure. Finally we provide very encouraging experimental results. 1</p><p>6 0.057299048 <a title="73-tfidf-6" href="./nips-2005-Gaussian_Process_Dynamical_Models.html">80 nips-2005-Gaussian Process Dynamical Models</a></p>
<p>7 0.05231978 <a title="73-tfidf-7" href="./nips-2005-Noise_and_the_two-thirds_power_Law.html">136 nips-2005-Noise and the two-thirds power Law</a></p>
<p>8 0.049508061 <a title="73-tfidf-8" href="./nips-2005-Integrate-and-Fire_models_with_adaptation_are_good_enough.html">99 nips-2005-Integrate-and-Fire models with adaptation are good enough</a></p>
<p>9 0.046118978 <a title="73-tfidf-9" href="./nips-2005-Faster_Rates_in_Regression_via_Active_Learning.html">74 nips-2005-Faster Rates in Regression via Active Learning</a></p>
<p>10 0.045641787 <a title="73-tfidf-10" href="./nips-2005-From_Weighted_Classification_to_Policy_Search.html">78 nips-2005-From Weighted Classification to Policy Search</a></p>
<p>11 0.044208053 <a title="73-tfidf-11" href="./nips-2005-Principles_of_real-time_computing_with_feedback_applied_to_cortical_microcircuit_models.html">157 nips-2005-Principles of real-time computing with feedback applied to cortical microcircuit models</a></p>
<p>12 0.043135889 <a title="73-tfidf-12" href="./nips-2005-An_aVLSI_Cricket_Ear_Model.html">25 nips-2005-An aVLSI Cricket Ear Model</a></p>
<p>13 0.042090084 <a title="73-tfidf-13" href="./nips-2005-Goal-Based_Imitation_as_Probabilistic_Inference_over_Graphical_Models.html">87 nips-2005-Goal-Based Imitation as Probabilistic Inference over Graphical Models</a></p>
<p>14 0.041480634 <a title="73-tfidf-14" href="./nips-2005-Learning_in_Silicon%3A_Timing_is_Everything.html">118 nips-2005-Learning in Silicon: Timing is Everything</a></p>
<p>15 0.040647842 <a title="73-tfidf-15" href="./nips-2005-A_Criterion_for_the_Convergence_of_Learning_with_Spike_Timing_Dependent_Plasticity.html">8 nips-2005-A Criterion for the Convergence of Learning with Spike Timing Dependent Plasticity</a></p>
<p>16 0.040491454 <a title="73-tfidf-16" href="./nips-2005-Affine_Structure_From_Sound.html">20 nips-2005-Affine Structure From Sound</a></p>
<p>17 0.039766833 <a title="73-tfidf-17" href="./nips-2005-Representing_Part-Whole_Relationships_in_Recurrent_Neural_Networks.html">164 nips-2005-Representing Part-Whole Relationships in Recurrent Neural Networks</a></p>
<p>18 0.03952153 <a title="73-tfidf-18" href="./nips-2005-Extracting_Dynamical_Structure_Embedded_in_Neural_Activity.html">67 nips-2005-Extracting Dynamical Structure Embedded in Neural Activity</a></p>
<p>19 0.038804568 <a title="73-tfidf-19" href="./nips-2005-Conditional_Visual_Tracking_in_Kernel_Space.html">45 nips-2005-Conditional Visual Tracking in Kernel Space</a></p>
<p>20 0.036535211 <a title="73-tfidf-20" href="./nips-2005-Large-scale_biophysical_parameter_estimation_in_single_neurons_via_constrained_linear_regression.html">106 nips-2005-Large-scale biophysical parameter estimation in single neurons via constrained linear regression</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2005_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.111), (1, -0.094), (2, 0.041), (3, 0.019), (4, -0.025), (5, -0.02), (6, 0.005), (7, -0.049), (8, 0.066), (9, 0.003), (10, -0.066), (11, 0.084), (12, -0.049), (13, 0.016), (14, 0.071), (15, -0.003), (16, 0.018), (17, -0.023), (18, 0.026), (19, 0.038), (20, 0.018), (21, -0.033), (22, 0.006), (23, -0.065), (24, -0.095), (25, 0.098), (26, -0.023), (27, -0.058), (28, -0.019), (29, -0.05), (30, 0.003), (31, -0.0), (32, -0.076), (33, 0.164), (34, 0.013), (35, 0.042), (36, 0.01), (37, -0.044), (38, 0.072), (39, 0.034), (40, -0.051), (41, -0.039), (42, 0.025), (43, -0.147), (44, -0.046), (45, -0.103), (46, -0.129), (47, -0.041), (48, 0.251), (49, -0.002)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96374506 <a title="73-lsi-1" href="./nips-2005-Fast_biped_walking_with_a_reflexive_controller_and_real-time_policy_searching.html">73 nips-2005-Fast biped walking with a reflexive controller and real-time policy searching</a></p>
<p>Author: Tao Geng, Bernd Porr, Florentin Wörgötter</p><p>Abstract: In this paper, we present our design and experiments of a planar biped robot (“RunBot”) under pure reﬂexive neuronal control. The goal of this study is to combine neuronal mechanisms with biomechanics to obtain very fast speed and the on-line learning of circuit parameters. Our controller is built with biologically inspired sensor- and motor-neuron models, including local reﬂexes and not employing any kind of position or trajectory-tracking control algorithm. Instead, this reﬂexive controller allows RunBot to exploit its own natural dynamics during critical stages of its walking gait cycle. To our knowledge, this is the ﬁrst time that dynamic biped walking is achieved using only a pure reﬂexive controller. In addition, this structure allows using a policy gradient reinforcement learning algorithm to tune the parameters of the reﬂexive controller in real-time during walking. This way RunBot can reach a relative speed of 3.5 leg-lengths per second after a few minutes of online learning, which is faster than that of any other biped robot, and is also comparable to the fastest relative speed of human walking. In addition, the stability domain of stable walking is quite large supporting this design strategy. 1</p><p>2 0.4954724 <a title="73-lsi-2" href="./nips-2005-Off-Road_Obstacle_Avoidance_through_End-to-End_Learning.html">143 nips-2005-Off-Road Obstacle Avoidance through End-to-End Learning</a></p>
<p>Author: Urs Muller, Jan Ben, Eric Cosatto, Beat Flepp, Yann L. Cun</p><p>Abstract: We describe a vision-based obstacle avoidance system for off-road mobile robots. The system is trained from end to end to map raw input images to steering angles. It is trained in supervised mode to predict the steering angles provided by a human driver during training runs collected in a wide variety of terrains, weather conditions, lighting conditions, and obstacle types. The robot is a 50cm off-road truck, with two forwardpointing wireless color cameras. A remote computer processes the video and controls the robot via radio. The learning system is a large 6-layer convolutional network whose input is a single left/right pair of unprocessed low-resolution images. The robot exhibits an excellent ability to detect obstacles and navigate around them in real time at speeds of 2 m/s.</p><p>3 0.44349834 <a title="73-lsi-3" href="./nips-2005-Dynamical_Synapses_Give_Rise_to_a_Power-Law_Distribution_of_Neuronal_Avalanches.html">61 nips-2005-Dynamical Synapses Give Rise to a Power-Law Distribution of Neuronal Avalanches</a></p>
<p>Author: Anna Levina, Michael Herrmann</p><p>Abstract: There is experimental evidence that cortical neurons show avalanche activity with the intensity of ﬁring events being distributed as a power-law. We present a biologically plausible extension of a neural network which exhibits a power-law avalanche distribution for a wide range of connectivity parameters. 1</p><p>4 0.3651171 <a title="73-lsi-4" href="./nips-2005-Learning_Shared_Latent_Structure_for_Image_Synthesis_and_Robotic_Imitation.html">115 nips-2005-Learning Shared Latent Structure for Image Synthesis and Robotic Imitation</a></p>
<p>Author: Aaron Shon, Keith Grochow, Aaron Hertzmann, Rajesh P. Rao</p><p>Abstract: We propose an algorithm that uses Gaussian process regression to learn common hidden structure shared between corresponding sets of heterogenous observations. The observation spaces are linked via a single, reduced-dimensionality latent variable space. We present results from two datasets demonstrating the algorithms’s ability to synthesize novel data from learned correspondences. We ﬁrst show that the method can learn the nonlinear mapping between corresponding views of objects, ﬁlling in missing data as needed to synthesize novel views. We then show that the method can learn a mapping between human degrees of freedom and robotic degrees of freedom for a humanoid robot, allowing robotic imitation of human poses from motion capture data. 1</p><p>5 0.34965199 <a title="73-lsi-5" href="./nips-2005-Affine_Structure_From_Sound.html">20 nips-2005-Affine Structure From Sound</a></p>
<p>Author: Sebastian Thrun</p><p>Abstract: We consider the problem of localizing a set of microphones together with a set of external acoustic events (e.g., hand claps), emitted at unknown times and unknown locations. We propose a solution that approximates this problem under a far ﬁeld approximation deﬁned in the calculus of afﬁne geometry, and that relies on singular value decomposition (SVD) to recover the afﬁne structure of the problem. We then deﬁne low-dimensional optimization techniques for embedding the solution into Euclidean geometry, and further techniques for recovering the locations and emission times of the acoustic events. The approach is useful for the calibration of ad-hoc microphone arrays and sensor networks. 1</p><p>6 0.34517112 <a title="73-lsi-6" href="./nips-2005-CMOL_CrossNets%3A_Possible_Neuromorphic_Nanoelectronic_Circuits.html">40 nips-2005-CMOL CrossNets: Possible Neuromorphic Nanoelectronic Circuits</a></p>
<p>7 0.33814278 <a title="73-lsi-7" href="./nips-2005-Learning_to_Control_an_Octopus_Arm_with_Gaussian_Process_Temporal_Difference_Methods.html">119 nips-2005-Learning to Control an Octopus Arm with Gaussian Process Temporal Difference Methods</a></p>
<p>8 0.33046344 <a title="73-lsi-8" href="./nips-2005-Rate_Distortion_Codes_in_Sensor_Networks%3A_A_System-level_Analysis.html">162 nips-2005-Rate Distortion Codes in Sensor Networks: A System-level Analysis</a></p>
<p>9 0.32657826 <a title="73-lsi-9" href="./nips-2005-Gaussian_Process_Dynamical_Models.html">80 nips-2005-Gaussian Process Dynamical Models</a></p>
<p>10 0.32628241 <a title="73-lsi-10" href="./nips-2005-An_aVLSI_Cricket_Ear_Model.html">25 nips-2005-An aVLSI Cricket Ear Model</a></p>
<p>11 0.29977319 <a title="73-lsi-11" href="./nips-2005-Representing_Part-Whole_Relationships_in_Recurrent_Neural_Networks.html">164 nips-2005-Representing Part-Whole Relationships in Recurrent Neural Networks</a></p>
<p>12 0.29630563 <a title="73-lsi-12" href="./nips-2005-Noise_and_the_two-thirds_power_Law.html">136 nips-2005-Noise and the two-thirds power Law</a></p>
<p>13 0.28955302 <a title="73-lsi-13" href="./nips-2005-Efficient_Estimation_of_OOMs.html">62 nips-2005-Efficient Estimation of OOMs</a></p>
<p>14 0.28758633 <a title="73-lsi-14" href="./nips-2005-Recovery_of_Jointly_Sparse_Signals_from_Few_Random_Projections.html">163 nips-2005-Recovery of Jointly Sparse Signals from Few Random Projections</a></p>
<p>15 0.27758777 <a title="73-lsi-15" href="./nips-2005-Large-scale_biophysical_parameter_estimation_in_single_neurons_via_constrained_linear_regression.html">106 nips-2005-Large-scale biophysical parameter estimation in single neurons via constrained linear regression</a></p>
<p>16 0.26699644 <a title="73-lsi-16" href="./nips-2005-Separation_of_Music_Signals_by_Harmonic_Structure_Modeling.html">174 nips-2005-Separation of Music Signals by Harmonic Structure Modeling</a></p>
<p>17 0.25405258 <a title="73-lsi-17" href="./nips-2005-Measuring_Shared_Information_and_Coordinated_Activity_in_Neuronal_Networks.html">124 nips-2005-Measuring Shared Information and Coordinated Activity in Neuronal Networks</a></p>
<p>18 0.25368538 <a title="73-lsi-18" href="./nips-2005-A_Connectionist_Model_for_Constructive_Modal_Reasoning.html">6 nips-2005-A Connectionist Model for Constructive Modal Reasoning</a></p>
<p>19 0.24007297 <a title="73-lsi-19" href="./nips-2005-Extracting_Dynamical_Structure_Embedded_in_Neural_Activity.html">67 nips-2005-Extracting Dynamical Structure Embedded in Neural Activity</a></p>
<p>20 0.23610528 <a title="73-lsi-20" href="./nips-2005-Spiking_Inputs_to_a_Winner-take-all_Network.html">181 nips-2005-Spiking Inputs to a Winner-take-all Network</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2005_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.034), (10, 0.026), (27, 0.032), (31, 0.04), (34, 0.077), (39, 0.014), (41, 0.016), (55, 0.023), (57, 0.026), (60, 0.01), (65, 0.011), (69, 0.049), (73, 0.037), (88, 0.058), (91, 0.037), (95, 0.409)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.86071628 <a title="73-lda-1" href="./nips-2005-Fast_biped_walking_with_a_reflexive_controller_and_real-time_policy_searching.html">73 nips-2005-Fast biped walking with a reflexive controller and real-time policy searching</a></p>
<p>Author: Tao Geng, Bernd Porr, Florentin Wörgötter</p><p>Abstract: In this paper, we present our design and experiments of a planar biped robot (“RunBot”) under pure reﬂexive neuronal control. The goal of this study is to combine neuronal mechanisms with biomechanics to obtain very fast speed and the on-line learning of circuit parameters. Our controller is built with biologically inspired sensor- and motor-neuron models, including local reﬂexes and not employing any kind of position or trajectory-tracking control algorithm. Instead, this reﬂexive controller allows RunBot to exploit its own natural dynamics during critical stages of its walking gait cycle. To our knowledge, this is the ﬁrst time that dynamic biped walking is achieved using only a pure reﬂexive controller. In addition, this structure allows using a policy gradient reinforcement learning algorithm to tune the parameters of the reﬂexive controller in real-time during walking. This way RunBot can reach a relative speed of 3.5 leg-lengths per second after a few minutes of online learning, which is faster than that of any other biped robot, and is also comparable to the fastest relative speed of human walking. In addition, the stability domain of stable walking is quite large supporting this design strategy. 1</p><p>2 0.30656973 <a title="73-lda-2" href="./nips-2005-Structured_Prediction_via_the_Extragradient_Method.html">184 nips-2005-Structured Prediction via the Extragradient Method</a></p>
<p>Author: Ben Taskar, Simon Lacoste-Julian, Michael I. Jordan</p><p>Abstract: We present a simple and scalable algorithm for large-margin estimation of structured models, including an important class of Markov networks and combinatorial models. We formulate the estimation problem as a convex-concave saddle-point problem and apply the extragradient method, yielding an algorithm with linear convergence using simple gradient and projection calculations. The projection step can be solved using combinatorial algorithms for min-cost quadratic ﬂow. This makes the approach an efﬁcient alternative to formulations based on reductions to a quadratic program (QP). We present experiments on two very different structured prediction tasks: 3D image segmentation and word alignment, illustrating the favorable scaling properties of our algorithm. 1</p><p>3 0.30652779 <a title="73-lda-3" href="./nips-2005-Nearest_Neighbor_Based_Feature_Selection_for_Regression_and_its_Application_to_Neural_Activity.html">132 nips-2005-Nearest Neighbor Based Feature Selection for Regression and its Application to Neural Activity</a></p>
<p>Author: Amir Navot, Lavi Shpigelman, Naftali Tishby, Eilon Vaadia</p><p>Abstract: We present a non-linear, simple, yet effective, feature subset selection method for regression and use it in analyzing cortical neural activity. Our algorithm involves a feature-weighted version of the k-nearest-neighbor algorithm. It is able to capture complex dependency of the target function on its input and makes use of the leave-one-out error as a natural regularization. We explain the characteristics of our algorithm on synthetic problems and use it in the context of predicting hand velocity from spikes recorded in motor cortex of a behaving monkey. By applying feature selection we are able to improve prediction quality and suggest a novel way of exploring neural data.</p><p>4 0.3051329 <a title="73-lda-4" href="./nips-2005-Preconditioner_Approximations_for_Probabilistic_Graphical_Models.html">154 nips-2005-Preconditioner Approximations for Probabilistic Graphical Models</a></p>
<p>Author: John D. Lafferty, Pradeep K. Ravikumar</p><p>Abstract: We present a family of approximation techniques for probabilistic graphical models, based on the use of graphical preconditioners developed in the scientiﬁc computing literature. Our framework yields rigorous upper and lower bounds on event probabilities and the log partition function of undirected graphical models, using non-iterative procedures that have low time complexity. As in mean ﬁeld approaches, the approximations are built upon tractable subgraphs; however, we recast the problem of optimizing the tractable distribution parameters and approximate inference in terms of the well-studied linear systems problem of obtaining a good matrix preconditioner. Experiments are presented that compare the new approximation schemes to variational methods. 1</p><p>5 0.30254373 <a title="73-lda-5" href="./nips-2005-Hot_Coupling%3A_A_Particle_Approach_to_Inference_and_Normalization_on_Pairwise_Undirected_Graphs.html">90 nips-2005-Hot Coupling: A Particle Approach to Inference and Normalization on Pairwise Undirected Graphs</a></p>
<p>Author: Firas Hamze, Nando de Freitas</p><p>Abstract: This paper presents a new sampling algorithm for approximating functions of variables representable as undirected graphical models of arbitrary connectivity with pairwise potentials, as well as for estimating the notoriously difﬁcult partition function of the graph. The algorithm ﬁts into the framework of sequential Monte Carlo methods rather than the more widely used MCMC, and relies on constructing a sequence of intermediate distributions which get closer to the desired one. While the idea of using “tempered” proposals is known, we construct a novel sequence of target distributions where, rather than dropping a global temperature parameter, we sequentially couple individual pairs of variables that are, initially, sampled exactly from a spanning tree of the variables. We present experimental results on inference and estimation of the partition function for sparse and densely-connected graphs.</p><p>6 0.30188808 <a title="73-lda-6" href="./nips-2005-Off-policy_Learning_with_Options_and_Recognizers.html">144 nips-2005-Off-policy Learning with Options and Recognizers</a></p>
<p>7 0.30123261 <a title="73-lda-7" href="./nips-2005-From_Weighted_Classification_to_Policy_Search.html">78 nips-2005-From Weighted Classification to Policy Search</a></p>
<p>8 0.30085433 <a title="73-lda-8" href="./nips-2005-Large-Scale_Multiclass_Transduction.html">105 nips-2005-Large-Scale Multiclass Transduction</a></p>
<p>9 0.30055767 <a title="73-lda-9" href="./nips-2005-Variable_KD-Tree_Algorithms_for_Spatial_Pattern_Search_and_Discovery.html">200 nips-2005-Variable KD-Tree Algorithms for Spatial Pattern Search and Discovery</a></p>
<p>10 0.29992062 <a title="73-lda-10" href="./nips-2005-Hyperparameter_and_Kernel_Learning_for_Graph_Based_Semi-Supervised_Classification.html">92 nips-2005-Hyperparameter and Kernel Learning for Graph Based Semi-Supervised Classification</a></p>
<p>11 0.29932418 <a title="73-lda-11" href="./nips-2005-Kernelized_Infomax_Clustering.html">102 nips-2005-Kernelized Infomax Clustering</a></p>
<p>12 0.29916787 <a title="73-lda-12" href="./nips-2005-Comparing_the_Effects_of_Different_Weight_Distributions_on_Finding_Sparse_Representations.html">43 nips-2005-Comparing the Effects of Different Weight Distributions on Finding Sparse Representations</a></p>
<p>13 0.29822454 <a title="73-lda-13" href="./nips-2005-An_Application_of_Markov_Random_Fields_to_Range_Sensing.html">23 nips-2005-An Application of Markov Random Fields to Range Sensing</a></p>
<p>14 0.29792917 <a title="73-lda-14" href="./nips-2005-Infinite_latent_feature_models_and_the_Indian_buffet_process.html">98 nips-2005-Infinite latent feature models and the Indian buffet process</a></p>
<p>15 0.29766083 <a title="73-lda-15" href="./nips-2005-Augmented_Rescorla-Wagner_and_Maximum_Likelihood_Estimation.html">32 nips-2005-Augmented Rescorla-Wagner and Maximum Likelihood Estimation</a></p>
<p>16 0.2975049 <a title="73-lda-16" href="./nips-2005-Nested_sampling_for_Potts_models.html">133 nips-2005-Nested sampling for Potts models</a></p>
<p>17 0.29736149 <a title="73-lda-17" href="./nips-2005-Soft_Clustering_on_Graphs.html">178 nips-2005-Soft Clustering on Graphs</a></p>
<p>18 0.29717809 <a title="73-lda-18" href="./nips-2005-Inference_with_Minimal_Communication%3A_a_Decision-Theoretic_Variational_Approach.html">96 nips-2005-Inference with Minimal Communication: a Decision-Theoretic Variational Approach</a></p>
<p>19 0.29700822 <a title="73-lda-19" href="./nips-2005-Assessing_Approximations_for_Gaussian_Process_Classification.html">30 nips-2005-Assessing Approximations for Gaussian Process Classification</a></p>
<p>20 0.29614374 <a title="73-lda-20" href="./nips-2005-Size_Regularized_Cut_for_Data_Clustering.html">177 nips-2005-Size Regularized Cut for Data Clustering</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
