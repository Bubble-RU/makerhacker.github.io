<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>122 nips-2005-Logic and MRF Circuitry for Labeling Occluding and Thinline Visual Contours</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2005" href="../home/nips2005_home.html">nips2005</a> <a title="nips-2005-122" href="#">nips2005-122</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>122 nips-2005-Logic and MRF Circuitry for Labeling Occluding and Thinline Visual Contours</h1>
<br/><p>Source: <a title="nips-2005-122-pdf" href="http://papers.nips.cc/paper/2892-logic-and-mrf-circuitry-for-labeling-occluding-and-thinline-visual-contours.pdf">pdf</a></p><p>Author: Eric Saund</p><p>Abstract: This paper presents representation and logic for labeling contrast edges and ridges in visual scenes in terms of both surface occlusion (border ownership) and thinline objects. In natural scenes, thinline objects include sticks and wires, while in human graphical communication thinlines include connectors, dividers, and other abstract devices. Our analysis is directed at both natural and graphical domains. The basic problem is to formulate the logic of the interactions among local image events, speciﬁcally contrast edges, ridges, junctions, and alignment relations, such as to encode the natural constraints among these events in visual scenes. In a sparse heterogeneous Markov Random Field framework, we deﬁne a set of interpretation nodes and energy/potential functions among them. The minimum energy conﬁguration found by Loopy Belief Propagation is shown to correspond to preferred human interpretation across a wide range of prototypical examples including important illusory contour ﬁgures such as the Kanizsa Triangle, as well as more difﬁcult examples. In practical terms, the approach delivers correct interpretations of inherently ambiguous hand-drawn box-and-connector diagrams at low computational cost.</p><p>Reference: <a title="nips-2005-122-reference" href="../nips2005_reference/nips-2005-Logic_and_MRF_Circuitry_for_Labeling_Occluding_and_Thinline_Visual_Contours_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 com  Abstract This paper presents representation and logic for labeling contrast edges and ridges in visual scenes in terms of both surface occlusion (border ownership) and thinline objects. [sent-3, score-0.878]
</p><p>2 In natural scenes, thinline objects include sticks and wires, while in human graphical communication thinlines include connectors, dividers, and other abstract devices. [sent-4, score-0.416]
</p><p>3 The basic problem is to formulate the logic of the interactions among local image events, speciﬁcally contrast edges, ridges, junctions, and alignment relations, such as to encode the natural constraints among these events in visual scenes. [sent-6, score-0.301]
</p><p>4 In a sparse heterogeneous Markov Random Field framework, we deﬁne a set of interpretation nodes and energy/potential functions among them. [sent-7, score-0.238]
</p><p>5 The minimum energy conﬁguration found by Loopy Belief Propagation is shown to correspond to preferred human interpretation across a wide range of prototypical examples including important illusory contour ﬁgures such as the Kanizsa Triangle, as well as more difﬁcult examples. [sent-8, score-0.926]
</p><p>6 In practical terms, the approach delivers correct interpretations of inherently ambiguous hand-drawn box-and-connector diagrams at low computational cost. [sent-9, score-0.269]
</p><p>7 1 Introduction A great deal of attention has been paid to the curious phenomenon of illusory contours in visual scenes [5]. [sent-10, score-0.502]
</p><p>8 Although a number of explanations have been proposed, computational accounts have converged on the understanding that illusory contours are an outcome of the more general problem of labeling scene contours in terms of causal events such as surface overlap. [sent-12, score-0.849]
</p><p>9 Illusory contours are the visual system’s way of expressing belief in an occlusion relation between two surfaces having the same lightness and therefore lacking a visible contrast edge. [sent-13, score-0.653]
</p><p>10 The phenomena are interesting in their revelation of interactions among multiple factors comprising the visual system’s prior assumptions about what constitutes likely interpretations of ambiguous input. [sent-14, score-0.304]
</p><p>11 Several computational models for this process have generated interpretations of Kanizsalike ﬁgures corresponding to human perception. [sent-15, score-0.195]
</p><p>12 optimization problem with hard constrains originating from the topology of contours and junctions, and soft constraints representing ﬁgural biases for non-accidental interpretations and ﬁgural closure. [sent-24, score-0.494]
</p><p>13 Heitger and von der Heydt[2] implemented a series of nonlinear ﬁltering operations that enacted interactions among line terminations and junctions to infer modal completions corresponding to illusory contours. [sent-25, score-0.576]
</p><p>14 Geiger[1] used a dense Markov Random Field to represent surface depths explicitly and propagated local evidence through a diffusion process. [sent-26, score-0.119]
</p><p>15 Saund[6] enumerated possible generic and non-generic interpretations of T- and L-junctions to set up an optimization problem solved by deterministic annealing. [sent-27, score-0.195]
</p><p>16 Liu and Wang[4] set up a network of contours traversing the boundaries of segmented regions, which interact to propagate local information through an iterative updating scheme. [sent-28, score-0.278]
</p><p>17 This paper expands this body of previous work in the following ways: • The computational model is expressed in terms of a sparse heterogeneous Markov Random Field whose solution is accessible to fast techniques such as Loopy Belief Propagation. [sent-29, score-0.062]
</p><p>18 • We introduce interpretations of thinlines in addition to solid surfaces, adding a signiﬁcant layer of richness and complexity. [sent-30, score-0.288]
</p><p>19 • The model infers occlusion relations of surfaces depicted by line drawings of their borders, as well as solid graphics depictions. [sent-31, score-0.217]
</p><p>20 • We devise MRF energy functions that implement circuitry for sophisticated logical constraints of the domain. [sent-32, score-0.157]
</p><p>21 The result is a formulation that is both fast and effective at correctly interpreting a greater range of psychophysical and near-practical contour conﬁguration examples than has heretofor been demonstrated. [sent-33, score-0.484]
</p><p>22 The model exposes aspects of fundamental ambiguity to be resolved by the incorporation of additional constraints and domain-speciﬁc knowledge. [sent-34, score-0.033]
</p><p>23 1 Visible Contours and Contour Ends Early vision studies commonly distinguish several models for visible contour creation and measurement, including contrast edges, lines or ridges, ramps, color and texture edges, etc. [sent-36, score-0.65]
</p><p>24 Let us idealize to consider only contrast edges and ridges (also known as “bars”), measured at a single scale. [sent-37, score-0.23]
</p><p>25 Spatial relation categories characterizing links in the MRF among Contour End nodes: Corner, Near Alignment, Far Alignment, Lateral. [sent-41, score-0.155]
</p><p>26 Resulting MRF including nodes of type Visible Contour, Contour End, Corner Tie, and Corner Tie Mediator. [sent-43, score-0.124]
</p><p>27 Contrast edges arise from distinct regions or surfaces, while ridges may represent either a boundary between regions or else a “thinline”, i. [sent-45, score-0.299]
</p><p>28 a physical or graphical object whose shape is essentially deﬁned by a one-dimensional path at our scale of measurement. [sent-47, score-0.053]
</p><p>29 Examples of thinlines in photographic imagery include twigs, sidewalk cracks, and telephone wires, while in graphical images thinlines include separators, connectors, and arrow shafts. [sent-48, score-0.211]
</p><p>30 Figure 7e shows a hand-drawn sketch in which some lines (measured as ridges) are intended to deﬁne boxes and therefore represent region boundaries, while others are connectors between boxes. [sent-49, score-0.074]
</p><p>31 We take the contour interpretation problem to include the analysis of this type of scene in addition to classical illusory contour ﬁgures. [sent-50, score-1.264]
</p><p>32 For any input data, we may construct a Markov Random Field consisting of four types of nodes derived from measured contrast edge and ridge contours. [sent-51, score-0.281]
</p><p>33 An interpretation is an assignment of states to nodes. [sent-52, score-0.123]
</p><p>34 Local potentials and the potential matrices associated with pairwise links between nodes encode constraints and biases among interpretation states based on the spatial relations among the visible contours. [sent-53, score-0.692]
</p><p>35 Figure 2 illustrates MRF nodes types and links for a simple example input image, as explained below. [sent-54, score-0.174]
</p><p>36 Let us assume that contours deﬁning region boundaries are assigned an occlusion direction, equivalent to relative surface depth and hence boundary ownership. [sent-55, score-0.552]
</p><p>37 Figure 3 shows the possible mappings between visible image contours measured as contrast edges or ridges, and their interpretation in terms of direction of surface overlap or else thinline object. [sent-56, score-1.077]
</p><p>38 Contrast edges always correspond to surface occlusion, while ridges may represent either a surface boundary or a thinline object. [sent-57, score-0.785]
</p><p>39 Correspondingly, the simplest MRF node type is the Visible Contour node which has state dimension 3 corresponding to two possible overlap directions and one thinline interpretation. [sent-58, score-0.525]
</p><p>40 Most of the interesting evidence and interaction occurs at terminations and junctions of visible contours. [sent-59, score-0.315]
</p><p>41 Contour End nodes are given the job of explaining why a smooth visible edge or ridge contour has terminated visibility, and hence they will encode the bulk of the modal (illusory) and amodal (occluded) completion information of a computed interpretation. [sent-60, score-1.206]
</p><p>42 Smooth visible contours may terminate in four ways:  Figure 3: Permissible mappings between visible edge and ridge contours and interpretations. [sent-61, score-0.89]
</p><p>43 Wedges indicate direction of surface overlap: white (FG) surface occludes shaded (BG) surface. [sent-62, score-0.272]
</p><p>44 The surface boundary contour or thinline object changes direction (turns a corner) 2. [sent-64, score-1.014]
</p><p>45 The contour becomes modal because the background surface lacks a visible edge with the foreground surface. [sent-65, score-0.887]
</p><p>46 The contour becomes amodal because it becomes occluded by another surface. [sent-67, score-0.642]
</p><p>47 The contour simply terminates when an surface overlap meets the end of a fold, or when a thin object or graphic stops. [sent-69, score-0.792]
</p><p>48 Contour Ends therefore have 3x4 = 12 interpretation states as shown in Figure 4. [sent-70, score-0.123]
</p><p>49 Figure 4: Contour End nodes have state dimension 12 indicating contour overlap type/direction (overlap or thinline) and one of four explanations for termination of the visible contour. [sent-71, score-0.835]
</p><p>50 Every Visible Contour node is linked to its two corresponding Contour End nodes through energy matrices (or equivalently, potential matrices, using Potential ψ = exp−E ) representing simple compatibility among overlap direction/thinline interpretation states. [sent-72, score-0.502]
</p><p>51 Additional links in the network are created based on spatial relations among Contour Ends as described next. [sent-73, score-0.177]
</p><p>52 Corner Tie nodes have state dimension 6 indicating the causal relationship between the Contour End nodes they link. [sent-75, score-0.198]
</p><p>53 Energy matrix linking the Left Contour End of a pair of corner-relation Contour Ends to their Corner Tie. [sent-77, score-0.033]
</p><p>54 The energy matrix linking the Right End Contour to the Corner Tie swaps the 5th and 6th columns. [sent-82, score-0.187]
</p><p>55 2 Contour Ends Relation Links Let us consider ﬁve classes of pairwise geometric relations among observed contour ends: Corner, Near-Alignment, Far-Alignment, Lateral, and Unrelated. [sent-84, score-0.586]
</p><p>56 Mathematical expressions forming the bases for these relations may be engineered as measures of distance and smooth continuation such as used by Saund [6]. [sent-85, score-0.096]
</p><p>57 The Corner relation depends only on proximity; Near-Alignment depends on proximity and alignment; Far-Alignment omits the proximity requirement. [sent-86, score-0.148]
</p><p>58 Within this framework a further reﬁnement distinguishes ridge Contour Ends from those arising from contrast edges. [sent-87, score-0.156]
</p><p>59 Namely, ridge ends are permitted to form Lateral relation links which correspond to potential modal contours. [sent-88, score-0.548]
</p><p>60 Contrast edge Contour Ends are excluded from this link type because they terminate at junctions which distribute modal and amodal completion roles to their participating Contour Ends. [sent-89, score-0.539]
</p><p>61 Contour End nodes from ridge contours may participate in Far-Alignment links but their local energies are set to preclude them from taking states representing modal completions. [sent-90, score-0.745]
</p><p>62 In this way the present model ﬁxes the topology of related ends in the process of setting up the Markov Graph. [sent-91, score-0.181]
</p><p>63 An important problem for future research is to formulate the Markov Graph to include all plausible Contour End pairings and have the actual pairings sort themselves out at solution time. [sent-92, score-0.06]
</p><p>64 Biases about preferred and less-preferred interpretations are represented through the terms in the energy matrices linking related Contour Ends. [sent-93, score-0.458]
</p><p>65 In accordance with prior work, we bias energy terms associated with curved Visible Contours and junctions of Contour Ends in favor of convex object interpretations. [sent-94, score-0.326]
</p><p>66 Space limitations preclude presenting the energy matrices in detail, but we discuss the main novel and signiﬁcant considerations. [sent-95, score-0.188]
</p><p>67 These energy matrices are constructed to trade off priors regarding accidental alignment versus amodal or modal invisible contour completion interpretations. [sent-97, score-1.057]
</p><p>68 For Con-  Figure 6: The Corner Tie Mediator node restricts border ownership of occluding contours to physically consistent interpretations. [sent-98, score-0.442]
</p><p>69 The energy matrix shown in e links the Corner Tie Mediator to the Left Corner Tie of a pair sharing a Contour End. [sent-99, score-0.227]
</p><p>70 The energy matrix for the link to the Right Corner Tie swaps the second and third columns. [sent-101, score-0.154]
</p><p>71 tour End pairs that are relatively near and well aligned, energy terms corresponding to causally unrelated interpretations (CE states 0,1,2) are large, while terms corresponding to amodal completion with compatible overlap/thinline property (CE states 6,7,8) are small. [sent-102, score-0.753]
</p><p>72 Actual energy values for the matrices are assigned by straightforward formulas derived from the Proximity and Smooth Continuation terms mentioned above. [sent-103, score-0.183]
</p><p>73 Per Kanizsa, modal completion interpretations (CE states 3,4,5) are somewhat more expensive than amodal interpretations, by a constant factor. [sent-104, score-0.565]
</p><p>74 Energy terms shift their relative weights in favor of causally unrelated interpretations (CE corner states 0,1,2) as the Contour Ends become more distant and less aligned. [sent-105, score-0.622]
</p><p>75 Contour Ends sharing a Corner relation can be related in one of three ways: they can be causally unrelated and unordered in depth; they can represent a turning of a surface boundary or thinline object; they can represent overlap of one contour above the other. [sent-106, score-1.215]
</p><p>76 In order to exploit the geometry of Contour Ends as local evidence, these alternatives must be articulated and entered into the MRF node graph. [sent-107, score-0.059]
</p><p>77 To do this we therefore introduce a third type of node, the Corner Tie node, possessing six states as illustrated in Figure 5a. [sent-108, score-0.082]
</p><p>78 The energy matrix relating Contour End nodes and Corner Tie nodes is shown in Figure 5b. [sent-109, score-0.322]
</p><p>79 It contains low energy terms representing the Corner Tie’s belief that the Contour End termination is due to direction change (turning a corner). [sent-110, score-0.267]
</p><p>80 It also contains low energy terms representing the conditions of one Contour End’s owning surface overlapping the other contour, i. [sent-111, score-0.268]
</p><p>81 the relative depth relation between these contours in the scene. [sent-113, score-0.316]
</p><p>82 3 Constraints on Overlaps and Thinlines at Junctions Physical considerations impose hard constraints on the interpretations of End Pairs meeting at a junction. [sent-115, score-0.228]
</p><p>83 One preferred interpretation for a T-junction is occlusion (6b). [sent-117, score-0.181]
</p><p>84 A less-preferred but possible interpretation is a change of direction (corner) by one surface, with accidental alignment by another contour (6c). [sent-118, score-0.686]
</p><p>85 What is impossible is for a surface boundary to bifurcate and “belong” to both sides of the T (6d). [sent-119, score-0.17]
</p><p>86 We therefore introduce a fourth node type, the Corner Tie Mediator. [sent-121, score-0.059]
</p><p>87 This node governs the number of Corner Ties that any Contour End can claim to form a direction change (corner turn) relation with. [sent-122, score-0.137]
</p><p>88 The energy matrix for the Corner Tie Mediator node is shown in Figure 6e: multiple Corner-Ties in the overlap direction-turn states (CT states 1 & 2) are excluded (solid arrows). [sent-123, score-0.381]
</p><p>89 But note that the matrix contains a low energy term (dashed arrow) for the formation of multiple direction-turn Corner-Ties provided they are in the Thinline state (CT state 3); branching of thinline objects is physically permissible. [sent-124, score-0.448]
</p><p>90 3 Experiments and Conclusion Loopy Belief Propagation under the Max-Product algorithm seeks the MAP conﬁguration which is equivalent to the minimum-energy assignment of states [8]. [sent-125, score-0.057]
</p><p>91 We have not encountered a failure of LBP to converge, and it is quite rare to encounter a lower-energy assignment of states than the algorithm delivers starting from an initial uniform distribution over states. [sent-126, score-0.094]
</p><p>92 For some ambiguous ﬁgures such as Figure 7e in which qualitatively different interpretations have similar energies, one may clamp one or more nodes to alternative states, leading to LBP solutions which persist once the clamping is removed. [sent-128, score-0.331]
</p><p>93 Figure 7 demonstrates MAP assignments corresponding to preferred human interpretations of the classic Kanizsa illusory contour ﬁgure and others containing both aligning L-junction and ridge termination evidence for modal contours, amodal completions, and thinline objects. [sent-130, score-1.641]
</p><p>94 Note that the MRF correctly predicts that outline drawings of surface boundaries do not induce illusory contours. [sent-131, score-0.396]
</p><p>95 Figure 7g borrows from experiments by Szummer and Cowans[7] toward a practical application in line drawing interpretation, in which closed boxes deﬁne regions while connectors remain interpreted as thinline objects. [sent-132, score-0.397]
</p><p>96 For this scene containing 369 nodes and 417 links, the entire process of forming the MRF and performing 100 iterations of LBP takes less than a second. [sent-133, score-0.099]
</p><p>97 The major pressures operating in these situations are a ﬁgural bias toward interpreting closed paths as convex regions, and a preference to interpret ridge contours participating in T- and X- junctions as thinline objects. [sent-134, score-0.833]
</p><p>98 We have shown how explicit consideration of ridge features and thinline interpretations brings new complexity to the logic of sorting out depth relations in visual scenes. [sent-135, score-0.804]
</p><p>99 This investigation suggests that a sparse heterogeneous Markov Random Field approach may provide a suitable basis for such models. [sent-136, score-0.037]
</p><p>100 (2001) On the optimality of solutions of the max-product belief propagation algorithm in arbitrary graphs, IEEE Trans. [sent-179, score-0.05]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('contour', 0.484), ('thinline', 0.298), ('corner', 0.264), ('contours', 0.236), ('tie', 0.226), ('illusory', 0.205), ('interpretations', 0.195), ('ends', 0.181), ('junctions', 0.149), ('ridges', 0.149), ('visible', 0.134), ('amodal', 0.13), ('modal', 0.124), ('ridge', 0.124), ('energy', 0.124), ('surface', 0.119), ('kanizsa', 0.112), ('mrf', 0.102), ('nodes', 0.099), ('saund', 0.093), ('thinlines', 0.093), ('overlap', 0.084), ('end', 0.077), ('links', 0.075), ('connectors', 0.074), ('occlusion', 0.068), ('interpretation', 0.066), ('relations', 0.066), ('occluding', 0.059), ('completion', 0.059), ('node', 0.059), ('states', 0.057), ('mediator', 0.056), ('alignment', 0.053), ('surfaces', 0.053), ('proximity', 0.052), ('boundary', 0.051), ('organization', 0.05), ('belief', 0.05), ('edges', 0.049), ('logic', 0.049), ('accidental', 0.049), ('gural', 0.049), ('lbp', 0.049), ('preferred', 0.047), ('causally', 0.044), ('loopy', 0.044), ('relation', 0.044), ('boundaries', 0.042), ('field', 0.04), ('cowans', 0.037), ('delivers', 0.037), ('geiger', 0.037), ('heitger', 0.037), ('heydt', 0.037), ('unrelated', 0.037), ('heterogeneous', 0.037), ('ambiguous', 0.037), ('ce', 0.037), ('visual', 0.036), ('among', 0.036), ('depth', 0.036), ('termination', 0.034), ('direction', 0.034), ('matrices', 0.034), ('linking', 0.033), ('constraints', 0.033), ('alto', 0.032), ('palo', 0.032), ('terminations', 0.032), ('ownership', 0.032), ('contrast', 0.032), ('biases', 0.03), ('completions', 0.03), ('continuation', 0.03), ('wires', 0.03), ('szummer', 0.03), ('pairings', 0.03), ('drawings', 0.03), ('border', 0.03), ('preclude', 0.03), ('swaps', 0.03), ('guration', 0.029), ('sharing', 0.028), ('gures', 0.028), ('labeling', 0.028), ('object', 0.028), ('occluded', 0.028), ('markov', 0.027), ('turning', 0.026), ('physically', 0.026), ('participating', 0.026), ('edge', 0.026), ('perceptual', 0.026), ('encode', 0.026), ('terms', 0.025), ('regions', 0.025), ('graphical', 0.025), ('type', 0.025), ('scenes', 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="122-tfidf-1" href="./nips-2005-Logic_and_MRF_Circuitry_for_Labeling_Occluding_and_Thinline_Visual_Contours.html">122 nips-2005-Logic and MRF Circuitry for Labeling Occluding and Thinline Visual Contours</a></p>
<p>Author: Eric Saund</p><p>Abstract: This paper presents representation and logic for labeling contrast edges and ridges in visual scenes in terms of both surface occlusion (border ownership) and thinline objects. In natural scenes, thinline objects include sticks and wires, while in human graphical communication thinlines include connectors, dividers, and other abstract devices. Our analysis is directed at both natural and graphical domains. The basic problem is to formulate the logic of the interactions among local image events, speciﬁcally contrast edges, ridges, junctions, and alignment relations, such as to encode the natural constraints among these events in visual scenes. In a sparse heterogeneous Markov Random Field framework, we deﬁne a set of interpretation nodes and energy/potential functions among them. The minimum energy conﬁguration found by Loopy Belief Propagation is shown to correspond to preferred human interpretation across a wide range of prototypical examples including important illusory contour ﬁgures such as the Kanizsa Triangle, as well as more difﬁcult examples. In practical terms, the approach delivers correct interpretations of inherently ambiguous hand-drawn box-and-connector diagrams at low computational cost.</p><p>2 0.12648652 <a title="122-tfidf-2" href="./nips-2005-Non-iterative_Estimation_with_Perturbed_Gaussian_Markov_Processes.html">139 nips-2005-Non-iterative Estimation with Perturbed Gaussian Markov Processes</a></p>
<p>Author: Yunsong Huang, B. Keith Jenkins</p><p>Abstract: We develop an approach for estimation with Gaussian Markov processes that imposes a smoothness prior while allowing for discontinuities. Instead of propagating information laterally between neighboring nodes in a graph, we study the posterior distribution of the hidden nodes as a whole—how it is perturbed by invoking discontinuities, or weakening the edges, in the graph. We show that the resulting computation amounts to feed-forward fan-in operations reminiscent of V1 neurons. Moreover, using suitable matrix preconditioners, the incurred matrix inverse and determinant can be approximated, without iteration, in the same computational style. Simulation results illustrate the merits of this approach.</p><p>3 0.11185823 <a title="122-tfidf-3" href="./nips-2005-An_Application_of_Markov_Random_Fields_to_Range_Sensing.html">23 nips-2005-An Application of Markov Random Fields to Range Sensing</a></p>
<p>Author: James Diebel, Sebastian Thrun</p><p>Abstract: This paper describes a highly successful application of MRFs to the problem of generating high-resolution range images. A new generation of range sensors combines the capture of low-resolution range images with the acquisition of registered high-resolution camera images. The MRF in this paper exploits the fact that discontinuities in range and coloring tend to co-align. This enables it to generate high-resolution, low-noise range images by integrating regular camera images into the range data. We show that by using such an MRF, we can substantially improve over existing range imaging technology. 1</p><p>4 0.096744031 <a title="122-tfidf-4" href="./nips-2005-A_Cortically-Plausible_Inverse_Problem_Solving_Method_Applied_to_Recognizing_Static_and_Kinematic_3D_Objects.html">7 nips-2005-A Cortically-Plausible Inverse Problem Solving Method Applied to Recognizing Static and Kinematic 3D Objects</a></p>
<p>Author: David Arathorn</p><p>Abstract: Recent neurophysiological evidence suggests the ability to interpret biological motion is facilitated by a neuronal</p><p>5 0.085179664 <a title="122-tfidf-5" href="./nips-2005-Message_passing_for_task_redistribution_on_sparse_graphs.html">125 nips-2005-Message passing for task redistribution on sparse graphs</a></p>
<p>Author: K. Wong, Zhuo Gao, David Tax</p><p>Abstract: The problem of resource allocation in sparse graphs with real variables is studied using methods of statistical physics. An efﬁcient distributed algorithm is devised on the basis of insight gained from the analysis and is examined using numerical simulations, showing excellent performance and full agreement with the theoretical results.</p><p>6 0.072158262 <a title="122-tfidf-6" href="./nips-2005-Walk-Sum_Interpretation_and_Analysis_of_Gaussian_Belief_Propagation.html">204 nips-2005-Walk-Sum Interpretation and Analysis of Gaussian Belief Propagation</a></p>
<p>7 0.064749114 <a title="122-tfidf-7" href="./nips-2005-Nested_sampling_for_Potts_models.html">133 nips-2005-Nested sampling for Potts models</a></p>
<p>8 0.062281668 <a title="122-tfidf-8" href="./nips-2005-Learning_Depth_from_Single_Monocular_Images.html">110 nips-2005-Learning Depth from Single Monocular Images</a></p>
<p>9 0.061220862 <a title="122-tfidf-9" href="./nips-2005-A_Bayesian_Framework_for_Tilt_Perception_and_Confidence.html">3 nips-2005-A Bayesian Framework for Tilt Perception and Confidence</a></p>
<p>10 0.055519551 <a title="122-tfidf-10" href="./nips-2005-Variable_KD-Tree_Algorithms_for_Spatial_Pattern_Search_and_Discovery.html">200 nips-2005-Variable KD-Tree Algorithms for Spatial Pattern Search and Discovery</a></p>
<p>11 0.051753696 <a title="122-tfidf-11" href="./nips-2005-Consensus_Propagation.html">46 nips-2005-Consensus Propagation</a></p>
<p>12 0.049764179 <a title="122-tfidf-12" href="./nips-2005-A_Connectionist_Model_for_Constructive_Modal_Reasoning.html">6 nips-2005-A Connectionist Model for Constructive Modal Reasoning</a></p>
<p>13 0.049051959 <a title="122-tfidf-13" href="./nips-2005-Active_Learning_For_Identifying_Function_Threshold_Boundaries.html">18 nips-2005-Active Learning For Identifying Function Threshold Boundaries</a></p>
<p>14 0.048672184 <a title="122-tfidf-14" href="./nips-2005-Hot_Coupling%3A_A_Particle_Approach_to_Inference_and_Normalization_on_Pairwise_Undirected_Graphs.html">90 nips-2005-Hot Coupling: A Particle Approach to Inference and Normalization on Pairwise Undirected Graphs</a></p>
<p>15 0.043054216 <a title="122-tfidf-15" href="./nips-2005-Inference_with_Minimal_Communication%3A_a_Decision-Theoretic_Variational_Approach.html">96 nips-2005-Inference with Minimal Communication: a Decision-Theoretic Variational Approach</a></p>
<p>16 0.042377785 <a title="122-tfidf-16" href="./nips-2005-Fast_Information_Value_for_Graphical_Models.html">70 nips-2005-Fast Information Value for Graphical Models</a></p>
<p>17 0.041536648 <a title="122-tfidf-17" href="./nips-2005-Faster_Rates_in_Regression_via_Active_Learning.html">74 nips-2005-Faster Rates in Regression via Active Learning</a></p>
<p>18 0.041313041 <a title="122-tfidf-18" href="./nips-2005-Structured_Prediction_via_the_Extragradient_Method.html">184 nips-2005-Structured Prediction via the Extragradient Method</a></p>
<p>19 0.040600259 <a title="122-tfidf-19" href="./nips-2005-Temporal_Abstraction_in_Temporal-difference_Networks.html">187 nips-2005-Temporal Abstraction in Temporal-difference Networks</a></p>
<p>20 0.03990734 <a title="122-tfidf-20" href="./nips-2005-Layered_Dynamic_Textures.html">108 nips-2005-Layered Dynamic Textures</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2005_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.124), (1, -0.008), (2, 0.03), (3, 0.094), (4, -0.059), (5, 0.005), (6, -0.173), (7, 0.136), (8, 0.077), (9, 0.052), (10, 0.112), (11, 0.047), (12, -0.034), (13, -0.021), (14, 0.001), (15, -0.059), (16, 0.072), (17, 0.061), (18, 0.022), (19, -0.001), (20, 0.044), (21, 0.014), (22, 0.04), (23, -0.005), (24, -0.034), (25, 0.041), (26, 0.071), (27, -0.058), (28, -0.016), (29, 0.109), (30, 0.052), (31, 0.108), (32, -0.086), (33, -0.047), (34, -0.006), (35, -0.025), (36, 0.078), (37, -0.035), (38, -0.055), (39, 0.019), (40, 0.146), (41, -0.048), (42, 0.05), (43, 0.177), (44, -0.13), (45, 0.0), (46, 0.104), (47, 0.106), (48, 0.007), (49, 0.16)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97664422 <a title="122-lsi-1" href="./nips-2005-Logic_and_MRF_Circuitry_for_Labeling_Occluding_and_Thinline_Visual_Contours.html">122 nips-2005-Logic and MRF Circuitry for Labeling Occluding and Thinline Visual Contours</a></p>
<p>Author: Eric Saund</p><p>Abstract: This paper presents representation and logic for labeling contrast edges and ridges in visual scenes in terms of both surface occlusion (border ownership) and thinline objects. In natural scenes, thinline objects include sticks and wires, while in human graphical communication thinlines include connectors, dividers, and other abstract devices. Our analysis is directed at both natural and graphical domains. The basic problem is to formulate the logic of the interactions among local image events, speciﬁcally contrast edges, ridges, junctions, and alignment relations, such as to encode the natural constraints among these events in visual scenes. In a sparse heterogeneous Markov Random Field framework, we deﬁne a set of interpretation nodes and energy/potential functions among them. The minimum energy conﬁguration found by Loopy Belief Propagation is shown to correspond to preferred human interpretation across a wide range of prototypical examples including important illusory contour ﬁgures such as the Kanizsa Triangle, as well as more difﬁcult examples. In practical terms, the approach delivers correct interpretations of inherently ambiguous hand-drawn box-and-connector diagrams at low computational cost.</p><p>2 0.64140213 <a title="122-lsi-2" href="./nips-2005-Non-iterative_Estimation_with_Perturbed_Gaussian_Markov_Processes.html">139 nips-2005-Non-iterative Estimation with Perturbed Gaussian Markov Processes</a></p>
<p>Author: Yunsong Huang, B. Keith Jenkins</p><p>Abstract: We develop an approach for estimation with Gaussian Markov processes that imposes a smoothness prior while allowing for discontinuities. Instead of propagating information laterally between neighboring nodes in a graph, we study the posterior distribution of the hidden nodes as a whole—how it is perturbed by invoking discontinuities, or weakening the edges, in the graph. We show that the resulting computation amounts to feed-forward fan-in operations reminiscent of V1 neurons. Moreover, using suitable matrix preconditioners, the incurred matrix inverse and determinant can be approximated, without iteration, in the same computational style. Simulation results illustrate the merits of this approach.</p><p>3 0.44454926 <a title="122-lsi-3" href="./nips-2005-A_Bayesian_Framework_for_Tilt_Perception_and_Confidence.html">3 nips-2005-A Bayesian Framework for Tilt Perception and Confidence</a></p>
<p>Author: Odelia Schwartz, Peter Dayan, Terrence J. Sejnowski</p><p>Abstract: The misjudgement of tilt in images lies at the heart of entertaining visual illusions and rigorous perceptual psychophysics. A wealth of ﬁndings has attracted many mechanistic models, but few clear computational principles. We adopt a Bayesian approach to perceptual tilt estimation, showing how a smoothness prior offers a powerful way of addressing much confusing data. In particular, we faithfully model recent results showing that conﬁdence in estimation can be systematically affected by the same aspects of images that affect bias. Conﬁdence is central to Bayesian modeling approaches, and is applicable in many other perceptual domains. Perceptual anomalies and illusions, such as the misjudgements of motion and tilt evident in so many psychophysical experiments, have intrigued researchers for decades.1–3 A Bayesian view4–8 has been particularly inﬂuential in models of motion processing, treating such anomalies as the normative product of prior information (often statistically codifying Gestalt laws) with likelihood information from the actual scenes presented. Here, we expand the range of statistically normative accounts to tilt estimation, for which there are classes of results (on estimation conﬁdence) that are so far not available for motion. The tilt illusion arises when the perceived tilt of a center target is misjudged (ie bias) in the presence of ﬂankers. Another phenomenon, called Crowding, refers to a loss in the conﬁdence (ie sensitivity) of perceived target tilt in the presence of ﬂankers. Attempts have been made to formalize these phenomena quantitatively. Crowding has been modeled as compulsory feature pooling (ie averaging of orientations), ignoring spatial positions.9, 10 The tilt illusion has been explained by lateral interactions11, 12 in populations of orientationtuned units; and by calibration.13 However, most models of this form cannot explain a number of crucial aspects of the data. First, the geometry of the positional arrangement of the stimuli affects attraction versus repulsion in bias, as emphasized by Kapadia et al14 (ﬁgure 1A), and others.15, 16 Second, Solomon et al. recently measured bias and sensitivity simultaneously.11 The rich and surprising range of sensitivities, far from ﬂat as a function of ﬂanker angles (ﬁgure 1B), are outside the reach of standard models. Moreover, current explanations do not offer a computational account of tilt perception as the outcome of a normative inference process. Here, we demonstrate that a Bayesian framework for orientation estimation, with a prior favoring smoothness, can naturally explain a range of seemingly puzzling tilt data. We explicitly consider both the geometry of the stimuli, and the issue of conﬁdence in the esti- 6 5 4 3 2 1 0 -1 -2 (B) Attraction Repulsion Sensititvity (1/deg) Bias (deg) (A) 0.6 0.5 0.4 0.3 0.2 0.1 -80 -60 -40 -20 0 20 40 60 80 Flanker tilt (deg) Figure 1: Tilt biases and sensitivities in visual perception. (A) Kapadia et al demonstrated the importance of geometry on tilt bias, with bar stimuli in the fovea (and similar results in the periphery). When 5 degrees clockwise ﬂankers are arranged colinearly, the center target appears attracted in the direction of the ﬂankers; when ﬂankers are lateral, the target appears repulsed. Data are an average of 5 subjects.14 (B) Solomon et al measured both biases and sensitivities for gratings in the visual periphery.11 On the top are example stimuli, with ﬂankers tilted 22.5 degrees clockwise. This constitutes the classic tilt illusion, with a repulsive bias percept. In addition, sensitivities vary as a function of ﬂanker angles, in a systematic way (even in cases when there are no biases at all). Sensitivities are given in units of the inverse of standard deviation of the tilt estimate. More detailed data for both experiments are shown in the results section. mation. Bayesian analyses have most frequently been applied to bias. Much less attention has been paid to the equally important phenomenon of sensitivity. This aspect of our model should be applicable to other perceptual domains. In section 1 we formulate the Bayesian model. The prior is determined by the principle of creating a smooth contour between the target and ﬂankers. We describe how to extract the bias and sensitivity. In section 2 we show experimental data of Kapadia et al and Solomon et al, alongside the model simulations, and demonstrate that the model can account for both geometry, and bias and sensitivity measurements in the data. Our results suggest a more uniﬁed, rational, approach to understanding tilt perception. 1 Bayesian model Under our Bayesian model, inference is controlled by the posterior distribution over the tilt of the target element. This comes from the combination of a prior favoring smooth conﬁgurations of the ﬂankers and target, and the likelihood associated with the actual scene. A complete distribution would consider all possible angles and relative spatial positions of the bars, and marginalize the posterior over all but the tilt of the central element. For simplicity, we make two benign approximations: conditionalizing over (ie clamping) the angles of the ﬂankers, and exploring only a small neighborhood of their positions. We now describe the steps of inference. Smoothness prior: Under these approximations, we consider a given actual conﬁguration (see ﬁg 2A) of ﬂankers f1 = (φ1 , x1 ), f2 = (φ2 , x2 ) and center target c = (φc , xc ), arranged from top to bottom. We have to generate a prior over φc and δ1 = x1 − xc and δ2 = x2 − xc based on the principle of smoothness. As a less benign approximation, we do this in two stages: articulating a principle that determines a single optimal conﬁguration; and generating a prior as a mixture of a Gaussian about this optimum and a uniform distribution, with the mixing proportion of the latter being determined by the smoothness of the optimum. Smoothness has been extensively studied in the computer vision literature.17–20 One widely (B) (C) f1 f1 β1 R Probability max smooth Max smooth target (deg) (A) 40 20 0 -20 c δ1 c -40 Φc f2 f2 1 0.8 0.6 0.4 0.2 0 -80 -60 -40 -20 0 20 40 Flanker tilt (deg) 60 80 -80 -60 -40 20 0 20 40 Flanker tilt (deg) 60 80 Figure 2: Geometry and smoothness for ﬂankers, f1 and f2 , and center target, c. (A) Example actual conﬁguration of ﬂankers and target, aligned along the y axis from top to bottom. (B) The elastica procedure can rotate the target angle (to Φc ) and shift the relative ﬂanker and target positions on the x axis (to δ1 and δ2 ) in its search for the maximally smooth solution. Small spatial shifts (up to 1/15 the size of R) of positions are allowed, but positional shift is overemphasized in the ﬁgure for visibility. (C) Top: center tilt that results in maximal smoothness, as a function of ﬂanker tilt. Boxed cartoons show examples for given ﬂanker tilts, of the optimally smooth conﬁguration. Note attraction of target towards ﬂankers for small ﬂanker angles; here ﬂankers and target are positioned in a nearly colinear arrangement. Note also repulsion of target away from ﬂankers for intermediate ﬂanker angles. Bottom: P [c, f1 , f2 ] for center tilt that yields maximal smoothness. The y axis is normalized between 0 and 1. used principle, elastica, known even to Euler, has been applied to contour completion21 and other computer vision applications.17 The basic idea is to ﬁnd the curve with minimum energy (ie, square of curvature). Sharon et al19 showed that the elastica function can be well approximated by a number of simpler forms. We adopt a version that Leung and Malik18 adopted from Sharon et al.19 We assume that the probability for completing a smooth curve, can be factorized into two terms: P [c, f1 , f2 ] = G(c, f1 )G(c, f2 ) (1) with the term G(c, f1 ) (and similarly, G(c, f2 )) written as: R Dβ 2 2 Dβ = β1 + βc − β1 βc (2) − ) where σR σβ and β1 (and similarly, βc ) is the angle between the orientation at f1 , and the line joining f1 and c. The distance between the centers of f1 and c is given by R. The two constants, σβ and σR , control the relative contribution to smoothness of the angle versus the spatial distance. Here, we set σβ = 1, and σR = 1.5. Figure 2B illustrates an example geometry, in which φc , δ1 , and δ2 , have been shifted from the actual scene (of ﬁgure 2A). G(c, f1 ) = exp(− We now estimate the smoothest solution for given conﬁgurations. Figure 2C shows for given ﬂanker tilts, the center tilt that yields maximal smoothness, and the corresponding probability of smoothness. For near vertical ﬂankers, the spatial lability leads to very weak attraction and high probability of smoothness. As the ﬂanker angle deviates farther from vertical, there is a large repulsion, but also lower probability of smoothness. These observations are key to our model: the maximally smooth center tilt will inﬂuence attractive and repulsive interactions of tilt estimation; the probability of smoothness will inﬂuence the relative weighting of the prior versus the likelihood. From the smoothness principle, we construct a two dimensional prior (ﬁgure 3A). One dimension represents tilt, the other dimension, the overall positional shift between target (B) Likelihood (D) Marginalized Posterior (C) Posterior 20 0.03 10 -10 -20 0 Probability 0 10 Angle Angle Angle 10 0 -10 -20 0.01 -10 -20 0.02 0 -0. 2 0 Position 0.2 (E) Psychometric function 20 -0. 2 0 0.2 -0. 2 0 0.2 Position Position -10 -5 0 Angle 5 10 Probability clockwise (A) Prior 20 1 0.8 0.6 0.4 0.2 0 -20 -10 0 10 20 Target angle (deg) Counter-clockwise Clockwise Figure 3: Bayes model for example ﬂankers and target. (A) Prior 2D distribution for ﬂankers set at 22.5 degrees (note repulsive preference for -5.5 degrees). (B) Likelihood 2D distribution for a target tilt of 3 degrees; (C) Posterior 2D distribution. All 2D distributions are drawn on the same grayscale range, and the presence of a larger baseline in the prior causes it to appear more dimmed. (D) Marginalized posterior, resulting in 1D distribution over tilt. Dashed line represents the mean, with slight preference for negative angle. (E) For this target tilt, we calculate probability clockwise, and obtain one point on psychometric curve. and ﬂankers (called ’position’). The prior is a 2D Gaussian distribution, sat upon a constant baseline.22 The Gaussian is centered at the estimated smoothest target angle and relative position, and the baseline is determined by the probability of smoothness. The baseline, and its dependence on the ﬂanker orientation, is a key difference from Weiss et al’s Gaussian prior for smooth, slow motion. It can be seen as a mechanism to allow segmentation (see Posterior description below). The standard deviation of the Gaussian is a free parameter. Likelihood: The likelihood over tilt and position (ﬁgure 3B) is determined by a 2D Gaussian distribution with an added baseline.22 The Gaussian is centered at the actual target tilt; and at a position taken as zero, since this is the actual position, to which the prior is compared. The standard deviation and baseline constant are free parameters. Posterior and marginalization: The posterior comes from multiplying likelihood and prior (ﬁgure 3C) and then marginalizing over position to obtain a 1D distribution over tilt. Figure 3D shows an example in which this distribution is bimodal. Other likelihoods, with closer agreement between target and smooth prior, give unimodal distributions. Note that the bimodality is a direct consequence of having an added baseline to the prior and likelihood (if these were Gaussian without a baseline, the posterior would always be Gaussian). The viewer is effectively assessing whether the target is associated with the same object as the ﬂankers, and this is reﬂected in the baseline, and consequently, in the bimodality, and conﬁdence estimate. We deﬁne α as the mean angle of the 1D posterior distribution (eg, value of dashed line on the x axis), and β as the height of the probability distribution at that mean angle (eg, height of dashed line). The term β is an indication of conﬁdence in the angle estimate, where for larger values we are more certain of the estimate. Decision of probability clockwise: The probability of a clockwise tilt is estimated from the marginalized posterior: 1 P = 1 + exp (3) −α.∗k − log(β+η) where α and β are deﬁned as above, k is a free parameter and η a small constant. Free parameters are set to a single constant value for all ﬂanker and center conﬁgurations. Weiss et al use a similar compressive nonlinearity, but without the term β. We also tried a decision function that integrates the posterior, but the resulting curves were far from the sigmoidal nature of the data. Bias and sensitivity: For one target tilt, we generate a single probability and therefore a single point on the psychometric function relating tilt to the probability of choosing clockwise. We generate the full psychometric curve from all target tilts and ﬁt to it a cumulative 60 40 20 -5 0 5 Target tilt (deg) 10 80 60 40 20 0 -10 (C) Data -5 0 5 Target tilt (deg) 10 80 60 40 20 0 -10 (D) Model 100 100 100 80 0 -10 Model Frequency responding clockwise (B) Data Frequency responding clockwise Frequency responding clockwise Frequency responding clockwise (A) 100 -5 0 5 Target tilt (deg) 10 80 60 40 20 0 -10 -5 0 5 10 Target tilt (deg) Figure 4: Kapadia et al data,14 versus Bayesian model. Solid lines are ﬁts to a cumulative Gaussian distribution. (A) Flankers are tilted 5 degrees clockwise (black curve) or anti-clockwise (gray) of vertical, and positioned spatially in a colinear arrangement. The center bar appears tilted in the direction of the ﬂankers (attraction), as can be seen by the attractive shift of the psychometric curve. The boxed stimuli cartoon illustrates a vertical target amidst the ﬂankers. (B) Model for colinear bars also produces attraction. (C) Data and (D) model for lateral ﬂankers results in repulsion. All data are collected in the fovea for bars. Gaussian distribution N (µ, σ) (ﬁgure 3E). The mean µ of the ﬁt corresponds to the bias, 1 and σ to the sensitivity, or conﬁdence in the bias. The ﬁt to a cumulative Gaussian and extraction of these parameters exactly mimic psychophysical procedures.11 2 Results: data versus model We ﬁrst consider the geometry of the center and ﬂanker conﬁgurations, modeling the full psychometric curve for colinear and parallel ﬂanks (recall that ﬁgure 1A showed summary biases). Figure 4A;B demonstrates attraction in the data and model; that is, the psychometric curve is shifted towards the ﬂanker, because of the nature of smooth completions for colinear ﬂankers. Figure 4C;D shows repulsion in the data and model. In this case, the ﬂankers are arranged laterally instead of colinearly. The smoothest solution in the model arises by shifting the target estimate away from the ﬂankers. This shift is rather minor, because the conﬁguration has a low probability of smoothness (similar to ﬁgure 2C), and thus the prior exerts only a weak effect. The above results show examples of changes in the psychometric curve, but do not address both bias and, particularly, sensitivity, across a whole range of ﬂanker conﬁgurations. Figure 5 depicts biases and sensitivity from Solomon et al, versus the Bayes model. The data are shown for a representative subject, but the qualitative behavior is consistent across all subjects tested. In ﬁgure 5A, bias is shown, for the condition that both ﬂankers are tilted at the same angle. The data exhibit small attraction at near vertical ﬂanker angles (this arrangement is close to colinear); large repulsion at intermediate ﬂanker angles of 22.5 and 45 degrees from vertical; and minimal repulsion at large angles from vertical. This behavior is also exhibited in the Bayes model (Figure 5B). For intermediate ﬂanker angles, the smoothest solution in the model is repulsive, and the effect of the prior is strong enough to induce a signiﬁcant repulsion. For large angles, the prior exerts almost no effect. Interestingly, sensitivity is far from ﬂat in both data and model. In the data (Figure 5C), there is most loss in sensitivity at intermediate ﬂanker angles of 22.5 and 45 degrees (ie, the subject is less certain); and sensitivity is higher for near vertical or near horizontal ﬂankers. The model shows the same qualitative behavior (Figure 5D). In the model, there are two factors driving sensitivity: one is the probability of completing a smooth curvature for a given ﬂanker conﬁguration, as in Figure 2B; this determines the strength of the prior. The other factor is certainty in a particular center estimation; this is determined by β, derived from the posterior distribution, and incorporated into the decision stage of the model Data 5 0 -60 -40 -80 -60 -40 -20 0 20 40 Flanker tilt (deg) -20 0 20 40 Flanker tilt (deg) 60 60 80 -60 -40 0.6 0.5 0.4 0.3 0.2 0.1 -20 0 20 40 Flanker tilt (deg) 60 80 60 80 -80 -60 -40 -20 0 20 40 Flanker tilt (deg) -80 -60 -40 -20 0 20 40 Flanker tilt (deg) 60 80 -20 0 20 40 Flanker tilt (deg) 60 80 (F) Bias (deg) 10 5 0 -5 0.6 0.5 0.4 0.3 0.2 0.1 -80 (D) 10 -10 -10 80 Sensitivity (1/deg) -80 5 0 -5 -80 -80 -60 -60 -40 -40 -20 0 20 40 Flanker tilt (deg) -20 0 20 40 Flanker tilt (deg) 60 -10 80 (H) 60 80 Sensitivity (1/deg) Sensititvity (1/deg) Bias (deg) 0.6 0.5 0.4 0.3 0.2 0.1 (G) Sensititvity (1/deg) 0 -5 (C) (E) 5 -5 -10 Model (B) 10 Bias (deg) Bias (deg) (A) 10 0.6 0.5 0.4 0.3 0.2 0.1 -80 -60 -40 Figure 5: Solomon et al data11 (subject FF), versus Bayesian model. (A) Data and (B) model biases with same-tilted ﬂankers; (C) Data and (D) model sensitivities with same-tilted ﬂankers; (E;G) data and (F;H) model as above, but for opposite-tilted ﬂankers (note that opposite-tilted data was collected for less ﬂanker angles). Each point in the ﬁgure is derived by ﬁtting a cummulative Gaussian distribution N (µ, σ) to corresponding psychometric curve, and setting bias 1 equal to µ and sensitivity to σ . In all experiments, ﬂanker and target gratings are presented in the visual periphery. Both data and model stimuli are averages of two conﬁgurations, on the left hand side (9 O’clock position) and right hand side (3 O’clock position). The conﬁgurations are similar to Figure 1 (B), but slightly shifted according to an iso-eccentric circle, so that all stimuli are similarly visible in the periphery. (equation 3). For ﬂankers that are far from vertical, the prior has minimal effect because one cannot ﬁnd a smooth solution (eg, the likelihood dominates), and thus sensitivity is higher. The low sensitivity at intermediate angles arises because the prior has considerable effect; and there is conﬂict between the prior (tilt, position), and likelihood (tilt, position). This leads to uncertainty in the target angle estimation . For ﬂankers near vertical, the prior exerts a strong effect; but there is less conﬂict between the likelihood and prior estimates (tilt, position) for a vertical target. This leads to more conﬁdence in the posterior estimate, and therefore, higher sensitivity. The only aspect that our model does not reproduce is the (more subtle) sensitivity difference between 0 and +/- 5 degree ﬂankers. Figure 5E-H depict data and model for opposite tilted ﬂankers. The bias is now close to zero in the data (Figure 5E) and model (Figure 5F), as would be expected (since the maximally smooth angle is now always roughly vertical). Perhaps more surprisingly, the sensitivities continue to to be non-ﬂat in the data (Figure 5G) and model (Figure 5H). This behavior arises in the model due to the strength of prior, and positional uncertainty. As before, there is most loss in sensitivity at intermediate angles. Note that to ﬁt Kapadia et al, simulations used a constant parameter of k = 9 in equation 3, whereas for the Solomon et al. simulations, k = 2.5. This indicates that, in our model, there was higher conﬁdence in the foveal experiments than in the peripheral ones. 3 Discussion We applied a Bayesian framework to the widely studied tilt illusion, and demonstrated the model on examples from two different data sets involving foveal and peripheral estimation. Our results support the appealing hypothesis that perceptual misjudgements are not a consequence of poor system design, but rather can be described as optimal inference.4–8 Our model accounts correctly for both attraction and repulsion, determined by the smoothness prior and the geometry of the scene. We emphasized the issue of estimation conﬁdence. The dataset showing how conﬁdence is affected by the same issues that affect bias,11 was exactly appropriate for a Bayesian formulation; other models in the literature typically do not incorporate conﬁdence in a thoroughly probabilistic manner. In fact, our model ﬁts the conﬁdence (and bias) data more proﬁciently than an account based on lateral interactions among a population of orientationtuned cells.11 Other Bayesian work, by Stocker et al,6 utilized the full slope of the psychometric curve in ﬁtting a prior and likelihood to motion data, but did not examine the issue of conﬁdence. Estimation conﬁdence plays a central role in Bayesian formulations as a whole. Understanding how priors affect conﬁdence should have direct bearing on many other Bayesian calculations such as multimodal integration.23 Our model is obviously over-simpliﬁed in a number of ways. First, we described it in terms of tilts and spatial positions; a more complete version should work in the pixel/ﬁltering domain.18, 19 We have also only considered two ﬂanking elements; the model is extendible to a full-ﬁeld surround, whereby smoothness operates along a range of geometric directions, and some directions are more (smoothly) dominant than others. Second, the prior is constructed by summarizing the maximal smoothness information; a more probabilistically correct version should capture the full probability of smoothness in its prior. Third, our model does not incorporate a formal noise representation; however, sensitivities could be inﬂuenced both by stimulus-driven noise and conﬁdence. Fourth, our model does not address attraction in the so-called indirect tilt illusion, thought to be mediated by a different mechanism. Finally, we have yet to account for neurophysiological data within this framework, and incorporate constraints at the neural implementation level. However, versions of our computations are oft suggested for intra-areal and feedback cortical circuits; and smoothness principles form a key part of the association ﬁeld connection scheme in Li’s24 dynamical model of contour integration in V1. Our model is connected to a wealth of literature in computer vision and perception. Notably, occlusion and contour completion might be seen as the extreme example in which there is no likelihood information at all for the center target; a host of papers have shown that under these circumstances, smoothness principles such as elastica and variants explain many aspects of perception. The model is also associated with many studies on contour integration motivated by Gestalt principles;25, 26 and exploration of natural scene statistics and Gestalt,27, 28 including the relation to contour grouping within a Bayesian framework.29, 30 Indeed, our model could be modiﬁed to include a prior from natural scenes. There are various directions for the experimental test and reﬁnement of our model. Most pressing is to determine bias and sensitivity for different center and ﬂanker contrasts. As in the case of motion, our model predicts that when there is more uncertainty in the center element, prior information is more dominant. Another interesting test would be to design a task such that the center element is actually part of a different ﬁgure and unrelated to the ﬂankers; our framework predicts that there would be minimal bias, because of segmentation. Our model should also be applied to other tilt-based illusions such as the Fraser spiral and Z¨ llner. Finally, our model can be applied to other perceptual domains;31 and given o the apparent similarities between the tilt illusion and the tilt after-effect, we plan to extend the model to adaptation, by considering smoothness in time as well as space. Acknowledgements This work was funded by the HHMI (OS, TJS) and the Gatsby Charitable Foundation (PD). We are very grateful to Serge Belongie, Leanne Chukoskie, Philip Meier and Joshua Solomon for helpful discussions. References [1] J J Gibson. Adaptation, after-effect, and contrast in the perception of tilted lines. Journal of Experimental Psychology, 20:553–569, 1937. [2] C Blakemore, R H S Carpentar, and M A Georgeson. Lateral inhibition between orientation detectors in the human visual system. Nature, 228:37–39, 1970. [3] J A Stuart and H M Burian. A study of separation difﬁculty: Its relationship to visual acuity in normal and amblyopic eyes. American Journal of Ophthalmology, 53:471–477, 1962. [4] A Yuille and H H Bulthoff. Perception as bayesian inference. In Knill and Whitman, editors, Bayesian decision theory and psychophysics, pages 123–161. Cambridge University Press, 1996. [5] Y Weiss, E P Simoncelli, and E H Adelson. Motion illusions as optimal percepts. Nature Neuroscience, 5:598–604, 2002. [6] A Stocker and E P Simoncelli. Constraining a bayesian model of human visual speed perception. Adv in Neural Info Processing Systems, 17, 2004. [7] D Kersten, P Mamassian, and A Yuille. Object perception as bayesian inference. Annual Review of Psychology, 55:271–304, 2004. [8] K Kording and D Wolpert. Bayesian integration in sensorimotor learning. Nature, 427:244–247, 2004. [9] L Parkes, J Lund, A Angelucci, J Solomon, and M Morgan. Compulsory averaging of crowded orientation signals in human vision. Nature Neuroscience, 4:739–744, 2001. [10] D G Pelli, M Palomares, and N J Majaj. Crowding is unlike ordinary masking: Distinguishing feature integration from detection. Journal of Vision, 4:1136–1169, 2002. [11] J Solomon, F M Felisberti, and M Morgan. Crowding and the tilt illusion: Toward a uniﬁed account. Journal of Vision, 4:500–508, 2004. [12] J A Bednar and R Miikkulainen. Tilt aftereffects in a self-organizing model of the primary visual cortex. Neural Computation, 12:1721–1740, 2000. [13] C W Clifford, P Wenderoth, and B Spehar. A functional angle on some after-effects in cortical vision. Proc Biol Sci, 1454:1705–1710, 2000. [14] M K Kapadia, G Westheimer, and C D Gilbert. Spatial distribution of contextual interactions in primary visual cortex and in visual perception. J Neurophysiology, 4:2048–262, 2000. [15] C C Chen and C W Tyler. Lateral modulation of contrast discrimination: Flanker orientation effects. Journal of Vision, 2:520–530, 2002. [16] I Mareschal, M P Sceniak, and R M Shapley. Contextual inﬂuences on orientation discrimination: binding local and global cues. Vision Research, 41:1915–1930, 2001. [17] D Mumford. Elastica and computer vision. In Chandrajit Bajaj, editor, Algebraic geometry and its applications. Springer Verlag, 1994. [18] T K Leung and J Malik. Contour continuity in region based image segmentation. In Proc. ECCV, pages 544–559, 1998. [19] E Sharon, A Brandt, and R Basri. Completion energies and scale. IEEE Pat. Anal. Mach. Intell., 22(10), 1997. [20] S W Zucker, C David, A Dobbins, and L Iverson. The organization of curve detection: coarse tangent ﬁelds. Computer Graphics and Image Processing, 9(3):213–234, 1988. [21] S Ullman. Filling in the gaps: the shape of subjective contours and a model for their generation. Biological Cybernetics, 25:1–6, 1976. [22] G E Hinton and A D Brown. Spiking boltzmann machines. Adv in Neural Info Processing Systems, 12, 1998. [23] R A Jacobs. What determines visual cue reliability? Trends in Cognitive Sciences, 6:345–350, 2002. [24] Z Li. A saliency map in primary visual cortex. Trends in Cognitive Science, 6:9–16, 2002. [25] D J Field, A Hayes, and R F Hess. Contour integration by the human visual system: evidence for a local “association ﬁeld”. Vision Research, 33:173–193, 1993. [26] J Beck, A Rosenfeld, and R Ivry. Line segregation. Spatial Vision, 4:75–101, 1989. [27] M Sigman, G A Cecchi, C D Gilbert, and M O Magnasco. On a common circle: Natural scenes and gestalt rules. PNAS, 98(4):1935–1940, 2001. [28] S Mahumad, L R Williams, K K Thornber, and K Xu. Segmentation of multiple salient closed contours from real images. IEEE Pat. Anal. Mach. Intell., 25(4):433–444, 1997. [29] W S Geisler, J S Perry, B J Super, and D P Gallogly. Edge co-occurence in natural images predicts contour grouping performance. Vision Research, 6:711–724, 2001. [30] J H Elder and R M Goldberg. Ecological statistics of gestalt laws for the perceptual organization of contours. Journal of Vision, 4:324–353, 2002. [31] S R Lehky and T J Sejnowski. Neural model of stereoacuity and depth interpolation based on a distributed representation of stereo disparity. Journal of Neuroscience, 10:2281–2299, 1990.</p><p>4 0.43810636 <a title="122-lsi-4" href="./nips-2005-A_Cortically-Plausible_Inverse_Problem_Solving_Method_Applied_to_Recognizing_Static_and_Kinematic_3D_Objects.html">7 nips-2005-A Cortically-Plausible Inverse Problem Solving Method Applied to Recognizing Static and Kinematic 3D Objects</a></p>
<p>Author: David Arathorn</p><p>Abstract: Recent neurophysiological evidence suggests the ability to interpret biological motion is facilitated by a neuronal</p><p>5 0.40677404 <a title="122-lsi-5" href="./nips-2005-Layered_Dynamic_Textures.html">108 nips-2005-Layered Dynamic Textures</a></p>
<p>Author: Antoni B. Chan, Nuno Vasconcelos</p><p>Abstract: A dynamic texture is a video model that treats a video as a sample from a spatio-temporal stochastic process, speciﬁcally a linear dynamical system. One problem associated with the dynamic texture is that it cannot model video where there are multiple regions of distinct motion. In this work, we introduce the layered dynamic texture model, which addresses this problem. We also introduce a variant of the model, and present the EM algorithm for learning each of the models. Finally, we demonstrate the efﬁcacy of the proposed model for the tasks of segmentation and synthesis of video.</p><p>6 0.38297084 <a title="122-lsi-6" href="./nips-2005-Nested_sampling_for_Potts_models.html">133 nips-2005-Nested sampling for Potts models</a></p>
<p>7 0.36906615 <a title="122-lsi-7" href="./nips-2005-An_Application_of_Markov_Random_Fields_to_Range_Sensing.html">23 nips-2005-An Application of Markov Random Fields to Range Sensing</a></p>
<p>8 0.36131293 <a title="122-lsi-8" href="./nips-2005-Message_passing_for_task_redistribution_on_sparse_graphs.html">125 nips-2005-Message passing for task redistribution on sparse graphs</a></p>
<p>9 0.35240978 <a title="122-lsi-9" href="./nips-2005-Walk-Sum_Interpretation_and_Analysis_of_Gaussian_Belief_Propagation.html">204 nips-2005-Walk-Sum Interpretation and Analysis of Gaussian Belief Propagation</a></p>
<p>10 0.34356228 <a title="122-lsi-10" href="./nips-2005-Hot_Coupling%3A_A_Particle_Approach_to_Inference_and_Normalization_on_Pairwise_Undirected_Graphs.html">90 nips-2005-Hot Coupling: A Particle Approach to Inference and Normalization on Pairwise Undirected Graphs</a></p>
<p>11 0.32259566 <a title="122-lsi-11" href="./nips-2005-Learning_Depth_from_Single_Monocular_Images.html">110 nips-2005-Learning Depth from Single Monocular Images</a></p>
<p>12 0.30533355 <a title="122-lsi-12" href="./nips-2005-Variable_KD-Tree_Algorithms_for_Spatial_Pattern_Search_and_Discovery.html">200 nips-2005-Variable KD-Tree Algorithms for Spatial Pattern Search and Discovery</a></p>
<p>13 0.26854438 <a title="122-lsi-13" href="./nips-2005-Consensus_Propagation.html">46 nips-2005-Consensus Propagation</a></p>
<p>14 0.26621762 <a title="122-lsi-14" href="./nips-2005-Structured_Prediction_via_the_Extragradient_Method.html">184 nips-2005-Structured Prediction via the Extragradient Method</a></p>
<p>15 0.26565501 <a title="122-lsi-15" href="./nips-2005-Preconditioner_Approximations_for_Probabilistic_Graphical_Models.html">154 nips-2005-Preconditioner Approximations for Probabilistic Graphical Models</a></p>
<p>16 0.26009029 <a title="122-lsi-16" href="./nips-2005-A_Connectionist_Model_for_Constructive_Modal_Reasoning.html">6 nips-2005-A Connectionist Model for Constructive Modal Reasoning</a></p>
<p>17 0.24507958 <a title="122-lsi-17" href="./nips-2005-Scaling_Laws_in_Natural_Scenes_and_the_Inference_of_3D_Shape.html">170 nips-2005-Scaling Laws in Natural Scenes and the Inference of 3D Shape</a></p>
<p>18 0.24412315 <a title="122-lsi-18" href="./nips-2005-Fast_Information_Value_for_Graphical_Models.html">70 nips-2005-Fast Information Value for Graphical Models</a></p>
<p>19 0.23985258 <a title="122-lsi-19" href="./nips-2005-Augmented_Rescorla-Wagner_and_Maximum_Likelihood_Estimation.html">32 nips-2005-Augmented Rescorla-Wagner and Maximum Likelihood Estimation</a></p>
<p>20 0.23305218 <a title="122-lsi-20" href="./nips-2005-Analyzing_Coupled_Brain_Sources%3A_Distinguishing_True_from_Spurious_Interaction.html">29 nips-2005-Analyzing Coupled Brain Sources: Distinguishing True from Spurious Interaction</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2005_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.028), (10, 0.028), (18, 0.013), (27, 0.037), (31, 0.086), (34, 0.067), (39, 0.014), (41, 0.015), (50, 0.012), (55, 0.038), (65, 0.011), (69, 0.065), (73, 0.022), (88, 0.034), (91, 0.025), (94, 0.4)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.87282521 <a title="122-lda-1" href="./nips-2005-Logic_and_MRF_Circuitry_for_Labeling_Occluding_and_Thinline_Visual_Contours.html">122 nips-2005-Logic and MRF Circuitry for Labeling Occluding and Thinline Visual Contours</a></p>
<p>Author: Eric Saund</p><p>Abstract: This paper presents representation and logic for labeling contrast edges and ridges in visual scenes in terms of both surface occlusion (border ownership) and thinline objects. In natural scenes, thinline objects include sticks and wires, while in human graphical communication thinlines include connectors, dividers, and other abstract devices. Our analysis is directed at both natural and graphical domains. The basic problem is to formulate the logic of the interactions among local image events, speciﬁcally contrast edges, ridges, junctions, and alignment relations, such as to encode the natural constraints among these events in visual scenes. In a sparse heterogeneous Markov Random Field framework, we deﬁne a set of interpretation nodes and energy/potential functions among them. The minimum energy conﬁguration found by Loopy Belief Propagation is shown to correspond to preferred human interpretation across a wide range of prototypical examples including important illusory contour ﬁgures such as the Kanizsa Triangle, as well as more difﬁcult examples. In practical terms, the approach delivers correct interpretations of inherently ambiguous hand-drawn box-and-connector diagrams at low computational cost.</p><p>2 0.50882381 <a title="122-lda-2" href="./nips-2005-Unbiased_Estimator_of_Shape_Parameter_for_Spiking_Irregularities_under_Changing_Environments.html">197 nips-2005-Unbiased Estimator of Shape Parameter for Spiking Irregularities under Changing Environments</a></p>
<p>Author: Keiji Miura, Masato Okada, Shun-ichi Amari</p><p>Abstract: We considered a gamma distribution of interspike intervals as a statistical model for neuronal spike generation. The model parameters consist of a time-dependent ﬁring rate and a shape parameter that characterizes spiking irregularities of individual neurons. Because the environment changes with time, observed data are generated from the time-dependent ﬁring rate, which is an unknown function. A statistical model with an unknown function is called a semiparametric model, which is one of the unsolved problem in statistics and is generally very difﬁcult to solve. We used a novel method of estimating functions in information geometry to estimate the shape parameter without estimating the unknown function. We analytically obtained an optimal estimating function for the shape parameter independent of the functional form of the ﬁring rate. This estimation is efﬁcient without Fisher information loss and better than maximum likelihood estimation. 1</p><p>3 0.44833836 <a title="122-lda-3" href="./nips-2005-Pattern_Recognition_from_One_Example_by_Chopping.html">151 nips-2005-Pattern Recognition from One Example by Chopping</a></p>
<p>Author: Francois Fleuret, Gilles Blanchard</p><p>Abstract: We investigate the learning of the appearance of an object from a single image of it. Instead of using a large number of pictures of the object to recognize, we use a labeled reference database of pictures of other objects to learn invariance to noise and variations in pose and illumination. This acquired knowledge is then used to predict if two pictures of new objects, which do not appear on the training pictures, actually display the same object. We propose a generic scheme called chopping to address this task. It relies on hundreds of random binary splits of the training set chosen to keep together the images of any given object. Those splits are extended to the complete image space with a simple learning algorithm. Given two images, the responses of the split predictors are combined with a Bayesian rule into a posterior probability of similarity. Experiments with the COIL-100 database and with a database of 150 deA graded LTEX symbols compare our method to a classical learning with several examples of the positive class and to a direct learning of the similarity. 1</p><p>4 0.31654289 <a title="122-lda-4" href="./nips-2005-Fast_Online_Policy_Gradient_Learning_with_SMD_Gain_Vector_Adaptation.html">72 nips-2005-Fast Online Policy Gradient Learning with SMD Gain Vector Adaptation</a></p>
<p>Author: Jin Yu, Douglas Aberdeen, Nicol N. Schraudolph</p><p>Abstract: Reinforcement learning by direct policy gradient estimation is attractive in theory but in practice leads to notoriously ill-behaved optimization problems. We improve its robustness and speed of convergence with stochastic meta-descent, a gain vector adaptation method that employs fast Hessian-vector products. In our experiments the resulting algorithms outperform previously employed online stochastic, ofﬂine conjugate, and natural policy gradient methods. 1</p><p>5 0.31610858 <a title="122-lda-5" href="./nips-2005-From_Weighted_Classification_to_Policy_Search.html">78 nips-2005-From Weighted Classification to Policy Search</a></p>
<p>Author: Doron Blatt, Alfred O. Hero</p><p>Abstract: This paper proposes an algorithm to convert a T -stage stochastic decision problem with a continuous state space to a sequence of supervised learning problems. The optimization problem associated with the trajectory tree and random trajectory methods of Kearns, Mansour, and Ng, 2000, is solved using the Gauss-Seidel method. The algorithm breaks a multistage reinforcement learning problem into a sequence of single-stage reinforcement learning subproblems, each of which is solved via an exact reduction to a weighted-classiﬁcation problem that can be solved using off-the-self methods. Thus the algorithm converts a reinforcement learning problem into simpler supervised learning subproblems. It is shown that the method converges in a ﬁnite number of steps to a solution that cannot be further improved by componentwise optimization. The implication of the proposed algorithm is that a plethora of classiﬁcation methods can be applied to ﬁnd policies in the reinforcement learning problem. 1</p><p>6 0.31505254 <a title="122-lda-6" href="./nips-2005-Inference_with_Minimal_Communication%3A_a_Decision-Theoretic_Variational_Approach.html">96 nips-2005-Inference with Minimal Communication: a Decision-Theoretic Variational Approach</a></p>
<p>7 0.31118786 <a title="122-lda-7" href="./nips-2005-Preconditioner_Approximations_for_Probabilistic_Graphical_Models.html">154 nips-2005-Preconditioner Approximations for Probabilistic Graphical Models</a></p>
<p>8 0.31068185 <a title="122-lda-8" href="./nips-2005-On_Local_Rewards_and_Scaling_Distributed_Reinforcement_Learning.html">145 nips-2005-On Local Rewards and Scaling Distributed Reinforcement Learning</a></p>
<p>9 0.31007174 <a title="122-lda-9" href="./nips-2005-Policy-Gradient_Methods_for_Planning.html">153 nips-2005-Policy-Gradient Methods for Planning</a></p>
<p>10 0.30839634 <a title="122-lda-10" href="./nips-2005-Estimating_the_wrong_Markov_random_field%3A_Benefits_in_the_computation-limited_setting.html">65 nips-2005-Estimating the wrong Markov random field: Benefits in the computation-limited setting</a></p>
<p>11 0.30759159 <a title="122-lda-11" href="./nips-2005-Variable_KD-Tree_Algorithms_for_Spatial_Pattern_Search_and_Discovery.html">200 nips-2005-Variable KD-Tree Algorithms for Spatial Pattern Search and Discovery</a></p>
<p>12 0.30657059 <a title="122-lda-12" href="./nips-2005-Walk-Sum_Interpretation_and_Analysis_of_Gaussian_Belief_Propagation.html">204 nips-2005-Walk-Sum Interpretation and Analysis of Gaussian Belief Propagation</a></p>
<p>13 0.30610931 <a title="122-lda-13" href="./nips-2005-A_Cortically-Plausible_Inverse_Problem_Solving_Method_Applied_to_Recognizing_Static_and_Kinematic_3D_Objects.html">7 nips-2005-A Cortically-Plausible Inverse Problem Solving Method Applied to Recognizing Static and Kinematic 3D Objects</a></p>
<p>14 0.30280232 <a title="122-lda-14" href="./nips-2005-Consensus_Propagation.html">46 nips-2005-Consensus Propagation</a></p>
<p>15 0.2979131 <a title="122-lda-15" href="./nips-2005-Layered_Dynamic_Textures.html">108 nips-2005-Layered Dynamic Textures</a></p>
<p>16 0.29763255 <a title="122-lda-16" href="./nips-2005-Oblivious_Equilibrium%3A_A_Mean_Field_Approximation_for_Large-Scale_Dynamic_Games.html">142 nips-2005-Oblivious Equilibrium: A Mean Field Approximation for Large-Scale Dynamic Games</a></p>
<p>17 0.2965481 <a title="122-lda-17" href="./nips-2005-Hot_Coupling%3A_A_Particle_Approach_to_Inference_and_Normalization_on_Pairwise_Undirected_Graphs.html">90 nips-2005-Hot Coupling: A Particle Approach to Inference and Normalization on Pairwise Undirected Graphs</a></p>
<p>18 0.29605094 <a title="122-lda-18" href="./nips-2005-Temporal_Abstraction_in_Temporal-difference_Networks.html">187 nips-2005-Temporal Abstraction in Temporal-difference Networks</a></p>
<p>19 0.29588896 <a title="122-lda-19" href="./nips-2005-Comparing_the_Effects_of_Different_Weight_Distributions_on_Finding_Sparse_Representations.html">43 nips-2005-Comparing the Effects of Different Weight Distributions on Finding Sparse Representations</a></p>
<p>20 0.29504165 <a title="122-lda-20" href="./nips-2005-Off-policy_Learning_with_Options_and_Recognizers.html">144 nips-2005-Off-policy Learning with Options and Recognizers</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
