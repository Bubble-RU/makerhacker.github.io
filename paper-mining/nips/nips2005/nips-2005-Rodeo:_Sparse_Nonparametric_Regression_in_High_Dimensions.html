<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>168 nips-2005-Rodeo: Sparse Nonparametric Regression in High Dimensions</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2005" href="../home/nips2005_home.html">nips2005</a> <a title="nips-2005-168" href="#">nips2005-168</a> knowledge-graph by maker-knowledge-mining</p><h1>168 nips-2005-Rodeo: Sparse Nonparametric Regression in High Dimensions</h1>
<br/><p>Source: <a title="nips-2005-168-pdf" href="http://papers.nips.cc/paper/2808-rodeo-sparse-nonparametric-regression-in-high-dimensions.pdf">pdf</a></p><p>Author: Larry Wasserman, John D. Lafferty</p><p>Abstract: We present a method for nonparametric regression that performs bandwidth selection and variable selection simultaneously. The approach is based on the technique of incrementally decreasing the bandwidth in directions where the gradient of the estimator with respect to bandwidth is large. When the unknown function satisﬁes a sparsity condition, our approach avoids the curse of dimensionality, achieving the optimal minimax rate of convergence, up to logarithmic factors, as if the relevant variables were known in advance. The method—called rodeo (regularization of derivative expectation operator)—conducts a sequence of hypothesis tests, and is easy to implement. A modiﬁed version that replaces hard with soft thresholding effectively solves a sequence of lasso problems. 1</p><p>Reference: <a title="nips-2005-168-reference" href="../nips2005_reference/nips-2005-Rodeo%3A_Sparse_Nonparametric_Regression_in_High_Dimensions_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('rodeo', 0.465), ('hj', 0.383), ('mh', 0.338), ('bandwid', 0.309), ('bandwidth', 0.257), ('zj', 0.248), ('wx', 0.192), ('xx', 0.186), ('mjj', 0.148), ('nonparamet', 0.096), ('ser', 0.094), ('thresholding', 0.09), ('ruppert', 0.085), ('lasso', 0.084), ('hd', 0.084), ('xj', 0.081), ('dj', 0.074), ('irrelev', 0.071), ('mn', 0.07), ('ds', 0.068)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="168-tfidf-1" href="./nips-2005-Rodeo%3A_Sparse_Nonparametric_Regression_in_High_Dimensions.html">168 nips-2005-Rodeo: Sparse Nonparametric Regression in High Dimensions</a></p>
<p>2 0.12072588 <a title="168-tfidf-2" href="./nips-2005-Convex_Neural_Networks.html">50 nips-2005-Convex Neural Networks</a></p>
<p>3 0.11378329 <a title="168-tfidf-3" href="./nips-2005-Beyond_Gaussian_Processes%3A_On_the_Distributions_of_Infinite_Networks.html">38 nips-2005-Beyond Gaussian Processes: On the Distributions of Infinite Networks</a></p>
<p>4 0.094529927 <a title="168-tfidf-4" href="./nips-2005-Augmented_Rescorla-Wagner_and_Maximum_Likelihood_Estimation.html">32 nips-2005-Augmented Rescorla-Wagner and Maximum Likelihood Estimation</a></p>
<p>5 0.090507701 <a title="168-tfidf-5" href="./nips-2005-The_Curse_of_Highly_Variable_Functions_for_Local_Kernel_Machines.html">190 nips-2005-The Curse of Highly Variable Functions for Local Kernel Machines</a></p>
<p>6 0.088002965 <a title="168-tfidf-6" href="./nips-2005-Fusion_of_Similarity_Data_in_Clustering.html">79 nips-2005-Fusion of Similarity Data in Clustering</a></p>
<p>7 0.086433068 <a title="168-tfidf-7" href="./nips-2005-Consistency_of_one-class_SVM_and_related_algorithms.html">47 nips-2005-Consistency of one-class SVM and related algorithms</a></p>
<p>8 0.086083025 <a title="168-tfidf-8" href="./nips-2005-From_Lasso_regression_to_Feature_vector_machine.html">77 nips-2005-From Lasso regression to Feature vector machine</a></p>
<p>9 0.084831938 <a title="168-tfidf-9" href="./nips-2005-Statistical_Convergence_of_Kernel_CCA.html">182 nips-2005-Statistical Convergence of Kernel CCA</a></p>
<p>10 0.084713221 <a title="168-tfidf-10" href="./nips-2005-Recovery_of_Jointly_Sparse_Signals_from_Few_Random_Projections.html">163 nips-2005-Recovery of Jointly Sparse Signals from Few Random Projections</a></p>
<p>11 0.080879495 <a title="168-tfidf-11" href="./nips-2005-Asymptotics_of_Gaussian_Regularized_Least_Squares.html">31 nips-2005-Asymptotics of Gaussian Regularized Least Squares</a></p>
<p>12 0.078303687 <a title="168-tfidf-12" href="./nips-2005-Convergence_and_Consistency_of_Regularized_Boosting_Algorithms_with_Stationary_B-Mixing_Observations.html">49 nips-2005-Convergence and Consistency of Regularized Boosting Algorithms with Stationary B-Mixing Observations</a></p>
<p>13 0.067536786 <a title="168-tfidf-13" href="./nips-2005-Selecting_Landmark_Points_for_Sparse_Manifold_Learning.html">172 nips-2005-Selecting Landmark Points for Sparse Manifold Learning</a></p>
<p>14 0.064027213 <a title="168-tfidf-14" href="./nips-2005-Generalization_Error_Bounds_for_Aggregation_by_Mirror_Descent_with_Averaging.html">82 nips-2005-Generalization Error Bounds for Aggregation by Mirror Descent with Averaging</a></p>
<p>15 0.062353864 <a title="168-tfidf-15" href="./nips-2005-Analysis_of_Spectral_Kernel_Design_based_Semi-supervised_Learning.html">27 nips-2005-Analysis of Spectral Kernel Design based Semi-supervised Learning</a></p>
<p>16 0.060754679 <a title="168-tfidf-16" href="./nips-2005-Computing_the_Solution_Path_for_the_Regularized_Support_Vector_Regression.html">44 nips-2005-Computing the Solution Path for the Regularized Support Vector Regression</a></p>
<p>17 0.057574451 <a title="168-tfidf-17" href="./nips-2005-Faster_Rates_in_Regression_via_Active_Learning.html">74 nips-2005-Faster Rates in Regression via Active Learning</a></p>
<p>18 0.049792349 <a title="168-tfidf-18" href="./nips-2005-Correcting_sample_selection_bias_in_maximum_entropy_density_estimation.html">51 nips-2005-Correcting sample selection bias in maximum entropy density estimation</a></p>
<p>19 0.047396146 <a title="168-tfidf-19" href="./nips-2005-Predicting_EMG_Data_from_M1_Neurons_with_Variational_Bayesian_Least_Squares.html">155 nips-2005-Predicting EMG Data from M1 Neurons with Variational Bayesian Least Squares</a></p>
<p>20 0.04634754 <a title="168-tfidf-20" href="./nips-2005-Value_Function_Approximation_with_Diffusion_Wavelets_and_Laplacian_Eigenfunctions.html">199 nips-2005-Value Function Approximation with Diffusion Wavelets and Laplacian Eigenfunctions</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2005_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.149), (1, -0.07), (2, -0.041), (3, 0.063), (4, -0.09), (5, -0.022), (6, -0.017), (7, 0.029), (8, 0.097), (9, 0.011), (10, -0.066), (11, -0.046), (12, 0.007), (13, -0.074), (14, 0.102), (15, 0.105), (16, 0.172), (17, 0.13), (18, 0.014), (19, 0.015), (20, -0.088), (21, -0.088), (22, -0.049), (23, -0.002), (24, 0.037), (25, -0.04), (26, -0.023), (27, 0.108), (28, -0.039), (29, 0.078), (30, -0.121), (31, -0.004), (32, 0.03), (33, 0.028), (34, -0.009), (35, -0.107), (36, 0.005), (37, -0.104), (38, 0.135), (39, 0.134), (40, -0.07), (41, 0.123), (42, -0.107), (43, -0.022), (44, 0.114), (45, 0.037), (46, 0.028), (47, -0.05), (48, 0.074), (49, -0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.90533596 <a title="168-lsi-1" href="./nips-2005-Rodeo%3A_Sparse_Nonparametric_Regression_in_High_Dimensions.html">168 nips-2005-Rodeo: Sparse Nonparametric Regression in High Dimensions</a></p>
<p>2 0.57206714 <a title="168-lsi-2" href="./nips-2005-Statistical_Convergence_of_Kernel_CCA.html">182 nips-2005-Statistical Convergence of Kernel CCA</a></p>
<p>3 0.56127119 <a title="168-lsi-3" href="./nips-2005-Augmented_Rescorla-Wagner_and_Maximum_Likelihood_Estimation.html">32 nips-2005-Augmented Rescorla-Wagner and Maximum Likelihood Estimation</a></p>
<p>4 0.52698779 <a title="168-lsi-4" href="./nips-2005-Beyond_Gaussian_Processes%3A_On_the_Distributions_of_Infinite_Networks.html">38 nips-2005-Beyond Gaussian Processes: On the Distributions of Infinite Networks</a></p>
<p>5 0.486018 <a title="168-lsi-5" href="./nips-2005-Convergence_and_Consistency_of_Regularized_Boosting_Algorithms_with_Stationary_B-Mixing_Observations.html">49 nips-2005-Convergence and Consistency of Regularized Boosting Algorithms with Stationary B-Mixing Observations</a></p>
<p>6 0.48070037 <a title="168-lsi-6" href="./nips-2005-Asymptotics_of_Gaussian_Regularized_Least_Squares.html">31 nips-2005-Asymptotics of Gaussian Regularized Least Squares</a></p>
<p>7 0.4546648 <a title="168-lsi-7" href="./nips-2005-From_Lasso_regression_to_Feature_vector_machine.html">77 nips-2005-From Lasso regression to Feature vector machine</a></p>
<p>8 0.44137013 <a title="168-lsi-8" href="./nips-2005-Computing_the_Solution_Path_for_the_Regularized_Support_Vector_Regression.html">44 nips-2005-Computing the Solution Path for the Regularized Support Vector Regression</a></p>
<p>9 0.43988571 <a title="168-lsi-9" href="./nips-2005-Selecting_Landmark_Points_for_Sparse_Manifold_Learning.html">172 nips-2005-Selecting Landmark Points for Sparse Manifold Learning</a></p>
<p>10 0.42819861 <a title="168-lsi-10" href="./nips-2005-Comparing_the_Effects_of_Different_Weight_Distributions_on_Finding_Sparse_Representations.html">43 nips-2005-Comparing the Effects of Different Weight Distributions on Finding Sparse Representations</a></p>
<p>11 0.41658601 <a title="168-lsi-11" href="./nips-2005-Convex_Neural_Networks.html">50 nips-2005-Convex Neural Networks</a></p>
<p>12 0.41531357 <a title="168-lsi-12" href="./nips-2005-Recovery_of_Jointly_Sparse_Signals_from_Few_Random_Projections.html">163 nips-2005-Recovery of Jointly Sparse Signals from Few Random Projections</a></p>
<p>13 0.3997623 <a title="168-lsi-13" href="./nips-2005-Worst-Case_Bounds_for_Gaussian_Process_Models.html">205 nips-2005-Worst-Case Bounds for Gaussian Process Models</a></p>
<p>14 0.39183155 <a title="168-lsi-14" href="./nips-2005-Non-Gaussian_Component_Analysis%3A_a_Semi-parametric_Framework_for_Linear_Dimension_Reduction.html">137 nips-2005-Non-Gaussian Component Analysis: a Semi-parametric Framework for Linear Dimension Reduction</a></p>
<p>15 0.35740674 <a title="168-lsi-15" href="./nips-2005-Consistency_of_one-class_SVM_and_related_algorithms.html">47 nips-2005-Consistency of one-class SVM and related algorithms</a></p>
<p>16 0.35182795 <a title="168-lsi-16" href="./nips-2005-Dual-Tree_Fast_Gauss_Transforms.html">59 nips-2005-Dual-Tree Fast Gauss Transforms</a></p>
<p>17 0.34361652 <a title="168-lsi-17" href="./nips-2005-Fusion_of_Similarity_Data_in_Clustering.html">79 nips-2005-Fusion of Similarity Data in Clustering</a></p>
<p>18 0.34104738 <a title="168-lsi-18" href="./nips-2005-Correcting_sample_selection_bias_in_maximum_entropy_density_estimation.html">51 nips-2005-Correcting sample selection bias in maximum entropy density estimation</a></p>
<p>19 0.33176267 <a title="168-lsi-19" href="./nips-2005-Faster_Rates_in_Regression_via_Active_Learning.html">74 nips-2005-Faster Rates in Regression via Active Learning</a></p>
<p>20 0.32919478 <a title="168-lsi-20" href="./nips-2005-A_matching_pursuit_approach_to_sparse_Gaussian_process_regression.html">16 nips-2005-A matching pursuit approach to sparse Gaussian process regression</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2005_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.34), (2, 0.039), (12, 0.022), (17, 0.012), (18, 0.021), (23, 0.024), (54, 0.083), (71, 0.135), (74, 0.017), (88, 0.067), (89, 0.044), (92, 0.089)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.68054634 <a title="168-lda-1" href="./nips-2005-Rodeo%3A_Sparse_Nonparametric_Regression_in_High_Dimensions.html">168 nips-2005-Rodeo: Sparse Nonparametric Regression in High Dimensions</a></p>
<p>2 0.53461599 <a title="168-lda-2" href="./nips-2005-The_Information-Form_Data_Association_Filter.html">192 nips-2005-The Information-Form Data Association Filter</a></p>
<p>3 0.49924919 <a title="168-lda-3" href="./nips-2005-Generalization_Error_Bounds_for_Aggregation_by_Mirror_Descent_with_Averaging.html">82 nips-2005-Generalization Error Bounds for Aggregation by Mirror Descent with Averaging</a></p>
<p>4 0.49924514 <a title="168-lda-4" href="./nips-2005-Divergences%2C_surrogate_loss_functions_and_experimental_design.html">58 nips-2005-Divergences, surrogate loss functions and experimental design</a></p>
<p>5 0.49776596 <a title="168-lda-5" href="./nips-2005-Convex_Neural_Networks.html">50 nips-2005-Convex Neural Networks</a></p>
<p>6 0.49354979 <a title="168-lda-6" href="./nips-2005-Beyond_Gaussian_Processes%3A_On_the_Distributions_of_Infinite_Networks.html">38 nips-2005-Beyond Gaussian Processes: On the Distributions of Infinite Networks</a></p>
<p>7 0.49258736 <a title="168-lda-7" href="./nips-2005-Computing_the_Solution_Path_for_the_Regularized_Support_Vector_Regression.html">44 nips-2005-Computing the Solution Path for the Regularized Support Vector Regression</a></p>
<p>8 0.49118432 <a title="168-lda-8" href="./nips-2005-Sensory_Adaptation_within_a_Bayesian_Framework_for_Perception.html">173 nips-2005-Sensory Adaptation within a Bayesian Framework for Perception</a></p>
<p>9 0.48794389 <a title="168-lda-9" href="./nips-2005-Generalization_error_bounds_for_classifiers_trained_with_interdependent_data.html">83 nips-2005-Generalization error bounds for classifiers trained with interdependent data</a></p>
<p>10 0.48754913 <a title="168-lda-10" href="./nips-2005-Consistency_of_one-class_SVM_and_related_algorithms.html">47 nips-2005-Consistency of one-class SVM and related algorithms</a></p>
<p>11 0.48691282 <a title="168-lda-11" href="./nips-2005-Learning_Minimum_Volume_Sets.html">112 nips-2005-Learning Minimum Volume Sets</a></p>
<p>12 0.48662585 <a title="168-lda-12" href="./nips-2005-Convergence_and_Consistency_of_Regularized_Boosting_Algorithms_with_Stationary_B-Mixing_Observations.html">49 nips-2005-Convergence and Consistency of Regularized Boosting Algorithms with Stationary B-Mixing Observations</a></p>
<p>13 0.4844248 <a title="168-lda-13" href="./nips-2005-Estimating_the_wrong_Markov_random_field%3A_Benefits_in_the_computation-limited_setting.html">65 nips-2005-Estimating the wrong Markov random field: Benefits in the computation-limited setting</a></p>
<p>14 0.4829638 <a title="168-lda-14" href="./nips-2005-Prediction_and_Change_Detection.html">156 nips-2005-Prediction and Change Detection</a></p>
<p>15 0.48233932 <a title="168-lda-15" href="./nips-2005-Comparing_the_Effects_of_Different_Weight_Distributions_on_Finding_Sparse_Representations.html">43 nips-2005-Comparing the Effects of Different Weight Distributions on Finding Sparse Representations</a></p>
<p>16 0.48224252 <a title="168-lda-16" href="./nips-2005-The_Curse_of_Highly_Variable_Functions_for_Local_Kernel_Machines.html">190 nips-2005-The Curse of Highly Variable Functions for Local Kernel Machines</a></p>
<p>17 0.4821192 <a title="168-lda-17" href="./nips-2005-Selecting_Landmark_Points_for_Sparse_Manifold_Learning.html">172 nips-2005-Selecting Landmark Points for Sparse Manifold Learning</a></p>
<p>18 0.48093826 <a title="168-lda-18" href="./nips-2005-Context_as_Filtering.html">48 nips-2005-Context as Filtering</a></p>
<p>19 0.48058251 <a title="168-lda-19" href="./nips-2005-Variational_Bayesian_Stochastic_Complexity_of_Mixture_Models.html">201 nips-2005-Variational Bayesian Stochastic Complexity of Mixture Models</a></p>
<p>20 0.4803611 <a title="168-lda-20" href="./nips-2005-A_PAC-Bayes_approach_to_the_Set_Covering_Machine.html">12 nips-2005-A PAC-Bayes approach to the Set Covering Machine</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
