<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>28 nips-2006-An Efficient Method for Gradient-Based Adaptation of Hyperparameters in SVM Models</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2006" href="../home/nips2006_home.html">nips2006</a> <a title="nips-2006-28" href="../nips2006/nips-2006-An_Efficient_Method_for_Gradient-Based_Adaptation_of_Hyperparameters_in_SVM_Models.html">nips2006-28</a> <a title="nips-2006-28-reference" href="#">nips2006-28-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>28 nips-2006-An Efficient Method for Gradient-Based Adaptation of Hyperparameters in SVM Models</h1>
<br/><p>Source: <a title="nips-2006-28-pdf" href="http://papers.nips.cc/paper/3059-an-efficient-method-for-gradient-based-adaptation-of-hyperparameters-in-svm-models.pdf">pdf</a></p><p>Author: S. S. Keerthi, Vikas Sindhwani, Olivier Chapelle</p><p>Abstract: We consider the task of tuning hyperparameters in SVM models based on minimizing a smooth performance validation function, e.g., smoothed k-fold crossvalidation error, using non-linear optimization techniques. The key computation in this approach is that of the gradient of the validation function with respect to hyperparameters. We show that for large-scale problems involving a wide choice of kernel-based models and validation functions, this computation can be very efﬁciently done; often within just a fraction of the training time. Empirical results show that a near-optimal set of hyperparameters can be identiﬁed by our approach with very few training rounds and gradient computations. . 1</p><br/>
<h2>reference text</h2><p>S. S. Keerthi, V. Sindhwani and O. Chapelle. An efﬁcient method for gradient-based adaptation of hyperparameters in SVM models. Technical Report, 2006. O. Chapelle, V. Vapnik, O. Bousquet and S. Mukherjee. Choosing multiple parameters for support vector machines. Machine Learning, 46:131–159, 2002. Y. Grandvalet, J. Mari´ thoz and S. Bengio. A probabilistic interpretation of SVMs with an applicae tion to unbalanced classiﬁcation. NIPS, 2005. J. Platt. Probabilities for support vector machines. In Advances in Large Margin Classiﬁers. MIT Press, Cambridge, Massachusetts, 1999. M. Seeger. Cross validation optimization for structured Hessian kernel methods. Tech. Report, MPI for Biological Cybernetics, T¨ bingen, Germany, May 2006. u</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
