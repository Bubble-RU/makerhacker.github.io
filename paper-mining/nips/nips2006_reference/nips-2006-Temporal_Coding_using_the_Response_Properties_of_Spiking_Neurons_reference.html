<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>187 nips-2006-Temporal Coding using the Response Properties of Spiking Neurons</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2006" href="../home/nips2006_home.html">nips2006</a> <a title="nips-2006-187" href="../nips2006/nips-2006-Temporal_Coding_using_the_Response_Properties_of_Spiking_Neurons.html">nips2006-187</a> <a title="nips-2006-187-reference" href="#">nips2006-187-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>187 nips-2006-Temporal Coding using the Response Properties of Spiking Neurons</h1>
<br/><p>Source: <a title="nips-2006-187-pdf" href="http://papers.nips.cc/paper/3123-temporal-coding-using-the-response-properties-of-spiking-neurons.pdf">pdf</a></p><p>Author: Thomas Voegtlin</p><p>Abstract: In biological neurons, the timing of a spike depends on the timing of synaptic currents, in a way that is classically described by the Phase Response Curve. This has implications for temporal coding: an action potential that arrives on a synapse has an implicit meaning, that depends on the position of the postsynaptic neuron on the ﬁring cycle. Here we show that this implicit code can be used to perform computations. Using theta neurons, we derive a spike-timing dependent learning rule from an error criterion. We demonstrate how to train an auto-encoder neural network using this rule. 1</p><br/>
<h2>reference text</h2><p>[1] W. Maass. Lower bounds for the computational power of networks of spiking neurons. Neural Computation, 8(1):1–40, 1996.</p>
<p>[2] S.M. Bohte, J.N. Kok, and H. La Poutr´ . Spike-prop: error-backprogation in multi-layer networks of e spiking neurons. Neurocomputing, 48:17–37, 2002.</p>
<p>[3] A. J. Bell and L. C. Parra. Maximising sensitivity in a spiking network. In Advances in Neural Information Processing Systems, volume 17, pages 121–128, 2005.</p>
<p>[4] R. F. Gal´ n, G. B. Ermentrout, and N. N. Urban. Efﬁcient estimation of phase-resetting curves in real a neurons and its signiﬁcance for neural-network modeling. Physical Review Letters, 94:158101, 2005.</p>
<p>[5] G. B. Ermentrout. Type I membranes, phase resetting curves, and synchrony. Neural Computation, 8:979–1001, 1996.</p>
<p>[6] W. Gerstner and W. M. Kistler. Spiking Neuron Models : Single Neurons, Populations, Plasticity. Cambridge University Press, 2002.</p>
<p>[7] R. P. N. Rao and T. J. Sejnowski. Predictive sequence learning in recurrent neocortical circuits. In Advances in Neural Information Processing Systems, volume 12, pages 164–170, 2000.</p>
<p>[8] E. Oja. Neural networks, principal components and subspaces. International Journal of Neural Systems, 1(1):61–68, 1989.</p>
<p>[9] B. Olshausen and D. Field. Sparse coding of natural images produces localized, oriented, bandpass receptive ﬁelds. Nature, 381:607–609, 1996.</p>
<p>[10] E. Oja. The nonlinear PCA learning rule in independent component analysis. Neurocomputing, 17(1):25– 46, 1997.</p>
<p>[11] Lengyel M., Kwag J., Paulsen O., and Dayan P. Matching storage and recall:hippocampal spike timingdependent plasticity and phase response curves. Nature Neuroscience, 8:1677–1683, 2006.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
