<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>6 nips-2006-A Kernel Subspace Method by Stochastic Realization for Learning Nonlinear Dynamical Systems</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2006" href="../home/nips2006_home.html">nips2006</a> <a title="nips-2006-6" href="../nips2006/nips-2006-A_Kernel_Subspace_Method_by_Stochastic_Realization_for_Learning_Nonlinear_Dynamical_Systems.html">nips2006-6</a> <a title="nips-2006-6-reference" href="#">nips2006-6-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>6 nips-2006-A Kernel Subspace Method by Stochastic Realization for Learning Nonlinear Dynamical Systems</h1>
<br/><p>Source: <a title="nips-2006-6-pdf" href="http://papers.nips.cc/paper/3103-a-kernel-subspace-method-by-stochastic-realization-for-learning-nonlinear-dynamical-systems.pdf">pdf</a></p><p>Author: Yoshinobu Kawahara, Takehisa Yairi, Kazuo Machida</p><p>Abstract: In this paper, we present a subspace method for learning nonlinear dynamical systems based on stochastic realization, in which state vectors are chosen using kernel canonical correlation analysis, and then state-space systems are identiﬁed through regression with the state vectors. We construct the theoretical underpinning and derive a concrete algorithm for nonlinear identiﬁcation. The obtained algorithm needs no iterative optimization procedure and can be implemented on the basis of fast and reliable numerical schemes. The simulation result shows that our algorithm can express dynamics with a high degree of accuracy. 1</p><br/>
<h2>reference text</h2><p>[1] Roweis, S. & Ghahramani, Z. (1999) “A Unifying Review of Linear Gaussian Models” Neural Computation, 11 (2) : 305-345.</p>
<p>[2] Van Overschee, P. & De Moor, B. (1996) “Subspace Identiﬁcation for Linear Systems: Theory, Implementation, Applications” Kluwer Academic Publishers, Dordrecht, Netherlands.</p>
<p>[3] Katayama, T. (2005) “Subspace Methods for System Identiﬁcation: A Realization Approach” Communications and Control Engineering, Springer Verlag, 2005.</p>
<p>[4] Moonen, M. & Moor, B. D. & Vandenberghe, L. & Vandewalle, J. (1989) “On- and Off-line Identiﬁcation of Linear State Space Models” International Journal of Control, 49 (1) : 219-232.</p>
<p>[5] Katayama, T. & Picci, G. (1999) “Realization of Stochastic Systems with Exogenous Inputs and Subspace Identiﬁcation Methods” Automatica, 35 (10) : 1635-1652.</p>
<p>[6] Goethals, I. & Pelckmans, K. & Suykens, J. A. K. & Moor, B. D. (2005) “Subspace Identiﬁcation of Hammerstein Systems Using Least Squares Support Vector Machines” IEEE Trans. on Automatic Control, 50 (10) : 1509-1519.</p>
<p>[7] Ni, X. & Verhaegen, M. & Krijgsman, A. & Verbruggen, H. B. (1996) “A New Method for Identiﬁcation and Control of Nonlinear Dynamic Systems” Engineering Application of Artiﬁcial Intelligence, 9 (3) : 231-243.</p>
<p>[8] Verdult, V. & Suykens, J. A. K. & Boets, J. & Goethals, I. & Moor, B. D. (2004) “Least Squares Support Vector Machines for Kernel CCA in Nonlinear State-Space Identiﬁcation” Proceedings of the 16th International Symposium on Mathematical Theory of Networks and Systems, (MTNS2004).</p>
<p>[9] Sch¨ lkopf, B. & Smola, A. (2002) “Learning with Kernels” MIT Press. o</p>
<p>[10] Rozanov, N. I. (1963) “Stationary Random Processes” Holden-Day, San Francisco, CA.</p>
<p>[11] Kuss, M. & Graepel, T. (2003) “The Geometry of Kernel Canonical Correlation Analysis” Technical Report, Max Planck Institute for Biological Cybernetics, Tubingen, Germany (108).</p>
<p>[12] Bach, F. R., & Jordan, M. I. (2002) “Kernel Independent Component Analysis” Journal of Machine Learning Research (JMLR), 3 : 1-48.</p>
<p>[13] Fukumizu, K. & Bach, F. R., & Jordan, M. I. (2004) “Dimensionality Reduction for Supervised Learning with Reproducing Kernel Hilbert Spaces” Journal of Machine Learning Research (JMLR), 5 : 73-99.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
