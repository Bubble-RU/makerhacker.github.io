<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>190 nips-2006-The Neurodynamics of Belief Propagation on Binary Markov Random Fields</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2006" href="../home/nips2006_home.html">nips2006</a> <a title="nips-2006-190" href="../nips2006/nips-2006-The_Neurodynamics_of_Belief_Propagation_on_Binary_Markov_Random_Fields.html">nips2006-190</a> <a title="nips-2006-190-reference" href="#">nips2006-190-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>190 nips-2006-The Neurodynamics of Belief Propagation on Binary Markov Random Fields</h1>
<br/><p>Source: <a title="nips-2006-190-pdf" href="http://papers.nips.cc/paper/3153-the-neurodynamics-of-belief-propagation-on-binary-markov-random-fields.pdf">pdf</a></p><p>Author: Thomas Ott, Ruedi Stoop</p><p>Abstract: We rigorously establish a close relationship between message passing algorithms and models of neurodynamics by showing that the equations of a continuous Hopﬁeld network can be derived from the equations of belief propagation on a binary Markov random ﬁeld. As Hopﬁeld networks are equipped with a Lyapunov function, convergence is guaranteed. As a consequence, in the limit of many weak connections per neuron, Hopﬁeld networks exactly implement a continuous-time variant of belief propagation starting from message initialisations that prevent from running into convergence problems. Our results lead to a better understanding of the role of message passing algorithms in real biological neural networks.</p><br/>
<h2>reference text</h2><p>[1] Yedidia, J.S., Freeman, W.T., Weiss, Y. (2003) Understanding belief propagtion and its generalizations. In G. Lakemeyer and B. Nebel (eds.) Exploring Artiﬁcial Intelligence in the New Millenium, Morgan Kaufmann, San Francisco.</p>
<p>[2] Mooij, J.M., Kappen, H.J. (2005) On the properties of the Bethe approximation and loopy belief propagation on binary networks. J.Stat.Mech., doi:10.1088/1742-5468/2005/11/P11012.</p>
<p>[3] Welling, M., Teh, W.T. (2003) Approximate inference in Boltzmann machines. Artiﬁcial Intelligence 143:19-50.</p>
<p>[4] Geman, S., Geman, D. (1984) Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. IEEE-PAMI 6(6):721-741.</p>
<p>[5] Huang, K. (1987) Statistical mechanics. Second edition, John Wiley & Sons, New York, Chapter 13.</p>
<p>[6] Haykin, S. (1999) Neural networks - a comprehensive foundation. Second edition, Prentice-Hall, Inc., Chapter 14.</p>
<p>[7] Koch, C. (1999), Biophysics of computation. Oxford University Press, Inc., New York.</p>
<p>[8] Douglas, R.J., Mahowald, M., Martin, K.A.C., Stratford, K.J. (1996) The role of synapses in cortical computation. Journal of Neurocytology 25: 893-911.</p>
<p>[9] Hopﬁeld, J.J. (1984) Neurons with graded response have collective computational properties like those of two-state neurons. PNAS 81:3088-3092.</p>
<p>[10] Heskes, T. (2004) On the uniqueness of loopy belief propagation ﬁxed points. Neural Comput. 16:2379-2413.</p>
<p>[11] Shon, A.P., Rao, R.P.N. (2005) Implementing belief propagation in neural circuits. Neurocomputing 65-66:877-884.</p>
<p>[12] Stoop, R., Stoop, N. (2004) Natural computation measured as a reduction of complexity. Chaos 14(3):675-679.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
