<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>181 nips-2006-Stability of $K$-Means Clustering</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2006" href="../home/nips2006_home.html">nips2006</a> <a title="nips-2006-181" href="../nips2006/nips-2006-Stability_of_%24K%24-Means_Clustering.html">nips2006-181</a> <a title="nips-2006-181-reference" href="#">nips2006-181-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>181 nips-2006-Stability of $K$-Means Clustering</h1>
<br/><p>Source: <a title="nips-2006-181-pdf" href="http://papers.nips.cc/paper/3116-stability-of-k-means-clustering.pdf">pdf</a></p><p>Author: Alexander Rakhlin, Andrea Caponnetto</p><p>Abstract: We phrase K-means clustering as an empirical risk minimization procedure over a class HK and explicitly calculate the covering number for this class. Next, we show that stability of K-means clustering is characterized by the geometry of HK with respect to the underlying distribution. We prove that in the case of a unique global minimizer, the clustering solution is stable with respect to complete changes of the data, while for the case of multiple minimizers, the change of Ω(n1/2 ) samples deﬁnes the transition between stability and instability. While for a ﬁnite number of minimizers this result follows from multinomial distribution estimates, the case of inﬁnite minimizers requires more reﬁned tools. We conclude by proving that stability of the functions in HK implies stability of the actual centers of the clusters. Since stability is often used for selecting the number of clusters in practice, we hope that our analysis serves as a starting point for ﬁnding theoretically grounded recipes for the choice of K. 1</p><br/>
<h2>reference text</h2><p>[1] Shai Ben-David. A framework for statistical clustering with a constant time approximation algorithms for k-median clustering. In COLT, pages 415–426, 2004.</p>
<p>[2] Ulrike von Luxburg and Shai Ben-David. Towards a statistical theory of clustering. PASCAL Workshop on Statistics and Optimization of Clustering, 2005.</p>
<p>[3] Shai Ben-David, Ulrike von Luxburg, and David Pal. A sober look at clustering stability. In COLT, 2006.</p>
<p>[4] A. Rakhlin. Stability of clustering methods. NIPS Workshop ”Theoretical Foundations of Clustering”, December 2005.</p>
<p>[5] A. Ben-Hur, A. Elisseeff, and I. Guyon. A stability based method for discovering structure in clustered data. In Pasiﬁc Symposium on Biocomputing, volume 7, pages 6–17, 2002.</p>
<p>[6] T. Lange, M. Braun, V. Roth, and J. Buhmann. Stability-based model selection. In NIPS, 2003.</p>
<p>[7] Joachim M. Buhmann. Empirical risk approximation: An induction principle for unsupervised learning. Technical Report IAI-TR-98-3, 3, 1998.</p>
<p>[8] A. Caponnetto and A. Rakhlin. Some properties of empirical risk minimization over Donsker classes. AI Memo 2005-018, Massachusetts Institute of Technology, May 2005.</p>
<p>[9] A. Caponnetto and A. Rakhlin. Stability properties of empirical risk minimization over Donsker classes. Journal of Machine Learning Research. Accepted. Available at http://cbcl.mit.edu/people/rakhlin/erm.pdf, 2006.</p>
<p>[10] Trevor Hastie, Robert Tibshirani, and Jerome Friedman. The Elements of Statistical Learning - Data Mining, Inference, and Prediction. Springer, 2002.</p>
<p>[11] Marina Meil˘ . Comparing clusterings: an axiomatic view. In ICML ’05: Proceedings of the a 22nd international conference on Machine learning, pages 577–584, New York, NY, USA, 2005. ACM Press.</p>
<p>[12] S.A. van de Geer. Empirical Processes in M-Estimation. Cambridge University Press, 2000.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
