<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>105 nips-2006-Large Margin Component Analysis</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2006" href="../home/nips2006_home.html">nips2006</a> <a title="nips-2006-105" href="../nips2006/nips-2006-Large_Margin_Component_Analysis.html">nips2006-105</a> <a title="nips-2006-105-reference" href="#">nips2006-105-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>105 nips-2006-Large Margin Component Analysis</h1>
<br/><p>Source: <a title="nips-2006-105-pdf" href="http://papers.nips.cc/paper/3088-large-margin-component-analysis.pdf">pdf</a></p><p>Author: Lorenzo Torresani, Kuang-chih Lee</p><p>Abstract: Metric learning has been shown to signiﬁcantly improve the accuracy of k-nearest neighbor (kNN) classiﬁcation. In problems involving thousands of features, distance learning algorithms cannot be used due to overﬁtting and high computational complexity. In such cases, previous work has relied on a two-step solution: ﬁrst apply dimensionality reduction methods to the data, and then learn a metric in the resulting low-dimensional subspace. In this paper we show that better classiﬁcation performance can be achieved by unifying the objectives of dimensionality reduction and metric learning. We propose a method that solves for the low-dimensional projection of the inputs, which minimizes a metric objective aimed at separating points in different classes by a large margin. This projection is deﬁned by a signiﬁcantly smaller number of parameters than metrics learned in input space, and thus our optimization reduces the risks of overﬁtting. Theory and results are presented for both a linear as well as a kernelized version of the algorithm. Overall, we achieve classiﬁcation rates similar, and in several cases superior, to those of support vector machines. 1</p><br/>
<h2>reference text</h2><p>[1] S. Chopra, R. Hadsell, and Y. LeCun. Learning a similarity metric discriminatively, with application to face veriﬁcation. In Proc. IEEE Conference on Computer Vision and Pattern Recognition, 2005.</p>
<p>[2] R. A. Fisher. The use of multiple measurements in taxonomic problems. Ann. Eugenics, 7:179–188, 1936.</p>
<p>[3] A. Globerson and S. Roweis. Metric learning by collapsing classes. In Y. Weiss, B. Sch¨ lkopf, and o J. Platt, editors, Advances in Neural Information Processing Systems 18. MIT Press, Cambridge, MA, 2006.</p>
<p>[4] J. Goldberger, S. Roweis, G. Hinton, and R. Salakhutdinov. Neighbourhood components analysis. In L. K. Saul, Y. Weiss, and L. Bottou, editors, Advances in Neural Information Processing Systems 17, 2005.</p>
<p>[5] T. Hastie and R. Tibshirani. Discriminant adaptive nearest neighbor classiﬁcation. IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), 18:607–616, 1996.</p>
<p>[6] A. Mordecai. Nonlinear Programming: Analysis and Methods. Dover Publishing, 2003.</p>
<p>[7] F. Pereira and G. Gordon. The support vector decomposition machine. In Proceedings of the International Conference on Machine Learning (ICML), 2006.</p>
<p>[8] J. D. M. Rennie and N. Srebro. Fast maximum margin matrix factorization for collaborative prediction. In Proceedings of the 22nd International Conference on Machine Learning (ICML), 2005.</p>
<p>[9] K. Q. Weinberger, J. Blitzer, and L. K. Saul. Distance metric learning for large margin nearest neighbor classiﬁcation. In Y. Weiss, B. Sch¨ lkopf, and J. Platt, editors, Advances in Neural Information Processing o Systems 18, 2006.</p>
<p>[10] E. P. Xing, A. Y. Ng, M. I. Jordan, , and S. Russell. Distance metric learning, with application to clustering with side-information. In T. G. Dietterich, S. Becker, and Z. Ghahramani, editors, Advances in Neural Information Processing Systems 14, 2002.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
