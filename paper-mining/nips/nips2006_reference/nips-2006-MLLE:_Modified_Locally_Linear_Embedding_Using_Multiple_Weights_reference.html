<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>127 nips-2006-MLLE: Modified Locally Linear Embedding Using Multiple Weights</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2006" href="../home/nips2006_home.html">nips2006</a> <a title="nips-2006-127" href="../nips2006/nips-2006-MLLE%3A_Modified_Locally_Linear_Embedding_Using_Multiple_Weights.html">nips2006-127</a> <a title="nips-2006-127-reference" href="#">nips2006-127-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>127 nips-2006-MLLE: Modified Locally Linear Embedding Using Multiple Weights</h1>
<br/><p>Source: <a title="nips-2006-127-pdf" href="http://papers.nips.cc/paper/3132-mlle-modified-locally-linear-embedding-using-multiple-weights.pdf">pdf</a></p><p>Author: Zhenyue Zhang, Jing Wang</p><p>Abstract: The locally linear embedding (LLE) is improved by introducing multiple linearly independent local weight vectors for each neighborhood. We characterize the reconstruction weights and show the existence of the linearly independent weight vectors at each neighborhood. The modiﬁed locally linear embedding (MLLE) proposed in this paper is much stable. It can retrieve the ideal embedding if MLLE is applied on data points sampled from an isometric manifold. MLLE is also compared with the local tangent space alignment (LTSA). Numerical examples are given that show the improvement and efﬁciency of MLLE. 1</p><br/>
<h2>reference text</h2><p>[1] D. Donoho and C. Grimes. Hessian Eigenmaps: new tools for nonlinear dimensionality reduction. Proceedings of National Academy of Science, 5591-5596, 2003 2  The data set can be downloaded at http://www.cs.toronto.edu/ roweis/data.html.  LLE  MLLE  5  3  4  2.5  3  2  2 1.5 1 1 0 0.5 −1 0 −2 −0.5  −3  −1  −4  −5 −1.5  −1  −0.5  0  0.5  1  1.5  2  2.5  −1.5 −1.5  −1  −0.5  0  0.5  1  1.5  2  2.5  Figure 5: Embedding results of N = 4400 handwritten digits by LLE(left) and MLLE(right).  Figure 6: Images of faces mapped into the embedding described by the ﬁrst two coordinates of MLLE, using the parameters k = 14 and d = 3.</p>
<p>[2] M. Brand. Charting a manifold. Advances in Neural Information Processing Systems, 15, MIT Press, 2003</p>
<p>[3] Jihun Ham, Daniel D. Lee, Sebastian Mika, Bernhard Scholkopf. A kernel view of the dimensionality reduction of manifolds. International Conference On Machine Learning 21, 2004.</p>
<p>[4] G. H. Golub and C. F Van Loan. Matrix Computations. Johns Hopkins University Press, Baltimore, Maryland, 3nd edition, 1996.</p>
<p>[5] S. Roweis and L Saul. Nonlinear dimensionality reduction by locally linear embedding. Science, 290: 2323–2326, 2000.</p>
<p>[6] L. Saul and S. Roweis. Think globally, ﬁt locally: unsupervised learning of nonlinear manifolds. Journal of Machine Learning Research, 4:119-155, 2003.</p>
<p>[7] J Tenenbaum, V. De Silva and J. Langford. A global geometric framework for nonlinear dimension reduction. Science, 290:2319–2323, 2000</p>
<p>[8] J. Wang, Z. Zhang and H. Zha. Adaptive Manifold Learning. Advances in Neural Information Processing Systems 17, edited by Lawrence K. Saul and Yair Weiss and L´ on Bottou, MIT e Press, Cambridge, MA, pp.1473-1480, 2005.</p>
<p>[9] Z. Zhang and H. Zha. Principal Manifolds and Nonlinear Dimensionality Reduction via Tangent Space Alignment. SIAM J. Scientiﬁc Computing, 26(1):313–338, 2004.</p>
<p>[10] H. Zha and Z. Zhang. Spectral Analysis of Alignment in Manifold Learning. Submitted, 2006.</p>
<p>[11] M. Vlachos, C. Domeniconi, D. Gunopulos, G. Kollios, and N. Koudas Non-Linear Dimensionality Reduction Techniques for Classiﬁcation and Visualization Proc. Eighth ACM SIGKDD Int’l Conf. Knowledge Discovery and Data Mining, July 2002.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
