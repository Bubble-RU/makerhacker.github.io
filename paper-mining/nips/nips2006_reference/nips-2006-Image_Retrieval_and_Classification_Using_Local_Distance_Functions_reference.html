<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>94 nips-2006-Image Retrieval and Classification Using Local Distance Functions</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2006" href="../home/nips2006_home.html">nips2006</a> <a title="nips-2006-94" href="../nips2006/nips-2006-Image_Retrieval_and_Classification_Using_Local_Distance_Functions.html">nips2006-94</a> <a title="nips-2006-94-reference" href="#">nips2006-94-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>94 nips-2006-Image Retrieval and Classification Using Local Distance Functions</h1>
<br/><p>Source: <a title="nips-2006-94-pdf" href="http://papers.nips.cc/paper/3126-image-retrieval-and-classification-using-local-distance-functions.pdf">pdf</a></p><p>Author: Andrea Frome, Yoram Singer, Jitendra Malik</p><p>Abstract: In this paper we introduce and experiment with a framework for learning local perceptual distance functions for visual recognition. We learn a distance function for each training image as a combination of elementary distances between patch-based visual features. We apply these combined local distance functions to the tasks of image retrieval and classiﬁcation of novel images. On the Caltech 101 object recognition benchmark, we achieve 60.3% mean recognition across classes using 15 training images per class, which is better than the best published performance by Zhang, et al. 1</p><br/>
<h2>reference text</h2><p>[1] I. Biederman, “Recognition-by-components: A theory of human image understanding,” Psychological Review, vol. 94, no. 2, pp. 115–147, 1987.</p>
<p>[2] C. Schmid and R. Mohr, “Combining greyvalue invariants with local constraints for object recognition,” in CVPR, 1996.</p>
<p>[3] D. Lowe, “Object recognition from local scale-invariant features,” in ICCV, pp. 1000–1015, Sep 1999.</p>
<p>[4] S. Belongie, J. Malik, and J. Puzicha, “Shape matching and object recognition using shape contexts,” PAMI, vol. 24, pp. 509–522, April 2002.</p>
<p>[5] A. Berg and J. Malik, “Geometric blur for template matching,” in CVPR, pp. 607–614, 2001.</p>
<p>[6] E. Xing, A. Ng, and M. Jordan, “Distance metric learning with application to clustering with sideinformation,” in NIPS, 2002.</p>
<p>[7] Schutlz and Joachims, “Learning a distance metric from relative comparisons,” in NIPS, 2003.</p>
<p>[8] S. Shalev-Shwartz, Y. Singer, and A. Ng, “Online and batch learning of pseudo-metrics,” in ICML, 2004.</p>
<p>[9] K. Q. Weinberger, J. Blitzer, and L. K. Saul, “Distance metric learning for large margin nearest neighbor classiﬁcation,” in NIPS, 2005.</p>
<p>[10] A. Globerson and S. Roweis, “Metric learning by collapsing classes,” in NIPS, 2005.</p>
<p>[11] H. Zhang, A. Berg, M. Maire, and J. Malik, “SVM-KNN: Discriminative Nearset Neighbor Classiﬁcation for Visual Category Recognition,” in CVPR, 2006.</p>
<p>[12] Y. Censor and S. A. Zenios, Parallel Optimization: Theory, Algorithms, and Applications. Oxford University Press, 1998.</p>
<p>[13] A. Berg, T. Berg, and J. Malik, “Shape matching and object recognition using low distortion correspondence,” in CVPR, 2005.</p>
<p>[14] S. Lazebnik, C. Schmid, and J. Ponce, “Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories,” in CVPR, 2006.</p>
<p>[15] K. Grauman and T. Darrell, “Pyramic match kernels: Discriminative classﬁciation with sets of image features (version 2),” Tech. Rep. MIT CSAIL TR 2006-020, MIT, March 2006.</p>
<p>[16] J. Mutch and D. G. Lowe, “Multiclass object recognition with sparse, localized features,” in CVPR, 2006.</p>
<p>[17] E. L. Allwein, R. E. Schapire, and Y. Singer, “Reducing multiclass to binary: A unifying approach for margin classiﬁers,” JMLR, vol. 1, pp. 113–141, 2000.</p>
<p>[18] L. Fei-Fei, R. Fergus, and P. Perona, “Learning generative visual models from few training examples: an incremental bayesian approach testing on 101 object categories.,” in Workshop on Generative-Model Based Vision, CVPR, 2004.</p>
<p>[19] G. Wang, Y. Zhang, and L. Fei-Fei, “Using dependent regions for object categorization in a generative framework,” in CVPR, 2006.</p>
<p>[20] A. D. Holub, M. Welling, and P. Perona, “Combining generative models and ﬁsher kernels for object recognition,” in ICCV, 2005.</p>
<p>[21] T. Serre, L. Wolf, and T. Poggio, “Object recognition with features inspired by visual cortex,” in CVPR, 2005. 8  To further speed up comparisons, in place of an exact nearest neighbor computation, we could use approximate nearest neighbor algorithms such as locality-sensitive hashing or spill trees.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
