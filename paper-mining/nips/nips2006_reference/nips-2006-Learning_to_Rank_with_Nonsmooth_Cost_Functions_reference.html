<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>119 nips-2006-Learning to Rank with Nonsmooth Cost Functions</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2006" href="../home/nips2006_home.html">nips2006</a> <a title="nips-2006-119" href="../nips2006/nips-2006-Learning_to_Rank_with_Nonsmooth_Cost_Functions.html">nips2006-119</a> <a title="nips-2006-119-reference" href="#">nips2006-119-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>119 nips-2006-Learning to Rank with Nonsmooth Cost Functions</h1>
<br/><p>Source: <a title="nips-2006-119-pdf" href="http://papers.nips.cc/paper/2971-learning-to-rank-with-nonsmooth-cost-functions.pdf">pdf</a></p><p>Author: Christopher J. Burges, Robert Ragno, Quoc V. Le</p><p>Abstract: The quality measures used in information retrieval are particularly difﬁcult to optimize directly, since they depend on the model scores only through the sorted order of the documents returned for a given query. Thus, the derivatives of the cost with respect to the model parameters are either zero, or are undeﬁned. In this paper, we propose a class of simple, ﬂexible algorithms, called LambdaRank, which avoids these difﬁculties by working with implicit cost functions. We describe LambdaRank using neural network models, although the idea applies to any differentiable function class. We give necessary and sufﬁcient conditions for the resulting implicit cost function to be convex, and we show that the general method has a simple mechanical interpretation. We demonstrate signiﬁcantly improved accuracy, over a state-of-the-art ranking algorithm, on several datasets. We also show that LambdaRank provides a method for signiﬁcantly speeding up the training phase of that ranking algorithm. Although this paper is directed towards ranking, the proposed method can be extended to any non-smooth and multivariate cost functions. 1</p><br/>
<h2>reference text</h2><p>[1] C. Buckley and E. Voorhees. Evaluating evaluation measure stability. In SIGIR, pages 33–40, 2000.</p>
<p>[2] C.J.C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender. Learning to Rank using Gradient Descent. In ICML 22, Bonn, Germany, 2005.</p>
<p>[3] C. Cortes and M. Mohri. Conﬁdence Intervals for the Area Under the ROC Curve. In NIPS 18. MIT Press, 2005.</p>
<p>[4] Y. Freund, R. Iyer, R.E. Schapire, and Y. Singer. An efﬁcient boosting algorithm for combining preferences. Journal of Machine Learning Research, 4:933–969, 2003.</p>
<p>[5] J. Friedman, T. Hastie, and R. Tibshirani. Additive logistic regression: A statistical view of boosting. The Annals of Statistics, 28(2):337–374, 2000.</p>
<p>[6] K. Jarvelin and J. Kekalainen. IR evaluation methods for retrieving highly relevant documents. In SIGIR 23. ACM, 2000.</p>
<p>[7] T. Joachims. A support vector method for multivariate performance measures. In ICML 22, 2005.</p>
<p>[8] I. Matveeva, C. Burges, T. Burkard, A. Lauscius, and L. Wong. High accuracy retrieval with multiple nested rankers. In SIGIR, 2006.</p>
<p>[9] I. Newton. Philosophiae Naturalis Principia Mathematica. The Royal Society, 1687.</p>
<p>[10] S. Robertson and H. Zaragoza. On rank-based effectiveness measures and optimisation. Technical Report MSR-TR-2006-61, Microsoft Research, 2006.</p>
<p>[11] M. Spivak. Calculus on Manifolds. Addison-Wesley, 1965.</p>
<p>[12] B. Taskar, V. Chatalbashev, D. Koller, and C. Guestrin. Learning structured prediciton models: A large margin approach. In ICML 22, Bonn, Germany, 2005.</p>
<p>[13] I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun. Support vector machine learning for interdependent and structured output spaces. In ICML 24, 2004.</p>
<p>[14] E.M. Voorhees. Overview of the TREC 2001/2002 Question Answering Track. In TREC, 2001,2002.</p>
<p>[15] L. Yan, R. Dodlier, M.C. Mozer, and R. Wolniewicz. Optimizing Classiﬁer Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic. In ICML 20, 2003.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
