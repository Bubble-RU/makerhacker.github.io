<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>7 nips-2006-A Local Learning Approach for Clustering</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2006" href="../home/nips2006_home.html">nips2006</a> <a title="nips-2006-7" href="../nips2006/nips-2006-A_Local_Learning_Approach_for_Clustering.html">nips2006-7</a> <a title="nips-2006-7-reference" href="#">nips2006-7-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>7 nips-2006-A Local Learning Approach for Clustering</h1>
<br/><p>Source: <a title="nips-2006-7-pdf" href="http://papers.nips.cc/paper/3115-a-local-learning-approach-for-clustering.pdf">pdf</a></p><p>Author: Mingrui Wu, Bernhard Schölkopf</p><p>Abstract: We present a local learning approach for clustering. The basic idea is that a good clustering result should have the property that the cluster label of each data point can be well predicted based on its neighboring data and their cluster labels, using current supervised learning methods. An optimization problem is formulated such that its solution has the above property. Relaxation and eigen-decomposition are applied to solve this optimization problem. We also brieﬂy investigate the parameter selection issue and provide a simple parameter selection method for the proposed algorithm. Experimental results are provided to validate the effectiveness of the proposed approach. 1</p><br/>
<h2>reference text</h2><p>[1] L. Bottou and V. Vapnik. Local learning algorithms. Neural Computation, 4:888–900, 1992.</p>
<p>[2] P. K. Chan, M. D. F. Schlag, and J. Y. Zien. Spectral k-way ratio-cut partitioning and clustering. IEEE Transactions on Computer-aided Design of Integrated Circuits and Systems, 13:1088– 1096, 1994.</p>
<p>[3] A. Y. Ng, M. I. Jordan, and Y. Weiss. On spectral clustering: analysis and an algorithm. In T. G. Dietterich, S. Becker, and Z. Ghahramani, editors, Advances in Neural Information Processing Systems 14, Cambridge, MA, 2002. MIT Press.</p>
<p>[4] C. H. Papadimitriou and K. Steiglitz. Combinatorial Optimization: Algorithms and Complexity. Dover, New York, 1998.</p>
<p>[5] B. Sch¨ lkopf and A. J. Smola. Learning with Kernels. The MIT Press, Cambridge, MA, 2002. o</p>
<p>[6] J. Shawe-Taylor and N. Cristianini. Kernel Methods for Pattern Analysis. Cambridge University Press, Cambridge, UK, 2004.</p>
<p>[7] A. Strehl and J. Ghosh. Cluster ensembles – a knowledge reuse framework for combining multiple partitions. Journal of Machine Learning Research, 3:583–617, 2002.</p>
<p>[8] V. Vapnik. The Nature of Statistical Learning Theory. Springer Verlag, New York, 1995.</p>
<p>[9] L. Xu, J. Neufeld, B. Larson, and D. Schuurmans. Maximum margin clustering. In L. K. Saul, Y. Weiss, and L. Bottou, editors, Advances in Neural Information Processing Systems 17. MIT Press, Cambridge, MA, 2005.</p>
<p>[10] S. X. Yu and J. Shi. Multiclass spectral clustering. In L. D. Raedt and S. Wrobel, editors, International Conference on Computer Vision. ACM, 2003.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
