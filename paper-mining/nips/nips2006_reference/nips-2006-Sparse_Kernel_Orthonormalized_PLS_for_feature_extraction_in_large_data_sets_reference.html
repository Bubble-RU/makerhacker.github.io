<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>177 nips-2006-Sparse Kernel Orthonormalized PLS for feature extraction in large data sets</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2006" href="../home/nips2006_home.html">nips2006</a> <a title="nips-2006-177" href="../nips2006/nips-2006-Sparse_Kernel_Orthonormalized_PLS_for_feature_extraction_in_large_data_sets.html">nips2006-177</a> <a title="nips-2006-177-reference" href="#">nips2006-177-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>177 nips-2006-Sparse Kernel Orthonormalized PLS for feature extraction in large data sets</h1>
<br/><p>Source: <a title="nips-2006-177-pdf" href="http://papers.nips.cc/paper/2970-sparse-kernel-orthonormalized-pls-for-feature-extraction-in-large-data-sets.pdf">pdf</a></p><p>Author: Jerónimo Arenas-garcía, Kaare B. Petersen, Lars K. Hansen</p><p>Abstract: In this paper we are presenting a novel multivariate analysis method. Our scheme is based on a novel kernel orthonormalized partial least squares (PLS) variant for feature extraction, imposing sparsity constrains in the solution to improve scalability. The algorithm is tested on a benchmark of UCI data sets, and on the analysis of integrated short-time music features for genre prediction. The upshot is that the method has strong expressive power even with rather few features, is clearly outperforming the ordinary kernel PLS, and therefore is an appealing method for feature extraction of labelled data. 1</p><br/>
<h2>reference text</h2><p>[1] Paul Geladi. Notes on the history and nature of partial least squares (PLS) modelling. Journal of Chemometrics, 2:231–246, 1988.</p>
<p>[2] L. Hoegaerts, J. A. K. Suykens, J. Vanderwalle, and B. De Moor. Primal space sparse kernel partial least squares regression for large problems. In Proceedings of International Joint Conference on Neural Networks (IJCNN), 2004.</p>
<p>[3] Agnar Hoskuldsson. PLS regression methods. Journal of Chemometrics, 2:211–228, 1988.</p>
<p>[4] Yuh-Jye Lee and O. L. Mangasarian. RSVM: reduced support vector machines. In Data Mining Institute Technical Report 00-07, July 2000. CD Proceedings of the SIAM International Conference on Data Mining, Chicago, April 5-7, 2001,, 2001.</p>
<p>[5] Anders Meng, Peter Ahrendt, Jan Larsen, and Lars Kai Hansen. Temporal feature integration for music genre classiﬁcation. IEEE Trans. Audio, Speech & Language Process., to appear.</p>
<p>[6] Michinari Momma and Kristin Bennett. Sparse kernel partial least squares regression. In Proceedings of Conference on learning theory (COLT), 2003.</p>
<p>[7] Roman Rosipal and Leonard J. Trejo. Kernel partial least squares regression in reproducing kernel hilbert space. Journal of Machine Learning Research, 2:97–123, 2001.</p>
<p>[8] Roman Rosipal, Leonard J. Trejo, and Bryan Matthews. Kernel pls-svc for linear and nonlinear classiﬁction. In Proceedings of Internation Conference on Machine Learning (ICML), 2003.</p>
<p>[9] Kramer N. Rosipal R. Overview and recent advances in partial least squares. In Subspace, Latent Structure and Feature Selection Techniques, 2006.</p>
<p>[10] Sam Roweis and Carlos Brody. Linear heteroencoders. Technical report, Gatsby Computational Neuroscience Unit, 1999.</p>
<p>[11] Paul D. Sampson, Ann P. Streissguth, Helen M. Barr, and Fred L. Bookstein. Neurobehavioral effetcs of prenatal alcohol: Part II. Partial Least Squares analysis. Neurotoxicology and teratology, 11:477–491, 1989.</p>
<p>[12] Bernhard Schoelkopf and Alexander Smola. Learning with kernels. MIT Press, 2002.</p>
<p>[13] John Shawe-Taylor and Nello Christiani. Kernel Methods for Pattern Analysis. Cambridge University Press, 2004.</p>
<p>[14] George Tzanetakis and Perry Cook. Music genre classiﬁcation of audio signals. IEEE Transactions on Speech and Audio Processing, 10(5):293–302, July 2002.</p>
<p>[15] Jacob A. Wegelin. A survey of partial least squares (PLS) methods, with emphasis on the two-block case. Technical report, University of Washington, 2000.</p>
<p>[16] Herman Wold. Path models with latent variables: the NIPALS approach. In Quatitative sociology: International perspectives on mathematical and statistical Model Building, pages 307–357. Academic Press, 1975.</p>
<p>[17] S. Wold, C. Albano, W. J. Dunn, U. Edlund, K. Esbensen, P. Geladi, S. Hellberg, E. Johansson, W. Lindberg, and M. Sjostrom. Chemometrics, Mathematics and Statistics in Chemistry, chapter Multivariate Data Analysis in Chemistry, page 17. Reidel Publishing Company, 1984.</p>
<p>[18] K. Worsley, J. Poline, K. Friston, and A. Evans. Characterizing the response of pet and fMRI data using multivariate linear models (MLM). NeuroImage, 6:305– 319, 1998.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
