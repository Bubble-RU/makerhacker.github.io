<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>85 nips-2006-Geometric entropy minimization (GEM) for anomaly detection and localization</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2006" href="../home/nips2006_home.html">nips2006</a> <a title="nips-2006-85" href="../nips2006/nips-2006-Geometric_entropy_minimization_%28GEM%29_for_anomaly_detection_and_localization.html">nips2006-85</a> <a title="nips-2006-85-reference" href="#">nips2006-85-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>85 nips-2006-Geometric entropy minimization (GEM) for anomaly detection and localization</h1>
<br/><p>Source: <a title="nips-2006-85-pdf" href="http://papers.nips.cc/paper/3145-geometric-entropy-minimization-gem-for-anomaly-detection-and-localization.pdf">pdf</a></p><p>Author: Alfred O. Hero</p><p>Abstract: We introduce a novel adaptive non-parametric anomaly detection approach, called GEM, that is based on the minimal covering properties of K-point entropic graphs when constructed on N training samples from a nominal probability distribution. Such graphs have the property that as N → ∞ their span recovers the entropy minimizing set that supports at least ρ = K/N (100)% of the mass of the Lebesgue part of the distribution. When a test sample falls outside of the entropy minimizing set an anomaly can be declared at a statistical level of signiﬁcance α = 1 − ρ. A method for implementing this non-parametric anomaly detector is proposed that approximates this minimum entropy set by the inﬂuence region of a K-point entropic graph built on the training data. By implementing an incremental leave-one-out k-nearest neighbor graph on resampled subsets of the training data GEM can efﬁciently detect outliers at a given level of signiﬁcance and compute their empirical p-values. We illustrate GEM for several simulated and real data sets in high dimensional feature spaces. 1</p><br/>
<h2>reference text</h2><p>[1] A. Hero, B. Ma, O. Michel, and J. Gorman, “Applications of entropic spanning graphs,” IEEE Signal Processing Magazine, vol. 19, pp. 85–95, Sept. 2002. www.eecs.umich.edu/˜hero/imag_proc.html.</p>
<p>[2] A. Hero and O. Michel, “Asymptotic theory of greedy approximations to minimal k-point random graphs,” IEEE Trans. on Inform. Theory, vol. IT-45, no. 6, pp. 1921–1939, Sept. 1999.</p>
<p>[3] T. S. Ferguson, Mathematical Statistics - A Decision Theoretic Approach. Academic Press, Orlando FL, 1967.</p>
<p>[4] I. V. Nikiforov and M. Basseville, Detection of abrupt changes: theory and applications. Prentice-Hall, Englewood-Cliffs, NJ, 1993.</p>
<p>[5] B. Scholkopf, R. Williamson, A. Smola, J. Shawe-Taylor, and J. Platt, “Support vector method for novelty detection,” in Advances in Neural Information Processing Systems (NIPS), vol. 13, 2000.</p>
<p>[6] G. R. G. Lanckriet, L. El Ghaoui, and M. I. Jordan, “Robust novelty detection with single-class mpm,” in Advances in Neural Information Processing Systems (NIPS), vol. 15, 2002.</p>
<p>[7] C. Scott and R. Nowak, “Learning minimum volume sets,” Journal of Machine Learning Research, vol. 7, pp. 665–704, April 2006.</p>
<p>[8] A. Lazarevic, A. Ozgur, L. Ertoz, J. Srivastava, and V. Kumar, “A comparative study of anomaly detection schemes in network intrusion detection,” in SIAM Conference on data mining, 2003.</p>
<p>[9] S. Ramaswamy, R. Rastogi, and K. Shim, “Efﬁcient algorithms for mining outliers from large data sets,” in Proceedings of the ACM SIGMOD Conference, 2000.</p>
<p>[10] R. Ravi, M. Marathe, D. Rosenkrantz, and S. Ravi, “Spanning trees short or small,” in Proc. 5th Annual ACM-SIAM Symposium on Discrete Algorithms, (Arlington, VA), pp. 546–555, 1994.</p>
<p>[11] J. E. Yukich, Probability theory of classical Euclidean optimization, vol. 1675 of Lecture Notes in Mathematics. Springer-Verlag, Berlin, 1998.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
