<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>48 nips-2006-Branch and Bound for Semi-Supervised Support Vector Machines</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2006" href="../home/nips2006_home.html">nips2006</a> <a title="nips-2006-48" href="../nips2006/nips-2006-Branch_and_Bound_for_Semi-Supervised_Support_Vector_Machines.html">nips2006-48</a> <a title="nips-2006-48-reference" href="#">nips2006-48-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>48 nips-2006-Branch and Bound for Semi-Supervised Support Vector Machines</h1>
<br/><p>Source: <a title="nips-2006-48-pdf" href="http://papers.nips.cc/paper/3135-branch-and-bound-for-semi-supervised-support-vector-machines.pdf">pdf</a></p><p>Author: Olivier Chapelle, Vikas Sindhwani, S. S. Keerthi</p><p>Abstract: Semi-supervised SVMs (S3 VM) attempt to learn low-density separators by maximizing the margin over labeled and unlabeled examples. The associated optimization problem is non-convex. To examine the full potential of S3 VMs modulo local minima problems in current implementations, we apply branch and bound techniques for obtaining exact, globally optimal solutions. Empirical evidence suggests that the globally optimal solution can return excellent generalization performance in situations where other implementations fail completely. While our current implementation is only applicable to small datasets, we discuss variants that can potentially lead to practically useful algorithms. 1</p><br/>
<h2>reference text</h2><p>[1] K. Bennett and A. Demiriz. Semi-supervised support vector machines. In Advances in Neural Information processing systems 12, 1998.</p>
<p>[2] G. Cauwenberghs and T. Poggio. Incremental and decremental support vector machine learning. In Advances in Neural Information Processing Systems, pages 409–415, 2000.</p>
<p>[3] O. Chapelle, M. Chi, and A. Zien. A continuation method for semi-supervised svms. In International Conference on Machine Learning, 2006.</p>
<p>[4] O. Chapelle, B. Sch¨lkopf, and A. Zien, editors. Semi-Supervised Learning. MIT Press, Camo bridge, 2006. in press. www.kyb.tuebingen.mpg.de/ssl-book/.</p>
<p>[5] O. Chapelle, V. Vapnik, O. Bousquet, and S. Mukherjee. Choosing multiple parameters for support vector machines. Machine Learning, 46:131–159, 2002.</p>
<p>[6] O. Chapelle and A. Zien. Semi-supervised classiﬁcation by low density separation. In Tenth International Workshop on Artiﬁcial Intelligence and Statistics, 2005.</p>
<p>[7] R. Collobert, F. Sinz, J. Weston, and L. Bottou. Large scale transductive SVMs. Journal of Machine Learning Research, 7:1687–1712, 2006.</p>
<p>[8] W. Gander, G. H. Golub, and U. Von Matt. A constrained eigenvalue problem. Linear Algebra and its Applications, 114/115:815–839, 1989.</p>
<p>[9] T. Joachims. Transductive inference for text classiﬁcation using support vector machines. In International Conference on Machine Learning, 1999.</p>
<p>[10] P.M. Pardalos and G.P. Rodgers. Computational aspects of a branch and bound algorithm for quadratic zero-one programming. Computing, 45:131–144, 1990.</p>
<p>[11] M. Seeger. A taxonomy of semi-supervised learning methods. In O. Chapelle, B. Sch¨lkopf, o and A. Zien, editors, Semi-Supervised Lerning. MIT Press, 2006.</p>
<p>[12] V. Sindhwani, S. Keerthi, and O. Chapelle. Deterministic annealing for semi-supervised kernel machines. In International Conference on Machine Learning, 2006.</p>
<p>[13] V. Sindhwani, P. Niyogi, and M. Belkin. Beyond the point cloud: From transductive to semi-supervised learning. In International Conference on Machine Learning, 2005.</p>
<p>[14] V. Vapnik and A. Sterin. On structural risk minimization or overall risk in a problem of pattern recognition. Automation and Remote Control, 10(3):1495–1503, 1977.</p>
<p>[15] V. N. Vapnik. Statistical Learning Theory. John Wiley & Sons, Inc., New York, 1998.</p>
<p>[16] W. Wapnik and A. Tscherwonenkis. Theorie der Zeichenerkennung. Akademie Verlag, Berlin, 1979.</p>
<p>[17] X. Zhu and Z. Ghahramani. Learning from labeled and unlabeled data with label propagation. Technical Report 02-107, CMU-CALD, 2002.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
