<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>43 nips-2006-Bayesian Model Scoring in Markov Random Fields</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2006" href="../home/nips2006_home.html">nips2006</a> <a title="nips-2006-43" href="../nips2006/nips-2006-Bayesian_Model_Scoring_in_Markov_Random_Fields.html">nips2006-43</a> <a title="nips-2006-43-reference" href="#">nips2006-43-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>43 nips-2006-Bayesian Model Scoring in Markov Random Fields</h1>
<br/><p>Source: <a title="nips-2006-43-pdf" href="http://papers.nips.cc/paper/3149-bayesian-model-scoring-in-markov-random-fields.pdf">pdf</a></p><p>Author: Sridevi Parise, Max Welling</p><p>Abstract: Scoring structures of undirected graphical models by means of evaluating the marginal likelihood is very hard. The main reason is the presence of the partition function which is intractable to evaluate, let alone integrate over. We propose to approximate the marginal likelihood by employing two levels of approximation: we assume normality of the posterior (the Laplace approximation) and approximate all remaining intractable quantities using belief propagation and the linear response approximation. This results in a fast procedure for model scoring. Empirically, we ﬁnd that our procedure has about two orders of magnitude better accuracy than standard BIC methods for small datasets, but deteriorates when the size of the dataset grows. 1</p><br/>
<h2>reference text</h2><p>[1] M.J. Beal and Z. Ghahramani. The variational bayesian EM algorithm for incomplete data: with application to scoring graphical model structures. In Bayesian Statistics, pages 453–464. Oxford University Press, 2003.</p>
<p>[2] P. Green and S. Richardson. Hidden markov models and disease mapping. Journal of the American Statistical Association, 97(460):1055–1070, 2002.</p>
<p>[3] D. Heckerman. A tutorial on learning with bayesian networks. pages 301–354, 1999.</p>
<p>[4] A. McCallum and D. Freitag F. Pereira. Maximum entropy Markov models for information extraction and segmentation. In Int’l Conf. on Machine Learning, pages p.591–598, San Francisco, 2000.</p>
<p>[5] T.S. Jaakkola M.J. Wainwright and A.S. Willsky. Tree-reweighted belief propagation algorithms and approximate ml estimation via pseudo-moment matching. In AISTATS, 2003.</p>
<p>[6] J. Møller, A. Pettitt, K. Berthelsen, and R. Reeves. An efﬁcient Markov chain Monte Carlo method for distributions with intractable normalisation constants. Biometrica, 93, 2006. to appear.</p>
<p>[7] I. Murray and Z. Ghahramani. Bayesian learning in undirected graphical models: approximate MCMC algorithms. In Proceedings of the 14th Annual Conference on Uncertainty in Artiﬁcial Intelligence (UAI-04), San Francisco, CA, 2004.</p>
<p>[8] I. Murray, Z. Ghahramani, and D.J.C. MacKay. Mcmc for doubly-intractable distributions. In Proceedings of the 14th Annual Conference on Uncertainty in Artiﬁcial Intelligence (UAI-06), Pittsburgh, PA, 2006.</p>
<p>[9] R.M. Neal. Annealed importance sampling. In Statistics and Computing, pages 125–139, 2001.</p>
<p>[10] S. Parise and M. Welling. Learning in markov random ﬁelds: An empirical study. In Proc. of the Joint Statistical Meeting – JSM2005, 2005.</p>
<p>[11] Y. Qi, M. Szummer, and T.P. Minka. Bayesian conditional random ﬁelds. In Artiﬁcial Intelligence and Statistics, 2005.</p>
<p>[12] K. Tanaka. Probabilistic inference by means of cluster variation method and linear response theory. IEICE Transactions in Information and Systems, E86-D(7):1228–1242, 2003.</p>
<p>[13] M. Welling and S. Parise. Bayesian random ﬁelds: The Bethe-Laplace approximation. In UAI, 2006.</p>
<p>[14] M. Welling and Y.W. Teh. Approximate inference in boltzmann machines. Artiﬁcial Intelligence, 143:19–50, 2003.</p>
<p>[15] M. Welling and Y.W. Teh. Linear response algorithms for approximate inference in graphical models. Neural Computation, 16 (1):197–221, 2004.</p>
<p>[16] J.S. Yedidia, W. Freeman, and Y. Weiss. Constructing free energy approximations and generalized belief propagation algorithms. Technical report, MERL, 2002. Technical Report TR-2002-35.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
