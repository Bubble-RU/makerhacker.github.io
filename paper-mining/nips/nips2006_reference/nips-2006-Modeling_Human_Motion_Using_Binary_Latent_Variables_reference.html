<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>134 nips-2006-Modeling Human Motion Using Binary Latent Variables</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2006" href="../home/nips2006_home.html">nips2006</a> <a title="nips-2006-134" href="../nips2006/nips-2006-Modeling_Human_Motion_Using_Binary_Latent_Variables.html">nips2006-134</a> <a title="nips-2006-134-reference" href="#">nips2006-134-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>134 nips-2006-Modeling Human Motion Using Binary Latent Variables</h1>
<br/><p>Source: <a title="nips-2006-134-pdf" href="http://papers.nips.cc/paper/3078-modeling-human-motion-using-binary-latent-variables.pdf">pdf</a></p><p>Author: Graham W. Taylor, Geoffrey E. Hinton, Sam T. Roweis</p><p>Abstract: We propose a non-linear generative model for human motion data that uses an undirected model with binary latent variables and real-valued “visible” variables that represent joint angles. The latent and visible variables at each time step receive directed connections from the visible variables at the last few time-steps. Such an architecture makes on-line inference efﬁcient and allows us to use a simple approximate learning procedure. After training, the model ﬁnds a single set of parameters that simultaneously capture several different kinds of motion. We demonstrate the power of our approach by synthesizing various motion sequences and by performing on-line ﬁlling in of data lost during motion capture. Website: http://www.cs.toronto.edu/∼gwtaylor/publications/nips2006mhmublv/</p><br/>
<h2>reference text</h2><p>[1] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based learning applied to document recognition,” Proceedings of the IEEE, vol. 86, pp. 2278–2324, November 1998.</p>
<p>[2] C. K. Liu, A. Hertzmann, and Z. Popovic, “Learning physics-based motion style with nonlinear inverse optimization,” ACM Trans. Graph., vol. 24, no. 3, pp. 1071–1081, 2005.</p>
<p>[3] O. Arikan, D. A. Forsyth, and J. F. O’Brien, “Motion synthesis from annotations,” in Proc. SIGGRAPH, 2002.</p>
<p>[4] M. Brand and A. Hertzmann, “Style machines.,” in Proc. SIGGRAPH, pp. 183–192, 2000.</p>
<p>[5] Y. Li, T. Wang, and H.-Y. Shum, “Motion texture: a two-level statistical model for character motion synthesis,” in Proc. SIGGRAPH, pp. 465–472, 2002.</p>
<p>[6] R. Urtasun, P. Glardon, R. Boulic, D. Thalmann, and P. Fua, “Style-based Motion Synthesis,” Computer Graphics Forum, vol. 23, no. 4, pp. 1–14, 2004.</p>
<p>[7] M. Welling, M. Rosen-Zvi, and G. E. Hinton, “Exponential family harmoniums with an application to information retrieval.,” in Proc. NIPS 17, 2005.</p>
<p>[8] Y. Freund and D. Haussler, “Unsupervised learning of distributions of binary vectors using 2-layer networks,” in Proc. NIPS 4, 1992.</p>
<p>[9] G. E. Hinton, “Training products of experts by minimizing contrastive divergence.,” Neural Comput, vol. 14, pp. 1771–1800, Aug 2002.</p>
<p>[10] I. Sutskever and G. E. Hinton, “Learning multilevel distributed representations for high-dimensional sequences,” Tech. Rep. UTML TR 2006-003, University of Toronto, 2006.</p>
<p>[11] Y. W. Teh and G. E. Hinton, “Rate-coded restricted Boltzmann machines for face recognition,” in Proc. NIPS 13, 2001.</p>
<p>[12] E. Hsu, K. Pulli, and J. Popoviˆ , “Style translation for human motion,” ACM Trans. Graph., vol. 24, no. 3, c pp. 1082–1089, 2005.</p>
<p>[13] F. S. Grassia, “Practical parameterization of rotations using the exponential map,” J. Graph. Tools, vol. 3, no. 3, pp. 29–48, 1998.</p>
<p>[14] G. E. Hinton, S. Osindero, and Y.-W. Teh, “A fast learning algorithm for deep belief nets,” Neural Comp., vol. 18, no. 7, pp. 1527–1554, 2006.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
