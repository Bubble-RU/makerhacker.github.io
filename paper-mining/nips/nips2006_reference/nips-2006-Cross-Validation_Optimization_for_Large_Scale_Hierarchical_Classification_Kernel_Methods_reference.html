<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>63 nips-2006-Cross-Validation Optimization for Large Scale Hierarchical Classification Kernel Methods</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2006" href="../home/nips2006_home.html">nips2006</a> <a title="nips-2006-63" href="../nips2006/nips-2006-Cross-Validation_Optimization_for_Large_Scale_Hierarchical_Classification_Kernel_Methods.html">nips2006-63</a> <a title="nips-2006-63-reference" href="#">nips2006-63-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>63 nips-2006-Cross-Validation Optimization for Large Scale Hierarchical Classification Kernel Methods</h1>
<br/><p>Source: <a title="nips-2006-63-pdf" href="http://papers.nips.cc/paper/3044-cross-validation-optimization-for-large-scale-hierarchical-classification-kernel-methods.pdf">pdf</a></p><p>Author: Matthias Seeger</p><p>Abstract: We propose a highly efﬁcient framework for kernel multi-class models with a large and structured set of classes. Kernel parameters are learned automatically by maximizing the cross-validation log likelihood, and predictive probabilities are estimated. We demonstrate our approach on large scale text classiﬁcation tasks with hierarchical class structure, achieving state-of-the-art results in an order of magnitude less time than previous work. 1</p><br/>
<h2>reference text</h2><p>[1] L. Cai and T. Hofmann. Hierarchical document categorization with support vector machines. In CIKM 13, pages 78–87, 2004.</p>
<p>[2] K. Crammer and Y. Singer. On the algorithmic implementation of multiclass kernel-based vector machines. J. M. Learn. Res., 2:265–292, 2001.</p>
<p>[3] P. Craven and G. Wahba. Smoothing noisy data with spline functions: Estimating the correct degree of smoothing by the method of generalized cross-validation. Numerische Mathematik, 31:377–403, 1979.</p>
<p>[4] P.J. Green and B. Silverman. Nonparametric Regression and Generalized Linear Models. Monographs on Statistics and Probability. Chapman & Hall, 1994.</p>
<p>[5] C.-W. Hsu and C.-J. Lin. A comparison of methods for multi-class support vector machines. IEEE Transactions on Neural Networks, 13:415–425, 2002.</p>
<p>[6] Y. Qi, T. Minka, R. Picard, and Z. Ghahramani. Predictive automatic relevance determination by expectation propagation. In Proceedings of ICML 21, 2004.</p>
<p>[7] M. Seeger. Gaussian processes for machine learning. International Journal of Neural Systems, 14(2):69– 106, 2004.</p>
<p>[8] M. Seeger. Cross-validation optimization for structured Hessian kernel methods. Technical report, Max Planck Institute for Biologic Cybernetics, T¨ bingen, Germany, 2006. u See www.kyb.tuebingen.mpg.de/bs/people/seeger.</p>
<p>[9] Y. Shen, A. Ng, and M. Seeger. Fast Gaussian process regression using KD-trees. In Advances in NIPS 18, 2006.</p>
<p>[10] A. Smola and P. Bartlett. Sparse greedy Gaussian process regression. In Advances in NIPS 13, pages 619–625, 2001.</p>
<p>[11] C. K. I. Williams and D. Barber. 20(12):1342–1351, 1998.  Bayesian classiﬁcation with Gaussian processes.  IEEE PAMI,</p>
<p>[12] C. Yang, R. Duraiswami, and L. Davis. Efﬁcient kernel machines using the improved fast Gauss transform. In Advances in NIPS 17, pages 1561–1568, 2005. 11 These methods solve a very large number of small problems iteratively, as opposed to ours which does few expensive Newton steps. The latter kind, if feasible at all, often makes better use of hardware features such as cacheing and vector operations, and therefore is the preferred approach in numerical optimization.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
