<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>83 nips-2001-Geometrical Singularities in the Neuromanifold of Multilayer Perceptrons</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2001" href="../home/nips2001_home.html">nips2001</a> <a title="nips-2001-83" href="#">nips2001-83</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>83 nips-2001-Geometrical Singularities in the Neuromanifold of Multilayer Perceptrons</h1>
<br/><p>Source: <a title="nips-2001-83-pdf" href="http://papers.nips.cc/paper/2015-geometrical-singularities-in-the-neuromanifold-of-multilayer-perceptrons.pdf">pdf</a></p><p>Author: Shun-ichi Amari, Hyeyoung Park, Tomoko Ozeki</p><p>Abstract: Singularities are ubiquitous in the parameter space of hierarchical models such as multilayer perceptrons. At singularities, the Fisher information matrix degenerates, and the Cramer-Rao paradigm does no more hold, implying that the classical model selection theory such as AIC and MDL cannot be applied. It is important to study the relation between the generalization error and the training error at singularities. The present paper demonstrates a method of analyzing these errors both for the maximum likelihood estimator and the Bayesian predictive distribution in terms of Gaussian random fields, by using simple models. 1</p><p>Reference: <a title="nips-2001-83-reference" href="../nips2001_reference/nips-2001-Geometrical_Singularities_in_the_Neuromanifold_of_Multilayer_Perceptrons_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 jp  Abstract Singularities are ubiquitous in the parameter space of hierarchical models such as multilayer perceptrons. [sent-4, score-0.374]
</p><p>2 At singularities, the Fisher information matrix degenerates, and the Cramer-Rao paradigm does no more hold, implying that the classical model selection theory such as AIC and MDL cannot be applied. [sent-5, score-0.172]
</p><p>3 It is important to study the relation between the generalization error and the training error at singularities. [sent-6, score-0.093]
</p><p>4 The present paper demonstrates a method of analyzing these errors both for the maximum likelihood estimator and the Bayesian predictive distribution in terms of Gaussian random fields, by using simple models. [sent-7, score-0.294]
</p><p>5 1  Introduction  A neural network is specified by a number of parameters which are synaptic weights and biases. [sent-8, score-0.067]
</p><p>6 Learning takes place by modifying these parameters from observed input-output examples. [sent-9, score-0.073]
</p><p>7 Then, a network is represented by a point in the parameter space S, where () plays the role of a coordinate system. [sent-14, score-0.124]
</p><p>8 A learning process is represented by a trajectory in the neuromanifold. [sent-16, score-0.026]
</p><p>9 The dynamical behavior of learning is known to be very slow, because of the plateau phenomenon. [sent-17, score-0.105]
</p><p>10 The statistical physical method [1] has made it clear that plateaus are ubiquitous in a large-scale perceptron. [sent-18, score-0.22]
</p><p>11 In order to improve the dynamics of learning, the natural gradient learning method has been introduced by taking the Riemannian geometrical structure of the neuromanifold into account [2, 3]. [sent-19, score-0.468]
</p><p>12 Its adaptive version, where the inverse of the Fisher information matrix is estimated adaptively, is shown to have excellent behaviors by computer simulations [4, 5]. [sent-20, score-0.145]
</p><p>13 Because of the symmetry in the architecture of the multilayer perceptrons, the parameter space of the MLP admits an equivalence relation [6, 7]. [sent-21, score-0.541]
</p><p>14 The residue class divided by the equivalence relation gives rise to singularities in the neuromanifold, and plateaus exist at such singularities [8]. [sent-22, score-1.49]
</p><p>15 The Fisher information matrix becomes singular at singularities, so that the neuromanifold is strongly curved like the spacetime including black holes. [sent-23, score-0.595]
</p><p>16 In the neighborhood of singularit ies, the Fisher-Cramer-Rao paradigm does not  hold, and the estimator is no more subject to the Gaussian distribution even asymptotically. [sent-24, score-0.224]
</p><p>17 The AlC and MDL criteria of model selection use the Gaussian paradigm, so that it is not appropriate. [sent-26, score-0.028]
</p><p>18 The problem was first pointed out by Hagiwara et al. [sent-27, score-0.034]
</p><p>19 Watanabe [10] applied algebraic geometry to elucidate the behavior of the Bayesian predictive estimator in MLP, showing sharp difference in regular cases and singular cases. [sent-29, score-0.664]
</p><p>20 Fukumizu [11] gives a general analysis of the maximum likelihood estimators in singular statistical models including the multilayer perceptrons. [sent-30, score-0.478]
</p><p>21 The present paper is a first step to elucidate effects of singularities in the neuromanifold of multilayer perceptrons. [sent-31, score-1.447]
</p><p>22 We use a simple cone model to elucidate how different the behaviors of the maximum likelihood estimator and the Bayes predictive distribution are from the regular case. [sent-32, score-0.852]
</p><p>23 To this end, we introduce the Gaussian random field [11, 12, 13], and analyze the generalization error and training error for both the mle (maximum likelihood estimator) and the Bayes estimator. [sent-33, score-0.09]
</p><p>24 2  Topology of neuromanifold  Let us consider MLP with h hidden units and one output unit, h  Y=  L  Vi<{J (Wi· x)  + n. [sent-34, score-0.52]
</p><p>25 Let us summarize all the parameters in a single parameter vector () = (Wl , ···, Wh; Vl , ···, Vh) and write h  f(x; ()) =  L  Vi<{J (Wi·  x). [sent-36, score-0.073]
</p><p>26 (2)  i=l  Then, () is a coordinate system of the neuromanifold. [sent-37, score-0.04]
</p><p>27 Because of the noise, the input-output relation is stochastic, given by the conditional probability distribution  p(ylx,()) =  1 {I -2(y-f(x;())) 2} ,  J2 exp  (3)  where we normalized the scale of noise equal to 1. [sent-38, score-0.093]
</p><p>28 Each point in the neuromanifold represents a neural network or its probability distribution. [sent-39, score-0.443]
</p><p>29 It is known that the behavior of MLP is invariant under 1) permutations of hidden units , and 2) sign change of both Wi and Vi at the same time. [sent-40, score-0.24]
</p><p>30 Two networks are equivalent when they are mapped by any of the above operations which form a group. [sent-41, score-0.029]
</p><p>31 Hence, it is natural to treat the residual space SI ::::J, where ::::J is the equivalence relation. [sent-42, score-0.138]
</p><p>32 There are some points which are invariant under a some nontrivial isotropy subgroup, on which singularities occurs. [sent-43, score-0.692]
</p><p>33 When Vi = 0, vi<{J (Wi· x) = 0 so that all the points on the sub manifold Vi = 0 are equivalent whatever Wi is. [sent-44, score-0.161]
</p><p>34 Hence, in M = SI ::::J, all of these points are reduced to one and the same point. [sent-46, score-0.029]
</p><p>35 When Wi = Wj hold, these two units may be merged into one, and when Vi +Vj is the same, the two points are equivalent even when they differ in Vi - Vj. [sent-47, score-0.16]
</p><p>36 Hence, the dimension reduction takes place in the subspace satisfying Wi = Wj. [sent-48, score-0.038]
</p><p>37 Such singularities occur on the critical submanifolds of the two types  (4)  3  Simple toy models  Given training data, the parameters of the neural network are estimated or trained by learning. [sent-49, score-0.674]
</p><p>38 It is important to elucidate the effects of singularities on learning or estimation. [sent-50, score-0.79]
</p><p>39 One is a very simple multilayer percept ron having only one hidden unit. [sent-52, score-0.433]
</p><p>40 The other is a simple cone model: Let x be Gaussian random variable x E R d +2 , with mean p, and identity covariance matrix I ,  (5) and let 5 = {p,Ip, E R d +2 } be the parameter space. [sent-53, score-0.334]
</p><p>41 The cone model M is a subset of 5, embedded as M : p,  (6)  where c is a constant, IIa 2 11 = 1, When d = 1, 51 is a circle so that  p,  =  W  W  E 5 d and 5 d is a d-dimensional unit sphere. [sent-54, score-0.287]
</p><p>42 is replaced by angle B, and we have  ~  VI + c2  See Figure 1. [sent-55, score-0.029]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('singularities', 0.575), ('neuromanifold', 0.403), ('multilayer', 0.254), ('cone', 0.228), ('vi', 0.191), ('elucidate', 0.182), ('wi', 0.157), ('mlp', 0.152), ('singular', 0.122), ('estimator', 0.117), ('plateaus', 0.115), ('tomoko', 0.115), ('relation', 0.093), ('behaviors', 0.085), ('mdl', 0.085), ('equivalence', 0.082), ('paradigm', 0.08), ('fisher', 0.076), ('ubiquitous', 0.076), ('predictive', 0.072), ('perceptrons', 0.07), ('hold', 0.067), ('geometrical', 0.065), ('regular', 0.063), ('hidden', 0.061), ('toy', 0.059), ('units', 0.056), ('amari', 0.055), ('watanabe', 0.05), ('residue', 0.05), ('hirosawa', 0.05), ('subgroup', 0.05), ('si', 0.047), ('nontrivial', 0.046), ('merged', 0.046), ('ylx', 0.046), ('mle', 0.046), ('ron', 0.046), ('ies', 0.046), ('wako', 0.046), ('wl', 0.046), ('parameter', 0.044), ('likelihood', 0.044), ('whatever', 0.042), ('percept', 0.042), ('permutations', 0.042), ('vh', 0.042), ('riemannian', 0.042), ('adaptively', 0.042), ('invariant', 0.042), ('gaussian', 0.04), ('network', 0.04), ('coordinate', 0.04), ('plateau', 0.04), ('vl', 0.04), ('wj', 0.04), ('attack', 0.04), ('saitama', 0.04), ('behavior', 0.039), ('curved', 0.038), ('algebraic', 0.038), ('admits', 0.038), ('riken', 0.038), ('place', 0.038), ('wh', 0.036), ('modifying', 0.035), ('vj', 0.035), ('pointed', 0.034), ('sub', 0.034), ('topology', 0.034), ('effects', 0.033), ('bayes', 0.033), ('implying', 0.032), ('matrix', 0.032), ('park', 0.031), ('sharp', 0.031), ('circle', 0.031), ('maximum', 0.031), ('japan', 0.03), ('symmetry', 0.03), ('simple', 0.03), ('perceptron', 0.03), ('residual', 0.03), ('equivalent', 0.029), ('summarize', 0.029), ('fields', 0.029), ('angle', 0.029), ('physical', 0.029), ('points', 0.029), ('hence', 0.029), ('unit', 0.028), ('selection', 0.028), ('excellent', 0.028), ('estimators', 0.027), ('synaptic', 0.027), ('manifold', 0.027), ('neighborhood', 0.027), ('treat', 0.026), ('dynamical', 0.026), ('trajectory', 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="83-tfidf-1" href="./nips-2001-Geometrical_Singularities_in_the_Neuromanifold_of_Multilayer_Perceptrons.html">83 nips-2001-Geometrical Singularities in the Neuromanifold of Multilayer Perceptrons</a></p>
<p>Author: Shun-ichi Amari, Hyeyoung Park, Tomoko Ozeki</p><p>Abstract: Singularities are ubiquitous in the parameter space of hierarchical models such as multilayer perceptrons. At singularities, the Fisher information matrix degenerates, and the Cramer-Rao paradigm does no more hold, implying that the classical model selection theory such as AIC and MDL cannot be applied. It is important to study the relation between the generalization error and the training error at singularities. The present paper demonstrates a method of analyzing these errors both for the maximum likelihood estimator and the Bayesian predictive distribution in terms of Gaussian random fields, by using simple models. 1</p><p>2 0.055724356 <a title="83-tfidf-2" href="./nips-2001-Fast_Parameter_Estimation_Using_Green%27s_Functions.html">76 nips-2001-Fast Parameter Estimation Using Green's Functions</a></p>
<p>Author: K. Wong, F. Li</p><p>Abstract: We propose a method for the fast estimation of hyperparameters in large networks, based on the linear response relation in the cavity method, and an empirical measurement of the Green's function. Simulation results show that it is efficient and precise, when compared with cross-validation and other techniques which require matrix inversion. 1</p><p>3 0.04832188 <a title="83-tfidf-3" href="./nips-2001-Analysis_of_Sparse_Bayesian_Learning.html">35 nips-2001-Analysis of Sparse Bayesian Learning</a></p>
<p>Author: Anita C. Faul, Michael E. Tipping</p><p>Abstract: The recent introduction of the 'relevance vector machine' has effectively demonstrated how sparsity may be obtained in generalised linear models within a Bayesian framework. Using a particular form of Gaussian parameter prior, 'learning' is the maximisation, with respect to hyperparameters, of the marginal likelihood of the data. This paper studies the properties of that objective function, and demonstrates that conditioned on an individual hyperparameter, the marginal likelihood has a unique maximum which is computable in closed form. It is further shown that if a derived 'sparsity criterion' is satisfied, this maximum is exactly equivalent to 'pruning' the corresponding parameter from the model. 1</p><p>4 0.046625286 <a title="83-tfidf-4" href="./nips-2001-A_Parallel_Mixture_of_SVMs_for_Very_Large_Scale_Problems.html">16 nips-2001-A Parallel Mixture of SVMs for Very Large Scale Problems</a></p>
<p>Author: Ronan Collobert, Samy Bengio, Yoshua Bengio</p><p>Abstract: Support Vector Machines (SVMs) are currently the state-of-the-art models for many classification problems but they suffer from the complexity of their training algorithm which is at least quadratic with respect to the number of examples. Hence, it is hopeless to try to solve real-life problems having more than a few hundreds of thousands examples with SVMs. The present paper proposes a new mixture of SVMs that can be easily implemented in parallel and where each SVM is trained on a small subset of the whole dataset. Experiments on a large benchmark dataset (Forest) as well as a difficult speech database , yielded significant time improvement (time complexity appears empirically to locally grow linearly with the number of examples) . In addition, and that is a surprise, a significant improvement in generalization was observed on Forest. 1</p><p>5 0.045577236 <a title="83-tfidf-5" href="./nips-2001-Exact_differential_equation_population_dynamics_for_integrate-and-fire_neurons.html">72 nips-2001-Exact differential equation population dynamics for integrate-and-fire neurons</a></p>
<p>Author: Julian Eggert, Berthold BĂ¤uml</p><p>Abstract: Mesoscopical, mathematical descriptions of dynamics of populations of spiking neurons are getting increasingly important for the understanding of large-scale processes in the brain using simulations. In our previous work, integral equation formulations for population dynamics have been derived for a special type of spiking neurons. For Integrate- and- Fire type neurons , these formulations were only approximately correct. Here, we derive a mathematically compact, exact population dynamics formulation for Integrate- and- Fire type neurons. It can be shown quantitatively in simulations that the numerical correspondence with microscopically modeled neuronal populations is excellent. 1 Introduction and motivation The goal of the population dynamics approach is to model the time course of the collective activity of entire populations of functionally and dynamically similar neurons in a compact way, using a higher descriptionallevel than that of single neurons and spikes. The usual observable at the level of neuronal populations is the populationaveraged instantaneous firing rate A(t), with A(t)6.t being the number of neurons in the population that release a spike in an interval [t, t+6.t). Population dynamics are formulated in such a way, that they match quantitatively the time course of a given A(t), either gained experimentally or by microscopical, detailed simulation. At least three main reasons can be formulated which underline the importance of the population dynamics approach for computational neuroscience. First, it enables the simulation of extensive networks involving a massive number of neurons and connections, which is typically the case when dealing with biologically realistic functional models that go beyond the single neuron level. Second, it increases the analytical understanding of large-scale neuronal dynamics , opening the way towards better control and predictive capabilities when dealing with large networks. Third, it enables a systematic embedding of the numerous neuronal models operating at different descriptional scales into a generalized theoretic framework, explaining the relationships, dependencies and derivations of the respective models. Early efforts on population dynamics approaches date back as early as 1972, to the work of Wilson and Cowan [8] and Knight [4], which laid the basis for all current population-averaged graded-response models (see e.g. [6] for modeling work using these models). More recently, population-based approaches for spiking neurons were developed, mainly by Gerstner [3, 2] and Knight [5]. In our own previous work [1], we have developed a theoretical framework which enables to systematize and simulate a wide range of models for population-based dynamics. It was shown that the equations of the framework produce results that agree quantitatively well with detailed simulations using spiking neurons, so that they can be used for realistic simulations involving networks with large numbers of spiking neurons. Nevertheless, for neuronal populations composed of Integrate-and-Fire (I&F;) neurons, this framework was only correct in an approximation. In this paper, we derive the exact population dynamics formulation for I&F; neurons. This is achieved by reducing the I&F; population dynamics to a point process and by taking advantage of the particular properties of I&F; neurons. 2 2.1 Background: Integrate-and-Fire dynamics Differential form We start with the standard Integrate- and- Fire (I&F;) model in form of the wellknown differential equation [7] (1) which describes the dynamics of the membrane potential Vi of a neuron i that is modeled as a single compartment with RC circuit characteristics. The membrane relaxation time is in this case T = RC with R being the membrane resistance and C the membrane capacitance. The resting potential v R est is the stationary potential that is approached in the no-input case. The input arriving from other neurons is described in form of a current ji. In addition to eq. (1), which describes the integrate part of the I&F; model, the neuronal dynamics are completed by a nonlinear step. Every time the membrane potential Vi reaches a fixed threshold () from below, Vi is lowered by a fixed amount Ll > 0, and from the new value of the membrane potential integration according to eq. (1) starts again. if Vi(t) = () (from below) . (2) At the same time, it is said that the release of a spike occurred (i.e., the neuron fired), and the time ti = t of this singular event is stored. Here ti indicates the time of the most recent spike. Storing all the last firing times , we gain the sequence of spikes {t{} (spike ordering index j, neuronal index i). 2.2 Integral form Now we look at the single neuron in a neuronal compound. We assume that the input current contribution ji from presynaptic spiking neurons can be described using the presynaptic spike times tf, a response-function ~ and a connection weight WÂˇ . ',J ji(t) = Wi ,j ~(t - tf) (3) l: l: j f Integrating the I&F; equation (1) beginning at the last spiking time tT, which determines the initial condition by Vi(ti) = vi(ti - 0) - 6., where vi(ti - 0) is the membrane potential just before the neuron spikes, we get 1 Vi(t) = v Rest + fj(t - t:) + l: Wi ,j l: a(t - t:; t - tf) , j - Vi(t:)) e- S / T (4) f with the refractory function fj(s) = - (v Rest (5) and the alpha-function r ds</p><p>6 0.043157954 <a title="83-tfidf-6" href="./nips-2001-A_New_Discriminative_Kernel_From_Probabilistic_Models.html">15 nips-2001-A New Discriminative Kernel From Probabilistic Models</a></p>
<p>7 0.042754564 <a title="83-tfidf-7" href="./nips-2001-Global_Coordination_of_Local_Linear_Models.html">84 nips-2001-Global Coordination of Local Linear Models</a></p>
<p>8 0.040999509 <a title="83-tfidf-8" href="./nips-2001-Efficient_Resources_Allocation_for_Markov_Decision_Processes.html">67 nips-2001-Efficient Resources Allocation for Markov Decision Processes</a></p>
<p>9 0.040672231 <a title="83-tfidf-9" href="./nips-2001-Quantizing_Density_Estimators.html">155 nips-2001-Quantizing Density Estimators</a></p>
<p>10 0.038830034 <a title="83-tfidf-10" href="./nips-2001-A_Natural_Policy_Gradient.html">13 nips-2001-A Natural Policy Gradient</a></p>
<p>11 0.037191298 <a title="83-tfidf-11" href="./nips-2001-Computing_Time_Lower_Bounds_for_Recurrent_Sigmoidal_Neural_Networks.html">52 nips-2001-Computing Time Lower Bounds for Recurrent Sigmoidal Neural Networks</a></p>
<p>12 0.037073482 <a title="83-tfidf-12" href="./nips-2001-Information_Geometrical_Framework_for_Analyzing_Belief_Propagation_Decoder.html">98 nips-2001-Information Geometrical Framework for Analyzing Belief Propagation Decoder</a></p>
<p>13 0.036699187 <a title="83-tfidf-13" href="./nips-2001-The_Noisy_Euclidean_Traveling_Salesman_Problem_and_Learning.html">186 nips-2001-The Noisy Euclidean Traveling Salesman Problem and Learning</a></p>
<p>14 0.036464997 <a title="83-tfidf-14" href="./nips-2001-Asymptotic_Universality_for_Learning_Curves_of_Support_Vector_Machines.html">38 nips-2001-Asymptotic Universality for Learning Curves of Support Vector Machines</a></p>
<p>15 0.03630767 <a title="83-tfidf-15" href="./nips-2001-Grouping_and_dimensionality_reduction_by_locally_linear_embedding.html">88 nips-2001-Grouping and dimensionality reduction by locally linear embedding</a></p>
<p>16 0.03577397 <a title="83-tfidf-16" href="./nips-2001-Bayesian_time_series_classification.html">43 nips-2001-Bayesian time series classification</a></p>
<p>17 0.035676051 <a title="83-tfidf-17" href="./nips-2001-Grammatical_Bigrams.html">86 nips-2001-Grammatical Bigrams</a></p>
<p>18 0.035560925 <a title="83-tfidf-18" href="./nips-2001-A_Variational_Approach_to_Learning_Curves.html">21 nips-2001-A Variational Approach to Learning Curves</a></p>
<p>19 0.034342486 <a title="83-tfidf-19" href="./nips-2001-Information-Geometric_Decomposition_in_Spike_Analysis.html">96 nips-2001-Information-Geometric Decomposition in Spike Analysis</a></p>
<p>20 0.034106281 <a title="83-tfidf-20" href="./nips-2001-A_Generalization_of_Principal_Components_Analysis_to_the_Exponential_Family.html">9 nips-2001-A Generalization of Principal Components Analysis to the Exponential Family</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2001_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.115), (1, -0.018), (2, -0.01), (3, -0.041), (4, 0.004), (5, -0.019), (6, 0.029), (7, -0.019), (8, -0.017), (9, -0.007), (10, -0.017), (11, 0.036), (12, 0.024), (13, -0.056), (14, 0.04), (15, 0.002), (16, -0.009), (17, -0.056), (18, 0.07), (19, 0.001), (20, -0.002), (21, 0.035), (22, 0.079), (23, 0.052), (24, 0.0), (25, 0.002), (26, -0.004), (27, 0.002), (28, -0.08), (29, 0.015), (30, 0.103), (31, -0.016), (32, 0.048), (33, -0.042), (34, -0.019), (35, 0.032), (36, 0.02), (37, 0.026), (38, 0.022), (39, -0.059), (40, 0.066), (41, 0.025), (42, 0.058), (43, 0.157), (44, 0.026), (45, -0.168), (46, 0.094), (47, -0.01), (48, 0.018), (49, -0.113)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.90604275 <a title="83-lsi-1" href="./nips-2001-Geometrical_Singularities_in_the_Neuromanifold_of_Multilayer_Perceptrons.html">83 nips-2001-Geometrical Singularities in the Neuromanifold of Multilayer Perceptrons</a></p>
<p>Author: Shun-ichi Amari, Hyeyoung Park, Tomoko Ozeki</p><p>Abstract: Singularities are ubiquitous in the parameter space of hierarchical models such as multilayer perceptrons. At singularities, the Fisher information matrix degenerates, and the Cramer-Rao paradigm does no more hold, implying that the classical model selection theory such as AIC and MDL cannot be applied. It is important to study the relation between the generalization error and the training error at singularities. The present paper demonstrates a method of analyzing these errors both for the maximum likelihood estimator and the Bayesian predictive distribution in terms of Gaussian random fields, by using simple models. 1</p><p>2 0.50829035 <a title="83-lsi-2" href="./nips-2001-Fast_Parameter_Estimation_Using_Green%27s_Functions.html">76 nips-2001-Fast Parameter Estimation Using Green's Functions</a></p>
<p>Author: K. Wong, F. Li</p><p>Abstract: We propose a method for the fast estimation of hyperparameters in large networks, based on the linear response relation in the cavity method, and an empirical measurement of the Green's function. Simulation results show that it is efficient and precise, when compared with cross-validation and other techniques which require matrix inversion. 1</p><p>3 0.45675102 <a title="83-lsi-3" href="./nips-2001-Active_Portfolio-Management_based_on_Error_Correction_Neural_Networks.html">26 nips-2001-Active Portfolio-Management based on Error Correction Neural Networks</a></p>
<p>Author: Hans-Georg Zimmermann, Ralph Neuneier, Ralph Grothmann</p><p>Abstract: This paper deals with a neural network architecture which establishes a portfolio management system similar to the Black / Litterman approach. This allocation scheme distributes funds across various securities or ﬁnancial markets while simultaneously complying with speciﬁc allocation constraints which meet the requirements of an investor. The portfolio optimization algorithm is modeled by a feedforward neural network. The underlying expected return forecasts are based on error correction neural networks (ECNN), which utilize the last model error as an auxiliary input to evaluate their own misspeciﬁcation. The portfolio optimization is implemented such that (i.) the allocations comply with investor’s constraints and that (ii.) the risk of the portfolio can be controlled. We demonstrate the proﬁtability of our approach by constructing internationally diversiﬁed portfolios across different ﬁnancial markets of the G7 contries. It turns out, that our approach is superior to a preset benchmark portfolio. ¢ £¡ 1 Introduction: Portfolio-Management We integrate the portfolio optimization algorithm suggested by Black / Litterman [1] into a neural network architecture. Combining the mean-variance theory [5] with the capital asset pricing model (CAPM) [7], this approach utilizes excess returns of the CAPM equilibrium to deﬁne a neutral, well balanced benchmark portfolio. Deviations from the benchmark allocation are only allowed within preset boundaries. Hence, as an advantage, there are no unrealistic solutions (e. g. large short positions, huge portfolio changes). Moreover, there is no need of formulating return expectations for all assets. In contrast to Black / Litterman, excess return forecasts are estimated by time-delay recurrent error correction neural networks [8]. Investment decisions which comply with given allocation constraints are derived from these predictions. The risk exposure of the portfolio is implicitly controlled by a parameter-optimizing task over time (sec. 3 and 5). Our approach consists of the following three steps: (i.) Construction of forecast models on the basis of error correction neural networks (ECNN) for all assets (sec. 2).   ¤§© © © § ¥ ¦¨¦¤ To whom correspondence should be addressed: Georg.Zimmermann@mchp.siemens.de.  ¤ ¤ (ii.) Computation of excess returns by a higher-level feedforward network (sec. 3 and 4). By this, the proﬁtability of an asset with respect to all others is measured. on the basis of the excess returns. (iii.) Optimization of the investment proportions Allocation constraints ensure, that the investment proportions may deviate from a given benchmark only within predeﬁned intervals (sec. 3 and 4). £ § ¨¡ ¥ £¡ ¦¤¢  ¡ © ¡ © Finally, we apply our neural network based portfolio management system to an asset allocation problem concerning the G7 countries (sec. 6). 2 Forecasting by Error Correction Neural Networks Most dynamical systems are driven by a superposition of autonomous development and external inﬂuences [8]. For discrete time grids, such a dynamics can be described by a recurrent state transition and an output equation (Eq. 1). ¥   § § state transition eq. output eq. (1)  $</p><p>4 0.43191656 <a title="83-lsi-4" href="./nips-2001-Quantizing_Density_Estimators.html">155 nips-2001-Quantizing Density Estimators</a></p>
<p>Author: Peter Meinicke, Helge Ritter</p><p>Abstract: We suggest a nonparametric framework for unsupervised learning of projection models in terms of density estimation on quantized sample spaces. The objective is not to optimally reconstruct the data but instead the quantizer is chosen to optimally reconstruct the density of the data. For the resulting quantizing density estimator (QDE) we present a general method for parameter estimation and model selection. We show how projection sets which correspond to traditional unsupervised methods like vector quantization or PCA appear in the new framework. For a principal component quantizer we present results on synthetic and realworld data, which show that the QDE can improve the generalization of the kernel density estimator although its estimate is based on signiﬁcantly lower-dimensional projection indices of the data.</p><p>5 0.37972093 <a title="83-lsi-5" href="./nips-2001-Gaussian_Process_Regression_with_Mismatched_Models.html">79 nips-2001-Gaussian Process Regression with Mismatched Models</a></p>
<p>Author: Peter Sollich</p><p>Abstract: Learning curves for Gaussian process regression are well understood when the 'student' model happens to match the 'teacher' (true data generation process). I derive approximations to the learning curves for the more generic case of mismatched models, and find very rich behaviour: For large input space dimensionality, where the results become exact, there are universal (student-independent) plateaux in the learning curve, with transitions in between that can exhibit arbitrarily many over-fitting maxima; over-fitting can occur even if the student estimates the teacher noise level correctly. In lower dimensions, plateaux also appear, and the learning curve remains dependent on the mismatch between student and teacher even in the asymptotic limit of a large number of training examples. Learning with excessively strong smoothness assumptions can be particularly dangerous: For example, a student with a standard radial basis function covariance function will learn a rougher teacher function only logarithmically slowly. All predictions are confirmed by simulations. 1</p><p>6 0.37595028 <a title="83-lsi-6" href="./nips-2001-Grammar_Transfer_in_a_Second_Order_Recurrent_Neural_Network.html">85 nips-2001-Grammar Transfer in a Second Order Recurrent Neural Network</a></p>
<p>7 0.36525515 <a title="83-lsi-7" href="./nips-2001-Information-Geometric_Decomposition_in_Spike_Analysis.html">96 nips-2001-Information-Geometric Decomposition in Spike Analysis</a></p>
<p>8 0.36496845 <a title="83-lsi-8" href="./nips-2001-Neural_Implementation_of_Bayesian_Inference_in_Population_Codes.html">131 nips-2001-Neural Implementation of Bayesian Inference in Population Codes</a></p>
<p>9 0.35262832 <a title="83-lsi-9" href="./nips-2001-Associative_memory_in_realistic_neuronal_networks.html">37 nips-2001-Associative memory in realistic neuronal networks</a></p>
<p>10 0.34757027 <a title="83-lsi-10" href="./nips-2001-Minimax_Probability_Machine.html">120 nips-2001-Minimax Probability Machine</a></p>
<p>11 0.33558393 <a title="83-lsi-11" href="./nips-2001-Analysis_of_Sparse_Bayesian_Learning.html">35 nips-2001-Analysis of Sparse Bayesian Learning</a></p>
<p>12 0.33287895 <a title="83-lsi-12" href="./nips-2001-Products_of_Gaussians.html">154 nips-2001-Products of Gaussians</a></p>
<p>13 0.331655 <a title="83-lsi-13" href="./nips-2001-Switch_Packet_Arbitration_via_Queue-Learning.html">177 nips-2001-Switch Packet Arbitration via Queue-Learning</a></p>
<p>14 0.32473683 <a title="83-lsi-14" href="./nips-2001-Linking_Motor_Learning_to_Function_Approximation%3A_Learning_in_an_Unlearnable_Force_Field.html">116 nips-2001-Linking Motor Learning to Function Approximation: Learning in an Unlearnable Force Field</a></p>
<p>15 0.31480777 <a title="83-lsi-15" href="./nips-2001-The_Noisy_Euclidean_Traveling_Salesman_Problem_and_Learning.html">186 nips-2001-The Noisy Euclidean Traveling Salesman Problem and Learning</a></p>
<p>16 0.31429788 <a title="83-lsi-16" href="./nips-2001-Global_Coordination_of_Local_Linear_Models.html">84 nips-2001-Global Coordination of Local Linear Models</a></p>
<p>17 0.31369439 <a title="83-lsi-17" href="./nips-2001-Why_Neuronal_Dynamics_Should_Control_Synaptic_Learning_Rules.html">197 nips-2001-Why Neuronal Dynamics Should Control Synaptic Learning Rules</a></p>
<p>18 0.31194675 <a title="83-lsi-18" href="./nips-2001-Infinite_Mixtures_of_Gaussian_Process_Experts.html">95 nips-2001-Infinite Mixtures of Gaussian Process Experts</a></p>
<p>19 0.31118202 <a title="83-lsi-19" href="./nips-2001-Asymptotic_Universality_for_Learning_Curves_of_Support_Vector_Machines.html">38 nips-2001-Asymptotic Universality for Learning Curves of Support Vector Machines</a></p>
<p>20 0.31100678 <a title="83-lsi-20" href="./nips-2001-Computing_Time_Lower_Bounds_for_Recurrent_Sigmoidal_Neural_Networks.html">52 nips-2001-Computing Time Lower Bounds for Recurrent Sigmoidal Neural Networks</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2001_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.013), (17, 0.018), (19, 0.534), (27, 0.087), (30, 0.051), (38, 0.026), (59, 0.02), (72, 0.031), (79, 0.037), (91, 0.065), (93, 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.94189852 <a title="83-lda-1" href="./nips-2001-Incremental_A%2A.html">93 nips-2001-Incremental A*</a></p>
<p>Author: S. Koenig, M. Likhachev</p><p>Abstract: Incremental search techniques ﬁnd optimal solutions to series of similar search tasks much faster than is possible by solving each search task from scratch. While researchers have developed incremental versions of uninformed search methods, we develop an incremental version of A*. The ﬁrst search of Lifelong Planning A* is the same as that of A* but all subsequent searches are much faster because it reuses those parts of the previous search tree that are identical to the new search tree. We then present experimental results that demonstrate the advantages of Lifelong Planning A* for simple route planning tasks. 1 Overview Artiﬁcial intelligence has investigated knowledge-based search techniques that allow one to solve search tasks in large domains. Most of the research on these methods has studied how to solve one-shot search problems. However, search is often a repetitive process, where one needs to solve a series of similar search tasks, for example, because the actual situation turns out to be slightly different from the one initially assumed or because the situation changes over time. An example for route planning tasks are changing trafﬁc conditions. Thus, one needs to replan for the new situation, for example if one always wants to display the least time-consuming route from the airport to the conference center on a web page. In these situations, most search methods replan from scratch, that is, solve the search problems independently. Incremental search techniques share with case-based planning, plan adaptation, repair-based planning, and learning search-control knowledge the property that they ﬁnd solutions to series of similar search tasks much faster than is possible by solving each search task from scratch. Incremental search techniques, however, differ from the other techniques in that the quality of their solutions is guaranteed to be as good as the quality of the solutions obtained by replanning from scratch. Although incremental search methods are not widely known in artiﬁcial intelligence and control, different researchers have developed incremental search versions of uninformed search methods in the algorithms literature. An overview can be found in [FMSN00]. We, on the other hand, develop an incremental version of A*, thus combining ideas from the algorithms literature and the artiﬁcial intelligence literature. We call the algorithm Lifelong Planning A* (LPA*), in analogy to “lifelong learning” [Thr98], because it reuses £ We thank Anthony Stentz for his support. The Intelligent Decision-Making Group is partly supported by NSF awards under contracts IIS9984827, IIS-0098807, and ITR/AP-0113881. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the ofﬁcial policies, either expressed or implied, of the sponsoring organizations and agencies or the U.S. government. information from previous searches. LPA* uses heuristics to focus the search and always ﬁnds a shortest path for the current edge costs. The ﬁrst search of LPA* is the same as that of A* but all subsequent searches are much faster. LPA* produces at least the search tree that A* builds. However, it achieves a substantial speedup over A* because it reuses those parts of the previous search tree that are identical to the new search tree. 2 The Route Planning Task Lifelong Planning A* (LPA*) solves the following search task: It applies to ﬁnite graph search problems on known graphs whose edge costs can increase or decrease over time. denotes the ﬁnite set of vertices of the graph. denotes the set of successors of vertex . Similarly, denotes the set of predecessors of vertex . denotes the cost of moving from vertex to vertex . LPA* always determines a shortest path from a given start vertex to a given goal vertex , knowing both the topology of the graph and the current edge costs. We use to denote the start distance of vertex , that is, the length of a shortest path from to .      ¨     ¨¦ £ £ ¡ ©§¥¤¢     FP HFE TSRQIGD¨  ¨¦ £ £ ¡    4 ©D¥CBA@!¨ ¨     ¨¦</p><p>2 0.90904659 <a title="83-lda-2" href="./nips-2001-Modeling_the_Modulatory_Effect_of_Attention_on_Human_Spatial_Vision.html">124 nips-2001-Modeling the Modulatory Effect of Attention on Human Spatial Vision</a></p>
<p>Author: Laurent Itti, Jochen Braun, Christof Koch</p><p>Abstract: We present new simulation results , in which a computational model of interacting visual neurons simultaneously predicts the modulation of spatial vision thresholds by focal visual attention, for five dual-task human psychophysics experiments. This new study complements our previous findings that attention activates a winnertake-all competition among early visual neurons within one cortical hypercolumn. This</p><p>same-paper 3 0.90061969 <a title="83-lda-3" href="./nips-2001-Geometrical_Singularities_in_the_Neuromanifold_of_Multilayer_Perceptrons.html">83 nips-2001-Geometrical Singularities in the Neuromanifold of Multilayer Perceptrons</a></p>
<p>Author: Shun-ichi Amari, Hyeyoung Park, Tomoko Ozeki</p><p>Abstract: Singularities are ubiquitous in the parameter space of hierarchical models such as multilayer perceptrons. At singularities, the Fisher information matrix degenerates, and the Cramer-Rao paradigm does no more hold, implying that the classical model selection theory such as AIC and MDL cannot be applied. It is important to study the relation between the generalization error and the training error at singularities. The present paper demonstrates a method of analyzing these errors both for the maximum likelihood estimator and the Bayesian predictive distribution in terms of Gaussian random fields, by using simple models. 1</p><p>4 0.80854106 <a title="83-lda-4" href="./nips-2001-Means%2C_Correlations_and_Bounds.html">119 nips-2001-Means, Correlations and Bounds</a></p>
<p>Author: Martijn Leisink, Bert Kappen</p><p>Abstract: The partition function for a Boltzmann machine can be bounded from above and below. We can use this to bound the means and the correlations. For networks with small weights, the values of these statistics can be restricted to non-trivial regions (i.e. a subset of [-1 , 1]). Experimental results show that reasonable bounding occurs for weight sizes where mean field expansions generally give good results. 1</p><p>5 0.76401764 <a title="83-lda-5" href="./nips-2001-Learning_Discriminative_Feature_Transforms_to_Low_Dimensions_in_Low_Dimentions.html">109 nips-2001-Learning Discriminative Feature Transforms to Low Dimensions in Low Dimentions</a></p>
<p>Author: Kari Torkkola</p><p>Abstract: The marriage of Renyi entropy with Parzen density estimation has been shown to be a viable tool in learning discriminative feature transforms. However, it suffers from computational complexity proportional to the square of the number of samples in the training data. This sets a practical limit to using large databases. We suggest immediate divorce of the two methods and remarriage of Renyi entropy with a semi-parametric density estimation method, such as a Gaussian Mixture Models (GMM). This allows all of the computation to take place in the low dimensional target space, and it reduces computational complexity proportional to square of the number of components in the mixtures. Furthermore, a convenient extension to Hidden Markov Models as commonly used in speech recognition becomes possible.</p><p>6 0.45460081 <a title="83-lda-6" href="./nips-2001-%28Not%29_Bounding_the_True_Error.html">1 nips-2001-(Not) Bounding the True Error</a></p>
<p>7 0.40898201 <a title="83-lda-7" href="./nips-2001-A_Natural_Policy_Gradient.html">13 nips-2001-A Natural Policy Gradient</a></p>
<p>8 0.40500617 <a title="83-lda-8" href="./nips-2001-Kernel_Feature_Spaces_and_Nonlinear_Blind_Souce_Separation.html">103 nips-2001-Kernel Feature Spaces and Nonlinear Blind Souce Separation</a></p>
<p>9 0.40225309 <a title="83-lda-9" href="./nips-2001-The_Noisy_Euclidean_Traveling_Salesman_Problem_and_Learning.html">186 nips-2001-The Noisy Euclidean Traveling Salesman Problem and Learning</a></p>
<p>10 0.39938655 <a title="83-lda-10" href="./nips-2001-Tree-based_reparameterization_for_approximate_inference_on_loopy_graphs.html">192 nips-2001-Tree-based reparameterization for approximate inference on loopy graphs</a></p>
<p>11 0.39837405 <a title="83-lda-11" href="./nips-2001-Computing_Time_Lower_Bounds_for_Recurrent_Sigmoidal_Neural_Networks.html">52 nips-2001-Computing Time Lower Bounds for Recurrent Sigmoidal Neural Networks</a></p>
<p>12 0.37256238 <a title="83-lda-12" href="./nips-2001-On_the_Generalization_Ability_of_On-Line_Learning_Algorithms.html">138 nips-2001-On the Generalization Ability of On-Line Learning Algorithms</a></p>
<p>13 0.37055916 <a title="83-lda-13" href="./nips-2001-Pranking_with_Ranking.html">147 nips-2001-Pranking with Ranking</a></p>
<p>14 0.3686133 <a title="83-lda-14" href="./nips-2001-Quantizing_Density_Estimators.html">155 nips-2001-Quantizing Density Estimators</a></p>
<p>15 0.36842787 <a title="83-lda-15" href="./nips-2001-Learning_from_Infinite_Data_in_Finite_Time.html">114 nips-2001-Learning from Infinite Data in Finite Time</a></p>
<p>16 0.36228892 <a title="83-lda-16" href="./nips-2001-Entropy_and_Inference%2C_Revisited.html">68 nips-2001-Entropy and Inference, Revisited</a></p>
<p>17 0.3619079 <a title="83-lda-17" href="./nips-2001-Contextual_Modulation_of_Target_Saliency.html">54 nips-2001-Contextual Modulation of Target Saliency</a></p>
<p>18 0.36069262 <a title="83-lda-18" href="./nips-2001-On_the_Convergence_of_Leveraging.html">137 nips-2001-On the Convergence of Leveraging</a></p>
<p>19 0.36004001 <a title="83-lda-19" href="./nips-2001-EM-DD%3A_An_Improved_Multiple-Instance_Learning_Technique.html">64 nips-2001-EM-DD: An Improved Multiple-Instance Learning Technique</a></p>
<p>20 0.35665286 <a title="83-lda-20" href="./nips-2001-Rates_of_Convergence_of_Performance_Gradient_Estimates_Using_Function_Approximation_and_Bias_in_Reinforcement_Learning.html">157 nips-2001-Rates of Convergence of Performance Gradient Estimates Using Function Approximation and Bias in Reinforcement Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
