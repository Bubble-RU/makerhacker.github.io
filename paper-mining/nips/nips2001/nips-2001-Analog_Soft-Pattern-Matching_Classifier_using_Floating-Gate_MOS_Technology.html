<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>34 nips-2001-Analog Soft-Pattern-Matching Classifier using Floating-Gate MOS Technology</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2001" href="../home/nips2001_home.html">nips2001</a> <a title="nips-2001-34" href="#">nips2001-34</a> knowledge-graph by maker-knowledge-mining</p><h1>34 nips-2001-Analog Soft-Pattern-Matching Classifier using Floating-Gate MOS Technology</h1>
<br/><p>Source: <a title="nips-2001-34-pdf" href="http://papers.nips.cc/paper/2114-analog-soft-pattern-matching-classifier-using-floating-gate-mos-technology.pdf">pdf</a></p><p>Author: Toshihiko Yamasaki, Tadashi Shibata</p><p>Abstract: A flexible pattern-matching analog classifier is presented in conjunction with a robust image representation algorithm called Principal Axes Projection (PAP). In the circuit, the functional form of matching is configurable in terms of the peak position, the peak height and the sharpness of the similarity evaluation. The test chip was fabricated in a 0.6-µm CMOS technology and successfully applied to hand-written pattern recognition and medical radiograph analysis using PAP as a feature extraction pre-processing step for robust image coding. The separation and classification of overlapping patterns is also experimentally demonstrated. 1 I ntr o du c ti o n Pattern classification using template matching techniques is a powerful tool in implementing human-like intelligent systems. However, the processing is computationally very expensive, consuming a lot of CPU time when implemented as software running on general-purpose computers. Therefore, software approaches are not practical for real-time applications. For systems working in mobile environment, in particular, they are not realistic because the memory and computational resources are severely limited. The development of analog VLSI chips having a fully parallel template matching architecture [1,2] would be a promising solution in such applications because they offer an opportunity of low-power operation as well as very compact implementation. In order to build a real human-like intelligent system, however, not only the pattern representation algorithm but also the matching hardware itself needs to be made flexible and robust in carrying out the pattern matching task. First of all, two-dimensional patterns need to be represented by feature vectors having substantially reduced dimensions, while at the same time preserving the human perception of similarity among patterns in the vector space mapping. For this purpose, an image representation algorithm called Principal Axes Projection (PAP) has been de- veloped [3] and its robust nature in pattern recognition has been demonstrated in the applications to medical radiograph analysis [3] and hand-written digits recognition [4]. However, the demonstration so far was only carried out by computer simulation. Regarding the matching hardware, high-flexibility analog template matching circuits have been developed for PAP vector representation. The circuits are flexible in a sense that the matching criteria (the weight to elements, the strictness in matching) are configurable. In Ref. [5], the fundamental characteristics of the building block circuits were presented, and their application to simple hand-written digits was presented in Ref. [6]. The purpose of this paper is to demonstrate the robust nature of the hardware matching system by experiments. The classification of simple hand-written patterns and the cephalometric landmark identification in gray-scale medical radiographs have been carried out and successful results are presented. In addition, multiple overlapping patterns can be separated without utilizing a priori knowledge, which is one of the most difficult problems at present in artificial intelligence. 2 I ma g e re pr es e n tati on by P AP PAP is a feature extraction technique using the edge information. The input image (64x64 pixels) is first subjected to pixel-by-pixel spatial filtering operations to detect edges in four directions: horizontal (HR); vertical (VR); +45 degrees (+45); and –45 degrees (-45). Each detected edge is represented by a binary flag and four edge maps are generated. The two-dimensional bit array in an edge map is reduced to a one-dimensional array of numerals by projection. The horizontal edge flags are accumulated in the horizontal direction and projected onto vertical axis. The vertical, +45-degree and –45-degree edge flags are similarly projected onto horizontal, -45-degree and +45-degree axes, respectively. Therefore the method is called “Principal Axes Projection (PAP)” [3,4]. Then each projection data set is series connected in the order of HR, +45, VR, -45 to form a feature vector. Neighboring four elements are averaged and merged to one element and a 64-dimensional vector is finally obtained. This vector representation very well preserves the human perception of similarity in the vector space. In the experiments below, we have further reduced the feature vector to 16 dimensions by merging each set of four neighboring elements into one, without any significant degradation in performance. C i r cui t c o nf i g ura ti ons A B C VGG A B C VGG IOUT IOUT 1 1 2 2 4 4 1 VIN 13 VIN RST RST £ ¡ ¤¢  £ ¥ §¦  3 Figure 1: Schematic of vector element matching circuit: (a) pyramid (gain reduction) type; (b) plateau (feedback) type. The capacitor area ratio is indicated in the figure. The basic functional form of the similarity evaluation is generated by the shortcut current flowing in a CMOS inverter as in Refs. [7,8,9]. However, their circuits were utilized to form radial basis functions and only the peak position was programmable. In our circuits, not only the peak position but also the peak height and the sharpness of the peak response shape are made configurable to realize flexible matching operations [5]. Two types of the element matching circuit are shown in Fig. 1. They evaluate the similarity between two vector elements. The result of the evaluation is given as an output current (IOUT ) from the pMOS current mirror. The peak position is temporarily memorized by auto-zeroing of the CMOS inverter. The common-gate transistor with VGG stabilizes the voltage supply to the inverter. By controlling the gate bias VGG, the peak height can be changed. This corresponds to multiplying a weight factor to the element. The sharpness of the functional form is taken as the strictness of the similarity evaluation. In the pyramid type circuit (Fig. 1(a)), the sharpness is controlled by the gain reduction in the input. In the plateau type (Fig. 1(b)), the output voltage of the inverter is fed back to input nodes and the sharpness changes in accordance with the amount of the feedback.    ¥£¡ ¦¤¢   £¨ 9&% ¦©§ (!! #$ 5 !' #$ &% 9 9 4 92 !¦ A1@9  ¨¥  5 4 52 (!  5 8765  9) 0 1 ¥ 1 ¨</p><p>Reference: <a title="nips-2001-34-reference" href="../nips2001_reference/nips-2001-Analog_Soft-Pattern-Matching_Classifier_using_Floating-Gate_MOS_Technology_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('circuit', 0.529), ('templ', 0.315), ('match', 0.301), ('vgg', 0.215), ('residu', 0.211), ('pattern', 0.172), ('pyramid', 0.169), ('overlap', 0.159), ('radiograph', 0.135), ('cmo', 0.119), ('win', 0.114), ('peak', 0.114), ('plateau', 0.112), ('abc', 0.108), ('iout', 0.108), ('yamasak', 0.108), ('scor', 0.107), ('sharp', 0.103), ('regim', 0.083), ('flag', 0.081)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999964 <a title="34-tfidf-1" href="./nips-2001-Analog_Soft-Pattern-Matching_Classifier_using_Floating-Gate_MOS_Technology.html">34 nips-2001-Analog Soft-Pattern-Matching Classifier using Floating-Gate MOS Technology</a></p>
<p>2 0.2108596 <a title="34-tfidf-2" href="./nips-2001-Citcuits_for_VLSI_Implementation_of_Temporally_Asymmetric_Hebbian_Learning.html">49 nips-2001-Citcuits for VLSI Implementation of Temporally Asymmetric Hebbian Learning</a></p>
<p>3 0.20481983 <a title="34-tfidf-3" href="./nips-2001-An_Efficient_Clustering_Algorithm_Using_Stochastic_Association_Model_and_Its_Implementation_Using_Nanostructures.html">33 nips-2001-An Efficient Clustering Algorithm Using Stochastic Association Model and Its Implementation Using Nanostructures</a></p>
<p>4 0.17640544 <a title="34-tfidf-4" href="./nips-2001-Stochastic_Mixed-Signal_VLSI_Architecture_for_High-Dimensional_Kernel_Machines.html">176 nips-2001-Stochastic Mixed-Signal VLSI Architecture for High-Dimensional Kernel Machines</a></p>
<p>5 0.16798662 <a title="34-tfidf-5" href="./nips-2001-Learning_Spike-Based_Correlations_and_Conditional_Probabilities_in_Silicon.html">112 nips-2001-Learning Spike-Based Correlations and Conditional Probabilities in Silicon</a></p>
<p>6 0.13100521 <a title="34-tfidf-6" href="./nips-2001-Transform-invariant_Image_Decomposition_with_Similarity_Templates.html">191 nips-2001-Transform-invariant Image Decomposition with Similarity Templates</a></p>
<p>7 0.1287225 <a title="34-tfidf-7" href="./nips-2001-Orientation-Selective_aVLSI_Spiking_Neurons.html">141 nips-2001-Orientation-Selective aVLSI Spiking Neurons</a></p>
<p>8 0.10928603 <a title="34-tfidf-8" href="./nips-2001-Learning_Lateral_Interactions_for_Feature_Binding_and_Sensory_Segmentation.html">111 nips-2001-Learning Lateral Interactions for Feature Binding and Sensory Segmentation</a></p>
<p>9 0.056673519 <a title="34-tfidf-9" href="./nips-2001-Categorization_by_Learning_and_Combining_Object_Parts.html">46 nips-2001-Categorization by Learning and Combining Object Parts</a></p>
<p>10 0.05331013 <a title="34-tfidf-10" href="./nips-2001-Intransitive_Likelihood-Ratio_Classifiers.html">99 nips-2001-Intransitive Likelihood-Ratio Classifiers</a></p>
<p>11 0.052990217 <a title="34-tfidf-11" href="./nips-2001-Matching_Free_Trees_with_Replicator_Equations.html">118 nips-2001-Matching Free Trees with Replicator Equations</a></p>
<p>12 0.050590675 <a title="34-tfidf-12" href="./nips-2001-Self-regulation_Mechanism_of_Temporally_Asymmetric_Hebbian_Plasticity.html">166 nips-2001-Self-regulation Mechanism of Temporally Asymmetric Hebbian Plasticity</a></p>
<p>13 0.050045904 <a title="34-tfidf-13" href="./nips-2001-Adaptive_Nearest_Neighbor_Classification_Using_Support_Vector_Machines.html">28 nips-2001-Adaptive Nearest Neighbor Classification Using Support Vector Machines</a></p>
<p>14 0.048785165 <a title="34-tfidf-14" href="./nips-2001-Fragment_Completion_in_Humans_and_Machines.html">78 nips-2001-Fragment Completion in Humans and Machines</a></p>
<p>15 0.047295511 <a title="34-tfidf-15" href="./nips-2001-Contextual_Modulation_of_Target_Saliency.html">54 nips-2001-Contextual Modulation of Target Saliency</a></p>
<p>16 0.046909507 <a title="34-tfidf-16" href="./nips-2001-Model_Based_Population_Tracking_and_Automatic_Detection_of_Distribution_Changes.html">122 nips-2001-Model Based Population Tracking and Automatic Detection of Distribution Changes</a></p>
<p>17 0.046808217 <a title="34-tfidf-17" href="./nips-2001-Grouping_with_Bias.html">89 nips-2001-Grouping with Bias</a></p>
<p>18 0.046774123 <a title="34-tfidf-18" href="./nips-2001-Dynamic_Time-Alignment_Kernel_in_Support_Vector_Machine.html">63 nips-2001-Dynamic Time-Alignment Kernel in Support Vector Machine</a></p>
<p>19 0.04565572 <a title="34-tfidf-19" href="./nips-2001-Unsupervised_Learning_of_Human_Motion_Models.html">193 nips-2001-Unsupervised Learning of Human Motion Models</a></p>
<p>20 0.045512073 <a title="34-tfidf-20" href="./nips-2001-A_Rotation_and_Translation_Invariant_Discrete_Saliency_Network.html">19 nips-2001-A Rotation and Translation Invariant Discrete Saliency Network</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2001_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.153), (1, -0.092), (2, -0.036), (3, -0.003), (4, 0.047), (5, -0.021), (6, -0.037), (7, 0.021), (8, 0.077), (9, 0.113), (10, -0.23), (11, 0.054), (12, 0.004), (13, 0.0), (14, 0.349), (15, 0.137), (16, -0.139), (17, 0.239), (18, 0.031), (19, 0.015), (20, -0.094), (21, 0.096), (22, 0.052), (23, -0.089), (24, 0.106), (25, 0.031), (26, -0.06), (27, -0.046), (28, 0.068), (29, 0.006), (30, 0.004), (31, -0.04), (32, 0.043), (33, -0.051), (34, 0.042), (35, 0.032), (36, 0.05), (37, 0.032), (38, -0.065), (39, -0.027), (40, 0.005), (41, 0.053), (42, 0.011), (43, 0.028), (44, -0.044), (45, 0.038), (46, 0.028), (47, 0.011), (48, -0.002), (49, 0.007)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95308155 <a title="34-lsi-1" href="./nips-2001-Analog_Soft-Pattern-Matching_Classifier_using_Floating-Gate_MOS_Technology.html">34 nips-2001-Analog Soft-Pattern-Matching Classifier using Floating-Gate MOS Technology</a></p>
<p>2 0.76652628 <a title="34-lsi-2" href="./nips-2001-Learning_Spike-Based_Correlations_and_Conditional_Probabilities_in_Silicon.html">112 nips-2001-Learning Spike-Based Correlations and Conditional Probabilities in Silicon</a></p>
<p>3 0.74724531 <a title="34-lsi-3" href="./nips-2001-Stochastic_Mixed-Signal_VLSI_Architecture_for_High-Dimensional_Kernel_Machines.html">176 nips-2001-Stochastic Mixed-Signal VLSI Architecture for High-Dimensional Kernel Machines</a></p>
<p>4 0.62997878 <a title="34-lsi-4" href="./nips-2001-An_Efficient_Clustering_Algorithm_Using_Stochastic_Association_Model_and_Its_Implementation_Using_Nanostructures.html">33 nips-2001-An Efficient Clustering Algorithm Using Stochastic Association Model and Its Implementation Using Nanostructures</a></p>
<p>5 0.61647958 <a title="34-lsi-5" href="./nips-2001-Citcuits_for_VLSI_Implementation_of_Temporally_Asymmetric_Hebbian_Learning.html">49 nips-2001-Citcuits for VLSI Implementation of Temporally Asymmetric Hebbian Learning</a></p>
<p>6 0.37221929 <a title="34-lsi-6" href="./nips-2001-Transform-invariant_Image_Decomposition_with_Similarity_Templates.html">191 nips-2001-Transform-invariant Image Decomposition with Similarity Templates</a></p>
<p>7 0.29049996 <a title="34-lsi-7" href="./nips-2001-Learning_Lateral_Interactions_for_Feature_Binding_and_Sensory_Segmentation.html">111 nips-2001-Learning Lateral Interactions for Feature Binding and Sensory Segmentation</a></p>
<p>8 0.27655059 <a title="34-lsi-8" href="./nips-2001-The_Fidelity_of_Local_Ordinal_Encoding.html">182 nips-2001-The Fidelity of Local Ordinal Encoding</a></p>
<p>9 0.2407302 <a title="34-lsi-9" href="./nips-2001-Orientation-Selective_aVLSI_Spiking_Neurons.html">141 nips-2001-Orientation-Selective aVLSI Spiking Neurons</a></p>
<p>10 0.24048157 <a title="34-lsi-10" href="./nips-2001-Probabilistic_principles_in_unsupervised_learning_of_visual_structure%3A_human_data_and_a_model.html">151 nips-2001-Probabilistic principles in unsupervised learning of visual structure: human data and a model</a></p>
<p>11 0.22204423 <a title="34-lsi-11" href="./nips-2001-A_Rotation_and_Translation_Invariant_Discrete_Saliency_Network.html">19 nips-2001-A Rotation and Translation Invariant Discrete Saliency Network</a></p>
<p>12 0.22184153 <a title="34-lsi-12" href="./nips-2001-Fragment_Completion_in_Humans_and_Machines.html">78 nips-2001-Fragment Completion in Humans and Machines</a></p>
<p>13 0.20861715 <a title="34-lsi-13" href="./nips-2001-The_g_Factor%3A_Relating_Distributions_on_Features_to_Distributions_on_Images.html">189 nips-2001-The g Factor: Relating Distributions on Features to Distributions on Images</a></p>
<p>14 0.20610288 <a title="34-lsi-14" href="./nips-2001-Fast_Parameter_Estimation_Using_Green%27s_Functions.html">76 nips-2001-Fast Parameter Estimation Using Green's Functions</a></p>
<p>15 0.20571466 <a title="34-lsi-15" href="./nips-2001-Switch_Packet_Arbitration_via_Queue-Learning.html">177 nips-2001-Switch Packet Arbitration via Queue-Learning</a></p>
<p>16 0.19975501 <a title="34-lsi-16" href="./nips-2001-Adaptive_Nearest_Neighbor_Classification_Using_Support_Vector_Machines.html">28 nips-2001-Adaptive Nearest Neighbor Classification Using Support Vector Machines</a></p>
<p>17 0.19237196 <a title="34-lsi-17" href="./nips-2001-Why_Neuronal_Dynamics_Should_Control_Synaptic_Learning_Rules.html">197 nips-2001-Why Neuronal Dynamics Should Control Synaptic Learning Rules</a></p>
<p>18 0.19181067 <a title="34-lsi-18" href="./nips-2001-Thin_Junction_Trees.html">190 nips-2001-Thin Junction Trees</a></p>
<p>19 0.19166599 <a title="34-lsi-19" href="./nips-2001-Categorization_by_Learning_and_Combining_Object_Parts.html">46 nips-2001-Categorization by Learning and Combining Object Parts</a></p>
<p>20 0.19073489 <a title="34-lsi-20" href="./nips-2001-Incorporating_Invariances_in_Non-Linear_Support_Vector_Machines.html">92 nips-2001-Incorporating Invariances in Non-Linear Support Vector Machines</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2001_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.023), (16, 0.113), (31, 0.063), (36, 0.017), (50, 0.043), (77, 0.024), (79, 0.055), (81, 0.011), (87, 0.392), (91, 0.064), (92, 0.081), (96, 0.012)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.69452375 <a title="34-lda-1" href="./nips-2001-Analog_Soft-Pattern-Matching_Classifier_using_Floating-Gate_MOS_Technology.html">34 nips-2001-Analog Soft-Pattern-Matching Classifier using Floating-Gate MOS Technology</a></p>
<p>2 0.47623768 <a title="34-lda-2" href="./nips-2001-Categorization_by_Learning_and_Combining_Object_Parts.html">46 nips-2001-Categorization by Learning and Combining Object Parts</a></p>
<p>3 0.41329589 <a title="34-lda-3" href="./nips-2001-Stochastic_Mixed-Signal_VLSI_Architecture_for_High-Dimensional_Kernel_Machines.html">176 nips-2001-Stochastic Mixed-Signal VLSI Architecture for High-Dimensional Kernel Machines</a></p>
<p>4 0.39817631 <a title="34-lda-4" href="./nips-2001-Citcuits_for_VLSI_Implementation_of_Temporally_Asymmetric_Hebbian_Learning.html">49 nips-2001-Citcuits for VLSI Implementation of Temporally Asymmetric Hebbian Learning</a></p>
<p>5 0.38826773 <a title="34-lda-5" href="./nips-2001-Orientation-Selective_aVLSI_Spiking_Neurons.html">141 nips-2001-Orientation-Selective aVLSI Spiking Neurons</a></p>
<p>6 0.38757169 <a title="34-lda-6" href="./nips-2001-Learning_Spike-Based_Correlations_and_Conditional_Probabilities_in_Silicon.html">112 nips-2001-Learning Spike-Based Correlations and Conditional Probabilities in Silicon</a></p>
<p>7 0.38656533 <a title="34-lda-7" href="./nips-2001-Grammar_Transfer_in_a_Second_Order_Recurrent_Neural_Network.html">85 nips-2001-Grammar Transfer in a Second Order Recurrent Neural Network</a></p>
<p>8 0.38551363 <a title="34-lda-8" href="./nips-2001-Reinforcement_Learning_with_Long_Short-Term_Memory.html">161 nips-2001-Reinforcement Learning with Long Short-Term Memory</a></p>
<p>9 0.38521543 <a title="34-lda-9" href="./nips-2001-Modeling_Temporal_Structure_in_Classical_Conditioning.html">123 nips-2001-Modeling Temporal Structure in Classical Conditioning</a></p>
<p>10 0.38410473 <a title="34-lda-10" href="./nips-2001-Activity_Driven_Adaptive_Stochastic_Resonance.html">27 nips-2001-Activity Driven Adaptive Stochastic Resonance</a></p>
<p>11 0.38330376 <a title="34-lda-11" href="./nips-2001-Grouping_with_Bias.html">89 nips-2001-Grouping with Bias</a></p>
<p>12 0.3818419 <a title="34-lda-12" href="./nips-2001-Exact_differential_equation_population_dynamics_for_integrate-and-fire_neurons.html">72 nips-2001-Exact differential equation population dynamics for integrate-and-fire neurons</a></p>
<p>13 0.38182473 <a title="34-lda-13" href="./nips-2001-Generating_velocity_tuning_by_asymmetric_recurrent_connections.html">82 nips-2001-Generating velocity tuning by asymmetric recurrent connections</a></p>
<p>14 0.38019019 <a title="34-lda-14" href="./nips-2001-Why_Neuronal_Dynamics_Should_Control_Synaptic_Learning_Rules.html">197 nips-2001-Why Neuronal Dynamics Should Control Synaptic Learning Rules</a></p>
<p>15 0.37992811 <a title="34-lda-15" href="./nips-2001-Cobot%3A_A_Social_Reinforcement_Learning_Agent.html">51 nips-2001-Cobot: A Social Reinforcement Learning Agent</a></p>
<p>16 0.37910402 <a title="34-lda-16" href="./nips-2001-Audio-Visual_Sound_Separation_Via_Hidden_Markov_Models.html">39 nips-2001-Audio-Visual Sound Separation Via Hidden Markov Models</a></p>
<p>17 0.37877795 <a title="34-lda-17" href="./nips-2001-Bayesian_time_series_classification.html">43 nips-2001-Bayesian time series classification</a></p>
<p>18 0.37723589 <a title="34-lda-18" href="./nips-2001-Relative_Density_Nets%3A_A_New_Way_to_Combine_Backpropagation_with_HMM%27s.html">162 nips-2001-Relative Density Nets: A New Way to Combine Backpropagation with HMM's</a></p>
<p>19 0.37649325 <a title="34-lda-19" href="./nips-2001-A_Rotation_and_Translation_Invariant_Discrete_Saliency_Network.html">19 nips-2001-A Rotation and Translation Invariant Discrete Saliency Network</a></p>
<p>20 0.37597147 <a title="34-lda-20" href="./nips-2001-Self-regulation_Mechanism_of_Temporally_Asymmetric_Hebbian_Plasticity.html">166 nips-2001-Self-regulation Mechanism of Temporally Asymmetric Hebbian Plasticity</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
