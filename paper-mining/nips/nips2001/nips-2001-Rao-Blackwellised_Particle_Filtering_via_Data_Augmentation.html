<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>156 nips-2001-Rao-Blackwellised Particle Filtering via Data Augmentation</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2001" href="../home/nips2001_home.html">nips2001</a> <a title="nips-2001-156" href="#">nips2001-156</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>156 nips-2001-Rao-Blackwellised Particle Filtering via Data Augmentation</h1>
<br/><p>Source: <a title="nips-2001-156-pdf" href="http://papers.nips.cc/paper/2066-rao-blackwellised-particle-filtering-via-data-augmentation.pdf">pdf</a></p><p>Author: Christophe Andrieu, Nando D. Freitas, Arnaud Doucet</p><p>Abstract: In this paper, we extend the Rao-Blackwellised particle filtering method to more complex hybrid models consisting of Gaussian latent variables and discrete observations. This is accomplished by augmenting the models with artificial variables that enable us to apply Rao-Blackwellisation. Other improvements include the design of an optimal importance proposal distribution and being able to swap the sampling an selection steps to handle outliers. We focus on sequential binary classifiers that consist of linear combinations of basis functions , whose coefficients evolve according to a Gaussian smoothness prior. Our results show significant improvements. 1</p><p>Reference: <a title="nips-2001-156-reference" href="../nips2001_reference/nips-2001-Rao-Blackwellised_Particle_Filtering_via_Data_Augmentation_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 VIa  Christophe Andrieu  N ando de Freitas  Arnaud Doucet  Statistics Group University of Bristol University Walk Bristol BS8 1TW, UK  Computer Science UC Berkeley 387 Soda Hall, Berkeley CA 94720-1776, USA  EE Engineering University of Melbourne Parkville, Victoria 3052 Australia  C. [sent-2, score-0.034]
</p><p>2 au  Abstract In this paper, we extend the Rao-Blackwellised particle filtering method to more complex hybrid models consisting of Gaussian latent variables and discrete observations. [sent-10, score-0.463]
</p><p>3 This is accomplished by augmenting the models with artificial variables that enable us to apply Rao-Blackwellisation. [sent-11, score-0.084]
</p><p>4 Other improvements include the design of an optimal importance proposal distribution and being able to swap the sampling an selection steps to handle outliers. [sent-12, score-0.371]
</p><p>5 We focus on sequential binary classifiers that consist of linear combinations of basis functions , whose coefficients evolve according to a Gaussian smoothness prior. [sent-13, score-0.244]
</p><p>6 1  Introduction  Sequential Monte Carlo (SMC) particle methods go back to the first publically available paper in the modern field of Monte Carlo simulation (Metropolis and Ulam 1949) ; see (Doucet, de Freitas and Gordon 2001) for a comprehensive review. [sent-15, score-0.229]
</p><p>7 SMC is often referred to as particle filtering (PF) in the context of computing filtering distributions for statistical inference and learning. [sent-16, score-0.499]
</p><p>8 Here, we attack a more complex model that does not admit immediate analytical tractability. [sent-20, score-0.086]
</p><p>9 This probabilistic model consists of Gaussian latent variables and binary observations. [sent-21, score-0.086]
</p><p>10 We show that by augmenting the model with artificial variables, it becomes possible to apply Rao-Blackwellisation and optimal sampling strategies. [sent-22, score-0.177]
</p><p>11 We focus on the problem of sequential binary classification (that is, when the data arrives one-at-a-time) using generic classifiers that consist of linear combinations of basis functions, whose coefficients evolve according to a Gaussian smoothness  prior (Kitagawa and Gersch 1996). [sent-23, score-0.328]
</p><p>12 We have previously addressed this problem in the context of sequential fault detection in marine diesel engines (H0jen-S0rensen, de Freitas and Fog 2000). [sent-24, score-0.441]
</p><p>13 This application is of great importance as early detection of incipient faults can improve safety and efficiency, as well as, help to reduce downtime and plant maintenance in many industrial and transportation environments. [sent-25, score-0.142]
</p><p>14 2  Model Specification and Estimation Objectives  Let us consider the following binary classification model. [sent-26, score-0.134]
</p><p>15 By convention, researchers tend to adopt a logistic (sigmoidal) link function 'P (u) = (1 + exp (_U)) -1 . [sent-34, score-0.075]
</p><p>16 However, from a Bayesian computational point of view, the probit link has many advantages and is equally valid. [sent-35, score-0.088]
</p><p>17 , \[I K (Xt)/ do not depend on unknown parameters; see (Andrieu, de Freitas and Doucet 1999) for the more general case . [sent-43, score-0.034]
</p><p>18 Typically K is rather large, say 10 or 100, and the bases \[Ik (. [sent-56, score-0.074]
</p><p>19 1  Augmented Statistical Model  We augment the probabilistic model artificially to obtain more efficient sampling algorithms, as will be detailed in the next section. [sent-59, score-0.169]
</p><p>20 N (0 1) d d fi were nt '" "an e ne Zt that one has Pr ( Zt =  11 Xt, . [sent-65, score-0.04]
</p><p>21 This data augmentation strategy was first introduced in econometrics by economics Nobel laureate Daniel McFadden (McFadden 1989). [sent-69, score-0.219]
</p><p>22 In the MCMC context, it has been used to design efficient samplers (Albert and Chib 1993). [sent-70, score-0.076]
</p><p>23 2  Estimation objectives  Given, at time t , the observations Ol:t £ (Xl:t, Zl:t), any Bayesian inference is based on the posterior distribution 1 P (d. [sent-73, score-0.048]
</p><p>24 I  lE ( f (xt, ,Bt) I Ol:t) or the marginal predictive distribution at time t for new input data Xt+1, that is Pr (Zt+1 = 11 01:t, xHd. [sent-79, score-0.05]
</p><p>25 The posterior density satisfies a time recursion according to Bayes rule, but it does not admit an analytical expression and, consequently, we need to resort to numerical methods to approximate it. [sent-80, score-0.163]
</p><p>26 3  Sequential Bayesian Estimation via Particle Filtering  A straightforward application of SMC methods to the model (1)-(2) would focus on sampling from the high-dimensional distribution P (d,Bo:t I 01:t) (H0jen-S0rensen et al. [sent-81, score-0.093]
</p><p>27 A substantially more efficient strategy is to exploit the augmentation of the model to sample only from the low-dimensional distribution P ( dY1:t I01:t). [sent-83, score-0.234]
</p><p>28 The low-dimensional samples allow us then to compute the remaining estimates analytically, as shown in the following subsection. [sent-84, score-0.034]
</p><p>29 For example, an estimate of the predictive distribution is given by  PrN(Zt+1 = Il ol:t,XH1) =  J  Pr( Zt+1 = lIYH1)PN(dYl:t+1 lol:t, xt+1)  (4)  N  ,,  (i) = ~ W t(i) ][(0,+00) ( YHl ) , i=l  where Y~21 ~ P ( dYHll Xl:t+1, Yi~~). [sent-89, score-0.05]
</p><p>30 This shows that we can restrict ourselves to the estimation of P (Y1:t1 Ol:t) for inference purposes. [sent-90, score-0.049]
</p><p>31 In the SMC framework, we must estimate the "target" density P (Y1:t1 Ol:t) pointwise up to a normalizing constant. [sent-91, score-0.035]
</p><p>32 By standard factorisation, one has t  p(Yl:tlol:t)  IT  Pr( zk IYk)p(Ykl xl:k,Yl:k-l), wherep(YIIY1:0,Xl:0) ,@,p(Yll xd· k=l Since Pr (Zk I Yk) is known, we only need to estimate P (Yk I Xl:k, Yl:k-d up to a norIX  malizing constant. [sent-92, score-0.038]
</p><p>33 This predictive density can be computed using the Kalman filter. [sent-93, score-0.085]
</p><p>34 Given (Xl:k' Yl:k-l), the Kalman filter equations are the following. [sent-94, score-0.05]
</p><p>35 Sampling Algorithm  In this section, we briefly outline the PF algorithm for generating samples from p(dYl:tlol:t). [sent-101, score-0.034]
</p><p>36 (For details, please refer to our extended technical report at http://www . [sent-102, score-0.058]
</p><p>37 ) Assume that at time t - 1 we have N particles {Yi~Ld~l distributed according to P (dYl:t - 11 ol:t- d from which one can get the following empirical distribution approximation 1  PN (dYl:t-11 ol:t-d  =N  N  L JYi~;_l (dYl:t-d . [sent-107, score-0.106]
</p><p>38 i= l  Various SMC methods can be used to obtain N new paths {Yi~~}~l distributed approximately according to P (dYl:t1 Ol:t)' The most successful of these methods typically combine importance sampling and a selection scheme. [sent-108, score-0.241]
</p><p>39 Since the selection step is standard (Doucet et al. [sent-110, score-0.052]
</p><p>40 2001), we shall concentrate on describing the importance sampling step. [sent-111, score-0.189]
</p><p>41 To obtain samples from P( dYl:t IOl:t), we can sample from a proposal distribution Q(dYl:t) and weight the samples appropriately. [sent-112, score-0.137]
</p><p>42 Typically, researchers use the transition prior as proposal distribution (Isard and Blake 1996). [sent-113, score-0.069]
</p><p>43 ) Remark 1 When we adopt the optimal proposal distribution, the importance weight Wt ex: Pr (Zt I X1:t, Y1:t - d does not depend on Yt. [sent-116, score-0.2]
</p><p>44 It is thus possible to carry out the selection step before the sampling step. [sent-117, score-0.145]
</p><p>45 The algorithm is then similar to the auxiliary variable particle filter of (Pitt and Shephard 1999). [sent-118, score-0.245]
</p><p>46 It enables us to search for more  Sequential importance sampling step • For  . [sent-120, score-0.189]
</p><p>47 Selection step • Multiply/Discard particles {~i ),,B~i~ _l}~l with respect to high/low impor. [sent-130, score-0.106]
</p><p>48 , N, C)  use one step of the Kalman recursion (5) to compute {,B~i~ l l t }  -C)  given {y/ ,(3 ti t-1 } and ~t l t-1'  Figure 1: RBPF for semiparametric binary classification. [sent-135, score-0.092]
</p><p>49 likely regions of the posterior at time t-1 using the information at time t to generate better samples at time t. [sent-136, score-0.034]
</p><p>50 4  Simulations  To compare our model , using the RBPF algorithm, to standard logistic and probit classification with PF, we generated data from clusters that change with time as shown in Figure 2. [sent-142, score-0.132]
</p><p>51 This data set captures the characteristics of a fault detection problem that we are currently studying. [sent-143, score-0.125]
</p><p>52 (For some results of applying PF to fault detection in marine diesel engines, please refer to (H0jen-S0rensen et al. [sent-144, score-0.305]
</p><p>53 The number of bases (cubic splines with random locations) was set to 10. [sent-151, score-0.127]
</p><p>54 (It is of course possible, when we have some data already, to initialise the bases locations so that they correspond to the input data. [sent-152, score-0.074]
</p><p>55 This trick for efficient classification in high dimensional input spaces is used in the support vector machines setting (Vapnik 1995). [sent-153, score-0.191]
</p><p>56 ) The experiment was repeated with the number of particles varying between 10 and 400. [sent-154, score-0.106]
</p><p>57 The new algorithm has a lower computational cost and shows a significant reduction in estimation variance. [sent-156, score-0.049]
</p><p>58 Another advantage of PF algorithms for classification is that they yield entire probability estimates of class membership as shown in Figure 4. [sent-159, score-0.084]
</p><p>59 50'----~--L-~--~8-~,0~-~,2--,~ 4-~,6-~,8  Computation (flops)  ,10'  Figure 3: Number of classification errors as the number of particles varies between 10 and 400 (different computational costs). [sent-206, score-0.19]
</p><p>60 The algorithm with the augmentation trick (RBPF) is more efficient than standard PF algorithms. [sent-207, score-0.265]
</p><p>61 5  Conclusions  In this paper, we proposed a dynamic Bayesian model for time-varying binary classification and an efficient particle filtering algorithm to perform the required computations. [sent-208, score-0.557]
</p><p>62 The efficiency of our algorithm is a result of data augmentation, RaoBlackwellisation, adopting the optimal importance distribution, being able to swap the sampling and selection steps and only needing to update the Kalman filter means in the particles loop. [sent-209, score-0.493]
</p><p>63 This extends the realm of efficient particle filtering to the ubiquitous setting of Gaussian latent variables and binary observations. [sent-210, score-0.509]
</p><p>64 Extensions to n-ary observations, different link functions and estimation of the hyper-parameters can be carried out in the same framework. [sent-211, score-0.089]
</p><p>65 Bayesian analysis of binary and polychotomous response data, Journal of the American Statistical Association 88(422): 669- 679. [sent-216, score-0.05]
</p><p>66 Sequential Bayesian estimation and model selection applied to neural networks, Technical Report CUED/F-INFENG/TR 341, Cambridge University Engineering Department. [sent-221, score-0.101]
</p><p>67 Convergence of sequential Monte Carlo methods, Technical Report CUED/F-INFENG/TR 381, Cambridge University Engineering Department. [sent-225, score-0.112]
</p><p>68 Rao blackwellised particle filtering for dynamic Bayesian networks, in C. [sent-237, score-0.347]
</p><p>69 On sequential Monte Carlo sampling methods for Bayesian filtering , Statistics and Computing 10(3): 197- 208. [sent-245, score-0.357]
</p><p>70 On-line probabilistic classification with particle filters, IEEE N eural Networks for Signal Processing, Sydney, Australia. [sent-250, score-0.279]
</p><p>71 A method of simulated momemts for estimation of discrete response models without numerical integration, Econometrica 57: 995- 1026. [sent-269, score-0.049]
</p><p>72 Filtering via simulation: Auxiliary particle filters , Journal of the American Statistical Association 94(446): 590- 599. [sent-278, score-0.275]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('doucet', 0.313), ('dyl', 0.243), ('zt', 0.241), ('xt', 0.231), ('freitas', 0.217), ('ol', 0.211), ('particle', 0.195), ('yt', 0.177), ('augmentation', 0.158), ('smc', 0.158), ('filtering', 0.152), ('andrieu', 0.152), ('pf', 0.147), ('rbpf', 0.121), ('kalman', 0.12), ('sequential', 0.112), ('xl', 0.106), ('particles', 0.106), ('pr', 0.103), ('tl', 0.103), ('lt', 0.1), ('yl', 0.1), ('carlo', 0.096), ('monte', 0.096), ('importance', 0.096), ('sampling', 0.093), ('mcfadden', 0.091), ('classification', 0.084), ('filters', 0.08), ('au', 0.08), ('pn', 0.079), ('fault', 0.079), ('efficient', 0.076), ('bases', 0.074), ('proposal', 0.069), ('yk', 0.066), ('crisan', 0.061), ('diesel', 0.061), ('econometrics', 0.061), ('fog', 0.061), ('gersch', 0.061), ('holmes', 0.061), ('jfgf', 0.061), ('kitagawa', 0.061), ('mallick', 0.061), ('marine', 0.061), ('shephard', 0.061), ('swap', 0.061), ('tlol', 0.061), ('ytlxl', 0.061), ('cov', 0.06), ('bayesian', 0.06), ('please', 0.058), ('cp', 0.053), ('chib', 0.053), ('splines', 0.053), ('augmenting', 0.053), ('godsill', 0.053), ('bristol', 0.053), ('selection', 0.052), ('predictive', 0.05), ('filter', 0.05), ('binary', 0.05), ('estimation', 0.049), ('le', 0.048), ('albert', 0.048), ('probit', 0.048), ('objectives', 0.048), ('pitt', 0.048), ('russell', 0.048), ('engines', 0.048), ('detection', 0.046), ('metropolis', 0.045), ('eds', 0.045), ('gordon', 0.045), ('isard', 0.045), ('american', 0.044), ('analytical', 0.044), ('admit', 0.042), ('evolve', 0.042), ('recursion', 0.042), ('blake', 0.042), ('link', 0.04), ('murphy', 0.04), ('nt', 0.04), ('smoothness', 0.04), ('yi', 0.039), ('zk', 0.038), ('remark', 0.037), ('latent', 0.036), ('association', 0.036), ('efficiency', 0.035), ('adopt', 0.035), ('density', 0.035), ('ex', 0.034), ('samples', 0.034), ('de', 0.034), ('artificial', 0.031), ('trick', 0.031), ('berkeley', 0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="156-tfidf-1" href="./nips-2001-Rao-Blackwellised_Particle_Filtering_via_Data_Augmentation.html">156 nips-2001-Rao-Blackwellised Particle Filtering via Data Augmentation</a></p>
<p>Author: Christophe Andrieu, Nando D. Freitas, Arnaud Doucet</p><p>Abstract: In this paper, we extend the Rao-Blackwellised particle filtering method to more complex hybrid models consisting of Gaussian latent variables and discrete observations. This is accomplished by augmenting the models with artificial variables that enable us to apply Rao-Blackwellisation. Other improvements include the design of an optimal importance proposal distribution and being able to swap the sampling an selection steps to handle outliers. We focus on sequential binary classifiers that consist of linear combinations of basis functions , whose coefficients evolve according to a Gaussian smoothness prior. Our results show significant improvements. 1</p><p>2 0.205699 <a title="156-tfidf-2" href="./nips-2001-Risk_Sensitive_Particle_Filters.html">163 nips-2001-Risk Sensitive Particle Filters</a></p>
<p>Author: Sebastian Thrun, John Langford, Vandi Verma</p><p>Abstract: We propose a new particle ﬁlter that incorporates a model of costs when generating particles. The approach is motivated by the observation that the costs of accidentally not tracking hypotheses might be signiﬁcant in some areas of state space, and next to irrelevant in others. By incorporating a cost model into particle ﬁltering, states that are more critical to the system performance are more likely to be tracked. Automatic calculation of the cost model is implemented using an MDP value function calculation that estimates the value of tracking a particular state. Experiments in two mobile robot domains illustrate the appropriateness of the approach.</p><p>3 0.16860043 <a title="156-tfidf-3" href="./nips-2001-KLD-Sampling%3A_Adaptive_Particle_Filters.html">102 nips-2001-KLD-Sampling: Adaptive Particle Filters</a></p>
<p>Author: Dieter Fox</p><p>Abstract: Over the last years, particle ﬁlters have been applied with great success to a variety of state estimation problems. We present a statistical approach to increasing the efﬁciency of particle ﬁlters by adapting the size of sample sets on-the-ﬂy. The key idea of the KLD-sampling method is to bound the approximation error introduced by the sample-based representation of the particle ﬁlter. The name KLD-sampling is due to the fact that we measure the approximation error by the Kullback-Leibler distance. Our adaptation approach chooses a small number of samples if the density is focused on a small part of the state space, and it chooses a large number of samples if the state uncertainty is high. Both the implementation and computation overhead of this approach are small. Extensive experiments using mobile robot localization as a test application show that our approach yields drastic improvements over particle ﬁlters with ﬁxed sample set sizes and over a previously introduced adaptation technique.</p><p>4 0.13116993 <a title="156-tfidf-4" href="./nips-2001-Pranking_with_Ranking.html">147 nips-2001-Pranking with Ranking</a></p>
<p>Author: Koby Crammer, Yoram Singer</p><p>Abstract: We discuss the problem of ranking instances. In our framework each instance is associated with a rank or a rating, which is an integer from 1 to k. Our goal is to find a rank-prediction rule that assigns each instance a rank which is as close as possible to the instance's true rank. We describe a simple and efficient online algorithm, analyze its performance in the mistake bound model, and prove its correctness. We describe two sets of experiments, with synthetic data and with the EachMovie dataset for collaborative filtering. In the experiments we performed, our algorithm outperforms online algorithms for regression and classification applied to ranking. 1</p><p>5 0.12842476 <a title="156-tfidf-5" href="./nips-2001-Tempo_tracking_and_rhythm_quantization_by_sequential_Monte_Carlo.html">179 nips-2001-Tempo tracking and rhythm quantization by sequential Monte Carlo</a></p>
<p>Author: Ali Taylan Cemgil, Bert Kappen</p><p>Abstract: We present a probabilistic generative model for timing deviations in expressive music. performance. The structure of the proposed model is equivalent to a switching state space model. We formulate two well known music recognition problems, namely tempo tracking and automatic transcription (rhythm quantization) as filtering and maximum a posteriori (MAP) state estimation tasks. The inferences are carried out using sequential Monte Carlo integration (particle filtering) techniques. For this purpose, we have derived a novel Viterbi algorithm for Rao-Blackwellized particle filters, where a subset of the hidden variables is integrated out. The resulting model is suitable for realtime tempo tracking and transcription and hence useful in a number of music applications such as adaptive automatic accompaniment and score typesetting. 1</p><p>6 0.11530294 <a title="156-tfidf-6" href="./nips-2001-Kernel_Machines_and_Boolean_Functions.html">105 nips-2001-Kernel Machines and Boolean Functions</a></p>
<p>7 0.10773831 <a title="156-tfidf-7" href="./nips-2001-Variance_Reduction_Techniques_for_Gradient_Estimates_in_Reinforcement_Learning.html">195 nips-2001-Variance Reduction Techniques for Gradient Estimates in Reinforcement Learning</a></p>
<p>8 0.077706791 <a title="156-tfidf-8" href="./nips-2001-The_Concave-Convex_Procedure_%28CCCP%29.html">180 nips-2001-The Concave-Convex Procedure (CCCP)</a></p>
<p>9 0.07451006 <a title="156-tfidf-9" href="./nips-2001-Bayesian_time_series_classification.html">43 nips-2001-Bayesian time series classification</a></p>
<p>10 0.072040752 <a title="156-tfidf-10" href="./nips-2001-A_Dynamic_HMM_for_On-line_Segmentation_of_Sequential_Data.html">7 nips-2001-A Dynamic HMM for On-line Segmentation of Sequential Data</a></p>
<p>11 0.068595953 <a title="156-tfidf-11" href="./nips-2001-Spectral_Relaxation_for_K-means_Clustering.html">171 nips-2001-Spectral Relaxation for K-means Clustering</a></p>
<p>12 0.063264653 <a title="156-tfidf-12" href="./nips-2001-Probabilistic_Inference_of_Hand_Motion_from_Neural_Activity_in_Motor_Cortex.html">150 nips-2001-Probabilistic Inference of Hand Motion from Neural Activity in Motor Cortex</a></p>
<p>13 0.061835401 <a title="156-tfidf-13" href="./nips-2001-Gaussian_Process_Regression_with_Mismatched_Models.html">79 nips-2001-Gaussian Process Regression with Mismatched Models</a></p>
<p>14 0.061091125 <a title="156-tfidf-14" href="./nips-2001-Adaptive_Sparseness_Using_Jeffreys_Prior.html">29 nips-2001-Adaptive Sparseness Using Jeffreys Prior</a></p>
<p>15 0.059425611 <a title="156-tfidf-15" href="./nips-2001-Minimax_Probability_Machine.html">120 nips-2001-Minimax Probability Machine</a></p>
<p>16 0.058931015 <a title="156-tfidf-16" href="./nips-2001-TAP_Gibbs_Free_Energy%2C_Belief_Propagation_and_Sparsity.html">178 nips-2001-TAP Gibbs Free Energy, Belief Propagation and Sparsity</a></p>
<p>17 0.058110204 <a title="156-tfidf-17" href="./nips-2001-Sequential_Noise_Compensation_by_Sequential_Monte_Carlo_Method.html">168 nips-2001-Sequential Noise Compensation by Sequential Monte Carlo Method</a></p>
<p>18 0.057242516 <a title="156-tfidf-18" href="./nips-2001-Asymptotic_Universality_for_Learning_Curves_of_Support_Vector_Machines.html">38 nips-2001-Asymptotic Universality for Learning Curves of Support Vector Machines</a></p>
<p>19 0.051600449 <a title="156-tfidf-19" href="./nips-2001-The_g_Factor%3A_Relating_Distributions_on_Features_to_Distributions_on_Images.html">189 nips-2001-The g Factor: Relating Distributions on Features to Distributions on Images</a></p>
<p>20 0.051494703 <a title="156-tfidf-20" href="./nips-2001-Adaptive_Nearest_Neighbor_Classification_Using_Support_Vector_Machines.html">28 nips-2001-Adaptive Nearest Neighbor Classification Using Support Vector Machines</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2001_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.18), (1, -0.0), (2, 0.023), (3, -0.062), (4, -0.09), (5, -0.136), (6, 0.111), (7, 0.276), (8, 0.04), (9, 0.116), (10, 0.047), (11, -0.05), (12, 0.128), (13, 0.082), (14, 0.128), (15, -0.042), (16, 0.095), (17, 0.105), (18, 0.025), (19, -0.048), (20, -0.074), (21, 0.003), (22, 0.053), (23, 0.085), (24, 0.059), (25, -0.174), (26, 0.05), (27, -0.026), (28, -0.019), (29, 0.05), (30, 0.005), (31, 0.013), (32, -0.106), (33, -0.106), (34, 0.105), (35, 0.105), (36, 0.027), (37, -0.075), (38, -0.019), (39, -0.043), (40, 0.013), (41, -0.112), (42, -0.176), (43, -0.038), (44, -0.054), (45, -0.014), (46, -0.015), (47, -0.03), (48, -0.008), (49, -0.014)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94590414 <a title="156-lsi-1" href="./nips-2001-Rao-Blackwellised_Particle_Filtering_via_Data_Augmentation.html">156 nips-2001-Rao-Blackwellised Particle Filtering via Data Augmentation</a></p>
<p>Author: Christophe Andrieu, Nando D. Freitas, Arnaud Doucet</p><p>Abstract: In this paper, we extend the Rao-Blackwellised particle filtering method to more complex hybrid models consisting of Gaussian latent variables and discrete observations. This is accomplished by augmenting the models with artificial variables that enable us to apply Rao-Blackwellisation. Other improvements include the design of an optimal importance proposal distribution and being able to swap the sampling an selection steps to handle outliers. We focus on sequential binary classifiers that consist of linear combinations of basis functions , whose coefficients evolve according to a Gaussian smoothness prior. Our results show significant improvements. 1</p><p>2 0.57003951 <a title="156-lsi-2" href="./nips-2001-Risk_Sensitive_Particle_Filters.html">163 nips-2001-Risk Sensitive Particle Filters</a></p>
<p>Author: Sebastian Thrun, John Langford, Vandi Verma</p><p>Abstract: We propose a new particle ﬁlter that incorporates a model of costs when generating particles. The approach is motivated by the observation that the costs of accidentally not tracking hypotheses might be signiﬁcant in some areas of state space, and next to irrelevant in others. By incorporating a cost model into particle ﬁltering, states that are more critical to the system performance are more likely to be tracked. Automatic calculation of the cost model is implemented using an MDP value function calculation that estimates the value of tracking a particular state. Experiments in two mobile robot domains illustrate the appropriateness of the approach.</p><p>3 0.54983819 <a title="156-lsi-3" href="./nips-2001-KLD-Sampling%3A_Adaptive_Particle_Filters.html">102 nips-2001-KLD-Sampling: Adaptive Particle Filters</a></p>
<p>Author: Dieter Fox</p><p>Abstract: Over the last years, particle ﬁlters have been applied with great success to a variety of state estimation problems. We present a statistical approach to increasing the efﬁciency of particle ﬁlters by adapting the size of sample sets on-the-ﬂy. The key idea of the KLD-sampling method is to bound the approximation error introduced by the sample-based representation of the particle ﬁlter. The name KLD-sampling is due to the fact that we measure the approximation error by the Kullback-Leibler distance. Our adaptation approach chooses a small number of samples if the density is focused on a small part of the state space, and it chooses a large number of samples if the state uncertainty is high. Both the implementation and computation overhead of this approach are small. Extensive experiments using mobile robot localization as a test application show that our approach yields drastic improvements over particle ﬁlters with ﬁxed sample set sizes and over a previously introduced adaptation technique.</p><p>4 0.50728744 <a title="156-lsi-4" href="./nips-2001-Tempo_tracking_and_rhythm_quantization_by_sequential_Monte_Carlo.html">179 nips-2001-Tempo tracking and rhythm quantization by sequential Monte Carlo</a></p>
<p>Author: Ali Taylan Cemgil, Bert Kappen</p><p>Abstract: We present a probabilistic generative model for timing deviations in expressive music. performance. The structure of the proposed model is equivalent to a switching state space model. We formulate two well known music recognition problems, namely tempo tracking and automatic transcription (rhythm quantization) as filtering and maximum a posteriori (MAP) state estimation tasks. The inferences are carried out using sequential Monte Carlo integration (particle filtering) techniques. For this purpose, we have derived a novel Viterbi algorithm for Rao-Blackwellized particle filters, where a subset of the hidden variables is integrated out. The resulting model is suitable for realtime tempo tracking and transcription and hence useful in a number of music applications such as adaptive automatic accompaniment and score typesetting. 1</p><p>5 0.47574085 <a title="156-lsi-5" href="./nips-2001-The_Concave-Convex_Procedure_%28CCCP%29.html">180 nips-2001-The Concave-Convex Procedure (CCCP)</a></p>
<p>Author: Alan L. Yuille, Anand Rangarajan</p><p>Abstract: We introduce the Concave-Convex procedure (CCCP) which constructs discrete time iterative dynamical systems which are guaranteed to monotonically decrease global optimization/energy functions. It can be applied to (almost) any optimization problem and many existing algorithms can be interpreted in terms of CCCP. In particular, we prove relationships to some applications of Legendre transform techniques. We then illustrate CCCP by applications to Potts models, linear assignment, EM algorithms, and Generalized Iterative Scaling (GIS). CCCP can be used both as a new way to understand existing optimization algorithms and as a procedure for generating new algorithms. 1</p><p>6 0.45212859 <a title="156-lsi-6" href="./nips-2001-Pranking_with_Ranking.html">147 nips-2001-Pranking with Ranking</a></p>
<p>7 0.42000008 <a title="156-lsi-7" href="./nips-2001-Variance_Reduction_Techniques_for_Gradient_Estimates_in_Reinforcement_Learning.html">195 nips-2001-Variance Reduction Techniques for Gradient Estimates in Reinforcement Learning</a></p>
<p>8 0.41482145 <a title="156-lsi-8" href="./nips-2001-Minimax_Probability_Machine.html">120 nips-2001-Minimax Probability Machine</a></p>
<p>9 0.32549903 <a title="156-lsi-9" href="./nips-2001-Kernel_Machines_and_Boolean_Functions.html">105 nips-2001-Kernel Machines and Boolean Functions</a></p>
<p>10 0.302928 <a title="156-lsi-10" href="./nips-2001-Active_Portfolio-Management_based_on_Error_Correction_Neural_Networks.html">26 nips-2001-Active Portfolio-Management based on Error Correction Neural Networks</a></p>
<p>11 0.28113088 <a title="156-lsi-11" href="./nips-2001-Using_Vocabulary_Knowledge_in_Bayesian_Multinomial_Estimation.html">194 nips-2001-Using Vocabulary Knowledge in Bayesian Multinomial Estimation</a></p>
<p>12 0.276059 <a title="156-lsi-12" href="./nips-2001-A_Dynamic_HMM_for_On-line_Segmentation_of_Sequential_Data.html">7 nips-2001-A Dynamic HMM for On-line Segmentation of Sequential Data</a></p>
<p>13 0.27552435 <a title="156-lsi-13" href="./nips-2001-Predictive_Representations_of_State.html">148 nips-2001-Predictive Representations of State</a></p>
<p>14 0.27446967 <a title="156-lsi-14" href="./nips-2001-Neural_Implementation_of_Bayesian_Inference_in_Population_Codes.html">131 nips-2001-Neural Implementation of Bayesian Inference in Population Codes</a></p>
<p>15 0.27292448 <a title="156-lsi-15" href="./nips-2001-Probabilistic_Inference_of_Hand_Motion_from_Neural_Activity_in_Motor_Cortex.html">150 nips-2001-Probabilistic Inference of Hand Motion from Neural Activity in Motor Cortex</a></p>
<p>16 0.27123037 <a title="156-lsi-16" href="./nips-2001-Analysis_of_Sparse_Bayesian_Learning.html">35 nips-2001-Analysis of Sparse Bayesian Learning</a></p>
<p>17 0.27066672 <a title="156-lsi-17" href="./nips-2001-On_Discriminative_vs._Generative_Classifiers%3A_A_comparison_of_logistic_regression_and_naive_Bayes.html">133 nips-2001-On Discriminative vs. Generative Classifiers: A comparison of logistic regression and naive Bayes</a></p>
<p>18 0.26848781 <a title="156-lsi-18" href="./nips-2001-Bayesian_time_series_classification.html">43 nips-2001-Bayesian time series classification</a></p>
<p>19 0.26279423 <a title="156-lsi-19" href="./nips-2001-Gaussian_Process_Regression_with_Mismatched_Models.html">79 nips-2001-Gaussian Process Regression with Mismatched Models</a></p>
<p>20 0.24659094 <a title="156-lsi-20" href="./nips-2001-Spectral_Relaxation_for_K-means_Clustering.html">171 nips-2001-Spectral Relaxation for K-means Clustering</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2001_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.025), (17, 0.027), (19, 0.032), (27, 0.112), (30, 0.079), (38, 0.013), (49, 0.369), (59, 0.057), (72, 0.038), (79, 0.056), (83, 0.03), (91, 0.094)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.81354177 <a title="156-lda-1" href="./nips-2001-Rao-Blackwellised_Particle_Filtering_via_Data_Augmentation.html">156 nips-2001-Rao-Blackwellised Particle Filtering via Data Augmentation</a></p>
<p>Author: Christophe Andrieu, Nando D. Freitas, Arnaud Doucet</p><p>Abstract: In this paper, we extend the Rao-Blackwellised particle filtering method to more complex hybrid models consisting of Gaussian latent variables and discrete observations. This is accomplished by augmenting the models with artificial variables that enable us to apply Rao-Blackwellisation. Other improvements include the design of an optimal importance proposal distribution and being able to swap the sampling an selection steps to handle outliers. We focus on sequential binary classifiers that consist of linear combinations of basis functions , whose coefficients evolve according to a Gaussian smoothness prior. Our results show significant improvements. 1</p><p>2 0.71165639 <a title="156-lda-2" href="./nips-2001-Product_Analysis%3A_Learning_to_Model_Observations_as_Products_of_Hidden_Variables.html">153 nips-2001-Product Analysis: Learning to Model Observations as Products of Hidden Variables</a></p>
<p>Author: Brendan J. Frey, Anitha Kannan, Nebojsa Jojic</p><p>Abstract: Factor analysis and principal components analysis can be used to model linear relationships between observed variables and linearly map high-dimensional data to a lower-dimensional hidden space. In factor analysis, the observations are modeled as a linear combination of normally distributed hidden variables. We describe a nonlinear generalization of factor analysis , called</p><p>3 0.64169836 <a title="156-lda-3" href="./nips-2001-Active_Learning_in_the_Drug_Discovery_Process.html">25 nips-2001-Active Learning in the Drug Discovery Process</a></p>
<p>Author: Manfred K. Warmuth, Gunnar Rätsch, Michael Mathieson, Jun Liao, Christian Lemmen</p><p>Abstract: We investigate the following data mining problem from Computational Chemistry: From a large data set of compounds, ﬁnd those that bind to a target molecule in as few iterations of biological testing as possible. In each iteration a comparatively small batch of compounds is screened for binding to the target. We apply active learning techniques for selecting the successive batches. One selection strategy picks unlabeled examples closest to the maximum margin hyperplane. Another produces many weight vectors by running perceptrons over multiple permutations of the data. Each weight vector votes with its prediction and we pick the unlabeled examples for which the prediction is most evenly split between and . For a third selection strategy note that each unlabeled example bisects the version space of consistent weight vectors. We estimate the volume on both sides of the split by bouncing a billiard through the version space and select unlabeled examples that cause the most even split of the version space. We demonstrate that on two data sets provided by DuPont Pharmaceuticals that all three selection strategies perform comparably well and are much better than selecting random batches for testing. § © ¨</p><p>4 0.45243084 <a title="156-lda-4" href="./nips-2001-Global_Coordination_of_Local_Linear_Models.html">84 nips-2001-Global Coordination of Local Linear Models</a></p>
<p>Author: Sam T. Roweis, Lawrence K. Saul, Geoffrey E. Hinton</p><p>Abstract: High dimensional data that lies on or near a low dimensional manifold can be described by a collection of local linear models. Such a description, however, does not provide a global parameterization of the manifold—arguably an important goal of unsupervised learning. In this paper, we show how to learn a collection of local linear models that solves this more difﬁcult problem. Our local linear models are represented by a mixture of factor analyzers, and the “global coordination” of these models is achieved by adding a regularizing term to the standard maximum likelihood objective function. The regularizer breaks a degeneracy in the mixture model’s parameter space, favoring models whose internal coordinate systems are aligned in a consistent way. As a result, the internal coordinates change smoothly and continuously as one traverses a connected path on the manifold—even when the path crosses the domains of many different local models. The regularizer takes the form of a Kullback-Leibler divergence and illustrates an unexpected application of variational methods: not to perform approximate inference in intractable probabilistic models, but to learn more useful internal representations in tractable ones. 1 Manifold Learning Consider an ensemble of images, each of which contains a face against a neutral background. Each image can be represented by a point in the high dimensional vector space of pixel intensities. This representation, however, does not exploit the strong correlations between pixels of the same image, nor does it support many useful operations for reasoning about faces. If, for example, we select two images with faces in widely different locations and then average their pixel intensities, we do not obtain an image of a face at their average location. Images of faces lie on or near a low-dimensional, curved manifold, and we can represent them more usefully by the coordinates on this manifold than by pixel intensities. Using these “intrinsic coordinates”, the average of two faces is another face with the average of their locations, poses and expressions. To analyze and manipulate faces, it is helpful to imagine a “magic black box” with levers or dials corresponding to the intrinsic coordinates on this manifold. Given a setting of the levers and dials, the box generates an image of a face. Given an image of a face, the box deduces the appropriate setting of the levers and dials. In this paper, we describe a fairly general way to construct such a box automatically from an ensemble of high-dimensional vectors. We assume only that there exists an underlying manifold of low dimensionality and that the relationship between the raw data and the manifold coordinates is locally linear and smoothly varying. Thus our method applies not only to images of faces, but also to many other forms of highly distributed perceptual and scientiﬁc data (e.g., spectrograms of speech, robotic sensors, gene expression arrays, document collections). 2 Local Linear Models The global structure of perceptual manifolds (such as images of faces) tends to be highly nonlinear. Fortunately, despite their complicated global structure, we can usually characterize these manifolds as locally linear. Thus, to a good approximation, they can be represented by collections of simpler models, each of which describes a locally linear neighborhood[3, 6, 8]. For unsupervised learning tasks, a probabilistic model that nicely captures this intuition is a mixture of factor analyzers (MFA)[5]. The model is used to describe high dimensional data that lies on or near a lower dimensional manifold. MFAs parameterize a joint distribution over observed and hidden variables: (1) where the observed variable, , represents the high dimensional data; the discrete hidden variables, , indexes different neighborhoods on the manifold; and the continuous hidden variables, , represent low dimensional local coordinates. The model assumes that data is sampled from different neighborhoods on the manifold with prior probabilities , and that within each neighborhood, the data’s local coordinates are normally distributed1 as:  RP&¤§¢  Q  ¡ I 0 (  3HGF D C¥@@@¥ 8¥75 ( E¨BAA9¨©©64§ 2 0 ( 31)£ ¥ ¡    ¡   ¥ ¡     ¥ §¥ ¡ &¤§¢'&§ %#¤¢$#¨</p><p>5 0.44314831 <a title="156-lda-5" href="./nips-2001-Fast%2C_Large-Scale_Transformation-Invariant_Clustering.html">75 nips-2001-Fast, Large-Scale Transformation-Invariant Clustering</a></p>
<p>Author: Brendan J. Frey, Nebojsa Jojic</p><p>Abstract: In previous work on “transformed mixtures of Gaussians” and “transformed hidden Markov models”, we showed how the EM algorithm in a discrete latent variable model can be used to jointly normalize data (e.g., center images, pitch-normalize spectrograms) and learn a mixture model of the normalized data. The only input to the algorithm is the data, a list of possible transformations, and the number of clusters to ﬁnd. The main criticism of this work was that the exhaustive computation of the posterior probabilities over transformations would make scaling up to large feature vectors and large sets of transformations intractable. Here, we describe how a tremendous speed-up is acheived through the use of a variational technique for decoupling transformations, and a fast Fourier transform method for computing posterior probabilities. For N ×N images, learning C clusters under N rotations, N scales, N x-translations and N y-translations takes only (C + 2 log N )N 2 scalar operations per iteration. In contrast, the original algorithm takes CN 6 operations to account for these transformations. We give results on learning a 4-component mixture model from a video sequence with frames of size 320 ×240. The model accounts for 360 rotations and 76,800 translations. Each iteration of EM takes only 10 seconds per frame in MATLAB, which is over 5 million times faster than the original algorithm. 1</p><p>6 0.44035643 <a title="156-lda-6" href="./nips-2001-The_Fidelity_of_Local_Ordinal_Encoding.html">182 nips-2001-The Fidelity of Local Ordinal Encoding</a></p>
<p>7 0.43934876 <a title="156-lda-7" href="./nips-2001-A_Natural_Policy_Gradient.html">13 nips-2001-A Natural Policy Gradient</a></p>
<p>8 0.43657324 <a title="156-lda-8" href="./nips-2001-KLD-Sampling%3A_Adaptive_Particle_Filters.html">102 nips-2001-KLD-Sampling: Adaptive Particle Filters</a></p>
<p>9 0.43652505 <a title="156-lda-9" href="./nips-2001-Neural_Implementation_of_Bayesian_Inference_in_Population_Codes.html">131 nips-2001-Neural Implementation of Bayesian Inference in Population Codes</a></p>
<p>10 0.43613672 <a title="156-lda-10" href="./nips-2001-Activity_Driven_Adaptive_Stochastic_Resonance.html">27 nips-2001-Activity Driven Adaptive Stochastic Resonance</a></p>
<p>11 0.43589661 <a title="156-lda-11" href="./nips-2001-Thin_Junction_Trees.html">190 nips-2001-Thin Junction Trees</a></p>
<p>12 0.43451852 <a title="156-lda-12" href="./nips-2001-Relative_Density_Nets%3A_A_New_Way_to_Combine_Backpropagation_with_HMM%27s.html">162 nips-2001-Relative Density Nets: A New Way to Combine Backpropagation with HMM's</a></p>
<p>13 0.43409592 <a title="156-lda-13" href="./nips-2001-Convolution_Kernels_for_Natural_Language.html">56 nips-2001-Convolution Kernels for Natural Language</a></p>
<p>14 0.43368125 <a title="156-lda-14" href="./nips-2001-Multi_Dimensional_ICA_to_Separate_Correlated_Sources.html">127 nips-2001-Multi Dimensional ICA to Separate Correlated Sources</a></p>
<p>15 0.43300489 <a title="156-lda-15" href="./nips-2001-Model-Free_Least-Squares_Policy_Iteration.html">121 nips-2001-Model-Free Least-Squares Policy Iteration</a></p>
<p>16 0.43276352 <a title="156-lda-16" href="./nips-2001-Grouping_with_Bias.html">89 nips-2001-Grouping with Bias</a></p>
<p>17 0.43264461 <a title="156-lda-17" href="./nips-2001-Kernel_Feature_Spaces_and_Nonlinear_Blind_Souce_Separation.html">103 nips-2001-Kernel Feature Spaces and Nonlinear Blind Souce Separation</a></p>
<p>18 0.43238816 <a title="156-lda-18" href="./nips-2001-Fast_and_Robust_Classification_using_Asymmetric_AdaBoost_and_a_Detector_Cascade.html">77 nips-2001-Fast and Robust Classification using Asymmetric AdaBoost and a Detector Cascade</a></p>
<p>19 0.43207419 <a title="156-lda-19" href="./nips-2001-Categorization_by_Learning_and_Combining_Object_Parts.html">46 nips-2001-Categorization by Learning and Combining Object Parts</a></p>
<p>20 0.43204433 <a title="156-lda-20" href="./nips-2001-Very_loopy_belief_propagation_for_unwrapping_phase_images.html">196 nips-2001-Very loopy belief propagation for unwrapping phase images</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
