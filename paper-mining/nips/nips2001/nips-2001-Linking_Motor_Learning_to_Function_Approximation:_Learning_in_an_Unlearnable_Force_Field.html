<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>116 nips-2001-Linking Motor Learning to Function Approximation: Learning in an Unlearnable Force Field</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2001" href="../home/nips2001_home.html">nips2001</a> <a title="nips-2001-116" href="#">nips2001-116</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>116 nips-2001-Linking Motor Learning to Function Approximation: Learning in an Unlearnable Force Field</h1>
<br/><p>Source: <a title="nips-2001-116-pdf" href="http://papers.nips.cc/paper/1966-linking-motor-learning-to-function-approximation-learning-in-an-unlearnable-force-field.pdf">pdf</a></p><p>Author: O. Donchin, Reza Shadmehr</p><p>Abstract: Reaching movements require the brain to generate motor commands that rely on an internal model of the task’s dynamics. Here we consider the errors that subjects make early in their reaching trajectories to various targets as they learn an internal model. Using a framework from function approximation, we argue that the sequence of errors should reﬂect the process of gradient descent. If so, then the sequence of errors should obey hidden state transitions of a simple dynamical system. Fitting the system to human data, we ﬁnd a surprisingly good ﬁt accounting for 98% of the variance. This allows us to draw tentative conclusions about the basis elements used by the brain in transforming sensory space to motor commands. To test the robustness of the results, we estimate the shape of the basis elements under two conditions: in a traditional learning paradigm with a consistent force ﬁeld, and in a random sequence of force ﬁelds where learning is not possible. Remarkably, we ﬁnd that the basis remains invariant. 1</p><p>Reference: <a title="nips-2001-116-reference" href="../nips2001_reference/nips-2001-Linking_Motor_Learning_to_Function_Approximation%3A_Learning_in_an_Unlearnable_Force_Field_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Linking motor learning to function approximation: Learning in an unlearnable force ﬁeld Opher Donchin and Reza Shadmehr Dept. [sent-1, score-0.42]
</p><p>2 edu  Abstract Reaching movements require the brain to generate motor commands that rely on an internal model of the task’s dynamics. [sent-6, score-0.54]
</p><p>3 Here we consider the errors that subjects make early in their reaching trajectories to various targets as they learn an internal model. [sent-7, score-0.58]
</p><p>4 Using a framework from function approximation, we argue that the sequence of errors should reﬂect the process of gradient descent. [sent-8, score-0.226]
</p><p>5 If so, then the sequence of errors should obey hidden state transitions of a simple dynamical system. [sent-9, score-0.27]
</p><p>6 Fitting the system to human data, we ﬁnd a surprisingly good ﬁt accounting for 98% of the variance. [sent-10, score-0.121]
</p><p>7 This allows us to draw tentative conclusions about the basis elements used by the brain in transforming sensory space to motor commands. [sent-11, score-0.275]
</p><p>8 To test the robustness of the results, we estimate the shape of the basis elements under two conditions: in a traditional learning paradigm with a consistent force ﬁeld, and in a random sequence of force ﬁelds where learning is not possible. [sent-12, score-0.759]
</p><p>9 1  Introduction  It appears that in constructing the motor commands to guide the arm toward a target, the brain relies on an internal model (IM) of the dynamics of the task that it learns through practice [1]. [sent-14, score-0.555]
</p><p>10 The IM is presumably a system that transforms a desired limb trajectory in sensory coordinates to motor commands. [sent-15, score-0.295]
</p><p>11 The motor commands in turn create the complex activation of muscles necessary to cause action. [sent-16, score-0.174]
</p><p>12 A major issue in motor control is to infer characteristics of the IM from the actions of subjects. [sent-17, score-0.123]
</p><p>13 Recently, we took a ﬁrst step toward mathematically characterizing the IM’s representation in the brain [2]. [sent-18, score-0.097]
</p><p>14 We analyzed the sequence of errors made by subjects on successive movements as they reached to targets while holding a robotic arm. [sent-19, score-0.819]
</p><p>15 The robot produced a force ﬁeld and subjects learned to compensate for the ﬁeld (presumably by constructing an IM) and eventually produced straight movements within the ﬁeld. [sent-20, score-1.044]
</p><p>16 Our analysis sought to draw conclusions about the structure of the IM from the sequence of errors generated by the subjects. [sent-21, score-0.196]
</p><p>17 For instance, in a  velocity-dependent force ﬁeld (such as the ﬁelds we use), the IM must be able to encode velocity in order to anticipate the upcoming force. [sent-22, score-0.371]
</p><p>18 We hoped that the eﬀect of errors in one direction on subsequent movements in other directions would give information about the width of the elements which the IM used in encoding velocity. [sent-23, score-0.67]
</p><p>19 For example, if the basis elements were narrow, then movements in a given direction would result in little or no change in performance in neighboring directions. [sent-24, score-0.502]
</p><p>20 We hypothesized that an estimate of the width of the basis elements could be calculated by ﬁtting the time sequence of errors to a set of equations representing a dynamical system. [sent-26, score-0.445]
</p><p>21 The dynamical system assumed that error in a movement resulted from a diﬀerence between the IM’s approximation and the actual environment, an assumption that has recently been corroborated [3]. [sent-27, score-0.485]
</p><p>22 The diﬀerence between this output and reality results in movement errors. [sent-29, score-0.278]
</p><p>23 B is a matrix characterizing the eﬀect of errors in one direction on other directions. [sent-30, score-0.295]
</p><p>24 That is, B can provide the generalization function we sought. [sent-31, score-0.055]
</p><p>25 But why might this dynamical system be a good model of trial-to-trial behavior in a learning paradigm? [sent-34, score-0.108]
</p><p>26 1 can be derived within the framework of functional approximation, and that B is closely related to the basis functions in the approximation process. [sent-36, score-0.093]
</p><p>27 We ﬁnd that this model gives accurate ﬁts to human data, even when the number of parameters in the model is drastically reduced. [sent-37, score-0.087]
</p><p>28 1 that learning involves simple movement-by-movement corrections to the IM, and that these variations depend only on the shape of the basis which the IM uses for representation. [sent-39, score-0.108]
</p><p>29 Remarkably, when subjects perform movements in a force ﬁeld that changes randomly from one movement to the next, the pattern of errors predicts a generalization function, and therefore a set of basis elements, indistinguishable from the condition where the force ﬁeld does not change. [sent-40, score-1.579]
</p><p>30 That is, “an unlearnable task is learned in exactly the same way as a learnable task. [sent-41, score-0.098]
</p><p>31 1  Approach The Learning Process  In the current task, subjects grip the handle of a robot and make 10cm reaching movements to targets presented visually. [sent-43, score-0.781]
</p><p>32 The robot produces a force ﬁeld F(x) pro˙ portional and perpendicular to the velocity of the hand, such as F = (0 13; −13 0)· x ˙ (with F in Newtons and x in m/s). [sent-44, score-0.556]
</p><p>33 To simulate the process of learning an IM, ˙ we assume that the IM uses scalar valued basis functions that encode velocity g = [g1 (x), . [sent-45, score-0.237]
</p><p>34 , gn (x)]T so that the IM’s expectation of force at a desired veloc˙ ˙ ˆ ˙ ity is: F(x) = W g(x), where W is a 2 × n matrix [4]. [sent-48, score-0.297]
</p><p>35 To move the hand to a ˙  target at direction k, a desired trajectory xk (t) is given as input to the IM, which ˙ ˆ ˙ in turn produces as output F(xk ) [5, 6]. [sent-49, score-0.387]
</p><p>36 As a result, forces are experienced F(t) ˜ ˆ ˙ so that a force error can be calculated as F(t) = F(t) − F(xk (t)). [sent-50, score-0.382]
</p><p>37 We do this for an arbitrary point in velocity space x0 ˙ by multiplying both sides of the Eq. [sent-54, score-0.144]
</p><p>38 2 by g(x0 ) with the result that: ˙ T  ˆ ˆ F(n+1) (x0 ) = F(n) (x0 ) + η ˙ ˙  ˜ g(xk(n) )T g(x0 ) F(n) dt ˙ ˙  (3)  t=0  Further simpliﬁcation will require approximation. [sent-55, score-0.062]
</p><p>39 Because we are considering a case where the actual force, F(x), is directly proportional to velocity, it is reasonable to ˙ make the approximation that, along a reasonably straight desired trajectory, the ˜ ˜ ˙ ˜ ˙ force error, F(t), is simply proportional to the velocity, F(xk(n) ) = F · xk(n) . [sent-56, score-0.414]
</p><p>40 3 is actually of the form T  ˜ F  xk(n) (t)g(xk(n) )T g(x0 ) dt ˙ ˙ ˙  (4)  t=0  One more assumption is required to make this tractable. [sent-58, score-0.062]
</p><p>41 We restrict our attention to only x0 that equals the peak velocity of ˙ ˙ the desired trajectory associated with a movement direction l. [sent-63, score-0.623]
</p><p>42 Since we have only ˆ eight diﬀerent points in velocity space to consider, F can be considered an eightˆ l rather than a function F(x). [sent-64, score-0.144]
</p><p>43 Similarly, B(xl , xk ) will become an ˆ ˙ valued vector, F ˙ ˙ 8x8 matrix, Bl,k . [sent-65, score-0.214]
</p><p>44 , 8  (6)  Figure 1: 12 N 9N 6N  3 cm  We performed simulations to test the approximation that displacement in arm motion at 250 msec toward a target at 10 cm is proportional to error in the force estimate made by the IM. [sent-70, score-0.838]
</p><p>45 A system of equations describing a controller, dynamics of a typical human arm, and robot dynamics [7] were simulated for a 500 msec min jerk motion to 8 targets. [sent-71, score-0.521]
</p><p>46 The simulated robot produced one of 8 force ﬁelds scaled to 3 diﬀerent magnitudes, while the controller remained na¨ ıve to the ﬁeld. [sent-72, score-0.526]
</p><p>47 The errors in hand motion at 250 msec were ﬁtted to the robot forces using a single compliance matrix. [sent-73, score-0.472]
</p><p>48 Lighter dashed lines are the displacement predictions of the model, darker solid lines are the actual displacement in the simulations’ movement. [sent-74, score-0.217]
</p><p>49 ˜ One more approximation is to assume that force error F in a given movement will be proportional to position error in that movement when both are evaluated at 250ms. [sent-75, score-0.914]
</p><p>50 1 which shows that the linear relationship holds for a wide range of movements and force errors. [sent-77, score-0.525]
</p><p>51 Finally, because the forces are perpendicular to the movement, we will disregard the error parallel to the direction of movement, reducing Eq. [sent-78, score-0.251]
</p><p>52 We are now in a position to write our system of equations in its ﬁnal form: ˆ (n) y (n) = Dk(n) (F (n) − Fk(n) ) (m+1) (n) ˜ ˆ ˆ Fl = Fl + Bl,k(n) F (n)  l = 1, . [sent-80, score-0.066]
</p><p>53 , 8  (7)  Note that this is a system of nine equations: a single movement causes a change in all 8 directions for which the IM has an expectation. [sent-83, score-0.372]
</p><p>54 Let us now introduce a new (n) ˆ (n) variable zk(n) ≡ Dk(n) Fk(n) , which represents the error (perpendicular displacement) that would have been experienced during this movement if we had not compensated for the expected ﬁeld. [sent-84, score-0.377]
</p><p>55 3  The shape of the generalization function B  Our task now is to give subjects a sequence of targets, observe the errors in their movements, and ask whether there are parameters for which the system of Eq. [sent-89, score-0.611]
</p><p>56 Given a sequence of N movement directions, forces imposed on each movement, and the resulting errors ({k, F, y}(n) , j=1, . [sent-91, score-0.559]
</p><p>57 We address this concern by making the assumption that the B matrix has a special shape: Bl,k = b( xl xk ). [sent-100, score-0.259]
</p><p>58 That is, each entry in the B matrix is determined ˙ ˙ according to the diﬀerence in angle between the two directions represented. [sent-101, score-0.15]
</p><p>59 This ˙ ˙ assumption implies that g(xk )T g(xl ) depends only on xk xl . [sent-102, score-0.227]
</p><p>60 20  90  Difference in angle  180  Normalized  Normalized  Simulated Bs  100  1  0. [sent-110, score-0.058]
</p><p>61 5 −180  −90  0  90  180  Difference in angle  Figure 2: We simulated a system of equations representing dynamics of robot, human arm, and adaptive controller for movements to a total of 192 targets spanning 8 directions of movement. [sent-113, score-0.858]
</p><p>62 The adaptive controller learned by applying gradient descent (η = 0. [sent-114, score-0.153]
</p><p>63 002) to learn a gaussian basis encoding arm velocity with a σ of 0. [sent-115, score-0.451]
</p><p>64 Errors, computed as displacement perpendicular to direction of target were measured at 250 msec and are plotted for one direction of movement (45 deg) (a - d). [sent-120, score-0.69]
</p><p>65 Circles indicate error on no ﬁeld trials and triangles indicate error on ﬁelded trials. [sent-122, score-0.104]
</p><p>66 7 and the generalization matrix B was estimated (f ). [sent-124, score-0.087]
</p><p>67 Data was also collected from 76 subjects, and ﬁt with the model (e), and it gave a generalization function that is nearly identicals to the generalization function of a controller using gaussians with a width of 0. [sent-125, score-0.251]
</p><p>68 3  Results  We ﬁrst tested the validity of our approach in an artiﬁcial learning system that used a simulation of human arm and robot dynamics to learn an IM of the imposed force ﬁeld with gaussian basis elements. [sent-127, score-0.879]
</p><p>69 The result was a sequence of errors to a series of targets. [sent-128, score-0.196]
</p><p>70 7 to the sequence of errors and found an estimate for the generalization function (Fig. [sent-130, score-0.251]
</p><p>71 As expected, when narrow basis elements are used, the generalization function is narrow. [sent-132, score-0.198]
</p><p>72 We next ﬁt the same model to data that had been collected from 76 subjects and again found an excellent ﬁt. [sent-133, score-0.255]
</p><p>73 2 show the generalization function, B, as a function of the angle between xk and xl . [sent-135, score-0.34]
</p><p>74 The demonstrate that errors in one direction aﬀect movements ˙ ˙ in other directions both in simulations errors and in the subjects’ errors. [sent-136, score-0.769]
</p><p>75 The greatest eﬀect of error is in the direction in which the movement was made. [sent-137, score-0.405]
</p><p>76 The immediately neighboring directions are also signiﬁcantly aﬀected but the eﬀect drops oﬀ with increasing distance. [sent-138, score-0.06]
</p><p>77 The generalization function which matched the human data was nearly identical to the one matching data produced by the simulation whose gaussians had σ = 0. [sent-139, score-0.29]
</p><p>78 5 −180 −90 0 90 180 Difference in angle Figure 3: Fitting the model in Eq. [sent-143, score-0.058]
</p><p>79 7 to a learning situation (a and c, 76 subjects) or a situation where subjects are presented with a random sequence of ﬁelds (b and d, 6 subjects) produce nearly identical models. [sent-144, score-0.381]
</p><p>80 a and b show errors (binned to 5 movements per data point), measured as perpendicular distance from a straight line trajectory at 250ms into the movement. [sent-145, score-0.62]
</p><p>81 Triangles are ﬁeld A (F = [0 13; −13 0] · x) movements , wedges ˙ are ﬁeld B (F = [0 − 13; 13 0] · x), and ﬁlled circles are no ﬁeld. [sent-146, score-0.298]
</p><p>82 It can be seen that subjects in the learning paradigm learn to counteract the ﬁeld, and show after aﬀects. [sent-148, score-0.357]
</p><p>83 c and d show that the model ﬁt both the learning paradigm and the random ﬁeld paradigm. [sent-150, score-0.065]
</p><p>84 The ﬁt is plotted for movements made to 90◦ during the ﬁrst 192 movements following ﬁrst exposure to the ﬁeld (movements 193 through 384 in a and b). [sent-151, score-0.596]
</p><p>85 Fits to the last 192 movements in each paradigm gave r 2 of 0. [sent-155, score-0.363]
</p><p>86 The normalized generalization function is nearly identical for the all four sets. [sent-159, score-0.131]
</p><p>87 terized as the accretion of small changes in the state of the controller accumulated over a large number of movements. [sent-164, score-0.12]
</p><p>88 In order to challenge this surprising aspect of the model, we decided to apply it to data in which human subjects performed movements in ﬁelds that varied randomly from trial to trial. [sent-165, score-0.64]
</p><p>89 As seen in a and b of the ﬁgure, subjects are able to improve their performance through learning in a consistent ﬁeld but they do not improve in the random ﬁeld. [sent-171, score-0.287]
</p><p>90 Although the ﬁts of each type of ﬁeld were performed independently, we can see in e that the B matrixes are nearly identical which indicates that trial-by-trial learning was the same for both types of ﬁelds. [sent-173, score-0.076]
</p><p>91 It is likely that in this case subjects come to rely on a feedback driven controller which would be unable to compensate for the errors generated early in the movement but would allow them to more quickly adjust to those errors as information about the ﬁeld they are moving through is processed. [sent-176, score-0.972]
</p><p>92 4  Conclusions  We hypothesized that the process of learning an internal model of the arm’s dynamics may be similar to mechanisms of gradient descent in the framework of approximation theory. [sent-177, score-0.165]
</p><p>93 If so, then errors experienced in a given movement should aﬀect subsequent movements in a meaningful way, and perhaps as simply as those predicted by the dynamical system in Eq. [sent-178, score-0.918]
</p><p>94 These equations appear to ﬁt both simulations and actual human data exceedingly well, making strong predictions about the shape of the basis with which the IM is apparently learned. [sent-180, score-0.29]
</p><p>95 Here we ﬁnd that the shape of the basis remains invariant despite radical changes in pattern of errors, as exhibited when subjects were exposed to a random ﬁeld as compared to a stationary ﬁeld. [sent-181, score-0.391]
</p><p>96 We conclude that even when the task is unlearnable and errors approximate a ﬂat line, the brain is attempting to learn with the same characteristic basis which is used when the task is simple and errors exponentially approach zero. [sent-182, score-0.557]
</p><p>97 Adaptive representation of dynamics during learning of a motor task. [sent-187, score-0.171]
</p><p>98 Learning of action through adaptive combination of motor primitives. [sent-194, score-0.154]
</p><p>99 A mathematical model of the adaptive control of human arm motions. [sent-209, score-0.323]
</p><p>100 Formation and control of optimal trajectory in human multijoint arm movement. [sent-225, score-0.366]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('im', 0.51), ('movements', 0.298), ('movement', 0.278), ('subjects', 0.255), ('force', 0.227), ('arm', 0.205), ('eld', 0.201), ('xk', 0.186), ('errors', 0.146), ('velocity', 0.144), ('motor', 0.123), ('robot', 0.117), ('mvmt', 0.093), ('displacement', 0.092), ('controller', 0.092), ('direction', 0.089), ('human', 0.087), ('dynamical', 0.074), ('trajectory', 0.074), ('msec', 0.074), ('targets', 0.07), ('shadmehr', 0.07), ('unlearnable', 0.07), ('dk', 0.068), ('perpendicular', 0.068), ('ect', 0.065), ('paradigm', 0.065), ('num', 0.065), ('basis', 0.065), ('dt', 0.062), ('experienced', 0.061), ('erence', 0.061), ('directions', 0.06), ('angle', 0.058), ('elds', 0.058), ('forces', 0.056), ('generalization', 0.055), ('di', 0.053), ('commands', 0.051), ('elements', 0.05), ('sequence', 0.05), ('nearly', 0.049), ('mm', 0.048), ('simulated', 0.048), ('dynamics', 0.048), ('compliance', 0.046), ('opher', 0.046), ('reza', 0.046), ('tting', 0.045), ('integral', 0.045), ('zk', 0.044), ('shape', 0.043), ('produced', 0.042), ('reaching', 0.041), ('xl', 0.041), ('rand', 0.04), ('error', 0.038), ('desired', 0.038), ('brain', 0.037), ('fl', 0.037), ('learn', 0.037), ('system', 0.034), ('straight', 0.034), ('fit', 0.034), ('actual', 0.033), ('motion', 0.033), ('toward', 0.032), ('nth', 0.032), ('consistent', 0.032), ('matrix', 0.032), ('equations', 0.032), ('adaptive', 0.031), ('internal', 0.031), ('field', 0.031), ('fk', 0.031), ('gradient', 0.03), ('simulation', 0.03), ('simulations', 0.03), ('ts', 0.029), ('imposed', 0.029), ('compensate', 0.029), ('adjustment', 0.029), ('zl', 0.029), ('task', 0.028), ('changes', 0.028), ('valued', 0.028), ('narrow', 0.028), ('hypothesized', 0.028), ('wij', 0.028), ('characterizing', 0.028), ('triangles', 0.028), ('approximation', 0.028), ('subsequent', 0.027), ('identical', 0.027), ('bs', 0.027), ('remarkably', 0.027), ('proportional', 0.027), ('cm', 0.026), ('presumably', 0.026), ('adjust', 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.000001 <a title="116-tfidf-1" href="./nips-2001-Linking_Motor_Learning_to_Function_Approximation%3A_Learning_in_an_Unlearnable_Force_Field.html">116 nips-2001-Linking Motor Learning to Function Approximation: Learning in an Unlearnable Force Field</a></p>
<p>Author: O. Donchin, Reza Shadmehr</p><p>Abstract: Reaching movements require the brain to generate motor commands that rely on an internal model of the task’s dynamics. Here we consider the errors that subjects make early in their reaching trajectories to various targets as they learn an internal model. Using a framework from function approximation, we argue that the sequence of errors should reﬂect the process of gradient descent. If so, then the sequence of errors should obey hidden state transitions of a simple dynamical system. Fitting the system to human data, we ﬁnd a surprisingly good ﬁt accounting for 98% of the variance. This allows us to draw tentative conclusions about the basis elements used by the brain in transforming sensory space to motor commands. To test the robustness of the results, we estimate the shape of the basis elements under two conditions: in a traditional learning paradigm with a consistent force ﬁeld, and in a random sequence of force ﬁelds where learning is not possible. Remarkably, we ﬁnd that the basis remains invariant. 1</p><p>2 0.31636474 <a title="116-tfidf-2" href="./nips-2001-The_Emergence_of_Multiple_Movement_Units_in_the_Presence_of_Noise_and_Feedback_Delay.html">181 nips-2001-The Emergence of Multiple Movement Units in the Presence of Noise and Feedback Delay</a></p>
<p>Author: Michael Kositsky, Andrew G. Barto</p><p>Abstract: Tangential hand velocity proﬁles of rapid human arm movements often appear as sequences of several bell-shaped acceleration-deceleration phases called submovements or movement units. This suggests how the nervous system might efﬁciently control a motor plant in the presence of noise and feedback delay. Another critical observation is that stochasticity in a motor control problem makes the optimal control policy essentially different from the optimal control policy for the deterministic case. We use a simpliﬁed dynamic model of an arm and address rapid aimed arm movements. We use reinforcement learning as a tool to approximate the optimal policy in the presence of noise and feedback delay. Using a simpliﬁed model we show that multiple submovements emerge as an optimal policy in the presence of noise and feedback delay. The optimal policy in this situation is to drive the arm’s end point close to the target by one fast submovement and then apply a few slow submovements to accurately drive the arm’s end point into the target region. In our simulations, the controller sometimes generates corrective submovements before the initial fast submovement is completed, much like the predictive corrections observed in a number of psychophysical experiments.</p><p>3 0.20731124 <a title="116-tfidf-3" href="./nips-2001-Classifying_Single_Trial_EEG%3A_Towards_Brain_Computer_Interfacing.html">50 nips-2001-Classifying Single Trial EEG: Towards Brain Computer Interfacing</a></p>
<p>Author: Benjamin Blankertz, Gabriel Curio, Klaus-Robert Müller</p><p>Abstract: Driven by the progress in the ﬁeld of single-trial analysis of EEG, there is a growing interest in brain computer interfaces (BCIs), i.e., systems that enable human subjects to control a computer only by means of their brain signals. In a pseudo-online simulation our BCI detects upcoming ﬁnger movements in a natural keyboard typing condition and predicts their laterality. This can be done on average 100–230 ms before the respective key is actually pressed, i.e., long before the onset of EMG. Our approach is appealing for its short response time and high classiﬁcation accuracy (>96%) in a binary decision where no human training is involved. We compare discriminative classiﬁers like Support Vector Machines (SVMs) and different variants of Fisher Discriminant that possess favorable regularization properties for dealing with high noise cases (inter-trial variablity).</p><p>4 0.13972513 <a title="116-tfidf-4" href="./nips-2001-Probabilistic_Inference_of_Hand_Motion_from_Neural_Activity_in_Motor_Cortex.html">150 nips-2001-Probabilistic Inference of Hand Motion from Neural Activity in Motor Cortex</a></p>
<p>Author: Yun Gao, Michael J. Black, Elie Bienenstock, Shy Shoham, John P. Donoghue</p><p>Abstract: Statistical learning and probabilistic inference techniques are used to infer the hand position of a subject from multi-electrode recordings of neural activity in motor cortex. First, an array of electrodes provides training data of neural ﬁring conditioned on hand kinematics. We learn a nonparametric representation of this ﬁring activity using a Bayesian model and rigorously compare it with previous models using cross-validation. Second, we infer a posterior probability distribution over hand motion conditioned on a sequence of neural test data using Bayesian inference. The learned ﬁring models of multiple cells are used to deﬁne a nonGaussian likelihood term which is combined with a prior probability for the kinematics. A particle ﬁltering method is used to represent, update, and propagate the posterior distribution over time. The approach is compared with traditional linear ﬁltering methods; the results suggest that it may be appropriate for neural prosthetic applications.</p><p>5 0.13015048 <a title="116-tfidf-5" href="./nips-2001-Eye_movements_and_the_maturation_of_cortical_orientation_selectivity.html">73 nips-2001-Eye movements and the maturation of cortical orientation selectivity</a></p>
<p>Author: Antonino Casile, Michele Rucci</p><p>Abstract: Neural activity appears to be a crucial component for shaping the receptive ﬁelds of cortical simple cells into adjacent, oriented subregions alternately receiving ON- and OFF-center excitatory geniculate inputs. It is known that the orientation selective responses of V1 neurons are reﬁned by visual experience. After eye opening, the spatiotemporal structure of neural activity in the early stages of the visual pathway depends both on the visual environment and on how the environment is scanned. We have used computational modeling to investigate how eye movements might affect the reﬁnement of the orientation tuning of simple cells in the presence of a Hebbian scheme of synaptic plasticity. Levels of correlation between the activity of simulated cells were examined while natural scenes were scanned so as to model sequences of saccades and ﬁxational eye movements, such as microsaccades, tremor and ocular drift. The speciﬁc patterns of activity required for a quantitatively accurate development of simple cell receptive ﬁelds with segregated ON and OFF subregions were observed during ﬁxational eye movements, but not in the presence of saccades or with static presentation of natural visual input. These results suggest an important role for the eye movements occurring during visual ﬁxation in the reﬁnement of orientation selectivity.</p><p>6 0.10379247 <a title="116-tfidf-6" href="./nips-2001-Probabilistic_principles_in_unsupervised_learning_of_visual_structure%3A_human_data_and_a_model.html">151 nips-2001-Probabilistic principles in unsupervised learning of visual structure: human data and a model</a></p>
<p>7 0.087509245 <a title="116-tfidf-7" href="./nips-2001-Discriminative_Direction_for_Kernel_Classifiers.html">60 nips-2001-Discriminative Direction for Kernel Classifiers</a></p>
<p>8 0.072471641 <a title="116-tfidf-8" href="./nips-2001-KLD-Sampling%3A_Adaptive_Particle_Filters.html">102 nips-2001-KLD-Sampling: Adaptive Particle Filters</a></p>
<p>9 0.069122337 <a title="116-tfidf-9" href="./nips-2001-A_Rotation_and_Translation_Invariant_Discrete_Saliency_Network.html">19 nips-2001-A Rotation and Translation Invariant Discrete Saliency Network</a></p>
<p>10 0.063298114 <a title="116-tfidf-10" href="./nips-2001-Generating_velocity_tuning_by_asymmetric_recurrent_connections.html">82 nips-2001-Generating velocity tuning by asymmetric recurrent connections</a></p>
<p>11 0.057311505 <a title="116-tfidf-11" href="./nips-2001-Risk_Sensitive_Particle_Filters.html">163 nips-2001-Risk Sensitive Particle Filters</a></p>
<p>12 0.051812358 <a title="116-tfidf-12" href="./nips-2001-Effective_Size_of_Receptive_Fields_of_Inferior_Temporal_Visual_Cortex_Neurons_in_Natural_Scenes.html">65 nips-2001-Effective Size of Receptive Fields of Inferior Temporal Visual Cortex Neurons in Natural Scenes</a></p>
<p>13 0.051146124 <a title="116-tfidf-13" href="./nips-2001-A_theory_of_neural_integration_in_the_head-direction_system.html">23 nips-2001-A theory of neural integration in the head-direction system</a></p>
<p>14 0.047474578 <a title="116-tfidf-14" href="./nips-2001-Asymptotic_Universality_for_Learning_Curves_of_Support_Vector_Machines.html">38 nips-2001-Asymptotic Universality for Learning Curves of Support Vector Machines</a></p>
<p>15 0.047241788 <a title="116-tfidf-15" href="./nips-2001-Modularity_in_the_motor_system%3A_decomposition_of_muscle_patterns_as_combinations_of_time-varying_synergies.html">125 nips-2001-Modularity in the motor system: decomposition of muscle patterns as combinations of time-varying synergies</a></p>
<p>16 0.046047296 <a title="116-tfidf-16" href="./nips-2001-A_Natural_Policy_Gradient.html">13 nips-2001-A Natural Policy Gradient</a></p>
<p>17 0.043113098 <a title="116-tfidf-17" href="./nips-2001-The_Steering_Approach_for_Multi-Criteria_Reinforcement_Learning.html">187 nips-2001-The Steering Approach for Multi-Criteria Reinforcement Learning</a></p>
<p>18 0.043044873 <a title="116-tfidf-18" href="./nips-2001-Learning_Discriminative_Feature_Transforms_to_Low_Dimensions_in_Low_Dimentions.html">109 nips-2001-Learning Discriminative Feature Transforms to Low Dimensions in Low Dimentions</a></p>
<p>19 0.04200232 <a title="116-tfidf-19" href="./nips-2001-Learning_Body_Pose_via_Specialized_Maps.html">108 nips-2001-Learning Body Pose via Specialized Maps</a></p>
<p>20 0.041469779 <a title="116-tfidf-20" href="./nips-2001-Bayesian_time_series_classification.html">43 nips-2001-Bayesian time series classification</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2001_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.161), (1, -0.13), (2, -0.021), (3, 0.044), (4, -0.066), (5, 0.037), (6, -0.081), (7, 0.178), (8, 0.154), (9, 0.144), (10, -0.018), (11, -0.042), (12, -0.256), (13, -0.029), (14, 0.042), (15, 0.231), (16, -0.297), (17, -0.083), (18, 0.074), (19, -0.015), (20, 0.072), (21, 0.033), (22, -0.043), (23, 0.012), (24, -0.018), (25, -0.16), (26, 0.04), (27, 0.135), (28, -0.149), (29, 0.117), (30, 0.046), (31, -0.117), (32, 0.191), (33, -0.026), (34, -0.078), (35, 0.031), (36, 0.04), (37, 0.034), (38, 0.001), (39, -0.031), (40, 0.006), (41, 0.032), (42, 0.034), (43, 0.035), (44, 0.004), (45, -0.062), (46, -0.034), (47, -0.012), (48, 0.028), (49, -0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96316361 <a title="116-lsi-1" href="./nips-2001-Linking_Motor_Learning_to_Function_Approximation%3A_Learning_in_an_Unlearnable_Force_Field.html">116 nips-2001-Linking Motor Learning to Function Approximation: Learning in an Unlearnable Force Field</a></p>
<p>Author: O. Donchin, Reza Shadmehr</p><p>Abstract: Reaching movements require the brain to generate motor commands that rely on an internal model of the task’s dynamics. Here we consider the errors that subjects make early in their reaching trajectories to various targets as they learn an internal model. Using a framework from function approximation, we argue that the sequence of errors should reﬂect the process of gradient descent. If so, then the sequence of errors should obey hidden state transitions of a simple dynamical system. Fitting the system to human data, we ﬁnd a surprisingly good ﬁt accounting for 98% of the variance. This allows us to draw tentative conclusions about the basis elements used by the brain in transforming sensory space to motor commands. To test the robustness of the results, we estimate the shape of the basis elements under two conditions: in a traditional learning paradigm with a consistent force ﬁeld, and in a random sequence of force ﬁelds where learning is not possible. Remarkably, we ﬁnd that the basis remains invariant. 1</p><p>2 0.89800817 <a title="116-lsi-2" href="./nips-2001-The_Emergence_of_Multiple_Movement_Units_in_the_Presence_of_Noise_and_Feedback_Delay.html">181 nips-2001-The Emergence of Multiple Movement Units in the Presence of Noise and Feedback Delay</a></p>
<p>Author: Michael Kositsky, Andrew G. Barto</p><p>Abstract: Tangential hand velocity proﬁles of rapid human arm movements often appear as sequences of several bell-shaped acceleration-deceleration phases called submovements or movement units. This suggests how the nervous system might efﬁciently control a motor plant in the presence of noise and feedback delay. Another critical observation is that stochasticity in a motor control problem makes the optimal control policy essentially different from the optimal control policy for the deterministic case. We use a simpliﬁed dynamic model of an arm and address rapid aimed arm movements. We use reinforcement learning as a tool to approximate the optimal policy in the presence of noise and feedback delay. Using a simpliﬁed model we show that multiple submovements emerge as an optimal policy in the presence of noise and feedback delay. The optimal policy in this situation is to drive the arm’s end point close to the target by one fast submovement and then apply a few slow submovements to accurately drive the arm’s end point into the target region. In our simulations, the controller sometimes generates corrective submovements before the initial fast submovement is completed, much like the predictive corrections observed in a number of psychophysical experiments.</p><p>3 0.68287414 <a title="116-lsi-3" href="./nips-2001-Modularity_in_the_motor_system%3A_decomposition_of_muscle_patterns_as_combinations_of_time-varying_synergies.html">125 nips-2001-Modularity in the motor system: decomposition of muscle patterns as combinations of time-varying synergies</a></p>
<p>Author: A. D'avella, M. C. Tresch</p><p>Abstract: The question of whether the nervous system produces movement through the combination of a few discrete elements has long been central to the study of motor control. Muscle synergies, i.e. coordinated patterns of muscle activity, have been proposed as possible building blocks. Here we propose a model based on combinations of muscle synergies with a speciﬁc amplitude and temporal structure. Time-varying synergies provide a realistic basis for the decomposition of the complex patterns observed in natural behaviors. To extract time-varying synergies from simultaneous recording of EMG activity we developed an algorithm which extends existing non-negative matrix factorization techniques.</p><p>4 0.53314584 <a title="116-lsi-4" href="./nips-2001-Classifying_Single_Trial_EEG%3A_Towards_Brain_Computer_Interfacing.html">50 nips-2001-Classifying Single Trial EEG: Towards Brain Computer Interfacing</a></p>
<p>Author: Benjamin Blankertz, Gabriel Curio, Klaus-Robert Müller</p><p>Abstract: Driven by the progress in the ﬁeld of single-trial analysis of EEG, there is a growing interest in brain computer interfaces (BCIs), i.e., systems that enable human subjects to control a computer only by means of their brain signals. In a pseudo-online simulation our BCI detects upcoming ﬁnger movements in a natural keyboard typing condition and predicts their laterality. This can be done on average 100–230 ms before the respective key is actually pressed, i.e., long before the onset of EMG. Our approach is appealing for its short response time and high classiﬁcation accuracy (>96%) in a binary decision where no human training is involved. We compare discriminative classiﬁers like Support Vector Machines (SVMs) and different variants of Fisher Discriminant that possess favorable regularization properties for dealing with high noise cases (inter-trial variablity).</p><p>5 0.39414477 <a title="116-lsi-5" href="./nips-2001-Probabilistic_Inference_of_Hand_Motion_from_Neural_Activity_in_Motor_Cortex.html">150 nips-2001-Probabilistic Inference of Hand Motion from Neural Activity in Motor Cortex</a></p>
<p>Author: Yun Gao, Michael J. Black, Elie Bienenstock, Shy Shoham, John P. Donoghue</p><p>Abstract: Statistical learning and probabilistic inference techniques are used to infer the hand position of a subject from multi-electrode recordings of neural activity in motor cortex. First, an array of electrodes provides training data of neural ﬁring conditioned on hand kinematics. We learn a nonparametric representation of this ﬁring activity using a Bayesian model and rigorously compare it with previous models using cross-validation. Second, we infer a posterior probability distribution over hand motion conditioned on a sequence of neural test data using Bayesian inference. The learned ﬁring models of multiple cells are used to deﬁne a nonGaussian likelihood term which is combined with a prior probability for the kinematics. A particle ﬁltering method is used to represent, update, and propagate the posterior distribution over time. The approach is compared with traditional linear ﬁltering methods; the results suggest that it may be appropriate for neural prosthetic applications.</p><p>6 0.37733072 <a title="116-lsi-6" href="./nips-2001-Probabilistic_principles_in_unsupervised_learning_of_visual_structure%3A_human_data_and_a_model.html">151 nips-2001-Probabilistic principles in unsupervised learning of visual structure: human data and a model</a></p>
<p>7 0.34936306 <a title="116-lsi-7" href="./nips-2001-Eye_movements_and_the_maturation_of_cortical_orientation_selectivity.html">73 nips-2001-Eye movements and the maturation of cortical orientation selectivity</a></p>
<p>8 0.28436568 <a title="116-lsi-8" href="./nips-2001-Geometrical_Singularities_in_the_Neuromanifold_of_Multilayer_Perceptrons.html">83 nips-2001-Geometrical Singularities in the Neuromanifold of Multilayer Perceptrons</a></p>
<p>9 0.2415181 <a title="116-lsi-9" href="./nips-2001-A_Rotation_and_Translation_Invariant_Discrete_Saliency_Network.html">19 nips-2001-A Rotation and Translation Invariant Discrete Saliency Network</a></p>
<p>10 0.23213036 <a title="116-lsi-10" href="./nips-2001-A_Rational_Analysis_of_Cognitive_Control_in_a_Speeded_Discrimination_Task.html">18 nips-2001-A Rational Analysis of Cognitive Control in a Speeded Discrimination Task</a></p>
<p>11 0.20536853 <a title="116-lsi-11" href="./nips-2001-Learning_Body_Pose_via_Specialized_Maps.html">108 nips-2001-Learning Body Pose via Specialized Maps</a></p>
<p>12 0.20073791 <a title="116-lsi-12" href="./nips-2001-Discriminative_Direction_for_Kernel_Classifiers.html">60 nips-2001-Discriminative Direction for Kernel Classifiers</a></p>
<p>13 0.19986583 <a title="116-lsi-13" href="./nips-2001-Reinforcement_Learning_and_Time_Perception_--_a_Model_of_Animal_Experiments.html">160 nips-2001-Reinforcement Learning and Time Perception -- a Model of Animal Experiments</a></p>
<p>14 0.19809049 <a title="116-lsi-14" href="./nips-2001-The_Steering_Approach_for_Multi-Criteria_Reinforcement_Learning.html">187 nips-2001-The Steering Approach for Multi-Criteria Reinforcement Learning</a></p>
<p>15 0.19781941 <a title="116-lsi-15" href="./nips-2001-Bayesian_time_series_classification.html">43 nips-2001-Bayesian time series classification</a></p>
<p>16 0.19081171 <a title="116-lsi-16" href="./nips-2001-A_Neural_Oscillator_Model_of_Auditory_Selective_Attention.html">14 nips-2001-A Neural Oscillator Model of Auditory Selective Attention</a></p>
<p>17 0.1872007 <a title="116-lsi-17" href="./nips-2001-Generating_velocity_tuning_by_asymmetric_recurrent_connections.html">82 nips-2001-Generating velocity tuning by asymmetric recurrent connections</a></p>
<p>18 0.18355742 <a title="116-lsi-18" href="./nips-2001-Active_Portfolio-Management_based_on_Error_Correction_Neural_Networks.html">26 nips-2001-Active Portfolio-Management based on Error Correction Neural Networks</a></p>
<p>19 0.18289703 <a title="116-lsi-19" href="./nips-2001-Fast_Parameter_Estimation_Using_Green%27s_Functions.html">76 nips-2001-Fast Parameter Estimation Using Green's Functions</a></p>
<p>20 0.17525156 <a title="116-lsi-20" href="./nips-2001-Reinforcement_Learning_with_Long_Short-Term_Memory.html">161 nips-2001-Reinforcement Learning with Long Short-Term Memory</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2001_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.021), (17, 0.016), (19, 0.039), (20, 0.306), (27, 0.1), (30, 0.133), (38, 0.041), (59, 0.024), (72, 0.071), (79, 0.029), (83, 0.029), (91, 0.111)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.83826429 <a title="116-lda-1" href="./nips-2001-Linking_Motor_Learning_to_Function_Approximation%3A_Learning_in_an_Unlearnable_Force_Field.html">116 nips-2001-Linking Motor Learning to Function Approximation: Learning in an Unlearnable Force Field</a></p>
<p>Author: O. Donchin, Reza Shadmehr</p><p>Abstract: Reaching movements require the brain to generate motor commands that rely on an internal model of the task’s dynamics. Here we consider the errors that subjects make early in their reaching trajectories to various targets as they learn an internal model. Using a framework from function approximation, we argue that the sequence of errors should reﬂect the process of gradient descent. If so, then the sequence of errors should obey hidden state transitions of a simple dynamical system. Fitting the system to human data, we ﬁnd a surprisingly good ﬁt accounting for 98% of the variance. This allows us to draw tentative conclusions about the basis elements used by the brain in transforming sensory space to motor commands. To test the robustness of the results, we estimate the shape of the basis elements under two conditions: in a traditional learning paradigm with a consistent force ﬁeld, and in a random sequence of force ﬁelds where learning is not possible. Remarkably, we ﬁnd that the basis remains invariant. 1</p><p>2 0.77775592 <a title="116-lda-2" href="./nips-2001-Speech_Recognition_using_SVMs.html">172 nips-2001-Speech Recognition using SVMs</a></p>
<p>Author: N. Smith, Mark Gales</p><p>Abstract: An important issue in applying SVMs to speech recognition is the ability to classify variable length sequences. This paper presents extensions to a standard scheme for handling this variable length data, the Fisher score. A more useful mapping is introduced based on the likelihood-ratio. The score-space defined by this mapping avoids some limitations of the Fisher score. Class-conditional generative models are directly incorporated into the definition of the score-space. The mapping, and appropriate normalisation schemes, are evaluated on a speaker-independent isolated letter task where the new mapping outperforms both the Fisher score and HMMs trained to maximise likelihood. 1</p><p>3 0.69089502 <a title="116-lda-3" href="./nips-2001-%28Not%29_Bounding_the_True_Error.html">1 nips-2001-(Not) Bounding the True Error</a></p>
<p>Author: John Langford, Rich Caruana</p><p>Abstract: We present a new approach to bounding the true error rate of a continuous valued classiﬁer based upon PAC-Bayes bounds. The method ﬁrst constructs a distribution over classiﬁers by determining how sensitive each parameter in the model is to noise. The true error rate of the stochastic classiﬁer found with the sensitivity analysis can then be tightly bounded using a PAC-Bayes bound. In this paper we demonstrate the method on artiﬁcial neural networks with results of a order of magnitude improvement vs. the best deterministic neural net bounds. £ ¡ ¤¢</p><p>4 0.6577245 <a title="116-lda-4" href="./nips-2001-Blind_Source_Separation_via_Multinode_Sparse_Representation.html">44 nips-2001-Blind Source Separation via Multinode Sparse Representation</a></p>
<p>Author: Michael Zibulevsky, Pavel Kisilev, Yehoshua Y. Zeevi, Barak A. Pearlmutter</p><p>Abstract: We consider a problem of blind source separation from a set of instantaneous linear mixtures, where the mixing matrix is unknown. It was discovered recently, that exploiting the sparsity of sources in an appropriate representation according to some signal dictionary, dramatically improves the quality of separation. In this work we use the property of multi scale transforms, such as wavelet or wavelet packets, to decompose signals into sets of local features with various degrees of sparsity. We use this intrinsic property for selecting the best (most sparse) subsets of features for further separation. The performance of the algorithm is verified on noise-free and noisy data. Experiments with simulated signals, musical sounds and images demonstrate significant improvement of separation quality over previously reported results. 1</p><p>5 0.58749449 <a title="116-lda-5" href="./nips-2001-Classifying_Single_Trial_EEG%3A_Towards_Brain_Computer_Interfacing.html">50 nips-2001-Classifying Single Trial EEG: Towards Brain Computer Interfacing</a></p>
<p>Author: Benjamin Blankertz, Gabriel Curio, Klaus-Robert Müller</p><p>Abstract: Driven by the progress in the ﬁeld of single-trial analysis of EEG, there is a growing interest in brain computer interfaces (BCIs), i.e., systems that enable human subjects to control a computer only by means of their brain signals. In a pseudo-online simulation our BCI detects upcoming ﬁnger movements in a natural keyboard typing condition and predicts their laterality. This can be done on average 100–230 ms before the respective key is actually pressed, i.e., long before the onset of EMG. Our approach is appealing for its short response time and high classiﬁcation accuracy (>96%) in a binary decision where no human training is involved. We compare discriminative classiﬁers like Support Vector Machines (SVMs) and different variants of Fisher Discriminant that possess favorable regularization properties for dealing with high noise cases (inter-trial variablity).</p><p>6 0.58476263 <a title="116-lda-6" href="./nips-2001-Dynamic_Time-Alignment_Kernel_in_Support_Vector_Machine.html">63 nips-2001-Dynamic Time-Alignment Kernel in Support Vector Machine</a></p>
<p>7 0.58319366 <a title="116-lda-7" href="./nips-2001-The_Fidelity_of_Local_Ordinal_Encoding.html">182 nips-2001-The Fidelity of Local Ordinal Encoding</a></p>
<p>8 0.57707244 <a title="116-lda-8" href="./nips-2001-Probabilistic_Abstraction_Hierarchies.html">149 nips-2001-Probabilistic Abstraction Hierarchies</a></p>
<p>9 0.57604897 <a title="116-lda-9" href="./nips-2001-KLD-Sampling%3A_Adaptive_Particle_Filters.html">102 nips-2001-KLD-Sampling: Adaptive Particle Filters</a></p>
<p>10 0.57465649 <a title="116-lda-10" href="./nips-2001-Probabilistic_Inference_of_Hand_Motion_from_Neural_Activity_in_Motor_Cortex.html">150 nips-2001-Probabilistic Inference of Hand Motion from Neural Activity in Motor Cortex</a></p>
<p>11 0.56659973 <a title="116-lda-11" href="./nips-2001-Categorization_by_Learning_and_Combining_Object_Parts.html">46 nips-2001-Categorization by Learning and Combining Object Parts</a></p>
<p>12 0.5624696 <a title="116-lda-12" href="./nips-2001-Effective_Size_of_Receptive_Fields_of_Inferior_Temporal_Visual_Cortex_Neurons_in_Natural_Scenes.html">65 nips-2001-Effective Size of Receptive Fields of Inferior Temporal Visual Cortex Neurons in Natural Scenes</a></p>
<p>13 0.55861211 <a title="116-lda-13" href="./nips-2001-Fast_and_Robust_Classification_using_Asymmetric_AdaBoost_and_a_Detector_Cascade.html">77 nips-2001-Fast and Robust Classification using Asymmetric AdaBoost and a Detector Cascade</a></p>
<p>14 0.55817205 <a title="116-lda-14" href="./nips-2001-Discriminative_Direction_for_Kernel_Classifiers.html">60 nips-2001-Discriminative Direction for Kernel Classifiers</a></p>
<p>15 0.55804318 <a title="116-lda-15" href="./nips-2001-Multi_Dimensional_ICA_to_Separate_Correlated_Sources.html">127 nips-2001-Multi Dimensional ICA to Separate Correlated Sources</a></p>
<p>16 0.55534786 <a title="116-lda-16" href="./nips-2001-Risk_Sensitive_Particle_Filters.html">163 nips-2001-Risk Sensitive Particle Filters</a></p>
<p>17 0.55483258 <a title="116-lda-17" href="./nips-2001-Relative_Density_Nets%3A_A_New_Way_to_Combine_Backpropagation_with_HMM%27s.html">162 nips-2001-Relative Density Nets: A New Way to Combine Backpropagation with HMM's</a></p>
<p>18 0.55358887 <a title="116-lda-18" href="./nips-2001-Adaptive_Sparseness_Using_Jeffreys_Prior.html">29 nips-2001-Adaptive Sparseness Using Jeffreys Prior</a></p>
<p>19 0.55299222 <a title="116-lda-19" href="./nips-2001-Computing_Time_Lower_Bounds_for_Recurrent_Sigmoidal_Neural_Networks.html">52 nips-2001-Computing Time Lower Bounds for Recurrent Sigmoidal Neural Networks</a></p>
<p>20 0.5525322 <a title="116-lda-20" href="./nips-2001-Probabilistic_principles_in_unsupervised_learning_of_visual_structure%3A_human_data_and_a_model.html">151 nips-2001-Probabilistic principles in unsupervised learning of visual structure: human data and a model</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
