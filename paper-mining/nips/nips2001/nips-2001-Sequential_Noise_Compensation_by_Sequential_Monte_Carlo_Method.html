<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>168 nips-2001-Sequential Noise Compensation by Sequential Monte Carlo Method</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2001" href="../home/nips2001_home.html">nips2001</a> <a title="nips-2001-168" href="#">nips2001-168</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>168 nips-2001-Sequential Noise Compensation by Sequential Monte Carlo Method</h1>
<br/><p>Source: <a title="nips-2001-168-pdf" href="http://papers.nips.cc/paper/2093-sequential-noise-compensation-by-sequential-monte-carlo-method.pdf">pdf</a></p><p>Author: K. Yao, S. Nakamura</p><p>Abstract: We present a sequential Monte Carlo method applied to additive noise compensation for robust speech recognition in time-varying noise. The method generates a set of samples according to the prior distribution given by clean speech models and noise prior evolved from previous estimation. An explicit model representing noise effects on speech features is used, so that an extended Kalman ﬁlter is constructed for each sample, generating the updated continuous state estimate as the estimation of the noise parameter, and prediction likelihood for weighting each sample. Minimum mean square error (MMSE) inference of the time-varying noise parameter is carried out over these samples by fusion the estimation of samples according to their weights. A residual resampling selection step and a Metropolis-Hastings smoothing step are used to improve calculation eﬃciency. Experiments were conducted on speech recognition in simulated non-stationary noises, where noise power changed artiﬁcially, and highly non-stationary Machinegun noise. In all the experiments carried out, we observed that the method can have signiﬁcant recognition performance improvement, over that achieved by noise compensation with stationary noise assumption. 1</p><p>Reference: <a title="nips-2001-168-reference" href="../nips2001_reference/nips-2001-Sequential_Noise_Compensation_by_Sequential_Monte_Carlo_Method_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Sequential noise compensation by sequential Monte Carlo method  Kaisheng Yao and Satoshi Nakamura ATR Spoken Language Translation Research Laboratories 2-2-2, Hikaridai Seika-cho, Souraku-gun, Kyoto, 619-0288, Japan E-mail: {kaisheng. [sent-1, score-0.648]
</p><p>2 jp  Abstract We present a sequential Monte Carlo method applied to additive noise compensation for robust speech recognition in time-varying noise. [sent-6, score-0.946]
</p><p>3 The method generates a set of samples according to the prior distribution given by clean speech models and noise prior evolved from previous estimation. [sent-7, score-0.658]
</p><p>4 An explicit model representing noise effects on speech features is used, so that an extended Kalman ﬁlter is constructed for each sample, generating the updated continuous state estimate as the estimation of the noise parameter, and prediction likelihood for weighting each sample. [sent-8, score-0.773]
</p><p>5 Minimum mean square error (MMSE) inference of the time-varying noise parameter is carried out over these samples by fusion the estimation of samples according to their weights. [sent-9, score-0.512]
</p><p>6 A residual resampling selection step and a Metropolis-Hastings smoothing step are used to improve calculation eﬃciency. [sent-10, score-0.16]
</p><p>7 Experiments were conducted on speech recognition in simulated non-stationary noises, where noise power changed artiﬁcially, and highly non-stationary Machinegun noise. [sent-11, score-0.527]
</p><p>8 In all the experiments carried out, we observed that the method can have signiﬁcant recognition performance improvement, over that achieved by noise compensation with stationary noise assumption. [sent-12, score-0.923]
</p><p>9 1  Introduction  Speech recognition in noise has been considered to be essential for its real applications. [sent-13, score-0.282]
</p><p>10 Among many approaches, model-based approach assumes explicit models representing noise eﬀects on speech features. [sent-15, score-0.437]
</p><p>11 In this approach, most researches are focused on stationary or slow-varying noise conditions. [sent-16, score-0.301]
</p><p>12 In this situation, environment noise parameters are often estimated before speech recognition from a small set of environment adaptation data. [sent-17, score-0.707]
</p><p>13 The estimated environment noise parameters are then used to compensate noise eﬀects in the feature or model space for recognition of noisy speech. [sent-18, score-0.643]
</p><p>14 However, it is well-known that noise statistics may vary during recognition. [sent-19, score-0.221]
</p><p>15 In this situation, the noise parameters estimated prior to speech recognition of the utterances is possibly not relevant to the subsequent frames of input speech if environment changes. [sent-20, score-0.874]
</p><p>16 A number of techniques have been proposed to compensate time-varying noise effects. [sent-21, score-0.238]
</p><p>17 In the ﬁrst approach, timevarying environment sources are modeled by Hidden Markov Models (HMM) or Gaussian mixtures that were trained by prior measurement of environments, so that noise compensation is a task of identiﬁcation of the underlying state sequences of the noise HMMs, e. [sent-23, score-0.933]
</p><p>18 ), so that statistics at some states or mixtures obtained before speech recognition are close to the real testing environments. [sent-27, score-0.282]
</p><p>19 In the second approach, environment model parameters are assumed to be timevarying, so it is not only an inference problem but also related to environment statistics estimation during speech recognition. [sent-28, score-0.454]
</p><p>20 In the Bayesian methods, all relevant information on the set of environment parameters and speech parameters, which are denoted as Θ(t) at frame t, is included in the posterior distribution given observation sequence Y (0 : t), i. [sent-33, score-0.431]
</p><p>21 For example, in [5], a Laplace transform is used to approximate the joint distribution of speech and noise parameters by vector Taylor series. [sent-38, score-0.443]
</p><p>22 The approximated joint distribution can give analytical formula for posterior distribution updating. [sent-39, score-0.091]
</p><p>23 We report an alternative approach for Bayesian estimation and compensation of noise eﬀects on speech features. [sent-40, score-0.743]
</p><p>24 The method is based on sequential Monte Carlo method [6]. [sent-41, score-0.18]
</p><p>25 In the method, a set of samples is generated hierarchically from the prior distribution given by speech models. [sent-42, score-0.353]
</p><p>26 A state space model representing noise eﬀects on speech features is used explicitly, and an extended Kalman ﬁlter (EKF) is constructed in each sample. [sent-43, score-0.464]
</p><p>27 The prediction likelihood of the EKF in each sample gives its weight for selection, smoothing, and inference of the time-varying noise parameter, so that noise compensation is carried out afterwards. [sent-44, score-0.824]
</p><p>28 Since noise parameter estimation, noise compensation and speech recognition are carried out frame-byframe, we denote this approach as sequential noise compensation. [sent-45, score-1.386]
</p><p>29 2  Speech and noise model  Our work is on speech features derived from Mel Frequency Cepstral Coeﬃcients (MFCC). [sent-46, score-0.423]
</p><p>30 In our work, speech and noise are respectively modeled by HMMs and a Gaussian mixture. [sent-50, score-0.44]
</p><p>31 For speech recognition in stationary additive noise, the following formula [4] has been shown to be eﬀective in compensating noise eﬀects. [sent-51, score-0.603]
</p><p>32 For Gaussian mixture kt at state st , the Log-Add method transforms the mean vector µl t kt of s the Gaussian mixture by, µl t kt ˆs  =  µl t kt + log(1 + exp(µl − µl t kt )) s n s  (1)  where µl is the mean vector in the noise model. [sent-52, score-4.57]
</p><p>33 n S and M each denote the number of states in speech models and the number of mixtures at each state. [sent-54, score-0.236]
</p><p>34 After the transformation, the mean vector µl t kt is further transformed by DCT, ˆs  and then plugged into speech models for recognition of noisy speech. [sent-56, score-1.122]
</p><p>35 Accordingly, n n the compensated mean is µl t kt (t). [sent-60, score-0.827]
</p><p>36 st and kt each denote the state and Gaussian mixture at frame t in speech models. [sent-62, score-1.265]
</p><p>37 µl t kt (t) and µl (t) each denote the speech and noise n s parameter. [sent-63, score-1.249]
</p><p>38 In Gaussian mixture kt at state st of speech model, speech parameter µl t kt (t) is assumed to be distributed in Gaussian s with mean µl t kt and variance Σl t kt . [sent-66, score-3.932]
</p><p>39 On the other hand, since the environment s s parameter is assumed to be time varying, the evolution of the environment mean vector can be modeled by a random walk function, i. [sent-67, score-0.276]
</p><p>40 , µl (t) = µl (t − 1) + v(t) n n  (2)  where v(t) is the environment driving noise in Gaussian distribution with zero mean and variance V . [sent-69, score-0.476]
</p><p>41 The above formula gives the prior distribution of the set of speech and noise model parameter Θ(t) = {st , kt , µl t kt (t), µl (t)}. [sent-71, score-2.137]
</p><p>42 , Y l (t) = µl t kt (t) + log (1 + exp (µl (t) − µl t kt (t))) + wst kt (t) s s n  (4)  where wst kt (t) is Gaussian with zero mean and variance Σl t kt , i. [sent-74, score-4.159]
</p><p>43 Another diﬃculty is that the n speech state and mixture sequence is hidden in (7). [sent-79, score-0.252]
</p><p>44 3  Time-varying noise parameter estimation by sequential Monte Carlo method  We apply the sequential Monte Carlo method [6] for posterior distribution updating. [sent-81, score-0.631]
</p><p>45 At each frame t, a proposal importance distribution is sampled whose target is the posterior distribution in (7), and it is implemented by sampling from lower distributions in hierarchy. [sent-82, score-0.177]
</p><p>46 MMSE inference of the time-varying noise parameter is a by-product of the steps, carried out after the smoothing step. [sent-84, score-0.325]
</p><p>47 In the sampling step, the prior distribution given by speech models is set to the proposal importance distribution, i. [sent-85, score-0.317]
</p><p>48 , q(Θ(t)|Θ(t − 1)) = ast−1 st pst kt N (µl t kt (t); µl t kt , Σl t kt ). [sent-87, score-3.445]
</p><p>49 The samples are then generated by sampling s s s hierarchically of the prior distribution described as follows: set i = 1 and perform the following steps: (i)  1. [sent-88, score-0.181]
</p><p>50 sample µ  ∼ ps(i) kt  l(i) (i) (i)  st kt  t  (t) ∼ N (; µl (i)  (i)  st kt  , Σl (i)  (i)  st kt  ), and set i = i + 1  4. [sent-91, score-3.734]
</p><p>51 repeat step 1 to 3 until i = N where superscript (i) denotes the index of samples and N denotes the number of samples. [sent-92, score-0.123]
</p><p>52 Each sample represents certain speech and noise parameter, which is (i) (i) l(i) l(i) denoted as Θ(i) (t) = (st , kt , µ (i) (i) (t), µn (t)). [sent-93, score-1.306]
</p><p>53 The weight of each sample is st kt  given by  t p(Θ(τ )(i) |Y l (τ )) τ =1 q(Θ(τ )(i) |Θ(τ −1)(i) ) . [sent-94, score-0.993]
</p><p>54 The remaining part in the right side of above equation, in fact, represents the prediction likelihood of the state space model given by (2) and (4) for each sample (i). [sent-96, score-0.09]
</p><p>55 This likelihood can be obtained analytically since after linearization of (4) with respect to µl (t) at n  l(i)  µn (t − 1), an extended Kalman ﬁlter (EKF) can be obtained, where the prediction likelihood of the EKF gives the weight, and the updated continuous state of EKF l(i) gives µn (t). [sent-97, score-0.098]
</p><p>56 In practice, after the above sampling step, the weights of all but several samples may become insigniﬁcant. [sent-98, score-0.132]
</p><p>57 Given the ﬁxed number of samples, this will results in degeneracy of the estimation, where not only some computational resources are wasted, but also estimation might be biased because of losing detailed information on some parts important to the parameter estimation. [sent-99, score-0.089]
</p><p>58 A selection step by residual resampling [6] is adopted after the sampling step. [sent-100, score-0.112]
</p><p>59 The method avoids the degeneracy by discarding those samples with insigniﬁcant weights, and in order to keep the number of the samples constant, samples with signiﬁcant weights are duplicated. [sent-101, score-0.328]
</p><p>60 Denote the ˜ ˜ set of samples after the selection step as Θ(t) = {Θ(i) (t); i = 1 · · · N } with weights ˜ = {β (i) (t); i = 1 · · · N }. [sent-103, score-0.144]
</p><p>61 ˜ β(t) After the selection step at frame t, these N samples are distributed approximately according to the posterior distribution in (7). [sent-104, score-0.212]
</p><p>62 However, the discrete nature of the approximation can lead to a skewed importance weights distribution, where ˜ the extreme case is all the samples have the same Θ(t) estimated. [sent-105, score-0.126]
</p><p>63 A MetropolisHastings smoothing [7] step is introduced in each sample where the step involves ˜ sampling a candidate Θ (i) (t) given the current Θ(i) (t) according to the proposal ˜ importance distribution q(Θ (t)|Θ(i) (t)). [sent-106, score-0.195]
</p><p>64 Denote the β ˇ ˇ ˇ ˇ obtained samples as Θ(t) = {Θ(i) (t); i = 1 · · · N } with weights β(t) = {β (i) (t); i = 1 · · · N }. [sent-109, score-0.102]
</p><p>65 , n N  µl (t) = ˆn i=1  ˇ β (i) (t) µl(i) (t) ˇ ˇ(j) (t) n β  N j=1  l(i)  where µn (t) is the updated continuous state of the EKF in the sample after the ˇ smoothing step. [sent-112, score-0.107]
</p><p>66 Once the estimate µl (t) has been obtained, it is plugged into (1) ˆn to do non-linear transformation of clean speech models. [sent-113, score-0.303]
</p><p>67 Five hundred clean speech utterances from 15 speakers and 111 utterances unseen in the training set were used for training and testing, respectively. [sent-116, score-0.307]
</p><p>68 Digits and silence were respectively modeled by 10-state and 3-state whole word HMMs with 4 diagonal Gaussian mixtures in each state. [sent-117, score-0.078]
</p><p>69 The ﬁrst was the baseline trained on clean speech without noise compensation, and the second was the system with noise compensation by (1) assuming stationary noise [4]. [sent-126, score-1.342]
</p><p>70 , without training transcript, and it was denoted according to the number of samples and variance of the environment driving noise V . [sent-130, score-0.569]
</p><p>71 Four seconds of contaminating noise was used in each experiment to obtain noise mean vector µl in (1) for Stationary Compensan tion. [sent-131, score-0.527]
</p><p>72 It was also for initialization of µl (0) in the sequential method. [sent-132, score-0.11]
</p><p>73 2  Speech recognition in simulated non-stationary noise  White noise signal was multiplied by a Chirp signal and a rectangular signal, so that the noise power of the contaminating White noise changed continuously, denoted as experiment A, and dramatically, denoted as experiment B. [sent-139, score-1.205]
</p><p>74 As a result, signalto-noise ratio (SNR) of the contaminating noise ranged from 0dB to 20. [sent-140, score-0.262]
</p><p>75 We plotted the noise power in 12th ﬁlter bank versus frames in Figure 2, together with the estimated noise power by the sequential method with number of samples set to 120 and environment driving noise variance set to 0. [sent-142, score-1.222]
</p><p>76 As a comparison, we also plotted the noise power and its estimate by the method with the same number of samples but larger driving noise variance to 0. [sent-144, score-0.705]
</p><p>77 First, the method can track the evolution of the noise power. [sent-147, score-0.269]
</p><p>78 Second, the larger driving noise variance V will make faster convergence but larger estimation error of the method. [sent-148, score-0.378]
</p><p>79 In terms of recognition performance, Table 1 shows that the method can eﬀectively improve system robustness to the time-varying noise. [sent-149, score-0.118]
</p><p>80 For example, with 60 samples, and the environment driving noise variance V set to 0. [sent-150, score-0.44]
</p><p>81 For example, given environment driving noise variance V set to 0. [sent-155, score-0.44]
</p><p>82 0001, increasing number of samples from 60 to 120, can improve word accuracy from 77. [sent-156, score-0.173]
</p><p>83 Table 1: Word Accuracy (in %) in simulated non-stationary noises, achieved by the sequential Monte Carlo method in comparison with baseline without noise compensation, denoted as Baseline, and noise compensation assuming stationary noise, denoted as Stationary Compensation. [sent-159, score-1.122]
</p><p>84 84  Speech recognition in real noise  In this experiment, speech signals were contaminated by highly non-stationary Machinegun noise in diﬀerent SNRs. [sent-177, score-0.705]
</p><p>85 The number of samples was set to 120, and the environment driving noise variance V was set to 0. [sent-178, score-0.525]
</p><p>86 Figure 2: Estimation of the time-varying parameter µl (t) by the sequential Monte n Carlo method at 12th ﬁlter bank in experiment A. [sent-181, score-0.228]
</p><p>87 86dB SNR, the method can improve word accuracy from 75. [sent-189, score-0.123]
</p><p>88 Table 2: Word Accuracy (in %) in Machinegun noise, achieved by the sequential Monte Carlo method in comparison with baseline without noise compensation, denoted as Baseline, and noise compensation assuming stationary noise, denoted as Stationary Compensation. [sent-194, score-1.103]
</p><p>89 89  Summary  We have presented a sequential Monte Carlo method for Bayesian estimation of time-varying noise parameter, which is for sequential noise compensation applied to robust speech recognition. [sent-212, score-1.234]
</p><p>90 The method uses samples to approximate the posterior distribution of the additive noise and speech parameters given observation sequence. [sent-213, score-0.615]
</p><p>91 Figure 3: Estimation of the time-varying parameter µl (t) by the sequential Monte n Carlo method at 12th ﬁlter bank in experiment A. [sent-214, score-0.228]
</p><p>92 Once the noise parameter has been inferred, it is plugged into a non-linear transformation of clean speech models. [sent-220, score-0.554]
</p><p>93 Experiments conducted on digits recognition in simulated non-stationary noises and real noises have shown that the method is very eﬀective to improve system robustness to time-varying additive noise. [sent-221, score-0.251]
</p><p>94 Moore, “Hidden markov model decomposition of speech and noise,” in ICASSP, 1990, pp. [sent-225, score-0.202]
</p><p>95 Kim, “Nonstationary environment compensation based on sequential estimation,” IEEE Signal Processing Letters, vol. [sent-229, score-0.492]
</p><p>96 Nakamura, “Sequential noise compensation by a sequential kullback proximal algorithm,” in EUROSPEECH, 2001, pp. [sent-236, score-0.613]
</p><p>97 Cao, “Residual noise compensation by a sequential em algorithm for robust speech recognition in nonstationary noise,” in ICSLP, 2000, vol. [sent-243, score-0.911]
</p><p>98 Kristjansson, “Algonquin: Iterating laplace’s method to remove multiple types of acoustic distortion for robust speech recognition,” in EUROSPEECH, 2001, pp. [sent-250, score-0.252]
</p><p>99 Chen, “Sequential monte carlo methods for dynamic systems,” J. [sent-255, score-0.146]
</p><p>100 Hastings, “Monte carlo sampling methods using markov chains and their applications,” Biometrika, vol. [sent-263, score-0.103]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('kt', 0.811), ('compensation', 0.282), ('noise', 0.221), ('speech', 0.202), ('st', 0.154), ('sequential', 0.11), ('environment', 0.1), ('driving', 0.085), ('samples', 0.085), ('ekf', 0.081), ('stationary', 0.08), ('carlo', 0.073), ('monte', 0.073), ('baseline', 0.066), ('recognition', 0.061), ('mmse', 0.054), ('lter', 0.053), ('clean', 0.049), ('snr', 0.047), ('noises', 0.047), ('pst', 0.047), ('denoted', 0.044), ('ast', 0.043), ('word', 0.042), ('contaminating', 0.041), ('machinegun', 0.041), ('nakamura', 0.041), ('yao', 0.041), ('estimation', 0.038), ('smoothing', 0.037), ('kalman', 0.036), ('method', 0.035), ('variance', 0.034), ('frame', 0.033), ('plugged', 0.032), ('posterior', 0.032), ('sampling', 0.03), ('parameter', 0.03), ('sample', 0.028), ('utterances', 0.028), ('experiment', 0.028), ('state', 0.027), ('dct', 0.027), ('mfcc', 0.027), ('refereeing', 0.027), ('wst', 0.027), ('di', 0.026), ('ects', 0.026), ('bank', 0.025), ('power', 0.024), ('accuracy', 0.024), ('importance', 0.024), ('hierarchically', 0.023), ('timevarying', 0.023), ('insigni', 0.023), ('estimated', 0.023), ('carried', 0.023), ('selection', 0.023), ('mixture', 0.023), ('prior', 0.023), ('improve', 0.022), ('hmms', 0.021), ('cepstral', 0.021), ('degeneracy', 0.021), ('residual', 0.021), ('likelihood', 0.021), ('transformation', 0.02), ('distribution', 0.02), ('additive', 0.02), ('eurospeech', 0.02), ('nonstationary', 0.02), ('formula', 0.019), ('gaussian', 0.019), ('resampling', 0.019), ('superscript', 0.019), ('acceptance', 0.019), ('simulated', 0.019), ('mixtures', 0.019), ('step', 0.019), ('proposal', 0.018), ('modeled', 0.017), ('compensate', 0.017), ('weights', 0.017), ('laplace', 0.016), ('ective', 0.016), ('signal', 0.016), ('mean', 0.016), ('curve', 0.016), ('denote', 0.015), ('robust', 0.015), ('updated', 0.015), ('bayesian', 0.015), ('inference', 0.014), ('table', 0.014), ('frames', 0.014), ('prediction', 0.014), ('representing', 0.014), ('erent', 0.014), ('environments', 0.014), ('evolution', 0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999988 <a title="168-tfidf-1" href="./nips-2001-Sequential_Noise_Compensation_by_Sequential_Monte_Carlo_Method.html">168 nips-2001-Sequential Noise Compensation by Sequential Monte Carlo Method</a></p>
<p>Author: K. Yao, S. Nakamura</p><p>Abstract: We present a sequential Monte Carlo method applied to additive noise compensation for robust speech recognition in time-varying noise. The method generates a set of samples according to the prior distribution given by clean speech models and noise prior evolved from previous estimation. An explicit model representing noise effects on speech features is used, so that an extended Kalman ﬁlter is constructed for each sample, generating the updated continuous state estimate as the estimation of the noise parameter, and prediction likelihood for weighting each sample. Minimum mean square error (MMSE) inference of the time-varying noise parameter is carried out over these samples by fusion the estimation of samples according to their weights. A residual resampling selection step and a Metropolis-Hastings smoothing step are used to improve calculation eﬃciency. Experiments were conducted on speech recognition in simulated non-stationary noises, where noise power changed artiﬁcially, and highly non-stationary Machinegun noise. In all the experiments carried out, we observed that the method can have signiﬁcant recognition performance improvement, over that achieved by noise compensation with stationary noise assumption. 1</p><p>2 0.21430072 <a title="168-tfidf-2" href="./nips-2001-ALGONQUIN_-_Learning_Dynamic_Noise_Models_From_Noisy_Speech_for_Robust_Speech_Recognition.html">4 nips-2001-ALGONQUIN - Learning Dynamic Noise Models From Noisy Speech for Robust Speech Recognition</a></p>
<p>Author: Brendan J. Frey, Trausti T. Kristjansson, Li Deng, Alex Acero</p><p>Abstract: A challenging, unsolved problem in the speech recognition community is recognizing speech signals that are corrupted by loud, highly nonstationary noise. One approach to noisy speech recognition is to automatically remove the noise from the cepstrum sequence before feeding it in to a clean speech recognizer. In previous work published in Eurospeech, we showed how a probability model trained on clean speech and a separate probability model trained on noise could be combined for the purpose of estimating the noisefree speech from the noisy speech. We showed how an iterative 2nd order vector Taylor series approximation could be used for probabilistic inference in this model. In many circumstances, it is not possible to obtain examples of noise without speech. Noise statistics may change significantly during an utterance, so that speechfree frames are not sufficient for estimating the noise model. In this paper, we show how the noise model can be learned even when the data contains speech. In particular, the noise model can be learned from the test utterance and then used to de noise the test utterance. The approximate inference technique is used as an approximate E step in a generalized EM algorithm that learns the parameters of the noise model from a test utterance. For both Wall Street J ournal data with added noise samples and the Aurora benchmark, we show that the new noise adaptive technique performs as well as or significantly better than the non-adaptive algorithm, without the need for a separate training set of noise examples. 1</p><p>3 0.16882305 <a title="168-tfidf-3" href="./nips-2001-Audio-Visual_Sound_Separation_Via_Hidden_Markov_Models.html">39 nips-2001-Audio-Visual Sound Separation Via Hidden Markov Models</a></p>
<p>Author: John R. Hershey, Michael Casey</p><p>Abstract: It is well known that under noisy conditions we can hear speech much more clearly when we read the speaker's lips. This suggests the utility of audio-visual information for the task of speech enhancement. We propose a method to exploit audio-visual cues to enable speech separation under non-stationary noise and with a single microphone. We revise and extend HMM-based speech enhancement techniques, in which signal and noise models are factori ally combined, to incorporate visual lip information and employ novel signal HMMs in which the dynamics of narrow-band and wide band components are factorial. We avoid the combinatorial explosion in the factorial model by using a simple approximate inference technique to quickly estimate the clean signals in a mixture. We present a preliminary evaluation of this approach using a small-vocabulary audio-visual database, showing promising improvements in machine intelligibility for speech enhanced using audio and visual information. 1</p><p>4 0.081843257 <a title="168-tfidf-4" href="./nips-2001-Dynamic_Time-Alignment_Kernel_in_Support_Vector_Machine.html">63 nips-2001-Dynamic Time-Alignment Kernel in Support Vector Machine</a></p>
<p>Author: Hiroshi Shimodaira, Ken-ichi Noma, Mitsuru Nakai, Shigeki Sagayama</p><p>Abstract: A new class of Support Vector Machine (SVM) that is applicable to sequential-pattern recognition such as speech recognition is developed by incorporating an idea of non-linear time alignment into the kernel function. Since the time-alignment operation of sequential pattern is embedded in the new kernel function, standard SVM training and classiﬁcation algorithms can be employed without further modiﬁcations. The proposed SVM (DTAK-SVM) is evaluated in speaker-dependent speech recognition experiments of hand-segmented phoneme recognition. Preliminary experimental results show comparable recognition performance with hidden Markov models (HMMs). 1</p><p>5 0.077553049 <a title="168-tfidf-5" href="./nips-2001-Speech_Recognition_with_Missing_Data_using_Recurrent_Neural_Nets.html">173 nips-2001-Speech Recognition with Missing Data using Recurrent Neural Nets</a></p>
<p>Author: S. Parveen, P. Green</p><p>Abstract: In the ‘missing data’ approach to improving the robustness of automatic speech recognition to added noise, an initial process identiﬁes spectraltemporal regions which are dominated by the speech source. The remaining regions are considered to be ‘missing’. In this paper we develop a connectionist approach to the problem of adapting speech recognition to the missing data case, using Recurrent Neural Networks. In contrast to methods based on Hidden Markov Models, RNNs allow us to make use of long-term time constraints and to make the problems of classiﬁcation with incomplete data and imputing missing values interact. We report encouraging results on an isolated digit recognition task.</p><p>6 0.063914165 <a title="168-tfidf-6" href="./nips-2001-Speech_Recognition_using_SVMs.html">172 nips-2001-Speech Recognition using SVMs</a></p>
<p>7 0.05896309 <a title="168-tfidf-7" href="./nips-2001-Asymptotic_Universality_for_Learning_Curves_of_Support_Vector_Machines.html">38 nips-2001-Asymptotic Universality for Learning Curves of Support Vector Machines</a></p>
<p>8 0.058110204 <a title="168-tfidf-8" href="./nips-2001-Rao-Blackwellised_Particle_Filtering_via_Data_Augmentation.html">156 nips-2001-Rao-Blackwellised Particle Filtering via Data Augmentation</a></p>
<p>9 0.05692165 <a title="168-tfidf-9" href="./nips-2001-Bayesian_time_series_classification.html">43 nips-2001-Bayesian time series classification</a></p>
<p>10 0.055632684 <a title="168-tfidf-10" href="./nips-2001-KLD-Sampling%3A_Adaptive_Particle_Filters.html">102 nips-2001-KLD-Sampling: Adaptive Particle Filters</a></p>
<p>11 0.054756004 <a title="168-tfidf-11" href="./nips-2001-A_Sequence_Kernel_and_its_Application_to_Speaker_Recognition.html">20 nips-2001-A Sequence Kernel and its Application to Speaker Recognition</a></p>
<p>12 0.054107077 <a title="168-tfidf-12" href="./nips-2001-Activity_Driven_Adaptive_Stochastic_Resonance.html">27 nips-2001-Activity Driven Adaptive Stochastic Resonance</a></p>
<p>13 0.052507285 <a title="168-tfidf-13" href="./nips-2001-Variance_Reduction_Techniques_for_Gradient_Estimates_in_Reinforcement_Learning.html">195 nips-2001-Variance Reduction Techniques for Gradient Estimates in Reinforcement Learning</a></p>
<p>14 0.050966326 <a title="168-tfidf-14" href="./nips-2001-Learning_Discriminative_Feature_Transforms_to_Low_Dimensions_in_Low_Dimentions.html">109 nips-2001-Learning Discriminative Feature Transforms to Low Dimensions in Low Dimentions</a></p>
<p>15 0.050300807 <a title="168-tfidf-15" href="./nips-2001-Infinite_Mixtures_of_Gaussian_Process_Experts.html">95 nips-2001-Infinite Mixtures of Gaussian Process Experts</a></p>
<p>16 0.046755757 <a title="168-tfidf-16" href="./nips-2001-TAP_Gibbs_Free_Energy%2C_Belief_Propagation_and_Sparsity.html">178 nips-2001-TAP Gibbs Free Energy, Belief Propagation and Sparsity</a></p>
<p>17 0.045934841 <a title="168-tfidf-17" href="./nips-2001-Risk_Sensitive_Particle_Filters.html">163 nips-2001-Risk Sensitive Particle Filters</a></p>
<p>18 0.045398746 <a title="168-tfidf-18" href="./nips-2001-Analysis_of_Sparse_Bayesian_Learning.html">35 nips-2001-Analysis of Sparse Bayesian Learning</a></p>
<p>19 0.042649694 <a title="168-tfidf-19" href="./nips-2001-Modeling_Temporal_Structure_in_Classical_Conditioning.html">123 nips-2001-Modeling Temporal Structure in Classical Conditioning</a></p>
<p>20 0.042280946 <a title="168-tfidf-20" href="./nips-2001-Tempo_tracking_and_rhythm_quantization_by_sequential_Monte_Carlo.html">179 nips-2001-Tempo tracking and rhythm quantization by sequential Monte Carlo</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2001_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.118), (1, -0.008), (2, -0.018), (3, -0.056), (4, -0.2), (5, 0.043), (6, 0.176), (7, -0.017), (8, 0.031), (9, -0.064), (10, 0.032), (11, 0.036), (12, 0.009), (13, 0.136), (14, -0.062), (15, 0.034), (16, -0.048), (17, -0.039), (18, -0.229), (19, 0.027), (20, -0.015), (21, -0.074), (22, 0.07), (23, 0.126), (24, 0.07), (25, -0.098), (26, 0.075), (27, -0.068), (28, 0.087), (29, 0.064), (30, 0.032), (31, 0.102), (32, -0.003), (33, 0.041), (34, -0.038), (35, -0.023), (36, 0.045), (37, 0.087), (38, 0.084), (39, 0.023), (40, -0.02), (41, -0.05), (42, -0.083), (43, 0.041), (44, 0.081), (45, 0.048), (46, 0.046), (47, 0.068), (48, 0.013), (49, -0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96856207 <a title="168-lsi-1" href="./nips-2001-Sequential_Noise_Compensation_by_Sequential_Monte_Carlo_Method.html">168 nips-2001-Sequential Noise Compensation by Sequential Monte Carlo Method</a></p>
<p>Author: K. Yao, S. Nakamura</p><p>Abstract: We present a sequential Monte Carlo method applied to additive noise compensation for robust speech recognition in time-varying noise. The method generates a set of samples according to the prior distribution given by clean speech models and noise prior evolved from previous estimation. An explicit model representing noise effects on speech features is used, so that an extended Kalman ﬁlter is constructed for each sample, generating the updated continuous state estimate as the estimation of the noise parameter, and prediction likelihood for weighting each sample. Minimum mean square error (MMSE) inference of the time-varying noise parameter is carried out over these samples by fusion the estimation of samples according to their weights. A residual resampling selection step and a Metropolis-Hastings smoothing step are used to improve calculation eﬃciency. Experiments were conducted on speech recognition in simulated non-stationary noises, where noise power changed artiﬁcially, and highly non-stationary Machinegun noise. In all the experiments carried out, we observed that the method can have signiﬁcant recognition performance improvement, over that achieved by noise compensation with stationary noise assumption. 1</p><p>2 0.86467695 <a title="168-lsi-2" href="./nips-2001-ALGONQUIN_-_Learning_Dynamic_Noise_Models_From_Noisy_Speech_for_Robust_Speech_Recognition.html">4 nips-2001-ALGONQUIN - Learning Dynamic Noise Models From Noisy Speech for Robust Speech Recognition</a></p>
<p>Author: Brendan J. Frey, Trausti T. Kristjansson, Li Deng, Alex Acero</p><p>Abstract: A challenging, unsolved problem in the speech recognition community is recognizing speech signals that are corrupted by loud, highly nonstationary noise. One approach to noisy speech recognition is to automatically remove the noise from the cepstrum sequence before feeding it in to a clean speech recognizer. In previous work published in Eurospeech, we showed how a probability model trained on clean speech and a separate probability model trained on noise could be combined for the purpose of estimating the noisefree speech from the noisy speech. We showed how an iterative 2nd order vector Taylor series approximation could be used for probabilistic inference in this model. In many circumstances, it is not possible to obtain examples of noise without speech. Noise statistics may change significantly during an utterance, so that speechfree frames are not sufficient for estimating the noise model. In this paper, we show how the noise model can be learned even when the data contains speech. In particular, the noise model can be learned from the test utterance and then used to de noise the test utterance. The approximate inference technique is used as an approximate E step in a generalized EM algorithm that learns the parameters of the noise model from a test utterance. For both Wall Street J ournal data with added noise samples and the Aurora benchmark, we show that the new noise adaptive technique performs as well as or significantly better than the non-adaptive algorithm, without the need for a separate training set of noise examples. 1</p><p>3 0.77426273 <a title="168-lsi-3" href="./nips-2001-Audio-Visual_Sound_Separation_Via_Hidden_Markov_Models.html">39 nips-2001-Audio-Visual Sound Separation Via Hidden Markov Models</a></p>
<p>Author: John R. Hershey, Michael Casey</p><p>Abstract: It is well known that under noisy conditions we can hear speech much more clearly when we read the speaker's lips. This suggests the utility of audio-visual information for the task of speech enhancement. We propose a method to exploit audio-visual cues to enable speech separation under non-stationary noise and with a single microphone. We revise and extend HMM-based speech enhancement techniques, in which signal and noise models are factori ally combined, to incorporate visual lip information and employ novel signal HMMs in which the dynamics of narrow-band and wide band components are factorial. We avoid the combinatorial explosion in the factorial model by using a simple approximate inference technique to quickly estimate the clean signals in a mixture. We present a preliminary evaluation of this approach using a small-vocabulary audio-visual database, showing promising improvements in machine intelligibility for speech enhanced using audio and visual information. 1</p><p>4 0.6315878 <a title="168-lsi-4" href="./nips-2001-Speech_Recognition_with_Missing_Data_using_Recurrent_Neural_Nets.html">173 nips-2001-Speech Recognition with Missing Data using Recurrent Neural Nets</a></p>
<p>Author: S. Parveen, P. Green</p><p>Abstract: In the ‘missing data’ approach to improving the robustness of automatic speech recognition to added noise, an initial process identiﬁes spectraltemporal regions which are dominated by the speech source. The remaining regions are considered to be ‘missing’. In this paper we develop a connectionist approach to the problem of adapting speech recognition to the missing data case, using Recurrent Neural Networks. In contrast to methods based on Hidden Markov Models, RNNs allow us to make use of long-term time constraints and to make the problems of classiﬁcation with incomplete data and imputing missing values interact. We report encouraging results on an isolated digit recognition task.</p><p>5 0.33804673 <a title="168-lsi-5" href="./nips-2001-A_Sequence_Kernel_and_its_Application_to_Speaker_Recognition.html">20 nips-2001-A Sequence Kernel and its Application to Speaker Recognition</a></p>
<p>Author: William M. Campbell</p><p>Abstract: A novel approach for comparing sequences of observations using an explicit-expansion kernel is demonstrated. The kernel is derived using the assumption of the independence of the sequence of observations and a mean-squared error training criterion. The use of an explicit expansion kernel reduces classiﬁer model size and computation dramatically, resulting in model sizes and computation one-hundred times smaller in our application. The explicit expansion also preserves the computational advantages of an earlier architecture based on mean-squared error training. Training using standard support vector machine methodology gives accuracy that signiﬁcantly exceeds the performance of state-of-the-art mean-squared error training for a speaker recognition task.</p><p>6 0.31945047 <a title="168-lsi-6" href="./nips-2001-Intransitive_Likelihood-Ratio_Classifiers.html">99 nips-2001-Intransitive Likelihood-Ratio Classifiers</a></p>
<p>7 0.30312157 <a title="168-lsi-7" href="./nips-2001-Activity_Driven_Adaptive_Stochastic_Resonance.html">27 nips-2001-Activity Driven Adaptive Stochastic Resonance</a></p>
<p>8 0.28943777 <a title="168-lsi-8" href="./nips-2001-Variance_Reduction_Techniques_for_Gradient_Estimates_in_Reinforcement_Learning.html">195 nips-2001-Variance Reduction Techniques for Gradient Estimates in Reinforcement Learning</a></p>
<p>9 0.26230958 <a title="168-lsi-9" href="./nips-2001-Dynamic_Time-Alignment_Kernel_in_Support_Vector_Machine.html">63 nips-2001-Dynamic Time-Alignment Kernel in Support Vector Machine</a></p>
<p>10 0.25973168 <a title="168-lsi-10" href="./nips-2001-Learning_Discriminative_Feature_Transforms_to_Low_Dimensions_in_Low_Dimentions.html">109 nips-2001-Learning Discriminative Feature Transforms to Low Dimensions in Low Dimentions</a></p>
<p>11 0.24898596 <a title="168-lsi-11" href="./nips-2001-Rao-Blackwellised_Particle_Filtering_via_Data_Augmentation.html">156 nips-2001-Rao-Blackwellised Particle Filtering via Data Augmentation</a></p>
<p>12 0.24881074 <a title="168-lsi-12" href="./nips-2001-Speech_Recognition_using_SVMs.html">172 nips-2001-Speech Recognition using SVMs</a></p>
<p>13 0.24380809 <a title="168-lsi-13" href="./nips-2001-Distribution_of_Mutual_Information.html">61 nips-2001-Distribution of Mutual Information</a></p>
<p>14 0.24197195 <a title="168-lsi-14" href="./nips-2001-KLD-Sampling%3A_Adaptive_Particle_Filters.html">102 nips-2001-KLD-Sampling: Adaptive Particle Filters</a></p>
<p>15 0.23672551 <a title="168-lsi-15" href="./nips-2001-Infinite_Mixtures_of_Gaussian_Process_Experts.html">95 nips-2001-Infinite Mixtures of Gaussian Process Experts</a></p>
<p>16 0.23543394 <a title="168-lsi-16" href="./nips-2001-A_Variational_Approach_to_Learning_Curves.html">21 nips-2001-A Variational Approach to Learning Curves</a></p>
<p>17 0.23511796 <a title="168-lsi-17" href="./nips-2001-TAP_Gibbs_Free_Energy%2C_Belief_Propagation_and_Sparsity.html">178 nips-2001-TAP Gibbs Free Energy, Belief Propagation and Sparsity</a></p>
<p>18 0.23498949 <a title="168-lsi-18" href="./nips-2001-A_Neural_Oscillator_Model_of_Auditory_Selective_Attention.html">14 nips-2001-A Neural Oscillator Model of Auditory Selective Attention</a></p>
<p>19 0.22124012 <a title="168-lsi-19" href="./nips-2001-Bayesian_time_series_classification.html">43 nips-2001-Bayesian time series classification</a></p>
<p>20 0.21433735 <a title="168-lsi-20" href="./nips-2001-Analysis_of_Sparse_Bayesian_Learning.html">35 nips-2001-Analysis of Sparse Bayesian Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2001_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.022), (14, 0.011), (17, 0.019), (19, 0.016), (20, 0.016), (27, 0.057), (30, 0.121), (38, 0.017), (59, 0.4), (72, 0.045), (79, 0.055), (83, 0.022), (91, 0.075)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9050023 <a title="168-lda-1" href="./nips-2001-Sequential_Noise_Compensation_by_Sequential_Monte_Carlo_Method.html">168 nips-2001-Sequential Noise Compensation by Sequential Monte Carlo Method</a></p>
<p>Author: K. Yao, S. Nakamura</p><p>Abstract: We present a sequential Monte Carlo method applied to additive noise compensation for robust speech recognition in time-varying noise. The method generates a set of samples according to the prior distribution given by clean speech models and noise prior evolved from previous estimation. An explicit model representing noise effects on speech features is used, so that an extended Kalman ﬁlter is constructed for each sample, generating the updated continuous state estimate as the estimation of the noise parameter, and prediction likelihood for weighting each sample. Minimum mean square error (MMSE) inference of the time-varying noise parameter is carried out over these samples by fusion the estimation of samples according to their weights. A residual resampling selection step and a Metropolis-Hastings smoothing step are used to improve calculation eﬃciency. Experiments were conducted on speech recognition in simulated non-stationary noises, where noise power changed artiﬁcially, and highly non-stationary Machinegun noise. In all the experiments carried out, we observed that the method can have signiﬁcant recognition performance improvement, over that achieved by noise compensation with stationary noise assumption. 1</p><p>2 0.824628 <a title="168-lda-2" href="./nips-2001-Learning_Body_Pose_via_Specialized_Maps.html">108 nips-2001-Learning Body Pose via Specialized Maps</a></p>
<p>Author: Rómer Rosales, Stan Sclaroff</p><p>Abstract: A nonlinear supervised learning model, the Specialized Mappings Architecture (SMA), is described and applied to the estimation of human body pose from monocular images. The SMA consists of several specialized forward mapping functions and an inverse mapping function. Each specialized function maps certain domains of the input space (image features) onto the output space (body pose parameters). The key algorithmic problems faced are those of learning the specialized domains and mapping functions in an optimal way, as well as performing inference given inputs and knowledge of the inverse function. Solutions to these problems employ the EM algorithm and alternating choices of conditional independence assumptions. Performance of the approach is evaluated with synthetic and real video sequences of human motion. 1</p><p>3 0.80116481 <a title="168-lda-3" href="./nips-2001-Sampling_Techniques_for_Kernel_Methods.html">164 nips-2001-Sampling Techniques for Kernel Methods</a></p>
<p>Author: Dimitris Achlioptas, Frank Mcsherry, Bernhard Schölkopf</p><p>Abstract: We propose randomized techniques for speeding up Kernel Principal Component Analysis on three levels: sampling and quantization of the Gram matrix in training, randomized rounding in evaluating the kernel expansions, and random projections in evaluating the kernel itself. In all three cases, we give sharp bounds on the accuracy of the obtained approximations. Rather intriguingly, all three techniques can be viewed as instantiations of the following idea: replace the kernel function by a “randomized kernel” which behaves like in expectation.</p><p>4 0.76366591 <a title="168-lda-4" href="./nips-2001-TAP_Gibbs_Free_Energy%2C_Belief_Propagation_and_Sparsity.html">178 nips-2001-TAP Gibbs Free Energy, Belief Propagation and Sparsity</a></p>
<p>Author: Lehel Csató, Manfred Opper, Ole Winther</p><p>Abstract: The adaptive TAP Gibbs free energy for a general densely connected probabilistic model with quadratic interactions and arbritary single site constraints is derived. We show how a speciﬁc sequential minimization of the free energy leads to a generalization of Minka’s expectation propagation. Lastly, we derive a sparse representation version of the sequential algorithm. The usefulness of the approach is demonstrated on classiﬁcation and density estimation with Gaussian processes and on an independent component analysis problem.</p><p>5 0.55629689 <a title="168-lda-5" href="./nips-2001-KLD-Sampling%3A_Adaptive_Particle_Filters.html">102 nips-2001-KLD-Sampling: Adaptive Particle Filters</a></p>
<p>Author: Dieter Fox</p><p>Abstract: Over the last years, particle ﬁlters have been applied with great success to a variety of state estimation problems. We present a statistical approach to increasing the efﬁciency of particle ﬁlters by adapting the size of sample sets on-the-ﬂy. The key idea of the KLD-sampling method is to bound the approximation error introduced by the sample-based representation of the particle ﬁlter. The name KLD-sampling is due to the fact that we measure the approximation error by the Kullback-Leibler distance. Our adaptation approach chooses a small number of samples if the density is focused on a small part of the state space, and it chooses a large number of samples if the state uncertainty is high. Both the implementation and computation overhead of this approach are small. Extensive experiments using mobile robot localization as a test application show that our approach yields drastic improvements over particle ﬁlters with ﬁxed sample set sizes and over a previously introduced adaptation technique.</p><p>6 0.52567619 <a title="168-lda-6" href="./nips-2001-ALGONQUIN_-_Learning_Dynamic_Noise_Models_From_Noisy_Speech_for_Robust_Speech_Recognition.html">4 nips-2001-ALGONQUIN - Learning Dynamic Noise Models From Noisy Speech for Robust Speech Recognition</a></p>
<p>7 0.51878864 <a title="168-lda-7" href="./nips-2001-Face_Recognition_Using_Kernel_Methods.html">74 nips-2001-Face Recognition Using Kernel Methods</a></p>
<p>8 0.49121192 <a title="168-lda-8" href="./nips-2001-Dynamic_Time-Alignment_Kernel_in_Support_Vector_Machine.html">63 nips-2001-Dynamic Time-Alignment Kernel in Support Vector Machine</a></p>
<p>9 0.48960793 <a title="168-lda-9" href="./nips-2001-Products_of_Gaussians.html">154 nips-2001-Products of Gaussians</a></p>
<p>10 0.48906118 <a title="168-lda-10" href="./nips-2001-Infinite_Mixtures_of_Gaussian_Process_Experts.html">95 nips-2001-Infinite Mixtures of Gaussian Process Experts</a></p>
<p>11 0.4849664 <a title="168-lda-11" href="./nips-2001-Estimating_the_Reliability_of_ICA_Projections.html">71 nips-2001-Estimating the Reliability of ICA Projections</a></p>
<p>12 0.4811838 <a title="168-lda-12" href="./nips-2001-Tempo_tracking_and_rhythm_quantization_by_sequential_Monte_Carlo.html">179 nips-2001-Tempo tracking and rhythm quantization by sequential Monte Carlo</a></p>
<p>13 0.47972521 <a title="168-lda-13" href="./nips-2001-Categorization_by_Learning_and_Combining_Object_Parts.html">46 nips-2001-Categorization by Learning and Combining Object Parts</a></p>
<p>14 0.47925633 <a title="168-lda-14" href="./nips-2001-Risk_Sensitive_Particle_Filters.html">163 nips-2001-Risk Sensitive Particle Filters</a></p>
<p>15 0.46682227 <a title="168-lda-15" href="./nips-2001-Quantizing_Density_Estimators.html">155 nips-2001-Quantizing Density Estimators</a></p>
<p>16 0.46255153 <a title="168-lda-16" href="./nips-2001-Neural_Implementation_of_Bayesian_Inference_in_Population_Codes.html">131 nips-2001-Neural Implementation of Bayesian Inference in Population Codes</a></p>
<p>17 0.46235621 <a title="168-lda-17" href="./nips-2001-Rao-Blackwellised_Particle_Filtering_via_Data_Augmentation.html">156 nips-2001-Rao-Blackwellised Particle Filtering via Data Augmentation</a></p>
<p>18 0.45937863 <a title="168-lda-18" href="./nips-2001-Multi_Dimensional_ICA_to_Separate_Correlated_Sources.html">127 nips-2001-Multi Dimensional ICA to Separate Correlated Sources</a></p>
<p>19 0.45555761 <a title="168-lda-19" href="./nips-2001-Probabilistic_Abstraction_Hierarchies.html">149 nips-2001-Probabilistic Abstraction Hierarchies</a></p>
<p>20 0.45529649 <a title="168-lda-20" href="./nips-2001-Kernel_Feature_Spaces_and_Nonlinear_Blind_Souce_Separation.html">103 nips-2001-Kernel Feature Spaces and Nonlinear Blind Souce Separation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
