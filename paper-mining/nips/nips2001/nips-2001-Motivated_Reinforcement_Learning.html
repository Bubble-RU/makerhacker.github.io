<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>126 nips-2001-Motivated Reinforcement Learning</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2001" href="../home/nips2001_home.html">nips2001</a> <a title="nips-2001-126" href="#">nips2001-126</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>126 nips-2001-Motivated Reinforcement Learning</h1>
<br/><p>Source: <a title="nips-2001-126-pdf" href="http://papers.nips.cc/paper/2048-motivated-reinforcement-learning.pdf">pdf</a></p><p>Author: Peter Dayan</p><p>Abstract: The standard reinforcement learning view of the involvement of neuromodulatory systems in instrumental conditioning includes a rather straightforward conception of motivation as prediction of sum future reward. Competition between actions is based on the motivating characteristics of their consequent states in this sense. Substantial, careful, experiments reviewed in Dickinson & Balleine, 12,13 into the neurobiology and psychology of motivation shows that this view is incomplete. In many cases, animals are faced with the choice not between many different actions at a given state, but rather whether a single response is worth executing at all. Evidence suggests that the motivational process underlying this choice has different psychological and neural properties from that underlying action choice. We describe and model these motivational systems, and consider the way they interact.</p><p>Reference: <a title="nips-2001-126-reference" href="../nips2001_reference/nips-2001-Motivated_Reinforcement_Learning_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('instru', 0.401), ('pavlov', 0.252), ('habit', 0.235), ('ballein', 0.214), ('dickinson', 0.192), ('hungry', 0.192), ('rl', 0.182), ('devalu', 0.171), ('sr', 0.155), ('anim', 0.155), ('amygdal', 0.152), ('reward', 0.147), ('mot', 0.139), ('xo', 0.134), ('appetit', 0.128), ('dopamin', 0.126), ('stimul', 0.11), ('psycholog', 0.108), ('rout', 0.108), ('pellet', 0.107)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999934 <a title="126-tfidf-1" href="./nips-2001-Motivated_Reinforcement_Learning.html">126 nips-2001-Motivated Reinforcement Learning</a></p>
<p>2 0.1589863 <a title="126-tfidf-2" href="./nips-2001-Modeling_Temporal_Structure_in_Classical_Conditioning.html">123 nips-2001-Modeling Temporal Structure in Classical Conditioning</a></p>
<p>3 0.14995852 <a title="126-tfidf-3" href="./nips-2001-Reinforcement_Learning_and_Time_Perception_--_a_Model_of_Animal_Experiments.html">160 nips-2001-Reinforcement Learning and Time Perception -- a Model of Animal Experiments</a></p>
<p>4 0.12422854 <a title="126-tfidf-4" href="./nips-2001-The_Steering_Approach_for_Multi-Criteria_Reinforcement_Learning.html">187 nips-2001-The Steering Approach for Multi-Criteria Reinforcement Learning</a></p>
<p>5 0.11456966 <a title="126-tfidf-5" href="./nips-2001-ACh%2C_Uncertainty%2C_and_Cortical_Inference.html">3 nips-2001-ACh, Uncertainty, and Cortical Inference</a></p>
<p>6 0.10384913 <a title="126-tfidf-6" href="./nips-2001-Reinforcement_Learning_with_Long_Short-Term_Memory.html">161 nips-2001-Reinforcement Learning with Long Short-Term Memory</a></p>
<p>7 0.093371131 <a title="126-tfidf-7" href="./nips-2001-Cobot%3A_A_Social_Reinforcement_Learning_Agent.html">51 nips-2001-Cobot: A Social Reinforcement Learning Agent</a></p>
<p>8 0.091274589 <a title="126-tfidf-8" href="./nips-2001-Stabilizing_Value_Function_Approximation_with_the_BFBP_Algorithm.html">175 nips-2001-Stabilizing Value Function Approximation with the BFBP Algorithm</a></p>
<p>9 0.090988562 <a title="126-tfidf-9" href="./nips-2001-Rates_of_Convergence_of_Performance_Gradient_Estimates_Using_Function_Approximation_and_Bias_in_Reinforcement_Learning.html">157 nips-2001-Rates of Convergence of Performance Gradient Estimates Using Function Approximation and Bias in Reinforcement Learning</a></p>
<p>10 0.083379596 <a title="126-tfidf-10" href="./nips-2001-A_Natural_Policy_Gradient.html">13 nips-2001-A Natural Policy Gradient</a></p>
<p>11 0.083276689 <a title="126-tfidf-11" href="./nips-2001-The_Emergence_of_Multiple_Movement_Units_in_the_Presence_of_Noise_and_Feedback_Delay.html">181 nips-2001-The Emergence of Multiple Movement Units in the Presence of Noise and Feedback Delay</a></p>
<p>12 0.080329962 <a title="126-tfidf-12" href="./nips-2001-Batch_Value_Function_Approximation_via_Support_Vectors.html">40 nips-2001-Batch Value Function Approximation via Support Vectors</a></p>
<p>13 0.080227122 <a title="126-tfidf-13" href="./nips-2001-A_Rational_Analysis_of_Cognitive_Control_in_a_Speeded_Discrimination_Task.html">18 nips-2001-A Rational Analysis of Cognitive Control in a Speeded Discrimination Task</a></p>
<p>14 0.07363259 <a title="126-tfidf-14" href="./nips-2001-Characterizing_Neural_Gain_Control_using_Spike-triggered_Covariance.html">48 nips-2001-Characterizing Neural Gain Control using Spike-triggered Covariance</a></p>
<p>15 0.071924344 <a title="126-tfidf-15" href="./nips-2001-Multiagent_Planning_with_Factored_MDPs.html">128 nips-2001-Multiagent Planning with Factored MDPs</a></p>
<p>16 0.070332363 <a title="126-tfidf-16" href="./nips-2001-Effective_Size_of_Receptive_Fields_of_Inferior_Temporal_Visual_Cortex_Neurons_in_Natural_Scenes.html">65 nips-2001-Effective Size of Receptive Fields of Inferior Temporal Visual Cortex Neurons in Natural Scenes</a></p>
<p>17 0.065611638 <a title="126-tfidf-17" href="./nips-2001-Direct_value-approximation_for_factored_MDPs.html">59 nips-2001-Direct value-approximation for factored MDPs</a></p>
<p>18 0.065422155 <a title="126-tfidf-18" href="./nips-2001-Convergence_of_Optimistic_and_Incremental_Q-Learning.html">55 nips-2001-Convergence of Optimistic and Incremental Q-Learning</a></p>
<p>19 0.063557312 <a title="126-tfidf-19" href="./nips-2001-A_Model_of_the_Phonological_Loop%3A_Generalization_and_Binding.html">12 nips-2001-A Model of the Phonological Loop: Generalization and Binding</a></p>
<p>20 0.062313758 <a title="126-tfidf-20" href="./nips-2001-Spike_timing_and_the_coding_of_naturalistic_sounds_in_a_central_auditory_area_of_songbirds.html">174 nips-2001-Spike timing and the coding of naturalistic sounds in a central auditory area of songbirds</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2001_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.171), (1, -0.1), (2, 0.163), (3, -0.008), (4, 0.018), (5, -0.069), (6, -0.037), (7, -0.033), (8, -0.008), (9, -0.054), (10, 0.175), (11, -0.037), (12, 0.006), (13, 0.069), (14, 0.074), (15, 0.028), (16, 0.012), (17, 0.061), (18, 0.016), (19, 0.001), (20, -0.002), (21, -0.08), (22, -0.022), (23, 0.04), (24, -0.04), (25, 0.116), (26, 0.104), (27, 0.068), (28, -0.039), (29, -0.092), (30, 0.182), (31, -0.01), (32, -0.017), (33, 0.027), (34, -0.031), (35, 0.069), (36, -0.099), (37, -0.064), (38, 0.066), (39, 0.061), (40, 0.173), (41, -0.091), (42, -0.045), (43, -0.064), (44, -0.004), (45, -0.013), (46, -0.107), (47, 0.009), (48, 0.014), (49, 0.074)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93613708 <a title="126-lsi-1" href="./nips-2001-Motivated_Reinforcement_Learning.html">126 nips-2001-Motivated Reinforcement Learning</a></p>
<p>2 0.66205937 <a title="126-lsi-2" href="./nips-2001-Reinforcement_Learning_and_Time_Perception_--_a_Model_of_Animal_Experiments.html">160 nips-2001-Reinforcement Learning and Time Perception -- a Model of Animal Experiments</a></p>
<p>3 0.66153818 <a title="126-lsi-3" href="./nips-2001-Cobot%3A_A_Social_Reinforcement_Learning_Agent.html">51 nips-2001-Cobot: A Social Reinforcement Learning Agent</a></p>
<p>4 0.66073793 <a title="126-lsi-4" href="./nips-2001-Reinforcement_Learning_with_Long_Short-Term_Memory.html">161 nips-2001-Reinforcement Learning with Long Short-Term Memory</a></p>
<p>5 0.65276986 <a title="126-lsi-5" href="./nips-2001-Modeling_Temporal_Structure_in_Classical_Conditioning.html">123 nips-2001-Modeling Temporal Structure in Classical Conditioning</a></p>
<p>6 0.58623022 <a title="126-lsi-6" href="./nips-2001-A_Rational_Analysis_of_Cognitive_Control_in_a_Speeded_Discrimination_Task.html">18 nips-2001-A Rational Analysis of Cognitive Control in a Speeded Discrimination Task</a></p>
<p>7 0.53502786 <a title="126-lsi-7" href="./nips-2001-Improvisation_and_Learning.html">91 nips-2001-Improvisation and Learning</a></p>
<p>8 0.52371627 <a title="126-lsi-8" href="./nips-2001-ACh%2C_Uncertainty%2C_and_Cortical_Inference.html">3 nips-2001-ACh, Uncertainty, and Cortical Inference</a></p>
<p>9 0.4461506 <a title="126-lsi-9" href="./nips-2001-The_Emergence_of_Multiple_Movement_Units_in_the_Presence_of_Noise_and_Feedback_Delay.html">181 nips-2001-The Emergence of Multiple Movement Units in the Presence of Noise and Feedback Delay</a></p>
<p>10 0.44507778 <a title="126-lsi-10" href="./nips-2001-Stabilizing_Value_Function_Approximation_with_the_BFBP_Algorithm.html">175 nips-2001-Stabilizing Value Function Approximation with the BFBP Algorithm</a></p>
<p>11 0.44355467 <a title="126-lsi-11" href="./nips-2001-Rates_of_Convergence_of_Performance_Gradient_Estimates_Using_Function_Approximation_and_Bias_in_Reinforcement_Learning.html">157 nips-2001-Rates of Convergence of Performance Gradient Estimates Using Function Approximation and Bias in Reinforcement Learning</a></p>
<p>12 0.41917872 <a title="126-lsi-12" href="./nips-2001-Switch_Packet_Arbitration_via_Queue-Learning.html">177 nips-2001-Switch Packet Arbitration via Queue-Learning</a></p>
<p>13 0.41774654 <a title="126-lsi-13" href="./nips-2001-Perceptual_Metamers_in_Stereoscopic_Vision.html">145 nips-2001-Perceptual Metamers in Stereoscopic Vision</a></p>
<p>14 0.41531661 <a title="126-lsi-14" href="./nips-2001-Predictive_Representations_of_State.html">148 nips-2001-Predictive Representations of State</a></p>
<p>15 0.40885726 <a title="126-lsi-15" href="./nips-2001-Convergence_of_Optimistic_and_Incremental_Q-Learning.html">55 nips-2001-Convergence of Optimistic and Incremental Q-Learning</a></p>
<p>16 0.40533328 <a title="126-lsi-16" href="./nips-2001-The_Steering_Approach_for_Multi-Criteria_Reinforcement_Learning.html">187 nips-2001-The Steering Approach for Multi-Criteria Reinforcement Learning</a></p>
<p>17 0.37940893 <a title="126-lsi-17" href="./nips-2001-Spike_timing_and_the_coding_of_naturalistic_sounds_in_a_central_auditory_area_of_songbirds.html">174 nips-2001-Spike timing and the coding of naturalistic sounds in a central auditory area of songbirds</a></p>
<p>18 0.35377753 <a title="126-lsi-18" href="./nips-2001-Probabilistic_principles_in_unsupervised_learning_of_visual_structure%3A_human_data_and_a_model.html">151 nips-2001-Probabilistic principles in unsupervised learning of visual structure: human data and a model</a></p>
<p>19 0.35276136 <a title="126-lsi-19" href="./nips-2001-Learning_Body_Pose_via_Specialized_Maps.html">108 nips-2001-Learning Body Pose via Specialized Maps</a></p>
<p>20 0.34753662 <a title="126-lsi-20" href="./nips-2001-Characterizing_Neural_Gain_Control_using_Spike-triggered_Covariance.html">48 nips-2001-Characterizing Neural Gain Control using Spike-triggered Covariance</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2001_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.063), (16, 0.132), (31, 0.038), (36, 0.012), (50, 0.076), (60, 0.016), (63, 0.015), (65, 0.349), (77, 0.016), (79, 0.018), (81, 0.022), (91, 0.077), (92, 0.045), (93, 0.051)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.72977036 <a title="126-lda-1" href="./nips-2001-Motivated_Reinforcement_Learning.html">126 nips-2001-Motivated Reinforcement Learning</a></p>
<p>2 0.62920296 <a title="126-lda-2" href="./nips-2001-Geometrical_Singularities_in_the_Neuromanifold_of_Multilayer_Perceptrons.html">83 nips-2001-Geometrical Singularities in the Neuromanifold of Multilayer Perceptrons</a></p>
<p>3 0.56716013 <a title="126-lda-3" href="./nips-2001-Intransitive_Likelihood-Ratio_Classifiers.html">99 nips-2001-Intransitive Likelihood-Ratio Classifiers</a></p>
<p>4 0.56696439 <a title="126-lda-4" href="./nips-2001-Fragment_Completion_in_Humans_and_Machines.html">78 nips-2001-Fragment Completion in Humans and Machines</a></p>
<p>5 0.46959847 <a title="126-lda-5" href="./nips-2001-The_Emergence_of_Multiple_Movement_Units_in_the_Presence_of_Noise_and_Feedback_Delay.html">181 nips-2001-The Emergence of Multiple Movement Units in the Presence of Noise and Feedback Delay</a></p>
<p>6 0.46387833 <a title="126-lda-6" href="./nips-2001-Linking_Motor_Learning_to_Function_Approximation%3A_Learning_in_an_Unlearnable_Force_Field.html">116 nips-2001-Linking Motor Learning to Function Approximation: Learning in an Unlearnable Force Field</a></p>
<p>7 0.45920554 <a title="126-lda-7" href="./nips-2001-ACh%2C_Uncertainty%2C_and_Cortical_Inference.html">3 nips-2001-ACh, Uncertainty, and Cortical Inference</a></p>
<p>8 0.45161918 <a title="126-lda-8" href="./nips-2001-Reinforcement_Learning_with_Long_Short-Term_Memory.html">161 nips-2001-Reinforcement Learning with Long Short-Term Memory</a></p>
<p>9 0.45094296 <a title="126-lda-9" href="./nips-2001-Risk_Sensitive_Particle_Filters.html">163 nips-2001-Risk Sensitive Particle Filters</a></p>
<p>10 0.4507854 <a title="126-lda-10" href="./nips-2001-Direct_value-approximation_for_factored_MDPs.html">59 nips-2001-Direct value-approximation for factored MDPs</a></p>
<p>11 0.45014217 <a title="126-lda-11" href="./nips-2001-Modeling_Temporal_Structure_in_Classical_Conditioning.html">123 nips-2001-Modeling Temporal Structure in Classical Conditioning</a></p>
<p>12 0.44867572 <a title="126-lda-12" href="./nips-2001-Convergence_of_Optimistic_and_Incremental_Q-Learning.html">55 nips-2001-Convergence of Optimistic and Incremental Q-Learning</a></p>
<p>13 0.44739786 <a title="126-lda-13" href="./nips-2001-Rates_of_Convergence_of_Performance_Gradient_Estimates_Using_Function_Approximation_and_Bias_in_Reinforcement_Learning.html">157 nips-2001-Rates of Convergence of Performance Gradient Estimates Using Function Approximation and Bias in Reinforcement Learning</a></p>
<p>14 0.44651914 <a title="126-lda-14" href="./nips-2001-Exact_differential_equation_population_dynamics_for_integrate-and-fire_neurons.html">72 nips-2001-Exact differential equation population dynamics for integrate-and-fire neurons</a></p>
<p>15 0.44569755 <a title="126-lda-15" href="./nips-2001-Multiagent_Planning_with_Factored_MDPs.html">128 nips-2001-Multiagent Planning with Factored MDPs</a></p>
<p>16 0.44464126 <a title="126-lda-16" href="./nips-2001-Efficient_Resources_Allocation_for_Markov_Decision_Processes.html">67 nips-2001-Efficient Resources Allocation for Markov Decision Processes</a></p>
<p>17 0.44413525 <a title="126-lda-17" href="./nips-2001-Generating_velocity_tuning_by_asymmetric_recurrent_connections.html">82 nips-2001-Generating velocity tuning by asymmetric recurrent connections</a></p>
<p>18 0.44394881 <a title="126-lda-18" href="./nips-2001-Probabilistic_Inference_of_Hand_Motion_from_Neural_Activity_in_Motor_Cortex.html">150 nips-2001-Probabilistic Inference of Hand Motion from Neural Activity in Motor Cortex</a></p>
<p>19 0.44374558 <a title="126-lda-19" href="./nips-2001-Cobot%3A_A_Social_Reinforcement_Learning_Agent.html">51 nips-2001-Cobot: A Social Reinforcement Learning Agent</a></p>
<p>20 0.4434284 <a title="126-lda-20" href="./nips-2001-Contextual_Modulation_of_Target_Saliency.html">54 nips-2001-Contextual Modulation of Target Saliency</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
