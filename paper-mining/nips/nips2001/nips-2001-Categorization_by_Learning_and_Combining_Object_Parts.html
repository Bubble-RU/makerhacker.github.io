<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>46 nips-2001-Categorization by Learning and Combining Object Parts</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2001" href="../home/nips2001_home.html">nips2001</a> <a title="nips-2001-46" href="#">nips2001-46</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>46 nips-2001-Categorization by Learning and Combining Object Parts</h1>
<br/><p>Source: <a title="nips-2001-46-pdf" href="http://papers.nips.cc/paper/2109-categorization-by-learning-and-combining-object-parts.pdf">pdf</a></p><p>Author: Bernd Heisele, Thomas Serre, Massimiliano Pontil, Thomas Vetter, Tomaso Poggio</p><p>Abstract: We describe an algorithm for automatically learning discriminative components of objects with SVM classiﬁers. It is based on growing image parts by minimizing theoretical bounds on the error probability of an SVM. Component-based face classiﬁers are then combined in a second stage to yield a hierarchical SVM classiﬁer. Experimental results in face classiﬁcation show considerable robustness against rotations in depth and suggest performance at signiﬁcantly better level than other face detection systems. Novel aspects of our approach are: a) an algorithm to learn component-based classiﬁcation experts and their combination, b) the use of 3-D morphable models for training, and c) a maximum operation on the output of each component classiﬁer which may be relevant for biological models of visual recognition.</p><p>Reference: <a title="nips-2001-46-reference" href="../nips2001_reference/nips-2001-Categorization_by_Learning_and_Combining_Object_Parts_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('fac', 0.476), ('svm', 0.332), ('detect', 0.229), ('expert', 0.198), ('mou', 0.198), ('compon', 0.192), ('heisel', 0.158), ('nos', 0.158), ('object', 0.157), ('pixel', 0.151), ('class', 0.147), ('head', 0.12), ('morph', 0.119), ('cmu', 0.117), ('gray', 0.111), ('rectangul', 0.108), ('pos', 0.106), ('train', 0.104), ('im', 0.104), ('biolog', 0.098)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="46-tfidf-1" href="./nips-2001-Categorization_by_Learning_and_Combining_Object_Parts.html">46 nips-2001-Categorization by Learning and Combining Object Parts</a></p>
<p>Author: Bernd Heisele, Thomas Serre, Massimiliano Pontil, Thomas Vetter, Tomaso Poggio</p><p>Abstract: We describe an algorithm for automatically learning discriminative components of objects with SVM classiﬁers. It is based on growing image parts by minimizing theoretical bounds on the error probability of an SVM. Component-based face classiﬁers are then combined in a second stage to yield a hierarchical SVM classiﬁer. Experimental results in face classiﬁcation show considerable robustness against rotations in depth and suggest performance at signiﬁcantly better level than other face detection systems. Novel aspects of our approach are: a) an algorithm to learn component-based classiﬁcation experts and their combination, b) the use of 3-D morphable models for training, and c) a maximum operation on the output of each component classiﬁer which may be relevant for biological models of visual recognition.</p><p>2 0.28943184 <a title="46-tfidf-2" href="./nips-2001-Fast_and_Robust_Classification_using_Asymmetric_AdaBoost_and_a_Detector_Cascade.html">77 nips-2001-Fast and Robust Classification using Asymmetric AdaBoost and a Detector Cascade</a></p>
<p>Author: Paul Viola, Michael Jones</p><p>Abstract: This paper develops a new approach for extremely fast detection in domains where the distribution of positive and negative examples is highly skewed (e.g. face detection or database retrieval). In such domains a cascade of simple classiﬁers each trained to achieve high detection rates and modest false positive rates can yield a ﬁnal detector with many desirable features: including high detection rates, very low false positive rates, and fast performance. Achieving extremely high detection rates, rather than low error, is not a task typically addressed by machine learning algorithms. We propose a new variant of AdaBoost as a mechanism for training the simple classiﬁers used in the cascade. Experimental results in the domain of face detection show the training algorithm yields signiﬁcant improvements in performance over conventional AdaBoost. The ﬁnal face detection system can process 15 frames per second, achieves over 90% detection, and a false positive rate of 1 in a 1,000,000.</p><p>3 0.28361565 <a title="46-tfidf-3" href="./nips-2001-Face_Recognition_Using_Kernel_Methods.html">74 nips-2001-Face Recognition Using Kernel Methods</a></p>
<p>Author: Ming-Hsuan Yang</p><p>Abstract: Principal Component Analysis and Fisher Linear Discriminant methods have demonstrated their success in face detection, recognition, and tracking. The representation in these subspace methods is based on second order statistics of the image set, and does not address higher order statistical dependencies such as the relationships among three or more pixels. Recently Higher Order Statistics and Independent Component Analysis (ICA) have been used as informative low dimensional representations for visual recognition. In this paper, we investigate the use of Kernel Principal Component Analysis and Kernel Fisher Linear Discriminant for learning low dimensional representations for face recognition, which we call Kernel Eigenface and Kernel Fisherface methods. While Eigenface and Fisherface methods aim to find projection directions based on the second order correlation of samples, Kernel Eigenface and Kernel Fisherface methods provide generalizations which take higher order correlations into account. We compare the performance of kernel methods with Eigenface, Fisherface and ICA-based methods for face recognition with variation in pose, scale, lighting and expression. Experimental results show that kernel methods provide better representations and achieve lower error rates for face recognition. 1 Motivation and Approach Subspace methods have been applied successfully in numerous visual recognition tasks such as face localization, face recognition, 3D object recognition, and tracking. In particular, Principal Component Analysis (PCA) [20] [13] ,and Fisher Linear Discriminant (FLD) methods [6] have been applied to face recognition with impressive results. While PCA aims to extract a subspace in which the variance is maximized (or the reconstruction error is minimized), some unwanted variations (due to lighting, facial expressions, viewing points, etc.) may be retained (See [8] for examples). It has been observed that in face recognition the variations between the images of the same face due to illumination and viewing direction are almost always larger than image variations due to the changes in face identity [1]. Therefore, while the PCA projections are optimal in a correlation sense (or for reconstruction</p><p>4 0.24969134 <a title="46-tfidf-4" href="./nips-2001-A_Parallel_Mixture_of_SVMs_for_Very_Large_Scale_Problems.html">16 nips-2001-A Parallel Mixture of SVMs for Very Large Scale Problems</a></p>
<p>Author: Ronan Collobert, Samy Bengio, Yoshua Bengio</p><p>Abstract: Support Vector Machines (SVMs) are currently the state-of-the-art models for many classification problems but they suffer from the complexity of their training algorithm which is at least quadratic with respect to the number of examples. Hence, it is hopeless to try to solve real-life problems having more than a few hundreds of thousands examples with SVMs. The present paper proposes a new mixture of SVMs that can be easily implemented in parallel and where each SVM is trained on a small subset of the whole dataset. Experiments on a large benchmark dataset (Forest) as well as a difficult speech database , yielded significant time improvement (time complexity appears empirically to locally grow linearly with the number of examples) . In addition, and that is a surprise, a significant improvement in generalization was observed on Forest. 1</p><p>5 0.21702318 <a title="46-tfidf-5" href="./nips-2001-Contextual_Modulation_of_Target_Saliency.html">54 nips-2001-Contextual Modulation of Target Saliency</a></p>
<p>Author: Antonio Torralba</p><p>Abstract: The most popular algorithms for object detection require the use of exhaustive spatial and scale search procedures. In such approaches, an object is defined by means of local features. fu this paper we show that including contextual information in object detection procedures provides an efficient way of cutting down the need for exhaustive search. We present results with real images showing that the proposed scheme is able to accurately predict likely object classes, locations and sizes. 1</p><p>6 0.19972771 <a title="46-tfidf-6" href="./nips-2001-Dynamic_Time-Alignment_Kernel_in_Support_Vector_Machine.html">63 nips-2001-Dynamic Time-Alignment Kernel in Support Vector Machine</a></p>
<p>7 0.18506747 <a title="46-tfidf-7" href="./nips-2001-Global_Coordination_of_Local_Linear_Models.html">84 nips-2001-Global Coordination of Local Linear Models</a></p>
<p>8 0.16891396 <a title="46-tfidf-8" href="./nips-2001-Transform-invariant_Image_Decomposition_with_Similarity_Templates.html">191 nips-2001-Transform-invariant Image Decomposition with Similarity Templates</a></p>
<p>9 0.14699404 <a title="46-tfidf-9" href="./nips-2001-Speech_Recognition_using_SVMs.html">172 nips-2001-Speech Recognition using SVMs</a></p>
<p>10 0.14268121 <a title="46-tfidf-10" href="./nips-2001-Effective_Size_of_Receptive_Fields_of_Inferior_Temporal_Visual_Cortex_Neurons_in_Natural_Scenes.html">65 nips-2001-Effective Size of Receptive Fields of Inferior Temporal Visual Cortex Neurons in Natural Scenes</a></p>
<p>11 0.13465568 <a title="46-tfidf-11" href="./nips-2001-Infinite_Mixtures_of_Gaussian_Process_Experts.html">95 nips-2001-Infinite Mixtures of Gaussian Process Experts</a></p>
<p>12 0.1320173 <a title="46-tfidf-12" href="./nips-2001-Asymptotic_Universality_for_Learning_Curves_of_Support_Vector_Machines.html">38 nips-2001-Asymptotic Universality for Learning Curves of Support Vector Machines</a></p>
<p>13 0.12873183 <a title="46-tfidf-13" href="./nips-2001-The_Fidelity_of_Local_Ordinal_Encoding.html">182 nips-2001-The Fidelity of Local Ordinal Encoding</a></p>
<p>14 0.12843868 <a title="46-tfidf-14" href="./nips-2001-Adaptive_Nearest_Neighbor_Classification_Using_Support_Vector_Machines.html">28 nips-2001-Adaptive Nearest Neighbor Classification Using Support Vector Machines</a></p>
<p>15 0.12804817 <a title="46-tfidf-15" href="./nips-2001-Incorporating_Invariances_in_Non-Linear_Support_Vector_Machines.html">92 nips-2001-Incorporating Invariances in Non-Linear Support Vector Machines</a></p>
<p>16 0.12299114 <a title="46-tfidf-16" href="./nips-2001-Active_Learning_in_the_Drug_Discovery_Process.html">25 nips-2001-Active Learning in the Drug Discovery Process</a></p>
<p>17 0.12205985 <a title="46-tfidf-17" href="./nips-2001-Grouping_with_Bias.html">89 nips-2001-Grouping with Bias</a></p>
<p>18 0.11732771 <a title="46-tfidf-18" href="./nips-2001-Unsupervised_Learning_of_Human_Motion_Models.html">193 nips-2001-Unsupervised Learning of Human Motion Models</a></p>
<p>19 0.11519137 <a title="46-tfidf-19" href="./nips-2001-Product_Analysis%3A_Learning_to_Model_Observations_as_Products_of_Hidden_Variables.html">153 nips-2001-Product Analysis: Learning to Model Observations as Products of Hidden Variables</a></p>
<p>20 0.11474849 <a title="46-tfidf-20" href="./nips-2001-Adaptive_Sparseness_Using_Jeffreys_Prior.html">29 nips-2001-Adaptive Sparseness Using Jeffreys Prior</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2001_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.298), (1, 0.057), (2, -0.123), (3, -0.188), (4, -0.003), (5, -0.143), (6, -0.189), (7, -0.162), (8, 0.289), (9, 0.063), (10, -0.177), (11, -0.058), (12, 0.067), (13, 0.101), (14, -0.149), (15, 0.072), (16, 0.035), (17, 0.141), (18, 0.012), (19, 0.137), (20, 0.123), (21, 0.029), (22, -0.175), (23, 0.117), (24, -0.018), (25, -0.002), (26, 0.135), (27, -0.031), (28, 0.104), (29, -0.078), (30, 0.016), (31, 0.174), (32, -0.029), (33, 0.062), (34, -0.046), (35, -0.023), (36, 0.082), (37, -0.061), (38, -0.064), (39, 0.076), (40, 0.058), (41, 0.011), (42, 0.027), (43, 0.006), (44, 0.03), (45, 0.06), (46, 0.052), (47, 0.006), (48, -0.052), (49, 0.105)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95112401 <a title="46-lsi-1" href="./nips-2001-Categorization_by_Learning_and_Combining_Object_Parts.html">46 nips-2001-Categorization by Learning and Combining Object Parts</a></p>
<p>Author: Bernd Heisele, Thomas Serre, Massimiliano Pontil, Thomas Vetter, Tomaso Poggio</p><p>Abstract: We describe an algorithm for automatically learning discriminative components of objects with SVM classiﬁers. It is based on growing image parts by minimizing theoretical bounds on the error probability of an SVM. Component-based face classiﬁers are then combined in a second stage to yield a hierarchical SVM classiﬁer. Experimental results in face classiﬁcation show considerable robustness against rotations in depth and suggest performance at signiﬁcantly better level than other face detection systems. Novel aspects of our approach are: a) an algorithm to learn component-based classiﬁcation experts and their combination, b) the use of 3-D morphable models for training, and c) a maximum operation on the output of each component classiﬁer which may be relevant for biological models of visual recognition.</p><p>2 0.68038028 <a title="46-lsi-2" href="./nips-2001-Fast_and_Robust_Classification_using_Asymmetric_AdaBoost_and_a_Detector_Cascade.html">77 nips-2001-Fast and Robust Classification using Asymmetric AdaBoost and a Detector Cascade</a></p>
<p>Author: Paul Viola, Michael Jones</p><p>Abstract: This paper develops a new approach for extremely fast detection in domains where the distribution of positive and negative examples is highly skewed (e.g. face detection or database retrieval). In such domains a cascade of simple classiﬁers each trained to achieve high detection rates and modest false positive rates can yield a ﬁnal detector with many desirable features: including high detection rates, very low false positive rates, and fast performance. Achieving extremely high detection rates, rather than low error, is not a task typically addressed by machine learning algorithms. We propose a new variant of AdaBoost as a mechanism for training the simple classiﬁers used in the cascade. Experimental results in the domain of face detection show the training algorithm yields signiﬁcant improvements in performance over conventional AdaBoost. The ﬁnal face detection system can process 15 frames per second, achieves over 90% detection, and a false positive rate of 1 in a 1,000,000.</p><p>3 0.60493243 <a title="46-lsi-3" href="./nips-2001-The_Fidelity_of_Local_Ordinal_Encoding.html">182 nips-2001-The Fidelity of Local Ordinal Encoding</a></p>
<p>Author: Javid Sadr, Sayan Mukherjee, Keith Thoresz, Pawan Sinha</p><p>Abstract: A key question in neuroscience is how to encode sensory stimuli such as images and sounds. Motivated by studies of response properties of neurons in the early cortical areas, we propose an encoding scheme that dispenses with absolute measures of signal intensity or contrast and uses, instead, only local ordinal measures. In this scheme, the structure of a signal is represented by a set of equalities and inequalities across adjacent regions. In this paper, we focus on characterizing the ﬁdelity of this representation strategy. We develop a regularization approach for image reconstruction from ordinal measures and thereby demonstrate that the ordinal representation scheme can faithfully encode signal structure. We also present a neurally plausible implementation of this computation that uses only local update rules. The results highlight the robustness and generalization ability of local ordinal encodings for the task of pattern classiﬁcation. 1</p><p>4 0.6006856 <a title="46-lsi-4" href="./nips-2001-Contextual_Modulation_of_Target_Saliency.html">54 nips-2001-Contextual Modulation of Target Saliency</a></p>
<p>Author: Antonio Torralba</p><p>Abstract: The most popular algorithms for object detection require the use of exhaustive spatial and scale search procedures. In such approaches, an object is defined by means of local features. fu this paper we show that including contextual information in object detection procedures provides an efficient way of cutting down the need for exhaustive search. We present results with real images showing that the proposed scheme is able to accurately predict likely object classes, locations and sizes. 1</p><p>5 0.5568555 <a title="46-lsi-5" href="./nips-2001-Face_Recognition_Using_Kernel_Methods.html">74 nips-2001-Face Recognition Using Kernel Methods</a></p>
<p>Author: Ming-Hsuan Yang</p><p>Abstract: Principal Component Analysis and Fisher Linear Discriminant methods have demonstrated their success in face detection, recognition, and tracking. The representation in these subspace methods is based on second order statistics of the image set, and does not address higher order statistical dependencies such as the relationships among three or more pixels. Recently Higher Order Statistics and Independent Component Analysis (ICA) have been used as informative low dimensional representations for visual recognition. In this paper, we investigate the use of Kernel Principal Component Analysis and Kernel Fisher Linear Discriminant for learning low dimensional representations for face recognition, which we call Kernel Eigenface and Kernel Fisherface methods. While Eigenface and Fisherface methods aim to find projection directions based on the second order correlation of samples, Kernel Eigenface and Kernel Fisherface methods provide generalizations which take higher order correlations into account. We compare the performance of kernel methods with Eigenface, Fisherface and ICA-based methods for face recognition with variation in pose, scale, lighting and expression. Experimental results show that kernel methods provide better representations and achieve lower error rates for face recognition. 1 Motivation and Approach Subspace methods have been applied successfully in numerous visual recognition tasks such as face localization, face recognition, 3D object recognition, and tracking. In particular, Principal Component Analysis (PCA) [20] [13] ,and Fisher Linear Discriminant (FLD) methods [6] have been applied to face recognition with impressive results. While PCA aims to extract a subspace in which the variance is maximized (or the reconstruction error is minimized), some unwanted variations (due to lighting, facial expressions, viewing points, etc.) may be retained (See [8] for examples). It has been observed that in face recognition the variations between the images of the same face due to illumination and viewing direction are almost always larger than image variations due to the changes in face identity [1]. Therefore, while the PCA projections are optimal in a correlation sense (or for reconstruction</p><p>6 0.54366875 <a title="46-lsi-6" href="./nips-2001-Transform-invariant_Image_Decomposition_with_Similarity_Templates.html">191 nips-2001-Transform-invariant Image Decomposition with Similarity Templates</a></p>
<p>7 0.52093941 <a title="46-lsi-7" href="./nips-2001-A_Parallel_Mixture_of_SVMs_for_Very_Large_Scale_Problems.html">16 nips-2001-A Parallel Mixture of SVMs for Very Large Scale Problems</a></p>
<p>8 0.48352483 <a title="46-lsi-8" href="./nips-2001-Receptive_field_structure_of_flow_detectors_for_heading_perception.html">158 nips-2001-Receptive field structure of flow detectors for heading perception</a></p>
<p>9 0.47115782 <a title="46-lsi-9" href="./nips-2001-Dynamic_Time-Alignment_Kernel_in_Support_Vector_Machine.html">63 nips-2001-Dynamic Time-Alignment Kernel in Support Vector Machine</a></p>
<p>10 0.45271716 <a title="46-lsi-10" href="./nips-2001-Effective_Size_of_Receptive_Fields_of_Inferior_Temporal_Visual_Cortex_Neurons_in_Natural_Scenes.html">65 nips-2001-Effective Size of Receptive Fields of Inferior Temporal Visual Cortex Neurons in Natural Scenes</a></p>
<p>11 0.43627298 <a title="46-lsi-11" href="./nips-2001-Incorporating_Invariances_in_Non-Linear_Support_Vector_Machines.html">92 nips-2001-Incorporating Invariances in Non-Linear Support Vector Machines</a></p>
<p>12 0.43601605 <a title="46-lsi-12" href="./nips-2001-Speech_Recognition_using_SVMs.html">172 nips-2001-Speech Recognition using SVMs</a></p>
<p>13 0.4227351 <a title="46-lsi-13" href="./nips-2001-Active_Learning_in_the_Drug_Discovery_Process.html">25 nips-2001-Active Learning in the Drug Discovery Process</a></p>
<p>14 0.42194605 <a title="46-lsi-14" href="./nips-2001-Kernel_Logistic_Regression_and_the_Import_Vector_Machine.html">104 nips-2001-Kernel Logistic Regression and the Import Vector Machine</a></p>
<p>15 0.41702563 <a title="46-lsi-15" href="./nips-2001-A_Sequence_Kernel_and_its_Application_to_Speaker_Recognition.html">20 nips-2001-A Sequence Kernel and its Application to Speaker Recognition</a></p>
<p>16 0.41121334 <a title="46-lsi-16" href="./nips-2001-Global_Coordination_of_Local_Linear_Models.html">84 nips-2001-Global Coordination of Local Linear Models</a></p>
<p>17 0.40723154 <a title="46-lsi-17" href="./nips-2001-Product_Analysis%3A_Learning_to_Model_Observations_as_Products_of_Hidden_Variables.html">153 nips-2001-Product Analysis: Learning to Model Observations as Products of Hidden Variables</a></p>
<p>18 0.40222666 <a title="46-lsi-18" href="./nips-2001-Adaptive_Nearest_Neighbor_Classification_Using_Support_Vector_Machines.html">28 nips-2001-Adaptive Nearest Neighbor Classification Using Support Vector Machines</a></p>
<p>19 0.39829379 <a title="46-lsi-19" href="./nips-2001-Classifying_Single_Trial_EEG%3A_Towards_Brain_Computer_Interfacing.html">50 nips-2001-Classifying Single Trial EEG: Towards Brain Computer Interfacing</a></p>
<p>20 0.39708951 <a title="46-lsi-20" href="./nips-2001-K-Local_Hyperplane_and_Convex_Distance_Nearest_Neighbor_Algorithms.html">101 nips-2001-K-Local Hyperplane and Convex Distance Nearest Neighbor Algorithms</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2001_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.029), (16, 0.235), (31, 0.072), (50, 0.074), (63, 0.023), (77, 0.041), (79, 0.02), (87, 0.262), (91, 0.058), (92, 0.075)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.90173715 <a title="46-lda-1" href="./nips-2001-Analog_Soft-Pattern-Matching_Classifier_using_Floating-Gate_MOS_Technology.html">34 nips-2001-Analog Soft-Pattern-Matching Classifier using Floating-Gate MOS Technology</a></p>
<p>Author: Toshihiko Yamasaki, Tadashi Shibata</p><p>Abstract: A flexible pattern-matching analog classifier is presented in conjunction with a robust image representation algorithm called Principal Axes Projection (PAP). In the circuit, the functional form of matching is configurable in terms of the peak position, the peak height and the sharpness of the similarity evaluation. The test chip was fabricated in a 0.6-µm CMOS technology and successfully applied to hand-written pattern recognition and medical radiograph analysis using PAP as a feature extraction pre-processing step for robust image coding. The separation and classification of overlapping patterns is also experimentally demonstrated. 1 I ntr o du c ti o n Pattern classification using template matching techniques is a powerful tool in implementing human-like intelligent systems. However, the processing is computationally very expensive, consuming a lot of CPU time when implemented as software running on general-purpose computers. Therefore, software approaches are not practical for real-time applications. For systems working in mobile environment, in particular, they are not realistic because the memory and computational resources are severely limited. The development of analog VLSI chips having a fully parallel template matching architecture [1,2] would be a promising solution in such applications because they offer an opportunity of low-power operation as well as very compact implementation. In order to build a real human-like intelligent system, however, not only the pattern representation algorithm but also the matching hardware itself needs to be made flexible and robust in carrying out the pattern matching task. First of all, two-dimensional patterns need to be represented by feature vectors having substantially reduced dimensions, while at the same time preserving the human perception of similarity among patterns in the vector space mapping. For this purpose, an image representation algorithm called Principal Axes Projection (PAP) has been de- veloped [3] and its robust nature in pattern recognition has been demonstrated in the applications to medical radiograph analysis [3] and hand-written digits recognition [4]. However, the demonstration so far was only carried out by computer simulation. Regarding the matching hardware, high-flexibility analog template matching circuits have been developed for PAP vector representation. The circuits are flexible in a sense that the matching criteria (the weight to elements, the strictness in matching) are configurable. In Ref. [5], the fundamental characteristics of the building block circuits were presented, and their application to simple hand-written digits was presented in Ref. [6]. The purpose of this paper is to demonstrate the robust nature of the hardware matching system by experiments. The classification of simple hand-written patterns and the cephalometric landmark identification in gray-scale medical radiographs have been carried out and successful results are presented. In addition, multiple overlapping patterns can be separated without utilizing a priori knowledge, which is one of the most difficult problems at present in artificial intelligence. 2 I ma g e re pr es e n tati on by P AP PAP is a feature extraction technique using the edge information. The input image (64x64 pixels) is first subjected to pixel-by-pixel spatial filtering operations to detect edges in four directions: horizontal (HR); vertical (VR); +45 degrees (+45); and –45 degrees (-45). Each detected edge is represented by a binary flag and four edge maps are generated. The two-dimensional bit array in an edge map is reduced to a one-dimensional array of numerals by projection. The horizontal edge flags are accumulated in the horizontal direction and projected onto vertical axis. The vertical, +45-degree and –45-degree edge flags are similarly projected onto horizontal, -45-degree and +45-degree axes, respectively. Therefore the method is called “Principal Axes Projection (PAP)” [3,4]. Then each projection data set is series connected in the order of HR, +45, VR, -45 to form a feature vector. Neighboring four elements are averaged and merged to one element and a 64-dimensional vector is finally obtained. This vector representation very well preserves the human perception of similarity in the vector space. In the experiments below, we have further reduced the feature vector to 16 dimensions by merging each set of four neighboring elements into one, without any significant degradation in performance. C i r cui t c o nf i g ura ti ons A B C VGG A B C VGG IOUT IOUT 1 1 2 2 4 4 1 VIN 13 VIN RST RST £ ¡ ¤¢  £ ¥ §¦  3 Figure 1: Schematic of vector element matching circuit: (a) pyramid (gain reduction) type; (b) plateau (feedback) type. The capacitor area ratio is indicated in the figure. The basic functional form of the similarity evaluation is generated by the shortcut current flowing in a CMOS inverter as in Refs. [7,8,9]. However, their circuits were utilized to form radial basis functions and only the peak position was programmable. In our circuits, not only the peak position but also the peak height and the sharpness of the peak response shape are made configurable to realize flexible matching operations [5]. Two types of the element matching circuit are shown in Fig. 1. They evaluate the similarity between two vector elements. The result of the evaluation is given as an output current (IOUT ) from the pMOS current mirror. The peak position is temporarily memorized by auto-zeroing of the CMOS inverter. The common-gate transistor with VGG stabilizes the voltage supply to the inverter. By controlling the gate bias VGG, the peak height can be changed. This corresponds to multiplying a weight factor to the element. The sharpness of the functional form is taken as the strictness of the similarity evaluation. In the pyramid type circuit (Fig. 1(a)), the sharpness is controlled by the gain reduction in the input. In the plateau type (Fig. 1(b)), the output voltage of the inverter is fed back to input nodes and the sharpness changes in accordance with the amount of the feedback.    ¥£¡ ¦¤¢   £¨ 9&% ¦©§ (!! #$ 5 !' #$ &% 9 9 4 92 !¦ A1@9  ¨¥  5 4 52 (!  5 8765  9) 0 1 ¥ 1 ¨</p><p>same-paper 2 0.79773748 <a title="46-lda-2" href="./nips-2001-Categorization_by_Learning_and_Combining_Object_Parts.html">46 nips-2001-Categorization by Learning and Combining Object Parts</a></p>
<p>Author: Bernd Heisele, Thomas Serre, Massimiliano Pontil, Thomas Vetter, Tomaso Poggio</p><p>Abstract: We describe an algorithm for automatically learning discriminative components of objects with SVM classiﬁers. It is based on growing image parts by minimizing theoretical bounds on the error probability of an SVM. Component-based face classiﬁers are then combined in a second stage to yield a hierarchical SVM classiﬁer. Experimental results in face classiﬁcation show considerable robustness against rotations in depth and suggest performance at signiﬁcantly better level than other face detection systems. Novel aspects of our approach are: a) an algorithm to learn component-based classiﬁcation experts and their combination, b) the use of 3-D morphable models for training, and c) a maximum operation on the output of each component classiﬁer which may be relevant for biological models of visual recognition.</p><p>3 0.71962261 <a title="46-lda-3" href="./nips-2001-Bayesian_time_series_classification.html">43 nips-2001-Bayesian time series classification</a></p>
<p>Author: Peter Sykacek, Stephen J. Roberts</p><p>Abstract: This paper proposes an approach to classiﬁcation of adjacent segments of a time series as being either of classes. We use a hierarchical model that consists of a feature extraction stage and a generative classiﬁer which is built on top of these features. Such two stage approaches are often used in signal and image processing. The novel part of our work is that we link these stages probabilistically by using a latent feature space. To use one joint model is a Bayesian requirement, which has the advantage to fuse information according to its certainty. The classiﬁer is implemented as hidden Markov model with Gaussian and Multinomial observation distributions deﬁned on a suitably chosen representation of autoregressive models. The Markov dependency is motivated by the assumption that successive classiﬁcations will be correlated. Inference is done with Markov chain Monte Carlo (MCMC) techniques. We apply the proposed approach to synthetic data and to classiﬁcation of EEG that was recorded while the subjects performed different cognitive tasks. All experiments show that using a latent feature space results in a signiﬁcant improvement in generalization accuracy. Hence we expect that this idea generalizes well to other hierarchical models.</p><p>4 0.7188623 <a title="46-lda-4" href="./nips-2001-Contextual_Modulation_of_Target_Saliency.html">54 nips-2001-Contextual Modulation of Target Saliency</a></p>
<p>Author: Antonio Torralba</p><p>Abstract: The most popular algorithms for object detection require the use of exhaustive spatial and scale search procedures. In such approaches, an object is defined by means of local features. fu this paper we show that including contextual information in object detection procedures provides an efficient way of cutting down the need for exhaustive search. We present results with real images showing that the proposed scheme is able to accurately predict likely object classes, locations and sizes. 1</p><p>5 0.71814668 <a title="46-lda-5" href="./nips-2001-Grouping_with_Bias.html">89 nips-2001-Grouping with Bias</a></p>
<p>Author: Stella X. Yu, Jianbo Shi</p><p>Abstract: With the optimization of pattern discrimination as a goal, graph partitioning approaches often lack the capability to integrate prior knowledge to guide grouping. In this paper, we consider priors from unitary generative models, partially labeled data and spatial attention. These priors are modelled as constraints in the solution space. By imposing uniformity condition on the constraints, we restrict the feasible space to one of smooth solutions. A subspace projection method is developed to solve this constrained eigenproblema We demonstrate that simple priors can greatly improve image segmentation results. 1</p><p>6 0.71521479 <a title="46-lda-6" href="./nips-2001-Modeling_Temporal_Structure_in_Classical_Conditioning.html">123 nips-2001-Modeling Temporal Structure in Classical Conditioning</a></p>
<p>7 0.71197426 <a title="46-lda-7" href="./nips-2001-A_Natural_Policy_Gradient.html">13 nips-2001-A Natural Policy Gradient</a></p>
<p>8 0.71139443 <a title="46-lda-8" href="./nips-2001-Global_Coordination_of_Local_Linear_Models.html">84 nips-2001-Global Coordination of Local Linear Models</a></p>
<p>9 0.7112512 <a title="46-lda-9" href="./nips-2001-The_Infinite_Hidden_Markov_Model.html">183 nips-2001-The Infinite Hidden Markov Model</a></p>
<p>10 0.70973164 <a title="46-lda-10" href="./nips-2001-Partially_labeled_classification_with_Markov_random_walks.html">144 nips-2001-Partially labeled classification with Markov random walks</a></p>
<p>11 0.70948982 <a title="46-lda-11" href="./nips-2001-Learning_Lateral_Interactions_for_Feature_Binding_and_Sensory_Segmentation.html">111 nips-2001-Learning Lateral Interactions for Feature Binding and Sensory Segmentation</a></p>
<p>12 0.70858437 <a title="46-lda-12" href="./nips-2001-Dynamic_Time-Alignment_Kernel_in_Support_Vector_Machine.html">63 nips-2001-Dynamic Time-Alignment Kernel in Support Vector Machine</a></p>
<p>13 0.70855725 <a title="46-lda-13" href="./nips-2001-Audio-Visual_Sound_Separation_Via_Hidden_Markov_Models.html">39 nips-2001-Audio-Visual Sound Separation Via Hidden Markov Models</a></p>
<p>14 0.70810342 <a title="46-lda-14" href="./nips-2001-Probabilistic_Inference_of_Hand_Motion_from_Neural_Activity_in_Motor_Cortex.html">150 nips-2001-Probabilistic Inference of Hand Motion from Neural Activity in Motor Cortex</a></p>
<p>15 0.70785934 <a title="46-lda-15" href="./nips-2001-Generating_velocity_tuning_by_asymmetric_recurrent_connections.html">82 nips-2001-Generating velocity tuning by asymmetric recurrent connections</a></p>
<p>16 0.70704019 <a title="46-lda-16" href="./nips-2001-Incorporating_Invariances_in_Non-Linear_Support_Vector_Machines.html">92 nips-2001-Incorporating Invariances in Non-Linear Support Vector Machines</a></p>
<p>17 0.70644534 <a title="46-lda-17" href="./nips-2001-Small-World_Phenomena_and_the_Dynamics_of_Information.html">169 nips-2001-Small-World Phenomena and the Dynamics of Information</a></p>
<p>18 0.7062912 <a title="46-lda-18" href="./nips-2001-Why_Neuronal_Dynamics_Should_Control_Synaptic_Learning_Rules.html">197 nips-2001-Why Neuronal Dynamics Should Control Synaptic Learning Rules</a></p>
<p>19 0.70586276 <a title="46-lda-19" href="./nips-2001-Exact_differential_equation_population_dynamics_for_integrate-and-fire_neurons.html">72 nips-2001-Exact differential equation population dynamics for integrate-and-fire neurons</a></p>
<p>20 0.70544696 <a title="46-lda-20" href="./nips-2001-On_Spectral_Clustering%3A_Analysis_and_an_algorithm.html">135 nips-2001-On Spectral Clustering: Analysis and an algorithm</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
