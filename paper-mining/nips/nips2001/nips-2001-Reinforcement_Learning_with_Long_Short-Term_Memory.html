<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>161 nips-2001-Reinforcement Learning with Long Short-Term Memory</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2001" href="../home/nips2001_home.html">nips2001</a> <a title="nips-2001-161" href="#">nips2001-161</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>161 nips-2001-Reinforcement Learning with Long Short-Term Memory</h1>
<br/><p>Source: <a title="nips-2001-161-pdf" href="http://papers.nips.cc/paper/1953-reinforcement-learning-with-long-short-term-memory.pdf">pdf</a></p><p>Author: Bram Bakker</p><p>Abstract: This paper presents reinforcement learning with a Long ShortTerm Memory recurrent neural network: RL-LSTM. Model-free RL-LSTM using Advantage(,x) learning and directed exploration can solve non-Markovian tasks with long-term dependencies between relevant events. This is demonstrated in a T-maze task, as well as in a difficult variation of the pole balancing task. 1</p><p>Reference: <a title="nips-2001-161-reference" href="../nips2001_reference/nips-2001-Reinforcement_Learning_with_Long_Short-Term_Memory_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('lstm', 0.549), ('cec', 0.298), ('timestep', 0.255), ('ag', 0.22), ('corrid', 0.219), ('rl', 0.172), ('timesery', 0.16), ('mem', 0.156), ('pol', 0.153), ('unit', 0.119), ('eim', 0.114), ('hist', 0.114), ('rememb', 0.113), ('lag', 0.101), ('rnn', 0.099), ('bit', 0.099), ('environ', 0.097), ('reinforc', 0.097), ('gat', 0.096), ('lenq', 0.092)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000006 <a title="161-tfidf-1" href="./nips-2001-Reinforcement_Learning_with_Long_Short-Term_Memory.html">161 nips-2001-Reinforcement Learning with Long Short-Term Memory</a></p>
<p>2 0.18099864 <a title="161-tfidf-2" href="./nips-2001-Multiagent_Planning_with_Factored_MDPs.html">128 nips-2001-Multiagent Planning with Factored MDPs</a></p>
<p>3 0.14173371 <a title="161-tfidf-3" href="./nips-2001-Rates_of_Convergence_of_Performance_Gradient_Estimates_Using_Function_Approximation_and_Bias_in_Reinforcement_Learning.html">157 nips-2001-Rates of Convergence of Performance Gradient Estimates Using Function Approximation and Bias in Reinforcement Learning</a></p>
<p>4 0.12484825 <a title="161-tfidf-4" href="./nips-2001-The_Steering_Approach_for_Multi-Criteria_Reinforcement_Learning.html">187 nips-2001-The Steering Approach for Multi-Criteria Reinforcement Learning</a></p>
<p>5 0.10564001 <a title="161-tfidf-5" href="./nips-2001-Generalizable_Relational_Binding_from_Coarse-coded_Distributed_Representations.html">80 nips-2001-Generalizable Relational Binding from Coarse-coded Distributed Representations</a></p>
<p>6 0.10384913 <a title="161-tfidf-6" href="./nips-2001-Motivated_Reinforcement_Learning.html">126 nips-2001-Motivated Reinforcement Learning</a></p>
<p>7 0.10367242 <a title="161-tfidf-7" href="./nips-2001-Computing_Time_Lower_Bounds_for_Recurrent_Sigmoidal_Neural_Networks.html">52 nips-2001-Computing Time Lower Bounds for Recurrent Sigmoidal Neural Networks</a></p>
<p>8 0.093416765 <a title="161-tfidf-8" href="./nips-2001-Batch_Value_Function_Approximation_via_Support_Vectors.html">40 nips-2001-Batch Value Function Approximation via Support Vectors</a></p>
<p>9 0.087483421 <a title="161-tfidf-9" href="./nips-2001-Cobot%3A_A_Social_Reinforcement_Learning_Agent.html">51 nips-2001-Cobot: A Social Reinforcement Learning Agent</a></p>
<p>10 0.083368406 <a title="161-tfidf-10" href="./nips-2001-A_Natural_Policy_Gradient.html">13 nips-2001-A Natural Policy Gradient</a></p>
<p>11 0.081983835 <a title="161-tfidf-11" href="./nips-2001-Speech_Recognition_with_Missing_Data_using_Recurrent_Neural_Nets.html">173 nips-2001-Speech Recognition with Missing Data using Recurrent Neural Nets</a></p>
<p>12 0.08180096 <a title="161-tfidf-12" href="./nips-2001-Stochastic_Mixed-Signal_VLSI_Architecture_for_High-Dimensional_Kernel_Machines.html">176 nips-2001-Stochastic Mixed-Signal VLSI Architecture for High-Dimensional Kernel Machines</a></p>
<p>13 0.080175482 <a title="161-tfidf-13" href="./nips-2001-Modeling_Temporal_Structure_in_Classical_Conditioning.html">123 nips-2001-Modeling Temporal Structure in Classical Conditioning</a></p>
<p>14 0.075526707 <a title="161-tfidf-14" href="./nips-2001-Reinforcement_Learning_and_Time_Perception_--_a_Model_of_Animal_Experiments.html">160 nips-2001-Reinforcement Learning and Time Perception -- a Model of Animal Experiments</a></p>
<p>15 0.074122638 <a title="161-tfidf-15" href="./nips-2001-A_Parallel_Mixture_of_SVMs_for_Very_Large_Scale_Problems.html">16 nips-2001-A Parallel Mixture of SVMs for Very Large Scale Problems</a></p>
<p>16 0.071014322 <a title="161-tfidf-16" href="./nips-2001-Associative_memory_in_realistic_neuronal_networks.html">37 nips-2001-Associative memory in realistic neuronal networks</a></p>
<p>17 0.069427796 <a title="161-tfidf-17" href="./nips-2001-A_Model_of_the_Phonological_Loop%3A_Generalization_and_Binding.html">12 nips-2001-A Model of the Phonological Loop: Generalization and Binding</a></p>
<p>18 0.069244541 <a title="161-tfidf-18" href="./nips-2001-The_Emergence_of_Multiple_Movement_Units_in_the_Presence_of_Noise_and_Feedback_Delay.html">181 nips-2001-The Emergence of Multiple Movement Units in the Presence of Noise and Feedback Delay</a></p>
<p>19 0.068138346 <a title="161-tfidf-19" href="./nips-2001-Playing_is_believing%3A_The_role_of_beliefs_in_multi-agent_learning.html">146 nips-2001-Playing is believing: The role of beliefs in multi-agent learning</a></p>
<p>20 0.0679316 <a title="161-tfidf-20" href="./nips-2001-Predictive_Representations_of_State.html">148 nips-2001-Predictive Representations of State</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2001_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.178), (1, -0.052), (2, 0.19), (3, -0.03), (4, 0.025), (5, -0.08), (6, -0.055), (7, 0.019), (8, -0.009), (9, 0.004), (10, 0.025), (11, -0.028), (12, -0.011), (13, 0.045), (14, 0.116), (15, -0.133), (16, -0.005), (17, 0.075), (18, 0.135), (19, -0.079), (20, -0.025), (21, -0.083), (22, 0.039), (23, 0.1), (24, -0.126), (25, 0.02), (26, 0.006), (27, 0.042), (28, -0.041), (29, -0.013), (30, 0.193), (31, 0.02), (32, 0.043), (33, -0.038), (34, -0.089), (35, 0.034), (36, -0.022), (37, -0.13), (38, -0.039), (39, -0.015), (40, 0.195), (41, 0.035), (42, -0.053), (43, 0.057), (44, -0.128), (45, 0.138), (46, -0.159), (47, 0.152), (48, -0.008), (49, 0.053)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.91427898 <a title="161-lsi-1" href="./nips-2001-Reinforcement_Learning_with_Long_Short-Term_Memory.html">161 nips-2001-Reinforcement Learning with Long Short-Term Memory</a></p>
<p>2 0.70954204 <a title="161-lsi-2" href="./nips-2001-Cobot%3A_A_Social_Reinforcement_Learning_Agent.html">51 nips-2001-Cobot: A Social Reinforcement Learning Agent</a></p>
<p>3 0.64992446 <a title="161-lsi-3" href="./nips-2001-Motivated_Reinforcement_Learning.html">126 nips-2001-Motivated Reinforcement Learning</a></p>
<p>4 0.58310688 <a title="161-lsi-4" href="./nips-2001-Multiagent_Planning_with_Factored_MDPs.html">128 nips-2001-Multiagent Planning with Factored MDPs</a></p>
<p>5 0.54466164 <a title="161-lsi-5" href="./nips-2001-Rates_of_Convergence_of_Performance_Gradient_Estimates_Using_Function_Approximation_and_Bias_in_Reinforcement_Learning.html">157 nips-2001-Rates of Convergence of Performance Gradient Estimates Using Function Approximation and Bias in Reinforcement Learning</a></p>
<p>6 0.51384193 <a title="161-lsi-6" href="./nips-2001-Improvisation_and_Learning.html">91 nips-2001-Improvisation and Learning</a></p>
<p>7 0.4458639 <a title="161-lsi-7" href="./nips-2001-Generalizable_Relational_Binding_from_Coarse-coded_Distributed_Representations.html">80 nips-2001-Generalizable Relational Binding from Coarse-coded Distributed Representations</a></p>
<p>8 0.42274934 <a title="161-lsi-8" href="./nips-2001-A_Model_of_the_Phonological_Loop%3A_Generalization_and_Binding.html">12 nips-2001-A Model of the Phonological Loop: Generalization and Binding</a></p>
<p>9 0.42171454 <a title="161-lsi-9" href="./nips-2001-Reinforcement_Learning_and_Time_Perception_--_a_Model_of_Animal_Experiments.html">160 nips-2001-Reinforcement Learning and Time Perception -- a Model of Animal Experiments</a></p>
<p>10 0.41403526 <a title="161-lsi-10" href="./nips-2001-The_Steering_Approach_for_Multi-Criteria_Reinforcement_Learning.html">187 nips-2001-The Steering Approach for Multi-Criteria Reinforcement Learning</a></p>
<p>11 0.41296154 <a title="161-lsi-11" href="./nips-2001-Computing_Time_Lower_Bounds_for_Recurrent_Sigmoidal_Neural_Networks.html">52 nips-2001-Computing Time Lower Bounds for Recurrent Sigmoidal Neural Networks</a></p>
<p>12 0.38183439 <a title="161-lsi-12" href="./nips-2001-Predictive_Representations_of_State.html">148 nips-2001-Predictive Representations of State</a></p>
<p>13 0.37796357 <a title="161-lsi-13" href="./nips-2001-Switch_Packet_Arbitration_via_Queue-Learning.html">177 nips-2001-Switch Packet Arbitration via Queue-Learning</a></p>
<p>14 0.36832792 <a title="161-lsi-14" href="./nips-2001-Speech_Recognition_with_Missing_Data_using_Recurrent_Neural_Nets.html">173 nips-2001-Speech Recognition with Missing Data using Recurrent Neural Nets</a></p>
<p>15 0.3595489 <a title="161-lsi-15" href="./nips-2001-Active_Portfolio-Management_based_on_Error_Correction_Neural_Networks.html">26 nips-2001-Active Portfolio-Management based on Error Correction Neural Networks</a></p>
<p>16 0.35853821 <a title="161-lsi-16" href="./nips-2001-A_Neural_Oscillator_Model_of_Auditory_Selective_Attention.html">14 nips-2001-A Neural Oscillator Model of Auditory Selective Attention</a></p>
<p>17 0.35725543 <a title="161-lsi-17" href="./nips-2001-Modeling_Temporal_Structure_in_Classical_Conditioning.html">123 nips-2001-Modeling Temporal Structure in Classical Conditioning</a></p>
<p>18 0.35699105 <a title="161-lsi-18" href="./nips-2001-Stochastic_Mixed-Signal_VLSI_Architecture_for_High-Dimensional_Kernel_Machines.html">176 nips-2001-Stochastic Mixed-Signal VLSI Architecture for High-Dimensional Kernel Machines</a></p>
<p>19 0.3509526 <a title="161-lsi-19" href="./nips-2001-ACh%2C_Uncertainty%2C_and_Cortical_Inference.html">3 nips-2001-ACh, Uncertainty, and Cortical Inference</a></p>
<p>20 0.34609419 <a title="161-lsi-20" href="./nips-2001-A_Rational_Analysis_of_Cognitive_Control_in_a_Speeded_Discrimination_Task.html">18 nips-2001-A Rational Analysis of Cognitive Control in a Speeded Discrimination Task</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2001_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.304), (14, 0.078), (16, 0.122), (31, 0.081), (36, 0.027), (50, 0.111), (77, 0.013), (79, 0.031), (91, 0.067), (92, 0.064)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.68768954 <a title="161-lda-1" href="./nips-2001-Reinforcement_Learning_with_Long_Short-Term_Memory.html">161 nips-2001-Reinforcement Learning with Long Short-Term Memory</a></p>
<p>2 0.57394415 <a title="161-lda-2" href="./nips-2001-TAP_Gibbs_Free_Energy%2C_Belief_Propagation_and_Sparsity.html">178 nips-2001-TAP Gibbs Free Energy, Belief Propagation and Sparsity</a></p>
<p>3 0.5332427 <a title="161-lda-3" href="./nips-2001-Convergence_of_Optimistic_and_Incremental_Q-Learning.html">55 nips-2001-Convergence of Optimistic and Incremental Q-Learning</a></p>
<p>4 0.53019446 <a title="161-lda-4" href="./nips-2001-An_Efficient%2C_Exact_Algorithm_for_Solving_Tree-Structured_Graphical_Games.html">32 nips-2001-An Efficient, Exact Algorithm for Solving Tree-Structured Graphical Games</a></p>
<p>5 0.52812922 <a title="161-lda-5" href="./nips-2001-Direct_value-approximation_for_factored_MDPs.html">59 nips-2001-Direct value-approximation for factored MDPs</a></p>
<p>6 0.52556837 <a title="161-lda-6" href="./nips-2001-Efficient_Resources_Allocation_for_Markov_Decision_Processes.html">67 nips-2001-Efficient Resources Allocation for Markov Decision Processes</a></p>
<p>7 0.52548009 <a title="161-lda-7" href="./nips-2001-Risk_Sensitive_Particle_Filters.html">163 nips-2001-Risk Sensitive Particle Filters</a></p>
<p>8 0.52356601 <a title="161-lda-8" href="./nips-2001-Multiagent_Planning_with_Factored_MDPs.html">128 nips-2001-Multiagent Planning with Factored MDPs</a></p>
<p>9 0.52270937 <a title="161-lda-9" href="./nips-2001-Modeling_Temporal_Structure_in_Classical_Conditioning.html">123 nips-2001-Modeling Temporal Structure in Classical Conditioning</a></p>
<p>10 0.52225292 <a title="161-lda-10" href="./nips-2001-Cobot%3A_A_Social_Reinforcement_Learning_Agent.html">51 nips-2001-Cobot: A Social Reinforcement Learning Agent</a></p>
<p>11 0.52178502 <a title="161-lda-11" href="./nips-2001-The_Steering_Approach_for_Multi-Criteria_Reinforcement_Learning.html">187 nips-2001-The Steering Approach for Multi-Criteria Reinforcement Learning</a></p>
<p>12 0.51661265 <a title="161-lda-12" href="./nips-2001-Grammar_Transfer_in_a_Second_Order_Recurrent_Neural_Network.html">85 nips-2001-Grammar Transfer in a Second Order Recurrent Neural Network</a></p>
<p>13 0.51597649 <a title="161-lda-13" href="./nips-2001-Rates_of_Convergence_of_Performance_Gradient_Estimates_Using_Function_Approximation_and_Bias_in_Reinforcement_Learning.html">157 nips-2001-Rates of Convergence of Performance Gradient Estimates Using Function Approximation and Bias in Reinforcement Learning</a></p>
<p>14 0.51592487 <a title="161-lda-14" href="./nips-2001-The_Infinite_Hidden_Markov_Model.html">183 nips-2001-The Infinite Hidden Markov Model</a></p>
<p>15 0.51393211 <a title="161-lda-15" href="./nips-2001-Self-regulation_Mechanism_of_Temporally_Asymmetric_Hebbian_Plasticity.html">166 nips-2001-Self-regulation Mechanism of Temporally Asymmetric Hebbian Plasticity</a></p>
<p>16 0.51239449 <a title="161-lda-16" href="./nips-2001-Playing_is_believing%3A_The_role_of_beliefs_in_multi-agent_learning.html">146 nips-2001-Playing is believing: The role of beliefs in multi-agent learning</a></p>
<p>17 0.51154953 <a title="161-lda-17" href="./nips-2001-Batch_Value_Function_Approximation_via_Support_Vectors.html">40 nips-2001-Batch Value Function Approximation via Support Vectors</a></p>
<p>18 0.51032197 <a title="161-lda-18" href="./nips-2001-Model-Free_Least-Squares_Policy_Iteration.html">121 nips-2001-Model-Free Least-Squares Policy Iteration</a></p>
<p>19 0.50944662 <a title="161-lda-19" href="./nips-2001-Exact_differential_equation_population_dynamics_for_integrate-and-fire_neurons.html">72 nips-2001-Exact differential equation population dynamics for integrate-and-fire neurons</a></p>
<p>20 0.50889891 <a title="161-lda-20" href="./nips-2001-Predictive_Representations_of_State.html">148 nips-2001-Predictive Representations of State</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
