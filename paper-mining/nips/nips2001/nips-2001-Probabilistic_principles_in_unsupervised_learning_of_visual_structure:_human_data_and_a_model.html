<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>151 nips-2001-Probabilistic principles in unsupervised learning of visual structure: human data and a model</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2001" href="../home/nips2001_home.html">nips2001</a> <a title="nips-2001-151" href="#">nips2001-151</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>151 nips-2001-Probabilistic principles in unsupervised learning of visual structure: human data and a model</h1>
<br/><p>Source: <a title="nips-2001-151-pdf" href="http://papers.nips.cc/paper/2119-probabilistic-principles-in-unsupervised-learning-of-visual-structure-human-data-and-a-model.pdf">pdf</a></p><p>Author: Shimon Edelman, Benjamin P. Hiles, Hwajin Yang, Nathan Intrator</p><p>Abstract: To ﬁnd out how the representations of structured visual objects depend on the co-occurrence statistics of their constituents, we exposed subjects to a set of composite images with tight control exerted over (1) the conditional probabilities of the constituent fragments, and (2) the value of Barlow’s criterion of “suspicious coincidence” (the ratio of joint probability to the product of marginals). We then compared the part veriﬁcation response times for various probe/target combinations before and after the exposure. For composite probes, the speedup was much larger for targets that contained pairs of fragments perfectly predictive of each other, compared to those that did not. This effect was modulated by the signiﬁcance of their co-occurrence as estimated by Barlow’s criterion. For lone-fragment probes, the speedup in all conditions was generally lower than for composites. These results shed light on the brain’s strategies for unsupervised acquisition of structural information in vision. 1 Motivation How does the human visual system decide for which objects it should maintain distinct and persistent internal representations of the kind typically postulated by theories of object recognition? Consider, for example, the image shown in Figure 1, left. This image can be represented as a monolithic hieroglyph, a pair of Chinese characters (which we shall refer to as and ), a set of strokes, or, trivially, as a collection of pixels. Note that the second option is only available to a system previously exposed to various combinations of Chinese characters. Indeed, a principled decision whether to represent this image as , or otherwise can only be made on the basis of prior exposure to related images. £ ¡ £¦ ¡ £ ¥¨§¢   ¥¤¢   ¢ According to Barlow’s [1] insight, one useful principle is tallying suspicious coincidences: two candidate fragments and should be combined into a composite object if the probability of their joint appearance is much higher than , which is the probability expected in the case of their statistical independence. This criterion may be compared to the Minimum Description Length (MDL) principle, which has been previously discussed in the context of object representation [2, 3]. In a simpliﬁed form [4], MDL calls for representing explicitly as a whole if , just as the principle of suspicious coincidences does. £ ©¢  £  ¢ ¥¤¥  £¦ ¢ ¥  £  ¢   £¦ ¢ ¥¤¥! ¨§¥ £ ¢ £ ©¢  £¦  £ ¨§¢¥ ¡ ¢   While the Barlow/MDL criterion certainly indicates a suspicious coincidence, there are additional probabilistic considerations that may be used and . One example is the possiin setting the degree of association between ble perfect predictability of from and vice versa, as measured by . If , then and are perfectly predictive of each other and should really be coded by a single symbol, whereas the MDL criterion may suggest merely that some association between the representation of and that of be established. In comparison, if and are not perfectly predictive of each other ( ), there is a case to be made in favor of coding them separately to allow for a maximally expressive representation, whereas MDL may actually suggest a high degree of association ). In this study we investigated whether the human (if visual system uses a criterion based on alongside MDL while learning (in an unsupervised manner) to represent composite objects. £ £  £ ¢  ¥  ¥ © §¥ ¡ ¢  ¨¦¤</p><p>Reference: <a title="nips-2001-151-reference" href="../nips2001_reference/nips-2001-Probabilistic_principles_in_unsupervised_learning_of_visual_structure%3A_human_data_and_a_model_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Probabilistic principles in unsupervised learning of visual structure: human data and a model Shimon Edelman, Benjamin P. [sent-1, score-0.276]
</p><p>2 We then compared the part veriﬁcation response times for various probe/target combinations before and after the exposure. [sent-5, score-0.12]
</p><p>3 For composite probes, the speedup was much larger for targets that contained pairs of fragments perfectly predictive of each other, compared to those that did not. [sent-6, score-0.763]
</p><p>4 For lone-fragment probes, the speedup in all conditions was generally lower than for composites. [sent-8, score-0.119]
</p><p>5 These results shed light on the brain’s strategies for unsupervised acquisition of structural information in vision. [sent-9, score-0.119]
</p><p>6 1 Motivation How does the human visual system decide for which objects it should maintain distinct and persistent internal representations of the kind typically postulated by theories of object recognition? [sent-10, score-0.324]
</p><p>7 This image can be represented as a monolithic hieroglyph, a pair of Chinese characters (which we shall refer to as and ), a set of strokes, or, trivially, as a collection of pixels. [sent-12, score-0.292]
</p><p>8 Note that the second option is only available to a system previously exposed to various combinations of Chinese characters. [sent-13, score-0.166]
</p><p>9 Indeed, a principled decision whether to represent this image as , or otherwise can only be made on the basis of prior exposure to related images. [sent-14, score-0.085]
</p><p>10 This criterion may be compared to the Minimum Description Length (MDL) principle, which has been previously discussed in the context of object representation [2, 3]. [sent-16, score-0.12]
</p><p>11 In a simpliﬁed form [4], MDL calls for representing explicitly as a whole if , just as the principle of suspicious coincidences does. [sent-17, score-0.318]
</p><p>12  ¨§¥  £  ¢  £ ©¢   £¦  £ ¨§¢¥ ¡ ¢    While the Barlow/MDL criterion certainly indicates a suspicious coincidence, there are additional probabilistic considerations that may be used and . [sent-19, score-0.319]
</p><p>13 One example is the possiin setting the degree of association between ble perfect predictability of from and vice versa, as measured by . [sent-20, score-0.089]
</p><p>14 If , then and are perfectly predictive of each other and should really be coded by a single symbol, whereas the MDL criterion may suggest merely that some association between the representation of and that of be established. [sent-21, score-0.128]
</p><p>15 In comparison, if and are not perfectly predictive of each other ( ), there is a case to be made in favor of coding them separately to allow for a maximally expressive representation, whereas MDL may actually suggest a high degree of association ). [sent-22, score-0.082]
</p><p>16 In this study we investigated whether the human (if visual system uses a criterion based on alongside MDL while learning (in an unsupervised manner) to represent composite objects. [sent-23, score-0.682]
</p><p>17 §£ ¤  ¢  ¢  © §¥  £ ¢  ¨¤ ¢  ¢  £   ¨¤ © §¥  ¡ ¤¢ ¦¥¦  £ ¥      £   ¢   ¢       £¦    £¥¤¢¥ £  ¢¥ ¢   AB  Figure 1: Left: how many objects are contained in image ? [sent-25, score-0.139]
</p><p>18 Without prior knowledge, a reasonable answer, which embodies a holistic bias, should be “one” (Gestalt effects, which would suggest two convex “blobs” [5], are beyond the scope of the present discussion). [sent-26, score-0.059]
</p><p>19 Right: in this set of ten images, appears ﬁve times as a whole; the other ﬁve times a fragment wholly contained in appears in isolation. [sent-27, score-0.209]
</p><p>20 This statistical fact provides to be composite, consisting of two fragments (call the upper grounds for considering one and the lower one ), because , but . [sent-28, score-0.19]
</p><p>21 £ ¤¢     " )(¡ '¢  ¢ £¥ &      %¢ £ $¢¥  £ ©¢ £ ¤¢  £ £ ¤¢  ¢  To date, psychophysical explorations of the sensitivity of human subjects to stimulus statistics tended to concentrate on means (and sometimes variances) of the frequency of various stimuli (e. [sent-29, score-0.552]
</p><p>22 [7], who showed that infants (and adults) can distinguish between “words” (stable pairs of syllables that recur in a continuous auditory stimulus stream) and non-words (syllables accidentally paired with each other, the ﬁrst of which comes from one “word” and the second – from the following one). [sent-33, score-0.255]
</p><p>23 Thus, subjects can sense (and act upon) differences in transition probabilities between successive auditory stimuli. [sent-34, score-0.286]
</p><p>24 This ﬁnding has been recently replicated, with infants as young as 2 months, in the visual sequence domain, using successive presentation of simple geometric shapes with controlled transition probabilities [8]. [sent-35, score-0.212]
</p><p>25 The present study was undertaken to investigate the relevance of the various notions of statistical independence to the unsupervised learning of complex visual stimuli by human subjects. [sent-37, score-0.462]
</p><p>26 First, instead of explicitly judging shape familiarity, our subjects had to verify the presence of a probe shape embedded in a target. [sent-39, score-0.729]
</p><p>27 This objective task, which produces a pattern of response times, is arguably better suited to the investigation of internal representations involved in object recognition than subjective judgment. [sent-40, score-0.178]
</p><p>28 Second, the estimation of familiarity requires the subject to access in each trial the representations of all the objects seen in the experi-  ment; in our task, each trial involved just two objects (the probe and the target), potentially sharpening the focus of the experimental approach. [sent-41, score-0.687]
</p><p>29 Third, our experiments tested the predictions of two distinct notions of stimulus independence: , and MDL, or Barlow’s ratio. [sent-42, score-0.104]
</p><p>30  ¨¤ © §¥  2 The psychophysical experiments In two experiments, we presented stimuli composed of characters such as those in Figure 1 to nearly 100 subjects unfamiliar with the Chinese script. [sent-43, score-0.625]
</p><p>31 The conditional probabilities of the appearance of individual characters were controlled. [sent-44, score-0.295]
</p><p>32 The experiments involved two types of probe conditions: P TYPE=Fragment, or (with as the reference condition), and P TYPE=Composite, or (with as reference). [sent-45, score-0.395]
</p><p>33 In this notation (see Figure 2, left), and are “familiar” fragments with controlled minimum conditional probability , and are novel (low-probability) fragments. [sent-46, score-0.233]
</p><p>34 £   ¦ ¢ ©¢¢ ©¨§£ £ £ ¢ ¤    ¢ ¦ ©¦¦ £ £ £ ¢   £ ¢ ¢ ¤¤¢ ¥©¢ ¢ £ ¡     ¨¦¤ © §¥ ¢  Each of the two experiments consisted of a baseline phase, followed by training exposure (unsupervised learning), followed in turn by the test phase (Figure 2, right). [sent-47, score-0.209]
</p><p>35 In the baseline and test phases, the subjects had to indicate whether or not the probe was contained in the target (a task previously used by Palmer [5]). [sent-48, score-0.776]
</p><p>36 In the intervening training phase, the subjects merely watched the character triplets presented on the screen; to ensure their attention, the subjects were asked to note the order in which the characters appeared. [sent-49, score-0.725]
</p><p>37 V  ABZ  VW  ABZ  baseline/test  target  reference  mask probe  A  ABZ  AB  ABZ 4  test  3 2 1  probe  target  Fragment  probe  target unsupervised training  Composite  Figure 2: Left: illustration of the probe and target composition for the two levels of P TYPE (Fragment and Composite). [sent-50, score-1.872]
</p><p>38 For convenience, the various categories of characters that appeared in the experiment are annotated here by Latin letters: , stand for characters , and stand for characters that with controlled appeared only once throughout an experiment. [sent-51, score-0.835]
</p><p>39 In experiment 1, the training set was constructed with for some pairs, and for others; in experiment 2, Barlow’s suspicious coincidence ratio was also controlled. [sent-52, score-0.746]
</p><p>40 Right top: the structure of a part veriﬁcation trial (same for baseline and test phases). [sent-53, score-0.146]
</p><p>41 The probe stimulus was followed by the target (each presented for ; a mask was shown before and after the target). [sent-54, score-0.557]
</p><p>42 A sequence consisting of 64 trials like this one was presented twice: before training (baseline phase) and after training (test phase). [sent-56, score-0.128]
</p><p>43 , probe contained in target), we looked at the S PEEDUP following training, deﬁned as ; negative trials were discarded. [sent-59, score-0.428]
</p><p>44 Right bottom: the structure of a training trial (the training phase, placed between baseline and test, consisted of 80 such trials). [sent-60, score-0.228]
</p><p>45 The three components of the stimulus appeared one by one for to make sure that the subject attended to each, then together for . [sent-61, score-0.112]
</p><p>46    ¤ & & 3  The logic behind the psychophysical experiments rested on two premises. [sent-66, score-0.063]
</p><p>47 First, we knew from earlier work [5] that a probe is detected faster if it is represented monolithically (that is, considered to be a good “object” in the Gestalt sense). [sent-67, score-0.335]
</p><p>48 Second, we hypothesized that a composite stimulus would be treated as a monolithic object to the extent that its constituent characters are predictable from each other, as measured by a high conditional probability, , and/or by a high suspicious coincidence ratio, . [sent-68, score-1.308]
</p><p>49 The main prediction following from these premises is that the S PEEDUP (the difference in response time between baseline and test phases) for a composite probe should reﬂect the mutual predictability of the probe’s constituents in the training set. [sent-69, score-0.998]
</p><p>50 Thus, our hypothesis — that statistics of co-occurrence determine the constituents in terms of which structured objects are represented — would be supported if the S PEEDUP turns out to be larger for those composite probes whose constituents tend to appear together in the training set. [sent-70, score-0.882]
</p><p>51 The experiments, therefore, hinged on a comparison of the patterns of response times in the “positive” trials (in which the probe actually is embedded in the target; see Figure 2, left) before and after exposure to the training set. [sent-71, score-0.53]
</p><p>52 ¤ © §¥  400 Composite Fragment  analog of speedup  0. [sent-73, score-0.151]
</p><p>53 8  minCP 1  Figure 3: Left: unsupervised learning of statistically deﬁned structure by human subjects, ). [sent-84, score-0.19]
</p><p>54 The dependent variable S PEED - UP is deﬁned as the difference in experiment 1 ( between baseline and test phases (least-squares estimates of means and standard errors, computed by the LSMEANS option of SAS procedure MIXED [10]). [sent-85, score-0.271]
</p><p>55 The S PEED - UP for composite probes (solid line) with exceeded that in the other conditions by . [sent-86, score-0.564]
</p><p>56 Right: the results of a simulation of experiment 1 by a model derived from about the one described in [4]. [sent-87, score-0.095]
</p><p>57 The model was exposed to the same 80 training images as the human subjects. [sent-88, score-0.193]
</p><p>58 The difference of reconstruction errors for probe and target served as the analog of RT; baseline measurements were conducted on half-trained networks. [sent-89, score-0.621]
</p><p>59 1 Experiment 1 Fourteen subjects, none of them familiar with the Chinese writing system, participated in this experiment in exchange for course credit. [sent-91, score-0.131]
</p><p>60 Among the stimuli, two characters could be paired, in which case we had . [sent-92, score-0.184]
</p><p>61 Alternatively, could be unpaired, with , (in this experiment, we held the suspicious coincidence ratio constant at ). [sent-93, score-0.515]
</p><p>62 For the paired the minimum conditional probability and the two characters were perfectly predictable from each other, whereas for the unpaired , and they were not. [sent-94, score-0.409]
</p><p>63 §¤  As expected, we found the value of S PEED - UP to be strikingly different for composite probes with ( ) compared to the other three conditions (about ); see Figure 3, left. [sent-98, score-0.564]
</p><p>64 A mixed-effects repeated measures analysis of variance (SAS procedure MIXED [10]) for S PEED - UP revealed a marginal effect of P TYPE ( ) and a signiﬁcant interaction P TYPE interaction ( ). [sent-99, score-0.072]
</p><p>65 The subjects in experiment 1 proved to be sensitive to the measure of independence in learning to associate object fragments together. [sent-101, score-0.609]
</p><p>66 cious coincidence ratio was the same in both cases, Thus, the visual system is sensitive to over and above the (constant-valued) MDLrelated criterion, according to which the propensity to form a uniﬁed representation of two fragments, and , should be determined by [1, 4]. [sent-103, score-0.328]
</p><p>67  ¨¤ © §¥  £  ¢  200  200  speedup, ms  speedup, ms  ¢  © ¥  #¢  ! [sent-104, score-0.098]
</p><p>68 0  1  250 200  speedup, ms  250 speedup, ms  ¡  ¦ §¦ ¤   ¨¤ © §¥  r=1. [sent-114, score-0.098]
</p><p>69 13 250  150 100 50 0 0  5 r  150 100 50 0 0  10  5 r  10  ¤ ¢ §  Figure 4: Human subjects, experiment 2 ( ). [sent-115, score-0.095]
</p><p>70 The effect of found in experiment 1 was modulated in a complicated fashion by the effect of the suspicious coincidence ratio (see text for discussion). [sent-116, score-0.61]
</p><p>71 To accommodate this constraint, some subjects saw two sets of stimuli, with and with , in the ﬁrst ses-   ¨¦¤ © §¥ ¦     © ¥  ¡  ¢   ¦  ¢  ! [sent-120, score-0.25]
</p><p>72 Eighty one subjects unfamiliar with the Chinese script participated in this experiment for course credit. [sent-122, score-0.449]
</p><p>73 ¦ §¦ ¤  ¦  The results (Figure 4) showed that S PEEDUP was consistently higher for composite probes. [sent-123, score-0.36]
</p><p>74 Thus, the association between probe constituents was strengthened by training in each of the four conditions. [sent-124, score-0.506]
</p><p>75 S PEEDUP was also generally higher for the high suspicious coincidence ratio case, , and disproportionately higher for composite probes in the , case, indicating a complicated synergy between the two measures of dependence, and . [sent-125, score-1.124]
</p><p>76 The model (Figure 5) is based on the following observation: an auto-association network fed with a sequence of composite images in which some fragment/location combinations are more likely than others develops a nonuniform spatial distribution of reconstruction errors. [sent-132, score-0.564]
</p><p>77 Speciﬁcally, smaller errors appear in those locations where the image fragments recur. [sent-133, score-0.23]
</p><p>78 This information can be used to form a spatial receptive ﬁeld for the learning module, while the reconstruction error can signal its relevance to the current input [11, 12]. [sent-134, score-0.231]
</p><p>79 In the simpliﬁed pilot model, the spatial receptive ﬁeld (labeled in Figure 5, left, as “relevance mask”) consists of four weights, one per quadrant: , . [sent-135, score-0.144]
</p><p>80 During the unsupervised training, the weights are updated by setting , where is the reconstruction error in trial , and and are learning constants. [sent-136, score-0.259]
</p><p>81 In a simulation of experiment 1, a separate module with its own four-weight “receptive ﬁeld” was trained for each of the composite stimuli shown to the human subjects. [sent-137, score-0.67]
</p><p>82 1 The Euclidean distance between probe and target representations at the output of the model served as the analog of response time, allowing us to compare the model’s performance with that of the humans. [sent-138, score-0.541]
</p><p>83 We found the same differential effects of for Fragment and Composite probes in the real and simulated experiments; compare Figure 3, left (humans) with Figure 3, right (model). [sent-139, score-0.243]
</p><p>84 ' $"    ¤  ¦    ¦ ¥ ¢  ¥ ¡   ¦ ¦ ¦ £ ¡ ¦    ©¥  §¥ ¨ ¦      '  ) 0(   ¨¤ © §¥  1  The full-ﬂedged model, currently under development, will have a more ﬂexible receptive ﬁeld structure, and will incorporate competitive learning among the modules. [sent-141, score-0.058]
</p><p>85 input  error  input  adapt  − erri relevance mask (RF) auto− associator  ensemble of modules reconstructed  Figure 5: Left: the functional architecture of a fragment module. [sent-142, score-0.356]
</p><p>86 The module consists of two adaptive components: a reconstruction network, and a relevance mask, which assigns different weights to different input pixels. [sent-143, score-0.216]
</p><p>87 The mask modulates the input multiplicatively, determining the module’s receptive ﬁeld. [sent-144, score-0.144]
</p><p>88 Given a sequence of images, several such modules working in parallel learn to represent different categories of spatially localized patterns (fragments) that recur in those images. [sent-145, score-0.095]
</p><p>89 The reconstruction error serves as an estimate of the module’s ability to deal with the input ([11, 12]; in the error image, shown on the right, white corresponds to high values). [sent-146, score-0.074]
</p><p>90 Right: the Chorus of Fragments (CoF) is a bank of such fragment modules, each tuned to a particular shape category, appearing in a particular location [13, 4]. [sent-147, score-0.219]
</p><p>91 4 Discussion Human subjects have been previously shown to be able to acquire, through unsupervised learning, sensitivity to transition probabilities between syllables of nonsense words [7] and between digits [14], and to co-occurrence statistics of simple geometrical ﬁgures [9]. [sent-148, score-0.464]
</p><p>92 Our results demonstrate that subjects can also learn (presumably without awareness; cf. [sent-149, score-0.25]
</p><p>93 [14]) to treat combinations of complex visual patterns differentially, depending on the conditional probabilities of the various combinations, accumulated during a short unsupervised training session. [sent-150, score-0.412]
</p><p>94 In our ﬁrst experiment, the criterion of suspicious coincidence between the occurrences and conditions: in each case, we of and was met in both had . [sent-151, score-0.503]
</p><p>95 Yet, the subjects’ behavior indicated a signiﬁcant holistic bias: the representation they form tends to be monolithic ( ), unless imperfect mutual predictability of the potential fragments ( and ) provides support for representing them separately. [sent-152, score-0.371]
</p><p>96 We note that a similar holistic bias, operating in a setting where a single encounter with a stimulus can make a difference, is found in language acquisition: an infant faced with an unfamiliar word will assume it refers to the entire shape of the most salient object [15]. [sent-153, score-0.33]
</p><p>97 In our second experiment, both the conditional probabilities as such, and the suspicious coincidence ratio were found to have the predicted effects, yet these two factors interacted in a complicated manner, which requires a further investigation. [sent-154, score-0.594]
</p><p>98 A productive, systematic framework for the representation of visual structure. [sent-183, score-0.086]
</p><p>99 Unsupervised statistical learning of higher-order spatial structures from visual scenes. [sent-228, score-0.127]
</p><p>100 Constraints on the nature of the neural representation of the visual world. [sent-274, score-0.086]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('composite', 0.36), ('probe', 0.335), ('suspicious', 0.273), ('subjects', 0.25), ('probes', 0.204), ('fragments', 0.19), ('coincidence', 0.184), ('characters', 0.184), ('fragment', 0.162), ('mincp', 0.136), ('peedup', 0.136), ('speedup', 0.119), ('unsupervised', 0.119), ('chinese', 0.118), ('mdl', 0.117), ('peed', 0.114), ('constituents', 0.095), ('experiment', 0.095), ('abz', 0.091), ('sas', 0.091), ('visual', 0.086), ('mask', 0.086), ('module', 0.084), ('barlow', 0.084), ('baseline', 0.08), ('object', 0.074), ('reconstruction', 0.074), ('stimulus', 0.072), ('human', 0.071), ('edelman', 0.068), ('monolithic', 0.068), ('unfamiliar', 0.068), ('trial', 0.066), ('target', 0.064), ('psychophysical', 0.063), ('stimuli', 0.06), ('phases', 0.06), ('holistic', 0.059), ('syllables', 0.059), ('relevance', 0.058), ('receptive', 0.058), ('ratio', 0.058), ('shape', 0.057), ('predictability', 0.054), ('objects', 0.052), ('combinations', 0.051), ('shapes', 0.051), ('predictable', 0.05), ('modules', 0.05), ('ms', 0.049), ('contained', 0.047), ('perfectly', 0.047), ('trials', 0.046), ('criterion', 0.046), ('aslin', 0.045), ('coincidences', 0.045), ('disproportionately', 0.045), ('familiarity', 0.045), ('intrator', 0.045), ('objecthood', 0.045), ('pilot', 0.045), ('recur', 0.045), ('saffran', 0.045), ('unpaired', 0.045), ('exposure', 0.045), ('phase', 0.043), ('exposed', 0.043), ('conditional', 0.043), ('training', 0.041), ('spatial', 0.041), ('representations', 0.041), ('type', 0.041), ('image', 0.04), ('appeared', 0.04), ('paired', 0.04), ('infants', 0.039), ('effects', 0.039), ('images', 0.038), ('interaction', 0.036), ('probabilities', 0.036), ('fiser', 0.036), ('stand', 0.036), ('participated', 0.036), ('option', 0.036), ('gestalt', 0.036), ('served', 0.036), ('various', 0.036), ('association', 0.035), ('structured', 0.035), ('eld', 0.034), ('nathan', 0.034), ('response', 0.033), ('analog', 0.032), ('replicated', 0.032), ('notions', 0.032), ('appearance', 0.032), ('involved', 0.03), ('reference', 0.03), ('mixed', 0.03), ('embedded', 0.03)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="151-tfidf-1" href="./nips-2001-Probabilistic_principles_in_unsupervised_learning_of_visual_structure%3A_human_data_and_a_model.html">151 nips-2001-Probabilistic principles in unsupervised learning of visual structure: human data and a model</a></p>
<p>Author: Shimon Edelman, Benjamin P. Hiles, Hwajin Yang, Nathan Intrator</p><p>Abstract: To ﬁnd out how the representations of structured visual objects depend on the co-occurrence statistics of their constituents, we exposed subjects to a set of composite images with tight control exerted over (1) the conditional probabilities of the constituent fragments, and (2) the value of Barlow’s criterion of “suspicious coincidence” (the ratio of joint probability to the product of marginals). We then compared the part veriﬁcation response times for various probe/target combinations before and after the exposure. For composite probes, the speedup was much larger for targets that contained pairs of fragments perfectly predictive of each other, compared to those that did not. This effect was modulated by the signiﬁcance of their co-occurrence as estimated by Barlow’s criterion. For lone-fragment probes, the speedup in all conditions was generally lower than for composites. These results shed light on the brain’s strategies for unsupervised acquisition of structural information in vision. 1 Motivation How does the human visual system decide for which objects it should maintain distinct and persistent internal representations of the kind typically postulated by theories of object recognition? Consider, for example, the image shown in Figure 1, left. This image can be represented as a monolithic hieroglyph, a pair of Chinese characters (which we shall refer to as and ), a set of strokes, or, trivially, as a collection of pixels. Note that the second option is only available to a system previously exposed to various combinations of Chinese characters. Indeed, a principled decision whether to represent this image as , or otherwise can only be made on the basis of prior exposure to related images. £ ¡ £¦ ¡ £ ¥¨§¢   ¥¤¢   ¢ According to Barlow’s [1] insight, one useful principle is tallying suspicious coincidences: two candidate fragments and should be combined into a composite object if the probability of their joint appearance is much higher than , which is the probability expected in the case of their statistical independence. This criterion may be compared to the Minimum Description Length (MDL) principle, which has been previously discussed in the context of object representation [2, 3]. In a simpliﬁed form [4], MDL calls for representing explicitly as a whole if , just as the principle of suspicious coincidences does. £ ©¢  £  ¢ ¥¤¥  £¦ ¢ ¥  £  ¢   £¦ ¢ ¥¤¥! ¨§¥ £ ¢ £ ©¢  £¦  £ ¨§¢¥ ¡ ¢   While the Barlow/MDL criterion certainly indicates a suspicious coincidence, there are additional probabilistic considerations that may be used and . One example is the possiin setting the degree of association between ble perfect predictability of from and vice versa, as measured by . If , then and are perfectly predictive of each other and should really be coded by a single symbol, whereas the MDL criterion may suggest merely that some association between the representation of and that of be established. In comparison, if and are not perfectly predictive of each other ( ), there is a case to be made in favor of coding them separately to allow for a maximally expressive representation, whereas MDL may actually suggest a high degree of association ). In this study we investigated whether the human (if visual system uses a criterion based on alongside MDL while learning (in an unsupervised manner) to represent composite objects. £ £  £ ¢  ¥  ¥ © §¥ ¡ ¢  ¨¦¤</p><p>2 0.18470325 <a title="151-tfidf-2" href="./nips-2001-Fragment_Completion_in_Humans_and_Machines.html">78 nips-2001-Fragment Completion in Humans and Machines</a></p>
<p>Author: David Jacobs, Bas Rokers, Archisman Rudra, Zili Liu</p><p>Abstract: Partial information can trigger a complete memory. At the same time, human memory is not perfect. A cue can contain enough information to specify an item in memory, but fail to trigger that item. In the context of word memory, we present experiments that demonstrate some basic patterns in human memory errors. We use cues that consist of word fragments. We show that short and long cues are completed more accurately than medium length ones and study some of the factors that lead to this behavior. We then present a novel computational model that shows some of the ﬂexibility and patterns of errors that occur in human memory. This model iterates between bottom-up and top-down computations. These are tied together using a Markov model of words that allows memory to be accessed with a simple feature set, and enables a bottom-up process to compute a probability distribution of possible completions of word fragments, in a manner similar to models of visual perceptual completion.</p><p>3 0.13281225 <a title="151-tfidf-3" href="./nips-2001-Effective_Size_of_Receptive_Fields_of_Inferior_Temporal_Visual_Cortex_Neurons_in_Natural_Scenes.html">65 nips-2001-Effective Size of Receptive Fields of Inferior Temporal Visual Cortex Neurons in Natural Scenes</a></p>
<p>Author: Thomas P. Trappenberg, Edmund T. Rolls, Simon M. Stringer</p><p>Abstract: Inferior temporal cortex (IT) neurons have large receptive ﬁelds when a single effective object stimulus is shown against a blank background, but have much smaller receptive ﬁelds when the object is placed in a natural scene. Thus, translation invariant object recognition is reduced in natural scenes, and this may help object selection. We describe a model which accounts for this by competition within an attractor in which the neurons are tuned to different objects in the scene, and the fovea has a higher cortical magniﬁcation factor than the peripheral visual ﬁeld. Furthermore, we show that top-down object bias can increase the receptive ﬁeld size, facilitating object search in complex visual scenes, and providing a model of object-based attention. The model leads to the prediction that introduction of a second object into a scene with blank background will reduce the receptive ﬁeld size to values that depend on the closeness of the second object to the target stimulus. We suggest that mechanisms of this type enable the output of IT to be primarily about one object, so that the areas that receive from IT can select the object as a potential target for action.</p><p>4 0.10379247 <a title="151-tfidf-4" href="./nips-2001-Linking_Motor_Learning_to_Function_Approximation%3A_Learning_in_an_Unlearnable_Force_Field.html">116 nips-2001-Linking Motor Learning to Function Approximation: Learning in an Unlearnable Force Field</a></p>
<p>Author: O. Donchin, Reza Shadmehr</p><p>Abstract: Reaching movements require the brain to generate motor commands that rely on an internal model of the task’s dynamics. Here we consider the errors that subjects make early in their reaching trajectories to various targets as they learn an internal model. Using a framework from function approximation, we argue that the sequence of errors should reﬂect the process of gradient descent. If so, then the sequence of errors should obey hidden state transitions of a simple dynamical system. Fitting the system to human data, we ﬁnd a surprisingly good ﬁt accounting for 98% of the variance. This allows us to draw tentative conclusions about the basis elements used by the brain in transforming sensory space to motor commands. To test the robustness of the results, we estimate the shape of the basis elements under two conditions: in a traditional learning paradigm with a consistent force ﬁeld, and in a random sequence of force ﬁelds where learning is not possible. Remarkably, we ﬁnd that the basis remains invariant. 1</p><p>5 0.099811867 <a title="151-tfidf-5" href="./nips-2001-Audio-Visual_Sound_Separation_Via_Hidden_Markov_Models.html">39 nips-2001-Audio-Visual Sound Separation Via Hidden Markov Models</a></p>
<p>Author: John R. Hershey, Michael Casey</p><p>Abstract: It is well known that under noisy conditions we can hear speech much more clearly when we read the speaker's lips. This suggests the utility of audio-visual information for the task of speech enhancement. We propose a method to exploit audio-visual cues to enable speech separation under non-stationary noise and with a single microphone. We revise and extend HMM-based speech enhancement techniques, in which signal and noise models are factori ally combined, to incorporate visual lip information and employ novel signal HMMs in which the dynamics of narrow-band and wide band components are factorial. We avoid the combinatorial explosion in the factorial model by using a simple approximate inference technique to quickly estimate the clean signals in a mixture. We present a preliminary evaluation of this approach using a small-vocabulary audio-visual database, showing promising improvements in machine intelligibility for speech enhanced using audio and visual information. 1</p><p>6 0.095666513 <a title="151-tfidf-6" href="./nips-2001-Modeling_Temporal_Structure_in_Classical_Conditioning.html">123 nips-2001-Modeling Temporal Structure in Classical Conditioning</a></p>
<p>7 0.094655529 <a title="151-tfidf-7" href="./nips-2001-Contextual_Modulation_of_Target_Saliency.html">54 nips-2001-Contextual Modulation of Target Saliency</a></p>
<p>8 0.081731282 <a title="151-tfidf-8" href="./nips-2001-Generalizable_Relational_Binding_from_Coarse-coded_Distributed_Representations.html">80 nips-2001-Generalizable Relational Binding from Coarse-coded Distributed Representations</a></p>
<p>9 0.080374606 <a title="151-tfidf-9" href="./nips-2001-Modeling_the_Modulatory_Effect_of_Attention_on_Human_Spatial_Vision.html">124 nips-2001-Modeling the Modulatory Effect of Attention on Human Spatial Vision</a></p>
<p>10 0.078891352 <a title="151-tfidf-10" href="./nips-2001-Spike_timing_and_the_coding_of_naturalistic_sounds_in_a_central_auditory_area_of_songbirds.html">174 nips-2001-Spike timing and the coding of naturalistic sounds in a central auditory area of songbirds</a></p>
<p>11 0.070818178 <a title="151-tfidf-11" href="./nips-2001-Classifying_Single_Trial_EEG%3A_Towards_Brain_Computer_Interfacing.html">50 nips-2001-Classifying Single Trial EEG: Towards Brain Computer Interfacing</a></p>
<p>12 0.064558074 <a title="151-tfidf-12" href="./nips-2001-A_Rational_Analysis_of_Cognitive_Control_in_a_Speeded_Discrimination_Task.html">18 nips-2001-A Rational Analysis of Cognitive Control in a Speeded Discrimination Task</a></p>
<p>13 0.063563608 <a title="151-tfidf-13" href="./nips-2001-Eye_movements_and_the_maturation_of_cortical_orientation_selectivity.html">73 nips-2001-Eye movements and the maturation of cortical orientation selectivity</a></p>
<p>14 0.061923012 <a title="151-tfidf-14" href="./nips-2001-Group_Redundancy_Measures_Reveal_Redundancy_Reduction_in_the_Auditory_Pathway.html">87 nips-2001-Group Redundancy Measures Reveal Redundancy Reduction in the Auditory Pathway</a></p>
<p>15 0.060109839 <a title="151-tfidf-15" href="./nips-2001-A_Maximum-Likelihood_Approach_to_Modeling_Multisensory_Enhancement.html">11 nips-2001-A Maximum-Likelihood Approach to Modeling Multisensory Enhancement</a></p>
<p>16 0.059720695 <a title="151-tfidf-16" href="./nips-2001-Convolution_Kernels_for_Natural_Language.html">56 nips-2001-Convolution Kernels for Natural Language</a></p>
<p>17 0.058909878 <a title="151-tfidf-17" href="./nips-2001-Categorization_by_Learning_and_Combining_Object_Parts.html">46 nips-2001-Categorization by Learning and Combining Object Parts</a></p>
<p>18 0.057758395 <a title="151-tfidf-18" href="./nips-2001-Natural_Language_Grammar_Induction_Using_a_Constituent-Context_Model.html">130 nips-2001-Natural Language Grammar Induction Using a Constituent-Context Model</a></p>
<p>19 0.056612317 <a title="151-tfidf-19" href="./nips-2001-A_General_Greedy_Approximation_Algorithm_with_Applications.html">8 nips-2001-A General Greedy Approximation Algorithm with Applications</a></p>
<p>20 0.056131896 <a title="151-tfidf-20" href="./nips-2001-Unsupervised_Learning_of_Human_Motion_Models.html">193 nips-2001-Unsupervised Learning of Human Motion Models</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2001_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.169), (1, -0.115), (2, -0.077), (3, 0.017), (4, -0.114), (5, -0.006), (6, -0.17), (7, 0.027), (8, -0.037), (9, -0.023), (10, -0.056), (11, 0.096), (12, -0.132), (13, 0.037), (14, 0.003), (15, 0.048), (16, 0.063), (17, 0.034), (18, -0.061), (19, 0.154), (20, -0.03), (21, -0.111), (22, -0.049), (23, -0.042), (24, 0.014), (25, -0.109), (26, -0.071), (27, 0.087), (28, -0.103), (29, 0.08), (30, 0.033), (31, 0.034), (32, 0.137), (33, 0.12), (34, -0.031), (35, 0.066), (36, 0.117), (37, -0.142), (38, -0.021), (39, 0.006), (40, -0.064), (41, -0.116), (42, 0.057), (43, -0.012), (44, -0.015), (45, -0.037), (46, 0.006), (47, -0.106), (48, 0.065), (49, 0.096)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95235932 <a title="151-lsi-1" href="./nips-2001-Probabilistic_principles_in_unsupervised_learning_of_visual_structure%3A_human_data_and_a_model.html">151 nips-2001-Probabilistic principles in unsupervised learning of visual structure: human data and a model</a></p>
<p>Author: Shimon Edelman, Benjamin P. Hiles, Hwajin Yang, Nathan Intrator</p><p>Abstract: To ﬁnd out how the representations of structured visual objects depend on the co-occurrence statistics of their constituents, we exposed subjects to a set of composite images with tight control exerted over (1) the conditional probabilities of the constituent fragments, and (2) the value of Barlow’s criterion of “suspicious coincidence” (the ratio of joint probability to the product of marginals). We then compared the part veriﬁcation response times for various probe/target combinations before and after the exposure. For composite probes, the speedup was much larger for targets that contained pairs of fragments perfectly predictive of each other, compared to those that did not. This effect was modulated by the signiﬁcance of their co-occurrence as estimated by Barlow’s criterion. For lone-fragment probes, the speedup in all conditions was generally lower than for composites. These results shed light on the brain’s strategies for unsupervised acquisition of structural information in vision. 1 Motivation How does the human visual system decide for which objects it should maintain distinct and persistent internal representations of the kind typically postulated by theories of object recognition? Consider, for example, the image shown in Figure 1, left. This image can be represented as a monolithic hieroglyph, a pair of Chinese characters (which we shall refer to as and ), a set of strokes, or, trivially, as a collection of pixels. Note that the second option is only available to a system previously exposed to various combinations of Chinese characters. Indeed, a principled decision whether to represent this image as , or otherwise can only be made on the basis of prior exposure to related images. £ ¡ £¦ ¡ £ ¥¨§¢   ¥¤¢   ¢ According to Barlow’s [1] insight, one useful principle is tallying suspicious coincidences: two candidate fragments and should be combined into a composite object if the probability of their joint appearance is much higher than , which is the probability expected in the case of their statistical independence. This criterion may be compared to the Minimum Description Length (MDL) principle, which has been previously discussed in the context of object representation [2, 3]. In a simpliﬁed form [4], MDL calls for representing explicitly as a whole if , just as the principle of suspicious coincidences does. £ ©¢  £  ¢ ¥¤¥  £¦ ¢ ¥  £  ¢   £¦ ¢ ¥¤¥! ¨§¥ £ ¢ £ ©¢  £¦  £ ¨§¢¥ ¡ ¢   While the Barlow/MDL criterion certainly indicates a suspicious coincidence, there are additional probabilistic considerations that may be used and . One example is the possiin setting the degree of association between ble perfect predictability of from and vice versa, as measured by . If , then and are perfectly predictive of each other and should really be coded by a single symbol, whereas the MDL criterion may suggest merely that some association between the representation of and that of be established. In comparison, if and are not perfectly predictive of each other ( ), there is a case to be made in favor of coding them separately to allow for a maximally expressive representation, whereas MDL may actually suggest a high degree of association ). In this study we investigated whether the human (if visual system uses a criterion based on alongside MDL while learning (in an unsupervised manner) to represent composite objects. £ £  £ ¢  ¥  ¥ © §¥ ¡ ¢  ¨¦¤</p><p>2 0.71974564 <a title="151-lsi-2" href="./nips-2001-Fragment_Completion_in_Humans_and_Machines.html">78 nips-2001-Fragment Completion in Humans and Machines</a></p>
<p>Author: David Jacobs, Bas Rokers, Archisman Rudra, Zili Liu</p><p>Abstract: Partial information can trigger a complete memory. At the same time, human memory is not perfect. A cue can contain enough information to specify an item in memory, but fail to trigger that item. In the context of word memory, we present experiments that demonstrate some basic patterns in human memory errors. We use cues that consist of word fragments. We show that short and long cues are completed more accurately than medium length ones and study some of the factors that lead to this behavior. We then present a novel computational model that shows some of the ﬂexibility and patterns of errors that occur in human memory. This model iterates between bottom-up and top-down computations. These are tied together using a Markov model of words that allows memory to be accessed with a simple feature set, and enables a bottom-up process to compute a probability distribution of possible completions of word fragments, in a manner similar to models of visual perceptual completion.</p><p>3 0.52355021 <a title="151-lsi-3" href="./nips-2001-A_Rational_Analysis_of_Cognitive_Control_in_a_Speeded_Discrimination_Task.html">18 nips-2001-A Rational Analysis of Cognitive Control in a Speeded Discrimination Task</a></p>
<p>Author: Michael C. Mozer, Michael D. Colagrosso, David E. Huber</p><p>Abstract: We are interested in the mechanisms by which individuals monitor and adjust their performance of simple cognitive tasks. We model a speeded discrimination task in which individuals are asked to classify a sequence of stimuli (Jones & Braver, 2001). Response conﬂict arises when one stimulus class is infrequent relative to another, resulting in more errors and slower reaction times for the infrequent class. How do control processes modulate behavior based on the relative class frequencies? We explain performance from a rational perspective that casts the goal of individuals as minimizing a cost that depends both on error rate and reaction time. With two additional assumptions of rationality—that class prior probabilities are accurately estimated and that inference is optimal subject to limitations on rate of information transmission—we obtain a good ﬁt to overall RT and error data, as well as trial-by-trial variations in performance. Consider the following scenario: While driving, you approach an intersection at which the trafﬁc light has already turned yellow, signaling that it is about to turn red. You also notice that a car is approaching you rapidly from behind, with no indication of slowing. Should you stop or speed through the intersection? The decision is difﬁcult due to the presence of two conﬂicting signals. Such response conﬂict can be produced in a psychological laboratory as well. For example, Stroop (1935) asked individuals to name the color of ink on which a word is printed. When the words are color names incongruous with the ink color— e.g., “blue” printed in red—reaction times are slower and error rates are higher. We are interested in the control mechanisms underlying performance of high-conﬂict tasks. Conﬂict requires individuals to monitor and adjust their behavior, possibly responding more slowly if errors are too frequent. In this paper, we model a speeded discrimination paradigm in which individuals are asked to classify a sequence of stimuli (Jones & Braver, 2001). The stimuli are letters of the alphabet, A–Z, presented in rapid succession. In a choice task, individuals are asked to press one response key if the letter is an X or another response key for any letter other than X (as a shorthand, we will refer to non-X stimuli as Y). In a go/no-go task, individuals are asked to press a response key when X is presented and to make no response otherwise. We address both tasks because they elicit slightly different decision-making behavior. In both tasks, Jones and Braver (2001) manipulated the relative frequency of the X and Y stimuli; the ratio of presentation frequency was either 17:83, 50:50, or 83:17. Response conﬂict arises when the two stimulus classes are unbalanced in frequency, resulting in more errors and slower reaction times. For example, when X’s are frequent but Y is presented, individuals are predisposed toward producing the X response, and this predisposition must be overcome by the perceptual evidence from the Y. Jones and Braver (2001) also performed an fMRI study of this task and found that anterior cingulate cortex (ACC) becomes activated in situations involving response conﬂict. Specifically, when one stimulus occurs infrequently relative to the other, event-related fMRI response in the ACC is greater for the low frequency stimulus. Jones and Braver also extended a neural network model of Botvinick, Braver, Barch, Carter, and Cohen (2001) to account for human performance in the two discrimination tasks. The heart of the model is a mechanism that monitors conﬂict—the posited role of the ACC—and adjusts response biases accordingly. In this paper, we develop a parsimonious alternative account of the role of the ACC and of how control processes modulate behavior when response conﬂict arises. 1 A RATIONAL ANALYSIS Our account is based on a rational analysis of human cognition, which views cognitive processes as being optimized with respect to certain task-related goals, and being adaptive to the structure of the environment (Anderson, 1990). We make three assumptions of rationality: (1) perceptual inference is optimal but is subject to rate limitations on information transmission, (2) response class prior probabilities are accurately estimated, and (3) the goal of individuals is to minimize a cost that depends both on error rate and reaction time. The heart of our account is an existing probabilistic model that explains a variety of facilitation effects that arise from long-term repetition priming (Colagrosso, in preparation; Mozer, Colagrosso, & Huber, 2000), and more broadly, that addresses changes in the nature of information transmission in neocortex due to experience. We give a brief overview of this model; the details are not essential for the present work. The model posits that neocortex can be characterized by a collection of informationprocessing pathways, and any act of cognition involves coordination among pathways. To model a simple discrimination task, we might suppose a perceptual pathway to map the visual input to a semantic representation, and a response pathway to map the semantic representation to a response. The choice and go/no-go tasks described earlier share a perceptual pathway, but require different response pathways. The model is framed in terms of probability theory: pathway inputs and outputs are random variables and microinference in a pathway is carried out by Bayesian belief revision.   To elaborate, consider a pathway whose input at time is a discrete random variable, denoted , which can assume values corresponding to alternative input states. Similarly, the output of the pathway at time is a discrete random variable, denoted , which can assume values . For example, the input to the perceptual pathway in the discrimination task is one of visual patterns corresponding to the letters of the alphabet, and the output is one of letter identities. (This model is highly abstract: the visual patterns are enumerated, but the actual pixel patterns are not explicitly represented in the model. Nonetheless, the similarity structure among inputs can be captured, but we skip a discussion of this issue because it is irrelevant for the current work.) To present a particular input alternative, , to the model for time steps, we clamp for . The model computes a probability distribution over given , i.e., P . ¡ # 4 0 ©2' &  0 ' ! 1)(</p><p>4 0.48603106 <a title="151-lsi-4" href="./nips-2001-Effective_Size_of_Receptive_Fields_of_Inferior_Temporal_Visual_Cortex_Neurons_in_Natural_Scenes.html">65 nips-2001-Effective Size of Receptive Fields of Inferior Temporal Visual Cortex Neurons in Natural Scenes</a></p>
<p>Author: Thomas P. Trappenberg, Edmund T. Rolls, Simon M. Stringer</p><p>Abstract: Inferior temporal cortex (IT) neurons have large receptive ﬁelds when a single effective object stimulus is shown against a blank background, but have much smaller receptive ﬁelds when the object is placed in a natural scene. Thus, translation invariant object recognition is reduced in natural scenes, and this may help object selection. We describe a model which accounts for this by competition within an attractor in which the neurons are tuned to different objects in the scene, and the fovea has a higher cortical magniﬁcation factor than the peripheral visual ﬁeld. Furthermore, we show that top-down object bias can increase the receptive ﬁeld size, facilitating object search in complex visual scenes, and providing a model of object-based attention. The model leads to the prediction that introduction of a second object into a scene with blank background will reduce the receptive ﬁeld size to values that depend on the closeness of the second object to the target stimulus. We suggest that mechanisms of this type enable the output of IT to be primarily about one object, so that the areas that receive from IT can select the object as a potential target for action.</p><p>5 0.46347409 <a title="151-lsi-5" href="./nips-2001-A_Maximum-Likelihood_Approach_to_Modeling_Multisensory_Enhancement.html">11 nips-2001-A Maximum-Likelihood Approach to Modeling Multisensory Enhancement</a></p>
<p>Author: H. Colonius, A. Diederich</p><p>Abstract: Multisensory response enhancement (MRE) is the augmentation of the response of a neuron to sensory input of one modality by simultaneous input from another modality. The maximum likelihood (ML) model presented here modifies the Bayesian model for MRE (Anastasio et al.) by incorporating a decision strategy to maximize the number of correct decisions. Thus the ML model can also deal with the important tasks of stimulus discrimination and identification in the presence of incongruent visual and auditory cues. It accounts for the inverse effectiveness observed in neurophysiological recording data, and it predicts a functional relation between uni- and bimodal levels of discriminability that is testable both in neurophysiological and behavioral experiments. 1</p><p>6 0.41964012 <a title="151-lsi-6" href="./nips-2001-Contextual_Modulation_of_Target_Saliency.html">54 nips-2001-Contextual Modulation of Target Saliency</a></p>
<p>7 0.40526193 <a title="151-lsi-7" href="./nips-2001-Group_Redundancy_Measures_Reveal_Redundancy_Reduction_in_the_Auditory_Pathway.html">87 nips-2001-Group Redundancy Measures Reveal Redundancy Reduction in the Auditory Pathway</a></p>
<p>8 0.40143543 <a title="151-lsi-8" href="./nips-2001-Linking_Motor_Learning_to_Function_Approximation%3A_Learning_in_an_Unlearnable_Force_Field.html">116 nips-2001-Linking Motor Learning to Function Approximation: Learning in an Unlearnable Force Field</a></p>
<p>9 0.39031845 <a title="151-lsi-9" href="./nips-2001-Modeling_the_Modulatory_Effect_of_Attention_on_Human_Spatial_Vision.html">124 nips-2001-Modeling the Modulatory Effect of Attention on Human Spatial Vision</a></p>
<p>10 0.38404763 <a title="151-lsi-10" href="./nips-2001-Spike_timing_and_the_coding_of_naturalistic_sounds_in_a_central_auditory_area_of_songbirds.html">174 nips-2001-Spike timing and the coding of naturalistic sounds in a central auditory area of songbirds</a></p>
<p>11 0.36356169 <a title="151-lsi-11" href="./nips-2001-Unsupervised_Learning_of_Human_Motion_Models.html">193 nips-2001-Unsupervised Learning of Human Motion Models</a></p>
<p>12 0.35814151 <a title="151-lsi-12" href="./nips-2001-Receptive_field_structure_of_flow_detectors_for_heading_perception.html">158 nips-2001-Receptive field structure of flow detectors for heading perception</a></p>
<p>13 0.35652757 <a title="151-lsi-13" href="./nips-2001-A_Rotation_and_Translation_Invariant_Discrete_Saliency_Network.html">19 nips-2001-A Rotation and Translation Invariant Discrete Saliency Network</a></p>
<p>14 0.33990818 <a title="151-lsi-14" href="./nips-2001-A_Neural_Oscillator_Model_of_Auditory_Selective_Attention.html">14 nips-2001-A Neural Oscillator Model of Auditory Selective Attention</a></p>
<p>15 0.33829004 <a title="151-lsi-15" href="./nips-2001-Learning_Body_Pose_via_Specialized_Maps.html">108 nips-2001-Learning Body Pose via Specialized Maps</a></p>
<p>16 0.32335675 <a title="151-lsi-16" href="./nips-2001-Generalizable_Relational_Binding_from_Coarse-coded_Distributed_Representations.html">80 nips-2001-Generalizable Relational Binding from Coarse-coded Distributed Representations</a></p>
<p>17 0.31488898 <a title="151-lsi-17" href="./nips-2001-Grammatical_Bigrams.html">86 nips-2001-Grammatical Bigrams</a></p>
<p>18 0.30666074 <a title="151-lsi-18" href="./nips-2001-Modeling_Temporal_Structure_in_Classical_Conditioning.html">123 nips-2001-Modeling Temporal Structure in Classical Conditioning</a></p>
<p>19 0.30274072 <a title="151-lsi-19" href="./nips-2001-The_Emergence_of_Multiple_Movement_Units_in_the_Presence_of_Noise_and_Feedback_Delay.html">181 nips-2001-The Emergence of Multiple Movement Units in the Presence of Noise and Feedback Delay</a></p>
<p>20 0.30244043 <a title="151-lsi-20" href="./nips-2001-Constructing_Distributed_Representations_Using_Additive_Clustering.html">53 nips-2001-Constructing Distributed Representations Using Additive Clustering</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2001_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.021), (19, 0.028), (27, 0.083), (30, 0.512), (38, 0.03), (59, 0.013), (72, 0.034), (79, 0.06), (83, 0.014), (91, 0.124)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.98425889 <a title="151-lda-1" href="./nips-2001-An_Efficient_Clustering_Algorithm_Using_Stochastic_Association_Model_and_Its_Implementation_Using_Nanostructures.html">33 nips-2001-An Efficient Clustering Algorithm Using Stochastic Association Model and Its Implementation Using Nanostructures</a></p>
<p>Author: Takashi Morie, Tomohiro Matsuura, Makoto Nagata, Atsushi Iwata</p><p>Abstract: This paper describes a clustering algorithm for vector quantizers using a “stochastic association model”. It offers a new simple and powerful softmax adaptation rule. The adaptation process is the same as the on-line K-means clustering method except for adding random ﬂuctuation in the distortion error evaluation process. Simulation results demonstrate that the new algorithm can achieve efﬁcient adaptation as high as the “neural gas” algorithm, which is reported as one of the most efﬁcient clustering methods. It is a key to add uncorrelated random ﬂuctuation in the similarity evaluation process for each reference vector. For hardware implementation of this process, we propose a nanostructure, whose operation is described by a single-electron circuit. It positively uses ﬂuctuation in quantum mechanical tunneling processes.</p><p>2 0.97723043 <a title="151-lda-2" href="./nips-2001-Speech_Recognition_with_Missing_Data_using_Recurrent_Neural_Nets.html">173 nips-2001-Speech Recognition with Missing Data using Recurrent Neural Nets</a></p>
<p>Author: S. Parveen, P. Green</p><p>Abstract: In the ‘missing data’ approach to improving the robustness of automatic speech recognition to added noise, an initial process identiﬁes spectraltemporal regions which are dominated by the speech source. The remaining regions are considered to be ‘missing’. In this paper we develop a connectionist approach to the problem of adapting speech recognition to the missing data case, using Recurrent Neural Networks. In contrast to methods based on Hidden Markov Models, RNNs allow us to make use of long-term time constraints and to make the problems of classiﬁcation with incomplete data and imputing missing values interact. We report encouraging results on an isolated digit recognition task.</p><p>3 0.96908218 <a title="151-lda-3" href="./nips-2001-Generating_velocity_tuning_by_asymmetric_recurrent_connections.html">82 nips-2001-Generating velocity tuning by asymmetric recurrent connections</a></p>
<p>Author: Xiaohui Xie, Martin A. Giese</p><p>Abstract: Asymmetric lateral connections are one possible mechanism that can account for the direction selectivity of cortical neurons. We present a mathematical analysis for a class of these models. Contrasting with earlier theoretical work that has relied on methods from linear systems theory, we study the network’s nonlinear dynamic properties that arise when the threshold nonlinearity of the neurons is taken into account. We show that such networks have stimulus-locked traveling pulse solutions that are appropriate for modeling the responses of direction selective cortical neurons. In addition, our analysis shows that outside a certain regime of stimulus speeds the stability of this solutions breaks down giving rise to another class of solutions that are characterized by speciﬁc spatiotemporal periodicity. This predicts that if direction selectivity in the cortex is mainly achieved by asymmetric lateral connections lurching activity waves might be observable in ensembles of direction selective cortical neurons within appropriate regimes of the stimulus speed.</p><p>4 0.95576936 <a title="151-lda-4" href="./nips-2001-Reducing_multiclass_to_binary_by_coupling_probability_estimates.html">159 nips-2001-Reducing multiclass to binary by coupling probability estimates</a></p>
<p>Author: B. Zadrozny</p><p>Abstract: This paper presents a method for obtaining class membership probability estimates for multiclass classiﬁcation problems by coupling the probability estimates produced by binary classiﬁers. This is an extension for arbitrary code matrices of a method due to Hastie and Tibshirani for pairwise coupling of probability estimates. Experimental results with Boosted Naive Bayes show that our method produces calibrated class membership probability estimates, while having similar classiﬁcation accuracy as loss-based decoding, a method for obtaining the most likely class that does not generate probability estimates.</p><p>5 0.94161236 <a title="151-lda-5" href="./nips-2001-Risk_Sensitive_Particle_Filters.html">163 nips-2001-Risk Sensitive Particle Filters</a></p>
<p>Author: Sebastian Thrun, John Langford, Vandi Verma</p><p>Abstract: We propose a new particle ﬁlter that incorporates a model of costs when generating particles. The approach is motivated by the observation that the costs of accidentally not tracking hypotheses might be signiﬁcant in some areas of state space, and next to irrelevant in others. By incorporating a cost model into particle ﬁltering, states that are more critical to the system performance are more likely to be tracked. Automatic calculation of the cost model is implemented using an MDP value function calculation that estimates the value of tracking a particular state. Experiments in two mobile robot domains illustrate the appropriateness of the approach.</p><p>same-paper 6 0.93940693 <a title="151-lda-6" href="./nips-2001-Probabilistic_principles_in_unsupervised_learning_of_visual_structure%3A_human_data_and_a_model.html">151 nips-2001-Probabilistic principles in unsupervised learning of visual structure: human data and a model</a></p>
<p>7 0.82679802 <a title="151-lda-7" href="./nips-2001-Effective_Size_of_Receptive_Fields_of_Inferior_Temporal_Visual_Cortex_Neurons_in_Natural_Scenes.html">65 nips-2001-Effective Size of Receptive Fields of Inferior Temporal Visual Cortex Neurons in Natural Scenes</a></p>
<p>8 0.8153367 <a title="151-lda-8" href="./nips-2001-Probabilistic_Abstraction_Hierarchies.html">149 nips-2001-Probabilistic Abstraction Hierarchies</a></p>
<p>9 0.80009449 <a title="151-lda-9" href="./nips-2001-Eye_movements_and_the_maturation_of_cortical_orientation_selectivity.html">73 nips-2001-Eye movements and the maturation of cortical orientation selectivity</a></p>
<p>10 0.76363701 <a title="151-lda-10" href="./nips-2001-KLD-Sampling%3A_Adaptive_Particle_Filters.html">102 nips-2001-KLD-Sampling: Adaptive Particle Filters</a></p>
<p>11 0.71412468 <a title="151-lda-11" href="./nips-2001-Dynamic_Time-Alignment_Kernel_in_Support_Vector_Machine.html">63 nips-2001-Dynamic Time-Alignment Kernel in Support Vector Machine</a></p>
<p>12 0.6936003 <a title="151-lda-12" href="./nips-2001-Categorization_by_Learning_and_Combining_Object_Parts.html">46 nips-2001-Categorization by Learning and Combining Object Parts</a></p>
<p>13 0.68777829 <a title="151-lda-13" href="./nips-2001-Computing_Time_Lower_Bounds_for_Recurrent_Sigmoidal_Neural_Networks.html">52 nips-2001-Computing Time Lower Bounds for Recurrent Sigmoidal Neural Networks</a></p>
<p>14 0.68169713 <a title="151-lda-14" href="./nips-2001-Fast_and_Robust_Classification_using_Asymmetric_AdaBoost_and_a_Detector_Cascade.html">77 nips-2001-Fast and Robust Classification using Asymmetric AdaBoost and a Detector Cascade</a></p>
<p>15 0.6731835 <a title="151-lda-15" href="./nips-2001-Stochastic_Mixed-Signal_VLSI_Architecture_for_High-Dimensional_Kernel_Machines.html">176 nips-2001-Stochastic Mixed-Signal VLSI Architecture for High-Dimensional Kernel Machines</a></p>
<p>16 0.6728071 <a title="151-lda-16" href="./nips-2001-A_Sequence_Kernel_and_its_Application_to_Speaker_Recognition.html">20 nips-2001-A Sequence Kernel and its Application to Speaker Recognition</a></p>
<p>17 0.66720337 <a title="151-lda-17" href="./nips-2001-Discriminative_Direction_for_Kernel_Classifiers.html">60 nips-2001-Discriminative Direction for Kernel Classifiers</a></p>
<p>18 0.66454542 <a title="151-lda-18" href="./nips-2001-Analog_Soft-Pattern-Matching_Classifier_using_Floating-Gate_MOS_Technology.html">34 nips-2001-Analog Soft-Pattern-Matching Classifier using Floating-Gate MOS Technology</a></p>
<p>19 0.66121638 <a title="151-lda-19" href="./nips-2001-Relative_Density_Nets%3A_A_New_Way_to_Combine_Backpropagation_with_HMM%27s.html">162 nips-2001-Relative Density Nets: A New Way to Combine Backpropagation with HMM's</a></p>
<p>20 0.65494186 <a title="151-lda-20" href="./nips-2001-ALGONQUIN_-_Learning_Dynamic_Noise_Models_From_Noisy_Speech_for_Robust_Speech_Recognition.html">4 nips-2001-ALGONQUIN - Learning Dynamic Noise Models From Noisy Speech for Robust Speech Recognition</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
