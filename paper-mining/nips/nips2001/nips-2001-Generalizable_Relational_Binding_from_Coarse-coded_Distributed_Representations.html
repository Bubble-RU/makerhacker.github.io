<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>80 nips-2001-Generalizable Relational Binding from Coarse-coded Distributed Representations</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2001" href="../home/nips2001_home.html">nips2001</a> <a title="nips-2001-80" href="#">nips2001-80</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>80 nips-2001-Generalizable Relational Binding from Coarse-coded Distributed Representations</h1>
<br/><p>Source: <a title="nips-2001-80-pdf" href="http://papers.nips.cc/paper/1942-generalizable-relational-binding-from-coarse-coded-distributed-representations.pdf">pdf</a></p><p>Author: Randall C. O'Reilly, R. S. Busby</p><p>Abstract: We present a model of binding of relationship information in a spatial domain (e.g., square above triangle) that uses low-order coarse-coded conjunctive representations instead of more popular temporal synchrony mechanisms. Supporters of temporal synchrony argue that conjunctive representations lack both efﬁciency (i.e., combinatorial numbers of units are required) and systematicity (i.e., the resulting representations are overly speciﬁc and thus do not support generalization to novel exemplars). To counter these claims, we show that our model: a) uses far fewer hidden units than the number of conjunctions represented, by using coarse-coded, distributed representations where each unit has a broad tuning curve through high-dimensional conjunction space, and b) is capable of considerable generalization to novel inputs.</p><p>Reference: <a title="nips-2001-80-reference" href="../nips2001_reference/nips-2001-Generalizable_Relational_Binding_from_Coarse-coded_Distributed_Representations_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 EDU  Abstract We present a model of binding of relationship information in a spatial domain (e. [sent-7, score-0.474]
</p><p>2 , square above triangle) that uses low-order coarse-coded conjunctive representations instead of more popular temporal synchrony mechanisms. [sent-9, score-0.587]
</p><p>3 Supporters of temporal synchrony argue that conjunctive representations lack both efﬁciency (i. [sent-10, score-0.514]
</p><p>4 , combinatorial numbers of units are required) and systematicity (i. [sent-12, score-0.171]
</p><p>5 , the resulting representations are overly speciﬁc and thus do not support generalization to novel exemplars). [sent-14, score-0.435]
</p><p>6 1 Introduction The binding problem as it is classically conceived arises when different pieces of information are processed by entirely separate units. [sent-16, score-0.327]
</p><p>7 For example, we can imagine there are neurons that separately code for the shape and color of objects, and we are viewing a scene having a red triangle and a blue square (Figure 1). [sent-17, score-0.517]
</p><p>8 Because color and shape are encoded separately in this system, the internal representations do not discriminate this situation from one where we are viewing a red square and a blue triangle. [sent-18, score-0.685]
</p><p>9 Perhaps the most popular solution is to imagine that binding is encoded by some kind of transient signal, such as temporal synchrony (e. [sent-21, score-0.448]
</p><p>10 Under this solution, the red and triangle units should ﬁre together, as should the blue and square units, with each group ﬁring out of phase with the other. [sent-24, score-0.589]
</p><p>11 Instead, one can imagine that color and shape information are encoded together (i. [sent-26, score-0.116]
</p><p>12 In the red-triangle blue-square example, some neurons encode the conjunction of red and triangle, while others encode the conjunction of blue and square. [sent-29, score-0.336]
</p><p>13 Because these units are explicitly sensitive to these  a) Input activates features  Red  Blue  Triangle  b) But rest of brain doesn’t know which features go with each other  Square  ? [sent-30, score-0.279]
</p><p>14 Red  Blue  Triangle  Square  Figure 1: Illustration of the binding problem. [sent-32, score-0.327]
</p><p>15 a) Visual inputs (red triangle, blue square) activate separate representations of color and shape properties. [sent-33, score-0.511]
</p><p>16 b) However, just the mere activation of these features does not distinguish for the rest of the brain the alternative scenario of a blue triangle and a red square. [sent-34, score-0.522]
</p><p>17 Red is indicated by dashed outline and blue by a dotted outline. [sent-35, score-0.133]
</p><p>18 Obj1 and obj2 show the features of the two objects (R = Red, G = Green, B = Blue, S = Square, C = Circle, T = Triangle), and remaining columns show 6 localist units and one coarsecoded conjunctive unit. [sent-39, score-0.767]
</p><p>19 Adding this one conjunctive unit is enough to disambiguate the inputs. [sent-40, score-0.26]
</p><p>20 conjunctions, they will not ﬁre to a red square or a blue triangle, and thereby avoid the binding problem. [sent-41, score-0.658]
</p><p>21 The obvious problem with this solution, and one reason it has been largely rejected in the literature, is that it would appear to require far too many units to cover all of the possible conjunctions that need to be represented — a combinatorial explosion. [sent-42, score-0.272]
</p><p>22 However, the combinatorial explosion problem is predicated on another seductive notion — that separate units are used for each possible conjunction. [sent-43, score-0.213]
</p><p>23 In short, both the binding problem itself and the problem with the conjunctive solution derive from localist assumptions about neural coding. [sent-44, score-0.607]
</p><p>24 Therefore, the input is represented by a complex distributed pattern of activation over units, and each unit can exhibit varying levels of sensitivity to the featural conjunctions present in the input. [sent-46, score-0.41]
</p><p>25 The binding problem is largely avoided because a different pattern of activation will be present for a red-triangle, blue-square input as compared to a red-square, blue-triangle input. [sent-47, score-0.441]
</p><p>26 These kinds of distributed representations can be difﬁcult to understand. [sent-48, score-0.389]
</p><p>27 This is probably a signiﬁcant reason why the ability of distributed representations to resolve the binding problem goes under-appreciated. [sent-49, score-0.672]
</p><p>28 However, we can analyze special cases of these representations to gain some insight. [sent-50, score-0.238]
</p><p>29 Here, we add one additional distributed unit to an otherwise localist  featural encoding like that shown in Figure 1. [sent-52, score-0.309]
</p><p>30 This unit has a coarse-coded conjunctive representation, meaning that instead of coding for a single conjunction, it codes for several possible conjunctions. [sent-53, score-0.26]
</p><p>31 The table shows that if this set of conjunctions is chosen wisely, this single unit can enable the distributed pattern of activation across all units to distinguish between any two possible combinations of stimulus inputs. [sent-54, score-0.482]
</p><p>32 A more realistic system will have a larger number of partially redundant coarse-coded conjunctive units that will not require such precise representations from each unit. [sent-55, score-0.581]
</p><p>33 A similar demonstration was recently provided by Mel and Fiser (2000) in an analysis of distributed, low-order conjunctive representations (resembling “Wickelfeatures”; Wickelgren, 1969; Seidenberg & McClelland, 1989) in the domain of textual inputs. [sent-56, score-0.452]
</p><p>34 However, they did not demonstrate that a neural network learning mechanism would develop these representations, or that they could support systematic generalization to novel inputs. [sent-57, score-0.33]
</p><p>35 2 Learning Generalizable Relational Bindings We present here a series of models that test the ability of existing neural network learning mechanisms to develop low-order coarse-coded conjunctive representations in a challenging binding domain. [sent-58, score-0.883]
</p><p>36 Speciﬁcally, we focus on the problem of relational binding, which provides a link to higher-level cognitive function, and speaks to the continued use of structured representations in these domains. [sent-59, score-0.489]
</p><p>37 Furthermore, we conduct a critical test of these models in assessing their ability to generalize to novel inputs after moderate amounts of training. [sent-60, score-0.195]
</p><p>38 This is important because conjunctive representations might appear to limit generalization as these representations are more speciﬁc than purely localist representations. [sent-61, score-0.858]
</p><p>39 Indeed the inability to generalize is considered by some the primary limitation of conjunctive binding mechanisms (Holyoak & Hummel, 2000). [sent-62, score-0.632]
</p><p>40 1 Relational Binding, Structured Representations, and Higher-level Cognition A number of existing models rely on structured representations because they are regarded as essential for encoding complex relational information and other kinds of data structures that are used in symbolic models (e. [sent-64, score-0.546]
</p><p>41 A canonical example of a structured representation is a propositional encoding (e. [sent-69, score-0.191]
</p><p>42 , LIKES cats milk) that has a main relational term (LIKES) that operates on a set of slot-like arguments that specify the items entering into the relationship. [sent-71, score-0.148]
</p><p>43 The fundamental problem with structured representations, regardless of what implements them, is that they cannot be easily learned. [sent-75, score-0.107]
</p><p>44 There are good reasons to believe that this reﬂects basic tradeoffs between complex structured representations and powerful learning mechanisms (Elman, 1991; St John & McClelland, 1990; O’Reilly & Munakata, 2000). [sent-77, score-0.38]
</p><p>45 Essentially, structured representations are discrete and fragile, and therefore do not admit to gradual changes over learning. [sent-78, score-0.345]
</p><p>46 In contrast, the discrete character of structured representations requires exhaustive combinatorial search in high-dimensional spaces. [sent-80, score-0.387]
</p><p>47 To provide an alternative to these structured representations, our models test a simple example of relational encoding, focusing on easily-visualized spatial relationships, which can be thought of in propositional terms as for example (LEFT-OF square triangle). [sent-81, score-0.375]
</p><p>48 Hidden  Question  Input  Figure 2: Spatial relationship binding model. [sent-86, score-0.424]
</p><p>49 Objects are represented by distributed patterns of activation over 8 features per location within a 4x4 array of locations. [sent-87, score-0.426]
</p><p>50 The network answers questions posed by the Question input (“what”, “where”, and “what relationship? [sent-89, score-0.23]
</p><p>51 ”) — the answers require binding of object, location, and relationship information. [sent-90, score-0.465]
</p><p>52 3 Spatial Relationship Binding Model The spatial relationship binding model is shown in Figure 2. [sent-91, score-0.474]
</p><p>53 The overall framework for training the network is to present it with input patterns containing objects in different locations, and ask it various questions about these input displays. [sent-92, score-0.567]
</p><p>54 These questions ask about the identity and location of objects (i. [sent-93, score-0.574]
</p><p>55 To answer these questions correctly, the hidden layer must bind object, location, and relationship information accurately in the hidden layer. [sent-101, score-0.387]
</p><p>56 Otherwise, it will confuse the two objects and their locations and relationships. [sent-102, score-0.298]
</p><p>57 Furthermore, we encoded the objects using distributed representations over features, so these features must be correctly bound into the same object. [sent-103, score-0.726]
</p><p>58 Speciﬁcally, objects are represented by distributed patterns of activation over 8 features per location, in a 4x4 location array. [sent-104, score-0.673]
</p><p>59 The network answers different questions about the objects posed by the Question input. [sent-106, score-0.423]
</p><p>60 ” question, the location of one of the objects is activated as an input in the Location layer, and the network must produce the correct object features for the object in that location. [sent-108, score-1.145]
</p><p>61 We also refer to this target object as the agent object. [sent-109, score-0.472]
</p><p>62 ” question, the object features for the agent object are activated in the Object layer, and the network must produce the correct location activation for that object. [sent-111, score-1.143]
</p><p>63 ” question, the object features for the agent object are activated, and the network must activate the relationship between this object and the other object (referred to as the patient object), in addition to activating the location for the agent object. [sent-113, score-1.946]
</p><p>64 ” question, the location of the agent object is activated, and the network must activate the relationship between this object and the patient object, in addition to activating the object features for the agent object. [sent-115, score-1.713]
</p><p>65 For example, it has only one object and location encoding layer, both of which can act as either an input or an output. [sent-117, score-0.519]
</p><p>66 This is better than an alternative architecture having separate slots representing the agent and patient objects, because such slot-based encodings solve the binding problem by having separate role-speciﬁc units, which becomes implausible as the number of different roles and objects multiply. [sent-118, score-0.934]
</p><p>67 Note that supporting the dual input/output roles requires an interactive (recurrent, bidirectionally-connected) network (O’Reilly, 2001, 1998). [sent-119, score-0.151]
</p><p>68 There are four levels of questions we can ask about this network. [sent-137, score-0.143]
</p><p>69 First, we can ask if standard neural network learning mechanisms are capable of solving this challenging binding problem. [sent-138, score-0.508]
</p><p>70 Second, we can ask whether the network actually develops coarsecoded distributed representations. [sent-140, score-0.289]
</p><p>71 Third, we can ask if these networks can generalize to novel inputs (both novel objects and novel locations for existing objects). [sent-142, score-0.8]
</p><p>72 Finally, we can ask whether there are differences in how well different kinds of learning algorithms generalize, speciﬁcally comparing the Leabra algorithm with purely error-driven networks, as was recently done in other generalization tests with interactive networks (O’Reilly, 2001). [sent-144, score-0.345]
</p><p>73 These results are replicated here, with Leabra generalization being roughly twice as good as other interactive algorithms. [sent-146, score-0.252]
</p><p>74 a) shows results for testing on familiar objects in novel locations. [sent-162, score-0.386]
</p><p>75 b) shows results for testing on novel objects that were never trained before. [sent-163, score-0.342]
</p><p>76 1 Detailed Results First, we examined the representations that developed in the network’s hidden layer (Figure 3). [sent-165, score-0.347]
</p><p>77 Many units encoded low-order combinations (conjunctions) of object, location, and relationship features (Figure 3a & b). [sent-166, score-0.399]
</p><p>78 Other units also encoded more systematic representations of location without respect to objects (Figure 3c) and object features without respect to location (Figure 3d). [sent-168, score-1.413]
</p><p>79 To test the generalization capacity of the networks, we trained on only 26 of the 28 possible objects that can be composed out of 8 features with two units active, and only a subset of all 416 possible agent object x location combinations. [sent-169, score-1.209]
</p><p>80 For each agent object-location input, there are 150 different patient object-location combinations per agent object-location, and we trained on 4, 10, 20, and 40, selected at random, for each different level of agent object-location combination training. [sent-171, score-0.828]
</p><p>81 The ability of the network to generalize to the 26 familiar objects in novel locations was tested by measuring performance on a random sample of 640 of the untrained agent objectlocation combinations. [sent-175, score-0.801]
</p><p>82 As one would expect, the number of training patterns improves generalization in a roughly proportional manner. [sent-177, score-0.17]
</p><p>83 Importantly, the network is able to generalize to a high level of performance, getting roughly 95% correct after training on only 25% of the training space (400x40), and achieving roughly 80% correct after training on only roughly 10% of the space (300x20). [sent-178, score-0.329]
</p><p>84 The ability of the network to generalize to novel objects was tested by simply presenting the two novel objects as agents in all possible locations, with a random sampling of 20 different patients (which were the familiar objects), for a total of 640 different testing items (Figure 4b). [sent-179, score-0.95]
</p><p>85 Generalization on these novel objects was roughly comparable to the familiar objects, except there was an apparent ceiling point at roughly 15% generalization error where the generalization did not improve even with more training. [sent-180, score-0.726]
</p><p>86 Overall, the network performed remarkably well on these novel objects, and future work will explore generalization with fewer training objects. [sent-181, score-0.266]
</p><p>87 of Patients Per Agent, Location  Figure 5: Generalization results for different algorithms on the spatial relationship binding task (see previous ﬁgure for details on measures) in the 400 x 10 or 20 conditions. [sent-188, score-0.474]
</p><p>88 The results for CHL (Figure 5) replicated earlier results (O’Reilly, 2001) in showing that the additional biases in Leabra produced roughly twice as good of generalization performance compared to CHL. [sent-193, score-0.17]
</p><p>89 4 Discussion These networks demonstrate that existing, powerful neural network learning algorithms can learn representations that perform complex relational binding of information. [sent-194, score-0.783]
</p><p>90 Speciﬁcally, these networks had to bind together object identity, location, and relationship information to answer a number of questions about input displays containing two objects. [sent-195, score-0.539]
</p><p>91 This supports our contention that rich distributed representations containing coarse-coded conjunctive encodings can effectively perform binding. [sent-196, score-0.559]
</p><p>92 It is critical to appreciate that these distributed representations are highly efﬁcient, encoding over 62400 unique input conﬁgurations with only 200 hidden units. [sent-197, score-0.513]
</p><p>93 Furthermore, these representations are systematic, in that they support generalization to novel inputs after training on a fraction of the input space. [sent-198, score-0.533]
</p><p>94 One early example of such an application is the St John and McClelland (1990) sentence gestalt model, which was able to sequentially process words in a sentence and construct a distributed internal representation of the meaning of the sentence (the sentence gestalt). [sent-200, score-0.343]
</p><p>95 We plan to extend this model to handle a more complex corpus of sentences to more fully push the relational binding capacities of the model. [sent-203, score-0.436]
</p><p>96 Finally, it is important to emphasize that we do not think that these low-order conjunctive representations are entirely sufﬁcient to resolve the binding problems that arise in the cortex. [sent-204, score-0.779]
</p><p>97 The interaction between such a selective attentional system and a complex object recognition system was modeled in O’Reilly and Munakata (2000). [sent-208, score-0.233]
</p><p>98 In this model, selective attention was an emergent process deriving from excitatory interac-  tions between a spatial processing pathway and the object processing pathway, combined with surround inhibition as implemented by inhibitory interneurons. [sent-209, score-0.283]
</p><p>99 The resulting model was capable of sequentially processing individual objects when multiple such objects were simultaneously present in the input. [sent-210, score-0.494]
</p><p>100 Distributed representations of structure: A theory of analogical access and mapping. [sent-260, score-0.238]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('binding', 0.327), ('objects', 0.247), ('agent', 0.239), ('representations', 0.238), ('object', 0.233), ('conjunctive', 0.214), ('reilly', 0.197), ('location', 0.184), ('leabra', 0.148), ('blue', 0.133), ('mcclelland', 0.132), ('units', 0.129), ('triangle', 0.129), ('red', 0.125), ('locs', 0.125), ('relational', 0.109), ('structured', 0.107), ('distributed', 0.107), ('hummel', 0.104), ('generalization', 0.102), ('conjunctions', 0.101), ('gs', 0.099), ('relationship', 0.097), ('novel', 0.095), ('munakata', 0.09), ('holyoak', 0.09), ('rlab', 0.083), ('rc', 0.082), ('interactive', 0.082), ('ask', 0.077), ('features', 0.075), ('square', 0.073), ('patient', 0.072), ('bt', 0.07), ('network', 0.069), ('roughly', 0.068), ('questions', 0.066), ('localist', 0.066), ('hidden', 0.066), ('systematic', 0.064), ('chl', 0.062), ('objs', 0.062), ('rel', 0.062), ('spat', 0.062), ('synchrony', 0.062), ('question', 0.062), ('gt', 0.061), ('activation', 0.06), ('encoded', 0.059), ('sentence', 0.059), ('gc', 0.058), ('patients', 0.058), ('color', 0.057), ('generalize', 0.056), ('input', 0.054), ('locations', 0.051), ('rs', 0.05), ('boulder', 0.05), ('activated', 0.05), ('spatial', 0.05), ('bind', 0.049), ('slots', 0.049), ('bs', 0.049), ('bc', 0.049), ('encoding', 0.048), ('relation', 0.047), ('rumelhart', 0.046), ('unit', 0.046), ('inputs', 0.044), ('kinds', 0.044), ('rt', 0.044), ('familiar', 0.044), ('layer', 0.043), ('combinatorial', 0.042), ('ajjanagadde', 0.042), ('fam', 0.042), ('featural', 0.042), ('konig', 0.042), ('malsburg', 0.042), ('seductive', 0.042), ('shastri', 0.042), ('answers', 0.041), ('networks', 0.04), ('conjunction', 0.039), ('activate', 0.039), ('items', 0.039), ('combinations', 0.039), ('bindings', 0.036), ('coarsecoded', 0.036), ('generalizable', 0.036), ('ucb', 0.036), ('wickelgren', 0.036), ('engel', 0.036), ('likes', 0.036), ('propositional', 0.036), ('hebbian', 0.035), ('cognitive', 0.035), ('mechanisms', 0.035), ('cally', 0.034), ('seidenberg', 0.033)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000006 <a title="80-tfidf-1" href="./nips-2001-Generalizable_Relational_Binding_from_Coarse-coded_Distributed_Representations.html">80 nips-2001-Generalizable Relational Binding from Coarse-coded Distributed Representations</a></p>
<p>Author: Randall C. O'Reilly, R. S. Busby</p><p>Abstract: We present a model of binding of relationship information in a spatial domain (e.g., square above triangle) that uses low-order coarse-coded conjunctive representations instead of more popular temporal synchrony mechanisms. Supporters of temporal synchrony argue that conjunctive representations lack both efﬁciency (i.e., combinatorial numbers of units are required) and systematicity (i.e., the resulting representations are overly speciﬁc and thus do not support generalization to novel exemplars). To counter these claims, we show that our model: a) uses far fewer hidden units than the number of conjunctions represented, by using coarse-coded, distributed representations where each unit has a broad tuning curve through high-dimensional conjunction space, and b) is capable of considerable generalization to novel inputs.</p><p>2 0.2729204 <a title="80-tfidf-2" href="./nips-2001-A_Model_of_the_Phonological_Loop%3A_Generalization_and_Binding.html">12 nips-2001-A Model of the Phonological Loop: Generalization and Binding</a></p>
<p>Author: Randall C. O'Reilly, R. Soto</p><p>Abstract: We present a neural network model that shows how the prefrontal cortex, interacting with the basal ganglia, can maintain a sequence of phonological information in activation-based working memory (i.e., the phonological loop). The primary function of this phonological loop may be to transiently encode arbitrary bindings of information necessary for tasks - the combinatorial expressive power of language enables very flexible binding of essentially arbitrary pieces of information. Our model takes advantage of the closed-class nature of phonemes, which allows different neural representations of all possible phonemes at each sequential position to be encoded. To make this work, we suggest that the basal ganglia provide a region-specific update signal that allocates phonemes to the appropriate sequential coding slot. To demonstrate that flexible, arbitrary binding of novel sequences can be supported by this mechanism, we show that the model can generalize to novel sequences after moderate amounts of training. 1</p><p>3 0.20531452 <a title="80-tfidf-3" href="./nips-2001-Effective_Size_of_Receptive_Fields_of_Inferior_Temporal_Visual_Cortex_Neurons_in_Natural_Scenes.html">65 nips-2001-Effective Size of Receptive Fields of Inferior Temporal Visual Cortex Neurons in Natural Scenes</a></p>
<p>Author: Thomas P. Trappenberg, Edmund T. Rolls, Simon M. Stringer</p><p>Abstract: Inferior temporal cortex (IT) neurons have large receptive ﬁelds when a single effective object stimulus is shown against a blank background, but have much smaller receptive ﬁelds when the object is placed in a natural scene. Thus, translation invariant object recognition is reduced in natural scenes, and this may help object selection. We describe a model which accounts for this by competition within an attractor in which the neurons are tuned to different objects in the scene, and the fovea has a higher cortical magniﬁcation factor than the peripheral visual ﬁeld. Furthermore, we show that top-down object bias can increase the receptive ﬁeld size, facilitating object search in complex visual scenes, and providing a model of object-based attention. The model leads to the prediction that introduction of a second object into a scene with blank background will reduce the receptive ﬁeld size to values that depend on the closeness of the second object to the target stimulus. We suggest that mechanisms of this type enable the output of IT to be primarily about one object, so that the areas that receive from IT can select the object as a potential target for action.</p><p>4 0.19170409 <a title="80-tfidf-4" href="./nips-2001-Contextual_Modulation_of_Target_Saliency.html">54 nips-2001-Contextual Modulation of Target Saliency</a></p>
<p>Author: Antonio Torralba</p><p>Abstract: The most popular algorithms for object detection require the use of exhaustive spatial and scale search procedures. In such approaches, an object is defined by means of local features. fu this paper we show that including contextual information in object detection procedures provides an efficient way of cutting down the need for exhaustive search. We present results with real images showing that the proposed scheme is able to accurately predict likely object classes, locations and sizes. 1</p><p>5 0.11600272 <a title="80-tfidf-5" href="./nips-2001-Learning_Lateral_Interactions_for_Feature_Binding_and_Sensory_Segmentation.html">111 nips-2001-Learning Lateral Interactions for Feature Binding and Sensory Segmentation</a></p>
<p>Author: Heiko Wersing</p><p>Abstract: We present a new approach to the supervised learning of lateral interactions for the competitive layer model (CLM) dynamic feature binding architecture. The method is based on consistency conditions, which were recently shown to characterize the attractor states of this linear threshold recurrent network. For a given set of training examples the learning problem is formulated as a convex quadratic optimization problem in the lateral interaction weights. An efﬁcient dimension reduction of the learning problem can be achieved by using a linear superposition of basis interactions. We show the successful application of the method to a medical image segmentation problem of ﬂuorescence microscope cell images.</p><p>6 0.11540829 <a title="80-tfidf-6" href="./nips-2001-Reinforcement_Learning_with_Long_Short-Term_Memory.html">161 nips-2001-Reinforcement Learning with Long Short-Term Memory</a></p>
<p>7 0.11368722 <a title="80-tfidf-7" href="./nips-2001-Multiagent_Planning_with_Factored_MDPs.html">128 nips-2001-Multiagent Planning with Factored MDPs</a></p>
<p>8 0.1016895 <a title="80-tfidf-8" href="./nips-2001-Rates_of_Convergence_of_Performance_Gradient_Estimates_Using_Function_Approximation_and_Bias_in_Reinforcement_Learning.html">157 nips-2001-Rates of Convergence of Performance Gradient Estimates Using Function Approximation and Bias in Reinforcement Learning</a></p>
<p>9 0.098063946 <a title="80-tfidf-9" href="./nips-2001-Categorization_by_Learning_and_Combining_Object_Parts.html">46 nips-2001-Categorization by Learning and Combining Object Parts</a></p>
<p>10 0.088550426 <a title="80-tfidf-10" href="./nips-2001-Learning_Hierarchical_Structures_with_Linear_Relational_Embedding.html">110 nips-2001-Learning Hierarchical Structures with Linear Relational Embedding</a></p>
<p>11 0.081762105 <a title="80-tfidf-11" href="./nips-2001-Constructing_Distributed_Representations_Using_Additive_Clustering.html">53 nips-2001-Constructing Distributed Representations Using Additive Clustering</a></p>
<p>12 0.081731282 <a title="80-tfidf-12" href="./nips-2001-Probabilistic_principles_in_unsupervised_learning_of_visual_structure%3A_human_data_and_a_model.html">151 nips-2001-Probabilistic principles in unsupervised learning of visual structure: human data and a model</a></p>
<p>13 0.078818947 <a title="80-tfidf-13" href="./nips-2001-A_Bayesian_Model_Predicts_Human_Parse_Preference_and_Reading_Times_in_Sentence_Processing.html">5 nips-2001-A Bayesian Model Predicts Human Parse Preference and Reading Times in Sentence Processing</a></p>
<p>14 0.078774087 <a title="80-tfidf-14" href="./nips-2001-Computing_Time_Lower_Bounds_for_Recurrent_Sigmoidal_Neural_Networks.html">52 nips-2001-Computing Time Lower Bounds for Recurrent Sigmoidal Neural Networks</a></p>
<p>15 0.068730511 <a title="80-tfidf-15" href="./nips-2001-Transform-invariant_Image_Decomposition_with_Similarity_Templates.html">191 nips-2001-Transform-invariant Image Decomposition with Similarity Templates</a></p>
<p>16 0.064026207 <a title="80-tfidf-16" href="./nips-2001-A_Rotation_and_Translation_Invariant_Discrete_Saliency_Network.html">19 nips-2001-A Rotation and Translation Invariant Discrete Saliency Network</a></p>
<p>17 0.055243406 <a title="80-tfidf-17" href="./nips-2001-The_Fidelity_of_Local_Ordinal_Encoding.html">182 nips-2001-The Fidelity of Local Ordinal Encoding</a></p>
<p>18 0.054103758 <a title="80-tfidf-18" href="./nips-2001-Unsupervised_Learning_of_Human_Motion_Models.html">193 nips-2001-Unsupervised Learning of Human Motion Models</a></p>
<p>19 0.05376273 <a title="80-tfidf-19" href="./nips-2001-Product_Analysis%3A_Learning_to_Model_Observations_as_Products_of_Hidden_Variables.html">153 nips-2001-Product Analysis: Learning to Model Observations as Products of Hidden Variables</a></p>
<p>20 0.052696783 <a title="80-tfidf-20" href="./nips-2001-Convolution_Kernels_for_Natural_Language.html">56 nips-2001-Convolution Kernels for Natural Language</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2001_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.186), (1, -0.144), (2, -0.027), (3, 0.037), (4, -0.127), (5, 0.026), (6, -0.284), (7, -0.034), (8, -0.083), (9, 0.013), (10, -0.113), (11, 0.153), (12, 0.135), (13, -0.012), (14, -0.009), (15, 0.152), (16, 0.223), (17, -0.096), (18, 0.037), (19, -0.008), (20, 0.137), (21, -0.097), (22, -0.089), (23, 0.27), (24, 0.037), (25, 0.024), (26, 0.073), (27, 0.089), (28, 0.074), (29, -0.031), (30, -0.137), (31, -0.074), (32, -0.021), (33, 0.034), (34, -0.103), (35, -0.001), (36, 0.039), (37, -0.053), (38, -0.01), (39, 0.156), (40, 0.035), (41, 0.036), (42, -0.158), (43, 0.102), (44, -0.07), (45, 0.025), (46, 0.055), (47, 0.052), (48, -0.009), (49, 0.054)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98023152 <a title="80-lsi-1" href="./nips-2001-Generalizable_Relational_Binding_from_Coarse-coded_Distributed_Representations.html">80 nips-2001-Generalizable Relational Binding from Coarse-coded Distributed Representations</a></p>
<p>Author: Randall C. O'Reilly, R. S. Busby</p><p>Abstract: We present a model of binding of relationship information in a spatial domain (e.g., square above triangle) that uses low-order coarse-coded conjunctive representations instead of more popular temporal synchrony mechanisms. Supporters of temporal synchrony argue that conjunctive representations lack both efﬁciency (i.e., combinatorial numbers of units are required) and systematicity (i.e., the resulting representations are overly speciﬁc and thus do not support generalization to novel exemplars). To counter these claims, we show that our model: a) uses far fewer hidden units than the number of conjunctions represented, by using coarse-coded, distributed representations where each unit has a broad tuning curve through high-dimensional conjunction space, and b) is capable of considerable generalization to novel inputs.</p><p>2 0.82175291 <a title="80-lsi-2" href="./nips-2001-A_Model_of_the_Phonological_Loop%3A_Generalization_and_Binding.html">12 nips-2001-A Model of the Phonological Loop: Generalization and Binding</a></p>
<p>Author: Randall C. O'Reilly, R. Soto</p><p>Abstract: We present a neural network model that shows how the prefrontal cortex, interacting with the basal ganglia, can maintain a sequence of phonological information in activation-based working memory (i.e., the phonological loop). The primary function of this phonological loop may be to transiently encode arbitrary bindings of information necessary for tasks - the combinatorial expressive power of language enables very flexible binding of essentially arbitrary pieces of information. Our model takes advantage of the closed-class nature of phonemes, which allows different neural representations of all possible phonemes at each sequential position to be encoded. To make this work, we suggest that the basal ganglia provide a region-specific update signal that allocates phonemes to the appropriate sequential coding slot. To demonstrate that flexible, arbitrary binding of novel sequences can be supported by this mechanism, we show that the model can generalize to novel sequences after moderate amounts of training. 1</p><p>3 0.55342835 <a title="80-lsi-3" href="./nips-2001-Contextual_Modulation_of_Target_Saliency.html">54 nips-2001-Contextual Modulation of Target Saliency</a></p>
<p>Author: Antonio Torralba</p><p>Abstract: The most popular algorithms for object detection require the use of exhaustive spatial and scale search procedures. In such approaches, an object is defined by means of local features. fu this paper we show that including contextual information in object detection procedures provides an efficient way of cutting down the need for exhaustive search. We present results with real images showing that the proposed scheme is able to accurately predict likely object classes, locations and sizes. 1</p><p>4 0.5302313 <a title="80-lsi-4" href="./nips-2001-Effective_Size_of_Receptive_Fields_of_Inferior_Temporal_Visual_Cortex_Neurons_in_Natural_Scenes.html">65 nips-2001-Effective Size of Receptive Fields of Inferior Temporal Visual Cortex Neurons in Natural Scenes</a></p>
<p>Author: Thomas P. Trappenberg, Edmund T. Rolls, Simon M. Stringer</p><p>Abstract: Inferior temporal cortex (IT) neurons have large receptive ﬁelds when a single effective object stimulus is shown against a blank background, but have much smaller receptive ﬁelds when the object is placed in a natural scene. Thus, translation invariant object recognition is reduced in natural scenes, and this may help object selection. We describe a model which accounts for this by competition within an attractor in which the neurons are tuned to different objects in the scene, and the fovea has a higher cortical magniﬁcation factor than the peripheral visual ﬁeld. Furthermore, we show that top-down object bias can increase the receptive ﬁeld size, facilitating object search in complex visual scenes, and providing a model of object-based attention. The model leads to the prediction that introduction of a second object into a scene with blank background will reduce the receptive ﬁeld size to values that depend on the closeness of the second object to the target stimulus. We suggest that mechanisms of this type enable the output of IT to be primarily about one object, so that the areas that receive from IT can select the object as a potential target for action.</p><p>5 0.43422696 <a title="80-lsi-5" href="./nips-2001-Reinforcement_Learning_with_Long_Short-Term_Memory.html">161 nips-2001-Reinforcement Learning with Long Short-Term Memory</a></p>
<p>Author: Bram Bakker</p><p>Abstract: This paper presents reinforcement learning with a Long ShortTerm Memory recurrent neural network: RL-LSTM. Model-free RL-LSTM using Advantage(,x) learning and directed exploration can solve non-Markovian tasks with long-term dependencies between relevant events. This is demonstrated in a T-maze task, as well as in a difficult variation of the pole balancing task. 1</p><p>6 0.40090138 <a title="80-lsi-6" href="./nips-2001-Constructing_Distributed_Representations_Using_Additive_Clustering.html">53 nips-2001-Constructing Distributed Representations Using Additive Clustering</a></p>
<p>7 0.40028536 <a title="80-lsi-7" href="./nips-2001-Learning_Lateral_Interactions_for_Feature_Binding_and_Sensory_Segmentation.html">111 nips-2001-Learning Lateral Interactions for Feature Binding and Sensory Segmentation</a></p>
<p>8 0.38050032 <a title="80-lsi-8" href="./nips-2001-Learning_Hierarchical_Structures_with_Linear_Relational_Embedding.html">110 nips-2001-Learning Hierarchical Structures with Linear Relational Embedding</a></p>
<p>9 0.37260026 <a title="80-lsi-9" href="./nips-2001-The_Fidelity_of_Local_Ordinal_Encoding.html">182 nips-2001-The Fidelity of Local Ordinal Encoding</a></p>
<p>10 0.36178973 <a title="80-lsi-10" href="./nips-2001-Probabilistic_principles_in_unsupervised_learning_of_visual_structure%3A_human_data_and_a_model.html">151 nips-2001-Probabilistic principles in unsupervised learning of visual structure: human data and a model</a></p>
<p>11 0.35150599 <a title="80-lsi-11" href="./nips-2001-A_Bayesian_Model_Predicts_Human_Parse_Preference_and_Reading_Times_in_Sentence_Processing.html">5 nips-2001-A Bayesian Model Predicts Human Parse Preference and Reading Times in Sentence Processing</a></p>
<p>12 0.29761392 <a title="80-lsi-12" href="./nips-2001-A_Rotation_and_Translation_Invariant_Discrete_Saliency_Network.html">19 nips-2001-A Rotation and Translation Invariant Discrete Saliency Network</a></p>
<p>13 0.28671992 <a title="80-lsi-13" href="./nips-2001-Multiagent_Planning_with_Factored_MDPs.html">128 nips-2001-Multiagent Planning with Factored MDPs</a></p>
<p>14 0.26543853 <a title="80-lsi-14" href="./nips-2001-A_Rational_Analysis_of_Cognitive_Control_in_a_Speeded_Discrimination_Task.html">18 nips-2001-A Rational Analysis of Cognitive Control in a Speeded Discrimination Task</a></p>
<p>15 0.26277602 <a title="80-lsi-15" href="./nips-2001-ACh%2C_Uncertainty%2C_and_Cortical_Inference.html">3 nips-2001-ACh, Uncertainty, and Cortical Inference</a></p>
<p>16 0.25912464 <a title="80-lsi-16" href="./nips-2001-Grammar_Transfer_in_a_Second_Order_Recurrent_Neural_Network.html">85 nips-2001-Grammar Transfer in a Second Order Recurrent Neural Network</a></p>
<p>17 0.2580348 <a title="80-lsi-17" href="./nips-2001-Computing_Time_Lower_Bounds_for_Recurrent_Sigmoidal_Neural_Networks.html">52 nips-2001-Computing Time Lower Bounds for Recurrent Sigmoidal Neural Networks</a></p>
<p>18 0.24934444 <a title="80-lsi-18" href="./nips-2001-Active_Portfolio-Management_based_on_Error_Correction_Neural_Networks.html">26 nips-2001-Active Portfolio-Management based on Error Correction Neural Networks</a></p>
<p>19 0.24613535 <a title="80-lsi-19" href="./nips-2001-Self-regulation_Mechanism_of_Temporally_Asymmetric_Hebbian_Plasticity.html">166 nips-2001-Self-regulation Mechanism of Temporally Asymmetric Hebbian Plasticity</a></p>
<p>20 0.23994987 <a title="80-lsi-20" href="./nips-2001-Fast_Parameter_Estimation_Using_Green%27s_Functions.html">76 nips-2001-Fast Parameter Estimation Using Green's Functions</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2001_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.016), (19, 0.034), (27, 0.075), (30, 0.07), (38, 0.513), (59, 0.019), (72, 0.053), (79, 0.029), (83, 0.01), (91, 0.098)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95343912 <a title="80-lda-1" href="./nips-2001-Generalizable_Relational_Binding_from_Coarse-coded_Distributed_Representations.html">80 nips-2001-Generalizable Relational Binding from Coarse-coded Distributed Representations</a></p>
<p>Author: Randall C. O'Reilly, R. S. Busby</p><p>Abstract: We present a model of binding of relationship information in a spatial domain (e.g., square above triangle) that uses low-order coarse-coded conjunctive representations instead of more popular temporal synchrony mechanisms. Supporters of temporal synchrony argue that conjunctive representations lack both efﬁciency (i.e., combinatorial numbers of units are required) and systematicity (i.e., the resulting representations are overly speciﬁc and thus do not support generalization to novel exemplars). To counter these claims, we show that our model: a) uses far fewer hidden units than the number of conjunctions represented, by using coarse-coded, distributed representations where each unit has a broad tuning curve through high-dimensional conjunction space, and b) is capable of considerable generalization to novel inputs.</p><p>2 0.86347079 <a title="80-lda-2" href="./nips-2001-A_Rotation_and_Translation_Invariant_Discrete_Saliency_Network.html">19 nips-2001-A Rotation and Translation Invariant Discrete Saliency Network</a></p>
<p>Author: Lance R. Williams, John W. Zweck</p><p>Abstract: We describe a neural network which enhances and completes salient closed contours. Our work is different from all previous work in three important ways. First, like the input provided to V1 by LGN, the input to our computation is isotropic. That is, the input is composed of spots not edges. Second, our network computes a well deﬁned function of the input based on a distribution of closed contours characterized by a random process. Third, even though our computation is implemented in a discrete network, its output is invariant to continuous rotations and translations of the input pattern.</p><p>3 0.83055246 <a title="80-lda-3" href="./nips-2001-Exact_differential_equation_population_dynamics_for_integrate-and-fire_neurons.html">72 nips-2001-Exact differential equation population dynamics for integrate-and-fire neurons</a></p>
<p>Author: Julian Eggert, Berthold BĂ¤uml</p><p>Abstract: Mesoscopical, mathematical descriptions of dynamics of populations of spiking neurons are getting increasingly important for the understanding of large-scale processes in the brain using simulations. In our previous work, integral equation formulations for population dynamics have been derived for a special type of spiking neurons. For Integrate- and- Fire type neurons , these formulations were only approximately correct. Here, we derive a mathematically compact, exact population dynamics formulation for Integrate- and- Fire type neurons. It can be shown quantitatively in simulations that the numerical correspondence with microscopically modeled neuronal populations is excellent. 1 Introduction and motivation The goal of the population dynamics approach is to model the time course of the collective activity of entire populations of functionally and dynamically similar neurons in a compact way, using a higher descriptionallevel than that of single neurons and spikes. The usual observable at the level of neuronal populations is the populationaveraged instantaneous firing rate A(t), with A(t)6.t being the number of neurons in the population that release a spike in an interval [t, t+6.t). Population dynamics are formulated in such a way, that they match quantitatively the time course of a given A(t), either gained experimentally or by microscopical, detailed simulation. At least three main reasons can be formulated which underline the importance of the population dynamics approach for computational neuroscience. First, it enables the simulation of extensive networks involving a massive number of neurons and connections, which is typically the case when dealing with biologically realistic functional models that go beyond the single neuron level. Second, it increases the analytical understanding of large-scale neuronal dynamics , opening the way towards better control and predictive capabilities when dealing with large networks. Third, it enables a systematic embedding of the numerous neuronal models operating at different descriptional scales into a generalized theoretic framework, explaining the relationships, dependencies and derivations of the respective models. Early efforts on population dynamics approaches date back as early as 1972, to the work of Wilson and Cowan [8] and Knight [4], which laid the basis for all current population-averaged graded-response models (see e.g. [6] for modeling work using these models). More recently, population-based approaches for spiking neurons were developed, mainly by Gerstner [3, 2] and Knight [5]. In our own previous work [1], we have developed a theoretical framework which enables to systematize and simulate a wide range of models for population-based dynamics. It was shown that the equations of the framework produce results that agree quantitatively well with detailed simulations using spiking neurons, so that they can be used for realistic simulations involving networks with large numbers of spiking neurons. Nevertheless, for neuronal populations composed of Integrate-and-Fire (I&F;) neurons, this framework was only correct in an approximation. In this paper, we derive the exact population dynamics formulation for I&F; neurons. This is achieved by reducing the I&F; population dynamics to a point process and by taking advantage of the particular properties of I&F; neurons. 2 2.1 Background: Integrate-and-Fire dynamics Differential form We start with the standard Integrate- and- Fire (I&F;) model in form of the wellknown differential equation [7] (1) which describes the dynamics of the membrane potential Vi of a neuron i that is modeled as a single compartment with RC circuit characteristics. The membrane relaxation time is in this case T = RC with R being the membrane resistance and C the membrane capacitance. The resting potential v R est is the stationary potential that is approached in the no-input case. The input arriving from other neurons is described in form of a current ji. In addition to eq. (1), which describes the integrate part of the I&F; model, the neuronal dynamics are completed by a nonlinear step. Every time the membrane potential Vi reaches a fixed threshold () from below, Vi is lowered by a fixed amount Ll > 0, and from the new value of the membrane potential integration according to eq. (1) starts again. if Vi(t) = () (from below) . (2) At the same time, it is said that the release of a spike occurred (i.e., the neuron fired), and the time ti = t of this singular event is stored. Here ti indicates the time of the most recent spike. Storing all the last firing times , we gain the sequence of spikes {t{} (spike ordering index j, neuronal index i). 2.2 Integral form Now we look at the single neuron in a neuronal compound. We assume that the input current contribution ji from presynaptic spiking neurons can be described using the presynaptic spike times tf, a response-function ~ and a connection weight WÂˇ . ',J ji(t) = Wi ,j ~(t - tf) (3) l: l: j f Integrating the I&F; equation (1) beginning at the last spiking time tT, which determines the initial condition by Vi(ti) = vi(ti - 0) - 6., where vi(ti - 0) is the membrane potential just before the neuron spikes, we get 1 Vi(t) = v Rest + fj(t - t:) + l: Wi ,j l: a(t - t:; t - tf) , j - Vi(t:)) e- S / T (4) f with the refractory function fj(s) = - (v Rest (5) and the alpha-function r ds</p><p>4 0.53351545 <a title="80-lda-4" href="./nips-2001-A_Model_of_the_Phonological_Loop%3A_Generalization_and_Binding.html">12 nips-2001-A Model of the Phonological Loop: Generalization and Binding</a></p>
<p>Author: Randall C. O'Reilly, R. Soto</p><p>Abstract: We present a neural network model that shows how the prefrontal cortex, interacting with the basal ganglia, can maintain a sequence of phonological information in activation-based working memory (i.e., the phonological loop). The primary function of this phonological loop may be to transiently encode arbitrary bindings of information necessary for tasks - the combinatorial expressive power of language enables very flexible binding of essentially arbitrary pieces of information. Our model takes advantage of the closed-class nature of phonemes, which allows different neural representations of all possible phonemes at each sequential position to be encoded. To make this work, we suggest that the basal ganglia provide a region-specific update signal that allocates phonemes to the appropriate sequential coding slot. To demonstrate that flexible, arbitrary binding of novel sequences can be supported by this mechanism, we show that the model can generalize to novel sequences after moderate amounts of training. 1</p><p>5 0.49947751 <a title="80-lda-5" href="./nips-2001-Effective_Size_of_Receptive_Fields_of_Inferior_Temporal_Visual_Cortex_Neurons_in_Natural_Scenes.html">65 nips-2001-Effective Size of Receptive Fields of Inferior Temporal Visual Cortex Neurons in Natural Scenes</a></p>
<p>Author: Thomas P. Trappenberg, Edmund T. Rolls, Simon M. Stringer</p><p>Abstract: Inferior temporal cortex (IT) neurons have large receptive ﬁelds when a single effective object stimulus is shown against a blank background, but have much smaller receptive ﬁelds when the object is placed in a natural scene. Thus, translation invariant object recognition is reduced in natural scenes, and this may help object selection. We describe a model which accounts for this by competition within an attractor in which the neurons are tuned to different objects in the scene, and the fovea has a higher cortical magniﬁcation factor than the peripheral visual ﬁeld. Furthermore, we show that top-down object bias can increase the receptive ﬁeld size, facilitating object search in complex visual scenes, and providing a model of object-based attention. The model leads to the prediction that introduction of a second object into a scene with blank background will reduce the receptive ﬁeld size to values that depend on the closeness of the second object to the target stimulus. We suggest that mechanisms of this type enable the output of IT to be primarily about one object, so that the areas that receive from IT can select the object as a potential target for action.</p><p>6 0.48914766 <a title="80-lda-6" href="./nips-2001-Activity_Driven_Adaptive_Stochastic_Resonance.html">27 nips-2001-Activity Driven Adaptive Stochastic Resonance</a></p>
<p>7 0.46357891 <a title="80-lda-7" href="./nips-2001-Adaptive_Sparseness_Using_Jeffreys_Prior.html">29 nips-2001-Adaptive Sparseness Using Jeffreys Prior</a></p>
<p>8 0.45632276 <a title="80-lda-8" href="./nips-2001-Contextual_Modulation_of_Target_Saliency.html">54 nips-2001-Contextual Modulation of Target Saliency</a></p>
<p>9 0.45582807 <a title="80-lda-9" href="./nips-2001-Correlation_Codes_in_Neuronal_Populations.html">57 nips-2001-Correlation Codes in Neuronal Populations</a></p>
<p>10 0.42664915 <a title="80-lda-10" href="./nips-2001-The_Fidelity_of_Local_Ordinal_Encoding.html">182 nips-2001-The Fidelity of Local Ordinal Encoding</a></p>
<p>11 0.41835839 <a title="80-lda-11" href="./nips-2001-Categorization_by_Learning_and_Combining_Object_Parts.html">46 nips-2001-Categorization by Learning and Combining Object Parts</a></p>
<p>12 0.41419813 <a title="80-lda-12" href="./nips-2001-Learning_Hierarchical_Structures_with_Linear_Relational_Embedding.html">110 nips-2001-Learning Hierarchical Structures with Linear Relational Embedding</a></p>
<p>13 0.41278416 <a title="80-lda-13" href="./nips-2001-Computing_Time_Lower_Bounds_for_Recurrent_Sigmoidal_Neural_Networks.html">52 nips-2001-Computing Time Lower Bounds for Recurrent Sigmoidal Neural Networks</a></p>
<p>14 0.40008417 <a title="80-lda-14" href="./nips-2001-Orientation-Selective_aVLSI_Spiking_Neurons.html">141 nips-2001-Orientation-Selective aVLSI Spiking Neurons</a></p>
<p>15 0.39418495 <a title="80-lda-15" href="./nips-2001-Neural_Implementation_of_Bayesian_Inference_in_Population_Codes.html">131 nips-2001-Neural Implementation of Bayesian Inference in Population Codes</a></p>
<p>16 0.39063188 <a title="80-lda-16" href="./nips-2001-Reinforcement_Learning_with_Long_Short-Term_Memory.html">161 nips-2001-Reinforcement Learning with Long Short-Term Memory</a></p>
<p>17 0.38759008 <a title="80-lda-17" href="./nips-2001-Fast%2C_Large-Scale_Transformation-Invariant_Clustering.html">75 nips-2001-Fast, Large-Scale Transformation-Invariant Clustering</a></p>
<p>18 0.38523155 <a title="80-lda-18" href="./nips-2001-Rates_of_Convergence_of_Performance_Gradient_Estimates_Using_Function_Approximation_and_Bias_in_Reinforcement_Learning.html">157 nips-2001-Rates of Convergence of Performance Gradient Estimates Using Function Approximation and Bias in Reinforcement Learning</a></p>
<p>19 0.3789112 <a title="80-lda-19" href="./nips-2001-Bayesian_morphometry_of_hippocampal_cells_suggests_same-cell_somatodendritic_repulsion.html">42 nips-2001-Bayesian morphometry of hippocampal cells suggests same-cell somatodendritic repulsion</a></p>
<p>20 0.37728927 <a title="80-lda-20" href="./nips-2001-Why_Neuronal_Dynamics_Should_Control_Synaptic_Learning_Rules.html">197 nips-2001-Why Neuronal Dynamics Should Control Synaptic Learning Rules</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
