<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>106 nips-2001-Laplacian Eigenmaps and Spectral Techniques for Embedding and Clustering</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2001" href="../home/nips2001_home.html">nips2001</a> <a title="nips-2001-106" href="#">nips2001-106</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>106 nips-2001-Laplacian Eigenmaps and Spectral Techniques for Embedding and Clustering</h1>
<br/><p>Source: <a title="nips-2001-106-pdf" href="http://papers.nips.cc/paper/1961-laplacian-eigenmaps-and-spectral-techniques-for-embedding-and-clustering.pdf">pdf</a></p><p>Author: Mikhail Belkin, Partha Niyogi</p><p>Abstract: Drawing on the correspondence between the graph Laplacian, the Laplace-Beltrami op erator on a manifold , and the connections to the heat equation , we propose a geometrically motivated algorithm for constructing a representation for data sampled from a low dimensional manifold embedded in a higher dimensional space. The algorithm provides a computationally efficient approach to nonlinear dimensionality reduction that has locality preserving properties and a natural connection to clustering. Several applications are considered. In many areas of artificial intelligence, information retrieval and data mining, one is often confronted with intrinsically low dimensional data lying in a very high dimensional space. For example, gray scale n x n images of a fixed object taken with a moving camera yield data points in rn: n2 . However , the intrinsic dimensionality of the space of all images of t he same object is the number of degrees of freedom of the camera - in fact the space has the natural structure of a manifold embedded in rn: n2 . While there is a large body of work on dimensionality reduction in general, most existing approaches do not explicitly take into account the structure of the manifold on which the data may possibly reside. Recently, there has been some interest (Tenenbaum et aI, 2000 ; Roweis and Saul, 2000) in the problem of developing low dimensional representations of data in this particular context. In this paper , we present a new algorithm and an accompanying framework of analysis for geometrically motivated dimensionality reduction. The core algorithm is very simple, has a few local computations and one sparse eigenvalu e problem. The solution reflects th e intrinsic geom etric structure of the manifold. Th e justification comes from the role of the Laplacian op erator in providing an optimal emb edding. Th e Laplacian of the graph obtained from the data points may be viewed as an approximation to the Laplace-Beltrami operator defined on the manifold. The emb edding maps for the data come from approximations to a natural map that is defined on the entire manifold. The framework of analysis presented here makes this connection explicit. While this connection is known to geometers and specialists in sp ectral graph theory (for example , see [1, 2]) to the best of our knowledge we do not know of any application to data representation yet. The connection of the Laplacian to the heat kernel enables us to choose the weights of the graph in a principled manner. The locality preserving character of the Laplacian Eigenmap algorithm makes it relatively insensitive to outliers and noise. A byproduct of this is that the algorithm implicitly emphasizes the natural clusters in the data. Connections to spectral clustering algorithms developed in learning and computer vision (see Shi and Malik , 1997) become very clear. Following the discussion of Roweis and Saul (2000) , and Tenenbaum et al (2000), we note that the biological perceptual apparatus is confronted with high dimensional stimuli from which it must recover low dimensional structure. One might argue that if the approach to recovering such low-dimensional structure is inherently local , then a natural clustering will emerge and thus might serve as the basis for the development of categories in biological perception. 1 The Algorithm Given k points Xl , ... , Xk in ]]{ I, we construct a weighted graph with k nodes, one for each point , and the set of edges connecting neighboring points to each other. 1. Step 1. [Constru cting th e Graph] We put an edge between nodes i and j if Xi and Xj are</p><p>Reference: <a title="nips-2001-106-reference" href="../nips2001_reference/nips-2001-Laplacian_Eigenmaps_and_Spectral_Techniques_for_Embedding_and_Clustering_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('heat', 0.357), ('laplac', 0.348), ('eigenmap', 0.206), ('manifold', 0.191), ('ly', 0.182), ('exalllpl', 0.164), ('lr', 0.163), ('fm', 0.163), ('graph', 0.143), ('embed', 0.137), ('connect', 0.131), ('yj', 0.114), ('dimend', 0.109), ('ilx', 0.107), ('dii', 0.107), ('div', 0.107), ('semidefinit', 0.107), ('ht', 0.104), ('eigenvalu', 0.101), ('emb', 0.098)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.000001 <a title="106-tfidf-1" href="./nips-2001-Laplacian_Eigenmaps_and_Spectral_Techniques_for_Embedding_and_Clustering.html">106 nips-2001-Laplacian Eigenmaps and Spectral Techniques for Embedding and Clustering</a></p>
<p>2 0.18055397 <a title="106-tfidf-2" href="./nips-2001-On_Spectral_Clustering%3A_Analysis_and_an_algorithm.html">135 nips-2001-On Spectral Clustering: Analysis and an algorithm</a></p>
<p>3 0.17370532 <a title="106-tfidf-3" href="./nips-2001-Spectral_Kernel_Methods_for_Clustering.html">170 nips-2001-Spectral Kernel Methods for Clustering</a></p>
<p>4 0.16987577 <a title="106-tfidf-4" href="./nips-2001-Grouping_and_dimensionality_reduction_by_locally_linear_embedding.html">88 nips-2001-Grouping and dimensionality reduction by locally linear embedding</a></p>
<p>5 0.15255345 <a title="106-tfidf-5" href="./nips-2001-Global_Coordination_of_Local_Linear_Models.html">84 nips-2001-Global Coordination of Local Linear Models</a></p>
<p>6 0.14022918 <a title="106-tfidf-6" href="./nips-2001-On_the_Concentration_of_Spectral_Properties.html">136 nips-2001-On the Concentration of Spectral Properties</a></p>
<p>7 0.12087741 <a title="106-tfidf-7" href="./nips-2001-Grouping_with_Bias.html">89 nips-2001-Grouping with Bias</a></p>
<p>8 0.1030879 <a title="106-tfidf-8" href="./nips-2001-Sampling_Techniques_for_Kernel_Methods.html">164 nips-2001-Sampling Techniques for Kernel Methods</a></p>
<p>9 0.10098182 <a title="106-tfidf-9" href="./nips-2001-Spectral_Relaxation_for_K-means_Clustering.html">171 nips-2001-Spectral Relaxation for K-means Clustering</a></p>
<p>10 0.091438591 <a title="106-tfidf-10" href="./nips-2001-Adaptive_Sparseness_Using_Jeffreys_Prior.html">29 nips-2001-Adaptive Sparseness Using Jeffreys Prior</a></p>
<p>11 0.08183267 <a title="106-tfidf-11" href="./nips-2001-The_Method_of_Quantum_Clustering.html">185 nips-2001-The Method of Quantum Clustering</a></p>
<p>12 0.078025453 <a title="106-tfidf-12" href="./nips-2001-Partially_labeled_classification_with_Markov_random_walks.html">144 nips-2001-Partially labeled classification with Markov random walks</a></p>
<p>13 0.077472366 <a title="106-tfidf-13" href="./nips-2001-Discriminative_Direction_for_Kernel_Classifiers.html">60 nips-2001-Discriminative Direction for Kernel Classifiers</a></p>
<p>14 0.075350739 <a title="106-tfidf-14" href="./nips-2001-A_Variational_Approach_to_Learning_Curves.html">21 nips-2001-A Variational Approach to Learning Curves</a></p>
<p>15 0.07494925 <a title="106-tfidf-15" href="./nips-2001-K-Local_Hyperplane_and_Convex_Distance_Nearest_Neighbor_Algorithms.html">101 nips-2001-K-Local Hyperplane and Convex Distance Nearest Neighbor Algorithms</a></p>
<p>16 0.071910553 <a title="106-tfidf-16" href="./nips-2001-Face_Recognition_Using_Kernel_Methods.html">74 nips-2001-Face Recognition Using Kernel Methods</a></p>
<p>17 0.070577987 <a title="106-tfidf-17" href="./nips-2001-Adaptive_Nearest_Neighbor_Classification_Using_Support_Vector_Machines.html">28 nips-2001-Adaptive Nearest Neighbor Classification Using Support Vector Machines</a></p>
<p>18 0.069049425 <a title="106-tfidf-18" href="./nips-2001-Learning_Body_Pose_via_Specialized_Maps.html">108 nips-2001-Learning Body Pose via Specialized Maps</a></p>
<p>19 0.066242293 <a title="106-tfidf-19" href="./nips-2001-Small-World_Phenomena_and_the_Dynamics_of_Information.html">169 nips-2001-Small-World Phenomena and the Dynamics of Information</a></p>
<p>20 0.064504921 <a title="106-tfidf-20" href="./nips-2001-Unsupervised_Learning_of_Human_Motion_Models.html">193 nips-2001-Unsupervised Learning of Human Motion Models</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2001_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.232), (1, 0.051), (2, -0.057), (3, 0.157), (4, 0.126), (5, -0.044), (6, -0.033), (7, -0.028), (8, 0.021), (9, -0.032), (10, 0.004), (11, -0.011), (12, -0.038), (13, -0.092), (14, -0.128), (15, -0.038), (16, -0.152), (17, 0.076), (18, -0.098), (19, -0.076), (20, -0.1), (21, 0.117), (22, 0.029), (23, 0.032), (24, -0.034), (25, -0.009), (26, 0.053), (27, -0.016), (28, -0.154), (29, 0.021), (30, -0.018), (31, -0.08), (32, -0.002), (33, -0.03), (34, -0.014), (35, 0.02), (36, -0.134), (37, 0.068), (38, -0.038), (39, 0.025), (40, 0.044), (41, 0.002), (42, 0.07), (43, 0.123), (44, 0.072), (45, -0.128), (46, 0.063), (47, 0.029), (48, -0.091), (49, -0.041)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94290024 <a title="106-lsi-1" href="./nips-2001-Laplacian_Eigenmaps_and_Spectral_Techniques_for_Embedding_and_Clustering.html">106 nips-2001-Laplacian Eigenmaps and Spectral Techniques for Embedding and Clustering</a></p>
<p>2 0.8507908 <a title="106-lsi-2" href="./nips-2001-Grouping_and_dimensionality_reduction_by_locally_linear_embedding.html">88 nips-2001-Grouping and dimensionality reduction by locally linear embedding</a></p>
<p>3 0.59856749 <a title="106-lsi-3" href="./nips-2001-On_the_Concentration_of_Spectral_Properties.html">136 nips-2001-On the Concentration of Spectral Properties</a></p>
<p>4 0.56319076 <a title="106-lsi-4" href="./nips-2001-Global_Coordination_of_Local_Linear_Models.html">84 nips-2001-Global Coordination of Local Linear Models</a></p>
<p>5 0.48700663 <a title="106-lsi-5" href="./nips-2001-Grouping_with_Bias.html">89 nips-2001-Grouping with Bias</a></p>
<p>6 0.4617793 <a title="106-lsi-6" href="./nips-2001-K-Local_Hyperplane_and_Convex_Distance_Nearest_Neighbor_Algorithms.html">101 nips-2001-K-Local Hyperplane and Convex Distance Nearest Neighbor Algorithms</a></p>
<p>7 0.4446018 <a title="106-lsi-7" href="./nips-2001-On_Spectral_Clustering%3A_Analysis_and_an_algorithm.html">135 nips-2001-On Spectral Clustering: Analysis and an algorithm</a></p>
<p>8 0.4352304 <a title="106-lsi-8" href="./nips-2001-Spectral_Kernel_Methods_for_Clustering.html">170 nips-2001-Spectral Kernel Methods for Clustering</a></p>
<p>9 0.43474042 <a title="106-lsi-9" href="./nips-2001-Learning_Hierarchical_Structures_with_Linear_Relational_Embedding.html">110 nips-2001-Learning Hierarchical Structures with Linear Relational Embedding</a></p>
<p>10 0.41732293 <a title="106-lsi-10" href="./nips-2001-Spectral_Relaxation_for_K-means_Clustering.html">171 nips-2001-Spectral Relaxation for K-means Clustering</a></p>
<p>11 0.41325715 <a title="106-lsi-11" href="./nips-2001-Probabilistic_Abstraction_Hierarchies.html">149 nips-2001-Probabilistic Abstraction Hierarchies</a></p>
<p>12 0.40934193 <a title="106-lsi-12" href="./nips-2001-Geometrical_Singularities_in_the_Neuromanifold_of_Multilayer_Perceptrons.html">83 nips-2001-Geometrical Singularities in the Neuromanifold of Multilayer Perceptrons</a></p>
<p>13 0.39907086 <a title="106-lsi-13" href="./nips-2001-Partially_labeled_classification_with_Markov_random_walks.html">144 nips-2001-Partially labeled classification with Markov random walks</a></p>
<p>14 0.36952162 <a title="106-lsi-14" href="./nips-2001-Adaptive_Nearest_Neighbor_Classification_Using_Support_Vector_Machines.html">28 nips-2001-Adaptive Nearest Neighbor Classification Using Support Vector Machines</a></p>
<p>15 0.35662931 <a title="106-lsi-15" href="./nips-2001-The_Method_of_Quantum_Clustering.html">185 nips-2001-The Method of Quantum Clustering</a></p>
<p>16 0.35360804 <a title="106-lsi-16" href="./nips-2001-Matching_Free_Trees_with_Replicator_Equations.html">118 nips-2001-Matching Free Trees with Replicator Equations</a></p>
<p>17 0.35139915 <a title="106-lsi-17" href="./nips-2001-A_Generalization_of_Principal_Components_Analysis_to_the_Exponential_Family.html">9 nips-2001-A Generalization of Principal Components Analysis to the Exponential Family</a></p>
<p>18 0.35120699 <a title="106-lsi-18" href="./nips-2001-A_Variational_Approach_to_Learning_Curves.html">21 nips-2001-A Variational Approach to Learning Curves</a></p>
<p>19 0.34070629 <a title="106-lsi-19" href="./nips-2001-Learning_Body_Pose_via_Specialized_Maps.html">108 nips-2001-Learning Body Pose via Specialized Maps</a></p>
<p>20 0.332838 <a title="106-lsi-20" href="./nips-2001-Generating_velocity_tuning_by_asymmetric_recurrent_connections.html">82 nips-2001-Generating velocity tuning by asymmetric recurrent connections</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2001_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.03), (16, 0.146), (31, 0.04), (36, 0.029), (50, 0.053), (63, 0.018), (68, 0.018), (77, 0.016), (79, 0.016), (81, 0.448), (91, 0.047), (92, 0.061)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.76628685 <a title="106-lda-1" href="./nips-2001-Laplacian_Eigenmaps_and_Spectral_Techniques_for_Embedding_and_Clustering.html">106 nips-2001-Laplacian Eigenmaps and Spectral Techniques for Embedding and Clustering</a></p>
<p>2 0.58961302 <a title="106-lda-2" href="./nips-2001-Analysis_of_Sparse_Bayesian_Learning.html">35 nips-2001-Analysis of Sparse Bayesian Learning</a></p>
<p>3 0.58049548 <a title="106-lda-3" href="./nips-2001-Efficiency_versus_Convergence_of_Boolean_Kernels_for_On-Line_Learning_Algorithms.html">66 nips-2001-Efficiency versus Convergence of Boolean Kernels for On-Line Learning Algorithms</a></p>
<p>4 0.44309759 <a title="106-lda-4" href="./nips-2001-Global_Coordination_of_Local_Linear_Models.html">84 nips-2001-Global Coordination of Local Linear Models</a></p>
<p>5 0.43141198 <a title="106-lda-5" href="./nips-2001-Spectral_Relaxation_for_K-means_Clustering.html">171 nips-2001-Spectral Relaxation for K-means Clustering</a></p>
<p>6 0.42438453 <a title="106-lda-6" href="./nips-2001-On_Spectral_Clustering%3A_Analysis_and_an_algorithm.html">135 nips-2001-On Spectral Clustering: Analysis and an algorithm</a></p>
<p>7 0.42342141 <a title="106-lda-7" href="./nips-2001-Fast_Parameter_Estimation_Using_Green%27s_Functions.html">76 nips-2001-Fast Parameter Estimation Using Green's Functions</a></p>
<p>8 0.41558719 <a title="106-lda-8" href="./nips-2001-Orientational_and_Geometric_Determinants_of_Place_and_Head-direction.html">142 nips-2001-Orientational and Geometric Determinants of Place and Head-direction</a></p>
<p>9 0.41250026 <a title="106-lda-9" href="./nips-2001-Algorithmic_Luckiness.html">31 nips-2001-Algorithmic Luckiness</a></p>
<p>10 0.40777066 <a title="106-lda-10" href="./nips-2001-Grouping_and_dimensionality_reduction_by_locally_linear_embedding.html">88 nips-2001-Grouping and dimensionality reduction by locally linear embedding</a></p>
<p>11 0.40622157 <a title="106-lda-11" href="./nips-2001-Grouping_with_Bias.html">89 nips-2001-Grouping with Bias</a></p>
<p>12 0.40469733 <a title="106-lda-12" href="./nips-2001-Information_Geometrical_Framework_for_Analyzing_Belief_Propagation_Decoder.html">98 nips-2001-Information Geometrical Framework for Analyzing Belief Propagation Decoder</a></p>
<p>13 0.40019 <a title="106-lda-13" href="./nips-2001-Contextual_Modulation_of_Target_Saliency.html">54 nips-2001-Contextual Modulation of Target Saliency</a></p>
<p>14 0.39768788 <a title="106-lda-14" href="./nips-2001-Duality%2C_Geometry%2C_and_Support_Vector_Regression.html">62 nips-2001-Duality, Geometry, and Support Vector Regression</a></p>
<p>15 0.3970086 <a title="106-lda-15" href="./nips-2001-Active_Information_Retrieval.html">24 nips-2001-Active Information Retrieval</a></p>
<p>16 0.39668626 <a title="106-lda-16" href="./nips-2001-Motivated_Reinforcement_Learning.html">126 nips-2001-Motivated Reinforcement Learning</a></p>
<p>17 0.39667746 <a title="106-lda-17" href="./nips-2001-Using_Vocabulary_Knowledge_in_Bayesian_Multinomial_Estimation.html">194 nips-2001-Using Vocabulary Knowledge in Bayesian Multinomial Estimation</a></p>
<p>18 0.39633858 <a title="106-lda-18" href="./nips-2001-A_Quantitative_Model_of_Counterfactual_Reasoning.html">17 nips-2001-A Quantitative Model of Counterfactual Reasoning</a></p>
<p>19 0.39535534 <a title="106-lda-19" href="./nips-2001-Spectral_Kernel_Methods_for_Clustering.html">170 nips-2001-Spectral Kernel Methods for Clustering</a></p>
<p>20 0.39475831 <a title="106-lda-20" href="./nips-2001-Estimating_the_Reliability_of_ICA_Projections.html">71 nips-2001-Estimating the Reliability of ICA Projections</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
