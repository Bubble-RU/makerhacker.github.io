<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>145 nips-2001-Perceptual Metamers in Stereoscopic Vision</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2001" href="../home/nips2001_home.html">nips2001</a> <a title="nips-2001-145" href="#">nips2001-145</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>145 nips-2001-Perceptual Metamers in Stereoscopic Vision</h1>
<br/><p>Source: <a title="nips-2001-145-pdf" href="http://papers.nips.cc/paper/2067-perceptual-metamers-in-stereoscopic-vision.pdf">pdf</a></p><p>Author: B. T. Backus</p><p>Abstract: Theories of cue combination suggest the possibility of constructing visual stimuli that evoke different patterns of neural activity in sensory areas of the brain, but that cannot be distinguished by any behavioral measure of perception. Such stimuli, if they exist, would be interesting for two reasons. First, one could know that none of the differences between the stimuli survive past the computations used to build the percepts. Second, it can be difficult to distinguish stimulus-driven components of measured neural activity from top-down components (such as those due to the interestingness of the stimuli). Changing the stimulus without changing the percept could be exploited to measure the stimulusdriven activity. Here we describe stimuli in which vertical and horizontal disparities trade during the construction of percepts of slanted surfaces, yielding stimulus equivalence classes. Equivalence class membership changed after a change of vergence eye posture alone, without changes to the retinal images. A formal correspondence can be drawn between these “perceptual metamers” and more familiar “sensory metamers” such as color metamers. 1</p><p>Reference: <a title="nips-2001-145-reference" href="../nips2001_reference/nips-2001-Perceptual_Metamers_in_Stereoscopic_Vision_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract Theories of cue combination suggest the possibility of constructing visual stimuli that evoke different patterns of neural activity in sensory areas of the brain, but that cannot be distinguished by any behavioral measure of perception. [sent-4, score-0.489]
</p><p>2 First, one could know that none of the differences between the stimuli survive past the computations used to build the percepts. [sent-6, score-0.201]
</p><p>3 Here we describe stimuli in which vertical and horizontal disparities trade during the construction of percepts of slanted surfaces, yielding stimulus equivalence classes. [sent-9, score-0.79]
</p><p>4 Equivalence class membership changed after a change of vergence eye posture alone, without changes to the retinal images. [sent-10, score-0.503]
</p><p>5 1  Introduction  Two types of perceptual process might, in principle, map physically different visual stimuli onto the same percept. [sent-12, score-0.385]
</p><p>6 First, the visual system has a host of constancy mechanisms that extract information about the visual environment across uninteresting changes in the proximal stimulus. [sent-13, score-0.212]
</p><p>7 Recent cue conflict experiments have shown that the visual system’s estimate of a scene parameter, as evinced in a visual percept, is often simply a weighted average of the parameter as specified by each cue separately [1][2]. [sent-16, score-0.363]
</p><p>8 When a vertical magnifier is placed before one eye, a truly frontoparallel surface appears slanted. [sent-21, score-0.422]
</p><p>9 Adding horizontal magnification in the same eye restores frontoparallel appearance. [sent-22, score-0.652]
</p><p>10 The original stimulus and the magnified stimulus therefore have different patterns of binocular disparity but give rise to similar judgments of surface slant [3]. [sent-23, score-1.141]
</p><p>11 We show here that such stimuli are perceptually indistinguishable to practiced observers in a psychophysical discrimination task, which implies the loss of some disparity information. [sent-24, score-0.636]
</p><p>12 This loss could occur, first, in a well-studied constancy mechanism that uses vertical disparity to correct the depth relief pattern associated with horizontal disparity [4]. [sent-25, score-1.006]
</p><p>13 However, the amount of horizontal magnification needed to null vertical magnification is less than would be predicted from use of this constancy mechanism alone; a second constancy mechanism exists that corrects horizontal disparities by using felt eye position, not vertical disparity [5]. [sent-26, score-1.943]
</p><p>14 Adding vertical magnification without changing eye position therefore creates a cue conflict stimulus. [sent-27, score-0.774]
</p><p>15 2  Stereoscopic slant perception: review of theory  The stereo component of the perceived slant of a random-dot surface can be modeled as the visual system’s weighted average of two stereo slant estimates [5][ 6]. [sent-29, score-2.145]
</p><p>16 Horizontal disparity is ambiguous because it depends not only on surface slant, but also on surface patch location relative to the head. [sent-30, score-0.492]
</p><p>17 One stereo estimator resolves this ambiguity using vertical disparity (images are vertically larger in the closer eye), and the other resolves it using felt eye position. [sent-31, score-0.854]
</p><p>18 Vertical magnification in one eye thus creates a cue-conflict because it affects only the estimator that uses vertical disparity. [sent-32, score-0.66]
</p><p>19 The two stereo estimators have different relative reliability at different distances, so the weights assigned to them by the visual system changes as a function of distance [7]. [sent-33, score-0.238]
</p><p>20 Since vergence eye posture is a cue to distance [8], one might predict that “perceptually metameric” stereo stimuli, if they exist, will lose their metameric status after a pure change of vergence eye posture that preserves the metamers’ retinal images [9]. [sent-34, score-1.324]
</p><p>21 We shall now briefly describe the two stereoscopic slant estimators. [sent-35, score-0.693]
</p><p>22 Although surface slant has two components (slant and tilt [10]), we will consider only slant about a vertical axis. [sent-37, score-1.394]
</p><p>23 The arguments can be extended to slant about axes of arbitrary orientation [5]. [sent-38, score-0.542]
</p><p>24 The visual signals used in stereoscopic slant perception can be conveniently parameterized by four numbers [5]. [sent-39, score-0.807]
</p><p>25 Two signals are the horizontal gradient of horizontal disparity, and the vertical gradient of vertical disparity, which we parameterize as horizontal size ratio (HSR) and vertical size ratio (VSR), respectively, in the manner of Rogers and Bradshaw [11]. [sent-42, score-1.139]
</p><p>26 They are defined as the horizontal (or vertical) size of the patch in the left eye, divided by the horizontal (or vertical) size in the right eye. [sent-43, score-0.369]
</p><p>27 The two remaining signals are the headcentric azimuth and vergence of the surface patch. [sent-45, score-0.373]
</p><p>28 A very good approximation that relates surface slant to horizontal disparity and VSR is:  S HSR,VSR = -tan-1 [ 1 ln HSR µ  VSR  ]  Equation 1  where µ is the vergence of the surface patch in radians. [sent-47, score-1.39]
</p><p>29 We call this method of slant estimation slant from HSR and VSR. [sent-48, score-1.084]
</p><p>30 A very good approximation that relates surface slant to horizontal disparity and azimuth is: S HSR,EP = -tan-1 [  1 ln HSR - tanγ µ  ]  Equation 2  where γ is the azimuth of the surface patch. [sent-49, score-1.254]
</p><p>31 We call this method of slant estimation slant from HSR and eye position on the supposition that azimuth per se is known to the visual system primarily through measurement of the eyes’ version. [sent-50, score-1.387]
</p><p>32 Each estimator uses three of the four signals available to estimate surface slant from horizontal disparity. [sent-51, score-0.885]
</p><p>33 Nonstereo slant estimates can be rendered irrelevant by the choice of task, in which case perceived slant is a weighted average of the slants predicted from these two stereoscopic slant estimates [5, 6]. [sent-52, score-1.89]
</p><p>34 In principle, the reliability of slant estimation by HSR and eye position is limited at short viewing distances (large µ) by error in the measurement of γ. [sent-53, score-0.785]
</p><p>35 The real visual system does not flinch, but instead produces a slant estimate that looks for all the world like a weighted average. [sent-58, score-0.637]
</p><p>36 It remains a possibility therefore that optimal slant estimation is implemented as a weighted combination of separate estimates. [sent-59, score-0.575]
</p><p>37 We next describe experiments that tested whether magnified (cue conflict) stimuli are distinguishable from natural (concordant) stimuli. [sent-61, score-0.289]
</p><p>38 3  Existence of stereoscopic metamers  Stimuli were sparse random dot stereograms (RDS) on a black background, 28 deg in diameter, presented directly in front of the head using a haploscope. [sent-62, score-0.516]
</p><p>39 Observers performed a forced choice task with stimuli that contained different amounts of unilateral vertical and horizontal magnification. [sent-63, score-0.6]
</p><p>40 Vertical magnification was zero for the “A” stimuli, and 2% in the right eye for the “B” stimuli (1% minification in the left eye and 1% magnification in the right eye). [sent-64, score-1.045]
</p><p>41 Horizontal magnification was set at the value that nulled apparent slant in “A” stimuli (i. [sent-65, score-1.048]
</p><p>42 Each trial consisted of two “A” stimuli and one “B” stimulus. [sent-68, score-0.201]
</p><p>43 The observer’s task was to determine whether the three stimuli were presented in AAB or BAA order [13], i. [sent-69, score-0.201]
</p><p>44 , whether the stimulus with vertical magnification was first or last of the three stimuli. [sent-71, score-0.524]
</p><p>45 6  -2  0  2  Horiz mag in left eye in stimulus B (%)  Figure 1. [sent-80, score-0.24]
</p><p>46 Observers are unable to distinguish 0% and 2% unilateral vertical magnification when unilateral horizontal magnification is added as well. [sent-81, score-0.968]
</p><p>47 Open squares show the horizontal magnification that evoked zero perceived slant under 2% vertical magnification. [sent-82, score-1.211]
</p><p>48 For each observer, there was a value of horizontal magnification that, when added to the “B” stimulus, rendered it indistinguishable from the “A” stimulus. [sent-83, score-0.475]
</p><p>49 From this experiment it is evident that stimuli with very different disparity patterns can be made perceptually indistinguishable in a forcedchoice task with well-practiced observers. [sent-85, score-0.551]
</p><p>50 1  Experimental conditions necessary for stereo metamers  Several properties of the experiment were essential to the effect. [sent-87, score-0.471]
</p><p>51 First, the vertical magnification must not be to large. [sent-88, score-0.454]
</p><p>52 At large vertical magnifications it is still possible to null apparent slant, but the stimuli are distinguishable because the dots themselves look different (they look as though blurred in the vertical direction). [sent-89, score-0.788]
</p><p>53 Two out of three observers were able to distinguish the “A” and “B” stimuli 100% of the time when the vertical magnification was increased from 2% to 5%. [sent-90, score-0.774]
</p><p>54 If left and right saccades are allowed, the “B” stimulus appears slanted in the direction predicted by its horizontal magnification. [sent-92, score-0.355]
</p><p>55 This is a rather striking effect—the surface appears to change slant simply because one starts looking about. [sent-93, score-0.674]
</p><p>56 Finally, if the stimuli are shown for more than about 1 sec it is possible to distinguish “A” and “B” stimuli by making vertical saccades from the top to the bottom of the stimulus, by taking advantage of the fact that in forward gaze, vertical saccades have equal amplitude in the two eyes [16]. [sent-95, score-1.005]
</p><p>57 For “B” stimuli only, the dots are diplopic (seen in double vision) immediately after a saccade to the top (or bottom) of the stimulus. [sent-96, score-0.244]
</p><p>58 An automatic vertical vergence eye movement then brings the dots into register after about 0. [sent-97, score-0.582]
</p><p>59 4  Breaking metamerization though change of vergence eye posture  In the haploscope it was possible to present unchanged retinal images across a range of vergence eye postures. [sent-100, score-0.925]
</p><p>60 Stimuli that were metameric to each other with the eyes verged at 100 cm were presented again with the eyes verged at 20 cm. [sent-101, score-0.412]
</p><p>61 Figure 2 illustrates this effect schematically, and Figure 3 quantifies it by plotting the amount of horizontal magnification that was needed to null apparent slant at each of the two vergence angles for one observer (left panel) and all four observers (right panel). [sent-103, score-1.354]
</p><p>62 First panel: both stereoscopic methods of estimating slant indicate that the surface is frontoparallel, and it appears so. [sent-106, score-0.825]
</p><p>63 Second panel: a vertical magnifier is placed before one eye, changing the estimate that uses vertical disparity, but not the estimate that uses eye position. [sent-107, score-0.599]
</p><p>64 Third panel: horizontal magnification is added until the surface appears frontoparallel again. [sent-109, score-0.614]
</p><p>65 The surface no longer appears frontoparallel because the weighting of the estimates has changed. [sent-112, score-0.221]
</p><p>66 Horiz magnification to null slant (%)  Vertical magnification: ±2% 2. [sent-113, score-0.84]
</p><p>67 When the eyes were verged at 100 or 20 cm distance, different amounts of horizontal magnification were needed to null the slant induced by vertical magnification. [sent-119, score-1.394]
</p><p>68 Left: 10 settings that nulled slant at 100 cm, followed by 20 settings at 20 cm, followed by 10 at 100 cm (observer BTB). [sent-120, score-0.638]
</p><p>69 Right: three out of four observers show an effect of vergence per se. [sent-121, score-0.273]
</p><p>70 5  Comparison of perceptual and sensory metamers  The stimuli described here appear the same as a result of perceptual computations that occur well after transduction of light energy by the photoreceptors. [sent-123, score-0.854]
</p><p>71 Physically different stimuli that are transduced identically might be dubbed sensory metamers. [sent-124, score-0.291]
</p><p>72 One example of a sensory metamer is given by the trade between intensity and duration for briefly flashed lights (Bloch’s Law [17]): two flashes containing the  same number of photons are indistinguishable if their durations are both less than 10 msec. [sent-125, score-0.283]
</p><p>73 The three cone photoreceptor types can support color vision because they are sensitive to different wavelengths of light. [sent-127, score-0.229]
</p><p>74 Table 1 summarizes several properties of color metamers, and analogous properties of our new stereo metamers. [sent-131, score-0.207]
</p><p>75 Light t’ is metameric to t if Bt’ = Bt, where B is the 3xN matrix whose rows represent the spectral sensitivities of the three cone mechanisms [19]. [sent-134, score-0.188]
</p><p>76 The transformation that maps one stereo metamer to another is simply a scaling of one eyes’ image in the vertical and horizontal directions, with less scaling typically needed in the horizontal than vertical direction. [sent-135, score-0.932]
</p><p>77 Then two random-dot image pairs (representing flat surfaces slanted about a vertical axis) will be metameric if their disparity patterns, [u’ v’] and [u v], are related to each other by [u’ v’] = [u(1+m) v(1+n)], where m and n are small (on the order of 0. [sent-137, score-0.63]
</p><p>78 01), with m/n equal to the weight of SHSR,VSR in the final slant estimate. [sent-138, score-0.542]
</p><p>79 Table 1: properties of color and stereo metamers PROPERTY  COLOR METAMERS  STEREO METAMERS. [sent-139, score-0.547]
</p><p>80 Depending how the problem is framed, this is a reduction from 2 dimensions (HSR and VSR) to one (slant), or from many dimensions (all physical stimuli that represent slanted surfaces) to one fewer dimensions. [sent-141, score-0.251]
</p><p>81 While color and stereo metamers can be described as sensory and perceptual, respectively, the boundary between these categories is fuzzy, as is the boundary between sensation and perception. [sent-142, score-0.637]
</p><p>82 Would motion metamers based on “early” motion detectors be sensory or perceptual? [sent-143, score-0.43]
</p><p>83 What of stimuli that look identical to retinal ganglion cells, after evoking different patterns of photoreceptor activity? [sent-144, score-0.299]
</p><p>84 While there is a real distinction to be made between sensory and perceptual metamers, but not all metamers need be easily categorized as one or the other. [sent-145, score-0.53]
</p><p>85 1 The metamer hierarchy Loftus [20] makes a distinction reminiscent of the one made here, between “memory metamers” and “perceptual metamers,” with memory metamers being stimuli that evoke distinguishable percepts during live viewing, but that become indistinguishable after mnemonic encoding. [sent-147, score-0.794]
</p><p>86 Thus, Loftus classified as “perceptual” both our perceptual and sensory metamers. [sent-148, score-0.19]
</p><p>87 In this framework, color and stereo metamers are both perceptual metamers, but only color metamers are sensory metamers. [sent-150, score-1.153]
</p><p>88 6  Conclusions  At each vergence eye posture it was possible to create stereoscopic stimuli with distinct disparity patterns that were nonetheless indistinguishable in a forced choice task. [sent-157, score-1.116]
</p><p>89 Stimuli that were metamers with the eyes in one position became distinguishable after a change of vergence eye posture alone, without changes to the retinal images. [sent-158, score-1.009]
</p><p>90 We can conclude that horizontal disparity per se is lost to the visual system after combination with the other signals that are used to interpret it as depth. [sent-159, score-0.502]
</p><p>91 Presumably, stereo metamers have distinguishable representations in primary visual cortex—one suspects this would be evident in evoked potentials or fMRI. [sent-160, score-0.616]
</p><p>92 The loss of information that renders these stimuli metameric probably occurs in two places. [sent-161, score-0.335]
</p><p>93 First, there appears to be a leak-proof “constancy” computation in which vertical disparity is used to correct horizontal disparity (Equation 1). [sent-162, score-0.875]
</p><p>94 The output of this computation is unaffected if equal amounts of horizontal and vertical magnification are added to one eyes’ image. [sent-163, score-0.621]
</p><p>95 However, the estimator that uses felt eye position can distinguish these stimuli, because their horizontal size ratios differ. [sent-164, score-0.465]
</p><p>96 Thus a second leak-proof step must occur, in which slant estimates are combined in a weighted average. [sent-165, score-0.601]
</p><p>97 It seems reasonable to call these stimuli “perceptual metamers,” by analogy with, and to distinguish them from, the traditional “sensory” metamerization of colored lights. [sent-166, score-0.274]
</p><p>98 , Horizontal and vertical disparity, eye position, and stereoscopic slant perception. [sent-204, score-1.065]
</p><p>99 Banks, Estimator reliability and distance scaling in stereoscopic slant perception. [sent-222, score-0.738]
</p><p>100 Horner, Selective nonconjugate binocular adaptation of vertical saccades and pursuits. [sent-298, score-0.311]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('slant', 0.542), ('metamers', 0.34), ('magnification', 0.252), ('disparity', 0.241), ('vertical', 0.202), ('stimuli', 0.201), ('vergence', 0.189), ('eye', 0.17), ('horizontal', 0.167), ('hsr', 0.151), ('stereoscopic', 0.151), ('stereo', 0.131), ('metameric', 0.113), ('surface', 0.108), ('perceptual', 0.1), ('sensory', 0.09), ('constancy', 0.088), ('posture', 0.088), ('vsr', 0.088), ('observers', 0.084), ('cue', 0.083), ('eyes', 0.076), ('color', 0.076), ('cm', 0.071), ('stimulus', 0.07), ('backus', 0.07), ('binocular', 0.065), ('distinguishable', 0.063), ('frontoparallel', 0.063), ('metamer', 0.063), ('visual', 0.062), ('vision', 0.059), ('res', 0.058), ('percept', 0.056), ('retinal', 0.056), ('indistinguishable', 0.056), ('lights', 0.05), ('slanted', 0.05), ('cone', 0.05), ('observer', 0.046), ('null', 0.046), ('azimuth', 0.044), ('saccades', 0.044), ('conflict', 0.04), ('disparities', 0.038), ('loftus', 0.038), ('metamerization', 0.038), ('percepts', 0.038), ('verged', 0.038), ('estimator', 0.036), ('bt', 0.036), ('distinguish', 0.035), ('patch', 0.035), ('panel', 0.033), ('weighted', 0.033), ('stereopsis', 0.033), ('evoke', 0.033), ('perceptually', 0.033), ('signals', 0.032), ('unilateral', 0.03), ('felt', 0.03), ('perceived', 0.028), ('apparent', 0.028), ('position', 0.027), ('estimates', 0.026), ('btb', 0.025), ('horiz', 0.025), ('jrf', 0.025), ('magnifications', 0.025), ('magnified', 0.025), ('magnifier', 0.025), ('nolt', 0.025), ('nulled', 0.025), ('relief', 0.025), ('rogers', 0.025), ('sensitivities', 0.025), ('stereograms', 0.025), ('images', 0.025), ('appears', 0.024), ('surfaces', 0.024), ('trade', 0.024), ('reliability', 0.023), ('viewing', 0.023), ('light', 0.023), ('resolves', 0.022), ('saccade', 0.022), ('psychol', 0.022), ('photoreceptor', 0.022), ('bradshaw', 0.022), ('physically', 0.022), ('wavelengths', 0.022), ('distance', 0.022), ('depth', 0.021), ('dots', 0.021), ('loss', 0.021), ('perception', 0.02), ('evoked', 0.02), ('banks', 0.02), ('patterns', 0.02), ('alone', 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="145-tfidf-1" href="./nips-2001-Perceptual_Metamers_in_Stereoscopic_Vision.html">145 nips-2001-Perceptual Metamers in Stereoscopic Vision</a></p>
<p>Author: B. T. Backus</p><p>Abstract: Theories of cue combination suggest the possibility of constructing visual stimuli that evoke different patterns of neural activity in sensory areas of the brain, but that cannot be distinguished by any behavioral measure of perception. Such stimuli, if they exist, would be interesting for two reasons. First, one could know that none of the differences between the stimuli survive past the computations used to build the percepts. Second, it can be difficult to distinguish stimulus-driven components of measured neural activity from top-down components (such as those due to the interestingness of the stimuli). Changing the stimulus without changing the percept could be exploited to measure the stimulusdriven activity. Here we describe stimuli in which vertical and horizontal disparities trade during the construction of percepts of slanted surfaces, yielding stimulus equivalence classes. Equivalence class membership changed after a change of vergence eye posture alone, without changes to the retinal images. A formal correspondence can be drawn between these “perceptual metamers” and more familiar “sensory metamers” such as color metamers. 1</p><p>2 0.2067592 <a title="145-tfidf-2" href="./nips-2001-A_Hierarchical_Model_of_Complex_Cells_in_Visual_Cortex_for_the_Binocular_Perception_of_Motion-in-Depth.html">10 nips-2001-A Hierarchical Model of Complex Cells in Visual Cortex for the Binocular Perception of Motion-in-Depth</a></p>
<p>Author: Silvio P. Sabatini, Fabio Solari, Giulia Andreani, Chiara Bartolozzi, Giacomo M. Bisio</p><p>Abstract: A cortical model for motion-in-depth selectivity of complex cells in the visual cortex is proposed. The model is based on a time extension of the phase-based techniques for disparity estimation. We consider the computation of the total temporal derivative of the time-varying disparity through the combination of the responses of disparity energy units. To take into account the physiological plausibility, the model is based on the combinations of binocular cells characterized by different ocular dominance indices. The resulting cortical units of the model show a sharp selectivity for motion-indepth that has been compared with that reported in the literature for real cortical cells. 1</p><p>3 0.10214251 <a title="145-tfidf-3" href="./nips-2001-Eye_movements_and_the_maturation_of_cortical_orientation_selectivity.html">73 nips-2001-Eye movements and the maturation of cortical orientation selectivity</a></p>
<p>Author: Antonino Casile, Michele Rucci</p><p>Abstract: Neural activity appears to be a crucial component for shaping the receptive ﬁelds of cortical simple cells into adjacent, oriented subregions alternately receiving ON- and OFF-center excitatory geniculate inputs. It is known that the orientation selective responses of V1 neurons are reﬁned by visual experience. After eye opening, the spatiotemporal structure of neural activity in the early stages of the visual pathway depends both on the visual environment and on how the environment is scanned. We have used computational modeling to investigate how eye movements might affect the reﬁnement of the orientation tuning of simple cells in the presence of a Hebbian scheme of synaptic plasticity. Levels of correlation between the activity of simulated cells were examined while natural scenes were scanned so as to model sequences of saccades and ﬁxational eye movements, such as microsaccades, tremor and ocular drift. The speciﬁc patterns of activity required for a quantitatively accurate development of simple cell receptive ﬁelds with segregated ON and OFF subregions were observed during ﬁxational eye movements, but not in the presence of saccades or with static presentation of natural visual input. These results suggest an important role for the eye movements occurring during visual ﬁxation in the reﬁnement of orientation selectivity.</p><p>4 0.08787591 <a title="145-tfidf-4" href="./nips-2001-Modeling_Temporal_Structure_in_Classical_Conditioning.html">123 nips-2001-Modeling Temporal Structure in Classical Conditioning</a></p>
<p>Author: Aaron C. Courville, David S. Touretzky</p><p>Abstract: The Temporal Coding Hypothesis of Miller and colleagues [7] suggests that animals integrate related temporal patterns of stimuli into single memory representations. We formalize this concept using quasi-Bayes estimation to update the parameters of a constrained hidden Markov model. This approach allows us to account for some surprising temporal effects in the second order conditioning experiments of Miller et al. [1 , 2, 3], which other models are unable to explain. 1</p><p>5 0.075040601 <a title="145-tfidf-5" href="./nips-2001-Characterizing_Neural_Gain_Control_using_Spike-triggered_Covariance.html">48 nips-2001-Characterizing Neural Gain Control using Spike-triggered Covariance</a></p>
<p>Author: Odelia Schwartz, E. J. Chichilnisky, Eero P. Simoncelli</p><p>Abstract: Spike-triggered averaging techniques are effective for linear characterization of neural responses. But neurons exhibit important nonlinear behaviors, such as gain control, that are not captured by such analyses. We describe a spike-triggered covariance method for retrieving suppressive components of the gain control signal in a neuron. We demonstrate the method in simulation and on retinal ganglion cell data. Analysis of physiological data reveals signiﬁcant suppressive axes and explains neural nonlinearities. This method should be applicable to other sensory areas and modalities. White noise analysis has emerged as a powerful technique for characterizing response properties of spiking neurons. A sequence of stimuli are drawn randomly from an ensemble and presented in rapid succession, and one examines the subset that elicit action potentials. This “spike-triggered” stimulus ensemble can provide information about the neuron’s response characteristics. In the most widely used form of this analysis, one estimates an excitatory linear kernel by computing the spike-triggered average (STA); that is, the mean stimulus that elicited a spike [e.g., 1, 2]. Under the assumption that spikes are generated by a Poisson process with instantaneous rate determined by linear projection onto a kernel followed by a static nonlinearity, the STA provides an unbiased estimate of this kernel [3]. Recently, a number of authors have developed interesting extensions of white noise analysis. Some have examined spike-triggered averages in a reduced linear subspace of input stimuli [e.g., 4]. Others have recovered excitatory subspaces, by computing the spiketriggered covariance (STC), followed by an eigenvector analysis to determine the subspace axes [e.g., 5, 6]. Sensory neurons exhibit striking nonlinear behaviors that are not explained by fundamentally linear mechanisms. For example, the response of a neuron typically saturates for large amplitude stimuli; the response to the optimal stimulus is often suppressed by the presence of a non-optimal mask [e.g., 7]; and the kernel recovered from STA analysis may change shape as a function of stimulus amplitude [e.g., 8, 9]. A variety of these nonlinear behaviors can be attributed to gain control [e.g., 8, 10, 11, 12, 13, 14], in which neural responses are suppressively modulated by a gain signal derived from the stimulus. Although the underlying mechanisms and time scales associated with such gain control are current topics of research, the basic functional properties appear to be ubiquitous, occurring throughout the nervous system. a b 0 k0 0 Figure 1: Geometric depiction of spike-triggered analyses. a, Spike-triggered averaging with two-dimensional stimuli. Black points indicate raw stimuli. White points indicate stimuli eliciting a spike, and the STA (black vector), which provides an estimate of , corresponds to their center of mass. b, Spike-triggered covariance analysis of suppressive axes. Shown are a set of stimuli lying on a plane perpendicular to the excitatory kernel, . Within the plane, stimuli eliciting a spike are concentrated in an elliptical region. The minor axis of the ellipse corresponds to a suppressive stimulus direction: stimuli with a signiﬁcant component along this axis are less likely to elicit spikes. The stimulus component along the major axis of the ellipse has no inﬂuence on spiking. ¢ £  ¡ ¢  ¡ Here we develop a white noise methodology for characterizing a neuron with gain control. We show that a set of suppressive kernels may be recovered by ﬁnding the eigenvectors of the spike-triggered covariance matrix associated with smallest variance. We apply the technique to electrophysiological data obtained from ganglion cells in salamander and macaque retina, and recover a set of axes that are shown to reduce responses in the neuron. Moreover, when we ﬁt a gain control model to the data using a maximum likelihood procedure within this subspace, the model accounts for changes in the STA as a function of contrast. 1 Characterizing suppressive axes ¤¥ As in all white noise approaches, we assume that stimuli correspond to vectors, , in some ﬁnite-dimensional space (e.g., a neighborhood of pixels or an interval of time samples). We assume a gain control model in which the probability of a stimulus eliciting a spike grows monotonically with the halfwave-rectiﬁed projection onto an excitatory linear kernel, , and is suppressively modulated by the fullwave-rectiﬁed projection onto a set of . linear kernels, ¨ ¤§  ¤¥    ©¤ §   ¨ ¤ ¥ ©¤ § ¦ First, we recover the excitatory kernel, . This is achieved by presenting spherically symmetric input stimuli (e.g., Gaussian white noise) to the neuron and computing the STA (Fig. 1a). STA correctly recovers the excitatory kernel, under the assumption that each of the gain control kernels are orthogonal (or equal) to the excitatory kernel. The proof is essentially the same as that given for recovering the kernel of a linear model followed by a monotonic nonlinearity [3]. In particular, any stimulus can be decomposed into a component in the direction of the excitatory kernel, and a component in a perpendicular direction. This can be paired with another stimulus that is identical, except that its component in the perpendicular direction is negated. The two stimuli are equally likely to occur in a spherically Gaussian stimulus set (since they are equidistant from the origin), and they are equally likely to elicit a spike (since their excitatory components are equal, and their rectiﬁed perpendicular components are equal). Their vector average lies in the direction of the excitatory kernel. Thus, the STA (which is an average over all such stimuli, or all such stimulus pairs) must also lie in that direction. In a subsequent section we explain how to Model: Retrieved: Excitatory: Excitatory: Eigenvalues: Suppressive: Suppressive: Weights Variance (eigenvalue) { 1.5 { 2{ 2.5 { 3{ 1 1 Arbitrary 0 Axis number 350 Figure 2: Estimation of kernels from a simulated model (equation 2). Left: Model kernels. Right: Sorted eigenvalues of covariance matrix of stimuli eliciting spikes (STC). Five eigenvalues fall signiﬁcantly below the others. Middle: STA (excitatory kernel) and eigenvectors (suppressive kernels) associated with the lowest eigenvalues. recover the excitatory kernel when it is not orthogonal to the suppressive kernels. Next, we recover the suppressive subspace, assuming the excitatory kernel is known. Consider the stimuli lying on a plane perpendicular to this kernel. These stimuli all elicit the same response in the excitatory kernel, but they may produce different amounts of suppression. Figure 1b illustrates the behavior in a three-dimensional stimulus space, in which one axis is assumed to be suppressive. The distribution of raw stimuli on the plane is spherically symmetric about the origin. But the distribution of stimuli eliciting a spike is narrower along the suppressive direction: these stimuli have a component along the suppressive axis and are therefore less likely to elicit a spike. This behavior is easily generalized from this plane to the entire stimulus space. If we assume that the suppressive axes are ﬁxed, then we expect to see reductions in variance in the same directions for any level of numerator excitation. Given this behavior of the spike-triggered stimulus ensemble, we can recover the suppressive subspace using principal component analysis. We construct the sample covariance matrix of the stimuli eliciting a spike: £ §¥</p><p>6 0.066243336 <a title="145-tfidf-6" href="./nips-2001-A_Maximum-Likelihood_Approach_to_Modeling_Multisensory_Enhancement.html">11 nips-2001-A Maximum-Likelihood Approach to Modeling Multisensory Enhancement</a></p>
<p>7 0.057848934 <a title="145-tfidf-7" href="./nips-2001-Group_Redundancy_Measures_Reveal_Redundancy_Reduction_in_the_Auditory_Pathway.html">87 nips-2001-Group Redundancy Measures Reveal Redundancy Reduction in the Auditory Pathway</a></p>
<p>8 0.05759301 <a title="145-tfidf-8" href="./nips-2001-Spike_timing_and_the_coding_of_naturalistic_sounds_in_a_central_auditory_area_of_songbirds.html">174 nips-2001-Spike timing and the coding of naturalistic sounds in a central auditory area of songbirds</a></p>
<p>9 0.047177762 <a title="145-tfidf-9" href="./nips-2001-Laplacian_Eigenmaps_and_Spectral_Techniques_for_Embedding_and_Clustering.html">106 nips-2001-Laplacian Eigenmaps and Spectral Techniques for Embedding and Clustering</a></p>
<p>10 0.046148185 <a title="145-tfidf-10" href="./nips-2001-Transform-invariant_Image_Decomposition_with_Similarity_Templates.html">191 nips-2001-Transform-invariant Image Decomposition with Similarity Templates</a></p>
<p>11 0.044747494 <a title="145-tfidf-11" href="./nips-2001-A_Rational_Analysis_of_Cognitive_Control_in_a_Speeded_Discrimination_Task.html">18 nips-2001-A Rational Analysis of Cognitive Control in a Speeded Discrimination Task</a></p>
<p>12 0.041743297 <a title="145-tfidf-12" href="./nips-2001-Modeling_the_Modulatory_Effect_of_Attention_on_Human_Spatial_Vision.html">124 nips-2001-Modeling the Modulatory Effect of Attention on Human Spatial Vision</a></p>
<p>13 0.041671511 <a title="145-tfidf-13" href="./nips-2001-Probabilistic_Inference_of_Hand_Motion_from_Neural_Activity_in_Motor_Cortex.html">150 nips-2001-Probabilistic Inference of Hand Motion from Neural Activity in Motor Cortex</a></p>
<p>14 0.040549885 <a title="145-tfidf-14" href="./nips-2001-Probabilistic_principles_in_unsupervised_learning_of_visual_structure%3A_human_data_and_a_model.html">151 nips-2001-Probabilistic principles in unsupervised learning of visual structure: human data and a model</a></p>
<p>15 0.040259581 <a title="145-tfidf-15" href="./nips-2001-Effective_Size_of_Receptive_Fields_of_Inferior_Temporal_Visual_Cortex_Neurons_in_Natural_Scenes.html">65 nips-2001-Effective Size of Receptive Fields of Inferior Temporal Visual Cortex Neurons in Natural Scenes</a></p>
<p>16 0.040197548 <a title="145-tfidf-16" href="./nips-2001-Fragment_Completion_in_Humans_and_Machines.html">78 nips-2001-Fragment Completion in Humans and Machines</a></p>
<p>17 0.036561273 <a title="145-tfidf-17" href="./nips-2001-Categorization_by_Learning_and_Combining_Object_Parts.html">46 nips-2001-Categorization by Learning and Combining Object Parts</a></p>
<p>18 0.035809159 <a title="145-tfidf-18" href="./nips-2001-K-Local_Hyperplane_and_Convex_Distance_Nearest_Neighbor_Algorithms.html">101 nips-2001-K-Local Hyperplane and Convex Distance Nearest Neighbor Algorithms</a></p>
<p>19 0.03556354 <a title="145-tfidf-19" href="./nips-2001-Generating_velocity_tuning_by_asymmetric_recurrent_connections.html">82 nips-2001-Generating velocity tuning by asymmetric recurrent connections</a></p>
<p>20 0.032836001 <a title="145-tfidf-20" href="./nips-2001-Receptive_field_structure_of_flow_detectors_for_heading_perception.html">158 nips-2001-Receptive field structure of flow detectors for heading perception</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2001_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.09), (1, -0.102), (2, -0.064), (3, -0.003), (4, -0.023), (5, 0.021), (6, -0.106), (7, 0.055), (8, 0.062), (9, 0.02), (10, -0.01), (11, 0.135), (12, -0.102), (13, 0.038), (14, 0.072), (15, -0.039), (16, -0.045), (17, 0.12), (18, 0.01), (19, 0.119), (20, -0.073), (21, 0.003), (22, 0.012), (23, -0.16), (24, 0.1), (25, 0.073), (26, -0.134), (27, -0.024), (28, 0.013), (29, -0.12), (30, 0.142), (31, 0.162), (32, -0.189), (33, -0.045), (34, 0.054), (35, -0.108), (36, -0.025), (37, -0.007), (38, -0.007), (39, 0.036), (40, 0.071), (41, 0.123), (42, -0.1), (43, 0.1), (44, 0.069), (45, -0.225), (46, 0.212), (47, 0.133), (48, -0.053), (49, 0.065)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97902453 <a title="145-lsi-1" href="./nips-2001-Perceptual_Metamers_in_Stereoscopic_Vision.html">145 nips-2001-Perceptual Metamers in Stereoscopic Vision</a></p>
<p>Author: B. T. Backus</p><p>Abstract: Theories of cue combination suggest the possibility of constructing visual stimuli that evoke different patterns of neural activity in sensory areas of the brain, but that cannot be distinguished by any behavioral measure of perception. Such stimuli, if they exist, would be interesting for two reasons. First, one could know that none of the differences between the stimuli survive past the computations used to build the percepts. Second, it can be difficult to distinguish stimulus-driven components of measured neural activity from top-down components (such as those due to the interestingness of the stimuli). Changing the stimulus without changing the percept could be exploited to measure the stimulusdriven activity. Here we describe stimuli in which vertical and horizontal disparities trade during the construction of percepts of slanted surfaces, yielding stimulus equivalence classes. Equivalence class membership changed after a change of vergence eye posture alone, without changes to the retinal images. A formal correspondence can be drawn between these “perceptual metamers” and more familiar “sensory metamers” such as color metamers. 1</p><p>2 0.83297163 <a title="145-lsi-2" href="./nips-2001-A_Hierarchical_Model_of_Complex_Cells_in_Visual_Cortex_for_the_Binocular_Perception_of_Motion-in-Depth.html">10 nips-2001-A Hierarchical Model of Complex Cells in Visual Cortex for the Binocular Perception of Motion-in-Depth</a></p>
<p>Author: Silvio P. Sabatini, Fabio Solari, Giulia Andreani, Chiara Bartolozzi, Giacomo M. Bisio</p><p>Abstract: A cortical model for motion-in-depth selectivity of complex cells in the visual cortex is proposed. The model is based on a time extension of the phase-based techniques for disparity estimation. We consider the computation of the total temporal derivative of the time-varying disparity through the combination of the responses of disparity energy units. To take into account the physiological plausibility, the model is based on the combinations of binocular cells characterized by different ocular dominance indices. The resulting cortical units of the model show a sharp selectivity for motion-indepth that has been compared with that reported in the literature for real cortical cells. 1</p><p>3 0.43642178 <a title="145-lsi-3" href="./nips-2001-Eye_movements_and_the_maturation_of_cortical_orientation_selectivity.html">73 nips-2001-Eye movements and the maturation of cortical orientation selectivity</a></p>
<p>Author: Antonino Casile, Michele Rucci</p><p>Abstract: Neural activity appears to be a crucial component for shaping the receptive ﬁelds of cortical simple cells into adjacent, oriented subregions alternately receiving ON- and OFF-center excitatory geniculate inputs. It is known that the orientation selective responses of V1 neurons are reﬁned by visual experience. After eye opening, the spatiotemporal structure of neural activity in the early stages of the visual pathway depends both on the visual environment and on how the environment is scanned. We have used computational modeling to investigate how eye movements might affect the reﬁnement of the orientation tuning of simple cells in the presence of a Hebbian scheme of synaptic plasticity. Levels of correlation between the activity of simulated cells were examined while natural scenes were scanned so as to model sequences of saccades and ﬁxational eye movements, such as microsaccades, tremor and ocular drift. The speciﬁc patterns of activity required for a quantitatively accurate development of simple cell receptive ﬁelds with segregated ON and OFF subregions were observed during ﬁxational eye movements, but not in the presence of saccades or with static presentation of natural visual input. These results suggest an important role for the eye movements occurring during visual ﬁxation in the reﬁnement of orientation selectivity.</p><p>4 0.33711135 <a title="145-lsi-4" href="./nips-2001-Receptive_field_structure_of_flow_detectors_for_heading_perception.html">158 nips-2001-Receptive field structure of flow detectors for heading perception</a></p>
<p>Author: J. A. Beintema, M. Lappe, Alexander C. Berg</p><p>Abstract: Observer translation relative to the world creates image flow that expands from the observer's direction of translation (heading) from which the observer can recover heading direction. Yet, the image flow is often more complex, depending on rotation of the eye, scene layout and translation velocity. A number of models [1-4] have been proposed on how the human visual system extracts heading from flow in a neurophysiologic ally plausible way. These models represent heading by a set of neurons that respond to large image flow patterns and receive input from motion sensed at different image locations. We analysed these models to determine the exact receptive field of these heading detectors. We find most models predict that, contrary to widespread believe, the contribut ing motion sensors have a preferred motion directed circularly rather than radially around the detector's preferred heading. Moreover, the results suggest to look for more refined structure within the circular flow, such as bi-circularity or local motion-opponency.</p><p>5 0.33414024 <a title="145-lsi-5" href="./nips-2001-Modeling_Temporal_Structure_in_Classical_Conditioning.html">123 nips-2001-Modeling Temporal Structure in Classical Conditioning</a></p>
<p>Author: Aaron C. Courville, David S. Touretzky</p><p>Abstract: The Temporal Coding Hypothesis of Miller and colleagues [7] suggests that animals integrate related temporal patterns of stimuli into single memory representations. We formalize this concept using quasi-Bayes estimation to update the parameters of a constrained hidden Markov model. This approach allows us to account for some surprising temporal effects in the second order conditioning experiments of Miller et al. [1 , 2, 3], which other models are unable to explain. 1</p><p>6 0.32314116 <a title="145-lsi-6" href="./nips-2001-Characterizing_Neural_Gain_Control_using_Spike-triggered_Covariance.html">48 nips-2001-Characterizing Neural Gain Control using Spike-triggered Covariance</a></p>
<p>7 0.31752998 <a title="145-lsi-7" href="./nips-2001-A_Maximum-Likelihood_Approach_to_Modeling_Multisensory_Enhancement.html">11 nips-2001-A Maximum-Likelihood Approach to Modeling Multisensory Enhancement</a></p>
<p>8 0.28006041 <a title="145-lsi-8" href="./nips-2001-A_Rational_Analysis_of_Cognitive_Control_in_a_Speeded_Discrimination_Task.html">18 nips-2001-A Rational Analysis of Cognitive Control in a Speeded Discrimination Task</a></p>
<p>9 0.2473083 <a title="145-lsi-9" href="./nips-2001-Orientational_and_Geometric_Determinants_of_Place_and_Head-direction.html">142 nips-2001-Orientational and Geometric Determinants of Place and Head-direction</a></p>
<p>10 0.23626363 <a title="145-lsi-10" href="./nips-2001-The_Fidelity_of_Local_Ordinal_Encoding.html">182 nips-2001-The Fidelity of Local Ordinal Encoding</a></p>
<p>11 0.22424412 <a title="145-lsi-11" href="./nips-2001-Spike_timing_and_the_coding_of_naturalistic_sounds_in_a_central_auditory_area_of_songbirds.html">174 nips-2001-Spike timing and the coding of naturalistic sounds in a central auditory area of songbirds</a></p>
<p>12 0.21442658 <a title="145-lsi-12" href="./nips-2001-Prodding_the_ROC_Curve%3A_Constrained_Optimization_of_Classifier_Performance.html">152 nips-2001-Prodding the ROC Curve: Constrained Optimization of Classifier Performance</a></p>
<p>13 0.21000502 <a title="145-lsi-13" href="./nips-2001-Probabilistic_Inference_of_Hand_Motion_from_Neural_Activity_in_Motor_Cortex.html">150 nips-2001-Probabilistic Inference of Hand Motion from Neural Activity in Motor Cortex</a></p>
<p>14 0.20798063 <a title="145-lsi-14" href="./nips-2001-Incremental_A%2A.html">93 nips-2001-Incremental A*</a></p>
<p>15 0.1945993 <a title="145-lsi-15" href="./nips-2001-Group_Redundancy_Measures_Reveal_Redundancy_Reduction_in_the_Auditory_Pathway.html">87 nips-2001-Group Redundancy Measures Reveal Redundancy Reduction in the Auditory Pathway</a></p>
<p>16 0.1933164 <a title="145-lsi-16" href="./nips-2001-Modeling_the_Modulatory_Effect_of_Attention_on_Human_Spatial_Vision.html">124 nips-2001-Modeling the Modulatory Effect of Attention on Human Spatial Vision</a></p>
<p>17 0.18099695 <a title="145-lsi-17" href="./nips-2001-Transform-invariant_Image_Decomposition_with_Similarity_Templates.html">191 nips-2001-Transform-invariant Image Decomposition with Similarity Templates</a></p>
<p>18 0.17620286 <a title="145-lsi-18" href="./nips-2001-Geometrical_Singularities_in_the_Neuromanifold_of_Multilayer_Perceptrons.html">83 nips-2001-Geometrical Singularities in the Neuromanifold of Multilayer Perceptrons</a></p>
<p>19 0.17492059 <a title="145-lsi-19" href="./nips-2001-The_Noisy_Euclidean_Traveling_Salesman_Problem_and_Learning.html">186 nips-2001-The Noisy Euclidean Traveling Salesman Problem and Learning</a></p>
<p>20 0.15805049 <a title="145-lsi-20" href="./nips-2001-Probabilistic_principles_in_unsupervised_learning_of_visual_structure%3A_human_data_and_a_model.html">151 nips-2001-Probabilistic principles in unsupervised learning of visual structure: human data and a model</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2001_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.015), (17, 0.011), (19, 0.044), (27, 0.091), (30, 0.064), (38, 0.032), (59, 0.019), (61, 0.377), (72, 0.04), (79, 0.044), (84, 0.011), (91, 0.154)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.85608107 <a title="145-lda-1" href="./nips-2001-Switch_Packet_Arbitration_via_Queue-Learning.html">177 nips-2001-Switch Packet Arbitration via Queue-Learning</a></p>
<p>Author: Timothy X. Brown</p><p>Abstract: In packet switches, packets queue at switch inputs and contend for outputs. The contention arbitration policy directly affects switch performance. The best policy depends on the current state of the switch and current trafﬁc patterns. This problem is hard because the state space, possible transitions, and set of actions all grow exponentially with the size of the switch. We present a reinforcement learning formulation of the problem that decomposes the value function into many small independent value functions and enables an efﬁcient action selection.</p><p>same-paper 2 0.83293021 <a title="145-lda-2" href="./nips-2001-Perceptual_Metamers_in_Stereoscopic_Vision.html">145 nips-2001-Perceptual Metamers in Stereoscopic Vision</a></p>
<p>Author: B. T. Backus</p><p>Abstract: Theories of cue combination suggest the possibility of constructing visual stimuli that evoke different patterns of neural activity in sensory areas of the brain, but that cannot be distinguished by any behavioral measure of perception. Such stimuli, if they exist, would be interesting for two reasons. First, one could know that none of the differences between the stimuli survive past the computations used to build the percepts. Second, it can be difficult to distinguish stimulus-driven components of measured neural activity from top-down components (such as those due to the interestingness of the stimuli). Changing the stimulus without changing the percept could be exploited to measure the stimulusdriven activity. Here we describe stimuli in which vertical and horizontal disparities trade during the construction of percepts of slanted surfaces, yielding stimulus equivalence classes. Equivalence class membership changed after a change of vergence eye posture alone, without changes to the retinal images. A formal correspondence can be drawn between these “perceptual metamers” and more familiar “sensory metamers” such as color metamers. 1</p><p>3 0.74091744 <a title="145-lda-3" href="./nips-2001-Bayesian_Predictive_Profiles_With_Applications_to_Retail_Transaction_Data.html">41 nips-2001-Bayesian Predictive Profiles With Applications to Retail Transaction Data</a></p>
<p>Author: Igor V. Cadez, Padhraic Smyth</p><p>Abstract: Massive transaction data sets are recorded in a routine manner in telecommunications, retail commerce, and Web site management. In this paper we address the problem of inferring predictive individual proﬁles from such historical transaction data. We describe a generative mixture model for count data and use an an approximate Bayesian estimation framework that eﬀectively combines an individual’s speciﬁc history with more general population patterns. We use a large real-world retail transaction data set to illustrate how these proﬁles consistently outperform non-mixture and non-Bayesian techniques in predicting customer behavior in out-of-sample data. 1</p><p>4 0.45992309 <a title="145-lda-4" href="./nips-2001-Reinforcement_Learning_and_Time_Perception_--_a_Model_of_Animal_Experiments.html">160 nips-2001-Reinforcement Learning and Time Perception -- a Model of Animal Experiments</a></p>
<p>Author: Jonathan L. Shapiro, J. Wearden</p><p>Abstract: Animal data on delayed-reward conditioning experiments shows a striking property - the data for different time intervals collapses into a single curve when the data is scaled by the time interval. This is called the scalar property of interval timing. Here a simple model of a neural clock is presented and shown to give rise to the scalar property. The model is an accumulator consisting of noisy, linear spiking neurons. It is analytically tractable and contains only three parameters. When coupled with reinforcement learning it simulates peak procedure experiments, producing both the scalar property and the pattern of single trial covariances. 1</p><p>5 0.45940307 <a title="145-lda-5" href="./nips-2001-Efficiency_versus_Convergence_of_Boolean_Kernels_for_On-Line_Learning_Algorithms.html">66 nips-2001-Efficiency versus Convergence of Boolean Kernels for On-Line Learning Algorithms</a></p>
<p>Author: Roni Khardon, Dan Roth, Rocco A. Servedio</p><p>Abstract: We study online learning in Boolean domains using kernels which capture feature expansions equivalent to using conjunctions over basic features. We demonstrate a tradeoff between the computational efﬁciency with which these kernels can be computed and the generalization ability of the resulting classiﬁer. We ﬁrst describe several kernel functions which capture either limited forms of conjunctions or all conjunctions. We show that these kernels can be used to efﬁciently run the Perceptron algorithm over an exponential number of conjunctions; however we also prove that using such kernels the Perceptron algorithm can make an exponential number of mistakes even when learning simple functions. We also consider an analogous use of kernel functions to run the multiplicative-update Winnow algorithm over an expanded feature space of exponentially many conjunctions. While known upper bounds imply that Winnow can learn DNF formulae with a polynomial mistake bound in this setting, we prove that it is computationally hard to simulate Winnow’s behavior for learning DNF over such a feature set, and thus that such kernel functions for Winnow are not efﬁciently computable.</p><p>6 0.45863426 <a title="145-lda-6" href="./nips-2001-Iterative_Double_Clustering_for_Unsupervised_and_Semi-Supervised_Learning.html">100 nips-2001-Iterative Double Clustering for Unsupervised and Semi-Supervised Learning</a></p>
<p>7 0.45812035 <a title="145-lda-7" href="./nips-2001-The_Infinite_Hidden_Markov_Model.html">183 nips-2001-The Infinite Hidden Markov Model</a></p>
<p>8 0.45797142 <a title="145-lda-8" href="./nips-2001-Modeling_Temporal_Structure_in_Classical_Conditioning.html">123 nips-2001-Modeling Temporal Structure in Classical Conditioning</a></p>
<p>9 0.45765877 <a title="145-lda-9" href="./nips-2001-Relative_Density_Nets%3A_A_New_Way_to_Combine_Backpropagation_with_HMM%27s.html">162 nips-2001-Relative Density Nets: A New Way to Combine Backpropagation with HMM's</a></p>
<p>10 0.45731425 <a title="145-lda-10" href="./nips-2001-Entropy_and_Inference%2C_Revisited.html">68 nips-2001-Entropy and Inference, Revisited</a></p>
<p>11 0.45729154 <a title="145-lda-11" href="./nips-2001-Grouping_with_Bias.html">89 nips-2001-Grouping with Bias</a></p>
<p>12 0.4567605 <a title="145-lda-12" href="./nips-2001-A_Dynamic_HMM_for_On-line_Segmentation_of_Sequential_Data.html">7 nips-2001-A Dynamic HMM for On-line Segmentation of Sequential Data</a></p>
<p>13 0.45536798 <a title="145-lda-13" href="./nips-2001-The_Fidelity_of_Local_Ordinal_Encoding.html">182 nips-2001-The Fidelity of Local Ordinal Encoding</a></p>
<p>14 0.45470592 <a title="145-lda-14" href="./nips-2001-Reinforcement_Learning_with_Long_Short-Term_Memory.html">161 nips-2001-Reinforcement Learning with Long Short-Term Memory</a></p>
<p>15 0.45405275 <a title="145-lda-15" href="./nips-2001-Small-World_Phenomena_and_the_Dynamics_of_Information.html">169 nips-2001-Small-World Phenomena and the Dynamics of Information</a></p>
<p>16 0.45337296 <a title="145-lda-16" href="./nips-2001-Probabilistic_Inference_of_Hand_Motion_from_Neural_Activity_in_Motor_Cortex.html">150 nips-2001-Probabilistic Inference of Hand Motion from Neural Activity in Motor Cortex</a></p>
<p>17 0.45309055 <a title="145-lda-17" href="./nips-2001-ACh%2C_Uncertainty%2C_and_Cortical_Inference.html">3 nips-2001-ACh, Uncertainty, and Cortical Inference</a></p>
<p>18 0.45292601 <a title="145-lda-18" href="./nips-2001-A_Natural_Policy_Gradient.html">13 nips-2001-A Natural Policy Gradient</a></p>
<p>19 0.45290166 <a title="145-lda-19" href="./nips-2001-Computing_Time_Lower_Bounds_for_Recurrent_Sigmoidal_Neural_Networks.html">52 nips-2001-Computing Time Lower Bounds for Recurrent Sigmoidal Neural Networks</a></p>
<p>20 0.45159262 <a title="145-lda-20" href="./nips-2001-Neural_Implementation_of_Bayesian_Inference_in_Population_Codes.html">131 nips-2001-Neural Implementation of Bayesian Inference in Population Codes</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
