<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>20 nips-2001-A Sequence Kernel and its Application to Speaker Recognition</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2001" href="../home/nips2001_home.html">nips2001</a> <a title="nips-2001-20" href="#">nips2001-20</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>20 nips-2001-A Sequence Kernel and its Application to Speaker Recognition</h1>
<br/><p>Source: <a title="nips-2001-20-pdf" href="http://papers.nips.cc/paper/1951-a-sequence-kernel-and-its-application-to-speaker-recognition.pdf">pdf</a></p><p>Author: William M. Campbell</p><p>Abstract: A novel approach for comparing sequences of observations using an explicit-expansion kernel is demonstrated. The kernel is derived using the assumption of the independence of the sequence of observations and a mean-squared error training criterion. The use of an explicit expansion kernel reduces classiﬁer model size and computation dramatically, resulting in model sizes and computation one-hundred times smaller in our application. The explicit expansion also preserves the computational advantages of an earlier architecture based on mean-squared error training. Training using standard support vector machine methodology gives accuracy that signiﬁcantly exceeds the performance of state-of-the-art mean-squared error training for a speaker recognition task.</p><p>Reference: <a title="nips-2001-20-reference" href="../nips2001_reference/nips-2001-A_Sequence_Kernel_and_its_Application_to_Speaker_Recognition_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 com  Abstract A novel approach for comparing sequences of observations using an explicit-expansion kernel is demonstrated. [sent-5, score-0.225]
</p><p>2 The kernel is derived using the assumption of the independence of the sequence of observations and a mean-squared error training criterion. [sent-6, score-0.399]
</p><p>3 The use of an explicit expansion kernel reduces classiﬁer model size and computation dramatically, resulting in model sizes and computation one-hundred times smaller in our application. [sent-7, score-0.212]
</p><p>4 The explicit expansion also preserves the computational advantages of an earlier architecture based on mean-squared error training. [sent-8, score-0.125]
</p><p>5 Training using standard support vector machine methodology gives accuracy that signiﬁcantly exceeds the performance of state-of-the-art mean-squared error training for a speaker recognition task. [sent-9, score-0.836]
</p><p>6 1 Introduction Comparison of sequences of observations is a natural and necessary operation in speech applications. [sent-10, score-0.235]
</p><p>7 Several recent approaches using support vector machines (SVM’s) have been proposed in the literature. [sent-11, score-0.108]
</p><p>8 First, large training sets result in long training times for support vector methods. [sent-14, score-0.229]
</p><p>9 Second, the emission probabilities must be approximated [3], since the output of the support vector machine is not a probability. [sent-15, score-0.141]
</p><p>10 A more recent method for comparing sequences is based on the Fisher kernel proposed by Jaakkola and Haussler [4]. [sent-16, score-0.201]
</p><p>11 This approach has been explored for speech recognition in [5]. [sent-17, score-0.235]
</p><p>12 The application to speaker recognition is detailed in [6]. [sent-18, score-0.641]
</p><p>13 We propose an alternative kernel based upon polynomial classiﬁers and the associated mean-squared error (MSE) training criterion [7]. [sent-19, score-0.407]
</p><p>14 The advantage of this kernel is that it preserves the structure of the classiﬁer in [7] which is both computationally and memory efﬁcient. [sent-20, score-0.159]
</p><p>15 We consider the application of text-independent speaker recognition; i. [sent-21, score-0.547]
</p><p>16 , determining or verifying the identity of an individual through voice characteristics. [sent-23, score-0.117]
</p><p>17 Text-independent recognition implies that knowledge of the text of the speech data is not used. [sent-24, score-0.235]
</p><p>18 Traditional methods for text-independent speaker recognition are vector quantization [8], Gaussian mixture models [9], and artiﬁcial neural networks [8]. [sent-25, score-0.646]
</p><p>19 A state-of-the-art approach based on polynomial classiﬁers was presented in [7]. [sent-26, score-0.124]
</p><p>20 The polynomial approach has several ad-  vantages over traditional methods–1) it is extremely computationally-efﬁcient for identiﬁcation, 2) the classiﬁer is discriminative which eliminates the need for a background or cohort model [10], and 3) the method generates small classiﬁer models. [sent-27, score-0.153]
</p><p>21 In Section 2, we describe polynomial classiﬁers and the associated scoring process. [sent-28, score-0.297]
</p><p>22 Section 5 compares the new kernel approach to the standard mean-squared error training approach. [sent-31, score-0.254]
</p><p>23 2 Polynomial classiﬁers for sequence data We start by considering the problem of speaker veriﬁcation–a two-class problem. [sent-32, score-0.587]
</p><p>24 In this case, the goal is to determine the correctness of an identity claim (e. [sent-33, score-0.117]
</p><p>25 , a user id was entered in the system) from a voice input. [sent-35, score-0.132]
</p><p>26 If is the class, then the decision to be made is if the claim is valid, , or if an impostor is trying to break into the system, . [sent-36, score-0.204]
</p><p>27 ¥ © ¡ ¢   § £ ¡ ¨¦¥¤¢   For the veriﬁcation application, a decision is made from a sequence of observations extracted from the speech input. [sent-38, score-0.261]
</p><p>28 We decide based on the output of a discriminant function using a polynomial classiﬁer. [sent-39, score-0.209]
</p><p>29 A polynomial classiﬁer of the form where is the vector of classiﬁer parameters (model) and is an expansion of the input and space into the vector of monomials of degree or less is used. [sent-40, score-0.239]
</p><p>30 5  If the polynomial classiﬁer is trained with a mean-squared error training criterion and target values of for and for , then will approximate the a posteriori probability [11]. [sent-44, score-0.359]
</p><p>31   `V   & )0 S"¥Ua  Y Y § £ ¡ & $S"¥XW  V § £ ¡ S"¥@  H  For the purposes of classiﬁcation, we can discard sides to get the discriminant function  (2)  where we have used the shorthand to denote the sequence . [sent-53, score-0.125]
</p><p>32 We use two terms of the Taylor series, , to approximate the discriminant function and also normalize by the number of frames to obtain the ﬁnal discriminant function (4)  Note that we have discarded the in this discriminant function since this will not affect the classiﬁcation decision. [sent-54, score-0.2]
</p><p>33 Substituting in the polynomial function  ¡  (5)  ¢ £  ¤ ¥  ¤  where we have deﬁned the mapping  as  ¦ §  (6)  ¦ ¨  We summarize the scoring method. [sent-58, score-0.323]
</p><p>34 For a sequence of input vectors and a speaker model, , we construct using (6). [sent-59, score-0.587]
</p><p>35 Since we are performing veriﬁcation, if is above a threshold then we declare the identity claim valid; otherwise, the claim is rejected as an impostor attempt. [sent-61, score-0.361]
</p><p>36 More details on this probabilistic scoring method can be found in [13]. [sent-62, score-0.202]
</p><p>37 ¤  1  ¤  ©   ©           Extending the sequence scoring framework to the case of identiﬁcation (i. [sent-63, score-0.24]
</p><p>38 , identifying the speaker from a list of speakers by voice) is straightforward. [sent-65, score-0.619]
</p><p>39 In this case, we construct speaker models for each speaker and then choose the speaker which maximizes (assuming equal prior probability of each speaker). [sent-66, score-1.56]
</p><p>40 ¤  5 3d 1  d 1    3 Mean-squared error training We next review how to train the polynomial classiﬁer to approximate the probability ; this process will help us set notation for the following sections. [sent-68, score-0.247]
</p><p>41 The desired speaker model and resulting problem is (7)  1  T ¡ ) ¥ f© &  ) & 0(& ) B    35 1 H ¡ ) S¦¥£ & §        1 2  0     ) Y & 0 h  V  u © ¡ 1 )  &  ( & )'%  " #  $  ! [sent-72, score-0.52]
</p><p>42 This criterion can be approximated using the training set as %  "  ! [sent-74, score-0.106]
</p><p>43        "u  ) d & 35 1 fed r ¢ ) d `& 35 1 edr  ¡ 1 © B BH R S  E F  P Q  (8)  C C  CI G @ H 96  CD A @8 6 B#975  C  C  C  C  " 4  $  3  where      Here, the speaker’s training data is , and the anti-speaker data is . [sent-75, score-0.124]
</p><p>44 (Anti-speakers are designed to have the same statistical characteristics as the impostor set. [sent-76, score-0.125]
</p><p>45      P T  A @ B#8 6  @ HG 6  P  The training method can be written in matrix form. [sent-78, score-0.106]
</p><p>46 First, deﬁne rows are the polynomial expansion of the speaker’s data; i. [sent-79, score-0.175]
</p><p>47 Deﬁne  X  Deﬁne a similar matrix for the impostor data,  zeros (i. [sent-87, score-0.125]
</p><p>48 If we deﬁne becomes  and solve for  1  U  We rearrange (12) to  (12)  , then (13) (14)  U  ¨  U  Y X `QV  4 The naive a posteriori sequence kernel  We can now combine the methods from Sections 2 and 3 to obtain a novel sequence comparison kernel in a straightforward manner. [sent-91, score-0.472]
</p><p>49 Combine the speaker model from (14) with the scoring equation from (5) to obtain the classiﬁer score   0 5   (3 5 ¡ ) &  # (E " #  & & ' 1 #  ( )5 #  %b ¢ ¦ H & )   ¨ )  # "! [sent-92, score-0.693]
</p><p>50 5 ¤  ¤    where is data using (6)), and  Y X V  Now population), so that (15) becomes  (15)  (note that this exactly the same as mapping the training . [sent-94, score-0.103]
</p><p>51 The scoring method in (16) is the basis of our sequence kernel. [sent-95, score-0.269]
</p><p>52 Given two sequences of speech feature vectors, and , we compare them by mapping and and then computing (17) We call the naive a posteriori sequence kernel since scoring assumes independence of observations and training approximates the a posteriori probabilities. [sent-96, score-0.86]
</p><p>53 The value can be interpreted as scoring using a polynomial classiﬁer on the sequence , see (5), with the MSE model trained from feature vectors (or vice-versa because of symmetry). [sent-97, score-0.397]
</p><p>54 First, scoring complexity can using be reduced dramatically in training by the following trick. [sent-99, score-0.304]
</p><p>55 , if we transform all the sequence data by before training, the sequence kernel is a simple inner product. [sent-104, score-0.265]
</p><p>56 For our application in Section 5, this reduces training time from hours per speaker down to seconds on a Sun Ultra , MHz. [sent-105, score-0.654]
</p><p>57 Second, since the NAPS kernel explicitly performs the expansion to “feature space”, we can simplify the output of the support vector machine. [sent-106, score-0.284]
</p><p>58 That is, once we train the support vector machine, we can collapse all the support vectors down into a single model , where is the quantity in parenthesis in (19). [sent-109, score-0.118]
</p><p>59 Third, although the NAPS kernel is reminiscent of the Mahalanobis distance, it is distinct. [sent-110, score-0.131]
</p><p>60 No assumption of equal covariance matrices for different classes (speakers) is made for the new kernel–the kernel covariance matrix is a mixture of the individual class covariances. [sent-111, score-0.131]
</p><p>61 Also, the kernel is not a distance measure–no subtraction of means occurs as in the Mahalanobis distance. [sent-112, score-0.131]
</p><p>62 1 Setup The NAPS kernel was tested on the standard speaker recognition database YOHO [14] collected from 138 speakers. [sent-114, score-0.745]
</p><p>63 ” Enrollment and veriﬁcation session were recorded at distinct times. [sent-118, score-0.092]
</p><p>64 (Enrollment is the process of collecting data for training and generating a speaker model. [sent-119, score-0.597]
</p><p>65 , the user makes an identity claim and then this hypothesis is veriﬁed. [sent-122, score-0.144]
</p><p>66 ) For each speaker, enrollment consisted of four sessions each containing twenty-four utterances. [sent-123, score-0.254]
</p><p>67 Veriﬁcation consisted of ten separate sessions with four utterances per session (again per speaker). [sent-124, score-0.24]
</p><p>68 Thus, there are 40 tests of the speaker’s identity and 40*137=5480 possible impostor attempts on a speaker. [sent-125, score-0.163]
</p><p>69 For clarity, we emphasize that enrollment and veriﬁcation session data is completely separate. [sent-126, score-0.267]
</p><p>70 To extract features for each of the utterances, we used standard speech processing. [sent-127, score-0.141]
</p><p>71 Each utterance was broken up into frames of ms each with a frame rate of frames/sec. [sent-128, score-0.086]
</p><p>72 T vT H  H  T8  § ¨H § ¨H  T qT § ¥£    ¦¤¢ ST  For veriﬁcation, we measure performance in terms of the pooled and average equal error rates (EER). [sent-134, score-0.235]
</p><p>73 The individual EER is the threshold at which the false accept rate (FAR) equals the false reject rate (FRR). [sent-136, score-0.138]
</p><p>74 The pooled EER is found by setting a constant threshold across the entire population. [sent-137, score-0.22]
</p><p>75 When the FAR equals the FRR for the entire population this is termed the pooled EER. [sent-138, score-0.215]
</p><p>76 ¢ 8  ¢ ©8  To eliminate bias in veriﬁcation, we trained the ﬁrst speakers against the ﬁrst and the second against the second (as in [7]). [sent-140, score-0.158]
</p><p>77 We then performed veriﬁcation using the second as impostors to the ﬁrst speakers models and vice versa. [sent-141, score-0.149]
</p><p>78 2 Experiments We trained support vector machines for each speaker using the software tool SVMTorch [15] and the NAPS kernel (17). [sent-145, score-0.792]
</p><p>79 The cepstral features were mapped to a dimension vector using a rd degree polynomial classiﬁer. [sent-146, score-0.195]
</p><p>80 We cross-validated using the ﬁrst enrollment sessions as training and the th enrollment session as a test to determine the best tradeoff between margin and error; the best performing value of was used with the ﬁnal SVMTorch training. [sent-150, score-0.598]
</p><p>81 Using the identical set of features and the same methodology, classiﬁer models were also trained using the mean-squared error criterion using the method in [7]. [sent-151, score-0.137]
</p><p>82 For ﬁnal testing, all enrollment session were used for training, and all veriﬁcation sessions were used for testing. [sent-152, score-0.346]
</p><p>83 The new kernel method reduces error rates considerably–the average EER is reduced by , the pooled EER is reduced by , and the identiﬁcation error rate is reduced by . [sent-154, score-0.576]
</p><p>84 The average number of support vectors was which resulted in a model size of about bytes (in single precision ﬂoating point); using the model size reduction method in Section 4 resulted in a model size of bytes–over a hundred times reduction in size. [sent-155, score-0.273]
</p><p>85 72%  We also plotted scores for all speakers versus a threshold, see Figure 1. [sent-162, score-0.124]
</p><p>86 One can easily see the reduction in pooled EER from the graph. [sent-164, score-0.189]
</p><p>87 Note also the dramatic shifting of the FRR curve to the right for the SVM training, resulting in substantially better error rates , the MSE training method gives than the MSE training. [sent-165, score-0.191]
</p><p>88 For instance, when FAR is ; whereas, the SVM training method gives an FRR of –a reduction by an FRR of a factor of in error. [sent-166, score-0.145]
</p><p>89 This data-dependent kernel was motivated by using a probabilistic scoring method and mean-squared error training. [sent-168, score-0.379]
</p><p>90 Experiments showed that incorporating this kernel in an SVM training architecture yielded performance superior to that of the MSE training criterion. [sent-169, score-0.285]
</p><p>91 6 £  8  The new kernel method is also applicable to more general situations. [sent-171, score-0.16]
</p><p>92 Potential applications include–using the approach with radial basis functions, application to automatic speech recognition, and extending to an SVM/HMM architecture. [sent-172, score-0.192]
</p><p>93 [2] Aravind Ganapathiraju and Joseph Picone, “Hybrid SVM/HMM architectures for speech recognition,” in Speech Transcription Workshop, 2000. [sent-176, score-0.141]
</p><p>94 [5] Nathan Smith, Mark Gales, and Mahesan Niranjan, “Data-dependent kernels in SVM classiﬁcation of speech patterns,” Tech. [sent-194, score-0.141]
</p><p>95 Gopinath, “A hybrid GMM/SVM approach to speaker ri a recognition,” in Proceedings of the International Conference on Acoustics, Speech, and Signal Processing, 2001. [sent-199, score-0.546]
</p><p>96 Assaleh, “Polynomial classiﬁer techniques for speaker veriﬁcation,” in Proceedings of the International Conference on Acoustics, Speech, and Signal Processing, 1999, pp. [sent-202, score-0.52]
</p><p>97 Assaleh, “Speaker recognition using neural networks and conventional classiﬁers,” IEEE Trans. [sent-207, score-0.094]
</p><p>98 Reynolds, “Automatic speaker recognition using Gaussian mixture speaker models,” The Lincoln Laboratory Journal, vol. [sent-214, score-1.134]
</p><p>99 Bridle, “A speaker veriﬁcation system using alpha-nets,” in Proceedings of the International Conference on Acoustics Speech and Signal Processing, 1991, pp. [sent-221, score-0.52]
</p><p>100 Broun, “A computationally scalable speaker recognition system,” in Proceedings of EUSIPCO, 2000, pp. [sent-229, score-0.614]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('speaker', 0.52), ('veri', 0.257), ('eer', 0.249), ('mse', 0.208), ('classi', 0.176), ('enrollment', 0.175), ('frr', 0.175), ('naps', 0.175), ('scoring', 0.173), ('cation', 0.155), ('pooled', 0.15), ('speech', 0.141), ('kernel', 0.131), ('impostor', 0.125), ('polynomial', 0.124), ('er', 0.112), ('qv', 0.108), ('gv', 0.099), ('speakers', 0.099), ('svm', 0.096), ('recognition', 0.094), ('identi', 0.092), ('campbell', 0.092), ('session', 0.092), ('voice', 0.079), ('sessions', 0.079), ('claim', 0.079), ('training', 0.077), ('ers', 0.072), ('utterances', 0.069), ('sequence', 0.067), ('william', 0.063), ('acoustics', 0.06), ('discriminant', 0.058), ('observations', 0.053), ('expansion', 0.051), ('posteriori', 0.05), ('assaleh', 0.05), ('edr', 0.05), ('impostors', 0.05), ('joseph', 0.05), ('khaled', 0.05), ('mahalanobis', 0.05), ('yoho', 0.05), ('fed', 0.047), ('error', 0.046), ('bytes', 0.043), ('cholesky', 0.043), ('ua', 0.043), ('support', 0.043), ('sequences', 0.041), ('threshold', 0.04), ('resulted', 0.04), ('cepstral', 0.039), ('emission', 0.039), ('rates', 0.039), ('reduction', 0.039), ('identity', 0.038), ('frame', 0.036), ('signal', 0.035), ('population', 0.035), ('svmtorch', 0.035), ('trained', 0.033), ('machines', 0.033), ('vector', 0.032), ('bb', 0.031), ('st', 0.03), ('haussler', 0.03), ('reduces', 0.03), ('entire', 0.03), ('method', 0.029), ('criterion', 0.029), ('taylor', 0.028), ('preserves', 0.028), ('reduced', 0.027), ('output', 0.027), ('proceedings', 0.027), ('dramatically', 0.027), ('user', 0.027), ('coef', 0.027), ('application', 0.027), ('testing', 0.027), ('naive', 0.026), ('frames', 0.026), ('id', 0.026), ('mapping', 0.026), ('far', 0.026), ('hybrid', 0.026), ('eliminate', 0.026), ('false', 0.025), ('scores', 0.025), ('independence', 0.025), ('nal', 0.024), ('ideal', 0.024), ('extending', 0.024), ('jaakkola', 0.024), ('rate', 0.024), ('hg', 0.024), ('methodology', 0.024), ('sch', 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999964 <a title="20-tfidf-1" href="./nips-2001-A_Sequence_Kernel_and_its_Application_to_Speaker_Recognition.html">20 nips-2001-A Sequence Kernel and its Application to Speaker Recognition</a></p>
<p>Author: William M. Campbell</p><p>Abstract: A novel approach for comparing sequences of observations using an explicit-expansion kernel is demonstrated. The kernel is derived using the assumption of the independence of the sequence of observations and a mean-squared error training criterion. The use of an explicit expansion kernel reduces classiﬁer model size and computation dramatically, resulting in model sizes and computation one-hundred times smaller in our application. The explicit expansion also preserves the computational advantages of an earlier architecture based on mean-squared error training. Training using standard support vector machine methodology gives accuracy that signiﬁcantly exceeds the performance of state-of-the-art mean-squared error training for a speaker recognition task.</p><p>2 0.26012498 <a title="20-tfidf-2" href="./nips-2001-Dynamic_Time-Alignment_Kernel_in_Support_Vector_Machine.html">63 nips-2001-Dynamic Time-Alignment Kernel in Support Vector Machine</a></p>
<p>Author: Hiroshi Shimodaira, Ken-ichi Noma, Mitsuru Nakai, Shigeki Sagayama</p><p>Abstract: A new class of Support Vector Machine (SVM) that is applicable to sequential-pattern recognition such as speech recognition is developed by incorporating an idea of non-linear time alignment into the kernel function. Since the time-alignment operation of sequential pattern is embedded in the new kernel function, standard SVM training and classiﬁcation algorithms can be employed without further modiﬁcations. The proposed SVM (DTAK-SVM) is evaluated in speaker-dependent speech recognition experiments of hand-segmented phoneme recognition. Preliminary experimental results show comparable recognition performance with hidden Markov models (HMMs). 1</p><p>3 0.22320317 <a title="20-tfidf-3" href="./nips-2001-Audio-Visual_Sound_Separation_Via_Hidden_Markov_Models.html">39 nips-2001-Audio-Visual Sound Separation Via Hidden Markov Models</a></p>
<p>Author: John R. Hershey, Michael Casey</p><p>Abstract: It is well known that under noisy conditions we can hear speech much more clearly when we read the speaker's lips. This suggests the utility of audio-visual information for the task of speech enhancement. We propose a method to exploit audio-visual cues to enable speech separation under non-stationary noise and with a single microphone. We revise and extend HMM-based speech enhancement techniques, in which signal and noise models are factori ally combined, to incorporate visual lip information and employ novel signal HMMs in which the dynamics of narrow-band and wide band components are factorial. We avoid the combinatorial explosion in the factorial model by using a simple approximate inference technique to quickly estimate the clean signals in a mixture. We present a preliminary evaluation of this approach using a small-vocabulary audio-visual database, showing promising improvements in machine intelligibility for speech enhanced using audio and visual information. 1</p><p>4 0.17197716 <a title="20-tfidf-4" href="./nips-2001-Categorization_by_Learning_and_Combining_Object_Parts.html">46 nips-2001-Categorization by Learning and Combining Object Parts</a></p>
<p>Author: Bernd Heisele, Thomas Serre, Massimiliano Pontil, Thomas Vetter, Tomaso Poggio</p><p>Abstract: We describe an algorithm for automatically learning discriminative components of objects with SVM classiﬁers. It is based on growing image parts by minimizing theoretical bounds on the error probability of an SVM. Component-based face classiﬁers are then combined in a second stage to yield a hierarchical SVM classiﬁer. Experimental results in face classiﬁcation show considerable robustness against rotations in depth and suggest performance at signiﬁcantly better level than other face detection systems. Novel aspects of our approach are: a) an algorithm to learn component-based classiﬁcation experts and their combination, b) the use of 3-D morphable models for training, and c) a maximum operation on the output of each component classiﬁer which may be relevant for biological models of visual recognition.</p><p>5 0.14021027 <a title="20-tfidf-5" href="./nips-2001-Fast_and_Robust_Classification_using_Asymmetric_AdaBoost_and_a_Detector_Cascade.html">77 nips-2001-Fast and Robust Classification using Asymmetric AdaBoost and a Detector Cascade</a></p>
<p>Author: Paul Viola, Michael Jones</p><p>Abstract: This paper develops a new approach for extremely fast detection in domains where the distribution of positive and negative examples is highly skewed (e.g. face detection or database retrieval). In such domains a cascade of simple classiﬁers each trained to achieve high detection rates and modest false positive rates can yield a ﬁnal detector with many desirable features: including high detection rates, very low false positive rates, and fast performance. Achieving extremely high detection rates, rather than low error, is not a task typically addressed by machine learning algorithms. We propose a new variant of AdaBoost as a mechanism for training the simple classiﬁers used in the cascade. Experimental results in the domain of face detection show the training algorithm yields signiﬁcant improvements in performance over conventional AdaBoost. The ﬁnal face detection system can process 15 frames per second, achieves over 90% detection, and a false positive rate of 1 in a 1,000,000.</p><p>6 0.13622423 <a title="20-tfidf-6" href="./nips-2001-Classifying_Single_Trial_EEG%3A_Towards_Brain_Computer_Interfacing.html">50 nips-2001-Classifying Single Trial EEG: Towards Brain Computer Interfacing</a></p>
<p>7 0.12467556 <a title="20-tfidf-7" href="./nips-2001-Discriminative_Direction_for_Kernel_Classifiers.html">60 nips-2001-Discriminative Direction for Kernel Classifiers</a></p>
<p>8 0.12252197 <a title="20-tfidf-8" href="./nips-2001-Speech_Recognition_using_SVMs.html">172 nips-2001-Speech Recognition using SVMs</a></p>
<p>9 0.115605 <a title="20-tfidf-9" href="./nips-2001-Kernel_Machines_and_Boolean_Functions.html">105 nips-2001-Kernel Machines and Boolean Functions</a></p>
<p>10 0.11542501 <a title="20-tfidf-10" href="./nips-2001-Asymptotic_Universality_for_Learning_Curves_of_Support_Vector_Machines.html">38 nips-2001-Asymptotic Universality for Learning Curves of Support Vector Machines</a></p>
<p>11 0.11313887 <a title="20-tfidf-11" href="./nips-2001-Reducing_multiclass_to_binary_by_coupling_probability_estimates.html">159 nips-2001-Reducing multiclass to binary by coupling probability estimates</a></p>
<p>12 0.11189935 <a title="20-tfidf-12" href="./nips-2001-Adaptive_Sparseness_Using_Jeffreys_Prior.html">29 nips-2001-Adaptive Sparseness Using Jeffreys Prior</a></p>
<p>13 0.11080127 <a title="20-tfidf-13" href="./nips-2001-Sampling_Techniques_for_Kernel_Methods.html">164 nips-2001-Sampling Techniques for Kernel Methods</a></p>
<p>14 0.10456865 <a title="20-tfidf-14" href="./nips-2001-Speech_Recognition_with_Missing_Data_using_Recurrent_Neural_Nets.html">173 nips-2001-Speech Recognition with Missing Data using Recurrent Neural Nets</a></p>
<p>15 0.10442074 <a title="20-tfidf-15" href="./nips-2001-ALGONQUIN_-_Learning_Dynamic_Noise_Models_From_Noisy_Speech_for_Robust_Speech_Recognition.html">4 nips-2001-ALGONQUIN - Learning Dynamic Noise Models From Noisy Speech for Robust Speech Recognition</a></p>
<p>16 0.10107777 <a title="20-tfidf-16" href="./nips-2001-Online_Learning_with_Kernels.html">139 nips-2001-Online Learning with Kernels</a></p>
<p>17 0.096967138 <a title="20-tfidf-17" href="./nips-2001-Multiplicative_Updates_for_Classification_by_Mixture_Models.html">129 nips-2001-Multiplicative Updates for Classification by Mixture Models</a></p>
<p>18 0.096179463 <a title="20-tfidf-18" href="./nips-2001-Prodding_the_ROC_Curve%3A_Constrained_Optimization_of_Classifier_Performance.html">152 nips-2001-Prodding the ROC Curve: Constrained Optimization of Classifier Performance</a></p>
<p>19 0.089900315 <a title="20-tfidf-19" href="./nips-2001-Kernel_Logistic_Regression_and_the_Import_Vector_Machine.html">104 nips-2001-Kernel Logistic Regression and the Import Vector Machine</a></p>
<p>20 0.088736273 <a title="20-tfidf-20" href="./nips-2001-Partially_labeled_classification_with_Markov_random_walks.html">144 nips-2001-Partially labeled classification with Markov random walks</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2001_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.248), (1, 0.172), (2, -0.104), (3, 0.132), (4, -0.171), (5, 0.211), (6, 0.101), (7, -0.111), (8, 0.019), (9, 0.04), (10, -0.024), (11, -0.091), (12, -0.093), (13, 0.148), (14, -0.09), (15, 0.025), (16, 0.022), (17, -0.003), (18, -0.101), (19, -0.087), (20, 0.009), (21, -0.078), (22, 0.081), (23, 0.008), (24, -0.028), (25, 0.032), (26, -0.036), (27, -0.029), (28, 0.069), (29, -0.056), (30, -0.007), (31, -0.004), (32, -0.026), (33, 0.013), (34, 0.041), (35, 0.089), (36, -0.022), (37, 0.029), (38, 0.033), (39, -0.036), (40, -0.038), (41, 0.021), (42, -0.0), (43, -0.04), (44, -0.013), (45, -0.047), (46, -0.021), (47, -0.005), (48, 0.025), (49, 0.011)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96020353 <a title="20-lsi-1" href="./nips-2001-A_Sequence_Kernel_and_its_Application_to_Speaker_Recognition.html">20 nips-2001-A Sequence Kernel and its Application to Speaker Recognition</a></p>
<p>Author: William M. Campbell</p><p>Abstract: A novel approach for comparing sequences of observations using an explicit-expansion kernel is demonstrated. The kernel is derived using the assumption of the independence of the sequence of observations and a mean-squared error training criterion. The use of an explicit expansion kernel reduces classiﬁer model size and computation dramatically, resulting in model sizes and computation one-hundred times smaller in our application. The explicit expansion also preserves the computational advantages of an earlier architecture based on mean-squared error training. Training using standard support vector machine methodology gives accuracy that signiﬁcantly exceeds the performance of state-of-the-art mean-squared error training for a speaker recognition task.</p><p>2 0.85171586 <a title="20-lsi-2" href="./nips-2001-Dynamic_Time-Alignment_Kernel_in_Support_Vector_Machine.html">63 nips-2001-Dynamic Time-Alignment Kernel in Support Vector Machine</a></p>
<p>Author: Hiroshi Shimodaira, Ken-ichi Noma, Mitsuru Nakai, Shigeki Sagayama</p><p>Abstract: A new class of Support Vector Machine (SVM) that is applicable to sequential-pattern recognition such as speech recognition is developed by incorporating an idea of non-linear time alignment into the kernel function. Since the time-alignment operation of sequential pattern is embedded in the new kernel function, standard SVM training and classiﬁcation algorithms can be employed without further modiﬁcations. The proposed SVM (DTAK-SVM) is evaluated in speaker-dependent speech recognition experiments of hand-segmented phoneme recognition. Preliminary experimental results show comparable recognition performance with hidden Markov models (HMMs). 1</p><p>3 0.67534292 <a title="20-lsi-3" href="./nips-2001-Speech_Recognition_with_Missing_Data_using_Recurrent_Neural_Nets.html">173 nips-2001-Speech Recognition with Missing Data using Recurrent Neural Nets</a></p>
<p>Author: S. Parveen, P. Green</p><p>Abstract: In the ‘missing data’ approach to improving the robustness of automatic speech recognition to added noise, an initial process identiﬁes spectraltemporal regions which are dominated by the speech source. The remaining regions are considered to be ‘missing’. In this paper we develop a connectionist approach to the problem of adapting speech recognition to the missing data case, using Recurrent Neural Networks. In contrast to methods based on Hidden Markov Models, RNNs allow us to make use of long-term time constraints and to make the problems of classiﬁcation with incomplete data and imputing missing values interact. We report encouraging results on an isolated digit recognition task.</p><p>4 0.662467 <a title="20-lsi-4" href="./nips-2001-Kernel_Logistic_Regression_and_the_Import_Vector_Machine.html">104 nips-2001-Kernel Logistic Regression and the Import Vector Machine</a></p>
<p>Author: Ji Zhu, Trevor Hastie</p><p>Abstract: The support vector machine (SVM) is known for its good performance in binary classiﬁcation, but its extension to multi-class classiﬁcation is still an on-going research issue. In this paper, we propose a new approach for classiﬁcation, called the import vector machine (IVM), which is built on kernel logistic regression (KLR). We show that the IVM not only performs as well as the SVM in binary classiﬁcation, but also can naturally be generalized to the multi-class case. Furthermore, the IVM provides an estimate of the underlying probability. Similar to the “support points” of the SVM, the IVM model uses only a fraction of the training data to index kernel basis functions, typically a much smaller fraction than the SVM. This gives the IVM a computational advantage over the SVM, especially when the size of the training data set is large.</p><p>5 0.62091607 <a title="20-lsi-5" href="./nips-2001-Categorization_by_Learning_and_Combining_Object_Parts.html">46 nips-2001-Categorization by Learning and Combining Object Parts</a></p>
<p>Author: Bernd Heisele, Thomas Serre, Massimiliano Pontil, Thomas Vetter, Tomaso Poggio</p><p>Abstract: We describe an algorithm for automatically learning discriminative components of objects with SVM classiﬁers. It is based on growing image parts by minimizing theoretical bounds on the error probability of an SVM. Component-based face classiﬁers are then combined in a second stage to yield a hierarchical SVM classiﬁer. Experimental results in face classiﬁcation show considerable robustness against rotations in depth and suggest performance at signiﬁcantly better level than other face detection systems. Novel aspects of our approach are: a) an algorithm to learn component-based classiﬁcation experts and their combination, b) the use of 3-D morphable models for training, and c) a maximum operation on the output of each component classiﬁer which may be relevant for biological models of visual recognition.</p><p>6 0.59484369 <a title="20-lsi-6" href="./nips-2001-Classifying_Single_Trial_EEG%3A_Towards_Brain_Computer_Interfacing.html">50 nips-2001-Classifying Single Trial EEG: Towards Brain Computer Interfacing</a></p>
<p>7 0.58986998 <a title="20-lsi-7" href="./nips-2001-Audio-Visual_Sound_Separation_Via_Hidden_Markov_Models.html">39 nips-2001-Audio-Visual Sound Separation Via Hidden Markov Models</a></p>
<p>8 0.57464474 <a title="20-lsi-8" href="./nips-2001-Fast_and_Robust_Classification_using_Asymmetric_AdaBoost_and_a_Detector_Cascade.html">77 nips-2001-Fast and Robust Classification using Asymmetric AdaBoost and a Detector Cascade</a></p>
<p>9 0.57065636 <a title="20-lsi-9" href="./nips-2001-Discriminative_Direction_for_Kernel_Classifiers.html">60 nips-2001-Discriminative Direction for Kernel Classifiers</a></p>
<p>10 0.55317092 <a title="20-lsi-10" href="./nips-2001-Adaptive_Sparseness_Using_Jeffreys_Prior.html">29 nips-2001-Adaptive Sparseness Using Jeffreys Prior</a></p>
<p>11 0.54568434 <a title="20-lsi-11" href="./nips-2001-Prodding_the_ROC_Curve%3A_Constrained_Optimization_of_Classifier_Performance.html">152 nips-2001-Prodding the ROC Curve: Constrained Optimization of Classifier Performance</a></p>
<p>12 0.53433603 <a title="20-lsi-12" href="./nips-2001-Reducing_multiclass_to_binary_by_coupling_probability_estimates.html">159 nips-2001-Reducing multiclass to binary by coupling probability estimates</a></p>
<p>13 0.52314812 <a title="20-lsi-13" href="./nips-2001-ALGONQUIN_-_Learning_Dynamic_Noise_Models_From_Noisy_Speech_for_Robust_Speech_Recognition.html">4 nips-2001-ALGONQUIN - Learning Dynamic Noise Models From Noisy Speech for Robust Speech Recognition</a></p>
<p>14 0.51174664 <a title="20-lsi-14" href="./nips-2001-Speech_Recognition_using_SVMs.html">172 nips-2001-Speech Recognition using SVMs</a></p>
<p>15 0.49462089 <a title="20-lsi-15" href="./nips-2001-Intransitive_Likelihood-Ratio_Classifiers.html">99 nips-2001-Intransitive Likelihood-Ratio Classifiers</a></p>
<p>16 0.48246506 <a title="20-lsi-16" href="./nips-2001-Kernel_Machines_and_Boolean_Functions.html">105 nips-2001-Kernel Machines and Boolean Functions</a></p>
<p>17 0.4631404 <a title="20-lsi-17" href="./nips-2001-Sequential_Noise_Compensation_by_Sequential_Monte_Carlo_Method.html">168 nips-2001-Sequential Noise Compensation by Sequential Monte Carlo Method</a></p>
<p>18 0.41674918 <a title="20-lsi-18" href="./nips-2001-Asymptotic_Universality_for_Learning_Curves_of_Support_Vector_Machines.html">38 nips-2001-Asymptotic Universality for Learning Curves of Support Vector Machines</a></p>
<p>19 0.40462163 <a title="20-lsi-19" href="./nips-2001-Sampling_Techniques_for_Kernel_Methods.html">164 nips-2001-Sampling Techniques for Kernel Methods</a></p>
<p>20 0.40436307 <a title="20-lsi-20" href="./nips-2001-A_New_Discriminative_Kernel_From_Probabilistic_Models.html">15 nips-2001-A New Discriminative Kernel From Probabilistic Models</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2001_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.059), (17, 0.012), (19, 0.038), (20, 0.02), (27, 0.098), (30, 0.139), (38, 0.015), (57, 0.29), (59, 0.02), (66, 0.011), (72, 0.081), (79, 0.03), (83, 0.017), (91, 0.098)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.81660247 <a title="20-lda-1" href="./nips-2001-A_Sequence_Kernel_and_its_Application_to_Speaker_Recognition.html">20 nips-2001-A Sequence Kernel and its Application to Speaker Recognition</a></p>
<p>Author: William M. Campbell</p><p>Abstract: A novel approach for comparing sequences of observations using an explicit-expansion kernel is demonstrated. The kernel is derived using the assumption of the independence of the sequence of observations and a mean-squared error training criterion. The use of an explicit expansion kernel reduces classiﬁer model size and computation dramatically, resulting in model sizes and computation one-hundred times smaller in our application. The explicit expansion also preserves the computational advantages of an earlier architecture based on mean-squared error training. Training using standard support vector machine methodology gives accuracy that signiﬁcantly exceeds the performance of state-of-the-art mean-squared error training for a speaker recognition task.</p><p>2 0.60360312 <a title="20-lda-2" href="./nips-2001-Dynamic_Time-Alignment_Kernel_in_Support_Vector_Machine.html">63 nips-2001-Dynamic Time-Alignment Kernel in Support Vector Machine</a></p>
<p>Author: Hiroshi Shimodaira, Ken-ichi Noma, Mitsuru Nakai, Shigeki Sagayama</p><p>Abstract: A new class of Support Vector Machine (SVM) that is applicable to sequential-pattern recognition such as speech recognition is developed by incorporating an idea of non-linear time alignment into the kernel function. Since the time-alignment operation of sequential pattern is embedded in the new kernel function, standard SVM training and classiﬁcation algorithms can be employed without further modiﬁcations. The proposed SVM (DTAK-SVM) is evaluated in speaker-dependent speech recognition experiments of hand-segmented phoneme recognition. Preliminary experimental results show comparable recognition performance with hidden Markov models (HMMs). 1</p><p>3 0.59820896 <a title="20-lda-3" href="./nips-2001-Probabilistic_Abstraction_Hierarchies.html">149 nips-2001-Probabilistic Abstraction Hierarchies</a></p>
<p>Author: Eran Segal, Daphne Koller, Dirk Ormoneit</p><p>Abstract: Many domains are naturally organized in an abstraction hierarchy or taxonomy, where the instances in “nearby” classes in the taxonomy are similar. In this paper, we provide a general probabilistic framework for clustering data into a set of classes organized as a taxonomy, where each class is associated with a probabilistic model from which the data was generated. The clustering algorithm simultaneously optimizes three things: the assignment of data instances to clusters, the models associated with the clusters, and the structure of the abstraction hierarchy. A unique feature of our approach is that it utilizes global optimization algorithms for both of the last two steps, reducing the sensitivity to noise and the propensity to local maxima that are characteristic of algorithms such as hierarchical agglomerative clustering that only take local steps. We provide a theoretical analysis for our algorithm, showing that it converges to a local maximum of the joint likelihood of model and data. We present experimental results on synthetic data, and on real data in the domains of gene expression and text.</p><p>4 0.59415078 <a title="20-lda-4" href="./nips-2001-KLD-Sampling%3A_Adaptive_Particle_Filters.html">102 nips-2001-KLD-Sampling: Adaptive Particle Filters</a></p>
<p>Author: Dieter Fox</p><p>Abstract: Over the last years, particle ﬁlters have been applied with great success to a variety of state estimation problems. We present a statistical approach to increasing the efﬁciency of particle ﬁlters by adapting the size of sample sets on-the-ﬂy. The key idea of the KLD-sampling method is to bound the approximation error introduced by the sample-based representation of the particle ﬁlter. The name KLD-sampling is due to the fact that we measure the approximation error by the Kullback-Leibler distance. Our adaptation approach chooses a small number of samples if the density is focused on a small part of the state space, and it chooses a large number of samples if the state uncertainty is high. Both the implementation and computation overhead of this approach are small. Extensive experiments using mobile robot localization as a test application show that our approach yields drastic improvements over particle ﬁlters with ﬁxed sample set sizes and over a previously introduced adaptation technique.</p><p>5 0.58317077 <a title="20-lda-5" href="./nips-2001-Discriminative_Direction_for_Kernel_Classifiers.html">60 nips-2001-Discriminative Direction for Kernel Classifiers</a></p>
<p>Author: Polina Golland</p><p>Abstract: In many scientiﬁc and engineering applications, detecting and understanding differences between two groups of examples can be reduced to a classical problem of training a classiﬁer for labeling new examples while making as few mistakes as possible. In the traditional classiﬁcation setting, the resulting classiﬁer is rarely analyzed in terms of the properties of the input data captured by the discriminative model. However, such analysis is crucial if we want to understand and visualize the detected differences. We propose an approach to interpretation of the statistical model in the original feature space that allows us to argue about the model in terms of the relevant changes to the input vectors. For each point in the input space, we deﬁne a discriminative direction to be the direction that moves the point towards the other class while introducing as little irrelevant change as possible with respect to the classiﬁer function. We derive the discriminative direction for kernel-based classiﬁers, demonstrate the technique on several examples and brieﬂy discuss its use in the statistical shape analysis, an application that originally motivated this work.</p><p>6 0.58004498 <a title="20-lda-6" href="./nips-2001-Risk_Sensitive_Particle_Filters.html">163 nips-2001-Risk Sensitive Particle Filters</a></p>
<p>7 0.57949436 <a title="20-lda-7" href="./nips-2001-Fast_and_Robust_Classification_using_Asymmetric_AdaBoost_and_a_Detector_Cascade.html">77 nips-2001-Fast and Robust Classification using Asymmetric AdaBoost and a Detector Cascade</a></p>
<p>8 0.57852048 <a title="20-lda-8" href="./nips-2001-Categorization_by_Learning_and_Combining_Object_Parts.html">46 nips-2001-Categorization by Learning and Combining Object Parts</a></p>
<p>9 0.57088494 <a title="20-lda-9" href="./nips-2001-%28Not%29_Bounding_the_True_Error.html">1 nips-2001-(Not) Bounding the True Error</a></p>
<p>10 0.56918228 <a title="20-lda-10" href="./nips-2001-A_kernel_method_for_multi-labelled_classification.html">22 nips-2001-A kernel method for multi-labelled classification</a></p>
<p>11 0.56914103 <a title="20-lda-11" href="./nips-2001-Probabilistic_principles_in_unsupervised_learning_of_visual_structure%3A_human_data_and_a_model.html">151 nips-2001-Probabilistic principles in unsupervised learning of visual structure: human data and a model</a></p>
<p>12 0.5688386 <a title="20-lda-12" href="./nips-2001-Convolution_Kernels_for_Natural_Language.html">56 nips-2001-Convolution Kernels for Natural Language</a></p>
<p>13 0.56833315 <a title="20-lda-13" href="./nips-2001-Adaptive_Sparseness_Using_Jeffreys_Prior.html">29 nips-2001-Adaptive Sparseness Using Jeffreys Prior</a></p>
<p>14 0.56729406 <a title="20-lda-14" href="./nips-2001-The_Method_of_Quantum_Clustering.html">185 nips-2001-The Method of Quantum Clustering</a></p>
<p>15 0.56698298 <a title="20-lda-15" href="./nips-2001-Classifying_Single_Trial_EEG%3A_Towards_Brain_Computer_Interfacing.html">50 nips-2001-Classifying Single Trial EEG: Towards Brain Computer Interfacing</a></p>
<p>16 0.56679577 <a title="20-lda-16" href="./nips-2001-Linking_Motor_Learning_to_Function_Approximation%3A_Learning_in_an_Unlearnable_Force_Field.html">116 nips-2001-Linking Motor Learning to Function Approximation: Learning in an Unlearnable Force Field</a></p>
<p>17 0.56490129 <a title="20-lda-17" href="./nips-2001-Computing_Time_Lower_Bounds_for_Recurrent_Sigmoidal_Neural_Networks.html">52 nips-2001-Computing Time Lower Bounds for Recurrent Sigmoidal Neural Networks</a></p>
<p>18 0.56248432 <a title="20-lda-18" href="./nips-2001-Relative_Density_Nets%3A_A_New_Way_to_Combine_Backpropagation_with_HMM%27s.html">162 nips-2001-Relative Density Nets: A New Way to Combine Backpropagation with HMM's</a></p>
<p>19 0.56221408 <a title="20-lda-19" href="./nips-2001-Incorporating_Invariances_in_Non-Linear_Support_Vector_Machines.html">92 nips-2001-Incorporating Invariances in Non-Linear Support Vector Machines</a></p>
<p>20 0.56187958 <a title="20-lda-20" href="./nips-2001-Activity_Driven_Adaptive_Stochastic_Resonance.html">27 nips-2001-Activity Driven Adaptive Stochastic Resonance</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
