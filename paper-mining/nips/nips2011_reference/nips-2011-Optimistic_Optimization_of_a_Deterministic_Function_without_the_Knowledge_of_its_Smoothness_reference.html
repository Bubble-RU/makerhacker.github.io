<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>208 nips-2011-Optimistic Optimization of a Deterministic Function without the Knowledge of its Smoothness</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-208" href="../nips2011/nips-2011-Optimistic_Optimization_of_a_Deterministic_Function_without_the_Knowledge_of_its_Smoothness.html">nips2011-208</a> <a title="nips-2011-208-reference" href="#">nips2011-208-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>208 nips-2011-Optimistic Optimization of a Deterministic Function without the Knowledge of its Smoothness</h1>
<br/><p>Source: <a title="nips-2011-208-pdf" href="http://papers.nips.cc/paper/4304-optimistic-optimization-of-a-deterministic-function-without-the-knowledge-of-its-smoothness.pdf">pdf</a></p><p>Author: Rémi Munos</p><p>Abstract: We consider a global optimization problem of a deterministic function f in a semimetric space, given a ﬁnite budget of n evaluations. The function f is assumed to be locally smooth (around one of its global maxima) with respect to a semi-metric ℓ. We describe two algorithms based on optimistic exploration that use a hierarchical partitioning of the space at all scales. A ﬁrst contribution is an algorithm, DOO, that requires the knowledge of ℓ. We report a ﬁnite-sample performance bound in terms of a measure of the quantity of near-optimal states. We then deﬁne a second algorithm, SOO, which does not require the knowledge of the semimetric ℓ under which f is smooth, and whose performance is almost as good as DOO optimally-ﬁtted.</p><br/>
<h2>reference text</h2><p>[ABM10]  J.-Y. Audibert, S. Bubeck, and R. Munos. Best arm identiﬁcation in multi-armed bandits. In Conference on Learning Theory, 2010. [ACBF02] P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit problem. Machine Learning Journal, 47(2-3):235–256, 2002. [AOS07] P. Auer, R. Ortner, and Cs. Szepesv´ ri. Improved rates for the stochastic continuum-armed bandit a problem. 20th Conference on Learning Theory, pages 454–468, 2007. [BM10] S. Bubeck and R. Munos. Open loop optimistic planning. In Conference on Learning Theory, 2010. [BMS09] S. Bubeck, R. Munos, and G. Stoltz. Pure exploration in multi-armed bandits problems. In Proc. of the 20th International Conference on Algorithmic Learning Theory, pages 23–37, 2009. [BMSB11] L. Busoniu, R. Munos, B. De Schutter, and R. Babuska. Optimistic planning for sparsely stochastic systems. In IEEE International Symposium on Adaptive Dynamic Programming and Reinforcement Learning, 2011. [BMSS08] S. Bubeck, R. Munos, G. Stoltz, and Cs. Szepesv´ ri. Online optimization of X-armed bandits. a In D. Koller, D. Schuurmans, Y. Bengio, and L. Bottou, editors, Advances in Neural Information Processing Systems, volume 22, pages 201–208. MIT Press, 2008. [BMSS11] S. Bubeck, R. Munos, G. Stoltz, and Cs. Szepesv´ ri. X-armed bandits. Journal of Machine a Learning Research, 12:1655–1695, 2011. [BSY11] S. Bubeck, G. Stoltz, and J. Y. Yu. Lipschitz bandits without the Lipschitz constant. In Proceedings of the 22nd International Conference on Algorithmic Learning Theory, 2011. [CM07] P.-A. Coquelin and R. Munos. Bandit algorithms for tree search. In Uncertainty in Artiﬁcial Intelligence, 2007. [FK04] D. E. Finkel and C. T. Kelley. Convergence analysis of the direct algorithm. Technical report, North Carolina State University, Center for, 2004. [Flo99] C.A. Floudas. Deterministic Global Optimization: Theory, Algorithms and Applications. Kluwer Academic Publishers, Dordrecht / Boston / London, 1999. [Gab01] J. M. X. Gablonsky. Modiﬁcations of the direct algorithm. PhD thesis, 2001. [GWMT06] S. Gelly, Y. Wang, R. Munos, and O. Teytaud. Modiﬁcation of UCT with patterns in monte-carlo go. Technical report, INRIA RR-6062, 2006. [Han92] E.R. Hansen. Global Optimization Using Interval Analysis. Marcel Dekker, New York, 1992. [HM08] J-F. Hren and R. Munos. Optimistic planning of deterministic systems. In European Workshop on Reinforcement Learning Springer LNAI 5323, editor, Recent Advances in Reinforcement Learning, pages 151–164, 2008. [HT96] R. Horst and H. Tuy. Global Optimization ? Deterministic Approaches. Springer, Berlin / Heidelberg / New York, 3rd edition, 1996. [JPS93] D. R. Jones, C. D. Perttunen, and B. E. Stuckman. Lipschitzian optimization without the lipschitz constant. Journal of Optimization Theory and Applications, 79(1):157–181, 1993. [Kea96] R. B. Kearfott. Rigorous Global Search: Continuous Problems. Kluwer Academic Publishers, Dordrecht / Boston / London, 1996. [Kle04] R. Kleinberg. Nearly tight bounds for the continuum-armed bandit problem. In 18th Advances in Neural Information Processing Systems, 2004. [KS06] L. Kocsis and Cs. Szepesv´ ri. Bandit based Monte-Carlo planning. In Proceedings of the 15th a European Conference on Machine Learning, pages 282–293, 2006. [KSU08] R. Kleinberg, A. Slivkins, and E. Upfal. Multi-armed bandits in metric spaces. In Proceedings of the 40th ACM Symposium on Theory of Computing, 2008. [Neu90] Neumaier. Interval Methods for Systems of Equations. Cambridge University Press, 1990. [Pin96] J.D. Pint´ r. Global Optimization in Action (Continuous and Lipschitz Optimization: Algorithms, e Implementations and Applications). Kluwer Academic Publishers, 1996. [SKKS10] Niranjan Srinivas, Andreas Krause, Sham Kakade, and Matthias Seeger. Gaussian process optimization in the bandit setting: No regret and experimental design. In International Conference on Machine Learning, pages 1015–1022, 2010. [Sli11] A. Slivkins. Multi-armed bandits on implicit metric spaces. In Advances in Neural Information Processing Systems, 2011. [SS00] R.G. Strongin and Ya.D. Sergeyev. Global Optimization with Non-Convex Constraints: Sequential and Parallel Algorithms. Kluwer Academic Publishers, Dordrecht / Boston / London, 2000.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
