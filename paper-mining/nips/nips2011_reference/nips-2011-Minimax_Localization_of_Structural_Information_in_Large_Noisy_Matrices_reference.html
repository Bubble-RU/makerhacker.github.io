<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>172 nips-2011-Minimax Localization of Structural Information in Large Noisy Matrices</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-172" href="../nips2011/nips-2011-Minimax_Localization_of_Structural_Information_in_Large_Noisy_Matrices.html">nips2011-172</a> <a title="nips-2011-172-reference" href="#">nips2011-172-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>172 nips-2011-Minimax Localization of Structural Information in Large Noisy Matrices</h1>
<br/><p>Source: <a title="nips-2011-172-pdf" href="http://papers.nips.cc/paper/4218-minimax-localization-of-structural-information-in-large-noisy-matrices.pdf">pdf</a></p><p>Author: Mladen Kolar, Sivaraman Balakrishnan, Alessandro Rinaldo, Aarti Singh</p><p>Abstract: We consider the problem of identifying a sparse set of relevant columns and rows in a large data matrix with highly corrupted entries. This problem of identifying groups from a collection of bipartite variables such as proteins and drugs, biological species and gene sequences, malware and signatures, etc is commonly referred to as biclustering or co-clustering. Despite its great practical relevance, and although several ad-hoc methods are available for biclustering, theoretical analysis of the problem is largely non-existent. The problem we consider is also closely related to structured multiple hypothesis testing, an area of statistics that has recently witnessed a ﬂurry of activity. We make the following contributions 1. We prove lower bounds on the minimum signal strength needed for successful recovery of a bicluster as a function of the noise variance, size of the matrix and bicluster of interest. 2. We show that a combinatorial procedure based on the scan statistic achieves this optimal limit. 3. We characterize the SNR required by several computationally tractable procedures for biclustering including element-wise thresholding, column/row average thresholding and a convex relaxation approach to sparse singular vector decomposition. 1</p><br/>
<h2>reference text</h2><p>[1] Louigi Addario-Berry, Nicolas Broutin, Luc Devroye, and G´ bor Lugosi. On combinatorial testing proba lems. Ann. Statist., 38(5):3063–3092, 2010.</p>
<p>[2] A.A. Amini and M.J. Wainwright. High-Dimensional Analysis Of Semideﬁnite Relaxations For Sparse Principal Components. The Annals of Statistics, 37(5B):2877–2921, 2009.</p>
<p>[3] Ery Arias-Castro, Emmanuel J. Cand` s, and Arnaud Durand. Detection of an anomalous cluster in a e network. Ann. Stat., 39(1):278–304, 2011.</p>
<p>[4] Ery Arias-Castro, Emmanuel J. Cand` s, Hannes Helgason, and Ofer Zeitouni. Searching for a trail of e evidence in a maze. Ann. Statist., 36(4):1726–1757, 2008.</p>
<p>[5] Ery Arias-Castro, David L. Donoho, and Xiaoming Huo. Adaptive multiscale detection of ﬁlamentary structures in a background of uniform random points. Ann. Statist., 34(1):326–349, 2006.</p>
<p>[6] Jushan Bai. Inferential theory for factor models of large dimensions. Econometrica, 71(1):pp. 135–171, 2003.</p>
<p>[7] Ulrich Bayer, Paolo Milani Comparetti, Clemens Hlauscheck, Christopher Kruegel, and Engin Kirda. Scalable, Behavior-Based Malware Clustering. In 16th Symposium on Network and Distributed System Security (NDSS), 2009.</p>
<p>[8] F. Benaych-Georges and R. Rao Nadakuditi. The singular values and vectors of low rank perturbations of large rectangular random matrices. ArXiv e-prints, March 2011.</p>
<p>[9] S. Busygin, O. Prokopyev, and P.M. Pardalos. Biclustering in data mining. Computers & Operations Research, 35(9):2964–2987, 2008.</p>
<p>[10] Emmanuel J. Cand` s, Xiaodong Li, Yi Ma, and John Wright. Robust principal component analysis? e CoRR, abs/0912.3599, 2009.</p>
<p>[11] Alexandre d’Aspremont, Laurent El Ghaoui, Michael I. Jordan, and Gert R. G. Lanckriet. A direct formulation for sparse pca using semideﬁnite programming. SIAM Review, 49:434–448, 2007.</p>
<p>[12] K.R. Davidson and S.J. Szarek. Local operator theory, random matrices and Banach spaces. Handbook of the geometry of Banach spaces, 1:317–366, 2001.</p>
<p>[13] R. Fletcher. Semi-deﬁnite matrix constraints in optimization. SIAM Journal on Control and Optimization, 23:493, 1985.</p>
<p>[14] J. A. Hartigan. Direct clustering of a data matrix. Journal of the American Statistical Association, 67(337):pp. 123–129, 1972.</p>
<p>[15] I.M. Johnstone. On the distribution of the largest eigenvalue in principal components analysis. The Annals of Statistics, 29(2):295–327, 2001.</p>
<p>[16] I.M. Johnstone and A.Y. Lu. On consistency and sparsity for principal components analysis in high dimensions. Journal of the American Statistical Association, 104(486):682–693, 2009.</p>
<p>[17] L. Lazzeroni and A. Owen. Plaid models for gene expression data. Statistica sinica, 12:61–86, 2002.</p>
<p>[18] Mihee Lee, Haipeng Shen, Jianhua Z. Huang, and J. S. Marron. Biclustering via sparse singular value decomposition. Biometrics, 66(4):1087–1095, 2010.</p>
<p>[19] Jinze Liu and Wei Wang. Op-cluster: Clustering by tendency in high dimensional space. In Proceedings of the Third IEEE International Conference on Data Mining, ICDM ’03, pages 187–, Washington, DC, USA, 2003. IEEE Computer Society.</p>
<p>[20] S.C. Madeira and A.L. Oliveira. Biclustering algorithms for biological data analysis: a survey. IEEE Transactions on computational Biology and Bioinformatics, pages 24–45, 2004.</p>
<p>[21] A. Onatski. Asymptotics of the principal components estimator of large factor models with weak factors. Economics Department, Columbia University, 2009.</p>
<p>[22] L. Parsons, E. Haque, and H. Liu. Subspace clustering for high dimensional data: a review. ACM SIGKDD Explorations Newsletter, 6(1):90–105, 2004.</p>
<p>[23] R.T. Rockafellar. The theory of subgradients and its applications to problems of optimization. Convex and nonconvex functions. Heldermann, 1981.</p>
<p>[24] H. Shen and J.Z. Huang. Sparse principal component analysis via regularized low rank matrix approximation. Journal of multivariate analysis, 99(6):1015–1034, 2008.</p>
<p>[25] GW Stewart. Perturbation theory for the singular value decomposition. Computer Science Technical Report Series; Vol. CS-TR-2539, page 13, 1990.</p>
<p>[26] X. Sun and A. B. Nobel. On the maximal size of Large-Average and ANOVA-ﬁt Submatrices in a Gaussian Random Matrix. ArXiv e-prints, September 2010.</p>
<p>[27] A. Tanay, R. Sharan, and R. Shamir. Biclustering algorithms: A survey. Handbook of computational molecular biology, 2004.</p>
<p>[28] A.B. Tsybakov. Introduction to nonparametric estimation. Springer, 2009.</p>
<p>[29] Lyle Ungar and Dean P. Foster. A formal statistical approach to collaborative ﬁltering. In CONALD, 98.</p>
<p>[30] S. Wang, R. R. Gutell, and D. P. Miranker. Biclustering as a method for RNA local multiple sequence alignment. Bioinformatics, 23:3289–3296, Dec 2007.</p>
<p>[31] D.M. Witten, R. Tibshirani, and T. Hastie. A penalized matrix decomposition, with applications to sparse principal components and canonical correlation analysis. Biostatistics, 10(3):515, 2009.</p>
<p>[32] H. Zou, T. Hastie, and R. Tibshirani. Sparse principal component analysis. Journal of computational and graphical statistics, 15(2):265–286, 2006.  9</p>
<br/>
<br/><br/><br/></body>
</html>
