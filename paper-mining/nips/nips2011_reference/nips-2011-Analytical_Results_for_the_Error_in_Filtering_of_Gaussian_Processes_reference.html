<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>37 nips-2011-Analytical Results for the Error in Filtering of Gaussian Processes</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-37" href="../nips2011/nips-2011-Analytical_Results_for_the_Error_in_Filtering_of_Gaussian_Processes.html">nips2011-37</a> <a title="nips-2011-37-reference" href="#">nips2011-37-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>37 nips-2011-Analytical Results for the Error in Filtering of Gaussian Processes</h1>
<br/><p>Source: <a title="nips-2011-37-pdf" href="http://papers.nips.cc/paper/4471-analytical-results-for-the-error-in-filtering-of-gaussian-processes.pdf">pdf</a></p><p>Author: Alex K. Susemihl, Ron Meir, Manfred Opper</p><p>Abstract: Bayesian ﬁltering of stochastic stimuli has received a great deal of attention recently. It has been applied to describe the way in which biological systems dynamically represent and make decisions about the environment. There have been no exact results for the error in the biologically plausible setting of inference on point process, however. We present an exact analysis of the evolution of the meansquared error in a state estimation task using Gaussian-tuned point processes as sensors. This allows us to study the dynamics of the error of an optimal Bayesian decoder, providing insights into the limits obtainable in this task. This is done for Markovian and a class of non-Markovian Gaussian processes. We ﬁnd that there is an optimal tuning width for which the error is minimized. This leads to a characterization of the optimal encoding for the setting as a function of the statistics of the stimulus, providing a mathematically sound primer for an ecological theory of sensory processing. 1</p><br/>
<h2>reference text</h2><p>[1] Tetsuya J. Kobayashi. Implementation of dynamic bayesian decision making by intracellular kinetics. Phys. Rev. Lett., 104(22):228104, Jun 2010.</p>
<p>[2] Jean-Pascal Pﬁster, Peter Dayan, and Mate Lengyel. Know thy neighbour: A normative theory of synaptic depression. In Y. Bengio, D. Schuurmans, J. Lafferty, C. K. I. Williams, and A. Culotta, editors, Advances in Neural Information Processing Systems 22, pages 1464–1472. 2009.</p>
<p>[3] Omer Bobrowski, Ron Meir, Shy Shoham, and Yonina C. Eldar. A neural network implementing optimal state estimation based on dynamic spike train decoding. In Neural Information Processing Systems, 2007.</p>
<p>[4] Dorthe Malzahn and Manfred Opper. A statistical physics approach for the analysis of machine learning algorithms on real data. Journal of Statistical Mechanics: Theory and Experiment, 2005(11):P11001, 2005.</p>
<p>[5] P. Sollich and A. Halees. Learning curves for gaussian process regression: Approximations and bounds. Neural Computation, 14(6):1393–1428, 2002.</p>
<p>[6] J Atick and A.N. Redlich. Could information theory provide an ecological theory of sensory processing? Network: Computation in Neural Systems, 5:213–251, 1992.</p>
<p>[7] M.W. Pettet and C.D. Gilbert. Dynamic changes in receptive-ﬁeld size in cat primary visual cortex. Proceedings of the National Academy of Sciences, 89(17):8366–8370, 1992.</p>
<p>[8] N. Brenner, W. Bialek, and R. de Ruyter van Steveninck. Adaptive rescaling maximizes information transmission. Neuron, 26(3):695–702, 2000.</p>
<p>[9] V. Dragoi, J. Sharma, and M. Sur. Adaptation-induced plasticity of orientation tuning in adult visual cortex. Neuron, 28(1):287–298, 2000.</p>
<p>[10] I. Dean, B.L. Robinson, N.S. Harper, and D. McAlpine. Rapid neural adaptation to sound level statistics. Journal of Neuroscience, 28(25):6430–6438, 2008.</p>
<p>[11] T. Hosoya, S.A. Baccus, and M. Meister. Dynamic predictive coding by the retina. Nature, 436(7047):71–77, 2005.</p>
<p>[12] Steve Yaeli and Ron Meir. Error-based analysis of optimal tuning functions explains phenomena observed in sensory neurons. Frontiers in Computational Neuroscience, 5(0):12, 2010.</p>
<p>[13] Quentin J. M. Huys, Richard S. Zemel, Rama Natarajan, and Peter Dayan. Fast population coding. Neural Computation, 19(2):404–441, 2007.</p>
<p>[14] C.E. Rasmussen and C.K.I. Williams. Gaussian Processes for Machine Learning. The MIT Press, 55 Hayward Street, Cambridge, MA 02142, 2006.</p>
<p>[15] C.W. Gardiner. Stochastic Methods: A Handbook for the Natural and Social Sciences, volume 13 of Springer Serier in Synergetics. Springer, Berlin Heidelberg, fourth edition, 2009.</p>
<p>[16] Hannes Risken. The Fokker-Planck Equation: Methods of Solutions and Applications, volume 18 of Springer Series in Synergetics. Springer, Berlin Heidelberg, second ed. 1989. third printing edition, 1996.</p>
<p>[17] M. Bethge, D. Rotermund, and K. Pawelzik. Optimal short-term population coding: When ﬁsher information fails. Neural Computation, 14(10):2317–2351, 2002.</p>
<p>[18] Philipp Berens, Alexander S. Ecker, Sebastian Gerwinn, Andreas S. Tolias, and Matthias Bethge. Reassessing optimal neural population codes with neurometric functions. Proceedings of the National Academy of Sciences, 108(11):4423–4428, 2011.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
