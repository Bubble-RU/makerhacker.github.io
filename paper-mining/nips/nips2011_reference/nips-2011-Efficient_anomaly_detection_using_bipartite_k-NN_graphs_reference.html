<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>81 nips-2011-Efficient anomaly detection using bipartite k-NN graphs</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-81" href="../nips2011/nips-2011-Efficient_anomaly_detection_using_bipartite_k-NN_graphs.html">nips2011-81</a> <a title="nips-2011-81-reference" href="#">nips2011-81-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>81 nips-2011-Efficient anomaly detection using bipartite k-NN graphs</h1>
<br/><p>Source: <a title="nips-2011-81-pdf" href="http://papers.nips.cc/paper/4287-efficient-anomaly-detection-using-bipartite-k-nn-graphs.pdf">pdf</a></p><p>Author: Kumar Sricharan, Alfred O. Hero</p><p>Abstract: Learning minimum volume sets of an underlying nominal distribution is a very effective approach to anomaly detection. Several approaches to learning minimum volume sets have been proposed in the literature, including the K-point nearest neighbor graph (K-kNNG) algorithm based on the geometric entropy minimization (GEM) principle [4]. The K-kNNG detector, while possessing several desirable characteristics, suffers from high computation complexity, and in [4] a simpler heuristic approximation, the leave-one-out kNNG (L1O-kNNG) was proposed. In this paper, we propose a novel bipartite k-nearest neighbor graph (BPkNNG) anomaly detection scheme for estimating minimum volume sets. Our bipartite estimator retains all the desirable theoretical properties of the K-kNNG, while being computationally simpler than the K-kNNG and the surrogate L1OkNNG detectors. We show that BP-kNNG is asymptotically consistent in recovering the p-value of each test point. Experimental results are given that illustrate the superior performance of BP-kNNG as compared to the L1O-kNNG and other state of the art anomaly detection schemes.</p><br/>
<h2>reference text</h2><p>[1] A. Asuncion and D.J. Newman. UCI machine learning repository, 2007.</p>
<p>[2] S. D. Bay and M. Schwabacher. Mining distance-based outliers in near linear time with randomization and a simple pruning rule. In Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’03, pages 29–38, New York, NY, USA, 2003. ACM.</p>
<p>[3] M. M. Breunig, H. Kriegel, R. T. Ng, and J. Sander. Lof: identifying density-based local outliers. In Proceedings of the 2000 ACM SIGMOD international conference on Management of data, SIGMOD ’00, pages 93–104, New York, NY, USA, 2000. ACM.</p>
<p>[4] A. O. Hero. Geometric entropy minimization (gem) for anomaly detection and localization. In Proc. Advances in Neural Information Processing Systems (NIPS, pages 585–592. MIT Press, 2006.</p>
<p>[5] F. T. Liu, K. M. Ting, and Z. Zhou. Isolation forest. In Proceedings of the 2008 Eighth IEEE International Conference on Data Mining, pages 413–422, Washington, DC, USA, 2008. IEEE Computer Society.</p>
<p>[6] C. Park, J. Z. Huang, and Y. Ding. A computable plug-in estimator of minimum volume sets for novelty detection. Operations Research, 58(5):1469–1480, 2010.</p>
<p>[7] S. Ramaswamy, R. Rastogi, and K. Shim. Efﬁcient algorithms for mining outliers from large data sets. SIGMOD Rec., 29:427–438, May 2000.</p>
<p>[8] D. M. Rocke and D. L. Woodruff. Identiﬁcation of Outliers in Multivariate Data. Journal of the American Statistical Association, 91(435):1047–1061, 1996.</p>
<p>[9] B. Sch¨ lkopf, R. Williamson, A. Smola, J. Shawe-Taylor, and J.Platt. Support Vector Method o for Novelty Detection. volume 12, 2000.</p>
<p>[10] C. Scott and R. Nowak. Learning minimum volume sets. J. Machine Learning Res, 7:665–704, 2006.</p>
<p>[11] K. Sricharan, R. Raich, and A. O. Hero. Empirical estimation of entropy functionals with conﬁdence. ArXiv e-prints, December 2010.</p>
<p>[12] K. M. Ting, G. Zhou, T. F. Liu, and J. S. C. Tan. Mass estimation and its applications. In Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’10, pages 989–998, New York, NY, USA, 2010. ACM.</p>
<p>[13] M. Zhao and V. Saligrama. Anomaly detection with score functions based on nearest neighbor graphs. Computing Research Repository, abs/0910.5461, 2009.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
