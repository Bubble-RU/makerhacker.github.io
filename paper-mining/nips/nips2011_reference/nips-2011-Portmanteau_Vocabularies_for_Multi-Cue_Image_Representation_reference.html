<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>216 nips-2011-Portmanteau Vocabularies for Multi-Cue Image Representation</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-216" href="../nips2011/nips-2011-Portmanteau_Vocabularies_for_Multi-Cue_Image_Representation.html">nips2011-216</a> <a title="nips-2011-216-reference" href="#">nips2011-216-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>216 nips-2011-Portmanteau Vocabularies for Multi-Cue Image Representation</h1>
<br/><p>Source: <a title="nips-2011-216-pdf" href="http://papers.nips.cc/paper/4481-portmanteau-vocabularies-for-multi-cue-image-representation.pdf">pdf</a></p><p>Author: Fahad S. Khan, Joost Weijer, Andrew D. Bagdanov, Maria Vanrell</p><p>Abstract: We describe a novel technique for feature combination in the bag-of-words model of image classiﬁcation. Our approach builds discriminative compound words from primitive cues learned independently from training images. Our main observation is that modeling joint-cue distributions independently is more statistically robust for typical classiﬁcation problems than attempting to empirically estimate the dependent, joint-cue distribution directly. We use Information theoretic vocabulary compression to ﬁnd discriminative combinations of cues and the resulting vocabulary of portmanteau1 words is compact, has the cue binding property, and supports individual weighting of cues in the ﬁnal image representation. State-of-theart results on both the Oxford Flower-102 and Caltech-UCSD Bird-200 datasets demonstrate the effectiveness of our technique compared to other, signiﬁcantly more complex approaches to multi-cue image representation. 1</p><br/>
<h2>reference text</h2><p>[1] Francis Bach. Exploring large feature spaces with hierarchical multiple kernel learning. In NIPS, 2008.</p>
<p>[2] A. Bosch, A. Zisserman, and X. Munoz. Scene classiﬁcation via plsa. In ECCV, 2006.</p>
<p>[3] Steve Branson, Catherine Wah, Florian Schroff, Boris Babenko, Peter Welinder, Pietro Perona, and Serge Belongie. Visual recognition with humans in the loop. In ECCV, 2010.</p>
<p>[4] G. Csurka, C. Bray, C. Dance, and L. Fan. Visual categorization with bags of keypoints. In Workshop on Statistical Learning in Computer Vision, ECCV, 2004.</p>
<p>[5] Inderjit Dhillon, Subramanyam Mallela, and Rahul Kumar. A divisive information-theoretic feature clustering algorithm for text classiﬁcation. Journal of Machine Learning Research (JMLR), 3:1265–1287, 2003.</p>
<p>[6] Noha M. Elﬁky, Fahad Shahbaz Khan, Joost van de Weijer, and Jordi Gonzalez. Discriminative compact pyramids for object and scene recognition. Pattern Recgnition, 2011.</p>
<p>[7] Brian Fulkerson, Andrea Vedaldi, and Stefano Soatto. Localizing objects with smart dictionaries. In ECCV, 2008.</p>
<p>[8] Satoshi Ito and Susumu Kubota. Object classiﬁcation using hetrogeneous co-occurrence features. In ECCV, 2010.</p>
<p>[9] Christopher Kanan and Garrison Cottrell. Robust classiﬁcation of objects, faces, and ﬂowers using natural image statistics. In CVPR, 2010.</p>
<p>[10] Fahad Shahbaz Khan, Joost van de Weijer, and Maria Vanrell. Top-down color attention for object recognition. In ICCV, 2009.</p>
<p>[11] Svetlana Lazebnik, Cordelia Schmid, and Jean Ponce. Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories. In CVPR, 2006.</p>
<p>[12] D. G. Lowe. Distinctive image features from scale-invariant points. IJCV, 60(2):91–110, 2004.</p>
<p>[13] M-E Nilsback and A. Zisserman. Automated ﬂower classiﬁcation over a large number of classes. In ICVGIP, 2008.</p>
<p>[14] Alain Rakotomamonjy, Francis Bach, Stephane Canu, and Yves Grandvalet. More efﬁciency in multiple kernel learning. In ICML, 2007.</p>
<p>[15] J. Sivic, B. Russell, A. Efros, A. Zisserman, and W.Freeman. Discovering object categories in image collections. In ICCV, 2005.</p>
<p>[16] Noam Slonim and Naftali Tishby. Agglomerative information bottleneck. In NIPS, 1999.</p>
<p>[17] Anne Treisman. Feature Binding, Attention and Object Perception. Philosophical Transactions: Biological Sciences, 353(1373):1295–1306, 1998.</p>
<p>[18] Koen E. A. van de Sande, Theo Gevers, and Cees G. M. Snoek. Evaluating color descriptors for object and scene recognition. PAMI, 32(9):1582–1596, 2010.</p>
<p>[19] J. van de Weijer, C. Schmid, Jakob J. Verbeek, and D. Larlus. Learning color names for real-world applications. IEEE Transaction in Image Processing (TIP), 18(7):1512–1524, 2009.</p>
<p>[20] Manik Varma and Bodla Rakesh Babu. More generality in efﬁcient multiple kernel learning. In ICML, 2009.</p>
<p>[21] Manik Varma and Debajyoti Ray. Learning the discriminative power-invariance trade-off. In ICCV, 2007.</p>
<p>[22] Jinjun Wang, Jianchao Yang, Kai Yu, Fengjun Lv, Thomas Huang, and Yihong Gong. constrained linear coding for image classiﬁcation. In CVPR, 2010.  Locality-</p>
<p>[23] Bangpeng Yao, Aditya Khosla, and Li Fei-Fei. Combining randomization and discrimination for ﬁnegrained image categorization. In CVPR, 2011.</p>
<p>[24] J. Zhang, M. Marszalek, S. Lazebnik, and C. Schmid. Local features and kernels for classiﬁcation of texture and object catergories: A comprehensive study. IJCV, 73(2):213–218, 2007.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
