<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>20 nips-2011-Active Learning Ranking from Pairwise Preferences with Almost Optimal Query Complexity</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-20" href="../nips2011/nips-2011-Active_Learning_Ranking_from_Pairwise_Preferences_with_Almost_Optimal_Query_Complexity.html">nips2011-20</a> <a title="nips-2011-20-reference" href="#">nips2011-20-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>20 nips-2011-Active Learning Ranking from Pairwise Preferences with Almost Optimal Query Complexity</h1>
<br/><p>Source: <a title="nips-2011-20-pdf" href="http://papers.nips.cc/paper/4428-active-learning-ranking-from-pairwise-preferences-with-almost-optimal-query-complexity.pdf">pdf</a></p><p>Author: Nir Ailon</p><p>Abstract: Given a set V of n elements we wish to linearly order them using pairwise preference labels which may be non-transitive (due to irrationality or arbitrary noise). The goal is to linearly order the elements while disagreeing with as few pairwise preference labels as possible. Our performance is measured by two parameters: The number of disagreements (loss) and the query complexity (number of pairwise preference labels). Our algorithm adaptively queries at most O(n poly(log n, ε−1 )) preference labels for a regret of ε times the optimal loss. This is strictly better, and often signiﬁcantly better than what non-adaptive sampling could achieve. Our main result helps settle an open problem posed by learning-to-rank (from pairwise information) theoreticians and practitioners: What is a provably correct way to sample preference labels? 1</p><br/>
<h2>reference text</h2><p>[1] Nir Ailon, Ron Begleiter, and Esther Ezra, A new active learning scheme with applications to learning to rank from pairwise preferences, arxiv.org/abs/1110.2136 (2011).</p>
<p>[2] Nir Ailon, Moses Charikar, and Alantha Newman, Aggregating inconsistent information: Ranking and clustering, J. ACM 55 (2008), no. 5.</p>
<p>[3] Nir Ailon and Mehryar Mohri, Preference based learning to rank, vol. 80, 2010, pp. 189–212.</p>
<p>[4] Nir Ailon and Kira Radinsky, Ranking from pairs and triplets: Information quality, evaluation methods and query complexity, WSDM, 2011.</p>
<p>[5] Noga Alon, Ranking tournaments, SIAM J. Discret. Math. 20 (2006), no. 1, 137–142.</p>
<p>[6] M. F. Balcan, N. Bansal, A. Beygelzimer, D. Coppersmith, J. Langford, and G. B. Sorkin, Robust reductions from ranking to classiﬁcation, Machine Learning 72 (2008), no. 1-2, 139– 153.</p>
<p>[7] Maria-Florina Balcan, Alina Beygelzimer, and John Langford, Agnostic active learning, J. Comput. Syst. Sci. 75 (2009), no. 1, 78–89.</p>
<p>[8] Maria-Florina Balcan, Steve Hanneke, and Jennifer Vaughan, The true sample complexity of active learning, Machine Learning 80 (2010), 111–139.</p>
<p>[9] A. Beygelzimer, J. Langford, and P. Ravikumar, Error-correcting tournaments, ALT, 2009, pp. 247–262.</p>
<p>[10] M. Braverman and E. Mossel, Noisy sorting without resampling, SODA: Proceedings of the 19th annual ACM-SIAM symposium on Discrete algorithms, 2008, pp. 268–276.</p>
<p>[11] B. Carterette, P. N. Bennett, D. Maxwell Chickering, and S. T. Dumais, Here or there: Preference judgments for relevance, ECIR, 2008.</p>
<p>[12] William W. Cohen, Robert E. Schapire, and Yoram Singer, Learning to order things, NIPS ’97, 1998, pp. 451–457.</p>
<p>[13] D. Cohn, L. Atlas, and R. Ladner, Improving generalization with active learning, Machine Learning 15 (1994), no. 2, 201–221.</p>
<p>[14] A. Culotta and A. McCallum, Reducing labeling effort for structured prediction tasks, AAAI: Proceedings of the 20th national conference on Artiﬁcial intelligence, 2005, pp. 746–751.</p>
<p>[15] S. Dasgupta, Coarse sample complexity bounds for active learning, Advances in Neural Information Processing Systems 18, 2005, pp. 235–242.</p>
<p>[16] S. Dasgupta, A. Tauman Kalai, and C. Monteleoni, Analysis of perceptron-based active learning, Journal of Machine Learning Research 10 (2009), 281–299.</p>
<p>[17] Sanjoy Dasgupta, Daniel Hsu, and Claire Monteleoni, A general agnostic active learning algorithm, NIPS, 2007.</p>
<p>[18] Persi Diaconis and R. L. Graham, Spearman’s footrule as a measure of disarray, Journal of the Royal Statistical Society. Series B (Methodological) 39 (1977), no. 2, pp. 262–268.</p>
<p>[19] U. Feige, D. Peleg, P. Raghavan, and E. Upfal, Computing with unreliable information, STOC: Proceedings of the 22nd annual ACM symposium on Theory of computing, 1990, pp. 128–137.</p>
<p>[20] Yoav Freund, H. Sebastian Seung, Eli Shamir, and Naftali Tishby, Selective sampling using the query by committee algorithm, Mach. Learn. 28 (1997), no. 2-3, 133–168.</p>
<p>[21] Steve Hanneke, A bound on the label complexity of agnostic active learning, ICML, 2007, pp. 353–360.</p>
<p>[22] Eyke H¨ llermeier, Johannes F¨ rnkranz, Weiwei Cheng, and Klaus Brinker, Label ranking by u u learning pairwise preferences, Artif. Intell. 172 (2008), no. 16-17, 1897–1916.</p>
<p>[23] Claire Kenyon-Mathieu and Warren Schudy, How to rank with few errors, STOC, 2007, pp. 95– 103.</p>
<p>[24] Dan Roth and Kevin Small, Margin-based active learning for structured output spaces, 2006.</p>
<p>[25] V. N. Vapnik and A. Ya. Chervonenkis, On the uniform convergence of relative frequencies of events to their probabilities, Theory of Prob. and its Applications 16 (1971), no. 2, 264–280.</p>
<p>[26] F. Xia, T-Y Liu, J. Wang, W. Zhang, and H. Li, Listwise approach to learning to rank: theory and algorithm, ICML ’08, 2008, pp. 1192–1199.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
