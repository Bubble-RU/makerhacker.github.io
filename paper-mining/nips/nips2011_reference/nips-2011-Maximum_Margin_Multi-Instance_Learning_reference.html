<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>168 nips-2011-Maximum Margin Multi-Instance Learning</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-168" href="../nips2011/nips-2011-Maximum_Margin_Multi-Instance_Learning.html">nips2011-168</a> <a title="nips-2011-168-reference" href="#">nips2011-168-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>168 nips-2011-Maximum Margin Multi-Instance Learning</h1>
<br/><p>Source: <a title="nips-2011-168-pdf" href="http://papers.nips.cc/paper/4294-maximum-margin-multi-instance-learning.pdf">pdf</a></p><p>Author: Hua Wang, Heng Huang, Farhad Kamangar, Feiping Nie, Chris H. Ding</p><p>Abstract: Multi-instance learning (MIL) considers input as bags of instances, in which labels are assigned to the bags. MIL is useful in many real-world applications. For example, in image categorization semantic meanings (labels) of an image mostly arise from its regions (instances) instead of the entire image (bag). Existing MIL methods typically build their models using the Bag-to-Bag (B2B) distance, which are often computationally expensive and may not truly reﬂect the semantic similarities. To tackle this, in this paper we approach MIL problems from a new perspective using the Class-to-Bag (C2B) distance, which directly assesses the relationships between the classes and the bags. Taking into account the two major challenges in MIL, high heterogeneity on data and weak label association, we propose a novel Maximum Margin Multi-Instance Learning (M3 I) approach to parameterize the C2B distance by introducing the class speciﬁc distance metrics and the locally adaptive signiﬁcance coefﬁcients. We apply our new approach to the automatic image categorization tasks on three (one single-label and two multilabel) benchmark data sets. Extensive experiments have demonstrated promising results that validate the proposed method.</p><br/>
<h2>reference text</h2><p>[1] O. Maron and A.L. Ratan. Multiple-instance learning for natural scene classiﬁcation. In ICML, 1998.</p>
<p>[2] Y. Chen and J.Z. Wang. Image categorization by learning and reasoning with regions. JMLR, 5:913–939, 2004.</p>
<p>[3] Z.H. Zhou and M.L. Zhang. Multi-instance multi-label learning with application to scene classiﬁcation. In NIPS, 2007.</p>
<p>[4] Z.J. Zha, X.S. Hua, T. Mei, J. Wang, G.J. Qi, and Z. Wang. Joint multi-label multi-instance learning for image classiﬁcation. In CVPR, 2008.</p>
<p>[5] R. Jin, S. Wang, and Z.H. Zhou. Learning a distance metric from multi-instance multi-label data. In CVPR, 2009.</p>
<p>[6] M. Guillaumin, J. Verbeek, and C. Schmid. Multiple instance metric learning from automatically labeled bags of faces. In ECCV, 2010.</p>
<p>[7] H. Wang, F. Nie, and H. Huang. Learning instance speciﬁc distance for multi-instance classiﬁcation. In AAAI, 2011.</p>
<p>[8] H. Wang, F. Nie, H. Huang, and Y. Yang. Learning frame relevance for video classiﬁcation. In ACM MM, 2011.</p>
<p>[9] O. Boiman, E. Shechtman, and M. Irani. In defense of nearest-neighbor based image classiﬁcation. In CVPR, 2008.</p>
<p>[10] A.W.M. Smeulders, M. Worring, S. Santini, A. Gupta, and R. Jain. Content-based image retrieval at the end of the early years. IEEE TPAMI, 22(12):1349–1380, 2002.</p>
<p>[11] H. Wang, H. Huang, and C. Ding. Image annotation using multi-label correlated Green’s function. In ICCV, 2009.</p>
<p>[12] H. Wang, H. Huang, and C. Ding. Multi-label feature transform for image classiﬁcations. In ECCV, 2010.</p>
<p>[13] H. Wang, C. Ding, and H. Huang. Multi-label linear discriminant analysis. In ECCV, pages 126–139. Springer, 2010.</p>
<p>[14] H. Wang, H. Huang, and C. Ding. Image annotation using bi-relational graph of images and semantic labels. In CVPR, 2011.</p>
<p>[15] M. Schultz and T. Joachims. Learning a distance metric from relative comparisons. In NIPS, 2003.</p>
<p>[16] A. Frome, Y. Singer, and J. Malik. Image retrieval and classiﬁcation using local distance functions. In NIPS, 2007.</p>
<p>[17] A. Frome, Y. Singer, F. Sha, and J. Malik. Learning globally-consistent local distance functions for shape-based image retrieval and classiﬁcation. In ICCV, 2007.</p>
<p>[18] Z. Wang, Y. Hu, and L.T. Chia. Image-to-Class Distance Metric Learning for Image Classiﬁcation. In ECCV, 2010.</p>
<p>[19] P. Duygulu, K. Barnard, J. De Freitas, and D. Forsyth. Object recognition as machine translation: Learning a lexicon for a ﬁxed image vocabulary. In ECCV, 2002.</p>
<p>[20] M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman. The PASCAL Visual Object Classes Challenge 2010 (VOC2010) Results. http://pascallin.ecs.soton.ac.uk/challenges/VOC/voc2010/.</p>
<p>[21] H. Wang, C. Ding, and H. Huang. Multi-label classiﬁcation: Inconsistency and class balanced k-nearest neighbor. In AAAI, 2010.</p>
<p>[22] J. Wang and J.D. Zucker. Solving the multiple-instance problem: A lazy learning approach. In ICML, 2000.</p>
<p>[23] R.E. Schapire and Y. Singer. BoosTexter: A boosting-based system for text categorization. Machine learning, 39(2):135–168, 2000.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
