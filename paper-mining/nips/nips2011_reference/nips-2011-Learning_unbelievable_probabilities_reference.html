<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>158 nips-2011-Learning unbelievable probabilities</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-158" href="../nips2011/nips-2011-Learning_unbelievable_probabilities.html">nips2011-158</a> <a title="nips-2011-158-reference" href="#">nips2011-158-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>158 nips-2011-Learning unbelievable probabilities</h1>
<br/><p>Source: <a title="nips-2011-158-pdf" href="http://papers.nips.cc/paper/4391-learning-unbelievable-probabilities.pdf">pdf</a></p><p>Author: Xaq Pitkow, Yashar Ahmadian, Ken D. Miller</p><p>Abstract: Loopy belief propagation performs approximate inference on graphical models with loops. One might hope to compensate for the approximation by adjusting model parameters. Learning algorithms for this purpose have been explored previously, and the claim has been made that every set of locally consistent marginals can arise from belief propagation run on a graphical model. On the contrary, here we show that many probability distributions have marginals that cannot be reached by belief propagation using any set of model parameters or any learning algorithm. We call such marginals ‘unbelievable.’ This problem occurs whenever the Hessian of the Bethe free energy is not positive-deﬁnite at the target marginals. All learning algorithms for belief propagation necessarily fail in these cases, producing beliefs or sets of beliefs that may even be worse than the pre-learning approximation. We then show that averaging inaccurate beliefs, each obtained from belief propagation using model parameters perturbed about some learned mean values, can achieve the unbelievable marginals. 1</p><br/>
<h2>reference text</h2><p>[1] Cooper G (1990) The computational complexity of probabilistic inference using bayesian belief networks. Artiﬁcial intelligence 42: 393–405.</p>
<p>[2] Pearl J (1988) Probabilistic reasoning in intelligent systems: networks of plausible inference. Morgan Kaufmann Publishers, San Mateo CA.</p>
<p>[3] Kschischang F, Frey B, Loeliger H (2001) Factor graphs and the sum-product algorithm. IEEE Transactions on Information Theory 47: 498–519.</p>
<p>[4] Bishop C (2006) Pattern recognition and machine learning. Springer New York.</p>
<p>[5] Wainwright M, Jordan M (2008) Graphical models, exponential families, and variational inference. Foundations and Trends in Machine Learning 1: 1–305.</p>
<p>[6] Yedidia JS, Freeman WT, Weiss Y (2000) Generalized belief propagation. In: Advances in Neural Information Processing Systems 13. MIT Press, pp. 689–695.</p>
<p>[7] Heskes T (2003) Stable ﬁxed points of loopy belief propagation are minima of the Bethe free energy. Advances in Neural Information Processing Systems 15: 343–350.</p>
<p>[8] Welling M, Teh Y (2001) Belief optimization for binary networks: A stable alternative to loopy belief propagation. In: Uncertainty in Artiﬁcial Intelligence. Morgan Kaufmann Publishers Inc., pp. 554–561.</p>
<p>[9] Wainwright MJ, Jaakkola TS, Willsky AS (2003) Tree-reweighted belief propagation algorithms and approximate ML estimation by pseudo-moment matching. In: Artiﬁcial Intelligence and Statistics.</p>
<p>[10] Welling M, Teh Y (2003) Approximate inference in Boltzmann machines. Artiﬁcial Intelligence 143: 19–50.</p>
<p>[11] Parise S, Welling M (2005) Learning in markov random ﬁelds: An empirical study. In: Joint Statistical Meeting. volume 4.</p>
<p>[12] Watanabe Y, Fukumizu K (2011) Loopy belief propagation, Bethe free energy and graph zeta function. arXiv cs.AI: 1103.0605v1.</p>
<p>[13] Hinton G, Sejnowski T (1983) Analyzing cooperative computation. Proceedings of the Fifth Annual Cognitive Science Society, Rochester NY .</p>
<p>[14] Welling M, Sutton C (2005) Learning in markov random ﬁelds with contrastive free energies. In: Cowell RG, Ghahramani Z, editors, Artiﬁcial Intelligence and Statistics. pp. 397-404.</p>
<p>[15] Yedidia J, Freeman W, Weiss Y (2005) Constructing free-energy approximations and generalized belief propagation algorithms. IEEE Transactions on Information Theory 51: 2282–2312.</p>
<p>[16] Mooij J, Kappen H (2005) On the properties of the Bethe approximation and loopy belief propagation on binary networks. Journal of Statistical Mechanics: Theory and Experiment 11: P11012.</p>
<p>[17] Mooij J, Kappen H (2005) Validity estimates for loopy belief propagation on binary real-world networks. In: Advances in Neural Information Processing Systems. Cambridge, MA: MIT Press, pp. 945–952.</p>
<p>[18] Heskes T (2004) On the uniqueness of loopy belief propagation ﬁxed points. Neural Computation 16: 2379–2413.</p>
<p>[19] Lafferty J, McCallum A, Pereira F (2001) Conditional random ﬁelds: Probabilistic models for segmenting and labeling sequence data. Proceedings of the 18th International Conference on Machine Learning : 282–289.</p>
<p>[20] Litvak S, Ullman S (2009) Cortical circuitry implementing graphical models. Neural Computation 21: 3010–3056.</p>
<p>[21] Steimer A, Maass W, Douglas R (2009) Belief propagation in networks of spiking neurons. Neural Computation 21: 2502–2523.</p>
<p>[22] Ott T, Stoop R (2007) The neurodynamics of belief propagation on binary markov random ﬁelds. In: Advances in Neural Information Processing Systems 19, Cambridge, MA: MIT Press. pp. 1057–1064.</p>
<p>[23] Shon A, Rao R (2005) Implementing belief propagation in neural circuits. Neurocomputing 65–66: 393– 399.</p>
<p>[24] George D, Hawkins J (2009) Towards a mathematical theory of cortical micro-circuits. PLoS Computational Biology 5: 1–26.</p>
<p>[25] Heinemann U, Globerson A (2011) What cannot be learned with Bethe approximations. In: Uncertainty in Artiﬁcial Intelligence. Corvallis, Oregon: AUAI Press, pp. 319–326.  9</p>
<br/>
<br/><br/><br/></body>
</html>
