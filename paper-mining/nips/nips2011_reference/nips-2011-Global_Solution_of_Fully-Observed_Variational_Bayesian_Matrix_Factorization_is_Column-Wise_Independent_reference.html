<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>107 nips-2011-Global Solution of Fully-Observed Variational Bayesian Matrix Factorization is Column-Wise Independent</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-107" href="../nips2011/nips-2011-Global_Solution_of_Fully-Observed_Variational_Bayesian_Matrix_Factorization_is_Column-Wise_Independent.html">nips2011-107</a> <a title="nips-2011-107-reference" href="#">nips2011-107-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>107 nips-2011-Global Solution of Fully-Observed Variational Bayesian Matrix Factorization is Column-Wise Independent</h1>
<br/><p>Source: <a title="nips-2011-107-pdf" href="http://papers.nips.cc/paper/4344-global-solution-of-fully-observed-variational-bayesian-matrix-factorization-is-column-wise-independent.pdf">pdf</a></p><p>Author: Shinichi Nakajima, Masashi Sugiyama, S. D. Babacan</p><p>Abstract: Variational Bayesian matrix factorization (VBMF) efﬁciently approximates the posterior distribution of factorized matrices by assuming matrix-wise independence of the two factors. A recent study on fully-observed VBMF showed that, under a stronger assumption that the two factorized matrices are column-wise independent, the global optimal solution can be analytically computed. However, it was not clear how restrictive the column-wise independence assumption is. In this paper, we prove that the global solution under matrix-wise independence is actually column-wise independent, implying that the column-wise independence assumption is harmless. A practical consequence of our theoretical ﬁnding is that the global solution under matrix-wise independence (which is a standard setup) can be obtained analytically in a computationally very efﬁcient way without any iterative algorithms. We experimentally illustrate advantages of using our analytic solution in probabilistic principal component analysis. 1</p><br/>
<h2>reference text</h2><p>[1] A. Asuncion and D.J. Newman. UCI machine learning repository, 2007.</p>
<p>[2] D. Babacan, M. Luessi, R. Molina, and A. Katsaggelos. Sparse Bayesian methods for low-rank matrix estimation. arXiv:1102.5288v1 [stat.ML], 2011.</p>
<p>[3] C. M. Bishop. Bayesian principal components. In Advances in NIPS, volume 11, pages 382–388, 1999.</p>
<p>[4] C. M. Bishop. Variational principal components. In Proc. of ICANN, volume 1, pages 514–509, 1999.</p>
<p>[5] E.-J. Candes, X. Li, Y. Ma, and J. Wright. Robust principal component analysis? CoRR, abs/0912.3599, 2009.</p>
<p>[6] J. D. Carroll and J. J. Chang. Analysis of individual differences in multidimensional scaling via an n-way generalization of ’eckart-young’ decomposition. Psychometrika, 35:283–319, 1970.</p>
<p>[7] S. Funk. Try this at home. http://sifter.org/˜simon/journal/20061211.html, 2006.</p>
<p>[8] R. A. Harshman. Foundations of the parafac procedure: Models and conditions for an ”explanatory” multimodal factor analysis. UCLA Working Papers in Phonetics, 16:1–84, 1970.</p>
<p>[9] H. Hotelling. Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24:417–441, 1933.</p>
<p>[10] H. Hotelling. Relations between two sets of variates. Biometrika, 28(3–4):321–377, 1936.</p>
<p>[11] T. G. Kolda and B. W. Bader. Tensor decompositions and applications. SIAM Review, 51(3):455–500, 2009.</p>
<p>[12] J. A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon, and J. Riedl. Grouplens: Applying collaborative ﬁltering to Usenet news. Communications of the ACM, 40(3):77–87, 1997.</p>
<p>[13] Y. J. Lim and T. W. Teh. Variational Bayesian approach to movie rating prediction. In Proceedings of KDD Cup and Workshop, 2007.</p>
<p>[14] S. Nakajima, M. Sugiyama, and D. Babacan. On Bayesian PCA: Automatic dimensionality selection and analytic solution. In Proceedings of 28th International Conference on Machine Learning (ICML2011), Bellevue, WA, USA, Jun. 28–Jul.2 2011.</p>
<p>[15] S. Nakajima, M. Sugiyama, and R. Tomioka. Global analytic solution for variational Bayesian matrix factorization. In J. Lafferty, C. K. I. Williams, R. Zemel, J. Shawe-Taylor, and A. Culotta, editors, Advances in Neural Information Processing Systems 23, pages 1759–1767, 2010.</p>
<p>[16] T. Raiko, A. Ilin, and J. Karhunen. Principal component analysis for large scale problems with lots of missing values. In J. Kok, J. Koronacki, R. Lopez de Mantras, S. Matwin, D. Mladenic, and A. Skowron, editors, Proceedings of the 18th European Conference on Machine Learning, volume 4701 of Lecture Notes in Computer Science, pages 691–698, Berlin, 2007. Springer-Verlag.</p>
<p>[17] S. Roweis and Z. Ghahramani. A unifying review of linear Gaussian models. Neural Computation, 11:305–345, 1999.</p>
<p>[18] R. Salakhutdinov and A. Mnih. Bayesian probabilistic matrix factorization using Markov chain Monte Carlo. In International Conference on Machine Learning, 2008.</p>
<p>[19] R. Salakhutdinov and A. Mnih. Probabilistic matrix factorization. In J. C. Platt, D. Koller, Y. Singer, and S. Roweis, editors, Advances in Neural Information Processing Systems 20, pages 1257–1264, Cambridge, MA, 2008. MIT Press.</p>
<p>[20] M. E. Tipping and C. M. Bishop. Probabilistic principal component analysis. Journal of the Royal Statistical Society, 61:611–622, 1999.</p>
<p>[21] L. R. Tucker. Some mathematical notes on three-mode factor analysis. Psychometrika, 31:279–311, 1996.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
