<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>167 nips-2011-Maximum Covariance Unfolding : Manifold Learning for Bimodal Data</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-167" href="../nips2011/nips-2011-Maximum_Covariance_Unfolding_%3A_Manifold_Learning_for_Bimodal_Data.html">nips2011-167</a> <a title="nips-2011-167-reference" href="#">nips2011-167-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>167 nips-2011-Maximum Covariance Unfolding : Manifold Learning for Bimodal Data</h1>
<br/><p>Source: <a title="nips-2011-167-pdf" href="http://papers.nips.cc/paper/4186-maximum-covariance-unfolding-manifold-learning-for-bimodal-data.pdf">pdf</a></p><p>Author: Vijay Mahadevan, Chi W. Wong, Jose C. Pereira, Tom Liu, Nuno Vasconcelos, Lawrence K. Saul</p><p>Abstract: We propose maximum covariance unfolding (MCU), a manifold learning algorithm for simultaneous dimensionality reduction of data from different input modalities. Given high dimensional inputs from two different but naturally aligned sources, MCU computes a common low dimensional embedding that maximizes the cross-modal (inter-source) correlations while preserving the local (intra-source) distances. In this paper, we explore two applications of MCU. First we use MCU to analyze EEG-fMRI data, where an important goal is to visualize the fMRI voxels that are most strongly correlated with changes in EEG traces. To perform this visualization, we augment MCU with an additional step for metric learning in the high dimensional voxel space. Second, we use MCU to perform cross-modal retrieval of matched image and text samples from Wikipedia. To manage large applications of MCU, we develop a fast implementation based on ideas from spectral graph theory. These ideas transform the original problem for MCU, one of semideﬁnite programming, into a simpler problem in semideﬁnite quadratic linear programming. 1</p><br/>
<h2>reference text</h2><p>[1] M. Belkin and P. Niyogi. Laplacian eigenmaps for dimensionality reduction and data representation. Neural Computation, 15(6):1373–1396, 2003.</p>
<p>[2] D. Blei, A. Ng, and M. Jordan. Latent dirichlet allocation. JMLR , 3:993–1022, 2003.</p>
<p>[3] R. Buxton, K. Uluda, D. Dubowitz, and T. T Liu. Modeling the hemodynamic response to brain activation. Neuroimage, 23(1):220-233, 2004.</p>
<p>[4] M. Bowling, A. Ghodsi, and D. Wilkinson. Action respecting embedding. In ICML, pages 65–72, 2005.</p>
<p>[5] M. Bowling, D. Wilkinson, A. Ghodsi, and A. Milstein. Subjective localization with action respecting embedding. In ISRR, 2005.</p>
<p>[6] F. Chung. Spectral graph theory. Amer Mathematical Society, 1997.</p>
<p>[7] N. Correa, T. Eichele, T. AdalI, Y. Li, and V. Calhoun. Multi-set canonical correlation analysis for the fusion of concurrent single trial ERP and functional MRI. NeuroImage, 2010.</p>
<p>[8] M. Greicius, B. Krasnow, A. Reiss, and V. Menon. Functional connectivity in the resting brain: a network analysis of the default mode hypothesis. PNAS, 100(1):253, 2003.</p>
<p>[9] D. Hardoon, S. Szedmak, and J. Shawe-Taylor. Canonical correlation analysis: An overview with application to learning methods. Neural Computation, 16(12):2639–2664, 2004.</p>
<p>[10] D. Lowe. Distinctive image features from scale-invariant keypoints. IJCV, 60(2):91–110, 2004.</p>
<p>[11] E. Martinez-Montes, P. Vald´ s-Sosa, F. Miwakeichi, R. Goldman, and M. Cohen. Concurrent EEG/fMRI e analysis by multiway partial least squares. NeuroImage, 22(3):1023–1034, 2004.</p>
<p>[12] N. Rasiwasia, J. Costa Pereira, E. Coviello, G. Doyle, G. Lanckriet, R. Levy, and N. Vasconcelos. A new approach to cross-modal multimedia retrieval. In ACM Multimedia, pages 251–260, 2010.</p>
<p>[13] P. Ritter and A. Villringer. Simultaneous EEG-fMRI. Neuroscience & Biobehavioral Reviews, 30(6):823– 838, 2006.</p>
<p>[14] S. T. Roweis and L. K. Saul. Nonlinear dimensionality reduction by locally linear embedding. Science, 290:2323–2326, 2000.</p>
<p>[15] B. Shaw and T. Jebara. Minimum volume embedding. In AISTATS, pages 460–467, San Juan, Puerto Rico, 2007.</p>
<p>[16] B. Shaw and T. Jebara. Structure preserving embedding. In ICML, 2009.</p>
<p>[17] X. Shen and F. Meyer. Low-dimensional embedding of fMRI datasets. Neuroimage, 41(3):886–902, 2008.</p>
<p>[18] L. Song, A. Smola, K. Borgwardt, and A. Gretton. Colored maximum variance unfolding. NIPS 2008.</p>
<p>[19] J. Sturm. Using SeDuMi 1.02, a MATLAB toolbox for optimization over symmetric cones. Optimization methods and software, 11(1):625–653, 1999.</p>
<p>[20] J. B. Tenenbaum, V. de Silva, and J. C. Langford. A global geometric framework for nonlinear dimensionality reduction. Science, 290:2319–2323, 2000.</p>
<p>[21] K. Weinberger and L. Saul. Unsupervised learning of image manifolds by semideﬁnite programming. IJCV, 70(1):77–90, 2006.</p>
<p>[22] K. Weinberger and L. Saul. Distance metric learning for large margin nearest neighbor classiﬁcation. JMLR, 10:207–244, 2009.</p>
<p>[23] K. Weinberger, F. Sha, Q. Zhu, and L. Saul. Graph laplacian regularization for large-scale semideﬁnite programming. NIPS, 19:1489, 2007.</p>
<p>[24] K. Q. Weinberger, F. Sha, and L. K. Saul. Learning a kernel matrix for nonlinear dimensionality reduction. ICML, 2004.</p>
<p>[25] X. Wu, A. So, Z. Li, and S. Li. Fast graph laplacian regularized kernel learning via semideﬁnite– quadratic–linear programming. NIPS, 22:1964–1972.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
