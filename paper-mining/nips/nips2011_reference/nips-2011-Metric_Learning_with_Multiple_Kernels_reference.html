<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>171 nips-2011-Metric Learning with Multiple Kernels</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-171" href="../nips2011/nips-2011-Metric_Learning_with_Multiple_Kernels.html">nips2011-171</a> <a title="nips-2011-171-reference" href="#">nips2011-171-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>171 nips-2011-Metric Learning with Multiple Kernels</h1>
<br/><p>Source: <a title="nips-2011-171-pdf" href="http://papers.nips.cc/paper/4399-metric-learning-with-multiple-kernels.pdf">pdf</a></p><p>Author: Jun Wang, Huyen T. Do, Adam Woznica, Alexandros Kalousis</p><p>Abstract: Metric learning has become a very active research ﬁeld. The most popular representative–Mahalanobis metric learning–can be seen as learning a linear transformation and then computing the Euclidean metric in the transformed space. Since a linear transformation might not always be appropriate for a given learning problem, kernelized versions of various metric learning algorithms exist. However, the problem then becomes ﬁnding the appropriate kernel function. Multiple kernel learning addresses this limitation by learning a linear combination of a number of predeﬁned kernels; this approach can be also readily used in the context of multiple-source learning to fuse different data sources. Surprisingly, and despite the extensive work on multiple kernel learning for SVMs, there has been no work in the area of metric learning with multiple kernel learning. In this paper we ﬁll this gap and present a general approach for metric learning with multiple kernel learning. Our approach can be instantiated with different metric learning algorithms provided that they satisfy some constraints. Experimental evidence suggests that our approach outperforms metric learning with an unweighted kernel combination and metric learning with cross-validation based kernel selection. 1</p><br/>
<h2>reference text</h2><p>[1] S.P. Boyd and L. Vandenberghe. Convex optimization. Cambridge Univ Pr, 2004.</p>
<p>[2] J. Dattorro. Convex optimization & Euclidean distance geometry. Meboo Publishing USA, 2005.</p>
<p>[3] J.V. Davis, B. Kulis, P. Jain, S. Sra, and I.S. Dhillon. Information-theoretic metric learning. In ICML, 2007.</p>
<p>[4] K. Gai, G. Chen, and C. Zhang. Learning kernels with radiuses of minimum enclosing balls. NIPS, 2010.</p>
<p>[5] A. Globerson and S. Roweis. Metric learning by collapsing classes. In NIPS, 2006.</p>
<p>[6] L. Grippo and M. Sciandrone. On the convergence of the block nonlinear gauss-seidel method under convex constraints* 1. Operations Research Letters, 26(3):127–136, 2000.</p>
<p>[7] M. Guillaumin, J. Verbeek, and C. Schmid. Is that you? Metric learning approaches for face identiﬁcation. In ICCV, pages 498–505, 2009.</p>
<p>[8] K. Huang, Y. Ying, and C. Campbell. Gsml: A uniﬁed framework for sparse metric learning. In Data Mining, 2009. ICDM’09. Ninth IEEE International Conference on, pages 189–198. IEEE, 2009.</p>
<p>[9] P. Jain, B. Kulis, and I. Dhillon. Inductive regularized learning of kernel functions. NIPS, 2010.</p>
<p>[10] G.R.G. Lanckriet, N. Cristianini, P. Bartlett, L. El Ghaoui, and M.I. Jordan. Learning the Kernel Matrix with Semideﬁnite Programming. Journal of Machine Learning Research, 5:27– 72, 2004.</p>
<p>[11] B. McFee and G. Lanckriet. Partial order embedding with multiple kernels. In Proceedings of the 26th Annual International Conference on Machine Learning, pages 721–728. ACM, 2009.</p>
<p>[12] B. McFee and G. Lanckriet. Metric learning to rank. In ICML. ACM New York, NY, USA, 2010.</p>
<p>[13] B. McFee and G. Lanckriet. Learning multi-modal similarity. The Journal of Machine Learning Research, 12:491–523, 2011.</p>
<p>[14] N. Nguyen and Y. Guo. Metric Learning: A Support Vector Approach. In ECML/PKDD, 2008.</p>
<p>[15] M.E. Nilsback and A. Zisserman. A visual vocabulary for ﬂower classiﬁcation. In Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on, volume 2, pages 1447–1454. Ieee, 2006.</p>
<p>[16] M.E. Nilsback and A. Zisserman. Automated ﬂower classiﬁcation over a large number of classes. In Computer Vision, Graphics & Image Processing, 2008. ICVGIP’08. Sixth Indian Conference on, pages 722–729. IEEE, 2008.</p>
<p>[17] A. Rakotomamonjy, F. Bach, S. Canu, and Y. Grandvalet. SimpleMKL. Journal of Machine Learning Research, 9:2491–2521, 2008.</p>
<p>[18] M. Schultz and T. Joachims. Learning a distance metric from relative comparisons. In NIPS, 2003.</p>
<p>[19] S. Shalev-Shwartz, Y. Singer, and A.Y. Ng. Online and batch learning of pseudo-metrics. In Proceedings of the twenty-ﬁrst international conference on Machine learning. ACM, 2004.</p>
<p>[20] S. Sonnenburg, G. Ratsch, and C. Schafer. A general and efﬁcient multiple kernel learning algorithm. In NIPS, 2006.</p>
<p>[21] J.P. Vert, J. Qiu, and W. Noble. A new pairwise kernel for biological network inference with support vector machines. BMC bioinformatics, 8(Suppl 10):S8, 2007.</p>
<p>[22] K.Q. Weinberger and L.K. Saul. Distance metric learning for large margin nearest neighbor classiﬁcation. The Journal of Machine Learning Research, 10:207–244, 2009.</p>
<p>[23] E.P. Xing, A.Y. Ng, M.I. Jordan, and S. Russell. Distance metric learning with application to clustering with side-information. In NIPS, 2003.  9</p>
<br/>
<br/><br/><br/></body>
</html>
