<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>212 nips-2011-Periodic Finite State Controllers for Efficient POMDP and DEC-POMDP Planning</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-212" href="../nips2011/nips-2011-Periodic_Finite_State_Controllers_for_Efficient_POMDP_and_DEC-POMDP_Planning.html">nips2011-212</a> <a title="nips-2011-212-reference" href="#">nips2011-212-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>212 nips-2011-Periodic Finite State Controllers for Efficient POMDP and DEC-POMDP Planning</h1>
<br/><p>Source: <a title="nips-2011-212-pdf" href="http://papers.nips.cc/paper/4297-periodic-finite-state-controllers-for-efficient-pomdp-and-dec-pomdp-planning.pdf">pdf</a></p><p>Author: Joni K. Pajarinen, Jaakko Peltonen</p><p>Abstract: Applications such as robot control and wireless communication require planning under uncertainty. Partially observable Markov decision processes (POMDPs) plan policies for single agents under uncertainty and their decentralized versions (DEC-POMDPs) ﬁnd a policy for multiple agents. The policy in inﬁnite-horizon POMDP and DEC-POMDP problems has been represented as ﬁnite state controllers (FSCs). We introduce a novel class of periodic FSCs, composed of layers connected only to the previous and next layer. Our periodic FSC method ﬁnds a deterministic ﬁnite-horizon policy and converts it to an initial periodic inﬁnitehorizon policy. This policy is optimized by a new inﬁnite-horizon algorithm to yield deterministic periodic policies, and by a new expectation maximization algorithm to yield stochastic periodic policies. Our method yields better results than earlier planning methods and can compute larger solutions than with regular FSCs.</p><br/>
<h2>reference text</h2><p>[1] R. D. Smallwood and E. J. Sondik. The optimal control of partially observable Markov processes over a ﬁnite horizon. Operations Research, pages 1071–1088, 1973.</p>
<p>[2] S. Seuken and S. Zilberstein. Formal models and algorithms for decentralized decision making under uncertainty. Autonomous Agents and Multi-Agent Systems, 17(2):190–250, 2008.</p>
<p>[3] H. Kurniawati, D. Hsu, and W.S. Lee. Sarsop: Efﬁcient point-based pomdp planning by approximating optimally reachable belief spaces. In Proc. Robotics: Science and Systems, 2008.</p>
<p>[4] S. Seuken and S. Zilberstein. Memory-bounded dynamic programming for DEC-POMDPs. In Proc. of 20th IJCAI, pages 2009–2016. Morgan Kaufmann, 2007.</p>
<p>[5] F. Wu, S. Zilberstein, and X. Chen. Point-based policy generation for decentralized POMDPs. In Proc. of 9th AAMAS, pages 1307–1314. IFAAMAS, 2010.</p>
<p>[6] P. Poupart and C. Boutilier. Bounded ﬁnite state controllers. Advances in neural information processing systems, 16:823–830, 2003.</p>
<p>[7] M. Toussaint, S. Harmeling, and A. Storkey. Probabilistic inference for solving (PO)MDPs. Technical report, University of Edinburgh, 2006.</p>
<p>[8] C. Amato, D. Bernstein, and S. Zilberstein. Optimizing Memory-Bounded Controllers for Decentralized POMDPs. In Proc. of 23rd UAI, pages 1–8. AUAI Press, 2007.</p>
<p>[9] A. Kumar and S. Zilberstein. Point-Based Backup for Decentralized POMDPs: Complexity and New Algorithms. In Proc. of 9th AAMAS, pages 1315–1322. IFAAMAS, 2010.</p>
<p>[10] Joni Pajarinen and Jaakko Peltonen. Efﬁcient Planning for Factored Inﬁnite-Horizon DECPOMDPs. In Proc. of 22nd IJCAI, pages 325–331. AAAI Press, July 2011.</p>
<p>[11] D. S. Bernstein, R. Givan, N. Immerman, and S. Zilberstein. The Complexity of Decentralized Control of Markov Decision Processes. Mathematics of Operations Research, 27(4):819–840, 2002.</p>
<p>[12] A. Kumar and S. Zilberstein. Anytime Planning for Decentralized POMDPs using Expectation Maximization. In Proc. of 26th UAI, 2010.</p>
<p>[13] D.S. Bernstein, E.A. Hansen, and S. Zilberstein. Bounded policy iteration for decentralized POMDPs. In Proc. of 19th IJCAI, pages 1287–1292. Morgan Kaufmann, 2005.</p>
<p>[14] D. Szer and F. Charpillet. An optimal best-ﬁrst search algorithm for solving inﬁnite horizon DEC-POMDPs. Proc. of 16th ECML, pages 389–399, 2005.</p>
<p>[15] C. Amato and S. Zilberstein. Achieving goals in decentralized POMDPs. In Proc. of 8th AAMAS, volume 1, pages 593–600. IFAAMAS, 2009.</p>
<p>[16] C. Amato, B. Bonet, and S. Zilberstein. Finite-State Controllers Based on Mealy Machines for Centralized and Decentralized POMDPs. In Proc. of 24th AAAI, 2010.</p>
<p>[17] S. Ji, R. Parr, H. Li, X. Liao, and L. Carin. Point-based policy iteration. In Proc. of 22nd AAAI, volume 22, page 1243, 2007.</p>
<p>[18] F.A. Oliehoek, M.T.J. Spaan, and N. Vlassis. Optimal and approximate q-value functions for decentralized pomdps. Journal of Artiﬁcial Intelligence Research, 32(1):289–353, 2008.  9</p>
<br/>
<br/><br/><br/></body>
</html>
