<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>185 nips-2011-Newtron: an Efficient Bandit algorithm for Online Multiclass Prediction</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-185" href="../nips2011/nips-2011-Newtron%3A_an_Efficient_Bandit_algorithm_for_Online_Multiclass_Prediction.html">nips2011-185</a> <a title="nips-2011-185-reference" href="#">nips2011-185-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>185 nips-2011-Newtron: an Efficient Bandit algorithm for Online Multiclass Prediction</h1>
<br/><p>Source: <a title="nips-2011-185-pdf" href="http://papers.nips.cc/paper/4245-newtron-an-efficient-bandit-algorithm-for-online-multiclass-prediction.pdf">pdf</a></p><p>Author: Elad Hazan, Satyen Kale</p><p>Abstract: We present an efﬁcient algorithm for the problem of online multiclass prediction with bandit feedback in the fully adversarial setting. We measure its regret with respect to the log-loss deﬁned in [AR09], which is parameterized by a scalar α. We prove that the regret of N EWTRON is O(log T ) when α is a constant that does not vary with horizon T , and at most O(T 2/3 ) if α is allowed to increase to inﬁnity √ with T . For α = O(log T ), the regret is bounded by O( T ), thus solving the open problem of [KSST08, AR09]. Our algorithm is based on a novel application of the online Newton method [HAK07]. We test our algorithm and show it to perform well in experiments, even when α is a small constant. 1</p><br/>
<h2>reference text</h2><p>[ACBFS03] Peter Auer, Nicol` Cesa-Bianchi, Yoav Freund, and Robert E. Schapire. The nono stochastic multiarmed bandit problem. SIAM J. Comput., 32:48–77, January 2003. [AHR08] Jacob Abernethy, Elad Hazan, and Alexander Rakhlin. Competing in the dark: An efﬁcient algorithm for bandit linear optimization. In COLT, pages 263–274, 2008. [AK08] [AR09]  Baruch Awerbuch and Robert Kleinberg. Online linear optimization and adaptive routing. J. Comput. Syst. Sci., 74(1):97–114, 2008. √ Jacob Abernethy and Alexander Rakhlin. An efﬁcient bandit algorithm for T -regret in online multiclass prediction? In COLT, 2009.  [CG11]  Koby Crammer and Claudio Gentile. Multiclass classiﬁcation with bandit feedback using adaptive regularization. In ICML, 2011.  [DH06]  Varsha Dani and Thomas P. Hayes. Robbing the bandit: less regret in online geometric optimization against an adaptive adversary. In SODA, pages 937–943, 2006.  [DHK07]  Varsha Dani, Thomas Hayes, and Sham Kakade. The price of bandit information for online optimization. In NIPS. 2007.  [FKM05]  Abraham D. Flaxman, Adam Tauman Kalai, and H. Brendan McMahan. Online convex optimization in the bandit setting: gradient descent without a gradient. In SODA, pages 385–394, 2005.  [HAK07]  Elad Hazan, Amit Agarwal, and Satyen Kale. Logarithmic regret algorithms for online convex optimization. Machine Learning, 69(2-3):169–192, 2007.  [HJ91]  R.A. Horn and C.R. Johnson. Topics in Matrix Analysis. Cambridge University Press, Cambridge, 1991.  [KSST08]  Sham M. Kakade, Shai Shalev-Shwartz, and Ambuj Tewari. Efﬁcient bandit algorithms for online multiclass prediction. In ICML’08, pages 440–447, 2008.  [LZ07]  John Langford and Tong Zhang. The epoch-greedy algorithm for multi-armed bandits with side information. In NIPS, 2007.  [MB04]  H. Brendan McMahan and Avrim Blum. Online geometric optimization in the bandit setting against an adaptive adversary. In COLT, pages 109–123, 2004.  [RTB07]  Alexander Rakhlin, Ambuj Tewari, and Peter Bartlett. Closing the gap between bandit and full-information online optimization: High-probability regret bound. Technical Report UCB/EECS-2007-109, EECS Department, University of California, Berkeley, Aug 2007.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
