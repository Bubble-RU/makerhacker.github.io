<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>31 nips-2011-An Application of Tree-Structured Expectation Propagation for Channel Decoding</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-31" href="../nips2011/nips-2011-An_Application_of_Tree-Structured_Expectation_Propagation_for_Channel_Decoding.html">nips2011-31</a> <a title="nips-2011-31-reference" href="#">nips2011-31-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>31 nips-2011-An Application of Tree-Structured Expectation Propagation for Channel Decoding</h1>
<br/><p>Source: <a title="nips-2011-31-pdf" href="http://papers.nips.cc/paper/4280-an-application-of-tree-structured-expectation-propagation-for-channel-decoding.pdf">pdf</a></p><p>Author: Pablo M. Olmos, Luis Salamanca, Juan Fuentes, Fernando Pérez-Cruz</p><p>Abstract: We show an application of a tree structure for approximate inference in graphical models using the expectation propagation algorithm. These approximations are typically used over graphs with short-range cycles. We demonstrate that these approximations also help in sparse graphs with long-range loops, as the ones used in coding theory to approach channel capacity. For asymptotically large sparse graph, the expectation propagation algorithm together with the tree structure yields a completely disconnected approximation to the graphical model but, for for ﬁnite-length practical sparse graphs, the tree structure approximation to the code graph provides accurate estimates for the marginal of each variable. Furthermore, we propose a new method for constructing the tree structure on the ﬂy that might be more amenable for sparse graphs with general factors. 1</p><br/>
<h2>reference text</h2><p>[1] Abdelaziz Amraoui, Andrea Montanari, Tom Richardson, and R¨ diger Urbanke. Finite-length scaling for u iteratively decoded LDPC ensembles. IEEE Transactions on Information Theory., 55(2):473–498, 2009.</p>
<p>[2] Thomas M. Cover and Joy A. Thomas. Elements of Information Theory. Wilson and Sons, New York, USA, 1991.</p>
<p>[3] Michael Luby, Michael Mitzenmacher, Amin Shokrollahi, Daniel Spielman, and Volker Stemann. Practical loss-resilient codes. In Proceedings of the 29th annual ACM Symposium on Theory of Computing, pages 150–159, 1997.</p>
<p>[4] Michael Luby, Michael Mitzenmacher, Amin Shokrollahi, Daniel Spielman, and Volker Stemann. Efﬁcient erasure correcting codes. IEEE Transactions on Information Theory, 47(2):569–584, Feb. 2001.</p>
<p>[5] David J. C. MacKay. Good error-correcting codes based on very sparse matrices. IEEE Transactions on Information Theory, 45(2):399–431, 1999.</p>
<p>[6] David J. C. MacKay. Information Theory, Inference, and Learning Algorithms. Cambridge University Press, 2003.</p>
<p>[7] David J. C. MacKay and Radford M. Neal. Near Shannon limit performance of low density parity check codes. Electronics Letters, 32:1645–1646, 1996.</p>
<p>[8] T. Minka. Power EP. http://research.microsoft.com/˜ minka/papers/.  Technical  report,  MSR-TR-2004-149,  2004.</p>
<p>[9] Thomas Minka and Yuan Qi. Tree-structured approximations by expectation propagation. In Proceedings of the Neural Information Processing Systems Conference, (NIPS), 2003.</p>
<p>[10] Thomas P. Minka. Expectation Propagation for approximate Bayesian inference. In Proceedings of the 17th Conference in Uncertainty in Artiﬁcial Intelligence (UAI 2001), pages 362–369. Morgan Kaufmann Publishers Inc., 2001.</p>
<p>[11] Pablo M. Olmos, Juan Jos´ Murillo-Fuentes, and Fernando P´ rez-Cruz. Tree-structure expectation prope e agation for decoding LDPC codes over binary erasure channels. In 2010 IEEE International Symposium on Information Theory, ISIT, Austin, Texas, 2010.</p>
<p>[12] P.M. Olmos, J.J. Murillo-Fuentes, and F. P´ rez-Cruz. Tree-structure expectation propagation for LDPC e decoding in erasure channels. Submitted to IEEE Transactions on Information Theory, 2011.</p>
<p>[13] P.M. Olmos, J.J. Murillo-Fuentes, and F. P´ rez-Cruz. Tree-structured expectation propagation for decode ing ﬁnite-length ldpc codes. IEEE Communications Letters, 15(2):235 –237, Feb. 2011.</p>
<p>[14] P. Oswald and A. Shokrollahi. Capacity-achieving sequences for the erasure channel. IEEE Transactions on Information Theory, 48(12):3017 – 3028, Dec. 2002.</p>
<p>[15] Tom Richardson and Ruediger Urbanke. Modern Coding Theory. Cambridge University Press, Mar. 2008.</p>
<p>[16] N. Takayuki, K. Kasai, and S. Kohichi. Analytical solution of covariance evolution for irregular LDPC codes. e-prints, November 2010.</p>
<p>[17] M. J. Wainwright, T. S. Jaakkola, and A. S. Willsk. Map estimation via agreement on (hyper)trees: Message-passing and linear-programming approaches. IEEE Transactions on Information Theory, 51(11):3697–3717, November 2005.</p>
<p>[18] Martin J. Wainwright and Michael I. Jordan. Graphical Models, Exponential Families, and Variational Inference. Foundations and Trends in Machine Learning, 2008.</p>
<p>[19] W. Weigerinck and T. Heskes. Fractional belief propagation. In S. Becker, S. Thrun, and K. Obermayer, editors, Advances in Neural Information Processing Systems 15, Cambridge, MA, December 2002. MIT Press.</p>
<p>[20] M. Welling, T. Minka, and Y.W. Teh. Structured region graphs: Morphing EP into GBP. In UAI, 2005.</p>
<p>[21] Nicholas C. Wormald. Differential equations for random processes and random graphs. Annals of Applied Probability, 5(4):1217–1235, 1995.</p>
<p>[22] J. S. Yedidia, W. T. Freeman, and Y. Weis. Constructing free-energy approximations and generalized belief propagation algorithms. IEEE Transactions on Information Theory, 51(7):2282–2312, July 2005.  9</p>
<br/>
<br/><br/><br/></body>
</html>
