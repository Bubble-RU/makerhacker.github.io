<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>74 nips-2011-Dynamic Pooling and Unfolding Recursive Autoencoders for Paraphrase Detection</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-74" href="../nips2011/nips-2011-Dynamic_Pooling_and_Unfolding_Recursive_Autoencoders_for_Paraphrase_Detection.html">nips2011-74</a> <a title="nips-2011-74-reference" href="#">nips2011-74-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>74 nips-2011-Dynamic Pooling and Unfolding Recursive Autoencoders for Paraphrase Detection</h1>
<br/><p>Source: <a title="nips-2011-74-pdf" href="http://papers.nips.cc/paper/4204-dynamic-pooling-and-unfolding-recursive-autoencoders-for-paraphrase-detection.pdf">pdf</a></p><p>Author: Richard Socher, Eric H. Huang, Jeffrey Pennin, Christopher D. Manning, Andrew Y. Ng</p><p>Abstract: Paraphrase detection is the task of examining two sentences and determining whether they have the same meaning. In order to obtain high accuracy on this task, thorough syntactic and semantic analysis of the two statements is needed. We introduce a method for paraphrase detection based on recursive autoencoders (RAE). Our unsupervised RAEs are based on a novel unfolding objective and learn feature vectors for phrases in syntactic trees. These features are used to measure the word- and phrase-wise similarity between two sentences. Since sentences may be of arbitrary length, the resulting matrix of similarity measures is of variable size. We introduce a novel dynamic pooling layer which computes a ﬁxed-sized representation from the variable-sized matrices. The pooled representation is then used as input to a classiﬁer. Our method outperforms other state-of-the-art approaches on the challenging MSRP paraphrase corpus. 1</p><br/>
<h2>reference text</h2><p>[1] E. Marsi and E. Krahmer. Explorations in sentence fusion. In European Workshop on Natural Language Generation, 2005.</p>
<p>[2] P. Clough, R. Gaizauskas, S. S. L. Piao, and Y. Wilks. METER: MEasuring TExt Reuse. In ACL, 2002.</p>
<p>[3] C. Callison-Burch. Syntactic constraints on paraphrases extracted from parallel corpora. In Proceedings of EMNLP, pages 196–205, 2008.</p>
<p>[4] B. Dolan, C. Quirk, and C. Brockett. Unsupervised construction of large paraphrase corpora: exploiting massively parallel news sources. In COLING, 2004.</p>
<p>[5] Y. Bengio, R. Ducharme, P. Vincent, and C. Janvin. A neural probabilistic language model. J. Mach. Learn. Res., 3, March 2003.</p>
<p>[6] R. Collobert and J. Weston. A uniﬁed architecture for natural language processing: deep neural networks with multitask learning. In ICML, 2008.</p>
<p>[7] Y. Bengio, J. Louradour, Collobert R, and J. Weston. Curriculum learning. In ICML, 2009.</p>
<p>[8] J. Turian, L. Ratinov, and Y. Bengio. Word representations: a simple and general method for semisupervised learning. In Proceedings of ACL, pages 384–394, 2010.</p>
<p>[9] J. B. Pollack. Recursive distributed representations. Artiﬁcial Intelligence, 46, November 1990.</p>
<p>[10] T. Voegtlin and P. Dominey. Linear Recursive Distributed Representations. Neural Networks, 18(7), 2005.</p>
<p>[11] J. L. Elman. Distributed representations, simple recurrent networks, and grammatical structure. Machine Learning, 7(2-3), 1991.</p>
<p>[12] R. Socher, J. Pennington, E. H. Huang, A. Y. Ng, and C. D. Manning. Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions. In EMNLP, 2011.</p>
<p>[13] C. Goller and A. K¨ chler. Learning task-dependent distributed representations by backpropagation u through structure. In Proceedings of the International Conference on Neural Networks (ICNN-96), 1996.</p>
<p>[14] D. Klein and C. D. Manning. Accurate unlexicalized parsing. In ACL, 2003.</p>
<p>[15] D. Das and N. A. Smith. Paraphrase identiﬁcation as probabilistic quasi-synchronous recognition. In In Proc. of ACL-IJCNLP, 2009.</p>
<p>[16] V. Rus, P. M. McCarthy, M. C. Lintean, D. S. McNamara, and A. C. Graesser. Paraphrase identiﬁcation with lexico-syntactic graph subsumption. In FLAIRS Conference, 2008.</p>
<p>[17] R. Mihalcea, C. Corley, and C. Strapparava. Corpus-based and Knowledge-based Measures of Text Semantic Similarity. In Proceedings of the 21st National Conference on Artiﬁcial Intelligence - Volume 1, 2006.</p>
<p>[18] A. Islam and D. Inkpen. Semantic Similarity of Short Texts. In Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2007), 2007.</p>
<p>[19] L. Qiu, M. Kan, and T. Chua. Paraphrase recognition via dissimilarity signiﬁcance classiﬁcation. In EMNLP, 2006.</p>
<p>[20] S. Fernando and M. Stevenson. A semantic similarity approach to paraphrase detection. Proceedings of the 11th Annual Research Colloquium of the UK Special Interest Group for Computational Linguistics, 2008.</p>
<p>[21] S. Wan, M. Dras, R. Dale, and C. Paris. Using dependency-based features to take the “para-farce” out of paraphrase. In Proceedings of the Australasian Language Technology Workshop 2006, 2006.</p>
<p>[22] R. Barzilay and L. Lee. Learning to paraphrase: an unsupervised approach using multiple-sequence alignment. In NAACL, 2003.</p>
<p>[23] Y. Zhang and J. Patrick. Paraphrase identiﬁcation by text canonicalization. In Proceedings of the Australasian Language Technology Workshop 2005, 2005.</p>
<p>[24] Z. Kozareva and A. Montoyo. Paraphrase Identiﬁcation on the Basis of Supervised Machine Learning Techniques. In Advances in Natural Language Processing, 5th International Conference on NLP, FinTAL, 2006.</p>
<p>[25] L. Bottou. From machine learning to machine reasoning. CoRR, abs/1102.1808, 2011.</p>
<p>[26] H. Larochelle, Y. Bengio, J. Louradour, and P. Lamblin. Exploring strategies for training deep neural networks. JMLR, 10, 2009.</p>
<p>[27] R. Socher, C. D. Manning, and A. Y. Ng. Learning continuous phrase representations and syntactic parsing with recursive neural networks. In Proceedings of the NIPS-2010 Deep Learning and Unsupervised Feature Learning Workshop, 2010.</p>
<p>[28] R. Socher, C. Lin, A. Y. Ng, and C.D. Manning. Parsing Natural Scenes and Natural Language with Recursive Neural Networks. In ICML, 2011.  9</p>
<br/>
<br/><br/><br/></body>
</html>
