<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>214 nips-2011-PiCoDes: Learning a Compact Code for Novel-Category Recognition</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-214" href="../nips2011/nips-2011-PiCoDes%3A_Learning_a_Compact_Code_for_Novel-Category_Recognition.html">nips2011-214</a> <a title="nips-2011-214-reference" href="#">nips2011-214-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>214 nips-2011-PiCoDes: Learning a Compact Code for Novel-Category Recognition</h1>
<br/><p>Source: <a title="nips-2011-214-pdf" href="http://papers.nips.cc/paper/4319-picodes-learning-a-compact-code-for-novel-category-recognition.pdf">pdf</a></p><p>Author: Alessandro Bergamo, Lorenzo Torresani, Andrew W. Fitzgibbon</p><p>Abstract: We introduce P I C O D ES: a very compact image descriptor which nevertheless allows high performance on object category recognition. In particular, we address novel-category recognition: the task of deﬁning indexing structures and image representations which enable a large collection of images to be searched for an object category that was not known when the index was built. Instead, the training images deﬁning the category are supplied at query time. We explicitly learn descriptors of a given length (from as small as 16 bytes per image) which have good object-recognition performance. In contrast to previous work in the domain of object recognition, we do not choose an arbitrary intermediate representation, but explicitly learn short codes. In contrast to previous approaches to learn compact codes, we optimize explicitly for (an upper bound on) classiﬁcation performance. Optimization directly for binary features is difﬁcult and nonconvex, but we present an alternation scheme and convex upper bound which demonstrate excellent performance in practice. P I C O D ES of 256 bytes match the accuracy of the current best known classiﬁer for the Caltech256 benchmark, but they decrease the database storage size by a factor of 100 and speed-up the training and testing of novel classes by orders of magnitude.</p><br/>
<h2>reference text</h2><p>[1] http://vlg.cs.dartmouth.edu/picodes.</p>
<p>[2] B. Babenko, S. Branson, and S. Belongie. Similarity metrics for categorization: From monolithic to category speciﬁc. In Intl. Conf. Computer Vision, pages 293 –300, 2009.</p>
<p>[3] A. Berg, J. Deng, and L. Fei-Fei. Large scale visual recognition challenge, 2010. http://www.imagenet.org/challenges/LSVRC/2010/.</p>
<p>[4] A. Bosch, A. Zisserman, and X. Mu˜ oz. Representing shape with a spatial pyramid kernel. In Conf. n Image and Video Retrieval (CIVR), pages 401–408, 2007.</p>
<p>[5] O. Chapelle and S. S. Keerthi. Multi-class feature selection with support vector machines. Proc. of the Am. Stat. Assoc., 2008.</p>
<p>[6] O. Chum, J. Philbin, and A. Zisserman. Near duplicate image detection: min-hash and tf-idf weighting. In British Machine Vision Conf., 2008.</p>
<p>[7] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. ImageNet: A Large-Scale Hierarchical Image Database. In CVPR, 2009.</p>
<p>[8] M. Douze, A. Ramisa, and C. Schmid. Combining attributes and ﬁsher vectors for efﬁcient image retrieval. In Proc. Comp. Vision Pattern Recogn. (CVPR), 2011.</p>
<p>[9] R.-E. Fan, K.-W. Chang, C.-J. Hsieh, X.-R. Wang, and C.-J. Lin. Liblinear: A library for large linear classiﬁcation. Journal of Machine Learning Research, 9:1871–1874, 2008.</p>
<p>[10] A. Farhadi, I. Endres, D. Hoiem, and D. Forsyth. Describing objects by their attributes. In CVPR, 2009.</p>
<p>[11] P. Gehler and S. Nowozin. On feature combination for multiclass object classiﬁcation. In ICCV, 2009.</p>
<p>[12] A. G. Hauptmann, R. Yan, W.-H. Lin, M. G. Christel, and H. D. Wactlar. Can high-level concepts ﬁll the semantic gap in video retrieval? a case study with broadcast news. IEEE Transactions on Multimedia, 9(5):958–966, 2007.</p>
<p>[13] P. Indyk and R. Motwani. Approximate nearest neighbors: towards removing the curse of dimensionality. In STOC ’98: Proceedings of the thirtieth annual ACM symposium on Theory of computing, New York, NY, USA, 1998. ACM Press.</p>
<p>[14] H. J´ gou, M. Douze, C. Schmid, and P. P´ rez. Aggregating local descriptors into a compact image e e representation. In Proc. Comp. Vision Pattern Recogn. (CVPR), 2010.</p>
<p>[15] B. Kulis and T. Darrell. Learning to hash with binary reconstructive embeddings. In Advances in Neural Information Processing Systems (NIPS), 2009.</p>
<p>[16] B. Kulis and K. Grauman. Kernelized locality-sensitive hashing for scalable image search. In Intl. Conf. Computer Vision, 2010.</p>
<p>[17] N. Kumar, A. C. Berg, P. N. Belhumeur, and S. K. Nayar. Attribute and Simile Classiﬁers for Face Veriﬁcation. In Intl. Conf. Computer Vision, 2009.</p>
<p>[18] C. H. Lampert, H. Nickisch, and S. Harmeling. Learning to detect unseen object classes by between-class attribute transfer. In CVPR, 2009.</p>
<p>[19] L. Li, H. Su, E. Xing, and L. Fei-Fei. Object Bank: A high-level image representation for scene classiﬁcation & semantic feature sparsiﬁcation. In NIPS. 2010.</p>
<p>[20] D. Lowe. Distinctive image features from scale-invariant keypoints. Intl. Jrnl. of Computer Vision, 60(2):91–110, 2004.</p>
<p>[21] A. Oliva and A. Torralba. Building the gist of a scene: The role of global image features in recognition. Visual Perception, Progress in Brain Research, 155, 2006.</p>
<p>[22] M. Raginsky and S. Lazebnik. Locality-sensitive binary codes from shift-invariant kernels. In Advances in Neural Information Processing Systems (NIPS), 2010.</p>
<p>[23] M. Ranzato, Y. Boureau, and Y. LeCun. Sparse feature learning for deep belief networks. In Advances in Neural Information Processing Systems (NIPS), 2007.</p>
<p>[24] R. Salakhutdinov and G. Hinton. Semantic hashing. Int. J. Approx. Reasoning, 50:969–978, 2009.</p>
<p>[25] E. Shechtman and M. Irani. Matching local self-similarities across images and videos. In Proc. Comp. Vision Pattern Recogn. (CVPR), 2007.</p>
<p>[26] A. Torralba, R. Fergus, and Y. Weiss. Small codes and large image databases for recognition. In Proc. Comp. Vision Pattern Recogn. (CVPR), 2008.</p>
<p>[27] L. Torresani, M. Szummer, and A. Fitzgibbon. Efﬁcient object category recognition using classemes. In ECCV, 2010.</p>
<p>[28] A. Vedaldi and A. Zisserman. Efﬁcient additive kernels via explicit feature maps. In CVPR, 2010.</p>
<p>[29] J. Vogel and B. Schiele. Semantic modeling of natural scenes for content-based image retrieval. Intl. Jrnl. of Computer Vision, 72(2):133–157, 2007.</p>
<p>[30] G. Wang, D. Hoiem, and D. Forsyth. Learning image similarity from ﬂickr using stochastic intersection kernel machines. In Intl. Conf. Computer Vision, 2009.</p>
<p>[31] Y. Weiss, A. Torralba, and R. Fergus. Spectral hashing. In NIPS. 2009.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
