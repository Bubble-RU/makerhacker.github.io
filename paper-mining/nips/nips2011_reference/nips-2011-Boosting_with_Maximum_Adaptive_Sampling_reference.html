<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>49 nips-2011-Boosting with Maximum Adaptive Sampling</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-49" href="../nips2011/nips-2011-Boosting_with_Maximum_Adaptive_Sampling.html">nips2011-49</a> <a title="nips-2011-49-reference" href="#">nips2011-49-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>49 nips-2011-Boosting with Maximum Adaptive Sampling</h1>
<br/><p>Source: <a title="nips-2011-49-pdf" href="http://papers.nips.cc/paper/4310-boosting-with-maximum-adaptive-sampling.pdf">pdf</a></p><p>Author: Charles Dubout, Francois Fleuret</p><p>Abstract: Classical Boosting algorithms, such as AdaBoost, build a strong classiﬁer without concern about the computational cost. Some applications, in particular in computer vision, may involve up to millions of training examples and features. In such contexts, the training time may become prohibitive. Several methods exist to accelerate training, typically either by sampling the features, or the examples, used to train the weak learners. Even if those methods can precisely quantify the speed improvement they deliver, they offer no guarantee of being more efﬁcient than any other, given the same amount of time. This paper aims at shading some light on this problem, i.e. given a ﬁxed amount of time, for a particular problem, which strategy is optimal in order to reduce the training loss the most. We apply this analysis to the design of new algorithms which estimate on the ﬂy at every iteration the optimal trade-off between the number of samples and the number of features to look at in order to maximize the expected loss reduction. Experiments in object recognition with two standard computer vision data-sets show that the adaptive methods we propose outperform basic sampling and state-of-the-art bandit methods. 1</p><br/>
<h2>reference text</h2><p>[1] P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit problem. Machine Learning, 47(2):235–256, 2002.</p>
<p>[2] P. Auer, N. Cesa-Bianchi, Y. Freund, and R. Schapire. The nonstochastic multiarmed bandit problem. SIAM Journal on Computing, 32(1):48–77, 2003.</p>
<p>[3] R. Busa-Fekete and B. Kegl. Accelerating AdaBoost using UCB. JMLR W&CP;, Jan 2009.</p>
<p>[4] R. Busa-Fekete and B. Kegl. Fast Boosting using adversarial bandits. In ICML, 2010.</p>
<p>[5] N. Dufﬁeld, C. Lund, and M. Thorup. Priority sampling for estimation of arbitrary subset sums. J. ACM, 54, December 2007.</p>
<p>[6] G. Escudero, L. M` rquez, and G. Rigau. Boosting applied to word sense disambiguation. a Machine Learning: ECML 2000, pages 129–141, 2000.</p>
<p>[7] F. Fleuret and D. Geman. Stationary features and cat detection. Journal of Machine Learning Research (JMLR), 9:2549–2578, 2008.</p>
<p>[8] Z. Kalal, J. Matas, and K. Mikolajczyk. Weighted sampling for large-scale Boosting. British machine vision conference, 2008.</p>
<p>[9] A. Krizhevsky. Learning Multiple Layers of Features from Tiny Images. Master’s thesis, 2009. http://www.cs.toronto.edu/˜kriz/cifar.html.</p>
<p>[10] Y. Lecun and C. Cortes. The mnist database of handwritten digits. http://yann.lecun. com/exdb/mnist/.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
