<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>230 nips-2011-RTRMC: A Riemannian trust-region method for low-rank matrix completion</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-230" href="../nips2011/nips-2011-RTRMC%3A_A_Riemannian_trust-region_method_for_low-rank_matrix_completion.html">nips2011-230</a> <a title="nips-2011-230-reference" href="#">nips2011-230-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>230 nips-2011-RTRMC: A Riemannian trust-region method for low-rank matrix completion</h1>
<br/><p>Source: <a title="nips-2011-230-pdf" href="http://papers.nips.cc/paper/4402-rtrmc-a-riemannian-trust-region-method-for-low-rank-matrix-completion.pdf">pdf</a></p><p>Author: Nicolas Boumal, Pierre-antoine Absil</p><p>Abstract: We consider large matrices of low rank. We address the problem of recovering such matrices when most of the entries are unknown. Matrix completion ﬁnds applications in recommender systems. In this setting, the rows of the matrix may correspond to items and the columns may correspond to users. The known entries are the ratings given by users to some items. The aim is to predict the unobserved ratings. This problem is commonly stated in a constrained optimization framework. We follow an approach that exploits the geometry of the low-rank constraint to recast the problem as an unconstrained optimization problem on the Grassmann manifold. We then apply ﬁrst- and second-order Riemannian trust-region methods to solve it. The cost of each iteration is linear in the number of known entries. Our methods, RTRMC 1 and 2, outperform state-of-the-art algorithms on a wide range of problem instances. 1</p><br/>
<h2>reference text</h2><p>[ABG07]  P.-A. Absil, C. G. Baker, and K. A. Gallivan. Trust-region methods on Riemannian manifolds. Found. Comput. Math., 7(3):303–330, July 2007.  [AMS08]  P.-A. Absil, R. Mahony, and R. Sepulchre. Optimization Algorithms on Matrix Manifolds. Princeton University Press, Princeton, NJ, 2008.  [BNR10]  L. Balzano, R. Nowak, and B. Recht. Online identiﬁcation and tracking of subspaces from highly incomplete information. In Communication, Control, and Computing (Allerton), 2010 48th Annual Allerton Conference on, pages 704–711. IEEE, 2010.  [Bro05]  M. Brookes. The matrix reference manual. Imperial College London, 2005.  [CCS08]  J.F. Cai, E.J. Cand` s, and Z. Shen. A singular value thresholding algorithm for matrix completion. e Arxiv preprint arXiv:0810.3286, 2008.  [CR09]  E.J. Cand` s and B. Recht. Exact matrix completion via convex optimization. Foundations of e Computational Mathematics, 9(6):717–772, 2009.  [DKM10] W. Dai, E. Kerman, and O. Milenkovic. A Geometric Approach to Low-Rank Matrix Completion. Arxiv preprint arXiv:1006.2086, 2010. [DMK11] W. Dai, O. Milenkovic, and E. Kerman. Subspace evolution and transfer (SET) for low-rank matrix completion. Signal Processing, IEEE Transactions on, PP(99):1, 2011. [GRGP01] K. Goldberg, T. Roeder, D. Gupta, and C. Perkins. Eigentaste: A constant time collaborative ﬁltering algorithm. Information Retrieval, 4(2):133–151, 2001. [KM10]  R.H. Keshavan and A. Montanari. Regularization for matrix completion. In Information Theory Proceedings (ISIT), 2010 IEEE International Symposium on, pages 1503–1507. IEEE, 2010.  [KMO09] R.H. Keshavan, A. Montanari, and S. Oh. Low-rank matrix completion with noisy observations: a quantitative comparison. In Communication, Control, and Computing, 2009. Allerton 2009. 47th Annual Allerton Conference on, pages 1216–1222. IEEE, 2009. [KO09]  R.H. Keshavan and S. Oh. OptSpace: A gradient descent algorithm on the Grassman manifold for matrix completion. Arxiv preprint arXiv:0910.5260 v2, 2009.  [Lar05]  R.M. Larsen. PROPACK–Software for large and sparse SVD calculations. Available online. URL http://sun. stanford. edu/rmunk/PROPACK, 2005.  [LB10]  K. Lee and Y. Bresler. ADMiRA: Atomic decomposition for minimum rank approximation. Information Theory, IEEE Transactions on, 56(9):4402–4416, 2010.  [MBS11]  G. Meyer, S. Bonnabel, and R. Sepulchre. Linear regression under ﬁxed-rank constraints: a Riemannian approach. In 28th International Conference on Machine Learning. ICML, 2011.  [TB97]  L.N. Trefethen and D. Bau. Numerical linear algebra. Society for Industrial Mathematics, 1997.  [Van11]  B. Vandereycken. Low-rank matrix completion by riemannian optimization. Technical report, ´ ANCHP-MATHICSE, Mathematics Section, Ecole Polytechnique F´ d´ rale de Lausanne, 2011. e e  [WYZ10] Z. Wen, W. Yin, and Y. Zhang. Solving a low-rank factorization model for matrix completion by a nonlinear successive over-relaxation algorithm. Technical report, Rice University, 2010. CAAM Technical Report TR10-07.  9</p>
<br/>
<br/><br/><br/></body>
</html>
