<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>93 nips-2011-Extracting Speaker-Specific Information with a Regularized Siamese Deep Network</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-93" href="../nips2011/nips-2011-Extracting_Speaker-Specific_Information_with_a_Regularized_Siamese_Deep_Network.html">nips2011-93</a> <a title="nips-2011-93-reference" href="#">nips2011-93-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>93 nips-2011-Extracting Speaker-Specific Information with a Regularized Siamese Deep Network</h1>
<br/><p>Source: <a title="nips-2011-93-pdf" href="http://papers.nips.cc/paper/4314-extracting-speaker-specific-information-with-a-regularized-siamese-deep-network.pdf">pdf</a></p><p>Author: Ke Chen, Ahmad Salman</p><p>Abstract: Speech conveys different yet mixed information ranging from linguistic to speaker-speciﬁc components, and each of them should be exclusively used in a speciﬁc task. However, it is extremely difﬁcult to extract a speciﬁc information component given the fact that nearly all existing acoustic representations carry all types of speech information. Thus, the use of the same representation in both speech and speaker recognition hinders a system from producing better performance due to interference of irrelevant information. In this paper, we present a deep neural architecture to extract speaker-speciﬁc information from MFCCs. As a result, a multi-objective loss function is proposed for learning speaker-speciﬁc characteristics and regularization via normalizing interference of non-speaker related information and avoiding information loss. With LDC benchmark corpora and a Chinese speech corpus, we demonstrate that a resultant speaker-speciﬁc representation is insensitive to text/languages spoken and environmental mismatches and hence outperforms MFCCs and other state-of-the-art techniques in speaker recognition. We discuss relevant issues and relate our approach to previous work. 1</p><br/>
<h2>reference text</h2><p>[1] Huang, X., Acero, A. & Hon, H. (2001) Spoken Language Processing. New York: Prentice Hall.</p>
<p>[2] Jang, G., Lee, T. & Oh, Y. (2001) Learning statistically efﬁcient feature for speaker recognition. Proc. ICASSP, pp. I427-I440, IEEE Press.</p>
<p>[3] Mammone, R., Zhang, X. & Ramachandran, R. (1996) Robust speaker recognition: a feature-based approach. IEEE Signal Processing Magazine, 13(1): 58-71.</p>
<p>[4] Reynold, D. & Campbell, W. (2008) Text-independent speaker recognition. In J. Benesty, M. Sondhi and Y. Huang (Eds.), Handbook of Speech Processing, pp. 763-781, Berlin: Springer.</p>
<p>[5] Bengio, Y. (2009) Learning deep architectures for AI. Foundation and Trends in Machine Learning 2(1): 1-127.</p>
<p>[6] Hinton, G. (2007) Learning multiple layers of representation. Trends in Cognitive Science 11(10): 428-434.</p>
<p>[7] Larochelle, H., Bengio, Y., Louradour, J. & Lamblin, P. (2009) Exploring strategies for training deep neural networks. Journal of Machine Learning Research 10(1): pp. 1-40.</p>
<p>[8] Boureau, Y., Bach, F., LeCun, Y. & Ponce, J. (2010) Learning mid-level features for recognition. Proc. CVPR, IEEE Press.</p>
<p>[9] Lee, H., Largman, Y., Pham, P. & Ng, A. (2009) Unsupervised feature learning for audio classiﬁcation using convolutional deep belief networks. In Advances in Neural Information Processing Systems 22, Cambridge, MA: MIT Press.</p>
<p>[10] Bromley, J., Guyon, I., LeCun, Y., Sackinger, E. & Shah, R. (1994) Signature veriﬁcation using a Siamese time delay neural network. In Advances in Neural Information Processing Systems 5, Morgan Kaufmann.</p>
<p>[11] Chopra, S., Hadsell, R. & LeCun, Y. (2005) Learning a similarity metric discriminatively, with application to face veriﬁcation. In Proc. CVPR, IEEE Press.</p>
<p>[12] Salakhutdinov, R. & Hinton, G. (2007) Learning a non-linear embedding by preserving class neighborhood structure. In Proc. AISTATS, Cambridge, MA: MIT Press.</p>
<p>[13] Hinton, G., Osindero, S. & Teh, Y. (2006) A fast learning algorithm for deep belief nets. Neural Computation 18(7): 1527-1554.</p>
<p>[14] Linguistic Data Consortium (LDC). [online] www.ldc.upenn.edu</p>
<p>[15] Wang, L. (2008) A Chinese speech corpus for speaker recognition. Tech. Report, SIAT-CAS, China.</p>
<p>[16] LeCun, Y., Chopra, S. Hadsell, R., Ranzato, M. & Huang, F. (2007) Energy-based models. In Predicting Structured Outputs, pp. 191-246, Cambridge, MA: MIT Press.</p>
<p>[17] Vincent, P., Bengio, Y. & Manzagol, P. (2008) Extracting and composing robust features with denoising autoencoders. Proc. ICML, pp. 1096-1102, ACM Press.</p>
<p>[18] Reynolds, D. (1995) Speaker Identiﬁcation and veriﬁcation using Gaussian mixture speaker models. Speech Communication 17(1): 91-108.</p>
<p>[19] Proakis, J. (2001) Digital Communications (4th Edition). New York: McGraw-Hill.</p>
<p>[20] Campbell, J. (1997) Speaker recognition: A tutorial. Proceedings of The IEEE 85(10): 1437-1462.</p>
<p>[21] van der Maaten, L. & Hinton, G. (2008) Visualizing data using t-SNE. Journal of Machine Learning Research 9: 2579-2605.</p>
<p>[22] Campbell, W. & Karam, Z. (2009) Speaker comparison with inner product discriminant functions. In Advances in Neural Information Processing Systems 22, Cambridge, MA: MIT Press.</p>
<p>[23] Kotti, M., Moschou, V. & Kotropoulos, C. (2008) Speaker segmentation and clustering. Signal Processing 88(8): 1091-1124.</p>
<p>[24] Raina, R., Battle, A., Lee, H., Packer, B. & Ng, A. (2007) Self-taught learning: transfer learning from unlabeled data. Proc. ICML, ACM press.</p>
<p>[25] Goldberger, J., Roweis, S., Hinton, G. & Salakhutdinov, R., (2005) Neighbourhood component analysis. In Advances in Neural Information Processing Systems 17, Cambridge, MA: MIT Press.</p>
<p>[26] Hinton, G. & Salakhutdinov, R. (2006) Reducing the dimensionality of data with neural networks. Science 313: 504-507.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
