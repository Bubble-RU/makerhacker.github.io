<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>26 nips-2011-Additive Gaussian Processes</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-26" href="../nips2011/nips-2011-Additive_Gaussian_Processes.html">nips2011-26</a> <a title="nips-2011-26-reference" href="#">nips2011-26-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>26 nips-2011-Additive Gaussian Processes</h1>
<br/><p>Source: <a title="nips-2011-26-pdf" href="http://papers.nips.cc/paper/4221-additive-gaussian-processes.pdf">pdf</a></p><p>Author: David K. Duvenaud, Hannes Nickisch, Carl E. Rasmussen</p><p>Abstract: We introduce a Gaussian process model of functions which are additive. An additive function is one which decomposes into a sum of low-dimensional functions, each depending on only a subset of the input variables. Additive GPs generalize both Generalized Additive Models, and the standard GP models which use squared-exponential kernels. Hyperparameter learning in this model can be seen as Bayesian Hierarchical Kernel Learning (HKL). We introduce an expressive but tractable parameterization of the kernel function, which allows efÔ¨Åcient evaluation of all input interaction terms, whose number is exponential in the input dimension. The additional structure discoverable by this model results in increased interpretability, as well as state-of-the-art predictive power in regression tasks. 1</p><br/>
<h2>reference text</h2><br/>
<br/><br/><br/></body>
</html>
