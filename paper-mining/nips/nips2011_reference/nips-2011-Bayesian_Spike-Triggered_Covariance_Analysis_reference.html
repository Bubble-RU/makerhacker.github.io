<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>44 nips-2011-Bayesian Spike-Triggered Covariance Analysis</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-44" href="../nips2011/nips-2011-Bayesian_Spike-Triggered_Covariance_Analysis.html">nips2011-44</a> <a title="nips-2011-44-reference" href="#">nips2011-44-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>44 nips-2011-Bayesian Spike-Triggered Covariance Analysis</h1>
<br/><p>Source: <a title="nips-2011-44-pdf" href="http://papers.nips.cc/paper/4411-bayesian-spike-triggered-covariance-analysis.pdf">pdf</a></p><p>Author: Jonathan W. Pillow, Il M. Park</p><p>Abstract: Neurons typically respond to a restricted number of stimulus features within the high-dimensional space of natural stimuli. Here we describe an explicit modelbased interpretation of traditional estimators for a neuron’s multi-dimensional feature space, which allows for several important generalizations and extensions. First, we show that traditional estimators based on the spike-triggered average (STA) and spike-triggered covariance (STC) can be formalized in terms of the “expected log-likelihood” of a Linear-Nonlinear-Poisson (LNP) model with Gaussian stimuli. This model-based formulation allows us to deﬁne maximum-likelihood and Bayesian estimators that are statistically consistent and efﬁcient in a wider variety of settings, such as with naturalistic (non-Gaussian) stimuli. It also allows us to employ Bayesian methods for regularization, smoothing, sparsiﬁcation, and model comparison, and provides Bayesian conﬁdence intervals on model parameters. We describe an empirical Bayes method for selecting the number of features, and extend the model to accommodate an arbitrary elliptical nonlinear response function, which results in a more powerful and more ﬂexible model for feature space inference. We validate these methods using neural data recorded extracellularly from macaque primary visual cortex. 1</p><br/>
<h2>reference text</h2><p>[1] J. Bussgang. Crosscorrelation functions of amplitude-distorted gaussian signals. RLE Technical Reports, 216, 1952.</p>
<p>[2] E. J. Chichilnisky. A simple white noise analysis of neuronal light responses. Network: Comput. Neural Syst., 12:199–213, 2001.</p>
<p>[3] R. de Ruyter and W. Bialek. Real-time performance of a movement-senstivive neuron in the blowﬂy visual system. Proc. R. Soc. Lond. B, 234:379–414, 1988.</p>
<p>[4] O. Schwartz, E. J. Chichilnisky, and E. P. Simoncelli. Characterizing neural gain control using spiketriggered covariance. Adv. Neural Information Processing Systems, pages 269–276, 2002.</p>
<p>[5] O. Schwartz, J. W. Pillow, N. C. Rust, and E. P. Simoncelli. Spike-triggered neural characterization. J. Vision, 6(4):484–507, 7 2006.</p>
<p>[6] E. P. Simoncelli, J. Pillow, L. Paninski, and O. Schwartz. Characterization of neural responses with stochastic stimuli. The Cognitive Neurosciences, III, chapter 23, pages 327–338. MIT Press, 2004.</p>
<p>[7] S. Gerwinn, J. Macke, M. Seeger, and M. Bethge. Bayesian inference for spiking neuron models with a sparsity prior. Adv. in Neural Information Processing Systems 20, pages 529–536. MIT Press, 2008.</p>
<p>[8] L. Paninski. Convergence properties of some spike-triggered analysis techniques. Network: Comput. Neural Syst., 14:437–464, 2003.</p>
<p>[9] J. W. Pillow and E. P. Simoncelli. Dimensionality reduction in neural models: An information-theoretic generalization of spike-triggered average and covariance analysis. J. Vision, 6(4):414–428, 4 2006.</p>
<p>[10] C. M. Bishop. Bayesian PCA. Adv. in Neural Information Processing Systems, pages 382–388, 1999.</p>
<p>[11] M. E. Tipping and C. M. Bishop. Probabilistic principal component analysis. J. the Royal Statistical Society. Series B, Statistical Methodology, pages 611–622, 1999.</p>
<p>[12] T. P. Minka. Automatic choice of dimensionality for PCA. NIPS, pages 598–604, 2001.</p>
<p>[13] M. Welling, F. Agakov, and C. K. I. Williams. Extreme components analysis. Adv. in Neural Information Processing Systems 16. MIT Press, 2004.</p>
<p>[14] Y. Chen and M. Welling. Bayesian extreme components analysis. IJCAI, 2009.</p>
<p>[15] T. Sharpee, N. C. Rust, and W. Bialek. Analyzing neural responses to natural signals: maximally informative dimensions. Neural Comput, 16(2):223–250, Feb 2004.</p>
<p>[16] N. C. Rust, O. Schwartz, J. A. Movshon, and E. P. Simoncelli. Spatiotemporal elements of macaque V1 receptive ﬁelds. Neuron, 46(6):945–956, Jun 2005.</p>
<p>[17] L. Paninski. Maximum likelihood estimation of cascade point-process neural encoding models. Network: Comput. Neural Syst., 15(04):243–262, November 2004.</p>
<p>[18] N. Brenner, S. P. Strong, R. Koberle, W. Bialek, and R. R. de Ruyter van Steveninck. Synergy in a neural code. Neural Comput, 12(7):1531–1552, Jul 2000.</p>
<p>[19] L. Paninski. Maximum likelihood estimation of cascade point-process neural encoding models. Network: Computation in Neural Systems, 15:243–262, 2004.</p>
<p>[20] F. Theunissen, S. David, N. Singh, A. Hsu, W. Vinje, and J. Gallant. Estimating spatio-temporal receptive ﬁelds of auditory and visual neurons from their responses to natural stimuli. Network: Comput. Neural Syst., 12:289–316, 2001.</p>
<p>[21] M. Sahani and J. Linden. Evidence optimization techniques for estimating stimulus-response functions. NIPS, 15, 2003.</p>
<p>[22] S. V. David, N. Mesgarani, and S. A. Shamma. Estimating sparse spectro-temporal receptive ﬁelds with natural stimuli. Network: Comput. Neural Syst., 18(3):191–212, 2007.</p>
<p>[23] I. H. Stevenson, J. M. Rebesco, N. G. Hatsopoulos, Z. Haga, L. E. Miller, and K. P. K¨ rding. Bayesian o inference of functional connectivity and network structure from spikes. IEEE Transactions on Neural Systems and Rehabilitation Engineering, 17(3):203–213, 2009.</p>
<p>[24] S. Gerwinn, J. H Macke, and M. Bethge. Bayesian inference for generalized linear models for spiking neurons. Frontiers in Computational Neuroscience, 2010.</p>
<p>[25] A. Calabrese, J. W. Schumacher, D. M. Schneider, L. Paninski, and S. M. N. Woolley. A generalized linear model for estimating spectrotemporal receptive ﬁelds from responses to natural sounds. PLoS One, 6(1):e16104, 2011.</p>
<p>[26] W. James and C. Stein. Estimation with quadratic loss. 4th Berkeley Symposium on Mathematical Statistics and Probability, 1:361–379, 1960.</p>
<p>[27] M. Tipping. Sparse Bayesian learning and the relevance vector machine. JMLR, 1:211–244, 2001.</p>
<p>[28] D. Donoho and M. Elad. Optimally sparse representation in general (nonorthogonal) dictionaries via l1 minimization. PNAS, 100:2197–2202, 2003.</p>
<p>[29] K. R. Rad and L. Paninski. Efﬁcient, adaptive estimation of two-dimensional ﬁring rate surfaces via gaussian process methods. Network: Comput. Neural Syst., 21(3-4):142–168, 2010.</p>
<p>[30] D. Wipf and S. Nagarajan. A new view of automatic relevance determination. Adv. in Neural Information Processing Systems 20, pages 1625–1632. MIT Press, 2008.</p>
<p>[31] W. Truccolo, U. T. Eden, M. R. Fellows, J. P. Donoghue, and E. N. Brown. A point process framework for relating neural spiking activity to spiking history, neural ensemble and extrinsic covariate effects. J. Neurophysiol, 93(2):1074–1089, 2005.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
