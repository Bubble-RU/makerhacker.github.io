<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>246 nips-2011-Selective Prediction of Financial Trends with Hidden Markov Models</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-246" href="../nips2011/nips-2011-Selective_Prediction_of_Financial_Trends_with_Hidden_Markov_Models.html">nips2011-246</a> <a title="nips-2011-246-reference" href="#">nips2011-246-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>246 nips-2011-Selective Prediction of Financial Trends with Hidden Markov Models</h1>
<br/><p>Source: <a title="nips-2011-246-pdf" href="http://papers.nips.cc/paper/4301-selective-prediction-of-financial-trends-with-hidden-markov-models.pdf">pdf</a></p><p>Author: Dmitry Pidan, Ran El-Yaniv</p><p>Abstract: Focusing on short term trend prediction in a Ä?Ĺš nancial context, we consider the problem of selective prediction whereby the predictor can abstain from prediction in order to improve performance. We examine two types of selective mechanisms for HMM predictors. The Ä?Ĺš rst is a rejection in the spirit of ChowĂ˘&euro;&trade;s well-known ambiguity principle. The second is a specialized mechanism for HMMs that identiÄ?Ĺš es low quality HMM states and abstain from prediction in those states. We call this model selective HMM (sHMM). In both approaches we can trade-off prediction coverage to gain better accuracy in a controlled manner. We compare performance of the ambiguity-based rejection technique with that of the sHMM approach. Our results indicate that both methods are effective, and that the sHMM model is superior. 1</p><br/>
<h2>reference text</h2><p>[1] P. L. Bartlett and M. H. Wegkamp. ClassiÄ?Ĺš cation with a reject option using a hinge loss. Journal of Machine Learning Research, 9:1823Ă˘&euro;&ldquo;1840, 2008.</p>
<p>[2] L. E. Baum, T. Petrie, G. Soules, and N. Weiss. A maximization technique occurring in the statistical analysis of probabilistic functions of markov chains. The Annals of Mathematical Statistics, 41(1):164Ă˘&euro;&ldquo;171, 1970.</p>
<p>[3] M. Bicego, E. Grosso, and E. Otranto. A Hidden Markov Model approach to classify and predict the sign of Ä?Ĺš nancial local trends. SSPR, 5342:852Ă˘&euro;&ldquo;861, 2008.</p>
<p>[4] M. Brand. Coupled Hidden Markov Models for modeling interacting processes. Technical Report 405, MIT Media Lab, 1997.</p>
<p>[5] C. Chow. On optimum recognition error and reject tradeoff. IEEE-IT, 16:41Ă˘&euro;&ldquo;46, 1970.</p>
<p>[6] R. El-Yaniv and Y. Wiener. On the foundations of noise-free selective classiÄ?Ĺš cation. JMLR, 11:1605Ă˘&euro;&ldquo;1641, May 2010.</p>
<p>[7] R. El-Yaniv and Y. Wiener. Agnostic selective classiÄ?Ĺš cation. In NIPS, 2011.</p>
<p>[8] S. Fine, Y. Singer, and N. Tishby. The Hierarchical Hidden Markov Model: Analysis and Applications. Machine Learning, 32(1):41Ă˘&euro;&ldquo;62, 1998.</p>
<p>[9] Y. Freund, Y. Mansour, and R. E. Schapire. Generalization bounds for averaged classiÄ?Ĺš ers. Annals of Statistics, 32(4):1698Ă˘&euro;&ldquo;1722, 2004.</p>
<p>[10] Z. Ghahramani and M. I. Jordan. Factorial Hidden Markov Models. Machine Learning, 29(2Ă˘&euro;&ldquo; 3):245Ă˘&euro;&ldquo;273, 1997.</p>
<p>[11] J. Hamilton. Analysis of time series subject to changes in regime. Journal of Econometrics, 45(1Ă˘&euro;&ldquo;2):39Ă˘&euro;&ldquo;70, 1990.</p>
<p>[12] B. Hanczar and E. R. Dougherty. ClassiÄ?Ĺš cation with reject option in gene expression data. Bioinformatics, 24:1889Ă˘&euro;&ldquo;1895, 2008.</p>
<p>[13] D. Hsu, S. Kakade, and T. Zhang. A spectral algorithm for learning Hidden Markov Models. In COLT, 2009.</p>
<p>[14] A. L. Koerich. Rejection strategies for handwritten word recognition. In IWFHR, 2004.</p>
<p>[15] A. Krogh. Hidden Markov Models for labeled sequences. In Proceedings of the 12th IAPR ICPRĂ˘&euro;&trade;94, pages 140Ă˘&euro;&ldquo;144, 1994.</p>
<p>[16] L. R. Rabiner. A tutorial on Hidden Markov Models and selected applications in speech recognition. Proceedings of the IEEE, 77(2), February 1989.</p>
<p>[17] S. Rao and J. Hong. Analysis of Hidden Markov Models and Support Vector Machines in Ä?Ĺš nancial applications. Technical Report UCB/EECS-2010-63, Electrical Engineering and Computer Sciences University of California at Berkeley, 2010.</p>
<p>[18] L. K. Saul and M. I. Jordan. Mixed memory Markov models: Decomposing complex stochastic processes as mixtures of simpler ones. Machine Learning, 37:75Ă˘&euro;&ldquo;87, 1999.</p>
<p>[19] S. Shi and A. S. Weigend. Taking time seriously: Hidden Markov Experts applied to Ä?Ĺš nancial engineering. In IEEE/IAFE, pages 244Ă˘&euro;&ldquo;252. IEEE, 1997.</p>
<p>[20] S. Siddiqi, G. Gordon, and A. Moore. Fast State Discovery for HMM Model Selection and Learning. In AI-STATS, 2007.</p>
<p>[21] F. Tortorella. Reducing the classiÄ?Ĺš cation cost of support vector classiÄ?Ĺš ers through an ROCbased reject rule. Pattern Anal. Appl., 7:128Ă˘&euro;&ldquo;143, 2004.</p>
<p>[22] A. Viterbi. Error bounds for convolutional codes and an asymptotically optimum decoding algorithm. IEEE-IT, 13(2):260Ă˘&euro;&ldquo;269, 1967.</p>
<p>[23] Y. Zhang. Prediction of Ä?Ĺš nancial time series with Hidden Markov Models. MasterĂ˘&euro;&trade;s thesis, The School of Computing Science, Simon Frazer University, Canada, 2004.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
