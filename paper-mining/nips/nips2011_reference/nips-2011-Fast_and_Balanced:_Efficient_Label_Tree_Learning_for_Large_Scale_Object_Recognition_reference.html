<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>96 nips-2011-Fast and Balanced: Efficient Label Tree Learning for Large Scale Object Recognition</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-96" href="../nips2011/nips-2011-Fast_and_Balanced%3A_Efficient_Label_Tree_Learning_for_Large_Scale_Object_Recognition.html">nips2011-96</a> <a title="nips-2011-96-reference" href="#">nips2011-96-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>96 nips-2011-Fast and Balanced: Efficient Label Tree Learning for Large Scale Object Recognition</h1>
<br/><p>Source: <a title="nips-2011-96-pdf" href="http://papers.nips.cc/paper/4212-fast-and-balanced-efficient-label-tree-learning-for-large-scale-object-recognition.pdf">pdf</a></p><p>Author: Jia Deng, Sanjeev Satheesh, Alexander C. Berg, Fei Li</p><p>Abstract: We present a novel approach to efﬁciently learn a label tree for large scale classiﬁcation with many classes. The key contribution of the approach is a technique to simultaneously determine the structure of the tree and learn the classiﬁers for each node in the tree. This approach also allows ﬁne grained control over the efﬁciency vs accuracy trade-off in designing a label tree, leading to more balanced trees. Experiments are performed on large scale image classiﬁcation with 10184 classes and 9 million images. We demonstrate signiﬁcant improvements in test accuracy and efﬁciency with less training time and more balanced trees compared to the previous state of the art by Bengio et al. 1</p><br/>
<h2>reference text</h2><p>[1] S. Bengio, J. Weston, and D. Grangier. Label embedding trees for large multi-class tasks. In Advances in Neural Information Processing Systems (NIPS), 2010.</p>
<p>[2] A. Beygelzimer, J. Langford, and P. Ravikumar. Multiclass classiﬁcation with ﬁlter trees. Preprint, June, 2007.</p>
<p>[3] Alina Beygelzimer, John Langford, Yuri Lifshits, Gregory B. Sorkin, and Alexander L. Strehl. Conditional probability tree estimation analysis and algorithms. Computing Research Repository, 2009.</p>
<p>[4] L. Bottou and O. Bousquet. The tradeoffs of large scale learning. Advances in neural information processing systems, 20:161–168, 2008.</p>
<p>[5] K. Crammer and Y. Singer. On the algorithmic implementation of multiclass kernel-based vector machines. The Journal of Machine Learning Research, 2:265–292, 2002.</p>
<p>[6] J. Deng, A.C. Berg, K. Li, and L. Fei-Fei. What does classifying more than 10,000 image categories tell us? In ECCV10.</p>
<p>[7] J. Deng, W. Dong, R. Socher, L.J. Li, K. Li, and L. Fei-Fei. ImageNet: A large-scale hierarchical image database. In CVPR09, 2009.</p>
<p>[8] C. Fellbaum. WordNet: An Electronic Lexical Database. MIT Press, 1998.</p>
<p>[9] Gregory Grifﬁn and Pietro Perona. Learning and using taxonomies for fast visual categorization. CVPR08, 2008.</p>
<p>[10] Y. Lin, F. Lv, S. Zhu, M. Yang, T. Cour, K. Yu, L. Cao, and T. Huang. Large-scale image classiﬁcation: Fast feature extraction and svm training. In Conference on Computer Vision and Pattern Recognition, page (to appear), volume 1, page 3, 2011.</p>
<p>[11] A. Torralba, R. Fergus, and W.T. Freeman. 80 million tiny images: A large data set for nonparametric object and scene recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence, pages 1958–1970, 2008.</p>
<p>[12] http://www.image-net.org/challenges/LSVRC/2010/.</p>
<p>[13] J. Wang, J. Yang, K. Yu, F. Lv, T. Huang, and Y. Gong. Locality-constrained linear coding for image classiﬁcation. 2010.</p>
<p>[14] D. Weiss, B. Sapp, and B. Taskar. Sidestepping intractable inference with structured ensemble cascades. In NIPS, volume 1281, pages 1282–1284, 2010.</p>
<p>[15] K. Yu and T. Zhang. Improved local coordinate coding using local tangents. ICML09, 2010.</p>
<p>[16] X. Zhou, K. Yu, T. Zhang, and T. Huang. Image classiﬁcation using super-vector coding of local image descriptors. Computer Vision–ECCV 2010, pages 141–154, 2010.</p>
<p>[17] M. Zinkevich, M. Weimer, A. Smola, and L. Li. Parallelized stochastic gradient descent. In J. Lafferty, C. K. I. Williams, J. Shawe-Taylor, R.S. Zemel, and A. Culotta, editors, Advances in Neural Information Processing Systems 23, pages 2595–2603. 2010.  9</p>
<br/>
<br/><br/><br/></body>
</html>
