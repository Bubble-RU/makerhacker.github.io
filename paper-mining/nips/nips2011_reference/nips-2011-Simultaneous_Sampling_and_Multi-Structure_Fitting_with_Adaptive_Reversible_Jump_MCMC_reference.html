<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>255 nips-2011-Simultaneous Sampling and Multi-Structure Fitting with Adaptive Reversible Jump MCMC</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-255" href="../nips2011/nips-2011-Simultaneous_Sampling_and_Multi-Structure_Fitting_with_Adaptive_Reversible_Jump_MCMC.html">nips2011-255</a> <a title="nips-2011-255-reference" href="#">nips2011-255-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>255 nips-2011-Simultaneous Sampling and Multi-Structure Fitting with Adaptive Reversible Jump MCMC</h1>
<br/><p>Source: <a title="nips-2011-255-pdf" href="http://papers.nips.cc/paper/4458-simultaneous-sampling-and-multi-structure-fitting-with-adaptive-reversible-jump-mcmc.pdf">pdf</a></p><p>Author: Trung T. Pham, Tat-jun Chin, Jin Yu, David Suter</p><p>Abstract: Multi-structure model ﬁtting has traditionally taken a two-stage approach: First, sample a (large) number of model hypotheses, then select the subset of hypotheses that optimise a joint ﬁtting and model selection criterion. This disjoint two-stage approach is arguably suboptimal and inefﬁcient — if the random sampling did not retrieve a good set of hypotheses, the optimised outcome will not represent a good ﬁt. To overcome this weakness we propose a new multi-structure ﬁtting approach based on Reversible Jump MCMC. Instrumental in raising the effectiveness of our method is an adaptive hypothesis generator, whose proposal distribution is learned incrementally and online. We prove that this adaptive proposal satisﬁes the diminishing adaptation property crucial for ensuring ergodicity in MCMC. Our method effectively conducts hypothesis sampling and optimisation simultaneously, and yields superior computational efﬁciency over previous two-stage methods. 1</p><br/>
<h2>reference text</h2><p>[1] H. Akaike. A new look at the statistical model identiﬁcation. IEEE Trans. on Automatic Control, 19(6):716–723, 1974.</p>
<p>[2] C. Andrieu, N. de Freitas, and A. Doucet. Robust full Bayesian learning for radial basis networks. Neural Computation, 13:2359–2407, 2001.</p>
<p>[3] C. Andrieu, N. de Freitas, A. Doucet, and M. I. Jordan. An introduction to MCMC for machine learning. Machine Learning, 50:5–43, 2003.</p>
<p>[4] C. Andrieu and J. Thoms. A tutorial on adaptive MCMC. Statistics and Computing, 18(4), 2008.</p>
<p>[5] S. P. Brooks, N. Friel, and R. King. Classical model selection via simulated annealing. J. R. Statist. Soc. B, 65(2):503–520, 2003.</p>
<p>[6] T.-J. Chin, J. Yu, and D. Suter. Accelerated hypothesis generation for multi-structure robust ﬁtting. In European Conf. on Computer Vision, 2010.</p>
<p>[7] A. Delong, A. Osokin, H. Isack, and Y. Boykov. Fast approximate energy minimization with label costs. In Computer Vision and Pattern Recognition, 2010.</p>
<p>[8] L. Fan and T. Pyln¨ n¨ inen. Adaptive sample consensus for efﬁcient random optimisation. In Int. Sympoa a sium on Visual Computing, 2009.</p>
<p>[9] M. A. Fischler and R. C. Bolles. Random sample consensus: A paradigm for model ﬁtting with applications to image analysis and automated cartography. Comm. of the ACM, 24:381–395, 1981.</p>
<p>[10] S. Gaffney and P. Smyth. Trajectory clustering with mixtures of regression models. In ACM SIG on Knowledge Discovery and Data Mining, 1999.</p>
<p>[11] P. Giordani and R. Kohn. Adaptive independent Metropolis-Hastings by fast estimation of mixtures of normals. Journal of Computational and Graphical Statistics, 19(2):243–259, 2010.</p>
<p>[12] P. J. Green. Reversible jump Markov chain Monte Carlo computation and Bayesian model determination. Biometrika, 82(4):711–732, 1995.</p>
<p>[13] H. Haario, E. Saksman, and J. Tamminen. An adaptive Metropolis algorithm. Bernoulli, 7(2):223–242, 2001.</p>
<p>[14] R. Hartley. In defense of the eight-point algorithm. IEEE Trans. on Pattern Analysis and Machine Intelligence, 19(6):580–593, 1997.</p>
<p>[15] R. Hartley and A. Zisserman. Multiple View Geometry. Cambridge University Press, 2004.</p>
<p>[16] P. J. Huber. Robust Statistics. John Wiley & Sons Inc., 2009.</p>
<p>[17] Y.-D. Jian and C.-S. Chen. Two-view motion segmentation by mixtures of dirichlet process with model selection and outlier removal. In International Conference on Computer Vision, 2007.</p>
<p>[18] N. Lazic, I. Givoni, B. Frey, and P. Aarabi. FLoSS: Facility location for subspace segmentation. In IEEE Int. Conf. on Computer Vision, 2009.</p>
<p>[19] H. Li. Two-view motion segmentation from linear programming relaxation. In Computer Vision and Pattern Recognition, 2007.</p>
<p>[20] D. Nott and R. Kohn. Adaptive sampling for Bayesian variable selection. Biometrika, 92:747–763, 2005.</p>
<p>[21] N. Quadrianto, T. S. Caetano, J. Lim, and D. Schuurmans. Convex relaxation of mixture regression with efﬁcient algorithms. In Advances in Neural Information Processing Systems, 2010.</p>
<p>[22] S. Richardson and P. J. Green. On Bayesian analysis on mixtures with an unknown number of components. J. R. Statist. Soc. B, 59(4):731–792, 1997.</p>
<p>[23] G. O. Roberts and J. S. Rosenthal. Coupling and ergodicity of adaptive Markov chain Monte Carlo algorithms. Journal of Applied Probability, 44:458–475, 2007.</p>
<p>[24] G. O. Roberts and J. S. Rosenthal. Examples of adaptive MCMC. Journal of Computational and Graphical Statistics, 18(2):349–367, 2009.</p>
<p>[25] K. Schinder and D. Suter. Two-view multibody structure-and-motion with outliers through model selection. IEEE Trans. on Pattern Analysis and Machine Intelligence, 28(6):983–995, 2006.</p>
<p>[26] N. Thakoor and J. Gao. Branch-and-bound hypothesis selection for two-view multiple structure and motion segmentation. In Computer Vision and Pattern Recognition, 2008.</p>
<p>[27] P. H. S. Torr. Motion segmentation and outlier detection. PhD thesis, Dept. of Engineering Science, University of Oxford, 1995.</p>
<p>[28] P. H. S. Torr and C. H. Davidson. IMPSAC: Synthesis of importance sampling and random sample consensus. IEEE Trans. on Pattern Analysis and Machine Intelligence, 25(3):354–364, 2003.</p>
<p>[29] E. Vincent and R. Lagani` re. Detecting planar homographies in an image pair. In International Sympoe sium on Image and Signal Processing and Analysis, 2001.</p>
<p>[30] H. S. Wong, T.-J. Chin, J. Yu, and D. Suter. Dynamic and hierarchical multi-structure geometric model ﬁtting. In International Conference on Computer Vision, 2011.</p>
<p>[31] J. Yu, T.-J. Chin, and D. Suter. A global optimization approach to robust multi-model ﬁtting. In Computer Vision and Pattern Recognition, 2011.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
