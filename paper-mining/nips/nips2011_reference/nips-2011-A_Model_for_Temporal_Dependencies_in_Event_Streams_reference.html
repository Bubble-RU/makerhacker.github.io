<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>8 nips-2011-A Model for Temporal Dependencies in Event Streams</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-8" href="../nips2011/nips-2011-A_Model_for_Temporal_Dependencies_in_Event_Streams.html">nips2011-8</a> <a title="nips-2011-8-reference" href="#">nips2011-8-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>8 nips-2011-A Model for Temporal Dependencies in Event Streams</h1>
<br/><p>Source: <a title="nips-2011-8-pdf" href="http://papers.nips.cc/paper/4395-a-model-for-temporal-dependencies-in-event-streams.pdf">pdf</a></p><p>Author: Asela Gunawardana, Christopher Meek, Puyang Xu</p><p>Abstract: We introduce the Piecewise-Constant Conditional Intensity Model, a model for learning temporal dependencies in event streams. We describe a closed-form Bayesian approach to learning these models, and describe an importance sampling algorithm for forecasting future events using these models, using a proposal distribution based on Poisson superposition. We then use synthetic data, supercomputer event logs, and web search query logs to illustrate that our learning algorithm can efﬁciently learn nonlinear temporal dependencies, and that our importance sampling algorithm can effectively forecast future events. 1</p><br/>
<h2>reference text</h2><p>[1] Simeon M. Berman. Note on extreme values, competing risks and semi-Markov processes. Ann. Math. Stat., 34(3):1104–1106, 1963.</p>
<p>[2] W. Buntine. Theory reﬁnement on Bayesian networks. In UAI, 1991.</p>
<p>[3] David Maxwell Chickering, David Heckerman, and Christopher Meek. A Bayesian approach to learning Bayesian networks with local structure. In UAI, 1997.</p>
<p>[4] D. J. Daley and D. Vere-Jones. An Introduction to the Theory of Point Processes: Elementary Theory and Methods, volume I. Springer, 2 edition, 2003.</p>
<p>[5] Thomas Dean and Keiji Kanazawa. Probabilistic temporal reasoning. In AAAI, 1988.</p>
<p>[6] Vanessa Didelez. Graphical models for marked point processes based on local independence. J. Roy. Stat. Soc., Ser. B, 70(1):245–264, 2008.</p>
<p>[7] Yu Fan and Christian R. Shelton. Sampling for approximate inference in continuous time Bayesian networks. In AI & M, 2008.</p>
<p>[8] N. Friedman, I. Nachman, and D. Pe´ r. Using Bayesian networks to analyze expression data. e J. Comp. Bio., 7:601–620, 2000.</p>
<p>[9] Nir Friedman, Kevin Murphy, and Stuart Russell. Learning the structure of dynamic probabilistic networks. In UAI, 1998.</p>
<p>[10] David Heckerman, David Maxwell Chickering, Christopher Meek, Robert Rounthwaite, and Carl Kadie. Dependency networks for inference, collaborative ﬁltering, and data visualization. JMLR, 1:49–75, October 2000.</p>
<p>[11] A. A. J. Marley and Hans Colonius. The “horse race” random utility model for choice probabilities and reaction times, and its competing risks interpretation. J. Math. Psych., 36:1–20, 1992.</p>
<p>[12] Uri Nodelman, Christian R. Shelton, and Daphne Koller. Continuous time Bayesian networks. In UAI, 2002.</p>
<p>[13] Uri Nodelman, Christian R. Shelton, and Daphne Koller. Expectation Maximization and complex duration distributions for continuous time Bayesian networks. In UAI, 2005.</p>
<p>[14] Adam Oliner and Jon Stearley. What supercomputers say - an analysis of ﬁve system logs. In IEEE/IFIP Conf. Dep. Sys. Net., 2007.</p>
<p>[15] Shyamsundar Rajaram, Thore Graepel, and Ralf Herbrich. Poisson-networks: A model for structured point processes. In AIStats, 2005.</p>
<p>[16] Aleksandr Simma, Moises Goldszmidt, John MacCormick, Paul Barham, Richard Brock, Rebecca Isaacs, and Reichard Mortier. CT-NOR: Representing and reasoning about events in continuous time. In UAI, 2008.</p>
<p>[17] Aleksandr Simma and Michael I. Jordan. Modeling events with cascades of Poisson processes. In UAI, 2010.</p>
<p>[18] Wilson Truccolo, Uri T. Eden, Matthew R. Gellows, John P. Donoghue, and Emery N. Brown. A point process framework relating neural spiking activity to spiking history, neural ensemble, and extrinsic covariate effects. J. Neurophysiol., 93:1074–1089, 2005.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
