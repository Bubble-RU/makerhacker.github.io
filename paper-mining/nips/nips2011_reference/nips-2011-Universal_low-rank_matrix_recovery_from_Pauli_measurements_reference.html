<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>297 nips-2011-Universal low-rank matrix recovery from Pauli measurements</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-297" href="../nips2011/nips-2011-Universal_low-rank_matrix_recovery_from_Pauli_measurements.html">nips2011-297</a> <a title="nips-2011-297-reference" href="#">nips2011-297-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>297 nips-2011-Universal low-rank matrix recovery from Pauli measurements</h1>
<br/><p>Source: <a title="nips-2011-297-pdf" href="http://papers.nips.cc/paper/4222-universal-low-rank-matrix-recovery-from-pauli-measurements.pdf">pdf</a></p><p>Author: Yi-kai Liu</p><p>Abstract: We study the problem of reconstructing an unknown matrix M of rank r and dimension d using O(rd poly log d) Pauli measurements. This has applications in quantum state tomography, and is a non-commutative analogue of a well-known problem in compressed sensing: recovering a sparse vector from a few of its Fourier coefﬁcients. We show that almost all sets of O(rd log6 d) Pauli measurements satisfy the rankr restricted isometry property (RIP). This implies that M can be recovered from a ﬁxed (“universal”) set of Pauli measurements, using nuclear-norm minimization (e.g., the matrix Lasso), with nearly-optimal bounds on the error. A similar result holds for any class of measurements that use an orthonormal operator basis whose elements have small operator norm. Our proof uses Dudley’s inequality for Gaussian processes, together with bounds on covering numbers obtained via entropy duality. 1</p><br/>
<h2>reference text</h2><p>[1] M. Fazel. Matrix Rank Minimization with Applications. PhD thesis, Stanford, 2002.</p>
<p>[2] N. Srebro. Learning with Matrix Factorizations. PhD thesis, MIT, 2004.</p>
<p>[3] B. Recht, M. Fazel, and P. A. Parrilo. Guaranteed minimum rank solutions to linear matrix equations via nuclear norm minimization. SIAM Review, 52(3):471–501, 2010.</p>
<p>[4] M. Fazel, E. Candes, B. Recht, and P. Parrilo. Compressed sensing and robust recovery of low rank matrices. In 42nd Asilomar Conference on Signals, Systems and Computers, pages 1043–1047, 2008.</p>
<p>[5] E. J. Candes and Y. Plan. Tight oracle bounds for low-rank matrix recovery from a minimal number of random measurements. 2009.</p>
<p>[6] E. J. Candes and B. Recht. Exact matrix completion via convex optimization. Found. of Comput. Math., 9:717–772.</p>
<p>[7] E. J. Candes and T. Tao. The power of convex relaxation: Near-optimal matrix completion. IEEE Trans. Inform. Theory, 56(5):2053–2080, 2009.</p>
<p>[8] D. Gross. Recovering low-rank matrices from few coefﬁcients in any basis. IEEE Trans. Inform. Theory, to appear. arXiv:0910.1879, 2010.</p>
<p>[9] B. Recht. A simpler approach to matrix completion. J. Machine Learning Research (to appear), 2010.</p>
<p>[10] S. Negahban and M. J. Wainwright. Restricted strong convexity and weighted matrix completion: Optimal bounds with noise. arXiv:1009.2118, 2010.</p>
<p>[11] E. J. Candes and T. Tao. Near-optimal signal recovery from random projections: universal encoding strategies. IEEE Trans. Inform. Theory, 52:5406–5425, 2004.</p>
<p>[12] M. Rudelson and R. Vershynin. On sparse reconstruction from Fourier and Gaussian measurements. Commun. Pure and Applied Math., 61:1025–1045, 2008.</p>
<p>[13] D. Gross, Y.-K. Liu, S. T. Flammia, S. Becker, and J. Eisert. Quantum state tomography via compressed sensing. Phys. Rev. Lett., 105(15):150401, Oct 2010. arXiv:0909.3304.</p>
<p>[14] E. J. Candes and Y. Plan. Matrix completion with noise. Proc. IEEE, 98(6):925 – 936, 2010.</p>
<p>[15] B. Brown, S. Flammia, D. Gross, and Y.-K. Liu. in preparation, 2011.</p>
<p>[16] O. Gu´ don, S. Mendelson, A. Pajor, and N. Tomczak-Jaegermann. Majorizing measures and e proportional subsets of bounded orthonormal systems. Rev. Mat. Iberoamericana, 24(3):1075– 1095, 2008.</p>
<p>[17] G. Aubrun. On almost randomizing channels with a short Kraus decomposition. Commun. Math. Phys., 288:1103–1116, 2009.</p>
<p>[18] M. A. Nielsen and I. Chuang. Quantum Computation and Quantum Information. Cambridge University Press, 2001.</p>
<p>[19] A. Rohde and A. Tsybakov. Estimation of high-dimensional low-rank matrices. arXiv:0912.5338, 2009.</p>
<p>[20] V. Koltchinskii, K. Lounici, and A. B. Tsybakov. Nuclear norm penalization and optimal rates for noisy low rank matrix completion. arXiv:1011.6256, 2010.</p>
<p>[21] Y.-K. Liu. Universal low-rank matrix recovery from Pauli measurements. arXiv:1103.2816, 2011.</p>
<p>[22] M. Ledoux and M. Talagrand. Probability in Banach spaces. Springer, 1991.</p>
<p>[23] G. Pisier. The volume of convex bodies and Banach space geometry. Cambridge, 1999.</p>
<p>[24] F. Krahmer and R. Ward. New and improved Johnson-Lindenstrauss embeddings via the restricted isometry property. SIAM J. Math. Anal., 43(3):1269–1281, 2011.</p>
<p>[25] A. Shabani, R. L. Kosut, M. Mohseni, H. Rabitz, M. A. Broome, M. P. Almeida, A. Fedrizzi, and A. G. White. Efﬁcient measurement of quantum dynamics via compressive sensing. Phys. Rev. Lett., 106(10):100401, 2011.</p>
<p>[26] P. Wojtaszczyk. Stability and instance optimality for gaussian measurements in compressed sensing. Found. Comput. Math., 10(1):1–13, 2009.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
