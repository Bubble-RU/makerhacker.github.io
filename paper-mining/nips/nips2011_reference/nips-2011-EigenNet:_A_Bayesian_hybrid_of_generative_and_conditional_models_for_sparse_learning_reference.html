<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>84 nips-2011-EigenNet: A Bayesian hybrid of generative and conditional models for sparse learning</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-84" href="../nips2011/nips-2011-EigenNet%3A_A_Bayesian_hybrid_of_generative_and_conditional_models_for_sparse_learning.html">nips2011-84</a> <a title="nips-2011-84-reference" href="#">nips2011-84-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>84 nips-2011-EigenNet: A Bayesian hybrid of generative and conditional models for sparse learning</h1>
<br/><p>Source: <a title="nips-2011-84-pdf" href="http://papers.nips.cc/paper/4378-eigennet-a-bayesian-hybrid-of-generative-and-conditional-models-for-sparse-learning.pdf">pdf</a></p><p>Author: Feng Yan, Yuan Qi</p><p>Abstract: For many real-world applications, we often need to select correlated variables— such as genetic variations and imaging features associated with Alzheimer’s disease—in a high dimensional space. The correlation between variables presents a challenge to classical variable selection methods. To address this challenge, the elastic net has been developed and successfully applied to many applications. Despite its great success, the elastic net does not exploit the correlation information embedded in the data to select correlated variables. To overcome this limitation, we present a novel hybrid model, EigenNet, that uses the eigenstructures of data to guide variable selection. Speciﬁcally, it integrates a sparse conditional classiﬁcation model with a generative model capturing variable correlations in a principled Bayesian framework. We develop an efﬁcient active-set algorithm to estimate the model via evidence maximization. Experimental results on synthetic data and imaging genetics data demonstrate the superior predictive performance of the EigenNet over the lasso, the elastic net, and the automatic relevance determination. 1</p><br/>
<h2>reference text</h2><p>Robert Tibshirani. Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society, Series B, 58:267–288, 1994. Hui Zou and Trevor Hastie. Regularization and variable selection via the Elastic Net. Journal of the Royal Statistical Society B, 67:301–320, 2005. Julia A. Lasserre, Christopher M. Bishop, and Thomas P. Minka. Principled hybrids of generative and discriminative models. In Proc. of IEEE Conference on Computer Vision and Pattern Recognition, pages 87–94, 2006. David J.C. MacKay. Bayesian interpolation. Neural Computation, 4:415–447, 1991. Ildiko E. Frank and Jerome H. Friedman. A statistical view of some chemometrics regression tools. Technometrics, 35(2):109–135, 1993. Jianqing Fan and Runze Li. Variable selection via nonconcave penalized likelihood and its oracle properties. Journal of the American Statistical Association, 96(456):1348–1360, 2001. Thomas P. Minka. Expectation propagation for approximate Bayesian inference. In Proceedings of the 17th Conference in Uncertainty in Artiﬁcial Intelligence, pages 362–369, 2001. Michael E. Tipping and Anita C. Faul. Fast marginal likelihood maximisation for sparse Bayesian models. In Proceedings of the Ninth International Workshop on Artiﬁcial Intelligence and Statistics, 2003. Matthew Turk and Alex Pentland. Eigenfaces for recognition. J. Cognitive Neuroscience, 3:71–86, 1991. L. Sirovich and M. Kirby. Low-dimensional procedure for the characterization of human faces. J. Opt. Soc. Am. A, 4(3):519–524, 1987. Park, Trevor, Casella, and George. The Bayesian Lasso. Journal of the American Statistical Association, 103(482):681–686, 2008. Qing Li and Nan Lin. The Bayesian Elastic Net. Bayesian Analysis, 5(1):151–170, 2010. Laurent Jacob, Guillaume Obozinski, and Jean-Philippe Vert. Group lasso with overlap and graph lasso. In Proceedings of the 26th Annual International Conference on Machine Learning, 2009. Yuan Qi, Thomas P. Minka, Rosalind W. Picard, and Zoubin Ghahraman. Predictive automatic relevance determination by expectation propagation. In Proceedings of Twenty-ﬁrst International Conference on Machine Learning, pages 671–678, 2004. Dominic Holland, James B Brewer, Donald J Hagler, Christine Fenema-Notestine, and Anders M Dale. Subregional neuroanatomical change as a biomarker for alzheimer’s disease. Proceedings of the National Academy of Sciences, 106(49):20954–20959, 2009. Yue Guan and Jennifer Dy. Sparse probabilistic principal component analysis. JMLR W&CP;: AISTATS, 5, 2009. C´ dric Archambeau and Francis Bach. Sparse probabilistic projections. In Advances in Neural e Information Processing Systems 21. 2009.  9</p>
<br/>
<br/><br/><br/></body>
</html>
