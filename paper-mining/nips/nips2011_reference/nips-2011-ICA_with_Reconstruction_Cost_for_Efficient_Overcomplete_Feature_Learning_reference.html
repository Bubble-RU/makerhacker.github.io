<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>124 nips-2011-ICA with Reconstruction Cost for Efficient Overcomplete Feature Learning</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-124" href="../nips2011/nips-2011-ICA_with_Reconstruction_Cost_for_Efficient_Overcomplete_Feature_Learning.html">nips2011-124</a> <a title="nips-2011-124-reference" href="#">nips2011-124-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>124 nips-2011-ICA with Reconstruction Cost for Efficient Overcomplete Feature Learning</h1>
<br/><p>Source: <a title="nips-2011-124-pdf" href="http://papers.nips.cc/paper/4467-ica-with-reconstruction-cost-for-efficient-overcomplete-feature-learning.pdf">pdf</a></p><p>Author: Quoc V. Le, Alexandre Karpenko, Jiquan Ngiam, Andrew Y. Ng</p><p>Abstract: Independent Components Analysis (ICA) and its variants have been successfully used for unsupervised feature learning. However, standard ICA requires an orthonoramlity constraint to be enforced, which makes it difﬁcult to learn overcomplete features. In addition, ICA is sensitive to whitening. These properties make it challenging to scale ICA to high dimensional data. In this paper, we propose a robust soft reconstruction cost for ICA that allows us to learn highly overcomplete sparse features even on unwhitened data. Our formulation reveals formal connections between ICA and sparse autoencoders, which have previously been observed only empirically. Our algorithm can be used in conjunction with off-the-shelf fast unconstrained optimizers. We show that the soft reconstruction cost can also be used to prevent replicated features in tiled convolutional neural networks. Using our method to learn highly overcomplete sparse features and tiled convolutional neural networks, we obtain competitive performances on a wide variety of object recognition tasks. We achieve state-of-the-art test accuracies on the STL-10 and Hollywood2 datasets. 1</p><br/>
<h2>reference text</h2><p>[1] M.A. Ranzato, C. Poultney, S. Chopra, and Y. LeCun. Efﬁcient learning of sparse representations with an energy-based model. In NIPS, 2006.</p>
<p>[2] R. Raina, A. Battle, H. Lee, B. Packer, and A.Y. Ng. Self-taught learning: Transfer learning from unlabelled data. In ICML, 2007.</p>
<p>[3] M. Ranzato, F. J. Huang, Y. Boureau, and Y. LeCun. Unsupervised learning of invariant feature hierarchies with applications to object recognition. In CVPR, 2007.</p>
<p>[4] J. Yang, K. Yu, Y. Gong, and T. Huang. Linear spatial pyramid matching using sparse coding for image classiﬁcation. In CVPR, 2009.</p>
<p>[5] J. Yang, K. Yu, and T. Huang. Efﬁcient highly over-complete sparse coding using a mixture model. In ECCV, 2010.</p>
<p>[6] A. Coates, H. Lee, and A. Y. Ng. An analysis of single-layer networks in unsupervised feature learning. In AISTATS 14, 2011.</p>
<p>[7] K. Yu, Y. Lin, and J. Lafferty. Learning image representations from pixel level via hierarchical sparse coding. In CVPR, 2011.</p>
<p>[8] Y. Bengio, P. Lamblin, D. Popovici, and H. Larochelle. Greedy layerwise training of deep networks. In NIPS, 2007.</p>
<p>[9] G. E. Hinton, S. Osindero, and Y. W. Teh. A fast learning algorithm for deep belief nets. Neural Computation, 2006.</p>
<p>[10] B. Olshausen and D. Field. Emergence of simple-cell receptive ﬁeld properties by learning a sparse code for natural images. Nature, 1996.</p>
<p>[11] A. Hyv¨ rinen, J. Karhunen, and E. Oja. Independent Component Analysis. Wiley Interscience, 2001. a</p>
<p>[12] Q. V. Le, J. Ngiam, Z. Chen, D. Chia, P. W. Koh, and A. Y. Ng. Tiled convolutional neural networks. In NIPS, 2010.</p>
<p>[13] Q. V. Le, W. Zou, S. Y. Yeung, and A. Y. Ng. Learning hierarchical spatio-temporal features for action recognition with independent subspace analysis. In CVPR, 2011.</p>
<p>[14] Q. V. Le, J. Ngiam, A. Coates, A. Lahiri, B. Prochnow, and A. Y. Ng. On optimization methods for deep learning. In ICML, 2011.</p>
<p>[15] M. Marzalek, I. Laptev, and C. Schmid. Actions in context. In CVPR, 2009.</p>
<p>[16] A. Hyv¨ rinen, J. Hurri, and P. O. Hoyer. Natural Image Statistics. Springer, 2009. a</p>
<p>[17] B. Olshausen and D. Field. Sparse coding with an overcomplete basis set: A strategy employed by v1. Vision Research, 1997.</p>
<p>[18] M. S. Lewicki and T. J. Sejnowski. Learning overcomplete representations. Neural Computation, 2000.</p>
<p>[19] L. Ma and L. Zhang. Overcomplete topographic independent component analysis. Elsevier, 2008.</p>
<p>[20] M. Schmidt. minFunc, 2005.</p>
<p>[21] P. Vincent, H. Larochelle, Y. Bengio, and P. A. Manzagol. Extracting and composing robust features with denoising autoencoders. In ICML, 2008.</p>
<p>[22] H. Lee, C. Ekanadham, and A. Y. Ng. Sparse deep belief net model for visual area V2. In NIPS, 2008.</p>
<p>[23] H. Larochelle, Y. Bengio, J. Louradour, and P. Lamblin. Exploring strategies for training deep neural networks. JMLR, 2009.</p>
<p>[24] G. Hinton. A practical guide to training restricted boltzmann machines. Technical report, U. of Toronto, 2010.</p>
<p>[25] P. Vincent. A connection between score matching and denoising autoencoders. Neural Computation, 2010.</p>
<p>[26] A. Hyv¨ rinen. Estimation of non-normalized statistical models using score matching. JMLR, 2005. a</p>
<p>[27] Y. Karklin and M.S. Lewicki. Is early vision optimized for extracting higher-order dependencies? In NIPS, 2006.</p>
<p>[28] C. Schuldt, I. Laptev, and B. Caputo. Recognizing human actions: A local SVM approach. In ICPR, 2004.</p>
<p>[29] J. Liu, J. Luo, and M. Shah. Recognizing realistic actions from videos “in the Wild”. In CVPR, 2009.</p>
<p>[30] Heng Wang, Muhammad Muneeb Ullah, Alexander Klaser, Ivan Laptev, and Cordelia Schmid. Evaluation of local spatio-temporal features for action recognition. In BMVC, 2010.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
