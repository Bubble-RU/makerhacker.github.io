<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>126 nips-2007-McRank: Learning to Rank Using Multiple Classification and Gradient Boosting</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-126" href="#">nips2007-126</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>126 nips-2007-McRank: Learning to Rank Using Multiple Classification and Gradient Boosting</h1>
<br/><p>Source: <a title="nips-2007-126-pdf" href="http://papers.nips.cc/paper/3270-mcrank-learning-to-rank-using-multiple-classification-and-gradient-boosting.pdf">pdf</a></p><p>Author: Ping Li, Qiang Wu, Christopher J. Burges</p><p>Abstract: We cast the ranking problem as (1) multiple classiﬁcation (“Mc”) (2) multiple ordinal classiﬁcation, which lead to computationally tractable learning algorithms for relevance ranking in Web search. We consider the DCG criterion (discounted cumulative gain), a standard quality measure in information retrieval. Our approach is motivated by the fact that perfect classiﬁcations result in perfect DCG scores and the DCG errors are bounded by classiﬁcation errors. We propose using the Expected Relevance to convert class probabilities into ranking scores. The class probabilities are learned using a gradient boosting tree algorithm. Evaluations on large-scale datasets show that our approach can improve LambdaRank [5] and the regressions-based ranker [6], in terms of the (normalized) DCG scores. An efﬁcient implementation of the boosting tree algorithm is also presented.</p><p>Reference: <a title="nips-2007-126-reference" href="../nips2007_reference/nips-2007-McRank%3A_Learning_to_Rank_Using_Multiple_Classification_and_Gradient_Boosting_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 com  Abstract We cast the ranking problem as (1) multiple classiﬁcation (“Mc”) (2) multiple ordinal classiﬁcation, which lead to computationally tractable learning algorithms for relevance ranking in Web search. [sent-7, score-1.048]
</p><p>2 Our approach is motivated by the fact that perfect classiﬁcations result in perfect DCG scores and the DCG errors are bounded by classiﬁcation errors. [sent-9, score-0.284]
</p><p>3 We propose using the Expected Relevance to convert class probabilities into ranking scores. [sent-10, score-0.38]
</p><p>4 The class probabilities are learned using a gradient boosting tree algorithm. [sent-11, score-0.319]
</p><p>5 Evaluations on large-scale datasets show that our approach can improve LambdaRank [5] and the regressions-based ranker [6], in terms of the (normalized) DCG scores. [sent-12, score-0.163]
</p><p>6 An efﬁcient implementation of the boosting tree algorithm is also presented. [sent-13, score-0.29]
</p><p>7 1 Introduction The general ranking problem has widespread applications including commercial search engines and recommender systems. [sent-14, score-0.388]
</p><p>8 We develop McRank, a computationally tractable learning algorithm for the general ranking problem; and we present our approach in the context of ranking in Web search. [sent-15, score-0.566]
</p><p>9 For a given user input query, a commercial search engine returns many pages of URLs, in an order determined by the underlying proprietary ranking algorithm. [sent-16, score-0.392]
</p><p>10 The type of ranking problem in this study is sometimes referred to as dynamic ranking (or simply, just ranking), because the URLs are dynamically ranked (in real-time) according to the speciﬁc user input query. [sent-18, score-0.603]
</p><p>11 This is different from the query-independent static ranking based on, for example, “page rank” [3] or “authorities and hubs” [12], which may, at least conceptually, serve as an important “feature” for dynamic ranking or to guide the generation of a list of URLs fed to the dynamic ranker. [sent-19, score-0.566]
</p><p>12 [6] considered the DCG measure (discounted cumulative gain) [10] and showed that the DCG errors are bounded by regression errors. [sent-25, score-0.141]
</p><p>13 From the deﬁnition of DCG, it appears more direct to cast the ranking problem as multiple classiﬁcation (“Mc”) as opposed to regression. [sent-27, score-0.367]
</p><p>14 In order to convert classiﬁcation results into ranking scores, we propose a simple and stable mechanism by using the Expected Relevance. [sent-28, score-0.323]
</p><p>15 Our evaluations on large-scale datasets demonstrate the superiority of the classiﬁcation-based ranker (McRank) over both the regression-based and pair-based schemes. [sent-29, score-0.186]
</p><p>16 2 Discounted Cumulative Gain (DCG) For an input query, the ranker returns n ordered URLs. [sent-30, score-0.121]
</p><p>17 Suppose the URLs fed to the ranker are originally ordered {1, 2, 3, . [sent-31, score-0.121]
</p><p>18 The ranker will output a permutation mapping π : {1, 2, 3, . [sent-35, score-0.15]
</p><p>19 The DCG score is computed from the relevance levels of the n URLs as n  n  DCG = i=1 ∗ 1  c[i] (2yσi − 1) =  i=1  c[πi ] (2yi − 1) ,  (1)  Much of the work was conducted while Ping Li was an intern at Microsoft in 2006. [sent-43, score-0.192]
</p><p>20 where [i] is the rank order, and yi ∈ {0, 1, 2, 3, 4} is the relevance level of the ith URL in the original (pre-ranked) order. [sent-45, score-0.346]
</p><p>21 yi = 4 corresponds to a “perfect” relevance and yi = 0 corresponds to a “poor” relevance. [sent-46, score-0.336]
</p><p>22 It is a common practice to normalize the DCG score for each query and report the normalized DCG (“NDCG”) score averaged over all queries. [sent-51, score-0.142]
</p><p>23 In other words, the NDCG for the jth query (NDCGj ) and the ﬁnal NDCG of the dataset (NDCGF ) are NDCGj =  DCGj , DCGj,g  NDCGF =  1 NQ  NQ  NDCGj ,  (3)  j=1  where DCGj,g is the maximum possible (or “gold standard”) DCG score of the jth query. [sent-52, score-0.21]
</p><p>24 3 Learning to Rank Using Classiﬁcation The deﬁnition of DCG suggests that we can cast the ranking problem naturally as multiple classiﬁcation (i. [sent-53, score-0.367]
</p><p>25 , K = 5 classes), because obviously perfect classiﬁcations will lead to perfect DCG scores. [sent-55, score-0.154]
</p><p>26 We should mention that one does not really need perfect classiﬁcations in order to produce perfect DCG scores. [sent-57, score-0.154]
</p><p>27 , URLs labeled level 4 are classiﬁed as level 3, and so on), we still have the perfect DCG score but the classiﬁcation “error” is 100%. [sent-61, score-0.207]
</p><p>28 This phenomenon to an extent, may provide some “safety cushion” for casting ranking as classiﬁcation. [sent-62, score-0.283]
</p><p>29 [6] cast ranking as regression and showed that the DCG errors are bounded by regression errors. [sent-63, score-0.514]
</p><p>30 For example, it is well-known that, although one can use regression for classiﬁcation, it is often better to use logistic regression especially for multiple classiﬁcation [8]. [sent-65, score-0.21]
</p><p>31 One simple way to obtain the perfect DCGg is to rank the URLs directly according to the gold-standard relevance levels. [sent-69, score-0.245]
</p><p>32 That is, all URLs with relevance level k + 1 are ranked higher than those with relevance level ≤ k; and the URLs with the same relevance levels are arbitrarily ranked without affecting DCGg . [sent-70, score-0.616]
</p><p>33 Suppose a classiﬁer assigns a relevance level yi ∈ {0, 1, 2, 3, 4} to the ith URL, for all n URLs. [sent-76, score-0.304]
</p><p>34 A permutation mapping π ranks the ˆ URLs according to yi , i. [sent-77, score-0.134]
</p><p>35 , π(i) < π(j) if yi > yj , and, URL i and URL j are arbitrarily ranked if ˆ ˆ ˆ yi = yj . [sent-79, score-0.247]
</p><p>36 The jth query corresponds to nj URLs; each URL is manually labeled by one of the K = 5 relevance levels. [sent-88, score-0.233]
</p><p>37 Both pair-based rankers and regression-based rankers implicitly made this assumption, as they tried to learn a single rank function for all queries using the same set of features. [sent-92, score-0.244]
</p><p>38 Here xi ∈ RP is the ith feature vector i=1 in P dimensions; and yi ∈ {0, 1, 2, 3, 4 = K − 1} is the class (relevance) label of the ith data point. [sent-97, score-0.202]
</p><p>39 3 From Classiﬁcation to Ranking Although perfect classiﬁcations lead to perfect DCG scores, in reality, we will need a mechanism to convert (imperfect) classiﬁcation results into ranking scores. [sent-99, score-0.477]
</p><p>40 This suggestion, however, will lead to highly unstable ranking results. [sent-102, score-0.283]
</p><p>41 Recall we assume a training dataset {yi , xi }N , where the class label yi ∈ {0, 1, 2, 3, 4 = K − 1}. [sent-105, score-0.178]
</p><p>42 i=1 We learn the class probabilities pi,k = Pr(yi = k), denoted by pi,k , and deﬁne a scoring function: ˆ K−1  Si =  pi,k T (k), ˆ  (5)  k=0  where T (k) is some monotone (increasing) function of the relevance level k. [sent-106, score-0.264]
</p><p>43 Once we have computed the scores Si for all data points, we can then sort the data points within each query by the descending order of Si . [sent-107, score-0.207]
</p><p>44 Consequently, the ranking results are not affected by any afﬁne transformation on T (k), aT (k) + b, (a > 0), because K−1  k=0  K−1  pi,k (a × T (k) + b) = a ×  K−1  pi,k T (k) k=0  + b,  pi,k = 1. [sent-115, score-0.305]
</p><p>45 (7)  Algorithm 1 implements a boosting tree algorithm for learning class probabilities pi,k ; and we use basically the same implementation later for regression as well as multiple ordinal classiﬁcation. [sent-120, score-0.723]
</p><p>46 Algorithm 1 The boosting tree algorithm for multiple classiﬁcation, taken from [9, Algorithm 6], although the presentation is slightly different. [sent-121, score-0.308]
</p><p>47 M is the total number of boosting iterations, J is the tree size (number of terminal nodes), and ν is the shrinkage coefﬁcient. [sent-124, score-0.327]
</p><p>48 4 Multiple Ordinal Classiﬁcation to Further Improve Ranking There is the possibility to (slightly) further improve our classiﬁcation-based ranking scheme by taking into account the natural orders among the class labels, i. [sent-130, score-0.34]
</p><p>49 A common approach for multiple ordinal classiﬁcation is to learn the cumulative probabilities Pr (yi ≤ k) instead of the class probabilities Pr (yi = k) = pi,k . [sent-133, score-0.391]
</p><p>50 Now we have a binary classiﬁcation problem and hence we can use exactly the same boosting tree algorithm for multiple classiﬁcation. [sent-138, score-0.308]
</p><p>51 We then infer the class probabilities pi,k = Pr (yi = k) = Pr (yi ≤ k) − Pr (yi ≤ k − 1) ,  (8)  and again we use the Expected Relevance to compute the ranking scores and sort the URLs. [sent-141, score-0.465]
</p><p>52 We call both rankers based on multiple classiﬁcation and multiple ordinal classiﬁcation as McRank. [sent-142, score-0.391]
</p><p>53 5 Regression-based Ranking Using Boosting Tree Algorithm With slight modiﬁcations, the boosting tree algorithm can be used for regressions. [sent-143, score-0.262]
</p><p>54 In fact, we also implemented the LAD boosting tree algorithm but we found the performance was considerably worse than the least-square tree boost. [sent-148, score-0.378]
</p><p>55 Algorithm 2 The boosting tree algorithm for regressions. [sent-149, score-0.262]
</p><p>56 After we have learned the values for Si , we use them directly as the ranking scores to order the data points within each query. [sent-150, score-0.384]
</p><p>57 1 The Datasets The artiﬁcial dataset [5] was meant to remove any variance caused by the quality of features and/or relevance labels. [sent-161, score-0.222]
</p><p>58 The Web search dataset Web-1 [5] has 367 features and 10,000/5,000/10,000 queries for train/validation/test, with in total 652,500 URLs. [sent-163, score-0.179]
</p><p>59 2 The Parameters: M , J, ν There are three main parameters in the boosting tree algorithm. [sent-170, score-0.262]
</p><p>60 The number of terminal nodes, J, should be reasonably big (but not too big) when the dataset is large with a large number of features, because the tree has to be deep enough to consider higher-order interactions [9]. [sent-179, score-0.205]
</p><p>61 With these values of J and ν, we did not observe obvious over-ﬁtting even for a very large number of boosting iterations M . [sent-181, score-0.146]
</p><p>62 3 The Test NDCG Results at Truncation Level L = 10 Table 1 lists the NDCG results (both the mean and standard deviation, in percentages (%)) for all 4 datasets and all 4 ranking algorithms, evaluated at the truncation level L = 10. [sent-184, score-0.56]
</p><p>63 The NDCG scores indicate that that McRank (ordinal classiﬁcation and classiﬁcation) considerably improves the regression-based ranker and LambdaRank. [sent-185, score-0.222]
</p><p>64 If we conduct a one-sided t-test, the im-  Table 1: The test NDCG scores produced by 4 rankers on 4 datasets. [sent-186, score-0.174]
</p><p>65 The average NDCG scores are presented in percentages (%) with the standard deviations in the parentheses. [sent-187, score-0.124]
</p><p>66 For the artiﬁcial data, Web-1, and Web-3, we use the ordinal classiﬁcation results to compute the p-values. [sent-190, score-0.226]
</p><p>67 However, for Web-2, because our implementation for testing ordinal classiﬁcation required too much memory for M = 2000, we did not obtain the ﬁnal test NDCG scores; the partial results indicated that ordinal classiﬁcation did not improve classiﬁcation for this dataset. [sent-191, score-0.48]
</p><p>68 However, multiple ordinal classiﬁcation did not show signiﬁcant improvement over multiple classiﬁcation, except for the artiﬁcial dataset. [sent-230, score-0.318]
</p><p>69 This is probably due to the fact that the artiﬁcial data are generated noise-free and hence the ﬂexible (with high capacity) rankers using boosting tree algorithms tend to ﬁt the data very well. [sent-232, score-0.335]
</p><p>70 4 The NDCG Results at Various Truncation Levels (L = 1 to 10) For the artiﬁcial dataset and Web-1, [5] also reported the NDCG scores at various truncation levels, L = 1 to 10. [sent-234, score-0.334]
</p><p>71 Figure 1 veriﬁes that the improvements shown in Table 1 are not only true for L = 10 but also (essentially) true for smaller truncation levels. [sent-237, score-0.162]
</p><p>72 7 Conclusion The ranking problem has become an important topic in machine learning, partly due to its widespread applications in many decision-making processes especially in commercial search engines. [sent-241, score-0.361]
</p><p>73 In one aspect, the ranking problem is difﬁcult because the measures of rank quality are usually based on sorting, which is not directly optimizable (at least not efﬁciently). [sent-242, score-0.349]
</p><p>74 On the other hand, one can cast ranking into various classical learning tasks such as regression and classiﬁcation. [sent-243, score-0.403]
</p><p>75 The proposed classiﬁcation-based ranking scheme is motivated by the fact that perfect classiﬁcations lead to perfect DCG scores and the DCG errors are bounded by the classiﬁcation errors. [sent-244, score-0.599]
</p><p>76 It appears  natural that the classiﬁcation-based ranker is more direct and should work better than the regressionbased ranker suggested in [6]. [sent-245, score-0.242]
</p><p>77 To learn the class probabilities, we implement a boosting tree algorithm for multiple classiﬁcation and we use the same implementation for multiple ordinal classiﬁcation and regression. [sent-247, score-0.633]
</p><p>78 Since commercial proprietary datasets are usually very large, an adaptive quantization-based approach efﬁciently implements the boosting tree algorithm, which avoids sorting and has lower memory cost. [sent-248, score-0.439]
</p><p>79 Our experimental results have demonstrated that McRank (including multiple classiﬁcation and multiple ordinal classiﬁcation) outperforms both the regression-based ranker and the pair-based LambdaRank. [sent-249, score-0.439]
</p><p>80 However, except for the artiﬁcial dataset, we did not observe signiﬁcant improvement of ordinal classiﬁcation over classiﬁcation. [sent-250, score-0.226]
</p><p>81 In a summary, we regard McRank algorithm (retrospectively) simple, robust, and capable of producing quality ranking results. [sent-251, score-0.307]
</p><p>82 Appendix I  An Efﬁcient Implementation for Building Boosting Trees  We use the standard regression tree algorithm [2], which recursively splits the training data points into two groups on the current “best” feature that will reduce the mean square errors (MSE) the most. [sent-252, score-0.253]
</p><p>83 We suggest a simpler and more efﬁcient approach, by taking advantage of some properties of the boosting tree algorithm. [sent-255, score-0.262]
</p><p>84 While the boosting tree algorithm is well-known to be robust and also accurate, an individual tree has limited predictive power and usually can be built quite crudely. [sent-256, score-0.378]
</p><p>85 In Figure 2(b), we bin (quantize) the data points into two (0/1) levels on the horizontal (i. [sent-260, score-0.152]
</p><p>86 Panel (b) suggests that, if we bin the data on the x axis to be binary, the reduced MSE will not be affected either, if the data are binned in the way as in (b). [sent-266, score-0.161]
</p><p>87 Of course, we would not know ahead of time how to bin the data to avoid losing accuracy. [sent-268, score-0.116]
</p><p>88 In the pre-processing stage, for each feature, the training data points are sorted according to the feature value; and we bin the feature values in the sorted order. [sent-270, score-0.218]
</p><p>89 We start with a very small initial bin length, e. [sent-271, score-0.116]
</p><p>90 As shown in Figure 2(c), we only bin the data where there are indeed data, because the boosting tree algorithm will not consider the area where there are no data anyway. [sent-274, score-0.378]
</p><p>91 If the bin length is so small that we need more than B bins, we simply increment the bin length and re-do the quantization. [sent-276, score-0.232]
</p><p>92 After the quantization, we replace the original feature value by the bin labels (0, 1, 2, . [sent-277, score-0.142]
</p><p>93 Note that since we start with a small bin length, the ordinal categorical features are naturally taken care of. [sent-281, score-0.366]
</p><p>94 This simple binning scheme is very effective particularly for the boosting tree algorithm:  • It simpliﬁes the implementation. [sent-282, score-0.294]
</p><p>95 Appendix II  Some More Experiments on Web-1  Figure 3 (a)(b) present the experiment with our adaptive quantization scheme on Web-1 dataset. [sent-290, score-0.12]
</p><p>96 We binned the data with the maximum bin number B = 23 , 24 , 25 , 26 , 27 , 28 , and 216 . [sent-291, score-0.139]
</p><p>97 Panel (a) plots the relative number of total bins in Web-1 as a function of the exponent, normalized by the total number of bins at B = 216 . [sent-293, score-0.144]
</p><p>98 When B = 28 , the total number of bins is only about 6% of that when B = 216 ; however, both quantization levels achieved the same test NDCG scores. [sent-295, score-0.196]
</p><p>99 Figure 3 (c) compares two scoring functions to convert learned class probabilities into rankK−1 ing scores, including the Expected Relevance Si = ˆ k=0 pi,k k and the Expected Gain Si = K−1 k ˆ k=0 pi,k 2 − 1 . [sent-300, score-0.128]
</p><p>100 A regression framework for learning ranking functions using relative relevance judgments. [sent-383, score-0.491]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ndcg', 0.442), ('dcg', 0.365), ('urls', 0.323), ('ranking', 0.283), ('lambdarank', 0.277), ('ordinal', 0.226), ('truncation', 0.162), ('boosting', 0.146), ('classi', 0.145), ('relevance', 0.126), ('ranker', 0.121), ('bin', 0.116), ('tree', 0.116), ('mcrank', 0.108), ('yi', 0.105), ('scores', 0.101), ('dcgg', 0.092), ('quantization', 0.088), ('regression', 0.082), ('query', 0.082), ('ranknet', 0.08), ('url', 0.08), ('classification', 0.078), ('perfect', 0.077), ('rankers', 0.073), ('gi', 0.07), ('nq', 0.067), ('si', 0.067), ('cation', 0.063), ('web', 0.06), ('mse', 0.057), ('pr', 0.056), ('queries', 0.056), ('commercial', 0.051), ('level', 0.05), ('dataset', 0.048), ('bins', 0.048), ('ndcgj', 0.046), ('multiple', 0.046), ('std', 0.043), ('datasets', 0.042), ('rank', 0.042), ('frank', 0.041), ('terminal', 0.041), ('convert', 0.04), ('cations', 0.038), ('cast', 0.038), ('arti', 0.037), ('microsoft', 0.037), ('ranked', 0.037), ('exponent', 0.036), ('cial', 0.036), ('levels', 0.036), ('panel', 0.036), ('burges', 0.034), ('probabilities', 0.032), ('scheme', 0.032), ('scoring', 0.031), ('lad', 0.031), ('ndcgf', 0.031), ('proprietary', 0.031), ('sl', 0.031), ('sorting', 0.031), ('appendix', 0.03), ('score', 0.03), ('cumulative', 0.03), ('surrogate', 0.029), ('errors', 0.029), ('permutation', 0.029), ('affecting', 0.028), ('gain', 0.028), ('loss', 0.028), ('implementation', 0.028), ('search', 0.027), ('engines', 0.027), ('sigir', 0.027), ('ranksvm', 0.027), ('feature', 0.026), ('class', 0.025), ('split', 0.025), ('jth', 0.025), ('sorted', 0.025), ('splitting', 0.025), ('ping', 0.024), ('convincing', 0.024), ('corporation', 0.024), ('sr', 0.024), ('total', 0.024), ('features', 0.024), ('sort', 0.024), ('quality', 0.024), ('reported', 0.023), ('evaluations', 0.023), ('rankboost', 0.023), ('binned', 0.023), ('percentages', 0.023), ('ith', 0.023), ('discounted', 0.022), ('affected', 0.022), ('implements', 0.022)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999964 <a title="126-tfidf-1" href="./nips-2007-McRank%3A_Learning_to_Rank_Using_Multiple_Classification_and_Gradient_Boosting.html">126 nips-2007-McRank: Learning to Rank Using Multiple Classification and Gradient Boosting</a></p>
<p>Author: Ping Li, Qiang Wu, Christopher J. Burges</p><p>Abstract: We cast the ranking problem as (1) multiple classiﬁcation (“Mc”) (2) multiple ordinal classiﬁcation, which lead to computationally tractable learning algorithms for relevance ranking in Web search. We consider the DCG criterion (discounted cumulative gain), a standard quality measure in information retrieval. Our approach is motivated by the fact that perfect classiﬁcations result in perfect DCG scores and the DCG errors are bounded by classiﬁcation errors. We propose using the Expected Relevance to convert class probabilities into ranking scores. The class probabilities are learned using a gradient boosting tree algorithm. Evaluations on large-scale datasets show that our approach can improve LambdaRank [5] and the regressions-based ranker [6], in terms of the (normalized) DCG scores. An efﬁcient implementation of the boosting tree algorithm is also presented.</p><p>2 0.31244475 <a title="126-tfidf-2" href="./nips-2007-Evaluating_Search_Engines_by_Modeling_the_Relationship_Between_Relevance_and_Clicks.html">83 nips-2007-Evaluating Search Engines by Modeling the Relationship Between Relevance and Clicks</a></p>
<p>Author: Ben Carterette, Rosie Jones</p><p>Abstract: We propose a model that leverages the millions of clicks received by web search engines to predict document relevance. This allows the comparison of ranking functions when clicks are available but complete relevance judgments are not. After an initial training phase using a set of relevance judgments paired with click data, we show that our model can predict the relevance score of documents that have not been judged. These predictions can be used to evaluate the performance of a search engine, using our novel formalization of the conﬁdence of the standard evaluation metric discounted cumulative gain (DCG), so comparisons can be made across time and datasets. This contrasts with previous methods which can provide only pair-wise relevance judgments between results shown for the same query. When no relevance judgments are available, we can identify the better of two ranked lists up to 82% of the time, and with only two relevance judgments for each query, we can identify the better ranking up to 94% of the time. While our experiments are on sponsored search results, which is the ﬁnancial backbone of web search, our method is general enough to be applicable to algorithmic web search results as well. Furthermore, we give an algorithm to guide the selection of additional documents to judge to improve conﬁdence. 1</p><p>3 0.26395085 <a title="126-tfidf-3" href="./nips-2007-COFI_RANK_-_Maximum_Margin_Matrix_Factorization_for_Collaborative_Ranking.html">41 nips-2007-COFI RANK - Maximum Margin Matrix Factorization for Collaborative Ranking</a></p>
<p>Author: Markus Weimer, Alexandros Karatzoglou, Quoc V. Le, Alex J. Smola</p><p>Abstract: In this paper, we consider collaborative ﬁltering as a ranking problem. We present a method which uses Maximum Margin Matrix Factorization and optimizes ranking instead of rating. We employ structured output prediction to optimize directly for ranking scores. Experimental results show that our method gives very good ranking scores and scales well on collaborative ﬁltering tasks. 1</p><p>4 0.23016717 <a title="126-tfidf-4" href="./nips-2007-A_General_Boosting_Method_and_its_Application_to_Learning_Ranking_Functions_for_Web_Search.html">6 nips-2007-A General Boosting Method and its Application to Learning Ranking Functions for Web Search</a></p>
<p>Author: Zhaohui Zheng, Hongyuan Zha, Tong Zhang, Olivier Chapelle, Keke Chen, Gordon Sun</p><p>Abstract: We present a general boosting method extending functional gradient boosting to optimize complex loss functions that are encountered in many machine learning problems. Our approach is based on optimization of quadratic upper bounds of the loss functions which allows us to present a rigorous convergence analysis of the algorithm. More importantly, this general framework enables us to use a standard regression base learner such as single regression tree for £tting any loss function. We illustrate an application of the proposed method in learning ranking functions for Web search by combining both preference data and labeled data for training. We present experimental results for Web search using data from a commercial search engine that show signi£cant improvements of our proposed methods over some existing methods. 1</p><p>5 0.17670812 <a title="126-tfidf-5" href="./nips-2007-Boosting_the_Area_under_the_ROC_Curve.html">39 nips-2007-Boosting the Area under the ROC Curve</a></p>
<p>Author: Phil Long, Rocco Servedio</p><p>Abstract: We show that any weak ranker that can achieve an area under the ROC curve slightly better than 1/2 (which can be achieved by random guessing) can be efﬁciently boosted to achieve an area under the ROC curve arbitrarily close to 1. We further show that this boosting can be performed even in the presence of independent misclassiﬁcation noise, given access to a noise-tolerant weak ranker.</p><p>6 0.11619104 <a title="126-tfidf-6" href="./nips-2007-Multi-Task_Learning_via_Conic_Programming.html">134 nips-2007-Multi-Task Learning via Conic Programming</a></p>
<p>7 0.10475378 <a title="126-tfidf-7" href="./nips-2007-Non-parametric_Modeling_of_Partially_Ranked_Data.html">142 nips-2007-Non-parametric Modeling of Partially Ranked Data</a></p>
<p>8 0.10181615 <a title="126-tfidf-8" href="./nips-2007-Regularized_Boost_for_Semi-Supervised_Learning.html">166 nips-2007-Regularized Boost for Semi-Supervised Learning</a></p>
<p>9 0.083449259 <a title="126-tfidf-9" href="./nips-2007-Learning_the_structure_of_manifolds_using_random_projections.html">116 nips-2007-Learning the structure of manifolds using random projections</a></p>
<p>10 0.075973287 <a title="126-tfidf-10" href="./nips-2007-One-Pass_Boosting.html">147 nips-2007-One-Pass Boosting</a></p>
<p>11 0.071576677 <a title="126-tfidf-11" href="./nips-2007-A_Risk_Minimization_Principle_for_a_Class_of_Parzen_Estimators.html">11 nips-2007-A Risk Minimization Principle for a Class of Parzen Estimators</a></p>
<p>12 0.07009659 <a title="126-tfidf-12" href="./nips-2007-On_Ranking_in_Survival_Analysis%3A_Bounds_on_the_Concordance_Index.html">144 nips-2007-On Ranking in Survival Analysis: Bounds on the Concordance Index</a></p>
<p>13 0.064268082 <a title="126-tfidf-13" href="./nips-2007-Optimal_ROC_Curve_for_a_Combination_of_Classifiers.html">149 nips-2007-Optimal ROC Curve for a Combination of Classifiers</a></p>
<p>14 0.064073212 <a title="126-tfidf-14" href="./nips-2007-Efficient_Bayesian_Inference_for_Dynamically_Changing_Graphs.html">75 nips-2007-Efficient Bayesian Inference for Dynamically Changing Graphs</a></p>
<p>15 0.062105056 <a title="126-tfidf-15" href="./nips-2007-Bayesian_Co-Training.html">32 nips-2007-Bayesian Co-Training</a></p>
<p>16 0.059228744 <a title="126-tfidf-16" href="./nips-2007-Random_Features_for_Large-Scale_Kernel_Machines.html">160 nips-2007-Random Features for Large-Scale Kernel Machines</a></p>
<p>17 0.057125341 <a title="126-tfidf-17" href="./nips-2007-Hidden_Common_Cause_Relations_in_Relational_Learning.html">97 nips-2007-Hidden Common Cause Relations in Relational Learning</a></p>
<p>18 0.055314951 <a title="126-tfidf-18" href="./nips-2007-Statistical_Analysis_of_Semi-Supervised_Regression.html">186 nips-2007-Statistical Analysis of Semi-Supervised Regression</a></p>
<p>19 0.055144332 <a title="126-tfidf-19" href="./nips-2007-A_learning_framework_for_nearest_neighbor_search.html">16 nips-2007-A learning framework for nearest neighbor search</a></p>
<p>20 0.052388046 <a title="126-tfidf-20" href="./nips-2007-Discriminative_Batch_Mode_Active_Learning.html">69 nips-2007-Discriminative Batch Mode Active Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2007_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.175), (1, 0.05), (2, -0.131), (3, 0.097), (4, 0.073), (5, 0.122), (6, 0.228), (7, -0.17), (8, 0.21), (9, -0.133), (10, -0.102), (11, 0.072), (12, 0.44), (13, 0.14), (14, 0.044), (15, -0.011), (16, -0.072), (17, 0.019), (18, -0.059), (19, 0.079), (20, -0.052), (21, -0.034), (22, -0.006), (23, 0.023), (24, -0.01), (25, -0.046), (26, 0.032), (27, 0.043), (28, 0.031), (29, -0.0), (30, -0.038), (31, 0.053), (32, 0.071), (33, -0.009), (34, 0.033), (35, -0.028), (36, -0.056), (37, -0.054), (38, -0.028), (39, -0.041), (40, 0.074), (41, 0.091), (42, -0.047), (43, -0.111), (44, 0.099), (45, 0.006), (46, -0.015), (47, 0.042), (48, 0.022), (49, -0.06)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93569446 <a title="126-lsi-1" href="./nips-2007-McRank%3A_Learning_to_Rank_Using_Multiple_Classification_and_Gradient_Boosting.html">126 nips-2007-McRank: Learning to Rank Using Multiple Classification and Gradient Boosting</a></p>
<p>Author: Ping Li, Qiang Wu, Christopher J. Burges</p><p>Abstract: We cast the ranking problem as (1) multiple classiﬁcation (“Mc”) (2) multiple ordinal classiﬁcation, which lead to computationally tractable learning algorithms for relevance ranking in Web search. We consider the DCG criterion (discounted cumulative gain), a standard quality measure in information retrieval. Our approach is motivated by the fact that perfect classiﬁcations result in perfect DCG scores and the DCG errors are bounded by classiﬁcation errors. We propose using the Expected Relevance to convert class probabilities into ranking scores. The class probabilities are learned using a gradient boosting tree algorithm. Evaluations on large-scale datasets show that our approach can improve LambdaRank [5] and the regressions-based ranker [6], in terms of the (normalized) DCG scores. An efﬁcient implementation of the boosting tree algorithm is also presented.</p><p>2 0.88285553 <a title="126-lsi-2" href="./nips-2007-Evaluating_Search_Engines_by_Modeling_the_Relationship_Between_Relevance_and_Clicks.html">83 nips-2007-Evaluating Search Engines by Modeling the Relationship Between Relevance and Clicks</a></p>
<p>Author: Ben Carterette, Rosie Jones</p><p>Abstract: We propose a model that leverages the millions of clicks received by web search engines to predict document relevance. This allows the comparison of ranking functions when clicks are available but complete relevance judgments are not. After an initial training phase using a set of relevance judgments paired with click data, we show that our model can predict the relevance score of documents that have not been judged. These predictions can be used to evaluate the performance of a search engine, using our novel formalization of the conﬁdence of the standard evaluation metric discounted cumulative gain (DCG), so comparisons can be made across time and datasets. This contrasts with previous methods which can provide only pair-wise relevance judgments between results shown for the same query. When no relevance judgments are available, we can identify the better of two ranked lists up to 82% of the time, and with only two relevance judgments for each query, we can identify the better ranking up to 94% of the time. While our experiments are on sponsored search results, which is the ﬁnancial backbone of web search, our method is general enough to be applicable to algorithmic web search results as well. Furthermore, we give an algorithm to guide the selection of additional documents to judge to improve conﬁdence. 1</p><p>3 0.79529279 <a title="126-lsi-3" href="./nips-2007-A_General_Boosting_Method_and_its_Application_to_Learning_Ranking_Functions_for_Web_Search.html">6 nips-2007-A General Boosting Method and its Application to Learning Ranking Functions for Web Search</a></p>
<p>Author: Zhaohui Zheng, Hongyuan Zha, Tong Zhang, Olivier Chapelle, Keke Chen, Gordon Sun</p><p>Abstract: We present a general boosting method extending functional gradient boosting to optimize complex loss functions that are encountered in many machine learning problems. Our approach is based on optimization of quadratic upper bounds of the loss functions which allows us to present a rigorous convergence analysis of the algorithm. More importantly, this general framework enables us to use a standard regression base learner such as single regression tree for £tting any loss function. We illustrate an application of the proposed method in learning ranking functions for Web search by combining both preference data and labeled data for training. We present experimental results for Web search using data from a commercial search engine that show signi£cant improvements of our proposed methods over some existing methods. 1</p><p>4 0.6730895 <a title="126-lsi-4" href="./nips-2007-COFI_RANK_-_Maximum_Margin_Matrix_Factorization_for_Collaborative_Ranking.html">41 nips-2007-COFI RANK - Maximum Margin Matrix Factorization for Collaborative Ranking</a></p>
<p>Author: Markus Weimer, Alexandros Karatzoglou, Quoc V. Le, Alex J. Smola</p><p>Abstract: In this paper, we consider collaborative ﬁltering as a ranking problem. We present a method which uses Maximum Margin Matrix Factorization and optimizes ranking instead of rating. We employ structured output prediction to optimize directly for ranking scores. Experimental results show that our method gives very good ranking scores and scales well on collaborative ﬁltering tasks. 1</p><p>5 0.51572108 <a title="126-lsi-5" href="./nips-2007-Boosting_the_Area_under_the_ROC_Curve.html">39 nips-2007-Boosting the Area under the ROC Curve</a></p>
<p>Author: Phil Long, Rocco Servedio</p><p>Abstract: We show that any weak ranker that can achieve an area under the ROC curve slightly better than 1/2 (which can be achieved by random guessing) can be efﬁciently boosted to achieve an area under the ROC curve arbitrarily close to 1. We further show that this boosting can be performed even in the presence of independent misclassiﬁcation noise, given access to a noise-tolerant weak ranker.</p><p>6 0.42624572 <a title="126-lsi-6" href="./nips-2007-Non-parametric_Modeling_of_Partially_Ranked_Data.html">142 nips-2007-Non-parametric Modeling of Partially Ranked Data</a></p>
<p>7 0.40841809 <a title="126-lsi-7" href="./nips-2007-On_Ranking_in_Survival_Analysis%3A_Bounds_on_the_Concordance_Index.html">144 nips-2007-On Ranking in Survival Analysis: Bounds on the Concordance Index</a></p>
<p>8 0.33388177 <a title="126-lsi-8" href="./nips-2007-Anytime_Induction_of_Cost-sensitive_Trees.html">27 nips-2007-Anytime Induction of Cost-sensitive Trees</a></p>
<p>9 0.32113761 <a title="126-lsi-9" href="./nips-2007-Active_Preference_Learning_with_Discrete_Choice_Data.html">19 nips-2007-Active Preference Learning with Discrete Choice Data</a></p>
<p>10 0.30196628 <a title="126-lsi-10" href="./nips-2007-Regularized_Boost_for_Semi-Supervised_Learning.html">166 nips-2007-Regularized Boost for Semi-Supervised Learning</a></p>
<p>11 0.29655445 <a title="126-lsi-11" href="./nips-2007-Optimal_ROC_Curve_for_a_Combination_of_Classifiers.html">149 nips-2007-Optimal ROC Curve for a Combination of Classifiers</a></p>
<p>12 0.27950224 <a title="126-lsi-12" href="./nips-2007-Multi-Task_Learning_via_Conic_Programming.html">134 nips-2007-Multi-Task Learning via Conic Programming</a></p>
<p>13 0.27140981 <a title="126-lsi-13" href="./nips-2007-Fast_and_Scalable_Training_of_Semi-Supervised_CRFs_with_Application_to_Activity_Recognition.html">88 nips-2007-Fast and Scalable Training of Semi-Supervised CRFs with Application to Activity Recognition</a></p>
<p>14 0.25787032 <a title="126-lsi-14" href="./nips-2007-One-Pass_Boosting.html">147 nips-2007-One-Pass Boosting</a></p>
<p>15 0.25722834 <a title="126-lsi-15" href="./nips-2007-A_learning_framework_for_nearest_neighbor_search.html">16 nips-2007-A learning framework for nearest neighbor search</a></p>
<p>16 0.25634938 <a title="126-lsi-16" href="./nips-2007-Learning_the_structure_of_manifolds_using_random_projections.html">116 nips-2007-Learning the structure of manifolds using random projections</a></p>
<p>17 0.25058237 <a title="126-lsi-17" href="./nips-2007-Classification_via_Minimum_Incremental_Coding_Length_%28MICL%29.html">45 nips-2007-Classification via Minimum Incremental Coding Length (MICL)</a></p>
<p>18 0.24402887 <a title="126-lsi-18" href="./nips-2007-Multiple-Instance_Pruning_For_Learning_Efficient_Cascade_Detectors.html">137 nips-2007-Multiple-Instance Pruning For Learning Efficient Cascade Detectors</a></p>
<p>19 0.24187149 <a title="126-lsi-19" href="./nips-2007-Semi-Supervised_Multitask_Learning.html">175 nips-2007-Semi-Supervised Multitask Learning</a></p>
<p>20 0.23045579 <a title="126-lsi-20" href="./nips-2007-Bayesian_Co-Training.html">32 nips-2007-Bayesian Co-Training</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2007_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.048), (13, 0.024), (16, 0.022), (19, 0.016), (21, 0.081), (34, 0.444), (35, 0.034), (47, 0.082), (83, 0.088), (85, 0.018), (90, 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.83511204 <a title="126-lda-1" href="./nips-2007-A_neural_network_implementing_optimal_state_estimation_based_on_dynamic_spike_train_decoding.html">17 nips-2007-A neural network implementing optimal state estimation based on dynamic spike train decoding</a></p>
<p>Author: Omer Bobrowski, Ron Meir, Shy Shoham, Yonina Eldar</p><p>Abstract: It is becoming increasingly evident that organisms acting in uncertain dynamical environments often employ exact or approximate Bayesian statistical calculations in order to continuously estimate the environmental state, integrate information from multiple sensory modalities, form predictions and choose actions. What is less clear is how these putative computations are implemented by cortical neural networks. An additional level of complexity is introduced because these networks observe the world through spike trains received from primary sensory afferents, rather than directly. A recent line of research has described mechanisms by which such computations can be implemented using a network of neurons whose activity directly represents a probability distribution across the possible “world states”. Much of this work, however, uses various approximations, which severely restrict the domain of applicability of these implementations. Here we make use of rigorous mathematical results from the theory of continuous time point process ﬁltering, and show how optimal real-time state estimation and prediction may be implemented in a general setting using linear neural networks. We demonstrate the applicability of the approach with several examples, and relate the required network properties to the statistical nature of the environment, thereby quantifying the compatibility of a given network with its environment. 1</p><p>same-paper 2 0.80645007 <a title="126-lda-2" href="./nips-2007-McRank%3A_Learning_to_Rank_Using_Multiple_Classification_and_Gradient_Boosting.html">126 nips-2007-McRank: Learning to Rank Using Multiple Classification and Gradient Boosting</a></p>
<p>Author: Ping Li, Qiang Wu, Christopher J. Burges</p><p>Abstract: We cast the ranking problem as (1) multiple classiﬁcation (“Mc”) (2) multiple ordinal classiﬁcation, which lead to computationally tractable learning algorithms for relevance ranking in Web search. We consider the DCG criterion (discounted cumulative gain), a standard quality measure in information retrieval. Our approach is motivated by the fact that perfect classiﬁcations result in perfect DCG scores and the DCG errors are bounded by classiﬁcation errors. We propose using the Expected Relevance to convert class probabilities into ranking scores. The class probabilities are learned using a gradient boosting tree algorithm. Evaluations on large-scale datasets show that our approach can improve LambdaRank [5] and the regressions-based ranker [6], in terms of the (normalized) DCG scores. An efﬁcient implementation of the boosting tree algorithm is also presented.</p><p>3 0.78811491 <a title="126-lda-3" href="./nips-2007-Local_Algorithms_for_Approximate_Inference_in_Minor-Excluded_Graphs.html">121 nips-2007-Local Algorithms for Approximate Inference in Minor-Excluded Graphs</a></p>
<p>Author: Kyomin Jung, Devavrat Shah</p><p>Abstract: We present a new local approximation algorithm for computing MAP and logpartition function for arbitrary exponential family distribution represented by a ﬁnite-valued pair-wise Markov random ﬁeld (MRF), say G. Our algorithm is based on decomposing G into appropriately chosen small components; computing estimates locally in each of these components and then producing a good global solution. We prove that the algorithm can provide approximate solution within arbitrary accuracy when G excludes some ﬁnite sized graph as its minor and G has bounded degree: all Planar graphs with bounded degree are examples of such graphs. The running time of the algorithm is Θ(n) (n is the number of nodes in G), with constant dependent on accuracy, degree of graph and size of the graph that is excluded as a minor (constant for Planar graphs). Our algorithm for minor-excluded graphs uses the decomposition scheme of Klein, Plotkin and Rao (1993). In general, our algorithm works with any decomposition scheme and provides quantiﬁable approximation guarantee that depends on the decomposition scheme.</p><p>4 0.75809705 <a title="126-lda-4" href="./nips-2007-Catching_Up_Faster_in_Bayesian_Model_Selection_and_Model_Averaging.html">44 nips-2007-Catching Up Faster in Bayesian Model Selection and Model Averaging</a></p>
<p>Author: Tim V. Erven, Steven D. Rooij, Peter Grünwald</p><p>Abstract: Bayesian model averaging, model selection and their approximations such as BIC are generally statistically consistent, but sometimes achieve slower rates of convergence than other methods such as AIC and leave-one-out cross-validation. On the other hand, these other methods can be inconsistent. We identify the catch-up phenomenon as a novel explanation for the slow convergence of Bayesian methods. Based on this analysis we deﬁne the switch-distribution, a modiﬁcation of the Bayesian model averaging distribution. We prove that in many situations model selection and prediction based on the switch-distribution is both consistent and achieves optimal convergence rates, thereby resolving the AIC-BIC dilemma. The method is practical; we give an efﬁcient algorithm. 1</p><p>5 0.48923174 <a title="126-lda-5" href="./nips-2007-Evaluating_Search_Engines_by_Modeling_the_Relationship_Between_Relevance_and_Clicks.html">83 nips-2007-Evaluating Search Engines by Modeling the Relationship Between Relevance and Clicks</a></p>
<p>Author: Ben Carterette, Rosie Jones</p><p>Abstract: We propose a model that leverages the millions of clicks received by web search engines to predict document relevance. This allows the comparison of ranking functions when clicks are available but complete relevance judgments are not. After an initial training phase using a set of relevance judgments paired with click data, we show that our model can predict the relevance score of documents that have not been judged. These predictions can be used to evaluate the performance of a search engine, using our novel formalization of the conﬁdence of the standard evaluation metric discounted cumulative gain (DCG), so comparisons can be made across time and datasets. This contrasts with previous methods which can provide only pair-wise relevance judgments between results shown for the same query. When no relevance judgments are available, we can identify the better of two ranked lists up to 82% of the time, and with only two relevance judgments for each query, we can identify the better ranking up to 94% of the time. While our experiments are on sponsored search results, which is the ﬁnancial backbone of web search, our method is general enough to be applicable to algorithmic web search results as well. Furthermore, we give an algorithm to guide the selection of additional documents to judge to improve conﬁdence. 1</p><p>6 0.47599518 <a title="126-lda-6" href="./nips-2007-Fixing_Max-Product%3A_Convergent_Message_Passing_Algorithms_for_MAP_LP-Relaxations.html">92 nips-2007-Fixing Max-Product: Convergent Message Passing Algorithms for MAP LP-Relaxations</a></p>
<p>7 0.45970514 <a title="126-lda-7" href="./nips-2007-Loop_Series_and_Bethe_Variational_Bounds_in_Attractive_Graphical_Models.html">123 nips-2007-Loop Series and Bethe Variational Bounds in Attractive Graphical Models</a></p>
<p>8 0.44585979 <a title="126-lda-8" href="./nips-2007-COFI_RANK_-_Maximum_Margin_Matrix_Factorization_for_Collaborative_Ranking.html">41 nips-2007-COFI RANK - Maximum Margin Matrix Factorization for Collaborative Ranking</a></p>
<p>9 0.43891585 <a title="126-lda-9" href="./nips-2007-Scan_Strategies_for_Meteorological_Radars.html">171 nips-2007-Scan Strategies for Meteorological Radars</a></p>
<p>10 0.43664074 <a title="126-lda-10" href="./nips-2007-A_General_Boosting_Method_and_its_Application_to_Learning_Ranking_Functions_for_Web_Search.html">6 nips-2007-A General Boosting Method and its Application to Learning Ranking Functions for Web Search</a></p>
<p>11 0.43390104 <a title="126-lda-11" href="./nips-2007-Message_Passing_for_Max-weight_Independent_Set.html">128 nips-2007-Message Passing for Max-weight Independent Set</a></p>
<p>12 0.43179205 <a title="126-lda-12" href="./nips-2007-On_higher-order_perceptron_algorithms.html">146 nips-2007-On higher-order perceptron algorithms</a></p>
<p>13 0.42801595 <a title="126-lda-13" href="./nips-2007-New_Outer_Bounds_on_the_Marginal_Polytope.html">141 nips-2007-New Outer Bounds on the Marginal Polytope</a></p>
<p>14 0.4212096 <a title="126-lda-14" href="./nips-2007-Optimal_ROC_Curve_for_a_Combination_of_Classifiers.html">149 nips-2007-Optimal ROC Curve for a Combination of Classifiers</a></p>
<p>15 0.41447589 <a title="126-lda-15" href="./nips-2007-Near-Maximum_Entropy_Models_for_Binary_Neural_Representations_of_Natural_Images.html">138 nips-2007-Near-Maximum Entropy Models for Binary Neural Representations of Natural Images</a></p>
<p>16 0.4144057 <a title="126-lda-16" href="./nips-2007-Simplified_Rules_and_Theoretical_Analysis_for_Information_Bottleneck_Optimization_and_PCA_with_Spiking_Neurons.html">177 nips-2007-Simplified Rules and Theoretical Analysis for Information Bottleneck Optimization and PCA with Spiking Neurons</a></p>
<p>17 0.4132354 <a title="126-lda-17" href="./nips-2007-Boosting_the_Area_under_the_ROC_Curve.html">39 nips-2007-Boosting the Area under the ROC Curve</a></p>
<p>18 0.41247544 <a title="126-lda-18" href="./nips-2007-Structured_Learning_with_Approximate_Inference.html">187 nips-2007-Structured Learning with Approximate Inference</a></p>
<p>19 0.40987167 <a title="126-lda-19" href="./nips-2007-TrueSkill_Through_Time%3A_Revisiting_the_History_of_Chess.html">208 nips-2007-TrueSkill Through Time: Revisiting the History of Chess</a></p>
<p>20 0.40232012 <a title="126-lda-20" href="./nips-2007-Hidden_Common_Cause_Relations_in_Relational_Learning.html">97 nips-2007-Hidden Common Cause Relations in Relational Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
