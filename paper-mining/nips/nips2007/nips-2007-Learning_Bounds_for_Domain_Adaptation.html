<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>110 nips-2007-Learning Bounds for Domain Adaptation</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-110" href="#">nips2007-110</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>110 nips-2007-Learning Bounds for Domain Adaptation</h1>
<br/><p>Source: <a title="nips-2007-110-pdf" href="http://papers.nips.cc/paper/3212-learning-bounds-for-domain-adaptation.pdf">pdf</a></p><p>Author: John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, Jennifer Wortman</p><p>Abstract: Empirical risk minimization offers well-known learning guarantees when training and test data come from the same domain. In the real world, though, we often wish to adapt a classiﬁer from a source domain with a large amount of training data to different target domain with very little training data. In this work we give uniform convergence bounds for algorithms that minimize a convex combination of source and target empirical risk. The bounds explicitly model the inherent trade-off between training on a large but inaccurate source data set and a small but accurate target training set. Our theory also gives results when we have multiple source domains, each of which may have a different number of instances, and we exhibit cases in which minimizing a non-uniform combination of source risks can achieve much lower target error than standard empirical risk minimization. 1</p><p>Reference: <a title="nips-2007-110-reference" href="../nips2007_reference/nips-2007-Learning_Bounds_for_Domain_Adaptation_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('sourc', 0.508), ('target', 0.38), ('dh', 0.334), ('mt', 0.239), ('domain', 0.232), ('risk', 0.204), ('hypothes', 0.173), ('senty', 0.167), ('ds', 0.144), ('ut', 0.135), ('ms', 0.133), ('dt', 0.118), ('unlabel', 0.092), ('fs', 0.088), ('blitz', 0.083), ('cram', 0.083), ('dvd', 0.083), ('dist', 0.083), ('theorem', 0.078), ('ft', 0.077)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="110-tfidf-1" href="./nips-2007-Learning_Bounds_for_Domain_Adaptation.html">110 nips-2007-Learning Bounds for Domain Adaptation</a></p>
<p>Author: John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, Jennifer Wortman</p><p>Abstract: Empirical risk minimization offers well-known learning guarantees when training and test data come from the same domain. In the real world, though, we often wish to adapt a classiﬁer from a source domain with a large amount of training data to different target domain with very little training data. In this work we give uniform convergence bounds for algorithms that minimize a convex combination of source and target empirical risk. The bounds explicitly model the inherent trade-off between training on a large but inaccurate source data set and a small but accurate target training set. Our theory also gives results when we have multiple source domains, each of which may have a different number of instances, and we exhibit cases in which minimizing a non-uniform combination of source risks can achieve much lower target error than standard empirical risk minimization. 1</p><p>2 0.17859295 <a title="110-tfidf-2" href="./nips-2007-Mining_Internet-Scale_Software_Repositories.html">129 nips-2007-Mining Internet-Scale Software Repositories</a></p>
<p>Author: Erik Linstead, Paul Rigor, Sushil Bajracharya, Cristina Lopes, Pierre F. Baldi</p><p>Abstract: Large repositories of source code create new challenges and opportunities for statistical machine learning. Here we ﬁrst develop Sourcerer, an infrastructure for the automated crawling, parsing, and database storage of open source software. Sourcerer allows us to gather Internet-scale source code. For instance, in one experiment, we gather 4,632 java projects from SourceForge and Apache totaling over 38 million lines of code from 9,250 developers. Simple statistical analyses of the data ﬁrst reveal robust power-law behavior for package, SLOC, and lexical containment distributions. We then develop and apply unsupervised author-topic, probabilistic models to automatically discover the topics embedded in the code and extract topic-word and author-topic distributions. In addition to serving as a convenient summary for program function and developer activities, these and other related distributions provide a statistical and information-theoretic basis for quantifying and analyzing developer similarity and competence, topic scattering, and document tangling, with direct applications to software engineering. Finally, by combining software textual content with structural information captured by our CodeRank approach, we are able to signiﬁcantly improve software retrieval performance, increasing the AUC metric to 0.84– roughly 10-30% better than previous approaches based on text alone. Supplementary material may be found at: http://sourcerer.ics.uci.edu/nips2007/nips07.html. 1</p><p>3 0.1328063 <a title="110-tfidf-3" href="./nips-2007-How_SVMs_can_estimate_quantiles_and_the_median.html">101 nips-2007-How SVMs can estimate quantiles and the median</a></p>
<p>Author: Andreas Christmann, Ingo Steinwart</p><p>Abstract: We investigate quantile regression based on the pinball loss and the ǫ-insensitive loss. For the pinball loss a condition on the data-generating distribution P is given that ensures that the conditional quantiles are approximated with respect to · 1 . This result is then used to derive an oracle inequality for an SVM based on the pinball loss. Moreover, we show that SVMs based on the ǫ-insensitive loss estimate the conditional median only under certain conditions on P . 1</p><p>4 0.10812628 <a title="110-tfidf-4" href="./nips-2007-Blind_channel_identification_for_speech_dereverberation_using_l1-norm_sparse_learning.html">37 nips-2007-Blind channel identification for speech dereverberation using l1-norm sparse learning</a></p>
<p>Author: Yuanqing Lin, Jingdong Chen, Youngmoo Kim, Daniel D. Lee</p><p>Abstract: Speech dereverberation remains an open problem after more than three decades of research. The most challenging step in speech dereverberation is blind channel identiﬁcation (BCI). Although many BCI approaches have been developed, their performance is still far from satisfactory for practical applications. The main difﬁculty in BCI lies in ﬁnding an appropriate acoustic model, which not only can effectively resolve solution degeneracies due to the lack of knowledge of the source, but also robustly models real acoustic environments. This paper proposes a sparse acoustic room impulse response (RIR) model for BCI, that is, an acoustic RIR can be modeled by a sparse FIR ﬁlter. Under this model, we show how to formulate the BCI of a single-input multiple-output (SIMO) system into a l1 norm regularized least squares (LS) problem, which is convex and can be solved efﬁciently with guaranteed global convergence. The sparseness of solutions is controlled by l1 -norm regularization parameters. We propose a sparse learning scheme that infers the optimal l1 -norm regularization parameters directly from microphone observations under a Bayesian framework. Our results show that the proposed approach is effective and robust, and it yields source estimates in real acoustic environments with high ﬁdelity to anechoic chamber measurements.</p><p>5 0.1034449 <a title="110-tfidf-5" href="./nips-2007-Discriminative_Batch_Mode_Active_Learning.html">69 nips-2007-Discriminative Batch Mode Active Learning</a></p>
<p>Author: Yuhong Guo, Dale Schuurmans</p><p>Abstract: Active learning sequentially selects unlabeled instances to label with the goal of reducing the effort needed to learn a good classiﬁer. Most previous studies in active learning have focused on selecting one unlabeled instance to label at a time while retraining in each iteration. Recently a few batch mode active learning approaches have been proposed that select a set of most informative unlabeled instances in each iteration under the guidance of heuristic scores. In this paper, we propose a discriminative batch mode active learning approach that formulates the instance selection task as a continuous optimization problem over auxiliary instance selection variables. The optimization is formulated to maximize the discriminative classiﬁcation performance of the target classiﬁer, while also taking the unlabeled data into account. Although the objective is not convex, we can manipulate a quasi-Newton method to obtain a good local solution. Our empirical studies on UCI datasets show that the proposed active learning is more effective than current state-of-the art batch mode active learning algorithms. 1</p><p>6 0.094117783 <a title="110-tfidf-6" href="./nips-2007-Simplified_Rules_and_Theoretical_Analysis_for_Information_Bottleneck_Optimization_and_PCA_with_Spiking_Neurons.html">177 nips-2007-Simplified Rules and Theoretical Analysis for Information Bottleneck Optimization and PCA with Spiking Neurons</a></p>
<p>7 0.092589974 <a title="110-tfidf-7" href="./nips-2007-Statistical_Analysis_of_Semi-Supervised_Regression.html">186 nips-2007-Statistical Analysis of Semi-Supervised Regression</a></p>
<p>8 0.092499405 <a title="110-tfidf-8" href="./nips-2007-A_Bayesian_Model_of_Conditioned_Perception.html">3 nips-2007-A Bayesian Model of Conditioned Perception</a></p>
<p>9 0.092012398 <a title="110-tfidf-9" href="./nips-2007-Progressive_mixture_rules_are_deviation_suboptimal.html">159 nips-2007-Progressive mixture rules are deviation suboptimal</a></p>
<p>10 0.091110379 <a title="110-tfidf-10" href="./nips-2007-Linear_programming_analysis_of_loopy_belief_propagation_for_weighted_matching.html">120 nips-2007-Linear programming analysis of loopy belief propagation for weighted matching</a></p>
<p>11 0.087474652 <a title="110-tfidf-11" href="./nips-2007-Boosting_Algorithms_for_Maximizing_the_Soft_Margin.html">38 nips-2007-Boosting Algorithms for Maximizing the Soft Margin</a></p>
<p>12 0.083384328 <a title="110-tfidf-12" href="./nips-2007-Simulated_Annealing%3A_Rigorous_finite-time_guarantees_for_optimization_on_continuous_domains.html">178 nips-2007-Simulated Annealing: Rigorous finite-time guarantees for optimization on continuous domains</a></p>
<p>13 0.082780577 <a title="110-tfidf-13" href="./nips-2007-An_online_Hebbian_learning_rule_that_performs_Independent_Component_Analysis.html">26 nips-2007-An online Hebbian learning rule that performs Independent Component Analysis</a></p>
<p>14 0.082121454 <a title="110-tfidf-14" href="./nips-2007-A_Unified_Near-Optimal_Estimator_For_Dimension_Reduction_in_%24l_%5Calpha%24_%28%240%3C%5Calpha%5Cleq_2%24%29_Using_Stable_Random_Projections.html">13 nips-2007-A Unified Near-Optimal Estimator For Dimension Reduction in $l \alpha$ ($0<\alpha\leq 2$) Using Stable Random Projections</a></p>
<p>15 0.081631325 <a title="110-tfidf-15" href="./nips-2007-Structured_Learning_with_Approximate_Inference.html">187 nips-2007-Structured Learning with Approximate Inference</a></p>
<p>16 0.080184534 <a title="110-tfidf-16" href="./nips-2007-Convex_Learning_with_Invariances.html">62 nips-2007-Convex Learning with Invariances</a></p>
<p>17 0.080008209 <a title="110-tfidf-17" href="./nips-2007-EEG-Based_Brain-Computer_Interaction%3A_Improved_Accuracy_by_Automatic_Single-Trial_Error_Detection.html">74 nips-2007-EEG-Based Brain-Computer Interaction: Improved Accuracy by Automatic Single-Trial Error Detection</a></p>
<p>18 0.079185158 <a title="110-tfidf-18" href="./nips-2007-Expectation_Maximization_and_Posterior_Constraints.html">84 nips-2007-Expectation Maximization and Posterior Constraints</a></p>
<p>19 0.076982103 <a title="110-tfidf-19" href="./nips-2007-One-Pass_Boosting.html">147 nips-2007-One-Pass Boosting</a></p>
<p>20 0.07654734 <a title="110-tfidf-20" href="./nips-2007-The_Value_of_Labeled_and_Unlabeled_Examples_when_the_Model_is_Imperfect.html">201 nips-2007-The Value of Labeled and Unlabeled Examples when the Model is Imperfect</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2007_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.22), (1, -0.052), (2, 0.027), (3, 0.022), (4, -0.064), (5, -0.002), (6, 0.145), (7, -0.025), (8, 0.025), (9, 0.043), (10, 0.055), (11, -0.017), (12, -0.02), (13, -0.154), (14, -0.096), (15, 0.136), (16, 0.034), (17, -0.034), (18, 0.01), (19, -0.07), (20, -0.003), (21, 0.005), (22, 0.078), (23, -0.016), (24, 0.096), (25, 0.046), (26, -0.118), (27, 0.13), (28, 0.098), (29, 0.269), (30, -0.138), (31, -0.021), (32, -0.097), (33, 0.163), (34, 0.09), (35, 0.012), (36, 0.008), (37, 0.226), (38, 0.077), (39, -0.028), (40, 0.02), (41, 0.15), (42, -0.115), (43, -0.048), (44, -0.064), (45, -0.15), (46, 0.04), (47, 0.003), (48, 0.082), (49, -0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.965904 <a title="110-lsi-1" href="./nips-2007-Learning_Bounds_for_Domain_Adaptation.html">110 nips-2007-Learning Bounds for Domain Adaptation</a></p>
<p>Author: John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, Jennifer Wortman</p><p>Abstract: Empirical risk minimization offers well-known learning guarantees when training and test data come from the same domain. In the real world, though, we often wish to adapt a classiﬁer from a source domain with a large amount of training data to different target domain with very little training data. In this work we give uniform convergence bounds for algorithms that minimize a convex combination of source and target empirical risk. The bounds explicitly model the inherent trade-off between training on a large but inaccurate source data set and a small but accurate target training set. Our theory also gives results when we have multiple source domains, each of which may have a different number of instances, and we exhibit cases in which minimizing a non-uniform combination of source risks can achieve much lower target error than standard empirical risk minimization. 1</p><p>2 0.64597082 <a title="110-lsi-2" href="./nips-2007-How_SVMs_can_estimate_quantiles_and_the_median.html">101 nips-2007-How SVMs can estimate quantiles and the median</a></p>
<p>Author: Andreas Christmann, Ingo Steinwart</p><p>Abstract: We investigate quantile regression based on the pinball loss and the ǫ-insensitive loss. For the pinball loss a condition on the data-generating distribution P is given that ensures that the conditional quantiles are approximated with respect to · 1 . This result is then used to derive an oracle inequality for an SVM based on the pinball loss. Moreover, we show that SVMs based on the ǫ-insensitive loss estimate the conditional median only under certain conditions on P . 1</p><p>3 0.62660611 <a title="110-lsi-3" href="./nips-2007-Mining_Internet-Scale_Software_Repositories.html">129 nips-2007-Mining Internet-Scale Software Repositories</a></p>
<p>Author: Erik Linstead, Paul Rigor, Sushil Bajracharya, Cristina Lopes, Pierre F. Baldi</p><p>Abstract: Large repositories of source code create new challenges and opportunities for statistical machine learning. Here we ﬁrst develop Sourcerer, an infrastructure for the automated crawling, parsing, and database storage of open source software. Sourcerer allows us to gather Internet-scale source code. For instance, in one experiment, we gather 4,632 java projects from SourceForge and Apache totaling over 38 million lines of code from 9,250 developers. Simple statistical analyses of the data ﬁrst reveal robust power-law behavior for package, SLOC, and lexical containment distributions. We then develop and apply unsupervised author-topic, probabilistic models to automatically discover the topics embedded in the code and extract topic-word and author-topic distributions. In addition to serving as a convenient summary for program function and developer activities, these and other related distributions provide a statistical and information-theoretic basis for quantifying and analyzing developer similarity and competence, topic scattering, and document tangling, with direct applications to software engineering. Finally, by combining software textual content with structural information captured by our CodeRank approach, we are able to signiﬁcantly improve software retrieval performance, increasing the AUC metric to 0.84– roughly 10-30% better than previous approaches based on text alone. Supplementary material may be found at: http://sourcerer.ics.uci.edu/nips2007/nips07.html. 1</p><p>4 0.51667351 <a title="110-lsi-4" href="./nips-2007-Boosting_Algorithms_for_Maximizing_the_Soft_Margin.html">38 nips-2007-Boosting Algorithms for Maximizing the Soft Margin</a></p>
<p>Author: Gunnar Rätsch, Manfred K. Warmuth, Karen A. Glocer</p><p>Abstract: We present a novel boosting algorithm, called SoftBoost, designed for sets of binary labeled examples that are not necessarily separable by convex combinations of base hypotheses. Our algorithm achieves robustness by capping the distributions on the examples. Our update of the distribution is motivated by minimizing a relative entropy subject to the capping constraints and constraints on the edges of the obtained base hypotheses. The capping constraints imply a soft margin in the dual optimization problem. Our algorithm produces a convex combination of hypotheses whose soft margin is within δ of its maximum. We employ relative enN tropy projection methods to prove an O( ln 2 ) iteration bound for our algorithm, δ where N is number of examples. We compare our algorithm with other approaches including LPBoost, BrownBoost, and SmoothBoost. We show that there exist cases where the number of iterations required by LPBoost grows linearly in N instead of the logarithmic growth for SoftBoost. In simulation studies we show that our algorithm converges about as fast as LPBoost, faster than BrownBoost, and much faster than SmoothBoost. In a benchmark comparison we illustrate the competitiveness of our approach.</p><p>5 0.50712419 <a title="110-lsi-5" href="./nips-2007-Blind_channel_identification_for_speech_dereverberation_using_l1-norm_sparse_learning.html">37 nips-2007-Blind channel identification for speech dereverberation using l1-norm sparse learning</a></p>
<p>Author: Yuanqing Lin, Jingdong Chen, Youngmoo Kim, Daniel D. Lee</p><p>Abstract: Speech dereverberation remains an open problem after more than three decades of research. The most challenging step in speech dereverberation is blind channel identiﬁcation (BCI). Although many BCI approaches have been developed, their performance is still far from satisfactory for practical applications. The main difﬁculty in BCI lies in ﬁnding an appropriate acoustic model, which not only can effectively resolve solution degeneracies due to the lack of knowledge of the source, but also robustly models real acoustic environments. This paper proposes a sparse acoustic room impulse response (RIR) model for BCI, that is, an acoustic RIR can be modeled by a sparse FIR ﬁlter. Under this model, we show how to formulate the BCI of a single-input multiple-output (SIMO) system into a l1 norm regularized least squares (LS) problem, which is convex and can be solved efﬁciently with guaranteed global convergence. The sparseness of solutions is controlled by l1 -norm regularization parameters. We propose a sparse learning scheme that infers the optimal l1 -norm regularization parameters directly from microphone observations under a Bayesian framework. Our results show that the proposed approach is effective and robust, and it yields source estimates in real acoustic environments with high ﬁdelity to anechoic chamber measurements.</p><p>6 0.50691658 <a title="110-lsi-6" href="./nips-2007-Simulated_Annealing%3A_Rigorous_finite-time_guarantees_for_optimization_on_continuous_domains.html">178 nips-2007-Simulated Annealing: Rigorous finite-time guarantees for optimization on continuous domains</a></p>
<p>7 0.49800083 <a title="110-lsi-7" href="./nips-2007-An_online_Hebbian_learning_rule_that_performs_Independent_Component_Analysis.html">26 nips-2007-An online Hebbian learning rule that performs Independent Component Analysis</a></p>
<p>8 0.47956002 <a title="110-lsi-8" href="./nips-2007-Progressive_mixture_rules_are_deviation_suboptimal.html">159 nips-2007-Progressive mixture rules are deviation suboptimal</a></p>
<p>9 0.47499847 <a title="110-lsi-9" href="./nips-2007-A_general_agnostic_active_learning_algorithm.html">15 nips-2007-A general agnostic active learning algorithm</a></p>
<p>10 0.46722522 <a title="110-lsi-10" href="./nips-2007-Optimal_models_of_sound_localization_by_barn_owls.html">150 nips-2007-Optimal models of sound localization by barn owls</a></p>
<p>11 0.43857101 <a title="110-lsi-11" href="./nips-2007-Classification_via_Minimum_Incremental_Coding_Length_%28MICL%29.html">45 nips-2007-Classification via Minimum Incremental Coding Length (MICL)</a></p>
<p>12 0.41863486 <a title="110-lsi-12" href="./nips-2007-The_Value_of_Labeled_and_Unlabeled_Examples_when_the_Model_is_Imperfect.html">201 nips-2007-The Value of Labeled and Unlabeled Examples when the Model is Imperfect</a></p>
<p>13 0.38576904 <a title="110-lsi-13" href="./nips-2007-Estimating_divergence_functionals_and_the_likelihood_ratio_by_penalized_convex_risk_minimization.html">82 nips-2007-Estimating divergence functionals and the likelihood ratio by penalized convex risk minimization</a></p>
<p>14 0.36005437 <a title="110-lsi-14" href="./nips-2007-Stability_Bounds_for_Non-i.i.d._Processes.html">184 nips-2007-Stability Bounds for Non-i.i.d. Processes</a></p>
<p>15 0.35463113 <a title="110-lsi-15" href="./nips-2007-Experience-Guided_Search%3A_A_Theory_of_Attentional_Control.html">85 nips-2007-Experience-Guided Search: A Theory of Attentional Control</a></p>
<p>16 0.35442427 <a title="110-lsi-16" href="./nips-2007-Discriminative_Batch_Mode_Active_Learning.html">69 nips-2007-Discriminative Batch Mode Active Learning</a></p>
<p>17 0.3458631 <a title="110-lsi-17" href="./nips-2007-One-Pass_Boosting.html">147 nips-2007-One-Pass Boosting</a></p>
<p>18 0.3455365 <a title="110-lsi-18" href="./nips-2007-Discriminative_Keyword_Selection_Using_Support_Vector_Machines.html">71 nips-2007-Discriminative Keyword Selection Using Support Vector Machines</a></p>
<p>19 0.34551021 <a title="110-lsi-19" href="./nips-2007-FilterBoost%3A_Regression_and_Classification_on_Large_Datasets.html">90 nips-2007-FilterBoost: Regression and Classification on Large Datasets</a></p>
<p>20 0.3344205 <a title="110-lsi-20" href="./nips-2007-Statistical_Analysis_of_Semi-Supervised_Regression.html">186 nips-2007-Statistical Analysis of Semi-Supervised Regression</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2007_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(17, 0.147), (25, 0.135), (28, 0.021), (30, 0.073), (45, 0.036), (46, 0.119), (53, 0.036), (56, 0.016), (60, 0.213), (62, 0.015), (79, 0.015), (90, 0.072)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.91235077 <a title="110-lda-1" href="./nips-2007-Learning_Bounds_for_Domain_Adaptation.html">110 nips-2007-Learning Bounds for Domain Adaptation</a></p>
<p>Author: John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, Jennifer Wortman</p><p>Abstract: Empirical risk minimization offers well-known learning guarantees when training and test data come from the same domain. In the real world, though, we often wish to adapt a classiﬁer from a source domain with a large amount of training data to different target domain with very little training data. In this work we give uniform convergence bounds for algorithms that minimize a convex combination of source and target empirical risk. The bounds explicitly model the inherent trade-off between training on a large but inaccurate source data set and a small but accurate target training set. Our theory also gives results when we have multiple source domains, each of which may have a different number of instances, and we exhibit cases in which minimizing a non-uniform combination of source risks can achieve much lower target error than standard empirical risk minimization. 1</p><p>2 0.88739741 <a title="110-lda-2" href="./nips-2007-The_Value_of_Labeled_and_Unlabeled_Examples_when_the_Model_is_Imperfect.html">201 nips-2007-The Value of Labeled and Unlabeled Examples when the Model is Imperfect</a></p>
<p>Author: Kaushik Sinha, Mikhail Belkin</p><p>Abstract: Semi-supervised learning, i.e. learning from both labeled and unlabeled data has received signiﬁcant attention in the machine learning literature in recent years. Still our understanding of the theoretical foundations of the usefulness of unlabeled data remains somewhat limited. The simplest and the best understood situation is when the data is described by an identiﬁable mixture model, and where each class comes from a pure component. This natural setup and its implications ware analyzed in [11, 5]. One important result was that in certain regimes, labeled data becomes exponentially more valuable than unlabeled data. However, in most realistic situations, one would not expect that the data comes from a parametric mixture distribution with identiﬁable components. There have been recent efforts to analyze the non-parametric situation, for example, “cluster” and “manifold” assumptions have been suggested as a basis for analysis. Still, a satisfactory and fairly complete theoretical understanding of the nonparametric problem, similar to that in [11, 5] has not yet been developed. In this paper we investigate an intermediate situation, when the data comes from a probability distribution, which can be modeled, but not perfectly, by an identiﬁable mixture distribution. This seems applicable to many situation, when, for example, a mixture of Gaussians is used to model the data. the contribution of this paper is an analysis of the role of labeled and unlabeled data depending on the amount of imperfection in the model.</p><p>3 0.88199323 <a title="110-lda-3" href="./nips-2007-Probabilistic_Matrix_Factorization.html">158 nips-2007-Probabilistic Matrix Factorization</a></p>
<p>Author: Andriy Mnih, Ruslan Salakhutdinov</p><p>Abstract: Many existing approaches to collaborative ﬁltering can neither handle very large datasets nor easily deal with users who have very few ratings. In this paper we present the Probabilistic Matrix Factorization (PMF) model which scales linearly with the number of observations and, more importantly, performs well on the large, sparse, and very imbalanced Netﬂix dataset. We further extend the PMF model to include an adaptive prior on the model parameters and show how the model capacity can be controlled automatically. Finally, we introduce a constrained version of the PMF model that is based on the assumption that users who have rated similar sets of movies are likely to have similar preferences. The resulting model is able to generalize considerably better for users with very few ratings. When the predictions of multiple PMF models are linearly combined with the predictions of Restricted Boltzmann Machines models, we achieve an error rate of 0.8861, that is nearly 7% better than the score of Netﬂix’s own system.</p><p>4 0.87349111 <a title="110-lda-4" href="./nips-2007-New_Outer_Bounds_on_the_Marginal_Polytope.html">141 nips-2007-New Outer Bounds on the Marginal Polytope</a></p>
<p>Author: David Sontag, Tommi S. Jaakkola</p><p>Abstract: We give a new class of outer bounds on the marginal polytope, and propose a cutting-plane algorithm for efﬁciently optimizing over these constraints. When combined with a concave upper bound on the entropy, this gives a new variational inference algorithm for probabilistic inference in discrete Markov Random Fields (MRFs). Valid constraints on the marginal polytope are derived through a series of projections onto the cut polytope. As a result, we obtain tighter upper bounds on the log-partition function. We also show empirically that the approximations of the marginals are signiﬁcantly more accurate when using the tighter outer bounds. Finally, we demonstrate the advantage of the new constraints for ﬁnding the MAP assignment in protein structure prediction. 1</p><p>5 0.87319523 <a title="110-lda-5" href="./nips-2007-Convex_Relaxations_of_Latent_Variable_Training.html">63 nips-2007-Convex Relaxations of Latent Variable Training</a></p>
<p>Author: Yuhong Guo, Dale Schuurmans</p><p>Abstract: We investigate a new, convex relaxation of an expectation-maximization (EM) variant that approximates a standard objective while eliminating local minima. First, a cautionary result is presented, showing that any convex relaxation of EM over hidden variables must give trivial results if any dependence on the missing values is retained. Although this appears to be a strong negative outcome, we then demonstrate how the problem can be bypassed by using equivalence relations instead of value assignments over hidden variables. In particular, we develop new algorithms for estimating exponential conditional models that only require equivalence relation information over the variable values. This reformulation leads to an exact expression for EM variants in a wide range of problems. We then develop a semideﬁnite relaxation that yields global training by eliminating local minima. 1</p><p>6 0.8707909 <a title="110-lda-6" href="./nips-2007-On_higher-order_perceptron_algorithms.html">146 nips-2007-On higher-order perceptron algorithms</a></p>
<p>7 0.87046725 <a title="110-lda-7" href="./nips-2007-Message_Passing_for_Max-weight_Independent_Set.html">128 nips-2007-Message Passing for Max-weight Independent Set</a></p>
<p>8 0.86924005 <a title="110-lda-8" href="./nips-2007-Theoretical_Analysis_of_Heuristic_Search_Methods_for_Online_POMDPs.html">204 nips-2007-Theoretical Analysis of Heuristic Search Methods for Online POMDPs</a></p>
<p>9 0.86860198 <a title="110-lda-9" href="./nips-2007-Sequential_Hypothesis_Testing_under_Stochastic_Deadlines.html">176 nips-2007-Sequential Hypothesis Testing under Stochastic Deadlines</a></p>
<p>10 0.86801791 <a title="110-lda-10" href="./nips-2007-Linear_programming_analysis_of_loopy_belief_propagation_for_weighted_matching.html">120 nips-2007-Linear programming analysis of loopy belief propagation for weighted matching</a></p>
<p>11 0.86767972 <a title="110-lda-11" href="./nips-2007-A_Unified_Near-Optimal_Estimator_For_Dimension_Reduction_in_%24l_%5Calpha%24_%28%240%3C%5Calpha%5Cleq_2%24%29_Using_Stable_Random_Projections.html">13 nips-2007-A Unified Near-Optimal Estimator For Dimension Reduction in $l \alpha$ ($0<\alpha\leq 2$) Using Stable Random Projections</a></p>
<p>12 0.86634952 <a title="110-lda-12" href="./nips-2007-A_General_Boosting_Method_and_its_Application_to_Learning_Ranking_Functions_for_Web_Search.html">6 nips-2007-A General Boosting Method and its Application to Learning Ranking Functions for Web Search</a></p>
<p>13 0.86548281 <a title="110-lda-13" href="./nips-2007-A_Risk_Minimization_Principle_for_a_Class_of_Parzen_Estimators.html">11 nips-2007-A Risk Minimization Principle for a Class of Parzen Estimators</a></p>
<p>14 0.86461556 <a title="110-lda-14" href="./nips-2007-Computational_Equivalence_of_Fixed_Points_and_No_Regret_Algorithms%2C_and_Convergence_to_Equilibria.html">54 nips-2007-Computational Equivalence of Fixed Points and No Regret Algorithms, and Convergence to Equilibria</a></p>
<p>15 0.8640815 <a title="110-lda-15" href="./nips-2007-GRIFT%3A_A_graphical_model_for_inferring_visual_classification_features_from_human_data.html">93 nips-2007-GRIFT: A graphical model for inferring visual classification features from human data</a></p>
<p>16 0.86407483 <a title="110-lda-16" href="./nips-2007-Configuration_Estimates_Improve_Pedestrian_Finding.html">56 nips-2007-Configuration Estimates Improve Pedestrian Finding</a></p>
<p>17 0.86378694 <a title="110-lda-17" href="./nips-2007-Boosting_the_Area_under_the_ROC_Curve.html">39 nips-2007-Boosting the Area under the ROC Curve</a></p>
<p>18 0.86357611 <a title="110-lda-18" href="./nips-2007-Testing_for_Homogeneity_with_Kernel_Fisher_Discriminant_Analysis.html">192 nips-2007-Testing for Homogeneity with Kernel Fisher Discriminant Analysis</a></p>
<p>19 0.86315793 <a title="110-lda-19" href="./nips-2007-Efficient_Inference_for_Distributions_on_Permutations.html">77 nips-2007-Efficient Inference for Distributions on Permutations</a></p>
<p>20 0.86264986 <a title="110-lda-20" href="./nips-2007-Bayesian_Co-Training.html">32 nips-2007-Bayesian Co-Training</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
