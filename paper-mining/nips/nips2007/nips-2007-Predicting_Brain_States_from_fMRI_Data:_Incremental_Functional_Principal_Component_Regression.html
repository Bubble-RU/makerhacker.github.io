<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>154 nips-2007-Predicting Brain States from fMRI Data: Incremental Functional Principal Component Regression</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-154" href="#">nips2007-154</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>154 nips-2007-Predicting Brain States from fMRI Data: Incremental Functional Principal Component Regression</h1>
<br/><p>Source: <a title="nips-2007-154-pdf" href="http://papers.nips.cc/paper/3326-predicting-brain-states-from-fmri-data-incremental-functional-principal-component-regression.pdf">pdf</a></p><p>Author: Sennay Ghebreab, Arnold Smeulders, Pieter Adriaans</p><p>Abstract: We propose a method for reconstruction of human brain states directly from functional neuroimaging data. The method extends the traditional multivariate regression analysis of discretized fMRI data to the domain of stochastic functional measurements, facilitating evaluation of brain responses to complex stimuli and boosting the power of functional imaging. The method searches for sets of voxel time courses that optimize a multivariate functional linear model in terms of R2 statistic. Population based incremental learning is used to identify spatially distributed brain responses to complex stimuli without attempting to localize function ﬁrst. Variation in hemodynamic lag across brain areas and among subjects is taken into account by voxel-wise non-linear registration of stimulus pattern to fMRI data. Application of the method on an international test benchmark for prediction of naturalistic stimuli from new and unknown fMRI data shows that the method successfully uncovers spatially distributed parts of the brain that are highly predictive of a given stimulus. 1</p><p>Reference: <a title="nips-2007-154-reference" href="../nips2007_reference/nips-2007-Predicting_Brain_States_from_fMRI_Data%3A_Incremental_Functional_Principal_Component_Regression_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 nl  Abstract We propose a method for reconstruction of human brain states directly from functional neuroimaging data. [sent-12, score-0.558]
</p><p>2 The method extends the traditional multivariate regression analysis of discretized fMRI data to the domain of stochastic functional measurements, facilitating evaluation of brain responses to complex stimuli and boosting the power of functional imaging. [sent-13, score-0.972]
</p><p>3 The method searches for sets of voxel time courses that optimize a multivariate functional linear model in terms of R2 statistic. [sent-14, score-0.845]
</p><p>4 Population based incremental learning is used to identify spatially distributed brain responses to complex stimuli without attempting to localize function ﬁrst. [sent-15, score-0.746]
</p><p>5 Variation in hemodynamic lag across brain areas and among subjects is taken into account by voxel-wise non-linear registration of stimulus pattern to fMRI data. [sent-16, score-0.771]
</p><p>6 Application of the method on an international test benchmark for prediction of naturalistic stimuli from new and unknown fMRI data shows that the method successfully uncovers spatially distributed parts of the brain that are highly predictive of a given stimulus. [sent-17, score-0.866]
</p><p>7 1  Introduction  To arrive at a better understanding of human brain function, functional neuroimaging traditionally studies the brain’s responses to controlled stimuli. [sent-18, score-0.641]
</p><p>8 Controlled stimuli have the beneﬁt of leading to clear and often localized response signals in fMRI as they are speciﬁcally designed to aﬀect only certain brain functions. [sent-19, score-0.526]
</p><p>9 The drawback of controlled stimuli is that they are a reduction of reality: one cannot be certain whether the response is due to the reduction or due to the stimulus. [sent-20, score-0.223]
</p><p>10 Naturalistic stimuli open the possibility to avoid the question whether the response is due to the reduction or the signal. [sent-21, score-0.223]
</p><p>11 Naturalistic stimuli, however, carry a high information content in their spatio-temporal structure that is likely to instigate complex brain states. [sent-22, score-0.303]
</p><p>12 To reveal brain responses to naturalistic stimuli, advanced signal processing methods are required that go beyond conventional mass univariate data analysis. [sent-24, score-0.497]
</p><p>13 Univariate techniques generally lack suﬃcient power to capture the spatially distributed response of the brain to naturalistic stimuli. [sent-25, score-0.628]
</p><p>14 Multivariate pattern techniques, on the other hand, have the capacity to identify patterns of information when they are present across the full spatial extent of the brain without attempting to localize func-  tion. [sent-26, score-0.425]
</p><p>15 Here, we propose a multivariate pattern analysis approach for predicting naturalistic stimuli on the basis of fMRI data. [sent-27, score-0.439]
</p><p>16 Inverting the task from correlating stimuli with fMRI data to predicting stimuli from fMRI data makes it easier to evaluate brain responses to naturalistic stimuli and may extend the power of functional imaging substantially [1]. [sent-28, score-1.156]
</p><p>17 Various multivariate approaches for reconstruction of brain states directly from fMRI measurements have recently been proposed. [sent-29, score-0.392]
</p><p>18 In most of these approaches, a classiﬁer is trained directly on the fMRI data to discriminate between known diﬀerent brain states. [sent-30, score-0.303]
</p><p>19 This classiﬁer is then used to predict brain states on the basis of new and unknown fMRI data alone. [sent-31, score-0.303]
</p><p>20 In one competition [6], participants trained pattern analyzers on fMRI of subjects viewing two short movies as well as on the subject’s movie feature ratings. [sent-33, score-0.545]
</p><p>21 Then participants employed the analyzers to predict the experience of subjects watching a third movie based purely on fMRI data. [sent-34, score-0.479]
</p><p>22 Very accurate predictions were reported for identifying the presence of speciﬁc time varying movie features (e. [sent-35, score-0.307]
</p><p>23 We propose an incremental multivariate linear modeling approach for functional covariates, i. [sent-38, score-0.326]
</p><p>24 Contemporary neuroimaging studies increasingly use high-resolution fMRI to accurately capture continuous brain processes, frequently instigated by continuous stimulations. [sent-44, score-0.43]
</p><p>25 We extend classical multivariate regression analysis of fMRI data [11] to stochastic functional measurements. [sent-47, score-0.296]
</p><p>26 We show that, cast into an incremental pattern searching framework, functional multivariate regression provides a powerful technique for fMRI-based prediction of naturalistic stimuli. [sent-48, score-0.581]
</p><p>27 2  Method  In the remainder, we consider stimuli data and data produced by fMRI scanners as continuous functions of time, sampled at the scan interval and subject to observational noise. [sent-49, score-0.303]
</p><p>28 We treat the data within a functional linear model where both the predictant and predictor are functional, but where the design matrix that takes care of the linear mapping between the two is vectorial. [sent-50, score-0.231]
</p><p>29 1  The Predictor  The predictor data are derived directly from the four-dimensional fMRI data I(x, t), where x ∈ ℜ3 denotes the spatial position of a voxel and t denotes its temporal position. [sent-52, score-0.518]
</p><p>30 We represent each of the S voxel time courses in functional form by f s (t), with t denoting the continuous path parameter and s = 1, . [sent-53, score-0.786]
</p><p>31 Rather than directly using voxel time courses for prediction, we use their principal components to eliminate collinearity in the predictor set. [sent-57, score-0.771]
</p><p>32 [10] showed that functional principal components analysis is more eﬀective than is its ordinary counterpart in recovering the signal of interest in fMRI data, even if limited or no prior knowledge of the hemodynamic function or experimental design is speciﬁed. [sent-60, score-0.383]
</p><p>33 In contrast to [10], however, our approach incrementally zooms in on stimuli-related voxel time courses for dimension reduction (see section 2. [sent-61, score-0.597]
</p><p>34 Given the set of S voxel time courses represented by the vector of functionals f(t) = [ f1 (t), . [sent-63, score-0.597]
</p><p>35 , fS (t)]T , functional principal components analysis extracts main modes of variation in f(t). [sent-66, score-0.295]
</p><p>36 Assuming this is Q, the central concept is that of taking the linear combination f sq =  f s (t)αq (t)dt t  (1)  where f sq is the principal component score value of voxel time course f s (t) in dimension q. [sent-68, score-0.704]
</p><p>37 2  The Predictand  We represent the stimulus pattern by the functional (t), t being the continuous time parameter. [sent-82, score-0.283]
</p><p>38 We register (t) to each voxel time course f s (t) in order to be able to compare equivalent time points on stimulus and brain activity data. [sent-83, score-0.822]
</p><p>39 s  (5)  t  Registration of (t) to all voxel time courses S results in predictand data g(t) = [g1 (t), . [sent-87, score-0.655]
</p><p>40 , gS (t)]T , where g(t) is (t) registered onto voxel times-course f (t). [sent-90, score-0.413]
</p><p>41 Our motivation for using voxel-wise registration over standard convolution of stimulus (t) with the hemodynamic reponse function, is the large variability in hemodynamic delays across brain regions and subjects. [sent-91, score-0.811]
</p><p>42 A non -linear warp of (t) does not guarantee an outcome that is associated with brain physiology, however it allows to capture unknown subtle localized variations in hemodynamic delays across brain regions and subjects. [sent-92, score-0.83]
</p><p>43 (8)  Given a new (sub)set of voxel time courses, prediction of a stimulus pattern now reduces to computing the matrix of principal component scores from this new set and weighting these scores by the ˆ estimated regression functions β(t). [sent-106, score-0.822]
</p><p>44 For the voxel set S , S  (g s (t) − g(t))2 ¯  (9)  (g s (t) − g s (t))2 ˆ  (10)  gS (t) = ˙ s=1 S  gS (t) = ¨ s=1  are derived, where the ﬁrst term is the variation of the response about its mean and the second the error sum of squares function. [sent-110, score-0.54]
</p><p>45 Our objective is to ﬁnd the set of voxel time courses S deﬁned as S = max ∗ S ⊂S  RS ∗ (t)dt  (12)  t  where S ∗ denotes a subset of the entire collection of voxels time courses S extracted from a single fMRI scan. [sent-112, score-0.889]
</p><p>46 That is, we aim at ﬁnding spatially distributed voxel responses S that best explain the naturalistic stimuli, without making any prior assumptions about location and size of voxel subsets. [sent-113, score-1.142]
</p><p>47 A value of 1 for mns means that for solution n the corresponding voxel time course f s (t) is included in the predictor set, while a value 0 indicates exclusion. [sent-128, score-0.485]
</p><p>48 (13)  The learning parameter γ controls the search: a low value enables to focus entirely on the most recent voxel subset while a low value ensures that previously selected voxel subsets are exploited. [sent-131, score-0.826]
</p><p>49 In order to ensure spatial coherence and limit computation load, we employ the PBIl algorithm not on single time courses, but on averages of spatial clusters of voxel time courses. [sent-132, score-0.517]
</p><p>50 That is, we ﬁrst spatially cluster voxel locations as shown in Figure 1, then compute average time course for each cluster and then explore the averages via PBIL for model building. [sent-133, score-0.503]
</p><p>51 6  The Prediction  The subset of voxel time courses that results from population based incremental learning deﬁnes the most predictive voxel locations and associated regression functions. [sent-135, score-1.194]
</p><p>52 (14) ˜ In here, g(t) is the vector of predicted stimuli of which the mean is considered to be the sought stim˜ ulus. [sent-140, score-0.22]
</p><p>53 The matrix F is the principal component scores matrix obtained from performing functional ˜ principal components analysis on subset fS (t), with S referring to the set of most predictive voxels as determined by training. [sent-141, score-0.594]
</p><p>54 Figure 1: Examples of K-means clustering of voxel locations using Euclidean distance. [sent-142, score-0.443]
</p><p>55 Diﬀerent gray values indicate diﬀerent clusters in a spatially normalized brain atlas. [sent-145, score-0.431]
</p><p>56 1  Experiments and Results Experiment  Evaluation of our method is done on a data subset from the 2006 Pittsburgh brain activity interpretation competition (PBAIC) [6, 7], involving fMRI scans of three diﬀerent subjects and two movie sessions. [sent-147, score-0.858]
</p><p>57 In each session, a subject viewed a new Home Improvement sitcom movie for approximately 20 minutes. [sent-148, score-0.353]
</p><p>58 The 20-minute movie contained 5 interruptions where no video was present, only a white ﬁxation cross on a black background. [sent-149, score-0.433]
</p><p>59 The scans produced volumes with approximately 35,000 brain voxels, each approximately 3. [sent-151, score-0.367]
</p><p>60 These scans were preprocessed (motion correction, slice time correction, linear trend removal) and spatially normalized (non-linear registration to the Montreal Neurological Institute brain atlas). [sent-156, score-0.553]
</p><p>61 After fMRI scanning, the three subjects watched the movie again to rate 30 movie features at time intervals corresponding to the fMRI scan rate. [sent-157, score-0.787]
</p><p>62 In our experiments, we focus on the 13 core movie features: amusement, attention, arousal, body parts, environmental sounds, faces, food, language, laughter, motion, music, sadness and tools. [sent-158, score-0.343]
</p><p>63 The real-valued ratings were convolved with a hemodynamic response function (HRF) modeled by two gamma functions, then subjected to voxel-wise non-linear registration as described in 2. [sent-159, score-0.381]
</p><p>64 Taking into account the hemodynamic lag, we divided each fMRI scan and each subject rating into 6 parts corresponding with the movie on parts. [sent-162, score-0.6]
</p><p>65 On average each movie part contained 105 discrete measurements. [sent-163, score-0.307]
</p><p>66 This resulted in 18 data sets for training (3 subjects × 6 movie parts) and another 18 for testing. [sent-165, score-0.402]
</p><p>67 We used movie 1 data for training and movie 2 data for prediction, and vice versa. [sent-166, score-0.614]
</p><p>68 For each feature, ﬁrst the individual brain scans were analyzed with our method, resulting in a ﬁrst sifting of voxels. [sent-168, score-0.367]
</p><p>69 Pearson product-moment correlation coeﬃcient between manual feature rating functions and the automatically predicted feature functions was used as an evaluation measure. [sent-170, score-0.32]
</p><p>70 6 and K-means clustering with 1024 clusters for all movie features. [sent-173, score-0.375]
</p><p>71 These values for Q and γ produced overall highest average cross correlation value in a small parameter optimization experiment (data not shown here). [sent-174, score-0.212]
</p><p>72 Signiﬁcant performance diﬀerences across features, however, were observed for diﬀerent learning parameter values, indicating considerable variation in brain response to distinct stimuli. [sent-176, score-0.434]
</p><p>73 8  1  Figure 2: Left: normalized cross correlation values from cross-validation for 13 core movie features. [sent-188, score-0.555]
</p><p>74 Right: functionalized subject3 (solid red) and predicted (dotted blue) rating for the language feature of part 5 of movie 1. [sent-189, score-0.516]
</p><p>75 Figure 2 (left) shows the average of 2 × 18 cross correlation coeﬃcients from cross validation for all 13 movie features. [sent-190, score-0.645]
</p><p>76 For features faces, language and motion cross correlation values above 0. [sent-191, score-0.315]
</p><p>77 These entries used recurrent neural networks, ridge regression and a dynamic Gaussian Markov Random Field modeling on the entire test data benchmark, yielding across feature average cross correlations of: 0. [sent-195, score-0.241]
</p><p>78 Here, the feature average cross correlation value based on the reduced training data set is 0. [sent-199, score-0.247]
</p><p>79 76, was obtained for feature language of subject 3 watching part 5 of movie 1. [sent-204, score-0.503]
</p><p>80 For this feature, ﬁrst level analysis of each of the 18 training data sets associated with movie 2 produced a total number of 1738 predictive voxels. [sent-205, score-0.365]
</p><p>81 In the second level analysis, these voxels were analyzed again to arrive at a reduced data set of 680 voxels for building the multivariate functional linear model and determining regression functions β(t). [sent-206, score-0.568]
</p><p>82 For prediction of feature language, corresponding voxel time courses were extracted from the fMRI data of subject 3 watching movie 1 part 5, and weighted by β(t). [sent-207, score-1.072]
</p><p>83 The manual rating of feature language of movie 1 part 5 by subject 3 and the average of the automatically predicted feature functions are shown in Figure 2 (right). [sent-208, score-0.627]
</p><p>84 Color denotes predictive power and cross hair shows most predictive location. [sent-210, score-0.28]
</p><p>85 The cross hair shows the voxel location in Brodman area 47 that was found to be predictive across most subjects and movie parts: it was selected in 6 out of 18 training items (see color bar). [sent-212, score-1.098]
</p><p>86 The distributed nature of these clusters is consistent with earlier ﬁndings that processing involved in language occurs in diﬀuse brain regions, including primary auditory and visual cortex, frontal regions in the left and right hemisphere, in homologues regions [13]. [sent-214, score-0.52]
</p><p>87 To determine g s (t), we convolved (t) with 16 diﬀerent HRF functions, and selected the convolved one with highest cross correlation with f s (t) to be g s (t). [sent-224, score-0.286]
</p><p>88 Hence, non-linear warping of stimulus onto voxel time course signiﬁcantly enhances the predictive power of our model. [sent-230, score-0.621]
</p><p>89 This suggests that non-linear warping is a potential alternative for determining the best possible HRF estimate to overcome potential negative consequences of assuming HRF consistency across subjects or brain regions [14]. [sent-231, score-0.553]
</p><p>90 Figure 4: Left: normalized cross correlation values from cross-validation for 13 core movie features, using 1st order derivative data. [sent-232, score-0.555]
</p><p>91 Right: cross correlation values from cross-validation for 13 core movie features, using HRF convoluted rather than warped stimuli data. [sent-233, score-0.744]
</p><p>92 The advantage of functional data analysis for principal component analysis of fMRI data was recently demonstrated in [10]. [sent-235, score-0.296]
</p><p>93 Here, we proposed a functional linear model that treats fMRI and stimuli as stochastic functional measurements. [sent-236, score-0.476]
</p><p>94 Cast into an incremental pattern searching framework, the method provides the ability to identify important covariance structure  of spatially distributed brain responses and stimuli, i. [sent-237, score-0.587]
</p><p>95 it directly couples activation across brain regions rather than ﬁrst localizing and then integrating function. [sent-239, score-0.374]
</p><p>96 The method is suited for unbiased probing of functional characteristics of brain areas as well as for exposing meaningful relations between complex stimuli and distributed brain responses. [sent-240, score-0.955]
</p><p>97 This ﬁnding is supported by the good prediction performance of our method in the 2006 PBAIC international competition for brain activity interpretation. [sent-241, score-0.433]
</p><p>98 Predicting the orientation of invisible stimuli from activity in human primary visual cortex. [sent-253, score-0.227]
</p><p>99 Characterizing the response of pet and fmri data using multivariate linear models. [sent-306, score-0.572]
</p><p>100 Variation of bold hemodynamic response function across subjects and brain regions and their eﬀects on statistical analysis. [sent-342, score-0.656]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('fmri', 0.418), ('voxel', 0.413), ('movie', 0.307), ('brain', 0.303), ('courses', 0.184), ('hrf', 0.173), ('functional', 0.159), ('stimuli', 0.158), ('naturalistic', 0.138), ('cross', 0.126), ('hemodynamic', 0.122), ('voxels', 0.108), ('principal', 0.102), ('di', 0.097), ('registration', 0.096), ('subjects', 0.095), ('erent', 0.091), ('spatially', 0.09), ('multivariate', 0.089), ('correlation', 0.086), ('warping', 0.084), ('incremental', 0.078), ('pbil', 0.077), ('sq', 0.077), ('gs', 0.076), ('predictor', 0.072), ('language', 0.069), ('neuroimaging', 0.067), ('stimulus', 0.066), ('response', 0.065), ('scans', 0.064), ('predictive', 0.058), ('pbaic', 0.058), ('predictand', 0.058), ('responses', 0.056), ('competition', 0.049), ('regression', 0.048), ('parts', 0.046), ('watching', 0.046), ('subject', 0.046), ('faces', 0.043), ('prediction', 0.041), ('scan', 0.04), ('activity', 0.04), ('rating', 0.039), ('manual', 0.039), ('regions', 0.039), ('functionalized', 0.038), ('ghebreab', 0.038), ('hair', 0.038), ('haynes', 0.038), ('overlay', 0.038), ('undershoot', 0.038), ('viviani', 0.038), ('watched', 0.038), ('amsterdam', 0.038), ('netherlands', 0.038), ('clusters', 0.038), ('coe', 0.037), ('convolved', 0.037), ('dt', 0.036), ('core', 0.036), ('feature', 0.035), ('fs', 0.035), ('component', 0.035), ('variation', 0.034), ('informatics', 0.034), ('motion', 0.034), ('genetic', 0.034), ('arousal', 0.034), ('sought', 0.034), ('smeulders', 0.034), ('spatial', 0.033), ('adjusted', 0.033), ('across', 0.032), ('distributed', 0.032), ('subjected', 0.031), ('delays', 0.031), ('warped', 0.031), ('analyzers', 0.031), ('mitchell', 0.031), ('ratings', 0.03), ('scores', 0.03), ('continuous', 0.03), ('clustering', 0.03), ('human', 0.029), ('color', 0.029), ('functions', 0.029), ('glass', 0.029), ('lag', 0.029), ('actor', 0.029), ('localize', 0.029), ('pattern', 0.028), ('squares', 0.028), ('predicted', 0.028), ('neuroscience', 0.028), ('arrive', 0.027), ('lab', 0.027), ('neuroimage', 0.027), ('predicting', 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="154-tfidf-1" href="./nips-2007-Predicting_Brain_States_from_fMRI_Data%3A_Incremental_Functional_Principal_Component_Regression.html">154 nips-2007-Predicting Brain States from fMRI Data: Incremental Functional Principal Component Regression</a></p>
<p>Author: Sennay Ghebreab, Arnold Smeulders, Pieter Adriaans</p><p>Abstract: We propose a method for reconstruction of human brain states directly from functional neuroimaging data. The method extends the traditional multivariate regression analysis of discretized fMRI data to the domain of stochastic functional measurements, facilitating evaluation of brain responses to complex stimuli and boosting the power of functional imaging. The method searches for sets of voxel time courses that optimize a multivariate functional linear model in terms of R2 statistic. Population based incremental learning is used to identify spatially distributed brain responses to complex stimuli without attempting to localize function ﬁrst. Variation in hemodynamic lag across brain areas and among subjects is taken into account by voxel-wise non-linear registration of stimulus pattern to fMRI data. Application of the method on an international test benchmark for prediction of naturalistic stimuli from new and unknown fMRI data shows that the method successfully uncovers spatially distributed parts of the brain that are highly predictive of a given stimulus. 1</p><p>2 0.41535515 <a title="154-tfidf-2" href="./nips-2007-Locality_and_low-dimensions_in_the_prediction_of_natural_experience_from_fMRI.html">122 nips-2007-Locality and low-dimensions in the prediction of natural experience from fMRI</a></p>
<p>Author: Francois Meyer, Greg Stephens</p><p>Abstract: Functional Magnetic Resonance Imaging (fMRI) provides dynamical access into the complex functioning of the human brain, detailing the hemodynamic activity of thousands of voxels during hundreds of sequential time points. One approach towards illuminating the connection between fMRI and cognitive function is through decoding; how do the time series of voxel activities combine to provide information about internal and external experience? Here we seek models of fMRI decoding which are balanced between the simplicity of their interpretation and the effectiveness of their prediction. We use signals from a subject immersed in virtual reality to compare global and local methods of prediction applying both linear and nonlinear techniques of dimensionality reduction. We ﬁnd that the prediction of complex stimuli is remarkably low-dimensional, saturating with less than 100 features. In particular, we build effective models based on the decorrelated components of cognitive activity in the classically-deﬁned Brodmann areas. For some of the stimuli, the top predictive areas were surprisingly transparent, including Wernicke’s area for verbal instructions, visual cortex for facial and body features, and visual-temporal regions for velocity. Direct sensory experience resulted in the most robust predictions, with the highest correlation (c ∼ 0.8) between the predicted and experienced time series of verbal instructions. Techniques based on non-linear dimensionality reduction (Laplacian eigenmaps) performed similarly. The interpretability and relative simplicity of our approach provides a conceptual basis upon which to build more sophisticated techniques for fMRI decoding and offers a window into cognitive function during dynamic, natural experience. 1</p><p>3 0.15918052 <a title="154-tfidf-3" href="./nips-2007-Continuous_Time_Particle_Filtering_for_fMRI.html">59 nips-2007-Continuous Time Particle Filtering for fMRI</a></p>
<p>Author: Lawrence Murray, Amos J. Storkey</p><p>Abstract: We construct a biologically motivated stochastic differential model of the neural and hemodynamic activity underlying the observed Blood Oxygen Level Dependent (BOLD) signal in Functional Magnetic Resonance Imaging (fMRI). The model poses a difﬁcult parameter estimation problem, both theoretically due to the nonlinearity and divergence of the differential system, and computationally due to its time and space complexity. We adapt a particle ﬁlter and smoother to the task, and discuss some of the practical approaches used to tackle the difﬁculties, including use of sparse matrices and parallelisation. Results demonstrate the tractability of the approach in its application to an effective connectivity study. 1</p><p>4 0.099084124 <a title="154-tfidf-4" href="./nips-2007-Supervised_Topic_Models.html">189 nips-2007-Supervised Topic Models</a></p>
<p>Author: Jon D. Mcauliffe, David M. Blei</p><p>Abstract: We introduce supervised latent Dirichlet allocation (sLDA), a statistical model of labelled documents. The model accommodates a variety of response types. We derive a maximum-likelihood procedure for parameter estimation, which relies on variational approximations to handle intractable posterior expectations. Prediction problems motivate this research: we use the ﬁtted model to predict response values for new documents. We test sLDA on two real-world problems: movie ratings predicted from reviews, and web page popularity predicted from text descriptions. We illustrate the beneﬁts of sLDA versus modern regularized regression, as well as versus an unsupervised LDA analysis followed by a separate regression. 1</p><p>5 0.083414696 <a title="154-tfidf-5" href="./nips-2007-Receptive_Fields_without_Spike-Triggering.html">164 nips-2007-Receptive Fields without Spike-Triggering</a></p>
<p>Author: Guenther Zeck, Matthias Bethge, Jakob H. Macke</p><p>Abstract: S timulus selectivity of sensory neurons is often characterized by estimating their receptive ﬁeld properties such as orientation selectivity. Receptive ﬁelds are usually derived from the mean (or covariance) of the spike-triggered stimulus ensemble. This approach treats each spike as an independent message but does not take into account that information might be conveyed through patterns of neural activity that are distributed across space or time. Can we ﬁnd a concise description for the processing of a whole population of neurons analogous to the receptive ﬁeld for single neurons? Here, we present a generalization of the linear receptive ﬁeld which is not bound to be triggered on individual spikes but can be meaningfully linked to distributed response patterns. More precisely, we seek to identify those stimulus features and the corresponding patterns of neural activity that are most reliably coupled. We use an extension of reverse-correlation methods based on canonical correlation analysis. The resulting population receptive ﬁelds span the subspace of stimuli that is most informative about the population response. We evaluate our approach using both neuronal models and multi-electrode recordings from rabbit retinal ganglion cells. We show how the model can be extended to capture nonlinear stimulus-response relationships using kernel canonical correlation analysis, which makes it possible to test different coding mechanisms. Our technique can also be used to calculate receptive ﬁelds from multi-dimensional neural measurements such as those obtained from dynamic imaging methods. 1</p><p>6 0.077878572 <a title="154-tfidf-6" href="./nips-2007-Second_Order_Bilinear_Discriminant_Analysis_for_single_trial_EEG_analysis.html">173 nips-2007-Second Order Bilinear Discriminant Analysis for single trial EEG analysis</a></p>
<p>7 0.074769117 <a title="154-tfidf-7" href="./nips-2007-Invariant_Common_Spatial_Patterns%3A_Alleviating_Nonstationarities_in_Brain-Computer_Interfacing.html">106 nips-2007-Invariant Common Spatial Patterns: Alleviating Nonstationarities in Brain-Computer Interfacing</a></p>
<p>8 0.070609972 <a title="154-tfidf-8" href="./nips-2007-Neural_characterization_in_partially_observed_populations_of_spiking_neurons.html">140 nips-2007-Neural characterization in partially observed populations of spiking neurons</a></p>
<p>9 0.069656372 <a title="154-tfidf-9" href="./nips-2007-Markov_Chain_Monte_Carlo_with_People.html">125 nips-2007-Markov Chain Monte Carlo with People</a></p>
<p>10 0.068495154 <a title="154-tfidf-10" href="./nips-2007-EEG-Based_Brain-Computer_Interaction%3A_Improved_Accuracy_by_Automatic_Single-Trial_Error_Detection.html">74 nips-2007-EEG-Based Brain-Computer Interaction: Improved Accuracy by Automatic Single-Trial Error Detection</a></p>
<p>11 0.064536899 <a title="154-tfidf-11" href="./nips-2007-A_Bayesian_Model_of_Conditioned_Perception.html">3 nips-2007-A Bayesian Model of Conditioned Perception</a></p>
<p>12 0.063348584 <a title="154-tfidf-12" href="./nips-2007-Sparse_deep_belief_net_model_for_visual_area_V2.html">182 nips-2007-Sparse deep belief net model for visual area V2</a></p>
<p>13 0.062897295 <a title="154-tfidf-13" href="./nips-2007-Probabilistic_Matrix_Factorization.html">158 nips-2007-Probabilistic Matrix Factorization</a></p>
<p>14 0.061815865 <a title="154-tfidf-14" href="./nips-2007-Experience-Guided_Search%3A_A_Theory_of_Attentional_Control.html">85 nips-2007-Experience-Guided Search: A Theory of Attentional Control</a></p>
<p>15 0.061211582 <a title="154-tfidf-15" href="./nips-2007-A_probabilistic_model_for_generating_realistic_lip_movements_from_speech.html">18 nips-2007-A probabilistic model for generating realistic lip movements from speech</a></p>
<p>16 0.060107544 <a title="154-tfidf-16" href="./nips-2007-GRIFT%3A_A_graphical_model_for_inferring_visual_classification_features_from_human_data.html">93 nips-2007-GRIFT: A graphical model for inferring visual classification features from human data</a></p>
<p>17 0.059630886 <a title="154-tfidf-17" href="./nips-2007-Bayesian_Inference_for_Spiking_Neuron_Models_with_a_Sparsity_Prior.html">33 nips-2007-Bayesian Inference for Spiking Neuron Models with a Sparsity Prior</a></p>
<p>18 0.056643166 <a title="154-tfidf-18" href="./nips-2007-Comparing_Bayesian_models_for_multisensory_cue_combination_without_mandatory_integration.html">51 nips-2007-Comparing Bayesian models for multisensory cue combination without mandatory integration</a></p>
<p>19 0.055706669 <a title="154-tfidf-19" href="./nips-2007-Inferring_Elapsed_Time_from_Stochastic_Neural_Processes.html">103 nips-2007-Inferring Elapsed Time from Stochastic Neural Processes</a></p>
<p>20 0.053804737 <a title="154-tfidf-20" href="./nips-2007-Predicting_human_gaze_using_low-level_saliency_combined_with_face_detection.html">155 nips-2007-Predicting human gaze using low-level saliency combined with face detection</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2007_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.172), (1, 0.083), (2, 0.081), (3, -0.069), (4, 0.012), (5, 0.168), (6, 0.033), (7, 0.151), (8, -0.147), (9, -0.107), (10, -0.093), (11, -0.037), (12, 0.037), (13, 0.008), (14, 0.236), (15, 0.053), (16, -0.001), (17, -0.153), (18, 0.12), (19, 0.242), (20, 0.053), (21, -0.01), (22, -0.15), (23, -0.186), (24, -0.088), (25, 0.246), (26, -0.142), (27, -0.031), (28, -0.26), (29, 0.015), (30, -0.139), (31, -0.036), (32, 0.028), (33, 0.134), (34, -0.144), (35, 0.056), (36, -0.099), (37, -0.016), (38, -0.09), (39, 0.019), (40, 0.042), (41, -0.054), (42, 0.066), (43, -0.097), (44, 0.017), (45, -0.021), (46, -0.041), (47, 0.008), (48, 0.02), (49, 0.052)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96815634 <a title="154-lsi-1" href="./nips-2007-Predicting_Brain_States_from_fMRI_Data%3A_Incremental_Functional_Principal_Component_Regression.html">154 nips-2007-Predicting Brain States from fMRI Data: Incremental Functional Principal Component Regression</a></p>
<p>Author: Sennay Ghebreab, Arnold Smeulders, Pieter Adriaans</p><p>Abstract: We propose a method for reconstruction of human brain states directly from functional neuroimaging data. The method extends the traditional multivariate regression analysis of discretized fMRI data to the domain of stochastic functional measurements, facilitating evaluation of brain responses to complex stimuli and boosting the power of functional imaging. The method searches for sets of voxel time courses that optimize a multivariate functional linear model in terms of R2 statistic. Population based incremental learning is used to identify spatially distributed brain responses to complex stimuli without attempting to localize function ﬁrst. Variation in hemodynamic lag across brain areas and among subjects is taken into account by voxel-wise non-linear registration of stimulus pattern to fMRI data. Application of the method on an international test benchmark for prediction of naturalistic stimuli from new and unknown fMRI data shows that the method successfully uncovers spatially distributed parts of the brain that are highly predictive of a given stimulus. 1</p><p>2 0.91866225 <a title="154-lsi-2" href="./nips-2007-Locality_and_low-dimensions_in_the_prediction_of_natural_experience_from_fMRI.html">122 nips-2007-Locality and low-dimensions in the prediction of natural experience from fMRI</a></p>
<p>Author: Francois Meyer, Greg Stephens</p><p>Abstract: Functional Magnetic Resonance Imaging (fMRI) provides dynamical access into the complex functioning of the human brain, detailing the hemodynamic activity of thousands of voxels during hundreds of sequential time points. One approach towards illuminating the connection between fMRI and cognitive function is through decoding; how do the time series of voxel activities combine to provide information about internal and external experience? Here we seek models of fMRI decoding which are balanced between the simplicity of their interpretation and the effectiveness of their prediction. We use signals from a subject immersed in virtual reality to compare global and local methods of prediction applying both linear and nonlinear techniques of dimensionality reduction. We ﬁnd that the prediction of complex stimuli is remarkably low-dimensional, saturating with less than 100 features. In particular, we build effective models based on the decorrelated components of cognitive activity in the classically-deﬁned Brodmann areas. For some of the stimuli, the top predictive areas were surprisingly transparent, including Wernicke’s area for verbal instructions, visual cortex for facial and body features, and visual-temporal regions for velocity. Direct sensory experience resulted in the most robust predictions, with the highest correlation (c ∼ 0.8) between the predicted and experienced time series of verbal instructions. Techniques based on non-linear dimensionality reduction (Laplacian eigenmaps) performed similarly. The interpretability and relative simplicity of our approach provides a conceptual basis upon which to build more sophisticated techniques for fMRI decoding and offers a window into cognitive function during dynamic, natural experience. 1</p><p>3 0.54489428 <a title="154-lsi-3" href="./nips-2007-Continuous_Time_Particle_Filtering_for_fMRI.html">59 nips-2007-Continuous Time Particle Filtering for fMRI</a></p>
<p>Author: Lawrence Murray, Amos J. Storkey</p><p>Abstract: We construct a biologically motivated stochastic differential model of the neural and hemodynamic activity underlying the observed Blood Oxygen Level Dependent (BOLD) signal in Functional Magnetic Resonance Imaging (fMRI). The model poses a difﬁcult parameter estimation problem, both theoretically due to the nonlinearity and divergence of the differential system, and computationally due to its time and space complexity. We adapt a particle ﬁlter and smoother to the task, and discuss some of the practical approaches used to tackle the difﬁculties, including use of sparse matrices and parallelisation. Results demonstrate the tractability of the approach in its application to an effective connectivity study. 1</p><p>4 0.28593323 <a title="154-lsi-4" href="./nips-2007-Feature_Selection_Methods_for_Improving_Protein_Structure_Prediction_with_Rosetta.html">89 nips-2007-Feature Selection Methods for Improving Protein Structure Prediction with Rosetta</a></p>
<p>Author: Ben Blum, Rhiju Das, Philip Bradley, David Baker, Michael I. Jordan, David Tax</p><p>Abstract: Rosetta is one of the leading algorithms for protein structure prediction today. It is a Monte Carlo energy minimization method requiring many random restarts to ﬁnd structures with low energy. In this paper we present a resampling technique for structure prediction of small alpha/beta proteins using Rosetta. From an initial round of Rosetta sampling, we learn properties of the energy landscape that guide a subsequent round of sampling toward lower-energy structures. Rather than attempt to ﬁt the full energy landscape, we use feature selection methods—both L1-regularized linear regression and decision trees—to identify structural features that give rise to low energy. We then enrich these structural features in the second sampling round. Results are presented across a benchmark set of nine small alpha/beta proteins demonstrating that our methods seldom impair, and frequently improve, Rosetta’s performance. 1</p><p>5 0.27978548 <a title="154-lsi-5" href="./nips-2007-Probabilistic_Matrix_Factorization.html">158 nips-2007-Probabilistic Matrix Factorization</a></p>
<p>Author: Andriy Mnih, Ruslan Salakhutdinov</p><p>Abstract: Many existing approaches to collaborative ﬁltering can neither handle very large datasets nor easily deal with users who have very few ratings. In this paper we present the Probabilistic Matrix Factorization (PMF) model which scales linearly with the number of observations and, more importantly, performs well on the large, sparse, and very imbalanced Netﬂix dataset. We further extend the PMF model to include an adaptive prior on the model parameters and show how the model capacity can be controlled automatically. Finally, we introduce a constrained version of the PMF model that is based on the assumption that users who have rated similar sets of movies are likely to have similar preferences. The resulting model is able to generalize considerably better for users with very few ratings. When the predictions of multiple PMF models are linearly combined with the predictions of Restricted Boltzmann Machines models, we achieve an error rate of 0.8861, that is nearly 7% better than the score of Netﬂix’s own system.</p><p>6 0.26870051 <a title="154-lsi-6" href="./nips-2007-GRIFT%3A_A_graphical_model_for_inferring_visual_classification_features_from_human_data.html">93 nips-2007-GRIFT: A graphical model for inferring visual classification features from human data</a></p>
<p>7 0.25477719 <a title="154-lsi-7" href="./nips-2007-Receptive_Fields_without_Spike-Triggering.html">164 nips-2007-Receptive Fields without Spike-Triggering</a></p>
<p>8 0.24122794 <a title="154-lsi-8" href="./nips-2007-EEG-Based_Brain-Computer_Interaction%3A_Improved_Accuracy_by_Automatic_Single-Trial_Error_Detection.html">74 nips-2007-EEG-Based Brain-Computer Interaction: Improved Accuracy by Automatic Single-Trial Error Detection</a></p>
<p>9 0.24033339 <a title="154-lsi-9" href="./nips-2007-Supervised_Topic_Models.html">189 nips-2007-Supervised Topic Models</a></p>
<p>10 0.2247275 <a title="154-lsi-10" href="./nips-2007-Invariant_Common_Spatial_Patterns%3A_Alleviating_Nonstationarities_in_Brain-Computer_Interfacing.html">106 nips-2007-Invariant Common Spatial Patterns: Alleviating Nonstationarities in Brain-Computer Interfacing</a></p>
<p>11 0.22412421 <a title="154-lsi-11" href="./nips-2007-A_Bayesian_Model_of_Conditioned_Perception.html">3 nips-2007-A Bayesian Model of Conditioned Perception</a></p>
<p>12 0.22345139 <a title="154-lsi-12" href="./nips-2007-Predictive_Matrix-Variate_t_Models.html">156 nips-2007-Predictive Matrix-Variate t Models</a></p>
<p>13 0.22046635 <a title="154-lsi-13" href="./nips-2007-Bayesian_Inference_for_Spiking_Neuron_Models_with_a_Sparsity_Prior.html">33 nips-2007-Bayesian Inference for Spiking Neuron Models with a Sparsity Prior</a></p>
<p>14 0.2181422 <a title="154-lsi-14" href="./nips-2007-An_online_Hebbian_learning_rule_that_performs_Independent_Component_Analysis.html">26 nips-2007-An online Hebbian learning rule that performs Independent Component Analysis</a></p>
<p>15 0.21676815 <a title="154-lsi-15" href="./nips-2007-Scan_Strategies_for_Meteorological_Radars.html">171 nips-2007-Scan Strategies for Meteorological Radars</a></p>
<p>16 0.21490875 <a title="154-lsi-16" href="./nips-2007-Second_Order_Bilinear_Discriminant_Analysis_for_single_trial_EEG_analysis.html">173 nips-2007-Second Order Bilinear Discriminant Analysis for single trial EEG analysis</a></p>
<p>17 0.21344511 <a title="154-lsi-17" href="./nips-2007-Subspace-Based_Face_Recognition_in_Analog_VLSI.html">188 nips-2007-Subspace-Based Face Recognition in Analog VLSI</a></p>
<p>18 0.21146709 <a title="154-lsi-18" href="./nips-2007-Active_Preference_Learning_with_Discrete_Choice_Data.html">19 nips-2007-Active Preference Learning with Discrete Choice Data</a></p>
<p>19 0.21035883 <a title="154-lsi-19" href="./nips-2007-Measuring_Neural_Synchrony_by_Message_Passing.html">127 nips-2007-Measuring Neural Synchrony by Message Passing</a></p>
<p>20 0.20751932 <a title="154-lsi-20" href="./nips-2007-Congruence_between_model_and_human_attention_reveals_unique_signatures_of_critical_visual_events.html">57 nips-2007-Congruence between model and human attention reveals unique signatures of critical visual events</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2007_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.035), (13, 0.033), (16, 0.044), (18, 0.034), (19, 0.013), (21, 0.068), (34, 0.022), (35, 0.027), (47, 0.1), (49, 0.019), (50, 0.275), (83, 0.095), (87, 0.067), (90, 0.074)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.7937597 <a title="154-lda-1" href="./nips-2007-Regulator_Discovery_from_Gene_Expression_Time_Series_of_Malaria_Parasites%3A_a_Hierachical_Approach.html">167 nips-2007-Regulator Discovery from Gene Expression Time Series of Malaria Parasites: a Hierachical Approach</a></p>
<p>Author: José M. Hernández-lobato, Tjeerd Dijkstra, Tom Heskes</p><p>Abstract: We introduce a hierarchical Bayesian model for the discovery of putative regulators from gene expression data only. The hierarchy incorporates the knowledge that there are just a few regulators that by themselves only regulate a handful of genes. This is implemented through a so-called spike-and-slab prior, a mixture of Gaussians with different widths, with mixing weights from a hierarchical Bernoulli model. For efﬁcient inference we implemented expectation propagation. Running the model on a malaria parasite data set, we found four genes with signiﬁcant homology to transcription factors in an amoebe, one RNA regulator and three genes of unknown function (out of the top ten genes considered).</p><p>same-paper 2 0.759565 <a title="154-lda-2" href="./nips-2007-Predicting_Brain_States_from_fMRI_Data%3A_Incremental_Functional_Principal_Component_Regression.html">154 nips-2007-Predicting Brain States from fMRI Data: Incremental Functional Principal Component Regression</a></p>
<p>Author: Sennay Ghebreab, Arnold Smeulders, Pieter Adriaans</p><p>Abstract: We propose a method for reconstruction of human brain states directly from functional neuroimaging data. The method extends the traditional multivariate regression analysis of discretized fMRI data to the domain of stochastic functional measurements, facilitating evaluation of brain responses to complex stimuli and boosting the power of functional imaging. The method searches for sets of voxel time courses that optimize a multivariate functional linear model in terms of R2 statistic. Population based incremental learning is used to identify spatially distributed brain responses to complex stimuli without attempting to localize function ﬁrst. Variation in hemodynamic lag across brain areas and among subjects is taken into account by voxel-wise non-linear registration of stimulus pattern to fMRI data. Application of the method on an international test benchmark for prediction of naturalistic stimuli from new and unknown fMRI data shows that the method successfully uncovers spatially distributed parts of the brain that are highly predictive of a given stimulus. 1</p><p>3 0.54613674 <a title="154-lda-3" href="./nips-2007-Continuous_Time_Particle_Filtering_for_fMRI.html">59 nips-2007-Continuous Time Particle Filtering for fMRI</a></p>
<p>Author: Lawrence Murray, Amos J. Storkey</p><p>Abstract: We construct a biologically motivated stochastic differential model of the neural and hemodynamic activity underlying the observed Blood Oxygen Level Dependent (BOLD) signal in Functional Magnetic Resonance Imaging (fMRI). The model poses a difﬁcult parameter estimation problem, both theoretically due to the nonlinearity and divergence of the differential system, and computationally due to its time and space complexity. We adapt a particle ﬁlter and smoother to the task, and discuss some of the practical approaches used to tackle the difﬁculties, including use of sparse matrices and parallelisation. Results demonstrate the tractability of the approach in its application to an effective connectivity study. 1</p><p>4 0.54512656 <a title="154-lda-4" href="./nips-2007-Supervised_Topic_Models.html">189 nips-2007-Supervised Topic Models</a></p>
<p>Author: Jon D. Mcauliffe, David M. Blei</p><p>Abstract: We introduce supervised latent Dirichlet allocation (sLDA), a statistical model of labelled documents. The model accommodates a variety of response types. We derive a maximum-likelihood procedure for parameter estimation, which relies on variational approximations to handle intractable posterior expectations. Prediction problems motivate this research: we use the ﬁtted model to predict response values for new documents. We test sLDA on two real-world problems: movie ratings predicted from reviews, and web page popularity predicted from text descriptions. We illustrate the beneﬁts of sLDA versus modern regularized regression, as well as versus an unsupervised LDA analysis followed by a separate regression. 1</p><p>5 0.53826362 <a title="154-lda-5" href="./nips-2007-Distributed_Inference_for_Latent_Dirichlet_Allocation.html">73 nips-2007-Distributed Inference for Latent Dirichlet Allocation</a></p>
<p>Author: David Newman, Padhraic Smyth, Max Welling, Arthur U. Asuncion</p><p>Abstract: We investigate the problem of learning a widely-used latent-variable model – the Latent Dirichlet Allocation (LDA) or “topic” model – using distributed computation, where each of processors only sees of the total data set. We propose two distributed inference schemes that are motivated from different perspectives. The ﬁrst scheme uses local Gibbs sampling on each processor with periodic updates—it is simple to implement and can be viewed as an approximation to a single processor implementation of Gibbs sampling. The second scheme relies on a hierarchical Bayesian extension of the standard LDA model to directly account for the fact that data are distributed across processors—it has a theoretical guarantee of convergence but is more complex to implement than the approximate method. Using ﬁve real-world text corpora we show that distributed learning works very well for LDA models, i.e., perplexity and precision-recall scores for distributed learning are indistinguishable from those obtained with single-processor learning. Our extensive experimental results include large-scale distributed computation on 1000 virtual processors; and speedup experiments of learning topics in a 100-million word corpus using 16 processors. ¢ ¤ ¦¥£ ¢ ¢</p><p>6 0.53754121 <a title="154-lda-6" href="./nips-2007-People_Tracking_with_the_Laplacian_Eigenmaps_Latent_Variable_Model.html">153 nips-2007-People Tracking with the Laplacian Eigenmaps Latent Variable Model</a></p>
<p>7 0.53696525 <a title="154-lda-7" href="./nips-2007-GRIFT%3A_A_graphical_model_for_inferring_visual_classification_features_from_human_data.html">93 nips-2007-GRIFT: A graphical model for inferring visual classification features from human data</a></p>
<p>8 0.52663416 <a title="154-lda-8" href="./nips-2007-Collapsed_Variational_Inference_for_HDP.html">47 nips-2007-Collapsed Variational Inference for HDP</a></p>
<p>9 0.52661818 <a title="154-lda-9" href="./nips-2007-A_probabilistic_model_for_generating_realistic_lip_movements_from_speech.html">18 nips-2007-A probabilistic model for generating realistic lip movements from speech</a></p>
<p>10 0.52443171 <a title="154-lda-10" href="./nips-2007-Locality_and_low-dimensions_in_the_prediction_of_natural_experience_from_fMRI.html">122 nips-2007-Locality and low-dimensions in the prediction of natural experience from fMRI</a></p>
<p>11 0.52096039 <a title="154-lda-11" href="./nips-2007-Neural_characterization_in_partially_observed_populations_of_spiking_neurons.html">140 nips-2007-Neural characterization in partially observed populations of spiking neurons</a></p>
<p>12 0.52075088 <a title="154-lda-12" href="./nips-2007-A_Bayesian_LDA-based_model_for_semi-supervised_part-of-speech_tagging.html">2 nips-2007-A Bayesian LDA-based model for semi-supervised part-of-speech tagging</a></p>
<p>13 0.52038366 <a title="154-lda-13" href="./nips-2007-Near-Maximum_Entropy_Models_for_Binary_Neural_Representations_of_Natural_Images.html">138 nips-2007-Near-Maximum Entropy Models for Binary Neural Representations of Natural Images</a></p>
<p>14 0.52016634 <a title="154-lda-14" href="./nips-2007-The_Generalized_FITC_Approximation.html">195 nips-2007-The Generalized FITC Approximation</a></p>
<p>15 0.51853794 <a title="154-lda-15" href="./nips-2007-Sparse_Feature_Learning_for_Deep_Belief_Networks.html">180 nips-2007-Sparse Feature Learning for Deep Belief Networks</a></p>
<p>16 0.5181945 <a title="154-lda-16" href="./nips-2007-The_discriminant_center-surround_hypothesis_for_bottom-up_saliency.html">202 nips-2007-The discriminant center-surround hypothesis for bottom-up saliency</a></p>
<p>17 0.51770753 <a title="154-lda-17" href="./nips-2007-Infinite_State_Bayes-Nets_for_Structured_Domains.html">105 nips-2007-Infinite State Bayes-Nets for Structured Domains</a></p>
<p>18 0.51732492 <a title="154-lda-18" href="./nips-2007-Scene_Segmentation_with_CRFs_Learned_from_Partially_Labeled_Images.html">172 nips-2007-Scene Segmentation with CRFs Learned from Partially Labeled Images</a></p>
<p>19 0.51636505 <a title="154-lda-19" href="./nips-2007-Predictive_Matrix-Variate_t_Models.html">156 nips-2007-Predictive Matrix-Variate t Models</a></p>
<p>20 0.51592511 <a title="154-lda-20" href="./nips-2007-Receptive_Fields_without_Spike-Triggering.html">164 nips-2007-Receptive Fields without Spike-Triggering</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
