<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>56 nips-2007-Configuration Estimates Improve Pedestrian Finding</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-56" href="#">nips2007-56</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>56 nips-2007-Configuration Estimates Improve Pedestrian Finding</h1>
<br/><p>Source: <a title="nips-2007-56-pdf" href="http://papers.nips.cc/paper/3210-configuration-estimates-improve-pedestrian-finding.pdf">pdf</a></p><p>Author: Duan Tran, David A. Forsyth</p><p>Abstract: Fair discriminative pedestrian ﬁnders are now available. In fact, these pedestrian ﬁnders make most errors on pedestrians in conﬁgurations that are uncommon in the training data, for example, mounting a bicycle. This is undesirable. However, the human conﬁguration can itself be estimated discriminatively using structure learning. We demonstrate a pedestrian ﬁnder which ﬁrst ﬁnds the most likely human pose in the window using a discriminative procedure trained with structure learning on a small dataset. We then present features (local histogram of oriented gradient and local PCA of gradient) based on that conﬁguration to an SVM classiﬁer. We show, using the INRIA Person dataset, that estimates of conﬁguration signiﬁcantly improve the accuracy of a discriminative pedestrian ﬁnder. 1</p><p>Reference: <a title="nips-2007-56-reference" href="../nips2007_reference/nips-2007-Configuration_Estimates_Improve_Pedestrian_Finding_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('pedest', 0.755), ('detect', 0.272), ('window', 0.208), ('fppw', 0.157), ('gur', 0.15), ('dal', 0.147), ('hog', 0.125), ('con', 0.121), ('scan', 0.117), ('leg', 0.112), ('fppi', 0.11), ('seg', 0.096), ('trig', 0.096), ('body', 0.092), ('mor', 0.088), ('im', 0.083), ('torso', 0.082), ('sabzmeydan', 0.079), ('ory', 0.07), ('feat', 0.066)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="56-tfidf-1" href="./nips-2007-Configuration_Estimates_Improve_Pedestrian_Finding.html">56 nips-2007-Configuration Estimates Improve Pedestrian Finding</a></p>
<p>Author: Duan Tran, David A. Forsyth</p><p>Abstract: Fair discriminative pedestrian ﬁnders are now available. In fact, these pedestrian ﬁnders make most errors on pedestrians in conﬁgurations that are uncommon in the training data, for example, mounting a bicycle. This is undesirable. However, the human conﬁguration can itself be estimated discriminatively using structure learning. We demonstrate a pedestrian ﬁnder which ﬁrst ﬁnds the most likely human pose in the window using a discriminative procedure trained with structure learning on a small dataset. We then present features (local histogram of oriented gradient and local PCA of gradient) based on that conﬁguration to an SVM classiﬁer. We show, using the INRIA Person dataset, that estimates of conﬁguration signiﬁcantly improve the accuracy of a discriminative pedestrian ﬁnder. 1</p><p>2 0.16772239 <a title="56-tfidf-2" href="./nips-2007-Multiple-Instance_Pruning_For_Learning_Efficient_Cascade_Detectors.html">137 nips-2007-Multiple-Instance Pruning For Learning Efficient Cascade Detectors</a></p>
<p>Author: Cha Zhang, Paul A. Viola</p><p>Abstract: Cascade detectors have been shown to operate extremely rapidly, with high accuracy, and have important applications such as face detection. Driven by this success, cascade learning has been an area of active research in recent years. Nevertheless, there are still challenging technical problems during the training process of cascade detectors. In particular, determining the optimal target detection rate for each stage of the cascade remains an unsolved issue. In this paper, we propose the multiple instance pruning (MIP) algorithm for soft cascades. This algorithm computes a set of thresholds which aggressively terminate computation with no reduction in detection rate or increase in false positive rate on the training dataset. The algorithm is based on two key insights: i) examples that are destined to be rejected by the complete classiﬁer can be safely pruned early; ii) face detection is a multiple instance learning problem. The MIP process is fully automatic and requires no assumptions of probability distributions, statistical independence, or ad hoc intermediate rejection targets. Experimental results on the MIT+CMU dataset demonstrate signiﬁcant performance advantages. 1</p><p>3 0.13696709 <a title="56-tfidf-3" href="./nips-2007-Object_Recognition_by_Scene_Alignment.html">143 nips-2007-Object Recognition by Scene Alignment</a></p>
<p>Author: Bryan Russell, Antonio Torralba, Ce Liu, Rob Fergus, William T. Freeman</p><p>Abstract: Current object recognition systems can only recognize a limited number of object categories; scaling up to many categories is the next challenge. We seek to build a system to recognize and localize many different object categories in complex scenes. We achieve this through a simple approach: by matching the input image, in an appropriate representation, to images in a large training set of labeled images. Due to regularities in object identities across similar scenes, the retrieved matches provide hypotheses for object identities and locations. We build a probabilistic model to transfer the labels from the retrieval set to the input image. We demonstrate the effectiveness of this approach and study algorithm component contributions using held-out test sets from the LabelMe database. 1</p><p>4 0.11436895 <a title="56-tfidf-4" href="./nips-2007-Learning_Visual_Attributes.html">113 nips-2007-Learning Visual Attributes</a></p>
<p>Author: Vittorio Ferrari, Andrew Zisserman</p><p>Abstract: We present a probabilistic generative model of visual attributes, together with an efﬁcient learning algorithm. Attributes are visual qualities of objects, such as ‘red’, ‘striped’, or ‘spotted’. The model sees attributes as patterns of image segments, repeatedly sharing some characteristic properties. These can be any combination of appearance, shape, or the layout of segments within the pattern. Moreover, attributes with general appearance are taken into account, such as the pattern of alternation of any two colors which is characteristic for stripes. To enable learning from unsegmented training images, the model is learnt discriminatively, by optimizing a likelihood ratio. As demonstrated in the experimental evaluation, our model can learn in a weakly supervised setting and encompasses a broad range of attributes. We show that attributes can be learnt starting from a text query to Google image search, and can then be used to recognize the attribute and determine its spatial extent in novel real-world images.</p><p>5 0.10611966 <a title="56-tfidf-5" href="./nips-2007-GRIFT%3A_A_graphical_model_for_inferring_visual_classification_features_from_human_data.html">93 nips-2007-GRIFT: A graphical model for inferring visual classification features from human data</a></p>
<p>Author: Michael Ross, Andrew Cohen</p><p>Abstract: This paper describes a new model for human visual classiﬁcation that enables the recovery of image features that explain human subjects’ performance on different visual classiﬁcation tasks. Unlike previous methods, this algorithm does not model their performance with a single linear classiﬁer operating on raw image pixels. Instead, it represents classiﬁcation as the combination of multiple feature detectors. This approach extracts more information about human visual classiﬁcation than previous methods and provides a foundation for further exploration. 1</p><p>6 0.10428327 <a title="56-tfidf-6" href="./nips-2007-Combined_discriminative_and_generative_articulated_pose_and_non-rigid_shape_estimation.html">50 nips-2007-Combined discriminative and generative articulated pose and non-rigid shape estimation</a></p>
<p>7 0.081397139 <a title="56-tfidf-7" href="./nips-2007-Scan_Strategies_for_Meteorological_Radars.html">171 nips-2007-Scan Strategies for Meteorological Radars</a></p>
<p>8 0.070680842 <a title="56-tfidf-8" href="./nips-2007-Congruence_between_model_and_human_attention_reveals_unique_signatures_of_critical_visual_events.html">57 nips-2007-Congruence between model and human attention reveals unique signatures of critical visual events</a></p>
<p>9 0.069210365 <a title="56-tfidf-9" href="./nips-2007-Predicting_human_gaze_using_low-level_saliency_combined_with_face_detection.html">155 nips-2007-Predicting human gaze using low-level saliency combined with face detection</a></p>
<p>10 0.06368003 <a title="56-tfidf-10" href="./nips-2007-The_discriminant_center-surround_hypothesis_for_bottom-up_saliency.html">202 nips-2007-The discriminant center-surround hypothesis for bottom-up saliency</a></p>
<p>11 0.056564622 <a title="56-tfidf-11" href="./nips-2007-Nearest-Neighbor-Based_Active_Learning_for_Rare_Category_Detection.html">139 nips-2007-Nearest-Neighbor-Based Active Learning for Rare Category Detection</a></p>
<p>12 0.054940637 <a title="56-tfidf-12" href="./nips-2007-A_Risk_Minimization_Principle_for_a_Class_of_Parzen_Estimators.html">11 nips-2007-A Risk Minimization Principle for a Class of Parzen Estimators</a></p>
<p>13 0.054346684 <a title="56-tfidf-13" href="./nips-2007-EEG-Based_Brain-Computer_Interaction%3A_Improved_Accuracy_by_Automatic_Single-Trial_Error_Detection.html">74 nips-2007-EEG-Based Brain-Computer Interaction: Improved Accuracy by Automatic Single-Trial Error Detection</a></p>
<p>14 0.053219374 <a title="56-tfidf-14" href="./nips-2007-Spatial_Latent_Dirichlet_Allocation.html">183 nips-2007-Spatial Latent Dirichlet Allocation</a></p>
<p>15 0.051277697 <a title="56-tfidf-15" href="./nips-2007-Learning_Horizontal_Connections_in_a_Sparse_Coding_Model_of_Natural_Images.html">111 nips-2007-Learning Horizontal Connections in a Sparse Coding Model of Natural Images</a></p>
<p>16 0.050751079 <a title="56-tfidf-16" href="./nips-2007-Sparse_deep_belief_net_model_for_visual_area_V2.html">182 nips-2007-Sparse deep belief net model for visual area V2</a></p>
<p>17 0.05031012 <a title="56-tfidf-17" href="./nips-2007-People_Tracking_with_the_Laplacian_Eigenmaps_Latent_Variable_Model.html">153 nips-2007-People Tracking with the Laplacian Eigenmaps Latent Variable Model</a></p>
<p>18 0.049207382 <a title="56-tfidf-18" href="./nips-2007-Kernels_on_Attributed_Pointsets_with_Applications.html">109 nips-2007-Kernels on Attributed Pointsets with Applications</a></p>
<p>19 0.049034812 <a title="56-tfidf-19" href="./nips-2007-Scene_Segmentation_with_CRFs_Learned_from_Partially_Labeled_Images.html">172 nips-2007-Scene Segmentation with CRFs Learned from Partially Labeled Images</a></p>
<p>20 0.048824329 <a title="56-tfidf-20" href="./nips-2007-Learning_the_2-D_Topology_of_Images.html">115 nips-2007-Learning the 2-D Topology of Images</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2007_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.144), (1, -0.005), (2, 0.054), (3, -0.093), (4, -0.028), (5, 0.095), (6, 0.077), (7, 0.117), (8, 0.082), (9, 0.072), (10, -0.08), (11, -0.028), (12, 0.029), (13, -0.037), (14, 0.027), (15, -0.128), (16, 0.127), (17, -0.096), (18, -0.013), (19, -0.002), (20, 0.028), (21, -0.032), (22, -0.023), (23, 0.023), (24, 0.013), (25, -0.004), (26, -0.04), (27, 0.008), (28, -0.082), (29, -0.143), (30, -0.002), (31, 0.035), (32, 0.11), (33, -0.053), (34, 0.045), (35, 0.294), (36, -0.074), (37, 0.04), (38, -0.033), (39, -0.109), (40, -0.136), (41, 0.048), (42, 0.015), (43, 0.053), (44, 0.074), (45, -0.009), (46, 0.168), (47, -0.114), (48, 0.062), (49, 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94452792 <a title="56-lsi-1" href="./nips-2007-Configuration_Estimates_Improve_Pedestrian_Finding.html">56 nips-2007-Configuration Estimates Improve Pedestrian Finding</a></p>
<p>Author: Duan Tran, David A. Forsyth</p><p>Abstract: Fair discriminative pedestrian ﬁnders are now available. In fact, these pedestrian ﬁnders make most errors on pedestrians in conﬁgurations that are uncommon in the training data, for example, mounting a bicycle. This is undesirable. However, the human conﬁguration can itself be estimated discriminatively using structure learning. We demonstrate a pedestrian ﬁnder which ﬁrst ﬁnds the most likely human pose in the window using a discriminative procedure trained with structure learning on a small dataset. We then present features (local histogram of oriented gradient and local PCA of gradient) based on that conﬁguration to an SVM classiﬁer. We show, using the INRIA Person dataset, that estimates of conﬁguration signiﬁcantly improve the accuracy of a discriminative pedestrian ﬁnder. 1</p><p>2 0.73610348 <a title="56-lsi-2" href="./nips-2007-Multiple-Instance_Pruning_For_Learning_Efficient_Cascade_Detectors.html">137 nips-2007-Multiple-Instance Pruning For Learning Efficient Cascade Detectors</a></p>
<p>Author: Cha Zhang, Paul A. Viola</p><p>Abstract: Cascade detectors have been shown to operate extremely rapidly, with high accuracy, and have important applications such as face detection. Driven by this success, cascade learning has been an area of active research in recent years. Nevertheless, there are still challenging technical problems during the training process of cascade detectors. In particular, determining the optimal target detection rate for each stage of the cascade remains an unsolved issue. In this paper, we propose the multiple instance pruning (MIP) algorithm for soft cascades. This algorithm computes a set of thresholds which aggressively terminate computation with no reduction in detection rate or increase in false positive rate on the training dataset. The algorithm is based on two key insights: i) examples that are destined to be rejected by the complete classiﬁer can be safely pruned early; ii) face detection is a multiple instance learning problem. The MIP process is fully automatic and requires no assumptions of probability distributions, statistical independence, or ad hoc intermediate rejection targets. Experimental results on the MIT+CMU dataset demonstrate signiﬁcant performance advantages. 1</p><p>3 0.6506663 <a title="56-lsi-3" href="./nips-2007-Object_Recognition_by_Scene_Alignment.html">143 nips-2007-Object Recognition by Scene Alignment</a></p>
<p>Author: Bryan Russell, Antonio Torralba, Ce Liu, Rob Fergus, William T. Freeman</p><p>Abstract: Current object recognition systems can only recognize a limited number of object categories; scaling up to many categories is the next challenge. We seek to build a system to recognize and localize many different object categories in complex scenes. We achieve this through a simple approach: by matching the input image, in an appropriate representation, to images in a large training set of labeled images. Due to regularities in object identities across similar scenes, the retrieved matches provide hypotheses for object identities and locations. We build a probabilistic model to transfer the labels from the retrieval set to the input image. We demonstrate the effectiveness of this approach and study algorithm component contributions using held-out test sets from the LabelMe database. 1</p><p>4 0.63134843 <a title="56-lsi-4" href="./nips-2007-Learning_Visual_Attributes.html">113 nips-2007-Learning Visual Attributes</a></p>
<p>Author: Vittorio Ferrari, Andrew Zisserman</p><p>Abstract: We present a probabilistic generative model of visual attributes, together with an efﬁcient learning algorithm. Attributes are visual qualities of objects, such as ‘red’, ‘striped’, or ‘spotted’. The model sees attributes as patterns of image segments, repeatedly sharing some characteristic properties. These can be any combination of appearance, shape, or the layout of segments within the pattern. Moreover, attributes with general appearance are taken into account, such as the pattern of alternation of any two colors which is characteristic for stripes. To enable learning from unsegmented training images, the model is learnt discriminatively, by optimizing a likelihood ratio. As demonstrated in the experimental evaluation, our model can learn in a weakly supervised setting and encompasses a broad range of attributes. We show that attributes can be learnt starting from a text query to Google image search, and can then be used to recognize the attribute and determine its spatial extent in novel real-world images.</p><p>5 0.6168043 <a title="56-lsi-5" href="./nips-2007-GRIFT%3A_A_graphical_model_for_inferring_visual_classification_features_from_human_data.html">93 nips-2007-GRIFT: A graphical model for inferring visual classification features from human data</a></p>
<p>Author: Michael Ross, Andrew Cohen</p><p>Abstract: This paper describes a new model for human visual classiﬁcation that enables the recovery of image features that explain human subjects’ performance on different visual classiﬁcation tasks. Unlike previous methods, this algorithm does not model their performance with a single linear classiﬁer operating on raw image pixels. Instead, it represents classiﬁcation as the combination of multiple feature detectors. This approach extracts more information about human visual classiﬁcation than previous methods and provides a foundation for further exploration. 1</p><p>6 0.50657666 <a title="56-lsi-6" href="./nips-2007-Scan_Strategies_for_Meteorological_Radars.html">171 nips-2007-Scan Strategies for Meteorological Radars</a></p>
<p>7 0.50071108 <a title="56-lsi-7" href="./nips-2007-Combined_discriminative_and_generative_articulated_pose_and_non-rigid_shape_estimation.html">50 nips-2007-Combined discriminative and generative articulated pose and non-rigid shape estimation</a></p>
<p>8 0.4256379 <a title="56-lsi-8" href="./nips-2007-Nearest-Neighbor-Based_Active_Learning_for_Rare_Category_Detection.html">139 nips-2007-Nearest-Neighbor-Based Active Learning for Rare Category Detection</a></p>
<p>9 0.42537919 <a title="56-lsi-9" href="./nips-2007-Congruence_between_model_and_human_attention_reveals_unique_signatures_of_critical_visual_events.html">57 nips-2007-Congruence between model and human attention reveals unique signatures of critical visual events</a></p>
<p>10 0.39118031 <a title="56-lsi-10" href="./nips-2007-Predicting_human_gaze_using_low-level_saliency_combined_with_face_detection.html">155 nips-2007-Predicting human gaze using low-level saliency combined with face detection</a></p>
<p>11 0.38776338 <a title="56-lsi-11" href="./nips-2007-The_Infinite_Gamma-Poisson_Feature_Model.html">196 nips-2007-The Infinite Gamma-Poisson Feature Model</a></p>
<p>12 0.35670289 <a title="56-lsi-12" href="./nips-2007-The_Distribution_Family_of_Similarity_Distances.html">193 nips-2007-The Distribution Family of Similarity Distances</a></p>
<p>13 0.34301841 <a title="56-lsi-13" href="./nips-2007-Unsupervised_Feature_Selection_for_Accurate_Recommendation_of_High-Dimensional_Image_Data.html">211 nips-2007-Unsupervised Feature Selection for Accurate Recommendation of High-Dimensional Image Data</a></p>
<p>14 0.33432639 <a title="56-lsi-14" href="./nips-2007-People_Tracking_with_the_Laplacian_Eigenmaps_Latent_Variable_Model.html">153 nips-2007-People Tracking with the Laplacian Eigenmaps Latent Variable Model</a></p>
<p>15 0.32542789 <a title="56-lsi-15" href="./nips-2007-Scene_Segmentation_with_CRFs_Learned_from_Partially_Labeled_Images.html">172 nips-2007-Scene Segmentation with CRFs Learned from Partially Labeled Images</a></p>
<p>16 0.3157303 <a title="56-lsi-16" href="./nips-2007-Kernels_on_Attributed_Pointsets_with_Applications.html">109 nips-2007-Kernels on Attributed Pointsets with Applications</a></p>
<p>17 0.31413537 <a title="56-lsi-17" href="./nips-2007-Learning_the_2-D_Topology_of_Images.html">115 nips-2007-Learning the 2-D Topology of Images</a></p>
<p>18 0.3134841 <a title="56-lsi-18" href="./nips-2007-Catching_Change-points_with_Lasso.html">43 nips-2007-Catching Change-points with Lasso</a></p>
<p>19 0.2861186 <a title="56-lsi-19" href="./nips-2007-EEG-Based_Brain-Computer_Interaction%3A_Improved_Accuracy_by_Automatic_Single-Trial_Error_Detection.html">74 nips-2007-EEG-Based Brain-Computer Interaction: Improved Accuracy by Automatic Single-Trial Error Detection</a></p>
<p>20 0.27248314 <a title="56-lsi-20" href="./nips-2007-Estimating_disparity_with_confidence_from_energy_neurons.html">81 nips-2007-Estimating disparity with confidence from energy neurons</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2007_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(25, 0.071), (30, 0.031), (45, 0.029), (46, 0.087), (48, 0.29), (53, 0.085), (56, 0.039), (60, 0.146), (63, 0.018), (90, 0.092)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.72565645 <a title="56-lda-1" href="./nips-2007-Configuration_Estimates_Improve_Pedestrian_Finding.html">56 nips-2007-Configuration Estimates Improve Pedestrian Finding</a></p>
<p>Author: Duan Tran, David A. Forsyth</p><p>Abstract: Fair discriminative pedestrian ﬁnders are now available. In fact, these pedestrian ﬁnders make most errors on pedestrians in conﬁgurations that are uncommon in the training data, for example, mounting a bicycle. This is undesirable. However, the human conﬁguration can itself be estimated discriminatively using structure learning. We demonstrate a pedestrian ﬁnder which ﬁrst ﬁnds the most likely human pose in the window using a discriminative procedure trained with structure learning on a small dataset. We then present features (local histogram of oriented gradient and local PCA of gradient) based on that conﬁguration to an SVM classiﬁer. We show, using the INRIA Person dataset, that estimates of conﬁguration signiﬁcantly improve the accuracy of a discriminative pedestrian ﬁnder. 1</p><p>2 0.63919336 <a title="56-lda-2" href="./nips-2007-Stable_Dual_Dynamic_Programming.html">185 nips-2007-Stable Dual Dynamic Programming</a></p>
<p>Author: Tao Wang, Michael Bowling, Dale Schuurmans, Daniel J. Lizotte</p><p>Abstract: Recently, we have introduced a novel approach to dynamic programming and reinforcement learning that is based on maintaining explicit representations of stationary distributions instead of value functions. In this paper, we investigate the convergence properties of these dual algorithms both theoretically and empirically, and show how they can be scaled up by incorporating function approximation. 1</p><p>3 0.63219941 <a title="56-lda-3" href="./nips-2007-Predictive_Matrix-Variate_t_Models.html">156 nips-2007-Predictive Matrix-Variate t Models</a></p>
<p>Author: Shenghuo Zhu, Kai Yu, Yihong Gong</p><p>Abstract: It is becoming increasingly important to learn from a partially-observed random matrix and predict its missing elements. We assume that the entire matrix is a single sample drawn from a matrix-variate t distribution and suggest a matrixvariate t model (MVTM) to predict those missing elements. We show that MVTM generalizes a range of known probabilistic models, and automatically performs model selection to encourage sparse predictive models. Due to the non-conjugacy of its prior, it is difﬁcult to make predictions by computing the mode or mean of the posterior distribution. We suggest an optimization method that sequentially minimizes a convex upper-bound of the log-likelihood, which is very efﬁcient and scalable. The experiments on a toy data and EachMovie dataset show a good predictive accuracy of the model. 1</p><p>4 0.58074415 <a title="56-lda-4" href="./nips-2007-Simplified_Rules_and_Theoretical_Analysis_for_Information_Bottleneck_Optimization_and_PCA_with_Spiking_Neurons.html">177 nips-2007-Simplified Rules and Theoretical Analysis for Information Bottleneck Optimization and PCA with Spiking Neurons</a></p>
<p>Author: Lars Buesing, Wolfgang Maass</p><p>Abstract: We show that under suitable assumptions (primarily linearization) a simple and perspicuous online learning rule for Information Bottleneck optimization with spiking neurons can be derived. This rule performs on common benchmark tasks as well as a rather complex rule that has previously been proposed [1]. Furthermore, the transparency of this new learning rule makes a theoretical analysis of its convergence properties feasible. A variation of this learning rule (with sign changes) provides a theoretically founded method for performing Principal Component Analysis (PCA) with spiking neurons. By applying this rule to an ensemble of neurons, different principal components of the input can be extracted. In addition, it is possible to preferentially extract those principal components from incoming signals X that are related or are not related to some additional target signal YT . In a biological interpretation, this target signal YT (also called relevance variable) could represent proprioceptive feedback, input from other sensory modalities, or top-down signals. 1</p><p>5 0.57779729 <a title="56-lda-5" href="./nips-2007-Kernels_on_Attributed_Pointsets_with_Applications.html">109 nips-2007-Kernels on Attributed Pointsets with Applications</a></p>
<p>Author: Mehul Parsana, Sourangshu Bhattacharya, Chiru Bhattacharya, K. Ramakrishnan</p><p>Abstract: This paper introduces kernels on attributed pointsets, which are sets of vectors embedded in an euclidean space. The embedding gives the notion of neighborhood, which is used to deﬁne positive semideﬁnite kernels on pointsets. Two novel kernels on neighborhoods are proposed, one evaluating the attribute similarity and the other evaluating shape similarity. Shape similarity function is motivated from spectral graph matching techniques. The kernels are tested on three real life applications: face recognition, photo album tagging, and shot annotation in video sequences, with encouraging results. 1</p><p>6 0.57740003 <a title="56-lda-6" href="./nips-2007-Predicting_human_gaze_using_low-level_saliency_combined_with_face_detection.html">155 nips-2007-Predicting human gaze using low-level saliency combined with face detection</a></p>
<p>7 0.5747028 <a title="56-lda-7" href="./nips-2007-Learning_the_2-D_Topology_of_Images.html">115 nips-2007-Learning the 2-D Topology of Images</a></p>
<p>8 0.57424951 <a title="56-lda-8" href="./nips-2007-Support_Vector_Machine_Classification_with_Indefinite_Kernels.html">190 nips-2007-Support Vector Machine Classification with Indefinite Kernels</a></p>
<p>9 0.57259476 <a title="56-lda-9" href="./nips-2007-Locality_and_low-dimensions_in_the_prediction_of_natural_experience_from_fMRI.html">122 nips-2007-Locality and low-dimensions in the prediction of natural experience from fMRI</a></p>
<p>10 0.57027149 <a title="56-lda-10" href="./nips-2007-Predicting_Brain_States_from_fMRI_Data%3A_Incremental_Functional_Principal_Component_Regression.html">154 nips-2007-Predicting Brain States from fMRI Data: Incremental Functional Principal Component Regression</a></p>
<p>11 0.5658319 <a title="56-lda-11" href="./nips-2007-Sequential_Hypothesis_Testing_under_Stochastic_Deadlines.html">176 nips-2007-Sequential Hypothesis Testing under Stochastic Deadlines</a></p>
<p>12 0.56076992 <a title="56-lda-12" href="./nips-2007-EEG-Based_Brain-Computer_Interaction%3A_Improved_Accuracy_by_Automatic_Single-Trial_Error_Detection.html">74 nips-2007-EEG-Based Brain-Computer Interaction: Improved Accuracy by Automatic Single-Trial Error Detection</a></p>
<p>13 0.56034285 <a title="56-lda-13" href="./nips-2007-GRIFT%3A_A_graphical_model_for_inferring_visual_classification_features_from_human_data.html">93 nips-2007-GRIFT: A graphical model for inferring visual classification features from human data</a></p>
<p>14 0.56007737 <a title="56-lda-14" href="./nips-2007-An_Analysis_of_Convex_Relaxations_for_MAP_Estimation.html">23 nips-2007-An Analysis of Convex Relaxations for MAP Estimation</a></p>
<p>15 0.55944169 <a title="56-lda-15" href="./nips-2007-Learning_Visual_Attributes.html">113 nips-2007-Learning Visual Attributes</a></p>
<p>16 0.5588448 <a title="56-lda-16" href="./nips-2007-Multiple-Instance_Pruning_For_Learning_Efficient_Cascade_Detectors.html">137 nips-2007-Multiple-Instance Pruning For Learning Efficient Cascade Detectors</a></p>
<p>17 0.55724841 <a title="56-lda-17" href="./nips-2007-Modeling_image_patches_with_a_directed_hierarchy_of_Markov_random_fields.html">132 nips-2007-Modeling image patches with a directed hierarchy of Markov random fields</a></p>
<p>18 0.55683297 <a title="56-lda-18" href="./nips-2007-Subspace-Based_Face_Recognition_in_Analog_VLSI.html">188 nips-2007-Subspace-Based Face Recognition in Analog VLSI</a></p>
<p>19 0.55679995 <a title="56-lda-19" href="./nips-2007-New_Outer_Bounds_on_the_Marginal_Polytope.html">141 nips-2007-New Outer Bounds on the Marginal Polytope</a></p>
<p>20 0.55553401 <a title="56-lda-20" href="./nips-2007-Learning_Horizontal_Connections_in_a_Sparse_Coding_Model_of_Natural_Images.html">111 nips-2007-Learning Horizontal Connections in a Sparse Coding Model of Natural Images</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
