<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>207 nips-2007-Transfer Learning using Kolmogorov Complexity: Basic Theory and Empirical Evaluations</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-207" href="#">nips2007-207</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>207 nips-2007-Transfer Learning using Kolmogorov Complexity: Basic Theory and Empirical Evaluations</h1>
<br/><p>Source: <a title="nips-2007-207-pdf" href="http://papers.nips.cc/paper/3228-transfer-learning-using-kolmogorov-complexity-basic-theory-and-empirical-evaluations.pdf">pdf</a></p><p>Author: M. M. Mahmud, Sylvian Ray</p><p>Abstract: In transfer learning we aim to solve new problems using fewer examples using information gained from solving related problems. Transfer learning has been successful in practice, and extensive PAC analysis of these methods has been developed. However it is not yet clear how to deﬁne relatedness between tasks. This is considered as a major problem as it is conceptually troubling and it makes it unclear how much information to transfer and when and how to transfer it. In this paper we propose to measure the amount of information one task contains about another using conditional Kolmogorov complexity between the tasks. We show how existing theory neatly solves the problem of measuring relatedness and transferring the ‘right’ amount of information in sequential transfer learning in a Bayesian setting. The theory also suggests that, in a very formal and precise sense, no other reasonable transfer method can do much better than our Kolmogorov Complexity theoretic transfer method, and that sequential transfer is always justiﬁed. We also develop a practical approximation to the method and use it to transfer information between 8 arbitrarily chosen databases from the UCI ML repository. 1</p><p>Reference: <a title="nips-2007-207-reference" href="../nips2007_reference/nips-2007-Transfer_Learning_using_Kolmogorov_Complexity%3A_Basic_Theory_and_Empirical_Evaluations_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract In transfer learning we aim to solve new problems using fewer examples using information gained from solving related problems. [sent-7, score-0.651]
</p><p>2 However it is not yet clear how to deﬁne relatedness between tasks. [sent-9, score-0.182]
</p><p>3 This is considered as a major problem as it is conceptually troubling and it makes it unclear how much information to transfer and when and how to transfer it. [sent-10, score-1.248]
</p><p>4 In this paper we propose to measure the amount of information one task contains about another using conditional Kolmogorov complexity between the tasks. [sent-11, score-0.175]
</p><p>5 We show how existing theory neatly solves the problem of measuring relatedness and transferring the ‘right’ amount of information in sequential transfer learning in a Bayesian setting. [sent-12, score-0.944]
</p><p>6 The theory also suggests that, in a very formal and precise sense, no other reasonable transfer method can do much better than our Kolmogorov Complexity theoretic transfer method, and that sequential transfer is always justiﬁed. [sent-13, score-1.991]
</p><p>7 We also develop a practical approximation to the method and use it to transfer information between 8 arbitrarily chosen databases from the UCI ML repository. [sent-14, score-0.755]
</p><p>8 1  Introduction  The goal of transfer learning [1] is to learn new tasks with fewer examples given information gained from solving related tasks, with each task corresponding to the distribution/probability measure generating the samples for that task. [sent-15, score-0.797]
</p><p>9 The study of transfer is motivated by the fact that people use knowledge gained from previously solved, related problems to solve new problems quicker. [sent-16, score-0.68]
</p><p>10 Figure 1 shows a prototypical transfer method [1], and it illustrates some of the key ideas. [sent-18, score-0.624]
</p><p>11 Transfer can also be done sequentially where information from tasks learned previously are used to speed up learning of new ones. [sent-23, score-0.151]
</p><p>12 Despite the practical successes, the key question of how one measures relatedness between tasks has, so far, eluded answer. [sent-24, score-0.286]
</p><p>13 As no explicit measure of relatedness is prescribed, it becomes difﬁcult to answer questions such as how much information to transfer between tasks and when not to transfer information. [sent-26, score-1.538]
</p><p>14 [3] gives a more explicit measure of task relatedness in which two tasks P and Q are said to be similar with respect to a given set of functions if the set contains an element f such that P (a) = Q(f (a)) for all events a. [sent-29, score-0.37]
</p><p>15 By assuming the existence of these functions, the authors are able to derive PAC sample complexity bounds for error of each task (as opposed to expected error, w. [sent-30, score-0.162]
</p><p>16 More interesting is the approach in [4], where the author derives PAC bounds in which the sample complexity is proportional to the joint Kolmogorov complexity [5] of the m hypotheses. [sent-34, score-0.151]
</p><p>17 So Kolmogorov complexity (see below) determines the relatedness between tasks. [sent-35, score-0.24]
</p><p>18 In this paper we approach the above idea from a Bayesian perspective and measure tasks relatedness using conditional Kolmogorov complexity of the hypothesis. [sent-37, score-0.377]
</p><p>19 We describe the basics of the theory to show how it justiﬁes this approach and neatly solves the problem of measuring task relatedness (details in [6; 7]). [sent-38, score-0.293]
</p><p>20 We assume that each hypothesis is represented by a program – for example a decision tree is represented by a program that contains a data structure representing the tree, and the relevant code to compute the leaf node corresponding to a given input vector. [sent-41, score-0.34]
</p><p>21 The Kolmogorov complexity of a hypothesis h (or any other bit string) is now deﬁned as the length of the shortest program that outputs h given no input. [sent-42, score-0.343]
</p><p>22 The conditional Kolmogorov complexity of hypothesis h given h′ , K(h|h′ ), is deﬁned as the length of the shortest program that outputs the program h given h′ as input. [sent-45, score-0.399]
</p><p>23 This is precisely what we wish to measure in transfer learning. [sent-47, score-0.653]
</p><p>24 Hence this becomes our measure of relatedness for performing sequential transfer learning in the Bayesian setting. [sent-48, score-0.872]
</p><p>25 In the Bayesian setting, any sequential transfer learning mechanism/algorithm is ‘just’ a conditional prior W (·|h′ ) over the hypothesis/probability measure space, where h′ is the task learned previously – i. [sent-49, score-0.887]
</p><p>26 the task we are trying to transfer information from. [sent-51, score-0.662]
</p><p>27 In this case, by setting the prior over the ′ hypothesis space to be P (·|h′ ) := 2−K(·|h ) we weight each candidate hypothesis by how related it is to previous tasks, and so we automatically transfer the right amount of information when learning the new problem. [sent-52, score-0.804]
</p><p>28 We show that in a certain precise sense this prior is never much worse than any reasonable transfer learning prior, or any non-transfer prior. [sent-53, score-0.707]
</p><p>29 So, sequential transfer learning is always justiﬁed from a theoretical perspective. [sent-54, score-0.661]
</p><p>30 This result is quite unexpected as the current belief in the transfer learning community is that it should hurt to transfer from unrelated tasks. [sent-55, score-1.274]
</p><p>31 Due to lack of space, we only just brieﬂy note that similar results hold for an appropriate interpretation of parallel transfer, and that, translated to the Bayesian setting, current practical transfer methods look like sequential transfer methods [6; 7]. [sent-56, score-1.354]
</p><p>32 Kolmogorov complexity is computable only in the limit (i. [sent-57, score-0.131]
</p><p>33 with inﬁnite resources), and so, while ideal for investigating transfer in the limit, in practice we need to use an approximation of it (see [8] for a good example of this). [sent-59, score-0.645]
</p><p>34 In this paper we perform transfer in Bayesian decision trees by using a fairly simple approximation to the 2−K(·|·) prior. [sent-60, score-0.757]
</p><p>35 We then describe our Kolmogorov complexity based Bayesian transfer learning method. [sent-63, score-0.682]
</p><p>36 In section 4 we describe our method for approximation of the above using Bayesian decision trees, and then in section 5 we describe 12 transfer experiments using 8 standard databases from the UCI machine learning repository [9]. [sent-64, score-0.786]
</p><p>37 Our experiments are the most general that we know of, in the sense that we 2  transfer between arbitrary databases with little or no semantic relationships. [sent-65, score-0.709]
</p><p>38 2  Preliminaries  We consider Bayesian transfer learning for ﬁnite input spaces Ii and ﬁnite output spaces Oi . [sent-67, score-0.684]
</p><p>39 We assume ﬁnite hypothesis spaces Hi , where each h ∈ Hi is a conditional probability measure on Oi , conditioned on elements of Ii . [sent-68, score-0.149]
</p><p>40 Given Dn = {(x1 , y1 ), (x2 , y2 ), · · · , (xn , yn )} from Ii × Oi , the probability of Dn according to h ∈ Hi is given by: n  h(yk |xk )  h(Dn ) := k=1  The conditional probability of a new sample (xnew , ynew ) ∈ Ii × Oi for any conditional probability measure µ (e. [sent-70, score-0.175]
</p><p>41 Note that we are considering cross-domain transfer [13] as our standard setting (see section 6). [sent-83, score-0.624]
</p><p>42 We further assume that each h ∈ Hi is a program (therefore a bit string) for some Universal preﬁx Turing machine U . [sent-84, score-0.135]
</p><p>43 1  Transfer Learning using Kolmogorov Complexity Kolmogorov Complexity based Task Relatedness  A program is a bit string, and a measure of absolute constructive information that a bit string x contains about another bit string y is given by the conditional Kolmogorov complexity of x given y [5] . [sent-89, score-0.549]
</p><p>44 Since our hypotheses are programs/bit strings, the amount of information that a hypothesis or program h′ contains about constructing another hypothesis h is also given by the same: Deﬁnition 1. [sent-90, score-0.224]
</p><p>45 The conditional Kolmogorov complexity of h ∈ Hj given h′ ∈ Hi is deﬁned as the length of the shortest program that given the program h′ as input, outputs the program h. [sent-91, score-0.419]
</p><p>46 Let f (x, y) be a computable function over product of bit strings. [sent-93, score-0.127]
</p><p>47 f is computable means that there is a program p such that p(x, n), n ∈ N, computes f (x) to accuracy ǫ < 2−n in ﬁnite time. [sent-94, score-0.154]
</p><p>48 Then for a constant cf = K(f ) + O(1), independent of x and y, but dependent on K(f ), the length of shortest program computing f , and some small constant (O(1)) [5, Corollary 4. [sent-96, score-0.171]
</p><p>49 Now assume that the data has been generated by a hj ∈ Hi (this is standard for a Bayesian setting, but we will relax this constraint below). [sent-102, score-0.135]
</p><p>50 ∞  hj (Dn )[MW (y|x, Dn ) − hj (y|x, Dn )]2 ≤ − ln W (hj ). [sent-104, score-0.369]
</p><p>51 3)  t=0 Dn  So for ﬁnite − ln W (hj ), convergence is rapid; the expected number of times n |MW (a|x, Dn ) − hj (a|x, Dn )| > ǫ is ≤ − ln W (hj )/ǫ2 , and the probability that the number of ǫ deviations > − ln W (hj )/ǫ2 δ is < δ. [sent-106, score-0.432]
</p><p>52 In essence these results hold as long as Hi can be enumerated and hj and W can be computed with inﬁnite resources. [sent-108, score-0.156]
</p><p>53 These results also hold if hj ∈ Hi , but ∃h′ ∈ Hi such that the nth order j KL divergence between hj and h′ is bounded by k. [sent-109, score-0.291]
</p><p>54 In this case the error bound is − ln W (h′ ) + k j j [11, section 2. [sent-110, score-0.151]
</p><p>55 3) error bound K(h) ln 2, and for any computable prior W (·), f (x, y) := − ln W (x)/ ln 2 satisﬁes conditions for f (x, y) in ( 3. [sent-113, score-0.48]
</p><p>56 3), with y = the empty string, we get: K(h) ln 2 ≤ − ln W (h) + cW (3. [sent-116, score-0.198]
</p><p>57 3), this means that for all h ∈ Hi , the error bound for the 2 prior can be no more than a constant worse than the error bound for any other prior. [sent-118, score-0.162]
</p><p>58 Since reasonable priors have small K(W ) (= O(1)), cW = O(1) and this prior is universally optimal [11, section 5. [sent-119, score-0.123]
</p><p>59 3  Bayesian Transfer Learning  Assume we have previously observed/learned m − 1 tasks, with task tj ∈ Hij , and the mth task to be learned is in Him . [sent-122, score-0.148]
</p><p>60 In the Bayesian framework, a transfer learning scheme corresponds to a computable prior W (·|t) over the space Him , W (h|t) ≤ 1 h∈Him  In this case, by ( 3. [sent-124, score-0.755]
</p><p>61 3), the error bound of the transfer learning scheme MW (deﬁned by the prior W ) is − ln W (h|t). [sent-125, score-0.833]
</p><p>62 We deﬁne our transfer learning method MT L by choosing the prior 2−K(·|t) : h(Dn )2−K(h|t) . [sent-126, score-0.682]
</p><p>63 MT L (Dn ) := h∈Him  For MT L the error bound is K(h|t) ln 2. [sent-127, score-0.151]
</p><p>64 1), we get that K(h|t) ln 2 ≤ − ln W (h|t) + cW So for a reasonable computable transfer learning scheme MW , cW = O(1) and for all h and t, the error bound for MT L is no more than a constant worse than the error bound for MW – i. [sent-129, score-1.023]
</p><p>65 4) the transfer learning scheme MT L is also universally optimal over all non-transfer learning schemes – i. [sent-135, score-0.689]
</p><p>66 in the precise formal sense of the framework in this paper, sequential transfer learning is always justiﬁed. [sent-137, score-0.686]
</p><p>67 We should also note that the 2−K(h) prior is not universally optimal with respect to the transfer prior W (·|t) because the inequality ( 3. [sent-139, score-0.805]
</p><p>68 Indeed, this is demonstrated in our experiments when the base classiﬁer used is an approximation to the 2−K(h) prior and the error of this prior is seen to be signiﬁcantly higher than the transfer learning prior 2−K(h|t) . [sent-142, score-0.85]
</p><p>69 Each hypothesis space Hi consists of decision trees for Ii deﬁned by the set fi of features. [sent-149, score-0.173]
</p><p>70 A tree h ∈ Hi is deﬁned recursively: h := nroot nj := rj Cj ∅ ∅ | rj Cj nj ∅ | rj Cj ∅ nj | rj Cj nj nj L R L R C is a vector of size |Oi |, with component Ci giving the probability of the ith class. [sent-150, score-0.469]
</p><p>71 Since c0 and the length of the program code p0 for computing the tree output are constants independent of the tree, we deﬁne the length of a tree as l(h) := N . [sent-154, score-0.271]
</p><p>72 In both cases, we can sample from the prior directly by growing the decision tree dynamically. [sent-157, score-0.189]
</p><p>73 In the transfer learning case, for the prior 2−Cld (·|h ) we ﬁrst generate an integer k −t according to 2 distribution. [sent-162, score-0.682]
</p><p>74 To sample from this, we can simply select a hi from the m − 1 trees at random and then sample from 2−Cld (·|hi ) to get the new tree. [sent-166, score-0.413]
</p><p>75 The transfer learning mixture: The approximation of the transfer learning mixture MT L is now: m  m h(Dn )2−Cld (h|t) /ZCld  PT L (Dn ) = h∈Him  m So by ( 3. [sent-167, score-1.269]
</p><p>76 3), the error bound for PT L is given by Cld (h|t) ln 2 + ln ZCld (the ln ZCld is a constant m that is same for all h ∈ Hi ). [sent-168, score-0.349]
</p><p>77 (b) Draw u uniformly at random from [0, 1] and set hcur := hprop if A(hprop , hcur ) > u, where A is deﬁned by m h(Dn )2−Cld (h|t) q(h′ ) A(h, h′ ) := min 1, m ′ h′ (Dn )2−Cld (h |t) q(h)  4. [sent-177, score-0.246]
</p><p>78 The algorithm is ﬁrst run for some J = T , to get the Markov chain q × A to converge, and then starting from the last hcur in ˆ the run, the algorithm is run again for J = N times to get N samples for PT L . [sent-180, score-0.136]
</p><p>79 To show transfer of information we used 20% of the data for a task as the training sample, but also used as prior knowledge trees learned on another task using 80% of the data as training sample. [sent-185, score-0.881]
</p><p>80 To the best of our knowledge our transfer experiments are the most general performed so far, in the sense that the databases information is transferred between have semantic relationship that is often tenuous. [sent-187, score-0.741]
</p><p>81 This set ensured that our base Bayesian classiﬁer with 2−l(h) prior is reasonably powerful and that any improvement in performance in the transfer experiments (set 3) was due to transfer and not deﬁciency in our base classiﬁer. [sent-190, score-1.306]
</p><p>82 As an example, for ecoli our classiﬁer outperforms Adaboost and Random Forests in [16], but is a bit worse than these for German Credit. [sent-193, score-0.177]
</p><p>83 In the second set of experiments we learned the databases that we are going to transfer to using 20% of the database as training sample, and 80% of the data as the testing sample. [sent-194, score-0.752]
</p><p>84 This was done to establish baseline performance for the transfer learning case. [sent-195, score-0.624]
</p><p>85 During transfer, the N N trees from the sampling of the 80/20 task were all used in the prior 2−Cld (·|t) . [sent-198, score-0.176]
</p><p>86 In our experiments, we transferred only to tasks that showed a signiﬁcant drop in error rate with the 20/80 split. [sent-226, score-0.142]
</p><p>87 As can be seen from comparing the tables, in most cases transfer of information improves the performance compared to the baseline transfer case. [sent-228, score-1.248]
</p><p>88 For ecoli, the transfer resulted in improvement to near 80/20 levels, while for australian the improvement was better than 80/20. [sent-229, score-0.654]
</p><p>89 Interestingly transfer learning did not hurt in one single case, which agrees with our theoretical results in the idealized setting. [sent-231, score-0.65]
</p><p>90 Transfer To and From rows gives databases information is transferred to and from. [sent-233, score-0.138]
</p><p>91 The theory is universally optimal and elegant, and we showed its practical applicability by constructing approximations to it to transfer information across disparate domains in standard UCI machine learning databases. [sent-308, score-0.737]
</p><p>92 We did not consider transferring from multiple previous tasks, and effect of size of source samples on transfer performance (using 70/30 etc. [sent-311, score-0.652]
</p><p>93 Due to the general nature of our method, we can perform transfer experiments between any combination of databases in the UCI repository. [sent-313, score-0.709]
</p><p>94 We also hope that it is clear that Kolmogorov complexity based approach elegantly solves the problem of cross-domain transfer, where we transfer information between tasks that are deﬁned over different input,output and distribution spaces. [sent-315, score-0.814]
</p><p>95 All these methods transfer information by ﬁnding structural similarity between various networks/rule that form the hypotheses. [sent-317, score-0.624]
</p><p>96 This is, of course, a way to measure constructive similarity between the hypotheses, and hence an approximation to Kolmogorov complexity based similarity. [sent-318, score-0.145]
</p><p>97 The theory of Kolmogorov complexity and its practical approximations such as [8] and this paper suggests that we can get good performance by just using generalized compressors, such as gzip, etc. [sent-321, score-0.13]
</p><p>98 Mapping and revising markov logic networks for transfer learning. [sent-389, score-0.624]
</p><p>99 3 A ﬂavor of this approach: if the standard compressor is gzip, then the function Cgzip (xy) will give the length of the string xy after compression by gzip. [sent-394, score-0.166]
</p><p>100 So Cgzip (h|h′ ) will give the relatedness between tasks. [sent-396, score-0.182]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('transfer', 0.624), ('cld', 0.334), ('dn', 0.261), ('hi', 0.239), ('kolmogorov', 0.221), ('relatedness', 0.182), ('hj', 0.135), ('ecoli', 0.123), ('oi', 0.112), ('mw', 0.104), ('ln', 0.099), ('cgzip', 0.088), ('hcur', 0.088), ('mt', 0.088), ('databases', 0.085), ('program', 0.081), ('trees', 0.08), ('tasks', 0.079), ('computable', 0.073), ('hprop', 0.07), ('xnew', 0.07), ('zcld', 0.07), ('string', 0.066), ('bayesian', 0.066), ('universally', 0.065), ('tree', 0.064), ('cw', 0.062), ('pt', 0.061), ('hypothesis', 0.061), ('complexity', 0.058), ('prior', 0.058), ('bit', 0.054), ('gzip', 0.053), ('hassan', 0.053), ('mushroom', 0.053), ('ynew', 0.053), ('uci', 0.047), ('rj', 0.045), ('pac', 0.045), ('hm', 0.043), ('learned', 0.043), ('cj', 0.04), ('universal', 0.04), ('bc', 0.039), ('task', 0.038), ('nj', 0.038), ('ii', 0.038), ('constructive', 0.037), ('sequential', 0.037), ('shortest', 0.036), ('compressor', 0.035), ('minimality', 0.035), ('nroot', 0.035), ('samarth', 0.035), ('swarup', 0.035), ('sylvian', 0.035), ('sample', 0.035), ('theoretic', 0.034), ('xy', 0.034), ('transferred', 0.032), ('decision', 0.032), ('length', 0.031), ('mcmc', 0.031), ('error', 0.031), ('hmi', 0.031), ('ray', 0.031), ('elegantly', 0.031), ('australian', 0.03), ('spaces', 0.03), ('measure', 0.029), ('previously', 0.029), ('conditional', 0.029), ('neatly', 0.028), ('transferring', 0.028), ('yeast', 0.028), ('yk', 0.028), ('gained', 0.027), ('illinois', 0.026), ('marcus', 0.026), ('hurt', 0.026), ('practical', 0.025), ('credit', 0.025), ('er', 0.025), ('precise', 0.025), ('get', 0.024), ('repository', 0.024), ('navigation', 0.023), ('cf', 0.023), ('translated', 0.023), ('justi', 0.023), ('theory', 0.023), ('pi', 0.022), ('outputs', 0.022), ('german', 0.022), ('solves', 0.022), ('approximation', 0.021), ('gives', 0.021), ('bound', 0.021), ('hold', 0.021), ('contains', 0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9999994 <a title="207-tfidf-1" href="./nips-2007-Transfer_Learning_using_Kolmogorov_Complexity%3A_Basic_Theory_and_Empirical_Evaluations.html">207 nips-2007-Transfer Learning using Kolmogorov Complexity: Basic Theory and Empirical Evaluations</a></p>
<p>Author: M. M. Mahmud, Sylvian Ray</p><p>Abstract: In transfer learning we aim to solve new problems using fewer examples using information gained from solving related problems. Transfer learning has been successful in practice, and extensive PAC analysis of these methods has been developed. However it is not yet clear how to deﬁne relatedness between tasks. This is considered as a major problem as it is conceptually troubling and it makes it unclear how much information to transfer and when and how to transfer it. In this paper we propose to measure the amount of information one task contains about another using conditional Kolmogorov complexity between the tasks. We show how existing theory neatly solves the problem of measuring relatedness and transferring the ‘right’ amount of information in sequential transfer learning in a Bayesian setting. The theory also suggests that, in a very formal and precise sense, no other reasonable transfer method can do much better than our Kolmogorov Complexity theoretic transfer method, and that sequential transfer is always justiﬁed. We also develop a practical approximation to the method and use it to transfer information between 8 arbitrarily chosen databases from the UCI ML repository. 1</p><p>2 0.28735092 <a title="207-tfidf-2" href="./nips-2007-Multi-task_Gaussian_Process_Prediction.html">135 nips-2007-Multi-task Gaussian Process Prediction</a></p>
<p>Author: Edwin V. Bonilla, Kian M. Chai, Christopher Williams</p><p>Abstract: In this paper we investigate multi-task learning in the context of Gaussian Processes (GP). We propose a model that learns a shared covariance function on input-dependent features and a “free-form” covariance matrix over tasks. This allows for good ﬂexibility when modelling inter-task dependencies while avoiding the need for large amounts of data for training. We show that under the assumption of noise-free observations and a block design, predictions for a given task only depend on its target values and therefore a cancellation of inter-task transfer occurs. We evaluate the beneﬁts of our model on two practical applications: a compiler performance prediction problem and an exam score prediction task. Additionally, we make use of GP approximations and properties of our model in order to provide scalability to large data sets. 1</p><p>3 0.097338662 <a title="207-tfidf-3" href="./nips-2007-Gaussian_Process_Models_for_Link_Analysis_and_Transfer_Learning.html">94 nips-2007-Gaussian Process Models for Link Analysis and Transfer Learning</a></p>
<p>Author: Kai Yu, Wei Chu</p><p>Abstract: This paper aims to model relational data on edges of networks. We describe appropriate Gaussian Processes (GPs) for directed, undirected, and bipartite networks. The inter-dependencies of edges can be effectively modeled by adapting the GP hyper-parameters. The framework suggests an intimate connection between link prediction and transfer learning, which were traditionally two separate research topics. We develop an efﬁcient learning algorithm that can handle a large number of observations. The experimental results on several real-world data sets verify superior learning capacity. 1</p><p>4 0.070397839 <a title="207-tfidf-4" href="./nips-2007-Multi-Task_Learning_via_Conic_Programming.html">134 nips-2007-Multi-Task Learning via Conic Programming</a></p>
<p>Author: Tsuyoshi Kato, Hisashi Kashima, Masashi Sugiyama, Kiyoshi Asai</p><p>Abstract: When we have several related tasks, solving them simultaneously is shown to be more effective than solving them individually. This approach is called multi-task learning (MTL) and has been studied extensively. Existing approaches to MTL often treat all the tasks as uniformly related to each other and the relatedness of the tasks is controlled globally. For this reason, the existing methods can lead to undesired solutions when some tasks are not highly related to each other, and some pairs of related tasks can have signiﬁcantly different solutions. In this paper, we propose a novel MTL algorithm that can overcome these problems. Our method makes use of a task network, which describes the relation structure among tasks. This allows us to deal with intricate relation structures in a systematic way. Furthermore, we control the relatedness of the tasks locally, so all pairs of related tasks are guaranteed to have similar solutions. We apply the above idea to support vector machines (SVMs) and show that the optimization problem can be cast as a second order cone program, which is convex and can be solved efﬁciently. The usefulness of our approach is demonstrated through simulations with protein super-family classiﬁcation and ordinal regression problems.</p><p>5 0.067264259 <a title="207-tfidf-5" href="./nips-2007-A_Spectral_Regularization_Framework_for_Multi-Task_Structure_Learning.html">12 nips-2007-A Spectral Regularization Framework for Multi-Task Structure Learning</a></p>
<p>Author: Andreas Argyriou, Massimiliano Pontil, Yiming Ying, Charles A. Micchelli</p><p>Abstract: Learning the common structure shared by a set of supervised tasks is an important practical and theoretical problem. Knowledge of this structure may lead to better generalization performance on the tasks and may also facilitate learning new tasks. We propose a framework for solving this problem, which is based on regularization with spectral functions of matrices. This class of regularization problems exhibits appealing computational properties and can be optimized efﬁciently by an alternating minimization algorithm. In addition, we provide a necessary and sufﬁcient condition for convexity of the regularizer. We analyze concrete examples of the framework, which are equivalent to regularization with Lp matrix norms. Experiments on two real data sets indicate that the algorithm scales well with the number of tasks and improves on state of the art statistical performance. 1</p><p>6 0.065618619 <a title="207-tfidf-6" href="./nips-2007-Progressive_mixture_rules_are_deviation_suboptimal.html">159 nips-2007-Progressive mixture rules are deviation suboptimal</a></p>
<p>7 0.065441623 <a title="207-tfidf-7" href="./nips-2007-Learning_Bounds_for_Domain_Adaptation.html">110 nips-2007-Learning Bounds for Domain Adaptation</a></p>
<p>8 0.056392476 <a title="207-tfidf-8" href="./nips-2007-Sequential_Hypothesis_Testing_under_Stochastic_Deadlines.html">176 nips-2007-Sequential Hypothesis Testing under Stochastic Deadlines</a></p>
<p>9 0.055229507 <a title="207-tfidf-9" href="./nips-2007-Bayesian_Inference_for_Spiking_Neuron_Models_with_a_Sparsity_Prior.html">33 nips-2007-Bayesian Inference for Spiking Neuron Models with a Sparsity Prior</a></p>
<p>10 0.054710448 <a title="207-tfidf-10" href="./nips-2007-The_Generalized_FITC_Approximation.html">195 nips-2007-The Generalized FITC Approximation</a></p>
<p>11 0.054588892 <a title="207-tfidf-11" href="./nips-2007-Hippocampal_Contributions_to_Control%3A_The_Third_Way.html">100 nips-2007-Hippocampal Contributions to Control: The Third Way</a></p>
<p>12 0.053700741 <a title="207-tfidf-12" href="./nips-2007-Testing_for_Homogeneity_with_Kernel_Fisher_Discriminant_Analysis.html">192 nips-2007-Testing for Homogeneity with Kernel Fisher Discriminant Analysis</a></p>
<p>13 0.052210744 <a title="207-tfidf-13" href="./nips-2007-Learning_the_structure_of_manifolds_using_random_projections.html">116 nips-2007-Learning the structure of manifolds using random projections</a></p>
<p>14 0.051518768 <a title="207-tfidf-14" href="./nips-2007-Theoretical_Analysis_of_Heuristic_Search_Methods_for_Online_POMDPs.html">204 nips-2007-Theoretical Analysis of Heuristic Search Methods for Online POMDPs</a></p>
<p>15 0.051404003 <a title="207-tfidf-15" href="./nips-2007-Using_Deep_Belief_Nets_to_Learn_Covariance_Kernels_for_Gaussian_Processes.html">212 nips-2007-Using Deep Belief Nets to Learn Covariance Kernels for Gaussian Processes</a></p>
<p>16 0.049922388 <a title="207-tfidf-16" href="./nips-2007-One-Pass_Boosting.html">147 nips-2007-One-Pass Boosting</a></p>
<p>17 0.048279487 <a title="207-tfidf-17" href="./nips-2007-Modeling_image_patches_with_a_directed_hierarchy_of_Markov_random_fields.html">132 nips-2007-Modeling image patches with a directed hierarchy of Markov random fields</a></p>
<p>18 0.045414686 <a title="207-tfidf-18" href="./nips-2007-Object_Recognition_by_Scene_Alignment.html">143 nips-2007-Object Recognition by Scene Alignment</a></p>
<p>19 0.044166464 <a title="207-tfidf-19" href="./nips-2007-Efficient_Principled_Learning_of_Thin_Junction_Trees.html">78 nips-2007-Efficient Principled Learning of Thin Junction Trees</a></p>
<p>20 0.043461747 <a title="207-tfidf-20" href="./nips-2007-The_Epoch-Greedy_Algorithm_for_Multi-armed_Bandits_with_Side_Information.html">194 nips-2007-The Epoch-Greedy Algorithm for Multi-armed Bandits with Side Information</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2007_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.161), (1, 0.009), (2, -0.042), (3, 0.043), (4, 0.003), (5, 0.009), (6, -0.109), (7, -0.063), (8, 0.02), (9, -0.058), (10, -0.069), (11, -0.039), (12, 0.007), (13, -0.015), (14, -0.075), (15, -0.09), (16, 0.023), (17, -0.103), (18, 0.103), (19, -0.115), (20, -0.122), (21, 0.202), (22, -0.038), (23, -0.082), (24, 0.124), (25, 0.01), (26, 0.031), (27, 0.005), (28, -0.054), (29, -0.041), (30, -0.146), (31, -0.025), (32, -0.177), (33, -0.177), (34, 0.045), (35, 0.201), (36, -0.036), (37, -0.185), (38, 0.004), (39, -0.045), (40, 0.05), (41, -0.084), (42, -0.145), (43, -0.165), (44, -0.102), (45, 0.021), (46, 0.044), (47, 0.146), (48, -0.088), (49, -0.036)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9701649 <a title="207-lsi-1" href="./nips-2007-Transfer_Learning_using_Kolmogorov_Complexity%3A_Basic_Theory_and_Empirical_Evaluations.html">207 nips-2007-Transfer Learning using Kolmogorov Complexity: Basic Theory and Empirical Evaluations</a></p>
<p>Author: M. M. Mahmud, Sylvian Ray</p><p>Abstract: In transfer learning we aim to solve new problems using fewer examples using information gained from solving related problems. Transfer learning has been successful in practice, and extensive PAC analysis of these methods has been developed. However it is not yet clear how to deﬁne relatedness between tasks. This is considered as a major problem as it is conceptually troubling and it makes it unclear how much information to transfer and when and how to transfer it. In this paper we propose to measure the amount of information one task contains about another using conditional Kolmogorov complexity between the tasks. We show how existing theory neatly solves the problem of measuring relatedness and transferring the ‘right’ amount of information in sequential transfer learning in a Bayesian setting. The theory also suggests that, in a very formal and precise sense, no other reasonable transfer method can do much better than our Kolmogorov Complexity theoretic transfer method, and that sequential transfer is always justiﬁed. We also develop a practical approximation to the method and use it to transfer information between 8 arbitrarily chosen databases from the UCI ML repository. 1</p><p>2 0.74785084 <a title="207-lsi-2" href="./nips-2007-Multi-task_Gaussian_Process_Prediction.html">135 nips-2007-Multi-task Gaussian Process Prediction</a></p>
<p>Author: Edwin V. Bonilla, Kian M. Chai, Christopher Williams</p><p>Abstract: In this paper we investigate multi-task learning in the context of Gaussian Processes (GP). We propose a model that learns a shared covariance function on input-dependent features and a “free-form” covariance matrix over tasks. This allows for good ﬂexibility when modelling inter-task dependencies while avoiding the need for large amounts of data for training. We show that under the assumption of noise-free observations and a block design, predictions for a given task only depend on its target values and therefore a cancellation of inter-task transfer occurs. We evaluate the beneﬁts of our model on two practical applications: a compiler performance prediction problem and an exam score prediction task. Additionally, we make use of GP approximations and properties of our model in order to provide scalability to large data sets. 1</p><p>3 0.46428511 <a title="207-lsi-3" href="./nips-2007-A_Spectral_Regularization_Framework_for_Multi-Task_Structure_Learning.html">12 nips-2007-A Spectral Regularization Framework for Multi-Task Structure Learning</a></p>
<p>Author: Andreas Argyriou, Massimiliano Pontil, Yiming Ying, Charles A. Micchelli</p><p>Abstract: Learning the common structure shared by a set of supervised tasks is an important practical and theoretical problem. Knowledge of this structure may lead to better generalization performance on the tasks and may also facilitate learning new tasks. We propose a framework for solving this problem, which is based on regularization with spectral functions of matrices. This class of regularization problems exhibits appealing computational properties and can be optimized efﬁciently by an alternating minimization algorithm. In addition, we provide a necessary and sufﬁcient condition for convexity of the regularizer. We analyze concrete examples of the framework, which are equivalent to regularization with Lp matrix norms. Experiments on two real data sets indicate that the algorithm scales well with the number of tasks and improves on state of the art statistical performance. 1</p><p>4 0.37146425 <a title="207-lsi-4" href="./nips-2007-Multi-Task_Learning_via_Conic_Programming.html">134 nips-2007-Multi-Task Learning via Conic Programming</a></p>
<p>Author: Tsuyoshi Kato, Hisashi Kashima, Masashi Sugiyama, Kiyoshi Asai</p><p>Abstract: When we have several related tasks, solving them simultaneously is shown to be more effective than solving them individually. This approach is called multi-task learning (MTL) and has been studied extensively. Existing approaches to MTL often treat all the tasks as uniformly related to each other and the relatedness of the tasks is controlled globally. For this reason, the existing methods can lead to undesired solutions when some tasks are not highly related to each other, and some pairs of related tasks can have signiﬁcantly different solutions. In this paper, we propose a novel MTL algorithm that can overcome these problems. Our method makes use of a task network, which describes the relation structure among tasks. This allows us to deal with intricate relation structures in a systematic way. Furthermore, we control the relatedness of the tasks locally, so all pairs of related tasks are guaranteed to have similar solutions. We apply the above idea to support vector machines (SVMs) and show that the optimization problem can be cast as a second order cone program, which is convex and can be solved efﬁciently. The usefulness of our approach is demonstrated through simulations with protein super-family classiﬁcation and ordinal regression problems.</p><p>5 0.36516157 <a title="207-lsi-5" href="./nips-2007-Sequential_Hypothesis_Testing_under_Stochastic_Deadlines.html">176 nips-2007-Sequential Hypothesis Testing under Stochastic Deadlines</a></p>
<p>Author: Peter Frazier, Angela J. Yu</p><p>Abstract: Most models of decision-making in neuroscience assume an inﬁnite horizon, which yields an optimal solution that integrates evidence up to a ﬁxed decision threshold; however, under most experimental as well as naturalistic behavioral settings, the decision has to be made before some ﬁnite deadline, which is often experienced as a stochastic quantity, either due to variable external constraints or internal timing uncertainty. In this work, we formulate this problem as sequential hypothesis testing under a stochastic horizon. We use dynamic programming tools to show that, for a large class of deadline distributions, the Bayes-optimal solution requires integrating evidence up to a threshold that declines monotonically over time. We use numerical simulations to illustrate the optimal policy in the special cases of a ﬁxed deadline and one that is drawn from a gamma distribution.</p><p>6 0.31845012 <a title="207-lsi-6" href="./nips-2007-Gaussian_Process_Models_for_Link_Analysis_and_Transfer_Learning.html">94 nips-2007-Gaussian Process Models for Link Analysis and Transfer Learning</a></p>
<p>7 0.30740312 <a title="207-lsi-7" href="./nips-2007-Near-Maximum_Entropy_Models_for_Binary_Neural_Representations_of_Natural_Images.html">138 nips-2007-Near-Maximum Entropy Models for Binary Neural Representations of Natural Images</a></p>
<p>8 0.30182695 <a title="207-lsi-8" href="./nips-2007-The_Generalized_FITC_Approximation.html">195 nips-2007-The Generalized FITC Approximation</a></p>
<p>9 0.29141653 <a title="207-lsi-9" href="./nips-2007-Progressive_mixture_rules_are_deviation_suboptimal.html">159 nips-2007-Progressive mixture rules are deviation suboptimal</a></p>
<p>10 0.29093733 <a title="207-lsi-10" href="./nips-2007-Anytime_Induction_of_Cost-sensitive_Trees.html">27 nips-2007-Anytime Induction of Cost-sensitive Trees</a></p>
<p>11 0.28788295 <a title="207-lsi-11" href="./nips-2007-Boosting_Algorithms_for_Maximizing_the_Soft_Margin.html">38 nips-2007-Boosting Algorithms for Maximizing the Soft Margin</a></p>
<p>12 0.28367418 <a title="207-lsi-12" href="./nips-2007-A_learning_framework_for_nearest_neighbor_search.html">16 nips-2007-A learning framework for nearest neighbor search</a></p>
<p>13 0.27912927 <a title="207-lsi-13" href="./nips-2007-Feature_Selection_Methods_for_Improving_Protein_Structure_Prediction_with_Rosetta.html">89 nips-2007-Feature Selection Methods for Improving Protein Structure Prediction with Rosetta</a></p>
<p>14 0.2733458 <a title="207-lsi-14" href="./nips-2007-Markov_Chain_Monte_Carlo_with_People.html">125 nips-2007-Markov Chain Monte Carlo with People</a></p>
<p>15 0.26880267 <a title="207-lsi-15" href="./nips-2007-Stability_Bounds_for_Non-i.i.d._Processes.html">184 nips-2007-Stability Bounds for Non-i.i.d. Processes</a></p>
<p>16 0.26769629 <a title="207-lsi-16" href="./nips-2007-Efficient_Principled_Learning_of_Thin_Junction_Trees.html">78 nips-2007-Efficient Principled Learning of Thin Junction Trees</a></p>
<p>17 0.26723757 <a title="207-lsi-17" href="./nips-2007-Augmented_Functional_Time_Series_Representation_and_Forecasting_with_Gaussian_Processes.html">28 nips-2007-Augmented Functional Time Series Representation and Forecasting with Gaussian Processes</a></p>
<p>18 0.26695362 <a title="207-lsi-18" href="./nips-2007-Learning_the_structure_of_manifolds_using_random_projections.html">116 nips-2007-Learning the structure of manifolds using random projections</a></p>
<p>19 0.26482728 <a title="207-lsi-19" href="./nips-2007-Hippocampal_Contributions_to_Control%3A_The_Third_Way.html">100 nips-2007-Hippocampal Contributions to Control: The Third Way</a></p>
<p>20 0.26271379 <a title="207-lsi-20" href="./nips-2007-Learning_and_using_relational_theories.html">114 nips-2007-Learning and using relational theories</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2007_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.036), (7, 0.308), (13, 0.022), (16, 0.015), (18, 0.017), (21, 0.051), (31, 0.033), (34, 0.017), (35, 0.029), (47, 0.092), (49, 0.014), (83, 0.168), (85, 0.034), (87, 0.017), (90, 0.056)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.87489355 <a title="207-lda-1" href="./nips-2007-Comparing_Bayesian_models_for_multisensory_cue_combination_without_mandatory_integration.html">51 nips-2007-Comparing Bayesian models for multisensory cue combination without mandatory integration</a></p>
<p>Author: Ulrik Beierholm, Ladan Shams, Wei J. Ma, Konrad Koerding</p><p>Abstract: Bayesian models of multisensory perception traditionally address the problem of estimating an underlying variable that is assumed to be the cause of the two sensory signals. The brain, however, has to solve a more general problem: it also has to establish which signals come from the same source and should be integrated, and which ones do not and should be segregated. In the last couple of years, a few models have been proposed to solve this problem in a Bayesian fashion. One of these has the strength that it formalizes the causal structure of sensory signals. We ﬁrst compare these models on a formal level. Furthermore, we conduct a psychophysics experiment to test human performance in an auditory-visual spatial localization task in which integration is not mandatory. We ﬁnd that the causal Bayesian inference model accounts for the data better than other models. Keywords: causal inference, Bayesian methods, visual perception. 1 Multisensory perception In the ventriloquist illusion, a performer speaks without moving his/her mouth while moving a puppet’s mouth in synchrony with his/her speech. This makes the puppet appear to be speaking. This illusion was ﬁrst conceptualized as ”visual capture”, occurring when visual and auditory stimuli exhibit a small conﬂict ([1, 2]). Only recently has it been demonstrated that the phenomenon may be seen as a byproduct of a much more ﬂexible and nearly Bayes-optimal strategy ([3]), and therefore is part of a large collection of cue combination experiments showing such statistical near-optimality [4, 5]. In fact, cue combination has become the poster child for Bayesian inference in the nervous system. In previous studies of multisensory integration, two sensory stimuli are presented which act as cues about a single underlying source. For instance, in the auditory-visual localization experiment by Alais and Burr [3], observers were asked to envisage each presentation of a light blob and a sound click as a single event, like a ball hitting the screen. In many cases, however, the brain is not only posed with the problem of identifying the position of a common source, but also of determining whether there was a common source at all. In the on-stage ventriloquist illusion, it is indeed primarily the causal inference process that is being fooled, because veridical perception would attribute independent causes to the auditory and the visual stimulus. 1 To extend our understanding of multisensory perception to this more general problem, it is necessary to manipulate the degree of belief assigned to there being a common cause within a multisensory task. Intuitively, we expect that when two signals are very different, they are less likely to be perceived as having a common source. It is well-known that increasing the discrepancy or inconsistency between stimuli reduces the inﬂuence that they have on each other [6, 7, 8, 9, 10, 11]. In auditoryvisual spatial localization, one variable that controls stimulus similarity is spatial disparity (another would be temporal disparity). Indeed, it has been reported that increasing spatial disparity leads to a decrease in auditory localization bias [1, 12, 13, 14, 15, 16, 17, 2, 18, 19, 20, 21]. This decrease also correlates with a decrease in the reports of unity [19, 21]. Despite the abundance of experimental data on this issue, no general theory exists that can explain multisensory perception across a wide range of cue conﬂicts. 2 Models The success of Bayesian models for cue integration has motivated attempts to extend them to situations of large sensory conﬂict and a consequent low degree of integration. In one of recent studies taking this approach, subjects were presented with concurrent visual ﬂashes and auditory beeps and asked to count both the number of ﬂashes and the number of beeps [11]. The advantage of the experimental paradigm adopted here was that it probed the joint response distribution by requiring a dual report. Human data were accounted for well by a Bayesian model in which the joint prior distribution over visual and auditory number was approximated from the data. In a similar study, subjects were presented with concurrent ﬂashes and taps and asked to count either the ﬂashes or the taps [9, 22]. The Bayesian model proposed by these authors assumed a joint prior distribution with a near-diagonal form. The corresponding generative model assumes that the sensory sources somehow interact with one another. A third experiment modulated the rates of ﬂashes and beeps. The task was to judge either the visual or the auditory modulation rate relative to a standard [23]. The data from this experiment were modeled using a joint prior distribution which is the sum of a near-diagonal prior and a ﬂat background. While all these models are Bayesian in a formal sense, their underlying generative model does not formalize the model selection process that underlies the combination of cues. This makes it necessary to either estimate an empirical prior [11] by ﬁtting it to human behavior or to assume an ad hoc form [22, 23]. However, we believe that such assumptions are not needed. It was shown recently that human judgments of spatial unity in an auditory-visual spatial localization task can be described using a Bayesian inference model that infers causal structure [24, 25]. In this model, the brain does not only estimate a stimulus variable, but also infers the probability that the two stimuli have a common cause. In this paper we compare these different models on a large data set of human position estimates in an auditory-visual task. In this section we ﬁrst describe the traditional cue integration model, then the recent models based on joint stimulus priors, and ﬁnally the causal inference model. To relate to the experiment in the next section, we will use the terminology of auditory-visual spatial localization, but the formalism is very general. 2.1 Traditional cue integration The traditional generative model of cue integration [26] has a single source location s which produces on each trial an internal representation (cue) of visual location, xV and one of auditory location, xA . We assume that the noise processes by which these internal representations are generated are conditionally independent from each other and follow Gaussian distributions. That is, p (xV |s) ∼ N (xV ; s, σV )and p (xA |s) ∼ N (xA ; s, σA ), where N (x; µ, σ) stands for the normal distribution over x with mean µ and standard deviation σ. If on a given trial the internal representations are xV and xA , the probability that their source was s is given by Bayes’ rule, p (s|xV , xA ) ∝ p (xV |s) p (xA |s) . If a subject performs maximum-likelihood estimation, then the estimate will be xV +wA s = wV wV +wA xA , where wV = σ1 and wA = σ1 . It is important to keep in mind that this is the ˆ 2 2 V A estimate on a single trial. A psychophysical experimenter can never have access to xV and xA , which 2 are the noisy internal representations. Instead, an experimenter will want to collect estimates over many trials and is interested in the distribution of s given sV and sA , which are the sources generated ˆ by the experimenter. In a typical cue combination experiment, xV and xA are not actually generated by the same source, but by different sources, a visual one sV and an auditory one sA . These sources are chosen close to each other so that the subject can imagine that the resulting cues originate from a single source and thus implicitly have a common cause. The experimentally observed distribution is then p (ˆ|sV , sA ) = s p (ˆ|xV , xA ) p (xV |sV ) p (xA |sA ) dxV dxA s Given that s is a linear combination of two normally distributed variables, it will itself follow a ˆ sV +wA 1 2 normal distribution, with mean s = wVwV +wA sA and variance σs = wV +wA . The reason that we ˆ ˆ emphasize this point is because many authors identify the estimate distribution p (ˆ|sV , sA ) with s the posterior distribution p (s|xV , xA ). This is justiﬁed in this case because all distributions are Gaussian and the estimate is a linear combination of cues. However, in the case of causal inference, these conditions are violated and the estimate distribution will in general not be the same as the posterior distribution. 2.2 Models with bisensory stimulus priors Models with bisensory stimulus priors propose the posterior over source positions to be proportional to the product of unimodal likelihoods and a two-dimensional prior: p (sV , sA |xV , xA ) = p (sV , sA ) p (xV |sV ) p (xA |sA ) The traditional cue combination model has p (sV , sA ) = p (sV ) δ (sV − sA ), usually (as above) even with p (sV ) uniform. The question arises what bisensory stimulus prior is appropriate. In [11], the prior is estimated from data, has a large number of parameters, and is therefore limited in its predictive power. In [23], it has the form − (sV −sA )2 p (sV , sA ) ∝ ω + e 2σ 2 coupling while in [22] the additional assumption ω = 0 is made1 . In all three models, the response distribution p (ˆV , sA |sV , sA ) is obtained by idens ˆ tifying it with the posterior distribution p (sV , sA |xV , xA ). This procedure thus implicitly assumes that marginalizing over the latent variables xV and xA is not necessary, which leads to a signiﬁcant error for non-Gaussian priors. In this paper we correctly deal with these issues and in all cases marginalize over the latent variables. The parametric models used for the coupling between the cues lead to an elegant low-dimensional model of cue integration that allows for estimates of single cues that differ from one another. C C=1 SA S XA 2.3 C=2 XV SV XA XV Causal inference model In the causal inference model [24, 25], we start from the traditional cue integration model but remove the assumption that two signals are caused by the same source. Instead, the number of sources can be one or two and is itself a variable that needs to be inferred from the cues. Figure 1: Generative model of causal inference. 1 This family of Bayesian posterior distributions also includes one used to successfully model cue combination in depth perception [27, 28]. In depth perception, however, there is no notion of segregation as always a single surface is assumed. 3 If there are two sources, they are assumed to be independent. Thus, we use the graphical model depicted in Fig. 1. We denote the number of sources by C. The probability distribution over C given internal representations xV and xA is given by Bayes’ rule: p (C|xV , xA ) ∝ p (xV , xA |C) p (C) . In this equation, p (C) is the a priori probability of C. We will denote the probability of a common cause by pcommon , so that p (C = 1) = pcommon and p (C = 2) = 1 − pcommon . The probability of generating xV and xA given C is obtained by inserting a summation over the sources: p (xV , xA |C = 1) = p (xV , xA |s)p (s) ds = p (xV |s) p (xA |s)p (s) ds Here p (s) is a prior for spatial location, which we assume to be distributed as N (s; 0, σP ). Then all three factors in this integral are Gaussians, allowing for an analytic solution: p (xV , xA |C = 1) = 2 2 2 2 2 −xA )2 σP σA √ 2 2 1 2 2 2 2 exp − 1 (xV σ2 σ2 +σ2+xV+σ2+xA σV . 2 σ2 σ2 2π σV σA +σV σP +σA σP V A V P A P For p (xV , xA |C = 2) we realize that xV and xA are independent of each other and thus obtain p (xV , xA |C = 2) = p (xV |sV )p (sV ) dsV p (xA |sA )p (sA ) dsA Again, as all these distributions are assumed to be Gaussian, we obtain an analytic solution, x2 x2 1 1 V A p (xV , xA |C = 2) = exp − 2 σ2 +σ2 + σ2 +σ2 . Now that we have com2 +σ 2 2 +σ 2 p p V A 2π (σV p )(σA p) puted p (C|xV , xA ), the posterior distribution over sources is given by p (si |xV , xA ) = p (si |xV , xA , C) p (C|xV , xA ) C=1,2 where i can be V or A and the posteriors conditioned on C are well-known: p (si |xA , xV , C = 1) = p (xA |si ) p (xV |si ) p (si ) , p (xA |s) p (xV |s) p (s) ds p (si |xA , xV , C = 2) = p (xi |si ) p (si ) p (xi |si ) p (si ) dsi The former is the same as in the case of mandatory integration with a prior, the latter is simply the unimodal posterior in the presence of a prior. Based on the posterior distribution on a given trial, p (si |xV , xA ), an estimate has to be created. For this, we use a sum-squared-error cost func2 2 tion, Cost = p (C = 1|xV , xA ) (ˆ − s) + p (C = 2|xV , xA ) (ˆ − sV or A ) . Then the best s s estimate is the mean of the posterior distribution, for instance for the visual estimation: sV = p (C = 1|xA , xV ) sV,C=1 + p (C = 2|xA , xV ) sV,C=2 ˆ ˆ ˆ where sV,C=1 = ˆ −2 −2 −2 xV σV +xA σA +xP σP −2 −2 −2 σV +σA +σP and sV,C=2 = ˆ −2 −2 xV σV +xP σP . −2 −2 σV +σP If pcommon equals 0 or 1, this estimate reduces to one of the conditioned estimates and is linear in xV and xA . If 0 < pcommon < 1, the estimate is a nonlinear combination of xV and xA , because of the functional form of p (C|xV , xA ). The response distributions, that is the distributions of sV and sA given ˆ ˆ sV and sA over many trials, now cannot be identiﬁed with the posterior distribution on a single trial and cannot be computed analytically either. The correct way to obtain the response distribution is to simulate an experiment numerically. Note that the causal inference model above can also be cast in the form of a bisensory stimulus prior by integrating out the latent variable C, with: p (sA , sV ) = p (C = 1) δ (sA − sV ) p (sA ) + p (sA ) p (sV ) p (C = 2) However, in addition to justifying the form of the interaction between the cues, the causal inference model has the advantage of being based on a generative model that well formalizes salient properties of the world, and it thereby also allows to predict judgments of unity. 4 3 Model performance and comparison To examine the performance of the causal inference model and to compare it to previous models, we performed a human psychophysics experiment in which we adopted the same dual-report paradigm as was used in [11]. Observers were simultaneously presented with a brief visual and also an auditory stimulus, each of which could originate from one of ﬁve locations on an imaginary horizontal line (-10◦ , -5◦ , 0◦ , 5◦ , or 10◦ with respect to the ﬁxation point). Auditory stimuli were 32 ms of white noise ﬁltered through an individually calibrated head related transfer function (HRTF) and presented through a pair of headphones, whereas the visual stimuli were high contrast Gabors on a noisy background presented on a 21-inch CRT monitor. Observers had to report by means of a key press (1-5) the perceived positions of both the visual and the auditory stimulus. Each combination of locations was presented with the same frequency over the course of the experiment. In this way, for each condition, visual and auditory response histograms were obtained. We obtained response distributions for each the three models described above by numeral simulation. On each trial, estimation is followed by a step in which, the key is selected which corresponds to the position closed to the best estimate. The simulated histograms obtained in this way were compared to the measured response frequencies of all subjects by computing the R2 statistic. Auditory response Auditory model Visual response Visual model no vision The parameters in the causal inference model were optimized using fminsearch in MATLAB to maximize R2 . The best combination of parameters yielded an R2 of 0.97. The response frequencies are depicted in Fig. 2. The bisensory prior models also explain most of the variance, with R2 = 0.96 for the Roach model and R2 = 0.91 for the Bresciani model. This shows that it is possible to model cue combination for large disparities well using such models. no audio 1 0 Figure 2: A comparison between subjects’ performance and the causal inference model. The blue line indicates the frequency of subjects responses to visual stimuli, red line is the responses to auditory stimuli. Each set of lines is one set of audio-visual stimulus conditions. Rows of conditions indicate constant visual stimulus, columns is constant audio stimulus. Model predictions is indicated by the red and blue dotted line. 5 3.1 Model comparison To facilitate quantitative comparison with other models, we now ﬁt the parameters of each model2 to individual subject data, maximizing the likelihood of the model, i.e., the probability of the response frequencies under the model. The causal inference model ﬁts human data better than the other models. Compared to the best ﬁt of the causal inference model, the Bresciani model has a maximal log likelihood ratio (base e) of the data of −22 ± 6 (mean ± s.e.m. over subjects), and the Roach model has a maximal log likelihood ratio of the data of −18 ± 6. A causal inference model that maximizes the probability of being correct instead of minimizing the mean squared error has a maximal log likelihood ratio of −18 ± 3. These values are considered decisive evidence in favor of the causal inference model that minimizes the mean squared error (for details, see [25]). The parameter values found in the likelihood optimization of the causal model are as follows: pcommon = 0.28 ± 0.05, σV = 2.14 ± 0.22◦ , σA = 9.2 ± 1.1◦ , σP = 12.3 ± 1.1◦ (mean ± s.e.m. over subjects). We see that there is a relatively low prior probability of a common cause. In this paradigm, auditory localization is considerably less precise than visual localization. Also, there is a weak prior for central locations. 3.2 Localization bias A useful quantity to gain more insight into the structure of multisensory data is the cross-modal bias. In our experiment, relative auditory bias is deﬁned as the difference between the mean auditory estimate in a given condition and the real auditory position, divided by the difference between the real visual position and the real auditory position in this condition. If the inﬂuence of vision on the auditory estimate is strong, then the relative auditory bias will be high (close to one). It is well-known that bias decreases with spatial disparity and our experiment is no exception (solid line in Fig. 3; data were combined between positive and negative disparities). It can easily be shown that a traditional cue integration model would predict a bias equal to σ2 −1 , which would be close to 1 and 1 + σV 2 A independent of disparity, unlike the data. This shows that a mandatory integration model is an insufﬁcient model of multisensory interactions. 45 % Auditory Bias We used the individual subject ﬁttings from above and and averaged the auditory bias values obtained from those ﬁts (i.e. we did not ﬁt the bias data themselves). Fits are shown in Fig. 3 (dashed lines). We applied a paired t-test to the differences between the 5◦ and 20◦ disparity conditions (model-subject comparison). Using a double-sided test, the null hypothesis that the difference between the bias in the 5◦ and 20◦ conditions is correctly predicted by each model is rejected for the Bresciani model (p < 0.002) and the Roach model (p < 0.042) and accepted for the causal inference model (p > 0.17). Alternatively, with a single-sided test, the hypothesis is rejected for the Bresciani model (p < 0.001) and the Roach model (p < 0.021) and accepted for the causal inference model (> 0.9). 50 40 35 30 25 20 5 10 15 Spatial Disparity (deg.) 20 Figure 3: Auditory bias as a function of spatial disparity. Solid blue line: data. Red: Causal inference model. Green: Model by Roach et al. [23]. Purple: Model by Bresciani et al. [22]. Models were optimized on response frequencies (as in Fig. 2), not on the bias data. The reason that the Bresciani model fares worst is that its prior distribution does not include a component that corresponds to independent causes. On 2 The Roach et al. model has four free parameters (ω,σV , σA , σcoupling ), the Bresciani et al. model has three (σV , σA , σcoupling ), and the causal inference model has four (pcommon ,σV , σA , σP ). We do not consider the Shams et al. model here, since it has many more parameters and it is not immediately clear how in this model the erroneous identiﬁcation of posterior with response distribution can be corrected. 6 the contrary, the prior used in the Roach model contains two terms, one term that is independent of the disparity and one term that decreases with increasing disparity. It is thus functionally somewhat similar to the causal inference model. 4 Discussion We have argued that any model of multisensory perception should account not only for situations of small, but also of large conﬂict. In these situations, segregation is more likely, in which the two stimuli are not perceived to have the same cause. Even when segregation occurs, the two stimuli can still inﬂuence each other. We compared three Bayesian models designed to account for situations of large conﬂict by applying them to auditory-visual spatial localization data. We pointed out a common mistake: for nonGaussian bisensory priors without mandatory integration, the response distribution can no longer be identiﬁed with the posterior distribution. After correct implementation of the three models, we found that the causal inference model is superior to the models with ad hoc bisensory priors. This is expected, as the nervous system actually needs to solve the problem of deciding which stimuli have a common cause and which stimuli are unrelated. We have seen that multisensory perception is a suitable tool for studying causal inference. However, the causal inference model also has the potential to quantitatively explain a number of other perceptual phenomena, including perceptual grouping and binding, as well as within-modality cue combination [27, 28]. Causal inference is a universal problem: whenever the brain has multiple pieces of information it must decide if they relate to one another or are independent. As the causal inference model describes how the brain processes probabilistic sensory information, the question arises about the neural basis of these processes. Neural populations encode probability distributions over stimuli through Bayes’ rule, a type of coding known as probabilistic population coding. Recent work has shown how the optimal cue combination assuming a common cause can be implemented in probabilistic population codes through simple linear operations on neural activities [29]. This framework makes essential use of the structure of neural variability and leads to physiological predictions for activity in areas that combine multisensory input, such as the superior colliculus. Computational mechanisms for causal inference are expected have a neural substrate that generalizes these linear operations on population activities. A neural implementation of the causal inference model will open the door to a complete neural theory of multisensory perception. References [1] H.L. Pick, D.H. Warren, and J.C. Hay. Sensory conﬂict in judgements of spatial direction. Percept. Psychophys., 6:203205, 1969. [2] D. H. Warren, R. B. Welch, and T. J. McCarthy. The role of visual-auditory ”compellingness” in the ventriloquism effect: implications for transitivity among the spatial senses. Percept Psychophys, 30(6):557– 64, 1981. [3] D. Alais and D. Burr. The ventriloquist effect results from near-optimal bimodal integration. Curr Biol, 14(3):257–62, 2004. [4] R. A. Jacobs. Optimal integration of texture and motion cues to depth. Vision Res, 39(21):3621–9, 1999. [5] R. J. van Beers, A. C. Sittig, and J. J. Gon. Integration of proprioceptive and visual position-information: An experimentally supported model. J Neurophysiol, 81(3):1355–64, 1999. [6] D. H. Warren and W. T. Cleaves. Visual-proprioceptive interaction under large amounts of conﬂict. J Exp Psychol, 90(2):206–14, 1971. [7] C. E. Jack and W. R. Thurlow. Effects of degree of visual association and angle of displacement on the ”ventriloquism” effect. Percept Mot Skills, 37(3):967–79, 1973. [8] G. H. Recanzone. Auditory inﬂuences on visual temporal rate perception. J Neurophysiol, 89(2):1078–93, 2003. [9] J. P. Bresciani, M. O. Ernst, K. Drewing, G. Bouyer, V. Maury, and A. Kheddar. Feeling what you hear: auditory signals can modulate tactile tap perception. Exp Brain Res, 162(2):172–80, 2005. 7 [10] R. Gepshtein, P. Leiderman, L. Genosar, and D. Huppert. Testing the three step excited state proton transfer model by the effect of an excess proton. J Phys Chem A Mol Spectrosc Kinet Environ Gen Theory, 109(42):9674–84, 2005. [11] L. Shams, W. J. Ma, and U. Beierholm. Sound-induced ﬂash illusion as an optimal percept. Neuroreport, 16(17):1923–7, 2005. [12] G Thomas. Experimental study of the inﬂuence of vision on sound localisation. J Exp Psychol, 28:167177, 1941. [13] W. R. Thurlow and C. E. Jack. Certain determinants of the ”ventriloquism effect”. Percept Mot Skills, 36(3):1171–84, 1973. [14] C.S. Choe, R. B. Welch, R.M. Gilford, and J.F. Juola. The ”ventriloquist effect”: visual dominance or response bias. Perception and Psychophysics, 18:55–60, 1975. [15] R. I. Bermant and R. B. Welch. Effect of degree of separation of visual-auditory stimulus and eye position upon spatial interaction of vision and audition. Percept Mot Skills, 42(43):487–93, 1976. [16] R. B. Welch and D. H. Warren. Immediate perceptual response to intersensory discrepancy. Psychol Bull, 88(3):638–67, 1980. [17] P. Bertelson and M. Radeau. Cross-modal bias and perceptual fusion with auditory-visual spatial discordance. Percept Psychophys, 29(6):578–84, 1981. [18] P. Bertelson, F. Pavani, E. Ladavas, J. Vroomen, and B. de Gelder. Ventriloquism in patients with unilateral visual neglect. Neuropsychologia, 38(12):1634–42, 2000. [19] D. A. Slutsky and G. H. Recanzone. Temporal and spatial dependency of the ventriloquism effect. Neuroreport, 12(1):7–10, 2001. [20] J. Lewald, W. H. Ehrenstein, and R. Guski. Spatio-temporal constraints for auditory–visual integration. Behav Brain Res, 121(1-2):69–79, 2001. [21] M. T. Wallace, G. E. Roberson, W. D. Hairston, B. E. Stein, J. W. Vaughan, and J. A. Schirillo. Unifying multisensory signals across time and space. Exp Brain Res, 158(2):252–8, 2004. [22] J. P. Bresciani, F. Dammeier, and M. O. Ernst. Vision and touch are automatically integrated for the perception of sequences of events. J Vis, 6(5):554–64, 2006. [23] N. W. Roach, J. Heron, and P. V. McGraw. Resolving multisensory conﬂict: a strategy for balancing the costs and beneﬁts of audio-visual integration. Proc Biol Sci, 273(1598):2159–68, 2006. [24] K. P. Kording and D. M. Wolpert. Bayesian decision theory in sensorimotor control. Trends Cogn Sci, 2006. 1364-6613 (Print) Journal article. [25] K.P. Kording, U. Beierholm, W.J. Ma, S. Quartz, J. Tenenbaum, and L. Shams. Causal inference in multisensory perception. PLoS ONE, 2(9):e943, 2007. [26] Z. Ghahramani. Computational and psychophysics of sensorimotor integration. PhD thesis, Massachusetts Institute of Technology, 1995. [27] D. C. Knill. Mixture models and the probabilistic structure of depth cues. Vision Res, 43(7):831–54, 2003. [28] D. C. Knill. Robust cue integration: A bayesian model and evidence from cue conﬂict studies with stereoscopic and ﬁgure cues to slant. Journal of Vision, 7(7):2–24. [29] W. J. Ma, J. M. Beck, P. E. Latham, and A. Pouget. Bayesian inference with probabilistic population codes. Nat Neurosci, 9(11):1432–8, 2006. 8</p><p>same-paper 2 0.76920801 <a title="207-lda-2" href="./nips-2007-Transfer_Learning_using_Kolmogorov_Complexity%3A_Basic_Theory_and_Empirical_Evaluations.html">207 nips-2007-Transfer Learning using Kolmogorov Complexity: Basic Theory and Empirical Evaluations</a></p>
<p>Author: M. M. Mahmud, Sylvian Ray</p><p>Abstract: In transfer learning we aim to solve new problems using fewer examples using information gained from solving related problems. Transfer learning has been successful in practice, and extensive PAC analysis of these methods has been developed. However it is not yet clear how to deﬁne relatedness between tasks. This is considered as a major problem as it is conceptually troubling and it makes it unclear how much information to transfer and when and how to transfer it. In this paper we propose to measure the amount of information one task contains about another using conditional Kolmogorov complexity between the tasks. We show how existing theory neatly solves the problem of measuring relatedness and transferring the ‘right’ amount of information in sequential transfer learning in a Bayesian setting. The theory also suggests that, in a very formal and precise sense, no other reasonable transfer method can do much better than our Kolmogorov Complexity theoretic transfer method, and that sequential transfer is always justiﬁed. We also develop a practical approximation to the method and use it to transfer information between 8 arbitrarily chosen databases from the UCI ML repository. 1</p><p>3 0.7517072 <a title="207-lda-3" href="./nips-2007-Fast_and_Scalable_Training_of_Semi-Supervised_CRFs_with_Application_to_Activity_Recognition.html">88 nips-2007-Fast and Scalable Training of Semi-Supervised CRFs with Application to Activity Recognition</a></p>
<p>Author: Maryam Mahdaviani, Tanzeem Choudhury</p><p>Abstract: We present a new and efﬁcient semi-supervised training method for parameter estimation and feature selection in conditional random ﬁelds (CRFs). In real-world applications such as activity recognition, unlabeled sensor traces are relatively easy to obtain whereas labeled examples are expensive and tedious to collect. Furthermore, the ability to automatically select a small subset of discriminatory features from a large pool can be advantageous in terms of computational speed as well as accuracy. In this paper, we introduce the semi-supervised virtual evidence boosting (sVEB) algorithm for training CRFs – a semi-supervised extension to the recently developed virtual evidence boosting (VEB) method for feature selection and parameter learning. The objective function of sVEB combines the unlabeled conditional entropy with labeled conditional pseudo-likelihood. It reduces the overall system cost as well as the human labeling cost required during training, which are both important considerations in building real-world inference systems. Experiments on synthetic data and real activity traces collected from wearable sensors, illustrate that sVEB beneﬁts from both the use of unlabeled data and automatic feature selection, and outperforms other semi-supervised approaches. 1</p><p>4 0.6306209 <a title="207-lda-4" href="./nips-2007-Support_Vector_Machine_Classification_with_Indefinite_Kernels.html">190 nips-2007-Support Vector Machine Classification with Indefinite Kernels</a></p>
<p>Author: Ronny Luss, Alexandre D'aspremont</p><p>Abstract: In this paper, we propose a method for support vector machine classiﬁcation using indeﬁnite kernels. Instead of directly minimizing or stabilizing a nonconvex loss function, our method simultaneously ﬁnds the support vectors and a proxy kernel matrix used in computing the loss. This can be interpreted as a robust classiﬁcation problem where the indeﬁnite kernel matrix is treated as a noisy observation of the true positive semideﬁnite kernel. Our formulation keeps the problem convex and relatively large problems can be solved efﬁciently using the analytic center cutting plane method. We compare the performance of our technique with other methods on several data sets.</p><p>5 0.57166386 <a title="207-lda-5" href="./nips-2007-Convex_Relaxations_of_Latent_Variable_Training.html">63 nips-2007-Convex Relaxations of Latent Variable Training</a></p>
<p>Author: Yuhong Guo, Dale Schuurmans</p><p>Abstract: We investigate a new, convex relaxation of an expectation-maximization (EM) variant that approximates a standard objective while eliminating local minima. First, a cautionary result is presented, showing that any convex relaxation of EM over hidden variables must give trivial results if any dependence on the missing values is retained. Although this appears to be a strong negative outcome, we then demonstrate how the problem can be bypassed by using equivalence relations instead of value assignments over hidden variables. In particular, we develop new algorithms for estimating exponential conditional models that only require equivalence relation information over the variable values. This reformulation leads to an exact expression for EM variants in a wide range of problems. We then develop a semideﬁnite relaxation that yields global training by eliminating local minima. 1</p><p>6 0.56639624 <a title="207-lda-6" href="./nips-2007-Gaussian_Process_Models_for_Link_Analysis_and_Transfer_Learning.html">94 nips-2007-Gaussian Process Models for Link Analysis and Transfer Learning</a></p>
<p>7 0.56446695 <a title="207-lda-7" href="./nips-2007-DIFFRAC%3A_a_discriminative_and_flexible_framework_for_clustering.html">65 nips-2007-DIFFRAC: a discriminative and flexible framework for clustering</a></p>
<p>8 0.56334835 <a title="207-lda-8" href="./nips-2007-Learning_the_2-D_Topology_of_Images.html">115 nips-2007-Learning the 2-D Topology of Images</a></p>
<p>9 0.56326783 <a title="207-lda-9" href="./nips-2007-Classification_via_Minimum_Incremental_Coding_Length_%28MICL%29.html">45 nips-2007-Classification via Minimum Incremental Coding Length (MICL)</a></p>
<p>10 0.56175113 <a title="207-lda-10" href="./nips-2007-Sparse_Feature_Learning_for_Deep_Belief_Networks.html">180 nips-2007-Sparse Feature Learning for Deep Belief Networks</a></p>
<p>11 0.5615381 <a title="207-lda-11" href="./nips-2007-Theoretical_Analysis_of_Heuristic_Search_Methods_for_Online_POMDPs.html">204 nips-2007-Theoretical Analysis of Heuristic Search Methods for Online POMDPs</a></p>
<p>12 0.56091142 <a title="207-lda-12" href="./nips-2007-The_Value_of_Labeled_and_Unlabeled_Examples_when_the_Model_is_Imperfect.html">201 nips-2007-The Value of Labeled and Unlabeled Examples when the Model is Imperfect</a></p>
<p>13 0.5604102 <a title="207-lda-13" href="./nips-2007-Structured_Learning_with_Approximate_Inference.html">187 nips-2007-Structured Learning with Approximate Inference</a></p>
<p>14 0.56019962 <a title="207-lda-14" href="./nips-2007-Message_Passing_for_Max-weight_Independent_Set.html">128 nips-2007-Message Passing for Max-weight Independent Set</a></p>
<p>15 0.55995309 <a title="207-lda-15" href="./nips-2007-Efficient_Bayesian_Inference_for_Dynamically_Changing_Graphs.html">75 nips-2007-Efficient Bayesian Inference for Dynamically Changing Graphs</a></p>
<p>16 0.55973685 <a title="207-lda-16" href="./nips-2007-Linear_programming_analysis_of_loopy_belief_propagation_for_weighted_matching.html">120 nips-2007-Linear programming analysis of loopy belief propagation for weighted matching</a></p>
<p>17 0.55897409 <a title="207-lda-17" href="./nips-2007-Bayesian_Policy_Learning_with_Trans-Dimensional_MCMC.html">34 nips-2007-Bayesian Policy Learning with Trans-Dimensional MCMC</a></p>
<p>18 0.55887151 <a title="207-lda-18" href="./nips-2007-Statistical_Analysis_of_Semi-Supervised_Regression.html">186 nips-2007-Statistical Analysis of Semi-Supervised Regression</a></p>
<p>19 0.55886132 <a title="207-lda-19" href="./nips-2007-Fitted_Q-iteration_in_continuous_action-space_MDPs.html">91 nips-2007-Fitted Q-iteration in continuous action-space MDPs</a></p>
<p>20 0.55873644 <a title="207-lda-20" href="./nips-2007-Ultrafast_Monte_Carlo_for_Statistical_Summations.html">209 nips-2007-Ultrafast Monte Carlo for Statistical Summations</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
