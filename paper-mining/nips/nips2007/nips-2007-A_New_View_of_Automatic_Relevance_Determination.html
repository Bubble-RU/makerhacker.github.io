<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>8 nips-2007-A New View of Automatic Relevance Determination</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-8" href="#">nips2007-8</a> knowledge-graph by maker-knowledge-mining</p><h1>8 nips-2007-A New View of Automatic Relevance Determination</h1>
<br/><p>Source: <a title="nips-2007-8-pdf" href="http://papers.nips.cc/paper/3372-a-new-view-of-automatic-relevance-determination.pdf">pdf</a></p><p>Author: David P. Wipf, Srikantan S. Nagarajan</p><p>Abstract: Automatic relevance determination (ARD) and the closely-related sparse Bayesian learning (SBL) framework are effective tools for pruning large numbers of irrelevant features leading to a sparse explanatory subset. However, popular update rules used for ARD are either difﬁcult to extend to more general problems of interest or are characterized by non-ideal convergence properties. Moreover, it remains unclear exactly how ARD relates to more traditional MAP estimation-based methods for learning sparse representations (e.g., the Lasso). This paper furnishes an alternative means of expressing the ARD cost function using auxiliary functions that naturally addresses both of these issues. First, the proposed reformulation of ARD can naturally be optimized by solving a series of re-weighted 1 problems. The result is an efﬁcient, extensible algorithm that can be implemented using standard convex programming toolboxes and is guaranteed to converge to a local minimum (or saddle point). Secondly, the analysis reveals that ARD is exactly equivalent to performing standard MAP estimation in weight space using a particular feature- and noise-dependent, non-factorial weight prior. We then demonstrate that this implicit prior maintains several desirable advantages over conventional priors with respect to feature selection. Overall these results suggest alternative cost functions and update procedures for selecting features and promoting sparse solutions in a variety of general situations. In particular, the methodology readily extends to handle problems such as non-negative sparse coding and covariance component estimation. 1</p><p>Reference: <a title="nips-2007-8-reference" href="../nips2007_reference/nips-2007-A_New_View_of_Automatic_Relevance_Determination_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ard', 0.753), ('spars', 0.214), ('lz', 0.161), ('mackay', 0.15), ('lasso', 0.148), ('xard', 0.134), ('pri', 0.128), ('xi', 0.118), ('sbl', 0.108), ('promot', 0.107), ('concav', 0.099), ('glob', 0.095), ('auxy', 0.093), ('saddl', 0.09), ('minim', 0.079), ('implicit', 0.073), ('zi', 0.07), ('feas', 0.063), ('hyperparamet', 0.062), ('map', 0.062)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999964 <a title="8-tfidf-1" href="./nips-2007-A_New_View_of_Automatic_Relevance_Determination.html">8 nips-2007-A New View of Automatic Relevance Determination</a></p>
<p>2 0.28246158 <a title="8-tfidf-2" href="./nips-2007-On_Sparsity_and_Overcompleteness_in_Image_Models.html">145 nips-2007-On Sparsity and Overcompleteness in Image Models</a></p>
<p>3 0.20303658 <a title="8-tfidf-3" href="./nips-2007-Heterogeneous_Component_Analysis.html">96 nips-2007-Heterogeneous Component Analysis</a></p>
<p>4 0.13270672 <a title="8-tfidf-4" href="./nips-2007-Learning_Horizontal_Connections_in_a_Sparse_Coding_Model_of_Natural_Images.html">111 nips-2007-Learning Horizontal Connections in a Sparse Coding Model of Natural Images</a></p>
<p>5 0.10889357 <a title="8-tfidf-5" href="./nips-2007-Compressed_Regression.html">53 nips-2007-Compressed Regression</a></p>
<p>6 0.10582028 <a title="8-tfidf-6" href="./nips-2007-Hierarchical_Penalization.html">99 nips-2007-Hierarchical Penalization</a></p>
<p>7 0.097955324 <a title="8-tfidf-7" href="./nips-2007-Catching_Change-points_with_Lasso.html">43 nips-2007-Catching Change-points with Lasso</a></p>
<p>8 0.090092063 <a title="8-tfidf-8" href="./nips-2007-Efficient_multiple_hyperparameter_learning_for_log-linear_models.html">79 nips-2007-Efficient multiple hyperparameter learning for log-linear models</a></p>
<p>9 0.087732039 <a title="8-tfidf-9" href="./nips-2007-Convex_Relaxations_of_Latent_Variable_Training.html">63 nips-2007-Convex Relaxations of Latent Variable Training</a></p>
<p>10 0.086295158 <a title="8-tfidf-10" href="./nips-2007-Sparse_Overcomplete_Latent_Variable_Decomposition_of_Counts_Data.html">181 nips-2007-Sparse Overcomplete Latent Variable Decomposition of Counts Data</a></p>
<p>11 0.081333615 <a title="8-tfidf-11" href="./nips-2007-SpAM%3A_Sparse_Additive_Models.html">179 nips-2007-SpAM: Sparse Additive Models</a></p>
<p>12 0.072537377 <a title="8-tfidf-12" href="./nips-2007-Sparse_Feature_Learning_for_Deep_Belief_Networks.html">180 nips-2007-Sparse Feature Learning for Deep Belief Networks</a></p>
<p>13 0.070652217 <a title="8-tfidf-13" href="./nips-2007-Multi-task_Gaussian_Process_Prediction.html">135 nips-2007-Multi-task Gaussian Process Prediction</a></p>
<p>14 0.069195643 <a title="8-tfidf-14" href="./nips-2007-Sparse_deep_belief_net_model_for_visual_area_V2.html">182 nips-2007-Sparse deep belief net model for visual area V2</a></p>
<p>15 0.068044409 <a title="8-tfidf-15" href="./nips-2007-The_Generalized_FITC_Approximation.html">195 nips-2007-The Generalized FITC Approximation</a></p>
<p>16 0.066038512 <a title="8-tfidf-16" href="./nips-2007-Regulator_Discovery_from_Gene_Expression_Time_Series_of_Malaria_Parasites%3A_a_Hierachical_Approach.html">167 nips-2007-Regulator Discovery from Gene Expression Time Series of Malaria Parasites: a Hierachical Approach</a></p>
<p>17 0.06601844 <a title="8-tfidf-17" href="./nips-2007-Convex_Clustering_with_Exemplar-Based_Models.html">61 nips-2007-Convex Clustering with Exemplar-Based Models</a></p>
<p>18 0.061362747 <a title="8-tfidf-18" href="./nips-2007-A_Spectral_Regularization_Framework_for_Multi-Task_Structure_Learning.html">12 nips-2007-A Spectral Regularization Framework for Multi-Task Structure Learning</a></p>
<p>19 0.059863701 <a title="8-tfidf-19" href="./nips-2007-Fixing_Max-Product%3A_Convergent_Message_Passing_Algorithms_for_MAP_LP-Relaxations.html">92 nips-2007-Fixing Max-Product: Convergent Message Passing Algorithms for MAP LP-Relaxations</a></p>
<p>20 0.058820054 <a title="8-tfidf-20" href="./nips-2007-Predictive_Matrix-Variate_t_Models.html">156 nips-2007-Predictive Matrix-Variate t Models</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2007_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.225), (1, -0.046), (2, 0.071), (3, -0.034), (4, 0.015), (5, 0.08), (6, -0.135), (7, 0.007), (8, 0.006), (9, 0.02), (10, 0.111), (11, 0.039), (12, 0.023), (13, 0.203), (14, -0.066), (15, 0.236), (16, 0.148), (17, -0.052), (18, 0.051), (19, -0.107), (20, 0.07), (21, -0.045), (22, -0.049), (23, 0.011), (24, -0.04), (25, 0.02), (26, 0.223), (27, 0.069), (28, -0.048), (29, -0.03), (30, -0.027), (31, -0.081), (32, -0.069), (33, -0.059), (34, 0.037), (35, -0.056), (36, 0.075), (37, -0.079), (38, -0.098), (39, -0.128), (40, -0.003), (41, 0.012), (42, 0.049), (43, 0.063), (44, 0.049), (45, 0.036), (46, -0.028), (47, -0.0), (48, 0.103), (49, -0.012)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.91805995 <a title="8-lsi-1" href="./nips-2007-A_New_View_of_Automatic_Relevance_Determination.html">8 nips-2007-A New View of Automatic Relevance Determination</a></p>
<p>2 0.80191898 <a title="8-lsi-2" href="./nips-2007-Heterogeneous_Component_Analysis.html">96 nips-2007-Heterogeneous Component Analysis</a></p>
<p>3 0.73308134 <a title="8-lsi-3" href="./nips-2007-On_Sparsity_and_Overcompleteness_in_Image_Models.html">145 nips-2007-On Sparsity and Overcompleteness in Image Models</a></p>
<p>4 0.6425944 <a title="8-lsi-4" href="./nips-2007-SpAM%3A_Sparse_Additive_Models.html">179 nips-2007-SpAM: Sparse Additive Models</a></p>
<p>5 0.61621875 <a title="8-lsi-5" href="./nips-2007-Compressed_Regression.html">53 nips-2007-Compressed Regression</a></p>
<p>6 0.61013192 <a title="8-lsi-6" href="./nips-2007-Regulator_Discovery_from_Gene_Expression_Time_Series_of_Malaria_Parasites%3A_a_Hierachical_Approach.html">167 nips-2007-Regulator Discovery from Gene Expression Time Series of Malaria Parasites: a Hierachical Approach</a></p>
<p>7 0.59928924 <a title="8-lsi-7" href="./nips-2007-Learning_Horizontal_Connections_in_a_Sparse_Coding_Model_of_Natural_Images.html">111 nips-2007-Learning Horizontal Connections in a Sparse Coding Model of Natural Images</a></p>
<p>8 0.55742663 <a title="8-lsi-8" href="./nips-2007-Hierarchical_Penalization.html">99 nips-2007-Hierarchical Penalization</a></p>
<p>9 0.50890905 <a title="8-lsi-9" href="./nips-2007-Efficient_multiple_hyperparameter_learning_for_log-linear_models.html">79 nips-2007-Efficient multiple hyperparameter learning for log-linear models</a></p>
<p>10 0.49634922 <a title="8-lsi-10" href="./nips-2007-Probabilistic_Matrix_Factorization.html">158 nips-2007-Probabilistic Matrix Factorization</a></p>
<p>11 0.49175897 <a title="8-lsi-11" href="./nips-2007-The_Generalized_FITC_Approximation.html">195 nips-2007-The Generalized FITC Approximation</a></p>
<p>12 0.49101746 <a title="8-lsi-12" href="./nips-2007-Predictive_Matrix-Variate_t_Models.html">156 nips-2007-Predictive Matrix-Variate t Models</a></p>
<p>13 0.47884074 <a title="8-lsi-13" href="./nips-2007-Sparse_Overcomplete_Latent_Variable_Decomposition_of_Counts_Data.html">181 nips-2007-Sparse Overcomplete Latent Variable Decomposition of Counts Data</a></p>
<p>14 0.46260995 <a title="8-lsi-14" href="./nips-2007-Catching_Change-points_with_Lasso.html">43 nips-2007-Catching Change-points with Lasso</a></p>
<p>15 0.45679078 <a title="8-lsi-15" href="./nips-2007-Blind_channel_identification_for_speech_dereverberation_using_l1-norm_sparse_learning.html">37 nips-2007-Blind channel identification for speech dereverberation using l1-norm sparse learning</a></p>
<p>16 0.43457693 <a title="8-lsi-16" href="./nips-2007-Sparse_Feature_Learning_for_Deep_Belief_Networks.html">180 nips-2007-Sparse Feature Learning for Deep Belief Networks</a></p>
<p>17 0.40296236 <a title="8-lsi-17" href="./nips-2007-Modelling_motion_primitives_and_their_timing_in_biologically_executed_movements.html">133 nips-2007-Modelling motion primitives and their timing in biologically executed movements</a></p>
<p>18 0.38850334 <a title="8-lsi-18" href="./nips-2007-Modeling_Natural_Sounds_with_Modulation_Cascade_Processes.html">130 nips-2007-Modeling Natural Sounds with Modulation Cascade Processes</a></p>
<p>19 0.383681 <a title="8-lsi-19" href="./nips-2007-A_Spectral_Regularization_Framework_for_Multi-Task_Structure_Learning.html">12 nips-2007-A Spectral Regularization Framework for Multi-Task Structure Learning</a></p>
<p>20 0.36898789 <a title="8-lsi-20" href="./nips-2007-Feature_Selection_Methods_for_Improving_Protein_Structure_Prediction_with_Rosetta.html">89 nips-2007-Feature Selection Methods for Improving Protein Structure Prediction with Rosetta</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2007_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(25, 0.079), (30, 0.076), (45, 0.048), (46, 0.129), (53, 0.038), (56, 0.023), (58, 0.241), (60, 0.201), (62, 0.031), (88, 0.012), (90, 0.024)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.8162787 <a title="8-lda-1" href="./nips-2007-A_Randomized_Algorithm_for_Large_Scale_Support_Vector_Learning.html">10 nips-2007-A Randomized Algorithm for Large Scale Support Vector Learning</a></p>
<p>same-paper 2 0.81291234 <a title="8-lda-2" href="./nips-2007-A_New_View_of_Automatic_Relevance_Determination.html">8 nips-2007-A New View of Automatic Relevance Determination</a></p>
<p>3 0.79195625 <a title="8-lda-3" href="./nips-2007-Topmoumoute_Online_Natural_Gradient_Algorithm.html">206 nips-2007-Topmoumoute Online Natural Gradient Algorithm</a></p>
<p>4 0.73777014 <a title="8-lda-4" href="./nips-2007-Bayesian_Co-Training.html">32 nips-2007-Bayesian Co-Training</a></p>
<p>5 0.73707759 <a title="8-lda-5" href="./nips-2007-Hierarchical_Penalization.html">99 nips-2007-Hierarchical Penalization</a></p>
<p>6 0.73657763 <a title="8-lda-6" href="./nips-2007-Convex_Relaxations_of_Latent_Variable_Training.html">63 nips-2007-Convex Relaxations of Latent Variable Training</a></p>
<p>7 0.73511666 <a title="8-lda-7" href="./nips-2007-Catching_Change-points_with_Lasso.html">43 nips-2007-Catching Change-points with Lasso</a></p>
<p>8 0.73480946 <a title="8-lda-8" href="./nips-2007-Ensemble_Clustering_using_Semidefinite_Programming.html">80 nips-2007-Ensemble Clustering using Semidefinite Programming</a></p>
<p>9 0.73402494 <a title="8-lda-9" href="./nips-2007-SpAM%3A_Sparse_Additive_Models.html">179 nips-2007-SpAM: Sparse Additive Models</a></p>
<p>10 0.73380131 <a title="8-lda-10" href="./nips-2007-A_Unified_Near-Optimal_Estimator_For_Dimension_Reduction_in_%24l_%5Calpha%24_%28%240%3C%5Calpha%5Cleq_2%24%29_Using_Stable_Random_Projections.html">13 nips-2007-A Unified Near-Optimal Estimator For Dimension Reduction in $l \alpha$ ($0<\alpha\leq 2$) Using Stable Random Projections</a></p>
<p>11 0.73316753 <a title="8-lda-11" href="./nips-2007-Semi-Supervised_Multitask_Learning.html">175 nips-2007-Semi-Supervised Multitask Learning</a></p>
<p>12 0.73310667 <a title="8-lda-12" href="./nips-2007-Hidden_Common_Cause_Relations_in_Relational_Learning.html">97 nips-2007-Hidden Common Cause Relations in Relational Learning</a></p>
<p>13 0.73149526 <a title="8-lda-13" href="./nips-2007-Multi-task_Gaussian_Process_Prediction.html">135 nips-2007-Multi-task Gaussian Process Prediction</a></p>
<p>14 0.73133731 <a title="8-lda-14" href="./nips-2007-Learning_Monotonic_Transformations_for_Classification.html">112 nips-2007-Learning Monotonic Transformations for Classification</a></p>
<p>15 0.73071069 <a title="8-lda-15" href="./nips-2007-Efficient_Inference_for_Distributions_on_Permutations.html">77 nips-2007-Efficient Inference for Distributions on Permutations</a></p>
<p>16 0.73070383 <a title="8-lda-16" href="./nips-2007-A_General_Boosting_Method_and_its_Application_to_Learning_Ranking_Functions_for_Web_Search.html">6 nips-2007-A General Boosting Method and its Application to Learning Ranking Functions for Web Search</a></p>
<p>17 0.73009419 <a title="8-lda-17" href="./nips-2007-Discriminative_Batch_Mode_Active_Learning.html">69 nips-2007-Discriminative Batch Mode Active Learning</a></p>
<p>18 0.72991866 <a title="8-lda-18" href="./nips-2007-Regularized_Boost_for_Semi-Supervised_Learning.html">166 nips-2007-Regularized Boost for Semi-Supervised Learning</a></p>
<p>19 0.72965783 <a title="8-lda-19" href="./nips-2007-Classification_via_Minimum_Incremental_Coding_Length_%28MICL%29.html">45 nips-2007-Classification via Minimum Incremental Coding Length (MICL)</a></p>
<p>20 0.72944796 <a title="8-lda-20" href="./nips-2007-Discriminative_K-means_for_Clustering.html">70 nips-2007-Discriminative K-means for Clustering</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
