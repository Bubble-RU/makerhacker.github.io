<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>19 nips-2007-Active Preference Learning with Discrete Choice Data</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-19" href="#">nips2007-19</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>19 nips-2007-Active Preference Learning with Discrete Choice Data</h1>
<br/><p>Source: <a title="nips-2007-19-pdf" href="http://papers.nips.cc/paper/3219-active-preference-learning-with-discrete-choice-data.pdf">pdf</a></p><p>Author: Brochu Eric, Nando D. Freitas, Abhijeet Ghosh</p><p>Abstract: We propose an active learning algorithm that learns a continuous valuation model from discrete preferences. The algorithm automatically decides what items are best presented to an individual in order to ﬁnd the item that they value highly in as few trials as possible, and exploits quirks of human psychology to minimize time and cognitive burden. To do this, our algorithm maximizes the expected improvement at each query without accurately modelling the entire valuation surface, which would be needlessly expensive. The problem is particularly difﬁcult because the space of choices is inﬁnite. We demonstrate the effectiveness of the new algorithm compared to related active learning methods. We also embed the algorithm within a decision making tool for assisting digital artists in rendering materials. The tool ﬁnds the best parameters while minimizing the number of queries. 1</p><p>Reference: <a title="nips-2007-19-reference" href="../nips2007_reference/nips-2007-Active_Preference_Learning_with_Discrete_Choice_Data_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 ca  Abstract We propose an active learning algorithm that learns a continuous valuation model from discrete preferences. [sent-3, score-0.617]
</p><p>2 The algorithm automatically decides what items are best presented to an individual in order to ﬁnd the item that they value highly in as few trials as possible, and exploits quirks of human psychology to minimize time and cognitive burden. [sent-4, score-0.268]
</p><p>3 To do this, our algorithm maximizes the expected improvement at each query without accurately modelling the entire valuation surface, which would be needlessly expensive. [sent-5, score-0.669]
</p><p>4 We demonstrate the effectiveness of the new algorithm compared to related active learning methods. [sent-7, score-0.122]
</p><p>5 We also embed the algorithm within a decision making tool for assisting digital artists in rendering materials. [sent-8, score-0.118]
</p><p>6 1  Introduction  A computer graphics artist sits down to use a simple renderer to ﬁnd appropriate surfaces for a typical reﬂectance model. [sent-10, score-0.181]
</p><p>7 He moves the specularity slider and waits for the image to be generated. [sent-15, score-0.168]
</p><p>8 He moves the slider back a bit and runs the simulation again. [sent-17, score-0.084]
</p><p>9 Now it’s the right colour, but the specularity doesn’t look quite right any more. [sent-21, score-0.084]
</p><p>10 He repeatedly bumps the specularity back up, rerunning the renderer at each attempt until it looks right. [sent-22, score-0.162]
</p><p>11 This is particularly apparent in psychoperceptual models, where continual tuning is required to make something “look right”. [sent-29, score-0.084]
</p><p>12 Using the animation of character walking motion as an example, for decades, animators and scientists have tried to develop objective functions based on kinematics, dynamics and motion capture data [Cooper et al. [sent-30, score-0.215]
</p><p>13 However, even when expensive mocap is available, we simply have to watch an animated ﬁlm to be convinced of how far we still are from solving the gait animation problem. [sent-32, score-0.134]
</p><p>14 Unfortunately, it is not at all easy to ﬁnd a mapping from parameterized animation to psychoperceptual plausibility. [sent-33, score-0.218]
</p><p>15 The application of this principle to animation and other psychoperceptual tools is motivated by the observation that humans often seem to be forming a mental model of the objective function. [sent-36, score-0.251]
</p><p>16 This model enables them to exploit feasible regions of the parameter space where the valuation is predicted to be high and to explore regions of high uncertainty. [sent-37, score-0.495]
</p><p>17 When resources are limited, such as an active learning environment, it is far more useful to ﬁt the area of interest well, even at the cost of overall predictive performance. [sent-41, score-0.157]
</p><p>18 Our objective function is the psycho-perceptual process underlying judgement — how well a realization ﬁts what the user has in mind. [sent-44, score-0.294]
</p><p>19 In the case of a human being rating the suitability of a simulation, however, it is not possible to evaluate this function over the entire domain. [sent-46, score-0.119]
</p><p>20 While it would theoretically be possible to ask the user to rate realizations with some numerical scale, such methods often have problems with validity and reliability. [sent-48, score-0.3]
</p><p>21 However, human beings do excel at comparing options and expressing a preference for one over others [Kingsley, 2006]. [sent-50, score-0.297]
</p><p>22 By presenting two or more realizations to a user and requiring only that they indicate preference, we can get far more robust results with much less cognitive burden on the user [Kendall, 1975]. [sent-52, score-0.645]
</p><p>23 While this means we can’t get responses for a valuation function directly, we model the valuation as a latent function, inferred from the preferences, which permits an active learning approach [Cohn et al. [sent-53, score-1.236]
</p><p>24 We can’t directly maximize the valuation function, so we propose to use an expected improvement function (EIF) [Jones et al. [sent-57, score-0.622]
</p><p>25 The EIF produces an estimate of the utility of knowing the valuation at any point in the space. [sent-59, score-0.547]
</p><p>26 The result is a principled way of trading off exploration (showing the user examples unlike any they have seen) and exploitation (trying to show the user improvements on examples they have indicated preference for). [sent-60, score-0.771]
</p><p>27 Of course, regression-based learning can produce an accurate model of the entire valuation function, which would also allow us to ﬁnd the best valuation. [sent-61, score-0.534]
</p><p>28 However, this comes at the cost of asking the user to compare many, many examples that have no practical relation what she is looking for, as we demonstrate experimentally in Sections 3 and 4. [sent-62, score-0.294]
</p><p>29 Our goal is to exploit the strengths of human psychology and perception to develop a novel framework of valuation optimization that uses active preference learning to ﬁnd the point in a parameter space that approximately maximizes valuation with the least effort to the human user. [sent-64, score-1.504]
</p><p>30 In Section 4, we present a simple, but practical application of our model in a material design gallery that allows artists to ﬁnd particular appearance rendering effects. [sent-66, score-0.608]
</p><p>31 Though we use animation and rendering as motivating domains, our work has a broad scope of application in music and other arts, as well as psychology, marketing and econometrics, and human-computer interfaces. [sent-68, score-0.248]
</p><p>32 1  Previous Work  Probability models for learning from discrete choices have a long history in psychology and econometrics [Thurstone, 1927; Mosteller, 1951; Stern, 1990; McFadden, 2001]. [sent-70, score-0.102]
</p><p>33 These methods all differ from our work in that they are intended to predict the probability of a preference outcome over a ﬁnite set of possible pairs, whereas we work with inﬁnite sets and are only incidentally interested in modelling outcomes. [sent-73, score-0.282]
</p><p>34 In Section 4, we introduce a novel “preference gallery” application for designing simulated materials in graphics and animation to demonstrate the practical utility of our model. [sent-74, score-0.377]
</p><p>35 In the computer graphics ﬁeld, the Design Gallery [Marks et al. [sent-75, score-0.165]
</p><p>36 , 1997] for animation and the gallery navigation interface for Bidirectional Reﬂectance Distribution Functions (BRDFs) [Ngan et al. [sent-76, score-0.51]
</p><p>37 Parts of our method are based on [Chu and Ghahramani, 2005b], which presents a preference learning method using probit models and Gaussian processes. [sent-80, score-0.249]
</p><p>38 They use a ThurstoneMosteller model, but with an innovative nonparametric model of the valuation function. [sent-81, score-0.495]
</p><p>39 [Chu and Ghahramani, 2005a] adds active learning to the model, though the method presented there differs from ours in that realizations are selected from a ﬁnite pool to maximize informativeness. [sent-82, score-0.195]
</p><p>40 As our experiments show in Section 3, this is too expensive an approach for our setting, leading us to develop the new active learning criteria presented here. [sent-86, score-0.122]
</p><p>41 2  Active Preference Learning  By querying the user with a paired comparison, one can estimate statistics of the valuation function at the query point, but only at considerable expense. [sent-87, score-0.873]
</p><p>42 Present the user with a new pair and record the choice: Augment the training set of paired choices with the new user data. [sent-90, score-0.583]
</p><p>43 Infer the valuation function: Here we use a Thurstone-Mosteller model with Gaussian processes. [sent-92, score-0.495]
</p><p>44 Note that we are not interested in predicting the value of the valuation function over the entire feasible domain, but rather in predicting it well near the optimum. [sent-96, score-0.534]
</p><p>45 Optimize the expected improvement function to obtain the next query point: Finding the maximum of the EI corresponds to a constrained nonlinear programming problem. [sent-104, score-0.102]
</p><p>46 1  Preference Learning Model  Assume we have shown the user M pairs of items. [sent-108, score-0.261]
</p><p>47 In each case, the user has chosen which item she likes best. [sent-109, score-0.316]
</p><p>48 , M }, where the symbol indicates that the user prefers r to c. [sent-113, score-0.261]
</p><p>49 That is, rk and ck correspond to two elements of x1:N . [sent-118, score-0.169]
</p><p>50 Our goal is to compute the item x (not necessarily in the training data) with the highest user valuation in as few comparisons as possible. [sent-119, score-0.811]
</p><p>51 We model the valuation functions u(·) for r and c as follows: u(rk ) u(ck )  = f (rk ) + erk = f (ck ) + eck , 3  (1)  where the noise terms are Gaussian: erk ∼ N (0, σ 2 ) and eck ∼ N (0, σ 2 ). [sent-120, score-0.731]
</p><p>52 Random utility models such as (1) have a long and inﬂuential history in psychology and the study of individual choice behaviour in economic markets. [sent-130, score-0.138]
</p><p>53 If the user had more than two choices one could adopting a multinomial-probit model. [sent-138, score-0.261]
</p><p>54 This multi-category extension would, for example, enable the user to state no preference for any of the two items being presented. [sent-139, score-0.51]
</p><p>55 2  Inference  Our goal is to estimate the posterior distribution of the latent utility function given the discrete data. [sent-141, score-0.095]
</p><p>56 Moreover, given the amount of uncertainty in user valuations, we believe the choice of approximating technique plays a small role and hence we expect the simple Laplace approximation to perform reasonably in comparison to other techniques. [sent-145, score-0.261]
</p><p>57 One of the criticisms of Gaussian processes, the fact that they are slow with large data sets, is not a problem for us, since active learning is designed explicitly to minimize the number of training data. [sent-150, score-0.122]
</p><p>58 3  The Expected Improvement Function  Now that we are armed with an expression for the predictive distribution, we can use it to decide what the next query should be. [sent-152, score-0.091]
</p><p>59 That is, µmax is the highest valuation for the data provided by the individual. [sent-159, score-0.495]
</p><p>60 8  1  Figure 2: The 2D test function (left), and the estimate of the function based on the results of a typical run of 12 preference queries (right). [sent-195, score-0.37]
</p><p>61 The predictor identiﬁes the region of the global maximum correctly and that of the local maxima less well, but requires far fewer queries than learning the entire function. [sent-197, score-0.16]
</p><p>62 This statistical measure of improvement has been widely used in the ﬁeld of experimental design and goes back many decades [Kushner, 1964]. [sent-199, score-0.106]
</p><p>63 , 1998] deﬁned the improvement over the current best point as I(x ) = max{0, µ(x ) − µmax }, which resulted in an expected improvement of EI(x ) = where d =  (µmax − µ(x ))Φ(d) + s(x )φ(d) if s > 0 0 if s = 0  µmax −µ(x ) . [sent-202, score-0.092]
</p><p>64 3  Experiments  The goal of our algorithm is to ﬁnd a good approximation of the maximum of a latent function using preference queries. [sent-209, score-0.292]
</p><p>65 At each time step, a query is generated in which two points x1 and x2 are adaptively selected, and the preference is found, where f (x1 ) > f (x2 ) ⇔ x1 x2 . [sent-211, score-0.305]
</p><p>66 Note that by design, this does not penalize the algorithm for drawing samples from X that are far from argmaxx , or for predicting a latent function that differs from the true function. [sent-213, score-0.085]
</p><p>67 We are not trying to learn the entire valuation function, which would take many more queries – we seek only to maximize the valuation, which involves accurate modelling only in the areas of high valuation. [sent-214, score-0.688]
</p><p>68 The solid line is our method; the dashed is a baseline comparison in which each query point is selected randomly. [sent-235, score-0.09]
</p><p>69 In all cases, we simulate 50 queries using our method (here called maxEI ). [sent-241, score-0.121]
</p><p>70 As a baseline, we compare against 50 queries using the maximum variance of the model (maxs ), which is a common criterion in active learning for regression [Seo et al. [sent-242, score-0.324]
</p><p>71 We ﬁnd that it takes far fewer queries to ﬁnd a good result using maxEI in all cases. [sent-245, score-0.121]
</p><p>72 We feels that requiring more than 50 user queries in a real application would be unacceptable, so we are instead currently investigating extensions that will allow the user to direct the search in higher dimensions. [sent-249, score-0.676]
</p><p>73 4  Preference Gallery for Material Design  Properly modeling the appearance of a material is a necessary component of realistic image synthesis. [sent-250, score-0.102]
</p><p>74 The appearance of a material is formalized by the notion of the Bidirectional Reﬂectance Distribution Function (BRDF). [sent-251, score-0.102]
</p><p>75 This can make the material design process quite difﬁcult for the end user, who cannot expected to be an expert in the ﬁeld of appearance modeling. [sent-255, score-0.162]
</p><p>76 Our application is a solution to this problem, using a “preference gallery” approach, in which users are simply required to view two or more images rendered with different material properties and indicate which ones they prefer. [sent-256, score-0.219]
</p><p>77 In practice, the ﬁrst few examples will be points of high variance, since little of the space is explored (that is, the model of user valuation is very uncertain). [sent-258, score-0.756]
</p><p>78 We use our active preference learning model on an example gallery application for helping users ﬁnd a desired BRDF. [sent-260, score-0.746]
</p><p>79 The gallery uses the Ashikhmin-Shirley Phong 6  Table 1: Results of the user study algorithm latin hypercubes maxs maxEI  trials 50 50 50  n (mean ± std) 18. [sent-262, score-0.783]
</p><p>80 23  model [Ashikhmin and Shirley, 2000] for the BRDFs which was recently validated to be well suited for representing real materials [Ngan et al. [sent-268, score-0.155]
</p><p>81 The BRDFs are rendered on a sphere under high frequency natural illumination as this has been shown to be the desired setting for human preception of reﬂectance [Fleming et al. [sent-270, score-0.162]
</p><p>82 Our gallery demonstration presents the user with two BRDF images at a time. [sent-272, score-0.609]
</p><p>83 We start with four predetermined queries to “seed” the parameter space, and after that use the learned model to select gallery images. [sent-273, score-0.416]
</p><p>84 The GP model is updated after each preference is indicated. [sent-274, score-0.249]
</p><p>85 We use parameters of real measured materials from the MERL database [Ngan et al. [sent-275, score-0.155]
</p><p>86 1  User Study  To evaluate the performance of our application, we have run a simple user study in which the generated images are restricted to a subset of 38 materials from the MERL database that we deemed to be representative of the appearance space of the measured materials. [sent-278, score-0.437]
</p><p>87 The user is given the task of ﬁnding a single randomly-selected image from that set by indicating preferences. [sent-279, score-0.261]
</p><p>88 Figure 4 shows a typical user run, where we ask the user to use the preference gallery to ﬁnd a provided target image. [sent-280, score-1.066]
</p><p>89 At each step, the user need only indicate the image they think looks most like the target. [sent-281, score-0.297]
</p><p>90 Using ﬁve subjects, we compared 50 trials using the EIF to select the images for the gallery (maxEI ), 50 trials using maximum variance (maxs , the same criterion as in the experiments of Section 3), and 50 trials using samples selected using a randomized Latin hypercube algorithm. [sent-283, score-0.49]
</p><p>91 In each case, one of the gallery images was the image with the highest predicted valuation and the other was selected by the algorithm. [sent-284, score-0.877]
</p><p>92 n is the number clicks required of the user to ﬁnd the target image. [sent-287, score-0.261]
</p><p>93 We suspect that this is because maxs has a tendency to select images from the corners of the parameter space, which adds limited information to the other images, whereas Latin hypercubes at least guarantees that the selected images ﬁll the space. [sent-290, score-0.276]
</p><p>94 With this paper, we have shown that understanding the task — and exploiting the quirks of human cognition — is also essential if we are to deploy real-world active learning applications. [sent-292, score-0.212]
</p><p>95 Extensions of Gaussian processes for ranking: semi-supervised and active learning. [sent-304, score-0.122]
</p><p>96 7  T arget  1  2  3  4  Figure 4: A shorter-than-average but otherwise typical run of the preference gallery tool. [sent-320, score-0.544]
</p><p>97 At each (numbered) iteration, the user is provided with two images generated with parameter instances and indicates the one they think most resembles the target image (top-left) they are looking for. [sent-321, score-0.347]
</p><p>98 Preference uncertainty, preference reﬁnement and paired comparison choice experiments. [sent-384, score-0.31]
</p><p>99 Gaussian process regression: active data selection and test point rejection. [sent-446, score-0.122]
</p><p>100 Support vector machine active learning with applications to text classiﬁcation. [sent-465, score-0.122]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('valuation', 0.495), ('gallery', 0.295), ('user', 0.261), ('preference', 0.249), ('ectance', 0.168), ('maxei', 0.168), ('ngan', 0.147), ('animation', 0.134), ('active', 0.122), ('queries', 0.121), ('chu', 0.116), ('brdf', 0.105), ('maxs', 0.094), ('jones', 0.09), ('rk', 0.087), ('brdfs', 0.084), ('eif', 0.084), ('mcfadden', 0.084), ('psychoperceptual', 0.084), ('seo', 0.084), ('slider', 0.084), ('specularity', 0.084), ('graphics', 0.084), ('ck', 0.082), ('rendering', 0.081), ('et', 0.081), ('materials', 0.074), ('ghahramani', 0.071), ('ashikhmin', 0.063), ('erk', 0.063), ('fleming', 0.063), ('fresnel', 0.063), ('mosteller', 0.063), ('siegel', 0.063), ('thurstone', 0.063), ('paired', 0.061), ('sin', 0.061), ('design', 0.06), ('dk', 0.057), ('query', 0.056), ('latin', 0.055), ('artist', 0.055), ('eck', 0.055), ('econometrics', 0.055), ('glickman', 0.055), ('item', 0.055), ('images', 0.053), ('material', 0.053), ('utility', 0.052), ('ei', 0.051), ('cooper', 0.05), ('appearance', 0.049), ('human', 0.048), ('stern', 0.047), ('psychology', 0.047), ('users', 0.047), ('improvement', 0.046), ('el', 0.044), ('cohn', 0.044), ('burden', 0.044), ('chess', 0.044), ('latent', 0.043), ('argmaxx', 0.042), ('castellan', 0.042), ('durand', 0.042), ('eurographics', 0.042), ('hypercubes', 0.042), ('kingsley', 0.042), ('phong', 0.042), ('quirks', 0.042), ('renderer', 0.042), ('sasena', 0.042), ('shirley', 0.042), ('twiddling', 0.042), ('tong', 0.042), ('guestrin', 0.04), ('cognitive', 0.04), ('economic', 0.039), ('realizations', 0.039), ('entire', 0.039), ('artists', 0.037), ('arts', 0.037), ('merl', 0.037), ('looks', 0.036), ('trials', 0.036), ('laplace', 0.035), ('marks', 0.035), ('predictive', 0.035), ('selected', 0.034), ('rendered', 0.033), ('kushner', 0.033), ('judgement', 0.033), ('bidirectional', 0.033), ('ghosh', 0.033), ('nd', 0.033), ('looking', 0.033), ('modelling', 0.033), ('application', 0.033), ('rating', 0.032), ('re', 0.032)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000017 <a title="19-tfidf-1" href="./nips-2007-Active_Preference_Learning_with_Discrete_Choice_Data.html">19 nips-2007-Active Preference Learning with Discrete Choice Data</a></p>
<p>Author: Brochu Eric, Nando D. Freitas, Abhijeet Ghosh</p><p>Abstract: We propose an active learning algorithm that learns a continuous valuation model from discrete preferences. The algorithm automatically decides what items are best presented to an individual in order to ﬁnd the item that they value highly in as few trials as possible, and exploits quirks of human psychology to minimize time and cognitive burden. To do this, our algorithm maximizes the expected improvement at each query without accurately modelling the entire valuation surface, which would be needlessly expensive. The problem is particularly difﬁcult because the space of choices is inﬁnite. We demonstrate the effectiveness of the new algorithm compared to related active learning methods. We also embed the algorithm within a decision making tool for assisting digital artists in rendering materials. The tool ﬁnds the best parameters while minimizing the number of queries. 1</p><p>2 0.13465625 <a title="19-tfidf-2" href="./nips-2007-A_General_Boosting_Method_and_its_Application_to_Learning_Ranking_Functions_for_Web_Search.html">6 nips-2007-A General Boosting Method and its Application to Learning Ranking Functions for Web Search</a></p>
<p>Author: Zhaohui Zheng, Hongyuan Zha, Tong Zhang, Olivier Chapelle, Keke Chen, Gordon Sun</p><p>Abstract: We present a general boosting method extending functional gradient boosting to optimize complex loss functions that are encountered in many machine learning problems. Our approach is based on optimization of quadratic upper bounds of the loss functions which allows us to present a rigorous convergence analysis of the algorithm. More importantly, this general framework enables us to use a standard regression base learner such as single regression tree for £tting any loss function. We illustrate an application of the proposed method in learning ranking functions for Web search by combining both preference data and labeled data for training. We present experimental results for Web search using data from a commercial search engine that show signi£cant improvements of our proposed methods over some existing methods. 1</p><p>3 0.095940351 <a title="19-tfidf-3" href="./nips-2007-Unsupervised_Feature_Selection_for_Accurate_Recommendation_of_High-Dimensional_Image_Data.html">211 nips-2007-Unsupervised Feature Selection for Accurate Recommendation of High-Dimensional Image Data</a></p>
<p>Author: Sabri Boutemedjet, Djemel Ziou, Nizar Bouguila</p><p>Abstract: Content-based image suggestion (CBIS) targets the recommendation of products based on user preferences on the visual content of images. In this paper, we motivate both feature selection and model order identiﬁcation as two key issues for a successful CBIS. We propose a generative model in which the visual features and users are clustered into separate classes. We identify the number of both user and image classes with the simultaneous selection of relevant visual features using the message length approach. The goal is to ensure an accurate prediction of ratings for multidimensional non-Gaussian and continuous image descriptors. Experiments on a collected data have demonstrated the merits of our approach.</p><p>4 0.070262954 <a title="19-tfidf-4" href="./nips-2007-Discriminative_Batch_Mode_Active_Learning.html">69 nips-2007-Discriminative Batch Mode Active Learning</a></p>
<p>Author: Yuhong Guo, Dale Schuurmans</p><p>Abstract: Active learning sequentially selects unlabeled instances to label with the goal of reducing the effort needed to learn a good classiﬁer. Most previous studies in active learning have focused on selecting one unlabeled instance to label at a time while retraining in each iteration. Recently a few batch mode active learning approaches have been proposed that select a set of most informative unlabeled instances in each iteration under the guidance of heuristic scores. In this paper, we propose a discriminative batch mode active learning approach that formulates the instance selection task as a continuous optimization problem over auxiliary instance selection variables. The optimization is formulated to maximize the discriminative classiﬁcation performance of the target classiﬁer, while also taking the unlabeled data into account. Although the objective is not convex, we can manipulate a quasi-Newton method to obtain a good local solution. Our empirical studies on UCI datasets show that the proposed active learning is more effective than current state-of-the art batch mode active learning algorithms. 1</p><p>5 0.066193469 <a title="19-tfidf-5" href="./nips-2007-Bayesian_Policy_Learning_with_Trans-Dimensional_MCMC.html">34 nips-2007-Bayesian Policy Learning with Trans-Dimensional MCMC</a></p>
<p>Author: Matthew Hoffman, Arnaud Doucet, Nando D. Freitas, Ajay Jasra</p><p>Abstract: A recently proposed formulation of the stochastic planning and control problem as one of parameter estimation for suitable artiﬁcial statistical models has led to the adoption of inference algorithms for this notoriously hard problem. At the algorithmic level, the focus has been on developing Expectation-Maximization (EM) algorithms. In this paper, we begin by making the crucial observation that the stochastic control problem can be reinterpreted as one of trans-dimensional inference. With this new interpretation, we are able to propose a novel reversible jump Markov chain Monte Carlo (MCMC) algorithm that is more efﬁcient than its EM counterparts. Moreover, it enables us to implement full Bayesian policy search, without the need for gradients and with one single Markov chain. The new approach involves sampling directly from a distribution that is proportional to the reward and, consequently, performs better than classic simulations methods in situations where the reward is a rare event.</p><p>6 0.065667525 <a title="19-tfidf-6" href="./nips-2007-Evaluating_Search_Engines_by_Modeling_the_Relationship_Between_Relevance_and_Clicks.html">83 nips-2007-Evaluating Search Engines by Modeling the Relationship Between Relevance and Clicks</a></p>
<p>7 0.062853754 <a title="19-tfidf-7" href="./nips-2007-Multiple-Instance_Active_Learning.html">136 nips-2007-Multiple-Instance Active Learning</a></p>
<p>8 0.062814347 <a title="19-tfidf-8" href="./nips-2007-COFI_RANK_-_Maximum_Margin_Matrix_Factorization_for_Collaborative_Ranking.html">41 nips-2007-COFI RANK - Maximum Margin Matrix Factorization for Collaborative Ranking</a></p>
<p>9 0.059694082 <a title="19-tfidf-9" href="./nips-2007-Gaussian_Process_Models_for_Link_Analysis_and_Transfer_Learning.html">94 nips-2007-Gaussian Process Models for Link Analysis and Transfer Learning</a></p>
<p>10 0.058685053 <a title="19-tfidf-10" href="./nips-2007-A_learning_framework_for_nearest_neighbor_search.html">16 nips-2007-A learning framework for nearest neighbor search</a></p>
<p>11 0.051762603 <a title="19-tfidf-11" href="./nips-2007-Probabilistic_Matrix_Factorization.html">158 nips-2007-Probabilistic Matrix Factorization</a></p>
<p>12 0.050782524 <a title="19-tfidf-12" href="./nips-2007-A_Bayesian_Model_of_Conditioned_Perception.html">3 nips-2007-A Bayesian Model of Conditioned Perception</a></p>
<p>13 0.049199034 <a title="19-tfidf-13" href="./nips-2007-Markov_Chain_Monte_Carlo_with_People.html">125 nips-2007-Markov Chain Monte Carlo with People</a></p>
<p>14 0.048304096 <a title="19-tfidf-14" href="./nips-2007-People_Tracking_with_the_Laplacian_Eigenmaps_Latent_Variable_Model.html">153 nips-2007-People Tracking with the Laplacian Eigenmaps Latent Variable Model</a></p>
<p>15 0.047592457 <a title="19-tfidf-15" href="./nips-2007-Hierarchical_Penalization.html">99 nips-2007-Hierarchical Penalization</a></p>
<p>16 0.047057431 <a title="19-tfidf-16" href="./nips-2007-Automatic_Generation_of_Social_Tags_for_Music_Recommendation.html">29 nips-2007-Automatic Generation of Social Tags for Music Recommendation</a></p>
<p>17 0.046282254 <a title="19-tfidf-17" href="./nips-2007-On_Sparsity_and_Overcompleteness_in_Image_Models.html">145 nips-2007-On Sparsity and Overcompleteness in Image Models</a></p>
<p>18 0.045953169 <a title="19-tfidf-18" href="./nips-2007-Selecting_Observations_against_Adversarial_Objectives.html">174 nips-2007-Selecting Observations against Adversarial Objectives</a></p>
<p>19 0.045084663 <a title="19-tfidf-19" href="./nips-2007-Learning_Visual_Attributes.html">113 nips-2007-Learning Visual Attributes</a></p>
<p>20 0.04436373 <a title="19-tfidf-20" href="./nips-2007-Object_Recognition_by_Scene_Alignment.html">143 nips-2007-Object Recognition by Scene Alignment</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2007_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.17), (1, 0.022), (2, -0.035), (3, -0.026), (4, 0.016), (5, 0.079), (6, 0.008), (7, -0.036), (8, 0.022), (9, -0.044), (10, -0.098), (11, -0.002), (12, 0.14), (13, 0.027), (14, -0.008), (15, 0.05), (16, -0.103), (17, 0.009), (18, 0.04), (19, -0.032), (20, 0.049), (21, -0.065), (22, 0.102), (23, -0.033), (24, -0.069), (25, 0.039), (26, -0.018), (27, -0.082), (28, 0.05), (29, -0.026), (30, -0.01), (31, -0.098), (32, 0.041), (33, -0.048), (34, 0.088), (35, -0.074), (36, -0.017), (37, 0.073), (38, -0.091), (39, -0.135), (40, -0.041), (41, -0.177), (42, 0.036), (43, -0.098), (44, -0.061), (45, -0.074), (46, 0.12), (47, -0.008), (48, 0.05), (49, 0.127)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92066193 <a title="19-lsi-1" href="./nips-2007-Active_Preference_Learning_with_Discrete_Choice_Data.html">19 nips-2007-Active Preference Learning with Discrete Choice Data</a></p>
<p>Author: Brochu Eric, Nando D. Freitas, Abhijeet Ghosh</p><p>Abstract: We propose an active learning algorithm that learns a continuous valuation model from discrete preferences. The algorithm automatically decides what items are best presented to an individual in order to ﬁnd the item that they value highly in as few trials as possible, and exploits quirks of human psychology to minimize time and cognitive burden. To do this, our algorithm maximizes the expected improvement at each query without accurately modelling the entire valuation surface, which would be needlessly expensive. The problem is particularly difﬁcult because the space of choices is inﬁnite. We demonstrate the effectiveness of the new algorithm compared to related active learning methods. We also embed the algorithm within a decision making tool for assisting digital artists in rendering materials. The tool ﬁnds the best parameters while minimizing the number of queries. 1</p><p>2 0.59945071 <a title="19-lsi-2" href="./nips-2007-Unsupervised_Feature_Selection_for_Accurate_Recommendation_of_High-Dimensional_Image_Data.html">211 nips-2007-Unsupervised Feature Selection for Accurate Recommendation of High-Dimensional Image Data</a></p>
<p>Author: Sabri Boutemedjet, Djemel Ziou, Nizar Bouguila</p><p>Abstract: Content-based image suggestion (CBIS) targets the recommendation of products based on user preferences on the visual content of images. In this paper, we motivate both feature selection and model order identiﬁcation as two key issues for a successful CBIS. We propose a generative model in which the visual features and users are clustered into separate classes. We identify the number of both user and image classes with the simultaneous selection of relevant visual features using the message length approach. The goal is to ensure an accurate prediction of ratings for multidimensional non-Gaussian and continuous image descriptors. Experiments on a collected data have demonstrated the merits of our approach.</p><p>3 0.49494934 <a title="19-lsi-3" href="./nips-2007-Probabilistic_Matrix_Factorization.html">158 nips-2007-Probabilistic Matrix Factorization</a></p>
<p>Author: Andriy Mnih, Ruslan Salakhutdinov</p><p>Abstract: Many existing approaches to collaborative ﬁltering can neither handle very large datasets nor easily deal with users who have very few ratings. In this paper we present the Probabilistic Matrix Factorization (PMF) model which scales linearly with the number of observations and, more importantly, performs well on the large, sparse, and very imbalanced Netﬂix dataset. We further extend the PMF model to include an adaptive prior on the model parameters and show how the model capacity can be controlled automatically. Finally, we introduce a constrained version of the PMF model that is based on the assumption that users who have rated similar sets of movies are likely to have similar preferences. The resulting model is able to generalize considerably better for users with very few ratings. When the predictions of multiple PMF models are linearly combined with the predictions of Restricted Boltzmann Machines models, we achieve an error rate of 0.8861, that is nearly 7% better than the score of Netﬂix’s own system.</p><p>4 0.49356458 <a title="19-lsi-4" href="./nips-2007-A_General_Boosting_Method_and_its_Application_to_Learning_Ranking_Functions_for_Web_Search.html">6 nips-2007-A General Boosting Method and its Application to Learning Ranking Functions for Web Search</a></p>
<p>Author: Zhaohui Zheng, Hongyuan Zha, Tong Zhang, Olivier Chapelle, Keke Chen, Gordon Sun</p><p>Abstract: We present a general boosting method extending functional gradient boosting to optimize complex loss functions that are encountered in many machine learning problems. Our approach is based on optimization of quadratic upper bounds of the loss functions which allows us to present a rigorous convergence analysis of the algorithm. More importantly, this general framework enables us to use a standard regression base learner such as single regression tree for £tting any loss function. We illustrate an application of the proposed method in learning ranking functions for Web search by combining both preference data and labeled data for training. We present experimental results for Web search using data from a commercial search engine that show signi£cant improvements of our proposed methods over some existing methods. 1</p><p>5 0.4760868 <a title="19-lsi-5" href="./nips-2007-Multiple-Instance_Active_Learning.html">136 nips-2007-Multiple-Instance Active Learning</a></p>
<p>Author: Burr Settles, Mark Craven, Soumya Ray</p><p>Abstract: We present a framework for active learning in the multiple-instance (MI) setting. In an MI learning problem, instances are naturally organized into bags and it is the bags, instead of individual instances, that are labeled for training. MI learners assume that every instance in a bag labeled negative is actually negative, whereas at least one instance in a bag labeled positive is actually positive. We consider the particular case in which an MI learner is allowed to selectively query unlabeled instances from positive bags. This approach is well motivated in domains in which it is inexpensive to acquire bag labels and possible, but expensive, to acquire instance labels. We describe a method for learning from labels at mixed levels of granularity, and introduce two active query selection strategies motivated by the MI setting. Our experiments show that learning from instance labels can signiﬁcantly improve performance of a basic MI learning algorithm in two multiple-instance domains: content-based image retrieval and text classiﬁcation. 1</p><p>6 0.47574452 <a title="19-lsi-6" href="./nips-2007-COFI_RANK_-_Maximum_Margin_Matrix_Factorization_for_Collaborative_Ranking.html">41 nips-2007-COFI RANK - Maximum Margin Matrix Factorization for Collaborative Ranking</a></p>
<p>7 0.44514793 <a title="19-lsi-7" href="./nips-2007-Evaluating_Search_Engines_by_Modeling_the_Relationship_Between_Relevance_and_Clicks.html">83 nips-2007-Evaluating Search Engines by Modeling the Relationship Between Relevance and Clicks</a></p>
<p>8 0.423576 <a title="19-lsi-8" href="./nips-2007-A_learning_framework_for_nearest_neighbor_search.html">16 nips-2007-A learning framework for nearest neighbor search</a></p>
<p>9 0.38465744 <a title="19-lsi-9" href="./nips-2007-A_Bayesian_Model_of_Conditioned_Perception.html">3 nips-2007-A Bayesian Model of Conditioned Perception</a></p>
<p>10 0.38398296 <a title="19-lsi-10" href="./nips-2007-Markov_Chain_Monte_Carlo_with_People.html">125 nips-2007-Markov Chain Monte Carlo with People</a></p>
<p>11 0.37757215 <a title="19-lsi-11" href="./nips-2007-Nearest-Neighbor-Based_Active_Learning_for_Rare_Category_Detection.html">139 nips-2007-Nearest-Neighbor-Based Active Learning for Rare Category Detection</a></p>
<p>12 0.3700515 <a title="19-lsi-12" href="./nips-2007-Modeling_homophily_and_stochastic_equivalence_in_symmetric_relational_data.html">131 nips-2007-Modeling homophily and stochastic equivalence in symmetric relational data</a></p>
<p>13 0.36951396 <a title="19-lsi-13" href="./nips-2007-Discriminative_Batch_Mode_Active_Learning.html">69 nips-2007-Discriminative Batch Mode Active Learning</a></p>
<p>14 0.33731234 <a title="19-lsi-14" href="./nips-2007-Bayesian_Policy_Learning_with_Trans-Dimensional_MCMC.html">34 nips-2007-Bayesian Policy Learning with Trans-Dimensional MCMC</a></p>
<p>15 0.33607116 <a title="19-lsi-15" href="./nips-2007-A_general_agnostic_active_learning_algorithm.html">15 nips-2007-A general agnostic active learning algorithm</a></p>
<p>16 0.3352018 <a title="19-lsi-16" href="./nips-2007-Hierarchical_Penalization.html">99 nips-2007-Hierarchical Penalization</a></p>
<p>17 0.32692695 <a title="19-lsi-17" href="./nips-2007-Infinite_State_Bayes-Nets_for_Structured_Domains.html">105 nips-2007-Infinite State Bayes-Nets for Structured Domains</a></p>
<p>18 0.31920025 <a title="19-lsi-18" href="./nips-2007-Automatic_Generation_of_Social_Tags_for_Music_Recommendation.html">29 nips-2007-Automatic Generation of Social Tags for Music Recommendation</a></p>
<p>19 0.31737894 <a title="19-lsi-19" href="./nips-2007-On_Sparsity_and_Overcompleteness_in_Image_Models.html">145 nips-2007-On Sparsity and Overcompleteness in Image Models</a></p>
<p>20 0.31708673 <a title="19-lsi-20" href="./nips-2007-McRank%3A_Learning_to_Rank_Using_Multiple_Classification_and_Gradient_Boosting.html">126 nips-2007-McRank: Learning to Rank Using Multiple Classification and Gradient Boosting</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2007_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.026), (13, 0.019), (16, 0.016), (18, 0.021), (19, 0.012), (21, 0.555), (31, 0.013), (34, 0.014), (35, 0.016), (42, 0.01), (47, 0.07), (49, 0.012), (83, 0.084), (87, 0.012), (90, 0.043)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.95971495 <a title="19-lda-1" href="./nips-2007-Inferring_Elapsed_Time_from_Stochastic_Neural_Processes.html">103 nips-2007-Inferring Elapsed Time from Stochastic Neural Processes</a></p>
<p>Author: Misha Ahrens, Maneesh Sahani</p><p>Abstract: Many perceptual processes and neural computations, such as speech recognition, motor control and learning, depend on the ability to measure and mark the passage of time. However, the processes that make such temporal judgements possible are unknown. A number of different hypothetical mechanisms have been advanced, all of which depend on the known, temporally predictable evolution of a neural or psychological state, possibly through oscillations or the gradual decay of a memory trace. Alternatively, judgements of elapsed time might be based on observations of temporally structured, but stochastic processes. Such processes need not be speciﬁc to the sense of time; typical neural and sensory processes contain at least some statistical structure across a range of time scales. Here, we investigate the statistical properties of an estimator of elapsed time which is based on a simple family of stochastic process. 1</p><p>2 0.95134783 <a title="19-lda-2" href="./nips-2007-Bayesian_Co-Training.html">32 nips-2007-Bayesian Co-Training</a></p>
<p>Author: Shipeng Yu, Balaji Krishnapuram, Harald Steck, R. B. Rao, Rómer Rosales</p><p>Abstract: We propose a Bayesian undirected graphical model for co-training, or more generally for semi-supervised multi-view learning. This makes explicit the previously unstated assumptions of a large class of co-training type algorithms, and also clariﬁes the circumstances under which these assumptions fail. Building upon new insights from this model, we propose an improved method for co-training, which is a novel co-training kernel for Gaussian process classiﬁers. The resulting approach is convex and avoids local-maxima problems, unlike some previous multi-view learning methods. Furthermore, it can automatically estimate how much each view should be trusted, and thus accommodate noisy or unreliable views. Experiments on toy data and real world data sets illustrate the beneﬁts of this approach. 1</p><p>3 0.94335401 <a title="19-lda-3" href="./nips-2007-The_Distribution_Family_of_Similarity_Distances.html">193 nips-2007-The Distribution Family of Similarity Distances</a></p>
<p>Author: Gertjan Burghouts, Arnold Smeulders, Jan-mark Geusebroek</p><p>Abstract: Assessing similarity between features is a key step in object recognition and scene categorization tasks. We argue that knowledge on the distribution of distances generated by similarity functions is crucial in deciding whether features are similar or not. Intuitively one would expect that similarities between features could arise from any distribution. In this paper, we will derive the contrary, and report the theoretical result that Lp -norms –a class of commonly applied distance metrics– from one feature vector to other vectors are Weibull-distributed if the feature values are correlated and non-identically distributed. Besides these assumptions being realistic for images, we experimentally show them to hold for various popular feature extraction algorithms, for a diverse range of images. This fundamental insight opens new directions in the assessment of feature similarity, with projected improvements in object and scene recognition algorithms. 1</p><p>same-paper 4 0.90551716 <a title="19-lda-4" href="./nips-2007-Active_Preference_Learning_with_Discrete_Choice_Data.html">19 nips-2007-Active Preference Learning with Discrete Choice Data</a></p>
<p>Author: Brochu Eric, Nando D. Freitas, Abhijeet Ghosh</p><p>Abstract: We propose an active learning algorithm that learns a continuous valuation model from discrete preferences. The algorithm automatically decides what items are best presented to an individual in order to ﬁnd the item that they value highly in as few trials as possible, and exploits quirks of human psychology to minimize time and cognitive burden. To do this, our algorithm maximizes the expected improvement at each query without accurately modelling the entire valuation surface, which would be needlessly expensive. The problem is particularly difﬁcult because the space of choices is inﬁnite. We demonstrate the effectiveness of the new algorithm compared to related active learning methods. We also embed the algorithm within a decision making tool for assisting digital artists in rendering materials. The tool ﬁnds the best parameters while minimizing the number of queries. 1</p><p>5 0.61392885 <a title="19-lda-5" href="./nips-2007-Scene_Segmentation_with_CRFs_Learned_from_Partially_Labeled_Images.html">172 nips-2007-Scene Segmentation with CRFs Learned from Partially Labeled Images</a></p>
<p>Author: Bill Triggs, Jakob J. Verbeek</p><p>Abstract: Conditional Random Fields (CRFs) are an effective tool for a variety of different data segmentation and labeling tasks including visual scene interpretation, which seeks to partition images into their constituent semantic-level regions and assign appropriate class labels to each region. For accurate labeling it is important to capture the global context of the image as well as local information. We introduce a CRF based scene labeling model that incorporates both local features and features aggregated over the whole image or large sections of it. Secondly, traditional CRF learning requires fully labeled datasets which can be costly and troublesome to produce. We introduce a method for learning CRFs from datasets with many unlabeled nodes by marginalizing out the unknown labels so that the log-likelihood of the known ones can be maximized by gradient ascent. Loopy Belief Propagation is used to approximate the marginals needed for the gradient and log-likelihood calculations and the Bethe free-energy approximation to the log-likelihood is monitored to control the step size. Our experimental results show that effective models can be learned from fragmentary labelings and that incorporating top-down aggregate features signiﬁcantly improves the segmentations. The resulting segmentations are compared to the state-of-the-art on three different image datasets. 1</p><p>6 0.59801304 <a title="19-lda-6" href="./nips-2007-Discriminative_Batch_Mode_Active_Learning.html">69 nips-2007-Discriminative Batch Mode Active Learning</a></p>
<p>7 0.59606922 <a title="19-lda-7" href="./nips-2007-GRIFT%3A_A_graphical_model_for_inferring_visual_classification_features_from_human_data.html">93 nips-2007-GRIFT: A graphical model for inferring visual classification features from human data</a></p>
<p>8 0.5844748 <a title="19-lda-8" href="./nips-2007-Configuration_Estimates_Improve_Pedestrian_Finding.html">56 nips-2007-Configuration Estimates Improve Pedestrian Finding</a></p>
<p>9 0.5810107 <a title="19-lda-9" href="./nips-2007-Fast_and_Scalable_Training_of_Semi-Supervised_CRFs_with_Application_to_Activity_Recognition.html">88 nips-2007-Fast and Scalable Training of Semi-Supervised CRFs with Application to Activity Recognition</a></p>
<p>10 0.5734936 <a title="19-lda-10" href="./nips-2007-Using_Deep_Belief_Nets_to_Learn_Covariance_Kernels_for_Gaussian_Processes.html">212 nips-2007-Using Deep Belief Nets to Learn Covariance Kernels for Gaussian Processes</a></p>
<p>11 0.57283258 <a title="19-lda-11" href="./nips-2007-Augmented_Functional_Time_Series_Representation_and_Forecasting_with_Gaussian_Processes.html">28 nips-2007-Augmented Functional Time Series Representation and Forecasting with Gaussian Processes</a></p>
<p>12 0.5655883 <a title="19-lda-12" href="./nips-2007-Gaussian_Process_Models_for_Link_Analysis_and_Transfer_Learning.html">94 nips-2007-Gaussian Process Models for Link Analysis and Transfer Learning</a></p>
<p>13 0.56310397 <a title="19-lda-13" href="./nips-2007-Multiple-Instance_Active_Learning.html">136 nips-2007-Multiple-Instance Active Learning</a></p>
<p>14 0.56099576 <a title="19-lda-14" href="./nips-2007-Semi-Supervised_Multitask_Learning.html">175 nips-2007-Semi-Supervised Multitask Learning</a></p>
<p>15 0.55742556 <a title="19-lda-15" href="./nips-2007-Privacy-Preserving_Belief_Propagation_and_Sampling.html">157 nips-2007-Privacy-Preserving Belief Propagation and Sampling</a></p>
<p>16 0.55737543 <a title="19-lda-16" href="./nips-2007-Hidden_Common_Cause_Relations_in_Relational_Learning.html">97 nips-2007-Hidden Common Cause Relations in Relational Learning</a></p>
<p>17 0.54658723 <a title="19-lda-17" href="./nips-2007-Hippocampal_Contributions_to_Control%3A_The_Third_Way.html">100 nips-2007-Hippocampal Contributions to Control: The Third Way</a></p>
<p>18 0.5449574 <a title="19-lda-18" href="./nips-2007-Evaluating_Search_Engines_by_Modeling_the_Relationship_Between_Relevance_and_Clicks.html">83 nips-2007-Evaluating Search Engines by Modeling the Relationship Between Relevance and Clicks</a></p>
<p>19 0.54429597 <a title="19-lda-19" href="./nips-2007-Inferring_Neural_Firing_Rates_from_Spike_Trains_Using_Gaussian_Processes.html">104 nips-2007-Inferring Neural Firing Rates from Spike Trains Using Gaussian Processes</a></p>
<p>20 0.54345644 <a title="19-lda-20" href="./nips-2007-Ultrafast_Monte_Carlo_for_Statistical_Summations.html">209 nips-2007-Ultrafast Monte Carlo for Statistical Summations</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
