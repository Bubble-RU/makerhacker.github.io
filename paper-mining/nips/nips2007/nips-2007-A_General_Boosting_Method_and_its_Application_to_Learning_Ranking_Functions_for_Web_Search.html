<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>6 nips-2007-A General Boosting Method and its Application to Learning Ranking Functions for Web Search</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-6" href="#">nips2007-6</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>6 nips-2007-A General Boosting Method and its Application to Learning Ranking Functions for Web Search</h1>
<br/><p>Source: <a title="nips-2007-6-pdf" href="http://papers.nips.cc/paper/3305-a-general-boosting-method-and-its-application-to-learning-ranking-functions-for-web-search.pdf">pdf</a></p><p>Author: Zhaohui Zheng, Hongyuan Zha, Tong Zhang, Olivier Chapelle, Keke Chen, Gordon Sun</p><p>Abstract: We present a general boosting method extending functional gradient boosting to optimize complex loss functions that are encountered in many machine learning problems. Our approach is based on optimization of quadratic upper bounds of the loss functions which allows us to present a rigorous convergence analysis of the algorithm. More importantly, this general framework enables us to use a standard regression base learner such as single regression tree for £tting any loss function. We illustrate an application of the proposed method in learning ranking functions for Web search by combining both preference data and labeled data for training. We present experimental results for Web search using data from a commercial search engine that show signi£cant improvements of our proposed methods over some existing methods. 1</p><p>Reference: <a title="nips-2007-6-reference" href="../nips2007_reference/nips-2007-A_General_Boosting_Method_and_its_Application_to_Learning_Ranking_Functions_for_Web_Search_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract We present a general boosting method extending functional gradient boosting to optimize complex loss functions that are encountered in many machine learning problems. [sent-6, score-0.458]
</p><p>2 Our approach is based on optimization of quadratic upper bounds of the loss functions which allows us to present a rigorous convergence analysis of the algorithm. [sent-7, score-0.273]
</p><p>3 More importantly, this general framework enables us to use a standard regression base learner such as single regression tree for £tting any loss function. [sent-8, score-0.266]
</p><p>4 We illustrate an application of the proposed method in learning ranking functions for Web search by combining both preference data and labeled data for training. [sent-9, score-0.837]
</p><p>5 We present experimental results for Web search using data from a commercial search engine that show signi£cant improvements of our proposed methods over some existing methods. [sent-10, score-0.255]
</p><p>6 1  Introduction  There has been much interest in developing machine learning methods involving complex loss functions beyond those used in regression and classi£cation problems [13]. [sent-11, score-0.16]
</p><p>7 Many methods have been proposed dealing with a wide range of problems including ranking problems, learning conditional random £elds and other structured learning problems [1, 3, 4, 5, 6, 7, 11, 13]. [sent-12, score-0.304]
</p><p>8 In this paper we propose a boosting framework that can handle a wide variety of complex loss functions. [sent-13, score-0.219]
</p><p>9 The proposed method uses a regression black box to optimize a general loss function based on quadratic upper bounds, and it also allows us to present a rigorous convergence analysis of the method. [sent-14, score-0.287]
</p><p>10 Our approach extends the gradient boosting approach proposed in [8] but can handle substantially more complex loss functions arising from a variety of machine learning problems. [sent-15, score-0.298]
</p><p>11 As an interesting and important application of the general boosting framework we apply it to the problem of learning ranking functions for Web search. [sent-16, score-0.432]
</p><p>12 Speci£cally, we want to rank a set of documents according to their relevance to a given query. [sent-17, score-0.219]
</p><p>13 We adopt the following framework: we extract a set of features x for each query-document pair, and learn a function h(x) so that we can rank the documents using the values h(x), say x with larger h(x) values are ranked higher. [sent-18, score-0.2]
</p><p>14 In Web search, we can identify two types of training data for learning a ranking function: 1) preference data indicating a document is more relevant than another with respect to a query [11, 12]; and 2) labeled data where documents are assigned ordinal labels representing degree of relevancy. [sent-20, score-1.236]
</p><p>15 In general, we will have both preference data and labeled data for 1  training a ranking function for Web search, leading to a complex loss function that can be handled by our proposed general boosting method which we now describe. [sent-21, score-1.01]
</p><p>16 We consider the following form of the risk functional R: n 1 R(h) = φi (h(xi,1 ), · · · , h(xi,mi ), yi ), (2) n i=1 where φi (h1 , . [sent-23, score-0.172]
</p><p>17 , hmi , y) is a loss function with respect to the £rst m i arguments h1 , . [sent-26, score-0.142]
</p><p>18 , hmi , y) = supz δ(y, z) + ψ(h, z) − ψ(h, y), where δ is a loss function [13]. [sent-33, score-0.114]
</p><p>19 , wk ], and tolerance > 0, the regression weak learner A produces a function g = A(W, X, R, ) ∈ C such ˆ that k  k  2  j=1  wj (ˆ(xj ) − rj ) ≤ min g g∈C  j=1  wj (g(xj ) − rj )2 + . [sent-44, score-0.319]
</p><p>20 Friedman [8] proposed a solution when the loss function in (2) can be expressed as n  R(h) =  φi (h(xi )),  (4)  i=1  which he named as gradient boosting. [sent-49, score-0.118]
</p><p>21 The idea is to estimate the gradient φ i (h(xi )) using regression at each step with uniform weighting, and update. [sent-50, score-0.115]
</p><p>22 Our main observation is that for twice differentiable risk functional R, at each tentative solution h k , we can expand R(h) around hk using Taylor expansion as 1 R(hk + g) = R(hk ) + R(hk )T g + g T 2 R(h )g, 2 where h lies between hk and hk + g. [sent-59, score-1.011]
</p><p>23 The right hand side is almost quadratic, and we can then replace it by a quadratic upper-bound 1 R(hk + g) ≤ Rk (g) = R(hk ) + R(hk )T g + g T W g, (6) 2 1 We consider that all xi are different, but some of the xi,mi in (2) might have been identical, hence the inequality. [sent-60, score-0.141]
</p><p>24 2  where W is a diagonal matrix upper bounding the Hessian between hk and hk + g. [sent-61, score-0.695]
</p><p>25 If we de£ne rj = −[ R(hk )]j /wj , then ∀g ∈ C, j wj (g(xj ) − rj )2 is equal to the above quadratic form (up to a constant). [sent-62, score-0.206]
</p><p>26 So g can be found by calling the regression weak learner A. [sent-63, score-0.135]
</p><p>27 Since at each step we try to minimize an upper bound Rk of R, if we let the minimum be gk , it is clear that R(hk + gk ) ≤ Rk (gk ) ≤ R(hk ). [sent-64, score-0.274]
</p><p>28 This means that by optimizing with respect to the problem Rk that can be handled by A, we also make progress with respect to optimizing R. [sent-65, score-0.129]
</p><p>29 However, in partice, instead of the quadratic upper bound (which has a theoretical garantee easier to derive), one may also consider minimizing an approximation to the Taylor expansion, which would be closer to a Newton type method. [sent-68, score-0.143]
</p><p>30 ,N , with either w = ∂ 2 R/∂hk (x )2 or % Newton-type method with diagonal Hessian W global diagonal upper bound on the Hessian % Upper-bound minimization let R = [r ] =1,. [sent-78, score-0.132]
</p><p>31 This is inline with earlier boosting work in which samplereweighting was a central idea. [sent-84, score-0.135]
</p><p>32 3  Learning Ranking Functions  We now apply Algorithm 1 to the problem of learning ranking functions. [sent-88, score-0.277]
</p><p>33 We use preference data as well as labeled data for training the ranking function. [sent-89, score-0.77]
</p><p>34 For preference data, we use x y to mean that x is preferred over y or x should be ranked higher than y, where x and y are the feature vectors for corresponding items to be ranked. [sent-90, score-0.41]
</p><p>35 We denote the set of available preferences as S = {x i yi , i = 1, . [sent-91, score-0.148]
</p><p>36 In addition to the preference data, there are also labeled data, L = {(z i , li ), i = 1, . [sent-95, score-0.473]
</p><p>37 , n}, where zi is the feature of an item and li is the corresponding numerically coded label. [sent-98, score-0.132]
</p><p>38 2 We formulate the ranking problem as computing a ranking function h ∈ H, such that h satis£es as much as possible the set of preferences, i. [sent-99, score-0.554]
</p><p>39 2 Some may argue that, absolute relevance judgments can also be converted to relative relevance judgments. [sent-105, score-0.209]
</p><p>40 For example, for a query, suppose we have three documents d 1 , d2 and d3 labeled as perfect, good, and bad, respectively. [sent-106, score-0.235]
</p><p>41 We can obtain the following relative relevance judgments: d 1 is preferred over d2 , d1 is preferred over d3 and d2 is preferred over d3 . [sent-107, score-0.216]
</p><p>42 However, it is often the case in Web search that for many queries there only exist documents with a single label and for such kind of queries, no preference data can be constructed. [sent-108, score-0.642]
</p><p>43 We use the following objective function to measure the empirical risk of a ranking function h, R(h) =  w 2  N  i=1  (max{0, h(yi ) − h(xi ) + τ })2 +  1−w 2  n  i=1  (li − h(zi ))2 . [sent-110, score-0.343]
</p><p>44 The objective function consists of two parts: 1) for the preference data part, we introduce a margin parameter τ and would like to enforce that h(xi ) ≥ h(yi ) + τ ; if not, the difference is quadratically penalized; and 2) for the labeled data part, we simply minimize the squared errors. [sent-111, score-0.518]
</p><p>45 The parameter w is the relative weight for the preference data and could typically be found by cross-validation. [sent-112, score-0.34]
</p><p>46 Note that R depends only on the values h(xi ), h(yi ), h(zi ) and we can optimize it using the general boosting framework discussed in section 2. [sent-114, score-0.135]
</p><p>47 For simplicity let us assume that each feature vector xi , yi and zi only appears in S and L once, otherwise we need to compute appropriately formed averages. [sent-117, score-0.271]
</p><p>48 The components of the negative gradient corresponding to h(zi ) is just li − h(zi ). [sent-125, score-0.105]
</p><p>49 In particular, if we evaluate the Hessian at h, the 2-by-2 block equals to 1 −1 0 0 , , −1 1 0 0 for xi yi with h(xi ) − h(yi ) < τ and h(xi ) − h(yi ) ≥ τ , respectively. [sent-129, score-0.185]
</p><p>50 We can upper bound the £rst matrix by the diagonal matrix diag(2, 2) leading to a quadratic upper bound. [sent-130, score-0.222]
</p><p>51 , 1) we construct a training set for £tting g m (x) by adding the following for each xi , yi ∈ S, (xi , max{0, hm−1 (yi ) − hm−1 (xi ) + τ }), (yi , − max{0, hm−1 (yi ) − hm−1 (xi ) + τ }), and {(zi , li − hm−1 (zi )), i = 1, . [sent-135, score-0.251]
</p><p>52 The £tting of g m (x) is done by using a base regressor with the above training set; We weigh the above preference data by w and the labeled data by 1 − w respectively. [sent-139, score-0.562]
</p><p>53 2) forming hm = hm−1 + ηsm gm (x), where sm is found by line search to minimize the objective function. [sent-140, score-0.207]
</p><p>54 τ could be the degree of preference if that information is available, e. [sent-144, score-0.338]
</p><p>55 , the absolute grade difference between each prefernce if it is converted from labeled data. [sent-146, score-0.243]
</p><p>56 When there is no preference data and the weak regression learner produces a regression tree, QBrank is identical to Gradient Boosting Trees (GBT) as proposed in [8]. [sent-149, score-0.531]
</p><p>57 An xi can appear multiple times in Step 1), in this case we use the average gradient values as the target value for each distinct xi . [sent-151, score-0.219]
</p><p>58 4  4  Experiment Results  We carried out several experiments illustrating the properties and effectiveness of QBrank using combined preference data and labeled data in the context of learning ranking functions for Web search [3]. [sent-152, score-0.837]
</p><p>59 We also compared its performance with QBrank using preference data only and several existing algorithms such as Gradient Boosting Trees [8] and RankSVM [11, 12]. [sent-153, score-0.34]
</p><p>60 RankSVM is a preference learning method which learns pair-wise preferences based on SVM approach. [sent-154, score-0.36]
</p><p>61 We sampled a set of queries from the query logs of a commercial search engine and generated a certain number of query-document pairs for each of the queries. [sent-161, score-0.452]
</p><p>62 In total we have 4,898 queries and 105,243 query-document pairs. [sent-163, score-0.11]
</p><p>63 We split the data into three subsets as follows: 1) we extract all the queries which have documents with a single label. [sent-164, score-0.258]
</p><p>64 The set of feature vectors and the corresponding labels form training set L1 , which contains around 2000 queries giving rise to 20,000 query-document pairs. [sent-165, score-0.13]
</p><p>65 (Some single-labeled data are from editorial database, where each query has a few ideal results with the same label. [sent-166, score-0.171]
</p><p>66 Other are bad ranking cases submitted internally and all the documents for a query are labeled as bad. [sent-167, score-0.66]
</p><p>67 We use L2 or L3 to generate a set of preference data as follows: given a query q and two documents dx and dy . [sent-169, score-0.699]
</p><p>68 If dx has a higher grade than dy , we include the preference x y while if dy has a higher grade than dx , we include the preference y x. [sent-171, score-0.972]
</p><p>69 For each query, we consider all pairs of documents within the search results for that query except those with equal grades. [sent-172, score-0.369]
</p><p>70 This way, we generate around 500,000 preference pairs in total. [sent-173, score-0.346]
</p><p>71 We denote the preference data as P2 and P3 corresponding to L2 and L3 , respectively. [sent-174, score-0.34]
</p><p>72 The output of QBrank is a ranking function h which is used to rank the documents x according to h(x). [sent-176, score-0.436]
</p><p>73 Therefore, document x is ranked higher than y by the ranking function h if h(x) > h(y), and we call this the predicted preference. [sent-177, score-0.412]
</p><p>74 We propose the following two metrics to evaluate the performance of a ranking function with respect to a given set of preferences which we considered as the true preferences. [sent-178, score-0.348]
</p><p>75 1) Precision at K%: for two documents x and y (with respect to the same query), it is reasonable to assume that it is easy to compare x and y if |h(x) − h(y)| is large, and x and y should have about the same rank if h(x) is close to h(y). [sent-179, score-0.187]
</p><p>76 Base on this, we sort all the document pairs x, y according to |h(x) − h(y)|. [sent-180, score-0.123]
</p><p>77 Precision at 100% can be considered as an overall performance measure of a ranking function. [sent-182, score-0.277]
</p><p>78 2) Discounted Cumulative Gain (DCG): DCG has been widely used to assess relevance in the context of search engines [10]. [sent-183, score-0.152]
</p><p>79 For a ranked list of N documents (N is set to be 5 in our experiments), we N use the following variation of DCG, DCGN = i=1 Gi / log2 (i + 1), where Gi represents the weights assigned to the label of the document at position i. [sent-184, score-0.26]
</p><p>80 In our experiments, τ is the absolute grade difference between each pair xi , yi . [sent-188, score-0.294]
</p><p>81 For a fair comparsion, we used single regression tree with 20 leaf nodes as the base regressor of both GBT and QBrank in our experiments. [sent-222, score-0.168]
</p><p>82 We are interested in the following questions: 1) How does GBT using labeled data L2 compare with QBrank or RankSVM using the preference data extracted from the same labeled data: P2 ? [sent-226, score-0.612]
</p><p>83 Table 1 presents the precision at K% on data P3 for the ranking function learned from GBT with labeled training data L2 , and QBrank and RankSVM with the corresponding preference data P2 . [sent-229, score-0.838]
</p><p>84 In case of preference learning, no preference pairs could be extracted from single labeled data. [sent-233, score-0.802]
</p><p>85 Therefore, existing methods such as RankSVM, RankNet and RankBoost that are formulated for preference data only can not take advantage of such data. [sent-234, score-0.34]
</p><p>86 The QBrank framework can combine preference data and labeled data in a natural way. [sent-235, score-0.473]
</p><p>87 From Figure 1, we can see QBrank using combined preference data and labeled data outperforms both QBrank and RankSVM using preference data only, which indicates that singled labeled data are also useful to QBrank training. [sent-236, score-0.946]
</p><p>88 Another observation is that GBT using labeled data is signi£cantly worse than QBrank using preference data extracted from the same labeled data3 . [sent-237, score-0.612]
</p><p>89 Notice that, we excluded all tied data (pairs of documents with the same grades) when converting preference data from the absolute relevance judgments, which can be signi£cant information loss, for example of x1 > x2 , and x3 > x4 . [sent-239, score-0.599]
</p><p>90 If we know x2 ties with x3 , then we can have the whole ranking x1 > {x2 , x3 } > x4 . [sent-240, score-0.277]
</p><p>91 5  Conclusions and Future Work  We proposed a general boosting method for optimizing complex loss functions. [sent-242, score-0.245]
</p><p>92 We also applied the general framework to the problem of learning ranking functions. [sent-243, score-0.277]
</p><p>93 Experimental results using a commercial search engine data show that our approach leads to signi£cant improvements. [sent-244, score-0.188]
</p><p>94 3  a 1% dcg gain is considered sign£cant on this data set for commercial search engines. [sent-246, score-0.239]
</p><p>95 De£nition 4 Let R(h) be a function of h, an global upper bound M of its Hessian with respect to 2 [W, X] satisfy: ∀h, β and g: R(h + βg) ≤ R(h) + β R(h)T g + β M g 2 . [sent-263, score-0.11]
</p><p>96 W,X 2 Although we only consider global upper bounds, it is easy to see that results with respect to local upper bounds can also be established. [sent-264, score-0.158]
</p><p>97 Let sk = sk gk W,X be the ¯ √ j normalized step-size, aj = i=0 si , and bj = i≥j (¯i 2 i + M s2 /2), then ¯ s ¯i ¯ ¯ h W,X h ¯ ¯ R(hk+1 ) ≤ R(h)+ ¯ max(0, R(0)−R(h))+inf (b0 − bj+1 ) ¯ j h W,X + ak h  s2 k (¯k  W,X W,X  + aj + (bj+1 − bk+1 ) . [sent-269, score-0.411]
</p><p>98 + ak  √  If we choose sk ≥ 0 such that k sk = ∞ and ¯ ¯ + sk k ) < ∞, then limk→∞ R(hk ) = ¯ ¯ ¯ inf h∈span(C) R(h), and the rate of convergence compared to any target h ∈ span(C) only depends ¯ ¯ on h W,X , and the sequences {aj } and {bj }. [sent-270, score-0.331]
</p><p>99 In particu√ lar, for for some £xed s > 0, we can choose 2 i ≤ M s2 /2, and sk gk W,X = s2 when R(hk + sk gk ) ≤ R(hk ) (¯k = 0 otherwise). [sent-273, score-0.356]
</p><p>100 The convergence results show that in order to have a risk not much worse than any target function ¯ h ∈ span(C), the approximation function hk does not need to be very complex when the complexity is measured by its 1-norm. [sent-275, score-0.409]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('qbrank', 0.482), ('gbt', 0.356), ('preference', 0.317), ('hk', 0.308), ('ranking', 0.277), ('ranksvm', 0.219), ('query', 0.148), ('boosting', 0.135), ('documents', 0.125), ('labeled', 0.11), ('queries', 0.11), ('yi', 0.105), ('gk', 0.096), ('document', 0.094), ('dcg', 0.093), ('hm', 0.09), ('zi', 0.086), ('grade', 0.083), ('sk', 0.082), ('xi', 0.08), ('hessian', 0.077), ('web', 0.073), ('search', 0.067), ('oachims', 0.063), ('quadratic', 0.061), ('span', 0.061), ('relevance', 0.06), ('loss', 0.059), ('gradient', 0.059), ('regression', 0.056), ('commercial', 0.056), ('hmi', 0.055), ('upper', 0.054), ('rj', 0.053), ('preferred', 0.052), ('dy', 0.05), ('rk', 0.048), ('friedman', 0.046), ('li', 0.046), ('learner', 0.045), ('precision', 0.045), ('comprises', 0.044), ('aj', 0.043), ('preferences', 0.043), ('chapire', 0.042), ('inger', 0.042), ('regressor', 0.042), ('xq', 0.042), ('zha', 0.042), ('engine', 0.042), ('risk', 0.042), ('bj', 0.042), ('ranked', 0.041), ('judgments', 0.039), ('wj', 0.039), ('dx', 0.036), ('weak', 0.034), ('rank', 0.034), ('convergence', 0.034), ('extracted', 0.029), ('pairs', 0.029), ('inf', 0.028), ('bound', 0.028), ('mi', 0.028), ('respect', 0.028), ('structured', 0.027), ('hj', 0.027), ('ordinal', 0.027), ('base', 0.027), ('optimizing', 0.026), ('reweighting', 0.026), ('sm', 0.026), ('max', 0.026), ('absolute', 0.026), ('complex', 0.025), ('engines', 0.025), ('sigir', 0.025), ('tied', 0.025), ('diagonal', 0.025), ('functional', 0.025), ('converted', 0.024), ('gi', 0.024), ('shrinkage', 0.024), ('xd', 0.024), ('objective', 0.024), ('tree', 0.023), ('ak', 0.023), ('data', 0.023), ('rigorous', 0.023), ('bounds', 0.022), ('trees', 0.022), ('taylor', 0.021), ('margin', 0.021), ('handled', 0.021), ('views', 0.021), ('degree', 0.021), ('functions', 0.02), ('expansion', 0.02), ('leaf', 0.02), ('training', 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999964 <a title="6-tfidf-1" href="./nips-2007-A_General_Boosting_Method_and_its_Application_to_Learning_Ranking_Functions_for_Web_Search.html">6 nips-2007-A General Boosting Method and its Application to Learning Ranking Functions for Web Search</a></p>
<p>Author: Zhaohui Zheng, Hongyuan Zha, Tong Zhang, Olivier Chapelle, Keke Chen, Gordon Sun</p><p>Abstract: We present a general boosting method extending functional gradient boosting to optimize complex loss functions that are encountered in many machine learning problems. Our approach is based on optimization of quadratic upper bounds of the loss functions which allows us to present a rigorous convergence analysis of the algorithm. More importantly, this general framework enables us to use a standard regression base learner such as single regression tree for £tting any loss function. We illustrate an application of the proposed method in learning ranking functions for Web search by combining both preference data and labeled data for training. We present experimental results for Web search using data from a commercial search engine that show signi£cant improvements of our proposed methods over some existing methods. 1</p><p>2 0.23181422 <a title="6-tfidf-2" href="./nips-2007-Evaluating_Search_Engines_by_Modeling_the_Relationship_Between_Relevance_and_Clicks.html">83 nips-2007-Evaluating Search Engines by Modeling the Relationship Between Relevance and Clicks</a></p>
<p>Author: Ben Carterette, Rosie Jones</p><p>Abstract: We propose a model that leverages the millions of clicks received by web search engines to predict document relevance. This allows the comparison of ranking functions when clicks are available but complete relevance judgments are not. After an initial training phase using a set of relevance judgments paired with click data, we show that our model can predict the relevance score of documents that have not been judged. These predictions can be used to evaluate the performance of a search engine, using our novel formalization of the conﬁdence of the standard evaluation metric discounted cumulative gain (DCG), so comparisons can be made across time and datasets. This contrasts with previous methods which can provide only pair-wise relevance judgments between results shown for the same query. When no relevance judgments are available, we can identify the better of two ranked lists up to 82% of the time, and with only two relevance judgments for each query, we can identify the better ranking up to 94% of the time. While our experiments are on sponsored search results, which is the ﬁnancial backbone of web search, our method is general enough to be applicable to algorithmic web search results as well. Furthermore, we give an algorithm to guide the selection of additional documents to judge to improve conﬁdence. 1</p><p>3 0.23016717 <a title="6-tfidf-3" href="./nips-2007-McRank%3A_Learning_to_Rank_Using_Multiple_Classification_and_Gradient_Boosting.html">126 nips-2007-McRank: Learning to Rank Using Multiple Classification and Gradient Boosting</a></p>
<p>Author: Ping Li, Qiang Wu, Christopher J. Burges</p><p>Abstract: We cast the ranking problem as (1) multiple classiﬁcation (“Mc”) (2) multiple ordinal classiﬁcation, which lead to computationally tractable learning algorithms for relevance ranking in Web search. We consider the DCG criterion (discounted cumulative gain), a standard quality measure in information retrieval. Our approach is motivated by the fact that perfect classiﬁcations result in perfect DCG scores and the DCG errors are bounded by classiﬁcation errors. We propose using the Expected Relevance to convert class probabilities into ranking scores. The class probabilities are learned using a gradient boosting tree algorithm. Evaluations on large-scale datasets show that our approach can improve LambdaRank [5] and the regressions-based ranker [6], in terms of the (normalized) DCG scores. An efﬁcient implementation of the boosting tree algorithm is also presented.</p><p>4 0.13465625 <a title="6-tfidf-4" href="./nips-2007-Active_Preference_Learning_with_Discrete_Choice_Data.html">19 nips-2007-Active Preference Learning with Discrete Choice Data</a></p>
<p>Author: Brochu Eric, Nando D. Freitas, Abhijeet Ghosh</p><p>Abstract: We propose an active learning algorithm that learns a continuous valuation model from discrete preferences. The algorithm automatically decides what items are best presented to an individual in order to ﬁnd the item that they value highly in as few trials as possible, and exploits quirks of human psychology to minimize time and cognitive burden. To do this, our algorithm maximizes the expected improvement at each query without accurately modelling the entire valuation surface, which would be needlessly expensive. The problem is particularly difﬁcult because the space of choices is inﬁnite. We demonstrate the effectiveness of the new algorithm compared to related active learning methods. We also embed the algorithm within a decision making tool for assisting digital artists in rendering materials. The tool ﬁnds the best parameters while minimizing the number of queries. 1</p><p>5 0.11618648 <a title="6-tfidf-5" href="./nips-2007-Regularized_Boost_for_Semi-Supervised_Learning.html">166 nips-2007-Regularized Boost for Semi-Supervised Learning</a></p>
<p>Author: Ke Chen, Shihai Wang</p><p>Abstract: Semi-supervised inductive learning concerns how to learn a decision rule from a data set containing both labeled and unlabeled data. Several boosting algorithms have been extended to semi-supervised learning with various strategies. To our knowledge, however, none of them takes local smoothness constraints among data into account during ensemble learning. In this paper, we introduce a local smoothness regularizer to semi-supervised boosting algorithms based on the universal optimization framework of margin cost functionals. Our regularizer is applicable to existing semi-supervised boosting algorithms to improve their generalization and speed up their training. Comparative results on synthetic, benchmark and real world tasks demonstrate the effectiveness of our local smoothness regularizer. We discuss relevant issues and relate our regularizer to previous work. 1</p><p>6 0.11510673 <a title="6-tfidf-6" href="./nips-2007-Boosting_the_Area_under_the_ROC_Curve.html">39 nips-2007-Boosting the Area under the ROC Curve</a></p>
<p>7 0.11425555 <a title="6-tfidf-7" href="./nips-2007-COFI_RANK_-_Maximum_Margin_Matrix_Factorization_for_Collaborative_Ranking.html">41 nips-2007-COFI RANK - Maximum Margin Matrix Factorization for Collaborative Ranking</a></p>
<p>8 0.10174575 <a title="6-tfidf-8" href="./nips-2007-Non-parametric_Modeling_of_Partially_Ranked_Data.html">142 nips-2007-Non-parametric Modeling of Partially Ranked Data</a></p>
<p>9 0.09070278 <a title="6-tfidf-9" href="./nips-2007-Multiple-Instance_Active_Learning.html">136 nips-2007-Multiple-Instance Active Learning</a></p>
<p>10 0.089198619 <a title="6-tfidf-10" href="./nips-2007-Statistical_Analysis_of_Semi-Supervised_Regression.html">186 nips-2007-Statistical Analysis of Semi-Supervised Regression</a></p>
<p>11 0.082344912 <a title="6-tfidf-11" href="./nips-2007-On_Ranking_in_Survival_Analysis%3A_Bounds_on_the_Concordance_Index.html">144 nips-2007-On Ranking in Survival Analysis: Bounds on the Concordance Index</a></p>
<p>12 0.077982329 <a title="6-tfidf-12" href="./nips-2007-Discriminative_Batch_Mode_Active_Learning.html">69 nips-2007-Discriminative Batch Mode Active Learning</a></p>
<p>13 0.072652273 <a title="6-tfidf-13" href="./nips-2007-Structured_Learning_with_Approximate_Inference.html">187 nips-2007-Structured Learning with Approximate Inference</a></p>
<p>14 0.072472297 <a title="6-tfidf-14" href="./nips-2007-Gaussian_Process_Models_for_Link_Analysis_and_Transfer_Learning.html">94 nips-2007-Gaussian Process Models for Link Analysis and Transfer Learning</a></p>
<p>15 0.070096955 <a title="6-tfidf-15" href="./nips-2007-A_learning_framework_for_nearest_neighbor_search.html">16 nips-2007-A learning framework for nearest neighbor search</a></p>
<p>16 0.061869085 <a title="6-tfidf-16" href="./nips-2007-On_higher-order_perceptron_algorithms.html">146 nips-2007-On higher-order perceptron algorithms</a></p>
<p>17 0.060210355 <a title="6-tfidf-17" href="./nips-2007-Spatial_Latent_Dirichlet_Allocation.html">183 nips-2007-Spatial Latent Dirichlet Allocation</a></p>
<p>18 0.057397924 <a title="6-tfidf-18" href="./nips-2007-Fast_and_Scalable_Training_of_Semi-Supervised_CRFs_with_Application_to_Activity_Recognition.html">88 nips-2007-Fast and Scalable Training of Semi-Supervised CRFs with Application to Activity Recognition</a></p>
<p>19 0.057042181 <a title="6-tfidf-19" href="./nips-2007-One-Pass_Boosting.html">147 nips-2007-One-Pass Boosting</a></p>
<p>20 0.056582779 <a title="6-tfidf-20" href="./nips-2007-Bundle_Methods_for_Machine_Learning.html">40 nips-2007-Bundle Methods for Machine Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2007_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.188), (1, 0.035), (2, -0.15), (3, 0.076), (4, 0.055), (5, 0.078), (6, 0.186), (7, -0.186), (8, 0.18), (9, -0.104), (10, -0.068), (11, 0.041), (12, 0.308), (13, 0.128), (14, 0.055), (15, 0.078), (16, -0.088), (17, 0.061), (18, -0.036), (19, 0.054), (20, 0.029), (21, -0.162), (22, 0.018), (23, -0.022), (24, -0.032), (25, 0.011), (26, 0.056), (27, -0.047), (28, 0.031), (29, 0.011), (30, -0.025), (31, -0.029), (32, 0.038), (33, -0.068), (34, 0.028), (35, -0.031), (36, -0.036), (37, -0.029), (38, -0.028), (39, -0.011), (40, 0.002), (41, -0.023), (42, -0.076), (43, -0.148), (44, 0.008), (45, 0.075), (46, 0.039), (47, 0.059), (48, -0.049), (49, 0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93919832 <a title="6-lsi-1" href="./nips-2007-A_General_Boosting_Method_and_its_Application_to_Learning_Ranking_Functions_for_Web_Search.html">6 nips-2007-A General Boosting Method and its Application to Learning Ranking Functions for Web Search</a></p>
<p>Author: Zhaohui Zheng, Hongyuan Zha, Tong Zhang, Olivier Chapelle, Keke Chen, Gordon Sun</p><p>Abstract: We present a general boosting method extending functional gradient boosting to optimize complex loss functions that are encountered in many machine learning problems. Our approach is based on optimization of quadratic upper bounds of the loss functions which allows us to present a rigorous convergence analysis of the algorithm. More importantly, this general framework enables us to use a standard regression base learner such as single regression tree for £tting any loss function. We illustrate an application of the proposed method in learning ranking functions for Web search by combining both preference data and labeled data for training. We present experimental results for Web search using data from a commercial search engine that show signi£cant improvements of our proposed methods over some existing methods. 1</p><p>2 0.89907652 <a title="6-lsi-2" href="./nips-2007-Evaluating_Search_Engines_by_Modeling_the_Relationship_Between_Relevance_and_Clicks.html">83 nips-2007-Evaluating Search Engines by Modeling the Relationship Between Relevance and Clicks</a></p>
<p>Author: Ben Carterette, Rosie Jones</p><p>Abstract: We propose a model that leverages the millions of clicks received by web search engines to predict document relevance. This allows the comparison of ranking functions when clicks are available but complete relevance judgments are not. After an initial training phase using a set of relevance judgments paired with click data, we show that our model can predict the relevance score of documents that have not been judged. These predictions can be used to evaluate the performance of a search engine, using our novel formalization of the conﬁdence of the standard evaluation metric discounted cumulative gain (DCG), so comparisons can be made across time and datasets. This contrasts with previous methods which can provide only pair-wise relevance judgments between results shown for the same query. When no relevance judgments are available, we can identify the better of two ranked lists up to 82% of the time, and with only two relevance judgments for each query, we can identify the better ranking up to 94% of the time. While our experiments are on sponsored search results, which is the ﬁnancial backbone of web search, our method is general enough to be applicable to algorithmic web search results as well. Furthermore, we give an algorithm to guide the selection of additional documents to judge to improve conﬁdence. 1</p><p>3 0.81452221 <a title="6-lsi-3" href="./nips-2007-McRank%3A_Learning_to_Rank_Using_Multiple_Classification_and_Gradient_Boosting.html">126 nips-2007-McRank: Learning to Rank Using Multiple Classification and Gradient Boosting</a></p>
<p>Author: Ping Li, Qiang Wu, Christopher J. Burges</p><p>Abstract: We cast the ranking problem as (1) multiple classiﬁcation (“Mc”) (2) multiple ordinal classiﬁcation, which lead to computationally tractable learning algorithms for relevance ranking in Web search. We consider the DCG criterion (discounted cumulative gain), a standard quality measure in information retrieval. Our approach is motivated by the fact that perfect classiﬁcations result in perfect DCG scores and the DCG errors are bounded by classiﬁcation errors. We propose using the Expected Relevance to convert class probabilities into ranking scores. The class probabilities are learned using a gradient boosting tree algorithm. Evaluations on large-scale datasets show that our approach can improve LambdaRank [5] and the regressions-based ranker [6], in terms of the (normalized) DCG scores. An efﬁcient implementation of the boosting tree algorithm is also presented.</p><p>4 0.62738192 <a title="6-lsi-4" href="./nips-2007-COFI_RANK_-_Maximum_Margin_Matrix_Factorization_for_Collaborative_Ranking.html">41 nips-2007-COFI RANK - Maximum Margin Matrix Factorization for Collaborative Ranking</a></p>
<p>Author: Markus Weimer, Alexandros Karatzoglou, Quoc V. Le, Alex J. Smola</p><p>Abstract: In this paper, we consider collaborative ﬁltering as a ranking problem. We present a method which uses Maximum Margin Matrix Factorization and optimizes ranking instead of rating. We employ structured output prediction to optimize directly for ranking scores. Experimental results show that our method gives very good ranking scores and scales well on collaborative ﬁltering tasks. 1</p><p>5 0.5043202 <a title="6-lsi-5" href="./nips-2007-Active_Preference_Learning_with_Discrete_Choice_Data.html">19 nips-2007-Active Preference Learning with Discrete Choice Data</a></p>
<p>Author: Brochu Eric, Nando D. Freitas, Abhijeet Ghosh</p><p>Abstract: We propose an active learning algorithm that learns a continuous valuation model from discrete preferences. The algorithm automatically decides what items are best presented to an individual in order to ﬁnd the item that they value highly in as few trials as possible, and exploits quirks of human psychology to minimize time and cognitive burden. To do this, our algorithm maximizes the expected improvement at each query without accurately modelling the entire valuation surface, which would be needlessly expensive. The problem is particularly difﬁcult because the space of choices is inﬁnite. We demonstrate the effectiveness of the new algorithm compared to related active learning methods. We also embed the algorithm within a decision making tool for assisting digital artists in rendering materials. The tool ﬁnds the best parameters while minimizing the number of queries. 1</p><p>6 0.44834298 <a title="6-lsi-6" href="./nips-2007-On_Ranking_in_Survival_Analysis%3A_Bounds_on_the_Concordance_Index.html">144 nips-2007-On Ranking in Survival Analysis: Bounds on the Concordance Index</a></p>
<p>7 0.42171928 <a title="6-lsi-7" href="./nips-2007-Regularized_Boost_for_Semi-Supervised_Learning.html">166 nips-2007-Regularized Boost for Semi-Supervised Learning</a></p>
<p>8 0.40449029 <a title="6-lsi-8" href="./nips-2007-Fast_and_Scalable_Training_of_Semi-Supervised_CRFs_with_Application_to_Activity_Recognition.html">88 nips-2007-Fast and Scalable Training of Semi-Supervised CRFs with Application to Activity Recognition</a></p>
<p>9 0.39328289 <a title="6-lsi-9" href="./nips-2007-Boosting_the_Area_under_the_ROC_Curve.html">39 nips-2007-Boosting the Area under the ROC Curve</a></p>
<p>10 0.3675884 <a title="6-lsi-10" href="./nips-2007-Non-parametric_Modeling_of_Partially_Ranked_Data.html">142 nips-2007-Non-parametric Modeling of Partially Ranked Data</a></p>
<p>11 0.31927258 <a title="6-lsi-11" href="./nips-2007-Discriminative_Batch_Mode_Active_Learning.html">69 nips-2007-Discriminative Batch Mode Active Learning</a></p>
<p>12 0.31593752 <a title="6-lsi-12" href="./nips-2007-Multiple-Instance_Active_Learning.html">136 nips-2007-Multiple-Instance Active Learning</a></p>
<p>13 0.29968265 <a title="6-lsi-13" href="./nips-2007-Convex_Learning_with_Invariances.html">62 nips-2007-Convex Learning with Invariances</a></p>
<p>14 0.29120663 <a title="6-lsi-14" href="./nips-2007-Nearest-Neighbor-Based_Active_Learning_for_Rare_Category_Detection.html">139 nips-2007-Nearest-Neighbor-Based Active Learning for Rare Category Detection</a></p>
<p>15 0.28528267 <a title="6-lsi-15" href="./nips-2007-Efficient_Convex_Relaxation_for_Transductive_Support_Vector_Machine.html">76 nips-2007-Efficient Convex Relaxation for Transductive Support Vector Machine</a></p>
<p>16 0.28004885 <a title="6-lsi-16" href="./nips-2007-Structured_Learning_with_Approximate_Inference.html">187 nips-2007-Structured Learning with Approximate Inference</a></p>
<p>17 0.27786854 <a title="6-lsi-17" href="./nips-2007-Bayesian_Co-Training.html">32 nips-2007-Bayesian Co-Training</a></p>
<p>18 0.27420786 <a title="6-lsi-18" href="./nips-2007-Statistical_Analysis_of_Semi-Supervised_Regression.html">186 nips-2007-Statistical Analysis of Semi-Supervised Regression</a></p>
<p>19 0.27408084 <a title="6-lsi-19" href="./nips-2007-FilterBoost%3A_Regression_and_Classification_on_Large_Datasets.html">90 nips-2007-FilterBoost: Regression and Classification on Large Datasets</a></p>
<p>20 0.27341053 <a title="6-lsi-20" href="./nips-2007-A_learning_framework_for_nearest_neighbor_search.html">16 nips-2007-A learning framework for nearest neighbor search</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2007_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.021), (13, 0.037), (16, 0.048), (21, 0.126), (27, 0.188), (31, 0.012), (34, 0.08), (35, 0.018), (47, 0.103), (49, 0.015), (83, 0.125), (85, 0.017), (87, 0.038), (90, 0.065)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.86537009 <a title="6-lda-1" href="./nips-2007-Hippocampal_Contributions_to_Control%3A_The_Third_Way.html">100 nips-2007-Hippocampal Contributions to Control: The Third Way</a></p>
<p>Author: Máté Lengyel, Peter Dayan</p><p>Abstract: Recent experimental studies have focused on the specialization of different neural structures for different types of instrumental behavior. Recent theoretical work has provided normative accounts for why there should be more than one control system, and how the output of different controllers can be integrated. Two particlar controllers have been identiﬁed, one associated with a forward model and the prefrontal cortex and a second associated with computationally simpler, habitual, actor-critic methods and part of the striatum. We argue here for the normative appropriateness of an additional, but so far marginalized control system, associated with episodic memory, and involving the hippocampus and medial temporal cortices. We analyze in depth a class of simple environments to show that episodic control should be useful in a range of cases characterized by complexity and inferential noise, and most particularly at the very early stages of learning, long before habitization has set in. We interpret data on the transfer of control from the hippocampus to the striatum in the light of this hypothesis. 1</p><p>2 0.81323594 <a title="6-lda-2" href="./nips-2007-The_Infinite_Gamma-Poisson_Feature_Model.html">196 nips-2007-The Infinite Gamma-Poisson Feature Model</a></p>
<p>Author: Michalis K. Titsias</p><p>Abstract: We present a probability distribution over non-negative integer valued matrices with possibly an inﬁnite number of columns. We also derive a stochastic process that reproduces this distribution over equivalence classes. This model can play the role of the prior in nonparametric Bayesian learning scenarios where multiple latent features are associated with the observed data and each feature can have multiple appearances or occurrences within each data point. Such data arise naturally when learning visual object recognition systems from unlabelled images. Together with the nonparametric prior we consider a likelihood model that explains the visual appearance and location of local image patches. Inference with this model is carried out using a Markov chain Monte Carlo algorithm. 1</p><p>same-paper 3 0.8067916 <a title="6-lda-3" href="./nips-2007-A_General_Boosting_Method_and_its_Application_to_Learning_Ranking_Functions_for_Web_Search.html">6 nips-2007-A General Boosting Method and its Application to Learning Ranking Functions for Web Search</a></p>
<p>Author: Zhaohui Zheng, Hongyuan Zha, Tong Zhang, Olivier Chapelle, Keke Chen, Gordon Sun</p><p>Abstract: We present a general boosting method extending functional gradient boosting to optimize complex loss functions that are encountered in many machine learning problems. Our approach is based on optimization of quadratic upper bounds of the loss functions which allows us to present a rigorous convergence analysis of the algorithm. More importantly, this general framework enables us to use a standard regression base learner such as single regression tree for £tting any loss function. We illustrate an application of the proposed method in learning ranking functions for Web search by combining both preference data and labeled data for training. We present experimental results for Web search using data from a commercial search engine that show signi£cant improvements of our proposed methods over some existing methods. 1</p><p>4 0.72356629 <a title="6-lda-4" href="./nips-2007-A_neural_network_implementing_optimal_state_estimation_based_on_dynamic_spike_train_decoding.html">17 nips-2007-A neural network implementing optimal state estimation based on dynamic spike train decoding</a></p>
<p>Author: Omer Bobrowski, Ron Meir, Shy Shoham, Yonina Eldar</p><p>Abstract: It is becoming increasingly evident that organisms acting in uncertain dynamical environments often employ exact or approximate Bayesian statistical calculations in order to continuously estimate the environmental state, integrate information from multiple sensory modalities, form predictions and choose actions. What is less clear is how these putative computations are implemented by cortical neural networks. An additional level of complexity is introduced because these networks observe the world through spike trains received from primary sensory afferents, rather than directly. A recent line of research has described mechanisms by which such computations can be implemented using a network of neurons whose activity directly represents a probability distribution across the possible “world states”. Much of this work, however, uses various approximations, which severely restrict the domain of applicability of these implementations. Here we make use of rigorous mathematical results from the theory of continuous time point process ﬁltering, and show how optimal real-time state estimation and prediction may be implemented in a general setting using linear neural networks. We demonstrate the applicability of the approach with several examples, and relate the required network properties to the statistical nature of the environment, thereby quantifying the compatibility of a given network with its environment. 1</p><p>5 0.72269887 <a title="6-lda-5" href="./nips-2007-McRank%3A_Learning_to_Rank_Using_Multiple_Classification_and_Gradient_Boosting.html">126 nips-2007-McRank: Learning to Rank Using Multiple Classification and Gradient Boosting</a></p>
<p>Author: Ping Li, Qiang Wu, Christopher J. Burges</p><p>Abstract: We cast the ranking problem as (1) multiple classiﬁcation (“Mc”) (2) multiple ordinal classiﬁcation, which lead to computationally tractable learning algorithms for relevance ranking in Web search. We consider the DCG criterion (discounted cumulative gain), a standard quality measure in information retrieval. Our approach is motivated by the fact that perfect classiﬁcations result in perfect DCG scores and the DCG errors are bounded by classiﬁcation errors. We propose using the Expected Relevance to convert class probabilities into ranking scores. The class probabilities are learned using a gradient boosting tree algorithm. Evaluations on large-scale datasets show that our approach can improve LambdaRank [5] and the regressions-based ranker [6], in terms of the (normalized) DCG scores. An efﬁcient implementation of the boosting tree algorithm is also presented.</p><p>6 0.71131676 <a title="6-lda-6" href="./nips-2007-GRIFT%3A_A_graphical_model_for_inferring_visual_classification_features_from_human_data.html">93 nips-2007-GRIFT: A graphical model for inferring visual classification features from human data</a></p>
<p>7 0.71071339 <a title="6-lda-7" href="./nips-2007-Gaussian_Process_Models_for_Link_Analysis_and_Transfer_Learning.html">94 nips-2007-Gaussian Process Models for Link Analysis and Transfer Learning</a></p>
<p>8 0.70998353 <a title="6-lda-8" href="./nips-2007-Discriminative_Batch_Mode_Active_Learning.html">69 nips-2007-Discriminative Batch Mode Active Learning</a></p>
<p>9 0.70781887 <a title="6-lda-9" href="./nips-2007-A_probabilistic_model_for_generating_realistic_lip_movements_from_speech.html">18 nips-2007-A probabilistic model for generating realistic lip movements from speech</a></p>
<p>10 0.70705682 <a title="6-lda-10" href="./nips-2007-Near-Maximum_Entropy_Models_for_Binary_Neural_Representations_of_Natural_Images.html">138 nips-2007-Near-Maximum Entropy Models for Binary Neural Representations of Natural Images</a></p>
<p>11 0.70657188 <a title="6-lda-11" href="./nips-2007-Scene_Segmentation_with_CRFs_Learned_from_Partially_Labeled_Images.html">172 nips-2007-Scene Segmentation with CRFs Learned from Partially Labeled Images</a></p>
<p>12 0.70644879 <a title="6-lda-12" href="./nips-2007-People_Tracking_with_the_Laplacian_Eigenmaps_Latent_Variable_Model.html">153 nips-2007-People Tracking with the Laplacian Eigenmaps Latent Variable Model</a></p>
<p>13 0.70333952 <a title="6-lda-13" href="./nips-2007-Inferring_Neural_Firing_Rates_from_Spike_Trains_Using_Gaussian_Processes.html">104 nips-2007-Inferring Neural Firing Rates from Spike Trains Using Gaussian Processes</a></p>
<p>14 0.70292884 <a title="6-lda-14" href="./nips-2007-Evaluating_Search_Engines_by_Modeling_the_Relationship_Between_Relevance_and_Clicks.html">83 nips-2007-Evaluating Search Engines by Modeling the Relationship Between Relevance and Clicks</a></p>
<p>15 0.7018531 <a title="6-lda-15" href="./nips-2007-Exponential_Family_Predictive_Representations_of_State.html">86 nips-2007-Exponential Family Predictive Representations of State</a></p>
<p>16 0.70017248 <a title="6-lda-16" href="./nips-2007-Predictive_Matrix-Variate_t_Models.html">156 nips-2007-Predictive Matrix-Variate t Models</a></p>
<p>17 0.7001189 <a title="6-lda-17" href="./nips-2007-Hidden_Common_Cause_Relations_in_Relational_Learning.html">97 nips-2007-Hidden Common Cause Relations in Relational Learning</a></p>
<p>18 0.69931686 <a title="6-lda-18" href="./nips-2007-Ultrafast_Monte_Carlo_for_Statistical_Summations.html">209 nips-2007-Ultrafast Monte Carlo for Statistical Summations</a></p>
<p>19 0.69895554 <a title="6-lda-19" href="./nips-2007-Message_Passing_for_Max-weight_Independent_Set.html">128 nips-2007-Message Passing for Max-weight Independent Set</a></p>
<p>20 0.69894928 <a title="6-lda-20" href="./nips-2007-Distributed_Inference_for_Latent_Dirichlet_Allocation.html">73 nips-2007-Distributed Inference for Latent Dirichlet Allocation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
