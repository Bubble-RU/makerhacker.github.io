<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>41 nips-2007-COFI RANK - Maximum Margin Matrix Factorization for Collaborative Ranking</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-41" href="#">nips2007-41</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>41 nips-2007-COFI RANK - Maximum Margin Matrix Factorization for Collaborative Ranking</h1>
<br/><p>Source: <a title="nips-2007-41-pdf" href="http://papers.nips.cc/paper/3359-cofi-rank-maximum-margin-matrix-factorization-for-collaborative-ranking.pdf">pdf</a></p><p>Author: Markus Weimer, Alexandros Karatzoglou, Quoc V. Le, Alex J. Smola</p><p>Abstract: In this paper, we consider collaborative ﬁltering as a ranking problem. We present a method which uses Maximum Margin Matrix Factorization and optimizes ranking instead of rating. We employ structured output prediction to optimize directly for ranking scores. Experimental results show that our method gives very good ranking scores and scales well on collaborative ﬁltering tasks. 1</p><p>Reference: <a title="nips-2007-41-reference" href="../nips2007_reference/nips-2007-COFI_RANK_-_Maximum_Margin_Matrix_Factorization_for_Collaborative_Ranking_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 C O F I R ANK Maximum Margin Matrix Factorization for Collaborative Ranking  Markus Weimer∗  Alexandros Karatzoglou†  Quoc Viet Le‡  Alex Smola§  Abstract In this paper, we consider collaborative ﬁltering as a ranking problem. [sent-1, score-0.372]
</p><p>2 We present a method which uses Maximum Margin Matrix Factorization and optimizes ranking instead of rating. [sent-2, score-0.255]
</p><p>3 We employ structured output prediction to optimize directly for ranking scores. [sent-3, score-0.297]
</p><p>4 Experimental results show that our method gives very good ranking scores and scales well on collaborative ﬁltering tasks. [sent-4, score-0.406]
</p><p>5 1  Introduction  Collaborative ﬁltering has gained much attention in the machine learning community due to the need for it in webshops such as those of Amazon, Apple and Netﬂix. [sent-5, score-0.07]
</p><p>6 However, suggesting the right items is a highly nontrivial task: (1) There are many items to choose from. [sent-8, score-0.293]
</p><p>7 Collaborative ﬁltering addresses this problem by learning the suggestion function for a user from ratings provided by this and other users on items offered in the webshop. [sent-10, score-0.524]
</p><p>8 Those ratings are typically collected on a ﬁve star ordinal scale within the webshops. [sent-11, score-0.215]
</p><p>9 Learning the suggestion function can be considered either a rating (classiﬁcation) or a ranking problem. [sent-12, score-0.412]
</p><p>10 In the context of rating, one predicts the actual rating for an item that a customer has not rated yet. [sent-13, score-0.261]
</p><p>11 On the other hand, for ranking, one predicts a preference ordering over the yet unrated items. [sent-14, score-0.055]
</p><p>12 This list is the direct outcome of a ranking algorithm, and can be computed from the results of a rating algorithm by sorting the items according to their predicted rating. [sent-16, score-0.533]
</p><p>13 We argue that rating algorithms solve the wrong problem, and one that is actually harder: The absolute value of the rating for an item is highly biased for different users, while the ranking is far less prone to this problem. [sent-17, score-0.579]
</p><p>14 One approach is to solve the rating problem using regression. [sent-18, score-0.142]
</p><p>15 Thus, we present an algorithm that solves the ranking problem directly, without ﬁrst computing the rating. [sent-21, score-0.231]
</p><p>16 For collaborative rating, Maximum Margin Matrix Factorization (MMMF) [11, 12, 10] has proven to be an effective means of estimating the rating function. [sent-22, score-0.283]
</p><p>17 MMMF takes advantage of the collaborative effects: rating patterns from other users are used to estimate ratings for the current user. [sent-23, score-0.544]
</p><p>18 au 1 We conjecture that this is the case in order to keep the rules simple, since ranking scores are somewhat nontrivial to deﬁne, and there are many different ways to evaluate a ranking, as we will see in the following. [sent-36, score-0.284]
</p><p>19 the procedures developed for movies cannot be applied to books. [sent-40, score-0.067]
</p><p>20 Our algorithm is based on this idea of MMMF, but optimizes ranking measures instead of rating measures. [sent-42, score-0.397]
</p><p>21 Given that only the top ranked items will actually be presented to the user, it is much more important to rank the ﬁrst items right than the last ones. [sent-43, score-0.323]
</p><p>22 In other words, it is more important to predict what a user likes than what she dislikes. [sent-44, score-0.087]
</p><p>23 All of above reasonings lead to the following goals: • • • •  The algorithm needs to be able to optimize ranking scores directly. [sent-46, score-0.303]
</p><p>24 The algorithm needs to scale well and parallelize such as to deal with millions of ratings arising from thousands of items and users with an acceptable memory footprint. [sent-49, score-0.398]
</p><p>25 We describe our algorithm C O F I R ANK in terms of optimizing the ranking measure Normalized Discounted Cumulative Gain (NDCG). [sent-51, score-0.253]
</p><p>26 2  Problem Deﬁnition  Assume that we have m items and u users. [sent-52, score-0.137]
</p><p>27 The ratings are stored in the sparse matrix Y where Yi,j ∈ {0, . [sent-53, score-0.17]
</p><p>28 , r} is the rating of item j by user i and r is some maximal score. [sent-56, score-0.293]
</p><p>29 In rating, one estimates the missing values in Y directly while we treat this as a ranking task. [sent-58, score-0.231]
</p><p>30 Additionally, in NDCG [16], the correct order of higher ranked items is more important than that of lower ranked items: n  Deﬁnition 1 (NDCG) Denote by y ∈ {1, . [sent-59, score-0.187]
</p><p>31 , r} a vector of ratings and let π be a permutation of that vector. [sent-62, score-0.17]
</p><p>32 πi denotes the position of item i after the permutation. [sent-63, score-0.064]
</p><p>33 Moreover, let k ∈ N be a truncation threshold and πs sorts y in decreasing order. [sent-64, score-0.079]
</p><p>34 In this case the Discounted Cumulative Gains (DCG@k) score [5] and its normalized variant (NDCG@k) are given by k  DCG@k(y, π) = i=1  2yπi − 1 log(i + 2)  and N DCG@k(y, π) =  DCG@k(y, π) DCG@k(y, πs )  DCG@k is maximized for π = πs . [sent-65, score-0.061]
</p><p>35 The truncation threshold k reﬂects how many recommendations users are willing to consider. [sent-66, score-0.169]
</p><p>36 Departing from traditional pairwise ranking measures [4], DCG is positiondependent: Higher positions have more inﬂuence on the score than lower positions. [sent-69, score-0.271]
</p><p>37 Optimizing DCG has gained much interest in the machine learning and information retrieval (e. [sent-70, score-0.049]
</p><p>38 However, we present the ﬁrst effort to optimize this measure for collaborative ﬁltering. [sent-73, score-0.179]
</p><p>39 Since we want our system to be scalable, we need a method which scales not much worse than linearly in the number of the items to be ranked. [sent-75, score-0.137]
</p><p>40 The avenue we pursue is to estimate a matrix F ∈ Rm×u and to use the values Fij for the purpose of ranking the items j for user i. [sent-76, score-0.488]
</p><p>41 Given a matrix Y of known ratings we are now able to deﬁne the performance of F : u  NDCG@k(Πi , Y i ),  R(F, Y ) := i=1  2  (1)  where Πi is argsort(−F i ), it sorts F i in decreasing order. [sent-77, score-0.225]
</p><p>42 Hence, we need to restrict the complexity of F to ensure good performance on the test set when maximizing the score on the training set. [sent-79, score-0.059]
</p><p>43 Note that the scores decompose into a sum over individual users’ scores, hence we only need to show how minimizing −NDCG(π, y) can be replaced by minimizing a convex upper bound on the latter. [sent-83, score-0.137]
</p><p>44 Summing over the users then provides us with a convex bound for all of the terms. [sent-84, score-0.204]
</p><p>45 Converting NDCG(π, y) into a loss by computing the regret with respect to the optimal permutation argsort(−y). [sent-86, score-0.111]
</p><p>46 Denote by π a permutation (of the n items a user might want to see) and let f ∈ Rn be a estimated rating. [sent-88, score-0.257]
</p><p>47 We use the convex upper-bounding technique described by [15] to combine regret and linear map into a convex upper bound which we can minimize efﬁciently. [sent-91, score-0.232]
</p><p>48 Step 2 (Linear Mapping) Key in our reasoning is the use of the Polya-Littlewood-Hardy inequality: For any two vectors a, b ∈ Rn their inner product is maximized by sorting a and b in the same order, that is a, b ≤ sort(a), sort(b) . [sent-94, score-0.065]
</p><p>49 This allows us to encode the permuation π = argsort(f ) in the following fashion: denote by c ∈ Rn a decreasing nonnegative sequence, then the function ψ(π, f ) := c, fπ  (3)  is linear in f and maximized with respect to π for argsort(f ). [sent-95, score-0.046]
</p><p>50 Since ci is decreasing by construction, the Polya-Littlewood-Hardy inequality applies. [sent-96, score-0.045]
</p><p>51 Step 3 (Convex Upper Bound) We adapt a result of [15] which describes how to ﬁnd convex upper bounds on nonconvex optimization problems. [sent-100, score-0.107]
</p><p>52 Moreover let π ∗ := argsort(−f ) be the ranking induced by f . [sent-102, score-0.231]
</p><p>53 Then the following loss function l(f, y) is convex in f and it satisﬁes l(f, y) ≥ ∆(y, π ∗ ). [sent-103, score-0.096]
</p><p>54 The argument of the maximization over the permutations π is a linear and thus convex function in f . [sent-105, score-0.101]
</p><p>55 Taking the maximum over a set of convex functions is convex itself, which proves the ﬁrst claim. [sent-106, score-0.122]
</p><p>56 3  4  Maximum Margin Matrix Factorization  Loss The reasoning in the previous section showed us how to replace the ranking score with a convex upper bound on a regret loss. [sent-112, score-0.438]
</p><p>57 The key idea in their reasoning is to introduce a regularizer on F via 1 Ω[F ] := min [tr M M + tr U U ] subject to U M = F. [sent-115, score-0.154]
</p><p>58 This approach learns the features of the items and the users. [sent-119, score-0.137]
</p><p>59 On large problems the storage requirements for the user matrix can be enormous and it is convenient to choose d = 10 or d = 100. [sent-121, score-0.12]
</p><p>60 Algorithm While (8) may not be jointly convex in M and U any more, it still is convex in M and U individually, whenever the other term is kept ﬁxed. [sent-122, score-0.122]
</p><p>61 We now discuss a general optimization method for solving regularized convex optimization problems. [sent-129, score-0.107]
</p><p>62 5  Optimization  Bundle Methods We discuss the optimization over the user matrix U ﬁrst, that is, consider the problem of minimizing λ R(U ) := L(U M, Ytrain ) + tr U U (9) 2 The regularizer tr U U is rather simple to compute and minimize. [sent-131, score-0.366]
</p><p>63 4  » In this case we optimize over  A F  F B  –  0 where Ω[F ] is replaced by 1 [tr A + tr B]. [sent-135, score-0.128]
</p><p>64 2  4  Algorithm 1 Bundle Method( ) Initialize t = 0, U0 = 0, b0 = 0 and H = ∞ repeat Find minimizer Ut and value L of the optimization problem minimize max tr Uj M + bj + U  0≤j≤t  λ tr U U. [sent-136, score-0.266]
</p><p>65 Subsequently, we minimize this piecewise linear lower bound in combination with λ tr U U to obtain a new location where to compute our next 2 Taylor approximation and iterate until convergence is achieved. [sent-138, score-0.152]
</p><p>66 After solving the optimization problem in U we switch to optimizing over the item matrix M . [sent-143, score-0.142]
</p><p>67 Computing the Loss So far we simply used the loss l(f, y) of (4) to deﬁne a convex loss without any concern to its computability. [sent-146, score-0.131]
</p><p>68 ¯ Here we denote by π the maximizer of of the loss and cπ−1 denotes the application of the inverse ¯ ¯ permutation π −1 to the vector c. [sent-154, score-0.068]
</p><p>69 ¯ 5  6  Experiments  We evaluated C O F I R ANK with the NDCG loss just deﬁned (denoted by C O F I R ANK -NDCG) as well as with loss functions which optimize ordinal regression (C O F I R ANK -Ordinal) and regression (C O F I R ANK -Regression). [sent-155, score-0.244]
</p><p>70 C O F I R ANK -Ordinal applies the algorithm described above to preference ranking by optimizing the preference ranking loss. [sent-156, score-0.534]
</p><p>71 Similarly, C O F I R ANK -Regression optimizes for regression using the root mean squared loss. [sent-157, score-0.053]
</p><p>72 Dataset EachMovie MovieLens Netﬂix  Users 61265 983 480189  Movies 1623 1682 17770  Ratings 2811717 100000 100480507  Table 1: Data set statistics  Weak generalization is evaluated by predicting the rank of unrated items for users known at training time. [sent-160, score-0.342]
</p><p>73 To do so, we randomly select N = 10, 20, 50 ratings for each user for training and and evaluate on the remaining ratings. [sent-161, score-0.224]
</p><p>74 Users with less then 20, 30, 60 rated movies where removed to ensure that the we could evaluate on at least 10 movies per user We compare C O F I R ANK -NDCG, C O F I R ANK -Ordinal, C O F I R ANK -Regression and MMMF [10]. [sent-162, score-0.253]
</p><p>75 All C O F I R ANK experiments and those of MMMF on MovieLens were repeated ten times. [sent-171, score-0.047]
</p><p>76 However, we cannot compare to any of the other methods on that data set as to the best of our knowledge, C O F I R ANK is the ﬁrst collaborative ranking algorithm to be applied to this data set, supposedly because of its large size. [sent-175, score-0.372]
</p><p>77 Strong generalization is evaluated on users that were not present at training time. [sent-176, score-0.151]
</p><p>78 We follow the procedure described in [17]: Movies with less than 50 ratings are discarded. [sent-177, score-0.137]
</p><p>79 The 100 users with the most rated movies are selected as the test set and the methods are trained on the remaining users. [sent-178, score-0.223]
</p><p>80 In evaluation, 10, 20 or 50 ratings from those of the 100 test users are selected. [sent-179, score-0.261]
</p><p>81 For those ratings, the user training procedure is applied to optimize U . [sent-180, score-0.125]
</p><p>82 The remaining ratings are tested using the same procedure as for the weak Method C O F I R ANK -NDCG C O F I R ANK -Ordinal C O F I R ANK -Regression  N=10 0. [sent-182, score-0.166]
</p><p>83 6287  EachMovie  Table 2: Results for the weak generalization setting experiments. [sent-228, score-0.056]
</p><p>84 We report the NDCG@10 accuracy for various numbers of training ratings used per user. [sent-229, score-0.137]
</p><p>85 For most results we report the mean over ten runs and the standard deviation. [sent-230, score-0.047]
</p><p>86 0190  Table 3: The NGDC@10 accuracy over ten runs and the standard deviation for the strong generalization evaluation. [sent-305, score-0.091]
</p><p>87 We compare C O F I R ANK -NDCG to Gaussian Process Ordinal Regression (GPOR) [3] Gaussian Process Regression (GPR) and the collaborative extensions (CPR, CGPOR) [17]. [sent-308, score-0.141]
</p><p>88 MMMF and C O F I R ANK only rely on the rating matrix. [sent-313, score-0.142]
</p><p>89 In the weak generalization experiments on the MovieLens data, C O F I R ANK performs better for N = 20 but is marginally outperformed by MMMF for the N = 10 and N = 50 cases. [sent-314, score-0.056]
</p><p>90 7  Discussion and Summary  C O F I R ANK is a novel approach to collaborative ﬁltering which solves the ranking problem faced by webshops directly. [sent-316, score-0.424]
</p><p>91 It can do so faster and at a higher accuracy than approaches which learn a rating to produce a ranking. [sent-317, score-0.142]
</p><p>92 C O F I R ANK is adaptable to different loss functions such as NDCG, Regression and Ordinal Regression in a plug-and-play manner. [sent-318, score-0.065]
</p><p>93 Additionally, C O F I R ANK is well suited for privacy concerned applications, as the optimization itself does not need ratings from the users, but only gradients. [sent-319, score-0.16]
</p><p>94 Our results, which we obtained without parameters tuning, are on par or outperform several of the most successful approaches to collaborative ﬁltering like MMMF, even when they are used with tuned parameters. [sent-320, score-0.141]
</p><p>95 For example, training on EachMovie with N = 10 can be done in less than ten minutes and uses less than 80M B of memory on a laptop. [sent-323, score-0.047]
</p><p>96 72 after the ﬁrst iteration, which also took less than ten minutes. [sent-325, score-0.047]
</p><p>97 However, C O F I R ANK is more than ten times faster than MMMF while using far less memory. [sent-328, score-0.047]
</p><p>98 Even the current implementation allows us to report the ﬁrst results on the Netﬂix data set for direct ranking optimization. [sent-330, score-0.231]
</p><p>99 A scalable modular convex solver for regularized risk minimization. [sent-435, score-0.061]
</p><p>100 Large margin methods for structured and interdependent output variables. [sent-442, score-0.086]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ank', 0.716), ('ranking', 0.231), ('ndcg', 0.228), ('mmmf', 0.222), ('ytrain', 0.157), ('dcg', 0.143), ('rating', 0.142), ('collaborative', 0.141), ('items', 0.137), ('ratings', 0.137), ('users', 0.124), ('movielens', 0.107), ('argsort', 0.105), ('tr', 0.09), ('user', 0.087), ('eachmovie', 0.086), ('ix', 0.083), ('ordinal', 0.078), ('net', 0.071), ('movies', 0.067), ('bundle', 0.065), ('item', 0.064), ('convex', 0.061), ('margin', 0.058), ('cgpor', 0.052), ('gpor', 0.052), ('gpr', 0.052), ('webshops', 0.052), ('ut', 0.048), ('ten', 0.047), ('factorization', 0.046), ('trec', 0.046), ('regularizer', 0.043), ('regret', 0.043), ('ltering', 0.042), ('score', 0.04), ('permutations', 0.04), ('suggestion', 0.039), ('optimize', 0.038), ('loss', 0.035), ('cgpr', 0.035), ('markus', 0.035), ('weimer', 0.035), ('ytest', 0.035), ('scores', 0.034), ('srebro', 0.033), ('matrix', 0.033), ('permutation', 0.033), ('rated', 0.032), ('retrieval', 0.031), ('adaptable', 0.03), ('hungarian', 0.03), ('sorts', 0.03), ('unrated', 0.03), ('gradients', 0.029), ('regression', 0.029), ('weak', 0.029), ('structured', 0.028), ('generalization', 0.027), ('editors', 0.027), ('taylor', 0.027), ('ranked', 0.025), ('decreasing', 0.025), ('minimize', 0.025), ('preference', 0.025), ('conversion', 0.024), ('truncation', 0.024), ('optimizes', 0.024), ('rank', 0.024), ('sorting', 0.023), ('customer', 0.023), ('tu', 0.023), ('optimization', 0.023), ('upper', 0.023), ('rennie', 0.022), ('hofmann', 0.022), ('optimizing', 0.022), ('smola', 0.022), ('reasoning', 0.021), ('recommendations', 0.021), ('saul', 0.021), ('maximized', 0.021), ('additionally', 0.02), ('repeat', 0.02), ('le', 0.02), ('ci', 0.02), ('maximizing', 0.019), ('nontrivial', 0.019), ('mt', 0.019), ('goals', 0.019), ('bound', 0.019), ('sort', 0.018), ('assignment', 0.018), ('lkopf', 0.018), ('stanford', 0.018), ('minimizer', 0.018), ('piecewise', 0.018), ('gained', 0.018), ('rn', 0.018), ('strong', 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="41-tfidf-1" href="./nips-2007-COFI_RANK_-_Maximum_Margin_Matrix_Factorization_for_Collaborative_Ranking.html">41 nips-2007-COFI RANK - Maximum Margin Matrix Factorization for Collaborative Ranking</a></p>
<p>Author: Markus Weimer, Alexandros Karatzoglou, Quoc V. Le, Alex J. Smola</p><p>Abstract: In this paper, we consider collaborative ﬁltering as a ranking problem. We present a method which uses Maximum Margin Matrix Factorization and optimizes ranking instead of rating. We employ structured output prediction to optimize directly for ranking scores. Experimental results show that our method gives very good ranking scores and scales well on collaborative ﬁltering tasks. 1</p><p>2 0.26395085 <a title="41-tfidf-2" href="./nips-2007-McRank%3A_Learning_to_Rank_Using_Multiple_Classification_and_Gradient_Boosting.html">126 nips-2007-McRank: Learning to Rank Using Multiple Classification and Gradient Boosting</a></p>
<p>Author: Ping Li, Qiang Wu, Christopher J. Burges</p><p>Abstract: We cast the ranking problem as (1) multiple classiﬁcation (“Mc”) (2) multiple ordinal classiﬁcation, which lead to computationally tractable learning algorithms for relevance ranking in Web search. We consider the DCG criterion (discounted cumulative gain), a standard quality measure in information retrieval. Our approach is motivated by the fact that perfect classiﬁcations result in perfect DCG scores and the DCG errors are bounded by classiﬁcation errors. We propose using the Expected Relevance to convert class probabilities into ranking scores. The class probabilities are learned using a gradient boosting tree algorithm. Evaluations on large-scale datasets show that our approach can improve LambdaRank [5] and the regressions-based ranker [6], in terms of the (normalized) DCG scores. An efﬁcient implementation of the boosting tree algorithm is also presented.</p><p>3 0.12579961 <a title="41-tfidf-3" href="./nips-2007-Evaluating_Search_Engines_by_Modeling_the_Relationship_Between_Relevance_and_Clicks.html">83 nips-2007-Evaluating Search Engines by Modeling the Relationship Between Relevance and Clicks</a></p>
<p>Author: Ben Carterette, Rosie Jones</p><p>Abstract: We propose a model that leverages the millions of clicks received by web search engines to predict document relevance. This allows the comparison of ranking functions when clicks are available but complete relevance judgments are not. After an initial training phase using a set of relevance judgments paired with click data, we show that our model can predict the relevance score of documents that have not been judged. These predictions can be used to evaluate the performance of a search engine, using our novel formalization of the conﬁdence of the standard evaluation metric discounted cumulative gain (DCG), so comparisons can be made across time and datasets. This contrasts with previous methods which can provide only pair-wise relevance judgments between results shown for the same query. When no relevance judgments are available, we can identify the better of two ranked lists up to 82% of the time, and with only two relevance judgments for each query, we can identify the better ranking up to 94% of the time. While our experiments are on sponsored search results, which is the ﬁnancial backbone of web search, our method is general enough to be applicable to algorithmic web search results as well. Furthermore, we give an algorithm to guide the selection of additional documents to judge to improve conﬁdence. 1</p><p>4 0.12127723 <a title="41-tfidf-4" href="./nips-2007-Non-parametric_Modeling_of_Partially_Ranked_Data.html">142 nips-2007-Non-parametric Modeling of Partially Ranked Data</a></p>
<p>Author: Guy Lebanon, Yi Mao</p><p>Abstract: Statistical models on full and partial rankings of n items are often of limited practical use for large n due to computational consideration. We explore the use of non-parametric models for partially ranked data and derive efﬁcient procedures for their use for large n. The derivations are largely possible through combinatorial and algebraic manipulations based on the lattice of partial rankings. In particular, we demonstrate for the ﬁrst time a non-parametric coherent and consistent model capable of efﬁciently aggregating partially ranked data of different types. 1</p><p>5 0.11425555 <a title="41-tfidf-5" href="./nips-2007-A_General_Boosting_Method_and_its_Application_to_Learning_Ranking_Functions_for_Web_Search.html">6 nips-2007-A General Boosting Method and its Application to Learning Ranking Functions for Web Search</a></p>
<p>Author: Zhaohui Zheng, Hongyuan Zha, Tong Zhang, Olivier Chapelle, Keke Chen, Gordon Sun</p><p>Abstract: We present a general boosting method extending functional gradient boosting to optimize complex loss functions that are encountered in many machine learning problems. Our approach is based on optimization of quadratic upper bounds of the loss functions which allows us to present a rigorous convergence analysis of the algorithm. More importantly, this general framework enables us to use a standard regression base learner such as single regression tree for £tting any loss function. We illustrate an application of the proposed method in learning ranking functions for Web search by combining both preference data and labeled data for training. We present experimental results for Web search using data from a commercial search engine that show signi£cant improvements of our proposed methods over some existing methods. 1</p><p>6 0.10933597 <a title="41-tfidf-6" href="./nips-2007-Predictive_Matrix-Variate_t_Models.html">156 nips-2007-Predictive Matrix-Variate t Models</a></p>
<p>7 0.10715201 <a title="41-tfidf-7" href="./nips-2007-Gaussian_Process_Models_for_Link_Analysis_and_Transfer_Learning.html">94 nips-2007-Gaussian Process Models for Link Analysis and Transfer Learning</a></p>
<p>8 0.10404777 <a title="41-tfidf-8" href="./nips-2007-Probabilistic_Matrix_Factorization.html">158 nips-2007-Probabilistic Matrix Factorization</a></p>
<p>9 0.077889055 <a title="41-tfidf-9" href="./nips-2007-Boosting_the_Area_under_the_ROC_Curve.html">39 nips-2007-Boosting the Area under the ROC Curve</a></p>
<p>10 0.077793784 <a title="41-tfidf-10" href="./nips-2007-Unsupervised_Feature_Selection_for_Accurate_Recommendation_of_High-Dimensional_Image_Data.html">211 nips-2007-Unsupervised Feature Selection for Accurate Recommendation of High-Dimensional Image Data</a></p>
<p>11 0.063350514 <a title="41-tfidf-11" href="./nips-2007-Retrieved_context_and_the_discovery_of_semantic_structure.html">169 nips-2007-Retrieved context and the discovery of semantic structure</a></p>
<p>12 0.062814347 <a title="41-tfidf-12" href="./nips-2007-Active_Preference_Learning_with_Discrete_Choice_Data.html">19 nips-2007-Active Preference Learning with Discrete Choice Data</a></p>
<p>13 0.057936199 <a title="41-tfidf-13" href="./nips-2007-Infinite_State_Bayes-Nets_for_Structured_Domains.html">105 nips-2007-Infinite State Bayes-Nets for Structured Domains</a></p>
<p>14 0.056702729 <a title="41-tfidf-14" href="./nips-2007-On_Ranking_in_Survival_Analysis%3A_Bounds_on_the_Concordance_Index.html">144 nips-2007-On Ranking in Survival Analysis: Bounds on the Concordance Index</a></p>
<p>15 0.055077244 <a title="41-tfidf-15" href="./nips-2007-Multi-Task_Learning_via_Conic_Programming.html">134 nips-2007-Multi-Task Learning via Conic Programming</a></p>
<p>16 0.054854725 <a title="41-tfidf-16" href="./nips-2007-Bundle_Methods_for_Machine_Learning.html">40 nips-2007-Bundle Methods for Machine Learning</a></p>
<p>17 0.050428353 <a title="41-tfidf-17" href="./nips-2007-Convex_Learning_with_Invariances.html">62 nips-2007-Convex Learning with Invariances</a></p>
<p>18 0.048225209 <a title="41-tfidf-18" href="./nips-2007-A_Spectral_Regularization_Framework_for_Multi-Task_Structure_Learning.html">12 nips-2007-A Spectral Regularization Framework for Multi-Task Structure Learning</a></p>
<p>19 0.044684406 <a title="41-tfidf-19" href="./nips-2007-A_Risk_Minimization_Principle_for_a_Class_of_Parzen_Estimators.html">11 nips-2007-A Risk Minimization Principle for a Class of Parzen Estimators</a></p>
<p>20 0.042214047 <a title="41-tfidf-20" href="./nips-2007-Computational_Equivalence_of_Fixed_Points_and_No_Regret_Algorithms%2C_and_Convergence_to_Equilibria.html">54 nips-2007-Computational Equivalence of Fixed Points and No Regret Algorithms, and Convergence to Equilibria</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2007_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.141), (1, 0.009), (2, -0.09), (3, 0.056), (4, 0.087), (5, 0.048), (6, 0.107), (7, -0.127), (8, 0.064), (9, -0.09), (10, -0.092), (11, -0.0), (12, 0.391), (13, 0.165), (14, -0.029), (15, -0.057), (16, -0.08), (17, -0.035), (18, -0.02), (19, 0.046), (20, -0.111), (21, -0.047), (22, -0.01), (23, -0.054), (24, -0.077), (25, 0.071), (26, -0.037), (27, -0.06), (28, 0.081), (29, 0.01), (30, 0.023), (31, -0.024), (32, 0.004), (33, 0.011), (34, 0.026), (35, 0.013), (36, 0.07), (37, 0.025), (38, 0.006), (39, -0.037), (40, -0.049), (41, -0.012), (42, -0.012), (43, 0.099), (44, 0.005), (45, -0.129), (46, 0.026), (47, -0.06), (48, 0.038), (49, -0.06)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94282913 <a title="41-lsi-1" href="./nips-2007-COFI_RANK_-_Maximum_Margin_Matrix_Factorization_for_Collaborative_Ranking.html">41 nips-2007-COFI RANK - Maximum Margin Matrix Factorization for Collaborative Ranking</a></p>
<p>Author: Markus Weimer, Alexandros Karatzoglou, Quoc V. Le, Alex J. Smola</p><p>Abstract: In this paper, we consider collaborative ﬁltering as a ranking problem. We present a method which uses Maximum Margin Matrix Factorization and optimizes ranking instead of rating. We employ structured output prediction to optimize directly for ranking scores. Experimental results show that our method gives very good ranking scores and scales well on collaborative ﬁltering tasks. 1</p><p>2 0.69035983 <a title="41-lsi-2" href="./nips-2007-Evaluating_Search_Engines_by_Modeling_the_Relationship_Between_Relevance_and_Clicks.html">83 nips-2007-Evaluating Search Engines by Modeling the Relationship Between Relevance and Clicks</a></p>
<p>Author: Ben Carterette, Rosie Jones</p><p>Abstract: We propose a model that leverages the millions of clicks received by web search engines to predict document relevance. This allows the comparison of ranking functions when clicks are available but complete relevance judgments are not. After an initial training phase using a set of relevance judgments paired with click data, we show that our model can predict the relevance score of documents that have not been judged. These predictions can be used to evaluate the performance of a search engine, using our novel formalization of the conﬁdence of the standard evaluation metric discounted cumulative gain (DCG), so comparisons can be made across time and datasets. This contrasts with previous methods which can provide only pair-wise relevance judgments between results shown for the same query. When no relevance judgments are available, we can identify the better of two ranked lists up to 82% of the time, and with only two relevance judgments for each query, we can identify the better ranking up to 94% of the time. While our experiments are on sponsored search results, which is the ﬁnancial backbone of web search, our method is general enough to be applicable to algorithmic web search results as well. Furthermore, we give an algorithm to guide the selection of additional documents to judge to improve conﬁdence. 1</p><p>3 0.63744783 <a title="41-lsi-3" href="./nips-2007-McRank%3A_Learning_to_Rank_Using_Multiple_Classification_and_Gradient_Boosting.html">126 nips-2007-McRank: Learning to Rank Using Multiple Classification and Gradient Boosting</a></p>
<p>Author: Ping Li, Qiang Wu, Christopher J. Burges</p><p>Abstract: We cast the ranking problem as (1) multiple classiﬁcation (“Mc”) (2) multiple ordinal classiﬁcation, which lead to computationally tractable learning algorithms for relevance ranking in Web search. We consider the DCG criterion (discounted cumulative gain), a standard quality measure in information retrieval. Our approach is motivated by the fact that perfect classiﬁcations result in perfect DCG scores and the DCG errors are bounded by classiﬁcation errors. We propose using the Expected Relevance to convert class probabilities into ranking scores. The class probabilities are learned using a gradient boosting tree algorithm. Evaluations on large-scale datasets show that our approach can improve LambdaRank [5] and the regressions-based ranker [6], in terms of the (normalized) DCG scores. An efﬁcient implementation of the boosting tree algorithm is also presented.</p><p>4 0.59895772 <a title="41-lsi-4" href="./nips-2007-A_General_Boosting_Method_and_its_Application_to_Learning_Ranking_Functions_for_Web_Search.html">6 nips-2007-A General Boosting Method and its Application to Learning Ranking Functions for Web Search</a></p>
<p>Author: Zhaohui Zheng, Hongyuan Zha, Tong Zhang, Olivier Chapelle, Keke Chen, Gordon Sun</p><p>Abstract: We present a general boosting method extending functional gradient boosting to optimize complex loss functions that are encountered in many machine learning problems. Our approach is based on optimization of quadratic upper bounds of the loss functions which allows us to present a rigorous convergence analysis of the algorithm. More importantly, this general framework enables us to use a standard regression base learner such as single regression tree for £tting any loss function. We illustrate an application of the proposed method in learning ranking functions for Web search by combining both preference data and labeled data for training. We present experimental results for Web search using data from a commercial search engine that show signi£cant improvements of our proposed methods over some existing methods. 1</p><p>5 0.56105816 <a title="41-lsi-5" href="./nips-2007-Probabilistic_Matrix_Factorization.html">158 nips-2007-Probabilistic Matrix Factorization</a></p>
<p>Author: Andriy Mnih, Ruslan Salakhutdinov</p><p>Abstract: Many existing approaches to collaborative ﬁltering can neither handle very large datasets nor easily deal with users who have very few ratings. In this paper we present the Probabilistic Matrix Factorization (PMF) model which scales linearly with the number of observations and, more importantly, performs well on the large, sparse, and very imbalanced Netﬂix dataset. We further extend the PMF model to include an adaptive prior on the model parameters and show how the model capacity can be controlled automatically. Finally, we introduce a constrained version of the PMF model that is based on the assumption that users who have rated similar sets of movies are likely to have similar preferences. The resulting model is able to generalize considerably better for users with very few ratings. When the predictions of multiple PMF models are linearly combined with the predictions of Restricted Boltzmann Machines models, we achieve an error rate of 0.8861, that is nearly 7% better than the score of Netﬂix’s own system.</p><p>6 0.54163766 <a title="41-lsi-6" href="./nips-2007-Non-parametric_Modeling_of_Partially_Ranked_Data.html">142 nips-2007-Non-parametric Modeling of Partially Ranked Data</a></p>
<p>7 0.45670894 <a title="41-lsi-7" href="./nips-2007-Predictive_Matrix-Variate_t_Models.html">156 nips-2007-Predictive Matrix-Variate t Models</a></p>
<p>8 0.44147184 <a title="41-lsi-8" href="./nips-2007-Active_Preference_Learning_with_Discrete_Choice_Data.html">19 nips-2007-Active Preference Learning with Discrete Choice Data</a></p>
<p>9 0.43174055 <a title="41-lsi-9" href="./nips-2007-On_Ranking_in_Survival_Analysis%3A_Bounds_on_the_Concordance_Index.html">144 nips-2007-On Ranking in Survival Analysis: Bounds on the Concordance Index</a></p>
<p>10 0.39614692 <a title="41-lsi-10" href="./nips-2007-Unsupervised_Feature_Selection_for_Accurate_Recommendation_of_High-Dimensional_Image_Data.html">211 nips-2007-Unsupervised Feature Selection for Accurate Recommendation of High-Dimensional Image Data</a></p>
<p>11 0.33874586 <a title="41-lsi-11" href="./nips-2007-Boosting_the_Area_under_the_ROC_Curve.html">39 nips-2007-Boosting the Area under the ROC Curve</a></p>
<p>12 0.31103149 <a title="41-lsi-12" href="./nips-2007-A_Spectral_Regularization_Framework_for_Multi-Task_Structure_Learning.html">12 nips-2007-A Spectral Regularization Framework for Multi-Task Structure Learning</a></p>
<p>13 0.29827097 <a title="41-lsi-13" href="./nips-2007-Bundle_Methods_for_Machine_Learning.html">40 nips-2007-Bundle Methods for Machine Learning</a></p>
<p>14 0.29053265 <a title="41-lsi-14" href="./nips-2007-Modeling_homophily_and_stochastic_equivalence_in_symmetric_relational_data.html">131 nips-2007-Modeling homophily and stochastic equivalence in symmetric relational data</a></p>
<p>15 0.25659263 <a title="41-lsi-15" href="./nips-2007-Heterogeneous_Component_Analysis.html">96 nips-2007-Heterogeneous Component Analysis</a></p>
<p>16 0.25437325 <a title="41-lsi-16" href="./nips-2007-Progressive_mixture_rules_are_deviation_suboptimal.html">159 nips-2007-Progressive mixture rules are deviation suboptimal</a></p>
<p>17 0.2497682 <a title="41-lsi-17" href="./nips-2007-Augmented_Functional_Time_Series_Representation_and_Forecasting_with_Gaussian_Processes.html">28 nips-2007-Augmented Functional Time Series Representation and Forecasting with Gaussian Processes</a></p>
<p>18 0.2346884 <a title="41-lsi-18" href="./nips-2007-Convex_Learning_with_Invariances.html">62 nips-2007-Convex Learning with Invariances</a></p>
<p>19 0.22837143 <a title="41-lsi-19" href="./nips-2007-Hidden_Common_Cause_Relations_in_Relational_Learning.html">97 nips-2007-Hidden Common Cause Relations in Relational Learning</a></p>
<p>20 0.22754991 <a title="41-lsi-20" href="./nips-2007-Gaussian_Process_Models_for_Link_Analysis_and_Transfer_Learning.html">94 nips-2007-Gaussian Process Models for Link Analysis and Transfer Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2007_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.037), (13, 0.062), (16, 0.029), (21, 0.068), (31, 0.018), (34, 0.085), (35, 0.039), (46, 0.012), (47, 0.078), (49, 0.011), (54, 0.01), (83, 0.097), (85, 0.033), (87, 0.014), (88, 0.269), (90, 0.047)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.73597908 <a title="41-lda-1" href="./nips-2007-Regularized_Boost_for_Semi-Supervised_Learning.html">166 nips-2007-Regularized Boost for Semi-Supervised Learning</a></p>
<p>Author: Ke Chen, Shihai Wang</p><p>Abstract: Semi-supervised inductive learning concerns how to learn a decision rule from a data set containing both labeled and unlabeled data. Several boosting algorithms have been extended to semi-supervised learning with various strategies. To our knowledge, however, none of them takes local smoothness constraints among data into account during ensemble learning. In this paper, we introduce a local smoothness regularizer to semi-supervised boosting algorithms based on the universal optimization framework of margin cost functionals. Our regularizer is applicable to existing semi-supervised boosting algorithms to improve their generalization and speed up their training. Comparative results on synthetic, benchmark and real world tasks demonstrate the effectiveness of our local smoothness regularizer. We discuss relevant issues and relate our regularizer to previous work. 1</p><p>same-paper 2 0.73419225 <a title="41-lda-2" href="./nips-2007-COFI_RANK_-_Maximum_Margin_Matrix_Factorization_for_Collaborative_Ranking.html">41 nips-2007-COFI RANK - Maximum Margin Matrix Factorization for Collaborative Ranking</a></p>
<p>Author: Markus Weimer, Alexandros Karatzoglou, Quoc V. Le, Alex J. Smola</p><p>Abstract: In this paper, we consider collaborative ﬁltering as a ranking problem. We present a method which uses Maximum Margin Matrix Factorization and optimizes ranking instead of rating. We employ structured output prediction to optimize directly for ranking scores. Experimental results show that our method gives very good ranking scores and scales well on collaborative ﬁltering tasks. 1</p><p>3 0.64374638 <a title="41-lda-3" href="./nips-2007-What_makes_some_POMDP_problems_easy_to_approximate%3F.html">215 nips-2007-What makes some POMDP problems easy to approximate?</a></p>
<p>Author: Wee S. Lee, Nan Rong, Daniel J. Hsu</p><p>Abstract: Point-based algorithms have been surprisingly successful in computing approximately optimal solutions for partially observable Markov decision processes (POMDPs) in high dimensional belief spaces. In this work, we seek to understand the belief-space properties that allow some POMDP problems to be approximated efﬁciently and thus help to explain the point-based algorithms’ success often observed in the experiments. We show that an approximately optimal POMDP solution can be computed in time polynomial in the covering number of a reachable belief space, which is the subset of the belief space reachable from a given belief point. We also show that under the weaker condition of having a small covering number for an optimal reachable space, which is the subset of the belief space reachable under an optimal policy, computing an approximately optimal solution is NP-hard. However, given a suitable set of points that “cover” an optimal reachable space well, an approximate solution can be computed in polynomial time. The covering number highlights several interesting properties that reduce the complexity of POMDP planning in practice, e.g., fully observed state variables, beliefs with sparse support, smooth beliefs, and circulant state-transition matrices. 1</p><p>4 0.55003053 <a title="41-lda-4" href="./nips-2007-A_neural_network_implementing_optimal_state_estimation_based_on_dynamic_spike_train_decoding.html">17 nips-2007-A neural network implementing optimal state estimation based on dynamic spike train decoding</a></p>
<p>Author: Omer Bobrowski, Ron Meir, Shy Shoham, Yonina Eldar</p><p>Abstract: It is becoming increasingly evident that organisms acting in uncertain dynamical environments often employ exact or approximate Bayesian statistical calculations in order to continuously estimate the environmental state, integrate information from multiple sensory modalities, form predictions and choose actions. What is less clear is how these putative computations are implemented by cortical neural networks. An additional level of complexity is introduced because these networks observe the world through spike trains received from primary sensory afferents, rather than directly. A recent line of research has described mechanisms by which such computations can be implemented using a network of neurons whose activity directly represents a probability distribution across the possible “world states”. Much of this work, however, uses various approximations, which severely restrict the domain of applicability of these implementations. Here we make use of rigorous mathematical results from the theory of continuous time point process ﬁltering, and show how optimal real-time state estimation and prediction may be implemented in a general setting using linear neural networks. We demonstrate the applicability of the approach with several examples, and relate the required network properties to the statistical nature of the environment, thereby quantifying the compatibility of a given network with its environment. 1</p><p>5 0.54991066 <a title="41-lda-5" href="./nips-2007-McRank%3A_Learning_to_Rank_Using_Multiple_Classification_and_Gradient_Boosting.html">126 nips-2007-McRank: Learning to Rank Using Multiple Classification and Gradient Boosting</a></p>
<p>Author: Ping Li, Qiang Wu, Christopher J. Burges</p><p>Abstract: We cast the ranking problem as (1) multiple classiﬁcation (“Mc”) (2) multiple ordinal classiﬁcation, which lead to computationally tractable learning algorithms for relevance ranking in Web search. We consider the DCG criterion (discounted cumulative gain), a standard quality measure in information retrieval. Our approach is motivated by the fact that perfect classiﬁcations result in perfect DCG scores and the DCG errors are bounded by classiﬁcation errors. We propose using the Expected Relevance to convert class probabilities into ranking scores. The class probabilities are learned using a gradient boosting tree algorithm. Evaluations on large-scale datasets show that our approach can improve LambdaRank [5] and the regressions-based ranker [6], in terms of the (normalized) DCG scores. An efﬁcient implementation of the boosting tree algorithm is also presented.</p><p>6 0.54485637 <a title="41-lda-6" href="./nips-2007-Probabilistic_Matrix_Factorization.html">158 nips-2007-Probabilistic Matrix Factorization</a></p>
<p>7 0.53646439 <a title="41-lda-7" href="./nips-2007-Catching_Up_Faster_in_Bayesian_Model_Selection_and_Model_Averaging.html">44 nips-2007-Catching Up Faster in Bayesian Model Selection and Model Averaging</a></p>
<p>8 0.53351492 <a title="41-lda-8" href="./nips-2007-Gaussian_Process_Models_for_Link_Analysis_and_Transfer_Learning.html">94 nips-2007-Gaussian Process Models for Link Analysis and Transfer Learning</a></p>
<p>9 0.52731532 <a title="41-lda-9" href="./nips-2007-Predictive_Matrix-Variate_t_Models.html">156 nips-2007-Predictive Matrix-Variate t Models</a></p>
<p>10 0.52632827 <a title="41-lda-10" href="./nips-2007-Fast_and_Scalable_Training_of_Semi-Supervised_CRFs_with_Application_to_Activity_Recognition.html">88 nips-2007-Fast and Scalable Training of Semi-Supervised CRFs with Application to Activity Recognition</a></p>
<p>11 0.51870424 <a title="41-lda-11" href="./nips-2007-Convex_Relaxations_of_Latent_Variable_Training.html">63 nips-2007-Convex Relaxations of Latent Variable Training</a></p>
<p>12 0.51755071 <a title="41-lda-12" href="./nips-2007-Exponential_Family_Predictive_Representations_of_State.html">86 nips-2007-Exponential Family Predictive Representations of State</a></p>
<p>13 0.51362777 <a title="41-lda-13" href="./nips-2007-Near-Maximum_Entropy_Models_for_Binary_Neural_Representations_of_Natural_Images.html">138 nips-2007-Near-Maximum Entropy Models for Binary Neural Representations of Natural Images</a></p>
<p>14 0.51218373 <a title="41-lda-14" href="./nips-2007-Simplified_Rules_and_Theoretical_Analysis_for_Information_Bottleneck_Optimization_and_PCA_with_Spiking_Neurons.html">177 nips-2007-Simplified Rules and Theoretical Analysis for Information Bottleneck Optimization and PCA with Spiking Neurons</a></p>
<p>15 0.50953132 <a title="41-lda-15" href="./nips-2007-A_probabilistic_model_for_generating_realistic_lip_movements_from_speech.html">18 nips-2007-A probabilistic model for generating realistic lip movements from speech</a></p>
<p>16 0.5081377 <a title="41-lda-16" href="./nips-2007-Expectation_Maximization_and_Posterior_Constraints.html">84 nips-2007-Expectation Maximization and Posterior Constraints</a></p>
<p>17 0.50715023 <a title="41-lda-17" href="./nips-2007-Online_Linear_Regression_and_Its_Application_to_Model-Based_Reinforcement_Learning.html">148 nips-2007-Online Linear Regression and Its Application to Model-Based Reinforcement Learning</a></p>
<p>18 0.50669861 <a title="41-lda-18" href="./nips-2007-Evaluating_Search_Engines_by_Modeling_the_Relationship_Between_Relevance_and_Clicks.html">83 nips-2007-Evaluating Search Engines by Modeling the Relationship Between Relevance and Clicks</a></p>
<p>19 0.50668323 <a title="41-lda-19" href="./nips-2007-Message_Passing_for_Max-weight_Independent_Set.html">128 nips-2007-Message Passing for Max-weight Independent Set</a></p>
<p>20 0.50613183 <a title="41-lda-20" href="./nips-2007-Multi-Task_Learning_via_Conic_Programming.html">134 nips-2007-Multi-Task Learning via Conic Programming</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
