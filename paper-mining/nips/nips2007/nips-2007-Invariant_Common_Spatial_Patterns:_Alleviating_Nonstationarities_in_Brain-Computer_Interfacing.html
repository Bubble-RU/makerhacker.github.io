<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>106 nips-2007-Invariant Common Spatial Patterns: Alleviating Nonstationarities in Brain-Computer Interfacing</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-106" href="#">nips2007-106</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>106 nips-2007-Invariant Common Spatial Patterns: Alleviating Nonstationarities in Brain-Computer Interfacing</h1>
<br/><p>Source: <a title="nips-2007-106-pdf" href="http://papers.nips.cc/paper/3184-invariant-common-spatial-patterns-alleviating-nonstationarities-in-brain-computer-interfacing.pdf">pdf</a></p><p>Author: Benjamin Blankertz, Motoaki Kawanabe, Ryota Tomioka, Friederike Hohlefeld, Klaus-Robert Müller, Vadim V. Nikulin</p><p>Abstract: Brain-Computer Interfaces can suffer from a large variance of the subject conditions within and across sessions. For example vigilance ﬂuctuations in the individual, variable task involvement, workload etc. alter the characteristics of EEG signals and thus challenge a stable BCI operation. In the present work we aim to deﬁne features based on a variant of the common spatial patterns (CSP) algorithm that are constructed invariant with respect to such nonstationarities. We enforce invariance properties by adding terms to the denominator of a Rayleigh coefﬁcient representation of CSP such as disturbance covariance matrices from ﬂuctuations in visual processing. In this manner physiological prior knowledge can be used to shape the classiﬁcation engine for BCI. As a proof of concept we present a BCI classiﬁer that is robust to changes in the level of parietal α -activity. In other words, the EEG decoding still works when there are lapses in vigilance.</p><p>Reference: <a title="nips-2007-106-reference" href="../nips2007_reference/nips-2007-Invariant_Common_Spatial_Patterns%3A_Alleviating_Nonstationarities_in_Brain-Computer_Interfacing_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 de  Abstract Brain-Computer Interfaces can suffer from a large variance of the subject conditions within and across sessions. [sent-7, score-0.078]
</p><p>2 alter the characteristics of EEG signals and thus challenge a stable BCI operation. [sent-9, score-0.076]
</p><p>3 In the present work we aim to deﬁne features based on a variant of the common spatial patterns (CSP) algorithm that are constructed invariant with respect to such nonstationarities. [sent-10, score-0.242]
</p><p>4 We enforce invariance properties by adding terms to the denominator of a Rayleigh coefﬁcient representation of CSP such as disturbance covariance matrices from ﬂuctuations in visual processing. [sent-11, score-0.212]
</p><p>5 As a proof of concept we present a BCI classiﬁer that is robust to changes in the level of parietal α -activity. [sent-13, score-0.077]
</p><p>6 1 Introduction Brain-Computer Interfaces (BCIs) translate the intent of a subject measured from brain signals directly into control commands, e. [sent-15, score-0.306]
</p><p>7 The classical approach to brain-computer interfacing is operant conditioning ([2, 7]) where a ﬁxed translation algorithm is used to generate a feedback signal from the electroencephalogram (EEG). [sent-18, score-0.179]
</p><p>8 Users are not equipped with a mental strategy they should use, rather they are instructed to watch a feedback signal and using the feedback to ﬁnd out ways to voluntarily control it. [sent-19, score-0.297]
</p><p>9 Recently machine learning techniques were applied to the BCI ﬁeld and allowed to decode the subject’s brain signals, placing the learning task on the machine side, i. [sent-22, score-0.122]
</p><p>10 a general translation algorithm is trained to infer the speciﬁc characteristics of the user’s brain signals [8, 9, 10, 11, 12, 13, 14]. [sent-24, score-0.198]
</p><p>11 This is done by a statistical analysis of a calibration measurement in which the subject performs well-deﬁned mental acts like imagined movements. [sent-25, score-0.28]
</p><p>12 Here, in principle no adaption of the user is required, but it is to be expected that users will adapt their behaviour during feedback operation. [sent-26, score-0.118]
</p><p>13 One of them is to make the system invariant to non task-related ﬂuctuations of the measured signals during feedback. [sent-30, score-0.173]
</p><p>14 These ﬂuctuations may be caused by changes in the subject’s brain processes, e. [sent-31, score-0.122]
</p><p>15 The calibration measurement that is used for training in machine learning techniques is recorded during 10-30 min, i. [sent-35, score-0.164]
</p><p>16 The present contribution focusses on invariant feature extraction for BCI. [sent-38, score-0.097]
</p><p>17 In particular we aim to enhance the invariance properties of the common spatial patterns (CSP, [15]) algorithm. [sent-39, score-0.217]
</p><p>18 CSP is the solution of a generalized eigenvalue problem and has as such a strong link to the maximization of a Rayleigh coefﬁcient, similar to Fisher’s discriminant analysis. [sent-40, score-0.143]
</p><p>19 [16] in the context of kernel Fisher’s discriminant analysis contains the key idea that we will follow: noise and distracting signal aspects with respect to which we want to make our feature extractor invariant is added to the denominator of a Rayleigh coefﬁcient. [sent-42, score-0.176]
</p><p>20 We demonstrate how our invariant CSP (iCSP) technique can be used to make a BCI system invariant to changes in the power of the parietal α -rhythm (see Section 2) reﬂecting, e. [sent-44, score-0.303]
</p><p>21 We would like to stress that adaptation and invariant classiﬁcation are no mutually exclusive alternatives but rather complementary approaches when striving for the same goal: a BCI system that is invariant to undesired distortions and nonstationarities. [sent-50, score-0.194]
</p><p>22 Macroscopic brain activity during resting wakefulness contains distinct ‘idle’ rhythms located over various brain areas, e. [sent-52, score-0.39]
</p><p>23 the parietal α -rhythm (7-13 Hz) can be measured over the visual cortex [17] and the µ -rhythm can be measured over the pericentral sensorimotor cortices in the scalp EEG, usually with a frequency of about 8–14 Hz ([18]). [sent-54, score-0.239]
</p><p>24 The strength of the parietal α -rhythm reﬂects visual processing load as well as attention and fatigue resp. [sent-55, score-0.116]
</p><p>25 The moment-to-moment amplitude ﬂuctuations of these local rhythms reﬂect variable functional states of the underlying neuronal cortical networks and can be used for brain-computer interfacing. [sent-57, score-0.069]
</p><p>26 Speciﬁcally, the pericentral µ - and β rythms are diminished, or even almost completely blocked, by movements of the somatotopically corresponding body part, independent of their active, passive or reﬂexive origin. [sent-58, score-0.089]
</p><p>27 This attenuation of brain rhythms is termed event-related desynchronization (ERD) and the dual effect of enhanced brain rhythms is called event-related synchronization (ERS) (see [19]). [sent-60, score-0.412]
</p><p>28 Since a focal ERD can be observed over the motor and/or sensory cortex even when a subject is only imagining a movement or sensation in the speciﬁc limb, this feature can be used for BCI control: The discrimination of the imagination of movements of left hand vs. [sent-61, score-0.274]
</p><p>29 To this end, spatial ﬁltering is an indispensable technique; that is to take a linear combination of signals recorded over EEG channels and extract only the component that we are interested in. [sent-65, score-0.203]
</p><p>30 In particular the CSP algorithm that optimizes spatial ﬁlters with respect to discriminability is a good candidate for feature extraction. [sent-66, score-0.094]
</p><p>31 05  Figure 1: Topographies of r2 –values (multiplied by the sign of the difference) quantifying the difference in log band-power in the alpha band (8–12 Hz) between different recording sessions: Left: Difference between imag_move and imag_lett. [sent-70, score-0.25]
</p><p>32 Due to lower visual processing demands, alpha power in occipital areas is stronger in imag_lett. [sent-71, score-0.378]
</p><p>33 The latter has decreased alpha power in centro-parietal areas. [sent-73, score-0.249]
</p><p>34 The ultimate challenge will be on-line feedback with strong ﬂuctuations of task demands etc, a project envisioned for the near future. [sent-86, score-0.109]
</p><p>35 Brain activity was recorded from the scalp with multi-channel ampliﬁers using 55 EEG channels. [sent-88, score-0.165]
</p><p>36 5–6 seconds one of 3 different visual stimuli indicated for 3 seconds which mental task the subject should accomplish during that period. [sent-90, score-0.188]
</p><p>37 The investigated mental tasks were imagined movements of the left hand, the right hand, and the right foot. [sent-91, score-0.126]
</p><p>38 Since the movement of the object was independent from the indicated targets, target-uncorrelated eye movements are induced. [sent-93, score-0.055]
</p><p>39 Due to the different demands in visual processing, the background brain activity can be expected to differ substancially in those two types of recordings. [sent-94, score-0.27]
</p><p>40 A sham_feedback paradigm was designed in order to charaterize invariance properties needed for stable real-world BCI applications. [sent-98, score-0.072]
</p><p>41 In this measurement the subjects received a fake feedback sequence which was preprogrammed. [sent-99, score-0.167]
</p><p>42 The aim of this recording was to collect data during a large variety of mental states and actions that are not correlated with the BCI control states (motor imagery of hands and feet). [sent-100, score-0.175]
</p><p>43 Subjects were told that they could control the feedback in some way that they should ﬁnd out, e. [sent-101, score-0.107]
</p><p>44 They were instructed not to perform movements of hands, arms, legs and feet. [sent-104, score-0.055]
</p><p>45 The type of feedback was a standard 1D cursor control. [sent-105, score-0.118]
</p><p>46 The preprogrammed ‘feedback’ signal was constructed such that it was random in the beginning and then alternating periods of increasingly more hits and periods with chance level performance. [sent-109, score-0.042]
</p><p>47 A decreased alpha power in centro-parietal areas during sham_feedback can be observed. [sent-114, score-0.249]
</p><p>48 Note that this recording includes much more variations of background mental activity than the difference between imag_move and imag_lett. [sent-115, score-0.181]
</p><p>49 The CSP technique ([15]) allows to determine spatial ﬁlters that maximize the variance of signals of one condition and at the same time minimize the variance of signals of another condition. [sent-117, score-0.246]
</p><p>50 Since variance of band-pass ﬁltered signals is equal to bandpower, CSP ﬁlters are well suited to discriminate mental states that are characterized by ERD/ERS effects ([20]). [sent-118, score-0.147]
</p><p>51 As such it has been well used in BCI systems ([8, 14]) where CSP ﬁlters are calculated individually for each subject on the data of a calibration measurement. [sent-119, score-0.158]
</p><p>52 Technically the Common Spatial Pattern (CSP) [21] algorithm gives spatial ﬁlters based on a discriminative criterion. [sent-120, score-0.094]
</p><p>53 Let X1 and X2 be the (time × channel) data matrices of the band-pass ﬁltered 3  EEG signals (concatenated trials) under the two conditions (e. [sent-121, score-0.108]
</p><p>54 , right-hand or left-hand imagination, respectively2) and Σ1 and Σ2 be the corresponding estimates of the covariance matrices Σi = Xi Xi . [sent-123, score-0.067]
</p><p>55 We deﬁne the two matrices Sd and Sc as follows: Sd = Σ(1) − Σ(2)  : discriminative activity matrix,  Sc = Σ  : common activity matrix. [sent-124, score-0.186]
</p><p>56 (1)  +Σ  (2)  The CSP spatial ﬁlter v ∈ RC (C is the number of channels) can be obtained by extremizing the Rayleigh coefﬁcient: {max, min}v∈RC  v Sd v . [sent-125, score-0.094]
</p><p>57 v Sc v  (1)  This can be done by solving a generalized eigenvalue problem. [sent-126, score-0.106]
</p><p>58 (2)  The eigenvalue λ is bounded between −1 and 1; a large positive eigenvalue corresponds to a projection of the signal given by v that has large power in the ﬁrst condition but small in the second condition; the converse is true for a large negative eigenvalue. [sent-128, score-0.218]
</p><p>59 On the other hand, the projection of the activity that is common to two classes v Sc v should be minimized because it doesn’t contribute to the discriminability. [sent-132, score-0.077]
</p><p>60 The norm is deﬁned by the common activity matrix Sc . [sent-137, score-0.077]
</p><p>61 Moreover we denote by V the matrix we obtain by putting the C generalized eigenvectors into columns, namely V = {v j }C ∈ j=1 RC×C and call patterns the row vectors of the inverse A = V −1 . [sent-144, score-0.085]
</p><p>62 Note that a ﬁlter v j ∈ RC has its corresponding pattern a j ∈ RC ; a ﬁlter v j extracts only the activity spanned by a j and cancels out all other activities spanned by ai (i = j); therefore a pattern a j tells what the ﬁlter v j is extracting out (see Fig. [sent-145, score-0.077]
</p><p>63 The selection of patterns is typically based on eigenvalues. [sent-149, score-0.051]
</p><p>64 But when a large amount of calibration data is not available it is advisable to use a more reﬁned technique to select the patterns or to manually choose them by visual inspection. [sent-150, score-0.17]
</p><p>65 The CSP spatial ﬁlters extracted as above are optimized for the calibration measurement. [sent-158, score-0.174]
</p><p>66 However, in online operation of the BCI system different non task-related modulations of brain signals may occur which are not suppressed by the CSP ﬁlters. [sent-159, score-0.249]
</p><p>67 The reason may be that these modulations have not been recorded in the calibration measurement or that they have been so infrequent that they are not consistently reﬂected in the statistics (e. [sent-160, score-0.215]
</p><p>68 The proposed iCSP method minimizes the inﬂuence of modulations that can be characterized in advance by a covariance matrix. [sent-163, score-0.086]
</p><p>69 In this manner we can code neurophysiological prior knowledge 2 We use the term covariance for zero-delay second order statistics between channels and not for the statistical variability. [sent-164, score-0.069]
</p><p>70 In the following motivation we assume that Ξ is the covariance matrix of a signal matrix Y . [sent-167, score-0.077]
</p><p>71 Using (1) (1) the notions from above, the objective is then to calculate spatial ﬁlters v j such that var(X1 v j ) is (1)  (1)  (2)  maximized and var(X2 v j ) and var(Y v j ) are minimized. [sent-168, score-0.094]
</p><p>72 Dually spatial ﬁlters v j are determined (2)  (2)  (2)  that maximize var(X2 v j ) and minimize var(X1 v j ) and var(Y v j ). [sent-169, score-0.094]
</p><p>73 Note that the idea of iCSP is in the spirit of the invariance constraints in (kernel) Fisher’s Discriminant proposed in [16]. [sent-179, score-0.072]
</p><p>74 As mentioned, iCSP is aiming at robust spatial ﬁltering against disturbances whose covariance Ξ can be anticipated from prior knowledge. [sent-181, score-0.163]
</p><p>75 Lemma 1 (Inﬂuence of generalized eigenvalue problems) Let λk and wk be k-th eigenvalue and eigenvector of the generalized eigvenvalue problem Aw = λ Bw,  (5)  respectively. [sent-187, score-0.431]
</p><p>76 Suppose that the matrices A and B are perturbed with small matrices ε ∆ and ε P where ε 1. [sent-188, score-0.064]
</p><p>77 The generalized eigenvalue problem eqns (3) and (4) can be rephrased as Σ1 v = d{(1 − ξ )(Σ1 + Σ2 ) + ξ Ξ}v,  Σ2 u = c{(1 − ξ )(Σ1 + Σ2 ) + ξ Ξ}u. [sent-190, score-0.106]
</p><p>78 0 α=2  filter  pattern  Figure 2: Comparison of CSP and iCSP on test data with artiﬁcially increased occipital alpha. [sent-219, score-0.09]
</p><p>79 The upper plots show the classiﬁer output on the test data with different degrees of alpha added (factors α = 0, 0. [sent-220, score-0.217]
</p><p>80 The lower panel shows the ﬁlter/pattern coefﬁcients topographically mapped on the scalp from original CSP (left) and iCSP (right). [sent-222, score-0.055]
</p><p>81 Here the invariance property was deﬁned with respect to the increase in the alpha activity in the visual cortex (occipital location) using an eyes open/eyes closed recording. [sent-223, score-0.487]
</p><p>82 M1k := Σ−1/2 (Σ−1/2 Σ1 Σ−1/2 − dk I)+ Σ−1/2 , M2k := Σ−1/2 (Σ−1/2 Σ2 Σ−1/2 − dk I)+ Σ−1/2 , and Σ := 1 (1 − ξ )(Σ1 + Σ2 ) + ξ Ξ. [sent-225, score-0.11]
</p><p>83 χ2k ) of the k-th eigenvalue vanishes and also the k-th eigenvector does coincide with the one for the original problem up to ε order, because the ﬁrst term of ψ 1k (resp. [sent-229, score-0.072]
</p><p>84 ψ 2k ) becomes zero (we note that dk and ck also depend on ξ ). [sent-230, score-0.055]
</p><p>85 5) on motor imagery data with the invariance characterized by data from a measurement during ‘eyes open’ (approx. [sent-234, score-0.209]
</p><p>86 While the performance of the original CSP is more and more deteriorated with increased alpha mixed in, the proposed iCSP method maintains a stable performance independent of the amount of increased alpha activity. [sent-241, score-0.434]
</p><p>87 The spatial ﬁlters that were extracted by CSP analysis vs. [sent-242, score-0.094]
</p><p>88 While the pattern of the original CSP has positive weights at the right occipital side which might be susceptible to α modulations, the corresponding iCSP has not. [sent-249, score-0.09]
</p><p>89 A more detailed inspection shows that both ﬁlters have a focus over the right (sensori-) motor cortex, but only the invariant ﬁlter has a spot of opposite sign right posterior to it. [sent-250, score-0.142]
</p><p>90 For the same values of ξ the iCSP ﬁlters + LDA classiﬁer trained on imag_move were applied to calcu6  35  35  Subject cv  test train  30  20 15  cv zv zk zq  20  15 10  5  5 0  0. [sent-254, score-0.08]
</p><p>91 The case for subject zk shows that the selection of ξ may be a delicate issue. [sent-283, score-0.12]
</p><p>92 For evaluation we used the imag_move session (see Section 2) as training set and the imag_lett session as test set. [sent-288, score-0.11]
</p><p>93 Obviously BCI users are subject to variations in attention and motivation. [sent-294, score-0.078]
</p><p>94 By substituting the expansions of λk and wk to Eq. [sent-307, score-0.219]
</p><p>95 (11), (A − λk B)ψ k = −(∆ − λk P)wk + χk Bwk = −(A − λk B)Mk (∆ − λk P)wk ,  7  (11)  holds, where we used the constraints w j Bwk = δ jk and (A − λk B)Mk =  ∑ Bw j w j  = I − Bwk wk . [sent-314, score-0.219]
</p><p>96 By a multiplication with wk B, the constant c turns out to be c = −wk Pwk /2, where we used the fact wk BMk = 0 and wk Bψ k = −wk Pwk /2 derived from the normalization wk (B + ε P)wk = 1. [sent-317, score-0.876]
</p><p>97 Stokes, “Learning to control brain activity: A review of the production and control of EEG components for driving brain-computer interface (BCI) systems”, Brain Cogn. [sent-358, score-0.233]
</p><p>98 Pfurtscheller, “Real-time EEG analysis with subject-speciﬁc spatial patterns for a Brain Computer Interface (BCI)”, IEEE Trans. [sent-381, score-0.145]
</p><p>99 Sajda, “Linear spatial integration for single trial detection in encephalography”, NeuroImage, 7(1): 223–230, 2002. [sent-408, score-0.094]
</p><p>100 Andrews, “Normal differentiation of occipital and precentral regions in man”, Arch. [sent-494, score-0.09]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('csp', 0.424), ('icsp', 0.379), ('bci', 0.367), ('wk', 0.219), ('alpha', 0.217), ('eeg', 0.2), ('brain', 0.122), ('lters', 0.107), ('rc', 0.103), ('invariant', 0.097), ('spatial', 0.094), ('occipital', 0.09), ('birbaumer', 0.082), ('blankertz', 0.082), ('pfurtscheller', 0.082), ('sc', 0.081), ('ller', 0.081), ('calibration', 0.08), ('subject', 0.078), ('activity', 0.077), ('feedback', 0.077), ('rayleigh', 0.077), ('parietal', 0.077), ('signals', 0.076), ('var', 0.075), ('uctuations', 0.074), ('invariance', 0.072), ('eigenvalue', 0.072), ('mental', 0.071), ('bwk', 0.069), ('pwk', 0.069), ('rhythms', 0.069), ('vk', 0.067), ('interfacing', 0.06), ('curio', 0.06), ('berlin', 0.056), ('movements', 0.055), ('dk', 0.055), ('session', 0.055), ('mill', 0.055), ('scalp', 0.055), ('sd', 0.053), ('lter', 0.052), ('schl', 0.052), ('measurement', 0.051), ('hinterberger', 0.051), ('modulations', 0.051), ('interface', 0.051), ('patterns', 0.051), ('mk', 0.049), ('eyes', 0.048), ('uk', 0.047), ('uence', 0.045), ('motor', 0.045), ('zk', 0.042), ('signal', 0.042), ('imagery', 0.041), ('cursor', 0.041), ('dornhege', 0.041), ('wolpaw', 0.041), ('adaption', 0.041), ('visual', 0.039), ('subjects', 0.039), ('zq', 0.038), ('schr', 0.038), ('discriminant', 0.037), ('interfaces', 0.036), ('classi', 0.036), ('covariance', 0.035), ('generalized', 0.034), ('cortex', 0.034), ('curran', 0.034), ('disturbance', 0.034), ('disturbances', 0.034), ('guger', 0.034), ('involvement', 0.034), ('nonstationarities', 0.034), ('pericentral', 0.034), ('stokes', 0.034), ('vigilance', 0.034), ('neurophysiological', 0.034), ('er', 0.034), ('eigenvalues', 0.033), ('recorded', 0.033), ('recording', 0.033), ('power', 0.032), ('matrices', 0.032), ('discrimination', 0.032), ('gl', 0.032), ('demands', 0.032), ('der', 0.031), ('germany', 0.03), ('control', 0.03), ('attenuation', 0.03), ('bler', 0.03), ('paralysed', 0.03), ('erd', 0.03), ('imagination', 0.03), ('neuper', 0.03), ('ramoser', 0.03)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000006 <a title="106-tfidf-1" href="./nips-2007-Invariant_Common_Spatial_Patterns%3A_Alleviating_Nonstationarities_in_Brain-Computer_Interfacing.html">106 nips-2007-Invariant Common Spatial Patterns: Alleviating Nonstationarities in Brain-Computer Interfacing</a></p>
<p>Author: Benjamin Blankertz, Motoaki Kawanabe, Ryota Tomioka, Friederike Hohlefeld, Klaus-Robert Müller, Vadim V. Nikulin</p><p>Abstract: Brain-Computer Interfaces can suffer from a large variance of the subject conditions within and across sessions. For example vigilance ﬂuctuations in the individual, variable task involvement, workload etc. alter the characteristics of EEG signals and thus challenge a stable BCI operation. In the present work we aim to deﬁne features based on a variant of the common spatial patterns (CSP) algorithm that are constructed invariant with respect to such nonstationarities. We enforce invariance properties by adding terms to the denominator of a Rayleigh coefﬁcient representation of CSP such as disturbance covariance matrices from ﬂuctuations in visual processing. In this manner physiological prior knowledge can be used to shape the classiﬁcation engine for BCI. As a proof of concept we present a BCI classiﬁer that is robust to changes in the level of parietal α -activity. In other words, the EEG decoding still works when there are lapses in vigilance.</p><p>2 0.30144376 <a title="106-tfidf-2" href="./nips-2007-Second_Order_Bilinear_Discriminant_Analysis_for_single_trial_EEG_analysis.html">173 nips-2007-Second Order Bilinear Discriminant Analysis for single trial EEG analysis</a></p>
<p>Author: Christoforos Christoforou, Paul Sajda, Lucas C. Parra</p><p>Abstract: Traditional analysis methods for single-trial classiﬁcation of electroencephalography (EEG) focus on two types of paradigms: phase locked methods, in which the amplitude of the signal is used as the feature for classiﬁcation, e.g. event related potentials; and second order methods, in which the feature of interest is the power of the signal, e.g. event related (de)synchronization. The procedure for deciding which paradigm to use is ad hoc and is typically driven by knowledge of the underlying neurophysiology. Here we propose a principled method, based on a bilinear model, in which the algorithm simultaneously learns the best ﬁrst and second order spatial and temporal features for classiﬁcation of EEG. The method is demonstrated on simulated data as well as on EEG taken from a benchmark data used to test classiﬁcation algorithms for brain computer interfaces. 1 1.1</p><p>3 0.28329444 <a title="106-tfidf-3" href="./nips-2007-EEG-Based_Brain-Computer_Interaction%3A_Improved_Accuracy_by_Automatic_Single-Trial_Error_Detection.html">74 nips-2007-EEG-Based Brain-Computer Interaction: Improved Accuracy by Automatic Single-Trial Error Detection</a></p>
<p>Author: Pierre Ferrez, José Millán</p><p>Abstract: Brain-computer interfaces (BCIs), as any other interaction modality based on physiological signals and body channels (e.g., muscular activity, speech and gestures), are prone to errors in the recognition of subject’s intent. An elegant approach to improve the accuracy of BCIs consists in a veriﬁcation procedure directly based on the presence of error-related potentials (ErrP) in the EEG recorded right after the occurrence of an error. Six healthy volunteer subjects with no prior BCI experience participated in a new human-robot interaction experiment where they were asked to mentally move a cursor towards a target that can be reached within a few steps using motor imagination. This experiment conﬁrms the previously reported presence of a new kind of ErrP. These “Interaction ErrP” exhibit a ﬁrst sharp negative peak followed by a positive peak and a second broader negative peak (∼290, ∼350 and ∼470 ms after the feedback, respectively). But in order to exploit these ErrP we need to detect them in each single trial using a short window following the feedback associated to the response of the classiﬁer embedded in the BCI. We have achieved an average recognition rate of correct and erroneous single trials of 81.8% and 76.2%, respectively. Furthermore, we have achieved an average recognition rate of the subject’s intent while trying to mentally drive the cursor of 73.1%. These results show that it’s possible to simultaneously extract useful information for mental control to operate a brain-actuated device as well as cognitive states such as error potentials to improve the quality of the braincomputer interaction. Finally, using a well-known inverse model (sLORETA), we show that the main focus of activity at the occurrence of the ErrP are, as expected, in the pre-supplementary motor area and in the anterior cingulate cortex. 1</p><p>4 0.15192758 <a title="106-tfidf-4" href="./nips-2007-Blind_channel_identification_for_speech_dereverberation_using_l1-norm_sparse_learning.html">37 nips-2007-Blind channel identification for speech dereverberation using l1-norm sparse learning</a></p>
<p>Author: Yuanqing Lin, Jingdong Chen, Youngmoo Kim, Daniel D. Lee</p><p>Abstract: Speech dereverberation remains an open problem after more than three decades of research. The most challenging step in speech dereverberation is blind channel identiﬁcation (BCI). Although many BCI approaches have been developed, their performance is still far from satisfactory for practical applications. The main difﬁculty in BCI lies in ﬁnding an appropriate acoustic model, which not only can effectively resolve solution degeneracies due to the lack of knowledge of the source, but also robustly models real acoustic environments. This paper proposes a sparse acoustic room impulse response (RIR) model for BCI, that is, an acoustic RIR can be modeled by a sparse FIR ﬁlter. Under this model, we show how to formulate the BCI of a single-input multiple-output (SIMO) system into a l1 norm regularized least squares (LS) problem, which is convex and can be solved efﬁciently with guaranteed global convergence. The sparseness of solutions is controlled by l1 -norm regularization parameters. We propose a sparse learning scheme that infers the optimal l1 -norm regularization parameters directly from microphone observations under a Bayesian framework. Our results show that the proposed approach is effective and robust, and it yields source estimates in real acoustic environments with high ﬁdelity to anechoic chamber measurements.</p><p>5 0.074769117 <a title="106-tfidf-5" href="./nips-2007-Predicting_Brain_States_from_fMRI_Data%3A_Incremental_Functional_Principal_Component_Regression.html">154 nips-2007-Predicting Brain States from fMRI Data: Incremental Functional Principal Component Regression</a></p>
<p>Author: Sennay Ghebreab, Arnold Smeulders, Pieter Adriaans</p><p>Abstract: We propose a method for reconstruction of human brain states directly from functional neuroimaging data. The method extends the traditional multivariate regression analysis of discretized fMRI data to the domain of stochastic functional measurements, facilitating evaluation of brain responses to complex stimuli and boosting the power of functional imaging. The method searches for sets of voxel time courses that optimize a multivariate functional linear model in terms of R2 statistic. Population based incremental learning is used to identify spatially distributed brain responses to complex stimuli without attempting to localize function ﬁrst. Variation in hemodynamic lag across brain areas and among subjects is taken into account by voxel-wise non-linear registration of stimulus pattern to fMRI data. Application of the method on an international test benchmark for prediction of naturalistic stimuli from new and unknown fMRI data shows that the method successfully uncovers spatially distributed parts of the brain that are highly predictive of a given stimulus. 1</p><p>6 0.072343558 <a title="106-tfidf-6" href="./nips-2007-Subspace-Based_Face_Recognition_in_Analog_VLSI.html">188 nips-2007-Subspace-Based Face Recognition in Analog VLSI</a></p>
<p>7 0.072089054 <a title="106-tfidf-7" href="./nips-2007-An_Analysis_of_Inference_with_the_Universum.html">24 nips-2007-An Analysis of Inference with the Universum</a></p>
<p>8 0.068629473 <a title="106-tfidf-8" href="./nips-2007-Locality_and_low-dimensions_in_the_prediction_of_natural_experience_from_fMRI.html">122 nips-2007-Locality and low-dimensions in the prediction of natural experience from fMRI</a></p>
<p>9 0.068110146 <a title="106-tfidf-9" href="./nips-2007-Convex_Learning_with_Invariances.html">62 nips-2007-Convex Learning with Invariances</a></p>
<p>10 0.058138162 <a title="106-tfidf-10" href="./nips-2007-Inferring_Elapsed_Time_from_Stochastic_Neural_Processes.html">103 nips-2007-Inferring Elapsed Time from Stochastic Neural Processes</a></p>
<p>11 0.057835504 <a title="106-tfidf-11" href="./nips-2007-DIFFRAC%3A_a_discriminative_and_flexible_framework_for_clustering.html">65 nips-2007-DIFFRAC: a discriminative and flexible framework for clustering</a></p>
<p>12 0.055645574 <a title="106-tfidf-12" href="./nips-2007-Receptive_Fields_without_Spike-Triggering.html">164 nips-2007-Receptive Fields without Spike-Triggering</a></p>
<p>13 0.052927595 <a title="106-tfidf-13" href="./nips-2007-Bayesian_Inference_for_Spiking_Neuron_Models_with_a_Sparsity_Prior.html">33 nips-2007-Bayesian Inference for Spiking Neuron Models with a Sparsity Prior</a></p>
<p>14 0.051750429 <a title="106-tfidf-14" href="./nips-2007-Measuring_Neural_Synchrony_by_Message_Passing.html">127 nips-2007-Measuring Neural Synchrony by Message Passing</a></p>
<p>15 0.048981439 <a title="106-tfidf-15" href="./nips-2007-The_rat_as_particle_filter.html">203 nips-2007-The rat as particle filter</a></p>
<p>16 0.048570447 <a title="106-tfidf-16" href="./nips-2007-Continuous_Time_Particle_Filtering_for_fMRI.html">59 nips-2007-Continuous Time Particle Filtering for fMRI</a></p>
<p>17 0.048493039 <a title="106-tfidf-17" href="./nips-2007-Catching_Up_Faster_in_Bayesian_Model_Selection_and_Model_Averaging.html">44 nips-2007-Catching Up Faster in Bayesian Model Selection and Model Averaging</a></p>
<p>18 0.045478996 <a title="106-tfidf-18" href="./nips-2007-Simplified_Rules_and_Theoretical_Analysis_for_Information_Bottleneck_Optimization_and_PCA_with_Spiking_Neurons.html">177 nips-2007-Simplified Rules and Theoretical Analysis for Information Bottleneck Optimization and PCA with Spiking Neurons</a></p>
<p>19 0.044572979 <a title="106-tfidf-19" href="./nips-2007-An_in-silico_Neural_Model_of_Dynamic_Routing_through_Neuronal_Coherence.html">25 nips-2007-An in-silico Neural Model of Dynamic Routing through Neuronal Coherence</a></p>
<p>20 0.044111766 <a title="106-tfidf-20" href="./nips-2007-Structured_Learning_with_Approximate_Inference.html">187 nips-2007-Structured Learning with Approximate Inference</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2007_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.169), (1, 0.064), (2, 0.064), (3, 0.015), (4, 0.002), (5, 0.17), (6, 0.085), (7, 0.125), (8, -0.167), (9, -0.088), (10, 0.014), (11, -0.185), (12, -0.027), (13, -0.036), (14, 0.264), (15, -0.037), (16, -0.004), (17, -0.333), (18, -0.15), (19, -0.03), (20, -0.109), (21, -0.117), (22, 0.079), (23, 0.185), (24, 0.052), (25, -0.106), (26, 0.154), (27, -0.183), (28, 0.027), (29, 0.004), (30, -0.042), (31, 0.023), (32, -0.0), (33, -0.123), (34, -0.034), (35, -0.012), (36, 0.019), (37, 0.013), (38, 0.063), (39, -0.035), (40, -0.017), (41, 0.058), (42, -0.012), (43, 0.055), (44, -0.002), (45, 0.05), (46, 0.04), (47, -0.045), (48, 0.001), (49, -0.008)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95834804 <a title="106-lsi-1" href="./nips-2007-Invariant_Common_Spatial_Patterns%3A_Alleviating_Nonstationarities_in_Brain-Computer_Interfacing.html">106 nips-2007-Invariant Common Spatial Patterns: Alleviating Nonstationarities in Brain-Computer Interfacing</a></p>
<p>Author: Benjamin Blankertz, Motoaki Kawanabe, Ryota Tomioka, Friederike Hohlefeld, Klaus-Robert Müller, Vadim V. Nikulin</p><p>Abstract: Brain-Computer Interfaces can suffer from a large variance of the subject conditions within and across sessions. For example vigilance ﬂuctuations in the individual, variable task involvement, workload etc. alter the characteristics of EEG signals and thus challenge a stable BCI operation. In the present work we aim to deﬁne features based on a variant of the common spatial patterns (CSP) algorithm that are constructed invariant with respect to such nonstationarities. We enforce invariance properties by adding terms to the denominator of a Rayleigh coefﬁcient representation of CSP such as disturbance covariance matrices from ﬂuctuations in visual processing. In this manner physiological prior knowledge can be used to shape the classiﬁcation engine for BCI. As a proof of concept we present a BCI classiﬁer that is robust to changes in the level of parietal α -activity. In other words, the EEG decoding still works when there are lapses in vigilance.</p><p>2 0.86670524 <a title="106-lsi-2" href="./nips-2007-EEG-Based_Brain-Computer_Interaction%3A_Improved_Accuracy_by_Automatic_Single-Trial_Error_Detection.html">74 nips-2007-EEG-Based Brain-Computer Interaction: Improved Accuracy by Automatic Single-Trial Error Detection</a></p>
<p>Author: Pierre Ferrez, José Millán</p><p>Abstract: Brain-computer interfaces (BCIs), as any other interaction modality based on physiological signals and body channels (e.g., muscular activity, speech and gestures), are prone to errors in the recognition of subject’s intent. An elegant approach to improve the accuracy of BCIs consists in a veriﬁcation procedure directly based on the presence of error-related potentials (ErrP) in the EEG recorded right after the occurrence of an error. Six healthy volunteer subjects with no prior BCI experience participated in a new human-robot interaction experiment where they were asked to mentally move a cursor towards a target that can be reached within a few steps using motor imagination. This experiment conﬁrms the previously reported presence of a new kind of ErrP. These “Interaction ErrP” exhibit a ﬁrst sharp negative peak followed by a positive peak and a second broader negative peak (∼290, ∼350 and ∼470 ms after the feedback, respectively). But in order to exploit these ErrP we need to detect them in each single trial using a short window following the feedback associated to the response of the classiﬁer embedded in the BCI. We have achieved an average recognition rate of correct and erroneous single trials of 81.8% and 76.2%, respectively. Furthermore, we have achieved an average recognition rate of the subject’s intent while trying to mentally drive the cursor of 73.1%. These results show that it’s possible to simultaneously extract useful information for mental control to operate a brain-actuated device as well as cognitive states such as error potentials to improve the quality of the braincomputer interaction. Finally, using a well-known inverse model (sLORETA), we show that the main focus of activity at the occurrence of the ErrP are, as expected, in the pre-supplementary motor area and in the anterior cingulate cortex. 1</p><p>3 0.81841695 <a title="106-lsi-3" href="./nips-2007-Second_Order_Bilinear_Discriminant_Analysis_for_single_trial_EEG_analysis.html">173 nips-2007-Second Order Bilinear Discriminant Analysis for single trial EEG analysis</a></p>
<p>Author: Christoforos Christoforou, Paul Sajda, Lucas C. Parra</p><p>Abstract: Traditional analysis methods for single-trial classiﬁcation of electroencephalography (EEG) focus on two types of paradigms: phase locked methods, in which the amplitude of the signal is used as the feature for classiﬁcation, e.g. event related potentials; and second order methods, in which the feature of interest is the power of the signal, e.g. event related (de)synchronization. The procedure for deciding which paradigm to use is ad hoc and is typically driven by knowledge of the underlying neurophysiology. Here we propose a principled method, based on a bilinear model, in which the algorithm simultaneously learns the best ﬁrst and second order spatial and temporal features for classiﬁcation of EEG. The method is demonstrated on simulated data as well as on EEG taken from a benchmark data used to test classiﬁcation algorithms for brain computer interfaces. 1 1.1</p><p>4 0.59986442 <a title="106-lsi-4" href="./nips-2007-Blind_channel_identification_for_speech_dereverberation_using_l1-norm_sparse_learning.html">37 nips-2007-Blind channel identification for speech dereverberation using l1-norm sparse learning</a></p>
<p>Author: Yuanqing Lin, Jingdong Chen, Youngmoo Kim, Daniel D. Lee</p><p>Abstract: Speech dereverberation remains an open problem after more than three decades of research. The most challenging step in speech dereverberation is blind channel identiﬁcation (BCI). Although many BCI approaches have been developed, their performance is still far from satisfactory for practical applications. The main difﬁculty in BCI lies in ﬁnding an appropriate acoustic model, which not only can effectively resolve solution degeneracies due to the lack of knowledge of the source, but also robustly models real acoustic environments. This paper proposes a sparse acoustic room impulse response (RIR) model for BCI, that is, an acoustic RIR can be modeled by a sparse FIR ﬁlter. Under this model, we show how to formulate the BCI of a single-input multiple-output (SIMO) system into a l1 norm regularized least squares (LS) problem, which is convex and can be solved efﬁciently with guaranteed global convergence. The sparseness of solutions is controlled by l1 -norm regularization parameters. We propose a sparse learning scheme that infers the optimal l1 -norm regularization parameters directly from microphone observations under a Bayesian framework. Our results show that the proposed approach is effective and robust, and it yields source estimates in real acoustic environments with high ﬁdelity to anechoic chamber measurements.</p><p>5 0.46902812 <a title="106-lsi-5" href="./nips-2007-An_Analysis_of_Inference_with_the_Universum.html">24 nips-2007-An Analysis of Inference with the Universum</a></p>
<p>Author: Olivier Chapelle, Alekh Agarwal, Fabian H. Sinz, Bernhard Schölkopf</p><p>Abstract: We study a pattern classiﬁcation algorithm which has recently been proposed by Vapnik and coworkers. It builds on a new inductive principle which assumes that in addition to positive and negative data, a third class of data is available, termed the Universum. We assay the behavior of the algorithm by establishing links with Fisher discriminant analysis and oriented PCA, as well as with an SVM in a projected subspace (or, equivalently, with a data-dependent reduced kernel). We also provide experimental results. 1</p><p>6 0.32834703 <a title="106-lsi-6" href="./nips-2007-Measuring_Neural_Synchrony_by_Message_Passing.html">127 nips-2007-Measuring Neural Synchrony by Message Passing</a></p>
<p>7 0.28483152 <a title="106-lsi-7" href="./nips-2007-An_in-silico_Neural_Model_of_Dynamic_Routing_through_Neuronal_Coherence.html">25 nips-2007-An in-silico Neural Model of Dynamic Routing through Neuronal Coherence</a></p>
<p>8 0.25856349 <a title="106-lsi-8" href="./nips-2007-An_online_Hebbian_learning_rule_that_performs_Independent_Component_Analysis.html">26 nips-2007-An online Hebbian learning rule that performs Independent Component Analysis</a></p>
<p>9 0.23055761 <a title="106-lsi-9" href="./nips-2007-Continuous_Time_Particle_Filtering_for_fMRI.html">59 nips-2007-Continuous Time Particle Filtering for fMRI</a></p>
<p>10 0.22551374 <a title="106-lsi-10" href="./nips-2007-Managing_Power_Consumption_and_Performance_of_Computing_Systems_Using_Reinforcement_Learning.html">124 nips-2007-Managing Power Consumption and Performance of Computing Systems Using Reinforcement Learning</a></p>
<p>11 0.22339809 <a title="106-lsi-11" href="./nips-2007-Catching_Up_Faster_in_Bayesian_Model_Selection_and_Model_Averaging.html">44 nips-2007-Catching Up Faster in Bayesian Model Selection and Model Averaging</a></p>
<p>12 0.2185189 <a title="106-lsi-12" href="./nips-2007-Predicting_Brain_States_from_fMRI_Data%3A_Incremental_Functional_Principal_Component_Regression.html">154 nips-2007-Predicting Brain States from fMRI Data: Incremental Functional Principal Component Regression</a></p>
<p>13 0.21270092 <a title="106-lsi-13" href="./nips-2007-Inferring_Elapsed_Time_from_Stochastic_Neural_Processes.html">103 nips-2007-Inferring Elapsed Time from Stochastic Neural Processes</a></p>
<p>14 0.20873003 <a title="106-lsi-14" href="./nips-2007-Locality_and_low-dimensions_in_the_prediction_of_natural_experience_from_fMRI.html">122 nips-2007-Locality and low-dimensions in the prediction of natural experience from fMRI</a></p>
<p>15 0.20321532 <a title="106-lsi-15" href="./nips-2007-A_Spectral_Regularization_Framework_for_Multi-Task_Structure_Learning.html">12 nips-2007-A Spectral Regularization Framework for Multi-Task Structure Learning</a></p>
<p>16 0.2017051 <a title="106-lsi-16" href="./nips-2007-Catching_Change-points_with_Lasso.html">43 nips-2007-Catching Change-points with Lasso</a></p>
<p>17 0.19935633 <a title="106-lsi-17" href="./nips-2007-Receptive_Fields_without_Spike-Triggering.html">164 nips-2007-Receptive Fields without Spike-Triggering</a></p>
<p>18 0.19827442 <a title="106-lsi-18" href="./nips-2007-Subspace-Based_Face_Recognition_in_Analog_VLSI.html">188 nips-2007-Subspace-Based Face Recognition in Analog VLSI</a></p>
<p>19 0.19656503 <a title="106-lsi-19" href="./nips-2007-Contraction_Properties_of_VLSI_Cooperative_Competitive_Neural_Networks_of_Spiking_Neurons.html">60 nips-2007-Contraction Properties of VLSI Cooperative Competitive Neural Networks of Spiking Neurons</a></p>
<p>20 0.18788804 <a title="106-lsi-20" href="./nips-2007-Unsupervised_Feature_Selection_for_Accurate_Recommendation_of_High-Dimensional_Image_Data.html">211 nips-2007-Unsupervised Feature Selection for Accurate Recommendation of High-Dimensional Image Data</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2007_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(4, 0.023), (5, 0.026), (13, 0.053), (16, 0.037), (18, 0.027), (19, 0.45), (21, 0.051), (34, 0.017), (35, 0.023), (47, 0.079), (49, 0.01), (83, 0.06), (85, 0.013), (87, 0.023), (90, 0.039)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.85168636 <a title="106-lda-1" href="./nips-2007-Invariant_Common_Spatial_Patterns%3A_Alleviating_Nonstationarities_in_Brain-Computer_Interfacing.html">106 nips-2007-Invariant Common Spatial Patterns: Alleviating Nonstationarities in Brain-Computer Interfacing</a></p>
<p>Author: Benjamin Blankertz, Motoaki Kawanabe, Ryota Tomioka, Friederike Hohlefeld, Klaus-Robert Müller, Vadim V. Nikulin</p><p>Abstract: Brain-Computer Interfaces can suffer from a large variance of the subject conditions within and across sessions. For example vigilance ﬂuctuations in the individual, variable task involvement, workload etc. alter the characteristics of EEG signals and thus challenge a stable BCI operation. In the present work we aim to deﬁne features based on a variant of the common spatial patterns (CSP) algorithm that are constructed invariant with respect to such nonstationarities. We enforce invariance properties by adding terms to the denominator of a Rayleigh coefﬁcient representation of CSP such as disturbance covariance matrices from ﬂuctuations in visual processing. In this manner physiological prior knowledge can be used to shape the classiﬁcation engine for BCI. As a proof of concept we present a BCI classiﬁer that is robust to changes in the level of parietal α -activity. In other words, the EEG decoding still works when there are lapses in vigilance.</p><p>2 0.81275702 <a title="106-lda-2" href="./nips-2007-Second_Order_Bilinear_Discriminant_Analysis_for_single_trial_EEG_analysis.html">173 nips-2007-Second Order Bilinear Discriminant Analysis for single trial EEG analysis</a></p>
<p>Author: Christoforos Christoforou, Paul Sajda, Lucas C. Parra</p><p>Abstract: Traditional analysis methods for single-trial classiﬁcation of electroencephalography (EEG) focus on two types of paradigms: phase locked methods, in which the amplitude of the signal is used as the feature for classiﬁcation, e.g. event related potentials; and second order methods, in which the feature of interest is the power of the signal, e.g. event related (de)synchronization. The procedure for deciding which paradigm to use is ad hoc and is typically driven by knowledge of the underlying neurophysiology. Here we propose a principled method, based on a bilinear model, in which the algorithm simultaneously learns the best ﬁrst and second order spatial and temporal features for classiﬁcation of EEG. The method is demonstrated on simulated data as well as on EEG taken from a benchmark data used to test classiﬁcation algorithms for brain computer interfaces. 1 1.1</p><p>3 0.72833174 <a title="106-lda-3" href="./nips-2007-A_Unified_Near-Optimal_Estimator_For_Dimension_Reduction_in_%24l_%5Calpha%24_%28%240%3C%5Calpha%5Cleq_2%24%29_Using_Stable_Random_Projections.html">13 nips-2007-A Unified Near-Optimal Estimator For Dimension Reduction in $l \alpha$ ($0<\alpha\leq 2$) Using Stable Random Projections</a></p>
<p>Author: Ping Li, Trevor J. Hastie</p><p>Abstract: Many tasks (e.g., clustering) in machine learning only require the lα distances instead of the original data. For dimension reductions in the lα norm (0 < α ≤ 2), the method of stable random projections can efﬁciently compute the lα distances in massive datasets (e.g., the Web or massive data streams) in one pass of the data. The estimation task for stable random projections has been an interesting topic. We propose a simple estimator based on the fractional power of the samples (projected data), which is surprisingly near-optimal in terms of the asymptotic variance. In fact, it achieves the Cram´ r-Rao bound when α = 2 and α = 0+. This e new result will be useful when applying stable random projections to distancebased clustering, classiﬁcations, kernels, massive data streams etc.</p><p>4 0.53258687 <a title="106-lda-4" href="./nips-2007-EEG-Based_Brain-Computer_Interaction%3A_Improved_Accuracy_by_Automatic_Single-Trial_Error_Detection.html">74 nips-2007-EEG-Based Brain-Computer Interaction: Improved Accuracy by Automatic Single-Trial Error Detection</a></p>
<p>Author: Pierre Ferrez, José Millán</p><p>Abstract: Brain-computer interfaces (BCIs), as any other interaction modality based on physiological signals and body channels (e.g., muscular activity, speech and gestures), are prone to errors in the recognition of subject’s intent. An elegant approach to improve the accuracy of BCIs consists in a veriﬁcation procedure directly based on the presence of error-related potentials (ErrP) in the EEG recorded right after the occurrence of an error. Six healthy volunteer subjects with no prior BCI experience participated in a new human-robot interaction experiment where they were asked to mentally move a cursor towards a target that can be reached within a few steps using motor imagination. This experiment conﬁrms the previously reported presence of a new kind of ErrP. These “Interaction ErrP” exhibit a ﬁrst sharp negative peak followed by a positive peak and a second broader negative peak (∼290, ∼350 and ∼470 ms after the feedback, respectively). But in order to exploit these ErrP we need to detect them in each single trial using a short window following the feedback associated to the response of the classiﬁer embedded in the BCI. We have achieved an average recognition rate of correct and erroneous single trials of 81.8% and 76.2%, respectively. Furthermore, we have achieved an average recognition rate of the subject’s intent while trying to mentally drive the cursor of 73.1%. These results show that it’s possible to simultaneously extract useful information for mental control to operate a brain-actuated device as well as cognitive states such as error potentials to improve the quality of the braincomputer interaction. Finally, using a well-known inverse model (sLORETA), we show that the main focus of activity at the occurrence of the ErrP are, as expected, in the pre-supplementary motor area and in the anterior cingulate cortex. 1</p><p>5 0.41544622 <a title="106-lda-5" href="./nips-2007-Blind_channel_identification_for_speech_dereverberation_using_l1-norm_sparse_learning.html">37 nips-2007-Blind channel identification for speech dereverberation using l1-norm sparse learning</a></p>
<p>Author: Yuanqing Lin, Jingdong Chen, Youngmoo Kim, Daniel D. Lee</p><p>Abstract: Speech dereverberation remains an open problem after more than three decades of research. The most challenging step in speech dereverberation is blind channel identiﬁcation (BCI). Although many BCI approaches have been developed, their performance is still far from satisfactory for practical applications. The main difﬁculty in BCI lies in ﬁnding an appropriate acoustic model, which not only can effectively resolve solution degeneracies due to the lack of knowledge of the source, but also robustly models real acoustic environments. This paper proposes a sparse acoustic room impulse response (RIR) model for BCI, that is, an acoustic RIR can be modeled by a sparse FIR ﬁlter. Under this model, we show how to formulate the BCI of a single-input multiple-output (SIMO) system into a l1 norm regularized least squares (LS) problem, which is convex and can be solved efﬁciently with guaranteed global convergence. The sparseness of solutions is controlled by l1 -norm regularization parameters. We propose a sparse learning scheme that infers the optimal l1 -norm regularization parameters directly from microphone observations under a Bayesian framework. Our results show that the proposed approach is effective and robust, and it yields source estimates in real acoustic environments with high ﬁdelity to anechoic chamber measurements.</p><p>6 0.39020288 <a title="106-lda-6" href="./nips-2007-An_Analysis_of_Inference_with_the_Universum.html">24 nips-2007-An Analysis of Inference with the Universum</a></p>
<p>7 0.35958427 <a title="106-lda-7" href="./nips-2007-Measuring_Neural_Synchrony_by_Message_Passing.html">127 nips-2007-Measuring Neural Synchrony by Message Passing</a></p>
<p>8 0.34582049 <a title="106-lda-8" href="./nips-2007-Random_Projections_for_Manifold_Learning.html">161 nips-2007-Random Projections for Manifold Learning</a></p>
<p>9 0.34378487 <a title="106-lda-9" href="./nips-2007-Locality_and_low-dimensions_in_the_prediction_of_natural_experience_from_fMRI.html">122 nips-2007-Locality and low-dimensions in the prediction of natural experience from fMRI</a></p>
<p>10 0.34053981 <a title="106-lda-10" href="./nips-2007-Simplified_Rules_and_Theoretical_Analysis_for_Information_Bottleneck_Optimization_and_PCA_with_Spiking_Neurons.html">177 nips-2007-Simplified Rules and Theoretical Analysis for Information Bottleneck Optimization and PCA with Spiking Neurons</a></p>
<p>11 0.33796635 <a title="106-lda-11" href="./nips-2007-Receptive_Fields_without_Spike-Triggering.html">164 nips-2007-Receptive Fields without Spike-Triggering</a></p>
<p>12 0.33681196 <a title="106-lda-12" href="./nips-2007-An_in-silico_Neural_Model_of_Dynamic_Routing_through_Neuronal_Coherence.html">25 nips-2007-An in-silico Neural Model of Dynamic Routing through Neuronal Coherence</a></p>
<p>13 0.33519682 <a title="106-lda-13" href="./nips-2007-Predicting_Brain_States_from_fMRI_Data%3A_Incremental_Functional_Principal_Component_Regression.html">154 nips-2007-Predicting Brain States from fMRI Data: Incremental Functional Principal Component Regression</a></p>
<p>14 0.3307251 <a title="106-lda-14" href="./nips-2007-The_discriminant_center-surround_hypothesis_for_bottom-up_saliency.html">202 nips-2007-The discriminant center-surround hypothesis for bottom-up saliency</a></p>
<p>15 0.3258177 <a title="106-lda-15" href="./nips-2007-SpAM%3A_Sparse_Additive_Models.html">179 nips-2007-SpAM: Sparse Additive Models</a></p>
<p>16 0.32194841 <a title="106-lda-16" href="./nips-2007-Learning_to_classify_complex_patterns_using_a_VLSI_network_of_spiking_neurons.html">117 nips-2007-Learning to classify complex patterns using a VLSI network of spiking neurons</a></p>
<p>17 0.31896707 <a title="106-lda-17" href="./nips-2007-Congruence_between_model_and_human_attention_reveals_unique_signatures_of_critical_visual_events.html">57 nips-2007-Congruence between model and human attention reveals unique signatures of critical visual events</a></p>
<p>18 0.31865641 <a title="106-lda-18" href="./nips-2007-Theoretical_Analysis_of_Learning_with_Reward-Modulated_Spike-Timing-Dependent_Plasticity.html">205 nips-2007-Theoretical Analysis of Learning with Reward-Modulated Spike-Timing-Dependent Plasticity</a></p>
<p>19 0.31270862 <a title="106-lda-19" href="./nips-2007-An_online_Hebbian_learning_rule_that_performs_Independent_Component_Analysis.html">26 nips-2007-An online Hebbian learning rule that performs Independent Component Analysis</a></p>
<p>20 0.31147921 <a title="106-lda-20" href="./nips-2007-Better_than_least_squares%3A_comparison_of_objective_functions_for_estimating_linear-nonlinear_models.html">36 nips-2007-Better than least squares: comparison of objective functions for estimating linear-nonlinear models</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
