<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>98 nips-2007-Hierarchical Apprenticeship Learning with Application to Quadruped Locomotion</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-98" href="#">nips2007-98</a> knowledge-graph by maker-knowledge-mining</p><h1>98 nips-2007-Hierarchical Apprenticeship Learning with Application to Quadruped Locomotion</h1>
<br/><p>Source: <a title="nips-2007-98-pdf" href="http://papers.nips.cc/paper/3253-hierarchical-apprenticeship-learning-with-application-to-quadruped-locomotion.pdf">pdf</a></p><p>Author: J. Z. Kolter, Pieter Abbeel, Andrew Y. Ng</p><p>Abstract: We consider apprenticeship learning—learning from expert demonstrations—in the setting of large, complex domains. Past work in apprenticeship learning requires that the expert demonstrate complete trajectories through the domain. However, in many problems even an expert has difﬁculty controlling the system, which makes this approach infeasible. For example, consider the task of teaching a quadruped robot to navigate over extreme terrain; demonstrating an optimal policy (i.e., an optimal set of foot locations over the entire terrain) is a highly non-trivial task, even for an expert. In this paper we propose a method for hierarchical apprenticeship learning, which allows the algorithm to accept isolated advice at different hierarchical levels of the control task. This type of advice is often feasible for experts to give, even if the expert is unable to demonstrate complete trajectories. This allows us to extend the apprenticeship learning paradigm to much larger, more challenging domains. In particular, in this paper we apply the hierarchical apprenticeship learning algorithm to the task of quadruped locomotion over extreme terrain, and achieve, to the best of our knowledge, results superior to any previously published work. 1</p><p>Reference: <a title="nips-2007-98-reference" href="../nips2007_reference/nips-2007-Hierarchical_Apprenticeship_Learning_with_Application_to_Quadruped_Locomotion_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('appr', 0.456), ('quadrup', 0.382), ('expert', 0.289), ('terrain', 0.277), ('footstep', 0.266), ('robot', 0.22), ('reward', 0.219), ('sh', 0.172), ('locomot', 0.172), ('hierarch', 0.166), ('policy', 0.158), ('hal', 0.148), ('mdp', 0.14), ('wt', 0.111), ('foot', 0.1), ('reinforc', 0.096), ('level', 0.088), ('mdps', 0.083), ('feet', 0.079), ('room', 0.074)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="98-tfidf-1" href="./nips-2007-Hierarchical_Apprenticeship_Learning_with_Application_to_Quadruped_Locomotion.html">98 nips-2007-Hierarchical Apprenticeship Learning with Application to Quadruped Locomotion</a></p>
<p>2 0.41893259 <a title="98-tfidf-2" href="./nips-2007-A_Game-Theoretic_Approach_to_Apprenticeship_Learning.html">5 nips-2007-A Game-Theoretic Approach to Apprenticeship Learning</a></p>
<p>3 0.19137059 <a title="98-tfidf-3" href="./nips-2007-Online_Linear_Regression_and_Its_Application_to_Model-Based_Reinforcement_Learning.html">148 nips-2007-Online Linear Regression and Its Application to Model-Based Reinforcement Learning</a></p>
<p>4 0.15543145 <a title="98-tfidf-4" href="./nips-2007-Incremental_Natural_Actor-Critic_Algorithms.html">102 nips-2007-Incremental Natural Actor-Critic Algorithms</a></p>
<p>5 0.15439071 <a title="98-tfidf-5" href="./nips-2007-Bayesian_Policy_Learning_with_Trans-Dimensional_MCMC.html">34 nips-2007-Bayesian Policy Learning with Trans-Dimensional MCMC</a></p>
<p>6 0.13708293 <a title="98-tfidf-6" href="./nips-2007-Random_Sampling_of_States_in_Dynamic_Programming.html">162 nips-2007-Random Sampling of States in Dynamic Programming</a></p>
<p>7 0.13267516 <a title="98-tfidf-7" href="./nips-2007-Reinforcement_Learning_in_Continuous_Action_Spaces_through_Sequential_Monte_Carlo_Methods.html">168 nips-2007-Reinforcement Learning in Continuous Action Spaces through Sequential Monte Carlo Methods</a></p>
<p>8 0.12796298 <a title="98-tfidf-8" href="./nips-2007-What_makes_some_POMDP_problems_easy_to_approximate%3F.html">215 nips-2007-What makes some POMDP problems easy to approximate?</a></p>
<p>9 0.11980084 <a title="98-tfidf-9" href="./nips-2007-Managing_Power_Consumption_and_Performance_of_Computing_Systems_Using_Reinforcement_Learning.html">124 nips-2007-Managing Power Consumption and Performance of Computing Systems Using Reinforcement Learning</a></p>
<p>10 0.11466572 <a title="98-tfidf-10" href="./nips-2007-Fitted_Q-iteration_in_continuous_action-space_MDPs.html">91 nips-2007-Fitted Q-iteration in continuous action-space MDPs</a></p>
<p>11 0.10709983 <a title="98-tfidf-11" href="./nips-2007-Markov_Chain_Monte_Carlo_with_People.html">125 nips-2007-Markov Chain Monte Carlo with People</a></p>
<p>12 0.10321649 <a title="98-tfidf-12" href="./nips-2007-Optimistic_Linear_Programming_gives_Logarithmic_Regret_for_Irreducible_MDPs.html">151 nips-2007-Optimistic Linear Programming gives Logarithmic Regret for Irreducible MDPs</a></p>
<p>13 0.1017179 <a title="98-tfidf-13" href="./nips-2007-Bayes-Adaptive_POMDPs.html">30 nips-2007-Bayes-Adaptive POMDPs</a></p>
<p>14 0.098397925 <a title="98-tfidf-14" href="./nips-2007-Receding_Horizon_Differential_Dynamic_Programming.html">163 nips-2007-Receding Horizon Differential Dynamic Programming</a></p>
<p>15 0.095074087 <a title="98-tfidf-15" href="./nips-2007-Stable_Dual_Dynamic_Programming.html">185 nips-2007-Stable Dual Dynamic Programming</a></p>
<p>16 0.083558746 <a title="98-tfidf-16" href="./nips-2007-Competition_Adds_Complexity.html">52 nips-2007-Competition Adds Complexity</a></p>
<p>17 0.080870859 <a title="98-tfidf-17" href="./nips-2007-Hippocampal_Contributions_to_Control%3A_The_Third_Way.html">100 nips-2007-Hippocampal Contributions to Control: The Third Way</a></p>
<p>18 0.077894576 <a title="98-tfidf-18" href="./nips-2007-A_Risk_Minimization_Principle_for_a_Class_of_Parzen_Estimators.html">11 nips-2007-A Risk Minimization Principle for a Class of Parzen Estimators</a></p>
<p>19 0.066152424 <a title="98-tfidf-19" href="./nips-2007-Exponential_Family_Predictive_Representations_of_State.html">86 nips-2007-Exponential Family Predictive Representations of State</a></p>
<p>20 0.063733429 <a title="98-tfidf-20" href="./nips-2007-Hierarchical_Penalization.html">99 nips-2007-Hierarchical Penalization</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2007_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.174), (1, -0.113), (2, -0.309), (3, -0.084), (4, 0.172), (5, 0.043), (6, 0.055), (7, -0.005), (8, 0.047), (9, -0.076), (10, -0.05), (11, -0.069), (12, 0.069), (13, 0.034), (14, 0.01), (15, 0.041), (16, -0.022), (17, -0.059), (18, 0.042), (19, -0.008), (20, 0.046), (21, 0.102), (22, -0.029), (23, -0.014), (24, -0.015), (25, 0.035), (26, -0.025), (27, 0.005), (28, 0.014), (29, 0.077), (30, -0.018), (31, 0.081), (32, 0.146), (33, 0.02), (34, -0.038), (35, 0.156), (36, -0.028), (37, 0.04), (38, -0.111), (39, 0.118), (40, 0.148), (41, -0.027), (42, 0.153), (43, 0.089), (44, 0.055), (45, -0.012), (46, 0.08), (47, -0.013), (48, -0.012), (49, -0.125)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93399739 <a title="98-lsi-1" href="./nips-2007-Hierarchical_Apprenticeship_Learning_with_Application_to_Quadruped_Locomotion.html">98 nips-2007-Hierarchical Apprenticeship Learning with Application to Quadruped Locomotion</a></p>
<p>2 0.82177776 <a title="98-lsi-2" href="./nips-2007-A_Game-Theoretic_Approach_to_Apprenticeship_Learning.html">5 nips-2007-A Game-Theoretic Approach to Apprenticeship Learning</a></p>
<p>3 0.59374928 <a title="98-lsi-3" href="./nips-2007-Competition_Adds_Complexity.html">52 nips-2007-Competition Adds Complexity</a></p>
<p>4 0.55948156 <a title="98-lsi-4" href="./nips-2007-Managing_Power_Consumption_and_Performance_of_Computing_Systems_Using_Reinforcement_Learning.html">124 nips-2007-Managing Power Consumption and Performance of Computing Systems Using Reinforcement Learning</a></p>
<p>5 0.53871769 <a title="98-lsi-5" href="./nips-2007-Online_Linear_Regression_and_Its_Application_to_Model-Based_Reinforcement_Learning.html">148 nips-2007-Online Linear Regression and Its Application to Model-Based Reinforcement Learning</a></p>
<p>6 0.5189113 <a title="98-lsi-6" href="./nips-2007-Bayesian_Policy_Learning_with_Trans-Dimensional_MCMC.html">34 nips-2007-Bayesian Policy Learning with Trans-Dimensional MCMC</a></p>
<p>7 0.50205255 <a title="98-lsi-7" href="./nips-2007-Fitted_Q-iteration_in_continuous_action-space_MDPs.html">91 nips-2007-Fitted Q-iteration in continuous action-space MDPs</a></p>
<p>8 0.46526533 <a title="98-lsi-8" href="./nips-2007-Reinforcement_Learning_in_Continuous_Action_Spaces_through_Sequential_Monte_Carlo_Methods.html">168 nips-2007-Reinforcement Learning in Continuous Action Spaces through Sequential Monte Carlo Methods</a></p>
<p>9 0.46396664 <a title="98-lsi-9" href="./nips-2007-Random_Sampling_of_States_in_Dynamic_Programming.html">162 nips-2007-Random Sampling of States in Dynamic Programming</a></p>
<p>10 0.43421254 <a title="98-lsi-10" href="./nips-2007-Receding_Horizon_Differential_Dynamic_Programming.html">163 nips-2007-Receding Horizon Differential Dynamic Programming</a></p>
<p>11 0.41289654 <a title="98-lsi-11" href="./nips-2007-Incremental_Natural_Actor-Critic_Algorithms.html">102 nips-2007-Incremental Natural Actor-Critic Algorithms</a></p>
<p>12 0.36919972 <a title="98-lsi-12" href="./nips-2007-Optimistic_Linear_Programming_gives_Logarithmic_Regret_for_Irreducible_MDPs.html">151 nips-2007-Optimistic Linear Programming gives Logarithmic Regret for Irreducible MDPs</a></p>
<p>13 0.35839874 <a title="98-lsi-13" href="./nips-2007-Stable_Dual_Dynamic_Programming.html">185 nips-2007-Stable Dual Dynamic Programming</a></p>
<p>14 0.32226494 <a title="98-lsi-14" href="./nips-2007-Combined_discriminative_and_generative_articulated_pose_and_non-rigid_shape_estimation.html">50 nips-2007-Combined discriminative and generative articulated pose and non-rigid shape estimation</a></p>
<p>15 0.31467539 <a title="98-lsi-15" href="./nips-2007-Bayes-Adaptive_POMDPs.html">30 nips-2007-Bayes-Adaptive POMDPs</a></p>
<p>16 0.3068133 <a title="98-lsi-16" href="./nips-2007-A_Risk_Minimization_Principle_for_a_Class_of_Parzen_Estimators.html">11 nips-2007-A Risk Minimization Principle for a Class of Parzen Estimators</a></p>
<p>17 0.30441594 <a title="98-lsi-17" href="./nips-2007-What_makes_some_POMDP_problems_easy_to_approximate%3F.html">215 nips-2007-What makes some POMDP problems easy to approximate?</a></p>
<p>18 0.30096781 <a title="98-lsi-18" href="./nips-2007-Markov_Chain_Monte_Carlo_with_People.html">125 nips-2007-Markov Chain Monte Carlo with People</a></p>
<p>19 0.29167092 <a title="98-lsi-19" href="./nips-2007-Discriminative_Log-Linear_Grammars_with_Latent_Variables.html">72 nips-2007-Discriminative Log-Linear Grammars with Latent Variables</a></p>
<p>20 0.28223851 <a title="98-lsi-20" href="./nips-2007-The_Epoch-Greedy_Algorithm_for_Multi-armed_Bandits_with_Side_Information.html">194 nips-2007-The Epoch-Greedy Algorithm for Multi-armed Bandits with Side Information</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2007_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(25, 0.052), (30, 0.027), (36, 0.095), (45, 0.063), (46, 0.087), (53, 0.028), (56, 0.012), (60, 0.147), (62, 0.012), (88, 0.011), (90, 0.027), (98, 0.321)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.66554826 <a title="98-lda-1" href="./nips-2007-Hierarchical_Apprenticeship_Learning_with_Application_to_Quadruped_Locomotion.html">98 nips-2007-Hierarchical Apprenticeship Learning with Application to Quadruped Locomotion</a></p>
<p>2 0.54048038 <a title="98-lda-2" href="./nips-2007-Incremental_Natural_Actor-Critic_Algorithms.html">102 nips-2007-Incremental Natural Actor-Critic Algorithms</a></p>
<p>3 0.53651702 <a title="98-lda-3" href="./nips-2007-Online_Linear_Regression_and_Its_Application_to_Model-Based_Reinforcement_Learning.html">148 nips-2007-Online Linear Regression and Its Application to Model-Based Reinforcement Learning</a></p>
<p>4 0.53440768 <a title="98-lda-4" href="./nips-2007-Modeling_Natural_Sounds_with_Modulation_Cascade_Processes.html">130 nips-2007-Modeling Natural Sounds with Modulation Cascade Processes</a></p>
<p>5 0.52717489 <a title="98-lda-5" href="./nips-2007-A_Game-Theoretic_Approach_to_Apprenticeship_Learning.html">5 nips-2007-A Game-Theoretic Approach to Apprenticeship Learning</a></p>
<p>6 0.52348685 <a title="98-lda-6" href="./nips-2007-Reinforcement_Learning_in_Continuous_Action_Spaces_through_Sequential_Monte_Carlo_Methods.html">168 nips-2007-Reinforcement Learning in Continuous Action Spaces through Sequential Monte Carlo Methods</a></p>
<p>7 0.50986135 <a title="98-lda-7" href="./nips-2007-Bayesian_Policy_Learning_with_Trans-Dimensional_MCMC.html">34 nips-2007-Bayesian Policy Learning with Trans-Dimensional MCMC</a></p>
<p>8 0.50876564 <a title="98-lda-8" href="./nips-2007-Managing_Power_Consumption_and_Performance_of_Computing_Systems_Using_Reinforcement_Learning.html">124 nips-2007-Managing Power Consumption and Performance of Computing Systems Using Reinforcement Learning</a></p>
<p>9 0.50684649 <a title="98-lda-9" href="./nips-2007-Stable_Dual_Dynamic_Programming.html">185 nips-2007-Stable Dual Dynamic Programming</a></p>
<p>10 0.50249124 <a title="98-lda-10" href="./nips-2007-Exponential_Family_Predictive_Representations_of_State.html">86 nips-2007-Exponential Family Predictive Representations of State</a></p>
<p>11 0.5013743 <a title="98-lda-11" href="./nips-2007-Fitted_Q-iteration_in_continuous_action-space_MDPs.html">91 nips-2007-Fitted Q-iteration in continuous action-space MDPs</a></p>
<p>12 0.49932015 <a title="98-lda-12" href="./nips-2007-Receding_Horizon_Differential_Dynamic_Programming.html">163 nips-2007-Receding Horizon Differential Dynamic Programming</a></p>
<p>13 0.49790487 <a title="98-lda-13" href="./nips-2007-What_makes_some_POMDP_problems_easy_to_approximate%3F.html">215 nips-2007-What makes some POMDP problems easy to approximate?</a></p>
<p>14 0.49772123 <a title="98-lda-14" href="./nips-2007-Hippocampal_Contributions_to_Control%3A_The_Third_Way.html">100 nips-2007-Hippocampal Contributions to Control: The Third Way</a></p>
<p>15 0.4957639 <a title="98-lda-15" href="./nips-2007-Learning_the_structure_of_manifolds_using_random_projections.html">116 nips-2007-Learning the structure of manifolds using random projections</a></p>
<p>16 0.49558043 <a title="98-lda-16" href="./nips-2007-Random_Projections_for_Manifold_Learning.html">161 nips-2007-Random Projections for Manifold Learning</a></p>
<p>17 0.49496484 <a title="98-lda-17" href="./nips-2007-Iterative_Non-linear_Dimensionality_Reduction_with_Manifold_Sculpting.html">107 nips-2007-Iterative Non-linear Dimensionality Reduction with Manifold Sculpting</a></p>
<p>18 0.49464235 <a title="98-lda-18" href="./nips-2007-Ensemble_Clustering_using_Semidefinite_Programming.html">80 nips-2007-Ensemble Clustering using Semidefinite Programming</a></p>
<p>19 0.49441084 <a title="98-lda-19" href="./nips-2007-Convex_Relaxations_of_Latent_Variable_Training.html">63 nips-2007-Convex Relaxations of Latent Variable Training</a></p>
<p>20 0.4923234 <a title="98-lda-20" href="./nips-2007-The_Epoch-Greedy_Algorithm_for_Multi-armed_Bandits_with_Side_Information.html">194 nips-2007-The Epoch-Greedy Algorithm for Multi-armed Bandits with Side Information</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
