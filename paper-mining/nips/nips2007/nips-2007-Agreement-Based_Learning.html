<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>22 nips-2007-Agreement-Based Learning</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-22" href="#">nips2007-22</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>22 nips-2007-Agreement-Based Learning</h1>
<br/><p>Source: <a title="nips-2007-22-pdf" href="http://papers.nips.cc/paper/3246-agreement-based-learning.pdf">pdf</a></p><p>Author: Percy Liang, Dan Klein, Michael I. Jordan</p><p>Abstract: The learning of probabilistic models with many hidden variables and nondecomposable dependencies is an important and challenging problem. In contrast to traditional approaches based on approximate inference in a single intractable model, our approach is to train a set of tractable submodels by encouraging them to agree on the hidden variables. This allows us to capture non-decomposable aspects of the data while still maintaining tractability. We propose an objective function for our approach, derive EM-style algorithms for parameter estimation, and demonstrate their effectiveness on three challenging real-world learning tasks. 1</p><p>Reference: <a title="nips-2007-22-reference" href="../nips2007_reference/nips-2007-Agreement-Based_Learning_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 In contrast to traditional approaches based on approximate inference in a single intractable model, our approach is to train a set of tractable submodels by encouraging them to agree on the hidden variables. [sent-9, score-0.661]
</p><p>2 Such models often include hidden variables, which play an important role in unsupervised learning and general missing data problems. [sent-13, score-0.152]
</p><p>3 The basic idea of our approach is to create several tractable submodels and train them jointly to agree on their hidden variables. [sent-23, score-0.655]
</p><p>4 In some applications, it is infeasible computationally to optimize the objective function; Section 4 provides two alternative objectives that lead to tractable algorithms. [sent-27, score-0.222]
</p><p>5 Section 5 demonstrates that our methods can be applied successfully to large datasets in three real world problem domains—grammar induction, word alignment, and phylogenetic hidden Markov modeling. [sent-28, score-0.384]
</p><p>6 1  2  Agreement-based learning of multiple submodels  Assume we have M (sub)models pm (x, z; θm ), m = 1, . [sent-29, score-0.754]
</p><p>7 , M , where each submodel speciﬁes a distribution over the observed data x ∈ X and some hidden state z ∈ Z. [sent-32, score-0.496]
</p><p>8 The submodels could be parameterized in completely different ways as long as they are deﬁned on the common event space X × Z. [sent-33, score-0.341]
</p><p>9 Intuitively, each submodel should capture a different aspect of the data in a tractable way. [sent-34, score-0.498]
</p><p>10 To learn these submodels, the simplest approach is to train them independently by maximizing the sum of their log-likelihoods: def  Oindep (θ) = log  pm (x, z; θm ) = m  z  log pm (x; θm ),  (1)  m  where θ = (θ1 , . [sent-35, score-1.048]
</p><p>11 , θM ) is the collective set of parameters and pm (x; θm ) = z pm (x, z; θm ) 1 is the likelihood under submodel pm . [sent-38, score-1.63]
</p><p>12 Given an input x, we can then produce an output z by combining the posteriors pm (z | x; θm ) of the trained submodels. [sent-39, score-0.473]
</p><p>13 If we view each submodel as trying to solve the same task of producing the desired posterior over z, then it seems advantageous to train the submodels jointly to encourage “agreement on z. [sent-40, score-0.823]
</p><p>14 ” We propose the following objective which realizes this insight: def  Oagree (θ) = log  pm (x, z; θm ) = z  m  pm (z | x; θm ). [sent-41, score-1.02]
</p><p>15 log pm (x; θm ) + log m  z  (2)  m  The last term rewards parameter values θ for which the submodels assign probability mass to the same z (conditioned on x); the summation over z reﬂects the fact that we do not know what z is. [sent-42, score-0.8]
</p><p>16 Then Oagree is the probability that the submodels all generate the same observed data x and the same hidden state: p(x1 = · · · = xM = x, z1 = · · · = zM ; θ). [sent-51, score-0.446]
</p><p>17 Oagree is also related to the likelihood of a proper probabilistic model pnorm , obtained by normalizing the product of the submodels, as is done in [3]. [sent-52, score-0.238]
</p><p>18 Our objective Oagree is then a lower bound on the likelihood under pnorm : def  pnorm (x; θ) =  z  pm (x, z; θm ) ≥ pm (x, z; θm )  m  x,z m  z  pm (x, z; θm ) = Oagree (θ). [sent-53, score-1.614]
</p><p>19 pm (x, z; θm )  m  (3)  m x,z  The inequality holds because the denominator of the lower bound contains additional cross terms. [sent-54, score-0.435]
</p><p>20 The bound is generally loose, but becomes tighter as each pm becomes more deterministic. [sent-55, score-0.413]
</p><p>21 Note that pnorm is distinct from the product-of-experts model [3], in which each “expert” model pm has its own set of (nuisance) hidden variables: ppoe (x) ∝ m z pm (x, z; θm ). [sent-56, score-1.033]
</p><p>22 In contrast, pnorm has one set of hidden variables z common to all submodels, which is what provides the mechanism for agreement-based learning. [sent-57, score-0.207]
</p><p>23 1  The product EM algorithm  We now derive the product EM algorithm to maximize Oagree . [sent-59, score-0.272]
</p><p>24 Simple algebra reveals that this optimization is equivalent to minimizing a KL-divergence: L(θ, q) = −KL(q(z)|| m pm (x, z; θm )) + constant, where the constant 1  To simplify notation, we consider one data point x. [sent-63, score-0.413]
</p><p>25 This quantity is minimized by setting q(z) ∝ m pm (x, z; θm ). [sent-69, score-0.413]
</p><p>26 In the (product) M-step, we optimize L with respect to θ, which decomposes into M independent objectives: L(θ, q) = m Eq log pm (x, z; θm ) + constant, where this constant does not depend on θ. [sent-70, score-0.458]
</p><p>27 Thus, our product EM algorithm differs from independent EM only in the E-step, in which the submodels are multiplied together to produce one posterior over z rather than M separate ones. [sent-72, score-0.548]
</p><p>28 Assuming that there is an efﬁcient EM algorithm for each submodel pm , there is no difﬁculty in performing the product M-step. [sent-73, score-0.94]
</p><p>29 In our applications (Section 5), each pm is composed of multinomial distributions, so the M-step simply involves computing ratios of expected counts. [sent-74, score-0.413]
</p><p>30 On the other hand, the product E-step can become intractable and we must develop approximations (Section 4). [sent-75, score-0.236]
</p><p>31 We can think of all the submodels pm as being deﬁned on a common space Z∪ = ∪m Zm , but the support of q(z) as computed in the E-step is only the intersection Z∩ = ∩m Zm . [sent-78, score-0.776]
</p><p>32 Controlling this support will be essential in developing tractable approximations (Section 4. [sent-79, score-0.156]
</p><p>33 In the general formulation, we required only that the submodels share the same event space X × Z. [sent-81, score-0.341]
</p><p>34 Now we make explicit the possibility of the submodels sharing features, which give us more structure for deriving approximations. [sent-82, score-0.341]
</p><p>35 We can now express our objective L(θ, q) (4) using (5) and (6): T θm φX (x) (Eq(z) φZ (z)) + H(q) − m  L(θ, q) = m  Am (θm ) for q ∈ Q(Z∩ ),  (7)  m  def  where Q(Z ) = {q : q(z) = 0 for z ∈ Z } is the set of distributions with support Z . [sent-86, score-0.171]
</p><p>36 Substituting µ and A∗ ∩ (µ) into (7), we obtain an objective in terms of the dual variables µ: Z def  L∗ (θ, µ) =  T θm φX (x) µ − A∗ ∩ (µ) − m Z m  Am (θm ) for µ ∈ M(Z∩ ). [sent-95, score-0.192]
</p><p>37 The mean parameters µ are exactly the z-speciﬁc expected sufﬁcient statistics computed in the product E-step. [sent-97, score-0.136]
</p><p>38 The product EM algorithm is summarized below:  E-step: M-step:  4  Product EM µ = argmaxµ ∈M(Z∩ ) {bT µ − A∗ ∩ (µ )} Z T θm = argmaxθm ∈Θm {θm φX (x)µ − Am (θm )}  Approximations  The product M-step is tractable provided that the M-step for each submodel is tractable, which is generally the case. [sent-99, score-0.77]
</p><p>39 Z  (11)  µ ∈M(Z )  Using this notation, E(bm , Zm ) is the E-step for training the m-th submodel independently using EM and E(b, Z∩ ) is the E-step of product EM. [sent-103, score-0.548]
</p><p>40 If E(bm , Zm ) is tractable and all submodels have the same dynamic programming structure (e. [sent-105, score-0.468]
</p><p>41 , if z is a tree and all features are local with respect to that tree), then E(b, Z∩ ) is also tractable: we can incorporate all the features into the same dynamic program and simply run product EM (see Section 5. [sent-107, score-0.19]
</p><p>42 However, E(b, Z∩ ) is intractable in general, owing to two complications: (1) we can sum over each Zm efﬁciently but not the intersection Z∩ ; and (2) each bm corresponds to a decomposable graphical model, but the combined b = m bm corresponds to a loopy graph. [sent-109, score-0.308]
</p><p>43 In the sequel, we describe two approximate objective functions addressing each complication, whose maximization can be carried out by performing M independent tractable E-steps. [sent-110, score-0.195]
</p><p>44 1  Domain-approximate product EM  Assume that for each submodel pm , E(b, Zm ) is tractable (see Section 5. [sent-112, score-1.047]
</p><p>45 We propose maximizing the following objective: def  L∗ (θ, µ1 , . [sent-114, score-0.137]
</p><p>46 The resulting expected sufﬁcient statistics are averaged and used in the product M-step, which breaks down into M separate M-steps. [sent-119, score-0.158]
</p><p>47 4  While we have not yet established any relationship between our approximation L∗ and the original dom objective L∗ , we can, however, relate L∗ to L∗ , which is deﬁned as an analogue of L∗ by replacing ∪ dom Z∩ with Z∪ in (10). [sent-120, score-0.31]
</p><p>48 2  Parameter-approximate product EM  Now suppose that for each submodel pm , E(bm , Z∩ ) is tractable (see Section 5. [sent-136, score-1.047]
</p><p>49 We propose maximizing the following objective: def  L∗ (θ, µ1 , . [sent-138, score-0.137]
</p><p>50 The product E-step could also be approximated by mean-ﬁeld or loopy belief propagation variants. [sent-159, score-0.157]
</p><p>51 The two approximations we developed have the advantage of permitting exact tractable solutions without resorting to expensive iterative methods which are only guaranteed to converge to a local optima. [sent-161, score-0.156]
</p><p>52 While we still lack a complete theory relating our approximations L∗ and L∗ to the original par dom objective L∗ , we can give some intuitions. [sent-162, score-0.332]
</p><p>53 Since we are operating in the space of expected sufﬁcient statistics µm , most of the information about the full posterior pm (z | x) must be captured in these statistics alone. [sent-163, score-0.44]
</p><p>54 Therefore, we expect our approximations to be accurate when each submodel has enough capacity to represent the posterior pm (z | x; θm ) as a low-variance unimodal distribution. [sent-164, score-0.88]
</p><p>55 5  Applications  We now empirically validate our algorithms on three concrete applications: grammar induction using product EM (Section 5. [sent-165, score-0.279]
</p><p>56 1), unsupervised word alignment using domain-approximate product EM (Section 5. [sent-166, score-0.475]
</p><p>57 2), and prediction of missing nucleotides in DNA sequences using parameter-approximate product EM (Section 5. [sent-167, score-0.278]
</p><p>58 5  HMM model  e1  a1  f1  e2  a2  f2  e3  a3  f3  e1  f4  f1  (a) Submodel p1  e3  a1  a4  e2  a2  a3  f2  f3  f4  alignment error rate  0. [sent-169, score-0.175]
</p><p>59 07  1  (b) Submodel p2  2  3  4  5  6  7  8  9  10  iteration  Figure 1: The two instances of IBM model 1 for word alignment are shown in (a) and (b). [sent-175, score-0.312]
</p><p>60 1  Grammar induction  Grammar induction is the problem of inducing latent syntactic structures given a set of observed sentences. [sent-178, score-0.144]
</p><p>61 There are two common types of syntactic structure (one based on word dependencies and the other based on constituent phrases), which can each be represented as a submodel. [sent-179, score-0.173]
</p><p>62 Their algorithm is a special case of our product EM algorithm, although they did not state an objective function. [sent-181, score-0.202]
</p><p>63 Since the shared hidden state is a tree structure, product EM is tractable. [sent-182, score-0.275]
</p><p>64 They show that training the two submodels to agree signiﬁcantly improves accuracy over independent training. [sent-183, score-0.422]
</p><p>65 2  Unsupervised word alignment  Word alignment is an important component of machine translation systems. [sent-186, score-0.525]
</p><p>66 The goal of unsupervised word alignment is to match the words in a source sentence to the words in the corresponding target sentence. [sent-189, score-0.362]
</p><p>67 , f|f | ); z is a set of alignment edges between positions in the English and positions in the French. [sent-196, score-0.175]
</p><p>68 Classical models for word alignment include IBM models 1 and 2 [2] and the HMM model [8]. [sent-197, score-0.352]
</p><p>69 These are asymmetric models, which means that they assign non-zero probability only to alignments in which each French word is aligned to at most one English word; we denote this set Z1 . [sent-198, score-0.248]
</p><p>70 , |e|}, corresponding to the English word (if any) that French word fj is aligned to. [sent-205, score-0.379]
</p><p>71 We have φZ (z) = 1 ij ij if and only if English word ei is aligned to French word fj and zN ULLj = 1 if and only if fj is not aligned to any English word. [sent-214, score-0.59]
</p><p>72 We can deﬁne a second submodel p2 (x, z; θ2 ) on X × Z2 by reversing the roles of English and French. [sent-217, score-0.391]
</p><p>73 We cannot use product EM algorithm to train p1 and p2 because summing over all alignments in Z∩ = Z1 ∩ Z2 is NP-hard. [sent-219, score-0.218]
</p><p>74 However, we can use domain-approximate product EM because E(b1 + b2 , Zm ) is tractable—the tractability here does not depend on decomposability of b but the asymmetric alignment structure of Zm . [sent-220, score-0.335]
</p><p>75 The concrete change from independent EM is slight: we need to only change the E-step of each pm to use the product of translation probabilities t1;ef t2;f e and change the M-step to use the average of the edge posteriors obtained from the two E-steps. [sent-221, score-0.666]
</p><p>76 Their M-step uses the elementwise product of µ1 and µ2 , whereas we use the average 1 2 (µ1 + µ2 ). [sent-225, score-0.136]
</p><p>77 Alignments are evaluated using alignment error rate (AER); see [6] for more details. [sent-230, score-0.175]
</p><p>78 We trained two instances of the HMM model [8] (English-to-French and French-to-English) using 10 iterations of domain-approximate product EM, initializing with independently trained IBM model 1 parameters. [sent-231, score-0.184]
</p><p>79 For prediction, we output alignment edges with sufﬁcient posterior probability: {(i, j) : 1 2 (µ1;ij + µ2;ij ) ≥ δ}. [sent-232, score-0.202]
</p><p>80 3  Phylogenetic HMM models  Suppose we have a set of species s ∈ S arranged in a ﬁxed phylogeny (i. [sent-235, score-0.159]
</p><p>81 Each species s is associated with a length L sequence of nucleotides ds = (ds1 , . [sent-238, score-0.26]
</p><p>82 A good phylogenetic model should take into consideration both the relationship between nucleotides of the different species at the same site and the relationship between adjacent nucleotides in the same species. [sent-243, score-0.487]
</p><p>83 Our approach is to instead create two tractable submodels and train them to agree. [sent-246, score-0.487]
</p><p>84 Deﬁne one submodel to be p1 (ds j | dsj ; θ1 )p1 (ds j+1 | ds j , ds(j+1) ; θ1 ),  p1 (x, z; θ1 ) = p1 (d; θ1 ) =  (15)  j odd s∈S s ∈C H(s)  where C H(s) is the set of children of s in the tree. [sent-247, score-0.473]
</p><p>85 The second submodel p2 is deﬁned similarly, only with the product taken over j even. [sent-248, score-0.527]
</p><p>86 Both submodels permit the same set of assignments of hidden nucleotides (Z∩ = Z1 = Z2 ). [sent-250, score-0.588]
</p><p>87 Exact product EM is not tractable since b = b1 + b2 corresponds to a graph with high tree-width. [sent-252, score-0.243]
</p><p>88 We can apply parameter-approximate product EM, in which the E-step only involves computing µm = E(2bm , Z∩ ). [sent-253, score-0.136]
</p><p>89 Our experiments used a multiple alignment consisting of L = 20, 000 consecutive sites belonging to the L1 transposons in the Cystic Fibrosis Transmembrane Conductance Regulator (CFTR) gene (chromosome 7). [sent-256, score-0.175]
</p><p>90 Eight eutherian species were arranged in the phylogeny shown in Figure 3. [sent-257, score-0.139]
</p><p>91 We trained two models using 30 iterations of parameter-approximate product EM. [sent-261, score-0.18]
</p><p>92 6  0  5  10  15  20  25  Independent EM Parameter-approximate product EM 0  iteration  5  10  15  20  25  iteration  Figure 3: The tree is the phylogeny topology used in experiments. [sent-278, score-0.223]
</p><p>93 The graphs show the prediction accuracy of independent versus agreement-based training (parameter-approximate product EM) when 20% and 50% of the observed nodes are held out. [sent-279, score-0.204]
</p><p>94 nucleotides under each model are averaged and the one with the highest posterior is chosen. [sent-280, score-0.169]
</p><p>95 Viewing these submodels as components of an overall model, our framework permits the submodels to be trained jointly without paying the computational cost associated with an actual jointly-normalized probability model. [sent-285, score-0.757]
</p><p>96 We have presented an objective function for agreement-based learning and three EM-style algorithms that maximize this objective or approximations to this objective. [sent-286, score-0.181]
</p><p>97 For word alignment and phylogenetic HMMs, our approach provides entirely new algorithms. [sent-289, score-0.454]
</p><p>98 Acknowledgments We would like to thank Adam Siepel for providing the phylogenetic data and acknowledge the support of the Defense Advanced Research Projects Agency under contract NBCHD030010. [sent-290, score-0.142]
</p><p>99 Efﬁcient approximations for learning phylogenetic HMM models from data. [sent-320, score-0.211]
</p><p>100 Combining phylogenetic and hidden Markov models in biosequence analysis. [sent-346, score-0.267]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('pm', 0.413), ('submodel', 0.391), ('submodels', 0.341), ('zm', 0.299), ('em', 0.238), ('oagree', 0.184), ('alignment', 0.175), ('phylogenetic', 0.142), ('nucleotides', 0.142), ('word', 0.137), ('product', 0.136), ('dom', 0.122), ('bm', 0.117), ('tractable', 0.107), ('hidden', 0.105), ('def', 0.105), ('pnorm', 0.102), ('par', 0.095), ('english', 0.088), ('ull', 0.082), ('az', 0.082), ('heldout', 0.071), ('hmm', 0.071), ('argmax', 0.071), ('grammar', 0.068), ('objective', 0.066), ('french', 0.065), ('siepel', 0.061), ('fj', 0.061), ('species', 0.061), ('ds', 0.057), ('induction', 0.054), ('phylogeny', 0.053), ('eq', 0.052), ('linguistics', 0.05), ('objectives', 0.049), ('approximations', 0.049), ('aligned', 0.044), ('alignments', 0.043), ('ibm', 0.042), ('azm', 0.041), ('oindep', 0.041), ('pseudolikelihood', 0.041), ('klein', 0.041), ('exponential', 0.039), ('train', 0.039), ('ascent', 0.039), ('ij', 0.038), ('translation', 0.038), ('sentences', 0.038), ('agree', 0.038), ('syntactic', 0.036), ('posteriors', 0.036), ('ri', 0.036), ('jojic', 0.036), ('mutation', 0.036), ('xm', 0.035), ('tree', 0.034), ('division', 0.034), ('maximizing', 0.032), ('berkeley', 0.032), ('aj', 0.031), ('piecewise', 0.031), ('intractable', 0.031), ('pietra', 0.03), ('ei', 0.03), ('bt', 0.03), ('language', 0.029), ('california', 0.028), ('liang', 0.027), ('unsupervised', 0.027), ('posterior', 0.027), ('auxiliary', 0.027), ('permits', 0.026), ('composite', 0.026), ('arranged', 0.025), ('held', 0.025), ('odd', 0.025), ('family', 0.025), ('jointly', 0.025), ('asymmetric', 0.024), ('maximized', 0.024), ('sup', 0.024), ('trained', 0.024), ('sentence', 0.023), ('log', 0.023), ('separate', 0.022), ('independent', 0.022), ('intersection', 0.022), ('inequality', 0.022), ('dual', 0.021), ('training', 0.021), ('concrete', 0.021), ('loopy', 0.021), ('variational', 0.021), ('sutton', 0.02), ('develop', 0.02), ('dynamic', 0.02), ('models', 0.02), ('duality', 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="22-tfidf-1" href="./nips-2007-Agreement-Based_Learning.html">22 nips-2007-Agreement-Based Learning</a></p>
<p>Author: Percy Liang, Dan Klein, Michael I. Jordan</p><p>Abstract: The learning of probabilistic models with many hidden variables and nondecomposable dependencies is an important and challenging problem. In contrast to traditional approaches based on approximate inference in a single intractable model, our approach is to train a set of tractable submodels by encouraging them to agree on the hidden variables. This allows us to capture non-decomposable aspects of the data while still maintaining tractability. We propose an objective function for our approach, derive EM-style algorithms for parameter estimation, and demonstrate their effectiveness on three challenging real-world learning tasks. 1</p><p>2 0.24789694 <a title="22-tfidf-2" href="./nips-2007-Expectation_Maximization_and_Posterior_Constraints.html">84 nips-2007-Expectation Maximization and Posterior Constraints</a></p>
<p>Author: Kuzman Ganchev, Ben Taskar, João Gama</p><p>Abstract: The expectation maximization (EM) algorithm is a widely used maximum likelihood estimation procedure for statistical models when the values of some of the variables in the model are not observed. Very often, however, our aim is primarily to ﬁnd a model that assigns values to the latent variables that have intended meaning for our data and maximizing expected likelihood only sometimes accomplishes this. Unfortunately, it is typically difﬁcult to add even simple a-priori information about latent variables in graphical models without making the models overly complex or intractable. In this paper, we present an efﬁcient, principled way to inject rich constraints on the posteriors of latent variables into the EM algorithm. Our method can be used to learn tractable graphical models that satisfy additional, otherwise intractable constraints. Focusing on clustering and the alignment problem for statistical machine translation, we show that simple, intuitive posterior constraints can greatly improve the performance over standard baselines and be competitive with more complex, intractable models. 1</p><p>3 0.16628195 <a title="22-tfidf-3" href="./nips-2007-Density_Estimation_under_Independent_Similarly_Distributed_Sampling_Assumptions.html">66 nips-2007-Density Estimation under Independent Similarly Distributed Sampling Assumptions</a></p>
<p>Author: Tony Jebara, Yingbo Song, Kapil Thadani</p><p>Abstract: A method is proposed for semiparametric estimation where parametric and nonparametric criteria are exploited in density estimation and unsupervised learning. This is accomplished by making sampling assumptions on a dataset that smoothly interpolate between the extreme of independently distributed (or id) sample data (as in nonparametric kernel density estimators) to the extreme of independent identically distributed (or iid) sample data. This article makes independent similarly distributed (or isd) sampling assumptions and interpolates between these two using a scalar parameter. The parameter controls a Bhattacharyya afﬁnity penalty between pairs of distributions on samples. Surprisingly, the isd method maintains certain consistency and unimodality properties akin to maximum likelihood estimation. The proposed isd scheme is an alternative for handling nonstationarity in data without making drastic hidden variable assumptions which often make estimation difﬁcult and laden with local optima. Experiments in density estimation on a variety of datasets conﬁrm the value of isd over iid estimation, id estimation and mixture modeling.</p><p>4 0.16393445 <a title="22-tfidf-4" href="./nips-2007-HM-BiTAM%3A_Bilingual_Topic_Exploration%2C_Word_Alignment%2C_and_Translation.html">95 nips-2007-HM-BiTAM: Bilingual Topic Exploration, Word Alignment, and Translation</a></p>
<p>Author: Bing Zhao, Eric P. Xing</p><p>Abstract: We present a novel paradigm for statistical machine translation (SMT), based on a joint modeling of word alignment and the topical aspects underlying bilingual document-pairs, via a hidden Markov Bilingual Topic AdMixture (HM-BiTAM). In this paradigm, parallel sentence-pairs from a parallel document-pair are coupled via a certain semantic-ﬂow, to ensure coherence of topical context in the alignment of mapping words between languages, likelihood-based training of topic-dependent translational lexicons, as well as in the inference of topic representations in each language. The learned HM-BiTAM can not only display topic patterns like methods such as LDA [1], but now for bilingual corpora; it also offers a principled way of inferring optimal translation using document context. Our method integrates the conventional model of HMM — a key component for most of the state-of-the-art SMT systems, with the recently proposed BiTAM model [10]; we report an extensive empirical analysis (in many ways complementary to the description-oriented [10]) of our method in three aspects: bilingual topic representation, word alignment, and translation.</p><p>5 0.1600063 <a title="22-tfidf-5" href="./nips-2007-Convex_Relaxations_of_Latent_Variable_Training.html">63 nips-2007-Convex Relaxations of Latent Variable Training</a></p>
<p>Author: Yuhong Guo, Dale Schuurmans</p><p>Abstract: We investigate a new, convex relaxation of an expectation-maximization (EM) variant that approximates a standard objective while eliminating local minima. First, a cautionary result is presented, showing that any convex relaxation of EM over hidden variables must give trivial results if any dependence on the missing values is retained. Although this appears to be a strong negative outcome, we then demonstrate how the problem can be bypassed by using equivalence relations instead of value assignments over hidden variables. In particular, we develop new algorithms for estimating exponential conditional models that only require equivalence relation information over the variable values. This reformulation leads to an exact expression for EM variants in a wide range of problems. We then develop a semideﬁnite relaxation that yields global training by eliminating local minima. 1</p><p>6 0.096562736 <a title="22-tfidf-6" href="./nips-2007-A_Probabilistic_Approach_to_Language_Change.html">9 nips-2007-A Probabilistic Approach to Language Change</a></p>
<p>7 0.09510348 <a title="22-tfidf-7" href="./nips-2007-A_Bayesian_LDA-based_model_for_semi-supervised_part-of-speech_tagging.html">2 nips-2007-A Bayesian LDA-based model for semi-supervised part-of-speech tagging</a></p>
<p>8 0.083823226 <a title="22-tfidf-8" href="./nips-2007-Fast_Variational_Inference_for_Large-scale_Internet_Diagnosis.html">87 nips-2007-Fast Variational Inference for Large-scale Internet Diagnosis</a></p>
<p>9 0.065183446 <a title="22-tfidf-9" href="./nips-2007-Stable_Dual_Dynamic_Programming.html">185 nips-2007-Stable Dual Dynamic Programming</a></p>
<p>10 0.058938969 <a title="22-tfidf-10" href="./nips-2007-Neural_characterization_in_partially_observed_populations_of_spiking_neurons.html">140 nips-2007-Neural characterization in partially observed populations of spiking neurons</a></p>
<p>11 0.057967246 <a title="22-tfidf-11" href="./nips-2007-Random_Features_for_Large-Scale_Kernel_Machines.html">160 nips-2007-Random Features for Large-Scale Kernel Machines</a></p>
<p>12 0.052357726 <a title="22-tfidf-12" href="./nips-2007-Unconstrained_On-line_Handwriting_Recognition_with_Recurrent_Neural_Networks.html">210 nips-2007-Unconstrained On-line Handwriting Recognition with Recurrent Neural Networks</a></p>
<p>13 0.05046922 <a title="22-tfidf-13" href="./nips-2007-Efficient_Bayesian_Inference_for_Dynamically_Changing_Graphs.html">75 nips-2007-Efficient Bayesian Inference for Dynamically Changing Graphs</a></p>
<p>14 0.050297737 <a title="22-tfidf-14" href="./nips-2007-Bayesian_Policy_Learning_with_Trans-Dimensional_MCMC.html">34 nips-2007-Bayesian Policy Learning with Trans-Dimensional MCMC</a></p>
<p>15 0.049125139 <a title="22-tfidf-15" href="./nips-2007-The_Infinite_Markov_Model.html">197 nips-2007-The Infinite Markov Model</a></p>
<p>16 0.048633233 <a title="22-tfidf-16" href="./nips-2007-Testing_for_Homogeneity_with_Kernel_Fisher_Discriminant_Analysis.html">192 nips-2007-Testing for Homogeneity with Kernel Fisher Discriminant Analysis</a></p>
<p>17 0.047470395 <a title="22-tfidf-17" href="./nips-2007-A_Bayesian_Framework_for_Cross-Situational_Word-Learning.html">1 nips-2007-A Bayesian Framework for Cross-Situational Word-Learning</a></p>
<p>18 0.046121467 <a title="22-tfidf-18" href="./nips-2007-Variational_inference_for_Markov_jump_processes.html">214 nips-2007-Variational inference for Markov jump processes</a></p>
<p>19 0.043490943 <a title="22-tfidf-19" href="./nips-2007-How_SVMs_can_estimate_quantiles_and_the_median.html">101 nips-2007-How SVMs can estimate quantiles and the median</a></p>
<p>20 0.043181479 <a title="22-tfidf-20" href="./nips-2007-Multi-task_Gaussian_Process_Prediction.html">135 nips-2007-Multi-task Gaussian Process Prediction</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2007_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.164), (1, 0.029), (2, -0.063), (3, -0.138), (4, 0.022), (5, -0.147), (6, -0.015), (7, -0.082), (8, -0.074), (9, -0.008), (10, 0.073), (11, -0.037), (12, -0.029), (13, -0.21), (14, -0.023), (15, -0.242), (16, -0.21), (17, 0.208), (18, -0.051), (19, 0.087), (20, -0.015), (21, -0.13), (22, -0.14), (23, 0.016), (24, 0.036), (25, 0.05), (26, 0.017), (27, -0.136), (28, 0.019), (29, 0.08), (30, -0.142), (31, 0.04), (32, 0.161), (33, -0.097), (34, -0.117), (35, 0.147), (36, -0.096), (37, -0.038), (38, 0.061), (39, 0.07), (40, 0.067), (41, -0.09), (42, 0.054), (43, -0.049), (44, -0.01), (45, 0.042), (46, -0.01), (47, 0.0), (48, 0.018), (49, -0.003)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96298343 <a title="22-lsi-1" href="./nips-2007-Agreement-Based_Learning.html">22 nips-2007-Agreement-Based Learning</a></p>
<p>Author: Percy Liang, Dan Klein, Michael I. Jordan</p><p>Abstract: The learning of probabilistic models with many hidden variables and nondecomposable dependencies is an important and challenging problem. In contrast to traditional approaches based on approximate inference in a single intractable model, our approach is to train a set of tractable submodels by encouraging them to agree on the hidden variables. This allows us to capture non-decomposable aspects of the data while still maintaining tractability. We propose an objective function for our approach, derive EM-style algorithms for parameter estimation, and demonstrate their effectiveness on three challenging real-world learning tasks. 1</p><p>2 0.80029637 <a title="22-lsi-2" href="./nips-2007-Expectation_Maximization_and_Posterior_Constraints.html">84 nips-2007-Expectation Maximization and Posterior Constraints</a></p>
<p>Author: Kuzman Ganchev, Ben Taskar, João Gama</p><p>Abstract: The expectation maximization (EM) algorithm is a widely used maximum likelihood estimation procedure for statistical models when the values of some of the variables in the model are not observed. Very often, however, our aim is primarily to ﬁnd a model that assigns values to the latent variables that have intended meaning for our data and maximizing expected likelihood only sometimes accomplishes this. Unfortunately, it is typically difﬁcult to add even simple a-priori information about latent variables in graphical models without making the models overly complex or intractable. In this paper, we present an efﬁcient, principled way to inject rich constraints on the posteriors of latent variables into the EM algorithm. Our method can be used to learn tractable graphical models that satisfy additional, otherwise intractable constraints. Focusing on clustering and the alignment problem for statistical machine translation, we show that simple, intuitive posterior constraints can greatly improve the performance over standard baselines and be competitive with more complex, intractable models. 1</p><p>3 0.63347036 <a title="22-lsi-3" href="./nips-2007-HM-BiTAM%3A_Bilingual_Topic_Exploration%2C_Word_Alignment%2C_and_Translation.html">95 nips-2007-HM-BiTAM: Bilingual Topic Exploration, Word Alignment, and Translation</a></p>
<p>Author: Bing Zhao, Eric P. Xing</p><p>Abstract: We present a novel paradigm for statistical machine translation (SMT), based on a joint modeling of word alignment and the topical aspects underlying bilingual document-pairs, via a hidden Markov Bilingual Topic AdMixture (HM-BiTAM). In this paradigm, parallel sentence-pairs from a parallel document-pair are coupled via a certain semantic-ﬂow, to ensure coherence of topical context in the alignment of mapping words between languages, likelihood-based training of topic-dependent translational lexicons, as well as in the inference of topic representations in each language. The learned HM-BiTAM can not only display topic patterns like methods such as LDA [1], but now for bilingual corpora; it also offers a principled way of inferring optimal translation using document context. Our method integrates the conventional model of HMM — a key component for most of the state-of-the-art SMT systems, with the recently proposed BiTAM model [10]; we report an extensive empirical analysis (in many ways complementary to the description-oriented [10]) of our method in three aspects: bilingual topic representation, word alignment, and translation.</p><p>4 0.61557394 <a title="22-lsi-4" href="./nips-2007-Convex_Relaxations_of_Latent_Variable_Training.html">63 nips-2007-Convex Relaxations of Latent Variable Training</a></p>
<p>Author: Yuhong Guo, Dale Schuurmans</p><p>Abstract: We investigate a new, convex relaxation of an expectation-maximization (EM) variant that approximates a standard objective while eliminating local minima. First, a cautionary result is presented, showing that any convex relaxation of EM over hidden variables must give trivial results if any dependence on the missing values is retained. Although this appears to be a strong negative outcome, we then demonstrate how the problem can be bypassed by using equivalence relations instead of value assignments over hidden variables. In particular, we develop new algorithms for estimating exponential conditional models that only require equivalence relation information over the variable values. This reformulation leads to an exact expression for EM variants in a wide range of problems. We then develop a semideﬁnite relaxation that yields global training by eliminating local minima. 1</p><p>5 0.61485678 <a title="22-lsi-5" href="./nips-2007-Density_Estimation_under_Independent_Similarly_Distributed_Sampling_Assumptions.html">66 nips-2007-Density Estimation under Independent Similarly Distributed Sampling Assumptions</a></p>
<p>Author: Tony Jebara, Yingbo Song, Kapil Thadani</p><p>Abstract: A method is proposed for semiparametric estimation where parametric and nonparametric criteria are exploited in density estimation and unsupervised learning. This is accomplished by making sampling assumptions on a dataset that smoothly interpolate between the extreme of independently distributed (or id) sample data (as in nonparametric kernel density estimators) to the extreme of independent identically distributed (or iid) sample data. This article makes independent similarly distributed (or isd) sampling assumptions and interpolates between these two using a scalar parameter. The parameter controls a Bhattacharyya afﬁnity penalty between pairs of distributions on samples. Surprisingly, the isd method maintains certain consistency and unimodality properties akin to maximum likelihood estimation. The proposed isd scheme is an alternative for handling nonstationarity in data without making drastic hidden variable assumptions which often make estimation difﬁcult and laden with local optima. Experiments in density estimation on a variety of datasets conﬁrm the value of isd over iid estimation, id estimation and mixture modeling.</p><p>6 0.48008531 <a title="22-lsi-6" href="./nips-2007-A_Probabilistic_Approach_to_Language_Change.html">9 nips-2007-A Probabilistic Approach to Language Change</a></p>
<p>7 0.42436704 <a title="22-lsi-7" href="./nips-2007-Fast_Variational_Inference_for_Large-scale_Internet_Diagnosis.html">87 nips-2007-Fast Variational Inference for Large-scale Internet Diagnosis</a></p>
<p>8 0.31425038 <a title="22-lsi-8" href="./nips-2007-A_Bayesian_Framework_for_Cross-Situational_Word-Learning.html">1 nips-2007-A Bayesian Framework for Cross-Situational Word-Learning</a></p>
<p>9 0.31300318 <a title="22-lsi-9" href="./nips-2007-Estimating_divergence_functionals_and_the_likelihood_ratio_by_penalized_convex_risk_minimization.html">82 nips-2007-Estimating divergence functionals and the likelihood ratio by penalized convex risk minimization</a></p>
<p>10 0.30535978 <a title="22-lsi-10" href="./nips-2007-Stable_Dual_Dynamic_Programming.html">185 nips-2007-Stable Dual Dynamic Programming</a></p>
<p>11 0.29746303 <a title="22-lsi-11" href="./nips-2007-Unconstrained_On-line_Handwriting_Recognition_with_Recurrent_Neural_Networks.html">210 nips-2007-Unconstrained On-line Handwriting Recognition with Recurrent Neural Networks</a></p>
<p>12 0.28693774 <a title="22-lsi-12" href="./nips-2007-A_Bayesian_LDA-based_model_for_semi-supervised_part-of-speech_tagging.html">2 nips-2007-A Bayesian LDA-based model for semi-supervised part-of-speech tagging</a></p>
<p>13 0.25877535 <a title="22-lsi-13" href="./nips-2007-Collapsed_Variational_Inference_for_HDP.html">47 nips-2007-Collapsed Variational Inference for HDP</a></p>
<p>14 0.25102937 <a title="22-lsi-14" href="./nips-2007-Neural_characterization_in_partially_observed_populations_of_spiking_neurons.html">140 nips-2007-Neural characterization in partially observed populations of spiking neurons</a></p>
<p>15 0.24123439 <a title="22-lsi-15" href="./nips-2007-Convex_Clustering_with_Exemplar-Based_Models.html">61 nips-2007-Convex Clustering with Exemplar-Based Models</a></p>
<p>16 0.23829021 <a title="22-lsi-16" href="./nips-2007-Discriminative_Keyword_Selection_Using_Support_Vector_Machines.html">71 nips-2007-Discriminative Keyword Selection Using Support Vector Machines</a></p>
<p>17 0.23527253 <a title="22-lsi-17" href="./nips-2007-Learning_with_Tree-Averaged_Densities_and_Distributions.html">119 nips-2007-Learning with Tree-Averaged Densities and Distributions</a></p>
<p>18 0.23520567 <a title="22-lsi-18" href="./nips-2007-Sparse_Overcomplete_Latent_Variable_Decomposition_of_Counts_Data.html">181 nips-2007-Sparse Overcomplete Latent Variable Decomposition of Counts Data</a></p>
<p>19 0.21510608 <a title="22-lsi-19" href="./nips-2007-Progressive_mixture_rules_are_deviation_suboptimal.html">159 nips-2007-Progressive mixture rules are deviation suboptimal</a></p>
<p>20 0.20864169 <a title="22-lsi-20" href="./nips-2007-Variational_inference_for_Markov_jump_processes.html">214 nips-2007-Variational inference for Markov jump processes</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2007_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.035), (13, 0.479), (16, 0.015), (21, 0.033), (31, 0.022), (34, 0.021), (35, 0.021), (47, 0.05), (49, 0.019), (83, 0.129), (85, 0.025), (87, 0.011), (90, 0.049)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.94758719 <a title="22-lda-1" href="./nips-2007-A_configurable_analog_VLSI_neural_network_with_spiking_neurons_and_self-regulating_plastic_synapses.html">14 nips-2007-A configurable analog VLSI neural network with spiking neurons and self-regulating plastic synapses</a></p>
<p>Author: Massimiliano Giulioni, Mario Pannunzi, Davide Badoni, Vittorio Dante, Paolo D. Giudice</p><p>Abstract: We summarize the implementation of an analog VLSI chip hosting a network of 32 integrate-and-ﬁre (IF) neurons with spike-frequency adaptation and 2,048 Hebbian plastic bistable spike-driven stochastic synapses endowed with a selfregulating mechanism which stops unnecessary synaptic changes. The synaptic matrix can be ﬂexibly conﬁgured and provides both recurrent and AER-based connectivity with external, AER compliant devices. We demonstrate the ability of the network to efﬁciently classify overlapping patterns, thanks to the self-regulating mechanism.</p><p>2 0.92520416 <a title="22-lda-2" href="./nips-2007-Temporal_Difference_Updating_without_a_Learning_Rate.html">191 nips-2007-Temporal Difference Updating without a Learning Rate</a></p>
<p>Author: Marcus Hutter, Shane Legg</p><p>Abstract: We derive an equation for temporal difference learning from statistical principles. Speciﬁcally, we start with the variational principle and then bootstrap to produce an updating rule for discounted state value estimates. The resulting equation is similar to the standard equation for temporal difference learning with eligibility traces, so called TD(λ), however it lacks the parameter α that speciﬁes the learning rate. In the place of this free parameter there is now an equation for the learning rate that is speciﬁc to each state transition. We experimentally test this new learning rule against TD(λ) and ﬁnd that it offers superior performance in various settings. Finally, we make some preliminary investigations into how to extend our new temporal difference algorithm to reinforcement learning. To do this we combine our update equation with both Watkins’ Q(λ) and Sarsa(λ) and ﬁnd that it again offers superior performance without a learning rate parameter. 1</p><p>3 0.91167092 <a title="22-lda-3" href="./nips-2007-Discriminative_Keyword_Selection_Using_Support_Vector_Machines.html">71 nips-2007-Discriminative Keyword Selection Using Support Vector Machines</a></p>
<p>Author: Fred Richardson, William M. Campbell</p><p>Abstract: Many tasks in speech processing involve classiﬁcation of long term characteristics of a speech segment such as language, speaker, dialect, or topic. A natural technique for determining these characteristics is to ﬁrst convert the input speech into a sequence of tokens such as words, phones, etc. From these tokens, we can then look for distinctive sequences, keywords, that characterize the speech. In many applications, a set of distinctive keywords may not be known a priori. In this case, an automatic method of building up keywords from short context units such as phones is desirable. We propose a method for the construction of keywords based upon Support Vector Machines. We cast the problem of keyword selection as a feature selection problem for n-grams of phones. We propose an alternating ﬁlter-wrapper method that builds successively longer keywords. Application of this method to language recognition and topic recognition tasks shows that the technique produces interesting and signiﬁcant qualitative and quantitative results.</p><p>same-paper 4 0.88686675 <a title="22-lda-4" href="./nips-2007-Agreement-Based_Learning.html">22 nips-2007-Agreement-Based Learning</a></p>
<p>Author: Percy Liang, Dan Klein, Michael I. Jordan</p><p>Abstract: The learning of probabilistic models with many hidden variables and nondecomposable dependencies is an important and challenging problem. In contrast to traditional approaches based on approximate inference in a single intractable model, our approach is to train a set of tractable submodels by encouraging them to agree on the hidden variables. This allows us to capture non-decomposable aspects of the data while still maintaining tractability. We propose an objective function for our approach, derive EM-style algorithms for parameter estimation, and demonstrate their effectiveness on three challenging real-world learning tasks. 1</p><p>5 0.84494984 <a title="22-lda-5" href="./nips-2007-Convex_Learning_with_Invariances.html">62 nips-2007-Convex Learning with Invariances</a></p>
<p>Author: Choon H. Teo, Amir Globerson, Sam T. Roweis, Alex J. Smola</p><p>Abstract: Incorporating invariances into a learning algorithm is a common problem in machine learning. We provide a convex formulation which can deal with arbitrary loss functions and arbitrary losses. In addition, it is a drop-in replacement for most optimization algorithms for kernels, including solvers of the SVMStruct family. The advantage of our setting is that it relies on column generation instead of modifying the underlying optimization problem directly. 1</p><p>6 0.67184252 <a title="22-lda-6" href="./nips-2007-HM-BiTAM%3A_Bilingual_Topic_Exploration%2C_Word_Alignment%2C_and_Translation.html">95 nips-2007-HM-BiTAM: Bilingual Topic Exploration, Word Alignment, and Translation</a></p>
<p>7 0.6193471 <a title="22-lda-7" href="./nips-2007-Expectation_Maximization_and_Posterior_Constraints.html">84 nips-2007-Expectation Maximization and Posterior Constraints</a></p>
<p>8 0.59930754 <a title="22-lda-8" href="./nips-2007-Learning_to_classify_complex_patterns_using_a_VLSI_network_of_spiking_neurons.html">117 nips-2007-Learning to classify complex patterns using a VLSI network of spiking neurons</a></p>
<p>9 0.56288129 <a title="22-lda-9" href="./nips-2007-Incremental_Natural_Actor-Critic_Algorithms.html">102 nips-2007-Incremental Natural Actor-Critic Algorithms</a></p>
<p>10 0.53837377 <a title="22-lda-10" href="./nips-2007-A_Probabilistic_Approach_to_Language_Change.html">9 nips-2007-A Probabilistic Approach to Language Change</a></p>
<p>11 0.53175884 <a title="22-lda-11" href="./nips-2007-Theoretical_Analysis_of_Learning_with_Reward-Modulated_Spike-Timing-Dependent_Plasticity.html">205 nips-2007-Theoretical Analysis of Learning with Reward-Modulated Spike-Timing-Dependent Plasticity</a></p>
<p>12 0.52602792 <a title="22-lda-12" href="./nips-2007-Hierarchical_Apprenticeship_Learning_with_Application_to_Quadruped_Locomotion.html">98 nips-2007-Hierarchical Apprenticeship Learning with Application to Quadruped Locomotion</a></p>
<p>13 0.51695603 <a title="22-lda-13" href="./nips-2007-Optimistic_Linear_Programming_gives_Logarithmic_Regret_for_Irreducible_MDPs.html">151 nips-2007-Optimistic Linear Programming gives Logarithmic Regret for Irreducible MDPs</a></p>
<p>14 0.51189137 <a title="22-lda-14" href="./nips-2007-Exponential_Family_Predictive_Representations_of_State.html">86 nips-2007-Exponential Family Predictive Representations of State</a></p>
<p>15 0.50836504 <a title="22-lda-15" href="./nips-2007-Simplified_Rules_and_Theoretical_Analysis_for_Information_Bottleneck_Optimization_and_PCA_with_Spiking_Neurons.html">177 nips-2007-Simplified Rules and Theoretical Analysis for Information Bottleneck Optimization and PCA with Spiking Neurons</a></p>
<p>16 0.50794309 <a title="22-lda-16" href="./nips-2007-Convex_Relaxations_of_Latent_Variable_Training.html">63 nips-2007-Convex Relaxations of Latent Variable Training</a></p>
<p>17 0.50783193 <a title="22-lda-17" href="./nips-2007-Efficient_Convex_Relaxation_for_Transductive_Support_Vector_Machine.html">76 nips-2007-Efficient Convex Relaxation for Transductive Support Vector Machine</a></p>
<p>18 0.49776992 <a title="22-lda-18" href="./nips-2007-Bundle_Methods_for_Machine_Learning.html">40 nips-2007-Bundle Methods for Machine Learning</a></p>
<p>19 0.49467614 <a title="22-lda-19" href="./nips-2007-Learning_with_Transformation_Invariant_Kernels.html">118 nips-2007-Learning with Transformation Invariant Kernels</a></p>
<p>20 0.49396315 <a title="22-lda-20" href="./nips-2007-An_Analysis_of_Inference_with_the_Universum.html">24 nips-2007-An Analysis of Inference with the Universum</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
