<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>173 nips-2007-Second Order Bilinear Discriminant Analysis for single trial EEG analysis</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-173" href="#">nips2007-173</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>173 nips-2007-Second Order Bilinear Discriminant Analysis for single trial EEG analysis</h1>
<br/><p>Source: <a title="nips-2007-173-pdf" href="http://papers.nips.cc/paper/3236-second-order-bilinear-discriminant-analysis-for-single-trial-eeg-analysis.pdf">pdf</a></p><p>Author: Christoforos Christoforou, Paul Sajda, Lucas C. Parra</p><p>Abstract: Traditional analysis methods for single-trial classiﬁcation of electroencephalography (EEG) focus on two types of paradigms: phase locked methods, in which the amplitude of the signal is used as the feature for classiﬁcation, e.g. event related potentials; and second order methods, in which the feature of interest is the power of the signal, e.g. event related (de)synchronization. The procedure for deciding which paradigm to use is ad hoc and is typically driven by knowledge of the underlying neurophysiology. Here we propose a principled method, based on a bilinear model, in which the algorithm simultaneously learns the best ﬁrst and second order spatial and temporal features for classiﬁcation of EEG. The method is demonstrated on simulated data as well as on EEG taken from a benchmark data used to test classiﬁcation algorithms for brain computer interfaces. 1 1.1</p><p>Reference: <a title="nips-2007-173-reference" href="../nips2007_reference/nips-2007-Second_Order_Bilinear_Discriminant_Analysis_for_single_trial_EEG_analysis_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract Traditional analysis methods for single-trial classiﬁcation of electroencephalography (EEG) focus on two types of paradigms: phase locked methods, in which the amplitude of the signal is used as the feature for classiﬁcation, e. [sent-7, score-0.484]
</p><p>2 event related potentials; and second order methods, in which the feature of interest is the power of the signal, e. [sent-9, score-0.115]
</p><p>3 The procedure for deciding which paradigm to use is ad hoc and is typically driven by knowledge of the underlying neurophysiology. [sent-12, score-0.043]
</p><p>4 Here we propose a principled method, based on a bilinear model, in which the algorithm simultaneously learns the best ﬁrst and second order spatial and temporal features for classiﬁcation of EEG. [sent-13, score-0.507]
</p><p>5 The method is demonstrated on simulated data as well as on EEG taken from a benchmark data used to test classiﬁcation algorithms for brain computer interfaces. [sent-14, score-0.237]
</p><p>6 1  Introduction Utility of discriminant analysis in EEG  Brain computer interface (BCI) algorithms [1][2][3][4] aim to decode brain activity, on a singletrial basis, in order to provide a direct control pathway between a user’s intentions and a computer. [sent-16, score-0.218]
</p><p>7 Single-trial discriminant analysis has also been used as a research tool to study the neural correlates of behavior. [sent-19, score-0.155]
</p><p>8 By extracting activity that differs maximally between two experimental conditions, the typically low signal-noise ratio of EEG can be overcome. [sent-20, score-0.154]
</p><p>9 The resulting discriminant components can be used to identify the spatial origin and time course of stimulus/response speciﬁc activity, while the improved SNR can be leveraged to correlate variability of neural activity across trials to behavioral variability and behavioral performance [7, 5]. [sent-21, score-0.582]
</p><p>10 In essence, discriminant analysis adds to the existing set of multi-variate statistical tools commonly used in neuroscience research (ANOVA, Hoteling T 2 , Wilks’ Λ test). [sent-22, score-0.155]
</p><p>11 2  Linear and quadratic approaches  In EEG the signal-to-noise ratio of individual channels is low, often at -20dB or less. [sent-24, score-0.232]
</p><p>12 To overcome this limitation, all analysis methods perform some form of averaging, either across repeated trials, across time, or across electrodes. [sent-25, score-0.117]
</p><p>13 Traditional EEG analysis averages signals across many repeated trials for individual electrodes. [sent-26, score-0.115]
</p><p>14 A conventional method is to average the measured potentials following stimulus presentation, thereby canceling uncorrelated noise that is not reproducible from one trial to the next. [sent-27, score-0.202]
</p><p>15 This averaged activity, called an event related potential (ERP), captures activity that is time-locked to the stimulus presentation but cancels evoked oscillatory activity that is not locked in phase to the timing of the stimulus. [sent-28, score-0.986]
</p><p>16 Alternatively, many studies compute the oscillatory activity in speciﬁc frequency bands by ﬁltering and squaring the signal prior to averaging. [sent-29, score-0.479]
</p><p>17 Thus, changes in oscillatory activity are termed event related synchronization or desynchronization (ERS/ERD). [sent-30, score-0.308]
</p><p>18 First order methods include temporal ﬁltering + thresholding [2], hierarchical linear classiﬁers [5] and bilinear discriminant analysis [8, 9]. [sent-32, score-0.5]
</p><p>19 Second order methods include the logistic regression with a quadratic term [11] and the well known common spatial patterns method (CSP) [10] and its variants: common spatio-spectral patterns (CSSP)[12], and common sparse spectral spatial patterns (CSSSP)[13] . [sent-33, score-0.412]
</p><p>20 Choosing what kind of features to use traditionally has been an ad hoc process motivated by knowledge of the underlying neurophysiology and task. [sent-34, score-0.085]
</p><p>21 Instead it would be desirable for the analysis method to extract the relevant neurophysiological activity de novo with minimal prior expectations. [sent-36, score-0.205]
</p><p>22 In this paper we present a new framework that combines both the ﬁrst order features and the second order features in the analysis of EEG. [sent-37, score-0.084]
</p><p>23 We use a bilinear formulation which can simultaneously extract spatial linear components as well as temporal (ﬁltered) features. [sent-38, score-0.554]
</p><p>24 1  Second order bilinear discriminant analysis Problem setting  Given a set of sample points D = {Xn , yn }N , X ∈ RD × T , y ∈ {−1, 1} , where Xn corresponds n=1 to the EEG signal of D channels and T sample points and yn indicate the class that corresponds to one of two conditions (e. [sent-40, score-0.907]
</p><p>25 right or left hand imaginary movement, stimulus versus control conditions, etc. [sent-42, score-0.049]
</p><p>26 ), the task is then to predict the class label y for an unobserved trial X. [sent-43, score-0.094]
</p><p>27 2  Second order bilinear model  Deﬁne a function, f (X; θ) = C Trace(UT XV) + (1 − C) Trace(ΛAT (XB)(XB)T A)  (1)  where θ = {U ∈ RD × R , V ∈ RT × R , A ∈ RD × K B ∈ RT × T } are the parameters of the model, Λ ∈ diag({−1, 1}) a given diagonal matrix with elements {−1, 1} and C ∈ [0, 1]. [sent-45, score-0.265]
</p><p>28 1  Interpretation of the model  The ﬁrst term of the equation (1) can be interpreted as a spatio-temporal projection of the signal, under the bilinear model, and captures the ﬁrst order statistics of the signal. [sent-48, score-0.346]
</p><p>29 Speciﬁcally, the columns ur of U represent R linear projections in space (rows of X). [sent-49, score-0.178]
</p><p>30 Similarly, each of the R columns of vk in matrix V represent linear projections in time (columns of X). [sent-50, score-0.106]
</p><p>31 By re-writing the term as: Trace(UT XV) = Trace(VUT X) = Trace(WT X) (3) T where we deﬁned W = UV , it is easy to see that the bilinear projection is a linear combination of elements of X with the rank − R constrained on W. [sent-51, score-0.275]
</p><p>32 This expression is linear in X and thus captures directly the amplitude of the signal directly. [sent-52, score-0.298]
</p><p>33 In particular, the polarity of the signal (positive evoked response versus negative evoked response) will contribute signiﬁcantly to discrimination if it is consistent across trials. [sent-53, score-0.465]
</p><p>34 This term, therefore, captures phase locked event related potentials in the EEG signal. [sent-54, score-0.451]
</p><p>35 The second term of equation (1), is a projection of the power of the ﬁltered signal, which captures the second order statistics of the signal. [sent-55, score-0.172]
</p><p>36 As before, each column of matrix A and B, represent components that project the data in space and time respectively. [sent-56, score-0.078]
</p><p>37 Depending on the structure one enforces in matrix B different interpretations of the model can be archived. [sent-57, score-0.04]
</p><p>38 In the general case where no structure on B is assumed, the model captures a linear combination of the elements of a rank − T second order matrix approximation of the signal Σ = XB(XB)T . [sent-58, score-0.252]
</p><p>39 In the case where Toeplitz structure is enforced on B, then B deﬁnes a temporal ﬁlter on the signal and the model captures the linear combination of the power of the second order matrix of the ﬁltered signal. [sent-59, score-0.464]
</p><p>40 For example if B is ﬁxed to a Toeplitz matrix with coefﬁcients corresponding to a 8Hz-12Hz band pass ﬁlter, then the second term is able to extract differences in the alpha-band which is known to be modulated during motor related tasks. [sent-60, score-0.141]
</p><p>41 Further, by learning B from the data, we may be able to identify new frequency bands that have so far not been identiﬁed in novel experimental paradigms. [sent-61, score-0.094]
</p><p>42 The spatial weights A together with the Trace operation ensure that the power is measured, not in individual electrodes, but in some component space that may reﬂect activity distributed across several electrodes. [sent-62, score-0.44]
</p><p>43 3  Logistic regression  We use a logistic Rregression (LR) formalism as it is particularly convenient when imposing additional statistical properties on the matrices U, V, A, B such as smoothness or sparseness. [sent-65, score-0.119]
</p><p>44 In addition, in our experience, LR performs well in strongly overlapping high-dimensional datasets and is insensitive to outliers, the later being of particular concern when including quadratic features. [sent-66, score-0.042]
</p><p>45 4  (9)  n=1  (11)  Fourier Basis for B  If matrix B is constrained to have a circular toepliz structure then it can be represented as B = F−1 DF, where F−1 denotes the inverse Fourier matrix, and D is a diagonal complex-valued matrix of Fourier coefﬁcients. [sent-72, score-0.08]
</p><p>46 1  Results Simulated data  In order to validate our method and its ability to capture both linear and second order features, we generated simulated data that contained both types of features; namely ERP type of features and ERS/ERD type of features. [sent-76, score-0.12]
</p><p>47 The simulated signals were generated with a signal to noise ratio of −20dB which is a typical noise level for EEG. [sent-77, score-0.219]
</p><p>48 A total of 28 channels, 500 ms long signals and at a sampling frequency of 100Hz where generated, resulting in a matrix of X of 28 by 50 elements, for each trial. [sent-78, score-0.093]
</p><p>49 1  30  0  50  100  150  200  250 300 time(m/s)  channels  A component  350  400  450  500  350  400  450  500  B component  1. [sent-88, score-0.342]
</p><p>50 2  0  50  100  150  channels  200  250 300 time (m/s)  Figure 1: Spatial and temporal component extracted on simulated data for the linear term (top) and quadratic term (bottom). [sent-98, score-0.606]
</p><p>51 For channels 10-18, a peak represented by a half cycle sinusoid was added at approximately 400 ms, which T simulates an ERP type feature. [sent-101, score-0.289]
</p><p>52 The linear component U (in this case only a column vector) has non-zero coefﬁcients for channels 10 to 18 only, showing that the method correctly identiﬁed the ERP activity. [sent-103, score-0.266]
</p><p>53 Furthermore, the associated temporal component V has a temporal proﬁle that matches the time course of the simulated evoked response. [sent-104, score-0.489]
</p><p>54 Similarly, the second order components A have non-zero weights for only channels 1-9 showing that the method also identiﬁed the spatial distribution of the non-phase locked activity. [sent-105, score-0.552]
</p><p>55 The temporal ﬁlter B was trained in the frequency domain and the resulting ﬁlter is shown here in the time domain. [sent-106, score-0.173]
</p><p>56 It exhibits a dominant 10Hz component, which is indeed the frequency of the non-phase locked activity. [sent-107, score-0.257]
</p><p>57 2  BCI competition dataset  To evaluate the performance of the proposed method on real data we applied the algorithm to an EEG data set that was made available through The BCI Competition 2003 ([14], Data Set IV). [sent-109, score-0.082]
</p><p>58 EEG was recorded on 28 channels for a single subject performing self-paced key typing, that is, pressing the corresponding keys with the index and little ﬁngers in a self-chosen order and timing (i. [sent-110, score-0.242]
</p><p>59 A total of 416 epochs were recorded, each of length 500ms. [sent-115, score-0.057]
</p><p>60 For the competition, the ﬁrst 316 epochs were to be used for classiﬁer training, while the remaining 100 epochs were to be used as a test set. [sent-116, score-0.114]
</p><p>61 For this experiment, the matrix B was ﬁxed to a Toeplitz structure that encodes a 10Hz33Hz bandpass ﬁlter and only the parameters U, V, A and w0 were trained. [sent-119, score-0.04]
</p><p>62 The number of columns of U and V were set to 1, where two columns were used for A. [sent-120, score-0.132]
</p><p>63 The temporal ﬁlter was selected based on prior knowledge of the relevant frequency band. [sent-121, score-0.173]
</p><p>64 This demonstrates the ﬂexibility of our approach to either incorporate prior knowledge when available or extract it from 5  U component  V component 0. [sent-122, score-0.203]
</p><p>65 1  First Column of A  0  100  200 300 time (m/s)  400  500  Second Column of A  Figure 2: Spatial and temporal component (top), and two spatial components for second order features (bottom) learned on the benchmark dataset data otherwise. [sent-126, score-0.492]
</p><p>66 Regularization parameters where chosen via a ﬁve fold cross validation procedure (details can be found in [8]). [sent-127, score-0.042]
</p><p>67 The resulting components for this dataset are shown in Figure 2. [sent-128, score-0.038]
</p><p>68 Benchmark performance was measured on the test set which had not been used during either training or cross validation. [sent-129, score-0.042]
</p><p>69 The number of misclassiﬁed trials in the test set was 13 which places our method on a new ﬁrst place given the results of the competition which can be found online http://ida. [sent-130, score-0.158]
</p><p>70 The receiveroperator characteristic (ROC) curve for cross validation and for the independent testset are shown in Figure 3. [sent-136, score-0.09]
</p><p>71 2 also shows the contribution of the linear and quadratic terms for every trial for the two types of key-presses. [sent-138, score-0.136]
</p><p>72 4  Conclusion  In this paper we have presented a framework for uncovering spatial as well as temporal features in EEG that combine the two predominant paradigms used in EEG analysis: event related potentials and oscillatory power. [sent-141, score-0.543]
</p><p>73 These represent phase locked activity (where polarity of the activity matters), and non-phase locked activity (where only the power of the signal is relevant). [sent-142, score-1.171]
</p><p>74 We used the probabilistic formalism of logistic regression that readily incorporates prior probabilities to regularize the increased number of parameters. [sent-143, score-0.119]
</p><p>75 We have evaluated the proposed method on both simulated data, and a real BCI benchmark dataset, achieving state-of-the-art classiﬁcation performance. [sent-144, score-0.174]
</p><p>76 For example, different sets of basis functions (other than a Fourier basis) can be enforced on the temporal decomposition of the data through the matrix B (e. [sent-146, score-0.201]
</p><p>77 8  1  Figure 3: ROC curve with area under the curve 0. [sent-177, score-0.096]
</p><p>78 96 for the cross validation on the benchmark dataset (left). [sent-178, score-0.138]
</p><p>79 93, on the independent test set, for the benchmark dataset. [sent-180, score-0.096]
</p><p>80 There were a total of 13 errors on unseen data, which is less than any of the results previously reported, placing this method in ﬁrst place in the benchmark ranking. [sent-181, score-0.096]
</p><p>81 It is clear that the two types of features contain independent information that can help improve the classiﬁcation performance. [sent-183, score-0.042]
</p><p>82 Boosting bit rates and error detection for the classiﬁcation of fast-paced motor commands based on single-trial eeg analysis. [sent-232, score-0.413]
</p><p>83 Spatiotemporal linear decoding of brain state: Application to performance augmentation in high-throughput tasks. [sent-247, score-0.063]
</p><p>84 Neural representation of task difﬁculty and decision making during perceptual categorization: A timing diagram. [sent-251, score-0.052]
</p><p>85 Optimal spatial ﬁltering of single trial EEG during u imagined hand movement. [sent-268, score-0.214]
</p><p>86 Spatio-spectral ﬁlters for improving the classiﬁcation of single trial eeg. [sent-285, score-0.094]
</p><p>87 Combined optimization of spatial and temporal ﬁlters for improving brain-computer interfacing. [sent-296, score-0.24]
</p><p>88 The bci competition 2003: progress and perspectives in detection and discrimination of eeg single trials. [sent-317, score-0.662]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('eeg', 0.413), ('bilinear', 0.225), ('locked', 0.204), ('channels', 0.19), ('erp', 0.161), ('discriminant', 0.155), ('activity', 0.154), ('signal', 0.141), ('xn', 0.132), ('bci', 0.128), ('blankertz', 0.128), ('spatial', 0.12), ('temporal', 0.12), ('ur', 0.112), ('curio', 0.112), ('lucas', 0.112), ('wo', 0.102), ('yn', 0.098), ('christoforos', 0.096), ('christoforou', 0.096), ('benchmark', 0.096), ('evoked', 0.095), ('parra', 0.095), ('trial', 0.094), ('fourier', 0.092), ('xb', 0.09), ('oscillatory', 0.09), ('amplitude', 0.086), ('ar', 0.082), ('competition', 0.082), ('logistic', 0.08), ('simulated', 0.078), ('trials', 0.076), ('component', 0.076), ('vr', 0.072), ('captures', 0.071), ('trace', 0.07), ('columns', 0.066), ('lter', 0.065), ('dyrholm', 0.064), ('mads', 0.064), ('marios', 0.064), ('philiastides', 0.064), ('toeplitz', 0.064), ('event', 0.064), ('brain', 0.063), ('classi', 0.062), ('ut', 0.059), ('potentials', 0.059), ('avenue', 0.059), ('biomedical', 0.057), ('epochs', 0.057), ('losch', 0.056), ('ryota', 0.056), ('sajda', 0.056), ('tomioka', 0.056), ('kazuyuki', 0.056), ('polarity', 0.056), ('rt', 0.056), ('paul', 0.055), ('phase', 0.053), ('ak', 0.053), ('frequency', 0.053), ('timing', 0.052), ('ltered', 0.052), ('gerson', 0.051), ('birbaumer', 0.051), ('dornhege', 0.051), ('pfurtscheller', 0.051), ('wolpaw', 0.051), ('sinusoid', 0.051), ('power', 0.051), ('extract', 0.051), ('rd', 0.05), ('term', 0.05), ('city', 0.049), ('stimulus', 0.049), ('curve', 0.048), ('hinterberger', 0.048), ('paradigms', 0.048), ('simulates', 0.048), ('bt', 0.047), ('xv', 0.045), ('lr', 0.045), ('roc', 0.045), ('engineering', 0.044), ('hoc', 0.043), ('log', 0.043), ('quadratic', 0.042), ('features', 0.042), ('cross', 0.042), ('bands', 0.041), ('enforced', 0.041), ('matrix', 0.04), ('discrimination', 0.039), ('adam', 0.039), ('formalism', 0.039), ('across', 0.039), ('components', 0.038), ('df', 0.038)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.000001 <a title="173-tfidf-1" href="./nips-2007-Second_Order_Bilinear_Discriminant_Analysis_for_single_trial_EEG_analysis.html">173 nips-2007-Second Order Bilinear Discriminant Analysis for single trial EEG analysis</a></p>
<p>Author: Christoforos Christoforou, Paul Sajda, Lucas C. Parra</p><p>Abstract: Traditional analysis methods for single-trial classiﬁcation of electroencephalography (EEG) focus on two types of paradigms: phase locked methods, in which the amplitude of the signal is used as the feature for classiﬁcation, e.g. event related potentials; and second order methods, in which the feature of interest is the power of the signal, e.g. event related (de)synchronization. The procedure for deciding which paradigm to use is ad hoc and is typically driven by knowledge of the underlying neurophysiology. Here we propose a principled method, based on a bilinear model, in which the algorithm simultaneously learns the best ﬁrst and second order spatial and temporal features for classiﬁcation of EEG. The method is demonstrated on simulated data as well as on EEG taken from a benchmark data used to test classiﬁcation algorithms for brain computer interfaces. 1 1.1</p><p>2 0.30144376 <a title="173-tfidf-2" href="./nips-2007-Invariant_Common_Spatial_Patterns%3A_Alleviating_Nonstationarities_in_Brain-Computer_Interfacing.html">106 nips-2007-Invariant Common Spatial Patterns: Alleviating Nonstationarities in Brain-Computer Interfacing</a></p>
<p>Author: Benjamin Blankertz, Motoaki Kawanabe, Ryota Tomioka, Friederike Hohlefeld, Klaus-Robert Müller, Vadim V. Nikulin</p><p>Abstract: Brain-Computer Interfaces can suffer from a large variance of the subject conditions within and across sessions. For example vigilance ﬂuctuations in the individual, variable task involvement, workload etc. alter the characteristics of EEG signals and thus challenge a stable BCI operation. In the present work we aim to deﬁne features based on a variant of the common spatial patterns (CSP) algorithm that are constructed invariant with respect to such nonstationarities. We enforce invariance properties by adding terms to the denominator of a Rayleigh coefﬁcient representation of CSP such as disturbance covariance matrices from ﬂuctuations in visual processing. In this manner physiological prior knowledge can be used to shape the classiﬁcation engine for BCI. As a proof of concept we present a BCI classiﬁer that is robust to changes in the level of parietal α -activity. In other words, the EEG decoding still works when there are lapses in vigilance.</p><p>3 0.21867406 <a title="173-tfidf-3" href="./nips-2007-EEG-Based_Brain-Computer_Interaction%3A_Improved_Accuracy_by_Automatic_Single-Trial_Error_Detection.html">74 nips-2007-EEG-Based Brain-Computer Interaction: Improved Accuracy by Automatic Single-Trial Error Detection</a></p>
<p>Author: Pierre Ferrez, José Millán</p><p>Abstract: Brain-computer interfaces (BCIs), as any other interaction modality based on physiological signals and body channels (e.g., muscular activity, speech and gestures), are prone to errors in the recognition of subject’s intent. An elegant approach to improve the accuracy of BCIs consists in a veriﬁcation procedure directly based on the presence of error-related potentials (ErrP) in the EEG recorded right after the occurrence of an error. Six healthy volunteer subjects with no prior BCI experience participated in a new human-robot interaction experiment where they were asked to mentally move a cursor towards a target that can be reached within a few steps using motor imagination. This experiment conﬁrms the previously reported presence of a new kind of ErrP. These “Interaction ErrP” exhibit a ﬁrst sharp negative peak followed by a positive peak and a second broader negative peak (∼290, ∼350 and ∼470 ms after the feedback, respectively). But in order to exploit these ErrP we need to detect them in each single trial using a short window following the feedback associated to the response of the classiﬁer embedded in the BCI. We have achieved an average recognition rate of correct and erroneous single trials of 81.8% and 76.2%, respectively. Furthermore, we have achieved an average recognition rate of the subject’s intent while trying to mentally drive the cursor of 73.1%. These results show that it’s possible to simultaneously extract useful information for mental control to operate a brain-actuated device as well as cognitive states such as error potentials to improve the quality of the braincomputer interaction. Finally, using a well-known inverse model (sLORETA), we show that the main focus of activity at the occurrence of the ErrP are, as expected, in the pre-supplementary motor area and in the anterior cingulate cortex. 1</p><p>4 0.11112355 <a title="173-tfidf-4" href="./nips-2007-Measuring_Neural_Synchrony_by_Message_Passing.html">127 nips-2007-Measuring Neural Synchrony by Message Passing</a></p>
<p>Author: Justin Dauwels, François Vialatte, Tomasz Rutkowski, Andrzej S. Cichocki</p><p>Abstract: A novel approach to measure the interdependence of two time series is proposed, referred to as “stochastic event synchrony” (SES); it quantiﬁes the alignment of two point processes by means of the following parameters: time delay, variance of the timing jitter, fraction of “spurious” events, and average similarity of events. SES may be applied to generic one-dimensional and multi-dimensional point processes, however, the paper mainly focusses on point processes in time-frequency domain. The average event similarity is in that case described by two parameters: the average frequency offset between events in the time-frequency plane, and the variance of the frequency offset (“frequency jitter”); SES then consists of ﬁve parameters in total. Those parameters quantify the synchrony of oscillatory events, and hence, they provide an alternative to existing synchrony measures that quantify amplitude or phase synchrony. The pairwise alignment of point processes is cast as a statistical inference problem, which is solved by applying the maxproduct algorithm on a graphical model. The SES parameters are determined from the resulting pairwise alignment by maximum a posteriori (MAP) estimation. The proposed interdependence measure is applied to the problem of detecting anomalies in EEG synchrony of Mild Cognitive Impairment (MCI) patients; the results indicate that SES signiﬁcantly improves the sensitivity of EEG in detecting MCI.</p><p>5 0.09359847 <a title="173-tfidf-5" href="./nips-2007-Inferring_Elapsed_Time_from_Stochastic_Neural_Processes.html">103 nips-2007-Inferring Elapsed Time from Stochastic Neural Processes</a></p>
<p>Author: Misha Ahrens, Maneesh Sahani</p><p>Abstract: Many perceptual processes and neural computations, such as speech recognition, motor control and learning, depend on the ability to measure and mark the passage of time. However, the processes that make such temporal judgements possible are unknown. A number of different hypothetical mechanisms have been advanced, all of which depend on the known, temporally predictable evolution of a neural or psychological state, possibly through oscillations or the gradual decay of a memory trace. Alternatively, judgements of elapsed time might be based on observations of temporally structured, but stochastic processes. Such processes need not be speciﬁc to the sense of time; typical neural and sensory processes contain at least some statistical structure across a range of time scales. Here, we investigate the statistical properties of an estimator of elapsed time which is based on a simple family of stochastic process. 1</p><p>6 0.092440739 <a title="173-tfidf-6" href="./nips-2007-Blind_channel_identification_for_speech_dereverberation_using_l1-norm_sparse_learning.html">37 nips-2007-Blind channel identification for speech dereverberation using l1-norm sparse learning</a></p>
<p>7 0.08975286 <a title="173-tfidf-7" href="./nips-2007-Efficient_Inference_for_Distributions_on_Permutations.html">77 nips-2007-Efficient Inference for Distributions on Permutations</a></p>
<p>8 0.080885321 <a title="173-tfidf-8" href="./nips-2007-Catching_Up_Faster_in_Bayesian_Model_Selection_and_Model_Averaging.html">44 nips-2007-Catching Up Faster in Bayesian Model Selection and Model Averaging</a></p>
<p>9 0.077878572 <a title="173-tfidf-9" href="./nips-2007-Predicting_Brain_States_from_fMRI_Data%3A_Incremental_Functional_Principal_Component_Regression.html">154 nips-2007-Predicting Brain States from fMRI Data: Incremental Functional Principal Component Regression</a></p>
<p>10 0.076894656 <a title="173-tfidf-10" href="./nips-2007-Catching_Change-points_with_Lasso.html">43 nips-2007-Catching Change-points with Lasso</a></p>
<p>11 0.076248623 <a title="173-tfidf-11" href="./nips-2007-Using_Deep_Belief_Nets_to_Learn_Covariance_Kernels_for_Gaussian_Processes.html">212 nips-2007-Using Deep Belief Nets to Learn Covariance Kernels for Gaussian Processes</a></p>
<p>12 0.076208994 <a title="173-tfidf-12" href="./nips-2007-Continuous_Time_Particle_Filtering_for_fMRI.html">59 nips-2007-Continuous Time Particle Filtering for fMRI</a></p>
<p>13 0.07450752 <a title="173-tfidf-13" href="./nips-2007-Receptive_Fields_without_Spike-Triggering.html">164 nips-2007-Receptive Fields without Spike-Triggering</a></p>
<p>14 0.071940318 <a title="173-tfidf-14" href="./nips-2007-Simplified_Rules_and_Theoretical_Analysis_for_Information_Bottleneck_Optimization_and_PCA_with_Spiking_Neurons.html">177 nips-2007-Simplified Rules and Theoretical Analysis for Information Bottleneck Optimization and PCA with Spiking Neurons</a></p>
<p>15 0.070918269 <a title="173-tfidf-15" href="./nips-2007-On_higher-order_perceptron_algorithms.html">146 nips-2007-On higher-order perceptron algorithms</a></p>
<p>16 0.070449315 <a title="173-tfidf-16" href="./nips-2007-Learning_Horizontal_Connections_in_a_Sparse_Coding_Model_of_Natural_Images.html">111 nips-2007-Learning Horizontal Connections in a Sparse Coding Model of Natural Images</a></p>
<p>17 0.069239132 <a title="173-tfidf-17" href="./nips-2007-The_discriminant_center-surround_hypothesis_for_bottom-up_saliency.html">202 nips-2007-The discriminant center-surround hypothesis for bottom-up saliency</a></p>
<p>18 0.068788938 <a title="173-tfidf-18" href="./nips-2007-A_neural_network_implementing_optimal_state_estimation_based_on_dynamic_spike_train_decoding.html">17 nips-2007-A neural network implementing optimal state estimation based on dynamic spike train decoding</a></p>
<p>19 0.067238919 <a title="173-tfidf-19" href="./nips-2007-Optimal_ROC_Curve_for_a_Combination_of_Classifiers.html">149 nips-2007-Optimal ROC Curve for a Combination of Classifiers</a></p>
<p>20 0.067154661 <a title="173-tfidf-20" href="./nips-2007-The_rat_as_particle_filter.html">203 nips-2007-The rat as particle filter</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2007_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.229), (1, 0.076), (2, 0.078), (3, 0.038), (4, 0.01), (5, 0.191), (6, 0.052), (7, 0.088), (8, -0.139), (9, -0.122), (10, 0.022), (11, -0.144), (12, -0.049), (13, -0.035), (14, 0.224), (15, -0.037), (16, 0.009), (17, -0.257), (18, -0.168), (19, -0.046), (20, -0.095), (21, -0.1), (22, 0.045), (23, 0.172), (24, 0.129), (25, -0.089), (26, 0.122), (27, -0.126), (28, 0.056), (29, 0.056), (30, 0.021), (31, 0.127), (32, 0.014), (33, -0.016), (34, -0.021), (35, -0.03), (36, 0.03), (37, -0.03), (38, 0.016), (39, -0.001), (40, -0.006), (41, -0.042), (42, 0.016), (43, 0.064), (44, 0.017), (45, 0.033), (46, 0.018), (47, 0.042), (48, 0.012), (49, 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94415921 <a title="173-lsi-1" href="./nips-2007-Second_Order_Bilinear_Discriminant_Analysis_for_single_trial_EEG_analysis.html">173 nips-2007-Second Order Bilinear Discriminant Analysis for single trial EEG analysis</a></p>
<p>Author: Christoforos Christoforou, Paul Sajda, Lucas C. Parra</p><p>Abstract: Traditional analysis methods for single-trial classiﬁcation of electroencephalography (EEG) focus on two types of paradigms: phase locked methods, in which the amplitude of the signal is used as the feature for classiﬁcation, e.g. event related potentials; and second order methods, in which the feature of interest is the power of the signal, e.g. event related (de)synchronization. The procedure for deciding which paradigm to use is ad hoc and is typically driven by knowledge of the underlying neurophysiology. Here we propose a principled method, based on a bilinear model, in which the algorithm simultaneously learns the best ﬁrst and second order spatial and temporal features for classiﬁcation of EEG. The method is demonstrated on simulated data as well as on EEG taken from a benchmark data used to test classiﬁcation algorithms for brain computer interfaces. 1 1.1</p><p>2 0.91696924 <a title="173-lsi-2" href="./nips-2007-Invariant_Common_Spatial_Patterns%3A_Alleviating_Nonstationarities_in_Brain-Computer_Interfacing.html">106 nips-2007-Invariant Common Spatial Patterns: Alleviating Nonstationarities in Brain-Computer Interfacing</a></p>
<p>Author: Benjamin Blankertz, Motoaki Kawanabe, Ryota Tomioka, Friederike Hohlefeld, Klaus-Robert Müller, Vadim V. Nikulin</p><p>Abstract: Brain-Computer Interfaces can suffer from a large variance of the subject conditions within and across sessions. For example vigilance ﬂuctuations in the individual, variable task involvement, workload etc. alter the characteristics of EEG signals and thus challenge a stable BCI operation. In the present work we aim to deﬁne features based on a variant of the common spatial patterns (CSP) algorithm that are constructed invariant with respect to such nonstationarities. We enforce invariance properties by adding terms to the denominator of a Rayleigh coefﬁcient representation of CSP such as disturbance covariance matrices from ﬂuctuations in visual processing. In this manner physiological prior knowledge can be used to shape the classiﬁcation engine for BCI. As a proof of concept we present a BCI classiﬁer that is robust to changes in the level of parietal α -activity. In other words, the EEG decoding still works when there are lapses in vigilance.</p><p>3 0.83923161 <a title="173-lsi-3" href="./nips-2007-EEG-Based_Brain-Computer_Interaction%3A_Improved_Accuracy_by_Automatic_Single-Trial_Error_Detection.html">74 nips-2007-EEG-Based Brain-Computer Interaction: Improved Accuracy by Automatic Single-Trial Error Detection</a></p>
<p>Author: Pierre Ferrez, José Millán</p><p>Abstract: Brain-computer interfaces (BCIs), as any other interaction modality based on physiological signals and body channels (e.g., muscular activity, speech and gestures), are prone to errors in the recognition of subject’s intent. An elegant approach to improve the accuracy of BCIs consists in a veriﬁcation procedure directly based on the presence of error-related potentials (ErrP) in the EEG recorded right after the occurrence of an error. Six healthy volunteer subjects with no prior BCI experience participated in a new human-robot interaction experiment where they were asked to mentally move a cursor towards a target that can be reached within a few steps using motor imagination. This experiment conﬁrms the previously reported presence of a new kind of ErrP. These “Interaction ErrP” exhibit a ﬁrst sharp negative peak followed by a positive peak and a second broader negative peak (∼290, ∼350 and ∼470 ms after the feedback, respectively). But in order to exploit these ErrP we need to detect them in each single trial using a short window following the feedback associated to the response of the classiﬁer embedded in the BCI. We have achieved an average recognition rate of correct and erroneous single trials of 81.8% and 76.2%, respectively. Furthermore, we have achieved an average recognition rate of the subject’s intent while trying to mentally drive the cursor of 73.1%. These results show that it’s possible to simultaneously extract useful information for mental control to operate a brain-actuated device as well as cognitive states such as error potentials to improve the quality of the braincomputer interaction. Finally, using a well-known inverse model (sLORETA), we show that the main focus of activity at the occurrence of the ErrP are, as expected, in the pre-supplementary motor area and in the anterior cingulate cortex. 1</p><p>4 0.53367877 <a title="173-lsi-4" href="./nips-2007-Blind_channel_identification_for_speech_dereverberation_using_l1-norm_sparse_learning.html">37 nips-2007-Blind channel identification for speech dereverberation using l1-norm sparse learning</a></p>
<p>Author: Yuanqing Lin, Jingdong Chen, Youngmoo Kim, Daniel D. Lee</p><p>Abstract: Speech dereverberation remains an open problem after more than three decades of research. The most challenging step in speech dereverberation is blind channel identiﬁcation (BCI). Although many BCI approaches have been developed, their performance is still far from satisfactory for practical applications. The main difﬁculty in BCI lies in ﬁnding an appropriate acoustic model, which not only can effectively resolve solution degeneracies due to the lack of knowledge of the source, but also robustly models real acoustic environments. This paper proposes a sparse acoustic room impulse response (RIR) model for BCI, that is, an acoustic RIR can be modeled by a sparse FIR ﬁlter. Under this model, we show how to formulate the BCI of a single-input multiple-output (SIMO) system into a l1 norm regularized least squares (LS) problem, which is convex and can be solved efﬁciently with guaranteed global convergence. The sparseness of solutions is controlled by l1 -norm regularization parameters. We propose a sparse learning scheme that infers the optimal l1 -norm regularization parameters directly from microphone observations under a Bayesian framework. Our results show that the proposed approach is effective and robust, and it yields source estimates in real acoustic environments with high ﬁdelity to anechoic chamber measurements.</p><p>5 0.48827711 <a title="173-lsi-5" href="./nips-2007-An_Analysis_of_Inference_with_the_Universum.html">24 nips-2007-An Analysis of Inference with the Universum</a></p>
<p>Author: Olivier Chapelle, Alekh Agarwal, Fabian H. Sinz, Bernhard Schölkopf</p><p>Abstract: We study a pattern classiﬁcation algorithm which has recently been proposed by Vapnik and coworkers. It builds on a new inductive principle which assumes that in addition to positive and negative data, a third class of data is available, termed the Universum. We assay the behavior of the algorithm by establishing links with Fisher discriminant analysis and oriented PCA, as well as with an SVM in a projected subspace (or, equivalently, with a data-dependent reduced kernel). We also provide experimental results. 1</p><p>6 0.41981655 <a title="173-lsi-6" href="./nips-2007-Measuring_Neural_Synchrony_by_Message_Passing.html">127 nips-2007-Measuring Neural Synchrony by Message Passing</a></p>
<p>7 0.38083169 <a title="173-lsi-7" href="./nips-2007-Catching_Up_Faster_in_Bayesian_Model_Selection_and_Model_Averaging.html">44 nips-2007-Catching Up Faster in Bayesian Model Selection and Model Averaging</a></p>
<p>8 0.38048893 <a title="173-lsi-8" href="./nips-2007-Catching_Change-points_with_Lasso.html">43 nips-2007-Catching Change-points with Lasso</a></p>
<p>9 0.35397965 <a title="173-lsi-9" href="./nips-2007-Modeling_Natural_Sounds_with_Modulation_Cascade_Processes.html">130 nips-2007-Modeling Natural Sounds with Modulation Cascade Processes</a></p>
<p>10 0.32478917 <a title="173-lsi-10" href="./nips-2007-An_online_Hebbian_learning_rule_that_performs_Independent_Component_Analysis.html">26 nips-2007-An online Hebbian learning rule that performs Independent Component Analysis</a></p>
<p>11 0.32005152 <a title="173-lsi-11" href="./nips-2007-An_in-silico_Neural_Model_of_Dynamic_Routing_through_Neuronal_Coherence.html">25 nips-2007-An in-silico Neural Model of Dynamic Routing through Neuronal Coherence</a></p>
<p>12 0.30633327 <a title="173-lsi-12" href="./nips-2007-Inferring_Elapsed_Time_from_Stochastic_Neural_Processes.html">103 nips-2007-Inferring Elapsed Time from Stochastic Neural Processes</a></p>
<p>13 0.29849166 <a title="173-lsi-13" href="./nips-2007-Continuous_Time_Particle_Filtering_for_fMRI.html">59 nips-2007-Continuous Time Particle Filtering for fMRI</a></p>
<p>14 0.29486686 <a title="173-lsi-14" href="./nips-2007-Optimal_ROC_Curve_for_a_Combination_of_Classifiers.html">149 nips-2007-Optimal ROC Curve for a Combination of Classifiers</a></p>
<p>15 0.29395545 <a title="173-lsi-15" href="./nips-2007-Efficient_Inference_for_Distributions_on_Permutations.html">77 nips-2007-Efficient Inference for Distributions on Permutations</a></p>
<p>16 0.29334912 <a title="173-lsi-16" href="./nips-2007-Congruence_between_model_and_human_attention_reveals_unique_signatures_of_critical_visual_events.html">57 nips-2007-Congruence between model and human attention reveals unique signatures of critical visual events</a></p>
<p>17 0.28728011 <a title="173-lsi-17" href="./nips-2007-GRIFT%3A_A_graphical_model_for_inferring_visual_classification_features_from_human_data.html">93 nips-2007-GRIFT: A graphical model for inferring visual classification features from human data</a></p>
<p>18 0.28649741 <a title="173-lsi-18" href="./nips-2007-Subspace-Based_Face_Recognition_in_Analog_VLSI.html">188 nips-2007-Subspace-Based Face Recognition in Analog VLSI</a></p>
<p>19 0.27653056 <a title="173-lsi-19" href="./nips-2007-Managing_Power_Consumption_and_Performance_of_Computing_Systems_Using_Reinforcement_Learning.html">124 nips-2007-Managing Power Consumption and Performance of Computing Systems Using Reinforcement Learning</a></p>
<p>20 0.26900733 <a title="173-lsi-20" href="./nips-2007-Augmented_Functional_Time_Series_Representation_and_Forecasting_with_Gaussian_Processes.html">28 nips-2007-Augmented Functional Time Series Representation and Forecasting with Gaussian Processes</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2007_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(4, 0.015), (5, 0.046), (13, 0.018), (16, 0.032), (18, 0.024), (19, 0.461), (21, 0.06), (34, 0.019), (35, 0.026), (47, 0.077), (83, 0.081), (85, 0.023), (87, 0.013), (90, 0.043)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.86131924 <a title="173-lda-1" href="./nips-2007-Invariant_Common_Spatial_Patterns%3A_Alleviating_Nonstationarities_in_Brain-Computer_Interfacing.html">106 nips-2007-Invariant Common Spatial Patterns: Alleviating Nonstationarities in Brain-Computer Interfacing</a></p>
<p>Author: Benjamin Blankertz, Motoaki Kawanabe, Ryota Tomioka, Friederike Hohlefeld, Klaus-Robert Müller, Vadim V. Nikulin</p><p>Abstract: Brain-Computer Interfaces can suffer from a large variance of the subject conditions within and across sessions. For example vigilance ﬂuctuations in the individual, variable task involvement, workload etc. alter the characteristics of EEG signals and thus challenge a stable BCI operation. In the present work we aim to deﬁne features based on a variant of the common spatial patterns (CSP) algorithm that are constructed invariant with respect to such nonstationarities. We enforce invariance properties by adding terms to the denominator of a Rayleigh coefﬁcient representation of CSP such as disturbance covariance matrices from ﬂuctuations in visual processing. In this manner physiological prior knowledge can be used to shape the classiﬁcation engine for BCI. As a proof of concept we present a BCI classiﬁer that is robust to changes in the level of parietal α -activity. In other words, the EEG decoding still works when there are lapses in vigilance.</p><p>same-paper 2 0.83746594 <a title="173-lda-2" href="./nips-2007-Second_Order_Bilinear_Discriminant_Analysis_for_single_trial_EEG_analysis.html">173 nips-2007-Second Order Bilinear Discriminant Analysis for single trial EEG analysis</a></p>
<p>Author: Christoforos Christoforou, Paul Sajda, Lucas C. Parra</p><p>Abstract: Traditional analysis methods for single-trial classiﬁcation of electroencephalography (EEG) focus on two types of paradigms: phase locked methods, in which the amplitude of the signal is used as the feature for classiﬁcation, e.g. event related potentials; and second order methods, in which the feature of interest is the power of the signal, e.g. event related (de)synchronization. The procedure for deciding which paradigm to use is ad hoc and is typically driven by knowledge of the underlying neurophysiology. Here we propose a principled method, based on a bilinear model, in which the algorithm simultaneously learns the best ﬁrst and second order spatial and temporal features for classiﬁcation of EEG. The method is demonstrated on simulated data as well as on EEG taken from a benchmark data used to test classiﬁcation algorithms for brain computer interfaces. 1 1.1</p><p>3 0.75005537 <a title="173-lda-3" href="./nips-2007-A_Unified_Near-Optimal_Estimator_For_Dimension_Reduction_in_%24l_%5Calpha%24_%28%240%3C%5Calpha%5Cleq_2%24%29_Using_Stable_Random_Projections.html">13 nips-2007-A Unified Near-Optimal Estimator For Dimension Reduction in $l \alpha$ ($0<\alpha\leq 2$) Using Stable Random Projections</a></p>
<p>Author: Ping Li, Trevor J. Hastie</p><p>Abstract: Many tasks (e.g., clustering) in machine learning only require the lα distances instead of the original data. For dimension reductions in the lα norm (0 < α ≤ 2), the method of stable random projections can efﬁciently compute the lα distances in massive datasets (e.g., the Web or massive data streams) in one pass of the data. The estimation task for stable random projections has been an interesting topic. We propose a simple estimator based on the fractional power of the samples (projected data), which is surprisingly near-optimal in terms of the asymptotic variance. In fact, it achieves the Cram´ r-Rao bound when α = 2 and α = 0+. This e new result will be useful when applying stable random projections to distancebased clustering, classiﬁcations, kernels, massive data streams etc.</p><p>4 0.54910332 <a title="173-lda-4" href="./nips-2007-EEG-Based_Brain-Computer_Interaction%3A_Improved_Accuracy_by_Automatic_Single-Trial_Error_Detection.html">74 nips-2007-EEG-Based Brain-Computer Interaction: Improved Accuracy by Automatic Single-Trial Error Detection</a></p>
<p>Author: Pierre Ferrez, José Millán</p><p>Abstract: Brain-computer interfaces (BCIs), as any other interaction modality based on physiological signals and body channels (e.g., muscular activity, speech and gestures), are prone to errors in the recognition of subject’s intent. An elegant approach to improve the accuracy of BCIs consists in a veriﬁcation procedure directly based on the presence of error-related potentials (ErrP) in the EEG recorded right after the occurrence of an error. Six healthy volunteer subjects with no prior BCI experience participated in a new human-robot interaction experiment where they were asked to mentally move a cursor towards a target that can be reached within a few steps using motor imagination. This experiment conﬁrms the previously reported presence of a new kind of ErrP. These “Interaction ErrP” exhibit a ﬁrst sharp negative peak followed by a positive peak and a second broader negative peak (∼290, ∼350 and ∼470 ms after the feedback, respectively). But in order to exploit these ErrP we need to detect them in each single trial using a short window following the feedback associated to the response of the classiﬁer embedded in the BCI. We have achieved an average recognition rate of correct and erroneous single trials of 81.8% and 76.2%, respectively. Furthermore, we have achieved an average recognition rate of the subject’s intent while trying to mentally drive the cursor of 73.1%. These results show that it’s possible to simultaneously extract useful information for mental control to operate a brain-actuated device as well as cognitive states such as error potentials to improve the quality of the braincomputer interaction. Finally, using a well-known inverse model (sLORETA), we show that the main focus of activity at the occurrence of the ErrP are, as expected, in the pre-supplementary motor area and in the anterior cingulate cortex. 1</p><p>5 0.4410378 <a title="173-lda-5" href="./nips-2007-Blind_channel_identification_for_speech_dereverberation_using_l1-norm_sparse_learning.html">37 nips-2007-Blind channel identification for speech dereverberation using l1-norm sparse learning</a></p>
<p>Author: Yuanqing Lin, Jingdong Chen, Youngmoo Kim, Daniel D. Lee</p><p>Abstract: Speech dereverberation remains an open problem after more than three decades of research. The most challenging step in speech dereverberation is blind channel identiﬁcation (BCI). Although many BCI approaches have been developed, their performance is still far from satisfactory for practical applications. The main difﬁculty in BCI lies in ﬁnding an appropriate acoustic model, which not only can effectively resolve solution degeneracies due to the lack of knowledge of the source, but also robustly models real acoustic environments. This paper proposes a sparse acoustic room impulse response (RIR) model for BCI, that is, an acoustic RIR can be modeled by a sparse FIR ﬁlter. Under this model, we show how to formulate the BCI of a single-input multiple-output (SIMO) system into a l1 norm regularized least squares (LS) problem, which is convex and can be solved efﬁciently with guaranteed global convergence. The sparseness of solutions is controlled by l1 -norm regularization parameters. We propose a sparse learning scheme that infers the optimal l1 -norm regularization parameters directly from microphone observations under a Bayesian framework. Our results show that the proposed approach is effective and robust, and it yields source estimates in real acoustic environments with high ﬁdelity to anechoic chamber measurements.</p><p>6 0.40776676 <a title="173-lda-6" href="./nips-2007-An_Analysis_of_Inference_with_the_Universum.html">24 nips-2007-An Analysis of Inference with the Universum</a></p>
<p>7 0.37934646 <a title="173-lda-7" href="./nips-2007-Measuring_Neural_Synchrony_by_Message_Passing.html">127 nips-2007-Measuring Neural Synchrony by Message Passing</a></p>
<p>8 0.37099013 <a title="173-lda-8" href="./nips-2007-Random_Projections_for_Manifold_Learning.html">161 nips-2007-Random Projections for Manifold Learning</a></p>
<p>9 0.36534789 <a title="173-lda-9" href="./nips-2007-Locality_and_low-dimensions_in_the_prediction_of_natural_experience_from_fMRI.html">122 nips-2007-Locality and low-dimensions in the prediction of natural experience from fMRI</a></p>
<p>10 0.35865274 <a title="173-lda-10" href="./nips-2007-Simplified_Rules_and_Theoretical_Analysis_for_Information_Bottleneck_Optimization_and_PCA_with_Spiking_Neurons.html">177 nips-2007-Simplified Rules and Theoretical Analysis for Information Bottleneck Optimization and PCA with Spiking Neurons</a></p>
<p>11 0.35844079 <a title="173-lda-11" href="./nips-2007-Predicting_Brain_States_from_fMRI_Data%3A_Incremental_Functional_Principal_Component_Regression.html">154 nips-2007-Predicting Brain States from fMRI Data: Incremental Functional Principal Component Regression</a></p>
<p>12 0.35688016 <a title="173-lda-12" href="./nips-2007-Receptive_Fields_without_Spike-Triggering.html">164 nips-2007-Receptive Fields without Spike-Triggering</a></p>
<p>13 0.35434884 <a title="173-lda-13" href="./nips-2007-The_discriminant_center-surround_hypothesis_for_bottom-up_saliency.html">202 nips-2007-The discriminant center-surround hypothesis for bottom-up saliency</a></p>
<p>14 0.35052606 <a title="173-lda-14" href="./nips-2007-An_in-silico_Neural_Model_of_Dynamic_Routing_through_Neuronal_Coherence.html">25 nips-2007-An in-silico Neural Model of Dynamic Routing through Neuronal Coherence</a></p>
<p>15 0.34751585 <a title="173-lda-15" href="./nips-2007-SpAM%3A_Sparse_Additive_Models.html">179 nips-2007-SpAM: Sparse Additive Models</a></p>
<p>16 0.33996347 <a title="173-lda-16" href="./nips-2007-Congruence_between_model_and_human_attention_reveals_unique_signatures_of_critical_visual_events.html">57 nips-2007-Congruence between model and human attention reveals unique signatures of critical visual events</a></p>
<p>17 0.33944613 <a title="173-lda-17" href="./nips-2007-Better_than_least_squares%3A_comparison_of_objective_functions_for_estimating_linear-nonlinear_models.html">36 nips-2007-Better than least squares: comparison of objective functions for estimating linear-nonlinear models</a></p>
<p>18 0.33925921 <a title="173-lda-18" href="./nips-2007-Near-Maximum_Entropy_Models_for_Binary_Neural_Representations_of_Natural_Images.html">138 nips-2007-Near-Maximum Entropy Models for Binary Neural Representations of Natural Images</a></p>
<p>19 0.33486184 <a title="173-lda-19" href="./nips-2007-An_online_Hebbian_learning_rule_that_performs_Independent_Component_Analysis.html">26 nips-2007-An online Hebbian learning rule that performs Independent Component Analysis</a></p>
<p>20 0.3345331 <a title="173-lda-20" href="./nips-2007-Compressed_Regression.html">53 nips-2007-Compressed Regression</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
