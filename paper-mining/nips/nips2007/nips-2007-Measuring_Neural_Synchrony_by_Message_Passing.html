<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>127 nips-2007-Measuring Neural Synchrony by Message Passing</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-127" href="#">nips2007-127</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>127 nips-2007-Measuring Neural Synchrony by Message Passing</h1>
<br/><p>Source: <a title="nips-2007-127-pdf" href="http://papers.nips.cc/paper/3322-measuring-neural-synchrony-by-message-passing.pdf">pdf</a></p><p>Author: Justin Dauwels, François Vialatte, Tomasz Rutkowski, Andrzej S. Cichocki</p><p>Abstract: A novel approach to measure the interdependence of two time series is proposed, referred to as “stochastic event synchrony” (SES); it quantiﬁes the alignment of two point processes by means of the following parameters: time delay, variance of the timing jitter, fraction of “spurious” events, and average similarity of events. SES may be applied to generic one-dimensional and multi-dimensional point processes, however, the paper mainly focusses on point processes in time-frequency domain. The average event similarity is in that case described by two parameters: the average frequency offset between events in the time-frequency plane, and the variance of the frequency offset (“frequency jitter”); SES then consists of ﬁve parameters in total. Those parameters quantify the synchrony of oscillatory events, and hence, they provide an alternative to existing synchrony measures that quantify amplitude or phase synchrony. The pairwise alignment of point processes is cast as a statistical inference problem, which is solved by applying the maxproduct algorithm on a graphical model. The SES parameters are determined from the resulting pairwise alignment by maximum a posteriori (MAP) estimation. The proposed interdependence measure is applied to the problem of detecting anomalies in EEG synchrony of Mild Cognitive Impairment (MCI) patients; the results indicate that SES signiﬁcantly improves the sensitivity of EEG in detecting MCI.</p><p>Reference: <a title="nips-2007-127-reference" href="../nips2007_reference/nips-2007-Measuring_Neural_Synchrony_by_Message_Passing_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 SES may be applied to generic one-dimensional and multi-dimensional point processes, however, the paper mainly focusses on point processes in time-frequency domain. [sent-5, score-0.083]
</p><p>2 The average event similarity is in that case described by two parameters: the average frequency offset between events in the time-frequency plane, and the variance of the frequency offset (“frequency jitter”); SES then consists of ﬁve parameters in total. [sent-6, score-0.528]
</p><p>3 Those parameters quantify the synchrony of oscillatory events, and hence, they provide an alternative to existing synchrony measures that quantify amplitude or phase synchrony. [sent-7, score-0.73]
</p><p>4 The pairwise alignment of point processes is cast as a statistical inference problem, which is solved by applying the maxproduct algorithm on a graphical model. [sent-8, score-0.175]
</p><p>5 The SES parameters are determined from the resulting pairwise alignment by maximum a posteriori (MAP) estimation. [sent-9, score-0.094]
</p><p>6 The proposed interdependence measure is applied to the problem of detecting anomalies in EEG synchrony of Mild Cognitive Impairment (MCI) patients; the results indicate that SES signiﬁcantly improves the sensitivity of EEG in detecting MCI. [sent-10, score-0.371]
</p><p>7 For instance, it is hotly debated whether the synchronous ﬁring of neurons plays a role in cognition [1] and even in consciousness [2]. [sent-12, score-0.086]
</p><p>8 The synchronous ﬁring paradigm has also attracted substantial attention in both the experimental (e. [sent-13, score-0.059]
</p><p>9 Moreover, medical studies have reported that many neurophysiological diseases (such as Alzheimer’s disease) are often associated with abnormalities in neural synchrony [5, 6]. [sent-18, score-0.31]
</p><p>10 The pairwise alignment of point processes is cast as a statistical inference problem, which is solved by applying the max-product algorithm on a graphical model [7]. [sent-20, score-0.175]
</p><p>11 Our experiments, however, indicate that the it ﬁnds reasonable alignments in practice. [sent-22, score-0.028]
</p><p>12 The SES parameters are determined from the resulting pairwise alignments by maximum a posteriori (MAP) estimation. [sent-23, score-0.056]
</p><p>13 The proposed method may be helpful to detect mental disorders such as Alzheimer’s disease, since mental disorders are often associated with abnormal blood and neural activity ﬂows, and changes in the synchrony of brain activity (see, e. [sent-24, score-0.459]
</p><p>14 In this paper, we will present promising results on the early prediction of Alzheimer’s disease from EEG signals based on SES. [sent-27, score-0.087]
</p><p>15 In the next section, we introduce SES for the case of onedimensional point processes. [sent-29, score-0.022]
</p><p>16 In Section 3, we consider the extension to multi-dimensional point processes. [sent-30, score-0.022]
</p><p>17 In Section 4, we use our measure to detect abnormalities in the EEG synchrony of Alzheimer’s disease patients. [sent-31, score-0.383]
</p><p>18 2 One-Dimensional Point Processes Let us consider the one-dimensional point processes (“event strings”) X and X in Fig. [sent-32, score-0.061]
</p><p>19 We wish to quantify to which extent X and X are synchronized. [sent-34, score-0.036]
</p><p>20 Intuitively speaking, two event strings can be considered as synchronous (or “locked”) if they are identical apart from: (i) a time shift δt ; (ii) small deviations in the event occurrence times (“event timing jitter”); (iii) a few event insertions and/or deletions. [sent-35, score-0.66]
</p><p>21 More precisely, for two event strings to be synchronous, the event timing jitter should be signiﬁcantly smaller than the average inter-event time, and the number of deletions and insertions should comprise only a small fraction of the total number of events. [sent-36, score-0.53]
</p><p>22 This intuitive concept of synchrony is illustrated in Fig. [sent-37, score-0.269]
</p><p>23 The event string X is obtained from event string X by successively shifting X over δt (resulting in Y ), slightly perturbing the event occurrence times (resulting in Z), and eventually, by adding (plus sign) and deleting (minus sign) events, resulting in X . [sent-39, score-0.537]
</p><p>24 Adding and deleting events in Z leads to “spurious” events in X and X (see Fig. [sent-40, score-0.286]
</p><p>25 1(a); spurious events are marked in red): a spurious event in X is an event that cannot be paired with an event in X and vice versa. [sent-41, score-0.897]
</p><p>26 The above intuitive reasoning leads to our novel measure for synchrony between two event strings, i. [sent-42, score-0.434]
</p><p>27 SES is related to the metrics (“distances”) proposed in [9]; those metrics are single numbers that quantify the synchrony between event strings. [sent-45, score-0.449]
</p><p>28 In contrast, we characterize synchrony by means of three parameters, which allows us to distinguish different types of synchrony (see [10]). [sent-46, score-0.538]
</p><p>29 First, one generates an event string V of length , where the events Vk are mutually independent and uniformly distributed in [0, T0 ]. [sent-50, score-0.299]
</p><p>30 The strings Z and Z are generated by delaying V over −δt /2 and δt /2 respectively and by (slightly) perturbing the resulting event occurrence times (variance of timing jitter equals st /2). [sent-51, score-0.652]
</p><p>31 The sequences X and X are obtained from Z and Z by removing some of the events; more precisely, from each pair (Zk , Zk ), either Zk or Zk is removed with probability ps . [sent-52, score-0.057]
</p><p>32 Since we do not wish/need to encode prior information about δt and st , we adopt improper priors p(δt ) = 1 = p(st ). [sent-56, score-0.247]
</p><p>33 In the following, we will denote model (6) by p(x, x , j, j , δt , st ) instead of p(x, x , b, b , δt , st , ), since for given x, x , b, and b (and hence given n, n , and nnon-spur ), the length is fully determined, i. [sent-62, score-0.494]
</p><p>34 It also noteworthy that T0 , λ and ps do not need to be speciﬁed individually, since they appear in (6) only through β. [sent-67, score-0.077]
</p><p>35 The latter serves in practice as a knob to control the number of spurious events. [sent-68, score-0.166]
</p><p>36 I B  2 0  34 00  78 9 00 0  5 6 1 0  X Z  X  V  T0  0 δt 2  Y Z  δt  δt 2  Z  X B  1  0 0 0  0  0 00  I  X  1  2 3 4  6  7 89  (a) Asymmetric procedure  (b) Symmetric procedure  Figure 1: One-dimensional stochastic event synchrony. [sent-69, score-0.144]
</p><p>37 Given event strings X and X , we wish to determine the parameters δt and st , and the hidden variables B and B ; the parameter ρspur (cf. [sent-70, score-0.451]
</p><p>38 (1)) can obtained from the latter : n k=1 bk  + n+n  ρspur =  n k=1 bk  . [sent-71, score-0.316]
</p><p>39 3 Multi-Dimensional Point Processes In this section, we will focus on the interdependence of multi-dimensional point processes. [sent-75, score-0.103]
</p><p>40 As a concrete example, we will consider multi-dimensional point processes in time-frequency domain; the proposed algorithm, however, is not restricted to that particular situation, it is applicable to generic multi-dimensional point processes. [sent-76, score-0.083]
</p><p>41 2 and [17]); each bump is described by ﬁve parameters: time X, frequency F , width ∆X, height ∆F , and amplitude W . [sent-81, score-0.214]
</p><p>42 The resulting bump models Y = ((X1 , F1 , ∆X1 , ∆F1 , W1 ), . [sent-82, score-0.14]
</p><p>43 , (Xn , Fn , ∆Xn , ∆Fn , Wn )), representing the most prominent oscillatory activity, are thus 5-dimensional point processes. [sent-88, score-0.06]
</p><p>44 Our extension of stochastic event synchrony to multi-dimensional point processes (and bump models in particular) is derived from the following observation (see Fig. [sent-89, score-0.614]
</p><p>45 3): bumps in one time-frequency map may not be present in the other map (“spurious” bumps); other bumps are present in both maps (“non-spurious bumps”), but appear at slightly different positions on the maps. [sent-90, score-0.236]
</p><p>46 3 connect the centers of non-spurious bumps, and hence, visualize the offset between pairs of non-spurious bumps. [sent-92, score-0.064]
</p><p>47 We quantify the interdependence between two bump models by ﬁve parameters, i. [sent-93, score-0.257]
</p><p>48 , the parameters ρspur , δt , and st introduced in Section 2, in addition to: • δf : the average frequency offset between non-spurious bumps, • sf : the variance of the frequency offset between non-spurious bumps. [sent-95, score-0.719]
</p><p>49 We determine the alignment of two bump models in addition to the 5 above parameters by an inference algorithm similar to the one of Section 2, as we will explain in the following; we will use the notation θ = (δt , st , δf , sf ). [sent-96, score-0.674]
</p><p>50 In principle, one may determine the sequences J and J and the parameters θ by cyclic maximization along the lines of (8) and (9). [sent-98, score-0.069]
</p><p>51 As a result, the Viterbi algorithm (or equivalently, the max-product algorithm applied on cycle-free factor graph of model (10)) becomes impractical. [sent-100, score-0.044]
</p><p>52 We solve this problem by applying the max-product algorithm on a cyclic factor graph of the system at hand, which will amount to a suboptimal but practical procedure to obtain pairwise alignments of multi-dimensional point processes (and bump models in particular). [sent-101, score-0.37]
</p><p>53 To this end, we introduce a representation of model (10) that is naturally represented by a cyclic graph: for each pair of events Yk and Yk , we introduce a binary variable Ckk that equals one if Yk and Yk form pair of nonspurious events and is zero otherwise. [sent-102, score-0.335]
</p><p>54 Since each event in Y associated to at most one event in Y , we have the constraints: n  n  C1k = S1 ∈ {0, 1}, k =1  n  C2k = S2 ∈ {0, 1}, . [sent-103, score-0.288]
</p><p>55 , k =1  Cnk = Sn ∈ {0, 1}, k =1  4  (11)  and similarly, each event in Y is associated to at most one event in Y , which is expressed by a similar set of constraints. [sent-106, score-0.288]
</p><p>56 On the other hand, we have prior knowledge about st and sf . [sent-111, score-0.468]
</p><p>57 Indeed, we expect a bump in one time-frequency map to appear in the other map at about the same frequency, but there may be some timing offset between both bumps. [sent-112, score-0.326]
</p><p>58 8s), since the former is much closer in frequency than the latter. [sent-120, score-0.052]
</p><p>59 As a consequence, we a priori expect smaller values for sf than for st . [sent-121, score-0.468]
</p><p>60 We encode this prior information by means of conjugate priors for st and sf , i. [sent-122, score-0.468]
</p><p>61 4 (each edge represents a variable, each node corresponds to a factor of (14), as indicated by the arrows at the right hand side; we refer to [7] for an introduction to factor graphs). [sent-126, score-0.04]
</p><p>62 We omitted the edges for the (observed) variables Xk , Xk , Fk , Fk , ∆Xk , ∆Xk , ∆Fk , and ∆Fk in order not to clutter the ﬁgure. [sent-127, score-0.029]
</p><p>63 Time-frequency map Time-frequency map  ↓  ↓  Bump model  Bump model  ⇔ Figure 2: Two-dimensional stochastic event synchrony. [sent-128, score-0.2]
</p><p>64 5  10  t [s]  15  20  (b) Non-spurious bumps (ρspur = 27%); the black lines connect the centers of non-spurious bumps. [sent-134, score-0.09]
</p><p>65 n k =1 cnk  =  δ[bn +  − 1]  µ↓ µ↑ µ↑ µ↓  = C11 N  = . [sent-145, score-0.027]
</p><p>66 ttt  N cnn  ˆ θ(k)  =  θ = (δt , st , δf , sf )  N ˆ θ(k)  xn −xn ∆xn +∆xn  ; δ t , st N  fn −fn ∆fn +∆fn  ; δ f , sf  p(δt , st , δf , sf ) = p(δt )p(st )p(δf )p(sf )  Figure 4: Factor graph of model (14). [sent-160, score-1.558]
</p><p>67 From c, we obtain the estimate ρspur as: ˆ ˆ n n n + k=1 ˆk b n + n − 2 k=1 k =1 ckk ˆ = . [sent-161, score-0.556]
</p><p>68 ˆ  (17)  θ  ˆ The estimate θ(i+1) (17) is available in closed-form; indeed, it is easily veriﬁed that the point esˆ(i+1) and δ (i+1) are the (sample) mean of the timing and frequency offset respectively, ˆ timates δt f (i+1)  computed over all pairs of non-spurious events. [sent-163, score-0.204]
</p><p>69 (i+1)  and sf ˆ  are obtained simi-  ˆ Update (16), i. [sent-165, score-0.221]
</p><p>70 , ﬁnding the optimal pairwise alignment C for given values θ(i) of the parameters θ, is less straightforward: it involves an intractable combinatorial optimization problem. [sent-167, score-0.094]
</p><p>71 We attempt to solve that problem by applying the max-product algorithm to the (cyclic) factor graph depicted ˆ in Fig. [sent-168, score-0.044]
</p><p>72 Let us ﬁrst point out that, since the alignment C is computed for given θ = θ(i) , (i) ˆ the (upward) messages along the edges θ are the point estimate θ (cf. [sent-170, score-0.2]
</p><p>73 (16)); equivalently, for the purpose of computing (16), one may remove the θ edges and the two bottom nodes in Fig. [sent-171, score-0.029]
</p><p>74 The other messages in the graph are iteratively updated according to the generic max-product update rule [7]. [sent-173, score-0.085]
</p><p>75 The messages ¯ µ↑(ckk ) and µ↑ (ckk ) propagate upward along the edges ckk towards the Σ-nodes connected to the edges Bk and Bk respectively (see Fig. [sent-175, score-0.702]
</p><p>76 4, left hand side); the messages µ↓(ckk ) and µ↓ (ckk ) ¯ propagate downward along the edges ckk from the Σ-nodes connected to the edges Bk and Bk respectively. [sent-176, score-0.694]
</p><p>77 After initialization (18) of the messages µ↑(ckk ) and µ↑ (ckk ) (k = 1, 2, . [sent-177, score-0.061]
</p><p>78 At last, one computes the marginals p(ckk ) (23), and from the latter, one may determine the decisions ckk by greedy decimation. [sent-184, score-0.556]
</p><p>79 The sampling frequency was 200 Hz, and the signals were bandpass ﬁltered between 4 6  Initialization µ↑(ckk ) = µ↑ (ckk ) ∝  N  ckk  xk − xk fk − fk ; δ t , st N ; δ f , sf ∆xk + ∆xk ∆fk + ∆fk  (18)  Iteratively compute messages until convergence A. [sent-186, score-2.076]
</p><p>80 The subjects comprised two study groups: the ﬁrst consisted of a group of 22 patients diagnosed as suffering from MCI, who subsequently developed mild AD. [sent-190, score-0.067]
</p><p>81 We computed a large variety of synchrony measures for both data sets; the results are summarized in Table 2. [sent-193, score-0.297]
</p><p>82 We report results for global synchrony, obtained by averaging the synchrony measures over 5 brain regions (frontal, temporal left and right, central, occipital). [sent-194, score-0.34]
</p><p>83 For SES, the bump models were clustered by means of the aggregation algorithm described in [17]. [sent-195, score-0.14]
</p><p>84 The strongest observed effect is a signiﬁcantly higher degree of background noise (ρspur ) in MCI patients, more speciﬁcally, a high number of spurious, non-synchronous oscillatory events (p = 0. [sent-196, score-0.171]
</p><p>85 We veriﬁed that the SES measures are not correlated (Pearson r) with other synchrony measures (p > 0. [sent-198, score-0.325]
</p><p>86 10); in contrast to the other measures, SES quantiﬁes the synchrony of oscillatory events (instead of more conventional amplitude or phase synchrony). [sent-199, score-0.494]
</p><p>87 Interestingly, we did not observe a signiﬁcant effect on the timing jitter st of the non-spurious events (p = 0. [sent-203, score-0.54]
</p><p>88 In other words, AD seems to be associated with a signiﬁcant increase of spurious background activity, while the non-spurious activity remains well synchronized. [sent-205, score-0.208]
</p><p>89 Moreover, only the non-spurious activity slows down (p = 0. [sent-206, score-0.042]
</p><p>90 5(c)), the average frequency of the spurious activity is not affected in MCI patients (see Fig. [sent-208, score-0.31]
</p><p>91 012∗  References  [16]  [18]  [20]  Measure  Granger coherence  Partial Coherence  PDC  DTF  ffDTF  dDTF  p-value  0. [sent-216, score-0.032]
</p><p>92 030∗  Measure  Kullback-Leibler  R´ nyi e  Jensen-Shannon  Jensen-R´ nyi e  IW  I  p-value  0. [sent-222, score-0.048]
</p><p>93 00021∗∗  Table 2: Sensitivity of synchrony measures for early prediction of AD (p-values for Mann-Whitney test; * and ** indicate p < 0. [sent-238, score-0.297]
</p><p>94 N k , S k , and H k are three measures of nonlinear interdependence [15]. [sent-241, score-0.109]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ckk', 0.556), ('fk', 0.272), ('synchrony', 0.269), ('st', 0.247), ('spur', 0.23), ('sf', 0.221), ('xk', 0.18), ('ses', 0.176), ('spurious', 0.166), ('bk', 0.158), ('event', 0.144), ('bump', 0.14), ('events', 0.133), ('eeg', 0.125), ('mci', 0.122), ('nspur', 0.122), ('jitter', 0.094), ('bumps', 0.09), ('alzheimer', 0.081), ('interdependence', 0.081), ('cyclic', 0.069), ('timing', 0.066), ('alignment', 0.066), ('fn', 0.064), ('offset', 0.064), ('messages', 0.061), ('strings', 0.06), ('synchronous', 0.059), ('ps', 0.057), ('vik', 0.054), ('frequency', 0.052), ('disease', 0.052), ('patients', 0.05), ('brain', 0.043), ('activity', 0.042), ('bn', 0.042), ('abnormalities', 0.041), ('cnn', 0.041), ('ctr', 0.041), ('ffdtf', 0.041), ('ntot', 0.041), ('xjk', 0.041), ('processes', 0.039), ('oscillatory', 0.038), ('synchronization', 0.036), ('quantify', 0.036), ('firing', 0.035), ('signals', 0.035), ('argmax', 0.034), ('zk', 0.033), ('coherence', 0.032), ('phase', 0.032), ('edges', 0.029), ('map', 0.028), ('alignments', 0.028), ('pairwise', 0.028), ('yk', 0.028), ('measures', 0.028), ('cichocki', 0.027), ('cnk', 0.027), ('consciousness', 0.027), ('lachaux', 0.027), ('martinerie', 0.027), ('quiroga', 0.027), ('riken', 0.027), ('saitama', 0.027), ('varela', 0.027), ('vialatte', 0.027), ('upward', 0.027), ('wavelet', 0.025), ('xn', 0.025), ('graph', 0.024), ('nyi', 0.024), ('rodriguez', 0.024), ('kraskov', 0.024), ('grassberger', 0.024), ('point', 0.022), ('string', 0.022), ('amplitude', 0.022), ('justin', 0.022), ('insertions', 0.022), ('disorders', 0.022), ('measure', 0.021), ('occurrence', 0.021), ('likewise', 0.02), ('cast', 0.02), ('noteworthy', 0.02), ('amari', 0.02), ('elapsed', 0.02), ('deleting', 0.02), ('perturbing', 0.02), ('factor', 0.02), ('hz', 0.02), ('downward', 0.019), ('blood', 0.019), ('variance', 0.019), ('clinical', 0.018), ('sk', 0.018), ('alternates', 0.017), ('mild', 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="127-tfidf-1" href="./nips-2007-Measuring_Neural_Synchrony_by_Message_Passing.html">127 nips-2007-Measuring Neural Synchrony by Message Passing</a></p>
<p>Author: Justin Dauwels, François Vialatte, Tomasz Rutkowski, Andrzej S. Cichocki</p><p>Abstract: A novel approach to measure the interdependence of two time series is proposed, referred to as “stochastic event synchrony” (SES); it quantiﬁes the alignment of two point processes by means of the following parameters: time delay, variance of the timing jitter, fraction of “spurious” events, and average similarity of events. SES may be applied to generic one-dimensional and multi-dimensional point processes, however, the paper mainly focusses on point processes in time-frequency domain. The average event similarity is in that case described by two parameters: the average frequency offset between events in the time-frequency plane, and the variance of the frequency offset (“frequency jitter”); SES then consists of ﬁve parameters in total. Those parameters quantify the synchrony of oscillatory events, and hence, they provide an alternative to existing synchrony measures that quantify amplitude or phase synchrony. The pairwise alignment of point processes is cast as a statistical inference problem, which is solved by applying the maxproduct algorithm on a graphical model. The SES parameters are determined from the resulting pairwise alignment by maximum a posteriori (MAP) estimation. The proposed interdependence measure is applied to the problem of detecting anomalies in EEG synchrony of Mild Cognitive Impairment (MCI) patients; the results indicate that SES signiﬁcantly improves the sensitivity of EEG in detecting MCI.</p><p>2 0.14404741 <a title="127-tfidf-2" href="./nips-2007-Incremental_Natural_Actor-Critic_Algorithms.html">102 nips-2007-Incremental Natural Actor-Critic Algorithms</a></p>
<p>Author: Shalabh Bhatnagar, Mohammad Ghavamzadeh, Mark Lee, Richard S. Sutton</p><p>Abstract: We present four new reinforcement learning algorithms based on actor-critic and natural-gradient ideas, and provide their convergence proofs. Actor-critic reinforcement learning methods are online approximations to policy iteration in which the value-function parameters are estimated using temporal difference learning and the policy parameters are updated by stochastic gradient descent. Methods based on policy gradients in this way are of special interest because of their compatibility with function approximation methods, which are needed to handle large or inﬁnite state spaces. The use of temporal difference learning in this way is of interest because in many applications it dramatically reduces the variance of the gradient estimates. The use of the natural gradient is of interest because it can produce better conditioned parameterizations and has been shown to further reduce variance in some cases. Our results extend prior two-timescale convergence results for actor-critic methods by Konda and Tsitsiklis by using temporal difference learning in the actor and by incorporating natural gradients, and they extend prior empirical studies of natural actor-critic methods by Peters, Vijayakumar and Schaal by providing the ﬁrst convergence proofs and the ﬁrst fully incremental algorithms. 1</p><p>3 0.11561605 <a title="127-tfidf-3" href="./nips-2007-Consistent_Minimization_of_Clustering_Objective_Functions.html">58 nips-2007-Consistent Minimization of Clustering Objective Functions</a></p>
<p>Author: Ulrike V. Luxburg, Stefanie Jegelka, Michael Kaufmann, Sébastien Bubeck</p><p>Abstract: Clustering is often formulated as a discrete optimization problem. The objective is to ﬁnd, among all partitions of the data set, the best one according to some quality measure. However, in the statistical setting where we assume that the ﬁnite data set has been sampled from some underlying space, the goal is not to ﬁnd the best partition of the given sample, but to approximate the true partition of the underlying space. We argue that the discrete optimization approach usually does not achieve this goal. As an alternative, we suggest the paradigm of “nearest neighbor clustering”. Instead of selecting the best out of all partitions of the sample, it only considers partitions in some restricted function class. Using tools from statistical learning theory we prove that nearest neighbor clustering is statistically consistent. Moreover, its worst case complexity is polynomial by construction, and it can be implemented with small average case complexity using branch and bound. 1</p><p>4 0.11460064 <a title="127-tfidf-4" href="./nips-2007-Locality_and_low-dimensions_in_the_prediction_of_natural_experience_from_fMRI.html">122 nips-2007-Locality and low-dimensions in the prediction of natural experience from fMRI</a></p>
<p>Author: Francois Meyer, Greg Stephens</p><p>Abstract: Functional Magnetic Resonance Imaging (fMRI) provides dynamical access into the complex functioning of the human brain, detailing the hemodynamic activity of thousands of voxels during hundreds of sequential time points. One approach towards illuminating the connection between fMRI and cognitive function is through decoding; how do the time series of voxel activities combine to provide information about internal and external experience? Here we seek models of fMRI decoding which are balanced between the simplicity of their interpretation and the effectiveness of their prediction. We use signals from a subject immersed in virtual reality to compare global and local methods of prediction applying both linear and nonlinear techniques of dimensionality reduction. We ﬁnd that the prediction of complex stimuli is remarkably low-dimensional, saturating with less than 100 features. In particular, we build effective models based on the decorrelated components of cognitive activity in the classically-deﬁned Brodmann areas. For some of the stimuli, the top predictive areas were surprisingly transparent, including Wernicke’s area for verbal instructions, visual cortex for facial and body features, and visual-temporal regions for velocity. Direct sensory experience resulted in the most robust predictions, with the highest correlation (c ∼ 0.8) between the predicted and experienced time series of verbal instructions. Techniques based on non-linear dimensionality reduction (Laplacian eigenmaps) performed similarly. The interpretability and relative simplicity of our approach provides a conceptual basis upon which to build more sophisticated techniques for fMRI decoding and offers a window into cognitive function during dynamic, natural experience. 1</p><p>5 0.11112355 <a title="127-tfidf-5" href="./nips-2007-Second_Order_Bilinear_Discriminant_Analysis_for_single_trial_EEG_analysis.html">173 nips-2007-Second Order Bilinear Discriminant Analysis for single trial EEG analysis</a></p>
<p>Author: Christoforos Christoforou, Paul Sajda, Lucas C. Parra</p><p>Abstract: Traditional analysis methods for single-trial classiﬁcation of electroencephalography (EEG) focus on two types of paradigms: phase locked methods, in which the amplitude of the signal is used as the feature for classiﬁcation, e.g. event related potentials; and second order methods, in which the feature of interest is the power of the signal, e.g. event related (de)synchronization. The procedure for deciding which paradigm to use is ad hoc and is typically driven by knowledge of the underlying neurophysiology. Here we propose a principled method, based on a bilinear model, in which the algorithm simultaneously learns the best ﬁrst and second order spatial and temporal features for classiﬁcation of EEG. The method is demonstrated on simulated data as well as on EEG taken from a benchmark data used to test classiﬁcation algorithms for brain computer interfaces. 1 1.1</p><p>6 0.10376125 <a title="127-tfidf-6" href="./nips-2007-On_higher-order_perceptron_algorithms.html">146 nips-2007-On higher-order perceptron algorithms</a></p>
<p>7 0.084315971 <a title="127-tfidf-7" href="./nips-2007-Loop_Series_and_Bethe_Variational_Bounds_in_Attractive_Graphical_Models.html">123 nips-2007-Loop Series and Bethe Variational Bounds in Attractive Graphical Models</a></p>
<p>8 0.083650783 <a title="127-tfidf-8" href="./nips-2007-Variational_Inference_for_Diffusion_Processes.html">213 nips-2007-Variational Inference for Diffusion Processes</a></p>
<p>9 0.077206269 <a title="127-tfidf-9" href="./nips-2007-Exponential_Family_Predictive_Representations_of_State.html">86 nips-2007-Exponential Family Predictive Representations of State</a></p>
<p>10 0.07609804 <a title="127-tfidf-10" href="./nips-2007-Bayesian_Policy_Learning_with_Trans-Dimensional_MCMC.html">34 nips-2007-Bayesian Policy Learning with Trans-Dimensional MCMC</a></p>
<p>11 0.071216337 <a title="127-tfidf-11" href="./nips-2007-Inferring_Elapsed_Time_from_Stochastic_Neural_Processes.html">103 nips-2007-Inferring Elapsed Time from Stochastic Neural Processes</a></p>
<p>12 0.064764179 <a title="127-tfidf-12" href="./nips-2007-TrueSkill_Through_Time%3A_Revisiting_the_History_of_Chess.html">208 nips-2007-TrueSkill Through Time: Revisiting the History of Chess</a></p>
<p>13 0.062572822 <a title="127-tfidf-13" href="./nips-2007-Congruence_between_model_and_human_attention_reveals_unique_signatures_of_critical_visual_events.html">57 nips-2007-Congruence between model and human attention reveals unique signatures of critical visual events</a></p>
<p>14 0.060851205 <a title="127-tfidf-14" href="./nips-2007-The_Infinite_Markov_Model.html">197 nips-2007-The Infinite Markov Model</a></p>
<p>15 0.060745236 <a title="127-tfidf-15" href="./nips-2007-Optimistic_Linear_Programming_gives_Logarithmic_Regret_for_Irreducible_MDPs.html">151 nips-2007-Optimistic Linear Programming gives Logarithmic Regret for Irreducible MDPs</a></p>
<p>16 0.052898414 <a title="127-tfidf-16" href="./nips-2007-Temporal_Difference_Updating_without_a_Learning_Rate.html">191 nips-2007-Temporal Difference Updating without a Learning Rate</a></p>
<p>17 0.051750429 <a title="127-tfidf-17" href="./nips-2007-Invariant_Common_Spatial_Patterns%3A_Alleviating_Nonstationarities_in_Brain-Computer_Interfacing.html">106 nips-2007-Invariant Common Spatial Patterns: Alleviating Nonstationarities in Brain-Computer Interfacing</a></p>
<p>18 0.047558192 <a title="127-tfidf-18" href="./nips-2007-EEG-Based_Brain-Computer_Interaction%3A_Improved_Accuracy_by_Automatic_Single-Trial_Error_Detection.html">74 nips-2007-EEG-Based Brain-Computer Interaction: Improved Accuracy by Automatic Single-Trial Error Detection</a></p>
<p>19 0.04688992 <a title="127-tfidf-19" href="./nips-2007-Receding_Horizon_Differential_Dynamic_Programming.html">163 nips-2007-Receding Horizon Differential Dynamic Programming</a></p>
<p>20 0.041617323 <a title="127-tfidf-20" href="./nips-2007-The_Tradeoffs_of_Large_Scale_Learning.html">200 nips-2007-The Tradeoffs of Large Scale Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2007_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.131), (1, -0.054), (2, 0.055), (3, -0.025), (4, -0.06), (5, 0.019), (6, 0.016), (7, 0.018), (8, -0.088), (9, -0.109), (10, -0.054), (11, -0.034), (12, -0.098), (13, -0.029), (14, 0.134), (15, 0.105), (16, -0.044), (17, -0.046), (18, -0.247), (19, 0.247), (20, -0.019), (21, -0.029), (22, 0.117), (23, -0.009), (24, 0.06), (25, 0.067), (26, 0.004), (27, 0.081), (28, 0.036), (29, -0.01), (30, 0.047), (31, 0.074), (32, 0.027), (33, -0.065), (34, 0.078), (35, -0.007), (36, -0.103), (37, 0.026), (38, -0.003), (39, 0.005), (40, 0.013), (41, -0.063), (42, -0.111), (43, 0.043), (44, -0.044), (45, -0.065), (46, 0.076), (47, 0.089), (48, -0.091), (49, 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96829396 <a title="127-lsi-1" href="./nips-2007-Measuring_Neural_Synchrony_by_Message_Passing.html">127 nips-2007-Measuring Neural Synchrony by Message Passing</a></p>
<p>Author: Justin Dauwels, François Vialatte, Tomasz Rutkowski, Andrzej S. Cichocki</p><p>Abstract: A novel approach to measure the interdependence of two time series is proposed, referred to as “stochastic event synchrony” (SES); it quantiﬁes the alignment of two point processes by means of the following parameters: time delay, variance of the timing jitter, fraction of “spurious” events, and average similarity of events. SES may be applied to generic one-dimensional and multi-dimensional point processes, however, the paper mainly focusses on point processes in time-frequency domain. The average event similarity is in that case described by two parameters: the average frequency offset between events in the time-frequency plane, and the variance of the frequency offset (“frequency jitter”); SES then consists of ﬁve parameters in total. Those parameters quantify the synchrony of oscillatory events, and hence, they provide an alternative to existing synchrony measures that quantify amplitude or phase synchrony. The pairwise alignment of point processes is cast as a statistical inference problem, which is solved by applying the maxproduct algorithm on a graphical model. The SES parameters are determined from the resulting pairwise alignment by maximum a posteriori (MAP) estimation. The proposed interdependence measure is applied to the problem of detecting anomalies in EEG synchrony of Mild Cognitive Impairment (MCI) patients; the results indicate that SES signiﬁcantly improves the sensitivity of EEG in detecting MCI.</p><p>2 0.54532981 <a title="127-lsi-2" href="./nips-2007-TrueSkill_Through_Time%3A_Revisiting_the_History_of_Chess.html">208 nips-2007-TrueSkill Through Time: Revisiting the History of Chess</a></p>
<p>Author: Pierre Dangauthier, Ralf Herbrich, Tom Minka, Thore Graepel</p><p>Abstract: We extend the Bayesian skill rating system TrueSkill to infer entire time series of skills of players by smoothing through time instead of ﬁltering. The skill of each participating player, say, every year is represented by a latent skill variable which is aﬀected by the relevant game outcomes that year, and coupled with the skill variables of the previous and subsequent year. Inference in the resulting factor graph is carried out by approximate message passing (EP) along the time series of skills. As before the system tracks the uncertainty about player skills, explicitly models draws, can deal with any number of competing entities and can infer individual skills from team results. We extend the system to estimate player-speciﬁc draw margins. Based on these models we present an analysis of the skill curves of important players in the history of chess over the past 150 years. Results include plots of players’ lifetime skill development as well as the ability to compare the skills of diﬀerent players across time. Our results indicate that a) the overall playing strength has increased over the past 150 years, and b) that modelling a player’s ability to force a draw provides signiﬁcantly better predictive power. 1</p><p>3 0.46219495 <a title="127-lsi-3" href="./nips-2007-Temporal_Difference_Updating_without_a_Learning_Rate.html">191 nips-2007-Temporal Difference Updating without a Learning Rate</a></p>
<p>Author: Marcus Hutter, Shane Legg</p><p>Abstract: We derive an equation for temporal difference learning from statistical principles. Speciﬁcally, we start with the variational principle and then bootstrap to produce an updating rule for discounted state value estimates. The resulting equation is similar to the standard equation for temporal difference learning with eligibility traces, so called TD(λ), however it lacks the parameter α that speciﬁes the learning rate. In the place of this free parameter there is now an equation for the learning rate that is speciﬁc to each state transition. We experimentally test this new learning rule against TD(λ) and ﬁnd that it offers superior performance in various settings. Finally, we make some preliminary investigations into how to extend our new temporal difference algorithm to reinforcement learning. To do this we combine our update equation with both Watkins’ Q(λ) and Sarsa(λ) and ﬁnd that it again offers superior performance without a learning rate parameter. 1</p><p>4 0.42587838 <a title="127-lsi-4" href="./nips-2007-Incremental_Natural_Actor-Critic_Algorithms.html">102 nips-2007-Incremental Natural Actor-Critic Algorithms</a></p>
<p>Author: Shalabh Bhatnagar, Mohammad Ghavamzadeh, Mark Lee, Richard S. Sutton</p><p>Abstract: We present four new reinforcement learning algorithms based on actor-critic and natural-gradient ideas, and provide their convergence proofs. Actor-critic reinforcement learning methods are online approximations to policy iteration in which the value-function parameters are estimated using temporal difference learning and the policy parameters are updated by stochastic gradient descent. Methods based on policy gradients in this way are of special interest because of their compatibility with function approximation methods, which are needed to handle large or inﬁnite state spaces. The use of temporal difference learning in this way is of interest because in many applications it dramatically reduces the variance of the gradient estimates. The use of the natural gradient is of interest because it can produce better conditioned parameterizations and has been shown to further reduce variance in some cases. Our results extend prior two-timescale convergence results for actor-critic methods by Konda and Tsitsiklis by using temporal difference learning in the actor and by incorporating natural gradients, and they extend prior empirical studies of natural actor-critic methods by Peters, Vijayakumar and Schaal by providing the ﬁrst convergence proofs and the ﬁrst fully incremental algorithms. 1</p><p>5 0.42094404 <a title="127-lsi-5" href="./nips-2007-Loop_Series_and_Bethe_Variational_Bounds_in_Attractive_Graphical_Models.html">123 nips-2007-Loop Series and Bethe Variational Bounds in Attractive Graphical Models</a></p>
<p>Author: Alan S. Willsky, Erik B. Sudderth, Martin J. Wainwright</p><p>Abstract: Variational methods are frequently used to approximate or bound the partition or likelihood function of a Markov random ﬁeld. Methods based on mean ﬁeld theory are guaranteed to provide lower bounds, whereas certain types of convex relaxations provide upper bounds. In general, loopy belief propagation (BP) provides often accurate approximations, but not bounds. We prove that for a class of attractive binary models, the so–called Bethe approximation associated with any ﬁxed point of loopy BP always lower bounds the true likelihood. Empirically, this bound is much tighter than the naive mean ﬁeld bound, and requires no further work than running BP. We establish these lower bounds using a loop series expansion due to Chertkov and Chernyak, which we show can be derived as a consequence of the tree reparameterization characterization of BP ﬁxed points. 1</p><p>6 0.41256329 <a title="127-lsi-6" href="./nips-2007-Exponential_Family_Predictive_Representations_of_State.html">86 nips-2007-Exponential Family Predictive Representations of State</a></p>
<p>7 0.40349287 <a title="127-lsi-7" href="./nips-2007-Consistent_Minimization_of_Clustering_Objective_Functions.html">58 nips-2007-Consistent Minimization of Clustering Objective Functions</a></p>
<p>8 0.37832925 <a title="127-lsi-8" href="./nips-2007-Second_Order_Bilinear_Discriminant_Analysis_for_single_trial_EEG_analysis.html">173 nips-2007-Second Order Bilinear Discriminant Analysis for single trial EEG analysis</a></p>
<p>9 0.35620055 <a title="127-lsi-9" href="./nips-2007-Congruence_between_model_and_human_attention_reveals_unique_signatures_of_critical_visual_events.html">57 nips-2007-Congruence between model and human attention reveals unique signatures of critical visual events</a></p>
<p>10 0.33500552 <a title="127-lsi-10" href="./nips-2007-The_Infinite_Markov_Model.html">197 nips-2007-The Infinite Markov Model</a></p>
<p>11 0.3297745 <a title="127-lsi-11" href="./nips-2007-Invariant_Common_Spatial_Patterns%3A_Alleviating_Nonstationarities_in_Brain-Computer_Interfacing.html">106 nips-2007-Invariant Common Spatial Patterns: Alleviating Nonstationarities in Brain-Computer Interfacing</a></p>
<p>12 0.32308051 <a title="127-lsi-12" href="./nips-2007-Locality_and_low-dimensions_in_the_prediction_of_natural_experience_from_fMRI.html">122 nips-2007-Locality and low-dimensions in the prediction of natural experience from fMRI</a></p>
<p>13 0.29932475 <a title="127-lsi-13" href="./nips-2007-The_Tradeoffs_of_Large_Scale_Learning.html">200 nips-2007-The Tradeoffs of Large Scale Learning</a></p>
<p>14 0.28620479 <a title="127-lsi-14" href="./nips-2007-EEG-Based_Brain-Computer_Interaction%3A_Improved_Accuracy_by_Automatic_Single-Trial_Error_Detection.html">74 nips-2007-EEG-Based Brain-Computer Interaction: Improved Accuracy by Automatic Single-Trial Error Detection</a></p>
<p>15 0.28467819 <a title="127-lsi-15" href="./nips-2007-Modelling_motion_primitives_and_their_timing_in_biologically_executed_movements.html">133 nips-2007-Modelling motion primitives and their timing in biologically executed movements</a></p>
<p>16 0.26731268 <a title="127-lsi-16" href="./nips-2007-Bayesian_Policy_Learning_with_Trans-Dimensional_MCMC.html">34 nips-2007-Bayesian Policy Learning with Trans-Dimensional MCMC</a></p>
<p>17 0.25120932 <a title="127-lsi-17" href="./nips-2007-On_higher-order_perceptron_algorithms.html">146 nips-2007-On higher-order perceptron algorithms</a></p>
<p>18 0.25046617 <a title="127-lsi-18" href="./nips-2007-Catching_Up_Faster_in_Bayesian_Model_Selection_and_Model_Averaging.html">44 nips-2007-Catching Up Faster in Bayesian Model Selection and Model Averaging</a></p>
<p>19 0.24087413 <a title="127-lsi-19" href="./nips-2007-Inferring_Elapsed_Time_from_Stochastic_Neural_Processes.html">103 nips-2007-Inferring Elapsed Time from Stochastic Neural Processes</a></p>
<p>20 0.22755539 <a title="127-lsi-20" href="./nips-2007-Variational_Inference_for_Diffusion_Processes.html">213 nips-2007-Variational Inference for Diffusion Processes</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2007_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.047), (13, 0.059), (16, 0.024), (18, 0.014), (19, 0.057), (21, 0.056), (31, 0.039), (33, 0.349), (34, 0.023), (35, 0.016), (47, 0.052), (49, 0.022), (83, 0.086), (87, 0.014), (90, 0.051)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.76834738 <a title="127-lda-1" href="./nips-2007-Measuring_Neural_Synchrony_by_Message_Passing.html">127 nips-2007-Measuring Neural Synchrony by Message Passing</a></p>
<p>Author: Justin Dauwels, François Vialatte, Tomasz Rutkowski, Andrzej S. Cichocki</p><p>Abstract: A novel approach to measure the interdependence of two time series is proposed, referred to as “stochastic event synchrony” (SES); it quantiﬁes the alignment of two point processes by means of the following parameters: time delay, variance of the timing jitter, fraction of “spurious” events, and average similarity of events. SES may be applied to generic one-dimensional and multi-dimensional point processes, however, the paper mainly focusses on point processes in time-frequency domain. The average event similarity is in that case described by two parameters: the average frequency offset between events in the time-frequency plane, and the variance of the frequency offset (“frequency jitter”); SES then consists of ﬁve parameters in total. Those parameters quantify the synchrony of oscillatory events, and hence, they provide an alternative to existing synchrony measures that quantify amplitude or phase synchrony. The pairwise alignment of point processes is cast as a statistical inference problem, which is solved by applying the maxproduct algorithm on a graphical model. The SES parameters are determined from the resulting pairwise alignment by maximum a posteriori (MAP) estimation. The proposed interdependence measure is applied to the problem of detecting anomalies in EEG synchrony of Mild Cognitive Impairment (MCI) patients; the results indicate that SES signiﬁcantly improves the sensitivity of EEG in detecting MCI.</p><p>2 0.62288684 <a title="127-lda-2" href="./nips-2007-The_Epoch-Greedy_Algorithm_for_Multi-armed_Bandits_with_Side_Information.html">194 nips-2007-The Epoch-Greedy Algorithm for Multi-armed Bandits with Side Information</a></p>
<p>Author: John Langford, Tong Zhang</p><p>Abstract: We present Epoch-Greedy, an algorithm for contextual multi-armed bandits (also known as bandits with side information). Epoch-Greedy has the following properties: 1. No knowledge of a time horizon T is necessary. 2. The regret incurred by Epoch-Greedy is controlled by a sample complexity bound for a hypothesis class. 3. The regret scales as O(T 2/3 S 1/3 ) or better (sometimes, much better). Here S is the complexity term in a sample complexity bound for standard supervised learning. 1</p><p>3 0.38579392 <a title="127-lda-3" href="./nips-2007-A_Unified_Near-Optimal_Estimator_For_Dimension_Reduction_in_%24l_%5Calpha%24_%28%240%3C%5Calpha%5Cleq_2%24%29_Using_Stable_Random_Projections.html">13 nips-2007-A Unified Near-Optimal Estimator For Dimension Reduction in $l \alpha$ ($0<\alpha\leq 2$) Using Stable Random Projections</a></p>
<p>Author: Ping Li, Trevor J. Hastie</p><p>Abstract: Many tasks (e.g., clustering) in machine learning only require the lα distances instead of the original data. For dimension reductions in the lα norm (0 < α ≤ 2), the method of stable random projections can efﬁciently compute the lα distances in massive datasets (e.g., the Web or massive data streams) in one pass of the data. The estimation task for stable random projections has been an interesting topic. We propose a simple estimator based on the fractional power of the samples (projected data), which is surprisingly near-optimal in terms of the asymptotic variance. In fact, it achieves the Cram´ r-Rao bound when α = 2 and α = 0+. This e new result will be useful when applying stable random projections to distancebased clustering, classiﬁcations, kernels, massive data streams etc.</p><p>4 0.37818199 <a title="127-lda-4" href="./nips-2007-Simplified_Rules_and_Theoretical_Analysis_for_Information_Bottleneck_Optimization_and_PCA_with_Spiking_Neurons.html">177 nips-2007-Simplified Rules and Theoretical Analysis for Information Bottleneck Optimization and PCA with Spiking Neurons</a></p>
<p>Author: Lars Buesing, Wolfgang Maass</p><p>Abstract: We show that under suitable assumptions (primarily linearization) a simple and perspicuous online learning rule for Information Bottleneck optimization with spiking neurons can be derived. This rule performs on common benchmark tasks as well as a rather complex rule that has previously been proposed [1]. Furthermore, the transparency of this new learning rule makes a theoretical analysis of its convergence properties feasible. A variation of this learning rule (with sign changes) provides a theoretically founded method for performing Principal Component Analysis (PCA) with spiking neurons. By applying this rule to an ensemble of neurons, different principal components of the input can be extracted. In addition, it is possible to preferentially extract those principal components from incoming signals X that are related or are not related to some additional target signal YT . In a biological interpretation, this target signal YT (also called relevance variable) could represent proprioceptive feedback, input from other sensory modalities, or top-down signals. 1</p><p>5 0.3773672 <a title="127-lda-5" href="./nips-2007-Invariant_Common_Spatial_Patterns%3A_Alleviating_Nonstationarities_in_Brain-Computer_Interfacing.html">106 nips-2007-Invariant Common Spatial Patterns: Alleviating Nonstationarities in Brain-Computer Interfacing</a></p>
<p>Author: Benjamin Blankertz, Motoaki Kawanabe, Ryota Tomioka, Friederike Hohlefeld, Klaus-Robert Müller, Vadim V. Nikulin</p><p>Abstract: Brain-Computer Interfaces can suffer from a large variance of the subject conditions within and across sessions. For example vigilance ﬂuctuations in the individual, variable task involvement, workload etc. alter the characteristics of EEG signals and thus challenge a stable BCI operation. In the present work we aim to deﬁne features based on a variant of the common spatial patterns (CSP) algorithm that are constructed invariant with respect to such nonstationarities. We enforce invariance properties by adding terms to the denominator of a Rayleigh coefﬁcient representation of CSP such as disturbance covariance matrices from ﬂuctuations in visual processing. In this manner physiological prior knowledge can be used to shape the classiﬁcation engine for BCI. As a proof of concept we present a BCI classiﬁer that is robust to changes in the level of parietal α -activity. In other words, the EEG decoding still works when there are lapses in vigilance.</p><p>6 0.3737846 <a title="127-lda-6" href="./nips-2007-An_Analysis_of_Inference_with_the_Universum.html">24 nips-2007-An Analysis of Inference with the Universum</a></p>
<p>7 0.37265271 <a title="127-lda-7" href="./nips-2007-Locality_and_low-dimensions_in_the_prediction_of_natural_experience_from_fMRI.html">122 nips-2007-Locality and low-dimensions in the prediction of natural experience from fMRI</a></p>
<p>8 0.3702189 <a title="127-lda-8" href="./nips-2007-Near-Maximum_Entropy_Models_for_Binary_Neural_Representations_of_Natural_Images.html">138 nips-2007-Near-Maximum Entropy Models for Binary Neural Representations of Natural Images</a></p>
<p>9 0.36953679 <a title="127-lda-9" href="./nips-2007-A_Kernel_Statistical_Test_of_Independence.html">7 nips-2007-A Kernel Statistical Test of Independence</a></p>
<p>10 0.3691566 <a title="127-lda-10" href="./nips-2007-Second_Order_Bilinear_Discriminant_Analysis_for_single_trial_EEG_analysis.html">173 nips-2007-Second Order Bilinear Discriminant Analysis for single trial EEG analysis</a></p>
<p>11 0.36836004 <a title="127-lda-11" href="./nips-2007-Fast_and_Scalable_Training_of_Semi-Supervised_CRFs_with_Application_to_Activity_Recognition.html">88 nips-2007-Fast and Scalable Training of Semi-Supervised CRFs with Application to Activity Recognition</a></p>
<p>12 0.36816645 <a title="127-lda-12" href="./nips-2007-Convex_Relaxations_of_Latent_Variable_Training.html">63 nips-2007-Convex Relaxations of Latent Variable Training</a></p>
<p>13 0.36809087 <a title="127-lda-13" href="./nips-2007-EEG-Based_Brain-Computer_Interaction%3A_Improved_Accuracy_by_Automatic_Single-Trial_Error_Detection.html">74 nips-2007-EEG-Based Brain-Computer Interaction: Improved Accuracy by Automatic Single-Trial Error Detection</a></p>
<p>14 0.36787942 <a title="127-lda-14" href="./nips-2007-A_probabilistic_model_for_generating_realistic_lip_movements_from_speech.html">18 nips-2007-A probabilistic model for generating realistic lip movements from speech</a></p>
<p>15 0.36713576 <a title="127-lda-15" href="./nips-2007-Expectation_Maximization_and_Posterior_Constraints.html">84 nips-2007-Expectation Maximization and Posterior Constraints</a></p>
<p>16 0.36678752 <a title="127-lda-16" href="./nips-2007-Exponential_Family_Predictive_Representations_of_State.html">86 nips-2007-Exponential Family Predictive Representations of State</a></p>
<p>17 0.36678267 <a title="127-lda-17" href="./nips-2007-GRIFT%3A_A_graphical_model_for_inferring_visual_classification_features_from_human_data.html">93 nips-2007-GRIFT: A graphical model for inferring visual classification features from human data</a></p>
<p>18 0.36487371 <a title="127-lda-18" href="./nips-2007-Classification_via_Minimum_Incremental_Coding_Length_%28MICL%29.html">45 nips-2007-Classification via Minimum Incremental Coding Length (MICL)</a></p>
<p>19 0.36484578 <a title="127-lda-19" href="./nips-2007-Efficient_multiple_hyperparameter_learning_for_log-linear_models.html">79 nips-2007-Efficient multiple hyperparameter learning for log-linear models</a></p>
<p>20 0.36458057 <a title="127-lda-20" href="./nips-2007-Efficient_Convex_Relaxation_for_Transductive_Support_Vector_Machine.html">76 nips-2007-Efficient Convex Relaxation for Transductive Support Vector Machine</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
