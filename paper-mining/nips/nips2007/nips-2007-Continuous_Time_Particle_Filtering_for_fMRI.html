<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>59 nips-2007-Continuous Time Particle Filtering for fMRI</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-59" href="#">nips2007-59</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>59 nips-2007-Continuous Time Particle Filtering for fMRI</h1>
<br/><p>Source: <a title="nips-2007-59-pdf" href="http://papers.nips.cc/paper/3172-continuous-time-particle-filtering-for-fmri.pdf">pdf</a></p><p>Author: Lawrence Murray, Amos J. Storkey</p><p>Abstract: We construct a biologically motivated stochastic differential model of the neural and hemodynamic activity underlying the observed Blood Oxygen Level Dependent (BOLD) signal in Functional Magnetic Resonance Imaging (fMRI). The model poses a difﬁcult parameter estimation problem, both theoretically due to the nonlinearity and divergence of the differential system, and computationally due to its time and space complexity. We adapt a particle ﬁlter and smoother to the task, and discuss some of the practical approaches used to tackle the difﬁculties, including use of sparse matrices and parallelisation. Results demonstrate the tractability of the approach in its application to an effective connectivity study. 1</p><p>Reference: <a title="nips-2007-59-reference" href="../nips2007_reference/nips-2007-Continuous_Time_Particle_Filtering_for_fMRI_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 uk  Abstract We construct a biologically motivated stochastic differential model of the neural and hemodynamic activity underlying the observed Blood Oxygen Level Dependent (BOLD) signal in Functional Magnetic Resonance Imaging (fMRI). [sent-7, score-0.721]
</p><p>2 The model poses a difﬁcult parameter estimation problem, both theoretically due to the nonlinearity and divergence of the differential system, and computationally due to its time and space complexity. [sent-8, score-0.121]
</p><p>3 We adapt a particle ﬁlter and smoother to the task, and discuss some of the practical approaches used to tackle the difﬁculties, including use of sparse matrices and parallelisation. [sent-9, score-0.161]
</p><p>4 Results demonstrate the tractability of the approach in its application to an effective connectivity study. [sent-10, score-0.101]
</p><p>5 The Blood Oxygen Level Dependent (BOLD) signal, from which fMR images are produced, is a measure of hemodynamic activity in the brain – only an indirect indicator of the neural processes which are of primary interest in most cases. [sent-12, score-0.598]
</p><p>6 For studies of higher level patterns of activity, such as effective connectivity [1], it becomes necessary to strip away the hemodynamic activity to reveal the underlying neural interactions. [sent-13, score-0.655]
</p><p>7 In the ﬁrst instance, this is because interactions between regions at the neural level are not necessarily evident at the hemodynamic level [2]. [sent-14, score-0.565]
</p><p>8 In the second, analyses increasingly beneﬁt from the temporal qualities of the data, and the hemodynamic response itself is a form of temporal blurring. [sent-15, score-0.445]
</p><p>9 We are interested in the application of machine learning techniques to reveal meaningful patterns of neural activity from fMRI. [sent-16, score-0.213]
</p><p>10 In this paper we construct a model of the processes underlying the BOLD signal that is suitable for use in a ﬁltering framework. [sent-17, score-0.074]
</p><p>11 This is important; under ﬁxed inputs, DCM reduces to a generative model with steady state equilibrium BOLD activity and independent noise at each time point. [sent-20, score-0.281]
</p><p>12 Incorporating stochasticity allows proper statistical characterisation of the dependence between brain regions, rather than relying on relating decay rates1 . [sent-21, score-0.101]
</p><p>13 Our work has involved applying a number of ﬁltering techniques to estimate the parameters of the model, most notably the Unscented Kalman Filter [4] and various particle ﬁltering techniques. [sent-22, score-0.112]
</p><p>14 This paper presents the application of a simple particle ﬁlter. [sent-23, score-0.112]
</p><p>15 In contrast, the approach here is applied to multiple regions and their interactions, not single regions in isolation. [sent-25, score-0.146]
</p><p>16 Its major limitation is that it is static, assuming that all observations are temporally independent and that interactions are immediate and wholly evident within each single observation. [sent-32, score-0.146]
</p><p>17 Furthermore, it does not distinguish between neural and hemodynamic activity, and in essence identiﬁes interactions only at the hemodynamic level. [sent-33, score-0.806]
</p><p>18 The major contributions of this paper are establishing a stochastic model of latent neural and hemodynamic activity, formulating a ﬁltering and smoothing approach for inference in this model, and overcoming the basic practical difﬁculties associated with this. [sent-34, score-0.478]
</p><p>19 The estimated neural activity relates to the domain problem and is temporally consistent with the stimulus. [sent-35, score-0.258]
</p><p>20 The approach is also able to establish connectivity relationships. [sent-36, score-0.101]
</p><p>21 The ability of this model to establish such connectivity relationships on the basis of stochastic temporal relationships is signiﬁcant. [sent-37, score-0.213]
</p><p>22 One problem in using structural equation models for effective connectivity analysis is the statistical equivalence of different causal models. [sent-38, score-0.192]
</p><p>23 By presuming a temporal causal order, temporal models of this form have no such equivalence problems. [sent-39, score-0.148]
</p><p>24 Any small amount of temporal connectivity information available in fMRI data is of signiﬁcant beneﬁt, as it can disambiguate between statically equivalent models. [sent-40, score-0.153]
</p><p>25 Section 2 outlines the basis of the hemodynamic model that is used. [sent-41, score-0.371]
</p><p>26 This is combined with neural, input and measurement models in Section 3 to give the full framework. [sent-42, score-0.086]
</p><p>27 2  Hemodynamics  Temporal analysis of fMRI is signiﬁcantly confounded by the fact that it does not measure brain activity directly, but instead via hemodynamic activity, which (crudely) temporally smooths the activity signal. [sent-44, score-0.756]
</p><p>28 The quality of temporal analysis therefore depends signiﬁcantly on the quality of model used to relate neural and hemodynamic activity. [sent-45, score-0.473]
</p><p>29 This models a venous compartment as a balloon using Windkessel dynamics. [sent-47, score-0.393]
</p><p>30 The state of the compartment is represented by its blood volume normalised to the volume at rest, v = V /V0 (blood volume V , rest volume V0 ), and deoxyhemoglobin (dHb) content normalised to the content at rest, q = Q/Q0 (dHb content Q, rest content Q0 ). [sent-48, score-0.915]
</p><p>31 The compartment receives inﬂow of fully oxygenated arterial blood fin (t), extracts oxygen from the blood, and expels partially deoxygenated blood fout (t). [sent-49, score-0.738]
</p><p>32 The full dynamics may be represented by the differential system: dq dt dv dt  = =  E(t) ≈ fout (v) ≈  1 E(t) q fin (t) − fout (v) τ0 E0 v 1 [fin (t) − fout (v)] τ0 1  1 − (1 − E0 ) fin (t) v  1 α  (1) (2) (3) (4)  where τ0 and α are constants, and E0 is the oxygen extraction fraction at rest. [sent-50, score-0.882]
</p><p>33 This base model is driven by the independent input fin (t). [sent-51, score-0.165]
</p><p>34 It may be further extended to couple in neural activity z(t) via an abstract vasodilatory signal s [13]: df dt ds dt  = =  s  (5)  z(t) −  s (f − 1) − . [sent-52, score-0.474]
</p><p>35 τs τf  (6)  The complete system deﬁned by Equations 1-6, with fin (t) = f , is now driven by the independent input z(t). [sent-53, score-0.181]
</p><p>36 From the balloon model, the relative BOLD signal change over the baseline S at any time may be predicted using [12]: q ∆S = V0 k1 (1 − q) + k2 1 − + k3 (1 − v) . [sent-54, score-0.221]
</p><p>37 2 0  30  0  30  Figure 1: Response of the balloon model to a 1s burst of neural activity at magnitude 1 (time on x axis, response on y axis). [sent-66, score-0.42]
</p><p>38 3  Model  We deﬁne a model of the neural and hemodynamic interactions between M regions of interest. [sent-67, score-0.568]
</p><p>39 A region consists of neural tissue and a venous compartment. [sent-68, score-0.148]
</p><p>40 We construct a model of the interactions between regions in four parts – the input model, the neural model, the hemodynamic model and the measurement model. [sent-73, score-0.684]
</p><p>41 This is similar to the deterministic neural model of DCM expressed as a stochastic differential equation, but excludes the bilinear components allowing modulation of connections between seeds. [sent-83, score-0.202]
</p><p>42 In addition, and unlike DCM, nonlinear interactions between regions could also be included to account for modulatory activity. [sent-85, score-0.186]
</p><p>43 3 Hemodynamic model Within each region, the variables fi , si , qi , vi and zi interact according to a stochastic extension of the balloon model (c. [sent-88, score-0.689]
</p><p>44 4  k1 7E0  k2 2  Table 1: Nominal values for constants of the balloon model [12; 13]. [sent-98, score-0.207]
</p><p>45 Equation 7): ∆yi = V0 k1 (1 − qi ) + k2 1 −  qi vi  + k3 (1 − vi ) . [sent-105, score-0.47]
</p><p>46 (13)  ∗ This may be converted to an absolute measurement yi for comparison with actual observations by using the baseline signal bi for each seed and an independent noise source ξ ∼ N (0, 1): ∗ yi = bi (1 + ∆yi ) + σyi ξ. [sent-106, score-0.327]
</p><p>47 This ﬁts nicely into a ﬁltering framework, whereby the input, neural and hemodynamic models deﬁne state transitions, and the measurement model predicted observations. [sent-108, score-0.534]
</p><p>48 , M , σzi , σfi , σsi , σqi and σvi deﬁne the system noise and σyi the measurement noise. [sent-112, score-0.193]
</p><p>49 Because of non-Gaussianity and nonlinearity of the transitions and measurements, a two-pass particle ﬁlter is proposed to solve the problem. [sent-131, score-0.14]
</p><p>50 The forward pass is performed using a sequential importance resampling technique similar to C ONDENSATION [15], obtaining P (x(tn ) | y(t1 ), . [sent-132, score-0.215]
</p><p>51 The transition of particles through the differential system uses a 4th/5th order Runge-Kutta-Fehlberg method, the adaptive step size maintaining ﬁxed error bounds. [sent-140, score-0.307]
</p><p>52 Naively, we can simply negate the derivatives of the differential system and step backwards to obtain P (x(tn ) | y(tn+1 ), . [sent-142, score-0.264]
</p><p>53 , y(tT )), then fuse these with the results of the forwards pass to obtain the desired posterior. [sent-145, score-0.379]
</p><p>54 Unfortunately, such a backwards model is divergent in q and v, so that the accumulated numerical errors of the Runge-Kutta can easily cause an explosion to implausible values and a tip-toe adaptive step size to maintain error bounds. [sent-146, score-0.185]
</p><p>55 An alternative is a two-pass smoother that reuses particles from the forwards pass [17], reweighting them on the backwards pass so that no explicit backwards dynamics are required. [sent-148, score-1.095]
</p><p>56 This sidesteps the divergence issue completely, but is computationally and spatially expensive and requires computa(i) (j) (i) (j) tion of p(x(tn ) = stn | x(tn−1 ) = stn−1 ) for particular particles stn and stn−1 . [sent-149, score-0.662]
</p><p>57 (i)  (i)  The forwards pass provides a weighted sample set {(st , πt )} at each time point t = t1 , . [sent-151, score-0.379]
</p><p>58 Initialising with ψtT = πtT , the backwards step to calculate weights at time tn is 4  as follows [17]2 : αtn γ tn  (i,j)  = =  p(x(tn+1 ) = stn+1 | x(tn ) = stn ) for i, j = 1, . [sent-158, score-1.179]
</p><p>59 , P αtn πtn  (i)  δ tn ψtn  = =  T αtn (ψtn+1 γtn ) where is element-wise division, πtn ⊗ δtn where ⊗ is element-wise multiplication. [sent-161, score-0.388]
</p><p>60 , P  There are numerous means of propagating particles through the forwards pass that accommodate the resampling step and propagation of the Wiener noise through the nonlinearity. [sent-166, score-0.658]
</p><p>61 These include various stochastic Runge-Kutta methods, the Unscented Transformation [4] or a simple Euler scheme using ﬁxed time steps and adding an appropriate portion of noise after each step. [sent-167, score-0.091]
</p><p>62 The requirement to (i) (j) efﬁciently make P 2 density calculations of p(x(tn+1 ) = stn+1 | x(tn ) = stn ) during the backwards pass is challenging with such approaches, however. [sent-168, score-0.626]
</p><p>63 To keep things simple, we instead simply propagate particles noiselessly through the transition function, and add noise from the Wiener process only at times t1 , . [sent-169, score-0.304]
</p><p>64 This reasonably approximates the noise of (j) the system while keeping the density calculations very simple – transition stn noiselessly to obtain the mean value of a Gaussian with covariance equal to that of the system noise, then calculate the (i) density of this Gaussian at stn+1 . [sent-173, score-0.565]
</p><p>65 Observe that if system noise is sufﬁciently tight, αtn becomes sparse as negligibly small densities round to zero. [sent-174, score-0.107]
</p><p>66 Propagation of particles through the transition function and density calculations can be performed in parallel. [sent-176, score-0.258]
</p><p>67 For the backwards pass, each particle at tn need only be transitioned once to produce a Gaussian from which the density of all particles at tn+1 can be calculated, ﬁlling in one column of αtn . [sent-178, score-0.848]
</p><p>68 [18]), applying a broad prior and small system noise to suggest that they are generally constant. [sent-181, score-0.107]
</p><p>69 The same applies to parameters of the balloon model, which may be included to allow variation in the hemodynamic response across the brain. [sent-182, score-0.518]
</p><p>70 5  Experiments  We apply the model to data collected during a simple ﬁnger tapping exercise. [sent-183, score-0.128]
</p><p>71 The experimental paradigm consists of alternating 6TR blocks of rest and tapping of the right index ﬁnger at 1. [sent-187, score-0.148]
</p><p>72 5Hz, where tapping frequency is provided by a constant audio cue, present during both rest and tapping phases. [sent-188, score-0.246]
</p><p>73 All scans across all sessions were realigned using SPM5 [19] and a two-level random effects analysis performed, from which 13 voxels were selected to represent regions of interest. [sent-189, score-0.135]
</p><p>74 The mean of all sessions is used as the measurement y(t), which consists of M = 4 elements, one for each region. [sent-192, score-0.116]
</p><p>75 , M and the prior and system noise as in Table 2. [sent-204, score-0.107]
</p><p>76 P = 106 particles are used for the forwards pass, downsampling to 2. [sent-206, score-0.382]
</p><p>77 5 × 104 particles for the more expensive backwards pass. [sent-207, score-0.321]
</p><p>78 2  We have expressed this in matrix notation rather than the original notation in [17]  5  4x108  2  3x108  1  2x108 0  1x108  -1  0 0  6  12  18  0  Figure 2: Experimental input u(t), x axis is time t expressed in TRs. [sent-208, score-0.11]
</p><p>79 Ai,i Ai,j Ci,1 zi fi , si , qi , vi , ci bi  i = 1, . [sent-209, score-0.449]
</p><p>80 The particle ﬁlter and smoother are distributed across nodes and run in parallel using the dysii Dynamic Systems Library 4 . [sent-233, score-0.161]
</p><p>81 After application of the ﬁlter, the predicted neural activity is given in Figure 4 and parameter estimates in Figures 6 and 7. [sent-234, score-0.213]
</p><p>82 6  Discussion  The model captures the expected underlying form for neural activity, with all regions distinctly correlated with the experimental stimulus. [sent-236, score-0.153]
</p><p>83 The parameters found typically match those expected for this form of ﬁnger tapping task. [sent-238, score-0.098]
</p><p>84 Particles stored during the forwards pass do not necessarily support the distributions obtained during the backwards pass. [sent-241, score-0.534]
</p><p>85 This is particularly obvious towards the extreme left of Figure 4, where the smoothed results appear to become erratic, essentially due to degeneracy in the backwards pass. [sent-242, score-0.221]
</p><p>86 Furthermore, while the smooth weighting of particles in the forwards pass is informative, that of the backwards pass is often not, potentially relying on heavy weighting of outlying particles and shedding little light on the actual nature of the distributions involved. [sent-243, score-1.058]
</p><p>87 The particle ﬁlter is able to establish consistent neural activity and parameter estimates across runs. [sent-246, score-0.325]
</p><p>88 This certainly shows the stochastic model and particle ﬁlter to be a promising approach for systematic connectivity analysis. [sent-248, score-0.273]
</p><p>89 Forwards pass results as shaded histogram, smoothed results as solid line with 2σ error, circles actual measurements. [sent-266, score-0.308]
</p><p>90 Figure 4: Neural activity predictions z (y axis) over time (x axis). [sent-267, score-0.163]
</p><p>91 Forwards pass results as shaded histogram, smoothed results as solid line with 2σ error. [sent-268, score-0.308]
</p><p>92 Forwards pass results as shaded histogram, smoothed results as solid line with 2σ error. [sent-274, score-0.308]
</p><p>93 Forwards pass results as shaded histogram, smoothed results as solid line with 2σ error. [sent-278, score-0.308]
</p><p>94 (2003) Modeling regional and psychophysiologic interactions in fMRI: the importance of hemodynamic deconvolution. [sent-292, score-0.415]
</p><p>95 (2004) A state-space model of the hemodynamic approach: nonlinear ﬁltering of BOLD signals. [sent-313, score-0.41]
</p><p>96 (2003) Altered effective connectivity during working memory performance in schizophrenia: a study with fMRI and structural equation modeling. [sent-337, score-0.148]
</p><p>97 (2005) Modulation of effective connectivity inside the working memory network in patients at the earliest stage of multiple sclerosis. [sent-341, score-0.101]
</p><p>98 (1998) Dynamics of blood ﬂow and oxygenation changes during brain activation: The balloon model. [sent-358, score-0.379]
</p><p>99 (2000) Nonlinear responses in fMRI: The balloon model, Volterra kernels, and other hemodynamics. [sent-366, score-0.177]
</p><p>100 (1996) Monte Carlo ﬁlter and smoother for non-Gaussian nonlinear state space models. [sent-376, score-0.115]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('tn', 0.388), ('hemodynamic', 0.341), ('stn', 0.248), ('forwards', 0.216), ('balloon', 0.177), ('particles', 0.166), ('pass', 0.163), ('activity', 0.163), ('blood', 0.158), ('backwards', 0.155), ('fmri', 0.142), ('fin', 0.135), ('tt', 0.135), ('vi', 0.12), ('compartment', 0.118), ('qi', 0.115), ('particle', 0.112), ('bold', 0.112), ('axis', 0.11), ('connectivity', 0.101), ('normalised', 0.1), ('dw', 0.098), ('tapping', 0.098), ('venous', 0.098), ('neuroimage', 0.095), ('fi', 0.092), ('lter', 0.092), ('dcm', 0.09), ('fout', 0.09), ('measurement', 0.086), ('dt', 0.086), ('friston', 0.079), ('oxygen', 0.079), ('interactions', 0.074), ('regions', 0.073), ('dhb', 0.068), ('nger', 0.068), ('wiener', 0.067), ('smoothed', 0.066), ('differential', 0.063), ('ltering', 0.062), ('noise', 0.061), ('cacies', 0.054), ('resonance', 0.054), ('si', 0.053), ('temporal', 0.052), ('resampling', 0.052), ('rest', 0.05), ('neural', 0.05), ('content', 0.05), ('shaded', 0.049), ('smoother', 0.049), ('edinburgh', 0.047), ('magnetic', 0.047), ('structural', 0.047), ('system', 0.046), ('kitagawa', 0.045), ('mcgonigle', 0.045), ('noiselessly', 0.045), ('ozaki', 0.045), ('vasodilatory', 0.045), ('temporally', 0.045), ('brain', 0.044), ('signal', 0.044), ('causal', 0.044), ('zi', 0.042), ('imaging', 0.041), ('yi', 0.041), ('sem', 0.039), ('isard', 0.039), ('penny', 0.039), ('storkey', 0.039), ('unscented', 0.039), ('nonlinear', 0.039), ('kalman', 0.037), ('histogram', 0.036), ('xt', 0.035), ('ow', 0.034), ('axt', 0.033), ('calculations', 0.033), ('transition', 0.032), ('nominal', 0.032), ('voxels', 0.032), ('stochastic', 0.03), ('model', 0.03), ('murray', 0.03), ('sessions', 0.03), ('solid', 0.03), ('relying', 0.029), ('modulation', 0.029), ('dynamics', 0.028), ('nonlinearity', 0.028), ('stochasticity', 0.028), ('volume', 0.028), ('state', 0.027), ('bi', 0.027), ('density', 0.027), ('evident', 0.027), ('informatics', 0.027), ('smoothing', 0.027)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000006 <a title="59-tfidf-1" href="./nips-2007-Continuous_Time_Particle_Filtering_for_fMRI.html">59 nips-2007-Continuous Time Particle Filtering for fMRI</a></p>
<p>Author: Lawrence Murray, Amos J. Storkey</p><p>Abstract: We construct a biologically motivated stochastic differential model of the neural and hemodynamic activity underlying the observed Blood Oxygen Level Dependent (BOLD) signal in Functional Magnetic Resonance Imaging (fMRI). The model poses a difﬁcult parameter estimation problem, both theoretically due to the nonlinearity and divergence of the differential system, and computationally due to its time and space complexity. We adapt a particle ﬁlter and smoother to the task, and discuss some of the practical approaches used to tackle the difﬁculties, including use of sparse matrices and parallelisation. Results demonstrate the tractability of the approach in its application to an effective connectivity study. 1</p><p>2 0.16195245 <a title="59-tfidf-2" href="./nips-2007-A_neural_network_implementing_optimal_state_estimation_based_on_dynamic_spike_train_decoding.html">17 nips-2007-A neural network implementing optimal state estimation based on dynamic spike train decoding</a></p>
<p>Author: Omer Bobrowski, Ron Meir, Shy Shoham, Yonina Eldar</p><p>Abstract: It is becoming increasingly evident that organisms acting in uncertain dynamical environments often employ exact or approximate Bayesian statistical calculations in order to continuously estimate the environmental state, integrate information from multiple sensory modalities, form predictions and choose actions. What is less clear is how these putative computations are implemented by cortical neural networks. An additional level of complexity is introduced because these networks observe the world through spike trains received from primary sensory afferents, rather than directly. A recent line of research has described mechanisms by which such computations can be implemented using a network of neurons whose activity directly represents a probability distribution across the possible “world states”. Much of this work, however, uses various approximations, which severely restrict the domain of applicability of these implementations. Here we make use of rigorous mathematical results from the theory of continuous time point process ﬁltering, and show how optimal real-time state estimation and prediction may be implemented in a general setting using linear neural networks. We demonstrate the applicability of the approach with several examples, and relate the required network properties to the statistical nature of the environment, thereby quantifying the compatibility of a given network with its environment. 1</p><p>3 0.15918052 <a title="59-tfidf-3" href="./nips-2007-Predicting_Brain_States_from_fMRI_Data%3A_Incremental_Functional_Principal_Component_Regression.html">154 nips-2007-Predicting Brain States from fMRI Data: Incremental Functional Principal Component Regression</a></p>
<p>Author: Sennay Ghebreab, Arnold Smeulders, Pieter Adriaans</p><p>Abstract: We propose a method for reconstruction of human brain states directly from functional neuroimaging data. The method extends the traditional multivariate regression analysis of discretized fMRI data to the domain of stochastic functional measurements, facilitating evaluation of brain responses to complex stimuli and boosting the power of functional imaging. The method searches for sets of voxel time courses that optimize a multivariate functional linear model in terms of R2 statistic. Population based incremental learning is used to identify spatially distributed brain responses to complex stimuli without attempting to localize function ﬁrst. Variation in hemodynamic lag across brain areas and among subjects is taken into account by voxel-wise non-linear registration of stimulus pattern to fMRI data. Application of the method on an international test benchmark for prediction of naturalistic stimuli from new and unknown fMRI data shows that the method successfully uncovers spatially distributed parts of the brain that are highly predictive of a given stimulus. 1</p><p>4 0.12890594 <a title="59-tfidf-4" href="./nips-2007-Locality_and_low-dimensions_in_the_prediction_of_natural_experience_from_fMRI.html">122 nips-2007-Locality and low-dimensions in the prediction of natural experience from fMRI</a></p>
<p>Author: Francois Meyer, Greg Stephens</p><p>Abstract: Functional Magnetic Resonance Imaging (fMRI) provides dynamical access into the complex functioning of the human brain, detailing the hemodynamic activity of thousands of voxels during hundreds of sequential time points. One approach towards illuminating the connection between fMRI and cognitive function is through decoding; how do the time series of voxel activities combine to provide information about internal and external experience? Here we seek models of fMRI decoding which are balanced between the simplicity of their interpretation and the effectiveness of their prediction. We use signals from a subject immersed in virtual reality to compare global and local methods of prediction applying both linear and nonlinear techniques of dimensionality reduction. We ﬁnd that the prediction of complex stimuli is remarkably low-dimensional, saturating with less than 100 features. In particular, we build effective models based on the decorrelated components of cognitive activity in the classically-deﬁned Brodmann areas. For some of the stimuli, the top predictive areas were surprisingly transparent, including Wernicke’s area for verbal instructions, visual cortex for facial and body features, and visual-temporal regions for velocity. Direct sensory experience resulted in the most robust predictions, with the highest correlation (c ∼ 0.8) between the predicted and experienced time series of verbal instructions. Techniques based on non-linear dimensionality reduction (Laplacian eigenmaps) performed similarly. The interpretability and relative simplicity of our approach provides a conceptual basis upon which to build more sophisticated techniques for fMRI decoding and offers a window into cognitive function during dynamic, natural experience. 1</p><p>5 0.11166693 <a title="59-tfidf-5" href="./nips-2007-Inferring_Elapsed_Time_from_Stochastic_Neural_Processes.html">103 nips-2007-Inferring Elapsed Time from Stochastic Neural Processes</a></p>
<p>Author: Misha Ahrens, Maneesh Sahani</p><p>Abstract: Many perceptual processes and neural computations, such as speech recognition, motor control and learning, depend on the ability to measure and mark the passage of time. However, the processes that make such temporal judgements possible are unknown. A number of different hypothetical mechanisms have been advanced, all of which depend on the known, temporally predictable evolution of a neural or psychological state, possibly through oscillations or the gradual decay of a memory trace. Alternatively, judgements of elapsed time might be based on observations of temporally structured, but stochastic processes. Such processes need not be speciﬁc to the sense of time; typical neural and sensory processes contain at least some statistical structure across a range of time scales. Here, we investigate the statistical properties of an estimator of elapsed time which is based on a simple family of stochastic process. 1</p><p>6 0.10624608 <a title="59-tfidf-6" href="./nips-2007-The_rat_as_particle_filter.html">203 nips-2007-The rat as particle filter</a></p>
<p>7 0.099139884 <a title="59-tfidf-7" href="./nips-2007-Variational_Inference_for_Diffusion_Processes.html">213 nips-2007-Variational Inference for Diffusion Processes</a></p>
<p>8 0.091655344 <a title="59-tfidf-8" href="./nips-2007-Testing_for_Homogeneity_with_Kernel_Fisher_Discriminant_Analysis.html">192 nips-2007-Testing for Homogeneity with Kernel Fisher Discriminant Analysis</a></p>
<p>9 0.076208994 <a title="59-tfidf-9" href="./nips-2007-Second_Order_Bilinear_Discriminant_Analysis_for_single_trial_EEG_analysis.html">173 nips-2007-Second Order Bilinear Discriminant Analysis for single trial EEG analysis</a></p>
<p>10 0.072021589 <a title="59-tfidf-10" href="./nips-2007-A_general_agnostic_active_learning_algorithm.html">15 nips-2007-A general agnostic active learning algorithm</a></p>
<p>11 0.066302858 <a title="59-tfidf-11" href="./nips-2007-Robust_Regression_with_Twinned_Gaussian_Processes.html">170 nips-2007-Robust Regression with Twinned Gaussian Processes</a></p>
<p>12 0.062116146 <a title="59-tfidf-12" href="./nips-2007-Random_Sampling_of_States_in_Dynamic_Programming.html">162 nips-2007-Random Sampling of States in Dynamic Programming</a></p>
<p>13 0.060932226 <a title="59-tfidf-13" href="./nips-2007-Neural_characterization_in_partially_observed_populations_of_spiking_neurons.html">140 nips-2007-Neural characterization in partially observed populations of spiking neurons</a></p>
<p>14 0.055656649 <a title="59-tfidf-14" href="./nips-2007-On_Sparsity_and_Overcompleteness_in_Image_Models.html">145 nips-2007-On Sparsity and Overcompleteness in Image Models</a></p>
<p>15 0.05508266 <a title="59-tfidf-15" href="./nips-2007-People_Tracking_with_the_Laplacian_Eigenmaps_Latent_Variable_Model.html">153 nips-2007-People Tracking with the Laplacian Eigenmaps Latent Variable Model</a></p>
<p>16 0.054164998 <a title="59-tfidf-16" href="./nips-2007-Variational_inference_for_Markov_jump_processes.html">214 nips-2007-Variational inference for Markov jump processes</a></p>
<p>17 0.053051181 <a title="59-tfidf-17" href="./nips-2007-Simplified_Rules_and_Theoretical_Analysis_for_Information_Bottleneck_Optimization_and_PCA_with_Spiking_Neurons.html">177 nips-2007-Simplified Rules and Theoretical Analysis for Information Bottleneck Optimization and PCA with Spiking Neurons</a></p>
<p>18 0.051551525 <a title="59-tfidf-18" href="./nips-2007-Learning_Horizontal_Connections_in_a_Sparse_Coding_Model_of_Natural_Images.html">111 nips-2007-Learning Horizontal Connections in a Sparse Coding Model of Natural Images</a></p>
<p>19 0.051041979 <a title="59-tfidf-19" href="./nips-2007-Bayesian_Inference_for_Spiking_Neuron_Models_with_a_Sparsity_Prior.html">33 nips-2007-Bayesian Inference for Spiking Neuron Models with a Sparsity Prior</a></p>
<p>20 0.050668657 <a title="59-tfidf-20" href="./nips-2007-Modeling_image_patches_with_a_directed_hierarchy_of_Markov_random_fields.html">132 nips-2007-Modeling image patches with a directed hierarchy of Markov random fields</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2007_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.182), (1, 0.026), (2, 0.098), (3, -0.014), (4, -0.013), (5, 0.082), (6, -0.027), (7, 0.023), (8, -0.122), (9, -0.166), (10, 0.013), (11, 0.039), (12, -0.015), (13, -0.001), (14, 0.168), (15, 0.038), (16, -0.005), (17, -0.058), (18, 0.075), (19, 0.053), (20, 0.111), (21, 0.051), (22, -0.032), (23, -0.121), (24, -0.03), (25, 0.057), (26, -0.055), (27, 0.024), (28, -0.141), (29, -0.053), (30, -0.01), (31, -0.013), (32, 0.158), (33, 0.063), (34, -0.088), (35, -0.025), (36, 0.034), (37, -0.057), (38, 0.107), (39, -0.024), (40, 0.011), (41, 0.011), (42, -0.013), (43, -0.054), (44, 0.104), (45, 0.132), (46, -0.089), (47, -0.024), (48, 0.141), (49, 0.001)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94081008 <a title="59-lsi-1" href="./nips-2007-Continuous_Time_Particle_Filtering_for_fMRI.html">59 nips-2007-Continuous Time Particle Filtering for fMRI</a></p>
<p>Author: Lawrence Murray, Amos J. Storkey</p><p>Abstract: We construct a biologically motivated stochastic differential model of the neural and hemodynamic activity underlying the observed Blood Oxygen Level Dependent (BOLD) signal in Functional Magnetic Resonance Imaging (fMRI). The model poses a difﬁcult parameter estimation problem, both theoretically due to the nonlinearity and divergence of the differential system, and computationally due to its time and space complexity. We adapt a particle ﬁlter and smoother to the task, and discuss some of the practical approaches used to tackle the difﬁculties, including use of sparse matrices and parallelisation. Results demonstrate the tractability of the approach in its application to an effective connectivity study. 1</p><p>2 0.64447457 <a title="59-lsi-2" href="./nips-2007-Predicting_Brain_States_from_fMRI_Data%3A_Incremental_Functional_Principal_Component_Regression.html">154 nips-2007-Predicting Brain States from fMRI Data: Incremental Functional Principal Component Regression</a></p>
<p>Author: Sennay Ghebreab, Arnold Smeulders, Pieter Adriaans</p><p>Abstract: We propose a method for reconstruction of human brain states directly from functional neuroimaging data. The method extends the traditional multivariate regression analysis of discretized fMRI data to the domain of stochastic functional measurements, facilitating evaluation of brain responses to complex stimuli and boosting the power of functional imaging. The method searches for sets of voxel time courses that optimize a multivariate functional linear model in terms of R2 statistic. Population based incremental learning is used to identify spatially distributed brain responses to complex stimuli without attempting to localize function ﬁrst. Variation in hemodynamic lag across brain areas and among subjects is taken into account by voxel-wise non-linear registration of stimulus pattern to fMRI data. Application of the method on an international test benchmark for prediction of naturalistic stimuli from new and unknown fMRI data shows that the method successfully uncovers spatially distributed parts of the brain that are highly predictive of a given stimulus. 1</p><p>3 0.62169558 <a title="59-lsi-3" href="./nips-2007-Locality_and_low-dimensions_in_the_prediction_of_natural_experience_from_fMRI.html">122 nips-2007-Locality and low-dimensions in the prediction of natural experience from fMRI</a></p>
<p>Author: Francois Meyer, Greg Stephens</p><p>Abstract: Functional Magnetic Resonance Imaging (fMRI) provides dynamical access into the complex functioning of the human brain, detailing the hemodynamic activity of thousands of voxels during hundreds of sequential time points. One approach towards illuminating the connection between fMRI and cognitive function is through decoding; how do the time series of voxel activities combine to provide information about internal and external experience? Here we seek models of fMRI decoding which are balanced between the simplicity of their interpretation and the effectiveness of their prediction. We use signals from a subject immersed in virtual reality to compare global and local methods of prediction applying both linear and nonlinear techniques of dimensionality reduction. We ﬁnd that the prediction of complex stimuli is remarkably low-dimensional, saturating with less than 100 features. In particular, we build effective models based on the decorrelated components of cognitive activity in the classically-deﬁned Brodmann areas. For some of the stimuli, the top predictive areas were surprisingly transparent, including Wernicke’s area for verbal instructions, visual cortex for facial and body features, and visual-temporal regions for velocity. Direct sensory experience resulted in the most robust predictions, with the highest correlation (c ∼ 0.8) between the predicted and experienced time series of verbal instructions. Techniques based on non-linear dimensionality reduction (Laplacian eigenmaps) performed similarly. The interpretability and relative simplicity of our approach provides a conceptual basis upon which to build more sophisticated techniques for fMRI decoding and offers a window into cognitive function during dynamic, natural experience. 1</p><p>4 0.5544219 <a title="59-lsi-4" href="./nips-2007-Inferring_Elapsed_Time_from_Stochastic_Neural_Processes.html">103 nips-2007-Inferring Elapsed Time from Stochastic Neural Processes</a></p>
<p>Author: Misha Ahrens, Maneesh Sahani</p><p>Abstract: Many perceptual processes and neural computations, such as speech recognition, motor control and learning, depend on the ability to measure and mark the passage of time. However, the processes that make such temporal judgements possible are unknown. A number of different hypothetical mechanisms have been advanced, all of which depend on the known, temporally predictable evolution of a neural or psychological state, possibly through oscillations or the gradual decay of a memory trace. Alternatively, judgements of elapsed time might be based on observations of temporally structured, but stochastic processes. Such processes need not be speciﬁc to the sense of time; typical neural and sensory processes contain at least some statistical structure across a range of time scales. Here, we investigate the statistical properties of an estimator of elapsed time which is based on a simple family of stochastic process. 1</p><p>5 0.52824187 <a title="59-lsi-5" href="./nips-2007-A_neural_network_implementing_optimal_state_estimation_based_on_dynamic_spike_train_decoding.html">17 nips-2007-A neural network implementing optimal state estimation based on dynamic spike train decoding</a></p>
<p>Author: Omer Bobrowski, Ron Meir, Shy Shoham, Yonina Eldar</p><p>Abstract: It is becoming increasingly evident that organisms acting in uncertain dynamical environments often employ exact or approximate Bayesian statistical calculations in order to continuously estimate the environmental state, integrate information from multiple sensory modalities, form predictions and choose actions. What is less clear is how these putative computations are implemented by cortical neural networks. An additional level of complexity is introduced because these networks observe the world through spike trains received from primary sensory afferents, rather than directly. A recent line of research has described mechanisms by which such computations can be implemented using a network of neurons whose activity directly represents a probability distribution across the possible “world states”. Much of this work, however, uses various approximations, which severely restrict the domain of applicability of these implementations. Here we make use of rigorous mathematical results from the theory of continuous time point process ﬁltering, and show how optimal real-time state estimation and prediction may be implemented in a general setting using linear neural networks. We demonstrate the applicability of the approach with several examples, and relate the required network properties to the statistical nature of the environment, thereby quantifying the compatibility of a given network with its environment. 1</p><p>6 0.51807284 <a title="59-lsi-6" href="./nips-2007-Variational_inference_for_Markov_jump_processes.html">214 nips-2007-Variational inference for Markov jump processes</a></p>
<p>7 0.48408478 <a title="59-lsi-7" href="./nips-2007-Variational_Inference_for_Diffusion_Processes.html">213 nips-2007-Variational Inference for Diffusion Processes</a></p>
<p>8 0.4679181 <a title="59-lsi-8" href="./nips-2007-Scan_Strategies_for_Meteorological_Radars.html">171 nips-2007-Scan Strategies for Meteorological Radars</a></p>
<p>9 0.41371435 <a title="59-lsi-9" href="./nips-2007-The_rat_as_particle_filter.html">203 nips-2007-The rat as particle filter</a></p>
<p>10 0.38109371 <a title="59-lsi-10" href="./nips-2007-Regulator_Discovery_from_Gene_Expression_Time_Series_of_Malaria_Parasites%3A_a_Hierachical_Approach.html">167 nips-2007-Regulator Discovery from Gene Expression Time Series of Malaria Parasites: a Hierachical Approach</a></p>
<p>11 0.3311004 <a title="59-lsi-11" href="./nips-2007-Fast_Variational_Inference_for_Large-scale_Internet_Diagnosis.html">87 nips-2007-Fast Variational Inference for Large-scale Internet Diagnosis</a></p>
<p>12 0.32541844 <a title="59-lsi-12" href="./nips-2007-Bayesian_Agglomerative_Clustering_with_Coalescents.html">31 nips-2007-Bayesian Agglomerative Clustering with Coalescents</a></p>
<p>13 0.32301617 <a title="59-lsi-13" href="./nips-2007-Collective_Inference_on_Markov_Models_for_Modeling_Bird_Migration.html">48 nips-2007-Collective Inference on Markov Models for Modeling Bird Migration</a></p>
<p>14 0.32111257 <a title="59-lsi-14" href="./nips-2007-A_general_agnostic_active_learning_algorithm.html">15 nips-2007-A general agnostic active learning algorithm</a></p>
<p>15 0.31953549 <a title="59-lsi-15" href="./nips-2007-Selecting_Observations_against_Adversarial_Objectives.html">174 nips-2007-Selecting Observations against Adversarial Objectives</a></p>
<p>16 0.31843439 <a title="59-lsi-16" href="./nips-2007-A_Bayesian_Model_of_Conditioned_Perception.html">3 nips-2007-A Bayesian Model of Conditioned Perception</a></p>
<p>17 0.31598955 <a title="59-lsi-17" href="./nips-2007-Feature_Selection_Methods_for_Improving_Protein_Structure_Prediction_with_Rosetta.html">89 nips-2007-Feature Selection Methods for Improving Protein Structure Prediction with Rosetta</a></p>
<p>18 0.31034988 <a title="59-lsi-18" href="./nips-2007-Augmented_Functional_Time_Series_Representation_and_Forecasting_with_Gaussian_Processes.html">28 nips-2007-Augmented Functional Time Series Representation and Forecasting with Gaussian Processes</a></p>
<p>19 0.29698008 <a title="59-lsi-19" href="./nips-2007-Bayesian_Inference_for_Spiking_Neuron_Models_with_a_Sparsity_Prior.html">33 nips-2007-Bayesian Inference for Spiking Neuron Models with a Sparsity Prior</a></p>
<p>20 0.2963292 <a title="59-lsi-20" href="./nips-2007-Managing_Power_Consumption_and_Performance_of_Computing_Systems_Using_Reinforcement_Learning.html">124 nips-2007-Managing Power Consumption and Performance of Computing Systems Using Reinforcement Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2007_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.025), (13, 0.03), (16, 0.041), (18, 0.036), (19, 0.017), (21, 0.071), (31, 0.027), (34, 0.024), (47, 0.075), (83, 0.072), (85, 0.019), (87, 0.428), (90, 0.053)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.93176943 <a title="59-lda-1" href="./nips-2007-Mining_Internet-Scale_Software_Repositories.html">129 nips-2007-Mining Internet-Scale Software Repositories</a></p>
<p>Author: Erik Linstead, Paul Rigor, Sushil Bajracharya, Cristina Lopes, Pierre F. Baldi</p><p>Abstract: Large repositories of source code create new challenges and opportunities for statistical machine learning. Here we ﬁrst develop Sourcerer, an infrastructure for the automated crawling, parsing, and database storage of open source software. Sourcerer allows us to gather Internet-scale source code. For instance, in one experiment, we gather 4,632 java projects from SourceForge and Apache totaling over 38 million lines of code from 9,250 developers. Simple statistical analyses of the data ﬁrst reveal robust power-law behavior for package, SLOC, and lexical containment distributions. We then develop and apply unsupervised author-topic, probabilistic models to automatically discover the topics embedded in the code and extract topic-word and author-topic distributions. In addition to serving as a convenient summary for program function and developer activities, these and other related distributions provide a statistical and information-theoretic basis for quantifying and analyzing developer similarity and competence, topic scattering, and document tangling, with direct applications to software engineering. Finally, by combining software textual content with structural information captured by our CodeRank approach, we are able to signiﬁcantly improve software retrieval performance, increasing the AUC metric to 0.84– roughly 10-30% better than previous approaches based on text alone. Supplementary material may be found at: http://sourcerer.ics.uci.edu/nips2007/nips07.html. 1</p><p>2 0.92921078 <a title="59-lda-2" href="./nips-2007-Spatial_Latent_Dirichlet_Allocation.html">183 nips-2007-Spatial Latent Dirichlet Allocation</a></p>
<p>Author: Xiaogang Wang, Eric Grimson</p><p>Abstract: In recent years, the language model Latent Dirichlet Allocation (LDA), which clusters co-occurring words into topics, has been widely applied in the computer vision ﬁeld. However, many of these applications have difﬁculty with modeling the spatial and temporal structure among visual words, since LDA assumes that a document is a “bag-of-words”. It is also critical to properly design “words” and “documents” when using a language model to solve vision problems. In this paper, we propose a topic model Spatial Latent Dirichlet Allocation (SLDA), which better encodes spatial structures among visual words that are essential for solving many vision problems. The spatial information is not encoded in the values of visual words but in the design of documents. Instead of knowing the partition of words into documents a priori, the word-document assignment becomes a random hidden variable in SLDA. There is a generative procedure, where knowledge of spatial structure can be ﬂexibly added as a prior, grouping visual words which are close in space into the same document. We use SLDA to discover objects from a collection of images, and show it achieves better performance than LDA. 1</p><p>3 0.85382712 <a title="59-lda-3" href="./nips-2007-Combined_discriminative_and_generative_articulated_pose_and_non-rigid_shape_estimation.html">50 nips-2007-Combined discriminative and generative articulated pose and non-rigid shape estimation</a></p>
<p>Author: Leonid Sigal, Alexandru Balan, Michael J. Black</p><p>Abstract: Estimation of three-dimensional articulated human pose and motion from images is a central problem in computer vision. Much of the previous work has been limited by the use of crude generative models of humans represented as articulated collections of simple parts such as cylinders. Automatic initialization of such models has proved difﬁcult and most approaches assume that the size and shape of the body parts are known a priori. In this paper we propose a method for automatically recovering a detailed parametric model of non-rigid body shape and pose from monocular imagery. Speciﬁcally, we represent the body using a parameterized triangulated mesh model that is learned from a database of human range scans. We demonstrate a discriminative method to directly recover the model parameters from monocular images using a conditional mixture of kernel regressors. This predicted pose and shape are used to initialize a generative model for more detailed pose and shape estimation. The resulting approach allows fully automatic pose and shape recovery from monocular and multi-camera imagery. Experimental results show that our method is capable of robustly recovering articulated pose, shape and biometric measurements (e.g. height, weight, etc.) in both calibrated and uncalibrated camera environments. 1</p><p>same-paper 4 0.8335166 <a title="59-lda-4" href="./nips-2007-Continuous_Time_Particle_Filtering_for_fMRI.html">59 nips-2007-Continuous Time Particle Filtering for fMRI</a></p>
<p>Author: Lawrence Murray, Amos J. Storkey</p><p>Abstract: We construct a biologically motivated stochastic differential model of the neural and hemodynamic activity underlying the observed Blood Oxygen Level Dependent (BOLD) signal in Functional Magnetic Resonance Imaging (fMRI). The model poses a difﬁcult parameter estimation problem, both theoretically due to the nonlinearity and divergence of the differential system, and computationally due to its time and space complexity. We adapt a particle ﬁlter and smoother to the task, and discuss some of the practical approaches used to tackle the difﬁculties, including use of sparse matrices and parallelisation. Results demonstrate the tractability of the approach in its application to an effective connectivity study. 1</p><p>5 0.5925706 <a title="59-lda-5" href="./nips-2007-Supervised_Topic_Models.html">189 nips-2007-Supervised Topic Models</a></p>
<p>Author: Jon D. Mcauliffe, David M. Blei</p><p>Abstract: We introduce supervised latent Dirichlet allocation (sLDA), a statistical model of labelled documents. The model accommodates a variety of response types. We derive a maximum-likelihood procedure for parameter estimation, which relies on variational approximations to handle intractable posterior expectations. Prediction problems motivate this research: we use the ﬁtted model to predict response values for new documents. We test sLDA on two real-world problems: movie ratings predicted from reviews, and web page popularity predicted from text descriptions. We illustrate the beneﬁts of sLDA versus modern regularized regression, as well as versus an unsupervised LDA analysis followed by a separate regression. 1</p><p>6 0.54325593 <a title="59-lda-6" href="./nips-2007-Distributed_Inference_for_Latent_Dirichlet_Allocation.html">73 nips-2007-Distributed Inference for Latent Dirichlet Allocation</a></p>
<p>7 0.51957369 <a title="59-lda-7" href="./nips-2007-HM-BiTAM%3A_Bilingual_Topic_Exploration%2C_Word_Alignment%2C_and_Translation.html">95 nips-2007-HM-BiTAM: Bilingual Topic Exploration, Word Alignment, and Translation</a></p>
<p>8 0.49458039 <a title="59-lda-8" href="./nips-2007-A_Bayesian_LDA-based_model_for_semi-supervised_part-of-speech_tagging.html">2 nips-2007-A Bayesian LDA-based model for semi-supervised part-of-speech tagging</a></p>
<p>9 0.49048778 <a title="59-lda-9" href="./nips-2007-Infinite_State_Bayes-Nets_for_Structured_Domains.html">105 nips-2007-Infinite State Bayes-Nets for Structured Domains</a></p>
<p>10 0.48160845 <a title="59-lda-10" href="./nips-2007-Collapsed_Variational_Inference_for_HDP.html">47 nips-2007-Collapsed Variational Inference for HDP</a></p>
<p>11 0.48088732 <a title="59-lda-11" href="./nips-2007-Object_Recognition_by_Scene_Alignment.html">143 nips-2007-Object Recognition by Scene Alignment</a></p>
<p>12 0.46773779 <a title="59-lda-12" href="./nips-2007-A_Bayesian_Framework_for_Cross-Situational_Word-Learning.html">1 nips-2007-A Bayesian Framework for Cross-Situational Word-Learning</a></p>
<p>13 0.45986485 <a title="59-lda-13" href="./nips-2007-Scene_Segmentation_with_CRFs_Learned_from_Partially_Labeled_Images.html">172 nips-2007-Scene Segmentation with CRFs Learned from Partially Labeled Images</a></p>
<p>14 0.45687634 <a title="59-lda-14" href="./nips-2007-People_Tracking_with_the_Laplacian_Eigenmaps_Latent_Variable_Model.html">153 nips-2007-People Tracking with the Laplacian Eigenmaps Latent Variable Model</a></p>
<p>15 0.45100129 <a title="59-lda-15" href="./nips-2007-Learning_Visual_Attributes.html">113 nips-2007-Learning Visual Attributes</a></p>
<p>16 0.44646025 <a title="59-lda-16" href="./nips-2007-Unsupervised_Feature_Selection_for_Accurate_Recommendation_of_High-Dimensional_Image_Data.html">211 nips-2007-Unsupervised Feature Selection for Accurate Recommendation of High-Dimensional Image Data</a></p>
<p>17 0.44400203 <a title="59-lda-17" href="./nips-2007-Configuration_Estimates_Improve_Pedestrian_Finding.html">56 nips-2007-Configuration Estimates Improve Pedestrian Finding</a></p>
<p>18 0.44023716 <a title="59-lda-18" href="./nips-2007-Retrieved_context_and_the_discovery_of_semantic_structure.html">169 nips-2007-Retrieved context and the discovery of semantic structure</a></p>
<p>19 0.43593684 <a title="59-lda-19" href="./nips-2007-Predicting_Brain_States_from_fMRI_Data%3A_Incremental_Functional_Principal_Component_Regression.html">154 nips-2007-Predicting Brain States from fMRI Data: Incremental Functional Principal Component Regression</a></p>
<p>20 0.42481199 <a title="59-lda-20" href="./nips-2007-Evaluating_Search_Engines_by_Modeling_the_Relationship_Between_Relevance_and_Clicks.html">83 nips-2007-Evaluating Search Engines by Modeling the Relationship Between Relevance and Clicks</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
