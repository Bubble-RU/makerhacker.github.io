<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>196 nips-2003-Wormholes Improve Contrastive Divergence</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2003" href="../home/nips2003_home.html">nips2003</a> <a title="nips-2003-196" href="#">nips2003-196</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>196 nips-2003-Wormholes Improve Contrastive Divergence</h1>
<br/><p>Source: <a title="nips-2003-196-pdf" href="http://papers.nips.cc/paper/2400-wormholes-improve-contrastive-divergence.pdf">pdf</a></p><p>Author: Max Welling, Andriy Mnih, Geoffrey E. Hinton</p><p>Abstract: In models that deﬁne probabilities via energies, maximum likelihood learning typically involves using Markov Chain Monte Carlo to sample from the model’s distribution. If the Markov chain is started at the data distribution, learning often works well even if the chain is only run for a few time steps [3]. But if the data distribution contains modes separated by regions of very low density, brief MCMC will not ensure that different modes have the correct relative energies because it cannot move particles from one mode to another. We show how to improve brief MCMC by allowing long-range moves that are suggested by the data distribution. If the model is approximately correct, these long-range moves have a reasonable acceptance rate.</p><p>Reference: <a title="nips-2003-196-reference" href="../nips2003_reference/nips-2003-Wormholes_Improve_Contrastive_Divergence_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 If the Markov chain is started at the data distribution, learning often works well even if the chain is only run for a few time steps [3]. [sent-4, score-0.384]
</p><p>2 But if the data distribution contains modes separated by regions of very low density, brief MCMC will not ensure that different modes have the correct relative energies because it cannot move particles from one mode to another. [sent-5, score-0.757]
</p><p>3 We show how to improve brief MCMC by allowing long-range moves that are suggested by the data distribution. [sent-6, score-0.131]
</p><p>4 If the model is approximately correct, these long-range moves have a reasonable acceptance rate. [sent-7, score-0.196]
</p><p>5 The main problem with this approach is the time that it takes for the Markov chain to approach its stationary distribution. [sent-11, score-0.154]
</p><p>6 Fortunately, in [3] it was shown that if the chain is started at the data distribution, running the chain for just a few steps is often sufﬁcient to provide a signal for learning. [sent-12, score-0.412]
</p><p>7 |Θ) + (3) ∆θj ∝ − ∂θj ∂θj data conf abulations  Ek  λk  3  second hidden layer  2  1  f  f  k  0  first hidden layer  −1  f  f  j  Wij  −2  −3 −3  Ej λj  Wjk  i  data −2  −1  0  1  2  3  (a)  (b)  Figure 1: a) shows a two-dimensional data distribution that has four well-separated modes. [sent-16, score-0.246]
</p><p>8 b) shows a feedforward neural network that is used to assign an energy to a two-dimensional input vector. [sent-17, score-0.232]
</p><p>9 Each hidden unit takes a weighted sum of its inputs, adds a learned bias, and puts this sum through a logistic non-linearity to produce an output that is sent to the next layer. [sent-18, score-0.132]
</p><p>10 Each hidden unit makes a contribution to the global energy that is equal to its output times a learned scale factor. [sent-19, score-0.301]
</p><p>11 There are 20 units in the ﬁrst hidden layer and 3 in the top layer. [sent-20, score-0.191]
</p><p>12 Unfortunately, real training sets may have modes that are separated by regions of very low density, and running the Markov chain for only a few steps may not allow it to move between these modes even when there is a lot of data. [sent-23, score-0.912]
</p><p>13 As a result, the relative energies of data points in different modes can be completely wrong without affecting the learning signal given by equation 3. [sent-24, score-0.339]
</p><p>14 The point of this paper is to show that, in the context of modelﬁtting, there are ways to use the known training data to introduce extra mode-hopping moves into the Markov chain. [sent-25, score-0.173]
</p><p>15 We rely on the observation that after some initial training, the training data itself provides useful suggestions about where the modes of the model are and how much probability mass there is in each mode. [sent-26, score-0.405]
</p><p>16 2 A simple example of wormholes Figure 1a shows some two-dimensional training data and a model that was used to model the density of the training data. [sent-27, score-0.584]
</p><p>17 The model is an unsupervised deterministic feedforward neural network with two hidden layers of logistic units. [sent-28, score-0.176]
</p><p>18 The parameters of the model are the weights and biases of the hidden units and one additional scale parameter per hidden unit which is used to convert the output of the hidden unit into an additive contribution to the global energy. [sent-29, score-0.287]
</p><p>19 By using backpropagation through the model, it is easy to compute the derivatives of the global energy assigned to an input vector w. [sent-30, score-0.197]
</p><p>20 the parameters (needed in equation 3), and it is also easy to compute the gradient of the energy w. [sent-33, score-0.264]
</p><p>21 e the slope of the energy surface at that point in dataspace). [sent-37, score-0.23]
</p><p>22 The latter gradient is needed for the ’Hybrid Monte Carlo’ sampler that we discuss next. [sent-38, score-0.162]
</p><p>23 To produce the confabulations we start at the datapoints and use a Markov chain that is a sim-  (a)  (b)  Figure 2: (a) shows the probabilities learned by the network without using wormholes, displayed on a 32 × 32 grid in the dataspace. [sent-40, score-0.407]
</p><p>24 (b) shows that the probability mass in the different minima matches the data distribution after 10 parameter updates using point-to-point wormholes deﬁned by the vector differences between pairs of training points. [sent-42, score-0.687]
</p><p>25 The mode-hopping allowed by the wormholes increases the number of confabulations that end up in the deeper minima which causes the learning algorithm to raise the energy of these minima. [sent-43, score-0.883]
</p><p>26 Each datapoint is treated as a particle on the energy surface. [sent-45, score-0.234]
</p><p>27 The particle is given a random initial momentum chosen from a unit-variance isotropic Gaussian and its deterministic trajectory along the energy surface is then simulated for 10 time steps. [sent-46, score-0.303]
</p><p>28 If this simulation has no numerical errors the increase, ∆E, in the combined potential and kinetic energy will be zero. [sent-47, score-0.197]
</p><p>29 Notice that the model assigns much more probability mass to some minima than to others. [sent-52, score-0.154]
</p><p>30 Figure 2b shows how the probability density is corrected by 10 parameter updates using a Markov chain that has been modiﬁed by adding an optional long-range jump at the end of each accepted trajectory. [sent-54, score-0.708]
</p><p>31 The candidate jump is simply the vector difference between two randomly selected training points. [sent-55, score-0.386]
</p><p>32 The jump is always accepted if it lowers the energy. [sent-56, score-0.427]
</p><p>33 If it raises the energy it is accepted with a probability of exp(−∆E). [sent-57, score-0.328]
</p><p>34 Since the probability that point A in the space will be offered a jump to point B is the same as the probability that B will be offered a jump to A, the jumps do not affect detailed balance. [sent-58, score-1.046]
</p><p>35 One way to think about the jumps is to imagine that every point in the dataspace is connected by wormholes to n(n − 1) other points so that it can move to any of these points in a single step. [sent-59, score-0.753]
</p><p>36 To understand how the long-range moves deal with the trade-off between energy and entropy, consider a proposed move that is based on the vector offset between a training point 1 Note that depending on the height of the energy barrier between the modes this may take too long for practical purposes. [sent-60, score-0.895]
</p><p>37 that lies in a deep narrow energy minimum and a training point that lies in a broad shallow minimum. [sent-61, score-0.469]
</p><p>38 If the move is applied to a random point in the deep minimum, it stands a good chance of moving to a point within the broad shallow minimum, but it will probably be rejected because the energy has increased. [sent-62, score-0.476]
</p><p>39 If the opposite move is applied to a random point in the broad minimum, the resulting point is unlikely to fall within the narrow minimum, though if it does it is very likely to be accepted. [sent-63, score-0.24]
</p><p>40 Jumps generated by random pairs of datapoints work well if the minima are all the same shape, but in a high-dimensional space it is very unlikely that such a jump will be accepted if different energy minima are strongly elongated in different directions. [sent-65, score-0.792]
</p><p>41 3 A local optimization-based method In high dimensions the simple wormhole method will have a low acceptance rate because most jumps will land in high-energy regions. [sent-66, score-0.681]
</p><p>42 One way avoid to that is to use local optimization: after a jump has been made descend into a nearby low-energy region. [sent-67, score-0.339]
</p><p>43 It ﬁts Gaussians to the detected low energy regions in order to account for their volume. [sent-70, score-0.269]
</p><p>44 Given a point x, let mx be the point found by running a minimization algorithm on E(x) for a few steps (or until convergence) starting at x. [sent-72, score-0.217]
</p><p>45 A Gaussian density gx (y) is then deﬁned by the mean mx and the covariance matrix Σx . [sent-75, score-0.179]
</p><p>46 To generate a jump proposal, we make a forward jump by adding the vector difference d between two randomly selected data points to the initial point x0 , obtaining x. [sent-76, score-0.741]
</p><p>47 Then we compute mx and Σx , and sample a proposed jump destination y from gx (y). [sent-77, score-0.474]
</p><p>48 Then we make a backward jump by adding −d to y to obtain z, and compute mz and Σz , specifying gz (x). [sent-78, score-0.417]
</p><p>49 exp(−E(x0 )) gx (y)  Our implementation of the algorithm executes 20 steps of steepest descent to ﬁnd mx and mz . [sent-80, score-0.25]
</p><p>50 4 Gaping wormholes In this section we describe a third method based on “darting MCMC” [8] to jump between the modes of a distribution. [sent-82, score-1.018]
</p><p>51 The idea of this technique is to deﬁne spherical regions on the modes of the distribution and to jump only between corresponding points in those regions. [sent-83, score-0.674]
</p><p>52 When we consider a long-range move we check whether or not we are inside a wormhole. [sent-84, score-0.133]
</p><p>53 When inside a wormhole we initiate a jump to some other wormhole (e. [sent-85, score-1.308]
</p><p>54 If we make a jump we must also use the usual Metropolis rejection rule to decide whether to accept the jump. [sent-88, score-0.417]
</p><p>55 In high dimensional spaces this procedure may still lead to unacceptably high rejection rates because the modes will likely decay sharply in at least a few directions. [sent-89, score-0.311]
</p><p>56 Since these ridges of probability are likely to be uncorrelated across the modes, the proposed target location of the jump will most of the time have very low probability, resulting in almost  certain rejection. [sent-90, score-0.473]
</p><p>57 To deal with this problem, we propose a generalization of the described method, where the wormholes can have arbitrary shapes and volumes. [sent-91, score-0.475]
</p><p>58 As before, when we are considering a long-range move we ﬁrst check our position, and if we are located inside a wormhole we initiate a jump (which may be rejected) while if we are located outside a wormhole we stay put. [sent-92, score-1.403]
</p><p>59 To maintain detailed balance between wormholes we need to compensate for their potentially different volume factors. [sent-93, score-0.608]
</p><p>60 To that end, we impose the constraint Vi Pi→j = Vj Pj→i (4) on all pairs of wormholes, where Pi→j is a transition probability and Vi and Vj are the volumes of the wormholes i and j respectively. [sent-94, score-0.524]
</p><p>61 This in fact deﬁnes a separate Markov chain between the wormholes with equilibrium distribution, PiEQ =  Vi j Vj  (5)  The simplest method2 to compensate for the different volume factors is therefore to sample a target wormhole from this distribution P EQ . [sent-95, score-1.114]
</p><p>62 When the target wormhole has been determined we can either sample a point uniformly within its volume or design some deterministic mapping (see also [4]). [sent-96, score-0.581]
</p><p>63 Finally, once the arrival point has been determined we need to compensate for the fact that the probability of the point of departure is likely to be different than the probability of the point of arrival. [sent-97, score-0.22]
</p><p>64 The usual Metropolis rule applies in this case, Parrive Paccept = min 1, (6) Pdepart This combined set of rules ensures that detailed balance holds and that the samples will eventually come from the correct probability distribution. [sent-98, score-0.14]
</p><p>65 One way of employing this sampler in conjunction with contrastive divergence learning is to ﬁt a “mixture of Gaussians” model to the data distribution in a preprocessing step. [sent-99, score-0.26]
</p><p>66 These regions provide good jump points during CD-learning because it is expected that the valleys in the energy landscape correspond to the regions where the data cluster. [sent-101, score-0.71]
</p><p>67 To minimize the rejection rate we map points in one ellipse to “corresponding” points in another ellipse as follows. [sent-102, score-0.237]
</p><p>68 Let Σdepart and Σarrive be the covariance matrices of the wormholes in question. [sent-103, score-0.446]
</p><p>69 The following transformation maps iso-probability contours in one wormhole to iso-probability contours in another, 1/2  −1/2  T xarrive − µarrive = −Uarrive Sarrive Sdepart Udepart (xdepart − µdepart )  (8)  with µ the center location of the ellipse. [sent-105, score-0.491]
</p><p>70 The negative sign in front of the transformation is to promote better exploration when the target wormhole turns out to be the same as the wormhole from which the jump is initiated. [sent-106, score-1.264]
</p><p>71 Thus, wormholes are sampled from P EQ and proposed moves are accepted according to equation 6. [sent-108, score-0.656]
</p><p>72 For both the deterministic and the stochastic moves we may also want to consider regions that overlap. [sent-109, score-0.205]
</p><p>73 For instance, if we generate wormholes by ﬁtting a mixture of Gaussians it 2 Other methods that respect the constraint 4 are possible but are suboptimal in the sense that they mix slower to the equilibrium distribution. [sent-110, score-0.485]
</p><p>74 (b) Probability density of the model learned with contrastive divergence. [sent-112, score-0.174]
</p><p>75 First deﬁne narrive as the total number of regions that contain point xarrive and similarly for ndepart . [sent-116, score-0.24]
</p><p>76 Detailed balance can still be maintained for both deterministic and stochastic moves if we adapt the Metropolis acceptance rule as follows, Paccept = min 1,  ndepart Parrive narrive Pdepart  (9)  Further details can be found in [6]. [sent-117, score-0.372]
</p><p>77 5 An experimental comparison of the three methods To highlight the difference between the point and the region wormhole sampler, we sampled 1024 data points along two very narrow orthogonal ridges (see ﬁgure 3a), with half of the cases in each mode. [sent-118, score-0.691]
</p><p>78 A model with the same architecture as depicted in ﬁgure 1 was learned using contrastive divergence, but with “Cauchy” nonlinearities of the form f (x) = log(1 + x2 ) instead of the logistic function. [sent-119, score-0.158]
</p><p>79 Clearly, the lack of mixing between the modes has resulted in one mode being much stronger than the other one. [sent-121, score-0.263]
</p><p>80 Subsequently, learning was resumed using a Markov chain that proposed a long-range jump for all confabulations after each brief HMC run. [sent-122, score-0.709]
</p><p>81 The regions in the region wormhole sampler were generated by ﬁtting a mixture of two Gaussians to the data using EM, and setting α = 10. [sent-123, score-0.688]
</p><p>82 Both the point wormhole method and the region wormhole method were able to correct the asymmetry in the solution but the region method does so much faster as shown in ﬁgure 4b. [sent-124, score-1.017]
</p><p>83 The reason is that a much smaller fraction of the confabulations succeed in making a long-range jump as shown in ﬁgure 4a. [sent-125, score-0.517]
</p><p>84 We then compared all three wormhole algorithms on a family of datasets of varying dimensionality. [sent-126, score-0.446]
</p><p>85 The ﬁrst two components of each point were sampled uniformly from two axis-aligned narrow orthogonal ridges and then rotated by 45◦ around the origin to ensure that the diagonal approximation to the Hessian, used by the local optimization-based algorithm, was not unfairly accurate. [sent-128, score-0.198]
</p><p>86 (b) Log-odds of the probability masses contained in small volumes surrounding the two modes for the point wormhole method (dashed line) and the region wormhole method (solid line). [sent-133, score-1.327]
</p><p>87 The second hidden layer consisted of Cauchy units, while the ﬁrst hidden layer consisted of some Cauchy and some sigmoid units. [sent-136, score-0.246]
</p><p>88 This prevented HMC from being slowed down by the narrow energy ravines resulting from the tight constraints on the last n − 2 components. [sent-147, score-0.275]
</p><p>89 After the model was trained (without wormholes), we compared the performance of the three jump samplers by allowing each sampler to make a proposal for each training case and then comparing the acceptance rates. [sent-148, score-0.65]
</p><p>90 The average number of successful jumps between modes per iteration is shown in the table below. [sent-151, score-0.336]
</p><p>91 Dimensionality 2 4 8 16 32  Network architecture 10+10, 2 20+10, 4 20+10, 6 40+10, 8 50+10, 10 Relative run time  Simple wormholes 10 6 3 1 1 1  Optimizationbased 15 17 19 13 9 2. [sent-152, score-0.446]
</p><p>92 6  Region wormholes 372 407 397 338 295 1  The network architecture column shows the number of units in the hidden layers with each entry giving the number of Cauchy units plus the number of sigmoid units in the ﬁrst hidden layer and the number of Cauchy units in the second hidden layer. [sent-153, score-0.987]
</p><p>93 Minimizing contrastive divergence is much easier than maximizing likelihood but the brief Markov chain does not have time to mix between separated modes in the distribution3 . [sent-155, score-0.638]
</p><p>94 Their success relies on the fact that the data distribution provides valuable suggestions about the location of the modes of a good model. [sent-158, score-0.266]
</p><p>95 Since the probability of the model distribution is expected to be substantial in these regions they can be successfully used as target locations for long-range moves in a MCMC sampler. [sent-159, score-0.241]
</p><p>96 The MCMC sampler with point-to-point wormholes is simple but has a high rejection rate when the modes are not aligned. [sent-160, score-0.91]
</p><p>97 Performing local gradient descent after a jump signiﬁcantly increases the acceptance rate, but only leads to a modest improvement in efﬁciency because of the extra computations required to maintain detailed balance. [sent-161, score-0.561]
</p><p>98 The MCMC sampler with region-to-region wormholes targets its moves to regions that are likely to have high probability under the model and therefore has a much better acceptance rate, provided the distribution can be modelled well by a mixture. [sent-162, score-0.881]
</p><p>99 None of the methods we have proposed will work well for high-dimensional, approximately factorial distributions that have exponentially many modes formed by the cross-product of multiple lower-dimensional distributions. [sent-163, score-0.233]
</p><p>100 3  However, note that in cases where the modes are well separated, even Markov chains that run for an extraordinarily long time will not mix properly between those modes, and the results of this paper become relevant. [sent-217, score-0.272]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('wormhole', 0.446), ('wormholes', 0.446), ('jump', 0.339), ('modes', 0.233), ('energy', 0.197), ('confabulations', 0.178), ('chain', 0.154), ('sampler', 0.124), ('mcmc', 0.104), ('acceptance', 0.103), ('jumps', 0.103), ('contrastive', 0.099), ('cauchy', 0.097), ('moves', 0.093), ('hmc', 0.089), ('accepted', 0.088), ('mx', 0.082), ('narrow', 0.078), ('rejection', 0.078), ('markov', 0.073), ('hidden', 0.073), ('regions', 0.072), ('units', 0.068), ('move', 0.066), ('minima', 0.062), ('ridges', 0.058), ('metropolis', 0.058), ('hessian', 0.054), ('gx', 0.053), ('monte', 0.052), ('detailed', 0.051), ('layer', 0.05), ('mass', 0.049), ('training', 0.047), ('energies', 0.047), ('region', 0.046), ('balance', 0.046), ('darting', 0.045), ('dataspace', 0.045), ('deep', 0.045), ('masses', 0.045), ('narrive', 0.045), ('ndepart', 0.045), ('paccept', 0.045), ('parrive', 0.045), ('pdepart', 0.045), ('xarrive', 0.045), ('datapoints', 0.044), ('density', 0.044), ('probability', 0.043), ('toronto', 0.042), ('steps', 0.041), ('gaussians', 0.04), ('updates', 0.04), ('deterministic', 0.04), ('mix', 0.039), ('gz', 0.039), ('depart', 0.039), ('initiate', 0.039), ('mz', 0.039), ('shallow', 0.039), ('separated', 0.038), ('inside', 0.038), ('brief', 0.038), ('vj', 0.038), ('gradient', 0.038), ('divergence', 0.037), ('particle', 0.037), ('proposal', 0.037), ('compensate', 0.035), ('started', 0.035), ('feedforward', 0.035), ('ellipse', 0.035), ('volumes', 0.035), ('steepest', 0.035), ('hx', 0.035), ('carlo', 0.034), ('target', 0.033), ('increment', 0.033), ('rejected', 0.033), ('suggestions', 0.033), ('point', 0.033), ('learned', 0.031), ('fortunately', 0.031), ('offered', 0.031), ('eq', 0.031), ('points', 0.03), ('maintain', 0.03), ('vi', 0.03), ('broad', 0.03), ('mode', 0.03), ('momentum', 0.029), ('dy', 0.029), ('equation', 0.029), ('deal', 0.029), ('uniformly', 0.029), ('rate', 0.029), ('check', 0.029), ('running', 0.028), ('logistic', 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000007 <a title="196-tfidf-1" href="./nips-2003-Wormholes_Improve_Contrastive_Divergence.html">196 nips-2003-Wormholes Improve Contrastive Divergence</a></p>
<p>Author: Max Welling, Andriy Mnih, Geoffrey E. Hinton</p><p>Abstract: In models that deﬁne probabilities via energies, maximum likelihood learning typically involves using Markov Chain Monte Carlo to sample from the model’s distribution. If the Markov chain is started at the data distribution, learning often works well even if the chain is only run for a few time steps [3]. But if the data distribution contains modes separated by regions of very low density, brief MCMC will not ensure that different modes have the correct relative energies because it cannot move particles from one mode to another. We show how to improve brief MCMC by allowing long-range moves that are suggested by the data distribution. If the model is approximately correct, these long-range moves have a reasonable acceptance rate.</p><p>2 0.096853852 <a title="196-tfidf-2" href="./nips-2003-Sequential_Bayesian_Kernel_Regression.html">176 nips-2003-Sequential Bayesian Kernel Regression</a></p>
<p>Author: Jaco Vermaak, Simon J. Godsill, Arnaud Doucet</p><p>Abstract: We propose a method for sequential Bayesian kernel regression. As is the case for the popular Relevance Vector Machine (RVM) [10, 11], the method automatically identiﬁes the number and locations of the kernels. Our algorithm overcomes some of the computational difﬁculties related to batch methods for kernel regression. It is non-iterative, and requires only a single pass over the data. It is thus applicable to truly sequential data sets and batch data sets alike. The algorithm is based on a generalisation of Importance Sampling, which allows the design of intuitively simple and efﬁcient proposal distributions for the model parameters. Comparative results on two standard data sets show our algorithm to compare favourably with existing batch estimation strategies.</p><p>3 0.083177693 <a title="196-tfidf-3" href="./nips-2003-Approximate_Expectation_Maximization.html">32 nips-2003-Approximate Expectation Maximization</a></p>
<p>Author: Tom Heskes, Onno Zoeter, Wim Wiegerinck</p><p>Abstract: We discuss the integration of the expectation-maximization (EM) algorithm for maximum likelihood learning of Bayesian networks with belief propagation algorithms for approximate inference. Specifically we propose to combine the outer-loop step of convergent belief propagation algorithms with the M-step of the EM algorithm. This then yields an approximate EM algorithm that is essentially still double loop, with the important advantage of an inner loop that is guaranteed to converge. Simulations illustrate the merits of such an approach. 1</p><p>4 0.076882951 <a title="196-tfidf-4" href="./nips-2003-Efficient_Multiscale_Sampling_from_Products_of_Gaussian_Mixtures.html">58 nips-2003-Efficient Multiscale Sampling from Products of Gaussian Mixtures</a></p>
<p>Author: Alexander T. Ihler, Erik B. Sudderth, William T. Freeman, Alan S. Willsky</p><p>Abstract: The problem of approximating the product of several Gaussian mixture distributions arises in a number of contexts, including the nonparametric belief propagation (NBP) inference algorithm and the training of product of experts models. This paper develops two multiscale algorithms for sampling from a product of Gaussian mixtures, and compares their performance to existing methods. The ﬁrst is a multiscale variant of previously proposed Monte Carlo techniques, with comparable theoretical guarantees but improved empirical convergence rates. The second makes use of approximate kernel density evaluation methods to construct a fast approximate sampler, which is guaranteed to sample points to within a tunable parameter of their true probability. We compare both multiscale samplers on a set of computational examples motivated by NBP, demonstrating signiﬁcant improvements over existing methods. 1</p><p>5 0.071911268 <a title="196-tfidf-5" href="./nips-2003-Inferring_State_Sequences_for_Non-linear_Systems_with_Embedded_Hidden_Markov_Models.html">91 nips-2003-Inferring State Sequences for Non-linear Systems with Embedded Hidden Markov Models</a></p>
<p>Author: Radford M. Neal, Matthew J. Beal, Sam T. Roweis</p><p>Abstract: We describe a Markov chain method for sampling from the distribution of the hidden state sequence in a non-linear dynamical system, given a sequence of observations. This method updates all states in the sequence simultaneously using an embedded Hidden Markov Model (HMM). An update begins with the creation of “pools” of candidate states at each time. We then deﬁne an embedded HMM whose states are indexes within these pools. Using a forward-backward dynamic programming algorithm, we can efﬁciently choose a state sequence with the appropriate probabilities from the exponentially large number of state sequences that pass through states in these pools. We illustrate the method in a simple one-dimensional example, and in an example showing how an embedded HMM can be used to in effect discretize the state space without any discretization error. We also compare the embedded HMM to a particle smoother on a more substantial problem of inferring human motion from 2D traces of markers. 1</p><p>6 0.070549622 <a title="196-tfidf-6" href="./nips-2003-Iterative_Scaled_Trust-Region_Learning_in_Krylov_Subspaces_via_Pearlmutter%27s_Implicit_Sparse_Hessian.html">97 nips-2003-Iterative Scaled Trust-Region Learning in Krylov Subspaces via Pearlmutter's Implicit Sparse Hessian</a></p>
<p>7 0.069531038 <a title="196-tfidf-7" href="./nips-2003-Learning_Curves_for_Stochastic_Gradient_Descent_in_Linear_Feedforward_Networks.html">104 nips-2003-Learning Curves for Stochastic Gradient Descent in Linear Feedforward Networks</a></p>
<p>8 0.05948982 <a title="196-tfidf-8" href="./nips-2003-Automatic_Annotation_of_Everyday_Movements.html">37 nips-2003-Automatic Annotation of Everyday Movements</a></p>
<p>9 0.059427053 <a title="196-tfidf-9" href="./nips-2003-Sample_Propagation.html">169 nips-2003-Sample Propagation</a></p>
<p>10 0.052846983 <a title="196-tfidf-10" href="./nips-2003-Model_Uncertainty_in_Classical_Conditioning.html">130 nips-2003-Model Uncertainty in Classical Conditioning</a></p>
<p>11 0.051827088 <a title="196-tfidf-11" href="./nips-2003-An_MCMC-Based_Method_of_Comparing_Connectionist_Models_in_Cognitive_Science.html">25 nips-2003-An MCMC-Based Method of Comparing Connectionist Models in Cognitive Science</a></p>
<p>12 0.049974255 <a title="196-tfidf-12" href="./nips-2003-A_Fast_Multi-Resolution_Method_for_Detection_of_Significant_Spatial_Disease_Clusters.html">6 nips-2003-A Fast Multi-Resolution Method for Detection of Significant Spatial Disease Clusters</a></p>
<p>13 0.046914384 <a title="196-tfidf-13" href="./nips-2003-Estimating_Internal_Variables_and_Paramters_of_a_Learning_Agent_by_a_Particle_Filter.html">64 nips-2003-Estimating Internal Variables and Paramters of a Learning Agent by a Particle Filter</a></p>
<p>14 0.046686526 <a title="196-tfidf-14" href="./nips-2003-Perspectives_on_Sparse_Bayesian_Learning.html">155 nips-2003-Perspectives on Sparse Bayesian Learning</a></p>
<p>15 0.045244005 <a title="196-tfidf-15" href="./nips-2003-Large_Scale_Online_Learning.html">102 nips-2003-Large Scale Online Learning</a></p>
<p>16 0.043737046 <a title="196-tfidf-16" href="./nips-2003-Nonstationary_Covariance_Functions_for_Gaussian_Process_Regression.html">141 nips-2003-Nonstationary Covariance Functions for Gaussian Process Regression</a></p>
<p>17 0.043297864 <a title="196-tfidf-17" href="./nips-2003-Probabilistic_Inference_of_Speech_Signals_from_Phaseless_Spectrograms.html">162 nips-2003-Probabilistic Inference of Speech Signals from Phaseless Spectrograms</a></p>
<p>18 0.041262604 <a title="196-tfidf-18" href="./nips-2003-Learning_the_k_in_k-means.html">111 nips-2003-Learning the k in k-means</a></p>
<p>19 0.041116692 <a title="196-tfidf-19" href="./nips-2003-Learning_a_World_Model_and_Planning_with_a_Self-Organizing%2C_Dynamic_Neural_System.html">110 nips-2003-Learning a World Model and Planning with a Self-Organizing, Dynamic Neural System</a></p>
<p>20 0.041088395 <a title="196-tfidf-20" href="./nips-2003-On_the_Concentration_of_Expectation_and_Approximate_Inference_in_Layered_Networks.html">142 nips-2003-On the Concentration of Expectation and Approximate Inference in Layered Networks</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2003_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.162), (1, 0.014), (2, -0.003), (3, 0.043), (4, -0.005), (5, -0.001), (6, 0.095), (7, 0.044), (8, 0.023), (9, 0.012), (10, -0.033), (11, -0.009), (12, 0.008), (13, -0.006), (14, 0.049), (15, -0.052), (16, -0.034), (17, 0.009), (18, 0.097), (19, -0.017), (20, -0.048), (21, 0.028), (22, -0.034), (23, 0.052), (24, -0.081), (25, -0.063), (26, -0.003), (27, 0.011), (28, 0.028), (29, -0.038), (30, -0.076), (31, -0.011), (32, 0.019), (33, 0.018), (34, 0.081), (35, -0.025), (36, -0.159), (37, -0.225), (38, -0.005), (39, 0.184), (40, -0.043), (41, 0.022), (42, -0.095), (43, 0.091), (44, -0.069), (45, 0.006), (46, -0.034), (47, 0.068), (48, -0.149), (49, 0.087)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92629439 <a title="196-lsi-1" href="./nips-2003-Wormholes_Improve_Contrastive_Divergence.html">196 nips-2003-Wormholes Improve Contrastive Divergence</a></p>
<p>Author: Max Welling, Andriy Mnih, Geoffrey E. Hinton</p><p>Abstract: In models that deﬁne probabilities via energies, maximum likelihood learning typically involves using Markov Chain Monte Carlo to sample from the model’s distribution. If the Markov chain is started at the data distribution, learning often works well even if the chain is only run for a few time steps [3]. But if the data distribution contains modes separated by regions of very low density, brief MCMC will not ensure that different modes have the correct relative energies because it cannot move particles from one mode to another. We show how to improve brief MCMC by allowing long-range moves that are suggested by the data distribution. If the model is approximately correct, these long-range moves have a reasonable acceptance rate.</p><p>2 0.62962538 <a title="196-lsi-2" href="./nips-2003-A_Fast_Multi-Resolution_Method_for_Detection_of_Significant_Spatial_Disease_Clusters.html">6 nips-2003-A Fast Multi-Resolution Method for Detection of Significant Spatial Disease Clusters</a></p>
<p>Author: Daniel B. Neill, Andrew W. Moore</p><p>Abstract: Given an N ×N grid of squares, where each square has a count and an underlying population, our goal is to ﬁnd the square region with the highest density, and to calculate its signiﬁcance by randomization. Any density measure D, dependent on the total count and total population of a region, can be used. For example, if each count represents the number of disease cases occurring in that square, we can use Kulldorff’s spatial scan statistic DK to ﬁnd the most signiﬁcant spatial disease cluster. A naive approach to ﬁnding the maximum density region requires O(N 3 ) time, and is generally computationally infeasible. We present a novel algorithm which partitions the grid into overlapping regions, bounds the maximum score of subregions contained in each region, and prunes regions which cannot contain the maximum density region. For sufﬁciently dense regions, this method ﬁnds the maximum density region in optimal O(N 2 ) time, in practice resulting in signiﬁcant (10-200x) speedups. 1</p><p>3 0.60652769 <a title="196-lsi-3" href="./nips-2003-Efficient_Multiscale_Sampling_from_Products_of_Gaussian_Mixtures.html">58 nips-2003-Efficient Multiscale Sampling from Products of Gaussian Mixtures</a></p>
<p>Author: Alexander T. Ihler, Erik B. Sudderth, William T. Freeman, Alan S. Willsky</p><p>Abstract: The problem of approximating the product of several Gaussian mixture distributions arises in a number of contexts, including the nonparametric belief propagation (NBP) inference algorithm and the training of product of experts models. This paper develops two multiscale algorithms for sampling from a product of Gaussian mixtures, and compares their performance to existing methods. The ﬁrst is a multiscale variant of previously proposed Monte Carlo techniques, with comparable theoretical guarantees but improved empirical convergence rates. The second makes use of approximate kernel density evaluation methods to construct a fast approximate sampler, which is guaranteed to sample points to within a tunable parameter of their true probability. We compare both multiscale samplers on a set of computational examples motivated by NBP, demonstrating signiﬁcant improvements over existing methods. 1</p><p>4 0.60276961 <a title="196-lsi-4" href="./nips-2003-An_MCMC-Based_Method_of_Comparing_Connectionist_Models_in_Cognitive_Science.html">25 nips-2003-An MCMC-Based Method of Comparing Connectionist Models in Cognitive Science</a></p>
<p>Author: Woojae Kim, Daniel J. Navarro, Mark A. Pitt, In J. Myung</p><p>Abstract: Despite the popularity of connectionist models in cognitive science, their performance can often be diﬃcult to evaluate. Inspired by the geometric approach to statistical model selection, we introduce a conceptually similar method to examine the global behavior of a connectionist model, by counting the number and types of response patterns it can simulate. The Markov Chain Monte Carlo-based algorithm that we constructed Þnds these patterns eﬃciently. We demonstrate the approach using two localist network models of speech perception. 1</p><p>5 0.55045259 <a title="196-lsi-5" href="./nips-2003-Sequential_Bayesian_Kernel_Regression.html">176 nips-2003-Sequential Bayesian Kernel Regression</a></p>
<p>Author: Jaco Vermaak, Simon J. Godsill, Arnaud Doucet</p><p>Abstract: We propose a method for sequential Bayesian kernel regression. As is the case for the popular Relevance Vector Machine (RVM) [10, 11], the method automatically identiﬁes the number and locations of the kernels. Our algorithm overcomes some of the computational difﬁculties related to batch methods for kernel regression. It is non-iterative, and requires only a single pass over the data. It is thus applicable to truly sequential data sets and batch data sets alike. The algorithm is based on a generalisation of Importance Sampling, which allows the design of intuitively simple and efﬁcient proposal distributions for the model parameters. Comparative results on two standard data sets show our algorithm to compare favourably with existing batch estimation strategies.</p><p>6 0.46593833 <a title="196-lsi-6" href="./nips-2003-Iterative_Scaled_Trust-Region_Learning_in_Krylov_Subspaces_via_Pearlmutter%27s_Implicit_Sparse_Hessian.html">97 nips-2003-Iterative Scaled Trust-Region Learning in Krylov Subspaces via Pearlmutter's Implicit Sparse Hessian</a></p>
<p>7 0.44377196 <a title="196-lsi-7" href="./nips-2003-Training_a_Quantum_Neural_Network.html">187 nips-2003-Training a Quantum Neural Network</a></p>
<p>8 0.43884328 <a title="196-lsi-8" href="./nips-2003-Hierarchical_Topic_Models_and_the_Nested_Chinese_Restaurant_Process.html">83 nips-2003-Hierarchical Topic Models and the Nested Chinese Restaurant Process</a></p>
<p>9 0.41196579 <a title="196-lsi-9" href="./nips-2003-Sensory_Modality_Segregation.html">175 nips-2003-Sensory Modality Segregation</a></p>
<p>10 0.40527219 <a title="196-lsi-10" href="./nips-2003-Learning_Curves_for_Stochastic_Gradient_Descent_in_Linear_Feedforward_Networks.html">104 nips-2003-Learning Curves for Stochastic Gradient Descent in Linear Feedforward Networks</a></p>
<p>11 0.38649625 <a title="196-lsi-11" href="./nips-2003-Design_of_Experiments_via_Information_Theory.html">51 nips-2003-Design of Experiments via Information Theory</a></p>
<p>12 0.38492936 <a title="196-lsi-12" href="./nips-2003-Sample_Propagation.html">169 nips-2003-Sample Propagation</a></p>
<p>13 0.382898 <a title="196-lsi-13" href="./nips-2003-Markov_Models_for_Automated_ECG_Interval_Analysis.html">123 nips-2003-Markov Models for Automated ECG Interval Analysis</a></p>
<p>14 0.37113485 <a title="196-lsi-14" href="./nips-2003-Large_Scale_Online_Learning.html">102 nips-2003-Large Scale Online Learning</a></p>
<p>15 0.35272795 <a title="196-lsi-15" href="./nips-2003-Statistical_Debugging_of_Sampled_Programs.html">181 nips-2003-Statistical Debugging of Sampled Programs</a></p>
<p>16 0.35159087 <a title="196-lsi-16" href="./nips-2003-Fast_Algorithms_for_Large-State-Space_HMMs_with_Applications_to_Web_Usage_Analysis.html">70 nips-2003-Fast Algorithms for Large-State-Space HMMs with Applications to Web Usage Analysis</a></p>
<p>17 0.35031056 <a title="196-lsi-17" href="./nips-2003-Inferring_State_Sequences_for_Non-linear_Systems_with_Embedded_Hidden_Markov_Models.html">91 nips-2003-Inferring State Sequences for Non-linear Systems with Embedded Hidden Markov Models</a></p>
<p>18 0.32086891 <a title="196-lsi-18" href="./nips-2003-ARA%2A%3A_Anytime_A%2A_with_Provable_Bounds_on_Sub-Optimality.html">2 nips-2003-ARA*: Anytime A* with Provable Bounds on Sub-Optimality</a></p>
<p>19 0.31951338 <a title="196-lsi-19" href="./nips-2003-Model_Uncertainty_in_Classical_Conditioning.html">130 nips-2003-Model Uncertainty in Classical Conditioning</a></p>
<p>20 0.31848735 <a title="196-lsi-20" href="./nips-2003-Measure_Based_Regularization.html">126 nips-2003-Measure Based Regularization</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2003_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.055), (11, 0.016), (29, 0.012), (30, 0.017), (33, 0.02), (35, 0.064), (53, 0.084), (55, 0.013), (69, 0.386), (71, 0.053), (76, 0.032), (85, 0.059), (91, 0.084)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.83155406 <a title="196-lda-1" href="./nips-2003-Wormholes_Improve_Contrastive_Divergence.html">196 nips-2003-Wormholes Improve Contrastive Divergence</a></p>
<p>Author: Max Welling, Andriy Mnih, Geoffrey E. Hinton</p><p>Abstract: In models that deﬁne probabilities via energies, maximum likelihood learning typically involves using Markov Chain Monte Carlo to sample from the model’s distribution. If the Markov chain is started at the data distribution, learning often works well even if the chain is only run for a few time steps [3]. But if the data distribution contains modes separated by regions of very low density, brief MCMC will not ensure that different modes have the correct relative energies because it cannot move particles from one mode to another. We show how to improve brief MCMC by allowing long-range moves that are suggested by the data distribution. If the model is approximately correct, these long-range moves have a reasonable acceptance rate.</p><p>2 0.79096472 <a title="196-lda-2" href="./nips-2003-Design_of_Experiments_via_Information_Theory.html">51 nips-2003-Design of Experiments via Information Theory</a></p>
<p>Author: Liam Paninski</p><p>Abstract: We discuss an idea for collecting data in a relatively efﬁcient manner. Our point of view is Bayesian and information-theoretic: on any given trial, we want to adaptively choose the input in such a way that the mutual information between the (unknown) state of the system and the (stochastic) output is maximal, given any prior information (including data collected on any previous trials). We prove a theorem that quantiﬁes the effectiveness of this strategy and give a few illustrative examples comparing the performance of this adaptive technique to that of the more usual nonadaptive experimental design. For example, we are able to explicitly calculate the asymptotic relative efﬁciency of the “staircase method” widely employed in psychophysics research, and to demonstrate the dependence of this efﬁciency on the form of the “psychometric function” underlying the output responses. 1</p><p>3 0.52215141 <a title="196-lda-3" href="./nips-2003-Efficient_Multiscale_Sampling_from_Products_of_Gaussian_Mixtures.html">58 nips-2003-Efficient Multiscale Sampling from Products of Gaussian Mixtures</a></p>
<p>Author: Alexander T. Ihler, Erik B. Sudderth, William T. Freeman, Alan S. Willsky</p><p>Abstract: The problem of approximating the product of several Gaussian mixture distributions arises in a number of contexts, including the nonparametric belief propagation (NBP) inference algorithm and the training of product of experts models. This paper develops two multiscale algorithms for sampling from a product of Gaussian mixtures, and compares their performance to existing methods. The ﬁrst is a multiscale variant of previously proposed Monte Carlo techniques, with comparable theoretical guarantees but improved empirical convergence rates. The second makes use of approximate kernel density evaluation methods to construct a fast approximate sampler, which is guaranteed to sample points to within a tunable parameter of their true probability. We compare both multiscale samplers on a set of computational examples motivated by NBP, demonstrating signiﬁcant improvements over existing methods. 1</p><p>4 0.48731506 <a title="196-lda-4" href="./nips-2003-Large_Margin_Classifiers%3A_Convex_Loss%2C_Low_Noise%2C_and_Convergence_Rates.html">101 nips-2003-Large Margin Classifiers: Convex Loss, Low Noise, and Convergence Rates</a></p>
<p>Author: Peter L. Bartlett, Michael I. Jordan, Jon D. Mcauliffe</p><p>Abstract: Many classiﬁcation algorithms, including the support vector machine, boosting and logistic regression, can be viewed as minimum contrast methods that minimize a convex surrogate of the 0-1 loss function. We characterize the statistical consequences of using such a surrogate by providing a general quantitative relationship between the risk as assessed using the 0-1 loss and the risk as assessed using any nonnegative surrogate loss function. We show that this relationship gives nontrivial bounds under the weakest possible condition on the loss function—that it satisfy a pointwise form of Fisher consistency for classiﬁcation. The relationship is based on a variational transformation of the loss function that is easy to compute in many applications. We also present a reﬁned version of this result in the case of low noise. Finally, we present applications of our results to the estimation of convergence rates in the general setting of function classes that are scaled hulls of a ﬁnite-dimensional base class.</p><p>5 0.47124499 <a title="196-lda-5" href="./nips-2003-Learning_with_Local_and_Global_Consistency.html">113 nips-2003-Learning with Local and Global Consistency</a></p>
<p>Author: Dengyong Zhou, Olivier Bousquet, Thomas N. Lal, Jason Weston, Bernhard Schölkopf</p><p>Abstract: We consider the general problem of learning from labeled and unlabeled data, which is often called semi-supervised learning or transductive inference. A principled approach to semi-supervised learning is to design a classifying function which is sufﬁciently smooth with respect to the intrinsic structure collectively revealed by known labeled and unlabeled points. We present a simple algorithm to obtain such a smooth solution. Our method yields encouraging experimental results on a number of classiﬁcation problems and demonstrates effective use of unlabeled data. 1</p><p>6 0.46601048 <a title="196-lda-6" href="./nips-2003-Inferring_State_Sequences_for_Non-linear_Systems_with_Embedded_Hidden_Markov_Models.html">91 nips-2003-Inferring State Sequences for Non-linear Systems with Embedded Hidden Markov Models</a></p>
<p>7 0.45426214 <a title="196-lda-7" href="./nips-2003-Measure_Based_Regularization.html">126 nips-2003-Measure Based Regularization</a></p>
<p>8 0.45374668 <a title="196-lda-8" href="./nips-2003-Semi-Supervised_Learning_with_Trees.html">172 nips-2003-Semi-Supervised Learning with Trees</a></p>
<p>9 0.44447958 <a title="196-lda-9" href="./nips-2003-Maximum_Likelihood_Estimation_of_a_Stochastic_Integrate-and-Fire_Neural_Model.html">125 nips-2003-Maximum Likelihood Estimation of a Stochastic Integrate-and-Fire Neural Model</a></p>
<p>10 0.44265923 <a title="196-lda-10" href="./nips-2003-Learning_Bounds_for_a_Generalized_Family_of_Bayesian_Posterior_Distributions.html">103 nips-2003-Learning Bounds for a Generalized Family of Bayesian Posterior Distributions</a></p>
<p>11 0.44062281 <a title="196-lda-11" href="./nips-2003-On_the_Dynamics_of_Boosting.html">143 nips-2003-On the Dynamics of Boosting</a></p>
<p>12 0.43863669 <a title="196-lda-12" href="./nips-2003-An_Infinity-sample_Theory_for_Multi-category_Large_Margin_Classification.html">23 nips-2003-An Infinity-sample Theory for Multi-category Large Margin Classification</a></p>
<p>13 0.43366244 <a title="196-lda-13" href="./nips-2003-A_Fast_Multi-Resolution_Method_for_Detection_of_Significant_Spatial_Disease_Clusters.html">6 nips-2003-A Fast Multi-Resolution Method for Detection of Significant Spatial Disease Clusters</a></p>
<p>14 0.43355107 <a title="196-lda-14" href="./nips-2003-Sequential_Bayesian_Kernel_Regression.html">176 nips-2003-Sequential Bayesian Kernel Regression</a></p>
<p>15 0.43181974 <a title="196-lda-15" href="./nips-2003-Linear_Dependent_Dimensionality_Reduction.html">115 nips-2003-Linear Dependent Dimensionality Reduction</a></p>
<p>16 0.42868379 <a title="196-lda-16" href="./nips-2003-Distributed_Optimization_in_Adaptive_Networks.html">55 nips-2003-Distributed Optimization in Adaptive Networks</a></p>
<p>17 0.42823017 <a title="196-lda-17" href="./nips-2003-Large_Scale_Online_Learning.html">102 nips-2003-Large Scale Online Learning</a></p>
<p>18 0.42727467 <a title="196-lda-18" href="./nips-2003-Sample_Propagation.html">169 nips-2003-Sample Propagation</a></p>
<p>19 0.4266603 <a title="196-lda-19" href="./nips-2003-Gaussian_Processes_in_Reinforcement_Learning.html">78 nips-2003-Gaussian Processes in Reinforcement Learning</a></p>
<p>20 0.4258765 <a title="196-lda-20" href="./nips-2003-Warped_Gaussian_Processes.html">194 nips-2003-Warped Gaussian Processes</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
