<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>134 nips-2003-Near-Minimax Optimal Classification with Dyadic Classification Trees</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2003" href="../home/nips2003_home.html">nips2003</a> <a title="nips-2003-134" href="#">nips2003-134</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>134 nips-2003-Near-Minimax Optimal Classification with Dyadic Classification Trees</h1>
<br/><p>Source: <a title="nips-2003-134-pdf" href="http://papers.nips.cc/paper/2364-near-minimax-optimal-classification-with-dyadic-classification-trees.pdf">pdf</a></p><p>Author: Clayton Scott, Robert Nowak</p><p>Abstract: This paper reports on a family of computationally practical classiﬁers that converge to the Bayes error at near-minimax optimal rates for a variety of distributions. The classiﬁers are based on dyadic classiﬁcation trees (DCTs), which involve adaptively pruned partitions of the feature space. A key aspect of DCTs is their spatial adaptivity, which enables local (rather than global) ﬁtting of the decision boundary. Our risk analysis involves a spatial decomposition of the usual concentration inequalities, leading to a spatially adaptive, data-dependent pruning criterion. For any distribution on (X, Y ) whose Bayes decision boundary behaves locally like a Lipschitz smooth function, we show that the DCT error converges to the Bayes error at a rate within a logarithmic factor of the minimax optimal rate. We also study DCTs equipped with polynomial classiﬁcation rules at each leaf, and show that as the smoothness of the boundary increases their errors converge to the Bayes error at a rate approaching n−1/2 , the parametric rate. We are not aware of any other practical classiﬁers that provide similar rate of convergence guarantees. Fast algorithms for tree pruning are discussed. 1</p><p>Reference: <a title="nips-2003-134-reference" href="../nips2003_reference/nips-2003-Near-Minimax_Optimal_Classification_with_Dyadic_Classification_Trees_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('prun', 0.396), ('tn', 0.324), ('dyad', 0.322), ('tv', 0.316), ('dcts', 0.257), ('rv', 0.214), ('subt', 0.193), ('leaf', 0.181), ('pdct', 0.15), ('dct', 0.149), ('bay', 0.131), ('tre', 0.125), ('nod', 0.12), ('minimax', 0.108), ('penal', 0.096), ('spat', 0.094), ('decid', 0.093), ('polynom', 0.093), ('theorem', 0.091), ('rat', 0.091)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999958 <a title="134-tfidf-1" href="./nips-2003-Near-Minimax_Optimal_Classification_with_Dyadic_Classification_Trees.html">134 nips-2003-Near-Minimax Optimal Classification with Dyadic Classification Trees</a></p>
<p>2 0.1372335 <a title="134-tfidf-2" href="./nips-2003-An_Iterative_Improvement_Procedure_for_Hierarchical_Clustering.html">24 nips-2003-An Iterative Improvement Procedure for Hierarchical Clustering</a></p>
<p>3 0.10110987 <a title="134-tfidf-3" href="./nips-2003-Applying_Metric-Trees_to_Belief-Point_POMDPs.html">29 nips-2003-Applying Metric-Trees to Belief-Point POMDPs</a></p>
<p>4 0.099098645 <a title="134-tfidf-4" href="./nips-2003-Bounded_Finite_State_Controllers.html">42 nips-2003-Bounded Finite State Controllers</a></p>
<p>5 0.096885532 <a title="134-tfidf-5" href="./nips-2003-New_Algorithms_for_Efficient_High_Dimensional_Non-parametric_Classification.html">136 nips-2003-New Algorithms for Efficient High Dimensional Non-parametric Classification</a></p>
<p>6 0.093045302 <a title="134-tfidf-6" href="./nips-2003-Large_Margin_Classifiers%3A_Convex_Loss%2C_Low_Noise%2C_and_Convergence_Rates.html">101 nips-2003-Large Margin Classifiers: Convex Loss, Low Noise, and Convergence Rates</a></p>
<p>7 0.091325723 <a title="134-tfidf-7" href="./nips-2003-A_Probabilistic_Model_of_Auditory_Space_Representation_in_the_Barn_Owl.html">15 nips-2003-A Probabilistic Model of Auditory Space Representation in the Barn Owl</a></p>
<p>8 0.081448726 <a title="134-tfidf-8" href="./nips-2003-Warped_Gaussian_Processes.html">194 nips-2003-Warped Gaussian Processes</a></p>
<p>9 0.077849917 <a title="134-tfidf-9" href="./nips-2003-On_the_Concentration_of_Expectation_and_Approximate_Inference_in_Layered_Networks.html">142 nips-2003-On the Concentration of Expectation and Approximate Inference in Layered Networks</a></p>
<p>10 0.067911915 <a title="134-tfidf-10" href="./nips-2003-Design_of_Experiments_via_Information_Theory.html">51 nips-2003-Design of Experiments via Information Theory</a></p>
<p>11 0.066747695 <a title="134-tfidf-11" href="./nips-2003-Minimax_Embeddings.html">128 nips-2003-Minimax Embeddings</a></p>
<p>12 0.066267893 <a title="134-tfidf-12" href="./nips-2003-Margin_Maximizing_Loss_Functions.html">122 nips-2003-Margin Maximizing Loss Functions</a></p>
<p>13 0.06447541 <a title="134-tfidf-13" href="./nips-2003-Semi-Supervised_Learning_with_Trees.html">172 nips-2003-Semi-Supervised Learning with Trees</a></p>
<p>14 0.063083015 <a title="134-tfidf-14" href="./nips-2003-A_Fast_Multi-Resolution_Method_for_Detection_of_Significant_Spatial_Disease_Clusters.html">6 nips-2003-A Fast Multi-Resolution Method for Detection of Significant Spatial Disease Clusters</a></p>
<p>15 0.059933838 <a title="134-tfidf-15" href="./nips-2003-Perspectives_on_Sparse_Bayesian_Learning.html">155 nips-2003-Perspectives on Sparse Bayesian Learning</a></p>
<p>16 0.058584101 <a title="134-tfidf-16" href="./nips-2003-Semidefinite_Relaxations_for_Approximate_Inference_on_Graphs_with_Cycles.html">174 nips-2003-Semidefinite Relaxations for Approximate Inference on Graphs with Cycles</a></p>
<p>17 0.058409777 <a title="134-tfidf-17" href="./nips-2003-Learning_Bounds_for_a_Generalized_Family_of_Bayesian_Posterior_Distributions.html">103 nips-2003-Learning Bounds for a Generalized Family of Bayesian Posterior Distributions</a></p>
<p>18 0.056604732 <a title="134-tfidf-18" href="./nips-2003-Salient_Boundary_Detection_using_Ratio_Contour.html">168 nips-2003-Salient Boundary Detection using Ratio Contour</a></p>
<p>19 0.055858336 <a title="134-tfidf-19" href="./nips-2003-Tree-structured_Approximations_by_Expectation_Propagation.html">189 nips-2003-Tree-structured Approximations by Expectation Propagation</a></p>
<p>20 0.054049999 <a title="134-tfidf-20" href="./nips-2003-Invariant_Pattern_Recognition_by_Semi-Definite_Programming_Machines.html">96 nips-2003-Invariant Pattern Recognition by Semi-Definite Programming Machines</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2003_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.176), (1, 0.015), (2, -0.042), (3, 0.015), (4, -0.054), (5, 0.095), (6, 0.07), (7, 0.002), (8, -0.008), (9, -0.091), (10, 0.079), (11, -0.06), (12, -0.016), (13, 0.002), (14, 0.04), (15, 0.118), (16, 0.042), (17, 0.031), (18, 0.013), (19, -0.07), (20, 0.125), (21, 0.077), (22, 0.026), (23, 0.028), (24, -0.036), (25, 0.112), (26, -0.069), (27, 0.113), (28, -0.086), (29, -0.014), (30, -0.158), (31, 0.009), (32, -0.044), (33, 0.042), (34, 0.05), (35, 0.082), (36, 0.218), (37, -0.012), (38, -0.081), (39, -0.111), (40, 0.08), (41, 0.14), (42, -0.052), (43, -0.16), (44, -0.029), (45, 0.011), (46, 0.052), (47, -0.104), (48, 0.106), (49, -0.063)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92057961 <a title="134-lsi-1" href="./nips-2003-Near-Minimax_Optimal_Classification_with_Dyadic_Classification_Trees.html">134 nips-2003-Near-Minimax Optimal Classification with Dyadic Classification Trees</a></p>
<p>2 0.60512608 <a title="134-lsi-2" href="./nips-2003-New_Algorithms_for_Efficient_High_Dimensional_Non-parametric_Classification.html">136 nips-2003-New Algorithms for Efficient High Dimensional Non-parametric Classification</a></p>
<p>3 0.50681102 <a title="134-lsi-3" href="./nips-2003-A_Fast_Multi-Resolution_Method_for_Detection_of_Significant_Spatial_Disease_Clusters.html">6 nips-2003-A Fast Multi-Resolution Method for Detection of Significant Spatial Disease Clusters</a></p>
<p>4 0.49321663 <a title="134-lsi-4" href="./nips-2003-An_Iterative_Improvement_Procedure_for_Hierarchical_Clustering.html">24 nips-2003-An Iterative Improvement Procedure for Hierarchical Clustering</a></p>
<p>5 0.47795767 <a title="134-lsi-5" href="./nips-2003-Semi-Supervised_Learning_with_Trees.html">172 nips-2003-Semi-Supervised Learning with Trees</a></p>
<p>6 0.448791 <a title="134-lsi-6" href="./nips-2003-Perspectives_on_Sparse_Bayesian_Learning.html">155 nips-2003-Perspectives on Sparse Bayesian Learning</a></p>
<p>7 0.44523072 <a title="134-lsi-7" href="./nips-2003-Large_Margin_Classifiers%3A_Convex_Loss%2C_Low_Noise%2C_and_Convergence_Rates.html">101 nips-2003-Large Margin Classifiers: Convex Loss, Low Noise, and Convergence Rates</a></p>
<p>8 0.41941047 <a title="134-lsi-8" href="./nips-2003-Semidefinite_Relaxations_for_Approximate_Inference_on_Graphs_with_Cycles.html">174 nips-2003-Semidefinite Relaxations for Approximate Inference on Graphs with Cycles</a></p>
<p>9 0.41648811 <a title="134-lsi-9" href="./nips-2003-Bounded_Finite_State_Controllers.html">42 nips-2003-Bounded Finite State Controllers</a></p>
<p>10 0.39423168 <a title="134-lsi-10" href="./nips-2003-Applying_Metric-Trees_to_Belief-Point_POMDPs.html">29 nips-2003-Applying Metric-Trees to Belief-Point POMDPs</a></p>
<p>11 0.38303775 <a title="134-lsi-11" href="./nips-2003-Sparse_Greedy_Minimax_Probability_Machine_Classification.html">178 nips-2003-Sparse Greedy Minimax Probability Machine Classification</a></p>
<p>12 0.37225839 <a title="134-lsi-12" href="./nips-2003-Reasoning_about_Time_and_Knowledge_in_Neural_Symbolic_Learning_Systems.html">165 nips-2003-Reasoning about Time and Knowledge in Neural Symbolic Learning Systems</a></p>
<p>13 0.37124431 <a title="134-lsi-13" href="./nips-2003-An_Infinity-sample_Theory_for_Multi-category_Large_Margin_Classification.html">23 nips-2003-An Infinity-sample Theory for Multi-category Large Margin Classification</a></p>
<p>14 0.36592478 <a title="134-lsi-14" href="./nips-2003-Statistical_Debugging_of_Sampled_Programs.html">181 nips-2003-Statistical Debugging of Sampled Programs</a></p>
<p>15 0.33298385 <a title="134-lsi-15" href="./nips-2003-On_the_Concentration_of_Expectation_and_Approximate_Inference_in_Layered_Networks.html">142 nips-2003-On the Concentration of Expectation and Approximate Inference in Layered Networks</a></p>
<p>16 0.3321197 <a title="134-lsi-16" href="./nips-2003-Tree-structured_Approximations_by_Expectation_Propagation.html">189 nips-2003-Tree-structured Approximations by Expectation Propagation</a></p>
<p>17 0.32602587 <a title="134-lsi-17" href="./nips-2003-Finding_the_M_Most_Probable_Configurations_using_Loopy_Belief_Propagation.html">74 nips-2003-Finding the M Most Probable Configurations using Loopy Belief Propagation</a></p>
<p>18 0.31794053 <a title="134-lsi-18" href="./nips-2003-Error_Bounds_for_Transductive_Learning_via_Compression_and_Clustering.html">63 nips-2003-Error Bounds for Transductive Learning via Compression and Clustering</a></p>
<p>19 0.31219682 <a title="134-lsi-19" href="./nips-2003-Salient_Boundary_Detection_using_Ratio_Contour.html">168 nips-2003-Salient Boundary Detection using Ratio Contour</a></p>
<p>20 0.31064376 <a title="134-lsi-20" href="./nips-2003-PAC-Bayesian_Generic_Chaining.html">151 nips-2003-PAC-Bayesian Generic Chaining</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2003_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.094), (11, 0.012), (20, 0.018), (31, 0.111), (53, 0.044), (58, 0.061), (62, 0.059), (76, 0.141), (89, 0.35)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.75066018 <a title="134-lda-1" href="./nips-2003-Near-Minimax_Optimal_Classification_with_Dyadic_Classification_Trees.html">134 nips-2003-Near-Minimax Optimal Classification with Dyadic Classification Trees</a></p>
<p>2 0.65418613 <a title="134-lda-2" href="./nips-2003-Learning_a_Rare_Event_Detection_Cascade_by_Direct_Feature_Selection.html">109 nips-2003-Learning a Rare Event Detection Cascade by Direct Feature Selection</a></p>
<p>3 0.59111249 <a title="134-lda-3" href="./nips-2003-A_Biologically_Plausible_Algorithm_for_Reinforcement-shaped_Representational_Learning.html">4 nips-2003-A Biologically Plausible Algorithm for Reinforcement-shaped Representational Learning</a></p>
<p>4 0.52467871 <a title="134-lda-4" href="./nips-2003-Semi-Supervised_Learning_with_Trees.html">172 nips-2003-Semi-Supervised Learning with Trees</a></p>
<p>5 0.52063912 <a title="134-lda-5" href="./nips-2003-Max-Margin_Markov_Networks.html">124 nips-2003-Max-Margin Markov Networks</a></p>
<p>6 0.51924914 <a title="134-lda-6" href="./nips-2003-Gaussian_Process_Latent_Variable_Models_for_Visualisation_of_High_Dimensional_Data.html">77 nips-2003-Gaussian Process Latent Variable Models for Visualisation of High Dimensional Data</a></p>
<p>7 0.51543981 <a title="134-lda-7" href="./nips-2003-Discriminating_Deformable_Shape_Classes.html">53 nips-2003-Discriminating Deformable Shape Classes</a></p>
<p>8 0.51045191 <a title="134-lda-8" href="./nips-2003-Discriminative_Fields_for_Modeling_Spatial_Dependencies_in_Natural_Images.html">54 nips-2003-Discriminative Fields for Modeling Spatial Dependencies in Natural Images</a></p>
<p>9 0.51030982 <a title="134-lda-9" href="./nips-2003-AUC_Optimization_vs._Error_Rate_Minimization.html">3 nips-2003-AUC Optimization vs. Error Rate Minimization</a></p>
<p>10 0.50880575 <a title="134-lda-10" href="./nips-2003-Perspectives_on_Sparse_Bayesian_Learning.html">155 nips-2003-Perspectives on Sparse Bayesian Learning</a></p>
<p>11 0.50699645 <a title="134-lda-11" href="./nips-2003-Online_Learning_via_Global_Feedback_for_Phrase_Recognition.html">147 nips-2003-Online Learning via Global Feedback for Phrase Recognition</a></p>
<p>12 0.50567764 <a title="134-lda-12" href="./nips-2003-Increase_Information_Transfer_Rates_in_BCI_by_CSP_Extension_to_Multi-class.html">90 nips-2003-Increase Information Transfer Rates in BCI by CSP Extension to Multi-class</a></p>
<p>13 0.50512832 <a title="134-lda-13" href="./nips-2003-Link_Prediction_in_Relational_Data.html">118 nips-2003-Link Prediction in Relational Data</a></p>
<p>14 0.50033534 <a title="134-lda-14" href="./nips-2003-Statistical_Debugging_of_Sampled_Programs.html">181 nips-2003-Statistical Debugging of Sampled Programs</a></p>
<p>15 0.50003272 <a title="134-lda-15" href="./nips-2003-Using_the_Forest_to_See_the_Trees%3A_A_Graphical_Model_Relating_Features%2C_Objects%2C_and_Scenes.html">192 nips-2003-Using the Forest to See the Trees: A Graphical Model Relating Features, Objects, and Scenes</a></p>
<p>16 0.49931887 <a title="134-lda-16" href="./nips-2003-Invariant_Pattern_Recognition_by_Semi-Definite_Programming_Machines.html">96 nips-2003-Invariant Pattern Recognition by Semi-Definite Programming Machines</a></p>
<p>17 0.49855632 <a title="134-lda-17" href="./nips-2003-Learning_with_Local_and_Global_Consistency.html">113 nips-2003-Learning with Local and Global Consistency</a></p>
<p>18 0.49814838 <a title="134-lda-18" href="./nips-2003-Hierarchical_Topic_Models_and_the_Nested_Chinese_Restaurant_Process.html">83 nips-2003-Hierarchical Topic Models and the Nested Chinese Restaurant Process</a></p>
<p>19 0.49775672 <a title="134-lda-19" href="./nips-2003-Multiple_Instance_Learning_via_Disjunctive_Programming_Boosting.html">132 nips-2003-Multiple Instance Learning via Disjunctive Programming Boosting</a></p>
<p>20 0.49765176 <a title="134-lda-20" href="./nips-2003-Large_Margin_Classifiers%3A_Convex_Loss%2C_Low_Noise%2C_and_Convergence_Rates.html">101 nips-2003-Large Margin Classifiers: Convex Loss, Low Noise, and Convergence Rates</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
