<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>154 nips-2003-Perception of the Structure of the Physical World Using Unknown Multimodal Sensors and Effectors</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2003" href="../home/nips2003_home.html">nips2003</a> <a title="nips-2003-154" href="#">nips2003-154</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>154 nips-2003-Perception of the Structure of the Physical World Using Unknown Multimodal Sensors and Effectors</h1>
<br/><p>Source: <a title="nips-2003-154-pdf" href="http://papers.nips.cc/paper/2348-perception-of-the-structure-of-the-physical-world-using-unknown-multimodal-sensors-and-effectors.pdf">pdf</a></p><p>Author: D. Philipona, J.k. O'regan, J.-p. Nadal, Olivier Coenen</p><p>Abstract: Is there a way for an algorithm linked to an unknown body to infer by itself information about this body and the world it is in? Taking the case of space for example, is there a way for this algorithm to realize that its body is in a three dimensional world? Is it possible for this algorithm to discover how to move in a straight line? And more basically: do these questions make any sense at all given that the algorithm only has access to the very high-dimensional data consisting of its sensory inputs and motor outputs? We demonstrate in this article how these questions can be given a positive answer. We show that it is possible to make an algorithm that, by analyzing the law that links its motor outputs to its sensory inputs, discovers information about the structure of the world regardless of the devices constituting the body it is linked to. We present results from simulations demonstrating a way to issue motor orders resulting in “fundamental” movements of the body as regards the structure of the physical world. 1</p><p>Reference: <a title="nips-2003-154-reference" href="../nips2003_reference/nips-2003-Perception_of_the_Structure_of_the_Physical_World_Using_Unknown_Multimodal_Sensors_and_Effectors_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Perception of the structure of the physical world using unknown multimodal sensors and effectors  D. [sent-1, score-0.223]
</p><p>2 Philipona Sony CSL, 6 rue Amyot 75005 Paris, France david. [sent-2, score-0.056]
</p><p>3 Nadal Laboratoire de Physique Statistique, ENS rue Lhomond 75231 Paris Cedex 05  O. [sent-11, score-0.056]
</p><p>4 Coenen Sony CSL, 6 rue Amyot 75005 Paris, France  Abstract Is there a way for an algorithm linked to an unknown body to infer by itself information about this body and the world it is in? [sent-15, score-0.558]
</p><p>5 Taking the case of space for example, is there a way for this algorithm to realize that its body is in a three dimensional world? [sent-16, score-0.208]
</p><p>6 Is it possible for this algorithm to discover how to move in a straight line? [sent-17, score-0.058]
</p><p>7 And more basically: do these questions make any sense at all given that the algorithm only has access to the very high-dimensional data consisting of its sensory inputs and motor outputs? [sent-18, score-0.744]
</p><p>8 We show that it is possible to make an algorithm that, by analyzing the law that links its motor outputs to its sensory inputs, discovers information about the structure of the world regardless of the devices constituting the body it is linked to. [sent-20, score-1.193]
</p><p>9 We present results from simulations demonstrating a way to issue motor orders resulting in “fundamental” movements of the body as regards the structure of the physical world. [sent-21, score-0.61]
</p><p>10 1  Introduction  What is it possible to discover from behind the interface of an unknown body, embedded in an unknown world? [sent-22, score-0.058]
</p><p>11 In the present article we provide a more advanced mathematical overview together with a more robust algorithm, and we also present a multimodal simulation. [sent-24, score-0.088]
</p><p>12 The mathematical section provides a rigorous treatment, relying on concepts from differential geometry, of what are essentially two very simple ideas. [sent-25, score-0.035]
</p><p>13 The ﬁrst idea is that transformations of the organism-environment system which leave the sensory inputs unchanged will do this independently of the code or the structure of sensors, and are in fact the only aspects of the sensorimotor law that are independent of the code (property 1). [sent-26, score-0.974]
</p><p>14 In a single given sensorimotor conﬁguration the effects of such transformations induce what is called a tangent space over which linear algebra can be used to extract a small number of independent basic elements, which we call “measuring rod”. [sent-27, score-0.629]
</p><p>15 The second idea is that there is a way of applying these measuring rods globally (property 2) so as to discover an overall substructure in the set of transformations that the organism-environment system can suffer, and that leave sensory inputs unchanged. [sent-28, score-1.059]
</p><p>16 Taken together these ideas make it possible, if the sensory devices are sufﬁciently informative, to extract an algebraic group structure corresponding to the intrinsic properties of the space in which the organism is embedded. [sent-29, score-0.589]
</p><p>17 The simulation section is for the moment limited to an implementation of the ﬁrst idea. [sent-30, score-0.067]
</p><p>18 It presents brieﬂy the main steps of an implementation giving access to the measuring rods, and presents the results of its application to a virtual rat with mixed visual, auditory and tactile sensors (see Figure 2). [sent-31, score-0.724]
</p><p>19 The group discovered reveals the properties of the Euclidian space implicit in the equations describing the physics of the simulated world. [sent-32, score-0.084]
</p><p>20 Figure 1: The virtual organism used for the simulations. [sent-33, score-0.101]
</p><p>21 Random motor commands produce random changes in the rat’s body conﬁguration, involving uncoordinated movements of the head, changes in the gaze direction, and changes in the aperture of the eyelids and diaphragms. [sent-34, score-0.722]
</p><p>22 2  Mathematical formulation  Let us note S the sensory inputs, and M the motor outputs. [sent-35, score-0.581]
</p><p>23 Let us note P the conﬁgurations of the body controlled by the algorithm and E the conﬁgurations of the environment. [sent-37, score-0.244]
</p><p>24 1  Isotropy group of the sensorimotor law  Through time, the algorithm will be able to experiment a set of sensorimotor laws linking its inputs to its outputs: def  ϕ(·, E) = {M → ϕ(M, E), E ∈ E} These are a set of functions linking S to M , parametrized by the environmental state E. [sent-40, score-0.937]
</p><p>25 Our goal is to extract from this set something that does not depend on the way the sensory information is provided. [sent-41, score-0.375]
</p><p>26 In other words something that would be the same for all h◦ϕ(·, E), where h is an invertible function corresponding to a change of encoding, including changes of the sensory devices (as long as they provide access to the same information). [sent-42, score-0.502]
</p><p>27 def  If we note Sym(X) = {f : X → X, f one to one mapping}, and consider : Γ(ϕ) = {f ∈ Sym(M × E) such that ϕ ◦ f = ϕ} then Property 1 Γ(ϕ1 ) = Γ(ϕ2 ) ⇔ ∃f ∈ Sym(S) such that ϕ1 = f ◦ ϕ2 Thus Γ(ϕ) is invariant by change of encoding, and retains from ϕ all that is independent of the encoding. [sent-43, score-0.083]
</p><p>28 This result is easily understood using an example from physics: think of a light sensor with unknown characteristics in a world consisting of a single point light source. [sent-44, score-0.171]
</p><p>29 The values of the measures are very dependent on the sensor, but the fact that they are equal on concentric spheres is an intrinsic property of the physics of the situation (Γ(ϕ), in this case, would be the group of rotations) and is independent of the code and of the sensor’s characteristics. [sent-45, score-0.233]
</p><p>30 But how can we understand the transformations f which, ﬁrst, involve a manifold E the algorithm does not know, and second that are invisible since ϕ ◦ f = ϕ. [sent-46, score-0.119]
</p><p>31 We will show that, under one reasonable assumption, there is an algorithm that can discover the Lie algebra of the Lie subgroups of Γ(ϕ) that have independent actions over M and E, i. [sent-47, score-0.204]
</p><p>32 2  (1)  Fundamental vector ﬁelds over the sensory inputs  We will assume that the sensory inputs provide enough information to observe univocally the changes of the environment when the exteroceptive sensors do not move. [sent-50, score-1.17]
</p><p>33 In mathematical form, we will assume that: Condition 1 There exists U × V ⊂ M × E such that ϕ(M, ·) is an injective immersion from V to S for any M ∈ U Under this condition, ϕ(M, V) is a manifold for any P ∈ U and ϕ(M, ·) is a diffeomorphism from V to ϕ(M, V). [sent-51, score-0.136]
</p><p>34 The key point for us is that this whole vector ﬁeld can be discovered experimentally by the algorithm from one vector alone : let us suppose the algorithm knows the one vector d −tX , M0 )|t=0 ∈ T M|M0 (the tangent space of M at M0 ), that we will call a dt φ1 (e measuring rod. [sent-54, score-0.497]
</p><p>35 The fundamental vector ﬁelds are the key to our problem because [2] : S  X S , Y S = [X, Y ]  where the left term uses the bracket of the vectors ﬁelds on ϕ(M0 , V) and the right term uses the bracket in the Lie algebra of G. [sent-56, score-0.334]
</p><p>36 If the action φM0 is effective (and it is possible to show that for any G there is a subgroup such that it is),we have the additional properties: 1. [sent-58, score-0.071]
</p><p>37 X → X S is an injective Lie algebra morphism: we can understand the whole Lie algebra of G through the Lie bracket over the fundamental vector ﬁelds 2. [sent-59, score-0.362]
</p><p>38 G is diffeomorphic to the group of ﬁnite compositions of fundamental ﬂows : any element g of G can be written as g = eX1 eX2 . [sent-60, score-0.155]
</p><p>39 3  Discovery of the measuring rods  Thus the question is: how can the algorithm come to know the measuring rods? [sent-67, score-0.655]
</p><p>40 Reciprocally, it can be shown that: Property 4 Any measuring rod that has a sensory image in the intersection of the tangent spaces of ϕ(M0 , V) and ϕ(U, E) for any E ∈ V reveals a monodimensional subgroup of transformations over V that is invariant under any change of encoding. [sent-70, score-1.208]
</p><p>41 1  Simulation Description of the virtual rat  We have applied these ideas to a virtual body satisfying the different necessary conditions for the theory to be applied. [sent-72, score-0.453]
</p><p>42 Though our approach would also apply to the situation where the sensorimotor law involves time-varying functions, for simplicity here we shall take the restricted case where S and M are linked by a non-delayed relationship. [sent-73, score-0.407]
</p><p>43 We thus implemented a rat’s head with instantaneous reactions so that M ∈ Rm and S ∈ Rs . [sent-74, score-0.122]
</p><p>44 The head had visual, auditory and tactile input devices (see Figure 2). [sent-76, score-0.395]
</p><p>45 The visual device consisted of two eyes, each one being constituted by 40 photosensitive cells randomly distributed on a planar retina, one lens, one diaphragm (or pupil) and two eyelids. [sent-77, score-0.356]
</p><p>46 The images of the 9 light sources constituting the environment were projected through the lens on the retina to locally stimulate photosensitive cells, with a total inﬂux related to the aperture of the diaphragm and the eyelids. [sent-78, score-0.435]
</p><p>47 The auditory device was constituted by one amplitude sensor in each of the two ears, with a sensitivity proﬁle favoring auditory sources with azimuth and elevation 0◦ with respect to the orientation of the head. [sent-79, score-0.469]
</p><p>48 The tactile device was constituted by 4 whiskers on each side of the rat’s jaw, that stuck to an object when touching it, and delivered a signal related to the shift from rest position. [sent-80, score-0.394]
</p><p>49 azimuth  (a)  (b)  (c)  Figure 2: The sensory system. [sent-82, score-0.374]
</p><p>50 (a) the sensory part of both eyes is constituted of randomly distributed photosensitive cells (small dark dots). [sent-83, score-0.534]
</p><p>51 (b) the auditory sensors have a gain proﬁle favoring sounds coming from the front of the ears. [sent-84, score-0.243]
</p><p>52 (c) tactile devices stick to the sources they come into contact with. [sent-85, score-0.193]
</p><p>53 Sixteen control parameters were constructed from linear combinations of the motor outputs of dimension m = 300 using a random matrix WM ∈ M(16, m) representing some motor neural code. [sent-87, score-0.586]
</p><p>54 The conﬁguration of the rat’s head was then computed from these sixteen variables in this way: six parameters controlled the position and orientation of the head, and, for each eye, three controlled the eye orientation plus two the aperture of the diaphragm and the eyelids. [sent-88, score-0.436]
</p><p>55 The whiskers were not controllable, but were ﬁxed to the head. [sent-89, score-0.048]
</p><p>56 In the simulation we used linear encoding WS and WM in order to show that the algorithm worked even when the dimension of the sensory and motor vectors was high. [sent-90, score-0.737]
</p><p>57 More important, note that even when linear  mixing is used, the sensorimotor law is highly nonlinear: the sensors deliver signals that are not linear with respect to the conﬁguration of the rat’s head, and this conﬁguration is itself not linear with respect to the motor outputs. [sent-92, score-0.768]
</p><p>58 In the present simulation we will only be making use of this point, but keep in mind that the second important result was the relation between the fundamental vector ﬁelds and these measuring rods. [sent-95, score-0.321]
</p><p>59 The nullspaces of the two ﬁrst matrices reﬂect redundant variables; the nullspace of the last one is related to the intersection of the two ﬁrst tangent spaces (see equation 2). [sent-98, score-0.583]
</p><p>60 The graphs show there are 14 control parameters with respect to the body, and 27 variables to parametrize the environment (see text). [sent-99, score-0.118]
</p><p>61 The nullspace of the last matrix leads to the computation of an intersection of dimension 6 reﬂecting the Lie group of Euclidian transformations SE(3) (see text). [sent-100, score-0.443]
</p><p>62 In [4], the simulation aimed to demonstrate that the dimensions of the different vector spaces involved were accessible. [sent-101, score-0.117]
</p><p>63 We now present a simulation that goes beyond this by estimating these vector space themselves, in particular T ϕ(M0 , V)|S0 T ϕ(U, E0 )|S0 , in the case of multimodal sensory inputs and with a robust algorithm. [sent-102, score-0.585]
</p><p>64 The method previously used to estimate the ﬁrst tangent space, and more speciﬁcally its dimension, indeed required  an unrealistic level of accuracy. [sent-103, score-0.257]
</p><p>65 At the end of the process, when the linear relationship is judged to be sufﬁciently diagonal, the singular values are taken as the diagonal elements, and are thus estimated with the precision of the time derivative estimator. [sent-108, score-0.114]
</p><p>66 Figure 3a presents the evolution of the estimated dimension of the tangent space during this bootstrapping process. [sent-109, score-0.376]
</p><p>67 Then during a second stage, using these combinations, it estimates the tangent space to sensory inputs resulting from movement of the environment while it keeps its motor output ﬁxed at M0 . [sent-111, score-1.082]
</p><p>68 3  Results2  Figure 3a demonstrates the evolution of the estimation of the ratio between successive singular values. [sent-114, score-0.114]
</p><p>69 The maximum of this ratio can be taken as the frontier between signiﬁcantly non-zero values and zero ones, and thus reveals the dimension of the tangent space to the sensory inputs observed in an immobile environment. [sent-115, score-0.846]
</p><p>70 There are indeed 14 effective parameters of control of the body with respect to the sensory inputs: from the 16 parameters described in section 3. [sent-116, score-0.547]
</p><p>71 1, for each eye the two parameters controlling the aperture of the diaphragm and the eyelids combine in a single effective one characterizing the total incoming light inﬂux. [sent-117, score-0.295]
</p><p>72 After this adaptation process the tangent space to sensory inputs observed for a ﬁxed motor output M0 can be estimated without bootstrapping as shown, as regards its dimension (27 = 9 × 3 for the 9 light sources moving in a three dimensional space), in Figure 3b. [sent-118, score-1.179]
</p><p>73 The intersection is computed from the nullspace of the matrix constituted by concatenation of generating vectors of the two previous spaces, using equation 2. [sent-119, score-0.4]
</p><p>74 This nullspace is of 2 The Matlab code of the simulation can be downloaded at http://nivea. [sent-120, score-0.223]
</p><p>75 Figure 4: The effects of motor commands corresponding to a generating family of 6 independent measuring rods computed by the algorithm. [sent-124, score-0.762]
</p><p>76 They reveal the control of the head in a rigid fashion. [sent-125, score-0.122]
</p><p>77 Without the Lie bracket to understand commutativity, these movements involve arbitrary compositions of translations and rotations. [sent-126, score-0.237]
</p><p>78 Note that the graph shows the ratio of successive singular values, and thus has one less value than the number of vectors. [sent-128, score-0.114]
</p><p>79 Figure 4 demonstrates the movements of the rat’s head associated with the measuring rods found using the pseudoinverse of the sensorimotor law. [sent-129, score-0.927]
</p><p>80 Contrast these with the non-rigid movements of the rat’s head associated with random motor commands of Figure 1. [sent-130, score-0.518]
</p><p>81 4  Conclusion  We have shown that sensorimotor laws possess intrinsic properties related to the structure of the physical world in which an organism’s body is embedded. [sent-131, score-0.546]
</p><p>82 These properties have an overall group structure, for which smoothly parametrizable subgroups that act separately on the body and on the environment can be discovered. [sent-132, score-0.445]
</p><p>83 We have brieﬂy presented a simulation demonstrating the way to access the measuring rods of these subgroups. [sent-133, score-0.574]
</p><p>84 This will allow the groups whose measuring rods have been found to be decomposed. [sent-135, score-0.47]
</p><p>85 It will then be possible for the algorithm to distinguish for instance between translations and rotations, and between rotations around different centers. [sent-136, score-0.05]
</p><p>86 The ultimate goal is to show that there is a way of extracting objects in the environment from the sensorimotor law, even though nothing is known about the sensors and effectors. [sent-138, score-0.471]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('sensory', 0.339), ('rods', 0.285), ('tangent', 0.257), ('motor', 0.242), ('sensorimotor', 0.231), ('body', 0.208), ('measuring', 0.185), ('intersection', 0.157), ('rat', 0.149), ('law', 0.138), ('inputs', 0.126), ('constituted', 0.124), ('head', 0.122), ('sensors', 0.122), ('nullspace', 0.119), ('environment', 0.118), ('mx', 0.105), ('movements', 0.104), ('tactile', 0.103), ('bracket', 0.095), ('diaphragm', 0.095), ('lie', 0.093), ('devices', 0.09), ('guration', 0.088), ('def', 0.083), ('rod', 0.083), ('auditory', 0.08), ('singular', 0.078), ('se', 0.075), ('algebra', 0.075), ('immobile', 0.071), ('philipona', 0.071), ('photosensitive', 0.071), ('regan', 0.071), ('subgroup', 0.071), ('subgroups', 0.071), ('sym', 0.071), ('aperture', 0.07), ('fundamental', 0.069), ('simulation', 0.067), ('device', 0.066), ('bootstrapping', 0.066), ('command', 0.066), ('transformations', 0.066), ('tx', 0.063), ('intrinsic', 0.059), ('discover', 0.058), ('sm', 0.058), ('regards', 0.056), ('rue', 0.056), ('dt', 0.055), ('dimension', 0.053), ('property', 0.053), ('organism', 0.053), ('multimodal', 0.053), ('delivered', 0.053), ('manifold', 0.053), ('spaces', 0.05), ('commands', 0.05), ('france', 0.05), ('rotations', 0.05), ('paris', 0.05), ('outputs', 0.049), ('elds', 0.048), ('world', 0.048), ('group', 0.048), ('virtual', 0.048), ('amyot', 0.048), ('cedex', 0.048), ('csl', 0.048), ('diff', 0.048), ('euclidian', 0.048), ('exk', 0.048), ('eyelids', 0.048), ('injective', 0.048), ('whiskers', 0.048), ('con', 0.047), ('sensor', 0.043), ('eye', 0.042), ('sony', 0.041), ('constituting', 0.041), ('favoring', 0.041), ('linking', 0.04), ('light', 0.04), ('linked', 0.038), ('compositions', 0.038), ('laboratoire', 0.038), ('code', 0.037), ('access', 0.037), ('derivative', 0.036), ('controlled', 0.036), ('encoding', 0.036), ('something', 0.036), ('successive', 0.036), ('physics', 0.036), ('mathematical', 0.035), ('azimuth', 0.035), ('sixteen', 0.035), ('deliver', 0.035), ('ws', 0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999964 <a title="154-tfidf-1" href="./nips-2003-Perception_of_the_Structure_of_the_Physical_World_Using_Unknown_Multimodal_Sensors_and_Effectors.html">154 nips-2003-Perception of the Structure of the Physical World Using Unknown Multimodal Sensors and Effectors</a></p>
<p>Author: D. Philipona, J.k. O'regan, J.-p. Nadal, Olivier Coenen</p><p>Abstract: Is there a way for an algorithm linked to an unknown body to infer by itself information about this body and the world it is in? Taking the case of space for example, is there a way for this algorithm to realize that its body is in a three dimensional world? Is it possible for this algorithm to discover how to move in a straight line? And more basically: do these questions make any sense at all given that the algorithm only has access to the very high-dimensional data consisting of its sensory inputs and motor outputs? We demonstrate in this article how these questions can be given a positive answer. We show that it is possible to make an algorithm that, by analyzing the law that links its motor outputs to its sensory inputs, discovers information about the structure of the world regardless of the devices constituting the body it is linked to. We present results from simulations demonstrating a way to issue motor orders resulting in “fundamental” movements of the body as regards the structure of the physical world. 1</p><p>2 0.16770193 <a title="154-tfidf-2" href="./nips-2003-A_Biologically_Plausible_Algorithm_for_Reinforcement-shaped_Representational_Learning.html">4 nips-2003-A Biologically Plausible Algorithm for Reinforcement-shaped Representational Learning</a></p>
<p>Author: Maneesh Sahani</p><p>Abstract: Signiﬁcant plasticity in sensory cortical representations can be driven in mature animals either by behavioural tasks that pair sensory stimuli with reinforcement, or by electrophysiological experiments that pair sensory input with direct stimulation of neuromodulatory nuclei, but usually not by sensory stimuli presented alone. Biologically motivated theories of representational learning, however, have tended to focus on unsupervised mechanisms, which may play a signiﬁcant role on evolutionary or developmental timescales, but which neglect this essential role of reinforcement in adult plasticity. By contrast, theoretical reinforcement learning has generally dealt with the acquisition of optimal policies for action in an uncertain world, rather than with the concurrent shaping of sensory representations. This paper develops a framework for representational learning which builds on the relative success of unsupervised generativemodelling accounts of cortical encodings to incorporate the effects of reinforcement in a biologically plausible way. 1</p><p>3 0.12331407 <a title="154-tfidf-3" href="./nips-2003-Attractive_People%3A_Assembling_Loose-Limbed_Models_using_Non-parametric_Belief_Propagation.html">35 nips-2003-Attractive People: Assembling Loose-Limbed Models using Non-parametric Belief Propagation</a></p>
<p>Author: Leonid Sigal, Michael Isard, Benjamin H. Sigelman, Michael J. Black</p><p>Abstract: The detection and pose estimation of people in images and video is made challenging by the variability of human appearance, the complexity of natural scenes, and the high dimensionality of articulated body models. To cope with these problems we represent the 3D human body as a graphical model in which the relationships between the body parts are represented by conditional probability distributions. We formulate the pose estimation problem as one of probabilistic inference over a graphical model where the random variables correspond to the individual limb parameters (position and orientation). Because the limbs are described by 6-dimensional vectors encoding pose in 3-space, discretization is impractical and the random variables in our model must be continuousvalued. To approximate belief propagation in such a graph we exploit a recently introduced generalization of the particle ﬁlter. This framework facilitates the automatic initialization of the body-model from low level cues and is robust to occlusion of body parts and scene clutter. 1</p><p>4 0.11413365 <a title="154-tfidf-4" href="./nips-2003-Learning_a_World_Model_and_Planning_with_a_Self-Organizing%2C_Dynamic_Neural_System.html">110 nips-2003-Learning a World Model and Planning with a Self-Organizing, Dynamic Neural System</a></p>
<p>Author: Marc Toussaint</p><p>Abstract: We present a connectionist architecture that can learn a model of the relations between perceptions and actions and use this model for behavior planning. State representations are learned with a growing selforganizing layer which is directly coupled to a perception and a motor layer. Knowledge about possible state transitions is encoded in the lateral connectivity. Motor signals modulate this lateral connectivity and a dynamic ﬁeld on the layer organizes a planning process. All mechanisms are local and adaptation is based on Hebbian ideas. The model is continuous in the action, perception, and time domain.</p><p>5 0.10191377 <a title="154-tfidf-5" href="./nips-2003-Geometric_Analysis_of_Constrained_Curves.html">81 nips-2003-Geometric Analysis of Constrained Curves</a></p>
<p>Author: Anuj Srivastava, Washington Mio, Xiuwen Liu, Eric Klassen</p><p>Abstract: We present a geometric approach to statistical shape analysis of closed curves in images. The basic idea is to specify a space of closed curves satisfying given constraints, and exploit the differential geometry of this space to solve optimization and inference problems. We demonstrate this approach by: (i) deﬁning and computing statistics of observed shapes, (ii) deﬁning and learning a parametric probability model on shape space, and (iii) designing a binary hypothesis test on this space. 1</p><p>6 0.095240779 <a title="154-tfidf-6" href="./nips-2003-Eye_Movements_for_Reward_Maximization.html">68 nips-2003-Eye Movements for Reward Maximization</a></p>
<p>7 0.073755145 <a title="154-tfidf-7" href="./nips-2003-Circuit_Optimization_Predicts_Dynamic_Networks_for_Chemosensory_Orientation_in_Nematode_C._elegans.html">45 nips-2003-Circuit Optimization Predicts Dynamic Networks for Chemosensory Orientation in Nematode C. elegans</a></p>
<p>8 0.073123783 <a title="154-tfidf-8" href="./nips-2003-Bounded_Invariance_and_the_Formation_of_Place_Fields.html">43 nips-2003-Bounded Invariance and the Formation of Place Fields</a></p>
<p>9 0.068540484 <a title="154-tfidf-9" href="./nips-2003-Bounded_Finite_State_Controllers.html">42 nips-2003-Bounded Finite State Controllers</a></p>
<p>10 0.063265644 <a title="154-tfidf-10" href="./nips-2003-Sensory_Modality_Segregation.html">175 nips-2003-Sensory Modality Segregation</a></p>
<p>11 0.062492691 <a title="154-tfidf-11" href="./nips-2003-Optimal_Manifold_Representation_of_Data%3A_An_Information_Theoretic_Approach.html">149 nips-2003-Optimal Manifold Representation of Data: An Information Theoretic Approach</a></p>
<p>12 0.061472386 <a title="154-tfidf-12" href="./nips-2003-An_Improved_Scheme_for_Detection_and_Labelling_in_Johansson_Displays.html">22 nips-2003-An Improved Scheme for Detection and Labelling in Johansson Displays</a></p>
<p>13 0.059956729 <a title="154-tfidf-13" href="./nips-2003-A_Probabilistic_Model_of_Auditory_Space_Representation_in_the_Barn_Owl.html">15 nips-2003-A Probabilistic Model of Auditory Space Representation in the Barn Owl</a></p>
<p>14 0.059733696 <a title="154-tfidf-14" href="./nips-2003-Probabilistic_Inference_in_Human_Sensorimotor_Processing.html">161 nips-2003-Probabilistic Inference in Human Sensorimotor Processing</a></p>
<p>15 0.057297509 <a title="154-tfidf-15" href="./nips-2003-Subject-Independent_Magnetoencephalographic_Source_Localization_by_a_Multilayer_Perceptron.html">182 nips-2003-Subject-Independent Magnetoencephalographic Source Localization by a Multilayer Perceptron</a></p>
<p>16 0.053378724 <a title="154-tfidf-16" href="./nips-2003-Distributed_Optimization_in_Adaptive_Networks.html">55 nips-2003-Distributed Optimization in Adaptive Networks</a></p>
<p>17 0.052433584 <a title="154-tfidf-17" href="./nips-2003-Prediction_on_Spike_Data_Using_Kernel_Algorithms.html">160 nips-2003-Prediction on Spike Data Using Kernel Algorithms</a></p>
<p>18 0.04416215 <a title="154-tfidf-18" href="./nips-2003-Reconstructing_MEG_Sources_with_Unknown_Correlations.html">166 nips-2003-Reconstructing MEG Sources with Unknown Correlations</a></p>
<p>19 0.043134853 <a title="154-tfidf-19" href="./nips-2003-Parameterized_Novelty_Detectors_for_Environmental_Sensor_Monitoring.html">153 nips-2003-Parameterized Novelty Detectors for Environmental Sensor Monitoring</a></p>
<p>20 0.043100931 <a title="154-tfidf-20" href="./nips-2003-Entrainment_of_Silicon_Central_Pattern_Generators_for_Legged_Locomotory_Control.html">61 nips-2003-Entrainment of Silicon Central Pattern Generators for Legged Locomotory Control</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2003_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.154), (1, 0.05), (2, 0.072), (3, 0.019), (4, -0.059), (5, -0.011), (6, 0.088), (7, -0.053), (8, 0.002), (9, -0.084), (10, 0.031), (11, 0.002), (12, 0.17), (13, 0.036), (14, 0.046), (15, 0.096), (16, -0.051), (17, 0.017), (18, 0.038), (19, 0.028), (20, 0.029), (21, -0.114), (22, 0.034), (23, 0.209), (24, -0.003), (25, -0.12), (26, 0.105), (27, 0.045), (28, -0.038), (29, 0.043), (30, 0.008), (31, 0.049), (32, 0.009), (33, -0.359), (34, 0.068), (35, 0.031), (36, -0.023), (37, 0.053), (38, -0.04), (39, -0.064), (40, -0.293), (41, 0.059), (42, -0.121), (43, -0.024), (44, 0.019), (45, -0.13), (46, 0.115), (47, -0.191), (48, -0.006), (49, -0.072)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98076934 <a title="154-lsi-1" href="./nips-2003-Perception_of_the_Structure_of_the_Physical_World_Using_Unknown_Multimodal_Sensors_and_Effectors.html">154 nips-2003-Perception of the Structure of the Physical World Using Unknown Multimodal Sensors and Effectors</a></p>
<p>Author: D. Philipona, J.k. O'regan, J.-p. Nadal, Olivier Coenen</p><p>Abstract: Is there a way for an algorithm linked to an unknown body to infer by itself information about this body and the world it is in? Taking the case of space for example, is there a way for this algorithm to realize that its body is in a three dimensional world? Is it possible for this algorithm to discover how to move in a straight line? And more basically: do these questions make any sense at all given that the algorithm only has access to the very high-dimensional data consisting of its sensory inputs and motor outputs? We demonstrate in this article how these questions can be given a positive answer. We show that it is possible to make an algorithm that, by analyzing the law that links its motor outputs to its sensory inputs, discovers information about the structure of the world regardless of the devices constituting the body it is linked to. We present results from simulations demonstrating a way to issue motor orders resulting in “fundamental” movements of the body as regards the structure of the physical world. 1</p><p>2 0.54067421 <a title="154-lsi-2" href="./nips-2003-Learning_a_World_Model_and_Planning_with_a_Self-Organizing%2C_Dynamic_Neural_System.html">110 nips-2003-Learning a World Model and Planning with a Self-Organizing, Dynamic Neural System</a></p>
<p>Author: Marc Toussaint</p><p>Abstract: We present a connectionist architecture that can learn a model of the relations between perceptions and actions and use this model for behavior planning. State representations are learned with a growing selforganizing layer which is directly coupled to a perception and a motor layer. Knowledge about possible state transitions is encoded in the lateral connectivity. Motor signals modulate this lateral connectivity and a dynamic ﬁeld on the layer organizes a planning process. All mechanisms are local and adaptation is based on Hebbian ideas. The model is continuous in the action, perception, and time domain.</p><p>3 0.48673663 <a title="154-lsi-3" href="./nips-2003-A_Biologically_Plausible_Algorithm_for_Reinforcement-shaped_Representational_Learning.html">4 nips-2003-A Biologically Plausible Algorithm for Reinforcement-shaped Representational Learning</a></p>
<p>Author: Maneesh Sahani</p><p>Abstract: Signiﬁcant plasticity in sensory cortical representations can be driven in mature animals either by behavioural tasks that pair sensory stimuli with reinforcement, or by electrophysiological experiments that pair sensory input with direct stimulation of neuromodulatory nuclei, but usually not by sensory stimuli presented alone. Biologically motivated theories of representational learning, however, have tended to focus on unsupervised mechanisms, which may play a signiﬁcant role on evolutionary or developmental timescales, but which neglect this essential role of reinforcement in adult plasticity. By contrast, theoretical reinforcement learning has generally dealt with the acquisition of optimal policies for action in an uncertain world, rather than with the concurrent shaping of sensory representations. This paper develops a framework for representational learning which builds on the relative success of unsupervised generativemodelling accounts of cortical encodings to incorporate the effects of reinforcement in a biologically plausible way. 1</p><p>4 0.45397493 <a title="154-lsi-4" href="./nips-2003-Sensory_Modality_Segregation.html">175 nips-2003-Sensory Modality Segregation</a></p>
<p>Author: Virginia Sa</p><p>Abstract: Why are sensory modalities segregated the way they are? In this paper we show that sensory modalities are well designed for self-supervised cross-modal learning. Using the Minimizing-Disagreement algorithm on an unsupervised speech categorization task with visual (moving lips) and auditory (sound signal) inputs, we show that very informative auditory dimensions actually harm performance when moved to the visual side of the network. It is better to throw them away than to consider them part of the “visual input”. We explain this ﬁnding in terms of the statistical structure in sensory inputs. 1</p><p>5 0.3939485 <a title="154-lsi-5" href="./nips-2003-Attractive_People%3A_Assembling_Loose-Limbed_Models_using_Non-parametric_Belief_Propagation.html">35 nips-2003-Attractive People: Assembling Loose-Limbed Models using Non-parametric Belief Propagation</a></p>
<p>Author: Leonid Sigal, Michael Isard, Benjamin H. Sigelman, Michael J. Black</p><p>Abstract: The detection and pose estimation of people in images and video is made challenging by the variability of human appearance, the complexity of natural scenes, and the high dimensionality of articulated body models. To cope with these problems we represent the 3D human body as a graphical model in which the relationships between the body parts are represented by conditional probability distributions. We formulate the pose estimation problem as one of probabilistic inference over a graphical model where the random variables correspond to the individual limb parameters (position and orientation). Because the limbs are described by 6-dimensional vectors encoding pose in 3-space, discretization is impractical and the random variables in our model must be continuousvalued. To approximate belief propagation in such a graph we exploit a recently introduced generalization of the particle ﬁlter. This framework facilitates the automatic initialization of the body-model from low level cues and is robust to occlusion of body parts and scene clutter. 1</p><p>6 0.37670058 <a title="154-lsi-6" href="./nips-2003-Probabilistic_Inference_in_Human_Sensorimotor_Processing.html">161 nips-2003-Probabilistic Inference in Human Sensorimotor Processing</a></p>
<p>7 0.35528278 <a title="154-lsi-7" href="./nips-2003-Eye_Movements_for_Reward_Maximization.html">68 nips-2003-Eye Movements for Reward Maximization</a></p>
<p>8 0.35296419 <a title="154-lsi-8" href="./nips-2003-An_Improved_Scheme_for_Detection_and_Labelling_in_Johansson_Displays.html">22 nips-2003-An Improved Scheme for Detection and Labelling in Johansson Displays</a></p>
<p>9 0.31016225 <a title="154-lsi-9" href="./nips-2003-Bounded_Invariance_and_the_Formation_of_Place_Fields.html">43 nips-2003-Bounded Invariance and the Formation of Place Fields</a></p>
<p>10 0.30336568 <a title="154-lsi-10" href="./nips-2003-Geometric_Analysis_of_Constrained_Curves.html">81 nips-2003-Geometric Analysis of Constrained Curves</a></p>
<p>11 0.27649027 <a title="154-lsi-11" href="./nips-2003-Circuit_Optimization_Predicts_Dynamic_Networks_for_Chemosensory_Orientation_in_Nematode_C._elegans.html">45 nips-2003-Circuit Optimization Predicts Dynamic Networks for Chemosensory Orientation in Nematode C. elegans</a></p>
<p>12 0.25253603 <a title="154-lsi-12" href="./nips-2003-Iterative_Scaled_Trust-Region_Learning_in_Krylov_Subspaces_via_Pearlmutter%27s_Implicit_Sparse_Hessian.html">97 nips-2003-Iterative Scaled Trust-Region Learning in Krylov Subspaces via Pearlmutter's Implicit Sparse Hessian</a></p>
<p>13 0.24770498 <a title="154-lsi-13" href="./nips-2003-Subject-Independent_Magnetoencephalographic_Source_Localization_by_a_Multilayer_Perceptron.html">182 nips-2003-Subject-Independent Magnetoencephalographic Source Localization by a Multilayer Perceptron</a></p>
<p>14 0.22021781 <a title="154-lsi-14" href="./nips-2003-Autonomous_Helicopter_Flight_via_Reinforcement_Learning.html">38 nips-2003-Autonomous Helicopter Flight via Reinforcement Learning</a></p>
<p>15 0.21682693 <a title="154-lsi-15" href="./nips-2003-Optimal_Manifold_Representation_of_Data%3A_An_Information_Theoretic_Approach.html">149 nips-2003-Optimal Manifold Representation of Data: An Information Theoretic Approach</a></p>
<p>16 0.21133196 <a title="154-lsi-16" href="./nips-2003-Entrainment_of_Silicon_Central_Pattern_Generators_for_Legged_Locomotory_Control.html">61 nips-2003-Entrainment of Silicon Central Pattern Generators for Legged Locomotory Control</a></p>
<p>17 0.21024279 <a title="154-lsi-17" href="./nips-2003-A_Probabilistic_Model_of_Auditory_Space_Representation_in_the_Barn_Owl.html">15 nips-2003-A Probabilistic Model of Auditory Space Representation in the Barn Owl</a></p>
<p>18 0.19312724 <a title="154-lsi-18" href="./nips-2003-When_Does_Non-Negative_Matrix_Factorization_Give_a_Correct_Decomposition_into_Parts%3F.html">195 nips-2003-When Does Non-Negative Matrix Factorization Give a Correct Decomposition into Parts?</a></p>
<p>19 0.19190353 <a title="154-lsi-19" href="./nips-2003-Increase_Information_Transfer_Rates_in_BCI_by_CSP_Extension_to_Multi-class.html">90 nips-2003-Increase Information Transfer Rates in BCI by CSP Extension to Multi-class</a></p>
<p>20 0.19082087 <a title="154-lsi-20" href="./nips-2003-Bounded_Finite_State_Controllers.html">42 nips-2003-Bounded Finite State Controllers</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2003_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.024), (11, 0.013), (30, 0.012), (35, 0.029), (53, 0.056), (71, 0.031), (76, 0.029), (85, 0.03), (91, 0.699)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98737419 <a title="154-lda-1" href="./nips-2003-Perception_of_the_Structure_of_the_Physical_World_Using_Unknown_Multimodal_Sensors_and_Effectors.html">154 nips-2003-Perception of the Structure of the Physical World Using Unknown Multimodal Sensors and Effectors</a></p>
<p>Author: D. Philipona, J.k. O'regan, J.-p. Nadal, Olivier Coenen</p><p>Abstract: Is there a way for an algorithm linked to an unknown body to infer by itself information about this body and the world it is in? Taking the case of space for example, is there a way for this algorithm to realize that its body is in a three dimensional world? Is it possible for this algorithm to discover how to move in a straight line? And more basically: do these questions make any sense at all given that the algorithm only has access to the very high-dimensional data consisting of its sensory inputs and motor outputs? We demonstrate in this article how these questions can be given a positive answer. We show that it is possible to make an algorithm that, by analyzing the law that links its motor outputs to its sensory inputs, discovers information about the structure of the world regardless of the devices constituting the body it is linked to. We present results from simulations demonstrating a way to issue motor orders resulting in “fundamental” movements of the body as regards the structure of the physical world. 1</p><p>2 0.97188276 <a title="154-lda-2" href="./nips-2003-Learning_a_World_Model_and_Planning_with_a_Self-Organizing%2C_Dynamic_Neural_System.html">110 nips-2003-Learning a World Model and Planning with a Self-Organizing, Dynamic Neural System</a></p>
<p>Author: Marc Toussaint</p><p>Abstract: We present a connectionist architecture that can learn a model of the relations between perceptions and actions and use this model for behavior planning. State representations are learned with a growing selforganizing layer which is directly coupled to a perception and a motor layer. Knowledge about possible state transitions is encoded in the lateral connectivity. Motor signals modulate this lateral connectivity and a dynamic ﬁeld on the layer organizes a planning process. All mechanisms are local and adaptation is based on Hebbian ideas. The model is continuous in the action, perception, and time domain.</p><p>3 0.97037339 <a title="154-lda-3" href="./nips-2003-Learning_Near-Pareto-Optimal_Conventions_in_Polynomial_Time.html">105 nips-2003-Learning Near-Pareto-Optimal Conventions in Polynomial Time</a></p>
<p>Author: Xiaofeng Wang, Tuomas Sandholm</p><p>Abstract: We study how to learn to play a Pareto-optimal strict Nash equilibrium when there exist multiple equilibria and agents may have different preferences among the equilibria. We focus on repeated coordination games of non-identical interest where agents do not know the game structure up front and receive noisy payoffs. We design efﬁcient near-optimal algorithms for both the perfect monitoring and the imperfect monitoring setting(where the agents only observe their own payoffs and the joint actions). 1</p><p>4 0.96663809 <a title="154-lda-4" href="./nips-2003-Identifying_Structure_across_Pre-partitioned_Data.html">87 nips-2003-Identifying Structure across Pre-partitioned Data</a></p>
<p>Author: Zvika Marx, Ido Dagan, Eli Shamir</p><p>Abstract: We propose an information-theoretic clustering approach that incorporates a pre-known partition of the data, aiming to identify common clusters that cut across the given partition. In the standard clustering setting the formation of clusters is guided by a single source of feature information. The newly utilized pre-partition factor introduces an additional bias that counterbalances the impact of the features whenever they become correlated with this known partition. The resulting algorithmic framework was applied successfully to synthetic data, as well as to identifying text-based cross-religion correspondences. 1 In t ro d u c t i o n The standard task of feature-based data clustering deals with a single set of elements that are characterized by a unified set of features. The goal of the clustering task is to identify implicit constructs, or themes, within the clustered set, grouping together elements that are characterized similarly by the features. In recent years there has been growing interest in more complex clustering settings, in which additional information is incorporated [1], [2]. Several such extensions ([3]-[5]) are based on the information bottleneck (IB) framework [6], which facilitates coherent information-theoretic representation of different information types. In a recent line of research we have investigated the cross-dataset clustering task [7], [8]. In this setting, some inherent a-priori partition of the clustered data to distinct subsets is given. The clustering goal it to identify corresponding (analogous) structures that cut across the different subsets, while ignoring internal structures that characterize individual subsets. To accomplish this task, those features that commonly characterize elements across the different subsets guide the clustering process, while within-subset regularities are neutralized. In [7], we presented a distance-based hard clustering algorithm for the coupledclustering problem, in which the clustered data is pre-partitioned to two subsets. In [8], our setting, generalized to pre-partitions of any number of subsets, was addressed by a heuristic extension of the probabilistic IB algorithm, yielding improved empirical results. Specifically, the algorithm in [8] was based on a modification of the IB stable-point equation, which amplified the impact of features characterizing a formed cluster across all, or most, subsets. This paper describes an information-theoretic framework that motivates and extends the algorithm proposed in [8]. The given pre-partitioning is represented via a probability distribution variable, which may represent “soft” pre-partitioning of the data, versus the strictly disjoint subsets assumed in the earlier cross-dataset framework. Further, we present a new functional that captures the cross-partition motivation. From the new functional, we derive a stable-point equation underlying our algorithmic framework in conjunction with the corresponding IB equation. Our algorithm was tested empirically on synthetic data and on a real-world textbased task that aimed to identify corresponding themes across distinct religions. We have cross-clustered five sets of keywords that were extracted from topical corpora of texts about Buddhism, Christianity, Hinduism, Islam and Judaism. In distinction from standard clustering results, our algorithm reveals themes that are common to all religions, such as sacred writings, festivals, narratives and myths and theological principles, and avoids topical clusters that correspond to individual religions (for example, ‘Christmas’ and ‘Easter’ are clustered together with ‘Ramadan’ rather than with ‘Church’). Finally, we have paid specific attention to the framework of clustering with side information [4]. While this approach was presented for a somewhat different mindset, it might be used directly to address clustering across pre-partitioned data. We compare the technical details of the two approaches and demonstrate empirically that clustering with side information does not seem appropriate for the kind of cross-partition tasks that we explored. 2 Th e In fo rmat i o n B ot t len eck M et h od Probabilistic (“soft”) data clustering outputs, for each element x of the set being clustered and each cluster c, an assignment probability p(c|x). The IB method [6] interprets probabilistic clustering as lossy data compression. The given data is represented by a random variable X ranging over the clustered elements. X is compressed through another random variable C, ranging over the clusters. Every element x is characterized by conditional probability distribution p(Y|x), where Y is a third random variable taking the members y of a given set of features as values. The IB method formalizes the clustering task as minimizing the IB functional: L(IB) = I(C; X) − β I(C; Y) . (1) As known from information theory (Ch. 13 of [9]), minimizing the mutual information I(C; X) optimizes distorted compression rate. A complementary bias to maximize I(C; Y) is interpreted in [6] as articulating the level of relevance of Y to the obtained clustering, inferred from the level by which C can predict Y. β is a free parameter counterbalancing the two biases. It is shown in [6] that p(c|x) values that minimize L(IB) satisfy the following equation: p(c|x) = 1 p (c )e −β DKL [ p ( Y |x )|| p (Y |c ) ] , z( β , x) (2) where DKL stands for the Kullback-Leibler (KL) divergence, or relative entropy, between two distributions and z(β ,x) is a normalization function over C. Eq. (2) implies that, optimally, x is assigned to c in proportion to their KL distance in a feature distribution space, where the distribution p(Y|c) takes the role of a Start at time t = 0 and iterate the following update-steps, till convergence: IB1: initialize p t (c|x) randomly or arbitrarily −β DKL [ p (Y | x )|| pt −1 (Y |c ) ] pt (c|x) ∝ IB2: pt (c) = IB3: pt (y|c) = pt −1 (c ) e ∑ x (t = 0) (t > 0) p t (c | x ) p ( x ) 1 ∑ pt ( c | x) p ( y | x ) p ( x) p t (c ) x Figure 1: The Information Bottleneck iterative algorithm (with fixed β and |C|). representative, or centroid, of c. The feature variable Y is hence utilized as the (exclusive) means to guide clustering, beyond the random nature of compression. Figure 1 presents the IB iterative algorithm for a fixed value of β . The IB1 update step follows Eq. (2). The other two steps, which are derived from the IB functional as well, estimate the p(c) and p(y|c) values required for the next iteration. The algorithm converges to a local minimum of the IB functional. The IB setting, particularly the derivation of steps IB1 and IB3 of the algorithm, assumes that Y and C are independent given X, that is: I(C; Y|X) = ∑x p(x) I(C|x; Y|x) = 0. The balancing parameter β affects the number of distinct clusters being formed in a manner that resembles (inverse) temperature in physical systems. The higher β is (i.e., the stronger the bias to construct C that predicts Y well), more distinct clusters are required for encoding the data. For each |C| = 2, 3, …, there is a minimal β value, enabling the formation of |C| distinct clusters. Setting β to be smaller than this critical value corresponding to the current |C| would result in two or more clusters that are identical to one another. Based on this, the iterative algorithm is applied repeatedly within a gradual cooling-like (deterministic annealing) scheme: starting with random initialization of the p0 (c|x)'s, generate two clusters with the critical β value, found empirically, for |C| = 2. Then, use a perturbation on the obtained two-cluster configuration to initialize the p0(c|x)'s for a larger set of clusters and execute additional runs of the algorithm to identify the critical β value for the larger |C|. And so on: each output configuration is used as a basis for a more granular one. The final outcome is a “soft hierarchy” of probabilistic clusters. 3 Cro ss- p a rt i t i o n Clu st eri n g Cross-partition (CP) clustering introduces a factor – a pre-given partition of the clustered data – additional to what considered in a standard clustering setting. For representing this factor we introduce the pre-partitioning variable W, ranging over all parts w of the pre-given partition. Every data element x is associated with W through a given probability distribution p(W|x). Our goal is to cluster the data, so that the clusters C would not be correlated with W. We notice that Y, which is intended to direct the formation of clusters, might be a-priori correlated with W, so the formed clusters might end up being correlated with W as well. Our method aims at eliminating this aspect of Y. 3.1 I n f or ma t i o n D e f oc us i n g As noted, some of the information conveyed by Y characterizes structures correlated with W, while the other part of the information characterizes the target cross-W structures. We are interested in detecting the latter while filtering out the former. However, there is no direct a-priori separation between the two parts of the Ymediated information. Our strategy in tackling this difficulty is: we follow in general Y's directions, as the IB method does, while avoiding Y's impact whenever it entails undesired inter-dependencies of C and W. Our strategy implies conflicting biases with regard to the mutual information I(C,Y): it should be maximized in order to form meaningful clusters, but be minimized as well in the specific context where Y entails C–W dependencies. Accordingly, we propose a computational procedure directed by two distinct cost-terms in tandem. The first one is the IB functional (Eq. 1), introducing the bias to maximize I(C,Y). With this bias alone, Y might dictate (or “explain”, in retrospect) substantial C–W dependencies, implying a low I(C;W|Y) value. 1 Hence, the guideline of preventing Y from accounting for C–W dependencies is realized through an opposing bias of maximizing I(C;W|Y) = ∑y p(y) I(C|y; W|y). The second cost term – the Information Defocusing (ID) functional – consequently counterbalances minimization of I(C,Y) against the new bias: L(ID) = I(C; Y) − η I(C;W|Y) , (3) where η is a free parameter articulating the tradeoff between the biases. The ID functional captures our goal of reducing the impact of Y selectively: “defocusing” a specific aspect of the information Y conveys: the information correlated with W. In a like manner to the stable-point equation of the IB functional (Eq. 2), we derive the following stable-point equation for the ID functional: η p ( w) 1 p ( c )∏ w p ( y | c, w) η +1 , p(c|y) = z (η , y ) (4) where z(η,y) is a normalization function over C. The derivation relies on an additional assumption, I(C;W) = 0, imposing the intended independence between C and W (the detailed derivation will be described elsewhere). The intuitive interpretation of Eq. (4) is as follows: a feature y is to be associated with a cluster c in proportion to a weighted, though flattened, geometric mean of the “W-projected centroids” p(y|c,w), priored by p(c). 2 This scheme overweighs y's that contribute to c evenly across W. Thus, clusters satisfying Eq. (4) are situated around centroids biased towards evenly contributing features. The higher η is, heavier emphasis is put on suppressing disagreements between the w's. For η → ∞ a plain weighted geometric-mean scheme is obtained. The inclusion of a step derived from Eq. (4) in our algorithm (see below) facilitates convergence on a configuration with centroids dominated by features that are evenly distributed across W. 3.2 T h e Cr os s - p a r t i t i on C l us t e r i n g A l g or i t h m Our proposed cross partition (CP) clustering algorithm (Fig. 2) seeks a clustering configuration that optimizes simultaneously both the IB and ID functionals, 1 Notice that “Z explaining well the dependencies between A and B” is equivalent with “A and B sharing little information in common given Z”, i.e. low I(A;B|Z) . Complete conditional independence is exemplified in the IB framework, assuming I(C;Y|X) = 0. 2 Eq. (4) resembles our suggestion in [8] to compute a geometric average over the subsets; in the current paper this scheme is analytically derived from the ID functional. Start at time t = 0 and iterate the following update-steps, till convergence: CP1: Initialize p t (c|x) randomly or arbitrarily −β DKL [ p (Y | x )|| pt −1 (Y |c ) ] pt (c|x) ∝ CP2: pt (c) = CP3: p*t (y|c,w) = CP4: (t = 0) p t −1 (c ) e ∑ x (t > 0) p t (c | x ) p ( x ) 1 ∑ pt ( c | x ) p ( y | x ) p ( w | x ) p ( x ) p t ( c ) p ( w) x Initialize p*t (c) randomly or arbitrarily (t = 0) p*t (c) (t > 0) = ∑ y p *t −1 (c | y ) p ( y ) η CP5: p*t (c|y) ∝ p *t (c)∏w p *t ( y | c, w) η +1 CP6: pt (y|c) = p ( w) p *t (c | y ) p ( y ) p *t (c ) Figure 2: The cross-partition clustering iterative algorithm (with fixed β, η, and |C|). thus obtaining clusters that cut across the pre-given partition W. To this end, the algorithm interleaves an iterative computation of the stable-point equations, and the additional estimated parameters, for both functionals. Steps CP1, CP2 and CP6 correspond to the computations related to the IB functional, while steps CP3, CP4 and CP5, which compute a separate set of parameters (denoted by an asterisk), correspond to the ID functional. Figure 3 summarizes the roles of the two functionals in the dynamics of the CP algorithm. The two components of the iterative cycle are tied together in steps CP3 and CP6, in which parameters from one set are used as input to compute a parameter of other set. The derivation of step CP3 relies on an additional assumption, namely that C, Y and W are jointly independent given X. This assumption, which extends to W the underlying assumption of the IB setting that C and Y are independent given X, still entails the IB stable point equation. At convergence, the stable point equations for both the IB and ID functionals are satisfied, each by its own set of parameters (in steps CP1 and CP5). The deterministic annealing scheme, which gradually increases β over repeated runs (see Sec. 2), is applied for the CP algorithm as well with η held fixed. For a given target number of clusters |C|, the algorithm empirically converges with a wide range of η values 3. I(C;X) ↓ IB β↑ I(C;Y) ↓ ID η↑ I(C; W|Y) I(C; Y; W|X) = 0 ← assumptions → I(C;W) = 0 Figure 3: The interplay of the IB and the ID functionals in the CP algorithm. High η values tend to dictate centroids with features that are unevenly distributed across W, resulting in shrinkage of some of the clusters. Further analysis will be provided in future work. 3 4 Exp e ri men t a l Resu lt s Our synthetic setting consisted of 75 virtual elements, evenly pre-partitioned into three 25-element parts denoted X 1 , X2 and X3 (in our formalism, for each clustered element x, p(w|x) = 1 holds for either w = 1, 2, or 3). On top of this pre-partition, we partitioned the data twice, getting two (exhaustive) clustering configurations: 1. Target cross-W clustering: five clusters, each with representatives from all X w's; 2. Masking within-w clustering: six clusters, each consisting of roughly half the elements of either X 1, X 2 or X3 with no representatives from the other X w's. Each cluster, of both configurations, was characterized by a designated subset of features. Masking clusters were designed to be more salient than target clusters: they had more designated features (60 vs. 48 per cluster, i.e., 360 vs. 240 in total) and their elements shared higher feature-element (virtual) co-occurrence counts with those designated features (900 vs. 450 per element-feature pair). Noise (random positive integer < 200) was added to all counts associating elements with their designated features (for both within-w and cross-W clusters), as well as to roughly quarter of the zero counts associating elements with the rest of the features. The plain IB method consistently produced configurations strongly correlated with the masking clustering, while the CP algorithm revealed the target configuration. We got (see Table 1A) almost perfect results in configurations of nearly equal-sized cross-W clusters, and somewhat less perfect reconstruction in configurations of diverging sizes (6, 9, 15, 21 and 24). Performance level was measured relatively to optimal target-output cluster match by the proportion of elements correctly assigned, where assignment of an element x follows its highest p(c|x). The results indicated were averaged over 200 runs. They were obtained for the optimal η, which was found to be higher in the diverging-sizes task. In the text-based task, the clustered elements – keywords – were automatically extracted from five distinct corpora addressing five religions: introductory web pages, online magazines, encyclopedic entries etc., all downloaded from the Internet. The clustered keyword set X was consequently pre-partitioned to disjoint subsets {X w} w∈W, one for each religion4 (|X w| ≈ 200 for each w). We conducted experiments simultaneously involving religion pairs as well as all five religions. We took the features Y to be a set of words that commonly occur within all five corpora (|Y| ≈ 7000). x–y co-occurrences were recorded within ±5-word sliding window truncated by sentence boundaries. η was fixed to a value (1.0) enabling the formation of 20 clusters in all settings. The obtained clusters revealed interesting cross religion themes (see Sec. 1). For instance, the cluster (one of nine) capturing the theme of sacred festivals: the three highest p(c/x) members within each religion were Full-moon, Ceremony, Celebration (Buddhism); Easter, Sunday, Christmas Table 1: Average correct assignment proportion scores for the synthetic task (A) and Jaccard-coefficient scores for the religion keyword classification task (B). A. Synthetic Data IB CP B. Religion Data IB Coupled Clustering [7] CP (cross-expert agreement on religion pairs .462±.232) equal-size clusters .305 .985 non-equal clusters .292 .827 4 religion pairs all five (one case) .200±.100 .220±.138 .407±.144 .104 ––––––– .167 A keyword x that appeared in the corpora of different religions was considered as a distinct element for each religion, so the Xw were kept disjointed. (Chrsitianity); Puja, Ceremony, Festival (Hinduism); Id-al-Fitr, Friday, Ramadan, (Islam); and Sukkoth, Shavuot, Rosh-Hodesh (Judaism). The closest cluster produced by the plain IB method was poorer by far, including Islamic Ramadan, and Id and Jewish Passover, Rosh-Hashanah and Sabbath (which our method ranked high too), but no single related term from the other religions. Our external evaluation standards were cross-religion keyword classes constructed manually by experts of comparative religion studies. One such expert classification involved all five religions, and eight classifications addressed religions in pairs. Each of the eight religion-pair classifications was contributed by two independent experts using the same keywords, so we could also assess the agreement between experts. As an overlap measure we employed the Jaccard coefficient: the number of element pairs co-assigned together by both one of the evaluated clusters and one of the expert classes, divided by the number of pairs co-assigned by either our clusters or the expert (or both). We did not assume the number of expert classes is known in advance (as done in the synthetic experiments), so the results were averaged over all configurations of 2–16 cluster hierarchy, for each experiment. The results shown in Table 1B – clear improvement relatively to plain IB and the distance-based coupled clustering [7] – are, however, persistent when the number of clusters is taken to be equal to the number of classes, or if only the best score in hierarchy is considered. The level of cross-expert agreement indicates that our results are reasonably close to the scores expected in such subjective task. 5 C o mp a ri so n t o R e la t ed W o r k The information bottleneck framework served as the basis for several approaches that represent additional information in their clustering setting. The multivariate information bottleneck (MIB) adapts the IB framework for networks of multiple variables [3]. However, all variables in such networks are either compressed (like X), or predicted (like Y). The incorporation of an empirical variable to be masked or defocused in the sense of our W is not possible. Including such variables in the MIB framework might be explored in future work. Particularly relevant to our work is the IB-based method for extracting relevant constructs with side information [4]. This approach addresses settings in which two different types of features are distinguished explicitly: relevant versus irrelevant ones, denoted by Y+ and Y−. Both types of features are incorporated within a single functional to be minimized: L(IB-side-info) = I(C; X) − β ( I(C; Y +) − γ I(C; Y−) ), which directly drives clustering to de-correlate C and Y−. Formally, our setting can be mapped to the side information setting by regarding the pre-partition W simply as the additional set of irrelevant features, giving symmetric (and opposite) roles to W and Y. However, it seems that this view does not address properly the desired cross-partition setting. In our setting, it is assumed that clustering should be guided in general by Y, while W should only neutralize particular information within Y that would otherwise yield the undesired correlation between C and W (as described in Section 3.1). For that reason, the defocusing functional tie the three variables together by conditioning the de-correlation of C and W on Y, while its underlying assumption ensures the global de-correlation. Indeed, our method was found empirically superior on the cross-dataset task. The side-information IB method (the iterative algorithm with best scoring γ) achieves correct assignment proportion of 0.52 in both synthetic tasks, where our method scored 0.99 and 0.83 (see Table 1A) and, in the religion-pair keyword classification task, Jaccard coefficient improved by 20% relatively to plain IB (compared to our 100% improvement, see Table 1B). 6 C o n c lu si o n s This paper addressed the problem of clustering a pre-partitioned dataset, aiming to detect new internal structures that are not correlated with the pre-given partition but rather cut across its components. The proposed framework extends the cross-dataset clustering algorithm [8], providing better formal grounding and representing any pre-given (soft) partition of the dataset. Supported by empirical evidence, we suggest that our framework is better suited for the cross-partition task than applying the side-information framework [4], which was originally developed to address a somewhat different setting. We also demonstrate substantial empirical advantage over the distance-based coupled-clustering algorithm [7]. As an applied real-world goal, the algorithm successfully detects cross-religion commonalities. This goal exemplifies the more general notion of detecting analogies across different systems, which is a somewhat vague and non-consensual task and therefore especially challenging for a computational framework. Our approach can be viewed as an initial step towards principled identification of “hidden” commonalities between substantially different real world systems, while suppressing the vast majority of attributes that are irrelevant for the analogy. Further research may study the role of defocusing in supervised learning, where some pre-given partitions might mask the role of underlying discriminative features. Additionally, it would be interesting to explore relationships to other disciplines, e.g., network information theory ([9], Ch. 14) which provided motivation for the side-information approach. Finally, both frameworks (ours and side-information) suggest the importance of dealing wisely with information that should not dictate the clustering output directly. A c k n ow l e d g me n t s We thank Yuval Krymolowski for helpful discussions and Tiina Mahlamäki, Eitan Reich and William Shepard, for contributing the religion keyword classifications. References [1] Hofmann, T. (2001) Unsupervised learning by probabilistic latent semantic analysis. Journal of Machine Learning Research, 41(1):177-196. [2] Wagstaff K., Cardie C., Rogers S. and Schroedl S., 2001. Constrained K-Means clustering with background knowledge. The 18th International Conference on Machine Learning (ICML-2001), pp 577-584. [3] Friedman N., Mosenzon O., Slonim N. & Tishby N. (2002) Multivariate information bottleneck. The 17th conference on Uncertainty in Artificial Intelligence (UAI-17), pp. 152161. [4] Chechik G. & Tishby N. (2002) Extracting relevant structures with side information. Advances in Neural Processing Information Systems 15 (NIPS'02). [5] Globerson, A., Chechik G. & Tishby N. (2003) Sufficient dimensionality reduction. Journal of Machine Learning Research, 3:1307-1331. [6] Tishby, N., Pereira, F. C. & Bialek, W. (1999) The information bottleneck method. The 37th Annual Allerton Conference on Communication, Control, and Computing, pp. 368-379. [7] Marx, Z., Dagan, I., Buhmann, J. M. & Shamir E. (2002) Coupled clustering: A method for detecting structural correspondence. Journal of Machine Learning Research, 3:747-780. [8] Dagan, I., Marx, Z. & Shamir E (2002) Cross-dataset clustering: Revealing corresponding themes across multiple corpora. Proceedings of the 6th Conference on Natural Language Learning (CoNLL-2002), pp. 15-21. [9] Cover T. M. & Thomas J. A. (1991) Elements of Information Theory. Sons, Inc., New York, New York. John Wiley &</p><p>5 0.95273697 <a title="154-lda-5" href="./nips-2003-Towards_Social_Robots%3A_Automatic_Evaluation_of_Human-Robot_Interaction_by_Facial_Expression_Classification.html">186 nips-2003-Towards Social Robots: Automatic Evaluation of Human-Robot Interaction by Facial Expression Classification</a></p>
<p>Author: G.C. Littlewort, M.S. Bartlett, I.R. Fasel, J. Chenu, T. Kanda, H. Ishiguro, J.R. Movellan</p><p>Abstract: Computer animated agents and robots bring a social dimension to human computer interaction and force us to think in new ways about how computers could be used in daily life. Face to face communication is a real-time process operating at a time scale of less than a second. In this paper we present progress on a perceptual primitive to automatically detect frontal faces in the video stream and code them with respect to 7 dimensions in real time: neutral, anger, disgust, fear, joy, sadness, surprise. The face ﬁnder employs a cascade of feature detectors trained with boosting techniques [13, 2]. The expression recognizer employs a novel combination of Adaboost and SVM’s. The generalization performance to new subjects for a 7-way forced choice was 93.3% and 97% correct on two publicly available datasets. The outputs of the classiﬁer change smoothly as a function of time, providing a potentially valuable representation to code facial expression dynamics in a fully automatic and unobtrusive manner. The system was deployed and evaluated for measuring spontaneous facial expressions in the ﬁeld in an application for automatic assessment of human-robot interaction.</p><p>6 0.92926711 <a title="154-lda-6" href="./nips-2003-Clustering_with_the_Connectivity_Kernel.html">46 nips-2003-Clustering with the Connectivity Kernel</a></p>
<p>7 0.78679454 <a title="154-lda-7" href="./nips-2003-An_MDP-Based_Approach_to_Online_Mechanism_Design.html">26 nips-2003-An MDP-Based Approach to Online Mechanism Design</a></p>
<p>8 0.74987429 <a title="154-lda-8" href="./nips-2003-Extending_Q-Learning_to_General_Adaptive_Multi-Agent_Systems.html">65 nips-2003-Extending Q-Learning to General Adaptive Multi-Agent Systems</a></p>
<p>9 0.71758175 <a title="154-lda-9" href="./nips-2003-A_Biologically_Plausible_Algorithm_for_Reinforcement-shaped_Representational_Learning.html">4 nips-2003-A Biologically Plausible Algorithm for Reinforcement-shaped Representational Learning</a></p>
<p>10 0.70367354 <a title="154-lda-10" href="./nips-2003-How_to_Combine_Expert_%28and_Novice%29_Advice_when_Actions_Impact_the_Environment%3F.html">84 nips-2003-How to Combine Expert (and Novice) Advice when Actions Impact the Environment?</a></p>
<p>11 0.7032277 <a title="154-lda-11" href="./nips-2003-Eye_Movements_for_Reward_Maximization.html">68 nips-2003-Eye Movements for Reward Maximization</a></p>
<p>12 0.68962789 <a title="154-lda-12" href="./nips-2003-Bounded_Invariance_and_the_Formation_of_Place_Fields.html">43 nips-2003-Bounded Invariance and the Formation of Place Fields</a></p>
<p>13 0.68419647 <a title="154-lda-13" href="./nips-2003-A_Nonlinear_Predictive_State_Representation.html">14 nips-2003-A Nonlinear Predictive State Representation</a></p>
<p>14 0.66875273 <a title="154-lda-14" href="./nips-2003-Algorithms_for_Interdependent_Security_Games.html">19 nips-2003-Algorithms for Interdependent Security Games</a></p>
<p>15 0.66830891 <a title="154-lda-15" href="./nips-2003-Distributed_Optimization_in_Adaptive_Networks.html">55 nips-2003-Distributed Optimization in Adaptive Networks</a></p>
<p>16 0.66782063 <a title="154-lda-16" href="./nips-2003-Feature_Selection_in_Clustering_Problems.html">73 nips-2003-Feature Selection in Clustering Problems</a></p>
<p>17 0.65301114 <a title="154-lda-17" href="./nips-2003-Gene_Expression_Clustering_with_Functional_Mixture_Models.html">79 nips-2003-Gene Expression Clustering with Functional Mixture Models</a></p>
<p>18 0.64638352 <a title="154-lda-18" href="./nips-2003-Learning_Spectral_Clustering.html">107 nips-2003-Learning Spectral Clustering</a></p>
<p>19 0.64234203 <a title="154-lda-19" href="./nips-2003-All_learning_is_Local%3A_Multi-agent_Learning_in_Global_Reward_Games.html">20 nips-2003-All learning is Local: Multi-agent Learning in Global Reward Games</a></p>
<p>20 0.64080524 <a title="154-lda-20" href="./nips-2003-Dynamical_Modeling_with_Kernels_for_Nonlinear_Time_Series_Prediction.html">57 nips-2003-Dynamical Modeling with Kernels for Nonlinear Time Series Prediction</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
