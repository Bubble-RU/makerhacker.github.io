<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>28 nips-2003-Application of SVMs for Colour Classification and Collision Detection with AIBO Robots</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2003" href="../home/nips2003_home.html">nips2003</a> <a title="nips-2003-28" href="#">nips2003-28</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>28 nips-2003-Application of SVMs for Colour Classification and Collision Detection with AIBO Robots</h1>
<br/><p>Source: <a title="nips-2003-28-pdf" href="http://papers.nips.cc/paper/2487-application-of-svms-for-colour-classification-and-collision-detection-with-aibo-robots.pdf">pdf</a></p><p>Author: Michael J. Quinlan, Stephan K. Chalup, Richard H. Middleton</p><p>Abstract: This article addresses the issues of colour classiﬁcation and collision detection as they occur in the legged league robot soccer environment of RoboCup. We show how the method of one-class classiﬁcation with support vector machines (SVMs) can be applied to solve these tasks satisfactorily using the limited hardware capacity of the prescribed Sony AIBO quadruped robots. The experimental evaluation shows an improvement over our previous methods of ellipse ﬁtting for colour classiﬁcation and the statistical approach used for collision detection.</p><p>Reference: <a title="nips-2003-28-reference" href="../nips2003_reference/nips-2003-Application_of_SVMs_for_Colour_Classification_and_Collision_Detection_with_AIBO_Robots_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 au  Abstract This article addresses the issues of colour classiﬁcation and collision detection as they occur in the legged league robot soccer environment of RoboCup. [sent-7, score-1.624]
</p><p>2 We show how the method of one-class classiﬁcation with support vector machines (SVMs) can be applied to solve these tasks satisfactorily using the limited hardware capacity of the prescribed Sony AIBO quadruped robots. [sent-8, score-0.188]
</p><p>3 The experimental evaluation shows an improvement over our previous methods of ellipse ﬁtting for colour classiﬁcation and the statistical approach used for collision detection. [sent-9, score-0.947]
</p><p>4 However, training-time requirements of sophisticated machine learning algorithms can overstrain the hardware of real world robots. [sent-11, score-0.11]
</p><p>5 Application of the latter was often restricted to simulations which sometimes could support training or tuning of the real world robot parameters. [sent-13, score-0.277]
</p><p>6 However, often the gap between simulation and the real world was too wide so that a transfer of training results from the simulated to the real robot turned out to be useless. [sent-14, score-0.238]
</p><p>7 A few years ago it may have been regarded as infeasible to consider the use of support vector machines [1, 2, 3] on real world robots with restricted processing capabilities. [sent-15, score-0.269]
</p><p>8 During the ﬁrst years after their invention support vector machines had the reputation to be more a theoretical concept than a method which could be efﬁciently applied in real world situations. [sent-16, score-0.166]
</p><p>9 In recent years it has become possible to speed up optimisations for SVMs in various ways [4]. [sent-18, score-0.059]
</p><p>10 With the present study we explore the feasibility and usefulness of one-class SVM classiﬁcation [5] for tasks faced by AIBO robots within the legged league environment of RoboCup [6]. [sent-20, score-0.465]
</p><p>11 We focus on two particularly critical issues: detection of objects based on ∗  http://www. [sent-21, score-0.129]
</p><p>12 au  correct colour classiﬁcation and detection of robot-to-robot collisions. [sent-25, score-0.711]
</p><p>13 Both issues seemed not to be sufﬁciently solved and implemented by the teams of RoboCup2002 and caused signiﬁcant deterioration in the quality of play even in the world-best teams of that league. [sent-26, score-0.15]
</p><p>14 The article has ﬁve more sections addressing the environment and tasks, the methods, followed by the experiments and applications for colour classiﬁcation and collision detection, respectively. [sent-27, score-1.037]
</p><p>15 A soccer team in the legged league consists of four robots, including one goal keeper. [sent-30, score-0.403]
</p><p>16 Each team is identiﬁed by robots wearing either a red or blue coloured ‘uniform’. [sent-31, score-0.133]
</p><p>17 The soccer matches take place on a green enclosed carpeted ﬁeld with white boundaries. [sent-32, score-0.109]
</p><p>18 To aid localisation six beacons are placed regularly around the ﬁeld, each uniquely identiﬁable by a speciﬁc colour pattern. [sent-34, score-0.582]
</p><p>19 The ball used is orange plastic and of a suitable size to be easily moved around by the robots. [sent-35, score-0.123]
</p><p>20 The legged league of RoboCup 2003 prescribed the use of Sony AIBO entertainment robots, models ERS-210 or the newer ERS-210A. [sent-37, score-0.335]
</p><p>21 The robots are programmed in a C++ software environment using the Sony’s OPEN-R software development kit [7]. [sent-39, score-0.178]
</p><p>22 They have 16MB of memory accessible by user programs. [sent-40, score-0.06]
</p><p>23 The dimensions of the robot (width × height × length) are 154 mm × 266 mm × 274 mm (not including the tail and ears) and the mass is approximately 1. [sent-41, score-0.226]
</p><p>24 The AIBO has 20 degrees of freedom (DOF): neck 3DOF (pan, tilt, and roll), ear 1DOF x 2, chin 1DOF, legs 3DOF (abductor, rotator, knee) x 4 and tail 2DOF (up-down, left-right). [sent-43, score-0.073]
</p><p>25 Among other sensors the AIBO has a 1/6 inch colour CMOS camera capable of 25 frames per seconds. [sent-44, score-0.688]
</p><p>26 Additionally, the camera has a ﬁeld of vision of 23. [sent-49, score-0.108]
</p><p>27 To help achieve results in different lighting conditions the camera allows the modiﬁcation of parameters: White balance, Shutter Speed and Gain. [sent-52, score-0.102]
</p><p>28 1 Colour classiﬁcation task The vision system for most teams consists of four main tasks, Colour Classiﬁcation, Run Length Encoding, Blob Formation and Object Recognition (Figure 1). [sent-54, score-0.097]
</p><p>29 The classiﬁcation process takes the image from the camera in a YUV bitmap format [8]. [sent-55, score-0.112]
</p><p>30 Each pixel in the image is assigned a colour label (i. [sent-56, score-0.62]
</p><p>31 A lookup table (LUT) is used to determine which YUV values correspond to which colour labels. [sent-60, score-0.65]
</p><p>32 The critical point is the initial generation of the LUT. [sent-61, score-0.052]
</p><p>33 Since the robot is extremely reliant on colour for object detection a new LUT has to be generated with any change in lighting conditions. [sent-62, score-0.877]
</p><p>34 Currently this is a manual task which requires a human to take hundreds of images and assign a colour label on a pixel-by-pixel basis. [sent-63, score-0.657]
</p><p>35 Using this method each LUT can take hours to create, yet it will still contain holes and classiﬁcation errors. [sent-64, score-0.084]
</p><p>36 2 Collision detection task The goal is to detect collisions using the limited sensors provided by the AIBO robot. [sent-66, score-0.211]
</p><p>37 The camera and infrared distance sensor on the AIBO don’t provide enough support in avoiding obstacles unless the speed of the robot is dramatically decreased. [sent-67, score-0.235]
</p><p>38 the angle of the joint) as the input to our collision detection system [10]. [sent-70, score-0.494]
</p><p>39 The parameter ν approximates the fraction of outliers and support vectors [5]. [sent-81, score-0.104]
</p><p>40 1 Method for colour classiﬁcation The classiﬁcation functions we seek take data that has been manually clustered to produce sets X k = xk ∈ R3 ; i = 1, . [sent-83, score-0.612]
</p><p>41 , Nk of colour space data for each object colour k. [sent-86, score-1.187]
</p><p>42 Each i  X k corresponds to sets of colour values in the YUV space corresponding to one of the known colour labels. [sent-87, score-1.164]
</p><p>43 By training with an extremely low ν and a large γ the boundary formed by the decision function approximates the region that contains the majority (1-ν) of the points in X k . [sent-89, score-0.104]
</p><p>44 In addition the SVM has the advantage of simultaneously removing the outliers that occur during manual classiﬁcation. [sent-90, score-0.111]
</p><p>45 The new colour set is constructed by attempting to classify every point in the YUV space (643 elements). [sent-91, score-0.582]
</p><p>46 All points that return a value of +1 are inside the region and therefore deemed to be of colour k. [sent-92, score-0.655]
</p><p>47 To avoid misclassiﬁcation each point in YUV space that does not strongly correspond to one of the known colours must remain classiﬁed as unknown. [sent-94, score-0.063]
</p><p>48 In addition the colours were originally selected because they are located in different areas of the YUV space. [sent-95, score-0.063]
</p><p>49 Because of this we can choose to treat each colour without regard to the location and shape of the other colours. [sent-96, score-0.624]
</p><p>50 2 Method for collision detection For collision detection the one-class SVM is employed as a novelty detection mechanism. [sent-99, score-1.117]
</p><p>51 These include ﬁve walk parameters, stepFrequency, backStrideLength, turn, strafe and timeParameter along with a sensor reading from the abductor and rotator joints on each of the four legs. [sent-101, score-0.115]
</p><p>52 For this reason a collision detection system must attempt to minimise the generation of false-positives (detecting a collision that we deemed not to have happened) while still ﬁnding a high percentage of actual collisions. [sent-104, score-0.934]
</p><p>53 Low false-positives are achieved by keeping the kernel parameter γ high but this has the side effect of lowering the generalisation to the data set, which results in the need for an increased number of training points. [sent-105, score-0.085]
</p><p>54 In a real world robotic system the need for more training points greatly increases the training time and in-turn the wear on the machinery. [sent-106, score-0.201]
</p><p>55 4 Experiments and application to colour classiﬁcation The SVM can be used in two situations during the colour classiﬁcation procedure. [sent-107, score-1.164]
</p><p>56 By lowering γ while the number of training points is low, a rough estimation of the ﬁnal shape can be obtained. [sent-109, score-0.15]
</p><p>57 By continuing the manual classiﬁcation and increasing γ a closer approximation to the area containing the training data is obtained. [sent-110, score-0.099]
</p><p>58 Of critical importance is testing the locomotion engine on the new carpet and in particular ball chasing. [sent-114, score-0.123]
</p><p>59 The task of ball chasing relies on the classiﬁcation of ball orange. [sent-115, score-0.188]
</p><p>60 By manually classifying a few images of the ball and then training the SVM with γ < 0, a sphere containing  all possible values for the ball is generated. [sent-117, score-0.256]
</p><p>61 Either all colours in the table can be trained (i. [sent-119, score-0.095]
</p><p>62 updating of an old table) or an individual colour is trained due to an initial classiﬁcation error. [sent-121, score-0.609]
</p><p>63 This procedure can be performed either on the robot or a remote computer. [sent-122, score-0.086]
</p><p>64 The initial table contained 3329 entries while after training the table contained 6989 entries. [sent-125, score-0.203]
</p><p>65 The most evident change can be seen in the classiﬁcation of colour white, see Figure 2. [sent-126, score-0.613]
</p><p>66 The LUTs were compared over 60 images, which equates to 1,520,640 individual pixel comparisons. [sent-127, score-0.063]
</p><p>67 The new LUT produced 117,652 errors, this equates to an 18% reduction in errors. [sent-129, score-0.063]
</p><p>68 Figure 2: Image Comparison: The left image is classiﬁed with the original LUT and the image on the right is the using the updated LUT. [sent-130, score-0.076]
</p><p>69 Nk  Note that minimising the trace of Q (tr(Q)) is the same as minimising the sum of the diagonal elements of Q which is the same as minimising the sum of the squares of the  lengths of the principal axes of the ellipsoid. [sent-136, score-0.186]
</p><p>70 The ellipsoidal shape deﬁned in (2) has the disadvantage of restricting the shape of possible regions in the colour space. [sent-137, score-0.666]
</p><p>71 Before the ellipsoid can be ﬁtted, potential outliers and duplicate points were identiﬁed and removed. [sent-139, score-0.256]
</p><p>72 The removal of outliers is important in avoiding too large a region. [sent-140, score-0.064]
</p><p>73 Figure 3 shows the effects of each method on the colour white. [sent-143, score-0.582]
</p><p>74 To make the comparison with ellipsoids, the initial LUT and the generated LUT from the SVM procedure are shown in the HSI colour space. [sent-144, score-0.609]
</p><p>75 Figure 3: Colour classiﬁcation in HSI colour space: A) Points manually classiﬁed at white. [sent-145, score-0.612]
</p><p>76 It is evident that the manual classiﬁcation of white is rather incomplete and contains many holes that should be classiﬁed as white. [sent-151, score-0.216]
</p><p>77 The negative results of these holes can be seen as noise in the left image of Figure 2. [sent-152, score-0.122]
</p><p>78 Using the ellipsoid ﬁtting method these holes are ﬁlled but with the potential drawback of over classiﬁcation. [sent-153, score-0.217]
</p><p>79 From image B in Figure 3 it is evident that the top section and the bottom left of the ellipsoid contain no white entries and therefore it is highly questionable that this area should be classiﬁed as white. [sent-154, score-0.256]
</p><p>80 It is clear from image D that the area now classiﬁed as white is a region that tightly ﬁts the original training set. [sent-156, score-0.144]
</p><p>81 5 Experiments and application to collision detection The collision detection system is designed with the aim that the entire system can be run on the robot. [sent-157, score-0.988]
</p><p>82 This means adhering to the memory and processing capabilities of the device. [sent-158, score-0.06]
</p><p>83 On the AIBO we have a maximum of 8MB memory available for collision detection, a total of  20,000 training points. [sent-159, score-0.477]
</p><p>84 This is the equivalent of 1000 steps which equates to approximately 10 minutes of training time. [sent-160, score-0.115]
</p><p>85 The training set is generated by having the robot behave normally on the ﬁeld but with the stipulation that all collisions are avoided. [sent-161, score-0.188]
</p><p>86 If more than 2 points in one sample are classiﬁed as -1 a collision is declared to be detected. [sent-163, score-0.388]
</p><p>87 05 and γ = 5 were chosen, this was based on the assumption that a collision point would lie considerably outside the training set. [sent-165, score-0.417]
</p><p>88 The solution to this problem could involve increasing ν due to the possibility that the initial training set contained many outliers and/or increasing γ to improve the tightness of the classiﬁcation. [sent-169, score-0.173]
</p><p>89 In our system these parameters appear to give the best balance between minimising false-positives and maximising correct detection of collisions. [sent-172, score-0.191]
</p><p>90 1 Comparison with the previous statistical method The previous method, described in [10], for collision detection involves observing a joint position substantially differing from its expected value. [sent-174, score-0.494]
</p><p>91 Initially we would have considered a collision to have occurred if a single error is found, but further investigation has shown that ﬁnding multiple errors (in most cases three) in quick succession is necessary to warrant a warning that can be acted upon by the robot’s behaviour system. [sent-176, score-0.365]
</p><p>92 Figure 4: Rear Rotators for a forwards walking boundary collision on both front legs, front right leg hitting ﬁrst. [sent-177, score-0.365]
</p><p>93 In addition it required considerable storage space to hold the table of means and standard deviations for each parameter combination. [sent-181, score-0.061]
</p><p>94 The previous statistical method had the advantage of extremely low computational expense, in fact it was a table look up. [sent-182, score-0.061]
</p><p>95 The trade-off is increased space, this method required the allocation of approximately 6MB of memory during both the training and detection stages. [sent-183, score-0.241]
</p><p>96 Conversely the SVM approach requires only about 1MB of memory during the detection phase, but this comes at the side effect of increased computation. [sent-184, score-0.189]
</p><p>97 Since the SVM approach was capable of running without reducing the frame rate, the extra memory could now be used for other applications. [sent-185, score-0.06]
</p><p>98 6 Summary The method of one-class classiﬁcation with SVMs was successfully applied to the tasks of colour classiﬁcation and collision detection using the restricted memory and processing power of the AIBO hardware. [sent-191, score-1.203]
</p><p>99 In a comparison with previously used methods the SVM based methods generated better results, and in the case of colour classiﬁcation the SVM approach was more efﬁcient and convenient. [sent-193, score-0.582]
</p><p>100 Acknowledgments We would like to thank William McMahan and Jared Bunting for their work on the previous vision classiﬁcation method and Craig Murch for his extensive contributions to both the vision and locomotion systems. [sent-194, score-0.118]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('colour', 0.582), ('collision', 0.365), ('lut', 0.231), ('aibo', 0.21), ('yuv', 0.21), ('league', 0.147), ('legged', 0.146), ('classi', 0.139), ('ellipsoid', 0.133), ('svm', 0.133), ('detection', 0.129), ('robocup', 0.126), ('robot', 0.086), ('holes', 0.084), ('robots', 0.078), ('camera', 0.074), ('ball', 0.073), ('quinlan', 0.073), ('cation', 0.07), ('outliers', 0.064), ('svms', 0.064), ('colours', 0.063), ('equates', 0.063), ('hsi', 0.063), ('middleton', 0.063), ('murch', 0.063), ('nubots', 0.063), ('teams', 0.063), ('minimising', 0.062), ('memory', 0.06), ('team', 0.055), ('soccer', 0.055), ('sony', 0.055), ('white', 0.054), ('environment', 0.052), ('training', 0.052), ('collisions', 0.05), ('deemed', 0.05), ('locomotion', 0.05), ('orange', 0.05), ('world', 0.048), ('manual', 0.047), ('libsvm', 0.046), ('legs', 0.044), ('tasks', 0.042), ('abductor', 0.042), ('bunting', 0.042), ('chalup', 0.042), ('chasing', 0.042), ('newcastle', 0.042), ('rotator', 0.042), ('stephan', 0.042), ('shape', 0.042), ('prescribed', 0.042), ('support', 0.04), ('article', 0.038), ('image', 0.038), ('mm', 0.037), ('mcmahan', 0.036), ('blob', 0.036), ('duplicate', 0.036), ('lookup', 0.036), ('hardware', 0.036), ('speed', 0.035), ('vision', 0.034), ('lmi', 0.033), ('lowering', 0.033), ('sensors', 0.032), ('table', 0.032), ('pixels', 0.032), ('evident', 0.031), ('joints', 0.031), ('contained', 0.03), ('manually', 0.03), ('tting', 0.03), ('tail', 0.029), ('deviations', 0.029), ('extremely', 0.029), ('machines', 0.028), ('lighting', 0.028), ('images', 0.028), ('xi', 0.027), ('initial', 0.027), ('richard', 0.027), ('craig', 0.027), ('library', 0.027), ('real', 0.026), ('qt', 0.025), ('generation', 0.025), ('restricted', 0.025), ('cmos', 0.025), ('formation', 0.025), ('http', 0.024), ('software', 0.024), ('years', 0.024), ('issues', 0.024), ('lkopf', 0.024), ('points', 0.023), ('michael', 0.023), ('object', 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="28-tfidf-1" href="./nips-2003-Application_of_SVMs_for_Colour_Classification_and_Collision_Detection_with_AIBO_Robots.html">28 nips-2003-Application of SVMs for Colour Classification and Collision Detection with AIBO Robots</a></p>
<p>Author: Michael J. Quinlan, Stephan K. Chalup, Richard H. Middleton</p><p>Abstract: This article addresses the issues of colour classiﬁcation and collision detection as they occur in the legged league robot soccer environment of RoboCup. We show how the method of one-class classiﬁcation with support vector machines (SVMs) can be applied to solve these tasks satisfactorily using the limited hardware capacity of the prescribed Sony AIBO quadruped robots. The experimental evaluation shows an improvement over our previous methods of ellipse ﬁtting for colour classiﬁcation and the statistical approach used for collision detection.</p><p>2 0.10419355 <a title="28-tfidf-2" href="./nips-2003-A_Low-Power_Analog_VLSI_Visual_Collision_Detector.html">10 nips-2003-A Low-Power Analog VLSI Visual Collision Detector</a></p>
<p>Author: Reid R. Harrison</p><p>Abstract: We have designed and tested a single-chip analog VLSI sensor that detects imminent collisions by measuring radially expansive optic flow. The design of the chip is based on a model proposed to explain leg-extension behavior in flies during landing approaches. A new elementary motion detector (EMD) circuit was developed to measure optic flow. This EMD circuit models the bandpass nature of large monopolar cells (LMCs) immediately postsynaptic to photoreceptors in the fly visual system. A 16 × 16 array of 2-D motion detectors was fabricated on a 2.24 mm × 2.24 mm die in a standard 0.5-µm CMOS process. The chip consumes 140 µW of power from a 5 V supply. With the addition of wide-angle optics, the sensor is able to detect collisions around 500 ms before impact in complex, real-world scenes. 1</p><p>3 0.097732931 <a title="28-tfidf-3" href="./nips-2003-1-norm_Support_Vector_Machines.html">1 nips-2003-1-norm Support Vector Machines</a></p>
<p>Author: Ji Zhu, Saharon Rosset, Robert Tibshirani, Trevor J. Hastie</p><p>Abstract: The standard 2-norm SVM is known for its good performance in twoclass classi£cation. In this paper, we consider the 1-norm SVM. We argue that the 1-norm SVM may have some advantage over the standard 2-norm SVM, especially when there are redundant noise features. We also propose an ef£cient algorithm that computes the whole solution path of the 1-norm SVM, hence facilitates adaptive selection of the tuning parameter for the 1-norm SVM. 1</p><p>4 0.092926502 <a title="28-tfidf-4" href="./nips-2003-A_Kullback-Leibler_Divergence_Based_Kernel_for_SVM_Classification_in_Multimedia_Applications.html">9 nips-2003-A Kullback-Leibler Divergence Based Kernel for SVM Classification in Multimedia Applications</a></p>
<p>Author: Pedro J. Moreno, Purdy P. Ho, Nuno Vasconcelos</p><p>Abstract: Over the last years signiﬁcant efforts have been made to develop kernels that can be applied to sequence data such as DNA, text, speech, video and images. The Fisher Kernel and similar variants have been suggested as good ways to combine an underlying generative model in the feature space and discriminant classiﬁers such as SVM’s. In this paper we suggest an alternative procedure to the Fisher kernel for systematically ﬁnding kernel functions that naturally handle variable length sequence data in multimedia domains. In particular for domains such as speech and images we explore the use of kernel functions that take full advantage of well known probabilistic models such as Gaussian Mixtures and single full covariance Gaussian models. We derive a kernel distance based on the Kullback-Leibler (KL) divergence between generative models. In effect our approach combines the best of both generative and discriminative methods and replaces the standard SVM kernels. We perform experiments on speaker identiﬁcation/veriﬁcation and image classiﬁcation tasks and show that these new kernels have the best performance in speaker veriﬁcation and mostly outperform the Fisher kernel based SVM’s and the generative classiﬁers in speaker identiﬁcation and image classiﬁcation. 1</p><p>5 0.087600589 <a title="28-tfidf-5" href="./nips-2003-Learning_a_Rare_Event_Detection_Cascade_by_Direct_Feature_Selection.html">109 nips-2003-Learning a Rare Event Detection Cascade by Direct Feature Selection</a></p>
<p>Author: Jianxin Wu, James M. Rehg, Matthew D. Mullin</p><p>Abstract: Face detection is a canonical example of a rare event detection problem, in which target patterns occur with much lower frequency than nontargets. Out of millions of face-sized windows in an input image, for example, only a few will typically contain a face. Viola and Jones recently proposed a cascade architecture for face detection which successfully addresses the rare event nature of the task. A central part of their method is a feature selection algorithm based on AdaBoost. We present a novel cascade learning algorithm based on forward feature selection which is two orders of magnitude faster than the Viola-Jones approach and yields classiﬁers of equivalent quality. This faster method could be used for more demanding classiﬁcation tasks, such as on-line learning. 1</p><p>6 0.079203203 <a title="28-tfidf-6" href="./nips-2003-Bayesian_Color_Constancy_with_Non-Gaussian_Models.html">39 nips-2003-Bayesian Color Constancy with Non-Gaussian Models</a></p>
<p>7 0.078739144 <a title="28-tfidf-7" href="./nips-2003-Towards_Social_Robots%3A_Automatic_Evaluation_of_Human-Robot_Interaction_by_Facial_Expression_Classification.html">186 nips-2003-Towards Social Robots: Automatic Evaluation of Human-Robot Interaction by Facial Expression Classification</a></p>
<p>8 0.077439226 <a title="28-tfidf-8" href="./nips-2003-Learning_with_Local_and_Global_Consistency.html">113 nips-2003-Learning with Local and Global Consistency</a></p>
<p>9 0.070696846 <a title="28-tfidf-9" href="./nips-2003-Auction_Mechanism_Design_for_Multi-Robot_Coordination.html">36 nips-2003-Auction Mechanism Design for Multi-Robot Coordination</a></p>
<p>10 0.070094042 <a title="28-tfidf-10" href="./nips-2003-Insights_from_Machine_Learning_Applied_to_Human_Visual_Classification.html">95 nips-2003-Insights from Machine Learning Applied to Human Visual Classification</a></p>
<p>11 0.068773217 <a title="28-tfidf-11" href="./nips-2003-Mutual_Boosting_for_Contextual_Inference.html">133 nips-2003-Mutual Boosting for Contextual Inference</a></p>
<p>12 0.065103747 <a title="28-tfidf-12" href="./nips-2003-Discriminating_Deformable_Shape_Classes.html">53 nips-2003-Discriminating Deformable Shape Classes</a></p>
<p>13 0.063379169 <a title="28-tfidf-13" href="./nips-2003-New_Algorithms_for_Efficient_High_Dimensional_Non-parametric_Classification.html">136 nips-2003-New Algorithms for Efficient High Dimensional Non-parametric Classification</a></p>
<p>14 0.058950625 <a title="28-tfidf-14" href="./nips-2003-Invariant_Pattern_Recognition_by_Semi-Definite_Programming_Machines.html">96 nips-2003-Invariant Pattern Recognition by Semi-Definite Programming Machines</a></p>
<p>15 0.057878364 <a title="28-tfidf-15" href="./nips-2003-Using_the_Forest_to_See_the_Trees%3A_A_Graphical_Model_Relating_Features%2C_Objects%2C_and_Scenes.html">192 nips-2003-Using the Forest to See the Trees: A Graphical Model Relating Features, Objects, and Scenes</a></p>
<p>16 0.055103518 <a title="28-tfidf-16" href="./nips-2003-Prediction_on_Spike_Data_Using_Kernel_Algorithms.html">160 nips-2003-Prediction on Spike Data Using Kernel Algorithms</a></p>
<p>17 0.053667471 <a title="28-tfidf-17" href="./nips-2003-Max-Margin_Markov_Networks.html">124 nips-2003-Max-Margin Markov Networks</a></p>
<p>18 0.051671378 <a title="28-tfidf-18" href="./nips-2003-Factorization_with_Uncertainty_and_Missing_Data%3A_Exploiting_Temporal_Coherence.html">69 nips-2003-Factorization with Uncertainty and Missing Data: Exploiting Temporal Coherence</a></p>
<p>19 0.05051659 <a title="28-tfidf-19" href="./nips-2003-Nonlinear_Filtering_of_Electron_Micrographs_by_Means_of_Support_Vector_Regression.html">139 nips-2003-Nonlinear Filtering of Electron Micrographs by Means of Support Vector Regression</a></p>
<p>20 0.048626456 <a title="28-tfidf-20" href="./nips-2003-Image_Reconstruction_by_Linear_Programming.html">88 nips-2003-Image Reconstruction by Linear Programming</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2003_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.169), (1, -0.024), (2, 0.036), (3, -0.134), (4, -0.09), (5, -0.097), (6, -0.061), (7, -0.068), (8, 0.021), (9, 0.026), (10, 0.026), (11, 0.003), (12, -0.097), (13, 0.049), (14, 0.056), (15, 0.019), (16, 0.021), (17, 0.035), (18, 0.013), (19, -0.0), (20, 0.167), (21, -0.076), (22, 0.009), (23, 0.005), (24, 0.05), (25, 0.016), (26, 0.041), (27, 0.117), (28, 0.003), (29, 0.072), (30, 0.022), (31, -0.026), (32, -0.016), (33, 0.037), (34, 0.15), (35, 0.038), (36, -0.101), (37, -0.001), (38, 0.031), (39, 0.078), (40, -0.045), (41, 0.086), (42, 0.069), (43, -0.016), (44, 0.151), (45, 0.096), (46, -0.039), (47, -0.016), (48, -0.064), (49, 0.074)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92111593 <a title="28-lsi-1" href="./nips-2003-Application_of_SVMs_for_Colour_Classification_and_Collision_Detection_with_AIBO_Robots.html">28 nips-2003-Application of SVMs for Colour Classification and Collision Detection with AIBO Robots</a></p>
<p>Author: Michael J. Quinlan, Stephan K. Chalup, Richard H. Middleton</p><p>Abstract: This article addresses the issues of colour classiﬁcation and collision detection as they occur in the legged league robot soccer environment of RoboCup. We show how the method of one-class classiﬁcation with support vector machines (SVMs) can be applied to solve these tasks satisfactorily using the limited hardware capacity of the prescribed Sony AIBO quadruped robots. The experimental evaluation shows an improvement over our previous methods of ellipse ﬁtting for colour classiﬁcation and the statistical approach used for collision detection.</p><p>2 0.56053007 <a title="28-lsi-2" href="./nips-2003-Discriminating_Deformable_Shape_Classes.html">53 nips-2003-Discriminating Deformable Shape Classes</a></p>
<p>Author: Salvador Ruiz-correa, Linda G. Shapiro, Marina Meila, Gabriel Berson</p><p>Abstract: We present and empirically test a novel approach for categorizing 3-D free form object shapes represented by range data . In contrast to traditional surface-signature based systems that use alignment to match speciﬁc objects, we adapted the newly introduced symbolic-signature representation to classify deformable shapes [10]. Our approach constructs an abstract description of shape classes using an ensemble of classiﬁers that learn object class parts and their corresponding geometrical relationships from a set of numeric and symbolic descriptors. We used our classiﬁcation engine in a series of large scale discrimination experiments on two well-deﬁned classes that share many common distinctive features. The experimental results suggest that our method outperforms traditional numeric signature-based methodologies. 1 1</p><p>3 0.55778146 <a title="28-lsi-3" href="./nips-2003-A_Kullback-Leibler_Divergence_Based_Kernel_for_SVM_Classification_in_Multimedia_Applications.html">9 nips-2003-A Kullback-Leibler Divergence Based Kernel for SVM Classification in Multimedia Applications</a></p>
<p>Author: Pedro J. Moreno, Purdy P. Ho, Nuno Vasconcelos</p><p>Abstract: Over the last years signiﬁcant efforts have been made to develop kernels that can be applied to sequence data such as DNA, text, speech, video and images. The Fisher Kernel and similar variants have been suggested as good ways to combine an underlying generative model in the feature space and discriminant classiﬁers such as SVM’s. In this paper we suggest an alternative procedure to the Fisher kernel for systematically ﬁnding kernel functions that naturally handle variable length sequence data in multimedia domains. In particular for domains such as speech and images we explore the use of kernel functions that take full advantage of well known probabilistic models such as Gaussian Mixtures and single full covariance Gaussian models. We derive a kernel distance based on the Kullback-Leibler (KL) divergence between generative models. In effect our approach combines the best of both generative and discriminative methods and replaces the standard SVM kernels. We perform experiments on speaker identiﬁcation/veriﬁcation and image classiﬁcation tasks and show that these new kernels have the best performance in speaker veriﬁcation and mostly outperform the Fisher kernel based SVM’s and the generative classiﬁers in speaker identiﬁcation and image classiﬁcation. 1</p><p>4 0.53948653 <a title="28-lsi-4" href="./nips-2003-Statistical_Debugging_of_Sampled_Programs.html">181 nips-2003-Statistical Debugging of Sampled Programs</a></p>
<p>Author: Alice X. Zheng, Michael I. Jordan, Ben Liblit, Alex Aiken</p><p>Abstract: We present a novel strategy for automatically debugging programs given sampled data from thousands of actual user runs. Our goal is to pinpoint those features that are most correlated with crashes. This is accomplished by maximizing an appropriately deﬁned utility function. It has analogies with intuitive debugging heuristics, and, as we demonstrate, is able to deal with various types of bugs that occur in real programs. 1</p><p>5 0.52207583 <a title="28-lsi-5" href="./nips-2003-New_Algorithms_for_Efficient_High_Dimensional_Non-parametric_Classification.html">136 nips-2003-New Algorithms for Efficient High Dimensional Non-parametric Classification</a></p>
<p>Author: Ting liu, Andrew W. Moore, Alexander Gray</p><p>Abstract: This paper is about non-approximate acceleration of high dimensional nonparametric operations such as k nearest neighbor classiﬁers and the prediction phase of Support Vector Machine classiﬁers. We attempt to exploit the fact that even if we want exact answers to nonparametric queries, we usually do not need to explicitly ﬁnd the datapoints close to the query, but merely need to ask questions about the properties about that set of datapoints. This offers a small amount of computational leeway, and we investigate how much that leeway can be exploited. For clarity, this paper concentrates on pure k-NN classiﬁcation and the prediction phase of SVMs. We introduce new ball tree algorithms that on real-world datasets give accelerations of 2-fold up to 100-fold compared against highly optimized traditional ball-tree-based k-NN. These results include datasets with up to 106 dimensions and 105 records, and show non-trivial speedups while giving exact answers. 1</p><p>6 0.49438283 <a title="28-lsi-6" href="./nips-2003-1-norm_Support_Vector_Machines.html">1 nips-2003-1-norm Support Vector Machines</a></p>
<p>7 0.49145278 <a title="28-lsi-7" href="./nips-2003-Discriminative_Fields_for_Modeling_Spatial_Dependencies_in_Natural_Images.html">54 nips-2003-Discriminative Fields for Modeling Spatial Dependencies in Natural Images</a></p>
<p>8 0.48890662 <a title="28-lsi-8" href="./nips-2003-AUC_Optimization_vs._Error_Rate_Minimization.html">3 nips-2003-AUC Optimization vs. Error Rate Minimization</a></p>
<p>9 0.46575481 <a title="28-lsi-9" href="./nips-2003-Insights_from_Machine_Learning_Applied_to_Human_Visual_Classification.html">95 nips-2003-Insights from Machine Learning Applied to Human Visual Classification</a></p>
<p>10 0.4641642 <a title="28-lsi-10" href="./nips-2003-An_Autonomous_Robotic_System_for_Mapping_Abandoned_Mines.html">21 nips-2003-An Autonomous Robotic System for Mapping Abandoned Mines</a></p>
<p>11 0.45958591 <a title="28-lsi-11" href="./nips-2003-Learning_a_Rare_Event_Detection_Cascade_by_Direct_Feature_Selection.html">109 nips-2003-Learning a Rare Event Detection Cascade by Direct Feature Selection</a></p>
<p>12 0.45143712 <a title="28-lsi-12" href="./nips-2003-A_Mixed-Signal_VLSI_for_Real-Time_Generation_of_Edge-Based_Image_Vectors.html">11 nips-2003-A Mixed-Signal VLSI for Real-Time Generation of Edge-Based Image Vectors</a></p>
<p>13 0.45032066 <a title="28-lsi-13" href="./nips-2003-Towards_Social_Robots%3A_Automatic_Evaluation_of_Human-Robot_Interaction_by_Facial_Expression_Classification.html">186 nips-2003-Towards Social Robots: Automatic Evaluation of Human-Robot Interaction by Facial Expression Classification</a></p>
<p>14 0.45017138 <a title="28-lsi-14" href="./nips-2003-Auction_Mechanism_Design_for_Multi-Robot_Coordination.html">36 nips-2003-Auction Mechanism Design for Multi-Robot Coordination</a></p>
<p>15 0.43843934 <a title="28-lsi-15" href="./nips-2003-Learning_with_Local_and_Global_Consistency.html">113 nips-2003-Learning with Local and Global Consistency</a></p>
<p>16 0.42293611 <a title="28-lsi-16" href="./nips-2003-Training_fMRI_Classifiers_to_Detect_Cognitive_States_across_Multiple_Human_Subjects.html">188 nips-2003-Training fMRI Classifiers to Detect Cognitive States across Multiple Human Subjects</a></p>
<p>17 0.42051402 <a title="28-lsi-17" href="./nips-2003-ARA%2A%3A_Anytime_A%2A_with_Provable_Bounds_on_Sub-Optimality.html">2 nips-2003-ARA*: Anytime A* with Provable Bounds on Sub-Optimality</a></p>
<p>18 0.41832352 <a title="28-lsi-18" href="./nips-2003-Using_the_Forest_to_See_the_Trees%3A_A_Graphical_Model_Relating_Features%2C_Objects%2C_and_Scenes.html">192 nips-2003-Using the Forest to See the Trees: A Graphical Model Relating Features, Objects, and Scenes</a></p>
<p>19 0.41688386 <a title="28-lsi-19" href="./nips-2003-Bayesian_Color_Constancy_with_Non-Gaussian_Models.html">39 nips-2003-Bayesian Color Constancy with Non-Gaussian Models</a></p>
<p>20 0.40409964 <a title="28-lsi-20" href="./nips-2003-A_Low-Power_Analog_VLSI_Visual_Collision_Detector.html">10 nips-2003-A Low-Power Analog VLSI Visual Collision Detector</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2003_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.047), (11, 0.051), (30, 0.025), (35, 0.039), (53, 0.063), (66, 0.01), (69, 0.011), (71, 0.074), (76, 0.032), (82, 0.016), (85, 0.187), (88, 0.244), (91, 0.1)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.86031687 <a title="28-lda-1" href="./nips-2003-Application_of_SVMs_for_Colour_Classification_and_Collision_Detection_with_AIBO_Robots.html">28 nips-2003-Application of SVMs for Colour Classification and Collision Detection with AIBO Robots</a></p>
<p>Author: Michael J. Quinlan, Stephan K. Chalup, Richard H. Middleton</p><p>Abstract: This article addresses the issues of colour classiﬁcation and collision detection as they occur in the legged league robot soccer environment of RoboCup. We show how the method of one-class classiﬁcation with support vector machines (SVMs) can be applied to solve these tasks satisfactorily using the limited hardware capacity of the prescribed Sony AIBO quadruped robots. The experimental evaluation shows an improvement over our previous methods of ellipse ﬁtting for colour classiﬁcation and the statistical approach used for collision detection.</p><p>2 0.79813534 <a title="28-lda-2" href="./nips-2003-Online_Learning_via_Global_Feedback_for_Phrase_Recognition.html">147 nips-2003-Online Learning via Global Feedback for Phrase Recognition</a></p>
<p>Author: Xavier Carreras, Lluís Màrquez</p><p>Abstract: This work presents an architecture based on perceptrons to recognize phrase structures, and an online learning algorithm to train the perceptrons together and dependently. The recognition strategy applies learning in two layers: a ﬁltering layer, which reduces the search space by identifying plausible phrase candidates, and a ranking layer, which recursively builds the optimal phrase structure. We provide a recognition-based feedback rule which reﬂects to each local function its committed errors from a global point of view, and allows to train them together online as perceptrons. Experimentation on a syntactic parsing problem, the recognition of clause hierarchies, improves state-of-the-art results and evinces the advantages of our global training method over optimizing each function locally and independently. 1</p><p>3 0.7405228 <a title="28-lda-3" href="./nips-2003-Approximate_Policy_Iteration_with_a_Policy_Language_Bias.html">34 nips-2003-Approximate Policy Iteration with a Policy Language Bias</a></p>
<p>Author: Alan Fern, Sungwook Yoon, Robert Givan</p><p>Abstract: We explore approximate policy iteration, replacing the usual costfunction learning step with a learning step in policy space. We give policy-language biases that enable solution of very large relational Markov decision processes (MDPs) that no previous technique can solve. In particular, we induce high-quality domain-speciﬁc planners for classical planning domains (both deterministic and stochastic variants) by solving such domains as extremely large MDPs. 1</p><p>4 0.69672769 <a title="28-lda-4" href="./nips-2003-Max-Margin_Markov_Networks.html">124 nips-2003-Max-Margin Markov Networks</a></p>
<p>Author: Ben Taskar, Carlos Guestrin, Daphne Koller</p><p>Abstract: In typical classiﬁcation tasks, we seek a function which assigns a label to a single object. Kernel-based approaches, such as support vector machines (SVMs), which maximize the margin of conﬁdence of the classiﬁer, are the method of choice for many such tasks. Their popularity stems both from the ability to use high-dimensional feature spaces, and from their strong theoretical guarantees. However, many real-world tasks involve sequential, spatial, or structured data, where multiple labels must be assigned. Existing kernel-based methods ignore structure in the problem, assigning labels independently to each object, losing much useful information. Conversely, probabilistic graphical models, such as Markov networks, can represent correlations between labels, by exploiting problem structure, but cannot handle high-dimensional feature spaces, and lack strong theoretical generalization guarantees. In this paper, we present a new framework that combines the advantages of both approaches: Maximum margin Markov (M3 ) networks incorporate both kernels, which efﬁciently deal with high-dimensional features, and the ability to capture correlations in structured data. We present an efﬁcient algorithm for learning M3 networks based on a compact quadratic program formulation. We provide a new theoretical bound for generalization in structured domains. Experiments on the task of handwritten character recognition and collective hypertext classiﬁcation demonstrate very signiﬁcant gains over previous approaches. 1</p><p>5 0.69090253 <a title="28-lda-5" href="./nips-2003-Using_the_Forest_to_See_the_Trees%3A_A_Graphical_Model_Relating_Features%2C_Objects%2C_and_Scenes.html">192 nips-2003-Using the Forest to See the Trees: A Graphical Model Relating Features, Objects, and Scenes</a></p>
<p>Author: Kevin P. Murphy, Antonio Torralba, William T. Freeman</p><p>Abstract: Standard approaches to object detection focus on local patches of the image, and try to classify them as background or not. We propose to use the scene context (image as a whole) as an extra source of (global) information, to help resolve local ambiguities. We present a conditional random ﬁeld for jointly solving the tasks of object detection and scene classiﬁcation. 1</p><p>6 0.67875969 <a title="28-lda-6" href="./nips-2003-Estimating_Internal_Variables_and_Paramters_of_a_Learning_Agent_by_a_Particle_Filter.html">64 nips-2003-Estimating Internal Variables and Paramters of a Learning Agent by a Particle Filter</a></p>
<p>7 0.67732227 <a title="28-lda-7" href="./nips-2003-ARA%2A%3A_Anytime_A%2A_with_Provable_Bounds_on_Sub-Optimality.html">2 nips-2003-ARA*: Anytime A* with Provable Bounds on Sub-Optimality</a></p>
<p>8 0.66120636 <a title="28-lda-8" href="./nips-2003-Learning_a_Rare_Event_Detection_Cascade_by_Direct_Feature_Selection.html">109 nips-2003-Learning a Rare Event Detection Cascade by Direct Feature Selection</a></p>
<p>9 0.6610105 <a title="28-lda-9" href="./nips-2003-New_Algorithms_for_Efficient_High_Dimensional_Non-parametric_Classification.html">136 nips-2003-New Algorithms for Efficient High Dimensional Non-parametric Classification</a></p>
<p>10 0.65759295 <a title="28-lda-10" href="./nips-2003-Variational_Linear_Response.html">193 nips-2003-Variational Linear Response</a></p>
<p>11 0.65580952 <a title="28-lda-11" href="./nips-2003-AUC_Optimization_vs._Error_Rate_Minimization.html">3 nips-2003-AUC Optimization vs. Error Rate Minimization</a></p>
<p>12 0.65196621 <a title="28-lda-12" href="./nips-2003-Insights_from_Machine_Learning_Applied_to_Human_Visual_Classification.html">95 nips-2003-Insights from Machine Learning Applied to Human Visual Classification</a></p>
<p>13 0.63904756 <a title="28-lda-13" href="./nips-2003-Near-Minimax_Optimal_Classification_with_Dyadic_Classification_Trees.html">134 nips-2003-Near-Minimax Optimal Classification with Dyadic Classification Trees</a></p>
<p>14 0.63310552 <a title="28-lda-14" href="./nips-2003-All_learning_is_Local%3A_Multi-agent_Learning_in_Global_Reward_Games.html">20 nips-2003-All learning is Local: Multi-agent Learning in Global Reward Games</a></p>
<p>15 0.63271177 <a title="28-lda-15" href="./nips-2003-Denoising_and_Untangling_Graphs_Using_Degree_Priors.html">50 nips-2003-Denoising and Untangling Graphs Using Degree Priors</a></p>
<p>16 0.62817943 <a title="28-lda-16" href="./nips-2003-Dynamical_Modeling_with_Kernels_for_Nonlinear_Time_Series_Prediction.html">57 nips-2003-Dynamical Modeling with Kernels for Nonlinear Time Series Prediction</a></p>
<p>17 0.61668742 <a title="28-lda-17" href="./nips-2003-Boosting_versus_Covering.html">41 nips-2003-Boosting versus Covering</a></p>
<p>18 0.61437601 <a title="28-lda-18" href="./nips-2003-Attractive_People%3A_Assembling_Loose-Limbed_Models_using_Non-parametric_Belief_Propagation.html">35 nips-2003-Attractive People: Assembling Loose-Limbed Models using Non-parametric Belief Propagation</a></p>
<p>19 0.61430025 <a title="28-lda-19" href="./nips-2003-Discriminative_Fields_for_Modeling_Spatial_Dependencies_in_Natural_Images.html">54 nips-2003-Discriminative Fields for Modeling Spatial Dependencies in Natural Images</a></p>
<p>20 0.61091518 <a title="28-lda-20" href="./nips-2003-Large_Margin_Classifiers%3A_Convex_Loss%2C_Low_Noise%2C_and_Convergence_Rates.html">101 nips-2003-Large Margin Classifiers: Convex Loss, Low Noise, and Convergence Rates</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
