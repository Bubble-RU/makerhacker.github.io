<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>101 nips-2003-Large Margin Classifiers: Convex Loss, Low Noise, and Convergence Rates</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2003" href="../home/nips2003_home.html">nips2003</a> <a title="nips-2003-101" href="#">nips2003-101</a> knowledge-graph by maker-knowledge-mining</p><h1>101 nips-2003-Large Margin Classifiers: Convex Loss, Low Noise, and Convergence Rates</h1>
<br/><p>Source: <a title="nips-2003-101-pdf" href="http://papers.nips.cc/paper/2416-large-margin-classifiers-convex-loss-low-noise-and-convergence-rates.pdf">pdf</a></p><p>Author: Peter L. Bartlett, Michael I. Jordan, Jon D. Mcauliffe</p><p>Abstract: Many classiﬁcation algorithms, including the support vector machine, boosting and logistic regression, can be viewed as minimum contrast methods that minimize a convex surrogate of the 0-1 loss function. We characterize the statistical consequences of using such a surrogate by providing a general quantitative relationship between the risk as assessed using the 0-1 loss and the risk as assessed using any nonnegative surrogate loss function. We show that this relationship gives nontrivial bounds under the weakest possible condition on the loss function—that it satisfy a pointwise form of Fisher consistency for classiﬁcation. The relationship is based on a variational transformation of the loss function that is easy to compute in many applications. We also present a reﬁned version of this result in the case of low noise. Finally, we present applications of our results to the estimation of convergence rates in the general setting of function classes that are scaled hulls of a ﬁnite-dimensional base class.</p><p>Reference: <a title="nips-2003-101-reference" href="../nips2003_reference/nips-2003-Large_Margin_Classifiers%3A_Convex_Loss%2C_Low_Noise%2C_and_Convergence_Rates_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('loss', 0.42), ('convex', 0.376), ('risk', 0.345), ('modul', 0.216), ('lb', 0.195), ('surrog', 0.192), ('px', 0.181), ('lipschitz', 0.168), ('excess', 0.165), ('mendelson', 0.13), ('pseudomet', 0.13), ('tsybakov', 0.113), ('quadr', 0.101), ('zhang', 0.1), ('strictly', 0.1), ('class', 0.099), ('nonneg', 0.098), ('absconv', 0.098), ('epigraph', 0.098), ('vay', 0.085)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="101-tfidf-1" href="./nips-2003-Large_Margin_Classifiers%3A_Convex_Loss%2C_Low_Noise%2C_and_Convergence_Rates.html">101 nips-2003-Large Margin Classifiers: Convex Loss, Low Noise, and Convergence Rates</a></p>
<p>2 0.32500499 <a title="101-tfidf-2" href="./nips-2003-Margin_Maximizing_Loss_Functions.html">122 nips-2003-Margin Maximizing Loss Functions</a></p>
<p>3 0.16638543 <a title="101-tfidf-3" href="./nips-2003-Sparseness_of_Support_Vector_Machines---Some_Asymptotically_Sharp_Bounds.html">180 nips-2003-Sparseness of Support Vector Machines---Some Asymptotically Sharp Bounds</a></p>
<p>4 0.1607956 <a title="101-tfidf-4" href="./nips-2003-Online_Learning_of_Non-stationary_Sequences.html">146 nips-2003-Online Learning of Non-stationary Sequences</a></p>
<p>5 0.15329267 <a title="101-tfidf-5" href="./nips-2003-An_Infinity-sample_Theory_for_Multi-category_Large_Margin_Classification.html">23 nips-2003-An Infinity-sample Theory for Multi-category Large Margin Classification</a></p>
<p>6 0.12455418 <a title="101-tfidf-6" href="./nips-2003-Design_of_Experiments_via_Information_Theory.html">51 nips-2003-Design of Experiments via Information Theory</a></p>
<p>7 0.11188416 <a title="101-tfidf-7" href="./nips-2003-1-norm_Support_Vector_Machines.html">1 nips-2003-1-norm Support Vector Machines</a></p>
<p>8 0.1058797 <a title="101-tfidf-8" href="./nips-2003-Learning_Bounds_for_a_Generalized_Family_of_Bayesian_Posterior_Distributions.html">103 nips-2003-Learning Bounds for a Generalized Family of Bayesian Posterior Distributions</a></p>
<p>9 0.10027613 <a title="101-tfidf-9" href="./nips-2003-Algorithms_for_Interdependent_Security_Games.html">19 nips-2003-Algorithms for Interdependent Security Games</a></p>
<p>10 0.098607697 <a title="101-tfidf-10" href="./nips-2003-Log-Linear_Models_for_Label_Ranking.html">121 nips-2003-Log-Linear Models for Label Ranking</a></p>
<p>11 0.09860155 <a title="101-tfidf-11" href="./nips-2003-Measure_Based_Regularization.html">126 nips-2003-Measure Based Regularization</a></p>
<p>12 0.093045302 <a title="101-tfidf-12" href="./nips-2003-Near-Minimax_Optimal_Classification_with_Dyadic_Classification_Trees.html">134 nips-2003-Near-Minimax Optimal Classification with Dyadic Classification Trees</a></p>
<p>13 0.089472614 <a title="101-tfidf-13" href="./nips-2003-Online_Passive-Aggressive_Algorithms.html">148 nips-2003-Online Passive-Aggressive Algorithms</a></p>
<p>14 0.084722355 <a title="101-tfidf-14" href="./nips-2003-Semidefinite_Relaxations_for_Approximate_Inference_on_Graphs_with_Cycles.html">174 nips-2003-Semidefinite Relaxations for Approximate Inference on Graphs with Cycles</a></p>
<p>15 0.083775327 <a title="101-tfidf-15" href="./nips-2003-Image_Reconstruction_by_Linear_Programming.html">88 nips-2003-Image Reconstruction by Linear Programming</a></p>
<p>16 0.073568255 <a title="101-tfidf-16" href="./nips-2003-Prediction_on_Spike_Data_Using_Kernel_Algorithms.html">160 nips-2003-Prediction on Spike Data Using Kernel Algorithms</a></p>
<p>17 0.073406011 <a title="101-tfidf-17" href="./nips-2003-Approximate_Expectation_Maximization.html">32 nips-2003-Approximate Expectation Maximization</a></p>
<p>18 0.069768392 <a title="101-tfidf-18" href="./nips-2003-On_the_Dynamics_of_Boosting.html">143 nips-2003-On the Dynamics of Boosting</a></p>
<p>19 0.068394773 <a title="101-tfidf-19" href="./nips-2003-Bounded_Finite_State_Controllers.html">42 nips-2003-Bounded Finite State Controllers</a></p>
<p>20 0.067147031 <a title="101-tfidf-20" href="./nips-2003-Max-Margin_Markov_Networks.html">124 nips-2003-Max-Margin Markov Networks</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2003_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.211), (1, 0.045), (2, -0.057), (3, 0.201), (4, -0.178), (5, 0.02), (6, 0.08), (7, -0.12), (8, 0.135), (9, -0.174), (10, 0.125), (11, -0.085), (12, -0.081), (13, 0.184), (14, 0.148), (15, 0.016), (16, -0.004), (17, -0.068), (18, 0.061), (19, 0.035), (20, 0.191), (21, -0.027), (22, -0.13), (23, 0.059), (24, 0.075), (25, -0.024), (26, -0.12), (27, 0.136), (28, 0.052), (29, 0.03), (30, -0.076), (31, -0.127), (32, 0.017), (33, -0.067), (34, 0.035), (35, -0.039), (36, 0.005), (37, -0.02), (38, 0.017), (39, -0.151), (40, -0.077), (41, 0.077), (42, 0.084), (43, -0.018), (44, -0.008), (45, -0.074), (46, -0.017), (47, 0.018), (48, 0.046), (49, 0.005)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95840126 <a title="101-lsi-1" href="./nips-2003-Large_Margin_Classifiers%3A_Convex_Loss%2C_Low_Noise%2C_and_Convergence_Rates.html">101 nips-2003-Large Margin Classifiers: Convex Loss, Low Noise, and Convergence Rates</a></p>
<p>2 0.79299402 <a title="101-lsi-2" href="./nips-2003-Margin_Maximizing_Loss_Functions.html">122 nips-2003-Margin Maximizing Loss Functions</a></p>
<p>3 0.72648406 <a title="101-lsi-3" href="./nips-2003-An_Infinity-sample_Theory_for_Multi-category_Large_Margin_Classification.html">23 nips-2003-An Infinity-sample Theory for Multi-category Large Margin Classification</a></p>
<p>4 0.6783672 <a title="101-lsi-4" href="./nips-2003-Sparseness_of_Support_Vector_Machines---Some_Asymptotically_Sharp_Bounds.html">180 nips-2003-Sparseness of Support Vector Machines---Some Asymptotically Sharp Bounds</a></p>
<p>5 0.58501983 <a title="101-lsi-5" href="./nips-2003-Online_Learning_of_Non-stationary_Sequences.html">146 nips-2003-Online Learning of Non-stationary Sequences</a></p>
<p>6 0.50391662 <a title="101-lsi-6" href="./nips-2003-Near-Minimax_Optimal_Classification_with_Dyadic_Classification_Trees.html">134 nips-2003-Near-Minimax Optimal Classification with Dyadic Classification Trees</a></p>
<p>7 0.49005157 <a title="101-lsi-7" href="./nips-2003-1-norm_Support_Vector_Machines.html">1 nips-2003-1-norm Support Vector Machines</a></p>
<p>8 0.43998906 <a title="101-lsi-8" href="./nips-2003-Learning_Bounds_for_a_Generalized_Family_of_Bayesian_Posterior_Distributions.html">103 nips-2003-Learning Bounds for a Generalized Family of Bayesian Posterior Distributions</a></p>
<p>9 0.42719948 <a title="101-lsi-9" href="./nips-2003-Design_of_Experiments_via_Information_Theory.html">51 nips-2003-Design of Experiments via Information Theory</a></p>
<p>10 0.39057505 <a title="101-lsi-10" href="./nips-2003-Kernel_Dimensionality_Reduction_for_Supervised_Learning.html">98 nips-2003-Kernel Dimensionality Reduction for Supervised Learning</a></p>
<p>11 0.38941845 <a title="101-lsi-11" href="./nips-2003-Semidefinite_Relaxations_for_Approximate_Inference_on_Graphs_with_Cycles.html">174 nips-2003-Semidefinite Relaxations for Approximate Inference on Graphs with Cycles</a></p>
<p>12 0.37154511 <a title="101-lsi-12" href="./nips-2003-Measure_Based_Regularization.html">126 nips-2003-Measure Based Regularization</a></p>
<p>13 0.36736041 <a title="101-lsi-13" href="./nips-2003-Log-Linear_Models_for_Label_Ranking.html">121 nips-2003-Log-Linear Models for Label Ranking</a></p>
<p>14 0.3611033 <a title="101-lsi-14" href="./nips-2003-Statistical_Debugging_of_Sampled_Programs.html">181 nips-2003-Statistical Debugging of Sampled Programs</a></p>
<p>15 0.34203553 <a title="101-lsi-15" href="./nips-2003-AUC_Optimization_vs._Error_Rate_Minimization.html">3 nips-2003-AUC Optimization vs. Error Rate Minimization</a></p>
<p>16 0.33428019 <a title="101-lsi-16" href="./nips-2003-No_Unbiased_Estimator_of_the_Variance_of_K-Fold_Cross-Validation.html">137 nips-2003-No Unbiased Estimator of the Variance of K-Fold Cross-Validation</a></p>
<p>17 0.33360329 <a title="101-lsi-17" href="./nips-2003-When_Does_Non-Negative_Matrix_Factorization_Give_a_Correct_Decomposition_into_Parts%3F.html">195 nips-2003-When Does Non-Negative Matrix Factorization Give a Correct Decomposition into Parts?</a></p>
<p>18 0.32928154 <a title="101-lsi-18" href="./nips-2003-Online_Passive-Aggressive_Algorithms.html">148 nips-2003-Online Passive-Aggressive Algorithms</a></p>
<p>19 0.32658738 <a title="101-lsi-19" href="./nips-2003-From_Algorithmic_to_Subjective_Randomness.html">75 nips-2003-From Algorithmic to Subjective Randomness</a></p>
<p>20 0.32213756 <a title="101-lsi-20" href="./nips-2003-PAC-Bayesian_Generic_Chaining.html">151 nips-2003-PAC-Bayesian Generic Chaining</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2003_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.141), (14, 0.017), (20, 0.313), (31, 0.045), (53, 0.085), (58, 0.057), (62, 0.093), (76, 0.131), (85, 0.01)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.80638862 <a title="101-lda-1" href="./nips-2003-Nonlinear_Processing_in_LGN_Neurons.html">140 nips-2003-Nonlinear Processing in LGN Neurons</a></p>
<p>2 0.75005972 <a title="101-lda-2" href="./nips-2003-Nonstationary_Covariance_Functions_for_Gaussian_Process_Regression.html">141 nips-2003-Nonstationary Covariance Functions for Gaussian Process Regression</a></p>
<p>same-paper 3 0.72899354 <a title="101-lda-3" href="./nips-2003-Large_Margin_Classifiers%3A_Convex_Loss%2C_Low_Noise%2C_and_Convergence_Rates.html">101 nips-2003-Large Margin Classifiers: Convex Loss, Low Noise, and Convergence Rates</a></p>
<p>4 0.59635174 <a title="101-lda-4" href="./nips-2003-On_the_Dynamics_of_Boosting.html">143 nips-2003-On the Dynamics of Boosting</a></p>
<p>5 0.59265715 <a title="101-lda-5" href="./nips-2003-Design_of_Experiments_via_Information_Theory.html">51 nips-2003-Design of Experiments via Information Theory</a></p>
<p>6 0.5892747 <a title="101-lda-6" href="./nips-2003-Wormholes_Improve_Contrastive_Divergence.html">196 nips-2003-Wormholes Improve Contrastive Divergence</a></p>
<p>7 0.58483374 <a title="101-lda-7" href="./nips-2003-Online_Passive-Aggressive_Algorithms.html">148 nips-2003-Online Passive-Aggressive Algorithms</a></p>
<p>8 0.58473557 <a title="101-lda-8" href="./nips-2003-A_Model_for_Learning_the_Semantics_of_Pictures.html">12 nips-2003-A Model for Learning the Semantics of Pictures</a></p>
<p>9 0.58344126 <a title="101-lda-9" href="./nips-2003-Sequential_Bayesian_Kernel_Regression.html">176 nips-2003-Sequential Bayesian Kernel Regression</a></p>
<p>10 0.5820272 <a title="101-lda-10" href="./nips-2003-Perspectives_on_Sparse_Bayesian_Learning.html">155 nips-2003-Perspectives on Sparse Bayesian Learning</a></p>
<p>11 0.58125699 <a title="101-lda-11" href="./nips-2003-Sparse_Representation_and_Its_Applications_in_Blind_Source_Separation.html">179 nips-2003-Sparse Representation and Its Applications in Blind Source Separation</a></p>
<p>12 0.58098185 <a title="101-lda-12" href="./nips-2003-Mechanism_of_Neural_Interference_by_Transcranial_Magnetic_Stimulation%3A_Network_or_Single_Neuron%3F.html">127 nips-2003-Mechanism of Neural Interference by Transcranial Magnetic Stimulation: Network or Single Neuron?</a></p>
<p>13 0.58041042 <a title="101-lda-13" href="./nips-2003-An_Infinity-sample_Theory_for_Multi-category_Large_Margin_Classification.html">23 nips-2003-An Infinity-sample Theory for Multi-category Large Margin Classification</a></p>
<p>14 0.57949638 <a title="101-lda-14" href="./nips-2003-Fast_Feature_Selection_from_Microarray_Expression_Data_via_Multiplicative_Large_Margin_Algorithms.html">72 nips-2003-Fast Feature Selection from Microarray Expression Data via Multiplicative Large Margin Algorithms</a></p>
<p>15 0.57948267 <a title="101-lda-15" href="./nips-2003-Margin_Maximizing_Loss_Functions.html">122 nips-2003-Margin Maximizing Loss Functions</a></p>
<p>16 0.57812709 <a title="101-lda-16" href="./nips-2003-Feature_Selection_in_Clustering_Problems.html">73 nips-2003-Feature Selection in Clustering Problems</a></p>
<p>17 0.57682288 <a title="101-lda-17" href="./nips-2003-Bayesian_Color_Constancy_with_Non-Gaussian_Models.html">39 nips-2003-Bayesian Color Constancy with Non-Gaussian Models</a></p>
<p>18 0.57562 <a title="101-lda-18" href="./nips-2003-Factorization_with_Uncertainty_and_Missing_Data%3A_Exploiting_Temporal_Coherence.html">69 nips-2003-Factorization with Uncertainty and Missing Data: Exploiting Temporal Coherence</a></p>
<p>19 0.57560652 <a title="101-lda-19" href="./nips-2003-Sensory_Modality_Segregation.html">175 nips-2003-Sensory Modality Segregation</a></p>
<p>20 0.57500583 <a title="101-lda-20" href="./nips-2003-Learning_the_k_in_k-means.html">111 nips-2003-Learning the k in k-means</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
