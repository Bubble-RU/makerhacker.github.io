<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>110 nips-2003-Learning a World Model and Planning with a Self-Organizing, Dynamic Neural System</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2003" href="../home/nips2003_home.html">nips2003</a> <a title="nips-2003-110" href="#">nips2003-110</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>110 nips-2003-Learning a World Model and Planning with a Self-Organizing, Dynamic Neural System</h1>
<br/><p>Source: <a title="nips-2003-110-pdf" href="http://papers.nips.cc/paper/2452-learning-a-world-model-and-planning-with-a-self-organizing-dynamic-neural-system.pdf">pdf</a></p><p>Author: Marc Toussaint</p><p>Abstract: We present a connectionist architecture that can learn a model of the relations between perceptions and actions and use this model for behavior planning. State representations are learned with a growing selforganizing layer which is directly coupled to a perception and a motor layer. Knowledge about possible state transitions is encoded in the lateral connectivity. Motor signals modulate this lateral connectivity and a dynamic ﬁeld on the layer organizes a planning process. All mechanisms are local and adaptation is based on Hebbian ideas. The model is continuous in the action, perception, and time domain.</p><p>Reference: <a title="nips-2003-110-reference" href="../nips2003_reference/nips-2003-Learning_a_World_Model_and_Planning_with_a_Self-Organizing%2C_Dynamic_Neural_System_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Learning a world model and planning with a self-organizing, dynamic neural system  Marc Toussaint Institut f¨ r Neuroinformatik u Ruhr-Universit¨ t Bochum, ND 04 a 44780 Bochum—Germany mt@neuroinformatik. [sent-1, score-0.257]
</p><p>2 de  Abstract We present a connectionist architecture that can learn a model of the relations between perceptions and actions and use this model for behavior planning. [sent-3, score-0.205]
</p><p>3 State representations are learned with a growing selforganizing layer which is directly coupled to a perception and a motor layer. [sent-4, score-0.77]
</p><p>4 Knowledge about possible state transitions is encoded in the lateral connectivity. [sent-5, score-0.304]
</p><p>5 Motor signals modulate this lateral connectivity and a dynamic ﬁeld on the layer organizes a planning process. [sent-6, score-0.677]
</p><p>6 All mechanisms are local and adaptation is based on Hebbian ideas. [sent-7, score-0.215]
</p><p>7 There is clear evidence that nervous systems use such internal models to perform predictive motor control, imagery, inference, and planning in a way that involves a simulation of actions and their perceptual implications [1, 2]. [sent-11, score-0.562]
</p><p>8 A tempting hypothesis is that the representations the brain uses for reasoning and planning are particularly designed (by adaptation or evolution) for just this purpose. [sent-13, score-0.293]
</p><p>9 To address such ideas we ﬁrst need a basic model for how a connectionist architecture can encode a world model and how self-organization of inherent representations is possible. [sent-14, score-0.288]
</p><p>10 In the ﬁeld of machine learning, world models are a standard approach to handle behavior organization problems (for a comparison of model-based approaches to the classical, model-free Reinforcement Learning see, e. [sent-15, score-0.186]
</p><p>11 Our approach for a connectionist world model (CWM) is functionally similar to existing Machine Learning approaches with selforganizing state space models [6, 7]. [sent-19, score-0.308]
</p><p>12 It is able to grow neural representations for different world states and to learn the implications of actions in terms of state transitions. [sent-20, score-0.298]
</p><p>13 motor layer a ka (aji , a)  xi wji  i  j ks (sj , s)  perceptive layer s  Figure 1: Schema of the CWM architecture. [sent-22, score-1.486]
</p><p>14 The adaptation mechanisms are largely derived from the idea of Hebbian plasticity. [sent-24, score-0.215]
</p><p>15 , the lateral connectivity, which encodes knowledge about possible state transitions, is adapted by a variant of the temporal Hebb rule and allows local adaptation of the world model to local world changes. [sent-27, score-0.746]
</p><p>16 • The coupling to the motor system is fully integrated in the architecture via a mechanism incorporating modulating synapses (comparable to shunting mechanisms). [sent-28, score-0.455]
</p><p>17 • The two dynamic processes on the CWM, the “tracking” process estimating the current state and the planning process (similar to Dynamic Programming), will be realized by activation dynamics on the architecture, incorporating in particular lateral interactions, inspired by neural ﬁelds [8]. [sent-29, score-0.558]
</p><p>18 The outline of the paper is as follows: In the next section we describe our architecture, the dynamics of activation and the couplings to perception and motor layers. [sent-30, score-0.5]
</p><p>19 In section 3 we introduce a dynamic process that generates, as an attractor, a value ﬁeld over the layer which is comparable to a state value function estimating the expected future return and allows for goal-oriented behavior organization. [sent-31, score-0.323]
</p><p>20 The self-organization process and adaptation mechanisms are described in section 4. [sent-32, score-0.215]
</p><p>21 2 The model The core of the connectionist world model (CWM) is a neural layer which is coupled to a perceptual layer and a motor layer, see ﬁgure 1. [sent-34, score-0.924]
</p><p>22 Let us enumerate the units of the central layer by i = 1, . [sent-35, score-0.309]
</p><p>23 Lateral connections within the layer may exist and we denote a connection from the i-th to j-th unit by (ji). [sent-38, score-0.42]
</p><p>24 To every unit we associate an activation xj ∈ R which is governed by the dynamics τx xj = −xj + ks (sj , s) + η ˙  ka (aji , a) wji xi ,  (1)  (ji)  which we will explain in detail in the following. [sent-42, score-1.092]
</p><p>25 First of all, xi are the time-dependent activations and the dot-notation τx x = F (x) means a time derivative which we algorith˙ mically implemented by a Euler integration step x(t) = x(t − 1) + τ1 F (x(t − 1)). [sent-43, score-0.12]
</p><p>26 ks (sj , s) is the forward excitation that unit j receives from the perceptive layer. [sent-45, score-0.334]
</p><p>27 Here, sj is the codebook vector (receptive ﬁeld) of unit j onto the perception layer which is compared to the current stimulus s via the kernel function ks . [sent-46, score-0.829]
</p><p>28 The third term, (ji) ka (aji , a) wji xi , describes the lateral interaction on the central layer. [sent-50, score-0.899]
</p><p>29 Namely, unit j receives lateral input from unit i iff there exists a connection (ji) from i to j. [sent-51, score-0.489]
</p><p>30 This lateral input is weighted by the connection’s synaptic strength wji . [sent-52, score-0.527]
</p><p>31 Additionally there is another term entering multiplicatively into this lateral interaction: Lateral inputs are modulated depending on the current motor activation. [sent-53, score-0.613]
</p><p>32 We chose a modulation of the following kind: To every existing connection (ji) we associate a codebook vector aji onto the motor layer which is compared to the current motor activity a via a Gaussian kernel function ka . [sent-54, score-1.655]
</p><p>33 Due to the multiplicative coupling, a connection contributes to lateral inputs only when the current motor activity “matches” the codebook vector of this connection. [sent-55, score-0.859]
</p><p>34 One example is shunting inhibition where inhibitory synapses attach to regions of the dentritic tree near to the soma and thereby modulate the transmission of the dentritic input [10]. [sent-57, score-0.286]
</p><p>35 In our architecture, a shunting synapse, receiving input from the motor layer, might attach to only one branch of a (lateral) dentritic tree and thereby multiplicatively modulate the lateral inputs summed up at this subtree. [sent-58, score-0.835]
</p><p>36 Let us assume normalized kernel functions −(sj − s)2 1 −(aji − a)2 1 , ka (aji , a) = √ . [sent-60, score-0.272]
</p><p>37 As for typical hidden Markov models we may derive the prior probability distribution P (j|a), given the action: P (a|j, i) P (j|i) P (j|i) P (j|a, i) = = ka (aji , a) , P (a|i) P (a|i) P (j|i) P (j|a) = ka (aji , a) P (i) . [sent-62, score-0.544]
</p><p>38 , comparing the input of a unit j (or, in the quasi-stationary case, xj itself) to the posterior and deriving theoretically grounded adaptation mechanisms. [sent-70, score-0.294]
</p><p>39 3 The dynamics of planning To organize goal-oriented behavior we assume that, in parallel to the activation dynamics (1), there exists a second dynamic process which can be motivated from classical approaches to Reinforcement Learning [11, 12]. [sent-72, score-0.432]
</p><p>40 Here, γ is the discount factor and we presumed that the received rewards (t) actually depend only on the state and thus enter equation (2) only in terms of the reward function r(i) (we neglect here that rewards may directly depend on the action). [sent-74, score-0.18]
</p><p>41 Behavior is described by a stochastic policy π(a|i), the probability of executing action a in state i. [sent-75, score-0.131]
</p><p>42 The practical meaning of the state-value function V is that it quantiﬁes how desirable and promising it is to reach a state i, also accounting for future rewards to be expected. [sent-79, score-0.117]
</p><p>43 In particular, if one knows the current state i it is a simple and efﬁcient rule of behavior to choose that action a that will lead to the neighbor state j with maximal V (j) (the greedy policy). [sent-80, score-0.279]
</p><p>44 Note though that direct Value Iteration presumes that the state and action spaces are known and ﬁnite, and that the current state and the world model P (j|i, a) is known. [sent-82, score-0.32]
</p><p>45 , it is given the command to reach a world state that corresponds to the stimulus g. [sent-86, score-0.273]
</p><p>46 This stimulus induces a reward excitation ri = ks (si , g) for each unit i. [sent-87, score-0.402]
</p><p>47 Now, besides the activations xi , we introduce another ﬁeld over the CWM, the value ﬁeld vi , which is in analogy to the state-value function V (i). [sent-88, score-0.161]
</p><p>48 , that connection (ji)) that leads to the neighbor state j with maximal value wji vj . [sent-93, score-0.489]
</p><p>49 Finally we replaced the probability factor P (j|i, a) by wji —we will see in the next section how wji is learned and what it will converge to. [sent-95, score-0.608]
</p><p>50 ∗ ∗ In practice, the value ﬁeld will relax quickly to its ﬁxed point vi = ri + γ max(ji) (wji vj ) and stay there if the goal does not change and if the world model is not re-adapted (see the experiments). [sent-96, score-0.306]
</p><p>51 The quasi-stationary value ﬁeld vi together with the current (typically nonstationary) activations xi allow the system to generate a motor signal that guides towards the goal. [sent-97, score-0.469]
</p><p>52 More precisely, the value ﬁeld vi determines for every unit i the “best” neighbor unit ki = argmaxj wji vj . [sent-98, score-0.606]
</p><p>53 The output motor signal is then the activation average  a=  xi aki i  (5)  i  of the motor codebook vectors aki i that have been learned for the corresponding connections. [sent-99, score-1.036]
</p><p>54 In the action selection process as given by equation (5) the signals ﬂow from the central layer back to the motor layer to induce the motor activity that should turn predictions into reality. [sent-101, score-1.143]
</p><p>55 Depending on the speciﬁc problem and the representation of motor commands on the motor layer, a post-processing of the motor signal a, e. [sent-102, score-0.924]
</p><p>56 a competition between contradictory motor units, might be necessary. [sent-104, score-0.308]
</p><p>57 In our experiments we will have two motor units and will always normalize the 2D vector a to unit length. [sent-105, score-0.479]
</p><p>58 4 Self-organization and adaptation The self-organization process of the central layer combines techniques from standard selforganizing maps [13, 14] and their extensions w. [sent-106, score-0.436]
</p><p>59 growing representations [15, 16] and the learning of temporal dependencies in lateral connections [17, 18]. [sent-109, score-0.451]
</p><p>60 The free variables of a CWM subject to adaptation are (1) the number of neurons and the lateral connectivity itself, (2) the codebook vectors si and aji to the perceptive and motor layers, respectively, and (3) the weights wji of the lateral connections. [sent-110, score-1.788]
</p><p>61 Mechanisms similar to those of FuzzyARTMAPs [15] or Growing Neural Gas [16] account for the insertion of new units when novelty is detected. [sent-113, score-0.127]
</p><p>62 We detect novelty in a straight-forward manner, namely when the difference between the actual perception and the best matching unit becomes too large. [sent-114, score-0.238]
</p><p>63 For this unit we integrate the error measure ez τe ez = −ez + (1 − ks (sz , s)) . [sent-117, score-0.415]
</p><p>64 ˙ We normalize ks (sz , s) such that it equals 1 in the perfect matching case when sz = s. [sent-118, score-0.291]
</p><p>65 We use simple Hebbian plasticity to ﬁne tune the representations of existing units and connections. [sent-122, score-0.15]
</p><p>66 Over time, the receptive ﬁelds of units and connections become more and more similar to the average stimuli that activated them. [sent-123, score-0.169]
</p><p>67 Although perfect prediction is not the actual objective of the CWM, the predictive power is a measure of the correctness of the learned world model and good predictive power is one-to-one with good behavior planning. [sent-126, score-0.326]
</p><p>68 The ﬁrst and simple mechanism to adapt the predictive power is to grow a new lateral connection between two successive best matching units z† and z if it does not yet exist. [sent-127, score-0.508]
</p><p>69 In our case we additionally have to account for the action-dependence of a lateral connection. [sent-133, score-0.244]
</p><p>70 We do so by considering the term ka (aji , a) xi instead of only the pre-synaptic activity. [sent-134, score-0.322]
</p><p>71 As a measure of temporal correlation we choose to relate this term to the derivative xj ˙ of the post-synaptic unit instead of its delayed activation—this saves us from specifying an ad-hoc “typical” delay and directly reﬂects that, in equation (1), lateral inputs relate to the derivative of xj . [sent-135, score-0.57]
</p><p>72 Hence, we consider the product xj ka (aji , a) xi as the measure of ˙ correlation. [sent-136, score-0.374]
</p><p>73 Our concrete implementation is a robust version of this idea: τw wji = κji [cji − wji κji ] , where ˙ τκ cji = −cji + xj ka (aji , a) xi , τκ κji = −κji + ka (aji , a) xi . [sent-137, score-1.374]
</p><p>74 ˙ ˙ ˙ Here, cji and κji are simply low-pass ﬁlters of xj ka (aji , a) xi and of ka (aji , a) xi . [sent-138, score-0.808]
</p><p>75 ˙ The term wji κji ensures convergence (assuming quasi static cji and κji ) of wji towards cji κji . [sent-139, score-0.79]
</p><p>76 The time scale of adaptation is modulated by the recent activity κji of the connection. [sent-140, score-0.18]
</p><p>77 The motor signal is 2-dimensional and encodes the forces f in x- and y¨ ˙ directions; the agent has a momentum and friction according to x = 0. [sent-149, score-0.44]
</p><p>78 Figure 2a also displays the (lateral) topology of the central layer after 30 000 time steps of self-organization, after which the system becomes quasi-stationary. [sent-152, score-0.272]
</p><p>79 During this ﬁrst phase, behavior planning is switched off and the maze is explored with a random walk that changes its direction only with probability 0. [sent-154, score-0.271]
</p><p>80 In the illustration, the positions of the units correspond to the codebook vectors that have been learned. [sent-156, score-0.268]
</p><p>81 The directedness and the codebook vectors of the connections can not displayed. [sent-157, score-0.273]
</p><p>82 A goal stimulus corresponding to a random position in the maze is given and changed every time the agent reaches the goal. [sent-159, score-0.362]
</p><p>83 Generally, the agent has no problem ﬁnding a path to the goal. [sent-160, score-0.132]
</p><p>84 The agent has reached goal A and now seeks for goal B. [sent-162, score-0.204]
</p><p>85 Starting at A the agent moves normally until it reaches the blockade. [sent-164, score-0.184]
</p><p>86 It stays there and moves slowly up an down in front of the blockade for a while—this while is of the order of the low-pass ﬁlter time scale τκ . [sent-165, score-0.155]
</p><p>87 During this time, the lateral weights of the connections pointing to the left are depressed and after about 150 time steps, this change of weights has enough inﬂuence on the value ﬁeld dynamics (4) to let the agent chose the way around the bottom to goal B. [sent-166, score-0.612]
</p><p>88 Figure 2c displays the next scene: Starting at B, the agent tries to reach goal C again via the blockade 1 (the previous adaptation depressed only the connections from right to left). [sent-167, score-0.652]
</p><p>89 Again, it reaches the blockade, stays there for a while, and then takes the way around to goal C. [sent-168, score-0.114]
</p><p>90 Figures 2d and 2e repeat this experiment with blockade 2. [sent-169, score-0.129]
</p><p>91 Starting at D, the agent reaches the blockade 2 and eventually chooses the way around to goal E. [sent-170, score-0.349]
</p><p>92 Then, seeking for goal F, the agent reaches the blockade ﬁrst from the left, thereafter from the bottom, then from the right, then it tries from the bottom again, and ﬁnally learned that none of these paths are valid anymore and chooses the way all around to goal F. [sent-171, score-0.459]
</p><p>93 Figures 2f shows that, once the world model has re-adapted to account for these blockades, the agent will not forget about them: Here, moving from G to H, it does not try to trespass block 2. [sent-172, score-0.325]
</p><p>94 net/03-cwm/, which visualize much better the dynamics of selforganization, the planning behavior, the dynamics of the value ﬁeld, and the world model readaptation. [sent-177, score-0.368]
</p><p>95 6 Discussion The goal of this research is an understanding of how neural systems may learn and represent a world model that allows for the generation of goal-directed behavioral sequences. [sent-178, score-0.2]
</p><p>96 In our approach for a connectionist world model a perceptual and a motor layer are coupled to selforganize a model of the perceptual implications of motor activity. [sent-179, score-1.131]
</p><p>97 A dynamical value ﬁeld on the learned world model organizes behavior planning—a method in principle borrowed from classical Value Iteration. [sent-180, score-0.322]
</p><p>98 The state space model is developed in a self-organizing way and small world changes require only little re-adaptation of the CWM. [sent-182, score-0.189]
</p><p>99 Another, rather straight-forward extension will be to replace random-walk exploration by more directed, information seeking exploration methods as they have already been developed for classical world models [20, 21]. [sent-185, score-0.274]
</p><p>100 The emulation theory of representation: motor control, imagery, and perception. [sent-192, score-0.308]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('motor', 0.308), ('aji', 0.285), ('wji', 0.283), ('ji', 0.273), ('ka', 0.272), ('lateral', 0.244), ('cwm', 0.236), ('codebook', 0.186), ('layer', 0.177), ('ks', 0.168), ('adaptation', 0.153), ('agent', 0.132), ('world', 0.129), ('blockade', 0.129), ('cji', 0.112), ('planning', 0.099), ('unit', 0.089), ('connections', 0.087), ('sj', 0.086), ('maze', 0.085), ('sz', 0.085), ('units', 0.082), ('ez', 0.079), ('action', 0.071), ('dynamics', 0.07), ('connection', 0.067), ('vi', 0.066), ('perception', 0.066), ('azz', 0.064), ('dentritic', 0.064), ('shunting', 0.064), ('trespass', 0.064), ('eld', 0.063), ('connectionist', 0.063), ('mechanisms', 0.062), ('state', 0.06), ('stimulus', 0.057), ('behavior', 0.057), ('selforganizing', 0.056), ('activation', 0.056), ('architecture', 0.055), ('xj', 0.052), ('reaches', 0.052), ('perceptive', 0.051), ('modulate', 0.051), ('classical', 0.051), ('xi', 0.05), ('central', 0.05), ('predictive', 0.049), ('growing', 0.048), ('vj', 0.048), ('hebb', 0.047), ('displays', 0.045), ('novelty', 0.045), ('activations', 0.045), ('aki', 0.043), ('attach', 0.043), ('depressed', 0.043), ('organizes', 0.043), ('learned', 0.042), ('representations', 0.041), ('hebbian', 0.041), ('matching', 0.038), ('perceptual', 0.038), ('implications', 0.038), ('gas', 0.037), ('mcclelland', 0.037), ('imagery', 0.037), ('bochum', 0.037), ('reinforcement', 0.037), ('goal', 0.036), ('behavioral', 0.035), ('reward', 0.035), ('connectivity', 0.034), ('rumelhart', 0.034), ('multiplicatively', 0.034), ('coupled', 0.032), ('seeking', 0.032), ('blocked', 0.032), ('exploration', 0.031), ('temporal', 0.031), ('neighbor', 0.031), ('actions', 0.03), ('switched', 0.03), ('rewards', 0.03), ('dynamic', 0.029), ('mechanism', 0.028), ('reach', 0.027), ('ri', 0.027), ('activity', 0.027), ('plasticity', 0.027), ('inputs', 0.027), ('interactions', 0.027), ('excitation', 0.026), ('stays', 0.026), ('sciences', 0.025), ('modulation', 0.025), ('recursion', 0.025), ('equation', 0.025), ('derivative', 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000012 <a title="110-tfidf-1" href="./nips-2003-Learning_a_World_Model_and_Planning_with_a_Self-Organizing%2C_Dynamic_Neural_System.html">110 nips-2003-Learning a World Model and Planning with a Self-Organizing, Dynamic Neural System</a></p>
<p>Author: Marc Toussaint</p><p>Abstract: We present a connectionist architecture that can learn a model of the relations between perceptions and actions and use this model for behavior planning. State representations are learned with a growing selforganizing layer which is directly coupled to a perception and a motor layer. Knowledge about possible state transitions is encoded in the lateral connectivity. Motor signals modulate this lateral connectivity and a dynamic ﬁeld on the layer organizes a planning process. All mechanisms are local and adaptation is based on Hebbian ideas. The model is continuous in the action, perception, and time domain.</p><p>2 0.13990283 <a title="110-tfidf-2" href="./nips-2003-All_learning_is_Local%3A_Multi-agent_Learning_in_Global_Reward_Games.html">20 nips-2003-All learning is Local: Multi-agent Learning in Global Reward Games</a></p>
<p>Author: Yu-han Chang, Tracey Ho, Leslie P. Kaelbling</p><p>Abstract: In large multiagent games, partial observability, coordination, and credit assignment persistently plague attempts to design good learning algorithms. We provide a simple and efﬁcient algorithm that in part uses a linear system to model the world from a single agent’s limited perspective, and takes advantage of Kalman ﬁltering to allow an agent to construct a good training signal and learn an effective policy. 1</p><p>3 0.11953263 <a title="110-tfidf-3" href="./nips-2003-Probabilistic_Inference_in_Human_Sensorimotor_Processing.html">161 nips-2003-Probabilistic Inference in Human Sensorimotor Processing</a></p>
<p>Author: Konrad P. Körding, Daniel M. Wolpert</p><p>Abstract: When we learn a new motor skill, we have to contend with both the variability inherent in our sensors and the task. The sensory uncertainty can be reduced by using information about the distribution of previously experienced tasks. Here we impose a distribution on a novel sensorimotor task and manipulate the variability of the sensory feedback. We show that subjects internally represent both the distribution of the task as well as their sensory uncertainty. Moreover, they combine these two sources of information in a way that is qualitatively predicted by optimal Bayesian processing. We further analyze if the subjects can represent multimodal distributions such as mixtures of Gaussians. The results show that the CNS employs probabilistic models during sensorimotor learning even when the priors are multimodal.</p><p>4 0.11413365 <a title="110-tfidf-4" href="./nips-2003-Perception_of_the_Structure_of_the_Physical_World_Using_Unknown_Multimodal_Sensors_and_Effectors.html">154 nips-2003-Perception of the Structure of the Physical World Using Unknown Multimodal Sensors and Effectors</a></p>
<p>Author: D. Philipona, J.k. O'regan, J.-p. Nadal, Olivier Coenen</p><p>Abstract: Is there a way for an algorithm linked to an unknown body to infer by itself information about this body and the world it is in? Taking the case of space for example, is there a way for this algorithm to realize that its body is in a three dimensional world? Is it possible for this algorithm to discover how to move in a straight line? And more basically: do these questions make any sense at all given that the algorithm only has access to the very high-dimensional data consisting of its sensory inputs and motor outputs? We demonstrate in this article how these questions can be given a positive answer. We show that it is possible to make an algorithm that, by analyzing the law that links its motor outputs to its sensory inputs, discovers information about the structure of the world regardless of the devices constituting the body it is linked to. We present results from simulations demonstrating a way to issue motor orders resulting in “fundamental” movements of the body as regards the structure of the physical world. 1</p><p>5 0.11272936 <a title="110-tfidf-5" href="./nips-2003-Estimating_Internal_Variables_and_Paramters_of_a_Learning_Agent_by_a_Particle_Filter.html">64 nips-2003-Estimating Internal Variables and Paramters of a Learning Agent by a Particle Filter</a></p>
<p>Author: Kazuyuki Samejima, Kenji Doya, Yasumasa Ueda, Minoru Kimura</p><p>Abstract: When we model a higher order functions, such as learning and memory, we face a difﬁculty of comparing neural activities with hidden variables that depend on the history of sensory and motor signals and the dynamics of the network. Here, we propose novel method for estimating hidden variables of a learning agent, such as connection weights from sequences of observable variables. Bayesian estimation is a method to estimate the posterior probability of hidden variables from observable data sequence using a dynamic model of hidden and observable variables. In this paper, we apply particle ﬁlter for estimating internal parameters and metaparameters of a reinforcement learning model. We veriﬁed the effectiveness of the method using both artiﬁcial data and real animal behavioral data. 1</p><p>6 0.097699046 <a title="110-tfidf-6" href="./nips-2003-Eye_Movements_for_Reward_Maximization.html">68 nips-2003-Eye Movements for Reward Maximization</a></p>
<p>7 0.085387744 <a title="110-tfidf-7" href="./nips-2003-Envelope-based_Planning_in_Relational_MDPs.html">62 nips-2003-Envelope-based Planning in Relational MDPs</a></p>
<p>8 0.082020976 <a title="110-tfidf-8" href="./nips-2003-A_Biologically_Plausible_Algorithm_for_Reinforcement-shaped_Representational_Learning.html">4 nips-2003-A Biologically Plausible Algorithm for Reinforcement-shaped Representational Learning</a></p>
<p>9 0.078815259 <a title="110-tfidf-9" href="./nips-2003-Auction_Mechanism_Design_for_Multi-Robot_Coordination.html">36 nips-2003-Auction Mechanism Design for Multi-Robot Coordination</a></p>
<p>10 0.078407943 <a title="110-tfidf-10" href="./nips-2003-Distributed_Optimization_in_Adaptive_Networks.html">55 nips-2003-Distributed Optimization in Adaptive Networks</a></p>
<p>11 0.075672016 <a title="110-tfidf-11" href="./nips-2003-Gaussian_Processes_in_Reinforcement_Learning.html">78 nips-2003-Gaussian Processes in Reinforcement Learning</a></p>
<p>12 0.074981526 <a title="110-tfidf-12" href="./nips-2003-Approximate_Planning_in_POMDPs_with_Macro-Actions.html">33 nips-2003-Approximate Planning in POMDPs with Macro-Actions</a></p>
<p>13 0.074913405 <a title="110-tfidf-13" href="./nips-2003-Approximate_Policy_Iteration_with_a_Policy_Language_Bias.html">34 nips-2003-Approximate Policy Iteration with a Policy Language Bias</a></p>
<p>14 0.070450783 <a title="110-tfidf-14" href="./nips-2003-Reasoning_about_Time_and_Knowledge_in_Neural_Symbolic_Learning_Systems.html">165 nips-2003-Reasoning about Time and Knowledge in Neural Symbolic Learning Systems</a></p>
<p>15 0.069835506 <a title="110-tfidf-15" href="./nips-2003-Different_Cortico-Basal_Ganglia_Loops_Specialize_in_Reward_Prediction_at_Different_Time_Scales.html">52 nips-2003-Different Cortico-Basal Ganglia Loops Specialize in Reward Prediction at Different Time Scales</a></p>
<p>16 0.068664707 <a title="110-tfidf-16" href="./nips-2003-Extending_Q-Learning_to_General_Adaptive_Multi-Agent_Systems.html">65 nips-2003-Extending Q-Learning to General Adaptive Multi-Agent Systems</a></p>
<p>17 0.06707634 <a title="110-tfidf-17" href="./nips-2003-On_the_Concentration_of_Expectation_and_Approximate_Inference_in_Layered_Networks.html">142 nips-2003-On the Concentration of Expectation and Approximate Inference in Layered Networks</a></p>
<p>18 0.064712979 <a title="110-tfidf-18" href="./nips-2003-Prediction_on_Spike_Data_Using_Kernel_Algorithms.html">160 nips-2003-Prediction on Spike Data Using Kernel Algorithms</a></p>
<p>19 0.064535052 <a title="110-tfidf-19" href="./nips-2003-Learning_Near-Pareto-Optimal_Conventions_in_Polynomial_Time.html">105 nips-2003-Learning Near-Pareto-Optimal Conventions in Polynomial Time</a></p>
<p>20 0.062262457 <a title="110-tfidf-20" href="./nips-2003-Entrainment_of_Silicon_Central_Pattern_Generators_for_Legged_Locomotory_Control.html">61 nips-2003-Entrainment of Silicon Central Pattern Generators for Legged Locomotory Control</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2003_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.197), (1, 0.202), (2, 0.054), (3, 0.031), (4, -0.01), (5, 0.012), (6, -0.012), (7, -0.028), (8, -0.033), (9, -0.066), (10, 0.087), (11, 0.007), (12, 0.063), (13, -0.053), (14, 0.067), (15, 0.129), (16, -0.011), (17, 0.017), (18, -0.046), (19, 0.036), (20, 0.022), (21, 0.007), (22, 0.002), (23, 0.083), (24, -0.058), (25, -0.001), (26, 0.043), (27, 0.019), (28, -0.001), (29, 0.02), (30, 0.07), (31, 0.021), (32, 0.01), (33, -0.15), (34, 0.055), (35, 0.056), (36, -0.14), (37, 0.043), (38, -0.063), (39, 0.083), (40, -0.045), (41, -0.126), (42, -0.186), (43, -0.008), (44, -0.021), (45, -0.094), (46, 0.002), (47, -0.114), (48, -0.082), (49, -0.06)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95911163 <a title="110-lsi-1" href="./nips-2003-Learning_a_World_Model_and_Planning_with_a_Self-Organizing%2C_Dynamic_Neural_System.html">110 nips-2003-Learning a World Model and Planning with a Self-Organizing, Dynamic Neural System</a></p>
<p>Author: Marc Toussaint</p><p>Abstract: We present a connectionist architecture that can learn a model of the relations between perceptions and actions and use this model for behavior planning. State representations are learned with a growing selforganizing layer which is directly coupled to a perception and a motor layer. Knowledge about possible state transitions is encoded in the lateral connectivity. Motor signals modulate this lateral connectivity and a dynamic ﬁeld on the layer organizes a planning process. All mechanisms are local and adaptation is based on Hebbian ideas. The model is continuous in the action, perception, and time domain.</p><p>2 0.6282441 <a title="110-lsi-2" href="./nips-2003-Eye_Movements_for_Reward_Maximization.html">68 nips-2003-Eye Movements for Reward Maximization</a></p>
<p>Author: Nathan Sprague, Dana Ballard</p><p>Abstract: Recent eye tracking studies in natural tasks suggest that there is a tight link between eye movements and goal directed motor actions. However, most existing models of human eye movements provide a bottom up account that relates visual attention to attributes of the visual scene. The purpose of this paper is to introduce a new model of human eye movements that directly ties eye movements to the ongoing demands of behavior. The basic idea is that eye movements serve to reduce uncertainty about environmental variables that are task relevant. A value is assigned to an eye movement by estimating the expected cost of the uncertainty that will result if the movement is not made. If there are several candidate eye movements, the one with the highest expected value is chosen. The model is illustrated using a humanoid graphic ﬁgure that navigates on a sidewalk in a virtual urban environment. Simulations show our protocol is superior to a simple round robin scheduling mechanism. 1</p><p>3 0.62790507 <a title="110-lsi-3" href="./nips-2003-Perception_of_the_Structure_of_the_Physical_World_Using_Unknown_Multimodal_Sensors_and_Effectors.html">154 nips-2003-Perception of the Structure of the Physical World Using Unknown Multimodal Sensors and Effectors</a></p>
<p>Author: D. Philipona, J.k. O'regan, J.-p. Nadal, Olivier Coenen</p><p>Abstract: Is there a way for an algorithm linked to an unknown body to infer by itself information about this body and the world it is in? Taking the case of space for example, is there a way for this algorithm to realize that its body is in a three dimensional world? Is it possible for this algorithm to discover how to move in a straight line? And more basically: do these questions make any sense at all given that the algorithm only has access to the very high-dimensional data consisting of its sensory inputs and motor outputs? We demonstrate in this article how these questions can be given a positive answer. We show that it is possible to make an algorithm that, by analyzing the law that links its motor outputs to its sensory inputs, discovers information about the structure of the world regardless of the devices constituting the body it is linked to. We present results from simulations demonstrating a way to issue motor orders resulting in “fundamental” movements of the body as regards the structure of the physical world. 1</p><p>4 0.58155358 <a title="110-lsi-4" href="./nips-2003-Probabilistic_Inference_in_Human_Sensorimotor_Processing.html">161 nips-2003-Probabilistic Inference in Human Sensorimotor Processing</a></p>
<p>Author: Konrad P. Körding, Daniel M. Wolpert</p><p>Abstract: When we learn a new motor skill, we have to contend with both the variability inherent in our sensors and the task. The sensory uncertainty can be reduced by using information about the distribution of previously experienced tasks. Here we impose a distribution on a novel sensorimotor task and manipulate the variability of the sensory feedback. We show that subjects internally represent both the distribution of the task as well as their sensory uncertainty. Moreover, they combine these two sources of information in a way that is qualitatively predicted by optimal Bayesian processing. We further analyze if the subjects can represent multimodal distributions such as mixtures of Gaussians. The results show that the CNS employs probabilistic models during sensorimotor learning even when the priors are multimodal.</p><p>5 0.43679473 <a title="110-lsi-5" href="./nips-2003-All_learning_is_Local%3A_Multi-agent_Learning_in_Global_Reward_Games.html">20 nips-2003-All learning is Local: Multi-agent Learning in Global Reward Games</a></p>
<p>Author: Yu-han Chang, Tracey Ho, Leslie P. Kaelbling</p><p>Abstract: In large multiagent games, partial observability, coordination, and credit assignment persistently plague attempts to design good learning algorithms. We provide a simple and efﬁcient algorithm that in part uses a linear system to model the world from a single agent’s limited perspective, and takes advantage of Kalman ﬁltering to allow an agent to construct a good training signal and learn an effective policy. 1</p><p>6 0.42785311 <a title="110-lsi-6" href="./nips-2003-Envelope-based_Planning_in_Relational_MDPs.html">62 nips-2003-Envelope-based Planning in Relational MDPs</a></p>
<p>7 0.41841659 <a title="110-lsi-7" href="./nips-2003-Reasoning_about_Time_and_Knowledge_in_Neural_Symbolic_Learning_Systems.html">165 nips-2003-Reasoning about Time and Knowledge in Neural Symbolic Learning Systems</a></p>
<p>8 0.39652565 <a title="110-lsi-8" href="./nips-2003-Estimating_Internal_Variables_and_Paramters_of_a_Learning_Agent_by_a_Particle_Filter.html">64 nips-2003-Estimating Internal Variables and Paramters of a Learning Agent by a Particle Filter</a></p>
<p>9 0.39476141 <a title="110-lsi-9" href="./nips-2003-Sensory_Modality_Segregation.html">175 nips-2003-Sensory Modality Segregation</a></p>
<p>10 0.3902536 <a title="110-lsi-10" href="./nips-2003-Autonomous_Helicopter_Flight_via_Reinforcement_Learning.html">38 nips-2003-Autonomous Helicopter Flight via Reinforcement Learning</a></p>
<p>11 0.38833329 <a title="110-lsi-11" href="./nips-2003-Circuit_Optimization_Predicts_Dynamic_Networks_for_Chemosensory_Orientation_in_Nematode_C._elegans.html">45 nips-2003-Circuit Optimization Predicts Dynamic Networks for Chemosensory Orientation in Nematode C. elegans</a></p>
<p>12 0.38043213 <a title="110-lsi-12" href="./nips-2003-Different_Cortico-Basal_Ganglia_Loops_Specialize_in_Reward_Prediction_at_Different_Time_Scales.html">52 nips-2003-Different Cortico-Basal Ganglia Loops Specialize in Reward Prediction at Different Time Scales</a></p>
<p>13 0.3785904 <a title="110-lsi-13" href="./nips-2003-A_Biologically_Plausible_Algorithm_for_Reinforcement-shaped_Representational_Learning.html">4 nips-2003-A Biologically Plausible Algorithm for Reinforcement-shaped Representational Learning</a></p>
<p>14 0.37086785 <a title="110-lsi-14" href="./nips-2003-A_Holistic_Approach_to_Compositional_Semantics%3A_a_connectionist_model_and_robot_experiments.html">8 nips-2003-A Holistic Approach to Compositional Semantics: a connectionist model and robot experiments</a></p>
<p>15 0.35703617 <a title="110-lsi-15" href="./nips-2003-Entrainment_of_Silicon_Central_Pattern_Generators_for_Legged_Locomotory_Control.html">61 nips-2003-Entrainment of Silicon Central Pattern Generators for Legged Locomotory Control</a></p>
<p>16 0.34815139 <a title="110-lsi-16" href="./nips-2003-Plasticity_Kernels_and_Temporal_Statistics.html">157 nips-2003-Plasticity Kernels and Temporal Statistics</a></p>
<p>17 0.34711909 <a title="110-lsi-17" href="./nips-2003-Extending_Q-Learning_to_General_Adaptive_Multi-Agent_Systems.html">65 nips-2003-Extending Q-Learning to General Adaptive Multi-Agent Systems</a></p>
<p>18 0.34372362 <a title="110-lsi-18" href="./nips-2003-Approximate_Policy_Iteration_with_a_Policy_Language_Bias.html">34 nips-2003-Approximate Policy Iteration with a Policy Language Bias</a></p>
<p>19 0.32243171 <a title="110-lsi-19" href="./nips-2003-Bounded_Invariance_and_the_Formation_of_Place_Fields.html">43 nips-2003-Bounded Invariance and the Formation of Place Fields</a></p>
<p>20 0.32118696 <a title="110-lsi-20" href="./nips-2003-Auction_Mechanism_Design_for_Multi-Robot_Coordination.html">36 nips-2003-Auction Mechanism Design for Multi-Robot Coordination</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2003_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.026), (11, 0.012), (29, 0.01), (30, 0.035), (35, 0.034), (53, 0.068), (71, 0.057), (76, 0.034), (85, 0.047), (91, 0.584), (99, 0.014)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.99369454 <a title="110-lda-1" href="./nips-2003-Perception_of_the_Structure_of_the_Physical_World_Using_Unknown_Multimodal_Sensors_and_Effectors.html">154 nips-2003-Perception of the Structure of the Physical World Using Unknown Multimodal Sensors and Effectors</a></p>
<p>Author: D. Philipona, J.k. O'regan, J.-p. Nadal, Olivier Coenen</p><p>Abstract: Is there a way for an algorithm linked to an unknown body to infer by itself information about this body and the world it is in? Taking the case of space for example, is there a way for this algorithm to realize that its body is in a three dimensional world? Is it possible for this algorithm to discover how to move in a straight line? And more basically: do these questions make any sense at all given that the algorithm only has access to the very high-dimensional data consisting of its sensory inputs and motor outputs? We demonstrate in this article how these questions can be given a positive answer. We show that it is possible to make an algorithm that, by analyzing the law that links its motor outputs to its sensory inputs, discovers information about the structure of the world regardless of the devices constituting the body it is linked to. We present results from simulations demonstrating a way to issue motor orders resulting in “fundamental” movements of the body as regards the structure of the physical world. 1</p><p>same-paper 2 0.98729396 <a title="110-lda-2" href="./nips-2003-Learning_a_World_Model_and_Planning_with_a_Self-Organizing%2C_Dynamic_Neural_System.html">110 nips-2003-Learning a World Model and Planning with a Self-Organizing, Dynamic Neural System</a></p>
<p>Author: Marc Toussaint</p><p>Abstract: We present a connectionist architecture that can learn a model of the relations between perceptions and actions and use this model for behavior planning. State representations are learned with a growing selforganizing layer which is directly coupled to a perception and a motor layer. Knowledge about possible state transitions is encoded in the lateral connectivity. Motor signals modulate this lateral connectivity and a dynamic ﬁeld on the layer organizes a planning process. All mechanisms are local and adaptation is based on Hebbian ideas. The model is continuous in the action, perception, and time domain.</p><p>3 0.98239106 <a title="110-lda-3" href="./nips-2003-Learning_Near-Pareto-Optimal_Conventions_in_Polynomial_Time.html">105 nips-2003-Learning Near-Pareto-Optimal Conventions in Polynomial Time</a></p>
<p>Author: Xiaofeng Wang, Tuomas Sandholm</p><p>Abstract: We study how to learn to play a Pareto-optimal strict Nash equilibrium when there exist multiple equilibria and agents may have different preferences among the equilibria. We focus on repeated coordination games of non-identical interest where agents do not know the game structure up front and receive noisy payoffs. We design efﬁcient near-optimal algorithms for both the perfect monitoring and the imperfect monitoring setting(where the agents only observe their own payoffs and the joint actions). 1</p><p>4 0.97682673 <a title="110-lda-4" href="./nips-2003-Identifying_Structure_across_Pre-partitioned_Data.html">87 nips-2003-Identifying Structure across Pre-partitioned Data</a></p>
<p>Author: Zvika Marx, Ido Dagan, Eli Shamir</p><p>Abstract: We propose an information-theoretic clustering approach that incorporates a pre-known partition of the data, aiming to identify common clusters that cut across the given partition. In the standard clustering setting the formation of clusters is guided by a single source of feature information. The newly utilized pre-partition factor introduces an additional bias that counterbalances the impact of the features whenever they become correlated with this known partition. The resulting algorithmic framework was applied successfully to synthetic data, as well as to identifying text-based cross-religion correspondences. 1 In t ro d u c t i o n The standard task of feature-based data clustering deals with a single set of elements that are characterized by a unified set of features. The goal of the clustering task is to identify implicit constructs, or themes, within the clustered set, grouping together elements that are characterized similarly by the features. In recent years there has been growing interest in more complex clustering settings, in which additional information is incorporated [1], [2]. Several such extensions ([3]-[5]) are based on the information bottleneck (IB) framework [6], which facilitates coherent information-theoretic representation of different information types. In a recent line of research we have investigated the cross-dataset clustering task [7], [8]. In this setting, some inherent a-priori partition of the clustered data to distinct subsets is given. The clustering goal it to identify corresponding (analogous) structures that cut across the different subsets, while ignoring internal structures that characterize individual subsets. To accomplish this task, those features that commonly characterize elements across the different subsets guide the clustering process, while within-subset regularities are neutralized. In [7], we presented a distance-based hard clustering algorithm for the coupledclustering problem, in which the clustered data is pre-partitioned to two subsets. In [8], our setting, generalized to pre-partitions of any number of subsets, was addressed by a heuristic extension of the probabilistic IB algorithm, yielding improved empirical results. Specifically, the algorithm in [8] was based on a modification of the IB stable-point equation, which amplified the impact of features characterizing a formed cluster across all, or most, subsets. This paper describes an information-theoretic framework that motivates and extends the algorithm proposed in [8]. The given pre-partitioning is represented via a probability distribution variable, which may represent “soft” pre-partitioning of the data, versus the strictly disjoint subsets assumed in the earlier cross-dataset framework. Further, we present a new functional that captures the cross-partition motivation. From the new functional, we derive a stable-point equation underlying our algorithmic framework in conjunction with the corresponding IB equation. Our algorithm was tested empirically on synthetic data and on a real-world textbased task that aimed to identify corresponding themes across distinct religions. We have cross-clustered five sets of keywords that were extracted from topical corpora of texts about Buddhism, Christianity, Hinduism, Islam and Judaism. In distinction from standard clustering results, our algorithm reveals themes that are common to all religions, such as sacred writings, festivals, narratives and myths and theological principles, and avoids topical clusters that correspond to individual religions (for example, ‘Christmas’ and ‘Easter’ are clustered together with ‘Ramadan’ rather than with ‘Church’). Finally, we have paid specific attention to the framework of clustering with side information [4]. While this approach was presented for a somewhat different mindset, it might be used directly to address clustering across pre-partitioned data. We compare the technical details of the two approaches and demonstrate empirically that clustering with side information does not seem appropriate for the kind of cross-partition tasks that we explored. 2 Th e In fo rmat i o n B ot t len eck M et h od Probabilistic (“soft”) data clustering outputs, for each element x of the set being clustered and each cluster c, an assignment probability p(c|x). The IB method [6] interprets probabilistic clustering as lossy data compression. The given data is represented by a random variable X ranging over the clustered elements. X is compressed through another random variable C, ranging over the clusters. Every element x is characterized by conditional probability distribution p(Y|x), where Y is a third random variable taking the members y of a given set of features as values. The IB method formalizes the clustering task as minimizing the IB functional: L(IB) = I(C; X) − β I(C; Y) . (1) As known from information theory (Ch. 13 of [9]), minimizing the mutual information I(C; X) optimizes distorted compression rate. A complementary bias to maximize I(C; Y) is interpreted in [6] as articulating the level of relevance of Y to the obtained clustering, inferred from the level by which C can predict Y. β is a free parameter counterbalancing the two biases. It is shown in [6] that p(c|x) values that minimize L(IB) satisfy the following equation: p(c|x) = 1 p (c )e −β DKL [ p ( Y |x )|| p (Y |c ) ] , z( β , x) (2) where DKL stands for the Kullback-Leibler (KL) divergence, or relative entropy, between two distributions and z(β ,x) is a normalization function over C. Eq. (2) implies that, optimally, x is assigned to c in proportion to their KL distance in a feature distribution space, where the distribution p(Y|c) takes the role of a Start at time t = 0 and iterate the following update-steps, till convergence: IB1: initialize p t (c|x) randomly or arbitrarily −β DKL [ p (Y | x )|| pt −1 (Y |c ) ] pt (c|x) ∝ IB2: pt (c) = IB3: pt (y|c) = pt −1 (c ) e ∑ x (t = 0) (t > 0) p t (c | x ) p ( x ) 1 ∑ pt ( c | x) p ( y | x ) p ( x) p t (c ) x Figure 1: The Information Bottleneck iterative algorithm (with fixed β and |C|). representative, or centroid, of c. The feature variable Y is hence utilized as the (exclusive) means to guide clustering, beyond the random nature of compression. Figure 1 presents the IB iterative algorithm for a fixed value of β . The IB1 update step follows Eq. (2). The other two steps, which are derived from the IB functional as well, estimate the p(c) and p(y|c) values required for the next iteration. The algorithm converges to a local minimum of the IB functional. The IB setting, particularly the derivation of steps IB1 and IB3 of the algorithm, assumes that Y and C are independent given X, that is: I(C; Y|X) = ∑x p(x) I(C|x; Y|x) = 0. The balancing parameter β affects the number of distinct clusters being formed in a manner that resembles (inverse) temperature in physical systems. The higher β is (i.e., the stronger the bias to construct C that predicts Y well), more distinct clusters are required for encoding the data. For each |C| = 2, 3, …, there is a minimal β value, enabling the formation of |C| distinct clusters. Setting β to be smaller than this critical value corresponding to the current |C| would result in two or more clusters that are identical to one another. Based on this, the iterative algorithm is applied repeatedly within a gradual cooling-like (deterministic annealing) scheme: starting with random initialization of the p0 (c|x)'s, generate two clusters with the critical β value, found empirically, for |C| = 2. Then, use a perturbation on the obtained two-cluster configuration to initialize the p0(c|x)'s for a larger set of clusters and execute additional runs of the algorithm to identify the critical β value for the larger |C|. And so on: each output configuration is used as a basis for a more granular one. The final outcome is a “soft hierarchy” of probabilistic clusters. 3 Cro ss- p a rt i t i o n Clu st eri n g Cross-partition (CP) clustering introduces a factor – a pre-given partition of the clustered data – additional to what considered in a standard clustering setting. For representing this factor we introduce the pre-partitioning variable W, ranging over all parts w of the pre-given partition. Every data element x is associated with W through a given probability distribution p(W|x). Our goal is to cluster the data, so that the clusters C would not be correlated with W. We notice that Y, which is intended to direct the formation of clusters, might be a-priori correlated with W, so the formed clusters might end up being correlated with W as well. Our method aims at eliminating this aspect of Y. 3.1 I n f or ma t i o n D e f oc us i n g As noted, some of the information conveyed by Y characterizes structures correlated with W, while the other part of the information characterizes the target cross-W structures. We are interested in detecting the latter while filtering out the former. However, there is no direct a-priori separation between the two parts of the Ymediated information. Our strategy in tackling this difficulty is: we follow in general Y's directions, as the IB method does, while avoiding Y's impact whenever it entails undesired inter-dependencies of C and W. Our strategy implies conflicting biases with regard to the mutual information I(C,Y): it should be maximized in order to form meaningful clusters, but be minimized as well in the specific context where Y entails C–W dependencies. Accordingly, we propose a computational procedure directed by two distinct cost-terms in tandem. The first one is the IB functional (Eq. 1), introducing the bias to maximize I(C,Y). With this bias alone, Y might dictate (or “explain”, in retrospect) substantial C–W dependencies, implying a low I(C;W|Y) value. 1 Hence, the guideline of preventing Y from accounting for C–W dependencies is realized through an opposing bias of maximizing I(C;W|Y) = ∑y p(y) I(C|y; W|y). The second cost term – the Information Defocusing (ID) functional – consequently counterbalances minimization of I(C,Y) against the new bias: L(ID) = I(C; Y) − η I(C;W|Y) , (3) where η is a free parameter articulating the tradeoff between the biases. The ID functional captures our goal of reducing the impact of Y selectively: “defocusing” a specific aspect of the information Y conveys: the information correlated with W. In a like manner to the stable-point equation of the IB functional (Eq. 2), we derive the following stable-point equation for the ID functional: η p ( w) 1 p ( c )∏ w p ( y | c, w) η +1 , p(c|y) = z (η , y ) (4) where z(η,y) is a normalization function over C. The derivation relies on an additional assumption, I(C;W) = 0, imposing the intended independence between C and W (the detailed derivation will be described elsewhere). The intuitive interpretation of Eq. (4) is as follows: a feature y is to be associated with a cluster c in proportion to a weighted, though flattened, geometric mean of the “W-projected centroids” p(y|c,w), priored by p(c). 2 This scheme overweighs y's that contribute to c evenly across W. Thus, clusters satisfying Eq. (4) are situated around centroids biased towards evenly contributing features. The higher η is, heavier emphasis is put on suppressing disagreements between the w's. For η → ∞ a plain weighted geometric-mean scheme is obtained. The inclusion of a step derived from Eq. (4) in our algorithm (see below) facilitates convergence on a configuration with centroids dominated by features that are evenly distributed across W. 3.2 T h e Cr os s - p a r t i t i on C l us t e r i n g A l g or i t h m Our proposed cross partition (CP) clustering algorithm (Fig. 2) seeks a clustering configuration that optimizes simultaneously both the IB and ID functionals, 1 Notice that “Z explaining well the dependencies between A and B” is equivalent with “A and B sharing little information in common given Z”, i.e. low I(A;B|Z) . Complete conditional independence is exemplified in the IB framework, assuming I(C;Y|X) = 0. 2 Eq. (4) resembles our suggestion in [8] to compute a geometric average over the subsets; in the current paper this scheme is analytically derived from the ID functional. Start at time t = 0 and iterate the following update-steps, till convergence: CP1: Initialize p t (c|x) randomly or arbitrarily −β DKL [ p (Y | x )|| pt −1 (Y |c ) ] pt (c|x) ∝ CP2: pt (c) = CP3: p*t (y|c,w) = CP4: (t = 0) p t −1 (c ) e ∑ x (t > 0) p t (c | x ) p ( x ) 1 ∑ pt ( c | x ) p ( y | x ) p ( w | x ) p ( x ) p t ( c ) p ( w) x Initialize p*t (c) randomly or arbitrarily (t = 0) p*t (c) (t > 0) = ∑ y p *t −1 (c | y ) p ( y ) η CP5: p*t (c|y) ∝ p *t (c)∏w p *t ( y | c, w) η +1 CP6: pt (y|c) = p ( w) p *t (c | y ) p ( y ) p *t (c ) Figure 2: The cross-partition clustering iterative algorithm (with fixed β, η, and |C|). thus obtaining clusters that cut across the pre-given partition W. To this end, the algorithm interleaves an iterative computation of the stable-point equations, and the additional estimated parameters, for both functionals. Steps CP1, CP2 and CP6 correspond to the computations related to the IB functional, while steps CP3, CP4 and CP5, which compute a separate set of parameters (denoted by an asterisk), correspond to the ID functional. Figure 3 summarizes the roles of the two functionals in the dynamics of the CP algorithm. The two components of the iterative cycle are tied together in steps CP3 and CP6, in which parameters from one set are used as input to compute a parameter of other set. The derivation of step CP3 relies on an additional assumption, namely that C, Y and W are jointly independent given X. This assumption, which extends to W the underlying assumption of the IB setting that C and Y are independent given X, still entails the IB stable point equation. At convergence, the stable point equations for both the IB and ID functionals are satisfied, each by its own set of parameters (in steps CP1 and CP5). The deterministic annealing scheme, which gradually increases β over repeated runs (see Sec. 2), is applied for the CP algorithm as well with η held fixed. For a given target number of clusters |C|, the algorithm empirically converges with a wide range of η values 3. I(C;X) ↓ IB β↑ I(C;Y) ↓ ID η↑ I(C; W|Y) I(C; Y; W|X) = 0 ← assumptions → I(C;W) = 0 Figure 3: The interplay of the IB and the ID functionals in the CP algorithm. High η values tend to dictate centroids with features that are unevenly distributed across W, resulting in shrinkage of some of the clusters. Further analysis will be provided in future work. 3 4 Exp e ri men t a l Resu lt s Our synthetic setting consisted of 75 virtual elements, evenly pre-partitioned into three 25-element parts denoted X 1 , X2 and X3 (in our formalism, for each clustered element x, p(w|x) = 1 holds for either w = 1, 2, or 3). On top of this pre-partition, we partitioned the data twice, getting two (exhaustive) clustering configurations: 1. Target cross-W clustering: five clusters, each with representatives from all X w's; 2. Masking within-w clustering: six clusters, each consisting of roughly half the elements of either X 1, X 2 or X3 with no representatives from the other X w's. Each cluster, of both configurations, was characterized by a designated subset of features. Masking clusters were designed to be more salient than target clusters: they had more designated features (60 vs. 48 per cluster, i.e., 360 vs. 240 in total) and their elements shared higher feature-element (virtual) co-occurrence counts with those designated features (900 vs. 450 per element-feature pair). Noise (random positive integer < 200) was added to all counts associating elements with their designated features (for both within-w and cross-W clusters), as well as to roughly quarter of the zero counts associating elements with the rest of the features. The plain IB method consistently produced configurations strongly correlated with the masking clustering, while the CP algorithm revealed the target configuration. We got (see Table 1A) almost perfect results in configurations of nearly equal-sized cross-W clusters, and somewhat less perfect reconstruction in configurations of diverging sizes (6, 9, 15, 21 and 24). Performance level was measured relatively to optimal target-output cluster match by the proportion of elements correctly assigned, where assignment of an element x follows its highest p(c|x). The results indicated were averaged over 200 runs. They were obtained for the optimal η, which was found to be higher in the diverging-sizes task. In the text-based task, the clustered elements – keywords – were automatically extracted from five distinct corpora addressing five religions: introductory web pages, online magazines, encyclopedic entries etc., all downloaded from the Internet. The clustered keyword set X was consequently pre-partitioned to disjoint subsets {X w} w∈W, one for each religion4 (|X w| ≈ 200 for each w). We conducted experiments simultaneously involving religion pairs as well as all five religions. We took the features Y to be a set of words that commonly occur within all five corpora (|Y| ≈ 7000). x–y co-occurrences were recorded within ±5-word sliding window truncated by sentence boundaries. η was fixed to a value (1.0) enabling the formation of 20 clusters in all settings. The obtained clusters revealed interesting cross religion themes (see Sec. 1). For instance, the cluster (one of nine) capturing the theme of sacred festivals: the three highest p(c/x) members within each religion were Full-moon, Ceremony, Celebration (Buddhism); Easter, Sunday, Christmas Table 1: Average correct assignment proportion scores for the synthetic task (A) and Jaccard-coefficient scores for the religion keyword classification task (B). A. Synthetic Data IB CP B. Religion Data IB Coupled Clustering [7] CP (cross-expert agreement on religion pairs .462±.232) equal-size clusters .305 .985 non-equal clusters .292 .827 4 religion pairs all five (one case) .200±.100 .220±.138 .407±.144 .104 ––––––– .167 A keyword x that appeared in the corpora of different religions was considered as a distinct element for each religion, so the Xw were kept disjointed. (Chrsitianity); Puja, Ceremony, Festival (Hinduism); Id-al-Fitr, Friday, Ramadan, (Islam); and Sukkoth, Shavuot, Rosh-Hodesh (Judaism). The closest cluster produced by the plain IB method was poorer by far, including Islamic Ramadan, and Id and Jewish Passover, Rosh-Hashanah and Sabbath (which our method ranked high too), but no single related term from the other religions. Our external evaluation standards were cross-religion keyword classes constructed manually by experts of comparative religion studies. One such expert classification involved all five religions, and eight classifications addressed religions in pairs. Each of the eight religion-pair classifications was contributed by two independent experts using the same keywords, so we could also assess the agreement between experts. As an overlap measure we employed the Jaccard coefficient: the number of element pairs co-assigned together by both one of the evaluated clusters and one of the expert classes, divided by the number of pairs co-assigned by either our clusters or the expert (or both). We did not assume the number of expert classes is known in advance (as done in the synthetic experiments), so the results were averaged over all configurations of 2–16 cluster hierarchy, for each experiment. The results shown in Table 1B – clear improvement relatively to plain IB and the distance-based coupled clustering [7] – are, however, persistent when the number of clusters is taken to be equal to the number of classes, or if only the best score in hierarchy is considered. The level of cross-expert agreement indicates that our results are reasonably close to the scores expected in such subjective task. 5 C o mp a ri so n t o R e la t ed W o r k The information bottleneck framework served as the basis for several approaches that represent additional information in their clustering setting. The multivariate information bottleneck (MIB) adapts the IB framework for networks of multiple variables [3]. However, all variables in such networks are either compressed (like X), or predicted (like Y). The incorporation of an empirical variable to be masked or defocused in the sense of our W is not possible. Including such variables in the MIB framework might be explored in future work. Particularly relevant to our work is the IB-based method for extracting relevant constructs with side information [4]. This approach addresses settings in which two different types of features are distinguished explicitly: relevant versus irrelevant ones, denoted by Y+ and Y−. Both types of features are incorporated within a single functional to be minimized: L(IB-side-info) = I(C; X) − β ( I(C; Y +) − γ I(C; Y−) ), which directly drives clustering to de-correlate C and Y−. Formally, our setting can be mapped to the side information setting by regarding the pre-partition W simply as the additional set of irrelevant features, giving symmetric (and opposite) roles to W and Y. However, it seems that this view does not address properly the desired cross-partition setting. In our setting, it is assumed that clustering should be guided in general by Y, while W should only neutralize particular information within Y that would otherwise yield the undesired correlation between C and W (as described in Section 3.1). For that reason, the defocusing functional tie the three variables together by conditioning the de-correlation of C and W on Y, while its underlying assumption ensures the global de-correlation. Indeed, our method was found empirically superior on the cross-dataset task. The side-information IB method (the iterative algorithm with best scoring γ) achieves correct assignment proportion of 0.52 in both synthetic tasks, where our method scored 0.99 and 0.83 (see Table 1A) and, in the religion-pair keyword classification task, Jaccard coefficient improved by 20% relatively to plain IB (compared to our 100% improvement, see Table 1B). 6 C o n c lu si o n s This paper addressed the problem of clustering a pre-partitioned dataset, aiming to detect new internal structures that are not correlated with the pre-given partition but rather cut across its components. The proposed framework extends the cross-dataset clustering algorithm [8], providing better formal grounding and representing any pre-given (soft) partition of the dataset. Supported by empirical evidence, we suggest that our framework is better suited for the cross-partition task than applying the side-information framework [4], which was originally developed to address a somewhat different setting. We also demonstrate substantial empirical advantage over the distance-based coupled-clustering algorithm [7]. As an applied real-world goal, the algorithm successfully detects cross-religion commonalities. This goal exemplifies the more general notion of detecting analogies across different systems, which is a somewhat vague and non-consensual task and therefore especially challenging for a computational framework. Our approach can be viewed as an initial step towards principled identification of “hidden” commonalities between substantially different real world systems, while suppressing the vast majority of attributes that are irrelevant for the analogy. Further research may study the role of defocusing in supervised learning, where some pre-given partitions might mask the role of underlying discriminative features. Additionally, it would be interesting to explore relationships to other disciplines, e.g., network information theory ([9], Ch. 14) which provided motivation for the side-information approach. Finally, both frameworks (ours and side-information) suggest the importance of dealing wisely with information that should not dictate the clustering output directly. A c k n ow l e d g me n t s We thank Yuval Krymolowski for helpful discussions and Tiina Mahlamäki, Eitan Reich and William Shepard, for contributing the religion keyword classifications. References [1] Hofmann, T. (2001) Unsupervised learning by probabilistic latent semantic analysis. Journal of Machine Learning Research, 41(1):177-196. [2] Wagstaff K., Cardie C., Rogers S. and Schroedl S., 2001. Constrained K-Means clustering with background knowledge. The 18th International Conference on Machine Learning (ICML-2001), pp 577-584. [3] Friedman N., Mosenzon O., Slonim N. & Tishby N. (2002) Multivariate information bottleneck. The 17th conference on Uncertainty in Artificial Intelligence (UAI-17), pp. 152161. [4] Chechik G. & Tishby N. (2002) Extracting relevant structures with side information. Advances in Neural Processing Information Systems 15 (NIPS'02). [5] Globerson, A., Chechik G. & Tishby N. (2003) Sufficient dimensionality reduction. Journal of Machine Learning Research, 3:1307-1331. [6] Tishby, N., Pereira, F. C. & Bialek, W. (1999) The information bottleneck method. The 37th Annual Allerton Conference on Communication, Control, and Computing, pp. 368-379. [7] Marx, Z., Dagan, I., Buhmann, J. M. & Shamir E. (2002) Coupled clustering: A method for detecting structural correspondence. Journal of Machine Learning Research, 3:747-780. [8] Dagan, I., Marx, Z. & Shamir E (2002) Cross-dataset clustering: Revealing corresponding themes across multiple corpora. Proceedings of the 6th Conference on Natural Language Learning (CoNLL-2002), pp. 15-21. [9] Cover T. M. & Thomas J. A. (1991) Elements of Information Theory. Sons, Inc., New York, New York. John Wiley &</p><p>5 0.9692384 <a title="110-lda-5" href="./nips-2003-Towards_Social_Robots%3A_Automatic_Evaluation_of_Human-Robot_Interaction_by_Facial_Expression_Classification.html">186 nips-2003-Towards Social Robots: Automatic Evaluation of Human-Robot Interaction by Facial Expression Classification</a></p>
<p>Author: G.C. Littlewort, M.S. Bartlett, I.R. Fasel, J. Chenu, T. Kanda, H. Ishiguro, J.R. Movellan</p><p>Abstract: Computer animated agents and robots bring a social dimension to human computer interaction and force us to think in new ways about how computers could be used in daily life. Face to face communication is a real-time process operating at a time scale of less than a second. In this paper we present progress on a perceptual primitive to automatically detect frontal faces in the video stream and code them with respect to 7 dimensions in real time: neutral, anger, disgust, fear, joy, sadness, surprise. The face ﬁnder employs a cascade of feature detectors trained with boosting techniques [13, 2]. The expression recognizer employs a novel combination of Adaboost and SVM’s. The generalization performance to new subjects for a 7-way forced choice was 93.3% and 97% correct on two publicly available datasets. The outputs of the classiﬁer change smoothly as a function of time, providing a potentially valuable representation to code facial expression dynamics in a fully automatic and unobtrusive manner. The system was deployed and evaluated for measuring spontaneous facial expressions in the ﬁeld in an application for automatic assessment of human-robot interaction.</p><p>6 0.95169383 <a title="110-lda-6" href="./nips-2003-Clustering_with_the_Connectivity_Kernel.html">46 nips-2003-Clustering with the Connectivity Kernel</a></p>
<p>7 0.81429952 <a title="110-lda-7" href="./nips-2003-An_MDP-Based_Approach_to_Online_Mechanism_Design.html">26 nips-2003-An MDP-Based Approach to Online Mechanism Design</a></p>
<p>8 0.79264075 <a title="110-lda-8" href="./nips-2003-Extending_Q-Learning_to_General_Adaptive_Multi-Agent_Systems.html">65 nips-2003-Extending Q-Learning to General Adaptive Multi-Agent Systems</a></p>
<p>9 0.76345962 <a title="110-lda-9" href="./nips-2003-A_Biologically_Plausible_Algorithm_for_Reinforcement-shaped_Representational_Learning.html">4 nips-2003-A Biologically Plausible Algorithm for Reinforcement-shaped Representational Learning</a></p>
<p>10 0.7476387 <a title="110-lda-10" href="./nips-2003-Eye_Movements_for_Reward_Maximization.html">68 nips-2003-Eye Movements for Reward Maximization</a></p>
<p>11 0.74340278 <a title="110-lda-11" href="./nips-2003-How_to_Combine_Expert_%28and_Novice%29_Advice_when_Actions_Impact_the_Environment%3F.html">84 nips-2003-How to Combine Expert (and Novice) Advice when Actions Impact the Environment?</a></p>
<p>12 0.73145682 <a title="110-lda-12" href="./nips-2003-Bounded_Invariance_and_the_Formation_of_Place_Fields.html">43 nips-2003-Bounded Invariance and the Formation of Place Fields</a></p>
<p>13 0.72341478 <a title="110-lda-13" href="./nips-2003-A_Nonlinear_Predictive_State_Representation.html">14 nips-2003-A Nonlinear Predictive State Representation</a></p>
<p>14 0.71513551 <a title="110-lda-14" href="./nips-2003-Distributed_Optimization_in_Adaptive_Networks.html">55 nips-2003-Distributed Optimization in Adaptive Networks</a></p>
<p>15 0.71245027 <a title="110-lda-15" href="./nips-2003-Feature_Selection_in_Clustering_Problems.html">73 nips-2003-Feature Selection in Clustering Problems</a></p>
<p>16 0.70540822 <a title="110-lda-16" href="./nips-2003-Algorithms_for_Interdependent_Security_Games.html">19 nips-2003-Algorithms for Interdependent Security Games</a></p>
<p>17 0.69956648 <a title="110-lda-17" href="./nips-2003-Gene_Expression_Clustering_with_Functional_Mixture_Models.html">79 nips-2003-Gene Expression Clustering with Functional Mixture Models</a></p>
<p>18 0.69826072 <a title="110-lda-18" href="./nips-2003-All_learning_is_Local%3A_Multi-agent_Learning_in_Global_Reward_Games.html">20 nips-2003-All learning is Local: Multi-agent Learning in Global Reward Games</a></p>
<p>19 0.69773501 <a title="110-lda-19" href="./nips-2003-Learning_Spectral_Clustering.html">107 nips-2003-Learning Spectral Clustering</a></p>
<p>20 0.69425362 <a title="110-lda-20" href="./nips-2003-Dynamical_Modeling_with_Kernels_for_Nonlinear_Time_Series_Prediction.html">57 nips-2003-Dynamical Modeling with Kernels for Nonlinear Time Series Prediction</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
