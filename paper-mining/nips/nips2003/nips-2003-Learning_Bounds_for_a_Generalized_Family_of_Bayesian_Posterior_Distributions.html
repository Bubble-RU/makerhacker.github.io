<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>103 nips-2003-Learning Bounds for a Generalized Family of Bayesian Posterior Distributions</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2003" href="../home/nips2003_home.html">nips2003</a> <a title="nips-2003-103" href="#">nips2003-103</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>103 nips-2003-Learning Bounds for a Generalized Family of Bayesian Posterior Distributions</h1>
<br/><p>Source: <a title="nips-2003-103-pdf" href="http://papers.nips.cc/paper/2439-learning-bounds-for-a-generalized-family-of-bayesian-posterior-distributions.pdf">pdf</a></p><p>Author: Tong Zhang</p><p>Abstract: In this paper we obtain convergence bounds for the concentration of Bayesian posterior distributions (around the true distribution) using a novel method that simpliﬁes and enhances previous results. Based on the analysis, we also introduce a generalized family of Bayesian posteriors, and show that the convergence behavior of these generalized posteriors is completely determined by the local prior structure around the true distribution. This important and surprising robustness property does not hold for the standard Bayesian posterior in that it may not concentrate when there exist “bad” prior structures even at places far away from the true distribution. 1</p><p>Reference: <a title="nips-2003-103-reference" href="../nips2003_reference/nips-2003-Learning_Bounds_for_a_Generalized_Family_of_Bayesian_Posterior_Distributions_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('wx', 0.503), ('ln', 0.398), ('kl', 0.348), ('bayes', 0.299), ('postery', 0.233), ('rq', 0.191), ('shal', 0.184), ('elx', 0.122), ('bound', 0.113), ('ineq', 0.11), ('lx', 0.108), ('wd', 0.108), ('bernstein', 0.098), ('nkl', 0.098), ('xi', 0.096), ('converg', 0.095), ('theorem', 0.088), ('rx', 0.085), ('sup', 0.083), ('risk', 0.076)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="103-tfidf-1" href="./nips-2003-Learning_Bounds_for_a_Generalized_Family_of_Bayesian_Posterior_Distributions.html">103 nips-2003-Learning Bounds for a Generalized Family of Bayesian Posterior Distributions</a></p>
<p>2 0.19842774 <a title="103-tfidf-2" href="./nips-2003-On_the_Concentration_of_Expectation_and_Approximate_Inference_in_Layered_Networks.html">142 nips-2003-On the Concentration of Expectation and Approximate Inference in Layered Networks</a></p>
<p>3 0.18209869 <a title="103-tfidf-3" href="./nips-2003-Variational_Linear_Response.html">193 nips-2003-Variational Linear Response</a></p>
<p>4 0.1168376 <a title="103-tfidf-4" href="./nips-2003-Design_of_Experiments_via_Information_Theory.html">51 nips-2003-Design of Experiments via Information Theory</a></p>
<p>5 0.10749737 <a title="103-tfidf-5" href="./nips-2003-Information_Maximization_in_Noisy_Channels_%3A_A_Variational_Approach.html">94 nips-2003-Information Maximization in Noisy Channels : A Variational Approach</a></p>
<p>6 0.1058797 <a title="103-tfidf-6" href="./nips-2003-Large_Margin_Classifiers%3A_Convex_Loss%2C_Low_Noise%2C_and_Convergence_Rates.html">101 nips-2003-Large Margin Classifiers: Convex Loss, Low Noise, and Convergence Rates</a></p>
<p>7 0.097416662 <a title="103-tfidf-7" href="./nips-2003-Efficient_Multiscale_Sampling_from_Products_of_Gaussian_Mixtures.html">58 nips-2003-Efficient Multiscale Sampling from Products of Gaussian Mixtures</a></p>
<p>8 0.095468186 <a title="103-tfidf-8" href="./nips-2003-Error_Bounds_for_Transductive_Learning_via_Compression_and_Clustering.html">63 nips-2003-Error Bounds for Transductive Learning via Compression and Clustering</a></p>
<p>9 0.086163528 <a title="103-tfidf-9" href="./nips-2003-A_Kullback-Leibler_Divergence_Based_Kernel_for_SVM_Classification_in_Multimedia_Applications.html">9 nips-2003-A Kullback-Leibler Divergence Based Kernel for SVM Classification in Multimedia Applications</a></p>
<p>10 0.084176436 <a title="103-tfidf-10" href="./nips-2003-Perspectives_on_Sparse_Bayesian_Learning.html">155 nips-2003-Perspectives on Sparse Bayesian Learning</a></p>
<p>11 0.081027851 <a title="103-tfidf-11" href="./nips-2003-Sequential_Bayesian_Kernel_Regression.html">176 nips-2003-Sequential Bayesian Kernel Regression</a></p>
<p>12 0.07575167 <a title="103-tfidf-12" href="./nips-2003-Measure_Based_Regularization.html">126 nips-2003-Measure Based Regularization</a></p>
<p>13 0.075620413 <a title="103-tfidf-13" href="./nips-2003-Margin_Maximizing_Loss_Functions.html">122 nips-2003-Margin Maximizing Loss Functions</a></p>
<p>14 0.073753975 <a title="103-tfidf-14" href="./nips-2003-An_Infinity-sample_Theory_for_Multi-category_Large_Margin_Classification.html">23 nips-2003-An Infinity-sample Theory for Multi-category Large Margin Classification</a></p>
<p>15 0.069672599 <a title="103-tfidf-15" href="./nips-2003-Simplicial_Mixtures_of_Markov_Chains%3A_Distributed_Modelling_of_Dynamic_User_Profiles.html">177 nips-2003-Simplicial Mixtures of Markov Chains: Distributed Modelling of Dynamic User Profiles</a></p>
<p>16 0.066702969 <a title="103-tfidf-16" href="./nips-2003-Robustness_in_Markov_Decision_Problems_with_Uncertain_Transition_Matrices.html">167 nips-2003-Robustness in Markov Decision Problems with Uncertain Transition Matrices</a></p>
<p>17 0.06504409 <a title="103-tfidf-17" href="./nips-2003-Nonstationary_Covariance_Functions_for_Gaussian_Process_Regression.html">141 nips-2003-Nonstationary Covariance Functions for Gaussian Process Regression</a></p>
<p>18 0.064547025 <a title="103-tfidf-18" href="./nips-2003-Approximate_Expectation_Maximization.html">32 nips-2003-Approximate Expectation Maximization</a></p>
<p>19 0.063697681 <a title="103-tfidf-19" href="./nips-2003-Boosting_versus_Covering.html">41 nips-2003-Boosting versus Covering</a></p>
<p>20 0.061318934 <a title="103-tfidf-20" href="./nips-2003-Model_Uncertainty_in_Classical_Conditioning.html">130 nips-2003-Model Uncertainty in Classical Conditioning</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2003_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.184), (1, 0.038), (2, -0.041), (3, 0.099), (4, -0.168), (5, 0.029), (6, 0.059), (7, 0.123), (8, 0.083), (9, -0.141), (10, -0.09), (11, -0.022), (12, 0.093), (13, -0.025), (14, 0.078), (15, -0.032), (16, -0.052), (17, 0.017), (18, 0.017), (19, -0.042), (20, 0.134), (21, -0.044), (22, 0.121), (23, 0.026), (24, -0.042), (25, 0.042), (26, -0.06), (27, 0.067), (28, -0.021), (29, -0.245), (30, -0.073), (31, -0.102), (32, 0.043), (33, -0.125), (34, -0.011), (35, -0.12), (36, 0.094), (37, -0.155), (38, -0.12), (39, 0.067), (40, -0.136), (41, -0.084), (42, 0.167), (43, 0.105), (44, 0.044), (45, 0.028), (46, -0.065), (47, 0.015), (48, -0.053), (49, -0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96050823 <a title="103-lsi-1" href="./nips-2003-Learning_Bounds_for_a_Generalized_Family_of_Bayesian_Posterior_Distributions.html">103 nips-2003-Learning Bounds for a Generalized Family of Bayesian Posterior Distributions</a></p>
<p>2 0.65242064 <a title="103-lsi-2" href="./nips-2003-Error_Bounds_for_Transductive_Learning_via_Compression_and_Clustering.html">63 nips-2003-Error Bounds for Transductive Learning via Compression and Clustering</a></p>
<p>3 0.61577111 <a title="103-lsi-3" href="./nips-2003-On_the_Concentration_of_Expectation_and_Approximate_Inference_in_Layered_Networks.html">142 nips-2003-On the Concentration of Expectation and Approximate Inference in Layered Networks</a></p>
<p>4 0.54375315 <a title="103-lsi-4" href="./nips-2003-Variational_Linear_Response.html">193 nips-2003-Variational Linear Response</a></p>
<p>5 0.51792711 <a title="103-lsi-5" href="./nips-2003-Design_of_Experiments_via_Information_Theory.html">51 nips-2003-Design of Experiments via Information Theory</a></p>
<p>6 0.43977255 <a title="103-lsi-6" href="./nips-2003-An_Infinity-sample_Theory_for_Multi-category_Large_Margin_Classification.html">23 nips-2003-An Infinity-sample Theory for Multi-category Large Margin Classification</a></p>
<p>7 0.43738794 <a title="103-lsi-7" href="./nips-2003-Information_Maximization_in_Noisy_Channels_%3A_A_Variational_Approach.html">94 nips-2003-Information Maximization in Noisy Channels : A Variational Approach</a></p>
<p>8 0.43305385 <a title="103-lsi-8" href="./nips-2003-Perspectives_on_Sparse_Bayesian_Learning.html">155 nips-2003-Perspectives on Sparse Bayesian Learning</a></p>
<p>9 0.40899456 <a title="103-lsi-9" href="./nips-2003-Large_Margin_Classifiers%3A_Convex_Loss%2C_Low_Noise%2C_and_Convergence_Rates.html">101 nips-2003-Large Margin Classifiers: Convex Loss, Low Noise, and Convergence Rates</a></p>
<p>10 0.40410167 <a title="103-lsi-10" href="./nips-2003-Approximability_of_Probability_Distributions.html">30 nips-2003-Approximability of Probability Distributions</a></p>
<p>11 0.39369157 <a title="103-lsi-11" href="./nips-2003-Fast_Feature_Selection_from_Microarray_Expression_Data_via_Multiplicative_Large_Margin_Algorithms.html">72 nips-2003-Fast Feature Selection from Microarray Expression Data via Multiplicative Large Margin Algorithms</a></p>
<p>12 0.3718017 <a title="103-lsi-12" href="./nips-2003-Semidefinite_Relaxations_for_Approximate_Inference_on_Graphs_with_Cycles.html">174 nips-2003-Semidefinite Relaxations for Approximate Inference on Graphs with Cycles</a></p>
<p>13 0.37088037 <a title="103-lsi-13" href="./nips-2003-Simplicial_Mixtures_of_Markov_Chains%3A_Distributed_Modelling_of_Dynamic_User_Profiles.html">177 nips-2003-Simplicial Mixtures of Markov Chains: Distributed Modelling of Dynamic User Profiles</a></p>
<p>14 0.35102341 <a title="103-lsi-14" href="./nips-2003-Hierarchical_Topic_Models_and_the_Nested_Chinese_Restaurant_Process.html">83 nips-2003-Hierarchical Topic Models and the Nested Chinese Restaurant Process</a></p>
<p>15 0.34168226 <a title="103-lsi-15" href="./nips-2003-Discriminative_Fields_for_Modeling_Spatial_Dependencies_in_Natural_Images.html">54 nips-2003-Discriminative Fields for Modeling Spatial Dependencies in Natural Images</a></p>
<p>16 0.3379899 <a title="103-lsi-16" href="./nips-2003-Efficient_Multiscale_Sampling_from_Products_of_Gaussian_Mixtures.html">58 nips-2003-Efficient Multiscale Sampling from Products of Gaussian Mixtures</a></p>
<p>17 0.32917133 <a title="103-lsi-17" href="./nips-2003-Probabilistic_Inference_in_Human_Sensorimotor_Processing.html">161 nips-2003-Probabilistic Inference in Human Sensorimotor Processing</a></p>
<p>18 0.32846582 <a title="103-lsi-18" href="./nips-2003-Model_Uncertainty_in_Classical_Conditioning.html">130 nips-2003-Model Uncertainty in Classical Conditioning</a></p>
<p>19 0.32709804 <a title="103-lsi-19" href="./nips-2003-Sequential_Bayesian_Kernel_Regression.html">176 nips-2003-Sequential Bayesian Kernel Regression</a></p>
<p>20 0.32138303 <a title="103-lsi-20" href="./nips-2003-Approximate_Expectation_Maximization.html">32 nips-2003-Approximate Expectation Maximization</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2003_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.08), (9, 0.011), (26, 0.02), (31, 0.032), (38, 0.01), (53, 0.057), (58, 0.125), (62, 0.073), (70, 0.25), (76, 0.208), (95, 0.015)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.93205643 <a title="103-lda-1" href="./nips-2003-Reasoning_about_Time_and_Knowledge_in_Neural_Symbolic_Learning_Systems.html">165 nips-2003-Reasoning about Time and Knowledge in Neural Symbolic Learning Systems</a></p>
<p>same-paper 2 0.8079958 <a title="103-lda-2" href="./nips-2003-Learning_Bounds_for_a_Generalized_Family_of_Bayesian_Posterior_Distributions.html">103 nips-2003-Learning Bounds for a Generalized Family of Bayesian Posterior Distributions</a></p>
<p>3 0.7343272 <a title="103-lda-3" href="./nips-2003-Information_Bottleneck_for_Gaussian_Variables.html">92 nips-2003-Information Bottleneck for Gaussian Variables</a></p>
<p>4 0.72627574 <a title="103-lda-4" href="./nips-2003-Decoding_V1_Neuronal_Activity_using_Particle_Filtering_with_Volterra_Kernels.html">49 nips-2003-Decoding V1 Neuronal Activity using Particle Filtering with Volterra Kernels</a></p>
<p>5 0.72416854 <a title="103-lda-5" href="./nips-2003-Identifying_Structure_across_Pre-partitioned_Data.html">87 nips-2003-Identifying Structure across Pre-partitioned Data</a></p>
<p>6 0.71972054 <a title="103-lda-6" href="./nips-2003-Maximum_Likelihood_Estimation_of_a_Stochastic_Integrate-and-Fire_Neural_Model.html">125 nips-2003-Maximum Likelihood Estimation of a Stochastic Integrate-and-Fire Neural Model</a></p>
<p>7 0.7193166 <a title="103-lda-7" href="./nips-2003-Learning_Curves_for_Stochastic_Gradient_Descent_in_Linear_Feedforward_Networks.html">104 nips-2003-Learning Curves for Stochastic Gradient Descent in Linear Feedforward Networks</a></p>
<p>8 0.71698165 <a title="103-lda-8" href="./nips-2003-Information_Dynamics_and_Emergent_Computation_in_Recurrent_Circuits_of_Spiking_Neurons.html">93 nips-2003-Information Dynamics and Emergent Computation in Recurrent Circuits of Spiking Neurons</a></p>
<p>9 0.71604335 <a title="103-lda-9" href="./nips-2003-No_Unbiased_Estimator_of_the_Variance_of_K-Fold_Cross-Validation.html">137 nips-2003-No Unbiased Estimator of the Variance of K-Fold Cross-Validation</a></p>
<p>10 0.71096259 <a title="103-lda-10" href="./nips-2003-Generalised_Propagation_for_Fast_Fourier_Transforms_with_Partial_or_Missing_Data.html">80 nips-2003-Generalised Propagation for Fast Fourier Transforms with Partial or Missing Data</a></p>
<p>11 0.70795286 <a title="103-lda-11" href="./nips-2003-Linear_Dependent_Dimensionality_Reduction.html">115 nips-2003-Linear Dependent Dimensionality Reduction</a></p>
<p>12 0.70564049 <a title="103-lda-12" href="./nips-2003-Tree-structured_Approximations_by_Expectation_Propagation.html">189 nips-2003-Tree-structured Approximations by Expectation Propagation</a></p>
<p>13 0.70556819 <a title="103-lda-13" href="./nips-2003-Discriminative_Fields_for_Modeling_Spatial_Dependencies_in_Natural_Images.html">54 nips-2003-Discriminative Fields for Modeling Spatial Dependencies in Natural Images</a></p>
<p>14 0.70354563 <a title="103-lda-14" href="./nips-2003-Perspectives_on_Sparse_Bayesian_Learning.html">155 nips-2003-Perspectives on Sparse Bayesian Learning</a></p>
<p>15 0.70348322 <a title="103-lda-15" href="./nips-2003-Fast_Feature_Selection_from_Microarray_Expression_Data_via_Multiplicative_Large_Margin_Algorithms.html">72 nips-2003-Fast Feature Selection from Microarray Expression Data via Multiplicative Large Margin Algorithms</a></p>
<p>16 0.70339847 <a title="103-lda-16" href="./nips-2003-Mechanism_of_Neural_Interference_by_Transcranial_Magnetic_Stimulation%3A_Network_or_Single_Neuron%3F.html">127 nips-2003-Mechanism of Neural Interference by Transcranial Magnetic Stimulation: Network or Single Neuron?</a></p>
<p>17 0.702815 <a title="103-lda-17" href="./nips-2003-Sequential_Bayesian_Kernel_Regression.html">176 nips-2003-Sequential Bayesian Kernel Regression</a></p>
<p>18 0.70131278 <a title="103-lda-18" href="./nips-2003-A_Biologically_Plausible_Algorithm_for_Reinforcement-shaped_Representational_Learning.html">4 nips-2003-A Biologically Plausible Algorithm for Reinforcement-shaped Representational Learning</a></p>
<p>19 0.69848597 <a title="103-lda-19" href="./nips-2003-Model_Uncertainty_in_Classical_Conditioning.html">130 nips-2003-Model Uncertainty in Classical Conditioning</a></p>
<p>20 0.69806921 <a title="103-lda-20" href="./nips-2003-Necessary_Intransitive_Likelihood-Ratio_Classifiers.html">135 nips-2003-Necessary Intransitive Likelihood-Ratio Classifiers</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
