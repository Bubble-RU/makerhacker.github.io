<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>34 nips-2003-Approximate Policy Iteration with a Policy Language Bias</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2003" href="../home/nips2003_home.html">nips2003</a> <a title="nips-2003-34" href="#">nips2003-34</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>34 nips-2003-Approximate Policy Iteration with a Policy Language Bias</h1>
<br/><p>Source: <a title="nips-2003-34-pdf" href="http://papers.nips.cc/paper/2456-approximate-policy-iteration-with-a-policy-language-bias.pdf">pdf</a></p><p>Author: Alan Fern, Sungwook Yoon, Robert Givan</p><p>Abstract: We explore approximate policy iteration, replacing the usual costfunction learning step with a learning step in policy space. We give policy-language biases that enable solution of very large relational Markov decision processes (MDPs) that no previous technique can solve. In particular, we induce high-quality domain-speciÔ¨Åc planners for classical planning domains (both deterministic and stochastic variants) by solving such domains as extremely large MDPs. 1</p><p>Reference: <a title="nips-2003-34-reference" href="../nips2003_reference/nips-2003-Approximate_Policy_Iteration_with_a_Policy_Language_Bias_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('policy', 0.644), ('ap', 0.333), ('sr', 0.297), ('bw', 0.274), ('plan', 0.207), ('domain', 0.156), ('ff', 0.149), ('heur', 0.145), ('mdp', 0.127), ('yoon', 0.104), ('rrl', 0.103), ('lw', 0.101), ('strips', 0.089), ('horizon', 0.087), ('sbw', 0.086), ('world', 0.081), ('jm', 0.074), ('it', 0.074), ('mlj', 0.068), ('slw', 0.068)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999958 <a title="34-tfidf-1" href="./nips-2003-Approximate_Policy_Iteration_with_a_Policy_Language_Bias.html">34 nips-2003-Approximate Policy Iteration with a Policy Language Bias</a></p>
<p>2 0.46419507 <a title="34-tfidf-2" href="./nips-2003-Policy_Search_by_Dynamic_Programming.html">158 nips-2003-Policy Search by Dynamic Programming</a></p>
<p>3 0.39372393 <a title="34-tfidf-3" href="./nips-2003-Gaussian_Processes_in_Reinforcement_Learning.html">78 nips-2003-Gaussian Processes in Reinforcement Learning</a></p>
<p>4 0.33193704 <a title="34-tfidf-4" href="./nips-2003-Envelope-based_Planning_in_Relational_MDPs.html">62 nips-2003-Envelope-based Planning in Relational MDPs</a></p>
<p>5 0.24603668 <a title="34-tfidf-5" href="./nips-2003-Bounded_Finite_State_Controllers.html">42 nips-2003-Bounded Finite State Controllers</a></p>
<p>6 0.21874274 <a title="34-tfidf-6" href="./nips-2003-Robustness_in_Markov_Decision_Problems_with_Uncertain_Transition_Matrices.html">167 nips-2003-Robustness in Markov Decision Problems with Uncertain Transition Matrices</a></p>
<p>7 0.19765083 <a title="34-tfidf-7" href="./nips-2003-Distributed_Optimization_in_Adaptive_Networks.html">55 nips-2003-Distributed Optimization in Adaptive Networks</a></p>
<p>8 0.15332618 <a title="34-tfidf-8" href="./nips-2003-Approximate_Planning_in_POMDPs_with_Macro-Actions.html">33 nips-2003-Approximate Planning in POMDPs with Macro-Actions</a></p>
<p>9 0.14794222 <a title="34-tfidf-9" href="./nips-2003-All_learning_is_Local%3A_Multi-agent_Learning_in_Global_Reward_Games.html">20 nips-2003-All learning is Local: Multi-agent Learning in Global Reward Games</a></p>
<p>10 0.14284131 <a title="34-tfidf-10" href="./nips-2003-Linear_Program_Approximations_for_Factored_Continuous-State_Markov_Decision_Processes.html">116 nips-2003-Linear Program Approximations for Factored Continuous-State Markov Decision Processes</a></p>
<p>11 0.13797909 <a title="34-tfidf-11" href="./nips-2003-Extending_Q-Learning_to_General_Adaptive_Multi-Agent_Systems.html">65 nips-2003-Extending Q-Learning to General Adaptive Multi-Agent Systems</a></p>
<p>12 0.12730299 <a title="34-tfidf-12" href="./nips-2003-Auction_Mechanism_Design_for_Multi-Robot_Coordination.html">36 nips-2003-Auction Mechanism Design for Multi-Robot Coordination</a></p>
<p>13 0.1096747 <a title="34-tfidf-13" href="./nips-2003-An_MDP-Based_Approach_to_Online_Mechanism_Design.html">26 nips-2003-An MDP-Based Approach to Online Mechanism Design</a></p>
<p>14 0.10420049 <a title="34-tfidf-14" href="./nips-2003-Applying_Metric-Trees_to_Belief-Point_POMDPs.html">29 nips-2003-Applying Metric-Trees to Belief-Point POMDPs</a></p>
<p>15 0.095875017 <a title="34-tfidf-15" href="./nips-2003-Autonomous_Helicopter_Flight_via_Reinforcement_Learning.html">38 nips-2003-Autonomous Helicopter Flight via Reinforcement Learning</a></p>
<p>16 0.086589806 <a title="34-tfidf-16" href="./nips-2003-Estimating_Internal_Variables_and_Paramters_of_a_Learning_Agent_by_a_Particle_Filter.html">64 nips-2003-Estimating Internal Variables and Paramters of a Learning Agent by a Particle Filter</a></p>
<p>17 0.085009053 <a title="34-tfidf-17" href="./nips-2003-ARA%2A%3A_Anytime_A%2A_with_Provable_Bounds_on_Sub-Optimality.html">2 nips-2003-ARA*: Anytime A* with Provable Bounds on Sub-Optimality</a></p>
<p>18 0.075497091 <a title="34-tfidf-18" href="./nips-2003-Eye_Movements_for_Reward_Maximization.html">68 nips-2003-Eye Movements for Reward Maximization</a></p>
<p>19 0.075084493 <a title="34-tfidf-19" href="./nips-2003-Simplicial_Mixtures_of_Markov_Chains%3A_Distributed_Modelling_of_Dynamic_User_Profiles.html">177 nips-2003-Simplicial Mixtures of Markov Chains: Distributed Modelling of Dynamic User Profiles</a></p>
<p>20 0.066010311 <a title="34-tfidf-20" href="./nips-2003-Perspectives_on_Sparse_Bayesian_Learning.html">155 nips-2003-Perspectives on Sparse Bayesian Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2003_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.203), (1, -0.36), (2, -0.278), (3, -0.148), (4, 0.002), (5, 0.225), (6, -0.216), (7, -0.199), (8, -0.142), (9, -0.133), (10, -0.072), (11, -0.063), (12, 0.08), (13, 0.009), (14, -0.037), (15, -0.127), (16, -0.044), (17, 0.117), (18, 0.006), (19, 0.182), (20, -0.004), (21, 0.111), (22, 0.014), (23, 0.008), (24, 0.024), (25, -0.142), (26, 0.087), (27, -0.067), (28, 0.118), (29, -0.018), (30, 0.01), (31, -0.063), (32, 0.001), (33, 0.02), (34, 0.025), (35, -0.043), (36, 0.052), (37, -0.013), (38, -0.067), (39, 0.028), (40, 0.06), (41, -0.01), (42, 0.001), (43, 0.054), (44, 0.052), (45, 0.048), (46, 0.053), (47, 0.03), (48, -0.017), (49, -0.048)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96809053 <a title="34-lsi-1" href="./nips-2003-Approximate_Policy_Iteration_with_a_Policy_Language_Bias.html">34 nips-2003-Approximate Policy Iteration with a Policy Language Bias</a></p>
<p>2 0.92766607 <a title="34-lsi-2" href="./nips-2003-Policy_Search_by_Dynamic_Programming.html">158 nips-2003-Policy Search by Dynamic Programming</a></p>
<p>3 0.80796719 <a title="34-lsi-3" href="./nips-2003-Envelope-based_Planning_in_Relational_MDPs.html">62 nips-2003-Envelope-based Planning in Relational MDPs</a></p>
<p>4 0.71792459 <a title="34-lsi-4" href="./nips-2003-Autonomous_Helicopter_Flight_via_Reinforcement_Learning.html">38 nips-2003-Autonomous Helicopter Flight via Reinforcement Learning</a></p>
<p>5 0.68093759 <a title="34-lsi-5" href="./nips-2003-Gaussian_Processes_in_Reinforcement_Learning.html">78 nips-2003-Gaussian Processes in Reinforcement Learning</a></p>
<p>6 0.62357432 <a title="34-lsi-6" href="./nips-2003-Robustness_in_Markov_Decision_Problems_with_Uncertain_Transition_Matrices.html">167 nips-2003-Robustness in Markov Decision Problems with Uncertain Transition Matrices</a></p>
<p>7 0.57486743 <a title="34-lsi-7" href="./nips-2003-Linear_Program_Approximations_for_Factored_Continuous-State_Markov_Decision_Processes.html">116 nips-2003-Linear Program Approximations for Factored Continuous-State Markov Decision Processes</a></p>
<p>8 0.55093372 <a title="34-lsi-8" href="./nips-2003-Bounded_Finite_State_Controllers.html">42 nips-2003-Bounded Finite State Controllers</a></p>
<p>9 0.51303065 <a title="34-lsi-9" href="./nips-2003-Distributed_Optimization_in_Adaptive_Networks.html">55 nips-2003-Distributed Optimization in Adaptive Networks</a></p>
<p>10 0.3331255 <a title="34-lsi-10" href="./nips-2003-Auction_Mechanism_Design_for_Multi-Robot_Coordination.html">36 nips-2003-Auction Mechanism Design for Multi-Robot Coordination</a></p>
<p>11 0.33159223 <a title="34-lsi-11" href="./nips-2003-Approximate_Planning_in_POMDPs_with_Macro-Actions.html">33 nips-2003-Approximate Planning in POMDPs with Macro-Actions</a></p>
<p>12 0.31620055 <a title="34-lsi-12" href="./nips-2003-Extending_Q-Learning_to_General_Adaptive_Multi-Agent_Systems.html">65 nips-2003-Extending Q-Learning to General Adaptive Multi-Agent Systems</a></p>
<p>13 0.27550146 <a title="34-lsi-13" href="./nips-2003-ARA%2A%3A_Anytime_A%2A_with_Provable_Bounds_on_Sub-Optimality.html">2 nips-2003-ARA*: Anytime A* with Provable Bounds on Sub-Optimality</a></p>
<p>14 0.27111036 <a title="34-lsi-14" href="./nips-2003-An_MDP-Based_Approach_to_Online_Mechanism_Design.html">26 nips-2003-An MDP-Based Approach to Online Mechanism Design</a></p>
<p>15 0.2600466 <a title="34-lsi-15" href="./nips-2003-Eye_Movements_for_Reward_Maximization.html">68 nips-2003-Eye Movements for Reward Maximization</a></p>
<p>16 0.24631619 <a title="34-lsi-16" href="./nips-2003-All_learning_is_Local%3A_Multi-agent_Learning_in_Global_Reward_Games.html">20 nips-2003-All learning is Local: Multi-agent Learning in Global Reward Games</a></p>
<p>17 0.2305087 <a title="34-lsi-17" href="./nips-2003-Learning_a_World_Model_and_Planning_with_a_Self-Organizing%2C_Dynamic_Neural_System.html">110 nips-2003-Learning a World Model and Planning with a Self-Organizing, Dynamic Neural System</a></p>
<p>18 0.21900104 <a title="34-lsi-18" href="./nips-2003-Applying_Metric-Trees_to_Belief-Point_POMDPs.html">29 nips-2003-Applying Metric-Trees to Belief-Point POMDPs</a></p>
<p>19 0.20691934 <a title="34-lsi-19" href="./nips-2003-Fast_Algorithms_for_Large-State-Space_HMMs_with_Applications_to_Web_Usage_Analysis.html">70 nips-2003-Fast Algorithms for Large-State-Space HMMs with Applications to Web Usage Analysis</a></p>
<p>20 0.20640804 <a title="34-lsi-20" href="./nips-2003-Simplicial_Mixtures_of_Markov_Chains%3A_Distributed_Modelling_of_Dynamic_User_Profiles.html">177 nips-2003-Simplicial Mixtures of Markov Chains: Distributed Modelling of Dynamic User Profiles</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2003_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.08), (5, 0.277), (26, 0.034), (31, 0.04), (38, 0.011), (53, 0.05), (58, 0.068), (62, 0.035), (76, 0.089), (85, 0.181), (95, 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.72530657 <a title="34-lda-1" href="./nips-2003-Different_Cortico-Basal_Ganglia_Loops_Specialize_in_Reward_Prediction_at_Different_Time_Scales.html">52 nips-2003-Different Cortico-Basal Ganglia Loops Specialize in Reward Prediction at Different Time Scales</a></p>
<p>same-paper 2 0.6963163 <a title="34-lda-2" href="./nips-2003-Approximate_Policy_Iteration_with_a_Policy_Language_Bias.html">34 nips-2003-Approximate Policy Iteration with a Policy Language Bias</a></p>
<p>3 0.64591217 <a title="34-lda-3" href="./nips-2003-Towards_Social_Robots%3A_Automatic_Evaluation_of_Human-Robot_Interaction_by_Facial_Expression_Classification.html">186 nips-2003-Towards Social Robots: Automatic Evaluation of Human-Robot Interaction by Facial Expression Classification</a></p>
<p>4 0.63516295 <a title="34-lda-4" href="./nips-2003-Envelope-based_Planning_in_Relational_MDPs.html">62 nips-2003-Envelope-based Planning in Relational MDPs</a></p>
<p>5 0.62729633 <a title="34-lda-5" href="./nips-2003-Insights_from_Machine_Learning_Applied_to_Human_Visual_Classification.html">95 nips-2003-Insights from Machine Learning Applied to Human Visual Classification</a></p>
<p>6 0.5175187 <a title="34-lda-6" href="./nips-2003-Mutual_Boosting_for_Contextual_Inference.html">133 nips-2003-Mutual Boosting for Contextual Inference</a></p>
<p>7 0.50447792 <a title="34-lda-7" href="./nips-2003-Training_fMRI_Classifiers_to_Detect_Cognitive_States_across_Multiple_Human_Subjects.html">188 nips-2003-Training fMRI Classifiers to Detect Cognitive States across Multiple Human Subjects</a></p>
<p>8 0.50291193 <a title="34-lda-8" href="./nips-2003-Learning_a_Rare_Event_Detection_Cascade_by_Direct_Feature_Selection.html">109 nips-2003-Learning a Rare Event Detection Cascade by Direct Feature Selection</a></p>
<p>9 0.48623747 <a title="34-lda-9" href="./nips-2003-A_Mixed-Signal_VLSI_for_Real-Time_Generation_of_Edge-Based_Image_Vectors.html">11 nips-2003-A Mixed-Signal VLSI for Real-Time Generation of Edge-Based Image Vectors</a></p>
<p>10 0.48615825 <a title="34-lda-10" href="./nips-2003-Learning_a_World_Model_and_Planning_with_a_Self-Organizing%2C_Dynamic_Neural_System.html">110 nips-2003-Learning a World Model and Planning with a Self-Organizing, Dynamic Neural System</a></p>
<p>11 0.48338878 <a title="34-lda-11" href="./nips-2003-Eye_Movements_for_Reward_Maximization.html">68 nips-2003-Eye Movements for Reward Maximization</a></p>
<p>12 0.48322362 <a title="34-lda-12" href="./nips-2003-Using_the_Forest_to_See_the_Trees%3A_A_Graphical_Model_Relating_Features%2C_Objects%2C_and_Scenes.html">192 nips-2003-Using the Forest to See the Trees: A Graphical Model Relating Features, Objects, and Scenes</a></p>
<p>13 0.4767237 <a title="34-lda-13" href="./nips-2003-Auction_Mechanism_Design_for_Multi-Robot_Coordination.html">36 nips-2003-Auction Mechanism Design for Multi-Robot Coordination</a></p>
<p>14 0.47664312 <a title="34-lda-14" href="./nips-2003-Gaussian_Processes_in_Reinforcement_Learning.html">78 nips-2003-Gaussian Processes in Reinforcement Learning</a></p>
<p>15 0.47349769 <a title="34-lda-15" href="./nips-2003-Human_and_Ideal_Observers_for_Detecting_Image_Curves.html">85 nips-2003-Human and Ideal Observers for Detecting Image Curves</a></p>
<p>16 0.47348168 <a title="34-lda-16" href="./nips-2003-Increase_Information_Transfer_Rates_in_BCI_by_CSP_Extension_to_Multi-class.html">90 nips-2003-Increase Information Transfer Rates in BCI by CSP Extension to Multi-class</a></p>
<p>17 0.47328436 <a title="34-lda-17" href="./nips-2003-An_Improved_Scheme_for_Detection_and_Labelling_in_Johansson_Displays.html">22 nips-2003-An Improved Scheme for Detection and Labelling in Johansson Displays</a></p>
<p>18 0.47303551 <a title="34-lda-18" href="./nips-2003-Predicting_Speech_Intelligibility_from_a_Population_of_Neurons.html">159 nips-2003-Predicting Speech Intelligibility from a Population of Neurons</a></p>
<p>19 0.47247022 <a title="34-lda-19" href="./nips-2003-Image_Reconstruction_by_Linear_Programming.html">88 nips-2003-Image Reconstruction by Linear Programming</a></p>
<p>20 0.47004735 <a title="34-lda-20" href="./nips-2003-Unsupervised_Color_Decomposition_Of_Histologically_Stained_Tissue_Samples.html">190 nips-2003-Unsupervised Color Decomposition Of Histologically Stained Tissue Samples</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
