<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>17 nips-2003-A Sampled Texture Prior for Image Super-Resolution</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2003" href="../home/nips2003_home.html">nips2003</a> <a title="nips-2003-17" href="#">nips2003-17</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>17 nips-2003-A Sampled Texture Prior for Image Super-Resolution</h1>
<br/><p>Source: <a title="nips-2003-17-pdf" href="http://papers.nips.cc/paper/2381-a-sampled-texture-prior-for-image-super-resolution.pdf">pdf</a></p><p>Author: Lyndsey C. Pickup, Stephen J. Roberts, Andrew Zisserman</p><p>Abstract: Super-resolution aims to produce a high-resolution image from a set of one or more low-resolution images by recovering or inventing plausible high-frequency image content. Typical approaches try to reconstruct a high-resolution image using the sub-pixel displacements of several lowresolution images, usually regularized by a generic smoothness prior over the high-resolution image space. Other methods use training data to learn low-to-high-resolution matches, and have been highly successful even in the single-input-image case. Here we present a domain-speciﬁc image prior in the form of a p.d.f. based upon sampled images, and show that for certain types of super-resolution problems, this sample-based prior gives a signiﬁcant improvement over other common multiple-image super-resolution techniques. 1</p><p>Reference: <a title="nips-2003-17-reference" href="../nips2003_reference/nips-2003-A_Sampled_Texture_Prior_for_Image_Super-Resolution_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 uk  Abstract Super-resolution aims to produce a high-resolution image from a set of one or more low-resolution images by recovering or inventing plausible high-frequency image content. [sent-6, score-1.02]
</p><p>2 Typical approaches try to reconstruct a high-resolution image using the sub-pixel displacements of several lowresolution images, usually regularized by a generic smoothness prior over the high-resolution image space. [sent-7, score-1.08]
</p><p>3 Other methods use training data to learn low-to-high-resolution matches, and have been highly successful even in the single-input-image case. [sent-8, score-0.024]
</p><p>4 Here we present a domain-speciﬁc image prior in the form of a p. [sent-9, score-0.534]
</p><p>5 based upon sampled images, and show that for certain types of super-resolution problems, this sample-based prior gives a signiﬁcant improvement over other common multiple-image super-resolution techniques. [sent-12, score-0.265]
</p><p>6 1  Introduction  The aim of super-resolution is to take a set of one or more low-resolution input images of a scene, and estimate a higher-resolution image. [sent-13, score-0.373]
</p><p>7 If there are several low resolution images available with sub-pixel displacements, then the high frequency information of the superresolution image can be increased. [sent-14, score-0.759]
</p><p>8 A second approach uses an unsupervised technique where latent variables are introduced to model the mean intensity of groups of surrounding pixels [2]. [sent-16, score-0.159]
</p><p>9 In cases where the high-frequency detail is recovered from image displacements, the models tend to assume that each low-resolution image is a subsample from a true highresolution image or continuous scene. [sent-17, score-1.127]
</p><p>10 The generation of the low-resolution inputs can then be expressed as a degradation of the super-resolution image, usually by applying an image homography, convolving with blurring functions, and subsampling [3, 4, 5, 6, 7, 8, 9]. [sent-18, score-0.35]
</p><p>11 Unfortunately, the ML (maximum likelihood) super-resolution images obtained by revers-  ing the generative process above tend to be poorly conditioned and susceptible to highfrequency noise. [sent-19, score-0.408]
</p><p>12 Most approaches to multiple-image super-resolution use a MAP (maximum a-posteriori) approach to regularize the solution using a prior distribution over the high-resolution space. [sent-20, score-0.226]
</p><p>13 Gaussian process priors [4], Gaussian MRFs (Markov Random Fields) and Huber MRFs [3] have all been proposed as suitable candidates. [sent-21, score-0.032]
</p><p>14 In this paper, we consider an image prior based upon samples taken from other images, inspired by the use of non-parametric sampling methods in texture synthesis [10]. [sent-22, score-0.841]
</p><p>15 This texture synthesis method outperformed many other complex parametric models for texture representation, and produces perceptively correct-looking areas of texture given a sample texture seed. [sent-23, score-0.994]
</p><p>16 It works by ﬁnding texture patches similar to the area around a pixel of interest, and estimating the intensity of the central pixel from a histogram built up from similar samples. [sent-24, score-0.811]
</p><p>17 We turn this approach around to produce an image prior by ﬁnding areas in our sample set that are similar to patches in our super-resolution image, and evaluate how well they match, building up a p. [sent-25, score-0.788]
</p><p>18 In short, given a set of low resolution images and example images of textures in the same class at the higher resolution, our objective is to construct a super-resolution image using a prior that is sampled from the example images. [sent-29, score-1.402]
</p><p>19 We develop our model in section 2, and expand upon some of the implementation details in section 3, as well as introducing the Huber prior model against which most of the comparisons in this paper are made. [sent-31, score-0.261]
</p><p>20 The main contribution of this work is in the construction of the prior over the super-resolution image, but ﬁrst we will consider the generative model for the low-resolution image generation, which closely follows the approaches of [3] and [4]. [sent-34, score-0.563]
</p><p>21 We have K low-resolution images y (k) , which we assume are generated from the super-resolution image x by y (k) = W (k) x +  G  (k)  (1)  −1 where G is a vector of i. [sent-35, score-0.661]
</p><p>22 Gaussians G ∼ N (0, βG ), and βG is the noise precision. [sent-38, score-0.059]
</p><p>23 The construction of W involves mapping each low-resolution pixel into the space of the super-resolution image, and performing a convolution with a point spread function. [sent-39, score-0.131]
</p><p>24 We begin by assuming that the image registration parameters may be determined a priori, so each input image has a corresponding set of registration parameters θ (k) . [sent-41, score-0.849]
</p><p>25 We may now construct the likelihood function βG M/2 βG (k) exp − ||y − W (k) x||2 (2) 2π 2 where each input image is assumed to have M pixels (and the super-resolution image N pixels). [sent-42, score-0.8]
</p><p>26 To address this problem, a prior over the super-resolution image is often used. [sent-44, score-0.534]
</p><p>27 In [4], the authors restricted themselves to Gaussian process priors, which made their estimation of the registration parameters θ tractable, but encouraged smoothness across x without any special treatment to allow for edges. [sent-45, score-0.097]
</p><p>28 The Huber Prior was used successfully in [3] to penalize image gradients while being less harsh on large image discontinuities than a Gaussian prior. [sent-46, score-0.689]
</p><p>29 Details of the Huber prior are given in section 3. [sent-47, score-0.205]
</p><p>30 If we assume a uniform prior over the input images, the posterior distribution over x is of the form K  p(x|{y (k) , θ (k) })  p(y (k) |x, θ (k) ). [sent-48, score-0.246]
</p><p>31 ∝ p(x)  (4)  k=1  To build our expression for p(x), we adopt the philosophy of [10], and sample from other example images rather than developing a parametric model. [sent-49, score-0.411]
</p><p>32 A similar philosophy was used in [11] for image-based rendering. [sent-50, score-0.043]
</p><p>33 Given a small image patch around any particular pixel, we can learn a distribution for the central pixel’s intensity value by examining the values at the centres of similar patches from other images. [sent-51, score-0.839]
</p><p>34 Each pixel xi has a neighbourhood region R(xi ) consisting of the pixels around it, but not including xi itself. [sent-52, score-0.405]
</p><p>35 For each R(xi ), we ﬁnd the closest neighbourhood patch in the set of sampled patches, and ﬁnd the central pixel associated with this nearest neighbour, LR (xi ). [sent-53, score-0.426]
</p><p>36 The intensity of our original pixel is then assumed to be Gaussian distributed with mean equal to the intensity of this central pixel, and with some precision βT , −1 xi ∼ N (LR (xi ), βT )  (5)  leading us to a prior of the form p(x) =  βT 2π  N/2  exp −  βT ||x − LR (x)||2 . [sent-54, score-0.532]
</p><p>37 Our super-resolution image is then just arg minx (L), where K  ||y (k) − W (k) x||2 . [sent-56, score-0.352]
</p><p>38 L = β||x − LR (x)||2 +  (8)  k=1  3  Implementation details  We optimize the objective function of equation 8 using scaled conjugate gradients (SCG) to obtain an approximation to our super-resolution image. [sent-57, score-0.063]
</p><p>39 For speed, we approximate this by dL 2 = 2β x − LR (x) − dx K  K  W (k)T y (k) − W (k) x ,  (9)  k=1  which assumes that small perturbations in the neighbours of x will not change the value returned by LR (x). [sent-59, score-0.023]
</p><p>40 Our image patch regions R(xi ) are square windows centred on xi , and pixels near the edge of the image are supported using the average image of [3] extending beyond the edge of the super-resolution image. [sent-62, score-1.311]
</p><p>41 To compute the nearest region in the example images, patches are normalized to sum to unity, and centre weighted as in [10] by a 2-dimensional Gaussian. [sent-63, score-0.227]
</p><p>42 The width of the image patches used, and of the Gaussian weights, depends very much upon the scales of the textures present in the image. [sent-64, score-0.637]
</p><p>43 Our images intensities were in the range [0, 1], and all the work so far has been with grey-scale images. [sent-65, score-0.332]
</p><p>44 Most of our results with this sample-based prior are compared to super-resolution images obtained using the Huber prior used in [3]. [sent-66, score-0.742]
</p><p>45 Other edge-preserving functions are discussed in [12], though the Huber function performed better than these as a prior in this case. [sent-67, score-0.205]
</p><p>46 Plugging this into the posterior distribution of equation 4 leads to a Huber MAP image x H which minimizes the negative log probability 4N  LH = β  K  ||y (k) − W (k) x||2 ,  ρ((Gx)i ) + i=1  (12)  k=1  where again the r. [sent-70, score-0.329]
</p><p>47 has been scaled so that β is the single unknown ratio parameter. [sent-73, score-0.032]
</p><p>48 We added varying amounts of Gaussian noise (2/256, 6/256 and 12/256, grey levels) and took varying number of these images (2, 5, 10) to produce nine separate sets of low-resolution inputs from each of our initial “ground-truth” high resolution images. [sent-76, score-0.747]
</p><p>49 Figure 1 shows three 100 × 100 pixel ground truth images, each accompanied by corresponding 40 × 40 pixel low-resolution images generated from the  ground truth images at half the resolution, with 6/256 levels of noise. [sent-77, score-1.476]
</p><p>50 Our aim was to reconstruct the central 50 × 50 pixel section of the original ground truth image. [sent-78, score-0.414]
</p><p>51 Figure 2 shows the example images from which our texture samples patches were taken 1 – note that these do not overlap with the sections used to generate the low-resolution images. [sent-79, score-0.756]
</p><p>52 Text Truth  Brick Truth  Beads Truth  Text Low−res  Brick Low−res  Beads Low−res  Figure 1: Left to right: ground truth text, ground truth brick, ground truth beads, low-res text, low-res brick and low-res beads. [sent-80, score-0.872]
</p><p>53 Figure 3 shows the difference in super-resolution image quality that can be obtained using the sample-based prior over the Huber prior using identical input sets as described above. [sent-84, score-0.78]
</p><p>54 For each Huber super-resolution image, we ran a set of reconstructions, varying the Huber parameter α and the prior strength parameter β. [sent-85, score-0.265]
</p><p>55 The image shown for each input number/noise level pair is the one which gave the minimum RMS error when compared to the ground-truth image; these are very close to the “best” images chosen from the same sets by a human subject. [sent-86, score-0.702]
</p><p>56 The images shown for the sample-based prior are again the best (in the sense of having minimal RMS error) of several runs per image. [sent-87, score-0.537]
</p><p>57 We varied the size of the sample patches from 5 to 13 pixels in edge length – computational cost meant that larger patches were not considered. [sent-88, score-0.578]
</p><p>58 Compared to the Huber images, we tried relatively few different patch size and β-value combinations for our sample-based prior; again, this was due to our method taking longer to execute than the Huber method. [sent-89, score-0.142]
</p><p>59 Consequently, the Huber parameters are more likely to lie close to their own optimal values than our sample-based prior parameters are. [sent-90, score-0.205]
</p><p>60 We also present images recovered using a “wrong” texture. [sent-91, score-0.369]
</p><p>61 We generated ten lowresolution images from a picture of a leaf, and used texture samples from a small black-andwhite spiral in our reconstruction (Figure 4). [sent-92, score-0.683]
</p><p>62 A selection of results are shown in Figure 5, where we varied the β parameter governing the prior’s contribution to the output image. [sent-93, score-0.026]
</p><p>63 The text and brick datasets contained 2, 6, 12 grey levels of noise, while the beads dataset used 2, 12 and 32 grey levels. [sent-100, score-1.041]
</p><p>64 Each image shown is the best of several attempts with varying prior strengths, Huber parameter (for the Huber MRF prior images) and patch neighbourhood sizes (for the texture-based prior images). [sent-101, score-1.199]
</p><p>65 Figure 4: The original 120×120 high-resolution image (left), and the 80×80 pixel “wrong” texture sample image (right). [sent-103, score-1.053]
</p><p>66 64  Figure 5: Four 120×120 super-resolution images are shown on the lower row, reconstructed using different values of the prior strength parameter β: 0. [sent-108, score-0.565]
</p><p>67 5  Discussion and further considerations  The images of Figure 3 show that our prior offers a qualitative improvement over the generic prior, especially when few input images are available. [sent-113, score-0.932]
</p><p>68 Figure 6 plots the RMS errors from the Huber and sample-based priors against each other. [sent-115, score-0.056]
</p><p>69 In all cases, the sample-based method fares better, with the difference most notable in the text example. [sent-116, score-0.111]
</p><p>70 In general, larger patch sizes (11 × 11 pixels) give smaller errors for the noisy inputs, while small patches (5 × 5) are better for the less noisy images. [sent-117, score-0.338]
</p><p>71 Computational costs mean we limited the patch size to no more than 13 × 13, and terminated the SCG optimization algorithm after approximately 20 iterations. [sent-118, score-0.142]
</p><p>72 Since in general the textures for the prior will not be invariant to rotation and scaling, consideration of the registration of the input images will be necessary. [sent-120, score-0.758]
</p><p>73 The optimal patch size will be a function of the image textures, so learning this as a parameter of an extended model, in a similar way to how [4] learns the point-spread function for a set of input images, is another direction of interest. [sent-121, score-0.512]
</p><p>74 Comparison of RMSE (grey levels)  Texture−based RMS  60  equal−error line text dataset brick dateset bead dataset  50 40 30 20 10 10  20  30 40 Huber RMS  50  60  Figure 6: Comparison of RMS errors in reconstructing the text, brick and bead images using the Huber and sample-based priors. [sent-122, score-1.012]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('huber', 0.457), ('images', 0.332), ('image', 0.329), ('brick', 0.242), ('texture', 0.228), ('grey', 0.22), ('prior', 0.205), ('patches', 0.196), ('beads', 0.162), ('lr', 0.149), ('patch', 0.142), ('truth', 0.137), ('pixel', 0.131), ('rms', 0.114), ('levels', 0.109), ('pixels', 0.101), ('text', 0.088), ('beta', 0.085), ('hmap', 0.081), ('lowresolution', 0.081), ('neighbourhood', 0.081), ('textures', 0.079), ('registration', 0.075), ('ground', 0.073), ('resolution', 0.072), ('scg', 0.07), ('displacements', 0.064), ('gx', 0.064), ('noise', 0.059), ('intensity', 0.058), ('bead', 0.054), ('highresolution', 0.054), ('synthesis', 0.046), ('central', 0.045), ('irani', 0.043), ('mrf', 0.043), ('mrfs', 0.043), ('philosophy', 0.043), ('res', 0.042), ('input', 0.041), ('oxford', 0.04), ('ml', 0.039), ('recovered', 0.037), ('sample', 0.036), ('xi', 0.035), ('upon', 0.033), ('varying', 0.032), ('scaled', 0.032), ('priors', 0.032), ('gradients', 0.031), ('centre', 0.031), ('recovering', 0.03), ('wrong', 0.03), ('generative', 0.029), ('strength', 0.028), ('reconstruct', 0.028), ('sampled', 0.027), ('obermayer', 0.026), ('low', 0.026), ('tend', 0.026), ('varied', 0.026), ('rotation', 0.026), ('plots', 0.024), ('learn', 0.024), ('unity', 0.023), ('centres', 0.023), ('cvgip', 0.023), ('fares', 0.023), ('glenn', 0.023), ('lh', 0.023), ('minx', 0.023), ('neighbour', 0.023), ('netherlands', 0.023), ('stephen', 0.023), ('subsample', 0.023), ('swamped', 0.023), ('zoom', 0.023), ('dx', 0.023), ('column', 0.023), ('edge', 0.023), ('implementation', 0.023), ('gaussian', 0.023), ('matches', 0.022), ('generic', 0.022), ('becker', 0.022), ('around', 0.022), ('smoothness', 0.022), ('thrun', 0.021), ('spiral', 0.021), ('accompanied', 0.021), ('anisotropic', 0.021), ('dissimilar', 0.021), ('greg', 0.021), ('pickup', 0.021), ('regularize', 0.021), ('rendering', 0.021), ('rmse', 0.021), ('susceptible', 0.021), ('generation', 0.021), ('reconstruction', 0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999964 <a title="17-tfidf-1" href="./nips-2003-A_Sampled_Texture_Prior_for_Image_Super-Resolution.html">17 nips-2003-A Sampled Texture Prior for Image Super-Resolution</a></p>
<p>Author: Lyndsey C. Pickup, Stephen J. Roberts, Andrew Zisserman</p><p>Abstract: Super-resolution aims to produce a high-resolution image from a set of one or more low-resolution images by recovering or inventing plausible high-frequency image content. Typical approaches try to reconstruct a high-resolution image using the sub-pixel displacements of several lowresolution images, usually regularized by a generic smoothness prior over the high-resolution image space. Other methods use training data to learn low-to-high-resolution matches, and have been highly successful even in the single-input-image case. Here we present a domain-speciﬁc image prior in the form of a p.d.f. based upon sampled images, and show that for certain types of super-resolution problems, this sample-based prior gives a signiﬁcant improvement over other common multiple-image super-resolution techniques. 1</p><p>2 0.22362526 <a title="17-tfidf-2" href="./nips-2003-Image_Reconstruction_by_Linear_Programming.html">88 nips-2003-Image Reconstruction by Linear Programming</a></p>
<p>Author: Koji Tsuda, Gunnar Rätsch</p><p>Abstract: A common way of image denoising is to project a noisy image to the subspace of admissible images made for instance by PCA. However, a major drawback of this method is that all pixels are updated by the projection, even when only a few pixels are corrupted by noise or occlusion. We propose a new method to identify the noisy pixels by 1 -norm penalization and update the identiﬁed pixels only. The identiﬁcation and updating of noisy pixels are formulated as one linear program which can be solved efﬁciently. Especially, one can apply the ν-trick to directly specify the fraction of pixels to be reconstructed. Moreover, we extend the linear program to be able to exploit prior knowledge that occlusions often appear in contiguous blocks (e.g. sunglasses on faces). The basic idea is to penalize boundary points and interior points of the occluded area differently. We are able to show the ν-property also for this extended LP leading a method which is easy to use. Experimental results impressively demonstrate the power of our approach.</p><p>3 0.19750996 <a title="17-tfidf-3" href="./nips-2003-A_Model_for_Learning_the_Semantics_of_Pictures.html">12 nips-2003-A Model for Learning the Semantics of Pictures</a></p>
<p>Author: Victor Lavrenko, R. Manmatha, Jiwoon Jeon</p><p>Abstract: We propose an approach to learning the semantics of images which allows us to automatically annotate an image with keywords and to retrieve images based on text queries. We do this using a formalism that models the generation of annotated images. We assume that every image is divided into regions, each described by a continuous-valued feature vector. Given a training set of images with annotations, we compute a joint probabilistic model of image features and words which allow us to predict the probability of generating a word given the image regions. This may be used to automatically annotate and retrieve images given a word as a query. Experiments show that our model signiﬁcantly outperforms the best of the previously reported results on the tasks of automatic image annotation and retrieval. 1</p><p>4 0.13505131 <a title="17-tfidf-4" href="./nips-2003-Using_the_Forest_to_See_the_Trees%3A_A_Graphical_Model_Relating_Features%2C_Objects%2C_and_Scenes.html">192 nips-2003-Using the Forest to See the Trees: A Graphical Model Relating Features, Objects, and Scenes</a></p>
<p>Author: Kevin P. Murphy, Antonio Torralba, William T. Freeman</p><p>Abstract: Standard approaches to object detection focus on local patches of the image, and try to classify them as background or not. We propose to use the scene context (image as a whole) as an extra source of (global) information, to help resolve local ambiguities. We present a conditional random ﬁeld for jointly solving the tasks of object detection and scene classiﬁcation. 1</p><p>5 0.12248046 <a title="17-tfidf-5" href="./nips-2003-Nonlinear_Filtering_of_Electron_Micrographs_by_Means_of_Support_Vector_Regression.html">139 nips-2003-Nonlinear Filtering of Electron Micrographs by Means of Support Vector Regression</a></p>
<p>Author: Roland Vollgraf, Michael Scholz, Ian A. Meinertzhagen, Klaus Obermayer</p><p>Abstract: Nonlinear ﬁltering can solve very complex problems, but typically involve very time consuming calculations. Here we show that for ﬁlters that are constructed as a RBF network with Gaussian basis functions, a decomposition into linear ﬁlters exists, which can be computed eﬃciently in the frequency domain, yielding dramatic improvement in speed. We present an application of this idea to image processing. In electron micrograph images of photoreceptor terminals of the fruit ﬂy, Drosophila, synaptic vesicles containing neurotransmitter should be detected and labeled automatically. We use hand labels, provided by human experts, to learn a RBF ﬁlter using Support Vector Regression with Gaussian kernels. We will show that the resulting nonlinear ﬁlter solves the task to a degree of accuracy, which is close to what can be achieved by human experts. This allows the very time consuming task of data evaluation to be done eﬃciently. 1</p><p>6 0.11393899 <a title="17-tfidf-6" href="./nips-2003-Feature_Selection_in_Clustering_Problems.html">73 nips-2003-Feature Selection in Clustering Problems</a></p>
<p>7 0.1114402 <a title="17-tfidf-7" href="./nips-2003-Local_Phase_Coherence_and_the_Perception_of_Blur.html">119 nips-2003-Local Phase Coherence and the Perception of Blur</a></p>
<p>8 0.11133597 <a title="17-tfidf-8" href="./nips-2003-Unsupervised_Color_Decomposition_Of_Histologically_Stained_Tissue_Samples.html">190 nips-2003-Unsupervised Color Decomposition Of Histologically Stained Tissue Samples</a></p>
<p>9 0.10854274 <a title="17-tfidf-9" href="./nips-2003-Bayesian_Color_Constancy_with_Non-Gaussian_Models.html">39 nips-2003-Bayesian Color Constancy with Non-Gaussian Models</a></p>
<p>10 0.08531446 <a title="17-tfidf-10" href="./nips-2003-Discriminative_Fields_for_Modeling_Spatial_Dependencies_in_Natural_Images.html">54 nips-2003-Discriminative Fields for Modeling Spatial Dependencies in Natural Images</a></p>
<p>11 0.076419346 <a title="17-tfidf-11" href="./nips-2003-Factorization_with_Uncertainty_and_Missing_Data%3A_Exploiting_Temporal_Coherence.html">69 nips-2003-Factorization with Uncertainty and Missing Data: Exploiting Temporal Coherence</a></p>
<p>12 0.072047569 <a title="17-tfidf-12" href="./nips-2003-Mutual_Boosting_for_Contextual_Inference.html">133 nips-2003-Mutual Boosting for Contextual Inference</a></p>
<p>13 0.070267498 <a title="17-tfidf-13" href="./nips-2003-A_Mixed-Signal_VLSI_for_Real-Time_Generation_of_Edge-Based_Image_Vectors.html">11 nips-2003-A Mixed-Signal VLSI for Real-Time Generation of Edge-Based Image Vectors</a></p>
<p>14 0.068508632 <a title="17-tfidf-14" href="./nips-2003-Non-linear_CCA_and_PCA_by_Alignment_of_Local_Models.html">138 nips-2003-Non-linear CCA and PCA by Alignment of Local Models</a></p>
<p>15 0.065211222 <a title="17-tfidf-15" href="./nips-2003-Gaussian_Process_Latent_Variable_Models_for_Visualisation_of_High_Dimensional_Data.html">77 nips-2003-Gaussian Process Latent Variable Models for Visualisation of High Dimensional Data</a></p>
<p>16 0.064685963 <a title="17-tfidf-16" href="./nips-2003-Linear_Response_for_Approximate_Inference.html">117 nips-2003-Linear Response for Approximate Inference</a></p>
<p>17 0.064092502 <a title="17-tfidf-17" href="./nips-2003-Towards_Social_Robots%3A_Automatic_Evaluation_of_Human-Robot_Interaction_by_Facial_Expression_Classification.html">186 nips-2003-Towards Social Robots: Automatic Evaluation of Human-Robot Interaction by Facial Expression Classification</a></p>
<p>18 0.063677691 <a title="17-tfidf-18" href="./nips-2003-Pairwise_Clustering_and_Graphical_Models.html">152 nips-2003-Pairwise Clustering and Graphical Models</a></p>
<p>19 0.062544882 <a title="17-tfidf-19" href="./nips-2003-Human_and_Ideal_Observers_for_Detecting_Image_Curves.html">85 nips-2003-Human and Ideal Observers for Detecting Image Curves</a></p>
<p>20 0.062232167 <a title="17-tfidf-20" href="./nips-2003-A_Kullback-Leibler_Divergence_Based_Kernel_for_SVM_Classification_in_Multimedia_Applications.html">9 nips-2003-A Kullback-Leibler Divergence Based Kernel for SVM Classification in Multimedia Applications</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2003_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.184), (1, -0.077), (2, 0.057), (3, -0.044), (4, -0.231), (5, -0.075), (6, 0.052), (7, -0.051), (8, 0.033), (9, -0.137), (10, -0.109), (11, 0.03), (12, -0.233), (13, 0.161), (14, -0.068), (15, -0.106), (16, -0.089), (17, 0.077), (18, -0.142), (19, 0.193), (20, 0.006), (21, 0.141), (22, -0.03), (23, -0.021), (24, -0.036), (25, 0.162), (26, 0.03), (27, -0.02), (28, 0.006), (29, -0.026), (30, 0.007), (31, -0.048), (32, 0.209), (33, -0.055), (34, 0.001), (35, 0.053), (36, -0.036), (37, -0.056), (38, 0.016), (39, 0.077), (40, 0.055), (41, 0.025), (42, -0.059), (43, 0.013), (44, -0.039), (45, -0.02), (46, 0.079), (47, -0.006), (48, 0.081), (49, 0.024)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98659807 <a title="17-lsi-1" href="./nips-2003-A_Sampled_Texture_Prior_for_Image_Super-Resolution.html">17 nips-2003-A Sampled Texture Prior for Image Super-Resolution</a></p>
<p>Author: Lyndsey C. Pickup, Stephen J. Roberts, Andrew Zisserman</p><p>Abstract: Super-resolution aims to produce a high-resolution image from a set of one or more low-resolution images by recovering or inventing plausible high-frequency image content. Typical approaches try to reconstruct a high-resolution image using the sub-pixel displacements of several lowresolution images, usually regularized by a generic smoothness prior over the high-resolution image space. Other methods use training data to learn low-to-high-resolution matches, and have been highly successful even in the single-input-image case. Here we present a domain-speciﬁc image prior in the form of a p.d.f. based upon sampled images, and show that for certain types of super-resolution problems, this sample-based prior gives a signiﬁcant improvement over other common multiple-image super-resolution techniques. 1</p><p>2 0.8233217 <a title="17-lsi-2" href="./nips-2003-A_Model_for_Learning_the_Semantics_of_Pictures.html">12 nips-2003-A Model for Learning the Semantics of Pictures</a></p>
<p>Author: Victor Lavrenko, R. Manmatha, Jiwoon Jeon</p><p>Abstract: We propose an approach to learning the semantics of images which allows us to automatically annotate an image with keywords and to retrieve images based on text queries. We do this using a formalism that models the generation of annotated images. We assume that every image is divided into regions, each described by a continuous-valued feature vector. Given a training set of images with annotations, we compute a joint probabilistic model of image features and words which allow us to predict the probability of generating a word given the image regions. This may be used to automatically annotate and retrieve images given a word as a query. Experiments show that our model signiﬁcantly outperforms the best of the previously reported results on the tasks of automatic image annotation and retrieval. 1</p><p>3 0.77779609 <a title="17-lsi-3" href="./nips-2003-Bayesian_Color_Constancy_with_Non-Gaussian_Models.html">39 nips-2003-Bayesian Color Constancy with Non-Gaussian Models</a></p>
<p>Author: Charles Rosenberg, Alok Ladsariya, Tom Minka</p><p>Abstract: We present a Bayesian approach to color constancy which utilizes a nonGaussian probabilistic model of the image formation process. The parameters of this model are estimated directly from an uncalibrated image set and a small number of additional algorithmic parameters are chosen using cross validation. The algorithm is empirically shown to exhibit RMS error lower than other color constancy algorithms based on the Lambertian surface reﬂectance model when estimating the illuminants of a set of test images. This is demonstrated via a direct performance comparison utilizing a publicly available set of real world test images and code base.</p><p>4 0.76733667 <a title="17-lsi-4" href="./nips-2003-Image_Reconstruction_by_Linear_Programming.html">88 nips-2003-Image Reconstruction by Linear Programming</a></p>
<p>Author: Koji Tsuda, Gunnar Rätsch</p><p>Abstract: A common way of image denoising is to project a noisy image to the subspace of admissible images made for instance by PCA. However, a major drawback of this method is that all pixels are updated by the projection, even when only a few pixels are corrupted by noise or occlusion. We propose a new method to identify the noisy pixels by 1 -norm penalization and update the identiﬁed pixels only. The identiﬁcation and updating of noisy pixels are formulated as one linear program which can be solved efﬁciently. Especially, one can apply the ν-trick to directly specify the fraction of pixels to be reconstructed. Moreover, we extend the linear program to be able to exploit prior knowledge that occlusions often appear in contiguous blocks (e.g. sunglasses on faces). The basic idea is to penalize boundary points and interior points of the occluded area differently. We are able to show the ν-property also for this extended LP leading a method which is easy to use. Experimental results impressively demonstrate the power of our approach.</p><p>5 0.56643498 <a title="17-lsi-5" href="./nips-2003-Nonlinear_Filtering_of_Electron_Micrographs_by_Means_of_Support_Vector_Regression.html">139 nips-2003-Nonlinear Filtering of Electron Micrographs by Means of Support Vector Regression</a></p>
<p>Author: Roland Vollgraf, Michael Scholz, Ian A. Meinertzhagen, Klaus Obermayer</p><p>Abstract: Nonlinear ﬁltering can solve very complex problems, but typically involve very time consuming calculations. Here we show that for ﬁlters that are constructed as a RBF network with Gaussian basis functions, a decomposition into linear ﬁlters exists, which can be computed eﬃciently in the frequency domain, yielding dramatic improvement in speed. We present an application of this idea to image processing. In electron micrograph images of photoreceptor terminals of the fruit ﬂy, Drosophila, synaptic vesicles containing neurotransmitter should be detected and labeled automatically. We use hand labels, provided by human experts, to learn a RBF ﬁlter using Support Vector Regression with Gaussian kernels. We will show that the resulting nonlinear ﬁlter solves the task to a degree of accuracy, which is close to what can be achieved by human experts. This allows the very time consuming task of data evaluation to be done eﬃciently. 1</p><p>6 0.56222045 <a title="17-lsi-6" href="./nips-2003-Unsupervised_Color_Decomposition_Of_Histologically_Stained_Tissue_Samples.html">190 nips-2003-Unsupervised Color Decomposition Of Histologically Stained Tissue Samples</a></p>
<p>7 0.5590896 <a title="17-lsi-7" href="./nips-2003-Local_Phase_Coherence_and_the_Perception_of_Blur.html">119 nips-2003-Local Phase Coherence and the Perception of Blur</a></p>
<p>8 0.5166803 <a title="17-lsi-8" href="./nips-2003-Discriminative_Fields_for_Modeling_Spatial_Dependencies_in_Natural_Images.html">54 nips-2003-Discriminative Fields for Modeling Spatial Dependencies in Natural Images</a></p>
<p>9 0.48216051 <a title="17-lsi-9" href="./nips-2003-Using_the_Forest_to_See_the_Trees%3A_A_Graphical_Model_Relating_Features%2C_Objects%2C_and_Scenes.html">192 nips-2003-Using the Forest to See the Trees: A Graphical Model Relating Features, Objects, and Scenes</a></p>
<p>10 0.4423618 <a title="17-lsi-10" href="./nips-2003-A_Mixed-Signal_VLSI_for_Real-Time_Generation_of_Edge-Based_Image_Vectors.html">11 nips-2003-A Mixed-Signal VLSI for Real-Time Generation of Edge-Based Image Vectors</a></p>
<p>11 0.41516805 <a title="17-lsi-11" href="./nips-2003-Feature_Selection_in_Clustering_Problems.html">73 nips-2003-Feature Selection in Clustering Problems</a></p>
<p>12 0.35528806 <a title="17-lsi-12" href="./nips-2003-Mutual_Boosting_for_Contextual_Inference.html">133 nips-2003-Mutual Boosting for Contextual Inference</a></p>
<p>13 0.34852141 <a title="17-lsi-13" href="./nips-2003-Non-linear_CCA_and_PCA_by_Alignment_of_Local_Models.html">138 nips-2003-Non-linear CCA and PCA by Alignment of Local Models</a></p>
<p>14 0.33414015 <a title="17-lsi-14" href="./nips-2003-Locality_Preserving_Projections.html">120 nips-2003-Locality Preserving Projections</a></p>
<p>15 0.33212173 <a title="17-lsi-15" href="./nips-2003-Factorization_with_Uncertainty_and_Missing_Data%3A_Exploiting_Temporal_Coherence.html">69 nips-2003-Factorization with Uncertainty and Missing Data: Exploiting Temporal Coherence</a></p>
<p>16 0.32654351 <a title="17-lsi-16" href="./nips-2003-When_Does_Non-Negative_Matrix_Factorization_Give_a_Correct_Decomposition_into_Parts%3F.html">195 nips-2003-When Does Non-Negative Matrix Factorization Give a Correct Decomposition into Parts?</a></p>
<p>17 0.31050968 <a title="17-lsi-17" href="./nips-2003-Human_and_Ideal_Observers_for_Detecting_Image_Curves.html">85 nips-2003-Human and Ideal Observers for Detecting Image Curves</a></p>
<p>18 0.30174294 <a title="17-lsi-18" href="./nips-2003-Gaussian_Process_Latent_Variable_Models_for_Visualisation_of_High_Dimensional_Data.html">77 nips-2003-Gaussian Process Latent Variable Models for Visualisation of High Dimensional Data</a></p>
<p>19 0.29763612 <a title="17-lsi-19" href="./nips-2003-Pairwise_Clustering_and_Graphical_Models.html">152 nips-2003-Pairwise Clustering and Graphical Models</a></p>
<p>20 0.26629212 <a title="17-lsi-20" href="./nips-2003-Salient_Boundary_Detection_using_Ratio_Contour.html">168 nips-2003-Salient Boundary Detection using Ratio Contour</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2003_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.032), (11, 0.111), (29, 0.025), (30, 0.025), (35, 0.033), (53, 0.108), (66, 0.013), (68, 0.285), (71, 0.067), (76, 0.052), (85, 0.06), (91, 0.085)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.81658405 <a title="17-lda-1" href="./nips-2003-A_Sampled_Texture_Prior_for_Image_Super-Resolution.html">17 nips-2003-A Sampled Texture Prior for Image Super-Resolution</a></p>
<p>Author: Lyndsey C. Pickup, Stephen J. Roberts, Andrew Zisserman</p><p>Abstract: Super-resolution aims to produce a high-resolution image from a set of one or more low-resolution images by recovering or inventing plausible high-frequency image content. Typical approaches try to reconstruct a high-resolution image using the sub-pixel displacements of several lowresolution images, usually regularized by a generic smoothness prior over the high-resolution image space. Other methods use training data to learn low-to-high-resolution matches, and have been highly successful even in the single-input-image case. Here we present a domain-speciﬁc image prior in the form of a p.d.f. based upon sampled images, and show that for certain types of super-resolution problems, this sample-based prior gives a signiﬁcant improvement over other common multiple-image super-resolution techniques. 1</p><p>2 0.80031902 <a title="17-lda-2" href="./nips-2003-An_MCMC-Based_Method_of_Comparing_Connectionist_Models_in_Cognitive_Science.html">25 nips-2003-An MCMC-Based Method of Comparing Connectionist Models in Cognitive Science</a></p>
<p>Author: Woojae Kim, Daniel J. Navarro, Mark A. Pitt, In J. Myung</p><p>Abstract: Despite the popularity of connectionist models in cognitive science, their performance can often be diﬃcult to evaluate. Inspired by the geometric approach to statistical model selection, we introduce a conceptually similar method to examine the global behavior of a connectionist model, by counting the number and types of response patterns it can simulate. The Markov Chain Monte Carlo-based algorithm that we constructed Þnds these patterns eﬃciently. We demonstrate the approach using two localist network models of speech perception. 1</p><p>3 0.78038162 <a title="17-lda-3" href="./nips-2003-Pairwise_Clustering_and_Graphical_Models.html">152 nips-2003-Pairwise Clustering and Graphical Models</a></p>
<p>Author: Noam Shental, Assaf Zomet, Tomer Hertz, Yair Weiss</p><p>Abstract: Signiﬁcant progress in clustering has been achieved by algorithms that are based on pairwise afﬁnities between the datapoints. In particular, spectral clustering methods have the advantage of being able to divide arbitrarily shaped clusters and are based on efﬁcient eigenvector calculations. However, spectral methods lack a straightforward probabilistic interpretation which makes it difﬁcult to automatically set parameters using training data. In this paper we use the previously proposed typical cut framework for pairwise clustering. We show an equivalence between calculating the typical cut and inference in an undirected graphical model. We show that for clustering problems with hundreds of datapoints exact inference may still be possible. For more complicated datasets, we show that loopy belief propagation (BP) and generalized belief propagation (GBP) can give excellent results on challenging clustering problems. We also use graphical models to derive a learning algorithm for afﬁnity matrices based on labeled data. 1</p><p>4 0.58529574 <a title="17-lda-4" href="./nips-2003-Semi-supervised_Protein_Classification_Using_Cluster_Kernels.html">173 nips-2003-Semi-supervised Protein Classification Using Cluster Kernels</a></p>
<p>Author: Jason Weston, Dengyong Zhou, André Elisseeff, William S. Noble, Christina S. Leslie</p><p>Abstract: A key issue in supervised protein classiﬁcation is the representation of input sequences of amino acids. Recent work using string kernels for protein data has achieved state-of-the-art classiﬁcation performance. However, such representations are based only on labeled data — examples with known 3D structures, organized into structural classes — while in practice, unlabeled data is far more plentiful. In this work, we develop simple and scalable cluster kernel techniques for incorporating unlabeled data into the representation of protein sequences. We show that our methods greatly improve the classiﬁcation performance of string kernels and outperform standard approaches for using unlabeled data, such as adding close homologs of the positive examples to the training data. We achieve equal or superior performance to previously presented cluster kernel methods while achieving far greater computational efﬁciency. 1</p><p>5 0.56843001 <a title="17-lda-5" href="./nips-2003-Image_Reconstruction_by_Linear_Programming.html">88 nips-2003-Image Reconstruction by Linear Programming</a></p>
<p>Author: Koji Tsuda, Gunnar Rätsch</p><p>Abstract: A common way of image denoising is to project a noisy image to the subspace of admissible images made for instance by PCA. However, a major drawback of this method is that all pixels are updated by the projection, even when only a few pixels are corrupted by noise or occlusion. We propose a new method to identify the noisy pixels by 1 -norm penalization and update the identiﬁed pixels only. The identiﬁcation and updating of noisy pixels are formulated as one linear program which can be solved efﬁciently. Especially, one can apply the ν-trick to directly specify the fraction of pixels to be reconstructed. Moreover, we extend the linear program to be able to exploit prior knowledge that occlusions often appear in contiguous blocks (e.g. sunglasses on faces). The basic idea is to penalize boundary points and interior points of the occluded area differently. We are able to show the ν-property also for this extended LP leading a method which is easy to use. Experimental results impressively demonstrate the power of our approach.</p><p>6 0.56214857 <a title="17-lda-6" href="./nips-2003-A_Model_for_Learning_the_Semantics_of_Pictures.html">12 nips-2003-A Model for Learning the Semantics of Pictures</a></p>
<p>7 0.56207454 <a title="17-lda-7" href="./nips-2003-Automatic_Annotation_of_Everyday_Movements.html">37 nips-2003-Automatic Annotation of Everyday Movements</a></p>
<p>8 0.54786205 <a title="17-lda-8" href="./nips-2003-Learning_Spectral_Clustering.html">107 nips-2003-Learning Spectral Clustering</a></p>
<p>9 0.52755088 <a title="17-lda-9" href="./nips-2003-Salient_Boundary_Detection_using_Ratio_Contour.html">168 nips-2003-Salient Boundary Detection using Ratio Contour</a></p>
<p>10 0.52566034 <a title="17-lda-10" href="./nips-2003-Discriminative_Fields_for_Modeling_Spatial_Dependencies_in_Natural_Images.html">54 nips-2003-Discriminative Fields for Modeling Spatial Dependencies in Natural Images</a></p>
<p>11 0.52458745 <a title="17-lda-11" href="./nips-2003-Learning_to_Find_Pre-Images.html">112 nips-2003-Learning to Find Pre-Images</a></p>
<p>12 0.52190006 <a title="17-lda-12" href="./nips-2003-A_Kullback-Leibler_Divergence_Based_Kernel_for_SVM_Classification_in_Multimedia_Applications.html">9 nips-2003-A Kullback-Leibler Divergence Based Kernel for SVM Classification in Multimedia Applications</a></p>
<p>13 0.52052385 <a title="17-lda-13" href="./nips-2003-Using_the_Forest_to_See_the_Trees%3A_A_Graphical_Model_Relating_Features%2C_Objects%2C_and_Scenes.html">192 nips-2003-Using the Forest to See the Trees: A Graphical Model Relating Features, Objects, and Scenes</a></p>
<p>14 0.5159446 <a title="17-lda-14" href="./nips-2003-Locality_Preserving_Projections.html">120 nips-2003-Locality Preserving Projections</a></p>
<p>15 0.51583552 <a title="17-lda-15" href="./nips-2003-Information_Dynamics_and_Emergent_Computation_in_Recurrent_Circuits_of_Spiking_Neurons.html">93 nips-2003-Information Dynamics and Emergent Computation in Recurrent Circuits of Spiking Neurons</a></p>
<p>16 0.51344907 <a title="17-lda-16" href="./nips-2003-Learning_with_Local_and_Global_Consistency.html">113 nips-2003-Learning with Local and Global Consistency</a></p>
<p>17 0.51308346 <a title="17-lda-17" href="./nips-2003-Non-linear_CCA_and_PCA_by_Alignment_of_Local_Models.html">138 nips-2003-Non-linear CCA and PCA by Alignment of Local Models</a></p>
<p>18 0.5130024 <a title="17-lda-18" href="./nips-2003-Nonlinear_Filtering_of_Electron_Micrographs_by_Means_of_Support_Vector_Regression.html">139 nips-2003-Nonlinear Filtering of Electron Micrographs by Means of Support Vector Regression</a></p>
<p>19 0.51149261 <a title="17-lda-19" href="./nips-2003-Denoising_and_Untangling_Graphs_Using_Degree_Priors.html">50 nips-2003-Denoising and Untangling Graphs Using Degree Priors</a></p>
<p>20 0.50973988 <a title="17-lda-20" href="./nips-2003-Measure_Based_Regularization.html">126 nips-2003-Measure Based Regularization</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
