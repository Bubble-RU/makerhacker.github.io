<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>92 nips-2003-Information Bottleneck for Gaussian Variables</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2003" href="../home/nips2003_home.html">nips2003</a> <a title="nips-2003-92" href="#">nips2003-92</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>92 nips-2003-Information Bottleneck for Gaussian Variables</h1>
<br/><p>Source: <a title="nips-2003-92-pdf" href="http://papers.nips.cc/paper/2457-information-bottleneck-for-gaussian-variables.pdf">pdf</a></p><p>Author: Gal Chechik, Amir Globerson, Naftali Tishby, Yair Weiss</p><p>Abstract: The problem of extracting the relevant aspects of data was addressed through the information bottleneck (IB) method, by (soft) clustering one variable while preserving information about another - relevance - variable. An interesting question addressed in the current work is the extension of these ideas to obtain continuous representations that preserve relevant information, rather than discrete clusters. We give a formal deﬁnition of the general continuous IB problem and obtain an analytic solution for the optimal representation for the important case of multivariate Gaussian variables. The obtained optimal representation is a noisy linear projection to eigenvectors of the normalized correlation matrix Σx|y Σ−1 , which x is also the basis obtained in Canonical Correlation Analysis. However, in Gaussian IB, the compression tradeoﬀ parameter uniquely determines the dimension, as well as the scale of each eigenvector. This introduces a novel interpretation where solutions of diﬀerent ranks lie on a continuum parametrized by the compression level. Our analysis also provides an analytic expression for the optimal tradeoﬀ - the information curve - in terms of the eigenvalue spectrum. 1</p><p>Reference: <a title="nips-2003-92-reference" href="../nips2003_reference/nips-2003-Information_Bottleneck_for_Gaussian_Variables_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ib', 0.477), ('gib', 0.269), ('tradeo', 0.268), ('bottleneck', 0.243), ('eigenvect', 0.239), ('compress', 0.235), ('cca', 0.22), ('nx', 0.159), ('imax', 0.154), ('relev', 0.139), ('ni', 0.139), ('project', 0.138), ('xy', 0.107), ('yb', 0.107), ('ya', 0.107), ('preserv', 0.106), ('eigenvalu', 0.105), ('curv', 0.095), ('cni', 0.092), ('yx', 0.092)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="92-tfidf-1" href="./nips-2003-Information_Bottleneck_for_Gaussian_Variables.html">92 nips-2003-Information Bottleneck for Gaussian Variables</a></p>
<p>2 0.35180646 <a title="92-tfidf-2" href="./nips-2003-Identifying_Structure_across_Pre-partitioned_Data.html">87 nips-2003-Identifying Structure across Pre-partitioned Data</a></p>
<p>3 0.15528104 <a title="92-tfidf-3" href="./nips-2003-Non-linear_CCA_and_PCA_by_Alignment_of_Local_Models.html">138 nips-2003-Non-linear CCA and PCA by Alignment of Local Models</a></p>
<p>4 0.1521809 <a title="92-tfidf-4" href="./nips-2003-Geometric_Clustering_Using_the_Information_Bottleneck_Method.html">82 nips-2003-Geometric Clustering Using the Information Bottleneck Method</a></p>
<p>5 0.1332275 <a title="92-tfidf-5" href="./nips-2003-Efficient_Multiscale_Sampling_from_Products_of_Gaussian_Mixtures.html">58 nips-2003-Efficient Multiscale Sampling from Products of Gaussian Mixtures</a></p>
<p>6 0.12023854 <a title="92-tfidf-6" href="./nips-2003-Limiting_Form_of_the_Sample_Covariance_Eigenspectrum_in_PCA_and_Kernel_PCA.html">114 nips-2003-Limiting Form of the Sample Covariance Eigenspectrum in PCA and Kernel PCA</a></p>
<p>7 0.11069844 <a title="92-tfidf-7" href="./nips-2003-Minimax_Embeddings.html">128 nips-2003-Minimax Embeddings</a></p>
<p>8 0.10709783 <a title="92-tfidf-8" href="./nips-2003-Out-of-Sample_Extensions_for_LLE%2C_Isomap%2C_MDS%2C_Eigenmaps%2C_and_Spectral_Clustering.html">150 nips-2003-Out-of-Sample Extensions for LLE, Isomap, MDS, Eigenmaps, and Spectral Clustering</a></p>
<p>9 0.10632706 <a title="92-tfidf-9" href="./nips-2003-Optimal_Manifold_Representation_of_Data%3A_An_Information_Theoretic_Approach.html">149 nips-2003-Optimal Manifold Representation of Data: An Information Theoretic Approach</a></p>
<p>10 0.10540764 <a title="92-tfidf-10" href="./nips-2003-Learning_Spectral_Clustering.html">107 nips-2003-Learning Spectral Clustering</a></p>
<p>11 0.10097911 <a title="92-tfidf-11" href="./nips-2003-Linear_Dependent_Dimensionality_Reduction.html">115 nips-2003-Linear Dependent Dimensionality Reduction</a></p>
<p>12 0.095935374 <a title="92-tfidf-12" href="./nips-2003-Kernel_Dimensionality_Reduction_for_Supervised_Learning.html">98 nips-2003-Kernel Dimensionality Reduction for Supervised Learning</a></p>
<p>13 0.088261545 <a title="92-tfidf-13" href="./nips-2003-Information_Maximization_in_Noisy_Channels_%3A_A_Variational_Approach.html">94 nips-2003-Information Maximization in Noisy Channels : A Variational Approach</a></p>
<p>14 0.084548593 <a title="92-tfidf-14" href="./nips-2003-Ranking_on_Data_Manifolds.html">164 nips-2003-Ranking on Data Manifolds</a></p>
<p>15 0.076288857 <a title="92-tfidf-15" href="./nips-2003-Error_Bounds_for_Transductive_Learning_via_Compression_and_Clustering.html">63 nips-2003-Error Bounds for Transductive Learning via Compression and Clustering</a></p>
<p>16 0.07530228 <a title="92-tfidf-16" href="./nips-2003-Reconstructing_MEG_Sources_with_Unknown_Correlations.html">166 nips-2003-Reconstructing MEG Sources with Unknown Correlations</a></p>
<p>17 0.074612521 <a title="92-tfidf-17" href="./nips-2003-Gene_Expression_Clustering_with_Functional_Mixture_Models.html">79 nips-2003-Gene Expression Clustering with Functional Mixture Models</a></p>
<p>18 0.072186954 <a title="92-tfidf-18" href="./nips-2003-Feature_Selection_in_Clustering_Problems.html">73 nips-2003-Feature Selection in Clustering Problems</a></p>
<p>19 0.071700528 <a title="92-tfidf-19" href="./nips-2003-Sample_Propagation.html">169 nips-2003-Sample Propagation</a></p>
<p>20 0.070277192 <a title="92-tfidf-20" href="./nips-2003-Log-Linear_Models_for_Label_Ranking.html">121 nips-2003-Log-Linear Models for Label Ranking</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2003_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.242), (1, 0.121), (2, -0.001), (3, -0.122), (4, -0.011), (5, -0.063), (6, -0.095), (7, 0.06), (8, 0.047), (9, 0.023), (10, -0.163), (11, -0.134), (12, 0.007), (13, 0.095), (14, 0.005), (15, 0.043), (16, 0.104), (17, -0.014), (18, 0.102), (19, 0.07), (20, 0.055), (21, -0.023), (22, 0.142), (23, 0.037), (24, 0.146), (25, 0.177), (26, 0.002), (27, 0.006), (28, -0.083), (29, 0.152), (30, 0.216), (31, -0.12), (32, 0.146), (33, 0.084), (34, 0.021), (35, -0.073), (36, -0.035), (37, 0.116), (38, -0.037), (39, -0.001), (40, 0.061), (41, -0.287), (42, 0.017), (43, -0.158), (44, 0.117), (45, -0.24), (46, 0.027), (47, -0.121), (48, -0.019), (49, -0.062)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92151558 <a title="92-lsi-1" href="./nips-2003-Information_Bottleneck_for_Gaussian_Variables.html">92 nips-2003-Information Bottleneck for Gaussian Variables</a></p>
<p>2 0.53046966 <a title="92-lsi-2" href="./nips-2003-Identifying_Structure_across_Pre-partitioned_Data.html">87 nips-2003-Identifying Structure across Pre-partitioned Data</a></p>
<p>3 0.44844091 <a title="92-lsi-3" href="./nips-2003-Non-linear_CCA_and_PCA_by_Alignment_of_Local_Models.html">138 nips-2003-Non-linear CCA and PCA by Alignment of Local Models</a></p>
<p>4 0.43962649 <a title="92-lsi-4" href="./nips-2003-Kernel_Dimensionality_Reduction_for_Supervised_Learning.html">98 nips-2003-Kernel Dimensionality Reduction for Supervised Learning</a></p>
<p>5 0.43189153 <a title="92-lsi-5" href="./nips-2003-Optimal_Manifold_Representation_of_Data%3A_An_Information_Theoretic_Approach.html">149 nips-2003-Optimal Manifold Representation of Data: An Information Theoretic Approach</a></p>
<p>6 0.38926071 <a title="92-lsi-6" href="./nips-2003-Efficient_Multiscale_Sampling_from_Products_of_Gaussian_Mixtures.html">58 nips-2003-Efficient Multiscale Sampling from Products of Gaussian Mixtures</a></p>
<p>7 0.37232444 <a title="92-lsi-7" href="./nips-2003-Geometric_Clustering_Using_the_Information_Bottleneck_Method.html">82 nips-2003-Geometric Clustering Using the Information Bottleneck Method</a></p>
<p>8 0.35759023 <a title="92-lsi-8" href="./nips-2003-Linear_Dependent_Dimensionality_Reduction.html">115 nips-2003-Linear Dependent Dimensionality Reduction</a></p>
<p>9 0.34780866 <a title="92-lsi-9" href="./nips-2003-Minimax_Embeddings.html">128 nips-2003-Minimax Embeddings</a></p>
<p>10 0.3269048 <a title="92-lsi-10" href="./nips-2003-Locality_Preserving_Projections.html">120 nips-2003-Locality Preserving Projections</a></p>
<p>11 0.3091515 <a title="92-lsi-11" href="./nips-2003-Information_Maximization_in_Noisy_Channels_%3A_A_Variational_Approach.html">94 nips-2003-Information Maximization in Noisy Channels : A Variational Approach</a></p>
<p>12 0.29871142 <a title="92-lsi-12" href="./nips-2003-Limiting_Form_of_the_Sample_Covariance_Eigenspectrum_in_PCA_and_Kernel_PCA.html">114 nips-2003-Limiting Form of the Sample Covariance Eigenspectrum in PCA and Kernel PCA</a></p>
<p>13 0.29485959 <a title="92-lsi-13" href="./nips-2003-Sample_Propagation.html">169 nips-2003-Sample Propagation</a></p>
<p>14 0.28453201 <a title="92-lsi-14" href="./nips-2003-Error_Bounds_for_Transductive_Learning_via_Compression_and_Clustering.html">63 nips-2003-Error Bounds for Transductive Learning via Compression and Clustering</a></p>
<p>15 0.26792079 <a title="92-lsi-15" href="./nips-2003-Convex_Methods_for_Transduction.html">48 nips-2003-Convex Methods for Transduction</a></p>
<p>16 0.26439118 <a title="92-lsi-16" href="./nips-2003-AUC_Optimization_vs._Error_Rate_Minimization.html">3 nips-2003-AUC Optimization vs. Error Rate Minimization</a></p>
<p>17 0.26375881 <a title="92-lsi-17" href="./nips-2003-Extreme_Components_Analysis.html">66 nips-2003-Extreme Components Analysis</a></p>
<p>18 0.26173884 <a title="92-lsi-18" href="./nips-2003-Out-of-Sample_Extensions_for_LLE%2C_Isomap%2C_MDS%2C_Eigenmaps%2C_and_Spectral_Clustering.html">150 nips-2003-Out-of-Sample Extensions for LLE, Isomap, MDS, Eigenmaps, and Spectral Clustering</a></p>
<p>19 0.25718802 <a title="92-lsi-19" href="./nips-2003-Gene_Expression_Clustering_with_Functional_Mixture_Models.html">79 nips-2003-Gene Expression Clustering with Functional Mixture Models</a></p>
<p>20 0.25366303 <a title="92-lsi-20" href="./nips-2003-Approximability_of_Probability_Distributions.html">30 nips-2003-Approximability of Probability Distributions</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2003_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.07), (11, 0.012), (26, 0.011), (31, 0.035), (53, 0.168), (58, 0.063), (62, 0.09), (70, 0.268), (71, 0.03), (76, 0.143), (85, 0.011), (95, 0.011)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.86422038 <a title="92-lda-1" href="./nips-2003-Reasoning_about_Time_and_Knowledge_in_Neural_Symbolic_Learning_Systems.html">165 nips-2003-Reasoning about Time and Knowledge in Neural Symbolic Learning Systems</a></p>
<p>same-paper 2 0.79565364 <a title="92-lda-2" href="./nips-2003-Information_Bottleneck_for_Gaussian_Variables.html">92 nips-2003-Information Bottleneck for Gaussian Variables</a></p>
<p>3 0.72138429 <a title="92-lda-3" href="./nips-2003-Learning_Bounds_for_a_Generalized_Family_of_Bayesian_Posterior_Distributions.html">103 nips-2003-Learning Bounds for a Generalized Family of Bayesian Posterior Distributions</a></p>
<p>4 0.71937597 <a title="92-lda-4" href="./nips-2003-Identifying_Structure_across_Pre-partitioned_Data.html">87 nips-2003-Identifying Structure across Pre-partitioned Data</a></p>
<p>5 0.67819679 <a title="92-lda-5" href="./nips-2003-Locality_Preserving_Projections.html">120 nips-2003-Locality Preserving Projections</a></p>
<p>6 0.67802316 <a title="92-lda-6" href="./nips-2003-Extreme_Components_Analysis.html">66 nips-2003-Extreme Components Analysis</a></p>
<p>7 0.67651111 <a title="92-lda-7" href="./nips-2003-Computing_Gaussian_Mixture_Models_with_EM_Using_Equivalence_Constraints.html">47 nips-2003-Computing Gaussian Mixture Models with EM Using Equivalence Constraints</a></p>
<p>8 0.6747641 <a title="92-lda-8" href="./nips-2003-Limiting_Form_of_the_Sample_Covariance_Eigenspectrum_in_PCA_and_Kernel_PCA.html">114 nips-2003-Limiting Form of the Sample Covariance Eigenspectrum in PCA and Kernel PCA</a></p>
<p>9 0.67324346 <a title="92-lda-9" href="./nips-2003-Geometric_Clustering_Using_the_Information_Bottleneck_Method.html">82 nips-2003-Geometric Clustering Using the Information Bottleneck Method</a></p>
<p>10 0.6728276 <a title="92-lda-10" href="./nips-2003-Feature_Selection_in_Clustering_Problems.html">73 nips-2003-Feature Selection in Clustering Problems</a></p>
<p>11 0.67193627 <a title="92-lda-11" href="./nips-2003-Clustering_with_the_Connectivity_Kernel.html">46 nips-2003-Clustering with the Connectivity Kernel</a></p>
<p>12 0.67051303 <a title="92-lda-12" href="./nips-2003-Measure_Based_Regularization.html">126 nips-2003-Measure Based Regularization</a></p>
<p>13 0.66885149 <a title="92-lda-13" href="./nips-2003-Convex_Methods_for_Transduction.html">48 nips-2003-Convex Methods for Transduction</a></p>
<p>14 0.66673315 <a title="92-lda-14" href="./nips-2003-Minimax_Embeddings.html">128 nips-2003-Minimax Embeddings</a></p>
<p>15 0.66651058 <a title="92-lda-15" href="./nips-2003-Learning_the_k_in_k-means.html">111 nips-2003-Learning the k in k-means</a></p>
<p>16 0.66420275 <a title="92-lda-16" href="./nips-2003-Non-linear_CCA_and_PCA_by_Alignment_of_Local_Models.html">138 nips-2003-Non-linear CCA and PCA by Alignment of Local Models</a></p>
<p>17 0.66306633 <a title="92-lda-17" href="./nips-2003-Kernel_Dimensionality_Reduction_for_Supervised_Learning.html">98 nips-2003-Kernel Dimensionality Reduction for Supervised Learning</a></p>
<p>18 0.66009891 <a title="92-lda-18" href="./nips-2003-Learning_a_Distance_Metric_from_Relative_Comparisons.html">108 nips-2003-Learning a Distance Metric from Relative Comparisons</a></p>
<p>19 0.65973604 <a title="92-lda-19" href="./nips-2003-Image_Reconstruction_by_Linear_Programming.html">88 nips-2003-Image Reconstruction by Linear Programming</a></p>
<p>20 0.65971428 <a title="92-lda-20" href="./nips-2003-Optimal_Manifold_Representation_of_Data%3A_An_Information_Theoretic_Approach.html">149 nips-2003-Optimal Manifold Representation of Data: An Information Theoretic Approach</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
