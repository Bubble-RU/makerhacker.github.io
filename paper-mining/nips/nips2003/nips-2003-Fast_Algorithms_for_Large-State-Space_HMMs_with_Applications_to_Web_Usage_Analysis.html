<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>70 nips-2003-Fast Algorithms for Large-State-Space HMMs with Applications to Web Usage Analysis</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2003" href="../home/nips2003_home.html">nips2003</a> <a title="nips-2003-70" href="#">nips2003-70</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>70 nips-2003-Fast Algorithms for Large-State-Space HMMs with Applications to Web Usage Analysis</h1>
<br/><p>Source: <a title="nips-2003-70-pdf" href="http://papers.nips.cc/paper/2525-fast-algorithms-for-large-state-space-hmms-with-applications-to-web-usage-analysis.pdf">pdf</a></p><p>Author: Pedro F. Felzenszwalb, Daniel P. Huttenlocher, Jon M. Kleinberg</p><p>Abstract: In applying Hidden Markov Models to the analysis of massive data streams, it is often necessary to use an artiﬁcially reduced set of states; this is due in large part to the fact that the basic HMM estimation algorithms have a quadratic dependence on the size of the state set. We present algorithms that reduce this computational bottleneck to linear or near-linear time, when the states can be embedded in an underlying grid of parameters. This type of state representation arises in many domains; in particular, we show an application to traﬃc analysis at a high-volume Web site. 1</p><p>Reference: <a title="nips-2003-70-reference" href="../nips2003_reference/nips-2003-Fast_Algorithms_for_Large-State-Space_HMMs_with_Applications_to_Web_Usage_Analysis_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 We present algorithms that reduce this computational bottleneck to linear or near-linear time, when the states can be embedded in an underlying grid of parameters. [sent-6, score-0.425]
</p><p>2 This type of state representation arises in many domains; in particular, we show an application to traﬃc analysis at a high-volume Web site. [sent-7, score-0.193]
</p><p>3 1  Introduction  Hidden Markov Models (HMMs) are used in a wide variety of applications where a sequence of observable events is correlated with or caused by a sequence of unobservable underlying states (e. [sent-8, score-0.523]
</p><p>4 Despite their broad applicability, HMMs are in practice limited to problems where the number of hidden states is relatively small. [sent-11, score-0.224]
</p><p>5 Recently, however, issues arising in massive data streams, such as the analysis of usage logs at hightraﬃc Web sites, have led to problems that call naturally for HMMs with large state sets over very long input sequences. [sent-13, score-0.408]
</p><p>6 The quadratic dependence on the number of states is a long-standing bottleneck that necessitates a small (often artiﬁcially coarsened) state set, particularly when the length T of the input is large. [sent-15, score-0.364]
</p><p>7 Given a structured embedding of states in an underlying d-dimensional space, our approach is to reduce the amount of work in the dynamic programming iterations of the Viterbi and forward-backward algorithms. [sent-23, score-0.248]
</p><p>8 For the Viterbi algorithm, we make use of distance transform (also known as Voronoi surface) techniques, which are widely used in computer vision, image processing, and discrete computational geometry [2]. [sent-24, score-0.304]
</p><p>9 For a broad class of distance functions on the embedding space (including functions that are far from obeying the triangle inequality), we are able to run each dynamic programming step of the Viterbi algorithm in O(n) time, yielding an overall running time of O(T n). [sent-25, score-0.42]
</p><p>10 In the case of the forward-backward algorithm, we are able to achieve O(T n) time for any transition probabilities that can be decomposed into a constant number of box ﬁlters [10]. [sent-26, score-0.369]
</p><p>11 Box ﬁlters are discrete convolution kernels that can be computed in linear time; many functions, including the Gaussian, can be expressed or approximated as the composition of a few box ﬁlters. [sent-27, score-0.337]
</p><p>12 Moreover, in the case of the forward-backward algorithm, we are able to obtain a running time of O(T n log n) for arbitrary state transition probabilities, as long as they are based only on diﬀerences in the embedded positions of the states. [sent-28, score-0.458]
</p><p>13 org) as a prototypical example of a high-traﬃc site (millions of page-visits per month) oﬀering an array of digital items for download. [sent-32, score-0.275]
</p><p>14 An important question at such a site is to determine variations in user interest in the items being oﬀered. [sent-33, score-0.392]
</p><p>15 We use a coin-tossing HMM model in which the discrete states correspond to the current probability of a user downloading a given item; this state set has a natural embedding in the interval [0, 1]. [sent-34, score-0.672]
</p><p>16 We study the eﬀect of increasing the number of states, and ﬁnd that a fairly large state set (of size roughly a hundred or more) is needed in order to detect brief but signiﬁcant events that aﬀect the download rate. [sent-35, score-0.555]
</p><p>17 With tens of millions of observations and a state set of this size, practical analysis would be computationally prohibitive without the faster HMM algorithms described here. [sent-36, score-0.278]
</p><p>18 The methods are also applicable to continuous Markov models, which have recently been employed for Web user modeling based on duration of page views [9]. [sent-40, score-0.183]
</p><p>19 FFT  Table 1: Some transition probabilities that can be handled eﬃciently using our techniques (see text for an explanation). [sent-59, score-0.235]
</p><p>20 Let qt denote the state of the system at time t, while ot denotes the observed symbol at time t. [sent-62, score-0.599]
</p><p>21 Compute P (O|λ), the probability of an observation sequence being generated by λ. [sent-72, score-0.165]
</p><p>22 Compute the posterior probabilities of each state, P (qt = si |O, λ). [sent-74, score-0.178]
</p><p>23 We show how to solve them more eﬃciently for a wide range of transition probabilities based on diﬀerences between states that are embedded in an underlying grid. [sent-76, score-0.446]
</p><p>24 This grid can be multi-dimensional, however in this paper we consider only the one-dimensional case. [sent-77, score-0.127]
</p><p>25 Table 1 lists some widely applicable transition probability distributions that can be handled by our methods. [sent-78, score-0.178]
</p><p>26 1  Viterbi Algorithm  The Viterbi algorithm is used to ﬁnd a maximum posterior probability state sequence, that is a sequence Q = (q1 , . [sent-89, score-0.319]
</p><p>27 While there are an exponential number of possible paths, the Viterbi algorithm uses a dynamic programming approach  Figure 1: An example of the L1 distance transform for a grid with n = 9 points containing the point set P = {1, 3, 7}. [sent-94, score-0.363]
</p><p>28 The distance transform value at each point is given by the height of the lower envelope, depicted as a dashed contour. [sent-95, score-0.273]
</p><p>29 , [8]), employing the recursive equation δt+1 (j) = bj (ot+1 ) max (δt (i)aij ) , i  where δt (i), for i = 1, 2, . [sent-98, score-0.107]
</p><p>30 , n, encodes the highest probability along a path which accounts for the ﬁrst t observations and ends in state si . [sent-101, score-0.356]
</p><p>31 The maximization term takes O(n2 ) time, resulting in an overall time of O(T n2 ) for a sequence of length T . [sent-102, score-0.139]
</p><p>32 Computing δt for each time step is only the ﬁrst pass of the Viterbi algorithm. [sent-103, score-0.161]
</p><p>33 This takes only O(T n) time, so the forward computation is the dominant part of the running time. [sent-105, score-0.119]
</p><p>34 In general a variant of the Viterbi algorithm is employed that uses negative log probabilities rather than probabilities, such that the computation becomes δt+1 (j) = bj (ot+1 ) + mini (δt (i) + aij ), where is used to denote a negative log probability. [sent-106, score-0.488]
</p><p>35 We now turn to the computation of δ for restricted forms of the transition costs aij , where there is an underlying parameter space such that the costs can be expressed in terms of a distance between parameter values corresponding to the states. [sent-107, score-0.702]
</p><p>36 Then, δt+1 (j) = bj (ot+1 ) + min (δt (i) + ρ(i − j)) . [sent-109, score-0.158]
</p><p>37 The approach is based on a generalization of the distance transform, which is deﬁned for sets of points on a grid. [sent-111, score-0.113]
</p><p>38 Consider a grid with N locations and a point set P on that grid. [sent-112, score-0.127]
</p><p>39 The distance transform of P speciﬁes for each grid location, the distance to the closest point in the set P , DP (j) = min ρ(i − j). [sent-113, score-0.527]
</p><p>40 i∈P  Clearly the distance transform can be computed in O(N 2 ) time by considering all pairs of grid locations. [sent-114, score-0.419]
</p><p>41 However, it can also be computed in linear time for many distance functions using simple algorithms (e. [sent-115, score-0.201]
</p><p>42 The algorithms work for distance transforms of d-dimensional grids, not just for the one-dimensional case that we illustrate here. [sent-119, score-0.164]
</p><p>43 In order to compute the distance transform eﬃciently it is commonly expressed as, DP (j) = min (ρ(i − j) + 1(i)) , i  where 1(i) is an indicator function for the set P such that 1(i) = 0 when i ∈ P and 1(i) = ∞ otherwise. [sent-120, score-0.325]
</p><p>44 Intuitively one can think of a collection of upward facing cones, one rooted at each grid location that is in the set P . [sent-121, score-0.166]
</p><p>45 The transform is then obtained by taking the lower envelope (or minimum) of these cones. [sent-122, score-0.177]
</p><p>46 For concreteness consider  the one-dimensional case with the L1 distance between grid locations. [sent-123, score-0.24]
</p><p>47 In this case the “cones” are v-shapes of slope 1 rising from the value y = 0 at each grid location that corresponds to a point of the set P , as illustrated in Figure 1. [sent-124, score-0.127]
</p><p>48 It is straightforward to verify that a simple two-pass algorithm correctly computes this one-dimensional distance transform. [sent-125, score-0.113]
</p><p>49 After the initialization step the value of D is (∞, 0, ∞, 0, ∞, ∞, ∞, 0, ∞), after the forward pass it is (∞, 0, 1, 0, 1, 2, 3, 0, 1) and after the backward pass the ﬁnal answer of (1, 0, 1, 0, 1, 2, 1, 0, 1). [sent-137, score-0.337]
</p><p>50 This computation of the distance transform does not depend on the form of the function 1(i). [sent-138, score-0.236]
</p><p>51 This suggests a generalization of distance transforms where the indicator function 1(i) is replaced with an arbitrary function, Df (j) = min (ρ(i − j) + f (i)) . [sent-139, score-0.215]
</p><p>52 i  The same observation was used in [4] to eﬃciently compute certain tree-based cost functions for visual recognition of multi-part objects. [sent-140, score-0.137]
</p><p>53 Intuitively, the upward-facing cones are now rooted at height f (i) rather than at zero, and are positioned at every grid location. [sent-141, score-0.276]
</p><p>54 This generalized distance transform Df is precisely the form of the minimization term in the computation of the Viterbi recursion δ in equation (1), where each state corresponds to a grid point. [sent-143, score-0.556]
</p><p>55 The computation for the second row of the table is similar, except that computing the distance transform for the L2 distance squared is a bit more involved (see [5]). [sent-146, score-0.427]
</p><p>56 The distribution in the ﬁrst row of the table can be handled using a linear time algorithm for the min-ﬁlter [3]. [sent-147, score-0.182]
</p><p>57 The function in the fourth row is often of practical interest, where the probability is p of staying near the current state and q of transitioning to any other state. [sent-150, score-0.277]
</p><p>58 2  Forward-Backward Algorithm  The forward-backward algorithm is used to ﬁnd the probability of the observed sequence given the the model, P (O|λ). [sent-154, score-0.126]
</p><p>59 The computation also determines the posterior probability of the states at each time, P (qt = si |O, λ). [sent-155, score-0.253]
</p><p>60 Most of the work in the forward-backward algorithm is spent in determining the so-called forward and backward probabilities at each step (again see [8] or any other introduction to HMMs). [sent-156, score-0.341]
</p><p>61 The forward probabilities at a given time can be expressed as the n-vector αt (i) = P (o1 , o2 , . [sent-157, score-0.255]
</p><p>62 , the probability of the partial observation sequence up until time t and the state at time t, given the model. [sent-162, score-0.47]
</p><p>63 The backward probabilities βt can be expressed analogously and are not considered here. [sent-163, score-0.239]
</p><p>64 The standard computation is to express the vector αt recursively as n  αt+1 (j) = bj (ot+1 )  (αt (i)aij ) . [sent-164, score-0.107]
</p><p>65 When the transition probabilities are based just on the diﬀerences between the underlying coordinates corresponding to the states, aij = h(j − i), the recursive computation of α becomes n  αt+1 (j) = bj (ot+1 )  (αt (i)h(j − i)) . [sent-166, score-0.638]
</p><p>66 i=1  The summation term is simply the convolution of αt with h. [sent-167, score-0.105]
</p><p>67 In general, this discrete convolution can be computed in O(n log n) time using the FFT. [sent-168, score-0.229]
</p><p>68 While this is a simple observation, it enables eﬃcient calculation of the forward and backward probabilities for problems where the states are embedded in a grid. [sent-169, score-0.458]
</p><p>69 One case of particular interest is the so-called box sum, in which the convolution kernel is a constant function within a region. [sent-171, score-0.274]
</p><p>70 A Gaussian can be well approximated by convolution of just a few such box ﬁlters [10], and thus it is possible to approximately compute the functions in the ﬁrst and second rows of Figure 1 in O(T n) time. [sent-173, score-0.263]
</p><p>71 3  Coin-Tossing Models and Web Usage Analysis  We now turn to the application mentioned in the introduction: using a coin-tossing model with a one-dimensional embedding of states to estimate the download probability of items at a Web site. [sent-176, score-0.529]
</p><p>72 Our data comes from the Internet Archive site (www. [sent-177, score-0.174]
</p><p>73 Each item on the site has a separate description page, which contains the option to download it; this is similar to the paper description pages on CiteSeer or the e-print arXiv and to the item description pages at online retailers (with the option to purchase). [sent-180, score-1.101]
</p><p>74 On a site of this type, the probability that a user chooses to acquire an item, conditioned on having visited the description page, can be viewed as a measure of interest [1]. [sent-181, score-0.435]
</p><p>75 This ratio of acquisitions to visits is particularly useful as a way of tracking the changes in user interest in an item. [sent-182, score-0.275]
</p><p>76 By identifying such discrete changes, we can discover the most signiﬁcant events, both on the site and on the Web at large, that have aﬀected user interest in each item. [sent-184, score-0.401]
</p><p>77 Such a history of events can be useful to site administrators, as feedback to the users of the site, and for researchers. [sent-185, score-0.343]
</p><p>78 For a ﬁxed item, each observation corresponds to a user’s visit to the item description,  0. [sent-187, score-0.383]
</p><p>79 05e+09  Figure 2: Estimate of underlying download bias; best state sequence for models with step sizes of . [sent-221, score-0.616]
</p><p>80 and there are two observable symbols V = {1, 0}, corresponding to the decision to download or not. [sent-224, score-0.318]
</p><p>81 We assume a model in which there is a hidden coin of some unknown bias that is ﬂipped when the user visits the description and whose outcome determines the download decision. [sent-225, score-0.63]
</p><p>82 Thus, each state si corresponds to a discretized value pi of the underlying bias parameter. [sent-226, score-0.435]
</p><p>83 The natural observation cost function bi (k) is simply the negative log of the probability p for a head and (1 − p) for a tail. [sent-227, score-0.16]
</p><p>84 The points at which state transitions occur in the optimal state sequence thus become candidates for discrete changes in user interest. [sent-228, score-0.708]
</p><p>85 The form of the state transition costs is based on our assumptions about the nature of these changes. [sent-229, score-0.34]
</p><p>86 We quantize the underlying bias parameter values equally, such that |pi −pj | ∝ |i−j| and use a cost function of the form aij = min (k1 |i − j|, k2 |i − j| + k3 ) , where the ki are positive constants and k1 > k2 . [sent-231, score-0.53]
</p><p>87 The model prefers constant or small changes in bias but allows for arbitrarily large changes, similarly to the “truncated model” common in robust statistics. [sent-233, score-0.156]
</p><p>88 Figure 2 shows the best state sequence obtained with the Viterbi algorithm under this model, using two diﬀerent discretizations of the parameter space, for an input sequence of 11, 159 visits from August 2002 to April 2003 to the description page for a particular video in the Internet Archive. [sent-234, score-0.546]
</p><p>89 The x-axis shows the visit time (UTC in billions of seconds since the epoch) and the y-axis shows the bias associated with the state in the optimal sequence at that time. [sent-243, score-0.562]
</p><p>90 We begin by observing that both models capture a number of discrete changes in download behavior. [sent-244, score-0.365]
</p><p>91 In particular, both models capture the long-term drop and rebound in bias which corresponds to the time period where the item was highlighted on a top-level page, as well as the two rightmost short downward spikes which correspond to technical problems that made downloads temporarily impossible. [sent-246, score-0.471]
</p><p>92 The two plots, however, exhibit some subtle but important diﬀerences that illustrate the qualitatively greater power we obtain from a larger state set. [sent-248, score-0.193]
</p><p>93 In particular, the 81-state model has four short downward spikes rather than three in the time interval from 1. [sent-249, score-0.152]
</p><p>94 The latter two are the technical failures identiﬁed by both models, but the ﬁrst two correspond to two distinct oﬀ-site referring pages each of which drove a signiﬁcant amount of low-interest user traﬃc to the item. [sent-252, score-0.219]
</p><p>95 While the 81-state model was able to resolve these as separate events, the 9-state model blurs them into an artiﬁcial period of medium bias, followed by a downward spike to the lowest possible state (i. [sent-253, score-0.257]
</p><p>96 the same state it used for the technical failures). [sent-255, score-0.193]
</p><p>97 Finally, the 81-state model discovers a gradual decline in the download rate near the end of the plot that is not visible when there are fewer states. [sent-256, score-0.242]
</p><p>98 We see that a model with a larger state set is able to pick up the eﬀects of diﬀerent types of events — both on-site and oﬀ-site highlighting of the item, as well as technical problems — and that these events often result in sudden, discrete changes. [sent-257, score-0.501]
</p><p>99 Moreover, it appears that beyond a certain point, the set of signiﬁcant events remains roughly ﬁxed even as the resolution in the state set increases. [sent-258, score-0.313]
</p><p>100 001 produces a plot that is qualitatively indistinguishable from the 81 state model with step size . [sent-260, score-0.228]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('viterbi', 0.318), ('aij', 0.281), ('download', 0.242), ('item', 0.215), ('state', 0.193), ('hmms', 0.187), ('ot', 0.182), ('site', 0.174), ('states', 0.132), ('visit', 0.129), ('web', 0.128), ('grid', 0.127), ('box', 0.126), ('transform', 0.123), ('events', 0.12), ('user', 0.116), ('distance', 0.113), ('qt', 0.112), ('bj', 0.107), ('tra', 0.107), ('convolution', 0.105), ('backward', 0.101), ('bias', 0.101), ('probabilities', 0.1), ('hmm', 0.094), ('transition', 0.087), ('di', 0.086), ('sequence', 0.083), ('erences', 0.082), ('si', 0.078), ('usage', 0.075), ('internet', 0.073), ('cones', 0.073), ('pass', 0.07), ('failures', 0.068), ('fft', 0.068), ('discrete', 0.068), ('page', 0.067), ('lters', 0.067), ('downward', 0.064), ('embedded', 0.064), ('underlying', 0.063), ('visits', 0.061), ('forward', 0.061), ('costs', 0.06), ('description', 0.059), ('items', 0.059), ('df', 0.059), ('running', 0.058), ('time', 0.056), ('changes', 0.055), ('envelope', 0.054), ('huttenlocher', 0.054), ('logs', 0.054), ('rabiner', 0.054), ('sudden', 0.054), ('embedding', 0.053), ('min', 0.051), ('hidden', 0.051), ('transforms', 0.051), ('erent', 0.049), ('users', 0.049), ('archive', 0.049), ('massive', 0.049), ('handled', 0.048), ('bi', 0.044), ('determining', 0.044), ('probability', 0.043), ('obstacle', 0.043), ('millions', 0.043), ('interest', 0.043), ('observations', 0.042), ('observable', 0.042), ('digital', 0.042), ('row', 0.041), ('ect', 0.041), ('broad', 0.041), ('primitives', 0.041), ('pami', 0.041), ('markov', 0.039), ('cially', 0.039), ('option', 0.039), ('rooted', 0.039), ('bottleneck', 0.039), ('dp', 0.039), ('observation', 0.039), ('expressed', 0.038), ('height', 0.037), ('arising', 0.037), ('table', 0.037), ('step', 0.035), ('streams', 0.035), ('correspond', 0.035), ('cost', 0.034), ('symbols', 0.034), ('applicability', 0.033), ('interval', 0.032), ('entries', 0.032), ('functions', 0.032), ('recognition', 0.032)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999988 <a title="70-tfidf-1" href="./nips-2003-Fast_Algorithms_for_Large-State-Space_HMMs_with_Applications_to_Web_Usage_Analysis.html">70 nips-2003-Fast Algorithms for Large-State-Space HMMs with Applications to Web Usage Analysis</a></p>
<p>Author: Pedro F. Felzenszwalb, Daniel P. Huttenlocher, Jon M. Kleinberg</p><p>Abstract: In applying Hidden Markov Models to the analysis of massive data streams, it is often necessary to use an artiﬁcially reduced set of states; this is due in large part to the fact that the basic HMM estimation algorithms have a quadratic dependence on the size of the state set. We present algorithms that reduce this computational bottleneck to linear or near-linear time, when the states can be embedded in an underlying grid of parameters. This type of state representation arises in many domains; in particular, we show an application to traﬃc analysis at a high-volume Web site. 1</p><p>2 0.16074051 <a title="70-tfidf-2" href="./nips-2003-Inferring_State_Sequences_for_Non-linear_Systems_with_Embedded_Hidden_Markov_Models.html">91 nips-2003-Inferring State Sequences for Non-linear Systems with Embedded Hidden Markov Models</a></p>
<p>Author: Radford M. Neal, Matthew J. Beal, Sam T. Roweis</p><p>Abstract: We describe a Markov chain method for sampling from the distribution of the hidden state sequence in a non-linear dynamical system, given a sequence of observations. This method updates all states in the sequence simultaneously using an embedded Hidden Markov Model (HMM). An update begins with the creation of “pools” of candidate states at each time. We then deﬁne an embedded HMM whose states are indexes within these pools. Using a forward-backward dynamic programming algorithm, we can efﬁciently choose a state sequence with the appropriate probabilities from the exponentially large number of state sequences that pass through states in these pools. We illustrate the method in a simple one-dimensional example, and in an example showing how an embedded HMM can be used to in effect discretize the state space without any discretization error. We also compare the embedded HMM to a particle smoother on a more substantial problem of inferring human motion from 2D traces of markers. 1</p><p>3 0.11383439 <a title="70-tfidf-3" href="./nips-2003-Approximate_Planning_in_POMDPs_with_Macro-Actions.html">33 nips-2003-Approximate Planning in POMDPs with Macro-Actions</a></p>
<p>Author: Georgios Theocharous, Leslie P. Kaelbling</p><p>Abstract: Recent research has demonstrated that useful POMDP solutions do not require consideration of the entire belief space. We extend this idea with the notion of temporal abstraction. We present and explore a new reinforcement learning algorithm over grid-points in belief space, which uses macro-actions and Monte Carlo updates of the Q-values. We apply the algorithm to a large scale robot navigation task and demonstrate that with temporal abstraction we can consider an even smaller part of the belief space, we can learn POMDP policies faster, and we can do information gathering more efﬁciently.</p><p>4 0.10288753 <a title="70-tfidf-4" href="./nips-2003-Robustness_in_Markov_Decision_Problems_with_Uncertain_Transition_Matrices.html">167 nips-2003-Robustness in Markov Decision Problems with Uncertain Transition Matrices</a></p>
<p>Author: Arnab Nilim, Laurent El Ghaoui</p><p>Abstract: Optimal solutions to Markov Decision Problems (MDPs) are very sensitive with respect to the state transition probabilities. In many practical problems, the estimation of those probabilities is far from accurate. Hence, estimation errors are limiting factors in applying MDPs to realworld problems. We propose an algorithm for solving ﬁnite-state and ﬁnite-action MDPs, where the solution is guaranteed to be robust with respect to estimation errors on the state transition probabilities. Our algorithm involves a statistically accurate yet numerically efﬁcient representation of uncertainty, via Kullback-Leibler divergence bounds. The worst-case complexity of the robust algorithm is the same as the original Bellman recursion. Hence, robustness can be added at practically no extra computing cost.</p><p>5 0.099149503 <a title="70-tfidf-5" href="./nips-2003-Simplicial_Mixtures_of_Markov_Chains%3A_Distributed_Modelling_of_Dynamic_User_Profiles.html">177 nips-2003-Simplicial Mixtures of Markov Chains: Distributed Modelling of Dynamic User Profiles</a></p>
<p>Author: Mark Girolami, Ata Kabán</p><p>Abstract: To provide a compact generative representation of the sequential activity of a number of individuals within a group there is a tradeoff between the deﬁnition of individual speciﬁc and global models. This paper proposes a linear-time distributed model for ﬁnite state symbolic sequences representing traces of individual user activity by making the assumption that heterogeneous user behavior may be ‘explained’ by a relatively small number of common structurally simple behavioral patterns which may interleave randomly in a user-speciﬁc proportion. The results of an empirical study on three different sources of user traces indicates that this modelling approach provides an efﬁcient representation scheme, reﬂected by improved prediction performance as well as providing lowcomplexity and intuitively interpretable representations.</p><p>6 0.098295674 <a title="70-tfidf-6" href="./nips-2003-Markov_Models_for_Automated_ECG_Interval_Analysis.html">123 nips-2003-Markov Models for Automated ECG Interval Analysis</a></p>
<p>7 0.085423335 <a title="70-tfidf-7" href="./nips-2003-Eigenvoice_Speaker_Adaptation_via_Composite_Kernel_Principal_Component_Analysis.html">60 nips-2003-Eigenvoice Speaker Adaptation via Composite Kernel Principal Component Analysis</a></p>
<p>8 0.084537558 <a title="70-tfidf-8" href="./nips-2003-Envelope-based_Planning_in_Relational_MDPs.html">62 nips-2003-Envelope-based Planning in Relational MDPs</a></p>
<p>9 0.082555622 <a title="70-tfidf-9" href="./nips-2003-Generalised_Propagation_for_Fast_Fourier_Transforms_with_Partial_or_Missing_Data.html">80 nips-2003-Generalised Propagation for Fast Fourier Transforms with Partial or Missing Data</a></p>
<p>10 0.082273483 <a title="70-tfidf-10" href="./nips-2003-Modeling_User_Rating_Profiles_For_Collaborative_Filtering.html">131 nips-2003-Modeling User Rating Profiles For Collaborative Filtering</a></p>
<p>11 0.080775134 <a title="70-tfidf-11" href="./nips-2003-Applying_Metric-Trees_to_Belief-Point_POMDPs.html">29 nips-2003-Applying Metric-Trees to Belief-Point POMDPs</a></p>
<p>12 0.078531697 <a title="70-tfidf-12" href="./nips-2003-Estimating_Internal_Variables_and_Paramters_of_a_Learning_Agent_by_a_Particle_Filter.html">64 nips-2003-Estimating Internal Variables and Paramters of a Learning Agent by a Particle Filter</a></p>
<p>13 0.075929791 <a title="70-tfidf-13" href="./nips-2003-Gaussian_Processes_in_Reinforcement_Learning.html">78 nips-2003-Gaussian Processes in Reinforcement Learning</a></p>
<p>14 0.075047806 <a title="70-tfidf-14" href="./nips-2003-All_learning_is_Local%3A_Multi-agent_Learning_in_Global_Reward_Games.html">20 nips-2003-All learning is Local: Multi-agent Learning in Global Reward Games</a></p>
<p>15 0.074048802 <a title="70-tfidf-15" href="./nips-2003-Linear_Program_Approximations_for_Factored_Continuous-State_Markov_Decision_Processes.html">116 nips-2003-Linear Program Approximations for Factored Continuous-State Markov Decision Processes</a></p>
<p>16 0.072754793 <a title="70-tfidf-16" href="./nips-2003-Eye_Movements_for_Reward_Maximization.html">68 nips-2003-Eye Movements for Reward Maximization</a></p>
<p>17 0.067786634 <a title="70-tfidf-17" href="./nips-2003-Nonlinear_Filtering_of_Electron_Micrographs_by_Means_of_Support_Vector_Regression.html">139 nips-2003-Nonlinear Filtering of Electron Micrographs by Means of Support Vector Regression</a></p>
<p>18 0.065820791 <a title="70-tfidf-18" href="./nips-2003-Information_Maximization_in_Noisy_Channels_%3A_A_Variational_Approach.html">94 nips-2003-Information Maximization in Noisy Channels : A Variational Approach</a></p>
<p>19 0.06419161 <a title="70-tfidf-19" href="./nips-2003-Variational_Linear_Response.html">193 nips-2003-Variational Linear Response</a></p>
<p>20 0.064009942 <a title="70-tfidf-20" href="./nips-2003-From_Algorithmic_to_Subjective_Randomness.html">75 nips-2003-From Algorithmic to Subjective Randomness</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2003_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.248), (1, 0.099), (2, -0.029), (3, 0.048), (4, -0.025), (5, -0.008), (6, 0.053), (7, -0.013), (8, 0.056), (9, 0.012), (10, 0.013), (11, -0.142), (12, -0.055), (13, 0.023), (14, 0.103), (15, -0.025), (16, 0.029), (17, -0.026), (18, 0.028), (19, -0.051), (20, -0.088), (21, 0.044), (22, 0.011), (23, -0.094), (24, -0.104), (25, -0.106), (26, -0.211), (27, -0.038), (28, 0.026), (29, 0.172), (30, -0.033), (31, 0.076), (32, -0.016), (33, -0.02), (34, -0.136), (35, 0.079), (36, -0.026), (37, -0.269), (38, -0.008), (39, -0.077), (40, -0.068), (41, 0.009), (42, 0.048), (43, -0.052), (44, 0.066), (45, 0.081), (46, -0.022), (47, -0.027), (48, -0.014), (49, -0.08)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96628243 <a title="70-lsi-1" href="./nips-2003-Fast_Algorithms_for_Large-State-Space_HMMs_with_Applications_to_Web_Usage_Analysis.html">70 nips-2003-Fast Algorithms for Large-State-Space HMMs with Applications to Web Usage Analysis</a></p>
<p>Author: Pedro F. Felzenszwalb, Daniel P. Huttenlocher, Jon M. Kleinberg</p><p>Abstract: In applying Hidden Markov Models to the analysis of massive data streams, it is often necessary to use an artiﬁcially reduced set of states; this is due in large part to the fact that the basic HMM estimation algorithms have a quadratic dependence on the size of the state set. We present algorithms that reduce this computational bottleneck to linear or near-linear time, when the states can be embedded in an underlying grid of parameters. This type of state representation arises in many domains; in particular, we show an application to traﬃc analysis at a high-volume Web site. 1</p><p>2 0.811364 <a title="70-lsi-2" href="./nips-2003-Markov_Models_for_Automated_ECG_Interval_Analysis.html">123 nips-2003-Markov Models for Automated ECG Interval Analysis</a></p>
<p>Author: Nicholas P. Hughes, Lionel Tarassenko, Stephen J. Roberts</p><p>Abstract: We examine the use of hidden Markov and hidden semi-Markov models for automatically segmenting an electrocardiogram waveform into its constituent waveform features. An undecimated wavelet transform is used to generate an overcomplete representation of the signal that is more appropriate for subsequent modelling. We show that the state durations implicit in a standard hidden Markov model are ill-suited to those of real ECG features, and we investigate the use of hidden semi-Markov models for improved state duration modelling. 1</p><p>3 0.65942407 <a title="70-lsi-3" href="./nips-2003-Inferring_State_Sequences_for_Non-linear_Systems_with_Embedded_Hidden_Markov_Models.html">91 nips-2003-Inferring State Sequences for Non-linear Systems with Embedded Hidden Markov Models</a></p>
<p>Author: Radford M. Neal, Matthew J. Beal, Sam T. Roweis</p><p>Abstract: We describe a Markov chain method for sampling from the distribution of the hidden state sequence in a non-linear dynamical system, given a sequence of observations. This method updates all states in the sequence simultaneously using an embedded Hidden Markov Model (HMM). An update begins with the creation of “pools” of candidate states at each time. We then deﬁne an embedded HMM whose states are indexes within these pools. Using a forward-backward dynamic programming algorithm, we can efﬁciently choose a state sequence with the appropriate probabilities from the exponentially large number of state sequences that pass through states in these pools. We illustrate the method in a simple one-dimensional example, and in an example showing how an embedded HMM can be used to in effect discretize the state space without any discretization error. We also compare the embedded HMM to a particle smoother on a more substantial problem of inferring human motion from 2D traces of markers. 1</p><p>4 0.65593517 <a title="70-lsi-4" href="./nips-2003-From_Algorithmic_to_Subjective_Randomness.html">75 nips-2003-From Algorithmic to Subjective Randomness</a></p>
<p>Author: Thomas L. Griffiths, Joshua B. Tenenbaum</p><p>Abstract: We explore the phenomena of subjective randomness as a case study in understanding how people discover structure embedded in noise. We present a rational account of randomness perception based on the statistical problem of model selection: given a stimulus, inferring whether the process that generated it was random or regular. Inspired by the mathematical definition of randomness given by Kolmogorov complexity, we characterize regularity in terms of a hierarchy of automata that augment a finite controller with different forms of memory. We find that the regularities detected in binary sequences depend upon presentation format, and that the kinds of automata that can identify these regularities are informative about the cognitive processes engaged by different formats. 1</p><p>5 0.57302523 <a title="70-lsi-5" href="./nips-2003-Linear_Program_Approximations_for_Factored_Continuous-State_Markov_Decision_Processes.html">116 nips-2003-Linear Program Approximations for Factored Continuous-State Markov Decision Processes</a></p>
<p>Author: Milos Hauskrecht, Branislav Kveton</p><p>Abstract: Approximate linear programming (ALP) has emerged recently as one of the most promising methods for solving complex factored MDPs with ﬁnite state spaces. In this work we show that ALP solutions are not limited only to MDPs with ﬁnite state spaces, but that they can also be applied successfully to factored continuous-state MDPs (CMDPs). We show how one can build an ALP-based approximation for such a model and contrast it to existing solution methods. We argue that this approach offers a robust alternative for solving high dimensional continuous-state space problems. The point is supported by experiments on three CMDP problems with 24-25 continuous state factors. 1</p><p>6 0.53525972 <a title="70-lsi-6" href="./nips-2003-Modeling_User_Rating_Profiles_For_Collaborative_Filtering.html">131 nips-2003-Modeling User Rating Profiles For Collaborative Filtering</a></p>
<p>7 0.50864518 <a title="70-lsi-7" href="./nips-2003-Simplicial_Mixtures_of_Markov_Chains%3A_Distributed_Modelling_of_Dynamic_User_Profiles.html">177 nips-2003-Simplicial Mixtures of Markov Chains: Distributed Modelling of Dynamic User Profiles</a></p>
<p>8 0.49835587 <a title="70-lsi-8" href="./nips-2003-Robustness_in_Markov_Decision_Problems_with_Uncertain_Transition_Matrices.html">167 nips-2003-Robustness in Markov Decision Problems with Uncertain Transition Matrices</a></p>
<p>9 0.4562158 <a title="70-lsi-9" href="./nips-2003-An_MCMC-Based_Method_of_Comparing_Connectionist_Models_in_Cognitive_Science.html">25 nips-2003-An MCMC-Based Method of Comparing Connectionist Models in Cognitive Science</a></p>
<p>10 0.43758947 <a title="70-lsi-10" href="./nips-2003-Eye_Movements_for_Reward_Maximization.html">68 nips-2003-Eye Movements for Reward Maximization</a></p>
<p>11 0.42775455 <a title="70-lsi-11" href="./nips-2003-Wormholes_Improve_Contrastive_Divergence.html">196 nips-2003-Wormholes Improve Contrastive Divergence</a></p>
<p>12 0.42733908 <a title="70-lsi-12" href="./nips-2003-Approximate_Planning_in_POMDPs_with_Macro-Actions.html">33 nips-2003-Approximate Planning in POMDPs with Macro-Actions</a></p>
<p>13 0.42062902 <a title="70-lsi-13" href="./nips-2003-Dynamical_Modeling_with_Kernels_for_Nonlinear_Time_Series_Prediction.html">57 nips-2003-Dynamical Modeling with Kernels for Nonlinear Time Series Prediction</a></p>
<p>14 0.41004801 <a title="70-lsi-14" href="./nips-2003-Eigenvoice_Speaker_Adaptation_via_Composite_Kernel_Principal_Component_Analysis.html">60 nips-2003-Eigenvoice Speaker Adaptation via Composite Kernel Principal Component Analysis</a></p>
<p>15 0.39574072 <a title="70-lsi-15" href="./nips-2003-Nonlinear_Filtering_of_Electron_Micrographs_by_Means_of_Support_Vector_Regression.html">139 nips-2003-Nonlinear Filtering of Electron Micrographs by Means of Support Vector Regression</a></p>
<p>16 0.39000708 <a title="70-lsi-16" href="./nips-2003-Iterative_Scaled_Trust-Region_Learning_in_Krylov_Subspaces_via_Pearlmutter%27s_Implicit_Sparse_Hessian.html">97 nips-2003-Iterative Scaled Trust-Region Learning in Krylov Subspaces via Pearlmutter's Implicit Sparse Hessian</a></p>
<p>17 0.37642741 <a title="70-lsi-17" href="./nips-2003-A_Nonlinear_Predictive_State_Representation.html">14 nips-2003-A Nonlinear Predictive State Representation</a></p>
<p>18 0.36466154 <a title="70-lsi-18" href="./nips-2003-ARA%2A%3A_Anytime_A%2A_with_Provable_Bounds_on_Sub-Optimality.html">2 nips-2003-ARA*: Anytime A* with Provable Bounds on Sub-Optimality</a></p>
<p>19 0.36404538 <a title="70-lsi-19" href="./nips-2003-Can_We_Learn_to_Beat_the_Best_Stock.html">44 nips-2003-Can We Learn to Beat the Best Stock</a></p>
<p>20 0.36319011 <a title="70-lsi-20" href="./nips-2003-A_Fast_Multi-Resolution_Method_for_Detection_of_Significant_Spatial_Disease_Clusters.html">6 nips-2003-A Fast Multi-Resolution Method for Detection of Significant Spatial Disease Clusters</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2003_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.04), (11, 0.018), (30, 0.024), (35, 0.54), (53, 0.069), (71, 0.054), (76, 0.031), (85, 0.055), (91, 0.073), (99, 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.98338276 <a title="70-lda-1" href="./nips-2003-Approximate_Expectation_Maximization.html">32 nips-2003-Approximate Expectation Maximization</a></p>
<p>Author: Tom Heskes, Onno Zoeter, Wim Wiegerinck</p><p>Abstract: We discuss the integration of the expectation-maximization (EM) algorithm for maximum likelihood learning of Bayesian networks with belief propagation algorithms for approximate inference. Specifically we propose to combine the outer-loop step of convergent belief propagation algorithms with the M-step of the EM algorithm. This then yields an approximate EM algorithm that is essentially still double loop, with the important advantage of an inner loop that is guaranteed to converge. Simulations illustrate the merits of such an approach. 1</p><p>same-paper 2 0.96978039 <a title="70-lda-2" href="./nips-2003-Fast_Algorithms_for_Large-State-Space_HMMs_with_Applications_to_Web_Usage_Analysis.html">70 nips-2003-Fast Algorithms for Large-State-Space HMMs with Applications to Web Usage Analysis</a></p>
<p>Author: Pedro F. Felzenszwalb, Daniel P. Huttenlocher, Jon M. Kleinberg</p><p>Abstract: In applying Hidden Markov Models to the analysis of massive data streams, it is often necessary to use an artiﬁcially reduced set of states; this is due in large part to the fact that the basic HMM estimation algorithms have a quadratic dependence on the size of the state set. We present algorithms that reduce this computational bottleneck to linear or near-linear time, when the states can be embedded in an underlying grid of parameters. This type of state representation arises in many domains; in particular, we show an application to traﬃc analysis at a high-volume Web site. 1</p><p>3 0.95848632 <a title="70-lda-3" href="./nips-2003-1-norm_Support_Vector_Machines.html">1 nips-2003-1-norm Support Vector Machines</a></p>
<p>Author: Ji Zhu, Saharon Rosset, Robert Tibshirani, Trevor J. Hastie</p><p>Abstract: The standard 2-norm SVM is known for its good performance in twoclass classi£cation. In this paper, we consider the 1-norm SVM. We argue that the 1-norm SVM may have some advantage over the standard 2-norm SVM, especially when there are redundant noise features. We also propose an ef£cient algorithm that computes the whole solution path of the 1-norm SVM, hence facilitates adaptive selection of the tuning parameter for the 1-norm SVM. 1</p><p>4 0.71185124 <a title="70-lda-4" href="./nips-2003-Inferring_State_Sequences_for_Non-linear_Systems_with_Embedded_Hidden_Markov_Models.html">91 nips-2003-Inferring State Sequences for Non-linear Systems with Embedded Hidden Markov Models</a></p>
<p>Author: Radford M. Neal, Matthew J. Beal, Sam T. Roweis</p><p>Abstract: We describe a Markov chain method for sampling from the distribution of the hidden state sequence in a non-linear dynamical system, given a sequence of observations. This method updates all states in the sequence simultaneously using an embedded Hidden Markov Model (HMM). An update begins with the creation of “pools” of candidate states at each time. We then deﬁne an embedded HMM whose states are indexes within these pools. Using a forward-backward dynamic programming algorithm, we can efﬁciently choose a state sequence with the appropriate probabilities from the exponentially large number of state sequences that pass through states in these pools. We illustrate the method in a simple one-dimensional example, and in an example showing how an embedded HMM can be used to in effect discretize the state space without any discretization error. We also compare the embedded HMM to a particle smoother on a more substantial problem of inferring human motion from 2D traces of markers. 1</p><p>5 0.6483314 <a title="70-lda-5" href="./nips-2003-Online_Learning_of_Non-stationary_Sequences.html">146 nips-2003-Online Learning of Non-stationary Sequences</a></p>
<p>Author: Claire Monteleoni, Tommi S. Jaakkola</p><p>Abstract: We consider an online learning scenario in which the learner can make predictions on the basis of a ﬁxed set of experts. We derive upper and lower relative loss bounds for a class of universal learning algorithms involving a switching dynamics over the choice of the experts. On the basis of the performance bounds we provide the optimal a priori discretization for learning the parameter that governs the switching dynamics. We demonstrate the new algorithm in the context of wireless networks.</p><p>6 0.64113897 <a title="70-lda-6" href="./nips-2003-Margin_Maximizing_Loss_Functions.html">122 nips-2003-Margin Maximizing Loss Functions</a></p>
<p>7 0.61706185 <a title="70-lda-7" href="./nips-2003-Markov_Models_for_Automated_ECG_Interval_Analysis.html">123 nips-2003-Markov Models for Automated ECG Interval Analysis</a></p>
<p>8 0.6029402 <a title="70-lda-8" href="./nips-2003-Iterative_Scaled_Trust-Region_Learning_in_Krylov_Subspaces_via_Pearlmutter%27s_Implicit_Sparse_Hessian.html">97 nips-2003-Iterative Scaled Trust-Region Learning in Krylov Subspaces via Pearlmutter's Implicit Sparse Hessian</a></p>
<p>9 0.58226764 <a title="70-lda-9" href="./nips-2003-Large_Margin_Classifiers%3A_Convex_Loss%2C_Low_Noise%2C_and_Convergence_Rates.html">101 nips-2003-Large Margin Classifiers: Convex Loss, Low Noise, and Convergence Rates</a></p>
<p>10 0.58102512 <a title="70-lda-10" href="./nips-2003-Fast_Feature_Selection_from_Microarray_Expression_Data_via_Multiplicative_Large_Margin_Algorithms.html">72 nips-2003-Fast Feature Selection from Microarray Expression Data via Multiplicative Large Margin Algorithms</a></p>
<p>11 0.57033408 <a title="70-lda-11" href="./nips-2003-Laplace_Propagation.html">100 nips-2003-Laplace Propagation</a></p>
<p>12 0.56499982 <a title="70-lda-12" href="./nips-2003-Denoising_and_Untangling_Graphs_Using_Degree_Priors.html">50 nips-2003-Denoising and Untangling Graphs Using Degree Priors</a></p>
<p>13 0.56487381 <a title="70-lda-13" href="./nips-2003-Policy_Search_by_Dynamic_Programming.html">158 nips-2003-Policy Search by Dynamic Programming</a></p>
<p>14 0.55905288 <a title="70-lda-14" href="./nips-2003-Linear_Response_for_Approximate_Inference.html">117 nips-2003-Linear Response for Approximate Inference</a></p>
<p>15 0.55701655 <a title="70-lda-15" href="./nips-2003-Sample_Propagation.html">169 nips-2003-Sample Propagation</a></p>
<p>16 0.55368984 <a title="70-lda-16" href="./nips-2003-Factorization_with_Uncertainty_and_Missing_Data%3A_Exploiting_Temporal_Coherence.html">69 nips-2003-Factorization with Uncertainty and Missing Data: Exploiting Temporal Coherence</a></p>
<p>17 0.54711163 <a title="70-lda-17" href="./nips-2003-Tree-structured_Approximations_by_Expectation_Propagation.html">189 nips-2003-Tree-structured Approximations by Expectation Propagation</a></p>
<p>18 0.54228991 <a title="70-lda-18" href="./nips-2003-Linear_Program_Approximations_for_Factored_Continuous-State_Markov_Decision_Processes.html">116 nips-2003-Linear Program Approximations for Factored Continuous-State Markov Decision Processes</a></p>
<p>19 0.53627425 <a title="70-lda-19" href="./nips-2003-Modeling_User_Rating_Profiles_For_Collaborative_Filtering.html">131 nips-2003-Modeling User Rating Profiles For Collaborative Filtering</a></p>
<p>20 0.53293943 <a title="70-lda-20" href="./nips-2003-Approximate_Planning_in_POMDPs_with_Macro-Actions.html">33 nips-2003-Approximate Planning in POMDPs with Macro-Actions</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
