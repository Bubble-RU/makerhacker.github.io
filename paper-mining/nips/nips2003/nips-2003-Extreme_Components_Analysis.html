<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>66 nips-2003-Extreme Components Analysis</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2003" href="../home/nips2003_home.html">nips2003</a> <a title="nips-2003-66" href="#">nips2003-66</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>66 nips-2003-Extreme Components Analysis</h1>
<br/><p>Source: <a title="nips-2003-66-pdf" href="http://papers.nips.cc/paper/2517-extreme-components-analysis.pdf">pdf</a></p><p>Author: Max Welling, Christopher Williams, Felix V. Agakov</p><p>Abstract: Principal components analysis (PCA) is one of the most widely used techniques in machine learning and data mining. Minor components analysis (MCA) is less well known, but can also play an important role in the presence of constraints on the data distribution. In this paper we present a probabilistic model for “extreme components analysis” (XCA) which at the maximum likelihood solution extracts an optimal combination of principal and minor components. For a given number of components, the log-likelihood of the XCA model is guaranteed to be larger or equal than that of the probabilistic models for PCA and MCA. We describe an efﬁcient algorithm to solve for the globally optimal solution. For log-convex spectra we prove that the solution consists of principal components only, while for log-concave spectra the solution consists of minor components. In general, the solution admits a combination of both. In experiments we explore the properties of XCA on some synthetic and real-world datasets.</p><p>Reference: <a title="nips-2003-66-reference" href="../nips2003_reference/nips-2003-Extreme_Components_Analysis_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('xca', 0.776), ('ppca', 0.248), ('mca', 0.224), ('pmca', 0.204), ('spectr', 0.195), ('pca', 0.138), ('eigenvalu', 0.133), ('princip', 0.106), ('mcs', 0.102), ('compon', 0.091), ('cxca', 0.082), ('retain', 0.081), ('pw', 0.075), ('fi', 0.066), ('inset', 0.062), ('pcs', 0.061), ('ci', 0.06), ('min', 0.059), ('su', 0.058), ('orthogon', 0.057)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="66-tfidf-1" href="./nips-2003-Extreme_Components_Analysis.html">66 nips-2003-Extreme Components Analysis</a></p>
<p>2 0.24432765 <a title="66-tfidf-2" href="./nips-2003-Limiting_Form_of_the_Sample_Covariance_Eigenspectrum_in_PCA_and_Kernel_PCA.html">114 nips-2003-Limiting Form of the Sample Covariance Eigenspectrum in PCA and Kernel PCA</a></p>
<p>3 0.11231317 <a title="66-tfidf-3" href="./nips-2003-Gaussian_Process_Latent_Variable_Models_for_Visualisation_of_High_Dimensional_Data.html">77 nips-2003-Gaussian Process Latent Variable Models for Visualisation of High Dimensional Data</a></p>
<p>4 0.087254331 <a title="66-tfidf-4" href="./nips-2003-Linear_Dependent_Dimensionality_Reduction.html">115 nips-2003-Linear Dependent Dimensionality Reduction</a></p>
<p>5 0.077286571 <a title="66-tfidf-5" href="./nips-2003-Minimax_Embeddings.html">128 nips-2003-Minimax Embeddings</a></p>
<p>6 0.073851839 <a title="66-tfidf-6" href="./nips-2003-Learning_Spectral_Clustering.html">107 nips-2003-Learning Spectral Clustering</a></p>
<p>7 0.064844035 <a title="66-tfidf-7" href="./nips-2003-Efficient_and_Robust_Feature_Extraction_by_Maximum_Margin_Criterion.html">59 nips-2003-Efficient and Robust Feature Extraction by Maximum Margin Criterion</a></p>
<p>8 0.063345395 <a title="66-tfidf-8" href="./nips-2003-Information_Maximization_in_Noisy_Channels_%3A_A_Variational_Approach.html">94 nips-2003-Information Maximization in Noisy Channels : A Variational Approach</a></p>
<p>9 0.06135904 <a title="66-tfidf-9" href="./nips-2003-Learning_to_Find_Pre-Images.html">112 nips-2003-Learning to Find Pre-Images</a></p>
<p>10 0.056554116 <a title="66-tfidf-10" href="./nips-2003-Information_Bottleneck_for_Gaussian_Variables.html">92 nips-2003-Information Bottleneck for Gaussian Variables</a></p>
<p>11 0.052146342 <a title="66-tfidf-11" href="./nips-2003-Out-of-Sample_Extensions_for_LLE%2C_Isomap%2C_MDS%2C_Eigenmaps%2C_and_Spectral_Clustering.html">150 nips-2003-Out-of-Sample Extensions for LLE, Isomap, MDS, Eigenmaps, and Spectral Clustering</a></p>
<p>12 0.050352059 <a title="66-tfidf-12" href="./nips-2003-Image_Reconstruction_by_Linear_Programming.html">88 nips-2003-Image Reconstruction by Linear Programming</a></p>
<p>13 0.050214164 <a title="66-tfidf-13" href="./nips-2003-Non-linear_CCA_and_PCA_by_Alignment_of_Local_Models.html">138 nips-2003-Non-linear CCA and PCA by Alignment of Local Models</a></p>
<p>14 0.047557745 <a title="66-tfidf-14" href="./nips-2003-Locality_Preserving_Projections.html">120 nips-2003-Locality Preserving Projections</a></p>
<p>15 0.046522424 <a title="66-tfidf-15" href="./nips-2003-Plasticity_Kernels_and_Temporal_Statistics.html">157 nips-2003-Plasticity Kernels and Temporal Statistics</a></p>
<p>16 0.045744997 <a title="66-tfidf-16" href="./nips-2003-Insights_from_Machine_Learning_Applied_to_Human_Visual_Classification.html">95 nips-2003-Insights from Machine Learning Applied to Human Visual Classification</a></p>
<p>17 0.045148119 <a title="66-tfidf-17" href="./nips-2003-Online_Classification_on_a_Budget.html">145 nips-2003-Online Classification on a Budget</a></p>
<p>18 0.044361293 <a title="66-tfidf-18" href="./nips-2003-Generalised_Propagation_for_Fast_Fourier_Transforms_with_Partial_or_Missing_Data.html">80 nips-2003-Generalised Propagation for Fast Fourier Transforms with Partial or Missing Data</a></p>
<p>19 0.043237638 <a title="66-tfidf-19" href="./nips-2003-Geometric_Analysis_of_Constrained_Curves.html">81 nips-2003-Geometric Analysis of Constrained Curves</a></p>
<p>20 0.042583138 <a title="66-tfidf-20" href="./nips-2003-Online_Passive-Aggressive_Algorithms.html">148 nips-2003-Online Passive-Aggressive Algorithms</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2003_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.149), (1, 0.049), (2, -0.011), (3, 0.032), (4, -0.021), (5, -0.058), (6, -0.138), (7, 0.04), (8, -0.028), (9, 0.1), (10, -0.106), (11, -0.085), (12, 0.032), (13, 0.024), (14, 0.002), (15, 0.097), (16, -0.014), (17, -0.144), (18, -0.018), (19, 0.035), (20, 0.049), (21, 0.097), (22, -0.041), (23, -0.044), (24, -0.029), (25, 0.099), (26, 0.154), (27, 0.122), (28, 0.097), (29, 0.19), (30, 0.129), (31, 0.09), (32, -0.034), (33, -0.093), (34, -0.136), (35, 0.061), (36, 0.166), (37, 0.012), (38, 0.008), (39, -0.028), (40, 0.001), (41, 0.157), (42, 0.16), (43, -0.075), (44, 0.008), (45, 0.069), (46, -0.068), (47, 0.023), (48, -0.018), (49, 0.149)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.91609561 <a title="66-lsi-1" href="./nips-2003-Extreme_Components_Analysis.html">66 nips-2003-Extreme Components Analysis</a></p>
<p>2 0.86863458 <a title="66-lsi-2" href="./nips-2003-Limiting_Form_of_the_Sample_Covariance_Eigenspectrum_in_PCA_and_Kernel_PCA.html">114 nips-2003-Limiting Form of the Sample Covariance Eigenspectrum in PCA and Kernel PCA</a></p>
<p>3 0.61743921 <a title="66-lsi-3" href="./nips-2003-Gaussian_Process_Latent_Variable_Models_for_Visualisation_of_High_Dimensional_Data.html">77 nips-2003-Gaussian Process Latent Variable Models for Visualisation of High Dimensional Data</a></p>
<p>4 0.46636805 <a title="66-lsi-4" href="./nips-2003-Efficient_and_Robust_Feature_Extraction_by_Maximum_Margin_Criterion.html">59 nips-2003-Efficient and Robust Feature Extraction by Maximum Margin Criterion</a></p>
<p>5 0.35556591 <a title="66-lsi-5" href="./nips-2003-Linear_Dependent_Dimensionality_Reduction.html">115 nips-2003-Linear Dependent Dimensionality Reduction</a></p>
<p>6 0.34907779 <a title="66-lsi-6" href="./nips-2003-Minimax_Embeddings.html">128 nips-2003-Minimax Embeddings</a></p>
<p>7 0.33549917 <a title="66-lsi-7" href="./nips-2003-Plasticity_Kernels_and_Temporal_Statistics.html">157 nips-2003-Plasticity Kernels and Temporal Statistics</a></p>
<p>8 0.30766952 <a title="66-lsi-8" href="./nips-2003-Information_Maximization_in_Noisy_Channels_%3A_A_Variational_Approach.html">94 nips-2003-Information Maximization in Noisy Channels : A Variational Approach</a></p>
<p>9 0.29749167 <a title="66-lsi-9" href="./nips-2003-Learning_Spectral_Clustering.html">107 nips-2003-Learning Spectral Clustering</a></p>
<p>10 0.28702104 <a title="66-lsi-10" href="./nips-2003-Non-linear_CCA_and_PCA_by_Alignment_of_Local_Models.html">138 nips-2003-Non-linear CCA and PCA by Alignment of Local Models</a></p>
<p>11 0.27522913 <a title="66-lsi-11" href="./nips-2003-Kernel_Dimensionality_Reduction_for_Supervised_Learning.html">98 nips-2003-Kernel Dimensionality Reduction for Supervised Learning</a></p>
<p>12 0.27257061 <a title="66-lsi-12" href="./nips-2003-Locality_Preserving_Projections.html">120 nips-2003-Locality Preserving Projections</a></p>
<p>13 0.26797441 <a title="66-lsi-13" href="./nips-2003-Information_Bottleneck_for_Gaussian_Variables.html">92 nips-2003-Information Bottleneck for Gaussian Variables</a></p>
<p>14 0.26696426 <a title="66-lsi-14" href="./nips-2003-Factorization_with_Uncertainty_and_Missing_Data%3A_Exploiting_Temporal_Coherence.html">69 nips-2003-Factorization with Uncertainty and Missing Data: Exploiting Temporal Coherence</a></p>
<p>15 0.26668575 <a title="66-lsi-15" href="./nips-2003-Convex_Methods_for_Transduction.html">48 nips-2003-Convex Methods for Transduction</a></p>
<p>16 0.25959805 <a title="66-lsi-16" href="./nips-2003-Sensory_Modality_Segregation.html">175 nips-2003-Sensory Modality Segregation</a></p>
<p>17 0.25844613 <a title="66-lsi-17" href="./nips-2003-Learning_to_Find_Pre-Images.html">112 nips-2003-Learning to Find Pre-Images</a></p>
<p>18 0.25672022 <a title="66-lsi-18" href="./nips-2003-Probabilistic_Inference_of_Speech_Signals_from_Phaseless_Spectrograms.html">162 nips-2003-Probabilistic Inference of Speech Signals from Phaseless Spectrograms</a></p>
<p>19 0.2541191 <a title="66-lsi-19" href="./nips-2003-Linear_Program_Approximations_for_Factored_Continuous-State_Markov_Decision_Processes.html">116 nips-2003-Linear Program Approximations for Factored Continuous-State Markov Decision Processes</a></p>
<p>20 0.25400215 <a title="66-lsi-20" href="./nips-2003-Unsupervised_Color_Decomposition_Of_Histologically_Stained_Tissue_Samples.html">190 nips-2003-Unsupervised Color Decomposition Of Histologically Stained Tissue Samples</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2003_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.061), (11, 0.016), (23, 0.28), (31, 0.058), (53, 0.143), (58, 0.061), (62, 0.085), (68, 0.012), (71, 0.024), (76, 0.118), (85, 0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.75262249 <a title="66-lda-1" href="./nips-2003-Hierarchical_Topic_Models_and_the_Nested_Chinese_Restaurant_Process.html">83 nips-2003-Hierarchical Topic Models and the Nested Chinese Restaurant Process</a></p>
<p>same-paper 2 0.7363537 <a title="66-lda-2" href="./nips-2003-Extreme_Components_Analysis.html">66 nips-2003-Extreme Components Analysis</a></p>
<p>3 0.6591801 <a title="66-lda-3" href="./nips-2003-An_Improved_Scheme_for_Detection_and_Labelling_in_Johansson_Displays.html">22 nips-2003-An Improved Scheme for Detection and Labelling in Johansson Displays</a></p>
<p>4 0.62088919 <a title="66-lda-4" href="./nips-2003-Feature_Selection_in_Clustering_Problems.html">73 nips-2003-Feature Selection in Clustering Problems</a></p>
<p>5 0.61989057 <a title="66-lda-5" href="./nips-2003-Computing_Gaussian_Mixture_Models_with_EM_Using_Equivalence_Constraints.html">47 nips-2003-Computing Gaussian Mixture Models with EM Using Equivalence Constraints</a></p>
<p>6 0.61371535 <a title="66-lda-6" href="./nips-2003-Information_Bottleneck_for_Gaussian_Variables.html">92 nips-2003-Information Bottleneck for Gaussian Variables</a></p>
<p>7 0.61321032 <a title="66-lda-7" href="./nips-2003-Locality_Preserving_Projections.html">120 nips-2003-Locality Preserving Projections</a></p>
<p>8 0.6124211 <a title="66-lda-8" href="./nips-2003-Limiting_Form_of_the_Sample_Covariance_Eigenspectrum_in_PCA_and_Kernel_PCA.html">114 nips-2003-Limiting Form of the Sample Covariance Eigenspectrum in PCA and Kernel PCA</a></p>
<p>9 0.6092819 <a title="66-lda-9" href="./nips-2003-Measure_Based_Regularization.html">126 nips-2003-Measure Based Regularization</a></p>
<p>10 0.60775775 <a title="66-lda-10" href="./nips-2003-Clustering_with_the_Connectivity_Kernel.html">46 nips-2003-Clustering with the Connectivity Kernel</a></p>
<p>11 0.60595572 <a title="66-lda-11" href="./nips-2003-Learning_a_Distance_Metric_from_Relative_Comparisons.html">108 nips-2003-Learning a Distance Metric from Relative Comparisons</a></p>
<p>12 0.60489655 <a title="66-lda-12" href="./nips-2003-Geometric_Clustering_Using_the_Information_Bottleneck_Method.html">82 nips-2003-Geometric Clustering Using the Information Bottleneck Method</a></p>
<p>13 0.60483658 <a title="66-lda-13" href="./nips-2003-Invariant_Pattern_Recognition_by_Semi-Definite_Programming_Machines.html">96 nips-2003-Invariant Pattern Recognition by Semi-Definite Programming Machines</a></p>
<p>14 0.60263747 <a title="66-lda-14" href="./nips-2003-Learning_with_Local_and_Global_Consistency.html">113 nips-2003-Learning with Local and Global Consistency</a></p>
<p>15 0.60178977 <a title="66-lda-15" href="./nips-2003-Learning_to_Find_Pre-Images.html">112 nips-2003-Learning to Find Pre-Images</a></p>
<p>16 0.60154915 <a title="66-lda-16" href="./nips-2003-Convex_Methods_for_Transduction.html">48 nips-2003-Convex Methods for Transduction</a></p>
<p>17 0.60109663 <a title="66-lda-17" href="./nips-2003-Learning_the_k_in_k-means.html">111 nips-2003-Learning the k in k-means</a></p>
<p>18 0.60064232 <a title="66-lda-18" href="./nips-2003-Identifying_Structure_across_Pre-partitioned_Data.html">87 nips-2003-Identifying Structure across Pre-partitioned Data</a></p>
<p>19 0.60008943 <a title="66-lda-19" href="./nips-2003-Ranking_on_Data_Manifolds.html">164 nips-2003-Ranking on Data Manifolds</a></p>
<p>20 0.59979928 <a title="66-lda-20" href="./nips-2003-Image_Reconstruction_by_Linear_Programming.html">88 nips-2003-Image Reconstruction by Linear Programming</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
