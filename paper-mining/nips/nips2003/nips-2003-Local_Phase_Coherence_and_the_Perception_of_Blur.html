<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>119 nips-2003-Local Phase Coherence and the Perception of Blur</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2003" href="../home/nips2003_home.html">nips2003</a> <a title="nips-2003-119" href="#">nips2003-119</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>119 nips-2003-Local Phase Coherence and the Perception of Blur</h1>
<br/><p>Source: <a title="nips-2003-119-pdf" href="http://papers.nips.cc/paper/2398-local-phase-coherence-and-the-perception-of-blur.pdf">pdf</a></p><p>Author: Zhou Wang, Eero P. Simoncelli</p><p>Abstract: unkown-abstract</p><p>Reference: <a title="nips-2003-119-reference" href="../nips2003_reference/nips-2003-Local_Phase_Coherence_and_the_Perception_of_Blur_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Humans are able to detect blurring of visual images, but the mechanism by which they do so is not clear. [sent-5, score-0.324]
</p><p>2 A traditional view is that a blurred image looks “unnatural” because of the reduction in energy (either globally or locally) at high frequencies. [sent-6, score-0.463]
</p><p>3 In this paper, we propose that the disruption of local phase can provide an alternative explanation for blur perception. [sent-7, score-0.977]
</p><p>4 We show that precisely localized features such as step edges result in strong local phase coherence structures across scale and space in the complex wavelet transform domain, and blurring causes loss of such phase coherence. [sent-8, score-2.252]
</p><p>5 We propose a technique for coarse-to-ﬁne phase prediction of wavelet coefﬁcients, and observe that (1) such predictions are highly effective in natural images, (2) phase coherence increases with the strength of image features, and (3) blurring disrupts the phase coherence relationship in images. [sent-9, score-2.986]
</p><p>6 We thus lay the groundwork for a new theory of perceptual blur estimation, as well as a variety of algorithms for restoration and manipulation of photographic images. [sent-10, score-0.486]
</p><p>7 1  Introduction  Blur is one of the most common forms of image distortion. [sent-11, score-0.163]
</p><p>8 It can arise from a variety of sources, such as atmospheric scatter, lens defocus, optical aberrations of the lens, and spatial and temporal sensor integration. [sent-12, score-0.114]
</p><p>9 Human observers are bothered by blur, and our visual systems are quite good at reporting whether an image appears blurred (or sharpened) [1, 2]. [sent-13, score-0.541]
</p><p>10 Clearly, detection of blur requires some model of what constitutes an unblurred image. [sent-15, score-0.375]
</p><p>11 In recent years, there has been a surge of interest in the modelling of natural images, both for purposes of improving the performance of image processing and computer vision systems, and also for furthering our understanding of biological visual systems. [sent-16, score-0.404]
</p><p>12 Speciﬁcally, image spectra are found to follow a power law [3–5]. [sent-18, score-0.163]
</p><p>13 Speciﬁcally, blurring usually reduces the energy of high frequency components, and thus the power spectrum of a blurry image should fall faster than a typical natural image. [sent-20, score-0.424]
</p><p>14 But this proposal is problematic, since individual images show signiﬁcant variability in their Fourier amplitudes, both in their shape and in the rate at which  they fall [1]. [sent-22, score-0.104]
</p><p>15 In particular, simply reducing the number of sharp features (e. [sent-23, score-0.152]
</p><p>16 , edges) in an image can lead to a steeper falloff in global amplitude spectrum, even though the image will still appear sharp [7]. [sent-25, score-0.453]
</p><p>17 Nevertheless, the visual system seems to be able to compensate for this when estimating blur [1, 2, 7]. [sent-26, score-0.459]
</p><p>18 Over the past two decades, researchers from many communities have converged on a view that images are better represented using bases of multi-scale bandpass oriented ﬁlters. [sent-27, score-0.188]
</p><p>19 These representations, loosely referred to as “wavelets”, are effective at decoupling the high-order statistical features of natural images. [sent-28, score-0.11]
</p><p>20 In addition, they provide the most basic model for neurons in the primary visual cortex of mammals, which are presumably adapted to efﬁciently represent the visually relevant features of images. [sent-29, score-0.276]
</p><p>21 Many recent statistical image models in the wavelet domain are based on the amplitudes of the coefﬁcients, and the relationship between the amplitudes of coefﬁcients in local neighborhoods or across different scales [e. [sent-30, score-0.704]
</p><p>22 In both human and computer vision, the amplitudes of complex wavelets have been widely used as a mechanism for localizing/representing features [e. [sent-33, score-0.25]
</p><p>23 It has also been shown that the relative wavelet amplitude as a function of scale can be used to explain a number of subjective experiments on the perception of blur [7]. [sent-36, score-0.692]
</p><p>24 In this paper, we propose the disruption of local phase as an alternative and effective measure for the detection of blur. [sent-37, score-0.704]
</p><p>25 This seems counterintuitive, because when an image is blurred through convolution with a symmetric linear ﬁlter, the phase information in the (global) Fourier transform domain does not change at all. [sent-38, score-1.052]
</p><p>26 But we show that this is not true for local phase information. [sent-39, score-0.577]
</p><p>27 In previous work, Fourier phase has been found to carry important information about image structures and features [14] and higher-order Fourier statistics have been used to examine the phase structure in natural images [15]. [sent-40, score-1.472]
</p><p>28 It has been pointed out that at the points of isolated even and odd symmetric features such as lines and step edges, the arrival phases of all Fourier harmonics are identical [11, 16]. [sent-41, score-0.179]
</p><p>29 Phase congruency [11, 17] provides a quantitative measure for the agreement of such phase alignment pattern. [sent-42, score-0.611]
</p><p>30 It has also been shown that maximum phase congruency feature detection is equivalent to maximum local energy model [18]. [sent-43, score-0.811]
</p><p>31 Local phase has been used in a number of machine vision and image processing applications, such as estimation of image motion [19] and disparity [20], description of image textures [21], and recognition of persons using iris patterns [22]. [sent-44, score-1.199]
</p><p>32 However, the behaviors of local phase at different scales in the vicinity of image features, and the means by which blur affects such behaviors have not been deeply investigated. [sent-45, score-1.197]
</p><p>33 2  Local Phase Coherence of Isolated Features  Wavelet transforms provide a convenient framework for localized representation of signals simultaneously in space and frequency. [sent-46, score-0.19]
</p><p>34 The wavelets are dilated/contracted and translated versions of a “mother wavelet” w(x). [sent-47, score-0.104]
</p><p>35 In this paper, we consider symmetric (linear phase) wavelets whose mother wavelets may be written as a modulation of a low-pass ﬁlter: w(x) = g(x) ejωc x ,  (1)  where ωc is the center frequency of the modulated band-pass ﬁlter, and g(x) is a slowly varying and symmetric function. [sent-48, score-0.323]
</p><p>36 The family of wavelets derived from the mother wavelet are then 1 x−p 1 x−p ws,p (x) = √ w =√ g ejωc (x−p)/s , (2) s s s s where s ∈ R+ is the scale factor, and p ∈ R is the translation factor. [sent-49, score-0.45]
</p><p>37 Considering the fact that g(−x) = g(x), the wavelet transform of a given real signal f (x) can be written as ∞  F (s, p) =  1 x ∗ f (x) ws,p (x) dx = f (x) ∗ √ g s s −∞  ejωc x/s  . [sent-50, score-0.337]
</p><p>38 x=p  (3)  Now assume that the signal f (x) being analyzed is localized near the position x 0 , and we rewrite it into a function f0 (x) that satisﬁes f (x) = f0 (x − x0 ). [sent-51, score-0.187]
</p><p>39 We now examine how the phase of F (s, p) evolves across space p and scale s. [sent-53, score-0.63]
</p><p>40 (4), we see that the phase of F (s, p) highly depends on the nature of F0 (ω). [sent-55, score-0.546]
</p><p>41 (6) s s Since both K(s) and s are real, we can write the phase as: p − x0 Φ(F (s, p)) = Φ(F (1, x0 + )) . [sent-59, score-0.516]
</p><p>42 (7) s This equation suggests a strong phase coherence relationship across scale and space. [sent-60, score-0.977]
</p><p>43 More generally, the phase at any given scale may be computed from the phase at any other scale by simply rescaling the position axis. [sent-64, score-1.146]
</p><p>44 This phase coherence relationship relies on the scale-invariance property of Eq. [sent-65, score-0.89]
</p><p>45 Notice that both functions of f0 (x) are precisely localized in space. [sent-70, score-0.214]
</p><p>46 Figure 1(b) shows that this precisely convergent phase behavior is disrupted by blurring. [sent-71, score-0.576]
</p><p>47 Thus, a measure of phase coherence can be used to detect blur. [sent-77, score-0.883]
</p><p>48 Note that the phase congruency relationship [11, 17], which expresses the alignment of phase at the location of a feature, corresponds to the center (vertical) contour of Fig. [sent-78, score-1.165]
</p><p>49 Thus, phase congruency measures [11, 17] provide no information about blur. [sent-80, score-0.611]
</p><p>50 x  0  x0  x0  x0  x0  x  0  signal space wavelet space s (scale)  . [sent-81, score-0.265]
</p><p>51 1: Local phase coherence of precisely localized (scale-invariant) features, and the disruption of this coherence in the presence of blur. [sent-94, score-1.478]
</p><p>52 We then examine these phase predictions in both sharp and blurred natural images. [sent-98, score-0.924]
</p><p>53 The discrete wavelet transform corresponds to a discrete sampling of the continuous wavelet transform F (s, p). [sent-106, score-0.642]
</p><p>54 2(a), where between every two adjacent scales, the scale factor s doubles and the spatial sampling rate is halved. [sent-108, score-0.132]
</p><p>55 2: Discrete wavelet transform sampling grid in the continuous wavelet transform domain. [sent-111, score-0.642]
</p><p>56 of the ﬁnest scale coefﬁcients {c1 , c2 , c3 , c4 } can be well predicted from the coarser scale coefﬁcients {a, b1 , b2 }, provided the local phase satisﬁes the phase coherence relationship. [sent-113, score-1.602]
</p><p>57 ˆ Speciﬁcally, the estimated phase Φ for {c1 , c2 , c3 , c4 } can be expressed as     3  b1 c1  c2   ∗ 2  b2 b2   ˆ Φ = Φ (a ) ·  1 2  . [sent-114, score-0.516]
</p><p>58 2(b), the phase prediction expression from the coarser scale coefﬁcients {a, b11 , b12 , b21 , b22 } to the group of ﬁnest scale coefﬁcients {cij } is as follows:   3  b11 b2 b12 b11 b2 b3 11 12 12 2 2 2 b11 b12 b22 b12 b22    b b21 b11 b22 ˆ Φ({cij }) = Φ (a∗ )2 ·  11 2 . [sent-117, score-0.722]
</p><p>59 2  Image Statistics  We decompose the images using the “steerable pyramid” [23], a multi-scale wavelet decomposition whose basis functions are spatially localized, oriented, and roughly one octave in bandwidth. [sent-119, score-0.336]
</p><p>60 (14), the phase of each coefﬁcient in the 8 oriented ﬁnest-scale subbands is predicted from the phases of its coarser-scale parent and grandparent coefﬁcients as illustrated in Fig. [sent-122, score-0.688]
</p><p>61 We applied such a phase prediction method to a dataset of 1000 high-resolution sharp images as well as their blurred versions, and then examined the errors between the predicted and true phases at the ﬁne scale. [sent-124, score-1.086]
</p><p>62 error  (c)  blurred image  highly blurred image  0  (d)  −π  sharp blurred highly blurred  0. [sent-131, score-1.448]
</p><p>63 02  −π  −π  π  0 phase prediction error  π  (g)  0  (f)  −π original coefficient magnitude  Fig. [sent-135, score-0.611]
</p><p>64 3: Local phase coherence statistics in sharp and blurred images. [sent-136, score-1.221]
</p><p>65 (a),(b),(c): example natural, blurred and highly blurred images taken from the test image database of 1000 (512×512, 8bits/pixel, gray-scale) natural images with a wide variety of contents (humans, animals, plants, landscapes, man-made objects, etc. [sent-137, score-0.977]
</p><p>66 Images are cropped to 200×200 for visibility; (d),(e),(f): conditional histograms of phase prediction error as a function of the original coefﬁcient magnitude for the three types of images. [sent-139, score-0.68]
</p><p>67 Each column of the histograms is scaled individually, such that the largest value of each column is mapped to white; (g) phase prediction error histogram of signiﬁcant coefﬁcients (magnitude greater than 20). [sent-140, score-0.645]
</p><p>68 3, we observe that phase coherence is highly effective in natural images and the phase prediction error decreases as the coefﬁcient magnitude increases. [sent-141, score-1.645]
</p><p>69 Furthermore, as expected, the blurring process clearly reduces the phase prediction accuracy. [sent-143, score-0.705]
</p><p>70 We thus hypothesize that it is perhaps this disruption of local phase coherence that the visual system senses as being “unnatural”. [sent-144, score-1.124]
</p><p>71 4  Discussion  This paper proposes a new view of image blur based on the observation that blur induces distortion of local phase, in addition to the widely noted loss of high-frequency energy. [sent-145, score-0.872]
</p><p>72 We have shown that isolated precisely localized features create strong local phase coherence, and that blurring disrupts this phase coherence. [sent-146, score-1.606]
</p><p>73 We have also developed a particular measure of phase coherence based on coarse-to-ﬁne phase prediction, and shown that this measure can serve as an indication of blur in natural images. [sent-147, score-1.74]
</p><p>74 In the future, it remains to be seen whether the visual systems detect blur by comparing the relative amplitude of localized ﬁlters at different scales [7], or alternatively, comparing the relative spread of local phase across scale and space. [sent-148, score-1.386]
</p><p>75 The coarse-to-ﬁne phase prediction method was developed in order to facilitate examination of phase coherence in real images, but the computations involved bear some resemblance to the behaviors of neurons in the primary visual cortex (area V1) of mammals. [sent-149, score-1.688]
</p><p>76 First, phase information is measured using pairs of localized bandpass ﬁlters in quadrature, as are widely used to describe the receptive ﬁeld properties of neurons in mammalian primary visual cortex (area V1) [24]. [sent-150, score-0.945]
</p><p>77 Similar “divisive normalization” mechanisms have been successfully used to account for many nonlinear behaviors of neurons in both visual and auditory neurons [26, 27]. [sent-154, score-0.257]
</p><p>78 Thus, it seems that mammalian visual systems are equipped with the basic computational building blocks that can be used to process local phase coherence. [sent-155, score-0.744]
</p><p>79 The importance of local phase coherence in blur perception seems intuitively sensible from the perspective of visual function. [sent-156, score-1.414]
</p><p>80 In particular, the accurate localization of image features is critical to a variety of visual capabilities, including various forms of hyperacuity, stereopsis, and motion estimation. [sent-157, score-0.431]
</p><p>81 Since the localization of image features depends critically on phase coherence, and blurring disrupts phase coherence, blur would seem to be a particularly disturbing artifact. [sent-158, score-1.776]
</p><p>82 This perhaps explains the subjective feeling of frustration when confronted with a blurred image that cannot be corrected by visual accommodation. [sent-159, score-0.541]
</p><p>83 For purposes of machine vision and image processing applications, we view the results of this paper as an important step towards the incorporation of phase properties into statistical models for images. [sent-160, score-0.737]
</p><p>84 Furthermore, if we would like to detect the position of an isolated precisely localized feature from phase samples measured above a certain allowable scale, then inﬁnite precision can be achieved using the phase convergence property illustrated in Fig. [sent-162, score-1.35]
</p><p>85 In other words, the detection precision is limited by the accuracy of phase measurement, rather than the highest spatial sampling density. [sent-164, score-0.642]
</p><p>86 This provides a workable mechanism of “seeing beyond the Nyquist limit” [28], which could explain a number of visual hyperacuity phenomena [29, 30], and may be used for the design of super-precision signal detection devices. [sent-165, score-0.324]
</p><p>87 Tolhurst, “Discrimination of changes in the second-order statistics of natural and synthetic images,” Vis Res, vol. [sent-169, score-0.084]
</p><p>88 Webster, “Neural adjustments to image blur,” Nature Neuroscience, vol. [sent-179, score-0.195]
</p><p>89 Field, “Relations between the statistics of natural images and the response properties of cortical cells,” J. [sent-192, score-0.188]
</p><p>90 Brady, “Visual sensitivity, blur and the sources of variability in the amplitude spectra of natural scenes,” Vis Res, vol. [sent-209, score-0.409]
</p><p>91 Bergen, “Spatiotemporal energy models for the perception of motion,” J Optical Society, vol. [sent-221, score-0.099]
</p><p>92 Owens, “Feature detection from local energy,” Pattern Recognition Letters, vol. [sent-235, score-0.112]
</p><p>93 Thomson, “Visual coding and the phase structure of natural scenes,” Network: Comput. [sent-257, score-0.564]
</p><p>94 Burr, “Feature detection in human vision: A phasedependent energy model,” Proc. [sent-266, score-0.108]
</p><p>95 Owens, “An energy feature detection scheme,” Int’l Conf on Image Processing, pp. [sent-281, score-0.139]
</p><p>96 Jepson, “Computation of component image velocity from local phase information,” Int’l J Computer Vision, no. [sent-287, score-0.74]
</p><p>97 Simoncelli, “A parametric texture model based on joint statistics of complex wavelet coefﬁcients,” Int’l J Computer Vision, vol. [sent-298, score-0.268]
</p><p>98 Daugman, “Statistical richness of visual phase information: update on recognizing persons by iris patterns,” Int’l J Computer Vision, no. [sent-302, score-0.72]
</p><p>99 Heeger, “Half-squaring in responses of cat striate cells,” Visual Neuroscience, no. [sent-325, score-0.1]
</p><p>100 Heeger, “Normalization of cell responses in cat striate cortex,” Visual Neuroscience, no. [sent-330, score-0.1]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('phase', 0.516), ('coherence', 0.336), ('blur', 0.324), ('blurred', 0.243), ('wavelet', 0.232), ('image', 0.163), ('localized', 0.154), ('visual', 0.135), ('blurring', 0.129), ('coef', 0.126), ('wavelets', 0.104), ('images', 0.104), ('cients', 0.097), ('congruency', 0.095), ('sharp', 0.09), ('ej', 0.087), ('fourier', 0.085), ('disruption', 0.076), ('restoration', 0.076), ('hyperacuity', 0.076), ('transform', 0.072), ('histograms', 0.069), ('simoncelli', 0.069), ('int', 0.069), ('disrupts', 0.066), ('features', 0.062), ('local', 0.061), ('precisely', 0.06), ('prediction', 0.06), ('vision', 0.058), ('scale', 0.057), ('conf', 0.057), ('mother', 0.057), ('energy', 0.057), ('amplitudes', 0.055), ('oriented', 0.055), ('adelson', 0.052), ('heeger', 0.052), ('detection', 0.051), ('natural', 0.048), ('phases', 0.046), ('behaviors', 0.046), ('deblurring', 0.044), ('owens', 0.044), ('photographic', 0.044), ('subbands', 0.044), ('unnatural', 0.044), ('webster', 0.044), ('perception', 0.042), ('isolated', 0.042), ('variety', 0.042), ('scales', 0.041), ('spatial', 0.041), ('cortex', 0.041), ('cat', 0.038), ('morrone', 0.038), ('bergen', 0.038), ('disparity', 0.038), ('fleet', 0.038), ('nest', 0.038), ('persons', 0.038), ('ruderman', 0.038), ('relationship', 0.038), ('neurons', 0.038), ('amplitude', 0.037), ('statistics', 0.036), ('transforms', 0.036), ('lter', 0.036), ('nyquist', 0.035), ('vis', 0.035), ('magnitude', 0.035), ('sampling', 0.034), ('signal', 0.033), ('responses', 0.033), ('wiener', 0.032), ('adjustments', 0.032), ('mammalian', 0.032), ('coarser', 0.032), ('pyramid', 0.032), ('neuroscience', 0.032), ('feature', 0.031), ('detect', 0.031), ('lens', 0.031), ('cij', 0.031), ('iris', 0.031), ('across', 0.03), ('highly', 0.03), ('measurement', 0.03), ('symmetric', 0.029), ('motion', 0.029), ('bandpass', 0.029), ('striate', 0.029), ('domain', 0.029), ('mechanism', 0.029), ('lters', 0.028), ('america', 0.028), ('predicted', 0.027), ('examine', 0.027), ('edges', 0.027), ('spectrum', 0.027)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="119-tfidf-1" href="./nips-2003-Local_Phase_Coherence_and_the_Perception_of_Blur.html">119 nips-2003-Local Phase Coherence and the Perception of Blur</a></p>
<p>Author: Zhou Wang, Eero P. Simoncelli</p><p>Abstract: unkown-abstract</p><p>2 0.14142174 <a title="119-tfidf-2" href="./nips-2003-Factorization_with_Uncertainty_and_Missing_Data%3A_Exploiting_Temporal_Coherence.html">69 nips-2003-Factorization with Uncertainty and Missing Data: Exploiting Temporal Coherence</a></p>
<p>Author: Amit Gruber, Yair Weiss</p><p>Abstract: The problem of “Structure From Motion” is a central problem in vision: given the 2D locations of certain points we wish to recover the camera motion and the 3D coordinates of the points. Under simpliﬁed camera models, the problem reduces to factorizing a measurement matrix into the product of two low rank matrices. Each element of the measurement matrix contains the position of a point in a particular image. When all elements are observed, the problem can be solved trivially using SVD, but in any realistic situation many elements of the matrix are missing and the ones that are observed have a diﬀerent directional uncertainty. Under these conditions, most existing factorization algorithms fail while human perception is relatively unchanged. In this paper we use the well known EM algorithm for factor analysis to perform factorization. This allows us to easily handle missing data and measurement uncertainty and more importantly allows us to place a prior on the temporal trajectory of the latent variables (the camera position). We show that incorporating this prior gives a signiﬁcant improvement in performance in challenging image sequences. 1</p><p>3 0.12272569 <a title="119-tfidf-3" href="./nips-2003-A_Neuromorphic_Multi-chip_Model_of_a_Disparity_Selective_Complex_Cell.html">13 nips-2003-A Neuromorphic Multi-chip Model of a Disparity Selective Complex Cell</a></p>
<p>Author: Bertram E. Shi, Eric K. Tsang</p><p>Abstract: The relative depth of objects causes small shifts in the left and right retinal positions of these objects, called binocular disparity. Here, we describe a neuromorphic implementation of a disparity selective complex cell using the binocular energy model, which has been proposed to model the response of disparity selective cells in the visual cortex. Our system consists of two silicon chips containing spiking neurons with monocular Gabor-type spatial receptive fields (RF) and circuits that combine the spike outputs to compute a disparity selective complex cell response. The disparity selectivity of the cell can be adjusted by both position and phase shifts between the monocular RF profiles, which are both used in biology. Our neuromorphic system performs better with phase encoding, because the relative responses of neurons tuned to different disparities by phase shifts are better matched than the responses of neurons tuned by position shifts.</p><p>4 0.1114402 <a title="119-tfidf-4" href="./nips-2003-A_Sampled_Texture_Prior_for_Image_Super-Resolution.html">17 nips-2003-A Sampled Texture Prior for Image Super-Resolution</a></p>
<p>Author: Lyndsey C. Pickup, Stephen J. Roberts, Andrew Zisserman</p><p>Abstract: Super-resolution aims to produce a high-resolution image from a set of one or more low-resolution images by recovering or inventing plausible high-frequency image content. Typical approaches try to reconstruct a high-resolution image using the sub-pixel displacements of several lowresolution images, usually regularized by a generic smoothness prior over the high-resolution image space. Other methods use training data to learn low-to-high-resolution matches, and have been highly successful even in the single-input-image case. Here we present a domain-speciﬁc image prior in the form of a p.d.f. based upon sampled images, and show that for certain types of super-resolution problems, this sample-based prior gives a signiﬁcant improvement over other common multiple-image super-resolution techniques. 1</p><p>5 0.10683445 <a title="119-tfidf-5" href="./nips-2003-Sparse_Representation_and_Its_Applications_in_Blind_Source_Separation.html">179 nips-2003-Sparse Representation and Its Applications in Blind Source Separation</a></p>
<p>Author: Yuanqing Li, Shun-ichi Amari, Sergei Shishkin, Jianting Cao, Fanji Gu, Andrzej S. Cichocki</p><p>Abstract: In this paper, sparse representation (factorization) of a data matrix is ﬁrst discussed. An overcomplete basis matrix is estimated by using the K−means method. We have proved that for the estimated overcomplete basis matrix, the sparse solution (coefﬁcient matrix) with minimum l1 −norm is unique with probability of one, which can be obtained using a linear programming algorithm. The comparisons of the l1 −norm solution and the l0 −norm solution are also presented, which can be used in recoverability analysis of blind source separation (BSS). Next, we apply the sparse matrix factorization approach to BSS in the overcomplete case. Generally, if the sources are not sufﬁciently sparse, we perform blind separation in the time-frequency domain after preprocessing the observed data using the wavelet packets transformation. Third, an EEG experimental data analysis example is presented to illustrate the usefulness of the proposed approach and demonstrate its performance. Two almost independent components obtained by the sparse representation method are selected for phase synchronization analysis, and their periods of signiﬁcant phase synchronization are found which are related to tasks. Finally, concluding remarks review the approach and state areas that require further study. 1</p><p>6 0.08688587 <a title="119-tfidf-6" href="./nips-2003-Generalised_Propagation_for_Fast_Fourier_Transforms_with_Partial_or_Missing_Data.html">80 nips-2003-Generalised Propagation for Fast Fourier Transforms with Partial or Missing Data</a></p>
<p>7 0.086369656 <a title="119-tfidf-7" href="./nips-2003-A_Model_for_Learning_the_Semantics_of_Pictures.html">12 nips-2003-A Model for Learning the Semantics of Pictures</a></p>
<p>8 0.085288852 <a title="119-tfidf-8" href="./nips-2003-Probabilistic_Inference_of_Speech_Signals_from_Phaseless_Spectrograms.html">162 nips-2003-Probabilistic Inference of Speech Signals from Phaseless Spectrograms</a></p>
<p>9 0.07874915 <a title="119-tfidf-9" href="./nips-2003-Using_the_Forest_to_See_the_Trees%3A_A_Graphical_Model_Relating_Features%2C_Objects%2C_and_Scenes.html">192 nips-2003-Using the Forest to See the Trees: A Graphical Model Relating Features, Objects, and Scenes</a></p>
<p>10 0.071264058 <a title="119-tfidf-10" href="./nips-2003-Mutual_Boosting_for_Contextual_Inference.html">133 nips-2003-Mutual Boosting for Contextual Inference</a></p>
<p>11 0.070807546 <a title="119-tfidf-11" href="./nips-2003-Markov_Models_for_Automated_ECG_Interval_Analysis.html">123 nips-2003-Markov Models for Automated ECG Interval Analysis</a></p>
<p>12 0.070132881 <a title="119-tfidf-12" href="./nips-2003-Nonlinear_Filtering_of_Electron_Micrographs_by_Means_of_Support_Vector_Regression.html">139 nips-2003-Nonlinear Filtering of Electron Micrographs by Means of Support Vector Regression</a></p>
<p>13 0.066116199 <a title="119-tfidf-13" href="./nips-2003-Feature_Selection_in_Clustering_Problems.html">73 nips-2003-Feature Selection in Clustering Problems</a></p>
<p>14 0.06487868 <a title="119-tfidf-14" href="./nips-2003-Nonlinear_Processing_in_LGN_Neurons.html">140 nips-2003-Nonlinear Processing in LGN Neurons</a></p>
<p>15 0.064446174 <a title="119-tfidf-15" href="./nips-2003-Eye_Micro-movements_Improve_Stimulus_Detection_Beyond_the_Nyquist_Limit_in_the_Peripheral_Retina.html">67 nips-2003-Eye Micro-movements Improve Stimulus Detection Beyond the Nyquist Limit in the Peripheral Retina</a></p>
<p>16 0.063296765 <a title="119-tfidf-16" href="./nips-2003-Human_and_Ideal_Observers_for_Detecting_Image_Curves.html">85 nips-2003-Human and Ideal Observers for Detecting Image Curves</a></p>
<p>17 0.058704276 <a title="119-tfidf-17" href="./nips-2003-Bounded_Invariance_and_the_Formation_of_Place_Fields.html">43 nips-2003-Bounded Invariance and the Formation of Place Fields</a></p>
<p>18 0.058082707 <a title="119-tfidf-18" href="./nips-2003-Decoding_V1_Neuronal_Activity_using_Particle_Filtering_with_Volterra_Kernels.html">49 nips-2003-Decoding V1 Neuronal Activity using Particle Filtering with Volterra Kernels</a></p>
<p>19 0.057417903 <a title="119-tfidf-19" href="./nips-2003-Image_Reconstruction_by_Linear_Programming.html">88 nips-2003-Image Reconstruction by Linear Programming</a></p>
<p>20 0.055635169 <a title="119-tfidf-20" href="./nips-2003-Probabilistic_Inference_in_Human_Sensorimotor_Processing.html">161 nips-2003-Probabilistic Inference in Human Sensorimotor Processing</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2003_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.173), (1, -0.002), (2, 0.148), (3, -0.02), (4, -0.167), (5, -0.067), (6, 0.106), (7, 0.004), (8, -0.025), (9, -0.028), (10, -0.015), (11, 0.084), (12, -0.051), (13, 0.143), (14, -0.076), (15, -0.026), (16, -0.004), (17, 0.016), (18, -0.057), (19, 0.119), (20, -0.045), (21, -0.018), (22, 0.038), (23, -0.043), (24, -0.03), (25, 0.129), (26, -0.048), (27, 0.013), (28, -0.076), (29, -0.049), (30, -0.007), (31, 0.055), (32, -0.099), (33, -0.078), (34, -0.085), (35, 0.082), (36, -0.066), (37, -0.117), (38, -0.205), (39, -0.045), (40, 0.226), (41, 0.066), (42, 0.038), (43, -0.001), (44, 0.096), (45, -0.111), (46, -0.069), (47, -0.078), (48, 0.027), (49, 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98232913 <a title="119-lsi-1" href="./nips-2003-Local_Phase_Coherence_and_the_Perception_of_Blur.html">119 nips-2003-Local Phase Coherence and the Perception of Blur</a></p>
<p>Author: Zhou Wang, Eero P. Simoncelli</p><p>Abstract: unkown-abstract</p><p>2 0.68832922 <a title="119-lsi-2" href="./nips-2003-A_Neuromorphic_Multi-chip_Model_of_a_Disparity_Selective_Complex_Cell.html">13 nips-2003-A Neuromorphic Multi-chip Model of a Disparity Selective Complex Cell</a></p>
<p>Author: Bertram E. Shi, Eric K. Tsang</p><p>Abstract: The relative depth of objects causes small shifts in the left and right retinal positions of these objects, called binocular disparity. Here, we describe a neuromorphic implementation of a disparity selective complex cell using the binocular energy model, which has been proposed to model the response of disparity selective cells in the visual cortex. Our system consists of two silicon chips containing spiking neurons with monocular Gabor-type spatial receptive fields (RF) and circuits that combine the spike outputs to compute a disparity selective complex cell response. The disparity selectivity of the cell can be adjusted by both position and phase shifts between the monocular RF profiles, which are both used in biology. Our neuromorphic system performs better with phase encoding, because the relative responses of neurons tuned to different disparities by phase shifts are better matched than the responses of neurons tuned by position shifts.</p><p>3 0.49053466 <a title="119-lsi-3" href="./nips-2003-Impact_of_an_Energy_Normalization_Transform_on_the_Performance_of_the_LF-ASD_Brain_Computer_Interface.html">89 nips-2003-Impact of an Energy Normalization Transform on the Performance of the LF-ASD Brain Computer Interface</a></p>
<p>Author: Yu Zhou, Steven G. Mason, Gary E. Birch</p><p>Abstract: This paper presents an energy normalization transform as a method to reduce system errors in the LF-ASD brain-computer interface. The energy normalization transform has two major benefits to the system performance. First, it can increase class separation between the active and idle EEG data. Second, it can desensitize the system to the signal amplitude variability. For four subjects in the study, the benefits resulted in the performance improvement of the LF-ASD in the range from 7.7% to 18.9%, while for the fifth subject, who had the highest non-normalized accuracy of 90.5%, the performance did not change notably with normalization. 1 In trod u ction In an effort to provide alternative communication channels for people who suffer from severe loss of motor function, several researchers have worked over the past two decades to develop a direct Brain-Computer Interface (BCI). Since electroencephalographic (EEG) signal has good time resolution and is non-invasive, it is commonly used for data source of a BCI. A BCI system converts the input EEG into control signals, which are then used to control devices like computers, environmental control system and neuro-prostheses. Mason and Birch [1] proposed the Low-Frequency Asynchronous Switch Design (LF-ASD) as a BCI which detected imagined voluntary movement-related potentials (IVMRPs) in spontaneous EEG. The principle signal processing components of the LF-ASD are shown in Figure 1. sIN Feature Extractor sLPF LPF Feature Classifier sFE sFC Figure 1: The original LF-ASD design. The input to the low-pass filter (LPF), denoted as SIN in Figure 1, are six bipolar EEG signals recorded from F1-FC1, Fz-FCz, F2-FC2, FC1-C1, FCz-Cz and FC2-C2 sampled at 128 Hz. The cutoff frequency of the LPF implemented by Mason and Birch was 4 Hz. The Feature Extractor of the LF-ASD extracts custom features related to IVMRPs. The Feature Classifier implements a one-nearest-neighbor (1NN) classifier, which determines if the input signals are related to a user state of voluntary movement or passive (idle) observation. The LF-ASD was able to achieve True Positive (TP) values in the range of 44%-81%, with the corresponding False Positive (FP) values around 1% [1]. Although encouraging, the current error rates of the LF-ASD are insufficient for real-world applications. This paper proposes a method to improve the system performance. 2 Design and Rationale The improved design of the LF-ASD with the Energy Normalization Transform (ENT) is provided in Figure 2. SIN ENT SN SNLPF LPF Feature Extractor SNFE SNFC Feature Classifier Figure 2: The improved LF-ASD with the Energy Normalization Transform. The design of the Feature Extractor and Feature Classifier were the same as shown in Figure 1. The Energy Normalization Transform (ENT) is implemented as S N (n ) = S s=( w s= − ( N ∑ w IN S IN −1) / 2 N −1) / 2 (n ) 2 (n − s) w N where W N (normalization window size) is the only parameter in the equation. The optimal parameter value was obtained by exhaustive search for the best class separation between active and idle EEG data. The method of obtaining the active and idle EEG data is provided in Section 3.1. The idea to use energy normalization to improve the LF-ASD design was based primarily on an observation that high frequency power decreases significantly around movement. For example, Jasper and Penfield [3] and Pfurtscheller et al, [4] reported EEG power decrease in the mu (8-12 Hz) and beta rhythm (18-26 Hz) when people are involved in motor related activity. Also Mason [5] found that the power in the frequency components greater than 4Hz decreased significantly during movement-related potential periods, while power in the frequency components less than 4Hz did not. Thus energy normalization, which would increase the low frequency power level, would strengthen the 0-4 Hz features used in the LF-ASD and hence reduce errors. In addition, as a side benefit, it can automatically adjust the mean scale of the input signal and desensitize the system to change in EEG power, which is known to vary over time [2]. Therefore, it was postulated that the addition of ENT into the improved design would have two major benefits. First, it can increase the EEG power around motor potentials, consequently increasing the class separation and feature strength. Second, it can desensitize the system to amplitude variance of the input signal. In addition, since the system components of the modified LF-ASD after the ENT were the same as in the original design, a major concern was whether or not the ENT distorted the features used by the LF-ASD. Since the features used by the LFASD are generated from the 0-4 Hz band, if the ENT does not distort the phase and magnitude spectrum in this specific band, it would not distort the features related to movement potential detection in the application. 3 3.1 Evaluation Test data Two types of EEG data were pre-recorded from five able-bodied individuals as shown in Figure 3. Active Data Type and Idle Data Type. Active Data was recorded during repeated right index finger flexions alternating with periods of no motor activity; Idle Data was recorded during extended periods of passive observation. Figure 3: Data Definition of M1, M2, Idle1 and Idle2. Observation windows centered at the time of the finger switch activations (as shown in Figure 4) were imposed in the active data to separate data related to movements from data during periods of idleness. For purpose of this study, data in the front part of the observation window was defined as M1 and data in the rear part of the window was defined as M2. Data falling out of the observation window was defined as Idle2. All the data in the Idle Data Type was defined as Idle1 for comparison with Idle2. Figure 4: Ensemble Average of EEG centered on finger activations. Figure 5: Density distribution of Idle1, Idle2, M1 and M2. It was noted, in terms of the density distribution of active and idle data, the separation between M2 and Idle2 was the largest and Idle1 and Idle2 were nearly identical (see Figure 5). For the study, M2 and Idle2 were chosen to represent the active and idle data classes and the separation between M2 and Idle2 data was defined by the difference of means (DOM) scaled by the amplitude range of Idle2. 3.2 Optimal parameter determination The optimal combination of normalization window size, W N, and observation window size, W O was selected to be that which achieved the maximal DOM value. This was determined by exhaustive search, and discussed in Section 4.1. 3.3 Effect of ENT on the Low Pass Filter output As mentioned previously, it was postulated that the ENT had two major impacts: increasing the class separation between active and idle EEG and desensitizing the system to the signal amplitude variance. The hypothesis was evaluated by comparing characteristics of SNLPF and SLPF in Figure 1 and Figure 2. DOM was applied to measure the increased class separation. The signal with the larger DOM meant larger class separation. In addition, the signal with smaller standard deviation may result in a more stable feature set. 3.4 Effect of ENT on the LF-ASD output The performances of the original and improved designs were evaluated by comparing the signal characteristics of SNFC in Figure 2 to SFC in Figure 1. A Receiver Operating Characteristic Curve (ROC Curve) [6] was generated for the original and improved designs. The ROC Curve characterizes the system performance over a range of TP vs. FP values. The larger area under ROC Curve indicates better system performance. In real applications, a BCI with high-level FP rates could cause frustration for subjects. Therefore, in this work only the LF-ASD performance when the FP values are less than 1% were studied. 4 4.1 Results Optimal normalization window size (WN) The method to choose optimal WN was an exhaustive search for maximal DOM between active and idle classes. This method was possibly dependent on the observation window size (W O). However, as shown in Figure 6a, the optimal WN was found to be independent of WO. Experimentally, the W O values were selected in the range of 50-60 samples, which corresponded to largest DOM between nonnormalized active and idle data. The optimal WN was obtained by exhaustive search for the largest DOM through normalized active and idle data. The DOM vs. WN profile for Subject 1 is shown in Figure 6b. a) b) Figure 6: Optimal parameter determination for Subject 1 in Channel 1 a) DOM vs. WO; b) DOM vs. WN. When using ENT, a small W N value may cause distortion to the feature set used by the LF-ASD. Thus, the optimal W N was not selected in this range (< 40 samples). When W N is greater than 200, the ENT has lost its capability to increase class separation and the DOM curve gradually goes towards the best separation without normalization. Thus, the optimal W N should correspond to the maximal DOM value when W N is in the range from 40 to 200. In Figure 6b, the optimal WN is around 51. 4.2 Effect of ENT on the Low Pass Filter output With ENT, the standard deviation of the low frequency EEG signal decreased from around 1.90 to 1.30 over the six channels and over the five subjects. This change resulted in more stable feature sets. Thus, the ENT desensitizes the system to input signal variance. a) b) Figure 7: Density distribution of the active vs. idle class without (a) and with (b) ENT, for Subject 1 in Channel 1. As shown in Figure 7, by increasing the EEG power around motor potentials, ENT can increase class separations between active and idle EEG data. The class separation in (frontal) Channels 1-3 across all subjects increased consistently with the proposed ENT. The same was true for (midline) Channels 4-6, for all subjects except Subject 5, whose DOM in channel 5-6 decreased by 2.3% and 3.4% respectively with normalization. That is consistent with the fact that his EEG power in Channels 4-6 does not decrease. On average, across all five subjects, DOM increases with normalization to about 28.8%, 26.4%, 39.4%, 20.5%, 17.8% and 22.5% over six channels respectively. In addition, the magnitude and phase spectrums of the EEG signal before and after ENT is provided in Figure 8. The ENT has no visible distortion to the signal in the low frequency band (0-4 Hz) used by the LF-ASD. Therefore, the ENT does not distort the features used by the LF-ASD. (a) (b) Figure 8: Magnitude and phase spectrum of the EEG signal before and after ENT. 4.3 Effect of ENT on the LF-ASD output The two major benefits of the ENT to the low frequency EEG data result in the performance improvement of the LF-ASD. Subject 1’s ROC Curves with and without ENT is shown in Figure 9, where the ROC-Curve with ENT of optimal parameter value is above the ROC Curve without ENT. This indicates that the improved LF-ASD performs better. Table I compares the system performance with and without ENT in terms of TP with corresponding FP at 1% across all the 5 subjects. Figure 9: The ROC Curves (in the section of interest) of Subject 1 with different WN values and the corresponding ROC Curve without ENT. Table I: Performance of the LF-ASD with and without LF-ASD in terms of the True Positive rate with corresponding False Positive at 1%. Subject 1 Subject 2 Subject 3 Subject 4 Subject 5 TP without ENT 66.1% 82.7% 79.7% 79.3% 90.5% TP with ENT 85.0% 90.4% 88.0% 87.8% 88.7% Performance Improvement 18.9% 7.7% 8.3% 8.5% -1.8% For 4 out of 5 subjects, corresponding with the FP at 1%, the improved system with ENT increased the TP value by 7.7%, 8.3%, 8.5% and 18.9% respectively. Thus, for these subjects, the range of TP with FP at 1% was improved from 66.1%-82.7% to 85.0%-90.4% with ENT. For the fifth subject, who had the highest non-normalized accuracy of 90.5%, the performance remained around 90% with ENT. In addition, this evaluation is conservative. Since the codebook in the Feature Classifier and the parameters in the Feature Extractor of the LF-ASD were derived from nonnormalized EEG, they work in favor of the non-normalized EEG. Therefore, if the parameters and the codebook of the modified LF-ASD are generated from the normalized EEG in the future, the modified LF-ASD may show better performance than this evaluation. 5 Conclusion The evaluation with data from five able-bodied subjects indicates that the proposed system with Energy Normalization Transform (ENT) has better performance than the original. This study has verified the original hypotheses that the improved design with ENT might have two major benefits: increased the class separation between active and idle EEG and desensitized the system performance to input amplitude variance. As a side benefit, the ENT can also make the design less sensitive to the mean input scale. In the broad band, the Energy Normalization Transform is a non-linear transform. However, it has no visible distortion to the signal in the 0-4 Hz band. Therefore, it does not distort the features used by the LF-ASD. For 4 out of 5 subjects, with the corresponding False Positive rate at 1%, the proposed transform increased the system performance by 7.7%, 8.3%, 8.5% and 18.9% respectively in terms of True Positive rate. Thus, the overall performance of the LF-ASD for these subjects was improved from 66.1%-82.7% to 85.0%-90.4%. For the fifth subject, who had the highest non-normalized accuracy of 90.5%, the performance did not change notably with normalization. In the future with the codebook derived from the normalized data, the performance could be further improved. References [1] Mason, S. G. and Birch, G. E., (2000) A Brain-Controlled Switch for Asynchronous Control Applications. IEEE Trans Biomed Eng, 47(10):1297-1307. [2] Vaughan, T. M., Wolpaw, J. R., and Donchin, E. (1996) EEG-Based Communication: Prospects and Problems. IEEE Trans Reh Eng, 4(4):425-430. [3] Jasper, H. and Penfield, W. (1949) Electrocortiograms in man: Effect of voluntary movement upon the electrical activity of the precentral gyrus. Arch.Psychiat.Nervenkr., 183:163-174. [4] Pfurtscheller, G., Neuper, C., and Flotzinger, D. (1997) EEG-based discrimination between imagination of right and left hand movement. Electroencephalography and Clinical Neurophysiology, 103:642-651. [5] Mason, S. G. (1997) Detection of single trial index finger flexions from continuous, spatiotemporal EEG. PhD Thesis, UBC, January. [6] Green, D. M. and Swets, J. A. (1996) Signal Detection Theory and Psychophysics New York: John Wiley and Sons, Inc.</p><p>4 0.48430735 <a title="119-lsi-4" href="./nips-2003-Factorization_with_Uncertainty_and_Missing_Data%3A_Exploiting_Temporal_Coherence.html">69 nips-2003-Factorization with Uncertainty and Missing Data: Exploiting Temporal Coherence</a></p>
<p>Author: Amit Gruber, Yair Weiss</p><p>Abstract: The problem of “Structure From Motion” is a central problem in vision: given the 2D locations of certain points we wish to recover the camera motion and the 3D coordinates of the points. Under simpliﬁed camera models, the problem reduces to factorizing a measurement matrix into the product of two low rank matrices. Each element of the measurement matrix contains the position of a point in a particular image. When all elements are observed, the problem can be solved trivially using SVD, but in any realistic situation many elements of the matrix are missing and the ones that are observed have a diﬀerent directional uncertainty. Under these conditions, most existing factorization algorithms fail while human perception is relatively unchanged. In this paper we use the well known EM algorithm for factor analysis to perform factorization. This allows us to easily handle missing data and measurement uncertainty and more importantly allows us to place a prior on the temporal trajectory of the latent variables (the camera position). We show that incorporating this prior gives a signiﬁcant improvement in performance in challenging image sequences. 1</p><p>5 0.48019883 <a title="119-lsi-5" href="./nips-2003-A_Sampled_Texture_Prior_for_Image_Super-Resolution.html">17 nips-2003-A Sampled Texture Prior for Image Super-Resolution</a></p>
<p>Author: Lyndsey C. Pickup, Stephen J. Roberts, Andrew Zisserman</p><p>Abstract: Super-resolution aims to produce a high-resolution image from a set of one or more low-resolution images by recovering or inventing plausible high-frequency image content. Typical approaches try to reconstruct a high-resolution image using the sub-pixel displacements of several lowresolution images, usually regularized by a generic smoothness prior over the high-resolution image space. Other methods use training data to learn low-to-high-resolution matches, and have been highly successful even in the single-input-image case. Here we present a domain-speciﬁc image prior in the form of a p.d.f. based upon sampled images, and show that for certain types of super-resolution problems, this sample-based prior gives a signiﬁcant improvement over other common multiple-image super-resolution techniques. 1</p><p>6 0.47519505 <a title="119-lsi-6" href="./nips-2003-Eye_Micro-movements_Improve_Stimulus_Detection_Beyond_the_Nyquist_Limit_in_the_Peripheral_Retina.html">67 nips-2003-Eye Micro-movements Improve Stimulus Detection Beyond the Nyquist Limit in the Peripheral Retina</a></p>
<p>7 0.46430022 <a title="119-lsi-7" href="./nips-2003-Markov_Models_for_Automated_ECG_Interval_Analysis.html">123 nips-2003-Markov Models for Automated ECG Interval Analysis</a></p>
<p>8 0.42530805 <a title="119-lsi-8" href="./nips-2003-Nonlinear_Filtering_of_Electron_Micrographs_by_Means_of_Support_Vector_Regression.html">139 nips-2003-Nonlinear Filtering of Electron Micrographs by Means of Support Vector Regression</a></p>
<p>9 0.41579908 <a title="119-lsi-9" href="./nips-2003-The_Diffusion-Limited_Biochemical_Signal-Relay_Channel.html">184 nips-2003-The Diffusion-Limited Biochemical Signal-Relay Channel</a></p>
<p>10 0.41099015 <a title="119-lsi-10" href="./nips-2003-Probabilistic_Inference_of_Speech_Signals_from_Phaseless_Spectrograms.html">162 nips-2003-Probabilistic Inference of Speech Signals from Phaseless Spectrograms</a></p>
<p>11 0.39805275 <a title="119-lsi-11" href="./nips-2003-Sparse_Representation_and_Its_Applications_in_Blind_Source_Separation.html">179 nips-2003-Sparse Representation and Its Applications in Blind Source Separation</a></p>
<p>12 0.38428649 <a title="119-lsi-12" href="./nips-2003-Bounded_Invariance_and_the_Formation_of_Place_Fields.html">43 nips-2003-Bounded Invariance and the Formation of Place Fields</a></p>
<p>13 0.37737721 <a title="119-lsi-13" href="./nips-2003-A_Model_for_Learning_the_Semantics_of_Pictures.html">12 nips-2003-A Model for Learning the Semantics of Pictures</a></p>
<p>14 0.37031123 <a title="119-lsi-14" href="./nips-2003-Image_Reconstruction_by_Linear_Programming.html">88 nips-2003-Image Reconstruction by Linear Programming</a></p>
<p>15 0.36831266 <a title="119-lsi-15" href="./nips-2003-Plasticity_Kernels_and_Temporal_Statistics.html">157 nips-2003-Plasticity Kernels and Temporal Statistics</a></p>
<p>16 0.35966429 <a title="119-lsi-16" href="./nips-2003-Unsupervised_Color_Decomposition_Of_Histologically_Stained_Tissue_Samples.html">190 nips-2003-Unsupervised Color Decomposition Of Histologically Stained Tissue Samples</a></p>
<p>17 0.35478753 <a title="119-lsi-17" href="./nips-2003-Using_the_Forest_to_See_the_Trees%3A_A_Graphical_Model_Relating_Features%2C_Objects%2C_and_Scenes.html">192 nips-2003-Using the Forest to See the Trees: A Graphical Model Relating Features, Objects, and Scenes</a></p>
<p>18 0.34657159 <a title="119-lsi-18" href="./nips-2003-Generalised_Propagation_for_Fast_Fourier_Transforms_with_Partial_or_Missing_Data.html">80 nips-2003-Generalised Propagation for Fast Fourier Transforms with Partial or Missing Data</a></p>
<p>19 0.33587632 <a title="119-lsi-19" href="./nips-2003-Nonlinear_Processing_in_LGN_Neurons.html">140 nips-2003-Nonlinear Processing in LGN Neurons</a></p>
<p>20 0.32666686 <a title="119-lsi-20" href="./nips-2003-A_Mixed-Signal_VLSI_for_Real-Time_Generation_of_Edge-Based_Image_Vectors.html">11 nips-2003-A Mixed-Signal VLSI for Real-Time Generation of Edge-Based Image Vectors</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2003_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.029), (11, 0.055), (29, 0.012), (30, 0.039), (35, 0.065), (53, 0.091), (69, 0.014), (71, 0.059), (76, 0.039), (85, 0.067), (91, 0.103), (93, 0.321), (99, 0.011)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.82112128 <a title="119-lda-1" href="./nips-2003-Local_Phase_Coherence_and_the_Perception_of_Blur.html">119 nips-2003-Local Phase Coherence and the Perception of Blur</a></p>
<p>Author: Zhou Wang, Eero P. Simoncelli</p><p>Abstract: unkown-abstract</p><p>2 0.7511518 <a title="119-lda-2" href="./nips-2003-Warped_Gaussian_Processes.html">194 nips-2003-Warped Gaussian Processes</a></p>
<p>Author: Edward Snelson, Zoubin Ghahramani, Carl E. Rasmussen</p><p>Abstract: We generalise the Gaussian process (GP) framework for regression by learning a nonlinear transformation of the GP outputs. This allows for non-Gaussian processes and non-Gaussian noise. The learning algorithm chooses a nonlinear transformation such that transformed data is well-modelled by a GP. This can be seen as including a preprocessing transformation as an integral part of the probabilistic modelling problem, rather than as an ad-hoc step. We demonstrate on several real regression problems that learning the transformation can lead to signiﬁcantly better performance than using a regular GP, or a GP with a ﬁxed transformation. 1</p><p>3 0.65940332 <a title="119-lda-3" href="./nips-2003-Fast_Feature_Selection_from_Microarray_Expression_Data_via_Multiplicative_Large_Margin_Algorithms.html">72 nips-2003-Fast Feature Selection from Microarray Expression Data via Multiplicative Large Margin Algorithms</a></p>
<p>Author: Claudio Gentile</p><p>Abstract: New feature selection algorithms for linear threshold functions are described which combine backward elimination with an adaptive regularization method. This makes them particularly suitable to the classiﬁcation of microarray expression data, where the goal is to obtain accurate rules depending on few genes only. Our algorithms are fast and easy to implement, since they center on an incremental (large margin) algorithm which allows us to avoid linear, quadratic or higher-order programming methods. We report on preliminary experiments with ﬁve known DNA microarray datasets. These experiments suggest that multiplicative large margin algorithms tend to outperform additive algorithms (such as SVM) on feature selection tasks. 1</p><p>4 0.49169862 <a title="119-lda-4" href="./nips-2003-All_learning_is_Local%3A_Multi-agent_Learning_in_Global_Reward_Games.html">20 nips-2003-All learning is Local: Multi-agent Learning in Global Reward Games</a></p>
<p>Author: Yu-han Chang, Tracey Ho, Leslie P. Kaelbling</p><p>Abstract: In large multiagent games, partial observability, coordination, and credit assignment persistently plague attempts to design good learning algorithms. We provide a simple and efﬁcient algorithm that in part uses a linear system to model the world from a single agent’s limited perspective, and takes advantage of Kalman ﬁltering to allow an agent to construct a good training signal and learn an effective policy. 1</p><p>5 0.48568621 <a title="119-lda-5" href="./nips-2003-Learning_with_Local_and_Global_Consistency.html">113 nips-2003-Learning with Local and Global Consistency</a></p>
<p>Author: Dengyong Zhou, Olivier Bousquet, Thomas N. Lal, Jason Weston, Bernhard Schölkopf</p><p>Abstract: We consider the general problem of learning from labeled and unlabeled data, which is often called semi-supervised learning or transductive inference. A principled approach to semi-supervised learning is to design a classifying function which is sufﬁciently smooth with respect to the intrinsic structure collectively revealed by known labeled and unlabeled points. We present a simple algorithm to obtain such a smooth solution. Our method yields encouraging experimental results on a number of classiﬁcation problems and demonstrates effective use of unlabeled data. 1</p><p>6 0.48528183 <a title="119-lda-6" href="./nips-2003-Discriminative_Fields_for_Modeling_Spatial_Dependencies_in_Natural_Images.html">54 nips-2003-Discriminative Fields for Modeling Spatial Dependencies in Natural Images</a></p>
<p>7 0.48475015 <a title="119-lda-7" href="./nips-2003-Learning_Spectral_Clustering.html">107 nips-2003-Learning Spectral Clustering</a></p>
<p>8 0.48428473 <a title="119-lda-8" href="./nips-2003-Large_Margin_Classifiers%3A_Convex_Loss%2C_Low_Noise%2C_and_Convergence_Rates.html">101 nips-2003-Large Margin Classifiers: Convex Loss, Low Noise, and Convergence Rates</a></p>
<p>9 0.48336592 <a title="119-lda-9" href="./nips-2003-Gaussian_Processes_in_Reinforcement_Learning.html">78 nips-2003-Gaussian Processes in Reinforcement Learning</a></p>
<p>10 0.48238379 <a title="119-lda-10" href="./nips-2003-Approximability_of_Probability_Distributions.html">30 nips-2003-Approximability of Probability Distributions</a></p>
<p>11 0.48226753 <a title="119-lda-11" href="./nips-2003-Measure_Based_Regularization.html">126 nips-2003-Measure Based Regularization</a></p>
<p>12 0.48090017 <a title="119-lda-12" href="./nips-2003-Maximum_Likelihood_Estimation_of_a_Stochastic_Integrate-and-Fire_Neural_Model.html">125 nips-2003-Maximum Likelihood Estimation of a Stochastic Integrate-and-Fire Neural Model</a></p>
<p>13 0.48058999 <a title="119-lda-13" href="./nips-2003-Denoising_and_Untangling_Graphs_Using_Degree_Priors.html">50 nips-2003-Denoising and Untangling Graphs Using Degree Priors</a></p>
<p>14 0.47986224 <a title="119-lda-14" href="./nips-2003-A_Model_for_Learning_the_Semantics_of_Pictures.html">12 nips-2003-A Model for Learning the Semantics of Pictures</a></p>
<p>15 0.4791683 <a title="119-lda-15" href="./nips-2003-Dynamical_Modeling_with_Kernels_for_Nonlinear_Time_Series_Prediction.html">57 nips-2003-Dynamical Modeling with Kernels for Nonlinear Time Series Prediction</a></p>
<p>16 0.47876689 <a title="119-lda-16" href="./nips-2003-Information_Dynamics_and_Emergent_Computation_in_Recurrent_Circuits_of_Spiking_Neurons.html">93 nips-2003-Information Dynamics and Emergent Computation in Recurrent Circuits of Spiking Neurons</a></p>
<p>17 0.47827658 <a title="119-lda-17" href="./nips-2003-Feature_Selection_in_Clustering_Problems.html">73 nips-2003-Feature Selection in Clustering Problems</a></p>
<p>18 0.47769877 <a title="119-lda-18" href="./nips-2003-Geometric_Analysis_of_Constrained_Curves.html">81 nips-2003-Geometric Analysis of Constrained Curves</a></p>
<p>19 0.47732997 <a title="119-lda-19" href="./nips-2003-Gene_Expression_Clustering_with_Functional_Mixture_Models.html">79 nips-2003-Gene Expression Clustering with Functional Mixture Models</a></p>
<p>20 0.47680897 <a title="119-lda-20" href="./nips-2003-On_the_Dynamics_of_Boosting.html">143 nips-2003-On the Dynamics of Boosting</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
