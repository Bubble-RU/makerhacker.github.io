<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>172 nips-2007-Scene Segmentation with CRFs Learned from Partially Labeled Images</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-172" href="../nips2007/nips-2007-Scene_Segmentation_with_CRFs_Learned_from_Partially_Labeled_Images.html">nips2007-172</a> <a title="nips-2007-172-reference" href="#">nips2007-172-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>172 nips-2007-Scene Segmentation with CRFs Learned from Partially Labeled Images</h1>
<br/><p>Source: <a title="nips-2007-172-pdf" href="http://papers.nips.cc/paper/3268-scene-segmentation-with-crfs-learned-from-partially-labeled-images.pdf">pdf</a></p><p>Author: Bill Triggs, Jakob J. Verbeek</p><p>Abstract: Conditional Random Fields (CRFs) are an effective tool for a variety of different data segmentation and labeling tasks including visual scene interpretation, which seeks to partition images into their constituent semantic-level regions and assign appropriate class labels to each region. For accurate labeling it is important to capture the global context of the image as well as local information. We introduce a CRF based scene labeling model that incorporates both local features and features aggregated over the whole image or large sections of it. Secondly, traditional CRF learning requires fully labeled datasets which can be costly and troublesome to produce. We introduce a method for learning CRFs from datasets with many unlabeled nodes by marginalizing out the unknown labels so that the log-likelihood of the known ones can be maximized by gradient ascent. Loopy Belief Propagation is used to approximate the marginals needed for the gradient and log-likelihood calculations and the Bethe free-energy approximation to the log-likelihood is monitored to control the step size. Our experimental results show that effective models can be learned from fragmentary labelings and that incorporating top-down aggregate features signiﬁcantly improves the segmentations. The resulting segmentations are compared to the state-of-the-art on three different image datasets. 1</p><br/>
<h2>reference text</h2><p>[1] P. Jansen, W. van der Mark, W. van den Heuvel, and F. Groen. Colour based off-road environment and terrain type classiﬁcation. In Proceedings of the IEEE Conference on Intelligent Transportation Systems, pages 216–221, 2005.</p>
<p>[2] S. Geman and D. Geman. Stochastic relaxation, Gibbs distributions and the Bayesian restoration of images. IEEE Transactions on Pattern Analysis and Machine Intelligence, 6(6):712–741, 1984.</p>
<p>[3] C. Rother, V. Kolmogorov, and A. Blake. GrabCut: interactive foreground extraction using iterated graph cuts. ACM Transactions on Graphics, 23(3):309–314, 2004.</p>
<p>[4] J. Lafferty, A. McCallum, and F. Pereira. Conditional random ﬁelds: probabilistic models for segmenting and labeling sequence data. In Proceedings of the International Conference on Machine Learning, volume 18, pages 282–289, 2001.</p>
<p>[5] X. He, R. Zemel, and M. Carreira-Perpi˜ an. Multiscale conditional random ﬁelds for image labelling. In n´ Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 695–702, 2004.</p>
<p>[6] S. Kumar and M. Hebert. A hierarchical ﬁeld framework for uniﬁed context-based classiﬁcation. In Proceedings of the IEEE International Conference on Computer Vision, pages 1284–1291, 2005.</p>
<p>[7] J. Shotton, J. Winn, C. Rother, and A. Criminisi. Textonboost: joint appearance, shape and context modeling for multi-class object recognition and segmentation. In Proceedings of the European Conference on Computer Vision, pages 1–15, 2006.</p>
<p>[8] A. Quattoni, M. Collins, and T. Darrell. Conditional random ﬁelds for object recognition. In Advances in Neural Information Processing Systems, volume 17, pages 1097–1104, 2005.</p>
<p>[9] P. Carbonetto, G. Dork´ , C. Schmid, H. K¨ ck, and N. de Freitas. A semi-supervised learning approach to o u object recognition with spatial integration of local features and segmentation cues. In Toward CategoryLevel Object Recognition, pages 277–300, 2006.</p>
<p>[10] J. Verbeek and B. Triggs. Region classiﬁcation with Markov ﬁeld aspect models. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2007.</p>
<p>[11] D. Lowe. Distinctive image features from scale-invariant keypoints. International Journal of Computer Vision, 60(2):91–110, 2004.</p>
<p>[12] J. van de Weijer and C. Schmid. Coloring local feature extraction. In Proceedings of the European Conference on Computer Vision, pages 334–348, 2006.</p>
<p>[13] The 2005 PASCAL visual object classes challenge. In F. d’Alche-Buc, I. Dagan, and J. Quinonero, editors, Machine Learning Challenges: Evaluating Predictive Uncertainty, Visual Object Classiﬁcation, and Recognizing Textual Entailment, First PASCAL Machine Learning Challenges Workshop. Springer, 2006.</p>
<p>[14] J. Yedidia, W. Freeman, and Y. Weiss. Understanding belief propagation and its generalizations. Technical Report TR-2001-22, Mitsubishi Electric Research Laboratories, 2001.</p>
<p>[15] F. Schroff, A. Criminisi, and A. Zisserman. Single-histogram class models for image segmentation. In Proceedings of the Indian Conference on Computer Vision, Graphics and Image Processing, 2006.  7  MSRC CRFσ loc+glo Labeling Sowerby CRFσ loc+glo Labeling Corel CRFσ loc+glo Labeling  Figure 4: Samples from the MSRC, Sowerby, and Corel datasets with segmentation and labeling.  8</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
