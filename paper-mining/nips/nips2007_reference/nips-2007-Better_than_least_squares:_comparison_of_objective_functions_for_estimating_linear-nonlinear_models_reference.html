<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>36 nips-2007-Better than least squares: comparison of objective functions for estimating linear-nonlinear models</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-36" href="../nips2007/nips-2007-Better_than_least_squares%3A_comparison_of_objective_functions_for_estimating_linear-nonlinear_models.html">nips2007-36</a> <a title="nips-2007-36-reference" href="#">nips2007-36-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>36 nips-2007-Better than least squares: comparison of objective functions for estimating linear-nonlinear models</h1>
<br/><p>Source: <a title="nips-2007-36-pdf" href="http://papers.nips.cc/paper/3242-better-than-least-squares-comparison-of-objective-functions-for-estimating-linear-nonlinear-models.pdf">pdf</a></p><p>Author: Tatyana Sharpee</p><p>Abstract: This paper compares a family of methods for characterizing neural feature selectivity with natural stimuli in the framework of the linear-nonlinear model. In this model, the neural ﬁring rate is a nonlinear function of a small number of relevant stimulus components. The relevant stimulus dimensions can be found by maximizing one of the family of objective functions, R´ nyi divergences of different e orders [1, 2]. We show that maximizing one of them, R´ nyi divergence of ore der 2, is equivalent to least-square ﬁtting of the linear-nonlinear model to neural data. Next, we derive reconstruction errors in relevant dimensions found by maximizing R´ nyi divergences of arbitrary order in the asymptotic limit of large spike e numbers. We ﬁnd that the smallest errors are obtained with R´ nyi divergence of e order 1, also known as Kullback-Leibler divergence. This corresponds to ﬁnding relevant dimensions by maximizing mutual information [2]. We numerically test how these optimization schemes perform in the regime of low signal-to-noise ratio (small number of spikes and increasing neural noise) for model visual neurons. We ﬁnd that optimization schemes based on either least square ﬁtting or information maximization perform well even when number of spikes is small. Information maximization provides slightly, but signiﬁcantly, better reconstructions than least square ﬁtting. This makes the problem of ﬁnding relevant dimensions, together with the problem of lossy compression [3], one of examples where informationtheoretic measures are no more data limited than those derived from least squares. 1</p><br/>
<h2>reference text</h2><p>[1] L. Paninski. Convergence properties of three spike-triggered average techniques. Network: Comput. Neural Syst., 14:437–464, 2003.</p>
<p>[2] T. Sharpee, N.C. Rust, and W. Bialek. Analyzing neural responses to natural signals: Maximally informatiove dimensions. Neural Computation, 16:223–250, 2004. See also physics/0212110, and a preliminary account in Advances in Neural Information Processing 15 edited by S. Becker, S. Thrun, and K. Obermayer, pp. 261-268 (MIT Press, Cambridge, 2003).</p>
<p>[3] Peter Harremo¨ s and Naftali Tishby. The Information bottleneck revisited or how to choose a good e distortion measure. Proc. of the IEEE Int. Symp. on Information Theory (ISIT), 2007.</p>
<p>[4] E. de Boer and P. Kuyper. Triggered correlation. IEEE Trans. Biomed. Eng., 15:169–179, 1968.</p>
<p>[5] I. W. Hunter and M. J. Korenberg. The identiﬁcation of nonlinear biological systems: Wiener and Hammerstein cascade models. Biol. Cybern., 55:135–144, 1986.</p>
<p>[6] R. R. de Ruyter van Steveninck and W. Bialek. Real-time performance of a movement-sensitive neuron in the blowﬂy visual system: coding and information transfer in short spike sequences. Proc. R. Soc. Lond. B, 265:259–265, 1988.</p>
<p>[7] V. Z. Marmarelis. Modeling Methodology for Nonlinear Physiological Systems. Ann. Biomed. Eng., 25:239–251, 1997.</p>
<p>[8] W. Bialek and R. R. de Ruyter van Steveninck. Features and dimensions: Motion estimation in ﬂy vision. q-bio/0505003, 2005.</p>
<p>[9] D. L. Ringach, G. Sapiro, and R. Shapley. A subspace reverse-correlation technique for hte study of visual neurons. Vision Res., 37:2455–2464, 1997.</p>
<p>[10] D. L. Ruderman and W. Bialek. Statistics of natural images: scaling in the woods. Phys. Rev. Lett., 73:814–817, 1994.</p>
<p>[11] T. O. Sharpee, H. Sugihara, A. V. Kurgansky, S. P. Rebrik, M. P. Stryker, and K. D. Miller. Adaptive ﬁltering enhances information transmission in visual cortex. Nature, 439:936–942, 2006.</p>
<p>[12] S. M. Ali and S. D. Silvey. A general class of coefﬁceint of divergence of one distribution from another. J. R. Statist. Soc. B, 28:131–142, 1966.</p>
<p>[13] I. Csisz´ r. Information-type measures of difference of probability distrbutions and indirect observations. a Studia Sci. Math. Hungar., 2:299–318, 1967.</p>
<p>[14] N. Brenner, S. P. Strong, R. Koberle, W. Bialek, and R. R. de Ruyter van Steveninck. Synergy in a neural code. Neural Computation, 12:1531–1552, 2000. See also physics/9902067.</p>
<p>[15] F. E. Theunissen, K. Sen, and A. J. Doupe. Spectral-temporal receptive ﬁelds of nonlinear auditory neurons obtained using natural sounds. J. Neurosci., 20:2315–2331, 2000.</p>
<p>[16] F.E. Theunissen, S.V. David, N.C. Singh, A. Hsu, W.E. Vinje, and J.L. Gallant. Estimating spatio-temporal receptive ﬁelds of auditory and visual neurons from their responses to natural stimuli. Network, 3:289– 316, 2001.</p>
<p>[17] K. Sen, F. E. Theunissen, and A. J. Doupe. Feature analysis of natural sounds in the songbird auditory forebrain. J. Neurophysiol., 86:1445–1458, 2001.</p>
<p>[18] D. Smyth, B. Willmore, G. E. Baker, I. D. Thompson, and D. J. Tolhurst. The receptive ﬁelds organization of simple cells in the primary visual cortex of ferrets under natural scene stimulation. J. Neurosci., 23:4746–4759, 2003.</p>
<p>[19] G. Felsen, J. Touryan, F. Han, and Y. Dan. Cortical sensitivity to visual features in natural scenes. PLoS Biol., 3:1819–1828, 2005.</p>
<p>[20] D. L. Ringach, M. J. Hawken, and R. Shapley. Receptive ﬁeld structure of neurons in monkey visual cortex revealed by stimulation with natural image sequences. Journal of Vision, 2:12–24, 2002.</p>
<p>[21] N. C. Rust, O. Schwartz, J. A. Movshon, and E. P. Simoncelli. Spatiotemporal elements of macaque V1 receptive ﬁelds. Neuron, 46:945–956, 2005.</p>
<p>[22] Schwartz O., J.W. Pillow, N.C. Rust, and E. P. Simoncelli. Spike-triggered neural characterization. Journal of Vision, 176:484–507, 2006.</p>
<p>[23] N. Tishby, F. C. Pereira, and W. Bialek. The information bottleneck method. In B. Hajek and R. S. Sreenivas, editors, Proceedings of the 37th Allerton Conference on Communication, Control and Computing, pp 368–377. University of Illinois, 1999. See also physics/0004057.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
