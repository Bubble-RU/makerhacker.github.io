<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>47 nips-2007-Collapsed Variational Inference for HDP</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-47" href="../nips2007/nips-2007-Collapsed_Variational_Inference_for_HDP.html">nips2007-47</a> <a title="nips-2007-47-reference" href="#">nips2007-47-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>47 nips-2007-Collapsed Variational Inference for HDP</h1>
<br/><p>Source: <a title="nips-2007-47-pdf" href="http://papers.nips.cc/paper/3342-collapsed-variational-inference-for-hdp.pdf">pdf</a></p><p>Author: Yee W. Teh, Kenichi Kurihara, Max Welling</p><p>Abstract: A wide variety of Dirichlet-multinomial ‘topic’ models have found interesting applications in recent years. While Gibbs sampling remains an important method of inference in such models, variational techniques have certain advantages such as easy assessment of convergence, easy optimization without the need to maintain detailed balance, a bound on the marginal likelihood, and side-stepping of issues with topic-identiﬁability. The most accurate variational technique thus far, namely collapsed variational latent Dirichlet allocation, did not deal with model selection nor did it include inference for hyperparameters. We address both issues by generalizing the technique, obtaining the ﬁrst variational algorithm to deal with the hierarchical Dirichlet process and to deal with hyperparameters of Dirichlet variables. Experiments show a signiﬁcant improvement in accuracy. 1</p><br/>
<h2>reference text</h2><p>[1] R. G. Cowell, A. P. Dawid, S. L. Lauritzen, and D. J. Spiegelhalter. Probabilistic Networks and Expert Systems. Springer-Verlag, 1999.</p>
<p>[2] M. J. Beal and Z. Ghahramani. Variational Bayesian learning of directed graphical models with hidden variables. Bayesian Analysis, 1(4), 2006.</p>
<p>[3] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent Dirichlet allocation. Journal of Machine Learning Research, 3:993–1022, 2003.</p>
<p>[4] Y. W. Teh, M. I. Jordan, M. J. Beal, and D. M. Blei. Hierarchical Dirichlet processes. Journal of the American Statistical Association, 101(476):1566–1581, 2006.</p>
<p>[5] T. P. Minka and J. Lafferty. Expectation propagation for the generative aspect model. In Proceedings of the Conference on Uncertainty in Artiﬁcial Intelligence, volume 18, 2002.</p>
<p>[6] W. Buntine and A. Jakulin. Applying discrete PCA in data analysis. In Proceedings of the Conference on Uncertainty in Artiﬁcial Intelligence, volume 20, 2004.</p>
<p>[7] Y. W. Teh, D. Newman, and M. Welling. A collapsed variational Bayesian inference algorithm for latent Dirichlet allocation. In Advances in Neural Information Processing Systems, volume 19, 2007.</p>
<p>[8] D. M. Blei and M. I. Jordan. Variational inference for Dirichlet process mixtures. Bayesian Analysis, 1(1):121–144, 2006.</p>
<p>[9] K. Kurihara, M. Welling, and N. Vlassis. Accelerated variational DP mixture models. In Advances in Neural Information Processing Systems, volume 19, 2007.</p>
<p>[10] P. Liang, S. Petrov, M. I. Jordan, and D. Klein. The inﬁnite PCFG using hierarchical Dirichlet processes. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2007.</p>
<p>[11] J. Sethuraman. A constructive deﬁnition of Dirichlet priors. Statistica Sinica, 4:639–650, 1994.</p>
<p>[12] T.L. Grifﬁths and M. Steyvers. A probabilistic approach to semantic representation. In Proceedings of the 24th Annual Conference of the Cognitive Science Society, 2002.</p>
<p>[13] C. E. Antoniak. Mixtures of Dirichlet processes with applications to Bayesian nonparametric problems. Annals of Statistics, 2(6):1152–1174, 1974.</p>
<p>[14] M. J. Beal. Variational Algorithms for Approximate Bayesian Inference. PhD thesis, Gatsby Computational Neuroscience Unit, University College London, 2003.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
