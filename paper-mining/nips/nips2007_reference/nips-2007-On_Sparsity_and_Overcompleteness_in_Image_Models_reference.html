<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>145 nips-2007-On Sparsity and Overcompleteness in Image Models</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-145" href="../nips2007/nips-2007-On_Sparsity_and_Overcompleteness_in_Image_Models.html">nips2007-145</a> <a title="nips-2007-145-reference" href="#">nips2007-145-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>145 nips-2007-On Sparsity and Overcompleteness in Image Models</h1>
<br/><p>Source: <a title="nips-2007-145-pdf" href="http://papers.nips.cc/paper/3312-on-sparsity-and-overcompleteness-in-image-models.pdf">pdf</a></p><p>Author: Pietro Berkes, Richard Turner, Maneesh Sahani</p><p>Abstract: Computational models of visual cortex, and in particular those based on sparse coding, have enjoyed much recent attention. Despite this currency, the question of how sparse or how over-complete a sparse representation should be, has gone without principled answer. Here, we use Bayesian model-selection methods to address these questions for a sparse-coding model based on a Student-t prior. Having validated our methods on toy data, we ﬁnd that natural images are indeed best modelled by extremely sparse distributions; although for the Student-t prior, the associated optimal basis size is only modestly over-complete. 1</p><br/>
<h2>reference text</h2><p>[1] B.A. Olshausen and D.J. Field. Emergence of simple-cell receptive ﬁeld properties by learning a sparse code for natural images. Nature, 381(6583):607–609, 1996.</p>
<p>[2] B.A. Olshausen and D.J. Field. Sparse coding with an overcomplete basis set: A strategy employed by V1? Vision Research, 37:3311–3325, 1997.</p>
<p>[3] Y.W Teh, M. Welling, S. Osindero, and G.E. Hinton. Energy-based models for sparse overcomplete representations. Journal of Machine Learning Research, 4:1235–1260, 2003.</p>
<p>[4] A.J. Bell and T.J. Sejnowski. The ‘independent components’ of natural scenes are edge ﬁlters. Vision Research, 37(23):3327–3338, 1997.</p>
<p>[5] S. Osindero, M. Welling, and G.E. Hinton. Topographic product models applied to natural scene statistics. Neural Computation, 18:381–344, 2006.</p>
<p>[6] D.J.C. McKay. Bayesian interpolation. Neural Comput, 4(3):415–447, 1992.</p>
<p>[7] C.M. Bishop. Variational principal components. In ICANN 1999 Proceedings, pages 509–514, 1999.</p>
<p>[8] M.J. Beal. Variational Algorithms for Approximate Bayesian Inference. PhD thesis, Gatsby Computational Neuroscience Unit, University College London, 2003.</p>
<p>[9] R.M. Neal. Annealed importance sampling. Statistics and Computing, 11:125–139, 2001.</p>
<p>[10] J.H. van Hateren and A. van der Schaaf. Independent component ﬁlters of natural images compared with simple cells in primary visual cortex. Proc. R. Soc. Lond. B, 265:359–366, 1998.  8</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
