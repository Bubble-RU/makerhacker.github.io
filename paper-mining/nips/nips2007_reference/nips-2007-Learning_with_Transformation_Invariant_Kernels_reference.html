<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>118 nips-2007-Learning with Transformation Invariant Kernels</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-118" href="../nips2007/nips-2007-Learning_with_Transformation_Invariant_Kernels.html">nips2007-118</a> <a title="nips-2007-118-reference" href="#">nips2007-118-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>118 nips-2007-Learning with Transformation Invariant Kernels</h1>
<br/><p>Source: <a title="nips-2007-118-pdf" href="http://papers.nips.cc/paper/3215-learning-with-transformation-invariant-kernels.pdf">pdf</a></p><p>Author: Christian Walder, Olivier Chapelle</p><p>Abstract: This paper considers kernels invariant to translation, rotation and dilation. We show that no non-trivial positive deﬁnite (p.d.) kernels exist which are radial and dilation invariant, only conditionally positive deﬁnite (c.p.d.) ones. Accordingly, we discuss the c.p.d. case and provide some novel analysis, including an elementary derivation of a c.p.d. representer theorem. On the practical side, we give a support vector machine (s.v.m.) algorithm for arbitrary c.p.d. kernels. For the thinplate kernel this leads to a classiﬁer with only one parameter (the amount of regularisation), which we demonstrate to be as effective as an s.v.m. with the Gaussian kernel, even though the Gaussian involves a second parameter (the length scale). 1</p><br/>
<h2>reference text</h2><p>Boughorbel, S., Tarel, J.-P., & Boujemaa, N. (2005). Conditionally positive deﬁnite kernels for svm based image recognition. Proc. of IEEE ICME’05. Amsterdam. Chapelle, O. (2007). Training a support vector machine in the primal. Neural Computation, 19, 1155–1178. Chapelle, O., & Sch¨ lkopf, B. (2001). Incorporating invariances in nonlinear support vector machines. In o T. Dietterich, S. Becker and Z. Ghahramani (Eds.), Advances in neural information processing systems 14, 609–616. Cambridge, MA: MIT Press. Fleuret, F., & Sahbi, H. (2003). Scale-invariance of support vector machines based on the triangular kernel. Proc. of ICCV SCTV Workshop. Golub, G. H., & Van Loan, C. F. (1996). Matrix computations. Baltimore MD: The Johns Hopkins University Press. 2nd edition. Hsu, C.-W., Chang, C.-C., & Lin, C.-J. (2003). A practical guide to support vector classiﬁcation (Technical Report). National Taiwan University. Mika, S., R¨ tsch, G., Weston, J., Sch¨ lkopf, B., Smola, A., & M¨ ller, K.-R. (2003). Constructing descriptive a o u and discriminative non-linear features: Rayleigh coefﬁcients in feature spaces. IEEE PAMI, 25, 623–628. Sch¨ lkopf, B., & Smola, A. J. (2002). Learning with kernels: Support vector machines, regularization, optio mization, and beyond. Cambridge: MIT Press. Smola, A., Sch¨ lkopf, B., & M¨ ller, K.-R. (1998). The connection between regularization operators and support o u vector kernels. Neural Networks, 11, 637–649. Wahba, G. (1990). Spline models for observational data. Philadelphia: Series in Applied Math., Vol. 59, SIAM. Walder, C., & Chapelle, O. (2007). Learning with transformation invariant kernels (Technical Report 165). Max Planck Institute for Biological Cybernetics, Department of Empirical Inference, T¨ bingen, Germany. u Wendland, H. (2004). Scattered data approximation. Monographs on Applied and Computational Mathematics. Cambridge University Press.  8</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
