<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>17 nips-2007-A neural network implementing optimal state estimation based on dynamic spike train decoding</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-17" href="../nips2007/nips-2007-A_neural_network_implementing_optimal_state_estimation_based_on_dynamic_spike_train_decoding.html">nips2007-17</a> <a title="nips-2007-17-reference" href="#">nips2007-17-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>17 nips-2007-A neural network implementing optimal state estimation based on dynamic spike train decoding</h1>
<br/><p>Source: <a title="nips-2007-17-pdf" href="http://papers.nips.cc/paper/3299-a-neural-network-implementing-optimal-state-estimation-based-on-dynamic-spike-train-decoding.pdf">pdf</a></p><p>Author: Omer Bobrowski, Ron Meir, Shy Shoham, Yonina Eldar</p><p>Abstract: It is becoming increasingly evident that organisms acting in uncertain dynamical environments often employ exact or approximate Bayesian statistical calculations in order to continuously estimate the environmental state, integrate information from multiple sensory modalities, form predictions and choose actions. What is less clear is how these putative computations are implemented by cortical neural networks. An additional level of complexity is introduced because these networks observe the world through spike trains received from primary sensory afferents, rather than directly. A recent line of research has described mechanisms by which such computations can be implemented using a network of neurons whose activity directly represents a probability distribution across the possible “world states”. Much of this work, however, uses various approximations, which severely restrict the domain of applicability of these implementations. Here we make use of rigorous mathematical results from the theory of continuous time point process ﬁltering, and show how optimal real-time state estimation and prediction may be implemented in a general setting using linear neural networks. We demonstrate the applicability of the approach with several examples, and relate the required network properties to the statistical nature of the environment, thereby quantifying the compatibility of a given network with its environment. 1</p><br/>
<h2>reference text</h2><p>[1] J.M. Beck and A. Pouget. Exact inferences in a neural implementation of a hidden markov model. Neural Comput, 19(5):1344–1361, 2007.</p>
<p>[2] R. Ben-Yishai, R.L. Bar-Or, and H. Sompolinsky. Theory of orientation tuning in visual cortex. Proc Natl Acad Sci U S A, 92(9):3844–8, Apr 1995. 542.</p>
<p>[3] P. Br´ maud. Point Processes and Queues: Martingale Dynamics. Springer, New York, 1981. e</p>
<p>[4] U.T. Eden, L.M. Frank, V. Solo, and E.N. Brown. Dynamic analysis of neural encoding by point process adaptive ﬁltering. Neural Computation, 16:971–998, 2004.</p>
<p>[5] G.R. Grimmett and D.R. Stirzaker. Probability and Random Processes. Oxford University Press, third edition, 2001.</p>
<p>[6] A.H. Jazwinsky. Stochastic Processes and Filtering Theory. Academic Press, 1970.</p>
<p>[7] H.J. Kushner. Dynamical equations for optimal nonlinear ﬁltering. J. Differential Equations, 3:179–190, 1967.</p>
<p>[8] R.P.N. Rao. Bayesian computation in recurrent neural circuits. Neural Comput, 16(1):1–38, 2004. 825.</p>
<p>[9] R.P.N. Rao. Neural models of Bayesain belief propagation. In K. Doya, S. Ishii, A. Pouget, and R. P. N. Rao, editors, Bayesian Brain, chapter 11. MIT Press, 2006.</p>
<p>[10] A. Segall, M. Davis, and T. Kailath. Nonlinear ﬁltering with counting observations. IEEE Tran. Information Theory,, 21(2):143–149, 1975.</p>
<p>[11] S. Shoham, L.M. Paninski, M.R. Fellows, N.G. Hatsopoulos, J.P. Donoghue, and R.A. Norman. Statistical encoding model for a primary motor cortical brain-machine interface. IEEE Trans Biomed Eng., 52(7):1312–22, 2005.</p>
<p>[12] D. L. Snyder. Filtering and detection for doubly stochastic Poisson processes. IEEE Transactions on Information Theory, IT-18:91–102, 1972.</p>
<p>[13] N. Twum-Danso and R. Brockett. Trajectory estimation from place cell data. Neural Netw, 14(6-7):835–844, 2001.</p>
<p>[14] W.M. Wonham. Some applications of stochastic differential equations to optimal nonlinear ﬁltering. J. SIAM Control, 2(3):347–369, 1965.</p>
<p>[15] M. Zakai. On the optimal ﬁltering of diffusion processes. Z. Wahrscheinlichkeitheorie verw Gebiete, 11:230–243, 1969.  8</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
