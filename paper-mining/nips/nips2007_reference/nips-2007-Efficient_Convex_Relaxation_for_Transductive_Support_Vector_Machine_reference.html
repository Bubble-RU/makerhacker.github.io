<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>76 nips-2007-Efficient Convex Relaxation for Transductive Support Vector Machine</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-76" href="../nips2007/nips-2007-Efficient_Convex_Relaxation_for_Transductive_Support_Vector_Machine.html">nips2007-76</a> <a title="nips-2007-76-reference" href="#">nips2007-76-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>76 nips-2007-Efficient Convex Relaxation for Transductive Support Vector Machine</h1>
<br/><p>Source: <a title="nips-2007-76-pdf" href="http://papers.nips.cc/paper/3356-efficient-convex-relaxation-for-transductive-support-vector-machine.pdf">pdf</a></p><p>Author: Zenglin Xu, Rong Jin, Jianke Zhu, Irwin King, Michael Lyu</p><p>Abstract: We consider the problem of Support Vector Machine transduction, which involves a combinatorial problem with exponential computational complexity in the number of unlabeled examples. Although several studies are devoted to Transductive SVM, they suffer either from the high computation complexity or from the solutions of local optimum. To address this problem, we propose solving Transductive SVM via a convex relaxation, which converts the NP-hard problem to a semi-deﬁnite programming. Compared with the other SDP relaxation for Transductive SVM, the proposed algorithm is computationally more efﬁcient with the number of free parameters reduced from O(n2 ) to O(n) where n is the number of examples. Empirical study with several benchmark data sets shows the promising performance of the proposed algorithm in comparison with other state-of-the-art implementations of Transductive SVM. 1</p><br/>
<h2>reference text</h2><p>[1] T. D. Bie and N. Cristianini. Convex methods for transduction. In S. Thrun, L. Saul, and B. Sch¨ lkopf, editors, Advances in Neural Information Processing Systems 16. MIT Press, o Cambridge, MA, 2004.</p>
<p>[2] O. Chapelle, M. Chi, and A. Zien. A continuation method for semi-supervised SVMs. In ICML ’06: Proceedings of the 23rd international conference on Machine learning, pages 185–192, New York, NY, USA, 2006. ACM Press.</p>
<p>[3] O. Chapelle, B. Sch¨ lkopf, and A. Zien. Semi-Supervised Learning. MIT Press, Cambridge, o MA, 2006.</p>
<p>[4] O. Chapelle, V. Sindhwani, and S. Keerthi. Branch and bound for semi-supervised support vector machines. In B. Sch¨ lkopf, J. Platt, and T. Hoffman, editors, Advances in Neural Inforo mation Processing Systems 19. MIT Press, Cambridge, MA, 2007.</p>
<p>[5] O. Chapelle and A. Zien. Semi-supervised classiﬁcation by low density separation. In Proceedings of the Tenth International Workshop on Artiﬁcial Intelligence and Statistics, pages 57–64, 2005.</p>
<p>[6] R. Collobert, F. Sinz, J. Weston, and L. Bottou. Large scale transductive SVMs. Journal of Machine Learning Reseaerch, 7:1687–1712, 2006.</p>
<p>[7] J.-B. Hiriart-Urruty and C. Lemarechal. Convex analysis and minimization algorithms II: advanced theory and bundle methods. (2nd part edition). Springer-Verlag, New York, 1993.</p>
<p>[8] T. Joachims. Transductive inference for text classiﬁcation using support vector machines. In ICML ’99: Proceedings of the Sixteenth International Conference on Machine Learning, pages 200–209, San Francisco, CA, USA, 1999. Morgan Kaufmann Publishers Inc.</p>
<p>[9] G. R. G. Lanckriet, N. Cristianini, P. Bartlett, L. E. Ghaoui, and M. I. Jordan. Learning the kernel matrix with semideﬁnite programming. Journal of Machine Learning Research, 5:27– 72, 2004.</p>
<p>[10] Y. Nesterov and A. Nemirovsky. Interior point polynomial methods in convex programming: Theory and applications. Studies in Applied Mathematics. Philadelphia, 1994.</p>
<p>[11] V. Sindhwani, S. S. Keerthi, and O. Chapelle. Deterministic annealing for semi-supervised kernel machines. In ICML ’06: Proceedings of the 23rd international conference on Machine learning, pages 841–848, New York, NY, USA, 2006. ACM Press.</p>
<p>[12] J. F. Sturm. Using SeDuMi 1.02, a MATLAB toolbox for optimization over symmetric cones. Optimization Methods and Software, 11:625–653, 1999.</p>
<p>[13] H. Valizadegan and R. Jin. Generalized maximum margin clustering and unsupervised kernel learning. In B. Sch¨ lkopf, J. Platt, and T. Hoffman, editors, Advances in Neural Information o Processing Systems 19. MIT Press, Cambridge, MA, 2007.</p>
<p>[14] L. Xu and D. Schuurmans. Unsupervised and semi-supervised multi-class support vector machines. In AAAI, pages 904–910, 2005.</p>
<p>[15] X. Zhu. Semi-supervised learning literature survey. Technical report, Computer Sciences, University of Wisconsin-Madison, 2005.</p>
<p>[16] X. Zhu, Z. Ghahramani, and J. D. Lafferty. Semi-supervised learning using gaussian ﬁelds and harmonic functions. In Proceedings of Twentith International Conference on Machine Learning (ICML-2003), pages 912–919, 2003.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
