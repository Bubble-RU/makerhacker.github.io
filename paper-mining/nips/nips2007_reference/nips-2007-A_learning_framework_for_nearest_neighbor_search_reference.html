<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>16 nips-2007-A learning framework for nearest neighbor search</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-16" href="../nips2007/nips-2007-A_learning_framework_for_nearest_neighbor_search.html">nips2007-16</a> <a title="nips-2007-16-reference" href="#">nips2007-16-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>16 nips-2007-A learning framework for nearest neighbor search</h1>
<br/><p>Source: <a title="nips-2007-16-pdf" href="http://papers.nips.cc/paper/3357-a-learning-framework-for-nearest-neighbor-search.pdf">pdf</a></p><p>Author: Lawrence Cayton, Sanjoy Dasgupta</p><p>Abstract: Can we leverage learning techniques to build a fast nearest-neighbor (ANN) retrieval data structure? We present a general learning framework for the NN problem in which sample queries are used to learn the parameters of a data structure that minimize the retrieval time and/or the miss rate. We explore the potential of this novel framework through two popular NN data structures: KD-trees and the rectilinear structures employed by locality sensitive hashing. We derive a generalization theory for these data structure classes and present simple learning algorithms for both. Experimental results reveal that learning often improves on the already strong performance of these data structures. 1</p><br/>
<h2>reference text</h2><p>[1] J. H. Friedman, J. L. Bentley, and R. A. Finkel. An algorithm for ﬁnding best matches in logarithmic expected time. ACM Transactions on Mathematical Software, 3(3):209–226, 1977.</p>
<p>[2] S. Arya, D. M. Mount, N. S. Netanyahu, R. Silverman, and A. Wu. An optimal algorithm for approximate nearest neighbor searching. Journal of the ACM, 45(6):891–923, 1998.</p>
<p>[3] T. Liu, A. W. Moore, A. Gray, and K. Yang. An investigation of practical approximate neighbor algorithms. In Neural Information Processing Systems (NIPS), 2004.</p>
<p>[4] S. Dasgupta and Y. Freund. Random projection trees and low dimensional manifolds. Technical report, UCSD, 2007.</p>
<p>[5] P. Indyk. Nearest neighbors in high dimensional spaces. In J. E. Goodman and J. O’Rourke, editors, Handbook of Discrete and Computational Geometry. CRC Press, 2006.</p>
<p>[6] M. T. Orchard. A fast nearest-neighbor search algorithm. In ICASSP, pages 2297–3000, 1991.</p>
<p>[7] E. Vidal. An algorithm for ﬁnding nearest neighbours in (approximately) constant average time. Pattern Recognition Letters, 4:145–157, 1986.</p>
<p>[8] S. Omohundro. Five balltree construction algorithms. Technical report, ICSI, 1989.</p>
<p>[9] A. Beygelzimer, S. Kakade, and J. Langford. Cover trees for nearest neighbor. In ICML, 2006.</p>
<p>[10] K. L. Clarkson. Nearest-neighbor searching and metric space dimensions. In Nearest-Neighbor Methods for Learning and Vision: Theory and Practice, pages 15–59. MIT Press, 2006.</p>
<p>[11] S. Maneewongvatana and D. Mount. The analysis of a probabilistic approach to nearest neighbor searching. In Workshop on Algorithms and Data Structures, 2001.</p>
<p>[12] S. Maneewongvatana and D. Mount. Analysis of approximate nearest neighbor searching with clustered point sets. In Workshop on Algorithm Engineering and Experimentation (ALENEX), 1999.</p>
<p>[13] Mayur Datar, Nicole Immorlica, Piotr Indyk, and Vahab S. Mirrokni. Locality-sensitive hashing scheme based on p-stable distributions. In SCG 2004, pages 253–262, New York, NY, USA, 2004. ACM Press.</p>
<p>[14] O. Bousquet, S. Boucheron, and G. Lugosi. Theory of classiﬁcation: a survey of recent advances. ESAIM: Probability and Statistics, 9:323–375, 2004.</p>
<p>[15] D. Mount and S. Arya. ANN library. http://www.cs.umd.edu/∼mount/ANN/.</p>
<p>[16] N. Rasiwasia, P. Moreno, and N. Vasconcelos. Bridging the gap: query by semantic example. IEEE Transactions on Multimedia, 2007.  8</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
