<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>138 nips-2007-Near-Maximum Entropy Models for Binary Neural Representations of Natural Images</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-138" href="../nips2007/nips-2007-Near-Maximum_Entropy_Models_for_Binary_Neural_Representations_of_Natural_Images.html">nips2007-138</a> <a title="nips-2007-138-reference" href="#">nips2007-138-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>138 nips-2007-Near-Maximum Entropy Models for Binary Neural Representations of Natural Images</h1>
<br/><p>Source: <a title="nips-2007-138-pdf" href="http://papers.nips.cc/paper/3336-near-maximum-entropy-models-for-binary-neural-representations-of-natural-images.pdf">pdf</a></p><p>Author: Matthias Bethge, Philipp Berens</p><p>Abstract: Maximum entropy analysis of binary variables provides an elegant way for studying the role of pairwise correlations in neural populations. Unfortunately, these approaches suffer from their poor scalability to high dimensions. In sensory coding, however, high-dimensional data is ubiquitous. Here, we introduce a new approach using a near-maximum entropy model, that makes this type of analysis feasible for very high-dimensional data—the model parameters can be derived in closed form and sampling is easy. Therefore, our NearMaxEnt approach can serve as a tool for testing predictions from a pairwise maximum entropy model not only for low-dimensional marginals, but also for high dimensional measurements of more than thousand units. We demonstrate its usefulness by studying natural images with dichotomized pixel intensities. Our results indicate that the statistics of such higher-dimensional measurements exhibit additional structure that are not predicted by pairwise correlations, despite the fact that pairwise correlations explain the lower-dimensional marginal statistics surprisingly well up to the limit of dimensionality where estimation of the full joint distribution is feasible. 1</p><br/>
<h2>reference text</h2><p>[1] D.H. Ackley, G.E. Hinton, and T.J. Sejnowski. A learning algorithm for boltzmann machines. Cognitive Science, 9:147–169, 1985.</p>
<p>[2] H.B. Barlow. Sensory mechanisms, the reduction of redundancy, and intelligence. In The Mechanisation of Thought Processes, pages 535–539, London: Her Majesty’s Stationery Ofﬁce, 1959.</p>
<p>[3] M. Bethge. Factorial coding of natural images: How effective are linear model in removing higher-order dependencies? J. Opt. Soc. Am. A, 23(6):1253–1268, June 2006.</p>
<p>[4] D.R. Cox and N. Wermuth. On some models for multivariate binary variables parallel in complexity with the multivariate gaussian distribution. Biometrika, 89:462–469, 2002.</p>
<p>[5] L.J. Emrich and M.R. Piedmonte. A method for generating high-dimensional multivariate binary variates. The American Statistician, 45(4):302–304, 1991.</p>
<p>[6] M. Huber. A bounding chain for swendsen-wang. Random Structures & Algorithms, 22:53–59, 2002.</p>
<p>[7] E.T. Jaynes. Where do we stand on maximum entropy inference. In R.D. Levine and M. Tribus, editors, The Maximum Entropy Formalism. MIT Press, Cambridge, MA, 1978.</p>
<p>[8] J. Linn. Divergence measures based on the shannon entropy. IEEE Trans Inf Theory, 37:145–151, 1991.</p>
<p>[9] D. J. C. MacKay. Information Theory, Inference and Learning Algorithms. Cambridge University Press, 2003.</p>
<p>[10] Sheila H Nirenberg and Jonathan D Victor. Analyzing the activity of large populations of neurons: how tractable is the problem? Current Opinion in Neurobiology, 17:397–400, August 2007.</p>
<p>[11] Karl Pearson. On a new method of determining correlation between a measured character a, and a character b, of which only the percentage of cases wherein b exceeds (or falls short of) a given intensity is recorded for each grade of a. Biometrika, 7:96–105, 1909.</p>
<p>[12] Elad Schneidman, Michael J Berry, Ronen Segev, and William Bialek. Weak pairwise correlations imply strongly correlated network states in a neural population. Nature, 440(7087):1007–1012, Apr 2006.</p>
<p>[13] J Shlens, JD Field, JL Gauthier, MI Grivich, D Petrusca, A Sher, AM Litke, and EJ Chichilnisky. The structure of multi-neuron ﬁring patterns in primate retina. J Neurosci, 26(32):8254–8266, Aug 2006.</p>
<p>[14] G. Tkacik, E. Schneidman, M.J. Berry, and W. Bialek. Ising models for networks of real neurons. arXiv:qbio.NC/0611072, 1:1–4, 2006.  8</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
