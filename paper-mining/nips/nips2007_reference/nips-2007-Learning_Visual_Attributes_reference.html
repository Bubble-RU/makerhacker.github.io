<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>113 nips-2007-Learning Visual Attributes</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-113" href="../nips2007/nips-2007-Learning_Visual_Attributes.html">nips2007-113</a> <a title="nips-2007-113-reference" href="#">nips2007-113-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>113 nips-2007-Learning Visual Attributes</h1>
<br/><p>Source: <a title="nips-2007-113-pdf" href="http://papers.nips.cc/paper/3217-learning-visual-attributes.pdf">pdf</a></p><p>Author: Vittorio Ferrari, Andrew Zisserman</p><p>Abstract: We present a probabilistic generative model of visual attributes, together with an efﬁcient learning algorithm. Attributes are visual qualities of objects, such as ‘red’, ‘striped’, or ‘spotted’. The model sees attributes as patterns of image segments, repeatedly sharing some characteristic properties. These can be any combination of appearance, shape, or the layout of segments within the pattern. Moreover, attributes with general appearance are taken into account, such as the pattern of alternation of any two colors which is characteristic for stripes. To enable learning from unsegmented training images, the model is learnt discriminatively, by optimizing a likelihood ratio. As demonstrated in the experimental evaluation, our model can learn in a weakly supervised setting and encompasses a broad range of attributes. We show that attributes can be learnt starting from a text query to Google image search, and can then be used to recognize the attribute and determine its spatial extent in novel real-world images.</p><br/>
<h2>reference text</h2><p>[1] N. Dalal and B. Triggs, Histograms of Oriented Gradients for Human Detection, CVPR, 2005.</p>
<p>[2] P. Felzenszwalb and D Huttenlocher, Efﬁcient Graph-Based Image Segmentation, IJCV, (50):2, 2004.</p>
<p>[3] R. Fergus, P. Perona, and A. Zisserman, Object Class Recognition by Unsupervised Scale-Invariant Learning, CVPR, 2003.</p>
<p>[4] N. Jojic and Y. Caspi, Capturing image structure with probabilistic index maps, CVPR, 2004</p>
<p>[5] S. Lazebnik, C. Schmid, and J. Ponce, A Sparse Texture Representation Using Local Afﬁne Regions, PAMI, (27):8, 2005</p>
<p>[6] Y. Liu, Y. Tsin, and W. Lin, The Promise and Perils of Near-Regular Texture, IJCV, (62):1, 2005</p>
<p>[7] J. Van de Weijer, C. Schmid, and J. Verbeek, Learning Color Names from Real-World Images, CVPR, 2007.</p>
<p>[8] M. Varma and A. Zisserman, Texture classiﬁcation: Are ﬁlter banks necessary?, CVPR, 2003.</p>
<p>[9] J. Winn, A. Criminisi, and T. Minka, Object Categorization by Learned Universal Visual Dictionary, ICCV, 2005.</p>
<p>[10] J. Winn and N. Jojic. LOCUS: Learning Object Classes with Unsupervised Segmentation, ICCV, 2005.</p>
<p>[11] K. Yanai and K. Barnard, Image Region Entropy: A Measure of ”Visualness” of Web Images Associated with One Concept, ACM Multimedia, 2005.</p>
<p>[12] Caltech 101 dataset: www.vision.caltech.edu/Image Datasets/Caltech101/Caltech101.html</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
