<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>116 nips-2007-Learning the structure of manifolds using random projections</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-116" href="../nips2007/nips-2007-Learning_the_structure_of_manifolds_using_random_projections.html">nips2007-116</a> <a title="nips-2007-116-reference" href="#">nips2007-116-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>116 nips-2007-Learning the structure of manifolds using random projections</h1>
<br/><p>Source: <a title="nips-2007-116-pdf" href="http://papers.nips.cc/paper/3195-learning-the-structure-of-manifolds-using-random-projections.pdf">pdf</a></p><p>Author: Yoav Freund, Sanjoy Dasgupta, Mayank Kabra, Nakul Verma</p><p>Abstract: We present a simple variant of the k-d tree which automatically adapts to intrinsic low dimensional structure in data. 1</p><br/>
<h2>reference text</h2><p>[1] M. Belkin and P. Niyogi. Laplacian eigenmaps for dimensionality reduction and data representation. Neural Computation, 15(6):1373–1396, 2003.</p>
<p>[2] M. Belkin, P. Niyogi, and V. Sindhwani. On manifold regularization. Conference on AI and Statistics, 2005.</p>
<p>[3] J. Bentley. Multidimensional binary search trees used for associative searching. Communications of the ACM, 18(9):509–517, 1975.</p>
<p>[4] W. Boothby. An Introduction to Differentiable Manifolds and Riemannian Geometry. Academic Press, 2003.</p>
<p>[5] T. M. Cover and P. E. Hart. Nearest neighbor pattern classiﬁcations. IEEE Transactions on Information Theory, 13(1):21–27, 1967.</p>
<p>[6] M. Datar, N. Immorlica, P. Indyk, and V. Mirrokni. Locality sensitive hashing scheme based on p-stable distributions. Symposium on Computational Geometry, 2004.</p>
<p>[7] L. Devroye, L. Gyorﬁ, and G. Lugosi. A Probabilistic Theory of Pattern Recognition. Springer, 1996.</p>
<p>[8] T. Liu, A. Moore, A. Gray, and K. Yang. An investigation of practical approximate nearest neighbor algorithms. Advances in Neural Information Processing Systems, 2004.</p>
<p>[9] J. McNames. A fast nearest neighbor algorithm based on a principal axis search tree. IEEE Transactions on Pattern Analysis and Machine Intelligence, 23(9):964–976, 2001.</p>
<p>[10] M. Raginsky and S. Lazebnik. Estimation of intrinsic dimensionality using high-rate vector quantization. Advances in Neural Information Processing Systems, 18, 2006.</p>
<p>[11] S. Roweis and L. Saul. Nonlinear dimensionality reduction by locally linear embedding. Science, 290:2323–2326, 2000.</p>
<p>[12] J. Tenenbaum, V. de Silva, and J. Langford. A global geometric framework for nonlinear dimensionality reduction. Science, 290(5500):2319–2323, 2000.  8</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
