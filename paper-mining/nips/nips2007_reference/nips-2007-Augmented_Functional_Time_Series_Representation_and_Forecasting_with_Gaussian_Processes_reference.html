<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>28 nips-2007-Augmented Functional Time Series Representation and Forecasting with Gaussian Processes</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-28" href="../nips2007/nips-2007-Augmented_Functional_Time_Series_Representation_and_Forecasting_with_Gaussian_Processes.html">nips2007-28</a> <a title="nips-2007-28-reference" href="#">nips2007-28-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>28 nips-2007-Augmented Functional Time Series Representation and Forecasting with Gaussian Processes</h1>
<br/><p>Source: <a title="nips-2007-28-pdf" href="http://papers.nips.cc/paper/3324-augmented-functional-time-series-representation-and-forecasting-with-gaussian-processes.pdf">pdf</a></p><p>Author: Nicolas Chapados, Yoshua Bengio</p><p>Abstract: We introduce a functional representation of time series which allows forecasts to be performed over an unspeciﬁed horizon with progressively-revealed information sets. By virtue of using Gaussian processes, a complete covariance matrix between forecasts at several time-steps is available. This information is put to use in an application to actively trade price spreads between commodity futures contracts. The approach delivers impressive out-of-sample risk-adjusted returns after transaction costs on a portfolio of 30 spreads. 1</p><br/>
<h2>reference text</h2><p>[1] C. Bishop. Neural Networks for Pattern Recognition. Oxford University Press, 1995.</p>
<p>[2] N. Chapados and Y. Bengio. Cost functions and model combination for VaR-based asset allocation using neural networks. IEEE Transactions on Neural Networks, 12(4):890–906, July 2001.</p>
<p>[3] F. X. Diebold and R. S. Mariano. Comparing predictive accuracy. Journal of Business & Economic Statistics, 13(3):253–263, July 1995.</p>
<p>[4] A. Girard, C. E. Rasmussen, J. Q. Candela, and R. Murray-Smith. Gaussian process priors with uncertain inputs – application to multiple-step ahead time series forecasting. In S. T. S. Becker and K. Obermayer, editors, Advances in Neural Information Processing Systems 15, pages 529–536. MIT Press, 2003.</p>
<p>[5] R. C. Grinold and R. N. Kahn. Active Portfolio Management. McGraw Hill, 1999.</p>
<p>[6] J. D. Hamilton. Time Series Analysis. Princeton University Press, 1994.</p>
<p>[7] J. C. Hull. Options, Futures and Other Derivatives. Prentice Hall, Englewood Cliffs, NJ, sixth edition, 2005.</p>
<p>[8] A. O’Hagan. Curve ﬁtting and optimal design for prediction. Journal of the Royal Statistical Society B, 40:1–42, 1978. (With discussion).</p>
<p>[9] J. Quionero-Candela and C. E. Rasmussen. A unifying view of sparse approximate gaussian process regression. Journal of Machine Learning Research, 6:1939–1959, 2005.</p>
<p>[10] J. O. Ramsay and B. W. Silverman. Functional Data Analysis. Springer, second edition, 2005.</p>
<p>[11] C. E. Rasmussen and C. K. I. Williams. Gaussian Processes for Machine Learning. MIT Press, 2006.</p>
<p>[12] V. Tresp. A bayesian committee machine. Neural Computation, 12:2719–2741, 2000.</p>
<p>[13] U.S. Department of Agriculture. Economic research service data sets. WWW publication. Available at http://www.ers.usda.gov/Data/.</p>
<p>[14] C. K. I. Williams and C. E. Rasmussen. Gaussian processes for regression. In D. S. Touretzky, M. C. Mozer, and M. E. Hasselmo, editors, Advances in Neural Information Processing Systems 8, pages 514– 520. MIT Press, 1996.  8</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
