<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>93 nips-2007-GRIFT: A graphical model for inferring visual classification features from human data</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-93" href="../nips2007/nips-2007-GRIFT%3A_A_graphical_model_for_inferring_visual_classification_features_from_human_data.html">nips2007-93</a> <a title="nips-2007-93-reference" href="#">nips2007-93-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>93 nips-2007-GRIFT: A graphical model for inferring visual classification features from human data</h1>
<br/><p>Source: <a title="nips-2007-93-pdf" href="http://papers.nips.cc/paper/3289-grift-a-graphical-model-for-inferring-visual-classification-features-from-human-data.pdf">pdf</a></p><p>Author: Michael Ross, Andrew Cohen</p><p>Abstract: This paper describes a new model for human visual classiﬁcation that enables the recovery of image features that explain human subjects’ performance on different visual classiﬁcation tasks. Unlike previous methods, this algorithm does not model their performance with a single linear classiﬁer operating on raw image pixels. Instead, it represents classiﬁcation as the combination of multiple feature detectors. This approach extracts more information about human visual classiﬁcation than previous methods and provides a foundation for further exploration. 1</p><br/>
<h2>reference text</h2><p>[1] A.J. Ahumada, Jr. Classiﬁcation image weights and internal noise level estimation. Journal of Vision, 2(1), 2002.</p>
<p>[2] C.M. Bishop. Neural Networks for Pattern Recognition. Oxford University Press, 1995.</p>
<p>[3] C.M. Bishop. Pattern Recognition and Machine Learning. Springer, 2006.</p>
<p>[4] A.L. Cohen, R.M. Shiffrin, J.M. Gold, D.A. Ross, and M.G. Ross. Inducing features from visual noise. Journal of Vision, 7(8), 2007.</p>
<p>[5] A. Gelman, J.B. Carlin, H.S. Stern, and D.B. Rubin. Bayesian Data Analysis. Chapman & Hall/CRC, 2003.</p>
<p>[6] J.M. Gold, P.J. Bennett, and A.B. Sekuler. Identiﬁcation of band-pass ﬁltered letters and faces by human and ideal observers. Vision Research, 39, 1999.</p>
<p>[7] J.M. Gold, A.L. Cohen, and R. Shiffrin. Visual noise reveals category representations. Psychonomics Bulletin & Review, 15(4), 2006.</p>
<p>[8] N.A. Macmillan and C.D. Creelman. Detection Theory: A User’s Guide. Lawrence Erlbaum Associates, 2005.</p>
<p>[9] S.E. Palmer. Vision Science: Photons to Phenomenology. The MIT Press, 1999.</p>
<p>[10] D.G. Pelli, B. Farell, and D.C. Moore. The remarkable inefﬁciency of word recognition. Nature, 425, 2003.</p>
<p>[11] J. Sergent. An investigation into component and conﬁgural processes underlying face perception. British Journal of Psychology, 75, 1984.  8</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
