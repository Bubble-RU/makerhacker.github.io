<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>165 nips-2007-Regret Minimization in Games with Incomplete Information</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-165" href="../nips2007/nips-2007-Regret_Minimization_in_Games_with_Incomplete_Information.html">nips2007-165</a> <a title="nips-2007-165-reference" href="#">nips2007-165-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>165 nips-2007-Regret Minimization in Games with Incomplete Information</h1>
<br/><p>Source: <a title="nips-2007-165-pdf" href="http://papers.nips.cc/paper/3306-regret-minimization-in-games-with-incomplete-information.pdf">pdf</a></p><p>Author: Martin Zinkevich, Michael Johanson, Michael Bowling, Carmelo Piccione</p><p>Abstract: Extensive games are a powerful model of multiagent decision-making scenarios with incomplete information. Finding a Nash equilibrium for very large instances of these games has received a great deal of recent attention. In this paper, we describe a new technique for solving large games based on regret minimization. In particular, we introduce the notion of counterfactual regret, which exploits the degree of incomplete information in an extensive game. We show how minimizing counterfactual regret minimizes overall regret, and therefore in self-play can be used to compute a Nash equilibrium. We demonstrate this technique in the domain of poker, showing we can solve abstractions of limit Texas Hold’em with as many as 1012 states, two orders of magnitude larger than previous methods. 1</p><br/>
<h2>reference text</h2><p>[1] D. Koller and N. Megiddo. The complexity of two-person zero-sum games in extensive form. Games and Economic Behavior, pages 528–552, 1992.</p>
<p>[2] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, and D. Szafron. Approximating game-theoretic optimal strategies for full-scale poker. In International Joint Conference on Artiﬁcial Intelligence, pages 661–668, 2003.</p>
<p>[3] A. Gilpin and T. Sandholm. Finding equilibria in large sequential games of imperfect information. In ACM Conference on Electronic Commerce, 2006.</p>
<p>[4] A. Gilpin and T. Sandholm. A competitive texas hold’em poker player via automated abstraction and real-time equilibrium computation. In National Conference on Artiﬁcial Intelligence, 2006.</p>
<p>[5] G. Gordon. No-regret algorithms for online convex programs. In Neural Information Processing Systems 19, 2007.</p>
<p>[6] M. Zinkevich, M. Bowling, and N. Burch. A new algorithm for generating strong strategies in massive zero-sum games. In Proceedings of the Twenty-Seventh Conference on Artiﬁcial Intelligence (AAAI), 2007. To Appear.</p>
<p>[7] A. Gilpin, S. Hoda, J. Pena, and T. Sandholm. Gradient-based algorithms for ﬁnding nash equilibria in extensive form games. In Proceedings of the Eighteenth International Conference on Game Theory, 2007.</p>
<p>[8] M. Osborne and A. Rubenstein. A Course in Game Theory. The MIT Press, Cambridge, Massachusetts, 1994.</p>
<p>[9] M. Zinkevich and M. Littman. The AAAI computer poker competition. Journal of the International Computer Games Association, 29, 2006. News item.  8</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
