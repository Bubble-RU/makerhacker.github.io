<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>27 nips-2007-Anytime Induction of Cost-sensitive Trees</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-27" href="../nips2007/nips-2007-Anytime_Induction_of_Cost-sensitive_Trees.html">nips2007-27</a> <a title="nips-2007-27-reference" href="#">nips2007-27-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>27 nips-2007-Anytime Induction of Cost-sensitive Trees</h1>
<br/><p>Source: <a title="nips-2007-27-pdf" href="http://papers.nips.cc/paper/3192-anytime-induction-of-cost-sensitive-trees.pdf">pdf</a></p><p>Author: Saher Esmeir, Shaul Markovitch</p><p>Abstract: Machine learning techniques are increasingly being used to produce a wide-range of classiﬁers for complex real-world applications that involve nonuniform testing costs and misclassiﬁcation costs. As the complexity of these applications grows, the management of resources during the learning and classiﬁcation processes becomes a challenging task. In this work we introduce ACT (Anytime Cost-sensitive Trees), a novel framework for operating in such environments. ACT is an anytime algorithm that allows trading computation time for lower classiﬁcation costs. It builds a tree top-down and exploits additional time resources to obtain better estimations for the utility of the different candidate splits. Using sampling techniques ACT approximates for each candidate split the cost of the subtree under it and favors the one with a minimal cost. Due to its stochastic nature ACT is expected to be able to escape local minima, into which greedy methods may be trapped. Experiments with a variety of datasets were conducted to compare the performance of ACT to that of the state of the art cost-sensitive tree learners. The results show that for most domains ACT produces trees of signiﬁcantly lower costs. ACT is also shown to exhibit good anytime behavior with diminishing returns.</p><br/>
<h2>reference text</h2><p>[1] N. Abe, B. Zadrozny, and J. Langford. An iterative method for multi-class cost-sensitive learning. In KDD, 2004.</p>
<p>[2] V. Bayer-Zubek and Dietterich. Integrating learning from examples into the search for diagnostic policies. Artiﬁcial Intelligence, 24:263–303, 2005.</p>
<p>[3] C. L. Blake and C. J. Merz. UCI repository of machine learning databases, 1998.</p>
<p>[4] A. Blumer, A. Ehrenfeucht, D. Haussler, and M. K. Warmuth. Occam’s Razor. Information Processing Letters, 24(6):377–380, 1987.</p>
<p>[5] M. Boddy and T. L. Dean. Deliberation scheduling for problem solving in time constrained environments. Artiﬁcial Intelligence, 67(2):245–285, 1994.</p>
<p>[6] J. Bradford, C. Kunz, R. Kohavi, C. Brunk, and C. Brodley. Pruning decision trees with misclassiﬁcation costs. In ECML, 1998.</p>
<p>[7] L. Breiman, J. Friedman, R. Olshen, and C. Stone. Classiﬁcation and Regression Trees. Wadsworth and Brooks, Monterey, CA, 1984.</p>
<p>[8] J. Demsar. Statistical comparisons of classiﬁers over multiple data sets. Journal of Machine Learning Research, 7:1–30, 2006.</p>
<p>[9] P. Domingos. Metacost: A general method for making classiﬁers cost-sensitive. In KDD, 1999.</p>
<p>[10] C. Elkan. The foundations of cost-sensitive learning. In IJCAI, 2001.</p>
<p>[11] S. Esmeir and S. Markovitch. Anytime learning of decision trees. Journal of Machine Learning Research, 8, 2007.</p>
<p>[12] R. Greiner, A. J. Grove, and D. Roth. Learning cost-sensitive active classiﬁers. Artiﬁcial Intelligence, 139(2):137–174, 2002.</p>
<p>[13] T. Hastie, R. Tibshirani, and J. Friedman. The Elements of Statistical Learning: Data Mining, Inference, and Prediction. New York: Springer-Verlag, 2001.</p>
<p>[14] D. Margineantu. Active cost-sensitive learning. In IJCAI, 2005.</p>
<p>[15] P. Melville, M. Saar-Tsechansky, F. Provost, and R. J. Mooney. Active feature acquisition for classiﬁer induction. In ICDM, 2004.</p>
<p>[16] S. W. Norton. Generating better decision trees. In IJCAI, 1989.</p>
<p>[17] M. Nunez. The use of background knowledge in decision tree induction. Machine Learning, 6:231–250, 1991.</p>
<p>[18] F. Provost and B. Buchanan. Inductive policy: The pragmatics of bias selection. Machine Learning, 20(1-2):35–61, 1995.</p>
<p>[19] Z. Qin, S. Zhang, and C. Zhang. Cost-sensitive decision trees with multiple cost scales. Lecture Notes in Computer Science, AI, Volume 3339/2004:380–390, 2004.</p>
<p>[20] J. R. Quinlan. C4.5: Programs for Machine Learning. Morgan Kaufmann, 1993.</p>
<p>[21] S. Sheng, C. X. Ling, A. Ni, and S. Zhang. Cost-sensitive test strategies. In AAAI, 2006.</p>
<p>[22] M. Tan and J. C. Schlimmer. Cost-sensitive concept learning of sensor use in approach and recognition. In Proceedings of the 6th international workshop on Machine Learning, 1989.</p>
<p>[23] P. Turney. Types of cost in inductive concept learning. In Workshop on Cost-Sensitive Learning at ICML, 2000.</p>
<p>[24] P. D. Turney. Cost-sensitive classiﬁcation: Empirical evaluation of a hybrid genetic decision tree induction algorithm. Journal of Artiﬁcial Intelligence Research, 2:369–409, 1995.  8</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
