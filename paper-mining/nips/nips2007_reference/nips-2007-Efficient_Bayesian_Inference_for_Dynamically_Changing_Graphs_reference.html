<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>75 nips-2007-Efficient Bayesian Inference for Dynamically Changing Graphs</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-75" href="../nips2007/nips-2007-Efficient_Bayesian_Inference_for_Dynamically_Changing_Graphs.html">nips2007-75</a> <a title="nips-2007-75-reference" href="#">nips2007-75-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>75 nips-2007-Efficient Bayesian Inference for Dynamically Changing Graphs</h1>
<br/><p>Source: <a title="nips-2007-75-pdf" href="http://papers.nips.cc/paper/3255-efficient-bayesian-inference-for-dynamically-changing-graphs.pdf">pdf</a></p><p>Author: Ozgur Sumer, Umut Acar, Alexander T. Ihler, Ramgopal R. Mettu</p><p>Abstract: Motivated by stochastic systems in which observed evidence and conditional dependencies between states of the network change over time, and certain quantities of interest (marginal distributions, likelihood estimates etc.) must be updated, we study the problem of adaptive inference in tree-structured Bayesian networks. We describe an algorithm for adaptive inference that handles a broad range of changes to the network and is able to maintain marginal distributions, MAP estimates, and data likelihoods in all expected logarithmic time. We give an implementation of our algorithm and provide experiments that show that the algorithm can yield up to two orders of magnitude speedups on answering queries and responding to dynamic changes over the sum-product algorithm. 1</p><br/>
<h2>reference text</h2><p>[1] Umut A. Acar, Guy E. Blelloch, Matthias Blume, and Kanat Tangwongsan. An experimental analysis of self-adjusting computation. In Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), 2006.</p>
<p>[2] Umut A. Acar, Guy E. Blelloch, Robert Harper, Jorge L. Vittes, and Maverick Woo. Dynamizing static algorithms with applications to dynamic trees and history independence. In ACM-SIAM Symposium on Discrete Algorithms (SODA), 2004.</p>
<p>[3] Umut A. Acar, Guy E. Blelloch, and Jorge L. Vittes. An experimental analysis of change propagation in dynamic trees. In Workshop on Algorithm Engineering and Experimentation (ALENEX), 2005.</p>
<p>[4] H. M. Berman, J. Westbrook, Z. Feng, G. Gilliland, T. N. Bhat, H. Weissig, I. N. Shindyalov, and P. E. Bourne. The protein data bank. Nucl. Acids Res., 28:235–242, 2000.</p>
<p>[5] P. Clifford. Markov random ﬁelds in statistics. In G. R. Grimmett and D. J. A. Welsh, editors, Disorder in Physical Systems, pages 19–32. Oxford University Press, Oxford, 1990.</p>
<p>[6] A. L. Delcher, A. J. Grove, S. Kasif, and J. Pearl. Logarithmic-time updates and queries in probabilistic networks. Journal of Artiﬁcial Intelligence Research, 4:37–59, 1995.</p>
<p>[7] R. L. Dunbrack Jr. Rotamer libraries in the 21st century. Curr Opin Struct Biol, 12(4):431–440, 2002.</p>
<p>[8] M. I. Jordan. Graphical models. Statistical Science, 19:140–155, 2004.</p>
<p>[9] H. Kamisetty, E. P Xing, and C. J. Langmead. Free energy estimates of all-atom protein structures using generalized belief propagation. In Proceedings of the 11th Annual International Conference on Research in Computational Molecular Biology, 2007. To appear.</p>
<p>[10] F. Kschischang, B. Frey, and H.-A. Loeliger. Factor graphs and the sum-product algorithm. IEEE Transactions on Information Theory, 47:498–519, 2001.</p>
<p>[11] R. McEliece and S. M. Aji. The generalized distributive law. IEEE Transactions on Information Theory, 46(2):325–343, March 2000.</p>
<p>[12] Marina Meil˘ and Michael I. Jordan. Learning with mixtures of trees. Journal of Machine Learning a Research, 1(1):1–48, October 2000.</p>
<p>[13] Gary L. Miller and John H. Reif. Parallel tree contraction and its application. In Proceedings of the 26th Annual IEEE Symposium on Foundations of Computer Science, pages 487–489, 1985.</p>
<p>[14] J. Pearl. Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. Morgan Kaufmann, San Francisco, 1988.</p>
<p>[15] M. J. Wainwright, T. Jaakkola, and A. S. Willsky. Tree consistency and bounds on the performance of the max-product algorithm and its generalizations. Statistics and Computing, 14:143–166, April 2004.</p>
<p>[16] S. J. Weiner, P.A. Kollman, D.A. Case, U.C. Singh, G. Alagona, S. Profeta Jr., and P. Weiner. A new force ﬁeld for the molecular mechanical simulation of nucleic acids and proteins. J. Am. Chem. Soc., 106:765–784, 1984.</p>
<p>[17] C. Yanover and Y. Weiss. Approximate inference and protein folding. In Proceedings of Neural Information Processing Systems Conference, pages 84–86, 2002.  8</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
