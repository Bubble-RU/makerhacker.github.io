<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>149 nips-2007-Optimal ROC Curve for a Combination of Classifiers</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2007" href="../home/nips2007_home.html">nips2007</a> <a title="nips-2007-149" href="../nips2007/nips-2007-Optimal_ROC_Curve_for_a_Combination_of_Classifiers.html">nips2007-149</a> <a title="nips-2007-149-reference" href="#">nips2007-149-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>149 nips-2007-Optimal ROC Curve for a Combination of Classifiers</h1>
<br/><p>Source: <a title="nips-2007-149-pdf" href="http://papers.nips.cc/paper/3263-optimal-roc-curve-for-a-combination-of-classifiers.pdf">pdf</a></p><p>Author: Marco Barreno, Alvaro Cardenas, J. D. Tygar</p><p>Abstract: We present a new analysis for the combination of binary classiﬁers. Our analysis makes use of the Neyman-Pearson lemma as a theoretical basis to analyze combinations of classiﬁers. We give a method for ﬁnding the optimal decision rule for a combination of classiﬁers and prove that it has the optimal ROC curve. We show how our method generalizes and improves previous work on combining classiﬁers and generating ROC curves. 1</p><br/>
<h2>reference text</h2><p>[1] Foster Provost and Tom Fawcett. Robust classiﬁcation for imprecise environments. Machine Learning Journal, 42(3):203–231, March 2001.</p>
<p>[2] Peter A. Flach and Shaomin Wu. Repairing concavities in ROC curves. In Proceedings of the 19th International Joint Conference on Artiﬁcial Intelligence (IJCAI’05), pages 702–707, August 2005.</p>
<p>[3] Tom Fawcett. ROC graphs: Notes and practical considerations for data mining researchers. Technical Report HPL-2003-4, HP Laboratories, Palo Alto, CA, January 2003. Updated March 2004.</p>
<p>[4] J. Neyman and E. S. Pearson. On the problem of the most efﬁcient tests of statistical hypotheses. Philosophical Transactions of the Royal Society of London, Series A, Containing Papers of a Mathematical or Physical Character, 231:289–337, 1933.</p>
<p>[5] Vincent H. Poor. An Introduction to Signal Detection and Estimation. Springer-Verlag, second edition, 1988.</p>
<p>[6] D. J. Newman, S. Hettich, C. L. Blake, and C. J. Merz. UCI repository of machine learning databases, 1998. http://www.ics.uci.edu/∼mlearn/MLRepository.html.</p>
<p>[7] I. Mierswa, M. Wurst, R. Klinkenberg, M. Scholz, and T. Euler. YALE: Rapid prototyping for complex data mining tasks. In Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD), 2006.</p>
<p>[8] L. Breiman. Bagging predictors. Machine Learning, 24(2):123–140, 1996.</p>
<p>[9] Y. Freund and R. E. Schapire. Experiments with a new boosting algorithm. In Thirteenth International Conference on Machine Learning, pages 148–156, Bari, Italy, 1996. Morgan Kaufmann.</p>
<p>[10] Thomas G. Dietterich. Ensemble methods in machine learning. Lecture Notes in Computer Science, 1857:1–15, 2000.</p>
<p>[11] Robert E. Schapire, Yoav Freund, Peter Bartlett, and Wee Sun Lee. Boosting the margin: A new explanation for the effectiveness of voting methods. The Annals of Statistics, 26(5):1651–1686, October 1998.</p>
<p>[12] Yoav Freund, Raj Iyer, Robert E. Schapire, and Yoram Singer. An efﬁcient boosting algorithm for combining preferences. Journal of Machine Learning Research (JMLR), 4:933–969, 2003.</p>
<p>[13] D. H. Wolpert. Stacked generalization. Neural Networks, 5:241–259, 1992. ˘</p>
<p>[14] Saso D˘ eroski and Bernard Zenko. Is combining classiﬁers with stacking better than selecting the best z one? Machine Learning, 54:255–273, 2004.  8</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
