<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>188 nips-2001-The Unified Propagation and Scaling Algorithm</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2001" href="../home/nips2001_home.html">nips2001</a> <a title="nips-2001-188" href="../nips2001/nips-2001-The_Unified_Propagation_and_Scaling_Algorithm.html">nips2001-188</a> <a title="nips-2001-188-reference" href="#">nips2001-188-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>188 nips-2001-The Unified Propagation and Scaling Algorithm</h1>
<br/><p>Source: <a title="nips-2001-188-pdf" href="http://papers.nips.cc/paper/2001-the-unified-propagation-and-scaling-algorithm.pdf">pdf</a></p><p>Author: Yee W. Teh, Max Welling</p><p>Abstract: In this paper we will show that a restricted class of constrained minimum divergence problems, named generalized inference problems, can be solved by approximating the KL divergence with a Bethe free energy. The algorithm we derive is closely related to both loopy belief propagation and iterative scaling. This uniﬁed propagation and scaling algorithm reduces to a convergent alternative to loopy belief propagation when no constraints are present. Experiments show the viability of our algorithm.</p><br/>
<h2>reference text</h2><p>[1] J. Pearl. Probabilistic reasoning in intelligent systems : networks of plausible inference. Morgan Kaufmann Publishers, San Mateo CA, 1988.  (a) Ordinary Inference  (c) σ(α) = 0.2  (b) No Obs Constraints  (d) σ(α) = 2.0 0.4  loopy IS  9 7 5 3 1 0.2 9  UPS  7 5 3 1 1  3  5  7  9  1  3  5  7  9  1  3  5  7  9  1  3  Figure 2: Each plot shows the mean absolute errors for various settings of  5  7  0  9  (x-axis) and (yaxis). The top plots show errors for loopy IS and bottom plots show errors for UPS. The inset shows the cases (black) when loopy IS did not converge within 2000 iterations, with linear damping slowly . increasing to  '     ¡ ¢   £ ¤£  D F</p>
<p>[2] J.S. Yedidia, W. Freeman, and Y. Weiss. Generalized belief propagation. In Advances in Neural Information Processing Systems, volume 13, 2000.</p>
<p>[3] W. E. Deming and F. F. Stephan. On a least square adjustment of a sampled frequency table when the expected marginal totals are known. Annals of Mathematical Statistics, 11:427–444, 1940.</p>
<p>[4] J. Darroch and D. Ratcliff. Generalized iterative scaling for log-linear models. Annals of Mathematical Statistics, 43:1470–1480, 1972.</p>
<p>[5] K. Murphy, Y. Weiss, and M. Jordan. Loopy belief propagation for approximate inference : An empirical study. In Proceedings of the Conference on Uncertainty in Artiﬁcial Intelligence, volume 15. Morgan Kaufmann Publishers, 1999.</p>
<p>[6] M. Welling and Y. W. Teh. Belief optimization for binary networks : A stable alternative to loopy belief propagation. In Uncertainty in Artiﬁcial Intelligence, 2001.</p>
<p>[7] A. L. Yuille. CCCP algorithms to minimize the Bethe and Kikuchi free energies: Convergent alternatives to belief propagation. 2002.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
