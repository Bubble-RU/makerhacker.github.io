<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>37 nips-2001-Associative memory in realistic neuronal networks</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2001" href="../home/nips2001_home.html">nips2001</a> <a title="nips-2001-37" href="../nips2001/nips-2001-Associative_memory_in_realistic_neuronal_networks.html">nips2001-37</a> <a title="nips-2001-37-reference" href="#">nips2001-37-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>37 nips-2001-Associative memory in realistic neuronal networks</h1>
<br/><p>Source: <a title="nips-2001-37-pdf" href="http://papers.nips.cc/paper/2056-associative-memory-in-realistic-neuronal-networks.pdf">pdf</a></p><p>Author: Peter E. Latham</p><p>Abstract: Almost two decades ago , Hopfield [1] showed that networks of highly reduced model neurons can exhibit multiple attracting fixed points, thus providing a substrate for associative memory. It is still not clear, however, whether realistic neuronal networks can support multiple attractors. The main difficulty is that neuronal networks in vivo exhibit a stable background state at low firing rate, typically a few Hz. Embedding attractor is easy; doing so without destabilizing the background is not. Previous work [2, 3] focused on the sparse coding limit, in which a vanishingly small number of neurons are involved in any memory. Here we investigate the case in which the number of neurons involved in a memory scales with the number of neurons in the network. In contrast to the sparse coding limit, we find that multiple attractors can co-exist robustly with a stable background state. Mean field theory is used to understand how the behavior of the network scales with its parameters, and simulations with analog neurons are presented. One of the most important features of the nervous system is its ability to perform associative memory. It is generally believed that associative memory is implemented using attractor networks - experimental studies point in that direction [4- 7], and there are virtually no competing theoretical models. Perhaps surprisingly, however, it is still an open theoretical question whether attractors can exist in realistic neuronal networks. The</p><br/>
<h2>reference text</h2><p>[1] J.J. Hopfield. Neural networks and physical systems with emergent collective computational abilities. Proc. Natl. Acad. Sci ., 79:2554- 2558, 1982.</p>
<p>[2] N. BruneI. Persistent activity and the single-cell frequency-current curve in a cortical network model. Network: Computation in Neural Systems, 11:261- 280, 2000.</p>
<p>[3] P.E. Latham and S.N. Nirenberg. Intrinsic dynamics in cultured neuronal networks. Soc . Neuroscience Abstract, 25:2259, 1999.</p>
<p>[4] J.M. Fuster and G.E. Alexander. Science, 173:652- 654, 1971.  Neuron activity related to short-term memory.</p>
<p>[5] Y. Miyashita. Inferior temporal cortex: where visual perception meets memory. Annu R ev Neurosci, 16:245- 263 , 1993.</p>
<p>[6] P.S. Goldman-Rakic. Cellular basis of working memory. Neuron, 14:477- 485 , 1995.</p>
<p>[7] R Romo, C.D. Brody, A. Hernandez , and L. Lemus. Neuronal correlates of parametric working memory in the prefrontal cortex. Nature , 399:470- 473, 1999.</p>
<p>[8] C.D. Gilbert. Laminar differences in receptive field properties of cells in cat primary visual cortex. J. Physiol. , 268:391- 421 , 1977.</p>
<p>[9] Y. Lamour, P. Dutar, and A. Jobert. Cerebral neorcortical neurons in the aged rat: spontaneous activity, properties of pyramidal tract neurons and effect of acetylcholine and cholinergic drugs. N euroscience, 16:835- 844, 1985.</p>
<p>[10] M.B. Szente, A. Baranyi, and C.D. Woody. Intracellular injection of apamin reduces a slow potassium current mediating afterhyperpolarizations and IPSPs in neocortical neurons of cats. Brain Res. , 461:64- 74, 1988.</p>
<p>[11] I. Salimi, H.H. Webster, and RW. Dykes. Neuronal activity in normal and deafferented forelimb somatosensory cortex of the awake cat . Brain Res., 656:263- 273, 1994.</p>
<p>[12] J.F. Herrero and P.M. Headley. Cutaneous responsiveness of lumbar spinal neurons in awake and halothane-anesthetized sheep. J. N europhysiol. , 74:1549- 1562, 1997.</p>
<p>[13] K. Ochi and J.J. Eggermont. Effects of quinine on neural activity in cat primary auditory cortex. Hear. Res., 105:105- 18, 1997.</p>
<p>[14] P.E. Latham, B.J. Richmond, P.G. Nelson, and S.N. Nirenberg. Intrinsic dynamics in neuronal networks. I. Theory. J. Neurophysiol., 83:808- 827, 2000.</p>
<p>[15] M.V. Tsodyks and M.V. Feigel'man. The enhanced storage capacity in neural networks with low activity level. Europhys. Lett. , 6:101- 105, 1988.</p>
<p>[16] A. Treves. Mean-field analysis of neuronal spike dynamics. Network, 4:259- 284, 1993.</p>
<p>[17] O. Shriki, D. Hansel , and H. Sompolonski. Modeling neuronal networks in cortex by rate models using the current-frequency response properties of cortical cells. Soc . Neurosci ence Abstract, 24:143 , 1998.</p>
<p>[18] C. van Vreeswijk and H. Sompolinsky. Chaos in neuronal networks with balanced excitatory and inhibitory activity. Science, 274: 1724- 1726, 1996.</p>
<p>[19] C. van Vreeswijk and H. Sompolinsky. Chaotic balanced state in a model of cortical circuits. Neural Comput., 10:1321- 1371 , 1998.</p>
<p>[20] H. Sompolinsky. Neural networks with nonlinear synapses and a static noise. Phys. Rev. A, 34:2571- 2574, 1986.</p>
<p>[21] J. Hertz , A. Krogh, and RG. Palmer. Introduction to the th eory of neural computation. Addison Wesley, Redwood City, CA, 1991.</p>
<p>[22] A.N. Burkitt. Retrieval properties of attractor neural that obey Dale's law using a self-consistent signal-to-noise analysis. Network: Computation in Neural Systems, 7:517- 531 , 1996.</p>
<p>[23] D.J. Amit and N. BruneI. Dynamics of a recurrent network of spiking neurons before and following learning. Network, 8:373- 404, 1997.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
