<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>83 nips-2001-Geometrical Singularities in the Neuromanifold of Multilayer Perceptrons</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2001" href="../home/nips2001_home.html">nips2001</a> <a title="nips-2001-83" href="../nips2001/nips-2001-Geometrical_Singularities_in_the_Neuromanifold_of_Multilayer_Perceptrons.html">nips2001-83</a> <a title="nips-2001-83-reference" href="#">nips2001-83-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>83 nips-2001-Geometrical Singularities in the Neuromanifold of Multilayer Perceptrons</h1>
<br/><p>Source: <a title="nips-2001-83-pdf" href="http://papers.nips.cc/paper/2015-geometrical-singularities-in-the-neuromanifold-of-multilayer-perceptrons.pdf">pdf</a></p><p>Author: Shun-ichi Amari, Hyeyoung Park, Tomoko Ozeki</p><p>Abstract: Singularities are ubiquitous in the parameter space of hierarchical models such as multilayer perceptrons. At singularities, the Fisher information matrix degenerates, and the Cramer-Rao paradigm does no more hold, implying that the classical model selection theory such as AIC and MDL cannot be applied. It is important to study the relation between the generalization error and the training error at singularities. The present paper demonstrates a method of analyzing these errors both for the maximum likelihood estimator and the Bayesian predictive distribution in terms of Gaussian random fields, by using simple models. 1</p><br/>
<h2>reference text</h2><br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
