<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>14 nips-2001-A Neural Oscillator Model of Auditory Selective Attention</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2001" href="../home/nips2001_home.html">nips2001</a> <a title="nips-2001-14" href="../nips2001/nips-2001-A_Neural_Oscillator_Model_of_Auditory_Selective_Attention.html">nips2001-14</a> <a title="nips-2001-14-reference" href="#">nips2001-14-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>14 nips-2001-A Neural Oscillator Model of Auditory Selective Attention</h1>
<br/><p>Source: <a title="nips-2001-14-pdf" href="http://papers.nips.cc/paper/2110-a-neural-oscillator-model-of-auditory-selective-attention.pdf">pdf</a></p><p>Author: Stuart N. Wrigley, Guy J. Brown</p><p>Abstract: A model of auditory grouping is described in which auditory attention plays a key role. The model is based upon an oscillatory correlation framework, in which neural oscillators representing a single perceptual stream are synchronised, and are desynchronised from oscillators representing other streams. The model suggests a mechanism by which attention can be directed to the high or low tones in a repeating sequence of tones with alternating frequencies. In addition, it simulates the perceptual segregation of a mistuned harmonic from a complex tone. 1</p><br/>
<h2>reference text</h2><p>[1] Anstis, S. & Saida, S. (1985) Adaptation to auditory streaming of frequency-modulated tones. J. Exp. Psychol. Human 11 257-271.</p>
<p>[2] Bregman, A. S. (1990) Auditory Scene Analysis. Cambridge MA: MIT Press.</p>
<p>[3] Brown, G. J. & Cooke, M. (1994) Computational auditory scene analysis. Comput. Speech Lang. 8, pp. 297-336.</p>
<p>[4] Carlyon, R. P., Cusack, R., Foxton, J. M. & Robertson, I. H. (2001) Effects of attention and unilateral neglect on auditory stream segregation. J. Exp. Psychol. Human 27(1) 115-127.</p>
<p>[5] Darwin, C. J., Hukin, R. W. & Al-Khatib, B. Y. (1995) Grouping in pitch perception: Evidence for sequential constraints. J. Acoust. Soc. Am. 98(2)Pt1 880-885.</p>
<p>[6] Joliot, M., Ribary, U. & Llin√°s, R. (1994) Human oscillatory brain activity near 40 Hz coexists with cognitive temporal binding. Proc. Natl. Acad. Sci. USA 91 11748-51.</p>
<p>[7] Mondor, T. A. & Bregman, A. S. (1994) Allocating attention to frequency regions. Percept. Psychophys. 56(3) 268-276.</p>
<p>[8] Moore, B. C. J. (1997) An introduction to the psychology of hearing. Academic Press.</p>
<p>[9] Spence, C. J., Driver, J. (1994) Covert spatial orienting in audition: exogenous and endogenous mechanisms. J. Exp. Psychol. Human 20(3) 555-574.</p>
<p>[10] Wang, D. L. (1996) Primitive auditory segregation based on oscillatory correlation. Cognitive Sci. 20 409-456.</p>
<p>[11] Wang, D. L. & Brown, G. J. (1999) Separation of speech from interfering sounds based on oscillatory correlation. IEEE Trans. Neural Networks 10 684-697.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
