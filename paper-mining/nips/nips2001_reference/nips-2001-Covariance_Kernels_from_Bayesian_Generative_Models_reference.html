<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>58 nips-2001-Covariance Kernels from Bayesian Generative Models</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2001" href="../home/nips2001_home.html">nips2001</a> <a title="nips-2001-58" href="../nips2001/nips-2001-Covariance_Kernels_from_Bayesian_Generative_Models.html">nips2001-58</a> <a title="nips-2001-58-reference" href="#">nips2001-58-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>58 nips-2001-Covariance Kernels from Bayesian Generative Models</h1>
<br/><p>Source: <a title="nips-2001-58-pdf" href="http://papers.nips.cc/paper/2133-covariance-kernels-from-bayesian-generative-models.pdf">pdf</a></p><p>Author: Matthias Seeger</p><p>Abstract: We propose the framework of mutual information kernels for learning covariance kernels, as used in Support Vector machines and Gaussian process classifiers, from unlabeled task data using Bayesian techniques. We describe an implementation of this framework which uses variational Bayesian mixtures of factor analyzers in order to attack classification problems in high-dimensional spaces where labeled data is sparse, but unlabeled data is abundant. 1</p><br/>
<h2>reference text</h2><p>[1] Avrim Blum and Tom Mitchell. Combining labeled and unlabeled data with CoTraining. In Proceedings of COLT, 1998.</p>
<p>[2] Z. Ghahramani and M. Beal. Variational inference for Bayesian mixtures of factor analysers. In Advances in NIPS 12. MIT Press, 1999.</p>
<p>[3] David Haussler. Convolution kernels on discrete structures. Technical Report UCSCCRL-99-10 , University of California, Santa Cruz, July 1999.</p>
<p>[4] Tommi S. Jaakkola and David Haussler. Exploiting generative models in discriminative classifiers. In Advances in N eural Information Processing Systems 11, 1998.</p>
<p>[5] Matthias Seeger. Covariance kernels from Bayesian generative models. Technical report , 2000. Available at http : //yyy . dai . ed. ac . ukr seeger /papers . html.</p>
<p>[6] Matthias Seeger. Learning with labeled and unlabeled data. Technical report, 2000. Available at http://yyy .dai. ed. ac. ukrseeger/papers .html.</p>
<p>[7] Martin Szummer and Tommi Jaakkola. Partially labeled classification with Markov random walks. In Advances in NIPS  14. MIT Press, 200l.</p>
<p>[8] Koji Tsuda, Motoaki Kawanabe, Gunnar Ratsch, Soeren Sonnenburg, and KlausRobert Muller. A new discriminative kernel from probabilistic models . In Advances in NIPS 14. MIT Press, 200l.</p>
<p>[9] Chris Watkins. Dynamic alignment kernels. Technical Report CSD-TR-98-11 , Royal Holloway, University of London, 1999.</p>
<p>[10] Christopher K.1. Williams and David Barber. Bayesian classification with Gaussian processes. IEEE Trans. PAMI, 20(12):1342- 1351, 1998.</p>
<p>[11] Peter Yianilos. Metric learning via normal mixtures. Technical report , NEC Research , Princeton, 1995.  17The a parameter in this work is related to MTS in this case.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
