<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>64 nips-2001-EM-DD: An Improved Multiple-Instance Learning Technique</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2001" href="../home/nips2001_home.html">nips2001</a> <a title="nips-2001-64" href="../nips2001/nips-2001-EM-DD%3A_An_Improved_Multiple-Instance_Learning_Technique.html">nips2001-64</a> <a title="nips-2001-64-reference" href="#">nips2001-64-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>64 nips-2001-EM-DD: An Improved Multiple-Instance Learning Technique</h1>
<br/><p>Source: <a title="nips-2001-64-pdf" href="http://papers.nips.cc/paper/1959-em-dd-an-improved-multiple-instance-learning-technique.pdf">pdf</a></p><p>Author: Qi Zhang, Sally A. Goldman</p><p>Abstract: We present a new multiple-inst ance (MI) learning technique (EMDD) that combines EM with the diverse density (DD) algorithm. EM-DD is a general-purpose MI algorithm that can be applied with boolean or real-value labels and makes real-value predictions. On the boolean Musk benchmarks, the EM-DD algorithm without any tuning significantly outperforms all previous algorithms. EM-DD is relatively insensitive to the number of relevant attributes in the data set and scales up well to large bag sizes. Furthermore, EMDD provides a new framework for MI learning, in which the MI problem is converted to a single-instance setting by using EM to estimate the instance responsible for the label of the bag. 1</p><br/>
<h2>reference text</h2><p>[1] Amar, R.A., Dooly, D.R., Goldman, S.A. & Zhang, Q. (2001). Multiple-Instance Learning of Real-Valued Data. Pr'oceedings 18th International Confer'ence on Machine Learning, pp. 3- 10. San Francisco, CA: Morgan Kaufmann.</p>
<p>[2] Auer, P. (1997) On learning from mult-instance examples: Empirical evaluation of a theoretical approach. Proceedings 14th International Conference on Ma chine Learning,  160.166.1a-S (DD)  80.166.1a-S (DD)  0. 8  0. 8  0. 6  0. 6  0.4  0.4  , . - ~-: :- T.;-~ ---  . ~.  0.2  .....  '  </p>
<p>[3] Dempster, A.P., Laird, N .M. , & Rubin, D.B. (1977). Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistics Society, Series B, 39 (1): 1-38.</p>
<p>[4] Dietterich, T. G., Lathrop , R. H., & Lozano-Perez, T. (1997). Solving the multipleinstance problem with axis-parallel rectangles. Artificial Intelligence, 89(1-2): 31-7l.</p>
<p>[5] Maron, O. (1998). Lea rning from Ambiguity. Doctoral dissertation, MIT, AI Technical Report 1639.</p>
<p>[6] Maron, O. & Lozano-Perez, T. (1998). A framework for multiple-instance learning. Neural Information Processing Systems 10. Cambridge, MA: MIT Press.</p>
<p>[7] Maron, O. & Ratan, A. (1998). Multiple-instance learning for natural scene classification. Proceedings 15th International Conference on Machine Learning, pp. 341-349. San Francisco, CA: Morgan Kaufmann.</p>
<p>[8] Press, W.H., Teukolsky, S.A., Vetterling, W .T., and F lannery, B.P. (1992). Numerical Recipes in C: the art of scientific computing . Cambridge University Press, New York, second edition.</p>
<p>[9] Ramon, J. & L. De Raedt. (2000). Multi instance neural networks. Proceedings of I CML -2000 workshop on </p>
<p>[10] Ray, S. & Page , D. (2001) . Multiple-Instance Regression. Proceedings 18th International Conference on Machine Learning, pp. 425-432. San Francisco, CA: Morgan Kaufmann.</p>
<p>[11] RufIo, G . (2000) . Learning single and multiple instance dec is io n tr'ees for' co mputer' security appli ca tions. Doctoral dissertation. Department of Computer Science, Uni versity of Turin, Torino, Italy.</p>
<p>[12] Wang, J. & Zucker, J.-D. (2000). Solving the Multiple-Instance Learning Problem: A Lazy Learning Approach. Proceedings 17th International Conference on Ma chin e Learning, pp. 1119-11 25 . San Francisco, CA: Morgan Kaufmann.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
