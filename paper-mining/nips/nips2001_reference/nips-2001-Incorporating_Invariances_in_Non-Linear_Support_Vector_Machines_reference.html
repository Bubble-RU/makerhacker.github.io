<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>92 nips-2001-Incorporating Invariances in Non-Linear Support Vector Machines</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2001" href="../home/nips2001_home.html">nips2001</a> <a title="nips-2001-92" href="../nips2001/nips-2001-Incorporating_Invariances_in_Non-Linear_Support_Vector_Machines.html">nips2001-92</a> <a title="nips-2001-92-reference" href="#">nips2001-92-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>92 nips-2001-Incorporating Invariances in Non-Linear Support Vector Machines</h1>
<br/><p>Source: <a title="nips-2001-92-pdf" href="http://papers.nips.cc/paper/2024-incorporating-invariances-in-non-linear-support-vector-machines.pdf">pdf</a></p><p>Author: Olivier Chapelle, Bernhard Schćž&scaron;lkopf</p><p>Abstract: The choice of an SVM kernel corresponds to the choice of a representation of the data in a feature space and, to improve performance , it should therefore incorporate prior knowledge such as known transformation invariances. We propose a technique which extends earlier work and aims at incorporating invariances in nonlinear kernels. We show on a digit recognition task that the proposed approach is superior to the Virtual Support Vector method, which previously had been the method of choice. 1</p><br/>
<h2>reference text</h2><p>[1] C. J. C. Burges. Geometry and invariance in kernel based methods. In B. Sch6lkopf, C. J . C. Burges, and A. J . Smola, editors, Advances in Kernel Methods - Support Vector Learning. MIT Press, 1999.</p>
<p>[2] O. Chapelle and B. Sch6lkopf. Incorporating invariances in nonlinear Support Vector Machines, 2001. Availabe at: www-connex.lip6.frrchapelle.</p>
<p>[3] O. Chapelle, V. Vapnik, O. Bousquet, and S. Mukherjee. Choosing multiple parameters for support vector machines. Machine Learning, 46:131- 159, 2002.</p>
<p>[4] C. Cortes and V. Vapnik. Support vector networks. Machine Learning, 20:273 297,1995.</p>
<p>[5] D. DeCoste and B. Sch6lkopf. Training invariant support vector machines. Machine Learning, 2001. In press.</p>
<p>[6] Todd K. Leen. From data distributions to regularization in invariant learning. In Nips, volume 7. The MIT Press, 1995.</p>
<p>[7] P. Niyogi, T. Poggio, and F. Girosi. Incorporating prior information in machine learning by creating virtual examples. IEEE Proceedings on Intelligent Signal Processing, 86(11):2196-2209, November 1998.</p>
<p>[8] John Platt. Probabilities for support vector machines. In A. Smola, P. Bartlett, B. Sch6lkopf, and D. Schuurmans, editors, Advances in Large Margin Classifiers. MIT Press, Cambridge, MA, 2000.</p>
<p>[9] B. Sch6lkopf, C. Burges, and V. Vapnik. Extracting support data for a given task. In U. M. Fayyad and R. Uthurusamy, editors, First International Conference on Knowledge Discovery fj Data Mining. AAAI Press, 1995.</p>
<p>[10] B. Sch6lkopf, C. Burges, and V. Vapnik. Incorporating invariances in support vector learning machines. In Artificial Neural Networks - ICANN'96, volume 1112, pages 47- 52, Berlin, 1996. Springer Lecture Notes in Computer Science.</p>
<p>[11] B. Sch6lkopf, P. Y. Simard, A. J. Smola, and V. N. Vapnik. Prior knowledge in support vector kernels. In MIT Press, editor, NIPS, volume 10, 1998.</p>
<p>[12] B. Sch6lkopf, A. Smola, and K.-R. Muller. Nonlinear component analysis as a kernel eigenvalue problem. Neural Computation, 10:1299- 1310, 1998.</p>
<p>[13] P. Simard, Y. LeCun, J. Denker, and B. Victorri. Transformation invariance in pattern recognition, tangent distance and tangent propagation. In G. Orr and K. Muller, editors, Neural Networks: Tricks of the trade. Springer, 1998.</p>
<p>[14] K. Tsuda. Support vector classifier with asymmetric kernel function. In M. Verleysen, editor, Proceedings of ESANN'99, pages 183- 188,1999.</p>
<p>[15] V. Vapnik. Statistical Learning Theory. John Wiley & Sons, 1998.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
