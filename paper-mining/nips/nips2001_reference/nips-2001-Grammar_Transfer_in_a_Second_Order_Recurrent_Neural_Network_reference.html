<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>85 nips-2001-Grammar Transfer in a Second Order Recurrent Neural Network</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2001" href="../home/nips2001_home.html">nips2001</a> <a title="nips-2001-85" href="../nips2001/nips-2001-Grammar_Transfer_in_a_Second_Order_Recurrent_Neural_Network.html">nips2001-85</a> <a title="nips-2001-85-reference" href="#">nips2001-85-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>85 nips-2001-Grammar Transfer in a Second Order Recurrent Neural Network</h1>
<br/><p>Source: <a title="nips-2001-85-pdf" href="http://papers.nips.cc/paper/1971-grammar-transfer-in-a-second-order-recurrent-neural-network.pdf">pdf</a></p><p>Author: Michiro Negishi, Stephen J. Hanson</p><p>Abstract: It has been known that people, after being exposed to sentences generated by an artificial grammar, acquire implicit grammatical knowledge and are able to transfer the knowledge to inputs that are generated by a modified grammar. We show that a second order recurrent neural network is able to transfer grammatical knowledge from one language (generated by a Finite State Machine) to another language which differ both in vocabularies and syntax. Representation of the grammatical knowledge in the network is analyzed using linear discriminant analysis. 1</p><br/>
<h2>reference text</h2><p>[1] Brooks, L. R. , and Vokey, J . R. (1991) Abstract analogies and abstracted grammars: Comments on Reber (1989) and Mathews et al. (1090). Journal of Experimental Psychology: Gen eral, 120, 316-323.</p>
<p>[2] Dienes, Z. , Altmann, and G. , Gao , S-J. (1999) Mapping across domains without feedback: A neural network model of transfer of implicit knowledge, Cognitive Science 23, 53-82.</p>
<p>[3] Elman, J. L. (1991) Distributed representation , simple recurrent neural networks, and grammatical structure. Machine Learning, 7, 195-225.</p>
<p>[4] Giles, C. L. , Miller, C. B. , Chen, D. , Chen, H. H. , Sun, G. Z. , and Lee, Y. C. (1992) Learning and Extracting Finite State Automata with Second-Order Recurrent Neural Networks, it Neural Computation, 4 , 393-495.</p>
<p>[5] Hanson, S. J., Negishi, M., (2001) The emergence of explicit knowledge (symbols & rules) in (associationist) neural networks, Submitted.</p>
<p>[6] Reber, A. (1969) Transfer of syntactic structure in synthetic languages. Journal of Experimental Psychology, 81 , 115-119.</p>
<p>[7] Williams, R . J. and Zipser, D. (1989) A learning algorithm for continually running fully recurrent neural networks, Neural Computation, 1 (2) , 270.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
