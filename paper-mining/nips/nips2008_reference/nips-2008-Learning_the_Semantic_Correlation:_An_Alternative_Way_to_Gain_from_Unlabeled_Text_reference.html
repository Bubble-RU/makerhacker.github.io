<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>120 nips-2008-Learning the Semantic Correlation: An Alternative Way to Gain from Unlabeled Text</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-120" href="../nips2008/nips-2008-Learning_the_Semantic_Correlation%3A_An_Alternative_Way_to_Gain_from_Unlabeled_Text.html">nips2008-120</a> <a title="nips-2008-120-reference" href="#">nips2008-120-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>120 nips-2008-Learning the Semantic Correlation: An Alternative Way to Gain from Unlabeled Text</h1>
<br/><p>Source: <a title="nips-2008-120-pdf" href="http://papers.nips.cc/paper/3490-learning-the-semantic-correlation-an-alternative-way-to-gain-from-unlabeled-text.pdf">pdf</a></p><p>Author: Yi Zhang, Artur Dubrawski, Jeff G. Schneider</p><p>Abstract: In this paper, we address the question of what kind of knowledge is generally transferable from unlabeled text. We suggest and analyze the semantic correlation of words as a generally transferable structure of the language and propose a new method to learn this structure using an appropriately chosen latent variable model. This semantic correlation contains structural information of the language space and can be used to control the joint shrinkage of model parameters for any speciﬁc task in the same space through regularization. In an empirical study, we construct 190 different text classiﬁcation tasks from a real-world benchmark, and the unlabeled documents are a mixture from all these tasks. We test the ability of various algorithms to use the mixed unlabeled text to enhance all classiﬁcation tasks. Empirical results show that the proposed approach is a reliable and scalable method for semi-supervised learning, regardless of the source of unlabeled data, the speciﬁc task to be enhanced, and the prediction model used.</p><br/>
<h2>reference text</h2><p>[1] R. K. Ando and T. Zhang. A framework for learning predictive structures from multiple tasks and unlabeled data. JMLR, 6:1817–1853, 2005.</p>
<p>[2] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. JMLR, 3:993–1022, 2003.</p>
<p>[3] A. Blum and S. Chawla. Learning from labeled and unlabeled data using graph mincuts. In ICML, pages 19–26, 2001.</p>
<p>[4] O. Chapelle, B. Scholkopf, and A. Zien. Semi-supervised Learning. The MIT Press, 2006.</p>
<p>[5] B. Efron. Bootstrap methods: Another look at the jackknife. The Annals of Statistics, 7, 1979.</p>
<p>[6] T. Hastie, R. Tibshirani, and J. Friedman. The Elements of Statistical Learning: Data Mining, Inference and Prediction. Springer, New York, 2001.</p>
<p>[7] T. Hofmann. Probabilistic latent semantic analysis. In UAI, 1999.</p>
<p>[8] T. Joachims. Transductive inference for text classiﬁcation using support vector machines. In ICML, pages 200–209, 1999.</p>
<p>[9] E. Krupka and N. Tishby. Incorporating Prior Knowledge on Features into Learning. In AISTATS, pages 227–234, 2007.</p>
<p>[10] K. Nigam, A. K. McCallum, S. Thrun, and T. Mitchell. Text classiﬁcation from labeled and unlabeled documents using em. Machine Learning, 39:103–134, 2000.</p>
<p>[11] R. Raina, A. Battle, H. Lee, and B. P. A. Y. Ng. Self-taught learning: Transfer learning from unlabeled data. In ICML, pages 759–766, 2007.</p>
<p>[12] R. Raina, A. Y. Ng, and D. Koller. Constructing informative priors using transfer learning. In ICML, pages 713–720, 2006.</p>
<p>[13] V. Sindhwani and S. Keerthi. Large scale semi-supervised linear svms. In SIGIR, 2006.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
