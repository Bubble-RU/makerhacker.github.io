<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>188 nips-2008-QUIC-SVD: Fast SVD Using Cosine Trees</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-188" href="../nips2008/nips-2008-QUIC-SVD%3A_Fast_SVD_Using_Cosine_Trees.html">nips2008-188</a> <a title="nips-2008-188-reference" href="#">nips2008-188-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>188 nips-2008-QUIC-SVD: Fast SVD Using Cosine Trees</h1>
<br/><p>Source: <a title="nips-2008-188-pdf" href="http://papers.nips.cc/paper/3473-quic-svd-fast-svd-using-cosine-trees.pdf">pdf</a></p><p>Author: Michael P. Holmes, Jr. Isbell, Charles Lee, Alexander G. Gray</p><p>Abstract: The Singular Value Decomposition is a key operation in many machine learning methods. Its computational cost, however, makes it unscalable and impractical for applications involving large datasets or real-time responsiveness, which are becoming increasingly common. We present a new method, QUIC-SVD, for fast approximation of the whole-matrix SVD based on a new sampling mechanism called the cosine tree. Our empirical tests show speedups of several orders of magnitude over exact SVD. Such scalability should enable QUIC-SVD to accelerate and enable a wide array of SVD-based methods and applications. 1</p><br/>
<h2>reference text</h2><p>[1] S. Friedland, A. Niknejad, M. Kaveh, and H. Zare. Fast Monte-Carlo Low Rank Approximations for Matrices. In Proceedings of Int. Conf. on System of Systems Engineering, 2006.</p>
<p>[2] A. Deshpande and S. Vempala. Adaptive Sampling and Fast Low-Rank Matrix Approximation. In 10th International Workshop on Randomization and Computation (RANDOM06), 2006.</p>
<p>[3] A. M. Frieze, R. Kannan, and S. Vempala. Fast Monte-Carlo Algorithms for Finding Low-Rank Approximations. In IEEE Symposium on Foundations of Computer Science, pages 370–378, 1998.</p>
<p>[4] P. Drineas, R. Kannan, and M. W. Mahoney. Fast Monte Carlo Algorithms for Matrices II: Computing a Low-Rank Approximation to a Matrix. SIAM Journal on Computing, 36(1):158–183, 2006.</p>
<p>[5] P. Drineas, E. Drinea, and P. S. Huggins. An Experimental Evaluation of a Monte-Carlo Algorithm for Singular Value Decomposition. Lectures Notes in Computer Science, 2563:279–296, 2003.</p>
<p>[6] T. Sarlos. Improved Approximation Algorithms for Large Matrices via Random Projections. In 47th IEEE Symposium on Foundations of Computer Science (FOCS), pages 143–152, 2006.</p>
<p>[7] D. Achlioptas, F. McSherry, and B. Scholkopf. Sampling Techniques for Kernel Methods. In Advances in Neural Information Processing Systems (NIPS) 17, 2002.</p>
<p>[8] M. P. Holmes, A. G. Gray, and C. L.Isbell, Jr. Ultrafast Monte Carlo for Kernel Estimators and Generalized Statistical Summations. In Advances in Neural Information Processing Systems (NIPS) 21, 2008.</p>
<p>[9] J. Audibert, R. Munos, and C. Szepesvari. Variance estimates and exploration function in multi-armed bandits. Technical report, CERTIS, 2007.  8</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
