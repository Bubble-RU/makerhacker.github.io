<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>80 nips-2008-Extended Grassmann Kernels for Subspace-Based Learning</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-80" href="../nips2008/nips-2008-Extended_Grassmann_Kernels_for_Subspace-Based_Learning.html">nips2008-80</a> <a title="nips-2008-80-reference" href="#">nips2008-80-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>80 nips-2008-Extended Grassmann Kernels for Subspace-Based Learning</h1>
<br/><p>Source: <a title="nips-2008-80-pdf" href="http://papers.nips.cc/paper/3433-extended-grassmann-kernels-for-subspace-based-learning.pdf">pdf</a></p><p>Author: Jihun Hamm, Daniel D. Lee</p><p>Abstract: Subspace-based learning problems involve data whose elements are linear subspaces of a vector space. To handle such data structures, Grassmann kernels have been proposed and used previously. In this paper, we analyze the relationship between Grassmann kernels and probabilistic similarity measures. Firstly, we show that the KL distance in the limit yields the Projection kernel on the Grassmann manifold, whereas the Bhattacharyya kernel becomes trivial in the limit and is suboptimal for subspace-based problems. Secondly, based on our analysis of the KL distance, we propose extensions of the Projection kernel which can be extended to the set of afﬁne as well as scaled subspaces. We demonstrate the advantages of these extended kernels for classiﬁcation and recognition tasks with Support Vector Machines and Kernel Discriminant Analysis using synthetic and real image databases. 1</p><br/>
<h2>reference text</h2><p>[1] Gianfranco Doretto, Alessandro Chiuso, Ying Nian Wu, and Stefano Soatto. Dynamic textures. Int. J. Comput. Vision, 51(2):91–109, 2003.</p>
<p>[2] Alan Edelman, Tom´ s A. Arias, and Steven T. Smith. The geometry of algorithms with orthogonality a constraints. SIAM J. Matrix Anal. Appl., 20(2):303–353, 1999.</p>
<p>[3] Athinodoros S. Georghiades, Peter N. Belhumeur, and David J. Kriegman. From few to many: Illumination cone models for face recognition under variable lighting and pose. IEEE Trans. Pattern Anal. Mach. Intell., 23(6):643–660, 2001.</p>
<p>[4] Zoubin Ghahramani and Geoffrey E. Hinton. The EM algorithm for mixtures of factor analyzers. Technical Report CRG-TR-96-1, Department of Computer Science, University of Toronto, 21 1996.</p>
<p>[5] Jihun Hamm. Subspace-based Learning with Grassmann Manifolds. Electrical and Systems Engineering, University of Pennsylvania, 2008. http://www.seas.upenn.edu/ jhham/Papers/thesis-jh.pdf.  Ph.D thesis in Available at</p>
<p>[6] Jihun Hamm and Daniel Lee. Grassmann discriminant analysis: a unifying view on subspace-based learning. In Int. Conf. Mach. Learning, 2008.  7  Yale Face 100  rate (%)  90 Eucl Lin LinSc Aff AffSc BC Bhat  80 70 60 50 40  1  3  5  7  9  subspace dimension (m)  ETH!80 100  rate (%)  90 Eucl Lin LinSc Aff AffSc BC Bhat  80 70 60 50 40  1  3  5  7  9  subspace dimension (m)  Figure 1: Comparison of Grassmann kernels for face recognition/ object categorization tasks with kernel discriminant analysis. The extended Projection kernels (Lin/LinSc/Aff/ AffSc) outperform the baseline method (Eucl) and the Binet-Cauchy (BC) and the Bhattacharyya (Bhat) kernels.</p>
<p>[7] Tony Jebara and Risi Imre Kondor. Bhattacharyya expected likelihood kernels. In COLT, pages 57–71, 2003.</p>
<p>[8] Risi Imre Kondor and Tony Jebara. A kernel between sets of vectors. In Proc. of the 20th Int. Conf. on Mach. Learn., pages 361–368, 2003.</p>
<p>[9] Bastian Leibe and Bernt Schiele. Analyzing appearance and contour based methods for object categorization. CVPR, 02:409, 2003.</p>
<p>[10] Bernhard Sch¨ lkopf and Alexander J. Smola. Learning with Kernels: Support Vector Machines, Regularo ization, Optimization, and Beyond. MIT Press, Cambridge, MA, USA, 2001.</p>
<p>[11] Gregory Shakhnarovich, John W. Fisher, and Trevor Darrell. Face recognition from long-term observations. In Proc. of the 7th Euro. Conf. on Computer Vision, pages 851–868, London, UK, 2002.</p>
<p>[12] Michael E. Tipping and Christopher M. Bishop. Probabilistic principal component analysis. Journal Of The Royal Statistical Society Series B, 61(3):611–622, 1999.</p>
<p>[13] Pavan Turaga, Ashok Veeraraghavan, and Rama Chellappa. Statistical analysis on Stiefel and Grassmann manifolds with applications in computer vision. In CVPR, 2008.</p>
<p>[14] Ashok Veeraraghavan, Amit K. Roy-Chowdhury, and Rama Chellappa. Matching shape sequences in video with applications in human movement analysis. IEEE Trans. Pattern Anal. Mach. Intell., 27(12):1896–1909, 2005.</p>
<p>[15] S.V.N. Vishwanathan and Alexander J. Smola. Binet-Cauchy kernels. In NIPS, 2004.</p>
<p>[16] Liwei Wang, Xiao Wang, and Jufu Feng. Subspace distance analysis with application to adaptive bayesian algorithm for face recognition. Pattern Recogn., 39(3):456–464, 2006.</p>
<p>[17] Lior Wolf and Amnon Shashua. Learning over sets using kernel principal angles. J. Mach. Learn. Res., 4:913–931, 2003.</p>
<p>[18] Shaohua Kevin Zhou and Rama Chellappa. From sample similarity to ensemble similarity: Probabilistic distance measures in Reproducing Kernel Hilbert Space. IEEE Trans. Pattern Anal. Mach. Intell., 28(6):917–929, 2006.  8</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
