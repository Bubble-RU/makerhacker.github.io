<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>119 nips-2008-Learning a discriminative hidden part model for human action recognition</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-119" href="../nips2008/nips-2008-Learning_a_discriminative_hidden_part_model_for_human_action_recognition.html">nips2008-119</a> <a title="nips-2008-119-reference" href="#">nips2008-119-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>119 nips-2008-Learning a discriminative hidden part model for human action recognition</h1>
<br/><p>Source: <a title="nips-2008-119-pdf" href="http://papers.nips.cc/paper/3565-learning-a-discriminative-hidden-part-model-for-human-action-recognition.pdf">pdf</a></p><p>Author: Yang Wang, Greg Mori</p><p>Abstract: We present a discriminative part-based approach for human action recognition from video sequences using motion features. Our model is based on the recently proposed hidden conditional random ﬁeld (hCRF) for object recognition. Similar to hCRF for object recognition, we model a human action by a ﬂexible constellation of parts conditioned on image observations. Different from object recognition, our model combines both large-scale global features and local patch features to distinguish various actions. Our experimental results show that our model is comparable to other state-of-the-art approaches in action recognition. In particular, our experimental results demonstrate that combining large-scale global features and local patch features performs signiﬁcantly better than directly applying hCRF on local patches alone. 1</p><br/>
<h2>reference text</h2><p>[1] A. C. Berg, T. L. Berg, and J. Malik. Shape matching and object recognition using low distortion correspondence. In IEEE CVPR, 2005.</p>
<p>[2] M. Blank, L. Gorelick, E. Shechtman, M. Irani, and R. Basri. Actions as space-time shapes. In IEEE ICCV, 2005.</p>
<p>[3] N. Dalal and B. Triggs. Histogram of oriented gradients for human detection. In IEEE CVPR, 2005.</p>
<p>[4] P. Doll´ r, V. Rabaud, G. Cottrell, and S. Belongie. Behavior recognition via sparse spatio-temporal a features. In VS-PETS Workshop, 2005.</p>
<p>[5] A. A. Efros, A. C. Berg, G. Mori, and J. Malik. Recognizing action at a distance. In IEEE ICCV, 2003.</p>
<p>[6] P. Felzenszwalb, D. McAllester, and D. Ramanan. A discriminatively trained, multiscale, deformable part model. In IEEE CVPR, 2008.</p>
<p>[7] P. F. Felzenszwalb and D. P. Huttenlocher. Pictorial structures for object recognition. IJCV, 61(1):55–79, January 2003.</p>
<p>[8] H. Jhuang, T. Serre, L. Wolf, and T. Poggio. A biologically inspired system for action recognition. In IEEE ICCV, 2007.</p>
<p>[9] Y. Ke, R. Sukthankar, and M. Hebert. Efﬁcient visual event detection using volumetric features. In IEEE ICCV, 2005.</p>
<p>[10] Y. Ke, R. Sukthankar, and M. Hebert. Event detection in crowded videos. In IEEE ICCV, 2007.</p>
<p>[11] J. Lafferty, A. McCallum, and F. Pereira. Conditional random ﬁelds: Probabilistic models for segmenting and labeling sequence data. In ICML, 2001.</p>
<p>[12] B. D. Lucas and T. Kanade. An iterative image registration technique with an application to stereo vision. In Proc. DARPA Image Understanding Workshop, 1981.</p>
<p>[13] J. C. Niebles and L. Fei-Fei. A hierarchical model of shape and appearance for human action classiﬁcation. In IEEE CVPR, 2007.</p>
<p>[14] J. C. Niebles, H. Wang, and L. Fei-Fei. Unsupervised learning of human action categories using spatialtemporal words. In BMVC, 2006.</p>
<p>[15] S. Nowozin, G. Bakir, and K. Tsuda. Discriminative subsequence mining for action classiﬁcation. In IEEE ICCV, 2007.</p>
<p>[16] A. Quattoni, M. Collins, and T. Darrell. Conditional random ﬁelds for object recognition. In NIPS 17, 2005.</p>
<p>[17] C. Schuldt, L. Laptev, and B. Caputo. Recognizing human actions: a local SVM approach. In IEEE ICPR, 2004.</p>
<p>[18] J. Sivic, B. C. Russell, A. A. Efros, A. Zisserman, and W. T. Freeman. Discovering objects and their location in images. In IEEE ICCV, 2005.</p>
<p>[19] S. B. Wang, A. Quattoni, L.-P. Morency, D. Demirdjian, and T. Darrell. Hidden conditional random ﬁelds for gesture recognition. In IEEE CVPR, 2006.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
