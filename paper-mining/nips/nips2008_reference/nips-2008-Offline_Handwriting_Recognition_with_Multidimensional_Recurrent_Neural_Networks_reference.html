<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>158 nips-2008-Offline Handwriting Recognition with Multidimensional Recurrent Neural Networks</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-158" href="../nips2008/nips-2008-Offline_Handwriting_Recognition_with_Multidimensional_Recurrent_Neural_Networks.html">nips2008-158</a> <a title="nips-2008-158-reference" href="#">nips2008-158-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>158 nips-2008-Offline Handwriting Recognition with Multidimensional Recurrent Neural Networks</h1>
<br/><p>Source: <a title="nips-2008-158-pdf" href="http://papers.nips.cc/paper/3449-offline-handwriting-recognition-with-multidimensional-recurrent-neural-networks.pdf">pdf</a></p><p>Author: Alex Graves, Jürgen Schmidhuber</p><p>Abstract: Ofﬂine handwriting recognition—the automatic transcription of images of handwritten text—is a challenging task that combines computer vision with sequence learning. In most systems the two elements are handled separately, with sophisticated preprocessing techniques used to extract the image features and sequential models such as HMMs used to provide the transcriptions. By combining two recent innovations in neural networks—multidimensional recurrent neural networks and connectionist temporal classiﬁcation—this paper introduces a globally trained ofﬂine handwriting recogniser that takes raw pixel data as input. Unlike competing systems, it does not require any alphabet speciﬁc preprocessing, and can therefore be used unchanged for any language. Evidence of its generality and power is provided by data from a recent international Arabic recognition competition, where it outperformed all entries (91.4% accuracy compared to 87.2% for the competition winner) despite the fact that neither author understands a word of Arabic. 1</p><br/>
<h2>reference text</h2><br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
