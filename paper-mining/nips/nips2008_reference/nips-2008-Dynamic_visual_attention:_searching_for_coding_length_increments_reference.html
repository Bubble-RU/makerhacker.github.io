<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>66 nips-2008-Dynamic visual attention: searching for coding length increments</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-66" href="../nips2008/nips-2008-Dynamic_visual_attention%3A_searching_for_coding_length_increments.html">nips2008-66</a> <a title="nips-2008-66-reference" href="#">nips2008-66-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>66 nips-2008-Dynamic visual attention: searching for coding length increments</h1>
<br/><p>Source: <a title="nips-2008-66-pdf" href="http://papers.nips.cc/paper/3531-dynamic-visual-attention-searching-for-coding-length-increments.pdf">pdf</a></p><p>Author: Xiaodi Hou, Liqing Zhang</p><p>Abstract: A visual attention system should respond placidly when common stimuli are presented, while at the same time keep alert to anomalous visual inputs. In this paper, a dynamic visual attention model based on the rarity of features is proposed. We introduce the Incremental Coding Length (ICL) to measure the perspective entropy gain of each feature. The objective of our model is to maximize the entropy of the sampled visual features. In order to optimize energy consumption, the limit amount of energy of the system is re-distributed amongst features according to their Incremental Coding Length. By selecting features with large coding length increments, the computational system can achieve attention selectivity in both static and dynamic scenes. We demonstrate that the proposed model achieves superior accuracy in comparison to mainstream approaches in static saliency map generation. Moreover, we also show that our model captures several less-reported dynamic visual search behaviors, such as attentional swing and inhibition of return. 1</p><br/>
<h2>reference text</h2><p>[1] V. Balasubramanian, D. Kimber, and M. Berry. Metabolically Efﬁcient Information Processing. Neural Computation, 13(4):799–815, 2001.</p>
<p>[2] A. Bell and T. Sejnowski. The independent components of natural scenes are edge ﬁlters. Vision Research, 37(23):3327–3338, 1997.</p>
<p>[3] N. Bruce and J. Tsotsos. Saliency Based on Information Maximization. Advances in Neural Information Processing Systems, 18, 2006.</p>
<p>[4] D. Gao, V. Mahadevan, and N. Vasconcelos. The discriminant center-surround hypothesis for bottom-up saliency. pages 497–504, 2007.</p>
<p>[5] L. Itti and P. Baldi. Bayesian Surprise Attracts Human Attention. Advances in Neural Information Processing Systems, 18:547, 2006.</p>
<p>[6] L. Itti and C. Koch. Computational modeling of visual attention. Nature Reviews Neuroscience, 2(3):194– 203, 2001.</p>
<p>[7] L. Itti, C. Koch, E. Niebur, et al. A model of saliency-based visual attention for rapid scene analysis. IEEE Transactions on Pattern Analysis and Machine Intelligence, 20(11):1254–1259, 1998.</p>
<p>[8] R. Klein. Inhibition of return. Trends in Cognitive Sciences, 4(4):138–147, 2000.</p>
<p>[9] C. Koch and T. Poggio. Predicting the visual world: silence is golden. Nature Neuroscience, 2:9–10, 1999.</p>
<p>[10] C. Koch and S. Ullman. Shifts in selective visual attention: towards the underlying neural circuitry. Hum Neurobiol, 4(4):219–27, 1985.</p>
<p>[11] W. Levy and R. Baxter. Energy Efﬁcient Neural Codes. Neural Codes and Distributed Representations: Foundations of Neural Computation, 1999.</p>
<p>[12] S. Ling and M. Carrasco. When sustained attention impairs perception. Nature neuroscience, 9(10):1243, 2006.</p>
<p>[13] J. Maunsell and S. Treue. Feature-based attention in visual cortex. Trends in Neurosciences, 29(6):317– 322, 2006.</p>
<p>[14] J. Najemnik and W. Geisler. Optimal eye movement strategies in visual search. Nature, 434(7031):387– 391, 2005.</p>
<p>[15] B. Olshausen et al. Emergence of simple-cell receptive ﬁeld properties by learning a sparse code for natural images. Nature, 381(6583):607–609, 1996.</p>
<p>[16] R. Peters and L. Itti. Beyond bottom-up: Incorporating task-dependent inﬂuences into a computational model of spatial attention. IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2007.</p>
<p>[17] R. Rao and D. Ballard. Predictive coding in the visual cortex: a functional interpretation of some extraclassical receptive-ﬁeld effects. Nature Neuroscience, 2:79–87, 1999.</p>
<p>[18] J. Reynolds, T. Pasternak, and R. Desimone. Attention Increases Sensitivity of V4 Neurons. Neuron, 26(3):703–714, 2000.</p>
<p>[19] S. Treue and J. Maunsell. Attentional modulation of visual motion processing in cortical areas MT and MST. Nature, 382(6591):539–541, 1996.</p>
<p>[20] J. van Hateren. Real and optimal neural images in early vision. Nature, 360(6399):68–70, 1992.</p>
<p>[21] M. Wainwright. Visual adaptation as optimal information transmission. Vision Research, 39(23):3960– 3974, 1999.</p>
<p>[22] D. Walther, D. Edgington, and C. Koch. Detection and tracking of objects in underwater video. Computer Vision and Pattern Recognition, 2004. CVPR 2004. Proceedings of the 2004 IEEE Computer Society Conference on, 1.</p>
<p>[23] D. Walther, U. Rutishauser, C. Koch, and P. Perona. Selective visual attention enables learning and recognition of multiple objects in cluttered scenes. Computer Vision and Image Understanding, 100(12):41–63, 2005.</p>
<p>[24] J. Wolfe, N. Klempen, and K. Dahlen. Post-attentive vision. Journal of Experimental Psychology: Human Perception and Performance, 26(2):693–716, 2000.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
