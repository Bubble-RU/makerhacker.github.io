<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>63 nips-2008-Dimensionality Reduction for Data in Multiple Feature Representations</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-63" href="../nips2008/nips-2008-Dimensionality_Reduction_for_Data_in_Multiple_Feature_Representations.html">nips2008-63</a> <a title="nips-2008-63-reference" href="#">nips2008-63-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>63 nips-2008-Dimensionality Reduction for Data in Multiple Feature Representations</h1>
<br/><p>Source: <a title="nips-2008-63-pdf" href="http://papers.nips.cc/paper/3602-dimensionality-reduction-for-data-in-multiple-feature-representations.pdf">pdf</a></p><p>Author: Yen-yu Lin, Tyng-luh Liu, Chiou-shann Fuh</p><p>Abstract: In solving complex visual learning tasks, adopting multiple descriptors to more precisely characterize the data has been a feasible way for improving performance. These representations are typically high dimensional and assume diverse forms. Thus ﬁnding a way to transform them into a uniﬁed space of lower dimension generally facilitates the underlying tasks, such as object recognition or clustering. We describe an approach that incorporates multiple kernel learning with dimensionality reduction (MKL-DR). While the proposed framework is ﬂexible in simultaneously tackling data in various feature representations, the formulation itself is general in that it is established upon graph embedding. It follows that any dimensionality reduction techniques explainable by graph embedding can be generalized by our method to consider data in multiple feature representations.</p><br/>
<h2>reference text</h2><p>[1] A. Berg, T. Berg, and J. Malik. Shape matching and object recognition using low distortion correspondences. In CVPR, 2005.</p>
<p>[2] A. Bosch, A. Zisserman, and X. Mu˜ oz. Image classiﬁcation using random forests and ferns. In ICCV, n 2007.</p>
<p>[3] H.-T. Chen, H.-W. Chang, and T.-L. Liu. Local discriminant embedding and its variants. In CVPR, 2005.</p>
<p>[4] L. Fei-Fei, R. Fergus, and P. Perona. Learning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories. In CVPR Workshop on Generative-Model Based Vision, 2004.</p>
<p>[5] A. Frome, Y. Singer, and J. Malik. Image retrieval and classiﬁcation using local distance functions. In NIPS, 2006.</p>
<p>[6] K. Grauman and T. Darrell. The pyramid match kernel: Efﬁcient learning with sets of features. JMLR, 2007.</p>
<p>[7] X. He and P. Niyogi. Locality preserving projections. In NIPS, 2003.</p>
<p>[8] S.-J. Kim, A. Magnani, and S. Boyd. Optimal kernel selection in kernel ﬁsher discriminant analysis. In ICML, 2006.</p>
<p>[9] G. Lanckriet, N. Cristianini, P. Bartlett, L. Ghaoui, and M. Jordan. Learning the kernel matrix with semideﬁnite programming. JMLR, 2004.</p>
<p>[10] Y.-Y. Lin, T.-L. Liu, and C.-S. Fuh. Local ensemble kernel learning for object category recognition. In CVPR, 2007.</p>
<p>[11] D. Lowe. Distinctive image features from scale-invariant keypoints. IJCV, 2004.</p>
<p>[12] S. Mika, G. R¨ tsch, J. Weston, B. Sch¨ lkopf, and K.-R. M¨ ller. Fisher discriminant analysis with kernels. a o u In Neural Networks for Signal Processing, 1999.</p>
<p>[13] J. Mutch and D. Lowe. Multiclass object recognition with sparse, localized features. In CVPR, 2006.</p>
<p>[14] A. Rakotomamonjy, F. Bach, S. Canu, and Y. Grandvalet. More efﬁciency in multiple kernel learning. In ICML, 2007.</p>
<p>[15] T. Serre, L. Wolf, and T. Poggio. Object recognition with features inspired by visual cortex. In CVPR, 2005.</p>
<p>[16] S. Sonnenburg, G. R¨ tsch, C. Sch¨ fer, and B. Sch¨ lkopf. Large scale multiple kernel learning. JMLR, a a o 2006.</p>
<p>[17] L. Vandenberghe and S. Boyd. Semideﬁnite programming. SIAM Review, 1996.</p>
<p>[18] M. Varma and D. Ray. Learning the discriminative power-invariance trade-off. In ICCV, 2007.</p>
<p>[19] S. Yan, D. Xu, B. Zhang, H. Zhang, Q. Yang, and S. Lin. Graph embedding and extensions: A general framework for dimensionality reduction. PAMI, 2007.</p>
<p>[20] H. Zhang, A. Berg, M. Maire, and J. Malik. Svm-knn: Discriminative nearest neighbor classiﬁcation for visual category recognition. In CVPR, 2006.</p>
<p>[21] J. Zhu, S. Rosset, H. Zou, and T. Hastie. Multi-class adaboost. Technical report, Dept. of Statistics, University of Michigan, 2005.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
