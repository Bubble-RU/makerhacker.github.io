<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>141 nips-2008-Multi-Agent Filtering with Infinitely Nested Beliefs</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-141" href="../nips2008/nips-2008-Multi-Agent_Filtering_with_Infinitely_Nested_Beliefs.html">nips2008-141</a> <a title="nips-2008-141-reference" href="#">nips2008-141-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>141 nips-2008-Multi-Agent Filtering with Infinitely Nested Beliefs</h1>
<br/><p>Source: <a title="nips-2008-141-pdf" href="http://papers.nips.cc/paper/3459-multi-agent-filtering-with-infinitely-nested-beliefs.pdf">pdf</a></p><p>Author: Luke Zettlemoyer, Brian Milch, Leslie P. Kaelbling</p><p>Abstract: In partially observable worlds with many agents, nested beliefs are formed when agents simultaneously reason about the unknown state of the world and the beliefs of the other agents. The multi-agent ﬁltering problem is to efﬁciently represent and update these beliefs through time as the agents act in the world. In this paper, we formally deﬁne an inﬁnite sequence of nested beliefs about the state of the world at the current time t, and present a ﬁltering algorithm that maintains a ﬁnite representation which can be used to generate these beliefs. In some cases, this representation can be updated exactly in constant time; we also present a simple approximation scheme to compact beliefs if they become too complex. In experiments, we demonstrate efﬁcient ﬁltering in a range of multi-agent domains. 1</p><br/>
<h2>reference text</h2><p>[1] D. S. Bernstein, E. Hansen, and S. Zilberstein. Bounded policy iteration for decentralized POMDPs. In Proc. of the 19th International Joint Conference on Artiﬁcial Intelligence (IJCAI), 2005.</p>
<p>[2] A. Brandenburger and E. Dekel. Hierarchies of beliefs and common knowledge. Journal of Economic Theory, 59:189–198, 1993.</p>
<p>[3] R. Fagin and J. Y. Halpern. Reasoning about knowledge and probability. Journal of the ACM, 41(2):340– 367, 1994.</p>
<p>[4] R. Fagin, J. Y. Halpern, Y. Moses, and M. Y. Vardi. Reasoning About Knowledge. The MIT Press, 1995.</p>
<p>[5] P. J. Gmytrasiewicz and P. Doshi. A framework for sequential planning in multi-agent settings. Journal of Artiﬁcial Intelligence Research, 24:49–79, 2005.</p>
<p>[6] E. A. Hansen, D. S. Bernstein, and S. Zilberstein. Dynamic programming for partially observable stochastic games. In Proc. of the 19th National Conf, on Artiﬁcial Intelligence (AAAI), 2004.</p>
<p>[7] L. P. Kaelbling, M. L. Littman, and A. R. Cassandra. Planning and acting in partially observable stochastic domains. Artiﬁcial Intelligence, 101:99–134, 1998.</p>
<p>[8] B. Milch and D. Koller. Probabilistic models for agents’ beliefs and decisions. In Proc. 16th Conference on Uncertainty in Artiﬁcial Intelligence (UAI), 2000.</p>
<p>[9] S. Seuken and S. Zilberstein. Improved memory-bounded dynamic programming for decentralized POMDPs. In Proc. of the 23rd Conference on Uncertainty in Artiﬁcial Intelligences (UAI), 2007.</p>
<p>[10] A. Shirazi and E. Amir. Probabilistic modal logic. In Proc. of the 22nd National Conference on Artiﬁcial Intelligence (AAAI), 2007. 6 This behavior can be veriﬁed by induction. If there is one muddy agent, it will see that the others are clean and raise its hand immediately. This implies that if no one raises their hand in the ﬁrst round, there must be at least two muddy agents. At time two, they will both see only one other muddy agent and infer that they are muddy. The pattern follows for larger m.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
