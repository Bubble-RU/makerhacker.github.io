<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>160 nips-2008-On Computational Power and the Order-Chaos Phase Transition in Reservoir Computing</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-160" href="../nips2008/nips-2008-On_Computational_Power_and_the_Order-Chaos_Phase_Transition_in_Reservoir_Computing.html">nips2008-160</a> <a title="nips-2008-160-reference" href="#">nips2008-160-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>160 nips-2008-On Computational Power and the Order-Chaos Phase Transition in Reservoir Computing</h1>
<br/><p>Source: <a title="nips-2008-160-pdf" href="http://papers.nips.cc/paper/3535-on-computational-power-and-the-order-chaos-phase-transition-in-reservoir-computing.pdf">pdf</a></p><p>Author: Benjamin Schrauwen, Lars Buesing, Robert A. Legenstein</p><p>Abstract: Randomly connected recurrent neural circuits have proven to be very powerful models for online computations when a trained memoryless readout function is appended. Such Reservoir Computing (RC) systems are commonly used in two ﬂavors: with analog or binary (spiking) neurons in the recurrent circuits. Previous work showed a fundamental difference between these two incarnations of the RC idea. The performance of a RC system built from binary neurons seems to depend strongly on the network connectivity structure. In networks of analog neurons such dependency has not been observed. In this article we investigate this apparent dichotomy in terms of the in-degree of the circuit nodes. Our analyses based amongst others on the Lyapunov exponent reveal that the phase transition between ordered and chaotic network behavior of binary circuits qualitatively differs from the one in analog circuits. This explains the observed decreased computational performance of binary circuits of high node in-degree. Furthermore, a novel mean-ﬁeld predictor for computational performance is introduced and shown to accurately predict the numerically obtained results. 1</p><br/>
<h2>reference text</h2><p>[1] H. Jaeger. The “echo state” approach to analyzing and training recurrent neural networks. GMD Report 148, German National Research Center for Information Technology, 2001.</p>
<p>[2] W. Maass, T. Natschl¨ ger, and H. Markram. Real-time computing without stable states: A new framework a for neural computation based on perturbations. Neural Computation, 14(11):2531–2560, 2002.</p>
<p>[3] Kristof Vandoorne, Wouter Dierckx, Benjamin Schrauwen, David Verstraeten, Roel Baets, Peter Bienstman, and Jan Van Campenhout. Toward optical signal processing using photonic reservoir computing. Optics Express, 16(15):11182–11192, 8 2008.</p>
<p>[4] H. Jaeger and H. Haas. Harnessing nonlinearity: predicting chaotic systems and saving energy in wireless communication. Science, 304:78–80, 2004.</p>
<p>[5] D. Verstraeten, B. Schrauwen, D. Stroobandt, and J. Van Campenhout. Isolated word recognition with the liquid state machine: a case study. Information Processing Letters, 95(6):521–528, 2005.</p>
<p>[6] P. Joshi and W. Maass. Movement generation with circuits of spiking neurons. Neural Computation, 17(8):1715–1738, 2005.</p>
<p>[7] D. Verstraeten, B. Schrauwen, M. D’Haene, and D. Stroobandt. A unifying comparison of Reservoir Computing methods. Neural Networks, 20:391–403, 2007.</p>
<p>[8] H. Jaeger. Echo state networks. Scholarpedia, 2(9):2330, 2007.</p>
<p>[9] S. H¨ usler and W. Maass. A statistical analysis of information processing properties of lamina-speciﬁc a cortical microcircuit models. Cerebral Cortex, 17(1):149–162, 2007.</p>
<p>[10] N. Bertschinger and T. Natschl¨ ger. Real-time computation at the edge of chaos in recurrent neural a networks. Neural Computation, 16(7):1413–1436, 2004.</p>
<p>[11] R. Legenstein and W. Maass. Edge of chaos and prediction of computational performance for neural microcircuit models. Neural Networks, pages 323–334, 2007.</p>
<p>[12] R. Legenstein and W. Maass. What makes a dynamical system computationally powerful? In S. Haykin, J. C. Principe, T.J. Sejnowski, and J.G. McWhirter, editors, New Directions in Statistical Signal Processing: From Systems to Brain, pages 127–154. MIT Press, 2007.</p>
<p>[13] B. Derrida and Pomeau Y. Random networks of automata: A simple annealed approximation. Europhysics Letters, 1(2):45–49, 1986.  8</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
