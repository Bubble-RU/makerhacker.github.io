<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>54 nips-2008-Covariance Estimation for High Dimensional Data Vectors Using the Sparse Matrix Transform</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-54" href="../nips2008/nips-2008-Covariance_Estimation_for_High_Dimensional_Data_Vectors_Using_the_Sparse_Matrix_Transform.html">nips2008-54</a> <a title="nips-2008-54-reference" href="#">nips2008-54-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>54 nips-2008-Covariance Estimation for High Dimensional Data Vectors Using the Sparse Matrix Transform</h1>
<br/><p>Source: <a title="nips-2008-54-pdf" href="http://papers.nips.cc/paper/3409-covariance-estimation-for-high-dimensional-data-vectors-using-the-sparse-matrix-transform.pdf">pdf</a></p><p>Author: Guangzhi Cao, Charles Bouman</p><p>Abstract: Covariance estimation for high dimensional vectors is a classically difﬁcult problem in statistical analysis and machine learning. In this paper, we propose a maximum likelihood (ML) approach to covariance estimation, which employs a novel sparsity constraint. More speciﬁcally, the covariance is constrained to have an eigen decomposition which can be represented as a sparse matrix transform (SMT). The SMT is formed by a product of pairwise coordinate rotations known as Givens rotations. Using this framework, the covariance can be efﬁciently estimated using greedy minimization of the log likelihood function, and the number of Givens rotations can be efﬁciently computed using a cross-validation procedure. The resulting estimator is positive deﬁnite and well-conditioned even when the sample size is limited. Experiments on standard hyperspectral data sets show that the SMT covariance estimate is consistently more accurate than both traditional shrinkage estimates and recently proposed graphical lasso estimates for a variety of different classes and sample sizes. 1</p><br/>
<h2>reference text</h2><p>[1] C. Stein, B. Efron, and C. Morris, “Improving the usual estimator of a normal covariance matrix,” Dept. of Statistics, Stanford University, Report 37, 1972.</p>
<p>[2] K. Fukunaga, Introduction to Statistical Pattern Recognition. Boston, MA: Academic Press, 1990, 2nd Ed.</p>
<p>[3] A. K. Jain, R. P. Duin, and J. Mao, “Statistical pattern recognition: A review,” IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 22, no. 1, pp. 4–37, 2000.</p>
<p>[4] J. H. Friedman, “Regularized discriminant analysis,” Journal of the American Statistical Association, vol. 84, no. 405, pp. 165–175, 1989.</p>
<p>[5] J. P. Hoffbeck and D. A. Landgrebe, “Covariance matrix estimation and classiﬁcation with limited training data,” IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 18, no. 7, pp. 763–767, 1996.</p>
<p>[6] P. J. Bickel and E. Levina, “Regularized estimation of large covariance matrices,” Annals of Statistics, vol. 36, no. 1, pp. 199–227, 2008.</p>
<p>[7] G. Cao and C. A. Bouman, “Covariance estimation for high dimensional data vectors using the sparse matrix transform,” Purdue University, Technical Report ECE 08-05, 2008.</p>
<p>[8] G. Cao, C. A. Bouman, and K. J. Webb, “Fast reconstruction algorithms for optical tomography using sparse matrix representations,” in Proceedings of 2007 IEEE International Symposium on Biomedical Imaging, April 2007.</p>
<p>[9] ——, “Non-iterative MAP reconstruction using sparse matrix representations,” (submitted to) IEEE Trans. on Image Processing.</p>
<p>[10] W. Givens, “Computation of plane unitary rotations transforming a general matrix to triangular form,” Journal of the Society for Industrial and Applied Mathematics, vol. 6, no. 1, pp. 26–50, March 1958.</p>
<p>[11] D. A. Landgrebe, Signal Theory Methods in Multispectral Remote Sensing. New York: WileyInterscience, 2005.</p>
<p>[12] J. Friedman, T. Hastie, and R. Tibshirani, “Sparse inverse covariance estimation with the graphical lasso,” Biostatistics, vol. 9, no. 3, pp. 432–441, Jul. 2008.</p>
<p>[13] M. J. Daniels and R. E. Kass, “Shrinkage estimators for covariance matrices,” Biometrics, vol. 57, no. 4, pp. 1173–1184, 2001.</p>
<p>[14] J. Schafer and K. Strimmer, “A shrinkage approach to large-scale covariance matrix estimation and implications for functional genomics,” Statistical Applications in Genetics and Molecular Biology, vol. 4, no. 1, 2005.</p>
<p>[15] P. J. Bickel and E. Levina, “Covariance regularization by thresholding,” Department of Statistics, UC Berkeley, Technical Report 744, 2007.</p>
<p>[16] J. W. Cooley and J. W. Tukey, “An algorithm for the machine calculation of complex Fourier series,” Mathematics of Computation, vol. 19, no. 90, pp. 297–301, April 1965.</p>
<p>[17] A. Soman and P. Vaidyanathan, “Paraunitary ﬁlter banks and wavelet packets,” Acoustics, Speech, and Signal Processing, 1992. ICASSP-92., 1992 IEEE International Conference on, vol. 4, pp. 397–400 vol.4, Mar 1992.  8</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
