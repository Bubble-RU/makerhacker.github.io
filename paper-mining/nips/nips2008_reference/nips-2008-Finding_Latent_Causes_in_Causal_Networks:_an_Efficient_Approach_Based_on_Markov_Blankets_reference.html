<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>86 nips-2008-Finding Latent Causes in Causal Networks: an Efficient Approach Based on Markov Blankets</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-86" href="../nips2008/nips-2008-Finding_Latent_Causes_in_Causal_Networks%3A_an_Efficient_Approach_Based_on_Markov_Blankets.html">nips2008-86</a> <a title="nips-2008-86-reference" href="#">nips2008-86-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>86 nips-2008-Finding Latent Causes in Causal Networks: an Efficient Approach Based on Markov Blankets</h1>
<br/><p>Source: <a title="nips-2008-86-pdf" href="http://papers.nips.cc/paper/3525-finding-latent-causes-in-causal-networks-an-efficient-approach-based-on-markov-blankets.pdf">pdf</a></p><p>Author: Jean-philippe Pellet, AndrÄ&sbquo;Ĺ  Elisseeff</p><p>Abstract: Causal structure-discovery techniques usually assume that all causes of more than one variable are observed. This is the so-called causal sufficiency assumption. In practice, it is untestable, and often violated. In this paper, we present an efficient causal structure-learning algorithm, suited for causally insufficient data. Similar to algorithms such as IC* and FCI, the proposed approach drops the causal sufficiency assumption and learns a structure that indicates (potential) latent causes for pairs of observed variables. Assuming a constant local density of the data-generating graph, our algorithm makes a quadratic number of conditionalindependence tests w.r.t. the number of variables. We show with experiments that our algorithm is comparable to the state-of-the-art FCI algorithm in accuracy, while being several orders of magnitude faster on large problems. We conclude that MBCS* makes a new range of causally insufficient problems computationally tractable. Keywords: Graphical Models, Structure Learning, Causal Inference. 1 Introduction: Task Definition & Related Work The statistical definition of causality pioneered by Pearl (2000) and Spirtes et al. (2001) has shed new light on how to detect causation. Central in this approach is the automated detection of causeeffect relationships using observational (i.e., non-experimental) data. This can be a necessary task, as in many situations, performing randomized controlled experiments to unveil causation can be impossible, unethical , or too costly. When the analysis deals with variables that cannot be manipulated, being able to learn from data collected by observing the running system is the only possibility. It turns out that learning the full causal structure of a set of variables is, in its most general form , impossible. If we suppose that the</p><br/>
<h2>reference text</h2><p>X. Boyen, N. Friedman, and D. Koller. Discovering the hidden structure of complex dynamic systems. In Proceedings of the 15th Conference on Uncertainty in Artijicial1ntelligence, 1999. G. Elidan and N. Friedman. Learning the dimensionality of hidden variables. In Proceedings of the 17th Conference in Uncertainty in Artijicial1ntelligence, pages 144-151 , 2001. G. Elidan, N. Lotner, N. Friedman, and D. Koller. Discovering hidden variables: A structure-based approach. In Proceedings of the 13th Conference on Advances in Neural Information Processing Systems, 2001. D. Margaritis and S. Thrun. Bayesian network induction via local neighborhoods. In Advances in Neural Information Processing Systems 12, 1999. 1. Pearl. Causality: Models, Reasoning, and Inference . Cambridge University Press, 2000. 1. Pearl. Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. Morgan Kaufmann, Los Altos, 1988. 1. Pearl and T. Verma. A theory of inferred causation. In Proc. of the Second Int. Con! on Principles of Knowledge Representation and Reasoning. Morgan Kaufmann, 1991. J.-P. Pellet and A. Elisseeff. Using Markov blankets for causal structure learning. Journal of Machine Learning Research, 9: 1295-1342, 2008 . R. Scheines. An introduction to causal inference. In V. McKim and S. Turner, editors, Causality in Crisis?, pages 185- 200. Univ. of Notre Dame Press, 1997. R. Scheines, P. Spirtes, C. Glymour, C. Meek, and T. Richardson. The TETRAD project: Constraint based aids to causal model specification. Technical report, Carnegie Mellon University, Dpt. of Philosophy, 1995. R. Silva, R. Scheines, C. Glymour, and P. Spirtes. Learning the structure of linear latent variable models. Journal of Machine Learning Research, 7: 191-246,2006. P. Spirtes, C. Meek, and T. Richardson. Causal inference in the presence of latent variables and selection bias. In Philippe Besnard and Steve Hanks, editors, Proceedings of the 11th Conference on Uncertainty in ArtijicialIntelligence, pages 491--498, San Mateo, CA, 1995. Morgan Kaufmann . P. Spirtes, T. Richardson, and C. Meek. Heuristic greedy search algorithms for latent variable models. In Proceedings of the 6th International Workshop on Artijiciallntelligence and Statistics, 1996. P. Spirtes, C. Glymour, and R. Scheines. Causation, Prediction, and Search, Second Edition. The MIT Press, 200 I. ISBN 0262194406. T. Verma. Graphical aspects of causal models. Technical Report R-191, Cognitive Systems Laboratory, UCLA, 1993.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
