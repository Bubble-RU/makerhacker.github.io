<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>4 nips-2008-A Scalable Hierarchical Distributed Language Model</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-4" href="../nips2008/nips-2008-A_Scalable_Hierarchical_Distributed_Language_Model.html">nips2008-4</a> <a title="nips-2008-4-reference" href="#">nips2008-4-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>4 nips-2008-A Scalable Hierarchical Distributed Language Model</h1>
<br/><p>Source: <a title="nips-2008-4-pdf" href="http://papers.nips.cc/paper/3583-a-scalable-hierarchical-distributed-language-model.pdf">pdf</a></p><p>Author: Andriy Mnih, Geoffrey E. Hinton</p><p>Abstract: Neural probabilistic language models (NPLMs) have been shown to be competitive with and occasionally superior to the widely-used n-gram language models. The main drawback of NPLMs is their extremely long training and testing times. Morin and Bengio have proposed a hierarchical language model built around a binary tree of words, which was two orders of magnitude faster than the nonhierarchical model it was based on. However, it performed considerably worse than its non-hierarchical counterpart in spite of using a word tree created using expert knowledge. We introduce a fast hierarchical language model along with a simple feature-based algorithm for automatic construction of word trees from the data. We then show that the resulting models can outperform non-hierarchical neural models as well as the best n-gram models. 1</p><br/>
<h2>reference text</h2><p>[1] Yoshua Bengio, Rejean Ducharme, Pascal Vincent, and Christian Jauvin. A neural probabilistic language model. Journal of Machine Learning Research, 3:1137–1155, 2003.</p>
<p>[2] Yoshua Bengio and Jean-S´ bastien Sen´ cal. Quick training of probabilistic neural nets by e e importance sampling. In AISTATS’03, 2003.</p>
<p>[3] P.F. Brown, R.L. Mercer, V.J. Della Pietra, and J.C. Lai. Class-based n-gram models of natural language. Computational Linguistics, 18(4):467–479, 1992.</p>
<p>[4] Stanley F. Chen and Joshua Goodman. An empirical study of smoothing techniques for language modeling. In Proceedings of the Thirty-Fourth Annual Meeting of the Association for Computational Linguistics, pages 310–318, San Francisco, 1996.</p>
<p>[5] Ahmad Emami, Peng Xu, and Frederick Jelinek. Using a connectionist model in a syntactical based language model. In Proceedings of ICASSP, volume 1, pages 372–375, 2003.</p>
<p>[6] C. Fellbaum et al. WordNet: an electronic lexical database. Cambridge, Mass: MIT Press, 1998.</p>
<p>[7] J. Goodman. A bit of progress in language modeling. Technical report, Microsoft Research, 2000.</p>
<p>[8] John G. McMahon and Francis J. Smith. Improving statistical language model performance with automatically generated word hierarchies. Computational Linguistics, 22(2):217–247, 1996.</p>
<p>[9] A. Mnih and G. Hinton. Three new graphical models for statistical language modelling. Proceedings of the 24th international conference on Machine learning, pages 641–648, 2007.</p>
<p>[10] Frederic Morin and Yoshua Bengio. Hierarchical probabilistic neural network language model. In Robert G. Cowell and Zoubin Ghahramani, editors, AISTATS’05, pages 246–252, 2005.</p>
<p>[11] F. Pereira, N. Tishby, and L. Lee. Distributional clustering of English words. Proceedings of the 31st conference on Association for Computational Linguistics, pages 183–190, 1993.</p>
<p>[12] Holger Schwenk and Jean-Luc Gauvain. Connectionist language modeling for large vocabulary continuous speech recognition. In Proceedings of the International Conference on Acoustics, Speech and Signal Processing, pages 765–768, 2002.  8</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
