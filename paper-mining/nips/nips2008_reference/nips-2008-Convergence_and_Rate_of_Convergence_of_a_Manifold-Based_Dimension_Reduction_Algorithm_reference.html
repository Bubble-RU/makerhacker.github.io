<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>51 nips-2008-Convergence and Rate of Convergence of a Manifold-Based Dimension Reduction Algorithm</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-51" href="../nips2008/nips-2008-Convergence_and_Rate_of_Convergence_of_a_Manifold-Based_Dimension_Reduction_Algorithm.html">nips2008-51</a> <a title="nips-2008-51-reference" href="#">nips2008-51-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>51 nips-2008-Convergence and Rate of Convergence of a Manifold-Based Dimension Reduction Algorithm</h1>
<br/><p>Source: <a title="nips-2008-51-pdf" href="http://papers.nips.cc/paper/3471-convergence-and-rate-of-convergence-of-a-manifold-based-dimension-reduction-algorithm.pdf">pdf</a></p><p>Author: Andrew Smith, Hongyuan Zha, Xiao-ming Wu</p><p>Abstract: We study the convergence and the rate of convergence of a local manifold learning algorithm: LTSA [13]. The main technical tool is the perturbation analysis on the linear invariant subspace that corresponds to the solution of LTSA. We derive a worst-case upper bound of errors for LTSA which naturally leads to a convergence result. We then derive the rate of convergence for LTSA in a special case. 1</p><br/>
<h2>reference text</h2><p>[1] M. Belkin and P. Niyogi. Laplacian eigenmaps for dimensionality reduction and data representation. Neural Computation, 15(6):1373–1396, 2003.</p>
<p>[2] M. Brand. Charting a manifold. In Neural Information Processing Systems, volume 15. Mitsubishi Electric Research Labs, MIT Press, March 2003.</p>
<p>[3] D. L. Donoho and C. E. Grimes. Hessian eigenmaps: New locally linear embedding techniques for high-dimensional data. Proceedings of the National Academy of Arts and Sciences, 100:5591–5596, 2003.</p>
<p>[4] X. Huo, X. S. Ni, and A. K. Smith. Mining of Enterprise Data, chapter A survey of manifoldbased learning methods. Springer, New York, 2005. Invited book chapter, accepted.</p>
<p>[5] X. Huo and A. K. Smith. Performance analysis of a manifold learning algorithm in dimension reduction. Technical report, Georgia Institute of Technology, March 2006. Downloadable at www2.isye.gatech.edu/statistics/papers/06-06.pdf, to appear in Linear Algebra and Its Applications.</p>
<p>[6] S. T. Roweis and L. K. Saul. Nonlinear dimensionality reduction by locally linear embedding. Science, 290:2323–2326, 2000.</p>
<p>[7] A. K. Smith. New results in dimension reduction and model selection. Ph.D. Thesis. Available at http://etd.gatech.edu, 2008.</p>
<p>[8] G. W. Stewart and J.-G. Sun. Matrix Perturbation Theory. Academic Press, Boston, MA, 1990.</p>
<p>[9] J. B. Tenenbaum, V. de Silva, and J. C. Langford. A global geometric framework for nonlinear dimensionality reduction. Science, 290:2319–2323, 2000.</p>
<p>[10] T. Wittman. MANIfold learning Matlab demo. URL: http://www.math.umn.edu/∼wittman/mani/index.html, April 2005.</p>
<p>[11] H. Zha and H. Zhang. Spectral properties of the alignment matrices in manifold learning. SIAM Review, 2008.</p>
<p>[12] H. Zha and Z. Zhang. Spectral analysis of alignment in manifold learning. In Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing, 2005.</p>
<p>[13] Z. Zhang and H. Zha. Principal manifolds and nonlinear dimension reduction via local tangent space alignment. SIAM Journal of Scientiﬁc Computing, 26(1):313–338, 2004.  8</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
