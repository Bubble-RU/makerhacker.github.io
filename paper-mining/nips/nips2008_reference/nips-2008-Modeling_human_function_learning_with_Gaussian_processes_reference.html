<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>138 nips-2008-Modeling human function learning with Gaussian processes</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-138" href="../nips2008/nips-2008-Modeling_human_function_learning_with_Gaussian_processes.html">nips2008-138</a> <a title="nips-2008-138-reference" href="#">nips2008-138-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>138 nips-2008-Modeling human function learning with Gaussian processes</h1>
<br/><p>Source: <a title="nips-2008-138-pdf" href="http://papers.nips.cc/paper/3529-modeling-human-function-learning-with-gaussian-processes.pdf">pdf</a></p><p>Author: Thomas L. Griffiths, Chris Lucas, Joseph Williams, Michael L. Kalish</p><p>Abstract: Accounts of how people learn functional relationships between continuous variables have tended to focus on two possibilities: that people are estimating explicit functions, or that they are performing associative learning supported by similarity. We provide a rational analysis of function learning, drawing on work on regression in machine learning and statistics. Using the equivalence of Bayesian linear regression and Gaussian processes, we show that learning explicit rules and using similarity can be seen as two views of one solution to this problem. We use this insight to deﬁne a Gaussian process model of human function learning that combines the strengths of both approaches. 1</p><br/>
<h2>reference text</h2><p>[1] J. D. Carroll. Functional learning: The learning of continuous functional mappings relating stimulus and response continua. Education Testing Service, Princeton, NJ, 1963.</p>
<p>[2] B. Brehmer. Hypotheses about relations between scaled variables in the learning of probabilistic inference tasks. Organizational Behavior and Human Decision Processes, 11:1–27, 1974.</p>
<p>[3] K. Koh and D. E. Meyer. Function learning: Induction of continuous stimulus-response relations. Journal of Experimental Psychology: Learning, Memory, and Cognition, 17:811–836, 1991.</p>
<p>[4] E. L. DeLosh, J. R. Busemeyer, and M. A. McDaniel. Extrapolation: The sine qua non of abstraction in function learning. Journal of Experimental Psychology: Learning, Memory, and Cognition, 23:968–986, 1997.</p>
<p>[5] J. R. Busemeyer, E. Byun, E. L. DeLosh, and M. A. McDaniel. Learning functional relations based on experience with input-output pairs by humans and artiﬁcial neural networks. In K. Lamberts and D. Shanks, editors, Concepts and Categories, pages 405–437. MIT Press, Cambridge, 1997.</p>
<p>[6] M. A. McDaniel and J. R. Busemeyer. The conceptual basis of function learning and extrapolation: Comparison of rule-based and associative-based models. Psychonomic Bulletin and Review, 12:24–42, 2005.</p>
<p>[7] M. Kalish, S. Lewandowsky, and J. Kruschke. Population of linear experts: Knowledge partitioning and function learning. Psychological Review, 111:1072–1099, 2004.</p>
<p>[8] J. R. Anderson. The adaptive character of thought. Erlbaum, Hillsdale, NJ, 1990.</p>
<p>[9] J. M. Bernardo and A. F. M. Smith. Bayesian theory. Wiley, New York, 1994.</p>
<p>[10] C. K. I. Williams. Prediction with Gaussian processes: From linear regression to linear prediction and beyond. In M. I. Jordan, editor, Learning in Graphical Models, pages 599–621. MIT Press, Cambridge, MA, 1998.</p>
<p>[11] R. M. Neal. Priors for inﬁnite networks. Technical Report CRG-TR-94-1, Department of Computer Science, University of Toronto, 1994.</p>
<p>[12] D.J.C. MacKay. Probable networks and plausible predictions - a review of practical bayesian methods for supervised neural networks. Network: Computation in Neural Systems, 6:469–505, 1995.</p>
<p>[13] W.R. Gilks, S. Richardson, and D. J. Spiegelhalter, editors. Markov Chain Monte Carlo in Practice. Chapman and Hall, Suffolk, UK, 1996.  8</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
