<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>125 nips-2008-Local Gaussian Process Regression for Real Time Online Model Learning</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-125" href="../nips2008/nips-2008-Local_Gaussian_Process_Regression_for_Real_Time_Online_Model_Learning.html">nips2008-125</a> <a title="nips-2008-125-reference" href="#">nips2008-125-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>125 nips-2008-Local Gaussian Process Regression for Real Time Online Model Learning</h1>
<br/><p>Source: <a title="nips-2008-125-pdf" href="http://papers.nips.cc/paper/3403-local-gaussian-process-regression-for-real-time-online-model-learning.pdf">pdf</a></p><p>Author: Duy Nguyen-tuong, Jan R. Peters, Matthias Seeger</p><p>Abstract: Learning in real-time applications, e.g., online approximation of the inverse dynamics model for model-based robot control, requires fast online regression techniques. Inspired by local learning, we propose a method to speed up standard Gaussian process regression (GPR) with local GP models (LGP). The training data is partitioned in local regions, for each an individual GP model is trained. The prediction for a query point is performed by weighted estimation using nearby local models. Unlike other GP approximations, such as mixtures of experts, we use a distance based measure for partitioning of the data and weighted prediction. The proposed method achieves online learning and prediction in real-time. Comparisons with other non-parametric regression methods show that LGP has higher accuracy than LWPR and close to the performance of standard GPR and ν-SVR. 1</p><br/>
<h2>reference text</h2><p>[1] C. E. Rasmussen and C. K. Williams, Gaussian Processes for Machine Learning. sachusetts Institute of Technology: MIT-Press, 2006.  Mas-</p>
<p>[2] J. Q. Candela and C. E. Rasmussen, “A unifying view of sparse approximate gaussian process regression,” Journal of Machine Learning Research, 2005.</p>
<p>[3] V. Treps, “Mixtures of gaussian process,” Advances in Neural Information Processing Systems, 2001.</p>
<p>[4] C. E. Rasmussen and Z. Ghahramani, “Inﬁnite mixtures of gaussian process experts,” Advances in Neural Information Processing Systems, 2002.</p>
<p>[5] L. Csato and M. Opper, “Sparse online gaussian processes,” Neural Computation, 2002.</p>
<p>[6] E. Snelson and Z. Ghahramani, “Local and global sparse gaussian process approximations,” Artiﬁcial Intelligence and Statistics, 2007.</p>
<p>[7] S. Schaal, C. G. Atkeson, and S. Vijayakumar, “Scalable techniques from nonparameteric statistics for real-time robot learning,” Applied Intelligence, pp. 49–60, 2002.</p>
<p>[8] S. Vijayakumar, A. D’Souza, and S. Schaal, “Incremental online learning in high dimensions,” Neural Computation, 2005.</p>
<p>[9] M. Seeger, “Low rank update for the cholesky decomposition,” Tech. Rep., 2007. [Online]. Available: http://www.kyb.tuebingen.mpg.de/bs/people/seeger/</p>
<p>[10] J. J. Craig, Introduction to Robotics: Mechanics and Control, 3rd ed. Prentice Hall, 2004.</p>
<p>[11] B. Sch¨ lkopf and A. Smola, Learning with Kernels: Support Vector Machines, Regularization, o Optimization and Beyond. Cambridge, MA: MIT-Press, 2002.</p>
<p>[12] S. Schaal, “The SL simulation and real-time control software package,” Tech. Rep., 2006. [Online]. Available: http://www-clmc.usc.edu/publications/S/schaal-TRSL.pdf</p>
<p>[13] C.-C. Chang and C.-J. Lin, LIBSVM: a library for support vector machines, 2001, http://www.csie.ntu.edu.tw/ cjlin/libsvm.</p>
<p>[14] M. Seeger, LHOTSE: Toolbox for Adaptive http://www.kyb.tuebingen.mpg.de/bs/people/seeger/lhotse/.  Statistical  Model,  2007,</p>
<p>[15] D. Nguyen-Tuong, J. Peters, and M. Seeger, “Computed torque control with nonparametric regression models,” Proceedings of the 2008 American Control Conference (ACC 2008), 2008.  8</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
