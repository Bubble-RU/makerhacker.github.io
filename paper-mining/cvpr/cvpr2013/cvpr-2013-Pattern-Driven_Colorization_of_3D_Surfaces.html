<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>327 cvpr-2013-Pattern-Driven Colorization of 3D Surfaces</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-327" href="#">cvpr2013-327</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>327 cvpr-2013-Pattern-Driven Colorization of 3D Surfaces</h1>
<br/><p>Source: <a title="cvpr-2013-327-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Leifman_Pattern-Driven_Colorization_of_2013_CVPR_paper.pdf">pdf</a></p><p>Author: George Leifman, Ayellet Tal</p><p>Abstract: Colorization refers to the process of adding color to black & white images or videos. This paper extends the term to handle surfaces in three dimensions. This is important for applications in which the colors of an object need to be restored and no relevant image exists for texturing it. We focus on surfaces with patterns and propose a novel algorithm for adding colors to these surfaces. The user needs only to scribble a few color strokes on one instance of each pattern, and the system proceeds to automatically colorize the whole surface. For this scheme to work, we address not only the problem of colorization, but also the problem of pattern detection on surfaces.</p><p>Reference: <a title="cvpr-2013-327-reference" href="../cvpr2013_reference/cvpr-2013-Pattern-Driven_Colorization_of_3D_Surfaces_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The user needs only to scribble a few color strokes on one instance of each pattern, and the system proceeds to automatically colorize the whole surface. [sent-8, score-0.73]
</p><p>2 [11] proposed a simple, yet effective, user-guided image colorization method. [sent-14, score-0.553]
</p><p>3 The user scribbles the desired colors in the interiors of various regions and the system spreads the colors to the rest of the image. [sent-15, score-0.433]
</p><p>4 The extension of colorization algorithms from images to surfaces is not straightforward. [sent-20, score-0.68]
</p><p>5 i let l  user scribbles a handful of strokes within and around a single instance of each pattern (left). [sent-28, score-0.797]
</p><p>6 Recently, [10] introduced a scribble-based colorization algorithm for 3D surfaces. [sent-30, score-0.553]
</p><p>7 The user draws several strokes and the system propagates the colors to the whole surface. [sent-31, score-0.567]
</p><p>8 Therefore, colorization of objects with patterns requires color strokes on each pattern instance, which is time consuming. [sent-33, score-1.017]
</p><p>9 For surfaces, an added difficulty is the lack of a simple parametrization:  Each vertex may have a different number of neighbors and different immediate surroundings. [sent-36, score-0.252]
</p><p>10 Nevertheless, some methods were recently proposed for symmetry and pattern detection on surfaces [18]. [sent-38, score-0.288]
</p><p>11 In [15], 222444111  (a) input strokes(b) filtered surface(c) automatic strokes(d) colorization Figure 2. [sent-43, score-0.617]
</p><p>12 Given a 3D model, the user scribbles only on one instance of the pattern (a). [sent-45, score-0.468]
</p><p>13 Each vertex is then classified in accordance  with the pattern, and new strokes are automatically  produced (c). [sent-47, score-0.654]
</p><p>14 Finally, the colorization is performed, utilizing this new set of strokes (d). [sent-48, score-0.855]
</p><p>15 It is based on the idea that the few strokes provided for colorization can be extremely helpful for classification. [sent-52, score-0.855]
</p><p>16 Finally, once the patterns are classified,  even highly complex surfaces are automatically colorized using the user’s strokes around and within a single instance of each pattern (Section 5). [sent-56, score-0.731]
</p><p>17 First, we propose a colorization algorithm that handles patterns. [sent-58, score-0.553]
</p><p>18 Finally, we describe a pattern classification algorithm that uses a handful of strokes as input. [sent-60, score-0.484]
</p><p>19 We assume that the surface is given as a triangular mesh that consists of vertices and faces. [sent-63, score-0.365]
</p><p>20 To colorize a model, the user draws a few scribbles with the desired colors on the surface (Figure 2(a)). [sent-64, score-0.626]
</p><p>21 It suffices to draw a few scribbles within and in the surroundings of a single instance of each pattern. [sent-65, score-0.297]
</p><p>22 The algorithm then automatically propagates the colors to the remaining vertices of the surface. [sent-66, score-0.35]
</p><p>23 For each face the scribble passes through, the closest vertex gets the color of the scribble. [sent-67, score-0.39]
</p><p>24 In addition, since our surface has patterns, we make another assumption: Vertices that belong to the same pattern should get the same color. [sent-70, score-0.256]
</p><p>25 This means that pattern colorization can be viewed as a vertex classification problem. [sent-71, score-0.96]
</p><p>26 In the filtered surface, the pattern boundaries are kept intact, whereas the details in the pattern region are filtered out. [sent-75, score-0.462]
</p><p>27 In the second step, each vertex of the filtered surface is classified, determining whether it belongs to the pattern or not. [sent-78, score-0.536]
</p><p>28 We start by associating every vertex with a descriptor, which characterizes its region in accordance with the pattern. [sent-79, score-0.434]
</p><p>29 Finally, we use a subset of the classified vertices to automatically produce additional colorization strokes in accordance with the pattern (Section 5). [sent-82, score-1.332]
</p><p>30 These strokes are the input to a pattern-independent colorization algorithm. [sent-83, score-0.855]
</p><p>31 The colorization is formulated as an optimization problem, which is based on geometric similarity between neighboring vertices, where the color strokes are considered the userdefined constraints. [sent-84, score-0.933]
</p><p>32 Pattern-Driven Region Descriptors  This section describes our vertex descriptor, which characterizes the neighbourhood of the vertex, in accordance with the pattern to be colorized. [sent-86, score-0.484]
</p><p>33 In particular, we first extract for each vertex its surrounding region, which is segmented into foreground (pattern) and background. [sent-87, score-0.375]
</p><p>34 The region-based descriptor captures the geometry of the region, whereas the boundary descriptor relies only on the shape of the region’s boundary. [sent-89, score-0.246]
</p><p>35 If a vertex does not belong to the pattern, the resulting segmentation of its surrounding region is insignificant. [sent-92, score-0.344]
</p><p>36 This is so, since the descriptors of this region will be very different from those of foreground vertices and therefore, will be classified as background in Section 4. [sent-93, score-0.518]
</p><p>37 222444222  (a) pat ern vertex(b) non-pat ern vertex  Figure 3. [sent-94, score-0.312]
</p><p>38 Given a vertex (green), we first extract a sub-surface (yellow) around it and then  segment it into a foreground (brown) and a background. [sent-96, score-0.349]
</p><p>39 Pattern-driven segmentation Prior to computing the descriptor, each vertex is associated with a sub-surface around it, which is segmented into a foreground and a background (Figure 3). [sent-99, score-0.349]
</p><p>40 We define a bounding box, whose size is twice the size of the bounding box that tightly encloses all the vertices of the user’s scribbles. [sent-101, score-0.261]
</p><p>41 To segment the sub-surface into its foreground and background, we apply the colorization algorithm of [10]. [sent-103, score-0.65]
</p><p>42 Briefly, this algorithm first associates each vertex with the spin image descriptor [9], and then computes the diffusion distance [13] between every pair of neighboring vertices vi and vj . [sent-105, score-0.889]
</p><p>43 To impose the constraint that two neighboring vertices should get the same color if their geometry is similar, the following cost function is minimized:  Ω(C) =v? [sent-106, score-0.375]
</p><p>44 s optimized, adding the constraints that the vertex for which? [sent-116, score-0.252]
</p><p>45 the region is computed, gets the foreground color, and the boundary vertices (of the surrounding sub-surface) get the background color. [sent-118, score-0.555]
</p><p>46 The solution to this optimization problem assigns colors to all the vertices in the sub-surface. [sent-119, score-0.324]
</p><p>47 Finally, we define the foreground (pattern) region to consist of all the vertices whose assigned colors differ from the background color. [sent-120, score-0.487]
</p><p>48 Region-based vertex descriptor We seek a descriptor that robustly characterizes the geometry not only of the vertex, but also of the region it resides in. [sent-123, score-0.591]
</p><p>49 In particular, for every pair of vi’s neighbors vji and vki, a Darboux uvw frame (Figure 4) is defined as u=  v = (vji − vki)  ni,  u, w = u  where ni is the surface normal at vertex angular variations are then computed:  vi. [sent-129, score-0.437]
</p><p>50 α  v,  (3)  Finally, a vertex vi is associated with a 3D histogram of triples < α, φ, > for every pair of neighbors. [sent-133, score-0.34]
</p><p>51 In our case, the neighbors of a vertex are those included in the foreground region, rather than the immediate neighbors, as common. [sent-134, score-0.349]
</p><p>52 This is so, since when considering all the pairs in the region, the resulting descriptors become almost identical for the vertices in the same region. [sent-137, score-0.31]
</p><p>53 Boundary-based vertex descriptor To describe the curve that bounds the foreground region, we use 2D histograms of the curve’s curvature and the torsion. [sent-146, score-0.557]
</p><p>54 Pattern Classification This section describes our classification technique, whose aim is to determine which vertices of the surface belong to the pattern and which do not. [sent-205, score-0.52]
</p><p>55 Recall that to colorize a surface, the user draws a few scribbles on a pattern’s instance and around it. [sent-206, score-0.504]
</p><p>56 For each face the scribble passes through, the closest vertex gets the color of the scribble. [sent-207, score-0.39]
</p><p>57 As a result, a few vertices are colored with the foreground color, and these are the positive examples. [sent-208, score-0.397]
</p><p>58 A few other vertices get the background color and these are the negative examples. [sent-209, score-0.431]
</p><p>59 While the set of positive examples can be easily enriched by using the foreground vertices found by our segmentation (Section 6), there is no easy way to enrich the set of the negative examples automatically. [sent-212, score-0.712]
</p><p>60 Recall that our final goal is to classify only a representative subset of vertices with very high confidence, which will suffice for colorization. [sent-220, score-0.291]
</p><p>61 Finally, to get only a representative subset with high confidence, we train an SVM classifier using the enriched set of the negative examples, and choose the vertices that are far from the separation plane (Section 4. [sent-227, score-0.547]
</p><p>62 In (b), the enriched set of negative examples is shown, where these are correctly classified. [sent-245, score-0.226]
</p><p>63 We utilize this to disqualify the vertices that were incorrectly classified as positive. [sent-249, score-0.306]
</p><p>64 We add the top 10% of these vertices as negative examples. [sent-250, score-0.349]
</p><p>65 Yet, transforming the data to another descriptor space, where the positive examples can be more easily separated from the negative examples, can improve the classification. [sent-255, score-0.291]
</p><p>66 We are given N observations in the ddimensional descriptor space, divided into a subset of positive examples and a subset of negative examples. [sent-258, score-0.291]
</p><p>67 The goal is to achieve maximal separation between the positive and the negative examples, while avoiding the clustering of the negative examples, which reside far from each other in the descriptor space. [sent-274, score-0.404]
</p><p>68 (b) The classification of vertices having high confidence is correct and suffices as input for the final colorization. [sent-278, score-0.381]
</p><p>69 Since we only need enough correctly-classified vertices to perform accurate colorization, we use only the SVM classifications that are far from the separation plane. [sent-290, score-0.316]
</p><p>70 In practice, the top 10% of the positive and the top 10% of the negative vertices suffice, as illustrated in Figure 6(b). [sent-291, score-0.388]
</p><p>71 This result, which is also shown in Figure 2(c), leads to the eye-pleasing colorization in Figure 2(d). [sent-292, score-0.553]
</p><p>72 Al the  stars are colorized by scribbling only four color strokes on one star instance and its surroundings. [sent-302, score-0.571]
</p><p>73 Final Colorization & Results The vertices, which were classified with the highest confidence, are used as input to the colorization algorithm, described in Equation (1). [sent-304, score-0.598]
</p><p>74 The positive vertices get the “foreground color” and the negative vertices get the “background color. [sent-305, score-0.721]
</p><p>75 ” Thanks to our pattern-aware filtering, even a single vertex in a pattern suffices to extract the pattern correctly. [sent-306, score-0.565]
</p><p>76 In Figure 7, all the stars are colorized easily, using only four color strokes on a single star instance and its surroundings. [sent-309, score-0.571]
</p><p>77 The user first marks one of the deers (Figure 8(a)) and our algorithm completes the colorization of all the instances of the deer (Figure 8(b)). [sent-313, score-0.808]
</p><p>78 Then, the user proceeds to scribble on one of the trees (Figure 8(c)). [sent-314, score-0.225]
</p><p>79 Our algorithm ignores the pattern found in the previous iteration and colorizes the other trees compatibly (Figure 8(d)). [sent-315, score-0.252]
</p><p>80 We allow the user to mark scribbles on more than one instance of a pattern, and take all these scribbles into consideration in our classification algorithm. [sent-319, score-0.562]
</p><p>81 Therefore, here, our  one-class SVM classification in the region descriptor space suffices to obtain the correct result. [sent-324, score-0.292]
</p><p>82 Given a surface with two distinct patterns, the user first marks one of them (the deer) (a). [sent-329, score-0.275]
</p><p>83 Then, the user scribbles on an instance of a tree (c) and all other trees are colorized automatically (d). [sent-331, score-0.493]
</p><p>84 stances are not identical, the user marks on a few instances of the same pattern and the learning is based on all these scribbles. [sent-332, score-0.318]
</p><p>85 Our algorithm detects all the suction cups and their accurate boundaries, whereas the boundaries produced by [7] are fuzzy and some suction cups are not detected. [sent-336, score-0.44]
</p><p>86 Our algorithm colorizes nicely both the different parts and the reliefs on them. [sent-338, score-0.255]
</p><p>87 Our algorithm detects all the suction cups and colorizes them accurately, whereas the boundaries produced by [7] are less precise and not all the suction cups are detected. [sent-341, score-0.576]
</p><p>88 Our pattern-driven algorithm nicely colorizes both the different parts and the reliefs on them. [sent-345, score-0.255]
</p><p>89 Implementation: Pattern-Aware Filtering As mentioned before, even a single vertex inside a pattern suffices to colorize the whole pattern. [sent-347, score-0.561]
</p><p>90 This is performed by the basic colorization technique described in Section 3. [sent-351, score-0.553]
</p><p>91 Each vertex moves halfway along its L(v) vector: v? [sent-359, score-0.252]
</p><p>92 We randomly sample a set of vertices V from the foreground region. [sent-365, score-0.358]
</p><p>93 For each sample vj ∈ V , we apply the col-  (a) input (b) filtered surface Figure 13. [sent-366, score-0.237]
</p><p>94 The boundary of the pattern is preserved, while the details inside the pattern are filtered out. [sent-368, score-0.33]
</p><p>95 orization algorithm of [10], where vj gets the foreground color and all the vertices on the sub-surface’s boundary get the background. [sent-369, score-0.578]
</p><p>96 We say that a smoothed surface has a good separation quality if the colorization of the pattern, using a single vertex in it, is similar to the colorization utilizing all the user’s strokes. [sent-371, score-1.517]
</p><p>97 Conclusion This paper introduced a colorization algorithm for surfaces with patterns. [sent-383, score-0.68]
</p><p>98 After the user scribbles a few color strokes on one instance of every pattern, the system successfully colorizes the whole surface. [sent-384, score-0.836]
</p><p>99 Finally, we show that our classification produces results that allow us to colorize surfaces of varying types and complexities. [sent-390, score-0.278]
</p><p>100 An adaptive edge detection based colorization algorithm and its applications. [sent-439, score-0.553]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('colorization', 0.553), ('strokes', 0.302), ('vertices', 0.261), ('vertex', 0.252), ('scribbles', 0.171), ('colorized', 0.141), ('colorizes', 0.136), ('user', 0.136), ('surfaces', 0.127), ('pattern', 0.116), ('suction', 0.114), ('colorize', 0.112), ('descriptor', 0.106), ('surface', 0.104), ('torsion', 0.101), ('foreground', 0.097), ('reliefs', 0.091), ('vi', 0.088), ('cups', 0.088), ('negative', 0.088), ('suffices', 0.081), ('vji', 0.081), ('enriched', 0.08), ('enriching', 0.075), ('vki', 0.075), ('mx', 0.073), ('curvature', 0.071), ('vj', 0.069), ('nji', 0.068), ('recoloring', 0.068), ('region', 0.066), ('filtered', 0.064), ('colors', 0.063), ('characterizes', 0.061), ('examples', 0.058), ('scribble', 0.057), ('accordance', 0.055), ('separation', 0.055), ('deer', 0.053), ('diffusion', 0.05), ('graphics', 0.05), ('descriptors', 0.049), ('color', 0.046), ('cotraining', 0.045), ('darboux', 0.045), ('leifman', 0.045), ('rfij', 0.045), ('suits', 0.045), ('wopt', 0.045), ('classified', 0.045), ('kij', 0.045), ('instance', 0.045), ('symmetry', 0.045), ('svm', 0.042), ('pfh', 0.04), ('draws', 0.04), ('positive', 0.039), ('classification', 0.039), ('separability', 0.038), ('mitra', 0.038), ('smoothing', 0.037), ('stars', 0.037), ('blodow', 0.037), ('transactions', 0.036), ('boundaries', 0.036), ('get', 0.036), ('bda', 0.035), ('monochrome', 0.035), ('marks', 0.035), ('gets', 0.035), ('boundary', 0.034), ('rusu', 0.034), ('mover', 0.034), ('confident', 0.033), ('neighboring', 0.032), ('proceeds', 0.032), ('curve', 0.031), ('instances', 0.031), ('technion', 0.031), ('enrich', 0.031), ('pauly', 0.031), ('spin', 0.031), ('filtering', 0.031), ('forum', 0.03), ('periodic', 0.03), ('suffice', 0.03), ('ern', 0.03), ('pages', 0.029), ('rbf', 0.029), ('wand', 0.029), ('equation', 0.029), ('nicely', 0.028), ('reside', 0.028), ('earth', 0.028), ('sz', 0.028), ('classifier', 0.027), ('handful', 0.027), ('propagates', 0.026), ('surrounding', 0.026), ('sx', 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="327-tfidf-1" href="./cvpr-2013-Pattern-Driven_Colorization_of_3D_Surfaces.html">327 cvpr-2013-Pattern-Driven Colorization of 3D Surfaces</a></p>
<p>Author: George Leifman, Ayellet Tal</p><p>Abstract: Colorization refers to the process of adding color to black & white images or videos. This paper extends the term to handle surfaces in three dimensions. This is important for applications in which the colors of an object need to be restored and no relevant image exists for texturing it. We focus on surfaces with patterns and propose a novel algorithm for adding colors to these surfaces. The user needs only to scribble a few color strokes on one instance of each pattern, and the system proceeds to automatically colorize the whole surface. For this scheme to work, we address not only the problem of colorization, but also the problem of pattern detection on surfaces.</p><p>2 0.27494043 <a title="327-tfidf-2" href="./cvpr-2013-Recovering_Stereo_Pairs_from_Anaglyphs.html">352 cvpr-2013-Recovering Stereo Pairs from Anaglyphs</a></p>
<p>Author: Armand Joulin, Sing Bing Kang</p><p>Abstract: An anaglyph is a single image created by selecting complementary colors from a stereo color pair; the user can perceive depth by viewing it through color-filtered glasses. We propose a technique to reconstruct the original color stereo pair given such an anaglyph. We modified SIFT-Flow and use it to initially match the different color channels across the two views. Our technique then iteratively refines the matches, selects the good matches (which defines the “anchor” colors), and propagates the anchor colors. We use a diffusion-based technique for the color propagation, and added a step to suppress unwanted colors. Results on a variety of inputs demonstrate the robustness of our technique. We also extended our method to anaglyph videos by using optic flow between time frames.</p><p>3 0.1245798 <a title="327-tfidf-3" href="./cvpr-2013-Multi-resolution_Shape_Analysis_via_Non-Euclidean_Wavelets%3A_Applications_to_Mesh_Segmentation_and_Surface_Alignment_Problems.html">297 cvpr-2013-Multi-resolution Shape Analysis via Non-Euclidean Wavelets: Applications to Mesh Segmentation and Surface Alignment Problems</a></p>
<p>Author: Won Hwa Kim, Moo K. Chung, Vikas Singh</p><p>Abstract: The analysis of 3-D shape meshes is a fundamental problem in computer vision, graphics, and medical imaging. Frequently, the needs of the application require that our analysis take a multi-resolution view of the shape ’s local and global topology, and that the solution is consistent across multiple scales. Unfortunately, the preferred mathematical construct which offers this behavior in classical image/signal processing, Wavelets, is no longer applicable in this general setting (data with non-uniform topology). In particular, the traditional definition does not allow writing out an expansion for graphs that do not correspond to the uniformly sampled lattice (e.g., images). In this paper, we adapt recent results in harmonic analysis, to derive NonEuclidean Wavelets based algorithms for a range of shape analysis problems in vision and medical imaging. We show how descriptors derived from the dual domain representation offer native multi-resolution behavior for characterizing local/global topology around vertices. With only minor modifications, the framework yields a method for extracting interest/key points from shapes, a surprisingly simple algorithm for 3-D shape segmentation (competitive with state of the art), and a method for surface alignment (without landmarks). We give an extensive set of comparison results on a large shape segmentation benchmark and derive a uniqueness theorem for the surface alignment problem.</p><p>4 0.12248413 <a title="327-tfidf-4" href="./cvpr-2013-Multi-scale_Curve_Detection_on_Surfaces.html">298 cvpr-2013-Multi-scale Curve Detection on Surfaces</a></p>
<p>Author: Michael Kolomenkin, Ilan Shimshoni, Ayellet Tal</p><p>Abstract: This paper extends to surfaces the multi-scale approach of edge detection on images. The common practice for detecting curves on surfaces requires the user to first select the scale of the features, apply an appropriate smoothing, and detect the edges on the smoothed surface. This approach suffers from two drawbacks. First, it relies on a hidden assumption that all the features on the surface are of the same scale. Second, manual user intervention is required. In this paper, we propose a general framework for automatically detecting the optimal scale for each point on the surface. We smooth the surface at each point according to this optimal scale and run the curve detection algorithm on the resulting surface. Our multi-scale algorithm solves the two disadvantages of the single-scale approach mentioned above. We demonstrate how to realize our approach on two commonly-used special cases: ridges & valleys and relief edges. In each case, the optimal scale is found in accordance with the mathematical definition of the curve.</p><p>5 0.11190238 <a title="327-tfidf-5" href="./cvpr-2013-Incorporating_User_Interaction_and_Topological_Constraints_within_Contour_Completion_via_Discrete_Calculus.html">222 cvpr-2013-Incorporating User Interaction and Topological Constraints within Contour Completion via Discrete Calculus</a></p>
<p>Author: Jia Xu, Maxwell D. Collins, Vikas Singh</p><p>Abstract: We study the problem of interactive segmentation and contour completion for multiple objects. The form of constraints our model incorporates are those coming from user scribbles (interior or exterior constraints) as well as information regarding the topology of the 2-D space after partitioning (number of closed contours desired). We discuss how concepts from discrete calculus and a simple identity using the Euler characteristic of a planar graph can be utilized to derive a practical algorithm for this problem. We also present specialized branch and bound methods for the case of single contour completion under such constraints. On an extensive dataset of ∼ 1000 images, our experimOenn tasn suggest vthea dt a assmetal ol fa m∼ou 1n0t0 of ismidaeg knowledge can give strong improvements over fully unsupervised contour completion methods. We show that by interpreting user indications topologically, user effort is substantially reduced.</p><p>6 0.098439321 <a title="327-tfidf-6" href="./cvpr-2013-Intrinsic_Characterization_of_Dynamic_Surfaces.html">226 cvpr-2013-Intrinsic Characterization of Dynamic Surfaces</a></p>
<p>7 0.089867167 <a title="327-tfidf-7" href="./cvpr-2013-Three-Dimensional_Bilateral_Symmetry_Plane_Estimation_in_the_Phase_Domain.html">432 cvpr-2013-Three-Dimensional Bilateral Symmetry Plane Estimation in the Phase Domain</a></p>
<p>8 0.084332675 <a title="327-tfidf-8" href="./cvpr-2013-HON4D%3A_Histogram_of_Oriented_4D_Normals_for_Activity_Recognition_from_Depth_Sequences.html">196 cvpr-2013-HON4D: Histogram of Oriented 4D Normals for Activity Recognition from Depth Sequences</a></p>
<p>9 0.084177233 <a title="327-tfidf-9" href="./cvpr-2013-Hyperbolic_Harmonic_Mapping_for_Constrained_Brain_Surface_Registration.html">208 cvpr-2013-Hyperbolic Harmonic Mapping for Constrained Brain Surface Registration</a></p>
<p>10 0.082343034 <a title="327-tfidf-10" href="./cvpr-2013-Optical_Flow_Estimation_Using_Laplacian_Mesh_Energy.html">316 cvpr-2013-Optical Flow Estimation Using Laplacian Mesh Energy</a></p>
<p>11 0.080016434 <a title="327-tfidf-11" href="./cvpr-2013-Correspondence-Less_Non-rigid_Registration_of_Triangular_Surface_Meshes.html">97 cvpr-2013-Correspondence-Less Non-rigid Registration of Triangular Surface Meshes</a></p>
<p>12 0.07972493 <a title="327-tfidf-12" href="./cvpr-2013-Improving_Image_Matting_Using_Comprehensive_Sampling_Sets.html">216 cvpr-2013-Improving Image Matting Using Comprehensive Sampling Sets</a></p>
<p>13 0.078446023 <a title="327-tfidf-13" href="./cvpr-2013-Reconstructing_Loopy_Curvilinear_Structures_Using_Integer_Programming.html">350 cvpr-2013-Reconstructing Loopy Curvilinear Structures Using Integer Programming</a></p>
<p>14 0.067151561 <a title="327-tfidf-14" href="./cvpr-2013-Unsupervised_Joint_Object_Discovery_and_Segmentation_in_Internet_Images.html">450 cvpr-2013-Unsupervised Joint Object Discovery and Segmentation in Internet Images</a></p>
<p>15 0.061387151 <a title="327-tfidf-15" href="./cvpr-2013-Template-Based_Isometric_Deformable_3D_Reconstruction_with_Sampling-Based_Focal_Length_Self-Calibration.html">423 cvpr-2013-Template-Based Isometric Deformable 3D Reconstruction with Sampling-Based Focal Length Self-Calibration</a></p>
<p>16 0.061288256 <a title="327-tfidf-16" href="./cvpr-2013-Joint_Detection%2C_Tracking_and_Mapping_by_Semantic_Bundle_Adjustment.html">231 cvpr-2013-Joint Detection, Tracking and Mapping by Semantic Bundle Adjustment</a></p>
<p>17 0.060998838 <a title="327-tfidf-17" href="./cvpr-2013-Ensemble_Video_Object_Cut_in_Highly_Dynamic_Scenes.html">148 cvpr-2013-Ensemble Video Object Cut in Highly Dynamic Scenes</a></p>
<p>18 0.059433494 <a title="327-tfidf-18" href="./cvpr-2013-Discriminative_Color_Descriptors.html">130 cvpr-2013-Discriminative Color Descriptors</a></p>
<p>19 0.056989767 <a title="327-tfidf-19" href="./cvpr-2013-Joint_Spectral_Correspondence_for_Disparate_Image_Matching.html">234 cvpr-2013-Joint Spectral Correspondence for Disparate Image Matching</a></p>
<p>20 0.0567054 <a title="327-tfidf-20" href="./cvpr-2013-Efficient_Computation_of_Shortest_Path-Concavity_for_3D_Meshes.html">141 cvpr-2013-Efficient Computation of Shortest Path-Concavity for 3D Meshes</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.16), (1, 0.052), (2, 0.022), (3, 0.031), (4, 0.034), (5, -0.047), (6, -0.041), (7, -0.01), (8, -0.032), (9, -0.023), (10, 0.023), (11, -0.041), (12, -0.027), (13, -0.045), (14, 0.049), (15, -0.089), (16, 0.025), (17, -0.04), (18, 0.075), (19, 0.061), (20, -0.055), (21, 0.063), (22, 0.015), (23, -0.023), (24, -0.132), (25, -0.025), (26, 0.144), (27, 0.064), (28, -0.061), (29, 0.005), (30, 0.089), (31, 0.092), (32, 0.026), (33, 0.044), (34, 0.046), (35, 0.003), (36, 0.006), (37, -0.059), (38, -0.003), (39, 0.05), (40, 0.032), (41, -0.018), (42, 0.05), (43, 0.092), (44, -0.052), (45, 0.0), (46, 0.049), (47, 0.044), (48, 0.065), (49, -0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93466032 <a title="327-lsi-1" href="./cvpr-2013-Pattern-Driven_Colorization_of_3D_Surfaces.html">327 cvpr-2013-Pattern-Driven Colorization of 3D Surfaces</a></p>
<p>Author: George Leifman, Ayellet Tal</p><p>Abstract: Colorization refers to the process of adding color to black & white images or videos. This paper extends the term to handle surfaces in three dimensions. This is important for applications in which the colors of an object need to be restored and no relevant image exists for texturing it. We focus on surfaces with patterns and propose a novel algorithm for adding colors to these surfaces. The user needs only to scribble a few color strokes on one instance of each pattern, and the system proceeds to automatically colorize the whole surface. For this scheme to work, we address not only the problem of colorization, but also the problem of pattern detection on surfaces.</p><p>2 0.76336592 <a title="327-lsi-2" href="./cvpr-2013-Multi-scale_Curve_Detection_on_Surfaces.html">298 cvpr-2013-Multi-scale Curve Detection on Surfaces</a></p>
<p>Author: Michael Kolomenkin, Ilan Shimshoni, Ayellet Tal</p><p>Abstract: This paper extends to surfaces the multi-scale approach of edge detection on images. The common practice for detecting curves on surfaces requires the user to first select the scale of the features, apply an appropriate smoothing, and detect the edges on the smoothed surface. This approach suffers from two drawbacks. First, it relies on a hidden assumption that all the features on the surface are of the same scale. Second, manual user intervention is required. In this paper, we propose a general framework for automatically detecting the optimal scale for each point on the surface. We smooth the surface at each point according to this optimal scale and run the curve detection algorithm on the resulting surface. Our multi-scale algorithm solves the two disadvantages of the single-scale approach mentioned above. We demonstrate how to realize our approach on two commonly-used special cases: ridges & valleys and relief edges. In each case, the optimal scale is found in accordance with the mathematical definition of the curve.</p><p>3 0.72306931 <a title="327-lsi-3" href="./cvpr-2013-Multi-resolution_Shape_Analysis_via_Non-Euclidean_Wavelets%3A_Applications_to_Mesh_Segmentation_and_Surface_Alignment_Problems.html">297 cvpr-2013-Multi-resolution Shape Analysis via Non-Euclidean Wavelets: Applications to Mesh Segmentation and Surface Alignment Problems</a></p>
<p>Author: Won Hwa Kim, Moo K. Chung, Vikas Singh</p><p>Abstract: The analysis of 3-D shape meshes is a fundamental problem in computer vision, graphics, and medical imaging. Frequently, the needs of the application require that our analysis take a multi-resolution view of the shape ’s local and global topology, and that the solution is consistent across multiple scales. Unfortunately, the preferred mathematical construct which offers this behavior in classical image/signal processing, Wavelets, is no longer applicable in this general setting (data with non-uniform topology). In particular, the traditional definition does not allow writing out an expansion for graphs that do not correspond to the uniformly sampled lattice (e.g., images). In this paper, we adapt recent results in harmonic analysis, to derive NonEuclidean Wavelets based algorithms for a range of shape analysis problems in vision and medical imaging. We show how descriptors derived from the dual domain representation offer native multi-resolution behavior for characterizing local/global topology around vertices. With only minor modifications, the framework yields a method for extracting interest/key points from shapes, a surprisingly simple algorithm for 3-D shape segmentation (competitive with state of the art), and a method for surface alignment (without landmarks). We give an extensive set of comparison results on a large shape segmentation benchmark and derive a uniqueness theorem for the surface alignment problem.</p><p>4 0.70450902 <a title="327-lsi-4" href="./cvpr-2013-Efficient_Computation_of_Shortest_Path-Concavity_for_3D_Meshes.html">141 cvpr-2013-Efficient Computation of Shortest Path-Concavity for 3D Meshes</a></p>
<p>Author: Henrik Zimmer, Marcel Campen, Leif Kobbelt</p><p>Abstract: In the context of shape segmentation and retrieval object-wide distributions of measures are needed to accurately evaluate and compare local regions ofshapes. Lien et al. [16] proposed two point-wise concavity measures in the context of Approximate Convex Decompositions of polygons measuring the distance from a point to the polygon ’s convex hull: an accurate Shortest Path-Concavity (SPC) measure and a Straight Line-Concavity (SLC) approximation of the same. While both are practicable on 2D shapes, the exponential costs of SPC in 3D makes it inhibitively expensive for a generalization to meshes [14]. In this paper we propose an efficient and straight forward approximation of the Shortest Path-Concavity measure to 3D meshes. Our approximation is based on discretizing the space between mesh and convex hull, thereby reducing the continuous Shortest Path search to an efficiently solvable graph problem. Our approach works outof-the-box on complex mesh topologies and requires no complicated handling of genus. Besides presenting a rigorous evaluation of our method on a variety of input meshes, we also define an SPC-based Shape Descriptor and show its superior retrieval and runtime performance compared with the recently presented results on the Convexity Distribution by Lian et al. [12].</p><p>5 0.69696653 <a title="327-lsi-5" href="./cvpr-2013-Hyperbolic_Harmonic_Mapping_for_Constrained_Brain_Surface_Registration.html">208 cvpr-2013-Hyperbolic Harmonic Mapping for Constrained Brain Surface Registration</a></p>
<p>Author: Rui Shi, Wei Zeng, Zhengyu Su, Hanna Damasio, Zhonglin Lu, Yalin Wang, Shing-Tung Yau, Xianfeng Gu</p><p>Abstract: Automatic computation of surface correspondence via harmonic map is an active research field in computer vision, computer graphics and computational geometry. It may help document and understand physical and biological phenomena and also has broad applications in biometrics, medical imaging and motion capture. Although numerous studies have been devoted to harmonic map research, limited progress has been made to compute a diffeomorphic harmonic map on general topology surfaces with landmark constraints. This work conquer this problem by changing the Riemannian metric on the target surface to a hyperbolic metric, so that the harmonic mapping is guaranteed to be a diffeomorphism under landmark constraints. The computational algorithms are based on the Ricci flow method and the method is general and robust. We apply our algorithm to study constrained human brain surface registration problem. Experimental results demonstrate that, by changing the Riemannian metric, the registrations are always diffeomorphic, and achieve relative high performance when evaluated with some popular cortical surface registration evaluation standards.</p><p>6 0.67167324 <a title="327-lsi-6" href="./cvpr-2013-Area_Preserving_Brain_Mapping.html">44 cvpr-2013-Area Preserving Brain Mapping</a></p>
<p>7 0.66557115 <a title="327-lsi-7" href="./cvpr-2013-Intrinsic_Characterization_of_Dynamic_Surfaces.html">226 cvpr-2013-Intrinsic Characterization of Dynamic Surfaces</a></p>
<p>8 0.63214481 <a title="327-lsi-8" href="./cvpr-2013-Towards_Contactless%2C_Low-Cost_and_Accurate_3D_Fingerprint_Identification.html">435 cvpr-2013-Towards Contactless, Low-Cost and Accurate 3D Fingerprint Identification</a></p>
<p>9 0.61136413 <a title="327-lsi-9" href="./cvpr-2013-Correspondence-Less_Non-rigid_Registration_of_Triangular_Surface_Meshes.html">97 cvpr-2013-Correspondence-Less Non-rigid Registration of Triangular Surface Meshes</a></p>
<p>10 0.58867192 <a title="327-lsi-10" href="./cvpr-2013-Keypoints_from_Symmetries_by_Wave_Propagation.html">240 cvpr-2013-Keypoints from Symmetries by Wave Propagation</a></p>
<p>11 0.58644915 <a title="327-lsi-11" href="./cvpr-2013-A_Non-parametric_Framework_for_Document_Bleed-through_Removal.html">22 cvpr-2013-A Non-parametric Framework for Document Bleed-through Removal</a></p>
<p>12 0.58169276 <a title="327-lsi-12" href="./cvpr-2013-Sensing_and_Recognizing_Surface_Textures_Using_a_GelSight_Sensor.html">391 cvpr-2013-Sensing and Recognizing Surface Textures Using a GelSight Sensor</a></p>
<p>13 0.56877244 <a title="327-lsi-13" href="./cvpr-2013-Axially_Symmetric_3D_Pots_Configuration_System_Using_Axis_of_Symmetry_and_Break_Curve.html">52 cvpr-2013-Axially Symmetric 3D Pots Configuration System Using Axis of Symmetry and Break Curve</a></p>
<p>14 0.55569685 <a title="327-lsi-14" href="./cvpr-2013-Learning_the_Change_for_Automatic_Image_Cropping.html">263 cvpr-2013-Learning the Change for Automatic Image Cropping</a></p>
<p>15 0.55340093 <a title="327-lsi-15" href="./cvpr-2013-Monocular_Template-Based_3D_Reconstruction_of_Extensible_Surfaces_with_Local_Linear_Elasticity.html">289 cvpr-2013-Monocular Template-Based 3D Reconstruction of Extensible Surfaces with Local Linear Elasticity</a></p>
<p>16 0.53855085 <a title="327-lsi-16" href="./cvpr-2013-Three-Dimensional_Bilateral_Symmetry_Plane_Estimation_in_the_Phase_Domain.html">432 cvpr-2013-Three-Dimensional Bilateral Symmetry Plane Estimation in the Phase Domain</a></p>
<p>17 0.53612685 <a title="327-lsi-17" href="./cvpr-2013-Improving_Image_Matting_Using_Comprehensive_Sampling_Sets.html">216 cvpr-2013-Improving Image Matting Using Comprehensive Sampling Sets</a></p>
<p>18 0.53483856 <a title="327-lsi-18" href="./cvpr-2013-The_Generalized_Laplacian_Distance_and_Its_Applications_for_Visual_Matching.html">429 cvpr-2013-The Generalized Laplacian Distance and Its Applications for Visual Matching</a></p>
<p>19 0.52775925 <a title="327-lsi-19" href="./cvpr-2013-Recovering_Stereo_Pairs_from_Anaglyphs.html">352 cvpr-2013-Recovering Stereo Pairs from Anaglyphs</a></p>
<p>20 0.52307671 <a title="327-lsi-20" href="./cvpr-2013-Optical_Flow_Estimation_Using_Laplacian_Mesh_Energy.html">316 cvpr-2013-Optical Flow Estimation Using Laplacian Mesh Energy</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.125), (16, 0.031), (26, 0.029), (28, 0.022), (33, 0.232), (59, 0.018), (67, 0.052), (69, 0.071), (82, 0.253), (87, 0.076)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.79702747 <a title="327-lda-1" href="./cvpr-2013-Pattern-Driven_Colorization_of_3D_Surfaces.html">327 cvpr-2013-Pattern-Driven Colorization of 3D Surfaces</a></p>
<p>Author: George Leifman, Ayellet Tal</p><p>Abstract: Colorization refers to the process of adding color to black & white images or videos. This paper extends the term to handle surfaces in three dimensions. This is important for applications in which the colors of an object need to be restored and no relevant image exists for texturing it. We focus on surfaces with patterns and propose a novel algorithm for adding colors to these surfaces. The user needs only to scribble a few color strokes on one instance of each pattern, and the system proceeds to automatically colorize the whole surface. For this scheme to work, we address not only the problem of colorization, but also the problem of pattern detection on surfaces.</p><p>2 0.76655072 <a title="327-lda-2" href="./cvpr-2013-Label_Propagation_from_ImageNet_to_3D_Point_Clouds.html">242 cvpr-2013-Label Propagation from ImageNet to 3D Point Clouds</a></p>
<p>Author: Yan Wang, Rongrong Ji, Shih-Fu Chang</p><p>Abstract: Recent years have witnessed a growing interest in understanding the semantics of point clouds in a wide variety of applications. However, point cloud labeling remains an open problem, due to the difficulty in acquiring sufficient 3D point labels towards training effective classifiers. In this paper, we overcome this challenge by utilizing the existing massive 2D semantic labeled datasets from decadelong community efforts, such as ImageNet and LabelMe, and a novel “cross-domain ” label propagation approach. Our proposed method consists of two major novel components, Exemplar SVM based label propagation, which effectively addresses the cross-domain issue, and a graphical model based contextual refinement incorporating 3D constraints. Most importantly, the entire process does not require any training data from the target scenes, also with good scalability towards large scale applications. We evaluate our approach on the well-known Cornell Point Cloud Dataset, achieving much greater efficiency and comparable accuracy even without any 3D training data. Our approach shows further major gains in accuracy when the training data from the target scenes is used, outperforming state-ofthe-art approaches with far better efficiency.</p><p>3 0.74985862 <a title="327-lda-3" href="./cvpr-2013-Adding_Unlabeled_Samples_to_Categories_by_Learned_Attributes.html">36 cvpr-2013-Adding Unlabeled Samples to Categories by Learned Attributes</a></p>
<p>Author: Jonghyun Choi, Mohammad Rastegari, Ali Farhadi, Larry S. Davis</p><p>Abstract: We propose a method to expand the visual coverage of training sets that consist of a small number of labeled examples using learned attributes. Our optimization formulation discovers category specific attributes as well as the images that have high confidence in terms of the attributes. In addition, we propose a method to stably capture example-specific attributes for a small sized training set. Our method adds images to a category from a large unlabeled image pool, and leads to significant improvement in category recognition accuracy evaluated on a large-scale dataset, ImageNet.</p><p>4 0.74091059 <a title="327-lda-4" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>Author: Ian Endres, Kevin J. Shih, Johnston Jiaa, Derek Hoiem</p><p>Abstract: We propose a method to learn a diverse collection of discriminative parts from object bounding box annotations. Part detectors can be trained and applied individually, which simplifies learning and extension to new features or categories. We apply the parts to object category detection, pooling part detections within bottom-up proposed regions and using a boosted classifier with proposed sigmoid weak learners for scoring. On PASCAL VOC 2010, we evaluate the part detectors ’ ability to discriminate and localize annotated keypoints. Our detection system is competitive with the best-existing systems, outperforming other HOG-based detectors on the more deformable categories.</p><p>5 0.73779142 <a title="327-lda-5" href="./cvpr-2013-Beyond_Point_Clouds%3A_Scene_Understanding_by_Reasoning_Geometry_and_Physics.html">61 cvpr-2013-Beyond Point Clouds: Scene Understanding by Reasoning Geometry and Physics</a></p>
<p>Author: Bo Zheng, Yibiao Zhao, Joey C. Yu, Katsushi Ikeuchi, Song-Chun Zhu</p><p>Abstract: In this paper, we present an approach for scene understanding by reasoning physical stability of objects from point cloud. We utilize a simple observation that, by human design, objects in static scenes should be stable with respect to gravity. This assumption is applicable to all scene categories and poses useful constraints for the plausible interpretations (parses) in scene understanding. Our method consists of two major steps: 1) geometric reasoning: recovering solid 3D volumetric primitives from defective point cloud; and 2) physical reasoning: grouping the unstable primitives to physically stable objects by optimizing the stability and the scene prior. We propose to use a novel disconnectivity graph (DG) to represent the energy landscape and use a Swendsen-Wang Cut (MCMC) method for optimization. In experiments, we demonstrate that the algorithm achieves substantially better performance for i) object segmentation, ii) 3D volumetric recovery of the scene, and iii) better parsing result for scene understanding in comparison to state-of-the-art methods in both public dataset and our own new dataset.</p><p>6 0.73745227 <a title="327-lda-6" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<p>7 0.73414344 <a title="327-lda-7" href="./cvpr-2013-Understanding_Bayesian_Rooms_Using_Composite_3D_Object_Models.html">445 cvpr-2013-Understanding Bayesian Rooms Using Composite 3D Object Models</a></p>
<p>8 0.73362577 <a title="327-lda-8" href="./cvpr-2013-Understanding_Indoor_Scenes_Using_3D_Geometric_Phrases.html">446 cvpr-2013-Understanding Indoor Scenes Using 3D Geometric Phrases</a></p>
<p>9 0.73335665 <a title="327-lda-9" href="./cvpr-2013-Integrating_Grammar_and_Segmentation_for_Human_Pose_Estimation.html">225 cvpr-2013-Integrating Grammar and Segmentation for Human Pose Estimation</a></p>
<p>10 0.73315728 <a title="327-lda-10" href="./cvpr-2013-Structure_Preserving_Object_Tracking.html">414 cvpr-2013-Structure Preserving Object Tracking</a></p>
<p>11 0.73307145 <a title="327-lda-11" href="./cvpr-2013-SLAM%2B%2B%3A_Simultaneous_Localisation_and_Mapping_at_the_Level_of_Objects.html">372 cvpr-2013-SLAM++: Simultaneous Localisation and Mapping at the Level of Objects</a></p>
<p>12 0.73302287 <a title="327-lda-12" href="./cvpr-2013-Cross-View_Action_Recognition_via_a_Continuous_Virtual_Path.html">98 cvpr-2013-Cross-View Action Recognition via a Continuous Virtual Path</a></p>
<p>13 0.73217857 <a title="327-lda-13" href="./cvpr-2013-Spatiotemporal_Deformable_Part_Models_for_Action_Detection.html">408 cvpr-2013-Spatiotemporal Deformable Part Models for Action Detection</a></p>
<p>14 0.73211986 <a title="327-lda-14" href="./cvpr-2013-A_Minimum_Error_Vanishing_Point_Detection_Approach_for_Uncalibrated_Monocular_Images_of_Man-Made_Environments.html">19 cvpr-2013-A Minimum Error Vanishing Point Detection Approach for Uncalibrated Monocular Images of Man-Made Environments</a></p>
<p>15 0.73158681 <a title="327-lda-15" href="./cvpr-2013-Bottom-Up_Segmentation_for_Top-Down_Detection.html">70 cvpr-2013-Bottom-Up Segmentation for Top-Down Detection</a></p>
<p>16 0.73154217 <a title="327-lda-16" href="./cvpr-2013-Part_Discovery_from_Partial_Correspondence.html">325 cvpr-2013-Part Discovery from Partial Correspondence</a></p>
<p>17 0.73152524 <a title="327-lda-17" href="./cvpr-2013-Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking.html">285 cvpr-2013-Minimum Uncertainty Gap for Robust Visual Tracking</a></p>
<p>18 0.7311151 <a title="327-lda-18" href="./cvpr-2013-Physically_Plausible_3D_Scene_Tracking%3A_The_Single_Actor_Hypothesis.html">331 cvpr-2013-Physically Plausible 3D Scene Tracking: The Single Actor Hypothesis</a></p>
<p>19 0.73082536 <a title="327-lda-19" href="./cvpr-2013-Learning_Structured_Hough_Voting_for_Joint_Object_Detection_and_Occlusion_Reasoning.html">256 cvpr-2013-Learning Structured Hough Voting for Joint Object Detection and Occlusion Reasoning</a></p>
<p>20 0.7307595 <a title="327-lda-20" href="./cvpr-2013-CLAM%3A_Coupled_Localization_and_Mapping_with_Efficient_Outlier_Handling.html">74 cvpr-2013-CLAM: Coupled Localization and Mapping with Efficient Outlier Handling</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
