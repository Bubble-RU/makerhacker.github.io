<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>355 cvpr-2013-Representing Videos Using Mid-level Discriminative Patches</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-355" href="#">cvpr2013-355</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>355 cvpr-2013-Representing Videos Using Mid-level Discriminative Patches</h1>
<br/><p>Source: <a title="cvpr-2013-355-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Jain_Representing_Videos_Using_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Arpit Jain, Abhinav Gupta, Mikel Rodriguez, Larry S. Davis</p><p>Abstract: How should a video be represented? We propose a new representation for videos based on mid-level discriminative spatio-temporal patches. These spatio-temporal patches might correspond to a primitive human action, a semantic object, or perhaps a random but informative spatiotemporal patch in the video. What defines these spatiotemporal patches is their discriminative and representative properties. We automatically mine these patches from hundreds of training videos and experimentally demonstrate that these patches establish correspondence across videos and align the videos for label transfer techniques. Furthermore, these patches can be used as a discriminative vocabulary for action classification where they demonstrate stateof-the-art performance on UCF50 and Olympics datasets.</p><p>Reference: <a title="cvpr-2013-355-reference" href="../cvpr2013_reference/cvpr-2013-Representing_Videos_Using_Mid-level_Discriminative_Patches_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('patch', 0.61), ('video', 0.267), ('olymp', 0.196), ('discrimin', 0.181), ('ipfp', 0.173), ('act', 0.168), ('transf', 0.156), ('est', 0.135), ('gangnam', 0.127), ('clust', 0.106), ('align', 0.105), ('gupt', 0.099), ('vocab', 0.096), ('constitu', 0.088), ('sem', 0.088), ('hundr', 0.086), ('lary', 0.084), ('annot', 0.084), ('fir', 0.079), ('spatiotemp', 0.077)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="355-tfidf-1" href="./cvpr-2013-Representing_Videos_Using_Mid-level_Discriminative_Patches.html">355 cvpr-2013-Representing Videos Using Mid-level Discriminative Patches</a></p>
<p>2 0.33161336 <a title="355-tfidf-2" href="./cvpr-2013-Separating_Signal_from_Noise_Using_Patch_Recurrence_across_Scales.html">393 cvpr-2013-Separating Signal from Noise Using Patch Recurrence across Scales</a></p>
<p>3 0.30872378 <a title="355-tfidf-3" href="./cvpr-2013-Sampling_Strategies_for_Real-Time_Action_Recognition.html">378 cvpr-2013-Sampling Strategies for Real-Time Action Recognition</a></p>
<p>4 0.28823221 <a title="355-tfidf-4" href="./cvpr-2013-What_Makes_a_Patch_Distinct%3F.html">464 cvpr-2013-What Makes a Patch Distinct?</a></p>
<p>5 0.23307636 <a title="355-tfidf-5" href="./cvpr-2013-Joint_Sparsity-Based_Representation_and_Analysis_of_Unconstrained_Activities.html">233 cvpr-2013-Joint Sparsity-Based Representation and Analysis of Unconstrained Activities</a></p>
<p>6 0.23025136 <a title="355-tfidf-6" href="./cvpr-2013-Fast_Image_Super-Resolution_Based_on_In-Place_Example_Regression.html">166 cvpr-2013-Fast Image Super-Resolution Based on In-Place Example Regression</a></p>
<p>7 0.22243072 <a title="355-tfidf-7" href="./cvpr-2013-Ensemble_Video_Object_Cut_in_Highly_Dynamic_Scenes.html">148 cvpr-2013-Ensemble Video Object Cut in Highly Dynamic Scenes</a></p>
<p>8 0.21744278 <a title="355-tfidf-8" href="./cvpr-2013-Expanded_Parts_Model_for_Human_Attribute_and_Action_Recognition_in_Still_Images.html">153 cvpr-2013-Expanded Parts Model for Human Attribute and Action Recognition in Still Images</a></p>
<p>9 0.21559012 <a title="355-tfidf-9" href="./cvpr-2013-First-Person_Activity_Recognition%3A_What_Are_They_Doing_to_Me%3F.html">175 cvpr-2013-First-Person Activity Recognition: What Are They Doing to Me?</a></p>
<p>10 0.21484779 <a title="355-tfidf-10" href="./cvpr-2013-Semi-supervised_Learning_of_Feature_Hierarchies_for_Object_Detection_in_a_Video.html">388 cvpr-2013-Semi-supervised Learning of Feature Hierarchies for Object Detection in a Video</a></p>
<p>11 0.20632799 <a title="355-tfidf-11" href="./cvpr-2013-Multi-source_Multi-scale_Counting_in_Extremely_Dense_Crowd_Images.html">299 cvpr-2013-Multi-source Multi-scale Counting in Extremely Dense Crowd Images</a></p>
<p>12 0.20598109 <a title="355-tfidf-12" href="./cvpr-2013-Harvesting_Mid-level_Visual_Concepts_from_Large-Scale_Internet_Images.html">200 cvpr-2013-Harvesting Mid-level Visual Concepts from Large-Scale Internet Images</a></p>
<p>13 0.20353489 <a title="355-tfidf-13" href="./cvpr-2013-Unsupervised_Salience_Learning_for_Person_Re-identification.html">451 cvpr-2013-Unsupervised Salience Learning for Person Re-identification</a></p>
<p>14 0.18673582 <a title="355-tfidf-14" href="./cvpr-2013-Large-Scale_Video_Summarization_Using_Web-Image_Priors.html">243 cvpr-2013-Large-Scale Video Summarization Using Web-Image Priors</a></p>
<p>15 0.17784673 <a title="355-tfidf-15" href="./cvpr-2013-Watching_Unlabeled_Video_Helps_Learn_New_Human_Actions_from_Very_Few_Labeled_Snapshots.html">459 cvpr-2013-Watching Unlabeled Video Helps Learn New Human Actions from Very Few Labeled Snapshots</a></p>
<p>16 0.17161845 <a title="355-tfidf-16" href="./cvpr-2013-An_Approach_to_Pose-Based_Action_Recognition.html">40 cvpr-2013-An Approach to Pose-Based Action Recognition</a></p>
<p>17 0.16753669 <a title="355-tfidf-17" href="./cvpr-2013-Looking_Beyond_the_Image%3A_Unsupervised_Learning_for_Object_Saliency_and_Detection.html">273 cvpr-2013-Looking Beyond the Image: Unsupervised Learning for Object Saliency and Detection</a></p>
<p>18 0.16582642 <a title="355-tfidf-18" href="./cvpr-2013-Part_Discovery_from_Partial_Correspondence.html">325 cvpr-2013-Part Discovery from Partial Correspondence</a></p>
<p>19 0.1634891 <a title="355-tfidf-19" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>20 0.16257186 <a title="355-tfidf-20" href="./cvpr-2013-Geometric_Context_from_Videos.html">187 cvpr-2013-Geometric Context from Videos</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.333), (1, 0.07), (2, 0.124), (3, 0.032), (4, 0.053), (5, 0.044), (6, 0.043), (7, -0.027), (8, 0.042), (9, -0.123), (10, -0.158), (11, -0.139), (12, 0.219), (13, 0.124), (14, 0.109), (15, 0.027), (16, 0.131), (17, -0.127), (18, -0.048), (19, 0.139), (20, 0.142), (21, -0.131), (22, 0.218), (23, -0.055), (24, 0.026), (25, 0.038), (26, 0.028), (27, 0.116), (28, -0.039), (29, 0.096), (30, -0.006), (31, 0.112), (32, 0.046), (33, 0.098), (34, -0.098), (35, 0.002), (36, 0.021), (37, -0.125), (38, 0.054), (39, -0.038), (40, 0.101), (41, 0.068), (42, 0.031), (43, 0.019), (44, 0.044), (45, -0.004), (46, 0.004), (47, -0.064), (48, 0.055), (49, 0.049)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96772587 <a title="355-lsi-1" href="./cvpr-2013-Representing_Videos_Using_Mid-level_Discriminative_Patches.html">355 cvpr-2013-Representing Videos Using Mid-level Discriminative Patches</a></p>
<p>2 0.81807888 <a title="355-lsi-2" href="./cvpr-2013-Separating_Signal_from_Noise_Using_Patch_Recurrence_across_Scales.html">393 cvpr-2013-Separating Signal from Noise Using Patch Recurrence across Scales</a></p>
<p>3 0.77196544 <a title="355-lsi-3" href="./cvpr-2013-Sampling_Strategies_for_Real-Time_Action_Recognition.html">378 cvpr-2013-Sampling Strategies for Real-Time Action Recognition</a></p>
<p>4 0.76886004 <a title="355-lsi-4" href="./cvpr-2013-Fast_Image_Super-Resolution_Based_on_In-Place_Example_Regression.html">166 cvpr-2013-Fast Image Super-Resolution Based on In-Place Example Regression</a></p>
<p>5 0.75039601 <a title="355-lsi-5" href="./cvpr-2013-Sparse_Quantization_for_Patch_Description.html">404 cvpr-2013-Sparse Quantization for Patch Description</a></p>
<p>6 0.71309572 <a title="355-lsi-6" href="./cvpr-2013-What_Makes_a_Patch_Distinct%3F.html">464 cvpr-2013-What Makes a Patch Distinct?</a></p>
<p>7 0.71123791 <a title="355-lsi-7" href="./cvpr-2013-Fast_Patch-Based_Denoising_Using_Approximated_Patch_Geodesic_Paths.html">169 cvpr-2013-Fast Patch-Based Denoising Using Approximated Patch Geodesic Paths</a></p>
<p>8 0.65778321 <a title="355-lsi-8" href="./cvpr-2013-Harvesting_Mid-level_Visual_Concepts_from_Large-Scale_Internet_Images.html">200 cvpr-2013-Harvesting Mid-level Visual Concepts from Large-Scale Internet Images</a></p>
<p>9 0.64246285 <a title="355-lsi-9" href="./cvpr-2013-Learning_without_Human_Scores_for_Blind_Image_Quality_Assessment.html">266 cvpr-2013-Learning without Human Scores for Blind Image Quality Assessment</a></p>
<p>10 0.61911631 <a title="355-lsi-10" href="./cvpr-2013-Unsupervised_Salience_Learning_for_Person_Re-identification.html">451 cvpr-2013-Unsupervised Salience Learning for Person Re-identification</a></p>
<p>11 0.61131138 <a title="355-lsi-11" href="./cvpr-2013-Expanded_Parts_Model_for_Human_Attribute_and_Action_Recognition_in_Still_Images.html">153 cvpr-2013-Expanded Parts Model for Human Attribute and Action Recognition in Still Images</a></p>
<p>12 0.60593557 <a title="355-lsi-12" href="./cvpr-2013-First-Person_Activity_Recognition%3A_What_Are_They_Doing_to_Me%3F.html">175 cvpr-2013-First-Person Activity Recognition: What Are They Doing to Me?</a></p>
<p>13 0.6005193 <a title="355-lsi-13" href="./cvpr-2013-Motionlets%3A_Mid-level_3D_Parts_for_Human_Motion_Recognition.html">291 cvpr-2013-Motionlets: Mid-level 3D Parts for Human Motion Recognition</a></p>
<p>14 0.59951216 <a title="355-lsi-14" href="./cvpr-2013-Supervised_Kernel_Descriptors_for_Visual_Recognition.html">421 cvpr-2013-Supervised Kernel Descriptors for Visual Recognition</a></p>
<p>15 0.59893566 <a title="355-lsi-15" href="./cvpr-2013-Joint_Sparsity-Based_Representation_and_Analysis_of_Unconstrained_Activities.html">233 cvpr-2013-Joint Sparsity-Based Representation and Analysis of Unconstrained Activities</a></p>
<p>16 0.58421659 <a title="355-lsi-16" href="./cvpr-2013-Recognize_Human_Activities_from_Partially_Observed_Videos.html">347 cvpr-2013-Recognize Human Activities from Partially Observed Videos</a></p>
<p>17 0.57537568 <a title="355-lsi-17" href="./cvpr-2013-A_Thousand_Frames_in_Just_a_Few_Words%3A_Lingual_Description_of_Videos_through_Latent_Topics_and_Sparse_Object_Stitching.html">28 cvpr-2013-A Thousand Frames in Just a Few Words: Lingual Description of Videos through Latent Topics and Sparse Object Stitching</a></p>
<p>18 0.57404083 <a title="355-lsi-18" href="./cvpr-2013-3D_R_Transform_on_Spatio-temporal_Interest_Points_for_Action_Recognition.html">3 cvpr-2013-3D R Transform on Spatio-temporal Interest Points for Action Recognition</a></p>
<p>19 0.57384014 <a title="355-lsi-19" href="./cvpr-2013-Spatiotemporal_Deformable_Part_Models_for_Action_Detection.html">408 cvpr-2013-Spatiotemporal Deformable Part Models for Action Detection</a></p>
<p>20 0.57071733 <a title="355-lsi-20" href="./cvpr-2013-Ensemble_Video_Object_Cut_in_Highly_Dynamic_Scenes.html">148 cvpr-2013-Ensemble Video Object Cut in Highly Dynamic Scenes</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.037), (4, 0.095), (5, 0.61), (37, 0.068), (81, 0.03), (86, 0.027), (95, 0.011), (97, 0.044)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99770224 <a title="355-lda-1" href="./cvpr-2013-Representing_Videos_Using_Mid-level_Discriminative_Patches.html">355 cvpr-2013-Representing Videos Using Mid-level Discriminative Patches</a></p>
<p>2 0.9973287 <a title="355-lda-2" href="./cvpr-2013-Context-Aware_Modeling_and_Recognition_of_Activities_in_Video.html">94 cvpr-2013-Context-Aware Modeling and Recognition of Activities in Video</a></p>
<p>3 0.99520081 <a title="355-lda-3" href="./cvpr-2013-Pixel-Level_Hand_Detection_in_Ego-centric_Videos.html">332 cvpr-2013-Pixel-Level Hand Detection in Ego-centric Videos</a></p>
<p>4 0.99386615 <a title="355-lda-4" href="./cvpr-2013-Blocks_That_Shout%3A_Distinctive_Parts_for_Scene_Classification.html">67 cvpr-2013-Blocks That Shout: Distinctive Parts for Scene Classification</a></p>
<p>5 0.99169308 <a title="355-lda-5" href="./cvpr-2013-Generalized_Domain-Adaptive_Dictionaries.html">185 cvpr-2013-Generalized Domain-Adaptive Dictionaries</a></p>
<p>6 0.99047434 <a title="355-lda-6" href="./cvpr-2013-GRASP_Recurring_Patterns_from_a_Single_View.html">183 cvpr-2013-GRASP Recurring Patterns from a Single View</a></p>
<p>7 0.98522323 <a title="355-lda-7" href="./cvpr-2013-Optimized_Product_Quantization_for_Approximate_Nearest_Neighbor_Search.html">319 cvpr-2013-Optimized Product Quantization for Approximate Nearest Neighbor Search</a></p>
<p>8 0.97959697 <a title="355-lda-8" href="./cvpr-2013-Statistical_Textural_Distinctiveness_for_Salient_Region_Detection_in_Natural_Images.html">411 cvpr-2013-Statistical Textural Distinctiveness for Salient Region Detection in Natural Images</a></p>
<p>9 0.97689688 <a title="355-lda-9" href="./cvpr-2013-Joint_3D_Scene_Reconstruction_and_Class_Segmentation.html">230 cvpr-2013-Joint 3D Scene Reconstruction and Class Segmentation</a></p>
<p>10 0.96713686 <a title="355-lda-10" href="./cvpr-2013-Multi-task_Sparse_Learning_with_Beta_Process_Prior_for_Action_Recognition.html">302 cvpr-2013-Multi-task Sparse Learning with Beta Process Prior for Action Recognition</a></p>
<p>11 0.96173656 <a title="355-lda-11" href="./cvpr-2013-Topical_Video_Object_Discovery_from_Key_Frames_by_Modeling_Word_Co-occurrence_Prior.html">434 cvpr-2013-Topical Video Object Discovery from Key Frames by Modeling Word Co-occurrence Prior</a></p>
<p>12 0.95977795 <a title="355-lda-12" href="./cvpr-2013-Spatiotemporal_Deformable_Part_Models_for_Action_Detection.html">408 cvpr-2013-Spatiotemporal Deformable Part Models for Action Detection</a></p>
<p>13 0.95827895 <a title="355-lda-13" href="./cvpr-2013-Joint_Sparsity-Based_Representation_and_Analysis_of_Unconstrained_Activities.html">233 cvpr-2013-Joint Sparsity-Based Representation and Analysis of Unconstrained Activities</a></p>
<p>14 0.9580428 <a title="355-lda-14" href="./cvpr-2013-First-Person_Activity_Recognition%3A_What_Are_They_Doing_to_Me%3F.html">175 cvpr-2013-First-Person Activity Recognition: What Are They Doing to Me?</a></p>
<p>15 0.95768476 <a title="355-lda-15" href="./cvpr-2013-Event_Recognition_in_Videos_by_Learning_from_Heterogeneous_Web_Sources.html">150 cvpr-2013-Event Recognition in Videos by Learning from Heterogeneous Web Sources</a></p>
<p>16 0.95497668 <a title="355-lda-16" href="./cvpr-2013-Histograms_of_Sparse_Codes_for_Object_Detection.html">204 cvpr-2013-Histograms of Sparse Codes for Object Detection</a></p>
<p>17 0.9547323 <a title="355-lda-17" href="./cvpr-2013-Subspace_Interpolation_via_Dictionary_Learning_for_Unsupervised_Domain_Adaptation.html">419 cvpr-2013-Subspace Interpolation via Dictionary Learning for Unsupervised Domain Adaptation</a></p>
<p>18 0.95247203 <a title="355-lda-18" href="./cvpr-2013-Leveraging_Structure_from_Motion_to_Learn_Discriminative_Codebooks_for_Scalable_Landmark_Classification.html">268 cvpr-2013-Leveraging Structure from Motion to Learn Discriminative Codebooks for Scalable Landmark Classification</a></p>
<p>19 0.94907993 <a title="355-lda-19" href="./cvpr-2013-Recognize_Human_Activities_from_Partially_Observed_Videos.html">347 cvpr-2013-Recognize Human Activities from Partially Observed Videos</a></p>
<p>20 0.94906843 <a title="355-lda-20" href="./cvpr-2013-HON4D%3A_Histogram_of_Oriented_4D_Normals_for_Activity_Recognition_from_Depth_Sequences.html">196 cvpr-2013-HON4D: Histogram of Oriented 4D Normals for Activity Recognition from Depth Sequences</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
