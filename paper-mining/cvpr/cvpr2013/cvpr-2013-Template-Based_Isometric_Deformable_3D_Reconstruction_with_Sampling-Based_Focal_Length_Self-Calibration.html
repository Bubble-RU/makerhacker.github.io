<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>423 cvpr-2013-Template-Based Isometric Deformable 3D Reconstruction with Sampling-Based Focal Length Self-Calibration</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-423" href="#">cvpr2013-423</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>423 cvpr-2013-Template-Based Isometric Deformable 3D Reconstruction with Sampling-Based Focal Length Self-Calibration</h1>
<br/><p>Source: <a title="cvpr-2013-423-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Bartoli_Template-Based_Isometric_Deformable_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Adrien Bartoli, Toby Collins</p><p>Abstract: It has been shown that a surface deforming isometrically can be reconstructed from a single image and a template 3D shape. Methods from the literature solve this problem efficiently. However, they all assume that the camera model is calibrated, which drastically limits their applicability. We propose (i) a general variational framework that applies to (calibrated and uncalibrated) general camera models and (ii) self-calibrating 3D reconstruction algorithms for the weak-perspective and full-perspective camera models. In the former case, our algorithm returns the normal field and camera ’s scale factor. In the latter case, our algorithm returns the normal field, depth and camera ’s focal length. Our algorithms are the first to achieve deformable 3D reconstruction including camera self-calibration. They apply to much more general setups than existing methods. Experimental results on simulated and real data show that our algorithms give results with the same level of accuracy as existing methods (which use the true focal length) on perspective images, and correctly find the normal field on affine images for which the existing methods fail.</p><p>Reference: <a title="cvpr-2013-423-reference" href="../cvpr2013_reference/cvpr-2013-Template-Based_Isometric_Deformable_3D_Reconstruction_with_Sampling-Based_Focal_Length_Self-Calibration_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 We propose (i) a general variational framework that applies to (calibrated and uncalibrated) general camera models and (ii) self-calibrating 3D reconstruction algorithms for the weak-perspective and full-perspective camera models. [sent-4, score-0.666]
</p><p>2 In the former case, our algorithm returns the normal field and camera ’s scale factor. [sent-5, score-0.367]
</p><p>3 In the latter case, our algorithm returns the normal field, depth and camera ’s focal length. [sent-6, score-0.938]
</p><p>4 Our algorithms are the first to achieve deformable 3D reconstruction including camera self-calibration. [sent-7, score-0.369]
</p><p>5 Experimental results on simulated and real data show that our algorithms give results with the same level of accuracy as existing methods (which use the true focal length) on perspective images, and correctly find the normal field on affine images for which the existing methods fail. [sent-9, score-0.906]
</p><p>6 Introduction The problem of 3D reconstruction of a deformable surface from monocular video data has been well studied over the past decade. [sent-11, score-0.543]
</p><p>7 In the template-based setup in particular, where a reference 3D view of the surface is known, 3D reconstruction is carried out from 3D to 2D correspondences established between the template and an input image of the surface being deformed. [sent-12, score-0.93]
</p><p>8 While this has initially been a reasonable assumption, being able to self-calibrate the camera would grant 3D reconstruction much more flexibility. [sent-16, score-0.311]
</p><p>9 The most interesting scenario, both in terms of stability and applicability, is where all the intrinsics are known but the focal length which is also allowed to vary in time [13]. [sent-18, score-0.61]
</p><p>10 This paper proposes a comprehensive framework for  3D reconstruction from a single uncalibrated image under isometric surface deformation. [sent-20, score-0.729]
</p><p>11 In this context, most existing methods use a fully calibrated perspective camera model [1, 2, 3, 7, 8, 10, 14, 15, 16, 17] and are defeated by affine imaging conditions. [sent-21, score-0.464]
</p><p>12 The reason is that they do not fully exploit the differential surface constraints, and use the so-called maximum depth heuristic [10], consisting in maximizing the surface’s depth while bounding surface extension [2, 3, 10, 14, 15, 16]. [sent-22, score-0.996]
</p><p>13 Two exceptions are [1, 5] which use a variational framework with a perspective and an orthographic projection model respectively. [sent-23, score-0.289]
</p><p>14 In contrast, our general variational framework applies to a general camera model, whether calibrated or uncalibrated. [sent-24, score-0.398]
</p><p>15 It relates the template to input image warp to the unknown surface embedding. [sent-25, score-0.605]
</p><p>16 It leads to a general PDE for isometric 3D reconstruction with the camera’s intrinsics as free parameters. [sent-26, score-0.572]
</p><p>17 We establish that in the affine case, only the surface normal can be computed but not the absolute depth, while in the perspective case, both the surface normal, absolute depth and focal length can be estimated. [sent-27, score-1.617]
</p><p>18 It computes the surface normal and the camera’s scale factor (the ratio between the camera’s focal length and the surface’s average depth). [sent-30, score-1.062]
</p><p>19 It computes the surface normal and depth, and the camera’s focal length. [sent-32, score-0.919]
</p><p>20 Experimental results support the fact that focal length  self-calibration is feasible. [sent-34, score-0.534]
</p><p>21 n §d§ full-perspective projection respectively, aankdgive solution algorithms for 3D reconstruction including camera self-calibration. [sent-42, score-0.455]
</p><p>22 State of the Art Reconstructing a deforming surface in the templatebased setting has two main steps: input image to template registration and 3D shape inference. [sent-45, score-0.553]
</p><p>23 This paper specifically focuses on the 3D shape inference step under isometric surface deformation [1, 2, 3, 5, 10, 14, 15, 16]. [sent-47, score-0.62]
</p><p>24 The most successful relaxation [2, 14] has been the maximum depth heuristic [10] that consists in maximizing the surface’s depth under inextensibility constraints [2, 14] using Second-Order Cone Programming (SOCP). [sent-49, score-0.396]
</p><p>25 The fastest results were however obtained by solving a variational for-  mulation exploiting the differential structure of local isometry in the perspective [1] and orthographic [5] projection cases. [sent-50, score-0.422]
</p><p>26 All the previously cited methods make a fundamental assumptions: the camera model is perspective projection and its intrinsics are known (except [5] which uses orthographic projection). [sent-51, score-0.447]
</p><p>27 These methods are defeated by affine imaging conditions since they do not directly exploit the problem’s full differential structure. [sent-52, score-0.25]
</p><p>28 In the former case, our algorithm computes the scale factor and the surface normal. [sent-56, score-0.327]
</p><p>29 In the latter case, our algorithm computes the camera’s focal length, the surface normal and depth. [sent-57, score-0.953]
</p><p>30 Our method is the first to solve 3D deformable shape reconstruction while performing camera self-calibration. [sent-58, score-0.369]
</p><p>31 The unknown 3TDhe es uterfmapcela tise parameterized by an is ⊂om Retric embedding of the template, represented by the surface embedding function ϕ : Ω → R3. [sent-62, score-0.457]
</p><p>32 The camera projection function is written Πtio : Rϕ3 : Ω→ → →R 2R. [sent-63, score-0.255]
</p><p>33 tion is w→ritte Rn η : Ω → Finally, the unknown surface unit normal function is written ξ : Ω → S3. [sent-65, score-0.526]
</p><p>34 Existing reconstruction methods compute the surface embedding function ϕ assuming that the camera projection function Π is known. [sent-72, score-0.752]
</p><p>35 This implies estimating the weak-perspective camera’s scale or self-calibrating the full-perspective camera’s focal length. [sent-74, score-0.391]
</p><p>36 First, composing the surface embedding and camera projection gives the warp; this is the reprojection constraint: η  = Π  ◦ ϕ. [sent-76, score-0.721]
</p><p>37 General Isometric 3D Reconstruction We start from the differential constraint (3), and append the scaled unit surface normal λξ as the rightmost column of this matrix equality:  ? [sent-80, score-0.609]
</p><p>38 the equation is simplified, and gives the general equation of isometric n3 iDs r seicmopnlsitfrieudc,tio ann:d  JηJη? [sent-101, score-0.609]
</p><p>39 )(4) This is a nonlinear PDE in the camera projection Π, the surface embedding ϕ and its normal ξ. [sent-106, score-0.861]
</p><p>40 Because of its global and parametric nature, camera projection will turn into a set of free unknown parameters when specializing this PDE to a particular camera model. [sent-110, score-0.587]
</p><p>41 Weak-Perspective Solution We show how the general reconstruction equation (4) is specialized and solved for weak-perspective projection. [sent-112, score-0.318]
</p><p>42 Specializing the General Equation The general affine camera’s projection function is ΠA(Q) = KASAQ. [sent-115, score-0.223]
</p><p>43 Defining ξ¯ : Ω → R2, the function giving the first two elements of theξ :u Ωnit → →no Rrmal, as ξ¯ = SAξ, we get the affine equation of isometric 3D reconstruction: JηJη? [sent-125, score-0.571]
</p><p>44 For a weak-perspective camera, KA = αI where the un-  =def df  known scale α > 0 is the ratio between the camfocal length f and the surface’s average depth d. [sent-130, score-0.289]
</p><p>45 This leads to the weak-perspective equation of isometric 3D reconstruction:  era’s  JηJη? [sent-131, score-0.404]
</p><p>46 Expanding equation (6), we get the following degree-two polynomial in μ: λ4μ2  =def  −  λ2tμ  +g  = 0,  (7)  =def  with t tr ? [sent-154, score-0.237]
</p><p>47 Criteria such as surface integrability or smoothness [3] can be used (through normal integration) to recover a C1 shape up to scale while disambiguating the normal field. [sent-200, score-0.688]
</p><p>48 Full-Perspective Solution  We here show how the general reconstruction equation (4) is specialized and solved for full-perspective projection. [sent-203, score-0.318]
</p><p>49 Finally, substituting this expression in the general reconstruction equation (4) we obtain the full-perspective equation of isometric 3D reconstruction:  JηJη? [sent-228, score-0.759]
</p><p>50 We further specialize this equation under twheit assumption that only the focal length f is unknown and the effect of the other intrinsics were undone. [sent-239, score-0.832]
</p><p>51 The relationship between ξ¯ and γ is quite complex and we thus cannot directly exploit it to solve the variational equation efficiently. [sent-262, score-0.22]
</p><p>52 Indeed, γ gives the depth and with the reprojection constraint, determines function ϕ, whose first partial derivatives lead to the normal function ξ. [sent-263, score-0.461]
</p><p>53 We propose the following estimation procedure: (i) sample f over a range of admissible values, (ii) for each candidate f value, solve the equation of isometric 3D reconstruction (11) and (iii) keep the value of f which best satisfies  ×  the global isometric constraint. [sent-264, score-0.817]
</p><p>54 Note that the template camera’s focpaixl length 5i s× generally unrelated to the runtime camera’s (for instance with printed paper we use the digital texture image as a template). [sent-267, score-0.308]
</p><p>55 Wofi itthso supte lcoiassl of generality, we here assume λ = 1 (the surface is developable), but the method applies to an arbitrary local scale function λ. [sent-272, score-0.317]
</p><p>56 More specifically, there are 4 solutions for the normal ξ¯ and 2 for the depth γ. [sent-283, score-0.406]
</p><p>57 Finding the 1-dimensional affine subspace of solutions, we select the 4 solutions for ξ¯ and the 2 solutions for γ from the quadratic constraint ζ1ζ2 − ζ32 = 0. [sent-286, score-0.275]
</p><p>58 W ζe do not keep the two ambiguous solutions for the normal field but rather recompute it a posteriori from function γ. [sent-288, score-0.26]
</p><p>59 For t)hi ∈s point pair we measure the amount of surface extension or shrinking with respect to the template as:  |δ(p, p? [sent-294, score-0.451]
</p><p>60 The surface embedding function ϕ is represented as a linear interpolant of control points positionned on a regular grid. [sent-317, score-0.352]
</p><p>61 The initial solution is provided by our focal length sampling algorithm. [sent-321, score-0.589]
</p><p>62 Note that for the weak-perspective solution only the normal error is computable. [sent-327, score-0.296]
</p><p>63 We first used SIFT [6] to obtain putative keypoint correspondences from which we then estimate a Thin-Plate Spline warp η using a robust method based on spatial consistency [12]. [sent-329, score-0.265]
</p><p>64 It should be noted that these compared methods assume the focal length to be known. [sent-332, score-0.534]
</p><p>65 In the case of simulated data this is the groundtruth focal length; it the case of real data it is obtained from static calibration. [sent-333, score-0.67]
</p><p>66 STAT-PE is an iterative method using the maximum depth heuristic [10]. [sent-334, score-0.216]
</p><p>67 STAT-SA is a convex solution using the maximum depth heuristic [14]. [sent-335, score-0.271]
</p><p>68 STAT-BR is a convex SOCP solution using the maximum depth heuristic [2]. [sent-336, score-0.271]
</p><p>69 We randomly drew m points on the simulated surfaces and projected them with a perspective camera. [sent-352, score-0.237]
</p><p>70 We varied the simulated focal length (default: 400 pixels), the number of keypoint correspondences (default: 200) and the standard deviation of the gaussiandistributed correspondence noise (default: 1. [sent-354, score-0.768]
</p><p>71 We observe that SELF-FP degrades with increasing focal length and correspondence noise and improves with increasing number of correspondences. [sent-358, score-0.621]
</p><p>72 However, the f-error is kept below about 15% and is of a few percents for most simulated configurations. [sent-359, score-0.268]
</p><p>73 This is comparable with an excellent static camera calibration. [sent-361, score-0.259]
</p><p>74 As with the ferror, we observe that SELF-FP degrades with increasing focal length and correspondence noise and improves with increasing number of correspondences. [sent-364, score-0.621]
</p><p>75 It gives normal estimates which are almost always more accurate than SELF-FP’s despite the significant amount of perspective in short focal 111555 111 686  MMeet h o d s u us i n g s se l f - c a l i b r a t i o n MMeetthhooddss uussiinngg ssttaatti cc ccaalli bbrraatti oonn  Figure 2. [sent-371, score-0.691]
</p><p>76 The first column shows the result when changing the simulated focal length. [sent-375, score-0.51]
</p><p>77 Therefore, the accuracy of some methods based on the maximum depth heuristic (STAT-SA and STAT-PE) degrades significantly. [sent-377, score-0.262]
</p><p>78 The focal length and depth also become ill-constrained as only their ratio can be measured, explaining why we observe that their estimates by SELF-FP degrades. [sent-378, score-0.721]
</p><p>79 The surface normal how-  ever is still well-constrained, as can be observed from SELFFP’s normal estimates. [sent-379, score-0.688]
</p><p>80 This can be seen from equation (12): when f grows large the depth γ becomes ill-constrained but not the normal ξ. [sent-380, score-0.522]
</p><p>81 We observe that the f-error and the depth error for SELF-RE increase with the focal length but much less than for SELF-FP, while the normal error is kept to its lower bound provided by STAT-RE. [sent-381, score-1.08]
</p><p>82 These two examples respectively use a short and long focal length. [sent-392, score-0.391]
</p><p>83 We now describe the short focal length example in details. [sent-393, score-0.534]
</p><p>84 The bar-plot in figure 3 shows the true and estimated focal length as the level of zoom varies. [sent-400, score-0.618]
</p><p>85 The focal length is fixed and its groundtruth value is 528 pixels. [sent-409, score-0.601]
</p><p>86 We observe on the left graph that SELF-FP produces a depth error slightly larger that the other methods, but of the same order of magnitude. [sent-411, score-0.227]
</p><p>87 On the other hand, SELF-RE achieves a depth error comparable to methods using static calibration. [sent-412, score-0.279]
</p><p>88 The middle graph shows that both SELF-FP and SELF-RE overestimate the focal length by a few dozens of pixels. [sent-413, score-0.534]
</p><p>89 The template here is in 3D since it is non-developable (the cap cannot be isometrically flattened to a plane). [sent-420, score-0.419]
</p><p>90 The groundtruth focal length from static calibration is 2040 pixels. [sent-422, score-0.743]
</p><p>91 We first reconstructed the visible part of the cap using template-based deformable 3D reconstruction. [sent-426, score-0.272]
</p><p>92 We then transferred the hidden part of the cap from the template by extrapolating the transformation obtained for the reconstructed visible part. [sent-428, score-0.379]
</p><p>93 The estimated focal length was 1890 pixels for SELF-FP and 2118 pixels for SELF-RE, which means an f-error of 7. [sent-435, score-0.534]
</p><p>94 Conclusion The main conclusion of our paper is that focal length self-calibration in template-based isometric deformable 3D reconstruction is feasible. [sent-440, score-1.005]
</p><p>95 Our initialization algorithm facilitates accurate 3D reconstruction for small to medium focal length values while our nonlinear refinement algorithm handles small to large focal length values extremely well, being as accurate as methods using static calibration. [sent-442, score-1.426]
</p><p>96 When the focal length grows too large it cannot be computed. [sent-443, score-0.573]
</p><p>97 We showed how the surface normal can however still be accurately estimated with the weak-perspective projection model. [sent-444, score-0.576]
</p><p>98 On template-based reconstruction from a single view: Analytical solutions and proofs of well-posedness for developable, isometric and conformal surfaces. [sent-461, score-0.535]
</p><p>99 Self-calibration and metric reconstruction in spite of varying and unknown internal camera parameters. [sent-537, score-0.35]
</p><p>100 Linear local models for monocular reconstruction of deformable surfaces. [sent-547, score-0.257]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('focal', 0.391), ('surface', 0.286), ('isometric', 0.268), ('normal', 0.201), ('def', 0.182), ('camera', 0.166), ('template', 0.165), ('depth', 0.146), ('cap', 0.146), ('reconstruction', 0.145), ('length', 0.143), ('equation', 0.136), ('pde', 0.135), ('simulated', 0.119), ('warp', 0.115), ('isometrically', 0.108), ('salzmann', 0.101), ('affine', 0.097), ('ka', 0.096), ('bartoli', 0.095), ('developable', 0.095), ('static', 0.093), ('projection', 0.089), ('variational', 0.084), ('reprojection', 0.082), ('specializing', 0.081), ('kept', 0.078), ('intrinsics', 0.076), ('percents', 0.071), ('isometry', 0.071), ('heuristic', 0.07), ('kp', 0.068), ('perspective', 0.067), ('groundtruth', 0.067), ('keypoint', 0.067), ('deformation', 0.066), ('embedding', 0.066), ('polynomial', 0.066), ('conformal', 0.063), ('differential', 0.062), ('defeated', 0.061), ('fullperspective', 0.061), ('inextensible', 0.061), ('perriollat', 0.061), ('pilet', 0.061), ('socp', 0.061), ('weakperspective', 0.061), ('constraint', 0.06), ('solutions', 0.059), ('deformable', 0.058), ('solution', 0.055), ('deforming', 0.055), ('monocular', 0.054), ('zoom', 0.053), ('nonlinear', 0.053), ('surfaces', 0.051), ('rd', 0.05), ('calibration', 0.049), ('lepetit', 0.049), ('orthographic', 0.049), ('correspondences', 0.048), ('jf', 0.047), ('specialize', 0.047), ('registration', 0.047), ('degrades', 0.046), ('free', 0.046), ('parallelizable', 0.043), ('calibrated', 0.043), ('cvlab', 0.042), ('observe', 0.041), ('computes', 0.041), ('error', 0.04), ('unknown', 0.039), ('grows', 0.039), ('reconstructed', 0.038), ('spline', 0.037), ('substituting', 0.037), ('general', 0.037), ('international', 0.036), ('default', 0.036), ('get', 0.035), ('giving', 0.035), ('refinement', 0.035), ('putative', 0.035), ('relaxing', 0.035), ('jacobian', 0.034), ('triangular', 0.034), ('relaxation', 0.034), ('latter', 0.034), ('dedicated', 0.034), ('sa', 0.033), ('gives', 0.032), ('extremely', 0.032), ('journal', 0.032), ('level', 0.031), ('applies', 0.031), ('visible', 0.03), ('uncalibrated', 0.03), ('det', 0.03), ('imaging', 0.03)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000008 <a title="423-tfidf-1" href="./cvpr-2013-Template-Based_Isometric_Deformable_3D_Reconstruction_with_Sampling-Based_Focal_Length_Self-Calibration.html">423 cvpr-2013-Template-Based Isometric Deformable 3D Reconstruction with Sampling-Based Focal Length Self-Calibration</a></p>
<p>Author: Adrien Bartoli, Toby Collins</p><p>Abstract: It has been shown that a surface deforming isometrically can be reconstructed from a single image and a template 3D shape. Methods from the literature solve this problem efficiently. However, they all assume that the camera model is calibrated, which drastically limits their applicability. We propose (i) a general variational framework that applies to (calibrated and uncalibrated) general camera models and (ii) self-calibrating 3D reconstruction algorithms for the weak-perspective and full-perspective camera models. In the former case, our algorithm returns the normal field and camera ’s scale factor. In the latter case, our algorithm returns the normal field, depth and camera ’s focal length. Our algorithms are the first to achieve deformable 3D reconstruction including camera self-calibration. They apply to much more general setups than existing methods. Experimental results on simulated and real data show that our algorithms give results with the same level of accuracy as existing methods (which use the true focal length) on perspective images, and correctly find the normal field on affine images for which the existing methods fail.</p><p>2 0.26372975 <a title="423-tfidf-2" href="./cvpr-2013-Monocular_Template-Based_3D_Reconstruction_of_Extensible_Surfaces_with_Local_Linear_Elasticity.html">289 cvpr-2013-Monocular Template-Based 3D Reconstruction of Extensible Surfaces with Local Linear Elasticity</a></p>
<p>Author: Abed Malti, Richard Hartley, Adrien Bartoli, Jae-Hak Kim</p><p>Abstract: We propose a new approach for template-based extensible surface reconstruction from a single view. We extend the method of isometric surface reconstruction and more recent work on conformal surface reconstruction. Our approach relies on the minimization of a proposed stretching energy formalized with respect to the Poisson ratio parameter of the surface. We derive a patch-based formulation of this stretching energy by assuming local linear elasticity. This formulation unifies geometrical and mechanical constraints in a single energy term. We prevent local scale ambiguities by imposing a set of fixed boundary 3D points. We experimentally prove the sufficiency of this set of boundary points and demonstrate the effectiveness of our approach on different developable and non-developable surfaces with a wide range of extensibility.</p><p>3 0.22531359 <a title="423-tfidf-3" href="./cvpr-2013-What_Object_Motion_Reveals_about_Shape_with_Unknown_BRDF_and_Lighting.html">465 cvpr-2013-What Object Motion Reveals about Shape with Unknown BRDF and Lighting</a></p>
<p>Author: Manmohan Chandraker, Dikpal Reddy, Yizhou Wang, Ravi Ramamoorthi</p><p>Abstract: We present a theory that addresses the problem of determining shape from the (small or differential) motion of an object with unknown isotropic reflectance, under arbitrary unknown distant illumination, , for both orthographic and perpsective projection. Our theory imposes fundamental limits on the hardness of surface reconstruction, independent of the method involved. Under orthographic projection, we prove that three differential motions suffice to yield an invariant that relates shape to image derivatives, regardless of BRDF and illumination. Under perspective projection, we show that four differential motions suffice to yield depth and a linear constraint on the surface gradient, with unknown BRDF and lighting. Further, we delineate the topological classes up to which reconstruction may be achieved using the invariants. Finally, we derive a general stratification that relates hardness of shape recovery to scene complexity. Qualitatively, our invariants are homogeneous partial differential equations for simple lighting and inhomogeneous for complex illumination. Quantitatively, our framework shows that the minimal number of motions required to resolve shape is greater for more complex scenes. Prior works that assume brightness constancy, Lambertian BRDF or a known directional light source follow as special cases of our stratification. We illustrate with synthetic and real data how potential reconstruction methods may exploit our framework.</p><p>4 0.17750064 <a title="423-tfidf-4" href="./cvpr-2013-A_New_Perspective_on_Uncalibrated_Photometric_Stereo.html">21 cvpr-2013-A New Perspective on Uncalibrated Photometric Stereo</a></p>
<p>Author: Thoma Papadhimitri, Paolo Favaro</p><p>Abstract: We investigate the problem of reconstructing normals, albedo and lights of Lambertian surfaces in uncalibrated photometric stereo under the perspective projection model. Our analysis is based on establishing the integrability constraint. In the orthographicprojection case, it is well-known that when such constraint is imposed, a solution can be identified only up to 3 parameters, the so-called generalized bas-relief (GBR) ambiguity. We show that in the perspective projection case the solution is unique. We also propose a closed-form solution which is simple, efficient and robust. We test our algorithm on synthetic data and publicly available real data. Our quantitative tests show that our method outperforms all prior work of uncalibrated photometric stereo under orthographic projection.</p><p>5 0.17057049 <a title="423-tfidf-5" href="./cvpr-2013-Mirror_Surface_Reconstruction_from_a_Single_Image.html">286 cvpr-2013-Mirror Surface Reconstruction from a Single Image</a></p>
<p>Author: Miaomiao Liu, Richard Hartley, Mathieu Salzmann</p><p>Abstract: This paper tackles the problem of reconstructing the shape of a smooth mirror surface from a single image. In particular, we consider the case where the camera is observing the reflection of a static reference target in the unknown mirror. We first study the reconstruction problem given dense correspondences between 3D points on the reference target and image locations. In such conditions, our differential geometry analysis provides a theoretical proof that the shape of the mirror surface can be uniquely recovered if the pose of the reference target is known. We then relax our assumptions by considering the case where only sparse correspondences are available. In this scenario, we formulate reconstruction as an optimization problem, which can be solved using a nonlinear least-squares method. We demonstrate the effectiveness of our method on both synthetic and real images.</p><p>6 0.16886249 <a title="423-tfidf-6" href="./cvpr-2013-Intrinsic_Characterization_of_Dynamic_Surfaces.html">226 cvpr-2013-Intrinsic Characterization of Dynamic Surfaces</a></p>
<p>7 0.16493264 <a title="423-tfidf-7" href="./cvpr-2013-Simultaneous_Super-Resolution_of_Depth_and_Images_Using_a_Single_Camera.html">397 cvpr-2013-Simultaneous Super-Resolution of Depth and Images Using a Single Camera</a></p>
<p>8 0.14772603 <a title="423-tfidf-8" href="./cvpr-2013-Layer_Depth_Denoising_and_Completion_for_Structured-Light_RGB-D_Cameras.html">245 cvpr-2013-Layer Depth Denoising and Completion for Structured-Light RGB-D Cameras</a></p>
<p>9 0.14357556 <a title="423-tfidf-9" href="./cvpr-2013-Dense_Reconstruction_Using_3D_Object_Shape_Priors.html">111 cvpr-2013-Dense Reconstruction Using 3D Object Shape Priors</a></p>
<p>10 0.13847505 <a title="423-tfidf-10" href="./cvpr-2013-HON4D%3A_Histogram_of_Oriented_4D_Normals_for_Activity_Recognition_from_Depth_Sequences.html">196 cvpr-2013-HON4D: Histogram of Oriented 4D Normals for Activity Recognition from Depth Sequences</a></p>
<p>11 0.13712007 <a title="423-tfidf-11" href="./cvpr-2013-Multi-view_Photometric_Stereo_with_Spatially_Varying_Isotropic_Materials.html">303 cvpr-2013-Multi-view Photometric Stereo with Spatially Varying Isotropic Materials</a></p>
<p>12 0.13617313 <a title="423-tfidf-12" href="./cvpr-2013-Joint_3D_Scene_Reconstruction_and_Class_Segmentation.html">230 cvpr-2013-Joint 3D Scene Reconstruction and Class Segmentation</a></p>
<p>13 0.13173598 <a title="423-tfidf-13" href="./cvpr-2013-A_Theory_of_Refractive_Photo-Light-Path_Triangulation.html">27 cvpr-2013-A Theory of Refractive Photo-Light-Path Triangulation</a></p>
<p>14 0.13115969 <a title="423-tfidf-14" href="./cvpr-2013-Multi-scale_Curve_Detection_on_Surfaces.html">298 cvpr-2013-Multi-scale Curve Detection on Surfaces</a></p>
<p>15 0.13082001 <a title="423-tfidf-15" href="./cvpr-2013-Dense_Variational_Reconstruction_of_Non-rigid_Surfaces_from_Monocular_Video.html">113 cvpr-2013-Dense Variational Reconstruction of Non-rigid Surfaces from Monocular Video</a></p>
<p>16 0.12764959 <a title="423-tfidf-16" href="./cvpr-2013-Shading-Based_Shape_Refinement_of_RGB-D_Images.html">394 cvpr-2013-Shading-Based Shape Refinement of RGB-D Images</a></p>
<p>17 0.12734522 <a title="423-tfidf-17" href="./cvpr-2013-Determining_Motion_Directly_from_Normal_Flows_Upon_the_Use_of_a_Spherical_Eye_Platform.html">124 cvpr-2013-Determining Motion Directly from Normal Flows Upon the Use of a Spherical Eye Platform</a></p>
<p>18 0.12614109 <a title="423-tfidf-18" href="./cvpr-2013-Uncalibrated_Photometric_Stereo_for_Unknown_Isotropic_Reflectances.html">443 cvpr-2013-Uncalibrated Photometric Stereo for Unknown Isotropic Reflectances</a></p>
<p>19 0.12569791 <a title="423-tfidf-19" href="./cvpr-2013-Templateless_Quasi-rigid_Shape_Modeling_with_Implicit_Loop-Closure.html">424 cvpr-2013-Templateless Quasi-rigid Shape Modeling with Implicit Loop-Closure</a></p>
<p>20 0.12468929 <a title="423-tfidf-20" href="./cvpr-2013-Correspondence-Less_Non-rigid_Registration_of_Triangular_Surface_Meshes.html">97 cvpr-2013-Correspondence-Less Non-rigid Registration of Triangular Surface Meshes</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.215), (1, 0.276), (2, 0.003), (3, 0.064), (4, -0.016), (5, -0.126), (6, -0.103), (7, 0.023), (8, 0.041), (9, -0.008), (10, -0.057), (11, 0.012), (12, -0.101), (13, -0.039), (14, 0.044), (15, -0.089), (16, 0.037), (17, 0.114), (18, -0.025), (19, 0.046), (20, -0.083), (21, -0.079), (22, -0.01), (23, 0.007), (24, -0.013), (25, 0.04), (26, -0.088), (27, 0.071), (28, 0.026), (29, 0.002), (30, 0.06), (31, 0.008), (32, 0.078), (33, 0.016), (34, 0.021), (35, 0.028), (36, -0.035), (37, -0.071), (38, -0.005), (39, -0.018), (40, 0.17), (41, -0.035), (42, -0.08), (43, 0.029), (44, -0.037), (45, -0.031), (46, 0.054), (47, -0.035), (48, 0.089), (49, -0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97710526 <a title="423-lsi-1" href="./cvpr-2013-Template-Based_Isometric_Deformable_3D_Reconstruction_with_Sampling-Based_Focal_Length_Self-Calibration.html">423 cvpr-2013-Template-Based Isometric Deformable 3D Reconstruction with Sampling-Based Focal Length Self-Calibration</a></p>
<p>Author: Adrien Bartoli, Toby Collins</p><p>Abstract: It has been shown that a surface deforming isometrically can be reconstructed from a single image and a template 3D shape. Methods from the literature solve this problem efficiently. However, they all assume that the camera model is calibrated, which drastically limits their applicability. We propose (i) a general variational framework that applies to (calibrated and uncalibrated) general camera models and (ii) self-calibrating 3D reconstruction algorithms for the weak-perspective and full-perspective camera models. In the former case, our algorithm returns the normal field and camera ’s scale factor. In the latter case, our algorithm returns the normal field, depth and camera ’s focal length. Our algorithms are the first to achieve deformable 3D reconstruction including camera self-calibration. They apply to much more general setups than existing methods. Experimental results on simulated and real data show that our algorithms give results with the same level of accuracy as existing methods (which use the true focal length) on perspective images, and correctly find the normal field on affine images for which the existing methods fail.</p><p>2 0.82436812 <a title="423-lsi-2" href="./cvpr-2013-Monocular_Template-Based_3D_Reconstruction_of_Extensible_Surfaces_with_Local_Linear_Elasticity.html">289 cvpr-2013-Monocular Template-Based 3D Reconstruction of Extensible Surfaces with Local Linear Elasticity</a></p>
<p>Author: Abed Malti, Richard Hartley, Adrien Bartoli, Jae-Hak Kim</p><p>Abstract: We propose a new approach for template-based extensible surface reconstruction from a single view. We extend the method of isometric surface reconstruction and more recent work on conformal surface reconstruction. Our approach relies on the minimization of a proposed stretching energy formalized with respect to the Poisson ratio parameter of the surface. We derive a patch-based formulation of this stretching energy by assuming local linear elasticity. This formulation unifies geometrical and mechanical constraints in a single energy term. We prevent local scale ambiguities by imposing a set of fixed boundary 3D points. We experimentally prove the sufficiency of this set of boundary points and demonstrate the effectiveness of our approach on different developable and non-developable surfaces with a wide range of extensibility.</p><p>3 0.76845336 <a title="423-lsi-3" href="./cvpr-2013-Mirror_Surface_Reconstruction_from_a_Single_Image.html">286 cvpr-2013-Mirror Surface Reconstruction from a Single Image</a></p>
<p>Author: Miaomiao Liu, Richard Hartley, Mathieu Salzmann</p><p>Abstract: This paper tackles the problem of reconstructing the shape of a smooth mirror surface from a single image. In particular, we consider the case where the camera is observing the reflection of a static reference target in the unknown mirror. We first study the reconstruction problem given dense correspondences between 3D points on the reference target and image locations. In such conditions, our differential geometry analysis provides a theoretical proof that the shape of the mirror surface can be uniquely recovered if the pose of the reference target is known. We then relax our assumptions by considering the case where only sparse correspondences are available. In this scenario, we formulate reconstruction as an optimization problem, which can be solved using a nonlinear least-squares method. We demonstrate the effectiveness of our method on both synthetic and real images.</p><p>4 0.75370038 <a title="423-lsi-4" href="./cvpr-2013-Towards_Contactless%2C_Low-Cost_and_Accurate_3D_Fingerprint_Identification.html">435 cvpr-2013-Towards Contactless, Low-Cost and Accurate 3D Fingerprint Identification</a></p>
<p>Author: Ajay Kumar, Cyril Kwong</p><p>Abstract: In order to avail the benefits of higher user convenience, hygiene, and improved accuracy, contactless 3D fingerprint recognition techniques have recently been introduced. One of the key limitations of these emerging 3D fingerprint technologies to replace the conventional 2D fingerprint system is their bulk and high cost, which mainly results from the use of multiple imaging cameras or structured lighting employed in these systems. This paper details the development of a contactless 3D fingerprint identification system that uses only single camera. We develop a new representation of 3D finger surface features using Finger Surface Codes and illustrate its effectiveness in matching 3D fingerprints. Conventional minutiae representation is extended in 3D space to accurately match the recovered 3D minutiae. Multiple 2D fingerprint images (with varying illumination profile) acquired to build 3D fingerprints can themselves be used recover 2D features for further improving 3D fingerprint identification and has been illustrated in this paper. The experimental results are shown on a database of 240 client fingerprints and confirm the advantages of the single camera based 3D fingerprint identification.</p><p>5 0.71162271 <a title="423-lsi-5" href="./cvpr-2013-What_Object_Motion_Reveals_about_Shape_with_Unknown_BRDF_and_Lighting.html">465 cvpr-2013-What Object Motion Reveals about Shape with Unknown BRDF and Lighting</a></p>
<p>Author: Manmohan Chandraker, Dikpal Reddy, Yizhou Wang, Ravi Ramamoorthi</p><p>Abstract: We present a theory that addresses the problem of determining shape from the (small or differential) motion of an object with unknown isotropic reflectance, under arbitrary unknown distant illumination, , for both orthographic and perpsective projection. Our theory imposes fundamental limits on the hardness of surface reconstruction, independent of the method involved. Under orthographic projection, we prove that three differential motions suffice to yield an invariant that relates shape to image derivatives, regardless of BRDF and illumination. Under perspective projection, we show that four differential motions suffice to yield depth and a linear constraint on the surface gradient, with unknown BRDF and lighting. Further, we delineate the topological classes up to which reconstruction may be achieved using the invariants. Finally, we derive a general stratification that relates hardness of shape recovery to scene complexity. Qualitatively, our invariants are homogeneous partial differential equations for simple lighting and inhomogeneous for complex illumination. Quantitatively, our framework shows that the minimal number of motions required to resolve shape is greater for more complex scenes. Prior works that assume brightness constancy, Lambertian BRDF or a known directional light source follow as special cases of our stratification. We illustrate with synthetic and real data how potential reconstruction methods may exploit our framework.</p><p>6 0.70661008 <a title="423-lsi-6" href="./cvpr-2013-Multi-scale_Curve_Detection_on_Surfaces.html">298 cvpr-2013-Multi-scale Curve Detection on Surfaces</a></p>
<p>7 0.69295889 <a title="423-lsi-7" href="./cvpr-2013-A_New_Perspective_on_Uncalibrated_Photometric_Stereo.html">21 cvpr-2013-A New Perspective on Uncalibrated Photometric Stereo</a></p>
<p>8 0.69242287 <a title="423-lsi-8" href="./cvpr-2013-Intrinsic_Characterization_of_Dynamic_Surfaces.html">226 cvpr-2013-Intrinsic Characterization of Dynamic Surfaces</a></p>
<p>9 0.69068515 <a title="423-lsi-9" href="./cvpr-2013-Relative_Volume_Constraints_for_Single_View_3D_Reconstruction.html">354 cvpr-2013-Relative Volume Constraints for Single View 3D Reconstruction</a></p>
<p>10 0.68459558 <a title="423-lsi-10" href="./cvpr-2013-The_Episolar_Constraint%3A_Monocular_Shape_from_Shadow_Correspondence.html">428 cvpr-2013-The Episolar Constraint: Monocular Shape from Shadow Correspondence</a></p>
<p>11 0.68286777 <a title="423-lsi-11" href="./cvpr-2013-Hyperbolic_Harmonic_Mapping_for_Constrained_Brain_Surface_Registration.html">208 cvpr-2013-Hyperbolic Harmonic Mapping for Constrained Brain Surface Registration</a></p>
<p>12 0.66666055 <a title="423-lsi-12" href="./cvpr-2013-Multi-view_Photometric_Stereo_with_Spatially_Varying_Isotropic_Materials.html">303 cvpr-2013-Multi-view Photometric Stereo with Spatially Varying Isotropic Materials</a></p>
<p>13 0.6342786 <a title="423-lsi-13" href="./cvpr-2013-Area_Preserving_Brain_Mapping.html">44 cvpr-2013-Area Preserving Brain Mapping</a></p>
<p>14 0.63236302 <a title="423-lsi-14" href="./cvpr-2013-Correspondence-Less_Non-rigid_Registration_of_Triangular_Surface_Meshes.html">97 cvpr-2013-Correspondence-Less Non-rigid Registration of Triangular Surface Meshes</a></p>
<p>15 0.62314171 <a title="423-lsi-15" href="./cvpr-2013-Simultaneous_Super-Resolution_of_Depth_and_Images_Using_a_Single_Camera.html">397 cvpr-2013-Simultaneous Super-Resolution of Depth and Images Using a Single Camera</a></p>
<p>16 0.61901432 <a title="423-lsi-16" href="./cvpr-2013-Uncalibrated_Photometric_Stereo_for_Unknown_Isotropic_Reflectances.html">443 cvpr-2013-Uncalibrated Photometric Stereo for Unknown Isotropic Reflectances</a></p>
<p>17 0.60771179 <a title="423-lsi-17" href="./cvpr-2013-A_Theory_of_Refractive_Photo-Light-Path_Triangulation.html">27 cvpr-2013-A Theory of Refractive Photo-Light-Path Triangulation</a></p>
<p>18 0.60471863 <a title="423-lsi-18" href="./cvpr-2013-Axially_Symmetric_3D_Pots_Configuration_System_Using_Axis_of_Symmetry_and_Break_Curve.html">52 cvpr-2013-Axially Symmetric 3D Pots Configuration System Using Axis of Symmetry and Break Curve</a></p>
<p>19 0.59350705 <a title="423-lsi-19" href="./cvpr-2013-Joint_3D_Scene_Reconstruction_and_Class_Segmentation.html">230 cvpr-2013-Joint 3D Scene Reconstruction and Class Segmentation</a></p>
<p>20 0.58366919 <a title="423-lsi-20" href="./cvpr-2013-Dense_Reconstruction_Using_3D_Object_Shape_Priors.html">111 cvpr-2013-Dense Reconstruction Using 3D Object Shape Priors</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.014), (10, 0.086), (16, 0.02), (26, 0.44), (33, 0.233), (67, 0.025), (69, 0.023), (87, 0.093)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.85927165 <a title="423-lda-1" href="./cvpr-2013-Template-Based_Isometric_Deformable_3D_Reconstruction_with_Sampling-Based_Focal_Length_Self-Calibration.html">423 cvpr-2013-Template-Based Isometric Deformable 3D Reconstruction with Sampling-Based Focal Length Self-Calibration</a></p>
<p>Author: Adrien Bartoli, Toby Collins</p><p>Abstract: It has been shown that a surface deforming isometrically can be reconstructed from a single image and a template 3D shape. Methods from the literature solve this problem efficiently. However, they all assume that the camera model is calibrated, which drastically limits their applicability. We propose (i) a general variational framework that applies to (calibrated and uncalibrated) general camera models and (ii) self-calibrating 3D reconstruction algorithms for the weak-perspective and full-perspective camera models. In the former case, our algorithm returns the normal field and camera ’s scale factor. In the latter case, our algorithm returns the normal field, depth and camera ’s focal length. Our algorithms are the first to achieve deformable 3D reconstruction including camera self-calibration. They apply to much more general setups than existing methods. Experimental results on simulated and real data show that our algorithms give results with the same level of accuracy as existing methods (which use the true focal length) on perspective images, and correctly find the normal field on affine images for which the existing methods fail.</p><p>2 0.84339976 <a title="423-lda-2" href="./cvpr-2013-Maximum_Cohesive_Grid_of_Superpixels_for_Fast_Object_Localization.html">280 cvpr-2013-Maximum Cohesive Grid of Superpixels for Fast Object Localization</a></p>
<p>Author: Liang Li, Wei Feng, Liang Wan, Jiawan Zhang</p><p>Abstract: This paper addresses a challenging problem of regularizing arbitrary superpixels into an optimal grid structure, which may significantly extend current low-level vision algorithms by allowing them to use superpixels (SPs) conveniently as using pixels. For this purpose, we aim at constructing maximum cohesive SP-grid, which is composed of real nodes, i.e. SPs, and dummy nodes that are meaningless in the image with only position-taking function in the grid. For a given formation of image SPs and proper number of dummy nodes, we first dynamically align them into a grid based on the centroid localities of SPs. We then define the SP-grid coherence as the sum of edge weights, with SP locality and appearance encoded, along all direct paths connecting any two nearest neighboring real nodes in the grid. We finally maximize the SP-grid coherence via cascade dynamic programming. Our approach can take the regional objectness as an optional constraint to produce more semantically reliable SP-grids. Experiments on object localization show that our approach outperforms state-of-the-art methods in terms of both detection accuracy and speed. We also find that with the same searching strategy and features, object localization at SP-level is about 100-500 times faster than pixel-level, with usually better detection accuracy.</p><p>3 0.82774186 <a title="423-lda-3" href="./cvpr-2013-Measures_and_Meta-Measures_for_the_Supervised_Evaluation_of_Image_Segmentation.html">281 cvpr-2013-Measures and Meta-Measures for the Supervised Evaluation of Image Segmentation</a></p>
<p>Author: Jordi Pont-Tuset, Ferran Marques</p><p>Abstract: This paper tackles the supervised evaluation of image segmentation algorithms. First, it surveys and structures the measures used to compare the segmentation results with a ground truth database; and proposes a new measure: the precision-recall for objects and parts. To compare the goodness of these measures, it defines three quantitative meta-measures involving six state of the art segmentation methods. The meta-measures consist in assuming some plausible hypotheses about the results and assessing how well each measure reflects these hypotheses. As a conclusion, this paper proposes the precision-recall curves for boundaries and for objects-and-parts as the tool of choice for the supervised evaluation of image segmentation. We make the datasets and code of all the measures publicly available.</p><p>4 0.80015373 <a title="423-lda-4" href="./cvpr-2013-Tracking_People_and_Their_Objects.html">440 cvpr-2013-Tracking People and Their Objects</a></p>
<p>Author: Tobias Baumgartner, Dennis Mitzel, Bastian Leibe</p><p>Abstract: Current pedestrian tracking approaches ignore important aspects of human behavior. Humans are not moving independently, but they closely interact with their environment, which includes not only other persons, but also different scene objects. Typical everyday scenarios include people moving in groups, pushing child strollers, or pulling luggage. In this paper, we propose a probabilistic approach for classifying such person-object interactions, associating objects to persons, and predicting how the interaction will most likely continue. Our approach relies on stereo depth information in order to track all scene objects in 3D, while simultaneously building up their 3D shape models. These models and their relative spatial arrangement are then fed into a probabilistic graphical model which jointly infers pairwise interactions and object classes. The inferred interactions can then be used to support tracking by recovering lost object tracks. We evaluate our approach on a novel dataset containing more than 15,000 frames of personobject interactions in 325 video sequences and demonstrate good performance in challenging real-world scenarios.</p><p>5 0.78087133 <a title="423-lda-5" href="./cvpr-2013-Exemplar-Based_Face_Parsing.html">152 cvpr-2013-Exemplar-Based Face Parsing</a></p>
<p>Author: Brandon M. Smith, Li Zhang, Jonathan Brandt, Zhe Lin, Jianchao Yang</p><p>Abstract: In this work, we propose an exemplar-based face image segmentation algorithm. We take inspiration from previous works on image parsing for general scenes. Our approach assumes a database of exemplar face images, each of which is associated with a hand-labeled segmentation map. Given a test image, our algorithm first selects a subset of exemplar images from the database, Our algorithm then computes a nonrigid warp for each exemplar image to align it with the test image. Finally, we propagate labels from the exemplar images to the test image in a pixel-wise manner, using trained weights to modulate and combine label maps from different exemplars. We evaluate our method on two challenging datasets and compare with two face parsing algorithms and a general scene parsing algorithm. We also compare our segmentation results with contour-based face alignment results; that is, we first run the alignment algorithms to extract contour points and then derive segments from the contours. Our algorithm compares favorably with all previous works on all datasets evaluated.</p><p>6 0.74590623 <a title="423-lda-6" href="./cvpr-2013-Occlusion_Patterns_for_Object_Class_Detection.html">311 cvpr-2013-Occlusion Patterns for Object Class Detection</a></p>
<p>7 0.70666087 <a title="423-lda-7" href="./cvpr-2013-Relative_Hidden_Markov_Models_for_Evaluating_Motion_Skill.html">353 cvpr-2013-Relative Hidden Markov Models for Evaluating Motion Skill</a></p>
<p>8 0.70316786 <a title="423-lda-8" href="./cvpr-2013-Compressible_Motion_Fields.html">88 cvpr-2013-Compressible Motion Fields</a></p>
<p>9 0.67549008 <a title="423-lda-9" href="./cvpr-2013-A_New_Perspective_on_Uncalibrated_Photometric_Stereo.html">21 cvpr-2013-A New Perspective on Uncalibrated Photometric Stereo</a></p>
<p>10 0.65626162 <a title="423-lda-10" href="./cvpr-2013-What_Object_Motion_Reveals_about_Shape_with_Unknown_BRDF_and_Lighting.html">465 cvpr-2013-What Object Motion Reveals about Shape with Unknown BRDF and Lighting</a></p>
<p>11 0.62941253 <a title="423-lda-11" href="./cvpr-2013-Physically_Plausible_3D_Scene_Tracking%3A_The_Single_Actor_Hypothesis.html">331 cvpr-2013-Physically Plausible 3D Scene Tracking: The Single Actor Hypothesis</a></p>
<p>12 0.62808704 <a title="423-lda-12" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<p>13 0.62609941 <a title="423-lda-13" href="./cvpr-2013-Hyperbolic_Harmonic_Mapping_for_Constrained_Brain_Surface_Registration.html">208 cvpr-2013-Hyperbolic Harmonic Mapping for Constrained Brain Surface Registration</a></p>
<p>14 0.62116265 <a title="423-lda-14" href="./cvpr-2013-Optimal_Geometric_Fitting_under_the_Truncated_L2-Norm.html">317 cvpr-2013-Optimal Geometric Fitting under the Truncated L2-Norm</a></p>
<p>15 0.62025791 <a title="423-lda-15" href="./cvpr-2013-Correlation_Filters_for_Object_Alignment.html">96 cvpr-2013-Correlation Filters for Object Alignment</a></p>
<p>16 0.61954969 <a title="423-lda-16" href="./cvpr-2013-Templateless_Quasi-rigid_Shape_Modeling_with_Implicit_Loop-Closure.html">424 cvpr-2013-Templateless Quasi-rigid Shape Modeling with Implicit Loop-Closure</a></p>
<p>17 0.6181187 <a title="423-lda-17" href="./cvpr-2013-Sparse_Subspace_Denoising_for_Image_Manifolds.html">405 cvpr-2013-Sparse Subspace Denoising for Image Manifolds</a></p>
<p>18 0.6181013 <a title="423-lda-18" href="./cvpr-2013-The_Generalized_Laplacian_Distance_and_Its_Applications_for_Visual_Matching.html">429 cvpr-2013-The Generalized Laplacian Distance and Its Applications for Visual Matching</a></p>
<p>19 0.61793101 <a title="423-lda-19" href="./cvpr-2013-Groupwise_Registration_via_Graph_Shrinkage_on_the_Image_Manifold.html">194 cvpr-2013-Groupwise Registration via Graph Shrinkage on the Image Manifold</a></p>
<p>20 0.61665779 <a title="423-lda-20" href="./cvpr-2013-Robust_Canonical_Time_Warping_for_the_Alignment_of_Grossly_Corrupted_Sequences.html">358 cvpr-2013-Robust Canonical Time Warping for the Alignment of Grossly Corrupted Sequences</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
