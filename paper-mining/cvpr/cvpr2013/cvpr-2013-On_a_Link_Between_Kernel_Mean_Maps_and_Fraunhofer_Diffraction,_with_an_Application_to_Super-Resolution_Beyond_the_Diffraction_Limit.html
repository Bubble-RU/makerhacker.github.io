<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>312 cvpr-2013-On a Link Between Kernel Mean Maps and Fraunhofer Diffraction, with an Application to Super-Resolution Beyond the Diffraction Limit</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-312" href="#">cvpr2013-312</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>312 cvpr-2013-On a Link Between Kernel Mean Maps and Fraunhofer Diffraction, with an Application to Super-Resolution Beyond the Diffraction Limit</h1>
<br/><p>Source: <a title="cvpr-2013-312-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Harmeling_On_a_Link_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Stefan Harmeling, Michael Hirsch, Bernhard Schölkopf</p><p>Abstract: We establish a link between Fourier optics and a recent construction from the machine learning community termed the kernel mean map. Using the Fraunhofer approximation, it identifies the kernel with the squared Fourier transform of the aperture. This allows us to use results about the invertibility of the kernel mean map to provide a statement about the invertibility of Fraunhofer diffraction, showing that imaging processes with arbitrarily small apertures can in principle be invertible, i.e., do not lose information, provided the objects to be imaged satisfy a generic condition. A real world experiment shows that we can super-resolve beyond the Rayleigh limit.</p><p>Reference: <a title="cvpr-2013-312-reference" href="../cvpr2013_reference/cvpr-2013-On_a_Link_Between_Kernel_Mean_Maps_and_Fraunhofer_Diffraction%2C_with_an_Application_to_Super-Resolution_Beyond_the_Diffraction_Limit_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 de  Abstract We establish a link between Fourier optics and a recent construction from the machine learning community termed the kernel mean map. [sent-4, score-0.54]
</p><p>2 Using the Fraunhofer approximation, it identifies the kernel with the squared Fourier transform of the aperture. [sent-5, score-0.308]
</p><p>3 This allows us to use results about the invertibility of the kernel mean map to provide a statement about the invertibility of Fraunhofer diffraction, showing that imaging processes with arbitrarily small apertures can in principle be invertible, i. [sent-6, score-0.777]
</p><p>4 , do not lose information, provided the objects to be imaged satisfy a generic condition. [sent-8, score-0.05]
</p><p>5 Introduction Imaging devices such as telescopes and microscopes collect incoming light using lenses or mirrors of finite size. [sent-11, score-0.239]
</p><p>6 This finite size imposes a finite aperture on the light that reaches the optical system, leading to effects of diffraction. [sent-12, score-0.406]
</p><p>7 In particular, diffraction ensures that the image of a point can never be a point. [sent-13, score-0.271]
</p><p>8 For instance, an imaging system using a lens with an F-number f/D (where f is the focal length, and D is the diameter of the circular aperture) has an impulse response function (Airy disk) whose radius is 1. [sent-14, score-0.329]
</p><p>9 22λf/D on the sensor, where λ is the wave length of the light (for simplicity, assumed to be monochromatic). [sent-15, score-0.21]
</p><p>10 For a lens focused at infinity, the transfer function is constant within a circle of radius ν = 1/(2λf/D), and zero outside [23, p. [sent-17, score-0.062]
</p><p>11 Object details smaller than the diffraction limit are washed out, and this fundamental limit of image-formation systems is often referred to as the diffraction limit [23, p. [sent-20, score-0.728]
</p><p>12 There are ways to circumvent it using sophisticated hardware, for instance with scanning near-field optical microscopy, or stimulated emission depletion microscopy (STED) using fluorescence [14], but these are not the topic of the current paper. [sent-22, score-0.154]
</p><p>13 Instead, we want to assay whether restrictions on the object being imaged can fundamentally change the resolution of an optical system. [sent-23, score-0.112]
</p><p>14 Specifically, we will show that under the generic assumption of bounded support, one can in principle (i. [sent-24, score-0.085]
</p><p>15 , given a perfect measurement of the image) resolve arbitrarily fine detail. [sent-26, score-0.039]
</p><p>16 This is done by pointing out a connection to the field of kernel methods in machine learning, and utilizing certain theoretical results from that domain. [sent-27, score-0.386]
</p><p>17 We do not claim that all our insights are new indeed, we will —  point out that in spite of the above received wisdom, there are certain theoretical results in the optics community, some of them rather old, that draw similar conclusions. [sent-28, score-0.161]
</p><p>18 We do believe, however, that the link to kernel methods is new, and hope that it will lead to a fruitful cross-fertilization of two previously unconnected branches of research. [sent-29, score-0.351]
</p><p>19 Using toy examples, we show that the assumption of bounded support can be used to recover image detail past the diffraction limit for simple real-world images, which are pixelized and not noise-free. [sent-30, score-0.473]
</p><p>20 In Section 2, we explain the notion of kernel means. [sent-32, score-0.264]
</p><p>21 These are particular types of mappings into reproducing kernel Hilbert spaces, and in some cases they can be shown to be invertible. [sent-33, score-0.391]
</p><p>22 The kernel map has applications in a number of tasks including testing of homogeneity and independence [11, 12]. [sent-34, score-0.317]
</p><p>23 However, our main interest is a link to wave optics, to be described in  lcwairegs e b,riyfthwFaoneu drνei, crdoimafnrpa olcysteiso asn,gwaelin elcroa mlnonpbiohjneilacenteitnsthloa rstgpepa rtia tehlrafn r. [sent-35, score-0.194]
</p><p>24 We show that Fraunhofer diffraction is actually a particular case of kernel mean mapping. [sent-40, score-0.606]
</p><p>25 This link between Fourier optics and machine learning allows us to leverage some theoretical results about kernel mean maps to make a surprising statement about super-resolved imaging. [sent-41, score-0.631]
</p><p>26 Section 5 discusses how this result relates to certain observations made by the wave optics community. [sent-42, score-0.225]
</p><p>27 Characteristic kernel means A symmetric function k : X2 → R, where X is a nonempty set, fisu ccatilloend a positive definite (pd) ek Xerne isl if for arbitrary points x1, . [sent-44, score-0.427]
</p><p>28 i,j  The kernel is called strictly positive definite if moreo? [sent-53, score-0.531]
</p><p>29 i,j aiajk(xi, xj) = 0, implies that all coefficients vani? [sent-55, score-0.077]
</p><p>30 Any positive definite kernel induces a mapping x → k(x, . [sent-57, score-0.398]
</p><p>31 )  (1)  into a reproducing kernel Hilbert space (RKHS), which is a Hilbert space of functions f : X → R with an inner product ? [sent-58, score-0.391]
</p><p>32 Kernel mean of a sample In an SVM [24], (1) is the mapping that takes each datapoint into the so-called feature space, in which a linear  learning method is applied. [sent-79, score-0.071]
</p><p>33 Rather than mapping the points one by one, however, one can also map a sample or a distribution directly to its mean in the feature space. [sent-80, score-0.124]
</p><p>34 Below, we will show that this kind of mapping contains optical imaging as a special case. [sent-81, score-0.19]
</p><p>35 But before, we first point out that even though the operation of taking the mean usually comes with a loss of information, this need not be the case if the kernel satisfies a certain condition. [sent-82, score-0.335]
</p><p>36 Clearly, if X equals Y , their kernel means are id}en ⊂tica Xl. [sent-97, score-0.3]
</p><p>37 , We call a kernel characteristic for samples, if the mean map μ based on k is injective, i. [sent-101, score-0.636]
</p><p>38 , if identical kernel means μ(X) = μ(Y ) imply identical samples X = Y . [sent-103, score-0.3]
</p><p>39 + 1)d, with d ∈ N, observing equal kernel means =μ( (X? [sent-111, score-0.3]
</p><p>40 μ +(Y 1 )) for the samples bXs arnvidn Yg e implies rtnhealt malel empirical =mo μm(Yen )ts f up htoe order d of X and Y coincide. [sent-113, score-0.124]
</p><p>41 The following proposition gives a sufficient condition for being a characteristic kernel:  Proposition 1 Strictly pd kernels are characteristic for samples. [sent-115, score-0.993]
</p><p>42 Proof: Consider a strictly pd kernel k and its mean map μ. [sent-116, score-0.836]
</p><p>43 , zl h} e q buea tlh kee srnete l( mnoeta tnhse, mμ(uXlti)se =t) μof( Yall ) . [sent-129, score-0.036]
</p><p>44 el Lemete Znts = =in { tzhe union }of b Xe t haned s eYt ,( nio. [sent-130, score-0.075]
</p><p>45 1  (6)  which by the reproducing property and bilinearity amounts to ? [sent-154, score-0.127]
</p><p>46 j= 1  (7)  Since k is strictly pd, this implies that for all ithe coefficients γi are zero, thus #X(zi) = #Y (zi)m/n. [sent-158, score-0.256]
</p><p>47 The mean map has some other interesting properties [28]. [sent-162, score-0.124]
</p><p>48 Among them is the fact that μ(X) represents the operation of taking a mean of a function on the sample X:  ? [sent-163, score-0.071]
</p><p>49 Kernel mean of a probability measure Instead of samples we next consider probability measures2 defined on X assuming that X has the necessary additionald esftriunectdu rone. [sent-172, score-0.265]
</p><p>50 XTo a ensure tgh tath athte X following integrals exists, we assume that all considered kernels are bounded (see [29]). [sent-173, score-0.225]
</p><p>51 Below, we will think of the measures as the light distribution of the object being imaged. [sent-174, score-0.197]
</p><p>52 We extend the mean map to probability measures by defining the kernel mean of P as  μ(P) =? [sent-175, score-0.65]
</p><p>53 (9)  Similar to the above definition, we call a kernel characteristic for probability measures [7] if the mean map is injective for probability measures, i. [sent-178, score-1.032]
</p><p>54 To state the analog of Proposition 1, we define a kernel k to be integrally strictly positive definite if for any finite non-zero signed Borel measure ν, the integral of k wrt. [sent-181, score-0.826]
</p><p>55 (10)  Note that an integrally strictly pd kernel is also strictly pd but not vice versa. [sent-186, score-1.315]
</p><p>56 Proposition 2 Integrally strictly pd kernels are characteristic for probability measures. [sent-187, score-0.894]
</p><p>57 This result was proven by [29]; we only provide a brief proof sketch: Consider two different probability measures P and Q. [sent-188, score-0.191]
</p><p>58 Their difference is a finite non-zero signed Borel measure ν = P − Q. [sent-189, score-0.14]
</p><p>59 Assuming equal kernel means, we hmaevaes: 0 = μ(P) − μ(Q)  =? [sent-190, score-0.264]
</p><p>60 ) dν(x)  (13)  Taking the squared norm and using the reproducing property we get a contradiction,  0 = ? [sent-196, score-0.171]
</p><p>61 ) > 0  (14) (15)  where we used for the last inequality the fact that k is integrally strictly pd. [sent-205, score-0.334]
</p><p>62 2We  assume  that all measures considered  are  Borel  measures. [sent-206, score-0.094]
</p><p>63 A more specific view on characteristic kernels, which will apply in the case of Fraunhofer imaging, can be obtained by considering translation invariant pd kernels on X = Rd, i. [sent-207, score-0.656]
</p><p>64 By xB −oc xhner’s theorem [30], they can be expressed as t Rhe. [sent-212, score-0.049]
</p><p>65 Fourier transform of a finite non-negative Borel measure Λ,  ψ(x) =? [sent-213, score-0.097]
</p><p>66 (16)  Following Corollary 4 in [29] we can write the squared RKHS distance between the kernel means of two probability measures in terms of their characteristic functions,  ? [sent-215, score-0.783]
</p><p>67 is the norm of the RKHS and φP (ω) = dP(x) is the characteristic function of P, and likew? [sent-221, score-0.248]
</p><p>68 e distinguished as long as the spectrum of the kernel is nonzero wherever the spectra of the probability distributions might differ. [sent-224, score-0.361]
</p><p>69 it is non-zero almost everywhere, the corresponding kernel can distinguish all probability distributions. [sent-227, score-0.361]
</p><p>70 If it does not have full support, it can sometimes still distinguish a restricted class of probability distribution as we see next. [sent-228, score-0.097]
</p><p>71 Kernel mean of a probability bounded support  measure with  Consider a translation invariant pd kernel k such that the support of the corresponding has a non-empty interior. [sent-232, score-0.934]
</p><p>72 For what class of probability measures can such a kernel be characteristic3? [sent-233, score-0.455]
</p><p>73 An obvious choice is a class of probability measures whose characteristic functions agree outside the support of However, there is a much more interesting class of measures which we define next. [sent-234, score-0.588]
</p><p>74 Let us consider a probability measure P with compact support. [sent-235, score-0.097]
</p><p>75 By the Paley-Wiener theorem [21] its characteristic function φP is entire (aka analytic or holomorphic), which implies that knowing φP on a compact subset deter-  Λ  Λ. [sent-236, score-0.374]
</p><p>76 This leads to the following proposition: Proposition 3 Translation invariant pd kernels, whose corresponding Λ have a support with non-empty interior, are characteristic for probability measures with compact support. [sent-238, score-0.763]
</p><p>77 3We  characteristic for a class of probability measures in the obvii. [sent-240, score-0.439]
</p><p>78 the kernel map is injective for the restricted class. [sent-242, score-0.425]
</p><p>79 use  ous way,  1 1 10 0 08 8 835 3  The kernel which will be relevant in the next section is the sinc kernel defined for σ > 0 as  k(x,x? [sent-243, score-0.596]
</p><p>80 2π1[−σ,σ](ω),  (19)  so Λ is non-zero on that interval (thus having a support with non-empty interior) and is thus characteristic for probability measures of bounded support. [sent-251, score-0.579]
</p><p>81 The square of the sinc kernel has the same properties, since it corresponds to the convo-  lution of Λ with itself, inheriting a support with non-empty interior from Λ. [sent-252, score-0.48]
</p><p>82 Imaging under incoherent illumination As electromagnetic radiation, light is governed by Maxwells equations a set of linear partial differential equations that form the foundation of classical electrodynamics including classical optics. [sent-256, score-0.327]
</p><p>83 Although electric and magnetic fields are vectorial in nature, in many situations4 polarisation effects, i. [sent-257, score-0.371]
</p><p>84 The property of linearity has major implications for the mathematical treatment as it allows us to analyse a system by studying its response to a single point stimulus. [sent-261, score-0.049]
</p><p>85 (21)  Here Ψ denotes the output of a linear optical system which is fully described by its impulse response h(u − ξ). [sent-264, score-0.201]
</p><p>86 Since the integration time is much longer than a single period of oscillation, we must average over time to obtain the recorded pixel intensities  ? [sent-275, score-0.037]
</p><p>87 n Htoe arce,co wuent m aunsdt tdakisetinguish between coherent and incoherent illumination: • In the case of coherent illumination, we cannot sim-  plify Equation ( c2o3h)e any tfu ilrltuhmeri nwaittihoonu,t w making any iamd-ditional assumptions. [sent-294, score-0.225]
</p><p>88 The square of the complex field can lead to cancellations or other non-linear interference effects. [sent-295, score-0.043]
</p><p>89 •  In the case of incoherent illumination, the spatial corIrenla thtieon c bseetw ofe iennc any etwnto i light rays ne,m tihtete sdp fartioaml c tohrescene is assumed to be negligible. [sent-296, score-0.436]
</p><p>90 )  (24)  Plugging expression (24) into Equation (23) yields the incoherent imaging equation  q(u) =? [sent-302, score-0.356]
</p><p>91 ibean image uint −en ξsi)t|ies; the impulse response f is c? [sent-315, score-0.175]
</p><p>92 alled the point spread function (PSF) of the imaging system as it corresponds to the image of a point light source. [sent-316, score-0.231]
</p><p>93 Although we had to make a number of assumptions to derive the incoherent imaging equation (25), it has been found to provide an accurate description for most typical imaging systems including astronomical, microscopical  imaging and photography [2]. [sent-317, score-0.612]
</p><p>94 Connection to kernel mean map As an image is inherently non-negative, the image of the object p(ξ) induces, up to normalization, a probabili? [sent-320, score-0.388]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('diffraction', 0.271), ('pd', 0.269), ('kernel', 0.264), ('characteristic', 0.248), ('fraunhofer', 0.194), ('incoherent', 0.186), ('strictly', 0.179), ('integrally', 0.155), ('electric', 0.155), ('borel', 0.144), ('magnetic', 0.141), ('imaging', 0.128), ('reproducing', 0.127), ('proposition', 0.127), ('zi', 0.125), ('optics', 0.118), ('injective', 0.108), ('wave', 0.107), ('light', 0.103), ('kernels', 0.101), ('finite', 0.097), ('probability', 0.097), ('measures', 0.094), ('rkhs', 0.093), ('fourier', 0.092), ('impulse', 0.09), ('definite', 0.088), ('aiajk', 0.087), ('invertibility', 0.087), ('link', 0.087), ('bounded', 0.085), ('implies', 0.077), ('hilbert', 0.075), ('mean', 0.071), ('sinc', 0.068), ('limit', 0.062), ('optical', 0.062), ('lens', 0.062), ('dp', 0.061), ('interior', 0.057), ('microscopy', 0.056), ('support', 0.055), ('refractive', 0.055), ('map', 0.053), ('xm', 0.052), ('imaged', 0.05), ('response', 0.049), ('theorem', 0.049), ('statement', 0.048), ('htoe', 0.047), ('aperture', 0.047), ('induces', 0.046), ('scalar', 0.044), ('squared', 0.044), ('london', 0.043), ('theoretical', 0.043), ('jk', 0.043), ('signed', 0.043), ('field', 0.043), ('equation', 0.042), ('tuebingen', 0.039), ('fisu', 0.039), ('dielectric', 0.039), ('polarisation', 0.039), ('tfu', 0.039), ('probabili', 0.039), ('airy', 0.039), ('microscopes', 0.039), ('eyt', 0.039), ('athte', 0.039), ('tzhe', 0.039), ('iennc', 0.039), ('halel', 0.039), ('yen', 0.039), ('dnecneo', 0.039), ('xon', 0.039), ('xpl', 0.039), ('arbitrarily', 0.039), ('illumination', 0.038), ('translation', 0.038), ('xi', 0.038), ('intensities', 0.037), ('connection', 0.036), ('means', 0.036), ('bernhard', 0.036), ('haned', 0.036), ('ofe', 0.036), ('holomorphic', 0.036), ('aofl', 0.036), ('vectorial', 0.036), ('contradiction', 0.036), ('stimulated', 0.036), ('ixt', 0.036), ('thtieon', 0.036), ('exposition', 0.036), ('lution', 0.036), ('bseetw', 0.036), ('kee', 0.036), ('uint', 0.036), ('bingen', 0.036)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000006 <a title="312-tfidf-1" href="./cvpr-2013-On_a_Link_Between_Kernel_Mean_Maps_and_Fraunhofer_Diffraction%2C_with_an_Application_to_Super-Resolution_Beyond_the_Diffraction_Limit.html">312 cvpr-2013-On a Link Between Kernel Mean Maps and Fraunhofer Diffraction, with an Application to Super-Resolution Beyond the Diffraction Limit</a></p>
<p>Author: Stefan Harmeling, Michael Hirsch, Bernhard Schölkopf</p><p>Abstract: We establish a link between Fourier optics and a recent construction from the machine learning community termed the kernel mean map. Using the Fraunhofer approximation, it identifies the kernel with the squared Fourier transform of the aperture. This allows us to use results about the invertibility of the kernel mean map to provide a statement about the invertibility of Fraunhofer diffraction, showing that imaging processes with arbitrarily small apertures can in principle be invertible, i.e., do not lose information, provided the objects to be imaged satisfy a generic condition. A real world experiment shows that we can super-resolve beyond the Rayleigh limit.</p><p>2 0.1523838 <a title="312-tfidf-2" href="./cvpr-2013-Kernel_Methods_on_the_Riemannian_Manifold_of_Symmetric_Positive_Definite_Matrices.html">238 cvpr-2013-Kernel Methods on the Riemannian Manifold of Symmetric Positive Definite Matrices</a></p>
<p>Author: Sadeep Jayasumana, Richard Hartley, Mathieu Salzmann, Hongdong Li, Mehrtash Harandi</p><p>Abstract: Symmetric Positive Definite (SPD) matrices have become popular to encode image information. Accounting for the geometry of the Riemannian manifold of SPD matrices has proven key to the success of many algorithms. However, most existing methods only approximate the true shape of the manifold locally by its tangent plane. In this paper, inspired by kernel methods, we propose to map SPD matrices to a high dimensional Hilbert space where Euclidean geometry applies. To encode the geometry of the manifold in the mapping, we introduce a family of provably positive definite kernels on the Riemannian manifold of SPD matrices. These kernels are derived from the Gaussian kernel, but exploit different metrics on the manifold. This lets us extend kernel-based algorithms developed for Euclidean spaces, such as SVM and kernel PCA, to the Riemannian manifold of SPD matrices. We demonstrate the benefits of our approach on the problems of pedestrian detection, object categorization, texture analysis, 2D motion segmentation and Diffusion Tensor Imaging (DTI) segmentation.</p><p>3 0.11087102 <a title="312-tfidf-3" href="./cvpr-2013-Kernel_Learning_for_Extrinsic_Classification_of_Manifold_Features.html">237 cvpr-2013-Kernel Learning for Extrinsic Classification of Manifold Features</a></p>
<p>Author: Raviteja Vemulapalli, Jaishanker K. Pillai, Rama Chellappa</p><p>Abstract: In computer vision applications, features often lie on Riemannian manifolds with known geometry. Popular learning algorithms such as discriminant analysis, partial least squares, support vector machines, etc., are not directly applicable to such features due to the non-Euclidean nature of the underlying spaces. Hence, classification is often performed in an extrinsic manner by mapping the manifolds to Euclidean spaces using kernels. However, for kernel based approaches, poor choice of kernel often results in reduced performance. In this paper, we address the issue of kernelselection for the classification of features that lie on Riemannian manifolds using the kernel learning approach. We propose two criteria for jointly learning the kernel and the classifier using a single optimization problem. Specifically, for the SVM classifier, we formulate the problem of learning a good kernel-classifier combination as a convex optimization problem and solve it efficiently following the multiple kernel learning approach. Experimental results on image set-based classification and activity recognition clearly demonstrate the superiority of the proposed approach over existing methods for classification of manifold features.</p><p>4 0.088842601 <a title="312-tfidf-4" href="./cvpr-2013-Keypoints_from_Symmetries_by_Wave_Propagation.html">240 cvpr-2013-Keypoints from Symmetries by Wave Propagation</a></p>
<p>Author: Samuele Salti, Alessandro Lanza, Luigi Di_Stefano</p><p>Abstract: The paper conjectures and demonstrates that repeatable keypoints based on salient symmetries at different scales can be detected by a novel analysis grounded on the wave equation rather than the heat equation underlying traditional Gaussian scale–space theory. While the image structures found by most state-of-the-art detectors, such as blobs and corners, occur typically on planar highly textured surfaces, salient symmetries are widespread in diverse kinds of images, including those related to untextured objects, which are hardly dealt with by current feature-based recognition pipelines. We provide experimental results on standard datasets and also contribute with a new dataset focused on untextured objects. Based on the positive experimental results, we hope to foster further research on the promising topic ofscale invariant analysis through the wave equation.</p><p>5 0.086895987 <a title="312-tfidf-5" href="./cvpr-2013-Fusing_Depth_from_Defocus_and_Stereo_with_Coded_Apertures.html">181 cvpr-2013-Fusing Depth from Defocus and Stereo with Coded Apertures</a></p>
<p>Author: Yuichi Takeda, Shinsaku Hiura, Kosuke Sato</p><p>Abstract: In this paper we propose a novel depth measurement method by fusing depth from defocus (DFD) and stereo. One of the problems of passive stereo method is the difficulty of finding correct correspondence between images when an object has a repetitive pattern or edges parallel to the epipolar line. On the other hand, the accuracy of DFD method is inherently limited by the effective diameter of the lens. Therefore, we propose the fusion of stereo method and DFD by giving different focus distances for left and right cameras of a stereo camera with coded apertures. Two types of depth cues, defocus and disparity, are naturally integrated by the magnification and phase shift of a single point spread function (PSF) per camera. In this paper we give the proof of the proportional relationship between the diameter of defocus and disparity which makes the calibration easy. We also show the outstanding performance of our method which has both advantages of two depth cues through simulation and actual experiments.</p><p>6 0.086081661 <a title="312-tfidf-6" href="./cvpr-2013-Unnatural_L0_Sparse_Representation_for_Natural_Image_Deblurring.html">449 cvpr-2013-Unnatural L0 Sparse Representation for Natural Image Deblurring</a></p>
<p>7 0.083080702 <a title="312-tfidf-7" href="./cvpr-2013-Blind_Deconvolution_of_Widefield_Fluorescence_Microscopic_Data_by_Regularization_of_the_Optical_Transfer_Function_%28OTF%29.html">65 cvpr-2013-Blind Deconvolution of Widefield Fluorescence Microscopic Data by Regularization of the Optical Transfer Function (OTF)</a></p>
<p>8 0.082207225 <a title="312-tfidf-8" href="./cvpr-2013-First-Person_Activity_Recognition%3A_What_Are_They_Doing_to_Me%3F.html">175 cvpr-2013-First-Person Activity Recognition: What Are They Doing to Me?</a></p>
<p>9 0.078971013 <a title="312-tfidf-9" href="./cvpr-2013-Depth_Acquisition_from_Density_Modulated_Binary_Patterns.html">114 cvpr-2013-Depth Acquisition from Density Modulated Binary Patterns</a></p>
<p>10 0.078866132 <a title="312-tfidf-10" href="./cvpr-2013-Handling_Noise_in_Single_Image_Deblurring_Using_Directional_Filters.html">198 cvpr-2013-Handling Noise in Single Image Deblurring Using Directional Filters</a></p>
<p>11 0.078750513 <a title="312-tfidf-11" href="./cvpr-2013-Supervised_Kernel_Descriptors_for_Visual_Recognition.html">421 cvpr-2013-Supervised Kernel Descriptors for Visual Recognition</a></p>
<p>12 0.076574624 <a title="312-tfidf-12" href="./cvpr-2013-Recovering_Line-Networks_in_Images_by_Junction-Point_Processes.html">351 cvpr-2013-Recovering Line-Networks in Images by Junction-Point Processes</a></p>
<p>13 0.075360477 <a title="312-tfidf-13" href="./cvpr-2013-The_Variational_Structure_of_Disparity_and_Regularization_of_4D_Light_Fields.html">431 cvpr-2013-The Variational Structure of Disparity and Regularization of 4D Light Fields</a></p>
<p>14 0.074748673 <a title="312-tfidf-14" href="./cvpr-2013-Globally_Consistent_Multi-label_Assignment_on_the_Ray_Space_of_4D_Light_Fields.html">188 cvpr-2013-Globally Consistent Multi-label Assignment on the Ray Space of 4D Light Fields</a></p>
<p>15 0.074121803 <a title="312-tfidf-15" href="./cvpr-2013-Principal_Observation_Ray_Calibration_for_Tiled-Lens-Array_Integral_Imaging_Display.html">337 cvpr-2013-Principal Observation Ray Calibration for Tiled-Lens-Array Integral Imaging Display</a></p>
<p>16 0.072878689 <a title="312-tfidf-16" href="./cvpr-2013-What_Object_Motion_Reveals_about_Shape_with_Unknown_BRDF_and_Lighting.html">465 cvpr-2013-What Object Motion Reveals about Shape with Unknown BRDF and Lighting</a></p>
<p>17 0.070753731 <a title="312-tfidf-17" href="./cvpr-2013-Multi-image_Blind_Deblurring_Using_a_Coupled_Adaptive_Sparse_Prior.html">295 cvpr-2013-Multi-image Blind Deblurring Using a Coupled Adaptive Sparse Prior</a></p>
<p>18 0.066403016 <a title="312-tfidf-18" href="./cvpr-2013-A_Theory_of_Refractive_Photo-Light-Path_Triangulation.html">27 cvpr-2013-A Theory of Refractive Photo-Light-Path Triangulation</a></p>
<p>19 0.062146667 <a title="312-tfidf-19" href="./cvpr-2013-Robust_Estimation_of_Nonrigid_Transformation_for_Point_Set_Registration.html">360 cvpr-2013-Robust Estimation of Nonrigid Transformation for Point Set Registration</a></p>
<p>20 0.061710246 <a title="312-tfidf-20" href="./cvpr-2013-Spectral_Modeling_and_Relighting_of_Reflective-Fluorescent_Scenes.html">409 cvpr-2013-Spectral Modeling and Relighting of Reflective-Fluorescent Scenes</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.141), (1, 0.077), (2, -0.032), (3, 0.057), (4, -0.005), (5, 0.035), (6, -0.042), (7, -0.037), (8, -0.028), (9, 0.006), (10, -0.008), (11, 0.002), (12, -0.002), (13, -0.09), (14, -0.1), (15, 0.04), (16, 0.007), (17, 0.0), (18, 0.029), (19, 0.029), (20, -0.034), (21, 0.043), (22, 0.019), (23, 0.046), (24, -0.022), (25, 0.047), (26, -0.03), (27, 0.06), (28, -0.017), (29, 0.041), (30, 0.019), (31, -0.092), (32, 0.027), (33, 0.007), (34, -0.016), (35, -0.09), (36, 0.059), (37, 0.034), (38, 0.026), (39, 0.005), (40, -0.01), (41, -0.006), (42, 0.013), (43, 0.01), (44, 0.019), (45, 0.022), (46, 0.039), (47, -0.034), (48, -0.048), (49, 0.133)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96676886 <a title="312-lsi-1" href="./cvpr-2013-On_a_Link_Between_Kernel_Mean_Maps_and_Fraunhofer_Diffraction%2C_with_an_Application_to_Super-Resolution_Beyond_the_Diffraction_Limit.html">312 cvpr-2013-On a Link Between Kernel Mean Maps and Fraunhofer Diffraction, with an Application to Super-Resolution Beyond the Diffraction Limit</a></p>
<p>Author: Stefan Harmeling, Michael Hirsch, Bernhard Schölkopf</p><p>Abstract: We establish a link between Fourier optics and a recent construction from the machine learning community termed the kernel mean map. Using the Fraunhofer approximation, it identifies the kernel with the squared Fourier transform of the aperture. This allows us to use results about the invertibility of the kernel mean map to provide a statement about the invertibility of Fraunhofer diffraction, showing that imaging processes with arbitrarily small apertures can in principle be invertible, i.e., do not lose information, provided the objects to be imaged satisfy a generic condition. A real world experiment shows that we can super-resolve beyond the Rayleigh limit.</p><p>2 0.70945996 <a title="312-lsi-2" href="./cvpr-2013-Kernel_Methods_on_the_Riemannian_Manifold_of_Symmetric_Positive_Definite_Matrices.html">238 cvpr-2013-Kernel Methods on the Riemannian Manifold of Symmetric Positive Definite Matrices</a></p>
<p>Author: Sadeep Jayasumana, Richard Hartley, Mathieu Salzmann, Hongdong Li, Mehrtash Harandi</p><p>Abstract: Symmetric Positive Definite (SPD) matrices have become popular to encode image information. Accounting for the geometry of the Riemannian manifold of SPD matrices has proven key to the success of many algorithms. However, most existing methods only approximate the true shape of the manifold locally by its tangent plane. In this paper, inspired by kernel methods, we propose to map SPD matrices to a high dimensional Hilbert space where Euclidean geometry applies. To encode the geometry of the manifold in the mapping, we introduce a family of provably positive definite kernels on the Riemannian manifold of SPD matrices. These kernels are derived from the Gaussian kernel, but exploit different metrics on the manifold. This lets us extend kernel-based algorithms developed for Euclidean spaces, such as SVM and kernel PCA, to the Riemannian manifold of SPD matrices. We demonstrate the benefits of our approach on the problems of pedestrian detection, object categorization, texture analysis, 2D motion segmentation and Diffusion Tensor Imaging (DTI) segmentation.</p><p>3 0.63809961 <a title="312-lsi-3" href="./cvpr-2013-Kernel_Learning_for_Extrinsic_Classification_of_Manifold_Features.html">237 cvpr-2013-Kernel Learning for Extrinsic Classification of Manifold Features</a></p>
<p>Author: Raviteja Vemulapalli, Jaishanker K. Pillai, Rama Chellappa</p><p>Abstract: In computer vision applications, features often lie on Riemannian manifolds with known geometry. Popular learning algorithms such as discriminant analysis, partial least squares, support vector machines, etc., are not directly applicable to such features due to the non-Euclidean nature of the underlying spaces. Hence, classification is often performed in an extrinsic manner by mapping the manifolds to Euclidean spaces using kernels. However, for kernel based approaches, poor choice of kernel often results in reduced performance. In this paper, we address the issue of kernelselection for the classification of features that lie on Riemannian manifolds using the kernel learning approach. We propose two criteria for jointly learning the kernel and the classifier using a single optimization problem. Specifically, for the SVM classifier, we formulate the problem of learning a good kernel-classifier combination as a convex optimization problem and solve it efficiently following the multiple kernel learning approach. Experimental results on image set-based classification and activity recognition clearly demonstrate the superiority of the proposed approach over existing methods for classification of manifold features.</p><p>4 0.60537767 <a title="312-lsi-4" href="./cvpr-2013-Blind_Deconvolution_of_Widefield_Fluorescence_Microscopic_Data_by_Regularization_of_the_Optical_Transfer_Function_%28OTF%29.html">65 cvpr-2013-Blind Deconvolution of Widefield Fluorescence Microscopic Data by Regularization of the Optical Transfer Function (OTF)</a></p>
<p>Author: Margret Keuper, Thorsten Schmidt, Maja Temerinac-Ott, Jan Padeken, Patrick Heun, Olaf Ronneberger, Thomas Brox</p><p>Abstract: With volumetric data from widefield fluorescence microscopy, many emerging questions in biological and biomedical research are being investigated. Data can be recorded with high temporal resolution while the specimen is only exposed to a low amount of phototoxicity. These advantages come at the cost of strong recording blur caused by the infinitely extended point spread function (PSF). For widefield microscopy, its magnitude only decays with the square of the distance to the focal point and consists of an airy bessel pattern which is intricate to describe in the spatial domain. However, the Fourier transform of the incoherent PSF (denoted as Optical Transfer Function (OTF)) is well localized and smooth. In this paper, we present a blind -fre iburg .de Figure 1. As for widefield microscopy the convolution ofthe signal deconvolution method that improves results of state-of-theart deconvolution methods on widefield data by exploiting the properties of the widefield OTF.</p><p>5 0.56457198 <a title="312-lsi-5" href="./cvpr-2013-Rolling_Riemannian_Manifolds_to_Solve_the_Multi-class_Classification_Problem.html">367 cvpr-2013-Rolling Riemannian Manifolds to Solve the Multi-class Classification Problem</a></p>
<p>Author: Rui Caseiro, Pedro Martins, João F. Henriques, Fátima Silva Leite, Jorge Batista</p><p>Abstract: In the past few years there has been a growing interest on geometric frameworks to learn supervised classification models on Riemannian manifolds [31, 27]. A popular framework, valid over any Riemannian manifold, was proposed in [31] for binary classification. Once moving from binary to multi-class classification thisparadigm is not valid anymore, due to the spread of multiple positive classes on the manifold [27]. It is then natural to ask whether the multi-class paradigm could be extended to operate on a large class of Riemannian manifolds. We propose a mathematically well-founded classification paradigm that allows to extend the work in [31] to multi-class models, taking into account the structure of the space. The idea is to project all the data from the manifold onto an affine tangent space at a particular point. To mitigate the distortion induced by local diffeomorphisms, we introduce for the first time in the computer vision community a well-founded mathematical concept, so-called Rolling map [21, 16]. The novelty in this alternate school of thought is that the manifold will be firstly rolled (without slipping or twisting) as a rigid body, then the given data is unwrapped onto the affine tangent space, where the classification is performed.</p><p>6 0.54895687 <a title="312-lsi-6" href="./cvpr-2013-MKPLS%3A_Manifold_Kernel_Partial_Least_Squares_for_Lipreading_and_Speaker_Identification.html">276 cvpr-2013-MKPLS: Manifold Kernel Partial Least Squares for Lipreading and Speaker Identification</a></p>
<p>7 0.52802318 <a title="312-lsi-7" href="./cvpr-2013-Discriminative_Brain_Effective_Connectivity_Analysis_for_Alzheimer%27s_Disease%3A_A_Kernel_Learning_Approach_upon_Sparse_Gaussian_Bayesian_Network.html">129 cvpr-2013-Discriminative Brain Effective Connectivity Analysis for Alzheimer's Disease: A Kernel Learning Approach upon Sparse Gaussian Bayesian Network</a></p>
<p>8 0.52437651 <a title="312-lsi-8" href="./cvpr-2013-Globally_Consistent_Multi-label_Assignment_on_the_Ray_Space_of_4D_Light_Fields.html">188 cvpr-2013-Globally Consistent Multi-label Assignment on the Ray Space of 4D Light Fields</a></p>
<p>9 0.51504201 <a title="312-lsi-9" href="./cvpr-2013-Continuous_Inference_in_Graphical_Models_with_Polynomial_Energies.html">95 cvpr-2013-Continuous Inference in Graphical Models with Polynomial Energies</a></p>
<p>10 0.5104081 <a title="312-lsi-10" href="./cvpr-2013-An_Iterated_L1_Algorithm_for_Non-smooth_Non-convex_Optimization_in_Computer_Vision.html">41 cvpr-2013-An Iterated L1 Algorithm for Non-smooth Non-convex Optimization in Computer Vision</a></p>
<p>11 0.50410306 <a title="312-lsi-11" href="./cvpr-2013-The_Variational_Structure_of_Disparity_and_Regularization_of_4D_Light_Fields.html">431 cvpr-2013-The Variational Structure of Disparity and Regularization of 4D Light Fields</a></p>
<p>12 0.49821007 <a title="312-lsi-12" href="./cvpr-2013-Supervised_Kernel_Descriptors_for_Visual_Recognition.html">421 cvpr-2013-Supervised Kernel Descriptors for Visual Recognition</a></p>
<p>13 0.49716249 <a title="312-lsi-13" href="./cvpr-2013-Discrete_MRF_Inference_of_Marginal_Densities_for_Non-uniformly_Discretized_Variable_Space.html">128 cvpr-2013-Discrete MRF Inference of Marginal Densities for Non-uniformly Discretized Variable Space</a></p>
<p>14 0.49573311 <a title="312-lsi-14" href="./cvpr-2013-Stochastic_Deconvolution.html">412 cvpr-2013-Stochastic Deconvolution</a></p>
<p>15 0.49319142 <a title="312-lsi-15" href="./cvpr-2013-Unnatural_L0_Sparse_Representation_for_Natural_Image_Deblurring.html">449 cvpr-2013-Unnatural L0 Sparse Representation for Natural Image Deblurring</a></p>
<p>16 0.48836893 <a title="312-lsi-16" href="./cvpr-2013-A_Practical_Rank-Constrained_Eight-Point_Algorithm_for_Fundamental_Matrix_Estimation.html">23 cvpr-2013-A Practical Rank-Constrained Eight-Point Algorithm for Fundamental Matrix Estimation</a></p>
<p>17 0.48377743 <a title="312-lsi-17" href="./cvpr-2013-A_Divide-and-Conquer_Method_for_Scalable_Low-Rank_Latent_Matrix_Pursuit.html">7 cvpr-2013-A Divide-and-Conquer Method for Scalable Low-Rank Latent Matrix Pursuit</a></p>
<p>18 0.47816733 <a title="312-lsi-18" href="./cvpr-2013-Recovering_Line-Networks_in_Images_by_Junction-Point_Processes.html">351 cvpr-2013-Recovering Line-Networks in Images by Junction-Point Processes</a></p>
<p>19 0.47764856 <a title="312-lsi-19" href="./cvpr-2013-Universality_of_the_Local_Marginal_Polytope.html">448 cvpr-2013-Universality of the Local Marginal Polytope</a></p>
<p>20 0.47601268 <a title="312-lsi-20" href="./cvpr-2013-Multi-image_Blind_Deblurring_Using_a_Coupled_Adaptive_Sparse_Prior.html">295 cvpr-2013-Multi-image Blind Deblurring Using a Coupled Adaptive Sparse Prior</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.151), (16, 0.023), (26, 0.051), (33, 0.18), (67, 0.029), (69, 0.059), (87, 0.098), (96, 0.324)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.79515028 <a title="312-lda-1" href="./cvpr-2013-On_a_Link_Between_Kernel_Mean_Maps_and_Fraunhofer_Diffraction%2C_with_an_Application_to_Super-Resolution_Beyond_the_Diffraction_Limit.html">312 cvpr-2013-On a Link Between Kernel Mean Maps and Fraunhofer Diffraction, with an Application to Super-Resolution Beyond the Diffraction Limit</a></p>
<p>Author: Stefan Harmeling, Michael Hirsch, Bernhard Schölkopf</p><p>Abstract: We establish a link between Fourier optics and a recent construction from the machine learning community termed the kernel mean map. Using the Fraunhofer approximation, it identifies the kernel with the squared Fourier transform of the aperture. This allows us to use results about the invertibility of the kernel mean map to provide a statement about the invertibility of Fraunhofer diffraction, showing that imaging processes with arbitrarily small apertures can in principle be invertible, i.e., do not lose information, provided the objects to be imaged satisfy a generic condition. A real world experiment shows that we can super-resolve beyond the Rayleigh limit.</p><p>2 0.72530425 <a title="312-lda-2" href="./cvpr-2013-Is_There_a_Procedural_Logic_to_Architecture%3F.html">228 cvpr-2013-Is There a Procedural Logic to Architecture?</a></p>
<p>Author: Julien Weissenberg, Hayko Riemenschneider, Mukta Prasad, Luc Van_Gool</p><p>Abstract: Urban models are key to navigation, architecture and entertainment. Apart from visualizing fa ¸cades, a number of tedious tasks remain largely manual (e.g. compression, generating new fac ¸ade designs and structurally comparing fa c¸ades for classification, retrieval and clustering). We propose a novel procedural modelling method to automatically learn a grammar from a set of fa c¸ades, generate new fa ¸cade instances and compare fa ¸cades. To deal with the difficulty of grammatical inference, we reformulate the problem. Instead of inferring a compromising, onesize-fits-all, single grammar for all tasks, we infer a model whose successive refinements are production rules tailored for each task. We demonstrate our automatic rule inference on datasets of two different architectural styles. Our method supercedes manual expert work and cuts the time required to build a procedural model of a fa ¸cade from several days to a few milliseconds.</p><p>3 0.70798141 <a title="312-lda-3" href="./cvpr-2013-Improving_the_Visual_Comprehension_of_Point_Sets.html">218 cvpr-2013-Improving the Visual Comprehension of Point Sets</a></p>
<p>Author: Sagi Katz, Ayellet Tal</p><p>Abstract: Point sets are the standard output of many 3D scanning systems and depth cameras. Presenting the set of points as is, might “hide ” the prominent features of the object from which the points are sampled. Our goal is to reduce the number of points in a point set, for improving the visual comprehension from a given viewpoint. This is done by controlling the density of the reduced point set, so as to create bright regions (low density) and dark regions (high density), producing an effect of shading. This data reduction is achieved by leveraging a limitation of a solution to the classical problem of determining visibility from a viewpoint. In addition, we introduce a new dual problem, for determining visibility of a point from infinity, and show how a limitation of its solution can be leveraged in a similar way.</p><p>4 0.69654614 <a title="312-lda-4" href="./cvpr-2013-The_Variational_Structure_of_Disparity_and_Regularization_of_4D_Light_Fields.html">431 cvpr-2013-The Variational Structure of Disparity and Regularization of 4D Light Fields</a></p>
<p>Author: Bastian Goldluecke, Sven Wanner</p><p>Abstract: Unlike traditional images which do not offer information for different directions of incident light, a light field is defined on ray space, and implicitly encodes scene geometry data in a rich structure which becomes visible on its epipolar plane images. In this work, we analyze regularization of light fields in variational frameworks and show that their variational structure is induced by disparity, which is in this context best understood as a vector field on epipolar plane image space. We derive differential constraints on this vector field to enable consistent disparity map regularization. Furthermore, we show how the disparity field is related to the regularization of more general vector-valued functions on the 4D ray space of the light field. This way, we derive an efficient variational framework with convex priors, which can serve as a fundament for a large class of inverse problems on ray space.</p><p>5 0.62572134 <a title="312-lda-5" href="./cvpr-2013-Globally_Consistent_Multi-label_Assignment_on_the_Ray_Space_of_4D_Light_Fields.html">188 cvpr-2013-Globally Consistent Multi-label Assignment on the Ray Space of 4D Light Fields</a></p>
<p>Author: Sven Wanner, Christoph Straehle, Bastian Goldluecke</p><p>Abstract: Wepresent thefirst variationalframeworkfor multi-label segmentation on the ray space of 4D light fields. For traditional segmentation of single images, , features need to be extractedfrom the 2Dprojection ofa three-dimensional scene. The associated loss of geometry information can cause severe problems, for example if different objects have a very similar visual appearance. In this work, we show that using a light field instead of an image not only enables to train classifiers which can overcome many of these problems, but also provides an optimal data structure for label optimization by implicitly providing scene geometry information. It is thus possible to consistently optimize label assignment over all views simultaneously. As a further contribution, we make all light fields available online with complete depth and segmentation ground truth data where available, and thus establish the first benchmark data set for light field analysis to facilitate competitive further development of algorithms.</p><p>6 0.61923236 <a title="312-lda-6" href="./cvpr-2013-Kernel_Null_Space_Methods_for_Novelty_Detection.html">239 cvpr-2013-Kernel Null Space Methods for Novelty Detection</a></p>
<p>7 0.6016956 <a title="312-lda-7" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>8 0.59892184 <a title="312-lda-8" href="./cvpr-2013-Explicit_Occlusion_Modeling_for_3D_Object_Class_Representations.html">154 cvpr-2013-Explicit Occlusion Modeling for 3D Object Class Representations</a></p>
<p>9 0.5985651 <a title="312-lda-9" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<p>10 0.59766614 <a title="312-lda-10" href="./cvpr-2013-Single_Image_Calibration_of_Multi-axial_Imaging_Systems.html">400 cvpr-2013-Single Image Calibration of Multi-axial Imaging Systems</a></p>
<p>11 0.59761918 <a title="312-lda-11" href="./cvpr-2013-Can_a_Fully_Unconstrained_Imaging_Model_Be_Applied_Effectively_to_Central_Cameras%3F.html">76 cvpr-2013-Can a Fully Unconstrained Imaging Model Be Applied Effectively to Central Cameras?</a></p>
<p>12 0.59725493 <a title="312-lda-12" href="./cvpr-2013-Multi-scale_Curve_Detection_on_Surfaces.html">298 cvpr-2013-Multi-scale Curve Detection on Surfaces</a></p>
<p>13 0.59667391 <a title="312-lda-13" href="./cvpr-2013-Physically_Plausible_3D_Scene_Tracking%3A_The_Single_Actor_Hypothesis.html">331 cvpr-2013-Physically Plausible 3D Scene Tracking: The Single Actor Hypothesis</a></p>
<p>14 0.59568512 <a title="312-lda-14" href="./cvpr-2013-A_Minimum_Error_Vanishing_Point_Detection_Approach_for_Uncalibrated_Monocular_Images_of_Man-Made_Environments.html">19 cvpr-2013-A Minimum Error Vanishing Point Detection Approach for Uncalibrated Monocular Images of Man-Made Environments</a></p>
<p>15 0.5955531 <a title="312-lda-15" href="./cvpr-2013-Separating_Signal_from_Noise_Using_Patch_Recurrence_across_Scales.html">393 cvpr-2013-Separating Signal from Noise Using Patch Recurrence across Scales</a></p>
<p>16 0.59546447 <a title="312-lda-16" href="./cvpr-2013-GeoF%3A_Geodesic_Forests_for_Learning_Coupled_Predictors.html">186 cvpr-2013-GeoF: Geodesic Forests for Learning Coupled Predictors</a></p>
<p>17 0.59544611 <a title="312-lda-17" href="./cvpr-2013-Voxel_Cloud_Connectivity_Segmentation_-_Supervoxels_for_Point_Clouds.html">458 cvpr-2013-Voxel Cloud Connectivity Segmentation - Supervoxels for Point Clouds</a></p>
<p>18 0.59519547 <a title="312-lda-18" href="./cvpr-2013-Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking.html">285 cvpr-2013-Minimum Uncertainty Gap for Robust Visual Tracking</a></p>
<p>19 0.59515548 <a title="312-lda-19" href="./cvpr-2013-Structure_Preserving_Object_Tracking.html">414 cvpr-2013-Structure Preserving Object Tracking</a></p>
<p>20 0.59434557 <a title="312-lda-20" href="./cvpr-2013-Stochastic_Deconvolution.html">412 cvpr-2013-Stochastic Deconvolution</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
