<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>438 cvpr-2013-Towards Pose Robust Face Recognition</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-438" href="#">cvpr2013-438</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>438 cvpr-2013-Towards Pose Robust Face Recognition</h1>
<br/><p>Source: <a title="cvpr-2013-438-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Yi_Towards_Pose_Robust_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Dong Yi, Zhen Lei, Stan Z. Li</p><p>Abstract: Most existing pose robust methods are too computational complex to meet practical applications and their performance under unconstrained environments are rarely evaluated. In this paper, we propose a novel method for pose robust face recognition towards practical applications, which is fast, pose robust and can work well under unconstrained environments. Firstly, a 3D deformable model is built and a fast 3D model fitting algorithm is proposed to estimate the pose of face image. Secondly, a group of Gabor filters are transformed according to the pose and shape of face image for feature extraction. Finally, PCA is applied on the pose adaptive Gabor features to remove the redundances and Cosine metric is used to evaluate the similarity. The proposed method has three advantages: (1) The pose correction is applied in the filter space rather than image space, which makes our method less affected by the precision of the 3D model; (2) By combining the holistic pose transformation and local Gabor filtering, the final feature is robust to pose and other negative factors in face recognition; (3) The 3D structure and facial symmetry are successfully used to deal with self-occlusion. Extensive experiments on FERET and PIE show the proposed method outperforms state-ofthe-art methods significantly, meanwhile, the method works well on LFW.</p><p>Reference: <a title="cvpr-2013-438-reference" href="../cvpr2013_reference/cvpr-2013-Towards_Pose_Robust_Face_Recognition_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 cn i  Abstract Most existing pose robust methods are too computational complex to meet practical applications and their performance under unconstrained environments are rarely evaluated. [sent-5, score-0.442]
</p><p>2 In this paper, we propose a novel method for pose robust face recognition towards practical applications, which is fast, pose robust and can work well under unconstrained environments. [sent-6, score-1.209]
</p><p>3 Firstly, a 3D deformable model is built and a fast 3D model fitting algorithm is proposed to estimate the pose of face image. [sent-7, score-0.801]
</p><p>4 Secondly, a group of Gabor filters are transformed according to the pose and shape of face image for feature extraction. [sent-8, score-0.845]
</p><p>5 Finally, PCA is applied on the pose adaptive Gabor features to remove the redundances and Cosine metric is used to evaluate the similarity. [sent-9, score-0.308]
</p><p>6 Introduction Comparing with other biometrics, the most superiority of face biometric is its non-intrusive nature. [sent-13, score-0.478]
</p><p>7 Therefore, face is one of the most suitable biometrics for surveillance applications. [sent-14, score-0.509]
</p><p>8 This leads to a problem in face recognition, unconstrained face recognition. [sent-17, score-0.966]
</p><p>9 Most face images captured by surveillance systems are non-ideal, because they are often affected by many factors: pose, illumination, expression, occlusion, distance, weather and so on. [sent-18, score-0.468]
</p><p>10 This paper will mainly focus on the pose problem while considering the other factors together. [sent-19, score-0.302]
</p><p>11 From the early stages of face recognition research to now [3 1], pose variation was always considered as an important problem. [sent-20, score-0.808]
</p><p>12 However, none of them is free from limitations and  is able to fully solve the pose problem. [sent-22, score-0.273]
</p><p>13 As noted in a recent survey [28], the protocols for testing face recognition across pose are even not unified, which indicates we still have a long way to build a fully pose invariant face recognition system. [sent-23, score-1.566]
</p><p>14 Because the pose variation is essentially caused by the 3D rigid motion of face, 3D model based methods generally have higher precision than 2D methods. [sent-25, score-0.34]
</p><p>15 3D methods are always based on a 3D face model, which may be a single model, or a deformable model in certain parametric forms. [sent-35, score-0.498]
</p><p>16 The flexibility and precision of the 3D face model is the core of 3D methods, therefore we usually call them as 3D model assisted methods. [sent-36, score-0.487]
</p><p>17 Four kinds of 3D methods for pose robust face recognition: (A) Pose normalization. [sent-38, score-0.77]
</p><p>18 the quality of on-site face images (probe) are uncontrolled. [sent-42, score-0.447]
</p><p>19 Pose Normalization: Face images in the probe are normalized to frontal view based on the 3D model, and then match the normalized probe to the gallery [2]. [sent-44, score-0.375]
</p><p>20 Pose Synthesis: Use the 3D model to generate some virtual face images with various poses for the face images in the gallery, and then match the probe to the virtual face images [30, 28]. [sent-46, score-1.48]
</p><p>21 Recognition by Fitting: Fit all face images in the gallery and probe by the 3D model. [sent-48, score-0.666]
</p><p>22 The texture and shape parameters are used for face recognition [3]. [sent-49, score-0.573]
</p><p>23 Filter Transformation: Transform the filters according to the pose and shape of face image, and then use the pose adapted filters for feature extraction. [sent-51, score-1.167]
</p><p>24 As reported in existing papers, the first three kinds of methods all need several minutes to process a face image and their recognition rates are heavily dependent on the precision of the 3D model and optimization algorithm. [sent-54, score-0.595]
</p><p>25 On the contrary, filter transformation is efficient, because it doesn’t need to fit the 3D model to face image in high precision and manipulate the texture of 3D model. [sent-55, score-0.63]
</p><p>26 Once having the pose and shape of face image, we can transform the filters to adapt to the face image. [sent-56, score-1.257]
</p><p>27 A early paper [14] has used this idea to achieve good results on the pose problem, in which Gabor filters were transformed according to the pose  and normal direction of face surface to construct pose robust features. [sent-57, score-1.373]
</p><p>28 However, this idea rarely got the attention of face recognition community since then. [sent-58, score-0.536]
</p><p>29 Limited by the face recognition technologies at that time, the method in [14] is obscure and need many manual steps to construct the whole system. [sent-59, score-0.51]
</p><p>30 We revisit the filter transformation based methods for the pose problem, which has been neglected for a long time. [sent-65, score-0.394]
</p><p>31 Inspired by this idea, many filters could be extended for the pose problem, such as Gabor, LBP, HOG and so on. [sent-66, score-0.322]
</p><p>32 In the framework of filter transformation, we propose a novel pose robust face recognition method, which is both robust to pose variations and other negative factors in face recognition. [sent-68, score-1.697]
</p><p>33 To meet the speed requirement of practical systems, we propose a fast 3D model fitting algorithm with acceptable precision for face recognition. [sent-70, score-0.586]
</p><p>34 We improve the state-of-the-art recognition rate across pose on the FERET and PIE databases. [sent-74, score-0.336]
</p><p>35 Pose Adaptive Filter The proposed method in this paper is belong to the fourth category: filter transformation, the main idea of which is transforming filter according to the pose and shape of face image and then using the transformed filter to extract pose robust features. [sent-77, score-1.249]
</p><p>36 Given a 2D face image, we get its pose and shape by fitting the 3D model to the image and then project the defined 3D feature points to the image plane. [sent-82, score-0.954]
</p><p>37 Finally, pose robust features are extracted at the projected feature points by Gabor filters. [sent-83, score-0.379]
</p><p>38 3D Model and Feature Points Definition Our 3D face model is similar to the shape part of classical 3D Morphable Model (3DMM) [3], and drops the texture part. [sent-86, score-0.51]
</p><p>39 Right: User defined 2D feature points on face image. [sent-92, score-0.524]
</p><p>40 Bottom: Our feature points defined on the surface of 3D face model. [sent-93, score-0.553]
</p><p>41 Because the original 3D face have var-  1  ×  ious poses and their cloud points are partial missing, we fit these faces by a generic 3D model with 33640 vertexes and 66750 triangles [5]. [sent-95, score-0.619]
</p><p>42 Apply PCA on the aligned 3D faces, we get a deformable 3D face model composed by the mean shape m, eigenvalues σ and eigen-shapes w. [sent-97, score-0.568]
</p><p>43 For most face recognition methods, features are usually extracted on uniform grid [1] or feature points defined on image plane [26]. [sent-99, score-0.616]
</p><p>44 For in-plane rotation, the uniform grid or 2D feature points can easily adapt to the face image by a similarity transformation, but they cannot work for outof-plane rotation. [sent-100, score-0.524]
</p><p>45 To deal with real 3D pose variations, we will define feature points on the surface of 3D face model, which is shown in Fig. [sent-101, score-0.855]
</p><p>46 By mirroring the points at the right half according to facial symmetry, we get 176 2 = 352 feature points. [sent-115, score-0.291]
</p><p>47 The advantages of the symmetric structure of the feature points will be illustrated in experiments, which is effective to deal with self-occlusion caused by pose variations. [sent-118, score-0.379]
</p><p>48 Fast 3D Model Fitting  3DMM [3] is the most popular model to estimate the pose, lighting, shape and texture parameters of face image. [sent-122, score-0.51]
</p><p>49 But for a face image, 3DMM usually need several minutes to obtain good result. [sent-124, score-0.447]
</p><p>50 To appeal the time requirement of practical systems, we propose a fast algorithm to solve the pose and shape parameters, while neglect the other parameters. [sent-125, score-0.337]
</p><p>51 Compared to 3DMM, our algorithm has lower precision but is good enough for face recognition across pose. [sent-126, score-0.55]
</p><p>52 The final three-view landmarker can detect the landmarks well on face images from -60 to 60 degree. [sent-138, score-0.6]
</p><p>53 Note that we just use the 34 of 76 landmarks because those landmarks on the boundary of face are unstable to pose variations [2]. [sent-139, score-0.939]
</p><p>54 Given a face image, landmarks x on the face image, and their corresponding vertex index I the 3D model, we can on solve the pose T of face and the shape parameter α by optimizing the following problem. [sent-141, score-1.774]
</p><p>55 After getting T and α, we say T is the pose of the face image, and its corresponding 3D shape S can be reconstructed by Equ. [sent-159, score-0.761]
</p><p>56 Pose Adaptive Feature Extraction Mapping the face image to the vertexes of S, we can get a 3D face with texture, using which we could synthesize face images with new poses. [sent-163, score-1.405]
</p><p>57 Because the fitting algorithm is coarse and the reconstructed 3D face is far from perfect, we don’t use this model to generate face images in PAF. [sent-164, score-0.949]
</p><p>58 S is just used as a mid-man to extract pose adaptive features. [sent-165, score-0.308]
</p><p>59 1, the 3D feature points are defined on the surface of 3D face and denoted by the vertex index J. [sent-167, score-0.585]
</p><p>60 By projecting S to the image plane, we can get the 2D coordinates of the feature points TS(J) on the face image. [sent-168, score-0.556]
</p><p>61 4, from which we can see feature points always have fixed semantic meaning for face images with various poses, i. [sent-170, score-0.549]
</p><p>62 Three face images of the same  × ×  subject are shown and their feature points are marked by red dots. [sent-176, score-0.524]
</p><p>63 gBiveciangus 5e ×the 8 phase information is sensitive to mis-alignment, we drop the phase and use the amplitude as feature for face recognition. [sent-180, score-0.58]
</p><p>64 By using zbuffer algorithm [25], the occluded area can be easily got based on the pose T and 3D shape S. [sent-185, score-0.34]
</p><p>65 In summary, the proposed PAF deals with pose variations from four aspects: holistic rigid transformation, non-rigid shape deformation, local Gabor filtering, and “half face” selection by facial symmetry. [sent-187, score-0.499]
</p><p>66 By combining rigid, non-rigid transformations and local Gabor feature, PAF is robust to  pose variations and other factors. [sent-188, score-0.347]
</p><p>67 As the most widely used database in the pose problem, PIE is further used for comparing PAF with state-of-the-art methods. [sent-193, score-0.305]
</p><p>68 Data Description FERET has been used to evaluate the robustness of face recognition system to pose in FRVT 2000 [16]. [sent-197, score-0.783]
</p><p>69 In the ex333555444200  periments, 200 frontal images are used as gallery, and face images with pose variations are used as probe. [sent-199, score-0.833]
</p><p>70 The face images in the training set are all fontal. [sent-201, score-0.447]
</p><p>71 Because most of existing methods have reported their results on PIE, the comparison with state-of-the-art methods  is further performed on the expression subset of PIE, with frontal pose as gallery and the remaining 12 poses as probes. [sent-202, score-0.547]
</p><p>72 Good pose robust face algorithms should perform well against not only pose variations but also other factors. [sent-207, score-1.067]
</p><p>73 LFW is the best database to evaluate the overall performance of face recognition algorithms under unconstrained environments. [sent-208, score-0.614]
</p><p>74 2L: Two landmarks based alignment (the center of two eyes and the center of mouth), and the full face is used for face recognition. [sent-217, score-1.003]
</p><p>75 2L-Half: Two landmarks based alignment, and the lesser-occluded half of face is used for face recogni-  tion. [sent-219, score-1.022]
</p><p>76 PN: All face images are normalized to frontal pose by the 3D model in Subsection 2. [sent-221, score-0.788]
</p><p>77 Then face recognition is performed on the normalized face images. [sent-224, score-0.957]
</p><p>78 The proposed method (PAF): The filters are adapted to the pose of face images, and the pose adaptive features are extracted for face recognition. [sent-226, score-1.524]
</p><p>79 0%, which illustrates the importance of facial symmetry in pose problem. [sent-240, score-0.455]
</p><p>80 PN applies pose normalization in the image space using the same 3D model and algorithm with PAF, therefore, PN would be expected to have comparable performance with PAF. [sent-241, score-0.325]
</p><p>81 Table 1 also list three latest methods for reference, in which the automatic pose normalization proposed in [2] is very similar to our PN baseline. [sent-244, score-0.352]
</p><p>82 This phenomenon indicates that we should focus more  on large pose variations (> 45 degree) in the future. [sent-260, score-0.318]
</p><p>83 Unconstrained Face Recognition As the most challenging database in face recognition community, LFW nearly contains all typical variations of face image. [sent-268, score-1.034]
</p><p>84 All face images in LFW are processed by the assembly line described in Section 2, and then the results are reported according to the restricted protocol. [sent-274, score-0.471]
</p><p>85 Conclusions Pose is a challenging and unsolved problem in face recognition. [sent-293, score-0.447]
</p><p>86 And the pose problem is usually coupled with other factors to jointly affect the performance of practical face recognition systems. [sent-294, score-0.86]
</p><p>87 To build a fast and pose robust face recognition system, this paper proposed a method PAF to transform filters according to the pose of face image and extract pose adaptive features. [sent-295, score-1.889]
</p><p>88 From the results on FERET and PIE, we can see PAF outperforms other compared pose 333555444422  robust methods significantly. [sent-298, score-0.302]
</p><p>89 “Fully automatic pose-invariant face recognition via 3d pose normalization”. [sent-317, score-0.806]
</p><p>90 “3D morphable model construction for robust ear and face recognition”. [sent-340, score-0.544]
</p><p>91 “Beyond simple features: A large-scale feature search approach to unconstrained face recognition”. [sent-362, score-0.554]
</p><p>92 “From few to many: Illumination cone models for face recognition under variable lighting and pose”. [sent-371, score-0.533]
</p><p>93 “Toward pose-invariant 2-d face recognition through point distribution models and facial symmetry”. [sent-377, score-0.623]
</p><p>94 “Labeled faces in the wild: A database for studying face recognition in unconstrained environments”. [sent-397, score-0.661]
</p><p>95 “Using facial symmetry to handle pose variations in real-world 3d face recog-  [19]  [20]  [21]  [22]  [23]  [24]  [25] [26]  [27] [28] [29]  [30]  nition”. [sent-436, score-0.947]
</p><p>96 “The feret database and evaluation procedure for face recognition algorithms”. [sent-448, score-0.769]
</p><p>97 “Probabilistic learning for fully automatic face recognition across pose”. [sent-453, score-0.533]
</p><p>98 “Robust pose invariant face recognition using coupled latent space discriminant analysis”. [sent-464, score-0.808]
</p><p>99 Fast matching by 2 lines of code for large scale face recognition systems. [sent-509, score-0.51]
</p><p>100 “Heterogeneous specular and diffuse 3-d surface approximation for face recognition across pose”. [sent-520, score-0.539]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('paf', 0.622), ('face', 0.447), ('pose', 0.273), ('feret', 0.227), ('pie', 0.135), ('gallery', 0.131), ('gabor', 0.113), ('facial', 0.113), ('lfw', 0.104), ('probe', 0.088), ('landmarks', 0.087), ('pn', 0.087), ('unconstrained', 0.072), ('symmetry', 0.069), ('morphable', 0.068), ('frontal', 0.068), ('forensics', 0.066), ('landmarker', 0.066), ('recognition', 0.063), ('filter', 0.062), ('transformation', 0.059), ('pca', 0.056), ('fitting', 0.055), ('security', 0.051), ('poses', 0.051), ('filters', 0.049), ('phase', 0.049), ('faces', 0.047), ('variations', 0.045), ('frvt', 0.044), ('iwi', 0.044), ('landmarking', 0.044), ('maurer', 0.044), ('muct', 0.044), ('points', 0.042), ('half', 0.041), ('biometrics', 0.041), ('shape', 0.041), ('precision', 0.04), ('wave', 0.04), ('transactions', 0.039), ('cls', 0.039), ('mint', 0.039), ('conference', 0.037), ('elf', 0.036), ('proceedings', 0.036), ('lei', 0.035), ('adaptive', 0.035), ('feature', 0.035), ('bif', 0.034), ('hussain', 0.034), ('gesture', 0.033), ('vertex', 0.032), ('vertexes', 0.032), ('probes', 0.032), ('database', 0.032), ('get', 0.032), ('halves', 0.031), ('normalization', 0.031), ('superiority', 0.031), ('project', 0.029), ('deal', 0.029), ('factors', 0.029), ('plane', 0.029), ('lbp', 0.029), ('surface', 0.029), ('robust', 0.029), ('mirroring', 0.028), ('asm', 0.027), ('phillips', 0.027), ('rigid', 0.027), ('pattern', 0.027), ('got', 0.026), ('deformable', 0.026), ('always', 0.025), ('coupled', 0.025), ('ul', 0.025), ('latest', 0.025), ('intelligence', 0.025), ('mouth', 0.024), ('ieee', 0.024), ('environments', 0.024), ('databases', 0.024), ('pages', 0.024), ('nose', 0.024), ('reported', 0.024), ('cone', 0.023), ('matthews', 0.023), ('automatic', 0.023), ('practical', 0.023), ('gross', 0.022), ('composed', 0.022), ('alignment', 0.022), ('texture', 0.022), ('meet', 0.021), ('experts', 0.021), ('kinds', 0.021), ('surveillance', 0.021), ('international', 0.021), ('comparable', 0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="438-tfidf-1" href="./cvpr-2013-Towards_Pose_Robust_Face_Recognition.html">438 cvpr-2013-Towards Pose Robust Face Recognition</a></p>
<p>Author: Dong Yi, Zhen Lei, Stan Z. Li</p><p>Abstract: Most existing pose robust methods are too computational complex to meet practical applications and their performance under unconstrained environments are rarely evaluated. In this paper, we propose a novel method for pose robust face recognition towards practical applications, which is fast, pose robust and can work well under unconstrained environments. Firstly, a 3D deformable model is built and a fast 3D model fitting algorithm is proposed to estimate the pose of face image. Secondly, a group of Gabor filters are transformed according to the pose and shape of face image for feature extraction. Finally, PCA is applied on the pose adaptive Gabor features to remove the redundances and Cosine metric is used to evaluate the similarity. The proposed method has three advantages: (1) The pose correction is applied in the filter space rather than image space, which makes our method less affected by the precision of the 3D model; (2) By combining the holistic pose transformation and local Gabor filtering, the final feature is robust to pose and other negative factors in face recognition; (3) The 3D structure and facial symmetry are successfully used to deal with self-occlusion. Extensive experiments on FERET and PIE show the proposed method outperforms state-ofthe-art methods significantly, meanwhile, the method works well on LFW.</p><p>2 0.28897798 <a title="438-tfidf-2" href="./cvpr-2013-Detecting_and_Aligning_Faces_by_Image_Retrieval.html">119 cvpr-2013-Detecting and Aligning Faces by Image Retrieval</a></p>
<p>Author: Xiaohui Shen, Zhe Lin, Jonathan Brandt, Ying Wu</p><p>Abstract: Detecting faces in uncontrolled environments continues to be a challenge to traditional face detection methods[24] due to the large variation in facial appearances, as well as occlusion and clutter. In order to overcome these challenges, we present a novel and robust exemplarbased face detector that integrates image retrieval and discriminative learning. A large database of faces with bounding rectangles and facial landmark locations is collected, and simple discriminative classifiers are learned from each of them. A voting-based method is then proposed to let these classifiers cast votes on the test image through an efficient image retrieval technique. As a result, faces can be very efficiently detected by selecting the modes from the voting maps, without resorting to exhaustive sliding window-style scanning. Moreover, due to the exemplar-based framework, our approach can detect faces under challenging conditions without explicitly modeling their variations. Evaluation on two public benchmark datasets shows that our new face detection approach is accurate and efficient, and achieves the state-of-the-art performance. We further propose to use image retrieval for face validation (in order to remove false positives) and for face alignment/landmark localization. The same methodology can also be easily generalized to other facerelated tasks, such as attribute recognition, as well as general object detection.</p><p>3 0.27381861 <a title="438-tfidf-3" href="./cvpr-2013-Probabilistic_Elastic_Matching_for_Pose_Variant_Face_Verification.html">338 cvpr-2013-Probabilistic Elastic Matching for Pose Variant Face Verification</a></p>
<p>Author: Haoxiang Li, Gang Hua, Zhe Lin, Jonathan Brandt, Jianchao Yang</p><p>Abstract: Pose variation remains to be a major challenge for realworld face recognition. We approach this problem through a probabilistic elastic matching method. We take a part based representation by extracting local features (e.g., LBP or SIFT) from densely sampled multi-scale image patches. By augmenting each feature with its location, a Gaussian mixture model (GMM) is trained to capture the spatialappearance distribution of all face images in the training corpus. Each mixture component of the GMM is confined to be a spherical Gaussian to balance the influence of the appearance and the location terms. Each Gaussian component builds correspondence of a pair of features to be matched between two faces/face tracks. For face verification, we train an SVM on the vector concatenating the difference vectors of all the feature pairs to decide if a pair of faces/face tracks is matched or not. We further propose a joint Bayesian adaptation algorithm to adapt the universally trained GMM to better model the pose variations between the target pair of faces/face tracks, which consistently improves face verification accuracy. Our experiments show that our method outperforms the state-ofthe-art in the most restricted protocol on Labeled Face in the Wild (LFW) and the YouTube video face database by a significant margin.</p><p>4 0.25027129 <a title="438-tfidf-4" href="./cvpr-2013-Fusing_Robust_Face_Region_Descriptors_via_Multiple_Metric_Learning_for_Face_Recognition_in_the_Wild.html">182 cvpr-2013-Fusing Robust Face Region Descriptors via Multiple Metric Learning for Face Recognition in the Wild</a></p>
<p>Author: Zhen Cui, Wen Li, Dong Xu, Shiguang Shan, Xilin Chen</p><p>Abstract: In many real-world face recognition scenarios, face images can hardly be aligned accurately due to complex appearance variations or low-quality images. To address this issue, we propose a new approach to extract robust face region descriptors. Specifically, we divide each image (resp. video) into several spatial blocks (resp. spatial-temporal volumes) and then represent each block (resp. volume) by sum-pooling the nonnegative sparse codes of position-free patches sampled within the block (resp. volume). Whitened Principal Component Analysis (WPCA) is further utilized to reduce the feature dimension, which leads to our Spatial Face Region Descriptor (SFRD) (resp. Spatial-Temporal Face Region Descriptor, STFRD) for images (resp. videos). Moreover, we develop a new distance method for face verification metric learning called Pairwise-constrained Multiple Metric Learning (PMML) to effectively integrate the face region descriptors of all blocks (resp. volumes) from an image (resp. a video). Our work achieves the state- of-the-art performances on two real-world datasets LFW and YouTube Faces (YTF) according to the restricted protocol.</p><p>5 0.24638732 <a title="438-tfidf-5" href="./cvpr-2013-Blessing_of_Dimensionality%3A_High-Dimensional_Feature_and_Its_Efficient_Compression_for_Face_Verification.html">64 cvpr-2013-Blessing of Dimensionality: High-Dimensional Feature and Its Efficient Compression for Face Verification</a></p>
<p>Author: Dong Chen, Xudong Cao, Fang Wen, Jian Sun</p><p>Abstract: Making a high-dimensional (e.g., 100K-dim) feature for face recognition seems not a good idea because it will bring difficulties on consequent training, computation, and storage. This prevents further exploration of the use of a highdimensional feature. In this paper, we study the performance of a highdimensional feature. We first empirically show that high dimensionality is critical to high performance. A 100K-dim feature, based on a single-type Local Binary Pattern (LBP) descriptor, can achieve significant improvements over both its low-dimensional version and the state-of-the-art. We also make the high-dimensional feature practical. With our proposed sparse projection method, named rotated sparse regression, both computation and model storage can be reduced by over 100 times without sacrificing accuracy quality.</p><p>6 0.23545307 <a title="438-tfidf-6" href="./cvpr-2013-Face_Recognition_in_Movie_Trailers_via_Mean_Sequence_Sparse_Representation-Based_Classification.html">160 cvpr-2013-Face Recognition in Movie Trailers via Mean Sequence Sparse Representation-Based Classification</a></p>
<p>7 0.231359 <a title="438-tfidf-7" href="./cvpr-2013-Facial_Feature_Tracking_Under_Varying_Facial_Expressions_and_Face_Poses_Based_on_Restricted_Boltzmann_Machines.html">161 cvpr-2013-Facial Feature Tracking Under Varying Facial Expressions and Face Poses Based on Restricted Boltzmann Machines</a></p>
<p>8 0.20564258 <a title="438-tfidf-8" href="./cvpr-2013-Constrained_Clustering_and_Its_Application_to_Face_Clustering_in_Videos.html">92 cvpr-2013-Constrained Clustering and Its Application to Face Clustering in Videos</a></p>
<p>9 0.19955602 <a title="438-tfidf-9" href="./cvpr-2013-Single-Sample_Face_Recognition_with_Image_Corruption_and_Misalignment_via_Sparse_Illumination_Transfer.html">399 cvpr-2013-Single-Sample Face Recognition with Image Corruption and Misalignment via Sparse Illumination Transfer</a></p>
<p>10 0.19100611 <a title="438-tfidf-10" href="./cvpr-2013-Exemplar-Based_Face_Parsing.html">152 cvpr-2013-Exemplar-Based Face Parsing</a></p>
<p>11 0.16589181 <a title="438-tfidf-11" href="./cvpr-2013-Class_Generative_Models_Based_on_Feature_Regression_for_Pose_Estimation_of_Object_Categories.html">82 cvpr-2013-Class Generative Models Based on Feature Regression for Pose Estimation of Object Categories</a></p>
<p>12 0.15249638 <a title="438-tfidf-12" href="./cvpr-2013-In_Defense_of_Sparsity_Based_Face_Recognition.html">220 cvpr-2013-In Defense of Sparsity Based Face Recognition</a></p>
<p>13 0.14460234 <a title="438-tfidf-13" href="./cvpr-2013-Unconstrained_Monocular_3D_Human_Pose_Estimation_by_Action_Detection_and_Cross-Modality_Regression_Forest.html">444 cvpr-2013-Unconstrained Monocular 3D Human Pose Estimation by Action Detection and Cross-Modality Regression Forest</a></p>
<p>14 0.12695375 <a title="438-tfidf-14" href="./cvpr-2013-The_SVM-Minus_Similarity_Score_for_Video_Face_Recognition.html">430 cvpr-2013-The SVM-Minus Similarity Score for Video Face Recognition</a></p>
<p>15 0.119828 <a title="438-tfidf-15" href="./cvpr-2013-A_Joint_Model_for_2D_and_3D_Pose_Estimation_from_a_Single_Image.html">14 cvpr-2013-A Joint Model for 2D and 3D Pose Estimation from a Single Image</a></p>
<p>16 0.11842123 <a title="438-tfidf-16" href="./cvpr-2013-Learning_SURF_Cascade_for_Fast_and_Accurate_Object_Detection.html">254 cvpr-2013-Learning SURF Cascade for Fast and Accurate Object Detection</a></p>
<p>17 0.11721221 <a title="438-tfidf-17" href="./cvpr-2013-Structured_Face_Hallucination.html">415 cvpr-2013-Structured Face Hallucination</a></p>
<p>18 0.11693371 <a title="438-tfidf-18" href="./cvpr-2013-Robust_Discriminative_Response_Map_Fitting_with_Constrained_Local_Models.html">359 cvpr-2013-Robust Discriminative Response Map Fitting with Constrained Local Models</a></p>
<p>19 0.1144708 <a title="438-tfidf-19" href="./cvpr-2013-Semi-supervised_Learning_with_Constraints_for_Person_Identification_in_Multimedia_Data.html">389 cvpr-2013-Semi-supervised Learning with Constraints for Person Identification in Multimedia Data</a></p>
<p>20 0.11227986 <a title="438-tfidf-20" href="./cvpr-2013-3D_Visual_Proxemics%3A_Recognizing_Human_Interactions_in_3D_from_a_Single_Image.html">4 cvpr-2013-3D Visual Proxemics: Recognizing Human Interactions in 3D from a Single Image</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.197), (1, -0.045), (2, -0.098), (3, 0.009), (4, 0.025), (5, -0.049), (6, -0.017), (7, -0.122), (8, 0.352), (9, -0.291), (10, 0.073), (11, 0.048), (12, 0.065), (13, 0.123), (14, 0.009), (15, 0.037), (16, 0.046), (17, -0.03), (18, -0.04), (19, 0.07), (20, -0.07), (21, 0.029), (22, -0.047), (23, 0.053), (24, 0.002), (25, 0.021), (26, -0.03), (27, 0.028), (28, -0.021), (29, -0.01), (30, -0.001), (31, 0.034), (32, 0.026), (33, -0.065), (34, 0.021), (35, 0.032), (36, -0.009), (37, 0.036), (38, 0.02), (39, 0.049), (40, -0.016), (41, 0.016), (42, 0.035), (43, -0.062), (44, -0.067), (45, 0.014), (46, 0.006), (47, 0.021), (48, -0.014), (49, -0.043)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98261064 <a title="438-lsi-1" href="./cvpr-2013-Towards_Pose_Robust_Face_Recognition.html">438 cvpr-2013-Towards Pose Robust Face Recognition</a></p>
<p>Author: Dong Yi, Zhen Lei, Stan Z. Li</p><p>Abstract: Most existing pose robust methods are too computational complex to meet practical applications and their performance under unconstrained environments are rarely evaluated. In this paper, we propose a novel method for pose robust face recognition towards practical applications, which is fast, pose robust and can work well under unconstrained environments. Firstly, a 3D deformable model is built and a fast 3D model fitting algorithm is proposed to estimate the pose of face image. Secondly, a group of Gabor filters are transformed according to the pose and shape of face image for feature extraction. Finally, PCA is applied on the pose adaptive Gabor features to remove the redundances and Cosine metric is used to evaluate the similarity. The proposed method has three advantages: (1) The pose correction is applied in the filter space rather than image space, which makes our method less affected by the precision of the 3D model; (2) By combining the holistic pose transformation and local Gabor filtering, the final feature is robust to pose and other negative factors in face recognition; (3) The 3D structure and facial symmetry are successfully used to deal with self-occlusion. Extensive experiments on FERET and PIE show the proposed method outperforms state-ofthe-art methods significantly, meanwhile, the method works well on LFW.</p><p>2 0.88099283 <a title="438-lsi-2" href="./cvpr-2013-Probabilistic_Elastic_Matching_for_Pose_Variant_Face_Verification.html">338 cvpr-2013-Probabilistic Elastic Matching for Pose Variant Face Verification</a></p>
<p>Author: Haoxiang Li, Gang Hua, Zhe Lin, Jonathan Brandt, Jianchao Yang</p><p>Abstract: Pose variation remains to be a major challenge for realworld face recognition. We approach this problem through a probabilistic elastic matching method. We take a part based representation by extracting local features (e.g., LBP or SIFT) from densely sampled multi-scale image patches. By augmenting each feature with its location, a Gaussian mixture model (GMM) is trained to capture the spatialappearance distribution of all face images in the training corpus. Each mixture component of the GMM is confined to be a spherical Gaussian to balance the influence of the appearance and the location terms. Each Gaussian component builds correspondence of a pair of features to be matched between two faces/face tracks. For face verification, we train an SVM on the vector concatenating the difference vectors of all the feature pairs to decide if a pair of faces/face tracks is matched or not. We further propose a joint Bayesian adaptation algorithm to adapt the universally trained GMM to better model the pose variations between the target pair of faces/face tracks, which consistently improves face verification accuracy. Our experiments show that our method outperforms the state-ofthe-art in the most restricted protocol on Labeled Face in the Wild (LFW) and the YouTube video face database by a significant margin.</p><p>3 0.83977771 <a title="438-lsi-3" href="./cvpr-2013-Face_Recognition_in_Movie_Trailers_via_Mean_Sequence_Sparse_Representation-Based_Classification.html">160 cvpr-2013-Face Recognition in Movie Trailers via Mean Sequence Sparse Representation-Based Classification</a></p>
<p>Author: Enrique G. Ortiz, Alan Wright, Mubarak Shah</p><p>Abstract: This paper presents an end-to-end video face recognition system, addressing the difficult problem of identifying a video face track using a large dictionary of still face images of a few hundred people, while rejecting unknown individuals. A straightforward application of the popular ?1minimization for face recognition on a frame-by-frame basis is prohibitively expensive, so we propose a novel algorithm Mean Sequence SRC (MSSRC) that performs video face recognition using a joint optimization leveraging all of the available video data and the knowledge that the face track frames belong to the same individual. By adding a strict temporal constraint to the ?1-minimization that forces individual frames in a face track to all reconstruct a single identity, we show the optimization reduces to a single minimization over the mean of the face track. We also introduce a new Movie Trailer Face Dataset collected from 101 movie trailers on YouTube. Finally, we show that our methodmatches or outperforms the state-of-the-art on three existing datasets (YouTube Celebrities, YouTube Faces, and Buffy) and our unconstrained Movie Trailer Face Dataset. More importantly, our method excels at rejecting unknown identities by at least 8% in average precision.</p><p>4 0.83950371 <a title="438-lsi-4" href="./cvpr-2013-Detecting_and_Aligning_Faces_by_Image_Retrieval.html">119 cvpr-2013-Detecting and Aligning Faces by Image Retrieval</a></p>
<p>Author: Xiaohui Shen, Zhe Lin, Jonathan Brandt, Ying Wu</p><p>Abstract: Detecting faces in uncontrolled environments continues to be a challenge to traditional face detection methods[24] due to the large variation in facial appearances, as well as occlusion and clutter. In order to overcome these challenges, we present a novel and robust exemplarbased face detector that integrates image retrieval and discriminative learning. A large database of faces with bounding rectangles and facial landmark locations is collected, and simple discriminative classifiers are learned from each of them. A voting-based method is then proposed to let these classifiers cast votes on the test image through an efficient image retrieval technique. As a result, faces can be very efficiently detected by selecting the modes from the voting maps, without resorting to exhaustive sliding window-style scanning. Moreover, due to the exemplar-based framework, our approach can detect faces under challenging conditions without explicitly modeling their variations. Evaluation on two public benchmark datasets shows that our new face detection approach is accurate and efficient, and achieves the state-of-the-art performance. We further propose to use image retrieval for face validation (in order to remove false positives) and for face alignment/landmark localization. The same methodology can also be easily generalized to other facerelated tasks, such as attribute recognition, as well as general object detection.</p><p>5 0.83053195 <a title="438-lsi-5" href="./cvpr-2013-Fusing_Robust_Face_Region_Descriptors_via_Multiple_Metric_Learning_for_Face_Recognition_in_the_Wild.html">182 cvpr-2013-Fusing Robust Face Region Descriptors via Multiple Metric Learning for Face Recognition in the Wild</a></p>
<p>Author: Zhen Cui, Wen Li, Dong Xu, Shiguang Shan, Xilin Chen</p><p>Abstract: In many real-world face recognition scenarios, face images can hardly be aligned accurately due to complex appearance variations or low-quality images. To address this issue, we propose a new approach to extract robust face region descriptors. Specifically, we divide each image (resp. video) into several spatial blocks (resp. spatial-temporal volumes) and then represent each block (resp. volume) by sum-pooling the nonnegative sparse codes of position-free patches sampled within the block (resp. volume). Whitened Principal Component Analysis (WPCA) is further utilized to reduce the feature dimension, which leads to our Spatial Face Region Descriptor (SFRD) (resp. Spatial-Temporal Face Region Descriptor, STFRD) for images (resp. videos). Moreover, we develop a new distance method for face verification metric learning called Pairwise-constrained Multiple Metric Learning (PMML) to effectively integrate the face region descriptors of all blocks (resp. volumes) from an image (resp. a video). Our work achieves the state- of-the-art performances on two real-world datasets LFW and YouTube Faces (YTF) according to the restricted protocol.</p><p>6 0.78987706 <a title="438-lsi-6" href="./cvpr-2013-Single-Sample_Face_Recognition_with_Image_Corruption_and_Misalignment_via_Sparse_Illumination_Transfer.html">399 cvpr-2013-Single-Sample Face Recognition with Image Corruption and Misalignment via Sparse Illumination Transfer</a></p>
<p>7 0.73839021 <a title="438-lsi-7" href="./cvpr-2013-Constrained_Clustering_and_Its_Application_to_Face_Clustering_in_Videos.html">92 cvpr-2013-Constrained Clustering and Its Application to Face Clustering in Videos</a></p>
<p>8 0.73062193 <a title="438-lsi-8" href="./cvpr-2013-Exemplar-Based_Face_Parsing.html">152 cvpr-2013-Exemplar-Based Face Parsing</a></p>
<p>9 0.72359824 <a title="438-lsi-9" href="./cvpr-2013-Supervised_Descent_Method_and_Its_Applications_to_Face_Alignment.html">420 cvpr-2013-Supervised Descent Method and Its Applications to Face Alignment</a></p>
<p>10 0.72052735 <a title="438-lsi-10" href="./cvpr-2013-Facial_Feature_Tracking_Under_Varying_Facial_Expressions_and_Face_Poses_Based_on_Restricted_Boltzmann_Machines.html">161 cvpr-2013-Facial Feature Tracking Under Varying Facial Expressions and Face Poses Based on Restricted Boltzmann Machines</a></p>
<p>11 0.71151781 <a title="438-lsi-11" href="./cvpr-2013-Blessing_of_Dimensionality%3A_High-Dimensional_Feature_and_Its_Efficient_Compression_for_Face_Verification.html">64 cvpr-2013-Blessing of Dimensionality: High-Dimensional Feature and Its Efficient Compression for Face Verification</a></p>
<p>12 0.7061857 <a title="438-lsi-12" href="./cvpr-2013-Structured_Face_Hallucination.html">415 cvpr-2013-Structured Face Hallucination</a></p>
<p>13 0.67520815 <a title="438-lsi-13" href="./cvpr-2013-Semi-supervised_Learning_with_Constraints_for_Person_Identification_in_Multimedia_Data.html">389 cvpr-2013-Semi-supervised Learning with Constraints for Person Identification in Multimedia Data</a></p>
<p>14 0.66940856 <a title="438-lsi-14" href="./cvpr-2013-Expressive_Visual_Text-to-Speech_Using_Active_Appearance_Models.html">159 cvpr-2013-Expressive Visual Text-to-Speech Using Active Appearance Models</a></p>
<p>15 0.66021931 <a title="438-lsi-15" href="./cvpr-2013-What%27s_in_a_Name%3F_First_Names_as_Facial_Attributes.html">463 cvpr-2013-What's in a Name? First Names as Facial Attributes</a></p>
<p>16 0.65790248 <a title="438-lsi-16" href="./cvpr-2013-In_Defense_of_Sparsity_Based_Face_Recognition.html">220 cvpr-2013-In Defense of Sparsity Based Face Recognition</a></p>
<p>17 0.61021733 <a title="438-lsi-17" href="./cvpr-2013-Robust_Discriminative_Response_Map_Fitting_with_Constrained_Local_Models.html">359 cvpr-2013-Robust Discriminative Response Map Fitting with Constrained Local Models</a></p>
<p>18 0.60307223 <a title="438-lsi-18" href="./cvpr-2013-The_SVM-Minus_Similarity_Score_for_Video_Face_Recognition.html">430 cvpr-2013-The SVM-Minus Similarity Score for Video Face Recognition</a></p>
<p>19 0.5915789 <a title="438-lsi-19" href="./cvpr-2013-Learning_SURF_Cascade_for_Fast_and_Accurate_Object_Detection.html">254 cvpr-2013-Learning SURF Cascade for Fast and Accurate Object Detection</a></p>
<p>20 0.55770797 <a title="438-lsi-20" href="./cvpr-2013-3D_Visual_Proxemics%3A_Recognizing_Human_Interactions_in_3D_from_a_Single_Image.html">4 cvpr-2013-3D Visual Proxemics: Recognizing Human Interactions in 3D from a Single Image</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.104), (15, 0.142), (16, 0.054), (19, 0.019), (26, 0.052), (28, 0.016), (33, 0.245), (39, 0.011), (63, 0.011), (67, 0.121), (69, 0.048), (87, 0.076)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.89409804 <a title="438-lda-1" href="./cvpr-2013-Towards_Pose_Robust_Face_Recognition.html">438 cvpr-2013-Towards Pose Robust Face Recognition</a></p>
<p>Author: Dong Yi, Zhen Lei, Stan Z. Li</p><p>Abstract: Most existing pose robust methods are too computational complex to meet practical applications and their performance under unconstrained environments are rarely evaluated. In this paper, we propose a novel method for pose robust face recognition towards practical applications, which is fast, pose robust and can work well under unconstrained environments. Firstly, a 3D deformable model is built and a fast 3D model fitting algorithm is proposed to estimate the pose of face image. Secondly, a group of Gabor filters are transformed according to the pose and shape of face image for feature extraction. Finally, PCA is applied on the pose adaptive Gabor features to remove the redundances and Cosine metric is used to evaluate the similarity. The proposed method has three advantages: (1) The pose correction is applied in the filter space rather than image space, which makes our method less affected by the precision of the 3D model; (2) By combining the holistic pose transformation and local Gabor filtering, the final feature is robust to pose and other negative factors in face recognition; (3) The 3D structure and facial symmetry are successfully used to deal with self-occlusion. Extensive experiments on FERET and PIE show the proposed method outperforms state-ofthe-art methods significantly, meanwhile, the method works well on LFW.</p><p>2 0.88504803 <a title="438-lda-2" href="./cvpr-2013-A_New_Perspective_on_Uncalibrated_Photometric_Stereo.html">21 cvpr-2013-A New Perspective on Uncalibrated Photometric Stereo</a></p>
<p>Author: Thoma Papadhimitri, Paolo Favaro</p><p>Abstract: We investigate the problem of reconstructing normals, albedo and lights of Lambertian surfaces in uncalibrated photometric stereo under the perspective projection model. Our analysis is based on establishing the integrability constraint. In the orthographicprojection case, it is well-known that when such constraint is imposed, a solution can be identified only up to 3 parameters, the so-called generalized bas-relief (GBR) ambiguity. We show that in the perspective projection case the solution is unique. We also propose a closed-form solution which is simple, efficient and robust. We test our algorithm on synthetic data and publicly available real data. Our quantitative tests show that our method outperforms all prior work of uncalibrated photometric stereo under orthographic projection.</p><p>3 0.88493073 <a title="438-lda-3" href="./cvpr-2013-Detecting_and_Aligning_Faces_by_Image_Retrieval.html">119 cvpr-2013-Detecting and Aligning Faces by Image Retrieval</a></p>
<p>Author: Xiaohui Shen, Zhe Lin, Jonathan Brandt, Ying Wu</p><p>Abstract: Detecting faces in uncontrolled environments continues to be a challenge to traditional face detection methods[24] due to the large variation in facial appearances, as well as occlusion and clutter. In order to overcome these challenges, we present a novel and robust exemplarbased face detector that integrates image retrieval and discriminative learning. A large database of faces with bounding rectangles and facial landmark locations is collected, and simple discriminative classifiers are learned from each of them. A voting-based method is then proposed to let these classifiers cast votes on the test image through an efficient image retrieval technique. As a result, faces can be very efficiently detected by selecting the modes from the voting maps, without resorting to exhaustive sliding window-style scanning. Moreover, due to the exemplar-based framework, our approach can detect faces under challenging conditions without explicitly modeling their variations. Evaluation on two public benchmark datasets shows that our new face detection approach is accurate and efficient, and achieves the state-of-the-art performance. We further propose to use image retrieval for face validation (in order to remove false positives) and for face alignment/landmark localization. The same methodology can also be easily generalized to other facerelated tasks, such as attribute recognition, as well as general object detection.</p><p>4 0.88473845 <a title="438-lda-4" href="./cvpr-2013-Robust_Multi-resolution_Pedestrian_Detection_in_Traffic_Scenes.html">363 cvpr-2013-Robust Multi-resolution Pedestrian Detection in Traffic Scenes</a></p>
<p>Author: Junjie Yan, Xucong Zhang, Zhen Lei, Shengcai Liao, Stan Z. Li</p><p>Abstract: The serious performance decline with decreasing resolution is the major bottleneck for current pedestrian detection techniques [14, 23]. In this paper, we take pedestrian detection in different resolutions as different but related problems, and propose a Multi-Task model to jointly consider their commonness and differences. The model contains resolution aware transformations to map pedestrians in different resolutions to a common space, where a shared detector is constructed to distinguish pedestrians from background. For model learning, we present a coordinate descent procedure to learn the resolution aware transformations and deformable part model (DPM) based detector iteratively. In traffic scenes, there are many false positives located around vehicles, therefore, we further build a context model to suppress them according to the pedestrian-vehicle relationship. The context model can be learned automatically even when the vehicle annotations are not available. Our method reduces the mean miss rate to 60% for pedestrians taller than 30 pixels on the Caltech Pedestrian Benchmark, which noticeably outperforms previous state-of-the-art (71%).</p><p>5 0.88328403 <a title="438-lda-5" href="./cvpr-2013-Learning_SURF_Cascade_for_Fast_and_Accurate_Object_Detection.html">254 cvpr-2013-Learning SURF Cascade for Fast and Accurate Object Detection</a></p>
<p>Author: Jianguo Li, Yimin Zhang</p><p>Abstract: This paper presents a novel learning framework for training boosting cascade based object detector from large scale dataset. The framework is derived from the wellknown Viola-Jones (VJ) framework but distinguished by three key differences. First, the proposed framework adopts multi-dimensional SURF features instead of single dimensional Haar features to describe local patches. In this way, the number of used local patches can be reduced from hundreds of thousands to several hundreds. Second, it adopts logistic regression as weak classifier for each local patch instead of decision trees in the VJ framework. Third, we adopt AUC as a single criterion for the convergence test during cascade training rather than the two trade-off criteria (false-positive-rate and hit-rate) in the VJ framework. The benefit is that the false-positive-rate can be adaptive among different cascade stages, and thus yields much faster convergence speed of SURF cascade. Combining these points together, the proposed approach has three good properties. First, the boosting cascade can be trained very efficiently. Experiments show that the proposed approach can train object detectors from billions of negative samples within one hour even on personal computers. Second, the built detector is comparable to the stateof-the-art algorithm not only on the accuracy but also on the processing speed. Third, the built detector is small in model-size due to short cascade stages.</p><p>6 0.88270676 <a title="438-lda-6" href="./cvpr-2013-3D_Pictorial_Structures_for_Multiple_View_Articulated_Pose_Estimation.html">2 cvpr-2013-3D Pictorial Structures for Multiple View Articulated Pose Estimation</a></p>
<p>7 0.88255268 <a title="438-lda-7" href="./cvpr-2013-Probabilistic_Graphlet_Cut%3A_Exploiting_Spatial_Structure_Cue_for_Weakly_Supervised_Image_Segmentation.html">339 cvpr-2013-Probabilistic Graphlet Cut: Exploiting Spatial Structure Cue for Weakly Supervised Image Segmentation</a></p>
<p>8 0.87810117 <a title="438-lda-8" href="./cvpr-2013-An_Iterated_L1_Algorithm_for_Non-smooth_Non-convex_Optimization_in_Computer_Vision.html">41 cvpr-2013-An Iterated L1 Algorithm for Non-smooth Non-convex Optimization in Computer Vision</a></p>
<p>9 0.87648058 <a title="438-lda-9" href="./cvpr-2013-PISA%3A_Pixelwise_Image_Saliency_by_Aggregating_Complementary_Appearance_Contrast_Measures_with_Spatial_Priors.html">322 cvpr-2013-PISA: Pixelwise Image Saliency by Aggregating Complementary Appearance Contrast Measures with Spatial Priors</a></p>
<p>10 0.87639159 <a title="438-lda-10" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>11 0.87637299 <a title="438-lda-11" href="./cvpr-2013-Real-Time_Model-Based_Rigid_Object_Pose_Estimation_and_Tracking_Combining_Dense_and_Sparse_Visual_Cues.html">345 cvpr-2013-Real-Time Model-Based Rigid Object Pose Estimation and Tracking Combining Dense and Sparse Visual Cues</a></p>
<p>12 0.87554836 <a title="438-lda-12" href="./cvpr-2013-Detection_Evolution_with_Multi-order_Contextual_Co-occurrence.html">122 cvpr-2013-Detection Evolution with Multi-order Contextual Co-occurrence</a></p>
<p>13 0.87349015 <a title="438-lda-13" href="./cvpr-2013-Articulated_Pose_Estimation_Using_Discriminative_Armlet_Classifiers.html">45 cvpr-2013-Articulated Pose Estimation Using Discriminative Armlet Classifiers</a></p>
<p>14 0.87334824 <a title="438-lda-14" href="./cvpr-2013-Integrating_Grammar_and_Segmentation_for_Human_Pose_Estimation.html">225 cvpr-2013-Integrating Grammar and Segmentation for Human Pose Estimation</a></p>
<p>15 0.87210637 <a title="438-lda-15" href="./cvpr-2013-Face_Recognition_in_Movie_Trailers_via_Mean_Sequence_Sparse_Representation-Based_Classification.html">160 cvpr-2013-Face Recognition in Movie Trailers via Mean Sequence Sparse Representation-Based Classification</a></p>
<p>16 0.87176555 <a title="438-lda-16" href="./cvpr-2013-Modeling_Mutual_Visibility_Relationship_in_Pedestrian_Detection.html">288 cvpr-2013-Modeling Mutual Visibility Relationship in Pedestrian Detection</a></p>
<p>17 0.87109959 <a title="438-lda-17" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<p>18 0.86991179 <a title="438-lda-18" href="./cvpr-2013-3D_Visual_Proxemics%3A_Recognizing_Human_Interactions_in_3D_from_a_Single_Image.html">4 cvpr-2013-3D Visual Proxemics: Recognizing Human Interactions in 3D from a Single Image</a></p>
<p>19 0.86960435 <a title="438-lda-19" href="./cvpr-2013-Context-Aware_Modeling_and_Recognition_of_Activities_in_Video.html">94 cvpr-2013-Context-Aware Modeling and Recognition of Activities in Video</a></p>
<p>20 0.86924881 <a title="438-lda-20" href="./cvpr-2013-Beyond_Physical_Connections%3A_Tree_Models_in_Human_Pose_Estimation.html">60 cvpr-2013-Beyond Physical Connections: Tree Models in Human Pose Estimation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
