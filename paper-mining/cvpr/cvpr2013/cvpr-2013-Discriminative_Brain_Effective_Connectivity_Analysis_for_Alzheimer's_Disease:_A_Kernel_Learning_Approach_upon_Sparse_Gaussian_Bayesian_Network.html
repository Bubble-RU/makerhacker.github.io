<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>129 cvpr-2013-Discriminative Brain Effective Connectivity Analysis for Alzheimer's Disease: A Kernel Learning Approach upon Sparse Gaussian Bayesian Network</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-129" href="#">cvpr2013-129</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>129 cvpr-2013-Discriminative Brain Effective Connectivity Analysis for Alzheimer's Disease: A Kernel Learning Approach upon Sparse Gaussian Bayesian Network</h1>
<br/><p>Source: <a title="cvpr-2013-129-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Zhou_Discriminative_Brain_Effective_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Luping Zhou, Lei Wang, Lingqiao Liu, Philip Ogunbona, Dinggang Shen</p><p>Abstract: Analyzing brain networks from neuroimages is becoming a promising approach in identifying novel connectivitybased biomarkers for the Alzheimer’s disease (AD). In this regard, brain “effective connectivity ” analysis, which studies the causal relationship among brain regions, is highly challenging and of many research opportunities. Most of the existing works in this field use generative methods. Despite their success in data representation and other important merits, generative methods are not necessarily discriminative, which may cause the ignorance of subtle but critical disease-induced changes. In this paper, we propose a learning-based approach that integrates the benefits of generative and discriminative methods to recover effective connectivity. In particular, we employ Fisher kernel to bridge the generative models of sparse Bayesian networks (SBN) and the discriminative classifiers of SVMs, and convert the SBN parameter learning to Fisher kernel learning via minimizing a generalization error bound of SVMs. Our method is able to simultaneously boost the discriminative power of both the generative SBN models and the SBN-induced SVM classifiers via Fisher kernel. The proposed method is tested on analyzing brain effective connectivity for AD from ADNI data, and demonstrates significant improvements over the state-of-the-art work.</p><p>Reference: <a title="cvpr-2013-129-reference" href="../cvpr2013_reference/cvpr-2013-Discriminative_Brain_Effective_Connectivity_Analysis_for_Alzheimer%27s_Disease%3A_A_Kernel_Learning_Approach_upon_Sparse_Gaussian_Bayesian_Network_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 In this regard, brain “effective connectivity ” analysis, which studies the causal relationship among brain regions, is highly challenging and of many research opportunities. [sent-2, score-0.938]
</p><p>2 In this paper, we propose a learning-based approach that integrates the benefits of generative and discriminative methods to recover effective connectivity. [sent-5, score-0.262]
</p><p>3 In particular, we employ Fisher kernel to bridge the generative models of sparse Bayesian networks (SBN) and the discriminative classifiers of SVMs, and convert the SBN parameter learning to Fisher kernel learning via minimizing a generalization error bound of SVMs. [sent-6, score-0.541]
</p><p>4 Our method is able to simultaneously boost the discriminative power of both the generative SBN models and the SBN-induced SVM  classifiers via Fisher kernel. [sent-7, score-0.29]
</p><p>5 The proposed method is tested on analyzing brain effective connectivity for AD from ADNI data, and demonstrates significant improvements over the state-of-the-art work. [sent-8, score-0.576]
</p><p>6 Introduction As the most common form of dementia, Alzheimer’s disease (AD) is a fatal and progressive neurodegenerative disease that has caused serious socioeconomic problems in developed countries. [sent-10, score-0.162]
</p><p>7 Currently, neuroimage analysis has evolved from studying local morphometry to complex relationships and interactions across brain regions. [sent-13, score-0.374]
</p><p>8 This is because the brain is, by  rectional relationships discriminative for AD. [sent-14, score-0.453]
</p><p>9 A brain network is usually modeled by a graph with each node corresponding to a brain region and each edge corresponding to the connectivity between regions. [sent-19, score-1.151]
</p><p>10 The connectivity could be statistical dependencies (functional connectivity) or causal relationships (effective connectivity) [14], represented by undirected or directed graph, respectively. [sent-20, score-0.266]
</p><p>11 This paper focuses on brain effective connectivity analysis, an endeavor that has gained research interest due to its ability to analyze the directional effect of one brain region over another. [sent-21, score-0.925]
</p><p>12 Effective connectivity analysis has been applied to fMRI [5], PET [1], and gray matter morphology in structural MRI [6], and has exhibited promising potential in identifying novel connectivity-based biomarkers for AD. [sent-22, score-0.364]
</p><p>13 With sparseness techniques, effective connectivity analysis has been able to handle medium to large scale brain networks. [sent-23, score-0.623]
</p><p>14 [1], where a sparse Gaussian Bayesian network (SGBN) is recovered from more than 40 brain regions in fluorodeoxyglucose PET (FDG-PET) images for AD analysis. [sent-25, score-0.544]
</p><p>15 That approach learns the Bayesian network (BN) structure and parameters simultaneously in one step, which demonstrates a more accurate network recovery than the conventional twostage approaches in sparse BN learning (such as LIMBDAG [13], MMHC [16], TC and TC-bw [9], etc. [sent-26, score-0.447]
</p><p>16 Despite the effectiveness in network representation, the above methods (including [1]) are all generative methods. [sent-28, score-0.312]
</p><p>17 When analyzing brain networks, they are prone to over-emphasizing major structures within an individual group, and neglecting the subtle disease-induced structural changes across different groups. [sent-30, score-0.401]
</p><p>18 Therefore, generative methods are usually inferior in prediction compared with the discriminative methods that focus on the class boundary. [sent-31, score-0.282]
</p><p>19 Recent progress in [10, 11] for learning discriminative BNs follows the conventional two-stage approach and works for discrete variables. [sent-34, score-0.161]
</p><p>20 They may not be suitable for brain network analysis where the brain regional measurements are usually continuous variables. [sent-35, score-0.893]
</p><p>21 To achieve our goal, we improve the model of the SGBN in [1], and further boost its discriminative power via a kernel learning approach that links the generative SGBN with the SVM classifiers. [sent-36, score-0.368]
</p><p>22 2) By inducing Fisher kernel on our A-SGBN models,  we provide a way to obtain subject-specific SGBN-induced feature vectors that can be used by discriminative classifiers such as SVMs. [sent-39, score-0.231]
</p><p>23 Through this, we integrate the generative and discriminative models. [sent-40, score-0.221]
</p><p>24 3) More significantly, we convert the learning of SGBN parameters to the learning of discriminative Fisher kernels, which makes the optimization simple. [sent-41, score-0.166]
</p><p>25 Specifically, we jointly learn the SGBN parameters and the separating hyperplane of SVMs over Fisher kernel by minimizing a generalization error bound of SVMs. [sent-42, score-0.158]
</p><p>26 4) We apply our method on ADNI 1 data to analyze brain effective connectivity for AD from both T1-weighted MRI and FDG-PET images. [sent-43, score-0.576]
</p><p>27 Our method significantly improves the discriminative power of the generative SGBN and the discriminative SVM classifier simultaneously. [sent-44, score-0.366]
</p><p>28 Gaussian Bayesian Network Gaussian Bayesian network (GBN) is the fundamental tool that we use to learn brain effective connectivity in this paper. [sent-49, score-0.771]
</p><p>29 A Bayesian network (BN) G is a directed acyclic graph (DAAG B) athyeats expresses kth (eB Nfa)ct oGr iisza atio dnir property colifc a joint distribution p(x). [sent-58, score-0.221]
</p><p>30 Each node xi is regressed over its parent nodes Pa(xi): xi = θi? [sent-68, score-0.383]
</p><p>31 Sparse Gaussian Bayesian Network The state-of-the-art work for brain causal relationship analysis in [1] underpins our study in this paper. [sent-77, score-0.403]
</p><p>32 In [1], it is proposed to learn a sparse GBN (SGBN) for brain effective connectivity analysis utilizing FDG-PET images. [sent-78, score-0.576]
</p><p>33 Com-  ××  pared with the conventional BN methods that learn the network structure and parameters in two steps, SGBN simultaneously learns the structure and parameters by enforcing sparseness constraint on a GBN. [sent-79, score-0.268]
</p><p>34 This one-step learning approach outperforms the conventional two-step methods with higher accuracies for the network edge recovery. [sent-80, score-0.252]
</p><p>35 The i-th row of the matrix Pa(xi) correspond to the parent nodes of xi, which are initially set as all the nodes other than xi, and further filtered implicitly by the sparseness constraint over their regression coefficients θi. [sent-92, score-0.183]
</p><p>36 Proposed Method  In this paper, we study brain networks from two sources. [sent-98, score-0.404]
</p><p>37 It has been reported that the covariation of gray matter morphology might be related to the anatomical connectivity [15]. [sent-100, score-0.336]
</p><p>38 Studying brain morphology as a network can take the advantage of statistical tools from graph theory. [sent-101, score-0.594]
</p><p>39 Building brain networks includes identifying network nodes and reconstructing the connectivity. [sent-104, score-0.642]
</p><p>40 Hence, after briefing how network nodes are defined in our method in Section 3. [sent-106, score-0.238]
</p><p>41 1, we concentrate on how to infer the effective connectivity that is both representative (Section 3. [sent-107, score-0.227]
</p><p>42 The T1-weighted MR images are segmented into gray matter (GM), white matter (WM), and cerebrospinal fluid (CSF) using FAST in the FSL2 package after intensity correction, skull stripping [17], and cerebellum removal. [sent-114, score-0.163]
</p><p>43 We use the GM volumes of each ROI as network  nodes, and select 40 ROIs that have the highest correlation with class labels into our study. [sent-116, score-0.223]
</p><p>44 The average tracer uptakes within each ROI are used as network nodes. [sent-121, score-0.229]
</p><p>45 SGBN Model Augmentation A simple way to use generative BNs for prediction is to train each class a BN individually and classify a new sample xi by assigning it to the class with a higher likelihood. [sent-125, score-0.315]
</p><p>46 Discriminative SBN Learning via Fisher Kernel Both SGBN and A-SGBN learn the brain networks for AD or NC separately. [sent-148, score-0.404]
</p><p>47 This may ignore some subtle but critical network differences that distinguish the two classes. [sent-149, score-0.223]
</p><p>48 Specifically, we employ Fisher kernel to extract feature vectors from the SGBN models of two classes, and then convert the model parameter learning to Fisher kernel learning with SVMs. [sent-154, score-0.212]
</p><p>49 Fisher kernel provides a way to compare samples induced by a generative model. [sent-159, score-0.218]
</p><p>50 Despite its success, to the best of our knowledge, Fisher kernel has not been applied to BN for brain connectivity analysis. [sent-168, score-0.61]
</p><p>51 More importantly, in the applications  above, there is no discriminative learning for Fisher kernel as in this paper. [sent-169, score-0.21]
</p><p>52 The advantage of discriminative Fisher kernel has also been confirmed by a very recent study that uses a different learning criterion within a different context [8]. [sent-170, score-0.21]
</p><p>53 2  Discriminative Fisher kernel learning via SVM  As each Fisher vector is a function of the SGBN parameters, discriminatively learning these parameters can thus be converted to learning discriminative Fisher kernels. [sent-199, score-0.272]
</p><p>54 Firstly, to obtain a discriminative Fisher kernel, we jointly learn the parameters of SGBN and the separating hyperplane of SVMs with Fisher kernel. [sent-205, score-0.162]
</p><p>55 (4) ξi ≥ 0, ∀i  Following the convention in SVMs, xi is the i-th sample with class label yi, w the normal of separating plane, b the bias term, ξ the slack variables and C the regularization parameter. [sent-217, score-0.212]
</p><p>56 The function h(·) measures the squared fitting errors 3o. [sent-249, score-0.161]
</p><p>57 Although not as discriminative as that in MRI, the ROIs in MRI-II are more spread across the frontal, parietal, occipital and frontal lobes, thus specially used for a detailed lobe-to-lobe comparison on connectivity. [sent-367, score-0.204]
</p><p>58 Since the change of data fitting from A-SGBN to DL-A-SGBN has been explicitly controlled by the user-defined parameters T1 and T2, we simply compare the model fitting between A-SGBN and B-SGBN. [sent-373, score-0.19]
</p><p>59 The fitting errors are tested on both training and test data for each class in all three data sets. [sent-374, score-0.151]
</p><p>60 The root of mean squared fitting errors (RMS) are summarized in Table 2. [sent-375, score-0.161]
</p><p>61 In order to test if the fitting errors of A-SGBN are statistically different from that of B-SGBN, a paired t-test (two-tailed) is conducted on the fitting errors over the 30 groups for each data set, respectively. [sent-376, score-0.288]
</p><p>62 We test whether our learning can improve the discriminative power on both kinds. [sent-412, score-0.176]
</p><p>63 In order to keep reasonable interpretation, we allow maximal 1% additional squared fitting errors (that is, Ti = 1. [sent-414, score-0.186]
</p><p>64 01 Ti0, (i = 1, 2), where Ti0 is the squared fitting error 0o1f t×he T initial solution) to be introduced during the learning of DL-A-SGBN. [sent-415, score-0.164]
</p><p>65 u675e()  significantly improves the discriminative power of SVM classifiers by 3. [sent-429, score-0.173]
</p><p>66 More importantly, by learning a discriminative SVM classifier, we also simultaneously improve the discriminative power of the generative models DL-A-SGBN 222222444866  by 3. [sent-433, score-0.397]
</p><p>67 Compared with the B-SGBN induced from [1], introducing a bias node (A-SGBN) better fits the population, therefore improves the prediction on test data by 9% for MRI, 6. [sent-450, score-0.177]
</p><p>68 The discriminative power of A-SGBN is further improved by 3 ∼ 6% via our discriminative pairsam fuerttehre learning. [sent-453, score-0.249]
</p><p>69 dT bhiys 3le ∼ads 6 t%o generative cmriomdeinlas iDveL- pAa-SGBN achieving a classification accuracy above 70%, with no more than 1% increase of the squared fitting error. [sent-454, score-0.25]
</p><p>70 Moreover, by selecting leading features in the SGBN-induced Fisher vectors, we can construct more discriminative SVM classifiers with additional 6% or more improvement from our DL-A-SGBN to differentiate both MCI vs NC groups in MRI or MRI-II and AD vs NC groups in PET. [sent-455, score-0.216]
</p><p>71 In sum, compared with the baseline B-SGBN, our proposed method can increase the prediction accuracy by as high as 18% for MRI, 16% for PET, and 20% for MRIII, using Fisher kernel induced SVM classifiers with feature selection. [sent-456, score-0.162]
</p><p>72 Meanwhile, these SVM classifiers are linked to the learned generative model DL-A-SGBN whose discriminative powers have also been increased by about 10% from B-SGBN on all three data sets. [sent-457, score-0.249]
</p><p>73 Our DL-A-SGBN models are not only discriminative, but also descriptive with only  a slight increase in the squared fitting errors (at most 1% increase, controlled by the optimization parameter). [sent-458, score-0.161]
</p><p>74 Comparison of Connectivity In order to gain more insight into the results, we also conduct a lobe-to-lobe comparison on the connectivity derived by our methods and B-SGBN. [sent-466, score-0.186]
</p><p>75 For example, the 40 nodes used in the MRI data set are mostly located in the temporal lobe and the subcortical region. [sent-468, score-0.273]
</p><p>76 Therefore, we specially design the MRI-II data set by selecting 40 regions that cover the frontal, parietal, occipital and temporal (including the subcortical region) lobes from MR images of the same subjects involved in MRI data. [sent-469, score-0.212]
</p><p>77 The structures of the brain networks recovered from NC  and MCI groups are displayed in Fig. [sent-473, score-0.47]
</p><p>78 The network structure is obtained by binarizing the edges Θ with a threshold of 0. [sent-475, score-0.25]
</p><p>79 Each row irepresents the effective connections (dark dots) starting from the node i, and each column j represents the effective connections ending at the node j. [sent-477, score-0.286]
</p><p>80 Because the bias node has no parent node, the last column is all zero. [sent-480, score-0.168]
</p><p>81 As shown, the two methods produce similar network structures both visually and quantitatively in most brain regions. [sent-482, score-0.568]
</p><p>82 About half different connections are identified within the temporal lobe (15 for NC, 5 for MCI), for which we also include subcortical structures such as hippocampus and amygdala. [sent-484, score-0.322]
</p><p>83 It is known that temporal lobe (and some subcortical structures) plays a very important role in the progression of AD. [sent-485, score-0.23]
</p><p>84 Such a structural difference in this lobe may potentially reflect the different capacity of prediction between our DL-A-SGBN and the B-SGBN. [sent-486, score-0.192]
</p><p>85 Traditional brain connectivity analysis focuses on the analysis of brain structure which is a binarized connectivity. [sent-490, score-0.884]
</p><p>86 For example, the network structures from both the BSGBN and our DL-A-SGBN indicate the loss of effective connections (around 17%) in MCI group in almost all lobes (slightly in the frontal lobe), which agrees well with documented studies [1, 6]. [sent-491, score-0.373]
</p><p>87 However, binarizing connectivity depends on the selection of threshold. [sent-492, score-0.212]
</p><p>88 If some connection strength has been weakened by the disease but not reduced below the threshold, this change will be unnecessarily ignored when merely studying the brain structure. [sent-493, score-0.508]
</p><p>89 Simply optimizing the connection strength across a subset of selected nodes has already significantly improved the prediction with only a minimum (or mostly no) change of brain structure. [sent-495, score-0.503]
</p><p>90 Moreover, using SGBN-induced Fisher kernels, we are able to produce a new kind of features to analyze brain connectivity: the subject specific change of connection strength between nodes. [sent-496, score-0.427]
</p><p>91 fAt”ls (oi ndi gsrcereinm)in →ati“vmei are t ohec cipointanlec gtiyorunss  from the bias node to “middle occipital gyrus right” and to “precuneus left”. [sent-499, score-0.261]
</p><p>92 Conclusion In this paper, we present an approach to model brain effective connectivity encoded with essential discriminative information. [sent-501, score-0.68]
</p><p>93 With the link of Fisher kernel, our approach is able to simultaneously produce generative SGBN models and its associated SVM classifier, both of which possess sufficient discriminative power for brain network analysis of AD. [sent-502, score-0.806]
</p><p>94 In addition, by considering the changing rate of connection strength, our method also provides a new perspective for brain connectivity analysis. [sent-503, score-0.582]
</p><p>95 A sparse structure learning algorithm for gaussian bayesian network identification from high-dimensional data. [sent-512, score-0.278]
</p><p>96 Modeling spatial layout with fisher vectors for image categorization. [sent-530, score-0.294]
</p><p>97 Alterations of directional connectivity among resting-state networks in alzheimer disease. [sent-538, score-0.319]
</p><p>98 Gray matter concentration and effective connectivity changes in alzheimer’s disease: A longitudinal structural mri study. [sent-546, score-0.527]
</p><p>99 Efficient heuristics for discriminative structure learning ofbayesian network classifiers. [sent-569, score-0.33]
</p><p>100 Similaritybased extraction of individual networks from gray matter mri scans. [sent-597, score-0.392]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('sgbn', 0.493), ('brain', 0.349), ('fisher', 0.294), ('mri', 0.237), ('network', 0.195), ('mci', 0.187), ('connectivity', 0.186), ('pet', 0.143), ('dag', 0.14), ('lobe', 0.135), ('generative', 0.117), ('xi', 0.109), ('discriminative', 0.104), ('fitting', 0.095), ('nc', 0.093), ('bn', 0.093), ('ad', 0.09), ('disease', 0.081), ('alzheimer', 0.078), ('gyrus', 0.076), ('parietal', 0.076), ('sbn', 0.076), ('xjl', 0.076), ('kernel', 0.075), ('pij', 0.074), ('xil', 0.073), ('node', 0.072), ('rois', 0.07), ('roi', 0.068), ('subcortical', 0.067), ('occipital', 0.067), ('svm', 0.064), ('matter', 0.063), ('pa', 0.061), ('networks', 0.055), ('causal', 0.054), ('bayesian', 0.052), ('bns', 0.05), ('gbn', 0.05), ('lobes', 0.05), ('parent', 0.05), ('morphology', 0.05), ('connection', 0.047), ('sparseness', 0.047), ('mr', 0.046), ('bias', 0.046), ('st', 0.046), ('nodes', 0.043), ('groups', 0.042), ('effective', 0.041), ('power', 0.041), ('discrimination', 0.039), ('squared', 0.038), ('bsgbn', 0.038), ('hippocampus', 0.038), ('pernkopf', 0.038), ('patients', 0.038), ('gray', 0.037), ('tr', 0.037), ('symbols', 0.034), ('adni', 0.034), ('tracer', 0.034), ('dementia', 0.034), ('frontal', 0.033), ('prediction', 0.033), ('learning', 0.031), ('population', 0.031), ('fmri', 0.031), ('strength', 0.031), ('connections', 0.03), ('axi', 0.029), ('gij', 0.029), ('hyperplane', 0.029), ('separating', 0.029), ('edges', 0.029), ('temporal', 0.028), ('errors', 0.028), ('biomarkers', 0.028), ('pearson', 0.028), ('classifiers', 0.028), ('subtle', 0.028), ('class', 0.028), ('alue', 0.027), ('mwin', 0.027), ('conventional', 0.026), ('thirdly', 0.026), ('binarizing', 0.026), ('atlas', 0.026), ('directed', 0.026), ('svms', 0.026), ('induced', 0.026), ('sel', 0.025), ('neuroimage', 0.025), ('bound', 0.025), ('fi', 0.025), ('keep', 0.025), ('inducing', 0.024), ('structures', 0.024), ('overfitting', 0.024), ('reflect', 0.024)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000006 <a title="129-tfidf-1" href="./cvpr-2013-Discriminative_Brain_Effective_Connectivity_Analysis_for_Alzheimer%27s_Disease%3A_A_Kernel_Learning_Approach_upon_Sparse_Gaussian_Bayesian_Network.html">129 cvpr-2013-Discriminative Brain Effective Connectivity Analysis for Alzheimer's Disease: A Kernel Learning Approach upon Sparse Gaussian Bayesian Network</a></p>
<p>Author: Luping Zhou, Lei Wang, Lingqiao Liu, Philip Ogunbona, Dinggang Shen</p><p>Abstract: Analyzing brain networks from neuroimages is becoming a promising approach in identifying novel connectivitybased biomarkers for the Alzheimer’s disease (AD). In this regard, brain “effective connectivity ” analysis, which studies the causal relationship among brain regions, is highly challenging and of many research opportunities. Most of the existing works in this field use generative methods. Despite their success in data representation and other important merits, generative methods are not necessarily discriminative, which may cause the ignorance of subtle but critical disease-induced changes. In this paper, we propose a learning-based approach that integrates the benefits of generative and discriminative methods to recover effective connectivity. In particular, we employ Fisher kernel to bridge the generative models of sparse Bayesian networks (SBN) and the discriminative classifiers of SVMs, and convert the SBN parameter learning to Fisher kernel learning via minimizing a generalization error bound of SVMs. Our method is able to simultaneously boost the discriminative power of both the generative SBN models and the SBN-induced SVM classifiers via Fisher kernel. The proposed method is tested on analyzing brain effective connectivity for AD from ADNI data, and demonstrates significant improvements over the state-of-the-art work.</p><p>2 0.18859476 <a title="129-tfidf-2" href="./cvpr-2013-Area_Preserving_Brain_Mapping.html">44 cvpr-2013-Area Preserving Brain Mapping</a></p>
<p>Author: Zhengyu Su, Wei Zeng, Rui Shi, Yalin Wang, Jian Sun, Xianfeng Gu</p><p>Abstract: Brain mapping transforms the brain cortical surface to canonical planar domains, which plays a fundamental role in morphological study. Most existing brain mapping methods are based on angle preserving maps, which may introduce large area distortions. This work proposes an area preserving brain mapping method based on MongeBrenier theory. The brain mapping is intrinsic to the Riemannian metric, unique, and diffeomorphic. The computation is equivalent to convex energy minimization and power Voronoi diagram construction. Comparing to the existing approaches based on Monge-Kantorovich theory, the proposed one greatly reduces the complexity (from n2 unknowns to n ), and improves the simplicity and efficiency. Experimental results on caudate nucleus surface mapping and cortical surface mapping demonstrate the efficacy and efficiency of the proposed method. Conventional methods for caudate nucleus surface mapping may suffer from numerical instability; in contrast, current method produces diffeomorpic mappings stably. In the study of cortical sur- face classification for recognition of Alzheimer’s Disease, the proposed method outperforms some other morphometry features.</p><p>3 0.11270925 <a title="129-tfidf-3" href="./cvpr-2013-Semi-supervised_Learning_of_Feature_Hierarchies_for_Object_Detection_in_a_Video.html">388 cvpr-2013-Semi-supervised Learning of Feature Hierarchies for Object Detection in a Video</a></p>
<p>Author: Yang Yang, Guang Shu, Mubarak Shah</p><p>Abstract: We propose a novel approach to boost the performance of generic object detectors on videos by learning videospecific features using a deep neural network. The insight behind our proposed approach is that an object appearing in different frames of a video clip should share similar features, which can be learned to build better detectors. Unlike many supervised detector adaptation or detection-bytracking methods, our method does not require any extra annotations or utilize temporal correspondence. We start with the high-confidence detections from a generic detector, then iteratively learn new video-specific features and refine the detection scores. In order to learn discriminative and compact features, we propose a new feature learning method using a deep neural network based on auto encoders. It differs from the existing unsupervised feature learning methods in two ways: first it optimizes both discriminative and generative properties of the features simultaneously, which gives our features better discriminative ability; second, our learned features are more compact, while the unsupervised feature learning methods usually learn a redundant set of over-complete features. Extensive experimental results on person and horse detection show that significant performance improvement can be achieved with our proposed method.</p><p>4 0.094475783 <a title="129-tfidf-4" href="./cvpr-2013-PDM-ENLOR%3A_Learning_Ensemble_of_Local_PDM-Based_Regressions.html">321 cvpr-2013-PDM-ENLOR: Learning Ensemble of Local PDM-Based Regressions</a></p>
<p>Author: Yen H. Le, Uday Kurkure, Ioannis A. Kakadiaris</p><p>Abstract: Statistical shape models, such as Active Shape Models (ASMs), sufferfrom their inability to represent a large range of variations of a complex shape and to account for the large errors in detection of model points. We propose a novel method (dubbed PDM-ENLOR) that overcomes these limitations by locating each shape model point individually using an ensemble of local regression models and appearance cues from selected model points. Our method first detects a set of reference points which were selected based on their saliency during training. For each model point, an ensemble of regressors is built. From the locations of the detected reference points, each regressor infers a candidate location for that model point using local geometric constraints, encoded by a point distribution model (PDM). The final location of that point is determined as a weighted linear combination, whose coefficients are learnt from the training data, of candidates proposed from its ensemble ’s component regressors. We use different subsets of reference points as explanatory variables for the component regressors to provide varying degrees of locality for the models in each ensemble. This helps our ensemble model to capture a larger range of shape variations as compared to a single PDM. We demonstrate the advantages of our method on the challenging problem of segmenting gene expression images of mouse brain.</p><p>5 0.092495263 <a title="129-tfidf-5" href="./cvpr-2013-Efficient_Maximum_Appearance_Search_for_Large-Scale_Object_Detection.html">144 cvpr-2013-Efficient Maximum Appearance Search for Large-Scale Object Detection</a></p>
<p>Author: Qiang Chen, Zheng Song, Rogerio Feris, Ankur Datta, Liangliang Cao, Zhongyang Huang, Shuicheng Yan</p><p>Abstract: In recent years, efficiency of large-scale object detection has arisen as an important topic due to the exponential growth in the size of benchmark object detection datasets. Most current object detection methods focus on improving accuracy of large-scale object detection with efficiency being an afterthought. In this paper, we present the Efficient Maximum Appearance Search (EMAS) model which is an order of magnitude faster than the existing state-of-the-art large-scale object detection approaches, while maintaining comparable accuracy. Our EMAS model consists of representing an image as an ensemble of densely sampled feature points with the proposed Pointwise Fisher Vector encoding method, so that the learnt discriminative scoring function can be applied locally. Consequently, the object detection problem is transformed into searching an image sub-area for maximum local appearance probability, thereby making EMAS an order of magnitude faster than the traditional detection methods. In addition, the proposed model is also suitable for incorporating global context at a negligible extra computational cost. EMAS can also incorporate fusion of multiple features, which greatly improves its performance in detecting multiple object categories. Our experiments show that the proposed algorithm can perform detection of 1000 object classes in less than one minute per image on the Image Net ILSVRC2012 dataset and for 107 object classes in less than 5 seconds per image for the SUN09 dataset using a single CPU.</p><p>6 0.092199415 <a title="129-tfidf-6" href="./cvpr-2013-Multi-target_Tracking_by_Lagrangian_Relaxation_to_Min-cost_Network_Flow.html">300 cvpr-2013-Multi-target Tracking by Lagrangian Relaxation to Min-cost Network Flow</a></p>
<p>7 0.091459163 <a title="129-tfidf-7" href="./cvpr-2013-BFO_Meets_HOG%3A_Feature_Extraction_Based_on_Histograms_of_Oriented_p.d.f._Gradients_for_Image_Classification.html">53 cvpr-2013-BFO Meets HOG: Feature Extraction Based on Histograms of Oriented p.d.f. Gradients for Image Classification</a></p>
<p>8 0.086248353 <a title="129-tfidf-8" href="./cvpr-2013-Hyperbolic_Harmonic_Mapping_for_Constrained_Brain_Surface_Registration.html">208 cvpr-2013-Hyperbolic Harmonic Mapping for Constrained Brain Surface Registration</a></p>
<p>9 0.082186855 <a title="129-tfidf-9" href="./cvpr-2013-Graph_Transduction_Learning_with_Connectivity_Constraints_with_Application_to_Multiple_Foreground_Cosegmentation.html">193 cvpr-2013-Graph Transduction Learning with Connectivity Constraints with Application to Multiple Foreground Cosegmentation</a></p>
<p>10 0.078892633 <a title="129-tfidf-10" href="./cvpr-2013-Groupwise_Registration_via_Graph_Shrinkage_on_the_Image_Manifold.html">194 cvpr-2013-Groupwise Registration via Graph Shrinkage on the Image Manifold</a></p>
<p>11 0.078306004 <a title="129-tfidf-11" href="./cvpr-2013-Recovering_Line-Networks_in_Images_by_Junction-Point_Processes.html">351 cvpr-2013-Recovering Line-Networks in Images by Junction-Point Processes</a></p>
<p>12 0.073593192 <a title="129-tfidf-12" href="./cvpr-2013-A_Joint_Model_for_2D_and_3D_Pose_Estimation_from_a_Single_Image.html">14 cvpr-2013-A Joint Model for 2D and 3D Pose Estimation from a Single Image</a></p>
<p>13 0.068696938 <a title="129-tfidf-13" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<p>14 0.068243839 <a title="129-tfidf-14" href="./cvpr-2013-Blocks_That_Shout%3A_Distinctive_Parts_for_Scene_Classification.html">67 cvpr-2013-Blocks That Shout: Distinctive Parts for Scene Classification</a></p>
<p>15 0.068077065 <a title="129-tfidf-15" href="./cvpr-2013-Video_Object_Segmentation_through_Spatially_Accurate_and_Temporally_Dense_Extraction_of_Primary_Object_Regions.html">455 cvpr-2013-Video Object Segmentation through Spatially Accurate and Temporally Dense Extraction of Primary Object Regions</a></p>
<p>16 0.066133223 <a title="129-tfidf-16" href="./cvpr-2013-Learning_Cross-Domain_Information_Transfer_for_Location_Recognition_and_Clustering.html">250 cvpr-2013-Learning Cross-Domain Information Transfer for Location Recognition and Clustering</a></p>
<p>17 0.065530911 <a title="129-tfidf-17" href="./cvpr-2013-Probabilistic_Label_Trees_for_Efficient_Large_Scale_Image_Classification.html">340 cvpr-2013-Probabilistic Label Trees for Efficient Large Scale Image Classification</a></p>
<p>18 0.064101055 <a title="129-tfidf-18" href="./cvpr-2013-A_Higher-Order_CRF_Model_for_Road_Network_Extraction.html">13 cvpr-2013-A Higher-Order CRF Model for Road Network Extraction</a></p>
<p>19 0.063656375 <a title="129-tfidf-19" href="./cvpr-2013-Robust_Discriminative_Response_Map_Fitting_with_Constrained_Local_Models.html">359 cvpr-2013-Robust Discriminative Response Map Fitting with Constrained Local Models</a></p>
<p>20 0.063374415 <a title="129-tfidf-20" href="./cvpr-2013-Towards_Efficient_and_Exact_MAP-Inference_for_Large_Scale_Discrete_Computer_Vision_Problems_via_Combinatorial_Optimization.html">436 cvpr-2013-Towards Efficient and Exact MAP-Inference for Large Scale Discrete Computer Vision Problems via Combinatorial Optimization</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.151), (1, -0.022), (2, -0.029), (3, 0.016), (4, 0.042), (5, 0.02), (6, -0.003), (7, -0.027), (8, -0.036), (9, -0.016), (10, 0.04), (11, 0.009), (12, -0.073), (13, -0.044), (14, -0.039), (15, -0.003), (16, -0.009), (17, 0.018), (18, 0.103), (19, -0.024), (20, -0.035), (21, 0.007), (22, -0.015), (23, 0.028), (24, -0.047), (25, 0.104), (26, -0.012), (27, 0.004), (28, -0.012), (29, 0.042), (30, -0.016), (31, 0.008), (32, 0.061), (33, 0.044), (34, 0.031), (35, -0.024), (36, -0.0), (37, -0.035), (38, 0.079), (39, -0.032), (40, -0.05), (41, -0.092), (42, -0.005), (43, -0.009), (44, -0.012), (45, 0.006), (46, -0.034), (47, -0.112), (48, -0.016), (49, 0.001)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.90427321 <a title="129-lsi-1" href="./cvpr-2013-Discriminative_Brain_Effective_Connectivity_Analysis_for_Alzheimer%27s_Disease%3A_A_Kernel_Learning_Approach_upon_Sparse_Gaussian_Bayesian_Network.html">129 cvpr-2013-Discriminative Brain Effective Connectivity Analysis for Alzheimer's Disease: A Kernel Learning Approach upon Sparse Gaussian Bayesian Network</a></p>
<p>Author: Luping Zhou, Lei Wang, Lingqiao Liu, Philip Ogunbona, Dinggang Shen</p><p>Abstract: Analyzing brain networks from neuroimages is becoming a promising approach in identifying novel connectivitybased biomarkers for the Alzheimer’s disease (AD). In this regard, brain “effective connectivity ” analysis, which studies the causal relationship among brain regions, is highly challenging and of many research opportunities. Most of the existing works in this field use generative methods. Despite their success in data representation and other important merits, generative methods are not necessarily discriminative, which may cause the ignorance of subtle but critical disease-induced changes. In this paper, we propose a learning-based approach that integrates the benefits of generative and discriminative methods to recover effective connectivity. In particular, we employ Fisher kernel to bridge the generative models of sparse Bayesian networks (SBN) and the discriminative classifiers of SVMs, and convert the SBN parameter learning to Fisher kernel learning via minimizing a generalization error bound of SVMs. Our method is able to simultaneously boost the discriminative power of both the generative SBN models and the SBN-induced SVM classifiers via Fisher kernel. The proposed method is tested on analyzing brain effective connectivity for AD from ADNI data, and demonstrates significant improvements over the state-of-the-art work.</p><p>2 0.63319188 <a title="129-lsi-2" href="./cvpr-2013-Groupwise_Registration_via_Graph_Shrinkage_on_the_Image_Manifold.html">194 cvpr-2013-Groupwise Registration via Graph Shrinkage on the Image Manifold</a></p>
<p>Author: Shihui Ying, Guorong Wu, Qian Wang, Dinggang Shen</p><p>Abstract: Recently, groupwise registration has been investigated for simultaneous alignment of all images without selecting any individual image as the template, thus avoiding the potential bias in image registration. However, none of current groupwise registration method fully utilizes the image distribution to guide the registration. Thus, the registration performance usually suffers from large inter-subject variations across individual images. To solve this issue, we propose a novel groupwise registration algorithm for large population dataset, guided by the image distribution on the manifold. Specifically, we first use a graph to model the distribution of all image data sitting on the image manifold, with each node representing an image and each edge representing the geodesic pathway between two nodes (or images). Then, the procedure of warping all images to theirpopulation center turns to the dynamic shrinking ofthe graph nodes along their graph edges until all graph nodes become close to each other. Thus, the topology ofimage distribution on the image manifold is always preserved during the groupwise registration. More importantly, by modeling , the distribution of all images via a graph, we can potentially reduce registration error since every time each image is warped only according to its nearby images with similar structures in the graph. We have evaluated our proposed groupwise registration method on both synthetic and real datasets, with comparison to the two state-of-the-art groupwise registration methods. All experimental results show that our proposed method achieves the best performance in terms of registration accuracy and robustness.</p><p>3 0.62805951 <a title="129-lsi-3" href="./cvpr-2013-Area_Preserving_Brain_Mapping.html">44 cvpr-2013-Area Preserving Brain Mapping</a></p>
<p>Author: Zhengyu Su, Wei Zeng, Rui Shi, Yalin Wang, Jian Sun, Xianfeng Gu</p><p>Abstract: Brain mapping transforms the brain cortical surface to canonical planar domains, which plays a fundamental role in morphological study. Most existing brain mapping methods are based on angle preserving maps, which may introduce large area distortions. This work proposes an area preserving brain mapping method based on MongeBrenier theory. The brain mapping is intrinsic to the Riemannian metric, unique, and diffeomorphic. The computation is equivalent to convex energy minimization and power Voronoi diagram construction. Comparing to the existing approaches based on Monge-Kantorovich theory, the proposed one greatly reduces the complexity (from n2 unknowns to n ), and improves the simplicity and efficiency. Experimental results on caudate nucleus surface mapping and cortical surface mapping demonstrate the efficacy and efficiency of the proposed method. Conventional methods for caudate nucleus surface mapping may suffer from numerical instability; in contrast, current method produces diffeomorpic mappings stably. In the study of cortical sur- face classification for recognition of Alzheimer’s Disease, the proposed method outperforms some other morphometry features.</p><p>4 0.59337413 <a title="129-lsi-4" href="./cvpr-2013-Sparse_Output_Coding_for_Large-Scale_Visual_Recognition.html">403 cvpr-2013-Sparse Output Coding for Large-Scale Visual Recognition</a></p>
<p>Author: Bin Zhao, Eric P. Xing</p><p>Abstract: Many vision tasks require a multi-class classifier to discriminate multiple categories, on the order of hundreds or thousands. In this paper, we propose sparse output coding, a principled way for large-scale multi-class classification, by turning high-cardinality multi-class categorization into a bit-by-bit decoding problem. Specifically, sparse output coding is composed of two steps: efficient coding matrix learning with scalability to thousands of classes, and probabilistic decoding. Empirical results on object recognition and scene classification demonstrate the effectiveness ofour proposed approach.</p><p>5 0.58944058 <a title="129-lsi-5" href="./cvpr-2013-Reconstructing_Loopy_Curvilinear_Structures_Using_Integer_Programming.html">350 cvpr-2013-Reconstructing Loopy Curvilinear Structures Using Integer Programming</a></p>
<p>Author: Engin Türetken, Fethallah Benmansour, Bjoern Andres, Hanspeter Pfister, Pascal Fua</p><p>Abstract: We propose a novel approach to automated delineation of linear structures that form complex and potentially loopy networks. This is in contrast to earlier approaches that usually assume a tree topology for the networks. At the heart of our method is an Integer Programming formulation that allows us to find the global optimum of an objective function designed to allow cycles but penalize spurious junctions and early terminations. We demonstrate that it outperforms state-of-the-art techniques on a wide range of datasets.</p><p>6 0.58706552 <a title="129-lsi-6" href="./cvpr-2013-Recovering_Line-Networks_in_Images_by_Junction-Point_Processes.html">351 cvpr-2013-Recovering Line-Networks in Images by Junction-Point Processes</a></p>
<p>7 0.58176804 <a title="129-lsi-7" href="./cvpr-2013-Probabilistic_Label_Trees_for_Efficient_Large_Scale_Image_Classification.html">340 cvpr-2013-Probabilistic Label Trees for Efficient Large Scale Image Classification</a></p>
<p>8 0.56567103 <a title="129-lsi-8" href="./cvpr-2013-Computing_Diffeomorphic_Paths_for_Large_Motion_Interpolation.html">90 cvpr-2013-Computing Diffeomorphic Paths for Large Motion Interpolation</a></p>
<p>9 0.55767876 <a title="129-lsi-9" href="./cvpr-2013-From_Local_Similarity_to_Global_Coding%3A_An_Application_to_Image_Classification.html">178 cvpr-2013-From Local Similarity to Global Coding: An Application to Image Classification</a></p>
<p>10 0.54919004 <a title="129-lsi-10" href="./cvpr-2013-Transfer_Sparse_Coding_for_Robust_Image_Representation.html">442 cvpr-2013-Transfer Sparse Coding for Robust Image Representation</a></p>
<p>11 0.54686522 <a title="129-lsi-11" href="./cvpr-2013-Gauging_Association_Patterns_of_Chromosome_Territories_via_Chromatic_Median.html">184 cvpr-2013-Gauging Association Patterns of Chromosome Territories via Chromatic Median</a></p>
<p>12 0.54277951 <a title="129-lsi-12" href="./cvpr-2013-Hyperbolic_Harmonic_Mapping_for_Constrained_Brain_Surface_Registration.html">208 cvpr-2013-Hyperbolic Harmonic Mapping for Constrained Brain Surface Registration</a></p>
<p>13 0.54152572 <a title="129-lsi-13" href="./cvpr-2013-On_a_Link_Between_Kernel_Mean_Maps_and_Fraunhofer_Diffraction%2C_with_an_Application_to_Super-Resolution_Beyond_the_Diffraction_Limit.html">312 cvpr-2013-On a Link Between Kernel Mean Maps and Fraunhofer Diffraction, with an Application to Super-Resolution Beyond the Diffraction Limit</a></p>
<p>14 0.53931522 <a title="129-lsi-14" href="./cvpr-2013-SCaLE%3A_Supervised_and_Cascaded_Laplacian_Eigenmaps_for_Visual_Object_Recognition_Based_on_Nearest_Neighbors.html">371 cvpr-2013-SCaLE: Supervised and Cascaded Laplacian Eigenmaps for Visual Object Recognition Based on Nearest Neighbors</a></p>
<p>15 0.53303969 <a title="129-lsi-15" href="./cvpr-2013-A_Genetic_Algorithm-Based_Solver_for_Very_Large_Jigsaw_Puzzles.html">11 cvpr-2013-A Genetic Algorithm-Based Solver for Very Large Jigsaw Puzzles</a></p>
<p>16 0.53285956 <a title="129-lsi-16" href="./cvpr-2013-Discrete_MRF_Inference_of_Marginal_Densities_for_Non-uniformly_Discretized_Variable_Space.html">128 cvpr-2013-Discrete MRF Inference of Marginal Densities for Non-uniformly Discretized Variable Space</a></p>
<p>17 0.53009617 <a title="129-lsi-17" href="./cvpr-2013-Optimizing_1-Nearest_Prototype_Classifiers.html">320 cvpr-2013-Optimizing 1-Nearest Prototype Classifiers</a></p>
<p>18 0.52696645 <a title="129-lsi-18" href="./cvpr-2013-A_Fast_Approximate_AIB_Algorithm_for_Distributional_Word_Clustering.html">8 cvpr-2013-A Fast Approximate AIB Algorithm for Distributional Word Clustering</a></p>
<p>19 0.52485561 <a title="129-lsi-19" href="./cvpr-2013-Accurate_and_Robust_Registration_of_Nonrigid_Surface_Using_Hierarchical_Statistical_Shape_Model.html">31 cvpr-2013-Accurate and Robust Registration of Nonrigid Surface Using Hierarchical Statistical Shape Model</a></p>
<p>20 0.52474427 <a title="129-lsi-20" href="./cvpr-2013-Adaptive_Active_Learning_for_Image_Classification.html">34 cvpr-2013-Adaptive Active Learning for Image Classification</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.143), (16, 0.032), (26, 0.049), (33, 0.225), (53, 0.264), (67, 0.076), (69, 0.059), (87, 0.052)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.81581438 <a title="129-lda-1" href="./cvpr-2013-Modeling_Mutual_Visibility_Relationship_in_Pedestrian_Detection.html">288 cvpr-2013-Modeling Mutual Visibility Relationship in Pedestrian Detection</a></p>
<p>Author: Wanli Ouyang, Xingyu Zeng, Xiaogang Wang</p><p>Abstract: Detecting pedestrians in cluttered scenes is a challenging problem in computer vision. The difficulty is added when several pedestrians overlap in images and occlude each other. We observe, however, that the occlusion/visibility statuses of overlapping pedestrians provide useful mutual relationship for visibility estimation - the visibility estimation of one pedestrian facilitates the visibility estimation of another. In this paper, we propose a mutual visibility deep model that jointly estimates the visibility statuses of overlapping pedestrians. The visibility relationship among pedestrians is learned from the deep model for recognizing co-existing pedestrians. Experimental results show that the mutual visibility deep model effectively improves the pedestrian detection results. Compared with existing image-based pedestrian detection approaches, our approach has the lowest average miss rate on the CaltechTrain dataset, the Caltech-Test dataset and the ETHdataset. Including mutual visibility leads to 4% −8% improvements on mluudlitnipglem ubteunaclh vmiasibrki ditayta lesaedtss.</p><p>same-paper 2 0.8155781 <a title="129-lda-2" href="./cvpr-2013-Discriminative_Brain_Effective_Connectivity_Analysis_for_Alzheimer%27s_Disease%3A_A_Kernel_Learning_Approach_upon_Sparse_Gaussian_Bayesian_Network.html">129 cvpr-2013-Discriminative Brain Effective Connectivity Analysis for Alzheimer's Disease: A Kernel Learning Approach upon Sparse Gaussian Bayesian Network</a></p>
<p>Author: Luping Zhou, Lei Wang, Lingqiao Liu, Philip Ogunbona, Dinggang Shen</p><p>Abstract: Analyzing brain networks from neuroimages is becoming a promising approach in identifying novel connectivitybased biomarkers for the Alzheimer’s disease (AD). In this regard, brain “effective connectivity ” analysis, which studies the causal relationship among brain regions, is highly challenging and of many research opportunities. Most of the existing works in this field use generative methods. Despite their success in data representation and other important merits, generative methods are not necessarily discriminative, which may cause the ignorance of subtle but critical disease-induced changes. In this paper, we propose a learning-based approach that integrates the benefits of generative and discriminative methods to recover effective connectivity. In particular, we employ Fisher kernel to bridge the generative models of sparse Bayesian networks (SBN) and the discriminative classifiers of SVMs, and convert the SBN parameter learning to Fisher kernel learning via minimizing a generalization error bound of SVMs. Our method is able to simultaneously boost the discriminative power of both the generative SBN models and the SBN-induced SVM classifiers via Fisher kernel. The proposed method is tested on analyzing brain effective connectivity for AD from ADNI data, and demonstrates significant improvements over the state-of-the-art work.</p><p>3 0.77346212 <a title="129-lda-3" href="./cvpr-2013-Video_Editing_with_Temporal%2C_Spatial_and_Appearance_Consistency.html">453 cvpr-2013-Video Editing with Temporal, Spatial and Appearance Consistency</a></p>
<p>Author: Xiaojie Guo, Xiaochun Cao, Xiaowu Chen, Yi Ma</p><p>Abstract: Given an area of interest in a video sequence, one may want to manipulate or edit the area, e.g. remove occlusions from or replace with an advertisement on it. Such a task involves three main challenges including temporal consistency, spatial pose, and visual realism. The proposed method effectively seeks an optimal solution to simultaneously deal with temporal alignment, pose rectification, as well as precise recovery of the occlusion. To make our method applicable to long video sequences, we propose a batch alignment method for automatically aligning and rectifying a small number of initial frames, and then show how to align the remaining frames incrementally to the aligned base images. From the error residual of the robust alignment process, we automatically construct a trimap of the region for each frame, which is used as the input to alpha matting methods to extract the occluding foreground. Experimental results on both simulated and real data demonstrate the accurate and robust performance of our method.</p><p>4 0.75012678 <a title="129-lda-4" href="./cvpr-2013-Image_Matting_with_Local_and_Nonlocal_Smooth_Priors.html">211 cvpr-2013-Image Matting with Local and Nonlocal Smooth Priors</a></p>
<p>Author: Xiaowu Chen, Dongqing Zou, Steven Zhiying Zhou, Qinping Zhao, Ping Tan</p><p>Abstract: In this paper we propose a novel alpha matting method with local and nonlocal smooth priors. We observe that the manifold preserving editing propagation [4] essentially introduced a nonlocal smooth prior on the alpha matte. This nonlocal smooth prior and the well known local smooth priorfrom matting Laplacian complement each other. So we combine them with a simple data term from color sampling in a graph model for nature image matting. Our method has a closed-form solution and can be solved efficiently. Compared with the state-of-the-art methods, our method produces more accurate results according to the evaluation on standard benchmark datasets.</p><p>5 0.74190277 <a title="129-lda-5" href="./cvpr-2013-Area_Preserving_Brain_Mapping.html">44 cvpr-2013-Area Preserving Brain Mapping</a></p>
<p>Author: Zhengyu Su, Wei Zeng, Rui Shi, Yalin Wang, Jian Sun, Xianfeng Gu</p><p>Abstract: Brain mapping transforms the brain cortical surface to canonical planar domains, which plays a fundamental role in morphological study. Most existing brain mapping methods are based on angle preserving maps, which may introduce large area distortions. This work proposes an area preserving brain mapping method based on MongeBrenier theory. The brain mapping is intrinsic to the Riemannian metric, unique, and diffeomorphic. The computation is equivalent to convex energy minimization and power Voronoi diagram construction. Comparing to the existing approaches based on Monge-Kantorovich theory, the proposed one greatly reduces the complexity (from n2 unknowns to n ), and improves the simplicity and efficiency. Experimental results on caudate nucleus surface mapping and cortical surface mapping demonstrate the efficacy and efficiency of the proposed method. Conventional methods for caudate nucleus surface mapping may suffer from numerical instability; in contrast, current method produces diffeomorpic mappings stably. In the study of cortical sur- face classification for recognition of Alzheimer’s Disease, the proposed method outperforms some other morphometry features.</p><p>6 0.74106073 <a title="129-lda-6" href="./cvpr-2013-Improving_Image_Matting_Using_Comprehensive_Sampling_Sets.html">216 cvpr-2013-Improving Image Matting Using Comprehensive Sampling Sets</a></p>
<p>7 0.73082149 <a title="129-lda-7" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>8 0.72916812 <a title="129-lda-8" href="./cvpr-2013-Structure_Preserving_Object_Tracking.html">414 cvpr-2013-Structure Preserving Object Tracking</a></p>
<p>9 0.72488666 <a title="129-lda-9" href="./cvpr-2013-Part_Discovery_from_Partial_Correspondence.html">325 cvpr-2013-Part Discovery from Partial Correspondence</a></p>
<p>10 0.72464633 <a title="129-lda-10" href="./cvpr-2013-Online_Object_Tracking%3A_A_Benchmark.html">314 cvpr-2013-Online Object Tracking: A Benchmark</a></p>
<p>11 0.72400683 <a title="129-lda-11" href="./cvpr-2013-Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking.html">285 cvpr-2013-Minimum Uncertainty Gap for Robust Visual Tracking</a></p>
<p>12 0.72242713 <a title="129-lda-12" href="./cvpr-2013-Spatiotemporal_Deformable_Part_Models_for_Action_Detection.html">408 cvpr-2013-Spatiotemporal Deformable Part Models for Action Detection</a></p>
<p>13 0.72214371 <a title="129-lda-13" href="./cvpr-2013-Part-Based_Visual_Tracking_with_Online_Latent_Structural_Learning.html">324 cvpr-2013-Part-Based Visual Tracking with Online Latent Structural Learning</a></p>
<p>14 0.72184473 <a title="129-lda-14" href="./cvpr-2013-Integrating_Grammar_and_Segmentation_for_Human_Pose_Estimation.html">225 cvpr-2013-Integrating Grammar and Segmentation for Human Pose Estimation</a></p>
<p>15 0.72137433 <a title="129-lda-15" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<p>16 0.71837008 <a title="129-lda-16" href="./cvpr-2013-Understanding_Indoor_Scenes_Using_3D_Geometric_Phrases.html">446 cvpr-2013-Understanding Indoor Scenes Using 3D Geometric Phrases</a></p>
<p>17 0.71796489 <a title="129-lda-17" href="./cvpr-2013-Understanding_Bayesian_Rooms_Using_Composite_3D_Object_Models.html">445 cvpr-2013-Understanding Bayesian Rooms Using Composite 3D Object Models</a></p>
<p>18 0.71720278 <a title="129-lda-18" href="./cvpr-2013-Bottom-Up_Segmentation_for_Top-Down_Detection.html">70 cvpr-2013-Bottom-Up Segmentation for Top-Down Detection</a></p>
<p>19 0.71680367 <a title="129-lda-19" href="./cvpr-2013-Robust_Estimation_of_Nonrigid_Transformation_for_Point_Set_Registration.html">360 cvpr-2013-Robust Estimation of Nonrigid Transformation for Point Set Registration</a></p>
<p>20 0.71663958 <a title="129-lda-20" href="./cvpr-2013-Incorporating_Structural_Alternatives_and_Sharing_into_Hierarchy_for_Multiclass_Object_Recognition_and_Detection.html">221 cvpr-2013-Incorporating Structural Alternatives and Sharing into Hierarchy for Multiclass Object Recognition and Detection</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
