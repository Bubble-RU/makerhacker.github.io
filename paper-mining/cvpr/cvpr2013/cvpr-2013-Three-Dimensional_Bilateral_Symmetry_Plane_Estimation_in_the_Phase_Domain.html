<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>432 cvpr-2013-Three-Dimensional Bilateral Symmetry Plane Estimation in the Phase Domain</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-432" href="#">cvpr2013-432</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>432 cvpr-2013-Three-Dimensional Bilateral Symmetry Plane Estimation in the Phase Domain</h1>
<br/><p>Source: <a title="cvpr-2013-432-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Kakarala_Three-Dimensional_Bilateral_Symmetry_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Ramakrishna Kakarala, Prabhu Kaliamoorthi, Vittal Premachandran</p><p>Abstract: We show that bilateral symmetry plane estimation for three-dimensional (3-D) shapes may be carried out accurately, and efficiently, in the spherical harmonic domain. Our methods are valuable for applications where spherical harmonic expansion is already employed, such as 3-D shape registration, morphometry, and retrieval. We show that the presence of bilateral symmetry in the 3-D shape is equivalent to a linear phase structure in the corresponding spherical harmonic coefficients, and provide algorithms for estimating the orientation of the symmetry plane. The benefit of using spherical harmonic phase is that symmetry estimation reduces to matching a compact set of descriptors, without the need to solve a correspondence problem. Our methods work on point clouds as well as large-scale mesh models of 3-D shapes.</p><p>Reference: <a title="cvpr-2013-432-reference" href="../cvpr2013_reference/cvpr-2013-Three-Dimensional_Bilateral_Symmetry_Plane_Estimation_in_the_Phase_Domain_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Three-dimensional bilateral symmetry plane estimation in the phase domain Ramakrishna Kakarala, Prabhu Kaliamoorthi, and Vittal Premachandran School of Computer Engineering, Nanyang Technological University, Singapore  ramakri shna @ntu . [sent-1, score-0.961]
</p><p>2 Abstract We show that bilateral symmetry plane estimation for three-dimensional (3-D) shapes may be carried out accurately, and efficiently, in the spherical harmonic domain. [sent-4, score-1.539]
</p><p>3 Our methods are valuable for applications where spherical harmonic expansion is already employed, such as 3-D shape registration, morphometry, and retrieval. [sent-5, score-0.905]
</p><p>4 We show that the presence of bilateral symmetry in the 3-D shape is equivalent to a linear phase structure in the corresponding spherical harmonic coefficients, and provide algorithms for estimating the orientation of the symmetry plane. [sent-6, score-2.167]
</p><p>5 The benefit of using spherical harmonic phase is that symmetry estimation reduces to matching a compact set of descriptors, without the need to solve a correspondence problem. [sent-7, score-1.507]
</p><p>6 Introduction The motivation to apply spherical harmonic expansion to solve three-dimensional (3-D) computer vision problems stems from at least three well-known properties. [sent-10, score-0.846]
</p><p>7 First, the expansion summarizes a large number of shape points (ver-  tices or surface voxels) in a relatively small number of coefficients. [sent-11, score-0.18]
</p><p>8 Third, the spherical harmonic coefficients behave predictably under 3-D rotation. [sent-13, score-0.877]
</p><p>9 Accordingly, spherical harmonics have been successfully employed in computer vision for 3-D shape registration [10], morphometry [3], and recognition [7][9]. [sent-14, score-0.705]
</p><p>10 In this paper, we show that spherical harmonics also provide an accurate and efficient solution for estimating the bilateral symmetry plane of a 3-D shape. [sent-15, score-1.315]
</p><p>11 Bilateral symmetry has been studied in numerous works (for example, [12] [6][20]). [sent-16, score-0.491]
</p><p>12 However, the problem of estimating the symmetry plane through spherical harmonic coefficients alone has not been solved, though there are results for the special case of moment coefficients [11]. [sent-17, score-1.601]
</p><p>13 Consequently, with current techniques, if the spherical harmonic expansion has already been computed, as would be the case in . [sent-18, score-0.846]
</p><p>14 sg  (a) (b)  (c)(d) Figure 1: The image in (a) is reconstructed from only its Fourier phase in (b), illustrating phase’s importance to appearance. [sent-24, score-0.257]
</p><p>15 The same is true for the sphere: the continental edges in the world map (c) are clearly visible in (d), which is reconstructed from (c) using only the spherical harmonic “phase” as defined in this paper. [sent-25, score-0.759]
</p><p>16 the applications mentioned above, there is no way to reuse the computationally-expensive expansion to obtain a symmetry plane estimate. [sent-26, score-0.693]
</p><p>17 And yet, as we show, the information required to obtain the estimate is clearly available in the harmonic coefficients, and a relatively simple estimation algorithm is possible. [sent-27, score-0.322]
</p><p>18 Our approach makes use of the “phase” of spherical harmonics, which is a term without a widely-accepted definition for spherical harmonics. [sent-28, score-0.874]
</p><p>19 In contrast, phase is welldefined for the ordinary Fourier transform: on the real line, the phase of transform F is φ in the polar decomposition F = |F|ejφ. [sent-29, score-0.636]
</p><p>20 The analogous definition for spherical harmFo =nics |F must, as we argue below, consider vectors of coeffi-  cients and treat the unit vector direction (vector divided by its length) as the phase. [sent-30, score-0.477]
</p><p>21 It is well-known that for the ordinary Fourier transform, phase defines the locations of edges and is therefore more important for appearance than magnitude. [sent-31, score-0.29]
</p><p>22 Figure 1 shows that this is true for phase of spherical 222444999  harmonic coefficients as well. [sent-32, score-1.134]
</p><p>23 The figure motivates us to examine what must be true for spherical harmonic phase if symmetry exists in the spatial domain. [sent-33, score-1.507]
</p><p>24 Our main contribution shows that bilateral symmetry in spherical data manifests itself as linear phase structure in the spherical harmonic coefficients. [sent-34, score-2.042]
</p><p>25 Our results allow symmetry to be determined from any type of spherical harmonic expansion, which is valuable since there are several different expansions in use in the literature. [sent-35, score-1.273]
</p><p>26 We also propose new algorithms for estimating the orientation of the symmetry plane by maximizing the fit of a linear phase equivalent to the harmonic coefficients. [sent-36, score-1.271]
</p><p>27 Our methods work for a wide variety of data, including point clouds and polygonal meshes (open as well as watertight), and they do not require that the meshes be aligned to the symmetry or have a star-shaped property. [sent-38, score-0.555]
</p><p>28 Previous work Given a point cloud in 3-D, one method for finding can-  ×  didates for the bilateral symmetry plane is to evaluate the distance of corresponding points when reflected across each candidate plane. [sent-40, score-0.758]
</p><p>29 h Ienf tihtse th 3r ×ee eigenvectors determine orthogonal candidates for the symmetry plane. [sent-43, score-0.516]
</p><p>30 [6] describe a reflective symmetry descriptor that is constructed by measuring the norm of the projection of a voxel set onto the space of bilaterallysymmetric sets. [sent-47, score-0.515]
</p><p>31 The shape of the descriptor function agrees visually with the perceived symmetries of 3-D shapes, and is valuable for shape registration and classification. [sent-49, score-0.169]
</p><p>32 However, the problem of estimating the orientation of the symmetry plane is not discussed in [6]. [sent-50, score-0.641]
</p><p>33 The 3-D Fourier transform is calculated on a psuedo-polar grid to detect symmetry groups in voxel data [1]. [sent-54, score-0.574]
</p><p>34 The richness of the literature on 3-D symmetry shows that the topic is of considerable interest. [sent-55, score-0.491]
</p><p>35 While many facets of symmetry have been explored, there is no existing work on determining bilateral symmetry from spherical harmonic expansion alone. [sent-56, score-1.926]
</p><p>36 [11] show that local minima for the spherical harmonic coefficients of evenorder moments provide candidates for the symmetry axis. [sent-58, score-1.393]
</p><p>37 To evaluate the suitability of a candidate reflection R, they compute the maximum possible distance between all vertices of S and their nearest points (which are found by minimization) in the reflection of S by R. [sent-59, score-0.281]
</p><p>38 That calculation is expensive, and does not take advantage of the structure present in the spherical harmonic coefficients. [sent-60, score-0.759]
</p><p>39 In this paper, we compute a much cheaper and more suitable distance using spherical harmonics coefficients alone, which is a substantial savings since a shape having thousands of vertices may be represented using only a few tens of coefficients. [sent-61, score-0.849]
</p><p>40 Moreover, the wide-spread use of spherical harmonics in various applications, as mentioned above, makes it attractive to investigate how to estimate the symmetry plane from harmonic coefficients alone. [sent-62, score-1.657]
</p><p>41 Our methods are compatible with each of the numerous uses of spherical harmonics in the literature, whether applied to the spherical mappings in [6], to the even-order moments in [11], or to the Zernike  coefficient mapping in [9]. [sent-63, score-1.138]
</p><p>42 Notation and background Conventions and notations for spherical harmonics vary across many papers on 3-D vision, and therefore we specify ours in this section, referring to standard works [21] for details. [sent-65, score-0.66]
</p><p>43 (1)  Spherical harmonics form an orthogonal basis for functions on S2, and, for each non-negative integer ? [sent-69, score-0.174]
</p><p>44 the spherical harmonic coefficients is important to our development. [sent-125, score-0.877]
</p><p>45 e tRedota btiyo n3 i×n t3he o spherical mhaarmtrioxn Pic domain is determined for each frequency ? [sent-127, score-0.437]
</p><p>46 Data in 3-D vision tasks are frequently presented as a set of points (xi, yi, zi), or equivalently in spherical coordinates (αi, βi, ρi), for i = 1, . [sent-152, score-0.437]
</p><p>47 Such data may be approximated with spherical harmonics by choosing coefficients F to minimize the squared error  i? [sent-156, score-0.729]
</p><p>48 The first case minimizes (7) by fitting the vertices from a triangulated mesh model, and is referred to as the vertex mapping in this paper. [sent-172, score-0.332]
</p><p>49 The EGI mapping of the model is obtained from surface normals, shown superimposed on  the model in (d), and approximated in (e) and (f). [sent-176, score-0.173]
</p><p>50 Symmetry  is equivalent to linear phase  Taking inspiration from the magnitude-phase decomposition of the real-line Fourier transform value as F = |F|ejφ, we define the magnitude-phase decomposition for t|Fhe| spherical harmonic vector F? [sent-178, score-1.057]
</p><p>51 unitary), ibnust tnhvea spherical rh raortmaotionnic phase hroetDates m as U? [sent-196, score-0.694]
</p><p>52 The spherical harmonic phase also transforms in a simple way under reflection. [sent-202, score-1.016]
</p><p>53 Consequently, p(2ar)a msheotwersi ztahtaiot nth oef spherical eha, αrmo? [sent-205, score-0.437]
</p><p>54 For each case, the spherical harmonic approximation to the mapping function is necessarily a star-shaped surface, but is still able to capture a variety of surface features, as such as the antennae as illustrated for the vertex mapping in part (c) of Fig. [sent-208, score-1.057]
</p><p>55 Now suppose that the reflection is across a plane Fwit? [sent-213, score-0.221]
</p><p>56 (8) Consequently, if f is reflection symmetric across N⊥, then for every rotation P such that PN = Y , we must have that F? [sent-237, score-0.241]
</p><p>57 (9)  This relationship helps to establish conditions for bilateral symmetry in the spherical harmonic domain. [sent-242, score-1.348]
</p><p>58 If a real-valued function h has symmetry across the origin, i. [sent-255, score-0.514]
</p><p>59 Such functions are described in signal processing as having linear phase, since the phase component ωx0 is linearly dependent on the shift x0. [sent-261, score-0.257]
</p><p>60 (10)  Note the similarity of (10) to (9), with the translation phase ejωx0 replaced by the rotation phase D? [sent-263, score-0.592]
</p><p>61 Finding the symmetry plane Since symmetric functions have linear-phase spherical harmonic coefficients, the problem of finding the symmetry plane requires optimizing a linear phase fit to the observed coefficients. [sent-266, score-2.365]
</p><p>62 n∗, we impose a similar symmetry for the rea=l c (o−e1ffi)cients: R−? [sent-296, score-0.491]
</p><p>63 opt  Inserting back into (12) and simplifying, we obtain our Imnsaienr ithnegoRretical result: the optimal choice for the rotation P that determines the orientation of the symmetry plane is obtained by maximizing the function ? [sent-344, score-0.719]
</p><p>64 1  Note that (14) is expressed only in terms of the spherical harmonics coefficients F and the rotation P, and the previously unnikcsno cwoenf ireciaeln nctose Fffi acinednt tsh eR r ohtaavtieo bne Pen, aenlidm thineat perdev. [sent-357, score-0.807]
</p><p>65 Third, if f is linear phase and therefore has coefficients F? [sent-372, score-0.375]
</p><p>66 1  (15) Setting P = PN, the true symmetry plane, gives the global maximum in this case, as expected. [sent-390, score-0.491]
</p><p>67 Fourth, if P is a rotation about the y axis (Euler angles α = γ = 0), then D? [sent-391, score-0.16]
</p><p>68 This is intuitively reasonable, since only two angles are required to specify the orientation of a plane in 3-D. [sent-398, score-0.258]
</p><p>69 Finally, calculation of (14) is efficient because it depends only on a relatively small number of spherical harmonic coefficients, and not on the much larger number of vertices. [sent-399, score-0.759]
</p><p>70 Optimum estimates for the symmetry plane The form of Φ in (14? [sent-402, score-0.606]
</p><p>71 Darker red values indicate improving estimates of the symmetry plane of (a). [sent-460, score-0.606]
</p><p>72 over three Euler angles α, β, and γ, which is, in principle, unnecessary, as two angles suffice to specify the orientation of the symmetry plane. [sent-462, score-0.716]
</p><p>73 To perform the search efficiently, we use a nested polar grid search, in which we 222555333  perform initially a coarse grid search by evaluating N values of α, β over [0, π] . [sent-482, score-0.192]
</p><p>74 As a baseline for both algorithms, we use the three eigenvectors of the covariance matrix to obtain three corresponding candidates for the symmetry plane. [sent-498, score-0.553]
</p><p>75 Experimental methods and results We estimate spherical harmonic coefficients using the iterated residual fitting (IRF) method [3]. [sent-502, score-0.905]
</p><p>76 Previous works have tested symmetry estimation on a relatively small number of shapes, and tested robustness by simulating acquisition and topological noise [1][1 1][20]. [sent-509, score-0.515]
</p><p>77 (a)(b)(c)  Figure 5: Uniform densification is illustrated for the plant model in (a), whose 316 vertices are plotted in (b), and whose densified samples are shown in (c). [sent-510, score-0.218]
</p><p>78 However, the vertices are not uniformly distributed across the shape’s surface, which may affect the symmetry estimation. [sent-515, score-0.598]
</p><p>79 Therefore, we uniformly sample a dense set of points across the surface of the shape by relying on the triangulated mesh. [sent-516, score-0.176]
</p><p>80 With such a representation, the points are more uniformly distributed on the shape surface, helping the identification of symmetry planes. [sent-519, score-0.527]
</p><p>81 In our experiments, every shape is randomly rotated in  all three Euler angles prior to symmetry estimation. [sent-521, score-0.609]
</p><p>82 To provide a shape-independent measure of fit, we define the normalized fitting error as the relative error between the linear phase fit for the optimum rotation Popt and its upper bound:  E(Popt) = 100 ×? [sent-522, score-0.46]
</p><p>83 Figure 6 shows examples from the PSB database of various degrees of symmetry and the associated fit. [sent-534, score-0.491]
</p><p>84 We found over numerous shapes that the E measure correlated well with our perception of how well the symmetry plane fit the shape. [sent-535, score-0.733]
</p><p>85 In each case the symmetry plane found by optimizing (14) with SH-ISA is shown superimposed in green. [sent-540, score-0.684]
</p><p>86 Rows 2-4 show results for the PSB database, and contain respectively the results for the EGI mapping, the vertex mapping using original vertices, denoted (O), and the vertex mapping using the densified vertices (D); similarly for other rows and S 10 and SEG databases. [sent-542, score-0.385]
</p><p>87 We find that the symmetry plane is signifi-  cantly better estimated using the vertex mapping than the EGI mapping, reducing E by at least 30%, and also that densification improves the vertex mapping results substantially, by similar amounts. [sent-545, score-0.975]
</p><p>88 The EGI mapping is unique only for convex objects, and does not capture shape properties as well as vertex mapping (see Fig. [sent-546, score-0.237]
</p><p>89 %  Figure 7: The symmetry plane from SH-ISA is shown superimposed in green. [sent-556, score-0.655]
</p><p>90 in the shape, as a benefit of (14) relying on the spherical harmonic expansion alone. [sent-558, score-0.871]
</p><p>91 The robustness of our linear phase methods are due to the least-squares fit of the spherical harmonic coefficients using IRF, the ability of low-frequency spherical harmonics to smooth fluctuations, and performing optimization of (14) without differentiation. [sent-560, score-1.796]
</p><p>92 The main limitation in symmetry determination is the spherical mapping. [sent-563, score-0.928]
</p><p>93 One important case is articulated shapes, which requires an analysis of intrinsic symmetry  [17], and would normally fail with the extrinsic methods used here, as shown in the left column of Figure 8. [sent-564, score-0.491]
</p><p>94 Summary and conclusions Figure 1inspires us to look in the phase domain for information about symmetry. [sent-569, score-0.257]
</p><p>95 By developing the idea that linear phase in spherical harmonic coefficients is equivalent to bilateral symmetry, our main theoretical contribution shows that optimizing the degree of linear phase fit is equivalent to estimating the symmetry plane. [sent-570, score-2.06]
</p><p>96 Our method is compatible with those works in that it is able to use any symmetry-preserving mapping to the sphere, including the vertex mapping and EGI mapping. [sent-573, score-0.201]
</p><p>97 Beyond symmetry, our results suggest that the phase of spherical harmonics is rich in other information about 3-D structure. [sent-574, score-0.868]
</p><p>98 Furthermore, the structural properties of phase for three-variable spherical harmonics, or SPHARM [16] constitute another interesting extension to explore. [sent-576, score-0.694]
</p><p>99 3-D symmetry detection and analysis using the pseudo-polar Fourier transform. [sent-581, score-0.491]
</p><p>100 Rotation invariant spherical harmonic representation of 3D shape descriptors. [sent-635, score-0.795]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('symmetry', 0.491), ('spherical', 0.437), ('harmonic', 0.322), ('phase', 0.257), ('harmonics', 0.174), ('euler', 0.16), ('wigner', 0.141), ('egi', 0.121), ('coefficients', 0.118), ('plane', 0.115), ('fourier', 0.111), ('densification', 0.101), ('bilateral', 0.098), ('expansion', 0.087), ('vertices', 0.084), ('reflection', 0.083), ('angles', 0.082), ('psb', 0.081), ('rotation', 0.078), ('shapes', 0.076), ('vertex', 0.067), ('mapping', 0.067), ('martinet', 0.061), ('popt', 0.061), ('py', 0.06), ('kazhdan', 0.06), ('symmetric', 0.057), ('surface', 0.057), ('ej', 0.056), ('pn', 0.056), ('irf', 0.054), ('sphere', 0.052), ('fit', 0.051), ('mesh', 0.051), ('symmetries', 0.049), ('superimposed', 0.049), ('seg', 0.047), ('optimum', 0.046), ('dof', 0.045), ('grid', 0.042), ('bandwidth', 0.041), ('transform', 0.041), ('antennae', 0.04), ('chazelle', 0.04), ('cients', 0.04), ('pyp', 0.04), ('covariance', 0.037), ('databases', 0.036), ('kakarala', 0.036), ('shrec', 0.036), ('shape', 0.036), ('triangle', 0.036), ('nested', 0.035), ('orientation', 0.035), ('triangulated', 0.035), ('zernike', 0.033), ('funkhouser', 0.033), ('morphometry', 0.033), ('densified', 0.033), ('ordinary', 0.033), ('nearly', 0.032), ('meshes', 0.032), ('candidate', 0.031), ('makadia', 0.031), ('unitary', 0.03), ('optimizing', 0.029), ('raising', 0.029), ('transactions', 0.028), ('fitting', 0.028), ('ntu', 0.028), ('rte', 0.027), ('specify', 0.026), ('inserting', 0.026), ('annealing', 0.026), ('fft', 0.026), ('trace', 0.026), ('candidates', 0.025), ('princeton', 0.025), ('polar', 0.025), ('isometric', 0.025), ('registration', 0.025), ('relying', 0.025), ('nz', 0.025), ('ny', 0.024), ('search', 0.024), ('eigenvalues', 0.024), ('consequently', 0.024), ('simulating', 0.024), ('bronstein', 0.024), ('ant', 0.024), ('reflective', 0.024), ('across', 0.023), ('valuable', 0.023), ('airplane', 0.023), ('coefficient', 0.023), ('sin', 0.023), ('processor', 0.023), ('mitra', 0.023), ('real', 0.023), ('mirror', 0.022)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="432-tfidf-1" href="./cvpr-2013-Three-Dimensional_Bilateral_Symmetry_Plane_Estimation_in_the_Phase_Domain.html">432 cvpr-2013-Three-Dimensional Bilateral Symmetry Plane Estimation in the Phase Domain</a></p>
<p>Author: Ramakrishna Kakarala, Prabhu Kaliamoorthi, Vittal Premachandran</p><p>Abstract: We show that bilateral symmetry plane estimation for three-dimensional (3-D) shapes may be carried out accurately, and efficiently, in the spherical harmonic domain. Our methods are valuable for applications where spherical harmonic expansion is already employed, such as 3-D shape registration, morphometry, and retrieval. We show that the presence of bilateral symmetry in the 3-D shape is equivalent to a linear phase structure in the corresponding spherical harmonic coefficients, and provide algorithms for estimating the orientation of the symmetry plane. The benefit of using spherical harmonic phase is that symmetry estimation reduces to matching a compact set of descriptors, without the need to solve a correspondence problem. Our methods work on point clouds as well as large-scale mesh models of 3-D shapes.</p><p>2 0.15824772 <a title="432-tfidf-2" href="./cvpr-2013-Depth_Acquisition_from_Density_Modulated_Binary_Patterns.html">114 cvpr-2013-Depth Acquisition from Density Modulated Binary Patterns</a></p>
<p>Author: Zhe Yang, Zhiwei Xiong, Yueyi Zhang, Jiao Wang, Feng Wu</p><p>Abstract: This paper proposes novel density modulated binary patterns for depth acquisition. Similar to Kinect, the illumination patterns do not need a projector for generation and can be emitted by infrared lasers and diffraction gratings. Our key idea is to use the density of light spots in the patterns to carry phase information. Two technical problems are addressed here. First, we propose an algorithm to design the patterns to carry more phase information without compromising the depth reconstruction from a single captured image as with Kinect. Second, since the carried phase is not strictly sinusoidal, the depth reconstructed from the phase contains a systematic error. We further propose a pixelbased phase matching algorithm to reduce the error. Experimental results show that the depth quality can be greatly improved using the phase carried by the density of light spots. Furthermore, our scheme can achieve 20 fps depth reconstruction with GPU assistance.</p><p>3 0.15741216 <a title="432-tfidf-3" href="./cvpr-2013-Analytic_Bilinear_Appearance_Subspace_Construction_for_Modeling_Image_Irradiance_under_Natural_Illumination_and_Non-Lambertian_Reflectance.html">42 cvpr-2013-Analytic Bilinear Appearance Subspace Construction for Modeling Image Irradiance under Natural Illumination and Non-Lambertian Reflectance</a></p>
<p>Author: Shireen Y. Elhabian, Aly A. Farag</p><p>Abstract: Conventional subspace construction approaches suffer from the need of “large-enough ” image ensemble rendering numerical methods intractable. In this paper, we propose an analytic formulation for low-dimensional subspace construction in which shading cues lie while preserving the natural structure of an image sample. Using the frequencyspace representation of the image irradiance equation, the process of finding such subspace is cast as establishing a relation between its principal components and that of a deterministic set of basis functions, termed as irradiance harmonics. Representing images as matrices further lessen the number of parameters to be estimated to define a bilinear projection which maps the image sample to a lowerdimensional bilinear subspace. Results show significant impact on dimensionality reduction with minimal loss of information as well as robustness against noise.</p><p>4 0.1569497 <a title="432-tfidf-4" href="./cvpr-2013-Determining_Motion_Directly_from_Normal_Flows_Upon_the_Use_of_a_Spherical_Eye_Platform.html">124 cvpr-2013-Determining Motion Directly from Normal Flows Upon the Use of a Spherical Eye Platform</a></p>
<p>Author: Tak-Wai Hui, Ronald Chung</p><p>Abstract: We address the problem of recovering camera motion from video data, which does not require the establishment of feature correspondences or computation of optical flows but from normal flows directly. We have designed an imaging system that has a wide field of view by fixating a number of cameras together to form an approximate spherical eye. With a substantially widened visual field, we discover that estimating the directions of translation and rotation components of the motion separately are possible and particularly efficient. In addition, the inherent ambiguities between translation and rotation also disappear. Magnitude of rotation is recovered subsequently. Experimental results on synthetic and real image data are provided. The results show that not only the accuracy of motion estimation is comparable to those of the state-of-the-art methods that require explicit feature correspondences or optical flows, but also a faster computation time.</p><p>5 0.14345838 <a title="432-tfidf-5" href="./cvpr-2013-Hyperbolic_Harmonic_Mapping_for_Constrained_Brain_Surface_Registration.html">208 cvpr-2013-Hyperbolic Harmonic Mapping for Constrained Brain Surface Registration</a></p>
<p>Author: Rui Shi, Wei Zeng, Zhengyu Su, Hanna Damasio, Zhonglin Lu, Yalin Wang, Shing-Tung Yau, Xianfeng Gu</p><p>Abstract: Automatic computation of surface correspondence via harmonic map is an active research field in computer vision, computer graphics and computational geometry. It may help document and understand physical and biological phenomena and also has broad applications in biometrics, medical imaging and motion capture. Although numerous studies have been devoted to harmonic map research, limited progress has been made to compute a diffeomorphic harmonic map on general topology surfaces with landmark constraints. This work conquer this problem by changing the Riemannian metric on the target surface to a hyperbolic metric, so that the harmonic mapping is guaranteed to be a diffeomorphism under landmark constraints. The computational algorithms are based on the Ricci flow method and the method is general and robust. We apply our algorithm to study constrained human brain surface registration problem. Experimental results demonstrate that, by changing the Riemannian metric, the registrations are always diffeomorphic, and achieve relative high performance when evaluated with some popular cortical surface registration evaluation standards.</p><p>6 0.13419753 <a title="432-tfidf-6" href="./cvpr-2013-Single_Image_Calibration_of_Multi-axial_Imaging_Systems.html">400 cvpr-2013-Single Image Calibration of Multi-axial Imaging Systems</a></p>
<p>7 0.13221192 <a title="432-tfidf-7" href="./cvpr-2013-Multi-resolution_Shape_Analysis_via_Non-Euclidean_Wavelets%3A_Applications_to_Mesh_Segmentation_and_Surface_Alignment_Problems.html">297 cvpr-2013-Multi-resolution Shape Analysis via Non-Euclidean Wavelets: Applications to Mesh Segmentation and Surface Alignment Problems</a></p>
<p>8 0.11476122 <a title="432-tfidf-8" href="./cvpr-2013-Axially_Symmetric_3D_Pots_Configuration_System_Using_Axis_of_Symmetry_and_Break_Curve.html">52 cvpr-2013-Axially Symmetric 3D Pots Configuration System Using Axis of Symmetry and Break Curve</a></p>
<p>9 0.10373734 <a title="432-tfidf-9" href="./cvpr-2013-Multi-view_Photometric_Stereo_with_Spatially_Varying_Isotropic_Materials.html">303 cvpr-2013-Multi-view Photometric Stereo with Spatially Varying Isotropic Materials</a></p>
<p>10 0.089867167 <a title="432-tfidf-10" href="./cvpr-2013-Pattern-Driven_Colorization_of_3D_Surfaces.html">327 cvpr-2013-Pattern-Driven Colorization of 3D Surfaces</a></p>
<p>11 0.086079702 <a title="432-tfidf-11" href="./cvpr-2013-Keypoints_from_Symmetries_by_Wave_Propagation.html">240 cvpr-2013-Keypoints from Symmetries by Wave Propagation</a></p>
<p>12 0.082276426 <a title="432-tfidf-12" href="./cvpr-2013-Mirror_Surface_Reconstruction_from_a_Single_Image.html">286 cvpr-2013-Mirror Surface Reconstruction from a Single Image</a></p>
<p>13 0.078192882 <a title="432-tfidf-13" href="./cvpr-2013-Incorporating_User_Interaction_and_Topological_Constraints_within_Contour_Completion_via_Discrete_Calculus.html">222 cvpr-2013-Incorporating User Interaction and Topological Constraints within Contour Completion via Discrete Calculus</a></p>
<p>14 0.07815598 <a title="432-tfidf-14" href="./cvpr-2013-Correspondence-Less_Non-rigid_Registration_of_Triangular_Surface_Meshes.html">97 cvpr-2013-Correspondence-Less Non-rigid Registration of Triangular Surface Meshes</a></p>
<p>15 0.077675968 <a title="432-tfidf-15" href="./cvpr-2013-Towards_Pose_Robust_Face_Recognition.html">438 cvpr-2013-Towards Pose Robust Face Recognition</a></p>
<p>16 0.071363166 <a title="432-tfidf-16" href="./cvpr-2013-Non-rigid_Structure_from_Motion_with_Diffusion_Maps_Prior.html">306 cvpr-2013-Non-rigid Structure from Motion with Diffusion Maps Prior</a></p>
<p>17 0.070731312 <a title="432-tfidf-17" href="./cvpr-2013-Probabilistic_Elastic_Matching_for_Pose_Variant_Face_Verification.html">338 cvpr-2013-Probabilistic Elastic Matching for Pose Variant Face Verification</a></p>
<p>18 0.065359674 <a title="432-tfidf-18" href="./cvpr-2013-Calibrating_Photometric_Stereo_by_Holistic_Reflectance_Symmetry_Analysis.html">75 cvpr-2013-Calibrating Photometric Stereo by Holistic Reflectance Symmetry Analysis</a></p>
<p>19 0.063852683 <a title="432-tfidf-19" href="./cvpr-2013-Uncalibrated_Photometric_Stereo_for_Unknown_Isotropic_Reflectances.html">443 cvpr-2013-Uncalibrated Photometric Stereo for Unknown Isotropic Reflectances</a></p>
<p>20 0.062717132 <a title="432-tfidf-20" href="./cvpr-2013-Optical_Flow_Estimation_Using_Laplacian_Mesh_Energy.html">316 cvpr-2013-Optical Flow Estimation Using Laplacian Mesh Energy</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.138), (1, 0.109), (2, -0.006), (3, 0.052), (4, 0.013), (5, -0.075), (6, -0.056), (7, -0.025), (8, 0.002), (9, -0.038), (10, -0.005), (11, 0.019), (12, -0.061), (13, -0.082), (14, 0.043), (15, -0.024), (16, 0.087), (17, 0.021), (18, 0.03), (19, 0.067), (20, -0.059), (21, 0.01), (22, -0.02), (23, 0.016), (24, -0.054), (25, 0.058), (26, 0.0), (27, -0.016), (28, -0.024), (29, -0.037), (30, 0.017), (31, 0.103), (32, 0.077), (33, 0.008), (34, -0.006), (35, 0.01), (36, 0.023), (37, 0.014), (38, 0.023), (39, 0.024), (40, -0.008), (41, 0.02), (42, 0.058), (43, 0.013), (44, -0.02), (45, 0.09), (46, 0.01), (47, 0.058), (48, -0.126), (49, -0.058)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95057082 <a title="432-lsi-1" href="./cvpr-2013-Three-Dimensional_Bilateral_Symmetry_Plane_Estimation_in_the_Phase_Domain.html">432 cvpr-2013-Three-Dimensional Bilateral Symmetry Plane Estimation in the Phase Domain</a></p>
<p>Author: Ramakrishna Kakarala, Prabhu Kaliamoorthi, Vittal Premachandran</p><p>Abstract: We show that bilateral symmetry plane estimation for three-dimensional (3-D) shapes may be carried out accurately, and efficiently, in the spherical harmonic domain. Our methods are valuable for applications where spherical harmonic expansion is already employed, such as 3-D shape registration, morphometry, and retrieval. We show that the presence of bilateral symmetry in the 3-D shape is equivalent to a linear phase structure in the corresponding spherical harmonic coefficients, and provide algorithms for estimating the orientation of the symmetry plane. The benefit of using spherical harmonic phase is that symmetry estimation reduces to matching a compact set of descriptors, without the need to solve a correspondence problem. Our methods work on point clouds as well as large-scale mesh models of 3-D shapes.</p><p>2 0.75673163 <a title="432-lsi-2" href="./cvpr-2013-Axially_Symmetric_3D_Pots_Configuration_System_Using_Axis_of_Symmetry_and_Break_Curve.html">52 cvpr-2013-Axially Symmetric 3D Pots Configuration System Using Axis of Symmetry and Break Curve</a></p>
<p>Author: Kilho Son, Eduardo B. Almeida, David B. Cooper</p><p>Abstract: Thispaper introduces a novel approachfor reassembling pot sherds found at archaeological excavation sites, for the purpose ofreconstructing claypots that had been made on a wheel. These pots and the sherds into which they have broken are axially symmetric. The reassembly process can be viewed as 3D puzzle solving or generalized cylinder learning from broken fragments. The estimation exploits both local and semi-global geometric structure, thus making it a fundamental problem of geometry estimation from noisy fragments in computer vision and pattern recognition. The data used are densely digitized 3D laser scans of each fragment’s outer surface. The proposed reassembly system is automatic and functions when the pile of available fragments is from one or multiple pots, and even when pieces are missing from any pot. The geometric structure used are curves on the pot along which the surface had broken and the silhouette of a pot with respect to an axis, called axisprofile curve (APC). For reassembling multiple pots with or without missing pieces, our algorithm estimates the APC from each fragment, then reassembles into configurations the ones having distinctive APC. Further growth of configurations is based on adding remaining fragments such that their APC and break curves are consistent with those of a configuration. The method is novel, more robust and handles the largest numbers of fragments to date.</p><p>3 0.70703024 <a title="432-lsi-3" href="./cvpr-2013-Towards_Contactless%2C_Low-Cost_and_Accurate_3D_Fingerprint_Identification.html">435 cvpr-2013-Towards Contactless, Low-Cost and Accurate 3D Fingerprint Identification</a></p>
<p>Author: Ajay Kumar, Cyril Kwong</p><p>Abstract: In order to avail the benefits of higher user convenience, hygiene, and improved accuracy, contactless 3D fingerprint recognition techniques have recently been introduced. One of the key limitations of these emerging 3D fingerprint technologies to replace the conventional 2D fingerprint system is their bulk and high cost, which mainly results from the use of multiple imaging cameras or structured lighting employed in these systems. This paper details the development of a contactless 3D fingerprint identification system that uses only single camera. We develop a new representation of 3D finger surface features using Finger Surface Codes and illustrate its effectiveness in matching 3D fingerprints. Conventional minutiae representation is extended in 3D space to accurately match the recovered 3D minutiae. Multiple 2D fingerprint images (with varying illumination profile) acquired to build 3D fingerprints can themselves be used recover 2D features for further improving 3D fingerprint identification and has been illustrated in this paper. The experimental results are shown on a database of 240 client fingerprints and confirm the advantages of the single camera based 3D fingerprint identification.</p><p>4 0.68816394 <a title="432-lsi-4" href="./cvpr-2013-Mirror_Surface_Reconstruction_from_a_Single_Image.html">286 cvpr-2013-Mirror Surface Reconstruction from a Single Image</a></p>
<p>Author: Miaomiao Liu, Richard Hartley, Mathieu Salzmann</p><p>Abstract: This paper tackles the problem of reconstructing the shape of a smooth mirror surface from a single image. In particular, we consider the case where the camera is observing the reflection of a static reference target in the unknown mirror. We first study the reconstruction problem given dense correspondences between 3D points on the reference target and image locations. In such conditions, our differential geometry analysis provides a theoretical proof that the shape of the mirror surface can be uniquely recovered if the pose of the reference target is known. We then relax our assumptions by considering the case where only sparse correspondences are available. In this scenario, we formulate reconstruction as an optimization problem, which can be solved using a nonlinear least-squares method. We demonstrate the effectiveness of our method on both synthetic and real images.</p><p>5 0.667238 <a title="432-lsi-5" href="./cvpr-2013-Area_Preserving_Brain_Mapping.html">44 cvpr-2013-Area Preserving Brain Mapping</a></p>
<p>Author: Zhengyu Su, Wei Zeng, Rui Shi, Yalin Wang, Jian Sun, Xianfeng Gu</p><p>Abstract: Brain mapping transforms the brain cortical surface to canonical planar domains, which plays a fundamental role in morphological study. Most existing brain mapping methods are based on angle preserving maps, which may introduce large area distortions. This work proposes an area preserving brain mapping method based on MongeBrenier theory. The brain mapping is intrinsic to the Riemannian metric, unique, and diffeomorphic. The computation is equivalent to convex energy minimization and power Voronoi diagram construction. Comparing to the existing approaches based on Monge-Kantorovich theory, the proposed one greatly reduces the complexity (from n2 unknowns to n ), and improves the simplicity and efficiency. Experimental results on caudate nucleus surface mapping and cortical surface mapping demonstrate the efficacy and efficiency of the proposed method. Conventional methods for caudate nucleus surface mapping may suffer from numerical instability; in contrast, current method produces diffeomorpic mappings stably. In the study of cortical sur- face classification for recognition of Alzheimer’s Disease, the proposed method outperforms some other morphometry features.</p><p>6 0.66182077 <a title="432-lsi-6" href="./cvpr-2013-Hyperbolic_Harmonic_Mapping_for_Constrained_Brain_Surface_Registration.html">208 cvpr-2013-Hyperbolic Harmonic Mapping for Constrained Brain Surface Registration</a></p>
<p>7 0.6589995 <a title="432-lsi-7" href="./cvpr-2013-Multi-resolution_Shape_Analysis_via_Non-Euclidean_Wavelets%3A_Applications_to_Mesh_Segmentation_and_Surface_Alignment_Problems.html">297 cvpr-2013-Multi-resolution Shape Analysis via Non-Euclidean Wavelets: Applications to Mesh Segmentation and Surface Alignment Problems</a></p>
<p>8 0.65142298 <a title="432-lsi-8" href="./cvpr-2013-Efficient_Computation_of_Shortest_Path-Concavity_for_3D_Meshes.html">141 cvpr-2013-Efficient Computation of Shortest Path-Concavity for 3D Meshes</a></p>
<p>9 0.63513434 <a title="432-lsi-9" href="./cvpr-2013-Multi-scale_Curve_Detection_on_Surfaces.html">298 cvpr-2013-Multi-scale Curve Detection on Surfaces</a></p>
<p>10 0.62663406 <a title="432-lsi-10" href="./cvpr-2013-Discovering_the_Structure_of_a_Planar_Mirror_System_from_Multiple_Observations_of_a_Single_Point.html">127 cvpr-2013-Discovering the Structure of a Planar Mirror System from Multiple Observations of a Single Point</a></p>
<p>11 0.62504429 <a title="432-lsi-11" href="./cvpr-2013-Correspondence-Less_Non-rigid_Registration_of_Triangular_Surface_Meshes.html">97 cvpr-2013-Correspondence-Less Non-rigid Registration of Triangular Surface Meshes</a></p>
<p>12 0.61983347 <a title="432-lsi-12" href="./cvpr-2013-Monocular_Template-Based_3D_Reconstruction_of_Extensible_Surfaces_with_Local_Linear_Elasticity.html">289 cvpr-2013-Monocular Template-Based 3D Reconstruction of Extensible Surfaces with Local Linear Elasticity</a></p>
<p>13 0.60103714 <a title="432-lsi-13" href="./cvpr-2013-Intrinsic_Characterization_of_Dynamic_Surfaces.html">226 cvpr-2013-Intrinsic Characterization of Dynamic Surfaces</a></p>
<p>14 0.57010281 <a title="432-lsi-14" href="./cvpr-2013-Adaptive_Compressed_Tomography_Sensing.html">35 cvpr-2013-Adaptive Compressed Tomography Sensing</a></p>
<p>15 0.56886542 <a title="432-lsi-15" href="./cvpr-2013-Improving_the_Visual_Comprehension_of_Point_Sets.html">218 cvpr-2013-Improving the Visual Comprehension of Point Sets</a></p>
<p>16 0.55581343 <a title="432-lsi-16" href="./cvpr-2013-Analytic_Bilinear_Appearance_Subspace_Construction_for_Modeling_Image_Irradiance_under_Natural_Illumination_and_Non-Lambertian_Reflectance.html">42 cvpr-2013-Analytic Bilinear Appearance Subspace Construction for Modeling Image Irradiance under Natural Illumination and Non-Lambertian Reflectance</a></p>
<p>17 0.52770227 <a title="432-lsi-17" href="./cvpr-2013-Specular_Reflection_Separation_Using_Dark_Channel_Prior.html">410 cvpr-2013-Specular Reflection Separation Using Dark Channel Prior</a></p>
<p>18 0.52540165 <a title="432-lsi-18" href="./cvpr-2013-Pattern-Driven_Colorization_of_3D_Surfaces.html">327 cvpr-2013-Pattern-Driven Colorization of 3D Surfaces</a></p>
<p>19 0.51139665 <a title="432-lsi-19" href="./cvpr-2013-Single_Image_Calibration_of_Multi-axial_Imaging_Systems.html">400 cvpr-2013-Single Image Calibration of Multi-axial Imaging Systems</a></p>
<p>20 0.50717109 <a title="432-lsi-20" href="./cvpr-2013-Computing_Diffeomorphic_Paths_for_Large_Motion_Interpolation.html">90 cvpr-2013-Computing Diffeomorphic Paths for Large Motion Interpolation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.102), (16, 0.024), (26, 0.035), (28, 0.025), (33, 0.25), (59, 0.01), (67, 0.054), (69, 0.071), (77, 0.018), (83, 0.223), (87, 0.084), (99, 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.8710047 <a title="432-lda-1" href="./cvpr-2013-Single_Image_Calibration_of_Multi-axial_Imaging_Systems.html">400 cvpr-2013-Single Image Calibration of Multi-axial Imaging Systems</a></p>
<p>Author: Amit Agrawal, Srikumar Ramalingam</p><p>Abstract: Imaging systems consisting of a camera looking at multiple spherical mirrors (reflection) or multiple refractive spheres (refraction) have been used for wide-angle imaging applications. We describe such setups as multi-axial imaging systems, since a single sphere results in an axial system. Assuming an internally calibrated camera, calibration of such multi-axial systems involves estimating the sphere radii and locations in the camera coordinate system. However, previous calibration approaches require manual intervention or constrained setups. We present a fully automatic approach using a single photo of a 2D calibration grid. The pose of the calibration grid is assumed to be unknown and is also recovered. Our approach can handle unconstrained setups, where the mirrors/refractive balls can be arranged in any fashion, not necessarily on a grid. The axial nature of rays allows us to compute the axis of each sphere separately. We then show that by choosing rays from two or more spheres, the unknown pose of the calibration grid can be obtained linearly and independently of sphere radii and locations. Knowing the pose, we derive analytical solutions for obtaining the sphere radius and location. This leads to an interesting result that 6-DOF pose estimation of a multi-axial camera can be done without the knowledge of full calibration. Simulations and real experiments demonstrate the applicability of our algorithm.</p><p>same-paper 2 0.84924322 <a title="432-lda-2" href="./cvpr-2013-Three-Dimensional_Bilateral_Symmetry_Plane_Estimation_in_the_Phase_Domain.html">432 cvpr-2013-Three-Dimensional Bilateral Symmetry Plane Estimation in the Phase Domain</a></p>
<p>Author: Ramakrishna Kakarala, Prabhu Kaliamoorthi, Vittal Premachandran</p><p>Abstract: We show that bilateral symmetry plane estimation for three-dimensional (3-D) shapes may be carried out accurately, and efficiently, in the spherical harmonic domain. Our methods are valuable for applications where spherical harmonic expansion is already employed, such as 3-D shape registration, morphometry, and retrieval. We show that the presence of bilateral symmetry in the 3-D shape is equivalent to a linear phase structure in the corresponding spherical harmonic coefficients, and provide algorithms for estimating the orientation of the symmetry plane. The benefit of using spherical harmonic phase is that symmetry estimation reduces to matching a compact set of descriptors, without the need to solve a correspondence problem. Our methods work on point clouds as well as large-scale mesh models of 3-D shapes.</p><p>3 0.82778889 <a title="432-lda-3" href="./cvpr-2013-Dense_Non-rigid_Point-Matching_Using_Random_Projections.html">109 cvpr-2013-Dense Non-rigid Point-Matching Using Random Projections</a></p>
<p>Author: Raffay Hamid, Dennis Decoste, Chih-Jen Lin</p><p>Abstract: We present a robust and efficient technique for matching dense sets of points undergoing non-rigid spatial transformations. Our main intuition is that the subset of points that can be matched with high confidence should be used to guide the matching procedure for the rest. We propose a novel algorithm that incorporates these high-confidence matches as a spatial prior to learn a discriminative subspace that simultaneously encodes both the feature similarity as well as their spatial arrangement. Conventional subspace learning usually requires spectral decomposition of the pair-wise distance matrix across the point-sets, which can become inefficient even for moderately sized problems. To this end, we propose the use of random projections for approximate subspace learning, which can provide significant time improvements at the cost of minimal precision loss. This efficiency gain allows us to iteratively find and remove high-confidence matches from the point sets, resulting in high recall. To show the effectiveness of our approach, we present a systematic set of experiments and results for the problem of dense non-rigid image-feature matching.</p><p>4 0.80578089 <a title="432-lda-4" href="./cvpr-2013-POOF%3A_Part-Based_One-vs.-One_Features_for_Fine-Grained_Categorization%2C_Face_Verification%2C_and_Attribute_Estimation.html">323 cvpr-2013-POOF: Part-Based One-vs.-One Features for Fine-Grained Categorization, Face Verification, and Attribute Estimation</a></p>
<p>Author: Thomas Berg, Peter N. Belhumeur</p><p>Abstract: From a set ofimages in aparticular domain, labeled with part locations and class, we present a method to automatically learn a large and diverse set of highly discriminative intermediate features that we call Part-based One-vs-One Features (POOFs). Each of these features specializes in discrimination between two particular classes based on the appearance at a particular part. We demonstrate the particular usefulness of these features for fine-grained visual categorization with new state-of-the-art results on bird species identification using the Caltech UCSD Birds (CUB) dataset and parity with the best existing results in face verification on the Labeled Faces in the Wild (LFW) dataset. Finally, we demonstrate the particular advantage of POOFs when training data is scarce.</p><p>5 0.8033067 <a title="432-lda-5" href="./cvpr-2013-What_Object_Motion_Reveals_about_Shape_with_Unknown_BRDF_and_Lighting.html">465 cvpr-2013-What Object Motion Reveals about Shape with Unknown BRDF and Lighting</a></p>
<p>Author: Manmohan Chandraker, Dikpal Reddy, Yizhou Wang, Ravi Ramamoorthi</p><p>Abstract: We present a theory that addresses the problem of determining shape from the (small or differential) motion of an object with unknown isotropic reflectance, under arbitrary unknown distant illumination, , for both orthographic and perpsective projection. Our theory imposes fundamental limits on the hardness of surface reconstruction, independent of the method involved. Under orthographic projection, we prove that three differential motions suffice to yield an invariant that relates shape to image derivatives, regardless of BRDF and illumination. Under perspective projection, we show that four differential motions suffice to yield depth and a linear constraint on the surface gradient, with unknown BRDF and lighting. Further, we delineate the topological classes up to which reconstruction may be achieved using the invariants. Finally, we derive a general stratification that relates hardness of shape recovery to scene complexity. Qualitatively, our invariants are homogeneous partial differential equations for simple lighting and inhomogeneous for complex illumination. Quantitatively, our framework shows that the minimal number of motions required to resolve shape is greater for more complex scenes. Prior works that assume brightness constancy, Lambertian BRDF or a known directional light source follow as special cases of our stratification. We illustrate with synthetic and real data how potential reconstruction methods may exploit our framework.</p><p>6 0.80124152 <a title="432-lda-6" href="./cvpr-2013-Dense_Reconstruction_Using_3D_Object_Shape_Priors.html">111 cvpr-2013-Dense Reconstruction Using 3D Object Shape Priors</a></p>
<p>7 0.78892308 <a title="432-lda-7" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<p>8 0.78860283 <a title="432-lda-8" href="./cvpr-2013-Beyond_Point_Clouds%3A_Scene_Understanding_by_Reasoning_Geometry_and_Physics.html">61 cvpr-2013-Beyond Point Clouds: Scene Understanding by Reasoning Geometry and Physics</a></p>
<p>9 0.78671569 <a title="432-lda-9" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>10 0.78539473 <a title="432-lda-10" href="./cvpr-2013-Cross-View_Action_Recognition_via_a_Continuous_Virtual_Path.html">98 cvpr-2013-Cross-View Action Recognition via a Continuous Virtual Path</a></p>
<p>11 0.78470325 <a title="432-lda-11" href="./cvpr-2013-Understanding_Indoor_Scenes_Using_3D_Geometric_Phrases.html">446 cvpr-2013-Understanding Indoor Scenes Using 3D Geometric Phrases</a></p>
<p>12 0.78414959 <a title="432-lda-12" href="./cvpr-2013-Multi-agent_Event_Detection%3A_Localization_and_Role_Assignment.html">292 cvpr-2013-Multi-agent Event Detection: Localization and Role Assignment</a></p>
<p>13 0.78402168 <a title="432-lda-13" href="./cvpr-2013-SLAM%2B%2B%3A_Simultaneous_Localisation_and_Mapping_at_the_Level_of_Objects.html">372 cvpr-2013-SLAM++: Simultaneous Localisation and Mapping at the Level of Objects</a></p>
<p>14 0.78351188 <a title="432-lda-14" href="./cvpr-2013-Label_Propagation_from_ImageNet_to_3D_Point_Clouds.html">242 cvpr-2013-Label Propagation from ImageNet to 3D Point Clouds</a></p>
<p>15 0.78289628 <a title="432-lda-15" href="./cvpr-2013-A_Minimum_Error_Vanishing_Point_Detection_Approach_for_Uncalibrated_Monocular_Images_of_Man-Made_Environments.html">19 cvpr-2013-A Minimum Error Vanishing Point Detection Approach for Uncalibrated Monocular Images of Man-Made Environments</a></p>
<p>16 0.78205794 <a title="432-lda-16" href="./cvpr-2013-Learning_Structured_Hough_Voting_for_Joint_Object_Detection_and_Occlusion_Reasoning.html">256 cvpr-2013-Learning Structured Hough Voting for Joint Object Detection and Occlusion Reasoning</a></p>
<p>17 0.7818476 <a title="432-lda-17" href="./cvpr-2013-Robust_Object_Co-detection.html">364 cvpr-2013-Robust Object Co-detection</a></p>
<p>18 0.78171158 <a title="432-lda-18" href="./cvpr-2013-3D_Visual_Proxemics%3A_Recognizing_Human_Interactions_in_3D_from_a_Single_Image.html">4 cvpr-2013-3D Visual Proxemics: Recognizing Human Interactions in 3D from a Single Image</a></p>
<p>19 0.78140837 <a title="432-lda-19" href="./cvpr-2013-Understanding_Bayesian_Rooms_Using_Composite_3D_Object_Models.html">445 cvpr-2013-Understanding Bayesian Rooms Using Composite 3D Object Models</a></p>
<p>20 0.78120899 <a title="432-lda-20" href="./cvpr-2013-Accurate_Localization_of_3D_Objects_from_RGB-D_Data_Using_Segmentation_Hypotheses.html">30 cvpr-2013-Accurate Localization of 3D Objects from RGB-D Data Using Segmentation Hypotheses</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
