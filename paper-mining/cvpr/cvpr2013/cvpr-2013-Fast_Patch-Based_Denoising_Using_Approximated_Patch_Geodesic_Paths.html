<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>169 cvpr-2013-Fast Patch-Based Denoising Using Approximated Patch Geodesic Paths</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-169" href="#">cvpr2013-169</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>169 cvpr-2013-Fast Patch-Based Denoising Using Approximated Patch Geodesic Paths</h1>
<br/><p>Source: <a title="cvpr-2013-169-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Chen_Fast_Patch-Based_Denoising_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Xiaogang Chen, Sing Bing Kang, Jie Yang, Jingyi Yu</p><p>Abstract: Patch-based methods such as Non-Local Means (NLM) and BM3D have become the de facto gold standard for image denoising. The core of these approaches is to use similar patches within the image as cues for denoising. The operation usually requires expensive pair-wise patch comparisons. In this paper, we present a novel fast patch-based denoising technique based on Patch Geodesic Paths (PatchGP). PatchGPs treat image patches as nodes and patch differences as edge weights for computing the shortest (geodesic) paths. The path lengths can then be used as weights of the smoothing/denoising kernel. We first show that, for natural images, PatchGPs can be effectively approximated by minimum hop paths (MHPs) that generally correspond to Euclidean line paths connecting two patch nodes. To construct the denoising kernel, we further discretize the MHP search directions and use only patches along the search directions. Along each MHP, we apply a weightpropagation scheme to robustly and efficiently compute the path distance. To handle noise at multiple scales, we conduct wavelet image decomposition and apply PatchGP scheme at each scale. Comprehensive experiments show that our approach achieves comparable quality as the state-of-the-art methods such as NLM and BM3D but is a few orders of magnitude faster.</p><p>Reference: <a title="cvpr-2013-169-reference" href="../cvpr2013_reference/cvpr-2013-Fast_Patch-Based_Denoising_Using_Approximated_Patch_Geodesic_Paths_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 In this paper, we present a novel fast patch-based denoising technique based on Patch Geodesic Paths (PatchGP). [sent-13, score-0.317]
</p><p>2 PatchGPs treat image patches as nodes and patch differences as edge weights for computing the shortest (geodesic) paths. [sent-14, score-0.397]
</p><p>3 We first show that, for natural images, PatchGPs can be effectively approximated by minimum hop paths (MHPs) that generally correspond to Euclidean line paths connecting two patch nodes. [sent-16, score-0.709]
</p><p>4 To construct the denoising kernel, we further discretize the MHP search directions and use only patches along the search directions. [sent-17, score-0.486]
</p><p>5 Along each MHP, we apply a weightpropagation scheme to robustly and efficiently compute the path distance. [sent-18, score-0.143]
</p><p>6 To handle noise at multiple  scales, we conduct wavelet image decomposition and apply PatchGP scheme at each scale. [sent-19, score-0.198]
</p><p>7 Traditional pixel-based edge-preserving algorithms such as median filters, bilateral filters [34], total variation [33] and anisotropic diffusion [33] have long served as workhorses in denoising tasks. [sent-23, score-0.543]
</p><p>8 The core of these approaches is to use patches similar to the noisy one within the image as cues. [sent-27, score-0.137]
</p><p>9 For example, in NLM and BM3D, denoising each patch requires computing its similarity with all other patches in a predefined search window. [sent-29, score-0.638]
</p><p>10 [4] show that one can use the K most similar patches instead of all patches within the window which is equivalent to solving the K-nearest neighbor (K-NN) problem in the high dimensional patch space. [sent-32, score-0.491]
</p><p>11 In this paper, we present a novel fast patch-based denoising technique based on Patch Geodesic Paths (PatchGP). [sent-34, score-0.317]
</p><p>12 PatchGP extends the pixel geodesic paths (PixelGP) [5] by treating image patches as nodes and assigning patch differences as edge weights for computing the shortest (geodesic) paths. [sent-35, score-0.762]
</p><p>13 We first show that for natural images, PatchGPs can be effectively approximated by minimum hop paths (MHPs) that generally correspond to Euclidean line paths connecting two patch nodes. [sent-39, score-0.709]
</p><p>14 To construct the denoising kernel, we further discretize the MHP search directions and use only patches along the search directions. [sent-40, score-0.486]
</p><p>15 Along each MHP, we apply a weight propagation scheme to robustly and efficiently compute the path distance. [sent-41, score-0.166]
</p><p>16 Finally, to handle noise at multiple scales, we conduct wavelet image decomposition and apply PatchGP scheme at each scale. [sent-42, score-0.198]
</p><p>17 Related work Image denoising is a long standing problem. [sent-45, score-0.276]
</p><p>18 [24] discussed the the relation between the patch complexity of natural images, patch size, and restoration errors. [sent-51, score-0.513]
</p><p>19 A widely used class of pixel-based algorithms is edge-preserving filters such as anisotropic diffusion [28] and bilateral filters [29]. [sent-55, score-0.326]
</p><p>20 They can be viewed as convolving the noisy image with a special smoothing kernel [29] [34]:  ˆ퐼(푖) =푍(1푖)푗∑∈Ω푖푤(푖,푗)퐼(푗),  (1)  where 푤 is the smoothing kernel, Ω푖 is the spatial support of 푤 or a neighbo∑rhood of pixel 푖, and 푍(푖) is the normaliza-  tion factor as푗∑∈Ω푖푤(푖,푗). [sent-56, score-0.204]
</p><p>21 Anisotropic diffusion uses similar local filte(rs∣푣 t(o푖 s)u−cc푣e(s푗s)i∣vely produces a family of parameterized images where new images at each iteration are computed by applying diffusion filters to the ones from the previous iteration [29]. [sent-58, score-0.143]
</p><p>22 For example, NLM uses patch similarity instead of pixel similarity for constructing the smoothing kernel:  푖. [sent-60, score-0.321]
</p><p>23 −  푤푁퐿푀(푖,푗) = 퐺휎(∣푁퐼(푖) − 푁퐼(푗)∣2),  (3)  푖  where 푁퐼 (푖) and 푁퐼 (푗) represent patches centered at and 푗 and ⋅ ∣2 is the sum of squared differences (SSD) between the patches. [sent-61, score-0.134]
</p><p>24 More sophisticated schemes [32] [36] [41] further utilize image statistics within patches to improve the denoising results. [sent-64, score-0.426]
</p><p>25 (1), whether pixel or patch based, are computational expensive. [sent-68, score-0.271]
</p><p>26 The original bilateral filters have computational complexity of 푂(푟2) for each pixel, where 푟 is radius of the spatial support. [sent-69, score-0.188]
</p><p>27 Despite great advances on pixel-based denoising, accelerating patch-based denoising remains as an open problem. [sent-78, score-0.301]
</p><p>28 This is mainly due to the high dimensionality of patch space. [sent-79, score-0.237]
</p><p>29 We, in  contrast, explore the problem from the perspective of natural image patch statistics. [sent-83, score-0.258]
</p><p>30 Patch Geodesic Paths The core of our approach is to accelerate patch-based denoising by only conducting patch comparisons on the geodesic paths. [sent-85, score-0.776]
</p><p>31 Pixel Geodesic Distance In a graph, the geodesic distance between two nodes is the accumulative edge weights in a shortest path connecting them. [sent-88, score-0.481]
</p><p>32 The pixel geodesic distance corresponds to  Γ  1 1 12 2 21 1 102 0  the shortest path in terms of image gradients, i. [sent-90, score-0.422]
</p><p>33 The concept of pixel geodesic distance has been successfully applied to colorization [39], segmentation and matting  [5, 18, 12], texture removal and non-photorealistic rendering [13], and most recently, denoising [13, 17]. [sent-93, score-0.604]
</p><p>34 (4) to:  푑퐺퐷(푠,푡) = mΓin푁∑푖=Γ−11∣퐼(Γ(푝푖+1)) − 퐼(Γ(푝푖))∣,  (5)  where Γ denotes a path starting from the patch centered at 푠 to the patch centered at 푁Γ denotes the hops of the path Γ. [sent-95, score-0.805]
</p><p>35 To apply pixel geodesic distance for image denoising, one can compute the smoothing ker-  푡. [sent-97, score-0.326]
</p><p>36 This is often referred to as Pixel Geodesic Path (PixelGP) denoising [17]. [sent-100, score-0.276]
</p><p>37 Specifically, we treat each image patch as a node and define the geodesic distance between two patches 푠 and as:  푡  푑푝푎푡푐ℎ퐺푃(푠,푡) = mΓin푁푖∑=Γ−11∣∣푁퐼(Γ(푝푖+1)) − 푁퐼(Γ(푝푖))∣∣, (6) where 푁퐼 (푥) is the patch centered at 푥, . [sent-106, score-0.85]
</p><p>38 h We pea ctcalhl tcheen tsehroerdte astt path ∣Γ∣ m beetawseuerens tw thoe patches the Patch Geodesic Path (PatchGP). [sent-108, score-0.216]
</p><p>39 However, the brute-force implementation of PatchGP is very expensive because weight computation requires pairwise patch comparisons. [sent-112, score-0.283]
</p><p>40 Minimal Hop Paths (MHP) Consider two patches centered at pixel 푠 and 푡. [sent-116, score-0.168]
</p><p>41 We define the Minimum Hop Path (MHP) as the path with the minimal number of hops connecting two nodes. [sent-117, score-0.196]
</p><p>42 Among all paths connecting 푝 and 푞, the diagonal red path is the corresponding MHP under 8connectivity. [sent-120, score-0.261]
</p><p>43 For each configuration (patch size, window size, noise variance), we find PatchGP between every pair ofpatches and verify ifit is an MHP. [sent-131, score-0.148]
</p><p>44 The percentage ofPatchGP being MHP is shown in (a) 5 5 patch size and (b) 7 ×7patch size. [sent-132, score-0.255]
</p><p>45 We add white Gaussian noise to the images and test different patch sizes. [sent-136, score-0.339]
</p><p>46 For a fixed noise variance and patch size, we first compute the ground truth PatchGPs between all patches. [sent-137, score-0.367]
</p><p>47 In Fig 2, the Y-axis is the percentage of MHPs being PatchGPs averaged over all 200 images and the X-axis is the spatial support (the maximum hop allowed between the nodes). [sent-139, score-0.17]
</p><p>48 The results hold for noisy images: even with noise variance 휎푛 = 15 and spatial support 7 (15 15 window), over 90% Pat=chG 1P5s a are pMatHiaPls s, as osrhto 7w (n1 5in× Fig 2i(nad)o awn)d, (vbe). [sent-141, score-0.163]
</p><p>49 Nevertheless, for images with small noise variances, the smaller window is required for smoothing and MHP approximation is mostly reserved (over 95% for window radius 5). [sent-146, score-0.244]
</p><p>50 (a) shows the cameraman image and two central patches (5x5) we aim to denoise. [sent-149, score-0.135]
</p><p>51 For each patch ,w witeh uisn eth ae s wpaintidaolw su, we fti (ndw i ntsd oPwatc shizGeP) otof 1t3he× c1e3n. [sent-151, score-0.237]
</p><p>52 (d) and (g) show the color-coded path hop maps for the corresponding PatchGPs. [sent-155, score-0.282]
</p><p>53 In the extreme case when patch size is 1 1, PatchGP degenerates xtotr PemixeelG caPse ew whhereen M paHtcPh his s nizoet longer c,o PnasticshteGnPt with PixelGP. [sent-158, score-0.255]
</p><p>54 Since most patch-based denoising schemes (NLM, BM3D, etc) use a large patch size, MHPs thus still provide good approximations to PatchGPs. [sent-159, score-0.559]
</p><p>55 For each patch, we compute its PatchGP to all other patches within a window of 13 13. [sent-163, score-0.15]
</p><p>56 3 (c) and (f) show the patch  geodesic doiwsta onfce 1 map w. [sent-165, score-0.456]
</p><p>57 They form concentric squares and are nearly identical to the MHP hop maps under 4-way connectivity. [sent-170, score-0.17]
</p><p>58 1(b), in order to denoise patch 푥0, we need to compute the path distances from 푁(푥0) to patches 푁(푥1), 푁(푥2), . [sent-182, score-0.502]
</p><p>59 ) This indicates the patch geodesic distance can be computed progressively: we can first compute 1-hop path distance  and then propagate it to 2-hop, 3-hop, and so on. [sent-189, score-0.614]
</p><p>60 Under our direction and hop discretization, we can reformulate the denoising filter as:  퐼ˆ(푖) =푧(1푖)휃∑∈Θ푟∑=푅1푤(푖,푖휃,푟)퐼(푖휃,푟푅), (9) where thenˆ ormalization factor 푧(푖) = ∑푟∑=1푤(푖,푖휃,푟). [sent-190, score-0.464]
</p><p>61 , patches that do not lie on the predefined directions will not be used. [sent-198, score-0.138]
</p><p>62 This can potentially affect the patch-based denoising performance as some of the missing patches may be critical for denoising the central patch. [sent-199, score-0.656]
</p><p>63 We also implement a multi-scale denoising scheme to compensate for sparse patch sampling. [sent-201, score-0.544]
</p><p>64 Reusing Fig 1, if 푁(푥1 ) is significantly differ-  ent from 푁(푥0) while 푁(푥2) is highly similar to 푁(푥0), patch 푁(푥2) should be assigned a large weight for denoising 푁(푥0). [sent-205, score-0.536]
</p><p>65 To compute 1-hop patch distance ∣푁(푥푟) − 푁(푥푟−1) , we can oemitpheurt etr 1ea-ht pixels wh idthisinta ntchee patch equally or adopt a Gaussian weighting [10]. [sent-215, score-0.532]
</p><p>66 The former (we call uniform weighting) is faster as its computation is independent of the patch size by using Integral Histogram [30]. [sent-216, score-0.32]
</p><p>67 8), we use patch size 7 ×7 and Gaussian weighting  fwoirth F 휎푤푒푖푔ℎ푡 =e u2s. [sent-219, score-0.29]
</p><p>68 A common challenge in pixel-based denoising is reducing low frequency noise: properly handling low frequency noise requires using ultralarge spatial support. [sent-221, score-0.42]
</p><p>69 4 (c) and (e) show the denoising results using the PixelGP [17] vs. [sent-224, score-0.276]
</p><p>70 We resolve this problem by using a coarse-to-fine denoising scheme. [sent-227, score-0.276]
</p><p>71 The Harr wavelet transformation provides two advantages: it is faster compared with the Gaussian pyramid and does not affect noise statistics. [sent-231, score-0.175]
</p><p>72 4 compares the denoising results of PixelGP [17], PatchGP, F-PatchGP and FM-PatchGP. [sent-237, score-0.307]
</p><p>73 The noisy image (b) is synthesized by adding Gaussian noise with variance 20. [sent-238, score-0.163]
</p><p>74 Specifically, we compare FM-PatchGP against the FoE, NLM, BM3D, PixelGP, and fast bilateral filters (F-BL) [38]. [sent-244, score-0.229]
</p><p>75 For each image, we synthesize 6 noisy versions by adding Gaussian noise with different variances between 5 and 30. [sent-252, score-0.171]
</p><p>76 5 corresponds to a specific image where the X-axis is the noise variance and Y-axis the PSNR. [sent-254, score-0.13]
</p><p>77 6 compares the visual quality, the PSNR, and the processing time of different denoising algorithms on the ’man’ image (with added Gaussian noise 휎푛=15). [sent-257, score-0.409]
</p><p>78 We downsample a clean image of resolution 4032× 6048 fWroem d [w22n]s tmo dlieff aer celneta rnes imolaugtieon osf a rendso lthuteino nad 4d0 3G2a×us6s0ia4n8 noise 휎푛 = 15. [sent-267, score-0.133]
</p><p>79 Our experiments suggest that FM-PatchGP can be potentially used for real-time denoising on mobile devices with relatively low computational power. [sent-290, score-0.276]
</p><p>80 Finally, we compare FM-PatchGP with two commercial denoising tools “Neat Image” [2] and “Noise Ninja” [3]. [sent-291, score-0.327]
</p><p>81 Both tools automatically estimate the noise profile to account for intensity-dependent noise variances [25]. [sent-292, score-0.262]
</p><p>82 We then use their identified ’uniform’ regions to estimate noise variance 휎푛 to determine the window size and then apply FMPatchGP with uniform weighting. [sent-293, score-0.23]
</p><p>83 Limitations and Future work We have presented a new patch-based image denoising algorithm based on the observation that patch geodesic paths (PatchGP) can be approximated by the minimal hop paths (MHP). [sent-309, score-1.146]
</p><p>84 Comprehensive experiments on a broad range of natural images demonstrate that our new fast multi-scale PatchGP or FM-PatchGP is comparable to or outperforms state-of-the-art algorithms in terms of quality, and is orders of magnitude faster. [sent-310, score-0.134]
</p><p>85 Similar to most denoising schemes, FM-PatchGP requires using good parameters, e. [sent-312, score-0.276]
</p><p>86 , the patch size, the window size, the discretized search directions, etc. [sent-314, score-0.329]
</p><p>87 Similar to BM3D and NLM, we usually fix the search directions and patch sizes and exhaust different window sizes. [sent-315, score-0.376]
</p><p>88 For example, FM-PatchGP can be used to quickly locate similar patches for conducting PCA-based denoising [40]. [sent-321, score-0.405]
</p><p>89 Finally, in our solution, we separately denoise each color channel and then combine the three channoise level 10  noise level 20  noise level 30  oisy imageN LNM TPimSeN:R0:. [sent-322, score-0.253]
</p><p>90 Comparisons between FM-PatchGP and two commercial denoising tools Noise Ninja [3] and Neat Image [2] on real images. [sent-342, score-0.327]
</p><p>91 11111222221111157755  fast bilateral filter (F-BL) [38], and our FM-PatchGP with uniform and Gaussian weighting at different image resolutions. [sent-351, score-0.259]
</p><p>92 A geodesic framework for fast interactive image and video segmentation and matting. [sent-375, score-0.284]
</p><p>93 A fundamental relationship between bilateral filtering, adaptive smoothing, and the nonlinear diffusion equation. [sent-388, score-0.171]
</p><p>94 Fast bilateral filtering for the display of high-dynamic-range images. [sent-438, score-0.15]
</p><p>95 Pointwise shapeadaptive dct for high-quality denoising and deblocking of grayscale and color images, 2006. [sent-444, score-0.276]
</p><p>96 Edge-preserving smoothing using a similarity measure in adaptive geodesic neighbourhoods. [sent-456, score-0.269]
</p><p>97 [22] [23]  [24]  [25] [26]  [27] [28] [29]  [30] [31]  [32] [33]  Image denoising with block-matching and 3d filtering. [sent-482, score-0.276]
</p><p>98 A fast approximation of the bilateral filter using a signal processing approach. [sent-524, score-0.188]
</p><p>99 Image denoising using scale mixtures of Gaussians in the wavelet domain. [sent-553, score-0.32]
</p><p>100 Two-stage image denoising by principal component analysis with local pixel grouping. [sent-614, score-0.31]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('patchgp', 0.573), ('denoising', 0.276), ('mhp', 0.271), ('mhps', 0.248), ('patch', 0.237), ('nlm', 0.222), ('geodesic', 0.219), ('pixelgp', 0.191), ('hop', 0.17), ('patchgps', 0.134), ('bilateral', 0.129), ('paths', 0.112), ('path', 0.112), ('patches', 0.104), ('noise', 0.102), ('psnr', 0.081), ('ninja', 0.076), ('fig', 0.062), ('filters', 0.059), ('neat', 0.057), ('smoothing', 0.05), ('denoise', 0.049), ('acceleration', 0.048), ('denoised', 0.048), ('hops', 0.047), ('window', 0.046), ('schemes', 0.046), ('yatziv', 0.044), ('wavelet', 0.044), ('gaussian', 0.044), ('foe', 0.042), ('foi', 0.042), ('diffusion', 0.042), ('fast', 0.041), ('cimplementation', 0.038), ('exhaust', 0.038), ('tpimsen', 0.038), ('anisotropic', 0.037), ('connecting', 0.037), ('kernel', 0.037), ('variances', 0.036), ('durand', 0.036), ('uniform', 0.036), ('weighting', 0.035), ('directions', 0.034), ('accumulative', 0.034), ('pixel', 0.034), ('shortest', 0.034), ('noisy', 0.033), ('panel', 0.033), ('cameraman', 0.031), ('nad', 0.031), ('compares', 0.031), ('orders', 0.031), ('scheme', 0.031), ('centered', 0.03), ('discretize', 0.03), ('faster', 0.029), ('commercial', 0.029), ('colorization', 0.028), ('variance', 0.028), ('notice', 0.027), ('criminisi', 0.027), ('comprehensive', 0.027), ('shanghai', 0.026), ('multichannel', 0.026), ('conducting', 0.025), ('discretized', 0.025), ('accelerating', 0.025), ('matting', 0.024), ('interactive', 0.024), ('distance', 0.023), ('weight', 0.023), ('expensive', 0.023), ('pleasing', 0.022), ('tools', 0.022), ('comparable', 0.022), ('nodes', 0.022), ('bai', 0.021), ('ministry', 0.021), ('frequency', 0.021), ('natural', 0.021), ('search', 0.021), ('filtering', 0.021), ('conduct', 0.021), ('laplacian', 0.02), ('discretization', 0.02), ('education', 0.02), ('approximated', 0.02), ('magnitude', 0.019), ('sapiro', 0.019), ('accelerate', 0.019), ('integral', 0.019), ('recursive', 0.018), ('accelerated', 0.018), ('directional', 0.018), ('size', 0.018), ('filter', 0.018), ('storage', 0.018), ('restoration', 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="169-tfidf-1" href="./cvpr-2013-Fast_Patch-Based_Denoising_Using_Approximated_Patch_Geodesic_Paths.html">169 cvpr-2013-Fast Patch-Based Denoising Using Approximated Patch Geodesic Paths</a></p>
<p>Author: Xiaogang Chen, Sing Bing Kang, Jie Yang, Jingyi Yu</p><p>Abstract: Patch-based methods such as Non-Local Means (NLM) and BM3D have become the de facto gold standard for image denoising. The core of these approaches is to use similar patches within the image as cues for denoising. The operation usually requires expensive pair-wise patch comparisons. In this paper, we present a novel fast patch-based denoising technique based on Patch Geodesic Paths (PatchGP). PatchGPs treat image patches as nodes and patch differences as edge weights for computing the shortest (geodesic) paths. The path lengths can then be used as weights of the smoothing/denoising kernel. We first show that, for natural images, PatchGPs can be effectively approximated by minimum hop paths (MHPs) that generally correspond to Euclidean line paths connecting two patch nodes. To construct the denoising kernel, we further discretize the MHP search directions and use only patches along the search directions. Along each MHP, we apply a weightpropagation scheme to robustly and efficiently compute the path distance. To handle noise at multiple scales, we conduct wavelet image decomposition and apply PatchGP scheme at each scale. Comprehensive experiments show that our approach achieves comparable quality as the state-of-the-art methods such as NLM and BM3D but is a few orders of magnitude faster.</p><p>2 0.18832746 <a title="169-tfidf-2" href="./cvpr-2013-Separating_Signal_from_Noise_Using_Patch_Recurrence_across_Scales.html">393 cvpr-2013-Separating Signal from Noise Using Patch Recurrence across Scales</a></p>
<p>Author: Maria Zontak, Inbar Mosseri, Michal Irani</p><p>Abstract: Recurrence of small clean image patches across different scales of a natural image has been successfully used for solving ill-posed problems in clean images (e.g., superresolution from a single image). In this paper we show how this multi-scale property can be extended to solve ill-posed problems under noisy conditions, such as image denoising. While clean patches are obscured by severe noise in the original scale of a noisy image, noise levels drop dramatically at coarser image scales. This allows for the unknown hidden clean patches to “naturally emerge ” in some coarser scale of the noisy image. We further show that patch recurrence across scales is strengthened when using directional pyramids (that blur and subsample only in one direction). Our statistical experiments show that for almost any noisy image patch (more than 99%), there exists a “good” clean version of itself at the same relative image coordinates in some coarser scale of the image.This is a strong phenomenon of noise-contaminated natural images, which can serve as a strong prior for separating the signal from the noise. Finally, incorporating this multi-scale prior into a simple denoising algorithm yields state-of-the-art denois- ing results.</p><p>3 0.15863661 <a title="169-tfidf-3" href="./cvpr-2013-Handling_Noise_in_Single_Image_Deblurring_Using_Directional_Filters.html">198 cvpr-2013-Handling Noise in Single Image Deblurring Using Directional Filters</a></p>
<p>Author: Lin Zhong, Sunghyun Cho, Dimitris Metaxas, Sylvain Paris, Jue Wang</p><p>Abstract: State-of-the-art single image deblurring techniques are sensitive to image noise. Even a small amount of noise, which is inevitable in low-light conditions, can degrade the quality of blur kernel estimation dramatically. The recent approach of Tai and Lin [17] tries to iteratively denoise and deblur a blurry and noisy image. However, as we show in this work, directly applying image denoising methods often partially damages the blur information that is extracted from the input image, leading to biased kernel estimation. We propose a new method for handling noise in blind image deconvolution based on new theoretical and practical insights. Our key observation is that applying a directional low-pass filter to the input image greatly reduces the noise level, while preserving the blur information in the orthogonal direction to the filter. Based on this observation, our method applies a series of directional filters at different orientations to the input image, and estimates an accurate Radon transform of the blur kernel from each filtered image. Finally, we reconstruct the blur kernel using inverse Radon transform. Experimental results on synthetic and real data show that our algorithm achieves higher quality results than previous approaches on blurry and noisy images. 1</p><p>4 0.15626362 <a title="169-tfidf-4" href="./cvpr-2013-Texture_Enhanced_Image_Denoising_via_Gradient_Histogram_Preservation.html">427 cvpr-2013-Texture Enhanced Image Denoising via Gradient Histogram Preservation</a></p>
<p>Author: Wangmeng Zuo, Lei Zhang, Chunwei Song, David Zhang</p><p>Abstract: Image denoising is a classical yet fundamental problem in low level vision, as well as an ideal test bed to evaluate various statistical image modeling methods. One of the most challenging problems in image denoising is how to preserve the fine scale texture structures while removing noise. Various natural image priors, such as gradient based prior, nonlocal self-similarity prior, and sparsity prior, have been extensively exploited for noise removal. The denoising algorithms based on these priors, however, tend to smooth the detailed image textures, degrading the image visual quality. To address this problem, in this paper we propose a texture enhanced image denoising (TEID) method by enforcing the gradient distribution of the denoised image to be close to the estimated gradient distribution of the original image. A novel gradient histogram preservation (GHP) algorithm is developed to enhance the texture structures while removing noise. Our experimental results demonstrate that theproposed GHP based TEID can well preserve the texture features of the denoised images, making them look more natural.</p><p>5 0.15401882 <a title="169-tfidf-5" href="./cvpr-2013-Joint_Geodesic_Upsampling_of_Depth_Images.html">232 cvpr-2013-Joint Geodesic Upsampling of Depth Images</a></p>
<p>Author: Ming-Yu Liu, Oncel Tuzel, Yuichi Taguchi</p><p>Abstract: We propose an algorithm utilizing geodesic distances to upsample a low resolution depth image using a registered high resolution color image. Specifically, it computes depth for each pixel in the high resolution image using geodesic paths to the pixels whose depths are known from the low resolution one. Though this is closely related to the all-pairshortest-path problem which has O(n2 log n) complexity, we develop a novel approximation algorithm whose complexity grows linearly with the image size and achieve realtime performance. We compare our algorithm with the state of the art on the benchmark dataset and show that our approach provides more accurate depth upsampling with fewer artifacts. In addition, we show that the proposed algorithm is well suited for upsampling depth images using binary edge maps, an important sensor fusion application.</p><p>6 0.14390998 <a title="169-tfidf-6" href="./cvpr-2013-Sparse_Subspace_Denoising_for_Image_Manifolds.html">405 cvpr-2013-Sparse Subspace Denoising for Image Manifolds</a></p>
<p>7 0.1263562 <a title="169-tfidf-7" href="./cvpr-2013-Fast_Image_Super-Resolution_Based_on_In-Place_Example_Regression.html">166 cvpr-2013-Fast Image Super-Resolution Based on In-Place Example Regression</a></p>
<p>8 0.10552908 <a title="169-tfidf-8" href="./cvpr-2013-GeoF%3A_Geodesic_Forests_for_Learning_Coupled_Predictors.html">186 cvpr-2013-GeoF: Geodesic Forests for Learning Coupled Predictors</a></p>
<p>9 0.096477747 <a title="169-tfidf-9" href="./cvpr-2013-A_Machine_Learning_Approach_for_Non-blind_Image_Deconvolution.html">17 cvpr-2013-A Machine Learning Approach for Non-blind Image Deconvolution</a></p>
<p>10 0.084045924 <a title="169-tfidf-10" href="./cvpr-2013-Learning_Separable_Filters.html">255 cvpr-2013-Learning Separable Filters</a></p>
<p>11 0.080004886 <a title="169-tfidf-11" href="./cvpr-2013-Representing_Videos_Using_Mid-level_Discriminative_Patches.html">355 cvpr-2013-Representing Videos Using Mid-level Discriminative Patches</a></p>
<p>12 0.078095093 <a title="169-tfidf-12" href="./cvpr-2013-Depth_Super_Resolution_by_Rigid_Body_Self-Similarity_in_3D.html">115 cvpr-2013-Depth Super Resolution by Rigid Body Self-Similarity in 3D</a></p>
<p>13 0.078080252 <a title="169-tfidf-13" href="./cvpr-2013-Fully-Connected_CRFs_with_Non-Parametric_Pairwise_Potential.html">180 cvpr-2013-Fully-Connected CRFs with Non-Parametric Pairwise Potential</a></p>
<p>14 0.077444926 <a title="169-tfidf-14" href="./cvpr-2013-What_Makes_a_Patch_Distinct%3F.html">464 cvpr-2013-What Makes a Patch Distinct?</a></p>
<p>15 0.069563575 <a title="169-tfidf-15" href="./cvpr-2013-Multi-source_Multi-scale_Counting_in_Extremely_Dense_Crowd_Images.html">299 cvpr-2013-Multi-source Multi-scale Counting in Extremely Dense Crowd Images</a></p>
<p>16 0.067825027 <a title="169-tfidf-16" href="./cvpr-2013-Ensemble_Video_Object_Cut_in_Highly_Dynamic_Scenes.html">148 cvpr-2013-Ensemble Video Object Cut in Highly Dynamic Scenes</a></p>
<p>17 0.067170091 <a title="169-tfidf-17" href="./cvpr-2013-A_New_Model_and_Simple_Algorithms_for_Multi-label_Mumford-Shah_Problems.html">20 cvpr-2013-A New Model and Simple Algorithms for Multi-label Mumford-Shah Problems</a></p>
<p>18 0.06429816 <a title="169-tfidf-18" href="./cvpr-2013-Discriminative_Non-blind_Deblurring.html">131 cvpr-2013-Discriminative Non-blind Deblurring</a></p>
<p>19 0.059761666 <a title="169-tfidf-19" href="./cvpr-2013-Supervised_Kernel_Descriptors_for_Visual_Recognition.html">421 cvpr-2013-Supervised Kernel Descriptors for Visual Recognition</a></p>
<p>20 0.059332982 <a title="169-tfidf-20" href="./cvpr-2013-Sampling_Strategies_for_Real-Time_Action_Recognition.html">378 cvpr-2013-Sampling Strategies for Real-Time Action Recognition</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.128), (1, 0.044), (2, -0.003), (3, 0.073), (4, -0.008), (5, 0.072), (6, 0.001), (7, -0.018), (8, -0.038), (9, -0.06), (10, -0.001), (11, -0.024), (12, -0.017), (13, -0.031), (14, 0.039), (15, -0.023), (16, -0.057), (17, -0.071), (18, 0.145), (19, 0.022), (20, 0.067), (21, 0.145), (22, -0.025), (23, -0.115), (24, -0.045), (25, -0.007), (26, -0.032), (27, -0.11), (28, -0.011), (29, -0.065), (30, -0.098), (31, -0.125), (32, 0.114), (33, 0.012), (34, -0.092), (35, 0.052), (36, 0.017), (37, -0.091), (38, -0.122), (39, 0.058), (40, 0.053), (41, -0.015), (42, 0.043), (43, -0.02), (44, -0.005), (45, 0.117), (46, -0.003), (47, 0.025), (48, 0.061), (49, -0.045)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96707231 <a title="169-lsi-1" href="./cvpr-2013-Fast_Patch-Based_Denoising_Using_Approximated_Patch_Geodesic_Paths.html">169 cvpr-2013-Fast Patch-Based Denoising Using Approximated Patch Geodesic Paths</a></p>
<p>Author: Xiaogang Chen, Sing Bing Kang, Jie Yang, Jingyi Yu</p><p>Abstract: Patch-based methods such as Non-Local Means (NLM) and BM3D have become the de facto gold standard for image denoising. The core of these approaches is to use similar patches within the image as cues for denoising. The operation usually requires expensive pair-wise patch comparisons. In this paper, we present a novel fast patch-based denoising technique based on Patch Geodesic Paths (PatchGP). PatchGPs treat image patches as nodes and patch differences as edge weights for computing the shortest (geodesic) paths. The path lengths can then be used as weights of the smoothing/denoising kernel. We first show that, for natural images, PatchGPs can be effectively approximated by minimum hop paths (MHPs) that generally correspond to Euclidean line paths connecting two patch nodes. To construct the denoising kernel, we further discretize the MHP search directions and use only patches along the search directions. Along each MHP, we apply a weightpropagation scheme to robustly and efficiently compute the path distance. To handle noise at multiple scales, we conduct wavelet image decomposition and apply PatchGP scheme at each scale. Comprehensive experiments show that our approach achieves comparable quality as the state-of-the-art methods such as NLM and BM3D but is a few orders of magnitude faster.</p><p>2 0.89261436 <a title="169-lsi-2" href="./cvpr-2013-Separating_Signal_from_Noise_Using_Patch_Recurrence_across_Scales.html">393 cvpr-2013-Separating Signal from Noise Using Patch Recurrence across Scales</a></p>
<p>Author: Maria Zontak, Inbar Mosseri, Michal Irani</p><p>Abstract: Recurrence of small clean image patches across different scales of a natural image has been successfully used for solving ill-posed problems in clean images (e.g., superresolution from a single image). In this paper we show how this multi-scale property can be extended to solve ill-posed problems under noisy conditions, such as image denoising. While clean patches are obscured by severe noise in the original scale of a noisy image, noise levels drop dramatically at coarser image scales. This allows for the unknown hidden clean patches to “naturally emerge ” in some coarser scale of the noisy image. We further show that patch recurrence across scales is strengthened when using directional pyramids (that blur and subsample only in one direction). Our statistical experiments show that for almost any noisy image patch (more than 99%), there exists a “good” clean version of itself at the same relative image coordinates in some coarser scale of the image.This is a strong phenomenon of noise-contaminated natural images, which can serve as a strong prior for separating the signal from the noise. Finally, incorporating this multi-scale prior into a simple denoising algorithm yields state-of-the-art denois- ing results.</p><p>3 0.80373025 <a title="169-lsi-3" href="./cvpr-2013-Fast_Image_Super-Resolution_Based_on_In-Place_Example_Regression.html">166 cvpr-2013-Fast Image Super-Resolution Based on In-Place Example Regression</a></p>
<p>Author: Jianchao Yang, Zhe Lin, Scott Cohen</p><p>Abstract: We propose a fast regression model for practical single image super-resolution based on in-place examples, by leveraging two fundamental super-resolution approaches— learning from an external database and learning from selfexamples. Our in-place self-similarity refines the recently proposed local self-similarity by proving that a patch in the upper scale image have good matches around its origin location in the lower scale image. Based on the in-place examples, a first-order approximation of the nonlinear mapping function from low- to high-resolution image patches is learned. Extensive experiments on benchmark and realworld images demonstrate that our algorithm can produce natural-looking results with sharp edges and preserved fine details, while the current state-of-the-art algorithms are prone to visual artifacts. Furthermore, our model can easily extend to deal with noise by combining the regression results on multiple in-place examples for robust estimation. The algorithm runs fast and is particularly useful for practical applications, where the input images typically contain diverse textures and they are potentially contaminated by noise or compression artifacts.</p><p>4 0.75424773 <a title="169-lsi-4" href="./cvpr-2013-Texture_Enhanced_Image_Denoising_via_Gradient_Histogram_Preservation.html">427 cvpr-2013-Texture Enhanced Image Denoising via Gradient Histogram Preservation</a></p>
<p>Author: Wangmeng Zuo, Lei Zhang, Chunwei Song, David Zhang</p><p>Abstract: Image denoising is a classical yet fundamental problem in low level vision, as well as an ideal test bed to evaluate various statistical image modeling methods. One of the most challenging problems in image denoising is how to preserve the fine scale texture structures while removing noise. Various natural image priors, such as gradient based prior, nonlocal self-similarity prior, and sparsity prior, have been extensively exploited for noise removal. The denoising algorithms based on these priors, however, tend to smooth the detailed image textures, degrading the image visual quality. To address this problem, in this paper we propose a texture enhanced image denoising (TEID) method by enforcing the gradient distribution of the denoised image to be close to the estimated gradient distribution of the original image. A novel gradient histogram preservation (GHP) algorithm is developed to enhance the texture structures while removing noise. Our experimental results demonstrate that theproposed GHP based TEID can well preserve the texture features of the denoised images, making them look more natural.</p><p>5 0.70885479 <a title="169-lsi-5" href="./cvpr-2013-What_Makes_a_Patch_Distinct%3F.html">464 cvpr-2013-What Makes a Patch Distinct?</a></p>
<p>Author: Ran Margolin, Ayellet Tal, Lihi Zelnik-Manor</p><p>Abstract: What makes an object salient? Most previous work assert that distinctness is the dominating factor. The difference between the various algorithms is in the way they compute distinctness. Some focus on the patterns, others on the colors, and several add high-level cues and priors. We propose a simple, yet powerful, algorithm that integrates these three factors. Our key contribution is a novel and fast approach to compute pattern distinctness. We rely on the inner statistics of the patches in the image for identifying unique patterns. We provide an extensive evaluation and show that our approach outperforms all state-of-the-art methods on the five most commonly-used datasets.</p><p>6 0.59591502 <a title="169-lsi-6" href="./cvpr-2013-Learning_without_Human_Scores_for_Blind_Image_Quality_Assessment.html">266 cvpr-2013-Learning without Human Scores for Blind Image Quality Assessment</a></p>
<p>7 0.58347893 <a title="169-lsi-7" href="./cvpr-2013-A_Machine_Learning_Approach_for_Non-blind_Image_Deconvolution.html">17 cvpr-2013-A Machine Learning Approach for Non-blind Image Deconvolution</a></p>
<p>8 0.52151173 <a title="169-lsi-8" href="./cvpr-2013-HDR_Deghosting%3A_How_to_Deal_with_Saturation%3F.html">195 cvpr-2013-HDR Deghosting: How to Deal with Saturation?</a></p>
<p>9 0.48314676 <a title="169-lsi-9" href="./cvpr-2013-Unsupervised_Salience_Learning_for_Person_Re-identification.html">451 cvpr-2013-Unsupervised Salience Learning for Person Re-identification</a></p>
<p>10 0.48099121 <a title="169-lsi-10" href="./cvpr-2013-Rotation%2C_Scaling_and_Deformation_Invariant_Scattering_for_Texture_Discrimination.html">369 cvpr-2013-Rotation, Scaling and Deformation Invariant Scattering for Texture Discrimination</a></p>
<p>11 0.47447151 <a title="169-lsi-11" href="./cvpr-2013-Ensemble_Video_Object_Cut_in_Highly_Dynamic_Scenes.html">148 cvpr-2013-Ensemble Video Object Cut in Highly Dynamic Scenes</a></p>
<p>12 0.47250038 <a title="169-lsi-12" href="./cvpr-2013-Sparse_Quantization_for_Patch_Description.html">404 cvpr-2013-Sparse Quantization for Patch Description</a></p>
<p>13 0.45060074 <a title="169-lsi-13" href="./cvpr-2013-Learning_Separable_Filters.html">255 cvpr-2013-Learning Separable Filters</a></p>
<p>14 0.44983244 <a title="169-lsi-14" href="./cvpr-2013-Handling_Noise_in_Single_Image_Deblurring_Using_Directional_Filters.html">198 cvpr-2013-Handling Noise in Single Image Deblurring Using Directional Filters</a></p>
<p>15 0.44534215 <a title="169-lsi-15" href="./cvpr-2013-Depth_Super_Resolution_by_Rigid_Body_Self-Similarity_in_3D.html">115 cvpr-2013-Depth Super Resolution by Rigid Body Self-Similarity in 3D</a></p>
<p>16 0.44002771 <a title="169-lsi-16" href="./cvpr-2013-Real-Time_No-Reference_Image_Quality_Assessment_Based_on_Filter_Learning.html">346 cvpr-2013-Real-Time No-Reference Image Quality Assessment Based on Filter Learning</a></p>
<p>17 0.43207413 <a title="169-lsi-17" href="./cvpr-2013-Representing_Videos_Using_Mid-level_Discriminative_Patches.html">355 cvpr-2013-Representing Videos Using Mid-level Discriminative Patches</a></p>
<p>18 0.42852315 <a title="169-lsi-18" href="./cvpr-2013-FrameBreak%3A_Dramatic_Image_Extrapolation_by_Guided_Shift-Maps.html">177 cvpr-2013-FrameBreak: Dramatic Image Extrapolation by Guided Shift-Maps</a></p>
<p>19 0.41697812 <a title="169-lsi-19" href="./cvpr-2013-Multipath_Sparse_Coding_Using_Hierarchical_Matching_Pursuit.html">304 cvpr-2013-Multipath Sparse Coding Using Hierarchical Matching Pursuit</a></p>
<p>20 0.41552922 <a title="169-lsi-20" href="./cvpr-2013-Nonlinearly_Constrained_MRFs%3A_Exploring_the_Intrinsic_Dimensions_of_Higher-Order_Cliques.html">308 cvpr-2013-Nonlinearly Constrained MRFs: Exploring the Intrinsic Dimensions of Higher-Order Cliques</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.151), (14, 0.243), (16, 0.028), (26, 0.064), (33, 0.25), (67, 0.041), (69, 0.041), (87, 0.065)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.83967519 <a title="169-lda-1" href="./cvpr-2013-Exploring_Implicit_Image_Statistics_for_Visual_Representativeness_Modeling.html">157 cvpr-2013-Exploring Implicit Image Statistics for Visual Representativeness Modeling</a></p>
<p>Author: Xiaoshuai Sun, Xin-Jing Wang, Hongxun Yao, Lei Zhang</p><p>Abstract: In this paper, we propose a computational model of visual representativeness by integrating cognitive theories of representativeness heuristics with computer vision and machine learning techniques. Unlike previous models that build their representativeness measure based on the visible data, our model takes the initial inputs as explicit positive reference and extend the measure by exploring the implicit negatives. Given a group of images that contains obvious visual concepts, we create a customized image ontology consisting of both positive and negative instances by mining the most related and confusable neighbors of the positive concept in ontological semantic knowledge bases. The representativeness of a new item is then determined by its likelihoods for both the positive and negative references. To ensure the effectiveness of probability inference as well as the cognitive plausibility, we discover the potential prototypes and treat them as an intermediate representation of semantic concepts. In the experiment, we evaluate the performance of representativeness models based on both human judgements and user-click logs of commercial image search engine. Experimental results on both ImageNet and image sets of general concepts demonstrate the superior performance of our model against the state-of-the-arts.</p><p>same-paper 2 0.83286107 <a title="169-lda-2" href="./cvpr-2013-Fast_Patch-Based_Denoising_Using_Approximated_Patch_Geodesic_Paths.html">169 cvpr-2013-Fast Patch-Based Denoising Using Approximated Patch Geodesic Paths</a></p>
<p>Author: Xiaogang Chen, Sing Bing Kang, Jie Yang, Jingyi Yu</p><p>Abstract: Patch-based methods such as Non-Local Means (NLM) and BM3D have become the de facto gold standard for image denoising. The core of these approaches is to use similar patches within the image as cues for denoising. The operation usually requires expensive pair-wise patch comparisons. In this paper, we present a novel fast patch-based denoising technique based on Patch Geodesic Paths (PatchGP). PatchGPs treat image patches as nodes and patch differences as edge weights for computing the shortest (geodesic) paths. The path lengths can then be used as weights of the smoothing/denoising kernel. We first show that, for natural images, PatchGPs can be effectively approximated by minimum hop paths (MHPs) that generally correspond to Euclidean line paths connecting two patch nodes. To construct the denoising kernel, we further discretize the MHP search directions and use only patches along the search directions. Along each MHP, we apply a weightpropagation scheme to robustly and efficiently compute the path distance. To handle noise at multiple scales, we conduct wavelet image decomposition and apply PatchGP scheme at each scale. Comprehensive experiments show that our approach achieves comparable quality as the state-of-the-art methods such as NLM and BM3D but is a few orders of magnitude faster.</p><p>3 0.80304205 <a title="169-lda-3" href="./cvpr-2013-Detection-_and_Trajectory-Level_Exclusion_in_Multiple_Object_Tracking.html">121 cvpr-2013-Detection- and Trajectory-Level Exclusion in Multiple Object Tracking</a></p>
<p>Author: Anton Milan, Konrad Schindler, Stefan Roth</p><p>Abstract: When tracking multiple targets in crowded scenarios, modeling mutual exclusion between distinct targets becomes important at two levels: (1) in data association, each target observation should support at most one trajectory and each trajectory should be assigned at most one observation per frame; (2) in trajectory estimation, two trajectories should remain spatially separated at all times to avoid collisions. Yet, existing trackers often sidestep these important constraints. We address this using a mixed discrete-continuous conditional randomfield (CRF) that explicitly models both types of constraints: Exclusion between conflicting observations with supermodular pairwise terms, and exclusion between trajectories by generalizing global label costs to suppress the co-occurrence of incompatible labels (trajectories). We develop an expansion move-based MAP estimation scheme that handles both non-submodular constraints and pairwise global label costs. Furthermore, we perform a statistical analysis of ground-truth trajectories to derive appropriate CRF potentials for modeling data fidelity, target dynamics, and inter-target occlusion.</p><p>4 0.79315734 <a title="169-lda-4" href="./cvpr-2013-Multi-source_Multi-scale_Counting_in_Extremely_Dense_Crowd_Images.html">299 cvpr-2013-Multi-source Multi-scale Counting in Extremely Dense Crowd Images</a></p>
<p>Author: Haroon Idrees, Imran Saleemi, Cody Seibert, Mubarak Shah</p><p>Abstract: We propose to leverage multiple sources of information to compute an estimate of the number of individuals present in an extremely dense crowd visible in a single image. Due to problems including perspective, occlusion, clutter, and few pixels per person, counting by human detection in such images is almost impossible. Instead, our approach relies on multiple sources such as low confidence head detections, repetition of texture elements (using SIFT), and frequency-domain analysis to estimate counts, along with confidence associated with observing individuals, in an image region. Secondly, we employ a global consistency constraint on counts using Markov Random Field. This caters for disparity in counts in local neighborhoods and across scales. We tested our approach on a new dataset of fifty crowd images containing 64K annotated humans, with the head counts ranging from 94 to 4543. This is in stark con- trast to datasets usedfor existing methods which contain not more than tens of individuals. We experimentally demonstrate the efficacy and reliability of the proposed approach by quantifying the counting performance.</p><p>5 0.77619994 <a title="169-lda-5" href="./cvpr-2013-Structure_Preserving_Object_Tracking.html">414 cvpr-2013-Structure Preserving Object Tracking</a></p>
<p>Author: Lu Zhang, Laurens van_der_Maaten</p><p>Abstract: Model-free trackers can track arbitrary objects based on a single (bounding-box) annotation of the object. Whilst the performance of model-free trackers has recently improved significantly, simultaneously tracking multiple objects with similar appearance remains very hard. In this paper, we propose a new multi-object model-free tracker (based on tracking-by-detection) that resolves this problem by incorporating spatial constraints between the objects. The spatial constraints are learned along with the object detectors using an online structured SVM algorithm. The experimental evaluation ofour structure-preserving object tracker (SPOT) reveals significant performance improvements in multi-object tracking. We also show that SPOT can improve the performance of single-object trackers by simultaneously tracking different parts of the object.</p><p>6 0.77585149 <a title="169-lda-6" href="./cvpr-2013-Robust_Estimation_of_Nonrigid_Transformation_for_Point_Set_Registration.html">360 cvpr-2013-Robust Estimation of Nonrigid Transformation for Point Set Registration</a></p>
<p>7 0.7758075 <a title="169-lda-7" href="./cvpr-2013-Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking.html">285 cvpr-2013-Minimum Uncertainty Gap for Robust Visual Tracking</a></p>
<p>8 0.77548182 <a title="169-lda-8" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>9 0.77221096 <a title="169-lda-9" href="./cvpr-2013-Part_Discovery_from_Partial_Correspondence.html">325 cvpr-2013-Part Discovery from Partial Correspondence</a></p>
<p>10 0.77158445 <a title="169-lda-10" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<p>11 0.77152473 <a title="169-lda-11" href="./cvpr-2013-Least_Soft-Threshold_Squares_Tracking.html">267 cvpr-2013-Least Soft-Threshold Squares Tracking</a></p>
<p>12 0.77104622 <a title="169-lda-12" href="./cvpr-2013-Discriminative_Non-blind_Deblurring.html">131 cvpr-2013-Discriminative Non-blind Deblurring</a></p>
<p>13 0.77073652 <a title="169-lda-13" href="./cvpr-2013-Spatiotemporal_Deformable_Part_Models_for_Action_Detection.html">408 cvpr-2013-Spatiotemporal Deformable Part Models for Action Detection</a></p>
<p>14 0.77053481 <a title="169-lda-14" href="./cvpr-2013-Integrating_Grammar_and_Segmentation_for_Human_Pose_Estimation.html">225 cvpr-2013-Integrating Grammar and Segmentation for Human Pose Estimation</a></p>
<p>15 0.77038616 <a title="169-lda-15" href="./cvpr-2013-Online_Object_Tracking%3A_A_Benchmark.html">314 cvpr-2013-Online Object Tracking: A Benchmark</a></p>
<p>16 0.77009785 <a title="169-lda-16" href="./cvpr-2013-Part-Based_Visual_Tracking_with_Online_Latent_Structural_Learning.html">324 cvpr-2013-Part-Based Visual Tracking with Online Latent Structural Learning</a></p>
<p>17 0.770082 <a title="169-lda-17" href="./cvpr-2013-Occlusion_Patterns_for_Object_Class_Detection.html">311 cvpr-2013-Occlusion Patterns for Object Class Detection</a></p>
<p>18 0.7693103 <a title="169-lda-18" href="./cvpr-2013-Physically_Plausible_3D_Scene_Tracking%3A_The_Single_Actor_Hypothesis.html">331 cvpr-2013-Physically Plausible 3D Scene Tracking: The Single Actor Hypothesis</a></p>
<p>19 0.76901913 <a title="169-lda-19" href="./cvpr-2013-Understanding_Bayesian_Rooms_Using_Composite_3D_Object_Models.html">445 cvpr-2013-Understanding Bayesian Rooms Using Composite 3D Object Models</a></p>
<p>20 0.76888531 <a title="169-lda-20" href="./cvpr-2013-Single_Image_Calibration_of_Multi-axial_Imaging_Systems.html">400 cvpr-2013-Single Image Calibration of Multi-axial Imaging Systems</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
