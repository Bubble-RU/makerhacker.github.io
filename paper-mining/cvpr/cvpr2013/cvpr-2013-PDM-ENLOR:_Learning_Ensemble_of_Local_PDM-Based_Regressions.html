<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>321 cvpr-2013-PDM-ENLOR: Learning Ensemble of Local PDM-Based Regressions</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-321" href="#">cvpr2013-321</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>321 cvpr-2013-PDM-ENLOR: Learning Ensemble of Local PDM-Based Regressions</h1>
<br/><p>Source: <a title="cvpr-2013-321-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Le_PDM-ENLOR_Learning_Ensemble_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Yen H. Le, Uday Kurkure, Ioannis A. Kakadiaris</p><p>Abstract: Statistical shape models, such as Active Shape Models (ASMs), sufferfrom their inability to represent a large range of variations of a complex shape and to account for the large errors in detection of model points. We propose a novel method (dubbed PDM-ENLOR) that overcomes these limitations by locating each shape model point individually using an ensemble of local regression models and appearance cues from selected model points. Our method first detects a set of reference points which were selected based on their saliency during training. For each model point, an ensemble of regressors is built. From the locations of the detected reference points, each regressor infers a candidate location for that model point using local geometric constraints, encoded by a point distribution model (PDM). The final location of that point is determined as a weighted linear combination, whose coefficients are learnt from the training data, of candidates proposed from its ensemble ’s component regressors. We use different subsets of reference points as explanatory variables for the component regressors to provide varying degrees of locality for the models in each ensemble. This helps our ensemble model to capture a larger range of shape variations as compared to a single PDM. We demonstrate the advantages of our method on the challenging problem of segmenting gene expression images of mouse brain.</p><p>Reference: <a title="cvpr-2013-321-reference" href="../cvpr2013_reference/cvpr-2013-PDM-ENLOR%3A_Learning_Ensemble_of_Local_PDM-Based_Regressions_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu/  Abstract Statistical shape models, such as Active Shape Models (ASMs), sufferfrom their inability to represent a large range of variations of a complex shape and to account for the large errors in detection of model points. [sent-9, score-0.456]
</p><p>2 We propose a novel method (dubbed PDM-ENLOR) that overcomes these limitations by locating each shape model point individually using an ensemble of local regression models and appearance cues from selected model points. [sent-10, score-0.837]
</p><p>3 Our method first detects a set of reference points which were selected based on their saliency during training. [sent-11, score-0.48]
</p><p>4 From the locations of the detected reference points, each regressor infers a candidate location for that model point using local geometric constraints, encoded by a point distribution model (PDM). [sent-13, score-0.605]
</p><p>5 The final location of that point is determined as a weighted linear combination, whose coefficients are learnt from the training data, of candidates proposed from its ensemble ’s component regressors. [sent-14, score-0.388]
</p><p>6 We use different subsets of reference points as explanatory variables for the component regressors to provide varying degrees of locality for the models in  each ensemble. [sent-15, score-0.792]
</p><p>7 This helps our ensemble model to capture a larger range of shape variations as compared to a single PDM. [sent-16, score-0.423]
</p><p>8 We demonstrate the advantages of our method on the challenging problem of segmenting gene expression images of mouse brain. [sent-17, score-0.755]
</p><p>9 The active shape model (ASM [7]) is one of the most popular statistical shape models that restricts the shape space to limit the range of possible shapes the model can form. [sent-21, score-0.802]
</p><p>10 However, one of their major limitations lies in their ability to represent the variations of a complex shape model, especially when the number of training samples is much smaller than the dimensions of the shape model. [sent-22, score-0.394]
</p><p>11 Such erroneous detections of a large number of model points can drive the fitting to an incorrect solution. [sent-25, score-0.356]
</p><p>12 In this paper, we propose a new approach for statistical  model fitting that also provides solutions to the problems of the model flexibility and the model point detection errors. [sent-26, score-0.511]
</p><p>13 Our PDM-ENLOR locates each shape model point individually using an ensemble of regression models built for that specific point. [sent-27, score-0.79]
</p><p>14 Specifically, a set of salient reference points are first selected to be used as explanatory variables of the regression models. [sent-28, score-0.815]
</p><p>15 These reference points are detected using our PASM-CTX algorithm. [sent-29, score-0.444]
</p><p>16 Then, each component regression model regresses the location of a model point of interest from the detected locations of its explanatory variables by fitting a point distribution model (PDM) [8], which is built to encode the spatial relationship between the dependent and the explanatory variables. [sent-30, score-0.916]
</p><p>17 In order to provide increased flexibility to the shape model and to handle the non-robust detection of the regression explanatory variables, the models are built with increasing degrees of locality based on the increasing number of reference points used. [sent-31, score-1.23]
</p><p>18 Note that the set of selected salient reference points is automatically selected during the training phase and may include points that do not belong to the boundaries. [sent-33, score-0.752]
</p><p>19 We evaluate our method on mouse brain gene expression images to segment sagittal sections from a mouse brain into 14 anatomical regions. [sent-34, score-1.495]
</p><p>20 The main challenges of this problem are the lack of visible edge cues of the regional boundaries and the shape variation of anatomical regions across images [16]. [sent-35, score-0.352]
</p><p>21 First, we  propose a novel method to construct an ensemble of multiple regression models to impose shape constraints of varying degrees of locality from local-to-global to increase the 111888777866  flexibility of the shape model. [sent-37, score-0.978]
</p><p>22 Third, our PASM-CTX method to detect the reference points is the first work that uses similaritybased features instead of a local gray level model to detect the local best matches in ASM search. [sent-41, score-0.488]
</p><p>23 This modification makes ASM applicable to gene expression image data whose regional boundaries are indistinct. [sent-42, score-0.536]
</p><p>24 In addition, since our method incorporates appearance guidance from only the points that are likely to be detected correctly, our method does not require any post-processing step to minimize the errors in fitting due to unreliable model points. [sent-43, score-0.544]
</p><p>25 Instead of partitioning the shapes, few recent methods [2, 18] fit a global shape model for each model point individually using local weights. [sent-59, score-0.376]
</p><p>26 The local weights for each model point control the neighborhood size for fitting that point and they are computed based on the distances between model points. [sent-60, score-0.453]
</p><p>27 While this approach avoids the partitioning of the shape model, determining the neighborhood size that controls the degree of locality is nontrivial. [sent-61, score-0.395]
</p><p>28 [29] proposed to detect the salient points based on prior knowledge about the contrast of the contour and reconstruct the full shape from the detection of salient points. [sent-70, score-0.57]
</p><p>29 However, instead of using a single global model, our method explicitly builds different regression models with different degrees of locality for each point to increase their flexibility. [sent-75, score-0.426]
</p><p>30 Similar to [29], the PASM-CTX and PDM-ENLOR detect the salient points and reconstructs the shape based on the guidance of the salient points to account for the large errors in detection. [sent-77, score-0.733]
</p><p>31 However, our methods learn the set of salient points from training data in advance and exploits information from additional supporting salient points, which may not belong to the boundaries. [sent-78, score-0.37]
</p><p>32 In addition, PDM-ENLOR uses salient points selectively in the ensemble of multiple models to provide further flexibility at local level. [sent-79, score-0.538]
</p><p>33 Overview In this section, we briefly present our method for fitting a shape model to an image. [sent-85, score-0.392]
</p><p>34 A set of reference points, which were selected during training phase based on a saliency criteria, are detected using PASM-CTX. [sent-87, score-0.415]
</p><p>35 Then, each point of the boundary shape model is localized independently using an ensemble of regression models. [sent-88, score-0.704]
</p><p>36 Each regression model is obtained by fitting a PDM, which is specifically built to represent the spatial relationship of the model point of interest and a subset of the reference points. [sent-89, score-0.774]
</p><p>37 Specifically, the final location of a model point pi in the shape model of interest, is given by:  = ? [sent-92, score-0.466]
</p><p>38 j=1  (1)  where k is the number of regression functions built for pi, Rji is a set of reference points used in the function fji to infer pi and cji is the ensemble coefficient for the regression 111888777977  function fji. [sent-95, score-1.207]
</p><p>39 The shape model of interest that contains sampled points on the boundaries of the object is referred as the boundary shape model. [sent-97, score-0.597]
</p><p>40 Reference point selection Only the points that can be reliably detected should be used as a reference to guide the inference for the location of the model points. [sent-102, score-0.556]
</p><p>41 The similarity-saliency score of a point u with respect to a reference image T computed for a set of training images I {Ii}in=1 is defined as: = γ(u,T,I)  =  ? [sent-107, score-0.372]
</p><p>42 First, the similarity-saliency score of each point with respect to the reference image T over the set of training images I (Eq. [sent-121, score-0.372]
</p><p>43 Then, a set of reference points ewsh Ios (eE similarity-saliency score i,s higher ft rheafna threshold t are selected. [sent-123, score-0.405]
</p><p>44 Mouse brain gene expression images: For mouse brain images, L contains all 1,245 vertices of a subdivision mesh, a geometric model specifically constructed for mouse brain gene expression images by Ju et al. [sent-133, score-2.178]
</p><p>45 For the 10-fold experiments, 183 to 196 reference points were selected and depicted as solid blue circles in Fig. [sent-136, score-0.441]
</p><p>46 In the mouse brain gene expression images, the intensity pattern of each anatomical region may vary significantly from image to image as each image expresses a different gene. [sent-138, score-1.025]
</p><p>47 Therefore, a special image called Nissl-stained image (NSI), which was constructed using a universal gene probe and has maximum similarity to other gene expression images, is used as a reference image ([16, 20]). [sent-139, score-1.123]
</p><p>48 Regression model definition In this section, we present how to encode different degrees of locality in our ensemble scheme by defining the explanatory variables Rji for regressors in Eq. [sent-142, score-0.598]
</p><p>49 The locality level j of a regression model fji (Rij) is based on the spatial relationship between pi and the reference points in Rji . [sent-144, score-0.954]
</p><p>50 We assume that the neighboring points provide simi-  Figure 1: Illustration of the shape models in mouse brain gene expression image segmentation. [sent-145, score-1.263]
</p><p>51 The squares depict the non-reference boundary points and the solid blue circles depict the reference points. [sent-146, score-0.463]
</p><p>52 The boundary shape model contains all sampled points on the regional boundaries of 14 anatomical regions. [sent-147, score-0.593]
</p><p>53 The extended shape model contains all the boundary points and the reference points (i. [sent-148, score-0.855]
</p><p>54 These clusters of the reference points are then used to construct the regression models for inference of the position of a target model point. [sent-156, score-0.676]
</p><p>55 Because there can be some reference points that are isolated from the others and should not be merged with their neighbors that are far away, we allow the clusters to have size of 1. [sent-168, score-0.489]
</p><p>56 The smk−a1lle∪r vQalue of, tfoher locality le (kve −l j o)f; the regression −m1odel fji corresponds to a more local model. [sent-186, score-0.412]
</p><p>57 Shape model point regression Given an input image, our method first detects the reference points and then infers the position of each model point using the constructed regression models. [sent-190, score-0.974]
</p><p>58 For clarity of presentation, first we present how to determine candidate locations using a PDM-based regression function assuming that the positions of the reference points are already available. [sent-191, score-0.557]
</p><p>59 1  PDM-based model point regression  In this section, we present how our method infers the po-  sition of a model point pi based on reference points in Rji using a PDM. [sent-195, score-0.957]
</p><p>60 Then, each shape x is represented as x = ¯x Pb, where b is the shape parameter. [sent-202, score-0.356]
</p><p>61 The fitting of the PDM ( x¯, P) to a shape x is given by:  +  x∗ = argminx | |W[x − ( x¯ + Pb)] | |22 ,  (5)  where the diagonal weight matrix W2m×2m is introduced to emphasize the importance of the model points: W(2i − 1, 2i − 1) = W(2i, 2i) is the weight of the ith Wmod(2eil point. [sent-203, score-0.392]
</p><p>62 Generally, the shape is rigidlyaligned before fitting to remove global transformations by using generalized Procrustes [14]. [sent-205, score-0.351]
</p><p>63 ,ekre −ea 1ch), shape Mco (n x¯tains pi (always being the first point of the shape) and all points in Rji . [sent-212, score-0.526]
</p><p>64 To use a PDM to infer the position of an unknown point pi, we reconstruct the full shape from the known locations of points in Rji and retrieve the point of interest pi. [sent-213, score-0.462]
</p><p>65 The inference of pi in the first (k −1) regression models employs only the geometric c foirnsstt (raki−nts1 b)e rtewgreeesns pi amnodd tehles reference points. [sent-216, score-0.757]
</p><p>66 To explicitly impose the geometric constraints on all the points in the boundary shape model, the extended shape model is used for training the PDM for the last regressor fki (Rik). [sent-217, score-0.704]
</p><p>67 In the ASM approach, a shape iteratively evolves in two steps: (i) finding a new shape estimate (target shape) whose each model point is detected as the best match in the local neighborhood of that point  from the previous iteration, and (ii) fitting the target shape by solving Eq. [sent-221, score-0.985]
</p><p>68 Due to the indistinct anatomical boundaries in gene expression images, the local gray level model of the traditional ASM formulation is not suitable for the detection of the model points. [sent-223, score-0.704]
</p><p>69 While we want to detect only the reference points, the extended shape model is used to train a PDM for maintaining the global shape constraint. [sent-225, score-0.691]
</p><p>70 Since the extended shape model contains context points which are not the points of interest, we refer our modified ASM method as PASM-CTX (Partial ASM with ConTeXt). [sent-226, score-0.534]
</p><p>71 At each iteration, we evolve the shape based on the guidance of the reference points only (i. [sent-227, score-0.633]
</p><p>72 , 0 as weight for non-reference points and 1 as weight for reference points in the fitting process). [sent-229, score-0.72]
</p><p>73 That means the fitting step at the last iteration is omitted and the best matches obtained from feature detectors at that iteration are the final estimates of the reference points. [sent-231, score-0.492]
</p><p>74 Initialization: To obtain a robust initialization for the specific application, the shape parameters are first computed based on the points on the outer boundary of the brain (i. [sent-232, score-0.565]
</p><p>75 The reason is that the outer boundary in mouse brain can be easily obtained quite accurately and it can provide certain information about the global shape [15, 4, 17, 20]. [sent-235, score-0.7]
</p><p>76 The neighboring point whose image patch around it in the test image is most similar to the image patch around pi in the reference image (NSI) is selected as the best match for pi. [sent-243, score-0.505]
</p><p>77 Combining the models in ensemble In this section, we provide the motivation for using an ensemble of models in Eq. [sent-252, score-0.476]
</p><p>78 Using an ensemble of models: A local model can pro-  vide improved geometric constraints due to the locality and the simplicity of the local shape. [sent-255, score-0.412]
</p><p>79 Using a global model in this case can help if the additional reference points can be detected more accurately. [sent-257, score-0.485]
</p><p>80 Learning the ensemble weights: For each model point pi, the coefficient vector ci = [ci1, ci2, . [sent-269, score-0.35]
</p><p>81 The matrix Ai contains the coordinates of the results obtained from the regression models that infer pi in all training images:  Il. [sent-273, score-0.359]
</p><p>82 Then, the ensemble coefficient vector for point pi is computed as:  (xi(g,l) y(ig,l)  ci∗= argcmiin||Aici− gi||22,  s. [sent-280, score-0.444]
</p><p>83 Experiments and Results Image data: We evaluated our method on 2D mouse brain gene expression images [4, 6]. [sent-285, score-0.909]
</p><p>84 The dataset contains 100 images depicting sagittal sections of postnatal day 7 mouse brains at standard section 9. [sent-286, score-0.364]
</p><p>85 The annotated shape and the anatomical point set L were extracted from the manually annotated subdivision mesh at subdivision level 2 and were provided by [15, 4]. [sent-288, score-0.659]
</p><p>86 We quantitatively compared the performance of the different methods using the Dice similarity coefficient (DSC) against the manual annotations for each of the 14 anatomical regions in the mouse brain. [sent-290, score-0.458]
</p><p>87 That can be explained by the non-robust detections of large number of model points due to the complex appearance of gene expression images. [sent-330, score-0.696]
</p><p>88 Comparison with previous works on the application: We also compared our method PDM-ENLOR with two state-of-the-art works on mouse brain gene expression image data of Kurkure et al. [sent-340, score-0.909]
</p><p>89 Conclusions In this paper, we have presented a new approach to improve the model flexibility and to handle the detection errors for statistical shape fitting problem towards image segmentation. [sent-346, score-0.567]
</p><p>90 We proposed to locate each model point individually using an ensemble of PDM-based regression models which were constructed with increasing degree of locality to provide more flexibility. [sent-347, score-0.708]
</p><p>91 A set of selected salient reference points is used to construct the models to minimize the errors in fitting due to unreliable model points. [sent-353, score-0.848]
</p><p>92 We demonstrated that the use of appearance cues from selected model points can significantly improve the fitting results. [sent-355, score-0.427]
</p><p>93 Furthermore, our method outperforms the state-of-the-art methods on a challenging problem of multiregion segmentation ofthe mouse brain gene expression images. [sent-356, score-0.909]
</p><p>94 Learning-based segmentation framework for tis111888888422  [5]  [6]  [7]  [8]  sue images containing gene expression data. [sent-394, score-0.478]
</p><p>95 Automated pipeline for atlas-based annotation of gene expression patterns: Application to postnatal day 7 mouse brain. [sent-423, score-0.803]
</p><p>96 Adapting active shape models for 3D segmentation of tubular structures in medical images. [sent-461, score-0.366]
</p><p>97 Similarity-based appearance prior for fitting a subdivision mesh in gene expression images. [sent-546, score-0.853]
</p><p>98 Discrete deformable model guided by partial active shape model for trus image segmentation. [sent-619, score-0.354]
</p><p>99 Towards robust and effective shape modeling: sparse shape composition. [sent-633, score-0.356]
</p><p>100 A novel 3d partitioned active shape model for segmentation of brain mr images. [sent-641, score-0.439]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('gene', 0.351), ('mouse', 0.277), ('reference', 0.263), ('ensemble', 0.204), ('asm', 0.194), ('rji', 0.191), ('pdm', 0.184), ('shape', 0.178), ('fitting', 0.173), ('brain', 0.154), ('regression', 0.152), ('kurkure', 0.143), ('points', 0.142), ('pi', 0.135), ('locality', 0.129), ('subdivision', 0.127), ('explanatory', 0.127), ('expression', 0.127), ('carson', 0.119), ('anatomical', 0.116), ('ju', 0.11), ('rki', 0.095), ('salient', 0.095), ('fji', 0.092), ('nsi', 0.088), ('medical', 0.088), ('dsc', 0.078), ('houston', 0.071), ('pdms', 0.071), ('warren', 0.071), ('point', 0.071), ('active', 0.066), ('conference', 0.066), ('flexibility', 0.063), ('boundary', 0.058), ('regional', 0.058), ('regressors', 0.057), ('neighborhood', 0.056), ('chiu', 0.055), ('statistical', 0.053), ('rij', 0.053), ('guidance', 0.05), ('paragios', 0.049), ('annulus', 0.048), ('bello', 0.048), ('lawson', 0.048), ('lekadir', 0.048), ('postnatal', 0.048), ('candidates', 0.045), ('individually', 0.045), ('clusters', 0.044), ('peripheral', 0.042), ('amberg', 0.042), ('similaritybased', 0.042), ('kriegel', 0.042), ('international', 0.042), ('model', 0.041), ('pages', 0.041), ('infers', 0.041), ('mesh', 0.04), ('degrees', 0.04), ('procrustes', 0.04), ('neighbors', 0.04), ('saliency', 0.039), ('thaller', 0.039), ('sagittal', 0.039), ('kakadiaris', 0.039), ('le', 0.039), ('detected', 0.039), ('cootes', 0.039), ('training', 0.038), ('geometric', 0.038), ('pji', 0.037), ('registration', 0.037), ('automated', 0.036), ('selected', 0.036), ('qh', 0.035), ('springs', 0.035), ('appearance', 0.035), ('models', 0.034), ('coefficient', 0.034), ('shapes', 0.033), ('outer', 0.033), ('unreliable', 0.033), ('built', 0.033), ('degree', 0.032), ('contour', 0.032), ('locates', 0.032), ('errors', 0.031), ('similarity', 0.031), ('extended', 0.031), ('coefficients', 0.03), ('barcelona', 0.03), ('spain', 0.03), ('vv', 0.03), ('post', 0.029), ('landmark', 0.029), ('deformable', 0.028), ('iteration', 0.028), ('detection', 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000006 <a title="321-tfidf-1" href="./cvpr-2013-PDM-ENLOR%3A_Learning_Ensemble_of_Local_PDM-Based_Regressions.html">321 cvpr-2013-PDM-ENLOR: Learning Ensemble of Local PDM-Based Regressions</a></p>
<p>Author: Yen H. Le, Uday Kurkure, Ioannis A. Kakadiaris</p><p>Abstract: Statistical shape models, such as Active Shape Models (ASMs), sufferfrom their inability to represent a large range of variations of a complex shape and to account for the large errors in detection of model points. We propose a novel method (dubbed PDM-ENLOR) that overcomes these limitations by locating each shape model point individually using an ensemble of local regression models and appearance cues from selected model points. Our method first detects a set of reference points which were selected based on their saliency during training. For each model point, an ensemble of regressors is built. From the locations of the detected reference points, each regressor infers a candidate location for that model point using local geometric constraints, encoded by a point distribution model (PDM). The final location of that point is determined as a weighted linear combination, whose coefficients are learnt from the training data, of candidates proposed from its ensemble ’s component regressors. We use different subsets of reference points as explanatory variables for the component regressors to provide varying degrees of locality for the models in each ensemble. This helps our ensemble model to capture a larger range of shape variations as compared to a single PDM. We demonstrate the advantages of our method on the challenging problem of segmenting gene expression images of mouse brain.</p><p>2 0.13129419 <a title="321-tfidf-2" href="./cvpr-2013-Robust_Discriminative_Response_Map_Fitting_with_Constrained_Local_Models.html">359 cvpr-2013-Robust Discriminative Response Map Fitting with Constrained Local Models</a></p>
<p>Author: Akshay Asthana, Stefanos Zafeiriou, Shiyang Cheng, Maja Pantic</p><p>Abstract: We present a novel discriminative regression based approach for the Constrained Local Models (CLMs) framework, referred to as the Discriminative Response Map Fitting (DRMF) method, which shows impressive performance in the generic face fitting scenario. The motivation behind this approach is that, unlike the holistic texture based features used in the discriminative AAM approaches, the response map can be represented by a small set of parameters and these parameters can be very efficiently used for reconstructing unseen response maps. Furthermore, we show that by adopting very simple off-the-shelf regression techniques, it is possible to learn robust functions from response maps to the shape parameters updates. The experiments, conducted on Multi-PIE, XM2VTS and LFPW database, show that the proposed DRMF method outperforms stateof-the-art algorithms for the task of generic face fitting. Moreover, the DRMF method is computationally very efficient and is real-time capable. The current MATLAB implementation takes 1second per image. To facilitate future comparisons, we release the MATLAB code1 and the pretrained models for research purposes.</p><p>3 0.11767365 <a title="321-tfidf-3" href="./cvpr-2013-Active_Contours_with_Group_Similarity.html">33 cvpr-2013-Active Contours with Group Similarity</a></p>
<p>Author: Xiaowei Zhou, Xiaojie Huang, James S. Duncan, Weichuan Yu</p><p>Abstract: Active contours are widely used in image segmentation. To cope with missing or misleading features in images, researchers have introduced various ways to model the prior of shapes and use the prior to constrain active contours. However, the shape prior is usually learnt from a large set of annotated data, which is not always accessible in practice. Moreover, it is often doubted that the existing shapes in the training set will be sufficient to model the new instance in the testing image. In this paper, we propose to use the group similarity of object shapes in multiple images as a prior to aid segmentation, which can be interpreted as an unsupervised approach of shape prior modeling. We show that the rank of the matrix consisting of multiple shapes is a good measure of the group similarity of the shapes, and the nuclear norm minimization is a simple and effective way to impose the proposed constraint on existing active contour models. Moreover, we develop a fast algorithm to solve the proposed model by using the accelerated proximal method. Experiments using echocardiographic image sequences acquired from acute canine experiments demonstrate that the proposed method can consistently improve the performance of active contour models and increase the robustness against image defects such as missing boundaries.</p><p>4 0.10908637 <a title="321-tfidf-4" href="./cvpr-2013-Salient_Object_Detection%3A_A_Discriminative_Regional_Feature_Integration_Approach.html">376 cvpr-2013-Salient Object Detection: A Discriminative Regional Feature Integration Approach</a></p>
<p>Author: Huaizu Jiang, Jingdong Wang, Zejian Yuan, Yang Wu, Nanning Zheng, Shipeng Li</p><p>Abstract: Salient object detection has been attracting a lot of interest, and recently various heuristic computational models have been designed. In this paper, we regard saliency map computation as a regression problem. Our method, which is based on multi-level image segmentation, uses the supervised learning approach to map the regional feature vector to a saliency score, and finally fuses the saliency scores across multiple levels, yielding the saliency map. The contributions lie in two-fold. One is that we show our approach, which integrates the regional contrast, regional property and regional backgroundness descriptors together to form the master saliency map, is able to produce superior saliency maps to existing algorithms most of which combine saliency maps heuristically computed from different types of features. The other is that we introduce a new regional feature vector, backgroundness, to characterize the background, which can be regarded as a counterpart of the objectness descriptor [2]. The performance evaluation on several popular benchmark data sets validates that our approach outperforms existing state-of-the-arts.</p><p>5 0.10743342 <a title="321-tfidf-5" href="./cvpr-2013-Accurate_and_Robust_Registration_of_Nonrigid_Surface_Using_Hierarchical_Statistical_Shape_Model.html">31 cvpr-2013-Accurate and Robust Registration of Nonrigid Surface Using Hierarchical Statistical Shape Model</a></p>
<p>Author: Hidekata Hontani, Yuto Tsunekawa, Yoshihide Sawada</p><p>Abstract: In this paper, we propose a new non-rigid robust registration method that registers a point distribution model (PDM) of a surface to given 3D images. The contributions of the paper are (1) a new hierarchical statistical shape model (SSM) of the surface that has better generalization ability is introduced, (2) the registration algorithm of the hierarchical SSM that can estimate the marginal posterior distribution of the surface location is proposed, and (3) the registration performance is improved by (3-1) robustly registering each local shape of the surface with the sparsity regularization and by (3-2) referring to the appearance between the neighboring model points in the likelihood computation. The SSM of a liver was constructed from a set of clinical CT images, and the performance of the proposed method was evaluated. Experimental results demonstrated that the proposed method outperformed some existing methods that use non-hierarchical SSMs.</p><p>6 0.094475783 <a title="321-tfidf-6" href="./cvpr-2013-Discriminative_Brain_Effective_Connectivity_Analysis_for_Alzheimer%27s_Disease%3A_A_Kernel_Learning_Approach_upon_Sparse_Gaussian_Bayesian_Network.html">129 cvpr-2013-Discriminative Brain Effective Connectivity Analysis for Alzheimer's Disease: A Kernel Learning Approach upon Sparse Gaussian Bayesian Network</a></p>
<p>7 0.094338417 <a title="321-tfidf-7" href="./cvpr-2013-Computationally_Efficient_Regression_on_a_Dependency_Graph_for_Human_Pose_Estimation.html">89 cvpr-2013-Computationally Efficient Regression on a Dependency Graph for Human Pose Estimation</a></p>
<p>8 0.089140035 <a title="321-tfidf-8" href="./cvpr-2013-Fast_Image_Super-Resolution_Based_on_In-Place_Example_Regression.html">166 cvpr-2013-Fast Image Super-Resolution Based on In-Place Example Regression</a></p>
<p>9 0.086840674 <a title="321-tfidf-9" href="./cvpr-2013-HDR_Deghosting%3A_How_to_Deal_with_Saturation%3F.html">195 cvpr-2013-HDR Deghosting: How to Deal with Saturation?</a></p>
<p>10 0.085561685 <a title="321-tfidf-10" href="./cvpr-2013-Multi-resolution_Shape_Analysis_via_Non-Euclidean_Wavelets%3A_Applications_to_Mesh_Segmentation_and_Surface_Alignment_Problems.html">297 cvpr-2013-Multi-resolution Shape Analysis via Non-Euclidean Wavelets: Applications to Mesh Segmentation and Surface Alignment Problems</a></p>
<p>11 0.084903836 <a title="321-tfidf-11" href="./cvpr-2013-Dense_Object_Reconstruction_with_Semantic_Priors.html">110 cvpr-2013-Dense Object Reconstruction with Semantic Priors</a></p>
<p>12 0.084060371 <a title="321-tfidf-12" href="./cvpr-2013-Saliency_Detection_via_Graph-Based_Manifold_Ranking.html">375 cvpr-2013-Saliency Detection via Graph-Based Manifold Ranking</a></p>
<p>13 0.082125984 <a title="321-tfidf-13" href="./cvpr-2013-Class_Generative_Models_Based_on_Feature_Regression_for_Pose_Estimation_of_Object_Categories.html">82 cvpr-2013-Class Generative Models Based on Feature Regression for Pose Estimation of Object Categories</a></p>
<p>14 0.08129596 <a title="321-tfidf-14" href="./cvpr-2013-Area_Preserving_Brain_Mapping.html">44 cvpr-2013-Area Preserving Brain Mapping</a></p>
<p>15 0.079849713 <a title="321-tfidf-15" href="./cvpr-2013-Hierarchical_Saliency_Detection.html">202 cvpr-2013-Hierarchical Saliency Detection</a></p>
<p>16 0.079060003 <a title="321-tfidf-16" href="./cvpr-2013-Discriminative_Subspace_Clustering.html">135 cvpr-2013-Discriminative Subspace Clustering</a></p>
<p>17 0.077568859 <a title="321-tfidf-17" href="./cvpr-2013-Robust_Estimation_of_Nonrigid_Transformation_for_Point_Set_Registration.html">360 cvpr-2013-Robust Estimation of Nonrigid Transformation for Point Set Registration</a></p>
<p>18 0.077337272 <a title="321-tfidf-18" href="./cvpr-2013-Dense_Reconstruction_Using_3D_Object_Shape_Priors.html">111 cvpr-2013-Dense Reconstruction Using 3D Object Shape Priors</a></p>
<p>19 0.077270076 <a title="321-tfidf-19" href="./cvpr-2013-Deep_Learning_Shape_Priors_for_Object_Segmentation.html">105 cvpr-2013-Deep Learning Shape Priors for Object Segmentation</a></p>
<p>20 0.076902807 <a title="321-tfidf-20" href="./cvpr-2013-Non-rigid_Structure_from_Motion_with_Diffusion_Maps_Prior.html">306 cvpr-2013-Non-rigid Structure from Motion with Diffusion Maps Prior</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.198), (1, 0.009), (2, 0.057), (3, 0.047), (4, 0.036), (5, -0.03), (6, -0.013), (7, -0.039), (8, 0.033), (9, -0.063), (10, 0.021), (11, 0.023), (12, -0.078), (13, -0.044), (14, 0.019), (15, -0.069), (16, -0.002), (17, 0.025), (18, 0.049), (19, 0.042), (20, -0.037), (21, 0.043), (22, -0.027), (23, -0.021), (24, -0.009), (25, 0.034), (26, -0.017), (27, -0.088), (28, 0.039), (29, -0.013), (30, 0.04), (31, 0.0), (32, -0.053), (33, -0.01), (34, 0.017), (35, 0.032), (36, -0.015), (37, -0.04), (38, -0.031), (39, 0.001), (40, -0.031), (41, 0.003), (42, -0.015), (43, 0.027), (44, 0.027), (45, 0.037), (46, -0.047), (47, 0.029), (48, -0.015), (49, 0.064)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94583529 <a title="321-lsi-1" href="./cvpr-2013-PDM-ENLOR%3A_Learning_Ensemble_of_Local_PDM-Based_Regressions.html">321 cvpr-2013-PDM-ENLOR: Learning Ensemble of Local PDM-Based Regressions</a></p>
<p>Author: Yen H. Le, Uday Kurkure, Ioannis A. Kakadiaris</p><p>Abstract: Statistical shape models, such as Active Shape Models (ASMs), sufferfrom their inability to represent a large range of variations of a complex shape and to account for the large errors in detection of model points. We propose a novel method (dubbed PDM-ENLOR) that overcomes these limitations by locating each shape model point individually using an ensemble of local regression models and appearance cues from selected model points. Our method first detects a set of reference points which were selected based on their saliency during training. For each model point, an ensemble of regressors is built. From the locations of the detected reference points, each regressor infers a candidate location for that model point using local geometric constraints, encoded by a point distribution model (PDM). The final location of that point is determined as a weighted linear combination, whose coefficients are learnt from the training data, of candidates proposed from its ensemble ’s component regressors. We use different subsets of reference points as explanatory variables for the component regressors to provide varying degrees of locality for the models in each ensemble. This helps our ensemble model to capture a larger range of shape variations as compared to a single PDM. We demonstrate the advantages of our method on the challenging problem of segmenting gene expression images of mouse brain.</p><p>2 0.71434832 <a title="321-lsi-2" href="./cvpr-2013-Correlation_Filters_for_Object_Alignment.html">96 cvpr-2013-Correlation Filters for Object Alignment</a></p>
<p>Author: Vishnu Naresh Boddeti, Takeo Kanade, B.V.K. Vijaya Kumar</p><p>Abstract: Alignment of 3D objects from 2D images is one of the most important and well studied problems in computer vision. A typical object alignment system consists of a landmark appearance model which is used to obtain an initial shape and a shape model which refines this initial shape by correcting the initialization errors. Since errors in landmark initialization from the appearance model propagate through the shape model, it is critical to have a robust landmark appearance model. While there has been much progress in designing sophisticated and robust shape models, there has been relatively less progress in designing robust landmark detection models. In thispaper wepresent an efficient and robust landmark detection model which is designed specifically to minimize localization errors thereby leading to state-of-the-art object alignment performance. We demonstrate the efficacy and speed of the proposed approach on the challenging task of multi-view car alignment.</p><p>3 0.71156025 <a title="321-lsi-3" href="./cvpr-2013-Active_Contours_with_Group_Similarity.html">33 cvpr-2013-Active Contours with Group Similarity</a></p>
<p>Author: Xiaowei Zhou, Xiaojie Huang, James S. Duncan, Weichuan Yu</p><p>Abstract: Active contours are widely used in image segmentation. To cope with missing or misleading features in images, researchers have introduced various ways to model the prior of shapes and use the prior to constrain active contours. However, the shape prior is usually learnt from a large set of annotated data, which is not always accessible in practice. Moreover, it is often doubted that the existing shapes in the training set will be sufficient to model the new instance in the testing image. In this paper, we propose to use the group similarity of object shapes in multiple images as a prior to aid segmentation, which can be interpreted as an unsupervised approach of shape prior modeling. We show that the rank of the matrix consisting of multiple shapes is a good measure of the group similarity of the shapes, and the nuclear norm minimization is a simple and effective way to impose the proposed constraint on existing active contour models. Moreover, we develop a fast algorithm to solve the proposed model by using the accelerated proximal method. Experiments using echocardiographic image sequences acquired from acute canine experiments demonstrate that the proposed method can consistently improve the performance of active contour models and increase the robustness against image defects such as missing boundaries.</p><p>4 0.70741051 <a title="321-lsi-4" href="./cvpr-2013-Accurate_and_Robust_Registration_of_Nonrigid_Surface_Using_Hierarchical_Statistical_Shape_Model.html">31 cvpr-2013-Accurate and Robust Registration of Nonrigid Surface Using Hierarchical Statistical Shape Model</a></p>
<p>Author: Hidekata Hontani, Yuto Tsunekawa, Yoshihide Sawada</p><p>Abstract: In this paper, we propose a new non-rigid robust registration method that registers a point distribution model (PDM) of a surface to given 3D images. The contributions of the paper are (1) a new hierarchical statistical shape model (SSM) of the surface that has better generalization ability is introduced, (2) the registration algorithm of the hierarchical SSM that can estimate the marginal posterior distribution of the surface location is proposed, and (3) the registration performance is improved by (3-1) robustly registering each local shape of the surface with the sparsity regularization and by (3-2) referring to the appearance between the neighboring model points in the likelihood computation. The SSM of a liver was constructed from a set of clinical CT images, and the performance of the proposed method was evaluated. Experimental results demonstrated that the proposed method outperformed some existing methods that use non-hierarchical SSMs.</p><p>5 0.70066088 <a title="321-lsi-5" href="./cvpr-2013-Improving_the_Visual_Comprehension_of_Point_Sets.html">218 cvpr-2013-Improving the Visual Comprehension of Point Sets</a></p>
<p>Author: Sagi Katz, Ayellet Tal</p><p>Abstract: Point sets are the standard output of many 3D scanning systems and depth cameras. Presenting the set of points as is, might “hide ” the prominent features of the object from which the points are sampled. Our goal is to reduce the number of points in a point set, for improving the visual comprehension from a given viewpoint. This is done by controlling the density of the reduced point set, so as to create bright regions (low density) and dark regions (high density), producing an effect of shading. This data reduction is achieved by leveraging a limitation of a solution to the classical problem of determining visibility from a viewpoint. In addition, we introduce a new dual problem, for determining visibility of a point from infinity, and show how a limitation of its solution can be leveraged in a similar way.</p><p>6 0.68964618 <a title="321-lsi-6" href="./cvpr-2013-Efficient_Computation_of_Shortest_Path-Concavity_for_3D_Meshes.html">141 cvpr-2013-Efficient Computation of Shortest Path-Concavity for 3D Meshes</a></p>
<p>7 0.68840319 <a title="321-lsi-7" href="./cvpr-2013-Robust_Discriminative_Response_Map_Fitting_with_Constrained_Local_Models.html">359 cvpr-2013-Robust Discriminative Response Map Fitting with Constrained Local Models</a></p>
<p>8 0.67754489 <a title="321-lsi-8" href="./cvpr-2013-Correspondence-Less_Non-rigid_Registration_of_Triangular_Surface_Meshes.html">97 cvpr-2013-Correspondence-Less Non-rigid Registration of Triangular Surface Meshes</a></p>
<p>9 0.66927028 <a title="321-lsi-9" href="./cvpr-2013-Multi-resolution_Shape_Analysis_via_Non-Euclidean_Wavelets%3A_Applications_to_Mesh_Segmentation_and_Surface_Alignment_Problems.html">297 cvpr-2013-Multi-resolution Shape Analysis via Non-Euclidean Wavelets: Applications to Mesh Segmentation and Surface Alignment Problems</a></p>
<p>10 0.66701436 <a title="321-lsi-10" href="./cvpr-2013-Dense_Object_Reconstruction_with_Semantic_Priors.html">110 cvpr-2013-Dense Object Reconstruction with Semantic Priors</a></p>
<p>11 0.65021473 <a title="321-lsi-11" href="./cvpr-2013-Keypoints_from_Symmetries_by_Wave_Propagation.html">240 cvpr-2013-Keypoints from Symmetries by Wave Propagation</a></p>
<p>12 0.64758414 <a title="321-lsi-12" href="./cvpr-2013-Axially_Symmetric_3D_Pots_Configuration_System_Using_Axis_of_Symmetry_and_Break_Curve.html">52 cvpr-2013-Axially Symmetric 3D Pots Configuration System Using Axis of Symmetry and Break Curve</a></p>
<p>13 0.63846934 <a title="321-lsi-13" href="./cvpr-2013-Robust_Canonical_Time_Warping_for_the_Alignment_of_Grossly_Corrupted_Sequences.html">358 cvpr-2013-Robust Canonical Time Warping for the Alignment of Grossly Corrupted Sequences</a></p>
<p>14 0.62811446 <a title="321-lsi-14" href="./cvpr-2013-Fast_Image_Super-Resolution_Based_on_In-Place_Example_Regression.html">166 cvpr-2013-Fast Image Super-Resolution Based on In-Place Example Regression</a></p>
<p>15 0.62676889 <a title="321-lsi-15" href="./cvpr-2013-Procrustean_Normal_Distribution_for_Non-rigid_Structure_from_Motion.html">341 cvpr-2013-Procrustean Normal Distribution for Non-rigid Structure from Motion</a></p>
<p>16 0.6261493 <a title="321-lsi-16" href="./cvpr-2013-Three-Dimensional_Bilateral_Symmetry_Plane_Estimation_in_the_Phase_Domain.html">432 cvpr-2013-Three-Dimensional Bilateral Symmetry Plane Estimation in the Phase Domain</a></p>
<p>17 0.62549418 <a title="321-lsi-17" href="./cvpr-2013-Expressive_Visual_Text-to-Speech_Using_Active_Appearance_Models.html">159 cvpr-2013-Expressive Visual Text-to-Speech Using Active Appearance Models</a></p>
<p>18 0.62523937 <a title="321-lsi-18" href="./cvpr-2013-Deep_Learning_Shape_Priors_for_Object_Segmentation.html">105 cvpr-2013-Deep Learning Shape Priors for Object Segmentation</a></p>
<p>19 0.61903197 <a title="321-lsi-19" href="./cvpr-2013-Tensor-Based_Human_Body_Modeling.html">426 cvpr-2013-Tensor-Based Human Body Modeling</a></p>
<p>20 0.61154908 <a title="321-lsi-20" href="./cvpr-2013-Adaptive_Compressed_Tomography_Sensing.html">35 cvpr-2013-Adaptive Compressed Tomography Sensing</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.108), (16, 0.025), (26, 0.037), (28, 0.02), (33, 0.276), (50, 0.262), (67, 0.052), (69, 0.075), (87, 0.058)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.83861005 <a title="321-lda-1" href="./cvpr-2013-A_Fast_Approximate_AIB_Algorithm_for_Distributional_Word_Clustering.html">8 cvpr-2013-A Fast Approximate AIB Algorithm for Distributional Word Clustering</a></p>
<p>Author: Lei Wang, Jianjia Zhang, Luping Zhou, Wanqing Li</p><p>Abstract: Distributional word clustering merges the words having similar probability distributions to attain reliable parameter estimation, compact classification models and even better classification performance. Agglomerative Information Bottleneck (AIB) is one of the typical word clustering algorithms and has been applied to both traditional text classification and recent image recognition. Although enjoying theoretical elegance, AIB has one main issue on its computational efficiency, especially when clustering a large number of words. Different from existing solutions to this issue, we analyze the characteristics of its objective function the loss of mutual information, and show that by merely using the ratio of word-class joint probabilities of each word, good candidate word pairs for merging can be easily identified. Based on this finding, we propose a fast approximate AIB algorithm and show that it can significantly improve the computational efficiency of AIB while well maintaining or even slightly increasing its classification performance. Experimental study on both text and image classification benchmark data sets shows that our algorithm can achieve more than 100 times speedup on large real data sets over the state-of-the-art method.</p><p>2 0.82798278 <a title="321-lda-2" href="./cvpr-2013-Subcategory-Aware_Object_Classification.html">417 cvpr-2013-Subcategory-Aware Object Classification</a></p>
<p>Author: Jian Dong, Wei Xia, Qiang Chen, Jianshi Feng, Zhongyang Huang, Shuicheng Yan</p><p>Abstract: In this paper, we introduce a subcategory-aware object classification framework to boost category level object classification performance. Motivated by the observation of considerable intra-class diversities and inter-class ambiguities in many current object classification datasets, we explicitly split data into subcategories by ambiguity guided subcategory mining. We then train an individual model for each subcategory rather than attempt to represent an object category with a monolithic model. More specifically, we build the instance affinity graph by combining both intraclass similarity and inter-class ambiguity. Visual subcategories, which correspond to the dense subgraphs, are detected by the graph shift algorithm and seamlessly integrated into the state-of-the-art detection assisted classification framework. Finally the responses from subcategory models are aggregated by subcategory-aware kernel regression. The extensive experiments over the PASCAL VOC 2007 and PASCAL VOC 2010 databases show the state-ofthe-art performance from our framework.</p><p>3 0.81934786 <a title="321-lda-3" href="./cvpr-2013-Large-Scale_Video_Summarization_Using_Web-Image_Priors.html">243 cvpr-2013-Large-Scale Video Summarization Using Web-Image Priors</a></p>
<p>Author: Aditya Khosla, Raffay Hamid, Chih-Jen Lin, Neel Sundaresan</p><p>Abstract: Given the enormous growth in user-generated videos, it is becoming increasingly important to be able to navigate them efficiently. As these videos are generally of poor quality, summarization methods designed for well-produced videos do not generalize to them. To address this challenge, we propose to use web-images as a prior to facilitate summarization of user-generated videos. Our main intuition is that people tend to take pictures of objects to capture them in a maximally informative way. Such images could therefore be used as prior information to summarize videos containing a similar set of objects. In this work, we apply our novel insight to develop a summarization algorithm that uses the web-image based prior information in an unsupervised manner. Moreover, to automatically evaluate summarization algorithms on a large scale, we propose a framework that relies on multiple summaries obtained through crowdsourcing. We demonstrate the effectiveness of our evaluation framework by comparing its performance to that ofmultiple human evaluators. Finally, wepresent resultsfor our framework tested on hundreds of user-generated videos.</p><p>same-paper 4 0.81629819 <a title="321-lda-4" href="./cvpr-2013-PDM-ENLOR%3A_Learning_Ensemble_of_Local_PDM-Based_Regressions.html">321 cvpr-2013-PDM-ENLOR: Learning Ensemble of Local PDM-Based Regressions</a></p>
<p>Author: Yen H. Le, Uday Kurkure, Ioannis A. Kakadiaris</p><p>Abstract: Statistical shape models, such as Active Shape Models (ASMs), sufferfrom their inability to represent a large range of variations of a complex shape and to account for the large errors in detection of model points. We propose a novel method (dubbed PDM-ENLOR) that overcomes these limitations by locating each shape model point individually using an ensemble of local regression models and appearance cues from selected model points. Our method first detects a set of reference points which were selected based on their saliency during training. For each model point, an ensemble of regressors is built. From the locations of the detected reference points, each regressor infers a candidate location for that model point using local geometric constraints, encoded by a point distribution model (PDM). The final location of that point is determined as a weighted linear combination, whose coefficients are learnt from the training data, of candidates proposed from its ensemble ’s component regressors. We use different subsets of reference points as explanatory variables for the component regressors to provide varying degrees of locality for the models in each ensemble. This helps our ensemble model to capture a larger range of shape variations as compared to a single PDM. We demonstrate the advantages of our method on the challenging problem of segmenting gene expression images of mouse brain.</p><p>5 0.8161341 <a title="321-lda-5" href="./cvpr-2013-Poselet_Key-Framing%3A_A_Model_for_Human_Activity_Recognition.html">336 cvpr-2013-Poselet Key-Framing: A Model for Human Activity Recognition</a></p>
<p>Author: Michalis Raptis, Leonid Sigal</p><p>Abstract: In this paper, we develop a new model for recognizing human actions. An action is modeled as a very sparse sequence of temporally local discriminative keyframes collections of partial key-poses of the actor(s), depicting key states in the action sequence. We cast the learning of keyframes in a max-margin discriminative framework, where we treat keyframes as latent variables. This allows us to (jointly) learn a set of most discriminative keyframes while also learning the local temporal context between them. Keyframes are encoded using a spatially-localizable poselet-like representation with HoG and BoW components learned from weak annotations; we rely on structured SVM formulation to align our components and minefor hard negatives to boost localization performance. This results in a model that supports spatio-temporal localization and is insensitive to dropped frames or partial observations. We show classification performance that is competitive with the state of the art on the benchmark UT-Interaction dataset and illustrate that our model outperforms prior methods in an on-line streaming setting.</p><p>6 0.77914363 <a title="321-lda-6" href="./cvpr-2013-Story-Driven_Summarization_for_Egocentric_Video.html">413 cvpr-2013-Story-Driven Summarization for Egocentric Video</a></p>
<p>7 0.764768 <a title="321-lda-7" href="./cvpr-2013-Bottom-Up_Segmentation_for_Top-Down_Detection.html">70 cvpr-2013-Bottom-Up Segmentation for Top-Down Detection</a></p>
<p>8 0.76459259 <a title="321-lda-8" href="./cvpr-2013-Understanding_Indoor_Scenes_Using_3D_Geometric_Phrases.html">446 cvpr-2013-Understanding Indoor Scenes Using 3D Geometric Phrases</a></p>
<p>9 0.76335901 <a title="321-lda-9" href="./cvpr-2013-Beyond_Point_Clouds%3A_Scene_Understanding_by_Reasoning_Geometry_and_Physics.html">61 cvpr-2013-Beyond Point Clouds: Scene Understanding by Reasoning Geometry and Physics</a></p>
<p>10 0.76207358 <a title="321-lda-10" href="./cvpr-2013-SLAM%2B%2B%3A_Simultaneous_Localisation_and_Mapping_at_the_Level_of_Objects.html">372 cvpr-2013-SLAM++: Simultaneous Localisation and Mapping at the Level of Objects</a></p>
<p>11 0.76185817 <a title="321-lda-11" href="./cvpr-2013-Understanding_Bayesian_Rooms_Using_Composite_3D_Object_Models.html">445 cvpr-2013-Understanding Bayesian Rooms Using Composite 3D Object Models</a></p>
<p>12 0.76179922 <a title="321-lda-12" href="./cvpr-2013-Incorporating_Structural_Alternatives_and_Sharing_into_Hierarchy_for_Multiclass_Object_Recognition_and_Detection.html">221 cvpr-2013-Incorporating Structural Alternatives and Sharing into Hierarchy for Multiclass Object Recognition and Detection</a></p>
<p>13 0.76174748 <a title="321-lda-13" href="./cvpr-2013-Learning_Structured_Hough_Voting_for_Joint_Object_Detection_and_Occlusion_Reasoning.html">256 cvpr-2013-Learning Structured Hough Voting for Joint Object Detection and Occlusion Reasoning</a></p>
<p>14 0.76141399 <a title="321-lda-14" href="./cvpr-2013-Discriminative_Re-ranking_of_Diverse_Segmentations.html">132 cvpr-2013-Discriminative Re-ranking of Diverse Segmentations</a></p>
<p>15 0.76102787 <a title="321-lda-15" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>16 0.75986522 <a title="321-lda-16" href="./cvpr-2013-Robust_Object_Co-detection.html">364 cvpr-2013-Robust Object Co-detection</a></p>
<p>17 0.75963312 <a title="321-lda-17" href="./cvpr-2013-Three-Dimensional_Bilateral_Symmetry_Plane_Estimation_in_the_Phase_Domain.html">432 cvpr-2013-Three-Dimensional Bilateral Symmetry Plane Estimation in the Phase Domain</a></p>
<p>18 0.7590276 <a title="321-lda-18" href="./cvpr-2013-Accurate_Localization_of_3D_Objects_from_RGB-D_Data_Using_Segmentation_Hypotheses.html">30 cvpr-2013-Accurate Localization of 3D Objects from RGB-D Data Using Segmentation Hypotheses</a></p>
<p>19 0.7589919 <a title="321-lda-19" href="./cvpr-2013-Adding_Unlabeled_Samples_to_Categories_by_Learned_Attributes.html">36 cvpr-2013-Adding Unlabeled Samples to Categories by Learned Attributes</a></p>
<p>20 0.7589711 <a title="321-lda-20" href="./cvpr-2013-Multi-agent_Event_Detection%3A_Localization_and_Role_Assignment.html">292 cvpr-2013-Multi-agent Event Detection: Localization and Role Assignment</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
