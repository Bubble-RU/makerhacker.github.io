<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>351 cvpr-2013-Recovering Line-Networks in Images by Junction-Point Processes</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-351" href="#">cvpr2013-351</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>351 cvpr-2013-Recovering Line-Networks in Images by Junction-Point Processes</h1>
<br/><p>Source: <a title="cvpr-2013-351-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Chai_Recovering_Line-Networks_in_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Dengfeng Chai, Wolfgang Förstner, Florent Lafarge</p><p>Abstract: The automatic extraction of line-networks from images is a well-known computer vision issue. Appearance and shape considerations have been deeply explored in the literature to improve accuracy in presence of occlusions, shadows, and a wide variety of irrelevant objects. However most existing works have ignored the structural aspect of the problem. We present an original method which provides structurally-coherent solutions. Contrary to the pixelbased and object-based methods, our result is a graph in which each node represents either a connection or an ending in the line-network. Based on stochastic geometry, we develop a new family of point processes consisting in sampling junction-points in the input image by using a Monte Carlo mechanism. The quality of a configuration is measured by a probability density which takes into account both image consistency and shape priors. Our experiments on a variety of problems illustrate the potential of our approach in terms of accuracy, flexibility and efficiency.</p><p>Reference: <a title="cvpr-2013-351-reference" href="../cvpr2013_reference/cvpr-2013-Recovering_Line-Networks_in_Images_by_Junction-Point_Processes_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Based on stochastic geometry, we develop a new family of point processes consisting in sampling junction-points in the input image by using a Monte Carlo mechanism. [sent-12, score-0.344]
</p><p>2 The quality of a configuration is measured by a probability density which takes into account both image consistency and shape priors. [sent-13, score-0.431]
</p><p>3 The pioneer works have been led on the well-known road extraction problem from remote sensed images [2, 11, 12]. [sent-17, score-0.59]
</p><p>4 Linenetwork extraction is also of interest in other problems like blood vessel detection from medical images [9, 10], or structure extraction from natural textures [8]. [sent-18, score-0.533]
</p><p>5 The network extraction is seen as a bi-  Figure1. [sent-25, score-0.318]
</p><p>6 OurJnctio-pintproces (midle) xploresthegraph  configurations in images in order to extract line-networks, here a road network (left) from an aerial image and blood vessels (right) from a retinal image. [sent-26, score-1.132]
</p><p>7 However, they are not adapted to recover the network structure as they ignore the notion of objects as shown in Fig. [sent-29, score-0.185]
</p><p>8 McKeown and Denlinger proposed road-surface texture correlation and road-edge to recover the road center, its width and local properties from aerial images [12]. [sent-31, score-0.555]
</p><p>9 Barzohar and Cooper proposed geometric-probabilistic models for road appearance, and applied dynamic programming to track roads [2]. [sent-32, score-0.485]
</p><p>10 merged perceptual grouping and segmentation techniques into a unified framework to segment road pixels from multi-sensor data[17]. [sent-34, score-0.341]
</p><p>11 [10] and Mnih and Hinton [14] proposed neural network based approaches. [sent-36, score-0.185]
</p><p>12 The former developed a 7-D vector composed of gray-level and invariant features for segmenting blood vessels, whereas the latter used a massive amount of training data to detect roads in aerial images. [sent-37, score-0.482]
</p><p>13 modeled road boundaries as active contours and exploited scale-space behavior to extract road boundaries [11]. [sent-40, score-0.732]
</p><p>14 This method is dedicated to road detection from remotely sensed images [18]. [sent-43, score-0.403]
</p><p>15 developed a phase field higher-order active contours for road network  Figure2. [sent-45, score-0.576]
</p><p>16 Thegraph111888999422  based models constitute a natural way to describe the line-network, contrary to pixel-based and object-based methods which do not take into account its structural aspect. [sent-47, score-0.165]
</p><p>17 The object-based models represent the line-networks as a configuration of geometric objects, typically line-segments. [sent-50, score-0.233]
</p><p>18 However, finding the optimal object configuration is a dif-  ficult task and the object connection is hard to obtain in practice as shown in Fig. [sent-52, score-0.245]
</p><p>19 The graph-based representation is the most natural way to address the problem as the network structure is guaranteed by construction. [sent-60, score-0.185]
</p><p>20 utilized road footprints as features which are tracked to detect intersections and extract the network from aerial images [6]. [sent-67, score-0.685]
</p><p>21 Note also that some works have been proposed to artificially generate road networks using procedural models, e. [sent-69, score-0.459]
</p><p>22 tree structures, whereas the latter provides a non-flexible representation with a constant edge length for road extraction only. [sent-82, score-0.474]
</p><p>23 u Erev as our configuration space is the set of the planar graphs embedded in the image support. [sent-86, score-0.31]
</p><p>24 lCyo noftrary to the conventional marked point processes used in the literature, e. [sent-90, score-0.353]
</p><p>25 [7, 8, 20], junction-point processes do not require complex geometric priors. [sent-92, score-0.239]
</p><p>26 Point processes describe an unordered set of points in a compact set F ⊂ Rk, where Rk is a ddseitm oefns piooninatsl space (ohmeprea, kt =et 2 F). [sent-102, score-0.199]
</p><p>27 Point processes can provide more complex realizations of points by using a probability density h(. [sent-117, score-0.397]
</p><p>28 which maximizes the probability density h, such that  ω? [sent-133, score-0.198]
</p><p>29 = argmaxh(ω)  (3)  is not a conventional optimization problem as the probability density h is multi-modal and defines in a configuration space having a variable dimension. [sent-134, score-0.443]
</p><p>30 A Monte Carlo sampler is usually required to find an approximation of ω? [sent-135, score-0.176]
</p><p>31 , and more precisely the Reversible Jump Markov Chain Monte Carlo (RJMCMC) sampler [5]. [sent-136, score-0.176]
</p><p>32 This algorithm consists of simulating a discrete Markov Chain (Xt)t∈N on the configuration space Ω, converging towards an invariant measure specified by h. [sent-137, score-0.193]
</p><p>33 At each iteration, the current configuration ω of the chain is locally perturbed to a configuration ω? [sent-138, score-0.46]
</p><p>34 is then accepted as the new state of the chain with a probability depending on the probability density variation between ω and ω? [sent-145, score-0.333]
</p><p>35 The kernel mixture must allow any configuration in Ω to be reached from any other configuration in a finite number of perturbations (irreductibility condition of the Markov chain), and each sub-kernel has to be reversible, i. [sent-154, score-0.495]
</p><p>36 The RJMCMC sampler is controlled by the relaxation parameter Tt, called the temperature, depending on time t and approaching zero as t tends to infinity. [sent-157, score-0.176]
</p><p>37 Point processes are attractive tools in vision as they allow the manipulation of parametric objects. [sent-160, score-0.199]
</p><p>38 As explained in Section 1, such an object-based technique, called marked point processes in the literature, is not adapted to address line-network extraction problems. [sent-174, score-0.434]
</p><p>39 We propose a new family of point processes able to manipulate planar graphs, called junction-point processes. [sent-175, score-0.354]
</p><p>40 , ), so that a point configuration is associated to a unique planar graph in F. [sent-184, score-0.391]
</p><p>41 We denote by Gx, the planar graph associated to the junction-point configuration x = {x1, . [sent-190, score-0.336]
</p><p>42 Contrary to the conventional marked point processes used in the literature, junction-point processes do not require complex geometric priors as a graph structure is  (w(i1)  wi(k)  111888999644  directly guaranteed by construction. [sent-198, score-0.675]
</p><p>43 4 illustrates the  advantages of junction-point processes for addressing linenetwork extraction problems. [sent-200, score-0.425]
</p><p>44 To the contrary, a junctionpoint process (right) brings structural guarantees as a unique planar graph is associated to each junction-point configuration. [sent-204, score-0.245]
</p><p>45 In order to be able to extract hierarchical line-networks, a line width is considered for each edge of a graph Gx. [sent-207, score-0.201]
</p><p>46 In a hierarchical network, one can assume that the widths of the lines can take only a few possible values. [sent-210, score-0.221]
</p><p>47 wi(k)  The probability density h extended to the junction-point configurations can be expressed as a product of a density hd measuring the consistency of a junction-point configuration with the data, and a density hp acting as a shape prior on the line-network h(x) ∝ hd(x)hp(x) (7) 3. [sent-212, score-0.942]
</p><p>48 We use these two conventional assumptions to design the data consistency density hd. [sent-216, score-0.229]
</p><p>49 Using histograms allow us to be relatively robust to the presence of clutter objects as small vehicles, trees and shadows for road extraction. [sent-218, score-0.382]
</p><p>50 By assuming the conditional independence of pixels in the image, one can expressed the global data density through a product of local likelihoods on each pixel p of the image hd(x)  ∝  ? [sent-219, score-0.178]
</p><p>51 These two criteria bring complementary information (see the blood vessels with different widths on the close-ups). [sent-222, score-0.443]
</p><p>52 The local likelihood at pixel p is expressed by taking into account both color similarity on the lines and discontinuity on the line borders. [sent-224, score-0.171]
</p><p>53 Shape priors The density hp is introduced to favor certain shapes of graphs. [sent-236, score-0.234]
</p><p>54 Three different criteria are taken into account to characterize the shape of a graph Gx from a junction-point configuration x : the graph connectivity, the edge orientation and the line width. [sent-237, score-0.422]
</p><p>55 The density hp can thus be formulated through a product of three densities by  hp(x) ∝ hconnectivity(x)·horientation(x)·hwidth(x)  (10)  Graph connectivity. [sent-238, score-0.234]
</p><p>56 The complexity of a graph can be analyzed through the graph connectivity. [sent-239, score-0.166]
</p><p>57 The graph connectivity density can nth-puso n bet expressed as  hconnectivity(x) =(kk? [sent-243, score-0.261]
</p><p>58 The relative orientation of the edges in a graph constitutes an important criterion to characterize graph shapes. [sent-256, score-0.166]
</p><p>59 1, the angles between the lines are significantly different between a road network and blood vessels. [sent-258, score-0.772]
</p><p>60 The line width density consists of favoring widths whose occurrences are the highest. [sent-286, score-0.409]
</p><p>61 Hw is estimated by counting the number of lines with different widths from the annotated image samples. [sent-303, score-0.221]
</p><p>62 1, is used to find an junction-point configuration close to the configuration maximizing the density h. [sent-307, score-0.523]
</p><p>63 Two kinds of proposition kernels are considered in the sampler: the birth and death kernel QBD, and the translation kernel QT. [sent-308, score-0.629]
</p><p>64 The uniform birth and death kernel allows a junction-point to be added or removed randomly in a configuration x, as illustrated in Fig. [sent-315, score-0.634]
</p><p>65 As detailed in [3], the proposition kernel ratio of a birth can be expressed by  QQBBDD((xx? [sent-318, score-0.379]
</p><p>66 ) is 111888999866  the number of junction-points in the proposed configuration x? [sent-322, score-0.193]
</p><p>67 pb) is the probability of choosing a death (resp. [sent-324, score-0.239]
</p><p>68 The translation kernel allows a junction-point to be moved without modifying the graph complexity (Fig. [sent-333, score-0.196]
</p><p>69 As the translation of a junction-point is proposed randomly, the proposition kernel ratio is simply given by  QQTT((xx? [sent-335, score-0.188]
</p><p>70 This proposition kernel is particularly interesting at the end of the sampling procedure to locally adjust the shape of the graph, as shown on Fig. [sent-338, score-0.185]
</p><p>71 At low temperature, tmhoe dceulrr (eUnt( junction-point configuration ienvgo. [sent-344, score-0.193]
</p><p>72 Flexibility The algorithm has been tested on a variety of linenetwork extraction problems ranging from road extraction from satellite and aerial images to blood vessel extraction from retinal images through more atypical problems as facade structure extraction (Fig. [sent-349, score-1.594]
</p><p>73 In particular, the data consistency term is able to distinguish a variety of lines with different colors and widths in images. [sent-352, score-0.303]
</p><p>74 In particular, the line-segments are not correctly connected (see red marks) and the network representation is not structured. [sent-362, score-0.185]
</p><p>75 Accuracy The accuracy of our algorithm has been evaluated on the road extraction problem from satellite images, and compared to existing methods [16, 21, 22]. [sent-365, score-0.52]
</p><p>76 Note that they do not produce the vectorization of roads contrary to our algorithm. [sent-369, score-0.221]
</p><p>77 9, the results obtained on hierarchical networks in which lines have different widths are convincing as few minor lines are omitted. [sent-372, score-0.358]
</p><p>78 1presents some quantitative comparisons with two line-segment point processes [8, 20]. [sent-374, score-0.254]
</p><p>79 Ouralgorithmisabletoextractbothregular(fistandsecondcolumns,fac deandtiles)andfre -form (three left columns, roads in a residential area, leaf and blood vessels in a retinal image) line-networks. [sent-377, score-0.547]
</p><p>80 Note in particular that the line-  networks with different widths are recovered with few omissions, eg blood vessels or leaf. [sent-378, score-0.513]
</p><p>81 For example, 270 seconds are necessary to obtain the road extraction result presented on Fig. [sent-389, score-0.474]
</p><p>82 We avoid this problem as each possible configuration is structured by construction. [sent-395, score-0.193]
</p><p>83 Quantitative comparison with different point processes from the Tiles image presented on Fig. [sent-397, score-0.254]
</p><p>84 limitations  Our model is based on the assumption that a network is represented by piecewise straight lines. [sent-405, score-0.185]
</p><p>85 The curved parts of a network can thus be more delicate to extract, at least computation times are increased as more junction-points are required to correctly recover these parts. [sent-406, score-0.231]
</p><p>86 Indeed, missing a junction-point penalizes all its adjacent lines whereas missing a line-segment is less disadvantageous in terms of network coverage. [sent-408, score-0.295]
</p><p>87 Based on a graph representation, every potential result has a coherent network structure and is vectorized contrary to the pixel-based and object-based methods. [sent-412, score-0.345]
</p><p>88 The algorithm is also flexible and can be applied to a variety of network extraction problems without tuning parameter models by trial and error. [sent-413, score-0.36]
</p><p>89 Finally the junction-  point processes have significant advantages compared to the conventional point processes as (i) they do not require the introduction of complex geometric priors, and (ii) their sampling is more stable. [sent-414, score-0.651]
</p><p>90 In future works, it would be interesting to improve the sampling procedure of the junction-point processes to reduce the computation time. [sent-415, score-0.25]
</p><p>91 Another interesting challenge is to adapt our approach to the networks of 3Dlines whose configuration spaces are significantly larger. [sent-417, score-0.263]
</p><p>92 In particular, the road connections are ideally recovered contrary to other algorithms (see close-ups). [sent-429, score-0.418]
</p><p>93 Automatic finding of main roads in aerial images by using geometric-stochastic models and estimation. [sent-442, score-0.303]
</p><p>94 Reversible jump markov chain monte carlo computation and bayesian model determination. [sent-467, score-0.23]
</p><p>95 Road network extraction and intersection detection from aerial images by tracking road footprints. [sent-475, score-0.818]
</p><p>96 Point process for unsupervised line network extraction in remote sensing. [sent-481, score-0.435]
</p><p>97 A review of 3d vessel lumen segmentation techniques: Models, features and extraction schemes. [sent-495, score-0.221]
</p><p>98 A new supervised method for blood vessel segmentation in retinal images by using gray-level and moment invariants-based features. [sent-502, score-0.381]
</p><p>99 Efficient monte carlo sampler for detecting parametric objects in large scenes. [sent-561, score-0.332]
</p><p>100 Extraction of urban road network using quickbird pan-sharpened multispectral and panchromatic imagery by performing edge-aided post-classification. [sent-566, score-0.526]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('road', 0.341), ('birth', 0.204), ('processes', 0.199), ('configuration', 0.193), ('network', 0.185), ('blood', 0.179), ('death', 0.178), ('sampler', 0.176), ('aerial', 0.159), ('widths', 0.154), ('roads', 0.144), ('density', 0.137), ('extraction', 0.133), ('lafarge', 0.124), ('retinal', 0.114), ('vessels', 0.11), ('hp', 0.097), ('rjmcmc', 0.096), ('lacoste', 0.093), ('linenetwork', 0.093), ('vessel', 0.088), ('graph', 0.083), ('dirichlet', 0.08), ('carlo', 0.08), ('gx', 0.078), ('temperature', 0.078), ('contrary', 0.077), ('poisson', 0.076), ('monte', 0.076), ('proposition', 0.075), ('chain', 0.074), ('networks', 0.07), ('hw', 0.069), ('lines', 0.067), ('hr', 0.066), ('hn', 0.066), ('reversible', 0.064), ('qm', 0.064), ('line', 0.063), ('barzohar', 0.062), ('hconnectivity', 0.062), ('horientation', 0.062), ('hwidth', 0.062), ('junctionpoint', 0.062), ('marin', 0.062), ('poullis', 0.062), ('prinet', 0.062), ('rochery', 0.062), ('sensed', 0.062), ('turetken', 0.062), ('probability', 0.061), ('planar', 0.06), ('kernel', 0.059), ('pk', 0.058), ('graphs', 0.057), ('hd', 0.055), ('width', 0.055), ('mckeown', 0.055), ('mayer', 0.055), ('isprs', 0.055), ('descombes', 0.055), ('point', 0.055), ('remote', 0.054), ('translation', 0.054), ('conventional', 0.052), ('connection', 0.052), ('wi', 0.051), ('sampling', 0.051), ('active', 0.05), ('perturbations', 0.05), ('procedural', 0.048), ('jermyn', 0.048), ('peng', 0.048), ('constitute', 0.048), ('marked', 0.047), ('xt', 0.046), ('considerations', 0.046), ('dir', 0.046), ('satellite', 0.046), ('mnih', 0.046), ('delicate', 0.046), ('parallelization', 0.044), ('florent', 0.044), ('tubular', 0.044), ('configurations', 0.044), ('adjacent', 0.043), ('wji', 0.042), ('variety', 0.042), ('directions', 0.042), ('shadows', 0.041), ('sequel', 0.041), ('zhejiang', 0.041), ('expressed', 0.041), ('consistency', 0.04), ('simulated', 0.04), ('geometric', 0.04), ('manipulate', 0.04), ('structural', 0.04), ('ik', 0.039), ('stochastic', 0.039)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="351-tfidf-1" href="./cvpr-2013-Recovering_Line-Networks_in_Images_by_Junction-Point_Processes.html">351 cvpr-2013-Recovering Line-Networks in Images by Junction-Point Processes</a></p>
<p>Author: Dengfeng Chai, Wolfgang Förstner, Florent Lafarge</p><p>Abstract: The automatic extraction of line-networks from images is a well-known computer vision issue. Appearance and shape considerations have been deeply explored in the literature to improve accuracy in presence of occlusions, shadows, and a wide variety of irrelevant objects. However most existing works have ignored the structural aspect of the problem. We present an original method which provides structurally-coherent solutions. Contrary to the pixelbased and object-based methods, our result is a graph in which each node represents either a connection or an ending in the line-network. Based on stochastic geometry, we develop a new family of point processes consisting in sampling junction-points in the input image by using a Monte Carlo mechanism. The quality of a configuration is measured by a probability density which takes into account both image consistency and shape priors. Our experiments on a variety of problems illustrate the potential of our approach in terms of accuracy, flexibility and efficiency.</p><p>2 0.38093823 <a title="351-tfidf-2" href="./cvpr-2013-A_Higher-Order_CRF_Model_for_Road_Network_Extraction.html">13 cvpr-2013-A Higher-Order CRF Model for Road Network Extraction</a></p>
<p>Author: Jan D. Wegner, Javier A. Montoya-Zegarra, Konrad Schindler</p><p>Abstract: The aim of this work is to extract the road network from aerial images. What makes the problem challenging is the complex structure of the prior: roads form a connected network of smooth, thin segments which meet at junctions and crossings. This type of a-priori knowledge is more difficult to turn into a tractable model than standard smoothness or co-occurrence assumptions. We develop a novel CRF formulation for road labeling, in which the prior is represented by higher-order cliques that connect sets of superpixels along straight line segments. These long-range cliques have asymmetric PN-potentials, which express a preference to assign all rather than just some of their constituent superpixels to the road class. Thus, the road likelihood is amplified for thin chains of superpixels, while the CRF is still amenable to optimization with graph cuts. Since the number of such cliques of arbitrary length is huge, we furthermorepropose a sampling scheme which concentrates on those cliques which are most relevant for the optimization. In experiments on two different databases the model significantly improves both the per-pixel accuracy and the topological correctness of the extracted roads, and outper- forms both a simple smoothness prior and heuristic rulebased road completion.</p><p>3 0.15810499 <a title="351-tfidf-3" href="./cvpr-2013-Reconstructing_Loopy_Curvilinear_Structures_Using_Integer_Programming.html">350 cvpr-2013-Reconstructing Loopy Curvilinear Structures Using Integer Programming</a></p>
<p>Author: Engin Türetken, Fethallah Benmansour, Bjoern Andres, Hanspeter Pfister, Pascal Fua</p><p>Abstract: We propose a novel approach to automated delineation of linear structures that form complex and potentially loopy networks. This is in contrast to earlier approaches that usually assume a tree topology for the networks. At the heart of our method is an Integer Programming formulation that allows us to find the global optimum of an objective function designed to allow cycles but penalize spurious junctions and early terminations. We demonstrate that it outperforms state-of-the-art techniques on a wide range of datasets.</p><p>4 0.11667362 <a title="351-tfidf-4" href="./cvpr-2013-Cross-View_Image_Geolocalization.html">99 cvpr-2013-Cross-View Image Geolocalization</a></p>
<p>Author: Tsung-Yi Lin, Serge Belongie, James Hays</p><p>Abstract: The recent availability oflarge amounts ofgeotagged imagery has inspired a number of data driven solutions to the image geolocalization problem. Existing approaches predict the location of a query image by matching it to a database of georeferenced photographs. While there are many geotagged images available on photo sharing and street view sites, most are clustered around landmarks and urban areas. The vast majority of the Earth’s land area has no ground level reference photos available, which limits the applicability of all existing image geolocalization methods. On the other hand, there is no shortage of visual and geographic data that densely covers the Earth we examine overhead imagery and land cover survey data but the relationship between this data and ground level query photographs is complex. In this paper, we introduce a cross-view feature translation approach to greatly extend the reach of image geolocalization methods. We can often localize a query even if it has no corresponding ground– – level images in the database. A key idea is to learn the relationship between ground level appearance and overhead appearance and land cover attributes from sparsely available geotagged ground-level images. We perform experiments over a 1600 km2 region containing a variety of scenes and land cover types. For each query, our algorithm produces a probability density over the region of interest.</p><p>5 0.11492571 <a title="351-tfidf-5" href="./cvpr-2013-Graph-Based_Optimization_with_Tubularity_Markov_Tree_for_3D_Vessel_Segmentation.html">190 cvpr-2013-Graph-Based Optimization with Tubularity Markov Tree for 3D Vessel Segmentation</a></p>
<p>Author: Ning Zhu, Albert C.S. Chung</p><p>Abstract: In this paper, we propose a graph-based method for 3D vessel tree structure segmentation based on a new tubularity Markov tree model ( TMT), which works as both new energy function and graph construction method. With the help of power-watershed implementation [7], a global optimal segmentation can be obtained with low computational cost. Different with other graph-based vessel segmentation methods, the proposed method does not depend on any skeleton and ROI extraction method. The classical issues of the graph-based methods, such as shrinking bias and sensitivity to seed point location, can be solved with the proposed method thanks to vessel data fidelity obtained with TMT. The proposed method is compared with some classical graph-based image segmentation methods and two up-to-date 3D vessel segmentation methods, and is demonstrated to be more accurate than these methods for 3D vessel tree segmentation. Although the segmentation is done without ROI extraction, the computational cost for the proposed method is low (within 20 seconds for 256*256*144 image).</p><p>6 0.10179023 <a title="351-tfidf-6" href="./cvpr-2013-Multi-target_Tracking_by_Lagrangian_Relaxation_to_Min-cost_Network_Flow.html">300 cvpr-2013-Multi-target Tracking by Lagrangian Relaxation to Min-cost Network Flow</a></p>
<p>7 0.088973835 <a title="351-tfidf-7" href="./cvpr-2013-Fast_Energy_Minimization_Using_Learned_State_Filters.html">165 cvpr-2013-Fast Energy Minimization Using Learned State Filters</a></p>
<p>8 0.082181126 <a title="351-tfidf-8" href="./cvpr-2013-Active_Contours_with_Group_Similarity.html">33 cvpr-2013-Active Contours with Group Similarity</a></p>
<p>9 0.078531422 <a title="351-tfidf-9" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<p>10 0.078355692 <a title="351-tfidf-10" href="./cvpr-2013-Detecting_Changes_in_3D_Structure_of_a_Scene_from_Multi-view_Images_Captured_by_a_Vehicle-Mounted_Camera.html">117 cvpr-2013-Detecting Changes in 3D Structure of a Scene from Multi-view Images Captured by a Vehicle-Mounted Camera</a></p>
<p>11 0.078306004 <a title="351-tfidf-11" href="./cvpr-2013-Discriminative_Brain_Effective_Connectivity_Analysis_for_Alzheimer%27s_Disease%3A_A_Kernel_Learning_Approach_upon_Sparse_Gaussian_Bayesian_Network.html">129 cvpr-2013-Discriminative Brain Effective Connectivity Analysis for Alzheimer's Disease: A Kernel Learning Approach upon Sparse Gaussian Bayesian Network</a></p>
<p>12 0.077562377 <a title="351-tfidf-12" href="./cvpr-2013-Incorporating_User_Interaction_and_Topological_Constraints_within_Contour_Completion_via_Discrete_Calculus.html">222 cvpr-2013-Incorporating User Interaction and Topological Constraints within Contour Completion via Discrete Calculus</a></p>
<p>13 0.076574624 <a title="351-tfidf-13" href="./cvpr-2013-On_a_Link_Between_Kernel_Mean_Maps_and_Fraunhofer_Diffraction%2C_with_an_Application_to_Super-Resolution_Beyond_the_Diffraction_Limit.html">312 cvpr-2013-On a Link Between Kernel Mean Maps and Fraunhofer Diffraction, with an Application to Super-Resolution Beyond the Diffraction Limit</a></p>
<p>14 0.071053132 <a title="351-tfidf-14" href="./cvpr-2013-Understanding_Indoor_Scenes_Using_3D_Geometric_Phrases.html">446 cvpr-2013-Understanding Indoor Scenes Using 3D Geometric Phrases</a></p>
<p>15 0.069817781 <a title="351-tfidf-15" href="./cvpr-2013-Mesh_Based_Semantic_Modelling_for_Indoor_and_Outdoor_Scenes.html">284 cvpr-2013-Mesh Based Semantic Modelling for Indoor and Outdoor Scenes</a></p>
<p>16 0.06940791 <a title="351-tfidf-16" href="./cvpr-2013-Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking.html">285 cvpr-2013-Minimum Uncertainty Gap for Robust Visual Tracking</a></p>
<p>17 0.067363687 <a title="351-tfidf-17" href="./cvpr-2013-Hypergraphs_for_Joint_Multi-view_Reconstruction_and_Multi-object_Tracking.html">209 cvpr-2013-Hypergraphs for Joint Multi-view Reconstruction and Multi-object Tracking</a></p>
<p>18 0.064008683 <a title="351-tfidf-18" href="./cvpr-2013-Graph_Matching_with_Anchor_Nodes%3A_A_Learning_Approach.html">192 cvpr-2013-Graph Matching with Anchor Nodes: A Learning Approach</a></p>
<p>19 0.063807033 <a title="351-tfidf-19" href="./cvpr-2013-Fully-Connected_CRFs_with_Non-Parametric_Pairwise_Potential.html">180 cvpr-2013-Fully-Connected CRFs with Non-Parametric Pairwise Potential</a></p>
<p>20 0.063610673 <a title="351-tfidf-20" href="./cvpr-2013-Sampling_Strategies_for_Real-Time_Action_Recognition.html">378 cvpr-2013-Sampling Strategies for Real-Time Action Recognition</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.19), (1, 0.036), (2, 0.003), (3, 0.002), (4, 0.074), (5, 0.006), (6, 0.008), (7, 0.006), (8, -0.036), (9, 0.017), (10, 0.067), (11, 0.008), (12, -0.068), (13, -0.007), (14, -0.026), (15, 0.014), (16, 0.006), (17, 0.045), (18, 0.124), (19, 0.007), (20, 0.004), (21, 0.06), (22, -0.086), (23, 0.053), (24, -0.004), (25, 0.049), (26, 0.04), (27, -0.032), (28, -0.066), (29, 0.138), (30, -0.074), (31, -0.017), (32, 0.021), (33, 0.08), (34, -0.125), (35, 0.029), (36, 0.042), (37, 0.06), (38, 0.029), (39, 0.041), (40, 0.018), (41, -0.007), (42, -0.011), (43, -0.052), (44, -0.173), (45, 0.011), (46, -0.028), (47, -0.064), (48, -0.222), (49, 0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92078769 <a title="351-lsi-1" href="./cvpr-2013-Recovering_Line-Networks_in_Images_by_Junction-Point_Processes.html">351 cvpr-2013-Recovering Line-Networks in Images by Junction-Point Processes</a></p>
<p>Author: Dengfeng Chai, Wolfgang Förstner, Florent Lafarge</p><p>Abstract: The automatic extraction of line-networks from images is a well-known computer vision issue. Appearance and shape considerations have been deeply explored in the literature to improve accuracy in presence of occlusions, shadows, and a wide variety of irrelevant objects. However most existing works have ignored the structural aspect of the problem. We present an original method which provides structurally-coherent solutions. Contrary to the pixelbased and object-based methods, our result is a graph in which each node represents either a connection or an ending in the line-network. Based on stochastic geometry, we develop a new family of point processes consisting in sampling junction-points in the input image by using a Monte Carlo mechanism. The quality of a configuration is measured by a probability density which takes into account both image consistency and shape priors. Our experiments on a variety of problems illustrate the potential of our approach in terms of accuracy, flexibility and efficiency.</p><p>2 0.77104902 <a title="351-lsi-2" href="./cvpr-2013-Reconstructing_Loopy_Curvilinear_Structures_Using_Integer_Programming.html">350 cvpr-2013-Reconstructing Loopy Curvilinear Structures Using Integer Programming</a></p>
<p>Author: Engin Türetken, Fethallah Benmansour, Bjoern Andres, Hanspeter Pfister, Pascal Fua</p><p>Abstract: We propose a novel approach to automated delineation of linear structures that form complex and potentially loopy networks. This is in contrast to earlier approaches that usually assume a tree topology for the networks. At the heart of our method is an Integer Programming formulation that allows us to find the global optimum of an objective function designed to allow cycles but penalize spurious junctions and early terminations. We demonstrate that it outperforms state-of-the-art techniques on a wide range of datasets.</p><p>3 0.76331335 <a title="351-lsi-3" href="./cvpr-2013-A_Higher-Order_CRF_Model_for_Road_Network_Extraction.html">13 cvpr-2013-A Higher-Order CRF Model for Road Network Extraction</a></p>
<p>Author: Jan D. Wegner, Javier A. Montoya-Zegarra, Konrad Schindler</p><p>Abstract: The aim of this work is to extract the road network from aerial images. What makes the problem challenging is the complex structure of the prior: roads form a connected network of smooth, thin segments which meet at junctions and crossings. This type of a-priori knowledge is more difficult to turn into a tractable model than standard smoothness or co-occurrence assumptions. We develop a novel CRF formulation for road labeling, in which the prior is represented by higher-order cliques that connect sets of superpixels along straight line segments. These long-range cliques have asymmetric PN-potentials, which express a preference to assign all rather than just some of their constituent superpixels to the road class. Thus, the road likelihood is amplified for thin chains of superpixels, while the CRF is still amenable to optimization with graph cuts. Since the number of such cliques of arbitrary length is huge, we furthermorepropose a sampling scheme which concentrates on those cliques which are most relevant for the optimization. In experiments on two different databases the model significantly improves both the per-pixel accuracy and the topological correctness of the extracted roads, and outper- forms both a simple smoothness prior and heuristic rulebased road completion.</p><p>4 0.62021065 <a title="351-lsi-4" href="./cvpr-2013-Lost%21_Leveraging_the_Crowd_for_Probabilistic_Visual_Self-Localization.html">274 cvpr-2013-Lost! Leveraging the Crowd for Probabilistic Visual Self-Localization</a></p>
<p>Author: Marcus A. Brubaker, Andreas Geiger, Raquel Urtasun</p><p>Abstract: In this paper we propose an affordable solution to selflocalization, which utilizes visual odometry and road maps as the only inputs. To this end, we present a probabilistic model as well as an efficient approximate inference algorithm, which is able to utilize distributed computation to meet the real-time requirements of autonomous systems. Because of the probabilistic nature of the model we are able to cope with uncertainty due to noisy visual odometry and inherent ambiguities in the map (e.g., in a Manhattan world). By exploiting freely available, community developed maps and visual odometry measurements, we are able to localize a vehicle up to 3m after only a few seconds of driving on maps which contain more than 2,150km of drivable roads.</p><p>5 0.57229513 <a title="351-lsi-5" href="./cvpr-2013-A_Statistical_Model_for_Recreational_Trails_in_Aerial_Images.html">26 cvpr-2013-A Statistical Model for Recreational Trails in Aerial Images</a></p>
<p>Author: Andrew Predoehl, Scott Morris, Kobus Barnard</p><p>Abstract: unkown-abstract</p><p>6 0.54792988 <a title="351-lsi-6" href="./cvpr-2013-Graph-Based_Optimization_with_Tubularity_Markov_Tree_for_3D_Vessel_Segmentation.html">190 cvpr-2013-Graph-Based Optimization with Tubularity Markov Tree for 3D Vessel Segmentation</a></p>
<p>7 0.54482383 <a title="351-lsi-7" href="./cvpr-2013-City-Scale_Change_Detection_in_Cadastral_3D_Models_Using_Images.html">81 cvpr-2013-City-Scale Change Detection in Cadastral 3D Models Using Images</a></p>
<p>8 0.54199553 <a title="351-lsi-8" href="./cvpr-2013-Manhattan_Junction_Catalogue_for_Spatial_Reasoning_of_Indoor_Scenes.html">278 cvpr-2013-Manhattan Junction Catalogue for Spatial Reasoning of Indoor Scenes</a></p>
<p>9 0.5327189 <a title="351-lsi-9" href="./cvpr-2013-Information_Consensus_for_Distributed_Multi-target_Tracking.html">224 cvpr-2013-Information Consensus for Distributed Multi-target Tracking</a></p>
<p>10 0.52910882 <a title="351-lsi-10" href="./cvpr-2013-Adaptive_Compressed_Tomography_Sensing.html">35 cvpr-2013-Adaptive Compressed Tomography Sensing</a></p>
<p>11 0.51313776 <a title="351-lsi-11" href="./cvpr-2013-Fast_Energy_Minimization_Using_Learned_State_Filters.html">165 cvpr-2013-Fast Energy Minimization Using Learned State Filters</a></p>
<p>12 0.50517124 <a title="351-lsi-12" href="./cvpr-2013-Discriminative_Brain_Effective_Connectivity_Analysis_for_Alzheimer%27s_Disease%3A_A_Kernel_Learning_Approach_upon_Sparse_Gaussian_Bayesian_Network.html">129 cvpr-2013-Discriminative Brain Effective Connectivity Analysis for Alzheimer's Disease: A Kernel Learning Approach upon Sparse Gaussian Bayesian Network</a></p>
<p>13 0.47975004 <a title="351-lsi-13" href="./cvpr-2013-Image_Understanding_from_Experts%27_Eyes_by_Modeling_Perceptual_Skill_of_Diagnostic_Reasoning_Processes.html">214 cvpr-2013-Image Understanding from Experts' Eyes by Modeling Perceptual Skill of Diagnostic Reasoning Processes</a></p>
<p>14 0.47919992 <a title="351-lsi-14" href="./cvpr-2013-Computing_Diffeomorphic_Paths_for_Large_Motion_Interpolation.html">90 cvpr-2013-Computing Diffeomorphic Paths for Large Motion Interpolation</a></p>
<p>15 0.46850774 <a title="351-lsi-15" href="./cvpr-2013-Multi-target_Tracking_by_Lagrangian_Relaxation_to_Min-cost_Network_Flow.html">300 cvpr-2013-Multi-target Tracking by Lagrangian Relaxation to Min-cost Network Flow</a></p>
<p>16 0.46818057 <a title="351-lsi-16" href="./cvpr-2013-Learning_Separable_Filters.html">255 cvpr-2013-Learning Separable Filters</a></p>
<p>17 0.45793766 <a title="351-lsi-17" href="./cvpr-2013-Maximum_Cohesive_Grid_of_Superpixels_for_Fast_Object_Localization.html">280 cvpr-2013-Maximum Cohesive Grid of Superpixels for Fast Object Localization</a></p>
<p>18 0.45211557 <a title="351-lsi-18" href="./cvpr-2013-A_Global_Approach_for_the_Detection_of_Vanishing_Points_and_Mutually_Orthogonal_Vanishing_Directions.html">12 cvpr-2013-A Global Approach for the Detection of Vanishing Points and Mutually Orthogonal Vanishing Directions</a></p>
<p>19 0.45195508 <a title="351-lsi-19" href="./cvpr-2013-A_Genetic_Algorithm-Based_Solver_for_Very_Large_Jigsaw_Puzzles.html">11 cvpr-2013-A Genetic Algorithm-Based Solver for Very Large Jigsaw Puzzles</a></p>
<p>20 0.45098299 <a title="351-lsi-20" href="./cvpr-2013-Fully-Connected_CRFs_with_Non-Parametric_Pairwise_Potential.html">180 cvpr-2013-Fully-Connected CRFs with Non-Parametric Pairwise Potential</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.017), (10, 0.103), (16, 0.029), (26, 0.095), (28, 0.016), (33, 0.278), (67, 0.036), (69, 0.037), (81, 0.213), (87, 0.082), (96, 0.014)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.89282519 <a title="351-lda-1" href="./cvpr-2013-The_Generalized_Laplacian_Distance_and_Its_Applications_for_Visual_Matching.html">429 cvpr-2013-The Generalized Laplacian Distance and Its Applications for Visual Matching</a></p>
<p>Author: Elhanan Elboer, Michael Werman, Yacov Hel-Or</p><p>Abstract: The graph Laplacian operator, which originated in spectral graph theory, is commonly used for learning applications such as spectral clustering and embedding. In this paper we explore the Laplacian distance, a distance function related to the graph Laplacian, and use it for visual search. We show that previous techniques such as Matching by Tone Mapping (MTM) are particular cases of the Laplacian distance. Generalizing the Laplacian distance results in distance measures which are tolerant to various visual distortions. A novel algorithm based on linear decomposition makes it possible to compute these generalized distances efficiently. The proposed approach is demonstrated for tone mapping invariant, outlier robust and multimodal template matching.</p><p>same-paper 2 0.86596787 <a title="351-lda-2" href="./cvpr-2013-Recovering_Line-Networks_in_Images_by_Junction-Point_Processes.html">351 cvpr-2013-Recovering Line-Networks in Images by Junction-Point Processes</a></p>
<p>Author: Dengfeng Chai, Wolfgang Förstner, Florent Lafarge</p><p>Abstract: The automatic extraction of line-networks from images is a well-known computer vision issue. Appearance and shape considerations have been deeply explored in the literature to improve accuracy in presence of occlusions, shadows, and a wide variety of irrelevant objects. However most existing works have ignored the structural aspect of the problem. We present an original method which provides structurally-coherent solutions. Contrary to the pixelbased and object-based methods, our result is a graph in which each node represents either a connection or an ending in the line-network. Based on stochastic geometry, we develop a new family of point processes consisting in sampling junction-points in the input image by using a Monte Carlo mechanism. The quality of a configuration is measured by a probability density which takes into account both image consistency and shape priors. Our experiments on a variety of problems illustrate the potential of our approach in terms of accuracy, flexibility and efficiency.</p><p>3 0.82730353 <a title="351-lda-3" href="./cvpr-2013-Harvesting_Mid-level_Visual_Concepts_from_Large-Scale_Internet_Images.html">200 cvpr-2013-Harvesting Mid-level Visual Concepts from Large-Scale Internet Images</a></p>
<p>Author: Quannan Li, Jiajun Wu, Zhuowen Tu</p><p>Abstract: Obtaining effective mid-level representations has become an increasingly important task in computer vision. In this paper, we propose a fully automatic algorithm which harvests visual concepts from a large number of Internet images (more than a quarter of a million) using text-based queries. Existing approaches to visual concept learning from Internet images either rely on strong supervision with detailed manual annotations or learn image-level classifiers only. Here, we take the advantage of having massive wellorganized Google and Bing image data; visual concepts (around 14, 000) are automatically exploited from images using word-based queries. Using the learned visual concepts, we show state-of-the-art performances on a variety of benchmark datasets, which demonstrate the effectiveness of the learned mid-level representations: being able to generalize well to general natural images. Our method shows significant improvement over the competing systems in image classification, including those with strong supervision.</p><p>4 0.82428271 <a title="351-lda-4" href="./cvpr-2013-Occlusion_Patterns_for_Object_Class_Detection.html">311 cvpr-2013-Occlusion Patterns for Object Class Detection</a></p>
<p>Author: Bojan Pepikj, Michael Stark, Peter Gehler, Bernt Schiele</p><p>Abstract: Despite the success of recent object class recognition systems, the long-standing problem of partial occlusion remains a major challenge, and a principled solution is yet to be found. In this paper we leave the beaten path of methods that treat occlusion as just another source of noise instead, we include the occluder itself into the modelling, by mining distinctive, reoccurring occlusion patterns from annotated training data. These patterns are then used as training data for dedicated detectors of varying sophistication. In particular, we evaluate and compare models that range from standard object class detectors to hierarchical, part-based representations of occluder/occludee pairs. In an extensive evaluation we derive insights that can aid further developments in tackling the occlusion challenge. –</p><p>5 0.82352442 <a title="351-lda-5" href="./cvpr-2013-Exemplar-Based_Face_Parsing.html">152 cvpr-2013-Exemplar-Based Face Parsing</a></p>
<p>Author: Brandon M. Smith, Li Zhang, Jonathan Brandt, Zhe Lin, Jianchao Yang</p><p>Abstract: In this work, we propose an exemplar-based face image segmentation algorithm. We take inspiration from previous works on image parsing for general scenes. Our approach assumes a database of exemplar face images, each of which is associated with a hand-labeled segmentation map. Given a test image, our algorithm first selects a subset of exemplar images from the database, Our algorithm then computes a nonrigid warp for each exemplar image to align it with the test image. Finally, we propagate labels from the exemplar images to the test image in a pixel-wise manner, using trained weights to modulate and combine label maps from different exemplars. We evaluate our method on two challenging datasets and compare with two face parsing algorithms and a general scene parsing algorithm. We also compare our segmentation results with contour-based face alignment results; that is, we first run the alignment algorithms to extract contour points and then derive segments from the contours. Our algorithm compares favorably with all previous works on all datasets evaluated.</p><p>6 0.82149953 <a title="351-lda-6" href="./cvpr-2013-Tracking_People_and_Their_Objects.html">440 cvpr-2013-Tracking People and Their Objects</a></p>
<p>7 0.8194471 <a title="351-lda-7" href="./cvpr-2013-What_Object_Motion_Reveals_about_Shape_with_Unknown_BRDF_and_Lighting.html">465 cvpr-2013-What Object Motion Reveals about Shape with Unknown BRDF and Lighting</a></p>
<p>8 0.81889683 <a title="351-lda-8" href="./cvpr-2013-Compressible_Motion_Fields.html">88 cvpr-2013-Compressible Motion Fields</a></p>
<p>9 0.81837636 <a title="351-lda-9" href="./cvpr-2013-Relative_Hidden_Markov_Models_for_Evaluating_Motion_Skill.html">353 cvpr-2013-Relative Hidden Markov Models for Evaluating Motion Skill</a></p>
<p>10 0.81751645 <a title="351-lda-10" href="./cvpr-2013-Maximum_Cohesive_Grid_of_Superpixels_for_Fast_Object_Localization.html">280 cvpr-2013-Maximum Cohesive Grid of Superpixels for Fast Object Localization</a></p>
<p>11 0.81708103 <a title="351-lda-11" href="./cvpr-2013-A_New_Perspective_on_Uncalibrated_Photometric_Stereo.html">21 cvpr-2013-A New Perspective on Uncalibrated Photometric Stereo</a></p>
<p>12 0.81624615 <a title="351-lda-12" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<p>13 0.81528068 <a title="351-lda-13" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<p>14 0.81475478 <a title="351-lda-14" href="./cvpr-2013-Correlation_Filters_for_Object_Alignment.html">96 cvpr-2013-Correlation Filters for Object Alignment</a></p>
<p>15 0.81448656 <a title="351-lda-15" href="./cvpr-2013-Robust_Monocular_Epipolar_Flow_Estimation.html">362 cvpr-2013-Robust Monocular Epipolar Flow Estimation</a></p>
<p>16 0.81446958 <a title="351-lda-16" href="./cvpr-2013-Determining_Motion_Directly_from_Normal_Flows_Upon_the_Use_of_a_Spherical_Eye_Platform.html">124 cvpr-2013-Determining Motion Directly from Normal Flows Upon the Use of a Spherical Eye Platform</a></p>
<p>17 0.81409919 <a title="351-lda-17" href="./cvpr-2013-Shading-Based_Shape_Refinement_of_RGB-D_Images.html">394 cvpr-2013-Shading-Based Shape Refinement of RGB-D Images</a></p>
<p>18 0.81372136 <a title="351-lda-18" href="./cvpr-2013-Optimal_Geometric_Fitting_under_the_Truncated_L2-Norm.html">317 cvpr-2013-Optimal Geometric Fitting under the Truncated L2-Norm</a></p>
<p>19 0.81359184 <a title="351-lda-19" href="./cvpr-2013-Label_Propagation_from_ImageNet_to_3D_Point_Clouds.html">242 cvpr-2013-Label Propagation from ImageNet to 3D Point Clouds</a></p>
<p>20 0.81352085 <a title="351-lda-20" href="./cvpr-2013-Templateless_Quasi-rigid_Shape_Modeling_with_Implicit_Loop-Closure.html">424 cvpr-2013-Templateless Quasi-rigid Shape Modeling with Implicit Loop-Closure</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
