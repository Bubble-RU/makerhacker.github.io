<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>296 cvpr-2013-Multi-level Discriminative Dictionary Learning towards Hierarchical Visual Categorization</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-296" href="#">cvpr2013-296</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>296 cvpr-2013-Multi-level Discriminative Dictionary Learning towards Hierarchical Visual Categorization</h1>
<br/><p>Source: <a title="cvpr-2013-296-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Shen_Multi-level_Discriminative_Dictionary_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Li Shen, Shuhui Wang, Gang Sun, Shuqiang Jiang, Qingming Huang</p><p>Abstract: For the task of visual categorization, the learning model is expected to be endowed with discriminative visual feature representation and flexibilities in processing many categories. Many existing approaches are designed based on a flat category structure, or rely on a set of pre-computed visual features, hence may not be appreciated for dealing with large numbers of categories. In this paper, we propose a novel dictionary learning method by taking advantage of hierarchical category correlation. For each internode of the hierarchical category structure, a discriminative dictionary and a set of classification models are learnt for visual categorization, and the dictionaries in different layers are learnt to exploit the discriminative visual properties of different granularity. Moreover, the dictionaries in lower levels also inherit the dictionary of ancestor nodes, so that categories in lower levels are described with multi-scale visual information using our dictionary learning approach. Experiments on ImageNet object data subset and SUN397 scene dataset demonstrate that our approach achieves promising performance on data with large numbers of classes compared with some state-of-the-art methods, and is more efficient in processing large numbers of categories.</p><p>Reference: <a title="cvpr-2013-296-reference" href="../cvpr2013_reference/cvpr-2013-Multi-level_Discriminative_Dictionary_Learning_towards_Hierarchical_Visual_Categorization_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 In this paper, we propose a novel dictionary learning method by taking advantage of hierarchical category correlation. [sent-15, score-0.87]
</p><p>2 For each internode of the hierarchical category structure, a discriminative dictionary and a set of classification models are learnt for visual categorization, and the dictionaries in different layers are learnt to exploit the discriminative visual properties of different granularity. [sent-16, score-2.042]
</p><p>3 Moreover, the dictionaries in lower levels also inherit the dictionary of ancestor nodes, so that categories in lower levels are described with multi-scale visual information using our dictionary learning approach. [sent-17, score-2.295]
</p><p>4 In learning stage, D0 denotes the dictionary used by first level nodes (V1,1 ,V1,2 and V1,3). [sent-27, score-0.894]
</p><p>5 The corresponding representation z1,1 is used for classi-  fication model learning among the child nodes (V2,1 and V2,2). [sent-29, score-0.344]
</p><p>6 The dictionary applied to quantize the local descriptors is often obtained by some clustering method, such as k-means. [sent-32, score-0.695]
</p><p>7 In recent work [28, 18], sparse coding based dictionary learning has reported more promising results. [sent-33, score-0.85]
</p><p>8 Furthermore, it is shown in [17, 2] that the dictionaries via supervised learning are beneficial for performance improvement by encoding more discriminative information into the representations. [sent-36, score-0.53]
</p><p>9 However, when the number of categories is large, these methods suffer from considerable time overhead during the supervised dictionary learning and predicting stages. [sent-37, score-0.876]
</p><p>10 The categories are usually organized in the form of tree-structured hierarchy [6] and are treated as the leaf nodes in the bottom of the tree. [sent-39, score-0.456]
</p><p>11 Each internode corresponds to one hyper-category that is composed of a group ofcategories with semantic relevance or visual similarity, so that the structure reflects the hierarchical correlation among categories. [sent-40, score-0.394]
</p><p>12 Firstly, due to diversified inter-correlation among different layers, the sibling nodes in higher levels are less related than the ones in lower levels, thus the discrimination between nodes in higher levels is easier. [sent-42, score-0.669]
</p><p>13 Finally, lower level categories are supposed to possess the general properties from the higher level categories and additional classspecific details. [sent-48, score-0.327]
</p><p>14 The learnt visual dictionary set and feature representations make better use of the category correlation encoded by the hierarchy. [sent-52, score-0.945]
</p><p>15 As the features exacted from larger receptive fields encode  more complex and specific patterns, the dictionaries learnt in lower layers are designed to encode the descriptors at larger scale. [sent-53, score-0.913]
</p><p>16 Given the structure, we learn one discriminative dictionary and a set of discriminative models for each hyper-category (internode). [sent-54, score-0.798]
</p><p>17 Besides, our learnt dictionaries in lower levels consist of additional part inherited from ancestor nodes, so that categories in lower levels are described with multi-scale visual information. [sent-55, score-1.284]
</p><p>18 For internal node V1,1, the corresponding dictionary D1,1 consists of two parts D0 and D0 represents the dictionary inherited  D10,1. [sent-58, score-1.606]
</p><p>19 The specific dictionary and the class models of nodes V2,1 and V2,2 are learnt in a discriminative formulation simultaneously. [sent-60, score-1.094]
</p><p>20 The dictionaries learnt at different layers encode different scale information. [sent-65, score-0.707]
</p><p>21 Moreover, each dictionary consists of the general part inherited from upper layers and the specific part learnt from its child nodes. [sent-66, score-1.335]
</p><p>22 Compared with unsupervised dictionary [28] or class−  specific dictionary [17, 2], our learnt dictionaries capture the information of multi-level visual (hyper-)categories in a more effective way. [sent-67, score-1.955]
</p><p>23 On training stage, the number of dictionaries is equal with the number of internodes in the tree, which is far less than the number of categories. [sent-69, score-0.451]
</p><p>24 Related Work Current dictionary learning approaches can be categorized into two main types: unsupervised and supervised dictionary learning. [sent-76, score-1.462]
</p><p>25 In the field of unsupervised dictionary learning, the dictionary is optimized only based on the reconstruction error of the signals [18]. [sent-77, score-1.394]
</p><p>26 [28] propose to learn a unique unsupervised dictionary by sparse coding for classification and achieve impressive results. [sent-79, score-0.877]
</p><p>27 [12] employ a tree-structured sparsity to encode the dependencies between dictionary atoms. [sent-84, score-0.706]
</p><p>28 The dictionaries learnt in a supervised way have stronger discriminative power. [sent-87, score-0.611]
</p><p>29 For example, label information is fed in Fisher discrimination criterion or logistic regression model for dictionary learning [17, 29]. [sent-88, score-0.782]
</p><p>30 A shared dictionary or multiple class-specific dictionaries can be obtained by su1L denotes the number of levels 333888224 pervised learning. [sent-89, score-1.154]
</p><p>31 [2] adapt supervised dictionary learning to local features, which achieves better discriminative power than features extracted by [28]. [sent-91, score-0.815]
</p><p>32 [34] propose to learn multiple specific dictionaries and a global dictionary shared by all categories. [sent-93, score-1.099]
</p><p>33 When the number of categories is large, the advantage of hierarchical structure over flat structure emerges in terms of efficiency and accuracy [22, 33, 3]. [sent-95, score-0.331]
</p><p>34 As one of the coding strategies, local coding aims to learn a set of anchor points (dictionary) to encode signals incorporating with locality constraint, which ensures that similar signals tend to have similar codes. [sent-113, score-0.328]
</p><p>35 As the supervised learning approach has been shown beneficial to dictionary learning, in this paper we propose to introduce a supervised formulation for local coding. [sent-114, score-0.837]
</p><p>36 Given a dictionary Db, ˆ xi,p can be reconstructed by:  ,  αi,p( ˆxi,p,Db)  =  argmin12? [sent-119, score-0.655]
</p><p>37 Due to the fact that max pooling is not differentiable, average pooling is more appropriate to task-driven dictionary learning [2]. [sent-148, score-0.877]
</p><p>38 iTtso jointly lse {adrn the dictionary a bned b colaunssdiefidca btiyo unn mito ldel, the model can be formulated as following:  ,  Wmi,Dn  2λ? [sent-160, score-0.655]
</p><p>39 Multi-Scale Dictionary Learning Given the tree structure, our goal is to learn a set of discriminative dictionaries for discrimination among the sibling nodes. [sent-183, score-0.652]
</p><p>40 Based on the above analysis, we propose to learn the dictionaries in different layers to encode the descriptors of different scales. [sent-188, score-0.611]
</p><p>41 Let T denote the set of leaf nodes (categories) in the tree, T¯ denote the set of internodes which represent the hyper-  categories, and  T+  = T ∪ T¯ denote the set containing all  333888335 the nodes in the tree. [sent-189, score-0.479]
</p><p>42 We need to learn a single dictionary Dt shared by its child nodes. [sent-200, score-0.831]
</p><p>43 For the child node v of node t, we define a response function f(∗). [sent-201, score-0.376]
</p><p>44 The dictionaries in different layers are learnt to discover the valuable properties with different scales. [sent-212, score-0.682]
</p><p>45 Multi-Level Dictionary chical Representation  Learning for Hierar-  Given the hierarchical structure, we learn a set of discriminative dictionaries to encode the descriptors of different scales. [sent-215, score-0.624]
</p><p>46 The dictionary learnt on an internode consists of the specific properties for discriminating the children nodes, and these properties are supposed to be embodied in their children nodes. [sent-216, score-1.103]
</p><p>47 Therefore, the dictionaries in the higher levels can be regarded as the sharing properties for the groups of correlated categories in lower levels, and they can be inherited by the child nodes through the tree path. [sent-217, score-1.202]
</p><p>48 1, the corresponding D1,1 is expressed as D1,1 = [D0, D0 denotes the inherited dictionary from V0,  D10,1]. [sent-219, score-0.889]
</p><p>49 and D10,1 denotes  the specific dictionary learnt in node V1,1. [sent-220, score-1.008]
</p><p>50 Then, for the child node V2,1, the response  function of sample i(Eq. [sent-223, score-0.276]
</p><p>51 The dictionary and classifier learning based on hierarchical structure can be revised from Eq. [sent-225, score-0.852]
</p><p>52 2F+ loss(W,D+,X,Y )  (9)  D+  where represents the set of dictionaries in the tree and W denotes the classifier matrix embedded in the structure. [sent-230, score-0.457]
</p><p>53 In this algorithm, the information propagates via multilevel dictionaries in a top-down fashion. [sent-233, score-0.383]
</p><p>54 For the nodes in lower layers, the learnt dictionaries are desired to encode more specific information. [sent-234, score-0.792]
</p><p>55 On the other hand, the inherited dictionaries from ancestors consist of more general information, based on which the response z should be used to minimize the classification loss. [sent-235, score-0.659]
</p><p>56 For an internode t, the learning process of dictionary and class models is done iteratively, which consists of two steps: 1) Coding: by fixing the dictionary Dt, we compute the coefficients and generate the features zt of the samples. [sent-242, score-1.544]
</p><p>57 2) Dictionary and class models updating: based on the features computed by previous dictionary, we optimize the class models and dictionary simultaneously. [sent-243, score-0.701]
</p><p>58 Particularly, the specific part of the dictionary needs to be updated rather than the inherited part. [sent-244, score-0.899]
</p><p>59 In fact, the inherited dictionary has been optimal in the higher layers, it should be inherited without any update by the classification models of the descendant nodes in lower levels. [sent-245, score-1.261]
</p><p>60 The dictionary updating is a loss minimization problem through the learnt features z. [sent-247, score-0.878]
</p><p>61 As the loss function is differentiable with respect to dictionary and class model parameters, the gradient of specific dictionary Dt of internode t and class model of its child node v 333888446 can be computed as following:  where:  βiΛ,p=? [sent-248, score-1.835]
</p><p>62 After learning the dictionary and discriminative class models, we can directly use the dictionary to calculate the visual feature z, and use w for classification. [sent-258, score-1.487]
</p><p>63 As the max pooling is helpful to enhance the performance, we then test the dictionary with max spatial pooling [2]. [sent-259, score-0.821]
</p><p>64 For dictionary Dt, D¯t denotes the dictionaries inherited from ancestor nodes and  the specific part Dt0is initialized by unsupervised dictionary  initDl . [sent-263, score-2.234]
</p><p>65 For each iteration, only the specific part Dt0 is updated, and the Wt is the weight of the representation which is generated via the whole dictionary Dt. [sent-264, score-0.703]
</p><p>66 Due to the fact that inherited dictionary is not updated, the corresponding representations can be saved and directly used for classification in lower levels. [sent-265, score-0.948]
</p><p>67 Experiments In this section, we evaluate our dictionary learning approach on two databases: SUN397 [27] and ImageNet subset [7]. [sent-267, score-0.711]
</p><p>68 Since some nodes in the hierarchy connect to more than one parent nodes, we change the original structure by  choosing one parent node for them. [sent-275, score-0.396]
</p><p>69 Considering the time complexity, we choose the median dictionary sizes (256, 256, 5 12) for the specific part of the dictionaries in different layers in our method. [sent-281, score-1.192]
</p><p>70 Thus, the dictionary sizes in different layers of the hierarchy are 256, 512 and 1024 in our experiments. [sent-282, score-0.92]
</p><p>71 The learnt specific dictionary sizes in different layers are all set as 512 in our experiments. [sent-294, score-1.019]
</p><p>72 For our method, it consists of three basis components: hierarchical structure, multinomial logistic classification, dictionary learning. [sent-295, score-0.811]
</p><p>73 Based on the task-independent dictionary learnt by Sparse Coding, this method trains the linear SVM with one-vs-all strategy. [sent-298, score-0.846]
</p><p>74 Based on the taskindependent dictionary learnt by Sparse Coding, we use the similar empirical loss in [33] and train the SVM with the hierarchical structure by SVM-struct package [13]. [sent-301, score-1.019]
</p><p>75 The method trains the SVM with one-vs-all strategy, and learn a dictionary for each category. [sent-304, score-0.71]
</p><p>76 With respect to the training time, we accumulate the  time of three steps: dictionary learning, mid-level feature computation and model learning. [sent-309, score-0.655]
</p><p>77 For the unsupervised dictionary learning methods (Bi-ScSPM and H-ScSPM), the time cost in dictionary learning is trivial compared with the other two steps. [sent-310, score-1.47]
</p><p>78 The number of dictionaries we need to learn is equal with the number of internodes and L − 1 features are computed for each image. [sent-314, score-0.482]
</p><p>79 For the supervised dictionary learning, the time cost lies on the number of dictionaries. [sent-337, score-0.703]
</p><p>80 However, the descriptors need to be computed through all the dictionaries in Bi-TDDL method, so the time complexity increases drastically. [sent-341, score-0.38]
</p><p>81 Even so, our method also outperforms H-ScSPM with the help of hierarchical dictionary learning. [sent-350, score-0.761]
</p><p>82 We can clearly see the promising results of MLDDL on hierarchical error, especially on the top-1 error rate, since our proposed method fully optimizes both the multilevel dictionaries and the discriminative models towards the 333888668  TAaMHb-lLgeSocD-4ri. [sent-354, score-0.569]
</p><p>83 Result Analysis and Discussion To investigate the relation among the dictionaries in different layers, we use another strategy (named as ML-DDL0) for dictionary learning in the hierarchical structure. [sent-366, score-1.18]
</p><p>84 In ML-DDL0, the dictionaries in lower levels do not inherit the dictionary from ancestor nodes, in other words, the dictionaries in different layers only have the specific parts which are learnt by discrimination models. [sent-367, score-2.037]
</p><p>85 On the other  hand, the nodes in lower levels are so visually similar that they are much harder to be distinguished compared with nodes in higher levels. [sent-371, score-0.45]
</p><p>86 However, the comparison between and H-ScSPM shows that the problem could be relieved by the benefit from dictionary learning. [sent-372, score-0.655]
</p><p>87 Furthermore, the effect of the dictionary inheritance has also been revealed by the performance difference between ML-DDL We can see that the accuracy has been improved in the lower layers, especially at the leaf nodes. [sent-373, score-0.84]
</p><p>88 This implies that the properties captured from the ancestor nodes are of great importance for child nodes. [sent-374, score-0.4]
</p><p>89 Different from the sharing model based on pre-computed features (sibling child nodes inherit the common information from ancestor nodes) [22], these properties can be selected and weighted via class models in child nodes, thus have more flexibilities. [sent-375, score-0.632]
</p><p>90 Due to dictionary inheritance in the hierarchy, the image representations in lower levels integrate all the useful information of multiple scales, which are beneficial to promote model capacity. [sent-376, score-0.916]
</p><p>91 Given a test image, its local descriptors are encoded based on the specific dictionary in each layer, and the reconstruction coefficients regarded as the response of the dictionary are pooled to represent the image. [sent-381, score-1.477]
</p><p>92 The dictionaries learnt in each layer consist of atoms which are biased to  ML-DDL0  and ML-DDL0. [sent-382, score-0.644]
</p><p>93 The points with different colors denote the locations having large values of the response using the learnt dictionaries in different levels. [sent-386, score-0.563]
</p><p>94 It shows that the dictionaries in different layers consist of specific atoms, thus the different part of visual information are highlighted at different layers. [sent-387, score-0.618]
</p><p>95 Compared with binary dictionary learning with flat structure (Bi-TDDL), the recognition accuracy of a lot of categories has been improved by ML-DDL. [sent-388, score-0.901]
</p><p>96 Besides, the misclassification in higher levels spreads through the path and finally incurs the misclassification of the child nodes. [sent-412, score-0.329]
</p><p>97 Therefore, the visual coherence of the hierarchy is directly related to the result, and finding a better tree structure is very important for visual classification. [sent-413, score-0.314]
</p><p>98 Conclusion In this paper, we present a hierarchical dictionary learning approach. [sent-415, score-0.817]
</p><p>99 The dictionaries in different layers are learnt  to capture the discriminative information of different scales. [sent-416, score-0.712]
</p><p>100 Besides, the inheritance of dictionaries in the hierarchical structure enables the categories in lower levels to exploit the features of multiple scales. [sent-417, score-0.801]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('dictionary', 0.655), ('dictionaries', 0.34), ('inherited', 0.196), ('learnt', 0.167), ('internode', 0.155), ('layers', 0.149), ('nodes', 0.145), ('child', 0.12), ('categories', 0.117), ('hierarchy', 0.116), ('internodes', 0.111), ('ancestor', 0.109), ('hierarchical', 0.106), ('node', 0.1), ('levels', 0.096), ('coding', 0.087), ('pooling', 0.083), ('tree', 0.079), ('sibling', 0.078), ('leaf', 0.078), ('inheritance', 0.066), ('layer', 0.063), ('dt', 0.058), ('discriminative', 0.056), ('loss', 0.056), ('response', 0.056), ('learning', 0.056), ('imagenet', 0.054), ('category', 0.053), ('db', 0.052), ('encode', 0.051), ('supervised', 0.048), ('unsupervised', 0.048), ('specific', 0.048), ('inherit', 0.047), ('discrimination', 0.045), ('xi', 0.045), ('mlddl', 0.044), ('xwpu', 0.044), ('categorization', 0.044), ('misclassification', 0.044), ('kb', 0.043), ('multilevel', 0.043), ('sharing', 0.042), ('visual', 0.042), ('besides', 0.041), ('lower', 0.041), ('cas', 0.04), ('descriptors', 0.04), ('zit', 0.039), ('consist', 0.039), ('flat', 0.038), ('denotes', 0.038), ('signals', 0.036), ('atoms', 0.035), ('structure', 0.035), ('semantic', 0.033), ('china', 0.033), ('jenatton', 0.033), ('scspm', 0.031), ('ranganath', 0.031), ('mairal', 0.031), ('learn', 0.031), ('wv', 0.03), ('classifying', 0.03), ('beneficial', 0.03), ('beijing', 0.029), ('shen', 0.028), ('sparse', 0.028), ('representations', 0.028), ('classification', 0.028), ('boureau', 0.027), ('grosse', 0.027), ('yu', 0.027), ('supposed', 0.026), ('receptive', 0.026), ('properties', 0.026), ('logistic', 0.026), ('shared', 0.025), ('path', 0.025), ('icml', 0.024), ('bach', 0.024), ('ix', 0.024), ('fv', 0.024), ('xc', 0.024), ('belonging', 0.024), ('multinomial', 0.024), ('trains', 0.024), ('promising', 0.024), ('zi', 0.024), ('multiclass', 0.024), ('numbers', 0.023), ('brought', 0.023), ('pooled', 0.023), ('class', 0.023), ('torralba', 0.023), ('stage', 0.023), ('among', 0.023), ('similarity', 0.023), ('distinguished', 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000006 <a title="296-tfidf-1" href="./cvpr-2013-Multi-level_Discriminative_Dictionary_Learning_towards_Hierarchical_Visual_Categorization.html">296 cvpr-2013-Multi-level Discriminative Dictionary Learning towards Hierarchical Visual Categorization</a></p>
<p>Author: Li Shen, Shuhui Wang, Gang Sun, Shuqiang Jiang, Qingming Huang</p><p>Abstract: For the task of visual categorization, the learning model is expected to be endowed with discriminative visual feature representation and flexibilities in processing many categories. Many existing approaches are designed based on a flat category structure, or rely on a set of pre-computed visual features, hence may not be appreciated for dealing with large numbers of categories. In this paper, we propose a novel dictionary learning method by taking advantage of hierarchical category correlation. For each internode of the hierarchical category structure, a discriminative dictionary and a set of classification models are learnt for visual categorization, and the dictionaries in different layers are learnt to exploit the discriminative visual properties of different granularity. Moreover, the dictionaries in lower levels also inherit the dictionary of ancestor nodes, so that categories in lower levels are described with multi-scale visual information using our dictionary learning approach. Experiments on ImageNet object data subset and SUN397 scene dataset demonstrate that our approach achieves promising performance on data with large numbers of classes compared with some state-of-the-art methods, and is more efficient in processing large numbers of categories.</p><p>2 0.56104934 <a title="296-tfidf-2" href="./cvpr-2013-Separable_Dictionary_Learning.html">392 cvpr-2013-Separable Dictionary Learning</a></p>
<p>Author: Simon Hawe, Matthias Seibert, Martin Kleinsteuber</p><p>Abstract: Many techniques in computer vision, machine learning, and statistics rely on the fact that a signal of interest admits a sparse representation over some dictionary. Dictionaries are either available analytically, or can be learned from a suitable training set. While analytic dictionaries permit to capture the global structure of a signal and allow a fast implementation, learned dictionaries often perform better in applications as they are more adapted to the considered class of signals. In imagery, unfortunately, the numerical burden for (i) learning a dictionary and for (ii) employing the dictionary for reconstruction tasks only allows to deal with relatively small image patches that only capture local image information. The approach presented in this paper aims at overcoming these drawbacks by allowing a separable structure on the dictionary throughout the learning process. On the one hand, this permits larger patch-sizes for the learning phase, on the other hand, the dictionary is applied efficiently in reconstruction tasks. The learning procedure is based on optimizing over a product of spheres which updates the dictionary as a whole, thus enforces basic dictionary proper- , ties such as mutual coherence explicitly during the learning procedure. In the special case where no separable structure is enforced, our method competes with state-of-the-art dictionary learning methods like K-SVD.</p><p>3 0.52501142 <a title="296-tfidf-3" href="./cvpr-2013-Beta_Process_Joint_Dictionary_Learning_for_Coupled_Feature_Spaces_with_Application_to_Single_Image_Super-Resolution.html">58 cvpr-2013-Beta Process Joint Dictionary Learning for Coupled Feature Spaces with Application to Single Image Super-Resolution</a></p>
<p>Author: Li He, Hairong Qi, Russell Zaretzki</p><p>Abstract: This paper addresses the problem of learning overcomplete dictionaries for the coupled feature spaces, where the learned dictionaries also reflect the relationship between the two spaces. A Bayesian method using a beta process prior is applied to learn the over-complete dictionaries. Compared to previous couple feature spaces dictionary learning algorithms, our algorithm not only provides dictionaries that customized to each feature space, but also adds more consistent and accurate mapping between the two feature spaces. This is due to the unique property of the beta process model that the sparse representation can be decomposed to values and dictionary atom indicators. The proposed algorithm is able to learn sparse representations that correspond to the same dictionary atoms with the same sparsity but different values in coupled feature spaces, thus bringing consistent and accurate mapping between coupled feature spaces. Another advantage of the proposed method is that the number of dictionary atoms and their relative importance may be inferred non-parametrically. We compare the proposed approach to several state-of-the-art dictionary learning methods super-resolution. tionaries learned resolution results ods. by applying this method to single image The experimental results show that dicby our method produces the best supercompared to other state-of-the-art meth-</p><p>4 0.46738502 <a title="296-tfidf-4" href="./cvpr-2013-Generalized_Domain-Adaptive_Dictionaries.html">185 cvpr-2013-Generalized Domain-Adaptive Dictionaries</a></p>
<p>Author: Sumit Shekhar, Vishal M. Patel, Hien V. Nguyen, Rama Chellappa</p><p>Abstract: Data-driven dictionaries have produced state-of-the-art results in various classification tasks. However, when the target data has a different distribution than the source data, the learned sparse representation may not be optimal. In this paper, we investigate if it is possible to optimally represent both source and target by a common dictionary. Specifically, we describe a technique which jointly learns projections of data in the two domains, and a latent dictionary which can succinctly represent both the domains in the projected low-dimensional space. An efficient optimization technique is presented, which can be easily kernelized and extended to multiple domains. The algorithm is modified to learn a common discriminative dictionary, which can be further used for classification. The proposed approach does not require any explicit correspondence between the source and target domains, and shows good results even when there are only a few labels available in the target domain. Various recognition experiments show that the methodperforms onparor better than competitive stateof-the-art methods.</p><p>5 0.46041566 <a title="296-tfidf-5" href="./cvpr-2013-Learning_Structured_Low-Rank_Representations_for_Image_Classification.html">257 cvpr-2013-Learning Structured Low-Rank Representations for Image Classification</a></p>
<p>Author: Yangmuzi Zhang, Zhuolin Jiang, Larry S. Davis</p><p>Abstract: An approach to learn a structured low-rank representation for image classification is presented. We use a supervised learning method to construct a discriminative and reconstructive dictionary. By introducing an ideal regularization term, we perform low-rank matrix recovery for contaminated training data from all categories simultaneously without losing structural information. A discriminative low-rank representation for images with respect to the constructed dictionary is obtained. With semantic structure information and strong identification capability, this representation is good for classification tasks even using a simple linear multi-classifier. Experimental results demonstrate the effectiveness of our approach.</p><p>6 0.43130642 <a title="296-tfidf-6" href="./cvpr-2013-Online_Robust_Dictionary_Learning.html">315 cvpr-2013-Online Robust Dictionary Learning</a></p>
<p>7 0.42742762 <a title="296-tfidf-7" href="./cvpr-2013-Block_and_Group_Regularized_Sparse_Modeling_for_Dictionary_Learning.html">66 cvpr-2013-Block and Group Regularized Sparse Modeling for Dictionary Learning</a></p>
<p>8 0.34622842 <a title="296-tfidf-8" href="./cvpr-2013-Tag_Taxonomy_Aware_Dictionary_Learning_for_Region_Tagging.html">422 cvpr-2013-Tag Taxonomy Aware Dictionary Learning for Region Tagging</a></p>
<p>9 0.3363649 <a title="296-tfidf-9" href="./cvpr-2013-Dictionary_Learning_from_Ambiguously_Labeled_Data.html">125 cvpr-2013-Dictionary Learning from Ambiguously Labeled Data</a></p>
<p>10 0.31167445 <a title="296-tfidf-10" href="./cvpr-2013-A_Bayesian_Approach_to_Multimodal_Visual_Dictionary_Learning.html">5 cvpr-2013-A Bayesian Approach to Multimodal Visual Dictionary Learning</a></p>
<p>11 0.23690537 <a title="296-tfidf-11" href="./cvpr-2013-Subspace_Interpolation_via_Dictionary_Learning_for_Unsupervised_Domain_Adaptation.html">419 cvpr-2013-Subspace Interpolation via Dictionary Learning for Unsupervised Domain Adaptation</a></p>
<p>12 0.23058996 <a title="296-tfidf-12" href="./cvpr-2013-Multi-task_Sparse_Learning_with_Beta_Process_Prior_for_Action_Recognition.html">302 cvpr-2013-Multi-task Sparse Learning with Beta Process Prior for Action Recognition</a></p>
<p>13 0.20852858 <a title="296-tfidf-13" href="./cvpr-2013-Histograms_of_Sparse_Codes_for_Object_Detection.html">204 cvpr-2013-Histograms of Sparse Codes for Object Detection</a></p>
<p>14 0.20029026 <a title="296-tfidf-14" href="./cvpr-2013-Probabilistic_Label_Trees_for_Efficient_Large_Scale_Image_Classification.html">340 cvpr-2013-Probabilistic Label Trees for Efficient Large Scale Image Classification</a></p>
<p>15 0.16036566 <a title="296-tfidf-15" href="./cvpr-2013-In_Defense_of_Sparsity_Based_Face_Recognition.html">220 cvpr-2013-In Defense of Sparsity Based Face Recognition</a></p>
<p>16 0.15521538 <a title="296-tfidf-16" href="./cvpr-2013-Supervised_Kernel_Descriptors_for_Visual_Recognition.html">421 cvpr-2013-Supervised Kernel Descriptors for Visual Recognition</a></p>
<p>17 0.15520079 <a title="296-tfidf-17" href="./cvpr-2013-Single-Sample_Face_Recognition_with_Image_Corruption_and_Misalignment_via_Sparse_Illumination_Transfer.html">399 cvpr-2013-Single-Sample Face Recognition with Image Corruption and Misalignment via Sparse Illumination Transfer</a></p>
<p>18 0.14438312 <a title="296-tfidf-18" href="./cvpr-2013-From_Local_Similarity_to_Global_Coding%3A_An_Application_to_Image_Classification.html">178 cvpr-2013-From Local Similarity to Global Coding: An Application to Image Classification</a></p>
<p>19 0.12646672 <a title="296-tfidf-19" href="./cvpr-2013-Semi-supervised_Learning_of_Feature_Hierarchies_for_Object_Detection_in_a_Video.html">388 cvpr-2013-Semi-supervised Learning of Feature Hierarchies for Object Detection in a Video</a></p>
<p>20 0.12187497 <a title="296-tfidf-20" href="./cvpr-2013-Pedestrian_Detection_with_Unsupervised_Multi-stage_Feature_Learning.html">328 cvpr-2013-Pedestrian Detection with Unsupervised Multi-stage Feature Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.238), (1, -0.267), (2, -0.353), (3, 0.415), (4, -0.126), (5, -0.144), (6, 0.164), (7, 0.236), (8, -0.066), (9, 0.131), (10, -0.003), (11, 0.101), (12, 0.018), (13, 0.043), (14, 0.05), (15, 0.022), (16, 0.002), (17, 0.055), (18, 0.019), (19, -0.034), (20, 0.017), (21, 0.023), (22, 0.014), (23, 0.016), (24, -0.021), (25, 0.025), (26, 0.029), (27, 0.014), (28, -0.039), (29, 0.11), (30, -0.04), (31, -0.007), (32, 0.0), (33, 0.015), (34, 0.078), (35, -0.001), (36, 0.023), (37, -0.034), (38, 0.036), (39, -0.026), (40, 0.01), (41, 0.017), (42, -0.031), (43, 0.064), (44, 0.021), (45, 0.004), (46, -0.043), (47, 0.0), (48, 0.023), (49, -0.003)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96368074 <a title="296-lsi-1" href="./cvpr-2013-Multi-level_Discriminative_Dictionary_Learning_towards_Hierarchical_Visual_Categorization.html">296 cvpr-2013-Multi-level Discriminative Dictionary Learning towards Hierarchical Visual Categorization</a></p>
<p>Author: Li Shen, Shuhui Wang, Gang Sun, Shuqiang Jiang, Qingming Huang</p><p>Abstract: For the task of visual categorization, the learning model is expected to be endowed with discriminative visual feature representation and flexibilities in processing many categories. Many existing approaches are designed based on a flat category structure, or rely on a set of pre-computed visual features, hence may not be appreciated for dealing with large numbers of categories. In this paper, we propose a novel dictionary learning method by taking advantage of hierarchical category correlation. For each internode of the hierarchical category structure, a discriminative dictionary and a set of classification models are learnt for visual categorization, and the dictionaries in different layers are learnt to exploit the discriminative visual properties of different granularity. Moreover, the dictionaries in lower levels also inherit the dictionary of ancestor nodes, so that categories in lower levels are described with multi-scale visual information using our dictionary learning approach. Experiments on ImageNet object data subset and SUN397 scene dataset demonstrate that our approach achieves promising performance on data with large numbers of classes compared with some state-of-the-art methods, and is more efficient in processing large numbers of categories.</p><p>2 0.95267373 <a title="296-lsi-2" href="./cvpr-2013-Separable_Dictionary_Learning.html">392 cvpr-2013-Separable Dictionary Learning</a></p>
<p>Author: Simon Hawe, Matthias Seibert, Martin Kleinsteuber</p><p>Abstract: Many techniques in computer vision, machine learning, and statistics rely on the fact that a signal of interest admits a sparse representation over some dictionary. Dictionaries are either available analytically, or can be learned from a suitable training set. While analytic dictionaries permit to capture the global structure of a signal and allow a fast implementation, learned dictionaries often perform better in applications as they are more adapted to the considered class of signals. In imagery, unfortunately, the numerical burden for (i) learning a dictionary and for (ii) employing the dictionary for reconstruction tasks only allows to deal with relatively small image patches that only capture local image information. The approach presented in this paper aims at overcoming these drawbacks by allowing a separable structure on the dictionary throughout the learning process. On the one hand, this permits larger patch-sizes for the learning phase, on the other hand, the dictionary is applied efficiently in reconstruction tasks. The learning procedure is based on optimizing over a product of spheres which updates the dictionary as a whole, thus enforces basic dictionary proper- , ties such as mutual coherence explicitly during the learning procedure. In the special case where no separable structure is enforced, our method competes with state-of-the-art dictionary learning methods like K-SVD.</p><p>3 0.94236785 <a title="296-lsi-3" href="./cvpr-2013-Beta_Process_Joint_Dictionary_Learning_for_Coupled_Feature_Spaces_with_Application_to_Single_Image_Super-Resolution.html">58 cvpr-2013-Beta Process Joint Dictionary Learning for Coupled Feature Spaces with Application to Single Image Super-Resolution</a></p>
<p>Author: Li He, Hairong Qi, Russell Zaretzki</p><p>Abstract: This paper addresses the problem of learning overcomplete dictionaries for the coupled feature spaces, where the learned dictionaries also reflect the relationship between the two spaces. A Bayesian method using a beta process prior is applied to learn the over-complete dictionaries. Compared to previous couple feature spaces dictionary learning algorithms, our algorithm not only provides dictionaries that customized to each feature space, but also adds more consistent and accurate mapping between the two feature spaces. This is due to the unique property of the beta process model that the sparse representation can be decomposed to values and dictionary atom indicators. The proposed algorithm is able to learn sparse representations that correspond to the same dictionary atoms with the same sparsity but different values in coupled feature spaces, thus bringing consistent and accurate mapping between coupled feature spaces. Another advantage of the proposed method is that the number of dictionary atoms and their relative importance may be inferred non-parametrically. We compare the proposed approach to several state-of-the-art dictionary learning methods super-resolution. tionaries learned resolution results ods. by applying this method to single image The experimental results show that dicby our method produces the best supercompared to other state-of-the-art meth-</p><p>4 0.92986143 <a title="296-lsi-4" href="./cvpr-2013-Block_and_Group_Regularized_Sparse_Modeling_for_Dictionary_Learning.html">66 cvpr-2013-Block and Group Regularized Sparse Modeling for Dictionary Learning</a></p>
<p>Author: Yu-Tseh Chi, Mohsen Ali, Ajit Rajwade, Jeffrey Ho</p><p>Abstract: This paper proposes a dictionary learning framework that combines the proposed block/group (BGSC) or reconstructed block/group (R-BGSC) sparse coding schemes with the novel Intra-block Coherence Suppression Dictionary Learning (ICS-DL) algorithm. An important and distinguishing feature of the proposed framework is that all dictionary blocks are trained simultaneously with respect to each data group while the intra-block coherence being explicitly minimized as an important objective. We provide both empirical evidence and heuristic support for this feature that can be considered as a direct consequence of incorporating both the group structure for the input data and the block structure for the dictionary in the learning process. The optimization problems for both the dictionary learning and sparse coding can be solved efficiently using block-gradient descent, and the details of the optimization algorithms are presented. We evaluate the proposed methods using well-known datasets, and favorable comparisons with state-of-the-art dictionary learning methods demonstrate the viability and validity of the proposed framework.</p><p>5 0.91305906 <a title="296-lsi-5" href="./cvpr-2013-Online_Robust_Dictionary_Learning.html">315 cvpr-2013-Online Robust Dictionary Learning</a></p>
<p>Author: Cewu Lu, Jiaping Shi, Jiaya Jia</p><p>Abstract: Online dictionary learning is particularly useful for processing large-scale and dynamic data in computer vision. It, however, faces the major difficulty to incorporate robust functions, rather than the square data fitting term, to handle outliers in training data. In thispaper, wepropose a new online framework enabling the use of ?1 sparse data fitting term in robust dictionary learning, notably enhancing the usability and practicality of this important technique. Extensive experiments have been carried out to validate our new framework.</p><p>6 0.88631159 <a title="296-lsi-6" href="./cvpr-2013-Learning_Structured_Low-Rank_Representations_for_Image_Classification.html">257 cvpr-2013-Learning Structured Low-Rank Representations for Image Classification</a></p>
<p>7 0.83761722 <a title="296-lsi-7" href="./cvpr-2013-Dictionary_Learning_from_Ambiguously_Labeled_Data.html">125 cvpr-2013-Dictionary Learning from Ambiguously Labeled Data</a></p>
<p>8 0.77643299 <a title="296-lsi-8" href="./cvpr-2013-Generalized_Domain-Adaptive_Dictionaries.html">185 cvpr-2013-Generalized Domain-Adaptive Dictionaries</a></p>
<p>9 0.76852995 <a title="296-lsi-9" href="./cvpr-2013-A_Bayesian_Approach_to_Multimodal_Visual_Dictionary_Learning.html">5 cvpr-2013-A Bayesian Approach to Multimodal Visual Dictionary Learning</a></p>
<p>10 0.71528327 <a title="296-lsi-10" href="./cvpr-2013-Tag_Taxonomy_Aware_Dictionary_Learning_for_Region_Tagging.html">422 cvpr-2013-Tag Taxonomy Aware Dictionary Learning for Region Tagging</a></p>
<p>11 0.60384709 <a title="296-lsi-11" href="./cvpr-2013-Histograms_of_Sparse_Codes_for_Object_Detection.html">204 cvpr-2013-Histograms of Sparse Codes for Object Detection</a></p>
<p>12 0.6007992 <a title="296-lsi-12" href="./cvpr-2013-Multi-task_Sparse_Learning_with_Beta_Process_Prior_for_Action_Recognition.html">302 cvpr-2013-Multi-task Sparse Learning with Beta Process Prior for Action Recognition</a></p>
<p>13 0.58362722 <a title="296-lsi-13" href="./cvpr-2013-In_Defense_of_Sparsity_Based_Face_Recognition.html">220 cvpr-2013-In Defense of Sparsity Based Face Recognition</a></p>
<p>14 0.5696553 <a title="296-lsi-14" href="./cvpr-2013-Classification_of_Tumor_Histology_via_Morphometric_Context.html">83 cvpr-2013-Classification of Tumor Histology via Morphometric Context</a></p>
<p>15 0.53782159 <a title="296-lsi-15" href="./cvpr-2013-Transfer_Sparse_Coding_for_Robust_Image_Representation.html">442 cvpr-2013-Transfer Sparse Coding for Robust Image Representation</a></p>
<p>16 0.44193947 <a title="296-lsi-16" href="./cvpr-2013-Multipath_Sparse_Coding_Using_Hierarchical_Matching_Pursuit.html">304 cvpr-2013-Multipath Sparse Coding Using Hierarchical Matching Pursuit</a></p>
<p>17 0.42429647 <a title="296-lsi-17" href="./cvpr-2013-Supervised_Kernel_Descriptors_for_Visual_Recognition.html">421 cvpr-2013-Supervised Kernel Descriptors for Visual Recognition</a></p>
<p>18 0.42078701 <a title="296-lsi-18" href="./cvpr-2013-From_Local_Similarity_to_Global_Coding%3A_An_Application_to_Image_Classification.html">178 cvpr-2013-From Local Similarity to Global Coding: An Application to Image Classification</a></p>
<p>19 0.39422226 <a title="296-lsi-19" href="./cvpr-2013-Subspace_Interpolation_via_Dictionary_Learning_for_Unsupervised_Domain_Adaptation.html">419 cvpr-2013-Subspace Interpolation via Dictionary Learning for Unsupervised Domain Adaptation</a></p>
<p>20 0.3884064 <a title="296-lsi-20" href="./cvpr-2013-Sparse_Output_Coding_for_Large-Scale_Visual_Recognition.html">403 cvpr-2013-Sparse Output Coding for Large-Scale Visual Recognition</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.103), (16, 0.021), (26, 0.039), (28, 0.012), (33, 0.345), (43, 0.122), (57, 0.012), (67, 0.072), (69, 0.085), (87, 0.078)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.97889936 <a title="296-lda-1" href="./cvpr-2013-Classification_of_Tumor_Histology_via_Morphometric_Context.html">83 cvpr-2013-Classification of Tumor Histology via Morphometric Context</a></p>
<p>Author: Hang Chang, Alexander Borowsky, Paul Spellman, Bahram Parvin</p><p>Abstract: Image-based classification oftissue histology, in terms of different components (e.g., normal signature, categories of aberrant signatures), provides a series of indices for tumor composition. Subsequently, aggregation of these indices in each whole slide image (WSI) from a large cohort can provide predictive models of clinical outcome. However, the performance of the existing techniques is hindered as a result of large technical and biological variations that are always present in a large cohort. In this paper, we propose two algorithms for classification of tissue histology based on robust representations of morphometric context, which are built upon nuclear level morphometric features at various locations and scales within the spatial pyramid matching (SPM) framework. These methods have been evaluated on two distinct datasets of different tumor types collected from The Cancer Genome Atlas (TCGA), and the experimental results indicate that our methods are (i) extensible to different tumor types; (ii) robust in the presence of wide technical and biological variations; (iii) invariant to different nuclear segmentation strategies; and (iv) scalable with varying training sample size. In addition, our experiments suggest that enforcing sparsity, during the construction of morphometric context, further improves the performance of the system.</p><p>2 0.96882993 <a title="296-lda-2" href="./cvpr-2013-Rolling_Shutter_Camera_Calibration.html">368 cvpr-2013-Rolling Shutter Camera Calibration</a></p>
<p>Author: Luc Oth, Paul Furgale, Laurent Kneip, Roland Siegwart</p><p>Abstract: Rolling Shutter (RS) cameras are used across a wide range of consumer electronic devices—from smart-phones to high-end cameras. It is well known, that if a RS camera is used with a moving camera or scene, significant image distortions are introduced. The quality or even success of structure from motion on rolling shutter images requires the usual intrinsic parameters such as focal length and distortion coefficients as well as accurate modelling of the shutter timing. The current state-of-the-art technique for calibrating the shutter timings requires specialised hardware. We present a new method that only requires video of a known calibration pattern. Experimental results on over 60 real datasets show that our method is more accurate than the current state of the art.</p><p>same-paper 3 0.9517169 <a title="296-lda-3" href="./cvpr-2013-Multi-level_Discriminative_Dictionary_Learning_towards_Hierarchical_Visual_Categorization.html">296 cvpr-2013-Multi-level Discriminative Dictionary Learning towards Hierarchical Visual Categorization</a></p>
<p>Author: Li Shen, Shuhui Wang, Gang Sun, Shuqiang Jiang, Qingming Huang</p><p>Abstract: For the task of visual categorization, the learning model is expected to be endowed with discriminative visual feature representation and flexibilities in processing many categories. Many existing approaches are designed based on a flat category structure, or rely on a set of pre-computed visual features, hence may not be appreciated for dealing with large numbers of categories. In this paper, we propose a novel dictionary learning method by taking advantage of hierarchical category correlation. For each internode of the hierarchical category structure, a discriminative dictionary and a set of classification models are learnt for visual categorization, and the dictionaries in different layers are learnt to exploit the discriminative visual properties of different granularity. Moreover, the dictionaries in lower levels also inherit the dictionary of ancestor nodes, so that categories in lower levels are described with multi-scale visual information using our dictionary learning approach. Experiments on ImageNet object data subset and SUN397 scene dataset demonstrate that our approach achieves promising performance on data with large numbers of classes compared with some state-of-the-art methods, and is more efficient in processing large numbers of categories.</p><p>4 0.94632965 <a title="296-lda-4" href="./cvpr-2013-Understanding_Indoor_Scenes_Using_3D_Geometric_Phrases.html">446 cvpr-2013-Understanding Indoor Scenes Using 3D Geometric Phrases</a></p>
<p>Author: Wongun Choi, Yu-Wei Chao, Caroline Pantofaru, Silvio Savarese</p><p>Abstract: Visual scene understanding is a difficult problem interleaving object detection, geometric reasoning and scene classification. We present a hierarchical scene model for learning and reasoning about complex indoor scenes which is computationally tractable, can be learned from a reasonable amount of training data, and avoids oversimplification. At the core of this approach is the 3D Geometric Phrase Model which captures the semantic and geometric relationships between objects whichfrequently co-occur in the same 3D spatial configuration. Experiments show that this model effectively explains scene semantics, geometry and object groupings from a single image, while also improving individual object detections.</p><p>5 0.94522089 <a title="296-lda-5" href="./cvpr-2013-Texture_Enhanced_Image_Denoising_via_Gradient_Histogram_Preservation.html">427 cvpr-2013-Texture Enhanced Image Denoising via Gradient Histogram Preservation</a></p>
<p>Author: Wangmeng Zuo, Lei Zhang, Chunwei Song, David Zhang</p><p>Abstract: Image denoising is a classical yet fundamental problem in low level vision, as well as an ideal test bed to evaluate various statistical image modeling methods. One of the most challenging problems in image denoising is how to preserve the fine scale texture structures while removing noise. Various natural image priors, such as gradient based prior, nonlocal self-similarity prior, and sparsity prior, have been extensively exploited for noise removal. The denoising algorithms based on these priors, however, tend to smooth the detailed image textures, degrading the image visual quality. To address this problem, in this paper we propose a texture enhanced image denoising (TEID) method by enforcing the gradient distribution of the denoised image to be close to the estimated gradient distribution of the original image. A novel gradient histogram preservation (GHP) algorithm is developed to enhance the texture structures while removing noise. Our experimental results demonstrate that theproposed GHP based TEID can well preserve the texture features of the denoised images, making them look more natural.</p><p>6 0.9444021 <a title="296-lda-6" href="./cvpr-2013-Bottom-Up_Segmentation_for_Top-Down_Detection.html">70 cvpr-2013-Bottom-Up Segmentation for Top-Down Detection</a></p>
<p>7 0.94429541 <a title="296-lda-7" href="./cvpr-2013-Context-Aware_Modeling_and_Recognition_of_Activities_in_Video.html">94 cvpr-2013-Context-Aware Modeling and Recognition of Activities in Video</a></p>
<p>8 0.9441458 <a title="296-lda-8" href="./cvpr-2013-Learning_Structured_Hough_Voting_for_Joint_Object_Detection_and_Occlusion_Reasoning.html">256 cvpr-2013-Learning Structured Hough Voting for Joint Object Detection and Occlusion Reasoning</a></p>
<p>9 0.94365203 <a title="296-lda-9" href="./cvpr-2013-Perceptual_Organization_and_Recognition_of_Indoor_Scenes_from_RGB-D_Images.html">329 cvpr-2013-Perceptual Organization and Recognition of Indoor Scenes from RGB-D Images</a></p>
<p>10 0.94340146 <a title="296-lda-10" href="./cvpr-2013-Discriminative_Re-ranking_of_Diverse_Segmentations.html">132 cvpr-2013-Discriminative Re-ranking of Diverse Segmentations</a></p>
<p>11 0.9430896 <a title="296-lda-11" href="./cvpr-2013-Adding_Unlabeled_Samples_to_Categories_by_Learned_Attributes.html">36 cvpr-2013-Adding Unlabeled Samples to Categories by Learned Attributes</a></p>
<p>12 0.94280565 <a title="296-lda-12" href="./cvpr-2013-SLAM%2B%2B%3A_Simultaneous_Localisation_and_Mapping_at_the_Level_of_Objects.html">372 cvpr-2013-SLAM++: Simultaneous Localisation and Mapping at the Level of Objects</a></p>
<p>13 0.94278461 <a title="296-lda-13" href="./cvpr-2013-Optimized_Pedestrian_Detection_for_Multiple_and_Occluded_People.html">318 cvpr-2013-Optimized Pedestrian Detection for Multiple and Occluded People</a></p>
<p>14 0.94233936 <a title="296-lda-14" href="./cvpr-2013-Class_Generative_Models_Based_on_Feature_Regression_for_Pose_Estimation_of_Object_Categories.html">82 cvpr-2013-Class Generative Models Based on Feature Regression for Pose Estimation of Object Categories</a></p>
<p>15 0.94203079 <a title="296-lda-15" href="./cvpr-2013-Studying_Relationships_between_Human_Gaze%2C_Description%2C_and_Computer_Vision.html">416 cvpr-2013-Studying Relationships between Human Gaze, Description, and Computer Vision</a></p>
<p>16 0.94163382 <a title="296-lda-16" href="./cvpr-2013-Beyond_Point_Clouds%3A_Scene_Understanding_by_Reasoning_Geometry_and_Physics.html">61 cvpr-2013-Beyond Point Clouds: Scene Understanding by Reasoning Geometry and Physics</a></p>
<p>17 0.94139349 <a title="296-lda-17" href="./cvpr-2013-Subcategory-Aware_Object_Classification.html">417 cvpr-2013-Subcategory-Aware Object Classification</a></p>
<p>18 0.94135058 <a title="296-lda-18" href="./cvpr-2013-Incorporating_Structural_Alternatives_and_Sharing_into_Hierarchy_for_Multiclass_Object_Recognition_and_Detection.html">221 cvpr-2013-Incorporating Structural Alternatives and Sharing into Hierarchy for Multiclass Object Recognition and Detection</a></p>
<p>19 0.94134921 <a title="296-lda-19" href="./cvpr-2013-Label_Propagation_from_ImageNet_to_3D_Point_Clouds.html">242 cvpr-2013-Label Propagation from ImageNet to 3D Point Clouds</a></p>
<p>20 0.94134349 <a title="296-lda-20" href="./cvpr-2013-Mesh_Based_Semantic_Modelling_for_Indoor_and_Outdoor_Scenes.html">284 cvpr-2013-Mesh Based Semantic Modelling for Indoor and Outdoor Scenes</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
