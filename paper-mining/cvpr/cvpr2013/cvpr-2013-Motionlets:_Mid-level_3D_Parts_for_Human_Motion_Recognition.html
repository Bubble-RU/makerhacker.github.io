<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>291 cvpr-2013-Motionlets: Mid-level 3D Parts for Human Motion Recognition</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-291" href="#">cvpr2013-291</a> knowledge-graph by maker-knowledge-mining</p><h1>291 cvpr-2013-Motionlets: Mid-level 3D Parts for Human Motion Recognition</h1>
<br/><p>Source: <a title="cvpr-2013-291-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Wang_Motionlets_Mid-level_3D_2013_CVPR_paper.pdf">pdf</a></p><p>Author: LiMin Wang, Yu Qiao, Xiaoou Tang</p><p>Abstract: This paper proposes motionlet, a mid-level and spatiotemporal part, for human motion recognition. Motionlet can be seen as a tight cluster in motion and appearance space, corresponding to the moving process of different body parts. We postulate three key properties of motionlet for action recognition: high motion saliency, multiple scale representation, and representative-discriminative ability. Towards this goal, we develop a data-driven approach to learn motionlets from training videos. First, we extract 3D regions with high motion saliency. Then we cluster these regions and preserve the centers as candidate templates for motionlet. Finally, we examine the representative and discriminative power of the candidates, and introduce a greedy method to select effective candidates. With motionlets, we present a mid-level representation for video, called motionlet activation vector. We conduct experiments on three datasets, KTH, HMDB51, and UCF50. The results show that the proposed methods significantly outperform state-of-the-art methods.</p><p>Reference: <a title="cvpr-2013-291-reference" href="../cvpr2013_reference/cvpr-2013-Motionlets%3A_Mid-level_3D_Parts_for_Human_Motion_Recognition_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('motionlet', 0.968), ('spatiotemp', 0.073), ('video', 0.071), ('hoe', 0.058), ('mj', 0.051), ('templ', 0.047), ('saly', 0.047), ('bank', 0.044), ('soe', 0.042), ('energy', 0.041), ('kth', 0.039), ('act', 0.036), ('gv', 0.035), ('mot', 0.033), ('sij', 0.031), ('bovw', 0.027), ('logo', 0.027), ('stip', 0.027), ('candid', 0.027), ('ory', 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="291-tfidf-1" href="./cvpr-2013-Motionlets%3A_Mid-level_3D_Parts_for_Human_Motion_Recognition.html">291 cvpr-2013-Motionlets: Mid-level 3D Parts for Human Motion Recognition</a></p>
<p>2 0.072803654 <a title="291-tfidf-2" href="./cvpr-2013-Sampling_Strategies_for_Real-Time_Action_Recognition.html">378 cvpr-2013-Sampling Strategies for Real-Time Action Recognition</a></p>
<p>3 0.06810914 <a title="291-tfidf-3" href="./cvpr-2013-Joint_Sparsity-Based_Representation_and_Analysis_of_Unconstrained_Activities.html">233 cvpr-2013-Joint Sparsity-Based Representation and Analysis of Unconstrained Activities</a></p>
<p>4 0.062128246 <a title="291-tfidf-4" href="./cvpr-2013-Representing_Videos_Using_Mid-level_Discriminative_Patches.html">355 cvpr-2013-Representing Videos Using Mid-level Discriminative Patches</a></p>
<p>5 0.057782769 <a title="291-tfidf-5" href="./cvpr-2013-First-Person_Activity_Recognition%3A_What_Are_They_Doing_to_Me%3F.html">175 cvpr-2013-First-Person Activity Recognition: What Are They Doing to Me?</a></p>
<p>6 0.055997699 <a title="291-tfidf-6" href="./cvpr-2013-3D_R_Transform_on_Spatio-temporal_Interest_Points_for_Action_Recognition.html">3 cvpr-2013-3D R Transform on Spatio-temporal Interest Points for Action Recognition</a></p>
<p>7 0.054138593 <a title="291-tfidf-7" href="./cvpr-2013-Learning_Video_Saliency_from_Human_Gaze_Using_Candidate_Selection.html">258 cvpr-2013-Learning Video Saliency from Human Gaze Using Candidate Selection</a></p>
<p>8 0.05317577 <a title="291-tfidf-8" href="./cvpr-2013-Hierarchical_Saliency_Detection.html">202 cvpr-2013-Hierarchical Saliency Detection</a></p>
<p>9 0.051955745 <a title="291-tfidf-9" href="./cvpr-2013-Salient_Object_Detection%3A_A_Discriminative_Regional_Feature_Integration_Approach.html">376 cvpr-2013-Salient Object Detection: A Discriminative Regional Feature Integration Approach</a></p>
<p>10 0.051095091 <a title="291-tfidf-10" href="./cvpr-2013-Spatiotemporal_Deformable_Part_Models_for_Action_Detection.html">408 cvpr-2013-Spatiotemporal Deformable Part Models for Action Detection</a></p>
<p>11 0.049734175 <a title="291-tfidf-11" href="./cvpr-2013-Expanded_Parts_Model_for_Human_Attribute_and_Action_Recognition_in_Still_Images.html">153 cvpr-2013-Expanded Parts Model for Human Attribute and Action Recognition in Still Images</a></p>
<p>12 0.049365249 <a title="291-tfidf-12" href="./cvpr-2013-An_Approach_to_Pose-Based_Action_Recognition.html">40 cvpr-2013-An Approach to Pose-Based Action Recognition</a></p>
<p>13 0.048734497 <a title="291-tfidf-13" href="./cvpr-2013-Hollywood_3D%3A_Recognizing_Actions_in_3D_Natural_Scenes.html">205 cvpr-2013-Hollywood 3D: Recognizing Actions in 3D Natural Scenes</a></p>
<p>14 0.048689127 <a title="291-tfidf-14" href="./cvpr-2013-Saliency_Detection_via_Graph-Based_Manifold_Ranking.html">375 cvpr-2013-Saliency Detection via Graph-Based Manifold Ranking</a></p>
<p>15 0.047060225 <a title="291-tfidf-15" href="./cvpr-2013-Recognize_Human_Activities_from_Partially_Observed_Videos.html">347 cvpr-2013-Recognize Human Activities from Partially Observed Videos</a></p>
<p>16 0.045829825 <a title="291-tfidf-16" href="./cvpr-2013-Evaluation_of_Color_STIPs_for_Human_Action_Recognition.html">149 cvpr-2013-Evaluation of Color STIPs for Human Action Recognition</a></p>
<p>17 0.045799389 <a title="291-tfidf-17" href="./cvpr-2013-PISA%3A_Pixelwise_Image_Saliency_by_Aggregating_Complementary_Appearance_Contrast_Measures_with_Spatial_Priors.html">322 cvpr-2013-PISA: Pixelwise Image Saliency by Aggregating Complementary Appearance Contrast Measures with Spatial Priors</a></p>
<p>18 0.045640159 <a title="291-tfidf-18" href="./cvpr-2013-Large-Scale_Video_Summarization_Using_Web-Image_Priors.html">243 cvpr-2013-Large-Scale Video Summarization Using Web-Image Priors</a></p>
<p>19 0.044882096 <a title="291-tfidf-19" href="./cvpr-2013-Looking_Beyond_the_Image%3A_Unsupervised_Learning_for_Object_Saliency_and_Detection.html">273 cvpr-2013-Looking Beyond the Image: Unsupervised Learning for Object Saliency and Detection</a></p>
<p>20 0.04447332 <a title="291-tfidf-20" href="./cvpr-2013-HON4D%3A_Histogram_of_Oriented_4D_Normals_for_Activity_Recognition_from_Depth_Sequences.html">196 cvpr-2013-HON4D: Histogram of Oriented 4D Normals for Activity Recognition from Depth Sequences</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.087), (1, 0.045), (2, 0.003), (3, 0.017), (4, -0.008), (5, 0.01), (6, 0.009), (7, -0.005), (8, -0.001), (9, -0.032), (10, -0.068), (11, -0.035), (12, 0.038), (13, 0.029), (14, 0.021), (15, -0.008), (16, -0.021), (17, -0.004), (18, 0.039), (19, 0.012), (20, -0.02), (21, 0.009), (22, -0.031), (23, -0.023), (24, 0.016), (25, -0.028), (26, 0.028), (27, -0.01), (28, -0.043), (29, -0.015), (30, -0.015), (31, -0.007), (32, -0.038), (33, 0.044), (34, -0.015), (35, 0.021), (36, 0.029), (37, -0.006), (38, -0.039), (39, 0.009), (40, -0.026), (41, 0.003), (42, -0.03), (43, -0.007), (44, -0.001), (45, -0.011), (46, -0.011), (47, 0.043), (48, 0.027), (49, 0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.85964692 <a title="291-lsi-1" href="./cvpr-2013-Motionlets%3A_Mid-level_3D_Parts_for_Human_Motion_Recognition.html">291 cvpr-2013-Motionlets: Mid-level 3D Parts for Human Motion Recognition</a></p>
<p>2 0.78310382 <a title="291-lsi-2" href="./cvpr-2013-Spatiotemporal_Deformable_Part_Models_for_Action_Detection.html">408 cvpr-2013-Spatiotemporal Deformable Part Models for Action Detection</a></p>
<p>3 0.72352916 <a title="291-lsi-3" href="./cvpr-2013-Evaluation_of_Color_STIPs_for_Human_Action_Recognition.html">149 cvpr-2013-Evaluation of Color STIPs for Human Action Recognition</a></p>
<p>4 0.71741623 <a title="291-lsi-4" href="./cvpr-2013-3D_R_Transform_on_Spatio-temporal_Interest_Points_for_Action_Recognition.html">3 cvpr-2013-3D R Transform on Spatio-temporal Interest Points for Action Recognition</a></p>
<p>5 0.70619011 <a title="291-lsi-5" href="./cvpr-2013-Poselet_Key-Framing%3A_A_Model_for_Human_Activity_Recognition.html">336 cvpr-2013-Poselet Key-Framing: A Model for Human Activity Recognition</a></p>
<p>6 0.70292634 <a title="291-lsi-6" href="./cvpr-2013-First-Person_Activity_Recognition%3A_What_Are_They_Doing_to_Me%3F.html">175 cvpr-2013-First-Person Activity Recognition: What Are They Doing to Me?</a></p>
<p>7 0.69399768 <a title="291-lsi-7" href="./cvpr-2013-Modeling_Actions_through_State_Changes.html">287 cvpr-2013-Modeling Actions through State Changes</a></p>
<p>8 0.69221509 <a title="291-lsi-8" href="./cvpr-2013-Recognize_Human_Activities_from_Partially_Observed_Videos.html">347 cvpr-2013-Recognize Human Activities from Partially Observed Videos</a></p>
<p>9 0.68982744 <a title="291-lsi-9" href="./cvpr-2013-Context-Aware_Modeling_and_Recognition_of_Activities_in_Video.html">94 cvpr-2013-Context-Aware Modeling and Recognition of Activities in Video</a></p>
<p>10 0.67351127 <a title="291-lsi-10" href="./cvpr-2013-Hollywood_3D%3A_Recognizing_Actions_in_3D_Natural_Scenes.html">205 cvpr-2013-Hollywood 3D: Recognizing Actions in 3D Natural Scenes</a></p>
<p>11 0.67065591 <a title="291-lsi-11" href="./cvpr-2013-Joint_Sparsity-Based_Representation_and_Analysis_of_Unconstrained_Activities.html">233 cvpr-2013-Joint Sparsity-Based Representation and Analysis of Unconstrained Activities</a></p>
<p>12 0.66339666 <a title="291-lsi-12" href="./cvpr-2013-Sampling_Strategies_for_Real-Time_Action_Recognition.html">378 cvpr-2013-Sampling Strategies for Real-Time Action Recognition</a></p>
<p>13 0.65664053 <a title="291-lsi-13" href="./cvpr-2013-Augmenting_Bag-of-Words%3A_Data-Driven_Discovery_of_Temporal_and_Structural_Information_for_Activity_Recognition.html">49 cvpr-2013-Augmenting Bag-of-Words: Data-Driven Discovery of Temporal and Structural Information for Activity Recognition</a></p>
<p>14 0.65324938 <a title="291-lsi-14" href="./cvpr-2013-Detecting_and_Naming_Actors_in_Movies_Using_Generative_Appearance_Models.html">120 cvpr-2013-Detecting and Naming Actors in Movies Using Generative Appearance Models</a></p>
<p>15 0.64334327 <a title="291-lsi-15" href="./cvpr-2013-Online_Dominant_and_Anomalous_Behavior_Detection_in_Videos.html">313 cvpr-2013-Online Dominant and Anomalous Behavior Detection in Videos</a></p>
<p>16 0.62339365 <a title="291-lsi-16" href="./cvpr-2013-Spatio-temporal_Depth_Cuboid_Similarity_Feature_for_Activity_Recognition_Using_Depth_Camera.html">407 cvpr-2013-Spatio-temporal Depth Cuboid Similarity Feature for Activity Recognition Using Depth Camera</a></p>
<p>17 0.60852259 <a title="291-lsi-17" href="./cvpr-2013-Story-Driven_Summarization_for_Egocentric_Video.html">413 cvpr-2013-Story-Driven Summarization for Egocentric Video</a></p>
<p>18 0.60603881 <a title="291-lsi-18" href="./cvpr-2013-Dynamic_Scene_Classification%3A_Learning_Motion_Descriptors_with_Slow_Features_Analysis.html">137 cvpr-2013-Dynamic Scene Classification: Learning Motion Descriptors with Slow Features Analysis</a></p>
<p>19 0.59695274 <a title="291-lsi-19" href="./cvpr-2013-HON4D%3A_Histogram_of_Oriented_4D_Normals_for_Activity_Recognition_from_Depth_Sequences.html">196 cvpr-2013-HON4D: Histogram of Oriented 4D Normals for Activity Recognition from Depth Sequences</a></p>
<p>20 0.59148908 <a title="291-lsi-20" href="./cvpr-2013-Bilinear_Programming_for_Human_Activity_Recognition_with_Unknown_MRF_Graphs.html">62 cvpr-2013-Bilinear Programming for Human Activity Recognition with Unknown MRF Graphs</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.068), (4, 0.087), (5, 0.189), (37, 0.064), (40, 0.012), (71, 0.212), (80, 0.02), (81, 0.03), (86, 0.067), (95, 0.016), (97, 0.061)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.82194543 <a title="291-lda-1" href="./cvpr-2013-Augmenting_CRFs_with_Boltzmann_Machine_Shape_Priors_for_Image_Labeling.html">50 cvpr-2013-Augmenting CRFs with Boltzmann Machine Shape Priors for Image Labeling</a></p>
<p>same-paper 2 0.79152471 <a title="291-lda-2" href="./cvpr-2013-Motionlets%3A_Mid-level_3D_Parts_for_Human_Motion_Recognition.html">291 cvpr-2013-Motionlets: Mid-level 3D Parts for Human Motion Recognition</a></p>
<p>3 0.76388812 <a title="291-lda-3" href="./cvpr-2013-Beyond_Physical_Connections%3A_Tree_Models_in_Human_Pose_Estimation.html">60 cvpr-2013-Beyond Physical Connections: Tree Models in Human Pose Estimation</a></p>
<p>4 0.76291502 <a title="291-lda-4" href="./cvpr-2013-First-Person_Activity_Recognition%3A_What_Are_They_Doing_to_Me%3F.html">175 cvpr-2013-First-Person Activity Recognition: What Are They Doing to Me?</a></p>
<p>5 0.75158381 <a title="291-lda-5" href="./cvpr-2013-A_Video_Representation_Using_Temporal_Superpixels.html">29 cvpr-2013-A Video Representation Using Temporal Superpixels</a></p>
<p>6 0.75020278 <a title="291-lda-6" href="./cvpr-2013-Composite_Statistical_Inference_for_Semantic_Segmentation.html">86 cvpr-2013-Composite Statistical Inference for Semantic Segmentation</a></p>
<p>7 0.74795377 <a title="291-lda-7" href="./cvpr-2013-Multi-source_Multi-scale_Counting_in_Extremely_Dense_Crowd_Images.html">299 cvpr-2013-Multi-source Multi-scale Counting in Extremely Dense Crowd Images</a></p>
<p>8 0.74661702 <a title="291-lda-8" href="./cvpr-2013-Constraints_as_Features.html">93 cvpr-2013-Constraints as Features</a></p>
<p>9 0.74568647 <a title="291-lda-9" href="./cvpr-2013-Tracking_People_and_Their_Objects.html">440 cvpr-2013-Tracking People and Their Objects</a></p>
<p>10 0.74555892 <a title="291-lda-10" href="./cvpr-2013-Integrating_Grammar_and_Segmentation_for_Human_Pose_Estimation.html">225 cvpr-2013-Integrating Grammar and Segmentation for Human Pose Estimation</a></p>
<p>11 0.74493104 <a title="291-lda-11" href="./cvpr-2013-Label_Propagation_from_ImageNet_to_3D_Point_Clouds.html">242 cvpr-2013-Label Propagation from ImageNet to 3D Point Clouds</a></p>
<p>12 0.74489081 <a title="291-lda-12" href="./cvpr-2013-Exploring_Compositional_High_Order_Pattern_Potentials_for_Structured_Output_Learning.html">156 cvpr-2013-Exploring Compositional High Order Pattern Potentials for Structured Output Learning</a></p>
<p>13 0.74459213 <a title="291-lda-13" href="./cvpr-2013-Decoding_Children%27s_Social_Behavior.html">103 cvpr-2013-Decoding Children's Social Behavior</a></p>
<p>14 0.74407154 <a title="291-lda-14" href="./cvpr-2013-Learning_Separable_Filters.html">255 cvpr-2013-Learning Separable Filters</a></p>
<p>15 0.74346465 <a title="291-lda-15" href="./cvpr-2013-Selective_Transfer_Machine_for_Personalized_Facial_Action_Unit_Detection.html">385 cvpr-2013-Selective Transfer Machine for Personalized Facial Action Unit Detection</a></p>
<p>16 0.74345523 <a title="291-lda-16" href="./cvpr-2013-Learning_to_Detect_Partially_Overlapping_Instances.html">264 cvpr-2013-Learning to Detect Partially Overlapping Instances</a></p>
<p>17 0.74317539 <a title="291-lda-17" href="./cvpr-2013-Optimizing_1-Nearest_Prototype_Classifiers.html">320 cvpr-2013-Optimizing 1-Nearest Prototype Classifiers</a></p>
<p>18 0.74302441 <a title="291-lda-18" href="./cvpr-2013-Representing_and_Discovering_Adversarial_Team_Behaviors_Using_Player_Roles.html">356 cvpr-2013-Representing and Discovering Adversarial Team Behaviors Using Player Roles</a></p>
<p>19 0.74248201 <a title="291-lda-19" href="./cvpr-2013-Finding_Group_Interactions_in_Social_Clutter.html">172 cvpr-2013-Finding Group Interactions in Social Clutter</a></p>
<p>20 0.74247116 <a title="291-lda-20" href="./cvpr-2013-Crossing_the_Line%3A_Crowd_Counting_by_Integer_Programming_with_Local_Features.html">100 cvpr-2013-Crossing the Line: Crowd Counting by Integer Programming with Local Features</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
