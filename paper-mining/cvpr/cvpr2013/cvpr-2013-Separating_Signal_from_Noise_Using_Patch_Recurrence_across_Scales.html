<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>393 cvpr-2013-Separating Signal from Noise Using Patch Recurrence across Scales</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-393" href="#">cvpr2013-393</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>393 cvpr-2013-Separating Signal from Noise Using Patch Recurrence across Scales</h1>
<br/><p>Source: <a title="cvpr-2013-393-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Zontak_Separating_Signal_from_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Maria Zontak, Inbar Mosseri, Michal Irani</p><p>Abstract: Recurrence of small clean image patches across different scales of a natural image has been successfully used for solving ill-posed problems in clean images (e.g., superresolution from a single image). In this paper we show how this multi-scale property can be extended to solve ill-posed problems under noisy conditions, such as image denoising. While clean patches are obscured by severe noise in the original scale of a noisy image, noise levels drop dramatically at coarser image scales. This allows for the unknown hidden clean patches to “naturally emerge ” in some coarser scale of the noisy image. We further show that patch recurrence across scales is strengthened when using directional pyramids (that blur and subsample only in one direction). Our statistical experiments show that for almost any noisy image patch (more than 99%), there exists a “good” clean version of itself at the same relative image coordinates in some coarser scale of the image.This is a strong phenomenon of noise-contaminated natural images, which can serve as a strong prior for separating the signal from the noise. Finally, incorporating this multi-scale prior into a simple denoising algorithm yields state-of-the-art denois- ing results.</p><p>Reference: <a title="cvpr-2013-393-reference" href="../cvpr2013_reference/cvpr-2013-Separating_Signal_from_Noise_Using_Patch_Recurrence_across_Scales_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 of Computer Science and Applied Mathematics The Weizmann Institute of Science, ISRAEL  Abstract Recurrence of small clean image patches across different scales of a natural image has been successfully used for solving ill-posed problems in clean images (e. [sent-2, score-1.241]
</p><p>2 In this paper we show how this multi-scale property can be extended to solve ill-posed problems under noisy conditions, such as image denoising. [sent-5, score-0.274]
</p><p>3 While clean patches are obscured by severe noise in the original scale of a noisy image, noise levels drop dramatically at coarser image scales. [sent-6, score-1.619]
</p><p>4 This allows for the unknown hidden clean patches to “naturally emerge ” in some coarser scale of the noisy image. [sent-7, score-1.298]
</p><p>5 We further show that patch recurrence across scales is strengthened when using directional pyramids (that blur and subsample only in one direction). [sent-8, score-1.262]
</p><p>6 Our statistical experiments show that for almost any noisy image patch (more than 99%), there exists a “good” clean version of itself at the same relative image coordinates in some coarser scale of the image. [sent-9, score-1.315]
</p><p>7 This is a strong phenomenon of noise-contaminated natural images, which can serve as a strong prior for separating the signal from the noise. [sent-10, score-0.236]
</p><p>8 Introduction The goal of natural image denoising is to recover a clean image I from its noise contaminated version IN. [sent-13, score-0.709]
</p><p>9 A leap improvement in denoising has been obtained by [3], who introduced a strong natural-image prior, which exploits the recurrence of small image patches internally, within a natural image. [sent-18, score-0.793]
</p><p>10 External statistics of natural image patches learned from large collections of clean images, has also been used as priors for denoising. [sent-20, score-0.721]
</p><p>11 While the external methods benefit from a large space of clean patches, the internal methods benefit from an imagespecific space of patches, which was shown by [16] to be very powerful. [sent-22, score-0.524]
</p><p>12 In contrast a big challenge for internal methods is to aggregate enough noisy patches which share the same underlying signal. [sent-24, score-0.572]
</p><p>13 This is particularly problematic when large patches are used (often necessary in the presence of severe noise [4, 9, 17]). [sent-25, score-0.455]
</p><p>14 In this paper we propose  ×  a new internal search space, which on one hand is imagespecific, yet, contains clean patches – the space of coarse patches of the noisy image. [sent-26, score-1.3]
</p><p>15 We present a strong multi-scale prior for solving illposed problems under severe noise, which is based on the recurrence of small patches across different scales of a natural image (where a coarser image scale is generated by blurring & subsampling the image). [sent-27, score-1.233]
</p><p>16 Most patch-based denoising methods perform deniosing by exploiting patch repetitions within the same scale, whereas our prior suggests to use patch repetitions across different scales. [sent-28, score-0.899]
</p><p>17 It was previously shown [7, 16] that small patches in clean natural images tend to recur across image scales. [sent-30, score-0.84]
</p><p>18 , 5 5) re-appears “as is” (without any spatial transforma5tio ×n) i)n coarser rvse r“saison iss” ”o (fw tihteh oimuta agney (s speea iFailg. [sent-33, score-0.273]
</p><p>19 It was further shown by [6] that due to local scale invariance in natural images, patches tend to recur at coarser image scales at similar relative image coordinates as in the fine scale. [sent-37, score-0.92]
</p><p>20 We show that these natural-image properties can be exploited for “pulling out” cleaner versions of the signal from  recurrence”  ×  × ××  coarser scales of the noisy image (see Fig. [sent-38, score-0.755]
</p><p>21 It is further noted that for some patches (especially edge patches), the cross-scale recurrence property is strengthened when using directional pyramids (that blur and subsample only in one direction). [sent-41, score-1.137]
</p><p>22 Surprisingly, our experiments indicate that with very 1 1 1 111119999955333  The local scale-invariance property of small patches in clean natural images  scale. [sent-42, score-0.755]
</p><p>23 We display the 5  5 patches at the same relative coordinates in all 4 images (i. [sent-43, score-0.374]
</p><p>24 , the 5 5 patch centered at (x0, y0) in the fine ( thx0e/ s3a,m mye0/ r3el)a itinv teh ceo coarse tsecsal iens a)l. [sent-45, score-0.367]
</p><p>25 lT 4he imrea igse strong similarity b peatwtcehe nce corresponding 5 5 patches  ssccaallee. [sent-46, score-0.345]
</p><p>26 s, Waned d tihspel 5a y× t h5e patch 5ce pnattecrheeds a att saccarolesss,-s acnadle t  Since the noise drops dramatically with scale, the clean patches naturally “emerge” at coarser pyramid levels of the noisy image  hine 5th×e 5cle paant image. [sent-47, score-1.835]
</p><p>27 Nreodte a tth (axt the patch a int th thee coarse s sccaalele of the noisy image isism maillsaor very stwimeielanr c otor trhesep colnedanin patch. [sent-48, score-0.629]
</p><p>28 high probability, for every noisy patch, a very good representative of its unknown clean patch resides within a small set of 60 patches (all its 5 5 descendant patches at the same sreelta otifv 6e0 0i pmaatcghe ecso (oarldli intsa5t e×s)5. [sent-49, score-1.814]
</p><p>29 Finally, incorporating this multi-scale prior into a simple denoising algorithm, yields results better than state-of-theart methods, especially for high noise levels. [sent-51, score-0.272]
</p><p>30 N faoctte hthatat w tehe u term y“m smualtlil-s 5ca ×le 5 denoising” of [10, 2] refers to a different notion using patches of different –  ×  sizes from various locations within the image. [sent-53, score-0.303]
</p><p>31 The multiscale property we exploit here is the “fractal-like” scale invariance property of natural images, namely, recurrence of small patches of a fixed size (e. [sent-54, score-0.697]
</p><p>32 , edge-detection in noisy images, super-resolution under noisy conditions, etc. [sent-61, score-0.48]
</p><p>33 2 we analyze and quantify the local cross-scale emergence of clean patches in noisy images, and show that this is a very strong phenomenon. [sent-64, score-0.958]
</p><p>34 We further show that patch recurrence across scales is strengthened when using directional pyramids. [sent-65, score-0.978]
</p><p>35 3 proposes an approach for finding the “best” coarser patch for any noisy patch in a noisy image, and discusses its limitations. [sent-67, score-1.361]
</p><p>36 4 proposes a very simple denoising algorithm which exploits this multi-scale prior, providing state-of-the-art denoising results (especially for high noise levels). [sent-69, score-0.403]
</p><p>37 Statistics of Clean Patches in Noisy Images We demonstrate how the local scale-invariance property of small patches in natural images (Fig. [sent-73, score-0.382]
</p><p>38 a) can be used for “pulling out” cleaner versions of the signal from coarser scales of the noisy image (Fig. [sent-75, score-0.755]
</p><p>39 We first extend the  ×  notion of ‘pyramids’ from the standard isotropic pyramid to directional pyramids. [sent-78, score-0.362]
</p><p>40 We then show that patch recurrence across scale is further strengthened when using directional pyramids. [sent-79, score-0.902]
</p><p>41 We generate a directional pyramid by blurring and subsampling the image only in one direction. [sent-82, score-0.336]
</p><p>42 This is different from the commonly used isotropic image pyramid, which preserves the aspect ratio, as well as from the Steerable Pyramid [15], which applies 1D directional filtering, but subsamples the image in both directions. [sent-83, score-0.249]
</p><p>43 For some patches (especially edge patches), the cross-scale recurrence property is strengthened when using directional pyramids. [sent-84, score-0.853]
</p><p>44 In particular, very thin edges which tend to disappear at low scales of the isotropic (or steerable) pyramid, are preserved well by our directional pyramids. [sent-85, score-0.402]
</p><p>45 The ‘hidden’ clean patches are obscured by noise at the original input image scale. [sent-88, score-0.815]
</p><p>46 However, these (unknown) clean patches recur at coarser image scales, at the same relative image coordinates. [sent-89, score-1.014]
</p><p>47 Since the noise level drops dramatically at coarser image scales (see Fig. [sent-90, score-0.535]
</p><p>48 b), the unknown clean patches naturally emerge at some coarser pyramid levels. [sent-92, score-1.154]
</p><p>49 Note that although the directional pyramids change the aspect ratio of the image, the patches compared across scales remain ofthe same size and shape (square 5 5 paacrtcohsesss)c ianle sallr smcaaliens. [sent-93, score-0.785]
</p><p>50 (b) The drop in noise variance σ2 as a function of the pyramid scale (empirically evaluated from many randomGaussian-noise images). [sent-97, score-0.31]
</p><p>51 (c) Examples of noisy patches and their corresponding clean patches ‘emerging at coarse pyramid scales. [sent-98, score-1.384]
</p><p>52 ’  ×  Patches are marked in (a) and magnified in (c): The noisy horizontal (red) and vertical (green) edge patches have corresponding clean patches at coarse scales of the respective directionalpyramid (at the same relative coordinates). [sent-99, score-1.421]
</p><p>53 The noisy uniform patch (cyan) has a clean patch at coarse scales of the Iso-pyramid. [sent-100, score-1.413]
</p><p>54 ve N a mgeoloyd: (ci)lea Hno w re mpraesneyn t5at ×ive 5 patch of the clean patch in a coarser scale of the noisy image? [sent-103, score-1.536]
</p><p>55 ) We show that statistically this is indeed a very strong phenomenon of noisy images. [sent-108, score-0.306]
</p><p>56 In fact, as will be shown, the vast majority of image patches (more than 99%) will benefit significantly from going down in scale, and will have a very good representative patch directly below them, at the same relative image coordinates (i. [sent-109, score-0.799]
</p><p>57 , on the ‘needle’ of their descendant patches see Fig. [sent-111, score-0.436]
</p><p>58 Each clean image I (converted to grayscale) was first contaminated by Gaussian noise with zero mean and variance σ2, resulting in a noisy image IN = I N. [sent-115, score-0.772]
</p><p>59 Each noisy patch pN has a needle in all 3 pyramids (illustrated here only for the Isotropic pyramid). [sent-118, score-0.99]
</p><p>60 (a) All the patches along the needle of the noisy patch are at the same relative image coordinates. [sent-119, score-1.177]
</p><p>61 Initially the patches get better (cleaner), but eventually new structures enter the patch. [sent-120, score-0.303]
</p><p>62 The “best” representative patch on the needle is marked in orange. [sent-121, score-0.625]
</p><p>63 (b) Zooming in on the descendant patches {psNc} along the needle (sc = 1, . [sent-122, score-0.723]
</p><p>64 types of pyramids: (i) Isotropic pyramid (blur and subsample1 both in x and in y), (ii) X-pyramid (blur and subsample only in the x direction), and (iii) Y-pyramid (blur and subsample only in the y direction) – see Fig. [sent-126, score-0.249]
</p><p>65 Namely, if (x, y) are the coor-  ××  dinate of the clean 5 5 patch p (and the noisy patch pN), tdhinena feor o ef tacheh cscleaalen sc ×= 5 50 p. [sent-137, score-1.316]
</p><p>66 9ats we compare p oonislyy apgatacinhs pt the 5 5 patch psNc whose coordinates are: (i) (0. [sent-138, score-0.354]
</p><p>67 |, ,| as t)h, ew “eb cehsot”s e re thpere osennet wathiviech ho mf tihneclean patch p. [sent-148, score-0.337]
</p><p>68 4 visually displays the resulting image when each patch in the noisy image is replaced by its single “best” descendant 5 5 patch psNc along its needle. [sent-150, score-1.024]
</p><p>69 ) It is evident that the resulting image is significantly cleaner than the noisy input. [sent-152, score-0.336]
</p><p>70 In fact, it is significantly cleaner (has significantly larger PSNR2) than what can be achieved by today’s state-of-the art denoising algorithms (see PSNR comparisons in Fig. [sent-153, score-0.235]
</p><p>71 Note that this is not a denoising algorithm, since we used the original clean image to guide the selection of patches. [sent-155, score-0.512]
</p><p>72 However, those patches were selected from the pyramid of the noisy image; no additional processing was  (Overlaps  1using Matlab “imresize” with a bicubic kernel 2PSNR= 20 log10 (255/σ), stands for “Peak Signal  to  Noise Ratio”. [sent-156, score-0.656]
</p><p>73 Noisy images (man-made  & natural  scenes), and their corresponding  ‘Oracle ’ images  –  generated by  replacing each noisy patch with its ‘best’ descendant patch along its limited ’multi-scale needle ’ in the noisy image pyramid (see text). [sent-159, score-1.688]
</p><p>74 done to improve the resulting image; only a single patch was selected, and in a very limited search space – only along the multi-scale ‘needle’ descending from the noisy patch. [sent-160, score-0.576]
</p><p>75 A cleaner patch exists at a coarser pyramid level of the noisy image, somewhere directly ‘underneath ’ the noisy patch, at the same relative image coordinates. [sent-163, score-1.287]
</p><p>76 Note that the Oracle selection is restricted to an extremely limited search range, namely: For each noisy patch, select one of 60 ‘candidate’ patches (20 patches on its needle 3 pyramids). [sent-165, score-1.112]
</p><p>77 l space so af tainl y yp soesasribchle5 5 patches (25625, assuming 256 graylevels), or relative t5o × ×the 5 huge space o6f all natural clean image patches, or even relative to the space of all patches within the noisy image (hundreds of thousand of patches, all of which are noisy). [sent-167, score-1.328]
</p><p>78 As can be seen, for most noisy patches, the good representative patches tend to be in relatively low scales. [sent-175, score-0.622]
</p><p>79 This behavior is quite intuitive, as there is a tradeoff between two factors: On one hand, we introduce more inaccuracies in the clean signal as we go down the scale (increasing ‘bias’). [sent-177, score-0.487]
</p><p>80 On the other hand, the noise levels drop dramatically as we go down the scales (decreasing variance). [sent-178, score-0.337]
</p><p>81 The total patch error is the sum of these two factors: the signal error plus the noise (bias/variance tradeoff). [sent-179, score-0.465]
</p><p>82 Extremely few patches prefer to stay at the top scale (e. [sent-188, score-0.428]
</p><p>83 The majority of patches prefer the Isotropic pyramid (65% for σ = 25). [sent-192, score-0.492]
</p><p>84 These are mostly smooth patches (which are a large majority of the image). [sent-193, score-0.325]
</p><p>85 The remaining patches (mostly edges and smooth  patches near the edges) prefer the directional pyramids (19% prefer the x-pyramid and 15% prefer the y-pyramid for σ = 25). [sent-194, score-1.103]
</p><p>86 This is due to using directional pyramids only in the X and Y directions. [sent-199, score-0.335]
</p><p>87 Adding directional pyramids at various other angles is bound to improve the resulting image, both visually 1 1 1 1 1 19 9 98 6 6  (a) ‘Best scale’ vs. [sent-200, score-0.335]
</p><p>88 4 we explain how the directional pyramids can be extended to arbitrary angles, to provide better representatives for arbitrary patch orientations. [sent-206, score-0.687]
</p><p>89 Nev-  ertheless, most oriented patches still manage to find reasonable representatives in coarse levels ofthe isotropic pyramid (e. [sent-207, score-0.637]
</p><p>90 Hence, the above 3 pyramids alone (with their very limited search space) already provide a good representation of the clean image, with very low errors. [sent-211, score-0.542]
</p><p>91 It is important to note that the “best” Oracle patch (the “best” patch along the the multi-scale ‘needle’) is not necessarily the best ‘Nearest Neighbor’ (NN) of the clean patch. [sent-212, score-1.024]
</p><p>92 In fact, it is most likely that the best NN of the clean patch resides elsewhere in the noisy pyramid. [sent-213, score-0.962]
</p><p>93 Moreover, a better representative can surely be found in a huge collection of clean natural patches. [sent-214, score-0.482]
</p><p>94 Nevertheless, what our experiments indicate is that there exists a very good representative of the clean patch in a tiny well-defined search space: one of 60 patches. [sent-215, score-0.757]
</p><p>95 Estimating the Multi-Scale Patch Errors To mimic the oracle, we wish to estimate the mean squared error (MSE) between the clean patch p and each of the noisy patches along its corresponding ’multi-scale  needle’ in the noisy pyramid. [sent-225, score-1.492]
</p><p>96 The problem is that we do not have the original clean patch p, only its noisy version pN. [sent-226, score-0.951]
</p><p>97 We next show how the MSE errors with respect to the unknown clean patch p can be estimated using pN. [sent-227, score-0.715]
</p><p>98 Let pN = p + n be the noisy patch, where n ∼ N(0, σ2) is assumed= =to p p b+e Gna buess thiaen n nooisisye p (ait. [sent-228, score-0.24]
</p><p>99 Let psNc = psc nsc denote a coarsescale patch along the ‘multi-scale needle’ of pN, where psc denotes the coarser version of the clean patch p, and nsc is a coarser version of the original noise n (at scale “sc”). [sent-232, score-1.916]
</p><p>100 The exact noise realization in each patch is not known. [sent-246, score-0.415]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('clean', 0.373), ('psnc', 0.324), ('patch', 0.315), ('patches', 0.303), ('needle', 0.266), ('coarser', 0.251), ('noisy', 0.24), ('recurrence', 0.239), ('pyramids', 0.169), ('directional', 0.166), ('oracle', 0.153), ('denoising', 0.139), ('descendant', 0.133), ('scales', 0.118), ('pyramid', 0.113), ('strengthened', 0.111), ('noise', 0.1), ('cleaner', 0.096), ('isotropic', 0.083), ('pn', 0.069), ('subsample', 0.068), ('emerge', 0.062), ('recur', 0.055), ('prefer', 0.054), ('severe', 0.052), ('coarse', 0.052), ('sc', 0.051), ('signal', 0.05), ('nsc', 0.05), ('levels', 0.049), ('blur', 0.047), ('natural', 0.045), ('dramatically', 0.045), ('representative', 0.044), ('strong', 0.042), ('scale', 0.042), ('psc', 0.041), ('imagespecific', 0.041), ('coordinates', 0.039), ('obscured', 0.039), ('pulling', 0.039), ('representatives', 0.037), ('external', 0.035), ('tend', 0.035), ('resides', 0.034), ('repetitions', 0.034), ('property', 0.034), ('prior', 0.033), ('steerable', 0.033), ('relative', 0.032), ('subsampling', 0.032), ('mse', 0.032), ('variance', 0.03), ('superresolution', 0.03), ('internal', 0.029), ('stay', 0.029), ('contaminated', 0.029), ('across', 0.029), ('unknown', 0.027), ('psnr', 0.026), ('drop', 0.025), ('tiny', 0.025), ('naturally', 0.025), ('exploits', 0.025), ('blurring', 0.025), ('today', 0.024), ('namely', 0.024), ('phenomenon', 0.024), ('version', 0.023), ('benefit', 0.023), ('majority', 0.022), ('illposed', 0.022), ('nly', 0.022), ('sfc', 0.022), ('tacheh', 0.022), ('ofexperts', 0.022), ('frrmom', 0.022), ('otifv', 0.022), ('pand', 0.022), ('graphically', 0.022), ('rvse', 0.022), ('gna', 0.022), ('lssc', 0.022), ('thpere', 0.022), ('trhesep', 0.022), ('tradeoff', 0.022), ('along', 0.021), ('going', 0.021), ('drops', 0.021), ('surely', 0.02), ('waned', 0.02), ('tchoem', 0.02), ('aing', 0.02), ('aofs', 0.02), ('coarsescale', 0.02), ('zontak', 0.02), ('insc', 0.02), ('ecso', 0.02), ('factors', 0.02), ('pes', 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="393-tfidf-1" href="./cvpr-2013-Separating_Signal_from_Noise_Using_Patch_Recurrence_across_Scales.html">393 cvpr-2013-Separating Signal from Noise Using Patch Recurrence across Scales</a></p>
<p>Author: Maria Zontak, Inbar Mosseri, Michal Irani</p><p>Abstract: Recurrence of small clean image patches across different scales of a natural image has been successfully used for solving ill-posed problems in clean images (e.g., superresolution from a single image). In this paper we show how this multi-scale property can be extended to solve ill-posed problems under noisy conditions, such as image denoising. While clean patches are obscured by severe noise in the original scale of a noisy image, noise levels drop dramatically at coarser image scales. This allows for the unknown hidden clean patches to “naturally emerge ” in some coarser scale of the noisy image. We further show that patch recurrence across scales is strengthened when using directional pyramids (that blur and subsample only in one direction). Our statistical experiments show that for almost any noisy image patch (more than 99%), there exists a “good” clean version of itself at the same relative image coordinates in some coarser scale of the image.This is a strong phenomenon of noise-contaminated natural images, which can serve as a strong prior for separating the signal from the noise. Finally, incorporating this multi-scale prior into a simple denoising algorithm yields state-of-the-art denois- ing results.</p><p>2 0.18996705 <a title="393-tfidf-2" href="./cvpr-2013-Representing_Videos_Using_Mid-level_Discriminative_Patches.html">355 cvpr-2013-Representing Videos Using Mid-level Discriminative Patches</a></p>
<p>Author: Arpit Jain, Abhinav Gupta, Mikel Rodriguez, Larry S. Davis</p><p>Abstract: How should a video be represented? We propose a new representation for videos based on mid-level discriminative spatio-temporal patches. These spatio-temporal patches might correspond to a primitive human action, a semantic object, or perhaps a random but informative spatiotemporal patch in the video. What defines these spatiotemporal patches is their discriminative and representative properties. We automatically mine these patches from hundreds of training videos and experimentally demonstrate that these patches establish correspondence across videos and align the videos for label transfer techniques. Furthermore, these patches can be used as a discriminative vocabulary for action classification where they demonstrate stateof-the-art performance on UCF50 and Olympics datasets.</p><p>3 0.18832746 <a title="393-tfidf-3" href="./cvpr-2013-Fast_Patch-Based_Denoising_Using_Approximated_Patch_Geodesic_Paths.html">169 cvpr-2013-Fast Patch-Based Denoising Using Approximated Patch Geodesic Paths</a></p>
<p>Author: Xiaogang Chen, Sing Bing Kang, Jie Yang, Jingyi Yu</p><p>Abstract: Patch-based methods such as Non-Local Means (NLM) and BM3D have become the de facto gold standard for image denoising. The core of these approaches is to use similar patches within the image as cues for denoising. The operation usually requires expensive pair-wise patch comparisons. In this paper, we present a novel fast patch-based denoising technique based on Patch Geodesic Paths (PatchGP). PatchGPs treat image patches as nodes and patch differences as edge weights for computing the shortest (geodesic) paths. The path lengths can then be used as weights of the smoothing/denoising kernel. We first show that, for natural images, PatchGPs can be effectively approximated by minimum hop paths (MHPs) that generally correspond to Euclidean line paths connecting two patch nodes. To construct the denoising kernel, we further discretize the MHP search directions and use only patches along the search directions. Along each MHP, we apply a weightpropagation scheme to robustly and efficiently compute the path distance. To handle noise at multiple scales, we conduct wavelet image decomposition and apply PatchGP scheme at each scale. Comprehensive experiments show that our approach achieves comparable quality as the state-of-the-art methods such as NLM and BM3D but is a few orders of magnitude faster.</p><p>4 0.18762812 <a title="393-tfidf-4" href="./cvpr-2013-Fast_Image_Super-Resolution_Based_on_In-Place_Example_Regression.html">166 cvpr-2013-Fast Image Super-Resolution Based on In-Place Example Regression</a></p>
<p>Author: Jianchao Yang, Zhe Lin, Scott Cohen</p><p>Abstract: We propose a fast regression model for practical single image super-resolution based on in-place examples, by leveraging two fundamental super-resolution approaches— learning from an external database and learning from selfexamples. Our in-place self-similarity refines the recently proposed local self-similarity by proving that a patch in the upper scale image have good matches around its origin location in the lower scale image. Based on the in-place examples, a first-order approximation of the nonlinear mapping function from low- to high-resolution image patches is learned. Extensive experiments on benchmark and realworld images demonstrate that our algorithm can produce natural-looking results with sharp edges and preserved fine details, while the current state-of-the-art algorithms are prone to visual artifacts. Furthermore, our model can easily extend to deal with noise by combining the regression results on multiple in-place examples for robust estimation. The algorithm runs fast and is particularly useful for practical applications, where the input images typically contain diverse textures and they are potentially contaminated by noise or compression artifacts.</p><p>5 0.15156546 <a title="393-tfidf-5" href="./cvpr-2013-Handling_Noise_in_Single_Image_Deblurring_Using_Directional_Filters.html">198 cvpr-2013-Handling Noise in Single Image Deblurring Using Directional Filters</a></p>
<p>Author: Lin Zhong, Sunghyun Cho, Dimitris Metaxas, Sylvain Paris, Jue Wang</p><p>Abstract: State-of-the-art single image deblurring techniques are sensitive to image noise. Even a small amount of noise, which is inevitable in low-light conditions, can degrade the quality of blur kernel estimation dramatically. The recent approach of Tai and Lin [17] tries to iteratively denoise and deblur a blurry and noisy image. However, as we show in this work, directly applying image denoising methods often partially damages the blur information that is extracted from the input image, leading to biased kernel estimation. We propose a new method for handling noise in blind image deconvolution based on new theoretical and practical insights. Our key observation is that applying a directional low-pass filter to the input image greatly reduces the noise level, while preserving the blur information in the orthogonal direction to the filter. Based on this observation, our method applies a series of directional filters at different orientations to the input image, and estimates an accurate Radon transform of the blur kernel from each filtered image. Finally, we reconstruct the blur kernel using inverse Radon transform. Experimental results on synthetic and real data show that our algorithm achieves higher quality results than previous approaches on blurry and noisy images. 1</p><p>6 0.11224885 <a title="393-tfidf-6" href="./cvpr-2013-Texture_Enhanced_Image_Denoising_via_Gradient_Histogram_Preservation.html">427 cvpr-2013-Texture Enhanced Image Denoising via Gradient Histogram Preservation</a></p>
<p>7 0.10649917 <a title="393-tfidf-7" href="./cvpr-2013-Multi-source_Multi-scale_Counting_in_Extremely_Dense_Crowd_Images.html">299 cvpr-2013-Multi-source Multi-scale Counting in Extremely Dense Crowd Images</a></p>
<p>8 0.10481998 <a title="393-tfidf-8" href="./cvpr-2013-Depth_Super_Resolution_by_Rigid_Body_Self-Similarity_in_3D.html">115 cvpr-2013-Depth Super Resolution by Rigid Body Self-Similarity in 3D</a></p>
<p>9 0.10453233 <a title="393-tfidf-9" href="./cvpr-2013-A_Machine_Learning_Approach_for_Non-blind_Image_Deconvolution.html">17 cvpr-2013-A Machine Learning Approach for Non-blind Image Deconvolution</a></p>
<p>10 0.10406669 <a title="393-tfidf-10" href="./cvpr-2013-What_Makes_a_Patch_Distinct%3F.html">464 cvpr-2013-What Makes a Patch Distinct?</a></p>
<p>11 0.084944636 <a title="393-tfidf-11" href="./cvpr-2013-Harvesting_Mid-level_Visual_Concepts_from_Large-Scale_Internet_Images.html">200 cvpr-2013-Harvesting Mid-level Visual Concepts from Large-Scale Internet Images</a></p>
<p>12 0.0835208 <a title="393-tfidf-12" href="./cvpr-2013-Ensemble_Video_Object_Cut_in_Highly_Dynamic_Scenes.html">148 cvpr-2013-Ensemble Video Object Cut in Highly Dynamic Scenes</a></p>
<p>13 0.083210453 <a title="393-tfidf-13" href="./cvpr-2013-Learning_Structured_Hough_Voting_for_Joint_Object_Detection_and_Occlusion_Reasoning.html">256 cvpr-2013-Learning Structured Hough Voting for Joint Object Detection and Occlusion Reasoning</a></p>
<p>14 0.081066333 <a title="393-tfidf-14" href="./cvpr-2013-Sparse_Subspace_Denoising_for_Image_Manifolds.html">405 cvpr-2013-Sparse Subspace Denoising for Image Manifolds</a></p>
<p>15 0.077473387 <a title="393-tfidf-15" href="./cvpr-2013-Sparse_Quantization_for_Patch_Description.html">404 cvpr-2013-Sparse Quantization for Patch Description</a></p>
<p>16 0.077007964 <a title="393-tfidf-16" href="./cvpr-2013-Unsupervised_Salience_Learning_for_Person_Re-identification.html">451 cvpr-2013-Unsupervised Salience Learning for Person Re-identification</a></p>
<p>17 0.07697574 <a title="393-tfidf-17" href="./cvpr-2013-Robust_Region_Grouping_via_Internal_Patch_Statistics.html">366 cvpr-2013-Robust Region Grouping via Internal Patch Statistics</a></p>
<p>18 0.074499041 <a title="393-tfidf-18" href="./cvpr-2013-Deformable_Spatial_Pyramid_Matching_for_Fast_Dense_Correspondences.html">107 cvpr-2013-Deformable Spatial Pyramid Matching for Fast Dense Correspondences</a></p>
<p>19 0.074385934 <a title="393-tfidf-19" href="./cvpr-2013-Sampling_Strategies_for_Real-Time_Action_Recognition.html">378 cvpr-2013-Sampling Strategies for Real-Time Action Recognition</a></p>
<p>20 0.069487482 <a title="393-tfidf-20" href="./cvpr-2013-Supervised_Kernel_Descriptors_for_Visual_Recognition.html">421 cvpr-2013-Supervised Kernel Descriptors for Visual Recognition</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.119), (1, 0.023), (2, -0.004), (3, 0.061), (4, -0.033), (5, 0.093), (6, 0.0), (7, 0.015), (8, -0.012), (9, -0.066), (10, -0.012), (11, -0.019), (12, 0.008), (13, -0.011), (14, 0.052), (15, -0.025), (16, -0.016), (17, -0.058), (18, 0.136), (19, 0.033), (20, 0.092), (21, 0.13), (22, 0.009), (23, -0.16), (24, -0.056), (25, -0.014), (26, -0.1), (27, -0.188), (28, 0.023), (29, -0.129), (30, -0.134), (31, -0.202), (32, 0.108), (33, 0.045), (34, -0.023), (35, 0.066), (36, -0.041), (37, -0.088), (38, -0.087), (39, -0.052), (40, 0.082), (41, 0.017), (42, 0.091), (43, -0.066), (44, 0.081), (45, 0.134), (46, 0.003), (47, -0.022), (48, 0.072), (49, -0.037)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99112475 <a title="393-lsi-1" href="./cvpr-2013-Separating_Signal_from_Noise_Using_Patch_Recurrence_across_Scales.html">393 cvpr-2013-Separating Signal from Noise Using Patch Recurrence across Scales</a></p>
<p>Author: Maria Zontak, Inbar Mosseri, Michal Irani</p><p>Abstract: Recurrence of small clean image patches across different scales of a natural image has been successfully used for solving ill-posed problems in clean images (e.g., superresolution from a single image). In this paper we show how this multi-scale property can be extended to solve ill-posed problems under noisy conditions, such as image denoising. While clean patches are obscured by severe noise in the original scale of a noisy image, noise levels drop dramatically at coarser image scales. This allows for the unknown hidden clean patches to “naturally emerge ” in some coarser scale of the noisy image. We further show that patch recurrence across scales is strengthened when using directional pyramids (that blur and subsample only in one direction). Our statistical experiments show that for almost any noisy image patch (more than 99%), there exists a “good” clean version of itself at the same relative image coordinates in some coarser scale of the image.This is a strong phenomenon of noise-contaminated natural images, which can serve as a strong prior for separating the signal from the noise. Finally, incorporating this multi-scale prior into a simple denoising algorithm yields state-of-the-art denois- ing results.</p><p>2 0.87528265 <a title="393-lsi-2" href="./cvpr-2013-Fast_Patch-Based_Denoising_Using_Approximated_Patch_Geodesic_Paths.html">169 cvpr-2013-Fast Patch-Based Denoising Using Approximated Patch Geodesic Paths</a></p>
<p>Author: Xiaogang Chen, Sing Bing Kang, Jie Yang, Jingyi Yu</p><p>Abstract: Patch-based methods such as Non-Local Means (NLM) and BM3D have become the de facto gold standard for image denoising. The core of these approaches is to use similar patches within the image as cues for denoising. The operation usually requires expensive pair-wise patch comparisons. In this paper, we present a novel fast patch-based denoising technique based on Patch Geodesic Paths (PatchGP). PatchGPs treat image patches as nodes and patch differences as edge weights for computing the shortest (geodesic) paths. The path lengths can then be used as weights of the smoothing/denoising kernel. We first show that, for natural images, PatchGPs can be effectively approximated by minimum hop paths (MHPs) that generally correspond to Euclidean line paths connecting two patch nodes. To construct the denoising kernel, we further discretize the MHP search directions and use only patches along the search directions. Along each MHP, we apply a weightpropagation scheme to robustly and efficiently compute the path distance. To handle noise at multiple scales, we conduct wavelet image decomposition and apply PatchGP scheme at each scale. Comprehensive experiments show that our approach achieves comparable quality as the state-of-the-art methods such as NLM and BM3D but is a few orders of magnitude faster.</p><p>3 0.78390521 <a title="393-lsi-3" href="./cvpr-2013-Fast_Image_Super-Resolution_Based_on_In-Place_Example_Regression.html">166 cvpr-2013-Fast Image Super-Resolution Based on In-Place Example Regression</a></p>
<p>Author: Jianchao Yang, Zhe Lin, Scott Cohen</p><p>Abstract: We propose a fast regression model for practical single image super-resolution based on in-place examples, by leveraging two fundamental super-resolution approaches— learning from an external database and learning from selfexamples. Our in-place self-similarity refines the recently proposed local self-similarity by proving that a patch in the upper scale image have good matches around its origin location in the lower scale image. Based on the in-place examples, a first-order approximation of the nonlinear mapping function from low- to high-resolution image patches is learned. Extensive experiments on benchmark and realworld images demonstrate that our algorithm can produce natural-looking results with sharp edges and preserved fine details, while the current state-of-the-art algorithms are prone to visual artifacts. Furthermore, our model can easily extend to deal with noise by combining the regression results on multiple in-place examples for robust estimation. The algorithm runs fast and is particularly useful for practical applications, where the input images typically contain diverse textures and they are potentially contaminated by noise or compression artifacts.</p><p>4 0.71432775 <a title="393-lsi-4" href="./cvpr-2013-What_Makes_a_Patch_Distinct%3F.html">464 cvpr-2013-What Makes a Patch Distinct?</a></p>
<p>Author: Ran Margolin, Ayellet Tal, Lihi Zelnik-Manor</p><p>Abstract: What makes an object salient? Most previous work assert that distinctness is the dominating factor. The difference between the various algorithms is in the way they compute distinctness. Some focus on the patterns, others on the colors, and several add high-level cues and priors. We propose a simple, yet powerful, algorithm that integrates these three factors. Our key contribution is a novel and fast approach to compute pattern distinctness. We rely on the inner statistics of the patches in the image for identifying unique patterns. We provide an extensive evaluation and show that our approach outperforms all state-of-the-art methods on the five most commonly-used datasets.</p><p>5 0.67492872 <a title="393-lsi-5" href="./cvpr-2013-Texture_Enhanced_Image_Denoising_via_Gradient_Histogram_Preservation.html">427 cvpr-2013-Texture Enhanced Image Denoising via Gradient Histogram Preservation</a></p>
<p>Author: Wangmeng Zuo, Lei Zhang, Chunwei Song, David Zhang</p><p>Abstract: Image denoising is a classical yet fundamental problem in low level vision, as well as an ideal test bed to evaluate various statistical image modeling methods. One of the most challenging problems in image denoising is how to preserve the fine scale texture structures while removing noise. Various natural image priors, such as gradient based prior, nonlocal self-similarity prior, and sparsity prior, have been extensively exploited for noise removal. The denoising algorithms based on these priors, however, tend to smooth the detailed image textures, degrading the image visual quality. To address this problem, in this paper we propose a texture enhanced image denoising (TEID) method by enforcing the gradient distribution of the denoised image to be close to the estimated gradient distribution of the original image. A novel gradient histogram preservation (GHP) algorithm is developed to enhance the texture structures while removing noise. Our experimental results demonstrate that theproposed GHP based TEID can well preserve the texture features of the denoised images, making them look more natural.</p><p>6 0.59680998 <a title="393-lsi-6" href="./cvpr-2013-Learning_without_Human_Scores_for_Blind_Image_Quality_Assessment.html">266 cvpr-2013-Learning without Human Scores for Blind Image Quality Assessment</a></p>
<p>7 0.57174736 <a title="393-lsi-7" href="./cvpr-2013-Unsupervised_Salience_Learning_for_Person_Re-identification.html">451 cvpr-2013-Unsupervised Salience Learning for Person Re-identification</a></p>
<p>8 0.56380188 <a title="393-lsi-8" href="./cvpr-2013-A_Machine_Learning_Approach_for_Non-blind_Image_Deconvolution.html">17 cvpr-2013-A Machine Learning Approach for Non-blind Image Deconvolution</a></p>
<p>9 0.52496129 <a title="393-lsi-9" href="./cvpr-2013-Representing_Videos_Using_Mid-level_Discriminative_Patches.html">355 cvpr-2013-Representing Videos Using Mid-level Discriminative Patches</a></p>
<p>10 0.51079637 <a title="393-lsi-10" href="./cvpr-2013-HDR_Deghosting%3A_How_to_Deal_with_Saturation%3F.html">195 cvpr-2013-HDR Deghosting: How to Deal with Saturation?</a></p>
<p>11 0.49283159 <a title="393-lsi-11" href="./cvpr-2013-Sparse_Quantization_for_Patch_Description.html">404 cvpr-2013-Sparse Quantization for Patch Description</a></p>
<p>12 0.46594754 <a title="393-lsi-12" href="./cvpr-2013-Multipath_Sparse_Coding_Using_Hierarchical_Matching_Pursuit.html">304 cvpr-2013-Multipath Sparse Coding Using Hierarchical Matching Pursuit</a></p>
<p>13 0.45011342 <a title="393-lsi-13" href="./cvpr-2013-Multi-source_Multi-scale_Counting_in_Extremely_Dense_Crowd_Images.html">299 cvpr-2013-Multi-source Multi-scale Counting in Extremely Dense Crowd Images</a></p>
<p>14 0.42472118 <a title="393-lsi-14" href="./cvpr-2013-FrameBreak%3A_Dramatic_Image_Extrapolation_by_Guided_Shift-Maps.html">177 cvpr-2013-FrameBreak: Dramatic Image Extrapolation by Guided Shift-Maps</a></p>
<p>15 0.40759957 <a title="393-lsi-15" href="./cvpr-2013-Ensemble_Video_Object_Cut_in_Highly_Dynamic_Scenes.html">148 cvpr-2013-Ensemble Video Object Cut in Highly Dynamic Scenes</a></p>
<p>16 0.40239471 <a title="393-lsi-16" href="./cvpr-2013-Handling_Noise_in_Single_Image_Deblurring_Using_Directional_Filters.html">198 cvpr-2013-Handling Noise in Single Image Deblurring Using Directional Filters</a></p>
<p>17 0.39487058 <a title="393-lsi-17" href="./cvpr-2013-Rotation%2C_Scaling_and_Deformation_Invariant_Scattering_for_Texture_Discrimination.html">369 cvpr-2013-Rotation, Scaling and Deformation Invariant Scattering for Texture Discrimination</a></p>
<p>18 0.38963741 <a title="393-lsi-18" href="./cvpr-2013-Depth_Super_Resolution_by_Rigid_Body_Self-Similarity_in_3D.html">115 cvpr-2013-Depth Super Resolution by Rigid Body Self-Similarity in 3D</a></p>
<p>19 0.3849209 <a title="393-lsi-19" href="./cvpr-2013-Robust_Region_Grouping_via_Internal_Patch_Statistics.html">366 cvpr-2013-Robust Region Grouping via Internal Patch Statistics</a></p>
<p>20 0.37676981 <a title="393-lsi-20" href="./cvpr-2013-Harvesting_Mid-level_Visual_Concepts_from_Large-Scale_Internet_Images.html">200 cvpr-2013-Harvesting Mid-level Visual Concepts from Large-Scale Internet Images</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.151), (16, 0.011), (26, 0.069), (28, 0.022), (33, 0.208), (59, 0.011), (67, 0.029), (69, 0.033), (87, 0.099), (92, 0.272)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.79002005 <a title="393-lda-1" href="./cvpr-2013-Depth_Super_Resolution_by_Rigid_Body_Self-Similarity_in_3D.html">115 cvpr-2013-Depth Super Resolution by Rigid Body Self-Similarity in 3D</a></p>
<p>Author: unkown-author</p><p>Abstract: We tackle the problem of jointly increasing the spatial resolution and apparent measurement accuracy of an input low-resolution, noisy, and perhaps heavily quantized depth map. In stark contrast to earlier work, we make no use of ancillary data like a color image at the target resolution, multiple aligned depth maps, or a database of highresolution depth exemplars. Instead, we proceed by identifying and merging patch correspondences within the input depth map itself, exploiting patchwise scene self-similarity across depth such as repetition of geometric primitives or object symmetry. While the notion of ‘single-image ’ super resolution has successfully been applied in the context of color and intensity images, we are to our knowledge the first to present a tailored analogue for depth images. Rather than reason in terms of patches of 2D pixels as others have before us, our key contribution is to proceed by reasoning in terms of patches of 3D points, with matched patch pairs related by a respective 6 DoF rigid body motion in 3D. In support of obtaining a dense correspondence field in reasonable time, we introduce a new 3D variant of Patch- Match. A third contribution is a simple, yet effective patch upscaling and merging technique, which predicts sharp object boundaries at the target resolution. We show that our results are highly competitive with those of alternative techniques leveraging even a color image at the target resolution or a database of high-resolution depth exemplars.</p><p>same-paper 2 0.78679883 <a title="393-lda-2" href="./cvpr-2013-Separating_Signal_from_Noise_Using_Patch_Recurrence_across_Scales.html">393 cvpr-2013-Separating Signal from Noise Using Patch Recurrence across Scales</a></p>
<p>Author: Maria Zontak, Inbar Mosseri, Michal Irani</p><p>Abstract: Recurrence of small clean image patches across different scales of a natural image has been successfully used for solving ill-posed problems in clean images (e.g., superresolution from a single image). In this paper we show how this multi-scale property can be extended to solve ill-posed problems under noisy conditions, such as image denoising. While clean patches are obscured by severe noise in the original scale of a noisy image, noise levels drop dramatically at coarser image scales. This allows for the unknown hidden clean patches to “naturally emerge ” in some coarser scale of the noisy image. We further show that patch recurrence across scales is strengthened when using directional pyramids (that blur and subsample only in one direction). Our statistical experiments show that for almost any noisy image patch (more than 99%), there exists a “good” clean version of itself at the same relative image coordinates in some coarser scale of the image.This is a strong phenomenon of noise-contaminated natural images, which can serve as a strong prior for separating the signal from the noise. Finally, incorporating this multi-scale prior into a simple denoising algorithm yields state-of-the-art denois- ing results.</p><p>3 0.7227965 <a title="393-lda-3" href="./cvpr-2013-A_Video_Representation_Using_Temporal_Superpixels.html">29 cvpr-2013-A Video Representation Using Temporal Superpixels</a></p>
<p>Author: Jason Chang, Donglai Wei, John W. Fisher_III</p><p>Abstract: We develop a generative probabilistic model for temporally consistent superpixels in video sequences. In contrast to supervoxel methods, object parts in different frames are tracked by the same temporal superpixel. We explicitly model flow between frames with a bilateral Gaussian process and use this information to propagate superpixels in an online fashion. We consider four novel metrics to quantify performance of a temporal superpixel representation and demonstrate superior performance when compared to supervoxel methods.</p><p>4 0.69653678 <a title="393-lda-4" href="./cvpr-2013-Multi-scale_Curve_Detection_on_Surfaces.html">298 cvpr-2013-Multi-scale Curve Detection on Surfaces</a></p>
<p>Author: Michael Kolomenkin, Ilan Shimshoni, Ayellet Tal</p><p>Abstract: This paper extends to surfaces the multi-scale approach of edge detection on images. The common practice for detecting curves on surfaces requires the user to first select the scale of the features, apply an appropriate smoothing, and detect the edges on the smoothed surface. This approach suffers from two drawbacks. First, it relies on a hidden assumption that all the features on the surface are of the same scale. Second, manual user intervention is required. In this paper, we propose a general framework for automatically detecting the optimal scale for each point on the surface. We smooth the surface at each point according to this optimal scale and run the curve detection algorithm on the resulting surface. Our multi-scale algorithm solves the two disadvantages of the single-scale approach mentioned above. We demonstrate how to realize our approach on two commonly-used special cases: ridges & valleys and relief edges. In each case, the optimal scale is found in accordance with the mathematical definition of the curve.</p><p>5 0.69496363 <a title="393-lda-5" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>Author: Ian Endres, Kevin J. Shih, Johnston Jiaa, Derek Hoiem</p><p>Abstract: We propose a method to learn a diverse collection of discriminative parts from object bounding box annotations. Part detectors can be trained and applied individually, which simplifies learning and extension to new features or categories. We apply the parts to object category detection, pooling part detections within bottom-up proposed regions and using a boosted classifier with proposed sigmoid weak learners for scoring. On PASCAL VOC 2010, we evaluate the part detectors ’ ability to discriminate and localize annotated keypoints. Our detection system is competitive with the best-existing systems, outperforming other HOG-based detectors on the more deformable categories.</p><p>6 0.69230914 <a title="393-lda-6" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<p>7 0.69170195 <a title="393-lda-7" href="./cvpr-2013-Single_Image_Calibration_of_Multi-axial_Imaging_Systems.html">400 cvpr-2013-Single Image Calibration of Multi-axial Imaging Systems</a></p>
<p>8 0.69168758 <a title="393-lda-8" href="./cvpr-2013-Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking.html">285 cvpr-2013-Minimum Uncertainty Gap for Robust Visual Tracking</a></p>
<p>9 0.69157666 <a title="393-lda-9" href="./cvpr-2013-A_Minimum_Error_Vanishing_Point_Detection_Approach_for_Uncalibrated_Monocular_Images_of_Man-Made_Environments.html">19 cvpr-2013-A Minimum Error Vanishing Point Detection Approach for Uncalibrated Monocular Images of Man-Made Environments</a></p>
<p>10 0.69122213 <a title="393-lda-10" href="./cvpr-2013-Structure_Preserving_Object_Tracking.html">414 cvpr-2013-Structure Preserving Object Tracking</a></p>
<p>11 0.68993652 <a title="393-lda-11" href="./cvpr-2013-Physically_Plausible_3D_Scene_Tracking%3A_The_Single_Actor_Hypothesis.html">331 cvpr-2013-Physically Plausible 3D Scene Tracking: The Single Actor Hypothesis</a></p>
<p>12 0.68745148 <a title="393-lda-12" href="./cvpr-2013-Spatial_Inference_Machines.html">406 cvpr-2013-Spatial Inference Machines</a></p>
<p>13 0.68721986 <a title="393-lda-13" href="./cvpr-2013-Occlusion_Patterns_for_Object_Class_Detection.html">311 cvpr-2013-Occlusion Patterns for Object Class Detection</a></p>
<p>14 0.68703955 <a title="393-lda-14" href="./cvpr-2013-Voxel_Cloud_Connectivity_Segmentation_-_Supervoxels_for_Point_Clouds.html">458 cvpr-2013-Voxel Cloud Connectivity Segmentation - Supervoxels for Point Clouds</a></p>
<p>15 0.68702716 <a title="393-lda-15" href="./cvpr-2013-Handling_Noise_in_Single_Image_Deblurring_Using_Directional_Filters.html">198 cvpr-2013-Handling Noise in Single Image Deblurring Using Directional Filters</a></p>
<p>16 0.68696797 <a title="393-lda-16" href="./cvpr-2013-Modeling_Actions_through_State_Changes.html">287 cvpr-2013-Modeling Actions through State Changes</a></p>
<p>17 0.68635273 <a title="393-lda-17" href="./cvpr-2013-Boundary_Cues_for_3D_Object_Shape_Recovery.html">71 cvpr-2013-Boundary Cues for 3D Object Shape Recovery</a></p>
<p>18 0.68620414 <a title="393-lda-18" href="./cvpr-2013-Intrinsic_Scene_Properties_from_a_Single_RGB-D_Image.html">227 cvpr-2013-Intrinsic Scene Properties from a Single RGB-D Image</a></p>
<p>19 0.68580264 <a title="393-lda-19" href="./cvpr-2013-Robust_Estimation_of_Nonrigid_Transformation_for_Point_Set_Registration.html">360 cvpr-2013-Robust Estimation of Nonrigid Transformation for Point Set Registration</a></p>
<p>20 0.68519139 <a title="393-lda-20" href="./cvpr-2013-GeoF%3A_Geodesic_Forests_for_Learning_Coupled_Predictors.html">186 cvpr-2013-GeoF: Geodesic Forests for Learning Coupled Predictors</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
