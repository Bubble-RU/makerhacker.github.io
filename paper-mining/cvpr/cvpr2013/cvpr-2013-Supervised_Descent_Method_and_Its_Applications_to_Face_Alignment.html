<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>420 cvpr-2013-Supervised Descent Method and Its Applications to Face Alignment</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-420" href="#">cvpr2013-420</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>420 cvpr-2013-Supervised Descent Method and Its Applications to Face Alignment</h1>
<br/><p>Source: <a title="cvpr-2013-420-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Xiong_Supervised_Descent_Method_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Xuehan Xiong, Fernando De_la_Torre</p><p>Abstract: Many computer vision problems (e.g., camera calibration, image alignment, structure from motion) are solved through a nonlinear optimization method. It is generally accepted that 2nd order descent methods are the most robust, fast and reliable approaches for nonlinear optimization ofa general smoothfunction. However, in the context of computer vision, 2nd order descent methods have two main drawbacks: (1) The function might not be analytically differentiable and numerical approximations are impractical. (2) The Hessian might be large and not positive definite. To address these issues, thispaperproposes a Supervised Descent Method (SDM) for minimizing a Non-linear Least Squares (NLS) function. During training, the SDM learns a sequence of descent directions that minimizes the mean of NLS functions sampled at different points. In testing, SDM minimizes the NLS objective using the learned descent directions without computing the Jacobian nor the Hessian. We illustrate the benefits of our approach in synthetic and real examples, and show how SDM achieves state-ofthe-art performance in the problem of facial feature detec- tion. The code is available at www. .human sen sin g. . cs . cmu . edu/in t ra fa ce.</p><p>Reference: <a title="cvpr-2013-420-reference" href="../cvpr2013_reference/cvpr-2013-Supervised_Descent_Method_and_Its_Applications_to_Face_Alignment_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 It is generally accepted that 2nd order descent methods are the most robust, fast and reliable approaches for nonlinear optimization ofa general smoothfunction. [sent-6, score-0.171]
</p><p>2 However, in the context of computer vision, 2nd order descent methods have two main drawbacks: (1) The function might not be analytically differentiable and numerical approximations are impractical. [sent-7, score-0.216]
</p><p>3 During training, the SDM learns a sequence of descent directions that minimizes the mean of NLS functions sampled at different points. [sent-10, score-0.268]
</p><p>4 In testing, SDM minimizes the NLS objective using the learned descent directions without computing the Jacobian nor the Hessian. [sent-11, score-0.214]
</p><p>5 We illustrate the benefits of our approach in synthetic and real examples, and show how SDM achieves state-ofthe-art performance in the problem of facial feature detec-  tion. [sent-12, score-0.132]
</p><p>6 dWoGhread iesnthe  learns from training data a set of generic descent directions {Rk}. [sent-36, score-0.257]
</p><p>7 p× , Newton’s method creates a sequence of updates as xk+1 = xk (xk)Jf (xk) , (1) where H(xk) ∈ ? [sent-49, score-0.163]
</p><p>8 555333002  However, when applying Newton’s method to computer vision problems, three main problems arise: (1) The Hessian is positive definite at the local minimum, but it might not be positive definite elsewhere; therefore, the Newton steps might not be taken in the descent direction. [sent-57, score-0.177]
</p><p>9 For instance, consider the case of image alignment using SIFT [21] features, where the SIFT can be seen as a non-differentiable image operator. [sent-60, score-0.101]
</p><p>10 In order to address previous limitations, this paper proposes a Supervised Descent Method (SDM) that learns the descent directions in a supervised manner. [sent-64, score-0.233]
</p><p>11 The training data consists of a set of functions {f(x, yi)} sampled at different locations yi (i. [sent-79, score-0.078]
</p><p>12 Using tfherise training ed)at wa,h SeDreM th leea mrnisn a sear {iexs∗ of parameter updates, which incrementally, minimizes the mean of all NLS functions in training. [sent-82, score-0.079]
</p><p>13 In testing, given an unseen y, an update is generated by projecting yspecific components onto the learned generic directions Rk. [sent-87, score-0.139]
</p><p>14 We illustrate the benefits of SDM on analytic functions, and in the problem of facial feature detection and tracking. [sent-88, score-0.205]
</p><p>15 We show how SDM improves state-of-the-art performance for facial feature detection in two “face in the wild” databases [26, 4] and demonstrate extremely good performance tracking faces in the YouTube celebrity database [20]. [sent-89, score-0.24]
</p><p>16 Previous work  This section reviews previous work on face alignment. [sent-91, score-0.101]
</p><p>17 Parameterized Appearance Models (PAMs), such as Active Appearance Models [11, 14, 2], Morphable Models [6, 19], Eigentracking [5], and template tracking [22, 30] build an object appearance and shape representation by computing Principal Component Analysis (PCA) on a set of manually labeled data. [sent-92, score-0.128]
</p><p>18 2a illustrates an image labeled with p landmarks (p = 66 in this case). [sent-94, score-0.155]
</p><p>19 Given an image d, PAMs alignment algorithms optimize Eq. [sent-138, score-0.101]
</p><p>20 [11] proposed to fit AAMs by learning a linear regression between the increment of motion parameters Δp and the appearance differences Δd. [sent-146, score-0.175]
</p><p>21 The linear regressor is a numerical approximation of the Jacobian [11]. [sent-147, score-0.1]
</p><p>22 Gradient Boosting, first introduced by Friedman [16], has become one of the most popular regressors in face alignment because of its efficiency and the ability to model nonlinearities. [sent-149, score-0.247]
</p><p>23 [29] showed that using boosted regression for AAM discriminative fitting significantly improved over the original lin-  ∂d(f∂(xp,p))  ear formulation. [sent-151, score-0.125]
</p><p>24 b) Mean landmarks, x0, initialized using the face detector. [sent-155, score-0.101]
</p><p>25 a new weak regressor is learned at each iteration but also the features are re-computed at the latest estimate of the landmark location. [sent-156, score-0.136]
</p><p>26 Beyond the gradient boosting, Rivera and Martinez [24] explored kernel regression to map from image features directly to landmark location achieving surprising results for low-resolution images. [sent-157, score-0.171]
</p><p>27 [12] investigated Random Forest regressors in the context of face alignment. [sent-159, score-0.146]
</p><p>28 [25] proposed to learn a regression model in the continuous domain to efficiently and uniformly sample the motion space. [sent-161, score-0.109]
</p><p>29 [32] learned a set of independent linear predictor for different local motion  and then a subset of them is chosen during tracking. [sent-163, score-0.079]
</p><p>30 Part-based deformable models perform alignment by maximizing the posterior likelihood of part locations given an image. [sent-164, score-0.123]
</p><p>31 Zhu and Ramanan [3 1] assumed that the face shape is a tree structure (for fast inference), and used a part-based model for face detection, pose estimation, and facial feature detection. [sent-176, score-0.387]
</p><p>32 Supervised Descent Method (SDM) This section describes the SDM in the context of face alignment, and unifies discriminative methods with PAMs. [sent-178, score-0.125]
</p><p>33 During training, we will assume that the correct p landmarks (in our case 66) are known, and we will refer to them as x∗ (see Fig. [sent-190, score-0.109]
</p><p>34 Also, to reproduce the testing scenario, we ran the face detector on the training images to provide an initial configuration of the landmarks (x0), which corresponds to an average shape (see Fig. [sent-192, score-0.294]
</p><p>35 In this setting, face alignment can be framed as minimizing the following function over Δx f(x0  + Δx)  = ? [sent-194, score-0.226]
</p><p>36 3 we do not learn any model of shape or appearance beforehand from training data. [sent-202, score-0.087]
</p><p>37 For the shape, our model will be a non-parametric one, an∗d we will optimize the landmark locations x ∈ ? [sent-207, score-0.091]
</p><p>38 Recall tohpatti mini tzrea dthieti olannadl mPAarMks lo, tchatei non-rigid motion is modeled as a linear combination of shape bases learned by computing PCA on a training set. [sent-209, score-0.142]
</p><p>39 Second, we use SIFT features extracted from patches around the landmarks to achieve a ro-  bust representation against illumination. [sent-213, score-0.109]
</p><p>40 The goal of SDM is to learn a series of descent directions and re-scaling factors (done by the Hessian in the case of Newton’s method) such that it produces a sequence of updates (xk+1 = xk + Δxk ) starting from x0 that converges to x∗ in the training data. [sent-219, score-0.398]
</p><p>41 The computation of this descent direction requires the function h to be twice differentiable or expensive numerical approximations for the Jacobian and Hessian. [sent-233, score-0.245]
</p><p>42 In our supervised setting, we will directly estimate R0 from training data by learning a linear regression between Δx∗ = x∗ − x0 and Δφ0. [sent-234, score-0.161]
</p><p>43 To∗ use the descent direction during testing, we will not use the information of φ∗ for training. [sent-239, score-0.119]
</p><p>44 To deal with non-quadratic functions, the SDM will generate a sequence of descent directions. [sent-245, score-0.143]
</p><p>45 For a particular image, the Newton method generates a sequence of updates along the imagespecific gradient directions, xk  =  xk−1  − 2H−1Jh? [sent-246, score-0.222]
</p><p>46 In contrast, SDM will learn a sequence of generic descent directions {Rk} and lbeiaasrn nte arm sesq {ubenk}c,e xk  =  xk−1  + Rk−1φk−1 + bk−1 ,  (8)  such that the succession ofxk converges to x∗ for all images in the training set. [sent-249, score-0.396]
</p><p>47 Learning for SDM This section illustrates how to learn Rk, bk from training data. [sent-252, score-0.116]
</p><p>48 Assume that we are given a set of face images {di} adnatda . [sent-253, score-0.101]
</p><p>49 la Fndo-r marks xi0, R0 and b0 are obtained by minimizing the expected loss between the predicted and the optimal landmark displacement under many possible initializations. [sent-256, score-0.123]
</p><p>50 We assume that xi0 is sampled f rxom a Normal distribution whose parameters capture the variance of a face detector. [sent-262, score-0.101]
</p><p>51 The subsequent Rk , bk can be learned as follows. [sent-270, score-0.087]
</p><p>52 More explicitly, after Rk−1 , bk−1 is learned, we update the current landmarks estimate xik using Eq. [sent-273, score-0.192]
</p><p>53 We generate a new set of training data by computing the new optimal parameter update Δxki = xi −xik and the new feature vector, φik = h(di (xik)). [sent-275, score-0.09]
</p><p>54 Rk a∗n−d bxk can be learned from a new linear regressor in the new training set by minimizing  arRgkm,bkin? [sent-276, score-0.141]
</p><p>55 (11)  The error monotonically decreases as a function of the number of regressors added. [sent-281, score-0.075]
</p><p>56 Recent work on boosted regres-  sion [27, 29, 15, 10] learns a set of weak regressors to model the relation between φ and Δx. [sent-286, score-0.102]
</p><p>57 SDM is developed to solve a general NLS problems while boosted regression is a greedy method to approximate the function mapping from φ to Δx. [sent-287, score-0.101]
</p><p>58 In the original gradient boosting formulation [16], feature vectors are fixed throughout the optimization, while [15, 10] re-sample the features at the updated landmarks for training different weak regressors. [sent-288, score-0.2]
</p><p>59 Although they have shown improvements using those re-sampled features, feature re-generation in regression is not well understood and invalidates some properties of gradient boosting. [sent-289, score-0.102]
</p><p>60 In SDM, the linear regressor and feature re-generation come up naturally in our derivation from Newton method. [sent-290, score-0.084]
</p><p>61 7 illustrates that a Newton update can be expressed as a linear combination of the feature differences between the one extracted at current landmark locations and the template. [sent-292, score-0.193]
</p><p>62 In previous work, it was unclear what the alignment error function is for discriminative methods. [sent-293, score-0.155]
</p><p>63 In the second experiment, we tested the performance of the SDM in the problem of facial feature detection in two standard databases. [sent-311, score-0.132]
</p><p>64 Finally, in the third experiment we illustrate how the method can be applied to facial feature tracking. [sent-312, score-0.132]
</p><p>65 SDM on analytic scalar functions This experiment compares the performance in speed and accuracy of the SDM against the Newton’s method on four analytic functions. [sent-315, score-0.171]
</p><p>66 186420Nehw(xto)n=S6extpS8NDewMton10  Figure 3: Normalized error versus iterations on four analytic (see Table 1) functions using the Newton method and SDM. [sent-345, score-0.128]
</p><p>67 Not surprisingly, when the Newton method converges it provides more accurate estimation than SDM, because SDM uses a generic descent direction. [sent-347, score-0.187]
</p><p>68 , h is linear function of x), SDM will converge in one iteration, because the average gradient evaluated at different locations will be the same for linear functions. [sent-350, score-0.107]
</p><p>69 Facial feature detection This section reports experiments on facial feature detection in two “face in the wild” datasets, and compares SDM with state-of-the-art methods. [sent-354, score-0.132]
</p><p>70 The two face databases are the LFPW dataset1 [4] and the LFW-A&C; dataset [26]. [sent-355, score-0.101]
</p><p>71 First the face is detected using the OpenCV face detector [7]. [sent-357, score-0.202]
</p><p>72 The evaluation  ×  is performed on the images in which a face can be detected. [sent-358, score-0.101]
</p><p>73 The initial shape estimate is given by centering the mean face at the normalized square. [sent-362, score-0.133]
</p><p>74 The translational and scaling differences between the initial and true landmark locations are also computed, and their means and variances are used for generating Monte Carlo samples in Eq. [sent-363, score-0.134]
</p><p>75 LFPW dataset contains images downloaded from the web that exhibit large variations in pose, illumination, and facial expression. [sent-369, score-0.132]
</p><p>76 Note that  SDM is different from the AAM trained in a discriminative manner with linear regression [11], because we do not learn any shape or appearance model (it is non-parametric). [sent-380, score-0.173]
</p><p>77 The recently proposed method in [10] is based on boosted regression with pose-indexed features. [sent-385, score-0.101]
</p><p>78 Most errors are caused by gradient feature’s incapability to distinguish between similar facial parts and occluding objects (e. [sent-394, score-0.16]
</p><p>79 Each image is annotated with the same 66 landmarks shown in Fig. [sent-398, score-0.109]
</p><p>80 Root mean squared error (RMSE) is used to measure the alignment accuracy. [sent-404, score-0.131]
</p><p>81 s aPR fiAxe reported a m50ed ×ian 2 alignment error o isf 2. [sent-406, score-0.131]
</p><p>82 Facial feature tracking  This section tested the use of SDM for facial feature tracking. [sent-415, score-0.181]
</p><p>83 We trained our model with 66 landmarks on MPIE [17] and LFW-A&C; datasets. [sent-431, score-0.109]
</p><p>84 It indicates that in two consecutive frames the probability of a tracked face shifting more than 20 pixels or scaling more than 10% is less than 5%. [sent-434, score-0.101]
</p><p>85 The dataset is labeled with the same 66 landmarks of our trained model except the 17 jaw points that are defined slightly different (See  Fig. [sent-438, score-0.132]
</p><p>86 To make sense of the numerical results, in the same figure we also show one tracking result overlayed with ground truth and in this example it gives us a RMS error of 5. [sent-444, score-0.118]
</p><p>87 Also, the person-specific AAM gives unreliable results when the subject’s face is partially occluded while SDM still provides a robust estimation (See Fig. [sent-447, score-0.101]
</p><p>88 It was released as a dataset for face tracking and recognition so no labeled facial landmarks are given. [sent-452, score-0.414]
</p><p>89 From the videos, we can observe that SDM can reliably track facial landmarks with large pose (±45◦ yaw, ±eli9a0b◦l yro tlrla acnkd ,f a±ci3a0l◦ l pitch), rokcscl wuistihon la argnde i pllousmei (n±at4io5n changes. [sent-455, score-0.311]
</p><p>90 SDM learns in a supervised manner generic descent directions, and is able to overcome many drawbacks of second order optimization schemes, such as nondifferentiability and expensive computation of the Jacobians and Hessians. [sent-460, score-0.235]
</p><p>91 We have illustrated the benefits of our approach in the minimization of analytic functions, and in the problem of facial feature detection and tracking. [sent-462, score-0.205]
</p><p>92 We have shown how SDM outperforms state-of-the-art approaches in facial feature detection and tracking in challenging databases. [sent-463, score-0.181]
</p><p>93 Beyond the SDM, an important contribution of this work in the context of algorithms for image alignment is to propose the error function of Eq. [sent-464, score-0.131]
</p><p>94 Existing discriminative methods for facial alignment pose the problem as a regression one, but lack a well-defined alignment error function. [sent-466, score-0.483]
</p><p>95 3 allows to establish a direct connection with existing PAMs for face alignment, and apply existing algorithms for minimizing it such as Gauss-Newton (or the supervised version proposed in this paper). [sent-468, score-0.162]
</p><p>96 Boix for the implementation of the linear and kernel regression method in the fall of 2008. [sent-473, score-0.093]
</p><p>97 Damped newton algorithms for matrix factorization with missing data. [sent-537, score-0.276]
</p><p>98 Robust and accurate shape model fitting using random forest regression voting. [sent-566, score-0.106]
</p><p>99 Face detection, pose estimation, and landmark localization in the wild. [sent-674, score-0.09]
</p><p>100 The first two rows show faces with strong changes in pose and illumination, and faces partially occluded. [sent-683, score-0.081]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('sdm', 0.778), ('newton', 0.276), ('nls', 0.168), ('facial', 0.132), ('descent', 0.119), ('hessian', 0.117), ('landmarks', 0.109), ('xk', 0.107), ('alignment', 0.101), ('lfpw', 0.101), ('face', 0.101), ('saragih', 0.078), ('pams', 0.076), ('jacobian', 0.074), ('regression', 0.074), ('jf', 0.073), ('analytic', 0.073), ('rk', 0.069), ('landmark', 0.069), ('bk', 0.062), ('aams', 0.059), ('ced', 0.054), ('aam', 0.052), ('tracking', 0.049), ('torre', 0.049), ('directions', 0.047), ('celebrities', 0.047), ('xik', 0.046), ('regressors', 0.045), ('morphable', 0.044), ('rms', 0.042), ('regressor', 0.042), ('cootes', 0.041), ('numerical', 0.039), ('converges', 0.038), ('rivera', 0.038), ('txep', 0.038), ('zimmermann', 0.038), ('pca', 0.038), ('update', 0.037), ('supervised', 0.037), ('youtube', 0.035), ('motion', 0.035), ('nonlinear', 0.033), ('updates', 0.032), ('boosting', 0.032), ('shape', 0.032), ('training', 0.031), ('pra', 0.031), ('imagespecific', 0.031), ('approximations', 0.031), ('error', 0.03), ('sift', 0.03), ('faces', 0.03), ('learns', 0.03), ('generic', 0.03), ('la', 0.03), ('twice', 0.029), ('tresadern', 0.029), ('celebrity', 0.029), ('eigentracking', 0.029), ('definite', 0.029), ('di', 0.028), ('gradient', 0.028), ('differentiable', 0.027), ('erf', 0.027), ('boosted', 0.027), ('stays', 0.026), ('wild', 0.025), ('functions', 0.025), ('learned', 0.025), ('ua', 0.024), ('discriminative', 0.024), ('minimizing', 0.024), ('appearance', 0.024), ('sequence', 0.024), ('labeled', 0.023), ('minimizes', 0.023), ('illustrates', 0.023), ('jd', 0.023), ('xto', 0.023), ('differences', 0.023), ('derivation', 0.023), ('xi', 0.022), ('opencv', 0.022), ('locations', 0.022), ('pose', 0.021), ('wx', 0.021), ('testing', 0.021), ('matthews', 0.02), ('sequences', 0.02), ('translational', 0.02), ('carlo', 0.019), ('converge', 0.019), ('observe', 0.019), ('optimization', 0.019), ('linear', 0.019), ('doll', 0.019), ('ks', 0.019), ('constrained', 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="420-tfidf-1" href="./cvpr-2013-Supervised_Descent_Method_and_Its_Applications_to_Face_Alignment.html">420 cvpr-2013-Supervised Descent Method and Its Applications to Face Alignment</a></p>
<p>Author: Xuehan Xiong, Fernando De_la_Torre</p><p>Abstract: Many computer vision problems (e.g., camera calibration, image alignment, structure from motion) are solved through a nonlinear optimization method. It is generally accepted that 2nd order descent methods are the most robust, fast and reliable approaches for nonlinear optimization ofa general smoothfunction. However, in the context of computer vision, 2nd order descent methods have two main drawbacks: (1) The function might not be analytically differentiable and numerical approximations are impractical. (2) The Hessian might be large and not positive definite. To address these issues, thispaperproposes a Supervised Descent Method (SDM) for minimizing a Non-linear Least Squares (NLS) function. During training, the SDM learns a sequence of descent directions that minimizes the mean of NLS functions sampled at different points. In testing, SDM minimizes the NLS objective using the learned descent directions without computing the Jacobian nor the Hessian. We illustrate the benefits of our approach in synthetic and real examples, and show how SDM achieves state-ofthe-art performance in the problem of facial feature detec- tion. The code is available at www. .human sen sin g. . cs . cmu . edu/in t ra fa ce.</p><p>2 0.14997493 <a title="420-tfidf-2" href="./cvpr-2013-Facial_Feature_Tracking_Under_Varying_Facial_Expressions_and_Face_Poses_Based_on_Restricted_Boltzmann_Machines.html">161 cvpr-2013-Facial Feature Tracking Under Varying Facial Expressions and Face Poses Based on Restricted Boltzmann Machines</a></p>
<p>Author: Yue Wu, Zuoguan Wang, Qiang Ji</p><p>Abstract: Facial feature tracking is an active area in computer vision due to its relevance to many applications. It is a nontrivial task, sincefaces may have varyingfacial expressions, poses or occlusions. In this paper, we address this problem by proposing a face shape prior model that is constructed based on the Restricted Boltzmann Machines (RBM) and their variants. Specifically, we first construct a model based on Deep Belief Networks to capture the face shape variations due to varying facial expressions for near-frontal view. To handle pose variations, the frontal face shape prior model is incorporated into a 3-way RBM model that could capture the relationship between frontal face shapes and non-frontal face shapes. Finally, we introduce methods to systematically combine the face shape prior models with image measurements of facial feature points. Experiments on benchmark databases show that with the proposed method, facial feature points can be tracked robustly and accurately even if faces have significant facial expressions and poses.</p><p>3 0.1327744 <a title="420-tfidf-3" href="./cvpr-2013-Blessing_of_Dimensionality%3A_High-Dimensional_Feature_and_Its_Efficient_Compression_for_Face_Verification.html">64 cvpr-2013-Blessing of Dimensionality: High-Dimensional Feature and Its Efficient Compression for Face Verification</a></p>
<p>Author: Dong Chen, Xudong Cao, Fang Wen, Jian Sun</p><p>Abstract: Making a high-dimensional (e.g., 100K-dim) feature for face recognition seems not a good idea because it will bring difficulties on consequent training, computation, and storage. This prevents further exploration of the use of a highdimensional feature. In this paper, we study the performance of a highdimensional feature. We first empirically show that high dimensionality is critical to high performance. A 100K-dim feature, based on a single-type Local Binary Pattern (LBP) descriptor, can achieve significant improvements over both its low-dimensional version and the state-of-the-art. We also make the high-dimensional feature practical. With our proposed sparse projection method, named rotated sparse regression, both computation and model storage can be reduced by over 100 times without sacrificing accuracy quality.</p><p>4 0.12209017 <a title="420-tfidf-4" href="./cvpr-2013-Detecting_and_Aligning_Faces_by_Image_Retrieval.html">119 cvpr-2013-Detecting and Aligning Faces by Image Retrieval</a></p>
<p>Author: Xiaohui Shen, Zhe Lin, Jonathan Brandt, Ying Wu</p><p>Abstract: Detecting faces in uncontrolled environments continues to be a challenge to traditional face detection methods[24] due to the large variation in facial appearances, as well as occlusion and clutter. In order to overcome these challenges, we present a novel and robust exemplarbased face detector that integrates image retrieval and discriminative learning. A large database of faces with bounding rectangles and facial landmark locations is collected, and simple discriminative classifiers are learned from each of them. A voting-based method is then proposed to let these classifiers cast votes on the test image through an efficient image retrieval technique. As a result, faces can be very efficiently detected by selecting the modes from the voting maps, without resorting to exhaustive sliding window-style scanning. Moreover, due to the exemplar-based framework, our approach can detect faces under challenging conditions without explicitly modeling their variations. Evaluation on two public benchmark datasets shows that our new face detection approach is accurate and efficient, and achieves the state-of-the-art performance. We further propose to use image retrieval for face validation (in order to remove false positives) and for face alignment/landmark localization. The same methodology can also be easily generalized to other facerelated tasks, such as attribute recognition, as well as general object detection.</p><p>5 0.11639147 <a title="420-tfidf-5" href="./cvpr-2013-Robust_Discriminative_Response_Map_Fitting_with_Constrained_Local_Models.html">359 cvpr-2013-Robust Discriminative Response Map Fitting with Constrained Local Models</a></p>
<p>Author: Akshay Asthana, Stefanos Zafeiriou, Shiyang Cheng, Maja Pantic</p><p>Abstract: We present a novel discriminative regression based approach for the Constrained Local Models (CLMs) framework, referred to as the Discriminative Response Map Fitting (DRMF) method, which shows impressive performance in the generic face fitting scenario. The motivation behind this approach is that, unlike the holistic texture based features used in the discriminative AAM approaches, the response map can be represented by a small set of parameters and these parameters can be very efficiently used for reconstructing unseen response maps. Furthermore, we show that by adopting very simple off-the-shelf regression techniques, it is possible to learn robust functions from response maps to the shape parameters updates. The experiments, conducted on Multi-PIE, XM2VTS and LFPW database, show that the proposed DRMF method outperforms stateof-the-art algorithms for the task of generic face fitting. Moreover, the DRMF method is computationally very efficient and is real-time capable. The current MATLAB implementation takes 1second per image. To facilitate future comparisons, we release the MATLAB code1 and the pretrained models for research purposes.</p><p>6 0.1064721 <a title="420-tfidf-6" href="./cvpr-2013-Towards_Pose_Robust_Face_Recognition.html">438 cvpr-2013-Towards Pose Robust Face Recognition</a></p>
<p>7 0.099888384 <a title="420-tfidf-7" href="./cvpr-2013-Single-Sample_Face_Recognition_with_Image_Corruption_and_Misalignment_via_Sparse_Illumination_Transfer.html">399 cvpr-2013-Single-Sample Face Recognition with Image Corruption and Misalignment via Sparse Illumination Transfer</a></p>
<p>8 0.096972041 <a title="420-tfidf-8" href="./cvpr-2013-Correlation_Filters_for_Object_Alignment.html">96 cvpr-2013-Correlation Filters for Object Alignment</a></p>
<p>9 0.096430384 <a title="420-tfidf-9" href="./cvpr-2013-Capturing_Complex_Spatio-temporal_Relations_among_Facial_Muscles_for_Facial_Expression_Recognition.html">77 cvpr-2013-Capturing Complex Spatio-temporal Relations among Facial Muscles for Facial Expression Recognition</a></p>
<p>10 0.095059365 <a title="420-tfidf-10" href="./cvpr-2013-Exemplar-Based_Face_Parsing.html">152 cvpr-2013-Exemplar-Based Face Parsing</a></p>
<p>11 0.090854891 <a title="420-tfidf-11" href="./cvpr-2013-Probabilistic_Elastic_Matching_for_Pose_Variant_Face_Verification.html">338 cvpr-2013-Probabilistic Elastic Matching for Pose Variant Face Verification</a></p>
<p>12 0.089229636 <a title="420-tfidf-12" href="./cvpr-2013-Face_Recognition_in_Movie_Trailers_via_Mean_Sequence_Sparse_Representation-Based_Classification.html">160 cvpr-2013-Face Recognition in Movie Trailers via Mean Sequence Sparse Representation-Based Classification</a></p>
<p>13 0.087328285 <a title="420-tfidf-13" href="./cvpr-2013-Expressive_Visual_Text-to-Speech_Using_Active_Appearance_Models.html">159 cvpr-2013-Expressive Visual Text-to-Speech Using Active Appearance Models</a></p>
<p>14 0.082641035 <a title="420-tfidf-14" href="./cvpr-2013-Constrained_Clustering_and_Its_Application_to_Face_Clustering_in_Videos.html">92 cvpr-2013-Constrained Clustering and Its Application to Face Clustering in Videos</a></p>
<p>15 0.079090931 <a title="420-tfidf-15" href="./cvpr-2013-Fusing_Robust_Face_Region_Descriptors_via_Multiple_Metric_Learning_for_Face_Recognition_in_the_Wild.html">182 cvpr-2013-Fusing Robust Face Region Descriptors via Multiple Metric Learning for Face Recognition in the Wild</a></p>
<p>16 0.073417962 <a title="420-tfidf-16" href="./cvpr-2013-Structured_Face_Hallucination.html">415 cvpr-2013-Structured Face Hallucination</a></p>
<p>17 0.072467536 <a title="420-tfidf-17" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<p>18 0.072182678 <a title="420-tfidf-18" href="./cvpr-2013-Hypergraphs_for_Joint_Multi-view_Reconstruction_and_Multi-object_Tracking.html">209 cvpr-2013-Hypergraphs for Joint Multi-view Reconstruction and Multi-object Tracking</a></p>
<p>19 0.069615424 <a title="420-tfidf-19" href="./cvpr-2013-Self-Paced_Learning_for_Long-Term_Tracking.html">386 cvpr-2013-Self-Paced Learning for Long-Term Tracking</a></p>
<p>20 0.068566389 <a title="420-tfidf-20" href="./cvpr-2013-Video_Editing_with_Temporal%2C_Spatial_and_Appearance_Consistency.html">453 cvpr-2013-Video Editing with Temporal, Spatial and Appearance Consistency</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.154), (1, -0.012), (2, -0.053), (3, 0.006), (4, 0.029), (5, -0.01), (6, 0.01), (7, -0.102), (8, 0.162), (9, -0.09), (10, 0.042), (11, 0.002), (12, 0.013), (13, 0.039), (14, 0.031), (15, 0.016), (16, 0.001), (17, 0.007), (18, 0.033), (19, 0.064), (20, -0.015), (21, -0.006), (22, 0.005), (23, 0.001), (24, 0.032), (25, 0.079), (26, -0.032), (27, 0.007), (28, 0.076), (29, 0.04), (30, -0.033), (31, -0.036), (32, -0.074), (33, -0.019), (34, -0.073), (35, -0.0), (36, -0.011), (37, -0.044), (38, 0.013), (39, -0.009), (40, 0.035), (41, 0.0), (42, -0.029), (43, 0.017), (44, -0.032), (45, 0.02), (46, -0.025), (47, -0.005), (48, 0.009), (49, -0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.91605461 <a title="420-lsi-1" href="./cvpr-2013-Supervised_Descent_Method_and_Its_Applications_to_Face_Alignment.html">420 cvpr-2013-Supervised Descent Method and Its Applications to Face Alignment</a></p>
<p>Author: Xuehan Xiong, Fernando De_la_Torre</p><p>Abstract: Many computer vision problems (e.g., camera calibration, image alignment, structure from motion) are solved through a nonlinear optimization method. It is generally accepted that 2nd order descent methods are the most robust, fast and reliable approaches for nonlinear optimization ofa general smoothfunction. However, in the context of computer vision, 2nd order descent methods have two main drawbacks: (1) The function might not be analytically differentiable and numerical approximations are impractical. (2) The Hessian might be large and not positive definite. To address these issues, thispaperproposes a Supervised Descent Method (SDM) for minimizing a Non-linear Least Squares (NLS) function. During training, the SDM learns a sequence of descent directions that minimizes the mean of NLS functions sampled at different points. In testing, SDM minimizes the NLS objective using the learned descent directions without computing the Jacobian nor the Hessian. We illustrate the benefits of our approach in synthetic and real examples, and show how SDM achieves state-ofthe-art performance in the problem of facial feature detec- tion. The code is available at www. .human sen sin g. . cs . cmu . edu/in t ra fa ce.</p><p>2 0.85594946 <a title="420-lsi-2" href="./cvpr-2013-Facial_Feature_Tracking_Under_Varying_Facial_Expressions_and_Face_Poses_Based_on_Restricted_Boltzmann_Machines.html">161 cvpr-2013-Facial Feature Tracking Under Varying Facial Expressions and Face Poses Based on Restricted Boltzmann Machines</a></p>
<p>Author: Yue Wu, Zuoguan Wang, Qiang Ji</p><p>Abstract: Facial feature tracking is an active area in computer vision due to its relevance to many applications. It is a nontrivial task, sincefaces may have varyingfacial expressions, poses or occlusions. In this paper, we address this problem by proposing a face shape prior model that is constructed based on the Restricted Boltzmann Machines (RBM) and their variants. Specifically, we first construct a model based on Deep Belief Networks to capture the face shape variations due to varying facial expressions for near-frontal view. To handle pose variations, the frontal face shape prior model is incorporated into a 3-way RBM model that could capture the relationship between frontal face shapes and non-frontal face shapes. Finally, we introduce methods to systematically combine the face shape prior models with image measurements of facial feature points. Experiments on benchmark databases show that with the proposed method, facial feature points can be tracked robustly and accurately even if faces have significant facial expressions and poses.</p><p>3 0.81143385 <a title="420-lsi-3" href="./cvpr-2013-Robust_Discriminative_Response_Map_Fitting_with_Constrained_Local_Models.html">359 cvpr-2013-Robust Discriminative Response Map Fitting with Constrained Local Models</a></p>
<p>Author: Akshay Asthana, Stefanos Zafeiriou, Shiyang Cheng, Maja Pantic</p><p>Abstract: We present a novel discriminative regression based approach for the Constrained Local Models (CLMs) framework, referred to as the Discriminative Response Map Fitting (DRMF) method, which shows impressive performance in the generic face fitting scenario. The motivation behind this approach is that, unlike the holistic texture based features used in the discriminative AAM approaches, the response map can be represented by a small set of parameters and these parameters can be very efficiently used for reconstructing unseen response maps. Furthermore, we show that by adopting very simple off-the-shelf regression techniques, it is possible to learn robust functions from response maps to the shape parameters updates. The experiments, conducted on Multi-PIE, XM2VTS and LFPW database, show that the proposed DRMF method outperforms stateof-the-art algorithms for the task of generic face fitting. Moreover, the DRMF method is computationally very efficient and is real-time capable. The current MATLAB implementation takes 1second per image. To facilitate future comparisons, we release the MATLAB code1 and the pretrained models for research purposes.</p><p>4 0.78359437 <a title="420-lsi-4" href="./cvpr-2013-Expressive_Visual_Text-to-Speech_Using_Active_Appearance_Models.html">159 cvpr-2013-Expressive Visual Text-to-Speech Using Active Appearance Models</a></p>
<p>Author: Robert Anderson, Björn Stenger, Vincent Wan, Roberto Cipolla</p><p>Abstract: This paper presents a complete system for expressive visual text-to-speech (VTTS), which is capable of producing expressive output, in the form of a ‘talking head’, given an input text and a set of continuous expression weights. The face is modeled using an active appearance model (AAM), and several extensions are proposed which make it more applicable to the task of VTTS. The model allows for normalization with respect to both pose and blink state which significantly reduces artifacts in the resulting synthesized sequences. We demonstrate quantitative improvements in terms of reconstruction error over a million frames, as well as in large-scale user studies, comparing the output of different systems.</p><p>5 0.7772966 <a title="420-lsi-5" href="./cvpr-2013-Structured_Face_Hallucination.html">415 cvpr-2013-Structured Face Hallucination</a></p>
<p>Author: Chih-Yuan Yang, Sifei Liu, Ming-Hsuan Yang</p><p>Abstract: The goal of face hallucination is to generate highresolution images with fidelity from low-resolution ones. In contrast to existing methods based on patch similarity or holistic constraints in the image space, we propose to exploit local image structures for face hallucination. Each face image is represented in terms of facial components, contours and smooth regions. The image structure is maintained via matching gradients in the reconstructed highresolution output. For facial components, we align input images to generate accurate exemplars and transfer the high-frequency details for preserving structural consistency. For contours, we learn statistical priors to generate salient structures in the high-resolution images. A patch matching method is utilized on the smooth regions where the image gradients are preserved. Experimental results demonstrate that the proposed algorithm generates hallucinated face images with favorable quality and adaptability.</p><p>6 0.70287013 <a title="420-lsi-6" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<p>7 0.69031143 <a title="420-lsi-7" href="./cvpr-2013-Towards_Pose_Robust_Face_Recognition.html">438 cvpr-2013-Towards Pose Robust Face Recognition</a></p>
<p>8 0.68555474 <a title="420-lsi-8" href="./cvpr-2013-Selective_Transfer_Machine_for_Personalized_Facial_Action_Unit_Detection.html">385 cvpr-2013-Selective Transfer Machine for Personalized Facial Action Unit Detection</a></p>
<p>9 0.66709733 <a title="420-lsi-9" href="./cvpr-2013-Detecting_and_Aligning_Faces_by_Image_Retrieval.html">119 cvpr-2013-Detecting and Aligning Faces by Image Retrieval</a></p>
<p>10 0.66160637 <a title="420-lsi-10" href="./cvpr-2013-Exemplar-Based_Face_Parsing.html">152 cvpr-2013-Exemplar-Based Face Parsing</a></p>
<p>11 0.65277356 <a title="420-lsi-11" href="./cvpr-2013-Correlation_Filters_for_Object_Alignment.html">96 cvpr-2013-Correlation Filters for Object Alignment</a></p>
<p>12 0.62784231 <a title="420-lsi-12" href="./cvpr-2013-Blessing_of_Dimensionality%3A_High-Dimensional_Feature_and_Its_Efficient_Compression_for_Face_Verification.html">64 cvpr-2013-Blessing of Dimensionality: High-Dimensional Feature and Its Efficient Compression for Face Verification</a></p>
<p>13 0.62015408 <a title="420-lsi-13" href="./cvpr-2013-Capturing_Complex_Spatio-temporal_Relations_among_Facial_Muscles_for_Facial_Expression_Recognition.html">77 cvpr-2013-Capturing Complex Spatio-temporal Relations among Facial Muscles for Facial Expression Recognition</a></p>
<p>14 0.61652178 <a title="420-lsi-14" href="./cvpr-2013-Fusing_Robust_Face_Region_Descriptors_via_Multiple_Metric_Learning_for_Face_Recognition_in_the_Wild.html">182 cvpr-2013-Fusing Robust Face Region Descriptors via Multiple Metric Learning for Face Recognition in the Wild</a></p>
<p>15 0.61220092 <a title="420-lsi-15" href="./cvpr-2013-What%27s_in_a_Name%3F_First_Names_as_Facial_Attributes.html">463 cvpr-2013-What's in a Name? First Names as Facial Attributes</a></p>
<p>16 0.59305012 <a title="420-lsi-16" href="./cvpr-2013-Single-Sample_Face_Recognition_with_Image_Corruption_and_Misalignment_via_Sparse_Illumination_Transfer.html">399 cvpr-2013-Single-Sample Face Recognition with Image Corruption and Misalignment via Sparse Illumination Transfer</a></p>
<p>17 0.59260118 <a title="420-lsi-17" href="./cvpr-2013-Robust_Canonical_Time_Warping_for_the_Alignment_of_Grossly_Corrupted_Sequences.html">358 cvpr-2013-Robust Canonical Time Warping for the Alignment of Grossly Corrupted Sequences</a></p>
<p>18 0.58550143 <a title="420-lsi-18" href="./cvpr-2013-Probabilistic_Elastic_Matching_for_Pose_Variant_Face_Verification.html">338 cvpr-2013-Probabilistic Elastic Matching for Pose Variant Face Verification</a></p>
<p>19 0.57580751 <a title="420-lsi-19" href="./cvpr-2013-Face_Recognition_in_Movie_Trailers_via_Mean_Sequence_Sparse_Representation-Based_Classification.html">160 cvpr-2013-Face Recognition in Movie Trailers via Mean Sequence Sparse Representation-Based Classification</a></p>
<p>20 0.54558671 <a title="420-lsi-20" href="./cvpr-2013-Learning_SURF_Cascade_for_Fast_and_Accurate_Object_Detection.html">254 cvpr-2013-Learning SURF Cascade for Fast and Accurate Object Detection</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.111), (16, 0.018), (26, 0.097), (33, 0.249), (39, 0.024), (55, 0.194), (67, 0.064), (69, 0.044), (87, 0.082)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.90231198 <a title="420-lda-1" href="./cvpr-2013-Expressive_Visual_Text-to-Speech_Using_Active_Appearance_Models.html">159 cvpr-2013-Expressive Visual Text-to-Speech Using Active Appearance Models</a></p>
<p>Author: Robert Anderson, Björn Stenger, Vincent Wan, Roberto Cipolla</p><p>Abstract: This paper presents a complete system for expressive visual text-to-speech (VTTS), which is capable of producing expressive output, in the form of a ‘talking head’, given an input text and a set of continuous expression weights. The face is modeled using an active appearance model (AAM), and several extensions are proposed which make it more applicable to the task of VTTS. The model allows for normalization with respect to both pose and blink state which significantly reduces artifacts in the resulting synthesized sequences. We demonstrate quantitative improvements in terms of reconstruction error over a million frames, as well as in large-scale user studies, comparing the output of different systems.</p><p>2 0.88965929 <a title="420-lda-2" href="./cvpr-2013-A_Statistical_Model_for_Recreational_Trails_in_Aerial_Images.html">26 cvpr-2013-A Statistical Model for Recreational Trails in Aerial Images</a></p>
<p>Author: Andrew Predoehl, Scott Morris, Kobus Barnard</p><p>Abstract: unkown-abstract</p><p>3 0.88055617 <a title="420-lda-3" href="./cvpr-2013-Understanding_Bayesian_Rooms_Using_Composite_3D_Object_Models.html">445 cvpr-2013-Understanding Bayesian Rooms Using Composite 3D Object Models</a></p>
<p>Author: Luca Del_Pero, Joshua Bowdish, Bonnie Kermgard, Emily Hartley, Kobus Barnard</p><p>Abstract: We develop a comprehensive Bayesian generative model for understanding indoor scenes. While it is common in this domain to approximate objects with 3D bounding boxes, we propose using strong representations with finer granularity. For example, we model a chair as a set of four legs, a seat and a backrest. We find that modeling detailed geometry improves recognition and reconstruction, and enables more refined use of appearance for scene understanding. We demonstrate this with a new likelihood function that re- wards 3D object hypotheses whose 2D projection is more uniform in color distribution. Such a measure would be confused by background pixels if we used a bounding box to represent a concave object like a chair. Complex objects are modeled using a set or re-usable 3D parts, and we show that this representation captures much of the variation among object instances with relatively few parameters. We also designed specific data-driven inference mechanismsfor eachpart that are shared by all objects containing that part, which helps make inference transparent to the modeler. Further, we show how to exploit contextual relationships to detect more objects, by, for example, proposing chairs around and underneath tables. We present results showing the benefits of each of these innovations. The performance of our approach often exceeds that of state-of-the-art methods on the two tasks of room layout estimation and object recognition, as evaluated on two bench mark data sets used in this domain. work. 1) Detailed geometric models, such as tables with legs and top (bottom left), provide better reconstructions than plain boxes (top right), when supported by image features such as geometric context [5] (top middle), or an approach to using color introduced here. 2) Non convex models allow for complex configurations, such as a chair under a table (bottom middle). 3) 3D contextual relationships, such as chairs being around a table, allow identifying objects supported by little image evidence, like the chair behind the table (bottom right). Best viewed in color.</p><p>same-paper 4 0.85607404 <a title="420-lda-4" href="./cvpr-2013-Supervised_Descent_Method_and_Its_Applications_to_Face_Alignment.html">420 cvpr-2013-Supervised Descent Method and Its Applications to Face Alignment</a></p>
<p>Author: Xuehan Xiong, Fernando De_la_Torre</p><p>Abstract: Many computer vision problems (e.g., camera calibration, image alignment, structure from motion) are solved through a nonlinear optimization method. It is generally accepted that 2nd order descent methods are the most robust, fast and reliable approaches for nonlinear optimization ofa general smoothfunction. However, in the context of computer vision, 2nd order descent methods have two main drawbacks: (1) The function might not be analytically differentiable and numerical approximations are impractical. (2) The Hessian might be large and not positive definite. To address these issues, thispaperproposes a Supervised Descent Method (SDM) for minimizing a Non-linear Least Squares (NLS) function. During training, the SDM learns a sequence of descent directions that minimizes the mean of NLS functions sampled at different points. In testing, SDM minimizes the NLS objective using the learned descent directions without computing the Jacobian nor the Hessian. We illustrate the benefits of our approach in synthetic and real examples, and show how SDM achieves state-ofthe-art performance in the problem of facial feature detec- tion. The code is available at www. .human sen sin g. . cs . cmu . edu/in t ra fa ce.</p><p>5 0.83763021 <a title="420-lda-5" href="./cvpr-2013-Occlusion_Patterns_for_Object_Class_Detection.html">311 cvpr-2013-Occlusion Patterns for Object Class Detection</a></p>
<p>Author: Bojan Pepikj, Michael Stark, Peter Gehler, Bernt Schiele</p><p>Abstract: Despite the success of recent object class recognition systems, the long-standing problem of partial occlusion remains a major challenge, and a principled solution is yet to be found. In this paper we leave the beaten path of methods that treat occlusion as just another source of noise instead, we include the occluder itself into the modelling, by mining distinctive, reoccurring occlusion patterns from annotated training data. These patterns are then used as training data for dedicated detectors of varying sophistication. In particular, we evaluate and compare models that range from standard object class detectors to hierarchical, part-based representations of occluder/occludee pairs. In an extensive evaluation we derive insights that can aid further developments in tackling the occlusion challenge. –</p><p>6 0.83203578 <a title="420-lda-6" href="./cvpr-2013-Tracking_People_and_Their_Objects.html">440 cvpr-2013-Tracking People and Their Objects</a></p>
<p>7 0.82986516 <a title="420-lda-7" href="./cvpr-2013-Exemplar-Based_Face_Parsing.html">152 cvpr-2013-Exemplar-Based Face Parsing</a></p>
<p>8 0.82551879 <a title="420-lda-8" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>9 0.82253253 <a title="420-lda-9" href="./cvpr-2013-Maximum_Cohesive_Grid_of_Superpixels_for_Fast_Object_Localization.html">280 cvpr-2013-Maximum Cohesive Grid of Superpixels for Fast Object Localization</a></p>
<p>10 0.82134563 <a title="420-lda-10" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<p>11 0.82086068 <a title="420-lda-11" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<p>12 0.82058549 <a title="420-lda-12" href="./cvpr-2013-Scene_Parsing_by_Integrating_Function%2C_Geometry_and_Appearance_Models.html">381 cvpr-2013-Scene Parsing by Integrating Function, Geometry and Appearance Models</a></p>
<p>13 0.81945395 <a title="420-lda-13" href="./cvpr-2013-Accurate_Localization_of_3D_Objects_from_RGB-D_Data_Using_Segmentation_Hypotheses.html">30 cvpr-2013-Accurate Localization of 3D Objects from RGB-D Data Using Segmentation Hypotheses</a></p>
<p>14 0.81938773 <a title="420-lda-14" href="./cvpr-2013-Structure_Preserving_Object_Tracking.html">414 cvpr-2013-Structure Preserving Object Tracking</a></p>
<p>15 0.81909627 <a title="420-lda-15" href="./cvpr-2013-Physically_Plausible_3D_Scene_Tracking%3A_The_Single_Actor_Hypothesis.html">331 cvpr-2013-Physically Plausible 3D Scene Tracking: The Single Actor Hypothesis</a></p>
<p>16 0.81864876 <a title="420-lda-16" href="./cvpr-2013-Understanding_Indoor_Scenes_Using_3D_Geometric_Phrases.html">446 cvpr-2013-Understanding Indoor Scenes Using 3D Geometric Phrases</a></p>
<p>17 0.81796068 <a title="420-lda-17" href="./cvpr-2013-Integrating_Grammar_and_Segmentation_for_Human_Pose_Estimation.html">225 cvpr-2013-Integrating Grammar and Segmentation for Human Pose Estimation</a></p>
<p>18 0.81768692 <a title="420-lda-18" href="./cvpr-2013-Part_Discovery_from_Partial_Correspondence.html">325 cvpr-2013-Part Discovery from Partial Correspondence</a></p>
<p>19 0.81630605 <a title="420-lda-19" href="./cvpr-2013-Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking.html">285 cvpr-2013-Minimum Uncertainty Gap for Robust Visual Tracking</a></p>
<p>20 0.81568176 <a title="420-lda-20" href="./cvpr-2013-A_Minimum_Error_Vanishing_Point_Detection_Approach_for_Uncalibrated_Monocular_Images_of_Man-Made_Environments.html">19 cvpr-2013-A Minimum Error Vanishing Point Detection Approach for Uncalibrated Monocular Images of Man-Made Environments</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
