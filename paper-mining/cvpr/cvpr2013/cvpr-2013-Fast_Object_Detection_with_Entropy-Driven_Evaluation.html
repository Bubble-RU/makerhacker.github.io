<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>168 cvpr-2013-Fast Object Detection with Entropy-Driven Evaluation</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-168" href="#">cvpr2013-168</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>168 cvpr-2013-Fast Object Detection with Entropy-Driven Evaluation</h1>
<br/><p>Source: <a title="cvpr-2013-168-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Sznitman_Fast_Object_Detection_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Raphael Sznitman, Carlos Becker, François Fleuret, Pascal Fua</p><p>Abstract: Cascade-style approaches to implementing ensemble classifiers can deliver significant speed-ups at test time. While highly effective, they remain challenging to tune and their overall performance depends on the availability of large validation sets to estimate rejection thresholds. These characteristics are often prohibitive and thus limit their applicability. We introduce an alternative approach to speeding-up classifier evaluation which overcomes these limitations. It involves maintaining a probability estimate of the class label at each intermediary response and stopping when the corresponding uncertainty becomes small enough. As a result, the evaluation terminates early based on the sequence of responses observed. Furthermore, it does so independently of the type of ensemble classifier used or the way it was trained. We show through extensive experimentation that our method provides 2 to 10 fold speed-ups, over existing state-of-the-art methods, at almost no loss in accuracy on a number of object classification tasks.</p><p>Reference: <a title="cvpr-2013-168-reference" href="../cvpr2013_reference/cvpr-2013-Fast_Object_Detection_with_Entropy-Driven_Evaluation_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 While highly effective, they remain challenging to tune and their overall performance depends on the availability of large validation sets to estimate rejection thresholds. [sent-6, score-0.343]
</p><p>2 It involves maintaining a probability estimate of the class label at each intermediary response and stopping when the corresponding uncertainty becomes small enough. [sent-9, score-0.579]
</p><p>3 Typically, using an ensemble classifier requires evaluating the many individual classifiers they are made of. [sent-15, score-0.248]
</p><p>4 Perhaps the most famous demonstration of this trade-off is found in the seminal face detection paper [26], where a “hard” cascade of classifiers was used to filter out and reject non-faces while only mildly decreasing the overall classifier accuracy. [sent-18, score-0.314]
</p><p>5 For example, a relaxation of the hard cascade to a soft one was introduced to more effectively reject non-target candidates and to alleviate many of the difficulties encountered when training hard cascades [4]. [sent-20, score-0.196]
</p><p>6 Similarly, some have used rejection criteria based on Walds’ Sequential Probability Ratio Test [23] or using more empir-  ical observations [29]. [sent-21, score-0.214]
</p><p>7 Unlike previous methods that need multiple stage-specific thresholds, the class label uncertainty in our method only requires a single threshold, common to all stages, to specify when the uncertainty is small enough. [sent-27, score-0.192]
</p><p>8 We show experimentally that our method provides significant gains in speed or accuracy, and often both, over state-of-the-art early stopping methods on a number of object classification tasks when using different ensemble classifiers. [sent-28, score-0.65]
</p><p>9 Among methods designed for this purpose and that attempt to reject negatives early, one ofthe earliest and most influential works is the hard cascade of classifiers proposed in [26] for face detection. [sent-40, score-0.227]
</p><p>10 In that work, rejection thresholds on a set of distinct classifiers were used to conservatively filter out non-faces during classification. [sent-41, score-0.355]
</p><p>11 Perhaps most relevant to this work is that of [4], where the hard cascade was replaced by a single soft cascade classifier with stage-wise rejection thresholds that were computed using a cascade calibration procedure (CCAL). [sent-43, score-0.632]
</p><p>12 More specifically, thresholds on the sum of stage scores were found by adjusting a performance vector such that each stage of the soft cascade rejected at most a fixed proportion of positive targets from a validation set. [sent-44, score-1.042]
</p><p>13 Furthermore, the final classifier accuracy is closely linked to the quantity and variability of positive samples in the validation set used to calibrate the cascade. [sent-46, score-0.31]
</p><p>14 Along the same lines, a simple Direct Backward Pruning algorithm (DBP) was introduced in [29] which sets rejection thresholds on the sum of stage scores. [sent-47, score-0.568]
</p><p>15 This was achieved by taking the threshold at each stage to be the minimum sum of stage scores observed over a validation set or subset. [sent-48, score-0.757]
</p><p>16 While effectively removing the need for the performance vector of [4], this strategy can still only perform well for validation subsets large enough so that thresholds generalize to the test set. [sent-49, score-0.306]
</p><p>17 A different approach to setting rejection thresholds is that of [23], where stage-wise thresholds are based on the Sequential Probability Ratio Test (SPRT). [sent-50, score-0.434]
</p><p>18 This test is shown to be optimal when individual observations at each stage are i. [sent-51, score-0.237]
</p><p>19 However, in practice, the ratio test used relies on the sum of stage scores, hence strongly correlating observations and thus violating a number of assumptions. [sent-54, score-0.302]
</p><p>20 In short, all the above-mentioned approaches to early termination of a classifier evaluation critically depend either on large validation sets or on several strong assumptions on the behavior of weak classifiers. [sent-55, score-0.358]
</p><p>21 Method As in cascade approaches [26, 23, 4, 29], given an ensemble classifier that sequentially evaluates stages, our goal is to reduce the computational burden by using as few resources as possible on easy-to-classify cases. [sent-58, score-0.238]
</p><p>22 We differ from earlier approaches in that we track the class label in a Bayesian way by modeling the individual stage computations, and dynamically infer when additional classification stages are necessary at run-time. [sent-59, score-0.431]
</p><p>23 In some sense, our method normalizes each stage individually and accumulates their normalized evidence. [sent-60, score-0.263]
</p><p>24 ,  (1)  where gk  : RD → R,  (2)  is a stage score at stage index k. [sent-71, score-1.035]
</p><p>25 In BS classifiers [9, 13], a stage is defined as gk (x) = αkhk (x) where hk is a weak learner and αk its weight. [sent-72, score-0.866]
</p><p>26 Similarly, in BT and RF classifiers [5], gk is a decision tree. [sent-73, score-0.606]
</p><p>27 1 depicts this sum for a few examples from a validation set V = 333222667199  Table 1. [sent-84, score-0.237]
</p><p>28 Summary of Notation x ∈ RDSample feature vector  Yx ∈∈ R{−1, 1} VY VN φ kx∗ gk (x) Gk (x) fk (x) F(x) ? [sent-85, score-0.699]
</p><p>29 In this figure, each curve shows the sum {of( stage scores of a BS face classifier for an example face (green) or non-face (red). [sent-88, score-0.51]
</p><p>30 Note that we consider the validation set to be disjoint from the classifier training set. [sent-89, score-0.247]
</p><p>31 Framework For a given test sample x, we want to evaluate as few stages as possible for a classifier of the form given in Eq. [sent-92, score-0.181]
</p><p>32 ,gk(x)) ≥ 0},(4) where the φ function is a stopping criterion. [sent-100, score-0.42]
</p><p>33 In fact, in both [4] and [29], the stopping criteria are of the form φ (g1(x), . [sent-103, score-0.492]
</p><p>34 9] selects each threshold by computing  θk={n:yn=1m,fiKn(xn)>τ}fk(xn),  (6)  where τ is a user specified threshold on the final sum fK(x). [sent-111, score-0.185]
</p><p>35 n  where |P| is the total number of positive examples in the vwahleidraet |ioPn| set, pk tios a user specified proportion amnpdl epsre idn tihs a function that returns one if fk (xn) ≤ r and zero otherwise. [sent-114, score-0.271]
</p><p>36 Similarly, the SPRT stopping c)ri ≤ter ri aonn din z e[2ro3] o, hise rowf itshee. [sent-115, score-0.42]
</p><p>37 Example of the sum of stage scores produced by a face classifier as function of the stage index. [sent-120, score-0.695]
</p><p>38 Each green and red line corresponds to a face and non-face sample from a validation set. [sent-121, score-0.254]
</p><p>39 The jittery black line shows a typical set of rejection thresholds produced by the CCAL procedure. [sent-122, score-0.308]
</p><p>40 Examples with sum of scores that fall below the black line at any stage k are rejected early. [sent-123, score-0.385]
</p><p>41 Clearly, the performances of these stopping criteria are  fk  θk  strongly dependent on the quality and representativity of the validation set used, as their threshold values are explicitly selected from examples. [sent-128, score-0.898]
</p><p>42 Entropy Driven Evaluation We define the stopping criterion φ in a significantly different way. [sent-131, score-0.494]
</p><p>43 After each stage, we observe the value, gk (x), which we also treat as a random variable and for which we can evaluate P(gk (x) |Y = 1) and P(gk (x) |Y = −1). [sent-135, score-0.539]
</p><p>44 In addition, we assume that gk (x) is conditionally independent from gj (x) ,j < k given the class label, which leads to ? [sent-136, score-0.568]
</p><p>45 = 1  Unlike [23] which also assumes conditional independence given the class label, this is our only assumption on the behavior of the stage scores. [sent-140, score-0.304]
</p><p>46 Given this, we take our stopping criteria to be φ (g1(x) , . [sent-141, score-0.492]
</p><p>47 , gk (x)) =  γ  333222777200  − H(Y |Gk (x)) ,  (10)  Stage Index k  Stage Index k Figure 2. [sent-144, score-0.539]
</p><p>48 (top) Sum of stage scores, fk (x) for a positive sample x0 (green) and negative samples x1  and x2 (red), as function of the stage index k. [sent-146, score-0.77]
</p><p>49 The dotted line depicts a chosen entropy threshold γ, converted to its corresponding probability thresholds ? [sent-148, score-0.363]
</p><p>50 n nI no bthseisr context, nthde γ γco ∈n (d0it,io1n)a isl entropy provides a measure of uncertainty on the class label, and hence we look for kx∗ such that it reduces the uncertainty below a specified level γ. [sent-152, score-0.274]
</p><p>51 As in [23], we can estimate the conditional likelihoods, P(gk (x) |Y = 1) and P(gk (x) |Y = −1) using the validation s(ext. [sent-165, score-0.198]
</p><p>52 2, let two samples, x1 and x2 have sum of scores fk∗ (x1) = fk∗ (x2), where k∗ = 5 is  the first stage where rejection takes place for both x1 and x2, when using a method from Sec. [sent-205, score-0.461]
</p><p>53 In this case, both x1 and x2 are rejected since rejection solely depends on fk∗ (·). [sent-208, score-0.208]
</p><p>54 In EDE however, early stopping depends on the posterior distribution, which depends on the sequence Gk (x) and not fk (·). [sent-209, score-0.763]
</p><p>55 That is, early stopping of our method depends on the progression sof, evaarlluyes st oatp peaincgh stage, manetdh noodt d on etnhed sum hoef stage scores. [sent-210, score-0.808]
</p><p>56 Furthermore, our method normalizes each stage individually, and estimates the reliability of individual stages. [sent-212, score-0.263]
</p><p>57 To build some intuition about this fact, consider an extreme example where a given stage computes a random response that is completely unrelated to x. [sent-213, score-0.237]
</p><p>58 Such a stage would strongly impact previous methods in a negative way, as it would force the threshold at that stage to be unreliable. [sent-214, score-0.566]
</p><p>59 EDE on the other hand, would effectively ignore the stage from the overall estimation, as it would weigh the information at this stage very poorly, since P(gk (x) |Y = 1) and P(gk (x) |Y = −1) would be similar. [sent-215, score-0.474]
</p><p>60 Block Evaluation While in [23, 4, 29] the stopping criteria are evaluated at each stage of the prediction procedure, this may not be necessary in some cases. [sent-218, score-0.79]
</p><p>61 For this reason, we propose to evaluate the stopping criterion at specific intervals of stages. [sent-219, score-0.494]
</p><p>62 , K − 1} be a block offset, then we can update δthe ∈ posterior Kdis −tr 1ib}ut bioen a a bnldo cekva olfufsaetet, tthhee stopping  criterion at every δ stages. [sent-223, score-0.583]
</p><p>63 own in our experiments, this block evaluation of the stopping criterion is not only beneficial as it reduces the need to update the posterior at each stage, but also makes EDE less sensitive to noise contained in each stage observation. [sent-233, score-0.82]
</p><p>64 (x) |Y = y), the stopping threshold γ and the block offset δ. [sent-242, score-0.522]
</p><p>65 5)  In general, the only difference between our algorithm and the evaluation of a typical ensemble classifier is the update of the posterior distribution (line 4). [sent-255, score-0.216]
</p><p>66 Experiments We now demonstrate the efficiency of our proposed EDE stopping criterion for three different tasks: face detection, image classification and structure recognition1 . [sent-259, score-0.586]
</p><p>67 As noted in [23, 29], comparing published results of competing early stopping methods is difficult because they are produced by pipelines that depend on training data, specific features being used, approach to non-maximal suppression, and parameter settings among many other things. [sent-262, score-0.508]
</p><p>68 Therefore, to compare our early stopping approach against others as fairly as possible, we reimplemented the CCAL, DBP and SPRT stopping criteria and evaluate each approach using the same classifier and validation set for each task mentioned above. [sent-263, score-1.247]
</p><p>69 5 )of a thned parameter space, a,n wde s peelercfoterdm tehde a parameters t sheaatr required the smallest number of stage evaluations, and for which at most 1% of the classification accuracy was incorrect when compared to non-early-stopping prediction. [sent-275, score-0.299]
</p><p>70 For each triple, this process was repeated 5 times over the validation set and the best triple was selected. [sent-276, score-0.188]
</p><p>71 In general, we are interested in observing how a method performs in terms of the number of stage evaluations and prediction accuracy. [sent-277, score-0.377]
</p><p>72 The validation set was comprised of 4000 positives and 6000 negatives. [sent-284, score-0.182]
</p><p>73 This set was used to compute both the CCAL, DBP and SPRT rejection thresholds and the conditional probabilities P(gk (x) |Y = y) of Section 3. [sent-285, score-0.326]
</p><p>74 For this experiment, we adjusted the number of stage evaluations, or stumps, required by each early stopping  ×  method to be approximately the same. [sent-287, score-0.767]
</p><p>75 We then compared the accuracy performance of the four stopping criteria on the MIT+CMU dataset [19], which consists of 130 images containing a total of 507 labelled faces. [sent-288, score-0.492]
</p><p>76 3, we report the accuracy and the distribution of stage evaluations required by each method. [sent-292, score-0.361]
</p><p>77 (top) Face detection ROC curves for each early stopping method evaluated and for non-early stopping on the MIT+CMU face dataset. [sent-295, score-1.003]
</p><p>78 Each stopping criterion was re-implemented and evaluated using the same Boosted Stumps (BS) classifier, training set and validation set. [sent-296, score-0.677]
</p><p>79 (bottom) Distribution of the number of stage evaluations of test sample for each method. [sent-297, score-0.361]
</p><p>80 In this case, each stage consists in the evaluation of a single stump. [sent-298, score-0.237]
</p><p>81 Since a validation set is required to  estimate the rejection thresholds, we only evaluate object categories for which enough positive samples are available to form large enough training and validation sets. [sent-303, score-0.547]
</p><p>82 Average number of stage evaluations and best F-score (in brackets) on object classification tasks for three Caltech-256 categories either without an early stopping criterion or with one of the four discussed in this paper. [sent-341, score-0.961]
</p><p>83 Our EDE criterion, in bold, not only provides the least number of stage evaluations but also the best F-score when compared to other early stopping methods. [sent-342, score-0.847]
</p><p>84 For each classifier and stopping criterion pair, we report in Table 2 both the average number of stage evaluations required and the best F-score (in brackets) for each classification task. [sent-346, score-0.982]
</p><p>85 In all evaluated cases, the EDE stopping criterion outperforms the other three methods on both speed and accu-  racy. [sent-349, score-0.545]
</p><p>86 4 depicts the best F-scores of each early stopping method as a function of the average number of evaluations when using a BT classifier on the Airplane classification task. [sent-352, score-0.771]
</p><p>87 Best F-score as function of number of stage evaluations required for a Boosted Tree (BT) classifier with different stopping criteria for Caltech-256 Airplane classification. [sent-355, score-0.94]
</p><p>88 Each method uses  the same classifier and validation set and each point shows the average performance for a stopping method when used with a specific set of parameters. [sent-356, score-0.667]
</p><p>89 We constructed our training and validation set by computing the gradient histogram features described in [25] for 5000 positive and 5000 negative randomly selected samples from two different volumes3. [sent-368, score-0.252]
</p><p>90 From the training and validation set, half the samples  were randomly selected to train a BS classifier with 500 stumps and the other half to learn the early stopping criteria. [sent-370, score-0.887]
</p><p>91 We repeated this 10 times and evaluated the resulting classifiers and corresponding stopping criteria on the test set. [sent-371, score-0.582]
</p><p>92 (bottom) Best F-score as a function of the number of stage evaluations required for a Boosted Stump (BS) classifier on the above classification task. [sent-380, score-0.488]
</p><p>93 Each point shows the average performance for a stopping method when used with different sets of parameters values. [sent-381, score-0.42]
</p><p>94 To this end, we trained a BS classifiers with 500 stumps and re-learned the thresholds and probability distributions using ever smaller validation sets. [sent-385, score-0.505]
</p><p>95 Even by the time the number of positives in the validation set has dropped from 2500 to 200, the performance of EDE is barely affected, while that of the others have degraded substantially. [sent-386, score-0.182]
</p><p>96 Conclusion This paper addressed the problem of speeding up the prediction of binary classification when using ensemble classifiers. [sent-388, score-0.2]
</p><p>97 Our proposed solution uses Bayesian inference to establish and track the probability of a samples class label as stage evaluations are computed. [sent-389, score-0.465]
</p><p>98 Our early stopping criteria is to terminate the prediction process when the uncertainty of the class label, measured by its Shannon entropy, falls below a chosen level. [sent-390, score-0.712]
</p><p>99 We showed through extensive experimentation on several classification tasks that our approach  provides significant accuracy and speed improvements over state-of-the-art early stopping methods. [sent-391, score-0.604]
</p><p>100 (top) Best F-score and (bottom) number of stage evaluations as a function of the number of positives used in the validation set on a logarithmic scale. [sent-395, score-0.521]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('gk', 0.539), ('stopping', 0.42), ('ede', 0.249), ('stage', 0.237), ('ccal', 0.172), ('sprt', 0.172), ('fk', 0.16), ('validation', 0.16), ('thresholds', 0.146), ('rejection', 0.142), ('dbp', 0.129), ('bs', 0.125), ('evaluations', 0.102), ('stumps', 0.1), ('entropy', 0.09), ('early', 0.088), ('classifier', 0.087), ('cascade', 0.077), ('criterion', 0.074), ('ensemble', 0.074), ('stages', 0.072), ('criteria', 0.072), ('bt', 0.07), ('classifiers', 0.067), ('uncertainty', 0.065), ('posterior', 0.055), ('face', 0.052), ('speeding', 0.048), ('rejected', 0.046), ('forests', 0.044), ('sum', 0.043), ('threshold', 0.041), ('classification', 0.04), ('scores', 0.039), ('boosted', 0.038), ('prediction', 0.038), ('conditional', 0.038), ('airplane', 0.037), ('rf', 0.036), ('fleuret', 0.035), ('cascades', 0.035), ('user', 0.035), ('epfl', 0.035), ('depicts', 0.034), ('block', 0.034), ('gm', 0.034), ('stump', 0.033), ('label', 0.033), ('xn', 0.032), ('probability', 0.032), ('samples', 0.032), ('positive', 0.031), ('reject', 0.031), ('sequential', 0.031), ('tubular', 0.03), ('path', 0.03), ('brackets', 0.029), ('class', 0.029), ('negative', 0.029), ('experimentation', 0.028), ('triple', 0.028), ('speed', 0.028), ('candidates', 0.027), ('offset', 0.027), ('learners', 0.026), ('yn', 0.026), ('soft', 0.026), ('normalizes', 0.026), ('paths', 0.025), ('specified', 0.025), ('fold', 0.025), ('saffari', 0.025), ('driven', 0.024), ('remainder', 0.024), ('switzerland', 0.024), ('evaluated', 0.023), ('kx', 0.023), ('prohibitive', 0.023), ('performances', 0.023), ('pruning', 0.023), ('leistner', 0.023), ('weak', 0.023), ('positives', 0.022), ('wiley', 0.022), ('required', 0.022), ('index', 0.022), ('classifies', 0.022), ('sample', 0.022), ('strongly', 0.022), ('likelihoods', 0.021), ('bayesian', 0.021), ('pami', 0.021), ('tune', 0.021), ('evaluating', 0.02), ('depends', 0.02), ('pk', 0.02), ('km', 0.02), ('line', 0.02), ('cmu', 0.02), ('earlier', 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="168-tfidf-1" href="./cvpr-2013-Fast_Object_Detection_with_Entropy-Driven_Evaluation.html">168 cvpr-2013-Fast Object Detection with Entropy-Driven Evaluation</a></p>
<p>Author: Raphael Sznitman, Carlos Becker, François Fleuret, Pascal Fua</p><p>Abstract: Cascade-style approaches to implementing ensemble classifiers can deliver significant speed-ups at test time. While highly effective, they remain challenging to tune and their overall performance depends on the availability of large validation sets to estimate rejection thresholds. These characteristics are often prohibitive and thus limit their applicability. We introduce an alternative approach to speeding-up classifier evaluation which overcomes these limitations. It involves maintaining a probability estimate of the class label at each intermediary response and stopping when the corresponding uncertainty becomes small enough. As a result, the evaluation terminates early based on the sequence of responses observed. Furthermore, it does so independently of the type of ensemble classifier used or the way it was trained. We show through extensive experimentation that our method provides 2 to 10 fold speed-ups, over existing state-of-the-art methods, at almost no loss in accuracy on a number of object classification tasks.</p><p>2 0.12917289 <a title="168-tfidf-2" href="./cvpr-2013-Learning_SURF_Cascade_for_Fast_and_Accurate_Object_Detection.html">254 cvpr-2013-Learning SURF Cascade for Fast and Accurate Object Detection</a></p>
<p>Author: Jianguo Li, Yimin Zhang</p><p>Abstract: This paper presents a novel learning framework for training boosting cascade based object detector from large scale dataset. The framework is derived from the wellknown Viola-Jones (VJ) framework but distinguished by three key differences. First, the proposed framework adopts multi-dimensional SURF features instead of single dimensional Haar features to describe local patches. In this way, the number of used local patches can be reduced from hundreds of thousands to several hundreds. Second, it adopts logistic regression as weak classifier for each local patch instead of decision trees in the VJ framework. Third, we adopt AUC as a single criterion for the convergence test during cascade training rather than the two trade-off criteria (false-positive-rate and hit-rate) in the VJ framework. The benefit is that the false-positive-rate can be adaptive among different cascade stages, and thus yields much faster convergence speed of SURF cascade. Combining these points together, the proposed approach has three good properties. First, the boosting cascade can be trained very efficiently. Experiments show that the proposed approach can train object detectors from billions of negative samples within one hour even on personal computers. Second, the built detector is comparable to the stateof-the-art algorithm not only on the accuracy but also on the processing speed. Third, the built detector is small in model-size due to short cascade stages.</p><p>3 0.11868453 <a title="168-tfidf-3" href="./cvpr-2013-Understanding_Indoor_Scenes_Using_3D_Geometric_Phrases.html">446 cvpr-2013-Understanding Indoor Scenes Using 3D Geometric Phrases</a></p>
<p>Author: Wongun Choi, Yu-Wei Chao, Caroline Pantofaru, Silvio Savarese</p><p>Abstract: Visual scene understanding is a difficult problem interleaving object detection, geometric reasoning and scene classification. We present a hierarchical scene model for learning and reasoning about complex indoor scenes which is computationally tractable, can be learned from a reasonable amount of training data, and avoids oversimplification. At the core of this approach is the 3D Geometric Phrase Model which captures the semantic and geometric relationships between objects whichfrequently co-occur in the same 3D spatial configuration. Experiments show that this model effectively explains scene semantics, geometry and object groupings from a single image, while also improving individual object detections.</p><p>4 0.10685983 <a title="168-tfidf-4" href="./cvpr-2013-Real-Time_No-Reference_Image_Quality_Assessment_Based_on_Filter_Learning.html">346 cvpr-2013-Real-Time No-Reference Image Quality Assessment Based on Filter Learning</a></p>
<p>Author: Peng Ye, Jayant Kumar, Le Kang, David Doermann</p><p>Abstract: This paper addresses the problem of general-purpose No-Reference Image Quality Assessment (NR-IQA) with the goal ofdeveloping a real-time, cross-domain model that can predict the quality of distorted images without prior knowledge of non-distorted reference images and types of distortions present in these images. The contributions of our work are two-fold: first, the proposed method is highly efficient. NR-IQA measures are often used in real-time imaging or communication systems, therefore it is important to have a fast NR-IQA algorithm that can be used in these real-time applications. Second, the proposed method has the potential to be used in multiple image domains. Previous work on NR-IQA focus primarily on predicting quality of natural scene image with respect to human perception, yet, in other image domains, the final receiver of a digital image may not be a human. The proposed method consists of the following components: (1) a local feature extractor; (2) a global feature extractor and (3) a regression model. While previous approaches usually treat local feature extraction and regres- sion model training independently, we propose a supervised method based on back-projection, which links the two steps by learning a compact set of filters which can be applied to local image patches to obtain discriminative local features. Using a small set of filters, the proposed method is extremely fast. We have tested this method on various natural scene and document image datasets and obtained stateof-the-art results.</p><p>5 0.093998246 <a title="168-tfidf-5" href="./cvpr-2013-SCALPEL%3A_Segmentation_Cascades_with_Localized_Priors_and_Efficient_Learning.html">370 cvpr-2013-SCALPEL: Segmentation Cascades with Localized Priors and Efficient Learning</a></p>
<p>Author: David Weiss, Ben Taskar</p><p>Abstract: We propose SCALPEL, a flexible method for object segmentation that integrates rich region-merging cues with mid- and high-level information about object layout, class, and scale into the segmentation process. Unlike competing approaches, SCALPEL uses a cascade of bottom-up segmentation models that is capable of learning to ignore boundaries early on, yet use them as a stopping criterion once the object has been mostly segmented. Furthermore, we show how such cascades can be learned efficiently. When paired with a novel method that generates better localized shapepriors than our competitors, our method leads to a concise, accurate set of segmentation proposals; these proposals are more accurate on the PASCAL VOC2010 dataset than state-of-the-art methods that use re-ranking to filter much larger bags of proposals. The code for our algorithm is available online.</p><p>6 0.088796653 <a title="168-tfidf-6" href="./cvpr-2013-Detecting_and_Aligning_Faces_by_Image_Retrieval.html">119 cvpr-2013-Detecting and Aligning Faces by Image Retrieval</a></p>
<p>7 0.078087486 <a title="168-tfidf-7" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>8 0.075946964 <a title="168-tfidf-8" href="./cvpr-2013-Sparse_Subspace_Denoising_for_Image_Manifolds.html">405 cvpr-2013-Sparse Subspace Denoising for Image Manifolds</a></p>
<p>9 0.072030783 <a title="168-tfidf-9" href="./cvpr-2013-Alternating_Decision_Forests.html">39 cvpr-2013-Alternating Decision Forests</a></p>
<p>10 0.069434121 <a title="168-tfidf-10" href="./cvpr-2013-Efficient_Detector_Adaptation_for_Object_Detection_in_a_Video.html">142 cvpr-2013-Efficient Detector Adaptation for Object Detection in a Video</a></p>
<p>11 0.068871967 <a title="168-tfidf-11" href="./cvpr-2013-A_Lazy_Man%27s_Approach_to_Benchmarking%3A_Semisupervised_Classifier_Evaluation_and_Recalibration.html">15 cvpr-2013-A Lazy Man's Approach to Benchmarking: Semisupervised Classifier Evaluation and Recalibration</a></p>
<p>12 0.067175053 <a title="168-tfidf-12" href="./cvpr-2013-Seeking_the_Strongest_Rigid_Detector.html">383 cvpr-2013-Seeking the Strongest Rigid Detector</a></p>
<p>13 0.066727109 <a title="168-tfidf-13" href="./cvpr-2013-Discriminative_Non-blind_Deblurring.html">131 cvpr-2013-Discriminative Non-blind Deblurring</a></p>
<p>14 0.065166153 <a title="168-tfidf-14" href="./cvpr-2013-Probabilistic_Elastic_Matching_for_Pose_Variant_Face_Verification.html">338 cvpr-2013-Probabilistic Elastic Matching for Pose Variant Face Verification</a></p>
<p>15 0.064691387 <a title="168-tfidf-15" href="./cvpr-2013-Adaptive_Active_Learning_for_Image_Classification.html">34 cvpr-2013-Adaptive Active Learning for Image Classification</a></p>
<p>16 0.063817874 <a title="168-tfidf-16" href="./cvpr-2013-Blocks_That_Shout%3A_Distinctive_Parts_for_Scene_Classification.html">67 cvpr-2013-Blocks That Shout: Distinctive Parts for Scene Classification</a></p>
<p>17 0.063663229 <a title="168-tfidf-17" href="./cvpr-2013-Learning_and_Calibrating_Per-Location_Classifiers_for_Visual_Place_Recognition.html">260 cvpr-2013-Learning and Calibrating Per-Location Classifiers for Visual Place Recognition</a></p>
<p>18 0.062745869 <a title="168-tfidf-18" href="./cvpr-2013-Multi-target_Tracking_by_Lagrangian_Relaxation_to_Min-cost_Network_Flow.html">300 cvpr-2013-Multi-target Tracking by Lagrangian Relaxation to Min-cost Network Flow</a></p>
<p>19 0.059030134 <a title="168-tfidf-19" href="./cvpr-2013-Discriminative_Re-ranking_of_Diverse_Segmentations.html">132 cvpr-2013-Discriminative Re-ranking of Diverse Segmentations</a></p>
<p>20 0.057174545 <a title="168-tfidf-20" href="./cvpr-2013-Semi-supervised_Node_Splitting_for_Random_Forest_Construction.html">390 cvpr-2013-Semi-supervised Node Splitting for Random Forest Construction</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.145), (1, -0.036), (2, -0.022), (3, -0.002), (4, 0.049), (5, 0.026), (6, 0.009), (7, -0.016), (8, 0.02), (9, -0.038), (10, -0.012), (11, -0.032), (12, 0.026), (13, -0.024), (14, -0.042), (15, -0.006), (16, 0.008), (17, -0.022), (18, 0.01), (19, 0.012), (20, -0.023), (21, -0.013), (22, -0.024), (23, 0.032), (24, 0.026), (25, 0.047), (26, -0.002), (27, 0.016), (28, -0.01), (29, 0.038), (30, -0.029), (31, 0.081), (32, -0.012), (33, 0.02), (34, -0.023), (35, 0.063), (36, -0.026), (37, -0.07), (38, -0.022), (39, 0.049), (40, -0.066), (41, -0.035), (42, 0.026), (43, 0.0), (44, -0.003), (45, 0.081), (46, 0.031), (47, -0.054), (48, 0.036), (49, 0.001)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93580687 <a title="168-lsi-1" href="./cvpr-2013-Fast_Object_Detection_with_Entropy-Driven_Evaluation.html">168 cvpr-2013-Fast Object Detection with Entropy-Driven Evaluation</a></p>
<p>Author: Raphael Sznitman, Carlos Becker, François Fleuret, Pascal Fua</p><p>Abstract: Cascade-style approaches to implementing ensemble classifiers can deliver significant speed-ups at test time. While highly effective, they remain challenging to tune and their overall performance depends on the availability of large validation sets to estimate rejection thresholds. These characteristics are often prohibitive and thus limit their applicability. We introduce an alternative approach to speeding-up classifier evaluation which overcomes these limitations. It involves maintaining a probability estimate of the class label at each intermediary response and stopping when the corresponding uncertainty becomes small enough. As a result, the evaluation terminates early based on the sequence of responses observed. Furthermore, it does so independently of the type of ensemble classifier used or the way it was trained. We show through extensive experimentation that our method provides 2 to 10 fold speed-ups, over existing state-of-the-art methods, at almost no loss in accuracy on a number of object classification tasks.</p><p>2 0.73049337 <a title="168-lsi-2" href="./cvpr-2013-A_Lazy_Man%27s_Approach_to_Benchmarking%3A_Semisupervised_Classifier_Evaluation_and_Recalibration.html">15 cvpr-2013-A Lazy Man's Approach to Benchmarking: Semisupervised Classifier Evaluation and Recalibration</a></p>
<p>Author: Peter Welinder, Max Welling, Pietro Perona</p><p>Abstract: How many labeled examples are needed to estimate a classifier’s performance on a new dataset? We study the case where data is plentiful, but labels are expensive. We show that by making a few reasonable assumptions on the structure of the data, it is possible to estimate performance curves, with confidence bounds, using a small number of ground truth labels. Our approach, which we call Semisupervised Performance Evaluation (SPE), is based on a generative model for the classifier’s confidence scores. In addition to estimating the performance of classifiers on new datasets, SPE can be used to recalibrate a classifier by reestimating the class-conditional confidence distributions.</p><p>3 0.70569223 <a title="168-lsi-3" href="./cvpr-2013-Learning_SURF_Cascade_for_Fast_and_Accurate_Object_Detection.html">254 cvpr-2013-Learning SURF Cascade for Fast and Accurate Object Detection</a></p>
<p>Author: Jianguo Li, Yimin Zhang</p><p>Abstract: This paper presents a novel learning framework for training boosting cascade based object detector from large scale dataset. The framework is derived from the wellknown Viola-Jones (VJ) framework but distinguished by three key differences. First, the proposed framework adopts multi-dimensional SURF features instead of single dimensional Haar features to describe local patches. In this way, the number of used local patches can be reduced from hundreds of thousands to several hundreds. Second, it adopts logistic regression as weak classifier for each local patch instead of decision trees in the VJ framework. Third, we adopt AUC as a single criterion for the convergence test during cascade training rather than the two trade-off criteria (false-positive-rate and hit-rate) in the VJ framework. The benefit is that the false-positive-rate can be adaptive among different cascade stages, and thus yields much faster convergence speed of SURF cascade. Combining these points together, the proposed approach has three good properties. First, the boosting cascade can be trained very efficiently. Experiments show that the proposed approach can train object detectors from billions of negative samples within one hour even on personal computers. Second, the built detector is comparable to the stateof-the-art algorithm not only on the accuracy but also on the processing speed. Third, the built detector is small in model-size due to short cascade stages.</p><p>4 0.66696513 <a title="168-lsi-4" href="./cvpr-2013-Optimizing_1-Nearest_Prototype_Classifiers.html">320 cvpr-2013-Optimizing 1-Nearest Prototype Classifiers</a></p>
<p>Author: Paul Wohlhart, Martin Köstinger, Michael Donoser, Peter M. Roth, Horst Bischof</p><p>Abstract: The development of complex, powerful classifiers and their constant improvement have contributed much to the progress in many fields of computer vision. However, the trend towards large scale datasets revived the interest in simpler classifiers to reduce runtime. Simple nearest neighbor classifiers have several beneficial properties, such as low complexity and inherent multi-class handling, however, they have a runtime linear in the size of the database. Recent related work represents data samples by assigning them to a set of prototypes that partition the input feature space and afterwards applies linear classifiers on top of this representation to approximate decision boundaries locally linear. In this paper, we go a step beyond these approaches and purely focus on 1-nearest prototype classification, where we propose a novel algorithm for deriving optimal prototypes in a discriminative manner from the training samples. Our method is implicitly multi-class capable, parameter free, avoids noise overfitting and, since during testing only comparisons to the derived prototypes are required, highly efficient. Experiments demonstrate that we are able to outperform related locally linear methods, while even getting close to the results of more complex classifiers.</p><p>5 0.64435124 <a title="168-lsi-5" href="./cvpr-2013-Efficient_Detector_Adaptation_for_Object_Detection_in_a_Video.html">142 cvpr-2013-Efficient Detector Adaptation for Object Detection in a Video</a></p>
<p>Author: Pramod Sharma, Ram Nevatia</p><p>Abstract: In this work, we present a novel and efficient detector adaptation method which improves the performance of an offline trained classifier (baseline classifier) by adapting it to new test datasets. We address two critical aspects of adaptation methods: generalizability and computational efficiency. We propose an adaptation method, which can be applied to various baseline classifiers and is computationally efficient also. For a given test video, we collect online samples in an unsupervised manner and train a randomfern adaptive classifier . The adaptive classifier improves precision of the baseline classifier by validating the obtained detection responses from baseline classifier as correct detections or false alarms. Experiments demonstrate generalizability, computational efficiency and effectiveness of our method, as we compare our method with state of the art approaches for the problem of human detection and show good performance with high computational efficiency on two different baseline classifiers.</p><p>6 0.63596153 <a title="168-lsi-6" href="./cvpr-2013-Kernel_Null_Space_Methods_for_Novelty_Detection.html">239 cvpr-2013-Kernel Null Space Methods for Novelty Detection</a></p>
<p>7 0.63135082 <a title="168-lsi-7" href="./cvpr-2013-Semi-supervised_Node_Splitting_for_Random_Forest_Construction.html">390 cvpr-2013-Semi-supervised Node Splitting for Random Forest Construction</a></p>
<p>8 0.61319762 <a title="168-lsi-8" href="./cvpr-2013-Discriminative_Sub-categorization.html">134 cvpr-2013-Discriminative Sub-categorization</a></p>
<p>9 0.61269391 <a title="168-lsi-9" href="./cvpr-2013-Learning_by_Associating_Ambiguously_Labeled_Images.html">261 cvpr-2013-Learning by Associating Ambiguously Labeled Images</a></p>
<p>10 0.61266625 <a title="168-lsi-10" href="./cvpr-2013-Selective_Transfer_Machine_for_Personalized_Facial_Action_Unit_Detection.html">385 cvpr-2013-Selective Transfer Machine for Personalized Facial Action Unit Detection</a></p>
<p>11 0.61259753 <a title="168-lsi-11" href="./cvpr-2013-Alternating_Decision_Forests.html">39 cvpr-2013-Alternating Decision Forests</a></p>
<p>12 0.59465539 <a title="168-lsi-12" href="./cvpr-2013-Seeking_the_Strongest_Rigid_Detector.html">383 cvpr-2013-Seeking the Strongest Rigid Detector</a></p>
<p>13 0.58909607 <a title="168-lsi-13" href="./cvpr-2013-Vantage_Feature_Frames_for_Fine-Grained_Categorization.html">452 cvpr-2013-Vantage Feature Frames for Fine-Grained Categorization</a></p>
<p>14 0.58879888 <a title="168-lsi-14" href="./cvpr-2013-Semi-supervised_Learning_with_Constraints_for_Person_Identification_in_Multimedia_Data.html">389 cvpr-2013-Semi-supervised Learning with Constraints for Person Identification in Multimedia Data</a></p>
<p>15 0.58610106 <a title="168-lsi-15" href="./cvpr-2013-Real-Time_No-Reference_Image_Quality_Assessment_Based_on_Filter_Learning.html">346 cvpr-2013-Real-Time No-Reference Image Quality Assessment Based on Filter Learning</a></p>
<p>16 0.58262742 <a title="168-lsi-16" href="./cvpr-2013-Discriminative_Brain_Effective_Connectivity_Analysis_for_Alzheimer%27s_Disease%3A_A_Kernel_Learning_Approach_upon_Sparse_Gaussian_Bayesian_Network.html">129 cvpr-2013-Discriminative Brain Effective Connectivity Analysis for Alzheimer's Disease: A Kernel Learning Approach upon Sparse Gaussian Bayesian Network</a></p>
<p>17 0.56830323 <a title="168-lsi-17" href="./cvpr-2013-Adaptive_Active_Learning_for_Image_Classification.html">34 cvpr-2013-Adaptive Active Learning for Image Classification</a></p>
<p>18 0.56776822 <a title="168-lsi-18" href="./cvpr-2013-Fast_Multiple-Part_Based_Object_Detection_Using_KD-Ferns.html">167 cvpr-2013-Fast Multiple-Part Based Object Detection Using KD-Ferns</a></p>
<p>19 0.56537575 <a title="168-lsi-19" href="./cvpr-2013-Finding_Things%3A_Image_Parsing_with_Regions_and_Per-Exemplar_Detectors.html">173 cvpr-2013-Finding Things: Image Parsing with Regions and Per-Exemplar Detectors</a></p>
<p>20 0.5649181 <a title="168-lsi-20" href="./cvpr-2013-Semi-supervised_Learning_of_Feature_Hierarchies_for_Object_Detection_in_a_Video.html">388 cvpr-2013-Semi-supervised Learning of Feature Hierarchies for Object Detection in a Video</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(6, 0.176), (10, 0.122), (16, 0.019), (19, 0.011), (26, 0.065), (33, 0.264), (67, 0.096), (69, 0.053), (76, 0.012), (87, 0.09)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.91429454 <a title="168-lda-1" href="./cvpr-2013-Megastereo%3A_Constructing_High-Resolution_Stereo_Panoramas.html">283 cvpr-2013-Megastereo: Constructing High-Resolution Stereo Panoramas</a></p>
<p>Author: Christian Richardt, Yael Pritch, Henning Zimmer, Alexander Sorkine-Hornung</p><p>Abstract: We present a solution for generating high-quality stereo panoramas at megapixel resolutions. While previous approaches introduced the basic principles, we show that those techniques do not generalise well to today’s high image resolutions and lead to disturbing visual artefacts. As our first contribution, we describe the necessary correction steps and a compact representation for the input images in order to achieve a highly accurate approximation to the required ray space. Our second contribution is a flow-based upsampling of the available input rays which effectively resolves known aliasing issues like stitching artefacts. The required rays are generated on the fly to perfectly match the desired output resolution, even for small numbers of input images. In addition, the upsampling is real-time and enables direct interactive control over the desired stereoscopic depth effect. In combination, our contributions allow the generation of stereoscopic panoramas at high output resolutions that are virtually free of artefacts such as seams, stereo discontinuities, vertical parallax and other mono-/stereoscopic shape distortions. Our process is robust, and other types of multiperspective panoramas, such as linear panoramas, can also benefit from our contributions. We show various comparisons and high-resolution results.</p><p>2 0.89391416 <a title="168-lda-2" href="./cvpr-2013-Action_Recognition_by_Hierarchical_Sequence_Summarization.html">32 cvpr-2013-Action Recognition by Hierarchical Sequence Summarization</a></p>
<p>Author: Yale Song, Louis-Philippe Morency, Randall Davis</p><p>Abstract: Recent progress has shown that learning from hierarchical feature representations leads to improvements in various computer vision tasks. Motivated by the observation that human activity data contains information at various temporal resolutions, we present a hierarchical sequence summarization approach for action recognition that learns multiple layers of discriminative feature representations at different temporal granularities. We build up a hierarchy dynamically and recursively by alternating sequence learning and sequence summarization. For sequence learning we use CRFs with latent variables to learn hidden spatiotemporal dynamics; for sequence summarization we group observations that have similar semantic meaning in the latent space. For each layer we learn an abstract feature representation through non-linear gate functions. This procedure is repeated to obtain a hierarchical sequence summary representation. We develop an efficient learning method to train our model and show that its complexity grows sublinearly with the size of the hierarchy. Experimental results show the effectiveness of our approach, achieving the best published results on the ArmGesture and Canal9 datasets.</p><p>same-paper 3 0.88478303 <a title="168-lda-3" href="./cvpr-2013-Fast_Object_Detection_with_Entropy-Driven_Evaluation.html">168 cvpr-2013-Fast Object Detection with Entropy-Driven Evaluation</a></p>
<p>Author: Raphael Sznitman, Carlos Becker, François Fleuret, Pascal Fua</p><p>Abstract: Cascade-style approaches to implementing ensemble classifiers can deliver significant speed-ups at test time. While highly effective, they remain challenging to tune and their overall performance depends on the availability of large validation sets to estimate rejection thresholds. These characteristics are often prohibitive and thus limit their applicability. We introduce an alternative approach to speeding-up classifier evaluation which overcomes these limitations. It involves maintaining a probability estimate of the class label at each intermediary response and stopping when the corresponding uncertainty becomes small enough. As a result, the evaluation terminates early based on the sequence of responses observed. Furthermore, it does so independently of the type of ensemble classifier used or the way it was trained. We show through extensive experimentation that our method provides 2 to 10 fold speed-ups, over existing state-of-the-art methods, at almost no loss in accuracy on a number of object classification tasks.</p><p>4 0.87172002 <a title="168-lda-4" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>Author: Ian Endres, Kevin J. Shih, Johnston Jiaa, Derek Hoiem</p><p>Abstract: We propose a method to learn a diverse collection of discriminative parts from object bounding box annotations. Part detectors can be trained and applied individually, which simplifies learning and extension to new features or categories. We apply the parts to object category detection, pooling part detections within bottom-up proposed regions and using a boosted classifier with proposed sigmoid weak learners for scoring. On PASCAL VOC 2010, we evaluate the part detectors ’ ability to discriminate and localize annotated keypoints. Our detection system is competitive with the best-existing systems, outperforming other HOG-based detectors on the more deformable categories.</p><p>5 0.86308318 <a title="168-lda-5" href="./cvpr-2013-Detecting_and_Aligning_Faces_by_Image_Retrieval.html">119 cvpr-2013-Detecting and Aligning Faces by Image Retrieval</a></p>
<p>Author: Xiaohui Shen, Zhe Lin, Jonathan Brandt, Ying Wu</p><p>Abstract: Detecting faces in uncontrolled environments continues to be a challenge to traditional face detection methods[24] due to the large variation in facial appearances, as well as occlusion and clutter. In order to overcome these challenges, we present a novel and robust exemplarbased face detector that integrates image retrieval and discriminative learning. A large database of faces with bounding rectangles and facial landmark locations is collected, and simple discriminative classifiers are learned from each of them. A voting-based method is then proposed to let these classifiers cast votes on the test image through an efficient image retrieval technique. As a result, faces can be very efficiently detected by selecting the modes from the voting maps, without resorting to exhaustive sliding window-style scanning. Moreover, due to the exemplar-based framework, our approach can detect faces under challenging conditions without explicitly modeling their variations. Evaluation on two public benchmark datasets shows that our new face detection approach is accurate and efficient, and achieves the state-of-the-art performance. We further propose to use image retrieval for face validation (in order to remove false positives) and for face alignment/landmark localization. The same methodology can also be easily generalized to other facerelated tasks, such as attribute recognition, as well as general object detection.</p><p>6 0.86253321 <a title="168-lda-6" href="./cvpr-2013-Structure_Preserving_Object_Tracking.html">414 cvpr-2013-Structure Preserving Object Tracking</a></p>
<p>7 0.86179721 <a title="168-lda-7" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<p>8 0.860129 <a title="168-lda-8" href="./cvpr-2013-Part_Discovery_from_Partial_Correspondence.html">325 cvpr-2013-Part Discovery from Partial Correspondence</a></p>
<p>9 0.86009121 <a title="168-lda-9" href="./cvpr-2013-Learning_SURF_Cascade_for_Fast_and_Accurate_Object_Detection.html">254 cvpr-2013-Learning SURF Cascade for Fast and Accurate Object Detection</a></p>
<p>10 0.85985172 <a title="168-lda-10" href="./cvpr-2013-Integrating_Grammar_and_Segmentation_for_Human_Pose_Estimation.html">225 cvpr-2013-Integrating Grammar and Segmentation for Human Pose Estimation</a></p>
<p>11 0.8592487 <a title="168-lda-11" href="./cvpr-2013-Understanding_Indoor_Scenes_Using_3D_Geometric_Phrases.html">446 cvpr-2013-Understanding Indoor Scenes Using 3D Geometric Phrases</a></p>
<p>12 0.85918301 <a title="168-lda-12" href="./cvpr-2013-Spatiotemporal_Deformable_Part_Models_for_Action_Detection.html">408 cvpr-2013-Spatiotemporal Deformable Part Models for Action Detection</a></p>
<p>13 0.85899425 <a title="168-lda-13" href="./cvpr-2013-Occlusion_Patterns_for_Object_Class_Detection.html">311 cvpr-2013-Occlusion Patterns for Object Class Detection</a></p>
<p>14 0.8581385 <a title="168-lda-14" href="./cvpr-2013-Probabilistic_Graphlet_Cut%3A_Exploiting_Spatial_Structure_Cue_for_Weakly_Supervised_Image_Segmentation.html">339 cvpr-2013-Probabilistic Graphlet Cut: Exploiting Spatial Structure Cue for Weakly Supervised Image Segmentation</a></p>
<p>15 0.85795844 <a title="168-lda-15" href="./cvpr-2013-MODEC%3A_Multimodal_Decomposable_Models_for_Human_Pose_Estimation.html">277 cvpr-2013-MODEC: Multimodal Decomposable Models for Human Pose Estimation</a></p>
<p>16 0.85777688 <a title="168-lda-16" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<p>17 0.85740471 <a title="168-lda-17" href="./cvpr-2013-A_Joint_Model_for_2D_and_3D_Pose_Estimation_from_a_Single_Image.html">14 cvpr-2013-A Joint Model for 2D and 3D Pose Estimation from a Single Image</a></p>
<p>18 0.85652137 <a title="168-lda-18" href="./cvpr-2013-Label_Propagation_from_ImageNet_to_3D_Point_Clouds.html">242 cvpr-2013-Label Propagation from ImageNet to 3D Point Clouds</a></p>
<p>19 0.85576385 <a title="168-lda-19" href="./cvpr-2013-Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking.html">285 cvpr-2013-Minimum Uncertainty Gap for Robust Visual Tracking</a></p>
<p>20 0.85567719 <a title="168-lda-20" href="./cvpr-2013-Detection_Evolution_with_Multi-order_Contextual_Co-occurrence.html">122 cvpr-2013-Detection Evolution with Multi-order Contextual Co-occurrence</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
