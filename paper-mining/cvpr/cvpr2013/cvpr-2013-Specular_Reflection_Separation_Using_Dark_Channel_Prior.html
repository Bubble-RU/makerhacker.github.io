<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>410 cvpr-2013-Specular Reflection Separation Using Dark Channel Prior</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-410" href="#">cvpr2013-410</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>410 cvpr-2013-Specular Reflection Separation Using Dark Channel Prior</h1>
<br/><p>Source: <a title="cvpr-2013-410-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Kim_Specular_Reflection_Separation_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Hyeongwoo Kim, Hailin Jin, Sunil Hadap, Inso Kweon</p><p>Abstract: We present a novel method to separate specular reflection from a single image. Separating an image into diffuse and specular components is an ill-posed problem due to lack of observations. Existing methods rely on a specularfree image to detect and estimate specularity, which however may confuse diffuse pixels with the same hue but a different saturation value as specular pixels. Our method is based on a novel observation that for most natural images the dark channel can provide an approximate specular-free image. We also propose a maximum a posteriori formulation which robustly recovers the specular reflection and chromaticity despite of the hue-saturation ambiguity. We demonstrate the effectiveness of the proposed algorithm on real and synthetic examples. Experimental results show that our method significantly outperforms the state-of-theart methods in separating specular reflection.</p><p>Reference: <a title="cvpr-2013-410-reference" href="../cvpr2013_reference/cvpr-2013-Specular_Reflection_Separation_Using_Dark_Channel_Prior_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Specular Reflection Separation using Dark Channel Prior  Hyeongwoo Kim KAIST  Hailin Jin Adobe Research  hyeongwoo . [sent-1, score-0.046]
</p><p>2 com  Abstract We present a novel method to separate specular reflection from a single image. [sent-5, score-0.955]
</p><p>3 Separating an image into diffuse and specular components is an ill-posed problem due to lack of observations. [sent-6, score-1.019]
</p><p>4 Existing methods rely on a specularfree image to detect and estimate specularity, which however may confuse diffuse pixels with the same hue but a different saturation value as specular pixels. [sent-7, score-1.184]
</p><p>5 Our method is based on a novel observation that for most natural images the dark channel can provide an approximate specular-free image. [sent-8, score-0.275]
</p><p>6 We also propose a maximum a posteriori formulation which robustly recovers the specular reflection and chromaticity despite of the hue-saturation ambiguity. [sent-9, score-1.255]
</p><p>7 Experimental results show that our method significantly outperforms the state-of-theart methods in separating specular reflection. [sent-11, score-0.587]
</p><p>8 Introduction The observed color of an image is formed from the spec-  tral energy distributions of the light reflected by the surface reflectance, and the intensity of the color is determined by the imaging geometry. [sent-13, score-0.251]
</p><p>9 This imaging process can also be explained in terms of the diffuse and specular reflections according to their physical properties. [sent-14, score-1.202]
</p><p>10 Diffuse reflection can be assumed to be associated only with the relative angle between the light direction and the surface normal among the imaging geometry regardless of the viewing direction, while specular reflection is dependent on the viewing direction. [sent-15, score-1.514]
</p><p>11 As shown in Figure 1(a), natural objects tend to have the diffuse property as well as the specular property on the reflection model. [sent-16, score-1.441]
</p><p>12 However, the behavior of the specular reflection often leads to problems in many computer vision applications such as stereo matching, segmentation, and recognition. [sent-17, score-0.972]
</p><p>13 Most of the applications simply consider the observed image as a diffuse reflection model, regarding the specular reflection as outliers. [sent-18, score-1.87]
</p><p>14 One of the notable works in separating specular reflection from a single image is studied by Tan and Ikeuchi [18]. [sent-19, score-1.017]
</p><p>15 Sunil Hadap  Inso Kweon  Adobe Research  KAIST  hadap@ adobe . [sent-20, score-0.068]
</p><p>16 Our result correctly distinguishes between diffuse and specular reflections, while the previous method inadequately recognizes the background region as specular reflection. [sent-29, score-1.537]
</p><p>17 Note that dark channel is similar to the specular component recovered by the previous method in many cases of natural images. [sent-30, score-0.842]
</p><p>18 Their method shows a satisfactory result, however it fails in the presence of the colors which have the same hue component with different saturation one. [sent-32, score-0.162]
</p><p>19 This hue-saturation ambiguity has been an issue in the recent studies of the single image-based specular reflection separation. [sent-33, score-0.955]
</p><p>20 To address the limit of the previous approaches, we introduce the statistics that a diffuse pixel of natural images in general has very low intensity in at least one color channel, motivated by the dark channel prior [4]. [sent-34, score-0.851]
</p><p>21 As shown in Figure 1(c), the dark channel of an image provides a pseudo specular reflection result, which is similar to the previous result shown in Figure 1(d). [sent-35, score-1.457]
</p><p>22 In this paper, we also propose a maximum a posteriori (MAP) approach that incorporates priors in the 111444556088  reflection model, resulting in more stable separation of the specular reflection shown in Figure 1(b). [sent-36, score-1.505]
</p><p>23 Related Work Separating object reflectance into diffuse and specular components is one of the fundamental problems in the computer vision and graphics areas, which is made difficult by the subtle nature of the physics involved. [sent-38, score-1.05]
</p><p>24 Since the dichromatic reflection model [14] which represents the complex reflecting properties of a surface as a linear combination of the diffuse and specular components was introduced, this model has been adopted in modern approaches for color  understanding. [sent-39, score-1.695]
</p><p>25 [12] improved this polarization-based method by incorporating color information that is the neighboring diffuse colors. [sent-43, score-0.531]
</p><p>26 Some efforts have been made in separating the reflections with multiple images. [sent-44, score-0.232]
</p><p>27 Advantages of using the multiview constraint come from the different physical properties of diffuse and specular reflections on the relation between lighting and viewing directions with respect to a surface normal. [sent-45, score-1.228]
</p><p>28 Sato and Ikeuchi [13] analyzed color signatures estimated from many images taken under a moving light source to compute specular reflection. [sent-46, score-0.636]
</p><p>29 Lin and Shum [9] took a couple of images with different light positions in order to obtain photometric images and estimate the intensities of the reflection components. [sent-47, score-0.49]
</p><p>30 The use of a pair of stereo images was also introduced by Lin et al. [sent-48, score-0.017]
</p><p>31 [8], where specular pixels are detected by color histogram and stereo correspondence is then employed to compute the corresponding  diffuse components in other views. [sent-49, score-1.097]
</p><p>32 These approaches show satisfactory results in separating specular reflection, yet it is not always applicable in general cases due to the requirement of multiple images. [sent-50, score-0.609]
</p><p>33 Besides the multiple images-based approaches, there have been a number of literatures separating the reflections from a single image. [sent-51, score-0.232]
</p><p>34 [2] identified specular and diffuse reflections on the basis of color segmentation. [sent-55, score-1.226]
</p><p>35 [16] successfully separated highlight reflections by using repeated textures. [sent-57, score-0.188]
</p><p>36 The third category is the analysis on different color spaces. [sent-58, score-0.061]
</p><p>37 [11] proposed an SUV color space which is composed of S and UV channels representing specular and diffuse components respectively. [sent-60, score-1.106]
</p><p>38 They extended the use of this color space to highlight removal by eroding S channel in [10]. [sent-61, score-0.224]
</p><p>39 [18, 17] demonstrated the effective algorithm in the chromaticity intensity space, which exploits a pseudo specular-free image to detect the diffuse pixels and iteratively propagates the maximum chromaticity of the diffuse component to adjacent neighborhoods. [sent-63, score-1.808]
</p><p>40 [22] who developed a fast bilateral filtering [21] approach for the purpose of refining maximum chromaticity with neighboring pixels in real-time. [sent-65, score-0.28]
</p><p>41 In this paper, we present an approach that incorporates an effective pseudo specular-free image and priors for the separation of the specular reflection out of a single image. [sent-66, score-1.284]
</p><p>42 We show that the dark channel as an alternative pseudo specular-free image has merits against the previous one. [sent-67, score-0.502]
</p><p>43 In addition, our approach introduces priors on the specular reflection as well as the diffuse chromaticity in the dichromatic reflection model, whereas most of the previous methods only measure the fidelity to the reflection model. [sent-68, score-2.753]
</p><p>44 Reflection Model Dichromatic reflection model [14] has been widely used for understanding reflection properties of a scene taken by a color image. [sent-71, score-0.921]
</p><p>45 We model an image as a linear combination of diffuse and specular reflections according to the dichromatic model. [sent-72, score-1.325]
</p><p>46 Denoting the diffuse and specular reflections by Id(x) and Is (x) respectively, the observed image I(x) is simply expressed as: I(x) = Id(x) + Is (x) . [sent-73, score-1.18]
</p><p>47 (1)  In our model, we represent the chromaticity of a color with the intensity normalized color vector:  ˜I(x) =? [sent-74, score-0.419]
</p><p>48 Let Λ(x) and Γ(x) represent the chromaticities of the diffuse and specular components respectively. [sent-77, score-1.039]
</p><p>49 Then Equation (1) can be  equivalently written as: I(x) = md(x)Λ(x) + ms (x)Γ(x) ,  (3)  where md and ms are the diffuse and specular reflection coefficients respectively, which depend on imaging geometry. [sent-78, score-1.651]
</p><p>50 We note that the diffuse chromaticity implies the inherent color of the surface while the specular chromaticity implies that of the illumination. [sent-79, score-1.639]
</p><p>51 Here, the specular chromaticity can be assumed to be uniform for a given image such that Γr (x) = Γg (x) = Γb(x) = 1/3. [sent-80, score-0.791]
</p><p>52 Geometric interpretation of our pseudo specular-free image and dark channel in the dichromatic reflection model. [sent-82, score-1.092]
</p><p>53 of generality, this can be achieved by normalizing the illumination chromaticity estimated from [19] as preprocessing step. [sent-87, score-0.281]
</p><p>54 Our goal is to estimate the specular reflection coefficient ms (x) from the observed single image I(x) so that the specular component Is (x) can be recovered, multiplied by the uniform specular chromaticity Γ, i. [sent-88, score-2.406]
</p><p>55 In our formulation, we represent the dichromatic reflection model in the RG chromaticity space: I˜(x) = α(x)Λ(x) + (1 − α(x))Γ,  (4)  where α = md/(md + ms). [sent-91, score-0.856]
</p><p>56 Note that the specular reflection coefficient can be easily recovered from ms = (1−α)(md +ms), where md +ms = ? [sent-92, score-1.133]
</p><p>57 This data fidelity term is ill-posed with respect to α. [sent-102, score-0.026]
</p><p>58 (5) The ob-  served image only provides a partial constraint for the specular reflection coefficient as there are many counterparts of the diffuse reflection term resulting in the same observed image. [sent-103, score-1.926]
</p><p>59 This under-constrained problem can be resolved by specifying the diffuse chromaticity Λ. [sent-104, score-0.736]
</p><p>60 Dark Channel  and Pseudo  Specular-Free  Image To begin with, we shortly discuss typical algorithms and their limitations in determining the diffuse chromaticity Λ. [sent-106, score-0.752]
</p><p>61 In particular, the left parts of the hemispheres in (b) and (c) are identical. [sent-114, score-0.046]
</p><p>62 Previous works [18, 22] utilize the pseudo specular-free image to detect the diffuse pixels and estimate the diffuse chromaticity, which is generated by shifting the maximum chromaticity of each pixel. [sent-115, score-1.463]
</p><p>63 However, these approaches are problematic especially when there exist pure diffuse reflections  having the same hue but different saturation value since they are all detected as specular reflections. [sent-116, score-1.287]
</p><p>64 To address this issue and improve the general performance, we introduce a simple but effective pseudo specularfree image followed by an efficient optimization framework. [sent-117, score-0.312]
</p><p>65 Motivated by [4], we exploits the dark channel to derive a new pseudo specular-free image. [sent-118, score-0.517]
</p><p>66 Based on our observation that a diffuse pixel is likely to have very low intensity in at least one color channel for most of natural images, we consider the dark channel as the rough estimate of the specular reflection for the input image. [sent-119, score-1.923]
</p><p>67 Thus, we obtain our pseudo specular-free image Ipseudo(x) by subtracting the dark channel Idark (x) from all color channels: Ipcseudo(x)  =  Ic(x) − Idark,  (6)  Idark(x)  =  c∈m{r,ing,b}Ic(x). [sent-120, score-0.563]
</p><p>68 (7)  Here, the dark channel is taken from the lowest intensity value among RGB channels at each pixel. [sent-121, score-0.316]
</p><p>69 As illustrated in Figure 2(d), this process is equivalent to project each pixel of the input image to one of the RG-, RB-, and, GBplanes along the illumination direction. [sent-122, score-0.029]
</p><p>70 In particular, the pseudo specular-free pixel (yellow dot) is obtained by projecting the pixel (green dot) of the input image to RG-plane along the illumination direction Γ. [sent-123, score-0.286]
</p><p>71 We note that this pseudo specular-free pixel has the incorrect diffuse coefficient m? [sent-124, score-0.753]
</p><p>72 compared to the correct diffuse reflection component (red dot). [sent-126, score-0.92]
</p><p>73 We take the pseudo specular-free  image and dark channel as the initial estimates of the diffuse and specular reflections respectively and then find the correct one by the optimization which will be explained later in detail. [sent-127, score-1.667]
</p><p>74 This scheme has a couple of benefits against the previous approach [18]. [sent-128, score-0.024]
</p><p>75 As shown in Figure 3, our pseudo specularfree image provides the direct estimate for the diffuse reflection. [sent-129, score-0.782]
</p><p>76 For instance, the left parts of the hemispheres in Figure 3 (b) and (c) are shown to be exactly identical to each 111444666200  111444666311  111444666422  111444666533  Figure 9. [sent-130, score-0.06]
</p><p>77 (b) and (c) Diffuse and specular reflections of our result. [sent-133, score-0.695]
</p><p>78 The proposed method achieves more robust results in the presence of two distinct diffuse colors having the same hue but different saturation value, and qualitatively outperforms the state-of-the-art methods for most of natural images. [sent-137, score-0.606]
</p><p>79 As discussed in the real examples, color boundaries are unfortunately found as specular pixels in some results. [sent-138, score-0.586]
</p><p>80 In the future work, we plan to reduce this artifact by improving the robustness of the clustering algorithm for the noise and highly textured surfaces. [sent-139, score-0.013]
</p><p>81 Detection of diffuse and specular interface reflections and inter-reflections by color image segmentation. [sent-156, score-1.249]
</p><p>82 Solving for colour constancy using a constrained dichromatic reflection model. [sent-162, score-0.59]
</p><p>83 Separation of diffuse and specular reflection in color images. [sent-207, score-1.486]
</p><p>84 Specularity removal in images and videos: A PDE approach. [sent-217, score-0.028]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('specular', 0.525), ('diffuse', 0.47), ('reflection', 0.43), ('chromaticity', 0.266), ('pseudo', 0.243), ('reflections', 0.17), ('dichromatic', 0.16), ('dark', 0.142), ('channel', 0.117), ('ms', 0.074), ('idark', 0.069), ('specularfree', 0.069), ('adobe', 0.068), ('separating', 0.062), ('color', 0.061), ('separation', 0.056), ('md', 0.056), ('hue', 0.053), ('saturation', 0.053), ('mallick', 0.051), ('hadap', 0.046), ('hemispheres', 0.046), ('hyeongwoo', 0.046), ('klinker', 0.046), ('kai', 0.041), ('kaist', 0.041), ('light', 0.036), ('specularity', 0.035), ('ic', 0.035), ('ikeuchi', 0.031), ('intensity', 0.031), ('reflectance', 0.031), ('tan', 0.03), ('kweon', 0.029), ('dot', 0.028), ('removal', 0.028), ('sato', 0.027), ('zickler', 0.026), ('channels', 0.026), ('coefficient', 0.026), ('nayar', 0.026), ('fidelity', 0.026), ('surface', 0.025), ('components', 0.024), ('couple', 0.024), ('viewing', 0.023), ('lin', 0.023), ('interface', 0.023), ('imaging', 0.022), ('satisfactory', 0.022), ('recovered', 0.022), ('component', 0.02), ('gilboa', 0.02), ('haze', 0.02), ('ular', 0.02), ('hailin', 0.02), ('chromaticities', 0.02), ('shafer', 0.02), ('posteriori', 0.02), ('kr', 0.019), ('inso', 0.019), ('finlayson', 0.019), ('lambert', 0.019), ('highlight', 0.018), ('spec', 0.018), ('stereo', 0.017), ('fresnel', 0.017), ('pde', 0.017), ('recognizes', 0.017), ('pure', 0.016), ('priors', 0.016), ('shortly', 0.016), ('natural', 0.016), ('id', 0.016), ('served', 0.016), ('ijcv', 0.016), ('physical', 0.015), ('exploits', 0.015), ('polarization', 0.015), ('shum', 0.015), ('illumination', 0.015), ('observed', 0.015), ('fang', 0.015), ('josa', 0.015), ('incorporates', 0.014), ('maximum', 0.014), ('korea', 0.014), ('pixel', 0.014), ('colors', 0.014), ('uv', 0.014), ('lischinski', 0.014), ('identical', 0.014), ('rgb', 0.014), ('counterparts', 0.014), ('neutral', 0.014), ('signatures', 0.014), ('confuse', 0.014), ('implies', 0.013), ('artifact', 0.013), ('propagates', 0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9999997 <a title="410-tfidf-1" href="./cvpr-2013-Specular_Reflection_Separation_Using_Dark_Channel_Prior.html">410 cvpr-2013-Specular Reflection Separation Using Dark Channel Prior</a></p>
<p>Author: Hyeongwoo Kim, Hailin Jin, Sunil Hadap, Inso Kweon</p><p>Abstract: We present a novel method to separate specular reflection from a single image. Separating an image into diffuse and specular components is an ill-posed problem due to lack of observations. Existing methods rely on a specularfree image to detect and estimate specularity, which however may confuse diffuse pixels with the same hue but a different saturation value as specular pixels. Our method is based on a novel observation that for most natural images the dark channel can provide an approximate specular-free image. We also propose a maximum a posteriori formulation which robustly recovers the specular reflection and chromaticity despite of the hue-saturation ambiguity. We demonstrate the effectiveness of the proposed algorithm on real and synthetic examples. Experimental results show that our method significantly outperforms the state-of-theart methods in separating specular reflection.</p><p>2 0.2427225 <a title="410-tfidf-2" href="./cvpr-2013-Video_Enhancement_of_People_Wearing_Polarized_Glasses%3A_Darkening_Reversal_and_Reflection_Reduction.html">454 cvpr-2013-Video Enhancement of People Wearing Polarized Glasses: Darkening Reversal and Reflection Reduction</a></p>
<p>Author: Mao Ye, Cha Zhang, Ruigang Yang</p><p>Abstract: With the wide-spread of consumer 3D-TV technology, stereoscopic videoconferencing systems are emerging. However, the special glasses participants wear to see 3D can create distracting images. This paper presents a computational framework to reduce undesirable artifacts in the eye regions caused by these 3D glasses. More specifically, we add polarized filters to the stereo camera so that partial images of reflection can be captured. A novel Bayesian model is then developed to describe the imaging process of the eye regions including darkening and reflection, and infer the eye regions based on Classification ExpectationMaximization (EM). The recovered eye regions under the glasses are brighter and with little reflections, leading to a more nature videoconferencing experience. Qualitative evaluations and user studies are conducted to demonstrate the substantial improvement our approach can achieve.</p><p>3 0.16800538 <a title="410-tfidf-3" href="./cvpr-2013-Mirror_Surface_Reconstruction_from_a_Single_Image.html">286 cvpr-2013-Mirror Surface Reconstruction from a Single Image</a></p>
<p>Author: Miaomiao Liu, Richard Hartley, Mathieu Salzmann</p><p>Abstract: This paper tackles the problem of reconstructing the shape of a smooth mirror surface from a single image. In particular, we consider the case where the camera is observing the reflection of a static reference target in the unknown mirror. We first study the reconstruction problem given dense correspondences between 3D points on the reference target and image locations. In such conditions, our differential geometry analysis provides a theoretical proof that the shape of the mirror surface can be uniquely recovered if the pose of the reference target is known. We then relax our assumptions by considering the case where only sparse correspondences are available. In this scenario, we formulate reconstruction as an optimization problem, which can be solved using a nonlinear least-squares method. We demonstrate the effectiveness of our method on both synthetic and real images.</p><p>4 0.1277692 <a title="410-tfidf-4" href="./cvpr-2013-Uncalibrated_Photometric_Stereo_for_Unknown_Isotropic_Reflectances.html">443 cvpr-2013-Uncalibrated Photometric Stereo for Unknown Isotropic Reflectances</a></p>
<p>Author: Feng Lu, Yasuyuki Matsushita, Imari Sato, Takahiro Okabe, Yoichi Sato</p><p>Abstract: We propose an uncalibrated photometric stereo method that works with general and unknown isotropic reflectances. Our method uses a pixel intensity profile, which is a sequence of radiance intensities recorded at a pixel across multi-illuminance images. We show that for general isotropic materials, the geodesic distance between intensity profiles is linearly related to the angular difference of their surface normals, and that the intensity distribution of an intensity profile conveys information about the reflectance properties, when the intensity profile is obtained under uniformly distributed directional lightings. Based on these observations, we show that surface normals can be estimated up to a convex/concave ambiguity. A solution method based on matrix decomposition with missing data is developed for a reliable estimation. Quantitative and qualitative evaluations of our method are performed using both synthetic and real-world scenes.</p><p>5 0.11647096 <a title="410-tfidf-5" href="./cvpr-2013-A_Theory_of_Refractive_Photo-Light-Path_Triangulation.html">27 cvpr-2013-A Theory of Refractive Photo-Light-Path Triangulation</a></p>
<p>Author: Visesh Chari, Peter Sturm</p><p>Abstract: 3D reconstruction of transparent refractive objects like a plastic bottle is challenging: they lack appearance related visual cues and merely reflect and refract light from the surrounding environment. Amongst several approaches to reconstruct such objects, the seminal work of Light-Path triangulation [17] is highly popular because of its general applicability and analysis of minimal scenarios. A lightpath is defined as the piece-wise linear path taken by a ray of light as it passes from source, through the object and into the camera. Transparent refractive objects not only affect the geometric configuration of light-paths but also their radiometric properties. In this paper, we describe a method that combines both geometric and radiometric information to do reconstruction. We show two major consequences of the addition of radiometric cues to the light-path setup. Firstly, we extend the case of scenarios in which reconstruction is plausible while reducing the minimal re- quirements for a unique reconstruction. This happens as a consequence of the fact that radiometric cues add an additional known variable to the already existing system of equations. Secondly, we present a simple algorithm for reconstruction, owing to the nature of the radiometric cue. We present several synthetic experiments to validate our theories, and show high quality reconstructions in challenging scenarios.</p><p>6 0.10384792 <a title="410-tfidf-6" href="./cvpr-2013-Discovering_the_Structure_of_a_Planar_Mirror_System_from_Multiple_Observations_of_a_Single_Point.html">127 cvpr-2013-Discovering the Structure of a Planar Mirror System from Multiple Observations of a Single Point</a></p>
<p>7 0.093922265 <a title="410-tfidf-7" href="./cvpr-2013-Multi-view_Photometric_Stereo_with_Spatially_Varying_Isotropic_Materials.html">303 cvpr-2013-Multi-view Photometric Stereo with Spatially Varying Isotropic Materials</a></p>
<p>8 0.090823822 <a title="410-tfidf-8" href="./cvpr-2013-Calibrating_Photometric_Stereo_by_Holistic_Reflectance_Symmetry_Analysis.html">75 cvpr-2013-Calibrating Photometric Stereo by Holistic Reflectance Symmetry Analysis</a></p>
<p>9 0.076883674 <a title="410-tfidf-9" href="./cvpr-2013-Illumination_Estimation_Based_on_Bilayer_Sparse_Coding.html">210 cvpr-2013-Illumination Estimation Based on Bilayer Sparse Coding</a></p>
<p>10 0.072941929 <a title="410-tfidf-10" href="./cvpr-2013-Evaluation_of_Color_STIPs_for_Human_Action_Recognition.html">149 cvpr-2013-Evaluation of Color STIPs for Human Action Recognition</a></p>
<p>11 0.072411664 <a title="410-tfidf-11" href="./cvpr-2013-Reconstructing_Gas_Flows_Using_Light-Path_Approximation.html">349 cvpr-2013-Reconstructing Gas Flows Using Light-Path Approximation</a></p>
<p>12 0.05991159 <a title="410-tfidf-12" href="./cvpr-2013-Recovering_Stereo_Pairs_from_Anaglyphs.html">352 cvpr-2013-Recovering Stereo Pairs from Anaglyphs</a></p>
<p>13 0.058712538 <a title="410-tfidf-13" href="./cvpr-2013-Photometric_Ambient_Occlusion.html">330 cvpr-2013-Photometric Ambient Occlusion</a></p>
<p>14 0.058649477 <a title="410-tfidf-14" href="./cvpr-2013-Discriminative_Color_Descriptors.html">130 cvpr-2013-Discriminative Color Descriptors</a></p>
<p>15 0.046289444 <a title="410-tfidf-15" href="./cvpr-2013-A_New_Perspective_on_Uncalibrated_Photometric_Stereo.html">21 cvpr-2013-A New Perspective on Uncalibrated Photometric Stereo</a></p>
<p>16 0.044828184 <a title="410-tfidf-16" href="./cvpr-2013-What_Object_Motion_Reveals_about_Shape_with_Unknown_BRDF_and_Lighting.html">465 cvpr-2013-What Object Motion Reveals about Shape with Unknown BRDF and Lighting</a></p>
<p>17 0.044465065 <a title="410-tfidf-17" href="./cvpr-2013-Three-Dimensional_Bilateral_Symmetry_Plane_Estimation_in_the_Phase_Domain.html">432 cvpr-2013-Three-Dimensional Bilateral Symmetry Plane Estimation in the Phase Domain</a></p>
<p>18 0.043831304 <a title="410-tfidf-18" href="./cvpr-2013-FrameBreak%3A_Dramatic_Image_Extrapolation_by_Guided_Shift-Maps.html">177 cvpr-2013-FrameBreak: Dramatic Image Extrapolation by Guided Shift-Maps</a></p>
<p>19 0.043575034 <a title="410-tfidf-19" href="./cvpr-2013-Layer_Depth_Denoising_and_Completion_for_Structured-Light_RGB-D_Cameras.html">245 cvpr-2013-Layer Depth Denoising and Completion for Structured-Light RGB-D Cameras</a></p>
<p>20 0.041705068 <a title="410-tfidf-20" href="./cvpr-2013-Analytic_Bilinear_Appearance_Subspace_Construction_for_Modeling_Image_Irradiance_under_Natural_Illumination_and_Non-Lambertian_Reflectance.html">42 cvpr-2013-Analytic Bilinear Appearance Subspace Construction for Modeling Image Irradiance under Natural Illumination and Non-Lambertian Reflectance</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.066), (1, 0.087), (2, 0.005), (3, 0.032), (4, -0.005), (5, -0.057), (6, -0.05), (7, 0.026), (8, 0.027), (9, -0.001), (10, -0.036), (11, -0.054), (12, -0.003), (13, -0.05), (14, -0.018), (15, 0.07), (16, 0.098), (17, -0.035), (18, 0.053), (19, -0.005), (20, 0.021), (21, 0.007), (22, -0.016), (23, -0.023), (24, -0.041), (25, -0.019), (26, 0.046), (27, 0.064), (28, 0.001), (29, 0.019), (30, -0.015), (31, -0.037), (32, 0.046), (33, -0.105), (34, 0.027), (35, -0.07), (36, -0.003), (37, 0.104), (38, -0.004), (39, -0.075), (40, -0.01), (41, 0.04), (42, -0.07), (43, 0.075), (44, -0.023), (45, 0.197), (46, 0.024), (47, 0.074), (48, -0.132), (49, -0.124)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96490061 <a title="410-lsi-1" href="./cvpr-2013-Specular_Reflection_Separation_Using_Dark_Channel_Prior.html">410 cvpr-2013-Specular Reflection Separation Using Dark Channel Prior</a></p>
<p>Author: Hyeongwoo Kim, Hailin Jin, Sunil Hadap, Inso Kweon</p><p>Abstract: We present a novel method to separate specular reflection from a single image. Separating an image into diffuse and specular components is an ill-posed problem due to lack of observations. Existing methods rely on a specularfree image to detect and estimate specularity, which however may confuse diffuse pixels with the same hue but a different saturation value as specular pixels. Our method is based on a novel observation that for most natural images the dark channel can provide an approximate specular-free image. We also propose a maximum a posteriori formulation which robustly recovers the specular reflection and chromaticity despite of the hue-saturation ambiguity. We demonstrate the effectiveness of the proposed algorithm on real and synthetic examples. Experimental results show that our method significantly outperforms the state-of-theart methods in separating specular reflection.</p><p>2 0.75012481 <a title="410-lsi-2" href="./cvpr-2013-Video_Enhancement_of_People_Wearing_Polarized_Glasses%3A_Darkening_Reversal_and_Reflection_Reduction.html">454 cvpr-2013-Video Enhancement of People Wearing Polarized Glasses: Darkening Reversal and Reflection Reduction</a></p>
<p>Author: Mao Ye, Cha Zhang, Ruigang Yang</p><p>Abstract: With the wide-spread of consumer 3D-TV technology, stereoscopic videoconferencing systems are emerging. However, the special glasses participants wear to see 3D can create distracting images. This paper presents a computational framework to reduce undesirable artifacts in the eye regions caused by these 3D glasses. More specifically, we add polarized filters to the stereo camera so that partial images of reflection can be captured. A novel Bayesian model is then developed to describe the imaging process of the eye regions including darkening and reflection, and infer the eye regions based on Classification ExpectationMaximization (EM). The recovered eye regions under the glasses are brighter and with little reflections, leading to a more nature videoconferencing experience. Qualitative evaluations and user studies are conducted to demonstrate the substantial improvement our approach can achieve.</p><p>3 0.73917949 <a title="410-lsi-3" href="./cvpr-2013-Discovering_the_Structure_of_a_Planar_Mirror_System_from_Multiple_Observations_of_a_Single_Point.html">127 cvpr-2013-Discovering the Structure of a Planar Mirror System from Multiple Observations of a Single Point</a></p>
<p>Author: Ilya Reshetouski, Alkhazur Manakov, Ayush Bandhari, Ramesh Raskar, Hans-Peter Seidel, Ivo Ihrke</p><p>Abstract: We investigate the problem of identifying the position of a viewer inside a room of planar mirrors with unknown geometry in conjunction with the room’s shape parameters. We consider the observations to consist of angularly resolved depth measurements of a single scene point that is being observed via many multi-bounce interactions with the specular room geometry. Applications of this problem statement include areas such as calibration, acoustic echo cancelation and time-of-flight imaging. We theoretically analyze the problem and derive sufficient conditions for a combination of convex room geometry, observer, and scene point to be reconstructable. The resulting constructive algorithm is exponential in nature and, therefore, not directly applicable to practical scenarios. To counter the situation, we propose theoretically devised geometric constraints that enable an efficient pruning of the solution space and develop a heuristic randomized search algorithm that uses these constraints to obtain an effective solution. We demonstrate the effectiveness of our algorithm on extensive simulations as well as in a challenging real-world calibration scenario.</p><p>4 0.59097862 <a title="410-lsi-4" href="./cvpr-2013-Mirror_Surface_Reconstruction_from_a_Single_Image.html">286 cvpr-2013-Mirror Surface Reconstruction from a Single Image</a></p>
<p>Author: Miaomiao Liu, Richard Hartley, Mathieu Salzmann</p><p>Abstract: This paper tackles the problem of reconstructing the shape of a smooth mirror surface from a single image. In particular, we consider the case where the camera is observing the reflection of a static reference target in the unknown mirror. We first study the reconstruction problem given dense correspondences between 3D points on the reference target and image locations. In such conditions, our differential geometry analysis provides a theoretical proof that the shape of the mirror surface can be uniquely recovered if the pose of the reference target is known. We then relax our assumptions by considering the case where only sparse correspondences are available. In this scenario, we formulate reconstruction as an optimization problem, which can be solved using a nonlinear least-squares method. We demonstrate the effectiveness of our method on both synthetic and real images.</p><p>5 0.50117838 <a title="410-lsi-5" href="./cvpr-2013-A_Theory_of_Refractive_Photo-Light-Path_Triangulation.html">27 cvpr-2013-A Theory of Refractive Photo-Light-Path Triangulation</a></p>
<p>Author: Visesh Chari, Peter Sturm</p><p>Abstract: 3D reconstruction of transparent refractive objects like a plastic bottle is challenging: they lack appearance related visual cues and merely reflect and refract light from the surrounding environment. Amongst several approaches to reconstruct such objects, the seminal work of Light-Path triangulation [17] is highly popular because of its general applicability and analysis of minimal scenarios. A lightpath is defined as the piece-wise linear path taken by a ray of light as it passes from source, through the object and into the camera. Transparent refractive objects not only affect the geometric configuration of light-paths but also their radiometric properties. In this paper, we describe a method that combines both geometric and radiometric information to do reconstruction. We show two major consequences of the addition of radiometric cues to the light-path setup. Firstly, we extend the case of scenarios in which reconstruction is plausible while reducing the minimal re- quirements for a unique reconstruction. This happens as a consequence of the fact that radiometric cues add an additional known variable to the already existing system of equations. Secondly, we present a simple algorithm for reconstruction, owing to the nature of the radiometric cue. We present several synthetic experiments to validate our theories, and show high quality reconstructions in challenging scenarios.</p><p>6 0.454229 <a title="410-lsi-6" href="./cvpr-2013-Reconstructing_Gas_Flows_Using_Light-Path_Approximation.html">349 cvpr-2013-Reconstructing Gas Flows Using Light-Path Approximation</a></p>
<p>7 0.4484714 <a title="410-lsi-7" href="./cvpr-2013-Uncalibrated_Photometric_Stereo_for_Unknown_Isotropic_Reflectances.html">443 cvpr-2013-Uncalibrated Photometric Stereo for Unknown Isotropic Reflectances</a></p>
<p>8 0.43293545 <a title="410-lsi-8" href="./cvpr-2013-Three-Dimensional_Bilateral_Symmetry_Plane_Estimation_in_the_Phase_Domain.html">432 cvpr-2013-Three-Dimensional Bilateral Symmetry Plane Estimation in the Phase Domain</a></p>
<p>9 0.42498779 <a title="410-lsi-9" href="./cvpr-2013-Spectral_Modeling_and_Relighting_of_Reflective-Fluorescent_Scenes.html">409 cvpr-2013-Spectral Modeling and Relighting of Reflective-Fluorescent Scenes</a></p>
<p>10 0.40125453 <a title="410-lsi-10" href="./cvpr-2013-Single_Image_Calibration_of_Multi-axial_Imaging_Systems.html">400 cvpr-2013-Single Image Calibration of Multi-axial Imaging Systems</a></p>
<p>11 0.38174614 <a title="410-lsi-11" href="./cvpr-2013-Multi-view_Photometric_Stereo_with_Spatially_Varying_Isotropic_Materials.html">303 cvpr-2013-Multi-view Photometric Stereo with Spatially Varying Isotropic Materials</a></p>
<p>12 0.38067186 <a title="410-lsi-12" href="./cvpr-2013-Calibrating_Photometric_Stereo_by_Holistic_Reflectance_Symmetry_Analysis.html">75 cvpr-2013-Calibrating Photometric Stereo by Holistic Reflectance Symmetry Analysis</a></p>
<p>13 0.37067947 <a title="410-lsi-13" href="./cvpr-2013-Axially_Symmetric_3D_Pots_Configuration_System_Using_Axis_of_Symmetry_and_Break_Curve.html">52 cvpr-2013-Axially Symmetric 3D Pots Configuration System Using Axis of Symmetry and Break Curve</a></p>
<p>14 0.34286204 <a title="410-lsi-14" href="./cvpr-2013-Light_Field_Distortion_Feature_for_Transparent_Object_Recognition.html">269 cvpr-2013-Light Field Distortion Feature for Transparent Object Recognition</a></p>
<p>15 0.3427254 <a title="410-lsi-15" href="./cvpr-2013-Towards_Contactless%2C_Low-Cost_and_Accurate_3D_Fingerprint_Identification.html">435 cvpr-2013-Towards Contactless, Low-Cost and Accurate 3D Fingerprint Identification</a></p>
<p>16 0.32474938 <a title="410-lsi-16" href="./cvpr-2013-Discriminative_Color_Descriptors.html">130 cvpr-2013-Discriminative Color Descriptors</a></p>
<p>17 0.32062075 <a title="410-lsi-17" href="./cvpr-2013-What_Object_Motion_Reveals_about_Shape_with_Unknown_BRDF_and_Lighting.html">465 cvpr-2013-What Object Motion Reveals about Shape with Unknown BRDF and Lighting</a></p>
<p>18 0.31583968 <a title="410-lsi-18" href="./cvpr-2013-Photometric_Ambient_Occlusion.html">330 cvpr-2013-Photometric Ambient Occlusion</a></p>
<p>19 0.31446311 <a title="410-lsi-19" href="./cvpr-2013-A_New_Perspective_on_Uncalibrated_Photometric_Stereo.html">21 cvpr-2013-A New Perspective on Uncalibrated Photometric Stereo</a></p>
<p>20 0.30922973 <a title="410-lsi-20" href="./cvpr-2013-Illumination_Estimation_Based_on_Bilayer_Sparse_Coding.html">210 cvpr-2013-Illumination Estimation Based on Bilayer Sparse Coding</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.065), (16, 0.519), (26, 0.027), (28, 0.011), (33, 0.134), (67, 0.03), (69, 0.038), (87, 0.053)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.81291139 <a title="410-lda-1" href="./cvpr-2013-Specular_Reflection_Separation_Using_Dark_Channel_Prior.html">410 cvpr-2013-Specular Reflection Separation Using Dark Channel Prior</a></p>
<p>Author: Hyeongwoo Kim, Hailin Jin, Sunil Hadap, Inso Kweon</p><p>Abstract: We present a novel method to separate specular reflection from a single image. Separating an image into diffuse and specular components is an ill-posed problem due to lack of observations. Existing methods rely on a specularfree image to detect and estimate specularity, which however may confuse diffuse pixels with the same hue but a different saturation value as specular pixels. Our method is based on a novel observation that for most natural images the dark channel can provide an approximate specular-free image. We also propose a maximum a posteriori formulation which robustly recovers the specular reflection and chromaticity despite of the hue-saturation ambiguity. We demonstrate the effectiveness of the proposed algorithm on real and synthetic examples. Experimental results show that our method significantly outperforms the state-of-theart methods in separating specular reflection.</p><p>2 0.65696049 <a title="410-lda-2" href="./cvpr-2013-Detecting_Pulse_from_Head_Motions_in_Video.html">118 cvpr-2013-Detecting Pulse from Head Motions in Video</a></p>
<p>Author: Guha Balakrishnan, Fredo Durand, John Guttag</p><p>Abstract: We extract heart rate and beat lengths from videos by measuring subtle head motion caused by the Newtonian reaction to the influx of blood at each beat. Our method tracks features on the head and performs principal component analysis (PCA) to decompose their trajectories into a set of component motions. It then chooses the component that best corresponds to heartbeats based on its temporal frequency spectrum. Finally, we analyze the motion projected to this component and identify peaks of the trajectories, which correspond to heartbeats. When evaluated on 18 subjects, our approach reported heart rates nearly identical to an electrocardiogram device. Additionally we were able to capture clinically relevant information about heart rate variability.</p><p>3 0.62814331 <a title="410-lda-3" href="./cvpr-2013-A_Theory_of_Refractive_Photo-Light-Path_Triangulation.html">27 cvpr-2013-A Theory of Refractive Photo-Light-Path Triangulation</a></p>
<p>Author: Visesh Chari, Peter Sturm</p><p>Abstract: 3D reconstruction of transparent refractive objects like a plastic bottle is challenging: they lack appearance related visual cues and merely reflect and refract light from the surrounding environment. Amongst several approaches to reconstruct such objects, the seminal work of Light-Path triangulation [17] is highly popular because of its general applicability and analysis of minimal scenarios. A lightpath is defined as the piece-wise linear path taken by a ray of light as it passes from source, through the object and into the camera. Transparent refractive objects not only affect the geometric configuration of light-paths but also their radiometric properties. In this paper, we describe a method that combines both geometric and radiometric information to do reconstruction. We show two major consequences of the addition of radiometric cues to the light-path setup. Firstly, we extend the case of scenarios in which reconstruction is plausible while reducing the minimal re- quirements for a unique reconstruction. This happens as a consequence of the fact that radiometric cues add an additional known variable to the already existing system of equations. Secondly, we present a simple algorithm for reconstruction, owing to the nature of the radiometric cue. We present several synthetic experiments to validate our theories, and show high quality reconstructions in challenging scenarios.</p><p>4 0.60560912 <a title="410-lda-4" href="./cvpr-2013-Information_Consensus_for_Distributed_Multi-target_Tracking.html">224 cvpr-2013-Information Consensus for Distributed Multi-target Tracking</a></p>
<p>Author: Ahmed T. Kamal, Jay A. Farrell, Amit K. Roy-Chowdhury</p><p>Abstract: Due to their high fault-tolerance, ease of installation and scalability to large networks, distributed algorithms have recently gained immense popularity in the sensor networks community, especially in computer vision. Multitarget tracking in a camera network is one of the fundamental problems in this domain. Distributed estimation algorithms work by exchanging information between sensors that are communication neighbors. Since most cameras are directional sensors, it is often the case that neighboring sensors may not be sensing the same target. Such sensors that do not have information about a target are termed as “naive ” with respect to that target. In this paper, we propose consensus-based distributed multi-target tracking algorithms in a camera network that are designed to address this issue of naivety. The estimation errors in tracking and data association, as well as the effect of naivety, are jointly addressed leading to the development of an informationweighted consensus algorithm, which we term as the Multitarget Information Consensus (MTIC) algorithm. The incorporation of the probabilistic data association mecha- nism makes the MTIC algorithm very robust to false measurements/clutter. Experimental analysis is provided to support the theoretical results.</p><p>5 0.58069772 <a title="410-lda-5" href="./cvpr-2013-Locally_Aligned_Feature_Transforms_across_Views.html">271 cvpr-2013-Locally Aligned Feature Transforms across Views</a></p>
<p>Author: Wei Li, Xiaogang Wang</p><p>Abstract: In this paper, we propose a new approach for matching images observed in different camera views with complex cross-view transforms and apply it to person reidentification. It jointly partitions the image spaces of two camera views into different configurations according to the similarity of cross-view transforms. The visual features of an image pair from different views are first locally aligned by being projected to a common feature space and then matched with softly assigned metrics which are locally optimized. The features optimal for recognizing identities are different from those for clustering cross-view transforms. They are jointly learned by utilizing sparsityinducing norm and information theoretical regularization. . cuhk . edu .hk (a) Camera view A (b) Camera view B This approach can be generalized to the settings where test images are from new camera views, not the same as those in the training set. Extensive experiments are conducted on public datasets and our own dataset. Comparisons with the state-of-the-art metric learning and person re-identification methods show the superior performance of our approach.</p><p>6 0.57471579 <a title="410-lda-6" href="./cvpr-2013-Robust_Multi-resolution_Pedestrian_Detection_in_Traffic_Scenes.html">363 cvpr-2013-Robust Multi-resolution Pedestrian Detection in Traffic Scenes</a></p>
<p>7 0.56992036 <a title="410-lda-7" href="./cvpr-2013-Efficient_2D-to-3D_Correspondence_Filtering_for_Scalable_3D_Object_Recognition.html">138 cvpr-2013-Efficient 2D-to-3D Correspondence Filtering for Scalable 3D Object Recognition</a></p>
<p>8 0.53346294 <a title="410-lda-8" href="./cvpr-2013-Sparse_Output_Coding_for_Large-Scale_Visual_Recognition.html">403 cvpr-2013-Sparse Output Coding for Large-Scale Visual Recognition</a></p>
<p>9 0.5093137 <a title="410-lda-9" href="./cvpr-2013-Patch_Match_Filter%3A_Efficient_Edge-Aware_Filtering_Meets_Randomized_Search_for_Fast_Correspondence_Field_Estimation.html">326 cvpr-2013-Patch Match Filter: Efficient Edge-Aware Filtering Meets Randomized Search for Fast Correspondence Field Estimation</a></p>
<p>10 0.45623434 <a title="410-lda-10" href="./cvpr-2013-Reconstructing_Gas_Flows_Using_Light-Path_Approximation.html">349 cvpr-2013-Reconstructing Gas Flows Using Light-Path Approximation</a></p>
<p>11 0.44213226 <a title="410-lda-11" href="./cvpr-2013-Robust_Feature_Matching_with_Alternate_Hough_and_Inverted_Hough_Transforms.html">361 cvpr-2013-Robust Feature Matching with Alternate Hough and Inverted Hough Transforms</a></p>
<p>12 0.43813822 <a title="410-lda-12" href="./cvpr-2013-Video_Enhancement_of_People_Wearing_Polarized_Glasses%3A_Darkening_Reversal_and_Reflection_Reduction.html">454 cvpr-2013-Video Enhancement of People Wearing Polarized Glasses: Darkening Reversal and Reflection Reduction</a></p>
<p>13 0.43628481 <a title="410-lda-13" href="./cvpr-2013-Uncalibrated_Photometric_Stereo_for_Unknown_Isotropic_Reflectances.html">443 cvpr-2013-Uncalibrated Photometric Stereo for Unknown Isotropic Reflectances</a></p>
<p>14 0.42621726 <a title="410-lda-14" href="./cvpr-2013-Discriminative_Color_Descriptors.html">130 cvpr-2013-Discriminative Color Descriptors</a></p>
<p>15 0.42038813 <a title="410-lda-15" href="./cvpr-2013-Depth_Super_Resolution_by_Rigid_Body_Self-Similarity_in_3D.html">115 cvpr-2013-Depth Super Resolution by Rigid Body Self-Similarity in 3D</a></p>
<p>16 0.4175497 <a title="410-lda-16" href="./cvpr-2013-Light_Field_Distortion_Feature_for_Transparent_Object_Recognition.html">269 cvpr-2013-Light Field Distortion Feature for Transparent Object Recognition</a></p>
<p>17 0.41310906 <a title="410-lda-17" href="./cvpr-2013-Recovering_Stereo_Pairs_from_Anaglyphs.html">352 cvpr-2013-Recovering Stereo Pairs from Anaglyphs</a></p>
<p>18 0.40627626 <a title="410-lda-18" href="./cvpr-2013-Segment-Tree_Based_Cost_Aggregation_for_Stereo_Matching.html">384 cvpr-2013-Segment-Tree Based Cost Aggregation for Stereo Matching</a></p>
<p>19 0.40187997 <a title="410-lda-19" href="./cvpr-2013-Evaluation_of_Color_STIPs_for_Human_Action_Recognition.html">149 cvpr-2013-Evaluation of Color STIPs for Human Action Recognition</a></p>
<p>20 0.4016417 <a title="410-lda-20" href="./cvpr-2013-Spectral_Modeling_and_Relighting_of_Reflective-Fluorescent_Scenes.html">409 cvpr-2013-Spectral Modeling and Relighting of Reflective-Fluorescent Scenes</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
