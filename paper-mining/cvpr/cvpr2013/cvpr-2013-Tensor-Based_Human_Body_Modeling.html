<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>426 cvpr-2013-Tensor-Based Human Body Modeling</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-426" href="#">cvpr2013-426</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>426 cvpr-2013-Tensor-Based Human Body Modeling</h1>
<br/><p>Source: <a title="cvpr-2013-426-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Chen_Tensor-Based_Human_Body_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Yinpeng Chen, Zicheng Liu, Zhengyou Zhang</p><p>Abstract: In this paper, we present a novel approach to model 3D human body with variations on both human shape and pose, by exploring a tensor decomposition technique. 3D human body modeling is important for 3D reconstruction and animation of realistic human body, which can be widely used in Tele-presence and video game applications. It is challenging due to a wide range of shape variations over different people and poses. The existing SCAPE model [4] is popular in computer vision for modeling 3D human body. However, it considers shape and pose deformations separately, which is not accurate since pose deformation is persondependent. Our tensor-based model addresses this issue by jointly modeling shape and pose deformations. Experimental results demonstrate that our tensor-based model outperforms the SCAPE model quite significantly. We also apply our model to capture human body using Microsoft Kinect sensors with excellent results.</p><p>Reference: <a title="cvpr-2013-426-reference" href="../cvpr2013_reference/cvpr-2013-Tensor-Based_Human_Body_Modeling_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 com iu  Abstract In this paper, we present a novel approach to model 3D human body with variations on both human shape and pose, by exploring a tensor decomposition technique. [sent-2, score-0.553]
</p><p>2 3D human body modeling is important for 3D reconstruction and animation of realistic human body, which can be widely used in Tele-presence and video game applications. [sent-3, score-0.335]
</p><p>3 However, it considers shape and pose deformations separately, which is not accurate since pose deformation is persondependent. [sent-6, score-0.574]
</p><p>4 We also apply our model to capture human body using Microsoft Kinect sensors with excellent results. [sent-9, score-0.272]
</p><p>5 Introduction 3D human body modeling has numerous applications in  Computer Vision, Graphics, and Multimedia. [sent-11, score-0.251]
</p><p>6 The problem is challenging because the variation in 3D human body geometry (over different people and poses) is a complicated function over multiple shape and pose variables. [sent-14, score-0.467]
</p><p>7 Among the early work in human body modeling [2, 13, 4, 3, 10], the SCAPE model [4] has been widely used in estimating human shape and pose as well as in reshaping human body in images and videos. [sent-15, score-0.819]
</p><p>8 It learns a pose deformation model from a subject with multiple poses and learns a shape model from many subjects with a neutral pose. [sent-16, score-0.808]
</p><p>9 However, the decoupling of shape and pose deformations in the SCAPE model has a major limitation - 3D meshes of different individuals change in the similar manner for the same pose change. [sent-17, score-0.421]
</p><p>10 We fit the SCAPE model on a female subject at the neutral pose  Figure 1. [sent-19, score-0.307]
</p><p>11 The shape parameters for both SCAPE and TenBo models are estimated from the original neutral pose data. [sent-22, score-0.327]
</p><p>12 Using the tensor decomposition technique, we model the deformation as a joint function over both shape and pose parameters to preserve the dependency between them. [sent-29, score-0.646]
</p><p>13 We also apply our TenBo model to capture human body using Microsoft Kinect sensors with excellent results. [sent-34, score-0.272]
</p><p>14 Then, we introduce mesh deformation definition and describe our TenBo model in details. [sent-37, score-0.371]
</p><p>15 Related Work 3D Human Body Models: The early human body models, including [2] and [13], focused on modeling the shape variations in similar poses. [sent-41, score-0.36]
</p><p>16 Allen [3] used maximum posteriori estimation to learn a correlated model of identity and pose-dependent body shape variation. [sent-43, score-0.328]
</p><p>17 The SCAPE model [4] is a widely used model which decouples shape and pose deformations. [sent-46, score-0.258]
</p><p>18 However, due to the decoupling, the pose deformation model is shared by all individuals, i. [sent-47, score-0.349]
</p><p>19 Human Shape and Pose Estimation: The SCAPE model [4] has been used widely in human shape and pose  estimation [8, 5, 6, 17, 20]. [sent-51, score-0.29]
</p><p>20 Guan [8] estimated human shape and pose from a single image using shading information. [sent-52, score-0.269]
</p><p>21 Weiss [17] scaned 3D human body from noisy image and range data by using silhouette objective. [sent-54, score-0.251]
</p><p>22 In [9], Hasler presented a bilinear model of shape and pose to estimate 3D meshes of dressed subjects from images. [sent-56, score-0.4]
</p><p>23 Tensor Faces: Tensor based approaches have been successfully applied to face modeling [15, 16], which motivated us to extend them to human body modeling. [sent-59, score-0.251]
</p><p>24 TenBo allows each subject to perform only a small subset of the poses rather than the full set and allows large variations among different subjects to perform the same pose, while TensorFaces requires the same capture configuration for all subjects (e. [sent-61, score-0.338]
</p><p>25 Overview Each 3D human body mesh can be considered as a deformation from a reference mesh. [sent-65, score-0.63]
</p><p>26 Our TenBo model considers the deformation D as a joint function D(v, θ) over shape parameters v and pose parameters θ to integrate  shape deformation (due to different persons) and pose deformation (due to different poses) using tensor technique. [sent-66, score-1.331]
</p><p>27 Compared with the SCAPE model, which separates the shape deformation S(v) and the pose deformation Q(θ) as D = S(v)Q(θ), our TenBo model is able to preserve the dependency between the shape and pose deformations. [sent-67, score-0.895]
</p><p>28 The SCAPE model only uses one subject (with multiple poses) to train the pose model and only uses one pose (from multiple persons) to train the shape model. [sent-69, score-0.434]
</p><p>29 In comparison, our TenBo model uses multiple poses from multiple subjects to combine the shape and pose deformations together. [sent-70, score-0.443]
</p><p>30 Mesh Deformation Definition We use the same mesh deformation definition as in the SCAPE model [4]. [sent-76, score-0.371]
</p><p>31 The deformation for an arbitrary 3D body mesh Y = {VY , P} indicates the difference between the mesh Y and {thVe r,ePfe}ren incdei mateessh t hXe. [sent-91, score-0.677]
</p><p>32 three vertices xn,1, xn,2, xn,3 of the triangle pn on the reference mesh X is deformed to yn,1, yn,2, 111000666  SCAPE ModelTenBo Model  SPTMrhosadiepnDelinD gfeiorfmerantiocen TpCUor saeni smTfidraouebnlmtreiopsn1hml. [sent-94, score-0.267]
</p><p>33 The deformation of triangle pn from X to Y is represented as the linear transformation of two edges ( Δxn,1 = xn,2 −xn,1 , Δxn,2 = xn,3 −xn,1) as follows: yn,3  Δyn,q =  yn,q+1 − yn,1  = Rl[n]DnΔxn,q,  q = 1, 2, (1)  where Rl[n] is the rotation matrix (from X to Y ) for the body segment l[n] (e. [sent-100, score-0.551]
</p><p>34 torso, upper arm) that includes the triangle pn, Dn is the non-rigid deformation matrix for the triangle pn. [sent-102, score-0.379]
</p><p>35 a tNricoetes {thDat Rl[n] i asl lsh traiarend-  ×  by all triangles belonging to the body segment l[n] . [sent-106, score-0.291]
</p><p>36 The calculation of Rl[n] and Dn for a given mesh Y and the 3D reconstruction of mesh Y using Rl[n] and Dn has been solved in the SCAPE model [4]. [sent-107, score-0.279]
</p><p>37 Tensor-based Human Body Model (TenBo) Our TenBo model includes two parts - (a) model for an individual body segment (e. [sent-110, score-0.333]
</p><p>38 We first introduce a tensor-based method to model the deformation of an individual body segment. [sent-113, score-0.44]
</p><p>39 Then we will discuss how to integrate local shape vector (refer to shape parameters for a body segment) into global shape vector (refer to shape parameters for the whole body). [sent-114, score-0.712]
</p><p>40 We use sl to denote the local shape vector on the lth body segment and use v to denote the global shape vector. [sent-115, score-0.639]
</p><p>41 Model for an Individual Body Segment  We model the deformation for each body segment as a joint function over both shape and pose parameters using tensor technique. [sent-121, score-0.903]
</p><p>42 We rearrange the deformation matrix Dn column by column as a 9 1vector for every triangle on the lctohl segment (including nl triangles) faonrd e group aial n vgelect oonrs t as  × ××  Figure 2. [sent-122, score-0.373]
</p><p>43 Tensor decomposition for the deformation of a body segment . [sent-123, score-0.478]
</p><p>44 Th×e Kloc)a,l a shape vector sl encodes the shape of the lth segment using It parameters. [sent-126, score-0.417]
</p><p>45 The joint angle vector θl includes joint angles from the two nearest joints of the lth segment (e. [sent-127, score-0.28]
</p><p>46 The deformation basis matrix Bl includes Kt deformation bases, which represent the deformation of the lth segment  ×  in a low dimensional space. [sent-132, score-0.82]
</p><p>47 GAfter training is completed, we can compute the deformation dl based on the local shape parameters sl and the joint angles θl , which are estimated for a specific person with a specific pose. [sent-150, score-0.59]
</p><p>48 Model for the Whole Body The local shape vectors sl from different body segments are highly correlated to the global shape vector v that encodes the shape of the whole body (e. [sent-153, score-0.863]
</p><p>49 We model this correlation using linear transform as: sl = Alv, (4) where sl includes It local shape parameters for the lth segment, v includes Iv global shape parameters, and Al is a  ×  transform matrix (It Iv) for the lth segment. [sent-156, score-0.66]
</p><p>50 By replacing the local shape vecto×r sl with the global shape vector v, eq. [sent-157, score-0.34]
</p><p>51 (5)  Combining all body segments, the entire TenBo model has L(ItJtKt + ItIv) + 9KtN parameters (ItJtKt parameters in Gl, ItIv parameters in Al, 9Ktnl parameters in Bl). [sent-159, score-0.327]
</p><p>52 Once we finish training the TenBo model, we can apply it to estimate shape parameters v and pose parameters θl using a 3D point cloud of a human body surface as input. [sent-161, score-0.552]
</p><p>53 Furthermore, we can generate animations for any subject (assuming shape vector v is available) with different pose sequences. [sent-162, score-0.308]
</p><p>54 Learning the TenBo Model The TenBo model is learnt based on a training dataset that includes 3D human body meshes from multiple subjects (each subject has one or multiple poses). [sent-165, score-0.515]
</p><p>55 Let us denote the number of subjects as I, the total number of poses as J and denote the number of poses for the ith subject as Ji (? [sent-167, score-0.328]
</p><p>56 Preprocessing  ×  In preprocessing, for every mesh in the training dataset, we compute the rotation matrix Rl and the joint angle vector θl for every body segment, and compute the deformation matrix Dn for every triangle (see calculation details in the SCAPE model [4]). [sent-173, score-0.727]
</p><p>57 Then, we rearrange Dn to generate segment deformation tensor dl (a 1 1 9nl tensor). [sent-174, score-0.472]
</p><p>58 We denote the deformation tensor a(nad 1th ×e joint angle vector for the jth pose for the ith subject as and respectively. [sent-175, score-0.579]
</p><p>59 Optimization  θli,j  The goal of training is to search for the optimum tensor core Gl, shape transform matrix Al and deformation bassoisr m coarterix G Bl for every body segment as well as the global shape vector vi for every training subject to minimize L2  ×× × ×  Figure 3. [sent-178, score-0.93]
</p><p>60 The deformation tensor Dl and joint angle matrix Θl . [sent-179, score-0.425]
</p><p>61 dli,j  distance between the actual deformation and the deformation generated by the tensor model (eq. [sent-180, score-0.582]
</p><p>62 Firstly, we group the deformation tensors and joint angle vectors of different poses for every subject as Dli = [dil,1 , . [sent-206, score-0.436]
</p><p>63 Note that training a TenBo model needs three inputs: dimension of the local shape vector It, dimension of the global shape vector Iv and the number of deformation bases Kt. [sent-254, score-0.504]
</p><p>64 Therefore, we can change the dimension of global shape parameters Iv by selecting the first Iv rows of as the global shape parameter matrix V . [sent-273, score-0.315]
</p><p>65 , zMp captured from a human body surface, determine the global shape parameters v and the pose parameters (or joint angles) θ, such that the difference between the reconstructed 3D human body based on v and θ and the original human body is minimum”. [sent-286, score-1.089]
</p><p>66 The rotation Rl[n] is a function of joint angles θ and the deformation Dn is a joint function of shape parameters v and joint angles θ. [sent-311, score-0.563]
</p><p>67 When using Microsoft Kinect, we can estimate the corresponding body segment l[zm] for each point zm using skeleton information. [sent-313, score-0.346]
</p><p>68 This is useful in searching for the closest vertex yclosest(zm) since it can significantly reduce the searching scope to the vertices on the body segment l[zm] . [sent-314, score-0.348]
</p><p>69 Other subjects perform either 10 predefined poses (randomly selected) or just the neutral pose. [sent-324, score-0.26]
</p><p>70 50 subjects only have the neutral pose and the other 39 subjects have more poses. [sent-328, score-0.377]
</p><p>71 A subject with more than two poses (except the reference subject) is selected as the validation data, and the remaining subjects are used for training both SCAPE and TenBo models. [sent-332, score-0.311]
</p><p>72 Accurate prediction requires (a) a good model to capture the relationship between the deformation and shape/pose parameters, and (b) accurate estimation of global shape parameters v. [sent-338, score-0.45]
</p><p>73 We use the average deformation error in the prediction over all validation subjects as the evaluation measure. [sent-339, score-0.422]
</p><p>74 The deformation error between a predicted mesh Yr (including vertices {yr1 . [sent-340, score-0.431]
</p><p>75 error is approximately proportional to the difference in deformation matrix Dn because: Δyrn,q − Δyno,q ≈ Rl[n] (Drn − Dno)Δxn,q, (10) where Drn is the deformation matrix to generate the predicted mesh Yr, Dno is the ground truth deformation matrix obtained from the original mesh Yo. [sent-355, score-1.01]
</p><p>76 In our experiment, the deformation error is highly correlated to the average deformation matrix difference (En | |Drn − Dno | |) with Pearson correlation 0. [sent-356, score-0.487]
</p><p>77 Since the deformation error and the Hausdorff distance have the same trend in results, we only show the deformation error for the sake of brevity. [sent-361, score-0.488]
</p><p>78 When training the TenBo model, we heuristically choose the local shape dimension It = 4 due to the low dimensional shape of body segment. [sent-367, score-0.416]
</p><p>79 In the prediction step, we predict the 3D geometry for non-neutral poses for the validation subject using the global  shape vector v (estimated under the neutral pose) and correspondingjoint angles θ for the non-neutral poses (computed in preprocessing). [sent-368, score-0.577]
</p><p>80 We estimate the global shape vector v using the neutral pose in two different ways: (a) using entire body scan as input, and (b) using sampled vertices as input. [sent-369, score-0.58]
</p><p>81 1  Using Entire Body Mesh for Shape Estimation  Using the entire body scan as input, the deformation tensor dl and joint angles θ are available (calculated in preprocessing). [sent-372, score-0.673]
</p><p>82 Figure (5) shows the prediction error for the SCAPE model and four TenBo models over different number of global shape parameters Iv. [sent-375, score-0.252]
</p><p>83 This is likely because the mesh resolution is low and the mesh alignment is not perfect. [sent-386, score-0.258]
</p><p>84 In the rest of this section, we use 4 global shape parameters (Iv = 4) for both SCAPE and TenBo models, and use 10 deformation bases (Kt = 10) for TenBo. [sent-388, score-0.401]
</p><p>85 For each validation subject, we randomly sample vertices on the 3D mesh of the neutral pose. [sent-399, score-0.308]
</p><p>86 Different from using the entire mesh, we can not compute the deformation and joint angles directly from the sampled  vertices. [sent-401, score-0.303]
</p><p>87 Therefore, we use the fitting algorithm in Section 7 to estimate both shape and pose parameters. [sent-402, score-0.255]
</p><p>88 We have three observations - (a) TenBo model outperforms the SCAPE model, (b) prediction error converges when the sampling rate is above 10%, so we do not need a lot of data to estimate body shape, and (c) sampling the whole body helps when the sampling rate is lower than 10%. [sent-405, score-0.572]
</p><p>89 The fitting algorithm is run on a single desktop without GPU acceleration to fit 100 point clouds, which are generate by random vertex sampling on 100 3D body scans (at sampling rate 20%). [sent-416, score-0.361]
</p><p>90 We use the  average shape at the neutral pose as the initial guess. [sent-417, score-0.3]
</p><p>91 Note that both models have the same complexity in animation where shape parameters are known and only pose parameters change over time. [sent-429, score-0.301]
</p><p>92 3D Reconstruction Using Microsoft Kinect We also apply the TenBo model to capture 3D human  body using Microsoft Kinect. [sent-432, score-0.272]
</p><p>93 With the help of skeleton, the body segment correspondence for pixels in the depth map can be easily estimated. [sent-433, score-0.257]
</p><p>94 Conclusion This paper presents a novel tensor-based 3D human body model (TenBo model). [sent-440, score-0.272]
</p><p>95 Compared with the popular SCAPE model which separates the shape and pose deformations, the proposed approach jointly models shape and pose deformations in a systematic manner. [sent-441, score-0.483]
</p><p>96 Our TenBo model is capable of capturing the human body shape using the depth map and skeleton provided by Microsoft Kinect sensors and generating animations. [sent-443, score-0.406]
</p><p>97 Learning a correlated model of identity and pose-dependent body shape variation for real-time synthesis. [sent-468, score-0.328]
</p><p>98 Estimating human shape and pose from a single image. [sent-513, score-0.269]
</p><p>99 Multilinear pose and body shape estimation of dressed subjects from image sets. [sent-524, score-0.53]
</p><p>100 A statistical model of human pose and body shape. [sent-533, score-0.379]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('tenbo', 0.665), ('scape', 0.476), ('deformation', 0.221), ('body', 0.198), ('mesh', 0.129), ('tensor', 0.119), ('shape', 0.109), ('pose', 0.107), ('gl', 0.107), ('sl', 0.098), ('subjects', 0.093), ('bl', 0.088), ('rl', 0.084), ('neutral', 0.084), ('poses', 0.083), ('dn', 0.072), ('subject', 0.069), ('zm', 0.064), ('hasler', 0.063), ('segment', 0.059), ('iv', 0.059), ('vertices', 0.058), ('human', 0.053), ('dl', 0.053), ('triangle', 0.051), ('prediction', 0.048), ('meshes', 0.047), ('kt', 0.045), ('kinect', 0.044), ('microsoft', 0.042), ('lth', 0.042), ('joint', 0.042), ('angles', 0.04), ('fitting', 0.039), ('alv', 0.038), ('itjtkt', 0.038), ('yclosest', 0.038), ('multilinear', 0.038), ('validation', 0.037), ('guan', 0.036), ('scans', 0.035), ('drn', 0.034), ('includes', 0.034), ('triangles', 0.034), ('vertex', 0.033), ('male', 0.032), ('balan', 0.031), ('freifeld', 0.031), ('animation', 0.031), ('cloud', 0.031), ('deformations', 0.03), ('allen', 0.03), ('reference', 0.029), ('jt', 0.029), ('dno', 0.028), ('dli', 0.028), ('sampling', 0.028), ('reshaping', 0.027), ('parameters', 0.027), ('female', 0.026), ('principal', 0.026), ('bltbl', 0.026), ('dlv', 0.026), ('drape', 0.026), ('itiv', 0.026), ('msec', 0.026), ('naked', 0.026), ('tensorfaces', 0.026), ('vtalt', 0.026), ('weiss', 0.025), ('skeleton', 0.025), ('preprocessing', 0.024), ('global', 0.024), ('ji', 0.023), ('error', 0.023), ('dressed', 0.023), ('animations', 0.023), ('vasilescu', 0.023), ('vtm', 0.023), ('hirshberg', 0.023), ('matrix', 0.022), ('angle', 0.021), ('model', 0.021), ('ahlen', 0.021), ('thorm', 0.021), ('zuffi', 0.021), ('bases', 0.02), ('um', 0.02), ('rearrange', 0.02), ('slt', 0.02), ('forearm', 0.02), ('al', 0.019), ('hausdorff', 0.019), ('pearson', 0.019), ('rosenhahn', 0.019), ('cross', 0.019), ('segments', 0.018), ('mna', 0.018), ('mpi', 0.018), ('popovi', 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="426-tfidf-1" href="./cvpr-2013-Tensor-Based_Human_Body_Modeling.html">426 cvpr-2013-Tensor-Based Human Body Modeling</a></p>
<p>Author: Yinpeng Chen, Zicheng Liu, Zhengyou Zhang</p><p>Abstract: In this paper, we present a novel approach to model 3D human body with variations on both human shape and pose, by exploring a tensor decomposition technique. 3D human body modeling is important for 3D reconstruction and animation of realistic human body, which can be widely used in Tele-presence and video game applications. It is challenging due to a wide range of shape variations over different people and poses. The existing SCAPE model [4] is popular in computer vision for modeling 3D human body. However, it considers shape and pose deformations separately, which is not accurate since pose deformation is persondependent. Our tensor-based model addresses this issue by jointly modeling shape and pose deformations. Experimental results demonstrate that our tensor-based model outperforms the SCAPE model quite significantly. We also apply our model to capture human body using Microsoft Kinect sensors with excellent results.</p><p>2 0.17210639 <a title="426-tfidf-2" href="./cvpr-2013-Templateless_Quasi-rigid_Shape_Modeling_with_Implicit_Loop-Closure.html">424 cvpr-2013-Templateless Quasi-rigid Shape Modeling with Implicit Loop-Closure</a></p>
<p>Author: Ming Zeng, Jiaxiang Zheng, Xuan Cheng, Xinguo Liu</p><p>Abstract: This paper presents a method for quasi-rigid objects modeling from a sequence of depth scans captured at different time instances. As quasi-rigid objects, such as human bodies, usually have shape motions during the capture procedure, it is difficult to reconstruct their geometries. We represent the shape motion by a deformation graph, and propose a model-to-partmethod to gradually integrate sampled points of depth scans into the deformation graph. Under an as-rigid-as-possible assumption, the model-to-part method can adjust the deformation graph non-rigidly, so as to avoid error accumulation in alignment, which also implicitly achieves loop-closure. To handle the drift and topological error for the deformation graph, two algorithms are introduced. First, we use a two-stage registration to largely keep the rigid motion part. Second, in the step of graph integration, we topology-adaptively integrate new parts and dynamically control the regularization effect of the deformation graph. We demonstrate the effectiveness and robustness of our method by several depth sequences of quasi-rigid objects, and an application in human shape modeling.</p><p>3 0.12598328 <a title="426-tfidf-3" href="./cvpr-2013-Optical_Flow_Estimation_Using_Laplacian_Mesh_Energy.html">316 cvpr-2013-Optical Flow Estimation Using Laplacian Mesh Energy</a></p>
<p>Author: Wenbin Li, Darren Cosker, Matthew Brown, Rui Tang</p><p>Abstract: In this paper we present a novel non-rigid optical flow algorithm for dense image correspondence and non-rigid registration. The algorithm uses a unique Laplacian Mesh Energy term to encourage local smoothness whilst simultaneously preserving non-rigid deformation. Laplacian deformation approaches have become popular in graphics research as they enable mesh deformations to preserve local surface shape. In this work we propose a novel Laplacian Mesh Energy formula to ensure such sensible local deformations between image pairs. We express this wholly within the optical flow optimization, and show its application in a novel coarse-to-fine pyramidal approach. Our algorithm achieves the state-of-the-art performance in all trials on the Garg et al. dataset, and top tier performance on the Middlebury evaluation.</p><p>4 0.12518233 <a title="426-tfidf-4" href="./cvpr-2013-Pose_from_Flow_and_Flow_from_Pose.html">334 cvpr-2013-Pose from Flow and Flow from Pose</a></p>
<p>Author: Katerina Fragkiadaki, Han Hu, Jianbo Shi</p><p>Abstract: Human pose detectors, although successful in localising faces and torsos of people, often fail with lower arms. Motion estimation is often inaccurate under fast movements of body parts. We build a segmentation-detection algorithm that mediates the information between body parts recognition, and multi-frame motion grouping to improve both pose detection and tracking. Motion of body parts, though not accurate, is often sufficient to segment them from their backgrounds. Such segmentations are crucialfor extracting hard to detect body parts out of their interior body clutter. By matching these segments to exemplars we obtain pose labeled body segments. The pose labeled segments and corresponding articulated joints are used to improve the motion flow fields by proposing kinematically constrained affine displacements on body parts. The pose-based articulated motion model is shown to handle large limb rotations and displacements. Our algorithm can detect people under rare poses, frequently missed by pose detectors, showing the benefits of jointly reasoning about pose, segmentation and motion in videos.</p><p>5 0.12140173 <a title="426-tfidf-5" href="./cvpr-2013-An_Approach_to_Pose-Based_Action_Recognition.html">40 cvpr-2013-An Approach to Pose-Based Action Recognition</a></p>
<p>Author: Chunyu Wang, Yizhou Wang, Alan L. Yuille</p><p>Abstract: We address action recognition in videos by modeling the spatial-temporal structures of human poses. We start by improving a state of the art method for estimating human joint locations from videos. More precisely, we obtain the K-best estimations output by the existing method and incorporate additional segmentation cues and temporal constraints to select the “best” one. Then we group the estimated joints into five body parts (e.g. the left arm) and apply data mining techniques to obtain a representation for the spatial-temporal structures of human actions. This representation captures the spatial configurations ofbodyparts in one frame (by spatial-part-sets) as well as the body part movements(by temporal-part-sets) which are characteristic of human actions. It is interpretable, compact, and also robust to errors on joint estimations. Experimental results first show that our approach is able to localize body joints more accurately than existing methods. Next we show that it outperforms state of the art action recognizers on the UCF sport, the Keck Gesture and the MSR-Action3D datasets.</p><p>6 0.12129438 <a title="426-tfidf-6" href="./cvpr-2013-A_Joint_Model_for_2D_and_3D_Pose_Estimation_from_a_Single_Image.html">14 cvpr-2013-A Joint Model for 2D and 3D Pose Estimation from a Single Image</a></p>
<p>7 0.11650816 <a title="426-tfidf-7" href="./cvpr-2013-Human_Pose_Estimation_Using_Body_Parts_Dependent_Joint_Regressors.html">206 cvpr-2013-Human Pose Estimation Using Body Parts Dependent Joint Regressors</a></p>
<p>8 0.10592746 <a title="426-tfidf-8" href="./cvpr-2013-Poselet_Conditioned_Pictorial_Structures.html">335 cvpr-2013-Poselet Conditioned Pictorial Structures</a></p>
<p>9 0.098611869 <a title="426-tfidf-9" href="./cvpr-2013-Mesh_Based_Semantic_Modelling_for_Indoor_and_Outdoor_Scenes.html">284 cvpr-2013-Mesh Based Semantic Modelling for Indoor and Outdoor Scenes</a></p>
<p>10 0.095215827 <a title="426-tfidf-10" href="./cvpr-2013-Unconstrained_Monocular_3D_Human_Pose_Estimation_by_Action_Detection_and_Cross-Modality_Regression_Forest.html">444 cvpr-2013-Unconstrained Monocular 3D Human Pose Estimation by Action Detection and Cross-Modality Regression Forest</a></p>
<p>11 0.092114866 <a title="426-tfidf-11" href="./cvpr-2013-Multi-target_Tracking_by_Rank-1_Tensor_Approximation.html">301 cvpr-2013-Multi-target Tracking by Rank-1 Tensor Approximation</a></p>
<p>12 0.088611826 <a title="426-tfidf-12" href="./cvpr-2013-Human_Pose_Estimation_Using_a_Joint_Pixel-wise_and_Part-wise_Formulation.html">207 cvpr-2013-Human Pose Estimation Using a Joint Pixel-wise and Part-wise Formulation</a></p>
<p>13 0.087692387 <a title="426-tfidf-13" href="./cvpr-2013-Multi-resolution_Shape_Analysis_via_Non-Euclidean_Wavelets%3A_Applications_to_Mesh_Segmentation_and_Surface_Alignment_Problems.html">297 cvpr-2013-Multi-resolution Shape Analysis via Non-Euclidean Wavelets: Applications to Mesh Segmentation and Surface Alignment Problems</a></p>
<p>14 0.072355106 <a title="426-tfidf-14" href="./cvpr-2013-Correspondence-Less_Non-rigid_Registration_of_Triangular_Surface_Meshes.html">97 cvpr-2013-Correspondence-Less Non-rigid Registration of Triangular Surface Meshes</a></p>
<p>15 0.071453989 <a title="426-tfidf-15" href="./cvpr-2013-Watching_Unlabeled_Video_Helps_Learn_New_Human_Actions_from_Very_Few_Labeled_Snapshots.html">459 cvpr-2013-Watching Unlabeled Video Helps Learn New Human Actions from Very Few Labeled Snapshots</a></p>
<p>16 0.068948537 <a title="426-tfidf-16" href="./cvpr-2013-Class_Generative_Models_Based_on_Feature_Regression_for_Pose_Estimation_of_Object_Categories.html">82 cvpr-2013-Class Generative Models Based on Feature Regression for Pose Estimation of Object Categories</a></p>
<p>17 0.067552283 <a title="426-tfidf-17" href="./cvpr-2013-Computationally_Efficient_Regression_on_a_Dependency_Graph_for_Human_Pose_Estimation.html">89 cvpr-2013-Computationally Efficient Regression on a Dependency Graph for Human Pose Estimation</a></p>
<p>18 0.066074073 <a title="426-tfidf-18" href="./cvpr-2013-Non-rigid_Structure_from_Motion_with_Diffusion_Maps_Prior.html">306 cvpr-2013-Non-rigid Structure from Motion with Diffusion Maps Prior</a></p>
<p>19 0.062460948 <a title="426-tfidf-19" href="./cvpr-2013-Beyond_Physical_Connections%3A_Tree_Models_in_Human_Pose_Estimation.html">60 cvpr-2013-Beyond Physical Connections: Tree Models in Human Pose Estimation</a></p>
<p>20 0.060864605 <a title="426-tfidf-20" href="./cvpr-2013-Towards_Pose_Robust_Face_Recognition.html">438 cvpr-2013-Towards Pose Robust Face Recognition</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.122), (1, 0.039), (2, -0.007), (3, -0.041), (4, -0.009), (5, -0.033), (6, 0.028), (7, 0.03), (8, 0.044), (9, -0.091), (10, -0.013), (11, 0.132), (12, -0.116), (13, 0.002), (14, 0.052), (15, -0.032), (16, 0.019), (17, 0.02), (18, -0.043), (19, 0.003), (20, -0.098), (21, -0.001), (22, -0.005), (23, 0.011), (24, -0.104), (25, -0.018), (26, -0.002), (27, -0.031), (28, 0.001), (29, -0.046), (30, 0.058), (31, -0.044), (32, -0.046), (33, -0.036), (34, 0.02), (35, 0.021), (36, -0.067), (37, -0.006), (38, -0.009), (39, 0.037), (40, -0.058), (41, -0.054), (42, 0.046), (43, 0.038), (44, 0.011), (45, -0.02), (46, -0.044), (47, 0.069), (48, -0.039), (49, 0.002)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93373412 <a title="426-lsi-1" href="./cvpr-2013-Tensor-Based_Human_Body_Modeling.html">426 cvpr-2013-Tensor-Based Human Body Modeling</a></p>
<p>Author: Yinpeng Chen, Zicheng Liu, Zhengyou Zhang</p><p>Abstract: In this paper, we present a novel approach to model 3D human body with variations on both human shape and pose, by exploring a tensor decomposition technique. 3D human body modeling is important for 3D reconstruction and animation of realistic human body, which can be widely used in Tele-presence and video game applications. It is challenging due to a wide range of shape variations over different people and poses. The existing SCAPE model [4] is popular in computer vision for modeling 3D human body. However, it considers shape and pose deformations separately, which is not accurate since pose deformation is persondependent. Our tensor-based model addresses this issue by jointly modeling shape and pose deformations. Experimental results demonstrate that our tensor-based model outperforms the SCAPE model quite significantly. We also apply our model to capture human body using Microsoft Kinect sensors with excellent results.</p><p>2 0.644898 <a title="426-lsi-2" href="./cvpr-2013-Poselet_Conditioned_Pictorial_Structures.html">335 cvpr-2013-Poselet Conditioned Pictorial Structures</a></p>
<p>Author: Leonid Pishchulin, Mykhaylo Andriluka, Peter Gehler, Bernt Schiele</p><p>Abstract: In this paper we consider the challenging problem of articulated human pose estimation in still images. We observe that despite high variability of the body articulations, human motions and activities often simultaneously constrain the positions of multiple body parts. Modelling such higher order part dependencies seemingly comes at a cost of more expensive inference, which resulted in their limited use in state-of-the-art methods. In this paper we propose a model that incorporates higher order part dependencies while remaining efficient. We achieve this by defining a conditional model in which all body parts are connected a-priori, but which becomes a tractable tree-structured pictorial structures model once the image observations are available. In order to derive a set of conditioning variables we rely on the poselet-based features that have been shown to be effective for people detection but have so far found limited application for articulated human pose estimation. We demon- strate the effectiveness of our approach on three publicly available pose estimation benchmarks improving or being on-par with state of the art in each case.</p><p>3 0.62214202 <a title="426-lsi-3" href="./cvpr-2013-A_Joint_Model_for_2D_and_3D_Pose_Estimation_from_a_Single_Image.html">14 cvpr-2013-A Joint Model for 2D and 3D Pose Estimation from a Single Image</a></p>
<p>Author: Edgar Simo-Serra, Ariadna Quattoni, Carme Torras, Francesc Moreno-Noguer</p><p>Abstract: We introduce a novel approach to automatically recover 3D human pose from a single image. Most previous work follows a pipelined approach: initially, a set of 2D features such as edges, joints or silhouettes are detected in the image, and then these observations are used to infer the 3D pose. Solving these two problems separately may lead to erroneous 3D poses when the feature detector has performed poorly. In this paper, we address this issue by jointly solving both the 2D detection and the 3D inference problems. For this purpose, we propose a Bayesian framework that integrates a generative model based on latent variables and discriminative 2D part detectors based on HOGs, and perform inference using evolutionary algorithms. Real experimentation demonstrates competitive results, and the ability of our methodology to provide accurate 2D and 3D pose estimations even when the 2D detectors are inaccurate.</p><p>4 0.61509389 <a title="426-lsi-4" href="./cvpr-2013-Human_Pose_Estimation_Using_Body_Parts_Dependent_Joint_Regressors.html">206 cvpr-2013-Human Pose Estimation Using Body Parts Dependent Joint Regressors</a></p>
<p>Author: Matthias Dantone, Juergen Gall, Christian Leistner, Luc Van_Gool</p><p>Abstract: In this work, we address the problem of estimating 2d human pose from still images. Recent methods that rely on discriminatively trained deformable parts organized in a tree model have shown to be very successful in solving this task. Within such a pictorial structure framework, we address the problem of obtaining good part templates by proposing novel, non-linear joint regressors. In particular, we employ two-layered random forests as joint regressors. The first layer acts as a discriminative, independent body part classifier. The second layer takes the estimated class distributions of the first one into account and is thereby able to predict joint locations by modeling the interdependence and co-occurrence of the parts. This results in a pose estimation framework that takes dependencies between body parts already for joint localization into account and is thus able to circumvent typical ambiguities of tree structures, such as for legs and arms. In the experiments, we demonstrate that our body parts dependent joint regressors achieve a higher joint localization accuracy than tree-based state-of-the-art methods.</p><p>5 0.6048165 <a title="426-lsi-5" href="./cvpr-2013-Multi-resolution_Shape_Analysis_via_Non-Euclidean_Wavelets%3A_Applications_to_Mesh_Segmentation_and_Surface_Alignment_Problems.html">297 cvpr-2013-Multi-resolution Shape Analysis via Non-Euclidean Wavelets: Applications to Mesh Segmentation and Surface Alignment Problems</a></p>
<p>Author: Won Hwa Kim, Moo K. Chung, Vikas Singh</p><p>Abstract: The analysis of 3-D shape meshes is a fundamental problem in computer vision, graphics, and medical imaging. Frequently, the needs of the application require that our analysis take a multi-resolution view of the shape ’s local and global topology, and that the solution is consistent across multiple scales. Unfortunately, the preferred mathematical construct which offers this behavior in classical image/signal processing, Wavelets, is no longer applicable in this general setting (data with non-uniform topology). In particular, the traditional definition does not allow writing out an expansion for graphs that do not correspond to the uniformly sampled lattice (e.g., images). In this paper, we adapt recent results in harmonic analysis, to derive NonEuclidean Wavelets based algorithms for a range of shape analysis problems in vision and medical imaging. We show how descriptors derived from the dual domain representation offer native multi-resolution behavior for characterizing local/global topology around vertices. With only minor modifications, the framework yields a method for extracting interest/key points from shapes, a surprisingly simple algorithm for 3-D shape segmentation (competitive with state of the art), and a method for surface alignment (without landmarks). We give an extensive set of comparison results on a large shape segmentation benchmark and derive a uniqueness theorem for the surface alignment problem.</p><p>6 0.59712911 <a title="426-lsi-6" href="./cvpr-2013-3D_Pictorial_Structures_for_Multiple_View_Articulated_Pose_Estimation.html">2 cvpr-2013-3D Pictorial Structures for Multiple View Articulated Pose Estimation</a></p>
<p>7 0.58337468 <a title="426-lsi-7" href="./cvpr-2013-Human_Pose_Estimation_Using_a_Joint_Pixel-wise_and_Part-wise_Formulation.html">207 cvpr-2013-Human Pose Estimation Using a Joint Pixel-wise and Part-wise Formulation</a></p>
<p>8 0.58333784 <a title="426-lsi-8" href="./cvpr-2013-Correspondence-Less_Non-rigid_Registration_of_Triangular_Surface_Meshes.html">97 cvpr-2013-Correspondence-Less Non-rigid Registration of Triangular Surface Meshes</a></p>
<p>9 0.57972658 <a title="426-lsi-9" href="./cvpr-2013-Computationally_Efficient_Regression_on_a_Dependency_Graph_for_Human_Pose_Estimation.html">89 cvpr-2013-Computationally Efficient Regression on a Dependency Graph for Human Pose Estimation</a></p>
<p>10 0.54117388 <a title="426-lsi-10" href="./cvpr-2013-Templateless_Quasi-rigid_Shape_Modeling_with_Implicit_Loop-Closure.html">424 cvpr-2013-Templateless Quasi-rigid Shape Modeling with Implicit Loop-Closure</a></p>
<p>11 0.52966839 <a title="426-lsi-11" href="./cvpr-2013-MODEC%3A_Multimodal_Decomposable_Models_for_Human_Pose_Estimation.html">277 cvpr-2013-MODEC: Multimodal Decomposable Models for Human Pose Estimation</a></p>
<p>12 0.52844322 <a title="426-lsi-12" href="./cvpr-2013-Articulated_Pose_Estimation_Using_Discriminative_Armlet_Classifiers.html">45 cvpr-2013-Articulated Pose Estimation Using Discriminative Armlet Classifiers</a></p>
<p>13 0.52734786 <a title="426-lsi-13" href="./cvpr-2013-Unconstrained_Monocular_3D_Human_Pose_Estimation_by_Action_Detection_and_Cross-Modality_Regression_Forest.html">444 cvpr-2013-Unconstrained Monocular 3D Human Pose Estimation by Action Detection and Cross-Modality Regression Forest</a></p>
<p>14 0.52448392 <a title="426-lsi-14" href="./cvpr-2013-An_Approach_to_Pose-Based_Action_Recognition.html">40 cvpr-2013-An Approach to Pose-Based Action Recognition</a></p>
<p>15 0.52381665 <a title="426-lsi-15" href="./cvpr-2013-Class_Generative_Models_Based_on_Feature_Regression_for_Pose_Estimation_of_Object_Categories.html">82 cvpr-2013-Class Generative Models Based on Feature Regression for Pose Estimation of Object Categories</a></p>
<p>16 0.52248806 <a title="426-lsi-16" href="./cvpr-2013-PDM-ENLOR%3A_Learning_Ensemble_of_Local_PDM-Based_Regressions.html">321 cvpr-2013-PDM-ENLOR: Learning Ensemble of Local PDM-Based Regressions</a></p>
<p>17 0.5155893 <a title="426-lsi-17" href="./cvpr-2013-Beyond_Physical_Connections%3A_Tree_Models_in_Human_Pose_Estimation.html">60 cvpr-2013-Beyond Physical Connections: Tree Models in Human Pose Estimation</a></p>
<p>18 0.51002151 <a title="426-lsi-18" href="./cvpr-2013-Efficient_Computation_of_Shortest_Path-Concavity_for_3D_Meshes.html">141 cvpr-2013-Efficient Computation of Shortest Path-Concavity for 3D Meshes</a></p>
<p>19 0.48836711 <a title="426-lsi-19" href="./cvpr-2013-Pose_from_Flow_and_Flow_from_Pose.html">334 cvpr-2013-Pose from Flow and Flow from Pose</a></p>
<p>20 0.48090333 <a title="426-lsi-20" href="./cvpr-2013-Expressive_Visual_Text-to-Speech_Using_Active_Appearance_Models.html">159 cvpr-2013-Expressive Visual Text-to-Speech Using Active Appearance Models</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.122), (16, 0.025), (26, 0.044), (33, 0.243), (59, 0.017), (67, 0.055), (69, 0.051), (76, 0.237), (80, 0.012), (87, 0.064), (93, 0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.84212512 <a title="426-lda-1" href="./cvpr-2013-Optimal_Geometric_Fitting_under_the_Truncated_L2-Norm.html">317 cvpr-2013-Optimal Geometric Fitting under the Truncated L2-Norm</a></p>
<p>Author: Erik Ask, Olof Enqvist, Fredrik Kahl</p><p>Abstract: This paper is concerned with model fitting in the presence of noise and outliers. Previously it has been shown that the number of outliers can be minimized with polynomial complexity in the number of measurements. This paper improves on these results in two ways. First, it is shown that for a large class of problems, the statistically more desirable truncated L2-norm can be optimized with the same complexity. Then, with the same methodology, it is shown how to transform multi-model fitting into a purely combinatorial problem—with worst-case complexity that is polynomial in the number of measurements, though exponential in the number of models. We apply our framework to a series of hard registration and stitching problems demonstrating that the approach is not only of theoretical interest. It gives a practical method for simultaneously dealing with measurement noise and large amounts of outliers for fitting problems with lowdimensional models.</p><p>same-paper 2 0.83118075 <a title="426-lda-2" href="./cvpr-2013-Tensor-Based_Human_Body_Modeling.html">426 cvpr-2013-Tensor-Based Human Body Modeling</a></p>
<p>Author: Yinpeng Chen, Zicheng Liu, Zhengyou Zhang</p><p>Abstract: In this paper, we present a novel approach to model 3D human body with variations on both human shape and pose, by exploring a tensor decomposition technique. 3D human body modeling is important for 3D reconstruction and animation of realistic human body, which can be widely used in Tele-presence and video game applications. It is challenging due to a wide range of shape variations over different people and poses. The existing SCAPE model [4] is popular in computer vision for modeling 3D human body. However, it considers shape and pose deformations separately, which is not accurate since pose deformation is persondependent. Our tensor-based model addresses this issue by jointly modeling shape and pose deformations. Experimental results demonstrate that our tensor-based model outperforms the SCAPE model quite significantly. We also apply our model to capture human body using Microsoft Kinect sensors with excellent results.</p><p>3 0.82602549 <a title="426-lda-3" href="./cvpr-2013-Procrustean_Normal_Distribution_for_Non-rigid_Structure_from_Motion.html">341 cvpr-2013-Procrustean Normal Distribution for Non-rigid Structure from Motion</a></p>
<p>Author: Minsik Lee, Jungchan Cho, Chong-Ho Choi, Songhwai Oh</p><p>Abstract: Non-rigid structure from motion is a fundamental problem in computer vision, which is yet to be solved satisfactorily. The main difficulty of the problem lies in choosing the right constraints for the solution. In this paper, we propose new constraints that are more effective for non-rigid shape recovery. Unlike the other proposals which have mainly focused on restricting the deformation space using rank constraints, our proposal constrains the motion parameters so that the 3D shapes are most closely aligned to each other, which makes the rank constraints unnecessary. Based on these constraints, we define a new class ofprobability distribution called the Procrustean normal distribution and propose a new NRSfM algorithm, EM-PND. The experimental results show that the proposed method outperforms the existing methods, and it works well even if there is no temporal dependence between the observed samples.</p><p>4 0.82243866 <a title="426-lda-4" href="./cvpr-2013-Topical_Video_Object_Discovery_from_Key_Frames_by_Modeling_Word_Co-occurrence_Prior.html">434 cvpr-2013-Topical Video Object Discovery from Key Frames by Modeling Word Co-occurrence Prior</a></p>
<p>Author: Gangqiang Zhao, Junsong Yuan, Gang Hua</p><p>Abstract: A topical video object refers to an object that is frequently highlighted in a video. It could be, e.g., the product logo and the leading actor/actress in a TV commercial. We propose a topic model that incorporates a word co-occurrence prior for efficient discovery of topical video objects from a set of key frames. Previous work using topic models, such as Latent Dirichelet Allocation (LDA), for video object discovery often takes a bag-of-visual-words representation, which ignored important co-occurrence information among the local features. We show that such data driven co-occurrence information from bottom-up can conveniently be incorporated in LDA with a Gaussian Markov prior, which combines top down probabilistic topic modeling with bottom up priors in a unified model. Our experiments on challenging videos demonstrate that the proposed approach can discover different types of topical objects despite variations in scale, view-point, color and lighting changes, or even partial occlusions. The efficacy of the co-occurrence prior is clearly demonstrated when comparing with topic models without such priors.</p><p>5 0.8152287 <a title="426-lda-5" href="./cvpr-2013-Heterogeneous_Visual_Features_Fusion_via_Sparse_Multimodal_Machine.html">201 cvpr-2013-Heterogeneous Visual Features Fusion via Sparse Multimodal Machine</a></p>
<p>Author: Hua Wang, Feiping Nie, Heng Huang, Chris Ding</p><p>Abstract: To better understand, search, and classify image and video information, many visual feature descriptors have been proposed to describe elementary visual characteristics, such as the shape, the color, the texture, etc. How to integrate these heterogeneous visual features and identify the important ones from them for specific vision tasks has become an increasingly critical problem. In this paper, We propose a novel Sparse Multimodal Learning (SMML) approach to integrate such heterogeneous features by using the joint structured sparsity regularizations to learn the feature importance of for the vision tasks from both group-wise and individual point of views. A new optimization algorithm is also introduced to solve the non-smooth objective with rigorously proved global convergence. We applied our SMML method to five broadly used object categorization and scene understanding image data sets for both singlelabel and multi-label image classification tasks. For each data set we integrate six different types of popularly used image features. Compared to existing scene and object cat- egorization methods using either single modality or multimodalities of features, our approach always achieves better performances measured.</p><p>6 0.80442697 <a title="426-lda-6" href="./cvpr-2013-Pixel-Level_Hand_Detection_in_Ego-centric_Videos.html">332 cvpr-2013-Pixel-Level Hand Detection in Ego-centric Videos</a></p>
<p>7 0.77142143 <a title="426-lda-7" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>8 0.77110726 <a title="426-lda-8" href="./cvpr-2013-Story-Driven_Summarization_for_Egocentric_Video.html">413 cvpr-2013-Story-Driven Summarization for Egocentric Video</a></p>
<p>9 0.76772082 <a title="426-lda-9" href="./cvpr-2013-Structure_Preserving_Object_Tracking.html">414 cvpr-2013-Structure Preserving Object Tracking</a></p>
<p>10 0.76680696 <a title="426-lda-10" href="./cvpr-2013-Integrating_Grammar_and_Segmentation_for_Human_Pose_Estimation.html">225 cvpr-2013-Integrating Grammar and Segmentation for Human Pose Estimation</a></p>
<p>11 0.76643753 <a title="426-lda-11" href="./cvpr-2013-Part_Discovery_from_Partial_Correspondence.html">325 cvpr-2013-Part Discovery from Partial Correspondence</a></p>
<p>12 0.76607352 <a title="426-lda-12" href="./cvpr-2013-Understanding_Indoor_Scenes_Using_3D_Geometric_Phrases.html">446 cvpr-2013-Understanding Indoor Scenes Using 3D Geometric Phrases</a></p>
<p>13 0.76593524 <a title="426-lda-13" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<p>14 0.76575702 <a title="426-lda-14" href="./cvpr-2013-Spatiotemporal_Deformable_Part_Models_for_Action_Detection.html">408 cvpr-2013-Spatiotemporal Deformable Part Models for Action Detection</a></p>
<p>15 0.76562858 <a title="426-lda-15" href="./cvpr-2013-Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking.html">285 cvpr-2013-Minimum Uncertainty Gap for Robust Visual Tracking</a></p>
<p>16 0.76439911 <a title="426-lda-16" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<p>17 0.76394874 <a title="426-lda-17" href="./cvpr-2013-Understanding_Bayesian_Rooms_Using_Composite_3D_Object_Models.html">445 cvpr-2013-Understanding Bayesian Rooms Using Composite 3D Object Models</a></p>
<p>18 0.76338822 <a title="426-lda-18" href="./cvpr-2013-Cross-View_Action_Recognition_via_a_Continuous_Virtual_Path.html">98 cvpr-2013-Cross-View Action Recognition via a Continuous Virtual Path</a></p>
<p>19 0.7632153 <a title="426-lda-19" href="./cvpr-2013-A_Joint_Model_for_2D_and_3D_Pose_Estimation_from_a_Single_Image.html">14 cvpr-2013-A Joint Model for 2D and 3D Pose Estimation from a Single Image</a></p>
<p>20 0.76286787 <a title="426-lda-20" href="./cvpr-2013-Label_Propagation_from_ImageNet_to_3D_Point_Clouds.html">242 cvpr-2013-Label Propagation from ImageNet to 3D Point Clouds</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
