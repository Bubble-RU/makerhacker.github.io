<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>96 cvpr-2013-Correlation Filters for Object Alignment</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-96" href="#">cvpr2013-96</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>96 cvpr-2013-Correlation Filters for Object Alignment</h1>
<br/><p>Source: <a title="cvpr-2013-96-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Boddeti_Correlation_Filters_for_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Vishnu Naresh Boddeti, Takeo Kanade, B.V.K. Vijaya Kumar</p><p>Abstract: Alignment of 3D objects from 2D images is one of the most important and well studied problems in computer vision. A typical object alignment system consists of a landmark appearance model which is used to obtain an initial shape and a shape model which refines this initial shape by correcting the initialization errors. Since errors in landmark initialization from the appearance model propagate through the shape model, it is critical to have a robust landmark appearance model. While there has been much progress in designing sophisticated and robust shape models, there has been relatively less progress in designing robust landmark detection models. In thispaper wepresent an efficient and robust landmark detection model which is designed specifically to minimize localization errors thereby leading to state-of-the-art object alignment performance. We demonstrate the efficacy and speed of the proposed approach on the challenging task of multi-view car alignment.</p><p>Reference: <a title="cvpr-2013-96-reference" href="../cvpr2013_reference/cvpr-2013-Correlation_Filters_for_Object_Alignment_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 A typical object alignment system consists of a landmark appearance model which is used to obtain an initial shape and a shape model which refines this initial shape by correcting the initialization errors. [sent-7, score-0.823]
</p><p>2 Since errors in landmark initialization from the appearance model propagate through the shape model, it is critical to have a robust landmark appearance model. [sent-8, score-0.901]
</p><p>3 While there has been much progress in designing sophisticated and robust shape models, there has been relatively less progress in designing robust landmark detection models. [sent-9, score-0.577]
</p><p>4 In thispaper wepresent an efficient and robust landmark detection model which is designed specifically to minimize localization errors thereby leading to state-of-the-art object alignment performance. [sent-10, score-0.573]
</p><p>5 We demonstrate the efficacy and speed of the proposed approach on the challenging task of multi-view car alignment. [sent-11, score-0.096]
</p><p>6 Introduction  Fitting a shape or a template to a given image is one of the most important and well studied problems in computer vision where the object shape is typically defined by a set of landmarks. [sent-13, score-0.247]
</p><p>7 The ability to accurately align shape models of deformable objects is critical for a variety of applications like object detection and recognition, object tracking, 3D scene modeling etc. [sent-14, score-0.145]
</p><p>8 A typical approach for shape fitting involves a local landmark appearance model which generates a likelihood map for that landmark and a deformable shape model which fits a shape to the landmark likelihood maps. [sent-15, score-1.363]
</p><p>9 There has been much progress in designing parametrized deformable shape models over the past two decades. [sent-16, score-0.204]
</p><p>10 introduced one of the most successful alignment models, Active Shape Models [5], where the object shape, as represented by a set of landmark points, is modeled by a Gaussian point distribution. [sent-18, score-0.45]
</p><p>11 , [23] proposed a Bayesian Tangent Shape Model (BTSM) where both the object pose and the shape . [sent-21, score-0.129]
</p><p>12 Acomparisonbetwe ntwodifer ntap ear ncemod-  els used with the same shape model for the task of car alignment. [sent-26, score-0.199]
</p><p>13 Top Row: car alignment with a random forest based landmark appearance model. [sent-27, score-0.589]
</p><p>14 Bottom Row: car alignment with the proposed landmark detector. [sent-28, score-0.525]
</p><p>15 introduced a robust version of BTSM to handle outliers and gross landmark detection errors. [sent-32, score-0.354]
</p><p>16 Other notable shape matching models include Active Appearance Models [3], Pictorial Structures [10] and Constrained Local Models [6][19]. [sent-33, score-0.123]
</p><p>17 The goal of the appearance model is to provide an initial shape for the alignment algorithm. [sent-34, score-0.303]
</p><p>18 Many different feature representations have been used in the literature for the purpose of landmark detection. [sent-37, score-0.314]
</p><p>19 The choice of the feature representation used to represent the landmarks critically affects the performance of the landmark detector. [sent-39, score-0.6]
</p><p>20 Additionally many discriminative appearance models like Support Vector Machines (SVMs) [24][21], RankBoost [22], FisherBoost [20], Random Forests (RFs) [13][4] have been proposed in the literature to detect landmarks in images. [sent-41, score-0.389]
</p><p>21 , none of them are specifically designed for the task of landmark localization. [sent-44, score-0.368]
</p><p>22 Correlation filters (CFs) are another class of template based linear classifiers which are designed to minimize localization errors in addition to discriminating between the target object and the background and as such are well suited to the task of landmark detection. [sent-45, score-0.52]
</p><p>23 While many different correlation filter designs exist [14][2] they have been traditionally designed to be used with scalar feature representations only. [sent-46, score-0.214]
</p><p>24 In this paper, we present a vector feature based extension to the scalar feature based unconstrained correlation filters [15][1]. [sent-47, score-0.193]
</p><p>25 The proposed vector correlation filter (VCF) with HOG features can accommodate significant within-class variations while being discriminative against background clutter. [sent-48, score-0.152]
</p><p>26 We demonstrate that VCFs are fast and accurate landmark detectors and can provide robust object alignment when used in conjunction with point based shape models (see Fig. [sent-49, score-0.622]
</p><p>27 1 for a comparison between a VCF and RF based landmark detector for the same shape model). [sent-50, score-0.437]
</p><p>28 We also show that VCFs outperform other popular landmark detectors based on SVMs and RFs leading to state  of the art object alignment accuracy. [sent-51, score-0.45]
</p><p>29 Proposed Approach Traditionally the focus of most research on object alignment models has been on improving the shape models. [sent-53, score-0.259]
</p><p>30 Many shape models have been proposed to account for and be robust to ever larger errors made by the appearance models. [sent-54, score-0.229]
</p><p>31 However, large gains in object alignment performance can also be had from designing more robust appearance models which also results in the shape models having to contend with lower noise levels, thereby improving their performance. [sent-55, score-0.402]
</p><p>32 We now describe the proposed landmark appearance model and the shape model that we use for the task of object alignment. [sent-56, score-0.502]
</p><p>33 Appearance Model The primary task of the appearance model is to serve as an initialization for the landmark search and as such requires very good localization performance. [sent-59, score-0.447]
</p><p>34 Although RFs and SVMs are widely used to design discriminative appearance models, they are not explicitly designed for localization and hence are unable to provide high localization accuracy. [sent-60, score-0.232]
</p><p>35 Correlation filters (CFs) are another class of classifiers which are generally designed for high localization performance and are hence better suited to the task of landmark detection. [sent-61, score-0.458]
</p><p>36 1  Correlation Filters  A CF is a spatial-frequency array (equivalently, a template in the image domain) that is specifically designed from a set of training patterns that are representative of a particular pattern class. [sent-65, score-0.109]
</p><p>37 , 2D FT of the template) and C(u, v) is the 2D FT of the correlation output c(x, y) with superscript ∗ denoting the complex conjugate. [sent-71, score-0.128]
</p><p>38 The CFs are usually designed to give a sharp peak at the center of the correlation output plane c(x, y) for a centered authentic query pattern and no such peak for an impostor. [sent-74, score-0.295]
</p><p>39 By explicitly controlling the shape of the entire  correlation output, unlike traditional classifiers which only control the output value at the target location, CFs achieve more accurate target localization. [sent-76, score-0.231]
</p><p>40 2  Vector Correlation Filter  Traditional correlation filters have been often designed using scalar features (most commonly pixel values) and cannot be directly used with vector features like HOG. [sent-83, score-0.202]
</p><p>41 We propose an extension ofthe unconstrained correlation filters described in Eq. [sent-84, score-0.168]
</p><p>42 The VCF, consists of one correlation filter per feature channel which are all jointly optimized to minimize the localization loss defined as the l2norm of the difference between the correlation output and the desired ideal correlation output. [sent-86, score-0.464]
</p><p>43 During test time the filter is applied by convolving each feature channel filter with its corresponding feature channel and finally summing up all the feature channel outputs. [sent-142, score-0.146]
</p><p>44 Shape Model Most approaches model the statistical distribution of the shape parameters so that the observed shape from local landmark detectors can be regularized by a prior model during image fitting. [sent-146, score-0.52]
</p><p>45 The proposed appearance model can be used in conjunction with any of these shape models. [sent-147, score-0.195]
</p><p>46 For our purposes we use the robust shape model introduced in [13] by Li et. [sent-148, score-0.124]
</p><p>47 due to its ability to handle gross landmark detection errors caused either by partial occlusions or clutter in the background. [sent-150, score-0.411]
</p><p>48 This model works on the premise that while the object shape is described by multiple landmark points, the actual shape lies in a low-dimensional subspace. [sent-151, score-0.52]
</p><p>49 Therefore, a small minimal subset of uncorrupted landmarks are sufficient to estimate and hallucinate the full shape (via a Bayesian Partial Shape Inference (BPSI) algorithm, see [13] for details). [sent-152, score-0.389]
</p><p>50 They adopt a hypothesis and test approach by performing a combinatorial search over 222222999311  µ  the space of possibly occluded landmarks. [sent-153, score-0.154]
</p><p>51 This explicit search results in a very robust shape alignment model which performs well under all conditions. [sent-154, score-0.26]
</p><p>52 The original algorithm however ignores the landmark confidence from the appearance model and generates many random partial shapes via Random Sample Consensus (RANSAC) [11] resulting in the evaluation of a very large number of hypotheses for a given probability of sampling a “good” subset. [sent-155, score-0.448]
</p><p>53 However, by generating the subsets to include landmarks with high confidence, fewer hypotheses can be evaluated to find a “good” subset with high probability. [sent-156, score-0.33]
</p><p>54 subsets of size k out of the top n confident landmarks i? [sent-161, score-0.31]
</p><p>55 The final object shape is determined by evaluating these hypotheses and choosing the hypothesis with the minimum error between hallucinated shape and the observed shape. [sent-166, score-0.274]
</p><p>56 Experiments To evaluate the efficacy of the proposed approach, we consider the task of multi-view car alignment from a single image. [sent-174, score-0.232]
</p><p>57 This is a challenging task since most car parts are only weakly discriminative for detection and the appearance of the cars can change dramatically as the viewing angle changes. [sent-175, score-0.224]
</p><p>58 Further cars in natural street scenes vary widely in shape and are often present in highly cluttered backgrounds, with severe occlusion, self or otherwise, in many instances. [sent-176, score-0.17]
</p><p>59 Database We evaluate the proposed approach on cars from the MIT Street Dataset [16] which contains over 3500 street scene images created for the task of object recognition and scene understanding. [sent-179, score-0.088]
</p><p>60 This dataset has annotated landmarks (available at www . [sent-180, score-0.286]
</p><p>61 aT shize car shape 1is3 represented by 8d, P1r4o,c 1ru0,s 1e4s aAnnda l8landmarks (see Fig. [sent-186, score-0.178]
</p><p>62 Patches from occluded landmarks are excluded while training the appearance model and for evaluation the occluded landmark is placed at the most likely location in the image. [sent-191, score-0.924]
</p><p>63 To design the VCF, we set the desired correlation output g for the positive samples to a positively scaled Gaussian at the patch center and to a negatively scaled ? [sent-198, score-0.173]
</p><p>64 Evaluation Quantitatively we evaluate the performance of each car alignment algorithm by computing the root mean square error (RMSE) of the detected landmarks with respect to manually labeled ground truth landmark locations. [sent-211, score-0.811]
</p><p>65 7 shows qualitative alignment results on some challenging images. [sent-214, score-0.136]
</p><p>66 Ground truth landmarks with labeled landmark indices for different viewpoints. [sent-216, score-0.6]
</p><p>67 RMSE for each pose averaged over 1) all images, 2) images with no occlusions, 3) unoccluded landmarks of partially occluded  images, 4) occluded landmarks of partially occluded images. [sent-222, score-1.157]
</p><p>68 We compare between three different appearance models, Vector Correlation  Filter, Random Forests and Linear SVM, all with the RANSAC BPSI shape model. [sent-223, score-0.167]
</p><p>69 1  Comparing Appearance Models  We compare three different discriminative appearance models for detecting landmarks namely, RFs, Linear SVMs and the proposed landmark detector, VCF. [sent-226, score-0.703]
</p><p>70 4 shows the landmark wise average error for three different poses. [sent-228, score-0.314]
</p><p>71 Our alignment results with the VCF are a significant improvement over the previous state-of-the-art results [13] (RFs based appearance model that we compare against) on this dataset. [sent-229, score-0.2]
</p><p>72 We observe that the VCF consistently results in lower RMSE over the other appearance models especially over the unoccluded landmarks where the appearance model directly influences the final result. [sent-230, score-0.551]
</p><p>73 5 with the x-axis representing the alignment difficulty for each detector. [sent-233, score-0.136]
</p><p>74 Comparison of the sorted RMSE for each pose for different appearance models along with example alignment results with the VCF appearance model corresponding to small, medium and large landmark RMSE. [sent-236, score-0.661]
</p><p>75 RMSE over all the landmarks in the image) for 649 images in comparison to RF and 804 images in comparison to SVM out of 1000 images in view 2. [sent-237, score-0.319]
</p><p>76 2  Comparing Shape Models  Here we compare different shape models for detecting landmarks namely, RANSAC BPSI and its modification Greedy  BPSI. [sent-240, score-0.409]
</p><p>77 We omit a comparison to other shape models like ASM and BTSM due to space constraints and we observe that RANSAC BPSI outperforms both ASM and BTSM which is consistent with the observations made in [13]. [sent-241, score-0.123]
</p><p>78 Further to evaluate the robustness of RANSAC BPSI and Greedy BPSI to occlusions, we evaluate BPSI assuming that the landmark occlusion masks are known. [sent-242, score-0.314]
</p><p>79 This is evident from the RMSE of the unoccluded landmarks and the unoccluded landmarks on partially occluded cars (compare “Oracle BPSI” and “RANSAC BPSI” or “Greedy BPSI”), 3) Greedy BPSI outperforms RANSAC BPSI on the occluded landmarks of partially occluded vehicles. [sent-247, score-1.561]
</p><p>80 This is because Greedy BPSI is more likely to omit the occluded landmarks for estimating the shape due to lower confidence from the appearance model while RANSAC BPSI, which selects the landmarks randomly, is more likely to include occluded landmarks in the hypothesized subset. [sent-248, score-1.304]
</p><p>81 Moreover, RANSAC BPSI and Greedy BPSI perform equally well on images with unoccluded landmarks. [sent-249, score-0.099]
</p><p>82 Comparing the performance of  RANSAC BPSI and Greedy BPSI on a per image basis for 1000 images in view 2, Greedy BPSI results in lower RMSE (cumulative RMSE over all the landmarks in the image) for 520 images (i. [sent-250, score-0.319]
</p><p>83 , lower RMSE on 60 images) in comparison to Oracle BPSI, 4) finally, analysis of the alignment results reveals that the model performs well on sedan like vehicle and most of the errors are on vehicles like jeeps, trucks and vans due to an overwhelming majority of cars in the dataset being sedans. [sent-254, score-0.3]
</p><p>84 Due to the considerable difference in the shape of these vehicles a mixture model with different shape models for different car types (e. [sent-255, score-0.329]
</p><p>85 Execution Time (in ms) Per Image on Single Core  Po432se34 R0 0F0 0 0 VC12F205/0S0 0VMRANS67 A0 0 0C0BPSIGre d79 y0 0BPSI Table 1 shows the timing results for the appearance and shape model individually for a C++ based implementation on a 2. [sent-261, score-0.167]
</p><p>86 Assuming that the VCFs are stored in the frequency domain, given a new image, the computational complexity for a MxN image with K channels, L landmarks and C templates per landmark is given by, T = K∗TFFT+L∗C∗TFFT+O(K∗L∗C∗MN)  gwivheerneb TyF, TFT = =K ∗OT(MN+ ∗L ∗loCg∗2MTN). [sent-263, score-0.626]
</p><p>87 + By making use Nof) the fact that images are N re ∗al l oangd that the output of the appearance model is real, one can decrease memory usage and computations by a factor of 2. [sent-264, score-0.09]
</p><p>88 99), resulting in a 8x speedup of the shape model without any loss in alignment accuracy. [sent-266, score-0.239]
</p><p>89 RMSE for each pose averaged  over  1) all images, 2) images with no occlusions, 3) unoccluded landmarks of partially occluded  images, 4) occluded landmarks of partially occluded images. [sent-276, score-1.157]
</p><p>90 We with occlusion oracle and Greedy  BPSI,  all with the VCF  compare  appearance  between three different shape models, RANSAC BPSI, BPSI  model. [sent-277, score-0.219]
</p><p>91 Conclusion  High accuracy object shape alignment, requires a high accuracy landmark detector as well as a robust shape model. [sent-280, score-0.561]
</p><p>92 While much work has been done on designing robust shape models, there has been lesser progress on designing robust landmark detection models. [sent-281, score-0.556]
</p><p>93 In this paper we proposed a robust and fast landmark detector which is specifically designed to minimize localization errors. [sent-282, score-0.436]
</p><p>94 On the challenging task of multi-view car alignment we observed a significant improvement in the alignment accuracy. [sent-283, score-0.368]
</p><p>95 Robust and accurate shape model fitting using random forest regression voting. [sent-318, score-0.129]
</p><p>96 Enforcing convexity for improved alignment with constrained local models. [sent-434, score-0.136]
</p><p>97 Ranking prior likelihood distributions for bayesian shape localization framework. [sent-442, score-0.174]
</p><p>98 Bayesian tangent shape  model: Estimating shape and pose parameters via bayesian inference. [sent-449, score-0.255]
</p><p>99 Face detection, pose estimation, and landmark localization in the wild. [sent-456, score-0.388]
</p><p>100 Fast facial feature extraction using a deformable shape model with haar-wavelet based local texture attributes. [sent-461, score-0.125]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('bpsi', 0.647), ('vcf', 0.333), ('landmark', 0.314), ('landmarks', 0.286), ('rmse', 0.203), ('alignment', 0.136), ('occluded', 0.13), ('ransac', 0.128), ('shape', 0.103), ('correlation', 0.102), ('rfs', 0.1), ('unoccluded', 0.099), ('cfs', 0.092), ('car', 0.075), ('btsm', 0.074), ('vcfs', 0.074), ('greedy', 0.067), ('appearance', 0.064), ('cf', 0.056), ('vijaya', 0.055), ('oracle', 0.052), ('localization', 0.048), ('cars', 0.045), ('filters', 0.042), ('template', 0.041), ('cootes', 0.04), ('rf', 0.039), ('designing', 0.038), ('svms', 0.037), ('sorted', 0.037), ('yp', 0.037), ('authentic', 0.037), ('jeeps', 0.037), ('tfft', 0.037), ('vans', 0.037), ('channels', 0.035), ('partially', 0.035), ('pattern', 0.035), ('cmu', 0.034), ('designed', 0.033), ('bolme', 0.033), ('draper', 0.033), ('trucks', 0.033), ('view', 0.033), ('filter', 0.031), ('fourier', 0.031), ('partial', 0.031), ('carnegie', 0.031), ('peak', 0.031), ('hog', 0.031), ('mellon', 0.03), ('kx', 0.03), ('vehicles', 0.028), ('conjunction', 0.028), ('int', 0.028), ('channel', 0.028), ('pose', 0.026), ('pages', 0.026), ('fitting', 0.026), ('frequency', 0.026), ('output', 0.026), ('occlusions', 0.026), ('desired', 0.025), ('scalar', 0.025), ('kumar', 0.025), ('pictorial', 0.024), ('hallucinated', 0.024), ('lucey', 0.024), ('unconstrained', 0.024), ('subsets', 0.024), ('wavelets', 0.024), ('hypothesis', 0.024), ('asm', 0.023), ('designs', 0.023), ('bayesian', 0.023), ('street', 0.022), ('deformable', 0.022), ('expression', 0.022), ('robust', 0.021), ('errors', 0.021), ('task', 0.021), ('mahalanobis', 0.021), ('progress', 0.021), ('gi', 0.021), ('ix', 0.02), ('detector', 0.02), ('models', 0.02), ('hypotheses', 0.02), ('optics', 0.02), ('inverted', 0.02), ('design', 0.02), ('mp', 0.02), ('diagonal', 0.019), ('confidence', 0.019), ('gross', 0.019), ('discriminative', 0.019), ('ieee', 0.019), ('fk', 0.018), ('closed', 0.018), ('influences', 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000006 <a title="96-tfidf-1" href="./cvpr-2013-Correlation_Filters_for_Object_Alignment.html">96 cvpr-2013-Correlation Filters for Object Alignment</a></p>
<p>Author: Vishnu Naresh Boddeti, Takeo Kanade, B.V.K. Vijaya Kumar</p><p>Abstract: Alignment of 3D objects from 2D images is one of the most important and well studied problems in computer vision. A typical object alignment system consists of a landmark appearance model which is used to obtain an initial shape and a shape model which refines this initial shape by correcting the initialization errors. Since errors in landmark initialization from the appearance model propagate through the shape model, it is critical to have a robust landmark appearance model. While there has been much progress in designing sophisticated and robust shape models, there has been relatively less progress in designing robust landmark detection models. In thispaper wepresent an efficient and robust landmark detection model which is designed specifically to minimize localization errors thereby leading to state-of-the-art object alignment performance. We demonstrate the efficacy and speed of the proposed approach on the challenging task of multi-view car alignment.</p><p>2 0.15788299 <a title="96-tfidf-2" href="./cvpr-2013-Part_Discovery_from_Partial_Correspondence.html">325 cvpr-2013-Part Discovery from Partial Correspondence</a></p>
<p>Author: Subhransu Maji, Gregory Shakhnarovich</p><p>Abstract: We study the problem of part discovery when partial correspondence between instances of a category are available. For visual categories that exhibit high diversity in structure such as buildings, our approach can be used to discover parts that are hard to name, but can be easily expressed as a correspondence between pairs of images. Parts naturally emerge from point-wise landmark matches across many instances within a category. We propose a learning framework for automatic discovery of parts in such weakly supervised settings, and show the utility of the rich part library learned in this way for three tasks: object detection, category-specific saliency estimation, and fine-grained image parsing.</p><p>3 0.14871472 <a title="96-tfidf-3" href="./cvpr-2013-Blessing_of_Dimensionality%3A_High-Dimensional_Feature_and_Its_Efficient_Compression_for_Face_Verification.html">64 cvpr-2013-Blessing of Dimensionality: High-Dimensional Feature and Its Efficient Compression for Face Verification</a></p>
<p>Author: Dong Chen, Xudong Cao, Fang Wen, Jian Sun</p><p>Abstract: Making a high-dimensional (e.g., 100K-dim) feature for face recognition seems not a good idea because it will bring difficulties on consequent training, computation, and storage. This prevents further exploration of the use of a highdimensional feature. In this paper, we study the performance of a highdimensional feature. We first empirically show that high dimensionality is critical to high performance. A 100K-dim feature, based on a single-type Local Binary Pattern (LBP) descriptor, can achieve significant improvements over both its low-dimensional version and the state-of-the-art. We also make the high-dimensional feature practical. With our proposed sparse projection method, named rotated sparse regression, both computation and model storage can be reduced by over 100 times without sacrificing accuracy quality.</p><p>4 0.13607982 <a title="96-tfidf-4" href="./cvpr-2013-Leveraging_Structure_from_Motion_to_Learn_Discriminative_Codebooks_for_Scalable_Landmark_Classification.html">268 cvpr-2013-Leveraging Structure from Motion to Learn Discriminative Codebooks for Scalable Landmark Classification</a></p>
<p>Author: Alessandro Bergamo, Sudipta N. Sinha, Lorenzo Torresani</p><p>Abstract: In this paper we propose a new technique for learning a discriminative codebook for local feature descriptors, specifically designed for scalable landmark classification. The key contribution lies in exploiting the knowledge of correspondences within sets offeature descriptors during codebook learning. Feature correspondences are obtained using structure from motion (SfM) computation on Internet photo collections which serve as the training data. Our codebook is defined by a random forest that is trained to map corresponding feature descriptors into identical codes. Unlike prior forest-based codebook learning methods, we utilize fine-grained descriptor labels and address the challenge of training a forest with an extremely large number of labels. Our codebook is used with various existing feature encoding schemes and also a variant we propose for importanceweighted aggregation of local features. We evaluate our approach on a public dataset of 25 landmarks and our new dataset of 620 landmarks (614K images). Our approach significantly outperforms the state of the art in landmark classification. Furthermore, our method is memory efficient and scalable.</p><p>5 0.1224435 <a title="96-tfidf-5" href="./cvpr-2013-Detecting_and_Aligning_Faces_by_Image_Retrieval.html">119 cvpr-2013-Detecting and Aligning Faces by Image Retrieval</a></p>
<p>Author: Xiaohui Shen, Zhe Lin, Jonathan Brandt, Ying Wu</p><p>Abstract: Detecting faces in uncontrolled environments continues to be a challenge to traditional face detection methods[24] due to the large variation in facial appearances, as well as occlusion and clutter. In order to overcome these challenges, we present a novel and robust exemplarbased face detector that integrates image retrieval and discriminative learning. A large database of faces with bounding rectangles and facial landmark locations is collected, and simple discriminative classifiers are learned from each of them. A voting-based method is then proposed to let these classifiers cast votes on the test image through an efficient image retrieval technique. As a result, faces can be very efficiently detected by selecting the modes from the voting maps, without resorting to exhaustive sliding window-style scanning. Moreover, due to the exemplar-based framework, our approach can detect faces under challenging conditions without explicitly modeling their variations. Evaluation on two public benchmark datasets shows that our new face detection approach is accurate and efficient, and achieves the state-of-the-art performance. We further propose to use image retrieval for face validation (in order to remove false positives) and for face alignment/landmark localization. The same methodology can also be easily generalized to other facerelated tasks, such as attribute recognition, as well as general object detection.</p><p>6 0.096972041 <a title="96-tfidf-6" href="./cvpr-2013-Supervised_Descent_Method_and_Its_Applications_to_Face_Alignment.html">420 cvpr-2013-Supervised Descent Method and Its Applications to Face Alignment</a></p>
<p>7 0.081849359 <a title="96-tfidf-7" href="./cvpr-2013-Robust_Discriminative_Response_Map_Fitting_with_Constrained_Local_Models.html">359 cvpr-2013-Robust Discriminative Response Map Fitting with Constrained Local Models</a></p>
<p>8 0.076046325 <a title="96-tfidf-8" href="./cvpr-2013-Vantage_Feature_Frames_for_Fine-Grained_Categorization.html">452 cvpr-2013-Vantage Feature Frames for Fine-Grained Categorization</a></p>
<p>9 0.073027812 <a title="96-tfidf-9" href="./cvpr-2013-Exemplar-Based_Face_Parsing.html">152 cvpr-2013-Exemplar-Based Face Parsing</a></p>
<p>10 0.073025584 <a title="96-tfidf-10" href="./cvpr-2013-Towards_Pose_Robust_Face_Recognition.html">438 cvpr-2013-Towards Pose Robust Face Recognition</a></p>
<p>11 0.072085537 <a title="96-tfidf-11" href="./cvpr-2013-Structured_Face_Hallucination.html">415 cvpr-2013-Structured Face Hallucination</a></p>
<p>12 0.068419345 <a title="96-tfidf-12" href="./cvpr-2013-Explicit_Occlusion_Modeling_for_3D_Object_Class_Representations.html">154 cvpr-2013-Explicit Occlusion Modeling for 3D Object Class Representations</a></p>
<p>13 0.068280622 <a title="96-tfidf-13" href="./cvpr-2013-Blind_Deconvolution_of_Widefield_Fluorescence_Microscopic_Data_by_Regularization_of_the_Optical_Transfer_Function_%28OTF%29.html">65 cvpr-2013-Blind Deconvolution of Widefield Fluorescence Microscopic Data by Regularization of the Optical Transfer Function (OTF)</a></p>
<p>14 0.067128874 <a title="96-tfidf-14" href="./cvpr-2013-Active_Contours_with_Group_Similarity.html">33 cvpr-2013-Active Contours with Group Similarity</a></p>
<p>15 0.066343948 <a title="96-tfidf-15" href="./cvpr-2013-Video_Editing_with_Temporal%2C_Spatial_and_Appearance_Consistency.html">453 cvpr-2013-Video Editing with Temporal, Spatial and Appearance Consistency</a></p>
<p>16 0.066200808 <a title="96-tfidf-16" href="./cvpr-2013-PDM-ENLOR%3A_Learning_Ensemble_of_Local_PDM-Based_Regressions.html">321 cvpr-2013-PDM-ENLOR: Learning Ensemble of Local PDM-Based Regressions</a></p>
<p>17 0.065450422 <a title="96-tfidf-17" href="./cvpr-2013-Single-Sample_Face_Recognition_with_Image_Corruption_and_Misalignment_via_Sparse_Illumination_Transfer.html">399 cvpr-2013-Single-Sample Face Recognition with Image Corruption and Misalignment via Sparse Illumination Transfer</a></p>
<p>18 0.065298349 <a title="96-tfidf-18" href="./cvpr-2013-Occlusion_Patterns_for_Object_Class_Detection.html">311 cvpr-2013-Occlusion Patterns for Object Class Detection</a></p>
<p>19 0.063591629 <a title="96-tfidf-19" href="./cvpr-2013-Efficient_2D-to-3D_Correspondence_Filtering_for_Scalable_3D_Object_Recognition.html">138 cvpr-2013-Efficient 2D-to-3D Correspondence Filtering for Scalable 3D Object Recognition</a></p>
<p>20 0.063328877 <a title="96-tfidf-20" href="./cvpr-2013-Fully-Connected_CRFs_with_Non-Parametric_Pairwise_Potential.html">180 cvpr-2013-Fully-Connected CRFs with Non-Parametric Pairwise Potential</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.141), (1, -0.001), (2, -0.012), (3, 0.002), (4, 0.048), (5, -0.006), (6, 0.008), (7, -0.027), (8, 0.082), (9, -0.086), (10, -0.022), (11, 0.016), (12, 0.027), (13, 0.009), (14, 0.017), (15, -0.066), (16, 0.02), (17, -0.02), (18, 0.031), (19, 0.017), (20, 0.016), (21, -0.0), (22, 0.021), (23, -0.008), (24, 0.022), (25, 0.057), (26, 0.011), (27, -0.029), (28, 0.044), (29, 0.018), (30, 0.002), (31, -0.023), (32, -0.05), (33, -0.062), (34, -0.026), (35, 0.039), (36, -0.034), (37, -0.113), (38, -0.006), (39, 0.085), (40, -0.026), (41, 0.03), (42, -0.029), (43, -0.07), (44, -0.014), (45, 0.035), (46, -0.033), (47, -0.036), (48, -0.087), (49, 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.89855927 <a title="96-lsi-1" href="./cvpr-2013-Correlation_Filters_for_Object_Alignment.html">96 cvpr-2013-Correlation Filters for Object Alignment</a></p>
<p>Author: Vishnu Naresh Boddeti, Takeo Kanade, B.V.K. Vijaya Kumar</p><p>Abstract: Alignment of 3D objects from 2D images is one of the most important and well studied problems in computer vision. A typical object alignment system consists of a landmark appearance model which is used to obtain an initial shape and a shape model which refines this initial shape by correcting the initialization errors. Since errors in landmark initialization from the appearance model propagate through the shape model, it is critical to have a robust landmark appearance model. While there has been much progress in designing sophisticated and robust shape models, there has been relatively less progress in designing robust landmark detection models. In thispaper wepresent an efficient and robust landmark detection model which is designed specifically to minimize localization errors thereby leading to state-of-the-art object alignment performance. We demonstrate the efficacy and speed of the proposed approach on the challenging task of multi-view car alignment.</p><p>2 0.66764909 <a title="96-lsi-2" href="./cvpr-2013-Supervised_Descent_Method_and_Its_Applications_to_Face_Alignment.html">420 cvpr-2013-Supervised Descent Method and Its Applications to Face Alignment</a></p>
<p>Author: Xuehan Xiong, Fernando De_la_Torre</p><p>Abstract: Many computer vision problems (e.g., camera calibration, image alignment, structure from motion) are solved through a nonlinear optimization method. It is generally accepted that 2nd order descent methods are the most robust, fast and reliable approaches for nonlinear optimization ofa general smoothfunction. However, in the context of computer vision, 2nd order descent methods have two main drawbacks: (1) The function might not be analytically differentiable and numerical approximations are impractical. (2) The Hessian might be large and not positive definite. To address these issues, thispaperproposes a Supervised Descent Method (SDM) for minimizing a Non-linear Least Squares (NLS) function. During training, the SDM learns a sequence of descent directions that minimizes the mean of NLS functions sampled at different points. In testing, SDM minimizes the NLS objective using the learned descent directions without computing the Jacobian nor the Hessian. We illustrate the benefits of our approach in synthetic and real examples, and show how SDM achieves state-ofthe-art performance in the problem of facial feature detec- tion. The code is available at www. .human sen sin g. . cs . cmu . edu/in t ra fa ce.</p><p>3 0.65398514 <a title="96-lsi-3" href="./cvpr-2013-Robust_Discriminative_Response_Map_Fitting_with_Constrained_Local_Models.html">359 cvpr-2013-Robust Discriminative Response Map Fitting with Constrained Local Models</a></p>
<p>Author: Akshay Asthana, Stefanos Zafeiriou, Shiyang Cheng, Maja Pantic</p><p>Abstract: We present a novel discriminative regression based approach for the Constrained Local Models (CLMs) framework, referred to as the Discriminative Response Map Fitting (DRMF) method, which shows impressive performance in the generic face fitting scenario. The motivation behind this approach is that, unlike the holistic texture based features used in the discriminative AAM approaches, the response map can be represented by a small set of parameters and these parameters can be very efficiently used for reconstructing unseen response maps. Furthermore, we show that by adopting very simple off-the-shelf regression techniques, it is possible to learn robust functions from response maps to the shape parameters updates. The experiments, conducted on Multi-PIE, XM2VTS and LFPW database, show that the proposed DRMF method outperforms stateof-the-art algorithms for the task of generic face fitting. Moreover, the DRMF method is computationally very efficient and is real-time capable. The current MATLAB implementation takes 1second per image. To facilitate future comparisons, we release the MATLAB code1 and the pretrained models for research purposes.</p><p>4 0.63178188 <a title="96-lsi-4" href="./cvpr-2013-Structured_Face_Hallucination.html">415 cvpr-2013-Structured Face Hallucination</a></p>
<p>Author: Chih-Yuan Yang, Sifei Liu, Ming-Hsuan Yang</p><p>Abstract: The goal of face hallucination is to generate highresolution images with fidelity from low-resolution ones. In contrast to existing methods based on patch similarity or holistic constraints in the image space, we propose to exploit local image structures for face hallucination. Each face image is represented in terms of facial components, contours and smooth regions. The image structure is maintained via matching gradients in the reconstructed highresolution output. For facial components, we align input images to generate accurate exemplars and transfer the high-frequency details for preserving structural consistency. For contours, we learn statistical priors to generate salient structures in the high-resolution images. A patch matching method is utilized on the smooth regions where the image gradients are preserved. Experimental results demonstrate that the proposed algorithm generates hallucinated face images with favorable quality and adaptability.</p><p>5 0.60474682 <a title="96-lsi-5" href="./cvpr-2013-Blessing_of_Dimensionality%3A_High-Dimensional_Feature_and_Its_Efficient_Compression_for_Face_Verification.html">64 cvpr-2013-Blessing of Dimensionality: High-Dimensional Feature and Its Efficient Compression for Face Verification</a></p>
<p>Author: Dong Chen, Xudong Cao, Fang Wen, Jian Sun</p><p>Abstract: Making a high-dimensional (e.g., 100K-dim) feature for face recognition seems not a good idea because it will bring difficulties on consequent training, computation, and storage. This prevents further exploration of the use of a highdimensional feature. In this paper, we study the performance of a highdimensional feature. We first empirically show that high dimensionality is critical to high performance. A 100K-dim feature, based on a single-type Local Binary Pattern (LBP) descriptor, can achieve significant improvements over both its low-dimensional version and the state-of-the-art. We also make the high-dimensional feature practical. With our proposed sparse projection method, named rotated sparse regression, both computation and model storage can be reduced by over 100 times without sacrificing accuracy quality.</p><p>6 0.60061246 <a title="96-lsi-6" href="./cvpr-2013-PDM-ENLOR%3A_Learning_Ensemble_of_Local_PDM-Based_Regressions.html">321 cvpr-2013-PDM-ENLOR: Learning Ensemble of Local PDM-Based Regressions</a></p>
<p>7 0.59051603 <a title="96-lsi-7" href="./cvpr-2013-Vantage_Feature_Frames_for_Fine-Grained_Categorization.html">452 cvpr-2013-Vantage Feature Frames for Fine-Grained Categorization</a></p>
<p>8 0.56787097 <a title="96-lsi-8" href="./cvpr-2013-Robust_Canonical_Time_Warping_for_the_Alignment_of_Grossly_Corrupted_Sequences.html">358 cvpr-2013-Robust Canonical Time Warping for the Alignment of Grossly Corrupted Sequences</a></p>
<p>9 0.56060517 <a title="96-lsi-9" href="./cvpr-2013-Dense_Object_Reconstruction_with_Semantic_Priors.html">110 cvpr-2013-Dense Object Reconstruction with Semantic Priors</a></p>
<p>10 0.55452949 <a title="96-lsi-10" href="./cvpr-2013-Exemplar-Based_Face_Parsing.html">152 cvpr-2013-Exemplar-Based Face Parsing</a></p>
<p>11 0.55380136 <a title="96-lsi-11" href="./cvpr-2013-Learning_SURF_Cascade_for_Fast_and_Accurate_Object_Detection.html">254 cvpr-2013-Learning SURF Cascade for Fast and Accurate Object Detection</a></p>
<p>12 0.55195427 <a title="96-lsi-12" href="./cvpr-2013-Single-Sample_Face_Recognition_with_Image_Corruption_and_Misalignment_via_Sparse_Illumination_Transfer.html">399 cvpr-2013-Single-Sample Face Recognition with Image Corruption and Misalignment via Sparse Illumination Transfer</a></p>
<p>13 0.55046719 <a title="96-lsi-13" href="./cvpr-2013-City-Scale_Change_Detection_in_Cadastral_3D_Models_Using_Images.html">81 cvpr-2013-City-Scale Change Detection in Cadastral 3D Models Using Images</a></p>
<p>14 0.54973203 <a title="96-lsi-14" href="./cvpr-2013-Detecting_and_Aligning_Faces_by_Image_Retrieval.html">119 cvpr-2013-Detecting and Aligning Faces by Image Retrieval</a></p>
<p>15 0.5468179 <a title="96-lsi-15" href="./cvpr-2013-Video_Editing_with_Temporal%2C_Spatial_and_Appearance_Consistency.html">453 cvpr-2013-Video Editing with Temporal, Spatial and Appearance Consistency</a></p>
<p>16 0.54528004 <a title="96-lsi-16" href="./cvpr-2013-Fast_Object_Detection_with_Entropy-Driven_Evaluation.html">168 cvpr-2013-Fast Object Detection with Entropy-Driven Evaluation</a></p>
<p>17 0.54439336 <a title="96-lsi-17" href="./cvpr-2013-Expressive_Visual_Text-to-Speech_Using_Active_Appearance_Models.html">159 cvpr-2013-Expressive Visual Text-to-Speech Using Active Appearance Models</a></p>
<p>18 0.53056067 <a title="96-lsi-18" href="./cvpr-2013-Leveraging_Structure_from_Motion_to_Learn_Discriminative_Codebooks_for_Scalable_Landmark_Classification.html">268 cvpr-2013-Leveraging Structure from Motion to Learn Discriminative Codebooks for Scalable Landmark Classification</a></p>
<p>19 0.51869327 <a title="96-lsi-19" href="./cvpr-2013-Towards_Pose_Robust_Face_Recognition.html">438 cvpr-2013-Towards Pose Robust Face Recognition</a></p>
<p>20 0.51659936 <a title="96-lsi-20" href="./cvpr-2013-Part_Discovery_from_Partial_Correspondence.html">325 cvpr-2013-Part Discovery from Partial Correspondence</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.114), (16, 0.041), (21, 0.202), (26, 0.097), (33, 0.238), (67, 0.052), (69, 0.051), (76, 0.014), (87, 0.076)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.89158738 <a title="96-lda-1" href="./cvpr-2013-Video_Enhancement_of_People_Wearing_Polarized_Glasses%3A_Darkening_Reversal_and_Reflection_Reduction.html">454 cvpr-2013-Video Enhancement of People Wearing Polarized Glasses: Darkening Reversal and Reflection Reduction</a></p>
<p>Author: Mao Ye, Cha Zhang, Ruigang Yang</p><p>Abstract: With the wide-spread of consumer 3D-TV technology, stereoscopic videoconferencing systems are emerging. However, the special glasses participants wear to see 3D can create distracting images. This paper presents a computational framework to reduce undesirable artifacts in the eye regions caused by these 3D glasses. More specifically, we add polarized filters to the stereo camera so that partial images of reflection can be captured. A novel Bayesian model is then developed to describe the imaging process of the eye regions including darkening and reflection, and infer the eye regions based on Classification ExpectationMaximization (EM). The recovered eye regions under the glasses are brighter and with little reflections, leading to a more nature videoconferencing experience. Qualitative evaluations and user studies are conducted to demonstrate the substantial improvement our approach can achieve.</p><p>2 0.87424463 <a title="96-lda-2" href="./cvpr-2013-Image_Understanding_from_Experts%27_Eyes_by_Modeling_Perceptual_Skill_of_Diagnostic_Reasoning_Processes.html">214 cvpr-2013-Image Understanding from Experts' Eyes by Modeling Perceptual Skill of Diagnostic Reasoning Processes</a></p>
<p>Author: Rui Li, Pengcheng Shi, Anne R. Haake</p><p>Abstract: Eliciting and representing experts ’ remarkable perceptual capability of locating, identifying and categorizing objects in images specific to their domains of expertise will benefit image understanding in terms of transferring human domain knowledge and perceptual expertise into image-based computational procedures. In this paper, we present a hierarchical probabilistic framework to summarize the stereotypical and idiosyncratic eye movement patterns shared within 11 board-certified dermatologists while they are examining and diagnosing medical images. Each inferred eye movement pattern characterizes the similar temporal and spatial properties of its corresponding seg. edu anne .haake @ rit . edu , ments of the experts ’ eye movement sequences. We further discover a subset of distinctive eye movement patterns which are commonly exhibited across multiple images. Based on the combinations of the exhibitions of these eye movement patterns, we are able to categorize the images from the perspective of experts’ viewing strategies. In each category, images share similar lesion distributions and configurations. The performance of our approach shows that modeling physicians ’ diagnostic viewing behaviors informs about medical images’ understanding to correct diagnosis.</p><p>same-paper 3 0.84596092 <a title="96-lda-3" href="./cvpr-2013-Correlation_Filters_for_Object_Alignment.html">96 cvpr-2013-Correlation Filters for Object Alignment</a></p>
<p>Author: Vishnu Naresh Boddeti, Takeo Kanade, B.V.K. Vijaya Kumar</p><p>Abstract: Alignment of 3D objects from 2D images is one of the most important and well studied problems in computer vision. A typical object alignment system consists of a landmark appearance model which is used to obtain an initial shape and a shape model which refines this initial shape by correcting the initialization errors. Since errors in landmark initialization from the appearance model propagate through the shape model, it is critical to have a robust landmark appearance model. While there has been much progress in designing sophisticated and robust shape models, there has been relatively less progress in designing robust landmark detection models. In thispaper wepresent an efficient and robust landmark detection model which is designed specifically to minimize localization errors thereby leading to state-of-the-art object alignment performance. We demonstrate the efficacy and speed of the proposed approach on the challenging task of multi-view car alignment.</p><p>4 0.83104658 <a title="96-lda-4" href="./cvpr-2013-HDR_Deghosting%3A_How_to_Deal_with_Saturation%3F.html">195 cvpr-2013-HDR Deghosting: How to Deal with Saturation?</a></p>
<p>Author: Jun Hu, Orazio Gallo, Kari Pulli, Xiaobai Sun</p><p>Abstract: We present a novel method for aligning images in an HDR (high-dynamic-range) image stack to produce a new exposure stack where all the images are aligned and appear as if they were taken simultaneously, even in the case of highly dynamic scenes. Our method produces plausible results even where the image used as a reference is either too dark or bright to allow for an accurate registration.</p><p>5 0.82582825 <a title="96-lda-5" href="./cvpr-2013-Weakly_Supervised_Learning_for_Attribute_Localization_in_Outdoor_Scenes.html">461 cvpr-2013-Weakly Supervised Learning for Attribute Localization in Outdoor Scenes</a></p>
<p>Author: Shuo Wang, Jungseock Joo, Yizhou Wang, Song-Chun Zhu</p><p>Abstract: In this paper, we propose a weakly supervised method for simultaneously learning scene parts and attributes from a collection ofimages associated with attributes in text, where the precise localization of the each attribute left unknown. Our method includes three aspects. (i) Compositional scene configuration. We learn the spatial layouts of the scene by Hierarchical Space Tiling (HST) representation, which can generate an excessive number of scene configurations through the hierarchical composition of a relatively small number of parts. (ii) Attribute association. The scene attributes contain nouns and adjectives corresponding to the objects and their appearance descriptions respectively. We assign the nouns to the nodes (parts) in HST using nonmaximum suppression of their correlation, then train an appearance model for each noun+adjective attribute pair. (iii) Joint inference and learning. For an image, we compute the most probable parse tree with the attributes as an instantiation of the HST by dynamic programming. Then update the HST and attribute association based on the in- ferred parse trees. We evaluate the proposed method by (i) showing the improvement of attribute recognition accuracy; and (ii) comparing the average precision of localizing attributes to the scene parts.</p><p>6 0.8148728 <a title="96-lda-6" href="./cvpr-2013-Occlusion_Patterns_for_Object_Class_Detection.html">311 cvpr-2013-Occlusion Patterns for Object Class Detection</a></p>
<p>7 0.81140172 <a title="96-lda-7" href="./cvpr-2013-Tracking_People_and_Their_Objects.html">440 cvpr-2013-Tracking People and Their Objects</a></p>
<p>8 0.80723506 <a title="96-lda-8" href="./cvpr-2013-Exemplar-Based_Face_Parsing.html">152 cvpr-2013-Exemplar-Based Face Parsing</a></p>
<p>9 0.8029899 <a title="96-lda-9" href="./cvpr-2013-Maximum_Cohesive_Grid_of_Superpixels_for_Fast_Object_Localization.html">280 cvpr-2013-Maximum Cohesive Grid of Superpixels for Fast Object Localization</a></p>
<p>10 0.80203104 <a title="96-lda-10" href="./cvpr-2013-Physically_Plausible_3D_Scene_Tracking%3A_The_Single_Actor_Hypothesis.html">331 cvpr-2013-Physically Plausible 3D Scene Tracking: The Single Actor Hypothesis</a></p>
<p>11 0.80196512 <a title="96-lda-11" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<p>12 0.80131692 <a title="96-lda-12" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>13 0.79964948 <a title="96-lda-13" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<p>14 0.79858339 <a title="96-lda-14" href="./cvpr-2013-Multi-task_Sparse_Learning_with_Beta_Process_Prior_for_Action_Recognition.html">302 cvpr-2013-Multi-task Sparse Learning with Beta Process Prior for Action Recognition</a></p>
<p>15 0.79825455 <a title="96-lda-15" href="./cvpr-2013-Optimal_Geometric_Fitting_under_the_Truncated_L2-Norm.html">317 cvpr-2013-Optimal Geometric Fitting under the Truncated L2-Norm</a></p>
<p>16 0.7962302 <a title="96-lda-16" href="./cvpr-2013-Beyond_Point_Clouds%3A_Scene_Understanding_by_Reasoning_Geometry_and_Physics.html">61 cvpr-2013-Beyond Point Clouds: Scene Understanding by Reasoning Geometry and Physics</a></p>
<p>17 0.79614449 <a title="96-lda-17" href="./cvpr-2013-Templateless_Quasi-rigid_Shape_Modeling_with_Implicit_Loop-Closure.html">424 cvpr-2013-Templateless Quasi-rigid Shape Modeling with Implicit Loop-Closure</a></p>
<p>18 0.79590523 <a title="96-lda-18" href="./cvpr-2013-Structure_Preserving_Object_Tracking.html">414 cvpr-2013-Structure Preserving Object Tracking</a></p>
<p>19 0.79574358 <a title="96-lda-19" href="./cvpr-2013-A_Minimum_Error_Vanishing_Point_Detection_Approach_for_Uncalibrated_Monocular_Images_of_Man-Made_Environments.html">19 cvpr-2013-A Minimum Error Vanishing Point Detection Approach for Uncalibrated Monocular Images of Man-Made Environments</a></p>
<p>20 0.7956534 <a title="96-lda-20" href="./cvpr-2013-Part_Discovery_from_Partial_Correspondence.html">325 cvpr-2013-Part Discovery from Partial Correspondence</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
