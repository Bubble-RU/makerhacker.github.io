<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>105 cvpr-2013-Deep Learning Shape Priors for Object Segmentation</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-105" href="#">cvpr2013-105</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>105 cvpr-2013-Deep Learning Shape Priors for Object Segmentation</h1>
<br/><p>Source: <a title="cvpr-2013-105-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Chen_Deep_Learning_Shape_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Fei Chen, Huimin Yu, Roland Hu, Xunxun Zeng</p><p>Abstract: In this paper we introduce a new shape-driven approach for object segmentation. Given a training set of shapes, we first use deep Boltzmann machine to learn the hierarchical architecture of shape priors. This learned hierarchical architecture is then used to model shape variations of global and local structures in an energetic form. Finally, it is applied to data-driven variational methods to perform object extraction of corrupted data based on shape probabilistic representation. Experiments demonstrate that our model can be applied to dataset of arbitrary prior shapes, and can cope with image noise and clutter, as well as partial occlusions.</p><p>Reference: <a title="cvpr-2013-105-reference" href="../cvpr2013_reference/cvpr-2013-Deep_Learning_Shape_Priors_for_Object_Segmentation_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Given a training set of shapes, we first use deep Boltzmann machine to learn the hierarchical architecture of shape priors. [sent-2, score-0.614]
</p><p>2 This learned hierarchical architecture is then used to model shape variations of global and local structures in an energetic form. [sent-3, score-0.453]
</p><p>3 Finally, it is applied to data-driven variational methods to perform object extraction of corrupted data based on shape probabilistic representation. [sent-4, score-0.266]
</p><p>4 Experiments demonstrate that our model can be applied to dataset of arbitrary prior shapes, and can cope with image noise and clutter, as well as partial occlusions. [sent-5, score-0.12]
</p><p>5 Without utilizing any high-level prior information about expected objects, purely low-level information such as intensity, color and texture does not provide the desired segmentations. [sent-8, score-0.071]
</p><p>6 In numerous studies  [1-6], prior knowledge about the shapes of the objects to be segmented can significantly improve the final reliability and accuracy of the segmentation result. [sent-9, score-0.247]
</p><p>7 However, given a training set of arbitrary prior shapes, there remains an open problem of how to define an appropriate prior shape model to guide object segmentation. [sent-10, score-0.416]
</p><p>8 The shape of an object is represented as a set of points. [sent-14, score-0.172]
</p><p>9 The evolutional shape is constrained by the point distribution model which is inferred from a training set of shapes. [sent-16, score-0.361]
</p><p>10 Later, level set based approaches have gained significant attention toward the integration of shape prior into variational segmentation [2-7]. [sent-18, score-0.337]
</p><p>11 Almost all these works optimize a linear combination of a data-driven term and a shape constraint term. [sent-19, score-0.172]
</p><p>12 Data-driven term aims at driving the segmenting curve to the object boundaries, and shape constraint term restricts possible shapes embodied by the contour. [sent-20, score-0.447]
</p><p>13 In level set approaches, shape is represented implicitly by signed distance functions (SDF). [sent-21, score-0.172]
</p><p>14 This shape representation is consistent with the level set framework, and has its advantages since parameterization free and easy handling of topological changes. [sent-22, score-0.172]
</p><p>15 However, SDF for shape representtation are not closed under linear operations, e. [sent-23, score-0.172]
</p><p>16 , the mean shape and linear combinations of training shapes are typically no longer SDF. [sent-25, score-0.4]
</p><p>17 Most existing works only consider  rseimprielsaer nptraitioorn s hoaf spheas eof d ae iknneodw ans ao mbjaepcpt cnlgas ? [sent-26, score-0.242]
</p><p>18 trreehaparts eosanes,s gCantirsoe nmt ooe rfse s areypt apdile. [sent-37, score-0.061]
</p><p>19 trehpart esaessnigtantsio nto oo fe svhearyp e pdixefeiln ? [sent-50, score-0.121]
</p><p>20 rptheropatbr easabesisnli gtatnyt ot hnto aot e tvshheisra ep ip dxixeeefli ni s? [sent-74, score-0.1]
</p><p>21 tehex data-driven function optimized on convex shape spaces of the? [sent-91, score-0.172]
</p><p>22 inrsde p, ar reessshepnaeptc etth iveoe frl eypg, riowobnha bldeiel stischteri cpl taorsertps t oeersf m met hn? [sent-257, score-0.064]
</p><p>23 inrsed p,a r eessshepnaetpc ett hiveoe fr leypg, iwoobhnai ldbeei stichsrtei pl atorsetrsp t reoersfm ethn ? [sent-268, score-0.163]
</p><p>24 e Tckhgerroeu anrde, m reasnpye wctiavyesl yt,o wdehfiilnee thhee lsahsatp tee rcmon ? [sent-276, score-0.056]
</p><p>25 Simple uniform distribution [4], Gaussian densities [2], non-parametric estimator [5, 6], manifold learning [9, 10], and sparse representation [11] were considered to model shape variation within a training set. [sent-278, score-0.224]
</p><p>26 They are suitable for segmenting objects of a known class in the image according to their possible similar shapes. [sent-280, score-0.049]
</p><p>27 If the given training set of shapes is large and associated with multiple different object classes, the statistical shape models and manifold learning do not effectively represent the shape distributions due to large variability of shapes. [sent-281, score-0.572]
</p><p>28 In  addition, global transformations like translation, rotation and scaling and local transformations like bending and stretching are expensive to shape model in image 111888667088  Table 1. [sent-282, score-0.228]
</p><p>29 Recently, deep learning models [12, 13] are attractive for their well performance in modeling high-dimensional richly structured data. [sent-288, score-0.302]
</p><p>30 A deep learning model is about learning multiple levels of representation and abstraction that help to make sense of data such as images, sound, and text. [sent-289, score-0.246]
</p><p>31 The deep Boltzmann machine (DBM) has been an important development in the quest for powerful deep learning models [14, 15]. [sent-290, score-0.553]
</p><p>32 Applications that use deep learning models are numerous in computer vision and information retrieval, including classification [15], dimensionality reduction [12], visual recognition tasks [16], acoustic modeling [17], etc. [sent-291, score-0.299]
</p><p>33 This shape generative  model has the appealing property that it can both generate realistic samples and generalize to generate samples that differ from shapes in the training set. [sent-293, score-0.4]
</p><p>34 Inspired by the above work [18], we focus on image segmentation, and propose a shape prior constraint term by deep learning to guide variational segmentation. [sent-294, score-0.633]
</p><p>35 In this paper, we first use deep Boltzmann machine to extract the hierarchical architecture of shapes in the training set. [sent-295, score-0.618]
</p><p>36 This architecture can effectively capture global and local features of prior shapes. [sent-296, score-0.215]
</p><p>37 It is then introduced into the variational framework as a shape prior term in an energetic form. [sent-297, score-0.474]
</p><p>38 By minimizing the proposed objective functional, the model is able to constrain an evolutional shape to follow global shape consistency while preserving its ability to capture local deformations. [sent-298, score-0.481]
</p><p>39 Learning shape priors via DBM A Restricted Boltzmann Machine (RBM) is a particular type of Markov Random Field (MRF) that has a two-layer architecture, in which the visible units are connected to hidden units. [sent-300, score-0.394]
</p><p>40 A Deep Boltzmann Machine (DBM) is an extension of the RBM that has multiple layers of hidden units arranged in layers [14]. [sent-301, score-0.137]
</p><p>41 In general, the shape prior can be simply described as two levels of representation: low-level local features (like edges or corners) and high-level global features (like object parts or object). [sent-302, score-0.243]
</p><p>42 On the other hand, high-level global features describe the image content, and they are more appropriate to cope with occlusion, noise, and  (a) (b)  Fig. [sent-304, score-0.049]
</p><p>43 (a) The visible-to-hidden weights receive inputs only from a square patch of visible units below. [sent-307, score-0.415]
</p><p>44 (b) A simple case that the training shape is divided into four square patches. [sent-308, score-0.29]
</p><p>45 th hiag" ht ierse rd p pberfei nsnaeernydt hthiedL dsehetna ? [sent-341, score-0.059]
</p><p>46 nt sri is(c a lsinot ekrnaocwtionn a st ebrimasse, s*),? [sent-462, score-0.133]
</p><p>47 aanndd +* i s the visible ssvheeiidsllfifdb--ecclneoo n nvnsneyeecmcctot imiroo e? [sent-463, score-0.085]
</p><p>48 r iT (sc ah lesin opte rkronabcoatwiboinln ai t sye brtihmaastse ts*h),e amannodd? [sent-465, score-0.166]
</p><p>49 7", the leaGrnivinegn ao sf e D ofB Mali ncoends tirsatisn nogf hdeapteersm ! [sent-588, score-0.136]
</p><p>50 r7e"l,a ttehde weGigivhtesn aan dse t tohef abli agsneesd itrna i(n2i)n. [sent-593, score-0.122]
</p><p>51 xim", uthme likelihood estimation of these parameters in this model is intractable, efficient approximate learning of DBMs can be carried out by using mean-field inference together with Markov Chain Monte Carlo algorithms [14]. [sent-601, score-0.05]
</p><p>52 Since the shapes often have similar local structural properties, the visible units can be divided into e)qual sized square patches to improve the learning p)ro? [sent-603, score-0.464]
</p><p>53 are restricted so that they receive inputs only from a )squ? [sent-607, score-0.127]
</p><p>54 In order to demonstrate )the advantages of three-layered DBM, we consider a simple case that the training shape is divided into four square patches for the arm posture experiment (Fig. [sent-609, score-0.29]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('deep', 0.246), ('dbm', 0.224), ('boltzmann', 0.217), ('oaenrr', 0.205), ('shapes', 0.176), ('shape', 0.172), ('tve', 0.168), ('architecture', 0.144), ('units', 0.137), ('asphpapineg', 0.137), ('dleh', 0.137), ('energetic', 0.137), ('evolutional', 0.137), ('svtiastieb', 0.137), ('sdf', 0.106), ('ah', 0.105), ('ett', 0.101), ('bw', 0.101), ('ae', 0.098), ('variational', 0.094), ('rbm', 0.09), ('visible', 0.085), ('ao', 0.083), ('nt', 0.083), ('nv', 0.078), ('receive', 0.078), ('sa', 0.074), ('tah', 0.074), ('oo', 0.071), ('prior', 0.071), ('mc', 0.069), ('square', 0.066), ('ar', 0.064), ('pl', 0.062), ('dbms', 0.061), ('tohef', 0.061), ('shh', 0.061), ('itrna', 0.061), ('arr', 0.061), ('eag', 0.061), ('edl', 0.061), ('eyt', 0.061), ('hoaf', 0.061), ('nmt', 0.061), ('oafs', 0.061), ('ofb', 0.061), ('quest', 0.061), ('rsf', 0.061), ('squ', 0.061), ('sye', 0.061), ('tahrey', 0.061), ('tne', 0.061), ('twi', 0.061), ('china', 0.061), ('ob', 0.059), ('ht', 0.059), ('tio', 0.058), ('se', 0.057), ('rpa', 0.056), ('straint', 0.056), ('aenrde', 0.056), ('cedure', 0.056), ('cic', 0.056), ('cov', 0.056), ('egr', 0.056), ('erd', 0.056), ('ianb', 0.056), ('itso', 0.056), ('richly', 0.056), ('rtn', 0.056), ('stretching', 0.056), ('tee', 0.056), ('em', 0.056), ('woo', 0.053), ('tae', 0.053), ('nogf', 0.053), ('acoustic', 0.053), ('iti', 0.053), ('training', 0.052), ('bo', 0.051), ('sri', 0.05), ('embodied', 0.05), ('enr', 0.05), ('tit', 0.05), ('uthme', 0.05), ('afs', 0.05), ('aot', 0.05), ('hda', 0.05), ('hide', 0.05), ('oab', 0.05), ('ot', 0.05), ('fe', 0.05), ('guide', 0.05), ('inputs', 0.049), ('cope', 0.049), ('segmenting', 0.049), ('ti', 0.049), ('xim', 0.048), ('fei', 0.048), ('ica', 0.048)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="105-tfidf-1" href="./cvpr-2013-Deep_Learning_Shape_Priors_for_Object_Segmentation.html">105 cvpr-2013-Deep Learning Shape Priors for Object Segmentation</a></p>
<p>Author: Fei Chen, Huimin Yu, Roland Hu, Xunxun Zeng</p><p>Abstract: In this paper we introduce a new shape-driven approach for object segmentation. Given a training set of shapes, we first use deep Boltzmann machine to learn the hierarchical architecture of shape priors. This learned hierarchical architecture is then used to model shape variations of global and local structures in an energetic form. Finally, it is applied to data-driven variational methods to perform object extraction of corrupted data based on shape probabilistic representation. Experiments demonstrate that our model can be applied to dataset of arbitrary prior shapes, and can cope with image noise and clutter, as well as partial occlusions.</p><p>2 0.14098983 <a title="105-tfidf-2" href="./cvpr-2013-Exploring_Compositional_High_Order_Pattern_Potentials_for_Structured_Output_Learning.html">156 cvpr-2013-Exploring Compositional High Order Pattern Potentials for Structured Output Learning</a></p>
<p>Author: Yujia Li, Daniel Tarlow, Richard Zemel</p><p>Abstract: When modeling structured outputs such as image segmentations, prediction can be improved by accurately modeling structure present in the labels. A key challenge is developing tractable models that are able to capture complex high level structure like shape. In this work, we study the learning of a general class of pattern-like high order potential, which we call Compositional High Order Pattern Potentials (CHOPPs). We show that CHOPPs include the linear deviation pattern potentials of Rother et al. [26] and also Restricted Boltzmann Machines (RBMs); we also establish the near equivalence of these two models. Experimentally, we show that performance is affected significantly by the degree of variability present in the datasets, and we define a quantitative variability measure to aid in studying this. We then improve CHOPPs performance in high variability datasets with two primary contributions: (a) developing a loss-sensitive joint learning procedure, so that internal pattern parameters can be learned in conjunction with other model potentials to minimize expected loss;and (b) learning an image-dependent mapping that encourages or inhibits patterns depending on image features. We also explore varying how multiple patterns are composed, and learning convolutional patterns. Quantitative results on challenging highly variable datasets show that the joint learning and image-dependent high order potentials can improve performance.</p><p>3 0.13907923 <a title="105-tfidf-3" href="./cvpr-2013-Augmenting_CRFs_with_Boltzmann_Machine_Shape_Priors_for_Image_Labeling.html">50 cvpr-2013-Augmenting CRFs with Boltzmann Machine Shape Priors for Image Labeling</a></p>
<p>Author: Andrew Kae, Kihyuk Sohn, Honglak Lee, Erik Learned-Miller</p><p>Abstract: Conditional random fields (CRFs) provide powerful tools for building models to label image segments. They are particularly well-suited to modeling local interactions among adjacent regions (e.g., superpixels). However, CRFs are limited in dealing with complex, global (long-range) interactions between regions. Complementary to this, restricted Boltzmann machines (RBMs) can be used to model global shapes produced by segmentation models. In this work, we present a new model that uses the combined power of these two network types to build a state-of-the-art labeler. Although the CRF is a good baseline labeler, we show how an RBM can be added to the architecture to provide a global shape bias that complements the local modeling provided by the CRF. We demonstrate its labeling performance for the parts of complex face images from the Labeled Faces in the Wild data set. This hybrid model produces results that are both quantitatively and qualitatively better than the CRF alone. In addition to high-quality labeling results, we demonstrate that the hidden units in the RBM portion of our model can be interpreted as face attributes that have been learned without any attribute-level supervision.</p><p>4 0.13397451 <a title="105-tfidf-4" href="./cvpr-2013-Weakly_Supervised_Learning_of_Mid-Level_Features_with_Beta-Bernoulli_Process_Restricted_Boltzmann_Machines.html">462 cvpr-2013-Weakly Supervised Learning of Mid-Level Features with Beta-Bernoulli Process Restricted Boltzmann Machines</a></p>
<p>Author: Roni Mittelman, Honglak Lee, Benjamin Kuipers, Silvio Savarese</p><p>Abstract: The use of semantic attributes in computer vision problems has been gaining increased popularity in recent years. Attributes provide an intermediate feature representation in between low-level features and the class categories, leading to improved learning on novel categories from few examples. However, a major caveat is that learning semantic attributes is a laborious task, requiring a significant amount of time and human intervention to provide labels. In order to address this issue, we propose a weakly supervised approach to learn mid-level features, where only class-level supervision is provided during training. We develop a novel extension of the restricted Boltzmann machine (RBM) by incorporating a Beta-Bernoulli process factor potential for hidden units. Unlike the standard RBM, our model uses the class labels to promote category-dependent sharing of learned features, which tends to improve the generalization performance. By using semantic attributes for which annotations are available, we show that we can find correspondences between the learned mid-level features and the labeled attributes. Therefore, the mid-level features have distinct semantic characterization which is similar to that given by the semantic attributes, even though their labeling was not provided during training. Our experimental results on object recognition tasks show significant performance gains, outperforming existing methods which rely on manually labeled semantic attributes.</p><p>5 0.12891772 <a title="105-tfidf-5" href="./cvpr-2013-Learning_Multiple_Non-linear_Sub-spaces_Using_K-RBMs.html">253 cvpr-2013-Learning Multiple Non-linear Sub-spaces Using K-RBMs</a></p>
<p>Author: Siddhartha Chandra, Shailesh Kumar, C.V. Jawahar</p><p>Abstract: Understanding the nature of data is the key to building good representations. In domains such as natural images, the data comes from very complex distributions which are hard to capture. Feature learning intends to discover or best approximate these underlying distributions and use their knowledge to weed out irrelevant information, preserving most of the relevant information. Feature learning can thus be seen as a form of dimensionality reduction. In this paper, we describe a feature learning scheme for natural images. We hypothesize that image patches do not all come from the same distribution, they lie in multiple nonlinear subspaces. We propose a framework that uses K Restricted Boltzmann Machines (K-RBMS) to learn multiple non-linear subspaces in the raw image space. Projections of the image patches into these subspaces gives us features, which we use to build image representations. Our algorithm solves the coupled problem of finding the right non-linear subspaces in the input space and associating image patches with those subspaces in an iterative EM like algorithm to minimize the overall reconstruction error. Extensive empirical results over several popular image classification datasets show that representations based on our framework outperform the traditional feature representations such as the SIFT based Bag-of-Words (BoW) and convolutional deep belief networks.</p><p>6 0.12313238 <a title="105-tfidf-6" href="./cvpr-2013-Non-rigid_Structure_from_Motion_with_Diffusion_Maps_Prior.html">306 cvpr-2013-Non-rigid Structure from Motion with Diffusion Maps Prior</a></p>
<p>7 0.10804088 <a title="105-tfidf-7" href="./cvpr-2013-Active_Contours_with_Group_Similarity.html">33 cvpr-2013-Active Contours with Group Similarity</a></p>
<p>8 0.10344396 <a title="105-tfidf-8" href="./cvpr-2013-SCaLE%3A_Supervised_and_Cascaded_Laplacian_Eigenmaps_for_Visual_Object_Recognition_Based_on_Nearest_Neighbors.html">371 cvpr-2013-SCaLE: Supervised and Cascaded Laplacian Eigenmaps for Visual Object Recognition Based on Nearest Neighbors</a></p>
<p>9 0.098641351 <a title="105-tfidf-9" href="./cvpr-2013-Semi-supervised_Learning_of_Feature_Hierarchies_for_Object_Detection_in_a_Video.html">388 cvpr-2013-Semi-supervised Learning of Feature Hierarchies for Object Detection in a Video</a></p>
<p>10 0.097230338 <a title="105-tfidf-10" href="./cvpr-2013-Modeling_Mutual_Visibility_Relationship_in_Pedestrian_Detection.html">288 cvpr-2013-Modeling Mutual Visibility Relationship in Pedestrian Detection</a></p>
<p>11 0.097069204 <a title="105-tfidf-11" href="./cvpr-2013-Facial_Feature_Tracking_Under_Varying_Facial_Expressions_and_Face_Poses_Based_on_Restricted_Boltzmann_Machines.html">161 cvpr-2013-Facial Feature Tracking Under Varying Facial Expressions and Face Poses Based on Restricted Boltzmann Machines</a></p>
<p>12 0.078008264 <a title="105-tfidf-12" href="./cvpr-2013-Dense_Reconstruction_Using_3D_Object_Shape_Priors.html">111 cvpr-2013-Dense Reconstruction Using 3D Object Shape Priors</a></p>
<p>13 0.077270076 <a title="105-tfidf-13" href="./cvpr-2013-PDM-ENLOR%3A_Learning_Ensemble_of_Local_PDM-Based_Regressions.html">321 cvpr-2013-PDM-ENLOR: Learning Ensemble of Local PDM-Based Regressions</a></p>
<p>14 0.077090807 <a title="105-tfidf-14" href="./cvpr-2013-Dense_Variational_Reconstruction_of_Non-rigid_Surfaces_from_Monocular_Video.html">113 cvpr-2013-Dense Variational Reconstruction of Non-rigid Surfaces from Monocular Video</a></p>
<p>15 0.075400837 <a title="105-tfidf-15" href="./cvpr-2013-Explicit_Occlusion_Modeling_for_3D_Object_Class_Representations.html">154 cvpr-2013-Explicit Occlusion Modeling for 3D Object Class Representations</a></p>
<p>16 0.075177297 <a title="105-tfidf-16" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<p>17 0.072152145 <a title="105-tfidf-17" href="./cvpr-2013-Action_Recognition_by_Hierarchical_Sequence_Summarization.html">32 cvpr-2013-Action Recognition by Hierarchical Sequence Summarization</a></p>
<p>18 0.067275524 <a title="105-tfidf-18" href="./cvpr-2013-Multipath_Sparse_Coding_Using_Hierarchical_Matching_Pursuit.html">304 cvpr-2013-Multipath Sparse Coding Using Hierarchical Matching Pursuit</a></p>
<p>19 0.067011058 <a title="105-tfidf-19" href="./cvpr-2013-Dense_Object_Reconstruction_with_Semantic_Priors.html">110 cvpr-2013-Dense Object Reconstruction with Semantic Priors</a></p>
<p>20 0.062508211 <a title="105-tfidf-20" href="./cvpr-2013-Scene_Parsing_by_Integrating_Function%2C_Geometry_and_Appearance_Models.html">381 cvpr-2013-Scene Parsing by Integrating Function, Geometry and Appearance Models</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.159), (1, 0.021), (2, -0.01), (3, 0.027), (4, 0.054), (5, -0.002), (6, 0.004), (7, 0.0), (8, -0.0), (9, -0.054), (10, 0.033), (11, -0.011), (12, -0.083), (13, -0.054), (14, 0.042), (15, 0.125), (16, -0.078), (17, 0.103), (18, 0.078), (19, 0.058), (20, 0.037), (21, -0.126), (22, 0.041), (23, -0.086), (24, -0.032), (25, -0.012), (26, 0.032), (27, -0.031), (28, 0.035), (29, 0.03), (30, 0.011), (31, -0.018), (32, -0.124), (33, 0.029), (34, 0.048), (35, 0.005), (36, 0.013), (37, -0.023), (38, 0.0), (39, -0.077), (40, 0.041), (41, 0.062), (42, 0.058), (43, -0.08), (44, 0.035), (45, 0.046), (46, 0.001), (47, 0.056), (48, -0.017), (49, 0.088)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.91733712 <a title="105-lsi-1" href="./cvpr-2013-Deep_Learning_Shape_Priors_for_Object_Segmentation.html">105 cvpr-2013-Deep Learning Shape Priors for Object Segmentation</a></p>
<p>Author: Fei Chen, Huimin Yu, Roland Hu, Xunxun Zeng</p><p>Abstract: In this paper we introduce a new shape-driven approach for object segmentation. Given a training set of shapes, we first use deep Boltzmann machine to learn the hierarchical architecture of shape priors. This learned hierarchical architecture is then used to model shape variations of global and local structures in an energetic form. Finally, it is applied to data-driven variational methods to perform object extraction of corrupted data based on shape probabilistic representation. Experiments demonstrate that our model can be applied to dataset of arbitrary prior shapes, and can cope with image noise and clutter, as well as partial occlusions.</p><p>2 0.67418998 <a title="105-lsi-2" href="./cvpr-2013-Learning_Multiple_Non-linear_Sub-spaces_Using_K-RBMs.html">253 cvpr-2013-Learning Multiple Non-linear Sub-spaces Using K-RBMs</a></p>
<p>Author: Siddhartha Chandra, Shailesh Kumar, C.V. Jawahar</p><p>Abstract: Understanding the nature of data is the key to building good representations. In domains such as natural images, the data comes from very complex distributions which are hard to capture. Feature learning intends to discover or best approximate these underlying distributions and use their knowledge to weed out irrelevant information, preserving most of the relevant information. Feature learning can thus be seen as a form of dimensionality reduction. In this paper, we describe a feature learning scheme for natural images. We hypothesize that image patches do not all come from the same distribution, they lie in multiple nonlinear subspaces. We propose a framework that uses K Restricted Boltzmann Machines (K-RBMS) to learn multiple non-linear subspaces in the raw image space. Projections of the image patches into these subspaces gives us features, which we use to build image representations. Our algorithm solves the coupled problem of finding the right non-linear subspaces in the input space and associating image patches with those subspaces in an iterative EM like algorithm to minimize the overall reconstruction error. Extensive empirical results over several popular image classification datasets show that representations based on our framework outperform the traditional feature representations such as the SIFT based Bag-of-Words (BoW) and convolutional deep belief networks.</p><p>3 0.6613614 <a title="105-lsi-3" href="./cvpr-2013-Exploring_Compositional_High_Order_Pattern_Potentials_for_Structured_Output_Learning.html">156 cvpr-2013-Exploring Compositional High Order Pattern Potentials for Structured Output Learning</a></p>
<p>Author: Yujia Li, Daniel Tarlow, Richard Zemel</p><p>Abstract: When modeling structured outputs such as image segmentations, prediction can be improved by accurately modeling structure present in the labels. A key challenge is developing tractable models that are able to capture complex high level structure like shape. In this work, we study the learning of a general class of pattern-like high order potential, which we call Compositional High Order Pattern Potentials (CHOPPs). We show that CHOPPs include the linear deviation pattern potentials of Rother et al. [26] and also Restricted Boltzmann Machines (RBMs); we also establish the near equivalence of these two models. Experimentally, we show that performance is affected significantly by the degree of variability present in the datasets, and we define a quantitative variability measure to aid in studying this. We then improve CHOPPs performance in high variability datasets with two primary contributions: (a) developing a loss-sensitive joint learning procedure, so that internal pattern parameters can be learned in conjunction with other model potentials to minimize expected loss;and (b) learning an image-dependent mapping that encourages or inhibits patterns depending on image features. We also explore varying how multiple patterns are composed, and learning convolutional patterns. Quantitative results on challenging highly variable datasets show that the joint learning and image-dependent high order potentials can improve performance.</p><p>4 0.65562642 <a title="105-lsi-4" href="./cvpr-2013-Weakly_Supervised_Learning_of_Mid-Level_Features_with_Beta-Bernoulli_Process_Restricted_Boltzmann_Machines.html">462 cvpr-2013-Weakly Supervised Learning of Mid-Level Features with Beta-Bernoulli Process Restricted Boltzmann Machines</a></p>
<p>Author: Roni Mittelman, Honglak Lee, Benjamin Kuipers, Silvio Savarese</p><p>Abstract: The use of semantic attributes in computer vision problems has been gaining increased popularity in recent years. Attributes provide an intermediate feature representation in between low-level features and the class categories, leading to improved learning on novel categories from few examples. However, a major caveat is that learning semantic attributes is a laborious task, requiring a significant amount of time and human intervention to provide labels. In order to address this issue, we propose a weakly supervised approach to learn mid-level features, where only class-level supervision is provided during training. We develop a novel extension of the restricted Boltzmann machine (RBM) by incorporating a Beta-Bernoulli process factor potential for hidden units. Unlike the standard RBM, our model uses the class labels to promote category-dependent sharing of learned features, which tends to improve the generalization performance. By using semantic attributes for which annotations are available, we show that we can find correspondences between the learned mid-level features and the labeled attributes. Therefore, the mid-level features have distinct semantic characterization which is similar to that given by the semantic attributes, even though their labeling was not provided during training. Our experimental results on object recognition tasks show significant performance gains, outperforming existing methods which rely on manually labeled semantic attributes.</p><p>5 0.65511084 <a title="105-lsi-5" href="./cvpr-2013-Augmenting_CRFs_with_Boltzmann_Machine_Shape_Priors_for_Image_Labeling.html">50 cvpr-2013-Augmenting CRFs with Boltzmann Machine Shape Priors for Image Labeling</a></p>
<p>Author: Andrew Kae, Kihyuk Sohn, Honglak Lee, Erik Learned-Miller</p><p>Abstract: Conditional random fields (CRFs) provide powerful tools for building models to label image segments. They are particularly well-suited to modeling local interactions among adjacent regions (e.g., superpixels). However, CRFs are limited in dealing with complex, global (long-range) interactions between regions. Complementary to this, restricted Boltzmann machines (RBMs) can be used to model global shapes produced by segmentation models. In this work, we present a new model that uses the combined power of these two network types to build a state-of-the-art labeler. Although the CRF is a good baseline labeler, we show how an RBM can be added to the architecture to provide a global shape bias that complements the local modeling provided by the CRF. We demonstrate its labeling performance for the parts of complex face images from the Labeled Faces in the Wild data set. This hybrid model produces results that are both quantitatively and qualitatively better than the CRF alone. In addition to high-quality labeling results, we demonstrate that the hidden units in the RBM portion of our model can be interpreted as face attributes that have been learned without any attribute-level supervision.</p><p>6 0.61223221 <a title="105-lsi-6" href="./cvpr-2013-Action_Recognition_by_Hierarchical_Sequence_Summarization.html">32 cvpr-2013-Action Recognition by Hierarchical Sequence Summarization</a></p>
<p>7 0.56186861 <a title="105-lsi-7" href="./cvpr-2013-Active_Contours_with_Group_Similarity.html">33 cvpr-2013-Active Contours with Group Similarity</a></p>
<p>8 0.55606216 <a title="105-lsi-8" href="./cvpr-2013-Wide-Baseline_Hair_Capture_Using_Strand-Based_Refinement.html">467 cvpr-2013-Wide-Baseline Hair Capture Using Strand-Based Refinement</a></p>
<p>9 0.55540031 <a title="105-lsi-9" href="./cvpr-2013-PDM-ENLOR%3A_Learning_Ensemble_of_Local_PDM-Based_Regressions.html">321 cvpr-2013-PDM-ENLOR: Learning Ensemble of Local PDM-Based Regressions</a></p>
<p>10 0.54764128 <a title="105-lsi-10" href="./cvpr-2013-SCaLE%3A_Supervised_and_Cascaded_Laplacian_Eigenmaps_for_Visual_Object_Recognition_Based_on_Nearest_Neighbors.html">371 cvpr-2013-SCaLE: Supervised and Cascaded Laplacian Eigenmaps for Visual Object Recognition Based on Nearest Neighbors</a></p>
<p>11 0.5405848 <a title="105-lsi-11" href="./cvpr-2013-Dense_Object_Reconstruction_with_Semantic_Priors.html">110 cvpr-2013-Dense Object Reconstruction with Semantic Priors</a></p>
<p>12 0.53668344 <a title="105-lsi-12" href="./cvpr-2013-Procrustean_Normal_Distribution_for_Non-rigid_Structure_from_Motion.html">341 cvpr-2013-Procrustean Normal Distribution for Non-rigid Structure from Motion</a></p>
<p>13 0.51721823 <a title="105-lsi-13" href="./cvpr-2013-Non-rigid_Structure_from_Motion_with_Diffusion_Maps_Prior.html">306 cvpr-2013-Non-rigid Structure from Motion with Diffusion Maps Prior</a></p>
<p>14 0.51316607 <a title="105-lsi-14" href="./cvpr-2013-Improving_the_Visual_Comprehension_of_Point_Sets.html">218 cvpr-2013-Improving the Visual Comprehension of Point Sets</a></p>
<p>15 0.48328644 <a title="105-lsi-15" href="./cvpr-2013-Dense_Variational_Reconstruction_of_Non-rigid_Surfaces_from_Monocular_Video.html">113 cvpr-2013-Dense Variational Reconstruction of Non-rigid Surfaces from Monocular Video</a></p>
<p>16 0.46569043 <a title="105-lsi-16" href="./cvpr-2013-Multipath_Sparse_Coding_Using_Hierarchical_Matching_Pursuit.html">304 cvpr-2013-Multipath Sparse Coding Using Hierarchical Matching Pursuit</a></p>
<p>17 0.45867026 <a title="105-lsi-17" href="./cvpr-2013-Robust_Discriminative_Response_Map_Fitting_with_Constrained_Local_Models.html">359 cvpr-2013-Robust Discriminative Response Map Fitting with Constrained Local Models</a></p>
<p>18 0.45512837 <a title="105-lsi-18" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<p>19 0.44043958 <a title="105-lsi-19" href="./cvpr-2013-Pedestrian_Detection_with_Unsupervised_Multi-stage_Feature_Learning.html">328 cvpr-2013-Pedestrian Detection with Unsupervised Multi-stage Feature Learning</a></p>
<p>20 0.43885994 <a title="105-lsi-20" href="./cvpr-2013-Relative_Hidden_Markov_Models_for_Evaluating_Motion_Skill.html">353 cvpr-2013-Relative Hidden Markov Models for Evaluating Motion Skill</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.132), (16, 0.021), (26, 0.044), (33, 0.233), (49, 0.311), (67, 0.064), (69, 0.056), (87, 0.061)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.77181131 <a title="105-lda-1" href="./cvpr-2013-Deep_Learning_Shape_Priors_for_Object_Segmentation.html">105 cvpr-2013-Deep Learning Shape Priors for Object Segmentation</a></p>
<p>Author: Fei Chen, Huimin Yu, Roland Hu, Xunxun Zeng</p><p>Abstract: In this paper we introduce a new shape-driven approach for object segmentation. Given a training set of shapes, we first use deep Boltzmann machine to learn the hierarchical architecture of shape priors. This learned hierarchical architecture is then used to model shape variations of global and local structures in an energetic form. Finally, it is applied to data-driven variational methods to perform object extraction of corrupted data based on shape probabilistic representation. Experiments demonstrate that our model can be applied to dataset of arbitrary prior shapes, and can cope with image noise and clutter, as well as partial occlusions.</p><p>2 0.76937658 <a title="105-lda-2" href="./cvpr-2013-A_Global_Approach_for_the_Detection_of_Vanishing_Points_and_Mutually_Orthogonal_Vanishing_Directions.html">12 cvpr-2013-A Global Approach for the Detection of Vanishing Points and Mutually Orthogonal Vanishing Directions</a></p>
<p>Author: Michel Antunes, João P. Barreto</p><p>Abstract: This article presents a new global approach for detecting vanishing points and groups of mutually orthogonal vanishing directions using lines detected in images of man-made environments. These two multi-model fitting problems are respectively cast as Uncapacited Facility Location (UFL) and Hierarchical Facility Location (HFL) instances that are efficiently solved using a message passing inference algorithm. We also propose new functions for measuring the consistency between an edge and aputative vanishingpoint, and for computing the vanishing point defined by a subset of edges. Extensive experiments in both synthetic and real images show that our algorithms outperform the state-ofthe-art methods while keeping computation tractable. In addition, we show for the first time results in simultaneously detecting multiple Manhattan-world configurations that can either share one vanishing direction (Atlanta world) or be completely independent.</p><p>3 0.73785043 <a title="105-lda-3" href="./cvpr-2013-A_Machine_Learning_Approach_for_Non-blind_Image_Deconvolution.html">17 cvpr-2013-A Machine Learning Approach for Non-blind Image Deconvolution</a></p>
<p>Author: Christian J. Schuler, Harold Christopher Burger, Stefan Harmeling, Bernhard Schölkopf</p><p>Abstract: Image deconvolution is the ill-posed problem of recovering a sharp image, given a blurry one generated by a convolution. In this work, we deal with space-invariant non- blind deconvolution. Currently, the most successful meth- ods involve a regularized inversion of the blur in Fourier domain as a first step. This step amplifies and colors the noise, and corrupts the image information. In a second (and arguably more difficult) step, one then needs to remove the colored noise, typically using a cleverly engineered algorithm. However, the methods based on this two-step ap- proach do not properly address the fact that the image information has been corrupted. In this work, we also rely on a two-step procedure, but learn the second step on a large dataset of natural images, using a neural network. We will show that this approach outperforms the current state-ofthe-art on a large dataset of artificially blurred images. We demonstrate the practical applicability of our method in a real-world example with photographic out-of-focus blur.</p><p>4 0.69107181 <a title="105-lda-4" href="./cvpr-2013-Learning_Structured_Low-Rank_Representations_for_Image_Classification.html">257 cvpr-2013-Learning Structured Low-Rank Representations for Image Classification</a></p>
<p>Author: Yangmuzi Zhang, Zhuolin Jiang, Larry S. Davis</p><p>Abstract: An approach to learn a structured low-rank representation for image classification is presented. We use a supervised learning method to construct a discriminative and reconstructive dictionary. By introducing an ideal regularization term, we perform low-rank matrix recovery for contaminated training data from all categories simultaneously without losing structural information. A discriminative low-rank representation for images with respect to the constructed dictionary is obtained. With semantic structure information and strong identification capability, this representation is good for classification tasks even using a simple linear multi-classifier. Experimental results demonstrate the effectiveness of our approach.</p><p>5 0.67806929 <a title="105-lda-5" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>Author: Ian Endres, Kevin J. Shih, Johnston Jiaa, Derek Hoiem</p><p>Abstract: We propose a method to learn a diverse collection of discriminative parts from object bounding box annotations. Part detectors can be trained and applied individually, which simplifies learning and extension to new features or categories. We apply the parts to object category detection, pooling part detections within bottom-up proposed regions and using a boosted classifier with proposed sigmoid weak learners for scoring. On PASCAL VOC 2010, we evaluate the part detectors ’ ability to discriminate and localize annotated keypoints. Our detection system is competitive with the best-existing systems, outperforming other HOG-based detectors on the more deformable categories.</p><p>6 0.67521584 <a title="105-lda-6" href="./cvpr-2013-Structure_Preserving_Object_Tracking.html">414 cvpr-2013-Structure Preserving Object Tracking</a></p>
<p>7 0.67208803 <a title="105-lda-7" href="./cvpr-2013-Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking.html">285 cvpr-2013-Minimum Uncertainty Gap for Robust Visual Tracking</a></p>
<p>8 0.67200285 <a title="105-lda-8" href="./cvpr-2013-Part_Discovery_from_Partial_Correspondence.html">325 cvpr-2013-Part Discovery from Partial Correspondence</a></p>
<p>9 0.67115587 <a title="105-lda-9" href="./cvpr-2013-Spatiotemporal_Deformable_Part_Models_for_Action_Detection.html">408 cvpr-2013-Spatiotemporal Deformable Part Models for Action Detection</a></p>
<p>10 0.67024153 <a title="105-lda-10" href="./cvpr-2013-Online_Object_Tracking%3A_A_Benchmark.html">314 cvpr-2013-Online Object Tracking: A Benchmark</a></p>
<p>11 0.67004865 <a title="105-lda-11" href="./cvpr-2013-Integrating_Grammar_and_Segmentation_for_Human_Pose_Estimation.html">225 cvpr-2013-Integrating Grammar and Segmentation for Human Pose Estimation</a></p>
<p>12 0.66902912 <a title="105-lda-12" href="./cvpr-2013-Understanding_Indoor_Scenes_Using_3D_Geometric_Phrases.html">446 cvpr-2013-Understanding Indoor Scenes Using 3D Geometric Phrases</a></p>
<p>13 0.66821808 <a title="105-lda-13" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<p>14 0.66801929 <a title="105-lda-14" href="./cvpr-2013-Understanding_Bayesian_Rooms_Using_Composite_3D_Object_Models.html">445 cvpr-2013-Understanding Bayesian Rooms Using Composite 3D Object Models</a></p>
<p>15 0.66725761 <a title="105-lda-15" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<p>16 0.66712433 <a title="105-lda-16" href="./cvpr-2013-Part-Based_Visual_Tracking_with_Online_Latent_Structural_Learning.html">324 cvpr-2013-Part-Based Visual Tracking with Online Latent Structural Learning</a></p>
<p>17 0.66711396 <a title="105-lda-17" href="./cvpr-2013-Bottom-Up_Segmentation_for_Top-Down_Detection.html">70 cvpr-2013-Bottom-Up Segmentation for Top-Down Detection</a></p>
<p>18 0.66677821 <a title="105-lda-18" href="./cvpr-2013-A_Joint_Model_for_2D_and_3D_Pose_Estimation_from_a_Single_Image.html">14 cvpr-2013-A Joint Model for 2D and 3D Pose Estimation from a Single Image</a></p>
<p>19 0.66580468 <a title="105-lda-19" href="./cvpr-2013-CLAM%3A_Coupled_Localization_and_Mapping_with_Efficient_Outlier_Handling.html">74 cvpr-2013-CLAM: Coupled Localization and Mapping with Efficient Outlier Handling</a></p>
<p>20 0.66569078 <a title="105-lda-20" href="./cvpr-2013-Least_Soft-Threshold_Squares_Tracking.html">267 cvpr-2013-Least Soft-Threshold Squares Tracking</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
