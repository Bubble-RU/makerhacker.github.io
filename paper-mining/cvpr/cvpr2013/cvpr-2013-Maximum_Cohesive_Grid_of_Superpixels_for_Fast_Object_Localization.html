<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>280 cvpr-2013-Maximum Cohesive Grid of Superpixels for Fast Object Localization</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-280" href="#">cvpr2013-280</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>280 cvpr-2013-Maximum Cohesive Grid of Superpixels for Fast Object Localization</h1>
<br/><p>Source: <a title="cvpr-2013-280-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Li_Maximum_Cohesive_Grid_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Liang Li, Wei Feng, Liang Wan, Jiawan Zhang</p><p>Abstract: This paper addresses a challenging problem of regularizing arbitrary superpixels into an optimal grid structure, which may significantly extend current low-level vision algorithms by allowing them to use superpixels (SPs) conveniently as using pixels. For this purpose, we aim at constructing maximum cohesive SP-grid, which is composed of real nodes, i.e. SPs, and dummy nodes that are meaningless in the image with only position-taking function in the grid. For a given formation of image SPs and proper number of dummy nodes, we first dynamically align them into a grid based on the centroid localities of SPs. We then define the SP-grid coherence as the sum of edge weights, with SP locality and appearance encoded, along all direct paths connecting any two nearest neighboring real nodes in the grid. We finally maximize the SP-grid coherence via cascade dynamic programming. Our approach can take the regional objectness as an optional constraint to produce more semantically reliable SP-grids. Experiments on object localization show that our approach outperforms state-of-the-art methods in terms of both detection accuracy and speed. We also find that with the same searching strategy and features, object localization at SP-level is about 100-500 times faster than pixel-level, with usually better detection accuracy.</p><p>Reference: <a title="cvpr-2013-280-reference" href="../cvpr2013_reference/cvpr-2013-Maximum_Cohesive_Grid_of_Superpixels_for_Fast_Object_Localization_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 For this purpose, we aim at constructing maximum cohesive SP-grid, which is composed of real nodes, i. [sent-2, score-0.42]
</p><p>2 SPs, and dummy nodes that are meaningless in the image with only position-taking function in the grid. [sent-4, score-0.422]
</p><p>3 For a given formation of image SPs and proper number of dummy nodes, we first dynamically align them into a grid based on the centroid localities of SPs. [sent-5, score-0.522]
</p><p>4 We then define the SP-grid coherence as the sum of edge weights, with SP locality and appearance encoded, along all direct paths connecting any two nearest neighboring real nodes in the grid. [sent-6, score-0.428]
</p><p>5 We finally maximize the SP-grid coherence via cascade dynamic programming. [sent-7, score-0.209]
</p><p>6 Our approach can take the regional objectness as an optional constraint to produce more semantically reliable SP-grids. [sent-8, score-0.268]
</p><p>7 Experiments on object localization show that our approach outperforms state-of-the-art methods in terms of both detection accuracy and speed. [sent-9, score-0.088]
</p><p>8 We  also find that with the same searching strategy and features, object localization at SP-level is about 100-500 times faster than pixel-level, with usually better detection accuracy. [sent-10, score-0.162]
</p><p>9 From the angle of MRF [8], superpixels (SPs), generated by grouping similar pixels into perceptually meaningful atomic regions [ 18], can dramatically reduce the number of variables to be optimized, thus leading to significant speed-up and allowing the analysis of long-range correlations. [sent-13, score-0.106]
</p><p>10 (e)-(g) Object detection results of TurboPixel [14], SuperLattice [ 17] and pixel-level RC with finer searching step [23]. [sent-41, score-0.099]
</p><p>11 Due to the apparent scale variation in query and target images, pixel-level RC needs finer step to search the foregroundbox, which may become very slow. [sent-42, score-0.066]
</p><p>12 (h) and (i) are the results of our approach by regularizing SLIC SPs (c) without/with the guidance of SP objectness (d), respectively. [sent-43, score-0.224]
</p><p>13 At the very beginning, superpixels were simply treated as fast over-segmentations to the image [ 15]. [sent-48, score-0.106]
</p><p>14 1(c), image over-segmentations usually tend to generate SPs with variant sizes, shapes and irregular spatial dis333 111777224  tributions. [sent-50, score-0.067]
</p><p>15 As the increasing usage of SPs in image parsing [22], segmentation [ 18, 24], co-segmentation [ 10, 20], and object localization [ 13], people start to realize the importance of structural regularities in SPs [ 1, 16, 21, 25]. [sent-51, score-0.13]
</p><p>16 seeking proper tradeoff between the structural regularity and the boundary accuracy of superpixels. [sent-57, score-0.134]
</p><p>17 Thus, compared to particular regular SP algorithms, it is more desirable to find a way rectifying arbitrary segmentations into a regular structure. [sent-62, score-0.131]
</p><p>18 Besides, anothernotable weakness ofcurrent regular SP methods is that their performance may highly depend on the pre-computed edge map [ 16, 21]. [sent-63, score-0.083]
</p><p>19 This paper, to the best of our knowl-  edge, for the first time proposes a generic approach to optimally regularizing arbitrary SPs into a regular grid. [sent-64, score-0.135]
</p><p>20 By this, we can both fully take advantage of the strength of various image segmentation/SP methods [ 1, 6, 5, 8], and enjoy the desirable properties of grid at the same time. [sent-65, score-0.081]
</p><p>21 To this end, we define cohesive SP-grid, which is composed of (1) real nodes, i. [sent-66, score-0.367]
</p><p>22 real SPs generated by any appropriate superpixel or segmentation algorithms, and (2) dummy nodes that are meaningless in the image with only position-taking function in the grid. [sent-68, score-0.531]
</p><p>23 We aim at constructing maximum cohesive SP-grid that regularizes all pairwise SP connections into a lattice, while preserving the most important image structures. [sent-69, score-0.34]
</p><p>24 First, we unevenly assign all real nodes into a grid by minimizing the overall locality discrepancy cost. [sent-71, score-0.383]
</p><p>25 The initial cohesive SP-grid is obtained by appending proper number of dummy nodes at the end of each grid column. [sent-72, score-0.809]
</p><p>26 We then iteratively refine the cohesive SP-grid by optimizing each grid column within its contemporary context configurations. [sent-73, score-0.418]
</p><p>27 As an optional compensation, the regional objectness score [ 2] can also be used as an extra constraint to refine the SP coherence measurement, thus leading to a more semantically feasible SP-grid. [sent-75, score-0.417]
</p><p>28 Experiments on object localization show that our approach outperforms state-of-the-art ones in terms of both detection accuracy and speed. [sent-76, score-0.088]
</p><p>29 With the same strategy and features [23], object localization via our SP-grid  is 100-500 times faster (including grid regularization and matching time) than pixel-level matching, and usually produces better detection accuracy. [sent-77, score-0.191]
</p><p>30 The concept of superpixels stems from the homogeneous subregions generated by a fast oversegmentation to the image, e. [sent-80, score-0.106]
</p><p>31 This kind of SPs usually form an irregular graph, with SP boundaries well-aligned to image edges. [sent-83, score-0.067]
</p><p>32 Recently, people start to realize the advantages of regular structured SPs. [sent-85, score-0.075]
</p><p>33 In contrast to the near-grid property of SLIC and TurboPixel, SuperLattice and LatticeCut are able to produce exact grid structured SPs. [sent-88, score-0.081]
</p><p>34 For instance, based on a pre-computed reliable edge map, SuperLattice adopts a greedy strategy to generate the optimal paths of SP-grid by following the input edge map and satisfying the grid structural constraints [ 17]. [sent-89, score-0.186]
</p><p>35 Recent useful object localization routines includes Region Covariance (RC) [23] and Efficient Subwindow Search (ESS) [ 12]. [sent-91, score-0.063]
</p><p>36 In [23], the RC descriptor encoding color, gradient and locality features has been proposed for robust object detection in differen-  t images. [sent-92, score-0.078]
</p><p>37 Note that, integralimage acceleration cannot be directly applied to irregular graphs with arbitrary structures. [sent-96, score-0.09]
</p><p>38 However, there is no general way to apply DP to any kind of irregular graphs of SPs. [sent-100, score-0.067]
</p><p>39 With the proposed approach, most successful algorithms for both object localization and DP-based applications can be directly applied to SP-level, via any suitable type of SPs. [sent-101, score-0.063]
</p><p>40 Overview To regularize arbitrary SPs with any kind of irregular structure, we consider optimally allocating SPs within a virtual grid. [sent-103, score-0.146]
</p><p>41 Since the SP pair coherence defined as their centroid locality and regional appearance closeness in Eq. [sent-108, score-0.274]
</p><p>42 Thus, we need also to incorporate position-taking dummy nodes. [sent-111, score-0.289]
</p><p>43 1  Note that, condition (2) and (3) in the Definition 1 ensure the only positive-taking function of dummy nodes. [sent-115, score-0.289]
</p><p>44 Hence, for a given set of real nodes P and dummy nodes D, our objective onf s generic aSlP n grid regularization can o bdee formally expressed as constructing an optimal cohesive SP-grid G = ? [sent-116, score-0.956]
</p><p>45 Maximum Cohesive Grid of Superpixels For a given set of superpixels P, seeking global maximum cro ahe gsivivene SP-grid uisp generally Pin,t sreaecktaibnlge, g e. [sent-122, score-0.16]
</p><p>46 alelt m r ×x c mum  cohesive  SP-grid  i  1Direct path from p to q is the sequence of edges connecting them and passing only dummy nodes in the same row/column of p and q. [sent-124, score-0.703]
</p><p>47 2 Moreover, recalling condition (3) in Definit(i|oPn| 1 + ,t 1he) state of a grid position, i. [sent-146, score-0.081]
</p><p>48 either some real node or the dummy node, highly correlates to its nearest neighboring positions, if they together form a direction path. [sent-148, score-0.45]
</p><p>49 2, this paper proposes a two-step nearotimum approach to (1) cohesive SP-grid initialization, and (2) cohesive SP-grid maximization by cascade DP. [sent-151, score-0.642]
</p><p>50 Locality-based SP-grid initialization For a good cohesive SP-grid, the relative localities ofSPs in the image should be respected. [sent-154, score-0.394]
</p><p>51 fN Pote in tthoa ct, oinl utmhisn paper, d binotght oof th our initialization and maximization are conducted in columns only, which is empirically proven to be comparable with optimizing in rows or in both rows and columns for object localization by our experiments. [sent-156, score-0.196]
</p><p>52 c PThe c columns can be determined by c − 1 column-cuts, with all 2This  assumes an  SP can be assigned  to more  than  one  grid positions. [sent-158, score-0.118]
</p><p>53 Then, we measure its goodness by t ahned following locality discrepancy score, and seek an optimal Bˆ = arg minB Loc(B) : ? [sent-163, score-0.137]
</p><p>54 1  where Loc(B) is the sum of discrepancy values of all c  cwohleumren Ls. [sent-167, score-0.084]
</p><p>55 3, intrai is the intra-column discrepancy measured by the average centroid L2-distance ofall consecutive SP pairs in the #i column; interi is the inter-column discrepancy measured by the x-coordinates difference between two neighboring SPs of the #i column-cut; constant ? [sent-172, score-0.225]
</p><p>56 > 0 avoids dividing by zero; Li = bi+1 − bi + 1is the length of the #i column and L¯ = is the average column length. [sent-173, score-0.12]
</p><p>57 ωsep and ωlen are the weights of column separability and size regularity in Eq. [sent-176, score-0.102]
</p><p>58 (4)  (5) (6)  #N  real node  Figure 4: Maximizing cohesive SP-grid using cascade DP. [sent-179, score-0.454]
</p><p>59 The blue solid-lined region is the correlated subgraph used to calculate coh(p, k, n); the orange solid-lined region is the correlated subgraph of S(k − 1, p − 1); while the red tdhaesh c-olrinreedla region gisr atpheh c oofrr Se(lkat−e d subgraph corresponding to S(k, n). [sent-180, score-0.279]
</p><p>60 The red arrow-lines starting from the #p position in column ρ denote the direct path connecting two nearest neighboring left and right real nodes of #p. [sent-181, score-0.269]
</p><p>61 Then, we can efficiently obtain Bˆ with minimum discrepancy using Algorithm 1 under theB following boundary croepndain-tions: 2 ≤ k ≤ c, 1 ≤ n ≤ |P|, C(1, n) = loc(1, n) and tBioLn n(s1:, n2) ≤= k1. [sent-184, score-0.084]
</p><p>62 ≤Ba cs,e 1d on nBˆ, we Pco|n,s Ctr(1uc,tn th)e = =ini ltoica(l 1c,onhe)s aivned DP-grid G(0) by simply padding proper nthuem ibneitri aolf c dummy nDoPd-egsr iadt Gthe end of each column (see Fig. [sent-185, score-0.386]
</p><p>63 Dynamic maximization of cohesive SP-grid Starting from G(0) , our near-optimal maximum cohesive SP-Sgtaridrt nGg∗ firso m pro Ggressively refined by optimizing its every cSoPl-ugmridn uGnder current configurations of other columns. [sent-189, score-0.628]
</p><p>64 Since we in turn repeatedly update every column of G ∗ via iDncPe e to w me ainxi tumrinze r ethpeea otevdelryal ul SdPat-ger eidve cryoh ceorelunmcen, we name the method cascade DP. [sent-190, score-0.088]
</p><p>65 (8)  Note that, S(k, n) is the maximum overall coherence of the correlated subgraph, asserting the maximum increments caused by allocating k dummy nodes in the first n real nodes of the current column ρ. [sent-193, score-0.889]
</p><p>66 The correlated subgraph corresponding to such change is composed of all the nodes in the first n + k rows of G∗ whose states (i. [sent-194, score-0.228]
</p><p>67 either some partthiceul fairrs tr nea+l nko rdoew or othf eG dummy node) jointly contribute to increasing Coh(G∗ ). [sent-196, score-0.31]
</p><p>68 If p = n + 1, this dummy node will be assigned right after the #n real node. [sent-200, score-0.418]
</p><p>69 BS (k, n) is the back-retrieval table recording the best position of #k dummy node that forms the best configuration of adding k dummy nodes in the first n real nodes of ρ. [sent-201, score-0.917]
</p><p>70 Note, to meet condition (3) of Definition 1, calculating coh(p, k, n) needs to find the nearest horizontal real node neighbors for a particular position p (see Fig. [sent-202, score-0.129]
</p><p>71 4 We repeat the above process column by column till convergence. [sent-204, score-0.1]
</p><p>72 For a particular column ρ, the whole SP-grid can be divided into two correlated subgraphs, as shown in Fig. [sent-205, score-0.101]
</p><p>73 The overall coherence of these two correlated subgraphs is S(k − 1, p − 1)  aenncde ec oohft( hp,e ske, ntw),o respectively. [sent-207, score-0.245]
</p><p>74 bItg risa chlsea irs t Sh(akt maximizing the coherence of the first (n + k) rows of G ∗ is equivalent to mtheax ciomhiezrienngc etheo sum ofirfscto (hne+renkc)e r oowfs the of ft wGo correlated subgraphs, i. [sent-208, score-0.236]
</p><p>75 i=p  (9) where il and ir is the left-first real node and right-first real node for #i real node of column ρ, kl and kr is the left-first real node and right-first real node for #k dummy node of column ρ. [sent-214, score-1.103]
</p><p>76 Superpixel coherence metric We calculate the coherence of two SPs according to both their localities and appearances. [sent-219, score-0.397]
</p><p>77 For the #p SP of P, we their  localities  and  app  4As we only update columns of G∗ , the overall coherence along vertical direcAtiosnw eo fo any cpodalutme cno lisu mfunslly o fd Getermined by G(0) and is invariant to any configurations olfum thnat sco fluumllyn. [sent-220, score-0.286]
</p><p>78 d eStoe,r we can btrye Gat the vertical coherence component of coh(p, k, n) for the #i column as a constant Vi, which can be pre-computed using G(0). [sent-221, score-0.199]
</p><p>79 Then, we define the coherence of any two SPs p and q as  Coh(p,q) = exp? [sent-224, score-0.149]
</p><p>80 ,  (10)  where op and oq are the normalized centroids of superpixel p and q, while Hp and Hq are the quantized color histograms of p and q, respectively. [sent-228, score-0.07]
</p><p>81 1, the accuracy of our cohesive SP-grid for object detection may be further refined by incorporating the SP-level objectness that is defined as the mean objectness of all inclusive pixels. [sent-238, score-0.63]
</p><p>82 We compute the objectness of each pixel by averaging the objectness scores of a number of randomly-sampled subwindows in the image using the method of [2]. [sent-239, score-0.318]
</p><p>83 We impose the guidance ofthresholded SP objectness in the following way: for any two neighboring SPs p and q in the image, if they both survive the objectness thresholding, we amplify their original coherence Coh(p, q) by a constant factor F > 1. [sent-240, score-0.53]
</p><p>84 Since our cohesive SPgrid initialization and maximization strictly satisfy Definition 1, the resultant G∗ is certainly a cohesive SP-grid. [sent-242, score-0.633]
</p><p>85 Be-  stiiodnes 1, ,t thhee c raesscualdtaen Dt GP guarantees strictly increasing coherence of G∗ in each iteration. [sent-243, score-0.17]
</p><p>86 The complexity of SP-grid einnictieal oifzat Gion is O(|P| 2c), where |P| is the number of input superpixels na insd O c |isP |thec c,o wluhmerne n |Pum| ibse thr oef n target SP-grid. [sent-244, score-0.106]
</p><p>87 Due to the computation of correlated subgraphs, the complexity of maximizing column ρ is O( |ρ| 3m), where |ρ| is tphlee nituym obfer m aofx irmeailz inngod ceos aumndn m i ss Oth(e| ρn|ummb)e,r w ohfe dummy nodes to be added in the column. [sent-245, score-0.531]
</p><p>88 SuperLattice [17] and TurboPixel [ 14], by the task of object localization on benchmark datasets. [sent-249, score-0.063]
</p><p>89 Note, for TurboPixel, we simply assign the grid coordinates for each SP as the grid coordinates of its corresponding seed [ 14]. [sent-250, score-0.162]
</p><p>90 5  same integral-image based searching strategy and RC fea-  5The source code of our approach will be released soon. [sent-274, score-0.074]
</p><p>91 333 111777779  For any object localization result R, in this paper, we measure its accuracy rate compared to ground truth GT as the cardinality ratio of their intersection and union sets Acc(R) =  | RR∩∪GGTT||. [sent-275, score-0.063]
</p><p>92 We can clearly see that for all methods, exact query constantly leads to higher accuracy than query by bounding box. [sent-279, score-0.088]
</p><p>93 For pixel-level RC, searching by finer steps may lead to better results than using large steps, but with the cost ofrapidly increased running time. [sent-280, score-0.074]
</p><p>94 The grid regularity of TurboPixel and SuperLattice help to quickly produce the detection results, with comparable (or better) accuracy to pixel-level methods. [sent-281, score-0.158]
</p><p>95 Note that, except for MS, SP-grid based object localization is 100-500 times faster (including SP generation, SP-grid regularization and matching time) than pixel-level matching, while producing more than 15% accuracy improvements. [sent-283, score-0.063]
</p><p>96 All results of our approach reported in Table 1were generated without objectness guidance. [sent-284, score-0.159]
</p><p>97 We can see that compared to SuperLattice and TurboPixel, our approach tends to produce more accurate detection results better aligned to the real object boundaries. [sent-287, score-0.085]
</p><p>98 5, our approach used objectness guidance to refine the SP pair coherence matrix using F = 10. [sent-290, score-0.339]
</p><p>99 Conclusion We have proposed an efficient approach to regularize arbitrary superpixels into a regular grid by adding dummy n-  Figure 6: The robustness of our approach to rotation and scale variances in object localization. [sent-304, score-0.553]
</p><p>100 We also show how to incorporate regional objectness as an extra (optional) constraint to produce semantically more feasible SP-grids. [sent-307, score-0.227]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('sps', 0.527), ('coh', 0.362), ('dummy', 0.289), ('cohesive', 0.287), ('superlattice', 0.194), ('turbopixel', 0.194), ('sp', 0.172), ('objectness', 0.159), ('coherence', 0.149), ('loc', 0.137), ('tianjin', 0.112), ('slic', 0.111), ('superpixels', 0.106), ('nodes', 0.105), ('discrepancy', 0.084), ('grid', 0.081), ('egs', 0.08), ('localities', 0.078), ('rc', 0.074), ('node', 0.069), ('irregular', 0.067), ('localization', 0.063), ('real', 0.06), ('latticecut', 0.058), ('regular', 0.054), ('locality', 0.053), ('subgraph', 0.052), ('regularity', 0.052), ('searching', 0.052), ('correlated', 0.051), ('column', 0.05), ('superpixel', 0.049), ('hp', 0.049), ('bl', 0.048), ('regional', 0.047), ('subgraphs', 0.045), ('hq', 0.045), ('dp', 0.045), ('tpami', 0.045), ('query', 0.044), ('optional', 0.041), ('anx', 0.039), ('argk', 0.039), ('nnloc', 0.039), ('pxsort', 0.039), ('uperlattices', 0.039), ('urbopixelt', 0.039), ('cascade', 0.038), ('columns', 0.037), ('subwindow', 0.036), ('maximizing', 0.036), ('regularizing', 0.034), ('allocating', 0.032), ('neighboring', 0.032), ('guidance', 0.031), ('maximization', 0.03), ('seeking', 0.03), ('edge', 0.029), ('constructing', 0.029), ('initialization', 0.029), ('ess', 0.028), ('ms', 0.028), ('len', 0.028), ('levinshtein', 0.028), ('meaningless', 0.028), ('prince', 0.028), ('pix', 0.028), ('meanshift', 0.028), ('proper', 0.027), ('detection', 0.025), ('ba', 0.025), ('structural', 0.025), ('feng', 0.025), ('centroid', 0.025), ('maximum', 0.024), ('optimally', 0.024), ('arbitrary', 0.023), ('china', 0.023), ('dynamic', 0.022), ('finer', 0.022), ('cno', 0.022), ('strategy', 0.022), ('dynamically', 0.022), ('path', 0.022), ('increasing', 0.021), ('moore', 0.021), ('realize', 0.021), ('partitioning', 0.021), ('op', 0.021), ('besides', 0.021), ('semantically', 0.021), ('mp', 0.021), ('bs', 0.021), ('calculate', 0.021), ('scaling', 0.021), ('bi', 0.02), ('lattice', 0.02), ('end', 0.02), ('composed', 0.02), ('liang', 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="280-tfidf-1" href="./cvpr-2013-Maximum_Cohesive_Grid_of_Superpixels_for_Fast_Object_Localization.html">280 cvpr-2013-Maximum Cohesive Grid of Superpixels for Fast Object Localization</a></p>
<p>Author: Liang Li, Wei Feng, Liang Wan, Jiawan Zhang</p><p>Abstract: This paper addresses a challenging problem of regularizing arbitrary superpixels into an optimal grid structure, which may significantly extend current low-level vision algorithms by allowing them to use superpixels (SPs) conveniently as using pixels. For this purpose, we aim at constructing maximum cohesive SP-grid, which is composed of real nodes, i.e. SPs, and dummy nodes that are meaningless in the image with only position-taking function in the grid. For a given formation of image SPs and proper number of dummy nodes, we first dynamically align them into a grid based on the centroid localities of SPs. We then define the SP-grid coherence as the sum of edge weights, with SP locality and appearance encoded, along all direct paths connecting any two nearest neighboring real nodes in the grid. We finally maximize the SP-grid coherence via cascade dynamic programming. Our approach can take the regional objectness as an optional constraint to produce more semantically reliable SP-grids. Experiments on object localization show that our approach outperforms state-of-the-art methods in terms of both detection accuracy and speed. We also find that with the same searching strategy and features, object localization at SP-level is about 100-500 times faster than pixel-level, with usually better detection accuracy.</p><p>2 0.11467293 <a title="280-tfidf-2" href="./cvpr-2013-Improving_an_Object_Detector_and_Extracting_Regions_Using_Superpixels.html">217 cvpr-2013-Improving an Object Detector and Extracting Regions Using Superpixels</a></p>
<p>Author: Guang Shu, Afshin Dehghan, Mubarak Shah</p><p>Abstract: We propose an approach to improve the detection performance of a generic detector when it is applied to a particular video. The performance of offline-trained objects detectors are usually degraded in unconstrained video environments due to variant illuminations, backgrounds and camera viewpoints. Moreover, most object detectors are trained using Haar-like features or gradient features but ignore video specificfeatures like consistent colorpatterns. In our approach, we apply a Superpixel-based Bag-of-Words (BoW) model to iteratively refine the output of a generic detector. Compared to other related work, our method builds a video-specific detector using superpixels, hence it can handle the problem of appearance variation. Most importantly, using Conditional Random Field (CRF) along with our super pixel-based BoW model, we develop and algorithm to segment the object from the background . Therefore our method generates an output of the exact object regions instead of the bounding boxes generated by most detectors. In general, our method takes detection bounding boxes of a generic detector as input and generates the detection output with higher average precision and precise object regions. The experiments on four recent datasets demonstrate the effectiveness of our approach and significantly improves the state-of-art detector by 5-16% in average precision.</p><p>3 0.081217147 <a title="280-tfidf-3" href="./cvpr-2013-Voxel_Cloud_Connectivity_Segmentation_-_Supervoxels_for_Point_Clouds.html">458 cvpr-2013-Voxel Cloud Connectivity Segmentation - Supervoxels for Point Clouds</a></p>
<p>Author: Jeremie Papon, Alexey Abramov, Markus Schoeler, Florentin Wörgötter</p><p>Abstract: Unsupervised over-segmentation of an image into regions of perceptually similar pixels, known as superpixels, is a widely used preprocessing step in segmentation algorithms. Superpixel methods reduce the number of regions that must be considered later by more computationally expensive algorithms, with a minimal loss of information. Nevertheless, as some information is inevitably lost, it is vital that superpixels not cross object boundaries, as such errors will propagate through later steps. Existing methods make use of projected color or depth information, but do not consider three dimensional geometric relationships between observed data points which can be used to prevent superpixels from crossing regions of empty space. We propose a novel over-segmentation algorithm which uses voxel relationships to produce over-segmentations which are fully consistent with the spatial geometry of the scene in three dimensional, rather than projective, space. Enforcing the constraint that segmented regions must have spatial connectivity prevents label flow across semantic object boundaries which might otherwise be violated. Additionally, as the algorithm works directly in 3D space, observations from several calibrated RGB+D cameras can be segmented jointly. Experiments on a large data set of human annotated RGB+D images demonstrate a significant reduction in occurrence of clusters crossing object boundaries, while maintaining speeds comparable to state-of-the-art 2D methods.</p><p>4 0.076832153 <a title="280-tfidf-4" href="./cvpr-2013-A_Video_Representation_Using_Temporal_Superpixels.html">29 cvpr-2013-A Video Representation Using Temporal Superpixels</a></p>
<p>Author: Jason Chang, Donglai Wei, John W. Fisher_III</p><p>Abstract: We develop a generative probabilistic model for temporally consistent superpixels in video sequences. In contrast to supervoxel methods, object parts in different frames are tracked by the same temporal superpixel. We explicitly model flow between frames with a bilateral Gaussian process and use this information to propagate superpixels in an online fashion. We consider four novel metrics to quantify performance of a temporal superpixel representation and demonstrate superior performance when compared to supervoxel methods.</p><p>5 0.076150931 <a title="280-tfidf-5" href="./cvpr-2013-Fast_Energy_Minimization_Using_Learned_State_Filters.html">165 cvpr-2013-Fast Energy Minimization Using Learned State Filters</a></p>
<p>Author: Matthieu Guillaumin, Luc Van_Gool, Vittorio Ferrari</p><p>Abstract: Pairwise discrete energies defined over graphs are ubiquitous in computer vision. Many algorithms have been proposed to minimize such energies, often concentrating on sparse graph topologies or specialized classes of pairwise potentials. However, when the graph is fully connected and the pairwise potentials are arbitrary, the complexity of even approximate minimization algorithms such as TRW-S grows quadratically both in the number of nodes and in the number of states a node can take. Moreover, recent applications are using more and more computationally expensive pairwise potentials. These factors make it very hard to employ fully connected models. In this paper we propose a novel, generic algorithm to approximately minimize any discrete pairwise energy function. Our method exploits tractable sub-energies to filter the domain of the function. The parameters of the filter are learnt from instances of the same class of energies with good candidate solutions. Compared to existing methods, it efficiently handles fully connected graphs, with many states per node, and arbitrary pairwise potentials, which might be expensive to compute. We demonstrate experimentally on two applications that our algorithm is much more efficient than other generic minimization algorithms such as TRW-S, while returning essentially identical solutions.</p><p>6 0.071662523 <a title="280-tfidf-6" href="./cvpr-2013-Label_Propagation_from_ImageNet_to_3D_Point_Clouds.html">242 cvpr-2013-Label Propagation from ImageNet to 3D Point Clouds</a></p>
<p>7 0.069420509 <a title="280-tfidf-7" href="./cvpr-2013-Nonparametric_Scene_Parsing_with_Adaptive_Feature_Relevance_and_Semantic_Context.html">309 cvpr-2013-Nonparametric Scene Parsing with Adaptive Feature Relevance and Semantic Context</a></p>
<p>8 0.069162756 <a title="280-tfidf-8" href="./cvpr-2013-Robust_Monocular_Epipolar_Flow_Estimation.html">362 cvpr-2013-Robust Monocular Epipolar Flow Estimation</a></p>
<p>9 0.068888471 <a title="280-tfidf-9" href="./cvpr-2013-Weakly-Supervised_Dual_Clustering_for_Image_Semantic_Segmentation.html">460 cvpr-2013-Weakly-Supervised Dual Clustering for Image Semantic Segmentation</a></p>
<p>10 0.066333652 <a title="280-tfidf-10" href="./cvpr-2013-SCALPEL%3A_Segmentation_Cascades_with_Localized_Priors_and_Efficient_Learning.html">370 cvpr-2013-SCALPEL: Segmentation Cascades with Localized Priors and Efficient Learning</a></p>
<p>11 0.06559106 <a title="280-tfidf-11" href="./cvpr-2013-Video_Object_Segmentation_through_Spatially_Accurate_and_Temporally_Dense_Extraction_of_Primary_Object_Regions.html">455 cvpr-2013-Video Object Segmentation through Spatially Accurate and Temporally Dense Extraction of Primary Object Regions</a></p>
<p>12 0.063577786 <a title="280-tfidf-12" href="./cvpr-2013-Deformable_Spatial_Pyramid_Matching_for_Fast_Dense_Correspondences.html">107 cvpr-2013-Deformable Spatial Pyramid Matching for Fast Dense Correspondences</a></p>
<p>13 0.060444973 <a title="280-tfidf-13" href="./cvpr-2013-Probabilistic_Label_Trees_for_Efficient_Large_Scale_Image_Classification.html">340 cvpr-2013-Probabilistic Label Trees for Efficient Large Scale Image Classification</a></p>
<p>14 0.059458546 <a title="280-tfidf-14" href="./cvpr-2013-Saliency_Detection_via_Graph-Based_Manifold_Ranking.html">375 cvpr-2013-Saliency Detection via Graph-Based Manifold Ranking</a></p>
<p>15 0.057629012 <a title="280-tfidf-15" href="./cvpr-2013-Block_and_Group_Regularized_Sparse_Modeling_for_Dictionary_Learning.html">66 cvpr-2013-Block and Group Regularized Sparse Modeling for Dictionary Learning</a></p>
<p>16 0.057283312 <a title="280-tfidf-16" href="./cvpr-2013-Image_Segmentation_by_Cascaded_Region_Agglomeration.html">212 cvpr-2013-Image Segmentation by Cascaded Region Agglomeration</a></p>
<p>17 0.05286859 <a title="280-tfidf-17" href="./cvpr-2013-Multi-target_Tracking_by_Lagrangian_Relaxation_to_Min-cost_Network_Flow.html">300 cvpr-2013-Multi-target Tracking by Lagrangian Relaxation to Min-cost Network Flow</a></p>
<p>18 0.052250251 <a title="280-tfidf-18" href="./cvpr-2013-Revisiting_Depth_Layers_from_Occlusions.html">357 cvpr-2013-Revisiting Depth Layers from Occlusions</a></p>
<p>19 0.051874638 <a title="280-tfidf-19" href="./cvpr-2013-Robust_Region_Grouping_via_Internal_Patch_Statistics.html">366 cvpr-2013-Robust Region Grouping via Internal Patch Statistics</a></p>
<p>20 0.049766954 <a title="280-tfidf-20" href="./cvpr-2013-Graph-Based_Discriminative_Learning_for_Location_Recognition.html">189 cvpr-2013-Graph-Based Discriminative Learning for Location Recognition</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.12), (1, -0.003), (2, 0.025), (3, 0.012), (4, 0.059), (5, 0.002), (6, 0.032), (7, 0.018), (8, -0.061), (9, 0.01), (10, 0.067), (11, -0.01), (12, 0.006), (13, 0.026), (14, -0.013), (15, -0.023), (16, 0.027), (17, -0.035), (18, 0.015), (19, 0.046), (20, 0.04), (21, 0.011), (22, -0.051), (23, 0.004), (24, 0.006), (25, 0.0), (26, -0.011), (27, -0.025), (28, 0.035), (29, 0.079), (30, 0.022), (31, -0.022), (32, 0.06), (33, -0.055), (34, -0.002), (35, -0.016), (36, 0.015), (37, -0.01), (38, 0.071), (39, -0.024), (40, 0.049), (41, -0.019), (42, -0.052), (43, -0.033), (44, 0.032), (45, 0.022), (46, 0.01), (47, -0.049), (48, -0.004), (49, -0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.89992124 <a title="280-lsi-1" href="./cvpr-2013-Maximum_Cohesive_Grid_of_Superpixels_for_Fast_Object_Localization.html">280 cvpr-2013-Maximum Cohesive Grid of Superpixels for Fast Object Localization</a></p>
<p>Author: Liang Li, Wei Feng, Liang Wan, Jiawan Zhang</p><p>Abstract: This paper addresses a challenging problem of regularizing arbitrary superpixels into an optimal grid structure, which may significantly extend current low-level vision algorithms by allowing them to use superpixels (SPs) conveniently as using pixels. For this purpose, we aim at constructing maximum cohesive SP-grid, which is composed of real nodes, i.e. SPs, and dummy nodes that are meaningless in the image with only position-taking function in the grid. For a given formation of image SPs and proper number of dummy nodes, we first dynamically align them into a grid based on the centroid localities of SPs. We then define the SP-grid coherence as the sum of edge weights, with SP locality and appearance encoded, along all direct paths connecting any two nearest neighboring real nodes in the grid. We finally maximize the SP-grid coherence via cascade dynamic programming. Our approach can take the regional objectness as an optional constraint to produce more semantically reliable SP-grids. Experiments on object localization show that our approach outperforms state-of-the-art methods in terms of both detection accuracy and speed. We also find that with the same searching strategy and features, object localization at SP-level is about 100-500 times faster than pixel-level, with usually better detection accuracy.</p><p>2 0.79641104 <a title="280-lsi-2" href="./cvpr-2013-A_Statistical_Model_for_Recreational_Trails_in_Aerial_Images.html">26 cvpr-2013-A Statistical Model for Recreational Trails in Aerial Images</a></p>
<p>Author: Andrew Predoehl, Scott Morris, Kobus Barnard</p><p>Abstract: unkown-abstract</p><p>3 0.74408835 <a title="280-lsi-3" href="./cvpr-2013-A_Video_Representation_Using_Temporal_Superpixels.html">29 cvpr-2013-A Video Representation Using Temporal Superpixels</a></p>
<p>Author: Jason Chang, Donglai Wei, John W. Fisher_III</p><p>Abstract: We develop a generative probabilistic model for temporally consistent superpixels in video sequences. In contrast to supervoxel methods, object parts in different frames are tracked by the same temporal superpixel. We explicitly model flow between frames with a bilateral Gaussian process and use this information to propagate superpixels in an online fashion. We consider four novel metrics to quantify performance of a temporal superpixel representation and demonstrate superior performance when compared to supervoxel methods.</p><p>4 0.73746204 <a title="280-lsi-4" href="./cvpr-2013-Voxel_Cloud_Connectivity_Segmentation_-_Supervoxels_for_Point_Clouds.html">458 cvpr-2013-Voxel Cloud Connectivity Segmentation - Supervoxels for Point Clouds</a></p>
<p>Author: Jeremie Papon, Alexey Abramov, Markus Schoeler, Florentin Wörgötter</p><p>Abstract: Unsupervised over-segmentation of an image into regions of perceptually similar pixels, known as superpixels, is a widely used preprocessing step in segmentation algorithms. Superpixel methods reduce the number of regions that must be considered later by more computationally expensive algorithms, with a minimal loss of information. Nevertheless, as some information is inevitably lost, it is vital that superpixels not cross object boundaries, as such errors will propagate through later steps. Existing methods make use of projected color or depth information, but do not consider three dimensional geometric relationships between observed data points which can be used to prevent superpixels from crossing regions of empty space. We propose a novel over-segmentation algorithm which uses voxel relationships to produce over-segmentations which are fully consistent with the spatial geometry of the scene in three dimensional, rather than projective, space. Enforcing the constraint that segmented regions must have spatial connectivity prevents label flow across semantic object boundaries which might otherwise be violated. Additionally, as the algorithm works directly in 3D space, observations from several calibrated RGB+D cameras can be segmented jointly. Experiments on a large data set of human annotated RGB+D images demonstrate a significant reduction in occurrence of clusters crossing object boundaries, while maintaining speeds comparable to state-of-the-art 2D methods.</p><p>5 0.67852181 <a title="280-lsi-5" href="./cvpr-2013-Label_Propagation_from_ImageNet_to_3D_Point_Clouds.html">242 cvpr-2013-Label Propagation from ImageNet to 3D Point Clouds</a></p>
<p>Author: Yan Wang, Rongrong Ji, Shih-Fu Chang</p><p>Abstract: Recent years have witnessed a growing interest in understanding the semantics of point clouds in a wide variety of applications. However, point cloud labeling remains an open problem, due to the difficulty in acquiring sufficient 3D point labels towards training effective classifiers. In this paper, we overcome this challenge by utilizing the existing massive 2D semantic labeled datasets from decadelong community efforts, such as ImageNet and LabelMe, and a novel “cross-domain ” label propagation approach. Our proposed method consists of two major novel components, Exemplar SVM based label propagation, which effectively addresses the cross-domain issue, and a graphical model based contextual refinement incorporating 3D constraints. Most importantly, the entire process does not require any training data from the target scenes, also with good scalability towards large scale applications. We evaluate our approach on the well-known Cornell Point Cloud Dataset, achieving much greater efficiency and comparable accuracy even without any 3D training data. Our approach shows further major gains in accuracy when the training data from the target scenes is used, outperforming state-ofthe-art approaches with far better efficiency.</p><p>6 0.66799325 <a title="280-lsi-6" href="./cvpr-2013-Robust_Region_Grouping_via_Internal_Patch_Statistics.html">366 cvpr-2013-Robust Region Grouping via Internal Patch Statistics</a></p>
<p>7 0.6151796 <a title="280-lsi-7" href="./cvpr-2013-Weakly-Supervised_Dual_Clustering_for_Image_Semantic_Segmentation.html">460 cvpr-2013-Weakly-Supervised Dual Clustering for Image Semantic Segmentation</a></p>
<p>8 0.60282677 <a title="280-lsi-8" href="./cvpr-2013-Probabilistic_Graphlet_Cut%3A_Exploiting_Spatial_Structure_Cue_for_Weakly_Supervised_Image_Segmentation.html">339 cvpr-2013-Probabilistic Graphlet Cut: Exploiting Spatial Structure Cue for Weakly Supervised Image Segmentation</a></p>
<p>9 0.60047692 <a title="280-lsi-9" href="./cvpr-2013-Image_Segmentation_by_Cascaded_Region_Agglomeration.html">212 cvpr-2013-Image Segmentation by Cascaded Region Agglomeration</a></p>
<p>10 0.58758479 <a title="280-lsi-10" href="./cvpr-2013-A_Comparative_Study_of_Modern_Inference_Techniques_for_Discrete_Energy_Minimization_Problems.html">6 cvpr-2013-A Comparative Study of Modern Inference Techniques for Discrete Energy Minimization Problems</a></p>
<p>11 0.54928493 <a title="280-lsi-11" href="./cvpr-2013-Gauging_Association_Patterns_of_Chromosome_Territories_via_Chromatic_Median.html">184 cvpr-2013-Gauging Association Patterns of Chromosome Territories via Chromatic Median</a></p>
<p>12 0.54738241 <a title="280-lsi-12" href="./cvpr-2013-Deformable_Spatial_Pyramid_Matching_for_Fast_Dense_Correspondences.html">107 cvpr-2013-Deformable Spatial Pyramid Matching for Fast Dense Correspondences</a></p>
<p>13 0.52122062 <a title="280-lsi-13" href="./cvpr-2013-Improving_an_Object_Detector_and_Extracting_Regions_Using_Superpixels.html">217 cvpr-2013-Improving an Object Detector and Extracting Regions Using Superpixels</a></p>
<p>14 0.52073395 <a title="280-lsi-14" href="./cvpr-2013-Patch_Match_Filter%3A_Efficient_Edge-Aware_Filtering_Meets_Randomized_Search_for_Fast_Correspondence_Field_Estimation.html">326 cvpr-2013-Patch Match Filter: Efficient Edge-Aware Filtering Meets Randomized Search for Fast Correspondence Field Estimation</a></p>
<p>15 0.51873767 <a title="280-lsi-15" href="./cvpr-2013-Incorporating_User_Interaction_and_Topological_Constraints_within_Contour_Completion_via_Discrete_Calculus.html">222 cvpr-2013-Incorporating User Interaction and Topological Constraints within Contour Completion via Discrete Calculus</a></p>
<p>16 0.51541477 <a title="280-lsi-16" href="./cvpr-2013-Graph-Based_Optimization_with_Tubularity_Markov_Tree_for_3D_Vessel_Segmentation.html">190 cvpr-2013-Graph-Based Optimization with Tubularity Markov Tree for 3D Vessel Segmentation</a></p>
<p>17 0.51031059 <a title="280-lsi-17" href="./cvpr-2013-Reconstructing_Loopy_Curvilinear_Structures_Using_Integer_Programming.html">350 cvpr-2013-Reconstructing Loopy Curvilinear Structures Using Integer Programming</a></p>
<p>18 0.50862455 <a title="280-lsi-18" href="./cvpr-2013-Submodular_Salient_Region_Detection.html">418 cvpr-2013-Submodular Salient Region Detection</a></p>
<p>19 0.50858635 <a title="280-lsi-19" href="./cvpr-2013-SCALPEL%3A_Segmentation_Cascades_with_Localized_Priors_and_Efficient_Learning.html">370 cvpr-2013-SCALPEL: Segmentation Cascades with Localized Priors and Efficient Learning</a></p>
<p>20 0.49972504 <a title="280-lsi-20" href="./cvpr-2013-Graph_Matching_with_Anchor_Nodes%3A_A_Learning_Approach.html">192 cvpr-2013-Graph Matching with Anchor Nodes: A Learning Approach</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.097), (16, 0.022), (26, 0.453), (33, 0.2), (67, 0.039), (69, 0.037), (87, 0.059)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.82096952 <a title="280-lda-1" href="./cvpr-2013-Template-Based_Isometric_Deformable_3D_Reconstruction_with_Sampling-Based_Focal_Length_Self-Calibration.html">423 cvpr-2013-Template-Based Isometric Deformable 3D Reconstruction with Sampling-Based Focal Length Self-Calibration</a></p>
<p>Author: Adrien Bartoli, Toby Collins</p><p>Abstract: It has been shown that a surface deforming isometrically can be reconstructed from a single image and a template 3D shape. Methods from the literature solve this problem efficiently. However, they all assume that the camera model is calibrated, which drastically limits their applicability. We propose (i) a general variational framework that applies to (calibrated and uncalibrated) general camera models and (ii) self-calibrating 3D reconstruction algorithms for the weak-perspective and full-perspective camera models. In the former case, our algorithm returns the normal field and camera ’s scale factor. In the latter case, our algorithm returns the normal field, depth and camera ’s focal length. Our algorithms are the first to achieve deformable 3D reconstruction including camera self-calibration. They apply to much more general setups than existing methods. Experimental results on simulated and real data show that our algorithms give results with the same level of accuracy as existing methods (which use the true focal length) on perspective images, and correctly find the normal field on affine images for which the existing methods fail.</p><p>same-paper 2 0.80795974 <a title="280-lda-2" href="./cvpr-2013-Maximum_Cohesive_Grid_of_Superpixels_for_Fast_Object_Localization.html">280 cvpr-2013-Maximum Cohesive Grid of Superpixels for Fast Object Localization</a></p>
<p>Author: Liang Li, Wei Feng, Liang Wan, Jiawan Zhang</p><p>Abstract: This paper addresses a challenging problem of regularizing arbitrary superpixels into an optimal grid structure, which may significantly extend current low-level vision algorithms by allowing them to use superpixels (SPs) conveniently as using pixels. For this purpose, we aim at constructing maximum cohesive SP-grid, which is composed of real nodes, i.e. SPs, and dummy nodes that are meaningless in the image with only position-taking function in the grid. For a given formation of image SPs and proper number of dummy nodes, we first dynamically align them into a grid based on the centroid localities of SPs. We then define the SP-grid coherence as the sum of edge weights, with SP locality and appearance encoded, along all direct paths connecting any two nearest neighboring real nodes in the grid. We finally maximize the SP-grid coherence via cascade dynamic programming. Our approach can take the regional objectness as an optional constraint to produce more semantically reliable SP-grids. Experiments on object localization show that our approach outperforms state-of-the-art methods in terms of both detection accuracy and speed. We also find that with the same searching strategy and features, object localization at SP-level is about 100-500 times faster than pixel-level, with usually better detection accuracy.</p><p>3 0.79058748 <a title="280-lda-3" href="./cvpr-2013-Measures_and_Meta-Measures_for_the_Supervised_Evaluation_of_Image_Segmentation.html">281 cvpr-2013-Measures and Meta-Measures for the Supervised Evaluation of Image Segmentation</a></p>
<p>Author: Jordi Pont-Tuset, Ferran Marques</p><p>Abstract: This paper tackles the supervised evaluation of image segmentation algorithms. First, it surveys and structures the measures used to compare the segmentation results with a ground truth database; and proposes a new measure: the precision-recall for objects and parts. To compare the goodness of these measures, it defines three quantitative meta-measures involving six state of the art segmentation methods. The meta-measures consist in assuming some plausible hypotheses about the results and assessing how well each measure reflects these hypotheses. As a conclusion, this paper proposes the precision-recall curves for boundaries and for objects-and-parts as the tool of choice for the supervised evaluation of image segmentation. We make the datasets and code of all the measures publicly available.</p><p>4 0.76879209 <a title="280-lda-4" href="./cvpr-2013-Tracking_People_and_Their_Objects.html">440 cvpr-2013-Tracking People and Their Objects</a></p>
<p>Author: Tobias Baumgartner, Dennis Mitzel, Bastian Leibe</p><p>Abstract: Current pedestrian tracking approaches ignore important aspects of human behavior. Humans are not moving independently, but they closely interact with their environment, which includes not only other persons, but also different scene objects. Typical everyday scenarios include people moving in groups, pushing child strollers, or pulling luggage. In this paper, we propose a probabilistic approach for classifying such person-object interactions, associating objects to persons, and predicting how the interaction will most likely continue. Our approach relies on stereo depth information in order to track all scene objects in 3D, while simultaneously building up their 3D shape models. These models and their relative spatial arrangement are then fed into a probabilistic graphical model which jointly infers pairwise interactions and object classes. The inferred interactions can then be used to support tracking by recovering lost object tracks. We evaluate our approach on a novel dataset containing more than 15,000 frames of personobject interactions in 325 video sequences and demonstrate good performance in challenging real-world scenarios.</p><p>5 0.74296772 <a title="280-lda-5" href="./cvpr-2013-Exemplar-Based_Face_Parsing.html">152 cvpr-2013-Exemplar-Based Face Parsing</a></p>
<p>Author: Brandon M. Smith, Li Zhang, Jonathan Brandt, Zhe Lin, Jianchao Yang</p><p>Abstract: In this work, we propose an exemplar-based face image segmentation algorithm. We take inspiration from previous works on image parsing for general scenes. Our approach assumes a database of exemplar face images, each of which is associated with a hand-labeled segmentation map. Given a test image, our algorithm first selects a subset of exemplar images from the database, Our algorithm then computes a nonrigid warp for each exemplar image to align it with the test image. Finally, we propagate labels from the exemplar images to the test image in a pixel-wise manner, using trained weights to modulate and combine label maps from different exemplars. We evaluate our method on two challenging datasets and compare with two face parsing algorithms and a general scene parsing algorithm. We also compare our segmentation results with contour-based face alignment results; that is, we first run the alignment algorithms to extract contour points and then derive segments from the contours. Our algorithm compares favorably with all previous works on all datasets evaluated.</p><p>6 0.71229309 <a title="280-lda-6" href="./cvpr-2013-Occlusion_Patterns_for_Object_Class_Detection.html">311 cvpr-2013-Occlusion Patterns for Object Class Detection</a></p>
<p>7 0.66019827 <a title="280-lda-7" href="./cvpr-2013-Relative_Hidden_Markov_Models_for_Evaluating_Motion_Skill.html">353 cvpr-2013-Relative Hidden Markov Models for Evaluating Motion Skill</a></p>
<p>8 0.658948 <a title="280-lda-8" href="./cvpr-2013-Compressible_Motion_Fields.html">88 cvpr-2013-Compressible Motion Fields</a></p>
<p>9 0.62073088 <a title="280-lda-9" href="./cvpr-2013-A_New_Perspective_on_Uncalibrated_Photometric_Stereo.html">21 cvpr-2013-A New Perspective on Uncalibrated Photometric Stereo</a></p>
<p>10 0.60151595 <a title="280-lda-10" href="./cvpr-2013-What_Object_Motion_Reveals_about_Shape_with_Unknown_BRDF_and_Lighting.html">465 cvpr-2013-What Object Motion Reveals about Shape with Unknown BRDF and Lighting</a></p>
<p>11 0.58768207 <a title="280-lda-11" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<p>12 0.58408809 <a title="280-lda-12" href="./cvpr-2013-Physically_Plausible_3D_Scene_Tracking%3A_The_Single_Actor_Hypothesis.html">331 cvpr-2013-Physically Plausible 3D Scene Tracking: The Single Actor Hypothesis</a></p>
<p>13 0.57588851 <a title="280-lda-13" href="./cvpr-2013-Templateless_Quasi-rigid_Shape_Modeling_with_Implicit_Loop-Closure.html">424 cvpr-2013-Templateless Quasi-rigid Shape Modeling with Implicit Loop-Closure</a></p>
<p>14 0.57562286 <a title="280-lda-14" href="./cvpr-2013-Hyperbolic_Harmonic_Mapping_for_Constrained_Brain_Surface_Registration.html">208 cvpr-2013-Hyperbolic Harmonic Mapping for Constrained Brain Surface Registration</a></p>
<p>15 0.57434165 <a title="280-lda-15" href="./cvpr-2013-Correlation_Filters_for_Object_Alignment.html">96 cvpr-2013-Correlation Filters for Object Alignment</a></p>
<p>16 0.57258755 <a title="280-lda-16" href="./cvpr-2013-Optimal_Geometric_Fitting_under_the_Truncated_L2-Norm.html">317 cvpr-2013-Optimal Geometric Fitting under the Truncated L2-Norm</a></p>
<p>17 0.57254422 <a title="280-lda-17" href="./cvpr-2013-Sparse_Subspace_Denoising_for_Image_Manifolds.html">405 cvpr-2013-Sparse Subspace Denoising for Image Manifolds</a></p>
<p>18 0.57154411 <a title="280-lda-18" href="./cvpr-2013-Robust_Canonical_Time_Warping_for_the_Alignment_of_Grossly_Corrupted_Sequences.html">358 cvpr-2013-Robust Canonical Time Warping for the Alignment of Grossly Corrupted Sequences</a></p>
<p>19 0.56998956 <a title="280-lda-19" href="./cvpr-2013-The_Generalized_Laplacian_Distance_and_Its_Applications_for_Visual_Matching.html">429 cvpr-2013-The Generalized Laplacian Distance and Its Applications for Visual Matching</a></p>
<p>20 0.56960237 <a title="280-lda-20" href="./cvpr-2013-3D_Visual_Proxemics%3A_Recognizing_Human_Interactions_in_3D_from_a_Single_Image.html">4 cvpr-2013-3D Visual Proxemics: Recognizing Human Interactions in 3D from a Single Image</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
