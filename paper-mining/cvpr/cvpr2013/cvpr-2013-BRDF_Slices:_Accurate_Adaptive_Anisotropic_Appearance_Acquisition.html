<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>54 cvpr-2013-BRDF Slices: Accurate Adaptive Anisotropic Appearance Acquisition</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-54" href="#">cvpr2013-54</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>54 cvpr-2013-BRDF Slices: Accurate Adaptive Anisotropic Appearance Acquisition</h1>
<br/><p>Source: <a title="cvpr-2013-54-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Filip_BRDF_Slices_Accurate_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Jirí Filip, Radomír Vávra, Michal Haindl, Pavel Žid, Mikuláš Krupika, Vlastimil Havran</p><p>Abstract: In this paper we introduce unique publicly available dense anisotropic BRDF data measurements. We use this dense data as a reference for performance evaluation of the proposed BRDF sparse angular sampling and interpolation approach. The method is based on sampling of BRDF subspaces at fixed elevations by means of several adaptively-represented, uniformly distributed, perpendicular slices. Although this proposed method requires only a sparse sampling of material, the interpolation provides a very accurate reconstruction, visually and computationally comparable to densely measured reference. Due to the simple slices measurement and method’s robustness it allows for a highly accurate acquisition of BRDFs. This in comparison with standard uniform angular sampling, is considerably faster yet uses far less samples.</p><p>Reference: <a title="cvpr-2013-54-reference" href="../cvpr2013_reference/cvpr-2013-BRDF_Slices%3A_Accurate_Adaptive_Anisotropic_Appearance_Acquisition_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 We use this dense data as a reference for performance evaluation of the proposed BRDF sparse angular sampling and interpolation approach. [sent-6, score-0.506]
</p><p>2 The method is based on sampling of BRDF subspaces at fixed elevations by means of several adaptively-represented, uniformly distributed, perpendicular slices. [sent-7, score-0.466]
</p><p>3 Although this proposed method requires only a sparse sampling of material, the interpolation provides a very accurate reconstruction, visually and computationally comparable to densely measured reference. [sent-8, score-0.564]
</p><p>4 Due to the simple slices measurement and method’s robustness it allows for a highly accurate acquisition of BRDFs. [sent-9, score-0.577]
</p><p>5 Introduction Accurate acquisition and representation of real-world materials’ appearance is of an ultimate challenge in computer vision and graphics. [sent-12, score-0.204]
</p><p>6 A directional properties of material reflectance was formalized by Nicodemus et al. [sent-14, score-0.19]
</p><p>7 measurement setup is introduced and its very dense BRDF measurements are analyzed. [sent-19, score-0.265]
</p><p>8 Additionally, we introduce a novel adaptive method of highly accurate interpolation of sparsely measured BRDF and have made measured data publicly available for research purposes. [sent-20, score-0.577]
</p><p>9 Related Work Based on the way the four degrees of mechanical free-  dom are realized, BRDF acquisition setups can be divided into three categories. [sent-22, score-0.251]
</p><p>10 The first is based on gonioreflectometers where all combinations of illumination and viewing directions are achieved by the sequential mutual positioning of light, sensor, and sample [7, 8]. [sent-23, score-0.275]
</p><p>11 The last two categories have either compromised accuracy, as well as limitations in the effective range of elevation angles, or require certain geometry of the sample making the measurement procedure more efficient. [sent-27, score-0.225]
</p><p>12 Although four anisotropic BRDFs have been made available for research purposes [14], their minimal azimuthal sampling step is 2o only and the resulting data are extremely noisy. [sent-28, score-0.6]
</p><p>13 Therefore, we introduce a novel gonioreflectometerbased acquisition setup for measurement of anisotropic BRDF with unique angular density and accuracy. [sent-29, score-0.497]
</p><p>14 Such precise measurement data are then used as reference data for the proposed interpolation algorithm evaluation. [sent-30, score-0.365]
</p><p>15 General methods of adaptive sampling [18] have been extensively studied. [sent-31, score-0.273]
</p><p>16 Their application to adaptive illumination sampling was investigated in [3]. [sent-32, score-0.33]
</p><p>17 How111444666866  ever, these approaches assume prior knowledge of the entire data, while we use only a sparse adaptive sampling of unknown reflectance data constrained by a typical BRDF behavior, i. [sent-36, score-0.432]
</p><p>18 To date, we are not aware of any literature on a sparse adaptive acquisition of unknown 4D BRDFs. [sent-39, score-0.338]
</p><p>19 Our work is motivated by the method of Filip and V a´vra [2], using a sparse set of azimuthal slices placed orthogonally to main reflectance features in BRDF space. [sent-40, score-0.741]
</p><p>20 These slices allow for an efficient and robust reconstruction. [sent-41, score-0.279]
</p><p>21 Measurement Setup All the measurements were done using the gonioreflectometer shown in Fig. [sent-43, score-0.16]
</p><p>22 Mechanical Construction The setup consists of the measured sample held by a rotating stage and two independently controlled arms with camera (one axis) and light (two axes) as shown in Fig. [sent-45, score-0.394]
</p><p>23 It allows for flexible and adaptive measurements of nearly arbitrary combinations of illumination and viewing directions. [sent-47, score-0.293]
</p><p>24 Although camera view occlusion by arm with light may occur, it can be analytically detected, and in most cases alternative positioning is possible. [sent-48, score-0.16]
</p><p>25 Verified illumination and camera arms positioning angular accuracy across all axes is ±0. [sent-49, score-0.298]
</p><p>26 HDR acquisition is achieved by adaptive exposure times and variable lighting intensity (through current being fed into LEDs); both of this is controlled remotely depending on the dynamic range of the measured sample. [sent-56, score-0.487]
</p><p>27 ing – Zero initial positions of all axes were found using a spirit level, plummet, and device’s axes intersection, etc. [sent-67, score-0.16]
</p><p>28 Lighting nonuniformity over the target area was measured using a luxmeter, fitted by a 2D polynomial, and compensated from the photos. [sent-68, score-0.17]
</p><p>29 The control application stores the list of the required measured positions, which can be adaptively modified during measurement. [sent-75, score-0.18]
</p><p>30 Uniform Sampling Evaluation View- and illumination-dependent reflectance properties of materials are often measured uniformly over a hemisphere. [sent-79, score-0.356]
</p><p>31 As examples can serve 81 81 directions sampling (656A1 samples) [s1 c7]a or 1er5v v1e e× 8151 1× d81ire cditrieoncsti sampling (p2li2n8g01 (6 samples) [l1es3)]. [sent-80, score-0.373]
</p><p>32 [ Unfortunately, even tsuiocnhs relatively dense sampling is insufficient to accurately capture important reflectance behavior. [sent-81, score-0.294]
</p><p>33 3 compares visualization quality of five materials when the ground truth data and uniform sampling 15 1 151 directions are used. [sent-83, score-0.403]
</p><p>34 Then all these directions were measured using the gonioreflectometer and visualized. [sent-86, score-0.281]
</p><p>35 As expected, even with a high number of uniform samples the differences are significant, especially for specular materials. [sent-87, score-0.234]
</p><p>36 A comparison of BRDF visualization on a sphere: measured 10975 exact directions in each pixel (the first row) vs. [sent-105, score-0.25]
</p><p>37 uniformly measured and interpolated 15 1 151 directions (the second  ×× ××  row). [sent-106, score-0.395]
</p><p>38 view- and illumination-dependent material appearance sampling to achieve better reconstruction precision using less samples. [sent-109, score-0.318]
</p><p>39 T yheearres)fore, we focused first on a dense measurement of BRDF subspace for fixed elevations of a single but challenging material. [sent-112, score-0.413]
</p><p>40 Our goal is to investigate the adaptive sparse sampling algorithm which can represent appearance of this subspace very precisely using a reasonable number of samples. [sent-113, score-0.46]
</p><p>41 This material provides an intricate golden appearance with a strong anisotropic behavior as shown in example images of various illumination and viewing conditions in the second row of Fig. [sent-116, score-0.349]
</p><p>42 When the material’s BRDF was measured uniformly in 81 81 and 151 15 1 sampling, we obtained the result ill8u1s×tra8t1ed a nind 1th5e1 ×fir1s5t1 row opfl Fig. [sent-118, score-0.195]
</p><p>43 Visualization of this BRDF on a  ×× ×× ×  sphere for 151 151 sampling is shown in the second row sopf Fig. [sent-121, score-0.222]
</p><p>44 In the further experiment we selected BRDF subspace at the highest elevation angles exhibiting the strongest anisotropic behavior, i. [sent-124, score-0.364]
</p><p>45 Figure 5 compares the reference subspace measurement (left) with two 4096 DPI scan 81 81 directions 151 151 dir. [sent-128, score-0.364]
</p><p>46 Thefirstrow:Highresolutionscanofthefabricmate-  rial (left), its uniformly measured BRDF: in 81 81 (middle) and r1ia5 1l e1f5t1), (right) odrirmecltyio mnse. [sent-130, score-0.195]
</p><p>47 Densely measured reference data with samples’ distance Δϕ = 0. [sent-138, score-0.197]
</p><p>48 The middle image corresponds to sampling 81 8 1and 15 1 15 1. [sent-141, score-0.196]
</p><p>49 The reference data are densely measured using azimuthal sampling step ≈ Δϕ = 2o using 11856 samples and interpoplalitendg in stteop a ≈res Δolϕuti =on 2Δϕ = 0. [sent-143, score-0.807]
</p><p>50 The subspace measured using 24 azimuthal samples (step Δϕ = 15o) contains n = (360o/15o)2 = 576 samples (middle), and the subspace measured using 48 azimuthal samples (Δϕ = 7. [sent-145, score-1.434]
</p><p>51 Performance of a barycentric interpolation of these uniform samples into reference data resolution (Δϕ = 0. [sent-148, score-0.5]
</p><p>52 These results prove unsatisfactory performance ofthe uniform acquisition approaches. [sent-151, score-0.269]
</p><p>53 The slice aligned with the direction of specular highlights is called axial slice 111444667088  Figure6. [sent-155, score-0.363]
</p><p>54 The axial slice rec−or ϕds the material’s anisotropic properties (mutual azimuthal position of the light and camera is fixed while the sample rotates), i. [sent-160, score-0.743]
</p><p>55 The slice perpendicular to the highlights is called diagonal slice sD (blue), i. [sent-163, score-0.35]
</p><p>56 The diagonal slice captures the shape of the specular peaks (light and camera travel in mutually opposite azimuthal directions over the sample). [sent-166, score-0.6]
</p><p>57 Both slices can be expressed as sA  (ϕv) = BRDF(θi, ϕi = ϕv ,θv ,β (ϕv) = BRDF(θi , ϕi = 2π  sA,θi,θv,α  − α,  sD,θi  − ϕv  θv, ϕv), (1) + β, θv , ϕv) . [sent-167, score-0.279]
</p><p>58 While [2] focuses on approximative subspace reconstruction using two slices only, we attempt for very accurate reconstruction of the subspace using the set of 12 axial and 12 diagonal slices. [sent-168, score-0.75]
</p><p>59 The slices’ placement is realized uniformly across the subspace in azimuthal step 30o. [sent-169, score-0.548]
</p><p>60 Such a placement divides the subspace image into a grid of rectangles (see Fig. [sent-170, score-0.156]
</p><p>61 The slices values are adaptively measured; however, the remaining data has to be interpolated. [sent-172, score-0.347]
</p><p>62 1 explains method of adaptive sampling along slices and Section 6. [sent-174, score-0.552]
</p><p>63 2 describes method of slices values propagation to missing parts of the BRDF subspace. [sent-175, score-0.304]
</p><p>64 Adaptive Slice Sampling Each slice can be interpreted as a one dimensional periodic signal with period 360o. [sent-178, score-0.159]
</p><p>65 , 1o) or adaptively decreasing a number of samples on the one hand and increasing reconstruction accuracy in areas with high variance on the other. [sent-181, score-0.213]
</p><p>66 As the behavior of the signal is unknown, the adaptive algorithm can work with already measured samples only; adding new samples in areas where it can improve reconstructed signal accuracy. [sent-182, score-0.588]
</p><p>67 We assume that all the previously taken samples are sorted by their angle ϕv and labeled by indices from 1 to n, when n is a count of samples al-  ×  ready taken. [sent-188, score-0.24]
</p><p>68 , n}, draw a line through samples wk −ake1 asandm pkl +e k k1 ∈an {d1 compare ,l dinrae wva alu lein u tihn position mofp tlehse sample kd w ki t+h t1h aen sample’s rvea l uinee v. [sent-192, score-0.18]
</p><p>69 , 10%) in any color channel, mark position s−in the middle of sample k −1 and k and position s+ in the middle mofi sample ska amnpdl ek k k+− −11 as cdan kd ainddate pso sfiotrio a new sample. [sent-195, score-0.206]
</p><p>70 When all the candidate positions of new samples are known, they can be measured and we can search for new candidate positions again. [sent-198, score-0.299]
</p><p>71 Algorithm stops when there are no candidate positions (due to a limited signal rate of innovation or measurement resolution) or after a defined number of iterations. [sent-199, score-0.189]
</p><p>72 density every point on the slice can be interpolated very precisely, using e. [sent-205, score-0.254]
</p><p>73 interpolation requires knowledge of values of eight points to interpolate desired value rxy at (x, y) inside the rectangle. [sent-215, score-0.314]
</p><p>74 q0y  and  q1y  are on  111444667199  First, values px0 and px1 are linearly interpolated along axis y yielding value pxy pxy (1 − y) ∗ px0 y ∗ px1  =  +  . [sent-219, score-0.455]
</p><p>75 To compute value rxy, the value pxy has to be compensated for a height difference introduced by a linear interpolation and values of the diagonal slices. [sent-220, score-0.414]
</p><p>76 Therefore, values c0y and c1y are also linearly interpolated along axis y from c00, c01 and c10, c11 respectively c0y (1 − y) ∗ c00 y ∗ c01 c1y (1 − y) ∗ c10 y ∗ c11  = =  + +  ,. [sent-221, score-0.193]
</p><p>77 The differences d0y and d1y between the linear interpolations of the corner values and values of the x-aligned slices are computed as d0y = q0y − c0y and d1y = q1y − c1y. [sent-222, score-0.387]
</p><p>78 Finally, the height difference i−n cthe point (x, y) is ob−tai cned with a linear interpolation of the differences in the axis x dxy = (1 − x) ∗ d0y + x ∗ d1y . [sent-223, score-0.287]
</p><p>79 The final value rxy is a sum of the value pxy and the difference dxy and its minimal value is constrained by a minimal value of px0, px1, q0y and q1y rxy  =  max(pxy  + dxy, min(px0,px1,  q0y, q1y))  . [sent-224, score-0.465]
</p><p>80 ××  It can be proven that changing x, y axes interpolation order yields the same result. [sent-226, score-0.25]
</p><p>81 Results  This section compares performance of the proposed interpolation method with uniform sampling using the same samples count. [sent-228, score-0.536]
</p><p>82 However, the selected sample has the strongest anisotropic behavior we have seen so far. [sent-230, score-0.237]
</p><p>83 10 shows densely measured reference BRDF subspace (a), uniform sampling by means of 81 81 (b) and 151 15 1 (d) interpolated to the same azi8m1×uth8a1l rbe)so alnudtio 1n5 as 1th5e1 r (edfe)r ienntceerp using a barycentric aizn-terpolation. [sent-232, score-0.801]
</p><p>84 10 (c) and (e) shows performance of the proposed interpolation method in suggested representation using 12 axial and 12 diagonal slices (f). [sent-234, score-0.57]
</p><p>85 1 T0h) ef 1ro0m× th scea rleedfe driefnfceere ndaceta i smhaogwe st (haset eth see proposed parameterization and interpolation is able to achieve significantly better reconstruction of the original data using the same number of samples. [sent-238, score-0.274]
</p><p>86 As the reconstruction of a single BRDF subspace is insufficient for any appearance visualization we measured eight additional subspaces at elevations 0o, 30o, 75o and  ××  their combinations. [sent-239, score-0.6]
</p><p>87 These measurements were obtained using 6561 samples and their reconstructions using the proposed method are shown in Fig. [sent-240, score-0.187]
</p><p>88 Furthermore, we interpolated data at missing elevations using a four-dimensional Krig interpolation of spherical angles (θi, ϕi, θv , ϕv) represented in a 0 ≈ 2π azimuthal continuity preserving )d rireepcrteiosnenalte parameterization m[6u]t. [sent-242, score-0.84]
</p><p>89 9shows a comparison of ground truth measurements on sphere (a), with rendering using barycentrically interpolated 81 81 (b) and 151 15 1 (c) uniform samples. [sent-244, score-0.467]
</p><p>90 The result 8o1f ×th8e1 proposed d5a1ta× acquisition aonrdm interpolation me erethsuodlt using 6561 adaptive samples is shown in (d). [sent-245, score-0.586]
</p><p>91 Per-pixel ground truth measurements on a sphere (a) compared with barycentrically interpolated uniform measurements (b), (c) and with the proposed interpolation from sparse measurements (d). [sent-256, score-0.816]
</p><p>92 although the reconstruction quality gain might look small, we believe that it can be considerably improved by the proposed adaptive measurement at additional elevations, i. [sent-259, score-0.304]
</p><p>93 The reconstruction of the BRDF subspace (720×720 pixels) adaptively dtiisotnrib oufte tdhe ein B B2R4 DslFice ssu tbaskpeasc typically 712-20 seconds regardless the sample count at Intel Xeon 2. [sent-262, score-0.301]
</p><p>94 Note that the measured sparse BRDF as well as its densely sampled subspaces are publicly available for research purposes in UTIA BTF Database [5]. [sent-264, score-0.281]
</p><p>95 Conclusions We presented a sparse BRDF data representation and interpolation methods that outperform in reconstruction quality uniform sampling using the same count of samples. [sent-266, score-0.564]
</p><p>96 The proposed sliced parametrization allows for fast, continuous acquisition at fixed elevations of camera and light, and fast, robust reconstruction of non-measured values at arbitrary resolution. [sent-267, score-0.481]
</p><p>97 The methods accuracy is given by a used number of slices and their adaptive sampling density specified 111444777200  (a) reference 518 400 samples  (b) uniform sampl. [sent-268, score-0.81]
</p><p>98 We believe that the proposed data-driven sampling together with the robust reconstruction performance represents an initial framework for intelligent adaptive sampling methods of view- and illuminationdependent material appearance. [sent-298, score-0.564]
</p><p>99 Fast method of sparse acquisition and reconstruction of view and illumination dependent datasets. [sent-307, score-0.34]
</p><p>100 A coaxial optical scanner for synchronous acquisition of 3D geometry and surface reflectance. [sent-346, score-0.177]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('brdf', 0.496), ('azimuthal', 0.303), ('slices', 0.279), ('interpolation', 0.184), ('acquisition', 0.177), ('sampling', 0.154), ('elevations', 0.151), ('measured', 0.137), ('interpolated', 0.135), ('pxy', 0.131), ('measurement', 0.121), ('slice', 0.119), ('adaptive', 0.119), ('subspace', 0.118), ('reflectance', 0.117), ('anisotropic', 0.116), ('samples', 0.106), ('filip', 0.105), ('rxy', 0.105), ('psnr', 0.097), ('rmse', 0.096), ('uniform', 0.092), ('measurements', 0.081), ('gonioreflectometer', 0.079), ('material', 0.073), ('dpi', 0.07), ('dxy', 0.07), ('positioning', 0.069), ('sphere', 0.068), ('axes', 0.066), ('axial', 0.066), ('directions', 0.065), ('reconstruction', 0.064), ('reference', 0.06), ('barycentric', 0.058), ('interpolations', 0.058), ('uniformly', 0.058), ('illumination', 0.057), ('optics', 0.057), ('elevation', 0.056), ('light', 0.055), ('subspaces', 0.055), ('barycentrically', 0.052), ('havran', 0.052), ('nicodemus', 0.052), ('visualization', 0.048), ('sample', 0.048), ('perpendicular', 0.048), ('densely', 0.047), ('azimuths', 0.047), ('mechanical', 0.045), ('materials', 0.044), ('eurographics', 0.044), ('adaptively', 0.043), ('bidirectional', 0.043), ('hdr', 0.043), ('angular', 0.043), ('middle', 0.042), ('sparse', 0.042), ('diagonal', 0.041), ('angles', 0.041), ('setup', 0.04), ('behavior', 0.04), ('signal', 0.04), ('rendering', 0.039), ('placement', 0.038), ('prague', 0.037), ('specular', 0.036), ('czech', 0.036), ('efr', 0.036), ('camera', 0.036), ('viewing', 0.036), ('cie', 0.035), ('axis', 0.033), ('compression', 0.033), ('compensated', 0.033), ('tim', 0.033), ('strongest', 0.033), ('symposium', 0.032), ('lawrence', 0.031), ('realized', 0.031), ('setups', 0.029), ('count', 0.028), ('parametrization', 0.028), ('exposure', 0.028), ('positions', 0.028), ('appearance', 0.027), ('arms', 0.027), ('minimal', 0.027), ('device', 0.027), ('kd', 0.026), ('parameterization', 0.026), ('controlled', 0.026), ('values', 0.025), ('db', 0.025), ('rotating', 0.025), ('dense', 0.023), ('densities', 0.023), ('highlights', 0.023), ('cma', 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999875 <a title="54-tfidf-1" href="./cvpr-2013-BRDF_Slices%3A_Accurate_Adaptive_Anisotropic_Appearance_Acquisition.html">54 cvpr-2013-BRDF Slices: Accurate Adaptive Anisotropic Appearance Acquisition</a></p>
<p>Author: Jirí Filip, Radomír Vávra, Michal Haindl, Pavel Žid, Mikuláš Krupika, Vlastimil Havran</p><p>Abstract: In this paper we introduce unique publicly available dense anisotropic BRDF data measurements. We use this dense data as a reference for performance evaluation of the proposed BRDF sparse angular sampling and interpolation approach. The method is based on sampling of BRDF subspaces at fixed elevations by means of several adaptively-represented, uniformly distributed, perpendicular slices. Although this proposed method requires only a sparse sampling of material, the interpolation provides a very accurate reconstruction, visually and computationally comparable to densely measured reference. Due to the simple slices measurement and method’s robustness it allows for a highly accurate acquisition of BRDFs. This in comparison with standard uniform angular sampling, is considerably faster yet uses far less samples.</p><p>2 0.40830645 <a title="54-tfidf-2" href="./cvpr-2013-Calibrating_Photometric_Stereo_by_Holistic_Reflectance_Symmetry_Analysis.html">75 cvpr-2013-Calibrating Photometric Stereo by Holistic Reflectance Symmetry Analysis</a></p>
<p>Author: Zhe Wu, Ping Tan</p><p>Abstract: Under unknown directional lighting, the uncalibrated Lambertian photometric stereo algorithm recovers the shape of a smooth surface up to the generalized bas-relief (GBR) ambiguity. We resolve this ambiguity from the halfvector symmetry, which is observed in many isotropic materials. Under this symmetry, a 2D BRDF slice with low-rank structure can be obtained from an image, if the surface normals and light directions are correctly recovered. In general, this structure is destroyed by the GBR ambiguity. As a result, we can resolve the ambiguity by restoring this structure. We develop a simple algorithm of auto-calibration from separable homogeneous specular reflection of real images. Compared with previous methods, this method takes a holistic approach to exploiting reflectance symmetry and produces superior results.</p><p>3 0.34332025 <a title="54-tfidf-3" href="./cvpr-2013-What_Object_Motion_Reveals_about_Shape_with_Unknown_BRDF_and_Lighting.html">465 cvpr-2013-What Object Motion Reveals about Shape with Unknown BRDF and Lighting</a></p>
<p>Author: Manmohan Chandraker, Dikpal Reddy, Yizhou Wang, Ravi Ramamoorthi</p><p>Abstract: We present a theory that addresses the problem of determining shape from the (small or differential) motion of an object with unknown isotropic reflectance, under arbitrary unknown distant illumination, , for both orthographic and perpsective projection. Our theory imposes fundamental limits on the hardness of surface reconstruction, independent of the method involved. Under orthographic projection, we prove that three differential motions suffice to yield an invariant that relates shape to image derivatives, regardless of BRDF and illumination. Under perspective projection, we show that four differential motions suffice to yield depth and a linear constraint on the surface gradient, with unknown BRDF and lighting. Further, we delineate the topological classes up to which reconstruction may be achieved using the invariants. Finally, we derive a general stratification that relates hardness of shape recovery to scene complexity. Qualitatively, our invariants are homogeneous partial differential equations for simple lighting and inhomogeneous for complex illumination. Quantitatively, our framework shows that the minimal number of motions required to resolve shape is greater for more complex scenes. Prior works that assume brightness constancy, Lambertian BRDF or a known directional light source follow as special cases of our stratification. We illustrate with synthetic and real data how potential reconstruction methods may exploit our framework.</p><p>4 0.2907083 <a title="54-tfidf-4" href="./cvpr-2013-Multi-view_Photometric_Stereo_with_Spatially_Varying_Isotropic_Materials.html">303 cvpr-2013-Multi-view Photometric Stereo with Spatially Varying Isotropic Materials</a></p>
<p>Author: Zhenglong Zhou, Zhe Wu, Ping Tan</p><p>Abstract: We present a method to capture both 3D shape and spatially varying reflectance with a multi-view photometric stereo technique that works for general isotropic materials. Our data capture setup is simple, which consists of only a digital camera and a handheld light source. From a single viewpoint, we use a set of photometric stereo images to identify surface points with the same distance to the camera. We collect this information from multiple viewpoints and combine it with structure-from-motion to obtain a precise reconstruction of the complete 3D shape. The spatially varying isotropic bidirectional reflectance distributionfunction (BRDF) is captured by simultaneously inferring a set of basis BRDFs and their mixing weights at each surface point. According to our experiments, the captured shapes are accurate to 0.3 millimeters. The captured reflectance has relative root-mean-square error (RMSE) of 9%.</p><p>5 0.2111468 <a title="54-tfidf-5" href="./cvpr-2013-Learning_Discriminative_Illumination_and_Filters_for_Raw_Material_Classification_with_Optimal_Projections_of_Bidirectional_Texture_Functions.html">251 cvpr-2013-Learning Discriminative Illumination and Filters for Raw Material Classification with Optimal Projections of Bidirectional Texture Functions</a></p>
<p>Author: Chao Liu, Geifei Yang, Jinwei Gu</p><p>Abstract: We present a computational imaging method for raw material classification using features of Bidirectional Texture Functions (BTF). Texture is an intrinsic feature for many materials, such as wood, fabric, and granite. At appropriate scales, even “uniform” materials will also exhibit texture features that can be helpful for recognition, such as paper, metal, and ceramic. To cope with the high-dimensionality of BTFs, in this paper, we proposed to learn discriminative illumination patterns and texture filters, with which we can directly measure optimal projections of BTFs for classification. We also studied the effects of texture rotation and scale variation for material classification. We built an LED-based multispectral dome, with which we have acquired a BTF database of a variety of materials and demonstrated the effectiveness of the proposed approach for material classification.</p><p>6 0.15501684 <a title="54-tfidf-6" href="./cvpr-2013-Analytic_Bilinear_Appearance_Subspace_Construction_for_Modeling_Image_Irradiance_under_Natural_Illumination_and_Non-Lambertian_Reflectance.html">42 cvpr-2013-Analytic Bilinear Appearance Subspace Construction for Modeling Image Irradiance under Natural Illumination and Non-Lambertian Reflectance</a></p>
<p>7 0.12290241 <a title="54-tfidf-7" href="./cvpr-2013-Uncalibrated_Photometric_Stereo_for_Unknown_Isotropic_Reflectances.html">443 cvpr-2013-Uncalibrated Photometric Stereo for Unknown Isotropic Reflectances</a></p>
<p>8 0.10248197 <a title="54-tfidf-8" href="./cvpr-2013-Sampling_Strategies_for_Real-Time_Action_Recognition.html">378 cvpr-2013-Sampling Strategies for Real-Time Action Recognition</a></p>
<p>9 0.10029266 <a title="54-tfidf-9" href="./cvpr-2013-Improved_Image_Set_Classification_via_Joint_Sparse_Approximated_Nearest_Subspaces.html">215 cvpr-2013-Improved Image Set Classification via Joint Sparse Approximated Nearest Subspaces</a></p>
<p>10 0.099678315 <a title="54-tfidf-10" href="./cvpr-2013-Adaptive_Compressed_Tomography_Sensing.html">35 cvpr-2013-Adaptive Compressed Tomography Sensing</a></p>
<p>11 0.089981005 <a title="54-tfidf-11" href="./cvpr-2013-Efficient_3D_Endfiring_TRUS_Prostate_Segmentation_with_Globally_Optimized_Rotational_Symmetry.html">139 cvpr-2013-Efficient 3D Endfiring TRUS Prostate Segmentation with Globally Optimized Rotational Symmetry</a></p>
<p>12 0.082924485 <a title="54-tfidf-12" href="./cvpr-2013-Single_Image_Calibration_of_Multi-axial_Imaging_Systems.html">400 cvpr-2013-Single Image Calibration of Multi-axial Imaging Systems</a></p>
<p>13 0.080899708 <a title="54-tfidf-13" href="./cvpr-2013-Discriminative_Subspace_Clustering.html">135 cvpr-2013-Discriminative Subspace Clustering</a></p>
<p>14 0.072129957 <a title="54-tfidf-14" href="./cvpr-2013-Spectral_Modeling_and_Relighting_of_Reflective-Fluorescent_Scenes.html">409 cvpr-2013-Spectral Modeling and Relighting of Reflective-Fluorescent Scenes</a></p>
<p>15 0.071635179 <a title="54-tfidf-15" href="./cvpr-2013-Sparse_Subspace_Denoising_for_Image_Manifolds.html">405 cvpr-2013-Sparse Subspace Denoising for Image Manifolds</a></p>
<p>16 0.067837164 <a title="54-tfidf-16" href="./cvpr-2013-Improving_Image_Matting_Using_Comprehensive_Sampling_Sets.html">216 cvpr-2013-Improving Image Matting Using Comprehensive Sampling Sets</a></p>
<p>17 0.067091651 <a title="54-tfidf-17" href="./cvpr-2013-A_Theory_of_Refractive_Photo-Light-Path_Triangulation.html">27 cvpr-2013-A Theory of Refractive Photo-Light-Path Triangulation</a></p>
<p>18 0.067044072 <a title="54-tfidf-18" href="./cvpr-2013-Intrinsic_Scene_Properties_from_a_Single_RGB-D_Image.html">227 cvpr-2013-Intrinsic Scene Properties from a Single RGB-D Image</a></p>
<p>19 0.062115654 <a title="54-tfidf-19" href="./cvpr-2013-Articulated_and_Restricted_Motion_Subspaces_and_Their_Signatures.html">46 cvpr-2013-Articulated and Restricted Motion Subspaces and Their Signatures</a></p>
<p>20 0.061898645 <a title="54-tfidf-20" href="./cvpr-2013-Reconstructing_Gas_Flows_Using_Light-Path_Approximation.html">349 cvpr-2013-Reconstructing Gas Flows Using Light-Path Approximation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.145), (1, 0.151), (2, -0.026), (3, 0.085), (4, -0.014), (5, -0.114), (6, -0.116), (7, -0.008), (8, 0.053), (9, -0.029), (10, -0.089), (11, -0.103), (12, -0.075), (13, -0.157), (14, 0.017), (15, 0.113), (16, 0.219), (17, -0.161), (18, 0.009), (19, -0.084), (20, 0.095), (21, -0.027), (22, -0.041), (23, 0.014), (24, 0.014), (25, -0.14), (26, -0.079), (27, -0.015), (28, 0.028), (29, 0.018), (30, -0.246), (31, 0.126), (32, -0.082), (33, -0.125), (34, -0.052), (35, -0.091), (36, 0.095), (37, -0.017), (38, 0.006), (39, 0.017), (40, 0.013), (41, 0.018), (42, 0.077), (43, -0.015), (44, -0.066), (45, -0.056), (46, -0.098), (47, -0.03), (48, 0.016), (49, 0.059)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94225985 <a title="54-lsi-1" href="./cvpr-2013-BRDF_Slices%3A_Accurate_Adaptive_Anisotropic_Appearance_Acquisition.html">54 cvpr-2013-BRDF Slices: Accurate Adaptive Anisotropic Appearance Acquisition</a></p>
<p>Author: Jirí Filip, Radomír Vávra, Michal Haindl, Pavel Žid, Mikuláš Krupika, Vlastimil Havran</p><p>Abstract: In this paper we introduce unique publicly available dense anisotropic BRDF data measurements. We use this dense data as a reference for performance evaluation of the proposed BRDF sparse angular sampling and interpolation approach. The method is based on sampling of BRDF subspaces at fixed elevations by means of several adaptively-represented, uniformly distributed, perpendicular slices. Although this proposed method requires only a sparse sampling of material, the interpolation provides a very accurate reconstruction, visually and computationally comparable to densely measured reference. Due to the simple slices measurement and method’s robustness it allows for a highly accurate acquisition of BRDFs. This in comparison with standard uniform angular sampling, is considerably faster yet uses far less samples.</p><p>2 0.89493608 <a title="54-lsi-2" href="./cvpr-2013-Calibrating_Photometric_Stereo_by_Holistic_Reflectance_Symmetry_Analysis.html">75 cvpr-2013-Calibrating Photometric Stereo by Holistic Reflectance Symmetry Analysis</a></p>
<p>Author: Zhe Wu, Ping Tan</p><p>Abstract: Under unknown directional lighting, the uncalibrated Lambertian photometric stereo algorithm recovers the shape of a smooth surface up to the generalized bas-relief (GBR) ambiguity. We resolve this ambiguity from the halfvector symmetry, which is observed in many isotropic materials. Under this symmetry, a 2D BRDF slice with low-rank structure can be obtained from an image, if the surface normals and light directions are correctly recovered. In general, this structure is destroyed by the GBR ambiguity. As a result, we can resolve the ambiguity by restoring this structure. We develop a simple algorithm of auto-calibration from separable homogeneous specular reflection of real images. Compared with previous methods, this method takes a holistic approach to exploiting reflectance symmetry and produces superior results.</p><p>3 0.70793962 <a title="54-lsi-3" href="./cvpr-2013-Analytic_Bilinear_Appearance_Subspace_Construction_for_Modeling_Image_Irradiance_under_Natural_Illumination_and_Non-Lambertian_Reflectance.html">42 cvpr-2013-Analytic Bilinear Appearance Subspace Construction for Modeling Image Irradiance under Natural Illumination and Non-Lambertian Reflectance</a></p>
<p>Author: Shireen Y. Elhabian, Aly A. Farag</p><p>Abstract: Conventional subspace construction approaches suffer from the need of “large-enough ” image ensemble rendering numerical methods intractable. In this paper, we propose an analytic formulation for low-dimensional subspace construction in which shading cues lie while preserving the natural structure of an image sample. Using the frequencyspace representation of the image irradiance equation, the process of finding such subspace is cast as establishing a relation between its principal components and that of a deterministic set of basis functions, termed as irradiance harmonics. Representing images as matrices further lessen the number of parameters to be estimated to define a bilinear projection which maps the image sample to a lowerdimensional bilinear subspace. Results show significant impact on dimensionality reduction with minimal loss of information as well as robustness against noise.</p><p>4 0.68202436 <a title="54-lsi-4" href="./cvpr-2013-What_Object_Motion_Reveals_about_Shape_with_Unknown_BRDF_and_Lighting.html">465 cvpr-2013-What Object Motion Reveals about Shape with Unknown BRDF and Lighting</a></p>
<p>Author: Manmohan Chandraker, Dikpal Reddy, Yizhou Wang, Ravi Ramamoorthi</p><p>Abstract: We present a theory that addresses the problem of determining shape from the (small or differential) motion of an object with unknown isotropic reflectance, under arbitrary unknown distant illumination, , for both orthographic and perpsective projection. Our theory imposes fundamental limits on the hardness of surface reconstruction, independent of the method involved. Under orthographic projection, we prove that three differential motions suffice to yield an invariant that relates shape to image derivatives, regardless of BRDF and illumination. Under perspective projection, we show that four differential motions suffice to yield depth and a linear constraint on the surface gradient, with unknown BRDF and lighting. Further, we delineate the topological classes up to which reconstruction may be achieved using the invariants. Finally, we derive a general stratification that relates hardness of shape recovery to scene complexity. Qualitatively, our invariants are homogeneous partial differential equations for simple lighting and inhomogeneous for complex illumination. Quantitatively, our framework shows that the minimal number of motions required to resolve shape is greater for more complex scenes. Prior works that assume brightness constancy, Lambertian BRDF or a known directional light source follow as special cases of our stratification. We illustrate with synthetic and real data how potential reconstruction methods may exploit our framework.</p><p>5 0.66948342 <a title="54-lsi-5" href="./cvpr-2013-Multi-view_Photometric_Stereo_with_Spatially_Varying_Isotropic_Materials.html">303 cvpr-2013-Multi-view Photometric Stereo with Spatially Varying Isotropic Materials</a></p>
<p>Author: Zhenglong Zhou, Zhe Wu, Ping Tan</p><p>Abstract: We present a method to capture both 3D shape and spatially varying reflectance with a multi-view photometric stereo technique that works for general isotropic materials. Our data capture setup is simple, which consists of only a digital camera and a handheld light source. From a single viewpoint, we use a set of photometric stereo images to identify surface points with the same distance to the camera. We collect this information from multiple viewpoints and combine it with structure-from-motion to obtain a precise reconstruction of the complete 3D shape. The spatially varying isotropic bidirectional reflectance distributionfunction (BRDF) is captured by simultaneously inferring a set of basis BRDFs and their mixing weights at each surface point. According to our experiments, the captured shapes are accurate to 0.3 millimeters. The captured reflectance has relative root-mean-square error (RMSE) of 9%.</p><p>6 0.65719366 <a title="54-lsi-6" href="./cvpr-2013-Learning_Discriminative_Illumination_and_Filters_for_Raw_Material_Classification_with_Optimal_Projections_of_Bidirectional_Texture_Functions.html">251 cvpr-2013-Learning Discriminative Illumination and Filters for Raw Material Classification with Optimal Projections of Bidirectional Texture Functions</a></p>
<p>7 0.62530667 <a title="54-lsi-7" href="./cvpr-2013-Uncalibrated_Photometric_Stereo_for_Unknown_Isotropic_Reflectances.html">443 cvpr-2013-Uncalibrated Photometric Stereo for Unknown Isotropic Reflectances</a></p>
<p>8 0.57878399 <a title="54-lsi-8" href="./cvpr-2013-Spectral_Modeling_and_Relighting_of_Reflective-Fluorescent_Scenes.html">409 cvpr-2013-Spectral Modeling and Relighting of Reflective-Fluorescent Scenes</a></p>
<p>9 0.49151278 <a title="54-lsi-9" href="./cvpr-2013-A_New_Perspective_on_Uncalibrated_Photometric_Stereo.html">21 cvpr-2013-A New Perspective on Uncalibrated Photometric Stereo</a></p>
<p>10 0.44295555 <a title="54-lsi-10" href="./cvpr-2013-Adaptive_Compressed_Tomography_Sensing.html">35 cvpr-2013-Adaptive Compressed Tomography Sensing</a></p>
<p>11 0.43548653 <a title="54-lsi-11" href="./cvpr-2013-Sensing_and_Recognizing_Surface_Textures_Using_a_GelSight_Sensor.html">391 cvpr-2013-Sensing and Recognizing Surface Textures Using a GelSight Sensor</a></p>
<p>12 0.35172507 <a title="54-lsi-12" href="./cvpr-2013-Towards_Contactless%2C_Low-Cost_and_Accurate_3D_Fingerprint_Identification.html">435 cvpr-2013-Towards Contactless, Low-Cost and Accurate 3D Fingerprint Identification</a></p>
<p>13 0.34449899 <a title="54-lsi-13" href="./cvpr-2013-Photometric_Ambient_Occlusion.html">330 cvpr-2013-Photometric Ambient Occlusion</a></p>
<p>14 0.3293432 <a title="54-lsi-14" href="./cvpr-2013-Improved_Image_Set_Classification_via_Joint_Sparse_Approximated_Nearest_Subspaces.html">215 cvpr-2013-Improved Image Set Classification via Joint Sparse Approximated Nearest Subspaces</a></p>
<p>15 0.31531265 <a title="54-lsi-15" href="./cvpr-2013-Specular_Reflection_Separation_Using_Dark_Channel_Prior.html">410 cvpr-2013-Specular Reflection Separation Using Dark Channel Prior</a></p>
<p>16 0.29755476 <a title="54-lsi-16" href="./cvpr-2013-Efficient_3D_Endfiring_TRUS_Prostate_Segmentation_with_Globally_Optimized_Rotational_Symmetry.html">139 cvpr-2013-Efficient 3D Endfiring TRUS Prostate Segmentation with Globally Optimized Rotational Symmetry</a></p>
<p>17 0.29572931 <a title="54-lsi-17" href="./cvpr-2013-Reconstructing_Gas_Flows_Using_Light-Path_Approximation.html">349 cvpr-2013-Reconstructing Gas Flows Using Light-Path Approximation</a></p>
<p>18 0.29135424 <a title="54-lsi-18" href="./cvpr-2013-Three-Dimensional_Bilateral_Symmetry_Plane_Estimation_in_the_Phase_Domain.html">432 cvpr-2013-Three-Dimensional Bilateral Symmetry Plane Estimation in the Phase Domain</a></p>
<p>19 0.28687781 <a title="54-lsi-19" href="./cvpr-2013-Kernel_Null_Space_Methods_for_Novelty_Detection.html">239 cvpr-2013-Kernel Null Space Methods for Novelty Detection</a></p>
<p>20 0.28674144 <a title="54-lsi-20" href="./cvpr-2013-Illumination_Estimation_Based_on_Bilayer_Sparse_Coding.html">210 cvpr-2013-Illumination Estimation Based on Bilayer Sparse Coding</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(4, 0.255), (10, 0.121), (16, 0.06), (26, 0.038), (28, 0.016), (33, 0.199), (59, 0.013), (66, 0.034), (67, 0.062), (69, 0.047), (87, 0.073)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.79688025 <a title="54-lda-1" href="./cvpr-2013-BRDF_Slices%3A_Accurate_Adaptive_Anisotropic_Appearance_Acquisition.html">54 cvpr-2013-BRDF Slices: Accurate Adaptive Anisotropic Appearance Acquisition</a></p>
<p>Author: Jirí Filip, Radomír Vávra, Michal Haindl, Pavel Žid, Mikuláš Krupika, Vlastimil Havran</p><p>Abstract: In this paper we introduce unique publicly available dense anisotropic BRDF data measurements. We use this dense data as a reference for performance evaluation of the proposed BRDF sparse angular sampling and interpolation approach. The method is based on sampling of BRDF subspaces at fixed elevations by means of several adaptively-represented, uniformly distributed, perpendicular slices. Although this proposed method requires only a sparse sampling of material, the interpolation provides a very accurate reconstruction, visually and computationally comparable to densely measured reference. Due to the simple slices measurement and method’s robustness it allows for a highly accurate acquisition of BRDFs. This in comparison with standard uniform angular sampling, is considerably faster yet uses far less samples.</p><p>2 0.75287616 <a title="54-lda-2" href="./cvpr-2013-A_Higher-Order_CRF_Model_for_Road_Network_Extraction.html">13 cvpr-2013-A Higher-Order CRF Model for Road Network Extraction</a></p>
<p>Author: Jan D. Wegner, Javier A. Montoya-Zegarra, Konrad Schindler</p><p>Abstract: The aim of this work is to extract the road network from aerial images. What makes the problem challenging is the complex structure of the prior: roads form a connected network of smooth, thin segments which meet at junctions and crossings. This type of a-priori knowledge is more difficult to turn into a tractable model than standard smoothness or co-occurrence assumptions. We develop a novel CRF formulation for road labeling, in which the prior is represented by higher-order cliques that connect sets of superpixels along straight line segments. These long-range cliques have asymmetric PN-potentials, which express a preference to assign all rather than just some of their constituent superpixels to the road class. Thus, the road likelihood is amplified for thin chains of superpixels, while the CRF is still amenable to optimization with graph cuts. Since the number of such cliques of arbitrary length is huge, we furthermorepropose a sampling scheme which concentrates on those cliques which are most relevant for the optimization. In experiments on two different databases the model significantly improves both the per-pixel accuracy and the topological correctness of the extracted roads, and outper- forms both a simple smoothness prior and heuristic rulebased road completion.</p><p>3 0.72416711 <a title="54-lda-3" href="./cvpr-2013-Learning_Discriminative_Illumination_and_Filters_for_Raw_Material_Classification_with_Optimal_Projections_of_Bidirectional_Texture_Functions.html">251 cvpr-2013-Learning Discriminative Illumination and Filters for Raw Material Classification with Optimal Projections of Bidirectional Texture Functions</a></p>
<p>Author: Chao Liu, Geifei Yang, Jinwei Gu</p><p>Abstract: We present a computational imaging method for raw material classification using features of Bidirectional Texture Functions (BTF). Texture is an intrinsic feature for many materials, such as wood, fabric, and granite. At appropriate scales, even “uniform” materials will also exhibit texture features that can be helpful for recognition, such as paper, metal, and ceramic. To cope with the high-dimensionality of BTFs, in this paper, we proposed to learn discriminative illumination patterns and texture filters, with which we can directly measure optimal projections of BTFs for classification. We also studied the effects of texture rotation and scale variation for material classification. We built an LED-based multispectral dome, with which we have acquired a BTF database of a variety of materials and demonstrated the effectiveness of the proposed approach for material classification.</p><p>4 0.72241718 <a title="54-lda-4" href="./cvpr-2013-Structure_Preserving_Object_Tracking.html">414 cvpr-2013-Structure Preserving Object Tracking</a></p>
<p>Author: Lu Zhang, Laurens van_der_Maaten</p><p>Abstract: Model-free trackers can track arbitrary objects based on a single (bounding-box) annotation of the object. Whilst the performance of model-free trackers has recently improved significantly, simultaneously tracking multiple objects with similar appearance remains very hard. In this paper, we propose a new multi-object model-free tracker (based on tracking-by-detection) that resolves this problem by incorporating spatial constraints between the objects. The spatial constraints are learned along with the object detectors using an online structured SVM algorithm. The experimental evaluation ofour structure-preserving object tracker (SPOT) reveals significant performance improvements in multi-object tracking. We also show that SPOT can improve the performance of single-object trackers by simultaneously tracking different parts of the object.</p><p>5 0.70201206 <a title="54-lda-5" href="./cvpr-2013-Exploring_Compositional_High_Order_Pattern_Potentials_for_Structured_Output_Learning.html">156 cvpr-2013-Exploring Compositional High Order Pattern Potentials for Structured Output Learning</a></p>
<p>Author: Yujia Li, Daniel Tarlow, Richard Zemel</p><p>Abstract: When modeling structured outputs such as image segmentations, prediction can be improved by accurately modeling structure present in the labels. A key challenge is developing tractable models that are able to capture complex high level structure like shape. In this work, we study the learning of a general class of pattern-like high order potential, which we call Compositional High Order Pattern Potentials (CHOPPs). We show that CHOPPs include the linear deviation pattern potentials of Rother et al. [26] and also Restricted Boltzmann Machines (RBMs); we also establish the near equivalence of these two models. Experimentally, we show that performance is affected significantly by the degree of variability present in the datasets, and we define a quantitative variability measure to aid in studying this. We then improve CHOPPs performance in high variability datasets with two primary contributions: (a) developing a loss-sensitive joint learning procedure, so that internal pattern parameters can be learned in conjunction with other model potentials to minimize expected loss;and (b) learning an image-dependent mapping that encourages or inhibits patterns depending on image features. We also explore varying how multiple patterns are composed, and learning convolutional patterns. Quantitative results on challenging highly variable datasets show that the joint learning and image-dependent high order potentials can improve performance.</p><p>6 0.69306654 <a title="54-lda-6" href="./cvpr-2013-Multi-view_Photometric_Stereo_with_Spatially_Varying_Isotropic_Materials.html">303 cvpr-2013-Multi-view Photometric Stereo with Spatially Varying Isotropic Materials</a></p>
<p>7 0.6926778 <a title="54-lda-7" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>8 0.6914494 <a title="54-lda-8" href="./cvpr-2013-Intrinsic_Scene_Properties_from_a_Single_RGB-D_Image.html">227 cvpr-2013-Intrinsic Scene Properties from a Single RGB-D Image</a></p>
<p>9 0.69090867 <a title="54-lda-9" href="./cvpr-2013-Discovering_the_Structure_of_a_Planar_Mirror_System_from_Multiple_Observations_of_a_Single_Point.html">127 cvpr-2013-Discovering the Structure of a Planar Mirror System from Multiple Observations of a Single Point</a></p>
<p>10 0.69017714 <a title="54-lda-10" href="./cvpr-2013-Single_Image_Calibration_of_Multi-axial_Imaging_Systems.html">400 cvpr-2013-Single Image Calibration of Multi-axial Imaging Systems</a></p>
<p>11 0.69003302 <a title="54-lda-11" href="./cvpr-2013-Integrating_Grammar_and_Segmentation_for_Human_Pose_Estimation.html">225 cvpr-2013-Integrating Grammar and Segmentation for Human Pose Estimation</a></p>
<p>12 0.68891329 <a title="54-lda-12" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<p>13 0.68687838 <a title="54-lda-13" href="./cvpr-2013-Robust_Multi-resolution_Pedestrian_Detection_in_Traffic_Scenes.html">363 cvpr-2013-Robust Multi-resolution Pedestrian Detection in Traffic Scenes</a></p>
<p>14 0.68672347 <a title="54-lda-14" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<p>15 0.68671942 <a title="54-lda-15" href="./cvpr-2013-Robust_Estimation_of_Nonrigid_Transformation_for_Point_Set_Registration.html">360 cvpr-2013-Robust Estimation of Nonrigid Transformation for Point Set Registration</a></p>
<p>16 0.68648744 <a title="54-lda-16" href="./cvpr-2013-Uncalibrated_Photometric_Stereo_for_Unknown_Isotropic_Reflectances.html">443 cvpr-2013-Uncalibrated Photometric Stereo for Unknown Isotropic Reflectances</a></p>
<p>17 0.68609691 <a title="54-lda-17" href="./cvpr-2013-Physically_Plausible_3D_Scene_Tracking%3A_The_Single_Actor_Hypothesis.html">331 cvpr-2013-Physically Plausible 3D Scene Tracking: The Single Actor Hypothesis</a></p>
<p>18 0.68551385 <a title="54-lda-18" href="./cvpr-2013-Spatiotemporal_Deformable_Part_Models_for_Action_Detection.html">408 cvpr-2013-Spatiotemporal Deformable Part Models for Action Detection</a></p>
<p>19 0.68541914 <a title="54-lda-19" href="./cvpr-2013-Part_Discovery_from_Partial_Correspondence.html">325 cvpr-2013-Part Discovery from Partial Correspondence</a></p>
<p>20 0.68491262 <a title="54-lda-20" href="./cvpr-2013-Calibrating_Photometric_Stereo_by_Holistic_Reflectance_Symmetry_Analysis.html">75 cvpr-2013-Calibrating Photometric Stereo by Holistic Reflectance Symmetry Analysis</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
