<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>362 cvpr-2013-Robust Monocular Epipolar Flow Estimation</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-362" href="#">cvpr2013-362</a> knowledge-graph by maker-knowledge-mining</p><h1>362 cvpr-2013-Robust Monocular Epipolar Flow Estimation</h1>
<br/><p>Source: <a title="cvpr-2013-362-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Yamaguchi_Robust_Monocular_Epipolar_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Koichiro Yamaguchi, David McAllester, Raquel Urtasun</p><p>Abstract: We consider the problem of computing optical flow in monocular video taken from a moving vehicle. In this setting, the vast majority of image flow is due to the vehicle â€™s ego-motion. We propose to take advantage of this fact and estimate flow along the epipolar lines of the egomotion. Towards this goal, we derive a slanted-plane MRF model which explicitly reasons about the ordering of planes and their physical validity at junctions. Furthermore, we present a bottom-up grouping algorithm which produces over-segmentations that respect flow boundaries. We demonstrate the effectiveness of our approach in the challenging KITTI flow benchmark [11] achieving half the error of the best competing general flow algorithm and one third of the error of the best epipolar flow algorithm.</p><p>Reference: <a title="cvpr-2013-362-reference" href="../cvpr2013_reference/cvpr-2013-Robust_Monocular_Epipolar_Flow_Estimation_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('epipol', 0.581), ('flow', 0.409), ('sp', 0.257), ('motionsl', 0.234), ('uw', 0.168), ('zp', 0.154), ('stereo', 0.148), ('disp', 0.135), ('csp', 0.135), ('mrf', 0.133), ('orac', 0.131), ('slant', 0.124), ('foe', 0.104), ('vz', 0.1), ('superpixel', 0.097), ('plan', 0.092), ('pcbp', 0.083), ('uv', 0.082), ('sgm', 0.073), ('coplan', 0.072)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999952 <a title="362-tfidf-1" href="./cvpr-2013-Robust_Monocular_Epipolar_Flow_Estimation.html">362 cvpr-2013-Robust Monocular Epipolar Flow Estimation</a></p>
<p>2 0.28192359 <a title="362-tfidf-2" href="./cvpr-2013-Globally_Consistent_Multi-label_Assignment_on_the_Ray_Space_of_4D_Light_Fields.html">188 cvpr-2013-Globally Consistent Multi-label Assignment on the Ray Space of 4D Light Fields</a></p>
<p>3 0.25922391 <a title="362-tfidf-3" href="./cvpr-2013-Determining_Motion_Directly_from_Normal_Flows_Upon_the_Use_of_a_Spherical_Eye_Platform.html">124 cvpr-2013-Determining Motion Directly from Normal Flows Upon the Use of a Spherical Eye Platform</a></p>
<p>4 0.24557644 <a title="362-tfidf-4" href="./cvpr-2013-The_Variational_Structure_of_Disparity_and_Regularization_of_4D_Light_Fields.html">431 cvpr-2013-The Variational Structure of Disparity and Regularization of 4D Light Fields</a></p>
<p>5 0.23630525 <a title="362-tfidf-5" href="./cvpr-2013-Radial_Distortion_Self-Calibration.html">344 cvpr-2013-Radial Distortion Self-Calibration</a></p>
<p>6 0.22922355 <a title="362-tfidf-6" href="./cvpr-2013-Large_Displacement_Optical_Flow_from_Nearest_Neighbor_Fields.html">244 cvpr-2013-Large Displacement Optical Flow from Nearest Neighbor Fields</a></p>
<p>7 0.2272093 <a title="362-tfidf-7" href="./cvpr-2013-Ensemble_Learning_for_Confidence_Measures_in_Stereo_Vision.html">147 cvpr-2013-Ensemble Learning for Confidence Measures in Stereo Vision</a></p>
<p>8 0.17989838 <a title="362-tfidf-8" href="./cvpr-2013-Real-Time_Model-Based_Rigid_Object_Pose_Estimation_and_Tracking_Combining_Dense_and_Sparse_Visual_Cues.html">345 cvpr-2013-Real-Time Model-Based Rigid Object Pose Estimation and Tracking Combining Dense and Sparse Visual Cues</a></p>
<p>9 0.17815866 <a title="362-tfidf-9" href="./cvpr-2013-A_Fully-Connected_Layered_Model_of_Foreground_and_Background_Flow.html">10 cvpr-2013-A Fully-Connected Layered Model of Foreground and Background Flow</a></p>
<p>10 0.1685212 <a title="362-tfidf-10" href="./cvpr-2013-Fast_Rigid_Motion_Segmentation_via_Incrementally-Complex_Local_Models.html">170 cvpr-2013-Fast Rigid Motion Segmentation via Incrementally-Complex Local Models</a></p>
<p>11 0.16438875 <a title="362-tfidf-11" href="./cvpr-2013-Pose_from_Flow_and_Flow_from_Pose.html">334 cvpr-2013-Pose from Flow and Flow from Pose</a></p>
<p>12 0.16204409 <a title="362-tfidf-12" href="./cvpr-2013-Patch_Match_Filter%3A_Efficient_Edge-Aware_Filtering_Meets_Randomized_Search_for_Fast_Correspondence_Field_Estimation.html">326 cvpr-2013-Patch Match Filter: Efficient Edge-Aware Filtering Meets Randomized Search for Fast Correspondence Field Estimation</a></p>
<p>13 0.157625 <a title="362-tfidf-13" href="./cvpr-2013-A_Practical_Rank-Constrained_Eight-Point_Algorithm_for_Fundamental_Matrix_Estimation.html">23 cvpr-2013-A Practical Rank-Constrained Eight-Point Algorithm for Fundamental Matrix Estimation</a></p>
<p>14 0.15485746 <a title="362-tfidf-14" href="./cvpr-2013-Multi-target_Tracking_by_Lagrangian_Relaxation_to_Min-cost_Network_Flow.html">300 cvpr-2013-Multi-target Tracking by Lagrangian Relaxation to Min-cost Network Flow</a></p>
<p>15 0.15229355 <a title="362-tfidf-15" href="./cvpr-2013-Efficient_Object_Detection_and_Segmentation_for_Fine-Grained_Recognition.html">145 cvpr-2013-Efficient Object Detection and Segmentation for Fine-Grained Recognition</a></p>
<p>16 0.14706776 <a title="362-tfidf-16" href="./cvpr-2013-Better_Exploiting_Motion_for_Better_Action_Recognition.html">59 cvpr-2013-Better Exploiting Motion for Better Action Recognition</a></p>
<p>17 0.13981535 <a title="362-tfidf-17" href="./cvpr-2013-Fusing_Depth_from_Defocus_and_Stereo_with_Coded_Apertures.html">181 cvpr-2013-Fusing Depth from Defocus and Stereo with Coded Apertures</a></p>
<p>18 0.13953345 <a title="362-tfidf-18" href="./cvpr-2013-Exploring_Weak_Stabilization_for_Motion_Feature_Extraction.html">158 cvpr-2013-Exploring Weak Stabilization for Motion Feature Extraction</a></p>
<p>19 0.13160928 <a title="362-tfidf-19" href="./cvpr-2013-Improving_an_Object_Detector_and_Extracting_Regions_Using_Superpixels.html">217 cvpr-2013-Improving an Object Detector and Extracting Regions Using Superpixels</a></p>
<p>20 0.12394864 <a title="362-tfidf-20" href="./cvpr-2013-Exploiting_the_Power_of_Stereo_Confidences.html">155 cvpr-2013-Exploiting the Power of Stereo Confidences</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.188), (1, -0.049), (2, 0.159), (3, -0.008), (4, -0.013), (5, -0.097), (6, 0.052), (7, 0.021), (8, 0.065), (9, 0.099), (10, 0.084), (11, 0.006), (12, -0.024), (13, -0.346), (14, -0.164), (15, -0.103), (16, 0.059), (17, 0.128), (18, -0.063), (19, 0.155), (20, -0.005), (21, -0.057), (22, 0.01), (23, -0.053), (24, -0.108), (25, -0.03), (26, -0.037), (27, -0.03), (28, -0.117), (29, 0.051), (30, 0.04), (31, 0.021), (32, -0.026), (33, -0.05), (34, 0.041), (35, 0.024), (36, -0.014), (37, 0.07), (38, 0.003), (39, 0.002), (40, -0.014), (41, 0.048), (42, -0.096), (43, 0.008), (44, -0.018), (45, -0.06), (46, 0.049), (47, -0.074), (48, 0.059), (49, 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94406927 <a title="362-lsi-1" href="./cvpr-2013-Robust_Monocular_Epipolar_Flow_Estimation.html">362 cvpr-2013-Robust Monocular Epipolar Flow Estimation</a></p>
<p>2 0.75391591 <a title="362-lsi-2" href="./cvpr-2013-Patch_Match_Filter%3A_Efficient_Edge-Aware_Filtering_Meets_Randomized_Search_for_Fast_Correspondence_Field_Estimation.html">326 cvpr-2013-Patch Match Filter: Efficient Edge-Aware Filtering Meets Randomized Search for Fast Correspondence Field Estimation</a></p>
<p>3 0.72626102 <a title="362-lsi-3" href="./cvpr-2013-Large_Displacement_Optical_Flow_from_Nearest_Neighbor_Fields.html">244 cvpr-2013-Large Displacement Optical Flow from Nearest Neighbor Fields</a></p>
<p>4 0.70194077 <a title="362-lsi-4" href="./cvpr-2013-Determining_Motion_Directly_from_Normal_Flows_Upon_the_Use_of_a_Spherical_Eye_Platform.html">124 cvpr-2013-Determining Motion Directly from Normal Flows Upon the Use of a Spherical Eye Platform</a></p>
<p>5 0.64599472 <a title="362-lsi-5" href="./cvpr-2013-The_Variational_Structure_of_Disparity_and_Regularization_of_4D_Light_Fields.html">431 cvpr-2013-The Variational Structure of Disparity and Regularization of 4D Light Fields</a></p>
<p>6 0.62370849 <a title="362-lsi-6" href="./cvpr-2013-Megastereo%3A_Constructing_High-Resolution_Stereo_Panoramas.html">283 cvpr-2013-Megastereo: Constructing High-Resolution Stereo Panoramas</a></p>
<p>7 0.60317242 <a title="362-lsi-7" href="./cvpr-2013-Globally_Consistent_Multi-label_Assignment_on_the_Ray_Space_of_4D_Light_Fields.html">188 cvpr-2013-Globally Consistent Multi-label Assignment on the Ray Space of 4D Light Fields</a></p>
<p>8 0.58645678 <a title="362-lsi-8" href="./cvpr-2013-A_Fully-Connected_Layered_Model_of_Foreground_and_Background_Flow.html">10 cvpr-2013-A Fully-Connected Layered Model of Foreground and Background Flow</a></p>
<p>9 0.57139593 <a title="362-lsi-9" href="./cvpr-2013-Compressible_Motion_Fields.html">88 cvpr-2013-Compressible Motion Fields</a></p>
<p>10 0.5549444 <a title="362-lsi-10" href="./cvpr-2013-Ensemble_Learning_for_Confidence_Measures_in_Stereo_Vision.html">147 cvpr-2013-Ensemble Learning for Confidence Measures in Stereo Vision</a></p>
<p>11 0.53604776 <a title="362-lsi-11" href="./cvpr-2013-Better_Exploiting_Motion_for_Better_Action_Recognition.html">59 cvpr-2013-Better Exploiting Motion for Better Action Recognition</a></p>
<p>12 0.52554446 <a title="362-lsi-12" href="./cvpr-2013-Segment-Tree_Based_Cost_Aggregation_for_Stereo_Matching.html">384 cvpr-2013-Segment-Tree Based Cost Aggregation for Stereo Matching</a></p>
<p>13 0.52073133 <a title="362-lsi-13" href="./cvpr-2013-Fast_Rigid_Motion_Segmentation_via_Incrementally-Complex_Local_Models.html">170 cvpr-2013-Fast Rigid Motion Segmentation via Incrementally-Complex Local Models</a></p>
<p>14 0.52057159 <a title="362-lsi-14" href="./cvpr-2013-In_Defense_of_3D-Label_Stereo.html">219 cvpr-2013-In Defense of 3D-Label Stereo</a></p>
<p>15 0.50119221 <a title="362-lsi-15" href="./cvpr-2013-Exploiting_the_Power_of_Stereo_Confidences.html">155 cvpr-2013-Exploiting the Power of Stereo Confidences</a></p>
<p>16 0.50019526 <a title="362-lsi-16" href="./cvpr-2013-Motion_Estimation_for_Self-Driving_Cars_with_a_Generalized_Camera.html">290 cvpr-2013-Motion Estimation for Self-Driving Cars with a Generalized Camera</a></p>
<p>17 0.48955482 <a title="362-lsi-17" href="./cvpr-2013-Fusing_Depth_from_Defocus_and_Stereo_with_Coded_Apertures.html">181 cvpr-2013-Fusing Depth from Defocus and Stereo with Coded Apertures</a></p>
<p>18 0.48856056 <a title="362-lsi-18" href="./cvpr-2013-Pose_from_Flow_and_Flow_from_Pose.html">334 cvpr-2013-Pose from Flow and Flow from Pose</a></p>
<p>19 0.47129571 <a title="362-lsi-19" href="./cvpr-2013-Real-Time_Model-Based_Rigid_Object_Pose_Estimation_and_Tracking_Combining_Dense_and_Sparse_Visual_Cues.html">345 cvpr-2013-Real-Time Model-Based Rigid Object Pose Estimation and Tracking Combining Dense and Sparse Visual Cues</a></p>
<p>20 0.46744707 <a title="362-lsi-20" href="./cvpr-2013-Dense_Segmentation-Aware_Descriptors.html">112 cvpr-2013-Dense Segmentation-Aware Descriptors</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(11, 0.334), (19, 0.133), (28, 0.057), (31, 0.017), (50, 0.014), (55, 0.075), (60, 0.01), (75, 0.039), (85, 0.02), (86, 0.168), (90, 0.031), (97, 0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.69531947 <a title="362-lda-1" href="./cvpr-2013-Robust_Monocular_Epipolar_Flow_Estimation.html">362 cvpr-2013-Robust Monocular Epipolar Flow Estimation</a></p>
<p>2 0.66613507 <a title="362-lda-2" href="./cvpr-2013-A_Non-parametric_Framework_for_Document_Bleed-through_Removal.html">22 cvpr-2013-A Non-parametric Framework for Document Bleed-through Removal</a></p>
<p>3 0.63891512 <a title="362-lda-3" href="./cvpr-2013-Spatio-temporal_Depth_Cuboid_Similarity_Feature_for_Activity_Recognition_Using_Depth_Camera.html">407 cvpr-2013-Spatio-temporal Depth Cuboid Similarity Feature for Activity Recognition Using Depth Camera</a></p>
<p>4 0.5662294 <a title="362-lda-4" href="./cvpr-2013-Boundary_Detection_Benchmarking%3A_Beyond_F-Measures.html">72 cvpr-2013-Boundary Detection Benchmarking: Beyond F-Measures</a></p>
<p>5 0.56509584 <a title="362-lda-5" href="./cvpr-2013-Segment-Tree_Based_Cost_Aggregation_for_Stereo_Matching.html">384 cvpr-2013-Segment-Tree Based Cost Aggregation for Stereo Matching</a></p>
<p>6 0.56218576 <a title="362-lda-6" href="./cvpr-2013-Lost%21_Leveraging_the_Crowd_for_Probabilistic_Visual_Self-Localization.html">274 cvpr-2013-Lost! Leveraging the Crowd for Probabilistic Visual Self-Localization</a></p>
<p>7 0.56139129 <a title="362-lda-7" href="./cvpr-2013-A_Fast_Approximate_AIB_Algorithm_for_Distributional_Word_Clustering.html">8 cvpr-2013-A Fast Approximate AIB Algorithm for Distributional Word Clustering</a></p>
<p>8 0.56117785 <a title="362-lda-8" href="./cvpr-2013-Dictionary_Learning_from_Ambiguously_Labeled_Data.html">125 cvpr-2013-Dictionary Learning from Ambiguously Labeled Data</a></p>
<p>9 0.56065309 <a title="362-lda-9" href="./cvpr-2013-Fast_Multiple-Part_Based_Object_Detection_Using_KD-Ferns.html">167 cvpr-2013-Fast Multiple-Part Based Object Detection Using KD-Ferns</a></p>
<p>10 0.55902624 <a title="362-lda-10" href="./cvpr-2013-Multi-target_Tracking_by_Lagrangian_Relaxation_to_Min-cost_Network_Flow.html">300 cvpr-2013-Multi-target Tracking by Lagrangian Relaxation to Min-cost Network Flow</a></p>
<p>11 0.55731499 <a title="362-lda-11" href="./cvpr-2013-Recovering_Stereo_Pairs_from_Anaglyphs.html">352 cvpr-2013-Recovering Stereo Pairs from Anaglyphs</a></p>
<p>12 0.55652714 <a title="362-lda-12" href="./cvpr-2013-A_Minimum_Error_Vanishing_Point_Detection_Approach_for_Uncalibrated_Monocular_Images_of_Man-Made_Environments.html">19 cvpr-2013-A Minimum Error Vanishing Point Detection Approach for Uncalibrated Monocular Images of Man-Made Environments</a></p>
<p>13 0.55448711 <a title="362-lda-13" href="./cvpr-2013-Adaptive_Compressed_Tomography_Sensing.html">35 cvpr-2013-Adaptive Compressed Tomography Sensing</a></p>
<p>14 0.55247116 <a title="362-lda-14" href="./cvpr-2013-Integrating_Grammar_and_Segmentation_for_Human_Pose_Estimation.html">225 cvpr-2013-Integrating Grammar and Segmentation for Human Pose Estimation</a></p>
<p>15 0.55186069 <a title="362-lda-15" href="./cvpr-2013-A_Joint_Model_for_2D_and_3D_Pose_Estimation_from_a_Single_Image.html">14 cvpr-2013-A Joint Model for 2D and 3D Pose Estimation from a Single Image</a></p>
<p>16 0.55158031 <a title="362-lda-16" href="./cvpr-2013-Hierarchical_Video_Representation_with_Trajectory_Binary_Partition_Tree.html">203 cvpr-2013-Hierarchical Video Representation with Trajectory Binary Partition Tree</a></p>
<p>17 0.55107331 <a title="362-lda-17" href="./cvpr-2013-Pose_from_Flow_and_Flow_from_Pose.html">334 cvpr-2013-Pose from Flow and Flow from Pose</a></p>
<p>18 0.5504266 <a title="362-lda-18" href="./cvpr-2013-Articulated_and_Restricted_Motion_Subspaces_and_Their_Signatures.html">46 cvpr-2013-Articulated and Restricted Motion Subspaces and Their Signatures</a></p>
<p>19 0.55011928 <a title="362-lda-19" href="./cvpr-2013-Fast_Energy_Minimization_Using_Learned_State_Filters.html">165 cvpr-2013-Fast Energy Minimization Using Learned State Filters</a></p>
<p>20 0.54901755 <a title="362-lda-20" href="./cvpr-2013-Harry_Potter%27s_Marauder%27s_Map%3A_Localizing_and_Tracking_Multiple_Persons-of-Interest_by_Nonnegative_Discretization.html">199 cvpr-2013-Harry Potter's Marauder's Map: Localizing and Tracking Multiple Persons-of-Interest by Nonnegative Discretization</a></p>
<br/><br/><br/></body>
</html>
