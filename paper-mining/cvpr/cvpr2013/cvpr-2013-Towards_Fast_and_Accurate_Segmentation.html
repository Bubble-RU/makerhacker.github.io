<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>437 cvpr-2013-Towards Fast and Accurate Segmentation</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-437" href="#">cvpr2013-437</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>437 cvpr-2013-Towards Fast and Accurate Segmentation</h1>
<br/><p>Source: <a title="cvpr-2013-437-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Taylor_Towards_Fast_and_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Camillo Jose Taylor</p><p>Abstract: In this paper we explore approaches to accelerating segmentation and edge detection algorithms based on the gPb framework. The paper characterizes the performance of a simple but effective edge detection scheme which can be computed rapidly and offers performance that is competitive with the pB detector. The paper also describes an approach for computing a reduced order normalized cut that captures the essential features of the original problem but can be computed in less than half a second on a standard computing platform.</p><p>Reference: <a title="cvpr-2013-437-reference" href="../cvpr2013_reference/cvpr-2013-Towards_Fast_and_Accurate_Segmentation_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu s  Abstract In this paper we explore approaches to accelerating segmentation and edge detection algorithms based on the gPb framework. [sent-4, score-0.539]
</p><p>2 The paper characterizes the performance of a simple but effective edge detection scheme which can be computed rapidly and offers performance that is competitive with the pB detector. [sent-5, score-0.541]
</p><p>3 The paper also describes an approach for computing a reduced order normalized cut that captures the essential features of the original problem but can be computed in less than half a second on a standard computing platform. [sent-6, score-0.479]
</p><p>4 More Recently Arbelaez, Maire, Fowlkes and Malik [3, 2] have proposed an impressive segmentation algorithm that achieves state of the art results on commonly available data sets. [sent-11, score-0.169]
</p><p>5 Their gPb method starts with a local edge extraction procedure which has been optimized using learning techniques. [sent-12, score-0.461]
</p><p>6 The results of this edge extraction step are then used as input to a spectral partitioning procedure which globalizes the results using Normalized Cuts. [sent-13, score-0.522]
</p><p>7 This globalization stage helps to focus attention on the most salient edges in the scene. [sent-14, score-0.204]
</p><p>8 The globalization procedure is very effective but it involves the solution of a large, sparse eigensystem which can be quite time consuming. [sent-15, score-0.437]
</p><p>9 Using their implementation one can perform gPb edge detection on a 0. [sent-19, score-0.356]
</p><p>10 The goal of this paper is to make accurate segmentation schemes based on normalized cuts more efficient by exploiting the structure of the underlying problem. [sent-24, score-0.539]
</p><p>11 The resulting ideas could be used to accelerate implementations on a variety of computational platforms including GPUs. [sent-25, score-0.173]
</p><p>12 To this end this paper makes two distinct contributions firstly we characterize the performance of an edge detection scheme based on normalized correlation which was first proposed by Meer and Georgescu [11]. [sent-26, score-0.65]
</p><p>13 We propose a scheme for tuning the parameters ofthis method using training data and show that the resulting tuned detector produces results that are comparable to pB at a fraction of the computational cost. [sent-27, score-0.231]
</p><p>14 Secondly this paper propose a new variant of the normalized cuts segmentation scheme which solves a reduced order eigensystem that captures the essential features ofthe original problem. [sent-28, score-1.1]
</p><p>15 We show how to construct this reduced order system, explain its computational advantages and characterize its performance. [sent-29, score-0.277]
</p><p>16 The remainder of this paper is organized as follows: Section 2 describes the proposed segmentation scheme in more detail while Section 3 presents experimental results obtained with an implementation of this method. [sent-30, score-0.285]
</p><p>17 The procedure consists of three main processing stages: an edge extraction phase, a normalized cuts phase and a region merging phase which produces a segmentation result based on the local and global edge signals. [sent-34, score-1.44]
</p><p>18 The proposed modifications to the edge extraction and normalized cuts stages are discussed in the following subsections. [sent-35, score-0.703]
</p><p>19 Normalized Edge Detection The first step in the procedure is an edge extraction stage which produces a set of edgels. [sent-38, score-0.504]
</p><p>20 This system employs a variant of the method proposed by Meer and Georgescu [11] which can be thought of as computing the normalized cross correlation between each pixel window and a set of oriented edge templates. [sent-39, score-0.602]
</p><p>21 Let wirj ∈ Rp denote the vector formed by stacking the intensity val∈ues R within a circle of radius r pixels centered at pixel location, (i, j), and then subtracting the mean value. [sent-40, score-0.197]
</p><p>22 Let tθr ∈ Rp denote the corresponding entries from an oriented step edge template. [sent-41, score-0.347]
</p><p>23 The entries in the oriented edge template are normalized so that the vector has unit length and zero mean, ? [sent-42, score-0.527]
</p><p>24 tw =een 1 ,th 1e pixel window and the edge template can be computed as follows. [sent-47, score-0.39]
</p><p>25 In this work we modify this edge detection scheme by introducing an additional factor in the denominator which is based on the average response to the template. [sent-52, score-0.601]
</p><p>26 Let μθr denote a scalar representing the average response to the edge template, |trθ · wirj | , over the entire image. [sent-53, score-0.515]
</p><p>27 The modified edge response sirj is| ,th oenve given by tirhee following expression. [sent-54, score-0.477]
</p><p>28 This modification serves to reintroduce some contrast information into the edge response so that larger steps have a greater response than smaller ones and slight variations in low contrast regions are not unduly amplified. [sent-58, score-0.497]
</p><p>29 The edge extraction procedure is applied to each channel of the Lab image and within each color channel we consider 4 different  scales corresponding to radii of 2, 5, 10, and 20 pixels. [sent-59, score-0.461]
</p><p>30 This analysis step produces a total of twelve edge signal values at each pixel representing edge strengths in the different channels and scales. [sent-60, score-0.789]
</p><p>31 These values must then be combined into a single composite edge strength value for the pixel. [sent-61, score-0.43]
</p><p>32 Here we choose to compute a simple weighted sum of the edge signals where the weights are chosen through a regression procedure. [sent-62, score-0.307]
</p><p>33 The second row of Figure 5 shows the results of applying the edge extraction procedure to some sample images. [sent-66, score-0.461]
</p><p>34 Since this edge extraction procedure considers multiple scales it is able to give greater weight to more salient edges which appear at several scales while still responding to more subtle features that only appear at finer scales. [sent-67, score-0.587]
</p><p>35 These results are obtained by computing the maximum response over all orientations to produce an edge strength image and by applying non-maximal suppression to obtain thinned edges. [sent-68, score-0.576]
</p><p>36 Following [3] we construct the matrix W using the intervening contour cue. [sent-72, score-0.186]
</p><p>37 For each pixel, p, we consider every other pixel, q, within a radius of 5 pixels and find the largest edge signal value along the line connecting the two sites, spq. [sent-73, score-0.429]
</p><p>38 The problem described in Equation 3 is ultimately solved, at least approximately, by finding the eigenvectors of the following generalized eigensystem corresponding to the k smallest eigenvalues where k is a constant on the order of 20. [sent-76, score-0.806]
</p><p>39 (D − W)y = λDy 111999111755  (4)  Solving this generalized eigenvalue problem is typically the major computational bottleneck in the normalized cuts segmentation procedure. [sent-77, score-0.6]
</p><p>40 The prinicipal challenges are related to the size of the system and the fact that we are interested in recovering the smallest eigenvalues rather than the largest. [sent-78, score-0.292]
</p><p>41 We propose to construct a reduced order normalized cut system which will be easier to solve by replacing the vector y in the previous equations with the vector Lx where x ∈ Rm, L ∈ Rn×m and k ? [sent-79, score-0.493]
</p><p>42 (LT(D − W)L)x = γ(LTDL)x  (6)  First we note that if Lx is an eigenvector of the generalized eigensystem in Equation 4 then x will be an eigenvector of the system in Equation 6 with the same eigenvalue. [sent-83, score-0.467]
</p><p>43 From this we can conclude that if the k relevant eigenvectors of the original problem lie in the span of the matrix L then our reduced eigenector problem will actually produce exactly the same results as the original problem. [sent-84, score-0.621]
</p><p>44 That is the k smallest eigenvalues of the reduced problem will be the same as those of the original problem and the corresponding vectors Lxi will match the eigenvectors of the original problem modulo an irrelevant scale factor. [sent-85, score-0.639]
</p><p>45 More generally  if the k eigenvectors are well approximated by the span of L then the eigenvectors of the reduced system will be good approximations for those of the original system. [sent-86, score-0.862]
</p><p>46 This figure shows the results of breaking an input image into superpixels by applying the watershed algorithm to the edge strength signal produced by the normalized edge detection stage. [sent-88, score-1.315]
</p><p>47 Our aim then is to construct a matrix, L, whose column span captures the variation we expect in the eigenvectors of the orginal system. [sent-89, score-0.425]
</p><p>48 We do this by first considering the edge strength signals produced in the edge detection phase. [sent-90, score-0.855]
</p><p>49 We produce an edge strength image by simply recording the max edge response over all orientations at each pixel as  described earlier. [sent-91, score-0.93]
</p><p>50 We then apply a watershed transform to this edge strength image to produce a set of superpixels as shown in Figure 1. [sent-92, score-0.664]
</p><p>51 Finally the label weights associated with each pixel are normalized so that they sum to 1. [sent-101, score-0.226]
</p><p>52 We have found in practise that the L matrices constructed in this manner do a significantly better job of capturing the desired eigenvectors than the binary versions. [sent-103, score-0.338]
</p><p>53 Once the L matrix has been constructed we can turn our attention to solving the reduced order eigensystem described in Equation 6. [sent-104, score-0.462]
</p><p>54 We first note that this system is much  smaller than the original system since m is on the order of 5000 where n was on the order of 115000 for the images in our test set. [sent-105, score-0.206]
</p><p>55 First we observe that the reduced order eigensystem is still sparse, if we consider the matrices W? [sent-107, score-0.45]
</p><p>56 = LTDL we note that these matrices will essentially capture the adjacency structure of the watershed superpixels in the image. [sent-109, score-0.232]
</p><p>57 Next observe that we are ultimately interested in finding the eigenvectors associated with the smallest eigenvalues of the generalized eigensystem. [sent-110, score-0.642]
</p><p>58 These eigenvectors can be found using a variant of the Lanczos procedure [10] which is related to the power method and proceeds by repeatedly performing matrix vector multiplications to produce a set of vectors that capture the desired portion of the spectrum. [sent-111, score-0.52]
</p><p>59 The watershed algorithm produced a superpixel segmentation containing 4329 segments. [sent-127, score-0.384]
</p><p>60 The goal in that work was to develop a scheme that could be used to approximate the eigenvectors of a weight matrix that considered the association between every pair of pixels in the image. [sent-134, score-0.535]
</p><p>61 Computing the eigenvectors of such a large system was decidedly unappealing so the authors propose an approach wherein they randomly sampled a subset of the rows of the affinity matrix to form a smaller, dense system involving only a few hundred rows. [sent-135, score-0.478]
</p><p>62 The approach advocated in this paper leverages the observation that in this image segmentation task the edge signal provides useful information about the final structure of the eigenproblem. [sent-137, score-0.527]
</p><p>63 Once the eigenvectors have been computed, the segmentation scheme proceeds along the lines described in [3]. [sent-139, score-0.609]
</p><p>64 Finally we compute the absolute values of the directional derivatives of each of the eigenimages and sum them to produce a spectral edge strength signal, sg (x, y, θ). [sent-142, score-0.577]
</p><p>65 This spectral signal is combined with the oriented edge strength signal produced in the edge extraction phase, sncc(x, y, θ), to produce a final edge strength signal. [sent-143, score-1.628]
</p><p>66 In our experiments we chose to recover the first 31 eigenvectors and σl was set to 400. [sent-145, score-0.289]
</p><p>67 The resulting final oriented edge strength signal, sf (x, y, θ), was passed to the contours2ucm routine provided as part of the Berkeley Segmentation Database to compute the final ultrametic contour map. [sent-146, score-0.557]
</p><p>68 Experimental Results The proposed edge detection and segmentation schemes were evaluated using the Berkeley Segmentation Database, BSDS, with the methods described in [3]. [sent-148, score-0.569]
</p><p>69 The parameters of the segmentation procedure were tuned using the 200 images in the training set and the final procedure was then applied to both the test and validation sets. [sent-149, score-0.303]
</p><p>70 Figure 2 plots the precision recall curve for the Normalized Edge Detection scheme proposed in Section 2. [sent-150, score-0.229]
</p><p>71 Note that the proposed scheme produces results which are comparable to those of the Pb detector on aggregate on this dataset but at a much lower computational cost. [sent-152, score-0.231]
</p><p>72 The precision recall curve of the proposed normalized edge detection scheme on the boundary benchmark of the BSDS 300 evaluation test set. [sent-156, score-0.729]
</p><p>73 Figures 3 and 4 compare the performance of the proposed reduced order segmentation scheme to other segmentation schemes in the literature on the BSDS 300 and BSDS 500 data sets. [sent-157, score-0.699]
</p><p>74 This graph compares the performance of the proposed reduced order normalized cuts segmentation scheme to other methods on the boundary benchmark of the BSDS 300 evaluation test set. [sent-161, score-0.812]
</p><p>75 This graph compares the performance of the proposed reduced order normalized cuts segmentation scheme to other methods on the boundary benchmark of the BSDS 500 evaluation test set. [sent-163, score-0.812]
</p><p>76 The first row shows the input image, the second row shows the re-  sults of the normalized edge detection stage. [sent-166, score-0.5]
</p><p>77 The third row shows the ultrametric contour maps produced by the contours2ucm stage. [sent-167, score-0.212]
</p><p>78 Table 3 indicates the time taken by the four main phases of the proposed segmentation scheme in seconds. [sent-194, score-0.354]
</p><p>79 Here the time taken to perform a segmentation is on the order of 4 minutes. [sent-198, score-0.174]
</p><p>80 The first row contains the input image, the second the results of the Normalized Edge Detector, the third the ultrametric contour maps which include the globalized edge weights. [sent-202, score-0.45]
</p><p>81 Note that the reduced order normalized cut scheme allows us to compute the 3 1smallest eigenvectors within 0. [sent-205, score-0.83]
</p><p>82 777 seconds reported to recover 17 eigenvectors with an optimized GPU implementation [5]. [sent-207, score-0.354]
</p><p>83 In order to investigate how the reduced order approximation affected the quality of the final results. [sent-208, score-0.24]
</p><p>84 That is we computed the eigenvectors of the original unreduced system and used those results for the final segmentation. [sent-210, score-0.353]
</p><p>85 The scores, curves and results were identical to those obtained with the reduced order system. [sent-212, score-0.201]
</p><p>86 The only difference was time, finding the eigenvectors of the full system required on average 430 seconds while solving the reduced system required only 0. [sent-213, score-0.644]
</p><p>87 This suggests that the reduced order system effectively captures the essential structure of the full eigenproblem for this task. [sent-215, score-0.353]
</p><p>88 The edge detection scheme was implemented in a straightforward manner using Matlab’s convolution routines. [sent-217, score-0.506]
</p><p>89 A real time implementation of the normalized edge detection scheme is a distinct possibility. [sent-219, score-0.65]
</p><p>90 This table shows the mean, median and maximum time spent in seconds on each of the four major computational phases when the proposed segmentation procedure was run on the 200 images in the BSDS 500 test set. [sent-225, score-0.432]
</p><p>91 This table shows the average time spent in seconds on each of the major computational phases of the gPb segmentation algorithm the weight matrix construction phase considerably. [sent-228, score-0.528]
</p><p>92 Conclusions  and Future Work  The goal of this paper has been to explore approaches  to accelerating edge detection and segmentation schemes based on the gPb framework by exploiting the underlying structure of the problem. [sent-230, score-0.617]
</p><p>93 To this end we have investigated the performance of an edge extraction scheme based on normalized correlation and shown that, with appropriate tuning, the scheme can be made to produce competitive results without excessive computation. [sent-231, score-0.872]
</p><p>94 This paper also presents ideas for tackling the key bottleneck in the normalized cuts procedure, the computation of generalized eigenvectors. [sent-232, score-0.419]
</p><p>95 We propose a reduced order normalized cut problem which is designed to capture the essential features of the full scale problem. [sent-233, score-0.439]
</p><p>96 The key to this approach is the construction of an appropriate matrix L whose columns provide a good approximation for the eigenvectors of the original system. [sent-234, score-0.39]
</p><p>97 We propose a scheme for constructing such a matrix using an initial superpixel segmentation of the frame and note that the resulting reduced systems exhibit special structure which can be exploited in the eigenvector analysis procedure to further accelerate convergence. [sent-235, score-0.746]
</p><p>98 The normalized edge detection scheme could be used for purposes other than segmentation and the reduced order acceleration could be applied to the output of other edge detectors. [sent-238, score-1.293]
</p><p>99 As an example it would be entirely possible to use the output of the mPb detector as an input to a reduced order normalized cuts system. [sent-239, score-0.527]
</p><p>100 Simi-  larly one can imagine using other superpixel segmentation schemes to construct appropriate L matrices that may provide other benefits. [sent-240, score-0.341]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('edge', 0.307), ('eigenvectors', 0.289), ('bsds', 0.222), ('eigensystem', 0.2), ('cuts', 0.182), ('gpb', 0.165), ('reduced', 0.162), ('scheme', 0.15), ('normalized', 0.144), ('watershed', 0.139), ('cholesky', 0.139), ('segmentation', 0.135), ('meer', 0.124), ('strength', 0.123), ('eigenvalues', 0.12), ('globalization', 0.113), ('wirj', 0.113), ('lx', 0.101), ('mpb', 0.1), ('lanczos', 0.1), ('response', 0.095), ('contour', 0.087), ('signal', 0.085), ('phase', 0.084), ('ois', 0.084), ('procedure', 0.084), ('schemes', 0.078), ('fowlkes', 0.077), ('eigenvector', 0.076), ('catanzaro', 0.075), ('inverses', 0.075), ('ltdl', 0.075), ('sirj', 0.075), ('ods', 0.075), ('extraction', 0.07), ('produced', 0.069), ('pb', 0.069), ('phases', 0.069), ('smallest', 0.068), ('gpu', 0.067), ('georgescu', 0.067), ('seconds', 0.065), ('system', 0.064), ('matlab', 0.064), ('matrix', 0.061), ('spectral', 0.061), ('span', 0.058), ('ultrametric', 0.056), ('platforms', 0.056), ('pri', 0.053), ('intelligence', 0.052), ('sharon', 0.051), ('generalized', 0.051), ('produce', 0.051), ('eigenvalue', 0.05), ('arbelaez', 0.05), ('maire', 0.05), ('matrices', 0.049), ('detection', 0.049), ('breaking', 0.048), ('accelerating', 0.048), ('essential', 0.048), ('reproduced', 0.047), ('pixel', 0.047), ('salient', 0.046), ('cut', 0.046), ('berkeley', 0.045), ('transactions', 0.045), ('edges', 0.045), ('amenable', 0.045), ('recall', 0.044), ('december', 0.044), ('superpixels', 0.044), ('comaniciu', 0.043), ('produces', 0.043), ('rn', 0.042), ('ideas', 0.042), ('superpixel', 0.041), ('spent', 0.041), ('columns', 0.04), ('interested', 0.04), ('oriented', 0.04), ('quite', 0.04), ('captures', 0.04), ('ultimately', 0.039), ('order', 0.039), ('computational', 0.038), ('rand', 0.038), ('construct', 0.038), ('accelerate', 0.037), ('radius', 0.037), ('template', 0.036), ('accelerated', 0.036), ('sg', 0.035), ('weight', 0.035), ('rapidly', 0.035), ('proceeds', 0.035), ('associated', 0.035), ('precision', 0.035), ('impressive', 0.034)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="437-tfidf-1" href="./cvpr-2013-Towards_Fast_and_Accurate_Segmentation.html">437 cvpr-2013-Towards Fast and Accurate Segmentation</a></p>
<p>Author: Camillo Jose Taylor</p><p>Abstract: In this paper we explore approaches to accelerating segmentation and edge detection algorithms based on the gPb framework. The paper characterizes the performance of a simple but effective edge detection scheme which can be computed rapidly and offers performance that is competitive with the pB detector. The paper also describes an approach for computing a reduced order normalized cut that captures the essential features of the original problem but can be computed in less than half a second on a standard computing platform.</p><p>2 0.194493 <a title="437-tfidf-2" href="./cvpr-2013-Boundary_Detection_Benchmarking%3A_Beyond_F-Measures.html">72 cvpr-2013-Boundary Detection Benchmarking: Beyond F-Measures</a></p>
<p>Author: Xiaodi Hou, Alan Yuille, Christof Koch</p><p>Abstract: For an ill-posed problem like boundary detection, human labeled datasets play a critical role. Compared with the active research on finding a better boundary detector to refresh the performance record, there is surprisingly little discussion on the boundary detection benchmark itself. The goal of this paper is to identify the potential pitfalls of today’s most popular boundary benchmark, BSDS 300. In the paper, we first introduce a psychophysical experiment to show that many of the “weak” boundary labels are unreliable and may contaminate the benchmark. Then we analyze the computation of f-measure and point out that the current benchmarking protocol encourages an algorithm to bias towards those problematic “weak” boundary labels. With this evidence, we focus on a new problem of detecting strong boundaries as one alternative. Finally, we assess the performances of 9 major algorithms on different ways of utilizing the dataset, suggesting new directions for improvements.</p><p>3 0.15797523 <a title="437-tfidf-3" href="./cvpr-2013-Perceptual_Organization_and_Recognition_of_Indoor_Scenes_from_RGB-D_Images.html">329 cvpr-2013-Perceptual Organization and Recognition of Indoor Scenes from RGB-D Images</a></p>
<p>Author: Saurabh Gupta, Pablo Arbeláez, Jitendra Malik</p><p>Abstract: We address the problems of contour detection, bottomup grouping and semantic segmentation using RGB-D data. We focus on the challenging setting of cluttered indoor scenes, and evaluate our approach on the recently introduced NYU-Depth V2 (NYUD2) dataset [27]. We propose algorithms for object boundary detection and hierarchical segmentation that generalize the gPb − ucm approach of [se2]g mbeyn mtaatkioinng t effective use oef t dheep gthP information. Wroea schho owf that our system can label each contour with its type (depth, normal or albedo). We also propose a generic method for long-range amodal completion of surfaces and show its effectiveness in grouping. We then turn to the problem of semantic segmentation and propose a simple approach that classifies superpixels into the 40 dominant object categories in NYUD2. We use both generic and class-specific features to encode the appearance and geometry of objects. We also show how our approach can be used for scene classification, and how this contextual information in turn improves object recognition. In all of these tasks, we report significant improvements over the state-of-the-art.</p><p>4 0.13274068 <a title="437-tfidf-4" href="./cvpr-2013-Incorporating_User_Interaction_and_Topological_Constraints_within_Contour_Completion_via_Discrete_Calculus.html">222 cvpr-2013-Incorporating User Interaction and Topological Constraints within Contour Completion via Discrete Calculus</a></p>
<p>Author: Jia Xu, Maxwell D. Collins, Vikas Singh</p><p>Abstract: We study the problem of interactive segmentation and contour completion for multiple objects. The form of constraints our model incorporates are those coming from user scribbles (interior or exterior constraints) as well as information regarding the topology of the 2-D space after partitioning (number of closed contours desired). We discuss how concepts from discrete calculus and a simple identity using the Euler characteristic of a planar graph can be utilized to derive a practical algorithm for this problem. We also present specialized branch and bound methods for the case of single contour completion under such constraints. On an extensive dataset of ∼ 1000 images, our experimOenn tasn suggest vthea dt a assmetal ol fa m∼ou 1n0t0 of ismidaeg knowledge can give strong improvements over fully unsupervised contour completion methods. We show that by interpreting user indications topologically, user effort is substantially reduced.</p><p>5 0.12240206 <a title="437-tfidf-5" href="./cvpr-2013-Winding_Number_for_Region-Boundary_Consistent_Salient_Contour_Extraction.html">468 cvpr-2013-Winding Number for Region-Boundary Consistent Salient Contour Extraction</a></p>
<p>Author: Yansheng Ming, Hongdong Li, Xuming He</p><p>Abstract: This paper aims to extract salient closed contours from an image. For this vision task, both region segmentation cues (e.g. color/texture homogeneity) and boundary detection cues (e.g. local contrast, edge continuity and contour closure) play important and complementary roles. In this paper we show how to combine both cues in a unified framework. The main focus is given to how to maintain the consistency (compatibility) between the region cues and the boundary cues. To this ends, we introduce the use of winding number–a well-known concept in topology–as a powerful mathematical device. By this device, the region-boundary consistency is represented as a set of simple linear relationships. Our method is applied to the figure-ground segmentation problem. The experiments show clearly improved results.</p><p>6 0.11806628 <a title="437-tfidf-6" href="./cvpr-2013-Dense_Non-rigid_Point-Matching_Using_Random_Projections.html">109 cvpr-2013-Dense Non-rigid Point-Matching Using Random Projections</a></p>
<p>7 0.10663323 <a title="437-tfidf-7" href="./cvpr-2013-Image_Segmentation_by_Cascaded_Region_Agglomeration.html">212 cvpr-2013-Image Segmentation by Cascaded Region Agglomeration</a></p>
<p>8 0.10338314 <a title="437-tfidf-8" href="./cvpr-2013-SCALPEL%3A_Segmentation_Cascades_with_Localized_Priors_and_Efficient_Learning.html">370 cvpr-2013-SCALPEL: Segmentation Cascades with Localized Priors and Efficient Learning</a></p>
<p>9 0.096416421 <a title="437-tfidf-9" href="./cvpr-2013-Multi-scale_Curve_Detection_on_Surfaces.html">298 cvpr-2013-Multi-scale Curve Detection on Surfaces</a></p>
<p>10 0.090497606 <a title="437-tfidf-10" href="./cvpr-2013-Improving_an_Object_Detector_and_Extracting_Regions_Using_Superpixels.html">217 cvpr-2013-Improving an Object Detector and Extracting Regions Using Superpixels</a></p>
<p>11 0.087664105 <a title="437-tfidf-11" href="./cvpr-2013-Active_Contours_with_Group_Similarity.html">33 cvpr-2013-Active Contours with Group Similarity</a></p>
<p>12 0.08723034 <a title="437-tfidf-12" href="./cvpr-2013-Efficient_Color_Boundary_Detection_with_Color-Opponent_Mechanisms.html">140 cvpr-2013-Efficient Color Boundary Detection with Color-Opponent Mechanisms</a></p>
<p>13 0.085473776 <a title="437-tfidf-13" href="./cvpr-2013-Joint_Spectral_Correspondence_for_Disparate_Image_Matching.html">234 cvpr-2013-Joint Spectral Correspondence for Disparate Image Matching</a></p>
<p>14 0.084494613 <a title="437-tfidf-14" href="./cvpr-2013-Graph-Based_Optimization_with_Tubularity_Markov_Tree_for_3D_Vessel_Segmentation.html">190 cvpr-2013-Graph-Based Optimization with Tubularity Markov Tree for 3D Vessel Segmentation</a></p>
<p>15 0.084009245 <a title="437-tfidf-15" href="./cvpr-2013-Depth_Acquisition_from_Density_Modulated_Binary_Patterns.html">114 cvpr-2013-Depth Acquisition from Density Modulated Binary Patterns</a></p>
<p>16 0.079641126 <a title="437-tfidf-16" href="./cvpr-2013-A_Principled_Deep_Random_Field_Model_for_Image_Segmentation.html">24 cvpr-2013-A Principled Deep Random Field Model for Image Segmentation</a></p>
<p>17 0.079315722 <a title="437-tfidf-17" href="./cvpr-2013-Constraints_as_Features.html">93 cvpr-2013-Constraints as Features</a></p>
<p>18 0.077885553 <a title="437-tfidf-18" href="./cvpr-2013-Robust_Region_Grouping_via_Internal_Patch_Statistics.html">366 cvpr-2013-Robust Region Grouping via Internal Patch Statistics</a></p>
<p>19 0.075725473 <a title="437-tfidf-19" href="./cvpr-2013-Intrinsic_Scene_Properties_from_a_Single_RGB-D_Image.html">227 cvpr-2013-Intrinsic Scene Properties from a Single RGB-D Image</a></p>
<p>20 0.07470905 <a title="437-tfidf-20" href="./cvpr-2013-Scalable_Sparse_Subspace_Clustering.html">379 cvpr-2013-Scalable Sparse Subspace Clustering</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.209), (1, 0.024), (2, 0.032), (3, 0.039), (4, 0.076), (5, -0.004), (6, 0.024), (7, -0.002), (8, -0.091), (9, -0.027), (10, 0.098), (11, -0.043), (12, -0.015), (13, -0.032), (14, 0.017), (15, 0.003), (16, 0.003), (17, -0.069), (18, 0.01), (19, 0.101), (20, 0.004), (21, 0.107), (22, -0.075), (23, -0.015), (24, 0.02), (25, 0.085), (26, 0.034), (27, -0.035), (28, 0.012), (29, 0.043), (30, 0.095), (31, 0.095), (32, -0.035), (33, -0.034), (34, 0.057), (35, 0.091), (36, 0.054), (37, 0.106), (38, -0.052), (39, 0.105), (40, 0.009), (41, 0.109), (42, 0.02), (43, 0.007), (44, -0.019), (45, -0.015), (46, 0.019), (47, 0.009), (48, 0.078), (49, 0.067)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96191126 <a title="437-lsi-1" href="./cvpr-2013-Towards_Fast_and_Accurate_Segmentation.html">437 cvpr-2013-Towards Fast and Accurate Segmentation</a></p>
<p>Author: Camillo Jose Taylor</p><p>Abstract: In this paper we explore approaches to accelerating segmentation and edge detection algorithms based on the gPb framework. The paper characterizes the performance of a simple but effective edge detection scheme which can be computed rapidly and offers performance that is competitive with the pB detector. The paper also describes an approach for computing a reduced order normalized cut that captures the essential features of the original problem but can be computed in less than half a second on a standard computing platform.</p><p>2 0.87934309 <a title="437-lsi-2" href="./cvpr-2013-Winding_Number_for_Region-Boundary_Consistent_Salient_Contour_Extraction.html">468 cvpr-2013-Winding Number for Region-Boundary Consistent Salient Contour Extraction</a></p>
<p>Author: Yansheng Ming, Hongdong Li, Xuming He</p><p>Abstract: This paper aims to extract salient closed contours from an image. For this vision task, both region segmentation cues (e.g. color/texture homogeneity) and boundary detection cues (e.g. local contrast, edge continuity and contour closure) play important and complementary roles. In this paper we show how to combine both cues in a unified framework. The main focus is given to how to maintain the consistency (compatibility) between the region cues and the boundary cues. To this ends, we introduce the use of winding number–a well-known concept in topology–as a powerful mathematical device. By this device, the region-boundary consistency is represented as a set of simple linear relationships. Our method is applied to the figure-ground segmentation problem. The experiments show clearly improved results.</p><p>3 0.87023985 <a title="437-lsi-3" href="./cvpr-2013-Incorporating_User_Interaction_and_Topological_Constraints_within_Contour_Completion_via_Discrete_Calculus.html">222 cvpr-2013-Incorporating User Interaction and Topological Constraints within Contour Completion via Discrete Calculus</a></p>
<p>Author: Jia Xu, Maxwell D. Collins, Vikas Singh</p><p>Abstract: We study the problem of interactive segmentation and contour completion for multiple objects. The form of constraints our model incorporates are those coming from user scribbles (interior or exterior constraints) as well as information regarding the topology of the 2-D space after partitioning (number of closed contours desired). We discuss how concepts from discrete calculus and a simple identity using the Euler characteristic of a planar graph can be utilized to derive a practical algorithm for this problem. We also present specialized branch and bound methods for the case of single contour completion under such constraints. On an extensive dataset of ∼ 1000 images, our experimOenn tasn suggest vthea dt a assmetal ol fa m∼ou 1n0t0 of ismidaeg knowledge can give strong improvements over fully unsupervised contour completion methods. We show that by interpreting user indications topologically, user effort is substantially reduced.</p><p>4 0.83561248 <a title="437-lsi-4" href="./cvpr-2013-Boundary_Detection_Benchmarking%3A_Beyond_F-Measures.html">72 cvpr-2013-Boundary Detection Benchmarking: Beyond F-Measures</a></p>
<p>Author: Xiaodi Hou, Alan Yuille, Christof Koch</p><p>Abstract: For an ill-posed problem like boundary detection, human labeled datasets play a critical role. Compared with the active research on finding a better boundary detector to refresh the performance record, there is surprisingly little discussion on the boundary detection benchmark itself. The goal of this paper is to identify the potential pitfalls of today’s most popular boundary benchmark, BSDS 300. In the paper, we first introduce a psychophysical experiment to show that many of the “weak” boundary labels are unreliable and may contaminate the benchmark. Then we analyze the computation of f-measure and point out that the current benchmarking protocol encourages an algorithm to bias towards those problematic “weak” boundary labels. With this evidence, we focus on a new problem of detecting strong boundaries as one alternative. Finally, we assess the performances of 9 major algorithms on different ways of utilizing the dataset, suggesting new directions for improvements.</p><p>5 0.79242027 <a title="437-lsi-5" href="./cvpr-2013-Measures_and_Meta-Measures_for_the_Supervised_Evaluation_of_Image_Segmentation.html">281 cvpr-2013-Measures and Meta-Measures for the Supervised Evaluation of Image Segmentation</a></p>
<p>Author: Jordi Pont-Tuset, Ferran Marques</p><p>Abstract: This paper tackles the supervised evaluation of image segmentation algorithms. First, it surveys and structures the measures used to compare the segmentation results with a ground truth database; and proposes a new measure: the precision-recall for objects and parts. To compare the goodness of these measures, it defines three quantitative meta-measures involving six state of the art segmentation methods. The meta-measures consist in assuming some plausible hypotheses about the results and assessing how well each measure reflects these hypotheses. As a conclusion, this paper proposes the precision-recall curves for boundaries and for objects-and-parts as the tool of choice for the supervised evaluation of image segmentation. We make the datasets and code of all the measures publicly available.</p><p>6 0.77786779 <a title="437-lsi-6" href="./cvpr-2013-Efficient_Color_Boundary_Detection_with_Color-Opponent_Mechanisms.html">140 cvpr-2013-Efficient Color Boundary Detection with Color-Opponent Mechanisms</a></p>
<p>7 0.73857915 <a title="437-lsi-7" href="./cvpr-2013-Image_Segmentation_by_Cascaded_Region_Agglomeration.html">212 cvpr-2013-Image Segmentation by Cascaded Region Agglomeration</a></p>
<p>8 0.68750387 <a title="437-lsi-8" href="./cvpr-2013-Active_Contours_with_Group_Similarity.html">33 cvpr-2013-Active Contours with Group Similarity</a></p>
<p>9 0.67683476 <a title="437-lsi-9" href="./cvpr-2013-Fast_Trust_Region_for_Segmentation.html">171 cvpr-2013-Fast Trust Region for Segmentation</a></p>
<p>10 0.66840607 <a title="437-lsi-10" href="./cvpr-2013-Sketch_Tokens%3A_A_Learned_Mid-level_Representation_for_Contour_and_Object_Detection.html">401 cvpr-2013-Sketch Tokens: A Learned Mid-level Representation for Contour and Object Detection</a></p>
<p>11 0.66055721 <a title="437-lsi-11" href="./cvpr-2013-Keypoints_from_Symmetries_by_Wave_Propagation.html">240 cvpr-2013-Keypoints from Symmetries by Wave Propagation</a></p>
<p>12 0.63979518 <a title="437-lsi-12" href="./cvpr-2013-A_Fast_Semidefinite_Approach_to_Solving_Binary_Quadratic_Problems.html">9 cvpr-2013-A Fast Semidefinite Approach to Solving Binary Quadratic Problems</a></p>
<p>13 0.63833737 <a title="437-lsi-13" href="./cvpr-2013-Graph-Based_Optimization_with_Tubularity_Markov_Tree_for_3D_Vessel_Segmentation.html">190 cvpr-2013-Graph-Based Optimization with Tubularity Markov Tree for 3D Vessel Segmentation</a></p>
<p>14 0.62371546 <a title="437-lsi-14" href="./cvpr-2013-Joint_Spectral_Correspondence_for_Disparate_Image_Matching.html">234 cvpr-2013-Joint Spectral Correspondence for Disparate Image Matching</a></p>
<p>15 0.62294233 <a title="437-lsi-15" href="./cvpr-2013-Perceptual_Organization_and_Recognition_of_Indoor_Scenes_from_RGB-D_Images.html">329 cvpr-2013-Perceptual Organization and Recognition of Indoor Scenes from RGB-D Images</a></p>
<p>16 0.60745192 <a title="437-lsi-16" href="./cvpr-2013-SCALPEL%3A_Segmentation_Cascades_with_Localized_Priors_and_Efficient_Learning.html">370 cvpr-2013-SCALPEL: Segmentation Cascades with Localized Priors and Efficient Learning</a></p>
<p>17 0.59585446 <a title="437-lsi-17" href="./cvpr-2013-Reconstructing_Loopy_Curvilinear_Structures_Using_Integer_Programming.html">350 cvpr-2013-Reconstructing Loopy Curvilinear Structures Using Integer Programming</a></p>
<p>18 0.5885762 <a title="437-lsi-18" href="./cvpr-2013-Efficient_Object_Detection_and_Segmentation_for_Fine-Grained_Recognition.html">145 cvpr-2013-Efficient Object Detection and Segmentation for Fine-Grained Recognition</a></p>
<p>19 0.58487421 <a title="437-lsi-19" href="./cvpr-2013-Voxel_Cloud_Connectivity_Segmentation_-_Supervoxels_for_Point_Clouds.html">458 cvpr-2013-Voxel Cloud Connectivity Segmentation - Supervoxels for Point Clouds</a></p>
<p>20 0.58067936 <a title="437-lsi-20" href="./cvpr-2013-Robust_Region_Grouping_via_Internal_Patch_Statistics.html">366 cvpr-2013-Robust Region Grouping via Internal Patch Statistics</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.11), (16, 0.034), (26, 0.052), (33, 0.3), (67, 0.081), (69, 0.053), (87, 0.084), (97, 0.21)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.87951052 <a title="437-lda-1" href="./cvpr-2013-Ensemble_Learning_for_Confidence_Measures_in_Stereo_Vision.html">147 cvpr-2013-Ensemble Learning for Confidence Measures in Stereo Vision</a></p>
<p>Author: Ralf Haeusler, Rahul Nair, Daniel Kondermann</p><p>Abstract: With the aim to improve accuracy of stereo confidence measures, we apply the random decision forest framework to a large set of diverse stereo confidence measures. Learning and testing sets were drawnfrom the recently introduced KITTI dataset, which currently poses higher challenges to stereo solvers than other benchmarks with ground truth for stereo evaluation. We experiment with semi global matching stereo (SGM) and a census dataterm, which is the best performing realtime capable stereo method known to date. On KITTI images, SGM still produces a significant amount of error. We obtain consistently improved area under curve values of sparsification measures in comparison to best performing single stereo confidence measures where numbers of stereo errors are large. More specifically, our method performs best in all but one out of 194 frames of the KITTI dataset.</p><p>same-paper 2 0.87264681 <a title="437-lda-2" href="./cvpr-2013-Towards_Fast_and_Accurate_Segmentation.html">437 cvpr-2013-Towards Fast and Accurate Segmentation</a></p>
<p>Author: Camillo Jose Taylor</p><p>Abstract: In this paper we explore approaches to accelerating segmentation and edge detection algorithms based on the gPb framework. The paper characterizes the performance of a simple but effective edge detection scheme which can be computed rapidly and offers performance that is competitive with the pB detector. The paper also describes an approach for computing a reduced order normalized cut that captures the essential features of the original problem but can be computed in less than half a second on a standard computing platform.</p><p>3 0.86931366 <a title="437-lda-3" href="./cvpr-2013-Spatiotemporal_Deformable_Part_Models_for_Action_Detection.html">408 cvpr-2013-Spatiotemporal Deformable Part Models for Action Detection</a></p>
<p>Author: Yicong Tian, Rahul Sukthankar, Mubarak Shah</p><p>Abstract: Deformable part models have achieved impressive performance for object detection, even on difficult image datasets. This paper explores the generalization of deformable part models from 2D images to 3D spatiotemporal volumes to better study their effectiveness for action detection in video. Actions are treated as spatiotemporal patterns and a deformable part model is generated for each action from a collection of examples. For each action model, the most discriminative 3D subvolumes are automatically selected as parts and the spatiotemporal relations between their locations are learned. By focusing on the most distinctive parts of each action, our models adapt to intra-class variation and show robustness to clutter. Extensive experiments on several video datasets demonstrate the strength of spatiotemporal DPMs for classifying and localizing actions.</p><p>4 0.85480946 <a title="437-lda-4" href="./cvpr-2013-Human_Pose_Estimation_Using_a_Joint_Pixel-wise_and_Part-wise_Formulation.html">207 cvpr-2013-Human Pose Estimation Using a Joint Pixel-wise and Part-wise Formulation</a></p>
<p>Author: Ľ</p><p>Abstract: Our goal is to detect humans and estimate their 2D pose in single images. In particular, handling cases of partial visibility where some limbs may be occluded or one person is partially occluding another. Two standard, but disparate, approaches have developed in the field: the first is the part based approach for layout type problems, involving optimising an articulated pictorial structure; the second is the pixel based approach for image labelling involving optimising a random field graph defined on the image. Our novel contribution is a formulation for pose estimation which combines these two models in a principled way in one optimisation problem and thereby inherits the advantages of both of them. Inference on this joint model finds the set of instances of persons in an image, the location of their joints, and a pixel-wise body part labelling. We achieve near or state of the art results on standard human pose data sets, and demonstrate the correct estimation for cases of self-occlusion, person overlap and image truncation.</p><p>5 0.84908611 <a title="437-lda-5" href="./cvpr-2013-Understanding_Indoor_Scenes_Using_3D_Geometric_Phrases.html">446 cvpr-2013-Understanding Indoor Scenes Using 3D Geometric Phrases</a></p>
<p>Author: Wongun Choi, Yu-Wei Chao, Caroline Pantofaru, Silvio Savarese</p><p>Abstract: Visual scene understanding is a difficult problem interleaving object detection, geometric reasoning and scene classification. We present a hierarchical scene model for learning and reasoning about complex indoor scenes which is computationally tractable, can be learned from a reasonable amount of training data, and avoids oversimplification. At the core of this approach is the 3D Geometric Phrase Model which captures the semantic and geometric relationships between objects whichfrequently co-occur in the same 3D spatial configuration. Experiments show that this model effectively explains scene semantics, geometry and object groupings from a single image, while also improving individual object detections.</p><p>6 0.8489641 <a title="437-lda-6" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>7 0.84794873 <a title="437-lda-7" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<p>8 0.847803 <a title="437-lda-8" href="./cvpr-2013-Label_Propagation_from_ImageNet_to_3D_Point_Clouds.html">242 cvpr-2013-Label Propagation from ImageNet to 3D Point Clouds</a></p>
<p>9 0.84678233 <a title="437-lda-9" href="./cvpr-2013-Detecting_and_Aligning_Faces_by_Image_Retrieval.html">119 cvpr-2013-Detecting and Aligning Faces by Image Retrieval</a></p>
<p>10 0.84594107 <a title="437-lda-10" href="./cvpr-2013-Integrating_Grammar_and_Segmentation_for_Human_Pose_Estimation.html">225 cvpr-2013-Integrating Grammar and Segmentation for Human Pose Estimation</a></p>
<p>11 0.84584039 <a title="437-lda-11" href="./cvpr-2013-PISA%3A_Pixelwise_Image_Saliency_by_Aggregating_Complementary_Appearance_Contrast_Measures_with_Spatial_Priors.html">322 cvpr-2013-PISA: Pixelwise Image Saliency by Aggregating Complementary Appearance Contrast Measures with Spatial Priors</a></p>
<p>12 0.84558117 <a title="437-lda-12" href="./cvpr-2013-Hierarchical_Saliency_Detection.html">202 cvpr-2013-Hierarchical Saliency Detection</a></p>
<p>13 0.84548014 <a title="437-lda-13" href="./cvpr-2013-A_Joint_Model_for_2D_and_3D_Pose_Estimation_from_a_Single_Image.html">14 cvpr-2013-A Joint Model for 2D and 3D Pose Estimation from a Single Image</a></p>
<p>14 0.84525007 <a title="437-lda-14" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<p>15 0.84511441 <a title="437-lda-15" href="./cvpr-2013-A_Lazy_Man%27s_Approach_to_Benchmarking%3A_Semisupervised_Classifier_Evaluation_and_Recalibration.html">15 cvpr-2013-A Lazy Man's Approach to Benchmarking: Semisupervised Classifier Evaluation and Recalibration</a></p>
<p>16 0.84485692 <a title="437-lda-16" href="./cvpr-2013-Cross-View_Action_Recognition_via_a_Continuous_Virtual_Path.html">98 cvpr-2013-Cross-View Action Recognition via a Continuous Virtual Path</a></p>
<p>17 0.84466708 <a title="437-lda-17" href="./cvpr-2013-Context-Aware_Modeling_and_Recognition_of_Activities_in_Video.html">94 cvpr-2013-Context-Aware Modeling and Recognition of Activities in Video</a></p>
<p>18 0.84457076 <a title="437-lda-18" href="./cvpr-2013-Learning_Structured_Hough_Voting_for_Joint_Object_Detection_and_Occlusion_Reasoning.html">256 cvpr-2013-Learning Structured Hough Voting for Joint Object Detection and Occlusion Reasoning</a></p>
<p>19 0.84432667 <a title="437-lda-19" href="./cvpr-2013-Incorporating_Structural_Alternatives_and_Sharing_into_Hierarchy_for_Multiclass_Object_Recognition_and_Detection.html">221 cvpr-2013-Incorporating Structural Alternatives and Sharing into Hierarchy for Multiclass Object Recognition and Detection</a></p>
<p>20 0.8441816 <a title="437-lda-20" href="./cvpr-2013-Part_Discovery_from_Partial_Correspondence.html">325 cvpr-2013-Part Discovery from Partial Correspondence</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
