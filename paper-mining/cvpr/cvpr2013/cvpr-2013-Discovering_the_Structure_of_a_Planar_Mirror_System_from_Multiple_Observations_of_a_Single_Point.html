<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>127 cvpr-2013-Discovering the Structure of a Planar Mirror System from Multiple Observations of a Single Point</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-127" href="#">cvpr2013-127</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>127 cvpr-2013-Discovering the Structure of a Planar Mirror System from Multiple Observations of a Single Point</h1>
<br/><p>Source: <a title="cvpr-2013-127-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Reshetouski_Discovering_the_Structure_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Ilya Reshetouski, Alkhazur Manakov, Ayush Bandhari, Ramesh Raskar, Hans-Peter Seidel, Ivo Ihrke</p><p>Abstract: We investigate the problem of identifying the position of a viewer inside a room of planar mirrors with unknown geometry in conjunction with the room’s shape parameters. We consider the observations to consist of angularly resolved depth measurements of a single scene point that is being observed via many multi-bounce interactions with the specular room geometry. Applications of this problem statement include areas such as calibration, acoustic echo cancelation and time-of-flight imaging. We theoretically analyze the problem and derive sufficient conditions for a combination of convex room geometry, observer, and scene point to be reconstructable. The resulting constructive algorithm is exponential in nature and, therefore, not directly applicable to practical scenarios. To counter the situation, we propose theoretically devised geometric constraints that enable an efficient pruning of the solution space and develop a heuristic randomized search algorithm that uses these constraints to obtain an effective solution. We demonstrate the effectiveness of our algorithm on extensive simulations as well as in a challenging real-world calibration scenario.</p><p>Reference: <a title="cvpr-2013-127-reference" href="../cvpr2013_reference/cvpr-2013-Discovering_the_Structure_of_a_Planar_Mirror_System_from_Multiple_Observations_of_a_Single_Point_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Examples using curved mirror surfaces include catadioptric imaging [21], reflectance [6, 8], and texture [12] measurement systems. [sent-10, score-0.567]
</p><p>2 Planar mirror systems have been used for multi-view imaging of flat [9] and extended depth samples [7, 19] and for confocal imaging [15, 17]. [sent-11, score-0.546]
</p><p>3 The pose estimation problem for a calibrated mirror geometry has recently been investigated by Ramalingam et al. [sent-20, score-0.616]
</p><p>4 In contrast, we aim at determining the geometry of a room of mirrors in conjunction with the camera pose. [sent-22, score-0.542]
</p><p>5 Our main result is that this is often possible given the depth-resolved imaging of many inter-reflections of a single scene point in case of a convex room geometry and we  derive sufficient conditions for a configuration to be recoverable. [sent-23, score-0.476]
</p><p>6 In practice, this lets us deal with221D rooms that have a floor and a ceiling orthogonal to the mirror walls. [sent-25, score-0.577]
</p><p>7 Simulation experiments show that a large class of room configurations is recoverable, however, the recovery rate decreases with the number of mirror walls. [sent-26, score-0.758]
</p><p>8 We also demonstrate our method in a practical calibration example where we estimate the mirror geometry and camera pose for a system with many inter-reflections. [sent-27, score-0.659]
</p><p>9 Our approach enables the recovery of the geometry of a mirror room from camera observations in more general settings than previously available techniques. [sent-31, score-0.858]
</p><p>10 The scene consists of a room with specular walls 888999  and one scene point (dark green), as well as a recording device (red). [sent-36, score-0.385]
</p><p>11 The receiver is capable of measuring the incidence angle and the distance of the point via the reflected ray paths without being able to detect the specular interaction. [sent-87, score-0.425]
</p><p>12 The mirroring room geometry (faint yellow) is unknown and has to be recovered from the point measurements. [sent-89, score-0.403]
</p><p>13 The task is to reconstruct the positions of the unknown mirror planes and to locate the receiver with respect to the mirror system. [sent-93, score-1.296]
</p><p>14 1 (b), we show how the receiver could na¨ıvely interpret the surrounding world as a virtual mirror world consisting of many point objects at different distances. [sent-95, score-0.861]
</p><p>15 In a sense, their paper describes the solution to a dual problem: Given the mirror geometry, compute the object. [sent-99, score-0.516]
</p><p>16 In the current paper, we consider the object geometry to be given (a single point) at different virtual locations but the mirror room geometry has to be recovered. [sent-100, score-0.994]
</p><p>17 Any real mirror system will fail to subdivide the plane perfectly when generating the unfolded representation of the mirror world, the condition for a perfect division being that the mirror operations induced by the walls form a group structure. [sent-104, score-1.687]
</p><p>18 The discontinuity lines correspond to mirror corners being hit by a ray bundle after a sequence of reflections. [sent-108, score-0.678]
</p><p>19 Intuitively, the bundle splits up at these points and traverses different mirror sequences thereafter. [sent-109, score-0.542]
</p><p>20 The numbers indicate mirrors in the base chamber (faint yellow) and their respective reflections. [sent-112, score-0.378]
</p><p>21 The pink lines mark Reshetouski’s “lines of discontinuity” [19] that split areas of different mirror sequences. [sent-113, score-0.546]
</p><p>22 As an example, there is exactly one ray among those that traverse the mirror sequence  L1 = (2) that hits the object point. [sent-123, score-0.6]
</p><p>23 In the following, we will discuss a solution for recovering the mirror room geometry including the occlusions introduced by nongroup mirror systems as well as the position of the receiver within such system. [sent-134, score-1.593]
</p><p>24 Our method allows for the recovery of convex room geometries with an arbitrary unknown number of mirror walls. [sent-135, score-0.812]
</p><p>25 In order to discuss ourrecovery algorithm it is necessary to introduce a few definitions as well 999000  as to explore some properties of mirror systems. [sent-142, score-0.516]
</p><p>26 Our main tool for recovery is a validation procedure: Given a candidate configu-  ration (consisting of mirror geometry, observer position and scene point position), determine if this configuration is compatible with the observations. [sent-143, score-0.735]
</p><p>27 By a closed convex room we mean a room that is equal to its convex hull. [sent-170, score-0.492]
</p><p>28 These are easier to deal with initially because mirror walls cannot be exchanged by an invariant transformation that keeps the mirror system apparently unchanged. [sent-172, score-1.123]
</p><p>29 This condition is satisfied if the point is at different distances to each of the mirror walls. [sent-174, score-0.564]
</p><p>30 The condition that the perspective center of the receiver is within the mirroring room is needed to uniquely predict the pose of the receiver with respect to the reconstructed mirror geometry. [sent-175, score-1.229]
</p><p>31 We also consider the number of mirror walls of the room geometry to be unknown. [sent-179, score-0.899]
</p><p>32 Under these conditions, we first derive constraints and conditions that allow for the reconstruction of the mirror geometry from the virtual point distribution. [sent-183, score-0.754]
</p><p>33 The sequence of mirror operations leading up to this event is the same for the two points, i. [sent-188, score-0.578]
</p><p>34 is a mirror operation that is completely determined by the two points A and A? [sent-198, score-0.538]
</p><p>35 The doublet from the inset figure (marked) and all other doublets in the system of Fig. [sent-202, score-0.746]
</p><p>36 Doublets belonging to the same physical mirror are marked with the same color. [sent-205, score-0.516]
</p><p>37 They usually appear in different locations of the virtual mirror world. [sent-206, score-0.58]
</p><p>38 Definition: A triplet is a pair of doublets T = (D, D? [sent-208, score-0.67]
</p><p>39 Properties: A triplet defines the angle between two mirror planes. [sent-211, score-0.64]
</p><p>40 This often is a corner of the mirror room reflected to some position in the virtual mirror world. [sent-212, score-1.394]
</p><p>41 It may happen though that two doublets that do not correspond to directly adjacent mirrors form a triplet. [sent-213, score-0.742]
</p><p>42 Nevertheless, the angle between these two mirror planes is fixed by the triplet. [sent-214, score-0.551]
</p><p>43 We will refer to the doublets that constitute the triplet as its legs. [sent-215, score-0.67]
</p><p>44 As in the case of doublets, a triplet can typically not be transformed to the base chamber without knowing the remaining geometry of the mirror world since an unspecified sequence of reflections lies between the observed position and the canonical position of the legs in the base chamber. [sent-216, score-1.217]
</p><p>45 Some examples of triplets in conjunction with the mirror corners defined by them are shown in Fig. [sent-217, score-0.802]
</p><p>46 It should be noted though that all adjacent doublets form triplets even though we only show a subset of them. [sent-219, score-0.8]
</p><p>47 As can be seen, doublets usually occur several times, making them stable features of the system. [sent-225, score-0.546]
</p><p>48 Moreover, combinations of doublets are repeated throughout the system. [sent-226, score-0.546]
</p><p>49 Middle: Doublets can be joined into triplets that are indicative of room corners. [sent-228, score-0.507]
</p><p>50 This way, a candidate room geometry can be recovered in some virtual location. [sent-230, score-0.42]
</p><p>51 In this position, the candidate geometry serves as a base chamber from which the a representation of the mirror world can be computed by an unfolding  procedure. [sent-233, score-0.895]
</p><p>52 Given two triplets with a common leg, we therefore have two options ofjoining them resulting in two candidate quadruplets that fix two potentially consistent relative positions and orientations of three mirror planes. [sent-242, score-0.837]
</p><p>53 In the current discussion we assume that doublets and triplets that are being observed in different locations can be identified and that no erroneous doublets or triplets exist. [sent-244, score-1.625]
</p><p>54 In practice, the identification of doublets is based on their length which is twice the distance to the corresponding mirror plane. [sent-247, score-1.062]
</p><p>55 Since we assumed that the object point is in general position with respect to all mirror planes this identification can easily be performed, yielding equivalence classes of doublets. [sent-248, score-0.659]
</p><p>56 3 (left,middle), the equivalence classes are color-coded with doublets of the same color, and triplets of the same color pair, belonging to the same class, respectively. [sent-251, score-0.842]
</p><p>57 In the following, we will drop the explicit mention of the equivalence classes, simply referring to them as doublets or triplets, it should be understood, however, that individual doublets or triplets are only representatives of their class. [sent-252, score-1.388]
</p><p>58 Conditions for Reconstructability A necessary condition for the proposed algorithm to work is that all doublets are being observed by the system, i. [sent-255, score-0.593]
</p><p>59 all mirrors in the room must be observed by their action on a set of two points. [sent-257, score-0.435]
</p><p>60 Consider the case of N doublets (which in the perfect case considered here corresponds to exactly N mirror walls in the room geometry), then the minimum amount of triplets that could yield a solution is N 1. [sent-259, score-1.599]
</p><p>61 ph C ownhsiedree rth ae g gnraodphes atrreu cdtouurebl tehtast ta wnde there are edges if a triplet with the two doublets in question exists. [sent-263, score-0.67]
</p><p>62 Verification Algorithm The algorithm for joining triplets into a candidate room configuration is then the discovery of connected components. [sent-278, score-0.639]
</p><p>63 We join the object point C in the reconstructed room with the receiver position R by a line of sight shown in black. [sent-289, score-0.533]
</p><p>64 The line of sight intersects exactly one mirror plane which must be the mirror that produced the virtual object point C. [sent-290, score-1.146]
</p><p>65 If the candidate configuration is correct, this mirror is the last in the reflection sequence leading up to the observation of C. [sent-291, score-0.747]
</p><p>66 Therefore, we can determine visibility inside the mirror system by Reshetouski unfolding [19]. [sent-296, score-0.569]
</p><p>67 Further, the number of all possible triplets is quadratic in the number of nodes in the doublet graph. [sent-314, score-0.432]
</p><p>68 An illustration of all potential doublets in an example configuration is depicted in Fig. [sent-318, score-0.643]
</p><p>69 In this figure, the real doublets are shown in red whereas pairs of points that are no doublets  are shown in light blue. [sent-320, score-1.092]
</p><p>70 As can be seen, the number of false doublets is far larger than the number of real ones, making an exhaustive search strategy on the full graph structure extremely costly. [sent-323, score-0.632]
</p><p>71 Geometric Search Space Pruning We therefore derive a number of filtering operations that are intended to reduce the number of potential doublets and the potential number of triplets that are built from them, effectively pruning the search space. [sent-326, score-0.956]
</p><p>72 Our filtering operations exploit the geometric features of a mirror configuration that impose strong constraints on valid distributions of observation points. [sent-329, score-0.602]
</p><p>73 999333  Using the assumption that our room is convex we can conclude, that AD entirely belongs to chamber C. [sent-355, score-0.386]
</p><p>74 When building potential triplets, we verify that the constituent doublets are compatible with each other. [sent-399, score-0.606]
</p><p>75 The left part of the figure shows an impossible case since proper doublets have a unique reflection sequence in the complete triangle spanned by the receiver and the doublet. [sent-401, score-0.882]
</p><p>76 In the situation on the right, the two doublets clearly do not conflict. [sent-424, score-0.567]
</p><p>77 The figure shows two triplets built from potential doublets D1 and D2, and D1 and D3, respectively. [sent-429, score-0.837]
</p><p>78 When a new triplet is joined in, all doublets have to be checked for compatibility, again due to the non-transitivity of the relation. [sent-432, score-0.709]
</p><p>79 The importance scores are based on doublet and triplet statistics (correct doublets and triplets occur more often) and compatibility checks as outlined in Sect. [sent-450, score-1.143]
</p><p>80 on the length of potential doublets to account for the expected variation. [sent-463, score-0.583]
</p><p>81 This in turn puts constraints on the point’s position with respect to the mirror planes. [sent-464, score-0.556]
</p><p>82 However, even in this case there is a chance that the correct mirror structure is recovered due to the randomized nature of the algorithm. [sent-466, score-0.556]
</p><p>83 We were using this constraint to terminate the repeated backward mirror operation necessary for the validation of candidate configurations. [sent-469, score-0.58]
</p><p>84 However, the position of the camera with respect to the mirror geometry can only be recovered up 999444  plots show the number reconstructable systems versus the number of reflections considered for the reconstruction task. [sent-472, score-0.825]
</p><p>85 3 and consider that the backward mirroring operation is stopped early, yielding one possible position and orientation with respect to the reconstructed mirror geometry for each possible stopping position. [sent-496, score-0.741]
</p><p>86 mirrors are not meeting at a corner or if the field of view of the receiver is restricted. [sent-503, score-0.424]
</p><p>87 We randomly generated 2000 different convex mirror systems with random object point positions for each n-gon, where n ∈ [3. [sent-508, score-0.574]
</p><p>88 We did not pay attention to include or exclude any particular reflection level such as the direct observation in our simulated mirror systems. [sent-517, score-0.609]
</p><p>89 To avoid a bias in the statistics due to extreme configurations, we limited the systems  to a ratio of 3 : 1between the largest mirror and the smallest one. [sent-518, score-0.516]
</p><p>90 If the number of mirror walls in the geometry increases, our chances of success decrease rapidly. [sent-539, score-0.685]
</p><p>91 In the vast majority of cases, the reason for a failure to reconstruct the geometry is that doublets are missing from the observation, see Fig. [sent-540, score-0.666]
</p><p>92 This indicates that some mirror planes are never observed via a direct reflection in many cases. [sent-542, score-0.669]
</p><p>93 Once sufficiently many doublets are observed, the failure to identify sufficiently many triplets is not a serious problem, Fig. [sent-543, score-0.82]
</p><p>94 The results for our randomized search strategy, which constitutes our practical reconstruction algorithm, show that for a low number n of mirror walls we can perform a reasonable job. [sent-545, score-0.679]
</p><p>95 8 (right) where we rendered the multiply reflected mirror planes as semitransparent polygons. [sent-567, score-0.574]
</p><p>96 The results show that we can reconstruct a mirror geometry even from real-world samples. [sent-568, score-0.616]
</p><p>97 The remaining mismatches can be attributed to the manual setup and alignment of the mirrors as well as to imperfect orthogonality between the ground and ceiling planes and the mirror walls. [sent-570, score-0.777]
</p><p>98 Discussion and Conclusions  We have shown that it is possible to reconstruct the geometry of a convex room of mirrors from the measurement of a single scene point and we have identified sufficient conditions for doing so. [sent-572, score-0.635]
</p><p>99 The goal would be to identify the class of reconstructable mirror systems. [sent-577, score-0.572]
</p><p>100 In particular, our definitions of doublets and triplets rely on a single bounce separation of two observed points. [sent-578, score-0.867]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('doublets', 0.546), ('mirror', 0.516), ('triplets', 0.254), ('room', 0.214), ('receiver', 0.207), ('mirrors', 0.196), ('doublet', 0.178), ('chamber', 0.14), ('triplet', 0.124), ('geometry', 0.1), ('reflection', 0.093), ('reflections', 0.088), ('maa', 0.076), ('specular', 0.076), ('walls', 0.069), ('virtual', 0.064), ('configuration', 0.06), ('reconstructable', 0.056), ('reshetouski', 0.051), ('mn', 0.05), ('ray', 0.048), ('candidate', 0.042), ('base', 0.042), ('equivalence', 0.042), ('bounce', 0.042), ('compatibility', 0.041), ('mirroring', 0.041), ('randomized', 0.04), ('position', 0.04), ('joined', 0.039), ('joining', 0.039), ('mab', 0.038), ('potential', 0.037), ('sequence', 0.036), ('planes', 0.035), ('recoverable', 0.034), ('simulation', 0.033), ('exhaustive', 0.032), ('convex', 0.032), ('conjunction', 0.032), ('sonar', 0.031), ('unfolding', 0.031), ('rooms', 0.031), ('lines', 0.03), ('connected', 0.03), ('ceiling', 0.03), ('simulations', 0.03), ('confocal', 0.03), ('lidar', 0.03), ('search', 0.029), ('planar', 0.029), ('subsequence', 0.028), ('catadioptric', 0.028), ('verification', 0.028), ('recovery', 0.028), ('pruning', 0.027), ('operations', 0.026), ('point', 0.026), ('apparent', 0.026), ('bundle', 0.026), ('angularly', 0.025), ('lbm', 0.025), ('mbb', 0.025), ('quadruplet', 0.025), ('quadruplets', 0.025), ('rroooomm', 0.025), ('velten', 0.025), ('graph', 0.025), ('surround', 0.025), ('reconstruction', 0.025), ('paths', 0.025), ('observed', 0.025), ('sight', 0.024), ('world', 0.024), ('measurement', 0.023), ('conditions', 0.023), ('compatible', 0.023), ('reflected', 0.023), ('ghosts', 0.023), ('lna', 0.023), ('condition', 0.022), ('operation', 0.022), ('discontinuity', 0.022), ('reconstructed', 0.022), ('kutulakos', 0.022), ('unknown', 0.022), ('system', 0.022), ('exponential', 0.021), ('situation', 0.021), ('sufficient', 0.021), ('flavors', 0.021), ('faint', 0.021), ('calibration', 0.021), ('corner', 0.021), ('failure', 0.02), ('lan', 0.02), ('incidence', 0.02), ('odd', 0.02), ('continued', 0.02), ('continuing', 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000007 <a title="127-tfidf-1" href="./cvpr-2013-Discovering_the_Structure_of_a_Planar_Mirror_System_from_Multiple_Observations_of_a_Single_Point.html">127 cvpr-2013-Discovering the Structure of a Planar Mirror System from Multiple Observations of a Single Point</a></p>
<p>Author: Ilya Reshetouski, Alkhazur Manakov, Ayush Bandhari, Ramesh Raskar, Hans-Peter Seidel, Ivo Ihrke</p><p>Abstract: We investigate the problem of identifying the position of a viewer inside a room of planar mirrors with unknown geometry in conjunction with the room’s shape parameters. We consider the observations to consist of angularly resolved depth measurements of a single scene point that is being observed via many multi-bounce interactions with the specular room geometry. Applications of this problem statement include areas such as calibration, acoustic echo cancelation and time-of-flight imaging. We theoretically analyze the problem and derive sufficient conditions for a combination of convex room geometry, observer, and scene point to be reconstructable. The resulting constructive algorithm is exponential in nature and, therefore, not directly applicable to practical scenarios. To counter the situation, we propose theoretically devised geometric constraints that enable an efficient pruning of the solution space and develop a heuristic randomized search algorithm that uses these constraints to obtain an effective solution. We demonstrate the effectiveness of our algorithm on extensive simulations as well as in a challenging real-world calibration scenario.</p><p>2 0.36312333 <a title="127-tfidf-2" href="./cvpr-2013-Mirror_Surface_Reconstruction_from_a_Single_Image.html">286 cvpr-2013-Mirror Surface Reconstruction from a Single Image</a></p>
<p>Author: Miaomiao Liu, Richard Hartley, Mathieu Salzmann</p><p>Abstract: This paper tackles the problem of reconstructing the shape of a smooth mirror surface from a single image. In particular, we consider the case where the camera is observing the reflection of a static reference target in the unknown mirror. We first study the reconstruction problem given dense correspondences between 3D points on the reference target and image locations. In such conditions, our differential geometry analysis provides a theoretical proof that the shape of the mirror surface can be uniquely recovered if the pose of the reference target is known. We then relax our assumptions by considering the case where only sparse correspondences are available. In this scenario, we formulate reconstruction as an optimization problem, which can be solved using a nonlinear least-squares method. We demonstrate the effectiveness of our method on both synthetic and real images.</p><p>3 0.21685699 <a title="127-tfidf-3" href="./cvpr-2013-Single_Image_Calibration_of_Multi-axial_Imaging_Systems.html">400 cvpr-2013-Single Image Calibration of Multi-axial Imaging Systems</a></p>
<p>Author: Amit Agrawal, Srikumar Ramalingam</p><p>Abstract: Imaging systems consisting of a camera looking at multiple spherical mirrors (reflection) or multiple refractive spheres (refraction) have been used for wide-angle imaging applications. We describe such setups as multi-axial imaging systems, since a single sphere results in an axial system. Assuming an internally calibrated camera, calibration of such multi-axial systems involves estimating the sphere radii and locations in the camera coordinate system. However, previous calibration approaches require manual intervention or constrained setups. We present a fully automatic approach using a single photo of a 2D calibration grid. The pose of the calibration grid is assumed to be unknown and is also recovered. Our approach can handle unconstrained setups, where the mirrors/refractive balls can be arranged in any fashion, not necessarily on a grid. The axial nature of rays allows us to compute the axis of each sphere separately. We then show that by choosing rays from two or more spheres, the unknown pose of the calibration grid can be obtained linearly and independently of sphere radii and locations. Knowing the pose, we derive analytical solutions for obtaining the sphere radius and location. This leads to an interesting result that 6-DOF pose estimation of a multi-axial camera can be done without the knowledge of full calibration. Simulations and real experiments demonstrate the applicability of our algorithm.</p><p>4 0.10925777 <a title="127-tfidf-4" href="./cvpr-2013-Understanding_Bayesian_Rooms_Using_Composite_3D_Object_Models.html">445 cvpr-2013-Understanding Bayesian Rooms Using Composite 3D Object Models</a></p>
<p>Author: Luca Del_Pero, Joshua Bowdish, Bonnie Kermgard, Emily Hartley, Kobus Barnard</p><p>Abstract: We develop a comprehensive Bayesian generative model for understanding indoor scenes. While it is common in this domain to approximate objects with 3D bounding boxes, we propose using strong representations with finer granularity. For example, we model a chair as a set of four legs, a seat and a backrest. We find that modeling detailed geometry improves recognition and reconstruction, and enables more refined use of appearance for scene understanding. We demonstrate this with a new likelihood function that re- wards 3D object hypotheses whose 2D projection is more uniform in color distribution. Such a measure would be confused by background pixels if we used a bounding box to represent a concave object like a chair. Complex objects are modeled using a set or re-usable 3D parts, and we show that this representation captures much of the variation among object instances with relatively few parameters. We also designed specific data-driven inference mechanismsfor eachpart that are shared by all objects containing that part, which helps make inference transparent to the modeler. Further, we show how to exploit contextual relationships to detect more objects, by, for example, proposing chairs around and underneath tables. We present results showing the benefits of each of these innovations. The performance of our approach often exceeds that of state-of-the-art methods on the two tasks of room layout estimation and object recognition, as evaluated on two bench mark data sets used in this domain. work. 1) Detailed geometric models, such as tables with legs and top (bottom left), provide better reconstructions than plain boxes (top right), when supported by image features such as geometric context [5] (top middle), or an approach to using color introduced here. 2) Non convex models allow for complex configurations, such as a chair under a table (bottom middle). 3) 3D contextual relationships, such as chairs being around a table, allow identifying objects supported by little image evidence, like the chair behind the table (bottom right). Best viewed in color.</p><p>5 0.10384792 <a title="127-tfidf-5" href="./cvpr-2013-Specular_Reflection_Separation_Using_Dark_Channel_Prior.html">410 cvpr-2013-Specular Reflection Separation Using Dark Channel Prior</a></p>
<p>Author: Hyeongwoo Kim, Hailin Jin, Sunil Hadap, Inso Kweon</p><p>Abstract: We present a novel method to separate specular reflection from a single image. Separating an image into diffuse and specular components is an ill-posed problem due to lack of observations. Existing methods rely on a specularfree image to detect and estimate specularity, which however may confuse diffuse pixels with the same hue but a different saturation value as specular pixels. Our method is based on a novel observation that for most natural images the dark channel can provide an approximate specular-free image. We also propose a maximum a posteriori formulation which robustly recovers the specular reflection and chromaticity despite of the hue-saturation ambiguity. We demonstrate the effectiveness of the proposed algorithm on real and synthetic examples. Experimental results show that our method significantly outperforms the state-of-theart methods in separating specular reflection.</p><p>6 0.096884876 <a title="127-tfidf-6" href="./cvpr-2013-A_Theory_of_Refractive_Photo-Light-Path_Triangulation.html">27 cvpr-2013-A Theory of Refractive Photo-Light-Path Triangulation</a></p>
<p>7 0.079225987 <a title="127-tfidf-7" href="./cvpr-2013-Understanding_Indoor_Scenes_Using_3D_Geometric_Phrases.html">446 cvpr-2013-Understanding Indoor Scenes Using 3D Geometric Phrases</a></p>
<p>8 0.066617988 <a title="127-tfidf-8" href="./cvpr-2013-Video_Enhancement_of_People_Wearing_Polarized_Glasses%3A_Darkening_Reversal_and_Reflection_Reduction.html">454 cvpr-2013-Video Enhancement of People Wearing Polarized Glasses: Darkening Reversal and Reflection Reduction</a></p>
<p>9 0.059225556 <a title="127-tfidf-9" href="./cvpr-2013-Globally_Consistent_Multi-label_Assignment_on_the_Ray_Space_of_4D_Light_Fields.html">188 cvpr-2013-Globally Consistent Multi-label Assignment on the Ray Space of 4D Light Fields</a></p>
<p>10 0.056365892 <a title="127-tfidf-10" href="./cvpr-2013-Can_a_Fully_Unconstrained_Imaging_Model_Be_Applied_Effectively_to_Central_Cameras%3F.html">76 cvpr-2013-Can a Fully Unconstrained Imaging Model Be Applied Effectively to Central Cameras?</a></p>
<p>11 0.05356916 <a title="127-tfidf-11" href="./cvpr-2013-Cross-View_Action_Recognition_via_a_Continuous_Virtual_Path.html">98 cvpr-2013-Cross-View Action Recognition via a Continuous Virtual Path</a></p>
<p>12 0.052997619 <a title="127-tfidf-12" href="./cvpr-2013-Tensor-Based_High-Order_Semantic_Relation_Transfer_for_Semantic_Scene_Segmentation.html">425 cvpr-2013-Tensor-Based High-Order Semantic Relation Transfer for Semantic Scene Segmentation</a></p>
<p>13 0.049469471 <a title="127-tfidf-13" href="./cvpr-2013-Multi-view_Photometric_Stereo_with_Spatially_Varying_Isotropic_Materials.html">303 cvpr-2013-Multi-view Photometric Stereo with Spatially Varying Isotropic Materials</a></p>
<p>14 0.045990784 <a title="127-tfidf-14" href="./cvpr-2013-The_Variational_Structure_of_Disparity_and_Regularization_of_4D_Light_Fields.html">431 cvpr-2013-The Variational Structure of Disparity and Regularization of 4D Light Fields</a></p>
<p>15 0.04481703 <a title="127-tfidf-15" href="./cvpr-2013-Reconstructing_Gas_Flows_Using_Light-Path_Approximation.html">349 cvpr-2013-Reconstructing Gas Flows Using Light-Path Approximation</a></p>
<p>16 0.044745497 <a title="127-tfidf-16" href="./cvpr-2013-A_Global_Approach_for_the_Detection_of_Vanishing_Points_and_Mutually_Orthogonal_Vanishing_Directions.html">12 cvpr-2013-A Global Approach for the Detection of Vanishing Points and Mutually Orthogonal Vanishing Directions</a></p>
<p>17 0.043668535 <a title="127-tfidf-17" href="./cvpr-2013-SLAM%2B%2B%3A_Simultaneous_Localisation_and_Mapping_at_the_Level_of_Objects.html">372 cvpr-2013-SLAM++: Simultaneous Localisation and Mapping at the Level of Objects</a></p>
<p>18 0.041638378 <a title="127-tfidf-18" href="./cvpr-2013-What_Object_Motion_Reveals_about_Shape_with_Unknown_BRDF_and_Lighting.html">465 cvpr-2013-What Object Motion Reveals about Shape with Unknown BRDF and Lighting</a></p>
<p>19 0.040975492 <a title="127-tfidf-19" href="./cvpr-2013-Detection_of_Manipulation_Action_Consequences_%28MAC%29.html">123 cvpr-2013-Detection of Manipulation Action Consequences (MAC)</a></p>
<p>20 0.040652338 <a title="127-tfidf-20" href="./cvpr-2013-Scene_Parsing_by_Integrating_Function%2C_Geometry_and_Appearance_Models.html">381 cvpr-2013-Scene Parsing by Integrating Function, Geometry and Appearance Models</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.106), (1, 0.088), (2, 0.007), (3, 0.008), (4, 0.015), (5, -0.058), (6, -0.036), (7, 0.02), (8, 0.014), (9, 0.005), (10, -0.027), (11, 0.037), (12, 0.015), (13, -0.049), (14, -0.12), (15, 0.016), (16, 0.108), (17, 0.082), (18, -0.002), (19, 0.045), (20, 0.022), (21, -0.011), (22, -0.037), (23, -0.021), (24, 0.013), (25, -0.019), (26, 0.035), (27, 0.053), (28, -0.007), (29, 0.006), (30, -0.046), (31, -0.011), (32, 0.057), (33, -0.08), (34, -0.019), (35, -0.04), (36, 0.047), (37, 0.049), (38, -0.002), (39, -0.066), (40, 0.051), (41, 0.081), (42, -0.016), (43, 0.07), (44, -0.01), (45, 0.263), (46, 0.113), (47, 0.054), (48, -0.208), (49, -0.165)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93469489 <a title="127-lsi-1" href="./cvpr-2013-Discovering_the_Structure_of_a_Planar_Mirror_System_from_Multiple_Observations_of_a_Single_Point.html">127 cvpr-2013-Discovering the Structure of a Planar Mirror System from Multiple Observations of a Single Point</a></p>
<p>Author: Ilya Reshetouski, Alkhazur Manakov, Ayush Bandhari, Ramesh Raskar, Hans-Peter Seidel, Ivo Ihrke</p><p>Abstract: We investigate the problem of identifying the position of a viewer inside a room of planar mirrors with unknown geometry in conjunction with the room’s shape parameters. We consider the observations to consist of angularly resolved depth measurements of a single scene point that is being observed via many multi-bounce interactions with the specular room geometry. Applications of this problem statement include areas such as calibration, acoustic echo cancelation and time-of-flight imaging. We theoretically analyze the problem and derive sufficient conditions for a combination of convex room geometry, observer, and scene point to be reconstructable. The resulting constructive algorithm is exponential in nature and, therefore, not directly applicable to practical scenarios. To counter the situation, we propose theoretically devised geometric constraints that enable an efficient pruning of the solution space and develop a heuristic randomized search algorithm that uses these constraints to obtain an effective solution. We demonstrate the effectiveness of our algorithm on extensive simulations as well as in a challenging real-world calibration scenario.</p><p>2 0.77252144 <a title="127-lsi-2" href="./cvpr-2013-Specular_Reflection_Separation_Using_Dark_Channel_Prior.html">410 cvpr-2013-Specular Reflection Separation Using Dark Channel Prior</a></p>
<p>Author: Hyeongwoo Kim, Hailin Jin, Sunil Hadap, Inso Kweon</p><p>Abstract: We present a novel method to separate specular reflection from a single image. Separating an image into diffuse and specular components is an ill-posed problem due to lack of observations. Existing methods rely on a specularfree image to detect and estimate specularity, which however may confuse diffuse pixels with the same hue but a different saturation value as specular pixels. Our method is based on a novel observation that for most natural images the dark channel can provide an approximate specular-free image. We also propose a maximum a posteriori formulation which robustly recovers the specular reflection and chromaticity despite of the hue-saturation ambiguity. We demonstrate the effectiveness of the proposed algorithm on real and synthetic examples. Experimental results show that our method significantly outperforms the state-of-theart methods in separating specular reflection.</p><p>3 0.71511966 <a title="127-lsi-3" href="./cvpr-2013-Mirror_Surface_Reconstruction_from_a_Single_Image.html">286 cvpr-2013-Mirror Surface Reconstruction from a Single Image</a></p>
<p>Author: Miaomiao Liu, Richard Hartley, Mathieu Salzmann</p><p>Abstract: This paper tackles the problem of reconstructing the shape of a smooth mirror surface from a single image. In particular, we consider the case where the camera is observing the reflection of a static reference target in the unknown mirror. We first study the reconstruction problem given dense correspondences between 3D points on the reference target and image locations. In such conditions, our differential geometry analysis provides a theoretical proof that the shape of the mirror surface can be uniquely recovered if the pose of the reference target is known. We then relax our assumptions by considering the case where only sparse correspondences are available. In this scenario, we formulate reconstruction as an optimization problem, which can be solved using a nonlinear least-squares method. We demonstrate the effectiveness of our method on both synthetic and real images.</p><p>4 0.6596247 <a title="127-lsi-4" href="./cvpr-2013-Single_Image_Calibration_of_Multi-axial_Imaging_Systems.html">400 cvpr-2013-Single Image Calibration of Multi-axial Imaging Systems</a></p>
<p>Author: Amit Agrawal, Srikumar Ramalingam</p><p>Abstract: Imaging systems consisting of a camera looking at multiple spherical mirrors (reflection) or multiple refractive spheres (refraction) have been used for wide-angle imaging applications. We describe such setups as multi-axial imaging systems, since a single sphere results in an axial system. Assuming an internally calibrated camera, calibration of such multi-axial systems involves estimating the sphere radii and locations in the camera coordinate system. However, previous calibration approaches require manual intervention or constrained setups. We present a fully automatic approach using a single photo of a 2D calibration grid. The pose of the calibration grid is assumed to be unknown and is also recovered. Our approach can handle unconstrained setups, where the mirrors/refractive balls can be arranged in any fashion, not necessarily on a grid. The axial nature of rays allows us to compute the axis of each sphere separately. We then show that by choosing rays from two or more spheres, the unknown pose of the calibration grid can be obtained linearly and independently of sphere radii and locations. Knowing the pose, we derive analytical solutions for obtaining the sphere radius and location. This leads to an interesting result that 6-DOF pose estimation of a multi-axial camera can be done without the knowledge of full calibration. Simulations and real experiments demonstrate the applicability of our algorithm.</p><p>5 0.64862496 <a title="127-lsi-5" href="./cvpr-2013-Video_Enhancement_of_People_Wearing_Polarized_Glasses%3A_Darkening_Reversal_and_Reflection_Reduction.html">454 cvpr-2013-Video Enhancement of People Wearing Polarized Glasses: Darkening Reversal and Reflection Reduction</a></p>
<p>Author: Mao Ye, Cha Zhang, Ruigang Yang</p><p>Abstract: With the wide-spread of consumer 3D-TV technology, stereoscopic videoconferencing systems are emerging. However, the special glasses participants wear to see 3D can create distracting images. This paper presents a computational framework to reduce undesirable artifacts in the eye regions caused by these 3D glasses. More specifically, we add polarized filters to the stereo camera so that partial images of reflection can be captured. A novel Bayesian model is then developed to describe the imaging process of the eye regions including darkening and reflection, and infer the eye regions based on Classification ExpectationMaximization (EM). The recovered eye regions under the glasses are brighter and with little reflections, leading to a more nature videoconferencing experience. Qualitative evaluations and user studies are conducted to demonstrate the substantial improvement our approach can achieve.</p><p>6 0.51502895 <a title="127-lsi-6" href="./cvpr-2013-Three-Dimensional_Bilateral_Symmetry_Plane_Estimation_in_the_Phase_Domain.html">432 cvpr-2013-Three-Dimensional Bilateral Symmetry Plane Estimation in the Phase Domain</a></p>
<p>7 0.51158839 <a title="127-lsi-7" href="./cvpr-2013-A_Theory_of_Refractive_Photo-Light-Path_Triangulation.html">27 cvpr-2013-A Theory of Refractive Photo-Light-Path Triangulation</a></p>
<p>8 0.48781916 <a title="127-lsi-8" href="./cvpr-2013-Axially_Symmetric_3D_Pots_Configuration_System_Using_Axis_of_Symmetry_and_Break_Curve.html">52 cvpr-2013-Axially Symmetric 3D Pots Configuration System Using Axis of Symmetry and Break Curve</a></p>
<p>9 0.46888006 <a title="127-lsi-9" href="./cvpr-2013-Reconstructing_Gas_Flows_Using_Light-Path_Approximation.html">349 cvpr-2013-Reconstructing Gas Flows Using Light-Path Approximation</a></p>
<p>10 0.43564117 <a title="127-lsi-10" href="./cvpr-2013-Underwater_Camera_Calibration_Using_Wavelength_Triangulation.html">447 cvpr-2013-Underwater Camera Calibration Using Wavelength Triangulation</a></p>
<p>11 0.40470988 <a title="127-lsi-11" href="./cvpr-2013-Shape_from_Silhouette_Probability_Maps%3A_Reconstruction_of_Thin_Objects_in_the_Presence_of_Silhouette_Extraction_and_Calibration_Error.html">395 cvpr-2013-Shape from Silhouette Probability Maps: Reconstruction of Thin Objects in the Presence of Silhouette Extraction and Calibration Error</a></p>
<p>12 0.38022482 <a title="127-lsi-12" href="./cvpr-2013-A_Genetic_Algorithm-Based_Solver_for_Very_Large_Jigsaw_Puzzles.html">11 cvpr-2013-A Genetic Algorithm-Based Solver for Very Large Jigsaw Puzzles</a></p>
<p>13 0.3624469 <a title="127-lsi-13" href="./cvpr-2013-Understanding_Bayesian_Rooms_Using_Composite_3D_Object_Models.html">445 cvpr-2013-Understanding Bayesian Rooms Using Composite 3D Object Models</a></p>
<p>14 0.34822887 <a title="127-lsi-14" href="./cvpr-2013-Beyond_Point_Clouds%3A_Scene_Understanding_by_Reasoning_Geometry_and_Physics.html">61 cvpr-2013-Beyond Point Clouds: Scene Understanding by Reasoning Geometry and Physics</a></p>
<p>15 0.33846372 <a title="127-lsi-15" href="./cvpr-2013-Light_Field_Distortion_Feature_for_Transparent_Object_Recognition.html">269 cvpr-2013-Light Field Distortion Feature for Transparent Object Recognition</a></p>
<p>16 0.33792797 <a title="127-lsi-16" href="./cvpr-2013-A_Linear_Approach_to_Matching_Cuboids_in_RGBD_Images.html">16 cvpr-2013-A Linear Approach to Matching Cuboids in RGBD Images</a></p>
<p>17 0.32806185 <a title="127-lsi-17" href="./cvpr-2013-Towards_Contactless%2C_Low-Cost_and_Accurate_3D_Fingerprint_Identification.html">435 cvpr-2013-Towards Contactless, Low-Cost and Accurate 3D Fingerprint Identification</a></p>
<p>18 0.32473797 <a title="127-lsi-18" href="./cvpr-2013-Universality_of_the_Local_Marginal_Polytope.html">448 cvpr-2013-Universality of the Local Marginal Polytope</a></p>
<p>19 0.31128013 <a title="127-lsi-19" href="./cvpr-2013-Manhattan_Scene_Understanding_via_XSlit_Imaging.html">279 cvpr-2013-Manhattan Scene Understanding via XSlit Imaging</a></p>
<p>20 0.30794194 <a title="127-lsi-20" href="./cvpr-2013-Improving_the_Visual_Comprehension_of_Point_Sets.html">218 cvpr-2013-Improving the Visual Comprehension of Point Sets</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.1), (16, 0.062), (26, 0.032), (28, 0.017), (33, 0.193), (66, 0.287), (67, 0.047), (69, 0.038), (87, 0.09)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.82111162 <a title="127-lda-1" href="./cvpr-2013-Calibrating_Photometric_Stereo_by_Holistic_Reflectance_Symmetry_Analysis.html">75 cvpr-2013-Calibrating Photometric Stereo by Holistic Reflectance Symmetry Analysis</a></p>
<p>Author: Zhe Wu, Ping Tan</p><p>Abstract: Under unknown directional lighting, the uncalibrated Lambertian photometric stereo algorithm recovers the shape of a smooth surface up to the generalized bas-relief (GBR) ambiguity. We resolve this ambiguity from the halfvector symmetry, which is observed in many isotropic materials. Under this symmetry, a 2D BRDF slice with low-rank structure can be obtained from an image, if the surface normals and light directions are correctly recovered. In general, this structure is destroyed by the GBR ambiguity. As a result, we can resolve the ambiguity by restoring this structure. We develop a simple algorithm of auto-calibration from separable homogeneous specular reflection of real images. Compared with previous methods, this method takes a holistic approach to exploiting reflectance symmetry and produces superior results.</p><p>same-paper 2 0.78870696 <a title="127-lda-2" href="./cvpr-2013-Discovering_the_Structure_of_a_Planar_Mirror_System_from_Multiple_Observations_of_a_Single_Point.html">127 cvpr-2013-Discovering the Structure of a Planar Mirror System from Multiple Observations of a Single Point</a></p>
<p>Author: Ilya Reshetouski, Alkhazur Manakov, Ayush Bandhari, Ramesh Raskar, Hans-Peter Seidel, Ivo Ihrke</p><p>Abstract: We investigate the problem of identifying the position of a viewer inside a room of planar mirrors with unknown geometry in conjunction with the room’s shape parameters. We consider the observations to consist of angularly resolved depth measurements of a single scene point that is being observed via many multi-bounce interactions with the specular room geometry. Applications of this problem statement include areas such as calibration, acoustic echo cancelation and time-of-flight imaging. We theoretically analyze the problem and derive sufficient conditions for a combination of convex room geometry, observer, and scene point to be reconstructable. The resulting constructive algorithm is exponential in nature and, therefore, not directly applicable to practical scenarios. To counter the situation, we propose theoretically devised geometric constraints that enable an efficient pruning of the solution space and develop a heuristic randomized search algorithm that uses these constraints to obtain an effective solution. We demonstrate the effectiveness of our algorithm on extensive simulations as well as in a challenging real-world calibration scenario.</p><p>3 0.73057383 <a title="127-lda-3" href="./cvpr-2013-Multi-view_Photometric_Stereo_with_Spatially_Varying_Isotropic_Materials.html">303 cvpr-2013-Multi-view Photometric Stereo with Spatially Varying Isotropic Materials</a></p>
<p>Author: Zhenglong Zhou, Zhe Wu, Ping Tan</p><p>Abstract: We present a method to capture both 3D shape and spatially varying reflectance with a multi-view photometric stereo technique that works for general isotropic materials. Our data capture setup is simple, which consists of only a digital camera and a handheld light source. From a single viewpoint, we use a set of photometric stereo images to identify surface points with the same distance to the camera. We collect this information from multiple viewpoints and combine it with structure-from-motion to obtain a precise reconstruction of the complete 3D shape. The spatially varying isotropic bidirectional reflectance distributionfunction (BRDF) is captured by simultaneously inferring a set of basis BRDFs and their mixing weights at each surface point. According to our experiments, the captured shapes are accurate to 0.3 millimeters. The captured reflectance has relative root-mean-square error (RMSE) of 9%.</p><p>4 0.72014284 <a title="127-lda-4" href="./cvpr-2013-Radial_Distortion_Self-Calibration.html">344 cvpr-2013-Radial Distortion Self-Calibration</a></p>
<p>Author: José Henrique Brito, Roland Angst, Kevin Köser, Marc Pollefeys</p><p>Abstract: In cameras with radial distortion, straight lines in space are in general mapped to curves in the image. Although epipolar geometry also gets distorted, there is a set of special epipolar lines that remain straight, namely those that go through the distortion center. By finding these straight epipolar lines in camera pairs we can obtain constraints on the distortion center(s) without any calibration object or plumbline assumptions in the scene. Although this holds for all radial distortion models we conceptually prove this idea using the division distortion model and the radial fundamental matrix which allow for a very simple closed form solution of the distortion center from two views (same distortion) or three views (different distortions). The non-iterative nature of our approach makes it immune to local minima and allows finding the distortion center also for cropped images or those where no good prior exists. Besides this, we give comprehensive relations between different undistortion models and discuss advantages and drawbacks.</p><p>5 0.71027166 <a title="127-lda-5" href="./cvpr-2013-Intrinsic_Scene_Properties_from_a_Single_RGB-D_Image.html">227 cvpr-2013-Intrinsic Scene Properties from a Single RGB-D Image</a></p>
<p>Author: Jonathan T. Barron, Jitendra Malik</p><p>Abstract: In this paper we extend the “shape, illumination and reflectance from shading ” (SIRFS) model [3, 4], which recovers intrinsic scene properties from a single image. Though SIRFS performs well on images of segmented objects, it performs poorly on images of natural scenes, which contain occlusion and spatially-varying illumination. We therefore present Scene-SIRFS, a generalization of SIRFS in which we have a mixture of shapes and a mixture of illuminations, and those mixture components are embedded in a “soft” segmentation of the input image. We additionally use the noisy depth maps provided by RGB-D sensors (in this case, the Kinect) to improve shape estimation. Our model takes as input a single RGB-D image and produces as output an improved depth map, a set of surface normals, a reflectance image, a shading image, and a spatially varying model of illumination. The output of our model can be used for graphics applications, or for any application involving RGB-D images.</p><p>6 0.68870485 <a title="127-lda-6" href="./cvpr-2013-Uncalibrated_Photometric_Stereo_for_Unknown_Isotropic_Reflectances.html">443 cvpr-2013-Uncalibrated Photometric Stereo for Unknown Isotropic Reflectances</a></p>
<p>7 0.66678423 <a title="127-lda-7" href="./cvpr-2013-BRDF_Slices%3A_Accurate_Adaptive_Anisotropic_Appearance_Acquisition.html">54 cvpr-2013-BRDF Slices: Accurate Adaptive Anisotropic Appearance Acquisition</a></p>
<p>8 0.66530782 <a title="127-lda-8" href="./cvpr-2013-Robust_Estimation_of_Nonrigid_Transformation_for_Point_Set_Registration.html">360 cvpr-2013-Robust Estimation of Nonrigid Transformation for Point Set Registration</a></p>
<p>9 0.66528213 <a title="127-lda-9" href="./cvpr-2013-A_New_Perspective_on_Uncalibrated_Photometric_Stereo.html">21 cvpr-2013-A New Perspective on Uncalibrated Photometric Stereo</a></p>
<p>10 0.66499054 <a title="127-lda-10" href="./cvpr-2013-What_Object_Motion_Reveals_about_Shape_with_Unknown_BRDF_and_Lighting.html">465 cvpr-2013-What Object Motion Reveals about Shape with Unknown BRDF and Lighting</a></p>
<p>11 0.65575671 <a title="127-lda-11" href="./cvpr-2013-Photometric_Ambient_Occlusion.html">330 cvpr-2013-Photometric Ambient Occlusion</a></p>
<p>12 0.65006602 <a title="127-lda-12" href="./cvpr-2013-Analytic_Bilinear_Appearance_Subspace_Construction_for_Modeling_Image_Irradiance_under_Natural_Illumination_and_Non-Lambertian_Reflectance.html">42 cvpr-2013-Analytic Bilinear Appearance Subspace Construction for Modeling Image Irradiance under Natural Illumination and Non-Lambertian Reflectance</a></p>
<p>13 0.64839876 <a title="127-lda-13" href="./cvpr-2013-Single_Image_Calibration_of_Multi-axial_Imaging_Systems.html">400 cvpr-2013-Single Image Calibration of Multi-axial Imaging Systems</a></p>
<p>14 0.64669794 <a title="127-lda-14" href="./cvpr-2013-Non-parametric_Filtering_for_Geometric_Detail_Extraction_and_Material_Representation.html">305 cvpr-2013-Non-parametric Filtering for Geometric Detail Extraction and Material Representation</a></p>
<p>15 0.64473271 <a title="127-lda-15" href="./cvpr-2013-Shading-Based_Shape_Refinement_of_RGB-D_Images.html">394 cvpr-2013-Shading-Based Shape Refinement of RGB-D Images</a></p>
<p>16 0.64370972 <a title="127-lda-16" href="./cvpr-2013-Bayesian_Depth-from-Defocus_with_Shading_Constraints.html">56 cvpr-2013-Bayesian Depth-from-Defocus with Shading Constraints</a></p>
<p>17 0.63854474 <a title="127-lda-17" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<p>18 0.63353938 <a title="127-lda-18" href="./cvpr-2013-Reconstructing_Gas_Flows_Using_Light-Path_Approximation.html">349 cvpr-2013-Reconstructing Gas Flows Using Light-Path Approximation</a></p>
<p>19 0.63314623 <a title="127-lda-19" href="./cvpr-2013-Exploiting_the_Power_of_Stereo_Confidences.html">155 cvpr-2013-Exploiting the Power of Stereo Confidences</a></p>
<p>20 0.6326564 <a title="127-lda-20" href="./cvpr-2013-Cross-View_Action_Recognition_via_a_Continuous_Virtual_Path.html">98 cvpr-2013-Cross-View Action Recognition via a Continuous Virtual Path</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
