<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>435 cvpr-2013-Towards Contactless, Low-Cost and Accurate 3D Fingerprint Identification</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-435" href="#">cvpr2013-435</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>435 cvpr-2013-Towards Contactless, Low-Cost and Accurate 3D Fingerprint Identification</h1>
<br/><p>Source: <a title="cvpr-2013-435-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Kumar_Towards_Contactless_Low-Cost_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Ajay Kumar, Cyril Kwong</p><p>Abstract: In order to avail the benefits of higher user convenience, hygiene, and improved accuracy, contactless 3D fingerprint recognition techniques have recently been introduced. One of the key limitations of these emerging 3D fingerprint technologies to replace the conventional 2D fingerprint system is their bulk and high cost, which mainly results from the use of multiple imaging cameras or structured lighting employed in these systems. This paper details the development of a contactless 3D fingerprint identification system that uses only single camera. We develop a new representation of 3D finger surface features using Finger Surface Codes and illustrate its effectiveness in matching 3D fingerprints. Conventional minutiae representation is extended in 3D space to accurately match the recovered 3D minutiae. Multiple 2D fingerprint images (with varying illumination profile) acquired to build 3D fingerprints can themselves be used recover 2D features for further improving 3D fingerprint identification and has been illustrated in this paper. The experimental results are shown on a database of 240 client fingerprints and confirm the advantages of the single camera based 3D fingerprint identification.</p><p>Reference: <a title="cvpr-2013-435-reference" href="../cvpr2013_reference/cvpr-2013-Towards_Contactless%2C_Low-Cost_and_Accurate_3D_Fingerprint_Identification_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Towards Contactless, Low-Cost and Accurate 3D Fingerprint Identification Ajay Kumar, Cyril Kwong Department of Computing, The Hong Kong Polytechnic University, Hung Hom, Kowloon, Hong Kong aj aykr@i eee . [sent-1, score-0.018]
</p><p>2 hk  Abstract In order to avail the benefits of higher user convenience, hygiene, and improved accuracy, contactless 3D fingerprint recognition techniques have recently been introduced. [sent-5, score-1.191]
</p><p>3 One of the key limitations of these emerging 3D fingerprint technologies to replace the conventional 2D fingerprint system is their bulk and high cost, which mainly results from the use of multiple imaging cameras or structured lighting employed in these systems. [sent-6, score-2.02]
</p><p>4 This paper details the development of a contactless 3D fingerprint identification system that uses only single camera. [sent-7, score-1.21]
</p><p>5 We develop a new representation of 3D finger surface features using Finger Surface Codes and illustrate its effectiveness in matching 3D fingerprints. [sent-8, score-0.3]
</p><p>6 Conventional minutiae representation is extended in 3D space to accurately match the recovered 3D minutiae. [sent-9, score-0.069]
</p><p>7 Multiple 2D fingerprint images (with varying illumination profile) acquired to build 3D fingerprints can themselves be used recover 2D features for further improving 3D fingerprint identification and has been illustrated in this paper. [sent-10, score-1.988]
</p><p>8 The experimental results are shown on a database of 240 client fingerprints and confirm the advantages of the single camera based 3D fingerprint identification. [sent-11, score-1.009]
</p><p>9 Introduction Automated identification of humans is an integral part of infrastructure needed for a wide range of commercial and law-enforcement applications [1], [9]. [sent-13, score-0.083]
</p><p>10 As compared to other extrinsic biometric features, the fingerprints are considered to be most invariant and employed worldwide by nearly all the law enforcement departments. [sent-14, score-0.146]
</p><p>11 Traditional fingerprint scans require placing and pressing of fingers against the hard surface, like glass or silicon, and often results in partial or degraded quality images. [sent-15, score-0.953]
</p><p>12 Such frequent degradation in fingerprint image quality is often attributed to skin deformations, moisture, reside of finger dirt, finger sweat, finger slips, and smear or due to sensor noise [3]. [sent-16, score-1.46]
</p><p>13 Contactless fingerprint systems can provide hygienic solutions to such problems and can cope-up with the residue of previous fingerprint impressions which can also be a potential security threat. [sent-17, score-1.835]
</p><p>14 Contactless fingerprint identification is essentially the acquisition of ridge-valley patterns without any physical contact between the finger and sensor surface [8], [13], [18]. [sent-18, score-1.248]
</p><p>15 The image quality from such contactless 2D fingerprint sensors [20] is often lower than that of most popular FTIR [1] sensors and its physical size is larger than that of solid-state sensors. [sent-19, score-1.179]
</p><p>16 Lack of popularity of such contactless 2D fingerprint systems can be attributed to their high cost and bulk as compared to the low-cost legacy touch-based fingerprint devices commonly available today. [sent-20, score-2.138]
</p><p>17 Contactless 3D Fingerprint Identification In order to avail the benefits of higher user convenience, hygiene, and improved accuracy, contactless 3D fingerprint recognition techniques have recently been introduced [2], [10], [20]-[22]. [sent-23, score-1.191]
</p><p>18 A contactless fingerprint identification system that uses multiple cameras to systematically acquire multiple views of the presented finger has been detailed in [2], [18]. [sent-24, score-1.433]
</p><p>19 One of the main obstacles of emerging 3D fingerprint technologies to replace the conventional 2D fingerprint system is their bulk and high cost, which mainly results from the nature of imaging technologies employed for the 3D fingerprint reconstruction. [sent-25, score-2.953]
</p><p>20 In [2], [18] five cameras are required while the system in [10] requires a specialized projector and a high-speed camera to implement 3D fingerprint scanning. [sent-26, score-0.917]
</p><p>21 Therefore there is strong motivation and need to develop low-cost solutions for 3D fingerprint identification. [sent-27, score-0.915]
</p><p>22 Our Work and Contributions This paper investigates and develops a low-cost solution to the problem of contactless 3D fingerprint identification using single camera. [sent-30, score-1.244]
</p><p>23 Our experimental results presented in this paper illustrate successful use of Lambertian reflectance based shape from shading technique for the problem of accurate 3D fingerprint identification. [sent-31, score-0.94]
</p><p>24 The experimental results are reported on 3D fingerprint database acquired from the 260 clients. [sent-32, score-0.955]
</p><p>25 We develop a Finger Surface Code representation of 3D fingerprint surface for efficient 3D fingerprint matching (section 3. [sent-33, score-1.899]
</p><p>26 Ã—  Our experimental results also confirm the superiority of such representation over Surface Code representation proposed in [16]. [sent-35, score-0.021]
</p><p>27 We extend the 2D representation of widely employed 2D minutiae features in 3D space to include height and angle information. [sent-36, score-0.095]
</p><p>28 Our approach also exploits 2D fingerprint images acquired for 3D fingerprint reconstruction to simultaneously extract 2D minutiae and matches them during identification. [sent-37, score-1.923]
</p><p>29 Our experimental results illustrate significant improvement in performance using combination of such simultaneously acquired 3D and 2D fingerprint features. [sent-38, score-0.974]
</p><p>30 Block Diagram and Finger Imaging The finger images are acquired using contactless imaging setup and the average/expected distance between the camera and the finger is ~10 cm. [sent-40, score-0.69]
</p><p>31 A digital camera which can acquire 2592 1944 pixel images with 10 fps (costing less than 100 US$) is employed. [sent-41, score-0.025]
</p><p>32 Illumination sequence and the image acquisition is synchronized and controlled by a computer using a very low-cost imaging interface (developed by us). [sent-43, score-0.047]
</p><p>33 The position of LEDs on the acquired images is calibrated. [sent-44, score-0.056]
</p><p>34 Once the ROI images are extracted, 3D fingerprint surface is reconstructed using the shape from shading technique. [sent-46, score-1.006]
</p><p>35 o r e c o v e r 3 D f in g e r p r(i1n)t wsuhr efa r c e e ? [sent-60, score-0.018]
</p><p>36 bth e e t hm eu l t ui n p i l et s2u Dr f cfie n g n e o r rp mr(i3na)t l iwmha e gr ee s c ? [sent-374, score-0.07]
</p><p>37 ) illustrates linear relationship between 3D fingerprint surface, observed pixel intensities from 2D fingerprint image and the unit surface normal vectors x. [sent-522, score-1.916]
</p><p>38 b e e s t i m a t e d f r o m (th4)e fol l o w i n g e q u a t i o n? [sent-529, score-0.016]
</p><p>39 toa sr x w a i u l l ri t e pv re e cs e t o n r t. [sent-552, score-0.034]
</p><p>40 T (h4)e recovered surface normals are then integrated to recover the 3D fingerprint surface z (x, y). [sent-561, score-1.069]
</p><p>41 228% pixels (outliers) with the high intensity values in seven images acquired for the 3D fingerprint reconstruction. [sent-563, score-0.955]
</p><p>42 3D Fingerprint Feature Extraction The 3D cloud point data reconstructed from the presented fingers is subjected to following (postprocessing) operations for the feature extraction. [sent-565, score-0.051]
</p><p>43 (a) Smoothing: The 3D fingerprint surface data is a range data representing the height value (z) on the 2D plane (x, y). [sent-566, score-0.984]
</p><p>44 The principle curvature calculation is often sensitive to the noise. [sent-567, score-0.072]
</p><p>45 The smoothing process employed is two steps process; firstly we apply a 5 5 median filter on the surface data to suppress the noise. [sent-568, score-0.134]
</p><p>46 h ioss etnh ein Â±te2p pisixzeel ifna cxto-yr d iTrehcet io3nDs from P. [sent-624, score-0.039]
</p><p>47 nTohrme anl vrmecatlo r v eocft othr ei d aatna gproaidnit nint othf e :sm ? [sent-632, score-0.111]
</p><p>48 urTfhaece ios mcaallc uvlaectetod byis thaen gradient of : ? [sent-639, score-0.017]
</p><p>49 -Tgyh, 1)n, owrmhearle vgxe atnord gisy aaren tghrea dgireandti eonft a:lo ? [sent-655, score-0.039]
</p><p>50 lT hvee ncotorrm aisli zeadn surface normal will be used for principle curvature estimation. [sent-663, score-0.19]
</p><p>51 (c) Principle Curvature: The principle curvature and the principle direction are computed using Cubic-Order Approximation Algorithm [14]-[15]. [sent-664, score-0.103]
</p><p>52 For a vertex P, the position of Qi is transformed to local coordinate that P is (0, 0, 0) and the axes become normal vector of P with two arbitrary orthonormal vectors in the tangent plane. [sent-665, score-0.067]
</p><p>53 Let (xi, yi, zi) be the position of the vertex and (ai, bi, ci ) be the normal vector of the vertex in the transformed coordinate. [sent-666, score-0.101]
</p><p>54 The Cubic-Order fitting approach tries to locate a surface that can fit the vertex and its neighbors such that, 333444333977  : ;? [sent-667, score-0.119]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('fingerprint', 0.899), ('contactless', 0.246), ('finger', 0.18), ('surface', 0.085), ('fingerprints', 0.069), ('minutiae', 0.069), ('identification', 0.065), ('bulk', 0.057), ('acquired', 0.056), ('avail', 0.046), ('hygiene', 0.046), ('ilsig', 0.046), ('curvature', 0.041), ('eri', 0.038), ('ei', 0.036), ('technologies', 0.035), ('er', 0.035), ('vertex', 0.034), ('fingers', 0.034), ('normal', 0.033), ('principle', 0.031), ('ng', 0.03), ('imaging', 0.028), ('roi', 0.027), ('employed', 0.026), ('hm', 0.026), ('acquire', 0.025), ('gr', 0.024), ('lambertian', 0.023), ('emerging', 0.023), ('smoothing', 0.023), ('shading', 0.022), ('hong', 0.022), ('kong', 0.021), ('confirm', 0.021), ('convenience', 0.021), ('attributed', 0.021), ('eosm', 0.02), ('fta', 0.02), ('tghrea', 0.02), ('hom', 0.02), ('pressing', 0.02), ('wet', 0.02), ('wai', 0.02), ('qac', 0.02), ('eocft', 0.02), ('othr', 0.02), ('silicon', 0.02), ('impressions', 0.02), ('etnh', 0.02), ('client', 0.02), ('bth', 0.02), ('wh', 0.02), ('acquisition', 0.019), ('conventional', 0.019), ('ein', 0.019), ('eig', 0.019), ('nint', 0.019), ('dirt', 0.019), ('costing', 0.019), ('alb', 0.019), ('symmetrically', 0.019), ('eosft', 0.019), ('enforcement', 0.019), ('hweh', 0.019), ('eonft', 0.019), ('nre', 0.019), ('illustrate', 0.019), ('efa', 0.018), ('rfa', 0.018), ('eee', 0.018), ('infrastructure', 0.018), ('dsi', 0.018), ('lte', 0.018), ('investigates', 0.018), ('iths', 0.018), ('cameras', 0.018), ('ri', 0.018), ('sensors', 0.017), ('eed', 0.017), ('thaen', 0.017), ('subjected', 0.017), ('obstacles', 0.017), ('residue', 0.017), ('develops', 0.016), ('erf', 0.016), ('eas', 0.016), ('fol', 0.016), ('polytechnic', 0.016), ('ips', 0.016), ('legacy', 0.016), ('sm', 0.016), ('develop', 0.016), ('replace', 0.016), ('biometric', 0.016), ('org', 0.016), ('othf', 0.016), ('toa', 0.016), ('leds', 0.016), ('worldwide', 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="435-tfidf-1" href="./cvpr-2013-Towards_Contactless%2C_Low-Cost_and_Accurate_3D_Fingerprint_Identification.html">435 cvpr-2013-Towards Contactless, Low-Cost and Accurate 3D Fingerprint Identification</a></p>
<p>Author: Ajay Kumar, Cyril Kwong</p><p>Abstract: In order to avail the benefits of higher user convenience, hygiene, and improved accuracy, contactless 3D fingerprint recognition techniques have recently been introduced. One of the key limitations of these emerging 3D fingerprint technologies to replace the conventional 2D fingerprint system is their bulk and high cost, which mainly results from the use of multiple imaging cameras or structured lighting employed in these systems. This paper details the development of a contactless 3D fingerprint identification system that uses only single camera. We develop a new representation of 3D finger surface features using Finger Surface Codes and illustrate its effectiveness in matching 3D fingerprints. Conventional minutiae representation is extended in 3D space to accurately match the recovered 3D minutiae. Multiple 2D fingerprint images (with varying illumination profile) acquired to build 3D fingerprints can themselves be used recover 2D features for further improving 3D fingerprint identification and has been illustrated in this paper. The experimental results are shown on a database of 240 client fingerprints and confirm the advantages of the single camera based 3D fingerprint identification.</p><p>2 0.04619186 <a title="435-tfidf-2" href="./cvpr-2013-Intrinsic_Characterization_of_Dynamic_Surfaces.html">226 cvpr-2013-Intrinsic Characterization of Dynamic Surfaces</a></p>
<p>Author: Tony Tung, Takashi Matsuyama</p><p>Abstract: This paper presents a novel approach to characterize deformable surface using intrinsic property dynamics. 3D dynamic surfaces representing humans in motion can be obtained using multiple view stereo reconstruction methods or depth cameras. Nowadays these technologies have become capable to capture surface variations in real-time, and give details such as clothing wrinkles and deformations. Assuming repetitive patterns in the deformations, we propose to model complex surface variations using sets of linear dynamical systems (LDS) where observations across time are given by surface intrinsic properties such as local curvatures. We introduce an approach based on bags of dynamical systems, where each surface feature to be represented in the codebook is modeled by a set of LDS equipped with timing structure. Experiments are performed on datasets of real-world dynamical surfaces and show compelling results for description, classification and segmentation.</p><p>3 0.043798368 <a title="435-tfidf-3" href="./cvpr-2013-Uncalibrated_Photometric_Stereo_for_Unknown_Isotropic_Reflectances.html">443 cvpr-2013-Uncalibrated Photometric Stereo for Unknown Isotropic Reflectances</a></p>
<p>Author: Feng Lu, Yasuyuki Matsushita, Imari Sato, Takahiro Okabe, Yoichi Sato</p><p>Abstract: We propose an uncalibrated photometric stereo method that works with general and unknown isotropic reflectances. Our method uses a pixel intensity profile, which is a sequence of radiance intensities recorded at a pixel across multi-illuminance images. We show that for general isotropic materials, the geodesic distance between intensity profiles is linearly related to the angular difference of their surface normals, and that the intensity distribution of an intensity profile conveys information about the reflectance properties, when the intensity profile is obtained under uniformly distributed directional lightings. Based on these observations, we show that surface normals can be estimated up to a convex/concave ambiguity. A solution method based on matrix decomposition with missing data is developed for a reliable estimation. Quantitative and qualitative evaluations of our method are performed using both synthetic and real-world scenes.</p><p>4 0.041691571 <a title="435-tfidf-4" href="./cvpr-2013-Multi-scale_Curve_Detection_on_Surfaces.html">298 cvpr-2013-Multi-scale Curve Detection on Surfaces</a></p>
<p>Author: Michael Kolomenkin, Ilan Shimshoni, Ayellet Tal</p><p>Abstract: This paper extends to surfaces the multi-scale approach of edge detection on images. The common practice for detecting curves on surfaces requires the user to first select the scale of the features, apply an appropriate smoothing, and detect the edges on the smoothed surface. This approach suffers from two drawbacks. First, it relies on a hidden assumption that all the features on the surface are of the same scale. Second, manual user intervention is required. In this paper, we propose a general framework for automatically detecting the optimal scale for each point on the surface. We smooth the surface at each point according to this optimal scale and run the curve detection algorithm on the resulting surface. Our multi-scale algorithm solves the two disadvantages of the single-scale approach mentioned above. We demonstrate how to realize our approach on two commonly-used special cases: ridges & valleys and relief edges. In each case, the optimal scale is found in accordance with the mathematical definition of the curve.</p><p>5 0.0411379 <a title="435-tfidf-5" href="./cvpr-2013-Template-Based_Isometric_Deformable_3D_Reconstruction_with_Sampling-Based_Focal_Length_Self-Calibration.html">423 cvpr-2013-Template-Based Isometric Deformable 3D Reconstruction with Sampling-Based Focal Length Self-Calibration</a></p>
<p>Author: Adrien Bartoli, Toby Collins</p><p>Abstract: It has been shown that a surface deforming isometrically can be reconstructed from a single image and a template 3D shape. Methods from the literature solve this problem efficiently. However, they all assume that the camera model is calibrated, which drastically limits their applicability. We propose (i) a general variational framework that applies to (calibrated and uncalibrated) general camera models and (ii) self-calibrating 3D reconstruction algorithms for the weak-perspective and full-perspective camera models. In the former case, our algorithm returns the normal field and camera â€™s scale factor. In the latter case, our algorithm returns the normal field, depth and camera â€™s focal length. Our algorithms are the first to achieve deformable 3D reconstruction including camera self-calibration. They apply to much more general setups than existing methods. Experimental results on simulated and real data show that our algorithms give results with the same level of accuracy as existing methods (which use the true focal length) on perspective images, and correctly find the normal field on affine images for which the existing methods fail.</p><p>6 0.039908953 <a title="435-tfidf-6" href="./cvpr-2013-Multi-view_Photometric_Stereo_with_Spatially_Varying_Isotropic_Materials.html">303 cvpr-2013-Multi-view Photometric Stereo with Spatially Varying Isotropic Materials</a></p>
<p>7 0.039655242 <a title="435-tfidf-7" href="./cvpr-2013-What_Object_Motion_Reveals_about_Shape_with_Unknown_BRDF_and_Lighting.html">465 cvpr-2013-What Object Motion Reveals about Shape with Unknown BRDF and Lighting</a></p>
<p>8 0.030759459 <a title="435-tfidf-8" href="./cvpr-2013-Mirror_Surface_Reconstruction_from_a_Single_Image.html">286 cvpr-2013-Mirror Surface Reconstruction from a Single Image</a></p>
<p>9 0.030440662 <a title="435-tfidf-9" href="./cvpr-2013-Hyperbolic_Harmonic_Mapping_for_Constrained_Brain_Surface_Registration.html">208 cvpr-2013-Hyperbolic Harmonic Mapping for Constrained Brain Surface Registration</a></p>
<p>10 0.029209424 <a title="435-tfidf-10" href="./cvpr-2013-Boundary_Cues_for_3D_Object_Shape_Recovery.html">71 cvpr-2013-Boundary Cues for 3D Object Shape Recovery</a></p>
<p>11 0.028588075 <a title="435-tfidf-11" href="./cvpr-2013-Shading-Based_Shape_Refinement_of_RGB-D_Images.html">394 cvpr-2013-Shading-Based Shape Refinement of RGB-D Images</a></p>
<p>12 0.027815882 <a title="435-tfidf-12" href="./cvpr-2013-HON4D%3A_Histogram_of_Oriented_4D_Normals_for_Activity_Recognition_from_Depth_Sequences.html">196 cvpr-2013-HON4D: Histogram of Oriented 4D Normals for Activity Recognition from Depth Sequences</a></p>
<p>13 0.02731584 <a title="435-tfidf-13" href="./cvpr-2013-Pattern-Driven_Colorization_of_3D_Surfaces.html">327 cvpr-2013-Pattern-Driven Colorization of 3D Surfaces</a></p>
<p>14 0.027248528 <a title="435-tfidf-14" href="./cvpr-2013-Multi-resolution_Shape_Analysis_via_Non-Euclidean_Wavelets%3A_Applications_to_Mesh_Segmentation_and_Surface_Alignment_Problems.html">297 cvpr-2013-Multi-resolution Shape Analysis via Non-Euclidean Wavelets: Applications to Mesh Segmentation and Surface Alignment Problems</a></p>
<p>15 0.026719272 <a title="435-tfidf-15" href="./cvpr-2013-Monocular_Template-Based_3D_Reconstruction_of_Extensible_Surfaces_with_Local_Linear_Elasticity.html">289 cvpr-2013-Monocular Template-Based 3D Reconstruction of Extensible Surfaces with Local Linear Elasticity</a></p>
<p>16 0.026633663 <a title="435-tfidf-16" href="./cvpr-2013-Intrinsic_Scene_Properties_from_a_Single_RGB-D_Image.html">227 cvpr-2013-Intrinsic Scene Properties from a Single RGB-D Image</a></p>
<p>17 0.026379472 <a title="435-tfidf-17" href="./cvpr-2013-Sensing_and_Recognizing_Surface_Textures_Using_a_GelSight_Sensor.html">391 cvpr-2013-Sensing and Recognizing Surface Textures Using a GelSight Sensor</a></p>
<p>18 0.026270628 <a title="435-tfidf-18" href="./cvpr-2013-A_Theory_of_Refractive_Photo-Light-Path_Triangulation.html">27 cvpr-2013-A Theory of Refractive Photo-Light-Path Triangulation</a></p>
<p>19 0.024464535 <a title="435-tfidf-19" href="./cvpr-2013-Determining_Motion_Directly_from_Normal_Flows_Upon_the_Use_of_a_Spherical_Eye_Platform.html">124 cvpr-2013-Determining Motion Directly from Normal Flows Upon the Use of a Spherical Eye Platform</a></p>
<p>20 0.024422674 <a title="435-tfidf-20" href="./cvpr-2013-Analytic_Bilinear_Appearance_Subspace_Construction_for_Modeling_Image_Irradiance_under_Natural_Illumination_and_Non-Lambertian_Reflectance.html">42 cvpr-2013-Analytic Bilinear Appearance Subspace Construction for Modeling Image Irradiance under Natural Illumination and Non-Lambertian Reflectance</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.045), (1, 0.049), (2, -0.001), (3, 0.018), (4, -0.001), (5, -0.034), (6, -0.024), (7, 0.002), (8, 0.007), (9, -0.005), (10, -0.016), (11, -0.021), (12, -0.027), (13, -0.023), (14, 0.013), (15, -0.012), (16, 0.025), (17, 0.017), (18, 0.014), (19, 0.001), (20, -0.033), (21, 0.009), (22, 0.008), (23, 0.002), (24, -0.045), (25, 0.001), (26, 0.007), (27, 0.001), (28, -0.013), (29, 0.007), (30, 0.005), (31, -0.009), (32, -0.004), (33, 0.026), (34, -0.015), (35, 0.006), (36, 0.003), (37, -0.006), (38, -0.013), (39, 0.007), (40, 0.022), (41, 0.022), (42, 0.02), (43, -0.006), (44, -0.0), (45, -0.022), (46, 0.02), (47, 0.038), (48, 0.011), (49, -0.055)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.88109064 <a title="435-lsi-1" href="./cvpr-2013-Towards_Contactless%2C_Low-Cost_and_Accurate_3D_Fingerprint_Identification.html">435 cvpr-2013-Towards Contactless, Low-Cost and Accurate 3D Fingerprint Identification</a></p>
<p>Author: Ajay Kumar, Cyril Kwong</p><p>Abstract: In order to avail the benefits of higher user convenience, hygiene, and improved accuracy, contactless 3D fingerprint recognition techniques have recently been introduced. One of the key limitations of these emerging 3D fingerprint technologies to replace the conventional 2D fingerprint system is their bulk and high cost, which mainly results from the use of multiple imaging cameras or structured lighting employed in these systems. This paper details the development of a contactless 3D fingerprint identification system that uses only single camera. We develop a new representation of 3D finger surface features using Finger Surface Codes and illustrate its effectiveness in matching 3D fingerprints. Conventional minutiae representation is extended in 3D space to accurately match the recovered 3D minutiae. Multiple 2D fingerprint images (with varying illumination profile) acquired to build 3D fingerprints can themselves be used recover 2D features for further improving 3D fingerprint identification and has been illustrated in this paper. The experimental results are shown on a database of 240 client fingerprints and confirm the advantages of the single camera based 3D fingerprint identification.</p><p>2 0.68582857 <a title="435-lsi-2" href="./cvpr-2013-Monocular_Template-Based_3D_Reconstruction_of_Extensible_Surfaces_with_Local_Linear_Elasticity.html">289 cvpr-2013-Monocular Template-Based 3D Reconstruction of Extensible Surfaces with Local Linear Elasticity</a></p>
<p>Author: Abed Malti, Richard Hartley, Adrien Bartoli, Jae-Hak Kim</p><p>Abstract: We propose a new approach for template-based extensible surface reconstruction from a single view. We extend the method of isometric surface reconstruction and more recent work on conformal surface reconstruction. Our approach relies on the minimization of a proposed stretching energy formalized with respect to the Poisson ratio parameter of the surface. We derive a patch-based formulation of this stretching energy by assuming local linear elasticity. This formulation unifies geometrical and mechanical constraints in a single energy term. We prevent local scale ambiguities by imposing a set of fixed boundary 3D points. We experimentally prove the sufficiency of this set of boundary points and demonstrate the effectiveness of our approach on different developable and non-developable surfaces with a wide range of extensibility.</p><p>3 0.65779567 <a title="435-lsi-3" href="./cvpr-2013-Intrinsic_Characterization_of_Dynamic_Surfaces.html">226 cvpr-2013-Intrinsic Characterization of Dynamic Surfaces</a></p>
<p>Author: Tony Tung, Takashi Matsuyama</p><p>Abstract: This paper presents a novel approach to characterize deformable surface using intrinsic property dynamics. 3D dynamic surfaces representing humans in motion can be obtained using multiple view stereo reconstruction methods or depth cameras. Nowadays these technologies have become capable to capture surface variations in real-time, and give details such as clothing wrinkles and deformations. Assuming repetitive patterns in the deformations, we propose to model complex surface variations using sets of linear dynamical systems (LDS) where observations across time are given by surface intrinsic properties such as local curvatures. We introduce an approach based on bags of dynamical systems, where each surface feature to be represented in the codebook is modeled by a set of LDS equipped with timing structure. Experiments are performed on datasets of real-world dynamical surfaces and show compelling results for description, classification and segmentation.</p><p>4 0.63742244 <a title="435-lsi-4" href="./cvpr-2013-Multi-resolution_Shape_Analysis_via_Non-Euclidean_Wavelets%3A_Applications_to_Mesh_Segmentation_and_Surface_Alignment_Problems.html">297 cvpr-2013-Multi-resolution Shape Analysis via Non-Euclidean Wavelets: Applications to Mesh Segmentation and Surface Alignment Problems</a></p>
<p>Author: Won Hwa Kim, Moo K. Chung, Vikas Singh</p><p>Abstract: The analysis of 3-D shape meshes is a fundamental problem in computer vision, graphics, and medical imaging. Frequently, the needs of the application require that our analysis take a multi-resolution view of the shape â€™s local and global topology, and that the solution is consistent across multiple scales. Unfortunately, the preferred mathematical construct which offers this behavior in classical image/signal processing, Wavelets, is no longer applicable in this general setting (data with non-uniform topology). In particular, the traditional definition does not allow writing out an expansion for graphs that do not correspond to the uniformly sampled lattice (e.g., images). In this paper, we adapt recent results in harmonic analysis, to derive NonEuclidean Wavelets based algorithms for a range of shape analysis problems in vision and medical imaging. We show how descriptors derived from the dual domain representation offer native multi-resolution behavior for characterizing local/global topology around vertices. With only minor modifications, the framework yields a method for extracting interest/key points from shapes, a surprisingly simple algorithm for 3-D shape segmentation (competitive with state of the art), and a method for surface alignment (without landmarks). We give an extensive set of comparison results on a large shape segmentation benchmark and derive a uniqueness theorem for the surface alignment problem.</p><p>5 0.61887699 <a title="435-lsi-5" href="./cvpr-2013-Multi-scale_Curve_Detection_on_Surfaces.html">298 cvpr-2013-Multi-scale Curve Detection on Surfaces</a></p>
<p>Author: Michael Kolomenkin, Ilan Shimshoni, Ayellet Tal</p><p>Abstract: This paper extends to surfaces the multi-scale approach of edge detection on images. The common practice for detecting curves on surfaces requires the user to first select the scale of the features, apply an appropriate smoothing, and detect the edges on the smoothed surface. This approach suffers from two drawbacks. First, it relies on a hidden assumption that all the features on the surface are of the same scale. Second, manual user intervention is required. In this paper, we propose a general framework for automatically detecting the optimal scale for each point on the surface. We smooth the surface at each point according to this optimal scale and run the curve detection algorithm on the resulting surface. Our multi-scale algorithm solves the two disadvantages of the single-scale approach mentioned above. We demonstrate how to realize our approach on two commonly-used special cases: ridges & valleys and relief edges. In each case, the optimal scale is found in accordance with the mathematical definition of the curve.</p><p>6 0.59775954 <a title="435-lsi-6" href="./cvpr-2013-Three-Dimensional_Bilateral_Symmetry_Plane_Estimation_in_the_Phase_Domain.html">432 cvpr-2013-Three-Dimensional Bilateral Symmetry Plane Estimation in the Phase Domain</a></p>
<p>7 0.59534544 <a title="435-lsi-7" href="./cvpr-2013-Uncalibrated_Photometric_Stereo_for_Unknown_Isotropic_Reflectances.html">443 cvpr-2013-Uncalibrated Photometric Stereo for Unknown Isotropic Reflectances</a></p>
<p>8 0.5775255 <a title="435-lsi-8" href="./cvpr-2013-Hyperbolic_Harmonic_Mapping_for_Constrained_Brain_Surface_Registration.html">208 cvpr-2013-Hyperbolic Harmonic Mapping for Constrained Brain Surface Registration</a></p>
<p>9 0.56623363 <a title="435-lsi-9" href="./cvpr-2013-Correspondence-Less_Non-rigid_Registration_of_Triangular_Surface_Meshes.html">97 cvpr-2013-Correspondence-Less Non-rigid Registration of Triangular Surface Meshes</a></p>
<p>10 0.56393945 <a title="435-lsi-10" href="./cvpr-2013-Template-Based_Isometric_Deformable_3D_Reconstruction_with_Sampling-Based_Focal_Length_Self-Calibration.html">423 cvpr-2013-Template-Based Isometric Deformable 3D Reconstruction with Sampling-Based Focal Length Self-Calibration</a></p>
<p>11 0.54006785 <a title="435-lsi-11" href="./cvpr-2013-Sensing_and_Recognizing_Surface_Textures_Using_a_GelSight_Sensor.html">391 cvpr-2013-Sensing and Recognizing Surface Textures Using a GelSight Sensor</a></p>
<p>12 0.53696239 <a title="435-lsi-12" href="./cvpr-2013-Multi-view_Photometric_Stereo_with_Spatially_Varying_Isotropic_Materials.html">303 cvpr-2013-Multi-view Photometric Stereo with Spatially Varying Isotropic Materials</a></p>
<p>13 0.52953464 <a title="435-lsi-13" href="./cvpr-2013-Area_Preserving_Brain_Mapping.html">44 cvpr-2013-Area Preserving Brain Mapping</a></p>
<p>14 0.52875537 <a title="435-lsi-14" href="./cvpr-2013-A_New_Perspective_on_Uncalibrated_Photometric_Stereo.html">21 cvpr-2013-A New Perspective on Uncalibrated Photometric Stereo</a></p>
<p>15 0.52174169 <a title="435-lsi-15" href="./cvpr-2013-Pattern-Driven_Colorization_of_3D_Surfaces.html">327 cvpr-2013-Pattern-Driven Colorization of 3D Surfaces</a></p>
<p>16 0.51622683 <a title="435-lsi-16" href="./cvpr-2013-Mirror_Surface_Reconstruction_from_a_Single_Image.html">286 cvpr-2013-Mirror Surface Reconstruction from a Single Image</a></p>
<p>17 0.51250976 <a title="435-lsi-17" href="./cvpr-2013-Efficient_Computation_of_Shortest_Path-Concavity_for_3D_Meshes.html">141 cvpr-2013-Efficient Computation of Shortest Path-Concavity for 3D Meshes</a></p>
<p>18 0.51023668 <a title="435-lsi-18" href="./cvpr-2013-Whitened_Expectation_Propagation%3A_Non-Lambertian_Shape_from_Shading_and_Shadow.html">466 cvpr-2013-Whitened Expectation Propagation: Non-Lambertian Shape from Shading and Shadow</a></p>
<p>19 0.50212371 <a title="435-lsi-19" href="./cvpr-2013-What_Object_Motion_Reveals_about_Shape_with_Unknown_BRDF_and_Lighting.html">465 cvpr-2013-What Object Motion Reveals about Shape with Unknown BRDF and Lighting</a></p>
<p>20 0.50130159 <a title="435-lsi-20" href="./cvpr-2013-Axially_Symmetric_3D_Pots_Configuration_System_Using_Axis_of_Symmetry_and_Break_Curve.html">52 cvpr-2013-Axially Symmetric 3D Pots Configuration System Using Axis of Symmetry and Break Curve</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.091), (16, 0.034), (26, 0.04), (33, 0.153), (65, 0.343), (67, 0.042), (69, 0.061), (87, 0.073)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.73845208 <a title="435-lda-1" href="./cvpr-2013-Towards_Contactless%2C_Low-Cost_and_Accurate_3D_Fingerprint_Identification.html">435 cvpr-2013-Towards Contactless, Low-Cost and Accurate 3D Fingerprint Identification</a></p>
<p>Author: Ajay Kumar, Cyril Kwong</p><p>Abstract: In order to avail the benefits of higher user convenience, hygiene, and improved accuracy, contactless 3D fingerprint recognition techniques have recently been introduced. One of the key limitations of these emerging 3D fingerprint technologies to replace the conventional 2D fingerprint system is their bulk and high cost, which mainly results from the use of multiple imaging cameras or structured lighting employed in these systems. This paper details the development of a contactless 3D fingerprint identification system that uses only single camera. We develop a new representation of 3D finger surface features using Finger Surface Codes and illustrate its effectiveness in matching 3D fingerprints. Conventional minutiae representation is extended in 3D space to accurately match the recovered 3D minutiae. Multiple 2D fingerprint images (with varying illumination profile) acquired to build 3D fingerprints can themselves be used recover 2D features for further improving 3D fingerprint identification and has been illustrated in this paper. The experimental results are shown on a database of 240 client fingerprints and confirm the advantages of the single camera based 3D fingerprint identification.</p><p>2 0.67225933 <a title="435-lda-2" href="./cvpr-2013-Efficient_3D_Endfiring_TRUS_Prostate_Segmentation_with_Globally_Optimized_Rotational_Symmetry.html">139 cvpr-2013-Efficient 3D Endfiring TRUS Prostate Segmentation with Globally Optimized Rotational Symmetry</a></p>
<p>Author: Jing Yuan, Wu Qiu, Eranga Ukwatta, Martin Rajchl, Xue-Cheng Tai, Aaron Fenster</p><p>Abstract: Segmenting 3D endfiring transrectal ultrasound (TRUS) prostate images efficiently and accurately is of utmost importance for the planning and guiding 3D TRUS guided prostate biopsy. Poor image quality and imaging artifacts of 3D TRUS images often introduce a challenging task in computation to directly extract the 3D prostate surface. In this work, we propose a novel global optimization approach to delineate 3D prostate boundaries using its rotational resliced images around a specified axis, which properly enforces the inherent rotational symmetry of prostate shapes to jointly adjust a series of 2D slicewise segmentations in the global 3D sense. We show that the introduced challenging combinatorial optimization problem can be solved globally and exactly by means of convex relaxation. In this regard, we propose a novel coupled continuous max-flow model, which not only provides a powerful mathematical tool to analyze the proposed optimization problem but also amounts to a new and efficient duality-basedalgorithm. Ex- tensive experiments demonstrate that the proposed method significantly outperforms the state-of-art methods in terms ofefficiency, accuracy, reliability and less user-interactions, and reduces the execution time by a factor of 100.</p><p>3 0.66335213 <a title="435-lda-3" href="./cvpr-2013-Five_Shades_of_Grey_for_Fast_and_Reliable_Camera_Pose_Estimation.html">176 cvpr-2013-Five Shades of Grey for Fast and Reliable Camera Pose Estimation</a></p>
<p>Author: Adam Herout, IstvÃ¡n SzentandrÃ¡si, Michal ZachariÃ¡Å¡, MarkÃ©ta DubskÃ¡, Rudolf Kajan</p><p>Abstract: We introduce here an improved design of the Uniform Marker Fields and an algorithm for their fast and reliable detection. Our concept of the marker field is designed so that it can be detected and recognized for camera pose estimation: in various lighting conditions, under a severe perspective, while heavily occluded, and under a strong motion blur. Our marker field detection harnesses the fact that the edges within the marker field meet at two vanishing points and that the projected planar grid of squares can be defined by a detectable mathematical formalism. The modules of the grid are greyscale and the locations within the marker field are defined by the edges between the modules. The assumption that the marker field is planar allows for a very cheap and reliable camera pose estimation in the captured scene. The detection rates and accuracy are slightly better compared to state-of-the-art marker-based solutions. At the same time, and more importantly, our detector of the marker field is several times faster and the reliable real-time detection can be thus achieved on mobile and low-power devices. We show three targeted applications where theplanarity is assured and where thepresented marker field design and detection algorithm provide a reliable and extremely fast solution.</p><p>4 0.64041281 <a title="435-lda-4" href="./cvpr-2013-FrameBreak%3A_Dramatic_Image_Extrapolation_by_Guided_Shift-Maps.html">177 cvpr-2013-FrameBreak: Dramatic Image Extrapolation by Guided Shift-Maps</a></p>
<p>Author: Yinda Zhang, Jianxiong Xiao, James Hays, Ping Tan</p><p>Abstract: We significantly extrapolate the field of view of a photograph by learning from a roughly aligned, wide-angle guide image of the same scene category. Our method can extrapolate typical photos into complete panoramas. The extrapolation problem is formulated in the shift-map image synthesis framework. We analyze the self-similarity of the guide image to generate a set of allowable local transformations and apply them to the input image. Our guided shift-map method preserves to the scene layout of the guide image when extrapolating a photograph. While conventional shiftmap methods only support translations, this is not expressive enough to characterize the self-similarity of complex scenes. Therefore we additionally allow image transformations of rotation, scaling and reflection. To handle this in- crease in complexity, we introduce a hierarchical graph optimization method to choose the optimal transformation at each output pixel. We demonstrate our approach on a variety of indoor, outdoor, natural, and man-made scenes.</p><p>5 0.62637126 <a title="435-lda-5" href="./cvpr-2013-Object-Centric_Anomaly_Detection_by_Attribute-Based_Reasoning.html">310 cvpr-2013-Object-Centric Anomaly Detection by Attribute-Based Reasoning</a></p>
<p>Author: Babak Saleh, Ali Farhadi, Ahmed Elgammal</p><p>Abstract: When describing images, humans tend not to talk about the obvious, but rather mention what they find interesting. We argue that abnormalities and deviations from typicalities are among the most important components that form what is worth mentioning. In this paper we introduce the abnormality detection as a recognition problem and show how to model typicalities and, consequently, meaningful deviations from prototypical properties of categories. Our model can recognize abnormalities and report the main reasons of any recognized abnormality. We also show that abnormality predictions can help image categorization. We introduce the abnormality detection dataset and show interesting results on how to reason about abnormalities.</p><p>6 0.59224731 <a title="435-lda-6" href="./cvpr-2013-MODEC%3A_Multimodal_Decomposable_Models_for_Human_Pose_Estimation.html">277 cvpr-2013-MODEC: Multimodal Decomposable Models for Human Pose Estimation</a></p>
<p>7 0.58929646 <a title="435-lda-7" href="./cvpr-2013-Category_Modeling_from_Just_a_Single_Labeling%3A_Use_Depth_Information_to_Guide_the_Learning_of_2D_Models.html">80 cvpr-2013-Category Modeling from Just a Single Labeling: Use Depth Information to Guide the Learning of 2D Models</a></p>
<p>8 0.57883501 <a title="435-lda-8" href="./cvpr-2013-A_Divide-and-Conquer_Method_for_Scalable_Low-Rank_Latent_Matrix_Pursuit.html">7 cvpr-2013-A Divide-and-Conquer Method for Scalable Low-Rank Latent Matrix Pursuit</a></p>
<p>9 0.50437963 <a title="435-lda-9" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>10 0.50421643 <a title="435-lda-10" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<p>11 0.50376976 <a title="435-lda-11" href="./cvpr-2013-Beyond_Point_Clouds%3A_Scene_Understanding_by_Reasoning_Geometry_and_Physics.html">61 cvpr-2013-Beyond Point Clouds: Scene Understanding by Reasoning Geometry and Physics</a></p>
<p>12 0.50115007 <a title="435-lda-12" href="./cvpr-2013-HDR_Deghosting%3A_How_to_Deal_with_Saturation%3F.html">195 cvpr-2013-HDR Deghosting: How to Deal with Saturation?</a></p>
<p>13 0.50077224 <a title="435-lda-13" href="./cvpr-2013-Physically_Plausible_3D_Scene_Tracking%3A_The_Single_Actor_Hypothesis.html">331 cvpr-2013-Physically Plausible 3D Scene Tracking: The Single Actor Hypothesis</a></p>
<p>14 0.49928799 <a title="435-lda-14" href="./cvpr-2013-A_Minimum_Error_Vanishing_Point_Detection_Approach_for_Uncalibrated_Monocular_Images_of_Man-Made_Environments.html">19 cvpr-2013-A Minimum Error Vanishing Point Detection Approach for Uncalibrated Monocular Images of Man-Made Environments</a></p>
<p>15 0.49729845 <a title="435-lda-15" href="./cvpr-2013-Prostate_Segmentation_in_CT_Images_via_Spatial-Constrained_Transductive_Lasso.html">342 cvpr-2013-Prostate Segmentation in CT Images via Spatial-Constrained Transductive Lasso</a></p>
<p>16 0.49715224 <a title="435-lda-16" href="./cvpr-2013-Understanding_Bayesian_Rooms_Using_Composite_3D_Object_Models.html">445 cvpr-2013-Understanding Bayesian Rooms Using Composite 3D Object Models</a></p>
<p>17 0.4962334 <a title="435-lda-17" href="./cvpr-2013-Single_Image_Calibration_of_Multi-axial_Imaging_Systems.html">400 cvpr-2013-Single Image Calibration of Multi-axial Imaging Systems</a></p>
<p>18 0.49553674 <a title="435-lda-18" href="./cvpr-2013-SLAM%2B%2B%3A_Simultaneous_Localisation_and_Mapping_at_the_Level_of_Objects.html">372 cvpr-2013-SLAM++: Simultaneous Localisation and Mapping at the Level of Objects</a></p>
<p>19 0.49518457 <a title="435-lda-19" href="./cvpr-2013-Structure_Preserving_Object_Tracking.html">414 cvpr-2013-Structure Preserving Object Tracking</a></p>
<p>20 0.49512586 <a title="435-lda-20" href="./cvpr-2013-Cross-View_Action_Recognition_via_a_Continuous_Virtual_Path.html">98 cvpr-2013-Cross-View Action Recognition via a Continuous Virtual Path</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
