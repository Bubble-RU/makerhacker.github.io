<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>278 cvpr-2013-Manhattan Junction Catalogue for Spatial Reasoning of Indoor Scenes</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-278" href="#">cvpr2013-278</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>278 cvpr-2013-Manhattan Junction Catalogue for Spatial Reasoning of Indoor Scenes</h1>
<br/><p>Source: <a title="cvpr-2013-278-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Ramalingam_Manhattan_Junction_Catalogue_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Srikumar Ramalingam, Jaishanker K. Pillai, Arpit Jain, Yuichi Taguchi</p><p>Abstract: Junctions are strong cues for understanding the geometry of a scene. In this paper, we consider the problem of detecting junctions and using them for recovering the spatial layout of an indoor scene. Junction detection has always been challenging due to missing and spurious lines. We work in a constrained Manhattan world setting where the junctions are formed by only line segments along the three principal orthogonal directions. Junctions can be classified into several categories based on the number and orientations of the incident line segments. We provide a simple and efficient voting scheme to detect and classify these junctions in real images. Indoor scenes are typically modeled as cuboids and we formulate the problem of the cuboid layout estimation as an inference problem in a conditional random field. Our formulation allows the incorporation of junction features and the training is done using structured prediction techniques. We outperform other single view geometry estimation methods on standard datasets.</p><p>Reference: <a title="cvpr-2013-278-reference" href="../cvpr2013_reference/cvpr-2013-Manhattan_Junction_Catalogue_for_Spatial_Reasoning_of_Indoor_Scenes_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('junct', 0.872), ('layout', 0.236), ('manhat', 0.124), ('indo', 0.103), ('ray', 0.089), ('tripl', 0.08), ('accum', 0.08), ('vot', 0.079), ('vpi', 0.079), ('lin', 0.079), ('hedau', 0.078), ('wal', 0.074), ('incid', 0.069), ('gc', 0.064), ('cliqu', 0.062), ('crf', 0.059), ('draw', 0.059), ('cuboid', 0.058), ('room', 0.054), ('corn', 0.053)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000006 <a title="278-tfidf-1" href="./cvpr-2013-Manhattan_Junction_Catalogue_for_Spatial_Reasoning_of_Indoor_Scenes.html">278 cvpr-2013-Manhattan Junction Catalogue for Spatial Reasoning of Indoor Scenes</a></p>
<p>Author: Srikumar Ramalingam, Jaishanker K. Pillai, Arpit Jain, Yuichi Taguchi</p><p>Abstract: Junctions are strong cues for understanding the geometry of a scene. In this paper, we consider the problem of detecting junctions and using them for recovering the spatial layout of an indoor scene. Junction detection has always been challenging due to missing and spurious lines. We work in a constrained Manhattan world setting where the junctions are formed by only line segments along the three principal orthogonal directions. Junctions can be classified into several categories based on the number and orientations of the incident line segments. We provide a simple and efficient voting scheme to detect and classify these junctions in real images. Indoor scenes are typically modeled as cuboids and we formulate the problem of the cuboid layout estimation as an inference problem in a conditional random field. Our formulation allows the incorporation of junction features and the training is done using structured prediction techniques. We outperform other single view geometry estimation methods on standard datasets.</p><p>2 0.21833766 <a title="278-tfidf-2" href="./cvpr-2013-Understanding_Indoor_Scenes_Using_3D_Geometric_Phrases.html">446 cvpr-2013-Understanding Indoor Scenes Using 3D Geometric Phrases</a></p>
<p>Author: Wongun Choi, Yu-Wei Chao, Caroline Pantofaru, Silvio Savarese</p><p>Abstract: Visual scene understanding is a difficult problem interleaving object detection, geometric reasoning and scene classification. We present a hierarchical scene model for learning and reasoning about complex indoor scenes which is computationally tractable, can be learned from a reasonable amount of training data, and avoids oversimplification. At the core of this approach is the 3D Geometric Phrase Model which captures the semantic and geometric relationships between objects whichfrequently co-occur in the same 3D spatial configuration. Experiments show that this model effectively explains scene semantics, geometry and object groupings from a single image, while also improving individual object detections.</p><p>3 0.12861066 <a title="278-tfidf-3" href="./cvpr-2013-Winding_Number_for_Region-Boundary_Consistent_Salient_Contour_Extraction.html">468 cvpr-2013-Winding Number for Region-Boundary Consistent Salient Contour Extraction</a></p>
<p>Author: Yansheng Ming, Hongdong Li, Xuming He</p><p>Abstract: This paper aims to extract salient closed contours from an image. For this vision task, both region segmentation cues (e.g. color/texture homogeneity) and boundary detection cues (e.g. local contrast, edge continuity and contour closure) play important and complementary roles. In this paper we show how to combine both cues in a unified framework. The main focus is given to how to maintain the consistency (compatibility) between the region cues and the boundary cues. To this ends, we introduce the use of winding number–a well-known concept in topology–as a powerful mathematical device. By this device, the region-boundary consistency is represented as a set of simple linear relationships. Our method is applied to the figure-ground segmentation problem. The experiments show clearly improved results.</p><p>4 0.12850766 <a title="278-tfidf-4" href="./cvpr-2013-Understanding_Bayesian_Rooms_Using_Composite_3D_Object_Models.html">445 cvpr-2013-Understanding Bayesian Rooms Using Composite 3D Object Models</a></p>
<p>Author: Luca Del_Pero, Joshua Bowdish, Bonnie Kermgard, Emily Hartley, Kobus Barnard</p><p>Abstract: We develop a comprehensive Bayesian generative model for understanding indoor scenes. While it is common in this domain to approximate objects with 3D bounding boxes, we propose using strong representations with finer granularity. For example, we model a chair as a set of four legs, a seat and a backrest. We find that modeling detailed geometry improves recognition and reconstruction, and enables more refined use of appearance for scene understanding. We demonstrate this with a new likelihood function that re- wards 3D object hypotheses whose 2D projection is more uniform in color distribution. Such a measure would be confused by background pixels if we used a bounding box to represent a concave object like a chair. Complex objects are modeled using a set or re-usable 3D parts, and we show that this representation captures much of the variation among object instances with relatively few parameters. We also designed specific data-driven inference mechanismsfor eachpart that are shared by all objects containing that part, which helps make inference transparent to the modeler. Further, we show how to exploit contextual relationships to detect more objects, by, for example, proposing chairs around and underneath tables. We present results showing the benefits of each of these innovations. The performance of our approach often exceeds that of state-of-the-art methods on the two tasks of room layout estimation and object recognition, as evaluated on two bench mark data sets used in this domain. work. 1) Detailed geometric models, such as tables with legs and top (bottom left), provide better reconstructions than plain boxes (top right), when supported by image features such as geometric context [5] (top middle), or an approach to using color introduced here. 2) Non convex models allow for complex configurations, such as a chair under a table (bottom middle). 3) 3D contextual relationships, such as chairs being around a table, allow identifying objects supported by little image evidence, like the chair behind the table (bottom right). Best viewed in color.</p><p>5 0.12067562 <a title="278-tfidf-5" href="./cvpr-2013-Scene_Parsing_by_Integrating_Function%2C_Geometry_and_Appearance_Models.html">381 cvpr-2013-Scene Parsing by Integrating Function, Geometry and Appearance Models</a></p>
<p>Author: Yibiao Zhao, Song-Chun Zhu</p><p>Abstract: Indoor functional objects exhibit large view and appearance variations, thus are difficult to be recognized by the traditional appearance-based classification paradigm. In this paper, we present an algorithm to parse indoor images based on two observations: i) The functionality is the most essentialproperty to define an indoor object, e.g. “a chair to sit on ”; ii) The geometry (3D shape) ofan object is designed to serve its function. We formulate the nature of the object function into a stochastic grammar model. This model characterizes a joint distribution over the function-geometryappearance (FGA) hierarchy. The hierarchical structure includes a scene category, , functional groups, , functional objects, functional parts and 3D geometric shapes. We use a simulated annealing MCMC algorithm to find the maximum a posteriori (MAP) solution, i.e. a parse tree. We design four data-driven steps to accelerate the search in the FGA space: i) group the line segments into 3D primitive shapes, ii) assign functional labels to these 3D primitive shapes, iii) fill in missing objects/parts according to the functional labels, and iv) synthesize 2D segmentation maps and verify the current parse tree by the Metropolis-Hastings acceptance probability. The experimental results on several challenging indoor datasets demonstrate theproposed approach not only significantly widens the scope ofindoor sceneparsing algorithm from the segmentation and the 3D recovery to the functional object recognition, but also yields improved overall performance.</p><p>6 0.10685735 <a title="278-tfidf-6" href="./cvpr-2013-Reconstructing_Loopy_Curvilinear_Structures_Using_Integer_Programming.html">350 cvpr-2013-Reconstructing Loopy Curvilinear Structures Using Integer Programming</a></p>
<p>7 0.1039228 <a title="278-tfidf-7" href="./cvpr-2013-Looking_Beyond_the_Image%3A_Unsupervised_Learning_for_Object_Saliency_and_Detection.html">273 cvpr-2013-Looking Beyond the Image: Unsupervised Learning for Object Saliency and Detection</a></p>
<p>8 0.079857014 <a title="278-tfidf-8" href="./cvpr-2013-A_Higher-Order_CRF_Model_for_Road_Network_Extraction.html">13 cvpr-2013-A Higher-Order CRF Model for Road Network Extraction</a></p>
<p>9 0.07777489 <a title="278-tfidf-9" href="./cvpr-2013-Analyzing_Semantic_Segmentation_Using_Hybrid_Human-Machine_CRFs.html">43 cvpr-2013-Analyzing Semantic Segmentation Using Hybrid Human-Machine CRFs</a></p>
<p>10 0.077707961 <a title="278-tfidf-10" href="./cvpr-2013-Revisiting_Depth_Layers_from_Occlusions.html">357 cvpr-2013-Revisiting Depth Layers from Occlusions</a></p>
<p>11 0.077470005 <a title="278-tfidf-11" href="./cvpr-2013-Fast_Energy_Minimization_Using_Learned_State_Filters.html">165 cvpr-2013-Fast Energy Minimization Using Learned State Filters</a></p>
<p>12 0.076864488 <a title="278-tfidf-12" href="./cvpr-2013-Globally_Consistent_Multi-label_Assignment_on_the_Ray_Space_of_4D_Light_Fields.html">188 cvpr-2013-Globally Consistent Multi-label Assignment on the Ray Space of 4D Light Fields</a></p>
<p>13 0.076728337 <a title="278-tfidf-13" href="./cvpr-2013-Mesh_Based_Semantic_Modelling_for_Indoor_and_Outdoor_Scenes.html">284 cvpr-2013-Mesh Based Semantic Modelling for Indoor and Outdoor Scenes</a></p>
<p>14 0.075569697 <a title="278-tfidf-14" href="./cvpr-2013-Perceptual_Organization_and_Recognition_of_Indoor_Scenes_from_RGB-D_Images.html">329 cvpr-2013-Perceptual Organization and Recognition of Indoor Scenes from RGB-D Images</a></p>
<p>15 0.074124843 <a title="278-tfidf-15" href="./cvpr-2013-Learning_Structured_Hough_Voting_for_Joint_Object_Detection_and_Occlusion_Reasoning.html">256 cvpr-2013-Learning Structured Hough Voting for Joint Object Detection and Occlusion Reasoning</a></p>
<p>16 0.069874935 <a title="278-tfidf-16" href="./cvpr-2013-3D-Based_Reasoning_with_Blocks%2C_Support%2C_and_Stability.html">1 cvpr-2013-3D-Based Reasoning with Blocks, Support, and Stability</a></p>
<p>17 0.067666404 <a title="278-tfidf-17" href="./cvpr-2013-A_Linear_Approach_to_Matching_Cuboids_in_RGBD_Images.html">16 cvpr-2013-A Linear Approach to Matching Cuboids in RGBD Images</a></p>
<p>18 0.065015644 <a title="278-tfidf-18" href="./cvpr-2013-A_Minimum_Error_Vanishing_Point_Detection_Approach_for_Uncalibrated_Monocular_Images_of_Man-Made_Environments.html">19 cvpr-2013-A Minimum Error Vanishing Point Detection Approach for Uncalibrated Monocular Images of Man-Made Environments</a></p>
<p>19 0.061716106 <a title="278-tfidf-19" href="./cvpr-2013-Fully-Connected_CRFs_with_Non-Parametric_Pairwise_Potential.html">180 cvpr-2013-Fully-Connected CRFs with Non-Parametric Pairwise Potential</a></p>
<p>20 0.06039736 <a title="278-tfidf-20" href="./cvpr-2013-Beyond_Point_Clouds%3A_Scene_Understanding_by_Reasoning_Geometry_and_Physics.html">61 cvpr-2013-Beyond Point Clouds: Scene Understanding by Reasoning Geometry and Physics</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.128), (1, -0.002), (2, -0.04), (3, 0.014), (4, 0.051), (5, -0.062), (6, 0.034), (7, -0.003), (8, 0.025), (9, 0.011), (10, 0.044), (11, -0.004), (12, -0.029), (13, -0.042), (14, 0.02), (15, 0.001), (16, 0.047), (17, 0.1), (18, 0.075), (19, 0.061), (20, -0.083), (21, 0.047), (22, 0.06), (23, 0.051), (24, 0.038), (25, 0.029), (26, -0.027), (27, 0.005), (28, 0.039), (29, -0.054), (30, -0.004), (31, 0.019), (32, -0.08), (33, 0.016), (34, 0.059), (35, 0.02), (36, 0.063), (37, 0.002), (38, 0.029), (39, -0.088), (40, 0.101), (41, 0.132), (42, -0.044), (43, -0.067), (44, 0.031), (45, -0.005), (46, 0.03), (47, -0.062), (48, 0.029), (49, -0.06)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.88512009 <a title="278-lsi-1" href="./cvpr-2013-Manhattan_Junction_Catalogue_for_Spatial_Reasoning_of_Indoor_Scenes.html">278 cvpr-2013-Manhattan Junction Catalogue for Spatial Reasoning of Indoor Scenes</a></p>
<p>Author: Srikumar Ramalingam, Jaishanker K. Pillai, Arpit Jain, Yuichi Taguchi</p><p>Abstract: Junctions are strong cues for understanding the geometry of a scene. In this paper, we consider the problem of detecting junctions and using them for recovering the spatial layout of an indoor scene. Junction detection has always been challenging due to missing and spurious lines. We work in a constrained Manhattan world setting where the junctions are formed by only line segments along the three principal orthogonal directions. Junctions can be classified into several categories based on the number and orientations of the incident line segments. We provide a simple and efficient voting scheme to detect and classify these junctions in real images. Indoor scenes are typically modeled as cuboids and we formulate the problem of the cuboid layout estimation as an inference problem in a conditional random field. Our formulation allows the incorporation of junction features and the training is done using structured prediction techniques. We outperform other single view geometry estimation methods on standard datasets.</p><p>2 0.69203842 <a title="278-lsi-2" href="./cvpr-2013-Understanding_Indoor_Scenes_Using_3D_Geometric_Phrases.html">446 cvpr-2013-Understanding Indoor Scenes Using 3D Geometric Phrases</a></p>
<p>Author: Wongun Choi, Yu-Wei Chao, Caroline Pantofaru, Silvio Savarese</p><p>Abstract: Visual scene understanding is a difficult problem interleaving object detection, geometric reasoning and scene classification. We present a hierarchical scene model for learning and reasoning about complex indoor scenes which is computationally tractable, can be learned from a reasonable amount of training data, and avoids oversimplification. At the core of this approach is the 3D Geometric Phrase Model which captures the semantic and geometric relationships between objects whichfrequently co-occur in the same 3D spatial configuration. Experiments show that this model effectively explains scene semantics, geometry and object groupings from a single image, while also improving individual object detections.</p><p>3 0.66632873 <a title="278-lsi-3" href="./cvpr-2013-Scene_Parsing_by_Integrating_Function%2C_Geometry_and_Appearance_Models.html">381 cvpr-2013-Scene Parsing by Integrating Function, Geometry and Appearance Models</a></p>
<p>Author: Yibiao Zhao, Song-Chun Zhu</p><p>Abstract: Indoor functional objects exhibit large view and appearance variations, thus are difficult to be recognized by the traditional appearance-based classification paradigm. In this paper, we present an algorithm to parse indoor images based on two observations: i) The functionality is the most essentialproperty to define an indoor object, e.g. “a chair to sit on ”; ii) The geometry (3D shape) ofan object is designed to serve its function. We formulate the nature of the object function into a stochastic grammar model. This model characterizes a joint distribution over the function-geometryappearance (FGA) hierarchy. The hierarchical structure includes a scene category, , functional groups, , functional objects, functional parts and 3D geometric shapes. We use a simulated annealing MCMC algorithm to find the maximum a posteriori (MAP) solution, i.e. a parse tree. We design four data-driven steps to accelerate the search in the FGA space: i) group the line segments into 3D primitive shapes, ii) assign functional labels to these 3D primitive shapes, iii) fill in missing objects/parts according to the functional labels, and iv) synthesize 2D segmentation maps and verify the current parse tree by the Metropolis-Hastings acceptance probability. The experimental results on several challenging indoor datasets demonstrate theproposed approach not only significantly widens the scope ofindoor sceneparsing algorithm from the segmentation and the 3D recovery to the functional object recognition, but also yields improved overall performance.</p><p>4 0.66566801 <a title="278-lsi-4" href="./cvpr-2013-Understanding_Bayesian_Rooms_Using_Composite_3D_Object_Models.html">445 cvpr-2013-Understanding Bayesian Rooms Using Composite 3D Object Models</a></p>
<p>Author: Luca Del_Pero, Joshua Bowdish, Bonnie Kermgard, Emily Hartley, Kobus Barnard</p><p>Abstract: We develop a comprehensive Bayesian generative model for understanding indoor scenes. While it is common in this domain to approximate objects with 3D bounding boxes, we propose using strong representations with finer granularity. For example, we model a chair as a set of four legs, a seat and a backrest. We find that modeling detailed geometry improves recognition and reconstruction, and enables more refined use of appearance for scene understanding. We demonstrate this with a new likelihood function that re- wards 3D object hypotheses whose 2D projection is more uniform in color distribution. Such a measure would be confused by background pixels if we used a bounding box to represent a concave object like a chair. Complex objects are modeled using a set or re-usable 3D parts, and we show that this representation captures much of the variation among object instances with relatively few parameters. We also designed specific data-driven inference mechanismsfor eachpart that are shared by all objects containing that part, which helps make inference transparent to the modeler. Further, we show how to exploit contextual relationships to detect more objects, by, for example, proposing chairs around and underneath tables. We present results showing the benefits of each of these innovations. The performance of our approach often exceeds that of state-of-the-art methods on the two tasks of room layout estimation and object recognition, as evaluated on two bench mark data sets used in this domain. work. 1) Detailed geometric models, such as tables with legs and top (bottom left), provide better reconstructions than plain boxes (top right), when supported by image features such as geometric context [5] (top middle), or an approach to using color introduced here. 2) Non convex models allow for complex configurations, such as a chair under a table (bottom middle). 3) 3D contextual relationships, such as chairs being around a table, allow identifying objects supported by little image evidence, like the chair behind the table (bottom right). Best viewed in color.</p><p>5 0.57461035 <a title="278-lsi-5" href="./cvpr-2013-Discovering_the_Structure_of_a_Planar_Mirror_System_from_Multiple_Observations_of_a_Single_Point.html">127 cvpr-2013-Discovering the Structure of a Planar Mirror System from Multiple Observations of a Single Point</a></p>
<p>Author: Ilya Reshetouski, Alkhazur Manakov, Ayush Bandhari, Ramesh Raskar, Hans-Peter Seidel, Ivo Ihrke</p><p>Abstract: We investigate the problem of identifying the position of a viewer inside a room of planar mirrors with unknown geometry in conjunction with the room’s shape parameters. We consider the observations to consist of angularly resolved depth measurements of a single scene point that is being observed via many multi-bounce interactions with the specular room geometry. Applications of this problem statement include areas such as calibration, acoustic echo cancelation and time-of-flight imaging. We theoretically analyze the problem and derive sufficient conditions for a combination of convex room geometry, observer, and scene point to be reconstructable. The resulting constructive algorithm is exponential in nature and, therefore, not directly applicable to practical scenarios. To counter the situation, we propose theoretically devised geometric constraints that enable an efficient pruning of the solution space and develop a heuristic randomized search algorithm that uses these constraints to obtain an effective solution. We demonstrate the effectiveness of our algorithm on extensive simulations as well as in a challenging real-world calibration scenario.</p><p>6 0.55176252 <a title="278-lsi-6" href="./cvpr-2013-Beyond_Point_Clouds%3A_Scene_Understanding_by_Reasoning_Geometry_and_Physics.html">61 cvpr-2013-Beyond Point Clouds: Scene Understanding by Reasoning Geometry and Physics</a></p>
<p>7 0.52980655 <a title="278-lsi-7" href="./cvpr-2013-Hallucinated_Humans_as_the_Hidden_Context_for_Labeling_3D_Scenes.html">197 cvpr-2013-Hallucinated Humans as the Hidden Context for Labeling 3D Scenes</a></p>
<p>8 0.52461112 <a title="278-lsi-8" href="./cvpr-2013-A_Linear_Approach_to_Matching_Cuboids_in_RGBD_Images.html">16 cvpr-2013-A Linear Approach to Matching Cuboids in RGBD Images</a></p>
<p>9 0.49516201 <a title="278-lsi-9" href="./cvpr-2013-Manhattan_Scene_Understanding_via_XSlit_Imaging.html">279 cvpr-2013-Manhattan Scene Understanding via XSlit Imaging</a></p>
<p>10 0.4767679 <a title="278-lsi-10" href="./cvpr-2013-Recovering_Line-Networks_in_Images_by_Junction-Point_Processes.html">351 cvpr-2013-Recovering Line-Networks in Images by Junction-Point Processes</a></p>
<p>11 0.47107449 <a title="278-lsi-11" href="./cvpr-2013-3D-Based_Reasoning_with_Blocks%2C_Support%2C_and_Stability.html">1 cvpr-2013-3D-Based Reasoning with Blocks, Support, and Stability</a></p>
<p>12 0.46567357 <a title="278-lsi-12" href="./cvpr-2013-Perceptual_Organization_and_Recognition_of_Indoor_Scenes_from_RGB-D_Images.html">329 cvpr-2013-Perceptual Organization and Recognition of Indoor Scenes from RGB-D Images</a></p>
<p>13 0.46536484 <a title="278-lsi-13" href="./cvpr-2013-Incorporating_User_Interaction_and_Topological_Constraints_within_Contour_Completion_via_Discrete_Calculus.html">222 cvpr-2013-Incorporating User Interaction and Topological Constraints within Contour Completion via Discrete Calculus</a></p>
<p>14 0.45391184 <a title="278-lsi-14" href="./cvpr-2013-Learning_Class-to-Image_Distance_with_Object_Matchings.html">247 cvpr-2013-Learning Class-to-Image Distance with Object Matchings</a></p>
<p>15 0.45309281 <a title="278-lsi-15" href="./cvpr-2013-A_Global_Approach_for_the_Detection_of_Vanishing_Points_and_Mutually_Orthogonal_Vanishing_Directions.html">12 cvpr-2013-A Global Approach for the Detection of Vanishing Points and Mutually Orthogonal Vanishing Directions</a></p>
<p>16 0.44782916 <a title="278-lsi-16" href="./cvpr-2013-Mesh_Based_Semantic_Modelling_for_Indoor_and_Outdoor_Scenes.html">284 cvpr-2013-Mesh Based Semantic Modelling for Indoor and Outdoor Scenes</a></p>
<p>17 0.44703656 <a title="278-lsi-17" href="./cvpr-2013-Fully-Connected_CRFs_with_Non-Parametric_Pairwise_Potential.html">180 cvpr-2013-Fully-Connected CRFs with Non-Parametric Pairwise Potential</a></p>
<p>18 0.44281191 <a title="278-lsi-18" href="./cvpr-2013-Spatial_Inference_Machines.html">406 cvpr-2013-Spatial Inference Machines</a></p>
<p>19 0.44018793 <a title="278-lsi-19" href="./cvpr-2013-Winding_Number_for_Region-Boundary_Consistent_Salient_Contour_Extraction.html">468 cvpr-2013-Winding Number for Region-Boundary Consistent Salient Contour Extraction</a></p>
<p>20 0.42611834 <a title="278-lsi-20" href="./cvpr-2013-Five_Shades_of_Grey_for_Fast_and_Reliable_Camera_Pose_Estimation.html">176 cvpr-2013-Five Shades of Grey for Fast and Reliable Camera Pose Estimation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.118), (4, 0.094), (5, 0.134), (37, 0.057), (58, 0.031), (68, 0.204), (81, 0.078), (86, 0.04), (89, 0.014), (95, 0.01), (97, 0.095)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.84820545 <a title="278-lda-1" href="./cvpr-2013-Calibrating_Photometric_Stereo_by_Holistic_Reflectance_Symmetry_Analysis.html">75 cvpr-2013-Calibrating Photometric Stereo by Holistic Reflectance Symmetry Analysis</a></p>
<p>Author: Zhe Wu, Ping Tan</p><p>Abstract: Under unknown directional lighting, the uncalibrated Lambertian photometric stereo algorithm recovers the shape of a smooth surface up to the generalized bas-relief (GBR) ambiguity. We resolve this ambiguity from the halfvector symmetry, which is observed in many isotropic materials. Under this symmetry, a 2D BRDF slice with low-rank structure can be obtained from an image, if the surface normals and light directions are correctly recovered. In general, this structure is destroyed by the GBR ambiguity. As a result, we can resolve the ambiguity by restoring this structure. We develop a simple algorithm of auto-calibration from separable homogeneous specular reflection of real images. Compared with previous methods, this method takes a holistic approach to exploiting reflectance symmetry and produces superior results.</p><p>2 0.82969415 <a title="278-lda-2" href="./cvpr-2013-Mirror_Surface_Reconstruction_from_a_Single_Image.html">286 cvpr-2013-Mirror Surface Reconstruction from a Single Image</a></p>
<p>Author: Miaomiao Liu, Richard Hartley, Mathieu Salzmann</p><p>Abstract: This paper tackles the problem of reconstructing the shape of a smooth mirror surface from a single image. In particular, we consider the case where the camera is observing the reflection of a static reference target in the unknown mirror. We first study the reconstruction problem given dense correspondences between 3D points on the reference target and image locations. In such conditions, our differential geometry analysis provides a theoretical proof that the shape of the mirror surface can be uniquely recovered if the pose of the reference target is known. We then relax our assumptions by considering the case where only sparse correspondences are available. In this scenario, we formulate reconstruction as an optimization problem, which can be solved using a nonlinear least-squares method. We demonstrate the effectiveness of our method on both synthetic and real images.</p><p>same-paper 3 0.82344818 <a title="278-lda-3" href="./cvpr-2013-Manhattan_Junction_Catalogue_for_Spatial_Reasoning_of_Indoor_Scenes.html">278 cvpr-2013-Manhattan Junction Catalogue for Spatial Reasoning of Indoor Scenes</a></p>
<p>Author: Srikumar Ramalingam, Jaishanker K. Pillai, Arpit Jain, Yuichi Taguchi</p><p>Abstract: Junctions are strong cues for understanding the geometry of a scene. In this paper, we consider the problem of detecting junctions and using them for recovering the spatial layout of an indoor scene. Junction detection has always been challenging due to missing and spurious lines. We work in a constrained Manhattan world setting where the junctions are formed by only line segments along the three principal orthogonal directions. Junctions can be classified into several categories based on the number and orientations of the incident line segments. We provide a simple and efficient voting scheme to detect and classify these junctions in real images. Indoor scenes are typically modeled as cuboids and we formulate the problem of the cuboid layout estimation as an inference problem in a conditional random field. Our formulation allows the incorporation of junction features and the training is done using structured prediction techniques. We outperform other single view geometry estimation methods on standard datasets.</p><p>4 0.80522013 <a title="278-lda-4" href="./cvpr-2013-As-Projective-As-Possible_Image_Stitching_with_Moving_DLT.html">47 cvpr-2013-As-Projective-As-Possible Image Stitching with Moving DLT</a></p>
<p>Author: Julio Zaragoza, Tat-Jun Chin, Michael S. Brown, David Suter</p><p>Abstract: We investigate projective estimation under model inadequacies, i.e., when the underpinning assumptions oftheprojective model are not fully satisfied by the data. We focus on the task of image stitching which is customarily solved by estimating a projective warp — a model that is justified when the scene is planar or when the views differ purely by rotation. Such conditions are easily violated in practice, and this yields stitching results with ghosting artefacts that necessitate the usage of deghosting algorithms. To this end we propose as-projective-as-possible warps, i.e., warps that aim to be globally projective, yet allow local non-projective deviations to account for violations to the assumed imaging conditions. Based on a novel estimation technique called Moving Direct Linear Transformation (Moving DLT), our method seamlessly bridges image regions that are inconsistent with the projective model. The result is highly accurate image stitching, with significantly reduced ghosting effects, thus lowering the dependency on post hoc deghosting.</p><p>5 0.79229015 <a title="278-lda-5" href="./cvpr-2013-Pattern-Driven_Colorization_of_3D_Surfaces.html">327 cvpr-2013-Pattern-Driven Colorization of 3D Surfaces</a></p>
<p>Author: George Leifman, Ayellet Tal</p><p>Abstract: Colorization refers to the process of adding color to black & white images or videos. This paper extends the term to handle surfaces in three dimensions. This is important for applications in which the colors of an object need to be restored and no relevant image exists for texturing it. We focus on surfaces with patterns and propose a novel algorithm for adding colors to these surfaces. The user needs only to scribble a few color strokes on one instance of each pattern, and the system proceeds to automatically colorize the whole surface. For this scheme to work, we address not only the problem of colorization, but also the problem of pattern detection on surfaces.</p><p>6 0.7606644 <a title="278-lda-6" href="./cvpr-2013-Better_Exploiting_Motion_for_Better_Action_Recognition.html">59 cvpr-2013-Better Exploiting Motion for Better Action Recognition</a></p>
<p>7 0.75892645 <a title="278-lda-7" href="./cvpr-2013-Robust_Monocular_Epipolar_Flow_Estimation.html">362 cvpr-2013-Robust Monocular Epipolar Flow Estimation</a></p>
<p>8 0.75710565 <a title="278-lda-8" href="./cvpr-2013-The_Variational_Structure_of_Disparity_and_Regularization_of_4D_Light_Fields.html">431 cvpr-2013-The Variational Structure of Disparity and Regularization of 4D Light Fields</a></p>
<p>9 0.74785066 <a title="278-lda-9" href="./cvpr-2013-SWIGS%3A_A_Swift_Guided_Sampling_Method.html">373 cvpr-2013-SWIGS: A Swift Guided Sampling Method</a></p>
<p>10 0.7466203 <a title="278-lda-10" href="./cvpr-2013-Multi-target_Tracking_by_Lagrangian_Relaxation_to_Min-cost_Network_Flow.html">300 cvpr-2013-Multi-target Tracking by Lagrangian Relaxation to Min-cost Network Flow</a></p>
<p>11 0.74588597 <a title="278-lda-11" href="./cvpr-2013-Motion_Estimation_for_Self-Driving_Cars_with_a_Generalized_Camera.html">290 cvpr-2013-Motion Estimation for Self-Driving Cars with a Generalized Camera</a></p>
<p>12 0.74508107 <a title="278-lda-12" href="./cvpr-2013-Robust_Estimation_of_Nonrigid_Transformation_for_Point_Set_Registration.html">360 cvpr-2013-Robust Estimation of Nonrigid Transformation for Point Set Registration</a></p>
<p>13 0.74462909 <a title="278-lda-13" href="./cvpr-2013-Discovering_the_Structure_of_a_Planar_Mirror_System_from_Multiple_Observations_of_a_Single_Point.html">127 cvpr-2013-Discovering the Structure of a Planar Mirror System from Multiple Observations of a Single Point</a></p>
<p>14 0.74448824 <a title="278-lda-14" href="./cvpr-2013-Optimal_Geometric_Fitting_under_the_Truncated_L2-Norm.html">317 cvpr-2013-Optimal Geometric Fitting under the Truncated L2-Norm</a></p>
<p>15 0.7431649 <a title="278-lda-15" href="./cvpr-2013-Megastereo%3A_Constructing_High-Resolution_Stereo_Panoramas.html">283 cvpr-2013-Megastereo: Constructing High-Resolution Stereo Panoramas</a></p>
<p>16 0.74159479 <a title="278-lda-16" href="./cvpr-2013-Optical_Flow_Estimation_Using_Laplacian_Mesh_Energy.html">316 cvpr-2013-Optical Flow Estimation Using Laplacian Mesh Energy</a></p>
<p>17 0.74121684 <a title="278-lda-17" href="./cvpr-2013-Template-Based_Isometric_Deformable_3D_Reconstruction_with_Sampling-Based_Focal_Length_Self-Calibration.html">423 cvpr-2013-Template-Based Isometric Deformable 3D Reconstruction with Sampling-Based Focal Length Self-Calibration</a></p>
<p>18 0.74066871 <a title="278-lda-18" href="./cvpr-2013-Fast_Energy_Minimization_Using_Learned_State_Filters.html">165 cvpr-2013-Fast Energy Minimization Using Learned State Filters</a></p>
<p>19 0.74003899 <a title="278-lda-19" href="./cvpr-2013-The_Episolar_Constraint%3A_Monocular_Shape_from_Shadow_Correspondence.html">428 cvpr-2013-The Episolar Constraint: Monocular Shape from Shadow Correspondence</a></p>
<p>20 0.73992622 <a title="278-lda-20" href="./cvpr-2013-Patch_Match_Filter%3A_Efficient_Edge-Aware_Filtering_Meets_Randomized_Search_for_Fast_Correspondence_Field_Estimation.html">326 cvpr-2013-Patch Match Filter: Efficient Edge-Aware Filtering Meets Randomized Search for Fast Correspondence Field Estimation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
