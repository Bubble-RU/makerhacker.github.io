<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>429 cvpr-2013-The Generalized Laplacian Distance and Its Applications for Visual Matching</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-429" href="#">cvpr2013-429</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>429 cvpr-2013-The Generalized Laplacian Distance and Its Applications for Visual Matching</h1>
<br/><p>Source: <a title="cvpr-2013-429-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Elboer_The_Generalized_Laplacian_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Elhanan Elboer, Michael Werman, Yacov Hel-Or</p><p>Abstract: The graph Laplacian operator, which originated in spectral graph theory, is commonly used for learning applications such as spectral clustering and embedding. In this paper we explore the Laplacian distance, a distance function related to the graph Laplacian, and use it for visual search. We show that previous techniques such as Matching by Tone Mapping (MTM) are particular cases of the Laplacian distance. Generalizing the Laplacian distance results in distance measures which are tolerant to various visual distortions. A novel algorithm based on linear decomposition makes it possible to compute these generalized distances efficiently. The proposed approach is demonstrated for tone mapping invariant, outlier robust and multimodal template matching.</p><p>Reference: <a title="cvpr-2013-429-reference" href="../cvpr2013_reference/cvpr-2013-The_Generalized_Laplacian_Distance_and_Its_Applications_for_Visual_Matching_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('gldabs', 0.436), ('mtm', 0.411), ('csign', 0.291), ('qj', 0.252), ('laplac', 0.25), ('templ', 0.224), ('ncc', 0.2), ('gld', 0.194), ('qi', 0.183), ('ton', 0.132), ('glds', 0.129), ('fij', 0.104), ('pj', 0.094), ('ld', 0.093), ('dissimil', 0.092), ('convolv', 0.091), ('vk', 0.09), ('wij', 0.088), ('pi', 0.087), ('wb', 0.085)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="429-tfidf-1" href="./cvpr-2013-The_Generalized_Laplacian_Distance_and_Its_Applications_for_Visual_Matching.html">429 cvpr-2013-The Generalized Laplacian Distance and Its Applications for Visual Matching</a></p>
<p>Author: Elhanan Elboer, Michael Werman, Yacov Hel-Or</p><p>Abstract: The graph Laplacian operator, which originated in spectral graph theory, is commonly used for learning applications such as spectral clustering and embedding. In this paper we explore the Laplacian distance, a distance function related to the graph Laplacian, and use it for visual search. We show that previous techniques such as Matching by Tone Mapping (MTM) are particular cases of the Laplacian distance. Generalizing the Laplacian distance results in distance measures which are tolerant to various visual distortions. A novel algorithm based on linear decomposition makes it possible to compute these generalized distances efficiently. The proposed approach is demonstrated for tone mapping invariant, outlier robust and multimodal template matching.</p><p>2 0.14472336 <a title="429-tfidf-2" href="./cvpr-2013-FasT-Match%3A_Fast_Affine_Template_Matching.html">162 cvpr-2013-FasT-Match: Fast Affine Template Matching</a></p>
<p>Author: Simon Korman, Daniel Reichman, Gilad Tsur, Shai Avidan</p><p>Abstract: Fast-Match is a fast algorithm for approximate template matching under 2D affine transformations that minimizes the Sum-of-Absolute-Differences (SAD) error measure. There is a huge number of transformations to consider but we prove that they can be sampled using a density that depends on the smoothness of the image. For each potential transformation, we approximate the SAD error using a sublinear algorithm that randomly examines only a small number of pixels. We further accelerate the algorithm using a branch-and-bound scheme. As images are known to be piecewise smooth, the result is a practical affine template matching algorithm with approximation guarantees, that takes a few seconds to run on a standard machine. We perform several experiments on three different datasets, and report very good results. To the best of our knowledge, this is the first template matching algorithm which is guaranteed to handle arbitrary 2D affine transformations.</p><p>3 0.091883935 <a title="429-tfidf-3" href="./cvpr-2013-Expanded_Parts_Model_for_Human_Attribute_and_Action_Recognition_in_Still_Images.html">153 cvpr-2013-Expanded Parts Model for Human Attribute and Action Recognition in Still Images</a></p>
<p>Author: Gaurav Sharma, Frédéric Jurie, Cordelia Schmid</p><p>Abstract: We propose a new model for recognizing human attributes (e.g. wearing a suit, sitting, short hair) and actions (e.g. running, riding a horse) in still images. The proposed model relies on a collection of part templates which are learnt discriminatively to explain specific scale-space locations in the images (in human centric coordinates). It avoids the limitations of highly structured models, which consist of a few (i.e. a mixture of) ‘average ’ templates. To learn our model, we propose an algorithm which automatically mines out parts and learns corresponding discriminative templates with their respective locations from a large number of candidate parts. We validate the method on recent challenging datasets: (i) Willow 7 actions [7], (ii) 27 Human Attributes (HAT) [25], and (iii) Stanford 40 actions [37]. We obtain convincing qualitative and state-of-the-art quantitative results on the three datasets.</p><p>4 0.087838195 <a title="429-tfidf-4" href="./cvpr-2013-Human_Pose_Estimation_Using_Body_Parts_Dependent_Joint_Regressors.html">206 cvpr-2013-Human Pose Estimation Using Body Parts Dependent Joint Regressors</a></p>
<p>Author: Matthias Dantone, Juergen Gall, Christian Leistner, Luc Van_Gool</p><p>Abstract: In this work, we address the problem of estimating 2d human pose from still images. Recent methods that rely on discriminatively trained deformable parts organized in a tree model have shown to be very successful in solving this task. Within such a pictorial structure framework, we address the problem of obtaining good part templates by proposing novel, non-linear joint regressors. In particular, we employ two-layered random forests as joint regressors. The first layer acts as a discriminative, independent body part classifier. The second layer takes the estimated class distributions of the first one into account and is thereby able to predict joint locations by modeling the interdependence and co-occurrence of the parts. This results in a pose estimation framework that takes dependencies between body parts already for joint localization into account and is thus able to circumvent typical ambiguities of tree structures, such as for legs and arms. In the experiments, we demonstrate that our body parts dependent joint regressors achieve a higher joint localization accuracy than tree-based state-of-the-art methods.</p><p>5 0.087654367 <a title="429-tfidf-5" href="./cvpr-2013-Fully-Connected_CRFs_with_Non-Parametric_Pairwise_Potential.html">180 cvpr-2013-Fully-Connected CRFs with Non-Parametric Pairwise Potential</a></p>
<p>Author: Neill D.F. Campbell, Kartic Subr, Jan Kautz</p><p>Abstract: Conditional Random Fields (CRFs) are used for diverse tasks, ranging from image denoising to object recognition. For images, they are commonly defined as a graph with nodes corresponding to individual pixels and pairwise links that connect nodes to their immediate neighbors. Recent work has shown that fully-connected CRFs, where each node is connected to every other node, can be solved efficiently under the restriction that the pairwise term is a Gaussian kernel over a Euclidean feature space. In this paper, we generalize the pairwise terms to a non-linear dissimilarity measure that is not required to be a distance metric. To this end, we propose a density estimation technique to derive conditional pairwise potentials in a nonparametric manner. We then use an efficient embedding technique to estimate an approximate Euclidean feature space for these potentials, in which the pairwise term can still be expressed as a Gaussian kernel. We demonstrate that the use of non-parametric models for the pairwise interactions, conditioned on the input data, greatly increases expressive power whilst maintaining efficient inference.</p><p>6 0.085957013 <a title="429-tfidf-6" href="./cvpr-2013-Least_Soft-Threshold_Squares_Tracking.html">267 cvpr-2013-Least Soft-Threshold Squares Tracking</a></p>
<p>7 0.085360222 <a title="429-tfidf-7" href="./cvpr-2013-Optical_Flow_Estimation_Using_Laplacian_Mesh_Energy.html">316 cvpr-2013-Optical Flow Estimation Using Laplacian Mesh Energy</a></p>
<p>8 0.072867818 <a title="429-tfidf-8" href="./cvpr-2013-A_Practical_Rank-Constrained_Eight-Point_Algorithm_for_Fundamental_Matrix_Estimation.html">23 cvpr-2013-A Practical Rank-Constrained Eight-Point Algorithm for Fundamental Matrix Estimation</a></p>
<p>9 0.067662179 <a title="429-tfidf-9" href="./cvpr-2013-Fast_Convolutional_Sparse_Coding.html">164 cvpr-2013-Fast Convolutional Sparse Coding</a></p>
<p>10 0.065357588 <a title="429-tfidf-10" href="./cvpr-2013-Joint_Spectral_Correspondence_for_Disparate_Image_Matching.html">234 cvpr-2013-Joint Spectral Correspondence for Disparate Image Matching</a></p>
<p>11 0.063427299 <a title="429-tfidf-11" href="./cvpr-2013-Graph-Laplacian_PCA%3A_Closed-Form_Solution_and_Robustness.html">191 cvpr-2013-Graph-Laplacian PCA: Closed-Form Solution and Robustness</a></p>
<p>12 0.059819702 <a title="429-tfidf-12" href="./cvpr-2013-Graph_Matching_with_Anchor_Nodes%3A_A_Learning_Approach.html">192 cvpr-2013-Graph Matching with Anchor Nodes: A Learning Approach</a></p>
<p>13 0.059671935 <a title="429-tfidf-13" href="./cvpr-2013-Learning_Separable_Filters.html">255 cvpr-2013-Learning Separable Filters</a></p>
<p>14 0.059650902 <a title="429-tfidf-14" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<p>15 0.057005182 <a title="429-tfidf-15" href="./cvpr-2013-SCaLE%3A_Supervised_and_Cascaded_Laplacian_Eigenmaps_for_Visual_Object_Recognition_Based_on_Nearest_Neighbors.html">371 cvpr-2013-SCaLE: Supervised and Cascaded Laplacian Eigenmaps for Visual Object Recognition Based on Nearest Neighbors</a></p>
<p>16 0.056311902 <a title="429-tfidf-16" href="./cvpr-2013-Template-Based_Isometric_Deformable_3D_Reconstruction_with_Sampling-Based_Focal_Length_Self-Calibration.html">423 cvpr-2013-Template-Based Isometric Deformable 3D Reconstruction with Sampling-Based Focal Length Self-Calibration</a></p>
<p>17 0.055380668 <a title="429-tfidf-17" href="./cvpr-2013-Constrained_Clustering_and_Its_Application_to_Face_Clustering_in_Videos.html">92 cvpr-2013-Constrained Clustering and Its Application to Face Clustering in Videos</a></p>
<p>18 0.054945242 <a title="429-tfidf-18" href="./cvpr-2013-Integrating_Grammar_and_Segmentation_for_Human_Pose_Estimation.html">225 cvpr-2013-Integrating Grammar and Segmentation for Human Pose Estimation</a></p>
<p>19 0.053578332 <a title="429-tfidf-19" href="./cvpr-2013-Event_Retrieval_in_Large_Video_Collections_with_Circulant_Temporal_Encoding.html">151 cvpr-2013-Event Retrieval in Large Video Collections with Circulant Temporal Encoding</a></p>
<p>20 0.053492174 <a title="429-tfidf-20" href="./cvpr-2013-Efficient_2D-to-3D_Correspondence_Filtering_for_Scalable_3D_Object_Recognition.html">138 cvpr-2013-Efficient 2D-to-3D Correspondence Filtering for Scalable 3D Object Recognition</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.114), (1, -0.021), (2, -0.002), (3, -0.018), (4, 0.005), (5, 0.002), (6, -0.023), (7, 0.04), (8, 0.017), (9, -0.011), (10, -0.016), (11, 0.01), (12, -0.084), (13, -0.007), (14, 0.017), (15, -0.039), (16, 0.042), (17, -0.027), (18, 0.016), (19, 0.005), (20, 0.049), (21, -0.008), (22, -0.008), (23, 0.011), (24, -0.014), (25, 0.018), (26, -0.023), (27, -0.046), (28, -0.068), (29, 0.061), (30, 0.021), (31, 0.002), (32, -0.007), (33, 0.001), (34, -0.012), (35, -0.024), (36, 0.023), (37, 0.073), (38, 0.014), (39, 0.041), (40, -0.017), (41, -0.013), (42, 0.001), (43, -0.023), (44, -0.056), (45, 0.001), (46, -0.017), (47, 0.112), (48, -0.015), (49, 0.03)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92239749 <a title="429-lsi-1" href="./cvpr-2013-The_Generalized_Laplacian_Distance_and_Its_Applications_for_Visual_Matching.html">429 cvpr-2013-The Generalized Laplacian Distance and Its Applications for Visual Matching</a></p>
<p>Author: Elhanan Elboer, Michael Werman, Yacov Hel-Or</p><p>Abstract: The graph Laplacian operator, which originated in spectral graph theory, is commonly used for learning applications such as spectral clustering and embedding. In this paper we explore the Laplacian distance, a distance function related to the graph Laplacian, and use it for visual search. We show that previous techniques such as Matching by Tone Mapping (MTM) are particular cases of the Laplacian distance. Generalizing the Laplacian distance results in distance measures which are tolerant to various visual distortions. A novel algorithm based on linear decomposition makes it possible to compute these generalized distances efficiently. The proposed approach is demonstrated for tone mapping invariant, outlier robust and multimodal template matching.</p><p>2 0.76778185 <a title="429-lsi-2" href="./cvpr-2013-FasT-Match%3A_Fast_Affine_Template_Matching.html">162 cvpr-2013-FasT-Match: Fast Affine Template Matching</a></p>
<p>Author: Simon Korman, Daniel Reichman, Gilad Tsur, Shai Avidan</p><p>Abstract: Fast-Match is a fast algorithm for approximate template matching under 2D affine transformations that minimizes the Sum-of-Absolute-Differences (SAD) error measure. There is a huge number of transformations to consider but we prove that they can be sampled using a density that depends on the smoothness of the image. For each potential transformation, we approximate the SAD error using a sublinear algorithm that randomly examines only a small number of pixels. We further accelerate the algorithm using a branch-and-bound scheme. As images are known to be piecewise smooth, the result is a practical affine template matching algorithm with approximation guarantees, that takes a few seconds to run on a standard machine. We perform several experiments on three different datasets, and report very good results. To the best of our knowledge, this is the first template matching algorithm which is guaranteed to handle arbitrary 2D affine transformations.</p><p>3 0.69133204 <a title="429-lsi-3" href="./cvpr-2013-Optimal_Geometric_Fitting_under_the_Truncated_L2-Norm.html">317 cvpr-2013-Optimal Geometric Fitting under the Truncated L2-Norm</a></p>
<p>Author: Erik Ask, Olof Enqvist, Fredrik Kahl</p><p>Abstract: This paper is concerned with model fitting in the presence of noise and outliers. Previously it has been shown that the number of outliers can be minimized with polynomial complexity in the number of measurements. This paper improves on these results in two ways. First, it is shown that for a large class of problems, the statistically more desirable truncated L2-norm can be optimized with the same complexity. Then, with the same methodology, it is shown how to transform multi-model fitting into a purely combinatorial problem—with worst-case complexity that is polynomial in the number of measurements, though exponential in the number of models. We apply our framework to a series of hard registration and stitching problems demonstrating that the approach is not only of theoretical interest. It gives a practical method for simultaneously dealing with measurement noise and large amounts of outliers for fitting problems with lowdimensional models.</p><p>4 0.66333979 <a title="429-lsi-4" href="./cvpr-2013-Gauging_Association_Patterns_of_Chromosome_Territories_via_Chromatic_Median.html">184 cvpr-2013-Gauging Association Patterns of Chromosome Territories via Chromatic Median</a></p>
<p>Author: Hu Ding, Branislav Stojkovic, Ronald Berezney, Jinhui Xu</p><p>Abstract: Computing accurate and robust organizational patterns of chromosome territories inside the cell nucleus is critical for understanding several fundamental genomic processes, such as co-regulation of gene activation, gene silencing, X chromosome inactivation, and abnormal chromosome rearrangement in cancer cells. The usage of advanced fluorescence labeling and image processing techniques has enabled researchers to investigate interactions of chromosome territories at large spatial resolution. The resulting high volume of generated data demands for high-throughput and automated image analysis methods. In this paper, we introduce a novel algorithmic tool for investigating association patterns of chromosome territories in a population of cells. Our method takes as input a set of graphs, one for each cell, containing information about spatial interaction of chromosome territories, and yields a single graph that contains essential information for the whole population and stands as its structural representative. We formulate this combinato- rial problem as a semi-definite programming and present novel techniques to efficiently solve it. We validate our approach on both artificial and real biological data; the experimental results suggest that our approach yields a nearoptimal solution, and can handle large-size datasets, which are significant improvements over existing techniques.</p><p>5 0.66246074 <a title="429-lsi-5" href="./cvpr-2013-A_Practical_Rank-Constrained_Eight-Point_Algorithm_for_Fundamental_Matrix_Estimation.html">23 cvpr-2013-A Practical Rank-Constrained Eight-Point Algorithm for Fundamental Matrix Estimation</a></p>
<p>Author: Yinqiang Zheng, Shigeki Sugimoto, Masatoshi Okutomi</p><p>Abstract: Due to its simplicity, the eight-point algorithm has been widely used in fundamental matrix estimation. Unfortunately, the rank-2 constraint of a fundamental matrix is enforced via a posterior rank correction step, thus leading to non-optimal solutions to the original problem. To address this drawback, existing algorithms need to solve either a very high order polynomial or a sequence of convex relaxation problems, both of which are computationally ineffective and numerically unstable. In this work, we present a new rank-2 constrained eight-point algorithm, which directly incorporates the rank-2 constraint in the minimization process. To avoid singularities, we propose to solve seven subproblems and retrieve their globally optimal solutions by using tailored polynomial system solvers. Our proposed method is noniterative, computationally efficient and numerically stable. Experiment results have verified its superiority over existing algebraic error based algorithms in terms of accuracy, as well as its advantages when used to initialize geometric error based algorithms.</p><p>6 0.64534259 <a title="429-lsi-6" href="./cvpr-2013-A_Fast_Semidefinite_Approach_to_Solving_Binary_Quadratic_Problems.html">9 cvpr-2013-A Fast Semidefinite Approach to Solving Binary Quadratic Problems</a></p>
<p>7 0.64310861 <a title="429-lsi-7" href="./cvpr-2013-Rotation%2C_Scaling_and_Deformation_Invariant_Scattering_for_Texture_Discrimination.html">369 cvpr-2013-Rotation, Scaling and Deformation Invariant Scattering for Texture Discrimination</a></p>
<p>8 0.63952029 <a title="429-lsi-8" href="./cvpr-2013-Robust_Estimation_of_Nonrigid_Transformation_for_Point_Set_Registration.html">360 cvpr-2013-Robust Estimation of Nonrigid Transformation for Point Set Registration</a></p>
<p>9 0.63534284 <a title="429-lsi-9" href="./cvpr-2013-A_New_Model_and_Simple_Algorithms_for_Multi-label_Mumford-Shah_Problems.html">20 cvpr-2013-A New Model and Simple Algorithms for Multi-label Mumford-Shah Problems</a></p>
<p>10 0.63118374 <a title="429-lsi-10" href="./cvpr-2013-Deformable_Graph_Matching.html">106 cvpr-2013-Deformable Graph Matching</a></p>
<p>11 0.61619759 <a title="429-lsi-11" href="./cvpr-2013-Joint_Spectral_Correspondence_for_Disparate_Image_Matching.html">234 cvpr-2013-Joint Spectral Correspondence for Disparate Image Matching</a></p>
<p>12 0.59852517 <a title="429-lsi-12" href="./cvpr-2013-Universality_of_the_Local_Marginal_Polytope.html">448 cvpr-2013-Universality of the Local Marginal Polytope</a></p>
<p>13 0.5978322 <a title="429-lsi-13" href="./cvpr-2013-Keypoints_from_Symmetries_by_Wave_Propagation.html">240 cvpr-2013-Keypoints from Symmetries by Wave Propagation</a></p>
<p>14 0.58823895 <a title="429-lsi-14" href="./cvpr-2013-A_Genetic_Algorithm-Based_Solver_for_Very_Large_Jigsaw_Puzzles.html">11 cvpr-2013-A Genetic Algorithm-Based Solver for Very Large Jigsaw Puzzles</a></p>
<p>15 0.58275717 <a title="429-lsi-15" href="./cvpr-2013-Diffusion_Processes_for_Retrieval_Revisited.html">126 cvpr-2013-Diffusion Processes for Retrieval Revisited</a></p>
<p>16 0.5713377 <a title="429-lsi-16" href="./cvpr-2013-Fast_Convolutional_Sparse_Coding.html">164 cvpr-2013-Fast Convolutional Sparse Coding</a></p>
<p>17 0.56479633 <a title="429-lsi-17" href="./cvpr-2013-Fast_Trust_Region_for_Segmentation.html">171 cvpr-2013-Fast Trust Region for Segmentation</a></p>
<p>18 0.56354839 <a title="429-lsi-18" href="./cvpr-2013-Constraints_as_Features.html">93 cvpr-2013-Constraints as Features</a></p>
<p>19 0.55917382 <a title="429-lsi-19" href="./cvpr-2013-Towards_Efficient_and_Exact_MAP-Inference_for_Large_Scale_Discrete_Computer_Vision_Problems_via_Combinatorial_Optimization.html">436 cvpr-2013-Towards Efficient and Exact MAP-Inference for Large Scale Discrete Computer Vision Problems via Combinatorial Optimization</a></p>
<p>20 0.5579024 <a title="429-lsi-20" href="./cvpr-2013-Auxiliary_Cuts_for_General_Classes_of_Higher_Order_Functionals.html">51 cvpr-2013-Auxiliary Cuts for General Classes of Higher Order Functionals</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.079), (4, 0.155), (5, 0.084), (29, 0.288), (37, 0.035), (81, 0.06), (86, 0.086), (95, 0.035), (97, 0.073)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.71812367 <a title="429-lda-1" href="./cvpr-2013-The_Generalized_Laplacian_Distance_and_Its_Applications_for_Visual_Matching.html">429 cvpr-2013-The Generalized Laplacian Distance and Its Applications for Visual Matching</a></p>
<p>Author: Elhanan Elboer, Michael Werman, Yacov Hel-Or</p><p>Abstract: The graph Laplacian operator, which originated in spectral graph theory, is commonly used for learning applications such as spectral clustering and embedding. In this paper we explore the Laplacian distance, a distance function related to the graph Laplacian, and use it for visual search. We show that previous techniques such as Matching by Tone Mapping (MTM) are particular cases of the Laplacian distance. Generalizing the Laplacian distance results in distance measures which are tolerant to various visual distortions. A novel algorithm based on linear decomposition makes it possible to compute these generalized distances efficiently. The proposed approach is demonstrated for tone mapping invariant, outlier robust and multimodal template matching.</p><p>2 0.58419001 <a title="429-lda-2" href="./cvpr-2013-Measuring_Crowd_Collectiveness.html">282 cvpr-2013-Measuring Crowd Collectiveness</a></p>
<p>Author: Bolei Zhou, Xiaoou Tang, Xiaogang Wang</p><p>Abstract: Collective motions are common in crowd systems and have attracted a great deal of attention in a variety of multidisciplinary fields. Collectiveness, which indicates the degree of individuals acting as a union in collective motion, is a fundamental and universal measurement for various crowd systems. By integrating path similarities among crowds on collective manifold, this paper proposes a descriptor of collectiveness and an efficient computation for the crowd and its constituent individuals. The algorithm of the Collective Merging is then proposed to detect collective motions from random motions. We validate the effectiveness and robustness of the proposed collectiveness descriptor on the system of self-driven particles. We then compare the collectiveness descriptor to human perception for collective motion and show high consistency. Our experiments regarding the detection of collective motions and the measurement of collectiveness in videos of pedestrian crowds and bacteria colony demonstrate a wide range of applications of the collectiveness descriptor1.</p><p>3 0.58293074 <a title="429-lda-3" href="./cvpr-2013-Joint_Spectral_Correspondence_for_Disparate_Image_Matching.html">234 cvpr-2013-Joint Spectral Correspondence for Disparate Image Matching</a></p>
<p>Author: Mayank Bansal, Kostas Daniilidis</p><p>Abstract: We address the problem of matching images with disparate appearance arising from factors like dramatic illumination (day vs. night), age (historic vs. new) and rendering style differences. The lack of local intensity or gradient patterns in these images makes the application of pixellevel descriptors like SIFT infeasible. We propose a novel formulation for detecting and matching persistent features between such images by analyzing the eigen-spectrum of the joint image graph constructed from all the pixels in the two images. We show experimental results of our approach on a public dataset of challenging image pairs and demonstrate significant performance improvements over state-of-the-art.</p><p>4 0.57470614 <a title="429-lda-4" href="./cvpr-2013-Hypergraphs_for_Joint_Multi-view_Reconstruction_and_Multi-object_Tracking.html">209 cvpr-2013-Hypergraphs for Joint Multi-view Reconstruction and Multi-object Tracking</a></p>
<p>Author: Martin Hofmann, Daniel Wolf, Gerhard Rigoll</p><p>Abstract: We generalize the network flow formulation for multiobject tracking to multi-camera setups. In the past, reconstruction of multi-camera data was done as a separate extension. In this work, we present a combined maximum a posteriori (MAP) formulation, which jointly models multicamera reconstruction as well as global temporal data association. A flow graph is constructed, which tracks objects in 3D world space. The multi-camera reconstruction can be efficiently incorporated as additional constraints on the flow graph without making the graph unnecessarily large. The final graph is efficiently solved using binary linear programming. On the PETS 2009 dataset we achieve results that significantly exceed the current state of the art.</p><p>5 0.57448125 <a title="429-lda-5" href="./cvpr-2013-Video_Editing_with_Temporal%2C_Spatial_and_Appearance_Consistency.html">453 cvpr-2013-Video Editing with Temporal, Spatial and Appearance Consistency</a></p>
<p>Author: Xiaojie Guo, Xiaochun Cao, Xiaowu Chen, Yi Ma</p><p>Abstract: Given an area of interest in a video sequence, one may want to manipulate or edit the area, e.g. remove occlusions from or replace with an advertisement on it. Such a task involves three main challenges including temporal consistency, spatial pose, and visual realism. The proposed method effectively seeks an optimal solution to simultaneously deal with temporal alignment, pose rectification, as well as precise recovery of the occlusion. To make our method applicable to long video sequences, we propose a batch alignment method for automatically aligning and rectifying a small number of initial frames, and then show how to align the remaining frames incrementally to the aligned base images. From the error residual of the robust alignment process, we automatically construct a trimap of the region for each frame, which is used as the input to alpha matting methods to extract the occluding foreground. Experimental results on both simulated and real data demonstrate the accurate and robust performance of our method.</p><p>6 0.57342803 <a title="429-lda-6" href="./cvpr-2013-Procrustean_Normal_Distribution_for_Non-rigid_Structure_from_Motion.html">341 cvpr-2013-Procrustean Normal Distribution for Non-rigid Structure from Motion</a></p>
<p>7 0.56894481 <a title="429-lda-7" href="./cvpr-2013-Recovering_Stereo_Pairs_from_Anaglyphs.html">352 cvpr-2013-Recovering Stereo Pairs from Anaglyphs</a></p>
<p>8 0.56857514 <a title="429-lda-8" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<p>9 0.56712943 <a title="429-lda-9" href="./cvpr-2013-Dense_Variational_Reconstruction_of_Non-rigid_Surfaces_from_Monocular_Video.html">113 cvpr-2013-Dense Variational Reconstruction of Non-rigid Surfaces from Monocular Video</a></p>
<p>10 0.56700206 <a title="429-lda-10" href="./cvpr-2013-BRDF_Slices%3A_Accurate_Adaptive_Anisotropic_Appearance_Acquisition.html">54 cvpr-2013-BRDF Slices: Accurate Adaptive Anisotropic Appearance Acquisition</a></p>
<p>11 0.56627202 <a title="429-lda-11" href="./cvpr-2013-SWIGS%3A_A_Swift_Guided_Sampling_Method.html">373 cvpr-2013-SWIGS: A Swift Guided Sampling Method</a></p>
<p>12 0.56606227 <a title="429-lda-12" href="./cvpr-2013-Real-Time_Model-Based_Rigid_Object_Pose_Estimation_and_Tracking_Combining_Dense_and_Sparse_Visual_Cues.html">345 cvpr-2013-Real-Time Model-Based Rigid Object Pose Estimation and Tracking Combining Dense and Sparse Visual Cues</a></p>
<p>13 0.56411338 <a title="429-lda-13" href="./cvpr-2013-Three-Dimensional_Bilateral_Symmetry_Plane_Estimation_in_the_Phase_Domain.html">432 cvpr-2013-Three-Dimensional Bilateral Symmetry Plane Estimation in the Phase Domain</a></p>
<p>14 0.5639807 <a title="429-lda-14" href="./cvpr-2013-Calibrating_Photometric_Stereo_by_Holistic_Reflectance_Symmetry_Analysis.html">75 cvpr-2013-Calibrating Photometric Stereo by Holistic Reflectance Symmetry Analysis</a></p>
<p>15 0.5631935 <a title="429-lda-15" href="./cvpr-2013-Robust_Monocular_Epipolar_Flow_Estimation.html">362 cvpr-2013-Robust Monocular Epipolar Flow Estimation</a></p>
<p>16 0.56296998 <a title="429-lda-16" href="./cvpr-2013-Separable_Dictionary_Learning.html">392 cvpr-2013-Separable Dictionary Learning</a></p>
<p>17 0.56275755 <a title="429-lda-17" href="./cvpr-2013-Motion_Estimation_for_Self-Driving_Cars_with_a_Generalized_Camera.html">290 cvpr-2013-Motion Estimation for Self-Driving Cars with a Generalized Camera</a></p>
<p>18 0.56265038 <a title="429-lda-18" href="./cvpr-2013-Templateless_Quasi-rigid_Shape_Modeling_with_Implicit_Loop-Closure.html">424 cvpr-2013-Templateless Quasi-rigid Shape Modeling with Implicit Loop-Closure</a></p>
<p>19 0.56235743 <a title="429-lda-19" href="./cvpr-2013-Fast_Rigid_Motion_Segmentation_via_Incrementally-Complex_Local_Models.html">170 cvpr-2013-Fast Rigid Motion Segmentation via Incrementally-Complex Local Models</a></p>
<p>20 0.56228632 <a title="429-lda-20" href="./cvpr-2013-Articulated_and_Restricted_Motion_Subspaces_and_Their_Signatures.html">46 cvpr-2013-Articulated and Restricted Motion Subspaces and Their Signatures</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
