<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>341 cvpr-2013-Procrustean Normal Distribution for Non-rigid Structure from Motion</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-341" href="#">cvpr2013-341</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>341 cvpr-2013-Procrustean Normal Distribution for Non-rigid Structure from Motion</h1>
<br/><p>Source: <a title="cvpr-2013-341-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Lee_Procrustean_Normal_Distribution_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Minsik Lee, Jungchan Cho, Chong-Ho Choi, Songhwai Oh</p><p>Abstract: Non-rigid structure from motion is a fundamental problem in computer vision, which is yet to be solved satisfactorily. The main difficulty of the problem lies in choosing the right constraints for the solution. In this paper, we propose new constraints that are more effective for non-rigid shape recovery. Unlike the other proposals which have mainly focused on restricting the deformation space using rank constraints, our proposal constrains the motion parameters so that the 3D shapes are most closely aligned to each other, which makes the rank constraints unnecessary. Based on these constraints, we define a new class ofprobability distribution called the Procrustean normal distribution and propose a new NRSfM algorithm, EM-PND. The experimental results show that the proposed method outperforms the existing methods, and it works well even if there is no temporal dependence between the observed samples.</p><p>Reference: <a title="cvpr-2013-341-reference" href="../cvpr2013_reference/cvpr-2013-Procrustean_Normal_Distribution_for_Non-rigid_Structure_from_Motion_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 In this paper, we propose new constraints that are more effective for non-rigid shape recovery. [sent-5, score-0.142]
</p><p>2 Unlike the other proposals which have mainly focused on restricting the deformation space using rank constraints, our proposal constrains the motion parameters so that the 3D shapes are most closely aligned to each other, which makes the rank constraints unnecessary. [sent-6, score-0.425]
</p><p>3 Based on these constraints, we define a new class ofprobability distribution called the Procrustean normal distribution and propose a new NRSfM algorithm, EM-PND. [sent-7, score-0.152]
</p><p>4 The experimental results show that the proposed method outperforms the existing methods, and it works well even if there is no temporal dependence between the observed samples. [sent-8, score-0.108]
</p><p>5 Structure from motion (SfM) [10], which estimates the 3D shape and pose of a rigid object from 2D-point tracks, is the most simple form of this problem. [sent-12, score-0.237]
</p><p>6 Majority of the approaches [4, 8, 11, 13] fix the number of shape bases to restrict the ‘degree’ of de{c j c 8 3 , chcho i ,  s  onghwai }@ s nu . [sent-19, score-0.14]
</p><p>7 [1] showed that only an orthogonality constraint on the rotations is sufficient to find a unique solution. [sent-23, score-0.249]
</p><p>8 However, the choice on the number of shape bases greatly affects the reconstruction performance and it is difficult to know the right number. [sent-24, score-0.178]
</p><p>9 These approaches assume temporal dependence between frames, and incorporate the discrete cosine transform (DCT) bases in the model. [sent-26, score-0.173]
</p><p>10 Most importantly, this number changes the solution of rotations, because the rotations are found based on the factorization results. [sent-29, score-0.244]
</p><p>11 This means that finding the correct rotations are vital for NRSFM. [sent-31, score-0.173]
</p><p>12 Because finding the correct rotations is important, we consider NRSfM as an alignment problem and introduce an additional constraint to each rotation matrix. [sent-33, score-0.294]
</p><p>13 This constraint is derived from the generalized Procrustes analysis (GPA) [6, 14], which aligns a set of shapes most closely to each other. [sent-34, score-0.18]
</p><p>14 We also modify the scale constraint in GPA to make the aligned shapes lie in a linear subspace, which makes the problem tractable. [sent-36, score-0.284]
</p><p>15 This subspace includes all possible deformation of shapes, and moreover, the null space of this subspace is 7-dimensional that is related to the variations due to rigid transformations. [sent-37, score-0.177]
</p><p>16 In other words, rigid and nonrigid shape variations are strictly separated under these con-  straints. [sent-38, score-0.316]
</p><p>17 This leads us to define a new class of probability distribution called the Procrustean normal distribution (PND), which is a special case of the normal distribution. [sent-39, score-0.202]
</p><p>18 Since there is no constraint on the deformation space, EM-PND loses less detail in the reconstructed shapes. [sent-41, score-0.139]
</p><p>19 Moreover, it does 1 1 12 2 27 78 80 8  not require any temporal dependence between the observed 2D tracks. [sent-42, score-0.108]
</p><p>20 EM-PND also works well when there are some missing data in the observation. [sent-43, score-0.082]
</p><p>21 Procrustean Normal Distribution Estimating rotations based on rank and orthonormality constraints as in other NRSfM algorithms can be troublesome, because of two reasons. [sent-49, score-0.362]
</p><p>22 First, knowing the correct rank is not easy and wrongly chosen rank can ruin the estimation. [sent-50, score-0.136]
</p><p>23 Second, how orthonormal the estimated rotations are is not directly connected to the accuracy ofthe rotations. [sent-51, score-0.173]
</p><p>24 Therefore, we propose another way to model the rotations  by incorporating GPA. [sent-52, score-0.173]
</p><p>25 GPA finds the relative motions (including rotations) between similar shapes by aligning them as closely as possible. [sent-53, score-0.139]
</p><p>26 This principle determines rigid motions by minimizing non-rigid variations, which can improve the accuracy of the estimated rotations in NRSfM. [sent-54, score-0.324]
</p><p>27 ) aligned shapes, and propose a new distribution based on the conditions. [sent-58, score-0.123]
</p><p>28 This distribution can be effectively used to separate rigid and non-rigid shape variations, and serves as a core component of the proposed algorithm. [sent-59, score-0.242]
</p><p>29 GPA and its modification GPA superimposes multiple landmark shapes to a common reference using rigid transformations. [sent-62, score-0.22]
</p><p>30 Let Xi ∈ Rnd si ∈ R, Ri ∈ Rnd ×nd, and ti ∈ Rnd be the 3D shape, scale, rotation, and translation, respectively, for the ith sample, 1 ≤ i≤ ns, where nd, np, and ns are the dimension of the coordinate system, the number of landmarks in a frame, and the number of frames, respectively. [sent-63, score-0.15]
</p><p>31 es shape space if the first constraint is used, and otherwi? [sent-96, score-0.151]
</p><p>32 Here, the translation component is removed from each shape in Step 1 and does not appear in the iterative procedure, because the optimal ti is in fact given as ti = −n1psiRiXi1 [6]. [sent-119, score-0.122]
</p><p>33 However, both the Procrustes and Kendall shape spaces are nonlinear manifolds, which make it hard to handle the distribution of the shape. [sent-124, score-0.126]
</p><p>34 We may drop the scale constraint to resolve this issue, but it is not a good idea because there can be scale changes due to camera motion that may significantly affect the reconstruction performance (as shown in the supplementary material). [sent-125, score-0.16]
</p><p>35 Therefore, we need to find a new scale constraint that makes the aligned shapes lie in a linear subspace. [sent-126, score-0.284]
</p><p>36 To do this, we propose another scale constraint so that each shape variation from the mean shape is orthogonal to the mean shape, i. [sent-127, score-0.275]
</p><p>37 si, and it makes the aligned shapes lie in the stereographic projection [14], which is a mapping from an n-dimensional sphere to a hyperplane, of a Procrustes shape space. [sent-150, score-0.283]
</p><p>38 This let us describe the distribution of the aligned shapes more easily using typ-  ical probability distributions. [sent-151, score-0.227]
</p><p>39 an aligned shape siRiXi and the last condition forces the set of the aligned shapes to be convex, which are relatively easy to handle. [sent-170, score-0.323]
</p><p>40 Hence, if we solve NRSfM based on a distribution constrained by these conditions, then we may enforce the reconstructed shapes to be a possible optimal solution for problem (1). [sent-171, score-0.218]
</p><p>41 Because there are three more conditions in (4) besides the first equation, which is the orthonormality constraint in other NRSfM algorithms, the solution may be quite different from the other NRSfM algorithms. [sent-173, score-0.163]
</p><p>42 Definition and Properties of PND Let Yi be the ith aligned shape expressed as Yi = siRiXi and Y = X, then (4) can be written as  ? [sent-177, score-0.194]
</p><p>43 e second and last conditions are linear equality and convex constraints w. [sent-188, score-0.1]
</p><p>44 However, if we relax the PSD constraint to a symmetric constraint, then the last one can be also expressed as a linear equality constraint w. [sent-192, score-0.152]
</p><p>45 ) To set the centroid of an aligned shape at the origin, an additional constraint is introduced as Yi1 = 0. [sent-199, score-0.223]
</p><p>46 (7)  These constraints can be simplified using the vectorization operator as ? [sent-200, score-0.102]
</p><p>47 T,  (9)  where yi is the ith column vector of Y and ⊗ is the Kro-  R? [sent-235, score-0.11]
</p><p>48 (10)  Note that nN, the number of columns of PN, corresponds to the degree of freedom (DOF) of a rigid transform. [sent-248, score-0.116]
</p><p>49 For example, nN = 7 for nd = 3, which corresponds to the DOF of a rigid transform (1 for scale, 3 for rotation, and 3 for translation) in a? [sent-249, score-0.172]
</p><p>50 , perpendicular to the subspace of rigid shape variations, the variations will ? [sent-269, score-0.252]
</p><p>51 e sum of the exterior products of yi with themselves. [sent-325, score-0.107]
</p><p>52 This proposition states that each constraint specifies a different orthogonal subspace. [sent-329, score-0.181]
</p><p>53 In other words, variations due to scaling, rotation and translation are mutually orthogonal to each other under the constraints in (8). [sent-330, score-0.269]
</p><p>54 Based on these constraints, we can define a new distribution that only includes non-rigid shape variations, eliminating rigid variations. [sent-331, score-0.242]
</p><p>55 Because PND does not include any rigid shape variations, it is possible to find relative motions between sample shapes by fitting them to a PND. [sent-375, score-0.33]
</p><p>56 First, because no low-rank constraint is needed for PND, there is no need to adjust the rank and less details will be lost in the fitting process. [sent-378, score-0.144]
</p><p>57 Second, PND strictly separates rigid and non-rigid variations in the fitting process, which will lead to more accurate motion parameters and reconstructed shapes. [sent-379, score-0.286]
</p><p>58 The idea ofruling out rigid variations is somewhat similar to that in [12], however, PND does not require accurate motion information in advance, unlike the approach. [sent-380, score-0.223]
</p><p>59 For PND, estimating the distribution of non-rigid variations determines the rigid motions as a by-product, because QN depends on the mean shape. [sent-381, score-0.263]
</p><p>60 form of a normal distribution is also Gaussian, hence Y? [sent-405, score-0.101]
</p><p>61 the  Note that (14) can be applied to distributions other than the normal distribution for the analysis of NRSfM, but we use the normal distribution for its simplicity. [sent-471, score-0.202]
</p><p>62 The proposed algorithm: EM-PND  ×np  Let Di ∈ Rnd be the input landmark data, observed by an orthographic camera, of the ith sample, and Wi ∈ Rnd be the weight matrix filled with ones and zeros that indicates whether the corresponding elements are observed or missing. [sent-475, score-0.116]
</p><p>63 lwliwjiljdlijl oifth weirjwkis=e 1,  (19)  where dijk and wijk are the (j, k)th elements of Di and Wi, respectively. [sent-480, score-0.132]
</p><p>64 Here, Xi is a hidden variable representing the true 3D shape of the ith sample. [sent-519, score-0.122]
</p><p>65 In order to represent the prior distribution of Xi, we assume that the aligned shapes Yi = siRiXi are independently and ident? [sent-551, score-0.227]
</p><p>66 All the constraints in this problem are the same as the constraints in (4) except that Xi is replaced with its expectation Mi. [sent-637, score-0.134]
</p><p>67 In this framework, the most difficult parameter to update is X, on which Q as well as the last three constraints in (29) depend. [sent-642, score-0.136]
</p><p>68 To resolve this, we regard Q as an independent parameter and simply ignore the constraints in the update of X. [sent-643, score-0.136]
</p><p>69 According to the constraints in (29), the feasible si and Ri are unique if the other parameters are fixed and all the samples are non-degenerate. [sent-662, score-0.139]
</p><p>70 The proposed method works well for random initial rotations when the shape variations are moderate, but the performance may deteriorate for large variations. [sent-688, score-0.309]
</p><p>71 Hence, we adopt the initialization method used in [5] for the rotations, which calculates rotations based on the factorization results for all possible numbers of shape bases and then automatically chooses the most ‘orthonormal’ ones. [sent-689, score-0.384]
</p><p>72 = 1, si  where zi is the vector of the missing elements for the ith sample and B = I −n1p11T. [sent-716, score-0.285]
</p><p>73 Li(zi) ∈ Rnd×np is a mapping that places each element of zi to the corresponding location in a shape matrix. [sent-717, score-0.159]
</p><p>74 Average reconstruction errors without noise and missing data  data \ methodEM-PPCAMPCSF2SPMEM-PND  TablewpFsdiytrhRa2folcnkieg. [sent-768, score-0.12]
</p><p>75 48 3706 943 missing data  data \ methodEM-PPCAMPCSF2SPMEM-PND  3. [sent-780, score-0.082]
</p><p>76 If a shape model rather than a reconstructed shape is needed, then X and Σ can be used instead. [sent-797, score-0.213]
</p><p>77 Similarly, si and Ri can be used to represent a rigid motion. [sent-798, score-0.188]
</p><p>78 Random scaling and rotation were applied to each of these samples to form a new 3D facial-landmark data with no temporal dependence. [sent-804, score-0.09]
</p><p>79 For the missing data, we randomly set 30 percents of the landmarks as missing. [sent-808, score-0.149]
</p><p>80 Average reconstruction errors with missing data and without noise  data \ methodEM-PPCAMPCSF2EM-PND  wspFdtyfiarhRcolkneGrtgciukCapenhg0 . [sent-812, score-0.12]
</p><p>81 Average reconstruction errors with noise and missing data  data \ methodEM-PPCAMPCSF2EM-PND  error, i. [sent-821, score-0.12]
</p><p>82 There are no experimental results for missing  data using SPM because SPM can not handle the case of missing data. [sent-836, score-0.164]
</p><p>83 Among the 32 cases, excluding four cases ofthe dance sequence, EM-PND gives the best performance except for two cases, and even for these two cases, EM-PND gives the second best performance. [sent-838, score-0.104]
</p><p>84 For the case in the pickup sequence without noise and missing data, the error difference between EM-PND and the best method is about five percent. [sent-839, score-0.14]
</p><p>85 For the shark sequence, EM-PPCA gives a smaller error than EM-PND for the case ofno missing data but with noise. [sent-840, score-0.176]
</p><p>86 This seems to be attributed due to the nature of the shark sequence, which was artificially generated by superposing two basis shapes [11]. [sent-841, score-0.166]
</p><p>87 Because of this, EMPPCA, which explicitly limits the number of shape bases in the reconstruction process, gives better performance for the shark data. [sent-842, score-0.272]
</p><p>88 The dance sequence includes a large deformation, and CSF2, which enforces temporal dependence between frames, gives better results than the other schemes. [sent-844, score-0.18]
</p><p>89 We expect that the performance of EM-PND for the dance sequence can also be improved by enforcing temporal dependence. [sent-845, score-0.085]
</p><p>90 Reconstructed results (top row: EM-PND, bottom row: the second best method, ◦: observed ground truth, : missing ground truth, reconstructed points). [sent-847, score-0.145]
</p><p>91 Note that CSF2 gives relatively good performance, but not for the FRGC data because CSF2 assumes the existence of temporal dependence between frames. [sent-853, score-0.14]
</p><p>92 EM-PND shows a better fit between the reconstructed points and the corresponding ground truth than the second best method, as can be seen from the reconstruction results in Fig. [sent-854, score-0.101]
</p><p>93 The videos of reconstructed shapes are also provided in the supplementary material to confirm the performance of EM-PND. [sent-856, score-0.167]
</p><p>94 Instead of rank constraints employed in the other methods, EM-PND imposes constraints on the motion parameters, following the practices in GPA, which makes the 3D shapes most closely aligned in a linear subspace. [sent-859, score-0.424]
</p><p>95 EM-PND gives state-of-the-art performance, as validated in the experimental results, by separating rigid and non-rigid variations and not using any  rank constraint. [sent-861, score-0.277]
</p><p>96 Future work will consider the problems of adding temporal dependence into the model and designing a new factorization algorithm based on PND to reduce the computation time. [sent-862, score-0.179]
</p><p>97 In defense of orthonormality constraints for nonrigid structure from motion. [sent-867, score-0.185]
</p><p>98 Shape and motion from image streams under orthography: a factorization method. [sent-945, score-0.117]
</p><p>99 Nonrigid structure-from-motion: Estimating shape and motion with hierarchical priors. [sent-952, score-0.121]
</p><p>100 A closed-form solution to non-rigid shape and motion recovery. [sent-966, score-0.121]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('pnd', 0.471), ('nrsfm', 0.326), ('vec', 0.312), ('gpa', 0.257), ('rotations', 0.173), ('sirixi', 0.14), ('di', 0.134), ('rigid', 0.116), ('xi', 0.111), ('rnd', 0.109), ('tvec', 0.109), ('shapes', 0.104), ('qn', 0.102), ('np', 0.101), ('pe', 0.09), ('zi', 0.084), ('ri', 0.083), ('missing', 0.082), ('constraint', 0.076), ('shape', 0.075), ('ry', 0.073), ('aligned', 0.072), ('si', 0.072), ('procrustean', 0.071), ('factorization', 0.071), ('dijk', 0.07), ('psd', 0.07), ('subjectto', 0.07), ('yiyt', 0.07), ('update', 0.069), ('rank', 0.068), ('constraints', 0.067), ('bases', 0.065), ('pn', 0.065), ('nonrigid', 0.064), ('rit', 0.064), ('yi', 0.063), ('reconstructed', 0.063), ('dependence', 0.063), ('shark', 0.062), ('wijk', 0.062), ('variations', 0.061), ('pickup', 0.058), ('rty', 0.058), ('proposition', 0.056), ('nd', 0.056), ('akhter', 0.054), ('orthonormality', 0.054), ('procrustes', 0.052), ('wi', 0.052), ('distribution', 0.051), ('spm', 0.051), ('normal', 0.05), ('orthogonal', 0.049), ('ci', 0.049), ('translation', 0.047), ('bxt', 0.047), ('fici', 0.047), ('fimi', 0.047), ('ivit', 0.047), ('kendall', 0.047), ('niw', 0.047), ('orthogonalized', 0.047), ('rimixt', 0.047), ('ritri', 0.047), ('seikh', 0.047), ('sitr', 0.047), ('sixi', 0.047), ('viuit', 0.047), ('ith', 0.047), ('motion', 0.046), ('temporal', 0.045), ('june', 0.045), ('rotation', 0.045), ('em', 0.044), ('exterior', 0.044), ('mi', 0.042), ('siri', 0.041), ('frgc', 0.041), ('yoga', 0.041), ('nr', 0.041), ('dance', 0.04), ('dof', 0.039), ('ptn', 0.038), ('reconstruction', 0.038), ('filled', 0.038), ('ny', 0.038), ('percents', 0.036), ('covariance', 0.036), ('motions', 0.035), ('vectorization', 0.035), ('drink', 0.035), ('seoul', 0.035), ('tr', 0.034), ('grand', 0.033), ('conditions', 0.033), ('lie', 0.032), ('gives', 0.032), ('zeros', 0.031), ('landmarks', 0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="341-tfidf-1" href="./cvpr-2013-Procrustean_Normal_Distribution_for_Non-rigid_Structure_from_Motion.html">341 cvpr-2013-Procrustean Normal Distribution for Non-rigid Structure from Motion</a></p>
<p>Author: Minsik Lee, Jungchan Cho, Chong-Ho Choi, Songhwai Oh</p><p>Abstract: Non-rigid structure from motion is a fundamental problem in computer vision, which is yet to be solved satisfactorily. The main difficulty of the problem lies in choosing the right constraints for the solution. In this paper, we propose new constraints that are more effective for non-rigid shape recovery. Unlike the other proposals which have mainly focused on restricting the deformation space using rank constraints, our proposal constrains the motion parameters so that the 3D shapes are most closely aligned to each other, which makes the rank constraints unnecessary. Based on these constraints, we define a new class ofprobability distribution called the Procrustean normal distribution and propose a new NRSfM algorithm, EM-PND. The experimental results show that the proposed method outperforms the existing methods, and it works well even if there is no temporal dependence between the observed samples.</p><p>2 0.30168623 <a title="341-tfidf-2" href="./cvpr-2013-Dense_Variational_Reconstruction_of_Non-rigid_Surfaces_from_Monocular_Video.html">113 cvpr-2013-Dense Variational Reconstruction of Non-rigid Surfaces from Monocular Video</a></p>
<p>Author: Ravi Garg, Anastasios Roussos, Lourdes Agapito</p><p>Abstract: This paper offers the first variational approach to the problem of dense 3D reconstruction of non-rigid surfaces from a monocular video sequence. We formulate nonrigid structure from motion (NRSfM) as a global variational energy minimization problem to estimate dense low-rank smooth 3D shapes for every frame along with the camera motion matrices, given dense 2D correspondences. Unlike traditional factorization based approaches to NRSfM, which model the low-rank non-rigid shape using a fixed number of basis shapes and corresponding coefficients, we minimize the rank of the matrix of time-varying shapes directly via trace norm minimization. In conjunction with this low-rank constraint, we use an edge preserving total-variation regularization term to obtain spatially smooth shapes for every frame. Thanks to proximal splitting techniques the optimization problem can be decomposed into many point-wise sub-problems and simple linear systems which can be easily solved on GPU hardware. We show results on real sequences of different objects (face, torso, beating heart) where, despite challenges in tracking, illumination changes and occlusions, our method reconstructs highly deforming smooth surfaces densely and accurately directly from video, without the need for any prior models or shape templates.</p><p>3 0.23609799 <a title="341-tfidf-3" href="./cvpr-2013-Non-rigid_Structure_from_Motion_with_Diffusion_Maps_Prior.html">306 cvpr-2013-Non-rigid Structure from Motion with Diffusion Maps Prior</a></p>
<p>Author: Lili Tao, Bogdan J. Matuszewski</p><p>Abstract: In this paper, a novel approach based on a non-linear manifold learning technique is proposed to recover 3D nonrigid structures from 2D image sequences captured by a single camera. Most ofthe existing approaches assume that 3D shapes can be accurately modelled in a linear subspace. These techniques perform well when the deformations are relatively small or simple, but fail when more complex deformations need to be recovered. The non-linear deformations are often observed in highly flexible objects for which the use of the linear model is impractical. A specific type of shape variations might be governed by only a small number of parameters, therefore can be wellrepresented in a low dimensional manifold. We learn a nonlinear shape prior using diffusion maps method. The key contribution in this paper is the introduction of the shape prior that constrain the reconstructed shapes to lie in the learned manifold. The proposed methodology has been validated quantitatively and qualitatively on 2D points sequences projected from the 3D motion capture data and real 2D video sequences. The comparisons oftheproposed man- ifold based method against several state-of-the-art techniques are shown on different types of deformable objects.</p><p>4 0.15220334 <a title="341-tfidf-4" href="./cvpr-2013-Articulated_and_Restricted_Motion_Subspaces_and_Their_Signatures.html">46 cvpr-2013-Articulated and Restricted Motion Subspaces and Their Signatures</a></p>
<p>Author: Bastien Jacquet, Roland Angst, Marc Pollefeys</p><p>Abstract: Articulated objects represent an important class ofobjects in our everyday environment. Automatic detection of the type of articulated or otherwise restricted motion and extraction of the corresponding motion parameters are therefore of high value, e.g. in order to augment an otherwise static 3D reconstruction with dynamic semantics, such as rotation axes and allowable translation directions for certain rigid parts or objects. Hence, in this paper, a novel theory to analyse relative transformations between two motion-restricted parts will be presented. The analysis is based on linear subspaces spanned by relative transformations. Moreover, a signature for relative transformations will be introduced which uniquely specifies the type of restricted motion encoded in these relative transformations. This theoretic framework enables the derivation of novel algebraic constraints, such as low-rank constraints for subsequent rotations around two fixed axes for example. Lastly, given the type of restricted motion as predicted by the signature, the paper shows how to extract all the motion parameters with matrix manipulations from linear algebra. Our theory is verified on several real data sets, such as a rotating blackboard or a wheel rolling on the floor amongst others.</p><p>5 0.12203736 <a title="341-tfidf-5" href="./cvpr-2013-Tensor-Based_High-Order_Semantic_Relation_Transfer_for_Semantic_Scene_Segmentation.html">425 cvpr-2013-Tensor-Based High-Order Semantic Relation Transfer for Semantic Scene Segmentation</a></p>
<p>Author: Heesoo Myeong, Kyoung Mu Lee</p><p>Abstract: We propose a novel nonparametric approach for semantic segmentation using high-order semantic relations. Conventional context models mainly focus on learning pairwise relationships between objects. Pairwise relations, however, are not enough to represent high-level contextual knowledge within images. In this paper, we propose semantic relation transfer, a method to transfer high-order semantic relations of objects from annotated images to unlabeled images analogous to label transfer techniques where label information are transferred. Wefirst define semantic tensors representing high-order relations of objects. Semantic relation transfer problem is then formulated as semi-supervised learning using a quadratic objective function of the semantic tensors. By exploiting low-rank property of the semantic tensors and employing Kronecker sum similarity, an efficient approximation algorithm is developed. Based on the predicted high-order semantic relations, we reason semantic segmentation and evaluate the performance on several challenging datasets.</p><p>6 0.10146806 <a title="341-tfidf-6" href="./cvpr-2013-Active_Contours_with_Group_Similarity.html">33 cvpr-2013-Active Contours with Group Similarity</a></p>
<p>7 0.08850684 <a title="341-tfidf-7" href="./cvpr-2013-Video_Editing_with_Temporal%2C_Spatial_and_Appearance_Consistency.html">453 cvpr-2013-Video Editing with Temporal, Spatial and Appearance Consistency</a></p>
<p>8 0.081942551 <a title="341-tfidf-8" href="./cvpr-2013-Top-Down_Segmentation_of_Non-rigid_Visual_Objects_Using_Derivative-Based_Search_on_Sparse_Manifolds.html">433 cvpr-2013-Top-Down Segmentation of Non-rigid Visual Objects Using Derivative-Based Search on Sparse Manifolds</a></p>
<p>9 0.080124632 <a title="341-tfidf-9" href="./cvpr-2013-Robust_Estimation_of_Nonrigid_Transformation_for_Point_Set_Registration.html">360 cvpr-2013-Robust Estimation of Nonrigid Transformation for Point Set Registration</a></p>
<p>10 0.079494387 <a title="341-tfidf-10" href="./cvpr-2013-Learning_Binary_Codes_for_High-Dimensional_Data_Using_Bilinear_Projections.html">246 cvpr-2013-Learning Binary Codes for High-Dimensional Data Using Bilinear Projections</a></p>
<p>11 0.078711875 <a title="341-tfidf-11" href="./cvpr-2013-Determining_Motion_Directly_from_Normal_Flows_Upon_the_Use_of_a_Spherical_Eye_Platform.html">124 cvpr-2013-Determining Motion Directly from Normal Flows Upon the Use of a Spherical Eye Platform</a></p>
<p>12 0.076017313 <a title="341-tfidf-12" href="./cvpr-2013-Deformable_Graph_Matching.html">106 cvpr-2013-Deformable Graph Matching</a></p>
<p>13 0.075453572 <a title="341-tfidf-13" href="./cvpr-2013-Fast_Rigid_Motion_Segmentation_via_Incrementally-Complex_Local_Models.html">170 cvpr-2013-Fast Rigid Motion Segmentation via Incrementally-Complex Local Models</a></p>
<p>14 0.075337008 <a title="341-tfidf-14" href="./cvpr-2013-A_New_Model_and_Simple_Algorithms_for_Multi-label_Mumford-Shah_Problems.html">20 cvpr-2013-A New Model and Simple Algorithms for Multi-label Mumford-Shah Problems</a></p>
<p>15 0.075179726 <a title="341-tfidf-15" href="./cvpr-2013-3D_Pictorial_Structures_for_Multiple_View_Articulated_Pose_Estimation.html">2 cvpr-2013-3D Pictorial Structures for Multiple View Articulated Pose Estimation</a></p>
<p>16 0.075153351 <a title="341-tfidf-16" href="./cvpr-2013-Learning_by_Associating_Ambiguously_Labeled_Images.html">261 cvpr-2013-Learning by Associating Ambiguously Labeled Images</a></p>
<p>17 0.074650832 <a title="341-tfidf-17" href="./cvpr-2013-Optimal_Geometric_Fitting_under_the_Truncated_L2-Norm.html">317 cvpr-2013-Optimal Geometric Fitting under the Truncated L2-Norm</a></p>
<p>18 0.070139453 <a title="341-tfidf-18" href="./cvpr-2013-A_Joint_Model_for_2D_and_3D_Pose_Estimation_from_a_Single_Image.html">14 cvpr-2013-A Joint Model for 2D and 3D Pose Estimation from a Single Image</a></p>
<p>19 0.068212375 <a title="341-tfidf-19" href="./cvpr-2013-Templateless_Quasi-rigid_Shape_Modeling_with_Implicit_Loop-Closure.html">424 cvpr-2013-Templateless Quasi-rigid Shape Modeling with Implicit Loop-Closure</a></p>
<p>20 0.066773593 <a title="341-tfidf-20" href="./cvpr-2013-Robust_Discriminative_Response_Map_Fitting_with_Constrained_Local_Models.html">359 cvpr-2013-Robust Discriminative Response Map Fitting with Constrained Local Models</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.167), (1, 0.072), (2, -0.039), (3, 0.038), (4, 0.012), (5, -0.041), (6, -0.012), (7, -0.099), (8, -0.019), (9, -0.018), (10, 0.059), (11, 0.069), (12, -0.093), (13, -0.069), (14, 0.042), (15, -0.017), (16, -0.007), (17, 0.036), (18, -0.068), (19, 0.029), (20, -0.009), (21, -0.044), (22, 0.031), (23, -0.033), (24, 0.132), (25, 0.05), (26, -0.053), (27, 0.016), (28, 0.051), (29, -0.049), (30, 0.056), (31, -0.063), (32, -0.173), (33, -0.056), (34, -0.039), (35, -0.019), (36, -0.088), (37, -0.031), (38, -0.043), (39, -0.135), (40, 0.072), (41, 0.122), (42, 0.016), (43, 0.008), (44, 0.027), (45, -0.033), (46, -0.044), (47, 0.121), (48, -0.125), (49, 0.038)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94071794 <a title="341-lsi-1" href="./cvpr-2013-Procrustean_Normal_Distribution_for_Non-rigid_Structure_from_Motion.html">341 cvpr-2013-Procrustean Normal Distribution for Non-rigid Structure from Motion</a></p>
<p>Author: Minsik Lee, Jungchan Cho, Chong-Ho Choi, Songhwai Oh</p><p>Abstract: Non-rigid structure from motion is a fundamental problem in computer vision, which is yet to be solved satisfactorily. The main difficulty of the problem lies in choosing the right constraints for the solution. In this paper, we propose new constraints that are more effective for non-rigid shape recovery. Unlike the other proposals which have mainly focused on restricting the deformation space using rank constraints, our proposal constrains the motion parameters so that the 3D shapes are most closely aligned to each other, which makes the rank constraints unnecessary. Based on these constraints, we define a new class ofprobability distribution called the Procrustean normal distribution and propose a new NRSfM algorithm, EM-PND. The experimental results show that the proposed method outperforms the existing methods, and it works well even if there is no temporal dependence between the observed samples.</p><p>2 0.82131779 <a title="341-lsi-2" href="./cvpr-2013-Dense_Variational_Reconstruction_of_Non-rigid_Surfaces_from_Monocular_Video.html">113 cvpr-2013-Dense Variational Reconstruction of Non-rigid Surfaces from Monocular Video</a></p>
<p>Author: Ravi Garg, Anastasios Roussos, Lourdes Agapito</p><p>Abstract: This paper offers the first variational approach to the problem of dense 3D reconstruction of non-rigid surfaces from a monocular video sequence. We formulate nonrigid structure from motion (NRSfM) as a global variational energy minimization problem to estimate dense low-rank smooth 3D shapes for every frame along with the camera motion matrices, given dense 2D correspondences. Unlike traditional factorization based approaches to NRSfM, which model the low-rank non-rigid shape using a fixed number of basis shapes and corresponding coefficients, we minimize the rank of the matrix of time-varying shapes directly via trace norm minimization. In conjunction with this low-rank constraint, we use an edge preserving total-variation regularization term to obtain spatially smooth shapes for every frame. Thanks to proximal splitting techniques the optimization problem can be decomposed into many point-wise sub-problems and simple linear systems which can be easily solved on GPU hardware. We show results on real sequences of different objects (face, torso, beating heart) where, despite challenges in tracking, illumination changes and occlusions, our method reconstructs highly deforming smooth surfaces densely and accurately directly from video, without the need for any prior models or shape templates.</p><p>3 0.80479968 <a title="341-lsi-3" href="./cvpr-2013-Non-rigid_Structure_from_Motion_with_Diffusion_Maps_Prior.html">306 cvpr-2013-Non-rigid Structure from Motion with Diffusion Maps Prior</a></p>
<p>Author: Lili Tao, Bogdan J. Matuszewski</p><p>Abstract: In this paper, a novel approach based on a non-linear manifold learning technique is proposed to recover 3D nonrigid structures from 2D image sequences captured by a single camera. Most ofthe existing approaches assume that 3D shapes can be accurately modelled in a linear subspace. These techniques perform well when the deformations are relatively small or simple, but fail when more complex deformations need to be recovered. The non-linear deformations are often observed in highly flexible objects for which the use of the linear model is impractical. A specific type of shape variations might be governed by only a small number of parameters, therefore can be wellrepresented in a low dimensional manifold. We learn a nonlinear shape prior using diffusion maps method. The key contribution in this paper is the introduction of the shape prior that constrain the reconstructed shapes to lie in the learned manifold. The proposed methodology has been validated quantitatively and qualitatively on 2D points sequences projected from the 3D motion capture data and real 2D video sequences. The comparisons oftheproposed man- ifold based method against several state-of-the-art techniques are shown on different types of deformable objects.</p><p>4 0.67368966 <a title="341-lsi-4" href="./cvpr-2013-Active_Contours_with_Group_Similarity.html">33 cvpr-2013-Active Contours with Group Similarity</a></p>
<p>Author: Xiaowei Zhou, Xiaojie Huang, James S. Duncan, Weichuan Yu</p><p>Abstract: Active contours are widely used in image segmentation. To cope with missing or misleading features in images, researchers have introduced various ways to model the prior of shapes and use the prior to constrain active contours. However, the shape prior is usually learnt from a large set of annotated data, which is not always accessible in practice. Moreover, it is often doubted that the existing shapes in the training set will be sufficient to model the new instance in the testing image. In this paper, we propose to use the group similarity of object shapes in multiple images as a prior to aid segmentation, which can be interpreted as an unsupervised approach of shape prior modeling. We show that the rank of the matrix consisting of multiple shapes is a good measure of the group similarity of the shapes, and the nuclear norm minimization is a simple and effective way to impose the proposed constraint on existing active contour models. Moreover, we develop a fast algorithm to solve the proposed model by using the accelerated proximal method. Experiments using echocardiographic image sequences acquired from acute canine experiments demonstrate that the proposed method can consistently improve the performance of active contour models and increase the robustness against image defects such as missing boundaries.</p><p>5 0.62419277 <a title="341-lsi-5" href="./cvpr-2013-Dense_Object_Reconstruction_with_Semantic_Priors.html">110 cvpr-2013-Dense Object Reconstruction with Semantic Priors</a></p>
<p>Author: Sid Yingze Bao, Manmohan Chandraker, Yuanqing Lin, Silvio Savarese</p><p>Abstract: We present a dense reconstruction approach that overcomes the drawbacks of traditional multiview stereo by incorporating semantic information in the form of learned category-level shape priors and object detection. Given training data comprised of 3D scans and images of objects from various viewpoints, we learn a prior comprised of a mean shape and a set of weighted anchor points. The former captures the commonality of shapes across the category, while the latter encodes similarities between instances in the form of appearance and spatial consistency. We propose robust algorithms to match anchor points across instances that enable learning a mean shape for the category, even with large shape variations across instances. We model the shape of an object instance as a warped version of the category mean, along with instance-specific details. Given multiple images of an unseen instance, we collate information from 2D object detectors to align the structure from motion point cloud with the mean shape, which is subsequently warped and refined to approach the actual shape. Extensive experiments demonstrate that our model is general enough to learn semantic priors for different object categories, yet powerful enough to reconstruct individual shapes with large variations. Qualitative and quantitative evaluations show that our framework can produce more accurate reconstructions than alternative state-of-the-art multiview stereo systems.</p><p>6 0.61890393 <a title="341-lsi-6" href="./cvpr-2013-Deep_Learning_Shape_Priors_for_Object_Segmentation.html">105 cvpr-2013-Deep Learning Shape Priors for Object Segmentation</a></p>
<p>7 0.61823612 <a title="341-lsi-7" href="./cvpr-2013-Articulated_and_Restricted_Motion_Subspaces_and_Their_Signatures.html">46 cvpr-2013-Articulated and Restricted Motion Subspaces and Their Signatures</a></p>
<p>8 0.61098021 <a title="341-lsi-8" href="./cvpr-2013-Robust_Canonical_Time_Warping_for_the_Alignment_of_Grossly_Corrupted_Sequences.html">358 cvpr-2013-Robust Canonical Time Warping for the Alignment of Grossly Corrupted Sequences</a></p>
<p>9 0.5935899 <a title="341-lsi-9" href="./cvpr-2013-PDM-ENLOR%3A_Learning_Ensemble_of_Local_PDM-Based_Regressions.html">321 cvpr-2013-PDM-ENLOR: Learning Ensemble of Local PDM-Based Regressions</a></p>
<p>10 0.57421905 <a title="341-lsi-10" href="./cvpr-2013-Accurate_and_Robust_Registration_of_Nonrigid_Surface_Using_Hierarchical_Statistical_Shape_Model.html">31 cvpr-2013-Accurate and Robust Registration of Nonrigid Surface Using Hierarchical Statistical Shape Model</a></p>
<p>11 0.54019511 <a title="341-lsi-11" href="./cvpr-2013-A_Practical_Rank-Constrained_Eight-Point_Algorithm_for_Fundamental_Matrix_Estimation.html">23 cvpr-2013-A Practical Rank-Constrained Eight-Point Algorithm for Fundamental Matrix Estimation</a></p>
<p>12 0.52536201 <a title="341-lsi-12" href="./cvpr-2013-Fast_Rigid_Motion_Segmentation_via_Incrementally-Complex_Local_Models.html">170 cvpr-2013-Fast Rigid Motion Segmentation via Incrementally-Complex Local Models</a></p>
<p>13 0.49746346 <a title="341-lsi-13" href="./cvpr-2013-Robust_Discriminative_Response_Map_Fitting_with_Constrained_Local_Models.html">359 cvpr-2013-Robust Discriminative Response Map Fitting with Constrained Local Models</a></p>
<p>14 0.49184239 <a title="341-lsi-14" href="./cvpr-2013-Top-Down_Segmentation_of_Non-rigid_Visual_Objects_Using_Derivative-Based_Search_on_Sparse_Manifolds.html">433 cvpr-2013-Top-Down Segmentation of Non-rigid Visual Objects Using Derivative-Based Search on Sparse Manifolds</a></p>
<p>15 0.47121322 <a title="341-lsi-15" href="./cvpr-2013-Relative_Hidden_Markov_Models_for_Evaluating_Motion_Skill.html">353 cvpr-2013-Relative Hidden Markov Models for Evaluating Motion Skill</a></p>
<p>16 0.46727231 <a title="341-lsi-16" href="./cvpr-2013-As-Projective-As-Possible_Image_Stitching_with_Moving_DLT.html">47 cvpr-2013-As-Projective-As-Possible Image Stitching with Moving DLT</a></p>
<p>17 0.46688232 <a title="341-lsi-17" href="./cvpr-2013-A_Divide-and-Conquer_Method_for_Scalable_Low-Rank_Latent_Matrix_Pursuit.html">7 cvpr-2013-A Divide-and-Conquer Method for Scalable Low-Rank Latent Matrix Pursuit</a></p>
<p>18 0.46073017 <a title="341-lsi-18" href="./cvpr-2013-Video_Editing_with_Temporal%2C_Spatial_and_Appearance_Consistency.html">453 cvpr-2013-Video Editing with Temporal, Spatial and Appearance Consistency</a></p>
<p>19 0.45941409 <a title="341-lsi-19" href="./cvpr-2013-Correlation_Filters_for_Object_Alignment.html">96 cvpr-2013-Correlation Filters for Object Alignment</a></p>
<p>20 0.44956383 <a title="341-lsi-20" href="./cvpr-2013-Auxiliary_Cuts_for_General_Classes_of_Higher_Order_Functionals.html">51 cvpr-2013-Auxiliary Cuts for General Classes of Higher Order Functionals</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.095), (16, 0.024), (26, 0.056), (28, 0.01), (33, 0.306), (39, 0.01), (67, 0.04), (69, 0.045), (76, 0.265), (87, 0.072)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.86330974 <a title="341-lda-1" href="./cvpr-2013-Optimal_Geometric_Fitting_under_the_Truncated_L2-Norm.html">317 cvpr-2013-Optimal Geometric Fitting under the Truncated L2-Norm</a></p>
<p>Author: Erik Ask, Olof Enqvist, Fredrik Kahl</p><p>Abstract: This paper is concerned with model fitting in the presence of noise and outliers. Previously it has been shown that the number of outliers can be minimized with polynomial complexity in the number of measurements. This paper improves on these results in two ways. First, it is shown that for a large class of problems, the statistically more desirable truncated L2-norm can be optimized with the same complexity. Then, with the same methodology, it is shown how to transform multi-model fitting into a purely combinatorial problem—with worst-case complexity that is polynomial in the number of measurements, though exponential in the number of models. We apply our framework to a series of hard registration and stitching problems demonstrating that the approach is not only of theoretical interest. It gives a practical method for simultaneously dealing with measurement noise and large amounts of outliers for fitting problems with lowdimensional models.</p><p>same-paper 2 0.8550573 <a title="341-lda-2" href="./cvpr-2013-Procrustean_Normal_Distribution_for_Non-rigid_Structure_from_Motion.html">341 cvpr-2013-Procrustean Normal Distribution for Non-rigid Structure from Motion</a></p>
<p>Author: Minsik Lee, Jungchan Cho, Chong-Ho Choi, Songhwai Oh</p><p>Abstract: Non-rigid structure from motion is a fundamental problem in computer vision, which is yet to be solved satisfactorily. The main difficulty of the problem lies in choosing the right constraints for the solution. In this paper, we propose new constraints that are more effective for non-rigid shape recovery. Unlike the other proposals which have mainly focused on restricting the deformation space using rank constraints, our proposal constrains the motion parameters so that the 3D shapes are most closely aligned to each other, which makes the rank constraints unnecessary. Based on these constraints, we define a new class ofprobability distribution called the Procrustean normal distribution and propose a new NRSfM algorithm, EM-PND. The experimental results show that the proposed method outperforms the existing methods, and it works well even if there is no temporal dependence between the observed samples.</p><p>3 0.85239422 <a title="341-lda-3" href="./cvpr-2013-Heterogeneous_Visual_Features_Fusion_via_Sparse_Multimodal_Machine.html">201 cvpr-2013-Heterogeneous Visual Features Fusion via Sparse Multimodal Machine</a></p>
<p>Author: Hua Wang, Feiping Nie, Heng Huang, Chris Ding</p><p>Abstract: To better understand, search, and classify image and video information, many visual feature descriptors have been proposed to describe elementary visual characteristics, such as the shape, the color, the texture, etc. How to integrate these heterogeneous visual features and identify the important ones from them for specific vision tasks has become an increasingly critical problem. In this paper, We propose a novel Sparse Multimodal Learning (SMML) approach to integrate such heterogeneous features by using the joint structured sparsity regularizations to learn the feature importance of for the vision tasks from both group-wise and individual point of views. A new optimization algorithm is also introduced to solve the non-smooth objective with rigorously proved global convergence. We applied our SMML method to five broadly used object categorization and scene understanding image data sets for both singlelabel and multi-label image classification tasks. For each data set we integrate six different types of popularly used image features. Compared to existing scene and object cat- egorization methods using either single modality or multimodalities of features, our approach always achieves better performances measured.</p><p>4 0.84428763 <a title="341-lda-4" href="./cvpr-2013-Tensor-Based_Human_Body_Modeling.html">426 cvpr-2013-Tensor-Based Human Body Modeling</a></p>
<p>Author: Yinpeng Chen, Zicheng Liu, Zhengyou Zhang</p><p>Abstract: In this paper, we present a novel approach to model 3D human body with variations on both human shape and pose, by exploring a tensor decomposition technique. 3D human body modeling is important for 3D reconstruction and animation of realistic human body, which can be widely used in Tele-presence and video game applications. It is challenging due to a wide range of shape variations over different people and poses. The existing SCAPE model [4] is popular in computer vision for modeling 3D human body. However, it considers shape and pose deformations separately, which is not accurate since pose deformation is persondependent. Our tensor-based model addresses this issue by jointly modeling shape and pose deformations. Experimental results demonstrate that our tensor-based model outperforms the SCAPE model quite significantly. We also apply our model to capture human body using Microsoft Kinect sensors with excellent results.</p><p>5 0.84375292 <a title="341-lda-5" href="./cvpr-2013-Topical_Video_Object_Discovery_from_Key_Frames_by_Modeling_Word_Co-occurrence_Prior.html">434 cvpr-2013-Topical Video Object Discovery from Key Frames by Modeling Word Co-occurrence Prior</a></p>
<p>Author: Gangqiang Zhao, Junsong Yuan, Gang Hua</p><p>Abstract: A topical video object refers to an object that is frequently highlighted in a video. It could be, e.g., the product logo and the leading actor/actress in a TV commercial. We propose a topic model that incorporates a word co-occurrence prior for efficient discovery of topical video objects from a set of key frames. Previous work using topic models, such as Latent Dirichelet Allocation (LDA), for video object discovery often takes a bag-of-visual-words representation, which ignored important co-occurrence information among the local features. We show that such data driven co-occurrence information from bottom-up can conveniently be incorporated in LDA with a Gaussian Markov prior, which combines top down probabilistic topic modeling with bottom up priors in a unified model. Our experiments on challenging videos demonstrate that the proposed approach can discover different types of topical objects despite variations in scale, view-point, color and lighting changes, or even partial occlusions. The efficacy of the co-occurrence prior is clearly demonstrated when comparing with topic models without such priors.</p><p>6 0.83204383 <a title="341-lda-6" href="./cvpr-2013-Pixel-Level_Hand_Detection_in_Ego-centric_Videos.html">332 cvpr-2013-Pixel-Level Hand Detection in Ego-centric Videos</a></p>
<p>7 0.79093879 <a title="341-lda-7" href="./cvpr-2013-Story-Driven_Summarization_for_Egocentric_Video.html">413 cvpr-2013-Story-Driven Summarization for Egocentric Video</a></p>
<p>8 0.7825163 <a title="341-lda-8" href="./cvpr-2013-Perceptual_Organization_and_Recognition_of_Indoor_Scenes_from_RGB-D_Images.html">329 cvpr-2013-Perceptual Organization and Recognition of Indoor Scenes from RGB-D Images</a></p>
<p>9 0.78250706 <a title="341-lda-9" href="./cvpr-2013-Label_Propagation_from_ImageNet_to_3D_Point_Clouds.html">242 cvpr-2013-Label Propagation from ImageNet to 3D Point Clouds</a></p>
<p>10 0.78235126 <a title="341-lda-10" href="./cvpr-2013-Understanding_Indoor_Scenes_Using_3D_Geometric_Phrases.html">446 cvpr-2013-Understanding Indoor Scenes Using 3D Geometric Phrases</a></p>
<p>11 0.78194153 <a title="341-lda-11" href="./cvpr-2013-Geometric_Context_from_Videos.html">187 cvpr-2013-Geometric Context from Videos</a></p>
<p>12 0.78166169 <a title="341-lda-12" href="./cvpr-2013-Robust_Monocular_Epipolar_Flow_Estimation.html">362 cvpr-2013-Robust Monocular Epipolar Flow Estimation</a></p>
<p>13 0.78140032 <a title="341-lda-13" href="./cvpr-2013-Mesh_Based_Semantic_Modelling_for_Indoor_and_Outdoor_Scenes.html">284 cvpr-2013-Mesh Based Semantic Modelling for Indoor and Outdoor Scenes</a></p>
<p>14 0.78096974 <a title="341-lda-14" href="./cvpr-2013-Correlation_Filters_for_Object_Alignment.html">96 cvpr-2013-Correlation Filters for Object Alignment</a></p>
<p>15 0.78094566 <a title="341-lda-15" href="./cvpr-2013-Tensor-Based_High-Order_Semantic_Relation_Transfer_for_Semantic_Scene_Segmentation.html">425 cvpr-2013-Tensor-Based High-Order Semantic Relation Transfer for Semantic Scene Segmentation</a></p>
<p>16 0.78091156 <a title="341-lda-16" href="./cvpr-2013-Multi-source_Multi-scale_Counting_in_Extremely_Dense_Crowd_Images.html">299 cvpr-2013-Multi-source Multi-scale Counting in Extremely Dense Crowd Images</a></p>
<p>17 0.78090757 <a title="341-lda-17" href="./cvpr-2013-SCALPEL%3A_Segmentation_Cascades_with_Localized_Priors_and_Efficient_Learning.html">370 cvpr-2013-SCALPEL: Segmentation Cascades with Localized Priors and Efficient Learning</a></p>
<p>18 0.78089803 <a title="341-lda-18" href="./cvpr-2013-Analyzing_Semantic_Segmentation_Using_Hybrid_Human-Machine_CRFs.html">43 cvpr-2013-Analyzing Semantic Segmentation Using Hybrid Human-Machine CRFs</a></p>
<p>19 0.78074366 <a title="341-lda-19" href="./cvpr-2013-Dense_Reconstruction_Using_3D_Object_Shape_Priors.html">111 cvpr-2013-Dense Reconstruction Using 3D Object Shape Priors</a></p>
<p>20 0.78057384 <a title="341-lda-20" href="./cvpr-2013-What_Object_Motion_Reveals_about_Shape_with_Unknown_BRDF_and_Lighting.html">465 cvpr-2013-What Object Motion Reveals about Shape with Unknown BRDF and Lighting</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
