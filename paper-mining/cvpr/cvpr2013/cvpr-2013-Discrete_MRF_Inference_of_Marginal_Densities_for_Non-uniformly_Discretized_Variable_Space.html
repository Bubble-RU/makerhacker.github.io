<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>128 cvpr-2013-Discrete MRF Inference of Marginal Densities for Non-uniformly Discretized Variable Space</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-128" href="#">cvpr2013-128</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>128 cvpr-2013-Discrete MRF Inference of Marginal Densities for Non-uniformly Discretized Variable Space</h1>
<br/><p>Source: <a title="cvpr-2013-128-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Saito_Discrete_MRF_Inference_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Masaki Saito, Takayuki Okatani, Koichiro Deguchi</p><p>Abstract: This paper is concerned with the inference of marginal densities based on MRF models. The optimization algorithmsfor continuous variables are only applicable to a limited number of problems, whereas those for discrete variables are versatile. Thus, it is quite common to convert the continuous variables into discrete ones for the problems that ideally should be solved in the continuous domain, such as stereo matching and optical flow estimation. In this paper, we show a novel formulation for this continuous-discrete conversion. The key idea is to estimate the marginal densities in the continuous domain by approximating them with mixtures of rectangular densities. Based on this formulation, we derive a mean field (MF) algorithm and a belief propagation (BP) algorithm. These algorithms can correctly handle the case where the variable space is discretized in a non-uniform manner. By intentionally using such a non-uniform discretization, a higher balance between computational efficiency and accuracy of marginal density estimates could be achieved. We present a method for actually doing this, which dynamically discretizes the variable space in a coarse-to-fine manner in the course of the computation. Experimental results show the effectiveness of our approach.</p><p>Reference: <a title="cvpr-2013-128-reference" href="../cvpr2013_reference/cvpr-2013-Discrete_MRF_Inference_of_Marginal_Densities_for_Non-uniformly_Discretized_Variable_Space_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 jp  Abstract This paper is concerned with the inference of marginal densities based on MRF models. [sent-5, score-0.643]
</p><p>2 The optimization algorithmsfor continuous variables are only applicable to a limited number of problems, whereas those for discrete variables are versatile. [sent-6, score-0.276]
</p><p>3 Thus, it is quite common to convert the continuous variables into discrete ones for the problems that ideally should be solved in the continuous domain, such as stereo matching and optical flow estimation. [sent-7, score-0.348]
</p><p>4 The key idea is to estimate the marginal densities in the continuous domain by approximating them with mixtures of rectangular densities. [sent-9, score-0.976]
</p><p>5 These algorithms can correctly handle the case where the variable space is discretized in a non-uniform manner. [sent-11, score-0.244]
</p><p>6 By intentionally using such a non-uniform discretization, a higher balance between computational efficiency and accuracy of marginal density estimates could be achieved. [sent-12, score-0.516]
</p><p>7 MPM first computes the marginal density of each variable xi; it then obtains its maximizer and uses it as the estimate of xi [11, 2, 4]. [sent-29, score-0.778]
</p><p>8 In this paper, we consider the estimation of marginal densities. [sent-30, score-0.342]
</p><p>9 Although MAP is in general computationally easier to perform and thus MPM is unlikely to be the first  choice when both can be used, there is no other choice when the marginal densities themselves are necessary, e. [sent-31, score-0.643]
</p><p>10 , learning the parameters in CRF (Conditional Random Field) models [3, 6] The computation of the marginal densities is differently formulated depending on whether the variable xi is continuous or discrete. [sent-33, score-1.035]
</p><p>11 Both iteratively estimate the marginal densities by repeatedly exchanging information, or messages, among the neighboring sites. [sent-35, score-0.643]
</p><p>12 In the case of continuous variables, the marginal densities are represented by some parametric density function and its parameters are iteratively updated at each site. [sent-36, score-0.897]
</p><p>13 In the case of discrete variables, the marginal densities are represented as discrete densities, and they are iteratively updated at each site. [sent-37, score-0.825]
</p><p>14 The former formulation for continuous variables can be used only for a small class of problems, as there are only a few choices for the parametric function representing the marginal densities. [sent-38, score-0.556]
</p><p>15 (This limitation comes from the constraint that in the message updating step, the densities before and after the update should be represented by the same parametric function. [sent-40, score-0.43]
</p><p>16 In the latter case, the continuous variables are discretized into discrete ones. [sent-46, score-0.31]
</p><p>17 For example, in stereo matching and optical flow estimation, the site variable is disparity and a flow vector, respectively, which are both continuous; they are discretized and the energy function is then defined based on the resulsting discrete variables. [sent-47, score-0.547]
</p><p>18 , that the problems that should ideally be dealt with in continuous domain are solved by discretization of the variables). [sent-50, score-0.327]
</p><p>19 In the conventional formulation, the variables are first discretized and the energy of Eq. [sent-51, score-0.261]
</p><p>20 Then, the marginal densities defined in the discrete domain are estimated using the discrete MF or BP algorithm. [sent-53, score-0.85]
</p><p>21 To make its minimization feasible, we “discretize” the marginal density of each site, or more rigorously, approximate the marginal density with a discrete density. [sent-55, score-1.041]
</p><p>22 We then search for the marginal densities that minimize the energy in the space of the approximating discrete densities. [sent-56, score-0.857]
</p><p>23 For the approximating density, we choose a mixture of rectangular densities in this study. [sent-57, score-0.557]
</p><p>24 In our formulation, the rectangular functions in the mixture are allowed to have arbitrary locations and sizes (as long as any two of them are not overlapped in the variable space), which provides a core practical value of our formulation. [sent-60, score-0.317]
</p><p>25 To be specific, the updating terms in the new MF and BP algorithms have additional terms as compared with conventional ones; these additional terms are regarded as compensating the non-uniform distribution of rectangular functions. [sent-62, score-0.344]
</p><p>26 Note that the conventional MF and BP algorithms are independent of how the continuous variables are discretized; as the energy is defined after the discretization, differences in the discretization simply change the meaning of the energy. [sent-63, score-0.503]
</p><p>27 , sampled densely ainc some region oarnmd sparsely in others) to improve the estimation accuracy of the marginal densities without increasing the computational cost. [sent-66, score-0.665]
</p><p>28 In this paper, taking one step further, we present a method that performs this non-uniform discretization dynamically in the course of the optimization. [sent-72, score-0.271]
</p><p>29 Our method employs a coarse-to-fine strategy; starting with coarsely divided blocks of the variable space, it recursively divides the block of the largest mixture weight into subblocks. [sent-73, score-0.413]
</p><p>30 (Each block is the support of a rectangular function in the mixture density. [sent-74, score-0.296]
</p><p>31 ) This block subdivision also requires dividing the current marginal density estimates as well as the messages. [sent-75, score-0.803]
</p><p>32 In Section 2, we derive the new MF and BP algorithms that can deal with nonuniformly discretized variable space. [sent-78, score-0.286]
</p><p>33 Algorithms for a non-uniformly  discretized  variable space In this section we derive the new MF and BP algorithms that can deal with non-uniformly discretized variable space. [sent-83, score-0.473]
</p><p>34 Minimization of the free energy The conventional MF and BP algorithms for discrete and continuous variables are all derived in the same variational framework for the minimization of the free energy [13]. [sent-86, score-0.505]
</p><p>35 We briefly summarize it here, as it will be used later to derive the new algorithms The joint density Q(x) of the variables x of all the sites of the MRF is given by  Q(x) =1Zexp(−E(x)),  (2)  where Z is a normalizing factor called the partition function. [sent-87, score-0.273]
</p><p>36 The direct computation of the marginal densities based on Eq. [sent-88, score-0.643]
</p><p>37 Then, restricting P to a particular class of densities for which the marginal densities can be computed easily, P that the best approximates Q is searched for. [sent-91, score-0.944]
</p><p>38 Derivation of a new MF algorithm The central issue ofthe variational approach is the choice of the class of the approximating densities (P’s). [sent-114, score-0.359]
</p><p>39 (6)  This means that the variable of each site is independent of that of any other site. [sent-117, score-0.26]
</p><p>40 is after convergence directly give the estimates of the marginal densities of Q. [sent-151, score-0.684]
</p><p>41 When xi is a discrete variable, pi(xi) is naturally a discrete density. [sent-153, score-0.366]
</p><p>42 ,xS ] be the discrete values that xi can take, we denote their probabilities by [pi1, . [sent-157, score-0.275]
</p><p>43 When xi is a continuous variable, we are to represent pi(xi) by some parametric function such as a Gaussian distribution; Eq. [sent-190, score-0.305]
</p><p>44 We wish to make feasible the computation for a problem originally defined in the continuous domain by discretizing the variable space. [sent-195, score-0.338]
</p><p>45 To do this, sticking to the above continuous formulation, we represent pi(xi) by a mixture of Si rectangular densities as  pi(xi) ≡? [sent-196, score-0.588]
</p><p>46 s  (13)  where fis and fisjt are respectively defined by  fis=? [sent-243, score-0.255]
</p><p>47 If we equate the pairs αis ↔ psi, (fis − Bsi) ↔ fi(xs) (not fis ↔ fi(xs)), and fisjt ↔ fij(xs, xt), th−e B tw)o ↔ ↔fre fe energies coi↔ncide with each o↔ther f. [sent-251, score-0.286]
</p><p>48 Under the natural correspondences αis ↔ psi, fis ↔ fi(xs), and fisjt ↔ fij(xs, xt), the only differe↔nce is the presence of Bsi. [sent-271, score-0.255]
</p><p>49 Therefore, Bsi can be regarded as a compensating term for the “non-uniformity” of the discretization of the variable space X. [sent-275, score-0.387]
</p><p>50 Derivation of a new BP algorithm  For Belief Propagation, the following class of approximating densities P’s is considered. [sent-278, score-0.359]
</p><p>51 (6)), and thus the marginal densities estimated by BP tend to be more accurate than MF. [sent-287, score-0.643]
</p><p>52 We denote the discrete values that xi takes by [x1, . [sent-300, score-0.275]
</p><p>53 mixture of rectangular densities for representing pi(xi) and pij(xi, xj). [sent-348, score-0.499]
</p><p>54 (21), it is seen that the former coincides with the latter if we equate the following four  pairs: αis ↔ psi, αsitj ↔ psijt, fis + (zi − 1)Bis ↔ fi(xs), and fisjt − Bsi − Btj ↔ fij(xs, xt). [sent-382, score-0.316]
</p><p>55 Usefulness of non-uniform discretization The new MF and BP algorithms can deal with nonuniformly discretized variable space. [sent-410, score-0.471]
</p><p>56 By densely discretizing important portion of the space and sparsely discretizing the rest and then using these algorithms, we will be able to achieve higher balance between computational efficiency and accuracy of marginal density estimates. [sent-411, score-0.684]
</p><p>57 ) The next question is how to obtain such an effective discretization of the variable space. [sent-414, score-0.332]
</p><p>58 For the case where no such knowledge is available, we present a method for dynamically discretizing the variable space to have an effective discretization. [sent-416, score-0.281]
</p><p>59 Coarse-to-fine block subdivision We assume here that behind the estimation of the marginal density, there is a motivation to accurately know  its shape around its maximum, e. [sent-419, score-0.578]
</p><p>60 Then, this will be made possible by more densely discretizing the space around the maximum of the marginal density. [sent-422, score-0.446]
</p><p>61 As it is in general impossible to know the maximum of the marginal density beforehand, we consider dynamically dividing the variable space, as shown in Fig. [sent-423, score-0.703]
</p><p>62 We start with initial coarse discretization of the variable space, that is, the variable space is divided into a small number of blocks. [sent-425, score-0.507]
</p><p>63 Each block indicates the support of a rectangular density composing the mixture approximating the true marginal density. [sent-428, score-0.829]
</p><p>64 rectangular function whose support is each block composes the mixture density approximating the true marginal density. [sent-430, score-0.829]
</p><p>65 Then, for each site (i), identify-  ing the block (s) whose mixture weight αis is the largest, we divide this block into a number of subblocks. [sent-432, score-0.409]
</p><p>66 ) Then, integrating these new blocks with the blocks that are not divided, we consider a new mixture of rectangular functions whose supports are given by them. [sent-434, score-0.308]
</p><p>67 We repeatedly perform these three procedures for a desired number of iterations: updating the mixture weights for the current discretization by our MF or BP algorithm, identifying the block(s) with the largest weight(s), and dividing them into subblocks to obtain a new discretization. [sent-435, score-0.466]
</p><p>68 Dividing a rectangular density The subdivision of a block means dividing the corresponding rectangular density into multiple rectangular densities, as shown in Fig. [sent-438, score-0.931]
</p><p>69 Thus, the mixture of rectangular densities after the subdivision has a different representation from the one before it. [sent-440, score-0.637]
</p><p>70 The principle of updating these parameters is that the mixtures before and after the subdivision should be the same density regardless of their difference in representation. [sent-442, score-0.381]
</p><p>71 Suppose that a rectangular density is divided into K rectangular densities of an identical size. [sent-446, score-0.721]
</p><p>72 Following the above principle,  the mixture weights of the new densities are given by the weight of the original density divided by K. [sent-447, score-0.562]
</p><p>73 Suppose, for example, that the s-th block of the i-th site is divided into two blocks. [sent-449, score-0.274]
</p><p>74 Effect of non-uniform discretization on marginal density estimates To compare the behaviours of the conventional and proposed algorithms when the variable space is non-uniformly discretized, we consider a simple Gaussian MRF for which the exact marginal densities can be analytically obtained. [sent-484, score-1.621]
</p><p>75 ,j)∈E  5  (29)  Clearly, its marginal densities are Gaussian distributions having zero mean. [sent-490, score-0.643]
</p><p>76 They show the estimates of the marginal density at the site in the upper-left corner of the 5 5 grid graph. [sent-498, score-0.657]
</p><p>77 by ree eds tdimotsa;t ethso bsye by tchoen proposed algorithms are shown by blue histograms; the exact marginal densities are shown by a continuous red curve. [sent-500, score-0.754]
</p><p>78 In the conventional algorithms, a marginal density is represented as a discrete density, i. [sent-501, score-0.653]
</p><p>79 In the plots, to enable direct comparison with densities in the continuous domain, its scale (i. [sent-507, score-0.39]
</p><p>80 In the proposed algorithms, the marginal densi-  ties are represented as the mixtures of rectangular densities, which are shown in the plots. [sent-510, score-0.503]
</p><p>81 2 and 3 that the estimated marginal densities by the conventional MF and BP algorithms both 666222  fileB0 10. [sent-512, score-0.752]
</p><p>82 The red dots indicate the marginal density estimate by the conventional MF; the blue histogram indicates those by the proposed MF; the continuous red curve indicates the exact marginal density. [sent-524, score-0.993]
</p><p>83 This is because of the asymmetric discretization; the energy tends to have a lower value when the marginal density estimates are in the side of denser discretization. [sent-542, score-0.56]
</p><p>84 Although there appears to exist small bias in the variances of the marginal density estimates, this is a fundamental limitation of these algorithms; even in the case of symmetric discretization, the MF and BP algorithms cannot estimate the exact value of the variance. [sent-546, score-0.497]
</p><p>85 Stereo matching We applied the proposed dynamic discretization method to stereo matching and examined its effectiveness. [sent-549, score-0.27]
</p><p>86 t W|L|e multiply t=he 2 v,a slumeoso tofh mtahex =da20ta, aanndd smoothness terms given by the library by 1/ 10, as otherwise, the marginal densities will have very sharp peaks, which is not fit for the purpose of this experiment. [sent-553, score-0.643]
</p><p>87 The dynamic discretization method is applied to the data as follows. [sent-554, score-0.239]
</p><p>88 Initially dividing the variable space into eight blocks of an identical width, we iterate the following three steps for eight times: performing the MF or BP algorithm, identifying the block of the largest weight, and dividing the  ×  block into two blocks. [sent-555, score-0.589]
</p><p>89 The above recursive subdivision increases the number of blocks from initial eight to sixteen (= 8 + 8). [sent-560, score-0.259]
</p><p>90 For both results, it is seen that the mixture density depicts the marginal density in a finer way with the increasing number of blocks. [sent-565, score-0.68]
</p><p>91 (The block sizes in the case of eight and sixteen block divisions are 128/8 = 16 and 128/ 16 = 8, respectively. [sent-567, score-0.289]
</p><p>92 ) As compared with the mixture densities of the fixed discretization, those of the dynamic discretization draw much finer details not only at the same number of blocks (i. [sent-568, score-0.667]
</p><p>93 As a result, the maxima of the marginal densities can be determined much more accurately, and thus the dynamic discretization yields smoother  disparity maps. [sent-571, score-0.921]
</p><p>94 Clearly, suffering from the insufficient number of divisions, the disparity maps for the fixed discretization are not smooth. [sent-572, score-0.252]
</p><p>95 Summary We have described a novel formulation of continuousdiscrete conversion for the inference of marginal densities based on MRF models. [sent-574, score-0.71]
</p><p>96 In the formulation, the marginal densities are estimated in the continuous domain by approximating them with mixtures of rectangular densities. [sent-575, score-0.976]
</p><p>97 We have also shown the method for dynamically discretizing the variable space in a coarse-to-fine manner in the course of the computation. [sent-577, score-0.281]
</p><p>98 This enables to improve the accuracy of marginal density estimates without sacrificing computational efficiency. [sent-578, score-0.516]
</p><p>99 Lower row: The marginal density  estimates at the site of the image pixel (100, 100). [sent-585, score-0.657]
</p><p>100 Lower row: The marginal density  estimates at the site of the image pixel (100, 100). [sent-589, score-0.657]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('mf', 0.382), ('marginal', 0.342), ('densities', 0.301), ('bp', 0.275), ('discretization', 0.213), ('dxi', 0.199), ('xi', 0.184), ('xs', 0.16), ('bsi', 0.156), ('site', 0.141), ('subdivision', 0.138), ('fis', 0.134), ('density', 0.133), ('rectangular', 0.126), ('fisjt', 0.121), ('variable', 0.119), ('psi', 0.11), ('bis', 0.107), ('pij', 0.106), ('xj', 0.106), ('pi', 0.103), ('block', 0.098), ('fij', 0.091), ('discrete', 0.091), ('continuous', 0.089), ('conventional', 0.087), ('discretizing', 0.083), ('discretized', 0.082), ('updating', 0.075), ('mrf', 0.074), ('mixture', 0.072), ('dxidxj', 0.069), ('isjt', 0.069), ('mtij', 0.069), ('psijt', 0.069), ('sitj', 0.069), ('approximating', 0.058), ('dynamically', 0.058), ('blocks', 0.055), ('fi', 0.054), ('xt', 0.052), ('dividing', 0.051), ('variables', 0.048), ('btj', 0.046), ('mpm', 0.046), ('formulation', 0.045), ('energy', 0.044), ('zi', 0.043), ('htj', 0.043), ('sites', 0.042), ('estimates', 0.041), ('substitution', 0.04), ('disparity', 0.039), ('mixtures', 0.035), ('divided', 0.035), ('substituting', 0.035), ('hisi', 0.035), ('ishis', 0.035), ('isln', 0.035), ('mksi', 0.035), ('nonuniformly', 0.035), ('pisjt', 0.035), ('pisln', 0.035), ('sijt', 0.035), ('sixteen', 0.035), ('compensating', 0.034), ('largest', 0.034), ('pis', 0.033), ('isi', 0.033), ('ni', 0.033), ('belief', 0.033), ('xis', 0.032), ('parametric', 0.032), ('eight', 0.031), ('equate', 0.031), ('okatani', 0.031), ('discretizes', 0.031), ('stereo', 0.031), ('coincides', 0.03), ('messages', 0.028), ('tohoku', 0.028), ('exp', 0.028), ('derived', 0.028), ('derive', 0.028), ('derivation', 0.027), ('divisions', 0.027), ('hsi', 0.027), ('dynamic', 0.026), ('propagation', 0.026), ('free', 0.026), ('ln', 0.026), ('domain', 0.025), ('equation', 0.025), ('originally', 0.022), ('sparsely', 0.022), ('message', 0.022), ('algorithms', 0.022), ('conversion', 0.022), ('weights', 0.021), ('space', 0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="128-tfidf-1" href="./cvpr-2013-Discrete_MRF_Inference_of_Marginal_Densities_for_Non-uniformly_Discretized_Variable_Space.html">128 cvpr-2013-Discrete MRF Inference of Marginal Densities for Non-uniformly Discretized Variable Space</a></p>
<p>Author: Masaki Saito, Takayuki Okatani, Koichiro Deguchi</p><p>Abstract: This paper is concerned with the inference of marginal densities based on MRF models. The optimization algorithmsfor continuous variables are only applicable to a limited number of problems, whereas those for discrete variables are versatile. Thus, it is quite common to convert the continuous variables into discrete ones for the problems that ideally should be solved in the continuous domain, such as stereo matching and optical flow estimation. In this paper, we show a novel formulation for this continuous-discrete conversion. The key idea is to estimate the marginal densities in the continuous domain by approximating them with mixtures of rectangular densities. Based on this formulation, we derive a mean field (MF) algorithm and a belief propagation (BP) algorithm. These algorithms can correctly handle the case where the variable space is discretized in a non-uniform manner. By intentionally using such a non-uniform discretization, a higher balance between computational efficiency and accuracy of marginal density estimates could be achieved. We present a method for actually doing this, which dynamically discretizes the variable space in a coarse-to-fine manner in the course of the computation. Experimental results show the effectiveness of our approach.</p><p>2 0.11302853 <a title="128-tfidf-2" href="./cvpr-2013-Universality_of_the_Local_Marginal_Polytope.html">448 cvpr-2013-Universality of the Local Marginal Polytope</a></p>
<p>Author: unkown-author</p><p>Abstract: We show that solving the LP relaxation of the MAP inference problem in graphical models (also known as the minsum problem, energy minimization, or weighted constraint satisfaction) is not easier than solving any LP. More precisely, any polytope is linear-time representable by a local marginal polytope and any LP can be reduced in linear time to a linear optimization (allowing infinite weights) over a local marginal polytope.</p><p>3 0.096135989 <a title="128-tfidf-3" href="./cvpr-2013-Fully-Connected_CRFs_with_Non-Parametric_Pairwise_Potential.html">180 cvpr-2013-Fully-Connected CRFs with Non-Parametric Pairwise Potential</a></p>
<p>Author: Neill D.F. Campbell, Kartic Subr, Jan Kautz</p><p>Abstract: Conditional Random Fields (CRFs) are used for diverse tasks, ranging from image denoising to object recognition. For images, they are commonly defined as a graph with nodes corresponding to individual pixels and pairwise links that connect nodes to their immediate neighbors. Recent work has shown that fully-connected CRFs, where each node is connected to every other node, can be solved efficiently under the restriction that the pairwise term is a Gaussian kernel over a Euclidean feature space. In this paper, we generalize the pairwise terms to a non-linear dissimilarity measure that is not required to be a distance metric. To this end, we propose a density estimation technique to derive conditional pairwise potentials in a nonparametric manner. We then use an efficient embedding technique to estimate an approximate Euclidean feature space for these potentials, in which the pairwise term can still be expressed as a Gaussian kernel. We demonstrate that the use of non-parametric models for the pairwise interactions, conditioned on the input data, greatly increases expressive power whilst maintaining efficient inference.</p><p>4 0.087393478 <a title="128-tfidf-4" href="./cvpr-2013-Continuous_Inference_in_Graphical_Models_with_Polynomial_Energies.html">95 cvpr-2013-Continuous Inference in Graphical Models with Polynomial Energies</a></p>
<p>Author: Mathieu Salzmann</p><p>Abstract: In this paper, we tackle the problem of performing inference in graphical models whose energy is a polynomial function of continuous variables. Our energy minimization method follows a dual decomposition approach, where the global problem is split into subproblems defined over the graph cliques. The optimal solution to these subproblems is obtained by making use of a polynomial system solver. Our algorithm inherits the convergence guarantees of dual decomposition. To speed up optimization, we also introduce a variant of this algorithm based on the augmented Lagrangian method. Our experiments illustrate the diversity of computer vision problems that can be expressed with polynomial energies, and demonstrate the benefits of our approach over existing continuous inference methods.</p><p>5 0.081840858 <a title="128-tfidf-5" href="./cvpr-2013-Adaptive_Active_Learning_for_Image_Classification.html">34 cvpr-2013-Adaptive Active Learning for Image Classification</a></p>
<p>Author: Xin Li, Yuhong Guo</p><p>Abstract: Recently active learning has attracted a lot of attention in computer vision field, as it is time and cost consuming to prepare a good set of labeled images for vision data analysis. Most existing active learning approaches employed in computer vision adopt most uncertainty measures as instance selection criteria. Although most uncertainty query selection strategies are very effective in many circumstances, they fail to take information in the large amount of unlabeled instances into account and are prone to querying outliers. In this paper, we present a novel adaptive active learning approach that combines an information density measure and a most uncertainty measure together to select critical instances to label for image classifications. Our experiments on two essential tasks of computer vision, object recognition and scene recognition, demonstrate the efficacy of the proposed approach.</p><p>6 0.081785373 <a title="128-tfidf-6" href="./cvpr-2013-A_Principled_Deep_Random_Field_Model_for_Image_Segmentation.html">24 cvpr-2013-A Principled Deep Random Field Model for Image Segmentation</a></p>
<p>7 0.081621535 <a title="128-tfidf-7" href="./cvpr-2013-Whitened_Expectation_Propagation%3A_Non-Lambertian_Shape_from_Shading_and_Shadow.html">466 cvpr-2013-Whitened Expectation Propagation: Non-Lambertian Shape from Shading and Shadow</a></p>
<p>8 0.076992795 <a title="128-tfidf-8" href="./cvpr-2013-Deformable_Spatial_Pyramid_Matching_for_Fast_Dense_Correspondences.html">107 cvpr-2013-Deformable Spatial Pyramid Matching for Fast Dense Correspondences</a></p>
<p>9 0.07402543 <a title="128-tfidf-9" href="./cvpr-2013-Detecting_Changes_in_3D_Structure_of_a_Scene_from_Multi-view_Images_Captured_by_a_Vehicle-Mounted_Camera.html">117 cvpr-2013-Detecting Changes in 3D Structure of a Scene from Multi-view Images Captured by a Vehicle-Mounted Camera</a></p>
<p>10 0.069311455 <a title="128-tfidf-10" href="./cvpr-2013-Accurate_and_Robust_Registration_of_Nonrigid_Surface_Using_Hierarchical_Statistical_Shape_Model.html">31 cvpr-2013-Accurate and Robust Registration of Nonrigid Surface Using Hierarchical Statistical Shape Model</a></p>
<p>11 0.068161644 <a title="128-tfidf-11" href="./cvpr-2013-Robust_Monocular_Epipolar_Flow_Estimation.html">362 cvpr-2013-Robust Monocular Epipolar Flow Estimation</a></p>
<p>12 0.065089829 <a title="128-tfidf-12" href="./cvpr-2013-Robust_Region_Grouping_via_Internal_Patch_Statistics.html">366 cvpr-2013-Robust Region Grouping via Internal Patch Statistics</a></p>
<p>13 0.06107587 <a title="128-tfidf-13" href="./cvpr-2013-Harry_Potter%27s_Marauder%27s_Map%3A_Localizing_and_Tracking_Multiple_Persons-of-Interest_by_Nonnegative_Discretization.html">199 cvpr-2013-Harry Potter's Marauder's Map: Localizing and Tracking Multiple Persons-of-Interest by Nonnegative Discretization</a></p>
<p>14 0.059915636 <a title="128-tfidf-14" href="./cvpr-2013-A_New_Model_and_Simple_Algorithms_for_Multi-label_Mumford-Shah_Problems.html">20 cvpr-2013-A New Model and Simple Algorithms for Multi-label Mumford-Shah Problems</a></p>
<p>15 0.057085373 <a title="128-tfidf-15" href="./cvpr-2013-Spatial_Inference_Machines.html">406 cvpr-2013-Spatial Inference Machines</a></p>
<p>16 0.055793151 <a title="128-tfidf-16" href="./cvpr-2013-3D_Pictorial_Structures_for_Multiple_View_Articulated_Pose_Estimation.html">2 cvpr-2013-3D Pictorial Structures for Multiple View Articulated Pose Estimation</a></p>
<p>17 0.054382581 <a title="128-tfidf-17" href="./cvpr-2013-Jointly_Aligning_and_Segmenting_Multiple_Web_Photo_Streams_for_the_Inference_of_Collective_Photo_Storylines.html">235 cvpr-2013-Jointly Aligning and Segmenting Multiple Web Photo Streams for the Inference of Collective Photo Storylines</a></p>
<p>18 0.052911479 <a title="128-tfidf-18" href="./cvpr-2013-Bilinear_Programming_for_Human_Activity_Recognition_with_Unknown_MRF_Graphs.html">62 cvpr-2013-Bilinear Programming for Human Activity Recognition with Unknown MRF Graphs</a></p>
<p>19 0.051248413 <a title="128-tfidf-19" href="./cvpr-2013-Visual_Tracking_via_Locality_Sensitive_Histograms.html">457 cvpr-2013-Visual Tracking via Locality Sensitive Histograms</a></p>
<p>20 0.051083762 <a title="128-tfidf-20" href="./cvpr-2013-Ensemble_Learning_for_Confidence_Measures_in_Stereo_Vision.html">147 cvpr-2013-Ensemble Learning for Confidence Measures in Stereo Vision</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.125), (1, 0.04), (2, -0.011), (3, 0.022), (4, 0.038), (5, -0.005), (6, 0.024), (7, -0.016), (8, -0.038), (9, 0.024), (10, 0.043), (11, 0.024), (12, -0.044), (13, 0.001), (14, -0.04), (15, 0.013), (16, -0.045), (17, -0.002), (18, 0.096), (19, -0.033), (20, -0.047), (21, -0.017), (22, 0.009), (23, 0.061), (24, 0.08), (25, -0.02), (26, -0.102), (27, 0.031), (28, -0.013), (29, -0.005), (30, 0.019), (31, 0.018), (32, 0.026), (33, 0.048), (34, -0.049), (35, -0.03), (36, -0.015), (37, -0.029), (38, -0.003), (39, -0.08), (40, -0.007), (41, 0.008), (42, 0.038), (43, 0.028), (44, -0.003), (45, -0.007), (46, 0.036), (47, -0.028), (48, -0.059), (49, 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97210979 <a title="128-lsi-1" href="./cvpr-2013-Discrete_MRF_Inference_of_Marginal_Densities_for_Non-uniformly_Discretized_Variable_Space.html">128 cvpr-2013-Discrete MRF Inference of Marginal Densities for Non-uniformly Discretized Variable Space</a></p>
<p>Author: Masaki Saito, Takayuki Okatani, Koichiro Deguchi</p><p>Abstract: This paper is concerned with the inference of marginal densities based on MRF models. The optimization algorithmsfor continuous variables are only applicable to a limited number of problems, whereas those for discrete variables are versatile. Thus, it is quite common to convert the continuous variables into discrete ones for the problems that ideally should be solved in the continuous domain, such as stereo matching and optical flow estimation. In this paper, we show a novel formulation for this continuous-discrete conversion. The key idea is to estimate the marginal densities in the continuous domain by approximating them with mixtures of rectangular densities. Based on this formulation, we derive a mean field (MF) algorithm and a belief propagation (BP) algorithm. These algorithms can correctly handle the case where the variable space is discretized in a non-uniform manner. By intentionally using such a non-uniform discretization, a higher balance between computational efficiency and accuracy of marginal density estimates could be achieved. We present a method for actually doing this, which dynamically discretizes the variable space in a coarse-to-fine manner in the course of the computation. Experimental results show the effectiveness of our approach.</p><p>2 0.77879202 <a title="128-lsi-2" href="./cvpr-2013-Continuous_Inference_in_Graphical_Models_with_Polynomial_Energies.html">95 cvpr-2013-Continuous Inference in Graphical Models with Polynomial Energies</a></p>
<p>Author: Mathieu Salzmann</p><p>Abstract: In this paper, we tackle the problem of performing inference in graphical models whose energy is a polynomial function of continuous variables. Our energy minimization method follows a dual decomposition approach, where the global problem is split into subproblems defined over the graph cliques. The optimal solution to these subproblems is obtained by making use of a polynomial system solver. Our algorithm inherits the convergence guarantees of dual decomposition. To speed up optimization, we also introduce a variant of this algorithm based on the augmented Lagrangian method. Our experiments illustrate the diversity of computer vision problems that can be expressed with polynomial energies, and demonstrate the benefits of our approach over existing continuous inference methods.</p><p>3 0.75317055 <a title="128-lsi-3" href="./cvpr-2013-Universality_of_the_Local_Marginal_Polytope.html">448 cvpr-2013-Universality of the Local Marginal Polytope</a></p>
<p>Author: unkown-author</p><p>Abstract: We show that solving the LP relaxation of the MAP inference problem in graphical models (also known as the minsum problem, energy minimization, or weighted constraint satisfaction) is not easier than solving any LP. More precisely, any polytope is linear-time representable by a local marginal polytope and any LP can be reduced in linear time to a linear optimization (allowing infinite weights) over a local marginal polytope.</p><p>4 0.68960786 <a title="128-lsi-4" href="./cvpr-2013-Towards_Efficient_and_Exact_MAP-Inference_for_Large_Scale_Discrete_Computer_Vision_Problems_via_Combinatorial_Optimization.html">436 cvpr-2013-Towards Efficient and Exact MAP-Inference for Large Scale Discrete Computer Vision Problems via Combinatorial Optimization</a></p>
<p>Author: Jörg Hendrik Kappes, Markus Speth, Gerhard Reinelt, Christoph Schnörr</p><p>Abstract: Discrete graphical models (also known as discrete Markov random fields) are a major conceptual tool to model the structure of optimization problems in computer vision. While in the last decade research has focused on fast approximative methods, algorithms that provide globally optimal solutions have come more into the research focus in the last years. However, large scale computer vision problems seemed to be out of reach for such methods. In this paper we introduce a promising way to bridge this gap based on partial optimality and structural properties of the underlying problem factorization. Combining these preprocessing steps, we are able to solve grids of size 2048 2048 in less than 90 seconds. On the hitherto unsolva2b04le8 C×h2i0ne4s8e character dataset of Nowozin et al. we obtain provably optimal results in 56% of the instances and achieve competitive runtimes on other recent benchmark problems. While in the present work only generalized Potts models are considered, an extension to general graphical models seems to be feasible.</p><p>5 0.67135715 <a title="128-lsi-5" href="./cvpr-2013-Auxiliary_Cuts_for_General_Classes_of_Higher_Order_Functionals.html">51 cvpr-2013-Auxiliary Cuts for General Classes of Higher Order Functionals</a></p>
<p>Author: Ismail Ben Ayed, Lena Gorelick, Yuri Boykov</p><p>Abstract: Several recent studies demonstrated that higher order (non-linear) functionals can yield outstanding performances in the contexts of segmentation, co-segmentation and tracking. In general, higher order functionals result in difficult problems that are not amenable to standard optimizers, and most of the existing works investigated particular forms of such functionals. In this study, we derive general bounds for a broad class of higher order functionals. By introducing auxiliary variables and invoking the Jensen ’s inequality as well as some convexity arguments, we prove that these bounds are auxiliary functionals for various non-linear terms, which include but are not limited to several affinity measures on the distributions or moments of segment appearance and shape, as well as soft constraints on segment volume. From these general-form bounds, we state various non-linear problems as the optimization of auxiliary functionals by graph cuts. The proposed bound optimizers are derivative-free, and consistently yield very steep functional decreases, thereby converging within a few graph cuts. We report several experiments on color and medical data, along with quantitative comparisons to stateof-the-art methods. The results demonstrate competitive performances of the proposed algorithms in regard to accuracy and convergence speed, and confirm their potential in various vision and medical applications.</p><p>6 0.66199636 <a title="128-lsi-6" href="./cvpr-2013-Nonlinearly_Constrained_MRFs%3A_Exploring_the_Intrinsic_Dimensions_of_Higher-Order_Cliques.html">308 cvpr-2013-Nonlinearly Constrained MRFs: Exploring the Intrinsic Dimensions of Higher-Order Cliques</a></p>
<p>7 0.66160864 <a title="128-lsi-7" href="./cvpr-2013-A_Comparative_Study_of_Modern_Inference_Techniques_for_Discrete_Energy_Minimization_Problems.html">6 cvpr-2013-A Comparative Study of Modern Inference Techniques for Discrete Energy Minimization Problems</a></p>
<p>8 0.63294178 <a title="128-lsi-8" href="./cvpr-2013-A_Principled_Deep_Random_Field_Model_for_Image_Segmentation.html">24 cvpr-2013-A Principled Deep Random Field Model for Image Segmentation</a></p>
<p>9 0.61630011 <a title="128-lsi-9" href="./cvpr-2013-Fully-Connected_CRFs_with_Non-Parametric_Pairwise_Potential.html">180 cvpr-2013-Fully-Connected CRFs with Non-Parametric Pairwise Potential</a></p>
<p>10 0.60707963 <a title="128-lsi-10" href="./cvpr-2013-A_Practical_Rank-Constrained_Eight-Point_Algorithm_for_Fundamental_Matrix_Estimation.html">23 cvpr-2013-A Practical Rank-Constrained Eight-Point Algorithm for Fundamental Matrix Estimation</a></p>
<p>11 0.60077065 <a title="128-lsi-11" href="./cvpr-2013-Learning_for_Structured_Prediction_Using_Approximate_Subgradient_Descent_with_Working_Sets.html">262 cvpr-2013-Learning for Structured Prediction Using Approximate Subgradient Descent with Working Sets</a></p>
<p>12 0.58976722 <a title="128-lsi-12" href="./cvpr-2013-Bilinear_Programming_for_Human_Activity_Recognition_with_Unknown_MRF_Graphs.html">62 cvpr-2013-Bilinear Programming for Human Activity Recognition with Unknown MRF Graphs</a></p>
<p>13 0.57695282 <a title="128-lsi-13" href="./cvpr-2013-An_Iterated_L1_Algorithm_for_Non-smooth_Non-convex_Optimization_in_Computer_Vision.html">41 cvpr-2013-An Iterated L1 Algorithm for Non-smooth Non-convex Optimization in Computer Vision</a></p>
<p>14 0.57411778 <a title="128-lsi-14" href="./cvpr-2013-Whitened_Expectation_Propagation%3A_Non-Lambertian_Shape_from_Shading_and_Shadow.html">466 cvpr-2013-Whitened Expectation Propagation: Non-Lambertian Shape from Shading and Shadow</a></p>
<p>15 0.56346726 <a title="128-lsi-15" href="./cvpr-2013-Accurate_and_Robust_Registration_of_Nonrigid_Surface_Using_Hierarchical_Statistical_Shape_Model.html">31 cvpr-2013-Accurate and Robust Registration of Nonrigid Surface Using Hierarchical Statistical Shape Model</a></p>
<p>16 0.56150937 <a title="128-lsi-16" href="./cvpr-2013-Optimal_Geometric_Fitting_under_the_Truncated_L2-Norm.html">317 cvpr-2013-Optimal Geometric Fitting under the Truncated L2-Norm</a></p>
<p>17 0.55257791 <a title="128-lsi-17" href="./cvpr-2013-Adaptive_Active_Learning_for_Image_Classification.html">34 cvpr-2013-Adaptive Active Learning for Image Classification</a></p>
<p>18 0.5499357 <a title="128-lsi-18" href="./cvpr-2013-Discriminative_Brain_Effective_Connectivity_Analysis_for_Alzheimer%27s_Disease%3A_A_Kernel_Learning_Approach_upon_Sparse_Gaussian_Bayesian_Network.html">129 cvpr-2013-Discriminative Brain Effective Connectivity Analysis for Alzheimer's Disease: A Kernel Learning Approach upon Sparse Gaussian Bayesian Network</a></p>
<p>19 0.54538751 <a title="128-lsi-19" href="./cvpr-2013-A_Fast_Semidefinite_Approach_to_Solving_Binary_Quadratic_Problems.html">9 cvpr-2013-A Fast Semidefinite Approach to Solving Binary Quadratic Problems</a></p>
<p>20 0.54417938 <a title="128-lsi-20" href="./cvpr-2013-Efficient_Large-Scale_Structured_Learning.html">143 cvpr-2013-Efficient Large-Scale Structured Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.115), (16, 0.026), (26, 0.055), (30, 0.224), (33, 0.294), (65, 0.013), (67, 0.053), (69, 0.048), (87, 0.08)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.88797766 <a title="128-lda-1" href="./cvpr-2013-Discrete_MRF_Inference_of_Marginal_Densities_for_Non-uniformly_Discretized_Variable_Space.html">128 cvpr-2013-Discrete MRF Inference of Marginal Densities for Non-uniformly Discretized Variable Space</a></p>
<p>Author: Masaki Saito, Takayuki Okatani, Koichiro Deguchi</p><p>Abstract: This paper is concerned with the inference of marginal densities based on MRF models. The optimization algorithmsfor continuous variables are only applicable to a limited number of problems, whereas those for discrete variables are versatile. Thus, it is quite common to convert the continuous variables into discrete ones for the problems that ideally should be solved in the continuous domain, such as stereo matching and optical flow estimation. In this paper, we show a novel formulation for this continuous-discrete conversion. The key idea is to estimate the marginal densities in the continuous domain by approximating them with mixtures of rectangular densities. Based on this formulation, we derive a mean field (MF) algorithm and a belief propagation (BP) algorithm. These algorithms can correctly handle the case where the variable space is discretized in a non-uniform manner. By intentionally using such a non-uniform discretization, a higher balance between computational efficiency and accuracy of marginal density estimates could be achieved. We present a method for actually doing this, which dynamically discretizes the variable space in a coarse-to-fine manner in the course of the computation. Experimental results show the effectiveness of our approach.</p><p>2 0.8684563 <a title="128-lda-2" href="./cvpr-2013-Boosting_Binary_Keypoint_Descriptors.html">69 cvpr-2013-Boosting Binary Keypoint Descriptors</a></p>
<p>Author: Tomasz Trzcinski, Mario Christoudias, Pascal Fua, Vincent Lepetit</p><p>Abstract: Binary keypoint descriptors provide an efficient alternative to their floating-point competitors as they enable faster processing while requiring less memory. In this paper, we propose a novel framework to learn an extremely compact binary descriptor we call BinBoost that is very robust to illumination and viewpoint changes. Each bit of our descriptor is computed with a boosted binary hash function, and we show how to efficiently optimize the different hash functions so that they complement each other, which is key to compactness and robustness. The hash functions rely on weak learners that are applied directly to the imagepatches, whichfrees usfrom any intermediate representation and lets us automatically learn the image gradient pooling configuration of the final descriptor. Our resulting descriptor significantly outperforms the state-of-the-art binary descriptors and performs similarly to the best floating-point descriptors at a fraction of the matching time and memory footprint.</p><p>3 0.86231464 <a title="128-lda-3" href="./cvpr-2013-Winding_Number_for_Region-Boundary_Consistent_Salient_Contour_Extraction.html">468 cvpr-2013-Winding Number for Region-Boundary Consistent Salient Contour Extraction</a></p>
<p>Author: Yansheng Ming, Hongdong Li, Xuming He</p><p>Abstract: This paper aims to extract salient closed contours from an image. For this vision task, both region segmentation cues (e.g. color/texture homogeneity) and boundary detection cues (e.g. local contrast, edge continuity and contour closure) play important and complementary roles. In this paper we show how to combine both cues in a unified framework. The main focus is given to how to maintain the consistency (compatibility) between the region cues and the boundary cues. To this ends, we introduce the use of winding number–a well-known concept in topology–as a powerful mathematical device. By this device, the region-boundary consistency is represented as a set of simple linear relationships. Our method is applied to the figure-ground segmentation problem. The experiments show clearly improved results.</p><p>4 0.85748088 <a title="128-lda-4" href="./cvpr-2013-Perceptual_Organization_and_Recognition_of_Indoor_Scenes_from_RGB-D_Images.html">329 cvpr-2013-Perceptual Organization and Recognition of Indoor Scenes from RGB-D Images</a></p>
<p>Author: Saurabh Gupta, Pablo Arbeláez, Jitendra Malik</p><p>Abstract: We address the problems of contour detection, bottomup grouping and semantic segmentation using RGB-D data. We focus on the challenging setting of cluttered indoor scenes, and evaluate our approach on the recently introduced NYU-Depth V2 (NYUD2) dataset [27]. We propose algorithms for object boundary detection and hierarchical segmentation that generalize the gPb − ucm approach of [se2]g mbeyn mtaatkioinng t effective use oef t dheep gthP information. Wroea schho owf that our system can label each contour with its type (depth, normal or albedo). We also propose a generic method for long-range amodal completion of surfaces and show its effectiveness in grouping. We then turn to the problem of semantic segmentation and propose a simple approach that classifies superpixels into the 40 dominant object categories in NYUD2. We use both generic and class-specific features to encode the appearance and geometry of objects. We also show how our approach can be used for scene classification, and how this contextual information in turn improves object recognition. In all of these tasks, we report significant improvements over the state-of-the-art.</p><p>5 0.85195482 <a title="128-lda-5" href="./cvpr-2013-Online_Object_Tracking%3A_A_Benchmark.html">314 cvpr-2013-Online Object Tracking: A Benchmark</a></p>
<p>Author: Yi Wu, Jongwoo Lim, Ming-Hsuan Yang</p><p>Abstract: Object tracking is one of the most important components in numerous applications of computer vision. While much progress has been made in recent years with efforts on sharing code and datasets, it is of great importance to develop a library and benchmark to gauge the state of the art. After briefly reviewing recent advances of online object tracking, we carry out large scale experiments with various evaluation criteria to understand how these algorithms perform. The test image sequences are annotated with different attributes for performance evaluation and analysis. By analyzing quantitative results, we identify effective approaches for robust tracking and provide potential future research directions in this field.</p><p>6 0.83673966 <a title="128-lda-6" href="./cvpr-2013-Learning_Structured_Hough_Voting_for_Joint_Object_Detection_and_Occlusion_Reasoning.html">256 cvpr-2013-Learning Structured Hough Voting for Joint Object Detection and Occlusion Reasoning</a></p>
<p>7 0.82739955 <a title="128-lda-7" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<p>8 0.82738048 <a title="128-lda-8" href="./cvpr-2013-Label_Propagation_from_ImageNet_to_3D_Point_Clouds.html">242 cvpr-2013-Label Propagation from ImageNet to 3D Point Clouds</a></p>
<p>9 0.82690072 <a title="128-lda-9" href="./cvpr-2013-Understanding_Indoor_Scenes_Using_3D_Geometric_Phrases.html">446 cvpr-2013-Understanding Indoor Scenes Using 3D Geometric Phrases</a></p>
<p>10 0.82599849 <a title="128-lda-10" href="./cvpr-2013-Category_Modeling_from_Just_a_Single_Labeling%3A_Use_Depth_Information_to_Guide_the_Learning_of_2D_Models.html">80 cvpr-2013-Category Modeling from Just a Single Labeling: Use Depth Information to Guide the Learning of 2D Models</a></p>
<p>11 0.82558209 <a title="128-lda-11" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>12 0.82488757 <a title="128-lda-12" href="./cvpr-2013-Cross-View_Action_Recognition_via_a_Continuous_Virtual_Path.html">98 cvpr-2013-Cross-View Action Recognition via a Continuous Virtual Path</a></p>
<p>13 0.82451302 <a title="128-lda-13" href="./cvpr-2013-Intrinsic_Scene_Properties_from_a_Single_RGB-D_Image.html">227 cvpr-2013-Intrinsic Scene Properties from a Single RGB-D Image</a></p>
<p>14 0.82385856 <a title="128-lda-14" href="./cvpr-2013-Detection-_and_Trajectory-Level_Exclusion_in_Multiple_Object_Tracking.html">121 cvpr-2013-Detection- and Trajectory-Level Exclusion in Multiple Object Tracking</a></p>
<p>15 0.8237735 <a title="128-lda-15" href="./cvpr-2013-A_Joint_Model_for_2D_and_3D_Pose_Estimation_from_a_Single_Image.html">14 cvpr-2013-A Joint Model for 2D and 3D Pose Estimation from a Single Image</a></p>
<p>16 0.82377279 <a title="128-lda-16" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<p>17 0.82367456 <a title="128-lda-17" href="./cvpr-2013-Efficient_Large-Scale_Structured_Learning.html">143 cvpr-2013-Efficient Large-Scale Structured Learning</a></p>
<p>18 0.8233366 <a title="128-lda-18" href="./cvpr-2013-Integrating_Grammar_and_Segmentation_for_Human_Pose_Estimation.html">225 cvpr-2013-Integrating Grammar and Segmentation for Human Pose Estimation</a></p>
<p>19 0.82327318 <a title="128-lda-19" href="./cvpr-2013-Dense_Reconstruction_Using_3D_Object_Shape_Priors.html">111 cvpr-2013-Dense Reconstruction Using 3D Object Shape Priors</a></p>
<p>20 0.82312822 <a title="128-lda-20" href="./cvpr-2013-Beyond_Point_Clouds%3A_Scene_Understanding_by_Reasoning_Geometry_and_Physics.html">61 cvpr-2013-Beyond Point Clouds: Scene Understanding by Reasoning Geometry and Physics</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
