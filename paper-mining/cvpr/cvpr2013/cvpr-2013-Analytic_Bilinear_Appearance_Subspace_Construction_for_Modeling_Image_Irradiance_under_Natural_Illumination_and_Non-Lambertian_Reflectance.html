<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>42 cvpr-2013-Analytic Bilinear Appearance Subspace Construction for Modeling Image Irradiance under Natural Illumination and Non-Lambertian Reflectance</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-42" href="#">cvpr2013-42</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>42 cvpr-2013-Analytic Bilinear Appearance Subspace Construction for Modeling Image Irradiance under Natural Illumination and Non-Lambertian Reflectance</h1>
<br/><p>Source: <a title="cvpr-2013-42-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Elhabian_Analytic_Bilinear_Appearance_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Shireen Y. Elhabian, Aly A. Farag</p><p>Abstract: Conventional subspace construction approaches suffer from the need of “large-enough ” image ensemble rendering numerical methods intractable. In this paper, we propose an analytic formulation for low-dimensional subspace construction in which shading cues lie while preserving the natural structure of an image sample. Using the frequencyspace representation of the image irradiance equation, the process of finding such subspace is cast as establishing a relation between its principal components and that of a deterministic set of basis functions, termed as irradiance harmonics. Representing images as matrices further lessen the number of parameters to be estimated to define a bilinear projection which maps the image sample to a lowerdimensional bilinear subspace. Results show significant impact on dimensionality reduction with minimal loss of information as well as robustness against noise.</p><p>Reference: <a title="cvpr-2013-42-reference" href="../cvpr2013_reference/cvpr-2013-Analytic_Bilinear_Appearance_Subspace_Construction_for_Modeling_Image_Irradiance_under_Natural_Illumination_and_Non-Lambertian_Reflectance_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 eg , Abstract Conventional subspace construction approaches suffer from the need of “large-enough ” image ensemble rendering numerical methods intractable. [sent-8, score-0.363]
</p><p>2 In this paper, we propose an analytic formulation for low-dimensional subspace construction in which shading cues lie while preserving the natural structure of an image sample. [sent-9, score-0.487]
</p><p>3 Using the frequencyspace representation of the image irradiance equation, the process of finding such subspace is cast as establishing a relation between its principal components and that of a deterministic set of basis functions, termed as irradiance harmonics. [sent-10, score-1.381]
</p><p>4 Representing images as matrices further lessen the number of parameters to be estimated to define a bilinear projection which maps the image sample to a lowerdimensional bilinear subspace. [sent-11, score-0.865]
</p><p>5 Results show significant impact on dimensionality reduction with minimal loss of information as well as robustness against noise. [sent-12, score-0.069]
</p><p>6 Introduction Appearance variation due to illumination changes is an  inherent challenge in many vision tasks such as recognition. [sent-14, score-0.184]
</p><p>7 While the lighting function is arbitrary, Belhumeur and Kriegman [1] proved that the set of images of a convex surfaces under distant illumination lies near a low dimensional linear subspace. [sent-15, score-0.216]
</p><p>8 As such, vision applications, concerned with the recovery of illumination, reflectance or surface geometry from images, e. [sent-16, score-0.377]
</p><p>9 Typically, subspace construction entails performing a dimensionality reduction scheme, e. [sent-22, score-0.304]
</p><p>10 First, the acquired/rendered image ensemble should be statistically significant vis- a`-vis capturing the 2 aly . [sent-26, score-0.074]
</p><p>11 Second, the curse of dimensionality hinders numerical methods such as Singular Value Decomposition (SVD) which becomes intractable especially with a large number of large-sized realizations in the image ensemble. [sent-29, score-0.116]
</p><p>12 One way to bypass the need for large image ensembles is to use the harmonic expansion of the image irradiance equation under the convolution framework [3, 4, 5] to analytically construct appearance subspaces to represent images under fixed pose but different illumination conditions. [sent-30, score-0.829]
</p><p>13 In this paper, we propose an approach for analytic bilinear subspace construction to capture the full behavior of appearance variation resulting from non-Lambertian surface reflectance when exposed to complex illumination. [sent-31, score-1.242]
</p><p>14 We take advantage of the two-fold benefit of the frequency-space representation of the image irradiance equation. [sent-32, score-0.452]
</p><p>15 First, it decouples the image formation process such that the illumination conditions and surface reflectance characteristics are encoded into the coefficients of a deterministic set of basis functions, which we term irradiance harmonics. [sent-33, score-1.215]
</p><p>16 This allows the incorporation of prior information about natural illumination and real world surface materials in the subspace construction process. [sent-34, score-0.583]
</p><p>17 Second and more importantly, the process of finding such subspace can be cast as establishing a relation between its principal components and that of the irradiance harmonics. [sent-35, score-0.787]
</p><p>18 This resolves the issue of dimensionality since the source of randomness in the imaging process becomes the irradiance harmonics coefficients rather than the whole image realization. [sent-36, score-0.923]
</p><p>19 Further we take into account the spatial correlation of image pixels while connecting the spatial constraints to the irradiance constraints. [sent-37, score-0.452]
</p><p>20 Results show the superiority of our approach compared to the analytic linear one, e. [sent-39, score-0.25]
</p><p>21 [6, 5], in terms of providing significant decrease in subspace dimensionality while maintaining higher approximation accuracy. [sent-41, score-0.237]
</p><p>22 Potential applications involve constructing generative appearance models which can be used for  rendering images under new illumination and in recognition applications. [sent-42, score-0.222]
</p><p>23 111444444644  representation of the image irradiance decouples the image formation process such that the illumination and reflectance  are encoded into  the coefficients csk of the irradiance basis functions Bs which are geometry and pose dependent. [sent-43, score-1.544]
</p><p>24 In case of analytic subspace construction (b), the image coefficients csk become the random variable instead of the image realization. [sent-44, score-0.586]
</p><p>25 Thus the inherent curse of dimensionality numerical methods such as Singular Value Decomposition can be handled. [sent-45, score-0.116]
</p><p>26 s Representing teh peo islleu manidnation by its spherical harmonics (SH) coefficients lnm as in [3, 5] and the surface reflectance by its coefficients in the basis of [7], [5] or [8], the image irradiance can be defined as,  apqr  E(α,β) =  ? [sent-50, score-1.561]
</p><p>27 Problem Formulation Let E ∈ RH×W be a matrix representation of the image ierrta Edia ∈nc eR of the visible surface normals to the viewer such that H denotes height and W denotes width. [sent-55, score-0.184]
</p><p>28 U˜TEV˜  (2)  such that this low-dimensional subspace captures most of the variations observed in the image space due to illumination and reflectance. [sent-63, score-0.348]
</p><p>29 [5](pixelcentering), we opted for image-centering to capture appearance variations which can be used for recognition applications where the contribution of each image is proportional to its deviation from the subspace origin. [sent-70, score-0.224]
</p><p>30 3 does not admit to a closed form solution allowing solving for the projection matrices simultaneously. [sent-74, score-0.145]
</p><p>31 [9] used alternating projection method to derive a numerical method for multilinear 1 (˜) denotes lower-dimensional. [sent-76, score-0.13]
</p><p>32 Let Bs ∈ RH×W be the s-th irradiance harmonics of the visible∈ su Rrface normals be represented as a matrix. [sent-79, score-0.856]
</p><p>33 Hence it can be decomposed into a core matrix CsB and two orthonormal projection matrices ∈ RH×H? [sent-80, score-0.149]
</p><p>34 The harmonic∈s projection matrices {U˜B , V˜B} and the core matrices CicssB ∀rosj are sno mlveadtr fcoers using Bidi}re acntdio tnhael cPoCrAe m(BatDri-PCA) [10∀] sin a an sooflflvineed stage using aildl iirreracdtioiannacle PhCaArmo (BniDcsup to illumination and reflectance order (N and P). [sent-83, score-0.595]
</p><p>35 based on the variations inherited from a deterministic ensemble of bases. [sent-86, score-0.064]
</p><p>36 nce of the visible surface normals can be rewritten as,  E =U˜B? [sent-97, score-0.184]
</p><p>37 V˜BT  (4)  According to the linearity property ofthe expectation operator, the origin of the image irradiance subspace can be given by, Y¯  =  U˜TU˜B? [sent-100, score-0.645]
</p><p>38 V˜BTV˜  (5)  where the harmonics coefficients cs becomes the random variable rather that the image itself. [sent-103, score-0.541]
</p><p>39 In order to simplify the process of finding the projection matrices {U˜, V˜}, we establish a relation between the ortmhaontroicremsal { coluVm},ns w oef eU˜s aanbldi sV˜h aan rde athtioosne bofe tUw˜eBe ann tdh eV˜ oBr-, respectively, such that, U˜T = AUU˜TB  RH? [sent-104, score-0.157]
</p><p>40 This renders another  ××  benefit of our analytic construction where the optimization problem in Eq. [sent-109, score-0.294]
</p><p>41 AVT  (7)  where the solution for {AU, AV} matrices is given by the following t shoelourteiomn. [sent-124, score-0.069]
</p><p>42 wInh tehree following, we use pseudo {(trcunca}te−dE) identity matrices for initializing this iterative procedure where convergence is observed within no more than three iterations. [sent-150, score-0.069]
</p><p>43 Model-based Bilinear PCA  ×  The major advantage of the analytic approach is the explicit relation between the principal components spanning the image space and the illumination and reflectance coefficients, allowing for a model-based framework for generic subspace generation. [sent-153, score-0.904]
</p><p>44 Assuming that the lighting function and the surface material/reflectance are independent, one would have [5], E{cs}  =  E{lnm}E{apqr}  ,  E{lmnlmn? [sent-155, score-0.165]
</p><p>45 } = (10) where the respective indices are given by the ordering function of the irradiance harmonics functions. [sent-161, score-0.823]
</p><p>46 [13] can be devised to incorporate prior information in a modelbased framework for analytic subspace construction. [sent-168, score-0.456]
</p><p>47 Connection with Analytic PCA Nillius and Eklundh [5] proposed an analytic PCA framework which depends on vector spaces. [sent-172, score-0.227]
</p><p>48 TW˜he o∈b sw thhiecnh t maps tohreoriginal vector space RD intoW a v∈ec Rtor subspace with D? [sent-176, score-0.193]
</p><p>49 In case of bilinear representation, the matrices U˜ ∈ and V˜ ∈ and {Yk}kK=1 can be U use ∈d to recover theV original image nsdet {YEk}}kK=1 where each Ek ∈ vRerH× thWe is approximated by E˜UY}kV˜T. [sent-195, score-0.387]
</p><p>50 Hence to store∈ ∈the R bilinear representation, we need H H? [sent-196, score-0.318]
</p><p>51 dT Hhe computation time for the bilinear representation Y is O(H? [sent-206, score-0.318]
</p><p>52 oNmoptea tihsoatn our algorithm involves two eigen problems of sizes H? [sent-210, score-0.059]
</p><p>53 while the linear counterpart involves an eigen problem of size D? [sent-214, score-0.117]
</p><p>54 Further, the decomposition of irradiance harmonics i×n tDhe linear case needs to solve an eigen problem of size D D while the bilinear case needs two eigen problems swizitehD Dsiz×eDs H w h×i eHt haendb Wlin e×a rWca. [sent-217, score-1.282]
</p><p>55 Experimental Results  In the sequel, surface reflectance is modeled using the database provided by Mitsubishi Electric Research Laboratories (Merl) [13] which represent a wide variety of surface materials with different diffuse and specular reflection properties (nB = 100). [sent-225, score-0.545]
</p><p>56 We fit the BRDF measurements up-to reflectance order P = 8 to (1) spherical harmonics basis [3], (2) hemispherical Zernike-based basis [5] and (3) the isotropic version of hemispherical harmonics (HSH)-based Helmholtz reflectance basis2 [8]. [sent-226, score-1.863]
</p><p>57 The main difference between the three types of basis is modeling the dependency of the surface BRDF w. [sent-227, score-0.23]
</p><p>58 the polar coordinates where associated Legendre polynomials is used in (1) while Zernike  polynomials and shifted associated Legendre polynomials in (2) and (3), respectively. [sent-230, score-0.249]
</p><p>59 We compute the irradiance harmonics for the visible part of a unit sphere, nonetheless, this analysis is applicable to any other geometrical structure. [sent-231, score-0.847]
</p><p>60 We use illumination order up to N = 10 and reflectance order up to P = 8 2See supplemental material sections 6 and 7 for their closed form. [sent-232, score-0.429]
</p><p>61 from which we selected S-harmonics of the highest average power content where S is chosen such that at least 70% of the cumulative power content is maintained (S ≈ 580). [sent-233, score-0.058]
</p><p>62 PCA [10] to obtain their orthonormal projection matrices spanning the row and column subspaces of the respective harmonics (H? [sent-235, score-0.563]
</p><p>63 = 14), in addition to their corresponding vector subspaces (D? [sent-237, score-0.071]
</p><p>64 Further, the BRDF that is used to render a testing image is excluded from training the reflectance prior. [sent-240, score-0.287]
</p><p>65 Given an image with the same geometry but under unknown natural illumination and reflectance. [sent-241, score-0.155]
</p><p>66 The trained appearance subspace is fit to such an image using number of  principal components which maintain Q = 98% of harmonics variation. [sent-242, score-0.638]
</p><p>67 2 shows the average reconstruction errors for each material in the Merl BRDF database based on linear and bilinear subspace construction. [sent-247, score-0.578]
</p><p>68 It can be noted that bilinear subspace, generally, attains lower error levels for all surface materials when compared to the linear one. [sent-248, score-0.557]
</p><p>69 This highlights the ability of bilinear representation to encode the intrinsic spatial properties of an image sample compared to the linear one. [sent-249, score-0.341]
</p><p>70 Further, HSH-based irradiance harmonics (diamond) provides minimal reconstruction error compared to SH-based (circle) and Zernike-based ones (square). [sent-250, score-0.892]
</p><p>71 This emphasizes the importance of accounting for the physical properties of non-emitting surfaces where a surface point receives incident illumination from the incoming hemisphere oriented by the surface normal at that point. [sent-251, score-0.409]
</p><p>72 In addition, the spectrum based on HSH-based basis captures more BRDF energy content compared to that of Zernike-based ones. [sent-252, score-0.103]
</p><p>73 Note  that bilinear subspaces surpass the linear ones while the Helmholtz HSH-based irradiance harmonics attains minimal reconstruction errors  for all the surface materials. [sent-257, score-1.479]
</p><p>74 maintained when the irradiance harmonics is decomposed (using PCA or BD-PCA in case of linear or bilinear subspace, respectively). [sent-258, score-1.25]
</p><p>75 3(a,b and c) portrays the average reconstruction error as a function of maintained harmonic variation percentage for linear and bilinear subspaces, respectively, with range Q ∈ [85%, 99%] . [sent-260, score-0.591]
</p><p>76 It can be noted tshpaetc a beilylin,e wairt subspace can capture 9t%he] appearance accurately with lower harmonic variation percentage (i. [sent-261, score-0.372]
</p><p>77 lowerdimensional subspace) compared to the linear one regardless of the basis used to model surface reflectance. [sent-263, score-0.318]
</p><p>78 Effect of Noise To test the robustness of the proposed subspace w. [sent-266, score-0.193]
</p><p>79 To conduct a fair assessment, we have fixed the harmonic variation that each subspace captures such that Q = 98%. [sent-270, score-0.316]
</p><p>80 One can observe the superiority of bilinear construction in capturing surface appearance even at low SNR levels compared to the linear one. [sent-273, score-0.566]
</p><p>81 This highlights the benefit of the proposed bilinear appearance model in terms of robustness against noise. [sent-274, score-0.349]
</p><p>82 4(d) shows sample reconstructions for the hippo toy from “Weizmann Photometric Stereo Database” [2] using the pink-fabric BRDF [13] and the Eucalyptus illumination map [11] where our bilinear representation attains minimal reconstruction errors. [sent-276, score-0.664]
</p><p>83 The average reconstruction error as a function of the harmonic variation percentage (Q%) maintained by the subspace. [sent-278, score-0.25]
</p><p>84 Surface reflectance is represented using (a) spherical harmonics basis [3], (b) hemispherical Zernike-based basis [5] and (c) the isotropic hemispherical harmonics (HSH)-based Helmholtz reflectance basis [8]. [sent-279, score-1.966]
</p><p>85 Conclusion In this paper, we proposed an analytic formulation for subspace reconstruction to capture the full behavior of complex illumination and non-Lambertian reflectance. [sent-281, score-0.619]
</p><p>86 Thanks to the frequency-space representation of the image irradiance equation, we were able to incorporate prior information about natural illumination and real world surface materials. [sent-282, score-0.734]
</p><p>87 The process of finding the analytic subspace was 111444445088  Figure 4. [sent-283, score-0.42]
</p><p>88 Surface reflectance is represented using (a) spherical harmonics basis [3], (b) hemispherical Zernike-based basis [5] and (c) the isotropic hemispherical harmonics (HSH)-based Helmholtz reflectance basis [8]. [sent-285, score-1.966]
</p><p>89 One can observe that bilinear subspace still capture appearance  even with low SNR levels. [sent-286, score-0.542]
</p><p>90 cast as establishing a relation between its principal components and that of the irradiance harmonics basis functions to resolve the issue of dimensionality. [sent-288, score-1.068]
</p><p>91 By representing images as matrices rather than vectors, we were able to lessen the number of parameters to be estimated to define a bilinear projection which maps the image sample to a lowerdimensional bilinear subspace. [sent-289, score-0.865]
</p><p>92 The proposed analytic bilinear PCA showed significant decrease in dimensionality when compared to the linear counterpart while attaining the lowest reconstruction errors. [sent-294, score-0.691]
</p><p>93 Kriegman, “What is the set of images of an object under all possible illumination conditions? [sent-298, score-0.155]
</p><p>94 Hanrahan, “On the relationship between radiance and irradiance: determining the illumination from images of a convex lambertian object,” Journal of the Optical Society of America A, vol. [sent-311, score-0.192]
</p><p>95 Jacobs, “Lambertian reflectance and linear subspaces,” IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. [sent-317, score-0.273]
</p><p>96 Ramamoorthi, “Analytic pca construction for theoretical analysis of lighting variability in images of a lambertian object,” IEEE Transaction of Pattern Analysis and Machine Intelligence, vol. [sent-326, score-0.239]
</p><p>97 Farag, “Towards efficient and compact phenomenological representation of arbitrary bidirectional surface reflectance,” in Proceedings of the British Machine Vision Conference (BMVC), pp. [sent-337, score-0.216]
</p><p>98 Wang, “Bidirectional pca with assembled matrix distance metric for image recognition,” Transactions on Systems, Man and Cybernetics - Part B, vol. [sent-351, score-0.097]
</p><p>99 Debevec, “Rendering synthetic objects into real scenes: bridging traditional and image-based graphics with global illumination and high dynamic range photography,” in Proceedings of the 25th annual conference on Computer graphics and interactive techniques, SIGGRAPH ’98, (New York, NY, USA), pp. [sent-356, score-0.155]
</p><p>100 McMillan, “A datadriven reflectance model,” ACM Transactions on Graphics, vol. [sent-368, score-0.25]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('irradiance', 0.452), ('harmonics', 0.371), ('bilinear', 0.318), ('reflectance', 0.25), ('analytic', 0.227), ('subspace', 0.193), ('hemispherical', 0.16), ('illumination', 0.155), ('snr', 0.14), ('surface', 0.127), ('brdf', 0.119), ('cs', 0.114), ('basis', 0.103), ('csb', 0.097), ('eklundh', 0.097), ('pca', 0.097), ('harmonic', 0.094), ('nillius', 0.086), ('polynomials', 0.083), ('helmholtz', 0.08), ('rh', 0.075), ('subspaces', 0.071), ('matrices', 0.069), ('construction', 0.067), ('av', 0.066), ('hsh', 0.065), ('legendre', 0.065), ('lowerdimensional', 0.065), ('au', 0.064), ('spherical', 0.06), ('eigen', 0.059), ('maintained', 0.058), ('coefficients', 0.056), ('projection', 0.052), ('bs', 0.052), ('ramamoorthi', 0.05), ('aly', 0.049), ('cscs', 0.049), ('farag', 0.049), ('hippo', 0.049), ('louisville', 0.049), ('phenomenological', 0.049), ('scscsb', 0.049), ('attains', 0.048), ('rw', 0.046), ('dimensionality', 0.044), ('reconstruction', 0.044), ('apqr', 0.043), ('csk', 0.043), ('eucalyptus', 0.043), ('hanrahan', 0.043), ('lessen', 0.043), ('lnm', 0.043), ('principal', 0.043), ('numerical', 0.042), ('materials', 0.041), ('bidirectional', 0.04), ('zernike', 0.04), ('deterministic', 0.039), ('lighting', 0.038), ('render', 0.037), ('lambertian', 0.037), ('kk', 0.036), ('establishing', 0.036), ('rendering', 0.036), ('devised', 0.036), ('multilinear', 0.036), ('relation', 0.036), ('counterpart', 0.035), ('yk', 0.035), ('isotropic', 0.035), ('bt', 0.034), ('normals', 0.033), ('rd', 0.033), ('ahn', 0.033), ('decouples', 0.033), ('merl', 0.033), ('multiplications', 0.032), ('july', 0.031), ('appearance', 0.031), ('curse', 0.03), ('photometric', 0.03), ('variation', 0.029), ('weizmann', 0.029), ('decomposed', 0.028), ('kriegman', 0.027), ('cast', 0.027), ('basri', 0.026), ('analytically', 0.026), ('percentage', 0.025), ('minimal', 0.025), ('ensemble', 0.025), ('toy', 0.025), ('transactions', 0.024), ('visible', 0.024), ('closed', 0.024), ('nb', 0.024), ('jacobs', 0.024), ('nl', 0.023), ('linear', 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="42-tfidf-1" href="./cvpr-2013-Analytic_Bilinear_Appearance_Subspace_Construction_for_Modeling_Image_Irradiance_under_Natural_Illumination_and_Non-Lambertian_Reflectance.html">42 cvpr-2013-Analytic Bilinear Appearance Subspace Construction for Modeling Image Irradiance under Natural Illumination and Non-Lambertian Reflectance</a></p>
<p>Author: Shireen Y. Elhabian, Aly A. Farag</p><p>Abstract: Conventional subspace construction approaches suffer from the need of “large-enough ” image ensemble rendering numerical methods intractable. In this paper, we propose an analytic formulation for low-dimensional subspace construction in which shading cues lie while preserving the natural structure of an image sample. Using the frequencyspace representation of the image irradiance equation, the process of finding such subspace is cast as establishing a relation between its principal components and that of a deterministic set of basis functions, termed as irradiance harmonics. Representing images as matrices further lessen the number of parameters to be estimated to define a bilinear projection which maps the image sample to a lowerdimensional bilinear subspace. Results show significant impact on dimensionality reduction with minimal loss of information as well as robustness against noise.</p><p>2 0.20389186 <a title="42-tfidf-2" href="./cvpr-2013-Multi-view_Photometric_Stereo_with_Spatially_Varying_Isotropic_Materials.html">303 cvpr-2013-Multi-view Photometric Stereo with Spatially Varying Isotropic Materials</a></p>
<p>Author: Zhenglong Zhou, Zhe Wu, Ping Tan</p><p>Abstract: We present a method to capture both 3D shape and spatially varying reflectance with a multi-view photometric stereo technique that works for general isotropic materials. Our data capture setup is simple, which consists of only a digital camera and a handheld light source. From a single viewpoint, we use a set of photometric stereo images to identify surface points with the same distance to the camera. We collect this information from multiple viewpoints and combine it with structure-from-motion to obtain a precise reconstruction of the complete 3D shape. The spatially varying isotropic bidirectional reflectance distributionfunction (BRDF) is captured by simultaneously inferring a set of basis BRDFs and their mixing weights at each surface point. According to our experiments, the captured shapes are accurate to 0.3 millimeters. The captured reflectance has relative root-mean-square error (RMSE) of 9%.</p><p>3 0.18273148 <a title="42-tfidf-3" href="./cvpr-2013-Uncalibrated_Photometric_Stereo_for_Unknown_Isotropic_Reflectances.html">443 cvpr-2013-Uncalibrated Photometric Stereo for Unknown Isotropic Reflectances</a></p>
<p>Author: Feng Lu, Yasuyuki Matsushita, Imari Sato, Takahiro Okabe, Yoichi Sato</p><p>Abstract: We propose an uncalibrated photometric stereo method that works with general and unknown isotropic reflectances. Our method uses a pixel intensity profile, which is a sequence of radiance intensities recorded at a pixel across multi-illuminance images. We show that for general isotropic materials, the geodesic distance between intensity profiles is linearly related to the angular difference of their surface normals, and that the intensity distribution of an intensity profile conveys information about the reflectance properties, when the intensity profile is obtained under uniformly distributed directional lightings. Based on these observations, we show that surface normals can be estimated up to a convex/concave ambiguity. A solution method based on matrix decomposition with missing data is developed for a reliable estimation. Quantitative and qualitative evaluations of our method are performed using both synthetic and real-world scenes.</p><p>4 0.18209188 <a title="42-tfidf-4" href="./cvpr-2013-What_Object_Motion_Reveals_about_Shape_with_Unknown_BRDF_and_Lighting.html">465 cvpr-2013-What Object Motion Reveals about Shape with Unknown BRDF and Lighting</a></p>
<p>Author: Manmohan Chandraker, Dikpal Reddy, Yizhou Wang, Ravi Ramamoorthi</p><p>Abstract: We present a theory that addresses the problem of determining shape from the (small or differential) motion of an object with unknown isotropic reflectance, under arbitrary unknown distant illumination, , for both orthographic and perpsective projection. Our theory imposes fundamental limits on the hardness of surface reconstruction, independent of the method involved. Under orthographic projection, we prove that three differential motions suffice to yield an invariant that relates shape to image derivatives, regardless of BRDF and illumination. Under perspective projection, we show that four differential motions suffice to yield depth and a linear constraint on the surface gradient, with unknown BRDF and lighting. Further, we delineate the topological classes up to which reconstruction may be achieved using the invariants. Finally, we derive a general stratification that relates hardness of shape recovery to scene complexity. Qualitatively, our invariants are homogeneous partial differential equations for simple lighting and inhomogeneous for complex illumination. Quantitatively, our framework shows that the minimal number of motions required to resolve shape is greater for more complex scenes. Prior works that assume brightness constancy, Lambertian BRDF or a known directional light source follow as special cases of our stratification. We illustrate with synthetic and real data how potential reconstruction methods may exploit our framework.</p><p>5 0.15741216 <a title="42-tfidf-5" href="./cvpr-2013-Three-Dimensional_Bilateral_Symmetry_Plane_Estimation_in_the_Phase_Domain.html">432 cvpr-2013-Three-Dimensional Bilateral Symmetry Plane Estimation in the Phase Domain</a></p>
<p>Author: Ramakrishna Kakarala, Prabhu Kaliamoorthi, Vittal Premachandran</p><p>Abstract: We show that bilateral symmetry plane estimation for three-dimensional (3-D) shapes may be carried out accurately, and efficiently, in the spherical harmonic domain. Our methods are valuable for applications where spherical harmonic expansion is already employed, such as 3-D shape registration, morphometry, and retrieval. We show that the presence of bilateral symmetry in the 3-D shape is equivalent to a linear phase structure in the corresponding spherical harmonic coefficients, and provide algorithms for estimating the orientation of the symmetry plane. The benefit of using spherical harmonic phase is that symmetry estimation reduces to matching a compact set of descriptors, without the need to solve a correspondence problem. Our methods work on point clouds as well as large-scale mesh models of 3-D shapes.</p><p>6 0.15501684 <a title="42-tfidf-6" href="./cvpr-2013-BRDF_Slices%3A_Accurate_Adaptive_Anisotropic_Appearance_Acquisition.html">54 cvpr-2013-BRDF Slices: Accurate Adaptive Anisotropic Appearance Acquisition</a></p>
<p>7 0.15211253 <a title="42-tfidf-7" href="./cvpr-2013-Intrinsic_Scene_Properties_from_a_Single_RGB-D_Image.html">227 cvpr-2013-Intrinsic Scene Properties from a Single RGB-D Image</a></p>
<p>8 0.14295813 <a title="42-tfidf-8" href="./cvpr-2013-Calibrating_Photometric_Stereo_by_Holistic_Reflectance_Symmetry_Analysis.html">75 cvpr-2013-Calibrating Photometric Stereo by Holistic Reflectance Symmetry Analysis</a></p>
<p>9 0.12933654 <a title="42-tfidf-9" href="./cvpr-2013-Improved_Image_Set_Classification_via_Joint_Sparse_Approximated_Nearest_Subspaces.html">215 cvpr-2013-Improved Image Set Classification via Joint Sparse Approximated Nearest Subspaces</a></p>
<p>10 0.1232265 <a title="42-tfidf-10" href="./cvpr-2013-A_New_Perspective_on_Uncalibrated_Photometric_Stereo.html">21 cvpr-2013-A New Perspective on Uncalibrated Photometric Stereo</a></p>
<p>11 0.11749488 <a title="42-tfidf-11" href="./cvpr-2013-Discriminative_Subspace_Clustering.html">135 cvpr-2013-Discriminative Subspace Clustering</a></p>
<p>12 0.11659023 <a title="42-tfidf-12" href="./cvpr-2013-Learning_Binary_Codes_for_High-Dimensional_Data_Using_Bilinear_Projections.html">246 cvpr-2013-Learning Binary Codes for High-Dimensional Data Using Bilinear Projections</a></p>
<p>13 0.11083844 <a title="42-tfidf-13" href="./cvpr-2013-Learning_Discriminative_Illumination_and_Filters_for_Raw_Material_Classification_with_Optimal_Projections_of_Bidirectional_Texture_Functions.html">251 cvpr-2013-Learning Discriminative Illumination and Filters for Raw Material Classification with Optimal Projections of Bidirectional Texture Functions</a></p>
<p>14 0.10732518 <a title="42-tfidf-14" href="./cvpr-2013-Sparse_Subspace_Denoising_for_Image_Manifolds.html">405 cvpr-2013-Sparse Subspace Denoising for Image Manifolds</a></p>
<p>15 0.10643428 <a title="42-tfidf-15" href="./cvpr-2013-Spectral_Modeling_and_Relighting_of_Reflective-Fluorescent_Scenes.html">409 cvpr-2013-Spectral Modeling and Relighting of Reflective-Fluorescent Scenes</a></p>
<p>16 0.10583695 <a title="42-tfidf-16" href="./cvpr-2013-Bilinear_Programming_for_Human_Activity_Recognition_with_Unknown_MRF_Graphs.html">62 cvpr-2013-Bilinear Programming for Human Activity Recognition with Unknown MRF Graphs</a></p>
<p>17 0.10018285 <a title="42-tfidf-17" href="./cvpr-2013-Dense_Non-rigid_Point-Matching_Using_Random_Projections.html">109 cvpr-2013-Dense Non-rigid Point-Matching Using Random Projections</a></p>
<p>18 0.093120784 <a title="42-tfidf-18" href="./cvpr-2013-Shading-Based_Shape_Refinement_of_RGB-D_Images.html">394 cvpr-2013-Shading-Based Shape Refinement of RGB-D Images</a></p>
<p>19 0.083502933 <a title="42-tfidf-19" href="./cvpr-2013-Single-Sample_Face_Recognition_with_Image_Corruption_and_Misalignment_via_Sparse_Illumination_Transfer.html">399 cvpr-2013-Single-Sample Face Recognition with Image Corruption and Misalignment via Sparse Illumination Transfer</a></p>
<p>20 0.079211488 <a title="42-tfidf-20" href="./cvpr-2013-Boundary_Cues_for_3D_Object_Shape_Recovery.html">71 cvpr-2013-Boundary Cues for 3D Object Shape Recovery</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.133), (1, 0.127), (2, -0.045), (3, 0.093), (4, -0.006), (5, -0.119), (6, -0.109), (7, -0.037), (8, 0.021), (9, -0.067), (10, -0.069), (11, -0.115), (12, -0.139), (13, -0.111), (14, 0.066), (15, 0.097), (16, 0.122), (17, -0.089), (18, -0.051), (19, -0.067), (20, 0.075), (21, -0.039), (22, 0.021), (23, 0.043), (24, -0.029), (25, -0.046), (26, -0.046), (27, -0.062), (28, 0.035), (29, -0.013), (30, -0.031), (31, 0.095), (32, 0.004), (33, -0.054), (34, -0.024), (35, 0.007), (36, 0.001), (37, -0.037), (38, -0.003), (39, 0.028), (40, -0.004), (41, 0.043), (42, 0.032), (43, -0.025), (44, 0.005), (45, -0.002), (46, 0.011), (47, -0.042), (48, -0.037), (49, 0.009)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95876122 <a title="42-lsi-1" href="./cvpr-2013-Analytic_Bilinear_Appearance_Subspace_Construction_for_Modeling_Image_Irradiance_under_Natural_Illumination_and_Non-Lambertian_Reflectance.html">42 cvpr-2013-Analytic Bilinear Appearance Subspace Construction for Modeling Image Irradiance under Natural Illumination and Non-Lambertian Reflectance</a></p>
<p>Author: Shireen Y. Elhabian, Aly A. Farag</p><p>Abstract: Conventional subspace construction approaches suffer from the need of “large-enough ” image ensemble rendering numerical methods intractable. In this paper, we propose an analytic formulation for low-dimensional subspace construction in which shading cues lie while preserving the natural structure of an image sample. Using the frequencyspace representation of the image irradiance equation, the process of finding such subspace is cast as establishing a relation between its principal components and that of a deterministic set of basis functions, termed as irradiance harmonics. Representing images as matrices further lessen the number of parameters to be estimated to define a bilinear projection which maps the image sample to a lowerdimensional bilinear subspace. Results show significant impact on dimensionality reduction with minimal loss of information as well as robustness against noise.</p><p>2 0.79841703 <a title="42-lsi-2" href="./cvpr-2013-Calibrating_Photometric_Stereo_by_Holistic_Reflectance_Symmetry_Analysis.html">75 cvpr-2013-Calibrating Photometric Stereo by Holistic Reflectance Symmetry Analysis</a></p>
<p>Author: Zhe Wu, Ping Tan</p><p>Abstract: Under unknown directional lighting, the uncalibrated Lambertian photometric stereo algorithm recovers the shape of a smooth surface up to the generalized bas-relief (GBR) ambiguity. We resolve this ambiguity from the halfvector symmetry, which is observed in many isotropic materials. Under this symmetry, a 2D BRDF slice with low-rank structure can be obtained from an image, if the surface normals and light directions are correctly recovered. In general, this structure is destroyed by the GBR ambiguity. As a result, we can resolve the ambiguity by restoring this structure. We develop a simple algorithm of auto-calibration from separable homogeneous specular reflection of real images. Compared with previous methods, this method takes a holistic approach to exploiting reflectance symmetry and produces superior results.</p><p>3 0.78684622 <a title="42-lsi-3" href="./cvpr-2013-BRDF_Slices%3A_Accurate_Adaptive_Anisotropic_Appearance_Acquisition.html">54 cvpr-2013-BRDF Slices: Accurate Adaptive Anisotropic Appearance Acquisition</a></p>
<p>Author: Jirí Filip, Radomír Vávra, Michal Haindl, Pavel Žid, Mikuláš Krupika, Vlastimil Havran</p><p>Abstract: In this paper we introduce unique publicly available dense anisotropic BRDF data measurements. We use this dense data as a reference for performance evaluation of the proposed BRDF sparse angular sampling and interpolation approach. The method is based on sampling of BRDF subspaces at fixed elevations by means of several adaptively-represented, uniformly distributed, perpendicular slices. Although this proposed method requires only a sparse sampling of material, the interpolation provides a very accurate reconstruction, visually and computationally comparable to densely measured reference. Due to the simple slices measurement and method’s robustness it allows for a highly accurate acquisition of BRDFs. This in comparison with standard uniform angular sampling, is considerably faster yet uses far less samples.</p><p>4 0.76202482 <a title="42-lsi-4" href="./cvpr-2013-Uncalibrated_Photometric_Stereo_for_Unknown_Isotropic_Reflectances.html">443 cvpr-2013-Uncalibrated Photometric Stereo for Unknown Isotropic Reflectances</a></p>
<p>Author: Feng Lu, Yasuyuki Matsushita, Imari Sato, Takahiro Okabe, Yoichi Sato</p><p>Abstract: We propose an uncalibrated photometric stereo method that works with general and unknown isotropic reflectances. Our method uses a pixel intensity profile, which is a sequence of radiance intensities recorded at a pixel across multi-illuminance images. We show that for general isotropic materials, the geodesic distance between intensity profiles is linearly related to the angular difference of their surface normals, and that the intensity distribution of an intensity profile conveys information about the reflectance properties, when the intensity profile is obtained under uniformly distributed directional lightings. Based on these observations, we show that surface normals can be estimated up to a convex/concave ambiguity. A solution method based on matrix decomposition with missing data is developed for a reliable estimation. Quantitative and qualitative evaluations of our method are performed using both synthetic and real-world scenes.</p><p>5 0.73214096 <a title="42-lsi-5" href="./cvpr-2013-Multi-view_Photometric_Stereo_with_Spatially_Varying_Isotropic_Materials.html">303 cvpr-2013-Multi-view Photometric Stereo with Spatially Varying Isotropic Materials</a></p>
<p>Author: Zhenglong Zhou, Zhe Wu, Ping Tan</p><p>Abstract: We present a method to capture both 3D shape and spatially varying reflectance with a multi-view photometric stereo technique that works for general isotropic materials. Our data capture setup is simple, which consists of only a digital camera and a handheld light source. From a single viewpoint, we use a set of photometric stereo images to identify surface points with the same distance to the camera. We collect this information from multiple viewpoints and combine it with structure-from-motion to obtain a precise reconstruction of the complete 3D shape. The spatially varying isotropic bidirectional reflectance distributionfunction (BRDF) is captured by simultaneously inferring a set of basis BRDFs and their mixing weights at each surface point. According to our experiments, the captured shapes are accurate to 0.3 millimeters. The captured reflectance has relative root-mean-square error (RMSE) of 9%.</p><p>6 0.7228961 <a title="42-lsi-6" href="./cvpr-2013-What_Object_Motion_Reveals_about_Shape_with_Unknown_BRDF_and_Lighting.html">465 cvpr-2013-What Object Motion Reveals about Shape with Unknown BRDF and Lighting</a></p>
<p>7 0.64507025 <a title="42-lsi-7" href="./cvpr-2013-A_New_Perspective_on_Uncalibrated_Photometric_Stereo.html">21 cvpr-2013-A New Perspective on Uncalibrated Photometric Stereo</a></p>
<p>8 0.64315772 <a title="42-lsi-8" href="./cvpr-2013-Spectral_Modeling_and_Relighting_of_Reflective-Fluorescent_Scenes.html">409 cvpr-2013-Spectral Modeling and Relighting of Reflective-Fluorescent Scenes</a></p>
<p>9 0.60086668 <a title="42-lsi-9" href="./cvpr-2013-Learning_Discriminative_Illumination_and_Filters_for_Raw_Material_Classification_with_Optimal_Projections_of_Bidirectional_Texture_Functions.html">251 cvpr-2013-Learning Discriminative Illumination and Filters for Raw Material Classification with Optimal Projections of Bidirectional Texture Functions</a></p>
<p>10 0.55963558 <a title="42-lsi-10" href="./cvpr-2013-Towards_Contactless%2C_Low-Cost_and_Accurate_3D_Fingerprint_Identification.html">435 cvpr-2013-Towards Contactless, Low-Cost and Accurate 3D Fingerprint Identification</a></p>
<p>11 0.55566961 <a title="42-lsi-11" href="./cvpr-2013-Improved_Image_Set_Classification_via_Joint_Sparse_Approximated_Nearest_Subspaces.html">215 cvpr-2013-Improved Image Set Classification via Joint Sparse Approximated Nearest Subspaces</a></p>
<p>12 0.51205707 <a title="42-lsi-12" href="./cvpr-2013-Three-Dimensional_Bilateral_Symmetry_Plane_Estimation_in_the_Phase_Domain.html">432 cvpr-2013-Three-Dimensional Bilateral Symmetry Plane Estimation in the Phase Domain</a></p>
<p>13 0.50702482 <a title="42-lsi-13" href="./cvpr-2013-Discriminative_Subspace_Clustering.html">135 cvpr-2013-Discriminative Subspace Clustering</a></p>
<p>14 0.48680156 <a title="42-lsi-14" href="./cvpr-2013-Sensing_and_Recognizing_Surface_Textures_Using_a_GelSight_Sensor.html">391 cvpr-2013-Sensing and Recognizing Surface Textures Using a GelSight Sensor</a></p>
<p>15 0.47667119 <a title="42-lsi-15" href="./cvpr-2013-Photometric_Ambient_Occlusion.html">330 cvpr-2013-Photometric Ambient Occlusion</a></p>
<p>16 0.47538805 <a title="42-lsi-16" href="./cvpr-2013-Intrinsic_Characterization_of_Dynamic_Surfaces.html">226 cvpr-2013-Intrinsic Characterization of Dynamic Surfaces</a></p>
<p>17 0.46768343 <a title="42-lsi-17" href="./cvpr-2013-Adaptive_Compressed_Tomography_Sensing.html">35 cvpr-2013-Adaptive Compressed Tomography Sensing</a></p>
<p>18 0.45409295 <a title="42-lsi-18" href="./cvpr-2013-Monocular_Template-Based_3D_Reconstruction_of_Extensible_Surfaces_with_Local_Linear_Elasticity.html">289 cvpr-2013-Monocular Template-Based 3D Reconstruction of Extensible Surfaces with Local Linear Elasticity</a></p>
<p>19 0.45392612 <a title="42-lsi-19" href="./cvpr-2013-Dense_Non-rigid_Point-Matching_Using_Random_Projections.html">109 cvpr-2013-Dense Non-rigid Point-Matching Using Random Projections</a></p>
<p>20 0.4430818 <a title="42-lsi-20" href="./cvpr-2013-Sparse_Subspace_Denoising_for_Image_Manifolds.html">405 cvpr-2013-Sparse Subspace Denoising for Image Manifolds</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.098), (13, 0.242), (16, 0.042), (26, 0.039), (33, 0.206), (66, 0.032), (67, 0.061), (69, 0.079), (87, 0.093)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.81527489 <a title="42-lda-1" href="./cvpr-2013-Analytic_Bilinear_Appearance_Subspace_Construction_for_Modeling_Image_Irradiance_under_Natural_Illumination_and_Non-Lambertian_Reflectance.html">42 cvpr-2013-Analytic Bilinear Appearance Subspace Construction for Modeling Image Irradiance under Natural Illumination and Non-Lambertian Reflectance</a></p>
<p>Author: Shireen Y. Elhabian, Aly A. Farag</p><p>Abstract: Conventional subspace construction approaches suffer from the need of “large-enough ” image ensemble rendering numerical methods intractable. In this paper, we propose an analytic formulation for low-dimensional subspace construction in which shading cues lie while preserving the natural structure of an image sample. Using the frequencyspace representation of the image irradiance equation, the process of finding such subspace is cast as establishing a relation between its principal components and that of a deterministic set of basis functions, termed as irradiance harmonics. Representing images as matrices further lessen the number of parameters to be estimated to define a bilinear projection which maps the image sample to a lowerdimensional bilinear subspace. Results show significant impact on dimensionality reduction with minimal loss of information as well as robustness against noise.</p><p>2 0.78227276 <a title="42-lda-2" href="./cvpr-2013-Multi-agent_Event_Detection%3A_Localization_and_Role_Assignment.html">292 cvpr-2013-Multi-agent Event Detection: Localization and Role Assignment</a></p>
<p>Author: Suha Kwak, Bohyung Han, Joon Hee Han</p><p>Abstract: We present a joint estimation technique of event localization and role assignment when the target video event is described by a scenario. Specifically, to detect multi-agent events from video, our algorithm identifies agents involved in an event and assigns roles to the participating agents. Instead of iterating through all possible agent-role combinations, we formulate the joint optimization problem as two efficient subproblems—quadratic programming for role assignment followed by linear programming for event localization. Additionally, we reduce the computational complexity significantly by applying role-specific event detectors to each agent independently. We test the performance of our algorithm in natural videos, which contain multiple target events and nonparticipating agents.</p><p>3 0.75789708 <a title="42-lda-3" href="./cvpr-2013-Recognize_Human_Activities_from_Partially_Observed_Videos.html">347 cvpr-2013-Recognize Human Activities from Partially Observed Videos</a></p>
<p>Author: Yu Cao, Daniel Barrett, Andrei Barbu, Siddharth Narayanaswamy, Haonan Yu, Aaron Michaux, Yuewei Lin, Sven Dickinson, Jeffrey Mark Siskind, Song Wang</p><p>Abstract: Recognizing human activities in partially observed videos is a challengingproblem and has many practical applications. When the unobserved subsequence is at the end of the video, the problem is reduced to activity prediction from unfinished activity streaming, which has been studied by many researchers. However, in the general case, an unobserved subsequence may occur at any time by yielding a temporal gap in the video. In this paper, we propose a new method that can recognize human activities from partially observed videos in the general case. Specifically, we formulate the problem into a probabilistic framework: 1) dividing each activity into multiple ordered temporal segments, 2) using spatiotemporal features of the training video samples in each segment as bases and applying sparse coding (SC) to derive the activity likelihood of the test video sample at each segment, and 3) finally combining the likelihood at each segment to achieve a global posterior for the activities. We further extend the proposed method to include more bases that correspond to a mixture of segments with different temporal lengths (MSSC), which can better rep- resent the activities with large intra-class variations. We evaluate the proposed methods (SC and MSSC) on various real videos. We also evaluate the proposed methods on two special cases: 1) activity prediction where the unobserved subsequence is at the end of the video, and 2) human activity recognition on fully observed videos. Experimental results show that the proposed methods outperform existing state-of-the-art comparison methods.</p><p>4 0.73130369 <a title="42-lda-4" href="./cvpr-2013-First-Person_Activity_Recognition%3A_What_Are_They_Doing_to_Me%3F.html">175 cvpr-2013-First-Person Activity Recognition: What Are They Doing to Me?</a></p>
<p>Author: Michael S. Ryoo, Larry Matthies</p><p>Abstract: This paper discusses the problem of recognizing interaction-level human activities from a first-person viewpoint. The goal is to enable an observer (e.g., a robot or a wearable camera) to understand ‘what activity others are performing to it’ from continuous video inputs. These include friendly interactions such as ‘a person hugging the observer’ as well as hostile interactions like ‘punching the observer’ or ‘throwing objects to the observer’, whose videos involve a large amount of camera ego-motion caused by physical interactions. The paper investigates multichannel kernels to integrate global and local motion information, and presents a new activity learning/recognition methodology that explicitly considers temporal structures displayed in first-person activity videos. In our experiments, we not only show classification results with segmented videos, but also confirm that our new approach is able to detect activities from continuous videos reliably.</p><p>5 0.71864581 <a title="42-lda-5" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<p>Author: Horst Possegger, Sabine Sternig, Thomas Mauthner, Peter M. Roth, Horst Bischof</p><p>Abstract: Combining foreground images from multiple views by projecting them onto a common ground-plane has been recently applied within many multi-object tracking approaches. These planar projections introduce severe artifacts and constrain most approaches to objects moving on a common 2D ground-plane. To overcome these limitations, we introduce the concept of an occupancy volume exploiting the full geometry and the objects ’ center of mass and develop an efficient algorithm for 3D object tracking. Individual objects are tracked using the local mass density scores within a particle filter based approach, constrained by a Voronoi partitioning between nearby trackers. Our method benefits from the geometric knowledge given by the occupancy volume to robustly extract features and train classifiers on-demand, when volumetric information becomes unreliable. We evaluate our approach on several challenging real-world scenarios including the public APIDIS dataset. Experimental evaluations demonstrate significant improvements compared to state-of-theart methods, while achieving real-time performance. – –</p><p>6 0.71806651 <a title="42-lda-6" href="./cvpr-2013-Beyond_Point_Clouds%3A_Scene_Understanding_by_Reasoning_Geometry_and_Physics.html">61 cvpr-2013-Beyond Point Clouds: Scene Understanding by Reasoning Geometry and Physics</a></p>
<p>7 0.71603245 <a title="42-lda-7" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>8 0.71326435 <a title="42-lda-8" href="./cvpr-2013-Intrinsic_Scene_Properties_from_a_Single_RGB-D_Image.html">227 cvpr-2013-Intrinsic Scene Properties from a Single RGB-D Image</a></p>
<p>9 0.7131592 <a title="42-lda-9" href="./cvpr-2013-Multi-view_Photometric_Stereo_with_Spatially_Varying_Isotropic_Materials.html">303 cvpr-2013-Multi-view Photometric Stereo with Spatially Varying Isotropic Materials</a></p>
<p>10 0.71041626 <a title="42-lda-10" href="./cvpr-2013-Discovering_the_Structure_of_a_Planar_Mirror_System_from_Multiple_Observations_of_a_Single_Point.html">127 cvpr-2013-Discovering the Structure of a Planar Mirror System from Multiple Observations of a Single Point</a></p>
<p>11 0.70950937 <a title="42-lda-11" href="./cvpr-2013-Physically_Plausible_3D_Scene_Tracking%3A_The_Single_Actor_Hypothesis.html">331 cvpr-2013-Physically Plausible 3D Scene Tracking: The Single Actor Hypothesis</a></p>
<p>12 0.70945644 <a title="42-lda-12" href="./cvpr-2013-A_Minimum_Error_Vanishing_Point_Detection_Approach_for_Uncalibrated_Monocular_Images_of_Man-Made_Environments.html">19 cvpr-2013-A Minimum Error Vanishing Point Detection Approach for Uncalibrated Monocular Images of Man-Made Environments</a></p>
<p>13 0.70891112 <a title="42-lda-13" href="./cvpr-2013-SLAM%2B%2B%3A_Simultaneous_Localisation_and_Mapping_at_the_Level_of_Objects.html">372 cvpr-2013-SLAM++: Simultaneous Localisation and Mapping at the Level of Objects</a></p>
<p>14 0.70751959 <a title="42-lda-14" href="./cvpr-2013-Understanding_Indoor_Scenes_Using_3D_Geometric_Phrases.html">446 cvpr-2013-Understanding Indoor Scenes Using 3D Geometric Phrases</a></p>
<p>15 0.70686865 <a title="42-lda-15" href="./cvpr-2013-Uncalibrated_Photometric_Stereo_for_Unknown_Isotropic_Reflectances.html">443 cvpr-2013-Uncalibrated Photometric Stereo for Unknown Isotropic Reflectances</a></p>
<p>16 0.70673329 <a title="42-lda-16" href="./cvpr-2013-Cross-View_Action_Recognition_via_a_Continuous_Virtual_Path.html">98 cvpr-2013-Cross-View Action Recognition via a Continuous Virtual Path</a></p>
<p>17 0.7066462 <a title="42-lda-17" href="./cvpr-2013-Understanding_Bayesian_Rooms_Using_Composite_3D_Object_Models.html">445 cvpr-2013-Understanding Bayesian Rooms Using Composite 3D Object Models</a></p>
<p>18 0.70655483 <a title="42-lda-18" href="./cvpr-2013-Label_Propagation_from_ImageNet_to_3D_Point_Clouds.html">242 cvpr-2013-Label Propagation from ImageNet to 3D Point Clouds</a></p>
<p>19 0.70642221 <a title="42-lda-19" href="./cvpr-2013-Joint_Detection%2C_Tracking_and_Mapping_by_Semantic_Bundle_Adjustment.html">231 cvpr-2013-Joint Detection, Tracking and Mapping by Semantic Bundle Adjustment</a></p>
<p>20 0.70609057 <a title="42-lda-20" href="./cvpr-2013-Exploiting_the_Power_of_Stereo_Confidences.html">155 cvpr-2013-Exploiting the Power of Stereo Confidences</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
