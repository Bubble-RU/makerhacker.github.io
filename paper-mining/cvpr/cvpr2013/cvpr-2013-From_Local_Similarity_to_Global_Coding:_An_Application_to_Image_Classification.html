<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>178 cvpr-2013-From Local Similarity to Global Coding: An Application to Image Classification</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-178" href="#">cvpr2013-178</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>178 cvpr-2013-From Local Similarity to Global Coding: An Application to Image Classification</h1>
<br/><p>Source: <a title="cvpr-2013-178-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Shaban_From_Local_Similarity_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Amirreza Shaban, Hamid R. Rabiee, Mehrdad Farajtabar, Marjan Ghazvininejad</p><p>Abstract: Bag of words models for feature extraction have demonstrated top-notch performance in image classification. These representations are usually accompanied by a coding method. Recently, methods that code a descriptor giving regard to its nearby bases have proved efficacious. These methods take into account the nonlinear structure of descriptors, since local similarities are a good approximation of global similarities. However, they confine their usage of the global similarities to nearby bases. In this paper, we propose a coding scheme that brings into focus the manifold structure of descriptors, and devise a method to compute the global similarities of descriptors to the bases. Given a local similarity measure between bases, a global measure is computed. Exploiting the local similarity of a descriptor and its nearby bases, a global measure of association of a descriptor to all the bases is computed. Unlike the locality-based and sparse coding methods, the proposed coding varies smoothly with respect to the underlying manifold. Experiments on benchmark image classification datasets substantiate the superiority oftheproposed method over its locality and sparsity based rivals.</p><p>Reference: <a title="cvpr-2013-178-reference" href="../cvpr2013_reference/cvpr-2013-From_Local_Similarity_to_Global_Coding%3A_An_Application_to_Image_Classification_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('cod', 0.371), ('manifold', 0.334), ('llc', 0.294), ('lsgc', 0.268), ('bk', 0.22), ('bi', 0.217), ('bj', 0.177), ('ui', 0.153), ('bui', 0.134), ('lsac', 0.134), ('raby', 0.134), ('shab', 0.134), ('pool', 0.113), ('bow', 0.113), ('nonlinear', 0.106), ('dict', 0.1), ('indirect', 0.096), ('conf', 0.095), ('grain', 0.091), ('farajtab', 0.089)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="178-tfidf-1" href="./cvpr-2013-From_Local_Similarity_to_Global_Coding%3A_An_Application_to_Image_Classification.html">178 cvpr-2013-From Local Similarity to Global Coding: An Application to Image Classification</a></p>
<p>Author: Amirreza Shaban, Hamid R. Rabiee, Mehrdad Farajtabar, Marjan Ghazvininejad</p><p>Abstract: Bag of words models for feature extraction have demonstrated top-notch performance in image classification. These representations are usually accompanied by a coding method. Recently, methods that code a descriptor giving regard to its nearby bases have proved efficacious. These methods take into account the nonlinear structure of descriptors, since local similarities are a good approximation of global similarities. However, they confine their usage of the global similarities to nearby bases. In this paper, we propose a coding scheme that brings into focus the manifold structure of descriptors, and devise a method to compute the global similarities of descriptors to the bases. Given a local similarity measure between bases, a global measure is computed. Exploiting the local similarity of a descriptor and its nearby bases, a global measure of association of a descriptor to all the bases is computed. Unlike the locality-based and sparse coding methods, the proposed coding varies smoothly with respect to the underlying manifold. Experiments on benchmark image classification datasets substantiate the superiority oftheproposed method over its locality and sparsity based rivals.</p><p>2 0.2241006 <a title="178-tfidf-2" href="./cvpr-2013-Kernel_Learning_for_Extrinsic_Classification_of_Manifold_Features.html">237 cvpr-2013-Kernel Learning for Extrinsic Classification of Manifold Features</a></p>
<p>Author: Raviteja Vemulapalli, Jaishanker K. Pillai, Rama Chellappa</p><p>Abstract: In computer vision applications, features often lie on Riemannian manifolds with known geometry. Popular learning algorithms such as discriminant analysis, partial least squares, support vector machines, etc., are not directly applicable to such features due to the non-Euclidean nature of the underlying spaces. Hence, classification is often performed in an extrinsic manner by mapping the manifolds to Euclidean spaces using kernels. However, for kernel based approaches, poor choice of kernel often results in reduced performance. In this paper, we address the issue of kernelselection for the classification of features that lie on Riemannian manifolds using the kernel learning approach. We propose two criteria for jointly learning the kernel and the classifier using a single optimization problem. Specifically, for the SVM classifier, we formulate the problem of learning a good kernel-classifier combination as a convex optimization problem and solve it efficiently following the multiple kernel learning approach. Experimental results on image set-based classification and activity recognition clearly demonstrate the superiority of the proposed approach over existing methods for classification of manifold features.</p><p>3 0.18586007 <a title="178-tfidf-3" href="./cvpr-2013-Rolling_Riemannian_Manifolds_to_Solve_the_Multi-class_Classification_Problem.html">367 cvpr-2013-Rolling Riemannian Manifolds to Solve the Multi-class Classification Problem</a></p>
<p>Author: Rui Caseiro, Pedro Martins, João F. Henriques, Fátima Silva Leite, Jorge Batista</p><p>Abstract: In the past few years there has been a growing interest on geometric frameworks to learn supervised classification models on Riemannian manifolds [31, 27]. A popular framework, valid over any Riemannian manifold, was proposed in [31] for binary classification. Once moving from binary to multi-class classification thisparadigm is not valid anymore, due to the spread of multiple positive classes on the manifold [27]. It is then natural to ask whether the multi-class paradigm could be extended to operate on a large class of Riemannian manifolds. We propose a mathematically well-founded classification paradigm that allows to extend the work in [31] to multi-class models, taking into account the structure of the space. The idea is to project all the data from the manifold onto an affine tangent space at a particular point. To mitigate the distortion induced by local diffeomorphisms, we introduce for the first time in the computer vision community a well-founded mathematical concept, so-called Rolling map [21, 16]. The novelty in this alternate school of thought is that the manifold will be firstly rolled (without slipping or twisting) as a rigid body, then the given data is unwrapped onto the affine tangent space, where the classification is performed.</p><p>4 0.18209992 <a title="178-tfidf-4" href="./cvpr-2013-Non-rigid_Structure_from_Motion_with_Diffusion_Maps_Prior.html">306 cvpr-2013-Non-rigid Structure from Motion with Diffusion Maps Prior</a></p>
<p>Author: Lili Tao, Bogdan J. Matuszewski</p><p>Abstract: In this paper, a novel approach based on a non-linear manifold learning technique is proposed to recover 3D nonrigid structures from 2D image sequences captured by a single camera. Most ofthe existing approaches assume that 3D shapes can be accurately modelled in a linear subspace. These techniques perform well when the deformations are relatively small or simple, but fail when more complex deformations need to be recovered. The non-linear deformations are often observed in highly flexible objects for which the use of the linear model is impractical. A specific type of shape variations might be governed by only a small number of parameters, therefore can be wellrepresented in a low dimensional manifold. We learn a nonlinear shape prior using diffusion maps method. The key contribution in this paper is the introduction of the shape prior that constrain the reconstructed shapes to lie in the learned manifold. The proposed methodology has been validated quantitatively and qualitatively on 2D points sequences projected from the 3D motion capture data and real 2D video sequences. The comparisons oftheproposed man- ifold based method against several state-of-the-art techniques are shown on different types of deformable objects.</p><p>5 0.17051698 <a title="178-tfidf-5" href="./cvpr-2013-Sparse_Subspace_Denoising_for_Image_Manifolds.html">405 cvpr-2013-Sparse Subspace Denoising for Image Manifolds</a></p>
<p>Author: Bo Wang, Zhuowen Tu</p><p>Abstract: With the increasing availability of high dimensional data and demand in sophisticated data analysis algorithms, manifold learning becomes a critical technique to perform dimensionality reduction, unraveling the intrinsic data structure. The real-world data however often come with noises and outliers; seldom, all the data live in a single linear subspace. Inspired by the recent advances in sparse subspace learning and diffusion-based approaches, we propose a new manifold denoising algorithm in which data neighborhoods are adaptively inferred via sparse subspace reconstruction; we then derive a new formulation to perform denoising to the original data. Experiments carried out on both toy and real applications demonstrate the effectiveness of our method; it is insensitive to parameter tuning and we show significant improvement over the competing algorithms.</p><p>6 0.16737589 <a title="178-tfidf-6" href="./cvpr-2013-BFO_Meets_HOG%3A_Feature_Extraction_Based_on_Histograms_of_Oriented_p.d.f._Gradients_for_Image_Classification.html">53 cvpr-2013-BFO Meets HOG: Feature Extraction Based on Histograms of Oriented p.d.f. Gradients for Image Classification</a></p>
<p>7 0.16475637 <a title="178-tfidf-7" href="./cvpr-2013-Top-Down_Segmentation_of_Non-rigid_Visual_Objects_Using_Derivative-Based_Search_on_Sparse_Manifolds.html">433 cvpr-2013-Top-Down Segmentation of Non-rigid Visual Objects Using Derivative-Based Search on Sparse Manifolds</a></p>
<p>8 0.16338469 <a title="178-tfidf-8" href="./cvpr-2013-MKPLS%3A_Manifold_Kernel_Partial_Least_Squares_for_Lipreading_and_Speaker_Identification.html">276 cvpr-2013-MKPLS: Manifold Kernel Partial Least Squares for Lipreading and Speaker Identification</a></p>
<p>9 0.14892504 <a title="178-tfidf-9" href="./cvpr-2013-Multi-level_Discriminative_Dictionary_Learning_towards_Hierarchical_Visual_Categorization.html">296 cvpr-2013-Multi-level Discriminative Dictionary Learning towards Hierarchical Visual Categorization</a></p>
<p>10 0.14832367 <a title="178-tfidf-10" href="./cvpr-2013-Learning_a_Manifold_as_an_Atlas.html">259 cvpr-2013-Learning a Manifold as an Atlas</a></p>
<p>11 0.14605834 <a title="178-tfidf-11" href="./cvpr-2013-Learning_Structured_Low-Rank_Representations_for_Image_Classification.html">257 cvpr-2013-Learning Structured Low-Rank Representations for Image Classification</a></p>
<p>12 0.14176065 <a title="178-tfidf-12" href="./cvpr-2013-Learning_Binary_Codes_for_High-Dimensional_Data_Using_Bilinear_Projections.html">246 cvpr-2013-Learning Binary Codes for High-Dimensional Data Using Bilinear Projections</a></p>
<p>13 0.13917051 <a title="178-tfidf-13" href="./cvpr-2013-A_Bayesian_Approach_to_Multimodal_Visual_Dictionary_Learning.html">5 cvpr-2013-A Bayesian Approach to Multimodal Visual Dictionary Learning</a></p>
<p>14 0.13913457 <a title="178-tfidf-14" href="./cvpr-2013-Harvesting_Mid-level_Visual_Concepts_from_Large-Scale_Internet_Images.html">200 cvpr-2013-Harvesting Mid-level Visual Concepts from Large-Scale Internet Images</a></p>
<p>15 0.13249962 <a title="178-tfidf-15" href="./cvpr-2013-Supervised_Kernel_Descriptors_for_Visual_Recognition.html">421 cvpr-2013-Supervised Kernel Descriptors for Visual Recognition</a></p>
<p>16 0.13079403 <a title="178-tfidf-16" href="./cvpr-2013-Kernel_Methods_on_the_Riemannian_Manifold_of_Symmetric_Positive_Definite_Matrices.html">238 cvpr-2013-Kernel Methods on the Riemannian Manifold of Symmetric Positive Definite Matrices</a></p>
<p>17 0.12897176 <a title="178-tfidf-17" href="./cvpr-2013-Joint_Sparsity-Based_Representation_and_Analysis_of_Unconstrained_Activities.html">233 cvpr-2013-Joint Sparsity-Based Representation and Analysis of Unconstrained Activities</a></p>
<p>18 0.12381852 <a title="178-tfidf-18" href="./cvpr-2013-Online_Robust_Dictionary_Learning.html">315 cvpr-2013-Online Robust Dictionary Learning</a></p>
<p>19 0.12348331 <a title="178-tfidf-19" href="./cvpr-2013-Generalized_Domain-Adaptive_Dictionaries.html">185 cvpr-2013-Generalized Domain-Adaptive Dictionaries</a></p>
<p>20 0.12293515 <a title="178-tfidf-20" href="./cvpr-2013-Harry_Potter%27s_Marauder%27s_Map%3A_Localizing_and_Tracking_Multiple_Persons-of-Interest_by_Nonnegative_Discretization.html">199 cvpr-2013-Harry Potter's Marauder's Map: Localizing and Tracking Multiple Persons-of-Interest by Nonnegative Discretization</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.24), (1, -0.013), (2, 0.151), (3, -0.133), (4, -0.011), (5, 0.014), (6, -0.086), (7, 0.121), (8, 0.002), (9, 0.02), (10, -0.121), (11, 0.014), (12, -0.059), (13, 0.058), (14, -0.082), (15, 0.075), (16, 0.026), (17, 0.044), (18, 0.013), (19, -0.001), (20, -0.008), (21, -0.015), (22, 0.156), (23, 0.038), (24, -0.041), (25, -0.208), (26, 0.032), (27, 0.025), (28, 0.062), (29, 0.02), (30, -0.01), (31, -0.101), (32, 0.026), (33, -0.071), (34, 0.047), (35, -0.02), (36, -0.003), (37, 0.057), (38, 0.032), (39, -0.019), (40, -0.015), (41, 0.053), (42, -0.053), (43, 0.094), (44, -0.075), (45, -0.066), (46, 0.073), (47, -0.003), (48, -0.051), (49, -0.024)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92743176 <a title="178-lsi-1" href="./cvpr-2013-From_Local_Similarity_to_Global_Coding%3A_An_Application_to_Image_Classification.html">178 cvpr-2013-From Local Similarity to Global Coding: An Application to Image Classification</a></p>
<p>Author: Amirreza Shaban, Hamid R. Rabiee, Mehrdad Farajtabar, Marjan Ghazvininejad</p><p>Abstract: Bag of words models for feature extraction have demonstrated top-notch performance in image classification. These representations are usually accompanied by a coding method. Recently, methods that code a descriptor giving regard to its nearby bases have proved efficacious. These methods take into account the nonlinear structure of descriptors, since local similarities are a good approximation of global similarities. However, they confine their usage of the global similarities to nearby bases. In this paper, we propose a coding scheme that brings into focus the manifold structure of descriptors, and devise a method to compute the global similarities of descriptors to the bases. Given a local similarity measure between bases, a global measure is computed. Exploiting the local similarity of a descriptor and its nearby bases, a global measure of association of a descriptor to all the bases is computed. Unlike the locality-based and sparse coding methods, the proposed coding varies smoothly with respect to the underlying manifold. Experiments on benchmark image classification datasets substantiate the superiority oftheproposed method over its locality and sparsity based rivals.</p><p>2 0.81885666 <a title="178-lsi-2" href="./cvpr-2013-MKPLS%3A_Manifold_Kernel_Partial_Least_Squares_for_Lipreading_and_Speaker_Identification.html">276 cvpr-2013-MKPLS: Manifold Kernel Partial Least Squares for Lipreading and Speaker Identification</a></p>
<p>Author: Amr Bakry, Ahmed Elgammal</p><p>Abstract: Visual speech recognition is a challenging problem, due to confusion between visual speech features. The speaker identification problem is usually coupled with speech recognition. Moreover, speaker identification is important to several applications, such as automatic access control, biometrics, authentication, and personal privacy issues. In this paper, we propose a novel approach for lipreading and speaker identification. Wepropose a new approachfor manifold parameterization in a low-dimensional latent space, where each manifold is represented as a point in that space. We initially parameterize each instance manifold using a nonlinear mapping from a unified manifold representation. We then factorize the parameter space using Kernel Partial Least Squares (KPLS) to achieve a low-dimension manifold latent space. We use two-way projections to achieve two manifold latent spaces, one for the speech content and one for the speaker. We apply our approach on two public databases: AVLetters and OuluVS. We show the results for three different settings of lipreading: speaker independent, speaker dependent, and speaker semi-dependent. Our approach outperforms for the speaker semi-dependent setting by at least 15% of the baseline, and competes in the other two settings.</p><p>3 0.77581924 <a title="178-lsi-3" href="./cvpr-2013-Kernel_Learning_for_Extrinsic_Classification_of_Manifold_Features.html">237 cvpr-2013-Kernel Learning for Extrinsic Classification of Manifold Features</a></p>
<p>Author: Raviteja Vemulapalli, Jaishanker K. Pillai, Rama Chellappa</p><p>Abstract: In computer vision applications, features often lie on Riemannian manifolds with known geometry. Popular learning algorithms such as discriminant analysis, partial least squares, support vector machines, etc., are not directly applicable to such features due to the non-Euclidean nature of the underlying spaces. Hence, classification is often performed in an extrinsic manner by mapping the manifolds to Euclidean spaces using kernels. However, for kernel based approaches, poor choice of kernel often results in reduced performance. In this paper, we address the issue of kernelselection for the classification of features that lie on Riemannian manifolds using the kernel learning approach. We propose two criteria for jointly learning the kernel and the classifier using a single optimization problem. Specifically, for the SVM classifier, we formulate the problem of learning a good kernel-classifier combination as a convex optimization problem and solve it efficiently following the multiple kernel learning approach. Experimental results on image set-based classification and activity recognition clearly demonstrate the superiority of the proposed approach over existing methods for classification of manifold features.</p><p>4 0.77090555 <a title="178-lsi-4" href="./cvpr-2013-Rolling_Riemannian_Manifolds_to_Solve_the_Multi-class_Classification_Problem.html">367 cvpr-2013-Rolling Riemannian Manifolds to Solve the Multi-class Classification Problem</a></p>
<p>Author: Rui Caseiro, Pedro Martins, João F. Henriques, Fátima Silva Leite, Jorge Batista</p><p>Abstract: In the past few years there has been a growing interest on geometric frameworks to learn supervised classification models on Riemannian manifolds [31, 27]. A popular framework, valid over any Riemannian manifold, was proposed in [31] for binary classification. Once moving from binary to multi-class classification thisparadigm is not valid anymore, due to the spread of multiple positive classes on the manifold [27]. It is then natural to ask whether the multi-class paradigm could be extended to operate on a large class of Riemannian manifolds. We propose a mathematically well-founded classification paradigm that allows to extend the work in [31] to multi-class models, taking into account the structure of the space. The idea is to project all the data from the manifold onto an affine tangent space at a particular point. To mitigate the distortion induced by local diffeomorphisms, we introduce for the first time in the computer vision community a well-founded mathematical concept, so-called Rolling map [21, 16]. The novelty in this alternate school of thought is that the manifold will be firstly rolled (without slipping or twisting) as a rigid body, then the given data is unwrapped onto the affine tangent space, where the classification is performed.</p><p>5 0.75550175 <a title="178-lsi-5" href="./cvpr-2013-Learning_a_Manifold_as_an_Atlas.html">259 cvpr-2013-Learning a Manifold as an Atlas</a></p>
<p>Author: Nikolaos Pitelis, Chris Russell, Lourdes Agapito</p><p>Abstract: In this work, we return to the underlying mathematical definition of a manifold and directly characterise learning a manifold as finding an atlas, or a set of overlapping charts, that accurately describe local structure. We formulate the problem of learning the manifold as an optimisation that simultaneously refines the continuous parameters defining the charts, and the discrete assignment of points to charts. In contrast to existing methods, this direct formulation of a manifold does not require “unwrapping ” the manifold into a lower dimensional space and allows us to learn closed manifolds of interest to vision, such as those corresponding to gait cycles or camera pose. We report state-ofthe-art results for manifold based nearest neighbour classification on vision datasets, and show how the same techniques can be applied to the 3D reconstruction of human motion from a single image.</p><p>6 0.7471928 <a title="178-lsi-6" href="./cvpr-2013-Kernel_Methods_on_the_Riemannian_Manifold_of_Symmetric_Positive_Definite_Matrices.html">238 cvpr-2013-Kernel Methods on the Riemannian Manifold of Symmetric Positive Definite Matrices</a></p>
<p>7 0.69695348 <a title="178-lsi-7" href="./cvpr-2013-Supervised_Kernel_Descriptors_for_Visual_Recognition.html">421 cvpr-2013-Supervised Kernel Descriptors for Visual Recognition</a></p>
<p>8 0.66787684 <a title="178-lsi-8" href="./cvpr-2013-BFO_Meets_HOG%3A_Feature_Extraction_Based_on_Histograms_of_Oriented_p.d.f._Gradients_for_Image_Classification.html">53 cvpr-2013-BFO Meets HOG: Feature Extraction Based on Histograms of Oriented p.d.f. Gradients for Image Classification</a></p>
<p>9 0.64917862 <a title="178-lsi-9" href="./cvpr-2013-Top-Down_Segmentation_of_Non-rigid_Visual_Objects_Using_Derivative-Based_Search_on_Sparse_Manifolds.html">433 cvpr-2013-Top-Down Segmentation of Non-rigid Visual Objects Using Derivative-Based Search on Sparse Manifolds</a></p>
<p>10 0.64559859 <a title="178-lsi-10" href="./cvpr-2013-Classification_of_Tumor_Histology_via_Morphometric_Context.html">83 cvpr-2013-Classification of Tumor Histology via Morphometric Context</a></p>
<p>11 0.6432904 <a title="178-lsi-11" href="./cvpr-2013-Transfer_Sparse_Coding_for_Robust_Image_Representation.html">442 cvpr-2013-Transfer Sparse Coding for Robust Image Representation</a></p>
<p>12 0.62394041 <a title="178-lsi-12" href="./cvpr-2013-Local_Fisher_Discriminant_Analysis_for_Pedestrian_Re-identification.html">270 cvpr-2013-Local Fisher Discriminant Analysis for Pedestrian Re-identification</a></p>
<p>13 0.61155218 <a title="178-lsi-13" href="./cvpr-2013-Sparse_Output_Coding_for_Large-Scale_Visual_Recognition.html">403 cvpr-2013-Sparse Output Coding for Large-Scale Visual Recognition</a></p>
<p>14 0.58840102 <a title="178-lsi-14" href="./cvpr-2013-Heterogeneous_Visual_Features_Fusion_via_Sparse_Multimodal_Machine.html">201 cvpr-2013-Heterogeneous Visual Features Fusion via Sparse Multimodal Machine</a></p>
<p>15 0.58579051 <a title="178-lsi-15" href="./cvpr-2013-Multipath_Sparse_Coding_Using_Hierarchical_Matching_Pursuit.html">304 cvpr-2013-Multipath Sparse Coding Using Hierarchical Matching Pursuit</a></p>
<p>16 0.58099812 <a title="178-lsi-16" href="./cvpr-2013-Histograms_of_Sparse_Codes_for_Object_Detection.html">204 cvpr-2013-Histograms of Sparse Codes for Object Detection</a></p>
<p>17 0.57608378 <a title="178-lsi-17" href="./cvpr-2013-SCaLE%3A_Supervised_and_Cascaded_Laplacian_Eigenmaps_for_Visual_Object_Recognition_Based_on_Nearest_Neighbors.html">371 cvpr-2013-SCaLE: Supervised and Cascaded Laplacian Eigenmaps for Visual Object Recognition Based on Nearest Neighbors</a></p>
<p>18 0.56746328 <a title="178-lsi-18" href="./cvpr-2013-Graph-Laplacian_PCA%3A_Closed-Form_Solution_and_Robustness.html">191 cvpr-2013-Graph-Laplacian PCA: Closed-Form Solution and Robustness</a></p>
<p>19 0.56466484 <a title="178-lsi-19" href="./cvpr-2013-Learning_Binary_Codes_for_High-Dimensional_Data_Using_Bilinear_Projections.html">246 cvpr-2013-Learning Binary Codes for High-Dimensional Data Using Bilinear Projections</a></p>
<p>20 0.56121731 <a title="178-lsi-20" href="./cvpr-2013-Inductive_Hashing_on_Manifolds.html">223 cvpr-2013-Inductive Hashing on Manifolds</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.094), (4, 0.133), (5, 0.224), (37, 0.093), (81, 0.041), (86, 0.066), (87, 0.176), (95, 0.026), (97, 0.076)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.91100395 <a title="178-lda-1" href="./cvpr-2013-Dense_Segmentation-Aware_Descriptors.html">112 cvpr-2013-Dense Segmentation-Aware Descriptors</a></p>
<p>Author: Eduard Trulls, Iasonas Kokkinos, Alberto Sanfeliu, Francesc Moreno-Noguer</p><p>Abstract: In this work we exploit segmentation to construct appearance descriptors that can robustly deal with occlusion and background changes. For this, we downplay measurements coming from areas that are unlikely to belong to the same region as the descriptor’s center, as suggested by soft segmentation masks. Our treatment is applicable to any image point, i.e. dense, and its computational overhead is in the order of a few seconds. We integrate this idea with Dense SIFT, and also with Dense Scale and Rotation Invariant Descriptors (SID), delivering descriptors that are densely computable, invariant to scaling and rotation, and robust to background changes. We apply our approach to standard benchmarks on large displacement motion estimation using SIFT-flow and widebaseline stereo, systematically demonstrating that the introduction of segmentation yields clear improvements.</p><p>2 0.89210796 <a title="178-lda-2" href="./cvpr-2013-Human_Pose_Estimation_Using_a_Joint_Pixel-wise_and_Part-wise_Formulation.html">207 cvpr-2013-Human Pose Estimation Using a Joint Pixel-wise and Part-wise Formulation</a></p>
<p>Author: Ľ</p><p>Abstract: Our goal is to detect humans and estimate their 2D pose in single images. In particular, handling cases of partial visibility where some limbs may be occluded or one person is partially occluding another. Two standard, but disparate, approaches have developed in the field: the first is the part based approach for layout type problems, involving optimising an articulated pictorial structure; the second is the pixel based approach for image labelling involving optimising a random field graph defined on the image. Our novel contribution is a formulation for pose estimation which combines these two models in a principled way in one optimisation problem and thereby inherits the advantages of both of them. Inference on this joint model finds the set of instances of persons in an image, the location of their joints, and a pixel-wise body part labelling. We achieve near or state of the art results on standard human pose data sets, and demonstrate the correct estimation for cases of self-occlusion, person overlap and image truncation.</p><p>same-paper 3 0.87803173 <a title="178-lda-3" href="./cvpr-2013-From_Local_Similarity_to_Global_Coding%3A_An_Application_to_Image_Classification.html">178 cvpr-2013-From Local Similarity to Global Coding: An Application to Image Classification</a></p>
<p>Author: Amirreza Shaban, Hamid R. Rabiee, Mehrdad Farajtabar, Marjan Ghazvininejad</p><p>Abstract: Bag of words models for feature extraction have demonstrated top-notch performance in image classification. These representations are usually accompanied by a coding method. Recently, methods that code a descriptor giving regard to its nearby bases have proved efficacious. These methods take into account the nonlinear structure of descriptors, since local similarities are a good approximation of global similarities. However, they confine their usage of the global similarities to nearby bases. In this paper, we propose a coding scheme that brings into focus the manifold structure of descriptors, and devise a method to compute the global similarities of descriptors to the bases. Given a local similarity measure between bases, a global measure is computed. Exploiting the local similarity of a descriptor and its nearby bases, a global measure of association of a descriptor to all the bases is computed. Unlike the locality-based and sparse coding methods, the proposed coding varies smoothly with respect to the underlying manifold. Experiments on benchmark image classification datasets substantiate the superiority oftheproposed method over its locality and sparsity based rivals.</p><p>4 0.87792188 <a title="178-lda-4" href="./cvpr-2013-Fusing_Robust_Face_Region_Descriptors_via_Multiple_Metric_Learning_for_Face_Recognition_in_the_Wild.html">182 cvpr-2013-Fusing Robust Face Region Descriptors via Multiple Metric Learning for Face Recognition in the Wild</a></p>
<p>Author: Zhen Cui, Wen Li, Dong Xu, Shiguang Shan, Xilin Chen</p><p>Abstract: In many real-world face recognition scenarios, face images can hardly be aligned accurately due to complex appearance variations or low-quality images. To address this issue, we propose a new approach to extract robust face region descriptors. Specifically, we divide each image (resp. video) into several spatial blocks (resp. spatial-temporal volumes) and then represent each block (resp. volume) by sum-pooling the nonnegative sparse codes of position-free patches sampled within the block (resp. volume). Whitened Principal Component Analysis (WPCA) is further utilized to reduce the feature dimension, which leads to our Spatial Face Region Descriptor (SFRD) (resp. Spatial-Temporal Face Region Descriptor, STFRD) for images (resp. videos). Moreover, we develop a new distance method for face verification metric learning called Pairwise-constrained Multiple Metric Learning (PMML) to effectively integrate the face region descriptors of all blocks (resp. volumes) from an image (resp. a video). Our work achieves the state- of-the-art performances on two real-world datasets LFW and YouTube Faces (YTF) according to the restricted protocol.</p><p>5 0.87523854 <a title="178-lda-5" href="./cvpr-2013-Pedestrian_Detection_with_Unsupervised_Multi-stage_Feature_Learning.html">328 cvpr-2013-Pedestrian Detection with Unsupervised Multi-stage Feature Learning</a></p>
<p>Author: Pierre Sermanet, Koray Kavukcuoglu, Soumith Chintala, Yann Lecun</p><p>Abstract: Pedestrian detection is a problem of considerable practical interest. Adding to the list of successful applications of deep learning methods to vision, we report state-of-theart and competitive results on all major pedestrian datasets with a convolutional network model. The model uses a few new twists, such as multi-stage features, connections that skip layers to integrate global shape information with local distinctive motif information, and an unsupervised method based on convolutional sparse coding to pre-train the filters at each stage.</p><p>6 0.86379838 <a title="178-lda-6" href="./cvpr-2013-Composite_Statistical_Inference_for_Semantic_Segmentation.html">86 cvpr-2013-Composite Statistical Inference for Semantic Segmentation</a></p>
<p>7 0.86366409 <a title="178-lda-7" href="./cvpr-2013-HON4D%3A_Histogram_of_Oriented_4D_Normals_for_Activity_Recognition_from_Depth_Sequences.html">196 cvpr-2013-HON4D: Histogram of Oriented 4D Normals for Activity Recognition from Depth Sequences</a></p>
<p>8 0.8631466 <a title="178-lda-8" href="./cvpr-2013-A_Video_Representation_Using_Temporal_Superpixels.html">29 cvpr-2013-A Video Representation Using Temporal Superpixels</a></p>
<p>9 0.8626259 <a title="178-lda-9" href="./cvpr-2013-A_Higher-Order_CRF_Model_for_Road_Network_Extraction.html">13 cvpr-2013-A Higher-Order CRF Model for Road Network Extraction</a></p>
<p>10 0.86147499 <a title="178-lda-10" href="./cvpr-2013-Multi-source_Multi-scale_Counting_in_Extremely_Dense_Crowd_Images.html">299 cvpr-2013-Multi-source Multi-scale Counting in Extremely Dense Crowd Images</a></p>
<p>11 0.86115825 <a title="178-lda-11" href="./cvpr-2013-Constraints_as_Features.html">93 cvpr-2013-Constraints as Features</a></p>
<p>12 0.86043537 <a title="178-lda-12" href="./cvpr-2013-Integrating_Grammar_and_Segmentation_for_Human_Pose_Estimation.html">225 cvpr-2013-Integrating Grammar and Segmentation for Human Pose Estimation</a></p>
<p>13 0.85998619 <a title="178-lda-13" href="./cvpr-2013-Spatial_Inference_Machines.html">406 cvpr-2013-Spatial Inference Machines</a></p>
<p>14 0.85977668 <a title="178-lda-14" href="./cvpr-2013-Winding_Number_for_Region-Boundary_Consistent_Salient_Contour_Extraction.html">468 cvpr-2013-Winding Number for Region-Boundary Consistent Salient Contour Extraction</a></p>
<p>15 0.85876209 <a title="178-lda-15" href="./cvpr-2013-Learning_to_Detect_Partially_Overlapping_Instances.html">264 cvpr-2013-Learning to Detect Partially Overlapping Instances</a></p>
<p>16 0.85856706 <a title="178-lda-16" href="./cvpr-2013-Representing_and_Discovering_Adversarial_Team_Behaviors_Using_Player_Roles.html">356 cvpr-2013-Representing and Discovering Adversarial Team Behaviors Using Player Roles</a></p>
<p>17 0.85823876 <a title="178-lda-17" href="./cvpr-2013-Layer_Depth_Denoising_and_Completion_for_Structured-Light_RGB-D_Cameras.html">245 cvpr-2013-Layer Depth Denoising and Completion for Structured-Light RGB-D Cameras</a></p>
<p>18 0.8581571 <a title="178-lda-18" href="./cvpr-2013-Exploring_Compositional_High_Order_Pattern_Potentials_for_Structured_Output_Learning.html">156 cvpr-2013-Exploring Compositional High Order Pattern Potentials for Structured Output Learning</a></p>
<p>19 0.85789609 <a title="178-lda-19" href="./cvpr-2013-Selective_Transfer_Machine_for_Personalized_Facial_Action_Unit_Detection.html">385 cvpr-2013-Selective Transfer Machine for Personalized Facial Action Unit Detection</a></p>
<p>20 0.85779232 <a title="178-lda-20" href="./cvpr-2013-Label_Propagation_from_ImageNet_to_3D_Point_Clouds.html">242 cvpr-2013-Label Propagation from ImageNet to 3D Point Clouds</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
