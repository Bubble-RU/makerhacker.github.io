<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>178 cvpr-2013-From Local Similarity to Global Coding: An Application to Image Classification</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-178" href="#">cvpr2013-178</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>178 cvpr-2013-From Local Similarity to Global Coding: An Application to Image Classification</h1>
<br/><p>Source: <a title="cvpr-2013-178-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Shaban_From_Local_Similarity_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Amirreza Shaban, Hamid R. Rabiee, Mehrdad Farajtabar, Marjan Ghazvininejad</p><p>Abstract: Bag of words models for feature extraction have demonstrated top-notch performance in image classification. These representations are usually accompanied by a coding method. Recently, methods that code a descriptor giving regard to its nearby bases have proved efficacious. These methods take into account the nonlinear structure of descriptors, since local similarities are a good approximation of global similarities. However, they confine their usage of the global similarities to nearby bases. In this paper, we propose a coding scheme that brings into focus the manifold structure of descriptors, and devise a method to compute the global similarities of descriptors to the bases. Given a local similarity measure between bases, a global measure is computed. Exploiting the local similarity of a descriptor and its nearby bases, a global measure of association of a descriptor to all the bases is computed. Unlike the locality-based and sparse coding methods, the proposed coding varies smoothly with respect to the underlying manifold. Experiments on benchmark image classification datasets substantiate the superiority oftheproposed method over its locality and sparsity based rivals.</p><p>Reference: <a title="cvpr-2013-178-reference" href="../cvpr2013_reference/cvpr-2013-From_Local_Similarity_to_Global_Coding%3A_An_Application_to_Image_Classification_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 These representations are usually accompanied by a coding method. [sent-11, score-0.484]
</p><p>2 Recently, methods that code a descriptor giving regard to its nearby bases have proved efficacious. [sent-12, score-0.6]
</p><p>3 These methods take into account the nonlinear structure of descriptors, since local similarities are a good approximation of global similarities. [sent-13, score-0.419]
</p><p>4 However, they confine their usage of the global similarities to nearby bases. [sent-14, score-0.318]
</p><p>5 In this paper, we propose a coding scheme that brings into focus the manifold structure of descriptors, and devise a method to compute the global similarities of descriptors to the bases. [sent-15, score-1.121]
</p><p>6 Given a local similarity measure between bases, a global measure is computed. [sent-16, score-0.277]
</p><p>7 Exploiting the local similarity of a descriptor and its nearby bases, a global measure of association of a descriptor to all the bases is computed. [sent-17, score-0.819]
</p><p>8 Unlike the locality-based and sparse coding methods, the proposed coding varies smoothly with respect to the underlying manifold. [sent-18, score-1.075]
</p><p>9 Experiments on benchmark image classification datasets substantiate the superiority oftheproposed method  over its locality and sparsity based rivals. [sent-19, score-0.326]
</p><p>10 Among these, BoW models, which are based on the representation of affine invariant descriptors of image patches, have proved to have great performance and are widely used in many applications such as image classification [15], image retrieval [20], and human pose estimation [1]. [sent-26, score-0.134]
</p><p>11 Researchers have empirically found that, assigning each feature to nearby bases leads to remarkable improvement in accuracy. [sent-30, score-0.52]
</p><p>12 Authors in [25] proved that under the manifold assumption, considering local bases in coding is essential for successful nonlinear feature learning. [sent-31, score-1.315]
</p><p>13 [23] in their LLC method use k-nearest neighbor bases in the coding process and set the coding coefficient for other bases to zero. [sent-34, score-1.863]
</p><p>14 Since the manifold is locally linear, a linear similarity measure is used for neighboring bases. [sent-35, score-0.367]
</p><p>15 Although this coding scheme captures the local manifold structure, it’s not capable of binding this information to derive and utilize the global structure of the manifold. [sent-36, score-0.929]
</p><p>16 To be more specific, two features that have different bases in their neighborhood generate completely different codings independent of their distance on the manifold. [sent-37, score-0.531]
</p><p>17 To overcome this drawback, we propose a novel method called Local Similarity Global Coding (LSGC), that uses the local similarities between bases to obtain a nonlinear global similarity measure between local features and bases. [sent-38, score-1.005]
</p><p>18 We first show that this coding scheme captures the global manifold structure and generates a smoother coding compared to LLC. [sent-39, score-1.387]
</p><p>19 Next, we formulate the coding as a linear transformation of any local coding (which is obtained by an arbitrary local coding scheme such as LLC). [sent-40, score-1.595]
</p><p>20 This formulation is of practical interest when the transformation from local to global coding is obtained by matrix-vector multiplication. [sent-41, score-0.6]
</p><p>21 First, local points in the image are selected or densely sampled, and an affine invariant feature vector xi called the descriptor vector is extracted from each local point. [sent-51, score-0.209]
</p><p>22 Each of these elements are called coding vectors ui. [sent-54, score-0.484]
</p><p>23 Different algorithms use different codebook learning and coding schemes. [sent-56, score-0.571]
</p><p>24 To aggregate the information of different local codings into one feature vector, local codings from image patches are merged together using a predefined pooling function: v = F(U)  (1)  where the ith column of U is the coding vector ui, F is the pooling function and v is the image feature vector. [sent-57, score-1.041]
</p><p>25 Among them are max pooling [24], sum normalization [19], sum pooling and ? [sent-59, score-0.234]
</p><p>26 ×  However, recent work empirically shows that the max pooling function leads to superior performance [24, 23]. [sent-61, score-0.131]
</p><p>27 The max pooling function can be defined as: vj  = max( |u1j |, |u2j | , . [sent-62, score-0.131]
</p><p>28 , |ulj |)  (2)  where uij is the jth element of ui and l is the number of local points for each image. [sent-65, score-0.169]
</p><p>29 Recent works mainly differ from each other in their dictionary learning and coding schemes. [sent-77, score-0.595]
</p><p>30 In the rest of the paper consider base bi as the ith column of dictionary matrix B which has a total of c columns. [sent-79, score-0.294]
</p><p>31 xi and ui are the local feature and corresponding coding for the ith local keypoint respectively. [sent-80, score-0.798]
</p><p>32 Related Work  In this section, we review commonly used methods in coding and dictionary learning for image classification. [sent-82, score-0.595]
</p><p>33 , c where xi and ui are descriptor and coding vectors of the ith local point respectively. [sent-94, score-0.783]
</p><p>34 n is the total number of local points and there are c bases in the dictionary B. [sent-95, score-0.568]
</p><p>35 The first term represents the reconstruction error and the second term controls the sparsity of coding ui. [sent-96, score-0.51]
</p><p>36 The sparsity prior plays a key role in coding, because it ensures that the coding captures outstanding patterns in local features. [sent-98, score-0.629]
</p><p>37 Although ScSPM proves its performance it has one a major drawback: the coding does not change smoothly when xi varies on the manifold. [sent-102, score-0.618]
</p><p>38 LScSPM [10] tries to overcome this problem by using manifold assumption. [sent-103, score-0.266]
</p><p>39 ij  where wij denotes the similarity between local features i and j. [sent-113, score-0.194]
</p><p>40 This objective function differs from standard sparse coding in the regularization term, which guarantees that the sparse code varies smoothly on the data manifold. [sent-114, score-0.565]
</p><p>41 The interpretation of smoothness term is that when wij for two local feature is high, their codings must be close in Euclidean space. [sent-115, score-0.2]
</p><p>42 As suggested in [23], locality is more important than sparsity. [sent-172, score-0.125]
</p><p>43 The fundamental assumption in their method is that the local features lie on a nonlinear m dimensional manifold where m is less that the dimension of the ambient space. [sent-173, score-0.428]
</p><p>44 Mentioning locality, brings into consideration the nonlinear structure of the data manifold in the coding process. [sent-175, score-0.855]
</p><p>45 In practice the second term is ignored and coding for each descriptor is obtained by optimizing only the first term using only k-nearest bases. [sent-189, score-0.526]
</p><p>46 This leads to non-zero coefficients for the k-nearest bases and zero for the others. [sent-190, score-0.461]
</p><p>47 σ  Localized soft-assignment coding [17] expresses the coding coefficient as the probability that a local feature xi belongs to a basis bj and surpasses the performance of LLC. [sent-192, score-1.293]
</p><p>48 Its local similarity measure is defined as:  pij=? [sent-193, score-0.185]
</p><p>49 Similar to LLC, coefficients for the k-nearest bases are computed and the others are set to zero. [sent-199, score-0.461]
</p><p>50 Local coding methods like LLC and soft-assignment coding implicitly give regard to manifold structure, since local similarity a is valid approximation only for neighboring points. [sent-200, score-1.397]
</p><p>51 However, these methods disregard global similarities between data, which could be captured using nonlinear similarity estimation methods. [sent-201, score-0.428]
</p><p>52 Motivation Recent image classification methods that look at both reconstruction error and locality in dictionary learning prove to have top-notch performance [23]. [sent-203, score-0.285]
</p><p>53 Looking at locality is a struggle to take the underlying nonlinear structure of local features into account. [sent-204, score-0.313]
</p><p>54 Locality ensures that nearby bases are preferred in coding data points, and this implicitly dis-  222777999644  Figure 2: Kmeans dictionary learning. [sent-205, score-1.086]
</p><p>55 The bases inherit the geometry of descriptors criminates in favor of the bases on the underlying manifold. [sent-207, score-0.985]
</p><p>56 Since bases are usually samples of the manifold, the distance (or similarity) of data to these bases is an appropriate feature that embodies the geometry of the data. [sent-208, score-0.914]
</p><p>57 Usual coding methods learn the bases by considering the manifold structure either explicitly or implicitly. [sent-209, score-1.182]
</p><p>58 To elaborate, we refer to a closely related trend in large-scale and  online manifold learning literature that tries to find only a few bases in order to best preserve the manifold structure. [sent-210, score-0.998]
</p><p>59 Thus, the bases which are learned by k-means trace the manifold structure of local features. [sent-214, score-0.781]
</p><p>60 Figure 2 illustrates how the bases learned by k-means cover the whole structure of data. [sent-215, score-0.459]
</p><p>61 The fact that these bases trace the manifold is a motivation to take the natural similarity between bases into account when coding as well. [sent-217, score-1.704]
</p><p>62 This leads to a better utilization of manifold structure in the coding process. [sent-218, score-0.752]
</p><p>63 Exploiting the non-linear dependence of bases to each other a framework is proposed in order to find a global coding scheme for a descriptor. [sent-219, score-1.061]
</p><p>64 Proposed Method Methods that take into account the manifold structure use only the k nearest bases in the coding process. [sent-221, score-1.182]
</p><p>65 In this paper we present a  novel algorithm extending the methods which rely only on local similarities between data and bases. [sent-223, score-0.255]
</p><p>66 We claim that local similarities between bases are valuable in the sense that they can be used to estimate global similarities between local features and bases. [sent-224, score-1.028]
</p><p>67 Considering bases learned by k-means, a local similarity between bases is proposed, which is then utilized to find a global similarity with regard to the manifold structure. [sent-225, score-1.443]
</p><p>68 At last a coding scheme is presented to derive global similarities between descriptors and bases. [sent-226, score-0.826]
</p><p>69 Local Similarity Choosing the similarity measure is arbitrary and the approach taken by any existing method (Gaussian kernel, LLC, Sparse Coding) can be adopted. [sent-229, score-0.128]
</p><p>70 We take the Gaussian kernel approach which is commonly used as a local similarity measure in the manifold learning methods [2]:  W(i,j) =? [sent-230, score-0.486]
</p><p>71 0exp(−| bi−σbj| 2)  oift hbjer∈wi kse-NN(bi)  (8) While W captures only local similarities, in the next subsection we propose a probabilistic framework to find a global measure of the probability that a base belongs to other bases. [sent-231, score-0.246]
</p><p>72 From Local to Global Similarity  Given a matrix W that contains local similarities between bases, stochastic matrix P is defined by normalizing W:  P = D−1W  (9)  where D is a diagonal? [sent-234, score-0.255]
</p><p>73 p(bj |bi) can be interpreted as the probability that bj is a memb|ebr of a Gaussian distribution with mean bi and variance σ. [sent-243, score-0.272]
</p><p>74 As matrix P measures the similarities between neighboring bases, the similarity between non-neighboring bases can be computed indirectly by random walks on the graph which has the adjacency matrix W [13]. [sent-244, score-0.723]
</p><p>75 Suppose p(2) (bk |bi) represents indirect belonging of bi to bk which is not among bi’s neighbors. [sent-245, score-0.37]
</p><p>76 Superscript 2 means an indirect dependence via 2 steps:  p(2)(bk|bi)  ? [sent-246, score-0.127]
</p><p>77 1 222777999755  Therefore, elements of the matrix P2 are indirect similarities of order 2. [sent-256, score-0.266]
</p><p>78 for the similarity of order t we use  similarity of order t  p(t)(bk|bi)  −  1: ? [sent-259, score-0.19]
</p><p>79 1  One can easily see that matrix Pt captures the similarities of order t. [sent-264, score-0.23]
</p><p>80 Although for every t, Pt can be regarded as a measure of non-local similarity, a better measure of dependence of basis j on basis ican be defined as:  S =1tmt? [sent-266, score-0.177]
</p><p>81 −=10Pm,  (12)  which considers a multi-resolution non-local dependence from very local to more global ones. [sent-267, score-0.175]
</p><p>82 (b) Global coding Figure 3: Comparing local and global coding scheme. [sent-367, score-1.084]
</p><p>83 Hand-written Image Classification In this study we aim to compare the classification performance of a Linear SVM with different coding schemes. [sent-371, score-0.533]
</p><p>84 We compare LSGC to LLC [23], soft assignment coding (SAC) [22], and localized soft assignment coding (LSAC) [17] on different benchmark image and hand-written letter datasets. [sent-372, score-1.172]
</p><p>85 In SAC method for each data point x, despite localized soft assignment coding, all coding coefficients are computed. [sent-375, score-0.598]
</p><p>86 In general, LSGC outperforms other coding methods with small numbers of labeled points. [sent-386, score-0.484]
</p><p>87 Employing the max pooling method, we obtain the temporal features. [sent-394, score-0.131]
</p><p>88 We consider five nearest neighbors in coding process and the bandwidth size parameter σ is set to the mean of standard deviation of the bases. [sent-397, score-0.484]
</p><p>89 Note that for t = 1, our method is reduced to soft-assignment coding [17]. [sent-407, score-0.484]
</p><p>90 the local similarity propagate sufficiently on the whole manifold. [sent-415, score-0.152]
</p><p>91 We claim that the superiority of the results is due to considering global similarities in the coding process. [sent-495, score-0.813]
</p><p>92 Conclusion and Future Work  In this paper, we presented a method that uses the information about manifold structure of descriptors, to infer a global similarity measure between bases and descriptors. [sent-503, score-0.885]
</p><p>93 We showed that by using a linear transformation that embodies the manifold information, we can obtain global similarities from the local ones. [sent-504, score-0.607]
</p><p>94 In addition, by using global similarities between bases and descriptors in the coding process, a smoother coding is obtained compared to previous methods. [sent-505, score-1.742]
</p><p>95 Our methods relies on the fact that the bases are sampling the data manifold which is done by k-means. [sent-506, score-0.669]
</p><p>96 Incorporating dictionary learning methods which take the manifold struc-  ture into account is remains as future work. [sent-507, score-0.35]
</p><p>97 Man-  [7]  [8]  [9] [10]  [11]  [12]  [13]  [14]  ifold coarse graining for online semi-supervised learning. [sent-558, score-0.152]
</p><p>98 Local features are not lonely–laplacian sparse coding for image classification. [sent-584, score-0.484]
</p><p>99 Online manifold regularization: A new learning setting and empirical study. [sent-591, score-0.269]
</p><p>100 Linear spatial pyramid matching using sparse coding for image classification. [sent-686, score-0.484]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('coding', 0.484), ('bases', 0.43), ('manifold', 0.239), ('llc', 0.202), ('similarities', 0.198), ('lsgc', 0.184), ('bk', 0.152), ('bi', 0.15), ('locality', 0.125), ('bj', 0.122), ('ui', 0.112), ('pooling', 0.103), ('codings', 0.101), ('similarity', 0.095), ('bui', 0.092), ('graining', 0.092), ('lsac', 0.092), ('rabiee', 0.092), ('shaban', 0.092), ('dictionary', 0.081), ('bow', 0.079), ('nonlinear', 0.076), ('dist', 0.07), ('indirect', 0.068), ('conference', 0.066), ('farajtabar', 0.061), ('mehrdad', 0.061), ('sac', 0.061), ('nearby', 0.061), ('bl', 0.06), ('dependence', 0.059), ('global', 0.059), ('local', 0.057), ('codebook', 0.057), ('ambient', 0.056), ('descriptors', 0.056), ('embodies', 0.054), ('shari', 0.054), ('vq', 0.054), ('xi', 0.053), ('pij', 0.052), ('classification', 0.049), ('euclidian', 0.045), ('scspm', 0.043), ('inherit', 0.043), ('smoothly', 0.043), ('superiority', 0.043), ('descriptor', 0.042), ('wij', 0.042), ('regard', 0.038), ('letter', 0.038), ('varies', 0.038), ('oift', 0.037), ('pages', 0.036), ('ieee', 0.036), ('ith', 0.035), ('coefficient', 0.035), ('online', 0.033), ('measure', 0.033), ('captures', 0.032), ('expresses', 0.032), ('kernel', 0.032), ('coefficients', 0.031), ('smoother', 0.031), ('pattern', 0.031), ('ensures', 0.03), ('centers', 0.03), ('semisupervised', 0.03), ('learning', 0.03), ('structure', 0.029), ('scheme', 0.029), ('benchmark', 0.029), ('remarkable', 0.029), ('claim', 0.029), ('proved', 0.029), ('localized', 0.029), ('attributes', 0.028), ('max', 0.028), ('base', 0.028), ('soft', 0.028), ('coarse', 0.027), ('lscg', 0.027), ('ofclasses', 0.027), ('anxd', 0.027), ('lscspm', 0.027), ('oftheproposed', 0.027), ('sharif', 0.027), ('subje', 0.027), ('substantiate', 0.027), ('brings', 0.027), ('defense', 0.027), ('tries', 0.027), ('sparsity', 0.026), ('svm', 0.026), ('trace', 0.026), ('basis', 0.026), ('fergus', 0.026), ('underlying', 0.026), ('assignment', 0.026), ('dreis', 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999988 <a title="178-tfidf-1" href="./cvpr-2013-From_Local_Similarity_to_Global_Coding%3A_An_Application_to_Image_Classification.html">178 cvpr-2013-From Local Similarity to Global Coding: An Application to Image Classification</a></p>
<p>Author: Amirreza Shaban, Hamid R. Rabiee, Mehrdad Farajtabar, Marjan Ghazvininejad</p><p>Abstract: Bag of words models for feature extraction have demonstrated top-notch performance in image classification. These representations are usually accompanied by a coding method. Recently, methods that code a descriptor giving regard to its nearby bases have proved efficacious. These methods take into account the nonlinear structure of descriptors, since local similarities are a good approximation of global similarities. However, they confine their usage of the global similarities to nearby bases. In this paper, we propose a coding scheme that brings into focus the manifold structure of descriptors, and devise a method to compute the global similarities of descriptors to the bases. Given a local similarity measure between bases, a global measure is computed. Exploiting the local similarity of a descriptor and its nearby bases, a global measure of association of a descriptor to all the bases is computed. Unlike the locality-based and sparse coding methods, the proposed coding varies smoothly with respect to the underlying manifold. Experiments on benchmark image classification datasets substantiate the superiority oftheproposed method over its locality and sparsity based rivals.</p><p>2 0.24748753 <a title="178-tfidf-2" href="./cvpr-2013-BFO_Meets_HOG%3A_Feature_Extraction_Based_on_Histograms_of_Oriented_p.d.f._Gradients_for_Image_Classification.html">53 cvpr-2013-BFO Meets HOG: Feature Extraction Based on Histograms of Oriented p.d.f. Gradients for Image Classification</a></p>
<p>Author: Takumi Kobayashi</p><p>Abstract: Image classification methods have been significantly developed in the last decade. Most methods stem from bagof-features (BoF) approach and it is recently extended to a vector aggregation model, such as using Fisher kernels. In this paper, we propose a novel feature extraction method for image classification. Following the BoF approach, a plenty of local descriptors are first extracted in an image and the proposed method is built upon the probability density function (p.d.f) formed by those descriptors. Since the p.d.f essentially represents the image, we extract the features from the p.d.f by means of the gradients on the p.d.f. The gradients, especially their orientations, effectively characterize the shape of the p.d.f from the geometrical viewpoint. We construct the features by the histogram of the oriented p.d.f gradients via orientation coding followed by aggregation of the orientation codes. The proposed image features, imposing no specific assumption on the targets, are so general as to be applicable to any kinds of tasks regarding image classifications. In the experiments on object recog- nition and scene classification using various datasets, the proposed method exhibits superior performances compared to the other existing methods.</p><p>3 0.15189929 <a title="178-tfidf-3" href="./cvpr-2013-Sparse_Output_Coding_for_Large-Scale_Visual_Recognition.html">403 cvpr-2013-Sparse Output Coding for Large-Scale Visual Recognition</a></p>
<p>Author: Bin Zhao, Eric P. Xing</p><p>Abstract: Many vision tasks require a multi-class classifier to discriminate multiple categories, on the order of hundreds or thousands. In this paper, we propose sparse output coding, a principled way for large-scale multi-class classification, by turning high-cardinality multi-class categorization into a bit-by-bit decoding problem. Specifically, sparse output coding is composed of two steps: efficient coding matrix learning with scalability to thousands of classes, and probabilistic decoding. Empirical results on object recognition and scene classification demonstrate the effectiveness ofour proposed approach.</p><p>4 0.147562 <a title="178-tfidf-4" href="./cvpr-2013-Transfer_Sparse_Coding_for_Robust_Image_Representation.html">442 cvpr-2013-Transfer Sparse Coding for Robust Image Representation</a></p>
<p>Author: Mingsheng Long, Guiguang Ding, Jianmin Wang, Jiaguang Sun, Yuchen Guo, Philip S. Yu</p><p>Abstract: Sparse coding learns a set of basis functions such that each input signal can be well approximated by a linear combination of just a few of the bases. It has attracted increasing interest due to its state-of-the-art performance in BoW based image representation. However, when labeled and unlabeled images are sampled from different distributions, they may be quantized into different visual words of the codebook and encoded with different representations, which may severely degrade classification performance. In this paper, we propose a Transfer Sparse Coding (TSC) approach to construct robust sparse representations for classifying cross-distribution images accurately. Specifically, we aim to minimize the distribution divergence between the labeled and unlabeled images, and incorporate this criterion into the objective function of sparse coding to make the new representations robust to the distribution difference. Experiments show that TSC can significantly outperform state-ofthe-art methods on three types of computer vision datasets.</p><p>5 0.14552425 <a title="178-tfidf-5" href="./cvpr-2013-Fast_Convolutional_Sparse_Coding.html">164 cvpr-2013-Fast Convolutional Sparse Coding</a></p>
<p>Author: Hilton Bristow, Anders Eriksson, Simon Lucey</p><p>Abstract: Sparse coding has become an increasingly popular method in learning and vision for a variety of classification, reconstruction and coding tasks. The canonical approach intrinsically assumes independence between observations during learning. For many natural signals however, sparse coding is applied to sub-elements (i.e. patches) of the signal, where such an assumption is invalid. Convolutional sparse coding explicitly models local interactions through the convolution operator, however the resulting optimization problem is considerably more complex than traditional sparse coding. In this paper, we draw upon ideas from signal processing and Augmented Lagrange Methods (ALMs) to produce a fast algorithm with globally optimal subproblems and super-linear convergence.</p><p>6 0.14438312 <a title="178-tfidf-6" href="./cvpr-2013-Multi-level_Discriminative_Dictionary_Learning_towards_Hierarchical_Visual_Categorization.html">296 cvpr-2013-Multi-level Discriminative Dictionary Learning towards Hierarchical Visual Categorization</a></p>
<p>7 0.13882211 <a title="178-tfidf-7" href="./cvpr-2013-Learning_Structured_Low-Rank_Representations_for_Image_Classification.html">257 cvpr-2013-Learning Structured Low-Rank Representations for Image Classification</a></p>
<p>8 0.13169894 <a title="178-tfidf-8" href="./cvpr-2013-Non-rigid_Structure_from_Motion_with_Diffusion_Maps_Prior.html">306 cvpr-2013-Non-rigid Structure from Motion with Diffusion Maps Prior</a></p>
<p>9 0.13130143 <a title="178-tfidf-9" href="./cvpr-2013-Supervised_Kernel_Descriptors_for_Visual_Recognition.html">421 cvpr-2013-Supervised Kernel Descriptors for Visual Recognition</a></p>
<p>10 0.12549315 <a title="178-tfidf-10" href="./cvpr-2013-Block_and_Group_Regularized_Sparse_Modeling_for_Dictionary_Learning.html">66 cvpr-2013-Block and Group Regularized Sparse Modeling for Dictionary Learning</a></p>
<p>11 0.12170223 <a title="178-tfidf-11" href="./cvpr-2013-Kernel_Learning_for_Extrinsic_Classification_of_Manifold_Features.html">237 cvpr-2013-Kernel Learning for Extrinsic Classification of Manifold Features</a></p>
<p>12 0.12128076 <a title="178-tfidf-12" href="./cvpr-2013-Sparse_Subspace_Denoising_for_Image_Manifolds.html">405 cvpr-2013-Sparse Subspace Denoising for Image Manifolds</a></p>
<p>13 0.12092886 <a title="178-tfidf-13" href="./cvpr-2013-A_Bayesian_Approach_to_Multimodal_Visual_Dictionary_Learning.html">5 cvpr-2013-A Bayesian Approach to Multimodal Visual Dictionary Learning</a></p>
<p>14 0.12076243 <a title="178-tfidf-14" href="./cvpr-2013-Efficient_Maximum_Appearance_Search_for_Large-Scale_Object_Detection.html">144 cvpr-2013-Efficient Maximum Appearance Search for Large-Scale Object Detection</a></p>
<p>15 0.11296982 <a title="178-tfidf-15" href="./cvpr-2013-Recognize_Human_Activities_from_Partially_Observed_Videos.html">347 cvpr-2013-Recognize Human Activities from Partially Observed Videos</a></p>
<p>16 0.10915619 <a title="178-tfidf-16" href="./cvpr-2013-Learning_a_Manifold_as_an_Atlas.html">259 cvpr-2013-Learning a Manifold as an Atlas</a></p>
<p>17 0.1060018 <a title="178-tfidf-17" href="./cvpr-2013-Online_Robust_Dictionary_Learning.html">315 cvpr-2013-Online Robust Dictionary Learning</a></p>
<p>18 0.10467098 <a title="178-tfidf-18" href="./cvpr-2013-Illumination_Estimation_Based_on_Bilayer_Sparse_Coding.html">210 cvpr-2013-Illumination Estimation Based on Bilayer Sparse Coding</a></p>
<p>19 0.1044689 <a title="178-tfidf-19" href="./cvpr-2013-Multipath_Sparse_Coding_Using_Hierarchical_Matching_Pursuit.html">304 cvpr-2013-Multipath Sparse Coding Using Hierarchical Matching Pursuit</a></p>
<p>20 0.10174884 <a title="178-tfidf-20" href="./cvpr-2013-Beta_Process_Joint_Dictionary_Learning_for_Coupled_Feature_Spaces_with_Application_to_Single_Image_Super-Resolution.html">58 cvpr-2013-Beta Process Joint Dictionary Learning for Coupled Feature Spaces with Application to Single Image Super-Resolution</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.203), (1, -0.094), (2, -0.128), (3, 0.134), (4, -0.007), (5, -0.031), (6, -0.036), (7, -0.083), (8, -0.1), (9, -0.034), (10, -0.021), (11, -0.014), (12, -0.028), (13, -0.069), (14, 0.025), (15, 0.012), (16, -0.089), (17, 0.01), (18, -0.01), (19, -0.024), (20, 0.066), (21, 0.072), (22, 0.091), (23, -0.058), (24, -0.033), (25, 0.17), (26, -0.054), (27, 0.123), (28, -0.078), (29, -0.019), (30, 0.04), (31, -0.025), (32, -0.055), (33, 0.016), (34, -0.002), (35, -0.013), (36, -0.009), (37, 0.059), (38, 0.14), (39, -0.097), (40, -0.063), (41, -0.083), (42, 0.051), (43, -0.007), (44, 0.015), (45, -0.105), (46, -0.042), (47, -0.037), (48, -0.05), (49, -0.053)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96333539 <a title="178-lsi-1" href="./cvpr-2013-From_Local_Similarity_to_Global_Coding%3A_An_Application_to_Image_Classification.html">178 cvpr-2013-From Local Similarity to Global Coding: An Application to Image Classification</a></p>
<p>Author: Amirreza Shaban, Hamid R. Rabiee, Mehrdad Farajtabar, Marjan Ghazvininejad</p><p>Abstract: Bag of words models for feature extraction have demonstrated top-notch performance in image classification. These representations are usually accompanied by a coding method. Recently, methods that code a descriptor giving regard to its nearby bases have proved efficacious. These methods take into account the nonlinear structure of descriptors, since local similarities are a good approximation of global similarities. However, they confine their usage of the global similarities to nearby bases. In this paper, we propose a coding scheme that brings into focus the manifold structure of descriptors, and devise a method to compute the global similarities of descriptors to the bases. Given a local similarity measure between bases, a global measure is computed. Exploiting the local similarity of a descriptor and its nearby bases, a global measure of association of a descriptor to all the bases is computed. Unlike the locality-based and sparse coding methods, the proposed coding varies smoothly with respect to the underlying manifold. Experiments on benchmark image classification datasets substantiate the superiority oftheproposed method over its locality and sparsity based rivals.</p><p>2 0.82786059 <a title="178-lsi-2" href="./cvpr-2013-BFO_Meets_HOG%3A_Feature_Extraction_Based_on_Histograms_of_Oriented_p.d.f._Gradients_for_Image_Classification.html">53 cvpr-2013-BFO Meets HOG: Feature Extraction Based on Histograms of Oriented p.d.f. Gradients for Image Classification</a></p>
<p>Author: Takumi Kobayashi</p><p>Abstract: Image classification methods have been significantly developed in the last decade. Most methods stem from bagof-features (BoF) approach and it is recently extended to a vector aggregation model, such as using Fisher kernels. In this paper, we propose a novel feature extraction method for image classification. Following the BoF approach, a plenty of local descriptors are first extracted in an image and the proposed method is built upon the probability density function (p.d.f) formed by those descriptors. Since the p.d.f essentially represents the image, we extract the features from the p.d.f by means of the gradients on the p.d.f. The gradients, especially their orientations, effectively characterize the shape of the p.d.f from the geometrical viewpoint. We construct the features by the histogram of the oriented p.d.f gradients via orientation coding followed by aggregation of the orientation codes. The proposed image features, imposing no specific assumption on the targets, are so general as to be applicable to any kinds of tasks regarding image classifications. In the experiments on object recog- nition and scene classification using various datasets, the proposed method exhibits superior performances compared to the other existing methods.</p><p>3 0.75448996 <a title="178-lsi-3" href="./cvpr-2013-Supervised_Kernel_Descriptors_for_Visual_Recognition.html">421 cvpr-2013-Supervised Kernel Descriptors for Visual Recognition</a></p>
<p>Author: Peng Wang, Jingdong Wang, Gang Zeng, Weiwei Xu, Hongbin Zha, Shipeng Li</p><p>Abstract: In visual recognition tasks, the design of low level image feature representation is fundamental. The advent of local patch features from pixel attributes such as SIFT and LBP, has precipitated dramatic progresses. Recently, a kernel view of these features, called kernel descriptors (KDES) [1], generalizes the feature design in an unsupervised fashion and yields impressive results. In this paper, we present a supervised framework to embed the image level label information into the design of patch level kernel descriptors, which we call supervised kernel descriptors (SKDES). Specifically, we adopt the broadly applied bag-of-words (BOW) image classification pipeline and a large margin criterion to learn the lowlevel patch representation, which makes the patch features much more compact and achieve better discriminative ability than KDES. With this method, we achieve competitive results over several public datasets comparing with stateof-the-art methods.</p><p>4 0.7507028 <a title="178-lsi-4" href="./cvpr-2013-Sparse_Output_Coding_for_Large-Scale_Visual_Recognition.html">403 cvpr-2013-Sparse Output Coding for Large-Scale Visual Recognition</a></p>
<p>Author: Bin Zhao, Eric P. Xing</p><p>Abstract: Many vision tasks require a multi-class classifier to discriminate multiple categories, on the order of hundreds or thousands. In this paper, we propose sparse output coding, a principled way for large-scale multi-class classification, by turning high-cardinality multi-class categorization into a bit-by-bit decoding problem. Specifically, sparse output coding is composed of two steps: efficient coding matrix learning with scalability to thousands of classes, and probabilistic decoding. Empirical results on object recognition and scene classification demonstrate the effectiveness ofour proposed approach.</p><p>5 0.72868401 <a title="178-lsi-5" href="./cvpr-2013-Transfer_Sparse_Coding_for_Robust_Image_Representation.html">442 cvpr-2013-Transfer Sparse Coding for Robust Image Representation</a></p>
<p>Author: Mingsheng Long, Guiguang Ding, Jianmin Wang, Jiaguang Sun, Yuchen Guo, Philip S. Yu</p><p>Abstract: Sparse coding learns a set of basis functions such that each input signal can be well approximated by a linear combination of just a few of the bases. It has attracted increasing interest due to its state-of-the-art performance in BoW based image representation. However, when labeled and unlabeled images are sampled from different distributions, they may be quantized into different visual words of the codebook and encoded with different representations, which may severely degrade classification performance. In this paper, we propose a Transfer Sparse Coding (TSC) approach to construct robust sparse representations for classifying cross-distribution images accurately. Specifically, we aim to minimize the distribution divergence between the labeled and unlabeled images, and incorporate this criterion into the objective function of sparse coding to make the new representations robust to the distribution difference. Experiments show that TSC can significantly outperform state-ofthe-art methods on three types of computer vision datasets.</p><p>6 0.69915372 <a title="178-lsi-6" href="./cvpr-2013-Classification_of_Tumor_Histology_via_Morphometric_Context.html">83 cvpr-2013-Classification of Tumor Histology via Morphometric Context</a></p>
<p>7 0.65301985 <a title="178-lsi-7" href="./cvpr-2013-Multipath_Sparse_Coding_Using_Hierarchical_Matching_Pursuit.html">304 cvpr-2013-Multipath Sparse Coding Using Hierarchical Matching Pursuit</a></p>
<p>8 0.64498365 <a title="178-lsi-8" href="./cvpr-2013-A_Bayesian_Approach_to_Multimodal_Visual_Dictionary_Learning.html">5 cvpr-2013-A Bayesian Approach to Multimodal Visual Dictionary Learning</a></p>
<p>9 0.63857663 <a title="178-lsi-9" href="./cvpr-2013-Fast_Convolutional_Sparse_Coding.html">164 cvpr-2013-Fast Convolutional Sparse Coding</a></p>
<p>10 0.62729317 <a title="178-lsi-10" href="./cvpr-2013-Illumination_Estimation_Based_on_Bilayer_Sparse_Coding.html">210 cvpr-2013-Illumination Estimation Based on Bilayer Sparse Coding</a></p>
<p>11 0.62688112 <a title="178-lsi-11" href="./cvpr-2013-Local_Fisher_Discriminant_Analysis_for_Pedestrian_Re-identification.html">270 cvpr-2013-Local Fisher Discriminant Analysis for Pedestrian Re-identification</a></p>
<p>12 0.62512624 <a title="178-lsi-12" href="./cvpr-2013-SCaLE%3A_Supervised_and_Cascaded_Laplacian_Eigenmaps_for_Visual_Object_Recognition_Based_on_Nearest_Neighbors.html">371 cvpr-2013-SCaLE: Supervised and Cascaded Laplacian Eigenmaps for Visual Object Recognition Based on Nearest Neighbors</a></p>
<p>13 0.6180324 <a title="178-lsi-13" href="./cvpr-2013-Discriminative_Brain_Effective_Connectivity_Analysis_for_Alzheimer%27s_Disease%3A_A_Kernel_Learning_Approach_upon_Sparse_Gaussian_Bayesian_Network.html">129 cvpr-2013-Discriminative Brain Effective Connectivity Analysis for Alzheimer's Disease: A Kernel Learning Approach upon Sparse Gaussian Bayesian Network</a></p>
<p>14 0.61454386 <a title="178-lsi-14" href="./cvpr-2013-MKPLS%3A_Manifold_Kernel_Partial_Least_Squares_for_Lipreading_and_Speaker_Identification.html">276 cvpr-2013-MKPLS: Manifold Kernel Partial Least Squares for Lipreading and Speaker Identification</a></p>
<p>15 0.59344369 <a title="178-lsi-15" href="./cvpr-2013-Heterogeneous_Visual_Features_Fusion_via_Sparse_Multimodal_Machine.html">201 cvpr-2013-Heterogeneous Visual Features Fusion via Sparse Multimodal Machine</a></p>
<p>16 0.59154445 <a title="178-lsi-16" href="./cvpr-2013-Sparse_Quantization_for_Patch_Description.html">404 cvpr-2013-Sparse Quantization for Patch Description</a></p>
<p>17 0.57675576 <a title="178-lsi-17" href="./cvpr-2013-Kernel_Learning_for_Extrinsic_Classification_of_Manifold_Features.html">237 cvpr-2013-Kernel Learning for Extrinsic Classification of Manifold Features</a></p>
<p>18 0.56586802 <a title="178-lsi-18" href="./cvpr-2013-Kernel_Methods_on_the_Riemannian_Manifold_of_Symmetric_Positive_Definite_Matrices.html">238 cvpr-2013-Kernel Methods on the Riemannian Manifold of Symmetric Positive Definite Matrices</a></p>
<p>19 0.56213099 <a title="178-lsi-19" href="./cvpr-2013-Learning_a_Manifold_as_an_Atlas.html">259 cvpr-2013-Learning a Manifold as an Atlas</a></p>
<p>20 0.55535275 <a title="178-lsi-20" href="./cvpr-2013-Graph-Laplacian_PCA%3A_Closed-Form_Solution_and_Robustness.html">191 cvpr-2013-Graph-Laplacian PCA: Closed-Form Solution and Robustness</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.054), (26, 0.015), (33, 0.77), (67, 0.035), (69, 0.02), (87, 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9998821 <a title="178-lda-1" href="./cvpr-2013-From_Local_Similarity_to_Global_Coding%3A_An_Application_to_Image_Classification.html">178 cvpr-2013-From Local Similarity to Global Coding: An Application to Image Classification</a></p>
<p>Author: Amirreza Shaban, Hamid R. Rabiee, Mehrdad Farajtabar, Marjan Ghazvininejad</p><p>Abstract: Bag of words models for feature extraction have demonstrated top-notch performance in image classification. These representations are usually accompanied by a coding method. Recently, methods that code a descriptor giving regard to its nearby bases have proved efficacious. These methods take into account the nonlinear structure of descriptors, since local similarities are a good approximation of global similarities. However, they confine their usage of the global similarities to nearby bases. In this paper, we propose a coding scheme that brings into focus the manifold structure of descriptors, and devise a method to compute the global similarities of descriptors to the bases. Given a local similarity measure between bases, a global measure is computed. Exploiting the local similarity of a descriptor and its nearby bases, a global measure of association of a descriptor to all the bases is computed. Unlike the locality-based and sparse coding methods, the proposed coding varies smoothly with respect to the underlying manifold. Experiments on benchmark image classification datasets substantiate the superiority oftheproposed method over its locality and sparsity based rivals.</p><p>2 0.99967265 <a title="178-lda-2" href="./cvpr-2013-Learning_Locally-Adaptive_Decision_Functions_for_Person_Verification.html">252 cvpr-2013-Learning Locally-Adaptive Decision Functions for Person Verification</a></p>
<p>Author: Zhen Li, Shiyu Chang, Feng Liang, Thomas S. Huang, Liangliang Cao, John R. Smith</p><p>Abstract: This paper considers the person verification problem in modern surveillance and video retrieval systems. The problem is to identify whether a pair of face or human body images is about the same person, even if the person is not seen before. Traditional methods usually look for a distance (or similarity) measure between images (e.g., by metric learning algorithms), and make decisions based on a fixed threshold. We show that this is nevertheless insufficient and sub-optimal for the verification problem. This paper proposes to learn a decision function for verification that can be viewed as a joint model of a distance metric and a locally adaptive thresholding rule. We further formulate the inference on our decision function as a second-order large-margin regularization problem, and provide an efficient algorithm in its dual from. We evaluate our algorithm on both human body verification and face verification problems. Our method outperforms not only the classical metric learning algorithm including LMNN and ITML, but also the state-of-the-art in the computer vision community.</p><p>3 0.99951315 <a title="178-lda-3" href="./cvpr-2013-Revisiting_Depth_Layers_from_Occlusions.html">357 cvpr-2013-Revisiting Depth Layers from Occlusions</a></p>
<p>Author: Adarsh Kowdle, Andrew Gallagher, Tsuhan Chen</p><p>Abstract: In this work, we consider images of a scene with a moving object captured by a static camera. As the object (human or otherwise) moves about the scene, it reveals pairwise depth-ordering or occlusion cues. The goal of this work is to use these sparse occlusion cues along with monocular depth occlusion cues to densely segment the scene into depth layers. We cast the problem of depth-layer segmentation as a discrete labeling problem on a spatiotemporal Markov Random Field (MRF) that uses the motion occlusion cues along with monocular cues and a smooth motion prior for the moving object. We quantitatively show that depth ordering produced by the proposed combination of the depth cues from object motion and monocular occlusion cues are superior to using either feature independently, and using a na¨ ıve combination of the features.</p><p>4 0.99933255 <a title="178-lda-4" href="./cvpr-2013-Fully-Connected_CRFs_with_Non-Parametric_Pairwise_Potential.html">180 cvpr-2013-Fully-Connected CRFs with Non-Parametric Pairwise Potential</a></p>
<p>Author: Neill D.F. Campbell, Kartic Subr, Jan Kautz</p><p>Abstract: Conditional Random Fields (CRFs) are used for diverse tasks, ranging from image denoising to object recognition. For images, they are commonly defined as a graph with nodes corresponding to individual pixels and pairwise links that connect nodes to their immediate neighbors. Recent work has shown that fully-connected CRFs, where each node is connected to every other node, can be solved efficiently under the restriction that the pairwise term is a Gaussian kernel over a Euclidean feature space. In this paper, we generalize the pairwise terms to a non-linear dissimilarity measure that is not required to be a distance metric. To this end, we propose a density estimation technique to derive conditional pairwise potentials in a nonparametric manner. We then use an efficient embedding technique to estimate an approximate Euclidean feature space for these potentials, in which the pairwise term can still be expressed as a Gaussian kernel. We demonstrate that the use of non-parametric models for the pairwise interactions, conditioned on the input data, greatly increases expressive power whilst maintaining efficient inference.</p><p>5 0.99918151 <a title="178-lda-5" href="./cvpr-2013-Background_Modeling_Based_on_Bidirectional_Analysis.html">55 cvpr-2013-Background Modeling Based on Bidirectional Analysis</a></p>
<p>Author: Atsushi Shimada, Hajime Nagahara, Rin-ichiro Taniguchi</p><p>Abstract: Background modeling and subtraction is an essential task in video surveillance applications. Most traditional studies use information observed in past frames to create and update a background model. To adapt to background changes, the backgroundmodel has been enhancedby introducing various forms of information including spatial consistency and temporal tendency. In this paper, we propose a new framework that leverages information from a future period. Our proposed approach realizes a low-cost and highly accurate background model. The proposed framework is called bidirectional background modeling, and performs background subtraction based on bidirectional analysis; i.e., analysis from past to present and analysis from future to present. Although a result will be output with some delay because information is takenfrom a futureperiod, our proposed approach improves the accuracy by about 30% if only a 33-millisecond of delay is acceptable. Furthermore, the memory cost can be reduced by about 65% relative to typical background modeling.</p><p>6 0.9991709 <a title="178-lda-6" href="./cvpr-2013-Learning_and_Calibrating_Per-Location_Classifiers_for_Visual_Place_Recognition.html">260 cvpr-2013-Learning and Calibrating Per-Location Classifiers for Visual Place Recognition</a></p>
<p>7 0.99912202 <a title="178-lda-7" href="./cvpr-2013-Constraints_as_Features.html">93 cvpr-2013-Constraints as Features</a></p>
<p>8 0.9988035 <a title="178-lda-8" href="./cvpr-2013-Real-Time_No-Reference_Image_Quality_Assessment_Based_on_Filter_Learning.html">346 cvpr-2013-Real-Time No-Reference Image Quality Assessment Based on Filter Learning</a></p>
<p>9 0.9985646 <a title="178-lda-9" href="./cvpr-2013-Dynamic_Scene_Classification%3A_Learning_Motion_Descriptors_with_Slow_Features_Analysis.html">137 cvpr-2013-Dynamic Scene Classification: Learning Motion Descriptors with Slow Features Analysis</a></p>
<p>10 0.99706554 <a title="178-lda-10" href="./cvpr-2013-Better_Exploiting_Motion_for_Better_Action_Recognition.html">59 cvpr-2013-Better Exploiting Motion for Better Action Recognition</a></p>
<p>11 0.99697036 <a title="178-lda-11" href="./cvpr-2013-Fast_Energy_Minimization_Using_Learned_State_Filters.html">165 cvpr-2013-Fast Energy Minimization Using Learned State Filters</a></p>
<p>12 0.99693245 <a title="178-lda-12" href="./cvpr-2013-Dense_Variational_Reconstruction_of_Non-rigid_Surfaces_from_Monocular_Video.html">113 cvpr-2013-Dense Variational Reconstruction of Non-rigid Surfaces from Monocular Video</a></p>
<p>13 0.99421024 <a title="178-lda-13" href="./cvpr-2013-Attribute-Based_Detection_of_Unfamiliar_Classes_with_Humans_in_the_Loop.html">48 cvpr-2013-Attribute-Based Detection of Unfamiliar Classes with Humans in the Loop</a></p>
<p>14 0.99352968 <a title="178-lda-14" href="./cvpr-2013-Multi-target_Tracking_by_Rank-1_Tensor_Approximation.html">301 cvpr-2013-Multi-target Tracking by Rank-1 Tensor Approximation</a></p>
<p>15 0.98722082 <a title="178-lda-15" href="./cvpr-2013-Graph-Based_Discriminative_Learning_for_Location_Recognition.html">189 cvpr-2013-Graph-Based Discriminative Learning for Location Recognition</a></p>
<p>16 0.98684919 <a title="178-lda-16" href="./cvpr-2013-Learning_without_Human_Scores_for_Blind_Image_Quality_Assessment.html">266 cvpr-2013-Learning without Human Scores for Blind Image Quality Assessment</a></p>
<p>17 0.98680776 <a title="178-lda-17" href="./cvpr-2013-Scalable_Sparse_Subspace_Clustering.html">379 cvpr-2013-Scalable Sparse Subspace Clustering</a></p>
<p>18 0.98449302 <a title="178-lda-18" href="./cvpr-2013-Query_Adaptive_Similarity_for_Large_Scale_Object_Retrieval.html">343 cvpr-2013-Query Adaptive Similarity for Large Scale Object Retrieval</a></p>
<p>19 0.9841013 <a title="178-lda-19" href="./cvpr-2013-Ensemble_Video_Object_Cut_in_Highly_Dynamic_Scenes.html">148 cvpr-2013-Ensemble Video Object Cut in Highly Dynamic Scenes</a></p>
<p>20 0.98400855 <a title="178-lda-20" href="./cvpr-2013-Non-rigid_Structure_from_Motion_with_Diffusion_Maps_Prior.html">306 cvpr-2013-Non-rigid Structure from Motion with Diffusion Maps Prior</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
