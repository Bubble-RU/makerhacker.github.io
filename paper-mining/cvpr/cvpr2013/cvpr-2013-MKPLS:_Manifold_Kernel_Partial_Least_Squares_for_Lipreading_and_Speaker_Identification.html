<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>276 cvpr-2013-MKPLS: Manifold Kernel Partial Least Squares for Lipreading and Speaker Identification</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-276" href="#">cvpr2013-276</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>276 cvpr-2013-MKPLS: Manifold Kernel Partial Least Squares for Lipreading and Speaker Identification</h1>
<br/><p>Source: <a title="cvpr-2013-276-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Bakry_MKPLS_Manifold_Kernel_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Amr Bakry, Ahmed Elgammal</p><p>Abstract: Visual speech recognition is a challenging problem, due to confusion between visual speech features. The speaker identification problem is usually coupled with speech recognition. Moreover, speaker identification is important to several applications, such as automatic access control, biometrics, authentication, and personal privacy issues. In this paper, we propose a novel approach for lipreading and speaker identification. Wepropose a new approachfor manifold parameterization in a low-dimensional latent space, where each manifold is represented as a point in that space. We initially parameterize each instance manifold using a nonlinear mapping from a unified manifold representation. We then factorize the parameter space using Kernel Partial Least Squares (KPLS) to achieve a low-dimension manifold latent space. We use two-way projections to achieve two manifold latent spaces, one for the speech content and one for the speaker. We apply our approach on two public databases: AVLetters and OuluVS. We show the results for three different settings of lipreading: speaker independent, speaker dependent, and speaker semi-dependent. Our approach outperforms for the speaker semi-dependent setting by at least 15% of the baseline, and competes in the other two settings.</p><p>Reference: <a title="cvpr-2013-276-reference" href="../cvpr2013_reference/cvpr-2013-MKPLS%3A_Manifold_Kernel_Partial_Least_Squares_for_Lipreading_and_Speaker_Identification_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract Visual speech recognition is a challenging problem, due to confusion between visual speech features. [sent-3, score-0.806]
</p><p>2 The speaker identification problem is usually coupled with speech recognition. [sent-4, score-0.974]
</p><p>3 Moreover, speaker identification is important to several applications, such as automatic access control, biometrics, authentication, and personal privacy issues. [sent-5, score-0.625]
</p><p>4 In this paper, we propose a novel approach for lipreading and speaker identification. [sent-6, score-0.728]
</p><p>5 Wepropose a new approachfor manifold parameterization in a low-dimensional latent space, where each manifold is represented as a point in that space. [sent-7, score-0.872]
</p><p>6 We initially parameterize each instance manifold using a nonlinear mapping from a unified manifold representation. [sent-8, score-0.705]
</p><p>7 We then factorize the parameter space using Kernel Partial Least Squares (KPLS) to achieve a low-dimension manifold latent space. [sent-9, score-0.42]
</p><p>8 We use two-way projections to achieve two manifold latent spaces, one for the speech content and one for the speaker. [sent-10, score-0.745]
</p><p>9 We show the results for three different settings of lipreading: speaker independent,  speaker dependent, and speaker semi-dependent. [sent-12, score-1.626]
</p><p>10 Our approach outperforms for the speaker semi-dependent setting by at least 15% of the baseline, and competes in the other two settings. [sent-13, score-0.593]
</p><p>11 Introduction Audio visual speech recognition (AVSR) has been investigated intensively in the last few decades [19]. [sent-15, score-0.415]
</p><p>12 Specially after bimodal fusion of audio and visual stimuli in perceiving speech has been demonstrated by the McGurk effect [15]. [sent-16, score-0.44]
</p><p>13 In the last two decades, with the advances in computer vision, visual speech recognition (VSR), also called lipreading, have attracted research attention [25]. [sent-19, score-0.415]
</p><p>14 from motor and radio) makes it very hard for audio speech recognition. [sent-23, score-0.417]
</p><p>15 Nevertheless, visual speech recognition is a challenging problem, due to confusion between visemes 1. [sent-25, score-0.468]
</p><p>16 Several approaches have been adopted for solving the lipreading problem. [sent-27, score-0.186]
</p><p>17 Speaker identification and authentication are tightly coupled with speech recognition [13, 23, 25]. [sent-34, score-0.494]
</p><p>18 Speaker identification is defined as the ability to identify the speaker within a group of users from solely speech related features, like voice or mouth motion. [sent-35, score-1.02]
</p><p>19 Meanwhile, speaker authentication is the ability to authenticate users. [sent-36, score-0.584]
</p><p>20 In this paper, we present a new approach for embedding of manifolds in a low-dimensional latent space. [sent-39, score-0.258]
</p><p>21 It is defined native unit for visual speech 6 6 6 8 8 8 42 242  as  the smallest discrimi-  tially parameterize each manifold using a nonlinear mapping from a unified manifold representation, similar to [5]. [sent-41, score-1.076]
</p><p>22 However, unlike [5], where factorization ofthe manifold parameterization is achieve using unsupervised subspace projection, we factorize the parameterization space in a supervised way. [sent-42, score-0.772]
</p><p>23 We propose to use kernel partial least square (KPLS) on the mapping coefficient space to achieve a supervised low-dimensional latent space for manifold parameterization. [sent-43, score-0.566]
</p><p>24 We use two-way projections to achieve two manifold latent spaces, one for the speech content and one for the speaker. [sent-44, score-0.745]
</p><p>25 The resulting low-dimensional parameterization can be considered as a global spatio-temporal descriptor for each speech sequence, which can be effectively used for speech recognition and speaker identification. [sent-45, score-1.532]
</p><p>26 From learning point of view, we propose a new way to learn a low-dimensional supervised parameterization of manifolds where each manifold is represented as a point in a latent space. [sent-47, score-0.716]
</p><p>27 From the visual-speech point of view, we propose a new approach for projecting visual speech features into dual latent spaces that are capable of discriminating speech and speaker. [sent-48, score-0.892]
</p><p>28 In this work, we use cosine similarity as a kernel on the parameterization space. [sent-49, score-0.324]
</p><p>29 Moreover, we use two different techniques for classifying new speech clip: one of them is SVM, we learn multi-class SVM based on the projected manifolds. [sent-50, score-0.372]
</p><p>30 The other one uses KPLS regression for classi-  fication on the latent space. [sent-51, score-0.142]
</p><p>31 We tackle three different lipreading problems: speaker independent, speaker dependent, and speaker semi-dependent. [sent-53, score-1.812]
</p><p>32 In both databases, our approach outperforms for speaker semi-dependent setting by at least 15% over the baseline [27], and competes in the other two settings. [sent-54, score-0.593]
</p><p>33 The problem statement will be defined clearly and the manifold parameterization will be described in Section 3. [sent-56, score-0.499]
</p><p>34 Thereafter, the proposed framework will be presented in details in two sections: first the manifold parameterization is described in Section 5, and the manifold embedding using KPLS is presented in Section 6. [sent-58, score-0.813]
</p><p>35 Related Work Encoding the dynamics of speech video as a descriptor has a long history within lipreading research. [sent-63, score-0.58]
</p><p>36 In [14], HMM was used for encoding the visual dynamics of speech using Active Shape Model (ASM) and Active Appearance Model (AAM). [sent-65, score-0.417]
</p><p>37 These methods try to capture the smooth temporal changes between the used visual units, but they may loose some visual information that may be crucial for discriminating small speech chunks like single letter utterance. [sent-68, score-0.46]
</p><p>38 On the other hand, the work in [27] is based on extracting a single spatio-temporal feature vector for representing the visual and temporal information for the whole speech video. [sent-69, score-0.395]
</p><p>39 In our method, we care about smoothness, since we extract the geometric deformation of the lip-moving manifold and at the same time use all the appearance information for learning a parameterization for this manifold. [sent-72, score-0.499]
</p><p>40 As the best of our knowledge, we are the first to use homeomorphic manifold analysis and KPLS in the field of visual speech recognition. [sent-74, score-0.71]
</p><p>41 In this paper, for the particular case of speech recognition and speaker identification, yk ∈ {c1, · · · , cK} {p1, · · · pL}. [sent-79, score-0.983]
</p><p>42 The basic assumption is that all these manifolds are topologically equivalent, however each of them has different geometry in RD. [sent-84, score-0.153]
</p><p>43 For instance, sequence of features representing a Viseme, starting from a neutral pose and reaching a peak pose, lies on a one-dimensional manifold (curve) in the feature space. [sent-88, score-0.293]
</p><p>44 The goal is to achieve a low-dimensional latent space of instance manifolds. [sent-89, score-0.149]
</p><p>45 In that space each manifold is represented by a single point. [sent-90, score-0.298]
</p><p>46 We learn two classification functions fspeech (S) and fspeaker (S) based on two latent spaces for speech and speaker respectively. [sent-92, score-1.039]
</p><p>47 The first step in our framework is to parameterize these manifolds to obtain a descriptor for each of them. [sent-93, score-0.146]
</p><p>48 The manifold parameterization we use is based on [5, 11]. [sent-94, score-0.499]
</p><p>49 We learn a regularized mapping function from a unified (average) lowdimensional embedded representation of all manifolds to each input manifolds. [sent-95, score-0.236]
</p><p>50 Therefore, the space of coefficients of these mapping functions provides a parameterization of the input manifold. [sent-97, score-0.284]
</p><p>51 The obtained parameterization is high-dimensional, which makes it hard to learn classification functions that can generalize well. [sent-98, score-0.226]
</p><p>52 In [5] subspace analysis was used to obtain a latent representation of the manifold parameterization space. [sent-99, score-0.599]
</p><p>53 Alternatively, we propose a supervised way to achieve a low-dimensional latent manifold parameterization space, which benefits from the class labels. [sent-101, score-0.599]
</p><p>54 Given the instance manifold parameterization, we propose two alternative manifold kernels based on the parameterization space. [sent-102, score-0.796]
</p><p>55 Given a manifold kernel, we use KPLS in the parameterization space to obtain a latent low-dimensional manifold parameterization space. [sent-103, score-1.123]
</p><p>56 We apply KPLS independently for the speech and speaker factors. [sent-104, score-0.914]
</p><p>57 It worth mentioning that the unified manifold representation is supposed to be topological equivalent to each instance manifold. [sent-105, score-0.345]
</p><p>58 In contrast, the unified manifold representation is a collapsing of all instance manifolds to one average manifold. [sent-108, score-0.462]
</p><p>59 In [5] individual manifolds are embedded and warped to compute an average embedding. [sent-110, score-0.155]
</p><p>60 Alternatively, if the topology of the manifold is known, a conceptual representation can be imposed; for example a unit circle can be used as topologically equivalent representation of all closed one-dimensional manifolds [11]. [sent-111, score-0.454]
</p><p>61 The most common techniques for projection to a latent spaces are PCA and LDA [4]. [sent-118, score-0.164]
</p><p>62 PLS compromises by creating orthogonal components (in the latent space) using the existing correlations between explanatory variables (in the input space) and corresponding labeling, while keeping most of the vari-  ance of the points in the input space. [sent-122, score-0.145]
</p><p>63 m-dim latent space Ramdomly in diotialize ui repeat ti ← Kui ti ←← ? [sent-175, score-0.145]
</p><p>64 mapping functions admit a representation in the form of a linear combination of kernel basis functions in the embedding space Re. [sent-209, score-0.154]
</p><p>65 To achieve a common parameterization space of all the manifold, we use the same set of basis functions K(·, wi) , i = 1· · · n, where wi ∈ Re. [sent-210, score-0.251]
</p><p>66 Manifold Kernels Given the manifold parameterization described above, a kernel in the space of manifolds can be defined as a kernel between their parameterizations, i. [sent-224, score-0.751]
</p><p>67 (5)  Therefore, we need to define kernels over the space of parameterizations, which consequently, measure the similarity between manifolds in terms of their geometric deformation from the common manifold representation. [sent-228, score-0.435]
</p><p>68 Cosine-manifold kernel: Since each parameterization point Ck represents ndimensional subspace in RD. [sent-230, score-0.226]
</p><p>69 Therefore, we can use cosine the angle between the two subspaces as a similarity in parameterization space. [sent-231, score-0.269]
</p><p>70 Then, the matrix T, of all embedded points, can be written as T = KR (9) For a new manifold Mν, represented by its parameterizatFioonr C a νn awnd m laanbieflo yν M(unknown), the corresponding embedded point can be given by tν = vνR. [sent-261, score-0.349]
</p><p>71 ) (Eq 6) is an N-dimensional row vector representing the similarity with all training manifold parameterizations {Ck, k = 1· · · N}. [sent-263, score-0.365]
</p><p>72 Multifactor Embedding As aforementioned, we have set of labeled manifold parameterizations {(Ck , yk) ; k = 1· · · N}. [sent-266, score-0.345]
</p><p>73 In this paper, we have two simultaneous tasks: speech recognition and speaker identification. [sent-270, score-0.934]
</p><p>74 AVletters: Similarity among points in the manifold parameterization original space (a), and after projection into the letters’ latent space (b). [sent-275, score-0.688]
</p><p>75 For any new manifold Mν, Cν is compute (Eq 4), then get toher corresponding elmd bMedded point by Eq 10, as tνh = vνRh. [sent-276, score-0.273]
</p><p>76 For speaker identification, we have different labeling ykp, k = 1· · · N. [sent-277, score-0.542]
</p><p>77 rFno rth new omjeacntiifoonld m Matrνix, we compute the parameterization C Foνr, ntehewn get itfhoel corresponding embedded point by tνp = vνRp. [sent-280, score-0.264]
</p><p>78 Figure 1 shows the affect of projecting into the letters’ latent space in the AVLetters database (see Section 7. [sent-281, score-0.147]
</p><p>79 ×  In Figure 1(a) , the similarity between speaker dominates the similarity between letters. [sent-283, score-0.604]
</p><p>80 We find that the most adequate databases are AVLetters [14] and OuluVs [27] for speech recognition and speaker identification. [sent-304, score-0.995]
</p><p>81 Each speaker repeats every English letter (A · · · Z) exactly three times, rwepithea a to evtaelr yof E 7n8g0l svhid eleott sequences. [sent-307, score-0.584]
</p><p>82 T exhea speaker was requested to start and end utterance of every letter in a neutral state (mouth closed). [sent-308, score-0.604]
</p><p>83 Visual speech recognition We adopt three test protocols for visual speech recognition: speaker independent, speaker dependent and speaker semi-dependent. [sent-335, score-2.433]
</p><p>84 Table 1 and Table 2 show the SI speech recognition accuracy for OuluVs and AVLetters, respectively. [sent-345, score-0.392]
</p><p>85 We can see that for solving speaker independent problem, we need a low-dimensional latent space (about 15 for OuluVs and 25 for AVLetters). [sent-346, score-0.667]
</p><p>86 Speaker recognition: The goal in this experiment is to find the speaker within the register set of users. [sent-395, score-0.542]
</p><p>87 The challenge is to find the speaker from the limited available information in the mouth area. [sent-396, score-0.588]
</p><p>88 Moreover, we want to prove that although the manifold  parameterization encodes mainly the geometric deformation from the unified manifold to the original data manifold, parameterization also hold speaker-related information. [sent-397, score-1.046]
</p><p>89 That was expected for two reasons: first, we have limited number of speaker (10 in AVLetters and 16 in OuluVs). [sent-400, score-0.542]
</p><p>90 Conclusion We proposed a framework that utilized the homeomorphic manifold analysis and KPLS for manifold classification. [sent-403, score-0.588]
</p><p>91 We tackled two related classification problems speaker identification and speech recognition. [sent-404, score-0.974]
</p><p>92 We use supervised latent low-dimensional space embedding for solving the simultaneous multi-factor classification problem. [sent-405, score-0.166]
</p><p>93 We presented three different configurations of lipreading speaker independent, speaker semi-dependent and speaker dependent. [sent-406, score-1.812]
</p><p>94 An optimization perspective on kernel partial least squares regression. [sent-419, score-0.156]
</p><p>95 A segment-  [9]  [10]  [11]  [12]  [13]  [14] [15] [16]  [17]  based audio-visual speech recognizer: Data collection, development, and initial experiments. [sent-455, score-0.372]
</p><p>96 Homeomorphic manifold analysis: Learning decomposable generative models for human motion analysis. [sent-474, score-0.273]
</p><p>97 Moving-talker, speakerindependent feature study, and baseline results using the CUAVE multimodal speech corpus. [sent-505, score-0.372]
</p><p>98 A tutorial on hidden Markov models and selected applications in speech recognition. [sent-521, score-0.372]
</p><p>99 Kernel partial least squares regression in reproducing kernel hilbert space. [sent-526, score-0.198]
</p><p>100 Visual speech recognition: lip segmentation and mapping, pages 1–38, 2009. [sent-550, score-0.397]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('speaker', 0.542), ('speech', 0.372), ('manifold', 0.273), ('kpls', 0.239), ('avletters', 0.236), ('parameterization', 0.226), ('ouluvs', 0.219), ('lipreading', 0.186), ('vsr', 0.135), ('pls', 0.119), ('manifolds', 0.117), ('ssd', 0.108), ('latent', 0.1), ('parameterizations', 0.072), ('avsr', 0.067), ('nipals', 0.067), ('ck', 0.065), ('spoken', 0.062), ('databases', 0.061), ('eq', 0.06), ('speakers', 0.06), ('identification', 0.06), ('kernel', 0.055), ('uttered', 0.051), ('yk', 0.049), ('unified', 0.048), ('mouth', 0.046), ('squares', 0.046), ('audio', 0.045), ('explanatory', 0.045), ('regression', 0.042), ('nk', 0.042), ('letter', 0.042), ('cov', 0.042), ('homeomorphic', 0.042), ('authentication', 0.042), ('embedding', 0.041), ('projection', 0.039), ('hmm', 0.039), ('embedded', 0.038), ('topologically', 0.036), ('elgammal', 0.036), ('si', 0.035), ('avicar', 0.034), ('chemometric', 0.034), ('deflation', 0.034), ('kcos', 0.034), ('mcgurk', 0.034), ('ramdomly', 0.034), ('titi', 0.034), ('vetor', 0.034), ('visemes', 0.034), ('yw', 0.033), ('ku', 0.033), ('mapping', 0.033), ('partial', 0.032), ('phrase', 0.032), ('rosipal', 0.03), ('ihfe', 0.03), ('rutgers', 0.03), ('parameterize', 0.029), ('conference', 0.029), ('closed', 0.028), ('specially', 0.028), ('competes', 0.028), ('letters', 0.027), ('clip', 0.026), ('synopsis', 0.026), ('clips', 0.026), ('spaces', 0.025), ('nonlinear', 0.025), ('lip', 0.025), ('space', 0.025), ('sd', 0.025), ('compete', 0.024), ('instance', 0.024), ('ak', 0.023), ('visual', 0.023), ('least', 0.023), ('cosine', 0.023), ('privacy', 0.023), ('international', 0.023), ('dynamics', 0.022), ('database', 0.022), ('factorize', 0.022), ('dominates', 0.022), ('xx', 0.021), ('biometrics', 0.021), ('sound', 0.021), ('xik', 0.021), ('ui', 0.02), ('recognition', 0.02), ('neutral', 0.02), ('similarity', 0.02), ('saenko', 0.02), ('dependent', 0.02), ('xw', 0.02), ('confusion', 0.019), ('pca', 0.019), ('dat', 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000008 <a title="276-tfidf-1" href="./cvpr-2013-MKPLS%3A_Manifold_Kernel_Partial_Least_Squares_for_Lipreading_and_Speaker_Identification.html">276 cvpr-2013-MKPLS: Manifold Kernel Partial Least Squares for Lipreading and Speaker Identification</a></p>
<p>Author: Amr Bakry, Ahmed Elgammal</p><p>Abstract: Visual speech recognition is a challenging problem, due to confusion between visual speech features. The speaker identification problem is usually coupled with speech recognition. Moreover, speaker identification is important to several applications, such as automatic access control, biometrics, authentication, and personal privacy issues. In this paper, we propose a novel approach for lipreading and speaker identification. Wepropose a new approachfor manifold parameterization in a low-dimensional latent space, where each manifold is represented as a point in that space. We initially parameterize each instance manifold using a nonlinear mapping from a unified manifold representation. We then factorize the parameter space using Kernel Partial Least Squares (KPLS) to achieve a low-dimension manifold latent space. We use two-way projections to achieve two manifold latent spaces, one for the speech content and one for the speaker. We apply our approach on two public databases: AVLetters and OuluVS. We show the results for three different settings of lipreading: speaker independent, speaker dependent, and speaker semi-dependent. Our approach outperforms for the speaker semi-dependent setting by at least 15% of the baseline, and competes in the other two settings.</p><p>2 0.18351945 <a title="276-tfidf-2" href="./cvpr-2013-Kernel_Learning_for_Extrinsic_Classification_of_Manifold_Features.html">237 cvpr-2013-Kernel Learning for Extrinsic Classification of Manifold Features</a></p>
<p>Author: Raviteja Vemulapalli, Jaishanker K. Pillai, Rama Chellappa</p><p>Abstract: In computer vision applications, features often lie on Riemannian manifolds with known geometry. Popular learning algorithms such as discriminant analysis, partial least squares, support vector machines, etc., are not directly applicable to such features due to the non-Euclidean nature of the underlying spaces. Hence, classification is often performed in an extrinsic manner by mapping the manifolds to Euclidean spaces using kernels. However, for kernel based approaches, poor choice of kernel often results in reduced performance. In this paper, we address the issue of kernelselection for the classification of features that lie on Riemannian manifolds using the kernel learning approach. We propose two criteria for jointly learning the kernel and the classifier using a single optimization problem. Specifically, for the SVM classifier, we formulate the problem of learning a good kernel-classifier combination as a convex optimization problem and solve it efficiently following the multiple kernel learning approach. Experimental results on image set-based classification and activity recognition clearly demonstrate the superiority of the proposed approach over existing methods for classification of manifold features.</p><p>3 0.14728212 <a title="276-tfidf-3" href="./cvpr-2013-Expressive_Visual_Text-to-Speech_Using_Active_Appearance_Models.html">159 cvpr-2013-Expressive Visual Text-to-Speech Using Active Appearance Models</a></p>
<p>Author: Robert Anderson, Björn Stenger, Vincent Wan, Roberto Cipolla</p><p>Abstract: This paper presents a complete system for expressive visual text-to-speech (VTTS), which is capable of producing expressive output, in the form of a ‘talking head’, given an input text and a set of continuous expression weights. The face is modeled using an active appearance model (AAM), and several extensions are proposed which make it more applicable to the task of VTTS. The model allows for normalization with respect to both pose and blink state which significantly reduces artifacts in the resulting synthesized sequences. We demonstrate quantitative improvements in terms of reconstruction error over a million frames, as well as in large-scale user studies, comparing the output of different systems.</p><p>4 0.14384413 <a title="276-tfidf-4" href="./cvpr-2013-Sparse_Subspace_Denoising_for_Image_Manifolds.html">405 cvpr-2013-Sparse Subspace Denoising for Image Manifolds</a></p>
<p>Author: Bo Wang, Zhuowen Tu</p><p>Abstract: With the increasing availability of high dimensional data and demand in sophisticated data analysis algorithms, manifold learning becomes a critical technique to perform dimensionality reduction, unraveling the intrinsic data structure. The real-world data however often come with noises and outliers; seldom, all the data live in a single linear subspace. Inspired by the recent advances in sparse subspace learning and diffusion-based approaches, we propose a new manifold denoising algorithm in which data neighborhoods are adaptively inferred via sparse subspace reconstruction; we then derive a new formulation to perform denoising to the original data. Experiments carried out on both toy and real applications demonstrate the effectiveness of our method; it is insensitive to parameter tuning and we show significant improvement over the competing algorithms.</p><p>5 0.1268708 <a title="276-tfidf-5" href="./cvpr-2013-Non-rigid_Structure_from_Motion_with_Diffusion_Maps_Prior.html">306 cvpr-2013-Non-rigid Structure from Motion with Diffusion Maps Prior</a></p>
<p>Author: Lili Tao, Bogdan J. Matuszewski</p><p>Abstract: In this paper, a novel approach based on a non-linear manifold learning technique is proposed to recover 3D nonrigid structures from 2D image sequences captured by a single camera. Most ofthe existing approaches assume that 3D shapes can be accurately modelled in a linear subspace. These techniques perform well when the deformations are relatively small or simple, but fail when more complex deformations need to be recovered. The non-linear deformations are often observed in highly flexible objects for which the use of the linear model is impractical. A specific type of shape variations might be governed by only a small number of parameters, therefore can be wellrepresented in a low dimensional manifold. We learn a nonlinear shape prior using diffusion maps method. The key contribution in this paper is the introduction of the shape prior that constrain the reconstructed shapes to lie in the learned manifold. The proposed methodology has been validated quantitatively and qualitatively on 2D points sequences projected from the 3D motion capture data and real 2D video sequences. The comparisons oftheproposed man- ifold based method against several state-of-the-art techniques are shown on different types of deformable objects.</p><p>6 0.12441368 <a title="276-tfidf-6" href="./cvpr-2013-Rolling_Riemannian_Manifolds_to_Solve_the_Multi-class_Classification_Problem.html">367 cvpr-2013-Rolling Riemannian Manifolds to Solve the Multi-class Classification Problem</a></p>
<p>7 0.12408019 <a title="276-tfidf-7" href="./cvpr-2013-Learning_a_Manifold_as_an_Atlas.html">259 cvpr-2013-Learning a Manifold as an Atlas</a></p>
<p>8 0.11323981 <a title="276-tfidf-8" href="./cvpr-2013-Top-Down_Segmentation_of_Non-rigid_Visual_Objects_Using_Derivative-Based_Search_on_Sparse_Manifolds.html">433 cvpr-2013-Top-Down Segmentation of Non-rigid Visual Objects Using Derivative-Based Search on Sparse Manifolds</a></p>
<p>9 0.10331795 <a title="276-tfidf-9" href="./cvpr-2013-Semi-supervised_Learning_with_Constraints_for_Person_Identification_in_Multimedia_Data.html">389 cvpr-2013-Semi-supervised Learning with Constraints for Person Identification in Multimedia Data</a></p>
<p>10 0.094742507 <a title="276-tfidf-10" href="./cvpr-2013-From_Local_Similarity_to_Global_Coding%3A_An_Application_to_Image_Classification.html">178 cvpr-2013-From Local Similarity to Global Coding: An Application to Image Classification</a></p>
<p>11 0.094076402 <a title="276-tfidf-11" href="./cvpr-2013-Kernel_Methods_on_the_Riemannian_Manifold_of_Symmetric_Positive_Definite_Matrices.html">238 cvpr-2013-Kernel Methods on the Riemannian Manifold of Symmetric Positive Definite Matrices</a></p>
<p>12 0.079607032 <a title="276-tfidf-12" href="./cvpr-2013-Harry_Potter%27s_Marauder%27s_Map%3A_Localizing_and_Tracking_Multiple_Persons-of-Interest_by_Nonnegative_Discretization.html">199 cvpr-2013-Harry Potter's Marauder's Map: Localizing and Tracking Multiple Persons-of-Interest by Nonnegative Discretization</a></p>
<p>13 0.077426538 <a title="276-tfidf-13" href="./cvpr-2013-Inductive_Hashing_on_Manifolds.html">223 cvpr-2013-Inductive Hashing on Manifolds</a></p>
<p>14 0.073520988 <a title="276-tfidf-14" href="./cvpr-2013-Improved_Image_Set_Classification_via_Joint_Sparse_Approximated_Nearest_Subspaces.html">215 cvpr-2013-Improved Image Set Classification via Joint Sparse Approximated Nearest Subspaces</a></p>
<p>15 0.06848833 <a title="276-tfidf-15" href="./cvpr-2013-Joint_Sparsity-Based_Representation_and_Analysis_of_Unconstrained_Activities.html">233 cvpr-2013-Joint Sparsity-Based Representation and Analysis of Unconstrained Activities</a></p>
<p>16 0.061970357 <a title="276-tfidf-16" href="./cvpr-2013-3D_Visual_Proxemics%3A_Recognizing_Human_Interactions_in_3D_from_a_Single_Image.html">4 cvpr-2013-3D Visual Proxemics: Recognizing Human Interactions in 3D from a Single Image</a></p>
<p>17 0.058991373 <a title="276-tfidf-17" href="./cvpr-2013-Watching_Unlabeled_Video_Helps_Learn_New_Human_Actions_from_Very_Few_Labeled_Snapshots.html">459 cvpr-2013-Watching Unlabeled Video Helps Learn New Human Actions from Very Few Labeled Snapshots</a></p>
<p>18 0.056904901 <a title="276-tfidf-18" href="./cvpr-2013-Learning_Cross-Domain_Information_Transfer_for_Location_Recognition_and_Clustering.html">250 cvpr-2013-Learning Cross-Domain Information Transfer for Location Recognition and Clustering</a></p>
<p>19 0.053144373 <a title="276-tfidf-19" href="./cvpr-2013-Consensus_of_k-NNs_for_Robust_Neighborhood_Selection_on_Graph-Based_Manifolds.html">91 cvpr-2013-Consensus of k-NNs for Robust Neighborhood Selection on Graph-Based Manifolds</a></p>
<p>20 0.052697007 <a title="276-tfidf-20" href="./cvpr-2013-Blessing_of_Dimensionality%3A_High-Dimensional_Feature_and_Its_Efficient_Compression_for_Face_Verification.html">64 cvpr-2013-Blessing of Dimensionality: High-Dimensional Feature and Its Efficient Compression for Face Verification</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.127), (1, -0.009), (2, -0.047), (3, 0.016), (4, 0.009), (5, 0.007), (6, -0.031), (7, -0.112), (8, -0.003), (9, -0.065), (10, 0.03), (11, -0.002), (12, -0.093), (13, -0.084), (14, -0.051), (15, 0.03), (16, -0.099), (17, 0.017), (18, -0.125), (19, -0.018), (20, 0.023), (21, 0.077), (22, 0.08), (23, 0.018), (24, -0.056), (25, 0.014), (26, -0.001), (27, 0.083), (28, -0.007), (29, -0.005), (30, -0.033), (31, -0.097), (32, -0.032), (33, 0.059), (34, -0.009), (35, -0.009), (36, 0.049), (37, 0.049), (38, 0.022), (39, -0.018), (40, 0.032), (41, -0.026), (42, -0.059), (43, 0.007), (44, -0.025), (45, 0.027), (46, -0.006), (47, -0.049), (48, 0.061), (49, 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94282746 <a title="276-lsi-1" href="./cvpr-2013-MKPLS%3A_Manifold_Kernel_Partial_Least_Squares_for_Lipreading_and_Speaker_Identification.html">276 cvpr-2013-MKPLS: Manifold Kernel Partial Least Squares for Lipreading and Speaker Identification</a></p>
<p>Author: Amr Bakry, Ahmed Elgammal</p><p>Abstract: Visual speech recognition is a challenging problem, due to confusion between visual speech features. The speaker identification problem is usually coupled with speech recognition. Moreover, speaker identification is important to several applications, such as automatic access control, biometrics, authentication, and personal privacy issues. In this paper, we propose a novel approach for lipreading and speaker identification. Wepropose a new approachfor manifold parameterization in a low-dimensional latent space, where each manifold is represented as a point in that space. We initially parameterize each instance manifold using a nonlinear mapping from a unified manifold representation. We then factorize the parameter space using Kernel Partial Least Squares (KPLS) to achieve a low-dimension manifold latent space. We use two-way projections to achieve two manifold latent spaces, one for the speech content and one for the speaker. We apply our approach on two public databases: AVLetters and OuluVS. We show the results for three different settings of lipreading: speaker independent, speaker dependent, and speaker semi-dependent. Our approach outperforms for the speaker semi-dependent setting by at least 15% of the baseline, and competes in the other two settings.</p><p>2 0.92079419 <a title="276-lsi-2" href="./cvpr-2013-Rolling_Riemannian_Manifolds_to_Solve_the_Multi-class_Classification_Problem.html">367 cvpr-2013-Rolling Riemannian Manifolds to Solve the Multi-class Classification Problem</a></p>
<p>Author: Rui Caseiro, Pedro Martins, João F. Henriques, Fátima Silva Leite, Jorge Batista</p><p>Abstract: In the past few years there has been a growing interest on geometric frameworks to learn supervised classification models on Riemannian manifolds [31, 27]. A popular framework, valid over any Riemannian manifold, was proposed in [31] for binary classification. Once moving from binary to multi-class classification thisparadigm is not valid anymore, due to the spread of multiple positive classes on the manifold [27]. It is then natural to ask whether the multi-class paradigm could be extended to operate on a large class of Riemannian manifolds. We propose a mathematically well-founded classification paradigm that allows to extend the work in [31] to multi-class models, taking into account the structure of the space. The idea is to project all the data from the manifold onto an affine tangent space at a particular point. To mitigate the distortion induced by local diffeomorphisms, we introduce for the first time in the computer vision community a well-founded mathematical concept, so-called Rolling map [21, 16]. The novelty in this alternate school of thought is that the manifold will be firstly rolled (without slipping or twisting) as a rigid body, then the given data is unwrapped onto the affine tangent space, where the classification is performed.</p><p>3 0.8617664 <a title="276-lsi-3" href="./cvpr-2013-Learning_a_Manifold_as_an_Atlas.html">259 cvpr-2013-Learning a Manifold as an Atlas</a></p>
<p>Author: Nikolaos Pitelis, Chris Russell, Lourdes Agapito</p><p>Abstract: In this work, we return to the underlying mathematical definition of a manifold and directly characterise learning a manifold as finding an atlas, or a set of overlapping charts, that accurately describe local structure. We formulate the problem of learning the manifold as an optimisation that simultaneously refines the continuous parameters defining the charts, and the discrete assignment of points to charts. In contrast to existing methods, this direct formulation of a manifold does not require “unwrapping ” the manifold into a lower dimensional space and allows us to learn closed manifolds of interest to vision, such as those corresponding to gait cycles or camera pose. We report state-ofthe-art results for manifold based nearest neighbour classification on vision datasets, and show how the same techniques can be applied to the 3D reconstruction of human motion from a single image.</p><p>4 0.8530786 <a title="276-lsi-4" href="./cvpr-2013-Kernel_Learning_for_Extrinsic_Classification_of_Manifold_Features.html">237 cvpr-2013-Kernel Learning for Extrinsic Classification of Manifold Features</a></p>
<p>Author: Raviteja Vemulapalli, Jaishanker K. Pillai, Rama Chellappa</p><p>Abstract: In computer vision applications, features often lie on Riemannian manifolds with known geometry. Popular learning algorithms such as discriminant analysis, partial least squares, support vector machines, etc., are not directly applicable to such features due to the non-Euclidean nature of the underlying spaces. Hence, classification is often performed in an extrinsic manner by mapping the manifolds to Euclidean spaces using kernels. However, for kernel based approaches, poor choice of kernel often results in reduced performance. In this paper, we address the issue of kernelselection for the classification of features that lie on Riemannian manifolds using the kernel learning approach. We propose two criteria for jointly learning the kernel and the classifier using a single optimization problem. Specifically, for the SVM classifier, we formulate the problem of learning a good kernel-classifier combination as a convex optimization problem and solve it efficiently following the multiple kernel learning approach. Experimental results on image set-based classification and activity recognition clearly demonstrate the superiority of the proposed approach over existing methods for classification of manifold features.</p><p>5 0.84588075 <a title="276-lsi-5" href="./cvpr-2013-Kernel_Methods_on_the_Riemannian_Manifold_of_Symmetric_Positive_Definite_Matrices.html">238 cvpr-2013-Kernel Methods on the Riemannian Manifold of Symmetric Positive Definite Matrices</a></p>
<p>Author: Sadeep Jayasumana, Richard Hartley, Mathieu Salzmann, Hongdong Li, Mehrtash Harandi</p><p>Abstract: Symmetric Positive Definite (SPD) matrices have become popular to encode image information. Accounting for the geometry of the Riemannian manifold of SPD matrices has proven key to the success of many algorithms. However, most existing methods only approximate the true shape of the manifold locally by its tangent plane. In this paper, inspired by kernel methods, we propose to map SPD matrices to a high dimensional Hilbert space where Euclidean geometry applies. To encode the geometry of the manifold in the mapping, we introduce a family of provably positive definite kernels on the Riemannian manifold of SPD matrices. These kernels are derived from the Gaussian kernel, but exploit different metrics on the manifold. This lets us extend kernel-based algorithms developed for Euclidean spaces, such as SVM and kernel PCA, to the Riemannian manifold of SPD matrices. We demonstrate the benefits of our approach on the problems of pedestrian detection, object categorization, texture analysis, 2D motion segmentation and Diffusion Tensor Imaging (DTI) segmentation.</p><p>6 0.66797906 <a title="276-lsi-6" href="./cvpr-2013-Top-Down_Segmentation_of_Non-rigid_Visual_Objects_Using_Derivative-Based_Search_on_Sparse_Manifolds.html">433 cvpr-2013-Top-Down Segmentation of Non-rigid Visual Objects Using Derivative-Based Search on Sparse Manifolds</a></p>
<p>7 0.59803265 <a title="276-lsi-7" href="./cvpr-2013-Sparse_Subspace_Denoising_for_Image_Manifolds.html">405 cvpr-2013-Sparse Subspace Denoising for Image Manifolds</a></p>
<p>8 0.57321042 <a title="276-lsi-8" href="./cvpr-2013-Non-rigid_Structure_from_Motion_with_Diffusion_Maps_Prior.html">306 cvpr-2013-Non-rigid Structure from Motion with Diffusion Maps Prior</a></p>
<p>9 0.53513235 <a title="276-lsi-9" href="./cvpr-2013-Improved_Image_Set_Classification_via_Joint_Sparse_Approximated_Nearest_Subspaces.html">215 cvpr-2013-Improved Image Set Classification via Joint Sparse Approximated Nearest Subspaces</a></p>
<p>10 0.53483129 <a title="276-lsi-10" href="./cvpr-2013-On_a_Link_Between_Kernel_Mean_Maps_and_Fraunhofer_Diffraction%2C_with_an_Application_to_Super-Resolution_Beyond_the_Diffraction_Limit.html">312 cvpr-2013-On a Link Between Kernel Mean Maps and Fraunhofer Diffraction, with an Application to Super-Resolution Beyond the Diffraction Limit</a></p>
<p>11 0.5144968 <a title="276-lsi-11" href="./cvpr-2013-From_Local_Similarity_to_Global_Coding%3A_An_Application_to_Image_Classification.html">178 cvpr-2013-From Local Similarity to Global Coding: An Application to Image Classification</a></p>
<p>12 0.50321865 <a title="276-lsi-12" href="./cvpr-2013-Graph-Laplacian_PCA%3A_Closed-Form_Solution_and_Robustness.html">191 cvpr-2013-Graph-Laplacian PCA: Closed-Form Solution and Robustness</a></p>
<p>13 0.47520462 <a title="276-lsi-13" href="./cvpr-2013-Local_Fisher_Discriminant_Analysis_for_Pedestrian_Re-identification.html">270 cvpr-2013-Local Fisher Discriminant Analysis for Pedestrian Re-identification</a></p>
<p>14 0.4570747 <a title="276-lsi-14" href="./cvpr-2013-Kernel_Null_Space_Methods_for_Novelty_Detection.html">239 cvpr-2013-Kernel Null Space Methods for Novelty Detection</a></p>
<p>15 0.45551825 <a title="276-lsi-15" href="./cvpr-2013-Inductive_Hashing_on_Manifolds.html">223 cvpr-2013-Inductive Hashing on Manifolds</a></p>
<p>16 0.43438789 <a title="276-lsi-16" href="./cvpr-2013-Harry_Potter%27s_Marauder%27s_Map%3A_Localizing_and_Tracking_Multiple_Persons-of-Interest_by_Nonnegative_Discretization.html">199 cvpr-2013-Harry Potter's Marauder's Map: Localizing and Tracking Multiple Persons-of-Interest by Nonnegative Discretization</a></p>
<p>17 0.43096304 <a title="276-lsi-17" href="./cvpr-2013-Learning_Cross-Domain_Information_Transfer_for_Location_Recognition_and_Clustering.html">250 cvpr-2013-Learning Cross-Domain Information Transfer for Location Recognition and Clustering</a></p>
<p>18 0.43051243 <a title="276-lsi-18" href="./cvpr-2013-Discriminative_Brain_Effective_Connectivity_Analysis_for_Alzheimer%27s_Disease%3A_A_Kernel_Learning_Approach_upon_Sparse_Gaussian_Bayesian_Network.html">129 cvpr-2013-Discriminative Brain Effective Connectivity Analysis for Alzheimer's Disease: A Kernel Learning Approach upon Sparse Gaussian Bayesian Network</a></p>
<p>19 0.4252364 <a title="276-lsi-19" href="./cvpr-2013-Computing_Diffeomorphic_Paths_for_Large_Motion_Interpolation.html">90 cvpr-2013-Computing Diffeomorphic Paths for Large Motion Interpolation</a></p>
<p>20 0.41781673 <a title="276-lsi-20" href="./cvpr-2013-The_SVM-Minus_Similarity_Score_for_Video_Face_Recognition.html">430 cvpr-2013-The SVM-Minus Similarity Score for Video Face Recognition</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.106), (16, 0.027), (26, 0.053), (33, 0.224), (59, 0.324), (67, 0.058), (69, 0.038), (87, 0.047)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.83057851 <a title="276-lda-1" href="./cvpr-2013-A_Genetic_Algorithm-Based_Solver_for_Very_Large_Jigsaw_Puzzles.html">11 cvpr-2013-A Genetic Algorithm-Based Solver for Very Large Jigsaw Puzzles</a></p>
<p>Author: Dror Sholomon, Omid David, Nathan S. Netanyahu</p><p>Abstract: In thispaper wepropose thefirst effective automated, genetic algorithm (GA)-based jigsaw puzzle solver. We introduce a novel procedure of merging two ”parent” solutions to an improved ”child” solution by detecting, extracting, and combining correctly assembled puzzle segments. The solver proposed exhibits state-of-the-art performance solving previously attempted puzzles faster and far more accurately, and also puzzles of size never before attempted. Other contributions include the creation of a benchmark of large images, previously unavailable. We share the data sets and all of our results for future testing and comparative evaluation of jigsaw puzzle solvers.</p><p>same-paper 2 0.75503165 <a title="276-lda-2" href="./cvpr-2013-MKPLS%3A_Manifold_Kernel_Partial_Least_Squares_for_Lipreading_and_Speaker_Identification.html">276 cvpr-2013-MKPLS: Manifold Kernel Partial Least Squares for Lipreading and Speaker Identification</a></p>
<p>Author: Amr Bakry, Ahmed Elgammal</p><p>Abstract: Visual speech recognition is a challenging problem, due to confusion between visual speech features. The speaker identification problem is usually coupled with speech recognition. Moreover, speaker identification is important to several applications, such as automatic access control, biometrics, authentication, and personal privacy issues. In this paper, we propose a novel approach for lipreading and speaker identification. Wepropose a new approachfor manifold parameterization in a low-dimensional latent space, where each manifold is represented as a point in that space. We initially parameterize each instance manifold using a nonlinear mapping from a unified manifold representation. We then factorize the parameter space using Kernel Partial Least Squares (KPLS) to achieve a low-dimension manifold latent space. We use two-way projections to achieve two manifold latent spaces, one for the speech content and one for the speaker. We apply our approach on two public databases: AVLetters and OuluVS. We show the results for three different settings of lipreading: speaker independent, speaker dependent, and speaker semi-dependent. Our approach outperforms for the speaker semi-dependent setting by at least 15% of the baseline, and competes in the other two settings.</p><p>3 0.73175114 <a title="276-lda-3" href="./cvpr-2013-Optical_Flow_Estimation_Using_Laplacian_Mesh_Energy.html">316 cvpr-2013-Optical Flow Estimation Using Laplacian Mesh Energy</a></p>
<p>Author: Wenbin Li, Darren Cosker, Matthew Brown, Rui Tang</p><p>Abstract: In this paper we present a novel non-rigid optical flow algorithm for dense image correspondence and non-rigid registration. The algorithm uses a unique Laplacian Mesh Energy term to encourage local smoothness whilst simultaneously preserving non-rigid deformation. Laplacian deformation approaches have become popular in graphics research as they enable mesh deformations to preserve local surface shape. In this work we propose a novel Laplacian Mesh Energy formula to ensure such sensible local deformations between image pairs. We express this wholly within the optical flow optimization, and show its application in a novel coarse-to-fine pyramidal approach. Our algorithm achieves the state-of-the-art performance in all trials on the Garg et al. dataset, and top tier performance on the Middlebury evaluation.</p><p>4 0.72393811 <a title="276-lda-4" href="./cvpr-2013-Dense_Segmentation-Aware_Descriptors.html">112 cvpr-2013-Dense Segmentation-Aware Descriptors</a></p>
<p>Author: Eduard Trulls, Iasonas Kokkinos, Alberto Sanfeliu, Francesc Moreno-Noguer</p><p>Abstract: In this work we exploit segmentation to construct appearance descriptors that can robustly deal with occlusion and background changes. For this, we downplay measurements coming from areas that are unlikely to belong to the same region as the descriptor’s center, as suggested by soft segmentation masks. Our treatment is applicable to any image point, i.e. dense, and its computational overhead is in the order of a few seconds. We integrate this idea with Dense SIFT, and also with Dense Scale and Rotation Invariant Descriptors (SID), delivering descriptors that are densely computable, invariant to scaling and rotation, and robust to background changes. We apply our approach to standard benchmarks on large displacement motion estimation using SIFT-flow and widebaseline stereo, systematically demonstrating that the introduction of segmentation yields clear improvements.</p><p>5 0.71179599 <a title="276-lda-5" href="./cvpr-2013-Multi-scale_Curve_Detection_on_Surfaces.html">298 cvpr-2013-Multi-scale Curve Detection on Surfaces</a></p>
<p>Author: Michael Kolomenkin, Ilan Shimshoni, Ayellet Tal</p><p>Abstract: This paper extends to surfaces the multi-scale approach of edge detection on images. The common practice for detecting curves on surfaces requires the user to first select the scale of the features, apply an appropriate smoothing, and detect the edges on the smoothed surface. This approach suffers from two drawbacks. First, it relies on a hidden assumption that all the features on the surface are of the same scale. Second, manual user intervention is required. In this paper, we propose a general framework for automatically detecting the optimal scale for each point on the surface. We smooth the surface at each point according to this optimal scale and run the curve detection algorithm on the resulting surface. Our multi-scale algorithm solves the two disadvantages of the single-scale approach mentioned above. We demonstrate how to realize our approach on two commonly-used special cases: ridges & valleys and relief edges. In each case, the optimal scale is found in accordance with the mathematical definition of the curve.</p><p>6 0.68144333 <a title="276-lda-6" href="./cvpr-2013-Visual_Place_Recognition_with_Repetitive_Structures.html">456 cvpr-2013-Visual Place Recognition with Repetitive Structures</a></p>
<p>7 0.67678493 <a title="276-lda-7" href="./cvpr-2013-Constrained_Clustering_and_Its_Application_to_Face_Clustering_in_Videos.html">92 cvpr-2013-Constrained Clustering and Its Application to Face Clustering in Videos</a></p>
<p>8 0.63651937 <a title="276-lda-8" href="./cvpr-2013-Axially_Symmetric_3D_Pots_Configuration_System_Using_Axis_of_Symmetry_and_Break_Curve.html">52 cvpr-2013-Axially Symmetric 3D Pots Configuration System Using Axis of Symmetry and Break Curve</a></p>
<p>9 0.63517725 <a title="276-lda-9" href="./cvpr-2013-Multi-resolution_Shape_Analysis_via_Non-Euclidean_Wavelets%3A_Applications_to_Mesh_Segmentation_and_Surface_Alignment_Problems.html">297 cvpr-2013-Multi-resolution Shape Analysis via Non-Euclidean Wavelets: Applications to Mesh Segmentation and Surface Alignment Problems</a></p>
<p>10 0.63096207 <a title="276-lda-10" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<p>11 0.63084263 <a title="276-lda-11" href="./cvpr-2013-Mesh_Based_Semantic_Modelling_for_Indoor_and_Outdoor_Scenes.html">284 cvpr-2013-Mesh Based Semantic Modelling for Indoor and Outdoor Scenes</a></p>
<p>12 0.6307537 <a title="276-lda-12" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>13 0.62981451 <a title="276-lda-13" href="./cvpr-2013-Structure_Preserving_Object_Tracking.html">414 cvpr-2013-Structure Preserving Object Tracking</a></p>
<p>14 0.62960351 <a title="276-lda-14" href="./cvpr-2013-Part_Discovery_from_Partial_Correspondence.html">325 cvpr-2013-Part Discovery from Partial Correspondence</a></p>
<p>15 0.62812793 <a title="276-lda-15" href="./cvpr-2013-Integrating_Grammar_and_Segmentation_for_Human_Pose_Estimation.html">225 cvpr-2013-Integrating Grammar and Segmentation for Human Pose Estimation</a></p>
<p>16 0.62799913 <a title="276-lda-16" href="./cvpr-2013-Occlusion_Patterns_for_Object_Class_Detection.html">311 cvpr-2013-Occlusion Patterns for Object Class Detection</a></p>
<p>17 0.62776923 <a title="276-lda-17" href="./cvpr-2013-Understanding_Indoor_Scenes_Using_3D_Geometric_Phrases.html">446 cvpr-2013-Understanding Indoor Scenes Using 3D Geometric Phrases</a></p>
<p>18 0.62710482 <a title="276-lda-18" href="./cvpr-2013-Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking.html">285 cvpr-2013-Minimum Uncertainty Gap for Robust Visual Tracking</a></p>
<p>19 0.62709439 <a title="276-lda-19" href="./cvpr-2013-Spatiotemporal_Deformable_Part_Models_for_Action_Detection.html">408 cvpr-2013-Spatiotemporal Deformable Part Models for Action Detection</a></p>
<p>20 0.62606055 <a title="276-lda-20" href="./cvpr-2013-Incorporating_Structural_Alternatives_and_Sharing_into_Hierarchy_for_Multiclass_Object_Recognition_and_Detection.html">221 cvpr-2013-Incorporating Structural Alternatives and Sharing into Hierarchy for Multiclass Object Recognition and Detection</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
