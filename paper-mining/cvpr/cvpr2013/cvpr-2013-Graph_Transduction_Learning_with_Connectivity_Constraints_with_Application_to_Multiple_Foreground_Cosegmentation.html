<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>193 cvpr-2013-Graph Transduction Learning with Connectivity Constraints with Application to Multiple Foreground Cosegmentation</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-193" href="#">cvpr2013-193</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>193 cvpr-2013-Graph Transduction Learning with Connectivity Constraints with Application to Multiple Foreground Cosegmentation</h1>
<br/><p>Source: <a title="cvpr-2013-193-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Ma_Graph_Transduction_Learning_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Tianyang Ma, Longin Jan Latecki</p><p>Abstract: The proposed approach is based on standard graph transduction, semi-supervised learning (SSL) framework. Its key novelty is the integration of global connectivity constraints into this framework. Although connectivity leads to higher order constraints and their number is an exponential, finding the most violated connectivity constraint can be done efficiently in polynomial time. Moreover, each such constraint can be represented as a linear inequality. Based on this fact, we design a cutting-plane algorithm to solve the integrated problem. It iterates between solving a convex quadraticproblem of labelpropagation with linear inequality constraints, and finding the most violated constraint. We demonstrate the benefits of the proposed approach on a realistic and very challenging problem of cosegmentation of multiple foreground objects in photo collections in which the foreground objects are not present in all photos. The obtained results not only demonstrate performance boost induced by the connectivity constraints, but also show a significant improvement over the state-of-the-art methods.</p><p>Reference: <a title="cvpr-2013-193-reference" href="../cvpr2013_reference/cvpr-2013-Graph_Transduction_Learning_with_Connectivity_Constraints_with_Application_to_Multiple_Foreground_Cosegmentation_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Its key novelty is the integration of global connectivity constraints into this framework. [sent-4, score-0.374]
</p><p>2 Although connectivity leads to higher order constraints and their number is an exponential, finding the most violated connectivity constraint can be done efficiently in polynomial time. [sent-5, score-0.798]
</p><p>3 It iterates between solving a convex quadraticproblem of labelpropagation with linear inequality constraints, and finding the most violated constraint. [sent-8, score-0.232]
</p><p>4 We demonstrate the benefits of the proposed approach on a realistic and very challenging problem of cosegmentation of multiple foreground objects in photo collections in which the foreground objects are not present in all photos. [sent-9, score-0.469]
</p><p>5 The obtained results not only demonstrate performance boost  induced by the connectivity constraints, but also show a significant improvement over the state-of-the-art methods. [sent-10, score-0.294]
</p><p>6 Introduction Given multiple images sharing overlapping contents, the goal of image cosegmentation is to simultaneously divide these images into non-overlapping regions of foreground and background. [sent-12, score-0.297]
</p><p>7 In an interactive or supervised setting [1], some foreground objects are explicitly assigned by an user as the regions of interest. [sent-14, score-0.225]
</p><p>8 Kim and Xing [12] has recently proposed a multiple foreground cosegmentation (MFC) task, in which K different foreground objects need to be jointly segmented from a group of M input images. [sent-15, score-0.395]
</p><p>9 Second Columns: the results of an excellent graph transduction SSL method RLGC [24]. [sent-42, score-0.5]
</p><p>10 Compared to RLGC, GTC improves the consistency of label assignment by enforcing connectivity of regions with the same label. [sent-44, score-0.454]
</p><p>11 This task contrasts the classical cosegmentation problem dealt with by most existing algorithms [7, 1, 15, 10, 13, 21, 22], where a much simpler and less realistic setting is usually assumed by requiring that the same set of objects occurs in every image. [sent-47, score-0.262]
</p><p>12 While this assumption provides a relatively strong  prior which has been utilized by most of cosegmentation algorithms, it severely limits the application scope of these cosegmentation algorithms, since it is not valid for most real photo collections. [sent-48, score-0.398]
</p><p>13 111999555533  In the supervised setting, it is straight forward that foreground model can be built through objects labeled by users in the training images. [sent-53, score-0.21]
</p><p>14 In the unsupervised setting, foreground model can be initialized by running unsupervised cosegmentation method [13, 9]. [sent-54, score-0.32]
</p><p>15 In particular, we formulate this problem as graph transduction SSL, which has demonstrated impressive results on many tasks, especially when there exists only a small amount of labeled data samples. [sent-61, score-0.547]
</p><p>16 Compared to supervised methods, its main advantage relies on using both labeled and unlabeled data during the training process, which yields considerable improvement in labeling accuracy, e. [sent-62, score-0.157]
</p><p>17 However, the label propagation accuracy in graph transduction SSL highly depends on how reliable the similarity of graph nodes is. [sent-65, score-0.771]
</p><p>18 In particular, due to large appearance variations of the same objects in different images, segments belonging to different objects may accidently have higher similarity than segments belonging to the same object. [sent-67, score-0.434]
</p><p>19 To address this problem, we propose to constrain graph transduction SSL framework by integrating global connectivity constraints. [sent-68, score-0.794]
</p><p>20 In other words, we enforce that segments assigned the same label form connected regions in each image. [sent-69, score-0.335]
</p><p>21 As in [12], for a given set of images containing common  objects, we first perform over-segmentation to obtain several segments for each image separately. [sent-71, score-0.169]
</p><p>22 Although using BoW enjoys some robustness to the object variations, such as changes in shape and orientation, it also makes the similarity between segments not very discriminative, which in turn significantly degrades the labeling results of SSL methods. [sent-73, score-0.169]
</p><p>23 We can see that many disconnected regions are wrongly assigned the same labels because of their similar color and texture, for example, the face of baby and apple basket. [sent-78, score-0.145]
</p><p>24 This happens because in standard graph transduction SSL framework, each segment is taken out-ofcontext and labeled independently. [sent-79, score-0.571]
</p><p>25 In particular, while the segment graph encodes the visual similarity between pairs of segments, the spatial information between segments in the same image is totally neglected. [sent-81, score-0.302]
</p><p>26 This information is expressed as connectivity in the proposed framework. [sent-82, score-0.294]
</p><p>27 In our graph-based formulation, if nodes representing segments from the same image share the same class label, they must form a connected subgraph [11]. [sent-83, score-0.34]
</p><p>28 As shown  in [14], although it is an exponential problem (with respect to the number of nodes) to examine if two nodes are connected, finding the most violated connectivity constraint can be done efficiently in polynomial time. [sent-85, score-0.508]
</p><p>29 To solve a SSL problem formulated with connectivity constraints in graph transduction formulation, we design a cutting-plane algorithm, in which we iterate between solving a convex problem of label propagation with linear inequality constraints, and finding the most violated constraint. [sent-87, score-1.232]
</p><p>30 The discretization step is then performed on each unlabeled data point independently, by simply assigning the label with the largest confidence. [sent-92, score-0.159]
</p><p>31 The first version of our method enforce the connectivity constraints at the final discretization step oflabel confidences obtained through SSL learning. [sent-93, score-0.421]
</p><p>32 More importantly, in the second version, we integrate the graph transduction formulation with connectivity constraints, and solve it as a convex quadratic programming with linear inequality constraints. [sent-96, score-0.952]
</p><p>33 We call this method graph transduction with connectivity constraints (GTC). [sent-97, score-0.901]
</p><p>34 In particular, the baby face belongs to the baby not to the basket anymore. [sent-101, score-0.147]
</p><p>35 It even can correct wrong labels as can be seen in the first row, where the basket is wrongly labeled as baby by RLGC, which is corrected by GTC. [sent-102, score-0.196]
</p><p>36 This examples as well as our ex111999555644  perimental results in Section 6 clearly demonstrate that the connectivity information can be used to increase the robustness of SSL methods. [sent-104, score-0.294]
</p><p>37 It significantly outperforms the MFC method in [12] and other state-of-the-art cosegmentation methods. [sent-106, score-0.188]
</p><p>38 In Section 3, we revisit the standard graph transduction SSL framework. [sent-108, score-0.5]
</p><p>39 In Sections 4 and 5, we introduce the proposed integration of connectivity constraints into the graph transduction framework, and derive a method to solve it efficiently. [sent-109, score-0.902]
</p><p>40 Related Work Many approaches have been proposed to solve the image cosegmentation problem [7, 1, 15, 10, 13, 21, 22]. [sent-111, score-0.216]
</p><p>41 All these approaches only consider two class (forground/background) cosegmentation problem. [sent-112, score-0.188]
</p><p>42 The initial model presented in  [15] provides a framework to enforce consistency among two foreground histograms in addition to the Marov Random Field (MRF) segmentation terms for each image. [sent-113, score-0.19]
</p><p>43 Recently, a Random Walker based method is proposed in [4], and is shown to be an effective framework for cosegmentation problem complementary to MRF formulation. [sent-115, score-0.188]
</p><p>44 In our method, the graph is constructed using segments as nodes, and the edges exist between every pair of segments, because the graph is used for the purpose of propagating the labels from labeled segments to unlabeled segments following the graph transduction SSL framework. [sent-119, score-1.365]
</p><p>45 To our best knowledge, this is for the first time that connectivity constraints are considered in the SSL framework. [sent-131, score-0.374]
</p><p>46 2, we will review how to use the graph transduction method to solve a standard semi-supervised learning problem. [sent-135, score-0.547]
</p><p>47 Finally, in Sec 5, we focus on how to impose the connectivity constraints under semi-supervised learning framework and how to solve it efficiently. [sent-136, score-0.421]
</p><p>48 Segment Graph Construction Given a set of images which contain multiple common  objects, we first divide each image Im into segments (or superpixels) Sm = {s1m, . [sent-139, score-0.169]
</p><p>49 We assume that segments in a small number of images are labeled with object categories. [sent-146, score-0.216]
</p><p>50 Our goal is to infer a label for each unlabeled segment. [sent-148, score-0.139]
</p><p>51 For two nodes iand j representing two different segments si and sj, the weight wij is computed using a RBF kernel:  wij= exp−d(x2iσ,2xj)  (1)  where d(xi , xj) computes the X2 distance between xi and xj, and σ is the kernel bandwidth parameter. [sent-152, score-0.31]
</p><p>52 Graph Transduction for SSL We assign the class labels to unlabeled image segments in a standard graph-based semi-supervised learning frame-  work, which we review here. [sent-158, score-0.281]
</p><p>53 The binary label matrix Y ∈ fined as yil = 1if node si has label l ∈ L and yil = 0 otherwise, where C is the number of labels in L. [sent-162, score-0.367]
</p><p>54 l yil ≤ 1for every node imeaning that each node can have? [sent-164, score-0.144]
</p><p>55 Graph-based semi-supervised learning methods propagate label information from labeled nodes to unlabeled nodes [28]. [sent-169, score-0.333]
</p><p>56 One term is used to measure the smoothness of the function on the graph of both labeled and unlabeled data, with the second term used to measure the fitness between F and the label information for the labeled nodes. [sent-172, score-0.342]
</p><p>57 As is usually the case in graph transduction SSL, this is a simple argmax step: for every node idetermine l∗ = arg maxl Fi∗l, and  then set Yi∗l = 1if l = l∗ and Yi∗l = 0 if l  = l∗. [sent-187, score-0.626]
</p><p>58 (a) Original image (b) Segments and adjacent graph (c) A simple adjacency graph. [sent-211, score-0.17]
</p><p>59 Enforcing Connectivity Constraints in SSL Before we give the formal definition of the connectivity constraints, we first introduce a binary adjacency graph G = (V, A) to represent the spatial adjacency of segments, i. [sent-229, score-0.483]
</p><p>60 , A(i, j) = 1if two segments si, sj belong to the same image and are adjacent and A(i, j) = 0 otherwise. [sent-231, score-0.219]
</p><p>61 Of course, the nodes of each connected subgraph must represent segments belonging to the same image. [sent-233, score-0.361]
</p><p>62 It is proved that each facet of Z can be defined by a linear inequality equation. [sent-244, score-0.163]
</p><p>63 The proposed SSL algorithm with connectivity constraints is an iterative cutting-plane method. [sent-249, score-0.374]
</p><p>64 It alternates between solving a convex quadratic programming (QP) with linear inequality constraints (5) according to graph (G, W), and adding a new connectivity constraint (facet) according to graph (G, A). [sent-250, score-0.748]
</p><p>65 We need to examine whether Ft violates the connectivity con-  =  straints. [sent-252, score-0.314]
</p><p>66 In order to do this, we need to define the connectivity constraints as linear constraints. [sent-253, score-0.374]
</p><p>67 Since our goal is to enforce connectivity of image segments belonging to the same object, i. [sent-254, score-0.511]
</p><p>68 , having the same label, for a pair of segments si and sj we only check the connectivity constraints if they are in the same image and have the same label l. [sent-256, score-0.67]
</p><p>69 , A(i, j) = 0, and the probability for both segments have label l ∈ L is positive, i. [sent-259, score-0.244]
</p><p>70 We call H a check condition set, since only for triples in H the connectivity condition needs to be checked. [sent-262, score-0.35]
</p><p>71 As proved in [14], each facet of the polytope containing Z is defined by the following linear inequality for a label l ∈ L and for all pairs (i, j) such that (i, j,l) ∈ H: Fitl + Fjtl  −? [sent-263, score-0.282]
</p><p>72 k∈S  For a triple (i, j,l) ∈ H, proving that no violated inequality exists or finding the most violated inequality in (6), which is given by  S∗(i,j,l) = argS∈mSa(ix,j) ? [sent-265, score-0.372]
</p><p>73 We call the proposed method graph transduction with connectivity constraints (GTC), since it integrates RLGC graph transduction formulation and global connectivity constraints. [sent-279, score-1.716]
</p><p>74 4: find the most violated constraints S∗ (i∗ ,j∗ , l∗) using Eq (8) 5: if Eq (9) holds for S∗ (i∗ ,j∗ , l∗) then 6: break 7: end if 8: derive linear equality constraint M from S∗(i∗, j∗, l∗) 9: Ct+1 ← Ct ∪ M 10: until |Ft − Ft−1 | <  σ  In Fig. [sent-283, score-0.21]
</p><p>75 3, we visualize some examples of the most violated connectivity constraints discovered by our algorithm. [sent-284, score-0.477]
</p><p>76 Green dots: pair of segments with the same label that are not connected. [sent-289, score-0.244]
</p><p>77 Adjacency connection between segments is displayed using black lines. [sent-291, score-0.169]
</p><p>78 of segments with the same label that are not connected. [sent-292, score-0.244]
</p><p>79 We do not show the actual segments for better visualization. [sent-294, score-0.169]
</p><p>80 One is to change the label for either of the two green dots so that two segments are no longer with the same label. [sent-298, score-0.296]
</p><p>81 The other one is to change the labels of some of the  separating segments marked in blue dots to the label of the segments with green dots, which makes the two green dots segments connected. [sent-299, score-0.715]
</p><p>82 For any semi-supervised learning method that yields a continuous label confidence matrix F∗, it is only possible to impose the connectivity constraints at the final binarization step of F∗ . [sent-301, score-0.535]
</p><p>83 For this we formulate the binarization step as solving a linear MRF problem with the connectivity constraints:  Y∗  =  N  C  Ya∈r[g0,1m]Na×xCi? [sent-302, score-0.381]
</p><p>84 2, which is a standard binarization procedure for graph transduction SSL algorithms. [sent-314, score-0.567]
</p><p>85 To summarize, RLGC solves the problem under a standard SSL framework, where only affinity graph (G, W) is utilized, and the connectivity between nodes is not considered. [sent-316, score-0.493]
</p><p>86 In GTCP, the constraints are considered, but only at the final binarization step of label confidences. [sent-317, score-0.222]
</p><p>87 For GTC, we integrate connectivity with RLGC in an iterative framework. [sent-318, score-0.294]
</p><p>88 By utilizing the additional information from adjacent graph (G, A), GTC can improve the label propagation process by increasing its robustness to the unstable affinity measurement in (G, W). [sent-319, score-0.254]
</p><p>89 Time Complexity: For the proposed GTC algorithm, in each iteration, solving convex QP with inequality constraints is very efficient. [sent-321, score-0.209]
</p><p>90 The main computation comes from finding the most violated connectivity constraints. [sent-322, score-0.397]
</p><p>91 In our method, K is usually a very small number (we follow [12], and obtain K = 18 segments using [13]). [sent-325, score-0.19]
</p><p>92 We follow the protocol of the interactive multiple foreground cosegmentation in [12], in which for each image group, 20% of images are randomly selected as training images, and the objects label in those images are provided. [sent-332, score-0.401]
</p><p>93 MFC-S [12] and our method can be viewed as typical SSL methods, since both require a small number of labeled data (labeled foreground objects in training images). [sent-379, score-0.164]
</p><p>94 As can be seen in Table 1, the performance of RLGC [24], which belongs to classic graph transduction SSL methods, is comparable to MFC-S. [sent-385, score-0.5]
</p><p>95 This demonstrates the effectiveness of solving MFC problem in SSL framework, and in particular, the benefits of utilizing unlabeled data in addition to labeled data for label inference. [sent-386, score-0.206]
</p><p>96 Our postprocessing method GTCP applied directly to the label confidence scores of RLGC is able to significantly increase the segmentation accuracy, which demonstrates the benefits of the global connectivity constraints. [sent-387, score-0.463]
</p><p>97 Moreover, the fact that GTC outperforms our postprocessing method GTCP by over 7% shows the importance of enforcing the global connectivity constraints directly in the graph transduction SSL framework. [sent-390, score-0.94]
</p><p>98 Conclusion In this work, we integrate the global connectivity constraints with graph transduction learning framework to address a very challenging task: multiple foreground cosegmentation. [sent-406, score-0.983]
</p><p>99 Connectivity constraints are naturally motivated by human visual perception in that we prefer to identify objects as connected image regions. [sent-407, score-0.152]
</p><p>100 They play a similar role in our approach by enforcing consistent class label assignment to connected image regions, which significantly improves the segmentation results. [sent-408, score-0.217]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ssl', 0.548), ('transduction', 0.391), ('connectivity', 0.294), ('rlgc', 0.266), ('gtc', 0.253), ('cosegmentation', 0.188), ('gtcp', 0.171), ('segments', 0.169), ('graph', 0.109), ('violated', 0.103), ('flickrmfc', 0.095), ('foreground', 0.09), ('mfc', 0.088), ('conn', 0.084), ('inequality', 0.083), ('constraints', 0.08), ('label', 0.075), ('ryt', 0.068), ('binarization', 0.067), ('nodes', 0.064), ('unlabeled', 0.064), ('yil', 0.062), ('subgraph', 0.062), ('fitl', 0.057), ('fjtl', 0.057), ('ftkl', 0.057), ('temple', 0.056), ('facet', 0.056), ('dots', 0.052), ('segmentation', 0.052), ('basket', 0.051), ('baby', 0.048), ('labeled', 0.047), ('supervised', 0.046), ('connected', 0.045), ('ft', 0.045), ('polytope', 0.044), ('postprocessing', 0.042), ('node', 0.041), ('adjacency', 0.04), ('qp', 0.038), ('flickermfc', 0.038), ('idetermine', 0.038), ('essential', 0.036), ('wij', 0.034), ('ftlf', 0.034), ('vicente', 0.033), ('gigantic', 0.031), ('jebara', 0.031), ('colorsift', 0.029), ('zeisl', 0.029), ('triples', 0.029), ('labels', 0.029), ('sj', 0.029), ('sec', 0.029), ('solve', 0.028), ('apple', 0.028), ('latecki', 0.028), ('maxl', 0.027), ('enforce', 0.027), ('constraint', 0.027), ('objects', 0.027), ('call', 0.027), ('affinity', 0.026), ('convex', 0.026), ('empty', 0.025), ('eq', 0.025), ('realistic', 0.025), ('segment', 0.024), ('proved', 0.024), ('enforcing', 0.024), ('si', 0.023), ('propagation', 0.023), ('subgraphs', 0.022), ('mkl', 0.022), ('joulin', 0.022), ('photo', 0.022), ('setting', 0.022), ('rn', 0.021), ('follow', 0.021), ('hashing', 0.021), ('adjacent', 0.021), ('assignment', 0.021), ('groups', 0.021), ('wrongly', 0.021), ('belonging', 0.021), ('user', 0.021), ('formulation', 0.021), ('unsupervised', 0.021), ('consistency', 0.021), ('iand', 0.02), ('mrf', 0.02), ('convexity', 0.02), ('examine', 0.02), ('solving', 0.02), ('argmax', 0.02), ('discretization', 0.02), ('submodular', 0.019), ('learning', 0.019), ('regions', 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="193-tfidf-1" href="./cvpr-2013-Graph_Transduction_Learning_with_Connectivity_Constraints_with_Application_to_Multiple_Foreground_Cosegmentation.html">193 cvpr-2013-Graph Transduction Learning with Connectivity Constraints with Application to Multiple Foreground Cosegmentation</a></p>
<p>Author: Tianyang Ma, Longin Jan Latecki</p><p>Abstract: The proposed approach is based on standard graph transduction, semi-supervised learning (SSL) framework. Its key novelty is the integration of global connectivity constraints into this framework. Although connectivity leads to higher order constraints and their number is an exponential, finding the most violated connectivity constraint can be done efficiently in polynomial time. Moreover, each such constraint can be represented as a linear inequality. Based on this fact, we design a cutting-plane algorithm to solve the integrated problem. It iterates between solving a convex quadraticproblem of labelpropagation with linear inequality constraints, and finding the most violated constraint. We demonstrate the benefits of the proposed approach on a realistic and very challenging problem of cosegmentation of multiple foreground objects in photo collections in which the foreground objects are not present in all photos. The obtained results not only demonstrate performance boost induced by the connectivity constraints, but also show a significant improvement over the state-of-the-art methods.</p><p>2 0.13452217 <a title="193-tfidf-2" href="./cvpr-2013-Adding_Unlabeled_Samples_to_Categories_by_Learned_Attributes.html">36 cvpr-2013-Adding Unlabeled Samples to Categories by Learned Attributes</a></p>
<p>Author: Jonghyun Choi, Mohammad Rastegari, Ali Farhadi, Larry S. Davis</p><p>Abstract: We propose a method to expand the visual coverage of training sets that consist of a small number of labeled examples using learned attributes. Our optimization formulation discovers category specific attributes as well as the images that have high confidence in terms of the attributes. In addition, we propose a method to stably capture example-specific attributes for a small sized training set. Our method adds images to a category from a large unlabeled image pool, and leads to significant improvement in category recognition accuracy evaluated on a large-scale dataset, ImageNet.</p><p>3 0.11521758 <a title="193-tfidf-3" href="./cvpr-2013-Jointly_Aligning_and_Segmenting_Multiple_Web_Photo_Streams_for_the_Inference_of_Collective_Photo_Storylines.html">235 cvpr-2013-Jointly Aligning and Segmenting Multiple Web Photo Streams for the Inference of Collective Photo Storylines</a></p>
<p>Author: Gunhee Kim, Eric P. Xing</p><p>Abstract: With an explosion of popularity of online photo sharing, we can trivially collect a huge number of photo streams for any interesting topics such as scuba diving as an outdoor recreational activity class. Obviously, the retrieved photo streams are neither aligned nor calibrated since they are taken in different temporal, spatial, and personal perspectives. However, at the same time, they are likely to share common storylines that consist of sequences of events and activities frequently recurred within the topic. In this paper, as a first technical step to detect such collective storylines, we propose an approach to jointly aligning and segmenting uncalibrated multiple photo streams. The alignment task discovers the matched images between different photo streams, and the image segmentation task parses each image into multiple meaningful regions to facilitate the image understanding. We close a loop between the two tasks so that solving one task helps enhance the performance of the other in a mutually rewarding way. To this end, we design a scalable message-passing based optimization framework to jointly achieve both tasks for the whole input image set at once. With evaluation on the new Flickr dataset of 15 outdoor activities that consist of 1.5 millions of images of 13 thousands of photo streams, our empirical results show that the proposed algorithms are more successful than other candidate methods for both tasks.</p><p>4 0.11360408 <a title="193-tfidf-4" href="./cvpr-2013-Unsupervised_Joint_Object_Discovery_and_Segmentation_in_Internet_Images.html">450 cvpr-2013-Unsupervised Joint Object Discovery and Segmentation in Internet Images</a></p>
<p>Author: Michael Rubinstein, Armand Joulin, Johannes Kopf, Ce Liu</p><p>Abstract: We present a new unsupervised algorithm to discover and segment out common objects from large and diverse image collections. In contrast to previous co-segmentation methods, our algorithm performs well even in the presence of significant amounts of noise images (images not containing a common object), as typical for datasets collected from Internet search. The key insight to our algorithm is that common object patterns should be salient within each image, while being sparse with respect to smooth transformations across images. We propose to use dense correspondences between images to capture the sparsity and visual variability of the common object over the entire database, which enables us to ignore noise objects that may be salient within their own images but do not commonly occur in others. We performed extensive numerical evaluation on es- tablished co-segmentation datasets, as well as several new datasets generated using Internet search. Our approach is able to effectively segment out the common object for diverse object categories, while naturally identifying images where the common object is not present.</p><p>5 0.097953975 <a title="193-tfidf-5" href="./cvpr-2013-Semi-supervised_Node_Splitting_for_Random_Forest_Construction.html">390 cvpr-2013-Semi-supervised Node Splitting for Random Forest Construction</a></p>
<p>Author: Xiao Liu, Mingli Song, Dacheng Tao, Zicheng Liu, Luming Zhang, Chun Chen, Jiajun Bu</p><p>Abstract: Node splitting is an important issue in Random Forest but robust splitting requires a large number of training samples. Existing solutions fail to properly partition the feature space if there are insufficient training data. In this paper, we present semi-supervised splitting to overcome this limitation by splitting nodes with the guidance of both labeled and unlabeled data. In particular, we derive a nonparametric algorithm to obtain an accurate quality measure of splitting by incorporating abundant unlabeled data. To avoid the curse of dimensionality, we project the data points from the original high-dimensional feature space onto a low-dimensional subspace before estimation. A unified optimization framework is proposed to select a coupled pair of subspace and separating hyperplane such that the smoothness of the subspace and the quality of the splitting are guaranteed simultaneously. The proposed algorithm is compared with state-of-the-art supervised and semi-supervised algorithms for typical computer vision applications such as object categorization and image segmen- tation. Experimental results on publicly available datasets demonstrate the superiority of our method.</p><p>6 0.08571174 <a title="193-tfidf-6" href="./cvpr-2013-Geometric_Context_from_Videos.html">187 cvpr-2013-Geometric Context from Videos</a></p>
<p>7 0.082186855 <a title="193-tfidf-7" href="./cvpr-2013-Discriminative_Brain_Effective_Connectivity_Analysis_for_Alzheimer%27s_Disease%3A_A_Kernel_Learning_Approach_upon_Sparse_Gaussian_Bayesian_Network.html">129 cvpr-2013-Discriminative Brain Effective Connectivity Analysis for Alzheimer's Disease: A Kernel Learning Approach upon Sparse Gaussian Bayesian Network</a></p>
<p>8 0.076444842 <a title="193-tfidf-8" href="./cvpr-2013-Category_Modeling_from_Just_a_Single_Labeling%3A_Use_Depth_Information_to_Guide_the_Learning_of_2D_Models.html">80 cvpr-2013-Category Modeling from Just a Single Labeling: Use Depth Information to Guide the Learning of 2D Models</a></p>
<p>9 0.074931711 <a title="193-tfidf-9" href="./cvpr-2013-Analyzing_Semantic_Segmentation_Using_Hybrid_Human-Machine_CRFs.html">43 cvpr-2013-Analyzing Semantic Segmentation Using Hybrid Human-Machine CRFs</a></p>
<p>10 0.073591352 <a title="193-tfidf-10" href="./cvpr-2013-Discriminative_Segment_Annotation_in_Weakly_Labeled_Video.html">133 cvpr-2013-Discriminative Segment Annotation in Weakly Labeled Video</a></p>
<p>11 0.070126981 <a title="193-tfidf-11" href="./cvpr-2013-Weakly-Supervised_Dual_Clustering_for_Image_Semantic_Segmentation.html">460 cvpr-2013-Weakly-Supervised Dual Clustering for Image Semantic Segmentation</a></p>
<p>12 0.069974512 <a title="193-tfidf-12" href="./cvpr-2013-Multi-class_Video_Co-segmentation_with_a_Generative_Multi-video_Model.html">294 cvpr-2013-Multi-class Video Co-segmentation with a Generative Multi-video Model</a></p>
<p>13 0.068677522 <a title="193-tfidf-13" href="./cvpr-2013-Constraints_as_Features.html">93 cvpr-2013-Constraints as Features</a></p>
<p>14 0.068370804 <a title="193-tfidf-14" href="./cvpr-2013-Fast_Energy_Minimization_Using_Learned_State_Filters.html">165 cvpr-2013-Fast Energy Minimization Using Learned State Filters</a></p>
<p>15 0.067303047 <a title="193-tfidf-15" href="./cvpr-2013-Graph_Matching_with_Anchor_Nodes%3A_A_Learning_Approach.html">192 cvpr-2013-Graph Matching with Anchor Nodes: A Learning Approach</a></p>
<p>16 0.065675251 <a title="193-tfidf-16" href="./cvpr-2013-Multi-target_Tracking_by_Lagrangian_Relaxation_to_Min-cost_Network_Flow.html">300 cvpr-2013-Multi-target Tracking by Lagrangian Relaxation to Min-cost Network Flow</a></p>
<p>17 0.065586425 <a title="193-tfidf-17" href="./cvpr-2013-Semi-supervised_Domain_Adaptation_with_Instance_Constraints.html">387 cvpr-2013-Semi-supervised Domain Adaptation with Instance Constraints</a></p>
<p>18 0.065047272 <a title="193-tfidf-18" href="./cvpr-2013-Voxel_Cloud_Connectivity_Segmentation_-_Supervoxels_for_Point_Clouds.html">458 cvpr-2013-Voxel Cloud Connectivity Segmentation - Supervoxels for Point Clouds</a></p>
<p>19 0.065016218 <a title="193-tfidf-19" href="./cvpr-2013-Deformable_Spatial_Pyramid_Matching_for_Fast_Dense_Correspondences.html">107 cvpr-2013-Deformable Spatial Pyramid Matching for Fast Dense Correspondences</a></p>
<p>20 0.064526409 <a title="193-tfidf-20" href="./cvpr-2013-Incorporating_User_Interaction_and_Topological_Constraints_within_Contour_Completion_via_Discrete_Calculus.html">222 cvpr-2013-Incorporating User Interaction and Topological Constraints within Contour Completion via Discrete Calculus</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.14), (1, -0.02), (2, 0.015), (3, 0.008), (4, 0.076), (5, 0.011), (6, -0.004), (7, -0.004), (8, -0.069), (9, 0.029), (10, 0.105), (11, -0.013), (12, -0.046), (13, 0.016), (14, -0.078), (15, -0.012), (16, -0.011), (17, -0.058), (18, 0.015), (19, 0.004), (20, -0.066), (21, 0.011), (22, -0.043), (23, -0.058), (24, 0.08), (25, -0.029), (26, 0.053), (27, 0.027), (28, -0.014), (29, 0.016), (30, -0.033), (31, 0.013), (32, -0.003), (33, 0.005), (34, 0.09), (35, 0.063), (36, 0.026), (37, -0.097), (38, 0.062), (39, -0.049), (40, -0.043), (41, -0.02), (42, 0.013), (43, 0.111), (44, -0.003), (45, -0.037), (46, -0.041), (47, -0.023), (48, 0.017), (49, -0.074)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93218583 <a title="193-lsi-1" href="./cvpr-2013-Graph_Transduction_Learning_with_Connectivity_Constraints_with_Application_to_Multiple_Foreground_Cosegmentation.html">193 cvpr-2013-Graph Transduction Learning with Connectivity Constraints with Application to Multiple Foreground Cosegmentation</a></p>
<p>Author: Tianyang Ma, Longin Jan Latecki</p><p>Abstract: The proposed approach is based on standard graph transduction, semi-supervised learning (SSL) framework. Its key novelty is the integration of global connectivity constraints into this framework. Although connectivity leads to higher order constraints and their number is an exponential, finding the most violated connectivity constraint can be done efficiently in polynomial time. Moreover, each such constraint can be represented as a linear inequality. Based on this fact, we design a cutting-plane algorithm to solve the integrated problem. It iterates between solving a convex quadraticproblem of labelpropagation with linear inequality constraints, and finding the most violated constraint. We demonstrate the benefits of the proposed approach on a realistic and very challenging problem of cosegmentation of multiple foreground objects in photo collections in which the foreground objects are not present in all photos. The obtained results not only demonstrate performance boost induced by the connectivity constraints, but also show a significant improvement over the state-of-the-art methods.</p><p>2 0.6575622 <a title="193-lsi-2" href="./cvpr-2013-Gauging_Association_Patterns_of_Chromosome_Territories_via_Chromatic_Median.html">184 cvpr-2013-Gauging Association Patterns of Chromosome Territories via Chromatic Median</a></p>
<p>Author: Hu Ding, Branislav Stojkovic, Ronald Berezney, Jinhui Xu</p><p>Abstract: Computing accurate and robust organizational patterns of chromosome territories inside the cell nucleus is critical for understanding several fundamental genomic processes, such as co-regulation of gene activation, gene silencing, X chromosome inactivation, and abnormal chromosome rearrangement in cancer cells. The usage of advanced fluorescence labeling and image processing techniques has enabled researchers to investigate interactions of chromosome territories at large spatial resolution. The resulting high volume of generated data demands for high-throughput and automated image analysis methods. In this paper, we introduce a novel algorithmic tool for investigating association patterns of chromosome territories in a population of cells. Our method takes as input a set of graphs, one for each cell, containing information about spatial interaction of chromosome territories, and yields a single graph that contains essential information for the whole population and stands as its structural representative. We formulate this combinato- rial problem as a semi-definite programming and present novel techniques to efficiently solve it. We validate our approach on both artificial and real biological data; the experimental results suggest that our approach yields a nearoptimal solution, and can handle large-size datasets, which are significant improvements over existing techniques.</p><p>3 0.6206789 <a title="193-lsi-3" href="./cvpr-2013-Semi-supervised_Node_Splitting_for_Random_Forest_Construction.html">390 cvpr-2013-Semi-supervised Node Splitting for Random Forest Construction</a></p>
<p>Author: Xiao Liu, Mingli Song, Dacheng Tao, Zicheng Liu, Luming Zhang, Chun Chen, Jiajun Bu</p><p>Abstract: Node splitting is an important issue in Random Forest but robust splitting requires a large number of training samples. Existing solutions fail to properly partition the feature space if there are insufficient training data. In this paper, we present semi-supervised splitting to overcome this limitation by splitting nodes with the guidance of both labeled and unlabeled data. In particular, we derive a nonparametric algorithm to obtain an accurate quality measure of splitting by incorporating abundant unlabeled data. To avoid the curse of dimensionality, we project the data points from the original high-dimensional feature space onto a low-dimensional subspace before estimation. A unified optimization framework is proposed to select a coupled pair of subspace and separating hyperplane such that the smoothness of the subspace and the quality of the splitting are guaranteed simultaneously. The proposed algorithm is compared with state-of-the-art supervised and semi-supervised algorithms for typical computer vision applications such as object categorization and image segmen- tation. Experimental results on publicly available datasets demonstrate the superiority of our method.</p><p>4 0.60330755 <a title="193-lsi-4" href="./cvpr-2013-Graph-Based_Optimization_with_Tubularity_Markov_Tree_for_3D_Vessel_Segmentation.html">190 cvpr-2013-Graph-Based Optimization with Tubularity Markov Tree for 3D Vessel Segmentation</a></p>
<p>Author: Ning Zhu, Albert C.S. Chung</p><p>Abstract: In this paper, we propose a graph-based method for 3D vessel tree structure segmentation based on a new tubularity Markov tree model ( TMT), which works as both new energy function and graph construction method. With the help of power-watershed implementation [7], a global optimal segmentation can be obtained with low computational cost. Different with other graph-based vessel segmentation methods, the proposed method does not depend on any skeleton and ROI extraction method. The classical issues of the graph-based methods, such as shrinking bias and sensitivity to seed point location, can be solved with the proposed method thanks to vessel data fidelity obtained with TMT. The proposed method is compared with some classical graph-based image segmentation methods and two up-to-date 3D vessel segmentation methods, and is demonstrated to be more accurate than these methods for 3D vessel tree segmentation. Although the segmentation is done without ROI extraction, the computational cost for the proposed method is low (within 20 seconds for 256*256*144 image).</p><p>5 0.5796752 <a title="193-lsi-5" href="./cvpr-2013-Graph_Matching_with_Anchor_Nodes%3A_A_Learning_Approach.html">192 cvpr-2013-Graph Matching with Anchor Nodes: A Learning Approach</a></p>
<p>Author: Nan Hu, Raif M. Rustamov, Leonidas Guibas</p><p>Abstract: In this paper, we consider the weighted graph matching problem with partially disclosed correspondences between a number of anchor nodes. Our construction exploits recently introduced node signatures based on graph Laplacians, namely the Laplacian family signature (LFS) on the nodes, and the pairwise heat kernel map on the edges. In this paper, without assuming an explicit form of parametric dependence nor a distance metric between node signatures, we formulate an optimization problem which incorporates the knowledge of anchor nodes. Solving this problem gives us an optimized proximity measure specific to the graphs under consideration. Using this as a first order compatibility term, we then set up an integer quadratic program (IQP) to solve for a near optimal graph matching. Our experiments demonstrate the superior performance of our approach on randomly generated graphs and on two widelyused image sequences, when compared with other existing signature and adjacency matrix based graph matching methods.</p><p>6 0.57887912 <a title="193-lsi-6" href="./cvpr-2013-Adaptive_Active_Learning_for_Image_Classification.html">34 cvpr-2013-Adaptive Active Learning for Image Classification</a></p>
<p>7 0.5775969 <a title="193-lsi-7" href="./cvpr-2013-A_Genetic_Algorithm-Based_Solver_for_Very_Large_Jigsaw_Puzzles.html">11 cvpr-2013-A Genetic Algorithm-Based Solver for Very Large Jigsaw Puzzles</a></p>
<p>8 0.57231373 <a title="193-lsi-8" href="./cvpr-2013-Constraints_as_Features.html">93 cvpr-2013-Constraints as Features</a></p>
<p>9 0.57145786 <a title="193-lsi-9" href="./cvpr-2013-Discriminative_Segment_Annotation_in_Weakly_Labeled_Video.html">133 cvpr-2013-Discriminative Segment Annotation in Weakly Labeled Video</a></p>
<p>10 0.56932783 <a title="193-lsi-10" href="./cvpr-2013-Deformable_Graph_Matching.html">106 cvpr-2013-Deformable Graph Matching</a></p>
<p>11 0.56703424 <a title="193-lsi-11" href="./cvpr-2013-Jointly_Aligning_and_Segmenting_Multiple_Web_Photo_Streams_for_the_Inference_of_Collective_Photo_Storylines.html">235 cvpr-2013-Jointly Aligning and Segmenting Multiple Web Photo Streams for the Inference of Collective Photo Storylines</a></p>
<p>12 0.55460495 <a title="193-lsi-12" href="./cvpr-2013-Probabilistic_Label_Trees_for_Efficient_Large_Scale_Image_Classification.html">340 cvpr-2013-Probabilistic Label Trees for Efficient Large Scale Image Classification</a></p>
<p>13 0.53926063 <a title="193-lsi-13" href="./cvpr-2013-Category_Modeling_from_Just_a_Single_Labeling%3A_Use_Depth_Information_to_Guide_the_Learning_of_2D_Models.html">80 cvpr-2013-Category Modeling from Just a Single Labeling: Use Depth Information to Guide the Learning of 2D Models</a></p>
<p>14 0.53812093 <a title="193-lsi-14" href="./cvpr-2013-Fast_Energy_Minimization_Using_Learned_State_Filters.html">165 cvpr-2013-Fast Energy Minimization Using Learned State Filters</a></p>
<p>15 0.53391755 <a title="193-lsi-15" href="./cvpr-2013-Consensus_of_k-NNs_for_Robust_Neighborhood_Selection_on_Graph-Based_Manifolds.html">91 cvpr-2013-Consensus of k-NNs for Robust Neighborhood Selection on Graph-Based Manifolds</a></p>
<p>16 0.5328036 <a title="193-lsi-16" href="./cvpr-2013-Weakly-Supervised_Dual_Clustering_for_Image_Semantic_Segmentation.html">460 cvpr-2013-Weakly-Supervised Dual Clustering for Image Semantic Segmentation</a></p>
<p>17 0.53266311 <a title="193-lsi-17" href="./cvpr-2013-Learning_by_Associating_Ambiguously_Labeled_Images.html">261 cvpr-2013-Learning by Associating Ambiguously Labeled Images</a></p>
<p>18 0.52489614 <a title="193-lsi-18" href="./cvpr-2013-Fully-Connected_CRFs_with_Non-Parametric_Pairwise_Potential.html">180 cvpr-2013-Fully-Connected CRFs with Non-Parametric Pairwise Potential</a></p>
<p>19 0.51406372 <a title="193-lsi-19" href="./cvpr-2013-Bilinear_Programming_for_Human_Activity_Recognition_with_Unknown_MRF_Graphs.html">62 cvpr-2013-Bilinear Programming for Human Activity Recognition with Unknown MRF Graphs</a></p>
<p>20 0.50539505 <a title="193-lsi-20" href="./cvpr-2013-Video_Object_Segmentation_through_Spatially_Accurate_and_Temporally_Dense_Extraction_of_Primary_Object_Regions.html">455 cvpr-2013-Video Object Segmentation through Spatially Accurate and Temporally Dense Extraction of Primary Object Regions</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.491), (16, 0.014), (26, 0.025), (33, 0.242), (67, 0.04), (69, 0.031), (87, 0.06)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.9617365 <a title="193-lda-1" href="./cvpr-2013-Multi-image_Blind_Deblurring_Using_a_Coupled_Adaptive_Sparse_Prior.html">295 cvpr-2013-Multi-image Blind Deblurring Using a Coupled Adaptive Sparse Prior</a></p>
<p>Author: Haichao Zhang, David Wipf, Yanning Zhang</p><p>Abstract: This paper presents a robust algorithm for estimating a single latent sharp image given multiple blurry and/or noisy observations. The underlying multi-image blind deconvolution problem is solved by linking all of the observations together via a Bayesian-inspired penalty function which couples the unknown latent image, blur kernels, and noise levels together in a unique way. This coupled penalty function enjoys a number of desirable properties, including a mechanism whereby the relative-concavity or shape is adapted as a function of the intrinsic quality of each blurry observation. In this way, higher quality observations may automatically contribute more to the final estimate than heavily degraded ones. The resulting algorithm, which requires no essential tuning parameters, can recover a high quality image from a set of observations containing potentially both blurry and noisy examples, without knowing a priorithe degradation type of each observation. Experimental results on both synthetic and real-world test images clearly demonstrate the efficacy of the proposed method.</p><p>2 0.9524923 <a title="193-lda-2" href="./cvpr-2013-Non-uniform_Motion_Deblurring_for_Bilayer_Scenes.html">307 cvpr-2013-Non-uniform Motion Deblurring for Bilayer Scenes</a></p>
<p>Author: Chandramouli Paramanand, Ambasamudram N. Rajagopalan</p><p>Abstract: We address the problem of estimating the latent image of a static bilayer scene (consisting of a foreground and a background at different depths) from motion blurred observations captured with a handheld camera. The camera motion is considered to be composed of in-plane rotations and translations. Since the blur at an image location depends both on camera motion and depth, deblurring becomes a difficult task. We initially propose a method to estimate the transformation spread function (TSF) corresponding to one of the depth layers. The estimated TSF (which reveals the camera motion during exposure) is used to segment the scene into the foreground and background layers and determine the relative depth value. The deblurred image of the scene is finally estimated within a regularization framework by accounting for blur variations due to camera motion as well as depth.</p><p>3 0.94910133 <a title="193-lda-3" href="./cvpr-2013-Explicit_Occlusion_Modeling_for_3D_Object_Class_Representations.html">154 cvpr-2013-Explicit Occlusion Modeling for 3D Object Class Representations</a></p>
<p>Author: M. Zeeshan Zia, Michael Stark, Konrad Schindler</p><p>Abstract: Despite the success of current state-of-the-art object class detectors, severe occlusion remains a major challenge. This is particularly true for more geometrically expressive 3D object class representations. While these representations have attracted renewed interest for precise object pose estimation, the focus has mostly been on rather clean datasets, where occlusion is not an issue. In this paper, we tackle the challenge of modeling occlusion in the context of a 3D geometric object class model that is capable of fine-grained, part-level 3D object reconstruction. Following the intuition that 3D modeling should facilitate occlusion reasoning, we design an explicit representation of likely geometric occlusion patterns. Robustness is achieved by pooling image evidence from of a set of fixed part detectors as well as a non-parametric representation of part configurations in the spirit of poselets. We confirm the potential of our method on cars in a newly collected data set of inner-city street scenes with varying levels of occlusion, and demonstrate superior performance in occlusion estimation and part localization, compared to baselines that are unaware of occlusions.</p><p>4 0.94472861 <a title="193-lda-4" href="./cvpr-2013-Can_a_Fully_Unconstrained_Imaging_Model_Be_Applied_Effectively_to_Central_Cameras%3F.html">76 cvpr-2013-Can a Fully Unconstrained Imaging Model Be Applied Effectively to Central Cameras?</a></p>
<p>Author: Filippo Bergamasco, Andrea Albarelli, Emanuele Rodolà, Andrea Torsello</p><p>Abstract: Traditional camera models are often the result of a compromise between the ability to account for non-linearities in the image formation model and the need for a feasible number of degrees of freedom in the estimation process. These considerations led to the definition of several ad hoc models that best adapt to different imaging devices, ranging from pinhole cameras with no radial distortion to the more complex catadioptric or polydioptric optics. In this paper we dai s .unive . it ence points in the scene with their projections on the image plane [5]. Unfortunately, no real camera behaves exactly like an ideal pinhole. In fact, in most cases, at least the distortion effects introduced by the lens should be accounted for [19]. Any pinhole-based model, regardless of its level of sophistication, is geometrically unable to properly describe cameras exhibiting a frustum angle that is near or above 180 degrees. For wide-angle cameras, several different para- metric models have been proposed. Some of them try to modify the captured image in order to follow the original propose the use of an unconstrained model even in standard central camera settings dominated by the pinhole model, and introduce a novel calibration approach that can deal effectively with the huge number of free parameters associated with it, resulting in a higher precision calibration than what is possible with the standard pinhole model with correction for radial distortion. This effectively extends the use of general models to settings that traditionally have been ruled by parametric approaches out of practical considerations. The benefit of such an unconstrained model to quasipinhole central cameras is supported by an extensive experimental validation.</p><p>5 0.94017589 <a title="193-lda-5" href="./cvpr-2013-Computing_Diffeomorphic_Paths_for_Large_Motion_Interpolation.html">90 cvpr-2013-Computing Diffeomorphic Paths for Large Motion Interpolation</a></p>
<p>Author: Dohyung Seo, Jeffrey Ho, Baba C. Vemuri</p><p>Abstract: In this paper, we introduce a novel framework for computing a path of diffeomorphisms between a pair of input diffeomorphisms. Direct computation of a geodesic path on the space of diffeomorphisms Diff(Ω) is difficult, and it can be attributed mainly to the infinite dimensionality of Diff(Ω). Our proposed framework, to some degree, bypasses this difficulty using the quotient map of Diff(Ω) to the quotient space Diff(M)/Diff(M)μ obtained by quotienting out the subgroup of volume-preserving diffeomorphisms Diff(M)μ. This quotient space was recently identified as the unit sphere in a Hilbert space in mathematics literature, a space with well-known geometric properties. Our framework leverages this recent result by computing the diffeomorphic path in two stages. First, we project the given diffeomorphism pair onto this sphere and then compute the geodesic path between these projected points. Sec- ond, we lift the geodesic on the sphere back to the space of diffeomerphisms, by solving a quadratic programming problem with bilinear constraints using the augmented Lagrangian technique with penalty terms. In this way, we can estimate the path of diffeomorphisms, first, staying in the space of diffeomorphisms, and second, preserving shapes/volumes in the deformed images along the path as much as possible. We have applied our framework to interpolate intermediate frames of frame-sub-sampled video sequences. In the reported experiments, our approach compares favorably with the popular Large Deformation Diffeomorphic Metric Mapping framework (LDDMM).</p><p>6 0.92788786 <a title="193-lda-6" href="./cvpr-2013-Self-Paced_Learning_for_Long-Term_Tracking.html">386 cvpr-2013-Self-Paced Learning for Long-Term Tracking</a></p>
<p>7 0.91242319 <a title="193-lda-7" href="./cvpr-2013-GeoF%3A_Geodesic_Forests_for_Learning_Coupled_Predictors.html">186 cvpr-2013-GeoF: Geodesic Forests for Learning Coupled Predictors</a></p>
<p>8 0.91138744 <a title="193-lda-8" href="./cvpr-2013-3D_R_Transform_on_Spatio-temporal_Interest_Points_for_Action_Recognition.html">3 cvpr-2013-3D R Transform on Spatio-temporal Interest Points for Action Recognition</a></p>
<p>9 0.88127816 <a title="193-lda-9" href="./cvpr-2013-Voxel_Cloud_Connectivity_Segmentation_-_Supervoxels_for_Point_Clouds.html">458 cvpr-2013-Voxel Cloud Connectivity Segmentation - Supervoxels for Point Clouds</a></p>
<p>10 0.88074726 <a title="193-lda-10" href="./cvpr-2013-Handling_Noise_in_Single_Image_Deblurring_Using_Directional_Filters.html">198 cvpr-2013-Handling Noise in Single Image Deblurring Using Directional Filters</a></p>
<p>11 0.86115104 <a title="193-lda-11" href="./cvpr-2013-Weakly_Supervised_Learning_of_Mid-Level_Features_with_Beta-Bernoulli_Process_Restricted_Boltzmann_Machines.html">462 cvpr-2013-Weakly Supervised Learning of Mid-Level Features with Beta-Bernoulli Process Restricted Boltzmann Machines</a></p>
<p>12 0.83125895 <a title="193-lda-12" href="./cvpr-2013-Part-Based_Visual_Tracking_with_Online_Latent_Structural_Learning.html">324 cvpr-2013-Part-Based Visual Tracking with Online Latent Structural Learning</a></p>
<p>same-paper 13 0.82722729 <a title="193-lda-13" href="./cvpr-2013-Graph_Transduction_Learning_with_Connectivity_Constraints_with_Application_to_Multiple_Foreground_Cosegmentation.html">193 cvpr-2013-Graph Transduction Learning with Connectivity Constraints with Application to Multiple Foreground Cosegmentation</a></p>
<p>14 0.81371516 <a title="193-lda-14" href="./cvpr-2013-Discriminative_Non-blind_Deblurring.html">131 cvpr-2013-Discriminative Non-blind Deblurring</a></p>
<p>15 0.81182492 <a title="193-lda-15" href="./cvpr-2013-Online_Object_Tracking%3A_A_Benchmark.html">314 cvpr-2013-Online Object Tracking: A Benchmark</a></p>
<p>16 0.79746634 <a title="193-lda-16" href="./cvpr-2013-Structure_Preserving_Object_Tracking.html">414 cvpr-2013-Structure Preserving Object Tracking</a></p>
<p>17 0.79518187 <a title="193-lda-17" href="./cvpr-2013-Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking.html">285 cvpr-2013-Minimum Uncertainty Gap for Robust Visual Tracking</a></p>
<p>18 0.78550529 <a title="193-lda-18" href="./cvpr-2013-Robust_Estimation_of_Nonrigid_Transformation_for_Point_Set_Registration.html">360 cvpr-2013-Robust Estimation of Nonrigid Transformation for Point Set Registration</a></p>
<p>19 0.7849192 <a title="193-lda-19" href="./cvpr-2013-Single_Image_Calibration_of_Multi-axial_Imaging_Systems.html">400 cvpr-2013-Single Image Calibration of Multi-axial Imaging Systems</a></p>
<p>20 0.78183061 <a title="193-lda-20" href="./cvpr-2013-Dense_3D_Reconstruction_from_Severely_Blurred_Images_Using_a_Single_Moving_Camera.html">108 cvpr-2013-Dense 3D Reconstruction from Severely Blurred Images Using a Single Moving Camera</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
