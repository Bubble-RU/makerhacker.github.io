<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>412 cvpr-2013-Stochastic Deconvolution</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-412" href="#">cvpr2013-412</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>412 cvpr-2013-Stochastic Deconvolution</h1>
<br/><p>Source: <a title="cvpr-2013-412-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Gregson_Stochastic_Deconvolution_2013_CVPR_paper.pdf">pdf</a></p><p>Author: James Gregson, Felix Heide, Matthias B. Hullin, Mushfiqur Rouf, Wolfgang Heidrich</p><p>Abstract: We present a novel stochastic framework for non-blind deconvolution based on point samples obtained from random walks. Unlike previous methods that must be tailored to specific regularization strategies, the new Stochastic Deconvolution method allows arbitrary priors, including nonconvex and data-dependent regularizers, to be introduced and tested with little effort. Stochastic Deconvolution is straightforward to implement, produces state-of-the-art results and directly leads to a natural boundary condition for image boundaries and saturated pixels.</p><p>Reference: <a title="cvpr-2013-412-reference" href="../cvpr2013_reference/cvpr-2013-Stochastic_Deconvolution_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 James Gregson  Stochastic Deconvolution Felix Heide Matthias Hullin Mushfiqur Rouf The University of British Columbia  Wolfgang Heidrich  Abstract We present a novel stochastic framework for non-blind deconvolution based on point samples obtained from random walks. [sent-1, score-1.075]
</p><p>2 Stochastic Deconvolution is straightforward to implement, produces state-of-the-art results and directly leads to a natural boundary condition for image boundaries and saturated pixels. [sent-3, score-0.21]
</p><p>3 Introduction Image deconvolution or deblurring has applications in astronomy, microscopy, GIS and photography among other disciplines. [sent-5, score-0.887]
</p><p>4 This paper presents Stochastic Deconvolution, a new framework for non-blind image deconvolution based on stochastic random walks. [sent-7, score-1.048]
</p><p>5 Stochastic Deconvolution is based on an adaptation of a recent stochastic optimiza-  tion method for solving computed tomography problems [6] to the problem of deconvolution. [sent-8, score-0.489]
</p><p>6 The resulting algorithm amounts to a variant of coordinate-descend optimization, where the descent direction is chosen using a random walk that utilizes spatial coherence. [sent-9, score-0.129]
</p><p>7 By solving the image deblurring problem in this fashion, the Stochastic Deconvolution framework directly addresses several issues inherent in developing deconvolution algorithms: •  •  •  Ease of Implementation. [sent-10, score-0.875]
</p><p>8 Both the basic algorithm and iEtsa regularized mveanriatanttiso are very straightforward tmo iamndplement, and is based on only two very simple operations: splatting of the point spread function (PSF) and point-evaluation of the regularization term. [sent-11, score-0.123]
</p><p>9 Because of the simplicity of implementing new regularizers, Susteoc ohfa tshteic s iDmepcloicnivtoylu oftion enables research into new regularization terms and image priors for deconvolution through rapid experimentation. [sent-13, score-0.793]
</p><p>10 An additional benefit of  Stochastic Deconvolution is that it naturally handles these boundary conditions and can use a near-identical process to deal with saturated regions. [sent-18, score-0.184]
</p><p>11 Finally, Stochastic DeconvolutSiohinf generalizes naturally ntaol deblurring problems woiluthspatially varying kernels such as the synthetic camera shake example depicted in Figure 1. [sent-20, score-0.177]
</p><p>12 The remainder of this paper is structured as follows: in the next section we discuss related work while providing an introduction to the deconvolution problem. [sent-21, score-0.69]
</p><p>13 Background and Related Work In this section, we introduce the notation for the deconvolution problem and summarize the optimization framework from Stochastic Tomography [6], which we modify to solve deconvolution problems. [sent-25, score-1.402]
</p><p>14 Image Deconvolution Image deconvolution attempts to remove the blurs introduced when images are captured with real optical systems, including motion blur (e. [sent-28, score-0.824]
</p><p>15 These artifacts are effectively captured by a point-spread-function (PSF) k that measures the projection of a point-light source on the captured image  for a fixed set of camera parameters. [sent-33, score-0.116]
</p><p>16 The captured image q is then represented as the intrinsic (deblurred) image p convolved with the PSF: 1 1 10 0 04 4 413 1  Green points represent energy added while blue correspond to energy subtracted from the reconstruction. [sent-40, score-0.175]
</p><p>17 focuses sampling effort in regions where the largest improvements  to the system energy are obtained. [sent-41, score-0.123]
</p><p>18 The algorithm automatically Right: Example of deblurring  with a spatially-varying (per-pixel) PSF simulating strong motion-blur. [sent-42, score-0.156]
</p><p>19 (1)  The goal of deconvolution is to invert Equation 1 to obtain an estimate of the intrinsic image. [sent-47, score-0.724]
</p><p>20 Traditional methods for solving deconvolution problems include Fourier-space division, the Wiener Filter [18], as well as iterative methods such as Richardson-Lucy [16, 14]. [sent-51, score-0.69]
</p><p>21 All these methods produce significant artifacts in cases where certain image frequencies are completely eliminated  by the blur, which is common especially in defocus blur. [sent-52, score-0.091]
</p><p>22 [21, 22, 5]), most state-of-the art deconvolution methods take a slightly different approach. [sent-55, score-0.69]
</p><p>23 General deconvolution methods define a quadratic fitting energy (either in the Fourier or image domain) that is minimized when the solution estimate convolved by the PSF equals the captured image, e. [sent-57, score-0.79]
</p><p>24 To address this, a prior or regularizer Γ(p) is typically added, weighted by λ, to give the system energy, Equation 3. [sent-60, score-0.163]
</p><p>25 F = Ffit + λΓ(p)  (3)  The regularizer penalizes solutions that do not conform to prior expectations on the solution such as smoothness or sparsity. [sent-61, score-0.163]
</p><p>26 Good regularizers suppress ringing and noise without introducing other undesirable artifacts. [sent-62, score-0.193]
</p><p>27 However a problem arises because the regularizer typically changes the mathematical structure of the problem. [sent-63, score-0.127]
</p><p>28 In particular, priors favoring piecewise smooth solutions cannot be expressed as linear systems, making it necessary  to develop highly specialized, regularizer-specific solvers (e. [sent-64, score-0.097]
</p><p>29 The goal of our work is to design a simple, reasonably efficient, general-purpose deconvolution algorithm capable of handling effectively arbitrary priors. [sent-68, score-0.719]
</p><p>30 To do so, we adapt the random walk optimization strategy from Stochastic Tomography [6] and modify it to solve deconvolution problems. [sent-69, score-0.808]
</p><p>31 The result is a straightforward method for image deconvolution that allows the use of arbitrary priors with no change to the underlying algorithm. [sent-70, score-0.802]
</p><p>32 Another benefit of our method is natural handling of boundary conditions and saturated pixels. [sent-71, score-0.19]
</p><p>33 [6] presented a stochastic random walk algorithm for solving tomographic reconstruction problems. [sent-75, score-0.511]
</p><p>34 A local sample mutation strategy inspired by Metropolis-Hastings then focuses the sampling efforts in regions with high payoff, i. [sent-78, score-0.21]
</p><p>35 Using L1 regularizers on several captured and synthetic examples, Gregson et al. [sent-86, score-0.183]
</p><p>36 One of the contributions of our work is to recognize that this framework for stochastic optimization with a random walk is in fact more general, and can be adapted to inverse problems other than tomography. [sent-88, score-0.454]
</p><p>37 This is significant since frequency content in measured quantities can differ significantly between deblurring and tomography, leading to more aggressive, often non-convex priors that are more difficult to optimize. [sent-89, score-0.218]
</p><p>38 To apply this random walk framework, we only need to derive problem-specific functions for sample mutation, i. [sent-92, score-0.13]
</p><p>39 a transition probability t(xk |xk−1) for choosing sample xk based on the previous sample location xk−1, a method for keeping track of the change ΔF(xk) of the objective function when placing a new sample xk, and finally a method for accepting and recording a new sample record(xk). [sent-94, score-0.397]
</p><p>40 The next section describes how to derive methods for these tasks in the case of deconvolution problems. [sent-95, score-0.69]
</p><p>41 We create a random walk of pixel locations xk at which we add or remove an energy quantum ed, thus generating a sequence p(k) of estimates of the intrinsic image: p(0)  =  q  p(k)  =  p(k−1) ±  (4) ed  · δxk ,  (5)  where δxk is the characteristic function (Kronecker Delta) for pixel xk. [sent-98, score-0.41]
</p><p>42 Both positive and negative energies are tested for each sample location xk in Algorithm 1but only the sign causing the greatest improvement kept. [sent-99, score-0.237]
</p><p>43 The quantity  ΔF(xk)  measures  the  change in the objective function if a given sample xk with value ±ed were to be accepted and added to the solution. [sent-101, score-0.328]
</p><p>44 q(k) can be efficiently updated during the random walk: q(0)  =  k  q(k)  =  q(k−1) ±  ⊗  p(0)  = ed  k  ⊗ q  (k ⊗ δxk)  (6) (7)  In other words, q(k) can be updated by splatting k⊗δxk , a shifted and mirrored copy obfe tuhep dPaSteFd abt ythsep sample l⊗ocδation xk. [sent-103, score-0.126]
</p><p>45 The change in the regularization energy is evaluated in an analogous manner, but is specific to the chosen regularizer. [sent-105, score-0.106]
</p><p>46 The mutation function generates a new sample xk from the previously accepted sample xk−1 . [sent-108, score-0.419]
</p><p>47 1 1 10 0 04 4 435 3  We also add a Russian-roulette chain terminating mutation where the sample is simply moved anywhere in the image domain with uniform probability. [sent-112, score-0.174]
</p><p>48 This mutation is applied with 1% probability, leading to sample chains with expected length of 100. [sent-113, score-0.149]
</p><p>49 Coordinate Descent methods provably converge for smooth objective functions for a fixed step length so long as all possible descent directions (i. [sent-119, score-0.089]
</p><p>50 In our framework, this condition is met by the ergodicity of the sampling process in the limit of number of samples. [sent-122, score-0.094]
</p><p>51 In this paper, we show empirical evidence of the convergence of Stochastic Deconvolution for convex objectives, in particular a total variation (TV) regularized deconvolution problem (Section 4). [sent-124, score-0.749]
</p><p>52 Our results in Section 4 empirically show that Stochastic Deconvolution is competitive for such regularizers and even for a simple discontinuous and data-dependent prior. [sent-126, score-0.216]
</p><p>53 The issue of boundary handling is difficult in deconvolution algorithms, since the process of capturing an image necessarily cuts off some of the data needed to deconvolve at the image boundaries. [sent-128, score-0.775]
</p><p>54 Stochastic Deconvolution naturally handles this situation by padding the input image by the PSF width and creating a mask that indicates which pixels are from the captured region versus from the boundary region. [sent-129, score-0.139]
</p><p>55 Ignoring the data term for these regions while enforcing the regularization term causes the method to perform a simple form of inpainting in the padded and saturated regions to improve the fit to the valid measurements. [sent-132, score-0.261]
</p><p>56 An outer iteration of the sampling procedure from Listing 1 is then started with a total of one mutation per-pixel, and the percentage of accepted samples computed. [sent-138, score-0.235]
</p><p>57 While Stochastic Deconvolution uses the same basic random walk as Stochastic Tomography [6], there are also a number of differences that are worth pointing out. [sent-145, score-0.096]
</p><p>58 First, adapting the method to deblurring requires very specific modifications to handle boundaries and saturation, while switching from continuously placed samples to discrete pixel locations. [sent-146, score-0.206]
</p><p>59 Perhaps more significantly, deblurring can be thought of as redistributing the energy from the blurred image to form the sharp intrinsic image. [sent-147, score-0.27]
</p><p>60 This makes the need for negative energy samples obvious since both negative and positive samples are needed near edges. [sent-148, score-0.095]
</p><p>61 Total variation (TV) regularizers corresponds to an assumption of sparse gradients, that is, of piecewise-smooth solutions with occasional step discontinuities. [sent-154, score-0.148]
</p><p>62 TV regularizers are simple and generally effective regularizers that have the benefits of being convex. [sent-164, score-0.296]
</p><p>63 We have also implemented a version of the regularizer introduced by Levin et al. [sent-166, score-0.127]
</p><p>64 Finally, we introduce a new regularizer that is designed to better deal with dark image regions. [sent-171, score-0.149]
</p><p>65 A standard problem with deconvolution algorithms is that the deconvolution has to be performed in linear intensity space, but the results have to be gamma corrected for viewing. [sent-172, score-1.47]
</p><p>66 The gamma curve, however, stretches the low intensity regions of the image disproportionately, thus amplifying noise in the solution. [sent-173, score-0.139]
</p><p>67 Our approach is to introduce a regularizer that minimizes the data term in linear space, but ensures sparse gradients in the gamma-corrected image. [sent-175, score-0.127]
</p><p>68 To achieve this, we apply an gamma curve to the signal before evaluating a sum of absolute differences (SAD) regularizer in a 3 3 window  Wabs coeluntteer dedif aetr x: Γ(x) =  ? [sent-176, score-0.217]
</p><p>69 This regularizer is non-convex and would be non-trivial to design and implement a custom solver for, but is easily added to the Stochastic Deconvolution framework. [sent-179, score-0.159]
</p><p>70 Results The following sections present results comparing different regularization strategies and objective functions, as well as comparing to several existing methods. [sent-183, score-0.096]
</p><p>71 With the addition of priors, Stochastic Deconvolution produces results with less noise and chromatic artifacts. [sent-190, score-0.105]
</p><p>72 To illustrate the effect of different regularizers we show results for an enlarged area of the train image using the convex Total-Variation (TV) prior, the prior from Levin et al. [sent-192, score-0.206]
</p><p>73 All three priors reduce the noise and chromatic artifacts present in the original results, however the two non-convex priors, (Figure 2(d) and 2(e)), provide the smoothest results. [sent-195, score-0.213]
</p><p>74 We stress that it was straightforward to implement all of these priors in our common framework, while developing specialized solvers for each method would have taken significantly more effort. [sent-197, score-0.184]
</p><p>75 Stochastic Deconvolution (right) using the regularizer of Levin et. [sent-204, score-0.127]
</p><p>76 Incorporation of the regularizer significantly reduces the noise in the reconstructed image while preserving image detail. [sent-206, score-0.149]
</p><p>77 We use the Gamma prior which reduces the noise and chromatic artifacts in dark regions such as the wheels and windows, while slightly improving the legibility of the text on the cab. [sent-209, score-0.269]
</p><p>78 Addition of a prior helps to suppress noise and chromatic artifacts present in the original results, while improving the legibility of the text. [sent-216, score-0.22]
</p><p>79 Figure 4 shows a comparison of deconvolution results using the method of Fergus et al. [sent-217, score-0.69]
</p><p>80 Stochastic Deconvolution is also able to reconstruct the entire image right up to the image boundary through the use of the stochastic boundary condition. [sent-220, score-0.47]
</p><p>81 Finally, we show a comparison of deconvolution results between the relatively recent method for large-blur removal of Xu and Jia [19] with Stochastic Deconvolution using Levin et al. [sent-221, score-0.69]
</p><p>82 Figure 6 highlights the effect of the stochastic boundary condition for inpainting plausible content in boundary regions, including additional windows and staircase details. [sent-224, score-0.553]
</p><p>83 The Stochastic Deconvolution result (bottom) shows substantially reduced ringing as well as much-improved handling ofimage boundaries due to the use of the Stochastic boundary condition. [sent-230, score-0.108]
</p><p>84 Non-blind deconvolution comparison with Xu and Jia (using kernels estimated by Xu and Jia) for the Roma image. [sent-233, score-0.69]
</p><p>85 regularizer results in a slightly sharper image with reduced chromatic artifacts. [sent-234, score-0.235]
</p><p>86 Due to the local nature of Stochastic Deconvolution, the deblurring problem can be relaxed from deconvolution to deblurring with spatially  leL reanvs i. [sent-239, score-1.024]
</p><p>87 Top row: inpainted details from the stochastic boundary condition, windows are added to a building on the boundary (red outline) and staircase details outside the image are introduced (yellow outline). [sent-248, score-0.499]
</p><p>88 rings for highly saturated pixels, while masking these from the reconstruction produces considerably smaller artifacts. [sent-251, score-0.105]
</p><p>89 with Stochastic  Deconvolution for defocus blur from a standard SLR. [sent-255, score-0.109]
</p><p>90 Comparison of per-channel TV (top) with the multichannel MTV prior (bottom) for a blur kernel with chromatic aberration. [sent-257, score-0.208]
</p><p>91 Deblurring with a TV regularizer yields gives an optimal peak PSNR value of 3 1. [sent-264, score-0.127]
</p><p>92 However, such discontinuous, discrete-choice regularizers are problematic to implement effectively in conventional, gradientbased solvers. [sent-271, score-0.18]
</p><p>93 Adding the L1 RGB distance to the nearest of one of five RGB clusters (computed by K-means) to a standard TV regularizer improves the best PSNR values by 0. [sent-276, score-0.127]
</p><p>94 However, we have performed empirical convergence tests for the anisotropic TV regularizer and compared final objective values to the provably convergent method of Chambolle and Pock [2]. [sent-278, score-0.256]
</p><p>95 The objective function history is shown in Figure 10(c), showing a fast initial convergence rate that gradually flattens, as might be expected from a stochastic sub-gradient method. [sent-283, score-0.457]
</p><p>96 Conclusions and Future Work In this paper we have present Stochastic Deconvolution, a new, general-purpose method for the deconvolution problem based on stochastic random-walks. [sent-287, score-1.048]
</p><p>97 Convergence history of method down to ed < 4 10−9 for anisotropic TV regularizer with weight λ = <10 4−3 ×. [sent-290, score-0.227]
</p><p>98 Note that each Stochastic Deconvolution iteration has an approximately equal computational cost to one gradient-descent step using image-space convolutions but is able to focus sampling effort near details, as shown in the sampling histogram. [sent-291, score-0.089]
</p><p>99 On the other hand, we gain the flexibility to not only incorporate arbitrary regularizers, but also to use spatially varying PSFs and modify the solver at boundaries and saturated pixels. [sent-295, score-0.17]
</p><p>100 Stochastic tomography and its applications in 3D imaging of mixing fluids. [sent-344, score-0.154]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('deconvolution', 0.69), ('stochastic', 0.358), ('xk', 0.203), ('psf', 0.166), ('deblurring', 0.156), ('regularizers', 0.148), ('tomography', 0.131), ('regularizer', 0.127), ('mutation', 0.115), ('tv', 0.115), ('saturated', 0.105), ('walk', 0.096), ('gamma', 0.09), ('raskar', 0.089), ('chromatic', 0.083), ('levin', 0.075), ('ffit', 0.074), ('gregson', 0.074), ('discontinuous', 0.068), ('psfs', 0.068), ('blur', 0.064), ('priors', 0.062), ('tomographic', 0.057), ('boundary', 0.056), ('mtv', 0.056), ('splatting', 0.056), ('artifacts', 0.046), ('defocus', 0.045), ('db', 0.044), ('regularization', 0.041), ('photography', 0.041), ('energy', 0.041), ('sd', 0.04), ('blurred', 0.039), ('siggraph', 0.038), ('coordinate', 0.038), ('convergence', 0.037), ('ergodicity', 0.037), ('tvpsnr', 0.037), ('prior', 0.036), ('anisotropic', 0.036), ('ed', 0.036), ('coded', 0.035), ('solvers', 0.035), ('blurs', 0.035), ('captured', 0.035), ('sample', 0.034), ('sampling', 0.034), ('intrinsic', 0.034), ('objective', 0.034), ('descent', 0.033), ('legibility', 0.033), ('accepted', 0.033), ('implement', 0.032), ('inpainting', 0.031), ('fergus', 0.031), ('joshi', 0.031), ('hullin', 0.03), ('padded', 0.03), ('equation', 0.029), ('exposure', 0.029), ('handling', 0.029), ('developing', 0.029), ('staircase', 0.029), ('history', 0.028), ('samples', 0.027), ('objectives', 0.027), ('jia', 0.027), ('regions', 0.027), ('xu', 0.027), ('outer', 0.026), ('straightforward', 0.026), ('chambolle', 0.025), ('anywhere', 0.025), ('padding', 0.025), ('multichannel', 0.025), ('yuan', 0.025), ('record', 0.025), ('hirsch', 0.025), ('sharper', 0.025), ('unoptimized', 0.025), ('change', 0.024), ('convolved', 0.024), ('handles', 0.023), ('condition', 0.023), ('ringing', 0.023), ('placed', 0.023), ('quan', 0.023), ('imaging', 0.023), ('deblurred', 0.022), ('provably', 0.022), ('noise', 0.022), ('convex', 0.022), ('dark', 0.022), ('modify', 0.022), ('spatially', 0.022), ('strategies', 0.021), ('flexibility', 0.021), ('shake', 0.021), ('effort', 0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000006 <a title="412-tfidf-1" href="./cvpr-2013-Stochastic_Deconvolution.html">412 cvpr-2013-Stochastic Deconvolution</a></p>
<p>Author: James Gregson, Felix Heide, Matthias B. Hullin, Mushfiqur Rouf, Wolfgang Heidrich</p><p>Abstract: We present a novel stochastic framework for non-blind deconvolution based on point samples obtained from random walks. Unlike previous methods that must be tailored to specific regularization strategies, the new Stochastic Deconvolution method allows arbitrary priors, including nonconvex and data-dependent regularizers, to be introduced and tested with little effort. Stochastic Deconvolution is straightforward to implement, produces state-of-the-art results and directly leads to a natural boundary condition for image boundaries and saturated pixels.</p><p>2 0.34059647 <a title="412-tfidf-2" href="./cvpr-2013-Blind_Deconvolution_of_Widefield_Fluorescence_Microscopic_Data_by_Regularization_of_the_Optical_Transfer_Function_%28OTF%29.html">65 cvpr-2013-Blind Deconvolution of Widefield Fluorescence Microscopic Data by Regularization of the Optical Transfer Function (OTF)</a></p>
<p>Author: Margret Keuper, Thorsten Schmidt, Maja Temerinac-Ott, Jan Padeken, Patrick Heun, Olaf Ronneberger, Thomas Brox</p><p>Abstract: With volumetric data from widefield fluorescence microscopy, many emerging questions in biological and biomedical research are being investigated. Data can be recorded with high temporal resolution while the specimen is only exposed to a low amount of phototoxicity. These advantages come at the cost of strong recording blur caused by the infinitely extended point spread function (PSF). For widefield microscopy, its magnitude only decays with the square of the distance to the focal point and consists of an airy bessel pattern which is intricate to describe in the spatial domain. However, the Fourier transform of the incoherent PSF (denoted as Optical Transfer Function (OTF)) is well localized and smooth. In this paper, we present a blind -fre iburg .de Figure 1. As for widefield microscopy the convolution ofthe signal deconvolution method that improves results of state-of-theart deconvolution methods on widefield data by exploiting the properties of the widefield OTF.</p><p>3 0.28734183 <a title="412-tfidf-3" href="./cvpr-2013-Handling_Noise_in_Single_Image_Deblurring_Using_Directional_Filters.html">198 cvpr-2013-Handling Noise in Single Image Deblurring Using Directional Filters</a></p>
<p>Author: Lin Zhong, Sunghyun Cho, Dimitris Metaxas, Sylvain Paris, Jue Wang</p><p>Abstract: State-of-the-art single image deblurring techniques are sensitive to image noise. Even a small amount of noise, which is inevitable in low-light conditions, can degrade the quality of blur kernel estimation dramatically. The recent approach of Tai and Lin [17] tries to iteratively denoise and deblur a blurry and noisy image. However, as we show in this work, directly applying image denoising methods often partially damages the blur information that is extracted from the input image, leading to biased kernel estimation. We propose a new method for handling noise in blind image deconvolution based on new theoretical and practical insights. Our key observation is that applying a directional low-pass filter to the input image greatly reduces the noise level, while preserving the blur information in the orthogonal direction to the filter. Based on this observation, our method applies a series of directional filters at different orientations to the input image, and estimates an accurate Radon transform of the blur kernel from each filtered image. Finally, we reconstruct the blur kernel using inverse Radon transform. Experimental results on synthetic and real data show that our algorithm achieves higher quality results than previous approaches on blurry and noisy images. 1</p><p>4 0.2750352 <a title="412-tfidf-4" href="./cvpr-2013-Unnatural_L0_Sparse_Representation_for_Natural_Image_Deblurring.html">449 cvpr-2013-Unnatural L0 Sparse Representation for Natural Image Deblurring</a></p>
<p>Author: Li Xu, Shicheng Zheng, Jiaya Jia</p><p>Abstract: We show in this paper that the success of previous maximum a posterior (MAP) based blur removal methods partly stems from their respective intermediate steps, which implicitly or explicitly create an unnatural representation containing salient image structures. We propose a generalized and mathematically sound L0 sparse expression, together with a new effective method, for motion deblurring. Our system does not require extra filtering during optimization and demonstrates fast energy decreasing, making a small number of iterations enough for convergence. It also provides a unifiedframeworkfor both uniform andnon-uniform motion deblurring. We extensively validate our method and show comparison with other approaches with respect to convergence speed, running time, and result quality.</p><p>5 0.25398514 <a title="412-tfidf-5" href="./cvpr-2013-Multi-image_Blind_Deblurring_Using_a_Coupled_Adaptive_Sparse_Prior.html">295 cvpr-2013-Multi-image Blind Deblurring Using a Coupled Adaptive Sparse Prior</a></p>
<p>Author: Haichao Zhang, David Wipf, Yanning Zhang</p><p>Abstract: This paper presents a robust algorithm for estimating a single latent sharp image given multiple blurry and/or noisy observations. The underlying multi-image blind deconvolution problem is solved by linking all of the observations together via a Bayesian-inspired penalty function which couples the unknown latent image, blur kernels, and noise levels together in a unique way. This coupled penalty function enjoys a number of desirable properties, including a mechanism whereby the relative-concavity or shape is adapted as a function of the intrinsic quality of each blurry observation. In this way, higher quality observations may automatically contribute more to the final estimate than heavily degraded ones. The resulting algorithm, which requires no essential tuning parameters, can recover a high quality image from a set of observations containing potentially both blurry and noisy examples, without knowing a priorithe degradation type of each observation. Experimental results on both synthetic and real-world test images clearly demonstrate the efficacy of the proposed method.</p><p>6 0.23951781 <a title="412-tfidf-6" href="./cvpr-2013-A_Machine_Learning_Approach_for_Non-blind_Image_Deconvolution.html">17 cvpr-2013-A Machine Learning Approach for Non-blind Image Deconvolution</a></p>
<p>7 0.23065838 <a title="412-tfidf-7" href="./cvpr-2013-Learning_to_Estimate_and_Remove_Non-uniform_Image_Blur.html">265 cvpr-2013-Learning to Estimate and Remove Non-uniform Image Blur</a></p>
<p>8 0.19433153 <a title="412-tfidf-8" href="./cvpr-2013-Discriminative_Non-blind_Deblurring.html">131 cvpr-2013-Discriminative Non-blind Deblurring</a></p>
<p>9 0.14637218 <a title="412-tfidf-9" href="./cvpr-2013-Non-uniform_Motion_Deblurring_for_Bilayer_Scenes.html">307 cvpr-2013-Non-uniform Motion Deblurring for Bilayer Scenes</a></p>
<p>10 0.13508578 <a title="412-tfidf-10" href="./cvpr-2013-Dense_3D_Reconstruction_from_Severely_Blurred_Images_Using_a_Single_Moving_Camera.html">108 cvpr-2013-Dense 3D Reconstruction from Severely Blurred Images Using a Single Moving Camera</a></p>
<p>11 0.086144179 <a title="412-tfidf-11" href="./cvpr-2013-Fusing_Depth_from_Defocus_and_Stereo_with_Coded_Apertures.html">181 cvpr-2013-Fusing Depth from Defocus and Stereo with Coded Apertures</a></p>
<p>12 0.082817085 <a title="412-tfidf-12" href="./cvpr-2013-HDR_Deghosting%3A_How_to_Deal_with_Saturation%3F.html">195 cvpr-2013-HDR Deghosting: How to Deal with Saturation?</a></p>
<p>13 0.078676395 <a title="412-tfidf-13" href="./cvpr-2013-An_Iterated_L1_Algorithm_for_Non-smooth_Non-convex_Optimization_in_Computer_Vision.html">41 cvpr-2013-An Iterated L1 Algorithm for Non-smooth Non-convex Optimization in Computer Vision</a></p>
<p>14 0.071914755 <a title="412-tfidf-14" href="./cvpr-2013-Blur_Processing_Using_Double_Discrete_Wavelet_Transform.html">68 cvpr-2013-Blur Processing Using Double Discrete Wavelet Transform</a></p>
<p>15 0.069194421 <a title="412-tfidf-15" href="./cvpr-2013-Active_Contours_with_Group_Similarity.html">33 cvpr-2013-Active Contours with Group Similarity</a></p>
<p>16 0.064630046 <a title="412-tfidf-16" href="./cvpr-2013-Accurate_and_Robust_Registration_of_Nonrigid_Surface_Using_Hierarchical_Statistical_Shape_Model.html">31 cvpr-2013-Accurate and Robust Registration of Nonrigid Surface Using Hierarchical Statistical Shape Model</a></p>
<p>17 0.063204661 <a title="412-tfidf-17" href="./cvpr-2013-The_Variational_Structure_of_Disparity_and_Regularization_of_4D_Light_Fields.html">431 cvpr-2013-The Variational Structure of Disparity and Regularization of 4D Light Fields</a></p>
<p>18 0.061451655 <a title="412-tfidf-18" href="./cvpr-2013-Globally_Consistent_Multi-label_Assignment_on_the_Ray_Space_of_4D_Light_Fields.html">188 cvpr-2013-Globally Consistent Multi-label Assignment on the Ray Space of 4D Light Fields</a></p>
<p>19 0.059003994 <a title="412-tfidf-19" href="./cvpr-2013-Texture_Enhanced_Image_Denoising_via_Gradient_Histogram_Preservation.html">427 cvpr-2013-Texture Enhanced Image Denoising via Gradient Histogram Preservation</a></p>
<p>20 0.050980765 <a title="412-tfidf-20" href="./cvpr-2013-Efficient_Large-Scale_Structured_Learning.html">143 cvpr-2013-Efficient Large-Scale Structured Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.131), (1, 0.131), (2, -0.032), (3, 0.118), (4, -0.073), (5, 0.318), (6, 0.043), (7, -0.022), (8, 0.021), (9, 0.012), (10, -0.005), (11, -0.03), (12, -0.016), (13, -0.048), (14, -0.069), (15, 0.006), (16, 0.065), (17, -0.02), (18, 0.071), (19, 0.064), (20, -0.048), (21, 0.049), (22, -0.004), (23, 0.028), (24, 0.003), (25, 0.007), (26, 0.041), (27, -0.029), (28, 0.017), (29, 0.011), (30, 0.072), (31, 0.026), (32, -0.086), (33, -0.033), (34, -0.003), (35, -0.042), (36, 0.008), (37, 0.006), (38, -0.015), (39, -0.046), (40, 0.024), (41, 0.025), (42, -0.042), (43, -0.075), (44, 0.03), (45, 0.024), (46, -0.043), (47, -0.014), (48, -0.019), (49, 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93618196 <a title="412-lsi-1" href="./cvpr-2013-Stochastic_Deconvolution.html">412 cvpr-2013-Stochastic Deconvolution</a></p>
<p>Author: James Gregson, Felix Heide, Matthias B. Hullin, Mushfiqur Rouf, Wolfgang Heidrich</p><p>Abstract: We present a novel stochastic framework for non-blind deconvolution based on point samples obtained from random walks. Unlike previous methods that must be tailored to specific regularization strategies, the new Stochastic Deconvolution method allows arbitrary priors, including nonconvex and data-dependent regularizers, to be introduced and tested with little effort. Stochastic Deconvolution is straightforward to implement, produces state-of-the-art results and directly leads to a natural boundary condition for image boundaries and saturated pixels.</p><p>2 0.89091682 <a title="412-lsi-2" href="./cvpr-2013-Blind_Deconvolution_of_Widefield_Fluorescence_Microscopic_Data_by_Regularization_of_the_Optical_Transfer_Function_%28OTF%29.html">65 cvpr-2013-Blind Deconvolution of Widefield Fluorescence Microscopic Data by Regularization of the Optical Transfer Function (OTF)</a></p>
<p>Author: Margret Keuper, Thorsten Schmidt, Maja Temerinac-Ott, Jan Padeken, Patrick Heun, Olaf Ronneberger, Thomas Brox</p><p>Abstract: With volumetric data from widefield fluorescence microscopy, many emerging questions in biological and biomedical research are being investigated. Data can be recorded with high temporal resolution while the specimen is only exposed to a low amount of phototoxicity. These advantages come at the cost of strong recording blur caused by the infinitely extended point spread function (PSF). For widefield microscopy, its magnitude only decays with the square of the distance to the focal point and consists of an airy bessel pattern which is intricate to describe in the spatial domain. However, the Fourier transform of the incoherent PSF (denoted as Optical Transfer Function (OTF)) is well localized and smooth. In this paper, we present a blind -fre iburg .de Figure 1. As for widefield microscopy the convolution ofthe signal deconvolution method that improves results of state-of-theart deconvolution methods on widefield data by exploiting the properties of the widefield OTF.</p><p>3 0.861696 <a title="412-lsi-3" href="./cvpr-2013-Multi-image_Blind_Deblurring_Using_a_Coupled_Adaptive_Sparse_Prior.html">295 cvpr-2013-Multi-image Blind Deblurring Using a Coupled Adaptive Sparse Prior</a></p>
<p>Author: Haichao Zhang, David Wipf, Yanning Zhang</p><p>Abstract: This paper presents a robust algorithm for estimating a single latent sharp image given multiple blurry and/or noisy observations. The underlying multi-image blind deconvolution problem is solved by linking all of the observations together via a Bayesian-inspired penalty function which couples the unknown latent image, blur kernels, and noise levels together in a unique way. This coupled penalty function enjoys a number of desirable properties, including a mechanism whereby the relative-concavity or shape is adapted as a function of the intrinsic quality of each blurry observation. In this way, higher quality observations may automatically contribute more to the final estimate than heavily degraded ones. The resulting algorithm, which requires no essential tuning parameters, can recover a high quality image from a set of observations containing potentially both blurry and noisy examples, without knowing a priorithe degradation type of each observation. Experimental results on both synthetic and real-world test images clearly demonstrate the efficacy of the proposed method.</p><p>4 0.83901811 <a title="412-lsi-4" href="./cvpr-2013-Handling_Noise_in_Single_Image_Deblurring_Using_Directional_Filters.html">198 cvpr-2013-Handling Noise in Single Image Deblurring Using Directional Filters</a></p>
<p>Author: Lin Zhong, Sunghyun Cho, Dimitris Metaxas, Sylvain Paris, Jue Wang</p><p>Abstract: State-of-the-art single image deblurring techniques are sensitive to image noise. Even a small amount of noise, which is inevitable in low-light conditions, can degrade the quality of blur kernel estimation dramatically. The recent approach of Tai and Lin [17] tries to iteratively denoise and deblur a blurry and noisy image. However, as we show in this work, directly applying image denoising methods often partially damages the blur information that is extracted from the input image, leading to biased kernel estimation. We propose a new method for handling noise in blind image deconvolution based on new theoretical and practical insights. Our key observation is that applying a directional low-pass filter to the input image greatly reduces the noise level, while preserving the blur information in the orthogonal direction to the filter. Based on this observation, our method applies a series of directional filters at different orientations to the input image, and estimates an accurate Radon transform of the blur kernel from each filtered image. Finally, we reconstruct the blur kernel using inverse Radon transform. Experimental results on synthetic and real data show that our algorithm achieves higher quality results than previous approaches on blurry and noisy images. 1</p><p>5 0.82791579 <a title="412-lsi-5" href="./cvpr-2013-Learning_to_Estimate_and_Remove_Non-uniform_Image_Blur.html">265 cvpr-2013-Learning to Estimate and Remove Non-uniform Image Blur</a></p>
<p>Author: Florent Couzinié-Devy, Jian Sun, Karteek Alahari, Jean Ponce</p><p>Abstract: This paper addresses the problem of restoring images subjected to unknown and spatially varying blur caused by defocus or linear (say, horizontal) motion. The estimation of the global (non-uniform) image blur is cast as a multilabel energy minimization problem. The energy is the sum of unary terms corresponding to learned local blur estimators, and binary ones corresponding to blur smoothness. Its global minimum is found using Ishikawa ’s method by exploiting the natural order of discretized blur values for linear motions and defocus. Once the blur has been estimated, the image is restored using a robust (non-uniform) deblurring algorithm based on sparse regularization with global image statistics. The proposed algorithm outputs both a segmentation of the image into uniform-blur layers and an estimate of the corresponding sharp image. We present qualitative results on real images, and use synthetic data to quantitatively compare our approach to the publicly available implementation of Chakrabarti et al. [5].</p><p>6 0.80505884 <a title="412-lsi-6" href="./cvpr-2013-Discriminative_Non-blind_Deblurring.html">131 cvpr-2013-Discriminative Non-blind Deblurring</a></p>
<p>7 0.80375332 <a title="412-lsi-7" href="./cvpr-2013-Unnatural_L0_Sparse_Representation_for_Natural_Image_Deblurring.html">449 cvpr-2013-Unnatural L0 Sparse Representation for Natural Image Deblurring</a></p>
<p>8 0.77036822 <a title="412-lsi-8" href="./cvpr-2013-A_Machine_Learning_Approach_for_Non-blind_Image_Deconvolution.html">17 cvpr-2013-A Machine Learning Approach for Non-blind Image Deconvolution</a></p>
<p>9 0.74866199 <a title="412-lsi-9" href="./cvpr-2013-Blur_Processing_Using_Double_Discrete_Wavelet_Transform.html">68 cvpr-2013-Blur Processing Using Double Discrete Wavelet Transform</a></p>
<p>10 0.58237112 <a title="412-lsi-10" href="./cvpr-2013-Non-uniform_Motion_Deblurring_for_Bilayer_Scenes.html">307 cvpr-2013-Non-uniform Motion Deblurring for Bilayer Scenes</a></p>
<p>11 0.48011881 <a title="412-lsi-11" href="./cvpr-2013-Dense_3D_Reconstruction_from_Severely_Blurred_Images_Using_a_Single_Moving_Camera.html">108 cvpr-2013-Dense 3D Reconstruction from Severely Blurred Images Using a Single Moving Camera</a></p>
<p>12 0.44690844 <a title="412-lsi-12" href="./cvpr-2013-Texture_Enhanced_Image_Denoising_via_Gradient_Histogram_Preservation.html">427 cvpr-2013-Texture Enhanced Image Denoising via Gradient Histogram Preservation</a></p>
<p>13 0.44678795 <a title="412-lsi-13" href="./cvpr-2013-On_a_Link_Between_Kernel_Mean_Maps_and_Fraunhofer_Diffraction%2C_with_an_Application_to_Super-Resolution_Beyond_the_Diffraction_Limit.html">312 cvpr-2013-On a Link Between Kernel Mean Maps and Fraunhofer Diffraction, with an Application to Super-Resolution Beyond the Diffraction Limit</a></p>
<p>14 0.38205782 <a title="412-lsi-14" href="./cvpr-2013-Adaptive_Compressed_Tomography_Sensing.html">35 cvpr-2013-Adaptive Compressed Tomography Sensing</a></p>
<p>15 0.37808484 <a title="412-lsi-15" href="./cvpr-2013-An_Iterated_L1_Algorithm_for_Non-smooth_Non-convex_Optimization_in_Computer_Vision.html">41 cvpr-2013-An Iterated L1 Algorithm for Non-smooth Non-convex Optimization in Computer Vision</a></p>
<p>16 0.36116263 <a title="412-lsi-16" href="./cvpr-2013-A_New_Model_and_Simple_Algorithms_for_Multi-label_Mumford-Shah_Problems.html">20 cvpr-2013-A New Model and Simple Algorithms for Multi-label Mumford-Shah Problems</a></p>
<p>17 0.36069486 <a title="412-lsi-17" href="./cvpr-2013-Auxiliary_Cuts_for_General_Classes_of_Higher_Order_Functionals.html">51 cvpr-2013-Auxiliary Cuts for General Classes of Higher Order Functionals</a></p>
<p>18 0.35748604 <a title="412-lsi-18" href="./cvpr-2013-Learning_without_Human_Scores_for_Blind_Image_Quality_Assessment.html">266 cvpr-2013-Learning without Human Scores for Blind Image Quality Assessment</a></p>
<p>19 0.35288024 <a title="412-lsi-19" href="./cvpr-2013-HDR_Deghosting%3A_How_to_Deal_with_Saturation%3F.html">195 cvpr-2013-HDR Deghosting: How to Deal with Saturation?</a></p>
<p>20 0.3463245 <a title="412-lsi-20" href="./cvpr-2013-Fast_Trust_Region_for_Segmentation.html">171 cvpr-2013-Fast Trust Region for Segmentation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.234), (16, 0.033), (21, 0.019), (26, 0.032), (28, 0.012), (33, 0.255), (67, 0.039), (68, 0.045), (69, 0.031), (77, 0.06), (87, 0.099), (96, 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.95959163 <a title="412-lda-1" href="./cvpr-2013-Can_a_Fully_Unconstrained_Imaging_Model_Be_Applied_Effectively_to_Central_Cameras%3F.html">76 cvpr-2013-Can a Fully Unconstrained Imaging Model Be Applied Effectively to Central Cameras?</a></p>
<p>Author: Filippo Bergamasco, Andrea Albarelli, Emanuele Rodolà, Andrea Torsello</p><p>Abstract: Traditional camera models are often the result of a compromise between the ability to account for non-linearities in the image formation model and the need for a feasible number of degrees of freedom in the estimation process. These considerations led to the definition of several ad hoc models that best adapt to different imaging devices, ranging from pinhole cameras with no radial distortion to the more complex catadioptric or polydioptric optics. In this paper we dai s .unive . it ence points in the scene with their projections on the image plane [5]. Unfortunately, no real camera behaves exactly like an ideal pinhole. In fact, in most cases, at least the distortion effects introduced by the lens should be accounted for [19]. Any pinhole-based model, regardless of its level of sophistication, is geometrically unable to properly describe cameras exhibiting a frustum angle that is near or above 180 degrees. For wide-angle cameras, several different para- metric models have been proposed. Some of them try to modify the captured image in order to follow the original propose the use of an unconstrained model even in standard central camera settings dominated by the pinhole model, and introduce a novel calibration approach that can deal effectively with the huge number of free parameters associated with it, resulting in a higher precision calibration than what is possible with the standard pinhole model with correction for radial distortion. This effectively extends the use of general models to settings that traditionally have been ruled by parametric approaches out of practical considerations. The benefit of such an unconstrained model to quasipinhole central cameras is supported by an extensive experimental validation.</p><p>2 0.95797163 <a title="412-lda-2" href="./cvpr-2013-Explicit_Occlusion_Modeling_for_3D_Object_Class_Representations.html">154 cvpr-2013-Explicit Occlusion Modeling for 3D Object Class Representations</a></p>
<p>Author: M. Zeeshan Zia, Michael Stark, Konrad Schindler</p><p>Abstract: Despite the success of current state-of-the-art object class detectors, severe occlusion remains a major challenge. This is particularly true for more geometrically expressive 3D object class representations. While these representations have attracted renewed interest for precise object pose estimation, the focus has mostly been on rather clean datasets, where occlusion is not an issue. In this paper, we tackle the challenge of modeling occlusion in the context of a 3D geometric object class model that is capable of fine-grained, part-level 3D object reconstruction. Following the intuition that 3D modeling should facilitate occlusion reasoning, we design an explicit representation of likely geometric occlusion patterns. Robustness is achieved by pooling image evidence from of a set of fixed part detectors as well as a non-parametric representation of part configurations in the spirit of poselets. We confirm the potential of our method on cars in a newly collected data set of inner-city street scenes with varying levels of occlusion, and demonstrate superior performance in occlusion estimation and part localization, compared to baselines that are unaware of occlusions.</p><p>3 0.95616406 <a title="412-lda-3" href="./cvpr-2013-GeoF%3A_Geodesic_Forests_for_Learning_Coupled_Predictors.html">186 cvpr-2013-GeoF: Geodesic Forests for Learning Coupled Predictors</a></p>
<p>Author: Peter Kontschieder, Pushmeet Kohli, Jamie Shotton, Antonio Criminisi</p><p>Abstract: Conventional decision forest based methods for image labelling tasks like object segmentation make predictions for each variable (pixel) independently [3, 5, 8]. This prevents them from enforcing dependencies between variables and translates into locally inconsistent pixel labellings. Random field models, instead, encourage spatial consistency of labels at increased computational expense. This paper presents a new and efficient forest based model that achieves spatially consistent semantic image segmentation by encoding variable dependencies directly in the feature space the forests operate on. Such correlations are captured via new long-range, soft connectivity features, computed via generalized geodesic distance transforms. Our model can be thought of as a generalization of the successful Semantic Texton Forest, Auto-Context, and Entangled Forest models. A second contribution is to show the connection between the typical Conditional Random Field (CRF) energy and the forest training objective. This analysis yields a new objective for training decision forests that encourages more accurate structured prediction. Our GeoF model is validated quantitatively on the task of semantic image segmentation, on four challenging and very diverse image datasets. GeoF outperforms both stateof-the-art forest models and the conventional pairwise CRF.</p><p>4 0.95521057 <a title="412-lda-4" href="./cvpr-2013-Computing_Diffeomorphic_Paths_for_Large_Motion_Interpolation.html">90 cvpr-2013-Computing Diffeomorphic Paths for Large Motion Interpolation</a></p>
<p>Author: Dohyung Seo, Jeffrey Ho, Baba C. Vemuri</p><p>Abstract: In this paper, we introduce a novel framework for computing a path of diffeomorphisms between a pair of input diffeomorphisms. Direct computation of a geodesic path on the space of diffeomorphisms Diff(Ω) is difficult, and it can be attributed mainly to the infinite dimensionality of Diff(Ω). Our proposed framework, to some degree, bypasses this difficulty using the quotient map of Diff(Ω) to the quotient space Diff(M)/Diff(M)μ obtained by quotienting out the subgroup of volume-preserving diffeomorphisms Diff(M)μ. This quotient space was recently identified as the unit sphere in a Hilbert space in mathematics literature, a space with well-known geometric properties. Our framework leverages this recent result by computing the diffeomorphic path in two stages. First, we project the given diffeomorphism pair onto this sphere and then compute the geodesic path between these projected points. Sec- ond, we lift the geodesic on the sphere back to the space of diffeomerphisms, by solving a quadratic programming problem with bilinear constraints using the augmented Lagrangian technique with penalty terms. In this way, we can estimate the path of diffeomorphisms, first, staying in the space of diffeomorphisms, and second, preserving shapes/volumes in the deformed images along the path as much as possible. We have applied our framework to interpolate intermediate frames of frame-sub-sampled video sequences. In the reported experiments, our approach compares favorably with the popular Large Deformation Diffeomorphic Metric Mapping framework (LDDMM).</p><p>5 0.95190054 <a title="412-lda-5" href="./cvpr-2013-Self-Paced_Learning_for_Long-Term_Tracking.html">386 cvpr-2013-Self-Paced Learning for Long-Term Tracking</a></p>
<p>Author: unkown-author</p><p>Abstract: We address the problem of long-term object tracking, where the object may become occluded or leave-the-view. In this setting, we show that an accurate appearance model is considerably more effective than a strong motion model. We develop simple but effective algorithms that alternate between tracking and learning a good appearance model given a track. We show that it is crucial to learn from the “right” frames, and use the formalism of self-paced curriculum learning to automatically select such frames. We leverage techniques from object detection for learning accurate appearance-based templates, demonstrating the importance of using a large negative training set (typically not used for tracking). We describe both an offline algorithm (that processes frames in batch) and a linear-time online (i.e. causal) algorithm that approaches real-time performance. Our models significantly outperform prior art, reducing the average error on benchmark videos by a factor of 4.</p><p>6 0.95169419 <a title="412-lda-6" href="./cvpr-2013-Non-uniform_Motion_Deblurring_for_Bilayer_Scenes.html">307 cvpr-2013-Non-uniform Motion Deblurring for Bilayer Scenes</a></p>
<p>7 0.95063657 <a title="412-lda-7" href="./cvpr-2013-Voxel_Cloud_Connectivity_Segmentation_-_Supervoxels_for_Point_Clouds.html">458 cvpr-2013-Voxel Cloud Connectivity Segmentation - Supervoxels for Point Clouds</a></p>
<p>8 0.94605732 <a title="412-lda-8" href="./cvpr-2013-Handling_Noise_in_Single_Image_Deblurring_Using_Directional_Filters.html">198 cvpr-2013-Handling Noise in Single Image Deblurring Using Directional Filters</a></p>
<p>9 0.94540286 <a title="412-lda-9" href="./cvpr-2013-Multi-image_Blind_Deblurring_Using_a_Coupled_Adaptive_Sparse_Prior.html">295 cvpr-2013-Multi-image Blind Deblurring Using a Coupled Adaptive Sparse Prior</a></p>
<p>10 0.94054157 <a title="412-lda-10" href="./cvpr-2013-3D_R_Transform_on_Spatio-temporal_Interest_Points_for_Action_Recognition.html">3 cvpr-2013-3D R Transform on Spatio-temporal Interest Points for Action Recognition</a></p>
<p>11 0.94017047 <a title="412-lda-11" href="./cvpr-2013-Weakly_Supervised_Learning_of_Mid-Level_Features_with_Beta-Bernoulli_Process_Restricted_Boltzmann_Machines.html">462 cvpr-2013-Weakly Supervised Learning of Mid-Level Features with Beta-Bernoulli Process Restricted Boltzmann Machines</a></p>
<p>12 0.93420237 <a title="412-lda-12" href="./cvpr-2013-Part-Based_Visual_Tracking_with_Online_Latent_Structural_Learning.html">324 cvpr-2013-Part-Based Visual Tracking with Online Latent Structural Learning</a></p>
<p>13 0.93056023 <a title="412-lda-13" href="./cvpr-2013-Graph_Transduction_Learning_with_Connectivity_Constraints_with_Application_to_Multiple_Foreground_Cosegmentation.html">193 cvpr-2013-Graph Transduction Learning with Connectivity Constraints with Application to Multiple Foreground Cosegmentation</a></p>
<p>14 0.92822063 <a title="412-lda-14" href="./cvpr-2013-On_a_Link_Between_Kernel_Mean_Maps_and_Fraunhofer_Diffraction%2C_with_an_Application_to_Super-Resolution_Beyond_the_Diffraction_Limit.html">312 cvpr-2013-On a Link Between Kernel Mean Maps and Fraunhofer Diffraction, with an Application to Super-Resolution Beyond the Diffraction Limit</a></p>
<p>15 0.92750257 <a title="412-lda-15" href="./cvpr-2013-Discriminative_Non-blind_Deblurring.html">131 cvpr-2013-Discriminative Non-blind Deblurring</a></p>
<p>16 0.92676145 <a title="412-lda-16" href="./cvpr-2013-Single_Image_Calibration_of_Multi-axial_Imaging_Systems.html">400 cvpr-2013-Single Image Calibration of Multi-axial Imaging Systems</a></p>
<p>17 0.92668992 <a title="412-lda-17" href="./cvpr-2013-Online_Object_Tracking%3A_A_Benchmark.html">314 cvpr-2013-Online Object Tracking: A Benchmark</a></p>
<p>18 0.92577481 <a title="412-lda-18" href="./cvpr-2013-Structure_Preserving_Object_Tracking.html">414 cvpr-2013-Structure Preserving Object Tracking</a></p>
<p>19 0.9253242 <a title="412-lda-19" href="./cvpr-2013-Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking.html">285 cvpr-2013-Minimum Uncertainty Gap for Robust Visual Tracking</a></p>
<p>20 0.92324698 <a title="412-lda-20" href="./cvpr-2013-Separating_Signal_from_Noise_Using_Patch_Recurrence_across_Scales.html">393 cvpr-2013-Separating Signal from Noise Using Patch Recurrence across Scales</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
