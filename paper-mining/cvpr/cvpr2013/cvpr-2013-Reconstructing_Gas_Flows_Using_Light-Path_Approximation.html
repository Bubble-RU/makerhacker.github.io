<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>349 cvpr-2013-Reconstructing Gas Flows Using Light-Path Approximation</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-349" href="#">cvpr2013-349</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>349 cvpr-2013-Reconstructing Gas Flows Using Light-Path Approximation</h1>
<br/><p>Source: <a title="cvpr-2013-349-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Ji_Reconstructing_Gas_Flows_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Yu Ji, Jinwei Ye, Jingyi Yu</p><p>Abstract: Transparent gas flows are difficult to reconstruct: the refractive index field (RIF) within the gas volume is uneven and rapidly evolving, and correspondence matching under distortions is challenging. We present a novel computational imaging solution by exploiting the light field probe (LFProbe). A LF-probe resembles a view-dependent pattern where each pixel on the pattern maps to a unique ray. By . ude l. edu observing the LF-probe through the gas flow, we acquire a dense set of ray-ray correspondences and then reconstruct their light paths. To recover the RIF, we use Fermat’s Principle to correlate each light path with the RIF via a Partial Differential Equation (PDE). We then develop an iterative optimization scheme to solve for all light-path PDEs in conjunction. Specifically, we initialize the light paths by fitting Hermite splines to ray-ray correspondences, discretize their PDEs onto voxels, and solve a large, over-determined PDE system for the RIF. The RIF can then be used to refine the light paths. Finally, we alternate the RIF and light-path estimations to improve the reconstruction. Experiments on synthetic and real data show that our approach can reliably reconstruct small to medium scale gas flows. In particular, when the flow is acquired by a small number of cameras, the use of ray-ray correspondences can greatly improve the reconstruction.</p><p>Reference: <a title="cvpr-2013-349-reference" href="../cvpr2013_reference/cvpr-2013-Reconstructing_Gas_Flows_Using_Light-Path_Approximation_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 We present a novel computational imaging solution by exploiting the light field probe (LFProbe). [sent-2, score-0.321]
</p><p>2 edu  observing the LF-probe through the gas flow, we acquire a dense set of ray-ray correspondences and then reconstruct their light paths. [sent-6, score-1.096]
</p><p>3 To recover the RIF, we use Fermat’s Principle to correlate each light path with the RIF via a Partial Differential Equation (PDE). [sent-7, score-0.343]
</p><p>4 Specifically, we initialize the light paths by fitting Hermite splines to ray-ray correspondences, discretize their PDEs onto voxels, and solve a large, over-determined PDE system for the RIF. [sent-9, score-0.387]
</p><p>5 The RIF can then be used to refine the light paths. [sent-10, score-0.207]
</p><p>6 Experiments on synthetic and real data show that our approach can reliably reconstruct small to medium scale gas flows. [sent-12, score-0.762]
</p><p>7 Introduction Accurately reconstructing transparent phenomena such as fluid wavefronts and gas flows remains as one of the most challenging problems in computer vision. [sent-15, score-1.016]
</p><p>8 Second, compared with static transparent objects, transparent gas flows are even more difficult to reconstruct since the refractive index field (RIF) within the gas volume is uneven and rapidly evolving, introducing large image distortions. [sent-19, score-1.962]
</p><p>9 We acquire ray-ray correspondences to first estimate their light paths and then use them to recover the refractive index field (RIF) of the gas volume. [sent-21, score-1.449]
</p><p>10 Usually, a known reference pattern is placed near the transparent surface and robust tracking is applied to establish correspondences between a feature point on the pattern and its image in the camera. [sent-24, score-0.38]
</p><p>11 It then uses Background Oriented Schlieren (BOS) to measure deflections and applies tomographic reconstruction for recovering the gas flow. [sent-30, score-0.742]
</p><p>12 We, in contrast, present a portable solution for acquiring small to medium scale gas flows. [sent-32, score-0.79]
</p><p>13 Our solution exploits the light field probe (LF-Probe) [28, 29] which serves as a view-dependent reference pattern. [sent-33, score-0.321]
</p><p>14 A LF-probe, in essence, is an “inverted” light field camera [22] where each pixel on the pattern maps to a 222555000755  unique ray. [sent-34, score-0.34]
</p><p>15 , a pattern ray from the LF-probe will be mapped to a pixel ray in the camera, as shown in Fig. [sent-37, score-0.325]
</p><p>16 Recent studies have shown that ray-ray correspondences greatly benefit specular surface reconstruction. [sent-39, score-0.241]
</p><p>17 We demonstrate how to use ray-ray correspondences for inferring light paths [16] through the RIF within the gas volume. [sent-43, score-1.071]
</p><p>18 Under Fermat’s Principle, each light path corresponds to the shortest Optical Path Length (OPL). [sent-44, score-0.333]
</p><p>19 By using variational method, we show that each light path and the RIF is related via a Partial Differential Equation (PDE). [sent-45, score-0.283]
</p><p>20 Specifically, we initialize the light paths by fitting Hermite splines [8] to ray-ray correspondences, discretize their PDEs onto voxels, and solve a large, over-determined PDE system for the RIF. [sent-47, score-0.387]
</p><p>21 The RIF can then be used to refine the light paths. [sent-48, score-0.207]
</p><p>22 Experiments on synthetic and real data show that our approach can reliably reconstruct small to medium scale gas flows. [sent-50, score-0.762]
</p><p>23 In particular, when the flow is acquired by a small number of cameras, the use of ray-ray correspondences can greatly improve reconstruction quality. [sent-51, score-0.249]
</p><p>24 Related Work Reconstructing transparent objects/phenomena such as fluids and gas flows is an important problem to oceanography and fluid mechanics and has recently attracted much attention from computer vision. [sent-53, score-1.013]
</p><p>25 [24] use pointpixel correspondences to first estimate the specular flow and then apply quadric approximations to recover mirror-type surfaces. [sent-57, score-0.313]
</p><p>26 A common issue in point-pixel based solutions is ambiguity: a pixel corresponds to a ray from the camera while the specular surface can lie at any position along the ray. [sent-58, score-0.34]
</p><p>27 Bonfort and Sturm [4] use images captured by multiple calibrated cameras to reconstruct specular surface via space carving. [sent-60, score-0.229]
</p><p>28 Kutulakos and Steger [16] discover that by analyzing the piecewise linear light paths in homogeneous refractive medium, one can view surface reconstruction as a generalized triangulation problem. [sent-61, score-0.614]
</p><p>29 In this paper, we demonstrate using non-linear light paths for recovering inhomogeneous refractive media. [sent-63, score-0.511]
</p><p>30 Morris and Kutulakos [20] track the corners of a checkerboard pattern over time in a stereo camera setting and then impose the refractive disparity constraint to iteratively solve for surface heights and normals. [sent-66, score-0.379]
</p><p>31 [30] point out that to robustly recover light paths, it is important to establish ray-ray correspondences. [sent-71, score-0.263]
</p><p>32 For example, they propose using Bokode [19], a special pinhole projector, to acquire ray-ray correspondences for directly recovering fluid surface normals. [sent-72, score-0.348]
</p><p>33 One of the most challenging transparent objects is 3D gas flows. [sent-77, score-0.735]
</p><p>34 Schardin [26] uses a knife edge to partially block rays proportional to their refracted directions to visualize dynamic gas flows, refractive solids, and shock waves. [sent-79, score-0.97]
</p><p>35 Howes [12] modifies the traditional Schlieren to conduct quantitative evaluation of refractive index distribution by encoding the hue. [sent-81, score-0.25]
</p><p>36 [2] captures distorted wavelet noise patterns through the gas vol-  ume from multiple viewpoints. [sent-87, score-0.647]
</p><p>37 It then measures deflections caused by gas refraction to correlate the incident ray (i. [sent-88, score-0.971]
</p><p>38 , around 3 meters in their experiments) and is suitable for acquiring large scale gas flow. [sent-95, score-0.714]
</p><p>39 We develop a low-cost, portable solution for acquiring gas flows of small to medium scales. [sent-96, score-0.918]
</p><p>40 2, can be viewed as an “inverted” light field  camera Lytro (www. [sent-106, score-0.299]
</p><p>41 In Lytro, a microlenslet array is placed in front of the camera sensor to acquire the 4D light field, where the sensor-lens distance is identical to the microlens’ focal length. [sent-109, score-0.43]
</p><p>42 Each microlens serves as a virtual pinhole camera and the lenslet array serves as a camera array. [sent-110, score-0.373]
</p><p>43 To obtain a dense set of correspondences, similar to [28, 29], we use color-coded pattern to encrypt the 4D ray positions and directions emitted by the probe. [sent-113, score-0.212]
</p><p>44 In particular, we use a combination of horizontal red gradient and vertical blue gradient behind each microlens to discriminate rays of different directions. [sent-114, score-0.204]
</p><p>45 To find out the position shifted due to refraction, we perform optical flow between the refracted pattern and the original one on the green channel to estimate the deflection vectors. [sent-119, score-0.204]
</p><p>46 We place 3 LF-probes to surround the target gas flow and 3 synchronized cameras to capture the corresponding LF-probe through the gas volume. [sent-125, score-1.437]
</p><p>47 Our goal is to first acquire a dense set of correspondences between rays entering the gas volume and the ones exiting the volume and then use these incident-exit ray pairs for estimating the light paths and the RIF. [sent-126, score-1.521]
</p><p>48 In order to reliably correlate the incidentexit ray pairs, we conduct two calibration procedures, one between each LF-probe and its viewing camera and the secLF-Probe 1  Figure 3. [sent-128, score-0.294]
</p><p>49 An additional checkerboard pattern is placed next to the probe for measuring the orientation of the probe w. [sent-137, score-0.262]
</p><p>50 Once we determine the direction β of a ray collected by the camera and the angle α between the probe’s normal and the camera’s principal axis, we can then compute the ray’s direction as γ = α + β, as shown in Fig. [sent-141, score-0.253]
</p><p>51 We obtain the ground truth by acquiring the LF-probe without any gas flows. [sent-148, score-0.714]
</p><p>52 When capturing the gas flows, we then use the optical flow for tracking the pattern. [sent-149, score-0.754]
</p><p>53 To resolve this issue, we place three addi-  tional cameras between the viewing cameras and conduct pair-wise camera calibrations. [sent-154, score-0.221]
</p><p>54 Once we finish the calibration process, each camera is able to acquire a dense set of ray-ray correspondences w. [sent-155, score-0.26]
</p><p>55 in) to represent rays emitting from the LF-Probes (the incident rays) and for the rays entering the camera (the exit rays) as shown in Fig. [sent-160, score-0.295]
</p><p>56 Volumetric Gas Reconstruction Given a dense set of ray-ray correspondences across the gas volume, our goal is to recover the RIF that best matches these correspondences. [sent-167, score-0.782]
</p><p>57 We instead derive how RIF is correlated with the light path using Fermat’s principle: the light always travels along the path with the shortest Optical Path length (OPL) [5]. [sent-169, score-0.616]
</p><p>58 the refractive index n at every point p(x, y, z) (or voxel in the discrete case) on the path c:  S =? [sent-173, score-0.343]
</p><p>59 cn(p)ds  (1)  We can further parameterize p(x, y, z) as function of the  time t that light reaches (x, y, z) as p(x(t) , y(t) , z(t)), then we have:  S =? [sent-174, score-0.207]
</p><p>60 xt2+ yt2+ zt2 (2) = ∂∂tx, = ∂∂ty, = ∂∂tz and n(p) is the refractive  where xt yt zt index at p. [sent-176, score-0.221]
</p><p>61 Our goal is to solve for both the light path c and the RIF n. [sent-178, score-0.283]
</p><p>62 Base on the Fermat’s Principle, each light path c corresponds to the shortest OPL. [sent-179, score-0.333]
</p><p>63 RIF Estimation If we have the light paths, we can then estimate the RIF. [sent-183, score-0.207]
</p><p>64 e light ray reaches the gas volume at t = t0 and leaves at t = t1. [sent-198, score-1.065]
</p><p>65 To recover the RIF, we discretize 3-D space into voxels and estimate the refraction index at each voxel. [sent-218, score-0.237]
</p><p>66 Specifically, we can predefine the gas volume and discretize Eqn. [sent-219, score-0.783]
</p><p>67 For voxels at the bounding faces of the gas  volume, we assume their refractive indices are equal to nair = 1. [sent-228, score-0.937]
</p><p>68 Using all light paths, we form a PDE system of the RIF. [sent-232, score-0.207]
</p><p>69 The RIF estimation method presented above requires knowing the light paths. [sent-234, score-0.207]
</p><p>70 Therefore, we initialize light paths by fitting a Hermite spline [8] to each rayray correspondence (Pin, Pout, . [sent-236, score-0.352]
</p><p>71 Light-Path Refinement  × ×  Once we obtain the initial estimation of the RIF, we refine the light paths within the gas volume using Fermat’s Principle. [sent-245, score-1.036]
</p><p>72 However, such graph approximation does not consider how much the distance light travels inside each voxel. [sent-251, score-0.207]
</p><p>73 To speed up 2sh×or3te2st v path computation, we aggressively prune the nodes based on the observation that light paths only  slightly deviate from a linear path. [sent-257, score-0.42]
</p><p>74 Specifically, we impose a “bounding volume” along the previously estimated light path as shown in Fig. [sent-258, score-0.283]
</p><p>75 Furthermore, inside each voxel, we prune a large amount of corners/Steiner points from the search by assuming that the light direction will not change drastically after the refinement. [sent-260, score-0.256]
</p><p>76 Synthetic Scene Simulations We first test our solution on a static gas volume whose RIF follows Gaussian distribution: n(x, y, z) = nair − (nair where (x0, y0, z (n0) is −the 1 )ceenter of flow. [sent-272, score-0.759]
</p><p>77 × T6o0 capture tnhsee LF-probe image, we dheasvcer ibmedplemented a voxel-based Ray-tracer that can trace along non-linear light paths within the volume. [sent-278, score-0.32]
</p><p>78 In this synthetic scene, we use three LF-probes surrounding the gas volume to mimic the real setup. [sent-282, score-0.745]
</p><p>79 − 1)e−((x−x0)2+(y−y0)2+(z−z0)2)/2,  Since our synthesized images are noise-free, we directly map the red/blue channels to incident ray directions and apply optical flow on the green channel to determine incident ray origins. [sent-286, score-0.548]
</p><p>80 The measured optical flows and angular variations are shown in Fig. [sent-287, score-0.227]
</p><p>81 4 to iteratively estimate the light paths and the RIF. [sent-290, score-0.32]
</p><p>82 Since this volume data has more complex geometric structures, we discretize the volume into 32 32 32 voxels. [sent-304, score-0.205]
</p><p>83 0W ien apply the same approach to iteratively recover the RIF and the light paths. [sent-306, score-0.238]
</p><p>84 Specifically, we have implemented the multi-camera BOS gas flow reconstruction algorithm [2] and conducted comparisons under various configurations: w. [sent-315, score-0.759]
</p><p>85 When testing different numbers of cameras, we fix the gas-pattern distance to 5 the gas volume sriazse,; wweh feinx studying pthatete impact aonfc gas-pattern ed gisasta vncole-, we use 4 camera-pattern pairs. [sent-318, score-0.716]
</p><p>86 This is because point-pixel correspondences are insufficient for determining the light paths unless the pattern is placed far away. [sent-340, score-0.49]
</p><p>87 ×  Since the gas flow is fast-evolving, we use a fast shutter of 1/320 s. [sent-360, score-0.745]
</p><p>88 To generate real 3D gas flows, we use an alcohol lamp whose flame temperature can reach around 600◦C. [sent-363, score-0.676]
</p><p>89 9 shows our reconstructed gas flows at three different time instances. [sent-367, score-0.807]
</p><p>90 The gas flow inside the volume is highly inhomogeneous. [sent-370, score-0.781]
</p><p>91 Our reconstructed RIF indicates that the central portion of the volume has a lower refractive index, i. [sent-373, score-0.292]
</p><p>92 (a) The captured LF-probe images; (b) Measured ray direction variations through the flow; (c)-(e) Three vertical slices of the reconstructed RIFs where (d) is the central slice. [sent-385, score-0.25]
</p><p>93 Discussions and Conclusions We have presented a new computational imaging solution for reconstructing dynamic 3D gas flows. [sent-397, score-0.703]
</p><p>94 We have then used these 222555 111311  correspondences to iteratively estimate the light paths and  the refractive index field of the gas volume. [sent-399, score-1.323]
</p><p>95 Experiments on synthetic and real data have shown that our approach provides a portable and reliable solution for reconstructing dynamic and inhomogeneous gas flows of small to medium scales. [sent-400, score-0.936]
</p><p>96 To reduce image noise, we illuminate the LF-probes with ultrabright light sources. [sent-403, score-0.232]
</p><p>97 We plan to use the light field camera such as Lytro (www. [sent-417, score-0.299]
</p><p>98 Compared with our current setting that each microlens on the LF-probe generates a single rayray correspondence, the new setup will map each pixel of the microlens pattern to a ray-ray correspondence. [sent-422, score-0.331]
</p><p>99 At the same time, we can  use the acquired gas flows to improve fluid simulations for producing more realistic animations. [sent-425, score-0.901]
</p><p>100 A theory of refractive and specular 3D shape by light-path triangulation. [sent-526, score-0.272]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('gas', 0.647), ('rif', 0.383), ('light', 0.207), ('refractive', 0.191), ('ray', 0.142), ('microlens', 0.129), ('flows', 0.128), ('paths', 0.113), ('correspondences', 0.104), ('schlieren', 0.1), ('acquire', 0.095), ('fluid', 0.093), ('transparent', 0.088), ('probe', 0.083), ('specular', 0.081), ('lenslet', 0.08), ('path', 0.076), ('rays', 0.075), ('opl', 0.071), ('fermat', 0.071), ('volume', 0.069), ('acquiring', 0.067), ('discretize', 0.067), ('flow', 0.065), ('hermite', 0.064), ('mpe', 0.064), ('camera', 0.061), ('pde', 0.059), ('bos', 0.057), ('fluids', 0.057), ('voxels', 0.056), ('surface', 0.056), ('acquisition', 0.054), ('refraction', 0.053), ('wetzstein', 0.053), ('ape', 0.053), ('incident', 0.052), ('shortest', 0.05), ('cameras', 0.049), ('deflections', 0.048), ('pdes', 0.047), ('reconstruction', 0.047), ('voxel', 0.046), ('reconstruct', 0.043), ('lytro', 0.043), ('pout', 0.043), ('atcheson', 0.043), ('medium', 0.043), ('nair', 0.043), ('array', 0.042), ('optical', 0.042), ('pattern', 0.041), ('pin', 0.038), ('fov', 0.036), ('ye', 0.035), ('portable', 0.033), ('acquired', 0.033), ('shutter', 0.033), ('angular', 0.033), ('viewing', 0.033), ('bokode', 0.032), ('cldt', 0.032), ('dalziel', 0.032), ('deflection', 0.032), ('eikonal', 0.032), ('microlenses', 0.032), ('pointpixel', 0.032), ('rayray', 0.032), ('steiner', 0.032), ('wavefronts', 0.032), ('exit', 0.032), ('reconstructed', 0.032), ('field', 0.031), ('recover', 0.031), ('checkerboard', 0.03), ('index', 0.03), ('synchronized', 0.029), ('synthetic', 0.029), ('directions', 0.029), ('conduct', 0.029), ('correlate', 0.029), ('evolving', 0.029), ('flame', 0.029), ('tevs', 0.029), ('reconstructing', 0.028), ('dynamic', 0.028), ('kutulakos', 0.028), ('slices', 0.027), ('photography', 0.026), ('bonfort', 0.026), ('sankaranarayanan', 0.026), ('establish', 0.025), ('placed', 0.025), ('direction', 0.025), ('ihrke', 0.025), ('magnor', 0.025), ('illuminate', 0.025), ('channel', 0.024), ('prune', 0.024), ('variations', 0.024)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.000002 <a title="349-tfidf-1" href="./cvpr-2013-Reconstructing_Gas_Flows_Using_Light-Path_Approximation.html">349 cvpr-2013-Reconstructing Gas Flows Using Light-Path Approximation</a></p>
<p>Author: Yu Ji, Jinwei Ye, Jingyi Yu</p><p>Abstract: Transparent gas flows are difficult to reconstruct: the refractive index field (RIF) within the gas volume is uneven and rapidly evolving, and correspondence matching under distortions is challenging. We present a novel computational imaging solution by exploiting the light field probe (LFProbe). A LF-probe resembles a view-dependent pattern where each pixel on the pattern maps to a unique ray. By . ude l. edu observing the LF-probe through the gas flow, we acquire a dense set of ray-ray correspondences and then reconstruct their light paths. To recover the RIF, we use Fermat’s Principle to correlate each light path with the RIF via a Partial Differential Equation (PDE). We then develop an iterative optimization scheme to solve for all light-path PDEs in conjunction. Specifically, we initialize the light paths by fitting Hermite splines to ray-ray correspondences, discretize their PDEs onto voxels, and solve a large, over-determined PDE system for the RIF. The RIF can then be used to refine the light paths. Finally, we alternate the RIF and light-path estimations to improve the reconstruction. Experiments on synthetic and real data show that our approach can reliably reconstruct small to medium scale gas flows. In particular, when the flow is acquired by a small number of cameras, the use of ray-ray correspondences can greatly improve the reconstruction.</p><p>2 0.25906354 <a title="349-tfidf-2" href="./cvpr-2013-A_Theory_of_Refractive_Photo-Light-Path_Triangulation.html">27 cvpr-2013-A Theory of Refractive Photo-Light-Path Triangulation</a></p>
<p>Author: Visesh Chari, Peter Sturm</p><p>Abstract: 3D reconstruction of transparent refractive objects like a plastic bottle is challenging: they lack appearance related visual cues and merely reflect and refract light from the surrounding environment. Amongst several approaches to reconstruct such objects, the seminal work of Light-Path triangulation [17] is highly popular because of its general applicability and analysis of minimal scenarios. A lightpath is defined as the piece-wise linear path taken by a ray of light as it passes from source, through the object and into the camera. Transparent refractive objects not only affect the geometric configuration of light-paths but also their radiometric properties. In this paper, we describe a method that combines both geometric and radiometric information to do reconstruction. We show two major consequences of the addition of radiometric cues to the light-path setup. Firstly, we extend the case of scenarios in which reconstruction is plausible while reducing the minimal re- quirements for a unique reconstruction. This happens as a consequence of the fact that radiometric cues add an additional known variable to the already existing system of equations. Secondly, we present a simple algorithm for reconstruction, owing to the nature of the radiometric cue. We present several synthetic experiments to validate our theories, and show high quality reconstructions in challenging scenarios.</p><p>3 0.1771903 <a title="349-tfidf-3" href="./cvpr-2013-Globally_Consistent_Multi-label_Assignment_on_the_Ray_Space_of_4D_Light_Fields.html">188 cvpr-2013-Globally Consistent Multi-label Assignment on the Ray Space of 4D Light Fields</a></p>
<p>Author: Sven Wanner, Christoph Straehle, Bastian Goldluecke</p><p>Abstract: Wepresent thefirst variationalframeworkfor multi-label segmentation on the ray space of 4D light fields. For traditional segmentation of single images, , features need to be extractedfrom the 2Dprojection ofa three-dimensional scene. The associated loss of geometry information can cause severe problems, for example if different objects have a very similar visual appearance. In this work, we show that using a light field instead of an image not only enables to train classifiers which can overcome many of these problems, but also provides an optimal data structure for label optimization by implicitly providing scene geometry information. It is thus possible to consistently optimize label assignment over all views simultaneously. As a further contribution, we make all light fields available online with complete depth and segmentation ground truth data where available, and thus establish the first benchmark data set for light field analysis to facilitate competitive further development of algorithms.</p><p>4 0.1681502 <a title="349-tfidf-4" href="./cvpr-2013-The_Variational_Structure_of_Disparity_and_Regularization_of_4D_Light_Fields.html">431 cvpr-2013-The Variational Structure of Disparity and Regularization of 4D Light Fields</a></p>
<p>Author: Bastian Goldluecke, Sven Wanner</p><p>Abstract: Unlike traditional images which do not offer information for different directions of incident light, a light field is defined on ray space, and implicitly encodes scene geometry data in a rich structure which becomes visible on its epipolar plane images. In this work, we analyze regularization of light fields in variational frameworks and show that their variational structure is induced by disparity, which is in this context best understood as a vector field on epipolar plane image space. We derive differential constraints on this vector field to enable consistent disparity map regularization. Furthermore, we show how the disparity field is related to the regularization of more general vector-valued functions on the 4D ray space of the light field. This way, we derive an efficient variational framework with convex priors, which can serve as a fundament for a large class of inverse problems on ray space.</p><p>5 0.16268566 <a title="349-tfidf-5" href="./cvpr-2013-Underwater_Camera_Calibration_Using_Wavelength_Triangulation.html">447 cvpr-2013-Underwater Camera Calibration Using Wavelength Triangulation</a></p>
<p>Author: Timothy Yau, Minglun Gong, Yee-Hong Yang</p><p>Abstract: In underwater imagery, the image formation process includes refractions that occur when light passes from water into the camera housing, typically through a flat glass port. We extend the existing work on physical refraction models by considering the dispersion of light, and derive new constraints on the model parameters for use in calibration. This leads to a novel calibration method that achieves improved accuracy compared to existing work. We describe how to construct a novel calibration device for our method and evaluate the accuracy of the method through synthetic and real experiments.</p><p>6 0.13763253 <a title="349-tfidf-6" href="./cvpr-2013-Can_a_Fully_Unconstrained_Imaging_Model_Be_Applied_Effectively_to_Central_Cameras%3F.html">76 cvpr-2013-Can a Fully Unconstrained Imaging Model Be Applied Effectively to Central Cameras?</a></p>
<p>7 0.13215564 <a title="349-tfidf-7" href="./cvpr-2013-Light_Field_Distortion_Feature_for_Transparent_Object_Recognition.html">269 cvpr-2013-Light Field Distortion Feature for Transparent Object Recognition</a></p>
<p>8 0.1255199 <a title="349-tfidf-8" href="./cvpr-2013-Determining_Motion_Directly_from_Normal_Flows_Upon_the_Use_of_a_Spherical_Eye_Platform.html">124 cvpr-2013-Determining Motion Directly from Normal Flows Upon the Use of a Spherical Eye Platform</a></p>
<p>9 0.12394962 <a title="349-tfidf-9" href="./cvpr-2013-Single_Image_Calibration_of_Multi-axial_Imaging_Systems.html">400 cvpr-2013-Single Image Calibration of Multi-axial Imaging Systems</a></p>
<p>10 0.11605849 <a title="349-tfidf-10" href="./cvpr-2013-Decoding%2C_Calibration_and_Rectification_for_Lenselet-Based_Plenoptic_Cameras.html">102 cvpr-2013-Decoding, Calibration and Rectification for Lenselet-Based Plenoptic Cameras</a></p>
<p>11 0.10934523 <a title="349-tfidf-11" href="./cvpr-2013-Fast_Rigid_Motion_Segmentation_via_Incrementally-Complex_Local_Models.html">170 cvpr-2013-Fast Rigid Motion Segmentation via Incrementally-Complex Local Models</a></p>
<p>12 0.1008751 <a title="349-tfidf-12" href="./cvpr-2013-Mirror_Surface_Reconstruction_from_a_Single_Image.html">286 cvpr-2013-Mirror Surface Reconstruction from a Single Image</a></p>
<p>13 0.088603683 <a title="349-tfidf-13" href="./cvpr-2013-Principal_Observation_Ray_Calibration_for_Tiled-Lens-Array_Integral_Imaging_Display.html">337 cvpr-2013-Principal Observation Ray Calibration for Tiled-Lens-Array Integral Imaging Display</a></p>
<p>14 0.084454224 <a title="349-tfidf-14" href="./cvpr-2013-Multi-view_Photometric_Stereo_with_Spatially_Varying_Isotropic_Materials.html">303 cvpr-2013-Multi-view Photometric Stereo with Spatially Varying Isotropic Materials</a></p>
<p>15 0.079719089 <a title="349-tfidf-15" href="./cvpr-2013-Template-Based_Isometric_Deformable_3D_Reconstruction_with_Sampling-Based_Focal_Length_Self-Calibration.html">423 cvpr-2013-Template-Based Isometric Deformable 3D Reconstruction with Sampling-Based Focal Length Self-Calibration</a></p>
<p>16 0.076124057 <a title="349-tfidf-16" href="./cvpr-2013-Uncalibrated_Photometric_Stereo_for_Unknown_Isotropic_Reflectances.html">443 cvpr-2013-Uncalibrated Photometric Stereo for Unknown Isotropic Reflectances</a></p>
<p>17 0.07560873 <a title="349-tfidf-17" href="./cvpr-2013-Depth_Acquisition_from_Density_Modulated_Binary_Patterns.html">114 cvpr-2013-Depth Acquisition from Density Modulated Binary Patterns</a></p>
<p>18 0.07399559 <a title="349-tfidf-18" href="./cvpr-2013-What_Object_Motion_Reveals_about_Shape_with_Unknown_BRDF_and_Lighting.html">465 cvpr-2013-What Object Motion Reveals about Shape with Unknown BRDF and Lighting</a></p>
<p>19 0.073002011 <a title="349-tfidf-19" href="./cvpr-2013-Photometric_Ambient_Occlusion.html">330 cvpr-2013-Photometric Ambient Occlusion</a></p>
<p>20 0.072411664 <a title="349-tfidf-20" href="./cvpr-2013-Specular_Reflection_Separation_Using_Dark_Channel_Prior.html">410 cvpr-2013-Specular Reflection Separation Using Dark Channel Prior</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.129), (1, 0.183), (2, 0.006), (3, 0.036), (4, -0.018), (5, -0.097), (6, -0.056), (7, -0.012), (8, 0.034), (9, 0.056), (10, -0.025), (11, 0.082), (12, 0.117), (13, -0.101), (14, -0.145), (15, 0.046), (16, 0.113), (17, 0.028), (18, 0.009), (19, 0.074), (20, 0.058), (21, -0.002), (22, -0.017), (23, -0.045), (24, -0.017), (25, 0.033), (26, 0.045), (27, 0.03), (28, -0.016), (29, -0.012), (30, -0.01), (31, -0.054), (32, 0.126), (33, -0.037), (34, 0.12), (35, -0.044), (36, 0.051), (37, -0.008), (38, -0.013), (39, -0.035), (40, -0.066), (41, 0.008), (42, -0.036), (43, 0.014), (44, 0.005), (45, 0.03), (46, -0.011), (47, 0.086), (48, 0.033), (49, -0.06)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94814092 <a title="349-lsi-1" href="./cvpr-2013-Reconstructing_Gas_Flows_Using_Light-Path_Approximation.html">349 cvpr-2013-Reconstructing Gas Flows Using Light-Path Approximation</a></p>
<p>Author: Yu Ji, Jinwei Ye, Jingyi Yu</p><p>Abstract: Transparent gas flows are difficult to reconstruct: the refractive index field (RIF) within the gas volume is uneven and rapidly evolving, and correspondence matching under distortions is challenging. We present a novel computational imaging solution by exploiting the light field probe (LFProbe). A LF-probe resembles a view-dependent pattern where each pixel on the pattern maps to a unique ray. By . ude l. edu observing the LF-probe through the gas flow, we acquire a dense set of ray-ray correspondences and then reconstruct their light paths. To recover the RIF, we use Fermat’s Principle to correlate each light path with the RIF via a Partial Differential Equation (PDE). We then develop an iterative optimization scheme to solve for all light-path PDEs in conjunction. Specifically, we initialize the light paths by fitting Hermite splines to ray-ray correspondences, discretize their PDEs onto voxels, and solve a large, over-determined PDE system for the RIF. The RIF can then be used to refine the light paths. Finally, we alternate the RIF and light-path estimations to improve the reconstruction. Experiments on synthetic and real data show that our approach can reliably reconstruct small to medium scale gas flows. In particular, when the flow is acquired by a small number of cameras, the use of ray-ray correspondences can greatly improve the reconstruction.</p><p>2 0.84357536 <a title="349-lsi-2" href="./cvpr-2013-A_Theory_of_Refractive_Photo-Light-Path_Triangulation.html">27 cvpr-2013-A Theory of Refractive Photo-Light-Path Triangulation</a></p>
<p>Author: Visesh Chari, Peter Sturm</p><p>Abstract: 3D reconstruction of transparent refractive objects like a plastic bottle is challenging: they lack appearance related visual cues and merely reflect and refract light from the surrounding environment. Amongst several approaches to reconstruct such objects, the seminal work of Light-Path triangulation [17] is highly popular because of its general applicability and analysis of minimal scenarios. A lightpath is defined as the piece-wise linear path taken by a ray of light as it passes from source, through the object and into the camera. Transparent refractive objects not only affect the geometric configuration of light-paths but also their radiometric properties. In this paper, we describe a method that combines both geometric and radiometric information to do reconstruction. We show two major consequences of the addition of radiometric cues to the light-path setup. Firstly, we extend the case of scenarios in which reconstruction is plausible while reducing the minimal re- quirements for a unique reconstruction. This happens as a consequence of the fact that radiometric cues add an additional known variable to the already existing system of equations. Secondly, we present a simple algorithm for reconstruction, owing to the nature of the radiometric cue. We present several synthetic experiments to validate our theories, and show high quality reconstructions in challenging scenarios.</p><p>3 0.84222817 <a title="349-lsi-3" href="./cvpr-2013-Underwater_Camera_Calibration_Using_Wavelength_Triangulation.html">447 cvpr-2013-Underwater Camera Calibration Using Wavelength Triangulation</a></p>
<p>Author: Timothy Yau, Minglun Gong, Yee-Hong Yang</p><p>Abstract: In underwater imagery, the image formation process includes refractions that occur when light passes from water into the camera housing, typically through a flat glass port. We extend the existing work on physical refraction models by considering the dispersion of light, and derive new constraints on the model parameters for use in calibration. This leads to a novel calibration method that achieves improved accuracy compared to existing work. We describe how to construct a novel calibration device for our method and evaluate the accuracy of the method through synthetic and real experiments.</p><p>4 0.78287822 <a title="349-lsi-4" href="./cvpr-2013-Light_Field_Distortion_Feature_for_Transparent_Object_Recognition.html">269 cvpr-2013-Light Field Distortion Feature for Transparent Object Recognition</a></p>
<p>Author: Kazuki Maeno, Hajime Nagahara, Atsushi Shimada, Rin-Ichiro Taniguchi</p><p>Abstract: Current object-recognition algorithms use local features, such as scale-invariant feature transform (SIFT) and speeded-up robust features (SURF), for visually learning to recognize objects. These approaches though cannot apply to transparent objects made of glass or plastic, as such objects take on the visual features of background objects, and the appearance ofsuch objects dramatically varies with changes in scene background. Indeed, in transmitting light, transparent objects have the unique characteristic of distorting the background by refraction. In this paper, we use a single-shot light?eld image as an input and model the distortion of the light ?eld caused by the refractive property of a transparent object. We propose a new feature, called the light ?eld distortion (LFD) feature, for identifying a transparent object. The proposal incorporates this LFD feature into the bag-of-features approach for recognizing transparent objects. We evaluated its performance in laboratory and real settings.</p><p>5 0.72244978 <a title="349-lsi-5" href="./cvpr-2013-Principal_Observation_Ray_Calibration_for_Tiled-Lens-Array_Integral_Imaging_Display.html">337 cvpr-2013-Principal Observation Ray Calibration for Tiled-Lens-Array Integral Imaging Display</a></p>
<p>Author: Weiming Li, Haitao Wang, Mingcai Zhou, Shandong Wang, Shaohui Jiao, Xing Mei, Tao Hong, Hoyoung Lee, Jiyeun Kim</p><p>Abstract: Integral imaging display (IID) is a promising technology to provide realistic 3D image without glasses. To achieve a large screen IID with a reasonable fabrication cost, a potential solution is a tiled-lens-array IID (TLA-IID). However, TLA-IIDs are subject to 3D image artifacts when there are even slight misalignments between the lens arrays. This work aims at compensating these artifacts by calibrating the lens array poses with a camera and including them in a ray model used for rendering the 3D image. Since the lens arrays are transparent, this task is challenging for traditional calibration methods. In this paper, we propose a novel calibration method based on defining a set of principle observation rays that pass lens centers of the TLA and the camera ’s optical center. The method is able to determine the lens array poses with only one camera at an arbitrary unknown position without using any additional markers. The principle observation rays are automatically extracted using a structured light based method from a dense correspondence map between the displayed and captured . pixels. . com, Experiments show that lens array misalignments xme i nlpr . ia . ac . cn @ can be estimated with a standard deviation smaller than 0.4 pixels. Based on this, 3D image artifacts are shown to be effectively removed in a test TLA-IID with challenging misalignments.</p><p>6 0.70333147 <a title="349-lsi-6" href="./cvpr-2013-Globally_Consistent_Multi-label_Assignment_on_the_Ray_Space_of_4D_Light_Fields.html">188 cvpr-2013-Globally Consistent Multi-label Assignment on the Ray Space of 4D Light Fields</a></p>
<p>7 0.69435167 <a title="349-lsi-7" href="./cvpr-2013-Can_a_Fully_Unconstrained_Imaging_Model_Be_Applied_Effectively_to_Central_Cameras%3F.html">76 cvpr-2013-Can a Fully Unconstrained Imaging Model Be Applied Effectively to Central Cameras?</a></p>
<p>8 0.69160438 <a title="349-lsi-8" href="./cvpr-2013-Decoding%2C_Calibration_and_Rectification_for_Lenselet-Based_Plenoptic_Cameras.html">102 cvpr-2013-Decoding, Calibration and Rectification for Lenselet-Based Plenoptic Cameras</a></p>
<p>9 0.68881851 <a title="349-lsi-9" href="./cvpr-2013-Single_Image_Calibration_of_Multi-axial_Imaging_Systems.html">400 cvpr-2013-Single Image Calibration of Multi-axial Imaging Systems</a></p>
<p>10 0.63857442 <a title="349-lsi-10" href="./cvpr-2013-The_Variational_Structure_of_Disparity_and_Regularization_of_4D_Light_Fields.html">431 cvpr-2013-The Variational Structure of Disparity and Regularization of 4D Light Fields</a></p>
<p>11 0.56678563 <a title="349-lsi-11" href="./cvpr-2013-Mirror_Surface_Reconstruction_from_a_Single_Image.html">286 cvpr-2013-Mirror Surface Reconstruction from a Single Image</a></p>
<p>12 0.56560886 <a title="349-lsi-12" href="./cvpr-2013-Discovering_the_Structure_of_a_Planar_Mirror_System_from_Multiple_Observations_of_a_Single_Point.html">127 cvpr-2013-Discovering the Structure of a Planar Mirror System from Multiple Observations of a Single Point</a></p>
<p>13 0.56191945 <a title="349-lsi-13" href="./cvpr-2013-Megastereo%3A_Constructing_High-Resolution_Stereo_Panoramas.html">283 cvpr-2013-Megastereo: Constructing High-Resolution Stereo Panoramas</a></p>
<p>14 0.55289537 <a title="349-lsi-14" href="./cvpr-2013-Manhattan_Scene_Understanding_via_XSlit_Imaging.html">279 cvpr-2013-Manhattan Scene Understanding via XSlit Imaging</a></p>
<p>15 0.52761364 <a title="349-lsi-15" href="./cvpr-2013-Specular_Reflection_Separation_Using_Dark_Channel_Prior.html">410 cvpr-2013-Specular Reflection Separation Using Dark Channel Prior</a></p>
<p>16 0.52655488 <a title="349-lsi-16" href="./cvpr-2013-Adherent_Raindrop_Detection_and_Removal_in_Video.html">37 cvpr-2013-Adherent Raindrop Detection and Removal in Video</a></p>
<p>17 0.51529735 <a title="349-lsi-17" href="./cvpr-2013-Spectral_Modeling_and_Relighting_of_Reflective-Fluorescent_Scenes.html">409 cvpr-2013-Spectral Modeling and Relighting of Reflective-Fluorescent Scenes</a></p>
<p>18 0.49977934 <a title="349-lsi-18" href="./cvpr-2013-Video_Enhancement_of_People_Wearing_Polarized_Glasses%3A_Darkening_Reversal_and_Reflection_Reduction.html">454 cvpr-2013-Video Enhancement of People Wearing Polarized Glasses: Darkening Reversal and Reflection Reduction</a></p>
<p>19 0.44645253 <a title="349-lsi-19" href="./cvpr-2013-Photometric_Ambient_Occlusion.html">330 cvpr-2013-Photometric Ambient Occlusion</a></p>
<p>20 0.44290683 <a title="349-lsi-20" href="./cvpr-2013-Motion_Estimation_for_Self-Driving_Cars_with_a_Generalized_Camera.html">290 cvpr-2013-Motion Estimation for Self-Driving Cars with a Generalized Camera</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.119), (16, 0.1), (26, 0.05), (33, 0.188), (42, 0.239), (65, 0.01), (66, 0.011), (67, 0.028), (69, 0.023), (77, 0.011), (87, 0.103), (96, 0.012)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.80431014 <a title="349-lda-1" href="./cvpr-2013-Reconstructing_Gas_Flows_Using_Light-Path_Approximation.html">349 cvpr-2013-Reconstructing Gas Flows Using Light-Path Approximation</a></p>
<p>Author: Yu Ji, Jinwei Ye, Jingyi Yu</p><p>Abstract: Transparent gas flows are difficult to reconstruct: the refractive index field (RIF) within the gas volume is uneven and rapidly evolving, and correspondence matching under distortions is challenging. We present a novel computational imaging solution by exploiting the light field probe (LFProbe). A LF-probe resembles a view-dependent pattern where each pixel on the pattern maps to a unique ray. By . ude l. edu observing the LF-probe through the gas flow, we acquire a dense set of ray-ray correspondences and then reconstruct their light paths. To recover the RIF, we use Fermat’s Principle to correlate each light path with the RIF via a Partial Differential Equation (PDE). We then develop an iterative optimization scheme to solve for all light-path PDEs in conjunction. Specifically, we initialize the light paths by fitting Hermite splines to ray-ray correspondences, discretize their PDEs onto voxels, and solve a large, over-determined PDE system for the RIF. The RIF can then be used to refine the light paths. Finally, we alternate the RIF and light-path estimations to improve the reconstruction. Experiments on synthetic and real data show that our approach can reliably reconstruct small to medium scale gas flows. In particular, when the flow is acquired by a small number of cameras, the use of ray-ray correspondences can greatly improve the reconstruction.</p><p>2 0.71022475 <a title="349-lda-2" href="./cvpr-2013-A_Theory_of_Refractive_Photo-Light-Path_Triangulation.html">27 cvpr-2013-A Theory of Refractive Photo-Light-Path Triangulation</a></p>
<p>Author: Visesh Chari, Peter Sturm</p><p>Abstract: 3D reconstruction of transparent refractive objects like a plastic bottle is challenging: they lack appearance related visual cues and merely reflect and refract light from the surrounding environment. Amongst several approaches to reconstruct such objects, the seminal work of Light-Path triangulation [17] is highly popular because of its general applicability and analysis of minimal scenarios. A lightpath is defined as the piece-wise linear path taken by a ray of light as it passes from source, through the object and into the camera. Transparent refractive objects not only affect the geometric configuration of light-paths but also their radiometric properties. In this paper, we describe a method that combines both geometric and radiometric information to do reconstruction. We show two major consequences of the addition of radiometric cues to the light-path setup. Firstly, we extend the case of scenarios in which reconstruction is plausible while reducing the minimal re- quirements for a unique reconstruction. This happens as a consequence of the fact that radiometric cues add an additional known variable to the already existing system of equations. Secondly, we present a simple algorithm for reconstruction, owing to the nature of the radiometric cue. We present several synthetic experiments to validate our theories, and show high quality reconstructions in challenging scenarios.</p><p>3 0.70055401 <a title="349-lda-3" href="./cvpr-2013-Detecting_Pulse_from_Head_Motions_in_Video.html">118 cvpr-2013-Detecting Pulse from Head Motions in Video</a></p>
<p>Author: Guha Balakrishnan, Fredo Durand, John Guttag</p><p>Abstract: We extract heart rate and beat lengths from videos by measuring subtle head motion caused by the Newtonian reaction to the influx of blood at each beat. Our method tracks features on the head and performs principal component analysis (PCA) to decompose their trajectories into a set of component motions. It then chooses the component that best corresponds to heartbeats based on its temporal frequency spectrum. Finally, we analyze the motion projected to this component and identify peaks of the trajectories, which correspond to heartbeats. When evaluated on 18 subjects, our approach reported heart rates nearly identical to an electrocardiogram device. Additionally we were able to capture clinically relevant information about heart rate variability.</p><p>4 0.69951463 <a title="349-lda-4" href="./cvpr-2013-Uncalibrated_Photometric_Stereo_for_Unknown_Isotropic_Reflectances.html">443 cvpr-2013-Uncalibrated Photometric Stereo for Unknown Isotropic Reflectances</a></p>
<p>Author: Feng Lu, Yasuyuki Matsushita, Imari Sato, Takahiro Okabe, Yoichi Sato</p><p>Abstract: We propose an uncalibrated photometric stereo method that works with general and unknown isotropic reflectances. Our method uses a pixel intensity profile, which is a sequence of radiance intensities recorded at a pixel across multi-illuminance images. We show that for general isotropic materials, the geodesic distance between intensity profiles is linearly related to the angular difference of their surface normals, and that the intensity distribution of an intensity profile conveys information about the reflectance properties, when the intensity profile is obtained under uniformly distributed directional lightings. Based on these observations, we show that surface normals can be estimated up to a convex/concave ambiguity. A solution method based on matrix decomposition with missing data is developed for a reliable estimation. Quantitative and qualitative evaluations of our method are performed using both synthetic and real-world scenes.</p><p>5 0.69006085 <a title="349-lda-5" href="./cvpr-2013-The_Variational_Structure_of_Disparity_and_Regularization_of_4D_Light_Fields.html">431 cvpr-2013-The Variational Structure of Disparity and Regularization of 4D Light Fields</a></p>
<p>Author: Bastian Goldluecke, Sven Wanner</p><p>Abstract: Unlike traditional images which do not offer information for different directions of incident light, a light field is defined on ray space, and implicitly encodes scene geometry data in a rich structure which becomes visible on its epipolar plane images. In this work, we analyze regularization of light fields in variational frameworks and show that their variational structure is induced by disparity, which is in this context best understood as a vector field on epipolar plane image space. We derive differential constraints on this vector field to enable consistent disparity map regularization. Furthermore, we show how the disparity field is related to the regularization of more general vector-valued functions on the 4D ray space of the light field. This way, we derive an efficient variational framework with convex priors, which can serve as a fundament for a large class of inverse problems on ray space.</p><p>6 0.68940246 <a title="349-lda-6" href="./cvpr-2013-Multi-view_Photometric_Stereo_with_Spatially_Varying_Isotropic_Materials.html">303 cvpr-2013-Multi-view Photometric Stereo with Spatially Varying Isotropic Materials</a></p>
<p>7 0.68770039 <a title="349-lda-7" href="./cvpr-2013-Robust_Multi-resolution_Pedestrian_Detection_in_Traffic_Scenes.html">363 cvpr-2013-Robust Multi-resolution Pedestrian Detection in Traffic Scenes</a></p>
<p>8 0.68679702 <a title="349-lda-8" href="./cvpr-2013-Mirror_Surface_Reconstruction_from_a_Single_Image.html">286 cvpr-2013-Mirror Surface Reconstruction from a Single Image</a></p>
<p>9 0.68645877 <a title="349-lda-9" href="./cvpr-2013-Locally_Aligned_Feature_Transforms_across_Views.html">271 cvpr-2013-Locally Aligned Feature Transforms across Views</a></p>
<p>10 0.68539971 <a title="349-lda-10" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<p>11 0.68446797 <a title="349-lda-11" href="./cvpr-2013-Motion_Estimation_for_Self-Driving_Cars_with_a_Generalized_Camera.html">290 cvpr-2013-Motion Estimation for Self-Driving Cars with a Generalized Camera</a></p>
<p>12 0.68444598 <a title="349-lda-12" href="./cvpr-2013-Depth_Super_Resolution_by_Rigid_Body_Self-Similarity_in_3D.html">115 cvpr-2013-Depth Super Resolution by Rigid Body Self-Similarity in 3D</a></p>
<p>13 0.68421662 <a title="349-lda-13" href="./cvpr-2013-Globally_Consistent_Multi-label_Assignment_on_the_Ray_Space_of_4D_Light_Fields.html">188 cvpr-2013-Globally Consistent Multi-label Assignment on the Ray Space of 4D Light Fields</a></p>
<p>14 0.68418276 <a title="349-lda-14" href="./cvpr-2013-Single_Image_Calibration_of_Multi-axial_Imaging_Systems.html">400 cvpr-2013-Single Image Calibration of Multi-axial Imaging Systems</a></p>
<p>15 0.68416303 <a title="349-lda-15" href="./cvpr-2013-Principal_Observation_Ray_Calibration_for_Tiled-Lens-Array_Integral_Imaging_Display.html">337 cvpr-2013-Principal Observation Ray Calibration for Tiled-Lens-Array Integral Imaging Display</a></p>
<p>16 0.68414062 <a title="349-lda-16" href="./cvpr-2013-Video_Enhancement_of_People_Wearing_Polarized_Glasses%3A_Darkening_Reversal_and_Reflection_Reduction.html">454 cvpr-2013-Video Enhancement of People Wearing Polarized Glasses: Darkening Reversal and Reflection Reduction</a></p>
<p>17 0.6832692 <a title="349-lda-17" href="./cvpr-2013-Underwater_Camera_Calibration_Using_Wavelength_Triangulation.html">447 cvpr-2013-Underwater Camera Calibration Using Wavelength Triangulation</a></p>
<p>18 0.68320918 <a title="349-lda-18" href="./cvpr-2013-Information_Consensus_for_Distributed_Multi-target_Tracking.html">224 cvpr-2013-Information Consensus for Distributed Multi-target Tracking</a></p>
<p>19 0.68317366 <a title="349-lda-19" href="./cvpr-2013-Physically_Plausible_3D_Scene_Tracking%3A_The_Single_Actor_Hypothesis.html">331 cvpr-2013-Physically Plausible 3D Scene Tracking: The Single Actor Hypothesis</a></p>
<p>20 0.68183655 <a title="349-lda-20" href="./cvpr-2013-Specular_Reflection_Separation_Using_Dark_Channel_Prior.html">410 cvpr-2013-Specular Reflection Separation Using Dark Channel Prior</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
