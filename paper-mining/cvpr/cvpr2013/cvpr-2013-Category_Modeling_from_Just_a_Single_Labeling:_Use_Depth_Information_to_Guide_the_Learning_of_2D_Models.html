<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>80 cvpr-2013-Category Modeling from Just a Single Labeling: Use Depth Information to Guide the Learning of 2D Models</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-80" href="#">cvpr2013-80</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>80 cvpr-2013-Category Modeling from Just a Single Labeling: Use Depth Information to Guide the Learning of 2D Models</h1>
<br/><p>Source: <a title="cvpr-2013-80-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Zhang_Category_Modeling_from_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Quanshi Zhang, Xuan Song, Xiaowei Shao, Ryosuke Shibasaki, Huijing Zhao</p><p>Abstract: An object model base that covers a large number of object categories is of great value for many computer vision tasks. As artifacts are usually designed to have various textures, their structure is the primary distinguishing feature between different categories. Thus, how to encode this structural information and how to start the model learning with a minimum of human labeling become two key challenges for the construction of the model base. We design a graphical model that uses object edges to represent object structures, and this paper aims to incrementally learn this category model from one labeled object and a number of casually captured scenes. However, the incremental model learning may be biased due to the limited human labeling. Therefore, we propose a new strategy that uses the depth information in RGBD images to guide the model learning for object detection in ordinary RGB images. In experiments, the proposed method achieves superior performance as good as the supervised methods that require the labeling of all target objects.</p><p>Reference: <a title="cvpr-2013-80-reference" href="../cvpr2013_reference/cvpr-2013-Category_Modeling_from_Just_a_Single_Labeling%3A_Use_Depth_Information_to_Guide_the_Learning_of_2D_Models_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('rgbd', 0.456), ('nod', 0.19), ('ordin', 0.178), ('jj', 0.161), ('img', 0.156), ('match', 0.147), ('categ', 0.147), ('fij', 0.144), ('nio', 0.125), ('attribut', 0.123), ('centerlin', 0.12), ('compat', 0.119), ('target', 0.118), ('discovery', 0.117), ('patch', 0.116), ('ibs', 0.109), ('superv', 0.107), ('rgb', 0.106), ('leordeanu', 0.103), ('hebert', 0.099)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999946 <a title="80-tfidf-1" href="./cvpr-2013-Category_Modeling_from_Just_a_Single_Labeling%3A_Use_Depth_Information_to_Guide_the_Learning_of_2D_Models.html">80 cvpr-2013-Category Modeling from Just a Single Labeling: Use Depth Information to Guide the Learning of 2D Models</a></p>
<p>Author: Quanshi Zhang, Xuan Song, Xiaowei Shao, Ryosuke Shibasaki, Huijing Zhao</p><p>Abstract: An object model base that covers a large number of object categories is of great value for many computer vision tasks. As artifacts are usually designed to have various textures, their structure is the primary distinguishing feature between different categories. Thus, how to encode this structural information and how to start the model learning with a minimum of human labeling become two key challenges for the construction of the model base. We design a graphical model that uses object edges to represent object structures, and this paper aims to incrementally learn this category model from one labeled object and a number of casually captured scenes. However, the incremental model learning may be biased due to the limited human labeling. Therefore, we propose a new strategy that uses the depth information in RGBD images to guide the model learning for object detection in ordinary RGB images. In experiments, the proposed method achieves superior performance as good as the supervised methods that require the labeling of all target objects.</p><p>2 0.17804831 <a title="80-tfidf-2" href="./cvpr-2013-Graph_Matching_with_Anchor_Nodes%3A_A_Learning_Approach.html">192 cvpr-2013-Graph Matching with Anchor Nodes: A Learning Approach</a></p>
<p>Author: Nan Hu, Raif M. Rustamov, Leonidas Guibas</p><p>Abstract: In this paper, we consider the weighted graph matching problem with partially disclosed correspondences between a number of anchor nodes. Our construction exploits recently introduced node signatures based on graph Laplacians, namely the Laplacian family signature (LFS) on the nodes, and the pairwise heat kernel map on the edges. In this paper, without assuming an explicit form of parametric dependence nor a distance metric between node signatures, we formulate an optimization problem which incorporates the knowledge of anchor nodes. Solving this problem gives us an optimized proximity measure specific to the graphs under consideration. Using this as a first order compatibility term, we then set up an integer quadratic program (IQP) to solve for a near optimal graph matching. Our experiments demonstrate the superior performance of our approach on randomly generated graphs and on two widelyused image sequences, when compared with other existing signature and adjacency matrix based graph matching methods.</p><p>3 0.16869783 <a title="80-tfidf-3" href="./cvpr-2013-Designing_Category-Level_Attributes_for_Discriminative_Visual_Recognition.html">116 cvpr-2013-Designing Category-Level Attributes for Discriminative Visual Recognition</a></p>
<p>Author: Felix X. Yu, Liangliang Cao, Rogerio S. Feris, John R. Smith, Shih-Fu Chang</p><p>Abstract: Attribute-based representation has shown great promises for visual recognition due to its intuitive interpretation and cross-category generalization property. However, human efforts are usually involved in the attribute designing process, making the representation costly to obtain. In this paper, we propose a novel formulation to automatically design discriminative “category-level attributes ”, which can be efficiently encoded by a compact category-attribute matrix. The formulation allows us to achieve intuitive and critical design criteria (category-separability, learnability) in a principled way. The designed attributes can be used for tasks of cross-category knowledge transfer, achieving superior performance over well-known attribute dataset Animals with Attributes (AwA) and a large-scale ILSVRC2010 dataset (1.2M images). This approach also leads to state-ofthe-art performance on the zero-shot learning task on AwA.</p><p>4 0.16569053 <a title="80-tfidf-4" href="./cvpr-2013-Deformable_Spatial_Pyramid_Matching_for_Fast_Dense_Correspondences.html">107 cvpr-2013-Deformable Spatial Pyramid Matching for Fast Dense Correspondences</a></p>
<p>Author: Jaechul Kim, Ce Liu, Fei Sha, Kristen Grauman</p><p>Abstract: We introduce a fast deformable spatial pyramid (DSP) matching algorithm for computing dense pixel correspondences. Dense matching methods typically enforce both appearance agreement between matched pixels as well as geometric smoothness between neighboring pixels. Whereas the prevailing approaches operate at the pixel level, we propose a pyramid graph model that simultaneously regularizes match consistency at multiple spatial extents—ranging from an entire image, to coarse grid cells, to every single pixel. This novel regularization substantially improves pixel-level matching in the face of challenging image variations, while the “deformable ” aspect of our model overcomes the strict rigidity of traditional spatial pyramids. Results on LabelMe and Caltech show our approach outperforms state-of-the-art methods (SIFT Flow [15] and PatchMatch [2]), both in terms of accuracy and run time.</p><p>5 0.15907034 <a title="80-tfidf-5" href="./cvpr-2013-Fast_Energy_Minimization_Using_Learned_State_Filters.html">165 cvpr-2013-Fast Energy Minimization Using Learned State Filters</a></p>
<p>Author: Matthieu Guillaumin, Luc Van_Gool, Vittorio Ferrari</p><p>Abstract: Pairwise discrete energies defined over graphs are ubiquitous in computer vision. Many algorithms have been proposed to minimize such energies, often concentrating on sparse graph topologies or specialized classes of pairwise potentials. However, when the graph is fully connected and the pairwise potentials are arbitrary, the complexity of even approximate minimization algorithms such as TRW-S grows quadratically both in the number of nodes and in the number of states a node can take. Moreover, recent applications are using more and more computationally expensive pairwise potentials. These factors make it very hard to employ fully connected models. In this paper we propose a novel, generic algorithm to approximately minimize any discrete pairwise energy function. Our method exploits tractable sub-energies to filter the domain of the function. The parameters of the filter are learnt from instances of the same class of energies with good candidate solutions. Compared to existing methods, it efficiently handles fully connected graphs, with many states per node, and arbitrary pairwise potentials, which might be expensive to compute. We demonstrate experimentally on two applications that our algorithm is much more efficient than other generic minimization algorithms such as TRW-S, while returning essentially identical solutions.</p><p>6 0.15723984 <a title="80-tfidf-6" href="./cvpr-2013-Adding_Unlabeled_Samples_to_Categories_by_Learned_Attributes.html">36 cvpr-2013-Adding Unlabeled Samples to Categories by Learned Attributes</a></p>
<p>7 0.15018409 <a title="80-tfidf-7" href="./cvpr-2013-Probabilistic_Label_Trees_for_Efficient_Large_Scale_Image_Classification.html">340 cvpr-2013-Probabilistic Label Trees for Efficient Large Scale Image Classification</a></p>
<p>8 0.14493385 <a title="80-tfidf-8" href="./cvpr-2013-Semi-supervised_Learning_of_Feature_Hierarchies_for_Object_Detection_in_a_Video.html">388 cvpr-2013-Semi-supervised Learning of Feature Hierarchies for Object Detection in a Video</a></p>
<p>9 0.13487723 <a title="80-tfidf-9" href="./cvpr-2013-Weakly_Supervised_Learning_for_Attribute_Localization_in_Outdoor_Scenes.html">461 cvpr-2013-Weakly Supervised Learning for Attribute Localization in Outdoor Scenes</a></p>
<p>10 0.13482599 <a title="80-tfidf-10" href="./cvpr-2013-Representing_Videos_Using_Mid-level_Discriminative_Patches.html">355 cvpr-2013-Representing Videos Using Mid-level Discriminative Patches</a></p>
<p>11 0.13106227 <a title="80-tfidf-11" href="./cvpr-2013-Simultaneous_Active_Learning_of_Classifiers_%26_Attributes_via_Relative_Feedback.html">396 cvpr-2013-Simultaneous Active Learning of Classifiers & Attributes via Relative Feedback</a></p>
<p>12 0.12774144 <a title="80-tfidf-12" href="./cvpr-2013-Learning_Class-to-Image_Distance_with_Object_Matchings.html">247 cvpr-2013-Learning Class-to-Image Distance with Object Matchings</a></p>
<p>13 0.12339488 <a title="80-tfidf-13" href="./cvpr-2013-Expanded_Parts_Model_for_Human_Attribute_and_Action_Recognition_in_Still_Images.html">153 cvpr-2013-Expanded Parts Model for Human Attribute and Action Recognition in Still Images</a></p>
<p>14 0.1229768 <a title="80-tfidf-14" href="./cvpr-2013-Enriching_Texture_Analysis_with_Semantic_Data.html">146 cvpr-2013-Enriching Texture Analysis with Semantic Data</a></p>
<p>15 0.12223771 <a title="80-tfidf-15" href="./cvpr-2013-Multi-target_Tracking_by_Lagrangian_Relaxation_to_Min-cost_Network_Flow.html">300 cvpr-2013-Multi-target Tracking by Lagrangian Relaxation to Min-cost Network Flow</a></p>
<p>16 0.11969489 <a title="80-tfidf-16" href="./cvpr-2013-Fully-Connected_CRFs_with_Non-Parametric_Pairwise_Potential.html">180 cvpr-2013-Fully-Connected CRFs with Non-Parametric Pairwise Potential</a></p>
<p>17 0.11761614 <a title="80-tfidf-17" href="./cvpr-2013-Understanding_Indoor_Scenes_Using_3D_Geometric_Phrases.html">446 cvpr-2013-Understanding Indoor Scenes Using 3D Geometric Phrases</a></p>
<p>18 0.11759048 <a title="80-tfidf-18" href="./cvpr-2013-Part_Discovery_from_Partial_Correspondence.html">325 cvpr-2013-Part Discovery from Partial Correspondence</a></p>
<p>19 0.11128806 <a title="80-tfidf-19" href="./cvpr-2013-Information_Consensus_for_Distributed_Multi-target_Tracking.html">224 cvpr-2013-Information Consensus for Distributed Multi-target Tracking</a></p>
<p>20 0.11067583 <a title="80-tfidf-20" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.302), (1, 0.006), (2, 0.049), (3, 0.011), (4, 0.133), (5, -0.02), (6, 0.013), (7, -0.035), (8, -0.06), (9, 0.008), (10, 0.029), (11, -0.025), (12, -0.092), (13, 0.026), (14, -0.043), (15, -0.045), (16, 0.143), (17, -0.003), (18, 0.035), (19, 0.069), (20, 0.053), (21, 0.019), (22, 0.056), (23, 0.079), (24, -0.028), (25, 0.061), (26, -0.028), (27, 0.068), (28, 0.068), (29, -0.049), (30, -0.088), (31, 0.043), (32, -0.006), (33, 0.129), (34, -0.088), (35, -0.105), (36, 0.014), (37, 0.052), (38, -0.04), (39, -0.01), (40, -0.007), (41, 0.088), (42, 0.06), (43, 0.02), (44, -0.062), (45, -0.002), (46, 0.004), (47, -0.008), (48, 0.061), (49, 0.024)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93502289 <a title="80-lsi-1" href="./cvpr-2013-Category_Modeling_from_Just_a_Single_Labeling%3A_Use_Depth_Information_to_Guide_the_Learning_of_2D_Models.html">80 cvpr-2013-Category Modeling from Just a Single Labeling: Use Depth Information to Guide the Learning of 2D Models</a></p>
<p>Author: Quanshi Zhang, Xuan Song, Xiaowei Shao, Ryosuke Shibasaki, Huijing Zhao</p><p>Abstract: An object model base that covers a large number of object categories is of great value for many computer vision tasks. As artifacts are usually designed to have various textures, their structure is the primary distinguishing feature between different categories. Thus, how to encode this structural information and how to start the model learning with a minimum of human labeling become two key challenges for the construction of the model base. We design a graphical model that uses object edges to represent object structures, and this paper aims to incrementally learn this category model from one labeled object and a number of casually captured scenes. However, the incremental model learning may be biased due to the limited human labeling. Therefore, we propose a new strategy that uses the depth information in RGBD images to guide the model learning for object detection in ordinary RGB images. In experiments, the proposed method achieves superior performance as good as the supervised methods that require the labeling of all target objects.</p><p>2 0.78070241 <a title="80-lsi-2" href="./cvpr-2013-Graph_Matching_with_Anchor_Nodes%3A_A_Learning_Approach.html">192 cvpr-2013-Graph Matching with Anchor Nodes: A Learning Approach</a></p>
<p>Author: Nan Hu, Raif M. Rustamov, Leonidas Guibas</p><p>Abstract: In this paper, we consider the weighted graph matching problem with partially disclosed correspondences between a number of anchor nodes. Our construction exploits recently introduced node signatures based on graph Laplacians, namely the Laplacian family signature (LFS) on the nodes, and the pairwise heat kernel map on the edges. In this paper, without assuming an explicit form of parametric dependence nor a distance metric between node signatures, we formulate an optimization problem which incorporates the knowledge of anchor nodes. Solving this problem gives us an optimized proximity measure specific to the graphs under consideration. Using this as a first order compatibility term, we then set up an integer quadratic program (IQP) to solve for a near optimal graph matching. Our experiments demonstrate the superior performance of our approach on randomly generated graphs and on two widelyused image sequences, when compared with other existing signature and adjacency matrix based graph matching methods.</p><p>3 0.76036507 <a title="80-lsi-3" href="./cvpr-2013-Deformable_Spatial_Pyramid_Matching_for_Fast_Dense_Correspondences.html">107 cvpr-2013-Deformable Spatial Pyramid Matching for Fast Dense Correspondences</a></p>
<p>Author: Jaechul Kim, Ce Liu, Fei Sha, Kristen Grauman</p><p>Abstract: We introduce a fast deformable spatial pyramid (DSP) matching algorithm for computing dense pixel correspondences. Dense matching methods typically enforce both appearance agreement between matched pixels as well as geometric smoothness between neighboring pixels. Whereas the prevailing approaches operate at the pixel level, we propose a pyramid graph model that simultaneously regularizes match consistency at multiple spatial extents—ranging from an entire image, to coarse grid cells, to every single pixel. This novel regularization substantially improves pixel-level matching in the face of challenging image variations, while the “deformable ” aspect of our model overcomes the strict rigidity of traditional spatial pyramids. Results on LabelMe and Caltech show our approach outperforms state-of-the-art methods (SIFT Flow [15] and PatchMatch [2]), both in terms of accuracy and run time.</p><p>4 0.72928721 <a title="80-lsi-4" href="./cvpr-2013-Deformable_Graph_Matching.html">106 cvpr-2013-Deformable Graph Matching</a></p>
<p>Author: Feng Zhou, Fernando De_la_Torre</p><p>Abstract: Graph matching (GM) is a fundamental problem in computer science, and it has been successfully applied to many problems in computer vision. Although widely used, existing GM algorithms cannot incorporate global consistence among nodes, which is a natural constraint in computer vision problems. This paper proposes deformable graph matching (DGM), an extension of GM for matching graphs subject to global rigid and non-rigid geometric constraints. The key idea of this work is a new factorization of the pair-wise affinity matrix. This factorization decouples the affinity matrix into the local structure of each graph and the pair-wise affinity edges. Besides the ability to incorporate global geometric transformations, this factorization offers three more benefits. First, there is no need to compute the costly (in space and time) pair-wise affinity matrix. Second, it provides a unified view of many GM methods and extends the standard iterative closest point algorithm. Third, it allows to use the path-following optimization algorithm that leads to improved optimization strategies and matching performance. Experimental results on synthetic and real databases illustrate how DGM outperforms state-of-the-art algorithms for GM. The code is available at http : / / human s en s ing . c s . cmu .edu / fgm.</p><p>5 0.72513676 <a title="80-lsi-5" href="./cvpr-2013-Probabilistic_Label_Trees_for_Efficient_Large_Scale_Image_Classification.html">340 cvpr-2013-Probabilistic Label Trees for Efficient Large Scale Image Classification</a></p>
<p>Author: Baoyuan Liu, Fereshteh Sadeghi, Marshall Tappen, Ohad Shamir, Ce Liu</p><p>Abstract: Large-scale recognition problems with thousands of classes pose a particular challenge because applying the classifier requires more computation as the number of classes grows. The label tree model integrates classification with the traversal of the tree so that complexity grows logarithmically. In this paper, we show how the parameters of the label tree can be found using maximum likelihood estimation. This new probabilistic learning technique produces a label tree with significantly improved recognition accuracy.</p><p>6 0.70851672 <a title="80-lsi-6" href="./cvpr-2013-Maximum_Cohesive_Grid_of_Superpixels_for_Fast_Object_Localization.html">280 cvpr-2013-Maximum Cohesive Grid of Superpixels for Fast Object Localization</a></p>
<p>7 0.68258804 <a title="80-lsi-7" href="./cvpr-2013-Learning_Class-to-Image_Distance_with_Object_Matchings.html">247 cvpr-2013-Learning Class-to-Image Distance with Object Matchings</a></p>
<p>8 0.66984081 <a title="80-lsi-8" href="./cvpr-2013-Weakly_Supervised_Learning_for_Attribute_Localization_in_Outdoor_Scenes.html">461 cvpr-2013-Weakly Supervised Learning for Attribute Localization in Outdoor Scenes</a></p>
<p>9 0.66772711 <a title="80-lsi-9" href="./cvpr-2013-Discriminatively_Trained_And-Or_Tree_Models_for_Object_Detection.html">136 cvpr-2013-Discriminatively Trained And-Or Tree Models for Object Detection</a></p>
<p>10 0.65937686 <a title="80-lsi-10" href="./cvpr-2013-Gauging_Association_Patterns_of_Chromosome_Territories_via_Chromatic_Median.html">184 cvpr-2013-Gauging Association Patterns of Chromosome Territories via Chromatic Median</a></p>
<p>11 0.65491402 <a title="80-lsi-11" href="./cvpr-2013-Incorporating_Structural_Alternatives_and_Sharing_into_Hierarchy_for_Multiclass_Object_Recognition_and_Detection.html">221 cvpr-2013-Incorporating Structural Alternatives and Sharing into Hierarchy for Multiclass Object Recognition and Detection</a></p>
<p>12 0.65345615 <a title="80-lsi-12" href="./cvpr-2013-Consensus_of_k-NNs_for_Robust_Neighborhood_Selection_on_Graph-Based_Manifolds.html">91 cvpr-2013-Consensus of k-NNs for Robust Neighborhood Selection on Graph-Based Manifolds</a></p>
<p>13 0.63830435 <a title="80-lsi-13" href="./cvpr-2013-Graph_Transduction_Learning_with_Connectivity_Constraints_with_Application_to_Multiple_Foreground_Cosegmentation.html">193 cvpr-2013-Graph Transduction Learning with Connectivity Constraints with Application to Multiple Foreground Cosegmentation</a></p>
<p>14 0.63789272 <a title="80-lsi-14" href="./cvpr-2013-Fully-Connected_CRFs_with_Non-Parametric_Pairwise_Potential.html">180 cvpr-2013-Fully-Connected CRFs with Non-Parametric Pairwise Potential</a></p>
<p>15 0.63656658 <a title="80-lsi-15" href="./cvpr-2013-GRASP_Recurring_Patterns_from_a_Single_View.html">183 cvpr-2013-GRASP Recurring Patterns from a Single View</a></p>
<p>16 0.6259892 <a title="80-lsi-16" href="./cvpr-2013-Fast_Energy_Minimization_Using_Learned_State_Filters.html">165 cvpr-2013-Fast Energy Minimization Using Learned State Filters</a></p>
<p>17 0.62553543 <a title="80-lsi-17" href="./cvpr-2013-Information_Consensus_for_Distributed_Multi-target_Tracking.html">224 cvpr-2013-Information Consensus for Distributed Multi-target Tracking</a></p>
<p>18 0.62135589 <a title="80-lsi-18" href="./cvpr-2013-Discriminative_Brain_Effective_Connectivity_Analysis_for_Alzheimer%27s_Disease%3A_A_Kernel_Learning_Approach_upon_Sparse_Gaussian_Bayesian_Network.html">129 cvpr-2013-Discriminative Brain Effective Connectivity Analysis for Alzheimer's Disease: A Kernel Learning Approach upon Sparse Gaussian Bayesian Network</a></p>
<p>19 0.61443478 <a title="80-lsi-19" href="./cvpr-2013-Understanding_Indoor_Scenes_Using_3D_Geometric_Phrases.html">446 cvpr-2013-Understanding Indoor Scenes Using 3D Geometric Phrases</a></p>
<p>20 0.61315751 <a title="80-lsi-20" href="./cvpr-2013-Scene_Text_Recognition_Using_Part-Based_Tree-Structured_Character_Detection.html">382 cvpr-2013-Scene Text Recognition Using Part-Based Tree-Structured Character Detection</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.087), (4, 0.07), (5, 0.163), (37, 0.087), (81, 0.036), (86, 0.048), (95, 0.334), (97, 0.098)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.82981938 <a title="80-lda-1" href="./cvpr-2013-Deep_Learning_Shape_Priors_for_Object_Segmentation.html">105 cvpr-2013-Deep Learning Shape Priors for Object Segmentation</a></p>
<p>Author: Fei Chen, Huimin Yu, Roland Hu, Xunxun Zeng</p><p>Abstract: In this paper we introduce a new shape-driven approach for object segmentation. Given a training set of shapes, we first use deep Boltzmann machine to learn the hierarchical architecture of shape priors. This learned hierarchical architecture is then used to model shape variations of global and local structures in an energetic form. Finally, it is applied to data-driven variational methods to perform object extraction of corrupted data based on shape probabilistic representation. Experiments demonstrate that our model can be applied to dataset of arbitrary prior shapes, and can cope with image noise and clutter, as well as partial occlusions.</p><p>2 0.7837677 <a title="80-lda-2" href="./cvpr-2013-3D_Pictorial_Structures_for_Multiple_View_Articulated_Pose_Estimation.html">2 cvpr-2013-3D Pictorial Structures for Multiple View Articulated Pose Estimation</a></p>
<p>Author: Magnus Burenius, Josephine Sullivan, Stefan Carlsson</p><p>Abstract: We consider the problem of automatically estimating the 3D pose of humans from images, taken from multiple calibrated views. We show that it is possible and tractable to extend the pictorial structures framework, popular for 2D pose estimation, to 3D. We discuss how to use this framework to impose view, skeleton, joint angle and intersection constraints in 3D. The 3D pictorial structures are evaluated on multiple view data from a professional football game. The evaluation is focused on computational tractability, but we also demonstrate how a simple 2D part detector can be plugged into the framework.</p><p>3 0.75775993 <a title="80-lda-3" href="./cvpr-2013-Robust_Region_Grouping_via_Internal_Patch_Statistics.html">366 cvpr-2013-Robust Region Grouping via Internal Patch Statistics</a></p>
<p>Author: Xiaobai Liu, Liang Lin, Alan L. Yuille</p><p>Abstract: In this work, we present an efficient multi-scale low-rank representation for image segmentation. Our method begins with partitioning the input images into a set of superpixels, followed by seeking the optimal superpixel-pair affinity matrix, both of which are performed at multiple scales of the input images. Since low-level superpixel features are usually corrupted by image noises, we propose to infer the low-rank refined affinity matrix. The inference is guided by two observations on natural images. First, looking into a single image, local small-size image patterns tend to recur frequently within the same semantic region, but may not appear in semantically different regions. We call this internal image statistics as replication prior, and quantitatively justify it on real image databases. Second, the affinity matrices at different scales should be consistently solved, which leads to the cross-scale consistency constraint. We formulate these two purposes with one unified formulation and develop an efficient optimization procedure. Our experiments demonstrate the presented method can substantially improve segmentation accuracy.</p><p>4 0.75538439 <a title="80-lda-4" href="./cvpr-2013-Three-Dimensional_Bilateral_Symmetry_Plane_Estimation_in_the_Phase_Domain.html">432 cvpr-2013-Three-Dimensional Bilateral Symmetry Plane Estimation in the Phase Domain</a></p>
<p>Author: Ramakrishna Kakarala, Prabhu Kaliamoorthi, Vittal Premachandran</p><p>Abstract: We show that bilateral symmetry plane estimation for three-dimensional (3-D) shapes may be carried out accurately, and efficiently, in the spherical harmonic domain. Our methods are valuable for applications where spherical harmonic expansion is already employed, such as 3-D shape registration, morphometry, and retrieval. We show that the presence of bilateral symmetry in the 3-D shape is equivalent to a linear phase structure in the corresponding spherical harmonic coefficients, and provide algorithms for estimating the orientation of the symmetry plane. The benefit of using spherical harmonic phase is that symmetry estimation reduces to matching a compact set of descriptors, without the need to solve a correspondence problem. Our methods work on point clouds as well as large-scale mesh models of 3-D shapes.</p><p>5 0.74844491 <a title="80-lda-5" href="./cvpr-2013-Supervised_Descent_Method_and_Its_Applications_to_Face_Alignment.html">420 cvpr-2013-Supervised Descent Method and Its Applications to Face Alignment</a></p>
<p>Author: Xuehan Xiong, Fernando De_la_Torre</p><p>Abstract: Many computer vision problems (e.g., camera calibration, image alignment, structure from motion) are solved through a nonlinear optimization method. It is generally accepted that 2nd order descent methods are the most robust, fast and reliable approaches for nonlinear optimization ofa general smoothfunction. However, in the context of computer vision, 2nd order descent methods have two main drawbacks: (1) The function might not be analytically differentiable and numerical approximations are impractical. (2) The Hessian might be large and not positive definite. To address these issues, thispaperproposes a Supervised Descent Method (SDM) for minimizing a Non-linear Least Squares (NLS) function. During training, the SDM learns a sequence of descent directions that minimizes the mean of NLS functions sampled at different points. In testing, SDM minimizes the NLS objective using the learned descent directions without computing the Jacobian nor the Hessian. We illustrate the benefits of our approach in synthetic and real examples, and show how SDM achieves state-ofthe-art performance in the problem of facial feature detec- tion. The code is available at www. .human sen sin g. . cs . cmu . edu/in t ra fa ce.</p><p>same-paper 6 0.72396368 <a title="80-lda-6" href="./cvpr-2013-Category_Modeling_from_Just_a_Single_Labeling%3A_Use_Depth_Information_to_Guide_the_Learning_of_2D_Models.html">80 cvpr-2013-Category Modeling from Just a Single Labeling: Use Depth Information to Guide the Learning of 2D Models</a></p>
<p>7 0.7062372 <a title="80-lda-7" href="./cvpr-2013-Robust_Discriminative_Response_Map_Fitting_with_Constrained_Local_Models.html">359 cvpr-2013-Robust Discriminative Response Map Fitting with Constrained Local Models</a></p>
<p>8 0.69479144 <a title="80-lda-8" href="./cvpr-2013-SLAM%2B%2B%3A_Simultaneous_Localisation_and_Mapping_at_the_Level_of_Objects.html">372 cvpr-2013-SLAM++: Simultaneous Localisation and Mapping at the Level of Objects</a></p>
<p>9 0.61327559 <a title="80-lda-9" href="./cvpr-2013-Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking.html">285 cvpr-2013-Minimum Uncertainty Gap for Robust Visual Tracking</a></p>
<p>10 0.61316466 <a title="80-lda-10" href="./cvpr-2013-Dense_Non-rigid_Point-Matching_Using_Random_Projections.html">109 cvpr-2013-Dense Non-rigid Point-Matching Using Random Projections</a></p>
<p>11 0.61189169 <a title="80-lda-11" href="./cvpr-2013-Lost%21_Leveraging_the_Crowd_for_Probabilistic_Visual_Self-Localization.html">274 cvpr-2013-Lost! Leveraging the Crowd for Probabilistic Visual Self-Localization</a></p>
<p>12 0.61109567 <a title="80-lda-12" href="./cvpr-2013-Discrete_MRF_Inference_of_Marginal_Densities_for_Non-uniformly_Discretized_Variable_Space.html">128 cvpr-2013-Discrete MRF Inference of Marginal Densities for Non-uniformly Discretized Variable Space</a></p>
<p>13 0.61027896 <a title="80-lda-13" href="./cvpr-2013-Submodular_Salient_Region_Detection.html">418 cvpr-2013-Submodular Salient Region Detection</a></p>
<p>14 0.60925061 <a title="80-lda-14" href="./cvpr-2013-Correspondence-Less_Non-rigid_Registration_of_Triangular_Surface_Meshes.html">97 cvpr-2013-Correspondence-Less Non-rigid Registration of Triangular Surface Meshes</a></p>
<p>15 0.60764086 <a title="80-lda-15" href="./cvpr-2013-A_Higher-Order_CRF_Model_for_Road_Network_Extraction.html">13 cvpr-2013-A Higher-Order CRF Model for Road Network Extraction</a></p>
<p>16 0.60680747 <a title="80-lda-16" href="./cvpr-2013-Depth_Super_Resolution_by_Rigid_Body_Self-Similarity_in_3D.html">115 cvpr-2013-Depth Super Resolution by Rigid Body Self-Similarity in 3D</a></p>
<p>17 0.60395724 <a title="80-lda-17" href="./cvpr-2013-A_Video_Representation_Using_Temporal_Superpixels.html">29 cvpr-2013-A Video Representation Using Temporal Superpixels</a></p>
<p>18 0.60089505 <a title="80-lda-18" href="./cvpr-2013-Exploring_Compositional_High_Order_Pattern_Potentials_for_Structured_Output_Learning.html">156 cvpr-2013-Exploring Compositional High Order Pattern Potentials for Structured Output Learning</a></p>
<p>19 0.60061526 <a title="80-lda-19" href="./cvpr-2013-City-Scale_Change_Detection_in_Cadastral_3D_Models_Using_Images.html">81 cvpr-2013-City-Scale Change Detection in Cadastral 3D Models Using Images</a></p>
<p>20 0.60032433 <a title="80-lda-20" href="./cvpr-2013-Poselet_Conditioned_Pictorial_Structures.html">335 cvpr-2013-Poselet Conditioned Pictorial Structures</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
