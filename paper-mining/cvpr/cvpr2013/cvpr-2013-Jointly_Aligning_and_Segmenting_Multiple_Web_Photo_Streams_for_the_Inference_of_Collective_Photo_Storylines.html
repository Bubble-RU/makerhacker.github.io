<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>235 cvpr-2013-Jointly Aligning and Segmenting Multiple Web Photo Streams for the Inference of Collective Photo Storylines</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-235" href="#">cvpr2013-235</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>235 cvpr-2013-Jointly Aligning and Segmenting Multiple Web Photo Streams for the Inference of Collective Photo Storylines</h1>
<br/><p>Source: <a title="cvpr-2013-235-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Kim_Jointly_Aligning_and_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Gunhee Kim, Eric P. Xing</p><p>Abstract: With an explosion of popularity of online photo sharing, we can trivially collect a huge number of photo streams for any interesting topics such as scuba diving as an outdoor recreational activity class. Obviously, the retrieved photo streams are neither aligned nor calibrated since they are taken in different temporal, spatial, and personal perspectives. However, at the same time, they are likely to share common storylines that consist of sequences of events and activities frequently recurred within the topic. In this paper, as a first technical step to detect such collective storylines, we propose an approach to jointly aligning and segmenting uncalibrated multiple photo streams. The alignment task discovers the matched images between different photo streams, and the image segmentation task parses each image into multiple meaningful regions to facilitate the image understanding. We close a loop between the two tasks so that solving one task helps enhance the performance of the other in a mutually rewarding way. To this end, we design a scalable message-passing based optimization framework to jointly achieve both tasks for the whole input image set at once. With evaluation on the new Flickr dataset of 15 outdoor activities that consist of 1.5 millions of images of 13 thousands of photo streams, our empirical results show that the proposed algorithms are more successful than other candidate methods for both tasks.</p><p>Reference: <a title="cvpr-2013-235-reference" href="../cvpr2013_reference/cvpr-2013-Jointly_Aligning_and_Segmenting_Multiple_Web_Photo_Streams_for_the_Inference_of_Collective_Photo_Storylines_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract With an explosion of popularity of online photo sharing, we can trivially collect a huge number of photo streams for any interesting topics such as scuba diving as an outdoor recreational activity class. [sent-4, score-2.053]
</p><p>2 Obviously, the retrieved photo streams are neither aligned nor calibrated since they are taken in different temporal, spatial, and personal perspectives. [sent-5, score-1.132]
</p><p>3 In this paper, as a first technical step to detect such collective storylines, we propose an approach to jointly aligning and segmenting uncalibrated multiple photo streams. [sent-7, score-0.822]
</p><p>4 The alignment task discovers the matched images between different photo streams, and the image segmentation task parses each image into multiple meaningful regions to facilitate the image understanding. [sent-8, score-0.858]
</p><p>5 5 millions of images of 13 thousands of photo streams, our empirical results show that the proposed algorithms are more successful than other candidate methods for both tasks. [sent-12, score-0.641]
</p><p>6 Introduction As online sharing of personal photo streams is becoming popular, many of such photo streams often share overlapping contents. [sent-14, score-2.198]
</p><p>7 For example, one can easily download a huge number of photo streams associated with the query term scuba+diving from any photo sharing sites such as Flickr. [sent-15, score-1.696]
</p><p>8 The retrieved photo streams record various events and activities associated with scuba+diving, which are captured by different people from their unique experiences. [sent-16, score-1.132]
</p><p>9 Obviously, the photo streams are neither aligned nor calibrated since they are taken in different temporal, spatial, and personal  Figure 1. [sent-17, score-1.132]
</p><p>10 Motivation for jointly aligning and segmenting multiple photo streams with an example of three photo streams of scuba+diving. [sent-18, score-2.291]
</p><p>11 The input is any number of photo streams of a specific activity that are taken by various users at different time and places. [sent-19, score-1.136]
</p><p>12 The images of different photo streams are matched (as shown in the same colors). [sent-22, score-1.103]
</p><p>13 However, at the same time, they are likely to share common storylines consisting of sequences of events and activities repeatedly recurred across the scuba+diving photo streams (e. [sent-26, score-1.339]
</p><p>14 The construction of such photo storylines can potentiate a variety of applications. [sent-29, score-0.777]
</p><p>15 Therefore our challenging goal is to build such collective storylines from the photo streams of millions of users,  and to discover the relations between the reconstructed storylines and photo streams of individual users. [sent-32, score-2.564]
</p><p>16 In this pa666121880  per, as a first technical step to achieve this ultimate goal, we propose a method to jointly perform alignment of multiple photo streams and cosegmentation of aligned images, as shown in Fig. [sent-33, score-1.65]
</p><p>17 In the alignment step, images of different photo sets are matched based on visual contents and associated meta-data. [sent-35, score-0.827]
</p><p>18 The alignment is a core task to build a big picture of storylines from a large number of fragmented photo streams of individual users. [sent-36, score-1.421]
</p><p>19 In the cosegmentation step, the aligned images are segmented together in order to facilitate image understanding such as pixel-level classification in the images. [sent-37, score-0.352]
</p><p>20 The main challenge of cosegmenting multiple photo streams is that the Web images by general users are too diverse to segment all at once. [sent-39, score-1.154]
</p><p>21 Conversely, once we parse each image into multiple segments, image matching, a basic operation for the photo stream alignment can be improved. [sent-42, score-0.981]
</p><p>22 In our approach, photo stream alignment and image  cosegmentation are achieved in a similar way. [sent-44, score-1.268]
</p><p>23 For the alignment, we first establish a sparse graph that connects similar photo streams to be aligned together as a Markov random field. [sent-45, score-1.19]
</p><p>24 Then, we perform belief propagation to jointly align all photo steams at once. [sent-46, score-0.738]
</p><p>25 Then, we perform cosegmentation of the entire image set all at once under the guidance of the graph by a message-passing style optimization. [sent-48, score-0.323]
</p><p>26 5 millions of images of 13 thousands of photo streams regarding 15 outdoor recreational activities from Flickr. [sent-50, score-1.262]
</p><p>27 Our experiments in Section 5 demonstrate that our approach outperforms other candidate methods on both photo stream alignment and image cosegmentation. [sent-51, score-0.981]
</p><p>28 Previous work While there has been little work on jointly aligning and segmenting multiple photo streams, the following two lines of research are remotely related to our work. [sent-54, score-0.753]
</p><p>29 Cosegmentation: Our problem involves segmenting aligned photo streams together. [sent-55, score-1.156]
</p><p>30 It resembles the cosegmentation problem [1, 8, 10, 11, 15, 20], whose objective is to jointly segment recurring objects (or foregrounds) that are shared in multiple images. [sent-56, score-0.376]
</p><p>31 First, we focus on segmentation of unordered  multiple Web photo streams. [sent-58, score-0.649]
</p><p>32 The cosegmentation of Flickr photo streams was discussed in [10], but it was applied to at most 20 images that are manually selected out of hundreds ofpictures of a single Flickr photo stream. [sent-59, score-1.983]
</p><p>33 In contrast, here we can handle an arbitrary number ofuncalibrated Web photo streams by closing the loop between segmentation and photo stream alignment. [sent-60, score-1.93]
</p><p>34 Second, in our experiments, we perform scalable segmentation with more than 100K images of 1K photo streams, which exceeds those of previous work by two orders of magnitude. [sent-61, score-0.672]
</p><p>35 However, their objectives of the image alignment are quite different from ours, which is to integrate with a subsequent image segmentation to infer common storylines of outdoor activities. [sent-66, score-0.43]
</p><p>36 As far as we know, [21] is one of the very few papers that involve the alignment of multiple photo streams. [sent-67, score-0.802]
</p><p>37 12 classes with less than 10 photo streams per class) compared to ours (i. [sent-70, score-1.078]
</p><p>38 15 outdoor activities with 1K photo streams per activity). [sent-72, score-1.188]
</p><p>39 (1) We propose an approach to jointly aligning and segmenting large-scale Web photo streams of different users. [sent-77, score-1.213]
</p><p>40 Compared to previous cosegmentation research, our approach can handle any number of uncalibrated photo streams. [sent-78, score-0.934]
</p><p>41 Compared to existing image alignment research, our work can widen its applicability for reconstructing collective storylines from multiple photo streams by closing the loop with cosegmentation in a mutually rewarding way. [sent-79, score-1.801]
</p><p>42 (2) We propose large-scale alignment and cosegmentation algorithms that jointly work on the whole dataset by using message-passing based optimization. [sent-80, score-0.515]
</p><p>43 The algorithms are scalable; they run in a linear time with the number of photo streams and images, respectively. [sent-81, score-1.078]
</p><p>44 Our largest experiments run on more than 100K images of 1K photo streams, which exceed those of previous work by orders of magnitude. [sent-83, score-0.618]
</p><p>45 Problem Formulation The input of our algorithm is the set of photo streams of a particular activity denoted by P = {P1, · · · , PL}, where La pisa tthiceu nlaurm abcetirv oityf input photo Pstre =am {Ps. [sent-89, score-1.731]
</p><p>46 E,a··ch· photo s wtrheaemre is a set of photos taken in sequence by a single photographer within a certain period of time, which is set to a single day in this paper. [sent-90, score-0.618]
</p><p>47 Without loss of generality, we assume that each photo stream is sorted by taken time. [sent-91, score-0.797]
</p><p>48 We also use I {I1, · · · , IN} to denote the whole image set without = distinguishing tIhe membership of photo esti rmeaamges. [sent-92, score-0.618]
</p><p>49 s eAts w a tnhootau-t tion convention, we use superscripts to denote photo stream numbers and subscripts to denote image numbers. [sent-93, score-0.797]
</p><p>50 The first output for the alignment is the set of correspondences between the images of different photo streams. [sent-99, score-0.802]
</p><p>51 Overview of Algorithm Our approach alternates between solving two target tasks, photo stream alignment and image cosegmentation. [sent-104, score-0.981]
</p><p>52 Given a large set of uncalibrated photo streams, we first build a nearest neighbor similarity graph that connects the photo streams to be aligned (see section 3. [sent-105, score-1.842]
</p><p>53 We formulate the alignment of the whole photo streams as an energy minimization problem, which can be solved by belief propagation on the graph. [sent-107, score-1.338]
</p><p>54 As a result of the alignment, we can obtain the correspondences between the images of different photo streams, from which we establish an image graph connecting the similar images that are likely to share common foregrounds (see section 4. [sent-111, score-0.786]
</p><p>55 We perform large-scale cosegmentation for all images at once under the guidance of the image graph in a message-passing way, which will be 1 In segmentation literature, it is called an unsupervised setting. [sent-113, score-0.379]
</p><p>56 The segmentation of images can enhance the similarity measurement between images, which subsequently contributes to a better photo stream alignment. [sent-124, score-0.856]
</p><p>57 Finally, we can return to the photo stream alignment step with the new segmentation-based image similarity. [sent-127, score-0.981]
</p><p>58 Image Similarity Measure It is vital to design a reliable similarity metric between images for an accurate alignment of photo streams. [sent-139, score-0.83]
</p><p>59 Pairwise Photo Stream Alignment For a better understanding, our discussion starts from the alignment of a pair of photo streams P1 and P2. [sent-155, score-1.262]
</p><p>60 That is, the objective is to establish the correspondences between two photo streams through image matching. [sent-156, score-1.101]
</p><p>61 The goal of alignment is to find a matching f : P1 → P2 ∪ {∅} where is the null, meaning that if f(pi) = →∅ for an image pi ∈e ∅P i1s, pi eh nasu no correspondence fi(np pP)2. [sent-160, score-0.388]
</p><p>62 T∈hPe Δ contains the entire temporal neighborhood in a photo stream (i. [sent-193, score-0.819]
</p><p>63 (2) to that of an arbitrary number of photo streams P. [sent-204, score-1.078]
</p><p>64 One naive approach may r baer yto n incrementally ctoo mstrbeiname pairwise alignments rsotaarcthing from the most similar photo stream pair and progressing to the most distant one. [sent-205, score-0.816]
</p><p>65 Second, more importantly, this method does not treat all photo streams equally, which may lead to local minima according to the order of consideration. [sent-208, score-1.078]
</p><p>66 To circumvent these issues, we jointly align all photo streams at once after constructing a graph between photo streams GP = (P, EP). [sent-209, score-2.236]
</p><p>67 For each photo stream Pi ∈ P, we afirmsst f iGnd a =set ( of photo streams that are sufficiently overlapped on timeline (i. [sent-210, score-1.901]
</p><p>68 the photo streams Pj such that (# of images of Pj within the time range of Pi)/ (total # of images Pj) ≥ γ). [sent-212, score-1.078]
</p><p>69 Given two photo streams Pi and Pj, for each image p ∈ Pi, we obtain the first nearest neighbor in Pj deanogeted p by PN? [sent-215, score-1.078]
</p><p>70 jective of multiple photo stream alignment reduces to find a matching f : Pi → Pj ∪ {∅} for all pairs (Pi, Pj) ∈ EP, which can be accomplished by minimizing E=  ? [sent-226, score-0.981]
</p><p>71 The optimization can be achieved by the belief propagation on the graph of photo streams GP, in such a way that we repeat a pairwise alignment aomf previous section by following the edges of EP  aunlitgiln convergence. [sent-231, score-1.393]
</p><p>72 Building An Image Graph For large-scale cosegmentation, we establish an image graph GI = (I, EC) where I the set of images of all is photo streams, Ia,ndE E)C w ish etrhee Iset i so tfh edges othfa imt caognensec otf th alel images t hreaatm mshs,ar aen enough commonality to be segmented together. [sent-236, score-0.767]
</p><p>73 E TBh ed eefdignees s etht eco edges boeft twweoe gnr otuhep images o Ef d∪iffEerewnhte photo streams while EW connects the images within the same photo esatrmeasm w. [sent-238, score-1.739]
</p><p>74 EileB Eis trivially obtained from the output oef p photo ssttrreeaamm. [sent-239, score-0.643]
</p><p>75 th Ee same photo stream are 666222113  consecutively taken by the same camera, and thus they are likely to share common objects and scenes. [sent-242, score-0.816]
</p><p>76 In order to define EW, we find KW-nearest neighbors for each image Ii among its temporal neighborhood in the same photo stream, which includes all images I such that |t(I) − t(Ii) | ≤ δ. [sent-243, score-0.678]
</p><p>77 gorithm: In our approach, we select the MFC [10] as our base cosegmentation algorithm, since it is scalable and has been successfully tested with Flickr user images. [sent-257, score-0.33]
</p><p>78 Message Passing db naosetadt Cosegmentation: The basic idea of our large-scale cosegmentation is to iteratively perform foreground modeling and region assignment based on image graph GI. [sent-273, score-0.446]
</p><p>79 Consequently, we formulate the cosegmentation of whole image set I the following energy maxias mtaitzioanti oofn:  {Fki}kK=+11  {vk}kK=+11  tion at round t. [sent-276, score-0.326]
</p><p>80 For example, the person foregrounds are ubiquitous in all photo sets but their appearances can be severely varied in different photo sets. [sent-303, score-1.326]
</p><p>81 Consequently, the implementation of our messagepassing based cosegmentation is straightforward; at every round, we iteratively segment each image Ii by using the learned foreground models from the partitioned regions of its neighbors Ni at previous round. [sent-338, score-0.424]
</p><p>82 Ilonwitiinagli zthaetio edng: Isn o of irmdearg teo g proceed our iterative cosegmentation algorithm, we need initial image partitions as starting points of belief propagation. [sent-341, score-0.354]
</p><p>83 The alignment BP works on the graph of photo streams while the cosegmentation BP runs on the image graph. [sent-348, score-1.585]
</p><p>84 The number of images and photo streams are shown in (a) and (b), respectively. [sent-355, score-1.078]
</p><p>85 is connected to a constant number of neighbors, the alignment BP runs in O(TL) and the cosegmentation BP does  imn eOnt(T BPN )r uwnshe inre LO (aTndL N) a are tthhee ncousmebgemre onft photo BsPtre daomess iann dO images, respectively. [sent-357, score-1.089]
</p><p>86 Experiments We evaluate the proposed approach from two technical perspectives: photo stream alignment in section 5. [sent-361, score-0.981]
</p><p>87 4 summarizes our Flickr dataset that consists of 1,514,976 images of 13,157 photo streams for 15 outdoor recreational activity classes. [sent-370, score-1.22]
</p><p>88 Flickr is one of the best image sources to test our algorithm since a large number of photo streams of different users are freely available with rich associated meta-data. [sent-371, score-1.101]
</p><p>89 We use the class names as search keywords, and download all the photo streams that contain more than 50 images. [sent-372, score-1.078]
</p><p>90 We use all pictures of each photo stream without any filtering. [sent-373, score-0.827]
</p><p>91 Results on Alignment Tasks: The performance of photo stream alignment is evaluated by a temporal localization task. [sent-378, score-1.003]
</p><p>92 We first randomly select 80% of photo streams of each class as training set and the others 666222335  Figure5. [sent-381, score-1.078]
</p><p>93 Then, the goal is to estimate the timestamps of all the images of the test photo streams by aligning them with training photo streams whose timestamps are known. [sent-390, score-2.296]
</p><p>94 Such temporal localization task is also important to achieve our ultimate goal, the picture-based storyline construction, which requires correctly locating each photo stream on the timeline to relate it with other photo streams. [sent-391, score-1.51]
</p><p>95 The (HMM) is the hidden Markov model method that has been widely applied for localizing tourists’ photo sets [3, 9]. [sent-395, score-0.618]
</p><p>96 Results on Segmentation Tasks: The task of image cosegmentation is to identify frequently recurring foregrounds in the image set. [sent-424, score-0.398]
</p><p>97 We also test the MFC algorithm (MFC) without involving the alignment step; this comparison can quantify the contribution of alignment to cosegmentation. [sent-432, score-0.368]
</p><p>98 Conclusion We proposed a scalable approach to jointly aligning and segmenting multiple uncalibrated Web photo streams of different users. [sent-459, score-1.265]
</p><p>99 We demonstrated superior alignment and cosegmentation performance for the Flickr outdoor activity dataset over other candidate methods. [sent-460, score-0.562]
</p><p>100 The empirical results assured that our method can be a key component to achieve our ultimate goal: inferring collective photo storylines from Web images, which is a next direction of our future work. [sent-461, score-0.843]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('photo', 0.618), ('streams', 0.46), ('cosegmentation', 0.287), ('alignment', 0.184), ('stream', 0.179), ('storylines', 0.159), ('mfc', 0.134), ('vni', 0.103), ('pi', 0.102), ('scuba', 0.101), ('bp', 0.096), ('foregrounds', 0.09), ('pj', 0.079), ('foreground', 0.075), ('flickr', 0.072), ('diving', 0.063), ('outdoor', 0.056), ('activities', 0.054), ('recreational', 0.051), ('vk', 0.049), ('assignment', 0.048), ('ii', 0.048), ('cni', 0.048), ('timestamps', 0.048), ('segmenting', 0.047), ('belief', 0.045), ('web', 0.045), ('ci', 0.045), ('jointly', 0.044), ('aligning', 0.044), ('mtni', 0.043), ('trip', 0.043), ('ni', 0.043), ('message', 0.043), ('baselines', 0.041), ('collective', 0.04), ('round', 0.039), ('gunhee', 0.038), ('neighbors', 0.038), ('graph', 0.036), ('partition', 0.035), ('activity', 0.035), ('segmented', 0.034), ('gti', 0.034), ('beliefs', 0.032), ('geolocation', 0.032), ('segmentation', 0.031), ('aligned', 0.031), ('propagation', 0.031), ('pictures', 0.03), ('commonality', 0.03), ('camping', 0.029), ('cosegmenting', 0.029), ('ctn', 0.029), ('recurred', 0.029), ('regass', 0.029), ('rewarding', 0.029), ('tourists', 0.029), ('uncalibrated', 0.029), ('accuracies', 0.029), ('similarity', 0.028), ('ep', 0.028), ('discover', 0.027), ('kk', 0.027), ('explosion', 0.026), ('ultimate', 0.026), ('tourist', 0.026), ('imt', 0.026), ('timeline', 0.026), ('acronyms', 0.026), ('trivially', 0.025), ('unsupervised', 0.025), ('hmm', 0.025), ('matched', 0.025), ('loop', 0.024), ('segment', 0.024), ('users', 0.023), ('scalable', 0.023), ('establish', 0.023), ('personal', 0.023), ('millions', 0.023), ('partitions', 0.022), ('dtw', 0.022), ('connects', 0.022), ('gmm', 0.022), ('temporal', 0.022), ('gi', 0.021), ('recurring', 0.021), ('storyline', 0.021), ('etht', 0.021), ('ew', 0.021), ('fki', 0.02), ('cos', 0.02), ('rock', 0.02), ('cti', 0.02), ('user', 0.02), ('share', 0.019), ('unary', 0.019), ('passing', 0.019), ('pairwise', 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999857 <a title="235-tfidf-1" href="./cvpr-2013-Jointly_Aligning_and_Segmenting_Multiple_Web_Photo_Streams_for_the_Inference_of_Collective_Photo_Storylines.html">235 cvpr-2013-Jointly Aligning and Segmenting Multiple Web Photo Streams for the Inference of Collective Photo Storylines</a></p>
<p>Author: Gunhee Kim, Eric P. Xing</p><p>Abstract: With an explosion of popularity of online photo sharing, we can trivially collect a huge number of photo streams for any interesting topics such as scuba diving as an outdoor recreational activity class. Obviously, the retrieved photo streams are neither aligned nor calibrated since they are taken in different temporal, spatial, and personal perspectives. However, at the same time, they are likely to share common storylines that consist of sequences of events and activities frequently recurred within the topic. In this paper, as a first technical step to detect such collective storylines, we propose an approach to jointly aligning and segmenting uncalibrated multiple photo streams. The alignment task discovers the matched images between different photo streams, and the image segmentation task parses each image into multiple meaningful regions to facilitate the image understanding. We close a loop between the two tasks so that solving one task helps enhance the performance of the other in a mutually rewarding way. To this end, we design a scalable message-passing based optimization framework to jointly achieve both tasks for the whole input image set at once. With evaluation on the new Flickr dataset of 15 outdoor activities that consist of 1.5 millions of images of 13 thousands of photo streams, our empirical results show that the proposed algorithms are more successful than other candidate methods for both tasks.</p><p>2 0.12846506 <a title="235-tfidf-2" href="./cvpr-2013-Unsupervised_Joint_Object_Discovery_and_Segmentation_in_Internet_Images.html">450 cvpr-2013-Unsupervised Joint Object Discovery and Segmentation in Internet Images</a></p>
<p>Author: Michael Rubinstein, Armand Joulin, Johannes Kopf, Ce Liu</p><p>Abstract: We present a new unsupervised algorithm to discover and segment out common objects from large and diverse image collections. In contrast to previous co-segmentation methods, our algorithm performs well even in the presence of significant amounts of noise images (images not containing a common object), as typical for datasets collected from Internet search. The key insight to our algorithm is that common object patterns should be salient within each image, while being sparse with respect to smooth transformations across images. We propose to use dense correspondences between images to capture the sparsity and visual variability of the common object over the entire database, which enables us to ignore noise objects that may be salient within their own images but do not commonly occur in others. We performed extensive numerical evaluation on es- tablished co-segmentation datasets, as well as several new datasets generated using Internet search. Our approach is able to effectively segment out the common object for diverse object categories, while naturally identifying images where the common object is not present.</p><p>3 0.11521758 <a title="235-tfidf-3" href="./cvpr-2013-Graph_Transduction_Learning_with_Connectivity_Constraints_with_Application_to_Multiple_Foreground_Cosegmentation.html">193 cvpr-2013-Graph Transduction Learning with Connectivity Constraints with Application to Multiple Foreground Cosegmentation</a></p>
<p>Author: Tianyang Ma, Longin Jan Latecki</p><p>Abstract: The proposed approach is based on standard graph transduction, semi-supervised learning (SSL) framework. Its key novelty is the integration of global connectivity constraints into this framework. Although connectivity leads to higher order constraints and their number is an exponential, finding the most violated connectivity constraint can be done efficiently in polynomial time. Moreover, each such constraint can be represented as a linear inequality. Based on this fact, we design a cutting-plane algorithm to solve the integrated problem. It iterates between solving a convex quadraticproblem of labelpropagation with linear inequality constraints, and finding the most violated constraint. We demonstrate the benefits of the proposed approach on a realistic and very challenging problem of cosegmentation of multiple foreground objects in photo collections in which the foreground objects are not present in all photos. The obtained results not only demonstrate performance boost induced by the connectivity constraints, but also show a significant improvement over the state-of-the-art methods.</p><p>4 0.085810013 <a title="235-tfidf-4" href="./cvpr-2013-Video_Editing_with_Temporal%2C_Spatial_and_Appearance_Consistency.html">453 cvpr-2013-Video Editing with Temporal, Spatial and Appearance Consistency</a></p>
<p>Author: Xiaojie Guo, Xiaochun Cao, Xiaowu Chen, Yi Ma</p><p>Abstract: Given an area of interest in a video sequence, one may want to manipulate or edit the area, e.g. remove occlusions from or replace with an advertisement on it. Such a task involves three main challenges including temporal consistency, spatial pose, and visual realism. The proposed method effectively seeks an optimal solution to simultaneously deal with temporal alignment, pose rectification, as well as precise recovery of the occlusion. To make our method applicable to long video sequences, we propose a batch alignment method for automatically aligning and rectifying a small number of initial frames, and then show how to align the remaining frames incrementally to the aligned base images. From the error residual of the robust alignment process, we automatically construct a trimap of the region for each frame, which is used as the input to alpha matting methods to extract the occluding foreground. Experimental results on both simulated and real data demonstrate the accurate and robust performance of our method.</p><p>5 0.085662186 <a title="235-tfidf-5" href="./cvpr-2013-Learning_the_Change_for_Automatic_Image_Cropping.html">263 cvpr-2013-Learning the Change for Automatic Image Cropping</a></p>
<p>Author: Jianzhou Yan, Stephen Lin, Sing Bing Kang, Xiaoou Tang</p><p>Abstract: Image cropping is a common operation used to improve the visual quality of photographs. In this paper, we present an automatic cropping technique that accounts for the two primary considerations of people when they crop: removal of distracting content, and enhancement of overall composition. Our approach utilizes a large training set consisting of photos before and after cropping by expert photographers to learn how to evaluate these two factors in a crop. In contrast to the many methods that exist for general assessment of image quality, ours specifically examines differences between the original and cropped photo in solving for the crop parameters. To this end, several novel image features are proposed to model the changes in image content and composition when a crop is applied. Our experiments demonstrate improvements of our method over recent cropping algorithms on a broad range of images.</p><p>6 0.069208756 <a title="235-tfidf-6" href="./cvpr-2013-Efficient_2D-to-3D_Correspondence_Filtering_for_Scalable_3D_Object_Recognition.html">138 cvpr-2013-Efficient 2D-to-3D Correspondence Filtering for Scalable 3D Object Recognition</a></p>
<p>7 0.065602802 <a title="235-tfidf-7" href="./cvpr-2013-Single-Sample_Face_Recognition_with_Image_Corruption_and_Misalignment_via_Sparse_Illumination_Transfer.html">399 cvpr-2013-Single-Sample Face Recognition with Image Corruption and Misalignment via Sparse Illumination Transfer</a></p>
<p>8 0.062541887 <a title="235-tfidf-8" href="./cvpr-2013-Deformable_Spatial_Pyramid_Matching_for_Fast_Dense_Correspondences.html">107 cvpr-2013-Deformable Spatial Pyramid Matching for Fast Dense Correspondences</a></p>
<p>9 0.06184835 <a title="235-tfidf-9" href="./cvpr-2013-Multi-class_Video_Co-segmentation_with_a_Generative_Multi-video_Model.html">294 cvpr-2013-Multi-class Video Co-segmentation with a Generative Multi-video Model</a></p>
<p>10 0.05986888 <a title="235-tfidf-10" href="./cvpr-2013-First-Person_Activity_Recognition%3A_What_Are_They_Doing_to_Me%3F.html">175 cvpr-2013-First-Person Activity Recognition: What Are They Doing to Me?</a></p>
<p>11 0.059662268 <a title="235-tfidf-11" href="./cvpr-2013-Weakly-Supervised_Dual_Clustering_for_Image_Semantic_Segmentation.html">460 cvpr-2013-Weakly-Supervised Dual Clustering for Image Semantic Segmentation</a></p>
<p>12 0.057441 <a title="235-tfidf-12" href="./cvpr-2013-Context-Aware_Modeling_and_Recognition_of_Activities_in_Video.html">94 cvpr-2013-Context-Aware Modeling and Recognition of Activities in Video</a></p>
<p>13 0.055857521 <a title="235-tfidf-13" href="./cvpr-2013-Robust_Canonical_Time_Warping_for_the_Alignment_of_Grossly_Corrupted_Sequences.html">358 cvpr-2013-Robust Canonical Time Warping for the Alignment of Grossly Corrupted Sequences</a></p>
<p>14 0.05460348 <a title="235-tfidf-14" href="./cvpr-2013-Hollywood_3D%3A_Recognizing_Actions_in_3D_Natural_Scenes.html">205 cvpr-2013-Hollywood 3D: Recognizing Actions in 3D Natural Scenes</a></p>
<p>15 0.054382581 <a title="235-tfidf-15" href="./cvpr-2013-Discrete_MRF_Inference_of_Marginal_Densities_for_Non-uniformly_Discretized_Variable_Space.html">128 cvpr-2013-Discrete MRF Inference of Marginal Densities for Non-uniformly Discretized Variable Space</a></p>
<p>16 0.049554501 <a title="235-tfidf-16" href="./cvpr-2013-Ensemble_Video_Object_Cut_in_Highly_Dynamic_Scenes.html">148 cvpr-2013-Ensemble Video Object Cut in Highly Dynamic Scenes</a></p>
<p>17 0.04760525 <a title="235-tfidf-17" href="./cvpr-2013-Whitened_Expectation_Propagation%3A_Non-Lambertian_Shape_from_Shading_and_Shadow.html">466 cvpr-2013-Whitened Expectation Propagation: Non-Lambertian Shape from Shading and Shadow</a></p>
<p>18 0.046346929 <a title="235-tfidf-18" href="./cvpr-2013-Joint_Sparsity-Based_Representation_and_Analysis_of_Unconstrained_Activities.html">233 cvpr-2013-Joint Sparsity-Based Representation and Analysis of Unconstrained Activities</a></p>
<p>19 0.046260785 <a title="235-tfidf-19" href="./cvpr-2013-3D_Visual_Proxemics%3A_Recognizing_Human_Interactions_in_3D_from_a_Single_Image.html">4 cvpr-2013-3D Visual Proxemics: Recognizing Human Interactions in 3D from a Single Image</a></p>
<p>20 0.045197885 <a title="235-tfidf-20" href="./cvpr-2013-Fast_Energy_Minimization_Using_Learned_State_Filters.html">165 cvpr-2013-Fast Energy Minimization Using Learned State Filters</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.128), (1, -0.005), (2, 0.012), (3, -0.005), (4, 0.022), (5, -0.008), (6, -0.024), (7, -0.008), (8, -0.018), (9, -0.012), (10, 0.064), (11, -0.001), (12, 0.009), (13, 0.007), (14, -0.005), (15, -0.05), (16, 0.024), (17, 0.025), (18, 0.034), (19, -0.025), (20, -0.013), (21, 0.026), (22, -0.01), (23, -0.061), (24, 0.056), (25, -0.07), (26, 0.029), (27, 0.049), (28, 0.006), (29, -0.012), (30, 0.025), (31, -0.011), (32, -0.03), (33, 0.011), (34, 0.043), (35, -0.02), (36, -0.042), (37, -0.024), (38, 0.016), (39, 0.047), (40, -0.042), (41, -0.001), (42, 0.015), (43, -0.004), (44, -0.0), (45, -0.04), (46, 0.028), (47, 0.036), (48, -0.017), (49, -0.037)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94373202 <a title="235-lsi-1" href="./cvpr-2013-Jointly_Aligning_and_Segmenting_Multiple_Web_Photo_Streams_for_the_Inference_of_Collective_Photo_Storylines.html">235 cvpr-2013-Jointly Aligning and Segmenting Multiple Web Photo Streams for the Inference of Collective Photo Storylines</a></p>
<p>Author: Gunhee Kim, Eric P. Xing</p><p>Abstract: With an explosion of popularity of online photo sharing, we can trivially collect a huge number of photo streams for any interesting topics such as scuba diving as an outdoor recreational activity class. Obviously, the retrieved photo streams are neither aligned nor calibrated since they are taken in different temporal, spatial, and personal perspectives. However, at the same time, they are likely to share common storylines that consist of sequences of events and activities frequently recurred within the topic. In this paper, as a first technical step to detect such collective storylines, we propose an approach to jointly aligning and segmenting uncalibrated multiple photo streams. The alignment task discovers the matched images between different photo streams, and the image segmentation task parses each image into multiple meaningful regions to facilitate the image understanding. We close a loop between the two tasks so that solving one task helps enhance the performance of the other in a mutually rewarding way. To this end, we design a scalable message-passing based optimization framework to jointly achieve both tasks for the whole input image set at once. With evaluation on the new Flickr dataset of 15 outdoor activities that consist of 1.5 millions of images of 13 thousands of photo streams, our empirical results show that the proposed algorithms are more successful than other candidate methods for both tasks.</p><p>2 0.69892806 <a title="235-lsi-2" href="./cvpr-2013-Unsupervised_Joint_Object_Discovery_and_Segmentation_in_Internet_Images.html">450 cvpr-2013-Unsupervised Joint Object Discovery and Segmentation in Internet Images</a></p>
<p>Author: Michael Rubinstein, Armand Joulin, Johannes Kopf, Ce Liu</p><p>Abstract: We present a new unsupervised algorithm to discover and segment out common objects from large and diverse image collections. In contrast to previous co-segmentation methods, our algorithm performs well even in the presence of significant amounts of noise images (images not containing a common object), as typical for datasets collected from Internet search. The key insight to our algorithm is that common object patterns should be salient within each image, while being sparse with respect to smooth transformations across images. We propose to use dense correspondences between images to capture the sparsity and visual variability of the common object over the entire database, which enables us to ignore noise objects that may be salient within their own images but do not commonly occur in others. We performed extensive numerical evaluation on es- tablished co-segmentation datasets, as well as several new datasets generated using Internet search. Our approach is able to effectively segment out the common object for diverse object categories, while naturally identifying images where the common object is not present.</p><p>3 0.68936867 <a title="235-lsi-3" href="./cvpr-2013-Video_Editing_with_Temporal%2C_Spatial_and_Appearance_Consistency.html">453 cvpr-2013-Video Editing with Temporal, Spatial and Appearance Consistency</a></p>
<p>Author: Xiaojie Guo, Xiaochun Cao, Xiaowu Chen, Yi Ma</p><p>Abstract: Given an area of interest in a video sequence, one may want to manipulate or edit the area, e.g. remove occlusions from or replace with an advertisement on it. Such a task involves three main challenges including temporal consistency, spatial pose, and visual realism. The proposed method effectively seeks an optimal solution to simultaneously deal with temporal alignment, pose rectification, as well as precise recovery of the occlusion. To make our method applicable to long video sequences, we propose a batch alignment method for automatically aligning and rectifying a small number of initial frames, and then show how to align the remaining frames incrementally to the aligned base images. From the error residual of the robust alignment process, we automatically construct a trimap of the region for each frame, which is used as the input to alpha matting methods to extract the occluding foreground. Experimental results on both simulated and real data demonstrate the accurate and robust performance of our method.</p><p>4 0.68072438 <a title="235-lsi-4" href="./cvpr-2013-A_Non-parametric_Framework_for_Document_Bleed-through_Removal.html">22 cvpr-2013-A Non-parametric Framework for Document Bleed-through Removal</a></p>
<p>Author: Róisín Rowley-Brooke, François Pitié, Anil Kokaram</p><p>Abstract: This paper presents recent work on a new framework for non-blind document bleed-through removal. The framework includes image preprocessing to remove local intensity variations, pixel region classification based on a segmentation of the joint recto-verso intensity histogram and connected component analysis on the subsequent image labelling. Finally restoration of the degraded regions is performed using exemplar-based image inpainting. The proposed method is evaluated visually and numerically on a freely available database of 25 scanned manuscript image pairs with ground truth, and is shown to outperform recent non-blind bleed-through removal techniques.</p><p>5 0.62239784 <a title="235-lsi-5" href="./cvpr-2013-Graph_Transduction_Learning_with_Connectivity_Constraints_with_Application_to_Multiple_Foreground_Cosegmentation.html">193 cvpr-2013-Graph Transduction Learning with Connectivity Constraints with Application to Multiple Foreground Cosegmentation</a></p>
<p>Author: Tianyang Ma, Longin Jan Latecki</p><p>Abstract: The proposed approach is based on standard graph transduction, semi-supervised learning (SSL) framework. Its key novelty is the integration of global connectivity constraints into this framework. Although connectivity leads to higher order constraints and their number is an exponential, finding the most violated connectivity constraint can be done efficiently in polynomial time. Moreover, each such constraint can be represented as a linear inequality. Based on this fact, we design a cutting-plane algorithm to solve the integrated problem. It iterates between solving a convex quadraticproblem of labelpropagation with linear inequality constraints, and finding the most violated constraint. We demonstrate the benefits of the proposed approach on a realistic and very challenging problem of cosegmentation of multiple foreground objects in photo collections in which the foreground objects are not present in all photos. The obtained results not only demonstrate performance boost induced by the connectivity constraints, but also show a significant improvement over the state-of-the-art methods.</p><p>6 0.61623132 <a title="235-lsi-6" href="./cvpr-2013-As-Projective-As-Possible_Image_Stitching_with_Moving_DLT.html">47 cvpr-2013-As-Projective-As-Possible Image Stitching with Moving DLT</a></p>
<p>7 0.6037581 <a title="235-lsi-7" href="./cvpr-2013-Recovering_Stereo_Pairs_from_Anaglyphs.html">352 cvpr-2013-Recovering Stereo Pairs from Anaglyphs</a></p>
<p>8 0.6024645 <a title="235-lsi-8" href="./cvpr-2013-FasT-Match%3A_Fast_Affine_Template_Matching.html">162 cvpr-2013-FasT-Match: Fast Affine Template Matching</a></p>
<p>9 0.59762537 <a title="235-lsi-9" href="./cvpr-2013-FrameBreak%3A_Dramatic_Image_Extrapolation_by_Guided_Shift-Maps.html">177 cvpr-2013-FrameBreak: Dramatic Image Extrapolation by Guided Shift-Maps</a></p>
<p>10 0.59757608 <a title="235-lsi-10" href="./cvpr-2013-Improving_Image_Matting_Using_Comprehensive_Sampling_Sets.html">216 cvpr-2013-Improving Image Matting Using Comprehensive Sampling Sets</a></p>
<p>11 0.5937075 <a title="235-lsi-11" href="./cvpr-2013-Image_Matting_with_Local_and_Nonlocal_Smooth_Priors.html">211 cvpr-2013-Image Matting with Local and Nonlocal Smooth Priors</a></p>
<p>12 0.59055942 <a title="235-lsi-12" href="./cvpr-2013-Learning_the_Change_for_Automatic_Image_Cropping.html">263 cvpr-2013-Learning the Change for Automatic Image Cropping</a></p>
<p>13 0.58987427 <a title="235-lsi-13" href="./cvpr-2013-Robust_Estimation_of_Nonrigid_Transformation_for_Point_Set_Registration.html">360 cvpr-2013-Robust Estimation of Nonrigid Transformation for Point Set Registration</a></p>
<p>14 0.58072829 <a title="235-lsi-14" href="./cvpr-2013-Efficient_Object_Detection_and_Segmentation_for_Fine-Grained_Recognition.html">145 cvpr-2013-Efficient Object Detection and Segmentation for Fine-Grained Recognition</a></p>
<p>15 0.57481861 <a title="235-lsi-15" href="./cvpr-2013-Joint_Spectral_Correspondence_for_Disparate_Image_Matching.html">234 cvpr-2013-Joint Spectral Correspondence for Disparate Image Matching</a></p>
<p>16 0.56519884 <a title="235-lsi-16" href="./cvpr-2013-Bilinear_Programming_for_Human_Activity_Recognition_with_Unknown_MRF_Graphs.html">62 cvpr-2013-Bilinear Programming for Human Activity Recognition with Unknown MRF Graphs</a></p>
<p>17 0.55779523 <a title="235-lsi-17" href="./cvpr-2013-Discriminative_Re-ranking_of_Diverse_Segmentations.html">132 cvpr-2013-Discriminative Re-ranking of Diverse Segmentations</a></p>
<p>18 0.55758679 <a title="235-lsi-18" href="./cvpr-2013-Deformable_Spatial_Pyramid_Matching_for_Fast_Dense_Correspondences.html">107 cvpr-2013-Deformable Spatial Pyramid Matching for Fast Dense Correspondences</a></p>
<p>19 0.54421568 <a title="235-lsi-19" href="./cvpr-2013-The_Generalized_Laplacian_Distance_and_Its_Applications_for_Visual_Matching.html">429 cvpr-2013-The Generalized Laplacian Distance and Its Applications for Visual Matching</a></p>
<p>20 0.54226691 <a title="235-lsi-20" href="./cvpr-2013-Efficient_2D-to-3D_Correspondence_Filtering_for_Scalable_3D_Object_Recognition.html">138 cvpr-2013-Efficient 2D-to-3D Correspondence Filtering for Scalable 3D Object Recognition</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.12), (16, 0.037), (26, 0.074), (28, 0.016), (33, 0.226), (67, 0.066), (69, 0.045), (77, 0.012), (80, 0.018), (87, 0.06), (89, 0.206)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.83932507 <a title="235-lda-1" href="./cvpr-2013-Jointly_Aligning_and_Segmenting_Multiple_Web_Photo_Streams_for_the_Inference_of_Collective_Photo_Storylines.html">235 cvpr-2013-Jointly Aligning and Segmenting Multiple Web Photo Streams for the Inference of Collective Photo Storylines</a></p>
<p>Author: Gunhee Kim, Eric P. Xing</p><p>Abstract: With an explosion of popularity of online photo sharing, we can trivially collect a huge number of photo streams for any interesting topics such as scuba diving as an outdoor recreational activity class. Obviously, the retrieved photo streams are neither aligned nor calibrated since they are taken in different temporal, spatial, and personal perspectives. However, at the same time, they are likely to share common storylines that consist of sequences of events and activities frequently recurred within the topic. In this paper, as a first technical step to detect such collective storylines, we propose an approach to jointly aligning and segmenting uncalibrated multiple photo streams. The alignment task discovers the matched images between different photo streams, and the image segmentation task parses each image into multiple meaningful regions to facilitate the image understanding. We close a loop between the two tasks so that solving one task helps enhance the performance of the other in a mutually rewarding way. To this end, we design a scalable message-passing based optimization framework to jointly achieve both tasks for the whole input image set at once. With evaluation on the new Flickr dataset of 15 outdoor activities that consist of 1.5 millions of images of 13 thousands of photo streams, our empirical results show that the proposed algorithms are more successful than other candidate methods for both tasks.</p><p>2 0.83316183 <a title="235-lda-2" href="./cvpr-2013-Image_Segmentation_by_Cascaded_Region_Agglomeration.html">212 cvpr-2013-Image Segmentation by Cascaded Region Agglomeration</a></p>
<p>Author: Zhile Ren, Gregory Shakhnarovich</p><p>Abstract: We propose a hierarchical segmentation algorithm that starts with a very fine oversegmentation and gradually merges regions using a cascade of boundary classifiers. This approach allows the weights of region and boundary features to adapt to the segmentation scale at which they are applied. The stages of the cascade are trained sequentially, with asymetric loss to maximize boundary recall. On six segmentation data sets, our algorithm achieves best performance under most region-quality measures, and does it with fewer segments than the prior work. Our algorithm is also highly competitive in a dense oversegmentation (superpixel) regime under boundary-based measures.</p><p>3 0.80572957 <a title="235-lda-3" href="./cvpr-2013-Hierarchical_Saliency_Detection.html">202 cvpr-2013-Hierarchical Saliency Detection</a></p>
<p>Author: Qiong Yan, Li Xu, Jianping Shi, Jiaya Jia</p><p>Abstract: When dealing with objects with complex structures, saliency detection confronts a critical problem namely that detection accuracy could be adversely affected if salient foreground or background in an image contains small-scale high-contrast patterns. This issue is common in natural images and forms a fundamental challenge for prior methods. We tackle it from a scale point of view and propose a multi-layer approach to analyze saliency cues. The final saliency map is produced in a hierarchical model. Different from varying patch sizes or downsizing images, our scale-based region handling is by finding saliency values optimally in a tree model. Our approach improves saliency detection on many images that cannot be handled well traditionally. A new dataset is also constructed. –</p><p>4 0.79442382 <a title="235-lda-4" href="./cvpr-2013-Occlusion_Patterns_for_Object_Class_Detection.html">311 cvpr-2013-Occlusion Patterns for Object Class Detection</a></p>
<p>Author: Bojan Pepikj, Michael Stark, Peter Gehler, Bernt Schiele</p><p>Abstract: Despite the success of recent object class recognition systems, the long-standing problem of partial occlusion remains a major challenge, and a principled solution is yet to be found. In this paper we leave the beaten path of methods that treat occlusion as just another source of noise instead, we include the occluder itself into the modelling, by mining distinctive, reoccurring occlusion patterns from annotated training data. These patterns are then used as training data for dedicated detectors of varying sophistication. In particular, we evaluate and compare models that range from standard object class detectors to hierarchical, part-based representations of occluder/occludee pairs. In an extensive evaluation we derive insights that can aid further developments in tackling the occlusion challenge. –</p><p>5 0.79203016 <a title="235-lda-5" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>Author: Ian Endres, Kevin J. Shih, Johnston Jiaa, Derek Hoiem</p><p>Abstract: We propose a method to learn a diverse collection of discriminative parts from object bounding box annotations. Part detectors can be trained and applied individually, which simplifies learning and extension to new features or categories. We apply the parts to object category detection, pooling part detections within bottom-up proposed regions and using a boosted classifier with proposed sigmoid weak learners for scoring. On PASCAL VOC 2010, we evaluate the part detectors ’ ability to discriminate and localize annotated keypoints. Our detection system is competitive with the best-existing systems, outperforming other HOG-based detectors on the more deformable categories.</p><p>6 0.79186714 <a title="235-lda-6" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<p>7 0.79097694 <a title="235-lda-7" href="./cvpr-2013-Tensor-Based_High-Order_Semantic_Relation_Transfer_for_Semantic_Scene_Segmentation.html">425 cvpr-2013-Tensor-Based High-Order Semantic Relation Transfer for Semantic Scene Segmentation</a></p>
<p>8 0.78927624 <a title="235-lda-8" href="./cvpr-2013-Structure_Preserving_Object_Tracking.html">414 cvpr-2013-Structure Preserving Object Tracking</a></p>
<p>9 0.78801066 <a title="235-lda-9" href="./cvpr-2013-Integrating_Grammar_and_Segmentation_for_Human_Pose_Estimation.html">225 cvpr-2013-Integrating Grammar and Segmentation for Human Pose Estimation</a></p>
<p>10 0.78743654 <a title="235-lda-10" href="./cvpr-2013-Part_Discovery_from_Partial_Correspondence.html">325 cvpr-2013-Part Discovery from Partial Correspondence</a></p>
<p>11 0.78501964 <a title="235-lda-11" href="./cvpr-2013-Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking.html">285 cvpr-2013-Minimum Uncertainty Gap for Robust Visual Tracking</a></p>
<p>12 0.78418493 <a title="235-lda-12" href="./cvpr-2013-Tracking_People_and_Their_Objects.html">440 cvpr-2013-Tracking People and Their Objects</a></p>
<p>13 0.78368783 <a title="235-lda-13" href="./cvpr-2013-Physically_Plausible_3D_Scene_Tracking%3A_The_Single_Actor_Hypothesis.html">331 cvpr-2013-Physically Plausible 3D Scene Tracking: The Single Actor Hypothesis</a></p>
<p>14 0.78301013 <a title="235-lda-14" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<p>15 0.78262395 <a title="235-lda-15" href="./cvpr-2013-Understanding_Indoor_Scenes_Using_3D_Geometric_Phrases.html">446 cvpr-2013-Understanding Indoor Scenes Using 3D Geometric Phrases</a></p>
<p>16 0.78247458 <a title="235-lda-16" href="./cvpr-2013-Spatiotemporal_Deformable_Part_Models_for_Action_Detection.html">408 cvpr-2013-Spatiotemporal Deformable Part Models for Action Detection</a></p>
<p>17 0.7823047 <a title="235-lda-17" href="./cvpr-2013-Robust_Estimation_of_Nonrigid_Transformation_for_Point_Set_Registration.html">360 cvpr-2013-Robust Estimation of Nonrigid Transformation for Point Set Registration</a></p>
<p>18 0.78201568 <a title="235-lda-18" href="./cvpr-2013-3D_Visual_Proxemics%3A_Recognizing_Human_Interactions_in_3D_from_a_Single_Image.html">4 cvpr-2013-3D Visual Proxemics: Recognizing Human Interactions in 3D from a Single Image</a></p>
<p>19 0.7811802 <a title="235-lda-19" href="./cvpr-2013-Understanding_Bayesian_Rooms_Using_Composite_3D_Object_Models.html">445 cvpr-2013-Understanding Bayesian Rooms Using Composite 3D Object Models</a></p>
<p>20 0.78110868 <a title="235-lda-20" href="./cvpr-2013-Incorporating_Structural_Alternatives_and_Sharing_into_Hierarchy_for_Multiclass_Object_Recognition_and_Detection.html">221 cvpr-2013-Incorporating Structural Alternatives and Sharing into Hierarchy for Multiclass Object Recognition and Detection</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
