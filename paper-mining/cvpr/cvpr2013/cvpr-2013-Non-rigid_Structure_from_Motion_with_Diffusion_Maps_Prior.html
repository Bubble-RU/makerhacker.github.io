<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>306 cvpr-2013-Non-rigid Structure from Motion with Diffusion Maps Prior</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-306" href="#">cvpr2013-306</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>306 cvpr-2013-Non-rigid Structure from Motion with Diffusion Maps Prior</h1>
<br/><p>Source: <a title="cvpr-2013-306-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Tao_Non-rigid_Structure_from_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Lili Tao, Bogdan J. Matuszewski</p><p>Abstract: In this paper, a novel approach based on a non-linear manifold learning technique is proposed to recover 3D nonrigid structures from 2D image sequences captured by a single camera. Most ofthe existing approaches assume that 3D shapes can be accurately modelled in a linear subspace. These techniques perform well when the deformations are relatively small or simple, but fail when more complex deformations need to be recovered. The non-linear deformations are often observed in highly flexible objects for which the use of the linear model is impractical. A specific type of shape variations might be governed by only a small number of parameters, therefore can be wellrepresented in a low dimensional manifold. We learn a nonlinear shape prior using diffusion maps method. The key contribution in this paper is the introduction of the shape prior that constrain the reconstructed shapes to lie in the learned manifold. The proposed methodology has been validated quantitatively and qualitatively on 2D points sequences projected from the 3D motion capture data and real 2D video sequences. The comparisons oftheproposed man- ifold based method against several state-of-the-art techniques are shown on different types of deformable objects.</p><p>Reference: <a title="cvpr-2013-306-reference" href="../cvpr2013_reference/cvpr-2013-Non-rigid_Structure_from_Motion_with_Diffusion_Maps_Prior_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 uk lt  Abstract In this paper, a novel approach based on a non-linear manifold learning technique is proposed to recover 3D nonrigid structures from 2D image sequences captured by a single camera. [sent-4, score-0.505]
</p><p>2 Most ofthe existing approaches assume that 3D shapes can be accurately modelled in a linear subspace. [sent-5, score-0.309]
</p><p>3 These techniques perform well when the deformations are relatively small or simple, but fail when more complex deformations need to be recovered. [sent-6, score-0.311]
</p><p>4 We learn a nonlinear shape prior using diffusion maps method. [sent-9, score-0.495]
</p><p>5 The key contribution in this paper is the introduction of the shape prior that constrain the reconstructed shapes to lie in the learned manifold. [sent-10, score-0.525]
</p><p>6 The proposed methodology has been validated quantitatively and qualitatively on 2D points sequences projected from the 3D motion capture data and real 2D video sequences. [sent-11, score-0.226]
</p><p>7 Introduction The objective of the Structure from Motion (SfM) is to jointly reconstruct 3D shapes and estimate corresponding camera motion trajectories based only on a set of observed image sequences. [sent-14, score-0.515]
</p><p>8 While the reconstruction of rigid objects has been well-established [19] over the past two decades, deformable shape reconstruction is still challenging, mainly because it is a severely under-constrained problem. [sent-15, score-0.463]
</p><p>9 [5] was the first to adopt the factorisation algorithm to deformable 3D structures by introducing a low rank shape model to represent deformable shapes. [sent-19, score-0.483]
</p><p>10 As a time-varying object usually cannot arbitrarily deform, the idea of this model is to represent a deformable shape as a linear combination of basis shapes. [sent-20, score-0.499]
</p><p>11 Due to its simplicity, shape basis model has been widely used to tackle the NRSfM [4, 26, 1]. [sent-21, score-0.345]
</p><p>12 [25] proposed a closed-form solution and showed that orthonormality constraints is insufficient to provide unique solution to estimate basis shapes. [sent-26, score-0.239]
</p><p>13 Departing from the shape basis model, a trajectory based algorithm was proposed in [2] by Akhter et al. [sent-31, score-0.529]
</p><p>14 The main advantage of this representation is that the basis trajectories can be predefined, thus removing a large number of unknowns from the estimation. [sent-33, score-0.235]
</p><p>15 However, there is no guarantee that the manifold is planar or isometric to a plane. [sent-39, score-0.397]
</p><p>16 Despite the manifold learning techniques are becoming increasingly popular and have been successfully used in different applications including medical image analysis [24], object classification [14] and segmentation [9], these techniques have not been widely applied in NRSfM problem. [sent-40, score-0.34]
</p><p>17 The main reason for their failure when recovering objects with large, complex deformations can be attributed to the reliance on a linear shape model. [sent-43, score-0.345]
</p><p>18 This paper focuses on modelling non-linear deformable objects with large complex deformations, such as deformable cloth or articulated full-body motion. [sent-44, score-0.456]
</p><p>19 In this case, the existing methods based on linear space manifold are no longer applicable. [sent-45, score-0.372]
</p><p>20 We argue that the linear models require more parameters than our method based on non-linear manifold learning approach. [sent-46, score-0.372]
</p><p>21 This paper proposes a novel method for reconstruction of 3D deformable structures exhibiting large and complex  ×  deformations. [sent-47, score-0.257]
</p><p>22 The proposed method is based on a recently introduced manifold learning technique called Diffusion Maps [6]. [sent-48, score-0.34]
</p><p>23 This manifold build as a shape prior, with the reconstructed shapes constrained to lie in the manifold. [sent-49, score-0.83]
</p><p>24 Learning instead a corresponding low dimensional manifold from the training examples. [sent-54, score-0.416]
</p><p>25 Our approach is to integrate the learned non-linear shape prior manifold into the NRSfM solver. [sent-56, score-0.528]
</p><p>26 The goal is to recover camera orientations matrix R and the concatenated time-varying shapes matrix S, based only on the 2D measurement in matrix W. [sent-66, score-0.434]
</p><p>27 It is an under constrained problem since the shape and motion are both changing with time. [sent-67, score-0.284]
</p><p>28 ytp]T  the  Low-rank shape model The points in each observed image can be represented as xt = RtSt, where xt represents input points, Rt is a 2×3 projection matrix representing camera orientation and 2S×t 3∈ pRro3×jecPt oisn a 3aDtri shape projected monertoa othriee ntttaht ofrna maned. [sent-70, score-0.552]
</p><p>29 Describing the deformation using a shape model in a linear subspace is one way of imposing compactness on S to reduce the dimensionality of the problem. [sent-71, score-0.306]
</p><p>30 A deformable 3D shape can be represented as a linear combination of K unknown but fixed basis shapes Bl :  St=? [sent-72, score-0.776]
</p><p>31 The measurement matrix can be decomposed and represented by pose, basis shapes and time varying coefficients matrices, therefore it can be rearranged as:  W=⎣⎢⎡α F1 1. [sent-79, score-0.616]
</p><p>32 K1− ⎥⎤⎦=MB  (3)  Since basis shapes B ∈ R3K×P, and M ∈ R2F×3K the Srainnkce eo fb maseisas suhreampeesn Bt Bm ∈atri Rx W is ,3 aKn adt mMos ∈t ∈in R the absence of noise. [sent-84, score-0.469]
</p><p>33 According dtoe [i2ne5d], tphe to l aim aimtabtiiognu toyf mthaet cixlo Qsed ∈-f Rorm solution in this approach is that the motion matrix is nonlinear, when an inaccurate set of basis shapes have been chosen, it may not be possible to remove the affine ambiguity. [sent-87, score-0.6]
</p><p>34 The trajectory for each point is approximated by a linear combination of a small number of basis trajectories Al:  Tp=? [sent-89, score-0.451]
</p><p>35 lK=1Alββ βpl  (4)  where ββpl are 1×3 coefficient vectors for the basis trajectory The basis trajectory can ebnet predefined tihne an object cintoderypendent way using Discrete Cosine Transform (DCT) basis and therefore avoid training process. [sent-90, score-1.012]
</p><p>36 The model only needs to consider camera parameters and trajectory coefficients, thus requires less parameters than shape basis model (see Table 1). [sent-91, score-0.593]
</p><p>37 Non-linear manifold model  Our model departs from the linear shape model. [sent-92, score-0.525]
</p><p>38 The shape basis B in the proposed method are selected from the learned shape manifold. [sent-93, score-0.498]
</p><p>39 Unlike the low rank shape model, where all the reconstructed shapes are represented as a linear combination of unknown but fixed K basis shapes, in the proposed method, the basis shapes may be different at each frame. [sent-94, score-1.215]
</p><p>40 Although it may seem to increase the number of parameters in the model, it should be recognised that all the basis shapes are selected from the manifold and are not estimated as a part of the optimisation process. [sent-95, score-0.907]
</p><p>41 The parameters to be estimated in the proposed approach include only the camera motion and shape coefficients, representing the shape in the local linear barycentric coordinates system approximating the manifold at the location corresponding to the current estimate of St. [sent-96, score-0.974]
</p><p>42 In most cases, K < 10, F, P > 100, the proposed model requires less parameters than low rank shape model and has a similar order of magnitude as trajectory model. [sent-98, score-0.369]
</p><p>43 NRSfM with Diffusion Maps In this section, an overview of the proposed manifold  based NRSfM algorithm is given first, followed by a short description of the diffusion maps including description of out-of-sample and pre-image problems. [sent-102, score-0.647]
</p><p>44 As known from [25], enforcing only the rotation constraints cannot guarantee the unique solution for the camera motion and the basis shapes. [sent-103, score-0.387]
</p><p>45 To solved this, the designed shape prior can help to attract a shape towards the manifold and therefore avoid incorrect reconstruction. [sent-104, score-0.681]
</p><p>46 are estimated by running a few iteration of the optimisation process in batch NRSfM using linear basis shapes model [17]. [sent-108, score-0.599]
</p><p>47 Intuitively, if the points in reduced space are relatively close, the corresponding shapes in high-dimensional space should represent similar shapes. [sent-110, score-0.375]
</p><p>48 Based on this observation, the reconstructed shape at each frame can be represented as weighted sum of K+1 basis shapes from the learned manifold. [sent-111, score-0.682]
</p><p>49 The coefficients of correspond basis shape are calculated based as barycentric coordinates of K+1 closest points in reduced space. [sent-112, score-0.646]
</p><p>50 Once the basis shapes and their coefficients have been obtained, an optimisation is applied to minimise the image reprojection error with an additional smoothing term and basic rotation constraint over all frames. [sent-113, score-0.703]
</p><p>51 Updating basis shapes in each iteration can  help to circumvent the problem. [sent-115, score-0.469]
</p><p>52 The basis shapes are being kept updated as long as 2D measurement error rt exceeds the defined threshold rT (10−3 in our case) or the error between two adjacent frames is relatively large which implies that the current results are unlikely to explain the shapes well. [sent-116, score-1.094]
</p><p>53 While linear manifold method like PCA is straightforward, the recovered input data lies on a linear subspace of high dimensional space. [sent-120, score-0.443]
</p><p>54 Diffusion maps is a graph based technique with isometric mapping from original shape space to reduced lowdimensional diffusion space. [sent-122, score-0.624]
</p><p>55 1)  Output: 3D deformable shapes S and camera motion R for each frame. [sent-124, score-0.594]
</p><p>56 3) 6: Non-linear optimisation by minimising 2D measurement error and shape smooth term to obtain updated shapes St and camera motion Rt,t=1 · · · F . [sent-144, score-0.865]
</p><p>57 G(iXve)n, a s ,eΨt of( shapes eXr1e e·X X· X· X∈M R ∈, MK ,? [sent-152, score-0.277]
</p><p>58 re M is the manifold embedded in R·N··, Euc∈lid Mean, wdihsetarenc Me fo irs each pair of shapes ? [sent-154, score-0.617]
</p><p>59 Out of sample extension In general, the diffusion map Ψ is only able to provide an embedding for the data which is given in the training set. [sent-189, score-0.367]
</p><p>60 However, in the NRSfM problem, it is necessary to calculate embedding for shapes which are not presented in the training set. [sent-190, score-0.389]
</p><p>61 Assuming we look for a shape St given by witist embedding xt, if this shape St does not exist in the training dataset, the exact pre-image might not be found in that case. [sent-211, score-0.418]
</p><p>62 Inspired by this, we assume that the pre-image can be represented as a linear combination of its neighbours on the manifold selected from the training samples. [sent-214, score-0.463]
</p><p>63 Since diffusion maps provides isometric mapping the data must keep  the same structure when embedded into the reduced space and therefore the neighbours on the manifold correspond to the closest neighbours in the ? [sent-217, score-0.992]
</p><p>64 Cost function The cost function to be minimised consists of the reprojection error, shape smoothing terms an rotation constraint. [sent-242, score-0.247]
</p><p>65 To eliminate the effect, basis shapes are updated until the 2D measurement error is smaller than predefined threshold rT and the error between two adjacent frames is small enough. [sent-278, score-0.728]
</p><p>66 Experimental Results The proposed methodology has been validated quantitatively and qualitatively on both motion capture and real data for different types of deformable object. [sent-280, score-0.253]
</p><p>67 Diffusion maps requires training process, so training datasets for two face sequences are taken from the BU-3DFE [27] and for two surface sequences are obtained from [22]. [sent-290, score-0.316]
</p><p>68 Since no separate training data are available in CMU database, half of each sequence is used for manifold learning and the other half for testing. [sent-291, score-0.377]
</p><p>69 The influence of embedding dimensionality For the first set of experiments, we start with tests on motion capture data. [sent-296, score-0.261]
</p><p>70 The accuracy of 3D shape reconstruction is affected by the dimensionality of the manifold representing prior information. [sent-297, score-0.677]
</p><p>71 To find the relationship between manifold dimensionality and the reconstruction error, experiments have been carried out with all the test sequences and dimensionality changing between 3 and 10. [sent-298, score-0.639]
</p><p>72 To simplify visualization of results, all the 12 sequences are separated into 3 groups, those are: small deformation sequences (surprise, talking, cardboard), large deformation sequences (cloth, walking, pick-up, yoga, drink, stretch) and all the dance sequences. [sent-299, score-0.538]
</p><p>73 tF=1(Δtx+Δty+Δtz)  (10)  where Δtx,Δty,Δtz are the standard deviations of x,y and z coordinates of ground truth shape at tth frame and etp is the Euclidean distance between corresponding point p at frame t in the reconstructed and ground truth shapes. [sent-303, score-0.247]
</p><p>74 2 shows the means of reconstruction error for each group and the overall average results when different manifold dimensions K are used. [sent-305, score-0.516]
</p><p>75 As expected, in general, increasing the number of manifold dimensions decreases the error. [sent-306, score-0.34]
</p><p>76 This is especially true for the group of dance sequences and the group representing large deformations. [sent-307, score-0.282]
</p><p>77 This does make sense as only a small number of basis shapes is required to describe the data variability containing only relatively small number of degrees of freedom. [sent-310, score-0.501]
</p><p>78 Bars left to right: Group of small deformation sequences, group of large deformation sequences, group of all dance sequences, all the sequences. [sent-312, score-0.319]
</p><p>79 Sensitivity to noise In most cases, inaccurate 2D measurement caused by feature tracking/detection error may lead to shape reconstruction failure for most previously proposed approaches, as those are very sensitive to noise. [sent-315, score-0.434]
</p><p>80 The measurement W was perturbed by Gaussian noise according to the standard deviation of the measurement data with given level of noise. [sent-318, score-0.231]
</p><p>81 Even with the noise presented in the measurements, reasonably accurate shapes are still obtainable, showing that manifold based method can produce results that are better than those obtained by previously proposed methods. [sent-328, score-0.662]
</p><p>82 Table 2 summarises the results showing 3D reconstruction errors of each method and each sequence, together with the optimal number of bases for which minimal reconstruction error on the test data is obtained. [sent-332, score-0.237]
</p><p>83 6543210KPMCDSTFAM2Le4vlof6Ni8se102  (a) (b) Figure 3: Reconstruction error as function of the measurement noise for the walking data. [sent-335, score-0.235]
</p><p>84 (a) Our method with varying number of manifold dimension K; (b) Our method evaluated against four other methods. [sent-336, score-0.34]
</p><p>85 The best result for DM method is chosen by changing manifold dimension K from 3 to 10. [sent-338, score-0.34]
</p><p>86 Considering the ambiguity of estimated camera motion [2], the shapes are aligned using a single global rotation based on Procrustes alignment method. [sent-339, score-0.472]
</p><p>87 As shown on the Table 2, trajectory based methods PTA, CSF and KSFM are able to provide comparable results, to the proposed method on objects with small deformations (e. [sent-340, score-0.303]
</p><p>88 But those methods provide relatively large error on highly non-rigid human motion sequences (e. [sent-345, score-0.307]
</p><p>89 Note that although the initial shapes of our method may not belong to the manifold M, after optimisation process, the results demonstrate good convergence msinisceat tiohen 3prDo errors are relatively somnsaltlr. [sent-350, score-0.747]
</p><p>90 4 shows a comparison of our reconstructed shapes with the results obtained from MP, PTA, KSFM methods. [sent-360, score-0.337]
</p><p>91 Comments and Future work The paper presented a new approach to integrate the idea from non-linear manifold learning techniques into the NRSfM framework for the task of reconstructing complex and highly deformable shapes. [sent-362, score-0.503]
</p><p>92 The diffusion maps have been introduced in order to build non-linear shape prior manifold. [sent-363, score-0.495]
</p><p>93 This approach significantly improved the reconstruction quality and is well-adapted to large deformation of complex objects, especially for non-rigid articulated body movement, which cannot be accurately represented in a linear subspace. [sent-364, score-0.342]
</p><p>94 As we only use limited number of shapes in training pro-  cess, to overcome this, the future work would include collecting and generating data for building a sufficiently dense representation of the manifold to further improve the performance. [sent-367, score-0.654]
</p><p>95 As manifold learning has shown to be a very powerful approach for analysis of the shapes, we believe the manifold based method is a suitable groundwork for reconstruction of deformable shapes. [sent-368, score-0.896]
</p><p>96 A factorization approach to structure from motion with shape priors. [sent-431, score-0.365]
</p><p>97 Computing smooth timetrajectories for camera and deformable shape in structure from motion with occlusion. [sent-449, score-0.512]
</p><p>98 Nonrigid structure-from-motion: Estimating shape and motion with hierarchical priors. [sent-509, score-0.284]
</p><p>99 A closed-form solution to non-rigid shape and motion recovery. [sent-542, score-0.284]
</p><p>100 A factorization-based approach for articulated nonrigid shape, motion and kinematic chain recovery from video. [sent-547, score-0.31]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('manifold', 0.34), ('nrsfm', 0.299), ('shapes', 0.277), ('diffusion', 0.255), ('basis', 0.192), ('trajectory', 0.184), ('shape', 0.153), ('ksfm', 0.152), ('pta', 0.15), ('motion', 0.131), ('deformable', 0.122), ('dance', 0.121), ('deformations', 0.119), ('articulated', 0.109), ('cardboard', 0.108), ('csf', 0.1), ('optimisation', 0.098), ('st', 0.098), ('sequences', 0.095), ('reconstruction', 0.094), ('measurement', 0.093), ('matuszewski', 0.091), ('tlbtl', 0.091), ('xt', 0.091), ('rt', 0.088), ('embedding', 0.075), ('akhter', 0.071), ('nonrigid', 0.07), ('barycentric', 0.067), ('deformation', 0.066), ('reduced', 0.066), ('mp', 0.064), ('camera', 0.064), ('cloth', 0.062), ('minimised', 0.061), ('rtst', 0.061), ('varol', 0.061), ('reconstructed', 0.06), ('tl', 0.059), ('isometric', 0.057), ('xj', 0.057), ('lk', 0.056), ('dm', 0.056), ('dimensionality', 0.055), ('neighbours', 0.054), ('coefficients', 0.054), ('btl', 0.054), ('xtp', 0.054), ('factorisation', 0.054), ('stretch', 0.054), ('bedding', 0.054), ('yoga', 0.054), ('maps', 0.052), ('del', 0.05), ('gotardo', 0.05), ('error', 0.049), ('calculated', 0.049), ('sfm', 0.048), ('walking', 0.048), ('adjacency', 0.047), ('rot', 0.047), ('orthonormality', 0.047), ('noise', 0.045), ('drink', 0.045), ('nystr', 0.045), ('trajectories', 0.043), ('talking', 0.043), ('optimising', 0.043), ('bregler', 0.043), ('initialisation', 0.043), ('coifman', 0.043), ('tz', 0.043), ('arias', 0.043), ('cmu', 0.042), ('structure', 0.042), ('bue', 0.042), ('mapping', 0.041), ('complex', 0.041), ('salzmann', 0.04), ('xi', 0.039), ('factorization', 0.039), ('dimensional', 0.039), ('frames', 0.037), ('training', 0.037), ('surprise', 0.035), ('sensitivity', 0.035), ('dct', 0.035), ('sheikh', 0.035), ('prior', 0.035), ('torresani', 0.034), ('coordinates', 0.034), ('facial', 0.033), ('group', 0.033), ('reprojection', 0.033), ('linear', 0.032), ('rank', 0.032), ('relatively', 0.032), ('predefined', 0.031), ('duality', 0.031), ('closest', 0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000011 <a title="306-tfidf-1" href="./cvpr-2013-Non-rigid_Structure_from_Motion_with_Diffusion_Maps_Prior.html">306 cvpr-2013-Non-rigid Structure from Motion with Diffusion Maps Prior</a></p>
<p>Author: Lili Tao, Bogdan J. Matuszewski</p><p>Abstract: In this paper, a novel approach based on a non-linear manifold learning technique is proposed to recover 3D nonrigid structures from 2D image sequences captured by a single camera. Most ofthe existing approaches assume that 3D shapes can be accurately modelled in a linear subspace. These techniques perform well when the deformations are relatively small or simple, but fail when more complex deformations need to be recovered. The non-linear deformations are often observed in highly flexible objects for which the use of the linear model is impractical. A specific type of shape variations might be governed by only a small number of parameters, therefore can be wellrepresented in a low dimensional manifold. We learn a nonlinear shape prior using diffusion maps method. The key contribution in this paper is the introduction of the shape prior that constrain the reconstructed shapes to lie in the learned manifold. The proposed methodology has been validated quantitatively and qualitatively on 2D points sequences projected from the 3D motion capture data and real 2D video sequences. The comparisons oftheproposed man- ifold based method against several state-of-the-art techniques are shown on different types of deformable objects.</p><p>2 0.38885772 <a title="306-tfidf-2" href="./cvpr-2013-Dense_Variational_Reconstruction_of_Non-rigid_Surfaces_from_Monocular_Video.html">113 cvpr-2013-Dense Variational Reconstruction of Non-rigid Surfaces from Monocular Video</a></p>
<p>Author: Ravi Garg, Anastasios Roussos, Lourdes Agapito</p><p>Abstract: This paper offers the first variational approach to the problem of dense 3D reconstruction of non-rigid surfaces from a monocular video sequence. We formulate nonrigid structure from motion (NRSfM) as a global variational energy minimization problem to estimate dense low-rank smooth 3D shapes for every frame along with the camera motion matrices, given dense 2D correspondences. Unlike traditional factorization based approaches to NRSfM, which model the low-rank non-rigid shape using a fixed number of basis shapes and corresponding coefficients, we minimize the rank of the matrix of time-varying shapes directly via trace norm minimization. In conjunction with this low-rank constraint, we use an edge preserving total-variation regularization term to obtain spatially smooth shapes for every frame. Thanks to proximal splitting techniques the optimization problem can be decomposed into many point-wise sub-problems and simple linear systems which can be easily solved on GPU hardware. We show results on real sequences of different objects (face, torso, beating heart) where, despite challenges in tracking, illumination changes and occlusions, our method reconstructs highly deforming smooth surfaces densely and accurately directly from video, without the need for any prior models or shape templates.</p><p>3 0.23609799 <a title="306-tfidf-3" href="./cvpr-2013-Procrustean_Normal_Distribution_for_Non-rigid_Structure_from_Motion.html">341 cvpr-2013-Procrustean Normal Distribution for Non-rigid Structure from Motion</a></p>
<p>Author: Minsik Lee, Jungchan Cho, Chong-Ho Choi, Songhwai Oh</p><p>Abstract: Non-rigid structure from motion is a fundamental problem in computer vision, which is yet to be solved satisfactorily. The main difficulty of the problem lies in choosing the right constraints for the solution. In this paper, we propose new constraints that are more effective for non-rigid shape recovery. Unlike the other proposals which have mainly focused on restricting the deformation space using rank constraints, our proposal constrains the motion parameters so that the 3D shapes are most closely aligned to each other, which makes the rank constraints unnecessary. Based on these constraints, we define a new class ofprobability distribution called the Procrustean normal distribution and propose a new NRSfM algorithm, EM-PND. The experimental results show that the proposed method outperforms the existing methods, and it works well even if there is no temporal dependence between the observed samples.</p><p>4 0.22429971 <a title="306-tfidf-4" href="./cvpr-2013-Diffusion_Processes_for_Retrieval_Revisited.html">126 cvpr-2013-Diffusion Processes for Retrieval Revisited</a></p>
<p>Author: Michael Donoser, Horst Bischof</p><p>Abstract: In this paper we revisit diffusion processes on affinity graphs for capturing the intrinsic manifold structure defined by pairwise affinity matrices. Such diffusion processes have already proved the ability to significantly improve subsequent applications like retrieval. We give a thorough overview of the state-of-the-art in this field and discuss obvious similarities and differences. Based on our observations, we are then able to derive a generic framework for diffusion processes in the scope of retrieval applications, where the related work represents specific instances of our generic formulation. We evaluate our framework on several retrieval tasks and are able to derive algorithms that e. g. achieve a 100% bullseye score on the popular MPEG7 shape retrieval data set.</p><p>5 0.19138904 <a title="306-tfidf-5" href="./cvpr-2013-Learning_a_Manifold_as_an_Atlas.html">259 cvpr-2013-Learning a Manifold as an Atlas</a></p>
<p>Author: Nikolaos Pitelis, Chris Russell, Lourdes Agapito</p><p>Abstract: In this work, we return to the underlying mathematical definition of a manifold and directly characterise learning a manifold as finding an atlas, or a set of overlapping charts, that accurately describe local structure. We formulate the problem of learning the manifold as an optimisation that simultaneously refines the continuous parameters defining the charts, and the discrete assignment of points to charts. In contrast to existing methods, this direct formulation of a manifold does not require “unwrapping ” the manifold into a lower dimensional space and allows us to learn closed manifolds of interest to vision, such as those corresponding to gait cycles or camera pose. We report state-ofthe-art results for manifold based nearest neighbour classification on vision datasets, and show how the same techniques can be applied to the 3D reconstruction of human motion from a single image.</p><p>6 0.16922268 <a title="306-tfidf-6" href="./cvpr-2013-Kernel_Learning_for_Extrinsic_Classification_of_Manifold_Features.html">237 cvpr-2013-Kernel Learning for Extrinsic Classification of Manifold Features</a></p>
<p>7 0.1687396 <a title="306-tfidf-7" href="./cvpr-2013-Sparse_Subspace_Denoising_for_Image_Manifolds.html">405 cvpr-2013-Sparse Subspace Denoising for Image Manifolds</a></p>
<p>8 0.16289502 <a title="306-tfidf-8" href="./cvpr-2013-Fast_Rigid_Motion_Segmentation_via_Incrementally-Complex_Local_Models.html">170 cvpr-2013-Fast Rigid Motion Segmentation via Incrementally-Complex Local Models</a></p>
<p>9 0.16282849 <a title="306-tfidf-9" href="./cvpr-2013-Hierarchical_Video_Representation_with_Trajectory_Binary_Partition_Tree.html">203 cvpr-2013-Hierarchical Video Representation with Trajectory Binary Partition Tree</a></p>
<p>10 0.14365809 <a title="306-tfidf-10" href="./cvpr-2013-Active_Contours_with_Group_Similarity.html">33 cvpr-2013-Active Contours with Group Similarity</a></p>
<p>11 0.14284942 <a title="306-tfidf-11" href="./cvpr-2013-Harry_Potter%27s_Marauder%27s_Map%3A_Localizing_and_Tracking_Multiple_Persons-of-Interest_by_Nonnegative_Discretization.html">199 cvpr-2013-Harry Potter's Marauder's Map: Localizing and Tracking Multiple Persons-of-Interest by Nonnegative Discretization</a></p>
<p>12 0.14218423 <a title="306-tfidf-12" href="./cvpr-2013-Consensus_of_k-NNs_for_Robust_Neighborhood_Selection_on_Graph-Based_Manifolds.html">91 cvpr-2013-Consensus of k-NNs for Robust Neighborhood Selection on Graph-Based Manifolds</a></p>
<p>13 0.13407792 <a title="306-tfidf-13" href="./cvpr-2013-Top-Down_Segmentation_of_Non-rigid_Visual_Objects_Using_Derivative-Based_Search_on_Sparse_Manifolds.html">433 cvpr-2013-Top-Down Segmentation of Non-rigid Visual Objects Using Derivative-Based Search on Sparse Manifolds</a></p>
<p>14 0.13169894 <a title="306-tfidf-14" href="./cvpr-2013-From_Local_Similarity_to_Global_Coding%3A_An_Application_to_Image_Classification.html">178 cvpr-2013-From Local Similarity to Global Coding: An Application to Image Classification</a></p>
<p>15 0.13092805 <a title="306-tfidf-15" href="./cvpr-2013-Rolling_Riemannian_Manifolds_to_Solve_the_Multi-class_Classification_Problem.html">367 cvpr-2013-Rolling Riemannian Manifolds to Solve the Multi-class Classification Problem</a></p>
<p>16 0.12852713 <a title="306-tfidf-16" href="./cvpr-2013-Articulated_and_Restricted_Motion_Subspaces_and_Their_Signatures.html">46 cvpr-2013-Articulated and Restricted Motion Subspaces and Their Signatures</a></p>
<p>17 0.1268708 <a title="306-tfidf-17" href="./cvpr-2013-MKPLS%3A_Manifold_Kernel_Partial_Least_Squares_for_Lipreading_and_Speaker_Identification.html">276 cvpr-2013-MKPLS: Manifold Kernel Partial Least Squares for Lipreading and Speaker Identification</a></p>
<p>18 0.12313238 <a title="306-tfidf-18" href="./cvpr-2013-Deep_Learning_Shape_Priors_for_Object_Segmentation.html">105 cvpr-2013-Deep Learning Shape Priors for Object Segmentation</a></p>
<p>19 0.11696918 <a title="306-tfidf-19" href="./cvpr-2013-Inductive_Hashing_on_Manifolds.html">223 cvpr-2013-Inductive Hashing on Manifolds</a></p>
<p>20 0.11491308 <a title="306-tfidf-20" href="./cvpr-2013-Kernel_Methods_on_the_Riemannian_Manifold_of_Symmetric_Positive_Definite_Matrices.html">238 cvpr-2013-Kernel Methods on the Riemannian Manifold of Symmetric Positive Definite Matrices</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.246), (1, 0.116), (2, -0.052), (3, 0.012), (4, -0.021), (5, -0.071), (6, 0.001), (7, -0.207), (8, 0.001), (9, -0.028), (10, 0.065), (11, 0.1), (12, -0.203), (13, -0.128), (14, 0.087), (15, 0.018), (16, -0.117), (17, 0.058), (18, -0.191), (19, 0.061), (20, 0.047), (21, 0.038), (22, 0.083), (23, 0.04), (24, 0.07), (25, 0.082), (26, 0.05), (27, 0.029), (28, -0.002), (29, -0.022), (30, 0.033), (31, -0.204), (32, -0.176), (33, -0.035), (34, -0.01), (35, 0.025), (36, -0.034), (37, -0.052), (38, -0.033), (39, -0.13), (40, 0.112), (41, 0.061), (42, -0.008), (43, -0.01), (44, -0.059), (45, -0.082), (46, -0.079), (47, 0.178), (48, 0.007), (49, 0.009)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95801169 <a title="306-lsi-1" href="./cvpr-2013-Non-rigid_Structure_from_Motion_with_Diffusion_Maps_Prior.html">306 cvpr-2013-Non-rigid Structure from Motion with Diffusion Maps Prior</a></p>
<p>Author: Lili Tao, Bogdan J. Matuszewski</p><p>Abstract: In this paper, a novel approach based on a non-linear manifold learning technique is proposed to recover 3D nonrigid structures from 2D image sequences captured by a single camera. Most ofthe existing approaches assume that 3D shapes can be accurately modelled in a linear subspace. These techniques perform well when the deformations are relatively small or simple, but fail when more complex deformations need to be recovered. The non-linear deformations are often observed in highly flexible objects for which the use of the linear model is impractical. A specific type of shape variations might be governed by only a small number of parameters, therefore can be wellrepresented in a low dimensional manifold. We learn a nonlinear shape prior using diffusion maps method. The key contribution in this paper is the introduction of the shape prior that constrain the reconstructed shapes to lie in the learned manifold. The proposed methodology has been validated quantitatively and qualitatively on 2D points sequences projected from the 3D motion capture data and real 2D video sequences. The comparisons oftheproposed man- ifold based method against several state-of-the-art techniques are shown on different types of deformable objects.</p><p>2 0.78630513 <a title="306-lsi-2" href="./cvpr-2013-Dense_Variational_Reconstruction_of_Non-rigid_Surfaces_from_Monocular_Video.html">113 cvpr-2013-Dense Variational Reconstruction of Non-rigid Surfaces from Monocular Video</a></p>
<p>Author: Ravi Garg, Anastasios Roussos, Lourdes Agapito</p><p>Abstract: This paper offers the first variational approach to the problem of dense 3D reconstruction of non-rigid surfaces from a monocular video sequence. We formulate nonrigid structure from motion (NRSfM) as a global variational energy minimization problem to estimate dense low-rank smooth 3D shapes for every frame along with the camera motion matrices, given dense 2D correspondences. Unlike traditional factorization based approaches to NRSfM, which model the low-rank non-rigid shape using a fixed number of basis shapes and corresponding coefficients, we minimize the rank of the matrix of time-varying shapes directly via trace norm minimization. In conjunction with this low-rank constraint, we use an edge preserving total-variation regularization term to obtain spatially smooth shapes for every frame. Thanks to proximal splitting techniques the optimization problem can be decomposed into many point-wise sub-problems and simple linear systems which can be easily solved on GPU hardware. We show results on real sequences of different objects (face, torso, beating heart) where, despite challenges in tracking, illumination changes and occlusions, our method reconstructs highly deforming smooth surfaces densely and accurately directly from video, without the need for any prior models or shape templates.</p><p>3 0.77910018 <a title="306-lsi-3" href="./cvpr-2013-Procrustean_Normal_Distribution_for_Non-rigid_Structure_from_Motion.html">341 cvpr-2013-Procrustean Normal Distribution for Non-rigid Structure from Motion</a></p>
<p>Author: Minsik Lee, Jungchan Cho, Chong-Ho Choi, Songhwai Oh</p><p>Abstract: Non-rigid structure from motion is a fundamental problem in computer vision, which is yet to be solved satisfactorily. The main difficulty of the problem lies in choosing the right constraints for the solution. In this paper, we propose new constraints that are more effective for non-rigid shape recovery. Unlike the other proposals which have mainly focused on restricting the deformation space using rank constraints, our proposal constrains the motion parameters so that the 3D shapes are most closely aligned to each other, which makes the rank constraints unnecessary. Based on these constraints, we define a new class ofprobability distribution called the Procrustean normal distribution and propose a new NRSfM algorithm, EM-PND. The experimental results show that the proposed method outperforms the existing methods, and it works well even if there is no temporal dependence between the observed samples.</p><p>4 0.69525236 <a title="306-lsi-4" href="./cvpr-2013-Learning_a_Manifold_as_an_Atlas.html">259 cvpr-2013-Learning a Manifold as an Atlas</a></p>
<p>Author: Nikolaos Pitelis, Chris Russell, Lourdes Agapito</p><p>Abstract: In this work, we return to the underlying mathematical definition of a manifold and directly characterise learning a manifold as finding an atlas, or a set of overlapping charts, that accurately describe local structure. We formulate the problem of learning the manifold as an optimisation that simultaneously refines the continuous parameters defining the charts, and the discrete assignment of points to charts. In contrast to existing methods, this direct formulation of a manifold does not require “unwrapping ” the manifold into a lower dimensional space and allows us to learn closed manifolds of interest to vision, such as those corresponding to gait cycles or camera pose. We report state-ofthe-art results for manifold based nearest neighbour classification on vision datasets, and show how the same techniques can be applied to the 3D reconstruction of human motion from a single image.</p><p>5 0.61494589 <a title="306-lsi-5" href="./cvpr-2013-Top-Down_Segmentation_of_Non-rigid_Visual_Objects_Using_Derivative-Based_Search_on_Sparse_Manifolds.html">433 cvpr-2013-Top-Down Segmentation of Non-rigid Visual Objects Using Derivative-Based Search on Sparse Manifolds</a></p>
<p>Author: Jacinto C. Nascimento, Gustavo Carneiro</p><p>Abstract: The solution for the top-down segmentation of non-rigid visual objects using machine learning techniques is generally regarded as too complex to be solved in its full generality given the large dimensionality of the search space of the explicit representation ofthe segmentation contour. In order to reduce this complexity, theproblem is usually divided into two stages: rigid detection and non-rigid segmentation. The rationale is based on the fact that the rigid detection can be run in a lower dimensionality space (i.e., less complex and faster) than the original contour space, and its result is then used to constrain the non-rigid segmentation. In this paper, we propose the use of sparse manifolds to reduce the dimensionality of the rigid detection search space of current stateof-the-art top-down segmentation methodologies. The main goals targeted by this smaller dimensionality search space are the decrease of the search running time complexity and the reduction of the training complexity of the rigid detec- tor. These goals are attainable given that both the search and training complexities are function of the dimensionality of the rigid search space. We test our approach in the segmentation of the left ventricle from ultrasound images and lips from frontal face images. Compared to the performance of state-of-the-art non-rigid segmentation system, our experiments show that the use of sparse manifolds for the rigid detection leads to the two goals mentioned above.</p><p>6 0.60956097 <a title="306-lsi-6" href="./cvpr-2013-MKPLS%3A_Manifold_Kernel_Partial_Least_Squares_for_Lipreading_and_Speaker_Identification.html">276 cvpr-2013-MKPLS: Manifold Kernel Partial Least Squares for Lipreading and Speaker Identification</a></p>
<p>7 0.59214467 <a title="306-lsi-7" href="./cvpr-2013-Active_Contours_with_Group_Similarity.html">33 cvpr-2013-Active Contours with Group Similarity</a></p>
<p>8 0.5751788 <a title="306-lsi-8" href="./cvpr-2013-Diffusion_Processes_for_Retrieval_Revisited.html">126 cvpr-2013-Diffusion Processes for Retrieval Revisited</a></p>
<p>9 0.56757259 <a title="306-lsi-9" href="./cvpr-2013-Deep_Learning_Shape_Priors_for_Object_Segmentation.html">105 cvpr-2013-Deep Learning Shape Priors for Object Segmentation</a></p>
<p>10 0.56436825 <a title="306-lsi-10" href="./cvpr-2013-Fast_Rigid_Motion_Segmentation_via_Incrementally-Complex_Local_Models.html">170 cvpr-2013-Fast Rigid Motion Segmentation via Incrementally-Complex Local Models</a></p>
<p>11 0.55227607 <a title="306-lsi-11" href="./cvpr-2013-Rolling_Riemannian_Manifolds_to_Solve_the_Multi-class_Classification_Problem.html">367 cvpr-2013-Rolling Riemannian Manifolds to Solve the Multi-class Classification Problem</a></p>
<p>12 0.55109996 <a title="306-lsi-12" href="./cvpr-2013-Dense_Object_Reconstruction_with_Semantic_Priors.html">110 cvpr-2013-Dense Object Reconstruction with Semantic Priors</a></p>
<p>13 0.54137516 <a title="306-lsi-13" href="./cvpr-2013-Articulated_and_Restricted_Motion_Subspaces_and_Their_Signatures.html">46 cvpr-2013-Articulated and Restricted Motion Subspaces and Their Signatures</a></p>
<p>14 0.53625107 <a title="306-lsi-14" href="./cvpr-2013-PDM-ENLOR%3A_Learning_Ensemble_of_Local_PDM-Based_Regressions.html">321 cvpr-2013-PDM-ENLOR: Learning Ensemble of Local PDM-Based Regressions</a></p>
<p>15 0.52702075 <a title="306-lsi-15" href="./cvpr-2013-Robust_Canonical_Time_Warping_for_the_Alignment_of_Grossly_Corrupted_Sequences.html">358 cvpr-2013-Robust Canonical Time Warping for the Alignment of Grossly Corrupted Sequences</a></p>
<p>16 0.51582104 <a title="306-lsi-16" href="./cvpr-2013-Consensus_of_k-NNs_for_Robust_Neighborhood_Selection_on_Graph-Based_Manifolds.html">91 cvpr-2013-Consensus of k-NNs for Robust Neighborhood Selection on Graph-Based Manifolds</a></p>
<p>17 0.49384949 <a title="306-lsi-17" href="./cvpr-2013-Graph-Laplacian_PCA%3A_Closed-Form_Solution_and_Robustness.html">191 cvpr-2013-Graph-Laplacian PCA: Closed-Form Solution and Robustness</a></p>
<p>18 0.48724177 <a title="306-lsi-18" href="./cvpr-2013-Sparse_Subspace_Denoising_for_Image_Manifolds.html">405 cvpr-2013-Sparse Subspace Denoising for Image Manifolds</a></p>
<p>19 0.47568151 <a title="306-lsi-19" href="./cvpr-2013-Multi-target_Tracking_by_Rank-1_Tensor_Approximation.html">301 cvpr-2013-Multi-target Tracking by Rank-1 Tensor Approximation</a></p>
<p>20 0.46893239 <a title="306-lsi-20" href="./cvpr-2013-Tensor-Based_Human_Body_Modeling.html">426 cvpr-2013-Tensor-Based Human Body Modeling</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.105), (16, 0.021), (26, 0.044), (33, 0.427), (67, 0.042), (69, 0.04), (87, 0.069), (90, 0.17)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.98970985 <a title="306-lda-1" href="./cvpr-2013-Spectral_Modeling_and_Relighting_of_Reflective-Fluorescent_Scenes.html">409 cvpr-2013-Spectral Modeling and Relighting of Reflective-Fluorescent Scenes</a></p>
<p>Author: Antony Lam, Imari Sato</p><p>Abstract: Hyperspectral reflectance data allows for highly accurate spectral relighting under arbitrary illumination, which is invaluable to applications ranging from archiving cultural e-heritage to consumer product design. Past methods for capturing the spectral reflectance of scenes has proven successful in relighting but they all share a common assumption. All the methods do not consider the effects of fluorescence despite fluorescence being found in many everyday objects. In this paper, we describe the very different ways that reflectance and fluorescence interact with illuminants and show the need to explicitly consider fluorescence in the relighting problem. We then propose a robust method based on well established theories of reflectance and fluorescence for imaging each of these components. Finally, we show that we can relight real scenes of reflective-fluorescent surfaces with much higher accuracy in comparison to only considering the reflective component.</p><p>2 0.96616548 <a title="306-lda-2" href="./cvpr-2013-Deformable_Graph_Matching.html">106 cvpr-2013-Deformable Graph Matching</a></p>
<p>Author: Feng Zhou, Fernando De_la_Torre</p><p>Abstract: Graph matching (GM) is a fundamental problem in computer science, and it has been successfully applied to many problems in computer vision. Although widely used, existing GM algorithms cannot incorporate global consistence among nodes, which is a natural constraint in computer vision problems. This paper proposes deformable graph matching (DGM), an extension of GM for matching graphs subject to global rigid and non-rigid geometric constraints. The key idea of this work is a new factorization of the pair-wise affinity matrix. This factorization decouples the affinity matrix into the local structure of each graph and the pair-wise affinity edges. Besides the ability to incorporate global geometric transformations, this factorization offers three more benefits. First, there is no need to compute the costly (in space and time) pair-wise affinity matrix. Second, it provides a unified view of many GM methods and extends the standard iterative closest point algorithm. Third, it allows to use the path-following optimization algorithm that leads to improved optimization strategies and matching performance. Experimental results on synthetic and real databases illustrate how DGM outperforms state-of-the-art algorithms for GM. The code is available at http : / / human s en s ing . c s . cmu .edu / fgm.</p><p>3 0.96543586 <a title="306-lda-3" href="./cvpr-2013-Graph-Laplacian_PCA%3A_Closed-Form_Solution_and_Robustness.html">191 cvpr-2013-Graph-Laplacian PCA: Closed-Form Solution and Robustness</a></p>
<p>Author: Bo Jiang, Chris Ding, Bio Luo, Jin Tang</p><p>Abstract: Principal Component Analysis (PCA) is a widely used to learn a low-dimensional representation. In many applications, both vector data X and graph data W are available. Laplacian embedding is widely used for embedding graph data. Wepropose a graph-Laplacian PCA (gLPCA) to learn a low dimensional representation of X that incorporates graph structures encoded in W. This model has several advantages: (1) It is a data representation model. (2) It has a compact closed-form solution and can be efficiently computed. (3) It is capable to remove corruptions. Extensive experiments on 8 datasets show promising results on image reconstruction and significant improvement on clustering and classification.</p><p>same-paper 4 0.95203614 <a title="306-lda-4" href="./cvpr-2013-Non-rigid_Structure_from_Motion_with_Diffusion_Maps_Prior.html">306 cvpr-2013-Non-rigid Structure from Motion with Diffusion Maps Prior</a></p>
<p>Author: Lili Tao, Bogdan J. Matuszewski</p><p>Abstract: In this paper, a novel approach based on a non-linear manifold learning technique is proposed to recover 3D nonrigid structures from 2D image sequences captured by a single camera. Most ofthe existing approaches assume that 3D shapes can be accurately modelled in a linear subspace. These techniques perform well when the deformations are relatively small or simple, but fail when more complex deformations need to be recovered. The non-linear deformations are often observed in highly flexible objects for which the use of the linear model is impractical. A specific type of shape variations might be governed by only a small number of parameters, therefore can be wellrepresented in a low dimensional manifold. We learn a nonlinear shape prior using diffusion maps method. The key contribution in this paper is the introduction of the shape prior that constrain the reconstructed shapes to lie in the learned manifold. The proposed methodology has been validated quantitatively and qualitatively on 2D points sequences projected from the 3D motion capture data and real 2D video sequences. The comparisons oftheproposed man- ifold based method against several state-of-the-art techniques are shown on different types of deformable objects.</p><p>5 0.93390656 <a title="306-lda-5" href="./cvpr-2013-Learning_Cross-Domain_Information_Transfer_for_Location_Recognition_and_Clustering.html">250 cvpr-2013-Learning Cross-Domain Information Transfer for Location Recognition and Clustering</a></p>
<p>Author: Raghuraman Gopalan</p><p>Abstract: Estimating geographic location from images is a challenging problem that is receiving recent attention. In contrast to many existing methods that primarily model discriminative information corresponding to different locations, we propose joint learning of information that images across locations share and vary upon. Starting with generative and discriminative subspaces pertaining to domains, which are obtained by a hierarchical grouping of images from adjacent locations, we present a top-down approach that first models cross-domain information transfer by utilizing the geometry ofthese subspaces, and then encodes the model results onto individual images to infer their location. We report competitive results for location recognition and clustering on two public datasets, im2GPS and San Francisco, and empirically validate the utility of various design choices involved in the approach.</p><p>6 0.93388408 <a title="306-lda-6" href="./cvpr-2013-Hierarchical_Video_Representation_with_Trajectory_Binary_Partition_Tree.html">203 cvpr-2013-Hierarchical Video Representation with Trajectory Binary Partition Tree</a></p>
<p>7 0.9338398 <a title="306-lda-7" href="./cvpr-2013-Articulated_and_Restricted_Motion_Subspaces_and_Their_Signatures.html">46 cvpr-2013-Articulated and Restricted Motion Subspaces and Their Signatures</a></p>
<p>8 0.9331491 <a title="306-lda-8" href="./cvpr-2013-SCALPEL%3A_Segmentation_Cascades_with_Localized_Priors_and_Efficient_Learning.html">370 cvpr-2013-SCALPEL: Segmentation Cascades with Localized Priors and Efficient Learning</a></p>
<p>9 0.93311375 <a title="306-lda-9" href="./cvpr-2013-Probabilistic_Label_Trees_for_Efficient_Large_Scale_Image_Classification.html">340 cvpr-2013-Probabilistic Label Trees for Efficient Large Scale Image Classification</a></p>
<p>10 0.93302089 <a title="306-lda-10" href="./cvpr-2013-Representing_Videos_Using_Mid-level_Discriminative_Patches.html">355 cvpr-2013-Representing Videos Using Mid-level Discriminative Patches</a></p>
<p>11 0.93295234 <a title="306-lda-11" href="./cvpr-2013-Multi-level_Discriminative_Dictionary_Learning_towards_Hierarchical_Visual_Categorization.html">296 cvpr-2013-Multi-level Discriminative Dictionary Learning towards Hierarchical Visual Categorization</a></p>
<p>12 0.9327451 <a title="306-lda-12" href="./cvpr-2013-Nonparametric_Scene_Parsing_with_Adaptive_Feature_Relevance_and_Semantic_Context.html">309 cvpr-2013-Nonparametric Scene Parsing with Adaptive Feature Relevance and Semantic Context</a></p>
<p>13 0.93235958 <a title="306-lda-13" href="./cvpr-2013-Plane-Based_Content_Preserving_Warps_for_Video_Stabilization.html">333 cvpr-2013-Plane-Based Content Preserving Warps for Video Stabilization</a></p>
<p>14 0.9321838 <a title="306-lda-14" href="./cvpr-2013-Multipath_Sparse_Coding_Using_Hierarchical_Matching_Pursuit.html">304 cvpr-2013-Multipath Sparse Coding Using Hierarchical Matching Pursuit</a></p>
<p>15 0.93211919 <a title="306-lda-15" href="./cvpr-2013-Mesh_Based_Semantic_Modelling_for_Indoor_and_Outdoor_Scenes.html">284 cvpr-2013-Mesh Based Semantic Modelling for Indoor and Outdoor Scenes</a></p>
<p>16 0.93209398 <a title="306-lda-16" href="./cvpr-2013-A_New_Model_and_Simple_Algorithms_for_Multi-label_Mumford-Shah_Problems.html">20 cvpr-2013-A New Model and Simple Algorithms for Multi-label Mumford-Shah Problems</a></p>
<p>17 0.93206275 <a title="306-lda-17" href="./cvpr-2013-Semi-supervised_Node_Splitting_for_Random_Forest_Construction.html">390 cvpr-2013-Semi-supervised Node Splitting for Random Forest Construction</a></p>
<p>18 0.93202072 <a title="306-lda-18" href="./cvpr-2013-Unsupervised_Joint_Object_Discovery_and_Segmentation_in_Internet_Images.html">450 cvpr-2013-Unsupervised Joint Object Discovery and Segmentation in Internet Images</a></p>
<p>19 0.93195713 <a title="306-lda-19" href="./cvpr-2013-Multi-target_Tracking_by_Lagrangian_Relaxation_to_Min-cost_Network_Flow.html">300 cvpr-2013-Multi-target Tracking by Lagrangian Relaxation to Min-cost Network Flow</a></p>
<p>20 0.93193203 <a title="306-lda-20" href="./cvpr-2013-Leveraging_Structure_from_Motion_to_Learn_Discriminative_Codebooks_for_Scalable_Landmark_Classification.html">268 cvpr-2013-Leveraging Structure from Motion to Learn Discriminative Codebooks for Scalable Landmark Classification</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
