<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>427 cvpr-2013-Texture Enhanced Image Denoising via Gradient Histogram Preservation</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-427" href="#">cvpr2013-427</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>427 cvpr-2013-Texture Enhanced Image Denoising via Gradient Histogram Preservation</h1>
<br/><p>Source: <a title="cvpr-2013-427-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Zuo_Texture_Enhanced_Image_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Wangmeng Zuo, Lei Zhang, Chunwei Song, David Zhang</p><p>Abstract: Image denoising is a classical yet fundamental problem in low level vision, as well as an ideal test bed to evaluate various statistical image modeling methods. One of the most challenging problems in image denoising is how to preserve the fine scale texture structures while removing noise. Various natural image priors, such as gradient based prior, nonlocal self-similarity prior, and sparsity prior, have been extensively exploited for noise removal. The denoising algorithms based on these priors, however, tend to smooth the detailed image textures, degrading the image visual quality. To address this problem, in this paper we propose a texture enhanced image denoising (TEID) method by enforcing the gradient distribution of the denoised image to be close to the estimated gradient distribution of the original image. A novel gradient histogram preservation (GHP) algorithm is developed to enhance the texture structures while removing noise. Our experimental results demonstrate that theproposed GHP based TEID can well preserve the texture features of the denoised images, making them look more natural.</p><p>Reference: <a title="cvpr-2013-427-reference" href="../cvpr2013_reference/cvpr-2013-Texture_Enhanced_Image_Denoising_via_Gradient_Histogram_Preservation_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 hk  Abstract Image denoising is a classical yet fundamental problem in low level vision, as well as an ideal test bed to evaluate various statistical image modeling methods. [sent-5, score-0.403]
</p><p>2 One of the most challenging problems in image denoising is how to preserve the fine scale texture structures while removing noise. [sent-6, score-0.588]
</p><p>3 Various natural image priors, such as gradient based prior, nonlocal self-similarity prior, and sparsity prior, have been extensively exploited for noise removal. [sent-7, score-0.439]
</p><p>4 The denoising algorithms based on these priors, however, tend to smooth the detailed image textures, degrading the image visual quality. [sent-8, score-0.393]
</p><p>5 To address this problem, in this paper we propose a texture enhanced image denoising (TEID) method by enforcing the gradient distribution of the denoised image to be close to the estimated gradient distribution of the original image. [sent-9, score-1.113]
</p><p>6 A novel gradient histogram preservation (GHP) algorithm is developed to enhance the texture structures while removing noise. [sent-10, score-0.596]
</p><p>7 Our experimental results demonstrate that theproposed GHP based TEID can well preserve the texture features of the denoised images, making them look more natural. [sent-11, score-0.372]
</p><p>8 Introduction The goal of image denoising is to estimate the latent clean image x from its noisy observation y. [sent-13, score-0.462]
</p><p>9 Image denoising is a classical yet still active topic in image processing and low level vision, while it is an ideal test bed to evaluate various statistical image modeling methods. [sent-15, score-0.403]
</p><p>10 In general, we hope that the denoised image should look like a natural image, and therefore the statistical modeling of natural image priors is crucial to the success of image denoising. [sent-16, score-0.413]
</p><p>11 Based on the fact that natural image gradients exhibit heavy-tailed distributions, gradient-based priors are widely used in image denoising [10, 17, 18]. [sent-17, score-0.499]
</p><p>12 By observing that natural images can be sparsely coded over a redundant dictionary, the sparsity prior has proved to be effective in image denoising via l0-norm or l1-norm minimization [8, 9]. [sent-19, score-0.563]
</p><p>13 Another popular prior is the nonlocal self-similarity (NSS) prior [2, 16]; that is, in natural images there are often many similar patches (i. [sent-20, score-0.279]
</p><p>14 The joint use of sparsity prior and NSS prior has led to state-of-the-art image denoising results [7, 21]. [sent-23, score-0.488]
</p><p>15 However, the many denoising algorithms based on the above priors can still fail to preserve the image fine scale texture structures, which have certain overlap  with noise in the frequency domain. [sent-24, score-0.656]
</p><p>16 The over-smoothing of those detailed texture structures makes the denoised image look less natural, degrading much the visual quality (please refer to Fig. [sent-25, score-0.395]
</p><p>17 On one hand, more fine texture features of the object and scene will be captured; on the other hand, the captured high resolution image is more prone to noise because the smaller size of each pixel makes the exposure less sufficient. [sent-28, score-0.19]
</p><p>18 Considering the fact that texture regions in an image are homogeneous and are usually composed of similar patterns, statistical descriptors such as histogram are more effective to represent them. [sent-31, score-0.277]
</p><p>19 Actually, in literature of texture representation and classification [13, 27, 28], global histogram of some local features is dominantly used as the final feature descriptor for matching. [sent-32, score-0.259]
</p><p>20 All these motivate us to use the histogram of image gradient to design new image denoising models. [sent-34, score-0.686]
</p><p>21 With the above consideration, in this paper we propose a  novel method for texture enhanced image denoising (TEID) via gradient histogram preservation (GHP). [sent-35, score-0.934]
</p><p>22 From the given noisy image y, we will estimate the gradient histogram of 11111222220000013311  Figure 1. [sent-36, score-0.383]
</p><p>23 (a) A cropped image with hair textures; (b) denoised image by the SAPCA-BM3D method [16]; (c) denoised image by the proposed  texture enhanced image denoising via gradient histogram preservation (GHP); (d) the gradient histograms of the denoised images. [sent-38, score-1.767]
</p><p>24 We can see that the proposed GHP method leads to better texture preservation and visual perception, and the gradient histogram of the denoised image by GHP is also closer to the reference gradient histogram estimated from the noisy image. [sent-39, score-1.15]
</p><p>25 , the gradient histogram of the denoised image should be close to hr. [sent-43, score-0.546]
</p><p>26 1, the proposed TEID method can well enhance the image texture regions, which are often over-smoothed by other denoising methods. [sent-45, score-0.489]
</p><p>27 The major contributions of this paper are as follows: (1) A novel image denoising framework, i. [sent-46, score-0.365]
</p><p>28 , TEID, is proposed, which preserves the gradient distribution of the original image. [sent-48, score-0.187]
</p><p>29 The existing image priors can be easily incorporated into the proposed frameworkto improve the quality of denoised image. [sent-49, score-0.297]
</p><p>30 (2) A histogram specification operator is developed to ensure the gradient histogram of denoised image being close to the reference histogram, resulting in a simple yet effective GHP based TEID algorithm. [sent-50, score-0.917]
</p><p>31 Related work  Generally, image denoising methods can be grouped in two categories: model-based methods and learning-based methods. [sent-53, score-0.365]
</p><p>32 Most denoising methods reconstruct the clean image by exploiting some image and noise prior models, and they belong to the first category. [sent-54, score-0.485]
</p><p>33 Numerous image denoising algorithms have been proposed, and here we only review those model-based denoising methods related to our work from a viewpoint of natural image priors. [sent-56, score-0.768]
</p><p>34 One representative class of image priors is the gradient priors based on the observation that natural images generally have a heavytailed distribution of gradients. [sent-60, score-0.369]
</p><p>35 The use of gradient prior can be traced back to 1990s, when Rudin et al. [sent-61, score-0.195]
</p><p>36 Another well-known prior model, the mixture of Gaussians (GMM), can also be used to approximate the distribution of gradient magnitude [10, 19]. [sent-63, score-0.224]
</p><p>37 The image gradient prior is basically a kind of sparsity prior, i. [sent-65, score-0.244]
</p><p>38 More gener-  ally, the sparsity prior has been well applied to filter responses, wavelet/curvelet transform coefficients, or the coding coefficients over a redundant dictionary. [sent-68, score-0.194]
</p><p>39 , K-SVD [9], task driven DL [20], and ASDS [8]) have been proposed and applied to image denoising and other restoration tasks. [sent-73, score-0.462]
</p><p>40 The seminal work of nonlocal means denoising in [2] has motivated a wide range of studies on NSS, and has led to a flurry of NSS based state-of-the-art denoising methods, e. [sent-77, score-0.876]
</p><p>41 Different image priors characterize different and complementary aspects of natural image statistics, and thus it is possible to combine multiple priors to improve the denoising performance. [sent-80, score-0.567]
</p><p>42 [7] unified both image local sparsity and nonlocal similarity priors via clustering-based sparse representation. [sent-82, score-0.293]
</p><p>43 However, many existing image denoising algorithms, including those sparsity and NSS priors based ones, tend to wipe out the image detailed textures while removing noise. [sent-85, score-0.584]
</p><p>44 As we discussed in the Introduction section, considering the randomness and homogeneousness of image texture regions, we propose to use the histogram of gradient to describe the image texture and design new image denoising algorithm with gradient histogram preservation. [sent-86, score-1.222]
</p><p>45 used hyper-Laplacian to model gradient, and proposed a content-aware prior for image deblurring by setting different shape parameters of gradient distribution in different image regions. [sent-88, score-0.266]
</p><p>46 By matching the gradient distribution prior, Cho et al. [sent-89, score-0.187]
</p><p>47 However, in [4, 5] the estimation of desired gradient distribution is rather heuristic, and the gradient histogram matching algorithm is very complex. [sent-91, score-0.508]
</p><p>48 The denoising model Given a clean image x, the noisy observation y of x is usually modeled as y = x + v, (1) where v is the additive white Gaussian noise (AWGN) with zero mean and standard deviation σ. [sent-96, score-0.532]
</p><p>49 The goal of image denoising is to estimate the desired image x from y. [sent-97, score-0.383]
</p><p>50 One popular approach to image denoising is the variational method, in which the denoised image is obtained by xˆ = +μ where R(x) denotes some regulariz? [sent-98, score-0.59]
</p><p>51 One common problem of image denoising methods is that the image fine scale details such as texture structures will be over-smoothed. [sent-103, score-0.531]
</p><p>52 Intuitively, a good estimation of x without smoothing too much the textures should have a similar gradient distribution to that of x. [sent-105, score-0.257]
</p><p>53 With this motivation, we propose a gradient histogram preservation (GHP) model for texture enhanced image denoising (TEID). [sent-106, score-0.934]
</p><p>54 Our intuitive idea is to integrate the gradient histogram prior with the other image priors to further improve the denoising performance. [sent-107, score-0.795]
</p><p>55 Suppose that we have an estimation ofthe gradient histogram ofx, denoted by hr (the estimation method will be discussed in Section 4). [sent-108, score-0.401]
</p><p>56 In order to make the gradient histogram of denoised image ˆx nearly the same as  argminx? [sent-109, score-0.546]
</p><p>57 ,  ,  the reference histogram hr, we propose the following GHP based image denoising model: xˆ =  argminx,F? [sent-113, score-0.572]
</p><p>58 hF = hr  (2) where F denotes an odd function which is monotonically non-descending in (0, +∞), hF denotes the histogram of the tnroann-sdfeosrmceendd gradient image h|F (∇x)|, and ∇ denotes the gradtriaennstf operator. [sent-121, score-0.401]
</p><p>59 Given F, we can fix ∇x0 = F(∇x), and use the conventional denoising mcaenth foixds ∇ txo update x. [sent-123, score-0.421]
</p><p>60 aGndive uns x, we can update d Fe simply by the histogram operator introduced in Section 3. [sent-124, score-0.249]
</p><p>61 Thus, with the introduction of F, we can easily incorporate gradient histogram prior with any existing image priors R(x). [sent-126, score-0.43]
</p><p>62 Specifically, we adopt the sparse nonlocal regularization term proposed in the centralized sparse representation (CSR) model [7], resulting in the following denoising model:  xˆ = argminx,F? [sent-128, score-0.623]
</p><p>63 hr  where λ is the regularization parameter, D is the dictionary and α is the coding coefficients of x over D. [sent-141, score-0.257]
</p><p>64 Each xi is coded over the dictionary D, and the coding coefficients is αi. [sent-148, score-0.173]
</p><p>65 (4) is that we use xˆi = Dαi to reconstruct each patch xi, and then put all reconstructed patches together as the denoised image ˆx (the overlapped pixels between neighboring patches are averaged). [sent-156, score-0.305]
</p><p>66 (3), βi is the nonlocal means of αi in the sparse coding domain. [sent-158, score-0.222]
</p><p>67 Next, we will see that there is an efficient iterative histogram specification algorithm to solve the model in Eq. [sent-200, score-0.317]
</p><p>68 (7)  To get the solution to the above sub-problem, we first use a gradient descent method to update x: x(k+1/2) = x(k) +  δ? [sent-228, score-0.214]
</p><p>69 (11)  To solve this sub-problem, we let d0 = |∇x|, and use the standard histogram specification operator |[∇1x2]| ,t aon odb utasine tthhee monotonic non-parametric mapping function F so that the histogram of |F (∇x)| is the same as hr. [sent-245, score-0.49]
</p><p>70 Finally, we Fs (u∇mxm)|a isriz the our proposed iterative histogram specification based GHP algorithm in Algorithm 1. [sent-246, score-0.317]
</p><p>71 It  should be noted that, for any gradient based image denoising model, we can easily incorporate the proposed GHP in it by simply modifying the gradient term and adding an extra histogram specification operation. [sent-247, score-0.978]
</p><p>72 Update the coding coeff+icμi∇ents(g o −f ∇eaxch patch: αi(k+1/2) = DTRix(k+1/2) Update the nonlocal mean of coding vector αi: βi ? [sent-264, score-0.246]
</p><p>73 Update x x(k+1) = D ◦ α(k+1) Update F= =v iDa histogram specification by Eq. [sent-270, score-0.297]
</p><p>74 Reference gradient histogram estimation To apply the model in Eq. [sent-276, score-0.321]
</p><p>75 (3), we need to know the reference histogram hr, which is supposed to be the gradient histogram of original image x. [sent-277, score-0.528]
</p><p>76 In this section, we propose a one dimensional deconvolution model to estimate the histogram hr. [sent-278, score-0.212]
</p><p>77 (13)  (14)  If we use the normalized histogram hx and hy to approximate px and py, we can rewrite Eq. [sent-316, score-0.392]
</p><p>78 Note that hg can wbeh eobreta ⊗in deden by discretizing pg, ann odp hy can N beo computed directly from the noisy observation y. [sent-318, score-0.166]
</p><p>79 ome regularization term based on the prior information of natural image’s gradient histogram. [sent-328, score-0.264]
</p><p>80 2 shows an example of reference gradient histogram estimation. [sent-357, score-0.365]
</p><p>81 Experimental results We first give the parameter setting in our GHP based TEID algorithm, and then conduct experiments to validate its performance in comparison with state-of-the-art denoising algorithms. [sent-360, score-0.365]
</p><p>82 Some state-of-the-art denoising methods are used for comparison, including shape-adaptive PCA based BM3D (SAPCA-BM3D) [16], the learned simultaneously sparse coding (LSSC) [21] and the CSR [7] methods. [sent-386, score-0.441]
</p><p>83 Considering the fact when noise is too strong, all methods cannot recover the fine scale texture structures in the image, and in practice the noise is often moderate or be-  low, we set the AWGN noise level σ ∈ {20, 25, 30, 35, 40} ilonw wth,e w experiments. [sent-388, score-0.31]
</p><p>84 Nonetheless, the goal of our GHP method is to preserve and enhance the image texture structures, and let’s compare the visual quality of the denoised images by these methods. [sent-392, score-0.378]
</p><p>85 Though they have good PSNR and even SSIM indices, the denoised images by them look somewhat unnatural. [sent-397, score-0.247]
</p><p>86 (a) Real and simulated AWGN gradient histograms (noise level σ  = 30);  (b) real and simulated gradient histograms of noisy image; and (c) real and estimated gradient histograms of the clean image. [sent-401, score-0.553]
</p><p>87 σ20S2A5PCA-3B0M3D[136]5402025LSS3C0[21]35402025CS3R0[7]35402025G3H0P3540  preserves much better these fine texture areas, making the denoised image look more natural and visually pleasant. [sent-404, score-0.427]
</p><p>88 Discussions It is worth noting that, to further enhance the noise removal and texture preservation performance of our method, region-based GHP could be implemented. [sent-409, score-0.271]
</p><p>89 Since natural images often consist of different regions with different textures, the gradient distributions in these regions will also vary. [sent-410, score-0.196]
</p><p>90 5(c), GHP leads to very satisfying denoising  results in all regions. [sent-420, score-0.365]
</p><p>91 Conclusion In this paper, we presented a novel gradient histogram preserving (GHP) model for texture-enhanced image denoising (TEID). [sent-423, score-0.686]
</p><p>92 The GHP model can preserve the gradient distribution by pushing the gradient histogram of the denoised image toward the reference histogram, and thus is promising in enhancing the texture structure while re1 1 12 2 20 0 068 6  moving random noise. [sent-424, score-0.902]
</p><p>93 To implement the GHP model, we proposed an efficient iterative histogram specification algorithm. [sent-425, score-0.317]
</p><p>94 Meanwhile, we presented a simple but theoretically  solid algorithm to estimate the reference gradient histogram from the noisy image. [sent-426, score-0.427]
</p><p>95 The proposed GHP has similar PSNR/SSIM measures to state-of-the-art denoising methods such as SAPCA-BM3D, LSSC and CSR; however, it leads to more natural and visually pleasant denoising results by preserving better the image texture areas. [sent-428, score-0.864]
</p><p>96 A review of image denoising methods, with a new one. [sent-443, score-0.365]
</p><p>97 Image denoising via sparse and redundant representations over learned dictionaries. [sent-509, score-0.415]
</p><p>98 Image denoising using a scale mixture of gaussians in the wavelet domain. [sent-619, score-0.408]
</p><p>99 (a) Noisy image with AWGN of standard deviation 30; (b) SAPCA-BM3D [16] restoration result; (c) LSSC [21] restoration result; (d) CSR [7] restoration result; (e) GHP restoration result; (f) ground truth. [sent-682, score-0.388]
</p><p>100 (a) Top: noisy image with AWGN of standard deviation 30; bottom: a two-region segmentation of it; (b) SAPCA-BM3D [16] restoration results; (c) GHP restoration results without segmentation; (d) GHP restoration results with segmentation; (e) ground truth. [sent-685, score-0.335]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ghp', 0.664), ('denoising', 0.365), ('denoised', 0.225), ('teid', 0.209), ('histogram', 0.163), ('gradient', 0.158), ('nonlocal', 0.146), ('specification', 0.134), ('nss', 0.118), ('awgn', 0.114), ('lssc', 0.101), ('preservation', 0.099), ('restoration', 0.097), ('texture', 0.096), ('hx', 0.09), ('csr', 0.084), ('hr', 0.08), ('priors', 0.072), ('hy', 0.07), ('textures', 0.07), ('px', 0.069), ('dictionary', 0.062), ('wiq', 0.057), ('update', 0.056), ('enhanced', 0.053), ('hg', 0.052), ('coding', 0.05), ('sparsity', 0.049), ('noise', 0.048), ('fine', 0.046), ('py', 0.045), ('pdf', 0.044), ('noisy', 0.044), ('reference', 0.044), ('iq', 0.043), ('deblurring', 0.042), ('ssim', 0.039), ('patch', 0.038), ('natural', 0.038), ('attouch', 0.038), ('dtrix', 0.038), ('qwiq', 0.038), ('prior', 0.037), ('clean', 0.035), ('alternating', 0.035), ('pg', 0.034), ('hf', 0.034), ('cho', 0.034), ('coefficients', 0.034), ('joshi', 0.031), ('rudin', 0.031), ('regularization', 0.031), ('deconvolution', 0.031), ('psnr', 0.03), ('operator', 0.03), ('zitnick', 0.03), ('centralized', 0.029), ('preserve', 0.029), ('distribution', 0.029), ('removing', 0.028), ('degrading', 0.028), ('enhance', 0.028), ('coded', 0.027), ('pca', 0.027), ('vea', 0.027), ('szeliski', 0.026), ('sparse', 0.026), ('jancsary', 0.026), ('gaussians', 0.025), ('ky', 0.024), ('structures', 0.024), ('redundant', 0.024), ('gradients', 0.024), ('dong', 0.023), ('wainwright', 0.023), ('minimization', 0.023), ('nonconvex', 0.023), ('randomness', 0.023), ('additive', 0.022), ('look', 0.022), ('patches', 0.021), ('surrogate', 0.02), ('bed', 0.02), ('iterative', 0.02), ('laplacian', 0.02), ('convexity', 0.02), ('kang', 0.02), ('characterize', 0.02), ('proximal', 0.019), ('varma', 0.019), ('white', 0.018), ('estimate', 0.018), ('mairal', 0.018), ('water', 0.018), ('durand', 0.018), ('hong', 0.018), ('statistical', 0.018), ('wavelet', 0.018), ('kong', 0.018), ('guarantee', 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="427-tfidf-1" href="./cvpr-2013-Texture_Enhanced_Image_Denoising_via_Gradient_Histogram_Preservation.html">427 cvpr-2013-Texture Enhanced Image Denoising via Gradient Histogram Preservation</a></p>
<p>Author: Wangmeng Zuo, Lei Zhang, Chunwei Song, David Zhang</p><p>Abstract: Image denoising is a classical yet fundamental problem in low level vision, as well as an ideal test bed to evaluate various statistical image modeling methods. One of the most challenging problems in image denoising is how to preserve the fine scale texture structures while removing noise. Various natural image priors, such as gradient based prior, nonlocal self-similarity prior, and sparsity prior, have been extensively exploited for noise removal. The denoising algorithms based on these priors, however, tend to smooth the detailed image textures, degrading the image visual quality. To address this problem, in this paper we propose a texture enhanced image denoising (TEID) method by enforcing the gradient distribution of the denoised image to be close to the estimated gradient distribution of the original image. A novel gradient histogram preservation (GHP) algorithm is developed to enhance the texture structures while removing noise. Our experimental results demonstrate that theproposed GHP based TEID can well preserve the texture features of the denoised images, making them look more natural.</p><p>2 0.23108035 <a title="427-tfidf-2" href="./cvpr-2013-Sparse_Subspace_Denoising_for_Image_Manifolds.html">405 cvpr-2013-Sparse Subspace Denoising for Image Manifolds</a></p>
<p>Author: Bo Wang, Zhuowen Tu</p><p>Abstract: With the increasing availability of high dimensional data and demand in sophisticated data analysis algorithms, manifold learning becomes a critical technique to perform dimensionality reduction, unraveling the intrinsic data structure. The real-world data however often come with noises and outliers; seldom, all the data live in a single linear subspace. Inspired by the recent advances in sparse subspace learning and diffusion-based approaches, we propose a new manifold denoising algorithm in which data neighborhoods are adaptively inferred via sparse subspace reconstruction; we then derive a new formulation to perform denoising to the original data. Experiments carried out on both toy and real applications demonstrate the effectiveness of our method; it is insensitive to parameter tuning and we show significant improvement over the competing algorithms.</p><p>3 0.15626362 <a title="427-tfidf-3" href="./cvpr-2013-Fast_Patch-Based_Denoising_Using_Approximated_Patch_Geodesic_Paths.html">169 cvpr-2013-Fast Patch-Based Denoising Using Approximated Patch Geodesic Paths</a></p>
<p>Author: Xiaogang Chen, Sing Bing Kang, Jie Yang, Jingyi Yu</p><p>Abstract: Patch-based methods such as Non-Local Means (NLM) and BM3D have become the de facto gold standard for image denoising. The core of these approaches is to use similar patches within the image as cues for denoising. The operation usually requires expensive pair-wise patch comparisons. In this paper, we present a novel fast patch-based denoising technique based on Patch Geodesic Paths (PatchGP). PatchGPs treat image patches as nodes and patch differences as edge weights for computing the shortest (geodesic) paths. The path lengths can then be used as weights of the smoothing/denoising kernel. We first show that, for natural images, PatchGPs can be effectively approximated by minimum hop paths (MHPs) that generally correspond to Euclidean line paths connecting two patch nodes. To construct the denoising kernel, we further discretize the MHP search directions and use only patches along the search directions. Along each MHP, we apply a weightpropagation scheme to robustly and efficiently compute the path distance. To handle noise at multiple scales, we conduct wavelet image decomposition and apply PatchGP scheme at each scale. Comprehensive experiments show that our approach achieves comparable quality as the state-of-the-art methods such as NLM and BM3D but is a few orders of magnitude faster.</p><p>4 0.15106219 <a title="427-tfidf-4" href="./cvpr-2013-Handling_Noise_in_Single_Image_Deblurring_Using_Directional_Filters.html">198 cvpr-2013-Handling Noise in Single Image Deblurring Using Directional Filters</a></p>
<p>Author: Lin Zhong, Sunghyun Cho, Dimitris Metaxas, Sylvain Paris, Jue Wang</p><p>Abstract: State-of-the-art single image deblurring techniques are sensitive to image noise. Even a small amount of noise, which is inevitable in low-light conditions, can degrade the quality of blur kernel estimation dramatically. The recent approach of Tai and Lin [17] tries to iteratively denoise and deblur a blurry and noisy image. However, as we show in this work, directly applying image denoising methods often partially damages the blur information that is extracted from the input image, leading to biased kernel estimation. We propose a new method for handling noise in blind image deconvolution based on new theoretical and practical insights. Our key observation is that applying a directional low-pass filter to the input image greatly reduces the noise level, while preserving the blur information in the orthogonal direction to the filter. Based on this observation, our method applies a series of directional filters at different orientations to the input image, and estimates an accurate Radon transform of the blur kernel from each filtered image. Finally, we reconstruct the blur kernel using inverse Radon transform. Experimental results on synthetic and real data show that our algorithm achieves higher quality results than previous approaches on blurry and noisy images. 1</p><p>5 0.11224885 <a title="427-tfidf-5" href="./cvpr-2013-Separating_Signal_from_Noise_Using_Patch_Recurrence_across_Scales.html">393 cvpr-2013-Separating Signal from Noise Using Patch Recurrence across Scales</a></p>
<p>Author: Maria Zontak, Inbar Mosseri, Michal Irani</p><p>Abstract: Recurrence of small clean image patches across different scales of a natural image has been successfully used for solving ill-posed problems in clean images (e.g., superresolution from a single image). In this paper we show how this multi-scale property can be extended to solve ill-posed problems under noisy conditions, such as image denoising. While clean patches are obscured by severe noise in the original scale of a noisy image, noise levels drop dramatically at coarser image scales. This allows for the unknown hidden clean patches to “naturally emerge ” in some coarser scale of the noisy image. We further show that patch recurrence across scales is strengthened when using directional pyramids (that blur and subsample only in one direction). Our statistical experiments show that for almost any noisy image patch (more than 99%), there exists a “good” clean version of itself at the same relative image coordinates in some coarser scale of the image.This is a strong phenomenon of noise-contaminated natural images, which can serve as a strong prior for separating the signal from the noise. Finally, incorporating this multi-scale prior into a simple denoising algorithm yields state-of-the-art denois- ing results.</p><p>6 0.10658139 <a title="427-tfidf-6" href="./cvpr-2013-Discriminative_Non-blind_Deblurring.html">131 cvpr-2013-Discriminative Non-blind Deblurring</a></p>
<p>7 0.099313021 <a title="427-tfidf-7" href="./cvpr-2013-A_Machine_Learning_Approach_for_Non-blind_Image_Deconvolution.html">17 cvpr-2013-A Machine Learning Approach for Non-blind Image Deconvolution</a></p>
<p>8 0.097371399 <a title="427-tfidf-8" href="./cvpr-2013-A_New_Model_and_Simple_Algorithms_for_Multi-label_Mumford-Shah_Problems.html">20 cvpr-2013-A New Model and Simple Algorithms for Multi-label Mumford-Shah Problems</a></p>
<p>9 0.090423696 <a title="427-tfidf-9" href="./cvpr-2013-Structured_Face_Hallucination.html">415 cvpr-2013-Structured Face Hallucination</a></p>
<p>10 0.084129117 <a title="427-tfidf-10" href="./cvpr-2013-Beta_Process_Joint_Dictionary_Learning_for_Coupled_Feature_Spaces_with_Application_to_Single_Image_Super-Resolution.html">58 cvpr-2013-Beta Process Joint Dictionary Learning for Coupled Feature Spaces with Application to Single Image Super-Resolution</a></p>
<p>11 0.080516569 <a title="427-tfidf-11" href="./cvpr-2013-Unnatural_L0_Sparse_Representation_for_Natural_Image_Deblurring.html">449 cvpr-2013-Unnatural L0 Sparse Representation for Natural Image Deblurring</a></p>
<p>12 0.072290234 <a title="427-tfidf-12" href="./cvpr-2013-Learning_Structured_Low-Rank_Representations_for_Image_Classification.html">257 cvpr-2013-Learning Structured Low-Rank Representations for Image Classification</a></p>
<p>13 0.06999585 <a title="427-tfidf-13" href="./cvpr-2013-Multi-image_Blind_Deblurring_Using_a_Coupled_Adaptive_Sparse_Prior.html">295 cvpr-2013-Multi-image Blind Deblurring Using a Coupled Adaptive Sparse Prior</a></p>
<p>14 0.069952585 <a title="427-tfidf-14" href="./cvpr-2013-Enriching_Texture_Analysis_with_Semantic_Data.html">146 cvpr-2013-Enriching Texture Analysis with Semantic Data</a></p>
<p>15 0.067395888 <a title="427-tfidf-15" href="./cvpr-2013-Fast_Image_Super-Resolution_Based_on_In-Place_Example_Regression.html">166 cvpr-2013-Fast Image Super-Resolution Based on In-Place Example Regression</a></p>
<p>16 0.066790171 <a title="427-tfidf-16" href="./cvpr-2013-Online_Robust_Dictionary_Learning.html">315 cvpr-2013-Online Robust Dictionary Learning</a></p>
<p>17 0.064825103 <a title="427-tfidf-17" href="./cvpr-2013-Learning_Separable_Filters.html">255 cvpr-2013-Learning Separable Filters</a></p>
<p>18 0.063978031 <a title="427-tfidf-18" href="./cvpr-2013-Multi-level_Discriminative_Dictionary_Learning_towards_Hierarchical_Visual_Categorization.html">296 cvpr-2013-Multi-level Discriminative Dictionary Learning towards Hierarchical Visual Categorization</a></p>
<p>19 0.063226908 <a title="427-tfidf-19" href="./cvpr-2013-Generalized_Domain-Adaptive_Dictionaries.html">185 cvpr-2013-Generalized Domain-Adaptive Dictionaries</a></p>
<p>20 0.062903658 <a title="427-tfidf-20" href="./cvpr-2013-Block_and_Group_Regularized_Sparse_Modeling_for_Dictionary_Learning.html">66 cvpr-2013-Block and Group Regularized Sparse Modeling for Dictionary Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.121), (1, 0.018), (2, -0.059), (3, 0.124), (4, -0.036), (5, 0.079), (6, 0.021), (7, -0.001), (8, -0.023), (9, -0.009), (10, 0.003), (11, -0.028), (12, -0.029), (13, -0.012), (14, 0.024), (15, 0.021), (16, -0.038), (17, -0.036), (18, 0.093), (19, 0.024), (20, 0.054), (21, 0.112), (22, 0.012), (23, -0.074), (24, -0.032), (25, -0.007), (26, -0.024), (27, -0.09), (28, 0.013), (29, -0.041), (30, -0.002), (31, -0.05), (32, 0.022), (33, -0.055), (34, -0.108), (35, 0.048), (36, -0.035), (37, -0.044), (38, -0.07), (39, -0.024), (40, -0.009), (41, -0.039), (42, 0.023), (43, -0.03), (44, 0.023), (45, 0.07), (46, -0.01), (47, 0.052), (48, 0.014), (49, -0.066)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92953169 <a title="427-lsi-1" href="./cvpr-2013-Texture_Enhanced_Image_Denoising_via_Gradient_Histogram_Preservation.html">427 cvpr-2013-Texture Enhanced Image Denoising via Gradient Histogram Preservation</a></p>
<p>Author: Wangmeng Zuo, Lei Zhang, Chunwei Song, David Zhang</p><p>Abstract: Image denoising is a classical yet fundamental problem in low level vision, as well as an ideal test bed to evaluate various statistical image modeling methods. One of the most challenging problems in image denoising is how to preserve the fine scale texture structures while removing noise. Various natural image priors, such as gradient based prior, nonlocal self-similarity prior, and sparsity prior, have been extensively exploited for noise removal. The denoising algorithms based on these priors, however, tend to smooth the detailed image textures, degrading the image visual quality. To address this problem, in this paper we propose a texture enhanced image denoising (TEID) method by enforcing the gradient distribution of the denoised image to be close to the estimated gradient distribution of the original image. A novel gradient histogram preservation (GHP) algorithm is developed to enhance the texture structures while removing noise. Our experimental results demonstrate that theproposed GHP based TEID can well preserve the texture features of the denoised images, making them look more natural.</p><p>2 0.81288773 <a title="427-lsi-2" href="./cvpr-2013-Fast_Patch-Based_Denoising_Using_Approximated_Patch_Geodesic_Paths.html">169 cvpr-2013-Fast Patch-Based Denoising Using Approximated Patch Geodesic Paths</a></p>
<p>Author: Xiaogang Chen, Sing Bing Kang, Jie Yang, Jingyi Yu</p><p>Abstract: Patch-based methods such as Non-Local Means (NLM) and BM3D have become the de facto gold standard for image denoising. The core of these approaches is to use similar patches within the image as cues for denoising. The operation usually requires expensive pair-wise patch comparisons. In this paper, we present a novel fast patch-based denoising technique based on Patch Geodesic Paths (PatchGP). PatchGPs treat image patches as nodes and patch differences as edge weights for computing the shortest (geodesic) paths. The path lengths can then be used as weights of the smoothing/denoising kernel. We first show that, for natural images, PatchGPs can be effectively approximated by minimum hop paths (MHPs) that generally correspond to Euclidean line paths connecting two patch nodes. To construct the denoising kernel, we further discretize the MHP search directions and use only patches along the search directions. Along each MHP, we apply a weightpropagation scheme to robustly and efficiently compute the path distance. To handle noise at multiple scales, we conduct wavelet image decomposition and apply PatchGP scheme at each scale. Comprehensive experiments show that our approach achieves comparable quality as the state-of-the-art methods such as NLM and BM3D but is a few orders of magnitude faster.</p><p>3 0.74444646 <a title="427-lsi-3" href="./cvpr-2013-Separating_Signal_from_Noise_Using_Patch_Recurrence_across_Scales.html">393 cvpr-2013-Separating Signal from Noise Using Patch Recurrence across Scales</a></p>
<p>Author: Maria Zontak, Inbar Mosseri, Michal Irani</p><p>Abstract: Recurrence of small clean image patches across different scales of a natural image has been successfully used for solving ill-posed problems in clean images (e.g., superresolution from a single image). In this paper we show how this multi-scale property can be extended to solve ill-posed problems under noisy conditions, such as image denoising. While clean patches are obscured by severe noise in the original scale of a noisy image, noise levels drop dramatically at coarser image scales. This allows for the unknown hidden clean patches to “naturally emerge ” in some coarser scale of the noisy image. We further show that patch recurrence across scales is strengthened when using directional pyramids (that blur and subsample only in one direction). Our statistical experiments show that for almost any noisy image patch (more than 99%), there exists a “good” clean version of itself at the same relative image coordinates in some coarser scale of the image.This is a strong phenomenon of noise-contaminated natural images, which can serve as a strong prior for separating the signal from the noise. Finally, incorporating this multi-scale prior into a simple denoising algorithm yields state-of-the-art denois- ing results.</p><p>4 0.72636449 <a title="427-lsi-4" href="./cvpr-2013-Fast_Image_Super-Resolution_Based_on_In-Place_Example_Regression.html">166 cvpr-2013-Fast Image Super-Resolution Based on In-Place Example Regression</a></p>
<p>Author: Jianchao Yang, Zhe Lin, Scott Cohen</p><p>Abstract: We propose a fast regression model for practical single image super-resolution based on in-place examples, by leveraging two fundamental super-resolution approaches— learning from an external database and learning from selfexamples. Our in-place self-similarity refines the recently proposed local self-similarity by proving that a patch in the upper scale image have good matches around its origin location in the lower scale image. Based on the in-place examples, a first-order approximation of the nonlinear mapping function from low- to high-resolution image patches is learned. Extensive experiments on benchmark and realworld images demonstrate that our algorithm can produce natural-looking results with sharp edges and preserved fine details, while the current state-of-the-art algorithms are prone to visual artifacts. Furthermore, our model can easily extend to deal with noise by combining the regression results on multiple in-place examples for robust estimation. The algorithm runs fast and is particularly useful for practical applications, where the input images typically contain diverse textures and they are potentially contaminated by noise or compression artifacts.</p><p>5 0.70342314 <a title="427-lsi-5" href="./cvpr-2013-A_Machine_Learning_Approach_for_Non-blind_Image_Deconvolution.html">17 cvpr-2013-A Machine Learning Approach for Non-blind Image Deconvolution</a></p>
<p>Author: Christian J. Schuler, Harold Christopher Burger, Stefan Harmeling, Bernhard Schölkopf</p><p>Abstract: Image deconvolution is the ill-posed problem of recovering a sharp image, given a blurry one generated by a convolution. In this work, we deal with space-invariant non- blind deconvolution. Currently, the most successful meth- ods involve a regularized inversion of the blur in Fourier domain as a first step. This step amplifies and colors the noise, and corrupts the image information. In a second (and arguably more difficult) step, one then needs to remove the colored noise, typically using a cleverly engineered algorithm. However, the methods based on this two-step ap- proach do not properly address the fact that the image information has been corrupted. In this work, we also rely on a two-step procedure, but learn the second step on a large dataset of natural images, using a neural network. We will show that this approach outperforms the current state-ofthe-art on a large dataset of artificially blurred images. We demonstrate the practical applicability of our method in a real-world example with photographic out-of-focus blur.</p><p>6 0.59363747 <a title="427-lsi-6" href="./cvpr-2013-What_Makes_a_Patch_Distinct%3F.html">464 cvpr-2013-What Makes a Patch Distinct?</a></p>
<p>7 0.56767046 <a title="427-lsi-7" href="./cvpr-2013-Handling_Noise_in_Single_Image_Deblurring_Using_Directional_Filters.html">198 cvpr-2013-Handling Noise in Single Image Deblurring Using Directional Filters</a></p>
<p>8 0.53973907 <a title="427-lsi-8" href="./cvpr-2013-Learning_without_Human_Scores_for_Blind_Image_Quality_Assessment.html">266 cvpr-2013-Learning without Human Scores for Blind Image Quality Assessment</a></p>
<p>9 0.52630305 <a title="427-lsi-9" href="./cvpr-2013-Sparse_Subspace_Denoising_for_Image_Manifolds.html">405 cvpr-2013-Sparse Subspace Denoising for Image Manifolds</a></p>
<p>10 0.52111435 <a title="427-lsi-10" href="./cvpr-2013-Rotation%2C_Scaling_and_Deformation_Invariant_Scattering_for_Texture_Discrimination.html">369 cvpr-2013-Rotation, Scaling and Deformation Invariant Scattering for Texture Discrimination</a></p>
<p>11 0.50833941 <a title="427-lsi-11" href="./cvpr-2013-Blind_Deconvolution_of_Widefield_Fluorescence_Microscopic_Data_by_Regularization_of_the_Optical_Transfer_Function_%28OTF%29.html">65 cvpr-2013-Blind Deconvolution of Widefield Fluorescence Microscopic Data by Regularization of the Optical Transfer Function (OTF)</a></p>
<p>12 0.50423127 <a title="427-lsi-12" href="./cvpr-2013-Real-Time_No-Reference_Image_Quality_Assessment_Based_on_Filter_Learning.html">346 cvpr-2013-Real-Time No-Reference Image Quality Assessment Based on Filter Learning</a></p>
<p>13 0.49355128 <a title="427-lsi-13" href="./cvpr-2013-Fast_Convolutional_Sparse_Coding.html">164 cvpr-2013-Fast Convolutional Sparse Coding</a></p>
<p>14 0.48703876 <a title="427-lsi-14" href="./cvpr-2013-Stochastic_Deconvolution.html">412 cvpr-2013-Stochastic Deconvolution</a></p>
<p>15 0.48129731 <a title="427-lsi-15" href="./cvpr-2013-Learning_Separable_Filters.html">255 cvpr-2013-Learning Separable Filters</a></p>
<p>16 0.47763583 <a title="427-lsi-16" href="./cvpr-2013-HDR_Deghosting%3A_How_to_Deal_with_Saturation%3F.html">195 cvpr-2013-HDR Deghosting: How to Deal with Saturation?</a></p>
<p>17 0.47313616 <a title="427-lsi-17" href="./cvpr-2013-Multipath_Sparse_Coding_Using_Hierarchical_Matching_Pursuit.html">304 cvpr-2013-Multipath Sparse Coding Using Hierarchical Matching Pursuit</a></p>
<p>18 0.47091594 <a title="427-lsi-18" href="./cvpr-2013-Adaptive_Compressed_Tomography_Sensing.html">35 cvpr-2013-Adaptive Compressed Tomography Sensing</a></p>
<p>19 0.46939129 <a title="427-lsi-19" href="./cvpr-2013-Multi-image_Blind_Deblurring_Using_a_Coupled_Adaptive_Sparse_Prior.html">295 cvpr-2013-Multi-image Blind Deblurring Using a Coupled Adaptive Sparse Prior</a></p>
<p>20 0.45140696 <a title="427-lsi-20" href="./cvpr-2013-Discriminative_Non-blind_Deblurring.html">131 cvpr-2013-Discriminative Non-blind Deblurring</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.139), (16, 0.03), (26, 0.095), (33, 0.264), (43, 0.21), (67, 0.034), (69, 0.027), (87, 0.061)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.90288562 <a title="427-lda-1" href="./cvpr-2013-Classification_of_Tumor_Histology_via_Morphometric_Context.html">83 cvpr-2013-Classification of Tumor Histology via Morphometric Context</a></p>
<p>Author: Hang Chang, Alexander Borowsky, Paul Spellman, Bahram Parvin</p><p>Abstract: Image-based classification oftissue histology, in terms of different components (e.g., normal signature, categories of aberrant signatures), provides a series of indices for tumor composition. Subsequently, aggregation of these indices in each whole slide image (WSI) from a large cohort can provide predictive models of clinical outcome. However, the performance of the existing techniques is hindered as a result of large technical and biological variations that are always present in a large cohort. In this paper, we propose two algorithms for classification of tissue histology based on robust representations of morphometric context, which are built upon nuclear level morphometric features at various locations and scales within the spatial pyramid matching (SPM) framework. These methods have been evaluated on two distinct datasets of different tumor types collected from The Cancer Genome Atlas (TCGA), and the experimental results indicate that our methods are (i) extensible to different tumor types; (ii) robust in the presence of wide technical and biological variations; (iii) invariant to different nuclear segmentation strategies; and (iv) scalable with varying training sample size. In addition, our experiments suggest that enforcing sparsity, during the construction of morphometric context, further improves the performance of the system.</p><p>2 0.87157333 <a title="427-lda-2" href="./cvpr-2013-Rolling_Shutter_Camera_Calibration.html">368 cvpr-2013-Rolling Shutter Camera Calibration</a></p>
<p>Author: Luc Oth, Paul Furgale, Laurent Kneip, Roland Siegwart</p><p>Abstract: Rolling Shutter (RS) cameras are used across a wide range of consumer electronic devices—from smart-phones to high-end cameras. It is well known, that if a RS camera is used with a moving camera or scene, significant image distortions are introduced. The quality or even success of structure from motion on rolling shutter images requires the usual intrinsic parameters such as focal length and distortion coefficients as well as accurate modelling of the shutter timing. The current state-of-the-art technique for calibrating the shutter timings requires specialised hardware. We present a new method that only requires video of a known calibration pattern. Experimental results on over 60 real datasets show that our method is more accurate than the current state of the art.</p><p>same-paper 3 0.84411526 <a title="427-lda-3" href="./cvpr-2013-Texture_Enhanced_Image_Denoising_via_Gradient_Histogram_Preservation.html">427 cvpr-2013-Texture Enhanced Image Denoising via Gradient Histogram Preservation</a></p>
<p>Author: Wangmeng Zuo, Lei Zhang, Chunwei Song, David Zhang</p><p>Abstract: Image denoising is a classical yet fundamental problem in low level vision, as well as an ideal test bed to evaluate various statistical image modeling methods. One of the most challenging problems in image denoising is how to preserve the fine scale texture structures while removing noise. Various natural image priors, such as gradient based prior, nonlocal self-similarity prior, and sparsity prior, have been extensively exploited for noise removal. The denoising algorithms based on these priors, however, tend to smooth the detailed image textures, degrading the image visual quality. To address this problem, in this paper we propose a texture enhanced image denoising (TEID) method by enforcing the gradient distribution of the denoised image to be close to the estimated gradient distribution of the original image. A novel gradient histogram preservation (GHP) algorithm is developed to enhance the texture structures while removing noise. Our experimental results demonstrate that theproposed GHP based TEID can well preserve the texture features of the denoised images, making them look more natural.</p><p>4 0.82530415 <a title="427-lda-4" href="./cvpr-2013-Occlusion_Patterns_for_Object_Class_Detection.html">311 cvpr-2013-Occlusion Patterns for Object Class Detection</a></p>
<p>Author: Bojan Pepikj, Michael Stark, Peter Gehler, Bernt Schiele</p><p>Abstract: Despite the success of recent object class recognition systems, the long-standing problem of partial occlusion remains a major challenge, and a principled solution is yet to be found. In this paper we leave the beaten path of methods that treat occlusion as just another source of noise instead, we include the occluder itself into the modelling, by mining distinctive, reoccurring occlusion patterns from annotated training data. These patterns are then used as training data for dedicated detectors of varying sophistication. In particular, we evaluate and compare models that range from standard object class detectors to hierarchical, part-based representations of occluder/occludee pairs. In an extensive evaluation we derive insights that can aid further developments in tackling the occlusion challenge. –</p><p>5 0.82151669 <a title="427-lda-5" href="./cvpr-2013-Tracking_People_and_Their_Objects.html">440 cvpr-2013-Tracking People and Their Objects</a></p>
<p>Author: Tobias Baumgartner, Dennis Mitzel, Bastian Leibe</p><p>Abstract: Current pedestrian tracking approaches ignore important aspects of human behavior. Humans are not moving independently, but they closely interact with their environment, which includes not only other persons, but also different scene objects. Typical everyday scenarios include people moving in groups, pushing child strollers, or pulling luggage. In this paper, we propose a probabilistic approach for classifying such person-object interactions, associating objects to persons, and predicting how the interaction will most likely continue. Our approach relies on stereo depth information in order to track all scene objects in 3D, while simultaneously building up their 3D shape models. These models and their relative spatial arrangement are then fed into a probabilistic graphical model which jointly infers pairwise interactions and object classes. The inferred interactions can then be used to support tracking by recovering lost object tracks. We evaluate our approach on a novel dataset containing more than 15,000 frames of personobject interactions in 325 video sequences and demonstrate good performance in challenging real-world scenarios.</p><p>6 0.81893981 <a title="427-lda-6" href="./cvpr-2013-Robust_Estimation_of_Nonrigid_Transformation_for_Point_Set_Registration.html">360 cvpr-2013-Robust Estimation of Nonrigid Transformation for Point Set Registration</a></p>
<p>7 0.81694752 <a title="427-lda-7" href="./cvpr-2013-Exemplar-Based_Face_Parsing.html">152 cvpr-2013-Exemplar-Based Face Parsing</a></p>
<p>8 0.81660771 <a title="427-lda-8" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<p>9 0.81336993 <a title="427-lda-9" href="./cvpr-2013-Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking.html">285 cvpr-2013-Minimum Uncertainty Gap for Robust Visual Tracking</a></p>
<p>10 0.81274629 <a title="427-lda-10" href="./cvpr-2013-Structure_Preserving_Object_Tracking.html">414 cvpr-2013-Structure Preserving Object Tracking</a></p>
<p>11 0.81237864 <a title="427-lda-11" href="./cvpr-2013-Accurate_and_Robust_Registration_of_Nonrigid_Surface_Using_Hierarchical_Statistical_Shape_Model.html">31 cvpr-2013-Accurate and Robust Registration of Nonrigid Surface Using Hierarchical Statistical Shape Model</a></p>
<p>12 0.81205964 <a title="427-lda-12" href="./cvpr-2013-Templateless_Quasi-rigid_Shape_Modeling_with_Implicit_Loop-Closure.html">424 cvpr-2013-Templateless Quasi-rigid Shape Modeling with Implicit Loop-Closure</a></p>
<p>13 0.81133533 <a title="427-lda-13" href="./cvpr-2013-Least_Soft-Threshold_Squares_Tracking.html">267 cvpr-2013-Least Soft-Threshold Squares Tracking</a></p>
<p>14 0.81130129 <a title="427-lda-14" href="./cvpr-2013-Compressible_Motion_Fields.html">88 cvpr-2013-Compressible Motion Fields</a></p>
<p>15 0.81103551 <a title="427-lda-15" href="./cvpr-2013-Maximum_Cohesive_Grid_of_Superpixels_for_Fast_Object_Localization.html">280 cvpr-2013-Maximum Cohesive Grid of Superpixels for Fast Object Localization</a></p>
<p>16 0.8107121 <a title="427-lda-16" href="./cvpr-2013-Part_Discovery_from_Partial_Correspondence.html">325 cvpr-2013-Part Discovery from Partial Correspondence</a></p>
<p>17 0.81029803 <a title="427-lda-17" href="./cvpr-2013-Physically_Plausible_3D_Scene_Tracking%3A_The_Single_Actor_Hypothesis.html">331 cvpr-2013-Physically Plausible 3D Scene Tracking: The Single Actor Hypothesis</a></p>
<p>18 0.81010312 <a title="427-lda-18" href="./cvpr-2013-Correlation_Filters_for_Object_Alignment.html">96 cvpr-2013-Correlation Filters for Object Alignment</a></p>
<p>19 0.80974615 <a title="427-lda-19" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>20 0.80932444 <a title="427-lda-20" href="./cvpr-2013-Optimal_Geometric_Fitting_under_the_Truncated_L2-Norm.html">317 cvpr-2013-Optimal Geometric Fitting under the Truncated L2-Norm</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
