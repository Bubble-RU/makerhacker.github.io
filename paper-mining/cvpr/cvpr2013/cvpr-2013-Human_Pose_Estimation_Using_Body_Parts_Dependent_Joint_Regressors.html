<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>206 cvpr-2013-Human Pose Estimation Using Body Parts Dependent Joint Regressors</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-206" href="#">cvpr2013-206</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>206 cvpr-2013-Human Pose Estimation Using Body Parts Dependent Joint Regressors</h1>
<br/><p>Source: <a title="cvpr-2013-206-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Dantone_Human_Pose_Estimation_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Matthias Dantone, Juergen Gall, Christian Leistner, Luc Van_Gool</p><p>Abstract: In this work, we address the problem of estimating 2d human pose from still images. Recent methods that rely on discriminatively trained deformable parts organized in a tree model have shown to be very successful in solving this task. Within such a pictorial structure framework, we address the problem of obtaining good part templates by proposing novel, non-linear joint regressors. In particular, we employ two-layered random forests as joint regressors. The first layer acts as a discriminative, independent body part classifier. The second layer takes the estimated class distributions of the first one into account and is thereby able to predict joint locations by modeling the interdependence and co-occurrence of the parts. This results in a pose estimation framework that takes dependencies between body parts already for joint localization into account and is thus able to circumvent typical ambiguities of tree structures, such as for legs and arms. In the experiments, we demonstrate that our body parts dependent joint regressors achieve a higher joint localization accuracy than tree-based state-of-the-art methods.</p><p>Reference: <a title="cvpr-2013-206-reference" href="../cvpr2013_reference/cvpr-2013-Human_Pose_Estimation_Using_Body_Parts_Dependent_Joint_Regressors_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Within such a pictorial structure framework, we address the problem of obtaining good part templates by proposing novel, non-linear joint regressors. [sent-10, score-1.034]
</p><p>2 In particular, we employ two-layered random forests as joint regressors. [sent-11, score-0.426]
</p><p>3 The first layer acts as a discriminative, independent body part classifier. [sent-12, score-0.587]
</p><p>4 The second layer takes the estimated class distributions of the first one into account and is thereby able to predict joint locations by modeling the interdependence and co-occurrence of the parts. [sent-13, score-0.348]
</p><p>5 This results in a pose estimation framework that takes dependencies between body parts already for joint localization into account and is thus able to circumvent typical ambiguities of tree structures, such as for legs and arms. [sent-14, score-1.145]
</p><p>6 In the experiments, we demonstrate that our body parts dependent joint regressors achieve a higher joint localization accuracy than tree-based state-of-the-art methods. [sent-15, score-1.357]
</p><p>7 One of the most popular approaches in this area is the pictorial structure framework [13, 11], which models the spatial relations of rigid parts using usually a tree model. [sent-18, score-0.647]
</p><p>8 , by learning better appearance [24, 9, 1] or shape models [42] of the body parts. [sent-21, score-0.336]
</p><p>9 In object detection, one of the best performing methods relies on so called deformable part models [10], which use mixtures of star models over templates of parts. [sent-22, score-0.466]
</p><p>10 Recently, [40] showed that mixtures of part templates can also be efficiently used in a tree model, leading to very powerful pose estimation models. [sent-23, score-0.736]
</p><p>11 In particular, instead of modeling the transformations of a single body part template as in the classical pictorial structure model, the transformations of the  structure (PS) model with independent part templates. [sent-24, score-1.11]
</p><p>12 While the first layer consists of the same independent classifiers, the second layer regresses the locations of the joints in dependency of the independent part classifiers. [sent-34, score-0.621]
</p><p>13 , nose (red), left hip joint (blue), and left knee (green), are more discriminative and resolve the ambiguities between the legs. [sent-37, score-0.507]
</p><p>14 limbs are encoded by different deformable templates per body part. [sent-38, score-0.762]
</p><p>15 While this approach outperforms classical pictorial structure models for human pose estimation, it has been shown in [41] that the used templates, which are scanningwindow templates trained with linear SVMs on HOG features [7], are very sensitive to noise and limit the performance. [sent-39, score-0.989]
</p><p>16 In this work, we thus address the problem of obtaining better part templates in the context of a pictorial structure framework. [sent-40, score-0.821]
</p><p>17 Similar to [40], we do not model the limb transformations explicitly, but use discriminative learned templates that allow the handling of limb pose variations im333000334199  plicitly. [sent-41, score-0.847]
</p><p>18 However, contrary to [40], we do not use noise sensitive, scanning-window templates, but instead propose non-linear regressors for the joint locations. [sent-42, score-0.529]
</p><p>19 As regressors, we rely on random forests that have shown to be fast, robust, and accurate in the context of predicting body parts or joint locations from depth data [29, 15]. [sent-43, score-0.987]
</p><p>20 To this end, we train joint regressors that use the output of independent body part templates as input and  thus predict the location of a joint in dependency of the cooccurrence of other body parts. [sent-46, score-1.918]
</p><p>21 In this way, joint regressors are already able to resolve some typical problems of tree models, such as the discrimination of left and right limbs. [sent-47, score-0.717]
</p><p>22 In our experiments, we show that the proposed body parts dependent joint regressors achieve a much higher joint localization accuracy than independent part templates or joint regressors. [sent-48, score-2.074]
</p><p>23 Integrated into a pictorial structure framework, the approach achieves a better joint localization accuracy than a state-of-the-art method [40] at comparable running time of a few seconds per image. [sent-49, score-0.643]
</p><p>24 In this section, we review only the most related work with a focus on pose estimation within a pictorial structure framework. [sent-53, score-0.555]
</p><p>25 While many approaches relied at the beginning on simple geometric primitives for the body parts and simple color models or background subtraction for the likelihoods, many improvements have been made to the part templates. [sent-55, score-0.539]
</p><p>26 For instance, linear SVMs for learning discriminative part templates were introduced in [26]. [sent-56, score-0.471]
</p><p>27 In [18], a cascade of body parts detec-  tors were proposed to obtain more discriminative templates. [sent-57, score-0.486]
</p><p>28 Other approaches rely on several templates for a single body part [32, 40]. [sent-58, score-0.779]
</p><p>29 Furthermore, human body models have been used to obtain better shapes of the body parts [42] or to synthesize training data [23]. [sent-59, score-0.881]
</p><p>30 Another research direction has focused on introducing richer body models that overcome the limitation of tree structures. [sent-61, score-0.452]
</p><p>31 For instance, a body part can be assigned with high confidence to two nodes of a tree in case of weak part templates or occlusions, e. [sent-62, score-1.001]
</p><p>32 , the left and right body part are sometimes assigned to a single observation. [sent-64, score-0.417]
</p><p>33 Besides of independent part templates for body parts, also hierarchies of part templates have been proposed [33, 38, 35]. [sent-70, score-1.308]
</p><p>34 [33] also introduces attributes of body parts allowing the sharing of part templates of similar shape. [sent-71, score-0.901]
</p><p>35 The hierarchy proposed in [38] even discards the semantic meaning  of body parts and relies on the concept of poselets [4]. [sent-72, score-0.502]
</p><p>36 Our work is focused on improving the body part templates or the likelihoods for the joint positions within a pictorial structure model. [sent-73, score-1.406]
</p><p>37 In contrast to previous works, which run each body part template independently and use a tree structure or loopy models for modeling the dependencies among body parts, we propose to take the dependencies between body parts already into account for predicting the joint locations. [sent-74, score-1.802]
</p><p>38 In this way, the joint or part templates are already able to discriminate left and right limbs and compensate already for some limitations of tree models. [sent-75, score-0.881]
</p><p>39 Since the templates are implemented by efficient randomized regression forests that predict directly the joint locations, our approach is comparable in running time to a state-of-theart method [40], while providing a higher joint localization accuracy. [sent-76, score-1.096]
</p><p>40 Random forests have been previously used for pose estimation from depth data [29, 15]. [sent-77, score-0.4]
</p><p>41 Random forests have been also used to improve poselets for pose estimation from depth data [16] and for pedestrian detection [27]. [sent-79, score-0.444]
</p><p>42 Pictorial Structure  As a human body model, we use a classical pictorial structure framework [11]. [sent-83, score-0.802]
</p><p>43 However, instead of using a limb representation for the body configuration, we use a joint representation J = {jk} where each joint jk = (xk) encreopdreess ethntea image lo =cat {iojn} o wf a joint. [sent-84, score-1.048]
</p><p>44 Thh jeo rnoto jt of the tree is defined by the nose, the only non-joint point in the body configuration. [sent-85, score-0.452]
</p><p>45 (2)  Assuming independent part templates for the likelihood, the posterior can be written as p(J|I) ∝  ? [sent-92, score-0.504]
</p><p>46 ,l) ∈E  The unary potentials φk (jk) are in many cases only approximations of the likelihoods p(I|jk) and correspond to part  templates. [sent-97, score-0.396]
</p><p>47 fF tohre ein lsitkaenlciheo, oHdsO pG( fIe|ajtures [7] and linear SVMs are used as part templates in [40]. [sent-98, score-0.443]
</p><p>48 While we use Gaussian binary potentials and perform inference as in [10], our work focuses only on extracting more discriminative unary potentials φk (jk). [sent-99, score-0.476]
</p><p>49 In particular, we address the weakness of independent part templates and propose non-linear, parts dependent joint regressors instead. [sent-100, score-1.26]
</p><p>50 Joint Regressors A joint representation as in (1) has the advantage that limb transformations like foreshortening do not need to be explicitly modeled in the pictorial structure model, which reduces complexity and running time. [sent-102, score-0.767]
</p><p>51 The independence assumption of common part templates is relaxed by training the regressors on image features and confidence maps of other body parts, i. [sent-103, score-1.149]
</p><p>52 In this work, we use the twerhmer ‘joint’ hfoer any lfan bdomdya prka point nli tkhei a wskorekle,to wne joint or the nose, whereas ‘body parts’ are defined as regions around the joints as illustrated Fig. [sent-106, score-0.436]
</p><p>53 4, we discuss three variations, namely part templates using random forests, independentjoint regressors, and parts dependentjoint regressors. [sent-114, score-0.676]
</p><p>54 Random Forests Random forests [5] or in general decision forests [6] have been used for many classification or regression tasks, for instance, labeling body parts in depth images [29], predicting the joint positions from depth data [15], or localizing facial feature points [8]. [sent-117, score-1.226]
</p><p>55 For classifying body parts, the parameter space is the set of class labels or body parts. [sent-121, score-0.672]
</p><p>56 Body Part Templates The body part templates are modeled as classical limb templates trained with a random forest. [sent-132, score-1.373]
</p><p>57 We train a separate forest for each body part, where each forest is trained by body part patches sampled from a Gaussian distribution centered at the body part annotation and negative patches sampled uniformly from the background of the image. [sent-138, score-1.478]
</p><p>58 Each patch P  FPf  is therefore augmented by a binary label c, which is k if it is sampled from body part lk. [sent-139, score-0.502]
</p><p>59 We use the same number of body parts as joints, i. [sent-140, score-0.458]
</p><p>60 c  The unary potentials for the body parts lk are obtained by densely extracting image patches from the test image and passing them through the trained trees. [sent-151, score-0.851]
</p><p>61 (11)  After computing the unary potentials for an image, the unary potentials for each joint are normalized to be within the range [0, 1] . [sent-169, score-0.771]
</p><p>62 To resolve this issue, we propose a third potential that predicts the joint locations as in (11), but also takes neighboring part potentials into account: φk(jk, L) = p(jk |I, L)  (12)  However, incorporating a multi-dimensional neighborhood structure is usually computationally demanding. [sent-189, score-0.612]
</p><p>63 The first layer only calculates independent part potentials φk (lk) (9). [sent-191, score-0.395]
</p><p>64 The second layer also predicts unary potentials but also incorporates the potentials of the first layer and their locations as additional feature maps. [sent-192, score-0.679]
</p><p>65 e, leaf probabilities i ps( tche|L e, nLriTch) aendd s e pt( ovf|L fe,a LtuTr)e now depend on tahfe p probabilities (ocf| Lth,eL body parts |aLn,dL we obtain  φk(jk,L)=? [sent-203, score-0.548]
</p><p>66 Comparison of the joint localization accuracy of the proposed unary potentials and comparison with a state-of-the-art method [40]. [sent-210, score-0.544]
</p><p>67 While the body part classification (9) and the independent joint regression (11) perform similarly, they are drastically outperformed by the proposed body parts dependent joint regressors (13). [sent-211, score-1.86]
</p><p>68 Since the body parts dependent joint regressors do not encode any explicit information of the human skeleton, using a pictorial structure model (PS), which models the kinematic chain, gives an additional performance boost. [sent-212, score-1.566]
</p><p>69 The body parts dependent joint regression together with a pictorial structure model outperforms [40]. [sent-213, score-1.231]
</p><p>70 In our experiments, we compare our method to three related methods, namely linear and non-linear SVMs for part templates [18] and flexible mixtures-of-parts [40]. [sent-219, score-0.472]
</p><p>71 Since clothing imposes a particular challenge for pose estimation in general, which is not well reflected in current datasets for pose estimation from still images, we collected a new dataset. [sent-222, score-0.379]
</p><p>72 Each image contains a person where the full body is visible and is annotated by 12 joints and a point for the head, namely the nose. [sent-228, score-0.588]
</p><p>73 The accuracy plots for individual joints using body parts dependent joint regressors with a pictorial structure model. [sent-232, score-1.693]
</p><p>74 In our experiments, we measure the joint localization error as a fraction of the upper body size. [sent-246, score-0.626]
</p><p>75 PCP declares a limb as correctly detected if the error of the predicted endpoints are within 50% of the limb length from the ground truth endpoints. [sent-251, score-0.34]
</p><p>76 random forests for the body part templates, independent and parts dependent joint regression, we fixed some parameters intuitively. [sent-268, score-1.131]
</p><p>77 We first evaluated the performance of the part templates  FPf,  (Section 4. [sent-274, score-0.443]
</p><p>78 3), and the body parts dependent joint regressors (Section 4. [sent-276, score-1.092]
</p><p>79 The proposed body parts dependent joint regressors clearly outperform the independent part templates and joint regressors. [sent-280, score-1.809]
</p><p>80 Integrating them into a pictorial structure model (Section 3), which encodes the kinematic skeleton, improves the accuracy further. [sent-281, score-0.416]
</p><p>81 We also evaluated the accuracy when the unary potentials for classification (9) and independent regression (11) are multiplied. [sent-284, score-0.417]
</p><p>82 This shows that training the regressors depending on the body part templates (13) is essential for the performance gain. [sent-286, score-1.124]
</p><p>83 [40] that uses a flexible mixture of templates modeled by linear SVMs. [sent-288, score-0.362]
</p><p>84 A comparison of the approach [40] and the parts dependent joint regression is shown in Fig. [sent-290, score-0.517]
</p><p>85 pictorial structure model with parts dependent joint regression outperforms [40]. [sent-295, score-0.895]
</p><p>86 To this end, we added the neck and the top of the head as joints and converted our joint representation into a limb representation by using the joints as endpoints of the limbs. [sent-310, score-0.909]
</p><p>87 The torso is obtained by the line between the average position of the two hip joints and the average position of the two shoulder joints. [sent-311, score-0.362]
</p><p>88 The results of our method using body parts dependent joint regression with a pictorial structure are given in Table 2. [sent-312, score-1.231]
</p><p>89 The comparison with a pictorial structure model that uses linear SVMs [ 18] or a cascade ofnon-linear SVMs [ 1 8] as part templates shows that our proposed unary potentials achieve a much higher accuracy. [sent-313, score-1.1]
</p><p>90 The accuracy with respect to the normalized joint localization error for individual joints is plotted in Fig. [sent-314, score-0.513]
</p><p>91 Our method outperforms  a limb related  methods using linear or non-linear SVMs for part templates within a pictorial structure framework. [sent-354, score-0.965]
</p><p>92 Only [35] achieves a better performance, but this approach uses a more complex and more expensive model than pictorial structures with a tree structure. [sent-355, score-0.446]
</p><p>93 Since the focus of this work is the improvement of the unary potentials in a pictorial structure framework, we used only a single tree model and have not performed clustering or used a more complex body model. [sent-361, score-1.109]
</p><p>94 Conclusion In this paper, we have addressed robust human pose estimation from still images by proposing novel discrimi-  native part template predictors within a pictorial structure framework. [sent-364, score-0.754]
</p><p>95 Our joint location regressors consist of random forests that operate over two layers. [sent-365, score-0.742]
</p><p>96 While the first layer acts as an independent body part classificator, the second one takes the predicted distributions of the first layer for estimating the joint locations into account, thus allowing to put the body parts into relation. [sent-366, score-1.369]
</p><p>97 In the experimental part, we have shown that our model yields higher accurate human joint predictors than independent part templates and outperforms state-of-the-art methods that also use a tree structure for the human model. [sent-367, score-1.026]
</p><p>98 Recovering human body  [26] [27]  [28] [29]  [30]  [3 1]  [32]  [33]  [34]  [35]  configurations using pairwise constraints between parts. [sent-535, score-0.394]
</p><p>99 Real-time human pose recognition in parts from single depth images. [sent-565, score-0.361]
</p><p>100 Articulated part-based model for joint object detection and pose estimation. [sent-588, score-0.35]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('templates', 0.362), ('body', 0.336), ('pictorial', 0.33), ('regressors', 0.316), ('joints', 0.223), ('joint', 0.213), ('forests', 0.179), ('potentials', 0.169), ('limb', 0.144), ('jk', 0.142), ('pose', 0.137), ('parts', 0.122), ('fpf', 0.121), ('tree', 0.116), ('unary', 0.11), ('hip', 0.107), ('dependent', 0.105), ('fashionpose', 0.096), ('layer', 0.084), ('part', 0.081), ('regression', 0.077), ('pcp', 0.074), ('forest', 0.072), ('lsp', 0.071), ('leeds', 0.068), ('pages', 0.062), ('independent', 0.061), ('patch', 0.06), ('ps', 0.059), ('human', 0.058), ('svms', 0.057), ('split', 0.055), ('lt', 0.054), ('localization', 0.052), ('head', 0.05), ('sports', 0.049), ('thresholds', 0.048), ('fashionista', 0.048), ('independentjoint', 0.048), ('tango', 0.048), ('structure', 0.048), ('goodness', 0.047), ('probabilities', 0.045), ('patches', 0.045), ('lk', 0.045), ('depth', 0.044), ('poselets', 0.044), ('articulated', 0.043), ('ambiguities', 0.042), ('limbs', 0.041), ('estimation', 0.04), ('knee', 0.04), ('nose', 0.039), ('kinematic', 0.038), ('resolve', 0.038), ('shotton', 0.037), ('likelihoods', 0.036), ('predicts', 0.036), ('loopy', 0.035), ('parsing', 0.035), ('already', 0.034), ('rescaled', 0.034), ('trees', 0.034), ('random', 0.034), ('predicting', 0.032), ('transformations', 0.032), ('shoulder', 0.032), ('ethz', 0.032), ('leaves', 0.032), ('fp', 0.031), ('skeleton', 0.031), ('relations', 0.031), ('template', 0.031), ('classical', 0.03), ('predictors', 0.029), ('neck', 0.029), ('clothes', 0.029), ('training', 0.029), ('kl', 0.029), ('dependencies', 0.029), ('namely', 0.029), ('hog', 0.029), ('sigal', 0.028), ('discriminative', 0.028), ('locations', 0.027), ('endpoints', 0.027), ('gall', 0.026), ('clothing', 0.025), ('hierarchies', 0.025), ('error', 0.025), ('confidence', 0.025), ('sampled', 0.025), ('acts', 0.025), ('trained', 0.024), ('tran', 0.024), ('annotate', 0.024), ('skin', 0.024), ('account', 0.024), ('tian', 0.024), ('deformable', 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999875 <a title="206-tfidf-1" href="./cvpr-2013-Human_Pose_Estimation_Using_Body_Parts_Dependent_Joint_Regressors.html">206 cvpr-2013-Human Pose Estimation Using Body Parts Dependent Joint Regressors</a></p>
<p>Author: Matthias Dantone, Juergen Gall, Christian Leistner, Luc Van_Gool</p><p>Abstract: In this work, we address the problem of estimating 2d human pose from still images. Recent methods that rely on discriminatively trained deformable parts organized in a tree model have shown to be very successful in solving this task. Within such a pictorial structure framework, we address the problem of obtaining good part templates by proposing novel, non-linear joint regressors. In particular, we employ two-layered random forests as joint regressors. The first layer acts as a discriminative, independent body part classifier. The second layer takes the estimated class distributions of the first one into account and is thereby able to predict joint locations by modeling the interdependence and co-occurrence of the parts. This results in a pose estimation framework that takes dependencies between body parts already for joint localization into account and is thus able to circumvent typical ambiguities of tree structures, such as for legs and arms. In the experiments, we demonstrate that our body parts dependent joint regressors achieve a higher joint localization accuracy than tree-based state-of-the-art methods.</p><p>2 0.37096164 <a title="206-tfidf-2" href="./cvpr-2013-Poselet_Conditioned_Pictorial_Structures.html">335 cvpr-2013-Poselet Conditioned Pictorial Structures</a></p>
<p>Author: Leonid Pishchulin, Mykhaylo Andriluka, Peter Gehler, Bernt Schiele</p><p>Abstract: In this paper we consider the challenging problem of articulated human pose estimation in still images. We observe that despite high variability of the body articulations, human motions and activities often simultaneously constrain the positions of multiple body parts. Modelling such higher order part dependencies seemingly comes at a cost of more expensive inference, which resulted in their limited use in state-of-the-art methods. In this paper we propose a model that incorporates higher order part dependencies while remaining efficient. We achieve this by defining a conditional model in which all body parts are connected a-priori, but which becomes a tractable tree-structured pictorial structures model once the image observations are available. In order to derive a set of conditioning variables we rely on the poselet-based features that have been shown to be effective for people detection but have so far found limited application for articulated human pose estimation. We demon- strate the effectiveness of our approach on three publicly available pose estimation benchmarks improving or being on-par with state of the art in each case.</p><p>3 0.35599008 <a title="206-tfidf-3" href="./cvpr-2013-Human_Pose_Estimation_Using_a_Joint_Pixel-wise_and_Part-wise_Formulation.html">207 cvpr-2013-Human Pose Estimation Using a Joint Pixel-wise and Part-wise Formulation</a></p>
<p>Author: Ľ</p><p>Abstract: Our goal is to detect humans and estimate their 2D pose in single images. In particular, handling cases of partial visibility where some limbs may be occluded or one person is partially occluding another. Two standard, but disparate, approaches have developed in the field: the first is the part based approach for layout type problems, involving optimising an articulated pictorial structure; the second is the pixel based approach for image labelling involving optimising a random field graph defined on the image. Our novel contribution is a formulation for pose estimation which combines these two models in a principled way in one optimisation problem and thereby inherits the advantages of both of them. Inference on this joint model finds the set of instances of persons in an image, the location of their joints, and a pixel-wise body part labelling. We achieve near or state of the art results on standard human pose data sets, and demonstrate the correct estimation for cases of self-occlusion, person overlap and image truncation.</p><p>4 0.28669289 <a title="206-tfidf-4" href="./cvpr-2013-Beyond_Physical_Connections%3A_Tree_Models_in_Human_Pose_Estimation.html">60 cvpr-2013-Beyond Physical Connections: Tree Models in Human Pose Estimation</a></p>
<p>Author: Fang Wang, Yi Li</p><p>Abstract: Simple tree models for articulated objects prevails in the last decade. However, it is also believed that these simple tree models are not capable of capturing large variations in many scenarios, such as human pose estimation. This paper attempts to address three questions: 1) are simple tree models sufficient? more specifically, 2) how to use tree models effectively in human pose estimation? and 3) how shall we use combined parts together with single parts efficiently? Assuming we have a set of single parts and combined parts, and the goal is to estimate a joint distribution of their locations. We surprisingly find that no latent variables are introduced in the Leeds Sport Dataset (LSP) during learning latent trees for deformable model, which aims at approximating the joint distributions of body part locations using minimal tree structure. This suggests one can straightforwardly use a mixed representation of single and combined parts to approximate their joint distribution in a simple tree model. As such, one only needs to build Visual Categories of the combined parts, and then perform inference on the learned latent tree. Our method outperformed the state of the art on the LSP, both in the scenarios when the training images are from the same dataset and from the PARSE dataset. Experiments on animal images from the VOC challenge further support our findings.</p><p>5 0.28192478 <a title="206-tfidf-5" href="./cvpr-2013-An_Approach_to_Pose-Based_Action_Recognition.html">40 cvpr-2013-An Approach to Pose-Based Action Recognition</a></p>
<p>Author: Chunyu Wang, Yizhou Wang, Alan L. Yuille</p><p>Abstract: We address action recognition in videos by modeling the spatial-temporal structures of human poses. We start by improving a state of the art method for estimating human joint locations from videos. More precisely, we obtain the K-best estimations output by the existing method and incorporate additional segmentation cues and temporal constraints to select the “best” one. Then we group the estimated joints into five body parts (e.g. the left arm) and apply data mining techniques to obtain a representation for the spatial-temporal structures of human actions. This representation captures the spatial configurations ofbodyparts in one frame (by spatial-part-sets) as well as the body part movements(by temporal-part-sets) which are characteristic of human actions. It is interpretable, compact, and also robust to errors on joint estimations. Experimental results first show that our approach is able to localize body joints more accurately than existing methods. Next we show that it outperforms state of the art action recognizers on the UCF sport, the Keck Gesture and the MSR-Action3D datasets.</p><p>6 0.25814849 <a title="206-tfidf-6" href="./cvpr-2013-Computationally_Efficient_Regression_on_a_Dependency_Graph_for_Human_Pose_Estimation.html">89 cvpr-2013-Computationally Efficient Regression on a Dependency Graph for Human Pose Estimation</a></p>
<p>7 0.25123078 <a title="206-tfidf-7" href="./cvpr-2013-Pose_from_Flow_and_Flow_from_Pose.html">334 cvpr-2013-Pose from Flow and Flow from Pose</a></p>
<p>8 0.2354957 <a title="206-tfidf-8" href="./cvpr-2013-A_Joint_Model_for_2D_and_3D_Pose_Estimation_from_a_Single_Image.html">14 cvpr-2013-A Joint Model for 2D and 3D Pose Estimation from a Single Image</a></p>
<p>9 0.22831483 <a title="206-tfidf-9" href="./cvpr-2013-Expanded_Parts_Model_for_Human_Attribute_and_Action_Recognition_in_Still_Images.html">153 cvpr-2013-Expanded Parts Model for Human Attribute and Action Recognition in Still Images</a></p>
<p>10 0.2272476 <a title="206-tfidf-10" href="./cvpr-2013-Unconstrained_Monocular_3D_Human_Pose_Estimation_by_Action_Detection_and_Cross-Modality_Regression_Forest.html">444 cvpr-2013-Unconstrained Monocular 3D Human Pose Estimation by Action Detection and Cross-Modality Regression Forest</a></p>
<p>11 0.17249058 <a title="206-tfidf-11" href="./cvpr-2013-Integrating_Grammar_and_Segmentation_for_Human_Pose_Estimation.html">225 cvpr-2013-Integrating Grammar and Segmentation for Human Pose Estimation</a></p>
<p>12 0.17022353 <a title="206-tfidf-12" href="./cvpr-2013-Scene_Coordinate_Regression_Forests_for_Camera_Relocalization_in_RGB-D_Images.html">380 cvpr-2013-Scene Coordinate Regression Forests for Camera Relocalization in RGB-D Images</a></p>
<p>13 0.16702721 <a title="206-tfidf-13" href="./cvpr-2013-3D_Pictorial_Structures_for_Multiple_View_Articulated_Pose_Estimation.html">2 cvpr-2013-3D Pictorial Structures for Multiple View Articulated Pose Estimation</a></p>
<p>14 0.15559407 <a title="206-tfidf-14" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>15 0.15356521 <a title="206-tfidf-15" href="./cvpr-2013-GeoF%3A_Geodesic_Forests_for_Learning_Coupled_Predictors.html">186 cvpr-2013-GeoF: Geodesic Forests for Learning Coupled Predictors</a></p>
<p>16 0.14956018 <a title="206-tfidf-16" href="./cvpr-2013-Tracking_Human_Pose_by_Tracking_Symmetric_Parts.html">439 cvpr-2013-Tracking Human Pose by Tracking Symmetric Parts</a></p>
<p>17 0.14280315 <a title="206-tfidf-17" href="./cvpr-2013-Articulated_Pose_Estimation_Using_Discriminative_Armlet_Classifiers.html">45 cvpr-2013-Articulated Pose Estimation Using Discriminative Armlet Classifiers</a></p>
<p>18 0.13881359 <a title="206-tfidf-18" href="./cvpr-2013-Class_Generative_Models_Based_on_Feature_Regression_for_Pose_Estimation_of_Object_Categories.html">82 cvpr-2013-Class Generative Models Based on Feature Regression for Pose Estimation of Object Categories</a></p>
<p>19 0.13759448 <a title="206-tfidf-19" href="./cvpr-2013-Analyzing_Semantic_Segmentation_Using_Hybrid_Human-Machine_CRFs.html">43 cvpr-2013-Analyzing Semantic Segmentation Using Hybrid Human-Machine CRFs</a></p>
<p>20 0.11929518 <a title="206-tfidf-20" href="./cvpr-2013-MODEC%3A_Multimodal_Decomposable_Models_for_Human_Pose_Estimation.html">277 cvpr-2013-MODEC: Multimodal Decomposable Models for Human Pose Estimation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.255), (1, -0.041), (2, 0.014), (3, -0.16), (4, 0.003), (5, 0.038), (6, 0.148), (7, 0.201), (8, 0.069), (9, -0.195), (10, -0.142), (11, 0.283), (12, -0.161), (13, 0.033), (14, -0.02), (15, 0.142), (16, -0.007), (17, -0.093), (18, -0.021), (19, -0.155), (20, -0.024), (21, 0.067), (22, -0.052), (23, -0.082), (24, -0.083), (25, 0.071), (26, -0.03), (27, 0.003), (28, 0.03), (29, -0.011), (30, 0.022), (31, -0.015), (32, -0.006), (33, -0.014), (34, 0.018), (35, -0.027), (36, -0.066), (37, 0.023), (38, 0.019), (39, 0.11), (40, 0.037), (41, -0.014), (42, 0.037), (43, 0.049), (44, 0.019), (45, 0.004), (46, -0.037), (47, 0.062), (48, -0.01), (49, -0.011)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97339052 <a title="206-lsi-1" href="./cvpr-2013-Human_Pose_Estimation_Using_Body_Parts_Dependent_Joint_Regressors.html">206 cvpr-2013-Human Pose Estimation Using Body Parts Dependent Joint Regressors</a></p>
<p>Author: Matthias Dantone, Juergen Gall, Christian Leistner, Luc Van_Gool</p><p>Abstract: In this work, we address the problem of estimating 2d human pose from still images. Recent methods that rely on discriminatively trained deformable parts organized in a tree model have shown to be very successful in solving this task. Within such a pictorial structure framework, we address the problem of obtaining good part templates by proposing novel, non-linear joint regressors. In particular, we employ two-layered random forests as joint regressors. The first layer acts as a discriminative, independent body part classifier. The second layer takes the estimated class distributions of the first one into account and is thereby able to predict joint locations by modeling the interdependence and co-occurrence of the parts. This results in a pose estimation framework that takes dependencies between body parts already for joint localization into account and is thus able to circumvent typical ambiguities of tree structures, such as for legs and arms. In the experiments, we demonstrate that our body parts dependent joint regressors achieve a higher joint localization accuracy than tree-based state-of-the-art methods.</p><p>2 0.92989063 <a title="206-lsi-2" href="./cvpr-2013-Poselet_Conditioned_Pictorial_Structures.html">335 cvpr-2013-Poselet Conditioned Pictorial Structures</a></p>
<p>Author: Leonid Pishchulin, Mykhaylo Andriluka, Peter Gehler, Bernt Schiele</p><p>Abstract: In this paper we consider the challenging problem of articulated human pose estimation in still images. We observe that despite high variability of the body articulations, human motions and activities often simultaneously constrain the positions of multiple body parts. Modelling such higher order part dependencies seemingly comes at a cost of more expensive inference, which resulted in their limited use in state-of-the-art methods. In this paper we propose a model that incorporates higher order part dependencies while remaining efficient. We achieve this by defining a conditional model in which all body parts are connected a-priori, but which becomes a tractable tree-structured pictorial structures model once the image observations are available. In order to derive a set of conditioning variables we rely on the poselet-based features that have been shown to be effective for people detection but have so far found limited application for articulated human pose estimation. We demon- strate the effectiveness of our approach on three publicly available pose estimation benchmarks improving or being on-par with state of the art in each case.</p><p>3 0.87701511 <a title="206-lsi-3" href="./cvpr-2013-Beyond_Physical_Connections%3A_Tree_Models_in_Human_Pose_Estimation.html">60 cvpr-2013-Beyond Physical Connections: Tree Models in Human Pose Estimation</a></p>
<p>Author: Fang Wang, Yi Li</p><p>Abstract: Simple tree models for articulated objects prevails in the last decade. However, it is also believed that these simple tree models are not capable of capturing large variations in many scenarios, such as human pose estimation. This paper attempts to address three questions: 1) are simple tree models sufficient? more specifically, 2) how to use tree models effectively in human pose estimation? and 3) how shall we use combined parts together with single parts efficiently? Assuming we have a set of single parts and combined parts, and the goal is to estimate a joint distribution of their locations. We surprisingly find that no latent variables are introduced in the Leeds Sport Dataset (LSP) during learning latent trees for deformable model, which aims at approximating the joint distributions of body part locations using minimal tree structure. This suggests one can straightforwardly use a mixed representation of single and combined parts to approximate their joint distribution in a simple tree model. As such, one only needs to build Visual Categories of the combined parts, and then perform inference on the learned latent tree. Our method outperformed the state of the art on the LSP, both in the scenarios when the training images are from the same dataset and from the PARSE dataset. Experiments on animal images from the VOC challenge further support our findings.</p><p>4 0.874623 <a title="206-lsi-4" href="./cvpr-2013-Computationally_Efficient_Regression_on_a_Dependency_Graph_for_Human_Pose_Estimation.html">89 cvpr-2013-Computationally Efficient Regression on a Dependency Graph for Human Pose Estimation</a></p>
<p>Author: Kota Hara, Rama Chellappa</p><p>Abstract: We present a hierarchical method for human pose estimation from a single still image. In our approach, a dependency graph representing relationships between reference points such as bodyjoints is constructed and thepositions of these reference points are sequentially estimated by a successive application of multidimensional output regressions along the dependency paths, starting from the root node. Each regressor takes image features computed from an image patch centered on the current node ’s position estimated by the previous regressor and is specialized for estimating its child nodes ’ positions. The use of the dependency graph allows us to decompose a complex pose estimation problem into a set of local pose estimation problems that are less complex. We design a dependency graph for two commonly used human pose estimation datasets, the Buffy Stickmen dataset and the ETHZ PASCAL Stickmen dataset, and demonstrate that our method achieves comparable accuracy to state-of-the-art results on both datasets with significantly lower computation time than existing methods. Furthermore, we propose an importance weighted boosted re- gression trees method for transductive learning settings and demonstrate the resulting improved performance for pose estimation tasks.</p><p>5 0.83552647 <a title="206-lsi-5" href="./cvpr-2013-Human_Pose_Estimation_Using_a_Joint_Pixel-wise_and_Part-wise_Formulation.html">207 cvpr-2013-Human Pose Estimation Using a Joint Pixel-wise and Part-wise Formulation</a></p>
<p>Author: Ľ</p><p>Abstract: Our goal is to detect humans and estimate their 2D pose in single images. In particular, handling cases of partial visibility where some limbs may be occluded or one person is partially occluding another. Two standard, but disparate, approaches have developed in the field: the first is the part based approach for layout type problems, involving optimising an articulated pictorial structure; the second is the pixel based approach for image labelling involving optimising a random field graph defined on the image. Our novel contribution is a formulation for pose estimation which combines these two models in a principled way in one optimisation problem and thereby inherits the advantages of both of them. Inference on this joint model finds the set of instances of persons in an image, the location of their joints, and a pixel-wise body part labelling. We achieve near or state of the art results on standard human pose data sets, and demonstrate the correct estimation for cases of self-occlusion, person overlap and image truncation.</p><p>6 0.83128333 <a title="206-lsi-6" href="./cvpr-2013-Articulated_Pose_Estimation_Using_Discriminative_Armlet_Classifiers.html">45 cvpr-2013-Articulated Pose Estimation Using Discriminative Armlet Classifiers</a></p>
<p>7 0.81525606 <a title="206-lsi-7" href="./cvpr-2013-MODEC%3A_Multimodal_Decomposable_Models_for_Human_Pose_Estimation.html">277 cvpr-2013-MODEC: Multimodal Decomposable Models for Human Pose Estimation</a></p>
<p>8 0.8137821 <a title="206-lsi-8" href="./cvpr-2013-3D_Pictorial_Structures_for_Multiple_View_Articulated_Pose_Estimation.html">2 cvpr-2013-3D Pictorial Structures for Multiple View Articulated Pose Estimation</a></p>
<p>9 0.8067109 <a title="206-lsi-9" href="./cvpr-2013-A_Joint_Model_for_2D_and_3D_Pose_Estimation_from_a_Single_Image.html">14 cvpr-2013-A Joint Model for 2D and 3D Pose Estimation from a Single Image</a></p>
<p>10 0.73518765 <a title="206-lsi-10" href="./cvpr-2013-Tensor-Based_Human_Body_Modeling.html">426 cvpr-2013-Tensor-Based Human Body Modeling</a></p>
<p>11 0.68983763 <a title="206-lsi-11" href="./cvpr-2013-Unconstrained_Monocular_3D_Human_Pose_Estimation_by_Action_Detection_and_Cross-Modality_Regression_Forest.html">444 cvpr-2013-Unconstrained Monocular 3D Human Pose Estimation by Action Detection and Cross-Modality Regression Forest</a></p>
<p>12 0.6675244 <a title="206-lsi-12" href="./cvpr-2013-An_Approach_to_Pose-Based_Action_Recognition.html">40 cvpr-2013-An Approach to Pose-Based Action Recognition</a></p>
<p>13 0.66274214 <a title="206-lsi-13" href="./cvpr-2013-Tracking_Human_Pose_by_Tracking_Symmetric_Parts.html">439 cvpr-2013-Tracking Human Pose by Tracking Symmetric Parts</a></p>
<p>14 0.65992242 <a title="206-lsi-14" href="./cvpr-2013-Class_Generative_Models_Based_on_Feature_Regression_for_Pose_Estimation_of_Object_Categories.html">82 cvpr-2013-Class Generative Models Based on Feature Regression for Pose Estimation of Object Categories</a></p>
<p>15 0.65283459 <a title="206-lsi-15" href="./cvpr-2013-Integrating_Grammar_and_Segmentation_for_Human_Pose_Estimation.html">225 cvpr-2013-Integrating Grammar and Segmentation for Human Pose Estimation</a></p>
<p>16 0.61349398 <a title="206-lsi-16" href="./cvpr-2013-Pose_from_Flow_and_Flow_from_Pose.html">334 cvpr-2013-Pose from Flow and Flow from Pose</a></p>
<p>17 0.59266186 <a title="206-lsi-17" href="./cvpr-2013-Expanded_Parts_Model_for_Human_Attribute_and_Action_Recognition_in_Still_Images.html">153 cvpr-2013-Expanded Parts Model for Human Attribute and Action Recognition in Still Images</a></p>
<p>18 0.51240808 <a title="206-lsi-18" href="./cvpr-2013-Scene_Coordinate_Regression_Forests_for_Camera_Relocalization_in_RGB-D_Images.html">380 cvpr-2013-Scene Coordinate Regression Forests for Camera Relocalization in RGB-D Images</a></p>
<p>19 0.48856807 <a title="206-lsi-19" href="./cvpr-2013-GeoF%3A_Geodesic_Forests_for_Learning_Coupled_Predictors.html">186 cvpr-2013-GeoF: Geodesic Forests for Learning Coupled Predictors</a></p>
<p>20 0.48370573 <a title="206-lsi-20" href="./cvpr-2013-Watching_Unlabeled_Video_Helps_Learn_New_Human_Actions_from_Very_Few_Labeled_Snapshots.html">459 cvpr-2013-Watching Unlabeled Video Helps Learn New Human Actions from Very Few Labeled Snapshots</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.125), (16, 0.017), (26, 0.044), (28, 0.098), (33, 0.281), (63, 0.022), (65, 0.011), (67, 0.11), (69, 0.033), (80, 0.068), (87, 0.101), (93, 0.011)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.95522916 <a title="206-lda-1" href="./cvpr-2013-3D_Visual_Proxemics%3A_Recognizing_Human_Interactions_in_3D_from_a_Single_Image.html">4 cvpr-2013-3D Visual Proxemics: Recognizing Human Interactions in 3D from a Single Image</a></p>
<p>Author: Ishani Chakraborty, Hui Cheng, Omar Javed</p><p>Abstract: We present a unified framework for detecting and classifying people interactions in unconstrained user generated images. 1 Unlike previous approaches that directly map people/face locations in 2D image space into features for classification, we first estimate camera viewpoint and people positions in 3D space and then extract spatial configuration features from explicit 3D people positions. This approach has several advantages. First, it can accurately estimate relative distances and orientations between people in 3D. Second, it encodes spatial arrangements of people into a richer set of shape descriptors than afforded in 2D. Our 3D shape descriptors are invariant to camera pose variations often seen in web images and videos. The proposed approach also estimates camera pose and uses it to capture the intent of the photo. To achieve accurate 3D people layout estimation, we develop an algorithm that robustly fuses semantic constraints about human interpositions into a linear camera model. This enables our model to handle large variations in people size, heights (e.g. age) and poses. An accurate 3D layout also allows us to construct features informed by Proxemics that improves our semantic classification. To characterize the human interaction space, we introduce visual proxemes; a set of prototypical patterns that represent commonly occurring social interactions in events. We train a discriminative classifier that classifies 3D arrangements of people into visual proxemes and quantitatively evaluate the performance on a large, challenging dataset.</p><p>same-paper 2 0.94299328 <a title="206-lda-2" href="./cvpr-2013-Human_Pose_Estimation_Using_Body_Parts_Dependent_Joint_Regressors.html">206 cvpr-2013-Human Pose Estimation Using Body Parts Dependent Joint Regressors</a></p>
<p>Author: Matthias Dantone, Juergen Gall, Christian Leistner, Luc Van_Gool</p><p>Abstract: In this work, we address the problem of estimating 2d human pose from still images. Recent methods that rely on discriminatively trained deformable parts organized in a tree model have shown to be very successful in solving this task. Within such a pictorial structure framework, we address the problem of obtaining good part templates by proposing novel, non-linear joint regressors. In particular, we employ two-layered random forests as joint regressors. The first layer acts as a discriminative, independent body part classifier. The second layer takes the estimated class distributions of the first one into account and is thereby able to predict joint locations by modeling the interdependence and co-occurrence of the parts. This results in a pose estimation framework that takes dependencies between body parts already for joint localization into account and is thus able to circumvent typical ambiguities of tree structures, such as for legs and arms. In the experiments, we demonstrate that our body parts dependent joint regressors achieve a higher joint localization accuracy than tree-based state-of-the-art methods.</p><p>3 0.93868583 <a title="206-lda-3" href="./cvpr-2013-Learning_by_Associating_Ambiguously_Labeled_Images.html">261 cvpr-2013-Learning by Associating Ambiguously Labeled Images</a></p>
<p>Author: Zinan Zeng, Shijie Xiao, Kui Jia, Tsung-Han Chan, Shenghua Gao, Dong Xu, Yi Ma</p><p>Abstract: We study in this paper the problem of learning classifiers from ambiguously labeled images. For instance, in the collection of new images, each image contains some samples of interest (e.g., human faces), and its associated caption has labels with the true ones included, while the samplelabel association is unknown. The task is to learn classifiers from these ambiguously labeled images and generalize to new images. An essential consideration here is how to make use of the information embedded in the relations between samples and labels, both within each image and across the image set. To this end, we propose a novel framework to address this problem. Our framework is motivated by the observation that samples from the same class repetitively appear in the collection of ambiguously labeled training images, while they are just ambiguously labeled in each image. If we can identify samples of the same class from each image and associate them across the image set, the matrix formed by the samples from the same class would be ideally low-rank. By leveraging such a low-rank assump- tion, we can simultaneously optimize a partial permutation matrix (PPM) for each image, which is formulated in order to exploit all information between samples and labels in a principled way. The obtained PPMs can be readily used to assign labels to samples in training images, and then a standard SVM classifier can be trained and used for unseen data. Experiments on benchmark datasets show the effectiveness of our proposed method.</p><p>4 0.93654251 <a title="206-lda-4" href="./cvpr-2013-Integrating_Grammar_and_Segmentation_for_Human_Pose_Estimation.html">225 cvpr-2013-Integrating Grammar and Segmentation for Human Pose Estimation</a></p>
<p>Author: Brandon Rothrock, Seyoung Park, Song-Chun Zhu</p><p>Abstract: In this paper we present a compositional and-or graph grammar model for human pose estimation. Our model has three distinguishing features: (i) large appearance differences between people are handled compositionally by allowingparts or collections ofparts to be substituted with alternative variants, (ii) each variant is a sub-model that can define its own articulated geometry and context-sensitive compatibility with neighboring part variants, and (iii) background region segmentation is incorporated into the part appearance models to better estimate the contrast of a part region from its surroundings, and improve resilience to background clutter. The resulting integrated framework is trained discriminatively in a max-margin framework using an efficient and exact inference algorithm. We present experimental evaluation of our model on two popular datasets, and show performance improvements over the state-of-art on both benchmarks.</p><p>5 0.93328285 <a title="206-lda-5" href="./cvpr-2013-Pedestrian_Detection_with_Unsupervised_Multi-stage_Feature_Learning.html">328 cvpr-2013-Pedestrian Detection with Unsupervised Multi-stage Feature Learning</a></p>
<p>Author: Pierre Sermanet, Koray Kavukcuoglu, Soumith Chintala, Yann Lecun</p><p>Abstract: Pedestrian detection is a problem of considerable practical interest. Adding to the list of successful applications of deep learning methods to vision, we report state-of-theart and competitive results on all major pedestrian datasets with a convolutional network model. The model uses a few new twists, such as multi-stage features, connections that skip layers to integrate global shape information with local distinctive motif information, and an unsupervised method based on convolutional sparse coding to pre-train the filters at each stage.</p><p>6 0.93177807 <a title="206-lda-6" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>7 0.93161452 <a title="206-lda-7" href="./cvpr-2013-PISA%3A_Pixelwise_Image_Saliency_by_Aggregating_Complementary_Appearance_Contrast_Measures_with_Spatial_Priors.html">322 cvpr-2013-PISA: Pixelwise Image Saliency by Aggregating Complementary Appearance Contrast Measures with Spatial Priors</a></p>
<p>8 0.93021929 <a title="206-lda-8" href="./cvpr-2013-Long-Term_Occupancy_Analysis_Using_Graph-Based_Optimisation_in_Thermal_Imagery.html">272 cvpr-2013-Long-Term Occupancy Analysis Using Graph-Based Optimisation in Thermal Imagery</a></p>
<p>9 0.93017399 <a title="206-lda-9" href="./cvpr-2013-Poselet_Conditioned_Pictorial_Structures.html">335 cvpr-2013-Poselet Conditioned Pictorial Structures</a></p>
<p>10 0.9291268 <a title="206-lda-10" href="./cvpr-2013-Probabilistic_Graphlet_Cut%3A_Exploiting_Spatial_Structure_Cue_for_Weakly_Supervised_Image_Segmentation.html">339 cvpr-2013-Probabilistic Graphlet Cut: Exploiting Spatial Structure Cue for Weakly Supervised Image Segmentation</a></p>
<p>11 0.92900401 <a title="206-lda-11" href="./cvpr-2013-GRASP_Recurring_Patterns_from_a_Single_View.html">183 cvpr-2013-GRASP Recurring Patterns from a Single View</a></p>
<p>12 0.92679459 <a title="206-lda-12" href="./cvpr-2013-MODEC%3A_Multimodal_Decomposable_Models_for_Human_Pose_Estimation.html">277 cvpr-2013-MODEC: Multimodal Decomposable Models for Human Pose Estimation</a></p>
<p>13 0.9267633 <a title="206-lda-13" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<p>14 0.92587042 <a title="206-lda-14" href="./cvpr-2013-Detecting_and_Aligning_Faces_by_Image_Retrieval.html">119 cvpr-2013-Detecting and Aligning Faces by Image Retrieval</a></p>
<p>15 0.92577034 <a title="206-lda-15" href="./cvpr-2013-Graph_Matching_with_Anchor_Nodes%3A_A_Learning_Approach.html">192 cvpr-2013-Graph Matching with Anchor Nodes: A Learning Approach</a></p>
<p>16 0.92564023 <a title="206-lda-16" href="./cvpr-2013-Beyond_Physical_Connections%3A_Tree_Models_in_Human_Pose_Estimation.html">60 cvpr-2013-Beyond Physical Connections: Tree Models in Human Pose Estimation</a></p>
<p>17 0.92560005 <a title="206-lda-17" href="./cvpr-2013-The_Episolar_Constraint%3A_Monocular_Shape_from_Shadow_Correspondence.html">428 cvpr-2013-The Episolar Constraint: Monocular Shape from Shadow Correspondence</a></p>
<p>18 0.92525691 <a title="206-lda-18" href="./cvpr-2013-Computationally_Efficient_Regression_on_a_Dependency_Graph_for_Human_Pose_Estimation.html">89 cvpr-2013-Computationally Efficient Regression on a Dependency Graph for Human Pose Estimation</a></p>
<p>19 0.9251132 <a title="206-lda-19" href="./cvpr-2013-3D_Pictorial_Structures_for_Multiple_View_Articulated_Pose_Estimation.html">2 cvpr-2013-3D Pictorial Structures for Multiple View Articulated Pose Estimation</a></p>
<p>20 0.92472672 <a title="206-lda-20" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
