<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>316 cvpr-2013-Optical Flow Estimation Using Laplacian Mesh Energy</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-316" href="#">cvpr2013-316</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>316 cvpr-2013-Optical Flow Estimation Using Laplacian Mesh Energy</h1>
<br/><p>Source: <a title="cvpr-2013-316-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Li_Optical_Flow_Estimation_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Wenbin Li, Darren Cosker, Matthew Brown, Rui Tang</p><p>Abstract: In this paper we present a novel non-rigid optical flow algorithm for dense image correspondence and non-rigid registration. The algorithm uses a unique Laplacian Mesh Energy term to encourage local smoothness whilst simultaneously preserving non-rigid deformation. Laplacian deformation approaches have become popular in graphics research as they enable mesh deformations to preserve local surface shape. In this work we propose a novel Laplacian Mesh Energy formula to ensure such sensible local deformations between image pairs. We express this wholly within the optical flow optimization, and show its application in a novel coarse-to-fine pyramidal approach. Our algorithm achieves the state-of-the-art performance in all trials on the Garg et al. dataset, and top tier performance on the Middlebury evaluation.</p><p>Reference: <a title="cvpr-2013-316-reference" href="../cvpr2013_reference/cvpr-2013-Optical_Flow_Estimation_Using_Laplacian_Mesh_Energy_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 uk i  Abstract In this paper we present a novel non-rigid optical flow algorithm for dense image correspondence and non-rigid registration. [sent-8, score-0.407]
</p><p>2 The algorithm uses a unique Laplacian Mesh Energy term to encourage local smoothness whilst simultaneously preserving non-rigid deformation. [sent-9, score-0.144]
</p><p>3 Laplacian deformation approaches have become popular in graphics research as they enable mesh deformations to preserve local surface shape. [sent-10, score-0.951]
</p><p>4 In this work we propose a novel Laplacian Mesh Energy formula to ensure such sensible local deformations between image pairs. [sent-11, score-0.117]
</p><p>5 We express this wholly within the optical flow optimization, and show its application in a novel coarse-to-fine pyramidal approach. [sent-12, score-0.524]
</p><p>6 dataset, and top tier performance on the Middlebury evaluation. [sent-14, score-0.07]
</p><p>7 Introduction Optical flow estimation is an important area of computer vision research. [sent-16, score-0.221]
</p><p>8 Current algorithms can broadly be clas-  sified into two categories variational methods and discrete optimization methods. [sent-17, score-0.076]
</p><p>9 The former is a continuous approach [5, 6, 18] to estimate optical flow based on modifications of Horn and Schunck’s framework proposed in [9]. [sent-18, score-0.379]
</p><p>10 Such approaches can provide high subpixel accuracy but may be limited by minimization of the non-convex energy function. [sent-19, score-0.154]
</p><p>11 The latter [4, 14] is based on combinatorial optimization algorithms such as min-cut and max-flow, which can recover non-convex energy functions and multiple local minima but may suffer from discretization artifacts, e. [sent-20, score-0.154]
</p><p>12 the optical flow field boundary is aligned with the coordinate axes. [sent-22, score-0.408]
</p><p>13 One desirable property of optical flow techniques is to preserve local image detail and also handle non-rigid image deformations. [sent-23, score-0.433]
</p><p>14 Under such deformations, the preservation of local detail is particularly important. [sent-24, score-0.041]
</p><p>15 [7] impose this by maintaining correlations between 2D trajectories of different points on a non-rigid surface using a variational framework. [sent-26, score-0.134]
</p><p>16 [12] propose a feature matching approach based on local surface smoothness, and also show particular application to non-rigidly deforming objects. [sent-28, score-0.031]
</p><p>17 In computer graphics research, a common requirement is that surface meshes are globally editable, but capable of maintaining local details under mesh deformations. [sent-29, score-0.863]
</p><p>18 In order to provide a flexible representation to allow computation and preservation of such details, Laplacian mesh structures have previously been described [13, 11]. [sent-30, score-0.753]
</p><p>19 Such schemes impose constraints in differential Laplacian coordinates calculated upon groups of triangles associated with each vertex. [sent-31, score-0.087]
</p><p>20 Meshes have previously been used in optical flow estima–  tion [8]. [sent-32, score-0.379]
</p><p>21 However, this is to reduce processing complexity as opposed to specifically imposing smoothness. [sent-33, score-0.026]
</p><p>22 In this paper we present an variational optical flow model which introduces a novel discrete energy based on Laplacian Mesh Deformation. [sent-34, score-0.609]
</p><p>23 Such deformation approaches are widely applied in graphics research, particularly for preserving local details [13, 11]. [sent-35, score-0.11]
</p><p>24 that of an underlying mesh which penalizes local movements and preserves smooth global ones, can be of great use for optical flow and tracking. [sent-38, score-1.13]
</p><p>25 Constraints on the local deformations expressed in Laplacian coordinates encourage local regularity of the mesh whilst allowing global non-rigidity. [sent-39, score-0.88]
</p><p>26 Our algorithm applies a mesh to an image with a resolution up to one vertex per pixel. [sent-40, score-0.829]
</p><p>27 The Laplacian Mesh Energy is described as an additional term for the energy function, and can be applied in a straightforward manner using our proposed minimization strategy. [sent-41, score-0.185]
</p><p>28 In addition, a novel coarse-to-fine approach is described for overcoming the loss of small optical flow details during its propagation between adjacent pyramid levels. [sent-42, score-0.471]
</p><p>29 Our approach provides excellent performance ranked in the top tier of the Middlebury evaluation1 , and either outperforms or shows comparable accuracy against the leading publicly available non-rigid approaches when evaluated on the non-rigid data set of Garg et al. [sent-45, score-0.07]
</p><p>30 Hybrid Energy In this section, we introduce our novel hybrid energy formula in which our algorithm considers a pair of consecutive frames in an image sequence. [sent-50, score-0.244]
</p><p>31 We define the optical flow displacement between I1(X) and I2 (X) as w = (u, v)T. [sent-52, score-0.418]
</p><p>32 Similar to [5, 9], a smoothness term is introduced into the formula, which controls global flow smoothness. [sent-54, score-0.297]
</p><p>33 Continuous Intensity Energy  Following the standard optical flow assumption regarding Intensity Constancy, we assume that the gray value of a pixel is not varied by its displacement through the entire image sequence. [sent-61, score-0.418]
</p><p>34 In addition, we also make a Gradient Constancy assumption which is engaged to provide additional stability in case the first assumption (Intensity Constancy) is violated by changes in illumination. [sent-62, score-0.026]
</p><p>35 The data term of energy function encoding these assumptions is therefore formulated as:  EData(w) =? [sent-63, score-0.185]
</p><p>36 The term = (∂xx, ∂yy)T is the spatial gradient and θ ∈ [0, 1] dteernmot ∇es a weight that can bthee manually assigned dw θith ∈ ∈di [f0f,e1r-] ent values. [sent-72, score-0.062]
</p><p>37 Furthermore, the smoothness term of our algorithm is a dense pixel based regularizer that penalizes global variation. [sent-73, score-0.115]
</p><p>38 The objective is to produce a globally smooth optical flow field:  ∇  ESmooth(w) =? [sent-74, score-0.379]
</p><p>39 Discrete Laplacian Mesh Energy In order to improve optical flow estimation against the local complexity of non-rigid motion, a novel Laplacian Mesh Energy concept is proposed in this section. [sent-82, score-0.419]
</p><p>40 The aim of this energy is to account for non-rigid motion in scene deformation. [sent-83, score-0.186]
</p><p>41 This concept is inspired by Laplacian Mesh Deformation research in graphics, which aims to preserve local mesh smoothness under non-linear transformation [13]. [sent-84, score-0.851]
</p><p>42 The usage of this concept in computer vision research for optical flow estimation is introduced for the first time here. [sent-85, score-0.419]
</p><p>43 Although non-rigid motion is highly nonlinear, the movement of pixels in such deformations still often exhibits strong correlations in local regions. [sent-86, score-0.128]
</p><p>44 Let M = (V, E, F) be a triangular mesh where mV =tio n{v. [sent-90, score-0.751]
</p><p>45 , =vn} ( Vd,eEsc,rFib)e sb geometric positions wofh tehree Vver =tice {sv in absolute c}art deessicarnib bceoso gredoinmateetsr,i cE p doesintoiotenss t ohef tsheet of edges, and F the set of faces. [sent-94, score-0.07]
</p><p>46 Considering a small mesh region, each vertex vi has a neighborhood ring denoted by Ni = {j | (i, j) ∈ E} which is the set of adjacent vertices oNf v=erte {xj vi. [sent-95, score-0.999]
</p><p>47 T,jh)e degree hdii ohf vi hise th seet n oufm abdejarc eofn tel veemrteicnetss in Ni. [sent-96, score-0.14]
</p><p>48 Here the mesh geometric motion is described by diifnfe Nrentials instead of absolute Cartesian coordinates. [sent-97, score-0.744]
</p><p>49 We define the differentials set as L = {δ1 , δ2 , . [sent-98, score-0.029]
</p><p>50 δn} where tdheef ncoeo trhdein daitfef rise presented as Lthe = di {ffδerence betw}ee wnh tehree vertex vi and the geometric average of its neighbors, i. [sent-101, score-0.271]
</p><p>51 (4)  These uniform weights are found sufficient for the 2D mesh in our evaluation. [sent-106, score-0.712]
</p><p>52 Next, we have the mesh energy in Laplacian coordinates as follows: ? [sent-107, score-0.897]
</p><p>53 1  Where wi denotes the motion of the vertices vi. [sent-113, score-0.081]
</p><p>54 This term of the energy function penalizes the shape variance after vertex motion. [sent-114, score-0.341]
</p><p>55 The rationale of using this energy is that the Laplacian coordinates L encode relative information between vertices and can therefore be used to preserve shape under mesh deformation. [sent-115, score-1.042]
</p><p>56 Optical Flow Framework Table 1 outlines our overall optical flow framework. [sent-117, score-0.379]
</p><p>57 In order to utilize the Laplacian Mesh Energy it is required to create a mesh over the initial image I1. [sent-118, score-0.738]
</p><p>58 Ideally, we desire that the triangles of this mesh do not overlap boundaries in the scene as this may lead to distortions given parallax motion between objects at different depths. [sent-119, score-0.889]
</p><p>59 We also present a novel coarse-to-fine pyramidal framework [5] to utilize our Laplacian Mesh Energy in a variational model. [sent-122, score-0.194]
</p><p>60 In our framework we overcome a previous limitation of such pyramidal approaches, i. [sent-123, score-0.145]
</p><p>61 the loss of small flow details when propagating flow field from coarse to finer pyramidal levels. [sent-125, score-0.714]
</p><p>62 In such cases, small image details at a finer level of the pyramid are lost due to flow computation being initially performed on a coarsely sampled version of the image. [sent-126, score-0.342]
</p><p>63 As such, the flow for these detailed regions is  not remained and propagated to the finer level. [sent-127, score-0.295]
</p><p>64 3) is proposed to minimize the discrete Laplacian Mesh Energy on every level of the pyramidal framework. [sent-130, score-0.172]
</p><p>65 Edge-Aware Mesh Initialization The proposed algorithm is input by an image pair and a mesh with triangle edges that follow object boundaries in one of the images as closely as possible. [sent-134, score-0.821]
</p><p>66 We will discuss the implications of mesh design and its affect on our algorithms behavior in the evaluation. [sent-135, score-0.712]
</p><p>67 The underlying mesh is an essential part of Laplacian Mesh Energy computation. [sent-136, score-0.712]
</p><p>68 Using a uniform mesh with equal distances between vertices along its horizontal and vertical adjacent neighbors is one strategy that can be employed in our approach. [sent-137, score-0.8]
</p><p>69 However, in such a case the grid elements within the mesh will typically overlap the boundaries of objects scene, which results in unexpected errors in our energy minimization. [sent-138, score-0.914]
</p><p>70 This is because triangles within the mesh will be skewed given parallax motion between different objects at different image depths, resulting in a noisier flow field in these areas. [sent-139, score-1.142]
</p><p>71 In order to address this issue, we propose an edge-aware meshing scheme which operates as follows: First, we create two edge maps on the input image using SLIC Superpixels [1] and Sobel Kernel edge detection respectively. [sent-140, score-0.109]
</p><p>72 We then apply a binary AND Operation on the two edge maps in order to deduce uncommon edges, and remove noise using a Gaussian filter. [sent-141, score-0.053]
</p><p>73 The rationale behind this approach  is that the Sobel kernel returns a large number of candidate edges, but also multiple false-positive noise like edges relating to image detail as opposed to object boundaries. [sent-142, score-0.132]
</p><p>74 The SLIC Superpixels on the other hand is less likely to create boundaries relating to image detail. [sent-143, score-0.108]
</p><p>75 Performing an AND operation eliminates a great deal of the noisy edge boundaries and retains a large proportion of reliable ones. [sent-144, score-0.075]
</p><p>76 Finally, we construct a triangular mesh M1 using Delaunay triangulation on tthe a remaining edge points. [sent-145, score-0.778]
</p><p>77 Given the input mesh M1, an n-level image pyramid is buiGlt i(vTeanbl the e1) i. [sent-146, score-0.74]
</p><p>78 n Tpuhet input images I1, I2 along with the mesh M1 are resized with the same sampling rate on each level, denoted by I1k, I2k and M1k, where k = 1, 2, . [sent-147, score-0.712]
</p><p>79 3, the aim of this step is to preserve small flow details which may be lost when propagated from the adjacent coarser level. [sent-155, score-0.401]
</p><p>80 First, we estimate a mesh M2k by propagating the mesh M1k from I1k eonsttiom Ia2kte. [sent-156, score-1.457]
</p><p>81 aN mexets, we bubildy a labelling gm thoede ml using vertex displacement vectors and solve it to retain small flow details. [sent-157, score-0.408]
</p><p>82 The iterative refinement algorithm for tracked mesh M2k Tesatbilmea 2ti. [sent-179, score-0.739]
</p><p>83 h In order to propagate the mesh from M1k to M2k at pyramidIn nle ovrdeel kr ,t we employ an m Aneschho frro Pmat Mch batose Md technique and Laplacian Mesh Deformation, which utilizes I1k, I2k and M1k. [sent-181, score-0.743]
</p><p>84 We follow the Anchor Patch process outlined in [10] tMo achieve this mesh propagation: SIFT features are initially detected and matched between images I1k and I2k given a corresponding set of features between each image. [sent-182, score-0.712]
</p><p>85 We then 222444333755  –  go through every vertex v of M1k and search for the three gnoea rthesrot uSgIhFT e vfeeraytu vreesr ef∗x w vi tohfin M a 9 9 search window centered on the vertex v in Iw1ki. [sent-183, score-0.316]
</p><p>86 t Tinh ea corresponding ifnedaotuwre cse ninI2k and Barycentric Coordinate Mappings defined by the triangle formed by the 3 SIFT features are used to calculate a corresponding vertex v? [sent-184, score-0.173]
</p><p>87 ) from [3, N1e0]x on waell taphep newly crrreoarte fdu nvcetirtoenx correspondences between I1k and I2k. [sent-187, score-0.031]
</p><p>88 This is carried out in order to select the most reliable vertex matches between the two images. [sent-188, score-0.117]
</p><p>89 sTmhael lve rretgeixo nmsa (tc3h ×es 3w)i tche nlotewre errors are dsel vected as sets of control points defined here as Vc, V? [sent-191, score-0.052]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('mesh', 0.712), ('laplacian', 0.264), ('vc', 0.231), ('flow', 0.221), ('optical', 0.158), ('energy', 0.154), ('pyramidal', 0.145), ('elap', 0.141), ('vertex', 0.117), ('garg', 0.109), ('constancy', 0.09), ('vi', 0.082), ('edata', 0.078), ('tier', 0.07), ('deformations', 0.069), ('middlebury', 0.063), ('bath', 0.062), ('triangles', 0.056), ('sobel', 0.055), ('deformation', 0.054), ('preserve', 0.054), ('esmooth', 0.052), ('err', 0.05), ('vertices', 0.049), ('variational', 0.049), ('boundaries', 0.048), ('formula', 0.048), ('smoothness', 0.045), ('tehree', 0.043), ('hybrid', 0.042), ('rationale', 0.042), ('whilst', 0.041), ('preservation', 0.041), ('parallax', 0.041), ('concept', 0.04), ('finer', 0.04), ('slic', 0.04), ('displacement', 0.039), ('triangular', 0.039), ('penalizes', 0.039), ('adjacent', 0.039), ('enhancement', 0.038), ('meshes', 0.037), ('propagated', 0.034), ('relating', 0.034), ('propagating', 0.033), ('motion', 0.032), ('intensity', 0.032), ('coordinates', 0.031), ('term', 0.031), ('thoede', 0.031), ('fdu', 0.031), ('cosker', 0.031), ('erence', 0.031), ('schunck', 0.031), ('lorentzian', 0.031), ('meyer', 0.031), ('bthee', 0.031), ('frro', 0.031), ('oufm', 0.031), ('triangle', 0.031), ('graphics', 0.031), ('surface', 0.031), ('edges', 0.03), ('field', 0.029), ('tdheef', 0.029), ('isv', 0.029), ('meshing', 0.029), ('differentials', 0.029), ('editable', 0.029), ('lv', 0.028), ('pyramid', 0.028), ('lost', 0.028), ('uk', 0.028), ('correlations', 0.027), ('superpixels', 0.027), ('discrete', 0.027), ('tsheet', 0.027), ('pizarro', 0.027), ('eofn', 0.027), ('lve', 0.027), ('lthe', 0.027), ('matthew', 0.027), ('encourage', 0.027), ('refinement', 0.027), ('edge', 0.027), ('maintaining', 0.027), ('dx', 0.027), ('deduce', 0.026), ('skewed', 0.026), ('engaged', 0.026), ('barycentric', 0.026), ('opposed', 0.026), ('create', 0.026), ('details', 0.025), ('cse', 0.025), ('tche', 0.025), ('noisier', 0.025), ('tice', 0.025), ('mv', 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="316-tfidf-1" href="./cvpr-2013-Optical_Flow_Estimation_Using_Laplacian_Mesh_Energy.html">316 cvpr-2013-Optical Flow Estimation Using Laplacian Mesh Energy</a></p>
<p>Author: Wenbin Li, Darren Cosker, Matthew Brown, Rui Tang</p><p>Abstract: In this paper we present a novel non-rigid optical flow algorithm for dense image correspondence and non-rigid registration. The algorithm uses a unique Laplacian Mesh Energy term to encourage local smoothness whilst simultaneously preserving non-rigid deformation. Laplacian deformation approaches have become popular in graphics research as they enable mesh deformations to preserve local surface shape. In this work we propose a novel Laplacian Mesh Energy formula to ensure such sensible local deformations between image pairs. We express this wholly within the optical flow optimization, and show its application in a novel coarse-to-fine pyramidal approach. Our algorithm achieves the state-of-the-art performance in all trials on the Garg et al. dataset, and top tier performance on the Middlebury evaluation.</p><p>2 0.40880704 <a title="316-tfidf-2" href="./cvpr-2013-Mesh_Based_Semantic_Modelling_for_Indoor_and_Outdoor_Scenes.html">284 cvpr-2013-Mesh Based Semantic Modelling for Indoor and Outdoor Scenes</a></p>
<p>Author: Julien P.C. Valentin, Sunando Sengupta, Jonathan Warrell, Ali Shahrokni, Philip H.S. Torr</p><p>Abstract: Semantic reconstruction of a scene is important for a variety of applications such as 3D modelling, object recognition and autonomous robotic navigation. However, most object labelling methods work in the image domain and fail to capture the information present in 3D space. In this work we propose a principled way to generate object labelling in 3D. Our method builds a triangulated meshed representation of the scene from multiple depth estimates. We then define a CRF over this mesh, which is able to capture the consistency of geometric properties of the objects present in the scene. In this framework, we are able to generate object hypotheses by combining information from multiple sources: geometric properties (from the 3D mesh), and appearance properties (from images). We demonstrate the robustness of our framework in both indoor and outdoor scenes. For indoor scenes we created an augmented version of the NYU indoor scene dataset (RGB-D images) with object labelled meshes for training and evaluation. For outdoor scenes, we created ground truth object labellings for the KITTI odometry dataset (stereo image sequence). We observe a signifi- cant speed-up in the inference stage by performing labelling on the mesh, and additionally achieve higher accuracies.</p><p>3 0.25505257 <a title="316-tfidf-3" href="./cvpr-2013-Multi-resolution_Shape_Analysis_via_Non-Euclidean_Wavelets%3A_Applications_to_Mesh_Segmentation_and_Surface_Alignment_Problems.html">297 cvpr-2013-Multi-resolution Shape Analysis via Non-Euclidean Wavelets: Applications to Mesh Segmentation and Surface Alignment Problems</a></p>
<p>Author: Won Hwa Kim, Moo K. Chung, Vikas Singh</p><p>Abstract: The analysis of 3-D shape meshes is a fundamental problem in computer vision, graphics, and medical imaging. Frequently, the needs of the application require that our analysis take a multi-resolution view of the shape ’s local and global topology, and that the solution is consistent across multiple scales. Unfortunately, the preferred mathematical construct which offers this behavior in classical image/signal processing, Wavelets, is no longer applicable in this general setting (data with non-uniform topology). In particular, the traditional definition does not allow writing out an expansion for graphs that do not correspond to the uniformly sampled lattice (e.g., images). In this paper, we adapt recent results in harmonic analysis, to derive NonEuclidean Wavelets based algorithms for a range of shape analysis problems in vision and medical imaging. We show how descriptors derived from the dual domain representation offer native multi-resolution behavior for characterizing local/global topology around vertices. With only minor modifications, the framework yields a method for extracting interest/key points from shapes, a surprisingly simple algorithm for 3-D shape segmentation (competitive with state of the art), and a method for surface alignment (without landmarks). We give an extensive set of comparison results on a large shape segmentation benchmark and derive a uniqueness theorem for the surface alignment problem.</p><p>4 0.20850223 <a title="316-tfidf-4" href="./cvpr-2013-Correspondence-Less_Non-rigid_Registration_of_Triangular_Surface_Meshes.html">97 cvpr-2013-Correspondence-Less Non-rigid Registration of Triangular Surface Meshes</a></p>
<p>Author: Zsolt Sánta, Zoltan Kato</p><p>Abstract: A novel correspondence-less approach is proposed to find a thin plate spline map between a pair of deformable 3D objects represented by triangular surface meshes. The proposed method works without landmark extraction and feature correspondences. The aligning transformation is found simply by solving a system of nonlinear equations. Each equation is generated by integrating a nonlinear function over the object’s domains. We derive recursive formulas for the efficient computation of these integrals. Based on a series of comparative tests on a large synthetic dataset, our triangular mesh-based algorithm outperforms state of the art methods both in terms of computing time and accuracy. The applicability of the proposed approach has been demonstrated on the registration of 3D lung CT volumes.</p><p>5 0.18030907 <a title="316-tfidf-5" href="./cvpr-2013-Large_Displacement_Optical_Flow_from_Nearest_Neighbor_Fields.html">244 cvpr-2013-Large Displacement Optical Flow from Nearest Neighbor Fields</a></p>
<p>Author: Zhuoyuan Chen, Hailin Jin, Zhe Lin, Scott Cohen, Ying Wu</p><p>Abstract: We present an optical flow algorithm for large displacement motions. Most existing optical flow methods use the standard coarse-to-fine framework to deal with large displacement motions which has intrinsic limitations. Instead, we formulate the motion estimation problem as a motion segmentation problem. We use approximate nearest neighbor fields to compute an initial motion field and use a robust algorithm to compute a set of similarity transformations as the motion candidates for segmentation. To account for deviations from similarity transformations, we add local deformations in the segmentation process. We also observe that small objects can be better recovered using translations as the motion candidates. We fuse the motion results obtained under similarity transformations and under translations together before a final refinement. Experimental validation shows that our method can successfully handle large displacement motions. Although we particularly focus on large displacement motions in this work, we make no sac- rifice in terms of overall performance. In particular, our method ranks at the top of the Middlebury benchmark.</p><p>6 0.1486236 <a title="316-tfidf-6" href="./cvpr-2013-Robust_Monocular_Epipolar_Flow_Estimation.html">362 cvpr-2013-Robust Monocular Epipolar Flow Estimation</a></p>
<p>7 0.13854431 <a title="316-tfidf-7" href="./cvpr-2013-Pose_from_Flow_and_Flow_from_Pose.html">334 cvpr-2013-Pose from Flow and Flow from Pose</a></p>
<p>8 0.1372513 <a title="316-tfidf-8" href="./cvpr-2013-Efficient_Computation_of_Shortest_Path-Concavity_for_3D_Meshes.html">141 cvpr-2013-Efficient Computation of Shortest Path-Concavity for 3D Meshes</a></p>
<p>9 0.12719098 <a title="316-tfidf-9" href="./cvpr-2013-A_Fully-Connected_Layered_Model_of_Foreground_and_Background_Flow.html">10 cvpr-2013-A Fully-Connected Layered Model of Foreground and Background Flow</a></p>
<p>10 0.12598328 <a title="316-tfidf-10" href="./cvpr-2013-Tensor-Based_Human_Body_Modeling.html">426 cvpr-2013-Tensor-Based Human Body Modeling</a></p>
<p>11 0.10874079 <a title="316-tfidf-11" href="./cvpr-2013-Real-Time_Model-Based_Rigid_Object_Pose_Estimation_and_Tracking_Combining_Dense_and_Sparse_Visual_Cues.html">345 cvpr-2013-Real-Time Model-Based Rigid Object Pose Estimation and Tracking Combining Dense and Sparse Visual Cues</a></p>
<p>12 0.10171624 <a title="316-tfidf-12" href="./cvpr-2013-Plane-Based_Content_Preserving_Warps_for_Video_Stabilization.html">333 cvpr-2013-Plane-Based Content Preserving Warps for Video Stabilization</a></p>
<p>13 0.098337777 <a title="316-tfidf-13" href="./cvpr-2013-Determining_Motion_Directly_from_Normal_Flows_Upon_the_Use_of_a_Spherical_Eye_Platform.html">124 cvpr-2013-Determining Motion Directly from Normal Flows Upon the Use of a Spherical Eye Platform</a></p>
<p>14 0.097265743 <a title="316-tfidf-14" href="./cvpr-2013-Better_Exploiting_Motion_for_Better_Action_Recognition.html">59 cvpr-2013-Better Exploiting Motion for Better Action Recognition</a></p>
<p>15 0.096987948 <a title="316-tfidf-15" href="./cvpr-2013-Multi-target_Tracking_by_Lagrangian_Relaxation_to_Min-cost_Network_Flow.html">300 cvpr-2013-Multi-target Tracking by Lagrangian Relaxation to Min-cost Network Flow</a></p>
<p>16 0.093613543 <a title="316-tfidf-16" href="./cvpr-2013-Intrinsic_Characterization_of_Dynamic_Surfaces.html">226 cvpr-2013-Intrinsic Characterization of Dynamic Surfaces</a></p>
<p>17 0.089418948 <a title="316-tfidf-17" href="./cvpr-2013-Exploring_Weak_Stabilization_for_Motion_Feature_Extraction.html">158 cvpr-2013-Exploring Weak Stabilization for Motion Feature Extraction</a></p>
<p>18 0.084262438 <a title="316-tfidf-18" href="./cvpr-2013-Patch_Match_Filter%3A_Efficient_Edge-Aware_Filtering_Meets_Randomized_Search_for_Fast_Correspondence_Field_Estimation.html">326 cvpr-2013-Patch Match Filter: Efficient Edge-Aware Filtering Meets Randomized Search for Fast Correspondence Field Estimation</a></p>
<p>19 0.084020287 <a title="316-tfidf-19" href="./cvpr-2013-The_Generalized_Laplacian_Distance_and_Its_Applications_for_Visual_Matching.html">429 cvpr-2013-The Generalized Laplacian Distance and Its Applications for Visual Matching</a></p>
<p>20 0.082343034 <a title="316-tfidf-20" href="./cvpr-2013-Pattern-Driven_Colorization_of_3D_Surfaces.html">327 cvpr-2013-Pattern-Driven Colorization of 3D Surfaces</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.148), (1, 0.133), (2, 0.024), (3, 0.002), (4, 0.007), (5, -0.049), (6, 0.019), (7, -0.041), (8, -0.065), (9, 0.028), (10, 0.12), (11, 0.117), (12, -0.029), (13, -0.022), (14, 0.155), (15, -0.063), (16, 0.027), (17, -0.039), (18, 0.029), (19, 0.091), (20, -0.191), (21, -0.089), (22, 0.119), (23, 0.03), (24, -0.273), (25, -0.042), (26, 0.109), (27, 0.001), (28, -0.104), (29, -0.105), (30, -0.014), (31, 0.069), (32, 0.114), (33, 0.029), (34, -0.105), (35, 0.003), (36, 0.006), (37, -0.071), (38, 0.001), (39, 0.015), (40, -0.176), (41, -0.088), (42, 0.032), (43, 0.017), (44, 0.08), (45, -0.034), (46, 0.031), (47, 0.099), (48, 0.007), (49, 0.058)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96450353 <a title="316-lsi-1" href="./cvpr-2013-Optical_Flow_Estimation_Using_Laplacian_Mesh_Energy.html">316 cvpr-2013-Optical Flow Estimation Using Laplacian Mesh Energy</a></p>
<p>Author: Wenbin Li, Darren Cosker, Matthew Brown, Rui Tang</p><p>Abstract: In this paper we present a novel non-rigid optical flow algorithm for dense image correspondence and non-rigid registration. The algorithm uses a unique Laplacian Mesh Energy term to encourage local smoothness whilst simultaneously preserving non-rigid deformation. Laplacian deformation approaches have become popular in graphics research as they enable mesh deformations to preserve local surface shape. In this work we propose a novel Laplacian Mesh Energy formula to ensure such sensible local deformations between image pairs. We express this wholly within the optical flow optimization, and show its application in a novel coarse-to-fine pyramidal approach. Our algorithm achieves the state-of-the-art performance in all trials on the Garg et al. dataset, and top tier performance on the Middlebury evaluation.</p><p>2 0.70514309 <a title="316-lsi-2" href="./cvpr-2013-Multi-resolution_Shape_Analysis_via_Non-Euclidean_Wavelets%3A_Applications_to_Mesh_Segmentation_and_Surface_Alignment_Problems.html">297 cvpr-2013-Multi-resolution Shape Analysis via Non-Euclidean Wavelets: Applications to Mesh Segmentation and Surface Alignment Problems</a></p>
<p>Author: Won Hwa Kim, Moo K. Chung, Vikas Singh</p><p>Abstract: The analysis of 3-D shape meshes is a fundamental problem in computer vision, graphics, and medical imaging. Frequently, the needs of the application require that our analysis take a multi-resolution view of the shape ’s local and global topology, and that the solution is consistent across multiple scales. Unfortunately, the preferred mathematical construct which offers this behavior in classical image/signal processing, Wavelets, is no longer applicable in this general setting (data with non-uniform topology). In particular, the traditional definition does not allow writing out an expansion for graphs that do not correspond to the uniformly sampled lattice (e.g., images). In this paper, we adapt recent results in harmonic analysis, to derive NonEuclidean Wavelets based algorithms for a range of shape analysis problems in vision and medical imaging. We show how descriptors derived from the dual domain representation offer native multi-resolution behavior for characterizing local/global topology around vertices. With only minor modifications, the framework yields a method for extracting interest/key points from shapes, a surprisingly simple algorithm for 3-D shape segmentation (competitive with state of the art), and a method for surface alignment (without landmarks). We give an extensive set of comparison results on a large shape segmentation benchmark and derive a uniqueness theorem for the surface alignment problem.</p><p>3 0.67382926 <a title="316-lsi-3" href="./cvpr-2013-Efficient_Computation_of_Shortest_Path-Concavity_for_3D_Meshes.html">141 cvpr-2013-Efficient Computation of Shortest Path-Concavity for 3D Meshes</a></p>
<p>Author: Henrik Zimmer, Marcel Campen, Leif Kobbelt</p><p>Abstract: In the context of shape segmentation and retrieval object-wide distributions of measures are needed to accurately evaluate and compare local regions ofshapes. Lien et al. [16] proposed two point-wise concavity measures in the context of Approximate Convex Decompositions of polygons measuring the distance from a point to the polygon ’s convex hull: an accurate Shortest Path-Concavity (SPC) measure and a Straight Line-Concavity (SLC) approximation of the same. While both are practicable on 2D shapes, the exponential costs of SPC in 3D makes it inhibitively expensive for a generalization to meshes [14]. In this paper we propose an efficient and straight forward approximation of the Shortest Path-Concavity measure to 3D meshes. Our approximation is based on discretizing the space between mesh and convex hull, thereby reducing the continuous Shortest Path search to an efficiently solvable graph problem. Our approach works outof-the-box on complex mesh topologies and requires no complicated handling of genus. Besides presenting a rigorous evaluation of our method on a variety of input meshes, we also define an SPC-based Shape Descriptor and show its superior retrieval and runtime performance compared with the recently presented results on the Convexity Distribution by Lian et al. [12].</p><p>4 0.61871016 <a title="316-lsi-4" href="./cvpr-2013-Mesh_Based_Semantic_Modelling_for_Indoor_and_Outdoor_Scenes.html">284 cvpr-2013-Mesh Based Semantic Modelling for Indoor and Outdoor Scenes</a></p>
<p>Author: Julien P.C. Valentin, Sunando Sengupta, Jonathan Warrell, Ali Shahrokni, Philip H.S. Torr</p><p>Abstract: Semantic reconstruction of a scene is important for a variety of applications such as 3D modelling, object recognition and autonomous robotic navigation. However, most object labelling methods work in the image domain and fail to capture the information present in 3D space. In this work we propose a principled way to generate object labelling in 3D. Our method builds a triangulated meshed representation of the scene from multiple depth estimates. We then define a CRF over this mesh, which is able to capture the consistency of geometric properties of the objects present in the scene. In this framework, we are able to generate object hypotheses by combining information from multiple sources: geometric properties (from the 3D mesh), and appearance properties (from images). We demonstrate the robustness of our framework in both indoor and outdoor scenes. For indoor scenes we created an augmented version of the NYU indoor scene dataset (RGB-D images) with object labelled meshes for training and evaluation. For outdoor scenes, we created ground truth object labellings for the KITTI odometry dataset (stereo image sequence). We observe a signifi- cant speed-up in the inference stage by performing labelling on the mesh, and additionally achieve higher accuracies.</p><p>5 0.59560955 <a title="316-lsi-5" href="./cvpr-2013-Correspondence-Less_Non-rigid_Registration_of_Triangular_Surface_Meshes.html">97 cvpr-2013-Correspondence-Less Non-rigid Registration of Triangular Surface Meshes</a></p>
<p>Author: Zsolt Sánta, Zoltan Kato</p><p>Abstract: A novel correspondence-less approach is proposed to find a thin plate spline map between a pair of deformable 3D objects represented by triangular surface meshes. The proposed method works without landmark extraction and feature correspondences. The aligning transformation is found simply by solving a system of nonlinear equations. Each equation is generated by integrating a nonlinear function over the object’s domains. We derive recursive formulas for the efficient computation of these integrals. Based on a series of comparative tests on a large synthetic dataset, our triangular mesh-based algorithm outperforms state of the art methods both in terms of computing time and accuracy. The applicability of the proposed approach has been demonstrated on the registration of 3D lung CT volumes.</p><p>6 0.58524424 <a title="316-lsi-6" href="./cvpr-2013-Area_Preserving_Brain_Mapping.html">44 cvpr-2013-Area Preserving Brain Mapping</a></p>
<p>7 0.55791378 <a title="316-lsi-7" href="./cvpr-2013-Hyperbolic_Harmonic_Mapping_for_Constrained_Brain_Surface_Registration.html">208 cvpr-2013-Hyperbolic Harmonic Mapping for Constrained Brain Surface Registration</a></p>
<p>8 0.49795863 <a title="316-lsi-8" href="./cvpr-2013-Intrinsic_Characterization_of_Dynamic_Surfaces.html">226 cvpr-2013-Intrinsic Characterization of Dynamic Surfaces</a></p>
<p>9 0.48921946 <a title="316-lsi-9" href="./cvpr-2013-A_Fully-Connected_Layered_Model_of_Foreground_and_Background_Flow.html">10 cvpr-2013-A Fully-Connected Layered Model of Foreground and Background Flow</a></p>
<p>10 0.46685472 <a title="316-lsi-10" href="./cvpr-2013-Compressible_Motion_Fields.html">88 cvpr-2013-Compressible Motion Fields</a></p>
<p>11 0.46471167 <a title="316-lsi-11" href="./cvpr-2013-Robust_Monocular_Epipolar_Flow_Estimation.html">362 cvpr-2013-Robust Monocular Epipolar Flow Estimation</a></p>
<p>12 0.45398352 <a title="316-lsi-12" href="./cvpr-2013-Large_Displacement_Optical_Flow_from_Nearest_Neighbor_Fields.html">244 cvpr-2013-Large Displacement Optical Flow from Nearest Neighbor Fields</a></p>
<p>13 0.44311723 <a title="316-lsi-13" href="./cvpr-2013-Pattern-Driven_Colorization_of_3D_Surfaces.html">327 cvpr-2013-Pattern-Driven Colorization of 3D Surfaces</a></p>
<p>14 0.44145113 <a title="316-lsi-14" href="./cvpr-2013-Monocular_Template-Based_3D_Reconstruction_of_Extensible_Surfaces_with_Local_Linear_Elasticity.html">289 cvpr-2013-Monocular Template-Based 3D Reconstruction of Extensible Surfaces with Local Linear Elasticity</a></p>
<p>15 0.42897081 <a title="316-lsi-15" href="./cvpr-2013-Three-Dimensional_Bilateral_Symmetry_Plane_Estimation_in_the_Phase_Domain.html">432 cvpr-2013-Three-Dimensional Bilateral Symmetry Plane Estimation in the Phase Domain</a></p>
<p>16 0.40115029 <a title="316-lsi-16" href="./cvpr-2013-Computing_Diffeomorphic_Paths_for_Large_Motion_Interpolation.html">90 cvpr-2013-Computing Diffeomorphic Paths for Large Motion Interpolation</a></p>
<p>17 0.40019736 <a title="316-lsi-17" href="./cvpr-2013-Towards_Contactless%2C_Low-Cost_and_Accurate_3D_Fingerprint_Identification.html">435 cvpr-2013-Towards Contactless, Low-Cost and Accurate 3D Fingerprint Identification</a></p>
<p>18 0.39622211 <a title="316-lsi-18" href="./cvpr-2013-Rotation%2C_Scaling_and_Deformation_Invariant_Scattering_for_Texture_Discrimination.html">369 cvpr-2013-Rotation, Scaling and Deformation Invariant Scattering for Texture Discrimination</a></p>
<p>19 0.38486943 <a title="316-lsi-19" href="./cvpr-2013-Patch_Match_Filter%3A_Efficient_Edge-Aware_Filtering_Meets_Randomized_Search_for_Fast_Correspondence_Field_Estimation.html">326 cvpr-2013-Patch Match Filter: Efficient Edge-Aware Filtering Meets Randomized Search for Fast Correspondence Field Estimation</a></p>
<p>20 0.38176203 <a title="316-lsi-20" href="./cvpr-2013-Multi-scale_Curve_Detection_on_Surfaces.html">298 cvpr-2013-Multi-scale Curve Detection on Surfaces</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.13), (16, 0.027), (26, 0.035), (33, 0.274), (59, 0.255), (67, 0.046), (69, 0.081), (87, 0.065)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.9238978 <a title="316-lda-1" href="./cvpr-2013-A_Genetic_Algorithm-Based_Solver_for_Very_Large_Jigsaw_Puzzles.html">11 cvpr-2013-A Genetic Algorithm-Based Solver for Very Large Jigsaw Puzzles</a></p>
<p>Author: Dror Sholomon, Omid David, Nathan S. Netanyahu</p><p>Abstract: In thispaper wepropose thefirst effective automated, genetic algorithm (GA)-based jigsaw puzzle solver. We introduce a novel procedure of merging two ”parent” solutions to an improved ”child” solution by detecting, extracting, and combining correctly assembled puzzle segments. The solver proposed exhibits state-of-the-art performance solving previously attempted puzzles faster and far more accurately, and also puzzles of size never before attempted. Other contributions include the creation of a benchmark of large images, previously unavailable. We share the data sets and all of our results for future testing and comparative evaluation of jigsaw puzzle solvers.</p><p>2 0.86779702 <a title="316-lda-2" href="./cvpr-2013-MKPLS%3A_Manifold_Kernel_Partial_Least_Squares_for_Lipreading_and_Speaker_Identification.html">276 cvpr-2013-MKPLS: Manifold Kernel Partial Least Squares for Lipreading and Speaker Identification</a></p>
<p>Author: Amr Bakry, Ahmed Elgammal</p><p>Abstract: Visual speech recognition is a challenging problem, due to confusion between visual speech features. The speaker identification problem is usually coupled with speech recognition. Moreover, speaker identification is important to several applications, such as automatic access control, biometrics, authentication, and personal privacy issues. In this paper, we propose a novel approach for lipreading and speaker identification. Wepropose a new approachfor manifold parameterization in a low-dimensional latent space, where each manifold is represented as a point in that space. We initially parameterize each instance manifold using a nonlinear mapping from a unified manifold representation. We then factorize the parameter space using Kernel Partial Least Squares (KPLS) to achieve a low-dimension manifold latent space. We use two-way projections to achieve two manifold latent spaces, one for the speech content and one for the speaker. We apply our approach on two public databases: AVLetters and OuluVS. We show the results for three different settings of lipreading: speaker independent, speaker dependent, and speaker semi-dependent. Our approach outperforms for the speaker semi-dependent setting by at least 15% of the baseline, and competes in the other two settings.</p><p>same-paper 3 0.85882092 <a title="316-lda-3" href="./cvpr-2013-Optical_Flow_Estimation_Using_Laplacian_Mesh_Energy.html">316 cvpr-2013-Optical Flow Estimation Using Laplacian Mesh Energy</a></p>
<p>Author: Wenbin Li, Darren Cosker, Matthew Brown, Rui Tang</p><p>Abstract: In this paper we present a novel non-rigid optical flow algorithm for dense image correspondence and non-rigid registration. The algorithm uses a unique Laplacian Mesh Energy term to encourage local smoothness whilst simultaneously preserving non-rigid deformation. Laplacian deformation approaches have become popular in graphics research as they enable mesh deformations to preserve local surface shape. In this work we propose a novel Laplacian Mesh Energy formula to ensure such sensible local deformations between image pairs. We express this wholly within the optical flow optimization, and show its application in a novel coarse-to-fine pyramidal approach. Our algorithm achieves the state-of-the-art performance in all trials on the Garg et al. dataset, and top tier performance on the Middlebury evaluation.</p><p>4 0.84553951 <a title="316-lda-4" href="./cvpr-2013-Dense_Segmentation-Aware_Descriptors.html">112 cvpr-2013-Dense Segmentation-Aware Descriptors</a></p>
<p>Author: Eduard Trulls, Iasonas Kokkinos, Alberto Sanfeliu, Francesc Moreno-Noguer</p><p>Abstract: In this work we exploit segmentation to construct appearance descriptors that can robustly deal with occlusion and background changes. For this, we downplay measurements coming from areas that are unlikely to belong to the same region as the descriptor’s center, as suggested by soft segmentation masks. Our treatment is applicable to any image point, i.e. dense, and its computational overhead is in the order of a few seconds. We integrate this idea with Dense SIFT, and also with Dense Scale and Rotation Invariant Descriptors (SID), delivering descriptors that are densely computable, invariant to scaling and rotation, and robust to background changes. We apply our approach to standard benchmarks on large displacement motion estimation using SIFT-flow and widebaseline stereo, systematically demonstrating that the introduction of segmentation yields clear improvements.</p><p>5 0.83913159 <a title="316-lda-5" href="./cvpr-2013-Multi-scale_Curve_Detection_on_Surfaces.html">298 cvpr-2013-Multi-scale Curve Detection on Surfaces</a></p>
<p>Author: Michael Kolomenkin, Ilan Shimshoni, Ayellet Tal</p><p>Abstract: This paper extends to surfaces the multi-scale approach of edge detection on images. The common practice for detecting curves on surfaces requires the user to first select the scale of the features, apply an appropriate smoothing, and detect the edges on the smoothed surface. This approach suffers from two drawbacks. First, it relies on a hidden assumption that all the features on the surface are of the same scale. Second, manual user intervention is required. In this paper, we propose a general framework for automatically detecting the optimal scale for each point on the surface. We smooth the surface at each point according to this optimal scale and run the curve detection algorithm on the resulting surface. Our multi-scale algorithm solves the two disadvantages of the single-scale approach mentioned above. We demonstrate how to realize our approach on two commonly-used special cases: ridges & valleys and relief edges. In each case, the optimal scale is found in accordance with the mathematical definition of the curve.</p><p>6 0.80861396 <a title="316-lda-6" href="./cvpr-2013-Constrained_Clustering_and_Its_Application_to_Face_Clustering_in_Videos.html">92 cvpr-2013-Constrained Clustering and Its Application to Face Clustering in Videos</a></p>
<p>7 0.80248564 <a title="316-lda-7" href="./cvpr-2013-Visual_Place_Recognition_with_Repetitive_Structures.html">456 cvpr-2013-Visual Place Recognition with Repetitive Structures</a></p>
<p>8 0.78255773 <a title="316-lda-8" href="./cvpr-2013-Axially_Symmetric_3D_Pots_Configuration_System_Using_Axis_of_Symmetry_and_Break_Curve.html">52 cvpr-2013-Axially Symmetric 3D Pots Configuration System Using Axis of Symmetry and Break Curve</a></p>
<p>9 0.77970219 <a title="316-lda-9" href="./cvpr-2013-Beyond_Point_Clouds%3A_Scene_Understanding_by_Reasoning_Geometry_and_Physics.html">61 cvpr-2013-Beyond Point Clouds: Scene Understanding by Reasoning Geometry and Physics</a></p>
<p>10 0.77874959 <a title="316-lda-10" href="./cvpr-2013-Multi-resolution_Shape_Analysis_via_Non-Euclidean_Wavelets%3A_Applications_to_Mesh_Segmentation_and_Surface_Alignment_Problems.html">297 cvpr-2013-Multi-resolution Shape Analysis via Non-Euclidean Wavelets: Applications to Mesh Segmentation and Surface Alignment Problems</a></p>
<p>11 0.77844369 <a title="316-lda-11" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>12 0.77825058 <a title="316-lda-12" href="./cvpr-2013-Bottom-Up_Segmentation_for_Top-Down_Detection.html">70 cvpr-2013-Bottom-Up Segmentation for Top-Down Detection</a></p>
<p>13 0.77815676 <a title="316-lda-13" href="./cvpr-2013-Understanding_Bayesian_Rooms_Using_Composite_3D_Object_Models.html">445 cvpr-2013-Understanding Bayesian Rooms Using Composite 3D Object Models</a></p>
<p>14 0.77758622 <a title="316-lda-14" href="./cvpr-2013-Understanding_Indoor_Scenes_Using_3D_Geometric_Phrases.html">446 cvpr-2013-Understanding Indoor Scenes Using 3D Geometric Phrases</a></p>
<p>15 0.7761395 <a title="316-lda-15" href="./cvpr-2013-SLAM%2B%2B%3A_Simultaneous_Localisation_and_Mapping_at_the_Level_of_Objects.html">372 cvpr-2013-SLAM++: Simultaneous Localisation and Mapping at the Level of Objects</a></p>
<p>16 0.77517432 <a title="316-lda-16" href="./cvpr-2013-Learning_Structured_Hough_Voting_for_Joint_Object_Detection_and_Occlusion_Reasoning.html">256 cvpr-2013-Learning Structured Hough Voting for Joint Object Detection and Occlusion Reasoning</a></p>
<p>17 0.77481002 <a title="316-lda-17" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<p>18 0.77427304 <a title="316-lda-18" href="./cvpr-2013-Discriminative_Re-ranking_of_Diverse_Segmentations.html">132 cvpr-2013-Discriminative Re-ranking of Diverse Segmentations</a></p>
<p>19 0.77424771 <a title="316-lda-19" href="./cvpr-2013-Mesh_Based_Semantic_Modelling_for_Indoor_and_Outdoor_Scenes.html">284 cvpr-2013-Mesh Based Semantic Modelling for Indoor and Outdoor Scenes</a></p>
<p>20 0.77336562 <a title="316-lda-20" href="./cvpr-2013-Part_Discovery_from_Partial_Correspondence.html">325 cvpr-2013-Part Discovery from Partial Correspondence</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
