<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>186 cvpr-2013-GeoF: Geodesic Forests for Learning Coupled Predictors</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-186" href="#">cvpr2013-186</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>186 cvpr-2013-GeoF: Geodesic Forests for Learning Coupled Predictors</h1>
<br/><p>Source: <a title="cvpr-2013-186-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Kontschieder_GeoF_Geodesic_Forests_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Peter Kontschieder, Pushmeet Kohli, Jamie Shotton, Antonio Criminisi</p><p>Abstract: Conventional decision forest based methods for image labelling tasks like object segmentation make predictions for each variable (pixel) independently [3, 5, 8]. This prevents them from enforcing dependencies between variables and translates into locally inconsistent pixel labellings. Random field models, instead, encourage spatial consistency of labels at increased computational expense. This paper presents a new and efficient forest based model that achieves spatially consistent semantic image segmentation by encoding variable dependencies directly in the feature space the forests operate on. Such correlations are captured via new long-range, soft connectivity features, computed via generalized geodesic distance transforms. Our model can be thought of as a generalization of the successful Semantic Texton Forest, Auto-Context, and Entangled Forest models. A second contribution is to show the connection between the typical Conditional Random Field (CRF) energy and the forest training objective. This analysis yields a new objective for training decision forests that encourages more accurate structured prediction. Our GeoF model is validated quantitatively on the task of semantic image segmentation, on four challenging and very diverse image datasets. GeoF outperforms both stateof-the-art forest models and the conventional pairwise CRF.</p><p>Reference: <a title="cvpr-2013-186-reference" href="../cvpr2013_reference/cvpr-2013-GeoF%3A_Geodesic_Forests_for_Learning_Coupled_Predictors_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('forest', 0.567), ('entangl', 0.477), ('geodes', 0.352), ('geof', 0.201), ('kidney', 0.139), ('fkd', 0.134), ('sem', 0.082), ('cp', 0.082), ('lung', 0.079), ('soft', 0.079), ('decid', 0.078), ('sji', 0.073), ('zk', 0.07), ('sj', 0.068), ('autocontext', 0.067), ('depht', 0.067), ('rlk', 0.067), ('spleen', 0.067), ('crf', 0.066), ('erf', 0.063)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999964 <a title="186-tfidf-1" href="./cvpr-2013-GeoF%3A_Geodesic_Forests_for_Learning_Coupled_Predictors.html">186 cvpr-2013-GeoF: Geodesic Forests for Learning Coupled Predictors</a></p>
<p>Author: Peter Kontschieder, Pushmeet Kohli, Jamie Shotton, Antonio Criminisi</p><p>Abstract: Conventional decision forest based methods for image labelling tasks like object segmentation make predictions for each variable (pixel) independently [3, 5, 8]. This prevents them from enforcing dependencies between variables and translates into locally inconsistent pixel labellings. Random field models, instead, encourage spatial consistency of labels at increased computational expense. This paper presents a new and efficient forest based model that achieves spatially consistent semantic image segmentation by encoding variable dependencies directly in the feature space the forests operate on. Such correlations are captured via new long-range, soft connectivity features, computed via generalized geodesic distance transforms. Our model can be thought of as a generalization of the successful Semantic Texton Forest, Auto-Context, and Entangled Forest models. A second contribution is to show the connection between the typical Conditional Random Field (CRF) energy and the forest training objective. This analysis yields a new objective for training decision forests that encourages more accurate structured prediction. Our GeoF model is validated quantitatively on the task of semantic image segmentation, on four challenging and very diverse image datasets. GeoF outperforms both stateof-the-art forest models and the conventional pairwise CRF.</p><p>2 0.43861264 <a title="186-tfidf-2" href="./cvpr-2013-Scene_Coordinate_Regression_Forests_for_Camera_Relocalization_in_RGB-D_Images.html">380 cvpr-2013-Scene Coordinate Regression Forests for Camera Relocalization in RGB-D Images</a></p>
<p>Author: Jamie Shotton, Ben Glocker, Christopher Zach, Shahram Izadi, Antonio Criminisi, Andrew Fitzgibbon</p><p>Abstract: We address the problem of inferring the pose of an RGB-D camera relative to a known 3D scene, given only a single acquired image. Our approach employs a regression forest that is capable of inferring an estimate of each pixel’s correspondence to 3D points in the scene ’s world coordinate frame. The forest uses only simple depth and RGB pixel comparison features, and does not require the computation of feature descriptors. The forest is trained to be capable of predicting correspondences at any pixel, so no interest point detectors are required. The camera pose is inferred using a robust optimization scheme. This starts with an initial set of hypothesized camera poses, constructed by applying the forest at a small fraction of image pixels. Preemptive RANSAC then iterates sampling more pixels at which to evaluate the forest, counting inliers, and refining the hypothesized poses. We evaluate on several varied scenes captured with an RGB-D camera and observe that the proposed technique achieves highly accurate relocalization and substantially out-performs two state of the art baselines.</p><p>3 0.21863583 <a title="186-tfidf-3" href="./cvpr-2013-Alternating_Decision_Forests.html">39 cvpr-2013-Alternating Decision Forests</a></p>
<p>Author: Samuel Schulter, Paul Wohlhart, Christian Leistner, Amir Saffari, Peter M. Roth, Horst Bischof</p><p>Abstract: This paper introduces a novel classification method termed Alternating Decision Forests (ADFs), which formulates the training of Random Forests explicitly as a global loss minimization problem. During training, the losses are minimized via keeping an adaptive weight distribution over the training samples, similar to Boosting methods. In order to keep the method as flexible and general as possible, we adopt the principle of employing gradient descent in function space, which allows to minimize arbitrary losses. Contrary to Boosted Trees, in our method the loss minimization is an inherent part of the tree growing process, thus allowing to keep the benefits ofcommon Random Forests, such as, parallel processing. We derive the new classifier and give a discussion and evaluation on standard machine learning data sets. Furthermore, we show how ADFs can be easily integrated into an object detection application. Compared to both, standard Random Forests and Boosted Trees, ADFs give better performance in our experiments, while yielding more compact models in terms of tree depth.</p><p>4 0.20233734 <a title="186-tfidf-4" href="./cvpr-2013-Human_Pose_Estimation_Using_Body_Parts_Dependent_Joint_Regressors.html">206 cvpr-2013-Human Pose Estimation Using Body Parts Dependent Joint Regressors</a></p>
<p>Author: Matthias Dantone, Juergen Gall, Christian Leistner, Luc Van_Gool</p><p>Abstract: In this work, we address the problem of estimating 2d human pose from still images. Recent methods that rely on discriminatively trained deformable parts organized in a tree model have shown to be very successful in solving this task. Within such a pictorial structure framework, we address the problem of obtaining good part templates by proposing novel, non-linear joint regressors. In particular, we employ two-layered random forests as joint regressors. The first layer acts as a discriminative, independent body part classifier. The second layer takes the estimated class distributions of the first one into account and is thereby able to predict joint locations by modeling the interdependence and co-occurrence of the parts. This results in a pose estimation framework that takes dependencies between body parts already for joint localization into account and is thus able to circumvent typical ambiguities of tree structures, such as for legs and arms. In the experiments, we demonstrate that our body parts dependent joint regressors achieve a higher joint localization accuracy than tree-based state-of-the-art methods.</p><p>5 0.19477998 <a title="186-tfidf-5" href="./cvpr-2013-Unconstrained_Monocular_3D_Human_Pose_Estimation_by_Action_Detection_and_Cross-Modality_Regression_Forest.html">444 cvpr-2013-Unconstrained Monocular 3D Human Pose Estimation by Action Detection and Cross-Modality Regression Forest</a></p>
<p>Author: Tsz-Ho Yu, Tae-Kyun Kim, Roberto Cipolla</p><p>Abstract: This work addresses the challenging problem of unconstrained 3D human pose estimation (HPE)from a novelperspective. Existing approaches struggle to operate in realistic applications, mainly due to their scene-dependent priors, such as background segmentation and multi-camera network, which restrict their use in unconstrained environments. We therfore present a framework which applies action detection and 2D pose estimation techniques to infer 3D poses in an unconstrained video. Action detection offers spatiotemporal priors to 3D human pose estimation by both recognising and localising actions in space-time. Instead of holistic features, e.g. silhouettes, we leverage the flexibility of deformable part model to detect 2D body parts as a feature to estimate 3D poses. A new unconstrained pose dataset has been collected to justify the feasibility of our method, which demonstrated promising results, significantly outperforming the relevant state-of-the-arts.</p><p>6 0.18337689 <a title="186-tfidf-6" href="./cvpr-2013-Joint_Geodesic_Upsampling_of_Depth_Images.html">232 cvpr-2013-Joint Geodesic Upsampling of Depth Images</a></p>
<p>7 0.12620759 <a title="186-tfidf-7" href="./cvpr-2013-Leveraging_Structure_from_Motion_to_Learn_Discriminative_Codebooks_for_Scalable_Landmark_Classification.html">268 cvpr-2013-Leveraging Structure from Motion to Learn Discriminative Codebooks for Scalable Landmark Classification</a></p>
<p>8 0.12505521 <a title="186-tfidf-8" href="./cvpr-2013-Spatial_Inference_Machines.html">406 cvpr-2013-Spatial Inference Machines</a></p>
<p>9 0.12489388 <a title="186-tfidf-9" href="./cvpr-2013-Learning_Compact_Binary_Codes_for_Visual_Tracking.html">249 cvpr-2013-Learning Compact Binary Codes for Visual Tracking</a></p>
<p>10 0.11817917 <a title="186-tfidf-10" href="./cvpr-2013-Simultaneous_Active_Learning_of_Classifiers_%26_Attributes_via_Relative_Feedback.html">396 cvpr-2013-Simultaneous Active Learning of Classifiers & Attributes via Relative Feedback</a></p>
<p>11 0.10866773 <a title="186-tfidf-11" href="./cvpr-2013-Analyzing_Semantic_Segmentation_Using_Hybrid_Human-Machine_CRFs.html">43 cvpr-2013-Analyzing Semantic Segmentation Using Hybrid Human-Machine CRFs</a></p>
<p>12 0.1022298 <a title="186-tfidf-12" href="./cvpr-2013-Fast_Energy_Minimization_Using_Learned_State_Filters.html">165 cvpr-2013-Fast Energy Minimization Using Learned State Filters</a></p>
<p>13 0.098726057 <a title="186-tfidf-13" href="./cvpr-2013-Perceptual_Organization_and_Recognition_of_Indoor_Scenes_from_RGB-D_Images.html">329 cvpr-2013-Perceptual Organization and Recognition of Indoor Scenes from RGB-D Images</a></p>
<p>14 0.096845828 <a title="186-tfidf-14" href="./cvpr-2013-Tensor-Based_High-Order_Semantic_Relation_Transfer_for_Semantic_Scene_Segmentation.html">425 cvpr-2013-Tensor-Based High-Order Semantic Relation Transfer for Semantic Scene Segmentation</a></p>
<p>15 0.096630283 <a title="186-tfidf-15" href="./cvpr-2013-Fast_Patch-Based_Denoising_Using_Approximated_Patch_Geodesic_Paths.html">169 cvpr-2013-Fast Patch-Based Denoising Using Approximated Patch Geodesic Paths</a></p>
<p>16 0.094748013 <a title="186-tfidf-16" href="./cvpr-2013-Semi-supervised_Node_Splitting_for_Random_Forest_Construction.html">390 cvpr-2013-Semi-supervised Node Splitting for Random Forest Construction</a></p>
<p>17 0.088629976 <a title="186-tfidf-17" href="./cvpr-2013-Fully-Connected_CRFs_with_Non-Parametric_Pairwise_Potential.html">180 cvpr-2013-Fully-Connected CRFs with Non-Parametric Pairwise Potential</a></p>
<p>18 0.083946079 <a title="186-tfidf-18" href="./cvpr-2013-Learning_Cross-Domain_Information_Transfer_for_Location_Recognition_and_Clustering.html">250 cvpr-2013-Learning Cross-Domain Information Transfer for Location Recognition and Clustering</a></p>
<p>19 0.078626968 <a title="186-tfidf-19" href="./cvpr-2013-Uncalibrated_Photometric_Stereo_for_Unknown_Isotropic_Reflectances.html">443 cvpr-2013-Uncalibrated Photometric Stereo for Unknown Isotropic Reflectances</a></p>
<p>20 0.076926716 <a title="186-tfidf-20" href="./cvpr-2013-Nonparametric_Scene_Parsing_with_Adaptive_Feature_Relevance_and_Semantic_Context.html">309 cvpr-2013-Nonparametric Scene Parsing with Adaptive Feature Relevance and Semantic Context</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.185), (1, -0.017), (2, -0.028), (3, 0.006), (4, 0.071), (5, -0.031), (6, 0.046), (7, 0.01), (8, 0.029), (9, -0.038), (10, 0.081), (11, -0.086), (12, -0.062), (13, 0.018), (14, -0.107), (15, 0.055), (16, 0.067), (17, -0.025), (18, 0.036), (19, 0.019), (20, 0.083), (21, 0.059), (22, -0.052), (23, -0.057), (24, -0.015), (25, 0.007), (26, 0.05), (27, 0.019), (28, 0.088), (29, -0.155), (30, -0.153), (31, -0.026), (32, -0.027), (33, -0.251), (34, -0.045), (35, 0.105), (36, -0.122), (37, 0.028), (38, 0.03), (39, 0.188), (40, 0.092), (41, 0.036), (42, 0.038), (43, -0.075), (44, 0.163), (45, 0.23), (46, -0.04), (47, -0.04), (48, -0.148), (49, -0.065)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.91048539 <a title="186-lsi-1" href="./cvpr-2013-GeoF%3A_Geodesic_Forests_for_Learning_Coupled_Predictors.html">186 cvpr-2013-GeoF: Geodesic Forests for Learning Coupled Predictors</a></p>
<p>Author: Peter Kontschieder, Pushmeet Kohli, Jamie Shotton, Antonio Criminisi</p><p>Abstract: Conventional decision forest based methods for image labelling tasks like object segmentation make predictions for each variable (pixel) independently [3, 5, 8]. This prevents them from enforcing dependencies between variables and translates into locally inconsistent pixel labellings. Random field models, instead, encourage spatial consistency of labels at increased computational expense. This paper presents a new and efficient forest based model that achieves spatially consistent semantic image segmentation by encoding variable dependencies directly in the feature space the forests operate on. Such correlations are captured via new long-range, soft connectivity features, computed via generalized geodesic distance transforms. Our model can be thought of as a generalization of the successful Semantic Texton Forest, Auto-Context, and Entangled Forest models. A second contribution is to show the connection between the typical Conditional Random Field (CRF) energy and the forest training objective. This analysis yields a new objective for training decision forests that encourages more accurate structured prediction. Our GeoF model is validated quantitatively on the task of semantic image segmentation, on four challenging and very diverse image datasets. GeoF outperforms both stateof-the-art forest models and the conventional pairwise CRF.</p><p>2 0.75577259 <a title="186-lsi-2" href="./cvpr-2013-Alternating_Decision_Forests.html">39 cvpr-2013-Alternating Decision Forests</a></p>
<p>Author: Samuel Schulter, Paul Wohlhart, Christian Leistner, Amir Saffari, Peter M. Roth, Horst Bischof</p><p>Abstract: This paper introduces a novel classification method termed Alternating Decision Forests (ADFs), which formulates the training of Random Forests explicitly as a global loss minimization problem. During training, the losses are minimized via keeping an adaptive weight distribution over the training samples, similar to Boosting methods. In order to keep the method as flexible and general as possible, we adopt the principle of employing gradient descent in function space, which allows to minimize arbitrary losses. Contrary to Boosted Trees, in our method the loss minimization is an inherent part of the tree growing process, thus allowing to keep the benefits ofcommon Random Forests, such as, parallel processing. We derive the new classifier and give a discussion and evaluation on standard machine learning data sets. Furthermore, we show how ADFs can be easily integrated into an object detection application. Compared to both, standard Random Forests and Boosted Trees, ADFs give better performance in our experiments, while yielding more compact models in terms of tree depth.</p><p>3 0.73230571 <a title="186-lsi-3" href="./cvpr-2013-Scene_Coordinate_Regression_Forests_for_Camera_Relocalization_in_RGB-D_Images.html">380 cvpr-2013-Scene Coordinate Regression Forests for Camera Relocalization in RGB-D Images</a></p>
<p>Author: Jamie Shotton, Ben Glocker, Christopher Zach, Shahram Izadi, Antonio Criminisi, Andrew Fitzgibbon</p><p>Abstract: We address the problem of inferring the pose of an RGB-D camera relative to a known 3D scene, given only a single acquired image. Our approach employs a regression forest that is capable of inferring an estimate of each pixel’s correspondence to 3D points in the scene ’s world coordinate frame. The forest uses only simple depth and RGB pixel comparison features, and does not require the computation of feature descriptors. The forest is trained to be capable of predicting correspondences at any pixel, so no interest point detectors are required. The camera pose is inferred using a robust optimization scheme. This starts with an initial set of hypothesized camera poses, constructed by applying the forest at a small fraction of image pixels. Preemptive RANSAC then iterates sampling more pixels at which to evaluate the forest, counting inliers, and refining the hypothesized poses. We evaluate on several varied scenes captured with an RGB-D camera and observe that the proposed technique achieves highly accurate relocalization and substantially out-performs two state of the art baselines.</p><p>4 0.49511352 <a title="186-lsi-4" href="./cvpr-2013-Semi-supervised_Node_Splitting_for_Random_Forest_Construction.html">390 cvpr-2013-Semi-supervised Node Splitting for Random Forest Construction</a></p>
<p>Author: Xiao Liu, Mingli Song, Dacheng Tao, Zicheng Liu, Luming Zhang, Chun Chen, Jiajun Bu</p><p>Abstract: Node splitting is an important issue in Random Forest but robust splitting requires a large number of training samples. Existing solutions fail to properly partition the feature space if there are insufficient training data. In this paper, we present semi-supervised splitting to overcome this limitation by splitting nodes with the guidance of both labeled and unlabeled data. In particular, we derive a nonparametric algorithm to obtain an accurate quality measure of splitting by incorporating abundant unlabeled data. To avoid the curse of dimensionality, we project the data points from the original high-dimensional feature space onto a low-dimensional subspace before estimation. A unified optimization framework is proposed to select a coupled pair of subspace and separating hyperplane such that the smoothness of the subspace and the quality of the splitting are guaranteed simultaneously. The proposed algorithm is compared with state-of-the-art supervised and semi-supervised algorithms for typical computer vision applications such as object categorization and image segmen- tation. Experimental results on publicly available datasets demonstrate the superiority of our method.</p><p>5 0.47368851 <a title="186-lsi-5" href="./cvpr-2013-Leveraging_Structure_from_Motion_to_Learn_Discriminative_Codebooks_for_Scalable_Landmark_Classification.html">268 cvpr-2013-Leveraging Structure from Motion to Learn Discriminative Codebooks for Scalable Landmark Classification</a></p>
<p>Author: Alessandro Bergamo, Sudipta N. Sinha, Lorenzo Torresani</p><p>Abstract: In this paper we propose a new technique for learning a discriminative codebook for local feature descriptors, specifically designed for scalable landmark classification. The key contribution lies in exploiting the knowledge of correspondences within sets offeature descriptors during codebook learning. Feature correspondences are obtained using structure from motion (SfM) computation on Internet photo collections which serve as the training data. Our codebook is defined by a random forest that is trained to map corresponding feature descriptors into identical codes. Unlike prior forest-based codebook learning methods, we utilize fine-grained descriptor labels and address the challenge of training a forest with an extremely large number of labels. Our codebook is used with various existing feature encoding schemes and also a variant we propose for importanceweighted aggregation of local features. We evaluate our approach on a public dataset of 25 landmarks and our new dataset of 620 landmarks (614K images). Our approach significantly outperforms the state of the art in landmark classification. Furthermore, our method is memory efficient and scalable.</p><p>6 0.46145311 <a title="186-lsi-6" href="./cvpr-2013-Spatial_Inference_Machines.html">406 cvpr-2013-Spatial Inference Machines</a></p>
<p>7 0.42540991 <a title="186-lsi-7" href="./cvpr-2013-Human_Pose_Estimation_Using_Body_Parts_Dependent_Joint_Regressors.html">206 cvpr-2013-Human Pose Estimation Using Body Parts Dependent Joint Regressors</a></p>
<p>8 0.42108917 <a title="186-lsi-8" href="./cvpr-2013-Fast_Object_Detection_with_Entropy-Driven_Evaluation.html">168 cvpr-2013-Fast Object Detection with Entropy-Driven Evaluation</a></p>
<p>9 0.38119054 <a title="186-lsi-9" href="./cvpr-2013-Analyzing_Semantic_Segmentation_Using_Hybrid_Human-Machine_CRFs.html">43 cvpr-2013-Analyzing Semantic Segmentation Using Hybrid Human-Machine CRFs</a></p>
<p>10 0.38087389 <a title="186-lsi-10" href="./cvpr-2013-Probabilistic_Label_Trees_for_Efficient_Large_Scale_Image_Classification.html">340 cvpr-2013-Probabilistic Label Trees for Efficient Large Scale Image Classification</a></p>
<p>11 0.38074777 <a title="186-lsi-11" href="./cvpr-2013-Unconstrained_Monocular_3D_Human_Pose_Estimation_by_Action_Detection_and_Cross-Modality_Regression_Forest.html">444 cvpr-2013-Unconstrained Monocular 3D Human Pose Estimation by Action Detection and Cross-Modality Regression Forest</a></p>
<p>12 0.37437144 <a title="186-lsi-12" href="./cvpr-2013-Fast_Energy_Minimization_Using_Learned_State_Filters.html">165 cvpr-2013-Fast Energy Minimization Using Learned State Filters</a></p>
<p>13 0.37106898 <a title="186-lsi-13" href="./cvpr-2013-Joint_Geodesic_Upsampling_of_Depth_Images.html">232 cvpr-2013-Joint Geodesic Upsampling of Depth Images</a></p>
<p>14 0.36601615 <a title="186-lsi-14" href="./cvpr-2013-A_Statistical_Model_for_Recreational_Trails_in_Aerial_Images.html">26 cvpr-2013-A Statistical Model for Recreational Trails in Aerial Images</a></p>
<p>15 0.36460355 <a title="186-lsi-15" href="./cvpr-2013-Fully-Connected_CRFs_with_Non-Parametric_Pairwise_Potential.html">180 cvpr-2013-Fully-Connected CRFs with Non-Parametric Pairwise Potential</a></p>
<p>16 0.35930619 <a title="186-lsi-16" href="./cvpr-2013-Computationally_Efficient_Regression_on_a_Dependency_Graph_for_Human_Pose_Estimation.html">89 cvpr-2013-Computationally Efficient Regression on a Dependency Graph for Human Pose Estimation</a></p>
<p>17 0.35790136 <a title="186-lsi-17" href="./cvpr-2013-Real-Time_No-Reference_Image_Quality_Assessment_Based_on_Filter_Learning.html">346 cvpr-2013-Real-Time No-Reference Image Quality Assessment Based on Filter Learning</a></p>
<p>18 0.35712507 <a title="186-lsi-18" href="./cvpr-2013-Segment-Tree_Based_Cost_Aggregation_for_Stereo_Matching.html">384 cvpr-2013-Segment-Tree Based Cost Aggregation for Stereo Matching</a></p>
<p>19 0.33734983 <a title="186-lsi-19" href="./cvpr-2013-Perceptual_Organization_and_Recognition_of_Indoor_Scenes_from_RGB-D_Images.html">329 cvpr-2013-Perceptual Organization and Recognition of Indoor Scenes from RGB-D Images</a></p>
<p>20 0.33600169 <a title="186-lsi-20" href="./cvpr-2013-Lost%21_Leveraging_the_Crowd_for_Probabilistic_Visual_Self-Localization.html">274 cvpr-2013-Lost! Leveraging the Crowd for Probabilistic Visual Self-Localization</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.066), (4, 0.099), (5, 0.12), (37, 0.107), (49, 0.238), (70, 0.015), (81, 0.087), (86, 0.065), (95, 0.025), (97, 0.073)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.8028633 <a title="186-lda-1" href="./cvpr-2013-Dense_Non-rigid_Point-Matching_Using_Random_Projections.html">109 cvpr-2013-Dense Non-rigid Point-Matching Using Random Projections</a></p>
<p>Author: Raffay Hamid, Dennis Decoste, Chih-Jen Lin</p><p>Abstract: We present a robust and efficient technique for matching dense sets of points undergoing non-rigid spatial transformations. Our main intuition is that the subset of points that can be matched with high confidence should be used to guide the matching procedure for the rest. We propose a novel algorithm that incorporates these high-confidence matches as a spatial prior to learn a discriminative subspace that simultaneously encodes both the feature similarity as well as their spatial arrangement. Conventional subspace learning usually requires spectral decomposition of the pair-wise distance matrix across the point-sets, which can become inefficient even for moderately sized problems. To this end, we propose the use of random projections for approximate subspace learning, which can provide significant time improvements at the cost of minimal precision loss. This efficiency gain allows us to iteratively find and remove high-confidence matches from the point sets, resulting in high recall. To show the effectiveness of our approach, we present a systematic set of experiments and results for the problem of dense non-rigid image-feature matching.</p><p>2 0.76188755 <a title="186-lda-2" href="./cvpr-2013-Discriminative_Re-ranking_of_Diverse_Segmentations.html">132 cvpr-2013-Discriminative Re-ranking of Diverse Segmentations</a></p>
<p>Author: Payman Yadollahpour, Dhruv Batra, Gregory Shakhnarovich</p><p>Abstract: This paper introduces a two-stage approach to semantic image segmentation. In the first stage a probabilistic model generates a set of diverse plausible segmentations. In the second stage, a discriminatively trained re-ranking model selects the best segmentation from this set. The re-ranking stage can use much more complex features than what could be tractably used in the probabilistic model, allowing a better exploration of the solution space than possible by simply producing the most probable solution from the probabilistic model. While our proposed approach already achieves state-of-the-art results (48.1%) on the challenging VOC 2012 dataset, our machine and human analyses suggest that even larger gains are possible with such an approach.</p><p>same-paper 3 0.74979156 <a title="186-lda-3" href="./cvpr-2013-GeoF%3A_Geodesic_Forests_for_Learning_Coupled_Predictors.html">186 cvpr-2013-GeoF: Geodesic Forests for Learning Coupled Predictors</a></p>
<p>Author: Peter Kontschieder, Pushmeet Kohli, Jamie Shotton, Antonio Criminisi</p><p>Abstract: Conventional decision forest based methods for image labelling tasks like object segmentation make predictions for each variable (pixel) independently [3, 5, 8]. This prevents them from enforcing dependencies between variables and translates into locally inconsistent pixel labellings. Random field models, instead, encourage spatial consistency of labels at increased computational expense. This paper presents a new and efficient forest based model that achieves spatially consistent semantic image segmentation by encoding variable dependencies directly in the feature space the forests operate on. Such correlations are captured via new long-range, soft connectivity features, computed via generalized geodesic distance transforms. Our model can be thought of as a generalization of the successful Semantic Texton Forest, Auto-Context, and Entangled Forest models. A second contribution is to show the connection between the typical Conditional Random Field (CRF) energy and the forest training objective. This analysis yields a new objective for training decision forests that encourages more accurate structured prediction. Our GeoF model is validated quantitatively on the task of semantic image segmentation, on four challenging and very diverse image datasets. GeoF outperforms both stateof-the-art forest models and the conventional pairwise CRF.</p><p>4 0.69356722 <a title="186-lda-4" href="./cvpr-2013-Cumulative_Attribute_Space_for_Age_and_Crowd_Density_Estimation.html">101 cvpr-2013-Cumulative Attribute Space for Age and Crowd Density Estimation</a></p>
<p>Author: Ke Chen, Shaogang Gong, Tao Xiang, Chen Change Loy</p><p>Abstract: A number of computer vision problems such as human age estimation, crowd density estimation and body/face pose (view angle) estimation can be formulated as a regression problem by learning a mapping function between a high dimensional vector-formed feature input and a scalarvalued output. Such a learning problem is made difficult due to sparse and imbalanced training data and large feature variations caused by both uncertain viewing conditions and intrinsic ambiguities between observable visual features and the scalar values to be estimated. Encouraged by the recent success in using attributes for solving classification problems with sparse training data, this paper introduces a novel cumulative attribute concept for learning a regression model when only sparse and imbalanced data are available. More precisely, low-level visual features extracted from sparse and imbalanced image samples are mapped onto a cumulative attribute space where each dimension has clearly defined semantic interpretation (a label) that captures how the scalar output value (e.g. age, people count) changes continuously and cumulatively. Extensive experiments show that our cumulative attribute framework gains notable advantage on accuracy for both age estimation and crowd counting when compared against conventional regression models, especially when the labelled training data is sparse with imbalanced sampling.</p><p>5 0.68876052 <a title="186-lda-5" href="./cvpr-2013-Crossing_the_Line%3A_Crowd_Counting_by_Integer_Programming_with_Local_Features.html">100 cvpr-2013-Crossing the Line: Crowd Counting by Integer Programming with Local Features</a></p>
<p>Author: Zheng Ma, Antoni B. Chan</p><p>Abstract: We propose an integer programming method for estimating the instantaneous count of pedestrians crossing a line of interest in a video sequence. Through a line sampling process, the video is first converted into a temporal slice image. Next, the number of people is estimated in a set of overlapping sliding windows on the temporal slice image, using a regression function that maps from local features to a count. Given that count in a sliding window is the sum of the instantaneous counts in the corresponding time interval, an integer programming method is proposed to recover the number of pedestrians crossing the line of interest in each frame. Integrating over a specific time interval yields the cumulative count of pedestrian crossing the line. Compared with current methods for line counting, our proposed approach achieves state-of-the-art performance on several challenging crowd video datasets.</p><p>6 0.68689334 <a title="186-lda-6" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<p>7 0.68499005 <a title="186-lda-7" href="./cvpr-2013-Rotation%2C_Scaling_and_Deformation_Invariant_Scattering_for_Texture_Discrimination.html">369 cvpr-2013-Rotation, Scaling and Deformation Invariant Scattering for Texture Discrimination</a></p>
<p>8 0.68364054 <a title="186-lda-8" href="./cvpr-2013-A_Fast_Semidefinite_Approach_to_Solving_Binary_Quadratic_Problems.html">9 cvpr-2013-A Fast Semidefinite Approach to Solving Binary Quadratic Problems</a></p>
<p>9 0.68101704 <a title="186-lda-9" href="./cvpr-2013-Patch_Match_Filter%3A_Efficient_Edge-Aware_Filtering_Meets_Randomized_Search_for_Fast_Correspondence_Field_Estimation.html">326 cvpr-2013-Patch Match Filter: Efficient Edge-Aware Filtering Meets Randomized Search for Fast Correspondence Field Estimation</a></p>
<p>10 0.68081081 <a title="186-lda-10" href="./cvpr-2013-Universality_of_the_Local_Marginal_Polytope.html">448 cvpr-2013-Universality of the Local Marginal Polytope</a></p>
<p>11 0.67991364 <a title="186-lda-11" href="./cvpr-2013-Learning_Separable_Filters.html">255 cvpr-2013-Learning Separable Filters</a></p>
<p>12 0.67943877 <a title="186-lda-12" href="./cvpr-2013-Multi-target_Tracking_by_Rank-1_Tensor_Approximation.html">301 cvpr-2013-Multi-target Tracking by Rank-1 Tensor Approximation</a></p>
<p>13 0.67921829 <a title="186-lda-13" href="./cvpr-2013-Lost%21_Leveraging_the_Crowd_for_Probabilistic_Visual_Self-Localization.html">274 cvpr-2013-Lost! Leveraging the Crowd for Probabilistic Visual Self-Localization</a></p>
<p>14 0.67888534 <a title="186-lda-14" href="./cvpr-2013-Adaptive_Compressed_Tomography_Sensing.html">35 cvpr-2013-Adaptive Compressed Tomography Sensing</a></p>
<p>15 0.67868775 <a title="186-lda-15" href="./cvpr-2013-Fast_Energy_Minimization_Using_Learned_State_Filters.html">165 cvpr-2013-Fast Energy Minimization Using Learned State Filters</a></p>
<p>16 0.67743993 <a title="186-lda-16" href="./cvpr-2013-Deformable_Graph_Matching.html">106 cvpr-2013-Deformable Graph Matching</a></p>
<p>17 0.6771338 <a title="186-lda-17" href="./cvpr-2013-A_New_Model_and_Simple_Algorithms_for_Multi-label_Mumford-Shah_Problems.html">20 cvpr-2013-A New Model and Simple Algorithms for Multi-label Mumford-Shah Problems</a></p>
<p>18 0.67652446 <a title="186-lda-18" href="./cvpr-2013-Recovering_Stereo_Pairs_from_Anaglyphs.html">352 cvpr-2013-Recovering Stereo Pairs from Anaglyphs</a></p>
<p>19 0.67616045 <a title="186-lda-19" href="./cvpr-2013-Towards_Efficient_and_Exact_MAP-Inference_for_Large_Scale_Discrete_Computer_Vision_Problems_via_Combinatorial_Optimization.html">436 cvpr-2013-Towards Efficient and Exact MAP-Inference for Large Scale Discrete Computer Vision Problems via Combinatorial Optimization</a></p>
<p>20 0.67535621 <a title="186-lda-20" href="./cvpr-2013-Whitened_Expectation_Propagation%3A_Non-Lambertian_Shape_from_Shading_and_Shadow.html">466 cvpr-2013-Whitened Expectation Propagation: Non-Lambertian Shape from Shading and Shadow</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
