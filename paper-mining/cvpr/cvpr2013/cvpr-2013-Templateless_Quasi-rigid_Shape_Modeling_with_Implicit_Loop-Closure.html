<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>424 cvpr-2013-Templateless Quasi-rigid Shape Modeling with Implicit Loop-Closure</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-424" href="#">cvpr2013-424</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>424 cvpr-2013-Templateless Quasi-rigid Shape Modeling with Implicit Loop-Closure</h1>
<br/><p>Source: <a title="cvpr-2013-424-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Zeng_Templateless_Quasi-rigid_Shape_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Ming Zeng, Jiaxiang Zheng, Xuan Cheng, Xinguo Liu</p><p>Abstract: This paper presents a method for quasi-rigid objects modeling from a sequence of depth scans captured at different time instances. As quasi-rigid objects, such as human bodies, usually have shape motions during the capture procedure, it is difficult to reconstruct their geometries. We represent the shape motion by a deformation graph, and propose a model-to-partmethod to gradually integrate sampled points of depth scans into the deformation graph. Under an as-rigid-as-possible assumption, the model-to-part method can adjust the deformation graph non-rigidly, so as to avoid error accumulation in alignment, which also implicitly achieves loop-closure. To handle the drift and topological error for the deformation graph, two algorithms are introduced. First, we use a two-stage registration to largely keep the rigid motion part. Second, in the step of graph integration, we topology-adaptively integrate new parts and dynamically control the regularization effect of the deformation graph. We demonstrate the effectiveness and robustness of our method by several depth sequences of quasi-rigid objects, and an application in human shape modeling.</p><p>Reference: <a title="cvpr-2013-424-reference" href="../cvpr2013_reference/cvpr-2013-Templateless_Quasi-rigid_Shape_Modeling_with_Implicit_Loop-Closure_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 We represent the shape motion by a deformation graph, and propose a model-to-partmethod to gradually integrate sampled points of depth scans into the deformation graph. [sent-3, score-1.293]
</p><p>2 Under an as-rigid-as-possible assumption, the model-to-part method can adjust the deformation graph non-rigidly, so as to avoid error accumulation in alignment, which also implicitly achieves loop-closure. [sent-4, score-0.557]
</p><p>3 To handle the drift and topological error for the deformation graph, two algorithms are introduced. [sent-5, score-0.371]
</p><p>4 First, we use a two-stage registration to largely keep the rigid motion part. [sent-6, score-0.677]
</p><p>5 Second, in the step of graph integration, we topology-adaptively integrate new parts and dynamically control the regularization effect of the deformation graph. [sent-7, score-0.613]
</p><p>6 With the recent developments of stereoscopic vision and depth acquisition devices, it is becoming easy to obtain the 3D models using images or depth scans captured simultaneously from different views (e. [sent-11, score-0.656]
</p><p>7 The quasi-rigid object exhibits slight deformation, which can not be reconstructed in a rigid registration fashion. [sent-29, score-0.714]
</p><p>8 In this paper, we address the deformable shape completion problem of nearly rigid objects, called quasi-rigid objects. [sent-47, score-0.397]
</p><p>9 Specifically, we maintain a deformation graph as the representation of the object and develop an incremental integration method to update the graph. [sent-50, score-0.598]
</p><p>10 For each depth scan, the graph is registered to it using a model-to-part method. [sent-51, score-0.266]
</p><p>11 The model-to-part method with the non-rigid deformation 111444555  model is flexible enough to gradually adjust the graph to fit the new depth scans, and is able to achieve results with loopclosure property. [sent-52, score-0.631]
</p><p>12 After registration, the depth scans are resampled and integrated into the deformation graph. [sent-53, score-0.907]
</p><p>13 The integration takes care of the topology, and provides topologyadaptive information for regularization on the registration step of succeeding scans. [sent-54, score-0.727]
</p><p>14 After integrating all depth scans, a global nonrigid warping is adopted to warp the points to their destination positions in the last frame. [sent-55, score-0.268]
</p><p>15 are several technical contributions: •  •  •  There  First, we propose a model-to-part registration scheme fFoirrs non-rigid pdoesfeo arm matoiodne,l wtoh-picahr td riesgtrisibturatetios tnh sec accumulated error in each registration step, and avoids explicit steps for error distribution. [sent-58, score-0.82]
</p><p>16 Second, we introduce a two-stage registration method tSoe cmoankde, wthee rinegtriosdtruatcieon a step rsotabguest r etog geometry tertahcokding. [sent-59, score-0.41]
</p><p>17 Third, we propose a topology-adaptive integration and a hreirldax,e wde regularization floorg graph update, wrahtiiocnh iamndprove the robustness of our method. [sent-60, score-0.331]
</p><p>18 To obtain the whole 3D model of a static object, scans of different views should be aligned together in a common coordinate by rigid transformations. [sent-63, score-0.608]
</p><p>19 Iterative closest point (ICP) [2, 6, 18] first sets up some point correspondences by nearest neighbor criterion, and then get a rigid transformation by minimizing the distances of the corresponding point pairs. [sent-64, score-0.363]
</p><p>20 The rigid registration is unable to deal with non-rigid shape. [sent-66, score-0.673]
</p><p>21 For deformable shapes, more degree of freedom is required to represent the deformation of shapes. [sent-68, score-0.458]
</p><p>22 Based on the embedded deformation introduced  by Sumner et al. [sent-69, score-0.371]
</p><p>23 [12] combined the correspondence optimization with deformation optimization together, and improved the robustness of registration. [sent-71, score-0.407]
</p><p>24 Based on the same deformation model, Huang et al. [sent-72, score-0.371]
</p><p>25 [8] studied the problem under isometric deformation, and argued that keeping low but necessary deformation freedom will improve the registration reliability. [sent-73, score-0.858]
</p><p>26 With the similar principle to reduce deformation freedom, Chang and his colleagues introduced an articulated model [3] and a linear blend skinning model [4] for the nonrigid registration. [sent-74, score-0.505]
</p><p>27 These pairwise registration methods are necessary building blocks for full shape reconstruction. [sent-75, score-0.457]
</p><p>28 The shape completion problem requires merging scans from different views to reconstruct the whole shape. [sent-77, score-0.521]
</p><p>29 [24] track the scans of slightly moving human, and impose an explicit global alignment to distribute the accumulated alignment errors. [sent-84, score-0.511]
</p><p>30 These methods optimize the registration problem in a small window of multiple frames to avoid an additional error distribution step. [sent-92, score-0.41]
</p><p>31 Chang and Zwicker [5] restrict the moving shape to be articulated, and solve a joint labeling/deformation problem with the reduced deformation model. [sent-93, score-0.418]
</p><p>32 They take little care about how to match the first and the last scans together, i. [sent-101, score-0.386]
</p><p>33 The incremental integration method may incur error accumulation in the rigid case, but the scheme works well in the nonrigid case thanks to the adjustability of the pre-integrated models. [sent-105, score-0.492]
</p><p>34 In our paper, we study the model-topart method further than [11] by incorporating the topology information obtained from the integration step into succeeding registration step, which adaptively control the flexibility of the integrated model. [sent-107, score-0.71]
</p><p>35 The input is a sequence of depth scans of a quasi-rigid object captured from different views at different time instances. [sent-111, score-0.539]
</p><p>36 [20] to represent space deformation by a deformation graph, where each node is a sample point of the object. [sent-113, score-0.742]
</p><p>37 When a scan comes, the deformation graph is non-rigidly registered to it, and then the new part in this new scan is re-sampled and integrated into the deformation graph. [sent-114, score-1.392]
</p><p>38 Then the topology ofthis 111444666  of the deformation graph. [sent-115, score-0.425]
</p><p>39 After integration of these depth scans, a global non-rigid warping is conducted on each scan according to the deformation records of this graph. [sent-116, score-0.911]
</p><p>40 The registration and the integration/update procedures repeat until the end of the sequence. [sent-119, score-0.41]
</p><p>41 After all depth scans are processed, the deformation graph records the whole deforming/dynamic behaviors of the scanned object. [sent-120, score-0.939]
</p><p>42 Using this dynamic information, all depth scans are aligned into one global coordinate, and are registered together compensating slight deformation. [sent-121, score-0.611]
</p><p>43 In the rest ofthis paper, we will first introduce the model-  to-part registration in Section 4, deformation graph integration and update in Section 5, then we present the implementation details and the experimental results in Section 6, and conclude this paper in Section 7. [sent-123, score-1.008]
</p><p>44 Model-to-Part Registration In the rigid alignment scenario, there is inevitable accumulation error without a global registration [17, 19]. [sent-125, score-0.777]
</p><p>45 A model-to-part scheme [22] incrementally aligns a new scan into a integration model, which improves the alignment of the new scans, but it is unable to adjust the integrated model. [sent-126, score-0.553]
</p><p>46 Inspired by KinectFusion, we take a similar model-to-part way in our quasi-rigid registration case. [sent-130, score-0.41]
</p><p>47 3, the relatively flexible way inherently keeps loop-closure by adjusting the “head” and the “tail” of integration model to match the last scan together. [sent-133, score-0.342]
</p><p>48 For the moving object, the motion can be divided into two parts[12]: global rigid transformation Φglobal and local non-rigid deformation Φlocal. [sent-134, score-0.693]
</p><p>49 The global rigid transformation is caused by camera movement or the object’s  ×  Figure3. [sent-135, score-0.322]
</p><p>50 The red is ground truth, the green is deformation graph, and the dark blue is a depth scan. [sent-137, score-0.488]
</p><p>51 right: model-to-part registration adjusts the deformation graph asrigid-as-possible, which exhibits loop-closure implicitly. [sent-140, score-0.914]
</p><p>52 The local non-rigid deformation comes from slight articulated motion or the small-scale deformation therein (such as folds in the cloth). [sent-142, score-0.896]
</p><p>53 Two-Stage Registration Let Gt denotes the deformation graph at frame t, and |Gt | denotes the number of the nodes in Gt. [sent-160, score-0.599]
</p><p>54 To register |GGt |w ditehn a new scan mDbte+r1, o we efin ndo tdhees b inest G transformation Φ = Φlocal ◦ Φglobal that transforms Gt to fit Dt+1. [sent-161, score-0.272]
</p><p>55 The second rigid term constrains the transformation matrix Hi to be rotational: |? [sent-172, score-0.277]
</p><p>56 N(i)  (8)  Since Φglobal accounts for most of the motion for the quasi-rigid object, we treat the rigid part and the non-rigid part separately, yielding a two-stage registration approach. [sent-184, score-0.631]
</p><p>57 Rigid Registration Stage: We use the ICP method to estimate rigid transformation between Gt and Dt+1. [sent-188, score-0.277]
</p><p>58 bottom left: the subset correspondences (green) masks the outdated nodes (grey), leading to expected alignment (bottom right). [sent-192, score-0.334]
</p><p>59 As the scans are integrated into the deformation graph, nodes added in the very beginning of the integration procedure do not overlap with the new scan. [sent-199, score-1.043]
</p><p>60 These outdated nodes will disturb the registration due to introducing wrong correspondences. [sent-200, score-0.669]
</p><p>61 At the start of the registration of a new scan, we only use the active nodes while mask the outdated nodes in the rigid registration. [sent-203, score-0.948]
</p><p>62 4, the scheme improves the robustness of the rigid registration, especially for the graph having integrated lots of scans. [sent-205, score-0.391]
</p><p>63 Non-Rigid Registration Stage: Given the rigid transformation Rt and Tt from rigid registration stage, we optimize the Eq. [sent-206, score-0.908]
</p><p>64 5 to obtain the local transformations for each node in the deformation graph. [sent-207, score-0.371]
</p><p>65 Like rigid registration, we adopt point-to-point and point-to-plane metrics together in Efit, which ensures the non-rigid registration flexible enough to globally “slide” on the target scan. [sent-208, score-0.631]
</p><p>66 In the quasi-rigid case, the object’s non-rigid deformation is small, while the deformation graph contains too many nodes to represent the small deformation. [sent-211, score-0.97]
</p><p>67 First, we set a large weight wreg to keep the deformation as-rigid-as-possible. [sent-213, score-0.468]
</p><p>68 Second, to prevent the defor-  102,  mation graph from collapsing together, we take a bijective closest correspondence instead of source-to-target closest correspondence. [sent-224, score-0.298]
</p><p>69 Specifically, for a node si with normal ni belonging to the set of graph nodes S, suppose its nearest point on a depth scan is pi∗ with normal ni∗, we find the id of pi∗ ’s nearest normal-compatible point Near(pi∗) from S: Near(pi∗) =  argh  min ||pi∗  − sh||22,  s. [sent-225, score-0.561]
</p><p>70 Relaxed Regularization for Re-appearing Parts After new sample points are added into the deformation graph, the nodes’ nearest neighbors are recomputed and their edges are rebuilt. [sent-231, score-0.371]
</p><p>71 Middle: the shape suddenly re-appears, and there are a large gap between the current scan (dark blue) and the previous scan (red), the relaxed regularization sets weak influences between them (green dash line). [sent-235, score-0.711]
</p><p>72 Right: the relaxed regularization allows these two part move apart when the graph are registered to new scans which have large overlapping regions between both red and dark blue parts. [sent-236, score-0.693]
</p><p>73 In the latter case, the re-appearing parts are prone to mismatch the previous scans due to little overlapping area between them. [sent-237, score-0.35]
</p><p>74 Since these two parts belong to the same articulated component and should move together, it is reasonable to link the nodes from these two parts with edges for  the registration regularization Ereg. [sent-238, score-0.705]
</p><p>75 Based on the consideration, we relax the regularization between position-near but normalincompatible nodes by introducing a relaxed regularization controller. [sent-242, score-0.425]
</p><p>76 Mathematically, for two sample nodes sti and stj, the relaxed regularization controller cir,ejg between them is defined:  cir,ejg=? [sent-243, score-0.504]
</p><p>77 For synthetic data, we generate depth scans by a virtual camera. [sent-257, score-0.467]
</p><p>78 In all the experiments, the rigid registration converges within 50 iterations and the non-rigid registration converges within 10 iterations, which costs about 40∼60 seconds for a frame. [sent-260, score-1.041]
</p><p>79 Evaluation of Proposed Techniques In this subsection we show the effectiveness of our bijective correspondence and relaxed regularization by without/with comparison, respectively. [sent-267, score-0.357]
</p><p>80 Without the bijective consistence, the graph nodes on the foot shrink to the joints (Fig. [sent-271, score-0.355]
</p><p>81 8 shows that the nonrelaxed regularization is unable to adjust the poorly integrated graph to correct position (Fig. [sent-277, score-0.358]
</p><p>82 The nodes on opposite side of the new scan are also “dragged” severely  (a) (b)  Figure 7. [sent-279, score-0.343]
</p><p>83 Comparison between non-relaxed regularization (a) and relaxed regularization (b). [sent-282, score-0.298]
</p><p>84 While our relaxed regularization is more topology-adaptive to deform the graph (Fig. [sent-284, score-0.295]
</p><p>85 The hand-held rotation inevitably incurs deformation on the objects. [sent-289, score-0.371]
</p><p>86 In this figure, the first rows are our results, and the second rows are results with rigid global registration[17]. [sent-292, score-0.266]
</p><p>87 Comparison between our method and global rigid registration on the (a) puppet and (b) pillow. [sent-295, score-0.727]
</p><p>88 75m height) with slight but substantial deformation (generated using MAYA). [sent-299, score-0.422]
</p><p>89 From this experiment, we show (1) Our result approximates the ground truth globally; (2) Both global rigid registration and KinectFusion are unable to compensate the obvious nonrigid deformation. [sent-313, score-0.788]
</p><p>90 (a) Snapshots of partial scans, (b) ground truth, (c) our result, (d) global rigid registration, (e) KinectFusion. [sent-315, score-0.266]
</p><p>91 To scan a human body, the human is asked to rotate by himself in front of the system, and try to keep his pose. [sent-322, score-0.332]
</p><p>92 Conclusion We have presented a general method for quasi-rigid shape modeling using depth scans captured at different  time instances. [sent-331, score-0.549]
</p><p>93 Without the template, we gradually integrate depth scans into our pipeline and finally obtain a deformation graph representing the whole shape. [sent-333, score-1.013]
</p><p>94 First is our model-to-part scheme to register the deformation graph to match the new scans. [sent-335, score-0.472]
</p><p>95 To keep the registration robust, we adopt a two-stage registration under the assumption of the as-rigid-as-possible. [sent-336, score-0.866]
</p><p>96 Second, we handle several topology issues raised with the integration of depth scans. [sent-337, score-0.297]
</p><p>97 Global registration of dynamic range scans for articulated model reconstruction. [sent-384, score-0.824]
</p><p>98 Global correspondence optimization for non-rigid registration of depth scans. [sent-459, score-0.563]
</p><p>99 Multiview registration of 3d scenes by minimizing error between coordinate frames. [sent-524, score-0.41]
</p><p>100 Home 3d body scans from noisy image and range data. [sent-616, score-0.39]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('registration', 0.41), ('deformation', 0.371), ('scans', 0.35), ('rigid', 0.221), ('scan', 0.216), ('sti', 0.132), ('efit', 0.128), ('stj', 0.128), ('nodes', 0.127), ('bijective', 0.127), ('integration', 0.126), ('depth', 0.117), ('regularization', 0.104), ('graph', 0.101), ('sumner', 0.099), ('kinectfusion', 0.093), ('relaxed', 0.09), ('completion', 0.087), ('correspondences', 0.086), ('ereg', 0.079), ('gt', 0.071), ('nonrigid', 0.07), ('integrated', 0.069), ('wrong', 0.069), ('scape', 0.068), ('articulated', 0.064), ('consistence', 0.063), ('outdated', 0.063), ('poisson', 0.063), ('alignment', 0.058), ('forum', 0.057), ('transformation', 0.056), ('topology', 0.054), ('wj', 0.052), ('slight', 0.051), ('controller', 0.051), ('erigid', 0.051), ('hti', 0.051), ('ltj', 0.051), ('puppet', 0.051), ('succeeding', 0.051), ('wreg', 0.051), ('dit', 0.051), ('guibas', 0.051), ('adams', 0.049), ('wand', 0.049), ('sj', 0.049), ('registered', 0.048), ('shape', 0.047), ('rusinkiewicz', 0.047), ('keep', 0.046), ('bodies', 0.046), ('vlasic', 0.045), ('singleview', 0.045), ('berner', 0.045), ('tevs', 0.045), ('dragged', 0.045), ('freedom', 0.045), ('global', 0.045), ('accumulation', 0.043), ('deformable', 0.042), ('kinects', 0.042), ('dti', 0.042), ('confine', 0.042), ('lti', 0.042), ('adjust', 0.042), ('unable', 0.042), ('template', 0.041), ('icp', 0.04), ('body', 0.04), ('rot', 0.04), ('bokeloh', 0.04), ('ovsjanikov', 0.04), ('folds', 0.039), ('suddenly', 0.038), ('integrate', 0.037), ('pipeline', 0.037), ('views', 0.037), ('popovi', 0.036), ('peers', 0.036), ('failing', 0.036), ('correspondence', 0.036), ('care', 0.036), ('chang', 0.036), ('warping', 0.036), ('human', 0.035), ('incompatible', 0.035), ('captured', 0.035), ('pi', 0.034), ('mation', 0.034), ('seidel', 0.033), ('gather', 0.033), ('liao', 0.033), ('sgp', 0.033), ('acm', 0.032), ('exhibits', 0.032), ('isometric', 0.032), ('thanks', 0.032), ('tt', 0.031), ('animation', 0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.000001 <a title="424-tfidf-1" href="./cvpr-2013-Templateless_Quasi-rigid_Shape_Modeling_with_Implicit_Loop-Closure.html">424 cvpr-2013-Templateless Quasi-rigid Shape Modeling with Implicit Loop-Closure</a></p>
<p>Author: Ming Zeng, Jiaxiang Zheng, Xuan Cheng, Xinguo Liu</p><p>Abstract: This paper presents a method for quasi-rigid objects modeling from a sequence of depth scans captured at different time instances. As quasi-rigid objects, such as human bodies, usually have shape motions during the capture procedure, it is difficult to reconstruct their geometries. We represent the shape motion by a deformation graph, and propose a model-to-partmethod to gradually integrate sampled points of depth scans into the deformation graph. Under an as-rigid-as-possible assumption, the model-to-part method can adjust the deformation graph non-rigidly, so as to avoid error accumulation in alignment, which also implicitly achieves loop-closure. To handle the drift and topological error for the deformation graph, two algorithms are introduced. First, we use a two-stage registration to largely keep the rigid motion part. Second, in the step of graph integration, we topology-adaptively integrate new parts and dynamically control the regularization effect of the deformation graph. We demonstrate the effectiveness and robustness of our method by several depth sequences of quasi-rigid objects, and an application in human shape modeling.</p><p>2 0.29877299 <a title="424-tfidf-2" href="./cvpr-2013-Robust_Estimation_of_Nonrigid_Transformation_for_Point_Set_Registration.html">360 cvpr-2013-Robust Estimation of Nonrigid Transformation for Point Set Registration</a></p>
<p>Author: Jiayi Ma, Ji Zhao, Jinwen Tian, Zhuowen Tu, Alan L. Yuille</p><p>Abstract: We present a new point matching algorithm for robust nonrigid registration. The method iteratively recovers the point correspondence and estimates the transformation between two point sets. In the first step of the iteration, feature descriptors such as shape context are used to establish rough correspondence. In the second step, we estimate the transformation using a robust estimator called L2E. This is the main novelty of our approach and it enables us to deal with the noise and outliers which arise in the correspondence step. The transformation is specified in a functional space, more specifically a reproducing kernel Hilbert space. We apply our method to nonrigid sparse image feature correspondence on 2D images and 3D surfaces. Our results quantitatively show that our approach outperforms state-ofthe-art methods, particularly when there are a large number of outliers. Moreover, our method of robustly estimating transformations from correspondences is general and has many other applications.</p><p>3 0.18589057 <a title="424-tfidf-3" href="./cvpr-2013-Groupwise_Registration_via_Graph_Shrinkage_on_the_Image_Manifold.html">194 cvpr-2013-Groupwise Registration via Graph Shrinkage on the Image Manifold</a></p>
<p>Author: Shihui Ying, Guorong Wu, Qian Wang, Dinggang Shen</p><p>Abstract: Recently, groupwise registration has been investigated for simultaneous alignment of all images without selecting any individual image as the template, thus avoiding the potential bias in image registration. However, none of current groupwise registration method fully utilizes the image distribution to guide the registration. Thus, the registration performance usually suffers from large inter-subject variations across individual images. To solve this issue, we propose a novel groupwise registration algorithm for large population dataset, guided by the image distribution on the manifold. Specifically, we first use a graph to model the distribution of all image data sitting on the image manifold, with each node representing an image and each edge representing the geodesic pathway between two nodes (or images). Then, the procedure of warping all images to theirpopulation center turns to the dynamic shrinking ofthe graph nodes along their graph edges until all graph nodes become close to each other. Thus, the topology ofimage distribution on the image manifold is always preserved during the groupwise registration. More importantly, by modeling , the distribution of all images via a graph, we can potentially reduce registration error since every time each image is warped only according to its nearby images with similar structures in the graph. We have evaluated our proposed groupwise registration method on both synthetic and real datasets, with comparison to the two state-of-the-art groupwise registration methods. All experimental results show that our proposed method achieves the best performance in terms of registration accuracy and robustness.</p><p>4 0.17210639 <a title="424-tfidf-4" href="./cvpr-2013-Tensor-Based_Human_Body_Modeling.html">426 cvpr-2013-Tensor-Based Human Body Modeling</a></p>
<p>Author: Yinpeng Chen, Zicheng Liu, Zhengyou Zhang</p><p>Abstract: In this paper, we present a novel approach to model 3D human body with variations on both human shape and pose, by exploring a tensor decomposition technique. 3D human body modeling is important for 3D reconstruction and animation of realistic human body, which can be widely used in Tele-presence and video game applications. It is challenging due to a wide range of shape variations over different people and poses. The existing SCAPE model [4] is popular in computer vision for modeling 3D human body. However, it considers shape and pose deformations separately, which is not accurate since pose deformation is persondependent. Our tensor-based model addresses this issue by jointly modeling shape and pose deformations. Experimental results demonstrate that our tensor-based model outperforms the SCAPE model quite significantly. We also apply our model to capture human body using Microsoft Kinect sensors with excellent results.</p><p>5 0.1712435 <a title="424-tfidf-5" href="./cvpr-2013-Correspondence-Less_Non-rigid_Registration_of_Triangular_Surface_Meshes.html">97 cvpr-2013-Correspondence-Less Non-rigid Registration of Triangular Surface Meshes</a></p>
<p>Author: Zsolt Sánta, Zoltan Kato</p><p>Abstract: A novel correspondence-less approach is proposed to find a thin plate spline map between a pair of deformable 3D objects represented by triangular surface meshes. The proposed method works without landmark extraction and feature correspondences. The aligning transformation is found simply by solving a system of nonlinear equations. Each equation is generated by integrating a nonlinear function over the object’s domains. We derive recursive formulas for the efficient computation of these integrals. Based on a series of comparative tests on a large synthetic dataset, our triangular mesh-based algorithm outperforms state of the art methods both in terms of computing time and accuracy. The applicability of the proposed approach has been demonstrated on the registration of 3D lung CT volumes.</p><p>6 0.14439221 <a title="424-tfidf-6" href="./cvpr-2013-Accurate_and_Robust_Registration_of_Nonrigid_Surface_Using_Hierarchical_Statistical_Shape_Model.html">31 cvpr-2013-Accurate and Robust Registration of Nonrigid Surface Using Hierarchical Statistical Shape Model</a></p>
<p>7 0.13412878 <a title="424-tfidf-7" href="./cvpr-2013-Top-Down_Segmentation_of_Non-rigid_Visual_Objects_Using_Derivative-Based_Search_on_Sparse_Manifolds.html">433 cvpr-2013-Top-Down Segmentation of Non-rigid Visual Objects Using Derivative-Based Search on Sparse Manifolds</a></p>
<p>8 0.12980618 <a title="424-tfidf-8" href="./cvpr-2013-Layer_Depth_Denoising_and_Completion_for_Structured-Light_RGB-D_Cameras.html">245 cvpr-2013-Layer Depth Denoising and Completion for Structured-Light RGB-D Cameras</a></p>
<p>9 0.12569791 <a title="424-tfidf-9" href="./cvpr-2013-Template-Based_Isometric_Deformable_3D_Reconstruction_with_Sampling-Based_Focal_Length_Self-Calibration.html">423 cvpr-2013-Template-Based Isometric Deformable 3D Reconstruction with Sampling-Based Focal Length Self-Calibration</a></p>
<p>10 0.11220442 <a title="424-tfidf-10" href="./cvpr-2013-Dense_Variational_Reconstruction_of_Non-rigid_Surfaces_from_Monocular_Video.html">113 cvpr-2013-Dense Variational Reconstruction of Non-rigid Surfaces from Monocular Video</a></p>
<p>11 0.10903331 <a title="424-tfidf-11" href="./cvpr-2013-Depth_Super_Resolution_by_Rigid_Body_Self-Similarity_in_3D.html">115 cvpr-2013-Depth Super Resolution by Rigid Body Self-Similarity in 3D</a></p>
<p>12 0.10840023 <a title="424-tfidf-12" href="./cvpr-2013-Optimal_Geometric_Fitting_under_the_Truncated_L2-Norm.html">317 cvpr-2013-Optimal Geometric Fitting under the Truncated L2-Norm</a></p>
<p>13 0.10649253 <a title="424-tfidf-13" href="./cvpr-2013-FrameBreak%3A_Dramatic_Image_Extrapolation_by_Guided_Shift-Maps.html">177 cvpr-2013-FrameBreak: Dramatic Image Extrapolation by Guided Shift-Maps</a></p>
<p>14 0.10564427 <a title="424-tfidf-14" href="./cvpr-2013-Hyperbolic_Harmonic_Mapping_for_Constrained_Brain_Surface_Registration.html">208 cvpr-2013-Hyperbolic Harmonic Mapping for Constrained Brain Surface Registration</a></p>
<p>15 0.10309478 <a title="424-tfidf-15" href="./cvpr-2013-Articulated_and_Restricted_Motion_Subspaces_and_Their_Signatures.html">46 cvpr-2013-Articulated and Restricted Motion Subspaces and Their Signatures</a></p>
<p>16 0.10167915 <a title="424-tfidf-16" href="./cvpr-2013-Simultaneous_Super-Resolution_of_Depth_and_Images_Using_a_Single_Camera.html">397 cvpr-2013-Simultaneous Super-Resolution of Depth and Images Using a Single Camera</a></p>
<p>17 0.096387133 <a title="424-tfidf-17" href="./cvpr-2013-Non-rigid_Structure_from_Motion_with_Diffusion_Maps_Prior.html">306 cvpr-2013-Non-rigid Structure from Motion with Diffusion Maps Prior</a></p>
<p>18 0.095565289 <a title="424-tfidf-18" href="./cvpr-2013-Detecting_Changes_in_3D_Structure_of_a_Scene_from_Multi-view_Images_Captured_by_a_Vehicle-Mounted_Camera.html">117 cvpr-2013-Detecting Changes in 3D Structure of a Scene from Multi-view Images Captured by a Vehicle-Mounted Camera</a></p>
<p>19 0.094648644 <a title="424-tfidf-19" href="./cvpr-2013-Monocular_Template-Based_3D_Reconstruction_of_Extensible_Surfaces_with_Local_Linear_Elasticity.html">289 cvpr-2013-Monocular Template-Based 3D Reconstruction of Extensible Surfaces with Local Linear Elasticity</a></p>
<p>20 0.092659935 <a title="424-tfidf-20" href="./cvpr-2013-Multi-resolution_Shape_Analysis_via_Non-Euclidean_Wavelets%3A_Applications_to_Mesh_Segmentation_and_Surface_Alignment_Problems.html">297 cvpr-2013-Multi-resolution Shape Analysis via Non-Euclidean Wavelets: Applications to Mesh Segmentation and Surface Alignment Problems</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.191), (1, 0.148), (2, 0.017), (3, 0.021), (4, 0.008), (5, -0.062), (6, -0.003), (7, -0.002), (8, 0.012), (9, -0.057), (10, 0.027), (11, 0.115), (12, -0.113), (13, 0.0), (14, 0.086), (15, -0.198), (16, -0.063), (17, 0.081), (18, 0.031), (19, 0.027), (20, -0.134), (21, -0.043), (22, 0.02), (23, -0.026), (24, -0.01), (25, -0.021), (26, -0.041), (27, 0.007), (28, 0.097), (29, 0.087), (30, 0.011), (31, -0.065), (32, 0.012), (33, -0.056), (34, 0.158), (35, -0.117), (36, -0.193), (37, 0.045), (38, -0.013), (39, 0.023), (40, -0.004), (41, -0.004), (42, -0.036), (43, -0.008), (44, -0.013), (45, -0.08), (46, -0.127), (47, -0.051), (48, 0.02), (49, -0.038)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96731031 <a title="424-lsi-1" href="./cvpr-2013-Templateless_Quasi-rigid_Shape_Modeling_with_Implicit_Loop-Closure.html">424 cvpr-2013-Templateless Quasi-rigid Shape Modeling with Implicit Loop-Closure</a></p>
<p>Author: Ming Zeng, Jiaxiang Zheng, Xuan Cheng, Xinguo Liu</p><p>Abstract: This paper presents a method for quasi-rigid objects modeling from a sequence of depth scans captured at different time instances. As quasi-rigid objects, such as human bodies, usually have shape motions during the capture procedure, it is difficult to reconstruct their geometries. We represent the shape motion by a deformation graph, and propose a model-to-partmethod to gradually integrate sampled points of depth scans into the deformation graph. Under an as-rigid-as-possible assumption, the model-to-part method can adjust the deformation graph non-rigidly, so as to avoid error accumulation in alignment, which also implicitly achieves loop-closure. To handle the drift and topological error for the deformation graph, two algorithms are introduced. First, we use a two-stage registration to largely keep the rigid motion part. Second, in the step of graph integration, we topology-adaptively integrate new parts and dynamically control the regularization effect of the deformation graph. We demonstrate the effectiveness and robustness of our method by several depth sequences of quasi-rigid objects, and an application in human shape modeling.</p><p>2 0.81986499 <a title="424-lsi-2" href="./cvpr-2013-Groupwise_Registration_via_Graph_Shrinkage_on_the_Image_Manifold.html">194 cvpr-2013-Groupwise Registration via Graph Shrinkage on the Image Manifold</a></p>
<p>Author: Shihui Ying, Guorong Wu, Qian Wang, Dinggang Shen</p><p>Abstract: Recently, groupwise registration has been investigated for simultaneous alignment of all images without selecting any individual image as the template, thus avoiding the potential bias in image registration. However, none of current groupwise registration method fully utilizes the image distribution to guide the registration. Thus, the registration performance usually suffers from large inter-subject variations across individual images. To solve this issue, we propose a novel groupwise registration algorithm for large population dataset, guided by the image distribution on the manifold. Specifically, we first use a graph to model the distribution of all image data sitting on the image manifold, with each node representing an image and each edge representing the geodesic pathway between two nodes (or images). Then, the procedure of warping all images to theirpopulation center turns to the dynamic shrinking ofthe graph nodes along their graph edges until all graph nodes become close to each other. Thus, the topology ofimage distribution on the image manifold is always preserved during the groupwise registration. More importantly, by modeling , the distribution of all images via a graph, we can potentially reduce registration error since every time each image is warped only according to its nearby images with similar structures in the graph. We have evaluated our proposed groupwise registration method on both synthetic and real datasets, with comparison to the two state-of-the-art groupwise registration methods. All experimental results show that our proposed method achieves the best performance in terms of registration accuracy and robustness.</p><p>3 0.78141415 <a title="424-lsi-3" href="./cvpr-2013-Robust_Estimation_of_Nonrigid_Transformation_for_Point_Set_Registration.html">360 cvpr-2013-Robust Estimation of Nonrigid Transformation for Point Set Registration</a></p>
<p>Author: Jiayi Ma, Ji Zhao, Jinwen Tian, Zhuowen Tu, Alan L. Yuille</p><p>Abstract: We present a new point matching algorithm for robust nonrigid registration. The method iteratively recovers the point correspondence and estimates the transformation between two point sets. In the first step of the iteration, feature descriptors such as shape context are used to establish rough correspondence. In the second step, we estimate the transformation using a robust estimator called L2E. This is the main novelty of our approach and it enables us to deal with the noise and outliers which arise in the correspondence step. The transformation is specified in a functional space, more specifically a reproducing kernel Hilbert space. We apply our method to nonrigid sparse image feature correspondence on 2D images and 3D surfaces. Our results quantitatively show that our approach outperforms state-ofthe-art methods, particularly when there are a large number of outliers. Moreover, our method of robustly estimating transformations from correspondences is general and has many other applications.</p><p>4 0.71884114 <a title="424-lsi-4" href="./cvpr-2013-Correspondence-Less_Non-rigid_Registration_of_Triangular_Surface_Meshes.html">97 cvpr-2013-Correspondence-Less Non-rigid Registration of Triangular Surface Meshes</a></p>
<p>Author: Zsolt Sánta, Zoltan Kato</p><p>Abstract: A novel correspondence-less approach is proposed to find a thin plate spline map between a pair of deformable 3D objects represented by triangular surface meshes. The proposed method works without landmark extraction and feature correspondences. The aligning transformation is found simply by solving a system of nonlinear equations. Each equation is generated by integrating a nonlinear function over the object’s domains. We derive recursive formulas for the efficient computation of these integrals. Based on a series of comparative tests on a large synthetic dataset, our triangular mesh-based algorithm outperforms state of the art methods both in terms of computing time and accuracy. The applicability of the proposed approach has been demonstrated on the registration of 3D lung CT volumes.</p><p>5 0.68742412 <a title="424-lsi-5" href="./cvpr-2013-Accurate_and_Robust_Registration_of_Nonrigid_Surface_Using_Hierarchical_Statistical_Shape_Model.html">31 cvpr-2013-Accurate and Robust Registration of Nonrigid Surface Using Hierarchical Statistical Shape Model</a></p>
<p>Author: Hidekata Hontani, Yuto Tsunekawa, Yoshihide Sawada</p><p>Abstract: In this paper, we propose a new non-rigid robust registration method that registers a point distribution model (PDM) of a surface to given 3D images. The contributions of the paper are (1) a new hierarchical statistical shape model (SSM) of the surface that has better generalization ability is introduced, (2) the registration algorithm of the hierarchical SSM that can estimate the marginal posterior distribution of the surface location is proposed, and (3) the registration performance is improved by (3-1) robustly registering each local shape of the surface with the sparsity regularization and by (3-2) referring to the appearance between the neighboring model points in the likelihood computation. The SSM of a liver was constructed from a set of clinical CT images, and the performance of the proposed method was evaluated. Experimental results demonstrated that the proposed method outperformed some existing methods that use non-hierarchical SSMs.</p><p>6 0.65574831 <a title="424-lsi-6" href="./cvpr-2013-As-Projective-As-Possible_Image_Stitching_with_Moving_DLT.html">47 cvpr-2013-As-Projective-As-Possible Image Stitching with Moving DLT</a></p>
<p>7 0.65232569 <a title="424-lsi-7" href="./cvpr-2013-FasT-Match%3A_Fast_Affine_Template_Matching.html">162 cvpr-2013-FasT-Match: Fast Affine Template Matching</a></p>
<p>8 0.60587466 <a title="424-lsi-8" href="./cvpr-2013-FrameBreak%3A_Dramatic_Image_Extrapolation_by_Guided_Shift-Maps.html">177 cvpr-2013-FrameBreak: Dramatic Image Extrapolation by Guided Shift-Maps</a></p>
<p>9 0.57684678 <a title="424-lsi-9" href="./cvpr-2013-Hyperbolic_Harmonic_Mapping_for_Constrained_Brain_Surface_Registration.html">208 cvpr-2013-Hyperbolic Harmonic Mapping for Constrained Brain Surface Registration</a></p>
<p>10 0.56696457 <a title="424-lsi-10" href="./cvpr-2013-Computing_Diffeomorphic_Paths_for_Large_Motion_Interpolation.html">90 cvpr-2013-Computing Diffeomorphic Paths for Large Motion Interpolation</a></p>
<p>11 0.56430775 <a title="424-lsi-11" href="./cvpr-2013-Dense_Object_Reconstruction_with_Semantic_Priors.html">110 cvpr-2013-Dense Object Reconstruction with Semantic Priors</a></p>
<p>12 0.52416587 <a title="424-lsi-12" href="./cvpr-2013-Template-Based_Isometric_Deformable_3D_Reconstruction_with_Sampling-Based_Focal_Length_Self-Calibration.html">423 cvpr-2013-Template-Based Isometric Deformable 3D Reconstruction with Sampling-Based Focal Length Self-Calibration</a></p>
<p>13 0.52326393 <a title="424-lsi-13" href="./cvpr-2013-Optimal_Geometric_Fitting_under_the_Truncated_L2-Norm.html">317 cvpr-2013-Optimal Geometric Fitting under the Truncated L2-Norm</a></p>
<p>14 0.51110256 <a title="424-lsi-14" href="./cvpr-2013-City-Scale_Change_Detection_in_Cadastral_3D_Models_Using_Images.html">81 cvpr-2013-City-Scale Change Detection in Cadastral 3D Models Using Images</a></p>
<p>15 0.50712961 <a title="424-lsi-15" href="./cvpr-2013-HDR_Deghosting%3A_How_to_Deal_with_Saturation%3F.html">195 cvpr-2013-HDR Deghosting: How to Deal with Saturation?</a></p>
<p>16 0.50635356 <a title="424-lsi-16" href="./cvpr-2013-Tensor-Based_Human_Body_Modeling.html">426 cvpr-2013-Tensor-Based Human Body Modeling</a></p>
<p>17 0.50351334 <a title="424-lsi-17" href="./cvpr-2013-Deformable_Graph_Matching.html">106 cvpr-2013-Deformable Graph Matching</a></p>
<p>18 0.49044266 <a title="424-lsi-18" href="./cvpr-2013-The_Episolar_Constraint%3A_Monocular_Shape_from_Shadow_Correspondence.html">428 cvpr-2013-The Episolar Constraint: Monocular Shape from Shadow Correspondence</a></p>
<p>19 0.48993543 <a title="424-lsi-19" href="./cvpr-2013-PDM-ENLOR%3A_Learning_Ensemble_of_Local_PDM-Based_Regressions.html">321 cvpr-2013-PDM-ENLOR: Learning Ensemble of Local PDM-Based Regressions</a></p>
<p>20 0.46781823 <a title="424-lsi-20" href="./cvpr-2013-Area_Preserving_Brain_Mapping.html">44 cvpr-2013-Area Preserving Brain Mapping</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.01), (10, 0.121), (16, 0.051), (26, 0.081), (28, 0.018), (33, 0.245), (67, 0.055), (69, 0.067), (76, 0.011), (79, 0.213), (87, 0.061)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.89918512 <a title="424-lda-1" href="./cvpr-2013-Blind_Deconvolution_of_Widefield_Fluorescence_Microscopic_Data_by_Regularization_of_the_Optical_Transfer_Function_%28OTF%29.html">65 cvpr-2013-Blind Deconvolution of Widefield Fluorescence Microscopic Data by Regularization of the Optical Transfer Function (OTF)</a></p>
<p>Author: Margret Keuper, Thorsten Schmidt, Maja Temerinac-Ott, Jan Padeken, Patrick Heun, Olaf Ronneberger, Thomas Brox</p><p>Abstract: With volumetric data from widefield fluorescence microscopy, many emerging questions in biological and biomedical research are being investigated. Data can be recorded with high temporal resolution while the specimen is only exposed to a low amount of phototoxicity. These advantages come at the cost of strong recording blur caused by the infinitely extended point spread function (PSF). For widefield microscopy, its magnitude only decays with the square of the distance to the focal point and consists of an airy bessel pattern which is intricate to describe in the spatial domain. However, the Fourier transform of the incoherent PSF (denoted as Optical Transfer Function (OTF)) is well localized and smooth. In this paper, we present a blind -fre iburg .de Figure 1. As for widefield microscopy the convolution ofthe signal deconvolution method that improves results of state-of-theart deconvolution methods on widefield data by exploiting the properties of the widefield OTF.</p><p>same-paper 2 0.8591792 <a title="424-lda-2" href="./cvpr-2013-Templateless_Quasi-rigid_Shape_Modeling_with_Implicit_Loop-Closure.html">424 cvpr-2013-Templateless Quasi-rigid Shape Modeling with Implicit Loop-Closure</a></p>
<p>Author: Ming Zeng, Jiaxiang Zheng, Xuan Cheng, Xinguo Liu</p><p>Abstract: This paper presents a method for quasi-rigid objects modeling from a sequence of depth scans captured at different time instances. As quasi-rigid objects, such as human bodies, usually have shape motions during the capture procedure, it is difficult to reconstruct their geometries. We represent the shape motion by a deformation graph, and propose a model-to-partmethod to gradually integrate sampled points of depth scans into the deformation graph. Under an as-rigid-as-possible assumption, the model-to-part method can adjust the deformation graph non-rigidly, so as to avoid error accumulation in alignment, which also implicitly achieves loop-closure. To handle the drift and topological error for the deformation graph, two algorithms are introduced. First, we use a two-stage registration to largely keep the rigid motion part. Second, in the step of graph integration, we topology-adaptively integrate new parts and dynamically control the regularization effect of the deformation graph. We demonstrate the effectiveness and robustness of our method by several depth sequences of quasi-rigid objects, and an application in human shape modeling.</p><p>3 0.80058789 <a title="424-lda-3" href="./cvpr-2013-Learning_Video_Saliency_from_Human_Gaze_Using_Candidate_Selection.html">258 cvpr-2013-Learning Video Saliency from Human Gaze Using Candidate Selection</a></p>
<p>Author: Dmitry Rudoy, Dan B. Goldman, Eli Shechtman, Lihi Zelnik-Manor</p><p>Abstract: During recent years remarkable progress has been made in visual saliency modeling. Our interest is in video saliency. Since videos are fundamentally different from still images, they are viewed differently by human observers. For example, the time each video frame is observed is a fraction of a second, while a still image can be viewed leisurely. Therefore, video saliency estimation methods should differ substantially from image saliency methods. In this paper we propose a novel methodfor video saliency estimation, which is inspired by the way people watch videos. We explicitly model the continuity of the video by predicting the saliency map of a given frame, conditioned on the map from the previousframe. Furthermore, accuracy and computation speed are improved by restricting the salient locations to a carefully selected candidate set. We validate our method using two gaze-tracked video datasets and show we outperform the state-of-the-art.</p><p>4 0.80027127 <a title="424-lda-4" href="./cvpr-2013-Occlusion_Patterns_for_Object_Class_Detection.html">311 cvpr-2013-Occlusion Patterns for Object Class Detection</a></p>
<p>Author: Bojan Pepikj, Michael Stark, Peter Gehler, Bernt Schiele</p><p>Abstract: Despite the success of recent object class recognition systems, the long-standing problem of partial occlusion remains a major challenge, and a principled solution is yet to be found. In this paper we leave the beaten path of methods that treat occlusion as just another source of noise instead, we include the occluder itself into the modelling, by mining distinctive, reoccurring occlusion patterns from annotated training data. These patterns are then used as training data for dedicated detectors of varying sophistication. In particular, we evaluate and compare models that range from standard object class detectors to hierarchical, part-based representations of occluder/occludee pairs. In an extensive evaluation we derive insights that can aid further developments in tackling the occlusion challenge. –</p><p>5 0.79832524 <a title="424-lda-5" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<p>Author: Yi Sun, Xiaogang Wang, Xiaoou Tang</p><p>Abstract: We propose a new approach for estimation of the positions of facial keypoints with three-level carefully designed convolutional networks. At each level, the outputs of multiple networks are fused for robust and accurate estimation. Thanks to the deep structures of convolutional networks, global high-level features are extracted over the whole face region at the initialization stage, which help to locate high accuracy keypoints. There are two folds of advantage for this. First, the texture context information over the entire face is utilized to locate each keypoint. Second, since the networks are trained to predict all the keypoints simultaneously, the geometric constraints among keypoints are implicitly encoded. The method therefore can avoid local minimum caused by ambiguity and data corruption in difficult image samples due to occlusions, large pose variations, and extreme lightings. The networks at the following two levels are trained to locally refine initial predictions and their inputs are limited to small regions around the initial predictions. Several network structures critical for accurate and robust facial point detection are investigated. Extensive experiments show that our approach outperforms state-ofthe-art methods in both detection accuracy and reliability1.</p><p>6 0.79540455 <a title="424-lda-6" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>7 0.79386359 <a title="424-lda-7" href="./cvpr-2013-Physically_Plausible_3D_Scene_Tracking%3A_The_Single_Actor_Hypothesis.html">331 cvpr-2013-Physically Plausible 3D Scene Tracking: The Single Actor Hypothesis</a></p>
<p>8 0.79314667 <a title="424-lda-8" href="./cvpr-2013-Understanding_Bayesian_Rooms_Using_Composite_3D_Object_Models.html">445 cvpr-2013-Understanding Bayesian Rooms Using Composite 3D Object Models</a></p>
<p>9 0.79289621 <a title="424-lda-9" href="./cvpr-2013-Tracking_People_and_Their_Objects.html">440 cvpr-2013-Tracking People and Their Objects</a></p>
<p>10 0.79267931 <a title="424-lda-10" href="./cvpr-2013-Beyond_Point_Clouds%3A_Scene_Understanding_by_Reasoning_Geometry_and_Physics.html">61 cvpr-2013-Beyond Point Clouds: Scene Understanding by Reasoning Geometry and Physics</a></p>
<p>11 0.79191947 <a title="424-lda-11" href="./cvpr-2013-Part_Discovery_from_Partial_Correspondence.html">325 cvpr-2013-Part Discovery from Partial Correspondence</a></p>
<p>12 0.79172617 <a title="424-lda-12" href="./cvpr-2013-Integrating_Grammar_and_Segmentation_for_Human_Pose_Estimation.html">225 cvpr-2013-Integrating Grammar and Segmentation for Human Pose Estimation</a></p>
<p>13 0.79121643 <a title="424-lda-13" href="./cvpr-2013-Understanding_Indoor_Scenes_Using_3D_Geometric_Phrases.html">446 cvpr-2013-Understanding Indoor Scenes Using 3D Geometric Phrases</a></p>
<p>14 0.79116637 <a title="424-lda-14" href="./cvpr-2013-Structure_Preserving_Object_Tracking.html">414 cvpr-2013-Structure Preserving Object Tracking</a></p>
<p>15 0.79033691 <a title="424-lda-15" href="./cvpr-2013-Robust_Estimation_of_Nonrigid_Transformation_for_Point_Set_Registration.html">360 cvpr-2013-Robust Estimation of Nonrigid Transformation for Point Set Registration</a></p>
<p>16 0.79015785 <a title="424-lda-16" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<p>17 0.79002059 <a title="424-lda-17" href="./cvpr-2013-Incorporating_Structural_Alternatives_and_Sharing_into_Hierarchy_for_Multiclass_Object_Recognition_and_Detection.html">221 cvpr-2013-Incorporating Structural Alternatives and Sharing into Hierarchy for Multiclass Object Recognition and Detection</a></p>
<p>18 0.78953016 <a title="424-lda-18" href="./cvpr-2013-3D_Visual_Proxemics%3A_Recognizing_Human_Interactions_in_3D_from_a_Single_Image.html">4 cvpr-2013-3D Visual Proxemics: Recognizing Human Interactions in 3D from a Single Image</a></p>
<p>19 0.78901982 <a title="424-lda-19" href="./cvpr-2013-Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking.html">285 cvpr-2013-Minimum Uncertainty Gap for Robust Visual Tracking</a></p>
<p>20 0.78886831 <a title="424-lda-20" href="./cvpr-2013-Optimal_Geometric_Fitting_under_the_Truncated_L2-Norm.html">317 cvpr-2013-Optimal Geometric Fitting under the Truncated L2-Norm</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
