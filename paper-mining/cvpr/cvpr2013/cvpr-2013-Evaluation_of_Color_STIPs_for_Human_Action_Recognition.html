<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>149 cvpr-2013-Evaluation of Color STIPs for Human Action Recognition</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-149" href="#">cvpr2013-149</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>149 cvpr-2013-Evaluation of Color STIPs for Human Action Recognition</h1>
<br/><p>Source: <a title="cvpr-2013-149-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Everts_Evaluation_of_Color_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Ivo Everts, Jan C. van_Gemert, Theo Gevers</p><p>Abstract: This paper is concerned with recognizing realistic human actions in videos based on spatio-temporal interest points (STIPs). Existing STIP-based action recognition approaches operate on intensity representations of the image data. Because of this, these approaches are sensitive to disturbing photometric phenomena such as highlights and shadows. Moreover, valuable information is neglected by discarding chromaticity from the photometric representation. These issues are addressed by Color STIPs. Color STIPs are multi-channel reformulations of existing intensity-based STIP detectors and descriptors, for which we consider a number of chromatic representations derived from the opponent color space. This enhanced modeling of appearance improves the quality of subsequent STIP detection and description. Color STIPs are shown to substantially outperform their intensity-based counterparts on the challenging UCF sports, UCF11 and UCF50 action recognition benchmarks. Moreover, the results show that color STIPs are currently the single best low-level feature choice for STIP-based approaches to human action recognition.</p><p>Reference: <a title="cvpr-2013-149-reference" href="../cvpr2013_reference/cvpr-2013-Evaluation_of_Color_STIPs_for_Human_Action_Recognition_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('stip', 0.813), ('gab', 0.212), ('photomet', 0.211), ('chromatic', 0.206), ('har', 0.19), ('channel', 0.106), ('ucf', 0.087), ('oppon', 0.079), ('intens', 0.078), ('disturb', 0.078), ('mbh', 0.073), ('inv', 0.068), ('codebook', 0.063), ('ic', 0.061), ('tens', 0.057), ('video', 0.056), ('col', 0.056), ('cuboid', 0.056), ('feev', 0.053), ('stipbas', 0.053)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="149-tfidf-1" href="./cvpr-2013-Evaluation_of_Color_STIPs_for_Human_Action_Recognition.html">149 cvpr-2013-Evaluation of Color STIPs for Human Action Recognition</a></p>
<p>2 0.29199839 <a title="149-tfidf-2" href="./cvpr-2013-Spatio-temporal_Depth_Cuboid_Similarity_Feature_for_Activity_Recognition_Using_Depth_Camera.html">407 cvpr-2013-Spatio-temporal Depth Cuboid Similarity Feature for Activity Recognition Using Depth Camera</a></p>
<p>3 0.15968004 <a title="149-tfidf-3" href="./cvpr-2013-Discriminative_Color_Descriptors.html">130 cvpr-2013-Discriminative Color Descriptors</a></p>
<p>4 0.12763759 <a title="149-tfidf-4" href="./cvpr-2013-Complex_Event_Detection_via_Multi-source_Video_Attributes.html">85 cvpr-2013-Complex Event Detection via Multi-source Video Attributes</a></p>
<p>5 0.114312 <a title="149-tfidf-5" href="./cvpr-2013-Sampling_Strategies_for_Real-Time_Action_Recognition.html">378 cvpr-2013-Sampling Strategies for Real-Time Action Recognition</a></p>
<p>6 0.11042551 <a title="149-tfidf-6" href="./cvpr-2013-Hollywood_3D%3A_Recognizing_Actions_in_3D_Natural_Scenes.html">205 cvpr-2013-Hollywood 3D: Recognizing Actions in 3D Natural Scenes</a></p>
<p>7 0.10936093 <a title="149-tfidf-7" href="./cvpr-2013-Context-Aware_Modeling_and_Recognition_of_Activities_in_Video.html">94 cvpr-2013-Context-Aware Modeling and Recognition of Activities in Video</a></p>
<p>8 0.10919011 <a title="149-tfidf-8" href="./cvpr-2013-A_New_Perspective_on_Uncalibrated_Photometric_Stereo.html">21 cvpr-2013-A New Perspective on Uncalibrated Photometric Stereo</a></p>
<p>9 0.1074305 <a title="149-tfidf-9" href="./cvpr-2013-Uncalibrated_Photometric_Stereo_for_Unknown_Isotropic_Reflectances.html">443 cvpr-2013-Uncalibrated Photometric Stereo for Unknown Isotropic Reflectances</a></p>
<p>10 0.10625055 <a title="149-tfidf-10" href="./cvpr-2013-Modeling_Actions_through_State_Changes.html">287 cvpr-2013-Modeling Actions through State Changes</a></p>
<p>11 0.10141216 <a title="149-tfidf-11" href="./cvpr-2013-HON4D%3A_Histogram_of_Oriented_4D_Normals_for_Activity_Recognition_from_Depth_Sequences.html">196 cvpr-2013-HON4D: Histogram of Oriented 4D Normals for Activity Recognition from Depth Sequences</a></p>
<p>12 0.092131644 <a title="149-tfidf-12" href="./cvpr-2013-Pixel-Level_Hand_Detection_in_Ego-centric_Videos.html">332 cvpr-2013-Pixel-Level Hand Detection in Ego-centric Videos</a></p>
<p>13 0.089291982 <a title="149-tfidf-13" href="./cvpr-2013-Efficient_Color_Boundary_Detection_with_Color-Opponent_Mechanisms.html">140 cvpr-2013-Efficient Color Boundary Detection with Color-Opponent Mechanisms</a></p>
<p>14 0.074771523 <a title="149-tfidf-14" href="./cvpr-2013-An_Approach_to_Pose-Based_Action_Recognition.html">40 cvpr-2013-An Approach to Pose-Based Action Recognition</a></p>
<p>15 0.073436998 <a title="149-tfidf-15" href="./cvpr-2013-Exploring_Weak_Stabilization_for_Motion_Feature_Extraction.html">158 cvpr-2013-Exploring Weak Stabilization for Motion Feature Extraction</a></p>
<p>16 0.072925285 <a title="149-tfidf-16" href="./cvpr-2013-Joint_Sparsity-Based_Representation_and_Analysis_of_Unconstrained_Activities.html">233 cvpr-2013-Joint Sparsity-Based Representation and Analysis of Unconstrained Activities</a></p>
<p>17 0.071314283 <a title="149-tfidf-17" href="./cvpr-2013-First-Person_Activity_Recognition%3A_What_Are_They_Doing_to_Me%3F.html">175 cvpr-2013-First-Person Activity Recognition: What Are They Doing to Me?</a></p>
<p>18 0.070238747 <a title="149-tfidf-18" href="./cvpr-2013-Specular_Reflection_Separation_Using_Dark_Channel_Prior.html">410 cvpr-2013-Specular Reflection Separation Using Dark Channel Prior</a></p>
<p>19 0.067347437 <a title="149-tfidf-19" href="./cvpr-2013-Better_Exploiting_Motion_for_Better_Action_Recognition.html">59 cvpr-2013-Better Exploiting Motion for Better Action Recognition</a></p>
<p>20 0.066989467 <a title="149-tfidf-20" href="./cvpr-2013-Representing_Videos_Using_Mid-level_Discriminative_Patches.html">355 cvpr-2013-Representing Videos Using Mid-level Discriminative Patches</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.138), (1, -0.016), (2, -0.021), (3, -0.002), (4, -0.002), (5, 0.003), (6, -0.027), (7, -0.039), (8, -0.021), (9, -0.037), (10, -0.071), (11, -0.026), (12, 0.128), (13, 0.094), (14, 0.057), (15, -0.017), (16, -0.002), (17, -0.054), (18, 0.053), (19, 0.044), (20, -0.04), (21, 0.039), (22, -0.039), (23, 0.041), (24, -0.003), (25, -0.049), (26, 0.008), (27, 0.024), (28, -0.113), (29, -0.023), (30, -0.045), (31, 0.021), (32, -0.085), (33, -0.018), (34, 0.001), (35, 0.039), (36, 0.165), (37, 0.024), (38, -0.056), (39, -0.035), (40, -0.047), (41, 0.11), (42, -0.107), (43, -0.056), (44, -0.001), (45, 0.069), (46, -0.118), (47, 0.059), (48, -0.051), (49, 0.039)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.89374763 <a title="149-lsi-1" href="./cvpr-2013-Evaluation_of_Color_STIPs_for_Human_Action_Recognition.html">149 cvpr-2013-Evaluation of Color STIPs for Human Action Recognition</a></p>
<p>2 0.68861973 <a title="149-lsi-2" href="./cvpr-2013-Spatio-temporal_Depth_Cuboid_Similarity_Feature_for_Activity_Recognition_Using_Depth_Camera.html">407 cvpr-2013-Spatio-temporal Depth Cuboid Similarity Feature for Activity Recognition Using Depth Camera</a></p>
<p>3 0.67685908 <a title="149-lsi-3" href="./cvpr-2013-3D_R_Transform_on_Spatio-temporal_Interest_Points_for_Action_Recognition.html">3 cvpr-2013-3D R Transform on Spatio-temporal Interest Points for Action Recognition</a></p>
<p>4 0.63336903 <a title="149-lsi-4" href="./cvpr-2013-A_Linear_Approach_to_Matching_Cuboids_in_RGBD_Images.html">16 cvpr-2013-A Linear Approach to Matching Cuboids in RGBD Images</a></p>
<p>5 0.62270647 <a title="149-lsi-5" href="./cvpr-2013-Motionlets%3A_Mid-level_3D_Parts_for_Human_Motion_Recognition.html">291 cvpr-2013-Motionlets: Mid-level 3D Parts for Human Motion Recognition</a></p>
<p>6 0.61467665 <a title="149-lsi-6" href="./cvpr-2013-Spatiotemporal_Deformable_Part_Models_for_Action_Detection.html">408 cvpr-2013-Spatiotemporal Deformable Part Models for Action Detection</a></p>
<p>7 0.59918648 <a title="149-lsi-7" href="./cvpr-2013-Modeling_Actions_through_State_Changes.html">287 cvpr-2013-Modeling Actions through State Changes</a></p>
<p>8 0.58482599 <a title="149-lsi-8" href="./cvpr-2013-Detecting_and_Naming_Actors_in_Movies_Using_Generative_Appearance_Models.html">120 cvpr-2013-Detecting and Naming Actors in Movies Using Generative Appearance Models</a></p>
<p>9 0.57993108 <a title="149-lsi-9" href="./cvpr-2013-Sampling_Strategies_for_Real-Time_Action_Recognition.html">378 cvpr-2013-Sampling Strategies for Real-Time Action Recognition</a></p>
<p>10 0.57367229 <a title="149-lsi-10" href="./cvpr-2013-Hollywood_3D%3A_Recognizing_Actions_in_3D_Natural_Scenes.html">205 cvpr-2013-Hollywood 3D: Recognizing Actions in 3D Natural Scenes</a></p>
<p>11 0.56772929 <a title="149-lsi-11" href="./cvpr-2013-Pixel-Level_Hand_Detection_in_Ego-centric_Videos.html">332 cvpr-2013-Pixel-Level Hand Detection in Ego-centric Videos</a></p>
<p>12 0.56159645 <a title="149-lsi-12" href="./cvpr-2013-First-Person_Activity_Recognition%3A_What_Are_They_Doing_to_Me%3F.html">175 cvpr-2013-First-Person Activity Recognition: What Are They Doing to Me?</a></p>
<p>13 0.55712581 <a title="149-lsi-13" href="./cvpr-2013-Context-Aware_Modeling_and_Recognition_of_Activities_in_Video.html">94 cvpr-2013-Context-Aware Modeling and Recognition of Activities in Video</a></p>
<p>14 0.54829031 <a title="149-lsi-14" href="./cvpr-2013-HON4D%3A_Histogram_of_Oriented_4D_Normals_for_Activity_Recognition_from_Depth_Sequences.html">196 cvpr-2013-HON4D: Histogram of Oriented 4D Normals for Activity Recognition from Depth Sequences</a></p>
<p>15 0.52514452 <a title="149-lsi-15" href="./cvpr-2013-Joint_Sparsity-Based_Representation_and_Analysis_of_Unconstrained_Activities.html">233 cvpr-2013-Joint Sparsity-Based Representation and Analysis of Unconstrained Activities</a></p>
<p>16 0.50619924 <a title="149-lsi-16" href="./cvpr-2013-Detection_of_Manipulation_Action_Consequences_%28MAC%29.html">123 cvpr-2013-Detection of Manipulation Action Consequences (MAC)</a></p>
<p>17 0.502626 <a title="149-lsi-17" href="./cvpr-2013-Recognize_Human_Activities_from_Partially_Observed_Videos.html">347 cvpr-2013-Recognize Human Activities from Partially Observed Videos</a></p>
<p>18 0.50064212 <a title="149-lsi-18" href="./cvpr-2013-Poselet_Key-Framing%3A_A_Model_for_Human_Activity_Recognition.html">336 cvpr-2013-Poselet Key-Framing: A Model for Human Activity Recognition</a></p>
<p>19 0.49342617 <a title="149-lsi-19" href="./cvpr-2013-Cross-View_Action_Recognition_via_a_Continuous_Virtual_Path.html">98 cvpr-2013-Cross-View Action Recognition via a Continuous Virtual Path</a></p>
<p>20 0.49208695 <a title="149-lsi-20" href="./cvpr-2013-Specular_Reflection_Separation_Using_Dark_Channel_Prior.html">410 cvpr-2013-Specular Reflection Separation Using Dark Channel Prior</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.074), (4, 0.087), (5, 0.22), (37, 0.077), (40, 0.024), (46, 0.161), (81, 0.059), (86, 0.057), (95, 0.013), (97, 0.106)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.88631046 <a title="149-lda-1" href="./cvpr-2013-SWIGS%3A_A_Swift_Guided_Sampling_Method.html">373 cvpr-2013-SWIGS: A Swift Guided Sampling Method</a></p>
<p>2 0.88127762 <a title="149-lda-2" href="./cvpr-2013-Multipath_Sparse_Coding_Using_Hierarchical_Matching_Pursuit.html">304 cvpr-2013-Multipath Sparse Coding Using Hierarchical Matching Pursuit</a></p>
<p>same-paper 3 0.86714435 <a title="149-lda-3" href="./cvpr-2013-Evaluation_of_Color_STIPs_for_Human_Action_Recognition.html">149 cvpr-2013-Evaluation of Color STIPs for Human Action Recognition</a></p>
<p>4 0.86674356 <a title="149-lda-4" href="./cvpr-2013-Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking.html">285 cvpr-2013-Minimum Uncertainty Gap for Robust Visual Tracking</a></p>
<p>5 0.8661741 <a title="149-lda-5" href="./cvpr-2013-Finding_Group_Interactions_in_Social_Clutter.html">172 cvpr-2013-Finding Group Interactions in Social Clutter</a></p>
<p>6 0.86607963 <a title="149-lda-6" href="./cvpr-2013-Exploring_Compositional_High_Order_Pattern_Potentials_for_Structured_Output_Learning.html">156 cvpr-2013-Exploring Compositional High Order Pattern Potentials for Structured Output Learning</a></p>
<p>7 0.86490297 <a title="149-lda-7" href="./cvpr-2013-City-Scale_Change_Detection_in_Cadastral_3D_Models_Using_Images.html">81 cvpr-2013-City-Scale Change Detection in Cadastral 3D Models Using Images</a></p>
<p>8 0.86485451 <a title="149-lda-8" href="./cvpr-2013-Occlusion_Patterns_for_Object_Class_Detection.html">311 cvpr-2013-Occlusion Patterns for Object Class Detection</a></p>
<p>9 0.86471498 <a title="149-lda-9" href="./cvpr-2013-Online_Robust_Dictionary_Learning.html">315 cvpr-2013-Online Robust Dictionary Learning</a></p>
<p>10 0.86448997 <a title="149-lda-10" href="./cvpr-2013-Harry_Potter%27s_Marauder%27s_Map%3A_Localizing_and_Tracking_Multiple_Persons-of-Interest_by_Nonnegative_Discretization.html">199 cvpr-2013-Harry Potter's Marauder's Map: Localizing and Tracking Multiple Persons-of-Interest by Nonnegative Discretization</a></p>
<p>11 0.86430007 <a title="149-lda-11" href="./cvpr-2013-Structure_Preserving_Object_Tracking.html">414 cvpr-2013-Structure Preserving Object Tracking</a></p>
<p>12 0.86276317 <a title="149-lda-12" href="./cvpr-2013-Bilinear_Programming_for_Human_Activity_Recognition_with_Unknown_MRF_Graphs.html">62 cvpr-2013-Bilinear Programming for Human Activity Recognition with Unknown MRF Graphs</a></p>
<p>13 0.86240029 <a title="149-lda-13" href="./cvpr-2013-Self-Paced_Learning_for_Long-Term_Tracking.html">386 cvpr-2013-Self-Paced Learning for Long-Term Tracking</a></p>
<p>14 0.86197174 <a title="149-lda-14" href="./cvpr-2013-A_Video_Representation_Using_Temporal_Superpixels.html">29 cvpr-2013-A Video Representation Using Temporal Superpixels</a></p>
<p>15 0.86159533 <a title="149-lda-15" href="./cvpr-2013-Efficient_2D-to-3D_Correspondence_Filtering_for_Scalable_3D_Object_Recognition.html">138 cvpr-2013-Efficient 2D-to-3D Correspondence Filtering for Scalable 3D Object Recognition</a></p>
<p>16 0.86133987 <a title="149-lda-16" href="./cvpr-2013-Globally_Consistent_Multi-label_Assignment_on_the_Ray_Space_of_4D_Light_Fields.html">188 cvpr-2013-Globally Consistent Multi-label Assignment on the Ray Space of 4D Light Fields</a></p>
<p>17 0.86106783 <a title="149-lda-17" href="./cvpr-2013-Label_Propagation_from_ImageNet_to_3D_Point_Clouds.html">242 cvpr-2013-Label Propagation from ImageNet to 3D Point Clouds</a></p>
<p>18 0.8609311 <a title="149-lda-18" href="./cvpr-2013-Multi-scale_Curve_Detection_on_Surfaces.html">298 cvpr-2013-Multi-scale Curve Detection on Surfaces</a></p>
<p>19 0.86087656 <a title="149-lda-19" href="./cvpr-2013-Cross-View_Action_Recognition_via_a_Continuous_Virtual_Path.html">98 cvpr-2013-Cross-View Action Recognition via a Continuous Virtual Path</a></p>
<p>20 0.86027473 <a title="149-lda-20" href="./cvpr-2013-The_Episolar_Constraint%3A_Monocular_Shape_from_Shadow_Correspondence.html">428 cvpr-2013-The Episolar Constraint: Monocular Shape from Shadow Correspondence</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
