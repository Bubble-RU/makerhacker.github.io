<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>41 cvpr-2013-An Iterated L1 Algorithm for Non-smooth Non-convex Optimization in Computer Vision</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-41" href="#">cvpr2013-41</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>41 cvpr-2013-An Iterated L1 Algorithm for Non-smooth Non-convex Optimization in Computer Vision</h1>
<br/><p>Source: <a title="cvpr-2013-41-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Ochs_An_Iterated_L1_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Peter Ochs, Alexey Dosovitskiy, Thomas Brox, Thomas Pock</p><p>Abstract: Natural image statistics indicate that we should use nonconvex norms for most regularization tasks in image processing and computer vision. Still, they are rarely used in practice due to the challenge to optimize them. Recently, iteratively reweighed ?1 minimization has been proposed as a way to tackle a class of non-convex functions by solving a sequence of convex ?2-?1 problems. Here we extend the problem class to linearly constrained optimization of a Lipschitz continuous function, which is the sum of a convex function and a function being concave and increasing on the non-negative orthant (possibly non-convex and nonconcave on the whole space). This allows to apply the algorithm to many computer vision tasks. We show the effect of non-convex regularizers on image denoising, deconvolution, optical flow, and depth map fusion. Non-convexity is particularly interesting in combination with total generalized variation and learned image priors. Efficient optimization is made possible by some important properties that are shown to hold.</p><p>Reference: <a title="cvpr-2013-41-reference" href="../cvpr2013_reference/cvpr-2013-An_Iterated_L1_Algorithm_for_Non-smooth_Non-convex_Optimization_in_Computer_Vision_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 de Abstract Natural image statistics indicate that we should use nonconvex norms for most regularization tasks in image processing and computer vision. [sent-4, score-0.429]
</p><p>2 1 minimization has been proposed as a way to tackle a class of non-convex functions by solving a sequence of convex ? [sent-7, score-0.468]
</p><p>3 Here we extend the problem class to linearly constrained optimization of a Lipschitz continuous function, which is the sum of a convex function and a function being concave and increasing on the non-negative orthant (possibly non-convex and nonconcave on the whole space). [sent-10, score-1.017]
</p><p>4 We show the effect of non-convex regularizers on image denoising, deconvolution, optical flow, and depth map fusion. [sent-12, score-0.124]
</p><p>5 Efficient optimization is made possible by some important properties that are  shown to hold. [sent-14, score-0.088]
</p><p>6 Introduction Modeling and optimization with variational methods in computer vision are like antagonists on a balance scale. [sent-16, score-0.186]
</p><p>7 A major modification of a variational approach always requires developing suitable numerical algorithms. [sent-17, score-0.228]
</p><p>8 About two decades ago, people started to replace quadratic regularization terms by non-smooth ? [sent-18, score-0.258]
</p><p>9 Although, initially, algorithms were very slow, now, state-of-the-art convex optimization techniques show comparable efficiency to quadratic problems [8]. [sent-20, score-0.569]
</p><p>10 The development in the non-convex world turns out to be much more difficult. [sent-21, score-0.077]
</p><p>11 Rockafellar pointed out that: “The great watershed in optimization is not between linearity and non-linearity, but convexity and non-convexity”. [sent-23, score-0.261]
</p><p>12 This statement has been enGraz University of Technology, Austria pock@ i . [sent-24, score-0.052]
</p><p>13 The depth map fusion result of a stack of depth maps is shown as a 3D rendering. [sent-27, score-0.254]
</p><p>14 Total generalized variation regularization used for the fusion has the property to favor piecewise affine functions like the roof or the street. [sent-28, score-0.365]
</p><p>15 However, there is a tradeoff between affine pieces and discontinuities. [sent-29, score-0.067]
</p><p>16 This paper enables the optimization of non-convex norms (right) which emphasize the model properties and perform better for many computer vision tasks. [sent-32, score-0.199]
</p><p>17 forced by deriving the worst-case complexity bounds for general non-convex problems in [17] and makes it seemingly hopeless to find efficient algorithms in the non-convex case. [sent-33, score-0.243]
</p><p>18 However, there exist particular instances that still allow for efficient numerical algorithms. [sent-34, score-0.065]
</p><p>19 In this paper, we show that a certain class of linearly constrained convex plus concave (only on the non-negative orthant) optimization problems are particularly suitable for computer vision problems and can be efficiently minimized using state-of-the-art algorithms from convex optimization. [sent-35, score-1.3]
</p><p>20 •  •  We show how this class of problems can be efficiently optimized by minimizing a sequence aofn convex problems. [sent-36, score-0.58]
</p><p>21 We prove that the proposed algorithm monotonically dWecere parosvese tthhea tfu thnect piornop voaselude aolgf othriet original problem, which makes the algorithm an efficient tool for practical applications. [sent-37, score-0.338]
</p><p>22 Moreover, under slightly restricted conditions, we show existence of accumulation points and, that each accumulation point is a stationary point. [sent-38, score-0.212]
</p><p>23 111777555977  •  In computer vision examples like image denoising, deIcnon cvoomluptuiotenr, optical falomwp,l easn ldik depth map fouissiionng,, we demonstrate that non-convex models consistently outperform their convex counterparts. [sent-39, score-0.473]
</p><p>24 Related work Since the seminal works of Geman and Geman [13], Blake and Zissermann [5], and Mumford and Shah [16] on image restoration, the application of non-convex potential functions in variational approaches for computer vision problems has become a standard paradigm. [sent-41, score-0.318]
</p><p>25 The nonconvexity can be motivated and justified from different viewpoints, including robust statistics [4], nonlinear partial differential equations [20], and natural image statistics [14]. [sent-42, score-0.223]
</p><p>26 Since then, numerous works demonstrated through ex-  periments [4, 23], that non-convex potential functions are the right choice. [sent-43, score-0.15]
</p><p>27 Early approaches are based on annealing-type schemes [13] and continuation methods such as the graduated non-convexity (GNC) algorithm [5]. [sent-45, score-0.143]
</p><p>28 However, these approaches are very slow and their results heavily depend on the initial guess. [sent-46, score-0.077]
</p><p>29 A first breakthrough was achieved by Geman and Reynolds [12]. [sent-47, score-0.067]
</p><p>30 They rewrote the (smooth) non-convex potential function as the infimum over a family of quadratic functions. [sent-48, score-0.109]
</p><p>31 This transformation suggests an algorithmic scheme that solves a sequence of quadratic problems, leading to the so-called iteratively reweighted least squares (IRLS) algorithm. [sent-49, score-0.415]
</p><p>32 This algorithm quickly became a standard solver and hence, it has been extended and studied in many works, see e. [sent-50, score-0.057]
</p><p>33 The IRLS algorithm can only be applied if the nonconvex function can be well approximated from above with quadratic functions. [sent-53, score-0.279]
</p><p>34 ∈ ∈[7 (]0 t,a1c)k,le wdh tihcihs problem by tehree nsoti-acbalel e adt iteratively reweighted ? [sent-57, score-0.374]
</p><p>35 1 problems and hence can be seen as non-smooth counterpart to the IRLS algorithm. [sent-60, score-0.131]
</p><p>36 1 regularized compressed sensing problems, but it turns out that this algorithm is also useful for computer vision applications. [sent-62, score-0.077]
</p><p>37 In particular, they show that the method monotonically decreases the energy of the non-convex problem. [sent-67, score-0.086]
</p><p>38 Unfortunately, the class of problems they considered is not suitable for typical computer vision problems, due to the absence of a linear operator that is needed in order to represent spatial regularization terms. [sent-68, score-0.432]
</p><p>39 Another track of algorithms considering non-convex objectives is the difference of convex functions (DC) programming [2]. [sent-69, score-0.381]
</p><p>40 The general DC algorithm (DCA) alternates between minimizing the difference of the convex dual functions and the difference of the convex functions. [sent-70, score-0.626]
</p><p>41 In the practical DCA convex programs obtained by linearizing one of the two functions are solved alternately. [sent-71, score-0.451]
</p><p>42 Applying DC programming to the function class of the IRL1 algorithm requires an “unnatural” splitting of the objective function. [sent-72, score-0.13]
</p><p>43 It makes the optimization hard as emerging proximity operators are difficult to solve in closed form. [sent-73, score-0.088]
</p><p>44 Therefore, we focus on generalizing the IRL1 algorithm, present a thorough analysis of this new optimization framework, and make it applicable to computer vision problems. [sent-74, score-0.189]
</p><p>45 A linearly constrained non-smooth and nonconvex optimization problem In this paper we study a wide class of optimization problems, which include ? [sent-76, score-0.617]
</p><p>46 The model we consider is a linearly constrained minimization problem on a finite dimensional Hilbert space H of the ftoiornm p minF(x),  s. [sent-82, score-0.252]
</p><p>47 In addition we suppose that F is bounded from below, F1 : H → R ∪ {∞} is proper convex and F2 : H+ → R is concave Ran ∪d increasing. [sent-85, score-0.373]
</p><p>48 Hr ceroen, H+ ndden Fote:s H the nonnegative orthant of the space Here; increasingness and the anbegsoaltuivtee voartluhean |tx o| are eto s a bec eun Hd;er isntocoreda icnogonrdesinsat aen-wdi tshee. [sent-86, score-0.488]
</p><p>49 aTbhseo lluinteear v aclouens |txra|in atr Aex to o= b eb uisn given by a olionredainr operator A : H → H1, mapping H into another finite dimensional AHi:lb Hert → space ,H m1,a apnpidn a v Hec tionrt ob a∈n Hoth1 . [sent-87, score-0.261]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('orthant', 0.285), ('convex', 0.241), ('irls', 0.221), ('geman', 0.202), ('dca', 0.19), ('nonconvex', 0.17), ('lipschitz', 0.14), ('concave', 0.132), ('problems', 0.131), ('reweighted', 0.126), ('linearly', 0.117), ('thomas', 0.116), ('norms', 0.111), ('dc', 0.11), ('quadratic', 0.109), ('accumulation', 0.106), ('variational', 0.098), ('regularization', 0.097), ('functions', 0.089), ('optimization', 0.088), ('monotonically', 0.086), ('txra', 0.084), ('ceroen', 0.084), ('alexey', 0.084), ('gnc', 0.084), ('hec', 0.084), ('iburg', 0.084), ('ldik', 0.084), ('reynolds', 0.084), ('tfu', 0.084), ('thnect', 0.084), ('tthhea', 0.084), ('class', 0.079), ('mumford', 0.078), ('aex', 0.078), ('bec', 0.078), ('easn', 0.078), ('freiburg', 0.078), ('graduated', 0.078), ('uisn', 0.078), ('turns', 0.077), ('slow', 0.077), ('tx', 0.077), ('constrained', 0.075), ('ago', 0.074), ('austria', 0.074), ('eun', 0.074), ('minf', 0.074), ('reweighed', 0.074), ('unnatural', 0.074), ('denoising', 0.07), ('nonconvexity', 0.07), ('aofn', 0.07), ('linearizing', 0.07), ('watershed', 0.07), ('depth', 0.07), ('ochs', 0.067), ('breakthrough', 0.067), ('affine', 0.067), ('numerical', 0.065), ('suitable', 0.065), ('adt', 0.065), ('continuation', 0.065), ('wdh', 0.065), ('fusion', 0.063), ('lb', 0.063), ('atr', 0.063), ('solves', 0.061), ('periments', 0.061), ('iteratively', 0.06), ('finite', 0.06), ('operator', 0.06), ('seemingly', 0.059), ('sequence', 0.059), ('tehree', 0.058), ('became', 0.057), ('hd', 0.057), ('cg', 0.057), ('alternates', 0.055), ('peter', 0.055), ('shah', 0.054), ('hilbert', 0.054), ('regularizers', 0.054), ('forced', 0.053), ('linearity', 0.053), ('started', 0.052), ('statement', 0.052), ('justified', 0.051), ('nonnegative', 0.051), ('programs', 0.051), ('deconvolution', 0.051), ('thorough', 0.051), ('stack', 0.051), ('statistics', 0.051), ('programming', 0.051), ('pock', 0.05), ('convexity', 0.05), ('generalizing', 0.05), ('hr', 0.05), ('roof', 0.049)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="41-tfidf-1" href="./cvpr-2013-An_Iterated_L1_Algorithm_for_Non-smooth_Non-convex_Optimization_in_Computer_Vision.html">41 cvpr-2013-An Iterated L1 Algorithm for Non-smooth Non-convex Optimization in Computer Vision</a></p>
<p>Author: Peter Ochs, Alexey Dosovitskiy, Thomas Brox, Thomas Pock</p><p>Abstract: Natural image statistics indicate that we should use nonconvex norms for most regularization tasks in image processing and computer vision. Still, they are rarely used in practice due to the challenge to optimize them. Recently, iteratively reweighed ?1 minimization has been proposed as a way to tackle a class of non-convex functions by solving a sequence of convex ?2-?1 problems. Here we extend the problem class to linearly constrained optimization of a Lipschitz continuous function, which is the sum of a convex function and a function being concave and increasing on the non-negative orthant (possibly non-convex and nonconcave on the whole space). This allows to apply the algorithm to many computer vision tasks. We show the effect of non-convex regularizers on image denoising, deconvolution, optical flow, and depth map fusion. Non-convexity is particularly interesting in combination with total generalized variation and learned image priors. Efficient optimization is made possible by some important properties that are shown to hold.</p><p>2 0.11376461 <a title="41-tfidf-2" href="./cvpr-2013-Simultaneous_Super-Resolution_of_Depth_and_Images_Using_a_Single_Camera.html">397 cvpr-2013-Simultaneous Super-Resolution of Depth and Images Using a Single Camera</a></p>
<p>Author: Hee Seok Lee, Kuoung Mu Lee</p><p>Abstract: In this paper, we propose a convex optimization framework for simultaneous estimation of super-resolved depth map and images from a single moving camera. The pixel measurement error in 3D reconstruction is directly related to the resolution of the images at hand. In turn, even a small measurement error can cause significant errors in reconstructing 3D scene structure or camera pose. Therefore, enhancing image resolution can be an effective solution for securing the accuracy as well as the resolution of 3D reconstruction. In the proposed method, depth map estimation and image super-resolution are formulated in a single energy minimization framework with a convex function and solved efficiently by a first-order primal-dual algorithm. Explicit inter-frame pixel correspondences are not required for our super-resolution procedure, thus we can avoid a huge computation time and obtain improved depth map in the accuracy and resolution as well as highresolution images with reasonable time. The superiority of our algorithm is demonstrated by presenting the improved depth map accuracy, image super-resolution results, and camera pose estimation.</p><p>3 0.078676395 <a title="41-tfidf-3" href="./cvpr-2013-Stochastic_Deconvolution.html">412 cvpr-2013-Stochastic Deconvolution</a></p>
<p>Author: James Gregson, Felix Heide, Matthias B. Hullin, Mushfiqur Rouf, Wolfgang Heidrich</p><p>Abstract: We present a novel stochastic framework for non-blind deconvolution based on point samples obtained from random walks. Unlike previous methods that must be tailored to specific regularization strategies, the new Stochastic Deconvolution method allows arbitrary priors, including nonconvex and data-dependent regularizers, to be introduced and tested with little effort. Stochastic Deconvolution is straightforward to implement, produces state-of-the-art results and directly leads to a natural boundary condition for image boundaries and saturated pixels.</p><p>4 0.072440729 <a title="41-tfidf-4" href="./cvpr-2013-Unnatural_L0_Sparse_Representation_for_Natural_Image_Deblurring.html">449 cvpr-2013-Unnatural L0 Sparse Representation for Natural Image Deblurring</a></p>
<p>Author: Li Xu, Shicheng Zheng, Jiaya Jia</p><p>Abstract: We show in this paper that the success of previous maximum a posterior (MAP) based blur removal methods partly stems from their respective intermediate steps, which implicitly or explicitly create an unnatural representation containing salient image structures. We propose a generalized and mathematically sound L0 sparse expression, together with a new effective method, for motion deblurring. Our system does not require extra filtering during optimization and demonstrates fast energy decreasing, making a small number of iterations enough for convergence. It also provides a unifiedframeworkfor both uniform andnon-uniform motion deblurring. We extensively validate our method and show comparison with other approaches with respect to convergence speed, running time, and result quality.</p><p>5 0.071447425 <a title="41-tfidf-5" href="./cvpr-2013-A_New_Model_and_Simple_Algorithms_for_Multi-label_Mumford-Shah_Problems.html">20 cvpr-2013-A New Model and Simple Algorithms for Multi-label Mumford-Shah Problems</a></p>
<p>Author: Byung-Woo Hong, Zhaojin Lu, Ganesh Sundaramoorthi</p><p>Abstract: In this work, we address the multi-label Mumford-Shah problem, i.e., the problem of jointly estimating a partitioning of the domain of the image, and functions defined within regions of the partition. We create algorithms that are efficient, robust to undesirable local minima, and are easy-toimplement. Our algorithms are formulated by slightly modifying the underlying statistical model from which the multilabel Mumford-Shah functional is derived. The advantage of this statistical model is that the underlying variables: the labels and thefunctions are less coupled than in the original formulation, and the labels can be computed from the functions with more global updates. The resulting algorithms can be tuned to the desired level of locality of the solution: from fully global updates to more local updates. We demonstrate our algorithm on two applications: joint multi-label segmentation and denoising, and joint multi-label motion segmentation and flow estimation. We compare to the stateof-the-art in multi-label Mumford-Shah problems and show that we achieve more promising results.</p><p>6 0.069887951 <a title="41-tfidf-6" href="./cvpr-2013-The_Variational_Structure_of_Disparity_and_Regularization_of_4D_Light_Fields.html">431 cvpr-2013-The Variational Structure of Disparity and Regularization of 4D Light Fields</a></p>
<p>7 0.069444045 <a title="41-tfidf-7" href="./cvpr-2013-Continuous_Inference_in_Graphical_Models_with_Polynomial_Energies.html">95 cvpr-2013-Continuous Inference in Graphical Models with Polynomial Energies</a></p>
<p>8 0.06786681 <a title="41-tfidf-8" href="./cvpr-2013-Dense_Variational_Reconstruction_of_Non-rigid_Surfaces_from_Monocular_Video.html">113 cvpr-2013-Dense Variational Reconstruction of Non-rigid Surfaces from Monocular Video</a></p>
<p>9 0.064361125 <a title="41-tfidf-9" href="./cvpr-2013-Globally_Consistent_Multi-label_Assignment_on_the_Ray_Space_of_4D_Light_Fields.html">188 cvpr-2013-Globally Consistent Multi-label Assignment on the Ray Space of 4D Light Fields</a></p>
<p>10 0.063672021 <a title="41-tfidf-10" href="./cvpr-2013-Layer_Depth_Denoising_and_Completion_for_Structured-Light_RGB-D_Cameras.html">245 cvpr-2013-Layer Depth Denoising and Completion for Structured-Light RGB-D Cameras</a></p>
<p>11 0.061654862 <a title="41-tfidf-11" href="./cvpr-2013-Joint_3D_Scene_Reconstruction_and_Class_Segmentation.html">230 cvpr-2013-Joint 3D Scene Reconstruction and Class Segmentation</a></p>
<p>12 0.059657976 <a title="41-tfidf-12" href="./cvpr-2013-Texture_Enhanced_Image_Denoising_via_Gradient_Histogram_Preservation.html">427 cvpr-2013-Texture Enhanced Image Denoising via Gradient Histogram Preservation</a></p>
<p>13 0.059435956 <a title="41-tfidf-13" href="./cvpr-2013-Sample-Specific_Late_Fusion_for_Visual_Category_Recognition.html">377 cvpr-2013-Sample-Specific Late Fusion for Visual Category Recognition</a></p>
<p>14 0.055914044 <a title="41-tfidf-14" href="./cvpr-2013-Efficient_Computation_of_Shortest_Path-Concavity_for_3D_Meshes.html">141 cvpr-2013-Efficient Computation of Shortest Path-Concavity for 3D Meshes</a></p>
<p>15 0.054074928 <a title="41-tfidf-15" href="./cvpr-2013-Sparse_Subspace_Denoising_for_Image_Manifolds.html">405 cvpr-2013-Sparse Subspace Denoising for Image Manifolds</a></p>
<p>16 0.0524345 <a title="41-tfidf-16" href="./cvpr-2013-Active_Contours_with_Group_Similarity.html">33 cvpr-2013-Active Contours with Group Similarity</a></p>
<p>17 0.052417979 <a title="41-tfidf-17" href="./cvpr-2013-A_Practical_Rank-Constrained_Eight-Point_Algorithm_for_Fundamental_Matrix_Estimation.html">23 cvpr-2013-A Practical Rank-Constrained Eight-Point Algorithm for Fundamental Matrix Estimation</a></p>
<p>18 0.052294008 <a title="41-tfidf-18" href="./cvpr-2013-Fast_Convolutional_Sparse_Coding.html">164 cvpr-2013-Fast Convolutional Sparse Coding</a></p>
<p>19 0.051386081 <a title="41-tfidf-19" href="./cvpr-2013-Towards_Efficient_and_Exact_MAP-Inference_for_Large_Scale_Discrete_Computer_Vision_Problems_via_Combinatorial_Optimization.html">436 cvpr-2013-Towards Efficient and Exact MAP-Inference for Large Scale Discrete Computer Vision Problems via Combinatorial Optimization</a></p>
<p>20 0.051116031 <a title="41-tfidf-20" href="./cvpr-2013-Multi-image_Blind_Deblurring_Using_a_Coupled_Adaptive_Sparse_Prior.html">295 cvpr-2013-Multi-image Blind Deblurring Using a Coupled Adaptive Sparse Prior</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.131), (1, 0.075), (2, -0.021), (3, 0.051), (4, 0.001), (5, 0.023), (6, 0.005), (7, -0.021), (8, -0.015), (9, 0.008), (10, 0.033), (11, 0.01), (12, -0.033), (13, 0.001), (14, -0.035), (15, 0.008), (16, -0.053), (17, 0.001), (18, 0.039), (19, 0.003), (20, -0.055), (21, -0.004), (22, -0.006), (23, -0.038), (24, 0.045), (25, 0.032), (26, -0.054), (27, 0.009), (28, 0.016), (29, -0.067), (30, 0.042), (31, 0.02), (32, -0.01), (33, -0.083), (34, -0.07), (35, -0.011), (36, 0.045), (37, -0.012), (38, -0.023), (39, -0.012), (40, -0.019), (41, -0.04), (42, -0.048), (43, 0.017), (44, 0.022), (45, 0.062), (46, -0.011), (47, -0.003), (48, 0.028), (49, 0.085)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96358919 <a title="41-lsi-1" href="./cvpr-2013-An_Iterated_L1_Algorithm_for_Non-smooth_Non-convex_Optimization_in_Computer_Vision.html">41 cvpr-2013-An Iterated L1 Algorithm for Non-smooth Non-convex Optimization in Computer Vision</a></p>
<p>Author: Peter Ochs, Alexey Dosovitskiy, Thomas Brox, Thomas Pock</p><p>Abstract: Natural image statistics indicate that we should use nonconvex norms for most regularization tasks in image processing and computer vision. Still, they are rarely used in practice due to the challenge to optimize them. Recently, iteratively reweighed ?1 minimization has been proposed as a way to tackle a class of non-convex functions by solving a sequence of convex ?2-?1 problems. Here we extend the problem class to linearly constrained optimization of a Lipschitz continuous function, which is the sum of a convex function and a function being concave and increasing on the non-negative orthant (possibly non-convex and nonconcave on the whole space). This allows to apply the algorithm to many computer vision tasks. We show the effect of non-convex regularizers on image denoising, deconvolution, optical flow, and depth map fusion. Non-convexity is particularly interesting in combination with total generalized variation and learned image priors. Efficient optimization is made possible by some important properties that are shown to hold.</p><p>2 0.76958805 <a title="41-lsi-2" href="./cvpr-2013-Continuous_Inference_in_Graphical_Models_with_Polynomial_Energies.html">95 cvpr-2013-Continuous Inference in Graphical Models with Polynomial Energies</a></p>
<p>Author: Mathieu Salzmann</p><p>Abstract: In this paper, we tackle the problem of performing inference in graphical models whose energy is a polynomial function of continuous variables. Our energy minimization method follows a dual decomposition approach, where the global problem is split into subproblems defined over the graph cliques. The optimal solution to these subproblems is obtained by making use of a polynomial system solver. Our algorithm inherits the convergence guarantees of dual decomposition. To speed up optimization, we also introduce a variant of this algorithm based on the augmented Lagrangian method. Our experiments illustrate the diversity of computer vision problems that can be expressed with polynomial energies, and demonstrate the benefits of our approach over existing continuous inference methods.</p><p>3 0.73419571 <a title="41-lsi-3" href="./cvpr-2013-A_Practical_Rank-Constrained_Eight-Point_Algorithm_for_Fundamental_Matrix_Estimation.html">23 cvpr-2013-A Practical Rank-Constrained Eight-Point Algorithm for Fundamental Matrix Estimation</a></p>
<p>Author: Yinqiang Zheng, Shigeki Sugimoto, Masatoshi Okutomi</p><p>Abstract: Due to its simplicity, the eight-point algorithm has been widely used in fundamental matrix estimation. Unfortunately, the rank-2 constraint of a fundamental matrix is enforced via a posterior rank correction step, thus leading to non-optimal solutions to the original problem. To address this drawback, existing algorithms need to solve either a very high order polynomial or a sequence of convex relaxation problems, both of which are computationally ineffective and numerically unstable. In this work, we present a new rank-2 constrained eight-point algorithm, which directly incorporates the rank-2 constraint in the minimization process. To avoid singularities, we propose to solve seven subproblems and retrieve their globally optimal solutions by using tailored polynomial system solvers. Our proposed method is noniterative, computationally efficient and numerically stable. Experiment results have verified its superiority over existing algebraic error based algorithms in terms of accuracy, as well as its advantages when used to initialize geometric error based algorithms.</p><p>4 0.69223875 <a title="41-lsi-4" href="./cvpr-2013-Towards_Efficient_and_Exact_MAP-Inference_for_Large_Scale_Discrete_Computer_Vision_Problems_via_Combinatorial_Optimization.html">436 cvpr-2013-Towards Efficient and Exact MAP-Inference for Large Scale Discrete Computer Vision Problems via Combinatorial Optimization</a></p>
<p>Author: Jörg Hendrik Kappes, Markus Speth, Gerhard Reinelt, Christoph Schnörr</p><p>Abstract: Discrete graphical models (also known as discrete Markov random fields) are a major conceptual tool to model the structure of optimization problems in computer vision. While in the last decade research has focused on fast approximative methods, algorithms that provide globally optimal solutions have come more into the research focus in the last years. However, large scale computer vision problems seemed to be out of reach for such methods. In this paper we introduce a promising way to bridge this gap based on partial optimality and structural properties of the underlying problem factorization. Combining these preprocessing steps, we are able to solve grids of size 2048 2048 in less than 90 seconds. On the hitherto unsolva2b04le8 C×h2i0ne4s8e character dataset of Nowozin et al. we obtain provably optimal results in 56% of the instances and achieve competitive runtimes on other recent benchmark problems. While in the present work only generalized Potts models are considered, an extension to general graphical models seems to be feasible.</p><p>5 0.68760151 <a title="41-lsi-5" href="./cvpr-2013-Nonlinearly_Constrained_MRFs%3A_Exploring_the_Intrinsic_Dimensions_of_Higher-Order_Cliques.html">308 cvpr-2013-Nonlinearly Constrained MRFs: Exploring the Intrinsic Dimensions of Higher-Order Cliques</a></p>
<p>Author: Yun Zeng, Chaohui Wang, Stefano Soatto, Shing-Tung Yau</p><p>Abstract: This paper introduces an efficient approach to integrating non-local statistics into the higher-order Markov Random Fields (MRFs) framework. Motivated by the observation that many non-local statistics (e.g., shape priors, color distributions) can usually be represented by a small number of parameters, we reformulate the higher-order MRF model by introducing additional latent variables to represent the intrinsic dimensions of the higher-order cliques. The resulting new model, called NC-MRF, not only provides the flexibility in representing the configurations of higher-order cliques, but also automatically decomposes the energy function into less coupled terms, allowing us to design an efficient algorithmic framework for maximum a posteriori (MAP) inference. Based on this novel modeling/inference framework, we achieve state-of-the-art solutions to the challenging problems of class-specific image segmentation and template-based 3D facial expression tracking, which demonstrate the potential of our approach.</p><p>6 0.68738955 <a title="41-lsi-6" href="./cvpr-2013-A_Comparative_Study_of_Modern_Inference_Techniques_for_Discrete_Energy_Minimization_Problems.html">6 cvpr-2013-A Comparative Study of Modern Inference Techniques for Discrete Energy Minimization Problems</a></p>
<p>7 0.66146809 <a title="41-lsi-7" href="./cvpr-2013-A_Fast_Semidefinite_Approach_to_Solving_Binary_Quadratic_Problems.html">9 cvpr-2013-A Fast Semidefinite Approach to Solving Binary Quadratic Problems</a></p>
<p>8 0.64242077 <a title="41-lsi-8" href="./cvpr-2013-Fast_Trust_Region_for_Segmentation.html">171 cvpr-2013-Fast Trust Region for Segmentation</a></p>
<p>9 0.63940644 <a title="41-lsi-9" href="./cvpr-2013-Universality_of_the_Local_Marginal_Polytope.html">448 cvpr-2013-Universality of the Local Marginal Polytope</a></p>
<p>10 0.6387617 <a title="41-lsi-10" href="./cvpr-2013-Auxiliary_Cuts_for_General_Classes_of_Higher_Order_Functionals.html">51 cvpr-2013-Auxiliary Cuts for General Classes of Higher Order Functionals</a></p>
<p>11 0.62910938 <a title="41-lsi-11" href="./cvpr-2013-A_Divide-and-Conquer_Method_for_Scalable_Low-Rank_Latent_Matrix_Pursuit.html">7 cvpr-2013-A Divide-and-Conquer Method for Scalable Low-Rank Latent Matrix Pursuit</a></p>
<p>12 0.62895209 <a title="41-lsi-12" href="./cvpr-2013-A_New_Model_and_Simple_Algorithms_for_Multi-label_Mumford-Shah_Problems.html">20 cvpr-2013-A New Model and Simple Algorithms for Multi-label Mumford-Shah Problems</a></p>
<p>13 0.590545 <a title="41-lsi-13" href="./cvpr-2013-Simultaneous_Super-Resolution_of_Depth_and_Images_Using_a_Single_Camera.html">397 cvpr-2013-Simultaneous Super-Resolution of Depth and Images Using a Single Camera</a></p>
<p>14 0.58451295 <a title="41-lsi-14" href="./cvpr-2013-Learning_for_Structured_Prediction_Using_Approximate_Subgradient_Descent_with_Working_Sets.html">262 cvpr-2013-Learning for Structured Prediction Using Approximate Subgradient Descent with Working Sets</a></p>
<p>15 0.57604313 <a title="41-lsi-15" href="./cvpr-2013-In_Defense_of_3D-Label_Stereo.html">219 cvpr-2013-In Defense of 3D-Label Stereo</a></p>
<p>16 0.56550699 <a title="41-lsi-16" href="./cvpr-2013-Discrete_MRF_Inference_of_Marginal_Densities_for_Non-uniformly_Discretized_Variable_Space.html">128 cvpr-2013-Discrete MRF Inference of Marginal Densities for Non-uniformly Discretized Variable Space</a></p>
<p>17 0.56043386 <a title="41-lsi-17" href="./cvpr-2013-Stochastic_Deconvolution.html">412 cvpr-2013-Stochastic Deconvolution</a></p>
<p>18 0.55826098 <a title="41-lsi-18" href="./cvpr-2013-Blind_Deconvolution_of_Widefield_Fluorescence_Microscopic_Data_by_Regularization_of_the_Optical_Transfer_Function_%28OTF%29.html">65 cvpr-2013-Blind Deconvolution of Widefield Fluorescence Microscopic Data by Regularization of the Optical Transfer Function (OTF)</a></p>
<p>19 0.55770135 <a title="41-lsi-19" href="./cvpr-2013-Fast_Convolutional_Sparse_Coding.html">164 cvpr-2013-Fast Convolutional Sparse Coding</a></p>
<p>20 0.547153 <a title="41-lsi-20" href="./cvpr-2013-Optimizing_1-Nearest_Prototype_Classifiers.html">320 cvpr-2013-Optimizing 1-Nearest Prototype Classifiers</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.133), (15, 0.315), (16, 0.01), (26, 0.035), (33, 0.265), (67, 0.025), (69, 0.06), (87, 0.082), (96, 0.011)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.79142374 <a title="41-lda-1" href="./cvpr-2013-An_Iterated_L1_Algorithm_for_Non-smooth_Non-convex_Optimization_in_Computer_Vision.html">41 cvpr-2013-An Iterated L1 Algorithm for Non-smooth Non-convex Optimization in Computer Vision</a></p>
<p>Author: Peter Ochs, Alexey Dosovitskiy, Thomas Brox, Thomas Pock</p><p>Abstract: Natural image statistics indicate that we should use nonconvex norms for most regularization tasks in image processing and computer vision. Still, they are rarely used in practice due to the challenge to optimize them. Recently, iteratively reweighed ?1 minimization has been proposed as a way to tackle a class of non-convex functions by solving a sequence of convex ?2-?1 problems. Here we extend the problem class to linearly constrained optimization of a Lipschitz continuous function, which is the sum of a convex function and a function being concave and increasing on the non-negative orthant (possibly non-convex and nonconcave on the whole space). This allows to apply the algorithm to many computer vision tasks. We show the effect of non-convex regularizers on image denoising, deconvolution, optical flow, and depth map fusion. Non-convexity is particularly interesting in combination with total generalized variation and learned image priors. Efficient optimization is made possible by some important properties that are shown to hold.</p><p>2 0.77820367 <a title="41-lda-2" href="./cvpr-2013-A_New_Perspective_on_Uncalibrated_Photometric_Stereo.html">21 cvpr-2013-A New Perspective on Uncalibrated Photometric Stereo</a></p>
<p>Author: Thoma Papadhimitri, Paolo Favaro</p><p>Abstract: We investigate the problem of reconstructing normals, albedo and lights of Lambertian surfaces in uncalibrated photometric stereo under the perspective projection model. Our analysis is based on establishing the integrability constraint. In the orthographicprojection case, it is well-known that when such constraint is imposed, a solution can be identified only up to 3 parameters, the so-called generalized bas-relief (GBR) ambiguity. We show that in the perspective projection case the solution is unique. We also propose a closed-form solution which is simple, efficient and robust. We test our algorithm on synthetic data and publicly available real data. Our quantitative tests show that our method outperforms all prior work of uncalibrated photometric stereo under orthographic projection.</p><p>3 0.73489267 <a title="41-lda-3" href="./cvpr-2013-Label-Embedding_for_Attribute-Based_Classification.html">241 cvpr-2013-Label-Embedding for Attribute-Based Classification</a></p>
<p>Author: Zeynep Akata, Florent Perronnin, Zaid Harchaoui, Cordelia Schmid</p><p>Abstract: Attributes are an intermediate representation, which enables parameter sharing between classes, a must when training data is scarce. We propose to view attribute-based image classification as a label-embedding problem: each class is embedded in the space of attribute vectors. We introduce a function which measures the compatibility between an image and a label embedding. The parameters of this function are learned on a training set of labeled samples to ensure that, given an image, the correct classes rank higher than the incorrect ones. Results on the Animals With Attributes and Caltech-UCSD-Birds datasets show that the proposed framework outperforms the standard Direct Attribute Prediction baseline in a zero-shot learning scenario. The label embedding framework offers other advantages such as the ability to leverage alternative sources of information in addition to attributes (e.g. class hierarchies) or to transition smoothly from zero-shot learning to learning with large quantities of data.</p><p>4 0.71553314 <a title="41-lda-4" href="./cvpr-2013-All_About_VLAD.html">38 cvpr-2013-All About VLAD</a></p>
<p>Author: unkown-author</p><p>Abstract: The objective of this paper is large scale object instance retrieval, given a query image. A starting point of such systems is feature detection and description, for example using SIFT. The focus of this paper, however, is towards very large scale retrieval where, due to storage requirements, very compact image descriptors are required and no information about the original SIFT descriptors can be accessed directly at run time. We start from VLAD, the state-of-the art compact descriptor introduced by J´ egou et al. [8] for this purpose, and make three novel contributions: first, we show that a simple change to the normalization method significantly improves retrieval performance; second, we show that vocabulary adaptation can substantially alleviate problems caused when images are added to the dataset after initial vocabulary learning. These two methods set a new stateof-the-art over all benchmarks investigated here for both mid-dimensional (20k-D to 30k-D) and small (128-D) descriptors. Our third contribution is a multiple spatial VLAD representation, MultiVLAD, that allows the retrieval and local- ization of objects that only extend over a small part of an image (again without requiring use of the original image SIFT descriptors).</p><p>5 0.71287817 <a title="41-lda-5" href="./cvpr-2013-Towards_Pose_Robust_Face_Recognition.html">438 cvpr-2013-Towards Pose Robust Face Recognition</a></p>
<p>Author: Dong Yi, Zhen Lei, Stan Z. Li</p><p>Abstract: Most existing pose robust methods are too computational complex to meet practical applications and their performance under unconstrained environments are rarely evaluated. In this paper, we propose a novel method for pose robust face recognition towards practical applications, which is fast, pose robust and can work well under unconstrained environments. Firstly, a 3D deformable model is built and a fast 3D model fitting algorithm is proposed to estimate the pose of face image. Secondly, a group of Gabor filters are transformed according to the pose and shape of face image for feature extraction. Finally, PCA is applied on the pose adaptive Gabor features to remove the redundances and Cosine metric is used to evaluate the similarity. The proposed method has three advantages: (1) The pose correction is applied in the filter space rather than image space, which makes our method less affected by the precision of the 3D model; (2) By combining the holistic pose transformation and local Gabor filtering, the final feature is robust to pose and other negative factors in face recognition; (3) The 3D structure and facial symmetry are successfully used to deal with self-occlusion. Extensive experiments on FERET and PIE show the proposed method outperforms state-ofthe-art methods significantly, meanwhile, the method works well on LFW.</p><p>6 0.69984913 <a title="41-lda-6" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<p>7 0.69952351 <a title="41-lda-7" href="./cvpr-2013-Beyond_Point_Clouds%3A_Scene_Understanding_by_Reasoning_Geometry_and_Physics.html">61 cvpr-2013-Beyond Point Clouds: Scene Understanding by Reasoning Geometry and Physics</a></p>
<p>8 0.69860113 <a title="41-lda-8" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>9 0.69775116 <a title="41-lda-9" href="./cvpr-2013-Intrinsic_Scene_Properties_from_a_Single_RGB-D_Image.html">227 cvpr-2013-Intrinsic Scene Properties from a Single RGB-D Image</a></p>
<p>10 0.69736356 <a title="41-lda-10" href="./cvpr-2013-Cross-View_Action_Recognition_via_a_Continuous_Virtual_Path.html">98 cvpr-2013-Cross-View Action Recognition via a Continuous Virtual Path</a></p>
<p>11 0.69712192 <a title="41-lda-11" href="./cvpr-2013-Detection-_and_Trajectory-Level_Exclusion_in_Multiple_Object_Tracking.html">121 cvpr-2013-Detection- and Trajectory-Level Exclusion in Multiple Object Tracking</a></p>
<p>12 0.6970337 <a title="41-lda-12" href="./cvpr-2013-Efficient_Large-Scale_Structured_Learning.html">143 cvpr-2013-Efficient Large-Scale Structured Learning</a></p>
<p>13 0.69696927 <a title="41-lda-13" href="./cvpr-2013-Understanding_Bayesian_Rooms_Using_Composite_3D_Object_Models.html">445 cvpr-2013-Understanding Bayesian Rooms Using Composite 3D Object Models</a></p>
<p>14 0.69611341 <a title="41-lda-14" href="./cvpr-2013-Label_Propagation_from_ImageNet_to_3D_Point_Clouds.html">242 cvpr-2013-Label Propagation from ImageNet to 3D Point Clouds</a></p>
<p>15 0.69607711 <a title="41-lda-15" href="./cvpr-2013-Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking.html">285 cvpr-2013-Minimum Uncertainty Gap for Robust Visual Tracking</a></p>
<p>16 0.69574314 <a title="41-lda-16" href="./cvpr-2013-Learning_Structured_Hough_Voting_for_Joint_Object_Detection_and_Occlusion_Reasoning.html">256 cvpr-2013-Learning Structured Hough Voting for Joint Object Detection and Occlusion Reasoning</a></p>
<p>17 0.69570994 <a title="41-lda-17" href="./cvpr-2013-A_Minimum_Error_Vanishing_Point_Detection_Approach_for_Uncalibrated_Monocular_Images_of_Man-Made_Environments.html">19 cvpr-2013-A Minimum Error Vanishing Point Detection Approach for Uncalibrated Monocular Images of Man-Made Environments</a></p>
<p>18 0.69559395 <a title="41-lda-18" href="./cvpr-2013-Layer_Depth_Denoising_and_Completion_for_Structured-Light_RGB-D_Cameras.html">245 cvpr-2013-Layer Depth Denoising and Completion for Structured-Light RGB-D Cameras</a></p>
<p>19 0.69534814 <a title="41-lda-19" href="./cvpr-2013-Separating_Signal_from_Noise_Using_Patch_Recurrence_across_Scales.html">393 cvpr-2013-Separating Signal from Noise Using Patch Recurrence across Scales</a></p>
<p>20 0.69527239 <a title="41-lda-20" href="./cvpr-2013-Globally_Consistent_Multi-label_Assignment_on_the_Ray_Space_of_4D_Light_Fields.html">188 cvpr-2013-Globally Consistent Multi-label Assignment on the Ray Space of 4D Light Fields</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
