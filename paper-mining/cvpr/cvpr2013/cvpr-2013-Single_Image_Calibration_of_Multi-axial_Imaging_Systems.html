<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>400 cvpr-2013-Single Image Calibration of Multi-axial Imaging Systems</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-400" href="#">cvpr2013-400</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>400 cvpr-2013-Single Image Calibration of Multi-axial Imaging Systems</h1>
<br/><p>Source: <a title="cvpr-2013-400-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Agrawal_Single_Image_Calibration_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Amit Agrawal, Srikumar Ramalingam</p><p>Abstract: Imaging systems consisting of a camera looking at multiple spherical mirrors (reflection) or multiple refractive spheres (refraction) have been used for wide-angle imaging applications. We describe such setups as multi-axial imaging systems, since a single sphere results in an axial system. Assuming an internally calibrated camera, calibration of such multi-axial systems involves estimating the sphere radii and locations in the camera coordinate system. However, previous calibration approaches require manual intervention or constrained setups. We present a fully automatic approach using a single photo of a 2D calibration grid. The pose of the calibration grid is assumed to be unknown and is also recovered. Our approach can handle unconstrained setups, where the mirrors/refractive balls can be arranged in any fashion, not necessarily on a grid. The axial nature of rays allows us to compute the axis of each sphere separately. We then show that by choosing rays from two or more spheres, the unknown pose of the calibration grid can be obtained linearly and independently of sphere radii and locations. Knowing the pose, we derive analytical solutions for obtaining the sphere radius and location. This leads to an interesting result that 6-DOF pose estimation of a multi-axial camera can be done without the knowledge of full calibration. Simulations and real experiments demonstrate the applicability of our algorithm.</p><p>Reference: <a title="cvpr-2013-400-reference" href="../cvpr2013_reference/cvpr-2013-Single_Image_Calibration_of_Multi-axial_Imaging_Systems_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Abstract Imaging systems consisting of a camera looking at multiple spherical mirrors (reflection) or multiple refractive spheres (refraction) have been used for wide-angle imaging applications. [sent-2, score-1.121]
</p><p>2 We describe such setups as multi-axial imaging systems, since a single sphere results in an axial system. [sent-3, score-0.735]
</p><p>3 Assuming an internally calibrated camera, calibration of such multi-axial systems involves estimating the sphere radii and locations in the camera coordinate system. [sent-4, score-0.99]
</p><p>4 The pose of the calibration grid is assumed to be unknown and is also recovered. [sent-7, score-0.402]
</p><p>5 The axial nature of rays allows us to compute the axis of each sphere separately. [sent-9, score-0.802]
</p><p>6 We then show that by choosing rays from two or more spheres, the unknown pose of the calibration grid can be obtained linearly and independently of sphere radii and locations. [sent-10, score-1.023]
</p><p>7 Knowing the pose, we derive  analytical solutions for obtaining the sphere radius and location. [sent-11, score-0.576]
</p><p>8 Introduction Catadioptric imaging systems consist of a camera looking at single or multiple mirrors for wide-angle imaging. [sent-15, score-0.439]
</p><p>9 The special configurations include a perspective camera placed at the focal point of a hyperbolic or an elliptical mirror, or an orthographic camera placed on the axis of a parabolic mirror. [sent-17, score-0.384]
</p><p>10 Common configurations such as camera viewing a spherical mirror or multiple mirrors always lead to a non-central imaging system [23]. [sent-18, score-0.79]
</p><p>11 In this paper, we describe such setups (see Figure 1) as multi-axial imaging systems, since a single spherical mirror/refractive ball results in an axial system [2, 24]. [sent-54, score-0.549]
</p><p>12 Without loss of generality, we use ‘sphere’ to refer to the spherical mirror as well as the refractive sphere. [sent-55, score-0.683]
</p><p>13 [24] manually marked the outline of each sphere in the captured image to get an initial estimate of sphere center and radius. [sent-59, score-0.886]
</p><p>14 Techniques such as [8, 19] also used the image contour of sphere for localization. [sent-61, score-0.449]
</p><p>15 Nayar’s [15] sphereo system require sphere centers to lie on an plane orthogonal to the imaging plane, along with coplanar light sources such that their centroid lies on the optical axis for calibration. [sent-65, score-0.676]
</p><p>16 This along with mechanical design data is used to estimate the initial sphere  locations [13, 7]. [sent-67, score-0.427]
</p><p>17 We show that calibration of such multi-axial systems can be done using a single photo of a 2D calibration grid (e. [sent-69, score-0.534]
</p><p>18 The pose of the checkerboard is assumed to be unknown, and is also recovered. [sent-72, score-0.501]
</p><p>19 It does not require estimation of the sphere contour in the captured photo. [sent-75, score-0.471]
</p><p>20 Our approach can handle spheres of different radii and is marker-less. [sent-76, score-0.386]
</p><p>21 While a single sphere results in a multi-perspective image and corresponds to an axial camera, multiple spheres correspond to a multi-axial camera where each 3D point is imaged multiple times via underlying axial cameras. [sent-79, score-1.22]
</p><p>22 The axial nature of rays allows us to compute the axis of each sphere separately. [sent-80, score-0.802]
</p><p>23 By choosing rays from two or more spheres, we demonstrate that the unknown pose of the checkerboard can be obtained linearly, and independently of sphere radii and locations. [sent-81, score-1.164]
</p><p>24 Thus, 6DOF pose estimation can be done in a semi-calibrated setting, without the knowledge of sphere locations and radii. [sent-82, score-0.568]
</p><p>25 Finally, we derive analytical solutions for estimating the radii and center of spheres with known checkerboard pose and axes. [sent-84, score-0.948]
</p><p>26 Related Work Axial Systems: A camera looking at a single mirror can be categorized as an (a) axial or (b) off-axis system, depending on its placement on the mirror axis. [sent-87, score-0.902]
</p><p>27 However, they require three images of a checkerboard in different orientations and their parameterization involves two rotations/translations. [sent-90, score-0.382]
</p><p>28 Instead, we use a global model parameterized via sphere radius and center. [sent-93, score-0.547]
</p><p>29 Micusik and Pajdla [14] proposed autocalibration of single mirror based axial systems starting from a central approximation, using multiple images. [sent-94, score-0.517]
</p><p>30 A brute force approach to apply axial methods to multi-axial scenario is to calibrate each sphere separately. [sent-95, score-0.674]
</p><p>31 However, this does not utilize inter-sphere constraints and the fact that the same checkerboard is seen via all spheres. [sent-96, score-0.382]
</p><p>32 We show that using rays from two or more spheres allow computing the checkerboard pose linearly and independently of sphere parameters. [sent-97, score-1.26]
</p><p>33 This greatly simplifies the calibration, where the checkerboard pose is estimated first, followed by the esti-  mation of sphere parameters. [sent-98, score-1.001]
</p><p>34 Other imaging systems such as flat refractive systems [1] have also been shown to be axial. [sent-99, score-0.416]
</p><p>35 We build upon the algorithm proposed in [1] to compute the axes and checkerboard pose. [sent-100, score-0.5]
</p><p>36 Off-Axis Systems: Off-axis mirror calibration is harder than calibrating axial systems. [sent-101, score-0.749]
</p><p>37 Multi-Axial Cameras Consider the multi-axial imaging systems, where a perspective camera observes the scene reflected via n spherical mirrors, or refracted via n refractive spheres. [sent-111, score-0.679]
</p><p>38 Let C(i)in=1 be the center of the ith sphere with radius ri. [sent-113, score-0.579]
</p><p>39 We assume that the internal camera calibration has been done offline and hence we know the camera ray v(i, j) for each 3D point P(i) and each mirror j. [sent-118, score-0.795]
</p><p>40 Our goal is to compute the center and radius of each sphere, as well as the unknown pose of the calibration grid given nK 3D-2D correspondences. [sent-119, score-0.554]
</p><p>41 As discussed, we use the term ‘sphere’ to describe both the spherical mirror and the refractive sphere. [sent-120, score-0.683]
</p><p>42 The estimation of axes and checkerboard pose is identical for both cases, and they differ only in the estimation of sphere radii and locations. [sent-121, score-1.214]
</p><p>43 Axial and Multi-Axial Geometry: It is well-known that a single sphere corresponds to an axial imaging system [2]. [sent-122, score-0.723]
</p><p>44 be the distance of the ith sphere center from the CO=P. [sent-125, score-0.459]
</p><p>45 x bise Athei d=i sCtain/cdei oisf dtheefin ied as the normalized vector joining the sphere center to the COP. [sent-129, score-0.459]
</p><p>46 [1] derived the coplanarity constraint for axial cameras considering flat refractive geometry. [sent-132, score-0.609]
</p><p>47 Since each sphere also corresponds to an axial camera, the coplanarity constraint can be used to compute the axis Ai of each sphere. [sent-133, score-0.842]
</p><p>48 Next, we show that the translation ambiguity along any individual axis can be removed by using rays from two or more spheres, since two or more axes will not be parallel in general. [sent-166, score-0.435]
</p><p>49 Recovering the Checkerboard Pose A brute-force approach for calibrating multi-axial system would be to calibrate each sphere separately, as an axial system. [sent-169, score-0.764]
</p><p>50 Note that the checkerboard pose in the camera coordinate system is identical with respect to all the spheres. [sent-170, score-0.67]
</p><p>51 In addition, calibrating each sphere separately leads to a more difficult and computationally expensive algorithm. [sent-173, score-0.492]
</p><p>52 Thus, there remains three calibration parameters for each mirror: (a) mirror radius rj, (b) mirror distance dj and (c) tA (j). [sent-179, score-0.892]
</p><p>53 The pose can be obtained in (a) linear fashion, and (b) independently of sphere radii and distances. [sent-184, score-0.67]
</p><p>54 Secondly, the full pose can be recovered linearly without estimating sphere parameters, thus enabling pose estimation in a semi-calibrated setting. [sent-187, score-0.687]
</p><p>55 Finally, since the translation ambiguity is resolved, two parameters remain for each sphere  × ×  (radius and distance) instead of three. [sent-188, score-0.576]
</p><p>56 Solving for sphere radius rj and distance dj along with tA (j) proved to be difficult and we were not able to find an analytical solution to estimate rj, dj and tA (j) simultaneously. [sent-190, score-0.679]
</p><p>57 Linear Estimation of Pose We assume that the axes of spheres can be estimated as explained in Section 3. [sent-193, score-0.421]
</p><p>58 If we combine the coplanarity constraints from two mirrors j and k whose axes are not parallel, Kt has rank 3 and G has rank 5. [sent-215, score-0.387]
</p><p>59 Using a second sphere k, we get another constraint t = sk + βAk. [sent-224, score-0.427]
</p><p>60 Let Q(i) = RP(i) + t be the transformed checkerboard  ×  points in the camera coordinate system. [sent-227, score-0.526]
</p><p>61 Solving for Spherical Mirror Parameters Now we consider the mirror case and describe how to solve for the sphere radius and distance assuming known checkerboard pose and axes. [sent-231, score-1.311]
</p><p>62 Estimation of sphere radius r and distance d for spherical mirror (left) and refractive ball (right) assuming known checkerboard pose and mirror axis. [sent-240, score-2.048]
</p><p>63 Referring to Figure 2, the spherical mirror is represented as a circle on π with center at S = [0, d] and radius r. [sent-244, score-0.577]
</p><p>64 Let M = kw be the common point on the mirror and the camera ray for some scalar k. [sent-245, score-0.464]
</p><p>65 Known Radius: In practice, a good initial estimate of mirror radius may be known. [sent-262, score-0.383]
</p><p>66 Non-linear refinement Non-linear refinement can be done by minimizing the image re-projection error for all checkerboard points. [sent-267, score-0.516]
</p><p>67 The projection of a 3D point can be obtained by solving a 4th degree equation for a spherical mirror as shown in [2]. [sent-268, score-0.502]
</p><p>68 L,je)t b pe(i t,h je) breo tehcecorresponding detected checkerboard corner in the image. [sent-272, score-0.382]
</p><p>69 Error in sphere locations and sphere radius after non-linear refinement for all four mirrors. [sent-307, score-1.012]
</p><p>70 We use a realistic scenario with four spherical  ×  mirrors of radius 0. [sent-310, score-0.441]
</p><p>71 After estimating the axes and pose, the mirror parameters are estimated, followed by non-linear refinement. [sent-322, score-0.381]
</p><p>72 Figure 5 shows the error in sphere locations and radii for all four mirrors, as a percentage of the true values. [sent-324, score-0.609]
</p><p>73 Multiple Refractive Spheres Now we consider a camera looking through multiple refractive spheres (ball lenses) as shown in Figure 8. [sent-328, score-0.689]
</p><p>74 Similar  to mirrors, the axis is defined as the vector joining the camera center to the center of the refractive sphere. [sent-329, score-0.537]
</p><p>75 The calibration parameters consist of centers, radii and refractive indices of the balls along with the unknown checkerboard pose. [sent-330, score-1.069]
</p><p>76 1, we can compute the checkerboard pose and axis of each refractive ball in exactly the same manner using the multi-axial property. [sent-333, score-0.911]
</p><p>77 Let M1 = kw be the common point on the refractive ball and the camera ray w. [sent-339, score-0.513]
</p><p>78 We therefore assume that the radius of refractive ball (and hence β) is known a-priori2 and solve for the single unknown d by solving the above derived 12th degree equation. [sent-360, score-0.514]
</p><p>79 The projection of a 3D point can be obtained by solving a 10th degree equation for refractive sphere as shown in [2]. [sent-362, score-0.762]
</p><p>80 Simulation: We use similar settings as in Section 6 to simulate a camera looking through four refractive spheres of radius 12. [sent-363, score-0.809]
</p><p>81 Neither the spherical array nor the checkerboard is fronto-parallel to the imaging plane. [sent-373, score-0.608]
</p><p>82 Figure 6 and Figure 7 shows the error in estimated axes, sphere distances and checkerboard pose using our algorithm after non-linear refinement, with Gaussian noise of increasing variance added to checkerboard corners. [sent-374, score-1.409]
</p><p>83 For example, the maximum error in sphere distance is less than 0. [sent-376, score-0.485]
</p><p>84 6ersa8um1Mean  Error in  Estmiated Axsi  ing known sphere radii. [sent-388, score-0.427]
</p><p>85 Simulation results for multiple refractive spheres assuming known sphere radii. [sent-401, score-0.947]
</p><p>86 Figure 8 also shows the detected corners (red) and re-projected corners as well as the sphere boundary (green) using the estimated calibration parameters. [sent-414, score-0.746]
</p><p>87 Spherical Mirrors: In Figure 9, the camera looks at the scene reflected from four spherical mirrors4 of radius 25. [sent-417, score-0.443]
</p><p>88 For the case of reflection, the camera does not view the checkerboard directly. [sent-420, score-0.499]
</p><p>89 To obtain the ground truth checkerboard pose, we need to estimate its extrinsic without a direct view [21, 10]. [sent-421, score-0.41]
</p><p>90 [25], which requires capturing three images of the checkerboard using a planar mirror in different orientations. [sent-423, score-0.645]
</p><p>91 The algorithm in [25] estimates the planar mirror poses as well as the checkerboard pose. [sent-424, score-0.645]
</p><p>92 1 1 14 4 40 0 024 2  and re-projected checkerboard points/sphere boundary (green) using estimated calibration parameters are shown. [sent-428, score-0.637]
</p><p>93 Comparison of checkerboard pose obtained using our method with ground truth (GT) pose for Figure 8. [sent-448, score-0.62]
</p><p>94 Figure 8 also shows the detected corners (red) and the re-projected corners as well as the sphere boundary (green) using the estimated calibration parameters. [sent-463, score-0.746]
</p><p>95 Notice that the estimated contour matches well with the actual sphere boundary. [sent-464, score-0.49]
</p><p>96 Table 3 shows the estimated checkerboard pose along with the ground truth pose estimated using [25]. [sent-475, score-0.702]
</p><p>97 Captured photo with detected (red) and re-projected checkerboard points (green) after calibration. [sent-484, score-0.414]
</p><p>98 Discussions and Conclusions We have presented a single image based calibration approach for multi-axial systems, consisting of a camera looking at multiple spherical mirrors or multiple refractive spheres. [sent-517, score-0.962]
</p><p>99 We believe that ours is the first algorithm that allows calibrating multiple refractive spheres based imaging system using a single photo. [sent-518, score-0.674]
</p><p>100 We also showed an interesting theoretical result that full 6-DOF pose estimation of such multi-axial systems can be done in a semi-calibrated setting (without the knowledge of complete calibration), by choosing rays from two or more of the underlying axial systems. [sent-519, score-0.465]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('sphere', 0.427), ('checkerboard', 0.382), ('mirror', 0.263), ('spheres', 0.262), ('refractive', 0.258), ('calibration', 0.214), ('axial', 0.207), ('spherical', 0.162), ('mirrors', 0.159), ('aj', 0.138), ('radii', 0.124), ('catadioptric', 0.122), ('radius', 0.12), ('pose', 0.119), ('axes', 0.118), ('camera', 0.117), ('translation', 0.11), ('coplanarity', 0.11), ('axis', 0.098), ('ray', 0.084), ('rotation', 0.078), ('rays', 0.07), ('ej', 0.065), ('calibrating', 0.065), ('imaging', 0.064), ('agrawal', 0.064), ('ramalingam', 0.06), ('error', 0.058), ('refraction', 0.055), ('ball', 0.054), ('mm', 0.053), ('looking', 0.052), ('simulation', 0.051), ('percantage', 0.05), ('balls', 0.049), ('sturm', 0.048), ('systems', 0.047), ('taguchi', 0.047), ('gt', 0.046), ('omnidirectional', 0.045), ('reflected', 0.044), ('inch', 0.044), ('unknown', 0.042), ('estimated', 0.041), ('calibrate', 0.04), ('degree', 0.04), ('rj', 0.039), ('ambiguity', 0.039), ('reflection', 0.038), ('sj', 0.038), ('refinement', 0.038), ('setups', 0.037), ('equation', 0.037), ('eliminating', 0.034), ('internally', 0.034), ('refracted', 0.034), ('cameras', 0.034), ('kt', 0.033), ('dioptric', 0.033), ('echigo', 0.033), ('estmiated', 0.033), ('kojima', 0.033), ('kwx', 0.033), ('kwy', 0.033), ('ogutrs', 0.033), ('sphereo', 0.033), ('simplifies', 0.032), ('photo', 0.032), ('dj', 0.032), ('center', 0.032), ('corners', 0.032), ('ta', 0.031), ('svd', 0.031), ('caglioti', 0.029), ('distortion', 0.029), ('plane', 0.029), ('analytical', 0.029), ('extrinsic', 0.028), ('rms', 0.028), ('grid', 0.027), ('gasparini', 0.027), ('nishino', 0.027), ('reprojection', 0.027), ('intervention', 0.027), ('coordinate', 0.027), ('placed', 0.026), ('omnivis', 0.026), ('snell', 0.026), ('sagawa', 0.026), ('micusik', 0.026), ('br', 0.025), ('system', 0.025), ('tardif', 0.024), ('takahashi', 0.024), ('arranged', 0.024), ('notice', 0.024), ('fashion', 0.023), ('estimation', 0.022), ('let', 0.022), ('contour', 0.022)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="400-tfidf-1" href="./cvpr-2013-Single_Image_Calibration_of_Multi-axial_Imaging_Systems.html">400 cvpr-2013-Single Image Calibration of Multi-axial Imaging Systems</a></p>
<p>Author: Amit Agrawal, Srikumar Ramalingam</p><p>Abstract: Imaging systems consisting of a camera looking at multiple spherical mirrors (reflection) or multiple refractive spheres (refraction) have been used for wide-angle imaging applications. We describe such setups as multi-axial imaging systems, since a single sphere results in an axial system. Assuming an internally calibrated camera, calibration of such multi-axial systems involves estimating the sphere radii and locations in the camera coordinate system. However, previous calibration approaches require manual intervention or constrained setups. We present a fully automatic approach using a single photo of a 2D calibration grid. The pose of the calibration grid is assumed to be unknown and is also recovered. Our approach can handle unconstrained setups, where the mirrors/refractive balls can be arranged in any fashion, not necessarily on a grid. The axial nature of rays allows us to compute the axis of each sphere separately. We then show that by choosing rays from two or more spheres, the unknown pose of the calibration grid can be obtained linearly and independently of sphere radii and locations. Knowing the pose, we derive analytical solutions for obtaining the sphere radius and location. This leads to an interesting result that 6-DOF pose estimation of a multi-axial camera can be done without the knowledge of full calibration. Simulations and real experiments demonstrate the applicability of our algorithm.</p><p>2 0.27558887 <a title="400-tfidf-2" href="./cvpr-2013-Underwater_Camera_Calibration_Using_Wavelength_Triangulation.html">447 cvpr-2013-Underwater Camera Calibration Using Wavelength Triangulation</a></p>
<p>Author: Timothy Yau, Minglun Gong, Yee-Hong Yang</p><p>Abstract: In underwater imagery, the image formation process includes refractions that occur when light passes from water into the camera housing, typically through a flat glass port. We extend the existing work on physical refraction models by considering the dispersion of light, and derive new constraints on the model parameters for use in calibration. This leads to a novel calibration method that achieves improved accuracy compared to existing work. We describe how to construct a novel calibration device for our method and evaluate the accuracy of the method through synthetic and real experiments.</p><p>3 0.22701675 <a title="400-tfidf-3" href="./cvpr-2013-Mirror_Surface_Reconstruction_from_a_Single_Image.html">286 cvpr-2013-Mirror Surface Reconstruction from a Single Image</a></p>
<p>Author: Miaomiao Liu, Richard Hartley, Mathieu Salzmann</p><p>Abstract: This paper tackles the problem of reconstructing the shape of a smooth mirror surface from a single image. In particular, we consider the case where the camera is observing the reflection of a static reference target in the unknown mirror. We first study the reconstruction problem given dense correspondences between 3D points on the reference target and image locations. In such conditions, our differential geometry analysis provides a theoretical proof that the shape of the mirror surface can be uniquely recovered if the pose of the reference target is known. We then relax our assumptions by considering the case where only sparse correspondences are available. In this scenario, we formulate reconstruction as an optimization problem, which can be solved using a nonlinear least-squares method. We demonstrate the effectiveness of our method on both synthetic and real images.</p><p>4 0.22077711 <a title="400-tfidf-4" href="./cvpr-2013-Can_a_Fully_Unconstrained_Imaging_Model_Be_Applied_Effectively_to_Central_Cameras%3F.html">76 cvpr-2013-Can a Fully Unconstrained Imaging Model Be Applied Effectively to Central Cameras?</a></p>
<p>Author: Filippo Bergamasco, Andrea Albarelli, Emanuele Rodolà, Andrea Torsello</p><p>Abstract: Traditional camera models are often the result of a compromise between the ability to account for non-linearities in the image formation model and the need for a feasible number of degrees of freedom in the estimation process. These considerations led to the definition of several ad hoc models that best adapt to different imaging devices, ranging from pinhole cameras with no radial distortion to the more complex catadioptric or polydioptric optics. In this paper we dai s .unive . it ence points in the scene with their projections on the image plane [5]. Unfortunately, no real camera behaves exactly like an ideal pinhole. In fact, in most cases, at least the distortion effects introduced by the lens should be accounted for [19]. Any pinhole-based model, regardless of its level of sophistication, is geometrically unable to properly describe cameras exhibiting a frustum angle that is near or above 180 degrees. For wide-angle cameras, several different para- metric models have been proposed. Some of them try to modify the captured image in order to follow the original propose the use of an unconstrained model even in standard central camera settings dominated by the pinhole model, and introduce a novel calibration approach that can deal effectively with the huge number of free parameters associated with it, resulting in a higher precision calibration than what is possible with the standard pinhole model with correction for radial distortion. This effectively extends the use of general models to settings that traditionally have been ruled by parametric approaches out of practical considerations. The benefit of such an unconstrained model to quasipinhole central cameras is supported by an extensive experimental validation.</p><p>5 0.21685699 <a title="400-tfidf-5" href="./cvpr-2013-Discovering_the_Structure_of_a_Planar_Mirror_System_from_Multiple_Observations_of_a_Single_Point.html">127 cvpr-2013-Discovering the Structure of a Planar Mirror System from Multiple Observations of a Single Point</a></p>
<p>Author: Ilya Reshetouski, Alkhazur Manakov, Ayush Bandhari, Ramesh Raskar, Hans-Peter Seidel, Ivo Ihrke</p><p>Abstract: We investigate the problem of identifying the position of a viewer inside a room of planar mirrors with unknown geometry in conjunction with the room’s shape parameters. We consider the observations to consist of angularly resolved depth measurements of a single scene point that is being observed via many multi-bounce interactions with the specular room geometry. Applications of this problem statement include areas such as calibration, acoustic echo cancelation and time-of-flight imaging. We theoretically analyze the problem and derive sufficient conditions for a combination of convex room geometry, observer, and scene point to be reconstructable. The resulting constructive algorithm is exponential in nature and, therefore, not directly applicable to practical scenarios. To counter the situation, we propose theoretically devised geometric constraints that enable an efficient pruning of the solution space and develop a heuristic randomized search algorithm that uses these constraints to obtain an effective solution. We demonstrate the effectiveness of our algorithm on extensive simulations as well as in a challenging real-world calibration scenario.</p><p>6 0.18864095 <a title="400-tfidf-6" href="./cvpr-2013-A_Theory_of_Refractive_Photo-Light-Path_Triangulation.html">27 cvpr-2013-A Theory of Refractive Photo-Light-Path Triangulation</a></p>
<p>7 0.15395896 <a title="400-tfidf-7" href="./cvpr-2013-Determining_Motion_Directly_from_Normal_Flows_Upon_the_Use_of_a_Spherical_Eye_Platform.html">124 cvpr-2013-Determining Motion Directly from Normal Flows Upon the Use of a Spherical Eye Platform</a></p>
<p>8 0.13731226 <a title="400-tfidf-8" href="./cvpr-2013-Decoding%2C_Calibration_and_Rectification_for_Lenselet-Based_Plenoptic_Cameras.html">102 cvpr-2013-Decoding, Calibration and Rectification for Lenselet-Based Plenoptic Cameras</a></p>
<p>9 0.13419753 <a title="400-tfidf-9" href="./cvpr-2013-Three-Dimensional_Bilateral_Symmetry_Plane_Estimation_in_the_Phase_Domain.html">432 cvpr-2013-Three-Dimensional Bilateral Symmetry Plane Estimation in the Phase Domain</a></p>
<p>10 0.12394962 <a title="400-tfidf-10" href="./cvpr-2013-Reconstructing_Gas_Flows_Using_Light-Path_Approximation.html">349 cvpr-2013-Reconstructing Gas Flows Using Light-Path Approximation</a></p>
<p>11 0.10752964 <a title="400-tfidf-11" href="./cvpr-2013-Rolling_Shutter_Camera_Calibration.html">368 cvpr-2013-Rolling Shutter Camera Calibration</a></p>
<p>12 0.10526274 <a title="400-tfidf-12" href="./cvpr-2013-Principal_Observation_Ray_Calibration_for_Tiled-Lens-Array_Integral_Imaging_Display.html">337 cvpr-2013-Principal Observation Ray Calibration for Tiled-Lens-Array Integral Imaging Display</a></p>
<p>13 0.093607381 <a title="400-tfidf-13" href="./cvpr-2013-Articulated_and_Restricted_Motion_Subspaces_and_Their_Signatures.html">46 cvpr-2013-Articulated and Restricted Motion Subspaces and Their Signatures</a></p>
<p>14 0.088836834 <a title="400-tfidf-14" href="./cvpr-2013-Motion_Estimation_for_Self-Driving_Cars_with_a_Generalized_Camera.html">290 cvpr-2013-Motion Estimation for Self-Driving Cars with a Generalized Camera</a></p>
<p>15 0.08788085 <a title="400-tfidf-15" href="./cvpr-2013-Learning_and_Calibrating_Per-Location_Classifiers_for_Visual_Place_Recognition.html">260 cvpr-2013-Learning and Calibrating Per-Location Classifiers for Visual Place Recognition</a></p>
<p>16 0.083527103 <a title="400-tfidf-16" href="./cvpr-2013-Globally_Consistent_Multi-label_Assignment_on_the_Ray_Space_of_4D_Light_Fields.html">188 cvpr-2013-Globally Consistent Multi-label Assignment on the Ray Space of 4D Light Fields</a></p>
<p>17 0.082924485 <a title="400-tfidf-17" href="./cvpr-2013-BRDF_Slices%3A_Accurate_Adaptive_Anisotropic_Appearance_Acquisition.html">54 cvpr-2013-BRDF Slices: Accurate Adaptive Anisotropic Appearance Acquisition</a></p>
<p>18 0.082902096 <a title="400-tfidf-18" href="./cvpr-2013-Physically_Plausible_3D_Scene_Tracking%3A_The_Single_Actor_Hypothesis.html">331 cvpr-2013-Physically Plausible 3D Scene Tracking: The Single Actor Hypothesis</a></p>
<p>19 0.082274146 <a title="400-tfidf-19" href="./cvpr-2013-Radial_Distortion_Self-Calibration.html">344 cvpr-2013-Radial Distortion Self-Calibration</a></p>
<p>20 0.077461183 <a title="400-tfidf-20" href="./cvpr-2013-Dense_Reconstruction_Using_3D_Object_Shape_Priors.html">111 cvpr-2013-Dense Reconstruction Using 3D Object Shape Priors</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.135), (1, 0.166), (2, -0.007), (3, 0.021), (4, -0.014), (5, -0.089), (6, -0.055), (7, -0.016), (8, 0.06), (9, 0.019), (10, -0.07), (11, 0.15), (12, 0.093), (13, -0.092), (14, -0.193), (15, 0.02), (16, 0.149), (17, 0.121), (18, -0.065), (19, 0.093), (20, 0.096), (21, -0.014), (22, -0.128), (23, -0.079), (24, -0.03), (25, 0.045), (26, -0.019), (27, 0.07), (28, -0.005), (29, 0.024), (30, 0.002), (31, -0.014), (32, 0.06), (33, -0.032), (34, 0.035), (35, 0.008), (36, 0.041), (37, -0.015), (38, -0.005), (39, 0.028), (40, 0.011), (41, 0.019), (42, 0.028), (43, 0.048), (44, 0.01), (45, 0.15), (46, 0.075), (47, 0.048), (48, -0.128), (49, -0.126)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94525367 <a title="400-lsi-1" href="./cvpr-2013-Single_Image_Calibration_of_Multi-axial_Imaging_Systems.html">400 cvpr-2013-Single Image Calibration of Multi-axial Imaging Systems</a></p>
<p>Author: Amit Agrawal, Srikumar Ramalingam</p><p>Abstract: Imaging systems consisting of a camera looking at multiple spherical mirrors (reflection) or multiple refractive spheres (refraction) have been used for wide-angle imaging applications. We describe such setups as multi-axial imaging systems, since a single sphere results in an axial system. Assuming an internally calibrated camera, calibration of such multi-axial systems involves estimating the sphere radii and locations in the camera coordinate system. However, previous calibration approaches require manual intervention or constrained setups. We present a fully automatic approach using a single photo of a 2D calibration grid. The pose of the calibration grid is assumed to be unknown and is also recovered. Our approach can handle unconstrained setups, where the mirrors/refractive balls can be arranged in any fashion, not necessarily on a grid. The axial nature of rays allows us to compute the axis of each sphere separately. We then show that by choosing rays from two or more spheres, the unknown pose of the calibration grid can be obtained linearly and independently of sphere radii and locations. Knowing the pose, we derive analytical solutions for obtaining the sphere radius and location. This leads to an interesting result that 6-DOF pose estimation of a multi-axial camera can be done without the knowledge of full calibration. Simulations and real experiments demonstrate the applicability of our algorithm.</p><p>2 0.81436473 <a title="400-lsi-2" href="./cvpr-2013-Underwater_Camera_Calibration_Using_Wavelength_Triangulation.html">447 cvpr-2013-Underwater Camera Calibration Using Wavelength Triangulation</a></p>
<p>Author: Timothy Yau, Minglun Gong, Yee-Hong Yang</p><p>Abstract: In underwater imagery, the image formation process includes refractions that occur when light passes from water into the camera housing, typically through a flat glass port. We extend the existing work on physical refraction models by considering the dispersion of light, and derive new constraints on the model parameters for use in calibration. This leads to a novel calibration method that achieves improved accuracy compared to existing work. We describe how to construct a novel calibration device for our method and evaluate the accuracy of the method through synthetic and real experiments.</p><p>3 0.77808672 <a title="400-lsi-3" href="./cvpr-2013-Discovering_the_Structure_of_a_Planar_Mirror_System_from_Multiple_Observations_of_a_Single_Point.html">127 cvpr-2013-Discovering the Structure of a Planar Mirror System from Multiple Observations of a Single Point</a></p>
<p>Author: Ilya Reshetouski, Alkhazur Manakov, Ayush Bandhari, Ramesh Raskar, Hans-Peter Seidel, Ivo Ihrke</p><p>Abstract: We investigate the problem of identifying the position of a viewer inside a room of planar mirrors with unknown geometry in conjunction with the room’s shape parameters. We consider the observations to consist of angularly resolved depth measurements of a single scene point that is being observed via many multi-bounce interactions with the specular room geometry. Applications of this problem statement include areas such as calibration, acoustic echo cancelation and time-of-flight imaging. We theoretically analyze the problem and derive sufficient conditions for a combination of convex room geometry, observer, and scene point to be reconstructable. The resulting constructive algorithm is exponential in nature and, therefore, not directly applicable to practical scenarios. To counter the situation, we propose theoretically devised geometric constraints that enable an efficient pruning of the solution space and develop a heuristic randomized search algorithm that uses these constraints to obtain an effective solution. We demonstrate the effectiveness of our algorithm on extensive simulations as well as in a challenging real-world calibration scenario.</p><p>4 0.72006971 <a title="400-lsi-4" href="./cvpr-2013-Reconstructing_Gas_Flows_Using_Light-Path_Approximation.html">349 cvpr-2013-Reconstructing Gas Flows Using Light-Path Approximation</a></p>
<p>Author: Yu Ji, Jinwei Ye, Jingyi Yu</p><p>Abstract: Transparent gas flows are difficult to reconstruct: the refractive index field (RIF) within the gas volume is uneven and rapidly evolving, and correspondence matching under distortions is challenging. We present a novel computational imaging solution by exploiting the light field probe (LFProbe). A LF-probe resembles a view-dependent pattern where each pixel on the pattern maps to a unique ray. By . ude l. edu observing the LF-probe through the gas flow, we acquire a dense set of ray-ray correspondences and then reconstruct their light paths. To recover the RIF, we use Fermat’s Principle to correlate each light path with the RIF via a Partial Differential Equation (PDE). We then develop an iterative optimization scheme to solve for all light-path PDEs in conjunction. Specifically, we initialize the light paths by fitting Hermite splines to ray-ray correspondences, discretize their PDEs onto voxels, and solve a large, over-determined PDE system for the RIF. The RIF can then be used to refine the light paths. Finally, we alternate the RIF and light-path estimations to improve the reconstruction. Experiments on synthetic and real data show that our approach can reliably reconstruct small to medium scale gas flows. In particular, when the flow is acquired by a small number of cameras, the use of ray-ray correspondences can greatly improve the reconstruction.</p><p>5 0.71379966 <a title="400-lsi-5" href="./cvpr-2013-Can_a_Fully_Unconstrained_Imaging_Model_Be_Applied_Effectively_to_Central_Cameras%3F.html">76 cvpr-2013-Can a Fully Unconstrained Imaging Model Be Applied Effectively to Central Cameras?</a></p>
<p>Author: Filippo Bergamasco, Andrea Albarelli, Emanuele Rodolà, Andrea Torsello</p><p>Abstract: Traditional camera models are often the result of a compromise between the ability to account for non-linearities in the image formation model and the need for a feasible number of degrees of freedom in the estimation process. These considerations led to the definition of several ad hoc models that best adapt to different imaging devices, ranging from pinhole cameras with no radial distortion to the more complex catadioptric or polydioptric optics. In this paper we dai s .unive . it ence points in the scene with their projections on the image plane [5]. Unfortunately, no real camera behaves exactly like an ideal pinhole. In fact, in most cases, at least the distortion effects introduced by the lens should be accounted for [19]. Any pinhole-based model, regardless of its level of sophistication, is geometrically unable to properly describe cameras exhibiting a frustum angle that is near or above 180 degrees. For wide-angle cameras, several different para- metric models have been proposed. Some of them try to modify the captured image in order to follow the original propose the use of an unconstrained model even in standard central camera settings dominated by the pinhole model, and introduce a novel calibration approach that can deal effectively with the huge number of free parameters associated with it, resulting in a higher precision calibration than what is possible with the standard pinhole model with correction for radial distortion. This effectively extends the use of general models to settings that traditionally have been ruled by parametric approaches out of practical considerations. The benefit of such an unconstrained model to quasipinhole central cameras is supported by an extensive experimental validation.</p><p>6 0.70147496 <a title="400-lsi-6" href="./cvpr-2013-A_Theory_of_Refractive_Photo-Light-Path_Triangulation.html">27 cvpr-2013-A Theory of Refractive Photo-Light-Path Triangulation</a></p>
<p>7 0.68781847 <a title="400-lsi-7" href="./cvpr-2013-Mirror_Surface_Reconstruction_from_a_Single_Image.html">286 cvpr-2013-Mirror Surface Reconstruction from a Single Image</a></p>
<p>8 0.66423291 <a title="400-lsi-8" href="./cvpr-2013-Principal_Observation_Ray_Calibration_for_Tiled-Lens-Array_Integral_Imaging_Display.html">337 cvpr-2013-Principal Observation Ray Calibration for Tiled-Lens-Array Integral Imaging Display</a></p>
<p>9 0.63270086 <a title="400-lsi-9" href="./cvpr-2013-Decoding%2C_Calibration_and_Rectification_for_Lenselet-Based_Plenoptic_Cameras.html">102 cvpr-2013-Decoding, Calibration and Rectification for Lenselet-Based Plenoptic Cameras</a></p>
<p>10 0.6224882 <a title="400-lsi-10" href="./cvpr-2013-Manhattan_Scene_Understanding_via_XSlit_Imaging.html">279 cvpr-2013-Manhattan Scene Understanding via XSlit Imaging</a></p>
<p>11 0.59391266 <a title="400-lsi-11" href="./cvpr-2013-Rolling_Shutter_Camera_Calibration.html">368 cvpr-2013-Rolling Shutter Camera Calibration</a></p>
<p>12 0.58332151 <a title="400-lsi-12" href="./cvpr-2013-Light_Field_Distortion_Feature_for_Transparent_Object_Recognition.html">269 cvpr-2013-Light Field Distortion Feature for Transparent Object Recognition</a></p>
<p>13 0.53709573 <a title="400-lsi-13" href="./cvpr-2013-Shape_from_Silhouette_Probability_Maps%3A_Reconstruction_of_Thin_Objects_in_the_Presence_of_Silhouette_Extraction_and_Calibration_Error.html">395 cvpr-2013-Shape from Silhouette Probability Maps: Reconstruction of Thin Objects in the Presence of Silhouette Extraction and Calibration Error</a></p>
<p>14 0.52689028 <a title="400-lsi-14" href="./cvpr-2013-Specular_Reflection_Separation_Using_Dark_Channel_Prior.html">410 cvpr-2013-Specular Reflection Separation Using Dark Channel Prior</a></p>
<p>15 0.50963897 <a title="400-lsi-15" href="./cvpr-2013-Three-Dimensional_Bilateral_Symmetry_Plane_Estimation_in_the_Phase_Domain.html">432 cvpr-2013-Three-Dimensional Bilateral Symmetry Plane Estimation in the Phase Domain</a></p>
<p>16 0.49955162 <a title="400-lsi-16" href="./cvpr-2013-Motion_Estimation_for_Self-Driving_Cars_with_a_Generalized_Camera.html">290 cvpr-2013-Motion Estimation for Self-Driving Cars with a Generalized Camera</a></p>
<p>17 0.49093816 <a title="400-lsi-17" href="./cvpr-2013-Video_Enhancement_of_People_Wearing_Polarized_Glasses%3A_Darkening_Reversal_and_Reflection_Reduction.html">454 cvpr-2013-Video Enhancement of People Wearing Polarized Glasses: Darkening Reversal and Reflection Reduction</a></p>
<p>18 0.48146194 <a title="400-lsi-18" href="./cvpr-2013-Megastereo%3A_Constructing_High-Resolution_Stereo_Panoramas.html">283 cvpr-2013-Megastereo: Constructing High-Resolution Stereo Panoramas</a></p>
<p>19 0.47933671 <a title="400-lsi-19" href="./cvpr-2013-Axially_Symmetric_3D_Pots_Configuration_System_Using_Axis_of_Symmetry_and_Break_Curve.html">52 cvpr-2013-Axially Symmetric 3D Pots Configuration System Using Axis of Symmetry and Break Curve</a></p>
<p>20 0.45697504 <a title="400-lsi-20" href="./cvpr-2013-Determining_Motion_Directly_from_Normal_Flows_Upon_the_Use_of_a_Spherical_Eye_Platform.html">124 cvpr-2013-Determining Motion Directly from Normal Flows Upon the Use of a Spherical Eye Platform</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.15), (16, 0.05), (26, 0.048), (33, 0.198), (47, 0.01), (67, 0.065), (69, 0.044), (83, 0.261), (87, 0.087)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.81421179 <a title="400-lda-1" href="./cvpr-2013-Single_Image_Calibration_of_Multi-axial_Imaging_Systems.html">400 cvpr-2013-Single Image Calibration of Multi-axial Imaging Systems</a></p>
<p>Author: Amit Agrawal, Srikumar Ramalingam</p><p>Abstract: Imaging systems consisting of a camera looking at multiple spherical mirrors (reflection) or multiple refractive spheres (refraction) have been used for wide-angle imaging applications. We describe such setups as multi-axial imaging systems, since a single sphere results in an axial system. Assuming an internally calibrated camera, calibration of such multi-axial systems involves estimating the sphere radii and locations in the camera coordinate system. However, previous calibration approaches require manual intervention or constrained setups. We present a fully automatic approach using a single photo of a 2D calibration grid. The pose of the calibration grid is assumed to be unknown and is also recovered. Our approach can handle unconstrained setups, where the mirrors/refractive balls can be arranged in any fashion, not necessarily on a grid. The axial nature of rays allows us to compute the axis of each sphere separately. We then show that by choosing rays from two or more spheres, the unknown pose of the calibration grid can be obtained linearly and independently of sphere radii and locations. Knowing the pose, we derive analytical solutions for obtaining the sphere radius and location. This leads to an interesting result that 6-DOF pose estimation of a multi-axial camera can be done without the knowledge of full calibration. Simulations and real experiments demonstrate the applicability of our algorithm.</p><p>2 0.75288123 <a title="400-lda-2" href="./cvpr-2013-Three-Dimensional_Bilateral_Symmetry_Plane_Estimation_in_the_Phase_Domain.html">432 cvpr-2013-Three-Dimensional Bilateral Symmetry Plane Estimation in the Phase Domain</a></p>
<p>Author: Ramakrishna Kakarala, Prabhu Kaliamoorthi, Vittal Premachandran</p><p>Abstract: We show that bilateral symmetry plane estimation for three-dimensional (3-D) shapes may be carried out accurately, and efficiently, in the spherical harmonic domain. Our methods are valuable for applications where spherical harmonic expansion is already employed, such as 3-D shape registration, morphometry, and retrieval. We show that the presence of bilateral symmetry in the 3-D shape is equivalent to a linear phase structure in the corresponding spherical harmonic coefficients, and provide algorithms for estimating the orientation of the symmetry plane. The benefit of using spherical harmonic phase is that symmetry estimation reduces to matching a compact set of descriptors, without the need to solve a correspondence problem. Our methods work on point clouds as well as large-scale mesh models of 3-D shapes.</p><p>3 0.72688383 <a title="400-lda-3" href="./cvpr-2013-Dense_Non-rigid_Point-Matching_Using_Random_Projections.html">109 cvpr-2013-Dense Non-rigid Point-Matching Using Random Projections</a></p>
<p>Author: Raffay Hamid, Dennis Decoste, Chih-Jen Lin</p><p>Abstract: We present a robust and efficient technique for matching dense sets of points undergoing non-rigid spatial transformations. Our main intuition is that the subset of points that can be matched with high confidence should be used to guide the matching procedure for the rest. We propose a novel algorithm that incorporates these high-confidence matches as a spatial prior to learn a discriminative subspace that simultaneously encodes both the feature similarity as well as their spatial arrangement. Conventional subspace learning usually requires spectral decomposition of the pair-wise distance matrix across the point-sets, which can become inefficient even for moderately sized problems. To this end, we propose the use of random projections for approximate subspace learning, which can provide significant time improvements at the cost of minimal precision loss. This efficiency gain allows us to iteratively find and remove high-confidence matches from the point sets, resulting in high recall. To show the effectiveness of our approach, we present a systematic set of experiments and results for the problem of dense non-rigid image-feature matching.</p><p>4 0.70487577 <a title="400-lda-4" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>Author: Ian Endres, Kevin J. Shih, Johnston Jiaa, Derek Hoiem</p><p>Abstract: We propose a method to learn a diverse collection of discriminative parts from object bounding box annotations. Part detectors can be trained and applied individually, which simplifies learning and extension to new features or categories. We apply the parts to object category detection, pooling part detections within bottom-up proposed regions and using a boosted classifier with proposed sigmoid weak learners for scoring. On PASCAL VOC 2010, we evaluate the part detectors ’ ability to discriminate and localize annotated keypoints. Our detection system is competitive with the best-existing systems, outperforming other HOG-based detectors on the more deformable categories.</p><p>5 0.70225656 <a title="400-lda-5" href="./cvpr-2013-Dense_Reconstruction_Using_3D_Object_Shape_Priors.html">111 cvpr-2013-Dense Reconstruction Using 3D Object Shape Priors</a></p>
<p>Author: Amaury Dame, Victor A. Prisacariu, Carl Y. Ren, Ian Reid</p><p>Abstract: We propose a formulation of monocular SLAM which combines live dense reconstruction with shape priors-based 3D tracking and reconstruction. Current live dense SLAM approaches are limited to the reconstruction of visible surfaces. Moreover, most of them are based on the minimisation of a photo-consistency error, which usually makes them sensitive to specularities. In the 3D pose recovery literature, problems caused by imperfect and ambiguous image information have been dealt with by using prior shape knowledge. At the same time, the success of depth sensors has shown that combining joint image and depth information drastically increases the robustness of the classical monocular 3D tracking and 3D reconstruction approaches. In this work we link dense SLAM to 3D object pose and shape recovery. More specifically, we automatically augment our SLAMsystem with object specific identity, together with 6D pose and additional shape degrees of freedom for the object(s) of known class in the scene, combining im- age data and depth information for the pose and shape recovery. This leads to a system that allows for full scaled 3D reconstruction with the known object(s) segmented from the scene. The segmentation enhances the clarity, accuracy and completeness of the maps built by the dense SLAM system, while the dense 3D data aids the segmentation process, yieldingfaster and more reliable convergence than when using 2D image data alone.</p><p>6 0.7014358 <a title="400-lda-6" href="./cvpr-2013-What_Object_Motion_Reveals_about_Shape_with_Unknown_BRDF_and_Lighting.html">465 cvpr-2013-What Object Motion Reveals about Shape with Unknown BRDF and Lighting</a></p>
<p>7 0.69975728 <a title="400-lda-7" href="./cvpr-2013-Structure_Preserving_Object_Tracking.html">414 cvpr-2013-Structure Preserving Object Tracking</a></p>
<p>8 0.69944191 <a title="400-lda-8" href="./cvpr-2013-POOF%3A_Part-Based_One-vs.-One_Features_for_Fine-Grained_Categorization%2C_Face_Verification%2C_and_Attribute_Estimation.html">323 cvpr-2013-POOF: Part-Based One-vs.-One Features for Fine-Grained Categorization, Face Verification, and Attribute Estimation</a></p>
<p>9 0.69656539 <a title="400-lda-9" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<p>10 0.69647765 <a title="400-lda-10" href="./cvpr-2013-Integrating_Grammar_and_Segmentation_for_Human_Pose_Estimation.html">225 cvpr-2013-Integrating Grammar and Segmentation for Human Pose Estimation</a></p>
<p>11 0.69618744 <a title="400-lda-11" href="./cvpr-2013-Part-Based_Visual_Tracking_with_Online_Latent_Structural_Learning.html">324 cvpr-2013-Part-Based Visual Tracking with Online Latent Structural Learning</a></p>
<p>12 0.69540423 <a title="400-lda-12" href="./cvpr-2013-Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking.html">285 cvpr-2013-Minimum Uncertainty Gap for Robust Visual Tracking</a></p>
<p>13 0.69501287 <a title="400-lda-13" href="./cvpr-2013-Spatiotemporal_Deformable_Part_Models_for_Action_Detection.html">408 cvpr-2013-Spatiotemporal Deformable Part Models for Action Detection</a></p>
<p>14 0.69498402 <a title="400-lda-14" href="./cvpr-2013-Online_Object_Tracking%3A_A_Benchmark.html">314 cvpr-2013-Online Object Tracking: A Benchmark</a></p>
<p>15 0.69457972 <a title="400-lda-15" href="./cvpr-2013-Physically_Plausible_3D_Scene_Tracking%3A_The_Single_Actor_Hypothesis.html">331 cvpr-2013-Physically Plausible 3D Scene Tracking: The Single Actor Hypothesis</a></p>
<p>16 0.69372314 <a title="400-lda-16" href="./cvpr-2013-Part_Discovery_from_Partial_Correspondence.html">325 cvpr-2013-Part Discovery from Partial Correspondence</a></p>
<p>17 0.69135976 <a title="400-lda-17" href="./cvpr-2013-Cross-View_Action_Recognition_via_a_Continuous_Virtual_Path.html">98 cvpr-2013-Cross-View Action Recognition via a Continuous Virtual Path</a></p>
<p>18 0.69073313 <a title="400-lda-18" href="./cvpr-2013-Voxel_Cloud_Connectivity_Segmentation_-_Supervoxels_for_Point_Clouds.html">458 cvpr-2013-Voxel Cloud Connectivity Segmentation - Supervoxels for Point Clouds</a></p>
<p>19 0.69039738 <a title="400-lda-19" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<p>20 0.69006866 <a title="400-lda-20" href="./cvpr-2013-Underwater_Camera_Calibration_Using_Wavelength_Triangulation.html">447 cvpr-2013-Underwater Camera Calibration Using Wavelength Triangulation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
