<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>165 cvpr-2013-Fast Energy Minimization Using Learned State Filters</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-165" href="#">cvpr2013-165</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>165 cvpr-2013-Fast Energy Minimization Using Learned State Filters</h1>
<br/><p>Source: <a title="cvpr-2013-165-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Guillaumin_Fast_Energy_Minimization_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Matthieu Guillaumin, Luc Van_Gool, Vittorio Ferrari</p><p>Abstract: Pairwise discrete energies defined over graphs are ubiquitous in computer vision. Many algorithms have been proposed to minimize such energies, often concentrating on sparse graph topologies or specialized classes of pairwise potentials. However, when the graph is fully connected and the pairwise potentials are arbitrary, the complexity of even approximate minimization algorithms such as TRW-S grows quadratically both in the number of nodes and in the number of states a node can take. Moreover, recent applications are using more and more computationally expensive pairwise potentials. These factors make it very hard to employ fully connected models. In this paper we propose a novel, generic algorithm to approximately minimize any discrete pairwise energy function. Our method exploits tractable sub-energies to filter the domain of the function. The parameters of the filter are learnt from instances of the same class of energies with good candidate solutions. Compared to existing methods, it efficiently handles fully connected graphs, with many states per node, and arbitrary pairwise potentials, which might be expensive to compute. We demonstrate experimentally on two applications that our algorithm is much more efficient than other generic minimization algorithms such as TRW-S, while returning essentially identical solutions.</p><p>Reference: <a title="cvpr-2013-165-reference" href="../cvpr2013_reference/cvpr-2013-Fast_Energy_Minimization_Using_Learned_State_Filters_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Many algorithms have been proposed to minimize such energies, often concentrating on sparse graph topologies or specialized classes of pairwise potentials. [sent-11, score-0.422]
</p><p>2 However, when the graph is fully connected and the pairwise potentials are arbitrary, the complexity of even approximate minimization algorithms such as TRW-S grows quadratically both in the number of nodes and in the number of states a node can take. [sent-12, score-1.577]
</p><p>3 In this paper we propose a novel, generic algorithm to approximately minimize any discrete pairwise energy function. [sent-15, score-0.539]
</p><p>4 Compared to existing methods, it efficiently handles fully connected graphs, with many states per node, and arbitrary pairwise potentials, which might be expensive to compute. [sent-18, score-1.045]
</p><p>5 Introduction Models requiring the minimization of a discrete pairwise energy defined over a graph are very common in computer vision. [sent-21, score-0.652]
</p><p>6 An edge (n, m) ∈ E connecting nodes n and m ha→s an aAsnso ecdiagteed ( pairwise energy nfuencctitnigon n En,m : L ann ×d Lmm h a→s aRn. [sent-26, score-0.575]
</p><p>7 With these definitions, the energy of a configuration of states x = [x1 · · · , x|V|] ∈ L is ? [sent-29, score-0.694]
</p><p>8 ,m) ∈E The fundamental task of finding the configuration of states x∗L = [x∗1, ··· , x|∗V|] ∈ L that minimizes (1) is often refeLrred to inference,|V Vb|]eca ∈us Le othfa athte m reinlaimtioizne tso ( 1th)e probabilistic models that typically lead to such energies. [sent-35, score-0.547]
</p><p>9 These models have been employed to address many lowlevel vision problems, where nodes are pixels and pairwise terms act as spatial regularization of the state configuration, e. [sent-36, score-0.618]
</p><p>10 Recently, higher-level applications of such energies have emerged, where nodes represent a larger variety of visual elements: body parts [22, 24], superpixels [21, 3 1], image windows [2, 9]. [sent-39, score-0.407]
</p><p>11 Here, pairwise terms often express more complex interactions such as kinematic constraints [22], semantic consistency [21], or appearance similarity of whole objects [9, 32]. [sent-40, score-0.461]
</p><p>12 The number of nodes, the density of the pairwise terms and the size of the state spaces increase. [sent-43, score-0.563]
</p><p>13 At the same time the pairwise terms are more and more arbitrary and computationally expensive. [sent-44, score-0.383]
</p><p>14 As an example, [16] uses fully connected graphs over all pixels in a image for semantic segmentation, using linear combination of Gaussians as pairwise potentials. [sent-45, score-0.756]
</p><p>15 In weakly supervised object localization, [9] uses fully connected graphs where nodes represent images and their state spaces have 100 to 1000 candidate windows for the location of an object. [sent-46, score-1.021]
</p><p>16 Such pairwise terms are arbitrary in that they have no particular form. [sent-48, score-0.383]
</p><p>17 Analog models have been recently proposed for co-detection [2] and co-segmentation [32] where discrete energy minimization is used to match candidate windows or segments across images. [sent-49, score-0.417]
</p><p>18 Densely connected  graphs are also emerging for human pose estimation [27], while at the same time the pairwise terms relating the body parts are becoming more expensive, evolving from simple truncated spatial priors [22] to similarity in appearance de111666888200  scriptors [24]. [sent-50, score-0.67]
</p><p>19 This adds to the computational burden already imposed by the very large state spaces typical for such models, as they correspond to all possible body part positions (10k-100k states [22, 24]). [sent-51, score-0.647]
</p><p>20 For example, the popular TRW-S algorithm [13] poses no restrictions on connectivity, number of states, nor form of the pairwise potential, but its memory and computational complexity grow quadratically in the number of states and linearly in the number of edges (i. [sent-53, score-0.798]
</p><p>21 Our method progressively filters node states in an iterative fashion. [sent-64, score-0.675]
</p><p>22 Filtering node states is made possible by automatically specializing to a particular family of problems during a training stage. [sent-67, score-0.591]
</p><p>23 different input images in semantic segmentation [3 1, 16, 25], or different input image sets in weakly supervised localization [9, 26, 20]). [sent-70, score-0.383]
</p><p>24 Our method then learns filters to discard as many states as possible without losing any state in the reference labeling. [sent-72, score-0.745]
</p><p>25 In this fashion, our method exploits the fact that the distribution of unary and pairwise energies will be similar on new problem instances, and is very efficient because it focuses where computational savings are likely to be obtained. [sent-73, score-0.477]
</p><p>26 Through experiments on two challenging applications (weakly supervised object localization and semantic segmentation), we demonstrate that our minimization algorithm is on average 20 faster than TRW-S [13] while returning essentially eid 2en0t×ic faal configurations -oSf [s1ta3te]s w (hseilce. [sent-77, score-0.405]
</p><p>27 Related Work Below, we group discrete pairwise energy minimization algorithms according to their operating conditions. [sent-80, score-0.566]
</p><p>28 A well-known class of tractable problems are energies defined over low treewidth graphs, with potentially many states in the nodes, and an arbitrary form of the pairwise terms. [sent-82, score-1.004]
</p><p>29 Belief Propagation on trees has complexity O(H2N), with H the (average) number of states in a node and N the number of nodes [4]. [sent-85, score-0.797]
</p><p>30 Graphcut algorithms perform fast and exact inference in models with two states and submodular pairwise terms [14], regardless of their connectivity. [sent-89, score-0.829]
</p><p>31 Move-making extensions of Graph-cut such as α/β-swap, α-expansion [6] support more than two states (often less than 100 [31, 6, 3]). [sent-90, score-0.418]
</p><p>32 Other forms of potentials that lends themselves for efficient inference include truncated convex [17], truncated to a small subset of state pairs [22], data independent [19], Gaussian [16], or where distance transforms are applicable [10, 11]. [sent-92, score-0.53]
</p><p>33 With two states and arbitrary pairwise terms, the roof duality algorithm [12, 23] produces partial solutions, where some nodes might be left unlabeled. [sent-96, score-0.961]
</p><p>34 Some message passing algorithms can approximately minimize generic pairwise energies, e. [sent-98, score-0.564]
</p><p>35 As the complexity of these methods is quadratic in the number of states and linear in the number of edges, they eventually struggle as the number of nodes increases, the graph becomes denser, and as the state space grows. [sent-101, score-0.788]
</p><p>36 These generic methods require computing all pairwise potentials, which for some models might be more expensive than inference itself [9]. [sent-103, score-0.514]
</p><p>37 In contrast, our filters are learned to be optimal for a particular problem class, and avoid unnecessary pairwise computations. [sent-104, score-0.429]
</p><p>38 Progressive state filtering In this section we describe our approach for fast minimization of pairwise energy functions. [sent-109, score-0.778]
</p><p>39 Filter  the  graph until  convergence  remaining states (darker = more states). [sent-115, score-0.504]
</p><p>40 The thickness of an edge illustrates the number of remaining pairwise potentials on it. [sent-116, score-0.479]
</p><p>41 The red edges account for all the pairwise potentials that are computed by our method. [sent-118, score-0.521]
</p><p>42 They compound to only a small fraction of all pairwise potentials in the original graph (especially in fully connected models with many nodes). [sent-119, score-0.806]
</p><p>43 ×InV t hanesde w cases even just computing all the pairwise potentials can become impractical, although they are typically needed for generic message passing algorithms [4, 13, 33]. [sent-136, score-0.744]
</p><p>44 (2), our method sparsifies the original  ×  problem so as to contain much fewer pairwise potentials, while retaining the same optimal configuration. [sent-140, score-0.41]
</p><p>45 More precisely, we iteratively filter the state space of a node by discarding states that are very unlikely to belong to the optimal configuration x∗L. [sent-141, score-1.106]
</p><p>46 Applying this idea to all nodes makes the number of pairwise terms drastically smaller, which has a positive impact both on the memory and the computational complexity of inference. [sent-143, score-0.463]
</p><p>47 For a node n and its state space Ln, a filter f(1) is a function that partitions Ln in two subsets: the states to keep and the states Ln \ to discard. [sent-145, score-1.271]
</p><p>48 After filtering, the energy (2) rsetamteasin Ls t\heL same, but the configuration space becomes L(1) = ··· × the filter retains the optimal  L(n1)  iLn(n t1w)  L1(1)  L(|1V|). [sent-146, score-0.458]
</p><p>49 different input images in semantic segmentation) so as to learn to discard as many states as possible, while preserving states likely to belong to the optimum of the original model. [sent-152, score-1.147]
</p><p>50 For this purpose, we propose filters that are functions of the min-marginals of a node  computed on a spanning tree of the original graph (sec. [sent-155, score-0.609]
</p><p>51 The key intuition is that such a min-marginal already contains reliable indications about which states are definitely not part of the optimal configuration of the full model. [sent-158, score-0.585]
</p><p>52 After applying the filter f(1) , in the second iteration we repeat the operation on L(1) with a second filter f(2) , leading to the pruned state spaces . [sent-159, score-0.554]
</p><p>53 1 at each iteration the node states spaces become smaller and consequently the edges become ‘thinner’ (i. [sent-163, score-0.707]
</p><p>54 This progressive ‘discard & explore’ paradigm is the key to the success of our algorithm, as it eventually acquires a full view of the original energy function, without paying the price of evaluating all its pairwise potentials. [sent-167, score-0.54]
</p><p>55 Our filtering process stops after an iteration where no state was filtered, then we use a standard generic message passing algorithm [13] to perform inference on the heavily thinned model. [sent-168, score-0.623]
</p><p>56 Typically, at this stage only a few states are left for each node (e. [sent-169, score-0.554]
</p><p>57 3-5 in our experiments on semantic segmentation) making inference extremely rapid and leaving only few pairwise potentials to compute. [sent-171, score-0.652]
</p><p>58 We learn the threshold θ such that all states with p(yn = 1|xn) ≤ θ can be discarded (red) while keeping as few states as possible (green). [sent-182, score-0.925]
</p><p>59 Filter functions At each iteration k of our algorithm, the filter function is a binary classifier that decides whether a state of a node should be kept or discarded. [sent-185, score-0.502]
</p><p>60 The filter acts on the  f(k)  L(nk)  current state space of node n and it is a function of the min-marginal poafc tehe L node computed on a random spanning tree T of the original graph. [sent-186, score-0.866]
</p><p>61 In essence, we use logistic regression to estimate the probability (yn = 1|xn) that state xn might belong to the global optimum =o f1 |txhe original graph (yn = 1), and therefore it should be kept  Φ(Tk,n)  ≥  ≥  p(Tk)  p(Tk)(yn  = 1|xn) =  σ(w(k) · Φ(Tk,)n(xn)). [sent-193, score-0.743]
</p><p>62 (4)  The threshold θ(k) represents the probability value below which states can be safely discarded. [sent-194, score-0.46]
</p><p>63 Note how the filter parameters w(k) , θ(k) are independent of the spanning tree and the state space of node n. [sent-195, score-0.691]
</p><p>64 This enables to learn filters that generalize well over different spanning trees and can adapt to the different sizes of the state spaces of different nodes. [sent-197, score-0.66]
</p><p>65 Filter features The key element for generalizing the filters over spanning trees and nodes is the choice of feature map A very good basis for this feature map are the min-  Φ(Tk,n)(xn). [sent-205, score-0.528]
</p><p>66 On a general graph, the min-marginal of state xn is the minimum energy that can be obtained over the whole configuration space L twhahetn c anno dbee n bhtaasi setadt eo xn  μn(xn) =xˆ ∈Lm, xˆinn=xnEL( xˆ). [sent-207, score-0.967]
</p><p>67 (5)  When restricted to a spanning tree T, the energy and minmarginals of a graph are simply summed only over the edges in T ET(x) =  ? [sent-208, score-0.604]
</p><p>68 First, a spanning tree is the sparsest substructure that connects all the nodes in a graph. [sent-214, score-0.385]
</p><p>69 The cost of computing all minmarginals of all nodes of T is only about the same as finding the minimum configuration of states on T. [sent-218, score-0.749]
</p><p>70 Despite observing only part of the information in the original graph, the min-marginals of a spanning tree already contain powerful cues for identifying states unlikely to be part of the optimal configuration of the full graph. [sent-220, score-0.88]
</p><p>71 The difference between the min-marginal of state xn and the best state: μT,n (xn) − min ˆxn μT,n ( xˆn). [sent-222, score-0.423]
</p><p>72 The rank of xn in the sorted list μT,n (·) of all states of node n. [sent-226, score-0.822]
</p><p>73 We run ToRnW t-rSai [n1in3]g on stthanescee training graphs t oof fo pbrtoaibntheir optimal configuration of states (or a very good approximation if the global optimum is not achievable). [sent-240, score-0.843]
</p><p>74 This provides a reference low-energy positive (yn = 1) state xn for each node x (i. [sent-241, score-0.59]
</p><p>75 Hanedncoev,e we leesaprnan nwni(nkg) ttroe mesaTximize the likelihood of the correct prediction for all the states of all nodes of all instances, leading to the following objective  |L(nk)  ? [sent-245, score-0.547]
</p><p>76 Note how the training set is imbalanced, as there are many more negative states in the reference labelling than positives. [sent-259, score-0.486]
</p><p>77 The latter should be absolutely avoided, as discarded states can never be recovered and therefore cannot be in the final configuration output by our algorithm. [sent-266, score-0.604]
</p><p>78 (10) We first apply the learning procedure above to the original training graphs G to train the first filter f(1) . [sent-272, score-0.379]
</p><p>79 4) can change considerably as the state spaces get smaller and the fraction of good states grows. [sent-281, score-0.647]
</p><p>80 Experiments We evaluate our method on two vision problems involving large fully-connected models with pairwise potentials that have arbitrary form and are computationally expensive. [sent-285, score-0.559]
</p><p>81 Each image is a node n in a fully connected graph G∈ ∈a Ind. [sent-299, score-0.424]
</p><p>82 The pairwise potentials En,m (xn, xm) express the dissimilarity between two windows (xn, xm) in different images In and Im. [sent-303, score-0.58]
</p><p>83 As the appearance descriptor is high-dimensional, the pairwise potentials are expensive to compute (30 minutes on average 111666888644  The curves illustrate the trade-off between accurate solutions (low average energy ratio) and computational cost (computed pairwise terms). [sent-305, score-1.005]
</p><p>84 For the baseline, we vary the number of kept states  TRW-S uses all S states. [sent-311, score-0.448]
</p><p>85 Most existing works use simple grid graphs where each node is only connected to its neighbors. [sent-333, score-0.413]
</p><p>86 The interest of using fully connected graphs for semantic segmentation has been recently shown by [16]. [sent-335, score-0.51]
</p><p>87 In addition to this new term, our pairwise potential also includes a traditional contrast-sensitive label smoothness term that encourages nearby, similar-looking superpixels to take the same label [16, 25, 3 1]. [sent-360, score-0.384]
</p><p>88 Building the fully connected graph with these pairwise terms takes about 75 seconds per image on average. [sent-361, score-0.622]
</p><p>89 Results We measure the computational benefits of our progressive state filtering algorithm in three ways: (1) The number of all pairwise potentials evaluated by our method. [sent-367, score-0.778]
</p><p>90 The overhead caused by our method (sampling the tree, computing the minmarginals and filtering) is indeed negligible (around 1s); (2) The energy ratio of the best configuration of the graph filtered by our method over the best configuration of the original graph. [sent-372, score-0.658]
</p><p>91 To obtain an insight on the efficiency-vs-quality tradeoff of our approach, we have learnt state filters with various numbers of random training spanning trees (Nt = 1. [sent-377, score-0.591]
</p><p>92 Because the threshold θ is set to discard no optimal state over all training trees (eq. [sent-380, score-0.393]
</p><p>93 As a baseline, we consider keeping the K labels for each node that have the best unaries, and vary the value of K from 1to S, the number of states in the original problem. [sent-382, score-0.623]
</p><p>94 We observe: (1) For all values of Nt, our algorithm successfully computes only a small fraction of the pairwise potentials, thanks to discarding many states of many nodes. [sent-385, score-0.77]
</p><p>95 o mTphuatninkgs utop t thois 2, 0it× now etark peasi only a ofrteacn-tion of the original time to compute the potentials for object localization (on average about 100s vs 1800s) and semantic segmentation (about 3s vs 75s). [sent-401, score-0.45]
</p><p>96 (2) Discarding states also has a positive impact on the time required to perform message passing, with 3 to 4× speed-up on this componmeensts oagfe eth pea energy mithin 3im×iz taoti 4o×n procedure. [sent-402, score-0.713]
</p><p>97 (3) The energy of the best configuration of the filtered graphs are essentially identical to those of the original graphs. [sent-404, score-0.619]
</p><p>98 On both problems, our approach obtains lower energy solutions for any given number of pairwise terms. [sent-411, score-0.487]
</p><p>99 Table 1reports the pixel-level accuracies obtained for semantic segmentation with our fully connected graphs on the official test set of MSRC-21, compared to the sparse graphs of [31]. [sent-413, score-0.669]
</p><p>100 Conclusion We presented a novel minimization algorithm for discrete pairwise energies that can handle densely connected graphs, large state spaces, and arbitrary pairwise potentials. [sent-451, score-1.132]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('states', 0.418), ('pairwise', 0.299), ('xn', 0.268), ('spanning', 0.193), ('potentials', 0.18), ('graphs', 0.159), ('state', 0.155), ('energy', 0.147), ('filter', 0.144), ('node', 0.136), ('configuration', 0.129), ('nodes', 0.129), ('yn', 0.12), ('connected', 0.118), ('message', 0.115), ('trees', 0.114), ('weakly', 0.104), ('windows', 0.101), ('semantic', 0.096), ('filters', 0.092), ('energies', 0.092), ('filtering', 0.089), ('passing', 0.089), ('minimization', 0.088), ('graph', 0.086), ('superpixels', 0.085), ('fully', 0.084), ('localization', 0.082), ('treewidth', 0.082), ('inference', 0.077), ('spaces', 0.074), ('minmarginals', 0.073), ('tree', 0.063), ('optimum', 0.062), ('generic', 0.061), ('truncated', 0.059), ('discarded', 0.057), ('instances', 0.057), ('unaries', 0.056), ('progressive', 0.055), ('filtered', 0.055), ('misclassifying', 0.055), ('discarding', 0.053), ('segmentation', 0.053), ('tg', 0.053), ('returning', 0.051), ('identical', 0.05), ('nt', 0.049), ('arbitrary', 0.049), ('discard', 0.049), ('candidate', 0.049), ('supervised', 0.048), ('slower', 0.046), ('nk', 0.045), ('pervised', 0.045), ('tk', 0.045), ('unary', 0.044), ('sapp', 0.044), ('speedups', 0.042), ('safely', 0.042), ('delivered', 0.042), ('savings', 0.042), ('moves', 0.042), ('edges', 0.042), ('solutions', 0.041), ('essentially', 0.04), ('veksler', 0.04), ('original', 0.039), ('expensive', 0.039), ('quadratically', 0.039), ('optimal', 0.038), ('might', 0.038), ('topologies', 0.037), ('training', 0.037), ('iteration', 0.037), ('terms', 0.035), ('fewer', 0.034), ('belong', 0.033), ('eth', 0.033), ('tractable', 0.033), ('xm', 0.033), ('kolmogorov', 0.032), ('learn', 0.032), ('logistic', 0.032), ('alexe', 0.032), ('objectness', 0.032), ('localizing', 0.032), ('discrete', 0.032), ('class', 0.031), ('interactions', 0.031), ('reference', 0.031), ('pami', 0.031), ('involving', 0.031), ('ln', 0.031), ('deselaers', 0.03), ('labels', 0.03), ('kept', 0.03), ('progressively', 0.029), ('roof', 0.028), ('inn', 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999958 <a title="165-tfidf-1" href="./cvpr-2013-Fast_Energy_Minimization_Using_Learned_State_Filters.html">165 cvpr-2013-Fast Energy Minimization Using Learned State Filters</a></p>
<p>Author: Matthieu Guillaumin, Luc Van_Gool, Vittorio Ferrari</p><p>Abstract: Pairwise discrete energies defined over graphs are ubiquitous in computer vision. Many algorithms have been proposed to minimize such energies, often concentrating on sparse graph topologies or specialized classes of pairwise potentials. However, when the graph is fully connected and the pairwise potentials are arbitrary, the complexity of even approximate minimization algorithms such as TRW-S grows quadratically both in the number of nodes and in the number of states a node can take. Moreover, recent applications are using more and more computationally expensive pairwise potentials. These factors make it very hard to employ fully connected models. In this paper we propose a novel, generic algorithm to approximately minimize any discrete pairwise energy function. Our method exploits tractable sub-energies to filter the domain of the function. The parameters of the filter are learnt from instances of the same class of energies with good candidate solutions. Compared to existing methods, it efficiently handles fully connected graphs, with many states per node, and arbitrary pairwise potentials, which might be expensive to compute. We demonstrate experimentally on two applications that our algorithm is much more efficient than other generic minimization algorithms such as TRW-S, while returning essentially identical solutions.</p><p>2 0.27261209 <a title="165-tfidf-2" href="./cvpr-2013-Fully-Connected_CRFs_with_Non-Parametric_Pairwise_Potential.html">180 cvpr-2013-Fully-Connected CRFs with Non-Parametric Pairwise Potential</a></p>
<p>Author: Neill D.F. Campbell, Kartic Subr, Jan Kautz</p><p>Abstract: Conditional Random Fields (CRFs) are used for diverse tasks, ranging from image denoising to object recognition. For images, they are commonly defined as a graph with nodes corresponding to individual pixels and pairwise links that connect nodes to their immediate neighbors. Recent work has shown that fully-connected CRFs, where each node is connected to every other node, can be solved efficiently under the restriction that the pairwise term is a Gaussian kernel over a Euclidean feature space. In this paper, we generalize the pairwise terms to a non-linear dissimilarity measure that is not required to be a distance metric. To this end, we propose a density estimation technique to derive conditional pairwise potentials in a nonparametric manner. We then use an efficient embedding technique to estimate an approximate Euclidean feature space for these potentials, in which the pairwise term can still be expressed as a Gaussian kernel. We demonstrate that the use of non-parametric models for the pairwise interactions, conditioned on the input data, greatly increases expressive power whilst maintaining efficient inference.</p><p>3 0.1925763 <a title="165-tfidf-3" href="./cvpr-2013-A_Principled_Deep_Random_Field_Model_for_Image_Segmentation.html">24 cvpr-2013-A Principled Deep Random Field Model for Image Segmentation</a></p>
<p>Author: Pushmeet Kohli, Anton Osokin, Stefanie Jegelka</p><p>Abstract: We discuss a model for image segmentation that is able to overcome the short-boundary bias observed in standard pairwise random field based approaches. To wit, we show that a random field with multi-layered hidden units can encode boundary preserving higher order potentials such as the ones used in the cooperative cuts model of [11] while still allowing for fast and exact MAP inference. Exact inference allows our model to outperform previous image segmentation methods, and to see the true effect of coupling graph edges. Finally, our model can be easily extended to handle segmentation instances with multiple labels, for which it yields promising results.</p><p>4 0.17781401 <a title="165-tfidf-4" href="./cvpr-2013-Analyzing_Semantic_Segmentation_Using_Hybrid_Human-Machine_CRFs.html">43 cvpr-2013-Analyzing Semantic Segmentation Using Hybrid Human-Machine CRFs</a></p>
<p>Author: Roozbeh Mottaghi, Sanja Fidler, Jian Yao, Raquel Urtasun, Devi Parikh</p><p>Abstract: Recent trends in semantic image segmentation have pushed for holistic scene understanding models that jointly reason about various tasks such as object detection, scene recognition, shape analysis, contextual reasoning. In this work, we are interested in understanding the roles of these different tasks in aiding semantic segmentation. Towards this goal, we “plug-in ” human subjects for each of the various components in a state-of-the-art conditional random field model (CRF) on the MSRC dataset. Comparisons among various hybrid human-machine CRFs give us indications of how much “head room ” there is to improve segmentation by focusing research efforts on each of the tasks. One of the interesting findings from our slew of studies was that human classification of isolated super-pixels, while being worse than current machine classifiers, provides a significant boost in performance when plugged into the CRF! Fascinated by this finding, we conducted in depth analysis of the human generated potentials. This inspired a new machine potential which significantly improves state-of-the-art performance on the MRSC dataset.</p><p>5 0.1715946 <a title="165-tfidf-5" href="./cvpr-2013-Exploring_Compositional_High_Order_Pattern_Potentials_for_Structured_Output_Learning.html">156 cvpr-2013-Exploring Compositional High Order Pattern Potentials for Structured Output Learning</a></p>
<p>Author: Yujia Li, Daniel Tarlow, Richard Zemel</p><p>Abstract: When modeling structured outputs such as image segmentations, prediction can be improved by accurately modeling structure present in the labels. A key challenge is developing tractable models that are able to capture complex high level structure like shape. In this work, we study the learning of a general class of pattern-like high order potential, which we call Compositional High Order Pattern Potentials (CHOPPs). We show that CHOPPs include the linear deviation pattern potentials of Rother et al. [26] and also Restricted Boltzmann Machines (RBMs); we also establish the near equivalence of these two models. Experimentally, we show that performance is affected significantly by the degree of variability present in the datasets, and we define a quantitative variability measure to aid in studying this. We then improve CHOPPs performance in high variability datasets with two primary contributions: (a) developing a loss-sensitive joint learning procedure, so that internal pattern parameters can be learned in conjunction with other model potentials to minimize expected loss;and (b) learning an image-dependent mapping that encourages or inhibits patterns depending on image features. We also explore varying how multiple patterns are composed, and learning convolutional patterns. Quantitative results on challenging highly variable datasets show that the joint learning and image-dependent high order potentials can improve performance.</p><p>6 0.14976852 <a title="165-tfidf-6" href="./cvpr-2013-Probabilistic_Label_Trees_for_Efficient_Large_Scale_Image_Classification.html">340 cvpr-2013-Probabilistic Label Trees for Efficient Large Scale Image Classification</a></p>
<p>7 0.13573098 <a title="165-tfidf-7" href="./cvpr-2013-Human_Pose_Estimation_Using_a_Joint_Pixel-wise_and_Part-wise_Formulation.html">207 cvpr-2013-Human Pose Estimation Using a Joint Pixel-wise and Part-wise Formulation</a></p>
<p>8 0.13408269 <a title="165-tfidf-8" href="./cvpr-2013-A_Comparative_Study_of_Modern_Inference_Techniques_for_Discrete_Energy_Minimization_Problems.html">6 cvpr-2013-A Comparative Study of Modern Inference Techniques for Discrete Energy Minimization Problems</a></p>
<p>9 0.133443 <a title="165-tfidf-9" href="./cvpr-2013-Poselet_Conditioned_Pictorial_Structures.html">335 cvpr-2013-Poselet Conditioned Pictorial Structures</a></p>
<p>10 0.13325894 <a title="165-tfidf-10" href="./cvpr-2013-3D_Pictorial_Structures_for_Multiple_View_Articulated_Pose_Estimation.html">2 cvpr-2013-3D Pictorial Structures for Multiple View Articulated Pose Estimation</a></p>
<p>11 0.13000943 <a title="165-tfidf-11" href="./cvpr-2013-Deformable_Spatial_Pyramid_Matching_for_Fast_Dense_Correspondences.html">107 cvpr-2013-Deformable Spatial Pyramid Matching for Fast Dense Correspondences</a></p>
<p>12 0.12992802 <a title="165-tfidf-12" href="./cvpr-2013-Spatial_Inference_Machines.html">406 cvpr-2013-Spatial Inference Machines</a></p>
<p>13 0.12803134 <a title="165-tfidf-13" href="./cvpr-2013-Nonparametric_Scene_Parsing_with_Adaptive_Feature_Relevance_and_Semantic_Context.html">309 cvpr-2013-Nonparametric Scene Parsing with Adaptive Feature Relevance and Semantic Context</a></p>
<p>14 0.12689717 <a title="165-tfidf-14" href="./cvpr-2013-Learning_Class-to-Image_Distance_with_Object_Matchings.html">247 cvpr-2013-Learning Class-to-Image Distance with Object Matchings</a></p>
<p>15 0.12626842 <a title="165-tfidf-15" href="./cvpr-2013-Detection-_and_Trajectory-Level_Exclusion_in_Multiple_Object_Tracking.html">121 cvpr-2013-Detection- and Trajectory-Level Exclusion in Multiple Object Tracking</a></p>
<p>16 0.12320176 <a title="165-tfidf-16" href="./cvpr-2013-Graph_Matching_with_Anchor_Nodes%3A_A_Learning_Approach.html">192 cvpr-2013-Graph Matching with Anchor Nodes: A Learning Approach</a></p>
<p>17 0.12240036 <a title="165-tfidf-17" href="./cvpr-2013-Learning_for_Structured_Prediction_Using_Approximate_Subgradient_Descent_with_Working_Sets.html">262 cvpr-2013-Learning for Structured Prediction Using Approximate Subgradient Descent with Working Sets</a></p>
<p>18 0.11791138 <a title="165-tfidf-18" href="./cvpr-2013-Tensor-Based_High-Order_Semantic_Relation_Transfer_for_Semantic_Scene_Segmentation.html">425 cvpr-2013-Tensor-Based High-Order Semantic Relation Transfer for Semantic Scene Segmentation</a></p>
<p>19 0.11400077 <a title="165-tfidf-19" href="./cvpr-2013-Learning_Separable_Filters.html">255 cvpr-2013-Learning Separable Filters</a></p>
<p>20 0.11399123 <a title="165-tfidf-20" href="./cvpr-2013-Multi-target_Tracking_by_Lagrangian_Relaxation_to_Min-cost_Network_Flow.html">300 cvpr-2013-Multi-target Tracking by Lagrangian Relaxation to Min-cost Network Flow</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.27), (1, -0.008), (2, 0.032), (3, -0.03), (4, 0.15), (5, 0.054), (6, 0.097), (7, 0.101), (8, -0.123), (9, -0.026), (10, 0.101), (11, 0.061), (12, -0.114), (13, 0.059), (14, -0.078), (15, 0.09), (16, 0.014), (17, 0.009), (18, 0.146), (19, -0.06), (20, -0.018), (21, -0.021), (22, -0.071), (23, 0.101), (24, 0.043), (25, -0.045), (26, -0.024), (27, 0.091), (28, -0.075), (29, 0.008), (30, -0.071), (31, -0.041), (32, 0.118), (33, -0.052), (34, -0.046), (35, 0.084), (36, 0.048), (37, -0.025), (38, -0.02), (39, 0.052), (40, -0.044), (41, 0.042), (42, -0.043), (43, -0.002), (44, -0.012), (45, -0.042), (46, -0.06), (47, 0.01), (48, -0.042), (49, -0.078)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97767979 <a title="165-lsi-1" href="./cvpr-2013-Fast_Energy_Minimization_Using_Learned_State_Filters.html">165 cvpr-2013-Fast Energy Minimization Using Learned State Filters</a></p>
<p>Author: Matthieu Guillaumin, Luc Van_Gool, Vittorio Ferrari</p><p>Abstract: Pairwise discrete energies defined over graphs are ubiquitous in computer vision. Many algorithms have been proposed to minimize such energies, often concentrating on sparse graph topologies or specialized classes of pairwise potentials. However, when the graph is fully connected and the pairwise potentials are arbitrary, the complexity of even approximate minimization algorithms such as TRW-S grows quadratically both in the number of nodes and in the number of states a node can take. Moreover, recent applications are using more and more computationally expensive pairwise potentials. These factors make it very hard to employ fully connected models. In this paper we propose a novel, generic algorithm to approximately minimize any discrete pairwise energy function. Our method exploits tractable sub-energies to filter the domain of the function. The parameters of the filter are learnt from instances of the same class of energies with good candidate solutions. Compared to existing methods, it efficiently handles fully connected graphs, with many states per node, and arbitrary pairwise potentials, which might be expensive to compute. We demonstrate experimentally on two applications that our algorithm is much more efficient than other generic minimization algorithms such as TRW-S, while returning essentially identical solutions.</p><p>2 0.85977888 <a title="165-lsi-2" href="./cvpr-2013-Fully-Connected_CRFs_with_Non-Parametric_Pairwise_Potential.html">180 cvpr-2013-Fully-Connected CRFs with Non-Parametric Pairwise Potential</a></p>
<p>Author: Neill D.F. Campbell, Kartic Subr, Jan Kautz</p><p>Abstract: Conditional Random Fields (CRFs) are used for diverse tasks, ranging from image denoising to object recognition. For images, they are commonly defined as a graph with nodes corresponding to individual pixels and pairwise links that connect nodes to their immediate neighbors. Recent work has shown that fully-connected CRFs, where each node is connected to every other node, can be solved efficiently under the restriction that the pairwise term is a Gaussian kernel over a Euclidean feature space. In this paper, we generalize the pairwise terms to a non-linear dissimilarity measure that is not required to be a distance metric. To this end, we propose a density estimation technique to derive conditional pairwise potentials in a nonparametric manner. We then use an efficient embedding technique to estimate an approximate Euclidean feature space for these potentials, in which the pairwise term can still be expressed as a Gaussian kernel. We demonstrate that the use of non-parametric models for the pairwise interactions, conditioned on the input data, greatly increases expressive power whilst maintaining efficient inference.</p><p>3 0.84851599 <a title="165-lsi-3" href="./cvpr-2013-A_Principled_Deep_Random_Field_Model_for_Image_Segmentation.html">24 cvpr-2013-A Principled Deep Random Field Model for Image Segmentation</a></p>
<p>Author: Pushmeet Kohli, Anton Osokin, Stefanie Jegelka</p><p>Abstract: We discuss a model for image segmentation that is able to overcome the short-boundary bias observed in standard pairwise random field based approaches. To wit, we show that a random field with multi-layered hidden units can encode boundary preserving higher order potentials such as the ones used in the cooperative cuts model of [11] while still allowing for fast and exact MAP inference. Exact inference allows our model to outperform previous image segmentation methods, and to see the true effect of coupling graph edges. Finally, our model can be easily extended to handle segmentation instances with multiple labels, for which it yields promising results.</p><p>4 0.75363994 <a title="165-lsi-4" href="./cvpr-2013-Towards_Efficient_and_Exact_MAP-Inference_for_Large_Scale_Discrete_Computer_Vision_Problems_via_Combinatorial_Optimization.html">436 cvpr-2013-Towards Efficient and Exact MAP-Inference for Large Scale Discrete Computer Vision Problems via Combinatorial Optimization</a></p>
<p>Author: Jörg Hendrik Kappes, Markus Speth, Gerhard Reinelt, Christoph Schnörr</p><p>Abstract: Discrete graphical models (also known as discrete Markov random fields) are a major conceptual tool to model the structure of optimization problems in computer vision. While in the last decade research has focused on fast approximative methods, algorithms that provide globally optimal solutions have come more into the research focus in the last years. However, large scale computer vision problems seemed to be out of reach for such methods. In this paper we introduce a promising way to bridge this gap based on partial optimality and structural properties of the underlying problem factorization. Combining these preprocessing steps, we are able to solve grids of size 2048 2048 in less than 90 seconds. On the hitherto unsolva2b04le8 C×h2i0ne4s8e character dataset of Nowozin et al. we obtain provably optimal results in 56% of the instances and achieve competitive runtimes on other recent benchmark problems. While in the present work only generalized Potts models are considered, an extension to general graphical models seems to be feasible.</p><p>5 0.7510891 <a title="165-lsi-5" href="./cvpr-2013-A_Comparative_Study_of_Modern_Inference_Techniques_for_Discrete_Energy_Minimization_Problems.html">6 cvpr-2013-A Comparative Study of Modern Inference Techniques for Discrete Energy Minimization Problems</a></p>
<p>Author: Jörg H. Kappes, Bjoern Andres, Fred A. Hamprecht, Christoph Schnörr, Sebastian Nowozin, Dhruv Batra, Sungwoong Kim, Bernhard X. Kausler, Jan Lellmann, Nikos Komodakis, Carsten Rother</p><p>Abstract: Seven years ago, Szeliski et al. published an influential study on energy minimization methods for Markov random fields (MRF). This study provided valuable insights in choosing the best optimization technique for certain classes of problems. While these insights remain generally useful today, the phenominal success of random field models means that the kinds of inference problems we solve have changed significantly. Specifically, the models today often include higher order interactions, flexible connectivity structures, large label-spaces of different cardinalities, or learned energy tables. To reflect these changes, we provide a modernized and enlarged study. We present an empirical comparison of 24 state-of-art techniques on a corpus of 2,300 energy minimization instances from 20 diverse computer vision applications. To ensure reproducibility, we evaluate all methods in the OpenGM2 framework and report extensive results regarding runtime and solution quality. Key insights from our study agree with the results of Szeliski et al. for the types of models they studied. However, on new and challenging types of models our findings disagree and suggest that polyhedral methods and integer programming solvers are competitive in terms of runtime and solution quality over a large range of model types.</p><p>6 0.71038914 <a title="165-lsi-6" href="./cvpr-2013-A_Higher-Order_CRF_Model_for_Road_Network_Extraction.html">13 cvpr-2013-A Higher-Order CRF Model for Road Network Extraction</a></p>
<p>7 0.7012651 <a title="165-lsi-7" href="./cvpr-2013-Learning_for_Structured_Prediction_Using_Approximate_Subgradient_Descent_with_Working_Sets.html">262 cvpr-2013-Learning for Structured Prediction Using Approximate Subgradient Descent with Working Sets</a></p>
<p>8 0.68151844 <a title="165-lsi-8" href="./cvpr-2013-Graph-Based_Optimization_with_Tubularity_Markov_Tree_for_3D_Vessel_Segmentation.html">190 cvpr-2013-Graph-Based Optimization with Tubularity Markov Tree for 3D Vessel Segmentation</a></p>
<p>9 0.65839016 <a title="165-lsi-9" href="./cvpr-2013-Exploring_Compositional_High_Order_Pattern_Potentials_for_Structured_Output_Learning.html">156 cvpr-2013-Exploring Compositional High Order Pattern Potentials for Structured Output Learning</a></p>
<p>10 0.65792173 <a title="165-lsi-10" href="./cvpr-2013-Spatial_Inference_Machines.html">406 cvpr-2013-Spatial Inference Machines</a></p>
<p>11 0.65588033 <a title="165-lsi-11" href="./cvpr-2013-Nonlinearly_Constrained_MRFs%3A_Exploring_the_Intrinsic_Dimensions_of_Higher-Order_Cliques.html">308 cvpr-2013-Nonlinearly Constrained MRFs: Exploring the Intrinsic Dimensions of Higher-Order Cliques</a></p>
<p>12 0.65381253 <a title="165-lsi-12" href="./cvpr-2013-Reconstructing_Loopy_Curvilinear_Structures_Using_Integer_Programming.html">350 cvpr-2013-Reconstructing Loopy Curvilinear Structures Using Integer Programming</a></p>
<p>13 0.64372009 <a title="165-lsi-13" href="./cvpr-2013-Analyzing_Semantic_Segmentation_Using_Hybrid_Human-Machine_CRFs.html">43 cvpr-2013-Analyzing Semantic Segmentation Using Hybrid Human-Machine CRFs</a></p>
<p>14 0.64285374 <a title="165-lsi-14" href="./cvpr-2013-Discriminative_Re-ranking_of_Diverse_Segmentations.html">132 cvpr-2013-Discriminative Re-ranking of Diverse Segmentations</a></p>
<p>15 0.63884193 <a title="165-lsi-15" href="./cvpr-2013-Universality_of_the_Local_Marginal_Polytope.html">448 cvpr-2013-Universality of the Local Marginal Polytope</a></p>
<p>16 0.63660991 <a title="165-lsi-16" href="./cvpr-2013-Gauging_Association_Patterns_of_Chromosome_Territories_via_Chromatic_Median.html">184 cvpr-2013-Gauging Association Patterns of Chromosome Territories via Chromatic Median</a></p>
<p>17 0.62539339 <a title="165-lsi-17" href="./cvpr-2013-Graph_Transduction_Learning_with_Connectivity_Constraints_with_Application_to_Multiple_Foreground_Cosegmentation.html">193 cvpr-2013-Graph Transduction Learning with Connectivity Constraints with Application to Multiple Foreground Cosegmentation</a></p>
<p>18 0.61141813 <a title="165-lsi-18" href="./cvpr-2013-Graph_Matching_with_Anchor_Nodes%3A_A_Learning_Approach.html">192 cvpr-2013-Graph Matching with Anchor Nodes: A Learning Approach</a></p>
<p>19 0.60971737 <a title="165-lsi-19" href="./cvpr-2013-Bilinear_Programming_for_Human_Activity_Recognition_with_Unknown_MRF_Graphs.html">62 cvpr-2013-Bilinear Programming for Human Activity Recognition with Unknown MRF Graphs</a></p>
<p>20 0.60115564 <a title="165-lsi-20" href="./cvpr-2013-Maximum_Cohesive_Grid_of_Superpixels_for_Fast_Object_Localization.html">280 cvpr-2013-Maximum Cohesive Grid of Superpixels for Fast Object Localization</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.076), (16, 0.01), (26, 0.032), (33, 0.689), (67, 0.044), (69, 0.025), (87, 0.06)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.99939358 <a title="165-lda-1" href="./cvpr-2013-Dense_Variational_Reconstruction_of_Non-rigid_Surfaces_from_Monocular_Video.html">113 cvpr-2013-Dense Variational Reconstruction of Non-rigid Surfaces from Monocular Video</a></p>
<p>Author: Ravi Garg, Anastasios Roussos, Lourdes Agapito</p><p>Abstract: This paper offers the first variational approach to the problem of dense 3D reconstruction of non-rigid surfaces from a monocular video sequence. We formulate nonrigid structure from motion (NRSfM) as a global variational energy minimization problem to estimate dense low-rank smooth 3D shapes for every frame along with the camera motion matrices, given dense 2D correspondences. Unlike traditional factorization based approaches to NRSfM, which model the low-rank non-rigid shape using a fixed number of basis shapes and corresponding coefficients, we minimize the rank of the matrix of time-varying shapes directly via trace norm minimization. In conjunction with this low-rank constraint, we use an edge preserving total-variation regularization term to obtain spatially smooth shapes for every frame. Thanks to proximal splitting techniques the optimization problem can be decomposed into many point-wise sub-problems and simple linear systems which can be easily solved on GPU hardware. We show results on real sequences of different objects (face, torso, beating heart) where, despite challenges in tracking, illumination changes and occlusions, our method reconstructs highly deforming smooth surfaces densely and accurately directly from video, without the need for any prior models or shape templates.</p><p>same-paper 2 0.99927765 <a title="165-lda-2" href="./cvpr-2013-Fast_Energy_Minimization_Using_Learned_State_Filters.html">165 cvpr-2013-Fast Energy Minimization Using Learned State Filters</a></p>
<p>Author: Matthieu Guillaumin, Luc Van_Gool, Vittorio Ferrari</p><p>Abstract: Pairwise discrete energies defined over graphs are ubiquitous in computer vision. Many algorithms have been proposed to minimize such energies, often concentrating on sparse graph topologies or specialized classes of pairwise potentials. However, when the graph is fully connected and the pairwise potentials are arbitrary, the complexity of even approximate minimization algorithms such as TRW-S grows quadratically both in the number of nodes and in the number of states a node can take. Moreover, recent applications are using more and more computationally expensive pairwise potentials. These factors make it very hard to employ fully connected models. In this paper we propose a novel, generic algorithm to approximately minimize any discrete pairwise energy function. Our method exploits tractable sub-energies to filter the domain of the function. The parameters of the filter are learnt from instances of the same class of energies with good candidate solutions. Compared to existing methods, it efficiently handles fully connected graphs, with many states per node, and arbitrary pairwise potentials, which might be expensive to compute. We demonstrate experimentally on two applications that our algorithm is much more efficient than other generic minimization algorithms such as TRW-S, while returning essentially identical solutions.</p><p>3 0.99917251 <a title="165-lda-3" href="./cvpr-2013-Dynamic_Scene_Classification%3A_Learning_Motion_Descriptors_with_Slow_Features_Analysis.html">137 cvpr-2013-Dynamic Scene Classification: Learning Motion Descriptors with Slow Features Analysis</a></p>
<p>Author: Christian Thériault, Nicolas Thome, Matthieu Cord</p><p>Abstract: In this paper, we address the challenging problem of categorizing video sequences composed of dynamic natural scenes. Contrarily to previous methods that rely on handcrafted descriptors, we propose here to represent videos using unsupervised learning of motion features. Our method encompasses three main contributions: 1) Based on the Slow Feature Analysis principle, we introduce a learned local motion descriptor which represents the principal and more stable motion components of training videos. 2) We integrate our local motion feature into a global coding/pooling architecture in order to provide an effective signature for each video sequence. 3) We report state of the art classification performances on two challenging natural scenes data sets. In particular, an outstanding improvement of 11 % in classification score is reached on a data set introduced in 2012.</p><p>4 0.9988364 <a title="165-lda-4" href="./cvpr-2013-Learning_and_Calibrating_Per-Location_Classifiers_for_Visual_Place_Recognition.html">260 cvpr-2013-Learning and Calibrating Per-Location Classifiers for Visual Place Recognition</a></p>
<p>Author: Petr Gronát, Guillaume Obozinski, Josef Sivic, Tomáš Pajdla</p><p>Abstract: The aim of this work is to localize a query photograph by finding other images depicting the same place in a large geotagged image database. This is a challenging task due to changes in viewpoint, imaging conditions and the large size of the image database. The contribution of this work is two-fold. First, we cast the place recognition problem as a classification task and use the available geotags to train a classifier for each location in the database in a similar manner to per-exemplar SVMs in object recognition. Second, as onlyfewpositive training examples are availablefor each location, we propose a new approach to calibrate all the per-location SVM classifiers using only the negative examples. The calibration we propose relies on a significance measure essentially equivalent to the p-values classically used in statistical hypothesis testing. Experiments are performed on a database of 25,000 geotagged street view images of Pittsburgh and demonstrate improved place recognition accuracy of the proposed approach over the previous work. 2Center for Machine Perception, Faculty of Electrical Engineering 3WILLOW project, Laboratoire d’Informatique de l’E´cole Normale Sup e´rieure, ENS/INRIA/CNRS UMR 8548. 4Universit Paris-Est, LIGM (UMR CNRS 8049), Center for Visual Computing, Ecole des Ponts - ParisTech, 77455 Marne-la-Valle, France</p><p>5 0.99850035 <a title="165-lda-5" href="./cvpr-2013-Fully-Connected_CRFs_with_Non-Parametric_Pairwise_Potential.html">180 cvpr-2013-Fully-Connected CRFs with Non-Parametric Pairwise Potential</a></p>
<p>Author: Neill D.F. Campbell, Kartic Subr, Jan Kautz</p><p>Abstract: Conditional Random Fields (CRFs) are used for diverse tasks, ranging from image denoising to object recognition. For images, they are commonly defined as a graph with nodes corresponding to individual pixels and pairwise links that connect nodes to their immediate neighbors. Recent work has shown that fully-connected CRFs, where each node is connected to every other node, can be solved efficiently under the restriction that the pairwise term is a Gaussian kernel over a Euclidean feature space. In this paper, we generalize the pairwise terms to a non-linear dissimilarity measure that is not required to be a distance metric. To this end, we propose a density estimation technique to derive conditional pairwise potentials in a nonparametric manner. We then use an efficient embedding technique to estimate an approximate Euclidean feature space for these potentials, in which the pairwise term can still be expressed as a Gaussian kernel. We demonstrate that the use of non-parametric models for the pairwise interactions, conditioned on the input data, greatly increases expressive power whilst maintaining efficient inference.</p><p>6 0.99847841 <a title="165-lda-6" href="./cvpr-2013-Better_Exploiting_Motion_for_Better_Action_Recognition.html">59 cvpr-2013-Better Exploiting Motion for Better Action Recognition</a></p>
<p>7 0.99834776 <a title="165-lda-7" href="./cvpr-2013-Constraints_as_Features.html">93 cvpr-2013-Constraints as Features</a></p>
<p>8 0.99798322 <a title="165-lda-8" href="./cvpr-2013-Real-Time_No-Reference_Image_Quality_Assessment_Based_on_Filter_Learning.html">346 cvpr-2013-Real-Time No-Reference Image Quality Assessment Based on Filter Learning</a></p>
<p>9 0.99793434 <a title="165-lda-9" href="./cvpr-2013-Multi-target_Tracking_by_Rank-1_Tensor_Approximation.html">301 cvpr-2013-Multi-target Tracking by Rank-1 Tensor Approximation</a></p>
<p>10 0.99788034 <a title="165-lda-10" href="./cvpr-2013-Background_Modeling_Based_on_Bidirectional_Analysis.html">55 cvpr-2013-Background Modeling Based on Bidirectional Analysis</a></p>
<p>11 0.99783784 <a title="165-lda-11" href="./cvpr-2013-Revisiting_Depth_Layers_from_Occlusions.html">357 cvpr-2013-Revisiting Depth Layers from Occlusions</a></p>
<p>12 0.99772727 <a title="165-lda-12" href="./cvpr-2013-Attribute-Based_Detection_of_Unfamiliar_Classes_with_Humans_in_the_Loop.html">48 cvpr-2013-Attribute-Based Detection of Unfamiliar Classes with Humans in the Loop</a></p>
<p>13 0.99749476 <a title="165-lda-13" href="./cvpr-2013-From_Local_Similarity_to_Global_Coding%3A_An_Application_to_Image_Classification.html">178 cvpr-2013-From Local Similarity to Global Coding: An Application to Image Classification</a></p>
<p>14 0.99612057 <a title="165-lda-14" href="./cvpr-2013-Learning_Locally-Adaptive_Decision_Functions_for_Person_Verification.html">252 cvpr-2013-Learning Locally-Adaptive Decision Functions for Person Verification</a></p>
<p>15 0.99509543 <a title="165-lda-15" href="./cvpr-2013-Graph-Based_Discriminative_Learning_for_Location_Recognition.html">189 cvpr-2013-Graph-Based Discriminative Learning for Location Recognition</a></p>
<p>16 0.99354362 <a title="165-lda-16" href="./cvpr-2013-Scalable_Sparse_Subspace_Clustering.html">379 cvpr-2013-Scalable Sparse Subspace Clustering</a></p>
<p>17 0.9934966 <a title="165-lda-17" href="./cvpr-2013-Query_Adaptive_Similarity_for_Large_Scale_Object_Retrieval.html">343 cvpr-2013-Query Adaptive Similarity for Large Scale Object Retrieval</a></p>
<p>18 0.99218202 <a title="165-lda-18" href="./cvpr-2013-Non-rigid_Structure_from_Motion_with_Diffusion_Maps_Prior.html">306 cvpr-2013-Non-rigid Structure from Motion with Diffusion Maps Prior</a></p>
<p>19 0.99198419 <a title="165-lda-19" href="./cvpr-2013-Learning_without_Human_Scores_for_Blind_Image_Quality_Assessment.html">266 cvpr-2013-Learning without Human Scores for Blind Image Quality Assessment</a></p>
<p>20 0.99176484 <a title="165-lda-20" href="./cvpr-2013-Ensemble_Video_Object_Cut_in_Highly_Dynamic_Scenes.html">148 cvpr-2013-Ensemble Video Object Cut in Highly Dynamic Scenes</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
