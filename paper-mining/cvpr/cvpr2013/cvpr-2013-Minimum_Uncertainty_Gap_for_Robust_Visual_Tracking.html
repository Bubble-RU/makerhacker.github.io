<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>285 cvpr-2013-Minimum Uncertainty Gap for Robust Visual Tracking</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-285" href="#">cvpr2013-285</a> knowledge-graph by maker-knowledge-mining</p><h1>285 cvpr-2013-Minimum Uncertainty Gap for Robust Visual Tracking</h1>
<br/><p>Source: <a title="cvpr-2013-285-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Kwon_Minimum_Uncertainty_Gap_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Junseok Kwon, Kyoung Mu Lee</p><p>Abstract: We propose a novel tracking algorithm that robustly tracks the target by finding the state which minimizes uncertainty of the likelihood at current state. The uncertainty of the likelihood is estimated by obtaining the gap between the lower and upper bounds of the likelihood. By minimizing the gap between the two bounds, our method finds the confident and reliable state of the target. In the paper, the state that gives the Minimum Uncertainty Gap (MUG) between likelihood bounds is shown to be more reliable than the state which gives the maximum likelihood only, especially when there are severe illumination changes, occlusions, and pose variations. A rigorous derivation of the lower and upper bounds of the likelihood for the visual tracking problem is provided to address this issue. Additionally, an efficient inference algorithm using Interacting Markov Chain Monte Carlo is presented to find the best state that maximizes the average of the lower and upper bounds of the likelihood and minimizes the gap between two bounds simultaneously. Experimental results demonstrate that our method successfully tracks the target in realistic videos and outperforms conventional tracking methods.</p><p>Reference: <a title="cvpr-2013-285-reference" href="../cvpr2013_reference/cvpr-2013-Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('xt', 0.481), ('track', 0.341), ('mug', 0.334), ('target', 0.28), ('yt', 0.261), ('gap', 0.22), ('imcmc', 0.191), ('xxtt', 0.167), ('chain', 0.162), ('uncertainty', 0.157), ('lnpl', 0.143), ('yyt', 0.143), ('vts', 0.127), ('up', 0.127), ('bound', 0.094), ('kwon', 0.092), ('xxt', 0.088), ('lnpq', 0.071), ('lnpu', 0.071), ('mont', 0.066)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000007 <a title="285-tfidf-1" href="./cvpr-2013-Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking.html">285 cvpr-2013-Minimum Uncertainty Gap for Robust Visual Tracking</a></p>
<p>2 0.41213739 <a title="285-tfidf-2" href="./cvpr-2013-Part-Based_Visual_Tracking_with_Online_Latent_Structural_Learning.html">324 cvpr-2013-Part-Based Visual Tracking with Online Latent Structural Learning</a></p>
<p>3 0.33114854 <a title="285-tfidf-3" href="./cvpr-2013-Online_Object_Tracking%3A_A_Benchmark.html">314 cvpr-2013-Online Object Tracking: A Benchmark</a></p>
<p>4 0.29892227 <a title="285-tfidf-4" href="./cvpr-2013-Visual_Tracking_via_Locality_Sensitive_Histograms.html">457 cvpr-2013-Visual Tracking via Locality Sensitive Histograms</a></p>
<p>5 0.28325504 <a title="285-tfidf-5" href="./cvpr-2013-Structure_Preserving_Object_Tracking.html">414 cvpr-2013-Structure Preserving Object Tracking</a></p>
<p>6 0.25245616 <a title="285-tfidf-6" href="./cvpr-2013-Self-Paced_Learning_for_Long-Term_Tracking.html">386 cvpr-2013-Self-Paced Learning for Long-Term Tracking</a></p>
<p>7 0.23041706 <a title="285-tfidf-7" href="./cvpr-2013-Least_Soft-Threshold_Squares_Tracking.html">267 cvpr-2013-Least Soft-Threshold Squares Tracking</a></p>
<p>8 0.19272012 <a title="285-tfidf-8" href="./cvpr-2013-Detection-_and_Trajectory-Level_Exclusion_in_Multiple_Object_Tracking.html">121 cvpr-2013-Detection- and Trajectory-Level Exclusion in Multiple Object Tracking</a></p>
<p>9 0.17551665 <a title="285-tfidf-9" href="./cvpr-2013-Harry_Potter%27s_Marauder%27s_Map%3A_Localizing_and_Tracking_Multiple_Persons-of-Interest_by_Nonnegative_Discretization.html">199 cvpr-2013-Harry Potter's Marauder's Map: Localizing and Tracking Multiple Persons-of-Interest by Nonnegative Discretization</a></p>
<p>10 0.17054634 <a title="285-tfidf-10" href="./cvpr-2013-Tracking_Human_Pose_by_Tracking_Symmetric_Parts.html">439 cvpr-2013-Tracking Human Pose by Tracking Symmetric Parts</a></p>
<p>11 0.15937759 <a title="285-tfidf-11" href="./cvpr-2013-Hypergraphs_for_Joint_Multi-view_Reconstruction_and_Multi-object_Tracking.html">209 cvpr-2013-Hypergraphs for Joint Multi-view Reconstruction and Multi-object Tracking</a></p>
<p>12 0.15079555 <a title="285-tfidf-12" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<p>13 0.13785584 <a title="285-tfidf-13" href="./cvpr-2013-Learning_Compact_Binary_Codes_for_Visual_Tracking.html">249 cvpr-2013-Learning Compact Binary Codes for Visual Tracking</a></p>
<p>14 0.13532022 <a title="285-tfidf-14" href="./cvpr-2013-Background_Modeling_Based_on_Bidirectional_Analysis.html">55 cvpr-2013-Background Modeling Based on Bidirectional Analysis</a></p>
<p>15 0.13274524 <a title="285-tfidf-15" href="./cvpr-2013-Lost%21_Leveraging_the_Crowd_for_Probabilistic_Visual_Self-Localization.html">274 cvpr-2013-Lost! Leveraging the Crowd for Probabilistic Visual Self-Localization</a></p>
<p>16 0.13183293 <a title="285-tfidf-16" href="./cvpr-2013-Real-Time_Model-Based_Rigid_Object_Pose_Estimation_and_Tracking_Combining_Dense_and_Sparse_Visual_Cues.html">345 cvpr-2013-Real-Time Model-Based Rigid Object Pose Estimation and Tracking Combining Dense and Sparse Visual Cues</a></p>
<p>17 0.1314683 <a title="285-tfidf-17" href="./cvpr-2013-Tracking_People_and_Their_Objects.html">440 cvpr-2013-Tracking People and Their Objects</a></p>
<p>18 0.1305853 <a title="285-tfidf-18" href="./cvpr-2013-Semi-supervised_Domain_Adaptation_with_Instance_Constraints.html">387 cvpr-2013-Semi-supervised Domain Adaptation with Instance Constraints</a></p>
<p>19 0.11743825 <a title="285-tfidf-19" href="./cvpr-2013-Information_Consensus_for_Distributed_Multi-target_Tracking.html">224 cvpr-2013-Information Consensus for Distributed Multi-target Tracking</a></p>
<p>20 0.11687896 <a title="285-tfidf-20" href="./cvpr-2013-A_Lazy_Man%27s_Approach_to_Benchmarking%3A_Semisupervised_Classifier_Evaluation_and_Recalibration.html">15 cvpr-2013-A Lazy Man's Approach to Benchmarking: Semisupervised Classifier Evaluation and Recalibration</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.177), (1, -0.1), (2, -0.004), (3, 0.162), (4, -0.277), (5, 0.126), (6, -0.043), (7, -0.041), (8, 0.128), (9, 0.199), (10, -0.088), (11, -0.05), (12, 0.092), (13, 0.054), (14, 0.019), (15, 0.083), (16, -0.089), (17, 0.024), (18, 0.019), (19, 0.034), (20, 0.01), (21, -0.043), (22, 0.056), (23, 0.034), (24, -0.004), (25, 0.025), (26, -0.047), (27, -0.038), (28, 0.01), (29, 0.034), (30, 0.081), (31, -0.042), (32, 0.007), (33, -0.001), (34, -0.041), (35, -0.016), (36, -0.018), (37, -0.029), (38, -0.015), (39, 0.006), (40, 0.06), (41, -0.024), (42, -0.028), (43, -0.052), (44, -0.062), (45, -0.027), (46, -0.011), (47, 0.029), (48, -0.074), (49, 0.082)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9773972 <a title="285-lsi-1" href="./cvpr-2013-Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking.html">285 cvpr-2013-Minimum Uncertainty Gap for Robust Visual Tracking</a></p>
<p>2 0.88415939 <a title="285-lsi-2" href="./cvpr-2013-Online_Object_Tracking%3A_A_Benchmark.html">314 cvpr-2013-Online Object Tracking: A Benchmark</a></p>
<p>3 0.8660531 <a title="285-lsi-3" href="./cvpr-2013-Visual_Tracking_via_Locality_Sensitive_Histograms.html">457 cvpr-2013-Visual Tracking via Locality Sensitive Histograms</a></p>
<p>4 0.84944147 <a title="285-lsi-4" href="./cvpr-2013-Part-Based_Visual_Tracking_with_Online_Latent_Structural_Learning.html">324 cvpr-2013-Part-Based Visual Tracking with Online Latent Structural Learning</a></p>
<p>5 0.84181684 <a title="285-lsi-5" href="./cvpr-2013-Least_Soft-Threshold_Squares_Tracking.html">267 cvpr-2013-Least Soft-Threshold Squares Tracking</a></p>
<p>6 0.82305032 <a title="285-lsi-6" href="./cvpr-2013-Structure_Preserving_Object_Tracking.html">414 cvpr-2013-Structure Preserving Object Tracking</a></p>
<p>7 0.7650907 <a title="285-lsi-7" href="./cvpr-2013-Self-Paced_Learning_for_Long-Term_Tracking.html">386 cvpr-2013-Self-Paced Learning for Long-Term Tracking</a></p>
<p>8 0.75414759 <a title="285-lsi-8" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<p>9 0.74965346 <a title="285-lsi-9" href="./cvpr-2013-Hypergraphs_for_Joint_Multi-view_Reconstruction_and_Multi-object_Tracking.html">209 cvpr-2013-Hypergraphs for Joint Multi-view Reconstruction and Multi-object Tracking</a></p>
<p>10 0.70425224 <a title="285-lsi-10" href="./cvpr-2013-Detection-_and_Trajectory-Level_Exclusion_in_Multiple_Object_Tracking.html">121 cvpr-2013-Detection- and Trajectory-Level Exclusion in Multiple Object Tracking</a></p>
<p>11 0.67401415 <a title="285-lsi-11" href="./cvpr-2013-Harry_Potter%27s_Marauder%27s_Map%3A_Localizing_and_Tracking_Multiple_Persons-of-Interest_by_Nonnegative_Discretization.html">199 cvpr-2013-Harry Potter's Marauder's Map: Localizing and Tracking Multiple Persons-of-Interest by Nonnegative Discretization</a></p>
<p>12 0.6737923 <a title="285-lsi-12" href="./cvpr-2013-Multi-target_Tracking_by_Rank-1_Tensor_Approximation.html">301 cvpr-2013-Multi-target Tracking by Rank-1 Tensor Approximation</a></p>
<p>13 0.66739708 <a title="285-lsi-13" href="./cvpr-2013-Information_Consensus_for_Distributed_Multi-target_Tracking.html">224 cvpr-2013-Information Consensus for Distributed Multi-target Tracking</a></p>
<p>14 0.65398496 <a title="285-lsi-14" href="./cvpr-2013-Physically_Plausible_3D_Scene_Tracking%3A_The_Single_Actor_Hypothesis.html">331 cvpr-2013-Physically Plausible 3D Scene Tracking: The Single Actor Hypothesis</a></p>
<p>15 0.63866442 <a title="285-lsi-15" href="./cvpr-2013-Learning_Compact_Binary_Codes_for_Visual_Tracking.html">249 cvpr-2013-Learning Compact Binary Codes for Visual Tracking</a></p>
<p>16 0.62951779 <a title="285-lsi-16" href="./cvpr-2013-Tracking_Human_Pose_by_Tracking_Symmetric_Parts.html">439 cvpr-2013-Tracking Human Pose by Tracking Symmetric Parts</a></p>
<p>17 0.62588227 <a title="285-lsi-17" href="./cvpr-2013-Tracking_People_and_Their_Objects.html">440 cvpr-2013-Tracking People and Their Objects</a></p>
<p>18 0.57912177 <a title="285-lsi-18" href="./cvpr-2013-Tracking_Sports_Players_with_Context-Conditioned_Motion_Models.html">441 cvpr-2013-Tracking Sports Players with Context-Conditioned Motion Models</a></p>
<p>19 0.51833892 <a title="285-lsi-19" href="./cvpr-2013-CLAM%3A_Coupled_Localization_and_Mapping_with_Efficient_Outlier_Handling.html">74 cvpr-2013-CLAM: Coupled Localization and Mapping with Efficient Outlier Handling</a></p>
<p>20 0.51422471 <a title="285-lsi-20" href="./cvpr-2013-Real-Time_Model-Based_Rigid_Object_Pose_Estimation_and_Tracking_Combining_Dense_and_Sparse_Visual_Cues.html">345 cvpr-2013-Real-Time Model-Based Rigid Object Pose Estimation and Tracking Combining Dense and Sparse Visual Cues</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(19, 0.093), (31, 0.562), (50, 0.011), (54, 0.02), (55, 0.044), (75, 0.012), (86, 0.142), (97, 0.012), (98, 0.011)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.86311519 <a title="285-lda-1" href="./cvpr-2013-Deep_Learning_Shape_Priors_for_Object_Segmentation.html">105 cvpr-2013-Deep Learning Shape Priors for Object Segmentation</a></p>
<p>same-paper 2 0.74572212 <a title="285-lda-2" href="./cvpr-2013-Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking.html">285 cvpr-2013-Minimum Uncertainty Gap for Robust Visual Tracking</a></p>
<p>3 0.67742932 <a title="285-lda-3" href="./cvpr-2013-Hypergraphs_for_Joint_Multi-view_Reconstruction_and_Multi-object_Tracking.html">209 cvpr-2013-Hypergraphs for Joint Multi-view Reconstruction and Multi-object Tracking</a></p>
<p>4 0.60309815 <a title="285-lda-4" href="./cvpr-2013-Unnatural_L0_Sparse_Representation_for_Natural_Image_Deblurring.html">449 cvpr-2013-Unnatural L0 Sparse Representation for Natural Image Deblurring</a></p>
<p>5 0.51451135 <a title="285-lda-5" href="./cvpr-2013-Self-Paced_Learning_for_Long-Term_Tracking.html">386 cvpr-2013-Self-Paced Learning for Long-Term Tracking</a></p>
<p>6 0.51194572 <a title="285-lda-6" href="./cvpr-2013-Incorporating_User_Interaction_and_Topological_Constraints_within_Contour_Completion_via_Discrete_Calculus.html">222 cvpr-2013-Incorporating User Interaction and Topological Constraints within Contour Completion via Discrete Calculus</a></p>
<p>7 0.46588284 <a title="285-lda-7" href="./cvpr-2013-Looking_Beyond_the_Image%3A_Unsupervised_Learning_for_Object_Saliency_and_Detection.html">273 cvpr-2013-Looking Beyond the Image: Unsupervised Learning for Object Saliency and Detection</a></p>
<p>8 0.45434356 <a title="285-lda-8" href="./cvpr-2013-Dense_3D_Reconstruction_from_Severely_Blurred_Images_Using_a_Single_Moving_Camera.html">108 cvpr-2013-Dense 3D Reconstruction from Severely Blurred Images Using a Single Moving Camera</a></p>
<p>9 0.42613405 <a title="285-lda-9" href="./cvpr-2013-Non-uniform_Motion_Deblurring_for_Bilayer_Scenes.html">307 cvpr-2013-Non-uniform Motion Deblurring for Bilayer Scenes</a></p>
<p>10 0.41974449 <a title="285-lda-10" href="./cvpr-2013-What_Object_Motion_Reveals_about_Shape_with_Unknown_BRDF_and_Lighting.html">465 cvpr-2013-What Object Motion Reveals about Shape with Unknown BRDF and Lighting</a></p>
<p>11 0.40645811 <a title="285-lda-11" href="./cvpr-2013-Stochastic_Deconvolution.html">412 cvpr-2013-Stochastic Deconvolution</a></p>
<p>12 0.40022975 <a title="285-lda-12" href="./cvpr-2013-Learning_to_Estimate_and_Remove_Non-uniform_Image_Blur.html">265 cvpr-2013-Learning to Estimate and Remove Non-uniform Image Blur</a></p>
<p>13 0.39925483 <a title="285-lda-13" href="./cvpr-2013-Blur_Processing_Using_Double_Discrete_Wavelet_Transform.html">68 cvpr-2013-Blur Processing Using Double Discrete Wavelet Transform</a></p>
<p>14 0.39537394 <a title="285-lda-14" href="./cvpr-2013-Robust_Object_Co-detection.html">364 cvpr-2013-Robust Object Co-detection</a></p>
<p>15 0.39492962 <a title="285-lda-15" href="./cvpr-2013-Part-Based_Visual_Tracking_with_Online_Latent_Structural_Learning.html">324 cvpr-2013-Part-Based Visual Tracking with Online Latent Structural Learning</a></p>
<p>16 0.39020565 <a title="285-lda-16" href="./cvpr-2013-Discriminative_Non-blind_Deblurring.html">131 cvpr-2013-Discriminative Non-blind Deblurring</a></p>
<p>17 0.39004987 <a title="285-lda-17" href="./cvpr-2013-Towards_Contactless%2C_Low-Cost_and_Accurate_3D_Fingerprint_Identification.html">435 cvpr-2013-Towards Contactless, Low-Cost and Accurate 3D Fingerprint Identification</a></p>
<p>18 0.38344777 <a title="285-lda-18" href="./cvpr-2013-A_Machine_Learning_Approach_for_Non-blind_Image_Deconvolution.html">17 cvpr-2013-A Machine Learning Approach for Non-blind Image Deconvolution</a></p>
<p>19 0.37931246 <a title="285-lda-19" href="./cvpr-2013-Universality_of_the_Local_Marginal_Polytope.html">448 cvpr-2013-Universality of the Local Marginal Polytope</a></p>
<p>20 0.37849182 <a title="285-lda-20" href="./cvpr-2013-Efficient_Color_Boundary_Detection_with_Color-Opponent_Mechanisms.html">140 cvpr-2013-Efficient Color Boundary Detection with Color-Opponent Mechanisms</a></p>
<br/><br/><br/></body>
</html>
