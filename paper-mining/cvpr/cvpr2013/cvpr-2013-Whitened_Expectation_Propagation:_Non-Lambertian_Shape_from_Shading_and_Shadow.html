<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>466 cvpr-2013-Whitened Expectation Propagation: Non-Lambertian Shape from Shading and Shadow</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-466" href="#">cvpr2013-466</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>466 cvpr-2013-Whitened Expectation Propagation: Non-Lambertian Shape from Shading and Shadow</h1>
<br/><p>Source: <a title="cvpr-2013-466-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Potetz_Whitened_Expectation_Propagation_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Brian Potetz, Mohammadreza Hajiarbabi</p><p>Abstract: For problems over continuous random variables, MRFs with large cliques pose a challenge in probabilistic inference. Difficulties in performing optimization efficiently have limited the probabilistic models explored in computer vision and other fields. One inference technique that handles large cliques well is Expectation Propagation. EP offers run times independent of clique size, which instead depend only on the rank, or intrinsic dimensionality, of potentials. This property would be highly advantageous in computer vision. Unfortunately, for grid-shaped models common in vision, traditional Gaussian EP requires quadratic space and cubic time in the number of pixels. Here, we propose a variation of EP that exploits regularities in natural scene statistics to achieve run times that are linear in both number of pixels and clique size. We test these methods on shape from shading, and we demonstrate strong performance not only for Lambertian surfaces, but also on arbitrary surface reflectance and lighting arrangements, which requires highly non-Gaussian potentials. Finally, we use large, non-local cliques to exploit cast shadow, which is traditionally ignored in shape from shading.</p><p>Reference: <a title="cvpr-2013-466-reference" href="../cvpr2013_reference/cvpr-2013-Whitened_Expectation_Propagation%3A_Non-Lambertian_Shape_from_Shading_and_Shadow_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 com Abstract For problems over continuous random variables, MRFs with large cliques pose a challenge in probabilistic inference. [sent-3, score-0.19]
</p><p>2 One inference technique that handles large cliques well is Expectation Propagation. [sent-5, score-0.24]
</p><p>3 EP offers run times independent of clique size, which instead depend only on the rank, or intrinsic dimensionality, of potentials. [sent-6, score-0.311]
</p><p>4 Here, we propose a variation of EP that exploits regularities in natural scene statistics to achieve run times that are linear in both number of pixels and clique size. [sent-9, score-0.395]
</p><p>5 We test these methods on shape from shading, and we demonstrate strong performance not only for Lambertian surfaces, but  also on arbitrary surface reflectance and lighting arrangements, which requires highly non-Gaussian potentials. [sent-10, score-0.335]
</p><p>6 Finally, we use large, non-local cliques to exploit cast shadow, which is traditionally ignored in shape from shading. [sent-11, score-0.225]
</p><p>7 The run time of BP is exponential in the clique size C: each potential requires O(CMC) operations, where Msiz eis C th:e e ncuhm pboteern otifa slt raeteqsu freors eOac(Ch Mvariable. [sent-16, score-0.425]
</p><p>8 Others have advanced methods of inference which can be applied to probabilistic models over discrete variables with  large cliques[10, 24], or large numbers of small cliques [12]. [sent-21, score-0.311]
</p><p>9 Nevertheless, efficient inference for large cliques remains limited to certain forms of potentials, and remains quadratic or worse in clique size. [sent-23, score-0.51]
</p><p>10 EP works by approximating a factorized distribution with a simpler, tractable distribution from a family of distributions whose moments can be readily computed. [sent-26, score-0.221]
</p><p>11 When the approximating family is a product of independent univariate marginals, EP is equivalent to BP [14]. [sent-27, score-0.225]
</p><p>12 The principal difference between BP and Gaussian EP can thus be summarized by a trade-off in their respective approximating families: BP favors flexible non-Gaussian marginals, while Gaussian EP favors a flexible covariance structure. [sent-30, score-0.246]
</p><p>13 For example, tree-shaped graphical models can have strong covariance structure, and so the approximating family of BP may be very poor for such models. [sent-32, score-0.351]
</p><p>14 In a complex graph, however, accurate covariance models can improve performance because updates to one variable immediately affect distant variables known to be correlated. [sent-35, score-0.207]
</p><p>15 Its running time is independent of clique size, and instead depends polynomially on the rank (or intrinsic dimensionality) of each potential (defined below). [sent-45, score-0.361]
</p><p>16 In this paper, we propose an efficient inference method that retains the computational advantages of  EP, reducing run time and space requirements to linear in the number of pixels, while remaining linear in clique size. [sent-46, score-0.389]
</p><p>17 This is achieved by limiting EP to efficient families of covariance structures chosen based on the statistics of natural scenes. [sent-47, score-0.223]
</p><p>18 We then test this approach on a problem with highly non-Gaussian potentials: non-Lambertian shape from shading (SfS). [sent-48, score-0.192]
</p><p>19 Finally, we use the method to efficiently perform inference over large cliques produced by cast shadows and by global spatial priors. [sent-50, score-0.318]
</p><p>20 ed and the approximating exponential family is a product of independent univariate discrete distributions, then EP is equivalent to classical belief propagation (BP) [14]. [sent-95, score-0.38]
</p><p>21 When the elements of the vector are real-valued, the approximating exponential family is nearly always chosen to be Gaussian: G(? [sent-97, score-0.209]
</p><p>22 Regardless of t)h tei mraen,k r otfh eera tchha potential, the covariance matrix of the posterior S remains full-rank, and must be stored as a D D matrix. [sent-129, score-0.226]
</p><p>23 If the graphical model underlying equation 1 is sparsely connected, it may alleviate memory requirements to store the inverse covariance matrix S−1 rather than S. [sent-134, score-0.222]
</p><p>24 Whitened EP For many problems of computer vision, both the number  of variables D and the number of potentials N grow linearly with the number of pixels. [sent-152, score-0.213]
</p><p>25 One desirable property of EP, however, is that the run time is independent of the size of the cliques; only the rank of the potentials affects the run time. [sent-158, score-0.324]
</p><p>26 Low-rank potentials of large clique size have a wide array of promising applications in computer vision [17, 10]. [sent-159, score-0.38]
</p><p>27 Also, in a multi-scale setting, potentials at coarse scales require large cliques, but rank remains the same at any scale. [sent-161, score-0.188]
</p><p>28 Difficulty in performing inference over large-clique potentials has limited the probabilistic models used in computer vision. [sent-163, score-0.243]
</p><p>29 In this section, we propose an algorithm that achieves both of these goals: run time that is linear in the number of pixels and in clique size. [sent-164, score-0.343]
</p><p>30 Expectation propagation can be made more efficient by limiting the forms of covariance structure expressible by S. [sent-169, score-0.313]
</p><p>31 In order for moment matching to correspond to minimizing KL-divergence, the approximating family P˜ must be an exponential family distribution (Eq. [sent-170, score-0.321]
</p><p>32 expressible covariance structure must include the covariance matrix for natural scenes. [sent-178, score-0.44]
</p><p>33 Additionally, since scene statistics are typically stationary, we prefer that local covariance structure achievable in one region of an image is also achievable in any region. [sent-179, score-0.222]
</p><p>34 Let S denote the covariance matrix for natural scenes. [sent-183, score-0.191]
</p><p>35 However, note that Vi is only non-zero in C columns, where C is the clique size ofthe potential. [sent-201, score-0.243]
</p><p>36 Thus, each update equation can be 111666777644  performed in time O(K3 + K2C), giving the whitened EP technique a nto ttiaml run (tiKme of O(NK2C) per iteration. [sent-209, score-0.42]
</p><p>37 Thus, the proposal that Gaussian EP might still work effectively if S−1 was constrained to WD−S1W is equivalent to the proposal that BcoPn might wd toork W effectively sif e messages were approximated by Gaussians as long as the variables were whitened beforehand to reduce correlation. [sent-211, score-0.446]
</p><p>38 In order to achieve linear time EP with respect to image size, we are not limited solely to diagonal covariance structure in whitened image space. [sent-212, score-0.558]
</p><p>39 gT Whe covariance structure of the posterior distribution may differ from that of the prior. [sent-222, score-0.194]
</p><p>40 Shape from Shading Whitened EP permits inference over images in linear time with respect to both pixels and clique size. [sent-226, score-0.353]
</p><p>41 To achieve this, it constrains the approximating distribution to be Gaussian with a covariance matrix WD−S1W for some diagonal DsiaSn. [sent-227, score-0.288]
</p><p>42 In particular, we are interested in whether Gaussian message approximation will be effective when the potentials φi are highly non-Gaussian. [sent-229, score-0.177]
</p><p>43 One highly non-Gaussian problem in computer vision is shape from shading (SfS). [sent-230, score-0.192]
</p><p>44 The goal of SfS is to estimate 3D shape from a single image, under the assumption that albedo is uniform, lighting originates from a single point from a known direction, and the surface reflectance function is both uniform and known. [sent-231, score-0.356]
</p><p>45 In recent years, several methods have been developed that solve the classical SfS problem well as long as surface reflectance R is assumed to be Lambertian [19, 17, 6, 3, 7]. [sent-233, score-0.211]
</p><p>46 Our hope is that whitened EP, by permitting efficient inference over large cliques, will enable new MRF models capable of tackling generalized depth inference problems. [sent-237, score-0.56]
</p><p>47 In this section, we demonstrate how whitened EP handles several of these issues. [sent-238, score-0.352]
</p><p>48 MRF Data Likelihood In the past, MRF models for SfS have inferred surface normals rather than depth [17]. [sent-239, score-0.243]
</p><p>49 m Haolw toev beer, c nonotall surface normal maps correspond to a valid surface z. [sent-242, score-0.2]
</p><p>50 Methods that infer surface normals must include additional MRF potentials that encourage p and q to obey this relationship. [sent-244, score-0.356]
</p><p>51 Enforcing integrability is often the largest computational bottleneck of probabilistic inference because it requires a clique size of at least four variables [17]. [sent-245, score-0.439]
</p><p>52 This has been difficult to do using belief propagation because it requires a clique size for φR of at least three. [sent-250, score-0.351]
</p><p>53 Belief propagation is exponential in clique size, and φR is not eligible for computational shortcuts such as the linear constraint node simplification. [sent-251, score-0.394]
</p><p>54 In contrast, whitened EP can either infer surface normals or infer depth directly, and the two objectives require similar run times. [sent-253, score-0.706]
</p><p>55 To infer depth, whitened EP operates over a MRF whose variable nodes correspond to the whitened surface depth. [sent-254, score-0.851]
</p><p>56 Let zw (x, y) = Wz refer to the whitened surface depth, where W(x ,isy t)he = li Wnezar whitening etr wanhsitfeornmed. [sent-255, score-0.554]
</p><p>57 Then, for each pixel (x, y), we can enforce that the surface normal at that point is consistent with the known pixel intensity i(x, y) with the potential φR(vp · z, vq · z | i), where vp and vq are the derivatives of inverse whitening fii)l,te wr centered at point (x, y). [sent-257, score-0.435]
</p><p>58 The clique size of this potential is the size of the support of vp and vq, and the rank of the potential is two. [sent-258, score-0.471]
</p><p>59 Because whitened EP is linear in both clique size and rank, inference over this potential is efficient. [sent-259, score-0.74]
</p><p>60 Alternatively, if whitened EP is used to infer surface normals p and q, the clique size would be twice the support of the inverse whitened filter. [sent-260, score-1.167]
</p><p>61 In our experiments, we will use whitened EP to infer depth directly. [sent-266, score-0.451]
</p><p>62 We use a Laplace distribution for φR to penalize depth maps z that are not consistent with the known pixel intensity: φR(vp ·z, vq ·z|i) = φR(p, q|i) = e−|R(p,q)−i)|/b  (15)  where R(p, q) = iis the reflectance map given by the known surface BRDF and lighting. [sent-267, score-0.304]
</p><p>63 MRF Spatial Prior The SfS problem is highly ambiguous: even when lighting direction and albedo are known, one image is consistent with large families of possible 3D surfaces which all render identically [6]. [sent-269, score-0.208]
</p><p>64 ×  Methods that allow spatial priors with larger cliques have produced substantial performance gains [24, 17]. [sent-272, score-0.208]
</p><p>65 However, these methods are limited in the size and form of cliques achievable by the method. [sent-273, score-0.191]
</p><p>66 First, inference is linear in clique size, which could allow the use of large clique spatial priors such as Fields of Experts [20], which consists of 5 5 potentials of rank one. [sent-275, score-0.798]
</p><p>67 sian potential requires no computational cost, regardless of rank or clique size. [sent-277, score-0.361]
</p><p>68 In all following SfS experiments, we use a spatial prior that is implemented as a Gaussian with zero mean and covariance matrix equal to the covariance structure of natural range images S. [sent-284, score-0.355]
</p><p>69 This prior has full rank and clique size rDan, making eits impractical tioor implement using dB cP. [sent-285, score-0.294]
</p><p>70 rIenq audirdeisti oonnl tyo O Oit(s1 e)ff i nci eeancth run taitmioen, unifying many pairwise potentials into one large potential increases the fidelity of the Bethe approximation implicit in message passing algorithms [25]. [sent-287, score-0.272]
</p><p>71 Finally, this approach allows us to match the full covariance structure of natural scenes, including distant non-local covariances. [sent-288, score-0.191]
</p><p>72 As mentioned earlier, a pairwise-connected MRF produces a restricted covariance structure whose inverse matrix S−1 only  contains elements along three unique diagonals [15]. [sent-289, score-0.197]
</p><p>73 Gaussian potentials permit EP to capture the second order statistics of all higher-order derivatives and any other linear feature. [sent-292, score-0.193]
</p><p>74 Results of whitened EP under several reflectances and lighting conditions. [sent-314, score-0.467]
</p><p>75 In all experiments, whitened EP was run for 10 iterations, which is typically near to convergence. [sent-330, score-0.42]
</p><p>76 was found numerically at each potential by sampling over a 26 26 discrete reflectance map (resembling fig. [sent-333, score-0.178]
</p><p>77 We also implemented classical EP with a sparse inverse covariance matrix; results are shown in 1d. [sent-340, score-0.197]
</p><p>78 Among these methods, whitened EP is fastest and admits a wider class of MRF models. [sent-346, score-0.352]
</p><p>79 For the 128 128 penny image, whitened EP required 8d emlsi. [sent-347, score-0.415]
</p><p>80 8×G1H28z pXeneonyn, amndag er u,n w-thiimteen grows linearly with the number of pixels, linearly with the clique size of the potentials, and linearly in their rank. [sent-349, score-0.342]
</p><p>81 The BP result required 24 hours, grows linearly with the number of pixels, quadratically in the clique size, and exponentially in rank. [sent-350, score-0.301]
</p><p>82 Our results suggests that the constrained covariance family used by whitened EP provided a sufficient approximation of the full covariance structure inferred by standard EP. [sent-367, score-0.811]
</p><p>83 While there has been some success in applying methods such as Lax-Friedrichs and fastmarching to non-Lambertian reflectance [1, 23], these generalizations must proceed on a case-by-case basis for each class of reflectance functions. [sent-369, score-0.254]
</p><p>84 Example potentials φR are shown along the left column of figure 2, and are highly non-Gaussian. [sent-373, score-0.177]
</p><p>85 When cast shadows are present and lighting originates from a single point source, we must enforce two rules. [sent-384, score-0.194]
</p><p>86 First, pixels lying in shadow must be occluded from the lighting direction. [sent-385, score-0.202]
</p><p>87 Because we are inferring depth directly (as opposed to surface normals), this can be enforced simply by a pairwise potential of rank one. [sent-386, score-0.27]
</p><p>88 Suppose that lighting comes from the left, and suppose zunlit is the depth of a shadowed pixel, and zlit is the depth at the nearest unshadowed pixel to its left. [sent-387, score-0.35]
</p><p>89 Secondly, we must also enforce that pixels that are lit within the image are unshadowed in the inferred shape. [sent-391, score-0.264]
</p><p>90 Note that this approach to enforcing shadow cues would be expensive using BP because the potential φL is realvalued with a clique size of three, and is not eligible for LCN computational shortcuts. [sent-403, score-0.423]
</p><p>91 Traditional Gaussian EP becomes inefficient whenever shadow cues are enforced because non-local connectivity produces an inverse covariance matrix that is no longer sparse. [sent-404, score-0.275]
</p><p>92 Importantly, the shadow constraint is satisfied completely by the inferred surface: all pixels that are lit in the input image are unshadowed in the inferred surface, and all black pixels in the input are shadowed in the output. [sent-406, score-0.42]
</p><p>93 Conclusions The methods in this paper reduce the run time ofEP from cubic to linear in the number of pixels for visual inference,  while retaining a run time that is linear in clique size. [sent-408, score-0.411]
</p><p>94 This is a substantial improvement over BP, which is exponential in clique size. [sent-409, score-0.29]
</p><p>95 The computational expense of inference for large cliques has prohibited the investigation of complex probabilistic models for vision. [sent-410, score-0.268]
</p><p>96 Our hope is that whitened EP will facilitate further research in these directions. [sent-411, score-0.352]
</p><p>97 Results for whitened EP on SfS shows that the sacrifice in performance for this approach is small, even in problems with highly non-Gaussian potentials. [sent-412, score-0.417]
</p><p>98 We expect that efficient inference with large cliques will be especially beneficial for depth inference, where multi-scale representations, complex spatial priors, shadows, occlusions, and the simultaneous inference of unknown global scene attributes all necessitate potentials with large cliques. [sent-414, score-0.507]
</p><p>99 High-frequency shape and albedo from shading using natural image statistics. [sent-431, score-0.216]
</p><p>100 Shape from shading with a linear triangular element surface model. [sent-492, score-0.228]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ep', 0.535), ('whitened', 0.352), ('sfs', 0.339), ('clique', 0.243), ('bp', 0.164), ('covariance', 0.164), ('cliques', 0.162), ('potentials', 0.137), ('shading', 0.128), ('reflectance', 0.111), ('visvi', 0.106), ('surface', 0.1), ('lambertian', 0.089), ('approximating', 0.082), ('family', 0.08), ('whitening', 0.078), ('lit', 0.078), ('inference', 0.078), ('shadow', 0.078), ('ivw', 0.071), ('unshadowed', 0.071), ('propagation', 0.069), ('mrf', 0.069), ('run', 0.068), ('potential', 0.067), ('expectation', 0.066), ('penny', 0.063), ('lighting', 0.06), ('vi', 0.055), ('reflectances', 0.055), ('expressible', 0.053), ('vwd', 0.053), ('zlit', 0.053), ('depth', 0.052), ('rank', 0.051), ('inferred', 0.051), ('marginals', 0.048), ('ivi', 0.047), ('exponential', 0.047), ('infer', 0.047), ('priors', 0.046), ('mrfs', 0.045), ('vp', 0.043), ('variables', 0.043), ('gaussian', 0.042), ('diagonal', 0.042), ('vq', 0.041), ('normals', 0.04), ('highly', 0.04), ('ds', 0.04), ('surfaces', 0.039), ('univariate', 0.039), ('shadows', 0.039), ('cast', 0.039), ('bk', 0.039), ('belief', 0.039), ('albedo', 0.037), ('eligible', 0.035), ('kurtotic', 0.035), ('zleft', 0.035), ('zunlit', 0.035), ('minka', 0.035), ('linearly', 0.033), ('inverse', 0.033), ('derivatives', 0.032), ('pixels', 0.032), ('must', 0.032), ('families', 0.032), ('beckmann', 0.031), ('potetz', 0.031), ('differentiating', 0.031), ('factorized', 0.03), ('posterior', 0.03), ('moments', 0.029), ('bethe', 0.029), ('achievable', 0.029), ('probabilistic', 0.028), ('vw', 0.027), ('shadowed', 0.027), ('wd', 0.027), ('natural', 0.027), ('forms', 0.027), ('subfigure', 0.026), ('experts', 0.026), ('power', 0.025), ('alternatively', 0.025), ('past', 0.025), ('quadratically', 0.025), ('binocular', 0.025), ('sacrifice', 0.025), ('regularities', 0.025), ('graphical', 0.025), ('zw', 0.024), ('originates', 0.024), ('permit', 0.024), ('equivalent', 0.024), ('bottleneck', 0.024), ('shape', 0.024), ('integrability', 0.023), ('vis', 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999958 <a title="466-tfidf-1" href="./cvpr-2013-Whitened_Expectation_Propagation%3A_Non-Lambertian_Shape_from_Shading_and_Shadow.html">466 cvpr-2013-Whitened Expectation Propagation: Non-Lambertian Shape from Shading and Shadow</a></p>
<p>Author: Brian Potetz, Mohammadreza Hajiarbabi</p><p>Abstract: For problems over continuous random variables, MRFs with large cliques pose a challenge in probabilistic inference. Difficulties in performing optimization efficiently have limited the probabilistic models explored in computer vision and other fields. One inference technique that handles large cliques well is Expectation Propagation. EP offers run times independent of clique size, which instead depend only on the rank, or intrinsic dimensionality, of potentials. This property would be highly advantageous in computer vision. Unfortunately, for grid-shaped models common in vision, traditional Gaussian EP requires quadratic space and cubic time in the number of pixels. Here, we propose a variation of EP that exploits regularities in natural scene statistics to achieve run times that are linear in both number of pixels and clique size. We test these methods on shape from shading, and we demonstrate strong performance not only for Lambertian surfaces, but also on arbitrary surface reflectance and lighting arrangements, which requires highly non-Gaussian potentials. Finally, we use large, non-local cliques to exploit cast shadow, which is traditionally ignored in shape from shading.</p><p>2 0.18801424 <a title="466-tfidf-2" href="./cvpr-2013-Shading-Based_Shape_Refinement_of_RGB-D_Images.html">394 cvpr-2013-Shading-Based Shape Refinement of RGB-D Images</a></p>
<p>Author: Lap-Fai Yu, Sai-Kit Yeung, Yu-Wing Tai, Stephen Lin</p><p>Abstract: We present a shading-based shape refinement algorithm which uses a noisy, incomplete depth map from Kinect to help resolve ambiguities in shape-from-shading. In our framework, the partial depth information is used to overcome bas-relief ambiguity in normals estimation, as well as to assist in recovering relative albedos, which are needed to reliably estimate the lighting environment and to separate shading from albedo. This refinement of surface normals using a noisy depth map leads to high-quality 3D surfaces. The effectiveness of our algorithm is demonstrated through several challenging real-world examples.</p><p>3 0.12924115 <a title="466-tfidf-3" href="./cvpr-2013-A_Higher-Order_CRF_Model_for_Road_Network_Extraction.html">13 cvpr-2013-A Higher-Order CRF Model for Road Network Extraction</a></p>
<p>Author: Jan D. Wegner, Javier A. Montoya-Zegarra, Konrad Schindler</p><p>Abstract: The aim of this work is to extract the road network from aerial images. What makes the problem challenging is the complex structure of the prior: roads form a connected network of smooth, thin segments which meet at junctions and crossings. This type of a-priori knowledge is more difficult to turn into a tractable model than standard smoothness or co-occurrence assumptions. We develop a novel CRF formulation for road labeling, in which the prior is represented by higher-order cliques that connect sets of superpixels along straight line segments. These long-range cliques have asymmetric PN-potentials, which express a preference to assign all rather than just some of their constituent superpixels to the road class. Thus, the road likelihood is amplified for thin chains of superpixels, while the CRF is still amenable to optimization with graph cuts. Since the number of such cliques of arbitrary length is huge, we furthermorepropose a sampling scheme which concentrates on those cliques which are most relevant for the optimization. In experiments on two different databases the model significantly improves both the per-pixel accuracy and the topological correctness of the extracted roads, and outper- forms both a simple smoothness prior and heuristic rulebased road completion.</p><p>4 0.12830155 <a title="466-tfidf-4" href="./cvpr-2013-Intrinsic_Scene_Properties_from_a_Single_RGB-D_Image.html">227 cvpr-2013-Intrinsic Scene Properties from a Single RGB-D Image</a></p>
<p>Author: Jonathan T. Barron, Jitendra Malik</p><p>Abstract: In this paper we extend the “shape, illumination and reflectance from shading ” (SIRFS) model [3, 4], which recovers intrinsic scene properties from a single image. Though SIRFS performs well on images of segmented objects, it performs poorly on images of natural scenes, which contain occlusion and spatially-varying illumination. We therefore present Scene-SIRFS, a generalization of SIRFS in which we have a mixture of shapes and a mixture of illuminations, and those mixture components are embedded in a “soft” segmentation of the input image. We additionally use the noisy depth maps provided by RGB-D sensors (in this case, the Kinect) to improve shape estimation. Our model takes as input a single RGB-D image and produces as output an improved depth map, a set of surface normals, a reflectance image, a shading image, and a spatially varying model of illumination. The output of our model can be used for graphics applications, or for any application involving RGB-D images.</p><p>5 0.12699611 <a title="466-tfidf-5" href="./cvpr-2013-Uncalibrated_Photometric_Stereo_for_Unknown_Isotropic_Reflectances.html">443 cvpr-2013-Uncalibrated Photometric Stereo for Unknown Isotropic Reflectances</a></p>
<p>Author: Feng Lu, Yasuyuki Matsushita, Imari Sato, Takahiro Okabe, Yoichi Sato</p><p>Abstract: We propose an uncalibrated photometric stereo method that works with general and unknown isotropic reflectances. Our method uses a pixel intensity profile, which is a sequence of radiance intensities recorded at a pixel across multi-illuminance images. We show that for general isotropic materials, the geodesic distance between intensity profiles is linearly related to the angular difference of their surface normals, and that the intensity distribution of an intensity profile conveys information about the reflectance properties, when the intensity profile is obtained under uniformly distributed directional lightings. Based on these observations, we show that surface normals can be estimated up to a convex/concave ambiguity. A solution method based on matrix decomposition with missing data is developed for a reliable estimation. Quantitative and qualitative evaluations of our method are performed using both synthetic and real-world scenes.</p><p>6 0.12161188 <a title="466-tfidf-6" href="./cvpr-2013-Boundary_Cues_for_3D_Object_Shape_Recovery.html">71 cvpr-2013-Boundary Cues for 3D Object Shape Recovery</a></p>
<p>7 0.12051308 <a title="466-tfidf-7" href="./cvpr-2013-Bayesian_Depth-from-Defocus_with_Shading_Constraints.html">56 cvpr-2013-Bayesian Depth-from-Defocus with Shading Constraints</a></p>
<p>8 0.12018382 <a title="466-tfidf-8" href="./cvpr-2013-Non-parametric_Filtering_for_Geometric_Detail_Extraction_and_Material_Representation.html">305 cvpr-2013-Non-parametric Filtering for Geometric Detail Extraction and Material Representation</a></p>
<p>9 0.1100296 <a title="466-tfidf-9" href="./cvpr-2013-Nonlinearly_Constrained_MRFs%3A_Exploring_the_Intrinsic_Dimensions_of_Higher-Order_Cliques.html">308 cvpr-2013-Nonlinearly Constrained MRFs: Exploring the Intrinsic Dimensions of Higher-Order Cliques</a></p>
<p>10 0.1099917 <a title="466-tfidf-10" href="./cvpr-2013-Multi-view_Photometric_Stereo_with_Spatially_Varying_Isotropic_Materials.html">303 cvpr-2013-Multi-view Photometric Stereo with Spatially Varying Isotropic Materials</a></p>
<p>11 0.10812848 <a title="466-tfidf-11" href="./cvpr-2013-Fully-Connected_CRFs_with_Non-Parametric_Pairwise_Potential.html">180 cvpr-2013-Fully-Connected CRFs with Non-Parametric Pairwise Potential</a></p>
<p>12 0.099929705 <a title="466-tfidf-12" href="./cvpr-2013-The_Episolar_Constraint%3A_Monocular_Shape_from_Shadow_Correspondence.html">428 cvpr-2013-The Episolar Constraint: Monocular Shape from Shadow Correspondence</a></p>
<p>13 0.098153137 <a title="466-tfidf-13" href="./cvpr-2013-Analyzing_Semantic_Segmentation_Using_Hybrid_Human-Machine_CRFs.html">43 cvpr-2013-Analyzing Semantic Segmentation Using Hybrid Human-Machine CRFs</a></p>
<p>14 0.092944436 <a title="466-tfidf-14" href="./cvpr-2013-Exploring_Compositional_High_Order_Pattern_Potentials_for_Structured_Output_Learning.html">156 cvpr-2013-Exploring Compositional High Order Pattern Potentials for Structured Output Learning</a></p>
<p>15 0.090816453 <a title="466-tfidf-15" href="./cvpr-2013-What_Object_Motion_Reveals_about_Shape_with_Unknown_BRDF_and_Lighting.html">465 cvpr-2013-What Object Motion Reveals about Shape with Unknown BRDF and Lighting</a></p>
<p>16 0.08554358 <a title="466-tfidf-16" href="./cvpr-2013-A_Principled_Deep_Random_Field_Model_for_Image_Segmentation.html">24 cvpr-2013-A Principled Deep Random Field Model for Image Segmentation</a></p>
<p>17 0.081621535 <a title="466-tfidf-17" href="./cvpr-2013-Discrete_MRF_Inference_of_Marginal_Densities_for_Non-uniformly_Discretized_Variable_Space.html">128 cvpr-2013-Discrete MRF Inference of Marginal Densities for Non-uniformly Discretized Variable Space</a></p>
<p>18 0.081203505 <a title="466-tfidf-18" href="./cvpr-2013-Fast_Energy_Minimization_Using_Learned_State_Filters.html">165 cvpr-2013-Fast Energy Minimization Using Learned State Filters</a></p>
<p>19 0.076431163 <a title="466-tfidf-19" href="./cvpr-2013-Continuous_Inference_in_Graphical_Models_with_Polynomial_Energies.html">95 cvpr-2013-Continuous Inference in Graphical Models with Polynomial Energies</a></p>
<p>20 0.076378413 <a title="466-tfidf-20" href="./cvpr-2013-Layer_Depth_Denoising_and_Completion_for_Structured-Light_RGB-D_Cameras.html">245 cvpr-2013-Layer Depth Denoising and Completion for Structured-Light RGB-D Cameras</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.154), (1, 0.128), (2, 0.009), (3, 0.047), (4, 0.039), (5, -0.047), (6, -0.044), (7, 0.073), (8, -0.016), (9, -0.029), (10, 0.007), (11, -0.077), (12, -0.134), (13, 0.036), (14, 0.002), (15, 0.099), (16, 0.02), (17, -0.008), (18, 0.057), (19, -0.086), (20, -0.017), (21, -0.039), (22, -0.015), (23, 0.043), (24, 0.053), (25, -0.033), (26, -0.064), (27, 0.071), (28, -0.059), (29, -0.038), (30, 0.078), (31, -0.087), (32, 0.017), (33, 0.14), (34, -0.097), (35, 0.069), (36, -0.051), (37, -0.052), (38, 0.008), (39, 0.069), (40, -0.023), (41, -0.007), (42, -0.002), (43, -0.09), (44, 0.031), (45, -0.011), (46, 0.052), (47, 0.022), (48, -0.01), (49, -0.072)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93617094 <a title="466-lsi-1" href="./cvpr-2013-Whitened_Expectation_Propagation%3A_Non-Lambertian_Shape_from_Shading_and_Shadow.html">466 cvpr-2013-Whitened Expectation Propagation: Non-Lambertian Shape from Shading and Shadow</a></p>
<p>Author: Brian Potetz, Mohammadreza Hajiarbabi</p><p>Abstract: For problems over continuous random variables, MRFs with large cliques pose a challenge in probabilistic inference. Difficulties in performing optimization efficiently have limited the probabilistic models explored in computer vision and other fields. One inference technique that handles large cliques well is Expectation Propagation. EP offers run times independent of clique size, which instead depend only on the rank, or intrinsic dimensionality, of potentials. This property would be highly advantageous in computer vision. Unfortunately, for grid-shaped models common in vision, traditional Gaussian EP requires quadratic space and cubic time in the number of pixels. Here, we propose a variation of EP that exploits regularities in natural scene statistics to achieve run times that are linear in both number of pixels and clique size. We test these methods on shape from shading, and we demonstrate strong performance not only for Lambertian surfaces, but also on arbitrary surface reflectance and lighting arrangements, which requires highly non-Gaussian potentials. Finally, we use large, non-local cliques to exploit cast shadow, which is traditionally ignored in shape from shading.</p><p>2 0.66433835 <a title="466-lsi-2" href="./cvpr-2013-Non-parametric_Filtering_for_Geometric_Detail_Extraction_and_Material_Representation.html">305 cvpr-2013-Non-parametric Filtering for Geometric Detail Extraction and Material Representation</a></p>
<p>Author: Zicheng Liao, Jason Rock, Yang Wang, David Forsyth</p><p>Abstract: Geometric detail is a universal phenomenon in real world objects. It is an important component in object modeling, but not accounted for in current intrinsic image works. In this work, we explore using a non-parametric method to separate geometric detail from intrinsic image components. We further decompose an image as albedo ∗ (ccoomarpsoen-escnatsle. shading +e shading pdoestaeil a).n Oaugre decomposition offers quantitative improvement in albedo recovery and material classification.Our method also enables interesting image editing activities, including bump removal, geometric detail smoothing/enhancement and material transfer.</p><p>3 0.62026387 <a title="466-lsi-3" href="./cvpr-2013-Bayesian_Depth-from-Defocus_with_Shading_Constraints.html">56 cvpr-2013-Bayesian Depth-from-Defocus with Shading Constraints</a></p>
<p>Author: Chen Li, Shuochen Su, Yasuyuki Matsushita, Kun Zhou, Stephen Lin</p><p>Abstract: We present a method that enhances the performance of depth-from-defocus (DFD) through the use of shading information. DFD suffers from important limitations namely coarse shape reconstruction and poor accuracy on textureless surfaces that can be overcome with the help of shading. We integrate both forms of data within a Bayesian framework that capitalizes on their relative strengths. Shading data, however, is challenging to recover accurately from surfaces that contain texture. To address this issue, we propose an iterative technique that utilizes depth information to improve shading estimation, which in turn is used to elevate depth estimation in the presence of textures. With this approach, we demonstrate improvements over existing DFD techniques, as well as effective shape reconstruction of textureless surfaces. – –</p><p>4 0.60534543 <a title="466-lsi-4" href="./cvpr-2013-A_New_Perspective_on_Uncalibrated_Photometric_Stereo.html">21 cvpr-2013-A New Perspective on Uncalibrated Photometric Stereo</a></p>
<p>Author: Thoma Papadhimitri, Paolo Favaro</p><p>Abstract: We investigate the problem of reconstructing normals, albedo and lights of Lambertian surfaces in uncalibrated photometric stereo under the perspective projection model. Our analysis is based on establishing the integrability constraint. In the orthographicprojection case, it is well-known that when such constraint is imposed, a solution can be identified only up to 3 parameters, the so-called generalized bas-relief (GBR) ambiguity. We show that in the perspective projection case the solution is unique. We also propose a closed-form solution which is simple, efficient and robust. We test our algorithm on synthetic data and publicly available real data. Our quantitative tests show that our method outperforms all prior work of uncalibrated photometric stereo under orthographic projection.</p><p>5 0.60257828 <a title="466-lsi-5" href="./cvpr-2013-Boundary_Cues_for_3D_Object_Shape_Recovery.html">71 cvpr-2013-Boundary Cues for 3D Object Shape Recovery</a></p>
<p>Author: Kevin Karsch, Zicheng Liao, Jason Rock, Jonathan T. Barron, Derek Hoiem</p><p>Abstract: Early work in computer vision considered a host of geometric cues for both shape reconstruction [11] and recognition [14]. However, since then, the vision community has focused heavily on shading cues for reconstruction [1], and moved towards data-driven approaches for recognition [6]. In this paper, we reconsider these perhaps overlooked “boundary” cues (such as self occlusions and folds in a surface), as well as many other established constraints for shape reconstruction. In a variety of user studies and quantitative tasks, we evaluate how well these cues inform shape reconstruction (relative to each other) in terms of both shape quality and shape recognition. Our findings suggest many new directions for future research in shape reconstruction, such as automatic boundary cue detection and relaxing assumptions in shape from shading (e.g. orthographic projection, Lambertian surfaces).</p><p>6 0.56363738 <a title="466-lsi-6" href="./cvpr-2013-A_Principled_Deep_Random_Field_Model_for_Image_Segmentation.html">24 cvpr-2013-A Principled Deep Random Field Model for Image Segmentation</a></p>
<p>7 0.56198633 <a title="466-lsi-7" href="./cvpr-2013-Uncalibrated_Photometric_Stereo_for_Unknown_Isotropic_Reflectances.html">443 cvpr-2013-Uncalibrated Photometric Stereo for Unknown Isotropic Reflectances</a></p>
<p>8 0.55842435 <a title="466-lsi-8" href="./cvpr-2013-Shading-Based_Shape_Refinement_of_RGB-D_Images.html">394 cvpr-2013-Shading-Based Shape Refinement of RGB-D Images</a></p>
<p>9 0.55297983 <a title="466-lsi-9" href="./cvpr-2013-Intrinsic_Scene_Properties_from_a_Single_RGB-D_Image.html">227 cvpr-2013-Intrinsic Scene Properties from a Single RGB-D Image</a></p>
<p>10 0.55171216 <a title="466-lsi-10" href="./cvpr-2013-Nonlinearly_Constrained_MRFs%3A_Exploring_the_Intrinsic_Dimensions_of_Higher-Order_Cliques.html">308 cvpr-2013-Nonlinearly Constrained MRFs: Exploring the Intrinsic Dimensions of Higher-Order Cliques</a></p>
<p>11 0.54800856 <a title="466-lsi-11" href="./cvpr-2013-Fully-Connected_CRFs_with_Non-Parametric_Pairwise_Potential.html">180 cvpr-2013-Fully-Connected CRFs with Non-Parametric Pairwise Potential</a></p>
<p>12 0.54219937 <a title="466-lsi-12" href="./cvpr-2013-Relative_Volume_Constraints_for_Single_View_3D_Reconstruction.html">354 cvpr-2013-Relative Volume Constraints for Single View 3D Reconstruction</a></p>
<p>13 0.52412111 <a title="466-lsi-13" href="./cvpr-2013-Towards_Contactless%2C_Low-Cost_and_Accurate_3D_Fingerprint_Identification.html">435 cvpr-2013-Towards Contactless, Low-Cost and Accurate 3D Fingerprint Identification</a></p>
<p>14 0.52026314 <a title="466-lsi-14" href="./cvpr-2013-Photometric_Ambient_Occlusion.html">330 cvpr-2013-Photometric Ambient Occlusion</a></p>
<p>15 0.48992121 <a title="466-lsi-15" href="./cvpr-2013-Universality_of_the_Local_Marginal_Polytope.html">448 cvpr-2013-Universality of the Local Marginal Polytope</a></p>
<p>16 0.48936796 <a title="466-lsi-16" href="./cvpr-2013-Continuous_Inference_in_Graphical_Models_with_Polynomial_Energies.html">95 cvpr-2013-Continuous Inference in Graphical Models with Polynomial Energies</a></p>
<p>17 0.48419189 <a title="466-lsi-17" href="./cvpr-2013-A_Higher-Order_CRF_Model_for_Road_Network_Extraction.html">13 cvpr-2013-A Higher-Order CRF Model for Road Network Extraction</a></p>
<p>18 0.47815853 <a title="466-lsi-18" href="./cvpr-2013-Discrete_MRF_Inference_of_Marginal_Densities_for_Non-uniformly_Discretized_Variable_Space.html">128 cvpr-2013-Discrete MRF Inference of Marginal Densities for Non-uniformly Discretized Variable Space</a></p>
<p>19 0.4714278 <a title="466-lsi-19" href="./cvpr-2013-Exploring_Compositional_High_Order_Pattern_Potentials_for_Structured_Output_Learning.html">156 cvpr-2013-Exploring Compositional High Order Pattern Potentials for Structured Output Learning</a></p>
<p>20 0.45314932 <a title="466-lsi-20" href="./cvpr-2013-Learning_for_Structured_Prediction_Using_Approximate_Subgradient_Descent_with_Working_Sets.html">262 cvpr-2013-Learning for Structured Prediction Using Approximate Subgradient Descent with Working Sets</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.126), (16, 0.016), (26, 0.037), (28, 0.027), (33, 0.258), (66, 0.012), (67, 0.035), (69, 0.034), (70, 0.242), (77, 0.011), (87, 0.109)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.85410786 <a title="466-lda-1" href="./cvpr-2013-Fine-Grained_Crowdsourcing_for_Fine-Grained_Recognition.html">174 cvpr-2013-Fine-Grained Crowdsourcing for Fine-Grained Recognition</a></p>
<p>Author: Jia Deng, Jonathan Krause, Li Fei-Fei</p><p>Abstract: Fine-grained recognition concerns categorization at sub-ordinate levels, where the distinction between object classes is highly local. Compared to basic level recognition, fine-grained categorization can be more challenging as there are in general less data and fewer discriminative features. This necessitates the use of stronger prior for feature selection. In this work, we include humans in the loop to help computers select discriminative features. We introduce a novel online game called “Bubbles ” that reveals discriminative features humans use. The player’s goal is to identify the category of a heavily blurred image. During the game, the player can choose to reveal full details of circular regions ( “bubbles”), with a certain penalty. With proper setup the game generates discriminative bubbles with assured quality. We next propose the “BubbleBank” algorithm that uses the human selected bubbles to improve machine recognition performance. Experiments demonstrate that our approach yields large improvements over the previous state of the art on challenging benchmarks.</p><p>same-paper 2 0.85039747 <a title="466-lda-2" href="./cvpr-2013-Whitened_Expectation_Propagation%3A_Non-Lambertian_Shape_from_Shading_and_Shadow.html">466 cvpr-2013-Whitened Expectation Propagation: Non-Lambertian Shape from Shading and Shadow</a></p>
<p>Author: Brian Potetz, Mohammadreza Hajiarbabi</p><p>Abstract: For problems over continuous random variables, MRFs with large cliques pose a challenge in probabilistic inference. Difficulties in performing optimization efficiently have limited the probabilistic models explored in computer vision and other fields. One inference technique that handles large cliques well is Expectation Propagation. EP offers run times independent of clique size, which instead depend only on the rank, or intrinsic dimensionality, of potentials. This property would be highly advantageous in computer vision. Unfortunately, for grid-shaped models common in vision, traditional Gaussian EP requires quadratic space and cubic time in the number of pixels. Here, we propose a variation of EP that exploits regularities in natural scene statistics to achieve run times that are linear in both number of pixels and clique size. We test these methods on shape from shading, and we demonstrate strong performance not only for Lambertian surfaces, but also on arbitrary surface reflectance and lighting arrangements, which requires highly non-Gaussian potentials. Finally, we use large, non-local cliques to exploit cast shadow, which is traditionally ignored in shape from shading.</p><p>3 0.84461111 <a title="466-lda-3" href="./cvpr-2013-A_Practical_Rank-Constrained_Eight-Point_Algorithm_for_Fundamental_Matrix_Estimation.html">23 cvpr-2013-A Practical Rank-Constrained Eight-Point Algorithm for Fundamental Matrix Estimation</a></p>
<p>Author: Yinqiang Zheng, Shigeki Sugimoto, Masatoshi Okutomi</p><p>Abstract: Due to its simplicity, the eight-point algorithm has been widely used in fundamental matrix estimation. Unfortunately, the rank-2 constraint of a fundamental matrix is enforced via a posterior rank correction step, thus leading to non-optimal solutions to the original problem. To address this drawback, existing algorithms need to solve either a very high order polynomial or a sequence of convex relaxation problems, both of which are computationally ineffective and numerically unstable. In this work, we present a new rank-2 constrained eight-point algorithm, which directly incorporates the rank-2 constraint in the minimization process. To avoid singularities, we propose to solve seven subproblems and retrieve their globally optimal solutions by using tailored polynomial system solvers. Our proposed method is noniterative, computationally efficient and numerically stable. Experiment results have verified its superiority over existing algebraic error based algorithms in terms of accuracy, as well as its advantages when used to initialize geometric error based algorithms.</p><p>4 0.83682305 <a title="466-lda-4" href="./cvpr-2013-Event_Recognition_in_Videos_by_Learning_from_Heterogeneous_Web_Sources.html">150 cvpr-2013-Event Recognition in Videos by Learning from Heterogeneous Web Sources</a></p>
<p>Author: Lin Chen, Lixin Duan, Dong Xu</p><p>Abstract: In this work, we propose to leverage a large number of loosely labeled web videos (e.g., from YouTube) and web images (e.g., from Google/Bing image search) for visual event recognition in consumer videos without requiring any labeled consumer videos. We formulate this task as a new multi-domain adaptation problem with heterogeneous sources, in which the samples from different source domains can be represented by different types of features with different dimensions (e.g., the SIFTfeaturesfrom web images and space-time (ST) features from web videos) while the target domain samples have all types of features. To effectively cope with the heterogeneous sources where some source domains are more relevant to the target domain, we propose a new method called Multi-domain Adaptation with Heterogeneous Sources (MDA-HS) to learn an optimal target classifier, in which we simultaneously seek the optimal weights for different source domains with different types of features as well as infer the labels of unlabeled target domain data based on multiple types of features. We solve our optimization problem by using the cutting-plane algorithm based on group-based multiple kernel learning. Comprehensive experiments on two datasets demonstrate the effectiveness of MDA-HS for event recognition in consumer videos.</p><p>5 0.80014056 <a title="466-lda-5" href="./cvpr-2013-Compressed_Hashing.html">87 cvpr-2013-Compressed Hashing</a></p>
<p>Author: Yue Lin, Rong Jin, Deng Cai, Shuicheng Yan, Xuelong Li</p><p>Abstract: Recent studies have shown that hashing methods are effective for high dimensional nearest neighbor search. A common problem shared by many existing hashing methods is that in order to achieve a satisfied performance, a large number of hash tables (i.e., long codewords) are required. To address this challenge, in this paper we propose a novel approach called Compressed Hashing by exploring the techniques of sparse coding and compressed sensing. In particular, we introduce a sparse coding scheme, based on the approximation theory of integral operator, that generate sparse representation for high dimensional vectors. We then project sparse codes into a low dimensional space by effectively exploring the Restricted Isometry Property (RIP), a key property in compressed sensing theory. Both of the theoretical analysis and the empirical studies on two large data sets show that the proposed approach is more effective than the state-of-the-art hashing algorithms.</p><p>6 0.78308272 <a title="466-lda-6" href="./cvpr-2013-Nonparametric_Scene_Parsing_with_Adaptive_Feature_Relevance_and_Semantic_Context.html">309 cvpr-2013-Nonparametric Scene Parsing with Adaptive Feature Relevance and Semantic Context</a></p>
<p>7 0.78273773 <a title="466-lda-7" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<p>8 0.77940464 <a title="466-lda-8" href="./cvpr-2013-Multi-view_Photometric_Stereo_with_Spatially_Varying_Isotropic_Materials.html">303 cvpr-2013-Multi-view Photometric Stereo with Spatially Varying Isotropic Materials</a></p>
<p>9 0.77901286 <a title="466-lda-9" href="./cvpr-2013-Intrinsic_Scene_Properties_from_a_Single_RGB-D_Image.html">227 cvpr-2013-Intrinsic Scene Properties from a Single RGB-D Image</a></p>
<p>10 0.7783016 <a title="466-lda-10" href="./cvpr-2013-Cross-View_Action_Recognition_via_a_Continuous_Virtual_Path.html">98 cvpr-2013-Cross-View Action Recognition via a Continuous Virtual Path</a></p>
<p>11 0.77799463 <a title="466-lda-11" href="./cvpr-2013-Boundary_Cues_for_3D_Object_Shape_Recovery.html">71 cvpr-2013-Boundary Cues for 3D Object Shape Recovery</a></p>
<p>12 0.77776092 <a title="466-lda-12" href="./cvpr-2013-Multi-scale_Curve_Detection_on_Surfaces.html">298 cvpr-2013-Multi-scale Curve Detection on Surfaces</a></p>
<p>13 0.77759063 <a title="466-lda-13" href="./cvpr-2013-A_Minimum_Error_Vanishing_Point_Detection_Approach_for_Uncalibrated_Monocular_Images_of_Man-Made_Environments.html">19 cvpr-2013-A Minimum Error Vanishing Point Detection Approach for Uncalibrated Monocular Images of Man-Made Environments</a></p>
<p>14 0.77756459 <a title="466-lda-14" href="./cvpr-2013-Shading-Based_Shape_Refinement_of_RGB-D_Images.html">394 cvpr-2013-Shading-Based Shape Refinement of RGB-D Images</a></p>
<p>15 0.77713746 <a title="466-lda-15" href="./cvpr-2013-Incorporating_User_Interaction_and_Topological_Constraints_within_Contour_Completion_via_Discrete_Calculus.html">222 cvpr-2013-Incorporating User Interaction and Topological Constraints within Contour Completion via Discrete Calculus</a></p>
<p>16 0.77683878 <a title="466-lda-16" href="./cvpr-2013-Ensemble_Learning_for_Confidence_Measures_in_Stereo_Vision.html">147 cvpr-2013-Ensemble Learning for Confidence Measures in Stereo Vision</a></p>
<p>17 0.77660686 <a title="466-lda-17" href="./cvpr-2013-Label_Propagation_from_ImageNet_to_3D_Point_Clouds.html">242 cvpr-2013-Label Propagation from ImageNet to 3D Point Clouds</a></p>
<p>18 0.77642536 <a title="466-lda-18" href="./cvpr-2013-Globally_Consistent_Multi-label_Assignment_on_the_Ray_Space_of_4D_Light_Fields.html">188 cvpr-2013-Globally Consistent Multi-label Assignment on the Ray Space of 4D Light Fields</a></p>
<p>19 0.776398 <a title="466-lda-19" href="./cvpr-2013-Exploiting_the_Power_of_Stereo_Confidences.html">155 cvpr-2013-Exploiting the Power of Stereo Confidences</a></p>
<p>20 0.77617592 <a title="466-lda-20" href="./cvpr-2013-Separating_Signal_from_Noise_Using_Patch_Recurrence_across_Scales.html">393 cvpr-2013-Separating Signal from Noise Using Patch Recurrence across Scales</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
