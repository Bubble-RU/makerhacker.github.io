<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>156 cvpr-2013-Exploring Compositional High Order Pattern Potentials for Structured Output Learning</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-156" href="#">cvpr2013-156</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>156 cvpr-2013-Exploring Compositional High Order Pattern Potentials for Structured Output Learning</h1>
<br/><p>Source: <a title="cvpr-2013-156-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Li_Exploring_Compositional_High_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Yujia Li, Daniel Tarlow, Richard Zemel</p><p>Abstract: When modeling structured outputs such as image segmentations, prediction can be improved by accurately modeling structure present in the labels. A key challenge is developing tractable models that are able to capture complex high level structure like shape. In this work, we study the learning of a general class of pattern-like high order potential, which we call Compositional High Order Pattern Potentials (CHOPPs). We show that CHOPPs include the linear deviation pattern potentials of Rother et al. [26] and also Restricted Boltzmann Machines (RBMs); we also establish the near equivalence of these two models. Experimentally, we show that performance is affected significantly by the degree of variability present in the datasets, and we define a quantitative variability measure to aid in studying this. We then improve CHOPPs performance in high variability datasets with two primary contributions: (a) developing a loss-sensitive joint learning procedure, so that internal pattern parameters can be learned in conjunction with other model potentials to minimize expected loss;and (b) learning an image-dependent mapping that encourages or inhibits patterns depending on image features. We also explore varying how multiple patterns are composed, and learning convolutional patterns. Quantitative results on challenging highly variable datasets show that the joint learning and image-dependent high order potentials can improve performance.</p><p>Reference: <a title="cvpr-2013-156-reference" href="../cvpr2013_reference/cvpr-2013-Exploring_Compositional_High_Order_Pattern_Potentials_for_Structured_Output_Learning_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 We show that CHOPPs include the linear deviation pattern potentials of Rother et al. [sent-6, score-0.431]
</p><p>2 Experimentally, we show that performance is affected significantly by the degree of variability present in the datasets, and we define a quantitative variability measure to aid in studying this. [sent-8, score-0.344]
</p><p>3 We also explore varying how multiple patterns are composed, and learning convolutional patterns. [sent-10, score-0.228]
</p><p>4 Quantitative results on challenging highly variable datasets show that the joint learning and image-dependent high order potentials can improve performance. [sent-11, score-0.51]
</p><p>5 Introduction Many tasks in computer vision can be framed as making predictions about complex, structured objects. [sent-13, score-0.137]
</p><p>6 For example, image labeling problems like stereo depth estimation, optical flow, and image segmentation can all be cast as making predictions jointly over many correlated outputs. [sent-14, score-0.137]
</p><p>7 outputs and make test-time predictions by either exactly or approximately solving a joint inference task. [sent-20, score-0.123]
</p><p>8 These formulations are collectively known as structured output learning, or structured prediction, and are the focus of this work. [sent-21, score-0.254]
</p><p>9 A key research issue that arises when working with structured output problems is how to best tradeoff expressivity of the model with the ability to efficiently learn and perform inference (make predictions). [sent-22, score-0.218]
</p><p>10 Traditionally, these concerns have led to the use of overly simplistic models over labelings that make unrealistic conditional independence assumptions, such as pairwise models with grid-structured topology. [sent-23, score-0.175]
</p><p>11 Recently, there have been successful efforts that weaken these assumptions, either by moving to densely connected pairwise models [13] or by enforcing smoothness in higher order neighborhoods [10]. [sent-24, score-0.154]
</p><p>12 One promising direction towards incorporating these goals in the structured output setting appears to be the pattern potentials of Rother et al. [sent-27, score-0.559]
</p><p>13 [26] and Komodakis & Para444999  gios [12], which are capable of modeling soft template structures and can dramatically outperform pairwise models in highly structured settings that arise, e. [sent-28, score-0.222]
</p><p>14 Yet despite the clearly powerful representational ability of pattern potentials, they have not found much success in more realistic settings, like those found in the PASCAL VOC image labeling task [4]. [sent-31, score-0.143]
</p><p>15 In fact, our starting observation in this work is that the similarity is not superficial— mathematically, RBM models are nearly identical to the pattern potentials of [26]. [sent-33, score-0.431]
</p><p>16 We will make this claim precise in Section 3, leading to the definition of a more general class of high order potential that includes both pattern potentials and RBMs. [sent-34, score-0.524]
</p><p>17 Our goal is to not only learn a tradeoff parameter between the standard and high order parts of the model, but also to learn internal pattern parameters. [sent-38, score-0.215]
</p><p>18 We then focus on the question of how effective these potentials are as the variability and complexity of the image segmentation task increases. [sent-39, score-0.575]
</p><p>19 We propose a simple method for assessing the degree of variation in the labels, then show that the  performance of a vanilla application of CHOPPs degrades relative to the performance of standard pairwise potentials as this measure of variability increases. [sent-40, score-0.706]
</p><p>20 This is analogous to allowing standard pairwise potentials to vary depending on local image color differences [1] or more advanced boundary detector responses like Pb [19]. [sent-43, score-0.499]
</p><p>21 Our results indicate that jointly training the CHOPP potentials with the rest of the model improves performance, and training specifically for the evaluation criterion used at test time (we use an intersection-overunion (IOU) measure throughout) improves over a maximum likelihood-based objective. [sent-45, score-0.406]
</p><p>22 [26], which is essentially a mixture model, versus the ‘sum’ version, which is more compositional in nature; and (b) convolutional applications of the high order potentials versus their global application. [sent-47, score-0.66]
</p><p>23 Structured Output Learning In structured output learning, the goal is to predict a vector of labels y ∈ Y = {1, . [sent-52, score-0.128]
</p><p>24 To increase the representational power of a model, a common approach is to introduce latent (or hidden) variables h ∈ H = {1, . [sent-74, score-0.155]
</p><p>25 by dHef}ining feature functions f(x, y, h) that may include latent vari-  ables, which leads to a probability distribution p(y, h | x). [sent-79, score-0.129]
</p><p>26 The former strategy is employed by latent structural SVMs [35], while the latter is employed by hidden CRF models [24]. [sent-82, score-0.219]
</p><p>27 These types of interactions are known collectively as high order potentials and have received considerable attention in recent years. [sent-86, score-0.461]
</p><p>28 They have been used for several purposes, including modeling higher order smoothness [10], co-occurrences of labels in semantic image segmentation [14], and cardinality-based potentials [33, 34]. [sent-87, score-0.432]
</p><p>29 We emphasize the distinction between first learning the internal parameters offline and then learning (or fixing by hand) the tradeoff parameters that controls the relative strength of the high order terms, versus the joint learning of both types of parameters. [sent-97, score-0.36]
</p><p>30 Restricted Boltzmann Machines A Restricted Boltzmann Machine (RBM) [28] is a form of undirected graphical model that uses hidden variables to model high-order regularities in data. [sent-104, score-0.206]
</p><p>31 that represent the observations, or data; and (2) the J hidden or latent units h = (h1, . [sent-109, score-0.273]
</p><p>32 h,  (1)  where W ∈ RI×J encodes the hidden-visible interactions, bw ∈er eR WI are Rthe input biases, and c ∈ RJ are the hidden bbia ∈ses R. [sent-119, score-0.16]
</p><p>33 Thaere energy pfuuntc btiiaosne specifies t∈he R probability distribution over the joint space (v, h) via the Boltzmann distribution  p(v,h) =Z1exp(−E(v,h))  (2)  with the partition function Z given by ? [sent-120, score-0.164]
</p><p>34 ntial sum over all possibly hidden vectors h: p(v) = ? [sent-128, score-0.201]
</p><p>35 with J binary hidden units, this takes on a particular nice? [sent-131, score-0.16]
</p><p>36 [21] also tried to use RBMs for structured output problems, but there are no pairwise connections between labels, and the actual loss was not considered during training. [sent-157, score-0.323]
</p><p>37 Equating Pattern Potentials and RBMs In [26], the basic pattern potential is defined as g(y) = min {d(y? [sent-160, score-0.141]
</p><p>38 In the same sense, the “min” case is equivalent to an RBM with a constraint that only one hidden unit can be active. [sent-174, score-0.16]
</p><p>39 The CHOPP-Augmented CRF Understanding the equivalence between RBMs and pattern potentials leads us to define a more general potential,  f(y;T) = −T log? [sent-177, score-0.431]
</p><p>40 If there is no constraint on hidden variables, setting T → 0 gives the “sum” compositional high order pattern potential. [sent-187, score-0.335]
</p><p>41 Therefore the CHOPP permits manipulations along two separate axes: the temperature T interpolates the RBM and pattern potential, while the constraints on hidden variable activities interpolates the “sum” and “min” composition strategies. [sent-189, score-0.345]
</p><p>42 In this section, we augment a standard pairwise CRF with the CHOPP and describe inference and learning algorithms. [sent-192, score-0.222]
</p><p>43 We do not enforce any constraint on hidden variables in the following discussion, but it is possible to derive the inference and learning algorithms for the case where we have a soft sparsity or hard 1-of-J constraint on hidden variables, e. [sent-193, score-0.463]
</p><p>44 fwehre nret f tyi(peyis|x o)f pa reir uwniasrey p po t e n t iaialsls, λ fuikja(nydi, λyjkp|xa)re ar trea Kde- doif -f  (5)  parameters for unary and pairwise potentials respectively, and W, b, c are RBM parameters. [sent-211, score-0.667]
</p><p>45 Given h, the distribution of y becom1es+ a pairwise MRF with only unary and pairwise potentials p(y|h,x)  ∝  exp  ? [sent-235, score-0.856]
</p><p>46 We achieve this by making the hidden biases c a function of the input image feature vector φ(x). [sent-243, score-0.217]
</p><p>47 These can be trained by tying together the weights between y and hidden variables h at all locations in an image. [sent-247, score-0.206]
</p><p>48 MAP Inference The task of inference is to find the y that maximizes the log probability logp(y|x) for a given x. [sent-251, score-0.136]
</p><p>49 T Tm →inim 0i,z iets tuhtes energy over hidden units. [sent-280, score-0.19]
</p><p>50 y + ψu(y) + ψp(y),  (12)  which is again just a set of unary potentials plus pairwise potentials, so we can use standard optimization methods for pairwise CRFs to find an optimal y; we use graph cuts. [sent-283, score-0.792]
</p><p>51 When there is no sparsity constraint on h, it is possible to analytically sum out the hidden variables, which leads to a collapsed energy function with J high order factors, one for each original hidden unit. [sent-288, score-0.449]
</p><p>52 Learning Here we fix the unary and pairwise potentials and focus on learning the parameters in the CHOPP. [sent-294, score-0.713]
</p><p>53 For the T = 1case, we can use Contrastive Divergence (CD) [8] to approximately maximize the conditional likelihood ofdata under our model, which is standard for learning RBMs. [sent-295, score-0.133]
</p><p>54 However we found that CD does not work very well because it is only learning the shape of the distribution in a neighborhood around the ground truth (by raising the probability of the ground truth and lowering the probability of everything else). [sent-296, score-0.186]
</p><p>55 In fact, it typically starts far from the ground truth (we use the prediction by a model with only unary and pairwise potentials as the initialization), and the model has not been trained to move the distribution from this region of label configurations towards the target labels. [sent-298, score-0.699]
</p><p>56 Instead, we train the model to minimize expected loss which we believe allows the model to more globally learn the distribution. [sent-299, score-0.121]
</p><p>57 Taking the derivative of the expected loss with respect to model parameter γ, which can be b, c or W (c0 and W0 as well if we use the conditioned CHOPPs), we get  ∂∂γL= Ey? [sent-309, score-0.121]
</p><p>58 (15)  This gradient has an intuitive explanation: if a sample has a loss lower than the average loss of the batch of samples, then we should reward it by raising its probability, and if its loss is higher than the average, then we should lower its probability. [sent-330, score-0.242]
</p><p>59 We trained a neural network classifier using these descriptors as input and use the log probability of each class for each pixel as the unary po-  tentials. [sent-342, score-0.253]
</p><p>60 For pairwise potentials, we used a standard 4connected grid neighborhood and the common Potts model, 555333  =  where fij (yi, yj |x) = pijI[yi yj] and pij is a penalty for assigning dif|xfe)ren =t l pabels fo? [sent-343, score-0.237]
</p><p>61 In minimum expected loss learning, we use 2 persistent sampling chains for each image, generate 1 sample from each chain, divide (y, h) into 3 blocks of variables (h and 2 y blocks for the 4-connected grid structure) and update parameters after every full block Gibbs sampling pass. [sent-351, score-0.167]
</p><p>62 To explore data set variability in a controlled fashion, we generated a series of increasingly variable synthetic data sets. [sent-356, score-0.25]
</p><p>63 To generate associated unary potentials, we added Gaussian noise with standard deviation 0. [sent-360, score-0.168]
</p><p>64 This gives us a set of silhouettes tinhagt preserve tbhee 3 challenging aspects osf modeling shape eins a realistic structured output setting. [sent-366, score-0.128]
</p><p>65 The two PASCAL datasets are challenging due to variability in the images and segmentations, while the number of images is quite small, especially compared to the settings where RBM models are typically used. [sent-367, score-0.172]
</p><p>66 For each data set, we then evaluated variability using a measure inspired by the learning procedure suggested by Rother et al. [sent-373, score-0.218]
</p><p>67 We found the quantitative measure matches intuition about the variability of data sets. [sent-392, score-0.172]
</p><p>68 3 show the results as a function of the variability measure described in the previous section. [sent-402, score-0.172]
</p><p>69 For the Unary+iPW+RBM model, there is a clear trend that as the variability of the data set increases, the benefit gained from adding the RBM declines. [sent-405, score-0.172]
</p><p>70 The first approach to extending the pretrained RBM+CRF model that we consider is to jointly learn the internal potential parameters. [sent-410, score-0.18]
</p><p>71 Joint learning with standard contrastive divergence on the Horse data led to poor performance, as the objective was unstable in the first few iterations and then steadily got worse during 555444  Figure2. [sent-411, score-0.15]
</p><p>72 Q0u4a0ntiavemasure of  variability using K = 32  are  reported in the bottom  row. [sent-419, score-0.172]
</p><p>73 So here we focus on the expected loss training described in Section 4. [sent-437, score-0.121]
</p><p>74 We see that training with the expected loss criterion improves performance across the board. [sent-441, score-0.121]
</p><p>75 Here we consider learning image-dependent hidden biases as described in Section 4. [sent-443, score-0.263]
</p><p>76 As inputs we use the learned unary potentials and the response of the Pb boundary detector [19], both downsampled to be of size 16 16. [sent-445, score-0.542]
</p><p>77 el, the imagedependent jointly trained RBM, using the intersection-overunion expected loss as this gave the best results in the previous experiment. [sent-447, score-0.198]
</p><p>78 For comparison, we also train Unary+Pairwise models with an image-independent pairwise potentials (PW) and an imagedependent pairwise potentials (iPW). [sent-450, score-1.043]
</p><p>79 Test results using image-specific hidden biases on the high variability real data sets. [sent-454, score-0.418]
</p><p>80 PW uses image-independent pairwise potentials, and iPW uses image-dependent pairwise potentials. [sent-455, score-0.25]
</p><p>81 ijRBM is jointly trained and has learned image-dependent hidden biases. [sent-457, score-0.192]
</p><p>82 similarly as to how image-dependent pairwise potentials  improve over image-independent pairwise potentials. [sent-458, score-0.624]
</p><p>83 Unfortunately, we were unable to achieve good results, which we attribute to the fact that learning methods for convolutional RBMs are not nearly as evolved as methods for learning ordinary RBMs. [sent-463, score-0.225]
</p><p>84 We qualitatively compare patterns learned by the “min” composition approach presented in [26] versus the patterns learned by a simple pre-trained RBM, which are appropriate for “sum” composition. [sent-466, score-0.13]
</p><p>85 As the variability of the data grows, we expect the utility of the “sum” composition scheme to increase. [sent-469, score-0.212]
</p><p>86 Discussion & Future Work We began by precisely mapping the relationship between pattern potentials and RBMs, and generalizing both to yield CHOPPs, a class of high order potential that includes both as special cases. [sent-471, score-0.524]
</p><p>87 Conversely, RBMs may 555555 benefit from the highly developed inference procedures that are more common in the structured output community, e. [sent-476, score-0.179]
</p><p>88 Also interesting is that pairwise potentials provide benefits that are reasonably orthogonal to those offered by RBM potentials. [sent-479, score-0.528]
</p><p>89 Empirically, our work emphasizes the importance ofdata set variability in the performance of these methods. [sent-480, score-0.237]
</p><p>90 It is possible to achieve large gains on low variability data, but it is a challenge on high variability data. [sent-481, score-0.373]
</p><p>91 Our proposed measure for quantitatively measuring data set variability is simple but useful in understanding what regime a data set falls in. [sent-482, score-0.172]
</p><p>92 While we work with small images and binary masks, we believe that the high variability data sets we are using preserve the key challenges that arise in trying to model shape in real image segmentation applications. [sent-484, score-0.23]
</p><p>93 Note that it would be straightforward to have a separate set of shape potentials per object class within a multi-label segmentation setting. [sent-485, score-0.403]
</p><p>94 To attain improvements in high variability settings, more sophisticated methods are needed. [sent-486, score-0.201]
</p><p>95 Our contributions of training under an expected loss criterion and adding conditional hidden biases to the model yield improvements on the high variability data. [sent-487, score-0.589]
</p><p>96 There are other architectures  to explore  for making  the high order potentials  image-  dependent. [sent-488, score-0.481]
</p><p>97 The convolutional approach ap-  pears promising, but it did not yield improvements experiments,  which we attribute to the relatively  nature of convolutional  RBM learning techniques. [sent-490, score-0.254]
</p><p>98 Efficient training for pairwise or higher order CRFs via dual decomposition. [sent-558, score-0.154]
</p><p>99 Stacks of convolutional restricted Boltzmann machines for shift-invariant feature learning. [sent-628, score-0.201]
</p><p>100 Support vector machine learning for interdependent and structured output spaces. [sent-688, score-0.174]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('rbm', 0.504), ('potentials', 0.374), ('chopps', 0.291), ('rbms', 0.191), ('variability', 0.172), ('unary', 0.168), ('hidden', 0.16), ('ipw', 0.157), ('boltzmann', 0.154), ('pairwise', 0.125), ('chopp', 0.112), ('convolutional', 0.104), ('structured', 0.097), ('pij', 0.075), ('loss', 0.07), ('rother', 0.067), ('ijrbm', 0.067), ('jrbm', 0.067), ('wh', 0.067), ('crf', 0.066), ('contrastive', 0.066), ('internal', 0.061), ('compositional', 0.06), ('crfs', 0.06), ('latent', 0.059), ('biases', 0.057), ('pattern', 0.057), ('qik', 0.055), ('units', 0.054), ('pretrained', 0.052), ('bird', 0.052), ('inference', 0.051), ('expected', 0.051), ('conditional', 0.05), ('representational', 0.05), ('zemel', 0.05), ('explore', 0.049), ('restricted', 0.049), ('min', 0.049), ('machines', 0.048), ('iou', 0.048), ('log', 0.047), ('learning', 0.046), ('variables', 0.046), ('hexp', 0.045), ('imagedependent', 0.045), ('iouperson', 0.045), ('pbi', 0.045), ('pbj', 0.045), ('yi', 0.042), ('sum', 0.041), ('composition', 0.04), ('predictions', 0.04), ('compositionality', 0.04), ('tradeoff', 0.039), ('probability', 0.038), ('divergence', 0.038), ('kohli', 0.038), ('wi', 0.037), ('yj', 0.037), ('ofdata', 0.037), ('eslami', 0.037), ('heess', 0.037), ('labeling', 0.036), ('potential', 0.035), ('tarlow', 0.035), ('vanilla', 0.035), ('researcher', 0.035), ('supplementary', 0.035), ('ey', 0.034), ('cd', 0.034), ('distribution', 0.032), ('jointly', 0.032), ('versus', 0.032), ('joint', 0.032), ('exp', 0.032), ('larochelle', 0.032), ('raising', 0.032), ('output', 0.031), ('logp', 0.031), ('pb', 0.031), ('toronto', 0.031), ('em', 0.03), ('energy', 0.03), ('fj', 0.03), ('oxf', 0.03), ('komodakis', 0.03), ('interpolates', 0.03), ('pw', 0.03), ('order', 0.029), ('segmentation', 0.029), ('patterns', 0.029), ('synthetic', 0.029), ('high', 0.029), ('offered', 0.029), ('evolved', 0.029), ('collectively', 0.029), ('horse', 0.028), ('emphasizes', 0.028), ('temperature', 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999964 <a title="156-tfidf-1" href="./cvpr-2013-Exploring_Compositional_High_Order_Pattern_Potentials_for_Structured_Output_Learning.html">156 cvpr-2013-Exploring Compositional High Order Pattern Potentials for Structured Output Learning</a></p>
<p>Author: Yujia Li, Daniel Tarlow, Richard Zemel</p><p>Abstract: When modeling structured outputs such as image segmentations, prediction can be improved by accurately modeling structure present in the labels. A key challenge is developing tractable models that are able to capture complex high level structure like shape. In this work, we study the learning of a general class of pattern-like high order potential, which we call Compositional High Order Pattern Potentials (CHOPPs). We show that CHOPPs include the linear deviation pattern potentials of Rother et al. [26] and also Restricted Boltzmann Machines (RBMs); we also establish the near equivalence of these two models. Experimentally, we show that performance is affected significantly by the degree of variability present in the datasets, and we define a quantitative variability measure to aid in studying this. We then improve CHOPPs performance in high variability datasets with two primary contributions: (a) developing a loss-sensitive joint learning procedure, so that internal pattern parameters can be learned in conjunction with other model potentials to minimize expected loss;and (b) learning an image-dependent mapping that encourages or inhibits patterns depending on image features. We also explore varying how multiple patterns are composed, and learning convolutional patterns. Quantitative results on challenging highly variable datasets show that the joint learning and image-dependent high order potentials can improve performance.</p><p>2 0.42372474 <a title="156-tfidf-2" href="./cvpr-2013-Weakly_Supervised_Learning_of_Mid-Level_Features_with_Beta-Bernoulli_Process_Restricted_Boltzmann_Machines.html">462 cvpr-2013-Weakly Supervised Learning of Mid-Level Features with Beta-Bernoulli Process Restricted Boltzmann Machines</a></p>
<p>Author: Roni Mittelman, Honglak Lee, Benjamin Kuipers, Silvio Savarese</p><p>Abstract: The use of semantic attributes in computer vision problems has been gaining increased popularity in recent years. Attributes provide an intermediate feature representation in between low-level features and the class categories, leading to improved learning on novel categories from few examples. However, a major caveat is that learning semantic attributes is a laborious task, requiring a significant amount of time and human intervention to provide labels. In order to address this issue, we propose a weakly supervised approach to learn mid-level features, where only class-level supervision is provided during training. We develop a novel extension of the restricted Boltzmann machine (RBM) by incorporating a Beta-Bernoulli process factor potential for hidden units. Unlike the standard RBM, our model uses the class labels to promote category-dependent sharing of learned features, which tends to improve the generalization performance. By using semantic attributes for which annotations are available, we show that we can find correspondences between the learned mid-level features and the labeled attributes. Therefore, the mid-level features have distinct semantic characterization which is similar to that given by the semantic attributes, even though their labeling was not provided during training. Our experimental results on object recognition tasks show significant performance gains, outperforming existing methods which rely on manually labeled semantic attributes.</p><p>3 0.41879737 <a title="156-tfidf-3" href="./cvpr-2013-Learning_Multiple_Non-linear_Sub-spaces_Using_K-RBMs.html">253 cvpr-2013-Learning Multiple Non-linear Sub-spaces Using K-RBMs</a></p>
<p>Author: Siddhartha Chandra, Shailesh Kumar, C.V. Jawahar</p><p>Abstract: Understanding the nature of data is the key to building good representations. In domains such as natural images, the data comes from very complex distributions which are hard to capture. Feature learning intends to discover or best approximate these underlying distributions and use their knowledge to weed out irrelevant information, preserving most of the relevant information. Feature learning can thus be seen as a form of dimensionality reduction. In this paper, we describe a feature learning scheme for natural images. We hypothesize that image patches do not all come from the same distribution, they lie in multiple nonlinear subspaces. We propose a framework that uses K Restricted Boltzmann Machines (K-RBMS) to learn multiple non-linear subspaces in the raw image space. Projections of the image patches into these subspaces gives us features, which we use to build image representations. Our algorithm solves the coupled problem of finding the right non-linear subspaces in the input space and associating image patches with those subspaces in an iterative EM like algorithm to minimize the overall reconstruction error. Extensive empirical results over several popular image classification datasets show that representations based on our framework outperform the traditional feature representations such as the SIFT based Bag-of-Words (BoW) and convolutional deep belief networks.</p><p>4 0.29518956 <a title="156-tfidf-4" href="./cvpr-2013-Augmenting_CRFs_with_Boltzmann_Machine_Shape_Priors_for_Image_Labeling.html">50 cvpr-2013-Augmenting CRFs with Boltzmann Machine Shape Priors for Image Labeling</a></p>
<p>Author: Andrew Kae, Kihyuk Sohn, Honglak Lee, Erik Learned-Miller</p><p>Abstract: Conditional random fields (CRFs) provide powerful tools for building models to label image segments. They are particularly well-suited to modeling local interactions among adjacent regions (e.g., superpixels). However, CRFs are limited in dealing with complex, global (long-range) interactions between regions. Complementary to this, restricted Boltzmann machines (RBMs) can be used to model global shapes produced by segmentation models. In this work, we present a new model that uses the combined power of these two network types to build a state-of-the-art labeler. Although the CRF is a good baseline labeler, we show how an RBM can be added to the architecture to provide a global shape bias that complements the local modeling provided by the CRF. We demonstrate its labeling performance for the parts of complex face images from the Labeled Faces in the Wild data set. This hybrid model produces results that are both quantitatively and qualitatively better than the CRF alone. In addition to high-quality labeling results, we demonstrate that the hidden units in the RBM portion of our model can be interpreted as face attributes that have been learned without any attribute-level supervision.</p><p>5 0.24813338 <a title="156-tfidf-5" href="./cvpr-2013-Analyzing_Semantic_Segmentation_Using_Hybrid_Human-Machine_CRFs.html">43 cvpr-2013-Analyzing Semantic Segmentation Using Hybrid Human-Machine CRFs</a></p>
<p>Author: Roozbeh Mottaghi, Sanja Fidler, Jian Yao, Raquel Urtasun, Devi Parikh</p><p>Abstract: Recent trends in semantic image segmentation have pushed for holistic scene understanding models that jointly reason about various tasks such as object detection, scene recognition, shape analysis, contextual reasoning. In this work, we are interested in understanding the roles of these different tasks in aiding semantic segmentation. Towards this goal, we “plug-in ” human subjects for each of the various components in a state-of-the-art conditional random field model (CRF) on the MSRC dataset. Comparisons among various hybrid human-machine CRFs give us indications of how much “head room ” there is to improve segmentation by focusing research efforts on each of the tasks. One of the interesting findings from our slew of studies was that human classification of isolated super-pixels, while being worse than current machine classifiers, provides a significant boost in performance when plugged into the CRF! Fascinated by this finding, we conducted in depth analysis of the human generated potentials. This inspired a new machine potential which significantly improves state-of-the-art performance on the MRSC dataset.</p><p>6 0.22340326 <a title="156-tfidf-6" href="./cvpr-2013-Fully-Connected_CRFs_with_Non-Parametric_Pairwise_Potential.html">180 cvpr-2013-Fully-Connected CRFs with Non-Parametric Pairwise Potential</a></p>
<p>7 0.2050111 <a title="156-tfidf-7" href="./cvpr-2013-A_Principled_Deep_Random_Field_Model_for_Image_Segmentation.html">24 cvpr-2013-A Principled Deep Random Field Model for Image Segmentation</a></p>
<p>8 0.1715946 <a title="156-tfidf-8" href="./cvpr-2013-Fast_Energy_Minimization_Using_Learned_State_Filters.html">165 cvpr-2013-Fast Energy Minimization Using Learned State Filters</a></p>
<p>9 0.15076676 <a title="156-tfidf-9" href="./cvpr-2013-Facial_Feature_Tracking_Under_Varying_Facial_Expressions_and_Face_Poses_Based_on_Restricted_Boltzmann_Machines.html">161 cvpr-2013-Facial Feature Tracking Under Varying Facial Expressions and Face Poses Based on Restricted Boltzmann Machines</a></p>
<p>10 0.14098983 <a title="156-tfidf-10" href="./cvpr-2013-Deep_Learning_Shape_Priors_for_Object_Segmentation.html">105 cvpr-2013-Deep Learning Shape Priors for Object Segmentation</a></p>
<p>11 0.13125247 <a title="156-tfidf-11" href="./cvpr-2013-A_Sentence_Is_Worth_a_Thousand_Pixels.html">25 cvpr-2013-A Sentence Is Worth a Thousand Pixels</a></p>
<p>12 0.12558471 <a title="156-tfidf-12" href="./cvpr-2013-Poselet_Conditioned_Pictorial_Structures.html">335 cvpr-2013-Poselet Conditioned Pictorial Structures</a></p>
<p>13 0.11946128 <a title="156-tfidf-13" href="./cvpr-2013-Learning_Class-to-Image_Distance_with_Object_Matchings.html">247 cvpr-2013-Learning Class-to-Image Distance with Object Matchings</a></p>
<p>14 0.11519208 <a title="156-tfidf-14" href="./cvpr-2013-Human_Pose_Estimation_Using_Body_Parts_Dependent_Joint_Regressors.html">206 cvpr-2013-Human Pose Estimation Using Body Parts Dependent Joint Regressors</a></p>
<p>15 0.10787129 <a title="156-tfidf-15" href="./cvpr-2013-Learning_for_Structured_Prediction_Using_Approximate_Subgradient_Descent_with_Working_Sets.html">262 cvpr-2013-Learning for Structured Prediction Using Approximate Subgradient Descent with Working Sets</a></p>
<p>16 0.10641173 <a title="156-tfidf-16" href="./cvpr-2013-Human_Pose_Estimation_Using_a_Joint_Pixel-wise_and_Part-wise_Formulation.html">207 cvpr-2013-Human Pose Estimation Using a Joint Pixel-wise and Part-wise Formulation</a></p>
<p>17 0.10045327 <a title="156-tfidf-17" href="./cvpr-2013-A_Higher-Order_CRF_Model_for_Road_Network_Extraction.html">13 cvpr-2013-A Higher-Order CRF Model for Road Network Extraction</a></p>
<p>18 0.098641276 <a title="156-tfidf-18" href="./cvpr-2013-Constrained_Clustering_and_Its_Application_to_Face_Clustering_in_Videos.html">92 cvpr-2013-Constrained Clustering and Its Application to Face Clustering in Videos</a></p>
<p>19 0.096274823 <a title="156-tfidf-19" href="./cvpr-2013-Detection-_and_Trajectory-Level_Exclusion_in_Multiple_Object_Tracking.html">121 cvpr-2013-Detection- and Trajectory-Level Exclusion in Multiple Object Tracking</a></p>
<p>20 0.092944436 <a title="156-tfidf-20" href="./cvpr-2013-Whitened_Expectation_Propagation%3A_Non-Lambertian_Shape_from_Shading_and_Shadow.html">466 cvpr-2013-Whitened Expectation Propagation: Non-Lambertian Shape from Shading and Shadow</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.217), (1, -0.03), (2, -0.007), (3, -0.013), (4, 0.147), (5, 0.066), (6, 0.038), (7, 0.091), (8, -0.034), (9, -0.053), (10, 0.118), (11, -0.009), (12, -0.136), (13, 0.021), (14, -0.093), (15, 0.352), (16, -0.078), (17, 0.159), (18, 0.167), (19, -0.051), (20, 0.097), (21, -0.322), (22, 0.048), (23, -0.097), (24, -0.066), (25, -0.148), (26, 0.031), (27, 0.071), (28, -0.013), (29, -0.044), (30, 0.04), (31, 0.043), (32, -0.022), (33, 0.095), (34, 0.145), (35, 0.018), (36, 0.064), (37, -0.036), (38, -0.062), (39, 0.079), (40, 0.083), (41, 0.023), (42, 0.046), (43, -0.056), (44, 0.033), (45, -0.063), (46, 0.018), (47, 0.042), (48, 0.01), (49, 0.038)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.91635311 <a title="156-lsi-1" href="./cvpr-2013-Exploring_Compositional_High_Order_Pattern_Potentials_for_Structured_Output_Learning.html">156 cvpr-2013-Exploring Compositional High Order Pattern Potentials for Structured Output Learning</a></p>
<p>Author: Yujia Li, Daniel Tarlow, Richard Zemel</p><p>Abstract: When modeling structured outputs such as image segmentations, prediction can be improved by accurately modeling structure present in the labels. A key challenge is developing tractable models that are able to capture complex high level structure like shape. In this work, we study the learning of a general class of pattern-like high order potential, which we call Compositional High Order Pattern Potentials (CHOPPs). We show that CHOPPs include the linear deviation pattern potentials of Rother et al. [26] and also Restricted Boltzmann Machines (RBMs); we also establish the near equivalence of these two models. Experimentally, we show that performance is affected significantly by the degree of variability present in the datasets, and we define a quantitative variability measure to aid in studying this. We then improve CHOPPs performance in high variability datasets with two primary contributions: (a) developing a loss-sensitive joint learning procedure, so that internal pattern parameters can be learned in conjunction with other model potentials to minimize expected loss;and (b) learning an image-dependent mapping that encourages or inhibits patterns depending on image features. We also explore varying how multiple patterns are composed, and learning convolutional patterns. Quantitative results on challenging highly variable datasets show that the joint learning and image-dependent high order potentials can improve performance.</p><p>2 0.75178784 <a title="156-lsi-2" href="./cvpr-2013-Learning_Multiple_Non-linear_Sub-spaces_Using_K-RBMs.html">253 cvpr-2013-Learning Multiple Non-linear Sub-spaces Using K-RBMs</a></p>
<p>Author: Siddhartha Chandra, Shailesh Kumar, C.V. Jawahar</p><p>Abstract: Understanding the nature of data is the key to building good representations. In domains such as natural images, the data comes from very complex distributions which are hard to capture. Feature learning intends to discover or best approximate these underlying distributions and use their knowledge to weed out irrelevant information, preserving most of the relevant information. Feature learning can thus be seen as a form of dimensionality reduction. In this paper, we describe a feature learning scheme for natural images. We hypothesize that image patches do not all come from the same distribution, they lie in multiple nonlinear subspaces. We propose a framework that uses K Restricted Boltzmann Machines (K-RBMS) to learn multiple non-linear subspaces in the raw image space. Projections of the image patches into these subspaces gives us features, which we use to build image representations. Our algorithm solves the coupled problem of finding the right non-linear subspaces in the input space and associating image patches with those subspaces in an iterative EM like algorithm to minimize the overall reconstruction error. Extensive empirical results over several popular image classification datasets show that representations based on our framework outperform the traditional feature representations such as the SIFT based Bag-of-Words (BoW) and convolutional deep belief networks.</p><p>3 0.72435582 <a title="156-lsi-3" href="./cvpr-2013-Augmenting_CRFs_with_Boltzmann_Machine_Shape_Priors_for_Image_Labeling.html">50 cvpr-2013-Augmenting CRFs with Boltzmann Machine Shape Priors for Image Labeling</a></p>
<p>Author: Andrew Kae, Kihyuk Sohn, Honglak Lee, Erik Learned-Miller</p><p>Abstract: Conditional random fields (CRFs) provide powerful tools for building models to label image segments. They are particularly well-suited to modeling local interactions among adjacent regions (e.g., superpixels). However, CRFs are limited in dealing with complex, global (long-range) interactions between regions. Complementary to this, restricted Boltzmann machines (RBMs) can be used to model global shapes produced by segmentation models. In this work, we present a new model that uses the combined power of these two network types to build a state-of-the-art labeler. Although the CRF is a good baseline labeler, we show how an RBM can be added to the architecture to provide a global shape bias that complements the local modeling provided by the CRF. We demonstrate its labeling performance for the parts of complex face images from the Labeled Faces in the Wild data set. This hybrid model produces results that are both quantitatively and qualitatively better than the CRF alone. In addition to high-quality labeling results, we demonstrate that the hidden units in the RBM portion of our model can be interpreted as face attributes that have been learned without any attribute-level supervision.</p><p>4 0.72402143 <a title="156-lsi-4" href="./cvpr-2013-Weakly_Supervised_Learning_of_Mid-Level_Features_with_Beta-Bernoulli_Process_Restricted_Boltzmann_Machines.html">462 cvpr-2013-Weakly Supervised Learning of Mid-Level Features with Beta-Bernoulli Process Restricted Boltzmann Machines</a></p>
<p>Author: Roni Mittelman, Honglak Lee, Benjamin Kuipers, Silvio Savarese</p><p>Abstract: The use of semantic attributes in computer vision problems has been gaining increased popularity in recent years. Attributes provide an intermediate feature representation in between low-level features and the class categories, leading to improved learning on novel categories from few examples. However, a major caveat is that learning semantic attributes is a laborious task, requiring a significant amount of time and human intervention to provide labels. In order to address this issue, we propose a weakly supervised approach to learn mid-level features, where only class-level supervision is provided during training. We develop a novel extension of the restricted Boltzmann machine (RBM) by incorporating a Beta-Bernoulli process factor potential for hidden units. Unlike the standard RBM, our model uses the class labels to promote category-dependent sharing of learned features, which tends to improve the generalization performance. By using semantic attributes for which annotations are available, we show that we can find correspondences between the learned mid-level features and the labeled attributes. Therefore, the mid-level features have distinct semantic characterization which is similar to that given by the semantic attributes, even though their labeling was not provided during training. Our experimental results on object recognition tasks show significant performance gains, outperforming existing methods which rely on manually labeled semantic attributes.</p><p>5 0.5896827 <a title="156-lsi-5" href="./cvpr-2013-A_Principled_Deep_Random_Field_Model_for_Image_Segmentation.html">24 cvpr-2013-A Principled Deep Random Field Model for Image Segmentation</a></p>
<p>Author: Pushmeet Kohli, Anton Osokin, Stefanie Jegelka</p><p>Abstract: We discuss a model for image segmentation that is able to overcome the short-boundary bias observed in standard pairwise random field based approaches. To wit, we show that a random field with multi-layered hidden units can encode boundary preserving higher order potentials such as the ones used in the cooperative cuts model of [11] while still allowing for fast and exact MAP inference. Exact inference allows our model to outperform previous image segmentation methods, and to see the true effect of coupling graph edges. Finally, our model can be easily extended to handle segmentation instances with multiple labels, for which it yields promising results.</p><p>6 0.54916906 <a title="156-lsi-6" href="./cvpr-2013-Deep_Learning_Shape_Priors_for_Object_Segmentation.html">105 cvpr-2013-Deep Learning Shape Priors for Object Segmentation</a></p>
<p>7 0.5463199 <a title="156-lsi-7" href="./cvpr-2013-Fully-Connected_CRFs_with_Non-Parametric_Pairwise_Potential.html">180 cvpr-2013-Fully-Connected CRFs with Non-Parametric Pairwise Potential</a></p>
<p>8 0.51366383 <a title="156-lsi-8" href="./cvpr-2013-Learning_for_Structured_Prediction_Using_Approximate_Subgradient_Descent_with_Working_Sets.html">262 cvpr-2013-Learning for Structured Prediction Using Approximate Subgradient Descent with Working Sets</a></p>
<p>9 0.47948772 <a title="156-lsi-9" href="./cvpr-2013-Analyzing_Semantic_Segmentation_Using_Hybrid_Human-Machine_CRFs.html">43 cvpr-2013-Analyzing Semantic Segmentation Using Hybrid Human-Machine CRFs</a></p>
<p>10 0.46987259 <a title="156-lsi-10" href="./cvpr-2013-Action_Recognition_by_Hierarchical_Sequence_Summarization.html">32 cvpr-2013-Action Recognition by Hierarchical Sequence Summarization</a></p>
<p>11 0.45972118 <a title="156-lsi-11" href="./cvpr-2013-Fast_Energy_Minimization_Using_Learned_State_Filters.html">165 cvpr-2013-Fast Energy Minimization Using Learned State Filters</a></p>
<p>12 0.42619559 <a title="156-lsi-12" href="./cvpr-2013-Discriminative_Re-ranking_of_Diverse_Segmentations.html">132 cvpr-2013-Discriminative Re-ranking of Diverse Segmentations</a></p>
<p>13 0.42604408 <a title="156-lsi-13" href="./cvpr-2013-Whitened_Expectation_Propagation%3A_Non-Lambertian_Shape_from_Shading_and_Shadow.html">466 cvpr-2013-Whitened Expectation Propagation: Non-Lambertian Shape from Shading and Shadow</a></p>
<p>14 0.42150488 <a title="156-lsi-14" href="./cvpr-2013-Spatial_Inference_Machines.html">406 cvpr-2013-Spatial Inference Machines</a></p>
<p>15 0.41940078 <a title="156-lsi-15" href="./cvpr-2013-Wide-Baseline_Hair_Capture_Using_Strand-Based_Refinement.html">467 cvpr-2013-Wide-Baseline Hair Capture Using Strand-Based Refinement</a></p>
<p>16 0.41292527 <a title="156-lsi-16" href="./cvpr-2013-A_Sentence_Is_Worth_a_Thousand_Pixels.html">25 cvpr-2013-A Sentence Is Worth a Thousand Pixels</a></p>
<p>17 0.39975101 <a title="156-lsi-17" href="./cvpr-2013-Nonlinearly_Constrained_MRFs%3A_Exploring_the_Intrinsic_Dimensions_of_Higher-Order_Cliques.html">308 cvpr-2013-Nonlinearly Constrained MRFs: Exploring the Intrinsic Dimensions of Higher-Order Cliques</a></p>
<p>18 0.3908664 <a title="156-lsi-18" href="./cvpr-2013-A_Higher-Order_CRF_Model_for_Road_Network_Extraction.html">13 cvpr-2013-A Higher-Order CRF Model for Road Network Extraction</a></p>
<p>19 0.38396865 <a title="156-lsi-19" href="./cvpr-2013-A_Comparative_Study_of_Modern_Inference_Techniques_for_Discrete_Energy_Minimization_Problems.html">6 cvpr-2013-A Comparative Study of Modern Inference Techniques for Discrete Energy Minimization Problems</a></p>
<p>20 0.3739683 <a title="156-lsi-20" href="./cvpr-2013-SCaLE%3A_Supervised_and_Cascaded_Laplacian_Eigenmaps_for_Visual_Object_Recognition_Based_on_Nearest_Neighbors.html">371 cvpr-2013-SCaLE: Supervised and Cascaded Laplacian Eigenmaps for Visual Object Recognition Based on Nearest Neighbors</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(4, 0.138), (10, 0.198), (16, 0.02), (26, 0.046), (28, 0.017), (33, 0.295), (39, 0.012), (67, 0.045), (69, 0.046), (80, 0.011), (87, 0.08)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.94883788 <a title="156-lda-1" href="./cvpr-2013-BRDF_Slices%3A_Accurate_Adaptive_Anisotropic_Appearance_Acquisition.html">54 cvpr-2013-BRDF Slices: Accurate Adaptive Anisotropic Appearance Acquisition</a></p>
<p>Author: Jirí Filip, Radomír Vávra, Michal Haindl, Pavel Žid, Mikuláš Krupika, Vlastimil Havran</p><p>Abstract: In this paper we introduce unique publicly available dense anisotropic BRDF data measurements. We use this dense data as a reference for performance evaluation of the proposed BRDF sparse angular sampling and interpolation approach. The method is based on sampling of BRDF subspaces at fixed elevations by means of several adaptively-represented, uniformly distributed, perpendicular slices. Although this proposed method requires only a sparse sampling of material, the interpolation provides a very accurate reconstruction, visually and computationally comparable to densely measured reference. Due to the simple slices measurement and method’s robustness it allows for a highly accurate acquisition of BRDFs. This in comparison with standard uniform angular sampling, is considerably faster yet uses far less samples.</p><p>2 0.94139755 <a title="156-lda-2" href="./cvpr-2013-A_Higher-Order_CRF_Model_for_Road_Network_Extraction.html">13 cvpr-2013-A Higher-Order CRF Model for Road Network Extraction</a></p>
<p>Author: Jan D. Wegner, Javier A. Montoya-Zegarra, Konrad Schindler</p><p>Abstract: The aim of this work is to extract the road network from aerial images. What makes the problem challenging is the complex structure of the prior: roads form a connected network of smooth, thin segments which meet at junctions and crossings. This type of a-priori knowledge is more difficult to turn into a tractable model than standard smoothness or co-occurrence assumptions. We develop a novel CRF formulation for road labeling, in which the prior is represented by higher-order cliques that connect sets of superpixels along straight line segments. These long-range cliques have asymmetric PN-potentials, which express a preference to assign all rather than just some of their constituent superpixels to the road class. Thus, the road likelihood is amplified for thin chains of superpixels, while the CRF is still amenable to optimization with graph cuts. Since the number of such cliques of arbitrary length is huge, we furthermorepropose a sampling scheme which concentrates on those cliques which are most relevant for the optimization. In experiments on two different databases the model significantly improves both the per-pixel accuracy and the topological correctness of the extracted roads, and outper- forms both a simple smoothness prior and heuristic rulebased road completion.</p><p>3 0.93975401 <a title="156-lda-3" href="./cvpr-2013-Structure_Preserving_Object_Tracking.html">414 cvpr-2013-Structure Preserving Object Tracking</a></p>
<p>Author: Lu Zhang, Laurens van_der_Maaten</p><p>Abstract: Model-free trackers can track arbitrary objects based on a single (bounding-box) annotation of the object. Whilst the performance of model-free trackers has recently improved significantly, simultaneously tracking multiple objects with similar appearance remains very hard. In this paper, we propose a new multi-object model-free tracker (based on tracking-by-detection) that resolves this problem by incorporating spatial constraints between the objects. The spatial constraints are learned along with the object detectors using an online structured SVM algorithm. The experimental evaluation ofour structure-preserving object tracker (SPOT) reveals significant performance improvements in multi-object tracking. We also show that SPOT can improve the performance of single-object trackers by simultaneously tracking different parts of the object.</p><p>4 0.92446864 <a title="156-lda-4" href="./cvpr-2013-Voxel_Cloud_Connectivity_Segmentation_-_Supervoxels_for_Point_Clouds.html">458 cvpr-2013-Voxel Cloud Connectivity Segmentation - Supervoxels for Point Clouds</a></p>
<p>Author: Jeremie Papon, Alexey Abramov, Markus Schoeler, Florentin Wörgötter</p><p>Abstract: Unsupervised over-segmentation of an image into regions of perceptually similar pixels, known as superpixels, is a widely used preprocessing step in segmentation algorithms. Superpixel methods reduce the number of regions that must be considered later by more computationally expensive algorithms, with a minimal loss of information. Nevertheless, as some information is inevitably lost, it is vital that superpixels not cross object boundaries, as such errors will propagate through later steps. Existing methods make use of projected color or depth information, but do not consider three dimensional geometric relationships between observed data points which can be used to prevent superpixels from crossing regions of empty space. We propose a novel over-segmentation algorithm which uses voxel relationships to produce over-segmentations which are fully consistent with the spatial geometry of the scene in three dimensional, rather than projective, space. Enforcing the constraint that segmented regions must have spatial connectivity prevents label flow across semantic object boundaries which might otherwise be violated. Additionally, as the algorithm works directly in 3D space, observations from several calibrated RGB+D cameras can be segmented jointly. Experiments on a large data set of human annotated RGB+D images demonstrate a significant reduction in occurrence of clusters crossing object boundaries, while maintaining speeds comparable to state-of-the-art 2D methods.</p><p>same-paper 5 0.92425948 <a title="156-lda-5" href="./cvpr-2013-Exploring_Compositional_High_Order_Pattern_Potentials_for_Structured_Output_Learning.html">156 cvpr-2013-Exploring Compositional High Order Pattern Potentials for Structured Output Learning</a></p>
<p>Author: Yujia Li, Daniel Tarlow, Richard Zemel</p><p>Abstract: When modeling structured outputs such as image segmentations, prediction can be improved by accurately modeling structure present in the labels. A key challenge is developing tractable models that are able to capture complex high level structure like shape. In this work, we study the learning of a general class of pattern-like high order potential, which we call Compositional High Order Pattern Potentials (CHOPPs). We show that CHOPPs include the linear deviation pattern potentials of Rother et al. [26] and also Restricted Boltzmann Machines (RBMs); we also establish the near equivalence of these two models. Experimentally, we show that performance is affected significantly by the degree of variability present in the datasets, and we define a quantitative variability measure to aid in studying this. We then improve CHOPPs performance in high variability datasets with two primary contributions: (a) developing a loss-sensitive joint learning procedure, so that internal pattern parameters can be learned in conjunction with other model potentials to minimize expected loss;and (b) learning an image-dependent mapping that encourages or inhibits patterns depending on image features. We also explore varying how multiple patterns are composed, and learning convolutional patterns. Quantitative results on challenging highly variable datasets show that the joint learning and image-dependent high order potentials can improve performance.</p><p>6 0.92159778 <a title="156-lda-6" href="./cvpr-2013-Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking.html">285 cvpr-2013-Minimum Uncertainty Gap for Robust Visual Tracking</a></p>
<p>7 0.92062521 <a title="156-lda-7" href="./cvpr-2013-Weakly_Supervised_Learning_of_Mid-Level_Features_with_Beta-Bernoulli_Process_Restricted_Boltzmann_Machines.html">462 cvpr-2013-Weakly Supervised Learning of Mid-Level Features with Beta-Bernoulli Process Restricted Boltzmann Machines</a></p>
<p>8 0.92043555 <a title="156-lda-8" href="./cvpr-2013-Discriminative_Non-blind_Deblurring.html">131 cvpr-2013-Discriminative Non-blind Deblurring</a></p>
<p>9 0.91993481 <a title="156-lda-9" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>10 0.91977531 <a title="156-lda-10" href="./cvpr-2013-Part-Based_Visual_Tracking_with_Online_Latent_Structural_Learning.html">324 cvpr-2013-Part-Based Visual Tracking with Online Latent Structural Learning</a></p>
<p>11 0.91954708 <a title="156-lda-11" href="./cvpr-2013-GeoF%3A_Geodesic_Forests_for_Learning_Coupled_Predictors.html">186 cvpr-2013-GeoF: Geodesic Forests for Learning Coupled Predictors</a></p>
<p>12 0.91917896 <a title="156-lda-12" href="./cvpr-2013-Handling_Noise_in_Single_Image_Deblurring_Using_Directional_Filters.html">198 cvpr-2013-Handling Noise in Single Image Deblurring Using Directional Filters</a></p>
<p>13 0.91870171 <a title="156-lda-13" href="./cvpr-2013-Online_Object_Tracking%3A_A_Benchmark.html">314 cvpr-2013-Online Object Tracking: A Benchmark</a></p>
<p>14 0.91853422 <a title="156-lda-14" href="./cvpr-2013-Graph_Transduction_Learning_with_Connectivity_Constraints_with_Application_to_Multiple_Foreground_Cosegmentation.html">193 cvpr-2013-Graph Transduction Learning with Connectivity Constraints with Application to Multiple Foreground Cosegmentation</a></p>
<p>15 0.91801339 <a title="156-lda-15" href="./cvpr-2013-Robust_Estimation_of_Nonrigid_Transformation_for_Point_Set_Registration.html">360 cvpr-2013-Robust Estimation of Nonrigid Transformation for Point Set Registration</a></p>
<p>16 0.91701818 <a title="156-lda-16" href="./cvpr-2013-Spatiotemporal_Deformable_Part_Models_for_Action_Detection.html">408 cvpr-2013-Spatiotemporal Deformable Part Models for Action Detection</a></p>
<p>17 0.91676748 <a title="156-lda-17" href="./cvpr-2013-Spatial_Inference_Machines.html">406 cvpr-2013-Spatial Inference Machines</a></p>
<p>18 0.91664433 <a title="156-lda-18" href="./cvpr-2013-Integrating_Grammar_and_Segmentation_for_Human_Pose_Estimation.html">225 cvpr-2013-Integrating Grammar and Segmentation for Human Pose Estimation</a></p>
<p>19 0.9155755 <a title="156-lda-19" href="./cvpr-2013-Least_Soft-Threshold_Squares_Tracking.html">267 cvpr-2013-Least Soft-Threshold Squares Tracking</a></p>
<p>20 0.91421926 <a title="156-lda-20" href="./cvpr-2013-Separating_Signal_from_Noise_Using_Patch_Recurrence_across_Scales.html">393 cvpr-2013-Separating Signal from Noise Using Patch Recurrence across Scales</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
