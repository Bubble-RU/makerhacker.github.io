<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>13 cvpr-2013-A Higher-Order CRF Model for Road Network Extraction</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-13" href="#">cvpr2013-13</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>13 cvpr-2013-A Higher-Order CRF Model for Road Network Extraction</h1>
<br/><p>Source: <a title="cvpr-2013-13-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Wegner_A_Higher-Order_CRF_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Jan D. Wegner, Javier A. Montoya-Zegarra, Konrad Schindler</p><p>Abstract: The aim of this work is to extract the road network from aerial images. What makes the problem challenging is the complex structure of the prior: roads form a connected network of smooth, thin segments which meet at junctions and crossings. This type of a-priori knowledge is more difficult to turn into a tractable model than standard smoothness or co-occurrence assumptions. We develop a novel CRF formulation for road labeling, in which the prior is represented by higher-order cliques that connect sets of superpixels along straight line segments. These long-range cliques have asymmetric PN-potentials, which express a preference to assign all rather than just some of their constituent superpixels to the road class. Thus, the road likelihood is amplified for thin chains of superpixels, while the CRF is still amenable to optimization with graph cuts. Since the number of such cliques of arbitrary length is huge, we furthermorepropose a sampling scheme which concentrates on those cliques which are most relevant for the optimization. In experiments on two different databases the model significantly improves both the per-pixel accuracy and the topological correctness of the extracted roads, and outper- forms both a simple smoothness prior and heuristic rulebased road completion.</p><p>Reference: <a title="cvpr-2013-13-reference" href="../cvpr2013_reference/cvpr-2013-A_Higher-Order_CRF_Model_for_Road_Network_Extraction_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 A higher-order CRF model for road network extraction Jan D. [sent-1, score-0.985]
</p><p>2 Montoya-Zegarra, Konrad Schindler Photogrammetry and Remote Sensing, ETH Z u¨rich, Switzerland  Abstract The aim of this work is to extract the road network from aerial images. [sent-3, score-0.96]
</p><p>3 What makes the problem challenging is the complex structure of the prior: roads form a connected network of smooth, thin segments which meet at junctions and crossings. [sent-4, score-0.737]
</p><p>4 This type of a-priori knowledge is more difficult to turn into a tractable model than standard smoothness or co-occurrence assumptions. [sent-5, score-0.026]
</p><p>5 We develop a novel CRF formulation for road labeling, in which the prior is represented by higher-order cliques that connect sets of superpixels along straight line segments. [sent-6, score-1.187]
</p><p>6 These long-range cliques have asymmetric PN-potentials, which express a preference to assign all rather than just some of their constituent superpixels to the road class. [sent-7, score-1.165]
</p><p>7 Thus, the road likelihood is amplified for thin chains of superpixels, while the CRF is still amenable to optimization with graph cuts. [sent-8, score-0.913]
</p><p>8 Since the number of such cliques of arbitrary length is huge, we furthermorepropose a sampling scheme which concentrates on those cliques which are most relevant for the optimization. [sent-9, score-0.469]
</p><p>9 In experiments on two different databases the model significantly improves both the per-pixel accuracy and the topological correctness of the extracted roads, and outper-  forms both a simple smoothness prior and heuristic rulebased road completion. [sent-10, score-0.815]
</p><p>10 Introduction The application problem behind this paper is the extraction ofthe road network from aerial or satellite images. [sent-12, score-1.049]
</p><p>11 This is a challenging vision problem with important applications in mapping and remote sensing. [sent-13, score-0.04]
</p><p>12 In spite of more than two decades of research [1, 7, 10, 18], the problem is largely unsolved—we are not aware of an operational system for automatic road extraction. [sent-14, score-0.723]
</p><p>13 The proposed higher-order CRF favors networks of elongated segments (top). [sent-16, score-0.193]
</p><p>14 approximate centerlines has been recovered, the exact segmentation can be refined locally (e. [sent-18, score-0.028]
</p><p>15 We point out that this is an instance of a more general issue beyond road extraction. [sent-21, score-0.693]
</p><p>16 It exists in similar form for other image understanding tasks which involve objects with a “network” topology, i. [sent-22, score-0.027]
</p><p>17 they are made up of thin segments linked together by junctions and crossings (Fig. [sent-24, score-0.26]
</p><p>18 semantic interpretation of the image content) is that the observation data is noisy, incomplete and ambiguous, such that prior knowledge about the layout of the observed scenes is necessary to obtain satisfactory results. [sent-28, score-0.065]
</p><p>19 As a consequence, a main focus of computer vision research over the past decade has been how to include such prior knowledge into the (usually probabilistic) models. [sent-29, score-0.067]
</p><p>20 Maybe the simplest form of prior are expectations about an object’s location, along the lines of “the sky is usually at the top”. [sent-30, score-0.105]
</p><p>21 They are conditionally independent between  different pixels and can directly be merged into the per-pixel likelihood, e. [sent-31, score-0.025]
</p><p>22 Arguably, much progress in image understanding in the last decade is due to the fact that in CRFs with appropriately restricted clique potentials (approximate) MAP estimation is possible with variants of graph cuts [3] or message passing [6, 14]. [sent-38, score-0.392]
</p><p>23 However, for some object classes more complex priors are adequate, and these include our target class, the roads on the earth’s surface. [sent-39, score-0.25]
</p><p>24 The characteristic feature of the roads is their network structure: road segments are thin linear structures with limited and smoothly changing curvature; and a road segment is usually connected to other road segments on both sides, sometimes connected only on one side, but almost never isolated. [sent-40, score-2.907]
</p><p>25 In principle, it is of course possible to formalize all the desired constraints into a probabilistic model, and some research in that direction exists, e. [sent-42, score-0.028]
</p><p>26 Unfortunately, the resulting likelihood functions tend not to be amenable to efficient inference algorithms. [sent-45, score-0.152]
</p><p>27 Solutions can only be found with Markov Chain Monte Carlo samplers or annealingtype methods, which are rather difficult to parameterise correctly and have high computational cost. [sent-46, score-0.03]
</p><p>28 In most of the literature, the network structure of roads is introduced only after detection, by filling gaps between detected road segments with heuristic rules (c. [sent-47, score-1.395]
</p><p>29 In the present paper, we explore the possibility to construct an intermediate model, which captures important properties of the road network while still being amenable to efficient inference techniques. [sent-51, score-1.031]
</p><p>30 To our knowledge this is the first work which exploits the rich modeling possibilities of the PN-Potts model for network modeling in general and for road extraction in particular. [sent-53, score-1.012]
</p><p>31 Related work There is an extensive body of work on road extraction, and we can only review a representative selection here. [sent-55, score-0.693]
</p><p>32 Road detection in images goes back to at least [1], where road pixels are identified with a sequence of local image processing operations. [sent-58, score-0.718]
</p><p>33 Only shortly afterwards [7] was probably the first work to explicitly incorporate topology, by searching long 1-dimensional structures. [sent-59, score-0.028]
</p><p>34 A local road score is computed at each pixel with a line detector and roads are found iteratively as minimum cost paths with an A∗-type algorithm. [sent-60, score-0.943]
</p><p>35 In [17] road extraction is based on multi-scale line detection. [sent-61, score-0.757]
</p><p>36 A heuristic completion scheme is employed to bridge gaps due to shadows, overhanging trees etc. [sent-62, score-0.125]
</p><p>37 Subsequently the road segmentation is refined with a pair of coupled active contours (“twin-snakes”). [sent-63, score-0.718]
</p><p>38 Detecting oriented road segments also forms the basis of [12]. [sent-64, score-0.792]
</p><p>39 The most road-like of these segments are then designated as seeds and the network is iteratively grown from there. [sent-65, score-0.355]
</p><p>40 In a final step, the network is pruned with a shape-based classifier to remove false positives. [sent-66, score-0.228]
</p><p>41 In [22, 15] marked point processes (MPP) are introduced as representation for short road segments. [sent-67, score-0.693]
</p><p>42 In [19, 20] a deep belief network is trained to detect image patches containing roads. [sent-70, score-0.228]
</p><p>43 A second network is trained to take the output of the first one as input and fill small gaps. [sent-71, score-0.263]
</p><p>44 Using massive amounts of training data—extracted automatically with the help of existing road databases—they achieve promising results, on images with largely unoccluded roads. [sent-72, score-0.693]
</p><p>45 The works mentioned so far have focused on rural and suburban areas, where the road network is relatively sparse and regular, and less affected by occlusions, shadows, cars etc. [sent-73, score-1.017]
</p><p>46 Given high-resolution images and a height map, road segments are detected using multiple cues (dark homogeneous areas, valley lines of the height map, lane markings, vehicles). [sent-75, score-0.873]
</p><p>47 The segments are then connected by iteratively inserting potentially missing connections and verifying that they have sufficiently homogeneous brightness. [sent-76, score-0.182]
</p><p>48 Overall, little research exists on road extraction in dense urban scenes. [sent-77, score-0.825]
</p><p>49 Road extraction has also been attempted from other data sources, e. [sent-78, score-0.064]
</p><p>50 [3 1] extract road center lines from range images generated with airborne laser scanning, and [25, 24] extract roads from synthetic aperture radar (SAR) imagery. [sent-80, score-1.028]
</p><p>51 Both approaches are surprisingly similar: detect oriented lines, link them to straight road segments, hypothesize addi-  tional segments to “fill the gaps” in the network with simple geometric rules, and select which of the hypotheses to keep by inference in a pairwise MRF over the segments. [sent-81, score-1.148]
</p><p>52 CRF Model of the road network We pose road extraction as a binary labeling problem on superpixels, linked together in a CRF which encodes the 111666999977  prior assumptions about the roads. [sent-83, score-1.776]
</p><p>53 Image representation and unaries Rather than working with individual pixels, the raw image is over-segmented into small, regular superpixels, which are the atomic units for all further processing. [sent-87, score-0.07]
</p><p>54 While our method can in principle be extended to individual pixels, we prefer to use superpixels for practical reasons. [sent-89, score-0.187]
</p><p>55 On the one hand, they yield more stable unaries because of their larger support, on the other hand, they greatly speed up processing, both during clique generation (Sec. [sent-90, score-0.278]
</p><p>56 Their main disadvantage is that in certain cases they will lead to jagged and incorrect road boundaries. [sent-93, score-0.721]
</p><p>57 We are mainly interested in improved extraction of the network topology, and believe segmentation boundaries are best cleaned up in a subsequent step with a  stronger shape prior (e. [sent-94, score-0.354]
</p><p>58 The next step is to estimate, for each superpixel, the likelihood of being road respectively background. [sent-97, score-0.735]
</p><p>59 In detail, we convert the image to opponent Gaussian color space [5] and convolve it with the 17-dimensional filter bank proposed by Winn et al. [sent-100, score-0.054]
</p><p>60 The filter bank consists of Gaussian kernels at three scales, first-order Gaussian derivatives in x and y at two scales, and LoG responses at four scales. [sent-102, score-0.029]
</p><p>61 The 34-dimensional feature vector for a superpixel is made up of the means and standard deviations of the individual filter channels. [sent-104, score-0.075]
</p><p>62 , [23, 21, 8, 9]), mainly because efficient inference methods existed only for these. [sent-110, score-0.076]
</p><p>63 They are sampled by connecting superpixels with high road likelihood. [sent-116, score-0.88]
</p><p>64 In our case the variables to bPe yla|bxe)led ∝ are pth(e− sEet (Sx oyf) superpixels, asned t hthee v laarbiaebl esest tios yi ∈ {0, 1}, where 1 denotes road and 0 background. [sent-120, score-0.75]
</p><p>65 Instea∈d {o0f, only allowing unary raonadd pairwise potentials, tIhne-  Gibbs energy for a higher-order CRF is given by  E (x,y)  = ? [sent-121, score-0.026]
</p><p>66 c∈H  ,  (1)  where H denotes the set of cliques (note, for convenience of notation we also include possible pairwise cliques in H), ψi are the unaries, and ψc are the clique potentials that encode dependencies between the variables of a clique. [sent-125, score-0.798]
</p><p>67 MAP inference consists in maximizing P (y|x), which is the same as minimizing tsh ien energy Eiz (inxg, y P). [sent-126, score-0.049]
</p><p>68 Obviously, a CRF with standard pairwise potentials will not be able to encode these long-range structures, but rather tend to smooth away thin structures such as roads, a welldocumented phenomenon in image segmentation (e. [sent-130, score-0.238]
</p><p>69 Instead, we require a higher-order potential over long elongated sets of superpixels (Fig. [sent-134, score-0.311]
</p><p>70 2), which encourages them to take on the road label if the cumulative evidence over the entire clique is strong enough. [sent-135, score-0.932]
</p><p>71 Still many such cliques will also contain some background superpixels, thus the penalty for non-road labels in the clique should increase gracefully rather than abruptly with the first deviating superpixel. [sent-136, score-0.488]
</p><p>72 The higher order potential ψc (xc, y) that we propose has the following form: 111667990088  ψc(xc,yc) =? [sent-138, score-0.03]
</p><p>73 (wci · yi) the weighted sum of road superpixels in the cliqu? [sent-142, score-0.88]
</p><p>74 α is an upper bound on the potentials, and γ are the remaining parameters of a truncated linear cost function. [sent-153, score-0.03]
</p><p>75 Using a truncated linear function ensures the desired graceful increase of the penalty, while penalizing only background pixels in road-dominated cliques introduces the desired asymmetry. [sent-154, score-0.396]
</p><p>76 The potential (2) is designed in such a way that it is a special case of the robust PN-Potts model, a class of higherorder CRFs introduced in [13] whose energies can be minimized in low polynomial time with graph cuts. [sent-155, score-0.03]
</p><p>77 The intuition is the following: if  a superpixel has high background likelihood and its features deviate a lot from the other ones in the clique, then it probably belongs to the background, i. [sent-159, score-0.178]
</p><p>78 labeling it as background should not have a large impact on the energy (for example, think of a small roundabout on a major road). [sent-161, score-0.068]
</p><p>79 Empirically we found the following weighting scheme to work best: we compute the mean feature vector xc of the clique, and for each superpixel measure the deviation of its feature vector xi from that mean, using the Euclidean distance dci = ? [sent-162, score-0.162]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('road', 0.693), ('roads', 0.25), ('network', 0.228), ('cliques', 0.222), ('clique', 0.208), ('superpixels', 0.187), ('crf', 0.153), ('potentials', 0.12), ('wci', 0.103), ('segments', 0.099), ('elongated', 0.094), ('thin', 0.092), ('crfs', 0.077), ('superpixel', 0.075), ('unaries', 0.07), ('mpps', 0.069), ('suburban', 0.069), ('extraction', 0.064), ('amenable', 0.061), ('topology', 0.058), ('xc', 0.057), ('gaps', 0.056), ('straight', 0.053), ('inference', 0.049), ('expectations', 0.043), ('likelihood', 0.042), ('urban', 0.041), ('remote', 0.04), ('heuristic', 0.039), ('aerial', 0.039), ('junctions', 0.038), ('carlo', 0.035), ('decade', 0.035), ('fill', 0.035), ('labeling', 0.035), ('gibbs', 0.034), ('monte', 0.034), ('preference', 0.034), ('satisfactory', 0.033), ('background', 0.033), ('prior', 0.032), ('linked', 0.031), ('evidence', 0.031), ('airborne', 0.03), ('asned', 0.03), ('bilities', 0.03), ('bxe', 0.03), ('cleaned', 0.03), ('dci', 0.03), ('eiz', 0.03), ('graceful', 0.03), ('javier', 0.03), ('ndis', 0.03), ('operational', 0.03), ('overhanging', 0.03), ('rids', 0.03), ('samplers', 0.03), ('shadows', 0.03), ('truncated', 0.03), ('lines', 0.03), ('connected', 0.03), ('potential', 0.03), ('rules', 0.03), ('bank', 0.029), ('asymmetric', 0.029), ('appropriately', 0.029), ('sar', 0.028), ('bpe', 0.028), ('brittle', 0.028), ('centerlines', 0.028), ('designated', 0.028), ('jagged', 0.028), ('yla', 0.028), ('desired', 0.028), ('probably', 0.028), ('chain', 0.027), ('rich', 0.027), ('connections', 0.027), ('existed', 0.027), ('markings', 0.027), ('rjmcmc', 0.027), ('rural', 0.027), ('tios', 0.027), ('exists', 0.027), ('smoothness', 0.026), ('homogeneous', 0.026), ('pairwise', 0.026), ('deduce', 0.025), ('photogrammetry', 0.025), ('amplified', 0.025), ('concentrates', 0.025), ('deviating', 0.025), ('opponent', 0.025), ('oyf', 0.025), ('radar', 0.025), ('satellite', 0.025), ('valley', 0.025), ('pixels', 0.025), ('contours', 0.025), ('databases', 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999988 <a title="13-tfidf-1" href="./cvpr-2013-A_Higher-Order_CRF_Model_for_Road_Network_Extraction.html">13 cvpr-2013-A Higher-Order CRF Model for Road Network Extraction</a></p>
<p>Author: Jan D. Wegner, Javier A. Montoya-Zegarra, Konrad Schindler</p><p>Abstract: The aim of this work is to extract the road network from aerial images. What makes the problem challenging is the complex structure of the prior: roads form a connected network of smooth, thin segments which meet at junctions and crossings. This type of a-priori knowledge is more difficult to turn into a tractable model than standard smoothness or co-occurrence assumptions. We develop a novel CRF formulation for road labeling, in which the prior is represented by higher-order cliques that connect sets of superpixels along straight line segments. These long-range cliques have asymmetric PN-potentials, which express a preference to assign all rather than just some of their constituent superpixels to the road class. Thus, the road likelihood is amplified for thin chains of superpixels, while the CRF is still amenable to optimization with graph cuts. Since the number of such cliques of arbitrary length is huge, we furthermorepropose a sampling scheme which concentrates on those cliques which are most relevant for the optimization. In experiments on two different databases the model significantly improves both the per-pixel accuracy and the topological correctness of the extracted roads, and outper- forms both a simple smoothness prior and heuristic rulebased road completion.</p><p>2 0.38093823 <a title="13-tfidf-2" href="./cvpr-2013-Recovering_Line-Networks_in_Images_by_Junction-Point_Processes.html">351 cvpr-2013-Recovering Line-Networks in Images by Junction-Point Processes</a></p>
<p>Author: Dengfeng Chai, Wolfgang Förstner, Florent Lafarge</p><p>Abstract: The automatic extraction of line-networks from images is a well-known computer vision issue. Appearance and shape considerations have been deeply explored in the literature to improve accuracy in presence of occlusions, shadows, and a wide variety of irrelevant objects. However most existing works have ignored the structural aspect of the problem. We present an original method which provides structurally-coherent solutions. Contrary to the pixelbased and object-based methods, our result is a graph in which each node represents either a connection or an ending in the line-network. Based on stochastic geometry, we develop a new family of point processes consisting in sampling junction-points in the input image by using a Monte Carlo mechanism. The quality of a configuration is measured by a probability density which takes into account both image consistency and shape priors. Our experiments on a variety of problems illustrate the potential of our approach in terms of accuracy, flexibility and efficiency.</p><p>3 0.16275071 <a title="13-tfidf-3" href="./cvpr-2013-Analyzing_Semantic_Segmentation_Using_Hybrid_Human-Machine_CRFs.html">43 cvpr-2013-Analyzing Semantic Segmentation Using Hybrid Human-Machine CRFs</a></p>
<p>Author: Roozbeh Mottaghi, Sanja Fidler, Jian Yao, Raquel Urtasun, Devi Parikh</p><p>Abstract: Recent trends in semantic image segmentation have pushed for holistic scene understanding models that jointly reason about various tasks such as object detection, scene recognition, shape analysis, contextual reasoning. In this work, we are interested in understanding the roles of these different tasks in aiding semantic segmentation. Towards this goal, we “plug-in ” human subjects for each of the various components in a state-of-the-art conditional random field model (CRF) on the MSRC dataset. Comparisons among various hybrid human-machine CRFs give us indications of how much “head room ” there is to improve segmentation by focusing research efforts on each of the tasks. One of the interesting findings from our slew of studies was that human classification of isolated super-pixels, while being worse than current machine classifiers, provides a significant boost in performance when plugged into the CRF! Fascinated by this finding, we conducted in depth analysis of the human generated potentials. This inspired a new machine potential which significantly improves state-of-the-art performance on the MRSC dataset.</p><p>4 0.14822921 <a title="13-tfidf-4" href="./cvpr-2013-Improving_an_Object_Detector_and_Extracting_Regions_Using_Superpixels.html">217 cvpr-2013-Improving an Object Detector and Extracting Regions Using Superpixels</a></p>
<p>Author: Guang Shu, Afshin Dehghan, Mubarak Shah</p><p>Abstract: We propose an approach to improve the detection performance of a generic detector when it is applied to a particular video. The performance of offline-trained objects detectors are usually degraded in unconstrained video environments due to variant illuminations, backgrounds and camera viewpoints. Moreover, most object detectors are trained using Haar-like features or gradient features but ignore video specificfeatures like consistent colorpatterns. In our approach, we apply a Superpixel-based Bag-of-Words (BoW) model to iteratively refine the output of a generic detector. Compared to other related work, our method builds a video-specific detector using superpixels, hence it can handle the problem of appearance variation. Most importantly, using Conditional Random Field (CRF) along with our super pixel-based BoW model, we develop and algorithm to segment the object from the background . Therefore our method generates an output of the exact object regions instead of the bounding boxes generated by most detectors. In general, our method takes detection bounding boxes of a generic detector as input and generates the detection output with higher average precision and precise object regions. The experiments on four recent datasets demonstrate the effectiveness of our approach and significantly improves the state-of-art detector by 5-16% in average precision.</p><p>5 0.13857181 <a title="13-tfidf-5" href="./cvpr-2013-Nonparametric_Scene_Parsing_with_Adaptive_Feature_Relevance_and_Semantic_Context.html">309 cvpr-2013-Nonparametric Scene Parsing with Adaptive Feature Relevance and Semantic Context</a></p>
<p>Author: Gautam Singh, Jana Kosecka</p><p>Abstract: This paper presents a nonparametric approach to semantic parsing using small patches and simple gradient, color and location features. We learn the relevance of individual feature channels at test time using a locally adaptive distance metric. To further improve the accuracy of the nonparametric approach, we examine the importance of the retrieval set used to compute the nearest neighbours using a novel semantic descriptor to retrieve better candidates. The approach is validated by experiments on several datasets used for semantic parsing demonstrating the superiority of the method compared to the state of art approaches.</p><p>6 0.12924115 <a title="13-tfidf-6" href="./cvpr-2013-Whitened_Expectation_Propagation%3A_Non-Lambertian_Shape_from_Shading_and_Shadow.html">466 cvpr-2013-Whitened Expectation Propagation: Non-Lambertian Shape from Shading and Shadow</a></p>
<p>7 0.12641402 <a title="13-tfidf-7" href="./cvpr-2013-Mesh_Based_Semantic_Modelling_for_Indoor_and_Outdoor_Scenes.html">284 cvpr-2013-Mesh Based Semantic Modelling for Indoor and Outdoor Scenes</a></p>
<p>8 0.11648107 <a title="13-tfidf-8" href="./cvpr-2013-Fully-Connected_CRFs_with_Non-Parametric_Pairwise_Potential.html">180 cvpr-2013-Fully-Connected CRFs with Non-Parametric Pairwise Potential</a></p>
<p>9 0.11098558 <a title="13-tfidf-9" href="./cvpr-2013-Fast_Energy_Minimization_Using_Learned_State_Filters.html">165 cvpr-2013-Fast Energy Minimization Using Learned State Filters</a></p>
<p>10 0.1073142 <a title="13-tfidf-10" href="./cvpr-2013-Composite_Statistical_Inference_for_Semantic_Segmentation.html">86 cvpr-2013-Composite Statistical Inference for Semantic Segmentation</a></p>
<p>11 0.10585759 <a title="13-tfidf-11" href="./cvpr-2013-A_Video_Representation_Using_Temporal_Superpixels.html">29 cvpr-2013-A Video Representation Using Temporal Superpixels</a></p>
<p>12 0.10479736 <a title="13-tfidf-12" href="./cvpr-2013-Label_Propagation_from_ImageNet_to_3D_Point_Clouds.html">242 cvpr-2013-Label Propagation from ImageNet to 3D Point Clouds</a></p>
<p>13 0.10284771 <a title="13-tfidf-13" href="./cvpr-2013-SCALPEL%3A_Segmentation_Cascades_with_Localized_Priors_and_Efficient_Learning.html">370 cvpr-2013-SCALPEL: Segmentation Cascades with Localized Priors and Efficient Learning</a></p>
<p>14 0.10045327 <a title="13-tfidf-14" href="./cvpr-2013-Exploring_Compositional_High_Order_Pattern_Potentials_for_Structured_Output_Learning.html">156 cvpr-2013-Exploring Compositional High Order Pattern Potentials for Structured Output Learning</a></p>
<p>15 0.097381555 <a title="13-tfidf-15" href="./cvpr-2013-Reconstructing_Loopy_Curvilinear_Structures_Using_Integer_Programming.html">350 cvpr-2013-Reconstructing Loopy Curvilinear Structures Using Integer Programming</a></p>
<p>16 0.095929995 <a title="13-tfidf-16" href="./cvpr-2013-Manhattan_Junction_Catalogue_for_Spatial_Reasoning_of_Indoor_Scenes.html">278 cvpr-2013-Manhattan Junction Catalogue for Spatial Reasoning of Indoor Scenes</a></p>
<p>17 0.095231652 <a title="13-tfidf-17" href="./cvpr-2013-Multi-target_Tracking_by_Lagrangian_Relaxation_to_Min-cost_Network_Flow.html">300 cvpr-2013-Multi-target Tracking by Lagrangian Relaxation to Min-cost Network Flow</a></p>
<p>18 0.091704942 <a title="13-tfidf-18" href="./cvpr-2013-Augmenting_CRFs_with_Boltzmann_Machine_Shape_Priors_for_Image_Labeling.html">50 cvpr-2013-Augmenting CRFs with Boltzmann Machine Shape Priors for Image Labeling</a></p>
<p>19 0.087336615 <a title="13-tfidf-19" href="./cvpr-2013-Weakly-Supervised_Dual_Clustering_for_Image_Semantic_Segmentation.html">460 cvpr-2013-Weakly-Supervised Dual Clustering for Image Semantic Segmentation</a></p>
<p>20 0.085558183 <a title="13-tfidf-20" href="./cvpr-2013-Voxel_Cloud_Connectivity_Segmentation_-_Supervoxels_for_Point_Clouds.html">458 cvpr-2013-Voxel Cloud Connectivity Segmentation - Supervoxels for Point Clouds</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.156), (1, 0.02), (2, 0.041), (3, -0.017), (4, 0.119), (5, 0.025), (6, 0.052), (7, 0.088), (8, -0.101), (9, 0.007), (10, 0.17), (11, -0.041), (12, -0.043), (13, 0.078), (14, -0.066), (15, 0.092), (16, 0.047), (17, 0.024), (18, 0.043), (19, 0.011), (20, 0.034), (21, -0.017), (22, -0.093), (23, 0.085), (24, -0.09), (25, 0.005), (26, -0.047), (27, 0.007), (28, -0.087), (29, 0.055), (30, -0.032), (31, -0.069), (32, 0.029), (33, 0.051), (34, -0.12), (35, 0.026), (36, -0.054), (37, 0.031), (38, 0.047), (39, 0.113), (40, 0.031), (41, -0.028), (42, 0.039), (43, -0.089), (44, -0.166), (45, -0.001), (46, -0.024), (47, -0.046), (48, -0.193), (49, -0.012)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96042246 <a title="13-lsi-1" href="./cvpr-2013-A_Higher-Order_CRF_Model_for_Road_Network_Extraction.html">13 cvpr-2013-A Higher-Order CRF Model for Road Network Extraction</a></p>
<p>Author: Jan D. Wegner, Javier A. Montoya-Zegarra, Konrad Schindler</p><p>Abstract: The aim of this work is to extract the road network from aerial images. What makes the problem challenging is the complex structure of the prior: roads form a connected network of smooth, thin segments which meet at junctions and crossings. This type of a-priori knowledge is more difficult to turn into a tractable model than standard smoothness or co-occurrence assumptions. We develop a novel CRF formulation for road labeling, in which the prior is represented by higher-order cliques that connect sets of superpixels along straight line segments. These long-range cliques have asymmetric PN-potentials, which express a preference to assign all rather than just some of their constituent superpixels to the road class. Thus, the road likelihood is amplified for thin chains of superpixels, while the CRF is still amenable to optimization with graph cuts. Since the number of such cliques of arbitrary length is huge, we furthermorepropose a sampling scheme which concentrates on those cliques which are most relevant for the optimization. In experiments on two different databases the model significantly improves both the per-pixel accuracy and the topological correctness of the extracted roads, and outper- forms both a simple smoothness prior and heuristic rulebased road completion.</p><p>2 0.67335653 <a title="13-lsi-2" href="./cvpr-2013-Recovering_Line-Networks_in_Images_by_Junction-Point_Processes.html">351 cvpr-2013-Recovering Line-Networks in Images by Junction-Point Processes</a></p>
<p>Author: Dengfeng Chai, Wolfgang Förstner, Florent Lafarge</p><p>Abstract: The automatic extraction of line-networks from images is a well-known computer vision issue. Appearance and shape considerations have been deeply explored in the literature to improve accuracy in presence of occlusions, shadows, and a wide variety of irrelevant objects. However most existing works have ignored the structural aspect of the problem. We present an original method which provides structurally-coherent solutions. Contrary to the pixelbased and object-based methods, our result is a graph in which each node represents either a connection or an ending in the line-network. Based on stochastic geometry, we develop a new family of point processes consisting in sampling junction-points in the input image by using a Monte Carlo mechanism. The quality of a configuration is measured by a probability density which takes into account both image consistency and shape priors. Our experiments on a variety of problems illustrate the potential of our approach in terms of accuracy, flexibility and efficiency.</p><p>3 0.64081007 <a title="13-lsi-3" href="./cvpr-2013-A_Statistical_Model_for_Recreational_Trails_in_Aerial_Images.html">26 cvpr-2013-A Statistical Model for Recreational Trails in Aerial Images</a></p>
<p>Author: Andrew Predoehl, Scott Morris, Kobus Barnard</p><p>Abstract: unkown-abstract</p><p>4 0.56124598 <a title="13-lsi-4" href="./cvpr-2013-Composite_Statistical_Inference_for_Semantic_Segmentation.html">86 cvpr-2013-Composite Statistical Inference for Semantic Segmentation</a></p>
<p>Author: Fuxin Li, Joao Carreira, Guy Lebanon, Cristian Sminchisescu</p><p>Abstract: In this paper we present an inference procedure for the semantic segmentation of images. Differentfrom many CRF approaches that rely on dependencies modeled with unary and pairwise pixel or superpixel potentials, our method is entirely based on estimates of the overlap between each of a set of mid-level object segmentation proposals and the objects present in the image. We define continuous latent variables on superpixels obtained by multiple intersections of segments, then output the optimal segments from the inferred superpixel statistics. The algorithm is capable of recombine and refine initial mid-level proposals, as well as handle multiple interacting objects, even from the same class, all in a consistent joint inference framework by maximizing the composite likelihood of the underlying statistical model using an EM algorithm. In the PASCAL VOC segmentation challenge, the proposed approach obtains high accuracy and successfully handles images of complex object interactions.</p><p>5 0.55759764 <a title="13-lsi-5" href="./cvpr-2013-Fast_Energy_Minimization_Using_Learned_State_Filters.html">165 cvpr-2013-Fast Energy Minimization Using Learned State Filters</a></p>
<p>Author: Matthieu Guillaumin, Luc Van_Gool, Vittorio Ferrari</p><p>Abstract: Pairwise discrete energies defined over graphs are ubiquitous in computer vision. Many algorithms have been proposed to minimize such energies, often concentrating on sparse graph topologies or specialized classes of pairwise potentials. However, when the graph is fully connected and the pairwise potentials are arbitrary, the complexity of even approximate minimization algorithms such as TRW-S grows quadratically both in the number of nodes and in the number of states a node can take. Moreover, recent applications are using more and more computationally expensive pairwise potentials. These factors make it very hard to employ fully connected models. In this paper we propose a novel, generic algorithm to approximately minimize any discrete pairwise energy function. Our method exploits tractable sub-energies to filter the domain of the function. The parameters of the filter are learnt from instances of the same class of energies with good candidate solutions. Compared to existing methods, it efficiently handles fully connected graphs, with many states per node, and arbitrary pairwise potentials, which might be expensive to compute. We demonstrate experimentally on two applications that our algorithm is much more efficient than other generic minimization algorithms such as TRW-S, while returning essentially identical solutions.</p><p>6 0.52248698 <a title="13-lsi-6" href="./cvpr-2013-A_Principled_Deep_Random_Field_Model_for_Image_Segmentation.html">24 cvpr-2013-A Principled Deep Random Field Model for Image Segmentation</a></p>
<p>7 0.52213186 <a title="13-lsi-7" href="./cvpr-2013-Manhattan_Junction_Catalogue_for_Spatial_Reasoning_of_Indoor_Scenes.html">278 cvpr-2013-Manhattan Junction Catalogue for Spatial Reasoning of Indoor Scenes</a></p>
<p>8 0.51060963 <a title="13-lsi-8" href="./cvpr-2013-Probabilistic_Graphlet_Cut%3A_Exploiting_Spatial_Structure_Cue_for_Weakly_Supervised_Image_Segmentation.html">339 cvpr-2013-Probabilistic Graphlet Cut: Exploiting Spatial Structure Cue for Weakly Supervised Image Segmentation</a></p>
<p>9 0.50655949 <a title="13-lsi-9" href="./cvpr-2013-Fully-Connected_CRFs_with_Non-Parametric_Pairwise_Potential.html">180 cvpr-2013-Fully-Connected CRFs with Non-Parametric Pairwise Potential</a></p>
<p>10 0.49633238 <a title="13-lsi-10" href="./cvpr-2013-A_Video_Representation_Using_Temporal_Superpixels.html">29 cvpr-2013-A Video Representation Using Temporal Superpixels</a></p>
<p>11 0.49556494 <a title="13-lsi-11" href="./cvpr-2013-Spatial_Inference_Machines.html">406 cvpr-2013-Spatial Inference Machines</a></p>
<p>12 0.48730046 <a title="13-lsi-12" href="./cvpr-2013-Reconstructing_Loopy_Curvilinear_Structures_Using_Integer_Programming.html">350 cvpr-2013-Reconstructing Loopy Curvilinear Structures Using Integer Programming</a></p>
<p>13 0.48393476 <a title="13-lsi-13" href="./cvpr-2013-Lost%21_Leveraging_the_Crowd_for_Probabilistic_Visual_Self-Localization.html">274 cvpr-2013-Lost! Leveraging the Crowd for Probabilistic Visual Self-Localization</a></p>
<p>14 0.46641868 <a title="13-lsi-14" href="./cvpr-2013-Nonparametric_Scene_Parsing_with_Adaptive_Feature_Relevance_and_Semantic_Context.html">309 cvpr-2013-Nonparametric Scene Parsing with Adaptive Feature Relevance and Semantic Context</a></p>
<p>15 0.46589711 <a title="13-lsi-15" href="./cvpr-2013-Analyzing_Semantic_Segmentation_Using_Hybrid_Human-Machine_CRFs.html">43 cvpr-2013-Analyzing Semantic Segmentation Using Hybrid Human-Machine CRFs</a></p>
<p>16 0.46446896 <a title="13-lsi-16" href="./cvpr-2013-Whitened_Expectation_Propagation%3A_Non-Lambertian_Shape_from_Shading_and_Shadow.html">466 cvpr-2013-Whitened Expectation Propagation: Non-Lambertian Shape from Shading and Shadow</a></p>
<p>17 0.43179941 <a title="13-lsi-17" href="./cvpr-2013-Label_Propagation_from_ImageNet_to_3D_Point_Clouds.html">242 cvpr-2013-Label Propagation from ImageNet to 3D Point Clouds</a></p>
<p>18 0.42878786 <a title="13-lsi-18" href="./cvpr-2013-Learning_for_Structured_Prediction_Using_Approximate_Subgradient_Descent_with_Working_Sets.html">262 cvpr-2013-Learning for Structured Prediction Using Approximate Subgradient Descent with Working Sets</a></p>
<p>19 0.4218263 <a title="13-lsi-19" href="./cvpr-2013-Robust_Region_Grouping_via_Internal_Patch_Statistics.html">366 cvpr-2013-Robust Region Grouping via Internal Patch Statistics</a></p>
<p>20 0.41917923 <a title="13-lsi-20" href="./cvpr-2013-A_Comparative_Study_of_Modern_Inference_Techniques_for_Discrete_Energy_Minimization_Problems.html">6 cvpr-2013-A Comparative Study of Modern Inference Techniques for Discrete Energy Minimization Problems</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(4, 0.214), (10, 0.137), (16, 0.015), (26, 0.052), (33, 0.302), (67, 0.036), (69, 0.042), (87, 0.105)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.91438061 <a title="13-lda-1" href="./cvpr-2013-BRDF_Slices%3A_Accurate_Adaptive_Anisotropic_Appearance_Acquisition.html">54 cvpr-2013-BRDF Slices: Accurate Adaptive Anisotropic Appearance Acquisition</a></p>
<p>Author: Jirí Filip, Radomír Vávra, Michal Haindl, Pavel Žid, Mikuláš Krupika, Vlastimil Havran</p><p>Abstract: In this paper we introduce unique publicly available dense anisotropic BRDF data measurements. We use this dense data as a reference for performance evaluation of the proposed BRDF sparse angular sampling and interpolation approach. The method is based on sampling of BRDF subspaces at fixed elevations by means of several adaptively-represented, uniformly distributed, perpendicular slices. Although this proposed method requires only a sparse sampling of material, the interpolation provides a very accurate reconstruction, visually and computationally comparable to densely measured reference. Due to the simple slices measurement and method’s robustness it allows for a highly accurate acquisition of BRDFs. This in comparison with standard uniform angular sampling, is considerably faster yet uses far less samples.</p><p>same-paper 2 0.90544361 <a title="13-lda-2" href="./cvpr-2013-A_Higher-Order_CRF_Model_for_Road_Network_Extraction.html">13 cvpr-2013-A Higher-Order CRF Model for Road Network Extraction</a></p>
<p>Author: Jan D. Wegner, Javier A. Montoya-Zegarra, Konrad Schindler</p><p>Abstract: The aim of this work is to extract the road network from aerial images. What makes the problem challenging is the complex structure of the prior: roads form a connected network of smooth, thin segments which meet at junctions and crossings. This type of a-priori knowledge is more difficult to turn into a tractable model than standard smoothness or co-occurrence assumptions. We develop a novel CRF formulation for road labeling, in which the prior is represented by higher-order cliques that connect sets of superpixels along straight line segments. These long-range cliques have asymmetric PN-potentials, which express a preference to assign all rather than just some of their constituent superpixels to the road class. Thus, the road likelihood is amplified for thin chains of superpixels, while the CRF is still amenable to optimization with graph cuts. Since the number of such cliques of arbitrary length is huge, we furthermorepropose a sampling scheme which concentrates on those cliques which are most relevant for the optimization. In experiments on two different databases the model significantly improves both the per-pixel accuracy and the topological correctness of the extracted roads, and outper- forms both a simple smoothness prior and heuristic rulebased road completion.</p><p>3 0.87575424 <a title="13-lda-3" href="./cvpr-2013-Learning_Discriminative_Illumination_and_Filters_for_Raw_Material_Classification_with_Optimal_Projections_of_Bidirectional_Texture_Functions.html">251 cvpr-2013-Learning Discriminative Illumination and Filters for Raw Material Classification with Optimal Projections of Bidirectional Texture Functions</a></p>
<p>Author: Chao Liu, Geifei Yang, Jinwei Gu</p><p>Abstract: We present a computational imaging method for raw material classification using features of Bidirectional Texture Functions (BTF). Texture is an intrinsic feature for many materials, such as wood, fabric, and granite. At appropriate scales, even “uniform” materials will also exhibit texture features that can be helpful for recognition, such as paper, metal, and ceramic. To cope with the high-dimensionality of BTFs, in this paper, we proposed to learn discriminative illumination patterns and texture filters, with which we can directly measure optimal projections of BTFs for classification. We also studied the effects of texture rotation and scale variation for material classification. We built an LED-based multispectral dome, with which we have acquired a BTF database of a variety of materials and demonstrated the effectiveness of the proposed approach for material classification.</p><p>4 0.86711848 <a title="13-lda-4" href="./cvpr-2013-Structure_Preserving_Object_Tracking.html">414 cvpr-2013-Structure Preserving Object Tracking</a></p>
<p>Author: Lu Zhang, Laurens van_der_Maaten</p><p>Abstract: Model-free trackers can track arbitrary objects based on a single (bounding-box) annotation of the object. Whilst the performance of model-free trackers has recently improved significantly, simultaneously tracking multiple objects with similar appearance remains very hard. In this paper, we propose a new multi-object model-free tracker (based on tracking-by-detection) that resolves this problem by incorporating spatial constraints between the objects. The spatial constraints are learned along with the object detectors using an online structured SVM algorithm. The experimental evaluation ofour structure-preserving object tracker (SPOT) reveals significant performance improvements in multi-object tracking. We also show that SPOT can improve the performance of single-object trackers by simultaneously tracking different parts of the object.</p><p>5 0.86604291 <a title="13-lda-5" href="./cvpr-2013-Exploring_Compositional_High_Order_Pattern_Potentials_for_Structured_Output_Learning.html">156 cvpr-2013-Exploring Compositional High Order Pattern Potentials for Structured Output Learning</a></p>
<p>Author: Yujia Li, Daniel Tarlow, Richard Zemel</p><p>Abstract: When modeling structured outputs such as image segmentations, prediction can be improved by accurately modeling structure present in the labels. A key challenge is developing tractable models that are able to capture complex high level structure like shape. In this work, we study the learning of a general class of pattern-like high order potential, which we call Compositional High Order Pattern Potentials (CHOPPs). We show that CHOPPs include the linear deviation pattern potentials of Rother et al. [26] and also Restricted Boltzmann Machines (RBMs); we also establish the near equivalence of these two models. Experimentally, we show that performance is affected significantly by the degree of variability present in the datasets, and we define a quantitative variability measure to aid in studying this. We then improve CHOPPs performance in high variability datasets with two primary contributions: (a) developing a loss-sensitive joint learning procedure, so that internal pattern parameters can be learned in conjunction with other model potentials to minimize expected loss;and (b) learning an image-dependent mapping that encourages or inhibits patterns depending on image features. We also explore varying how multiple patterns are composed, and learning convolutional patterns. Quantitative results on challenging highly variable datasets show that the joint learning and image-dependent high order potentials can improve performance.</p><p>6 0.85198641 <a title="13-lda-6" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<p>7 0.84833652 <a title="13-lda-7" href="./cvpr-2013-Label_Propagation_from_ImageNet_to_3D_Point_Clouds.html">242 cvpr-2013-Label Propagation from ImageNet to 3D Point Clouds</a></p>
<p>8 0.84824109 <a title="13-lda-8" href="./cvpr-2013-Cross-View_Action_Recognition_via_a_Continuous_Virtual_Path.html">98 cvpr-2013-Cross-View Action Recognition via a Continuous Virtual Path</a></p>
<p>9 0.84789723 <a title="13-lda-9" href="./cvpr-2013-Intrinsic_Scene_Properties_from_a_Single_RGB-D_Image.html">227 cvpr-2013-Intrinsic Scene Properties from a Single RGB-D Image</a></p>
<p>10 0.84708673 <a title="13-lda-10" href="./cvpr-2013-Efficient_Large-Scale_Structured_Learning.html">143 cvpr-2013-Efficient Large-Scale Structured Learning</a></p>
<p>11 0.84656423 <a title="13-lda-11" href="./cvpr-2013-Ensemble_Learning_for_Confidence_Measures_in_Stereo_Vision.html">147 cvpr-2013-Ensemble Learning for Confidence Measures in Stereo Vision</a></p>
<p>12 0.84638381 <a title="13-lda-12" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>13 0.8462494 <a title="13-lda-13" href="./cvpr-2013-Globally_Consistent_Multi-label_Assignment_on_the_Ray_Space_of_4D_Light_Fields.html">188 cvpr-2013-Globally Consistent Multi-label Assignment on the Ray Space of 4D Light Fields</a></p>
<p>14 0.84622908 <a title="13-lda-14" href="./cvpr-2013-Boundary_Cues_for_3D_Object_Shape_Recovery.html">71 cvpr-2013-Boundary Cues for 3D Object Shape Recovery</a></p>
<p>15 0.84605712 <a title="13-lda-15" href="./cvpr-2013-Shading-Based_Shape_Refinement_of_RGB-D_Images.html">394 cvpr-2013-Shading-Based Shape Refinement of RGB-D Images</a></p>
<p>16 0.84590191 <a title="13-lda-16" href="./cvpr-2013-Detection-_and_Trajectory-Level_Exclusion_in_Multiple_Object_Tracking.html">121 cvpr-2013-Detection- and Trajectory-Level Exclusion in Multiple Object Tracking</a></p>
<p>17 0.8454693 <a title="13-lda-17" href="./cvpr-2013-A_Minimum_Error_Vanishing_Point_Detection_Approach_for_Uncalibrated_Monocular_Images_of_Man-Made_Environments.html">19 cvpr-2013-A Minimum Error Vanishing Point Detection Approach for Uncalibrated Monocular Images of Man-Made Environments</a></p>
<p>18 0.84482288 <a title="13-lda-18" href="./cvpr-2013-Separating_Signal_from_Noise_Using_Patch_Recurrence_across_Scales.html">393 cvpr-2013-Separating Signal from Noise Using Patch Recurrence across Scales</a></p>
<p>19 0.8445937 <a title="13-lda-19" href="./cvpr-2013-Robust_Monocular_Epipolar_Flow_Estimation.html">362 cvpr-2013-Robust Monocular Epipolar Flow Estimation</a></p>
<p>20 0.84425879 <a title="13-lda-20" href="./cvpr-2013-Capturing_Layers_in_Image_Collections_with_Componential_Models%3A_From_the_Layered_Epitome_to_the_Componential_Counting_Grid.html">78 cvpr-2013-Capturing Layers in Image Collections with Componential Models: From the Layered Epitome to the Componential Counting Grid</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
