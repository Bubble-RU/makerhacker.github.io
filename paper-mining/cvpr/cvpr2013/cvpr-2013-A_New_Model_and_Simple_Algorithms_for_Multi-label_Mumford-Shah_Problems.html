<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>20 cvpr-2013-A New Model and Simple Algorithms for Multi-label Mumford-Shah Problems</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-20" href="#">cvpr2013-20</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>20 cvpr-2013-A New Model and Simple Algorithms for Multi-label Mumford-Shah Problems</h1>
<br/><p>Source: <a title="cvpr-2013-20-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Hong_A_New_Model_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Byung-Woo Hong, Zhaojin Lu, Ganesh Sundaramoorthi</p><p>Abstract: In this work, we address the multi-label Mumford-Shah problem, i.e., the problem of jointly estimating a partitioning of the domain of the image, and functions defined within regions of the partition. We create algorithms that are efficient, robust to undesirable local minima, and are easy-toimplement. Our algorithms are formulated by slightly modifying the underlying statistical model from which the multilabel Mumford-Shah functional is derived. The advantage of this statistical model is that the underlying variables: the labels and thefunctions are less coupled than in the original formulation, and the labels can be computed from the functions with more global updates. The resulting algorithms can be tuned to the desired level of locality of the solution: from fully global updates to more local updates. We demonstrate our algorithm on two applications: joint multi-label segmentation and denoising, and joint multi-label motion segmentation and flow estimation. We compare to the stateof-the-art in multi-label Mumford-Shah problems and show that we achieve more promising results.</p><p>Reference: <a title="cvpr-2013-20-reference" href="../cvpr2013_reference/cvpr-2013-A_New_Model_and_Simple_Algorithms_for_Multi-label_Mumford-Shah_Problems_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 A New Model and Simple Algorithms for Multi-Label Mumford-Shah Problems  Byung-Woo Hong Chung-Ang University hong@ cau . [sent-1, score-0.046]
</p><p>2 , the problem of jointly estimating a partitioning of the domain of the image, and functions defined within regions of the partition. [sent-5, score-0.362]
</p><p>3 We create algorithms that are efficient, robust to undesirable local minima, and are easy-toimplement. [sent-6, score-0.116]
</p><p>4 Our algorithms are formulated by slightly modifying the underlying statistical model from which the multilabel Mumford-Shah functional is derived. [sent-7, score-0.46]
</p><p>5 The advantage of this statistical model is that the underlying variables: the labels and thefunctions are less coupled than in the original formulation, and the labels can be computed from the functions with more global updates. [sent-8, score-0.42]
</p><p>6 The resulting algorithms can be tuned to the desired level of locality of the solution: from fully global updates to more local updates. [sent-9, score-0.349]
</p><p>7 We demonstrate our algorithm on two applications: joint multi-label segmentation and denoising, and joint multi-label motion segmentation and flow estimation. [sent-10, score-0.281]
</p><p>8 We compare to the stateof-the-art in multi-label Mumford-Shah problems and show that we achieve more promising results. [sent-11, score-0.051]
</p><p>9 Introduction Many problems in computer vision are formulated as Mumford-Shah problems, i. [sent-13, score-0.093]
</p><p>10 , joint estimation problems where two variables must be estimated from the image(s), each variable depending on the other. [sent-15, score-0.252]
</p><p>11 The estimate of one variable depends on the other, but both variables are unknown, and the estimation should be setup as a joint estimation problem where the variables are estimated simultaneously. [sent-17, score-0.241]
</p><p>12 Some other examples of joint estimation problems are segmentation and denoising [18, 20], 3D reconstruction [9], tomography [14], image registration [19], and optical flow [17]. [sent-18, score-0.443]
</p><p>13 In this paper, we address multi-label Mumford-Shah problems, in which labels (representing regions in the image) and functions must be estimated simultaneously. [sent-24, score-0.32]
</p><p>14 We wish to emphasize that our method applies to any multilabel Mumford-Shah problem, although our experiments are illustrated on joint segmentation and denoising, and motion segmentation. [sent-25, score-0.273]
</p><p>15 Our approach leads to a simple implementation, faster convergence, and a better estimation of the underlying variables, when compared to existing methods. [sent-26, score-0.161]
</p><p>16 Our method is less sensitive to initialization, and many times a random initialization is effective, making full automation a possibility, unlike existing methods which require hand initialization. [sent-27, score-0.076]
</p><p>17 Our approach is based on a slightly different underlying statistical model than the original Mumford-Shah problem; nevertheless, our model has the same generative capabilities as the original statistical model. [sent-28, score-0.249]
</p><p>18 The advantage is that the proposed model leads to a decoupling of the variables to be estimated, and therefore the optimization problem becomes simpler. [sent-29, score-0.122]
</p><p>19 Further, the modified statistical model leads to better and easier-to-implement optimization algorithms in which the user is able to choose the degree of locality of label updates (from fully global to fully local). [sent-30, score-0.422]
</p><p>20 Related Work  The original Mumford-Shah problem for joint edge detection and denoising was formulated in [12] (see also [2, 7]) and was setup as a variational problem. [sent-33, score-0.263]
</p><p>21 Multiple regions are considered in [20] approaches by using logical combinations of multiple level sets. [sent-35, score-0.105]
</p><p>22 While the methods of [20, 18] were ground breaking in providing a numerical solution, the methods are sensitive to initialization and are usually trapped in undesirable local minima, and the problem is exacerbated with an increasing number of regions. [sent-36, score-0.274]
</p><p>23 A more global approach to the two-label piecewise smooth Mumford-Shah functional has been considered in [8] using graph cuts [3] and it is shown to experimentally yield lower energy solutions and converge faster than [18]. [sent-37, score-0.461]
</p><p>24 Our work is based on the idea in [8] that one can provide better solutions to Mumford-Shah by looking at extensions of the functions into the entire domain of the image. [sent-38, score-0.181]
</p><p>25 We extend that work by first showing it comes from a different statistical model, and that the algorithm considered comes from an underlying energy that is being optimized. [sent-39, score-0.206]
</p><p>26 Further, we extend it to multiple labels, extend the algorithm to any  desired locality of the label updates, and our algorithm does not rely on graph cuts. [sent-40, score-0.126]
</p><p>27 In [5], a discrete approach to [20] (multiple phases and a piecewise constant model) is implemented using advanced discrete optimization techniques. [sent-41, score-0.06]
</p><p>28 Recently, convex optimization techniques have been applied to various problems in computer vision (e. [sent-43, score-0.092]
</p><p>29 , [10]), the original Mumford-Shah problem of edge-detection and image denoising is no exception. [sent-45, score-0.154]
</p><p>30 While the Mumford-Shah functional is not convex, one can consider a relaxation, and optimize the relaxed functional. [sent-46, score-0.25]
</p><p>31 This approach is considered by [15, 16] where the functional is lifted to a higher dimensional space. [sent-47, score-0.282]
</p><p>32 The method does not to apply to the case of multi-label piecewise smooth Mumford-Shah where a partitioning of the domain is desired. [sent-48, score-0.192]
</p><p>33 Mathematical Formulation The multi-label Mumford-Shah functional is in the form:  E({Ri,fi}iN=1) =i? [sent-50, score-0.202]
</p><p>34 RiD(I(x),fi(x))dx+ αReg(fi) + βLen(∂Ri) , (1) subject to the constraint that Ri are mutually exclusive and the union is the entire domain Ω of the image. [sent-52, score-0.056]
</p><p>35 Here I Ω → Rk is the image (with k-channels), fi : Ri → Rk : are approximations of the image in the regions Ri, ∂R→i dRe-  notes the boundary of Ri. [sent-53, score-0.551]
</p><p>36 , D(I(x) , fi(x)) = |I(x) − fi (x) for the original Mumford-Shah problem), R|Ie(gx()·) − −w fill( impose spatial regularity of fi in the region Ri, one possible mchpooiscee sisp  |2  Reg(fi) =? [sent-56, score-1.072]
</p><p>37 Results of segmentation and reconstruction by our method and the multiphase Mumford-Shah level sets method. [sent-58, score-0.203]
</p><p>38 Even on the simple two-label case, the classical Mumford-Shah functional has many local minima. [sent-59, score-0.202]
</p><p>39 [top] same input image (left 4 images) and different initializations (right 4 images). [sent-60, score-0.059]
</p><p>40 [middle] reconstruction (left 4 images) and segmentation (right 4 images) by the proposed method with the 4 different initializations given above. [sent-61, score-0.158]
</p><p>41 [bottom] reconstruction (left 4 images) and segmentation (right 4 images) by the multiphase Mumford-Shah level sets method with the 4 different initialization given above. [sent-62, score-0.279]
</p><p>42 e spatial regularity do tfh teh lee region eRnai t(syin Lceen L(·e)n( is∂ tRoi e) =su ? [sent-65, score-0.258]
</p><p>43 , fi and Ri are infinite dimensional) and the non-convexity of the space of variables on which the functional is defined implies that the energy has many local minima. [sent-73, score-0.833]
</p><p>44 For example, Figure 1 shows that even in the case of simple synthetic images, the Mumford-Shah functional has many local minima. [sent-74, score-0.202]
</p><p>45 The reason that these problems are difficult to optimize is due to the dependence of each of the variables in the optimization on the other. [sent-75, score-0.266]
</p><p>46 Indeed, to define a function fi, the region Ri must be known, but the region Ri is unknown. [sent-76, score-0.227]
</p><p>47 , the image reconstruction), then the discontinuities form the boundaries of the regions, and the regions can be defined, however the functions are unknown. [sent-79, score-0.23]
</p><p>48 Hence, there is a constraint that must be maintained between the function and the regions. [sent-80, score-0.047]
</p><p>49 Generative Model We wish to undue the dependence of the functions on the regions by considering a different underlying model for image formation. [sent-83, score-0.476]
</p><p>50 We illustrate the idea on the joint image  denoising and segmentation problem, but it can be generalized in other Mumford-Shah (MS) problems. [sent-84, score-0.277]
</p><p>51 The underlying model in the original MS denoising/segmentation problem is  + η(x), x ∈ Ri, fi : Ri → Rk p(fi|Ri) ∝ exp? [sent-85, score-0.494]
</p><p>52 I(x) = fi(x)  (3) (4)  1 1 12 2 21 12 80 8  where η is a noise process, and the probability is the conditional prior probability of the function fi. [sent-88, score-0.065]
</p><p>53 The generative model implies that the regions Ri must be first chosen according to a prior distribution, and the functions may then be chosen according to a conditional distribution (conditioned on the region). [sent-89, score-0.464]
</p><p>54 In the proposed formulation, we wish to remove this conditional dependence, while still maintaining the ability to generate all the images that the original model can generate. [sent-90, score-0.144]
</p><p>55 Our model is the following: I(x) = fi(x) + η(x), x p(fi)  ∝ exp  ∈  Ri, fi : Ω → Rk  ? [sent-91, score-0.407]
</p><p>56 (5) (6)  where we have defined the functions on the entire domain Ω (and defined the regularity on Ω) rather than Ri, and therefore, the prior probability of the functions is no longer conditional on the regions. [sent-94, score-0.539]
</p><p>57 Hence to generate the image, the  sampling of the regions and functions are done independently. [sent-95, score-0.23]
</p><p>58 The benefit of the proposed model is that in optimization, the regions can be updated more globally than in the original model. [sent-96, score-0.105]
</p><p>59 However, the proposed formulation leads to a better local optimum, and is even faster to converge than the traditional model as we show in experiments. [sent-98, score-0.109]
</p><p>60 Optimization Algorithm The proposed model leads to the following regularity term in the energy:  Reg(fi) =? [sent-101, score-0.203]
</p><p>61 Ω|∇fi(x)|2dx  (7)  rather than (2), and the other terms in the energy (1) remain the same:  E({Ri,fi}iN=1) =i? [sent-102, score-0.061]
</p><p>62 Ω|∇fi(x)|2dx + βLen(∂Ri)  (8)  Since the conditional dependence of the function on the region is now removed, the update of the regions can be computed given the functions in a more global fashion, and the optimal update of the functions can be computed given the regions. [sent-105, score-0.778]
</p><p>63 , [10]) techniques can be  applied, but we wish to apply a simpler method (with global updates) to ensure easy implementation. [sent-108, score-0.143]
</p><p>64 Given estimates of the functions fi : Ω → Rk, we describe how to obtain optimal estimates :fo Ωr t →he regions Ri. [sent-109, score-0.721]
</p><p>65 Notice that, unlike the standard model, when optimizing in Ri for a fixed fi, the second term in (8) can be ignored as it does not depend on the region. [sent-110, score-0.062]
</p><p>66 For the moment, setting β = 0, the globally optimal estimate is (given the functions fi are fixed) is  Ri= {x : i = argjminD(I(x),fj(x))}. [sent-111, score-0.532]
</p><p>67 (9)  The above optimum does not take into account the length term that implies spatial regularity of the regions, and thus we show how to integrate that next. [sent-112, score-0.344]
</p><p>68 We first approximate the length term with the following region integral:  ? [sent-113, score-0.131]
</p><p>69 RiWRi(x)dx, where WRi(x) =σ1(Gσ∗1Ric)(x),  (10)  where Gσ indicates a Gaussian smoothing kernel of standard deviation σ, and 1Rci is the indicator function on Ric. [sent-114, score-0.051]
</p><p>70 It can be shown from the co-area formula and the Lebesgue differentiation theorem that the integral above converges to the length as σ → 0. [sent-115, score-0.11]
</p><p>71 (11)  Note that we like to apply the same argument as before, and write the optimal solution as a simple thresholding step as in (9); however, part of the integrand depends on the region Ri (when β 0), which is unknown. [sent-119, score-0.133]
</p><p>72 i , and optimizing (11) with respect to Ri yields  =  Ri= {x : i = argjminD(I(x),fj(x)) + βWRj? [sent-122, score-0.062]
</p><p>73 (12) Notice this requires two parameters, β and σ; if desired to avoid an additional parameter, one can get similar results by simply replacing D(I(x) , fj (x)) + βWRj? [sent-124, score-0.209]
</p><p>74 The equation (12) can then be iterated with the previous estimate replacing Ri? [sent-132, score-0.038]
</p><p>75 re Ads i nσ [ →1 →1] 0a anndd approximates mean ceu srcvhaetumree flow as shown in [1, 6], and thus minimizes the length of the boundary of the regions. [sent-136, score-0.238]
</p><p>76 In our numerical scheme, we consider a fixed σ and only one iteration, the effects of a large number of iterations are attained by a larger σ. [sent-137, score-0.036]
</p><p>77 Also, given that regions Ri are fixed, we can compute a global minimum for the fi (in the case of a convex D). [sent-138, score-0.617]
</p><p>78 For the case that D(x, y) = |x − y|2, we have that − αΔfi (x) = (I(x) − fi (x)) 1Ri (x) . [sent-139, score-0.407]
</p><p>79 −∂∂NfαiΔ=f0i (x) = (I(x) − fi(x) 1Ri(x) x ∈ int(Ω) where N denotes the normal to the boundary (Neumann boundary ecosn tdheiti onnosrm), aanld to oin tth(e·) dboenuontdeasr iynt (eNrieour-. [sent-143, score-0.078]
</p><p>80 Update Ri:  Ri= {x ∈ Ω : i = argjminFj(x)}, where Fj (x) = |I(x) − fj (x) |2 + βWRj? [sent-149, score-0.115]
</p><p>81 From Global to More Local Updates In the previous section, we have derived a more global optimization algorithm than traditional local approaches for optimizing Mumford-Shah-type problems. [sent-153, score-0.126]
</p><p>82 Our approach is not a fully global method, however, each update of the regions approximates a global optimum of the energy conditioned on the functions, and each update ofthe functions is a global optimizer conditioned on the regions. [sent-154, score-0.896]
</p><p>83 In many cases, a global approach yields undesirable estimates that capture undesired clutter (see Fig. [sent-155, score-0.257]
</p><p>84 A local approach is less affected by clutter if the initialization is close to the desired solution, but is susceptible to local features (e. [sent-157, score-0.167]
</p><p>85 In this section, we show that the algorithm derived in the previous section can be generalized to an algorithm that is a trade-off between the global updates and local updates of traditional methods, yielding advantages of both. [sent-160, score-0.31]
</p><p>86 Suppose first that one has an initial estimate of the labels to be determined. [sent-161, score-0.043]
</p><p>87 Our global update of the regions given the current functions implies that a pixel far from a region can change to the same label as the far region. [sent-162, score-0.522]
</p><p>88 In contrast, in local approaches, only pixels in one region that border another region may switch to the bordering region. [sent-163, score-0.319]
</p><p>89 The simple intuition above can be formalized mathematically as follows. [sent-165, score-0.037]
</p><p>90 Define a band of a region Ri as follows:  local tradeoff algorithm for optimizing the multi-label MumfordShah-type problem. [sent-166, score-0.152]
</p><p>91 The regions Ri with different labels are represented in solid colors and bands Bε (Ri) are represented by the dashed lines. [sent-167, score-0.184]
</p><p>92 pi is allowed to transition to Rj if pi ∈ Bε (Rj ) (p1 can to transition to R3, p2 to R3, and p3 to R1 or R2). [sent-168, score-0.08]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ri', 0.462), ('fi', 0.407), ('functional', 0.202), ('regularity', 0.168), ('wrj', 0.156), ('denoising', 0.154), ('wri', 0.138), ('reg', 0.128), ('functions', 0.125), ('updates', 0.123), ('undesirable', 0.116), ('fj', 0.115), ('len', 0.11), ('regions', 0.105), ('argjmind', 0.104), ('kaust', 0.104), ('multiphase', 0.104), ('rk', 0.094), ('switch', 0.093), ('region', 0.09), ('variables', 0.087), ('underlying', 0.087), ('dri', 0.08), ('dependence', 0.08), ('wish', 0.079), ('conditioned', 0.077), ('initialization', 0.076), ('implies', 0.076), ('partitioning', 0.076), ('rid', 0.071), ('multilabel', 0.071), ('locality', 0.07), ('joint', 0.067), ('denoised', 0.065), ('conditional', 0.065), ('global', 0.064), ('optimizing', 0.062), ('update', 0.062), ('energy', 0.061), ('piecewise', 0.06), ('initializations', 0.059), ('optimum', 0.059), ('dx', 0.059), ('statistical', 0.058), ('segmentation', 0.056), ('desired', 0.056), ('domain', 0.056), ('ganesh', 0.053), ('problems', 0.051), ('smoothing', 0.051), ('rj', 0.05), ('hong', 0.049), ('optimize', 0.048), ('must', 0.047), ('minima', 0.046), ('ceu', 0.046), ('bordering', 0.046), ('cau', 0.046), ('exacerbated', 0.046), ('tmhaen', 0.046), ('generative', 0.046), ('dimensional', 0.044), ('edges', 0.044), ('labels', 0.043), ('destroy', 0.043), ('fte', 0.043), ('integrand', 0.043), ('lock', 0.043), ('mumford', 0.043), ('neumann', 0.043), ('reconstruction', 0.043), ('formulated', 0.042), ('estimates', 0.042), ('length', 0.041), ('convex', 0.041), ('approximates', 0.04), ('possibility', 0.04), ('transition', 0.04), ('boundary', 0.039), ('faster', 0.039), ('xdi', 0.038), ('argjmin', 0.038), ('replacing', 0.038), ('ms', 0.037), ('anndd', 0.037), ('formalized', 0.037), ('king', 0.037), ('tomography', 0.037), ('fully', 0.036), ('numerical', 0.036), ('lifted', 0.036), ('bands', 0.036), ('func', 0.036), ('converge', 0.035), ('clutter', 0.035), ('leads', 0.035), ('flow', 0.035), ('converges', 0.035), ('integral', 0.034), ('year', 0.034)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="20-tfidf-1" href="./cvpr-2013-A_New_Model_and_Simple_Algorithms_for_Multi-label_Mumford-Shah_Problems.html">20 cvpr-2013-A New Model and Simple Algorithms for Multi-label Mumford-Shah Problems</a></p>
<p>Author: Byung-Woo Hong, Zhaojin Lu, Ganesh Sundaramoorthi</p><p>Abstract: In this work, we address the multi-label Mumford-Shah problem, i.e., the problem of jointly estimating a partitioning of the domain of the image, and functions defined within regions of the partition. We create algorithms that are efficient, robust to undesirable local minima, and are easy-toimplement. Our algorithms are formulated by slightly modifying the underlying statistical model from which the multilabel Mumford-Shah functional is derived. The advantage of this statistical model is that the underlying variables: the labels and thefunctions are less coupled than in the original formulation, and the labels can be computed from the functions with more global updates. The resulting algorithms can be tuned to the desired level of locality of the solution: from fully global updates to more local updates. We demonstrate our algorithm on two applications: joint multi-label segmentation and denoising, and joint multi-label motion segmentation and flow estimation. We compare to the stateof-the-art in multi-label Mumford-Shah problems and show that we achieve more promising results.</p><p>2 0.15915136 <a title="20-tfidf-2" href="./cvpr-2013-Optimal_Geometric_Fitting_under_the_Truncated_L2-Norm.html">317 cvpr-2013-Optimal Geometric Fitting under the Truncated L2-Norm</a></p>
<p>Author: Erik Ask, Olof Enqvist, Fredrik Kahl</p><p>Abstract: This paper is concerned with model fitting in the presence of noise and outliers. Previously it has been shown that the number of outliers can be minimized with polynomial complexity in the number of measurements. This paper improves on these results in two ways. First, it is shown that for a large class of problems, the statistically more desirable truncated L2-norm can be optimized with the same complexity. Then, with the same methodology, it is shown how to transform multi-model fitting into a purely combinatorial problem—with worst-case complexity that is polynomial in the number of measurements, though exponential in the number of models. We apply our framework to a series of hard registration and stitching problems demonstrating that the approach is not only of theoretical interest. It gives a practical method for simultaneously dealing with measurement noise and large amounts of outliers for fitting problems with lowdimensional models.</p><p>3 0.1458046 <a title="20-tfidf-3" href="./cvpr-2013-Scene_Parsing_by_Integrating_Function%2C_Geometry_and_Appearance_Models.html">381 cvpr-2013-Scene Parsing by Integrating Function, Geometry and Appearance Models</a></p>
<p>Author: Yibiao Zhao, Song-Chun Zhu</p><p>Abstract: Indoor functional objects exhibit large view and appearance variations, thus are difficult to be recognized by the traditional appearance-based classification paradigm. In this paper, we present an algorithm to parse indoor images based on two observations: i) The functionality is the most essentialproperty to define an indoor object, e.g. “a chair to sit on ”; ii) The geometry (3D shape) ofan object is designed to serve its function. We formulate the nature of the object function into a stochastic grammar model. This model characterizes a joint distribution over the function-geometryappearance (FGA) hierarchy. The hierarchical structure includes a scene category, , functional groups, , functional objects, functional parts and 3D geometric shapes. We use a simulated annealing MCMC algorithm to find the maximum a posteriori (MAP) solution, i.e. a parse tree. We design four data-driven steps to accelerate the search in the FGA space: i) group the line segments into 3D primitive shapes, ii) assign functional labels to these 3D primitive shapes, iii) fill in missing objects/parts according to the functional labels, and iv) synthesize 2D segmentation maps and verify the current parse tree by the Metropolis-Hastings acceptance probability. The experimental results on several challenging indoor datasets demonstrate theproposed approach not only significantly widens the scope ofindoor sceneparsing algorithm from the segmentation and the 3D recovery to the functional object recognition, but also yields improved overall performance.</p><p>4 0.11548999 <a title="20-tfidf-4" href="./cvpr-2013-Learning_to_Detect_Partially_Overlapping_Instances.html">264 cvpr-2013-Learning to Detect Partially Overlapping Instances</a></p>
<p>Author: Carlos Arteta, Victor Lempitsky, J. Alison Noble, Andrew Zisserman</p><p>Abstract: The objective of this work is to detect all instances of a class (such as cells or people) in an image. The instances may be partially overlapping and clustered, and hence quite challenging for traditional detectors, which aim at localizing individual instances. Our approach is to propose a set of candidate regions, and then select regions based on optimizing a global classification score, subject to the constraint that the selected regions are non-overlapping. Our novel contribution is to extend standard object detection by introducing separate classes for tuples of objects into the detection process. For example, our detector can pick a region containing two or three object instances, while assigning such region an appropriate label. We show that this formulation can be learned within the structured output SVM framework, and that the inference in such model can be accomplished using dynamic programming on a tree structured region graph. Furthermore, the learning only requires weak annotations – a dot on each instance. The improvement resulting from the addition of the capability to detect tuples of objects is demonstrated on quite disparate data sets: fluorescence microscopy images and UCSD pedestrians.</p><p>5 0.10965621 <a title="20-tfidf-5" href="./cvpr-2013-Sparse_Subspace_Denoising_for_Image_Manifolds.html">405 cvpr-2013-Sparse Subspace Denoising for Image Manifolds</a></p>
<p>Author: Bo Wang, Zhuowen Tu</p><p>Abstract: With the increasing availability of high dimensional data and demand in sophisticated data analysis algorithms, manifold learning becomes a critical technique to perform dimensionality reduction, unraveling the intrinsic data structure. The real-world data however often come with noises and outliers; seldom, all the data live in a single linear subspace. Inspired by the recent advances in sparse subspace learning and diffusion-based approaches, we propose a new manifold denoising algorithm in which data neighborhoods are adaptively inferred via sparse subspace reconstruction; we then derive a new formulation to perform denoising to the original data. Experiments carried out on both toy and real applications demonstrate the effectiveness of our method; it is insensitive to parameter tuning and we show significant improvement over the competing algorithms.</p><p>6 0.099264555 <a title="20-tfidf-6" href="./cvpr-2013-Fully-Connected_CRFs_with_Non-Parametric_Pairwise_Potential.html">180 cvpr-2013-Fully-Connected CRFs with Non-Parametric Pairwise Potential</a></p>
<p>7 0.097371399 <a title="20-tfidf-7" href="./cvpr-2013-Texture_Enhanced_Image_Denoising_via_Gradient_Histogram_Preservation.html">427 cvpr-2013-Texture Enhanced Image Denoising via Gradient Histogram Preservation</a></p>
<p>8 0.093731649 <a title="20-tfidf-8" href="./cvpr-2013-Submodular_Salient_Region_Detection.html">418 cvpr-2013-Submodular Salient Region Detection</a></p>
<p>9 0.093117699 <a title="20-tfidf-9" href="./cvpr-2013-A_Fast_Approximate_AIB_Algorithm_for_Distributional_Word_Clustering.html">8 cvpr-2013-A Fast Approximate AIB Algorithm for Distributional Word Clustering</a></p>
<p>10 0.090215124 <a title="20-tfidf-10" href="./cvpr-2013-Hypergraphs_for_Joint_Multi-view_Reconstruction_and_Multi-object_Tracking.html">209 cvpr-2013-Hypergraphs for Joint Multi-view Reconstruction and Multi-object Tracking</a></p>
<p>11 0.090001531 <a title="20-tfidf-11" href="./cvpr-2013-Auxiliary_Cuts_for_General_Classes_of_Higher_Order_Functionals.html">51 cvpr-2013-Auxiliary Cuts for General Classes of Higher Order Functionals</a></p>
<p>12 0.080239691 <a title="20-tfidf-12" href="./cvpr-2013-SCaLE%3A_Supervised_and_Cascaded_Laplacian_Eigenmaps_for_Visual_Object_Recognition_Based_on_Nearest_Neighbors.html">371 cvpr-2013-SCaLE: Supervised and Cascaded Laplacian Eigenmaps for Visual Object Recognition Based on Nearest Neighbors</a></p>
<p>13 0.0787559 <a title="20-tfidf-13" href="./cvpr-2013-Continuous_Inference_in_Graphical_Models_with_Polynomial_Energies.html">95 cvpr-2013-Continuous Inference in Graphical Models with Polynomial Energies</a></p>
<p>14 0.078491122 <a title="20-tfidf-14" href="./cvpr-2013-Efficient_2D-to-3D_Correspondence_Filtering_for_Scalable_3D_Object_Recognition.html">138 cvpr-2013-Efficient 2D-to-3D Correspondence Filtering for Scalable 3D Object Recognition</a></p>
<p>15 0.075337008 <a title="20-tfidf-15" href="./cvpr-2013-Procrustean_Normal_Distribution_for_Non-rigid_Structure_from_Motion.html">341 cvpr-2013-Procrustean Normal Distribution for Non-rigid Structure from Motion</a></p>
<p>16 0.07252422 <a title="20-tfidf-16" href="./cvpr-2013-Simultaneous_Super-Resolution_of_Depth_and_Images_Using_a_Single_Camera.html">397 cvpr-2013-Simultaneous Super-Resolution of Depth and Images Using a Single Camera</a></p>
<p>17 0.071447425 <a title="20-tfidf-17" href="./cvpr-2013-An_Iterated_L1_Algorithm_for_Non-smooth_Non-convex_Optimization_in_Computer_Vision.html">41 cvpr-2013-An Iterated L1 Algorithm for Non-smooth Non-convex Optimization in Computer Vision</a></p>
<p>18 0.070702367 <a title="20-tfidf-18" href="./cvpr-2013-Hierarchical_Saliency_Detection.html">202 cvpr-2013-Hierarchical Saliency Detection</a></p>
<p>19 0.070090786 <a title="20-tfidf-19" href="./cvpr-2013-Pose_from_Flow_and_Flow_from_Pose.html">334 cvpr-2013-Pose from Flow and Flow from Pose</a></p>
<p>20 0.067170091 <a title="20-tfidf-20" href="./cvpr-2013-Fast_Patch-Based_Denoising_Using_Approximated_Patch_Geodesic_Paths.html">169 cvpr-2013-Fast Patch-Based Denoising Using Approximated Patch Geodesic Paths</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.169), (1, 0.055), (2, 0.01), (3, 0.046), (4, 0.041), (5, 0.014), (6, 0.03), (7, -0.036), (8, -0.053), (9, 0.005), (10, 0.072), (11, 0.045), (12, -0.063), (13, -0.038), (14, -0.016), (15, 0.007), (16, -0.016), (17, -0.005), (18, 0.088), (19, 0.039), (20, 0.005), (21, 0.017), (22, -0.049), (23, -0.04), (24, 0.085), (25, -0.012), (26, -0.035), (27, -0.034), (28, 0.051), (29, -0.037), (30, 0.049), (31, 0.045), (32, -0.003), (33, 0.019), (34, -0.052), (35, -0.062), (36, 0.029), (37, 0.058), (38, -0.013), (39, -0.044), (40, -0.072), (41, -0.051), (42, 0.058), (43, -0.117), (44, 0.009), (45, 0.114), (46, 0.079), (47, 0.026), (48, 0.078), (49, -0.006)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96291512 <a title="20-lsi-1" href="./cvpr-2013-A_New_Model_and_Simple_Algorithms_for_Multi-label_Mumford-Shah_Problems.html">20 cvpr-2013-A New Model and Simple Algorithms for Multi-label Mumford-Shah Problems</a></p>
<p>Author: Byung-Woo Hong, Zhaojin Lu, Ganesh Sundaramoorthi</p><p>Abstract: In this work, we address the multi-label Mumford-Shah problem, i.e., the problem of jointly estimating a partitioning of the domain of the image, and functions defined within regions of the partition. We create algorithms that are efficient, robust to undesirable local minima, and are easy-toimplement. Our algorithms are formulated by slightly modifying the underlying statistical model from which the multilabel Mumford-Shah functional is derived. The advantage of this statistical model is that the underlying variables: the labels and thefunctions are less coupled than in the original formulation, and the labels can be computed from the functions with more global updates. The resulting algorithms can be tuned to the desired level of locality of the solution: from fully global updates to more local updates. We demonstrate our algorithm on two applications: joint multi-label segmentation and denoising, and joint multi-label motion segmentation and flow estimation. We compare to the stateof-the-art in multi-label Mumford-Shah problems and show that we achieve more promising results.</p><p>2 0.75553346 <a title="20-lsi-2" href="./cvpr-2013-Optimal_Geometric_Fitting_under_the_Truncated_L2-Norm.html">317 cvpr-2013-Optimal Geometric Fitting under the Truncated L2-Norm</a></p>
<p>Author: Erik Ask, Olof Enqvist, Fredrik Kahl</p><p>Abstract: This paper is concerned with model fitting in the presence of noise and outliers. Previously it has been shown that the number of outliers can be minimized with polynomial complexity in the number of measurements. This paper improves on these results in two ways. First, it is shown that for a large class of problems, the statistically more desirable truncated L2-norm can be optimized with the same complexity. Then, with the same methodology, it is shown how to transform multi-model fitting into a purely combinatorial problem—with worst-case complexity that is polynomial in the number of measurements, though exponential in the number of models. We apply our framework to a series of hard registration and stitching problems demonstrating that the approach is not only of theoretical interest. It gives a practical method for simultaneously dealing with measurement noise and large amounts of outliers for fitting problems with lowdimensional models.</p><p>3 0.72130597 <a title="20-lsi-3" href="./cvpr-2013-Auxiliary_Cuts_for_General_Classes_of_Higher_Order_Functionals.html">51 cvpr-2013-Auxiliary Cuts for General Classes of Higher Order Functionals</a></p>
<p>Author: Ismail Ben Ayed, Lena Gorelick, Yuri Boykov</p><p>Abstract: Several recent studies demonstrated that higher order (non-linear) functionals can yield outstanding performances in the contexts of segmentation, co-segmentation and tracking. In general, higher order functionals result in difficult problems that are not amenable to standard optimizers, and most of the existing works investigated particular forms of such functionals. In this study, we derive general bounds for a broad class of higher order functionals. By introducing auxiliary variables and invoking the Jensen ’s inequality as well as some convexity arguments, we prove that these bounds are auxiliary functionals for various non-linear terms, which include but are not limited to several affinity measures on the distributions or moments of segment appearance and shape, as well as soft constraints on segment volume. From these general-form bounds, we state various non-linear problems as the optimization of auxiliary functionals by graph cuts. The proposed bound optimizers are derivative-free, and consistently yield very steep functional decreases, thereby converging within a few graph cuts. We report several experiments on color and medical data, along with quantitative comparisons to stateof-the-art methods. The results demonstrate competitive performances of the proposed algorithms in regard to accuracy and convergence speed, and confirm their potential in various vision and medical applications.</p><p>4 0.65361911 <a title="20-lsi-4" href="./cvpr-2013-Fast_Trust_Region_for_Segmentation.html">171 cvpr-2013-Fast Trust Region for Segmentation</a></p>
<p>Author: Lena Gorelick, Frank R. Schmidt, Yuri Boykov</p><p>Abstract: Trust region is a well-known general iterative approach to optimization which offers many advantages over standard gradient descent techniques. In particular, it allows more accurate nonlinear approximation models. In each iteration this approach computes a global optimum of a suitable approximation model within a fixed radius around the current solution, a.k.a. trust region. In general, this approach can be used only when some efficient constrained optimization algorithm is available for the selected nonlinear (more accurate) approximation model. In this paper we propose a Fast Trust Region (FTR) approach for optimization of segmentation energies with nonlinear regional terms, which are known to be challenging for existing algorithms. These energies include, but are not limited to, KL divergence and Bhattacharyya distance between the observed and the target appearance distributions, volume constraint on segment size, and shape prior constraint in a form of 퐿2 distance from target shape moments. Our method is 1-2 orders of magnitude faster than the existing state-of-the-art methods while converging to comparable or better solutions.</p><p>5 0.64018446 <a title="20-lsi-5" href="./cvpr-2013-A_Practical_Rank-Constrained_Eight-Point_Algorithm_for_Fundamental_Matrix_Estimation.html">23 cvpr-2013-A Practical Rank-Constrained Eight-Point Algorithm for Fundamental Matrix Estimation</a></p>
<p>Author: Yinqiang Zheng, Shigeki Sugimoto, Masatoshi Okutomi</p><p>Abstract: Due to its simplicity, the eight-point algorithm has been widely used in fundamental matrix estimation. Unfortunately, the rank-2 constraint of a fundamental matrix is enforced via a posterior rank correction step, thus leading to non-optimal solutions to the original problem. To address this drawback, existing algorithms need to solve either a very high order polynomial or a sequence of convex relaxation problems, both of which are computationally ineffective and numerically unstable. In this work, we present a new rank-2 constrained eight-point algorithm, which directly incorporates the rank-2 constraint in the minimization process. To avoid singularities, we propose to solve seven subproblems and retrieve their globally optimal solutions by using tailored polynomial system solvers. Our proposed method is noniterative, computationally efficient and numerically stable. Experiment results have verified its superiority over existing algebraic error based algorithms in terms of accuracy, as well as its advantages when used to initialize geometric error based algorithms.</p><p>6 0.63210785 <a title="20-lsi-6" href="./cvpr-2013-Nonlinearly_Constrained_MRFs%3A_Exploring_the_Intrinsic_Dimensions_of_Higher-Order_Cliques.html">308 cvpr-2013-Nonlinearly Constrained MRFs: Exploring the Intrinsic Dimensions of Higher-Order Cliques</a></p>
<p>7 0.62395507 <a title="20-lsi-7" href="./cvpr-2013-An_Iterated_L1_Algorithm_for_Non-smooth_Non-convex_Optimization_in_Computer_Vision.html">41 cvpr-2013-An Iterated L1 Algorithm for Non-smooth Non-convex Optimization in Computer Vision</a></p>
<p>8 0.60603917 <a title="20-lsi-8" href="./cvpr-2013-Continuous_Inference_in_Graphical_Models_with_Polynomial_Energies.html">95 cvpr-2013-Continuous Inference in Graphical Models with Polynomial Energies</a></p>
<p>9 0.60565841 <a title="20-lsi-9" href="./cvpr-2013-Universality_of_the_Local_Marginal_Polytope.html">448 cvpr-2013-Universality of the Local Marginal Polytope</a></p>
<p>10 0.5971393 <a title="20-lsi-10" href="./cvpr-2013-Efficient_3D_Endfiring_TRUS_Prostate_Segmentation_with_Globally_Optimized_Rotational_Symmetry.html">139 cvpr-2013-Efficient 3D Endfiring TRUS Prostate Segmentation with Globally Optimized Rotational Symmetry</a></p>
<p>11 0.59428209 <a title="20-lsi-11" href="./cvpr-2013-A_Fast_Semidefinite_Approach_to_Solving_Binary_Quadratic_Problems.html">9 cvpr-2013-A Fast Semidefinite Approach to Solving Binary Quadratic Problems</a></p>
<p>12 0.59157246 <a title="20-lsi-12" href="./cvpr-2013-Towards_Efficient_and_Exact_MAP-Inference_for_Large_Scale_Discrete_Computer_Vision_Problems_via_Combinatorial_Optimization.html">436 cvpr-2013-Towards Efficient and Exact MAP-Inference for Large Scale Discrete Computer Vision Problems via Combinatorial Optimization</a></p>
<p>13 0.57483 <a title="20-lsi-13" href="./cvpr-2013-A_Comparative_Study_of_Modern_Inference_Techniques_for_Discrete_Energy_Minimization_Problems.html">6 cvpr-2013-A Comparative Study of Modern Inference Techniques for Discrete Energy Minimization Problems</a></p>
<p>14 0.56108391 <a title="20-lsi-14" href="./cvpr-2013-Discrete_MRF_Inference_of_Marginal_Densities_for_Non-uniformly_Discretized_Variable_Space.html">128 cvpr-2013-Discrete MRF Inference of Marginal Densities for Non-uniformly Discretized Variable Space</a></p>
<p>15 0.53594023 <a title="20-lsi-15" href="./cvpr-2013-Texture_Enhanced_Image_Denoising_via_Gradient_Histogram_Preservation.html">427 cvpr-2013-Texture Enhanced Image Denoising via Gradient Histogram Preservation</a></p>
<p>16 0.53276175 <a title="20-lsi-16" href="./cvpr-2013-Learning_for_Structured_Prediction_Using_Approximate_Subgradient_Descent_with_Working_Sets.html">262 cvpr-2013-Learning for Structured Prediction Using Approximate Subgradient Descent with Working Sets</a></p>
<p>17 0.53260815 <a title="20-lsi-17" href="./cvpr-2013-Prostate_Segmentation_in_CT_Images_via_Spatial-Constrained_Transductive_Lasso.html">342 cvpr-2013-Prostate Segmentation in CT Images via Spatial-Constrained Transductive Lasso</a></p>
<p>18 0.52539587 <a title="20-lsi-18" href="./cvpr-2013-The_Generalized_Laplacian_Distance_and_Its_Applications_for_Visual_Matching.html">429 cvpr-2013-The Generalized Laplacian Distance and Its Applications for Visual Matching</a></p>
<p>19 0.5228433 <a title="20-lsi-19" href="./cvpr-2013-A_Fast_Approximate_AIB_Algorithm_for_Distributional_Word_Clustering.html">8 cvpr-2013-A Fast Approximate AIB Algorithm for Distributional Word Clustering</a></p>
<p>20 0.49738652 <a title="20-lsi-20" href="./cvpr-2013-Learning_to_Detect_Partially_Overlapping_Instances.html">264 cvpr-2013-Learning to Detect Partially Overlapping Instances</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.139), (16, 0.021), (26, 0.105), (33, 0.348), (67, 0.037), (69, 0.041), (71, 0.141), (87, 0.09)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.96419787 <a title="20-lda-1" href="./cvpr-2013-Selective_Transfer_Machine_for_Personalized_Facial_Action_Unit_Detection.html">385 cvpr-2013-Selective Transfer Machine for Personalized Facial Action Unit Detection</a></p>
<p>Author: Wen-Sheng Chu, Fernando De La Torre, Jeffery F. Cohn</p><p>Abstract: Automatic facial action unit (AFA) detection from video is a long-standing problem in facial expression analysis. Most approaches emphasize choices of features and classifiers. They neglect individual differences in target persons. People vary markedly in facial morphology (e.g., heavy versus delicate brows, smooth versus deeply etched wrinkles) and behavior. Individual differences can dramatically influence how well generic classifiers generalize to previously unseen persons. While a possible solution would be to train person-specific classifiers, that often is neither feasible nor theoretically compelling. The alternative that we propose is to personalize a generic classifier in an unsupervised manner (no additional labels for the test subjects are required). We introduce a transductive learning method, which we refer to Selective Transfer Machine (STM), to personalize a generic classifier by attenuating person-specific biases. STM achieves this effect by simultaneously learning a classifier and re-weighting the training samples that are most relevant to the test subject. To evaluate the effectiveness of STM, we compared STM to generic classifiers and to cross-domain learning methods in three major databases: CK+ [20], GEMEP-FERA [32] and RU-FACS [2]. STM outperformed generic classifiers in all.</p><p>2 0.95604134 <a title="20-lda-2" href="./cvpr-2013-Universality_of_the_Local_Marginal_Polytope.html">448 cvpr-2013-Universality of the Local Marginal Polytope</a></p>
<p>Author: unkown-author</p><p>Abstract: We show that solving the LP relaxation of the MAP inference problem in graphical models (also known as the minsum problem, energy minimization, or weighted constraint satisfaction) is not easier than solving any LP. More precisely, any polytope is linear-time representable by a local marginal polytope and any LP can be reduced in linear time to a linear optimization (allowing infinite weights) over a local marginal polytope.</p><p>same-paper 3 0.9388333 <a title="20-lda-3" href="./cvpr-2013-A_New_Model_and_Simple_Algorithms_for_Multi-label_Mumford-Shah_Problems.html">20 cvpr-2013-A New Model and Simple Algorithms for Multi-label Mumford-Shah Problems</a></p>
<p>Author: Byung-Woo Hong, Zhaojin Lu, Ganesh Sundaramoorthi</p><p>Abstract: In this work, we address the multi-label Mumford-Shah problem, i.e., the problem of jointly estimating a partitioning of the domain of the image, and functions defined within regions of the partition. We create algorithms that are efficient, robust to undesirable local minima, and are easy-toimplement. Our algorithms are formulated by slightly modifying the underlying statistical model from which the multilabel Mumford-Shah functional is derived. The advantage of this statistical model is that the underlying variables: the labels and thefunctions are less coupled than in the original formulation, and the labels can be computed from the functions with more global updates. The resulting algorithms can be tuned to the desired level of locality of the solution: from fully global updates to more local updates. We demonstrate our algorithm on two applications: joint multi-label segmentation and denoising, and joint multi-label motion segmentation and flow estimation. We compare to the stateof-the-art in multi-label Mumford-Shah problems and show that we achieve more promising results.</p><p>4 0.93353677 <a title="20-lda-4" href="./cvpr-2013-Occlusion_Patterns_for_Object_Class_Detection.html">311 cvpr-2013-Occlusion Patterns for Object Class Detection</a></p>
<p>Author: Bojan Pepikj, Michael Stark, Peter Gehler, Bernt Schiele</p><p>Abstract: Despite the success of recent object class recognition systems, the long-standing problem of partial occlusion remains a major challenge, and a principled solution is yet to be found. In this paper we leave the beaten path of methods that treat occlusion as just another source of noise instead, we include the occluder itself into the modelling, by mining distinctive, reoccurring occlusion patterns from annotated training data. These patterns are then used as training data for dedicated detectors of varying sophistication. In particular, we evaluate and compare models that range from standard object class detectors to hierarchical, part-based representations of occluder/occludee pairs. In an extensive evaluation we derive insights that can aid further developments in tackling the occlusion challenge. –</p><p>5 0.93301582 <a title="20-lda-5" href="./cvpr-2013-Beta_Process_Joint_Dictionary_Learning_for_Coupled_Feature_Spaces_with_Application_to_Single_Image_Super-Resolution.html">58 cvpr-2013-Beta Process Joint Dictionary Learning for Coupled Feature Spaces with Application to Single Image Super-Resolution</a></p>
<p>Author: Li He, Hairong Qi, Russell Zaretzki</p><p>Abstract: This paper addresses the problem of learning overcomplete dictionaries for the coupled feature spaces, where the learned dictionaries also reflect the relationship between the two spaces. A Bayesian method using a beta process prior is applied to learn the over-complete dictionaries. Compared to previous couple feature spaces dictionary learning algorithms, our algorithm not only provides dictionaries that customized to each feature space, but also adds more consistent and accurate mapping between the two feature spaces. This is due to the unique property of the beta process model that the sparse representation can be decomposed to values and dictionary atom indicators. The proposed algorithm is able to learn sparse representations that correspond to the same dictionary atoms with the same sparsity but different values in coupled feature spaces, thus bringing consistent and accurate mapping between coupled feature spaces. Another advantage of the proposed method is that the number of dictionary atoms and their relative importance may be inferred non-parametrically. We compare the proposed approach to several state-of-the-art dictionary learning methods super-resolution. tionaries learned resolution results ods. by applying this method to single image The experimental results show that dicby our method produces the best supercompared to other state-of-the-art meth-</p><p>6 0.92945236 <a title="20-lda-6" href="./cvpr-2013-Compressible_Motion_Fields.html">88 cvpr-2013-Compressible Motion Fields</a></p>
<p>7 0.92878741 <a title="20-lda-7" href="./cvpr-2013-Exemplar-Based_Face_Parsing.html">152 cvpr-2013-Exemplar-Based Face Parsing</a></p>
<p>8 0.92872232 <a title="20-lda-8" href="./cvpr-2013-Relative_Hidden_Markov_Models_for_Evaluating_Motion_Skill.html">353 cvpr-2013-Relative Hidden Markov Models for Evaluating Motion Skill</a></p>
<p>9 0.92839241 <a title="20-lda-9" href="./cvpr-2013-Tracking_People_and_Their_Objects.html">440 cvpr-2013-Tracking People and Their Objects</a></p>
<p>10 0.92803061 <a title="20-lda-10" href="./cvpr-2013-What_Object_Motion_Reveals_about_Shape_with_Unknown_BRDF_and_Lighting.html">465 cvpr-2013-What Object Motion Reveals about Shape with Unknown BRDF and Lighting</a></p>
<p>11 0.92667902 <a title="20-lda-11" href="./cvpr-2013-Correlation_Filters_for_Object_Alignment.html">96 cvpr-2013-Correlation Filters for Object Alignment</a></p>
<p>12 0.92579728 <a title="20-lda-12" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<p>13 0.92552006 <a title="20-lda-13" href="./cvpr-2013-Robust_Monocular_Epipolar_Flow_Estimation.html">362 cvpr-2013-Robust Monocular Epipolar Flow Estimation</a></p>
<p>14 0.92528206 <a title="20-lda-14" href="./cvpr-2013-Templateless_Quasi-rigid_Shape_Modeling_with_Implicit_Loop-Closure.html">424 cvpr-2013-Templateless Quasi-rigid Shape Modeling with Implicit Loop-Closure</a></p>
<p>15 0.92524409 <a title="20-lda-15" href="./cvpr-2013-Intrinsic_Scene_Properties_from_a_Single_RGB-D_Image.html">227 cvpr-2013-Intrinsic Scene Properties from a Single RGB-D Image</a></p>
<p>16 0.92472535 <a title="20-lda-16" href="./cvpr-2013-Robust_Estimation_of_Nonrigid_Transformation_for_Point_Set_Registration.html">360 cvpr-2013-Robust Estimation of Nonrigid Transformation for Point Set Registration</a></p>
<p>17 0.92460483 <a title="20-lda-17" href="./cvpr-2013-Optimal_Geometric_Fitting_under_the_Truncated_L2-Norm.html">317 cvpr-2013-Optimal Geometric Fitting under the Truncated L2-Norm</a></p>
<p>18 0.92459863 <a title="20-lda-18" href="./cvpr-2013-A_New_Perspective_on_Uncalibrated_Photometric_Stereo.html">21 cvpr-2013-A New Perspective on Uncalibrated Photometric Stereo</a></p>
<p>19 0.92451376 <a title="20-lda-19" href="./cvpr-2013-Label_Propagation_from_ImageNet_to_3D_Point_Clouds.html">242 cvpr-2013-Label Propagation from ImageNet to 3D Point Clouds</a></p>
<p>20 0.92412221 <a title="20-lda-20" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
