<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>433 cvpr-2013-Top-Down Segmentation of Non-rigid Visual Objects Using Derivative-Based Search on Sparse Manifolds</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-433" href="#">cvpr2013-433</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>433 cvpr-2013-Top-Down Segmentation of Non-rigid Visual Objects Using Derivative-Based Search on Sparse Manifolds</h1>
<br/><p>Source: <a title="cvpr-2013-433-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Nascimento_Top-Down_Segmentation_of_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Jacinto C. Nascimento, Gustavo Carneiro</p><p>Abstract: The solution for the top-down segmentation of non-rigid visual objects using machine learning techniques is generally regarded as too complex to be solved in its full generality given the large dimensionality of the search space of the explicit representation ofthe segmentation contour. In order to reduce this complexity, theproblem is usually divided into two stages: rigid detection and non-rigid segmentation. The rationale is based on the fact that the rigid detection can be run in a lower dimensionality space (i.e., less complex and faster) than the original contour space, and its result is then used to constrain the non-rigid segmentation. In this paper, we propose the use of sparse manifolds to reduce the dimensionality of the rigid detection search space of current stateof-the-art top-down segmentation methodologies. The main goals targeted by this smaller dimensionality search space are the decrease of the search running time complexity and the reduction of the training complexity of the rigid detec- tor. These goals are attainable given that both the search and training complexities are function of the dimensionality of the rigid search space. We test our approach in the segmentation of the left ventricle from ultrasound images and lips from frontal face images. Compared to the performance of state-of-the-art non-rigid segmentation system, our experiments show that the use of sparse manifolds for the rigid detection leads to the two goals mentioned above.</p><p>Reference: <a title="cvpr-2013-433-reference" href="../cvpr2013_reference/cvpr-2013-Top-Down_Segmentation_of_Non-rigid_Visual_Objects_Using_Derivative-Based_Search_on_Sparse_Manifolds_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 In order to reduce this complexity, theproblem is usually divided into two stages: rigid detection and non-rigid segmentation. [sent-3, score-0.629]
</p><p>2 The rationale is based on the fact that the rigid detection can be run in a lower dimensionality space (i. [sent-4, score-0.847]
</p><p>3 , less complex and faster) than the original contour space, and its result is then used to constrain the non-rigid segmentation. [sent-6, score-0.177]
</p><p>4 In this paper, we propose the use of sparse manifolds to reduce the dimensionality of the rigid detection search space of current stateof-the-art top-down segmentation methodologies. [sent-7, score-1.506]
</p><p>5 The main goals targeted by this smaller dimensionality search space are the decrease of the search running time complexity and the reduction of the training complexity of the rigid detec-  tor. [sent-8, score-1.646]
</p><p>6 These goals are attainable given that both the search and training complexities are function of the dimensionality of the rigid search space. [sent-9, score-1.242]
</p><p>7 We test our approach in the segmentation of the left ventricle from ultrasound images and lips from frontal face images. [sent-10, score-0.729]
</p><p>8 Compared to the performance of state-of-the-art non-rigid segmentation system, our experiments show that the use of sparse manifolds for the rigid detection leads to the two goals mentioned above. [sent-11, score-1.223]
</p><p>9 Introduction The top-down segmentation of non-rigid visual objects based on machine learning approaches [4, 9, 28, 29, 30, 3 1] has been traditionally addressed by dividing it into two procedures that are run in the following sequence: 1) rigid detection and 2) non-rigid segmentation. [sent-13, score-0.86]
</p><p>10 The main reason for the existence of a rigid detection step is the reduction of the training complexity and the search running time complexity. [sent-14, score-1.087]
</p><p>11 The introduction of the rigid detection procedure allows for a significant reduction of K during the non-rigid segmentation by constraining the search for the visual object borders within a small window around the output produced by the rigid detector. [sent-16, score-1.72]
</p><p>12 Usually, the rigid detection finds the center, scale and orientation of the visual object by searching for it in a parameter space of r dimensions, where r << S (note that throughout the paper, r represents a variable that indicates the dimensionality of the rigid detection space). [sent-17, score-1.531]
</p><p>13 As a result, the rigid detection approach becomes the dominant procedure in terms of running time complexity, which is function of r. [sent-18, score-0.672]
</p><p>14 Another issue addressed by the introduction of a rigid detection approach is the alleviation of the need of a large and complete training set. [sent-19, score-0.743]
</p><p>15 Nevertheless, the rigid detector still runs in an r-dimensional space, which means that the detector complexity is also function of r, and the training set available rarely provides enough information for a robust training. [sent-20, score-0.694]
</p><p>16 The usual solution to get around this issue consists of generating artificial positive and negative training samples by randomly perturbing the rigid parameters of the annotated data [25]. [sent-21, score-0.947]
</p><p>17 This random perturbation is commonly drawn from some simple probability density function (e. [sent-22, score-0.035]
</p><p>18 The issue with this approach is that the actual training data distribution is unlikely to follow simple probability density functions, so this process is probably unnecessarily increasing the complexity of the learning process by adding artificial samples that may not be plausible in practice. [sent-25, score-0.424]
</p><p>19 In this paper, we propose the use of sparse manifolds [18]  with low intrinsic dimensionality for the rigid detection stage in non-rigid top-down visual segmentation methodologies [4, 5, 9, 30, 3 1]. [sent-26, score-1.425]
</p><p>20 The intrinsic low dimensionality of sparse manifolds decreases the search running time complexity of the current state-of-the-art rigid detection approaches aforementioned. [sent-27, score-1.468]
</p><p>21 Consequently, this produces less complex and faster training processes. [sent-29, score-0.127]
</p><p>22 We test our approach in the challenging problems of left ventricle (LV) endocardial segmentation from ultrasound images and of lip segmentation from frontal face images. [sent-30, score-1.084]
</p><p>23 In the experiments, we produce competitive segmentation results with significant running time complexity reduction using a sparse manifold of two dimensions, which represents a substantial reduction from the original five dimensional rigid search space usually found in current approaches. [sent-31, score-1.56]
</p><p>24 Furthermore, we show that the training process is robust to the reduction of the number of additional artificial positive and negative samples, which indicates that smaller training sets can be used in our framework without affecting the segmentation accuracy. [sent-32, score-0.623]
</p><p>25 Also note that these smaller training sets result in less complex and faster training processes. [sent-33, score-0.204]
</p><p>26 Related Work The use of machine learning techniques to solve topdown non-rigid segmentation problems has been intensively investigated in the past few years. [sent-35, score-0.34]
</p><p>27 Particularly challenging problems in this domain are the segmentation of the left ventricle (LV) of the heart from ultrasound images [20] (see Figures 1(a) and 5), and the segmentation of the lip border from frontal face images [24] (see Figures 1(b) and 6). [sent-36, score-1.063]
</p><p>28 However, none of these approaches attempt to reduce the dimensionality of the rigid search space using gradient-based search methods on manifolds. [sent-38, score-1.074]
</p><p>29 Gradient-based search methods on manifolds have been recently investigated by Helmke et al. [sent-39, score-0.447]
</p><p>30 [11], who propose a new optimization approach for the essential matrix computation with the use of Gauss-Newton iterations on a manifold in order to reduce the computational effort. [sent-40, score-0.272]
</p><p>31 [14] also elaborate a numerical optimization of a cost function defined on a manifold. [sent-42, score-0.036]
</p><p>32 In the same research line, Newton’s method is applied along the geodesics and variants of projections are proposed where the optimization strategies take advantage of the manifold structure[1, 7, 23]. [sent-43, score-0.273]
</p><p>33 Our approach represents an application of such gradient-based  search methods in the problem of top-down non-rigid segmentation with the specific goals ofreducing the search running time and the training complexity. [sent-44, score-0.779]
</p><p>34 Non-rigid Top-down Definition  Segmentation Problem  Given an image containing the sought visual object, our goal is to produce a non-rigid segmentation using a matrix  (a)(b) Figure 1. [sent-46, score-0.346]
</p><p>35 Application of the transformation At to the window enclosing the sought segmentation contour for the case of (a) left ventricle segmentation, and (b) lip segmentation. [sent-47, score-0.969]
</p><p>36 Both figures depict the explicit segmentation contour with the rectangular window (left panel) and zoomed in image of the visual information within the window (right panel). [sent-48, score-0.736]
</p><p>37 Note that the images on the right panels are the ones used by the rigid classifier p(t |I, D) in (2). [sent-49, score-0.57]
</p><p>38 R2×S  S ∈ of S 2-D points, which is the explicit representatSio ∈n oRf the segmentation contour. [sent-50, score-0.257]
</p><p>39 Assume the availability of  {(I,S)j}|jD=|1, containing  a training set, represented by D = training images Ij : Ωnt → [0, 255] a(nId, Sth)e respective man-  ual annotations Sj, :w Ωhe →re Ω [0 d,e25no5t]e asn tdhe th hiem raegsep elactttiivcee . [sent-51, score-0.28]
</p><p>40 (1)  The high dimensionality of S makes the computation of (1) intractable, and the usual solution to alleviate the problem is the introduction of an intermediate problem that can be solved in lower dimensionality, where the solution is used to constrain the optimization (1). [sent-54, score-0.325]
</p><p>41 This intermediate problem involves the use of a hidden variable t ∈ Rr, with r << (in2v ×ol vSe)s, athse efo ulsloew osf [a4, h i9d, d3e0n, 3v 1ar]:i  p(S|I,D) =? [sent-55, score-0.155]
</p><p>42 (2)  In practice, the variable t is used to transform linearly the coordinates of a window that encloses the segmentation contour (see Fig. [sent-57, score-0.542]
</p><p>43 This linear transform is obtained from the variable t as follows: At = f(t), where At ∈ R3×3 [4, 9, 30, 3 1]1. [sent-59, score-0.057]
</p><p>44 Then the term p(t |I, D) in (2) represents the rigid detect. [sent-60, score-0.518]
</p><p>45 io Tnh celnas thsiefi etre tmhat p outputs t ihne (p2r)o rbeapbriel-ity of having the sought visual object within the boundaries of the window transformed by t. [sent-61, score-0.359]
</p><p>46 The term p(S |t, I,D) in (o2f) hise t whein ndoown-ri trgaidns sfeorgmmeednt batyio tn. [sent-62, score-0.038]
</p><p>47 cTlahessi tferiemr d pe(nSo|tte,dI , bDy )th ien probability of finding the contour S in image I given the value of t. [sent-63, score-0.133]
</p><p>48 That is, t constrains the search space of S to be within the image window defined by t. [sent-64, score-0.286]
</p><p>49 Assuming that the original rigid search space represented by the variable t has dimension r = R, the main objective of this paper is the introduction of a new space for t with  dimension r = M  < R, based  on a sparse manifold. [sent-65, score-0.94]
</p><p>50 Partition of the manifold into patches (top) and the corresponding tangent hyperplanes (bottom). [sent-68, score-0.331]
</p><p>51 The arrows illustrate the mappings back and forth between the patches and the hyperplanes. [sent-69, score-0.036]
</p><p>52 The black dots are the annotations from which a low dimensional representation is built. [sent-70, score-0.039]
</p><p>53 Sparse Manifolds The intuition of using manifolds for reducing the dimensionality of t is centered on the idea that the training annota-  tions Sj can be confidently represented in a manifold M by the respeccatnive b elo cwonefri ddeinmtleyn srieopnreasl evnatreiadb ilne a tj . [sent-72, score-0.891]
</p><p>54 nFiofro lldea Mrnin bgy such manifold, we follow the Gaussian Processes Multiple Dynamical Models (GP-MLM) [18] implementation. [sent-73, score-0.059]
</p><p>55 GPMLM is a local method that finds multiple representations of the manifold, valid in different regions. [sent-74, score-0.041]
</p><p>56 , GP-LVM [19]); and 3) it allows for an elegant way to perform model selection approaches, which increases the efficiency of GP-MLM. [sent-77, score-0.04]
</p><p>57 The manifold learning strategy consists of the following input/output (see Fig. [sent-78, score-0.23]
</p><p>58 2 for an illustration): •  •  Input: training samples Sj, j = 1, . [sent-79, score-0.135]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('rigid', 0.518), ('manifolds', 0.249), ('ventricle', 0.238), ('manifold', 0.23), ('segmentation', 0.197), ('dimensionality', 0.184), ('ultrasound', 0.156), ('lip', 0.148), ('search', 0.147), ('instituto', 0.134), ('contour', 0.133), ('goals', 0.126), ('sought', 0.11), ('window', 0.103), ('artificial', 0.1), ('complexity', 0.099), ('reduction', 0.092), ('frontal', 0.089), ('adelaide', 0.086), ('running', 0.085), ('training', 0.077), ('sj', 0.077), ('panel', 0.077), ('detection', 0.069), ('sparse', 0.064), ('explicit', 0.06), ('tangent', 0.06), ('bdy', 0.059), ('endocardial', 0.059), ('athse', 0.059), ('mme', 0.059), ('bgy', 0.059), ('ssp', 0.059), ('etre', 0.059), ('mrnin', 0.059), ('usual', 0.058), ('figures', 0.058), ('samples', 0.058), ('variable', 0.057), ('ilne', 0.055), ('nid', 0.055), ('lv', 0.054), ('intrinsic', 0.053), ('portugal', 0.052), ('tica', 0.052), ('encloses', 0.052), ('ual', 0.052), ('elo', 0.052), ('methodologies', 0.052), ('panels', 0.052), ('investigated', 0.051), ('faster', 0.05), ('perturbing', 0.049), ('nso', 0.049), ('optimizations', 0.049), ('lips', 0.049), ('nascimento', 0.049), ('unnecessarily', 0.048), ('ihne', 0.048), ('intensively', 0.046), ('rob', 0.046), ('vse', 0.046), ('topdown', 0.046), ('negative', 0.045), ('constrain', 0.044), ('confidently', 0.044), ('geodesics', 0.043), ('complexities', 0.043), ('zoomed', 0.043), ('reduce', 0.042), ('issue', 0.042), ('finds', 0.041), ('dimension', 0.041), ('jd', 0.041), ('hyperplanes', 0.041), ('rationale', 0.04), ('enclosing', 0.04), ('elegant', 0.04), ('newton', 0.039), ('annotations', 0.039), ('intermediate', 0.039), ('visual', 0.039), ('heart', 0.038), ('ples', 0.038), ('orf', 0.038), ('australian', 0.038), ('hise', 0.038), ('addressed', 0.037), ('australia', 0.037), ('borders', 0.037), ('ol', 0.037), ('lowdimensional', 0.037), ('space', 0.036), ('restrictive', 0.036), ('elaborate', 0.036), ('forth', 0.036), ('targeted', 0.036), ('asn', 0.035), ('affecting', 0.035), ('perturbation', 0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="433-tfidf-1" href="./cvpr-2013-Top-Down_Segmentation_of_Non-rigid_Visual_Objects_Using_Derivative-Based_Search_on_Sparse_Manifolds.html">433 cvpr-2013-Top-Down Segmentation of Non-rigid Visual Objects Using Derivative-Based Search on Sparse Manifolds</a></p>
<p>Author: Jacinto C. Nascimento, Gustavo Carneiro</p><p>Abstract: The solution for the top-down segmentation of non-rigid visual objects using machine learning techniques is generally regarded as too complex to be solved in its full generality given the large dimensionality of the search space of the explicit representation ofthe segmentation contour. In order to reduce this complexity, theproblem is usually divided into two stages: rigid detection and non-rigid segmentation. The rationale is based on the fact that the rigid detection can be run in a lower dimensionality space (i.e., less complex and faster) than the original contour space, and its result is then used to constrain the non-rigid segmentation. In this paper, we propose the use of sparse manifolds to reduce the dimensionality of the rigid detection search space of current stateof-the-art top-down segmentation methodologies. The main goals targeted by this smaller dimensionality search space are the decrease of the search running time complexity and the reduction of the training complexity of the rigid detec- tor. These goals are attainable given that both the search and training complexities are function of the dimensionality of the rigid search space. We test our approach in the segmentation of the left ventricle from ultrasound images and lips from frontal face images. Compared to the performance of state-of-the-art non-rigid segmentation system, our experiments show that the use of sparse manifolds for the rigid detection leads to the two goals mentioned above.</p><p>2 0.18026564 <a title="433-tfidf-2" href="./cvpr-2013-Rolling_Riemannian_Manifolds_to_Solve_the_Multi-class_Classification_Problem.html">367 cvpr-2013-Rolling Riemannian Manifolds to Solve the Multi-class Classification Problem</a></p>
<p>Author: Rui Caseiro, Pedro Martins, João F. Henriques, Fátima Silva Leite, Jorge Batista</p><p>Abstract: In the past few years there has been a growing interest on geometric frameworks to learn supervised classification models on Riemannian manifolds [31, 27]. A popular framework, valid over any Riemannian manifold, was proposed in [31] for binary classification. Once moving from binary to multi-class classification thisparadigm is not valid anymore, due to the spread of multiple positive classes on the manifold [27]. It is then natural to ask whether the multi-class paradigm could be extended to operate on a large class of Riemannian manifolds. We propose a mathematically well-founded classification paradigm that allows to extend the work in [31] to multi-class models, taking into account the structure of the space. The idea is to project all the data from the manifold onto an affine tangent space at a particular point. To mitigate the distortion induced by local diffeomorphisms, we introduce for the first time in the computer vision community a well-founded mathematical concept, so-called Rolling map [21, 16]. The novelty in this alternate school of thought is that the manifold will be firstly rolled (without slipping or twisting) as a rigid body, then the given data is unwrapped onto the affine tangent space, where the classification is performed.</p><p>3 0.17710516 <a title="433-tfidf-3" href="./cvpr-2013-Kernel_Learning_for_Extrinsic_Classification_of_Manifold_Features.html">237 cvpr-2013-Kernel Learning for Extrinsic Classification of Manifold Features</a></p>
<p>Author: Raviteja Vemulapalli, Jaishanker K. Pillai, Rama Chellappa</p><p>Abstract: In computer vision applications, features often lie on Riemannian manifolds with known geometry. Popular learning algorithms such as discriminant analysis, partial least squares, support vector machines, etc., are not directly applicable to such features due to the non-Euclidean nature of the underlying spaces. Hence, classification is often performed in an extrinsic manner by mapping the manifolds to Euclidean spaces using kernels. However, for kernel based approaches, poor choice of kernel often results in reduced performance. In this paper, we address the issue of kernelselection for the classification of features that lie on Riemannian manifolds using the kernel learning approach. We propose two criteria for jointly learning the kernel and the classifier using a single optimization problem. Specifically, for the SVM classifier, we formulate the problem of learning a good kernel-classifier combination as a convex optimization problem and solve it efficiently following the multiple kernel learning approach. Experimental results on image set-based classification and activity recognition clearly demonstrate the superiority of the proposed approach over existing methods for classification of manifold features.</p><p>4 0.16983287 <a title="433-tfidf-4" href="./cvpr-2013-Active_Contours_with_Group_Similarity.html">33 cvpr-2013-Active Contours with Group Similarity</a></p>
<p>Author: Xiaowei Zhou, Xiaojie Huang, James S. Duncan, Weichuan Yu</p><p>Abstract: Active contours are widely used in image segmentation. To cope with missing or misleading features in images, researchers have introduced various ways to model the prior of shapes and use the prior to constrain active contours. However, the shape prior is usually learnt from a large set of annotated data, which is not always accessible in practice. Moreover, it is often doubted that the existing shapes in the training set will be sufficient to model the new instance in the testing image. In this paper, we propose to use the group similarity of object shapes in multiple images as a prior to aid segmentation, which can be interpreted as an unsupervised approach of shape prior modeling. We show that the rank of the matrix consisting of multiple shapes is a good measure of the group similarity of the shapes, and the nuclear norm minimization is a simple and effective way to impose the proposed constraint on existing active contour models. Moreover, we develop a fast algorithm to solve the proposed model by using the accelerated proximal method. Experiments using echocardiographic image sequences acquired from acute canine experiments demonstrate that the proposed method can consistently improve the performance of active contour models and increase the robustness against image defects such as missing boundaries.</p><p>5 0.13412878 <a title="433-tfidf-5" href="./cvpr-2013-Templateless_Quasi-rigid_Shape_Modeling_with_Implicit_Loop-Closure.html">424 cvpr-2013-Templateless Quasi-rigid Shape Modeling with Implicit Loop-Closure</a></p>
<p>Author: Ming Zeng, Jiaxiang Zheng, Xuan Cheng, Xinguo Liu</p><p>Abstract: This paper presents a method for quasi-rigid objects modeling from a sequence of depth scans captured at different time instances. As quasi-rigid objects, such as human bodies, usually have shape motions during the capture procedure, it is difficult to reconstruct their geometries. We represent the shape motion by a deformation graph, and propose a model-to-partmethod to gradually integrate sampled points of depth scans into the deformation graph. Under an as-rigid-as-possible assumption, the model-to-part method can adjust the deformation graph non-rigidly, so as to avoid error accumulation in alignment, which also implicitly achieves loop-closure. To handle the drift and topological error for the deformation graph, two algorithms are introduced. First, we use a two-stage registration to largely keep the rigid motion part. Second, in the step of graph integration, we topology-adaptively integrate new parts and dynamically control the regularization effect of the deformation graph. We demonstrate the effectiveness and robustness of our method by several depth sequences of quasi-rigid objects, and an application in human shape modeling.</p><p>6 0.13407792 <a title="433-tfidf-6" href="./cvpr-2013-Non-rigid_Structure_from_Motion_with_Diffusion_Maps_Prior.html">306 cvpr-2013-Non-rigid Structure from Motion with Diffusion Maps Prior</a></p>
<p>7 0.13281408 <a title="433-tfidf-7" href="./cvpr-2013-Sparse_Subspace_Denoising_for_Image_Manifolds.html">405 cvpr-2013-Sparse Subspace Denoising for Image Manifolds</a></p>
<p>8 0.12741423 <a title="433-tfidf-8" href="./cvpr-2013-Learning_a_Manifold_as_an_Atlas.html">259 cvpr-2013-Learning a Manifold as an Atlas</a></p>
<p>9 0.11323981 <a title="433-tfidf-9" href="./cvpr-2013-MKPLS%3A_Manifold_Kernel_Partial_Least_Squares_for_Lipreading_and_Speaker_Identification.html">276 cvpr-2013-MKPLS: Manifold Kernel Partial Least Squares for Lipreading and Speaker Identification</a></p>
<p>10 0.10158674 <a title="433-tfidf-10" href="./cvpr-2013-Improved_Image_Set_Classification_via_Joint_Sparse_Approximated_Nearest_Subspaces.html">215 cvpr-2013-Improved Image Set Classification via Joint Sparse Approximated Nearest Subspaces</a></p>
<p>11 0.099570319 <a title="433-tfidf-11" href="./cvpr-2013-Kernel_Methods_on_the_Riemannian_Manifold_of_Symmetric_Positive_Definite_Matrices.html">238 cvpr-2013-Kernel Methods on the Riemannian Manifold of Symmetric Positive Definite Matrices</a></p>
<p>12 0.098549232 <a title="433-tfidf-12" href="./cvpr-2013-Articulated_and_Restricted_Motion_Subspaces_and_Their_Signatures.html">46 cvpr-2013-Articulated and Restricted Motion Subspaces and Their Signatures</a></p>
<p>13 0.091478631 <a title="433-tfidf-13" href="./cvpr-2013-Fast_Rigid_Motion_Segmentation_via_Incrementally-Complex_Local_Models.html">170 cvpr-2013-Fast Rigid Motion Segmentation via Incrementally-Complex Local Models</a></p>
<p>14 0.089291617 <a title="433-tfidf-14" href="./cvpr-2013-Seeking_the_Strongest_Rigid_Detector.html">383 cvpr-2013-Seeking the Strongest Rigid Detector</a></p>
<p>15 0.087057255 <a title="433-tfidf-15" href="./cvpr-2013-Dense_Variational_Reconstruction_of_Non-rigid_Surfaces_from_Monocular_Video.html">113 cvpr-2013-Dense Variational Reconstruction of Non-rigid Surfaces from Monocular Video</a></p>
<p>16 0.085229009 <a title="433-tfidf-16" href="./cvpr-2013-Incorporating_User_Interaction_and_Topological_Constraints_within_Contour_Completion_via_Discrete_Calculus.html">222 cvpr-2013-Incorporating User Interaction and Topological Constraints within Contour Completion via Discrete Calculus</a></p>
<p>17 0.084928222 <a title="433-tfidf-17" href="./cvpr-2013-Inductive_Hashing_on_Manifolds.html">223 cvpr-2013-Inductive Hashing on Manifolds</a></p>
<p>18 0.081942551 <a title="433-tfidf-18" href="./cvpr-2013-Procrustean_Normal_Distribution_for_Non-rigid_Structure_from_Motion.html">341 cvpr-2013-Procrustean Normal Distribution for Non-rigid Structure from Motion</a></p>
<p>19 0.080388598 <a title="433-tfidf-19" href="./cvpr-2013-Real-Time_Model-Based_Rigid_Object_Pose_Estimation_and_Tracking_Combining_Dense_and_Sparse_Visual_Cues.html">345 cvpr-2013-Real-Time Model-Based Rigid Object Pose Estimation and Tracking Combining Dense and Sparse Visual Cues</a></p>
<p>20 0.078203499 <a title="433-tfidf-20" href="./cvpr-2013-Harry_Potter%27s_Marauder%27s_Map%3A_Localizing_and_Tracking_Multiple_Persons-of-Interest_by_Nonnegative_Discretization.html">199 cvpr-2013-Harry Potter's Marauder's Map: Localizing and Tracking Multiple Persons-of-Interest by Nonnegative Discretization</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.179), (1, 0.005), (2, -0.032), (3, 0.026), (4, 0.06), (5, -0.012), (6, 0.001), (7, -0.103), (8, -0.04), (9, -0.084), (10, 0.062), (11, -0.004), (12, -0.089), (13, -0.111), (14, 0.003), (15, -0.007), (16, -0.13), (17, -0.016), (18, -0.154), (19, 0.092), (20, 0.016), (21, 0.084), (22, 0.054), (23, -0.002), (24, 0.019), (25, 0.046), (26, 0.01), (27, 0.06), (28, 0.038), (29, 0.034), (30, -0.029), (31, -0.113), (32, -0.108), (33, 0.037), (34, 0.036), (35, -0.057), (36, 0.047), (37, 0.033), (38, -0.034), (39, 0.044), (40, 0.064), (41, 0.088), (42, -0.01), (43, -0.014), (44, 0.021), (45, 0.028), (46, -0.055), (47, -0.026), (48, 0.002), (49, -0.011)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92707092 <a title="433-lsi-1" href="./cvpr-2013-Top-Down_Segmentation_of_Non-rigid_Visual_Objects_Using_Derivative-Based_Search_on_Sparse_Manifolds.html">433 cvpr-2013-Top-Down Segmentation of Non-rigid Visual Objects Using Derivative-Based Search on Sparse Manifolds</a></p>
<p>Author: Jacinto C. Nascimento, Gustavo Carneiro</p><p>Abstract: The solution for the top-down segmentation of non-rigid visual objects using machine learning techniques is generally regarded as too complex to be solved in its full generality given the large dimensionality of the search space of the explicit representation ofthe segmentation contour. In order to reduce this complexity, theproblem is usually divided into two stages: rigid detection and non-rigid segmentation. The rationale is based on the fact that the rigid detection can be run in a lower dimensionality space (i.e., less complex and faster) than the original contour space, and its result is then used to constrain the non-rigid segmentation. In this paper, we propose the use of sparse manifolds to reduce the dimensionality of the rigid detection search space of current stateof-the-art top-down segmentation methodologies. The main goals targeted by this smaller dimensionality search space are the decrease of the search running time complexity and the reduction of the training complexity of the rigid detec- tor. These goals are attainable given that both the search and training complexities are function of the dimensionality of the rigid search space. We test our approach in the segmentation of the left ventricle from ultrasound images and lips from frontal face images. Compared to the performance of state-of-the-art non-rigid segmentation system, our experiments show that the use of sparse manifolds for the rigid detection leads to the two goals mentioned above.</p><p>2 0.81967419 <a title="433-lsi-2" href="./cvpr-2013-Rolling_Riemannian_Manifolds_to_Solve_the_Multi-class_Classification_Problem.html">367 cvpr-2013-Rolling Riemannian Manifolds to Solve the Multi-class Classification Problem</a></p>
<p>Author: Rui Caseiro, Pedro Martins, João F. Henriques, Fátima Silva Leite, Jorge Batista</p><p>Abstract: In the past few years there has been a growing interest on geometric frameworks to learn supervised classification models on Riemannian manifolds [31, 27]. A popular framework, valid over any Riemannian manifold, was proposed in [31] for binary classification. Once moving from binary to multi-class classification thisparadigm is not valid anymore, due to the spread of multiple positive classes on the manifold [27]. It is then natural to ask whether the multi-class paradigm could be extended to operate on a large class of Riemannian manifolds. We propose a mathematically well-founded classification paradigm that allows to extend the work in [31] to multi-class models, taking into account the structure of the space. The idea is to project all the data from the manifold onto an affine tangent space at a particular point. To mitigate the distortion induced by local diffeomorphisms, we introduce for the first time in the computer vision community a well-founded mathematical concept, so-called Rolling map [21, 16]. The novelty in this alternate school of thought is that the manifold will be firstly rolled (without slipping or twisting) as a rigid body, then the given data is unwrapped onto the affine tangent space, where the classification is performed.</p><p>3 0.79695243 <a title="433-lsi-3" href="./cvpr-2013-Learning_a_Manifold_as_an_Atlas.html">259 cvpr-2013-Learning a Manifold as an Atlas</a></p>
<p>Author: Nikolaos Pitelis, Chris Russell, Lourdes Agapito</p><p>Abstract: In this work, we return to the underlying mathematical definition of a manifold and directly characterise learning a manifold as finding an atlas, or a set of overlapping charts, that accurately describe local structure. We formulate the problem of learning the manifold as an optimisation that simultaneously refines the continuous parameters defining the charts, and the discrete assignment of points to charts. In contrast to existing methods, this direct formulation of a manifold does not require “unwrapping ” the manifold into a lower dimensional space and allows us to learn closed manifolds of interest to vision, such as those corresponding to gait cycles or camera pose. We report state-ofthe-art results for manifold based nearest neighbour classification on vision datasets, and show how the same techniques can be applied to the 3D reconstruction of human motion from a single image.</p><p>4 0.77618587 <a title="433-lsi-4" href="./cvpr-2013-MKPLS%3A_Manifold_Kernel_Partial_Least_Squares_for_Lipreading_and_Speaker_Identification.html">276 cvpr-2013-MKPLS: Manifold Kernel Partial Least Squares for Lipreading and Speaker Identification</a></p>
<p>Author: Amr Bakry, Ahmed Elgammal</p><p>Abstract: Visual speech recognition is a challenging problem, due to confusion between visual speech features. The speaker identification problem is usually coupled with speech recognition. Moreover, speaker identification is important to several applications, such as automatic access control, biometrics, authentication, and personal privacy issues. In this paper, we propose a novel approach for lipreading and speaker identification. Wepropose a new approachfor manifold parameterization in a low-dimensional latent space, where each manifold is represented as a point in that space. We initially parameterize each instance manifold using a nonlinear mapping from a unified manifold representation. We then factorize the parameter space using Kernel Partial Least Squares (KPLS) to achieve a low-dimension manifold latent space. We use two-way projections to achieve two manifold latent spaces, one for the speech content and one for the speaker. We apply our approach on two public databases: AVLetters and OuluVS. We show the results for three different settings of lipreading: speaker independent, speaker dependent, and speaker semi-dependent. Our approach outperforms for the speaker semi-dependent setting by at least 15% of the baseline, and competes in the other two settings.</p><p>5 0.72894919 <a title="433-lsi-5" href="./cvpr-2013-Kernel_Learning_for_Extrinsic_Classification_of_Manifold_Features.html">237 cvpr-2013-Kernel Learning for Extrinsic Classification of Manifold Features</a></p>
<p>Author: Raviteja Vemulapalli, Jaishanker K. Pillai, Rama Chellappa</p><p>Abstract: In computer vision applications, features often lie on Riemannian manifolds with known geometry. Popular learning algorithms such as discriminant analysis, partial least squares, support vector machines, etc., are not directly applicable to such features due to the non-Euclidean nature of the underlying spaces. Hence, classification is often performed in an extrinsic manner by mapping the manifolds to Euclidean spaces using kernels. However, for kernel based approaches, poor choice of kernel often results in reduced performance. In this paper, we address the issue of kernelselection for the classification of features that lie on Riemannian manifolds using the kernel learning approach. We propose two criteria for jointly learning the kernel and the classifier using a single optimization problem. Specifically, for the SVM classifier, we formulate the problem of learning a good kernel-classifier combination as a convex optimization problem and solve it efficiently following the multiple kernel learning approach. Experimental results on image set-based classification and activity recognition clearly demonstrate the superiority of the proposed approach over existing methods for classification of manifold features.</p><p>6 0.71345937 <a title="433-lsi-6" href="./cvpr-2013-Kernel_Methods_on_the_Riemannian_Manifold_of_Symmetric_Positive_Definite_Matrices.html">238 cvpr-2013-Kernel Methods on the Riemannian Manifold of Symmetric Positive Definite Matrices</a></p>
<p>7 0.69790328 <a title="433-lsi-7" href="./cvpr-2013-Non-rigid_Structure_from_Motion_with_Diffusion_Maps_Prior.html">306 cvpr-2013-Non-rigid Structure from Motion with Diffusion Maps Prior</a></p>
<p>8 0.60640466 <a title="433-lsi-8" href="./cvpr-2013-Active_Contours_with_Group_Similarity.html">33 cvpr-2013-Active Contours with Group Similarity</a></p>
<p>9 0.55427593 <a title="433-lsi-9" href="./cvpr-2013-Sparse_Subspace_Denoising_for_Image_Manifolds.html">405 cvpr-2013-Sparse Subspace Denoising for Image Manifolds</a></p>
<p>10 0.53933811 <a title="433-lsi-10" href="./cvpr-2013-Procrustean_Normal_Distribution_for_Non-rigid_Structure_from_Motion.html">341 cvpr-2013-Procrustean Normal Distribution for Non-rigid Structure from Motion</a></p>
<p>11 0.51120651 <a title="433-lsi-11" href="./cvpr-2013-Improved_Image_Set_Classification_via_Joint_Sparse_Approximated_Nearest_Subspaces.html">215 cvpr-2013-Improved Image Set Classification via Joint Sparse Approximated Nearest Subspaces</a></p>
<p>12 0.50884598 <a title="433-lsi-12" href="./cvpr-2013-Deep_Learning_Shape_Priors_for_Object_Segmentation.html">105 cvpr-2013-Deep Learning Shape Priors for Object Segmentation</a></p>
<p>13 0.50369585 <a title="433-lsi-13" href="./cvpr-2013-Probabilistic_Graphlet_Cut%3A_Exploiting_Spatial_Structure_Cue_for_Weakly_Supervised_Image_Segmentation.html">339 cvpr-2013-Probabilistic Graphlet Cut: Exploiting Spatial Structure Cue for Weakly Supervised Image Segmentation</a></p>
<p>14 0.49226677 <a title="433-lsi-14" href="./cvpr-2013-Computing_Diffeomorphic_Paths_for_Large_Motion_Interpolation.html">90 cvpr-2013-Computing Diffeomorphic Paths for Large Motion Interpolation</a></p>
<p>15 0.49176675 <a title="433-lsi-15" href="./cvpr-2013-PDM-ENLOR%3A_Learning_Ensemble_of_Local_PDM-Based_Regressions.html">321 cvpr-2013-PDM-ENLOR: Learning Ensemble of Local PDM-Based Regressions</a></p>
<p>16 0.49038333 <a title="433-lsi-16" href="./cvpr-2013-Local_Fisher_Discriminant_Analysis_for_Pedestrian_Re-identification.html">270 cvpr-2013-Local Fisher Discriminant Analysis for Pedestrian Re-identification</a></p>
<p>17 0.48578164 <a title="433-lsi-17" href="./cvpr-2013-Graph-Laplacian_PCA%3A_Closed-Form_Solution_and_Robustness.html">191 cvpr-2013-Graph-Laplacian PCA: Closed-Form Solution and Robustness</a></p>
<p>18 0.46780694 <a title="433-lsi-18" href="./cvpr-2013-Dense_Variational_Reconstruction_of_Non-rigid_Surfaces_from_Monocular_Video.html">113 cvpr-2013-Dense Variational Reconstruction of Non-rigid Surfaces from Monocular Video</a></p>
<p>19 0.46490279 <a title="433-lsi-19" href="./cvpr-2013-Towards_Fast_and_Accurate_Segmentation.html">437 cvpr-2013-Towards Fast and Accurate Segmentation</a></p>
<p>20 0.46027505 <a title="433-lsi-20" href="./cvpr-2013-Measures_and_Meta-Measures_for_the_Supervised_Evaluation_of_Image_Segmentation.html">281 cvpr-2013-Measures and Meta-Measures for the Supervised Evaluation of Image Segmentation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.126), (16, 0.024), (24, 0.177), (26, 0.065), (33, 0.318), (67, 0.086), (69, 0.04), (87, 0.087)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.9502455 <a title="433-lda-1" href="./cvpr-2013-Adherent_Raindrop_Detection_and_Removal_in_Video.html">37 cvpr-2013-Adherent Raindrop Detection and Removal in Video</a></p>
<p>Author: Shaodi You, Robby T. Tan, Rei Kawakami, Katsushi Ikeuchi</p><p>Abstract: Raindrops adhered to a windscreen or window glass can significantly degrade the visibility of a scene. Detecting and removing raindrops will, therefore, benefit many computer vision applications, particularly outdoor surveillance systems and intelligent vehicle systems. In this paper, a method that automatically detects and removes adherent raindrops is introduced. The core idea is to exploit the local spatiotemporal derivatives ofraindrops. First, it detects raindrops based on the motion and the intensity temporal derivatives of the input video. Second, relying on an analysis that some areas of a raindrop completely occludes the scene, yet the remaining areas occludes only partially, the method removes the two types of areas separately. For partially occluding areas, it restores them by retrieving as much as possible information of the scene, namely, by solving a blending function on the detected partially occluding areas using the temporal intensity change. For completely occluding areas, it recovers them by using a video completion technique. Experimental results using various real videos show the effectiveness of the proposed method.</p><p>2 0.91455966 <a title="433-lda-2" href="./cvpr-2013-Finding_Things%3A_Image_Parsing_with_Regions_and_Per-Exemplar_Detectors.html">173 cvpr-2013-Finding Things: Image Parsing with Regions and Per-Exemplar Detectors</a></p>
<p>Author: Joseph Tighe, Svetlana Lazebnik</p><p>Abstract: This paper presents a system for image parsing, or labeling each pixel in an image with its semantic category, aimed at achieving broad coverage across hundreds of object categories, many of them sparsely sampled. The system combines region-level features with per-exemplar sliding window detectors. Per-exemplar detectors are better suited for our parsing task than traditional bounding box detectors: they perform well on classes with little training data and high intra-class variation, and they allow object masks to be transferred into the test image for pixel-level segmentation. The proposed system achieves state-of-theart accuracy on three challenging datasets, the largest of which contains 45,676 images and 232 labels.</p><p>3 0.91057974 <a title="433-lda-3" href="./cvpr-2013-Segment-Tree_Based_Cost_Aggregation_for_Stereo_Matching.html">384 cvpr-2013-Segment-Tree Based Cost Aggregation for Stereo Matching</a></p>
<p>Author: Xing Mei, Xun Sun, Weiming Dong, Haitao Wang, Xiaopeng Zhang</p><p>Abstract: This paper presents a novel tree-based cost aggregation method for dense stereo matching. Instead of employing the minimum spanning tree (MST) and its variants, a new tree structure, ”Segment-Tree ”, is proposed for non-local matching cost aggregation. Conceptually, the segment-tree is constructed in a three-step process: first, the pixels are grouped into a set of segments with the reference color or intensity image; second, a tree graph is created for each segment; and in the final step, these independent segment graphs are linked to form the segment-tree structure. In practice, this tree can be efficiently built in time nearly linear to the number of the image pixels. Compared to MST where the graph connectivity is determined with local edge weights, our method introduces some ’non-local’ decision rules: the pixels in one perceptually consistent segment are more likely to share similar disparities, and therefore their connectivity within the segment should be first enforced in the tree construction process. The matching costs are then aggregated over the tree within two passes. Performance evaluation on 19 Middlebury data sets shows that the proposed method is comparable to previous state-of-the-art aggregation methods in disparity accuracy and processing speed. Furthermore, the tree structure can be refined with the estimated disparities, which leads to consistent scene segmentation and significantly better aggregation results.</p><p>same-paper 4 0.90912396 <a title="433-lda-4" href="./cvpr-2013-Top-Down_Segmentation_of_Non-rigid_Visual_Objects_Using_Derivative-Based_Search_on_Sparse_Manifolds.html">433 cvpr-2013-Top-Down Segmentation of Non-rigid Visual Objects Using Derivative-Based Search on Sparse Manifolds</a></p>
<p>Author: Jacinto C. Nascimento, Gustavo Carneiro</p><p>Abstract: The solution for the top-down segmentation of non-rigid visual objects using machine learning techniques is generally regarded as too complex to be solved in its full generality given the large dimensionality of the search space of the explicit representation ofthe segmentation contour. In order to reduce this complexity, theproblem is usually divided into two stages: rigid detection and non-rigid segmentation. The rationale is based on the fact that the rigid detection can be run in a lower dimensionality space (i.e., less complex and faster) than the original contour space, and its result is then used to constrain the non-rigid segmentation. In this paper, we propose the use of sparse manifolds to reduce the dimensionality of the rigid detection search space of current stateof-the-art top-down segmentation methodologies. The main goals targeted by this smaller dimensionality search space are the decrease of the search running time complexity and the reduction of the training complexity of the rigid detec- tor. These goals are attainable given that both the search and training complexities are function of the dimensionality of the rigid search space. We test our approach in the segmentation of the left ventricle from ultrasound images and lips from frontal face images. Compared to the performance of state-of-the-art non-rigid segmentation system, our experiments show that the use of sparse manifolds for the rigid detection leads to the two goals mentioned above.</p><p>5 0.90417731 <a title="433-lda-5" href="./cvpr-2013-Plane-Based_Content_Preserving_Warps_for_Video_Stabilization.html">333 cvpr-2013-Plane-Based Content Preserving Warps for Video Stabilization</a></p>
<p>Author: Zihan Zhou, Hailin Jin, Yi Ma</p><p>Abstract: Recently, a new image deformation technique called content-preserving warping (CPW) has been successfully employed to produce the state-of-the-art video stabilization results in many challenging cases. The key insight of CPW is that the true image deformation due to viewpoint change can be well approximated by a carefully constructed warp using a set of sparsely constructed 3D points only. However, since CPW solely relies on the tracked feature points to guide the warping, it works poorly in large textureless regions, such as ground and building interiors. To overcome this limitation, in this paper we present a hybrid approach for novel view synthesis, observing that the textureless regions often correspond to large planar surfaces in the scene. Particularly, given a jittery video, we first segment each frame into piecewise planar regions as well as regions labeled as non-planar using Markov random fields. Then, a new warp is computed by estimating a single homography for regions belong to the same plane, while in- heriting results from CPW in the non-planar regions. We demonstrate how the segmentation information can be efficiently obtained and seamlessly integrated into the stabilization framework. Experimental results on a variety of real video sequences verify the effectiveness of our method.</p><p>6 0.89583224 <a title="433-lda-6" href="./cvpr-2013-Learning_Collections_of_Part_Models_for_Object_Recognition.html">248 cvpr-2013-Learning Collections of Part Models for Object Recognition</a></p>
<p>7 0.89287382 <a title="433-lda-7" href="./cvpr-2013-Understanding_Indoor_Scenes_Using_3D_Geometric_Phrases.html">446 cvpr-2013-Understanding Indoor Scenes Using 3D Geometric Phrases</a></p>
<p>8 0.89251482 <a title="433-lda-8" href="./cvpr-2013-Deep_Convolutional_Network_Cascade_for_Facial_Point_Detection.html">104 cvpr-2013-Deep Convolutional Network Cascade for Facial Point Detection</a></p>
<p>9 0.89239508 <a title="433-lda-9" href="./cvpr-2013-Label_Propagation_from_ImageNet_to_3D_Point_Clouds.html">242 cvpr-2013-Label Propagation from ImageNet to 3D Point Clouds</a></p>
<p>10 0.89238149 <a title="433-lda-10" href="./cvpr-2013-Integrating_Grammar_and_Segmentation_for_Human_Pose_Estimation.html">225 cvpr-2013-Integrating Grammar and Segmentation for Human Pose Estimation</a></p>
<p>11 0.89219403 <a title="433-lda-11" href="./cvpr-2013-A_Joint_Model_for_2D_and_3D_Pose_Estimation_from_a_Single_Image.html">14 cvpr-2013-A Joint Model for 2D and 3D Pose Estimation from a Single Image</a></p>
<p>12 0.89159447 <a title="433-lda-12" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<p>13 0.89141744 <a title="433-lda-13" href="./cvpr-2013-Part_Discovery_from_Partial_Correspondence.html">325 cvpr-2013-Part Discovery from Partial Correspondence</a></p>
<p>14 0.89110893 <a title="433-lda-14" href="./cvpr-2013-Spatiotemporal_Deformable_Part_Models_for_Action_Detection.html">408 cvpr-2013-Spatiotemporal Deformable Part Models for Action Detection</a></p>
<p>15 0.89056557 <a title="433-lda-15" href="./cvpr-2013-Structure_Preserving_Object_Tracking.html">414 cvpr-2013-Structure Preserving Object Tracking</a></p>
<p>16 0.89047897 <a title="433-lda-16" href="./cvpr-2013-Detecting_and_Aligning_Faces_by_Image_Retrieval.html">119 cvpr-2013-Detecting and Aligning Faces by Image Retrieval</a></p>
<p>17 0.89012593 <a title="433-lda-17" href="./cvpr-2013-MODEC%3A_Multimodal_Decomposable_Models_for_Human_Pose_Estimation.html">277 cvpr-2013-MODEC: Multimodal Decomposable Models for Human Pose Estimation</a></p>
<p>18 0.89007545 <a title="433-lda-18" href="./cvpr-2013-Hierarchical_Saliency_Detection.html">202 cvpr-2013-Hierarchical Saliency Detection</a></p>
<p>19 0.8898865 <a title="433-lda-19" href="./cvpr-2013-Analyzing_Semantic_Segmentation_Using_Hybrid_Human-Machine_CRFs.html">43 cvpr-2013-Analyzing Semantic Segmentation Using Hybrid Human-Machine CRFs</a></p>
<p>20 0.88972056 <a title="433-lda-20" href="./cvpr-2013-A_Lazy_Man%27s_Approach_to_Benchmarking%3A_Semisupervised_Classifier_Evaluation_and_Recalibration.html">15 cvpr-2013-A Lazy Man's Approach to Benchmarking: Semisupervised Classifier Evaluation and Recalibration</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
