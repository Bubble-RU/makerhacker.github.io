<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>222 cvpr-2013-Incorporating User Interaction and Topological Constraints within Contour Completion via Discrete Calculus</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-222" href="#">cvpr2013-222</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>222 cvpr-2013-Incorporating User Interaction and Topological Constraints within Contour Completion via Discrete Calculus</h1>
<br/><p>Source: <a title="cvpr-2013-222-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Xu_Incorporating_User_Interaction_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Jia Xu, Maxwell D. Collins, Vikas Singh</p><p>Abstract: We study the problem of interactive segmentation and contour completion for multiple objects. The form of constraints our model incorporates are those coming from user scribbles (interior or exterior constraints) as well as information regarding the topology of the 2-D space after partitioning (number of closed contours desired). We discuss how concepts from discrete calculus and a simple identity using the Euler characteristic of a planar graph can be utilized to derive a practical algorithm for this problem. We also present specialized branch and bound methods for the case of single contour completion under such constraints. On an extensive dataset of ∼ 1000 images, our experimOenn tasn suggest vthea dt a assmetal ol fa m∼ou 1n0t0 of ismidaeg knowledge can give strong improvements over fully unsupervised contour completion methods. We show that by interpreting user indications topologically, user effort is substantially reduced.</p><p>Reference: <a title="cvpr-2013-222-reference" href="../cvpr2013_reference/cvpr-2013-Incorporating_User_Interaction_and_Topological_Constraints_within_Contour_Completion_via_Discrete_Calculus_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu / Abstract We study the problem of interactive segmentation and contour completion for multiple objects. [sent-5, score-0.694]
</p><p>2 The form of constraints our model incorporates are those coming from user scribbles (interior or exterior constraints) as well as information regarding the topology of the 2-D space after partitioning (number of closed contours desired). [sent-6, score-0.607]
</p><p>3 We discuss how concepts from discrete calculus and a simple identity using the Euler characteristic of a planar graph can be utilized to derive a practical algorithm for this problem. [sent-7, score-0.354]
</p><p>4 We also present specialized branch and bound methods for the case of single contour completion under such constraints. [sent-8, score-0.627]
</p><p>5 On an extensive dataset of ∼ 1000 images, our experimOenn tasn suggest vthea dt a assmetal ol fa m∼ou 1n0t0 of ismidaeg knowledge can give strong improvements over fully unsupervised contour completion methods. [sent-9, score-0.593]
</p><p>6 We show that by interpreting user indications topologically, user effort is substantially reduced. [sent-10, score-0.365]
</p><p>7 Introduction  This paper is focused on developing optimization models for the problem of multiple contour completion/segmentation subject to side constraints. [sent-12, score-0.37]
</p><p>8 The type of constraints our algorithm incorporates are (a) those relating to inside (or outside) seed indications given via user scribbles; (b) global constraints on the topology, i. [sent-13, score-0.404]
</p><p>9 , information which reflects the number of unique closed contours a user is looking for. [sent-15, score-0.415]
</p><p>10 The objective then is to find k closed “legal” contour cycles with desirable properties (e. [sent-20, score-0.567]
</p><p>11 The basic primitives in our construction are contour fragments, not pixels. [sent-24, score-0.417]
</p><p>12 Our high level goal is the design of practical contour completion algorithms that take advice which in a sense parallels a powerful suite of methods that have recently demon–  strated how global knowledge can be incorporated within popular region-based image segmentation methods [26]. [sent-27, score-0.681]
</p><p>13 Figure 1: Left to right: input images, edgelets or contours with seed indications, and final contour. [sent-28, score-0.426]
</p><p>14 The associated body of literature is vast methods range from performing edge detection at the level of local patches [32], to taking the continuity of edge contours into account [37, 29], to incorporating high-level cues [36] such as those derived from shape and/or appearance [25]. [sent-33, score-0.378]
</p><p>15 While the appropriateness of a specific contour detector is governed by the downstream application, developments in recent years have given a number of powerful methods that yield high quality boundary detection on a large variety of images and perform well on established benchmarks [25]. [sent-34, score-0.513]
</p><p>16 Since one expects the global contour to be smooth, the well known Snakes formulation introduced an objective function based on first and second derivative of the curve. [sent-39, score-0.452]
</p><p>17 Others have proposed utilizing the ratio of two line integrals [18], incorporating curvature [3 1, 10], joining pre-extracted line segments [40, 35], and using CRFs to ensure the continuity of contours [30]. [sent-40, score-0.349]
</p><p>18 Note that despite similarities, contour detection on its own is not the same as image segmentation. [sent-41, score-0.37]
</p><p>19 In fact, even when formalized under contour completion, an algorithm may not always produce a closed contour. [sent-42, score-0.472]
</p><p>20 Without getting into the merits of edges versus regions, one can view edgebased contours as a viable alternative to “region-based” image segmentation methods in many applications. [sent-44, score-0.346]
</p><p>21 To address this limitation, there has been a noticeable shift recently towards the incorporation of additional information within the contour completion process. [sent-46, score-0.593]
</p><p>22 Specific examples of this line of work include semantic contours [16], the hierarchical ultrametric contour map [2], and particle filtering based object detection via edges [23]. [sent-48, score-0.659]
</p><p>23 While semantic knowledge based contour completion is quite powerful, its performance invariably depends on the richness of the underlying training corpus. [sent-50, score-0.593]
</p><p>24 In these circumstances, it seems natural to endow the contour completion models with the capability to leverage some form of user supervision (foreground and background seeds) [15]. [sent-52, score-0.765]
</p><p>25 Further, knowledge provided in the form of the number of closed contours a user requires, can be a powerful form of user guidance as well. [sent-53, score-0.588]
</p><p>26 While there are many mechanisms which incorporate such constraints in region based segmentation, only a few methods take such information explicitly into account for edge-based contour completion. [sent-55, score-0.443]
</p><p>27 In this work, we leverage a discrete calculus based toolset to incorporate such topological and seed indications type supervision within a practical contour completion algorithm. [sent-56, score-1.067]
</p><p>28 The primary contributions of the this paper are: (i) We present a unified optimization model for multiple contour completion/segmentation which incorporates topological constraints as well as inclusion/exclusion of foreground and background seeds. [sent-57, score-0.672]
</p><p>29 The topological knowledge is included by using the Euler characteristic of the edgelet graph where as inclusion/exclusion constraints utilize concepts from discrete calculus. [sent-58, score-0.334]
</p><p>30 (ii) For an extensive dataset, we provide strong evidence that with a small amount of user interaction, one can obtain high quality segmentations based on edge contours information alone. [sent-59, score-0.399]
</p><p>31 Preliminaries The tools of discrete calculus provide a powerful formalism to represent the topological information in an image [14, 20, 7]. [sent-62, score-0.329]
</p><p>32 We use conventions of discrete calculus to describe our problem of finding multiple contour closures. [sent-63, score-0.574]
</p><p>33 If the decomposition is such that (i) the interiors of the cells are disjoint and (ii) the boundary between any two p-dimensional cells is a (p − 1)-dimensional cell then we pha-dveim a cneslilo complex. [sent-69, score-0.352]
</p><p>34 Similarly, each vertex is incident on two or more edges and each edge is incident on two faces. [sent-76, score-0.596]
</p><p>35 Notice that the interior of a pair of faces is disjoint, and the boundary between any two faces gives an edge, where the dimension is reduced by one. [sent-77, score-0.321]
</p><p>36 As a consequence, we get a 2D cell complex for a planar graph, and also a set of incidence relationships among simplices of different dimensions. [sent-78, score-0.254]
</p><p>37 A cell complex may be oriented such that we can describe directions on each cell relative to its orientation, see Fig. [sent-79, score-0.252]
</p><p>38 Each type of cell has a corresponding pair of possible orientations: a vertex (0-cell) is either a source or a sink while an edge (1-cell) may be directed toward either endpoint. [sent-81, score-0.274]
</p><p>39 Further, each cell induces a corresponding ori111888888755  Vertex  Figure 2: sionalities boundary cboouhnerdeanrtyly (  Edge  Face  Coherent  Anti-coherent  (a) (b) Visualization of the orientations on cells of different dimen(a). [sent-82, score-0.325]
</p><p>40 entation on incident cells; for example, a directed edge has a source endpoint vertex at one end and sink at the other. [sent-85, score-0.347]
</p><p>41 The orientations of a cell and a member of its boundary are coherent if the induced orientations agree, an example is shown in Fig. [sent-86, score-0.298]
</p><p>42 All faces are given the same orientation, while edges and vertices are given arbitrary orientations. [sent-89, score-0.248]
</p><p>43 After enumerating its constituent vertices, edges and faces,  ×  a selection of some subset of faces is specified with an indicator vector x ∈ {0, 1}|F|. [sent-90, score-0.251]
</p><p>44 Similarly, by discarding orientation information, we can define the edge-face corresponding matrix C2 ∈ {0, 1}|E|×|F| which labels which edges are incident to∈ w {h0i,c1h} face. [sent-98, score-0.283]
</p><p>45 | is defined analogously to (1), where A1;ij = 1 iff node i is incident to edge j. [sent-101, score-0.302]
</p><p>46 Discrete calculus describes the notion of duality between cell complices. [sent-104, score-0.284]
</p><p>47 For any given cell complex, we can pco−nqst)r-ucectl li (tss dyu, aql ≤in a way tahnayt preserves incidence relationships between cells, see Fig. [sent-106, score-0.2]
</p><p>48 Using these concepts, in the following sections, we will formalize the required constraints within a contour completion objective function. [sent-108, score-0.676]
</p><p>49 A p-cell is in the foreground if and only if it is incident to a (p + 1)-cell in the foreground. [sent-114, score-0.3]
</p><p>50 This condition ensures that each connected component of the foreground is itself a cell complex, a property we will use shortly. [sent-115, score-0.355]
</p><p>51 Tarhieasbele edges a{0re, 1th}ose which are incident to both a foreground and a background face. [sent-117, score-0.418]
</p><p>52 =ly rep-  =  resent the contour of the selected foreground. [sent-124, score-0.37]
</p><p>53 1 to derive the identity w = |C1x| (2) Observe that each edge is incident to exactly two faces, and we specified that all faces have identical orientation. [sent-126, score-0.34]
</p><p>54 Therefore, for all internal edges (non-boundary edges in the foreground) the C1 operator when multiplied with x, cancels the contribution from these two faces, leaving non-zero values only for the boundary edges. [sent-128, score-0.348]
</p><p>55 The internal edges (which are incident to foreground faces on both sides) can still be computed in a different manner. [sent-129, score-0.507]
</p><p>56 The vector C2x will count the inside edges twice and the boundary edges once, as we discard orientation (and thus sign information). [sent-130, score-0.382]
</p><p>57 Selected faces are shaded, foreground edges are bold and foreground vertices highlighted in yellow. [sent-138, score-0.518]
</p><p>58 Internal edges yi wi = 0 are bold/black, boundary edges yi = wi = 1are red. [sent-139, score-0.348]
</p><p>59 =  edges incident to each foreground vertex (or node), where (A2y)i is the number of foreground edges incident to vertex (or node) i. [sent-140, score-0.96]
</p><p>60 Similarily, when scaled by the degree di of vertex i, (A3y)i ∈ [0, 1] will be the proportion of edges incident to iwhich a∈re [ 0i,n1 f]o wreigllr obuen thde. [sent-141, score-0.345]
</p><p>61 Conversely, if no edge incident to iis selected in the solution, then (A2y)i = (A3y)i = 0 and (4) is satisfied only for zi = 0. [sent-143, score-0.285]
</p><p>62 The expressions introduced above allow the identification of whether a user provided seed falls “inside” or “outside” the contour completion given by w, and will serve  as constraints for our multiple contour completion model. [sent-144, score-1.436]
</p><p>63 4 shows an illustrative example for an image, where the input to the contour completion are edgelets (or edgels) obtained from boundaries of a globalPb derived superpixels. [sent-146, score-0.816]
</p><p>64 Our final requirement is to be able to specify the number of closed contours desired. [sent-148, score-0.273]
</p><p>65 The DijkstraGC [38] finds a segmentation where two manually indicated seed points are connected via the foreground where as Nowozin [28] makes use of a LP relaxation. [sent-151, score-0.309]
</p><p>66 If we explicitly constrain that the Euler characteristic of an induced subgraph created by selecting any given foreground is exactly two, this will give a foreground region that is connected and simple in a geometric sense. [sent-155, score-0.453]
</p><p>67 Optimization Model Before we introduce the contour completion model, we briefly describe the procedure for deriving the components of the graph from an image. [sent-174, score-0.626]
</p><p>68 This process follows existing algorithms for contour and boundary detection. [sent-175, score-0.482]
</p><p>69 Each superpixel corresponds to a face, and the boundary of the superpixel corresponds to edges in the graph (these are the basic primitives of the closed contours we will derive). [sent-178, score-0.721]
</p><p>70 With this construction, the problem of finding multiple contour closures reduces to finding multiple cycles in the graph. [sent-180, score-0.425]
</p><p>71 We use an objective function which is the ratio of these quantities, This ends up being the portion of contour w. [sent-186, score-0.451]
</p><p>72 Minimizing this quantity has been shown to provide a contour that has strong edge support in the image. [sent-189, score-0.456]
</p><p>73 1 constructs a cell complex using a superpixel decomposition of the image do-  main. [sent-207, score-0.195]
</p><p>74 Occlusion or weak boundaries give cases where the set of superpixel boundary primitives (the input to our optimization) do not include some valid edgelets (ones which have not been picked up by either the contour detector or superpixel method). [sent-209, score-0.89]
</p><p>75 The natural solution to this is to supplement the basic set of edgelet primitives with additional contour pieces that bridge the ‘gaps’ and allow a more accurate contour closure even in the presence of very weak signal variations. [sent-210, score-0.912]
</p><p>76 But introducing completions between all pairs of edgelets is prohibitive and leads to a problem with a large number of variables (especially for multiple contours). [sent-212, score-0.295]
</p><p>77 The following model, while applicable to the multiple contour setting, is most effective for finding a single contour which encloses a simply connected foreground region. [sent-213, score-0.964]
</p><p>78 A key subcomponent of this problem is how to join two edgelets which will follow each other on the contour. [sent-215, score-0.221]
</p><p>79 For any pair of points along with tangents we can construct a segment of an euler spiral which connects these points with consistent tangents. [sent-222, score-0.452]
</p><p>80 We can compute an average completion in 30μs, versus 1ms for [19] on the same machine, making it an attractive option to calculate a large number of completions, quickly, within the core contour completion engine. [sent-232, score-0.816]
</p><p>81 We are given a set of image edgelets derived from an edge detector as before, as well as user-provided foreground and background seeds. [sent-234, score-0.411]
</p><p>82 The core objective considered by the algorithm is an alternating path p which consists of a sequence of edgelets joined by Euler Spiral segments. [sent-235, score-0.27]
</p><p>83 The goal is to find a closed contour that minimizes an objective function that increases with the addition of each contour segment. [sent-236, score-0.882]
</p><p>84 If p is not a cycle, we may construct the children of this node by considering each image edglet in sequence and 111888889088  calculating the euler completion, on the fly. [sent-245, score-0.303]
</p><p>85 The path for the a child is then p plus the current completion and edgelet appended to the end. [sent-246, score-0.318]
</p><p>86 We compare our approach (which we refer as EulerSeg) with three other contour grouping methods: (i) Ratio Region Cut (RRC) from [34], (ii) Superpixel Closure (SC) from [21], and an adaptive grouping method (EJ) [11]. [sent-256, score-0.446]
</p><p>87 The cell complex is generated from superpixels via [22] and the same number of superpixels as SC in all our experiment. [sent-260, score-0.292]
</p><p>88 As the examples show, our objective function minimizes gaps in the closure and leverages user seeds to handle slender objects better and outperforms both with ≤ 5 seeds. [sent-273, score-0.325]
</p><p>89 We note that in some images of BSDS500, there are no salient objects or closed contours (e. [sent-281, score-0.317]
</p><p>90 However, another challenging class of images in BSD are those that depict a large number of foreground objects, here our algorithm significantly improves upon previous results with a small amount of user guideline and the topological constraint. [sent-285, score-0.371]
</p><p>91 We measure the effects of  user interactions using a robot user setting. [sent-296, score-0.327]
</p><p>92 The question we ask is how much user interaction is required to get a region F-measure score of 0. [sent-298, score-0.21]
</p><p>93 Discussion We present a framework based on discrete calculus which unifies the contour completion and segmentation settings. [sent-318, score-0.854]
</p><p>94 Our model easily accommodates user indications and multiple foreground regions. [sent-320, score-0.358]
</p><p>95 Two solvers specialized toward different aspects of the problem are derived, one based on an ILP over superpixels and the other a branch-and-bound using completions with spirals to join edgelets. [sent-321, score-0.295]
</p><p>96 We demonstrate our model finds salient contours across a large dataset, showing significant improvement over similar methods. [sent-322, score-0.215]
</p><p>97 Interactive graph cuts for optimal boundary and region segmentation of objects in N-D images. [sent-365, score-0.232]
</p><p>98 Robust piecewise-planar 3d reconstruction and completion from large-scale unstructured point data. [sent-373, score-0.223]
</p><p>99 Scale-invariant contour comple-  [31]  [32] [33] [34] [35]  [36] [37]  [38] [39]  [40] [41]  tion using conditional random fields. [sent-523, score-0.37]
</p><p>100 Globally optimal grouping for symmetric closed boundaries by combining boundary and region information. [sent-552, score-0.315]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('contour', 0.37), ('eulerseg', 0.261), ('rrc', 0.253), ('euler', 0.252), ('completion', 0.223), ('edgelets', 0.19), ('contours', 0.171), ('incident', 0.165), ('calculus', 0.158), ('spiral', 0.158), ('user', 0.142), ('foreground', 0.135), ('cell', 0.126), ('iseg', 0.119), ('edges', 0.118), ('sc', 0.113), ('boundary', 0.112), ('completions', 0.105), ('closed', 0.102), ('whd', 0.095), ('wsd', 0.095), ('topological', 0.094), ('faces', 0.089), ('edge', 0.086), ('superpixels', 0.083), ('indications', 0.081), ('incidence', 0.074), ('seeds', 0.073), ('globalpb', 0.071), ('closure', 0.07), ('topology', 0.07), ('superpixel', 0.069), ('seed', 0.065), ('characteristic', 0.063), ('vertex', 0.062), ('cells', 0.057), ('segmentation', 0.057), ('cycles', 0.055), ('edgelet', 0.055), ('planar', 0.054), ('curvature', 0.053), ('fresnel', 0.053), ('connected', 0.052), ('node', 0.051), ('integrals', 0.049), ('scribbles', 0.049), ('fowlkes', 0.049), ('gscseq', 0.048), ('primitives', 0.047), ('discrete', 0.046), ('cycle', 0.045), ('interactive', 0.044), ('indicator', 0.044), ('ij', 0.044), ('salient', 0.044), ('constraints', 0.043), ('robot', 0.043), ('tangents', 0.042), ('dtu', 0.042), ('expects', 0.042), ('legal', 0.042), ('spirals', 0.042), ('stahl', 0.042), ('condition', 0.042), ('ratio', 0.041), ('vertices', 0.041), ('objective', 0.04), ('path', 0.04), ('extensibility', 0.039), ('subgraph', 0.038), ('grouping', 0.038), ('interaction', 0.038), ('encloses', 0.037), ('nt', 0.036), ('continuity', 0.035), ('ilp', 0.035), ('strokes', 0.035), ('turbopixels', 0.035), ('zi', 0.034), ('specialized', 0.034), ('endpoint', 0.034), ('levinshtein', 0.034), ('count', 0.034), ('graph', 0.033), ('globally', 0.033), ('tu', 0.033), ('boundaries', 0.033), ('circumstances', 0.032), ('maire', 0.031), ('interior', 0.031), ('pami', 0.031), ('powerful', 0.031), ('join', 0.031), ('region', 0.03), ('supervision', 0.03), ('brightness', 0.03), ('incorporates', 0.03), ('orientations', 0.03), ('horses', 0.029), ('aez', 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000014 <a title="222-tfidf-1" href="./cvpr-2013-Incorporating_User_Interaction_and_Topological_Constraints_within_Contour_Completion_via_Discrete_Calculus.html">222 cvpr-2013-Incorporating User Interaction and Topological Constraints within Contour Completion via Discrete Calculus</a></p>
<p>Author: Jia Xu, Maxwell D. Collins, Vikas Singh</p><p>Abstract: We study the problem of interactive segmentation and contour completion for multiple objects. The form of constraints our model incorporates are those coming from user scribbles (interior or exterior constraints) as well as information regarding the topology of the 2-D space after partitioning (number of closed contours desired). We discuss how concepts from discrete calculus and a simple identity using the Euler characteristic of a planar graph can be utilized to derive a practical algorithm for this problem. We also present specialized branch and bound methods for the case of single contour completion under such constraints. On an extensive dataset of ∼ 1000 images, our experimOenn tasn suggest vthea dt a assmetal ol fa m∼ou 1n0t0 of ismidaeg knowledge can give strong improvements over fully unsupervised contour completion methods. We show that by interpreting user indications topologically, user effort is substantially reduced.</p><p>2 0.26197031 <a title="222-tfidf-2" href="./cvpr-2013-Winding_Number_for_Region-Boundary_Consistent_Salient_Contour_Extraction.html">468 cvpr-2013-Winding Number for Region-Boundary Consistent Salient Contour Extraction</a></p>
<p>Author: Yansheng Ming, Hongdong Li, Xuming He</p><p>Abstract: This paper aims to extract salient closed contours from an image. For this vision task, both region segmentation cues (e.g. color/texture homogeneity) and boundary detection cues (e.g. local contrast, edge continuity and contour closure) play important and complementary roles. In this paper we show how to combine both cues in a unified framework. The main focus is given to how to maintain the consistency (compatibility) between the region cues and the boundary cues. To this ends, we introduce the use of winding number–a well-known concept in topology–as a powerful mathematical device. By this device, the region-boundary consistency is represented as a set of simple linear relationships. Our method is applied to the figure-ground segmentation problem. The experiments show clearly improved results.</p><p>3 0.22749248 <a title="222-tfidf-3" href="./cvpr-2013-Active_Contours_with_Group_Similarity.html">33 cvpr-2013-Active Contours with Group Similarity</a></p>
<p>Author: Xiaowei Zhou, Xiaojie Huang, James S. Duncan, Weichuan Yu</p><p>Abstract: Active contours are widely used in image segmentation. To cope with missing or misleading features in images, researchers have introduced various ways to model the prior of shapes and use the prior to constrain active contours. However, the shape prior is usually learnt from a large set of annotated data, which is not always accessible in practice. Moreover, it is often doubted that the existing shapes in the training set will be sufficient to model the new instance in the testing image. In this paper, we propose to use the group similarity of object shapes in multiple images as a prior to aid segmentation, which can be interpreted as an unsupervised approach of shape prior modeling. We show that the rank of the matrix consisting of multiple shapes is a good measure of the group similarity of the shapes, and the nuclear norm minimization is a simple and effective way to impose the proposed constraint on existing active contour models. Moreover, we develop a fast algorithm to solve the proposed model by using the accelerated proximal method. Experiments using echocardiographic image sequences acquired from acute canine experiments demonstrate that the proposed method can consistently improve the performance of active contour models and increase the robustness against image defects such as missing boundaries.</p><p>4 0.21110603 <a title="222-tfidf-4" href="./cvpr-2013-Perceptual_Organization_and_Recognition_of_Indoor_Scenes_from_RGB-D_Images.html">329 cvpr-2013-Perceptual Organization and Recognition of Indoor Scenes from RGB-D Images</a></p>
<p>Author: Saurabh Gupta, Pablo Arbeláez, Jitendra Malik</p><p>Abstract: We address the problems of contour detection, bottomup grouping and semantic segmentation using RGB-D data. We focus on the challenging setting of cluttered indoor scenes, and evaluate our approach on the recently introduced NYU-Depth V2 (NYUD2) dataset [27]. We propose algorithms for object boundary detection and hierarchical segmentation that generalize the gPb − ucm approach of [se2]g mbeyn mtaatkioinng t effective use oef t dheep gthP information. Wroea schho owf that our system can label each contour with its type (depth, normal or albedo). We also propose a generic method for long-range amodal completion of surfaces and show its effectiveness in grouping. We then turn to the problem of semantic segmentation and propose a simple approach that classifies superpixels into the 40 dominant object categories in NYUD2. We use both generic and class-specific features to encode the appearance and geometry of objects. We also show how our approach can be used for scene classification, and how this contextual information in turn improves object recognition. In all of these tasks, we report significant improvements over the state-of-the-art.</p><p>5 0.13274068 <a title="222-tfidf-5" href="./cvpr-2013-Towards_Fast_and_Accurate_Segmentation.html">437 cvpr-2013-Towards Fast and Accurate Segmentation</a></p>
<p>Author: Camillo Jose Taylor</p><p>Abstract: In this paper we explore approaches to accelerating segmentation and edge detection algorithms based on the gPb framework. The paper characterizes the performance of a simple but effective edge detection scheme which can be computed rapidly and offers performance that is competitive with the pB detector. The paper also describes an approach for computing a reduced order normalized cut that captures the essential features of the original problem but can be computed in less than half a second on a standard computing platform.</p><p>6 0.13236052 <a title="222-tfidf-6" href="./cvpr-2013-Efficient_Color_Boundary_Detection_with_Color-Opponent_Mechanisms.html">140 cvpr-2013-Efficient Color Boundary Detection with Color-Opponent Mechanisms</a></p>
<p>7 0.11657015 <a title="222-tfidf-7" href="./cvpr-2013-Sketch_Tokens%3A_A_Learned_Mid-level_Representation_for_Contour_and_Object_Detection.html">401 cvpr-2013-Sketch Tokens: A Learned Mid-level Representation for Contour and Object Detection</a></p>
<p>8 0.11190238 <a title="222-tfidf-8" href="./cvpr-2013-Pattern-Driven_Colorization_of_3D_Surfaces.html">327 cvpr-2013-Pattern-Driven Colorization of 3D Surfaces</a></p>
<p>9 0.10176245 <a title="222-tfidf-9" href="./cvpr-2013-Exemplar-Based_Face_Parsing.html">152 cvpr-2013-Exemplar-Based Face Parsing</a></p>
<p>10 0.098747849 <a title="222-tfidf-10" href="./cvpr-2013-SCALPEL%3A_Segmentation_Cascades_with_Localized_Priors_and_Efficient_Learning.html">370 cvpr-2013-SCALPEL: Segmentation Cascades with Localized Priors and Efficient Learning</a></p>
<p>11 0.098365866 <a title="222-tfidf-11" href="./cvpr-2013-Boundary_Detection_Benchmarking%3A_Beyond_F-Measures.html">72 cvpr-2013-Boundary Detection Benchmarking: Beyond F-Measures</a></p>
<p>12 0.095131971 <a title="222-tfidf-12" href="./cvpr-2013-Reconstructing_Loopy_Curvilinear_Structures_Using_Integer_Programming.html">350 cvpr-2013-Reconstructing Loopy Curvilinear Structures Using Integer Programming</a></p>
<p>13 0.092818335 <a title="222-tfidf-13" href="./cvpr-2013-Ensemble_Video_Object_Cut_in_Highly_Dynamic_Scenes.html">148 cvpr-2013-Ensemble Video Object Cut in Highly Dynamic Scenes</a></p>
<p>14 0.092557207 <a title="222-tfidf-14" href="./cvpr-2013-Improving_Image_Matting_Using_Comprehensive_Sampling_Sets.html">216 cvpr-2013-Improving Image Matting Using Comprehensive Sampling Sets</a></p>
<p>15 0.091788195 <a title="222-tfidf-15" href="./cvpr-2013-Unsupervised_Joint_Object_Discovery_and_Segmentation_in_Internet_Images.html">450 cvpr-2013-Unsupervised Joint Object Discovery and Segmentation in Internet Images</a></p>
<p>16 0.090131 <a title="222-tfidf-16" href="./cvpr-2013-Saliency_Detection_via_Graph-Based_Manifold_Ranking.html">375 cvpr-2013-Saliency Detection via Graph-Based Manifold Ranking</a></p>
<p>17 0.087519191 <a title="222-tfidf-17" href="./cvpr-2013-Weakly-Supervised_Dual_Clustering_for_Image_Semantic_Segmentation.html">460 cvpr-2013-Weakly-Supervised Dual Clustering for Image Semantic Segmentation</a></p>
<p>18 0.087410294 <a title="222-tfidf-18" href="./cvpr-2013-Probabilistic_Label_Trees_for_Efficient_Large_Scale_Image_Classification.html">340 cvpr-2013-Probabilistic Label Trees for Efficient Large Scale Image Classification</a></p>
<p>19 0.086853199 <a title="222-tfidf-19" href="./cvpr-2013-Boundary_Cues_for_3D_Object_Shape_Recovery.html">71 cvpr-2013-Boundary Cues for 3D Object Shape Recovery</a></p>
<p>20 0.086828753 <a title="222-tfidf-20" href="./cvpr-2013-Voxel_Cloud_Connectivity_Segmentation_-_Supervoxels_for_Point_Clouds.html">458 cvpr-2013-Voxel Cloud Connectivity Segmentation - Supervoxels for Point Clouds</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.205), (1, 0.035), (2, 0.067), (3, 0.032), (4, 0.108), (5, -0.023), (6, 0.019), (7, 0.044), (8, -0.057), (9, -0.032), (10, 0.159), (11, -0.066), (12, -0.046), (13, 0.024), (14, 0.029), (15, -0.012), (16, 0.042), (17, -0.047), (18, 0.013), (19, 0.133), (20, -0.038), (21, 0.156), (22, -0.128), (23, -0.036), (24, 0.029), (25, 0.089), (26, 0.163), (27, -0.03), (28, 0.04), (29, 0.066), (30, 0.109), (31, 0.071), (32, -0.06), (33, 0.058), (34, 0.075), (35, 0.068), (36, 0.102), (37, 0.093), (38, -0.002), (39, 0.076), (40, 0.092), (41, 0.142), (42, -0.003), (43, 0.02), (44, 0.021), (45, 0.018), (46, 0.036), (47, -0.084), (48, -0.008), (49, 0.061)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96107817 <a title="222-lsi-1" href="./cvpr-2013-Incorporating_User_Interaction_and_Topological_Constraints_within_Contour_Completion_via_Discrete_Calculus.html">222 cvpr-2013-Incorporating User Interaction and Topological Constraints within Contour Completion via Discrete Calculus</a></p>
<p>Author: Jia Xu, Maxwell D. Collins, Vikas Singh</p><p>Abstract: We study the problem of interactive segmentation and contour completion for multiple objects. The form of constraints our model incorporates are those coming from user scribbles (interior or exterior constraints) as well as information regarding the topology of the 2-D space after partitioning (number of closed contours desired). We discuss how concepts from discrete calculus and a simple identity using the Euler characteristic of a planar graph can be utilized to derive a practical algorithm for this problem. We also present specialized branch and bound methods for the case of single contour completion under such constraints. On an extensive dataset of ∼ 1000 images, our experimOenn tasn suggest vthea dt a assmetal ol fa m∼ou 1n0t0 of ismidaeg knowledge can give strong improvements over fully unsupervised contour completion methods. We show that by interpreting user indications topologically, user effort is substantially reduced.</p><p>2 0.95440537 <a title="222-lsi-2" href="./cvpr-2013-Winding_Number_for_Region-Boundary_Consistent_Salient_Contour_Extraction.html">468 cvpr-2013-Winding Number for Region-Boundary Consistent Salient Contour Extraction</a></p>
<p>Author: Yansheng Ming, Hongdong Li, Xuming He</p><p>Abstract: This paper aims to extract salient closed contours from an image. For this vision task, both region segmentation cues (e.g. color/texture homogeneity) and boundary detection cues (e.g. local contrast, edge continuity and contour closure) play important and complementary roles. In this paper we show how to combine both cues in a unified framework. The main focus is given to how to maintain the consistency (compatibility) between the region cues and the boundary cues. To this ends, we introduce the use of winding number–a well-known concept in topology–as a powerful mathematical device. By this device, the region-boundary consistency is represented as a set of simple linear relationships. Our method is applied to the figure-ground segmentation problem. The experiments show clearly improved results.</p><p>3 0.81495106 <a title="222-lsi-3" href="./cvpr-2013-Boundary_Detection_Benchmarking%3A_Beyond_F-Measures.html">72 cvpr-2013-Boundary Detection Benchmarking: Beyond F-Measures</a></p>
<p>Author: Xiaodi Hou, Alan Yuille, Christof Koch</p><p>Abstract: For an ill-posed problem like boundary detection, human labeled datasets play a critical role. Compared with the active research on finding a better boundary detector to refresh the performance record, there is surprisingly little discussion on the boundary detection benchmark itself. The goal of this paper is to identify the potential pitfalls of today’s most popular boundary benchmark, BSDS 300. In the paper, we first introduce a psychophysical experiment to show that many of the “weak” boundary labels are unreliable and may contaminate the benchmark. Then we analyze the computation of f-measure and point out that the current benchmarking protocol encourages an algorithm to bias towards those problematic “weak” boundary labels. With this evidence, we focus on a new problem of detecting strong boundaries as one alternative. Finally, we assess the performances of 9 major algorithms on different ways of utilizing the dataset, suggesting new directions for improvements.</p><p>4 0.80568361 <a title="222-lsi-4" href="./cvpr-2013-Towards_Fast_and_Accurate_Segmentation.html">437 cvpr-2013-Towards Fast and Accurate Segmentation</a></p>
<p>Author: Camillo Jose Taylor</p><p>Abstract: In this paper we explore approaches to accelerating segmentation and edge detection algorithms based on the gPb framework. The paper characterizes the performance of a simple but effective edge detection scheme which can be computed rapidly and offers performance that is competitive with the pB detector. The paper also describes an approach for computing a reduced order normalized cut that captures the essential features of the original problem but can be computed in less than half a second on a standard computing platform.</p><p>5 0.76500112 <a title="222-lsi-5" href="./cvpr-2013-Efficient_Color_Boundary_Detection_with_Color-Opponent_Mechanisms.html">140 cvpr-2013-Efficient Color Boundary Detection with Color-Opponent Mechanisms</a></p>
<p>Author: Kaifu Yang, Shaobing Gao, Chaoyi Li, Yongjie Li</p><p>Abstract: Color information plays an important role in better understanding of natural scenes by at least facilitating discriminating boundaries of objects or areas. In this study, we propose a new framework for boundary detection in complex natural scenes based on the color-opponent mechanisms of the visual system. The red-green and blue-yellow color opponent channels in the human visual system are regarded as the building blocks for various color perception tasks such as boundary detection. The proposed framework is a feedforward hierarchical model, which has direct counterpart to the color-opponent mechanisms involved in from the retina to the primary visual cortex (V1). Results show that our simple framework has excellent ability to flexibly capture both the structured chromatic and achromatic boundaries in complex scenes.</p><p>6 0.7127592 <a title="222-lsi-6" href="./cvpr-2013-Active_Contours_with_Group_Similarity.html">33 cvpr-2013-Active Contours with Group Similarity</a></p>
<p>7 0.66313738 <a title="222-lsi-7" href="./cvpr-2013-Measures_and_Meta-Measures_for_the_Supervised_Evaluation_of_Image_Segmentation.html">281 cvpr-2013-Measures and Meta-Measures for the Supervised Evaluation of Image Segmentation</a></p>
<p>8 0.66053635 <a title="222-lsi-8" href="./cvpr-2013-Image_Segmentation_by_Cascaded_Region_Agglomeration.html">212 cvpr-2013-Image Segmentation by Cascaded Region Agglomeration</a></p>
<p>9 0.64805311 <a title="222-lsi-9" href="./cvpr-2013-Fast_Trust_Region_for_Segmentation.html">171 cvpr-2013-Fast Trust Region for Segmentation</a></p>
<p>10 0.62006855 <a title="222-lsi-10" href="./cvpr-2013-Graph-Based_Optimization_with_Tubularity_Markov_Tree_for_3D_Vessel_Segmentation.html">190 cvpr-2013-Graph-Based Optimization with Tubularity Markov Tree for 3D Vessel Segmentation</a></p>
<p>11 0.6055333 <a title="222-lsi-11" href="./cvpr-2013-Perceptual_Organization_and_Recognition_of_Indoor_Scenes_from_RGB-D_Images.html">329 cvpr-2013-Perceptual Organization and Recognition of Indoor Scenes from RGB-D Images</a></p>
<p>12 0.59877121 <a title="222-lsi-12" href="./cvpr-2013-Reconstructing_Loopy_Curvilinear_Structures_Using_Integer_Programming.html">350 cvpr-2013-Reconstructing Loopy Curvilinear Structures Using Integer Programming</a></p>
<p>13 0.57775444 <a title="222-lsi-13" href="./cvpr-2013-Sketch_Tokens%3A_A_Learned_Mid-level_Representation_for_Contour_and_Object_Detection.html">401 cvpr-2013-Sketch Tokens: A Learned Mid-level Representation for Contour and Object Detection</a></p>
<p>14 0.55326349 <a title="222-lsi-14" href="./cvpr-2013-Keypoints_from_Symmetries_by_Wave_Propagation.html">240 cvpr-2013-Keypoints from Symmetries by Wave Propagation</a></p>
<p>15 0.54204172 <a title="222-lsi-15" href="./cvpr-2013-Learning_the_Change_for_Automatic_Image_Cropping.html">263 cvpr-2013-Learning the Change for Automatic Image Cropping</a></p>
<p>16 0.53838724 <a title="222-lsi-16" href="./cvpr-2013-A_Statistical_Model_for_Recreational_Trails_in_Aerial_Images.html">26 cvpr-2013-A Statistical Model for Recreational Trails in Aerial Images</a></p>
<p>17 0.53751785 <a title="222-lsi-17" href="./cvpr-2013-Maximum_Cohesive_Grid_of_Superpixels_for_Fast_Object_Localization.html">280 cvpr-2013-Maximum Cohesive Grid of Superpixels for Fast Object Localization</a></p>
<p>18 0.5350197 <a title="222-lsi-18" href="./cvpr-2013-Voxel_Cloud_Connectivity_Segmentation_-_Supervoxels_for_Point_Clouds.html">458 cvpr-2013-Voxel Cloud Connectivity Segmentation - Supervoxels for Point Clouds</a></p>
<p>19 0.52817142 <a title="222-lsi-19" href="./cvpr-2013-Pattern-Driven_Colorization_of_3D_Surfaces.html">327 cvpr-2013-Pattern-Driven Colorization of 3D Surfaces</a></p>
<p>20 0.51812202 <a title="222-lsi-20" href="./cvpr-2013-SCALPEL%3A_Segmentation_Cascades_with_Localized_Priors_and_Efficient_Learning.html">370 cvpr-2013-SCALPEL: Segmentation Cascades with Localized Priors and Efficient Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.112), (16, 0.019), (26, 0.042), (30, 0.019), (33, 0.226), (67, 0.057), (69, 0.047), (87, 0.365), (99, 0.011)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.94994926 <a title="222-lda-1" href="./cvpr-2013-Lost%21_Leveraging_the_Crowd_for_Probabilistic_Visual_Self-Localization.html">274 cvpr-2013-Lost! Leveraging the Crowd for Probabilistic Visual Self-Localization</a></p>
<p>Author: Marcus A. Brubaker, Andreas Geiger, Raquel Urtasun</p><p>Abstract: In this paper we propose an affordable solution to selflocalization, which utilizes visual odometry and road maps as the only inputs. To this end, we present a probabilistic model as well as an efficient approximate inference algorithm, which is able to utilize distributed computation to meet the real-time requirements of autonomous systems. Because of the probabilistic nature of the model we are able to cope with uncertainty due to noisy visual odometry and inherent ambiguities in the map (e.g., in a Manhattan world). By exploiting freely available, community developed maps and visual odometry measurements, we are able to localize a vehicle up to 3m after only a few seconds of driving on maps which contain more than 2,150km of drivable roads.</p><p>2 0.9375422 <a title="222-lda-2" href="./cvpr-2013-Joint_3D_Scene_Reconstruction_and_Class_Segmentation.html">230 cvpr-2013-Joint 3D Scene Reconstruction and Class Segmentation</a></p>
<p>Author: Christian Häne, Christopher Zach, Andrea Cohen, Roland Angst, Marc Pollefeys</p><p>Abstract: Both image segmentation and dense 3D modeling from images represent an intrinsically ill-posed problem. Strong regularizers are therefore required to constrain the solutions from being ’too noisy’. Unfortunately, these priors generally yield overly smooth reconstructions and/or segmentations in certain regions whereas they fail in other areas to constrain the solution sufficiently. In this paper we argue that image segmentation and dense 3D reconstruction contribute valuable information to each other’s task. As a consequence, we propose a rigorous mathematical framework to formulate and solve a joint segmentation and dense reconstruction problem. Image segmentations provide geometric cues about which surface orientations are more likely to appear at a certain location in space whereas a dense 3D reconstruction yields a suitable regularization for the segmentation problem by lifting the labeling from 2D images to 3D space. We show how appearance-based cues and 3D surface orientation priors can be learned from training data and subsequently used for class-specific regularization. Experimental results on several real data sets highlight the advantages of our joint formulation.</p><p>3 0.93123782 <a title="222-lda-3" href="./cvpr-2013-Relative_Volume_Constraints_for_Single_View_3D_Reconstruction.html">354 cvpr-2013-Relative Volume Constraints for Single View 3D Reconstruction</a></p>
<p>Author: Eno Töppe, Claudia Nieuwenhuis, Daniel Cremers</p><p>Abstract: We introduce the concept of relative volume constraints in order to account for insufficient information in the reconstruction of 3D objects from a single image. The key idea is to formulate a variational reconstruction approach with shape priors in form of relative depth profiles or volume ratios relating object parts. Such shape priors can easily be derived either from a user sketch or from the object’s shading profile in the image. They can handle textured or shadowed object regions by propagating information. We propose a convex relaxation of the constrained optimization problem which can be solved optimally in a few seconds on graphics hardware. In contrast to existing single view reconstruction algorithms, the proposed algorithm provides substantially more flexibility to recover shape details such as self-occlusions, dents and holes, which are not visible in the object silhouette.</p><p>4 0.92002952 <a title="222-lda-4" href="./cvpr-2013-Hypergraphs_for_Joint_Multi-view_Reconstruction_and_Multi-object_Tracking.html">209 cvpr-2013-Hypergraphs for Joint Multi-view Reconstruction and Multi-object Tracking</a></p>
<p>Author: Martin Hofmann, Daniel Wolf, Gerhard Rigoll</p><p>Abstract: We generalize the network flow formulation for multiobject tracking to multi-camera setups. In the past, reconstruction of multi-camera data was done as a separate extension. In this work, we present a combined maximum a posteriori (MAP) formulation, which jointly models multicamera reconstruction as well as global temporal data association. A flow graph is constructed, which tracks objects in 3D world space. The multi-camera reconstruction can be efficiently incorporated as additional constraints on the flow graph without making the graph unnecessarily large. The final graph is efficiently solved using binary linear programming. On the PETS 2009 dataset we achieve results that significantly exceed the current state of the art.</p><p>5 0.90281689 <a title="222-lda-5" href="./cvpr-2013-Dictionary_Learning_from_Ambiguously_Labeled_Data.html">125 cvpr-2013-Dictionary Learning from Ambiguously Labeled Data</a></p>
<p>Author: Yi-Chen Chen, Vishal M. Patel, Jaishanker K. Pillai, Rama Chellappa, P. Jonathon Phillips</p><p>Abstract: We propose a novel dictionary-based learning method for ambiguously labeled multiclass classification, where each training sample has multiple labels and only one of them is the correct label. The dictionary learning problem is solved using an iterative alternating algorithm. At each iteration of the algorithm, two alternating steps are performed: a confidence update and a dictionary update. The confidence of each sample is defined as the probability distribution on its ambiguous labels. The dictionaries are updated using either soft (EM-based) or hard decision rules. Extensive evaluations on existing datasets demonstrate that the proposed method performs significantly better than state-of-the-art ambiguously labeled learning approaches.</p><p>6 0.89788818 <a title="222-lda-6" href="./cvpr-2013-Principal_Observation_Ray_Calibration_for_Tiled-Lens-Array_Integral_Imaging_Display.html">337 cvpr-2013-Principal Observation Ray Calibration for Tiled-Lens-Array Integral Imaging Display</a></p>
<p>7 0.89649075 <a title="222-lda-7" href="./cvpr-2013-Alternating_Decision_Forests.html">39 cvpr-2013-Alternating Decision Forests</a></p>
<p>8 0.88942456 <a title="222-lda-8" href="./cvpr-2013-Deformable_Spatial_Pyramid_Matching_for_Fast_Dense_Correspondences.html">107 cvpr-2013-Deformable Spatial Pyramid Matching for Fast Dense Correspondences</a></p>
<p>same-paper 9 0.87180662 <a title="222-lda-9" href="./cvpr-2013-Incorporating_User_Interaction_and_Topological_Constraints_within_Contour_Completion_via_Discrete_Calculus.html">222 cvpr-2013-Incorporating User Interaction and Topological Constraints within Contour Completion via Discrete Calculus</a></p>
<p>10 0.84196156 <a title="222-lda-10" href="./cvpr-2013-Simultaneous_Active_Learning_of_Classifiers_%26_Attributes_via_Relative_Feedback.html">396 cvpr-2013-Simultaneous Active Learning of Classifiers & Attributes via Relative Feedback</a></p>
<p>11 0.8404063 <a title="222-lda-11" href="./cvpr-2013-Multi-scale_Curve_Detection_on_Surfaces.html">298 cvpr-2013-Multi-scale Curve Detection on Surfaces</a></p>
<p>12 0.80754369 <a title="222-lda-12" href="./cvpr-2013-Boundary_Cues_for_3D_Object_Shape_Recovery.html">71 cvpr-2013-Boundary Cues for 3D Object Shape Recovery</a></p>
<p>13 0.79647231 <a title="222-lda-13" href="./cvpr-2013-Exploiting_the_Power_of_Stereo_Confidences.html">155 cvpr-2013-Exploiting the Power of Stereo Confidences</a></p>
<p>14 0.79281008 <a title="222-lda-14" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<p>15 0.78009617 <a title="222-lda-15" href="./cvpr-2013-Manhattan_Scene_Understanding_via_XSlit_Imaging.html">279 cvpr-2013-Manhattan Scene Understanding via XSlit Imaging</a></p>
<p>16 0.77830374 <a title="222-lda-16" href="./cvpr-2013-Ensemble_Learning_for_Confidence_Measures_in_Stereo_Vision.html">147 cvpr-2013-Ensemble Learning for Confidence Measures in Stereo Vision</a></p>
<p>17 0.77444941 <a title="222-lda-17" href="./cvpr-2013-A_Minimum_Error_Vanishing_Point_Detection_Approach_for_Uncalibrated_Monocular_Images_of_Man-Made_Environments.html">19 cvpr-2013-A Minimum Error Vanishing Point Detection Approach for Uncalibrated Monocular Images of Man-Made Environments</a></p>
<p>18 0.77309394 <a title="222-lda-18" href="./cvpr-2013-Wide-Baseline_Hair_Capture_Using_Strand-Based_Refinement.html">467 cvpr-2013-Wide-Baseline Hair Capture Using Strand-Based Refinement</a></p>
<p>19 0.7720992 <a title="222-lda-19" href="./cvpr-2013-SWIGS%3A_A_Swift_Guided_Sampling_Method.html">373 cvpr-2013-SWIGS: A Swift Guided Sampling Method</a></p>
<p>20 0.77178496 <a title="222-lda-20" href="./cvpr-2013-Boundary_Detection_Benchmarking%3A_Beyond_F-Measures.html">72 cvpr-2013-Boundary Detection Benchmarking: Beyond F-Measures</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
