<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>465 cvpr-2013-What Object Motion Reveals about Shape with Unknown BRDF and Lighting</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-465" href="#">cvpr2013-465</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>465 cvpr-2013-What Object Motion Reveals about Shape with Unknown BRDF and Lighting</h1>
<br/><p>Source: <a title="cvpr-2013-465-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Chandraker_What_Object_Motion_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Manmohan Chandraker, Dikpal Reddy, Yizhou Wang, Ravi Ramamoorthi</p><p>Abstract: We present a theory that addresses the problem of determining shape from the (small or differential) motion of an object with unknown isotropic reflectance, under arbitrary unknown distant illumination, , for both orthographic and perpsective projection. Our theory imposes fundamental limits on the hardness of surface reconstruction, independent of the method involved. Under orthographic projection, we prove that three differential motions suffice to yield an invariant that relates shape to image derivatives, regardless of BRDF and illumination. Under perspective projection, we show that four differential motions suffice to yield depth and a linear constraint on the surface gradient, with unknown BRDF and lighting. Further, we delineate the topological classes up to which reconstruction may be achieved using the invariants. Finally, we derive a general stratification that relates hardness of shape recovery to scene complexity. Qualitatively, our invariants are homogeneous partial differential equations for simple lighting and inhomogeneous for complex illumination. Quantitatively, our framework shows that the minimal number of motions required to resolve shape is greater for more complex scenes. Prior works that assume brightness constancy, Lambertian BRDF or a known directional light source follow as special cases of our stratification. We illustrate with synthetic and real data how potential reconstruction methods may exploit our framework.</p><p>Reference: <a title="cvpr-2013-465-reference" href="../cvpr2013_reference/cvpr-2013-What_Object_Motion_Reveals_about_Shape_with_Unknown_BRDF_and_Lighting_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract We present a theory that addresses the problem of determining shape from the (small or differential) motion of an object with unknown isotropic reflectance, under arbitrary unknown distant illumination, , for both orthographic and perpsective projection. [sent-4, score-0.937]
</p><p>2 Our theory imposes fundamental limits on the hardness of surface reconstruction, independent of the method involved. [sent-5, score-0.572]
</p><p>3 Under orthographic projection, we prove that three differential motions suffice to yield an invariant that relates shape to image derivatives, regardless of BRDF and illumination. [sent-6, score-0.904]
</p><p>4 Under perspective projection, we show that four differential motions suffice to yield depth and a linear constraint on the surface gradient, with unknown BRDF and lighting. [sent-7, score-1.261]
</p><p>5 Finally, we derive a general stratification that relates hardness of shape recovery to scene complexity. [sent-9, score-0.478]
</p><p>6 Qualitatively, our invariants are homogeneous partial differential equations for simple lighting and inhomogeneous for complex illumination. [sent-10, score-0.535]
</p><p>7 Introduction An open problem in computer vision since early works on optical flow has been to determine the shape of an object with unknown reflectance undergoing differential motion, when observed by a static camera under unknown illumination. [sent-15, score-0.993]
</p><p>8 This paper presents a theory to solve the problem for both orthographic and perspective camera projections, with arbitrary unknown distant lighting (directional or area). [sent-16, score-0.79]
</p><p>9 Unlike traditional approaches to shape recovery from motion like optical flow [6, 10] or multiview stereo [15], our theory does not make physically incorrect assumptions like brightness constancy, or simplifying ones like Lambertian reflectance. [sent-17, score-0.625]
</p><p>10 In Section 3, we correctly model the dependence of image formation on the bidirectional reflectance distribution function (BRDF) and illumination, to derive a physically valid differential flow relation. [sent-18, score-0.513]
</p><p>11 Remarkably, it can be shown that even when the BRDF and illumination are unknown, the differential flow constrains the shape of an object through an invariant relating surface depth to image derivatives. [sent-19, score-0.925]
</p><p>12 For orthographic projections, considered in Section 4, three differential motions suffice and the invariant is a  quasilinear partial differential equation (PDE). [sent-21, score-1.142]
</p><p>13 For perspective projections, we show in Section 5 that surface depth may be directly recovered from four differential motions, with an additional linear PDE constraining the surface normal. [sent-22, score-1.119]
</p><p>14 Besides characterizing the invariants, in each case, we also study the precise extent to which surface reconstruction may be performed. [sent-24, score-0.408]
</p><p>15 Notably, the brightness constancy relation popularly used in optical flow [6, 10] is a special case of our differential flow relation, as are more physically-based studies that relate the motion field to radiometric entities assuming diffuse reflectance [11, 12]. [sent-26, score-0.974]
</p><p>16 Note that the limits imposed by our theory on the hardness of motion field estimation are fundamental ones they hold true regardless of the actual reconstruction method employed. [sent-30, score-0.505]
</p><p>17 In summary, this paper makes the following contributions: • A theory that relates shape to object motion, for unknown isotropic BRDF and illumination (directional or area), under orthographic and perspective projections. [sent-31, score-0.839]
</p><p>18 A stratification of the hardness of shape recovery from motion, under various imaging conditions (Table 1). [sent-33, score-0.392]
</p><p>19 The qualitative hardness of shape from motion is indicated by the nature of reconstruction invariant and quantified by minimal number of required motions. [sent-36, score-0.452]
</p><p>20 While attempts have been made to relax the assumption for certain reflectance models [5, 12], our work provides the first unified theoretical and computational paradigm that relates shape recovery to image derivatives from object motion, with unknown BRDF and illumination. [sent-41, score-0.507]
</p><p>21 Similar to our setup, albeit limited to Lambertian reflectance and directional lighting, passive photometric stereo methods [9, 18] use object motion to reconstruct a dense depth map. [sent-44, score-0.412]
</p><p>22 recover shape under nonLambertian reflectance using an isometric relationship between change in intensity profiles under light source motion and surface normal differences [14]. [sent-53, score-0.554]
</p><p>23 The object BRDF is assumed isotropic and homogeneous (or having slow spatial variation), with an unknown functional form. [sent-62, score-0.299]
</p><p>24 μ  where  −  −  −  ,  (4)  Differential flow relation Assuming isotropic BRDF ρ, the image intensity of a 3D point x, imaged at pixel u, is I(u, t) = σ(x)ρ(n, x) , (5) where σ is the albedo and n is the surface normal at the point. [sent-90, score-0.604]
</p><p>25 The BRDF ρ is usually written as a function of incident and outgoing directions, but for fixed lighting and view, can be seen as a function of surface position and orientation. [sent-92, score-0.375]
</p><p>26 Denoting E = log I, we n(ot∇e that t(hωe ×alnb)ed =o can b∇e easily eliminated by dividing out I(u, t), to yield the differential flow relation:  (∇uE)? [sent-110, score-0.426]
</p><p>27 (8)  The differential flow relation in (7) and (8) is a strict generalization of the brightness constancy relation used by the vast majority of prior works on optical flow [6, 10]. [sent-113, score-0.808]
</p><p>28 (9)  In the following, we explore the extent to which the motion field μ and object shape may be recovered using (8), under both orthographic and perspective image formation. [sent-120, score-0.554]
</p><p>29 Precisely, we show that it is possible to eliminate all BRDF and lighting effects in an image sequence, leaving a simple relationship between image derivatives, surface depths and normals. [sent-121, score-0.455]
</p><p>30 Orthographic Projection In this section, we consider recovery of the shape of an object with unknown BRDF, using a sequence of differential motions. [sent-123, score-0.619]
</p><p>31 (13) Note thatpi, qi and ωi are known from the images and calibration, while surface depth z and the entity π related to normals and BRDF are unknown. [sent-133, score-0.365]
</p><p>32 Under orthographic projection, surface depth under unknown BRDF may not be unambiguously recovered using solely motion as the cue. [sent-138, score-0.88]
</p><p>33 BRDF-Invariant Constraints on Surface While one may not use (10) directly to obtain depth, we may still exploit the rank deficiency to infer information about the surface depth, as stated by the following: Proposition 2. [sent-141, score-0.363]
</p><p>34 For an object with unknown BRDF, observed under unknown lighting and orthographic camera, three differential motions suffice to yield a BRDF and lighting invariant relation between image derivatives and surface geometry. [sent-142, score-1.796]
</p><p>35 Thus, we may directly relate surface depth and gradient to image intensity, even for unknown BRDF and illumination. [sent-174, score-0.587]
</p><p>36 Surface Depth Estimation Next, we consider the precise extent to which surface depth may be recovered using Proposition 2. [sent-178, score-0.468]
</p><p>37 Two or more differential motions of a surface with unknown BRDF, with a colocated source and sensor, yield level curves of surface depth, corresponding to known depths of some (possibly isolated) points on the surface. [sent-187, score-1.555]
</p><p>38 Thus, (19) allows reconstruction of level curves of the surface, with unknown BRDF, under colocated illumination. [sent-205, score-0.479]
</p><p>39 Note that (19) is a first-order, homogeneous, quasilinear partial differential equation (PDE). [sent-206, score-0.399]
</p><p>40 Three or more differential motions of a surface with unknown BRDF, under unknown illumination, yield characteristic surface curves C(x(s) , y(s) , z(s)), defined by  λ1+1 λ2zddsx = λ3+1 λ4zddsy = −γ41ddzs  (25)  corresponding to depths at some (possibly isolated) points. [sent-209, score-1.642]
</p><p>41 Given orthographic images (left) under five differential motions of a surface with non-Lambertian BRDF under colocated illumination, level curves of the surface are reconstructed using (24) (center). [sent-213, score-1.408]
</p><p>42 The surface may be reconstructed by interpolating between the level curves (right). [sent-215, score-0.401]
</p><p>43 Given orthographic images (left) under five differential motions of a surface with non-Lambertian BRDF under unknown lighting, characteristic curves of (25) are reconstructed (center). [sent-218, score-1.253]
</p><p>44 The surface is reconstructed by interpolating between the characteristic curves (right). [sent-220, score-0.424]
</p><p>45 Note that dz is zero for the colocated case since characteristic curves correspond to level curves of depth, while it is in general non-zero for the non-colocated case. [sent-230, score-0.338]
</p><p>46 Figure 1illustrates the characteristic curves recovered for a synthetic sphere and vase, rendered under colocated illumination. [sent-232, score-0.308]
</p><p>47 Orthographic images are recorded for five differential motions, with arbitrary rotations of approximately 0. [sent-233, score-0.337]
</p><p>48 After computing depths along several characteristic curves using the BRDF-invariant relation (23), we interpolate depths between the curves, to recover the entire surface geometry. [sent-236, score-0.664]
</p><p>49 Surprisingly, we obtain even stronger results in the perspective case, showing that with four or more differential motions with unknown BRDF, we can directly recover surface depth, as well as a linear constraint on the derivatives of the depth. [sent-240, score-1.135]
</p><p>50 Differential Flow Relation In the perspective case, one may rewrite (8) as (compare to the linear relation in (10) for the orthographic case),  p? [sent-245, score-0.439]
</p><p>51 Now, one may derive a theory similar to the orthographic case by treating z/(1 + βz), 1/(1 + βz) and π as independent variables and using the rank deficiency (note the form ofp? [sent-257, score-0.358]
</p><p>52 ) arising from a sequence of m ≥ 4 differential motions. [sent-258, score-0.297]
</p><p>53 ×  Instead, in the following, we take a closer look at the perspective equations for differential flow, to show that they yield a more comprehensive solution for surface geometry. [sent-260, score-0.723]
</p><p>54 BRDF-Invariant Depth Estimation We demonstrate that under perspective projection, object motion can completely specify the surface depth, without any initial information: Proposition 5. [sent-263, score-0.469]
</p><p>55 Four or more differential motions of a surface with unknown BRDF, under unknown illumination, suffice to yield under perspective projection: (i) the surface depth (ii) a linear constraint on the derivatives of surface depth. [sent-264, score-2.041]
</p><p>56 (32)  +  +  Thus, in the perspective case, one may directly use (3 1) to recover the surface depth. [sent-321, score-0.439]
</p><p>57 4 = 0, (33) which is a linear constraint on surface depth derivatives. [sent-325, score-0.365]
</p><p>58 Three or more differential motions of a surface with unknown BRDF, under unknown illumination, suffice to yield under perspective projection the surface depth and the slope of the gradient. [sent-331, score-1.77]
</p><p>59 Thus, we have shown that in the perspective case, even when BRDF and illumination are unknown, one may derive an invariant that relates shape to object motion, through a linear relation and a linear PDE on the surface depth. [sent-332, score-0.764]
</p><p>60 1 Direct Depth Recovery As established by Proposition 5, under perspective projection, one may directly recover the surface depth using (3 1). [sent-338, score-0.539]
</p><p>61 An object with unknown BRDF is imaged with perspective projection under unknown illumination after undergoing four arbitrary differential motions (approximately 0. [sent-340, score-1.218]
</p><p>62 Note that no prior knowledge of the surface is required in the perspective case, even at isolated points. [sent-342, score-0.406]
</p><p>63 (a) One of five images (four motions) under perspective projection, with arbitrary non-Lambertian BRDF and unknown lighting. [sent-353, score-0.343]
</p><p>64 (a) One of five images (four motions), with arbitrary nonLambertian BRDF and unknown lighting, under perspective projection. [sent-356, score-0.343]
</p><p>65 The object is imaged under perspective projection after undergoing five random differential motions (approximately 0. [sent-361, score-0.717]
</p><p>66 Stratification of Shape from Motion Our theory not only shows the possibility of shape recovery  under unknown BRDFs and lighting, but also derives the minimum computational and imaging budget required and the precise extent to which surface shape may be recovered. [sent-364, score-0.809]
</p><p>67 In this section, we discuss how this work establishes a theoretical notion that relates the hardness of surface reconstruction to the scene complexity, which supports our intuitive understanding of an “easy” reconstruction problem versus a “hard” one. [sent-365, score-0.639]
</p><p>68 Generalization of [1] For the Lambertian BRDF, under known directional lighting, Basri and Frolova [1] show that shape and image derivatives may be related by a quasilinear PDE. [sent-366, score-0.331]
</p><p>69 In particular, the framework of this paper can also handle general BRDFs, unknown directional or area lighting and various camera projections. [sent-392, score-0.409]
</p><p>70 Shape may be recovered under Lambertian BRDF and known lighting with one motion, while an unknown BRDF with colocated lighting requires two motions under orthography and three under perspective projection. [sent-394, score-0.954]
</p><p>71 An unknown BRDF, unknown illumination and perspective projection may be considered an even “harder” reconstruction problem, for which the minimal imaging requirement is four motions. [sent-395, score-0.749]
</p><p>72 Similarly, simpler illuminations like colocated lighting result in a homogeneous PDE, while more complex illuminations make the PDE inhomogeneous, whose solution is arguably harder. [sent-396, score-0.343]
</p><p>73 Thus, the nature of the reconstruction invariant is a qualitative indicator of the hardness of shape from motion. [sent-397, score-0.331]
</p><p>74 For a given scene complexity, the hardness of reconstruction is quantified by the minimum number of motions specified by our theory for reconstruction to be possible. [sent-398, score-0.636]
</p><p>75 The camera is calibrated and a hand-eye calibration is performed to transform the gyroscope motions into the camera coordinate system. [sent-408, score-0.304]
</p><p>76 222555222866  motions, of a real object with unknown BRDF, acquired under unknown illumination. [sent-414, score-0.376]
</p><p>77 (Right) Views of surface reconstructed using the theory of Section 5. [sent-416, score-0.396]
</p><p>78 In Figure 5, we show the reconstruction for a porcelain bas-relief sculpture with fine depth variations, using six differential motions. [sent-424, score-0.48]
</p><p>79 The reconstructed surface using the solution in (3 1) is shown on the right. [sent-426, score-0.294]
</p><p>80 This demonstrates the practical utility of our theory which does not assume brightness constancy or simplified forms of the BRDF and illumination, rather it correctly accounts for shading changes through an invariant that eliminates the BRDF and lighting. [sent-428, score-0.311]
</p><p>81 Again, note that the unknown BRDF is clearly nonLambertian and the lighting is unknown, yet our theory allows surface reconstruction with fine details. [sent-430, score-0.748]
</p><p>82 Discussion and Future Work This paper answers the question of what motion reveals about shape, with unknown isotropic BRDF and arbitrary, unknown distant illumination, for orthographic and perspective projections. [sent-432, score-0.85]
</p><p>83 We derive differential flow invariants that relate image derivatives to shape and exactly characterize the object geometry that can be recovered. [sent-433, score-0.575]
</p><p>84 This work generalizes traditional notions of brightness constancy or Lambertian BRDFs in the optical flow and multiview stereo literatures. [sent-434, score-0.335]
</p><p>85 (Left)Oneofel veni putimages,relatedbytendifer n-  tial motions, of a real object with unknown BRDF, acquired under unknown illumination. [sent-436, score-0.376]
</p><p>86 (Center) Top view of the surface reconstructed using the theory of Section 5. [sent-438, score-0.396]
</p><p>87 Correctly accounting for intensity variations, in spite of unknown BRDF and illumination, allows us to recover surface details such as the fine striations between the lobes of the shell. [sent-440, score-0.478]
</p><p>88 Our results are not just valid for a particular approach to reconstruction, rather they impose fundamental limits on the hardness of surface reconstruction. [sent-441, score-0.47]
</p><p>89 In the process, we also present a stratification of shape from motion that relates hardness of reconstruction to scene complexity qualitatively in terms of the nature of the involved PDE and quantitatively in terms of the minimum number of required motions. [sent-442, score-0.545]
</p><p>90 This work and previous results have shown that differential motions carry rich information, independent of the lighting and BRDF. [sent-447, score-0.59]
</p><p>91 This paper developed a general theory to understand the information carried in the motion cue, while prior works like [3] have taken a first step towards considering differential photometric stereo for the lighting cue. [sent-448, score-0.68]
</p><p>92 An interesting future direction would be to consider small viewpoint changes, as well as a unified framework that combines all the differential cues. [sent-449, score-0.297]
</p><p>93 Following optical flow studies [11, 17], we make a distinction between entities directly expressed in terms of intrinsic surface coordinates (such as albedo) and those expressed in 3D coordinates (such as camera direction). [sent-459, score-0.474]
</p><p>94 The 3D position vector of a point on the surface at time t is x(a, b, t), while the corresponding surface normal is n(a, b, t). [sent-460, score-0.554]
</p><p>95 (37) The isotropic BRDF on the surface is a function of normal and position, denoted by ρ(n, x). [sent-466, score-0.362]
</p><p>96 δt  (39)  where the surface entities correspond to (a? [sent-496, score-0.309]
</p><p>97 2 establishesi t=hat 1 t,·he· integral surface of (42), S : z = u(x, y), is indeed the surface under consideration and the Scoe :f zfi =cien ut( xfu,yn)ctions can be obtained from three or more differential motions of the surface. [sent-522, score-1.01]
</p><p>98 This completes the proof that the characteristic curves C, given by (25), reside on the surface S. [sent-544, score-0.395]
</p><p>99 A theory of differential photometric stereo for unknown isotropic BRDFs. [sent-565, score-0.742]
</p><p>100 Dense shape reconstruction of a moving object under arbitrary, unknown lighting. [sent-644, score-0.331]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('brdf', 0.589), ('differential', 0.297), ('surface', 0.265), ('unknown', 0.188), ('motions', 0.183), ('pde', 0.162), ('orthographic', 0.161), ('hardness', 0.153), ('colocated', 0.135), ('perspective', 0.115), ('lighting', 0.11), ('stratification', 0.105), ('theory', 0.102), ('quasilinear', 0.102), ('depth', 0.1), ('lambertian', 0.094), ('proposition', 0.09), ('motion', 0.089), ('illumination', 0.085), ('relation', 0.084), ('flow', 0.083), ('reconstruction', 0.083), ('brdfs', 0.081), ('depths', 0.08), ('recovery', 0.074), ('curves', 0.073), ('isotropic', 0.073), ('directional', 0.073), ('constancy', 0.069), ('reflectance', 0.068), ('suffice', 0.067), ('brightness', 0.064), ('derivatives', 0.062), ('shape', 0.06), ('characteristic', 0.057), ('projection', 0.056), ('relates', 0.055), ('ev', 0.052), ('frolova', 0.051), ('inhomogeneous', 0.048), ('stereo', 0.047), ('ramamoorthi', 0.046), ('yield', 0.046), ('rewrite', 0.045), ('gyroscope', 0.045), ('optical', 0.044), ('entities', 0.044), ('eu', 0.044), ('chandraker', 0.044), ('recovered', 0.043), ('zx', 0.042), ('invariants', 0.042), ('nonlambertian', 0.042), ('shading', 0.041), ('arbitrary', 0.04), ('zy', 0.039), ('imaged', 0.039), ('camera', 0.038), ('homogeneous', 0.038), ('distant', 0.036), ('orthography', 0.036), ('albedo', 0.036), ('invariant', 0.035), ('photometric', 0.035), ('may', 0.034), ('setup', 0.034), ('reconstructedsurface', 0.034), ('simakov', 0.034), ('physically', 0.034), ('relations', 0.033), ('quantified', 0.032), ('derive', 0.031), ('dikpal', 0.03), ('deficiency', 0.03), ('canas', 0.03), ('illuminations', 0.03), ('reconstructed', 0.029), ('zickler', 0.029), ('helmholtz', 0.028), ('inputimage', 0.028), ('ravi', 0.028), ('multiview', 0.028), ('basri', 0.027), ('undergoing', 0.027), ('fundamental', 0.027), ('span', 0.026), ('pseudoinverse', 0.026), ('extent', 0.026), ('isolated', 0.026), ('field', 0.026), ('limits', 0.025), ('recover', 0.025), ('vanishes', 0.024), ('reciprocity', 0.024), ('nec', 0.024), ('pz', 0.024), ('normal', 0.024), ('specular', 0.023), ('source', 0.023), ('radiometric', 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="465-tfidf-1" href="./cvpr-2013-What_Object_Motion_Reveals_about_Shape_with_Unknown_BRDF_and_Lighting.html">465 cvpr-2013-What Object Motion Reveals about Shape with Unknown BRDF and Lighting</a></p>
<p>Author: Manmohan Chandraker, Dikpal Reddy, Yizhou Wang, Ravi Ramamoorthi</p><p>Abstract: We present a theory that addresses the problem of determining shape from the (small or differential) motion of an object with unknown isotropic reflectance, under arbitrary unknown distant illumination, , for both orthographic and perpsective projection. Our theory imposes fundamental limits on the hardness of surface reconstruction, independent of the method involved. Under orthographic projection, we prove that three differential motions suffice to yield an invariant that relates shape to image derivatives, regardless of BRDF and illumination. Under perspective projection, we show that four differential motions suffice to yield depth and a linear constraint on the surface gradient, with unknown BRDF and lighting. Further, we delineate the topological classes up to which reconstruction may be achieved using the invariants. Finally, we derive a general stratification that relates hardness of shape recovery to scene complexity. Qualitatively, our invariants are homogeneous partial differential equations for simple lighting and inhomogeneous for complex illumination. Quantitatively, our framework shows that the minimal number of motions required to resolve shape is greater for more complex scenes. Prior works that assume brightness constancy, Lambertian BRDF or a known directional light source follow as special cases of our stratification. We illustrate with synthetic and real data how potential reconstruction methods may exploit our framework.</p><p>2 0.47343358 <a title="465-tfidf-2" href="./cvpr-2013-Calibrating_Photometric_Stereo_by_Holistic_Reflectance_Symmetry_Analysis.html">75 cvpr-2013-Calibrating Photometric Stereo by Holistic Reflectance Symmetry Analysis</a></p>
<p>Author: Zhe Wu, Ping Tan</p><p>Abstract: Under unknown directional lighting, the uncalibrated Lambertian photometric stereo algorithm recovers the shape of a smooth surface up to the generalized bas-relief (GBR) ambiguity. We resolve this ambiguity from the halfvector symmetry, which is observed in many isotropic materials. Under this symmetry, a 2D BRDF slice with low-rank structure can be obtained from an image, if the surface normals and light directions are correctly recovered. In general, this structure is destroyed by the GBR ambiguity. As a result, we can resolve the ambiguity by restoring this structure. We develop a simple algorithm of auto-calibration from separable homogeneous specular reflection of real images. Compared with previous methods, this method takes a holistic approach to exploiting reflectance symmetry and produces superior results.</p><p>3 0.36370289 <a title="465-tfidf-3" href="./cvpr-2013-Multi-view_Photometric_Stereo_with_Spatially_Varying_Isotropic_Materials.html">303 cvpr-2013-Multi-view Photometric Stereo with Spatially Varying Isotropic Materials</a></p>
<p>Author: Zhenglong Zhou, Zhe Wu, Ping Tan</p><p>Abstract: We present a method to capture both 3D shape and spatially varying reflectance with a multi-view photometric stereo technique that works for general isotropic materials. Our data capture setup is simple, which consists of only a digital camera and a handheld light source. From a single viewpoint, we use a set of photometric stereo images to identify surface points with the same distance to the camera. We collect this information from multiple viewpoints and combine it with structure-from-motion to obtain a precise reconstruction of the complete 3D shape. The spatially varying isotropic bidirectional reflectance distributionfunction (BRDF) is captured by simultaneously inferring a set of basis BRDFs and their mixing weights at each surface point. According to our experiments, the captured shapes are accurate to 0.3 millimeters. The captured reflectance has relative root-mean-square error (RMSE) of 9%.</p><p>4 0.34332025 <a title="465-tfidf-4" href="./cvpr-2013-BRDF_Slices%3A_Accurate_Adaptive_Anisotropic_Appearance_Acquisition.html">54 cvpr-2013-BRDF Slices: Accurate Adaptive Anisotropic Appearance Acquisition</a></p>
<p>Author: Jirí Filip, Radomír Vávra, Michal Haindl, Pavel Žid, Mikuláš Krupika, Vlastimil Havran</p><p>Abstract: In this paper we introduce unique publicly available dense anisotropic BRDF data measurements. We use this dense data as a reference for performance evaluation of the proposed BRDF sparse angular sampling and interpolation approach. The method is based on sampling of BRDF subspaces at fixed elevations by means of several adaptively-represented, uniformly distributed, perpendicular slices. Although this proposed method requires only a sparse sampling of material, the interpolation provides a very accurate reconstruction, visually and computationally comparable to densely measured reference. Due to the simple slices measurement and method’s robustness it allows for a highly accurate acquisition of BRDFs. This in comparison with standard uniform angular sampling, is considerably faster yet uses far less samples.</p><p>5 0.2265723 <a title="465-tfidf-5" href="./cvpr-2013-Uncalibrated_Photometric_Stereo_for_Unknown_Isotropic_Reflectances.html">443 cvpr-2013-Uncalibrated Photometric Stereo for Unknown Isotropic Reflectances</a></p>
<p>Author: Feng Lu, Yasuyuki Matsushita, Imari Sato, Takahiro Okabe, Yoichi Sato</p><p>Abstract: We propose an uncalibrated photometric stereo method that works with general and unknown isotropic reflectances. Our method uses a pixel intensity profile, which is a sequence of radiance intensities recorded at a pixel across multi-illuminance images. We show that for general isotropic materials, the geodesic distance between intensity profiles is linearly related to the angular difference of their surface normals, and that the intensity distribution of an intensity profile conveys information about the reflectance properties, when the intensity profile is obtained under uniformly distributed directional lightings. Based on these observations, we show that surface normals can be estimated up to a convex/concave ambiguity. A solution method based on matrix decomposition with missing data is developed for a reliable estimation. Quantitative and qualitative evaluations of our method are performed using both synthetic and real-world scenes.</p><p>6 0.22531359 <a title="465-tfidf-6" href="./cvpr-2013-Template-Based_Isometric_Deformable_3D_Reconstruction_with_Sampling-Based_Focal_Length_Self-Calibration.html">423 cvpr-2013-Template-Based Isometric Deformable 3D Reconstruction with Sampling-Based Focal Length Self-Calibration</a></p>
<p>7 0.19647835 <a title="465-tfidf-7" href="./cvpr-2013-Learning_Discriminative_Illumination_and_Filters_for_Raw_Material_Classification_with_Optimal_Projections_of_Bidirectional_Texture_Functions.html">251 cvpr-2013-Learning Discriminative Illumination and Filters for Raw Material Classification with Optimal Projections of Bidirectional Texture Functions</a></p>
<p>8 0.19618632 <a title="465-tfidf-8" href="./cvpr-2013-A_New_Perspective_on_Uncalibrated_Photometric_Stereo.html">21 cvpr-2013-A New Perspective on Uncalibrated Photometric Stereo</a></p>
<p>9 0.18209188 <a title="465-tfidf-9" href="./cvpr-2013-Analytic_Bilinear_Appearance_Subspace_Construction_for_Modeling_Image_Irradiance_under_Natural_Illumination_and_Non-Lambertian_Reflectance.html">42 cvpr-2013-Analytic Bilinear Appearance Subspace Construction for Modeling Image Irradiance under Natural Illumination and Non-Lambertian Reflectance</a></p>
<p>10 0.15996383 <a title="465-tfidf-10" href="./cvpr-2013-Mirror_Surface_Reconstruction_from_a_Single_Image.html">286 cvpr-2013-Mirror Surface Reconstruction from a Single Image</a></p>
<p>11 0.14779282 <a title="465-tfidf-11" href="./cvpr-2013-Large_Displacement_Optical_Flow_from_Nearest_Neighbor_Fields.html">244 cvpr-2013-Large Displacement Optical Flow from Nearest Neighbor Fields</a></p>
<p>12 0.1397081 <a title="465-tfidf-12" href="./cvpr-2013-Intrinsic_Scene_Properties_from_a_Single_RGB-D_Image.html">227 cvpr-2013-Intrinsic Scene Properties from a Single RGB-D Image</a></p>
<p>13 0.13321914 <a title="465-tfidf-13" href="./cvpr-2013-Intrinsic_Characterization_of_Dynamic_Surfaces.html">226 cvpr-2013-Intrinsic Characterization of Dynamic Surfaces</a></p>
<p>14 0.12350707 <a title="465-tfidf-14" href="./cvpr-2013-Shading-Based_Shape_Refinement_of_RGB-D_Images.html">394 cvpr-2013-Shading-Based Shape Refinement of RGB-D Images</a></p>
<p>15 0.12263364 <a title="465-tfidf-15" href="./cvpr-2013-Dense_Reconstruction_Using_3D_Object_Shape_Priors.html">111 cvpr-2013-Dense Reconstruction Using 3D Object Shape Priors</a></p>
<p>16 0.12057285 <a title="465-tfidf-16" href="./cvpr-2013-Multi-scale_Curve_Detection_on_Surfaces.html">298 cvpr-2013-Multi-scale Curve Detection on Surfaces</a></p>
<p>17 0.11233475 <a title="465-tfidf-17" href="./cvpr-2013-Boundary_Cues_for_3D_Object_Shape_Recovery.html">71 cvpr-2013-Boundary Cues for 3D Object Shape Recovery</a></p>
<p>18 0.10715658 <a title="465-tfidf-18" href="./cvpr-2013-A_Theory_of_Refractive_Photo-Light-Path_Triangulation.html">27 cvpr-2013-A Theory of Refractive Photo-Light-Path Triangulation</a></p>
<p>19 0.10381584 <a title="465-tfidf-19" href="./cvpr-2013-Determining_Motion_Directly_from_Normal_Flows_Upon_the_Use_of_a_Spherical_Eye_Platform.html">124 cvpr-2013-Determining Motion Directly from Normal Flows Upon the Use of a Spherical Eye Platform</a></p>
<p>20 0.099062361 <a title="465-tfidf-20" href="./cvpr-2013-Monocular_Template-Based_3D_Reconstruction_of_Extensible_Surfaces_with_Local_Linear_Elasticity.html">289 cvpr-2013-Monocular Template-Based 3D Reconstruction of Extensible Surfaces with Local Linear Elasticity</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/cvpr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.178), (1, 0.301), (2, 0.0), (3, 0.087), (4, -0.06), (5, -0.177), (6, -0.154), (7, 0.034), (8, 0.063), (9, 0.009), (10, -0.083), (11, -0.114), (12, -0.107), (13, -0.116), (14, 0.148), (15, 0.121), (16, 0.253), (17, -0.163), (18, -0.03), (19, -0.095), (20, 0.003), (21, -0.099), (22, 0.004), (23, 0.077), (24, -0.01), (25, -0.08), (26, -0.073), (27, 0.047), (28, -0.003), (29, 0.024), (30, -0.193), (31, 0.036), (32, -0.005), (33, -0.05), (34, -0.019), (35, -0.029), (36, 0.073), (37, -0.038), (38, 0.044), (39, -0.024), (40, 0.109), (41, 0.006), (42, 0.03), (43, 0.038), (44, -0.058), (45, -0.011), (46, -0.03), (47, -0.029), (48, 0.077), (49, 0.083)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.94162416 <a title="465-lsi-1" href="./cvpr-2013-Calibrating_Photometric_Stereo_by_Holistic_Reflectance_Symmetry_Analysis.html">75 cvpr-2013-Calibrating Photometric Stereo by Holistic Reflectance Symmetry Analysis</a></p>
<p>Author: Zhe Wu, Ping Tan</p><p>Abstract: Under unknown directional lighting, the uncalibrated Lambertian photometric stereo algorithm recovers the shape of a smooth surface up to the generalized bas-relief (GBR) ambiguity. We resolve this ambiguity from the halfvector symmetry, which is observed in many isotropic materials. Under this symmetry, a 2D BRDF slice with low-rank structure can be obtained from an image, if the surface normals and light directions are correctly recovered. In general, this structure is destroyed by the GBR ambiguity. As a result, we can resolve the ambiguity by restoring this structure. We develop a simple algorithm of auto-calibration from separable homogeneous specular reflection of real images. Compared with previous methods, this method takes a holistic approach to exploiting reflectance symmetry and produces superior results.</p><p>same-paper 2 0.93022025 <a title="465-lsi-2" href="./cvpr-2013-What_Object_Motion_Reveals_about_Shape_with_Unknown_BRDF_and_Lighting.html">465 cvpr-2013-What Object Motion Reveals about Shape with Unknown BRDF and Lighting</a></p>
<p>Author: Manmohan Chandraker, Dikpal Reddy, Yizhou Wang, Ravi Ramamoorthi</p><p>Abstract: We present a theory that addresses the problem of determining shape from the (small or differential) motion of an object with unknown isotropic reflectance, under arbitrary unknown distant illumination, , for both orthographic and perpsective projection. Our theory imposes fundamental limits on the hardness of surface reconstruction, independent of the method involved. Under orthographic projection, we prove that three differential motions suffice to yield an invariant that relates shape to image derivatives, regardless of BRDF and illumination. Under perspective projection, we show that four differential motions suffice to yield depth and a linear constraint on the surface gradient, with unknown BRDF and lighting. Further, we delineate the topological classes up to which reconstruction may be achieved using the invariants. Finally, we derive a general stratification that relates hardness of shape recovery to scene complexity. Qualitatively, our invariants are homogeneous partial differential equations for simple lighting and inhomogeneous for complex illumination. Quantitatively, our framework shows that the minimal number of motions required to resolve shape is greater for more complex scenes. Prior works that assume brightness constancy, Lambertian BRDF or a known directional light source follow as special cases of our stratification. We illustrate with synthetic and real data how potential reconstruction methods may exploit our framework.</p><p>3 0.8321861 <a title="465-lsi-3" href="./cvpr-2013-Uncalibrated_Photometric_Stereo_for_Unknown_Isotropic_Reflectances.html">443 cvpr-2013-Uncalibrated Photometric Stereo for Unknown Isotropic Reflectances</a></p>
<p>Author: Feng Lu, Yasuyuki Matsushita, Imari Sato, Takahiro Okabe, Yoichi Sato</p><p>Abstract: We propose an uncalibrated photometric stereo method that works with general and unknown isotropic reflectances. Our method uses a pixel intensity profile, which is a sequence of radiance intensities recorded at a pixel across multi-illuminance images. We show that for general isotropic materials, the geodesic distance between intensity profiles is linearly related to the angular difference of their surface normals, and that the intensity distribution of an intensity profile conveys information about the reflectance properties, when the intensity profile is obtained under uniformly distributed directional lightings. Based on these observations, we show that surface normals can be estimated up to a convex/concave ambiguity. A solution method based on matrix decomposition with missing data is developed for a reliable estimation. Quantitative and qualitative evaluations of our method are performed using both synthetic and real-world scenes.</p><p>4 0.82725459 <a title="465-lsi-4" href="./cvpr-2013-Multi-view_Photometric_Stereo_with_Spatially_Varying_Isotropic_Materials.html">303 cvpr-2013-Multi-view Photometric Stereo with Spatially Varying Isotropic Materials</a></p>
<p>Author: Zhenglong Zhou, Zhe Wu, Ping Tan</p><p>Abstract: We present a method to capture both 3D shape and spatially varying reflectance with a multi-view photometric stereo technique that works for general isotropic materials. Our data capture setup is simple, which consists of only a digital camera and a handheld light source. From a single viewpoint, we use a set of photometric stereo images to identify surface points with the same distance to the camera. We collect this information from multiple viewpoints and combine it with structure-from-motion to obtain a precise reconstruction of the complete 3D shape. The spatially varying isotropic bidirectional reflectance distributionfunction (BRDF) is captured by simultaneously inferring a set of basis BRDFs and their mixing weights at each surface point. According to our experiments, the captured shapes are accurate to 0.3 millimeters. The captured reflectance has relative root-mean-square error (RMSE) of 9%.</p><p>5 0.77725446 <a title="465-lsi-5" href="./cvpr-2013-BRDF_Slices%3A_Accurate_Adaptive_Anisotropic_Appearance_Acquisition.html">54 cvpr-2013-BRDF Slices: Accurate Adaptive Anisotropic Appearance Acquisition</a></p>
<p>Author: Jirí Filip, Radomír Vávra, Michal Haindl, Pavel Žid, Mikuláš Krupika, Vlastimil Havran</p><p>Abstract: In this paper we introduce unique publicly available dense anisotropic BRDF data measurements. We use this dense data as a reference for performance evaluation of the proposed BRDF sparse angular sampling and interpolation approach. The method is based on sampling of BRDF subspaces at fixed elevations by means of several adaptively-represented, uniformly distributed, perpendicular slices. Although this proposed method requires only a sparse sampling of material, the interpolation provides a very accurate reconstruction, visually and computationally comparable to densely measured reference. Due to the simple slices measurement and method’s robustness it allows for a highly accurate acquisition of BRDFs. This in comparison with standard uniform angular sampling, is considerably faster yet uses far less samples.</p><p>6 0.70645362 <a title="465-lsi-6" href="./cvpr-2013-Analytic_Bilinear_Appearance_Subspace_Construction_for_Modeling_Image_Irradiance_under_Natural_Illumination_and_Non-Lambertian_Reflectance.html">42 cvpr-2013-Analytic Bilinear Appearance Subspace Construction for Modeling Image Irradiance under Natural Illumination and Non-Lambertian Reflectance</a></p>
<p>7 0.70263374 <a title="465-lsi-7" href="./cvpr-2013-A_New_Perspective_on_Uncalibrated_Photometric_Stereo.html">21 cvpr-2013-A New Perspective on Uncalibrated Photometric Stereo</a></p>
<p>8 0.59488517 <a title="465-lsi-8" href="./cvpr-2013-Spectral_Modeling_and_Relighting_of_Reflective-Fluorescent_Scenes.html">409 cvpr-2013-Spectral Modeling and Relighting of Reflective-Fluorescent Scenes</a></p>
<p>9 0.56691557 <a title="465-lsi-9" href="./cvpr-2013-Towards_Contactless%2C_Low-Cost_and_Accurate_3D_Fingerprint_Identification.html">435 cvpr-2013-Towards Contactless, Low-Cost and Accurate 3D Fingerprint Identification</a></p>
<p>10 0.53442836 <a title="465-lsi-10" href="./cvpr-2013-Learning_Discriminative_Illumination_and_Filters_for_Raw_Material_Classification_with_Optimal_Projections_of_Bidirectional_Texture_Functions.html">251 cvpr-2013-Learning Discriminative Illumination and Filters for Raw Material Classification with Optimal Projections of Bidirectional Texture Functions</a></p>
<p>11 0.52231151 <a title="465-lsi-11" href="./cvpr-2013-Template-Based_Isometric_Deformable_3D_Reconstruction_with_Sampling-Based_Focal_Length_Self-Calibration.html">423 cvpr-2013-Template-Based Isometric Deformable 3D Reconstruction with Sampling-Based Focal Length Self-Calibration</a></p>
<p>12 0.50534159 <a title="465-lsi-12" href="./cvpr-2013-Intrinsic_Characterization_of_Dynamic_Surfaces.html">226 cvpr-2013-Intrinsic Characterization of Dynamic Surfaces</a></p>
<p>13 0.50488067 <a title="465-lsi-13" href="./cvpr-2013-Monocular_Template-Based_3D_Reconstruction_of_Extensible_Surfaces_with_Local_Linear_Elasticity.html">289 cvpr-2013-Monocular Template-Based 3D Reconstruction of Extensible Surfaces with Local Linear Elasticity</a></p>
<p>14 0.44961673 <a title="465-lsi-14" href="./cvpr-2013-Mirror_Surface_Reconstruction_from_a_Single_Image.html">286 cvpr-2013-Mirror Surface Reconstruction from a Single Image</a></p>
<p>15 0.43890724 <a title="465-lsi-15" href="./cvpr-2013-Multi-scale_Curve_Detection_on_Surfaces.html">298 cvpr-2013-Multi-scale Curve Detection on Surfaces</a></p>
<p>16 0.43454981 <a title="465-lsi-16" href="./cvpr-2013-Sensing_and_Recognizing_Surface_Textures_Using_a_GelSight_Sensor.html">391 cvpr-2013-Sensing and Recognizing Surface Textures Using a GelSight Sensor</a></p>
<p>17 0.40554333 <a title="465-lsi-17" href="./cvpr-2013-Photometric_Ambient_Occlusion.html">330 cvpr-2013-Photometric Ambient Occlusion</a></p>
<p>18 0.40244645 <a title="465-lsi-18" href="./cvpr-2013-Relative_Volume_Constraints_for_Single_View_3D_Reconstruction.html">354 cvpr-2013-Relative Volume Constraints for Single View 3D Reconstruction</a></p>
<p>19 0.39705047 <a title="465-lsi-19" href="./cvpr-2013-A_Theory_of_Refractive_Photo-Light-Path_Triangulation.html">27 cvpr-2013-A Theory of Refractive Photo-Light-Path Triangulation</a></p>
<p>20 0.39240783 <a title="465-lsi-20" href="./cvpr-2013-Shading-Based_Shape_Refinement_of_RGB-D_Images.html">394 cvpr-2013-Shading-Based Shape Refinement of RGB-D Images</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/cvpr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.092), (16, 0.036), (26, 0.098), (28, 0.015), (33, 0.272), (66, 0.078), (67, 0.034), (69, 0.038), (83, 0.131), (87, 0.11)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.92222029 <a title="465-lda-1" href="./cvpr-2013-Single_Image_Calibration_of_Multi-axial_Imaging_Systems.html">400 cvpr-2013-Single Image Calibration of Multi-axial Imaging Systems</a></p>
<p>Author: Amit Agrawal, Srikumar Ramalingam</p><p>Abstract: Imaging systems consisting of a camera looking at multiple spherical mirrors (reflection) or multiple refractive spheres (refraction) have been used for wide-angle imaging applications. We describe such setups as multi-axial imaging systems, since a single sphere results in an axial system. Assuming an internally calibrated camera, calibration of such multi-axial systems involves estimating the sphere radii and locations in the camera coordinate system. However, previous calibration approaches require manual intervention or constrained setups. We present a fully automatic approach using a single photo of a 2D calibration grid. The pose of the calibration grid is assumed to be unknown and is also recovered. Our approach can handle unconstrained setups, where the mirrors/refractive balls can be arranged in any fashion, not necessarily on a grid. The axial nature of rays allows us to compute the axis of each sphere separately. We then show that by choosing rays from two or more spheres, the unknown pose of the calibration grid can be obtained linearly and independently of sphere radii and locations. Knowing the pose, we derive analytical solutions for obtaining the sphere radius and location. This leads to an interesting result that 6-DOF pose estimation of a multi-axial camera can be done without the knowledge of full calibration. Simulations and real experiments demonstrate the applicability of our algorithm.</p><p>same-paper 2 0.91868693 <a title="465-lda-2" href="./cvpr-2013-What_Object_Motion_Reveals_about_Shape_with_Unknown_BRDF_and_Lighting.html">465 cvpr-2013-What Object Motion Reveals about Shape with Unknown BRDF and Lighting</a></p>
<p>Author: Manmohan Chandraker, Dikpal Reddy, Yizhou Wang, Ravi Ramamoorthi</p><p>Abstract: We present a theory that addresses the problem of determining shape from the (small or differential) motion of an object with unknown isotropic reflectance, under arbitrary unknown distant illumination, , for both orthographic and perpsective projection. Our theory imposes fundamental limits on the hardness of surface reconstruction, independent of the method involved. Under orthographic projection, we prove that three differential motions suffice to yield an invariant that relates shape to image derivatives, regardless of BRDF and illumination. Under perspective projection, we show that four differential motions suffice to yield depth and a linear constraint on the surface gradient, with unknown BRDF and lighting. Further, we delineate the topological classes up to which reconstruction may be achieved using the invariants. Finally, we derive a general stratification that relates hardness of shape recovery to scene complexity. Qualitatively, our invariants are homogeneous partial differential equations for simple lighting and inhomogeneous for complex illumination. Quantitatively, our framework shows that the minimal number of motions required to resolve shape is greater for more complex scenes. Prior works that assume brightness constancy, Lambertian BRDF or a known directional light source follow as special cases of our stratification. We illustrate with synthetic and real data how potential reconstruction methods may exploit our framework.</p><p>3 0.90287673 <a title="465-lda-3" href="./cvpr-2013-Three-Dimensional_Bilateral_Symmetry_Plane_Estimation_in_the_Phase_Domain.html">432 cvpr-2013-Three-Dimensional Bilateral Symmetry Plane Estimation in the Phase Domain</a></p>
<p>Author: Ramakrishna Kakarala, Prabhu Kaliamoorthi, Vittal Premachandran</p><p>Abstract: We show that bilateral symmetry plane estimation for three-dimensional (3-D) shapes may be carried out accurately, and efficiently, in the spherical harmonic domain. Our methods are valuable for applications where spherical harmonic expansion is already employed, such as 3-D shape registration, morphometry, and retrieval. We show that the presence of bilateral symmetry in the 3-D shape is equivalent to a linear phase structure in the corresponding spherical harmonic coefficients, and provide algorithms for estimating the orientation of the symmetry plane. The benefit of using spherical harmonic phase is that symmetry estimation reduces to matching a compact set of descriptors, without the need to solve a correspondence problem. Our methods work on point clouds as well as large-scale mesh models of 3-D shapes.</p><p>4 0.901205 <a title="465-lda-4" href="./cvpr-2013-Calibrating_Photometric_Stereo_by_Holistic_Reflectance_Symmetry_Analysis.html">75 cvpr-2013-Calibrating Photometric Stereo by Holistic Reflectance Symmetry Analysis</a></p>
<p>Author: Zhe Wu, Ping Tan</p><p>Abstract: Under unknown directional lighting, the uncalibrated Lambertian photometric stereo algorithm recovers the shape of a smooth surface up to the generalized bas-relief (GBR) ambiguity. We resolve this ambiguity from the halfvector symmetry, which is observed in many isotropic materials. Under this symmetry, a 2D BRDF slice with low-rank structure can be obtained from an image, if the surface normals and light directions are correctly recovered. In general, this structure is destroyed by the GBR ambiguity. As a result, we can resolve the ambiguity by restoring this structure. We develop a simple algorithm of auto-calibration from separable homogeneous specular reflection of real images. Compared with previous methods, this method takes a holistic approach to exploiting reflectance symmetry and produces superior results.</p><p>5 0.89871842 <a title="465-lda-5" href="./cvpr-2013-Discovering_the_Structure_of_a_Planar_Mirror_System_from_Multiple_Observations_of_a_Single_Point.html">127 cvpr-2013-Discovering the Structure of a Planar Mirror System from Multiple Observations of a Single Point</a></p>
<p>Author: Ilya Reshetouski, Alkhazur Manakov, Ayush Bandhari, Ramesh Raskar, Hans-Peter Seidel, Ivo Ihrke</p><p>Abstract: We investigate the problem of identifying the position of a viewer inside a room of planar mirrors with unknown geometry in conjunction with the room’s shape parameters. We consider the observations to consist of angularly resolved depth measurements of a single scene point that is being observed via many multi-bounce interactions with the specular room geometry. Applications of this problem statement include areas such as calibration, acoustic echo cancelation and time-of-flight imaging. We theoretically analyze the problem and derive sufficient conditions for a combination of convex room geometry, observer, and scene point to be reconstructable. The resulting constructive algorithm is exponential in nature and, therefore, not directly applicable to practical scenarios. To counter the situation, we propose theoretically devised geometric constraints that enable an efficient pruning of the solution space and develop a heuristic randomized search algorithm that uses these constraints to obtain an effective solution. We demonstrate the effectiveness of our algorithm on extensive simulations as well as in a challenging real-world calibration scenario.</p><p>6 0.89763302 <a title="465-lda-6" href="./cvpr-2013-Multi-view_Photometric_Stereo_with_Spatially_Varying_Isotropic_Materials.html">303 cvpr-2013-Multi-view Photometric Stereo with Spatially Varying Isotropic Materials</a></p>
<p>7 0.8968668 <a title="465-lda-7" href="./cvpr-2013-A_New_Perspective_on_Uncalibrated_Photometric_Stereo.html">21 cvpr-2013-A New Perspective on Uncalibrated Photometric Stereo</a></p>
<p>8 0.89466792 <a title="465-lda-8" href="./cvpr-2013-Intrinsic_Scene_Properties_from_a_Single_RGB-D_Image.html">227 cvpr-2013-Intrinsic Scene Properties from a Single RGB-D Image</a></p>
<p>9 0.89446449 <a title="465-lda-9" href="./cvpr-2013-Uncalibrated_Photometric_Stereo_for_Unknown_Isotropic_Reflectances.html">443 cvpr-2013-Uncalibrated Photometric Stereo for Unknown Isotropic Reflectances</a></p>
<p>10 0.89211583 <a title="465-lda-10" href="./cvpr-2013-Dense_Non-rigid_Point-Matching_Using_Random_Projections.html">109 cvpr-2013-Dense Non-rigid Point-Matching Using Random Projections</a></p>
<p>11 0.88430357 <a title="465-lda-11" href="./cvpr-2013-Radial_Distortion_Self-Calibration.html">344 cvpr-2013-Radial Distortion Self-Calibration</a></p>
<p>12 0.88172489 <a title="465-lda-12" href="./cvpr-2013-Shading-Based_Shape_Refinement_of_RGB-D_Images.html">394 cvpr-2013-Shading-Based Shape Refinement of RGB-D Images</a></p>
<p>13 0.88072872 <a title="465-lda-13" href="./cvpr-2013-Exemplar-Based_Face_Parsing.html">152 cvpr-2013-Exemplar-Based Face Parsing</a></p>
<p>14 0.87995958 <a title="465-lda-14" href="./cvpr-2013-Boundary_Cues_for_3D_Object_Shape_Recovery.html">71 cvpr-2013-Boundary Cues for 3D Object Shape Recovery</a></p>
<p>15 0.87992114 <a title="465-lda-15" href="./cvpr-2013-Robust_Real-Time_Tracking_of_Multiple_Objects_by_Volumetric_Mass_Densities.html">365 cvpr-2013-Robust Real-Time Tracking of Multiple Objects by Volumetric Mass Densities</a></p>
<p>16 0.87783021 <a title="465-lda-16" href="./cvpr-2013-Maximum_Cohesive_Grid_of_Superpixels_for_Fast_Object_Localization.html">280 cvpr-2013-Maximum Cohesive Grid of Superpixels for Fast Object Localization</a></p>
<p>17 0.87760401 <a title="465-lda-17" href="./cvpr-2013-Occlusion_Patterns_for_Object_Class_Detection.html">311 cvpr-2013-Occlusion Patterns for Object Class Detection</a></p>
<p>18 0.87712461 <a title="465-lda-18" href="./cvpr-2013-Dense_Reconstruction_Using_3D_Object_Shape_Priors.html">111 cvpr-2013-Dense Reconstruction Using 3D Object Shape Priors</a></p>
<p>19 0.87678379 <a title="465-lda-19" href="./cvpr-2013-Ensemble_Learning_for_Confidence_Measures_in_Stereo_Vision.html">147 cvpr-2013-Ensemble Learning for Confidence Measures in Stereo Vision</a></p>
<p>20 0.87631953 <a title="465-lda-20" href="./cvpr-2013-A_Minimum_Error_Vanishing_Point_Detection_Approach_for_Uncalibrated_Monocular_Images_of_Man-Made_Environments.html">19 cvpr-2013-A Minimum Error Vanishing Point Detection Approach for Uncalibrated Monocular Images of Man-Made Environments</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
