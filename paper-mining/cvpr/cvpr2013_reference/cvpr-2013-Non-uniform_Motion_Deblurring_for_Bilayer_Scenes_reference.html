<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>307 cvpr-2013-Non-uniform Motion Deblurring for Bilayer Scenes</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-307" href="../cvpr2013/cvpr-2013-Non-uniform_Motion_Deblurring_for_Bilayer_Scenes.html">cvpr2013-307</a> <a title="cvpr-2013-307-reference" href="#">cvpr2013-307-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>307 cvpr-2013-Non-uniform Motion Deblurring for Bilayer Scenes</h1>
<br/><p>Source: <a title="cvpr-2013-307-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Paramanand_Non-uniform_Motion_Deblurring_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Chandramouli Paramanand, Ambasamudram N. Rajagopalan</p><p>Abstract: We address the problem of estimating the latent image of a static bilayer scene (consisting of a foreground and a background at different depths) from motion blurred observations captured with a handheld camera. The camera motion is considered to be composed of in-plane rotations and translations. Since the blur at an image location depends both on camera motion and depth, deblurring becomes a difficult task. We initially propose a method to estimate the transformation spread function (TSF) corresponding to one of the depth layers. The estimated TSF (which reveals the camera motion during exposure) is used to segment the scene into the foreground and background layers and determine the relative depth value. The deblurred image of the scene is finally estimated within a regularization framework by accounting for blur variations due to camera motion as well as depth.</p><br/>
<h2>reference text</h2><p>[1] http : / /www .us a . canon . com/ cus a / con sume r / st andard_di spl ay/ Lens_Advant age_I S .</p>
<p>[2] J. Chen, L. Yuan, C. K. Tang, and L. Quan. Robust dual motion deblurring. In Proc. CVPR, 2008.</p>
<p>[3] S. Cho, H. Cho, Y. Tai, and S. Lee. Non-uniform motion deblurring for camera shakes using image registration. In SIGGRAPH Talks, 2011.</p>
<p>[4] S. Cho, Y. Matsushita, and S. Lee. Removing non-uniform motion blur from images. In Proc. ICCV, 2007.</p>
<p>[5] P. F. Felzenszwalb and D. P. Huttenlocher. Efficient graph-based image segmentation. Intl. Jrnl. Comp. Vis., 2004.</p>
<p>[6] P. F. Felzenszwalb and D. P. Huttenlocher. Efficient belief propagation for early vision. Intl. Jrnl. Comp. Vis., 2006.</p>
<p>[7] R. Fergus, B. Singh, A. Hertzmann, S. T. Roweis, and W. T. Freeman. Removing camera shake from a single photograph. ACM Transactions on Graphics, 25(3):787–794, 2006.</p>
<p>[8] A. Gupta, N. Joshi, L. Zitnick, M. Cohen, and B. Curless. Single image deblurring using motion density functions. In Proc. ECCV, 2010.</p>
<p>[9] M. Hirsch, C. J. Schuler, S. Harmeling, and B. Scholkopf. Fast removal of non-uniform camera shake. In Proc. ICCV, 2011.</p>
<p>[10] Z. Hu and M. Yang. Fast non-uniform deblurring using constrained camera pose subspace. In Proc. BMVC, 2012.</p>
<p>[11] H. Ji and K. Wang. A two-stage approach to blind spatially-varying motion deblurring. In Proc. CVPR, 2012.</p>
<p>[12] N. Joshi, S. B. Kang, L. Zitnick, and R. Szeliski. Image deblurring using inertial measurement sensors. In Proc. SIGGRAPH, 2010.</p>
<p>[13] D. Krishnan, T. Tay, and R. Fergus. Blind deconvolution using a normalized sparsity measure. In Proc. CVPR, 2011.</p>
<p>[14] A. Levin, Y. Weiss, F. Durand, and W. T. Freeman. Understanding and evaluating blind deconvolution algorithms. In Proc. CVPR, 2009.</p>
<p>[15] J. Liu, S. Ji, and J. Ye. Slep: Sparse learning with efficient projections. 2009. http://www.public.asu.edu/ jye02/Software/SLEP.</p>
<p>[16] Q. Shan, J. Jia, and A. Agarwala. High-quality motion deblurring from a single image. ACM Transactions on Graphics, 27(3). 1 1 1 1 121 121 9 9  Figure 2. The blurred observations are shown in rows 1 and 3, first two columns. The estimated latent image is shown in the last column (rows 1 and 3). Rows 2 and 4: zoomed-in patches of the reference depth layer. Row 5: zoomed-in regions from the blurred observations, restored image and deblurred image when parallax was ignored (in each of the two sets of patches). Row 6: First and third images- output from [10], second and fourth images- output of [23].</p>
<p>[17] M. Sorel and J. Flusser. Space-variant restoration of images degraded by camera motion blur. IEEE Trans. Imag. Proc., 17(2): 105–1 16, 2008.</p>
<p>[18] F. Sroubek and J. Flusser. Multichannel blind deconvolution of spatially misaligned images. IEEE Trans. Imag. Proc., 14(7):874–883, 2005.  scenes under projective motion path. IEEE Trans. Patt. Anal. Mach. Intell., 33(8): 1603–1618, 2011.</p>
<p>[22] R. Vio, J. Nagy, and W. Wamsteker. Blind motion deblurring using multiple images. Jrnl Comput. Phy., 228(14):5057–5071, 2009.</p>
<p>[23] O. Whyte, J. Sivic, A. Zisserman, and J. Ponce. Non-uniform deblurring for shaken images. In Proc. CVPR, 2010.</p>
<p>[19] A. Stein, D. Hoiem, and M. Hebert. Learning to find object bound-</p>
<p>[24] L. Xu and J. Jia. Two-phase kernel estimation for robust motion  aries using motion cues. In Proc. ICCV, 2007.  deblurring. In Proc. ECCV, 2010.</p>
<p>[25] 2L0.1 X2u. and J. Jia. Depth-aware motion deblur ing.</p>
<p>[20] Ypr.o Tjaeci,ti Nv.e K moontgio,n S d.e Lbinlu,r arnindg S.. In Y. P Srohcin. C CVoPdRe,d 2 e0x1p0o.sure imaging for</p>
<p>[21] Y. Tai, P. Tan, and M. S. Brown.  Richardson-lucy deblurring for 1 1 1 1 1 12 2 2 20 0  In Proc. ICCP,</p>
<br/>
<br/><br/><br/></body>
</html>
