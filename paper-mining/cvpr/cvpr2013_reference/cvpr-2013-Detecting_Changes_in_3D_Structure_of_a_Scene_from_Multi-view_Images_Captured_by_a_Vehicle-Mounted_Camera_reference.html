<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>117 cvpr-2013-Detecting Changes in 3D Structure of a Scene from Multi-view Images Captured by a Vehicle-Mounted Camera</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-117" href="../cvpr2013/cvpr-2013-Detecting_Changes_in_3D_Structure_of_a_Scene_from_Multi-view_Images_Captured_by_a_Vehicle-Mounted_Camera.html">cvpr2013-117</a> <a title="cvpr-2013-117-reference" href="#">cvpr2013-117-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>117 cvpr-2013-Detecting Changes in 3D Structure of a Scene from Multi-view Images Captured by a Vehicle-Mounted Camera</h1>
<br/><p>Source: <a title="cvpr-2013-117-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Sakurada_Detecting_Changes_in_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Ken Sakurada, Takayuki Okatani, Koichiro Deguchi</p><p>Abstract: This paper proposes a method for detecting temporal changes of the three-dimensional structure of an outdoor scene from its multi-view images captured at two separate times. For the images, we consider those captured by a camera mounted on a vehicle running in a city street. The method estimates scene structures probabilistically, not deterministically, and based on their estimates, it evaluates the probability of structural changes in the scene, where the inputs are the similarity of the local image patches among the multi-view images. The aim of the probabilistic treatment is to maximize the accuracy of change detection, behind which there is our conjecture that although it is difficult to estimate the scene structures deterministically, it should be easier to detect their changes. The proposed method is compared with the methods that use multi-view stereo (MVS) to reconstruct the scene structures of the two time points and then differentiate them to detect changes. The experimental results show that the proposed method outperforms such MVS-based methods.</p><br/>
<h2>reference text</h2><p>[1] S. Agarwal, N. Snavely, I. Simon, S. M. Seitz, and R. Szeliski. Building Rome in a day. In ICCV, pages 72–79, 2009.</p>
<p>[2] D. Crandall, A. Owens, N. Snavely, and D. Huttenlocher. DiscreteContinuous Optimization for Large-Scale Structure from Motion. In CVPR, pages 3001–3008, 2011.</p>
<p>[3] D. Crispell, J. Mundy, and G. Taubin. A Variable-Resolution Probabilistic Three-Dimensional Model for Change Detection. Geoscience and Remote Sensing, 50(2):489–500, 2012.</p>
<p>[4] M. A. Fischler and R. C. Bolles. Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography. Communications of the ACM, 24(6):381– 395, 1981.</p>
<p>[5] Y. Furukawa and J. Ponce. Accurate, Dense, and Robust Multi-View Stereopsis. PAMI, 32(8): 1362–1376, 2010.</p>
<p>[6] R. Hartley and A. Zisserman. Multiple View Geometry in Computer Vision Second Edition. Cambridge University Press, 2004.</p>
<p>[7] A. Huertas and R. Nevatia. Detecting Changes in Aerial Views of Man-Made Structures. In ICCV, pages 73–80, 1998.</p>
<p>[8] D. C. Ibrahim Eden. Using 3D Line Segments for Robust and Efficient Change Detection from Multiple Noisy Images. In ECCV, pages 172–185, 2008.</p>
<p>[9] S. B. Kang, R. Szeliski, and J. Chai. Handling Occlusions in Dense Multi-view Stereo. In CVPR, pages I–103–I–1 10, 2001.</p>
<p>[10] V. Kolmogorov and R. Zabih. What energy functions can be minimized via graph cuts? PAMI, 26(2): 147–59, 2004.</p>
<p>[11] D. G. Lowe. Distinctive Image Features from Scale-Invariant Keypoints. IJCV, 60(2):91–1 10, 2004.</p>
<p>[12] T. Pollard and J. L. Mundy. Change Detection in a 3-d World. In CVPR, pages 1–6, 2007.</p>
<p>[13] M. Pollefeys, D. Nist e´r, J.-M. Frahm, A. Akbarzadeh, P. Mordohai, B. Clipp, C. Engels, D. Gallup, S.-J. Kim, P. Merrell, C. Salmi, S. Sinha, B. Talton, L. Wang, Q. Yang, H. Stew e´nius, R. Yang, G. Welch, and H. Towles. Detailed Real-Time Urban 3D Reconstruction from Video. IJCV, 78(2-3):143–167, 2008.</p>
<p>[14] R. J. Radke, S. Andra, O. Al-Kofahi, and B. Roysam. Image Change Detection Algorithms: A Systematic Survey. TRANSACTIONS ON IMAGE PROCESSING, 14(3):294–307, 2005.</p>
<p>[15] G. Schindler and F. Dellaert. Probabilistic temporal inference on reconstructed 3D scenes. In CVPR, pages 1410–1417, 2010.</p>
<p>[16] S. Seitz, B. Curless, J. Diebel, D. Scharstein, and R. Szeliski. A Comparison and Evaluation of Multi-View Stereo Reconstruction Algorithms. In CVPR, pages 519–528, 2006.</p>
<p>[17] N. Snavely, S. M. Seitz, and R. Szeliski. Modeling the World from Internet Photo Collections. IJCV, 80(2): 189–210, 2007.</p>
<p>[18] A. Taneja, L. Ballan, and M. Pollefeys. Image based detection of geometric changes in urban environments. In ICCV, pages 2336– 2343, 2011.</p>
<p>[19] E. Tola, V. Lepetit, and P. Fua. DAISY: An Efficient Dense Descriptor Applied to Wide-Baseline Stereo. PAMI, 32(5):815–830, 2010.</p>
<p>[20] A. Torii, M. Havlena, and T. Pajdla. From Google Street View to 3D City Models. In ICCV Workshops, pages 2188–2195, 2009.</p>
<p>[21] B. Triggs, P. McLauchlan, R. Hartley, and A. Fitzgibbon. Bundle Adjustment - Modern Synthesis. In ICCV, pages 298–372, 1999.</p>
<p>[22] C. Zhang, L. Wang, and R. Yang. Semantic Segmentation of Urban Scenes Using Dense Depth Maps. In ECCV, pages 708–721, 2010.</p>
<p>[23] G. Zhang, J. Jia, T.-t. Wong, and H. Bao. Recovering Consistent Video Depth Maps via Bundle Optimization. In CVPR, pages 1–8, 2008.</p>
<p>[24]  G. Zhang, J. Jia, W. Xiong, T.-T. Wong, P.-A. Heng, and H. Bao. Moving Object Extraction with a Hand-held Camera. In ICCV, pages 1–8, 2007. 111444333  I? dnesagDec te th Images/Ground TruthProposed(0.76)PMVS2(0.59)Patch-MVS(0.53)SIFT-MVS(0.71) I? round truthG roposedP SM-SFVIT(a)(b)(c)(d)(e)(f)(g) P SIrMaoFtcpTVh-oSMse2dVSTable0 (. 26a48.) 69F1s0c (o.b462r3e)1870sof 0th(.76 ce)9735detc0 t(.de786)d5106cha0n(.g6875e)02s6ho0 w(.69n5f)718inF0 g(.97 68)237.Av0 e.86r5a326ge  Figure 7. Results of the proposed method and the three MVS-based ones for a scene. From left to right columns, the input images and the ground truth, the results of the proposed methods, and those of PMVS2, Patch-MVS, and SIFT-MVS, respectively. The third row shows the detected changes. The numbers in their captions are the F1 scores representing accuracy of the detection.  Figure 8. Results for other images. From top to bottom rows, I?, hand-marked ground truths, results of the proposed method, and those of SIFT-MVS.  111 444444</p>
<br/>
<br/><br/><br/></body>
</html>
