<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>431 cvpr-2013-The Variational Structure of Disparity and Regularization of 4D Light Fields</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-431" href="../cvpr2013/cvpr-2013-The_Variational_Structure_of_Disparity_and_Regularization_of_4D_Light_Fields.html">cvpr2013-431</a> <a title="cvpr-2013-431-reference" href="#">cvpr2013-431-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>431 cvpr-2013-The Variational Structure of Disparity and Regularization of 4D Light Fields</h1>
<br/><p>Source: <a title="cvpr-2013-431-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Goldluecke_The_Variational_Structure_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Bastian Goldluecke, Sven Wanner</p><p>Abstract: Unlike traditional images which do not offer information for different directions of incident light, a light field is defined on ray space, and implicitly encodes scene geometry data in a rich structure which becomes visible on its epipolar plane images. In this work, we analyze regularization of light fields in variational frameworks and show that their variational structure is induced by disparity, which is in this context best understood as a vector field on epipolar plane image space. We derive differential constraints on this vector field to enable consistent disparity map regularization. Furthermore, we show how the disparity field is related to the regularization of more general vector-valued functions on the 4D ray space of the light field. This way, we derive an efficient variational framework with convex priors, which can serve as a fundament for a large class of inverse problems on ray space.</p><br/>
<h2>reference text</h2><p>[1] A. Beck and M. Teboulle. Fast iterative shrinkagethresholding algorithm for linear inverse problems. SIAM J. Imaging Sciences, 2: 183–202, 2009.</p>
<p>[2] T. Bishop and P. Favaro. The light field camera: Extended depth of field, aliasing, and superresolution. IEEE Transactions on Pattern Analysis and Machine Intelligence, 34(5):972–986, 2012.</p>
<p>[3] R. Bolles, H. Baker, and D. Marimont. Epipolar-plane image analysis: An approach to determining structure from motion. International Journal of Computer Vision, 1(1):7–55, 1987.</p>
<p>[4] A. Chambolle and T. Pock. A first-order primal-dual algorithm for convex problems with applications to imaging. J. Math. Imaging Vis., 40(1): 120–145, 2011.</p>
<p>[5] A. Criminisi, S. Kang, R. Swaminathan, R. Szeliski, and P. Anandan. Extracting layers and analyzing their specular properties using epipolar-plane-image analysis. Computer vision and image understanding, 97(1):5 1–85, 2005.</p>
<p>[6] B. Goldluecke, E. Strekalovskiy, and D. Cremers. The natural vectorial total variation which arises from geometric measure theory. SIAM Journal on Imaging Sciences, 5(2):537– 563, 2012.</p>
<p>[7] S. Gortler, R. Grzeszczuk, R. Szeliski, and M. Cohen. The Lumigraph. In Proc. SIGGRAPH, pages 43–54, 1996.</p>
<p>[8] K. Kolev, T. Pock, and D. Cremers. Anisotropic minimal surfaces integrating photoconsistency and normal informa11111000000000079977  Input viewLinear interpolation  InputdisparityLinearinterpolation  Lightfieldinpaint g,Li htfieldinpaint g Disparitymapina tingIpaint gwithconstrains interpolated disparity  inpainted disparity  Figure 8. Light field inpainting for view interpolation. Intermediate views in the upsampled light field were marked as unknown regions before solving the inpainting model (12). Images in the two top rows above show, from left to right, closeups of one of the input views, a novel view generated by linear interpolation, i.e. standard light field rendering, a novel view generated by inpainting with interpolated disparity quantities, and finally a novel view generated by inpainting with disparity quantities also recovered via inpainting. In the bottom row, one can compare disparity fields in the unknown regions generated with different methods. In particular, we can see that the optimal way to infer disparity is via inpainting and additional observation of the local constraints (5). Results obtained via inpainting are generally sharper than those obtained via interpolation and show less ghosting artifacts.  tion for multiview Computer Vision,  stereo. In Proc. European Conference  2010.  on</p>
<p>[9] M. Levoy. Light fields and computational imaging. Computer, 39(8):46–55, 2006.</p>
<p>[10] M. Levoy and P. Hanrahan. Light field rendering. In Proc. SIGGRAPH, pages 31–42, 1996.</p>
<p>[11] A. Lumsdaine and T. Georgiev. The focused plenoptic camera. In In Proc. IEEE International Conference on Computational Photography, pages 1–8, 2009.</p>
<p>[12] R. Ng. Digital Light Field Photography. PhD thesis, Stanford University, 2006. Note: thesis led to commercial light field camera, see also www . lyt ro . com.</p>
<p>[13] C. Perwass and L. Wietzke. The next generation of photography, 2010. www . rayt rix . de.</p>
<p>[14] S. Wanner and B. Goldluecke. Globally consistent depth labeling of 4D light fields. In Proc. International Conference on Computer Vision and Pattern Recognition, pages 41–48, 2012.</p>
<p>[15] S. Wanner and B. Goldluecke. Spatial and angular variational super-resolution of 4D light fields. In Proc. European Conference on Computer Vision, 2012.</p>
<p>[16] S. Wanner, C. Straehle, and B. Goldluecke. Globally consistent multi-label assignment on the ray space of 4D light fields. In Proc. International Conference on Computer Vision and Pattern Recognition, 2013.</p>
<p>[17] B. Wilburn, N. Joshi, V. Vaish, E.-V. Talvala, E. Antunez, A. Barth, A. Adams, M. Horowitz, and M. Levoy. High performance imaging using large camera arrays. ACM Transactions on Graphics, 24:765–776, July 2005.</p>
<p>[18] C. Zach, M. Niethammer, and J.-M. Frahm. Continuous maximal flows and Wulff shapes: Application to MRFs. In Proc. International Conference on Computer Vision and Pattern Recognition, 2009.  1 1 10 0 0 0 1 80 8</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
