<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>3 cvpr-2013-3D R Transform on Spatio-temporal Interest Points for Action Recognition</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-3" href="../cvpr2013/cvpr-2013-3D_R_Transform_on_Spatio-temporal_Interest_Points_for_Action_Recognition.html">cvpr2013-3</a> <a title="cvpr-2013-3-reference" href="#">cvpr2013-3-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>3 cvpr-2013-3D R Transform on Spatio-temporal Interest Points for Action Recognition</h1>
<br/><p>Source: <a title="cvpr-2013-3-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Yuan_3D_R_Transform_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Chunfeng Yuan, Xi Li, Weiming Hu, Haibin Ling, Stephen Maybank</p><p>Abstract: Spatio-temporal interest points serve as an elementary building block in many modern action recognition algorithms, and most of them exploit the local spatio-temporal volume features using a Bag of Visual Words (BOVW) representation. Such representation, however, ignorespotentially valuable information about the global spatio-temporal distribution of interest points. In this paper, we propose a new global feature to capture the detailed geometrical distribution of interest points. It is calculated by using the ℛ transform which is defined as an extended 3D discrete Rℛa tdroann transform, followed by applying a tewdo 3-dDir decitsicorneatel two-dimensional principal component analysis. Such ℛ feature captures the geometrical information of the Sinuctehre ℛst points and keeps invariant to geometry transformation and robust to noise. In addition, we propose a new fusion strategy to combine the ℛ feature with the BOVW representation for further improving recognition accuracy. Wpree suetnilitzaea context-aware fusion method to capture both the pairwise similarities and higher-order contextual interactions of the videos. Experimental results on several publicly available datasets demonstrate the effectiveness of the proposed approach for action recognition.</p><br/>
<h2>reference text</h2><p>[1] I. Laptev. On space-time interest points. IJCV, Vol.64, No.2, pp.107123, 2005.</p>
<p>[2] H. Wang, M. M. Ullah, A. Kl¨ aser, I. Laptev, C. Schmid. Evaluation of local spatio-temporal features for action recognition. In BMVC, 2009.</p>
<p>[3] Y. Shkolnisky, and A. Averbuch. 3D Fourier Based Discrete Radon Transform. Applied and Computational Harmonic Analysis, Vol.15, No.1, pp.33-69(37), 2003.</p>
<p>[4] S. Tabbone, L. Wendling, J. Salmon. A new shape descriptor defined on the Radon transform. CVIU, pp.42-51, 2006.</p>
<p>[5] P. Daras, D. Zarpalas, D. Tzovaras, and M. G. Strintzis. Shape Matching using the 3D Radon Tranform. In 3DPVT, 2004.</p>
<p>[6] D. Zhang, and Z. Zhou. (2퐷)2PCA: 2-Directional 2-Dimensional PCA for Efficient Face Representation and Recognition. Neurocomputing, Vol.69, No.1-3, pp.224-231, 2005.</p>
<p>[7] S. Lazebnik, C. Schmid, and J. Ponce. Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories. In CVPR, pp.2169-2178, 2006.</p>
<p>[8] I. Laptev, M. Marszalek, C. Schmid, and B. Rozenfeld. Learning realistic human actions from movies. In CVPR, 2008.</p>
<p>[9] J. Choi, W. J. Jeon, and S. C. Lee. Spatio-Temporal Pyramid Matching for Sports Videos. In ACM MIR, 2008.</p>
<p>[10] M. Bregonzio, S. Gong and T. Xiang. Recognising Action as Clouds of Space-Time Interest Points. In CVPR, 2009.</p>
<p>[11] L. Wang, H. Zhou, S.-C. Low, and C. Leckie. Action Recognition via Multi-Feature Fusion and Gaussian Process Classification. In WACV, 2009.</p>
<p>[12] X. Sun, M. Chen, and A. Hauptmann. Action recognition via local descriptors and holistic features. In CVPR, 2009.</p>
<p>[13] J. Liu, J. Luo, and M. Shah. Action Recognition in Unconstrained Amateur Videos. In ICASSP, pp.3549-3552, 2009.</p>
<p>[14] Y. Ye, L. Qin, Z. Cheng, Q. Huang. Recognizing Realistic Action Using Contextual Feature Group. In PCM, 2011.</p>
<p>[15] M. Bregonzio, T. Xiang, S. Gong. Fusing appearance and distribution information of interest points for action recognition. Pattern Recognition, Vol.45, No.3, pp. 1220-1234, 2012.</p>
<p>[16] H. Sahbi, and X. Li. Context Dependent SVMs for Interconnected Image Network Annotation. In ACM MM, 2010.</p>
<p>[17] X. Li , A. Dick, H. Wang, C. Shen, and A. van den Hengel. Graph mode-based contextual kernels for robust SVM tracking. In ICCV, 2011.</p>
<p>[18] Y. Wang, K. Huang, and T. Tan. Human Activity Recognition Based on ℛ Transform. In CVPR, 2007.</p>
<p>[19] J. Yang, D. Zhang, A.F. Frangi, and J. Yang, Two-dimensional PCA: a new approach to appearance-based face representation and recognition. PAMI, VOL. 26, NO. 1, pp.131-137, 2004.</p>
<p>[20] C. Schuldt, I. Laptev, and B. Caputo. Recognizing Human Actions: A Local SVM Approach. In ICPR, pp.32-36, 2004.</p>
<p>[21] M. D. Rodriguez, J. Ahmed, and M. Shah. Action MACH: a spatiotemporal maximum average correlation height filter for action recognition. In CVPR, 2008.</p>
<p>[22] A. Kovashka, and K. Grauman. Learning a Hierarchy ofDiscriminative Space-Time Neighborhood Features for Human Action Recognition. In CVPR, 2010.</p>
<p>[23] L. Yeffet, and L.Wolf. Local trinary patterns for human action recognition. In ICCV, 2009.</p>
<p>[24] Q. V. Le, W. Y. Zou, S. Y. Yeung, and A. Y. Ng. Learning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis. In CVPR, pp. 3361-3368, 2011.</p>
<p>[25] H. Wang, A. Kl¨ aser, I. Laptev, C. Schmid, C. L. Liu. Action Recognition by Dense Trajectories. In CVPR, pp.3169-3 176, 2011. 7 7 7 32 23208 808</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
