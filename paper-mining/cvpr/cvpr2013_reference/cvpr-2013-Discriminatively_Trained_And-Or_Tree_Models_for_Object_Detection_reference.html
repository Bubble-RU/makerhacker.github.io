<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>136 cvpr-2013-Discriminatively Trained And-Or Tree Models for Object Detection</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-136" href="../cvpr2013/cvpr-2013-Discriminatively_Trained_And-Or_Tree_Models_for_Object_Detection.html">cvpr2013-136</a> <a title="cvpr-2013-136-reference" href="#">cvpr2013-136-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>136 cvpr-2013-Discriminatively Trained And-Or Tree Models for Object Detection</h1>
<br/><p>Source: <a title="cvpr-2013-136-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Song_Discriminatively_Trained_And-Or_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Xi Song, Tianfu Wu, Yunde Jia, Song-Chun Zhu</p><p>Abstract: This paper presents a method of learning reconfigurable And-Or Tree (AOT) models discriminatively from weakly annotated data for object detection. To explore the appearance and geometry space of latent structures effectively, we first quantize the image lattice using an overcomplete set of shape primitives, and then organize them into a directed acyclic And-Or Graph (AOG) by exploiting their compositional relations. We allow overlaps between child nodes when combining them into a parent node, which is equivalent to introducing an appearance Or-node implicitly for the overlapped portion. The learning of an AOT model consists of three components: (i) Unsupervised sub-category learning (i.e., branches of an object Or-node) with the latent structures in AOG being integrated out. (ii) Weaklysupervised part configuration learning (i.e., seeking the globally optimal parse trees in AOG for each sub-category). To search the globally optimal parse tree in AOG efficiently, we propose a dynamic programming (DP) algorithm. (iii) Joint appearance and structural parameters training under latent structural SVM framework. In experiments, our method is tested on PASCAL VOC 2007 and 2010 detection , benchmarks of 20 object classes and outperforms comparable state-of-the-art methods.</p><br/>
<h2>reference text</h2><br/>
<br/><br/><br/></body>
</html>
