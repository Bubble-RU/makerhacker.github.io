<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>150 cvpr-2013-Event Recognition in Videos by Learning from Heterogeneous Web Sources</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-150" href="../cvpr2013/cvpr-2013-Event_Recognition_in_Videos_by_Learning_from_Heterogeneous_Web_Sources.html">cvpr2013-150</a> <a title="cvpr-2013-150-reference" href="#">cvpr2013-150-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>150 cvpr-2013-Event Recognition in Videos by Learning from Heterogeneous Web Sources</h1>
<br/><p>Source: <a title="cvpr-2013-150-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Chen_Event_Recognition_in_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Lin Chen, Lixin Duan, Dong Xu</p><p>Abstract: In this work, we propose to leverage a large number of loosely labeled web videos (e.g., from YouTube) and web images (e.g., from Google/Bing image search) for visual event recognition in consumer videos without requiring any labeled consumer videos. We formulate this task as a new multi-domain adaptation problem with heterogeneous sources, in which the samples from different source domains can be represented by different types of features with different dimensions (e.g., the SIFTfeaturesfrom web images and space-time (ST) features from web videos) while the target domain samples have all types of features. To effectively cope with the heterogeneous sources where some source domains are more relevant to the target domain, we propose a new method called Multi-domain Adaptation with Heterogeneous Sources (MDA-HS) to learn an optimal target classifier, in which we simultaneously seek the optimal weights for different source domains with different types of features as well as infer the labels of unlabeled target domain data based on multiple types of features. We solve our optimization problem by using the cutting-plane algorithm based on group-based multiple kernel learning. Comprehensive experiments on two datasets demonstrate the effectiveness of MDA-HS for event recognition in consumer videos.</p><br/>
<h2>reference text</h2><p>[1] Y. Aytar and A. Zisserman. Tabula rasa: Model transfer for object category detection. In ICCV, 2011.</p>
<p>[2] L. Bruzzone and M. Marconcini. Domain adaptation problems: A dasvm classification technique and a circular validation strategy. T-PAMI, 32(5):770–787, 2010.</p>
<p>[3] C.-C. Chang and C.-J. Lin. LIBSVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology, 2(3):27: 1–27:27, 2011.</p>
<p>[4] S.-F. Chang, D. Ellis, W. Jiang, K. Lee, A. Yanagawa, E. C. Loui, and J. Luo. Large-scale multimodal semantic concept detection for consumer video. In MIR workshop, ACM Multimedia, 2007.</p>
<p>[5] R. Chattopadhyay, J. Ye, S. Panchanathan, W. Fan, and I. Davidson. Multisource domain adaptation and its application to early detection of fatigue. In KDD, 2007.</p>
<p>[6] M. Chen, K. Q. Weinberger, and J. C. Blitzer. Co-training for domain adaptation. In NIPS, 2011.</p>
<p>[7] L. Duan, I. W. Tsang, D. Xu, and J. Luo. Visual event recognition in videos by learning from web data. T-PAMI, 34(9): 1667–1680, 2012.</p>
<p>[8] L. Duan, I. W. Tsang, D. Xu, and S. J. Maybank. Domain transfer multiple kernel learning. T-PAMI, 34(3):465–479, 2012.</p>
<p>[9] L. Duan, D. Xu, and S.-F. Chang. Exploiting web images for event recognition in consumer videos: A multiple source domain adaptation approach. In CVPR, pages 1338–1345, 2012.</p>
<p>[10] L. Duan, D. Xu, and I. W. Tsang. Domain adaptation from multiple sources: A domain-dependent regularization approach. T-NNLS, 23(3):504–5 18, 2012.</p>
<p>[11] L. Duan, D. Xu, and I. W. Tsang. Learning with augmented features for heterogeneous domain adaptation. In ICML, 2012.</p>
<p>[12] B. Gong, K. Grauman, and F. Sha. Connecting the dots with landmarks: Discriminatively learning domain-invariant features for unsupervised domain adaptation. In ICML, 2013.</p>
<p>[13] B. Gong, Y. Shi, F. Sha, and K. Grauman. Geodesic flow kernel for unsupervised domain adaptation. In CVPR, 2012.</p>
<p>[14] R. Gopalan, R. Li, and R. Chellappa. Domain adaptation for object recognition: An unsupervised approach. In ICCV, 2011.</p>
<p>[15] J. Hoffman, K. Saeko, B. Kulis, and T. Darrell. Discovering latent domains for multisource domain adaptation. In ECCV, 2012.</p>
<p>[16] N. Ikizler-Cinbis and S. Sclaroff. Object, scene and actions: Combining multiple features for human action recognition. In ECCV, 2010.</p>
<p>[17] N. Ikizler-Cinbis and S. Sclaroff. Web-based classifiers for human action recognition. T-MM, 14(4): 1031–1045, 2012.</p>
<p>[18] Y.-G. Jiang, G. Ye, S.-F. Chang, D. Ellis, and A. C. Loui. Consumer video understanding: A benchmark database and an evaluation ofhuman and machine performance. In ICMR, 2011.</p>
<p>[19] J. E. Kelley. The cutting plane method for solving convex programs. SIAM Journal on Applied Mathematics, 8(4):703–712, 1960.</p>
<p>[20] B. Kulis, K. Saenko, and T. Darrell. What you saw is not what you get: Domain adaptation using asymmetric kernel transforms. In CVPR, 2011.</p>
<p>[21] I. Laptev and T. Lindeberg. Space-time interest points. In ICCV, 2003.</p>
<p>[22] W. Li, L. Duan, D. Xu, and I. W. Tsang. Text-based image retrieval using progressive multi-instance learning. In ICCV, pages 2049–2055, 2011.</p>
<p>[23] Y.-F. Li, I. W. Tsang, J. T.-Y. Kwok, and Z.-H. Zhou. Tighter and convex maximum margin clustering. In AISTATS, 2009.</p>
<p>[24] J. Liu, J. Luo, and M. Shah. Recognizing realistic actions from videos “in the wild”. In CVPR, 2009.</p>
<p>[25] D. G. Lowe. Disctinctive image features from scale-invariance keypoint. IJCV, 60(2):91–1 10, 2004.</p>
<p>[26] K. Saenko, B. Kulis, M. Fritz, and T. Darrell. Adapting visual category models to new domains. In ECCV, 2010.</p>
<p>[27] G. Schweikert, C. Widmer, B. Sch o¨lkopf, and G. R ¨atsch. An empirical analysis of domain adaptation algorithms for genomic sequence analysis. In NIPS, 2009.</p>
<p>[28] C.-W. Seah, I. W. Tsang, and Y.-S. Ong. Healing sample selection bias by source classifier selection. In ICDM, 2011.</p>
<p>[29] M. Szafranski, Y. Grandvalet, and A. Rakotomamonjy. composite kernel learning. Machine Learning, 79(1-2):73–103, 2010.</p>
<p>[30] H. Wang, A. Kl¨ aser, C. Schmid, and C.-L. Liu. Action recognition by dense trajectories. In CVPR, 2011.</p>
<p>[31] X. Xu, I. W. Tsang, and D. Xu. Soft margin multiple kernel learning. T-NNLS, 24(5):749–761, 2013.</p>
<p>[32] J. Yang, R. Yan, and A. Hauptmann. Cross-domain video concept detection using adaptive svms. In ACM MM, 2007.</p>
<p>[33] D. Zhang, J. He, Y. Liu, L. Si, and R. D. Lawrence. Multi-view transfer learning with a large margin approach. In KDD, 2011. 222666777311</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
