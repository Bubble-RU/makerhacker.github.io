<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>18 cvpr-2013-A Max-Margin Riffled Independence Model for Image Tag Ranking</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-18" href="../cvpr2013/cvpr-2013-A_Max-Margin_Riffled_Independence_Model_for_Image_Tag_Ranking.html">cvpr2013-18</a> <a title="cvpr-2013-18-reference" href="#">cvpr2013-18-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>18 cvpr-2013-A Max-Margin Riffled Independence Model for Image Tag Ranking</h1>
<br/><p>Source: <a title="cvpr-2013-18-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Lan_A_Max-Margin_Riffled_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Tian Lan, Greg Mori</p><p>Abstract: We propose Max-Margin Riffled Independence Model (MMRIM), a new method for image tag ranking modeling the structured preferences among tags. The goal is to predict a ranked tag list for a given image, where tags are ordered by their importance or relevance to the image content. Our model integrates the max-margin formalism with riffled independence factorizations proposed in [10], which naturally allows for structured learning and efficient ranking. Experimental results on the SUN Attribute and LabelMe datasets demonstrate the superior performance of the proposed model compared with baseline tag ranking methods. We also apply the predicted rank list of tags to several higher-level computer vision applications in image understanding and retrieval, and demonstrate that MMRIM significantly improves the accuracy of these applications.</p><br/>
<h2>reference text</h2><p>[1] A.C.Berg, T. Berg, H. D. III, J. Dodge, A. Goyal, X. Han, A. Mensch, M. Mitchell, A. Sood, K. Stratos, and K. Yamaguchi. Understanding and predicting importance in images. In CVPR, 2012.</p>
<p>[2] K. Barnard, P. Duygulu, D. Forsyth, N. de Freitas, D. M. Blei, and M. I. Jordan. Matching words and pictures. JMLR, 2003.</p>
<p>[3] T. L. Berg, A. C. Berg, J. Edwards, and D. Forsyth. Whoâ€™s in the picture. In NIPS. 2004.</p>
<p>[4] O. Chapelle, Q. Le, and A. Smola. Large margin optimization of ranking measures. In NIPS Workshop on Learning to Rank, 2007.</p>
<p>[5] C. Desai, D. Ramanan, and C. Fowlkes. Discriminative models for multi-class object layout. In ICCV, 2009.</p>
<p>[6] T.-M.-T. Do and T. Artieres. Large margin training for hidden markov models with partially observed states. In ICML, 2009.</p>
<p>[7] A. Farhadi, I. Endres, D. Hoiem, and D. Forsyth. Describing objects by their attributes. In CVPR, 2009.</p>
<p>[8] C. Galleguillos, A. Rabinovich, and S. Belongie. Object categorization using co-occurrence, location and appearance. In CVPR, 2008.</p>
<p>[9] M. Guillaumin, T. Mensink, J. Verbeek, and C. Schmid. Tagprop: Discriminative metric learning in nearest neighbor models for image auto-annotation. In ICCV, 2009.</p>
<p>[10] J. Huang and C. Guestrin. Riffled independence for ranked data. In NIPS, 2009.</p>
<p>[11] J. Huang and C. Guestrin. Learning hierarchical riffle independent groupings from rankings. In ICML, 2010.</p>
<p>[12] S. J. Hwang and K. Grauman. Accounting for the relative importance of objects in image retrieval. In BMVC, 2010.</p>
<p>[13] S. J. Hwang and K. Grauman. Reading between the lines: Object localization using implicit cues from image tags. In CVPR, 2010.</p>
<p>[14] T. Joachims. Training linear SVMs in linear time. In SIGKDD, 2006.</p>
<p>[15] D. Liu, X.-S. Hua, L. Yang, M. Wang, and H.-J. Zhang. Tag ranking. In WWW, 2009.</p>
<p>[16] G. Patterson and J. Hays. Sun attribute database: Discovering, annotating, and recognizing scene attributes. In CVPR, 2012.</p>
<p>[17] R. Rensink, J. ORegan, and J. Clark. To see or not to see: the need for attention to perceive changes in scenes. Psychol. Sci., 1997.</p>
<p>[18] B. C. Russell, A. Torralba, K. P. Murphy, and W. T. Freeman. LabelMe: A database and web-based tool for image annotation. IJCV, 2008.</p>
<p>[19] B. Siddiquie, R. S. Feris, and L. S. Davis. Image ranking and</p>
<p>[20]</p>
<p>[21]</p>
<p>[22]</p>
<p>[23]  retrieval based on multi-attribute queries. In ICCV, 2011. R. Socher and L. Fei-Fei. Connecting modalities: Semisupervised segmentation and annotation of images using unaligned text corpora. In CVPR, 2010. M. Spain and P. Perona. Measuring and predicting object importance. IJCV, 2010. Y. Wang and G. Mori. A discriminative latent model of image region and object tag correspondence. In NIPS. 2010. J. Xiao, J. Hays, K. A. Ehinger, A. Oliva, and A. Torralba. Sun database: Large-scale scene recognition from abbey to zoo. In CVPR, 2010. 333 111 010088</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
