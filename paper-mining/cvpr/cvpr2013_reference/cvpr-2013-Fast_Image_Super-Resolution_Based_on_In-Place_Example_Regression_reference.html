<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>166 cvpr-2013-Fast Image Super-Resolution Based on In-Place Example Regression</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-166" href="../cvpr2013/cvpr-2013-Fast_Image_Super-Resolution_Based_on_In-Place_Example_Regression.html">cvpr2013-166</a> <a title="cvpr-2013-166-reference" href="#">cvpr2013-166-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>166 cvpr-2013-Fast Image Super-Resolution Based on In-Place Example Regression</h1>
<br/><p>Source: <a title="cvpr-2013-166-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Yang_Fast_Image_Super-Resolution_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Jianchao Yang, Zhe Lin, Scott Cohen</p><p>Abstract: We propose a fast regression model for practical single image super-resolution based on in-place examples, by leveraging two fundamental super-resolution approaches— learning from an external database and learning from selfexamples. Our in-place self-similarity refines the recently proposed local self-similarity by proving that a patch in the upper scale image have good matches around its origin location in the lower scale image. Based on the in-place examples, a first-order approximation of the nonlinear mapping function from low- to high-resolution image patches is learned. Extensive experiments on benchmark and realworld images demonstrate that our algorithm can produce natural-looking results with sharp edges and preserved fine details, while the current state-of-the-art algorithms are prone to visual artifacts. Furthermore, our model can easily extend to deal with noise by combining the regression results on multiple in-place examples for robust estimation. The algorithm runs fast and is particularly useful for practical applications, where the input images typically contain diverse textures and they are potentially contaminated by noise or compression artifacts.</p><br/>
<h2>reference text</h2><p>[1] A. Buades, B. Coll, and J. M. Morel. A non local algorithm for image denoising. In IEEE Conference on Computer Vision and Pattern Recognition, 2005.</p>
<p>[2] H. Chang, D.-Y. Yeung, and Y. Xiong. Super-resolution through neighbor embedding. In IEEE Computer Society Conference on Computer Vision and Pattern Recognition, volume 1, pages 275–282, 2004.</p>
<p>[3] S. Dai, M. Han, W. Xu, Y. Wu, and Y. Gong. Soft edge smoothness prior for alpha channel super resolution. In IEEE Conference on Computer Vision and Pattern Recognition, 2007.</p>
<p>[4] M. Ebrahimi and E. Vrscay. Solving the inverse problem of image zooming using self-examples. In Internaltional Conference on Image Analysis and Recognition, pages 117–130, 2007.</p>
<p>[5] R. Fattal. Upsampling via imposed edge statistics. ACM Transactions on Graphics, 26(3), 2007.</p>
<p>[6] G. Freedman and R. Fattal. Imag and video upscaling</p>
<p>[7]</p>
<p>[8]</p>
<p>[9]</p>
<p>[10]</p>
<p>[11]</p>
<p>[12]</p>
<p>[13]</p>
<p>[14]</p>
<p>[15]  from local self-examples. ACM Transactions on Graphics, 28(3): 1–10, 2011. W. T. Freeman, T. R. Jones, and E. C. Pasztor. Examplebased super-resolution. IEEE Computer Graphics and Applications, 22:56–65, 2002. Y. Freund, S. Dasgupta, M. Kabra, and N. Verma. Learning the structure of manifolds using random projections. In NIPS, 2007. D. Glasner, S. Bagon, and M. Irani. Super-resolution from a single image. In IEEE International Conference on Computer Vision, 2009. H. He and W. C. Siu. Single image super-resolution using gaussian process regression. In CVPR, 2011. D. Martin, C. Fowlkes, D. Tal, and J. Malik. A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics. In IEEEInternational Conference on Computer Vision, volume 2, pages 416–423, July 2001 . S. Roweis and L. Saul. Nonlinear dimensionality reduction by locally linear embedding. Science, 290(5500):2201– 2372, 2000. J. Sun, J. Sun, Z. Xu, and H.-Y. Shum. Image superresolution using gradient profile priors. In IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2008. J. Sun, N.-N. Zheng, H. Tao, and H.-Y. Shum. Image hallucinatoin with primal sketch priors. In IEEE Computer Society Conference on Computer Vision and Pattern Recognition, volume 2, pages 729–736, 2003. Y. W. Tai, S. Liu, M. S. Brown, and S. Lin. Super resolution using edge prior and single image detail synthesis. In CVPR,  2010.</p>
<p>[16] M. F. Tappen, B. C. Russel, and W. T. Freeman. Exploiting the sparse derivative prior for super-resolution and image demosaicing. In IEEE Workshop on Statistical and Computational Theories of Vision, 2003.</p>
<p>[17] Q. Wang, X. Tang, and H. Shum. Patch based blind image super-resolution. In ICCV, 2005.  Figure 8. Illustration of the in-place matching proof. In order to get sharp results for singular structure (p, q), we want to match (p, q) with (p?, q?) in searching the example pair.</p>
<p>[18] J. Yang, Z. Wang, Z. Lin, S. Cohen, and T. S. Huang. Coupled dictionary learning for image super-resolution. IEEE Transactions on Image Processing, 21:3467–3478, 2012.</p>
<p>[19] J. Yang, J. Wright, T. Huang, and Y. Ma. Image superresolution via sparse representation. IEEE Transactions on Image Processing, 19(1 1), 2010.</p>
<p>[20] X. Zhu and P. Milanfar. Automatic parameter selection for denoising algoirthms using a non-reference measure of image content. IEEE Transactions on Image Processing, 19:31 16–3132, 2010.</p>
<p>[21] M. Zontak and M. Irani. Internal statistics of a single natural image. In IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2011.  ×  A. Proof of in-place matching  Proof. For simplicity, our discussion is based on continuous image signals. Given a patch y (a a) from the low-frequency band image nY a ace pnattecrhed y ya t( a(x ×, y a),) fsrhoomwn t hine Figure 8, we assume it has a singular structure centered at (p, q). This point has a shift from the patch center by p = x + tx and q = y + ty (|tx |, |ty | < a/2). (x?, y?) and (p?, q?) are the corresponding |ctoo|r,|dtin|at</p>
<br/>
<br/><br/><br/></body>
</html>
