<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>161 cvpr-2013-Facial Feature Tracking Under Varying Facial Expressions and Face Poses Based on Restricted Boltzmann Machines</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-161" href="../cvpr2013/cvpr-2013-Facial_Feature_Tracking_Under_Varying_Facial_Expressions_and_Face_Poses_Based_on_Restricted_Boltzmann_Machines.html">cvpr2013-161</a> <a title="cvpr-2013-161-reference" href="#">cvpr2013-161-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>161 cvpr-2013-Facial Feature Tracking Under Varying Facial Expressions and Face Poses Based on Restricted Boltzmann Machines</h1>
<br/><p>Source: <a title="cvpr-2013-161-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Wu_Facial_Feature_Tracking_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Yue Wu, Zuoguan Wang, Qiang Ji</p><p>Abstract: Facial feature tracking is an active area in computer vision due to its relevance to many applications. It is a nontrivial task, sincefaces may have varyingfacial expressions, poses or occlusions. In this paper, we address this problem by proposing a face shape prior model that is constructed based on the Restricted Boltzmann Machines (RBM) and their variants. Specifically, we first construct a model based on Deep Belief Networks to capture the face shape variations due to varying facial expressions for near-frontal view. To handle pose variations, the frontal face shape prior model is incorporated into a 3-way RBM model that could capture the relationship between frontal face shapes and non-frontal face shapes. Finally, we introduce methods to systematically combine the face shape prior models with image measurements of facial feature points. Experiments on benchmark databases show that with the proposed method, facial feature points can be tracked robustly and accurately even if faces have significant facial expressions and poses.</p><br/>
<h2>reference text</h2><p>[1] P. Belhumeur, D. Jacobs, D. Kriegman, and N. Kumar. Localizing parts of faces using a consensus of exemplars. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 2729–2736, 2011. 2</p>
<p>[2] T. F. Cootes, C. J. Taylor, D. H. Cooper, and J. Graham. Active shape models their training and application. Computer Vision and Image Understanding, 61(1):38–59, 1995. 2</p>
<p>[3] M. Dantone, J. Gall, G. Fanelli, and L. Van Gool. Real-time facial feature detection using conditional regression forests. 333444555866  (a) multi-view, smile, left  (c) multi-view, surprise, left (e) multi-view, failed case, left  (b) multi-view, smile, right  (d) multi-view, surprise, right (f) multi-view, failed case, right Figure 10. Facial feature tracking results  on  ISL multi-view facial expression database using the proposed method (PoseRBM).  In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 2578–2585, 2012. 2</p>
<p>[4] L. Ding and A. Martinez. Features versus context: An approach for precise and detailed detection and delineation of faces and facial features. Pattern Analysis and Machine Intelligence, 32(1 1):2022–2038, 2010. 2</p>
<p>[5] S. Eslami, N. Heess, and J. Winn. The shape boltzmann machine: a strong model of object shape. In CVPR, pages</p>
<p>[6]</p>
<p>[7]</p>
<p>[8]</p>
<p>[9]</p>
<p>[10]</p>
<p>[11]</p>
<p>[12]</p>
<p>[13]</p>
<p>[14]</p>
<p>[15]  406–413, 2012. 1, 2, 3, 7 G. Hinton. Training products of experts by minimizing contrastive divergence. Neural Computation, 14(8): 1771–1800, August 2002. 3, 4 Y. Huang, Q. Liu, and D. Metaxas. A component-based framework for generalized face alignment. IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics, 41(1):287–298, 2011. 2 J. R. joshua M. Susskind, Geoffrey E. Hinton and A. K. Anderson. Generating facial expressions with deep belief nets. Affective Computing, Focus on Emotion Expression, Synthesis and Recognition, 2008. 2 Y. li Tian, T. Kanade, and J. F. Cohn. Recognizing action units for facial expression analysis. Pattern Analysis and Machine Intelligence, 23(2):97–1 15, February 2001 . 2 P. Lucey, J. Cohn, T. Kanade, J. Saragih, Z. Ambadar, and I. Matthews. The extended cohn kanade dataset: A complete dataset for action unit and emotion specified expression. In IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), pages 94–101, 2010. 5 P. Luo. Hierarchical face parsing via deep learning. In CVPR, pages 2480–2487, 2012. 2 I. Matthews and S. Baker. Active appearance models revisited. Int. J. Comput. Vision, 60(2): 135–164, 2004. 2, 5 R. Memisevic and G. E. Hinton. Learning to represent spatial transformations with factored higher–order boltzmann machines. Neural Comput., 22(6): 1473–1492, 2010. 1, 4 A. Mohamed, G. Dahl, and G. Hinton. Acoustic modeling using deep belief networks. IEEE Transactions on Audio, Speech, and Language Processing, PP(99): 1, 2011. 3 M. Pantic, M. F. Valstar, R. Rademaker, and L. Maat. Web-</p>
<p>[16]  based database for facial expression analysis. In Proc. of IEEE Intl. Conf. on Multimedia and Expo, pages 3 17–321, 2005. 5, 6 P. Phillips, H. Moon, S. Rizvi, and P. Rauss. The feret evaluation methodology for face–recognition algorithms. Pattern Analysis and Machine Intelligence, 22(10): 1090 1104, 2000. 6 G. Taylor, L. Sigal, D. Fleet, and G. Hinton. Dynamical binary latent variable models for 3d human pose tracking. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 631–638, 2010. 1, 2, 3 Y. Tong, W. Liao, and Q. Ji. Facial action unit recognition by exploiting their dynamic and semantic relationships. Pattern Analysis and Machine Intelligence, 29(10): 1683 –1699, oct. 2007. 5, 6 Y. Tong, Y. Wang, Z. Zhu, and Q. Ji. Robust facial feature tracking under varying face pose and facial expression. Pattern Recognition, 40(1 1):3195–3208, Nov. 2007. 2, 6, 7 M. Valstar, B. Martinez, X. Binefa, and M. Pantic. Facial point detection using boosted regression and graph models. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 2729–2736, 2010. 2 M. Valstar, B. Martinez, X. Binefa, and M. Pantic. Facial point detection using boosted regression and graph models. In IEEE Conference on Computer Vision and Pattern Recognition, pages 2729 –2736, june 2010. 6 Z. Wang, S. Lyu, G. Schalk, and Q. Ji. Learning with target prior. In Annual Conference on Neural Information Processing Systems (NIPS), 2012. 2 Z. Wang, S. Lyu, G. Schalk, and Q. Ji. Deep feature learning using target priors with applications in ecog signal decod–</p>
<p>[17]</p>
<p>[18]</p>
<p>[19]</p>
<p>[20]</p>
<p>[21]</p>
<p>[22]</p>
<p>[23]  ing for bci. In International Joint Conferences on Artificial Intelligence (IJCAI), 2013. 2</p>
<p>[24] R. B. Wilbur and A. C. Kak. Purdue rvl-slll american sign language database. Technical report, Purdue University, 2006. 5, 6 333444555977</p>
<br/>
<br/><br/><br/></body>
</html>
