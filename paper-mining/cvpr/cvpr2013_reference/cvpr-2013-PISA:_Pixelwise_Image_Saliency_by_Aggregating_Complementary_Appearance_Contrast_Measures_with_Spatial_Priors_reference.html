<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>322 cvpr-2013-PISA: Pixelwise Image Saliency by Aggregating Complementary Appearance Contrast Measures with Spatial Priors</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-322" href="../cvpr2013/cvpr-2013-PISA%3A_Pixelwise_Image_Saliency_by_Aggregating_Complementary_Appearance_Contrast_Measures_with_Spatial_Priors.html">cvpr2013-322</a> <a title="cvpr-2013-322-reference" href="#">cvpr2013-322-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>322 cvpr-2013-PISA: Pixelwise Image Saliency by Aggregating Complementary Appearance Contrast Measures with Spatial Priors</h1>
<br/><p>Source: <a title="cvpr-2013-322-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Shi_PISA_Pixelwise_Image_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Keyang Shi, Keze Wang, Jiangbo Lu, Liang Lin</p><p>Abstract: Driven by recent vision and graphics applications such as image segmentation and object recognition, assigning pixel-accurate saliency values to uniformly highlight foreground objects becomes increasingly critical. More often, such fine-grained saliency detection is also desired to have a fast runtime. Motivated by these, we propose a generic and fast computational framework called PISA Pixelwise Image Saliency Aggregating complementary saliency cues based on color and structure contrasts with spatial priors holistically. Overcoming the limitations of previous methods often using homogeneous superpixel-based and color contrast-only treatment, our PISA approach directly performs saliency modeling for each individual pixel and makes use of densely overlapping, feature-adaptive observations for saliency measure computation. We further impose a spatial prior term on each of the two contrast measures, which constrains pixels rendered salient to be compact and also centered in image domain. By fusing complementary contrast measures in such a pixelwise adaptive manner, the detection effectiveness is significantly boosted. Without requiring reliable region segmentation or post– relaxation, PISA exploits an efficient edge-aware image representation and filtering technique and produces spatially coherent yet detail-preserving saliency maps. Extensive experiments on three public datasets demonstrate PISA’s superior detection accuracy and competitive runtime speed over the state-of-the-arts approaches.</p><br/>
<h2>reference text</h2><p>[1] R. Achanta, S. Hemami, F. Estrada, and S. S ¨usstrunk. Frequency-tuned salient region detection. In CVPR, 2009.</p>
<p>[2] S. Alpert, M. Galun, R. Basri, and A. Brandt. Image segmentation by probabilistic bottom-up aggregation and cue integration. In CVPR, 2007.</p>
<p>[3] A. Borji, D. Sihite, and L. Itti. Salient object detection: a  benchmark. In ECCV, 2012.</p>
<p>[4] N. Bruce and K. Tsotsos. Saliency based on information maximization. In NIPS, 2005.</p>
<p>[5] M. Cheng, G. Zhang, N. Mitra, X. Huang, and S. Hu. Global contrast based salient region detection. In CVPR, 2011.</p>
<p>[6] W. Einh a¨user, and P. K ¨onig. Does luminance-contrast contribute to a saliency map for overt visual attention? European Journal of Neuroscience, 2003.</p>
<p>[7] S. Goferman, L. Zelnik-Manor, and A. Tal. Context-aware saliency detection. In CVPR, 2010.</p>
<p>[8] C. Guo, Q. Ma, and L. Zhang. Spatial-temporal saliency detection using phase spectrum of quaternion fourier transform. In CVPR, 2008.</p>
<p>[9] M. Heikkil a¨, and M. Pietik¨ ainen, C. Schmid. Description of interest regions with local binary patterns. Pattern Recognition, 2009.</p>
<p>[10] X. Hou and L. Zhang. Saliency detection: A spectral residual approach. In CVPR, 2007.</p>
<p>[11] L. Itti, C. Koch, and E. Niebur. A model of saliency-based visual attention for rapid scene analysis. IEEE TPAMI, 1998.</p>
<p>[12] C. Koch, and S. Ullman. Shifts in selective visual attention: towards the underlying neural circuitry. Human Neurbiology, 1985.</p>
<p>[13] J. Kopf, M. Cohen, D. Lischinski, and M. Uyttendaele. Joint bilateral upsampling. ACM TOG, 2007.</p>
<p>[14] Z. Liang, M. Wang, X. Zhou, L. Lin, and W. Li. Salient object detection based on regions. Multimedia Tools and Applications, 2012.</p>
<p>[15] T. Liu, J. Sun, N. Zheng, X. Tang, and H. Shum. Learning to detect a salient object. In CVPR, 2007.</p>
<p>[16] J. Lu, K. Shi, D. Min, L. Lin, and M. Do. Cross-based local  multipoint filtering. In CVPR, 2012.</p>
<p>[17] B. Manjunath and W. Ma. Texture features for browsing and retrieval of image data. IEEE TPAMI, 1996.</p>
<p>[18] V. Movahedi and J. Elder. Design and perceptual validation of performance measures for salient object segmentation. In POCV, 2010.</p>
<p>[19] F. Perazzi, P. Kr ¨ahenb u¨hl, Y. Pritch, and A. Hornung. Saliency filters: contrast based filtering for salient region detection. In CVPR, 2012.</p>
<p>[20] G. Sharma, F. Jurie, and C. Schmid. Discriminative Spatial Saliency for Image Classification. In CVPR, 2012.</p>
<p>[21] R. Valenti, N. Sebe, and T. Gevers. Image saliency by isocentric curvedness and color. In ICCV, 2009.</p>
<p>[22] L. Wang, J. Xue, N. Zheng, and G. Hua. Automatic salient object extraction with contextual cue. In ICCV, 2011.</p>
<p>[23] Y. Wang, C. Tai, O. Sorkine, and T. Lee. Optimized scaleand-stretch for image resizing. ACM TOG, 2008.</p>
<p>[24] Y. Wei, F. Wen, W. Zhu, and J. Sun. Geodesic saliency using background priors. In ECCV, 2012.</p>
<p>[25] Y. Zhai and M. Shah. Visual attention detection in video sequences using spatiotemporal cues. In CVPR, 2006. 222111222200</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
