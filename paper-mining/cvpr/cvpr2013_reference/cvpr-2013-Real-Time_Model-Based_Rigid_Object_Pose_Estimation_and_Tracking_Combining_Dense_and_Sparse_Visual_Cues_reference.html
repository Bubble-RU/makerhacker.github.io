<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>345 cvpr-2013-Real-Time Model-Based Rigid Object Pose Estimation and Tracking Combining Dense and Sparse Visual Cues</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-345" href="../cvpr2013/cvpr-2013-Real-Time_Model-Based_Rigid_Object_Pose_Estimation_and_Tracking_Combining_Dense_and_Sparse_Visual_Cues.html">cvpr2013-345</a> <a title="cvpr-2013-345-reference" href="#">cvpr2013-345-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>345 cvpr-2013-Real-Time Model-Based Rigid Object Pose Estimation and Tracking Combining Dense and Sparse Visual Cues</h1>
<br/><p>Source: <a title="cvpr-2013-345-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Pauwels_Real-Time_Model-Based_Rigid_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Karl Pauwels, Leonardo Rubio, Javier Díaz, Eduardo Ros</p><p>Abstract: We propose a novel model-based method for estimating and tracking the six-degrees-of-freedom (6DOF) pose of rigid objects of arbitrary shapes in real-time. By combining dense motion and stereo cues with sparse keypoint correspondences, and by feeding back information from the model to the cue extraction level, the method is both highly accurate and robust to noise and occlusions. A tight integration of the graphical and computational capability of Graphics Processing Units (GPUs) results in pose updates at framerates exceeding 60 Hz. Since a benchmark dataset that enables the evaluation of stereo-vision-based pose estimators in complex scenarios is currently missing in the literature, we have introduced a novel synthetic benchmark dataset with varying objects, background motion, noise and occlusions. Using this dataset and a novel evaluation methodology, we show that the proposed method greatly outperforms state-of-the-art methods. Finally, we demonstrate excellent performance on challenging real-world sequences involving object manipulation.</p><br/>
<h2>reference text</h2><p>[1] P. Besl and N. McKay. A method for registration of 3D shapes. IEEE PAMI, 14:239–256, 1992. 3</p>
<p>[2] G. Blais and M. Levine. Registering multiview range data to create 3D computer objects. IEEE PAMI, 17(8):820–824, 1995. 3</p>
<p>[3] G. Bradski. The OpenCV Library. Dr. Dobb’s Journal of Software Tools, 2000. 4</p>
<p>[4] T. Brox, B. Rosenhahn, J. Gall, and D. Cremers. Combined region and motion-based 3D tracking of rigid and articulated objects. IEEE PAMI, 32(3):402–415, 2010. 1, 5</p>
<p>[5] C. Choi and H. I. Christensen. Robust 3D visual tracking using particle filtering on the special euclidean group: A combined approach of keypoint and edge features. Int. J. Robot. Res., 31(4):498–519, 2012. 1, 5</p>
<p>[6] T. Drummond and R. Cipolla. Real-time visual tracking of complex structures. IEEE PAMI, 24(7):932–946, 2002. 1</p>
<p>[7] S. Hinterstoisser, S. Holzer, C. Cagniart, S. Ilic, K. Konolige, N. Navab, and V. Lepetit. Multimodal templates for real-time detection of texture-less objects in heavily cluttered scenes. In ICCV, pages 858–865, 2011. 1</p>
<p>[8] A. Kasper, Z. Xue, and R. Dillmann. The KIT object models database: An object model database for object recognition, localization and manipulation in service robotics. Int. J. Robot. Res., 31(8):927–934, 2012. 5</p>
<p>[9] V. Lepetit and P. Fua. Monocular model-based 3D tracking of rigid objects. Foundations and Trends in Computer Graphics and Vision, 1:1–89, 2005. 1, 4</p>
<p>[10] J. Liebelt and C. Schmid. Multi-view object class detection with a 3D geometric model. In CVPR, pages 1688–1695, 2010. 1</p>
<p>[11] H. C. Longuet-Higgins and K. Prazdny. The interpretation of a moving retinal image. P. Roy. Soc. B-Biol. Sci. , 208:385– 397, 1980. 3</p>
<p>[12] D. Lowe. Distinctive image features from scale-invariant keypoints. IJCV, 60(2):91–1 10, 2004. 2</p>
<p>[13] T. M ¨orwald, J. Prankl, A. Richtsfeld, M. Zillich, and M. Vincze. BLORT - The Blocks World Robotic Vision Toolbox. In ICRA, 2010. 1, 6</p>
<p>[14] F. Mosteller and J. Tukey. Data analysis and regression: A second course in statistics. Addison-Wesley Reading, Mass., 1977. 4</p>
<p>[15] R. A. Newcombe, A. J. Davison, S. Izadi, P. Kohli, O. Hilliges, J. Shotton, D. Molyneaux, S. Hodges, D. Kim, and A. Fitzgibbon. KinectFusion: real-time dense surface mapping and tracking. In IEEE ISMAR, pages 127–136, Oct. 2011. 1, 7</p>
<p>[16] K. Pauwels, M. Tomasi, J. D ı´az, E. Ros, and M. Van Hulle. A comparison of FPGA and GPU for real-time phase-based optical flow, stereo, and local image features. IEEE T. Comput., 61(7):999–1012, 2012. 2</p>
<p>[17] V. Prisacariu and I. Reid. PWP3D: Real-time segmentation and tracking of 3D objects. IJCV, 98:335–354, 2012. 1, 5, 6, 7</p>
<p>[18] J. Shotton, A. Fitzgibbon, M. Cook, T. Sharp, M. Finocchio, R. Moore, A. Kipman, and A. Blake. Real-time human pose recognition in parts from single depth images. In CVPR, pages 1297–1304, June 2011. 1</p>
<p>[19] Wikipedia. Kinect, 2013. 7</p>
<p>[20] C. Wu. SiftGPU: A GPU implementation of scale invariant feature transform (SIFT). http : / / c s .unc . edu / ˜ccwu / s i ft gpu, 2007. 2</p>
<p>[21] C. Yang and G. Medioni. Object modelling by registration of multiple range images. Image Vision Comput., 10(3): 145– 155, 1992. 3 222333555422</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
