<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>328 cvpr-2013-Pedestrian Detection with Unsupervised Multi-stage Feature Learning</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-328" href="../cvpr2013/cvpr-2013-Pedestrian_Detection_with_Unsupervised_Multi-stage_Feature_Learning.html">cvpr2013-328</a> <a title="cvpr-2013-328-reference" href="#">cvpr2013-328-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>328 cvpr-2013-Pedestrian Detection with Unsupervised Multi-stage Feature Learning</h1>
<br/><p>Source: <a title="cvpr-2013-328-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Sermanet_Pedestrian_Detection_with_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Pierre Sermanet, Koray Kavukcuoglu, Soumith Chintala, Yann Lecun</p><p>Abstract: Pedestrian detection is a problem of considerable practical interest. Adding to the list of successful applications of deep learning methods to vision, we report state-of-theart and competitive results on all major pedestrian datasets with a convolutional network model. The model uses a few new twists, such as multi-stage features, connections that skip layers to integrate global shape information with local distinctive motif information, and an unsupervised method based on convolutional sparse coding to pre-train the filters at each stage.</p><br/>
<h2>reference text</h2><p>[1] M. Aharon, M. Elad, and A. M. Bruckstein. K-SVD and its non-negative variant for dictionary design. In M. Papadakis, A. F. Laine, and M. A. Unser, editors, Society of Photo-Optical Instrumentation Engineers (SPIE) Conference Series, volume 5914, pages 327–339, Aug. 2005. 2</p>
<p>[2] A. Beck and M. Teboulle. A fast iterative shrinkagethresholding algorithm for linear inverse problems. SIAM J. Img. Sci., 2(1): 183–202, 2009. 2, 3</p>
<p>[3] R. Benenson, M. Mathias, R. Timofte, and L. Van Gool. Pedestrian detection at 100 frames per second. In Computer 333666223 919  Pedestrian Detection AUC, Reasonable (> 50 pixels no/partial occlusion) 100 ConvNet  %)(  80  CroCshnsTFatlrsk FeFat FSrPMDynitnWhe  en0ad1FPIw 60 nderCuvbtU 40  L a t MHS Hv muoikHmglMS-L tiOVFLVvbGtmp1Sr2 VSPehoarsyepFIaVPnlseJvt  ea r A  20  0  INRIA-fixed  INRIA  Daimler  ETH  Caltech-UsaTestTudBrussels  Datasets Pedestrian Detection AUC, Large (> 100 pixels) 100 ConvNet ChnFtrs  I (%)P  FCeroFats rMPsHSTDyOainWtGlehk L a tHS MSv iuomk MgltS-LiVv bFLm2p1tSr  80  en0ad1FPw 60  CdateunAUevrebr 420 VSPehroayspFe PIaVlnse tJv INRIA-fixed  INRIA  Daimler  ETH  Caltech-UsaTestTudBrussels  Datasets  Figure 5: Reasonable and Large measures for all INRIA-trained systems on all major datasets, using the proposed continuous AUC percentage. The AUC is computed from DET curves (smaller AUC means more accuracy and less false positives). For a clearer overall performance, each ConvNet point is connected by dotted lines. While only the ’reasonable’ and ’large’ measures are plotted here, all measures are reported in table 2. The ConvNet system yields state-of-the-art or competitive results on most datasets and measures, except for the low resolutions measures on the Caltech dataset because of higher reliance on high-resolution cues than other methods. Trained on  INRIA  ConvNet ChnFtrs CrossTalk FPDW FeatSynth FtrMine HOG HiAkSlvlm - AU HCog %Lbp LatSvm-V1 LatSvm-V2 MLS MultiFtrPlsPoseInv ShapeletVJVeryFast  CaTIlNutDRedIENcBIahRTAim-rUH-uIsA flesiraxe lTdes t914 56872602. .0981674571 73 8-. 76913451 73527 -. 078 95 71 9438-. 6051071 98 - . 01684 63- . 87 5367384 3752. .395 693867 2162196. .64 985276281 7967. .012 8926 89 5841. .1827 846 18 9724 3. .923 3158 14791382. .82 428 76825408351. .2584376834261079-. 12 04897683206 -. 861759 6 8345865. .8947869 658249 04. .7814751 40 6- . 359 Reasonable - AUC % - >50 pixels & no/partial occlusion  CaTIlNutDRedIENcBIahRTAim-rUH-uIsA flesiraxe lTdes t713 25482912. .0519 74 1 836 4-. 28943 41 49726 -. 0710945 1 60436-. 6489041 9 - . 026 4 63- . 83 534635148672. .31891236 7521 89 2. .24 9 0427426381062. .07823 26 487964873. .68240845215 19 623. .962031 5 1 37281 7. .803921 64524 59 7. .2853 5 3429 029-. 19 0287 680 65-. 821729 86 8207863. .520789 96581 903. .1384761 40 2- . 35 Large - AUC %  - > 100 pixels  CTIaNltuIRDedaNcBIEhA-RTirmuU-HIfsAles iarxeT lsdest31 27134 0. 8. 54 283213 42016-. 126 2 12 387051-. 28703 21 63125-. 4014712 87 - . 3604 372- . 98 3 235 831 6. .12 70835 2 60 528. .4025 2 12 496 148. .658 4324 26487 204. .2659721 4296 230. 9. 8513214 21461327. .869780253 23 50435. .6593712432 30867-. 483 6756 04963-. 0594 876 7029865. .36 1 8 86576309 6. .09 03729 4- .14. Near - AUC % - >80 pixels  CaITNltuRDeIdNcBaEhIi-RAmrTU-HuIlAsf iexsearelTdse t21 41 80 71. .3409 3213 12759-. 2 465321 40 81 -. 92039 321 87182-. 5984312 7 9- . 3954 832- . 79643 36210631. .5918 5435 3205 48 . .076453 21 25160 4 . .57 9725 2748207 . .5296253412 1 7061 . .41 87521 24165496 . .537185235423 730 9. .72 8 4 32 91847-. 6287168 68069 0-. 084067 6 8758 69. .6371 98 56896580 . .03 70 29 - .79.8 Medium - AUC % - 30-80 pixels  CaTINltuDedIRcBNhIEaiRTAmr-UuI-Hlfs Aesiarxe lTsedst359635 43723. 218 421 4650 9720 -. 45.90 4597 59209-. 571671 5470 950 -. 76.40 1 70 -0 -.20 1 80 20- 0.10 1 67840 91 20 . 1.4 90 1 58750 4 240 . 94.670 8 798625015 . 7953 258 9875815 1. 5 31 596 895 80 97. 7208731 584 0 9403 0. 176.90 67 84 8376 . 2817 31 7640 5 -0 . 08.0 789 798 93-. 847 9 9 745 9 4. 127 59 9 7318 1 . 7 5 2 47 8- . 9 3 Table 2: Performance of all systems on all datasets using the proposed continuous AUC percentage over the range [0,1] from DET curves. The top performing results (among INRIA-trained models) are highlighted in bold for each row. DET curves plot false positives per image (FPPI) against miss rate. Hence a smaller AUC% means a more accurate system with lower amount of false positives. The ConvNet model (ConvNet-U-MS here) holds several state-of-the-art or competitive scores. We report the multiple measures introduced by [10] for all major pedestrian datasets. For readibility, not all measures are reported nor are models not trained on INRIA. All results however are reported in the supplementary paper. Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, pages 2903–2910. IEEE, 2012. 1</p>
<p>[4] Y. Bengio, P. Lamblin, D. Popovici, and H. Larochelle. Greedy layer-wise training of deep networks. In Advances 333666333200  in Neural Information Processing Systems 19, pages 153–160. MIT Press, 2007. 1, 2</p>
<p>[5] N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. In C. Schmid, S. Soatto, and C. Tomasi, editors, CVPR ’05, volume 2, pages 886–893, June 2005. 1, 2, 5</p>
<p>[6] I. Daubechies, M. Defrise, and C. De Mol. An iterative thresholding algorithm for linear inverse problems with a sparsity constraint. Communications on Pure and Applied Mathematics, 57(1 1): 1413–1457,  2004. 2, 3</p>
<p>[7] P. Doll a´r, R. Appel, and W. Kienzle. frame-rate pedestrian detection.  Crosstalk cascades for  1</p>
<p>[8] P. Doll a´r, S. Belongie, and P. Perona. The fastest pedestrian detector in the west. In BMVC 2010, Aberystwyth, UK. 1, 2</p>
<p>[9] P. Doll a´r, Z. Tu, P. Perona, and S. Belongie. Integral channel  features. In BMVC 2009, London, England. 1, 2</p>
<p>[10] P. Doll a´r, C. Wojek, B. Schiele, and P. Perona. Pedestrian detection: A benchmark. In CVPR’09. IEEE, June 2009. 4, 6, 7</p>
<p>[11] P. Doll a´r, C. Wojek, B. Schiele, and P. Perona. Pedestrian detection: An evaluation of the state of the art. PAMI, 99, 2011. 5</p>
<p>[12] J. Fan, W. Xu, Y. Wu, and Y. Gong. Human tracking using convolutional neural networks. Neural Networks, IEEE Transactions on, 21(10): 1610 –1623, 2010. 4</p>
<p>[13] P. Felzenszwalb, R. Girshick, D. McAllester, and D. Ramanan. Object detection with discriminatively trained part based models. In PAMI 2010. 1</p>
<p>[14] A. Frome, G. Cheung, A. Abdulkader, M. Zennaro, B. Wu, A. Bissacco, H. Adam, H. Neven, and L. Vincent. Large-scale privacy protection in street-level imagery. In ICCV’09. 1, 2</p>
<p>[15] C. Garcia and M. Delakis. Convolutional face finder: A neural architecture for fast and robust face detection. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2004. 1, 2</p>
<p>[16] G. E. Hinton and R. R. Salakhutdinov. Reducing the dimensionality of data with neural networks. Science, 313(5786):504–507, 2006. 1, 2</p>
<p>[17] K. Jarrett, K. Kavukcuoglu, M. Ranzato, and Y. LeCun. What is the best multi-stage architecture for object recognition? In ICCV’09. IEEE, 2009. 1, 4</p>
<p>[18] K. Kavukcuoglu, M. Ranzato, R. Fergus, and Y. LeCun. Learning invariant features through topographic filter maps. In CVPR’09. IEEE, 2009. 2</p>
<p>[19] K. Kavukcuoglu, M. Ranzato, and Y. LeCun. Fast inference in sparse coding algorithms with applications to object recognition. Technical report, CBLL, Courant Institute, NYU, 2008. CBLL-TR-2008-12-01. 2</p>
<p>[20] K. Kavukcuoglu, P. Sermanet, Y. Boureau, K. Gregor, M. Mathieu, and Y. LeCun. Learning convolutional feature hierachies for visual recognition. In Advances in Neural Information Processing Systems (NIPS 2010), 2010. 1, 2, 3, 6</p>
<p>[21] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In NIPS 2012: Neural Information Processing Systems. 1</p>
<p>[22] Q. Le, M. Quigley, J. Feng, J. Chen, Y. Zou, W, M. Rasi, T. Low, and A. Ng. Haptic belt with pedestrian detection. In NIPS, 2011 (Demonstrations). 6</p>
<p>[23] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradientbased learning applied to document recognition. Proceedings of the IEEE, 86(1 1):2278–2324, November 1998. 1, 2, 4</p>
<p>[24] H. Lee, A. Battle, R. Raina, and A. Y. Ng. Efficient sparse coding algorithms. In B. Sch o¨lkopf, J. Platt, and T. Hoffman, editors, Advances in Neural Information Processing Systems 19, pages 801–808. MIT Press, Cambridge, MA, 2007. 2</p>
<p>[25] H. Lee, R. Grosse, R. Ranganath, and A. Ng. Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations. In ICML’09, pages 609–616. ACM, 2009. 2</p>
<p>[26] Y. Li and S. Osher. Coordinate Descent Optimization for l1 Minimization with Application to Compressed Sensing; a Greedy Algorithm. CAM Report, pages 09–17. 2</p>
<p>[27] J. Mairal, F. Bach, J. Ponce, G. Sapiro, and A. Zisserman. Discriminative learned dictionaries for local image analysis. Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on, pages 1–8, June 2008. 2</p>
<p>[28] S. Maji, A. C. Berg, and J. Malik. Classification using intersection kernel support vector machines is efficient. volume 0, pages 1–8, Los Alamitos, CA, USA, 2008. IEEE Computer Society. 1</p>
<p>[29] S. Nowlan and J. Platt. A convolutional neural network hand tracker. pages 901–908, San Mateo, CA, 1995. Morgan Kaufmann. 1, 2</p>
<p>[30] B. A. Olshausen and D. J. Field. Sparse coding with an overcomplete basis set: a strategy employed by v1? Vision Research, 37(23):331 1–3325, 1997. 2 [3 1] M. Osadchy, Y. LeCun, and M. Miller. Synergistic face detection and pose estimation with energy-based models. Journal of Machine Learning Research, 8: 1197–1215, May 2007. 1, 2</p>
<p>[32] M. Ranzato, C. Poultney, S. Chopra, and Y. LeCun. Efficient learning of sparse representations with an energy-based model. In NIPS’07. MIT Press, 2007. 1, 2</p>
<p>[33] W. R. Schwartz, A. Kembhavi, D. Harwood, and L. S. Davis. Human detection using partial least squares analysis. In Computer Vision, 2009 IEEE 12th International Conference on, pages 24 –31, 29 2009-oct. 2 2009. 1</p>
<p>[34] P. Sermanet, S. Chintala, and Y. LeCun. Convolutional neural networks applied to house numbers digit classification. In Proceedings of International Conference on Pattern Recognition, 2012. 5</p>
<p>[35] P. Sermanet and Y. LeCun. Traffic sign recognition with multi-scale convolutional networks. In Proceedings of International Joint Conference on Neural Networks, 2011. 5</p>
<p>[36] G. Taylor, R. Fergus, G. Williams, I. Spiro, and C. Bregler. Pose-sensitive embedding by nonlinear nca regression. In Advances in Neural Information Processing Systems NIPS 23, 2010. 1, 2</p>
<p>[37] R. Vaillant, C. Monrocq, and Y. LeCun. Original approach for the localisation of objects in images. IEE Proc on Vision, Image, and Signal Processing, 141(4):245–250, August 1994. 1, 2</p>
<p>[38] S. Walk, N. Majer, K. Schindler, and B. Schiele. New fea-  tures and insights for pedestrian detection. In CVPR 2010, San Francisco, California. 1, 2</p>
<p>[39] M. Zeiler, D. Krishnan, G. Taylor, and R. Fergus. Deconvolutional Networks. In CVPR’10. IEEE, 2010. 2 333666333311</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
