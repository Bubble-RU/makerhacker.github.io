<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>373 cvpr-2013-SWIGS: A Swift Guided Sampling Method</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-373" href="../cvpr2013/cvpr-2013-SWIGS%3A_A_Swift_Guided_Sampling_Method.html">cvpr2013-373</a> <a title="cvpr-2013-373-reference" href="#">cvpr2013-373-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>373 cvpr-2013-SWIGS: A Swift Guided Sampling Method</h1>
<br/><p>Source: <a title="cvpr-2013-373-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Fragoso_SWIGS_A_Swift_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Victor Fragoso, Matthew Turk</p><p>Abstract: We present SWIGS, a Swift and efficient Guided Sampling method for robust model estimation from image feature correspondences. Our method leverages the accuracy of our new confidence measure (MR-Rayleigh), which assigns a correctness-confidence to a putative correspondence in an online fashion. MR-Rayleigh is inspired by Meta-Recognition (MR), an algorithm that aims to predict when a classifier’s outcome is correct. We demonstrate that by using a Rayleigh distribution, the prediction accuracy of MR can be improved considerably. Our experiments show that MR-Rayleigh tends to predict better than the often-used Lowe ’s ratio, Brown’s ratio, and the standard MR under a range of imaging conditions. Furthermore, our homography estimation experiment demonstrates that SWIGS performs similarly or better than other guided sampling methods while requiring fewer iterations, leading to fast and accurate model estimates.</p><br/>
<h2>reference text</h2><p>[1] H. Bay, A. Ess, T. Tuytelaars, and L. Van Gool. Speeded-up robust features (surf). Comput. Vis. Image Underst., 110(3):346–359, June 2008. 4</p>
<p>[2] A. S. Brahmachari and S. Sarkar. BLOGS: Balanced local and global search for non-degenerate two view epipolar geometry. In Proc. IEEE Intl. Conf. on Computer Vision, 2009. 1, 2, 4, 6, 8</p>
<p>[3] M. Brown, R. Szeliski, and S. Winder. Multi-image matching using multi-scale oriented patches. In Proc. IEEE Computer Vision and Pattern Recognition, 2005. 1, 2</p>
<p>[4] J. Cech, J. Matas, and M. Perdoch. Efficient sequential correspondence selection by cosegmentation. IEEE Trans. Pattern Anal. Mach. Intell., 32(9): 1568–1581, Sept. 2010. 2</p>
<p>[5] T.-J. Chin, J. Yu, and D. Suter. Accelerated hypothesis generation for multistructure data via preference analysis. IEEE Trans. Pattern Anal. Mach. Intell., 43(4):625–638, 2012. 1, 2</p>
<p>[6] O. Chum and J. Matas. Matching with PROSAC progressive sample consensus. In Proc. IEEE Computer Vision and Pattern Recognition, 2005. 1</p>
<p>[7] O. Chum, J. Matas, and J. Kittler. Locally optimized RANSAC. In Proc. Pattern Recognition (DAGM Symposium), 2003. 1</p>
<p>[8] T. Fawcett. An introduction to ROC analysis. Pattern Recogn. Lett., 27(8):861–874, Jun. 2006. 5</p>
<p>[9] M. A. Fischler and R. C. Bolles. Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography. Commun. ACM, 24(6):381–395, June 1981. 1</p>
<p>[10] L. Goshen and I. Shimshoni. Guided sampling via weak motion models and outlier sample generation for epipolar geometry estimation. In Proc. IEEE Computer Vision and Pattern Recognition, 2005. 1</p>
<p>[11] L. Goshen and I. Shimshoni. Balanced exploration and exploitation model search for efficient epipolar geometry estimation. IEEE Trans. Pattern Anal. Mach. Intell., 30(7): 1230–1242, July 2008. 2, 3, 6, 8</p>
<p>[12] A. Irschara, C. Zach, J.-M. Frahm, and H. Bischof. From structurefrom-motion point clouds to fast location recognition. In Proc. IEEE Computer Vision and Pattern Recognition, 2009. 1</p>
<p>[13] Y. Li, N. Snavely, and D. P. Huttenlocher. Location recognition using prioritized feature matching. In Proc. European Conf. on Computer Vision, 2010. 1</p>
<p>[14] D. G. Lowe. Distinctive image features from scale-invariant keypoints. Intl. Journal of Computer Vision, 60(2):91–1 10, Nov. 2004. 1, 2, 4</p>
<p>[15] K. Mikolajczyk and C. Schmid. A performance evaluation of local descriptors. IEEE Trans. Pattern Anal. Mach. Intell., 27(10), Oct. 2005. 4</p>
<p>[16] T. Sattler, B. Leibe, and L. Kobbelt. Fast image-based localization using direct 2d-to-3d matching. In Proc. IEEE Intl. Conf. on Computer Vision, 2011. 1</p>
<p>[17] T. a. Sattler. SCRAMSAC: Improving RANSAC’s efficiency with a spacial consistency filter. In Proc. IEEE Intl. Conf. on Computer Vision, 2009. 2</p>
<p>[18] W. J. Scheirer, A. Rocha, R. J. Micheals, and T. E. Boult. Meta–  Recognition: The theory and practice of recognition score analysis. IEEE Trans. Pattern Anal. Mach. Intell., 33(8): 1689–1695, Aug. 2011. 1, 3, 7, 8</p>
<p>[19] B. Tordoff and D. W. Murray. Guided sampling and consensus for motion estimation. In Proc. European Conf. on Computer Vision, 2002. 1, 2, 3, 6, 8</p>
<p>[20] P. H. S. Torr. Bayesian model estimation and selection for epipolar geometry and generic manifold fitting. Intl. Journal of Computer Vision, 50(1):35–61, Apr. 2002. 1</p>
<p>[21] P. H. S. Torr and A. Zisserman. MLESAC: A new robust estimator with application to estimating image geometry. Comput. Vis. Image Underst., 78(1): 138–156, Apr. 2000. 6 222777777755</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
