<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>261 cvpr-2013-Learning by Associating Ambiguously Labeled Images</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-261" href="../cvpr2013/cvpr-2013-Learning_by_Associating_Ambiguously_Labeled_Images.html">cvpr2013-261</a> <a title="cvpr-2013-261-reference" href="#">cvpr2013-261-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>261 cvpr-2013-Learning by Associating Ambiguously Labeled Images</h1>
<br/><p>Source: <a title="cvpr-2013-261-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Zeng_Learning_by_Associating_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Zinan Zeng, Shijie Xiao, Kui Jia, Tsung-Han Chan, Shenghua Gao, Dong Xu, Yi Ma</p><p>Abstract: We study in this paper the problem of learning classifiers from ambiguously labeled images. For instance, in the collection of new images, each image contains some samples of interest (e.g., human faces), and its associated caption has labels with the true ones included, while the samplelabel association is unknown. The task is to learn classifiers from these ambiguously labeled images and generalize to new images. An essential consideration here is how to make use of the information embedded in the relations between samples and labels, both within each image and across the image set. To this end, we propose a novel framework to address this problem. Our framework is motivated by the observation that samples from the same class repetitively appear in the collection of ambiguously labeled training images, while they are just ambiguously labeled in each image. If we can identify samples of the same class from each image and associate them across the image set, the matrix formed by the samples from the same class would be ideally low-rank. By leveraging such a low-rank assump- tion, we can simultaneously optimize a partial permutation matrix (PPM) for each image, which is formulated in order to exploit all information between samples and labels in a principled way. The obtained PPMs can be readily used to assign labels to samples in training images, and then a standard SVM classifier can be trained and used for unseen data. Experiments on benchmark datasets show the effectiveness of our proposed method.</p><br/>
<h2>reference text</h2><br/>
<br/><br/><br/></body>
</html>
