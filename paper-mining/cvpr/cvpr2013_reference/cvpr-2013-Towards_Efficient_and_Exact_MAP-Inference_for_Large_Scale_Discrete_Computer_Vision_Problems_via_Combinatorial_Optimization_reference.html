<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>436 cvpr-2013-Towards Efficient and Exact MAP-Inference for Large Scale Discrete Computer Vision Problems via Combinatorial Optimization</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-436" href="../cvpr2013/cvpr-2013-Towards_Efficient_and_Exact_MAP-Inference_for_Large_Scale_Discrete_Computer_Vision_Problems_via_Combinatorial_Optimization.html">cvpr2013-436</a> <a title="cvpr-2013-436-reference" href="#">cvpr2013-436-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>436 cvpr-2013-Towards Efficient and Exact MAP-Inference for Large Scale Discrete Computer Vision Problems via Combinatorial Optimization</h1>
<br/><p>Source: <a title="cvpr-2013-436-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Kappes_Towards_Efficient_and_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Jörg Hendrik Kappes, Markus Speth, Gerhard Reinelt, Christoph Schnörr</p><p>Abstract: Discrete graphical models (also known as discrete Markov random fields) are a major conceptual tool to model the structure of optimization problems in computer vision. While in the last decade research has focused on fast approximative methods, algorithms that provide globally optimal solutions have come more into the research focus in the last years. However, large scale computer vision problems seemed to be out of reach for such methods. In this paper we introduce a promising way to bridge this gap based on partial optimality and structural properties of the underlying problem factorization. Combining these preprocessing steps, we are able to solve grids of size 2048 2048 in less than 90 seconds. On the hitherto unsolva2b04le8 C×h2i0ne4s8e character dataset of Nowozin et al. we obtain provably optimal results in 56% of the instances and achieve competitive runtimes on other recent benchmark problems. While in the present work only generalized Potts models are considered, an extension to general graphical models seems to be feasible.</p><br/>
<h2>reference text</h2><p>[1] BrainWeb: Simulated brain database. http://brainweb. bic.mni.mcgill.ca/brainweb/.</p>
<p>[2] The probabilistic inference challenge (PIC 2011). http://www.cs.huji.ac.il/project/PASCAL/.</p>
<p>[3] K. Alahari, P. Kohli, and P. H. S. Torr. Dynamic hybrid algorithms for MAP inference in discrete MRFs. TPAMI, 32(10): 1846–1857, 2010.</p>
<p>[4] B. Andres, T. Beier, and J. H. Kappes. OpenGM: A C++ library for discrete graphical models, 2012. http://arxiv.org/abs/1206.01 11. 111777555755</p>
<p>[5] T. Bonato. Contraction-based Separation and Lifting for Solving the Max-Cut Problem. Optimus Verlag, 2011.</p>
<p>[6] E. Boros and P. L. Hammer. Pseudo-Boolean optimization. Discrete Applied Mathematics, 123(1–3): 155– 225, 2002.</p>
<p>[7] Y. Boykov and V. Kolmogorov. An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision. TPAMI, 26(9): 1124–1 137, 2004.</p>
<p>[8] Y. Boykov, O. Veksler, and R. Zabih. Fast approximate energy minimization via graph cuts. TPAMI, 23(1 1): 1222–1239, 2001.</p>
<p>[9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest. Introduction to Algorithms. MIT Press, 1990.</p>
<p>[10] V. Franc, S. Sonnenburg, and T. Werner. Cutting plane methods in machine learning. In Optimization for Machine Learning. MIT Press, 2011.</p>
<p>[11] P. Hammer. Some network flow problems solved with pseudo-Boolean programming. Operations Research, 13(3):388–399, 1965.</p>
<p>[12] T. Hazan and A. Shashua. Convergent message-passing algorithms for inference over general graphs with convex free energies. In UAI, 2008.</p>
<p>[13] J. K. Johnson, D. M. Malioutov, and A. S. Willsky. Lagrangian relaxation for MAP estimation in graphical models. In Proceedings of the Annual Allerton Conference on Communication, Control, and Computing, 2007.</p>
<p>[14] F. Kahl and P. Strandmark. Generalized roof duality</p>
<p>[15]</p>
<p>[16]</p>
<p>[17]</p>
<p>[18]</p>
<p>[19]</p>
<p>[20]</p>
<p>[21]</p>
<p>[22]</p>
<p>[23]</p>
<p>[24]  for pseudo-Boolean optimization. In ICCV, 2011. J. H. Kappes, B. Savchynskyy, and C. Schnörr. A bundle approach to efficient MAP-inference by Lagrangian relaxation. In CVPR, 2012. J. H. Kappes, M. Speth, B. Andres, G. Reinelt, and C. Schnörr. Globally optimal image partitioning by multicuts. In EMMCVPR, 2011. P. Kohli, A. Shekhovtsov, C. Rother, V. Kolmogorov, and P. H. S. Torr. On partial optimality in multi-label MRFs. In ICML, 2008. D. Koller and N. Friedman. Probabilistic Graphical Models: Principles and Techniques. MIT Press, 2009. V. Kolmogorov. Convergent tree-reweighted message passing for energy minimization. TPAMI, 28(10): 1568– 1583, 2006. N. Komodakis, N. Paragios, and G. Tziritas. MRF energy minimization and beyond via dual decomposition. TPAMI, 33(3):531–552, 2011. N. Komodakis and G. Tziritas. Approximate labeling via graph cuts based on linear programming. TPAMI, 29(8): 1436–1453, 2007. I. Kovtun. Partial optimal labeling search for a NP-hard subclass of (max, +) problems. In Proceedings of the DAGM Symposium, 2003. V. Lempitsky, C. Rother, S. Roth, and A. Blake. Fusion moves for Markov random field optimization. TPAMI, 32(8): 1392–1405, 2010. S. Nowozin, C. Rother, S. Bagon, T. Sharp, B. Yao,</p>
<p>[25]</p>
<p>[26]</p>
<p>[27]</p>
<p>[28]</p>
<p>[29]</p>
<p>[30]  [3 1]</p>
<p>[32]</p>
<p>[33]</p>
<p>[34]  and P. Kohli. Decision tree fields. In ICCV, 2011. J. B. Orlin. A faster strongly polynomial time algorithm for submodular function minimization. In IPCO, 2007. L. Otten and R. Dechter. Anytime AND/OR depth-first search for combinatorial optimization. In SOCS, 2011. C. Rother, V. Kolmogorov, V. Lempitsky, and M. Szummer. Optimizing binary MRFs via extended roof duality. In CVPR, 2007. B. Savchynskyy, S. Schmidt, J. H. Kappes, and C. Schnörr. A study of Nesterov’s scheme for Lagrangian decomposition and MAP labeling. In CVPR, 2011. B. Savchynskyy, S. Schmidt, J. H. Kappes, and C. Schnörr. Efficient MRF energy minimization via adaptive diminishing smoothing. In UAI, 2012. M. I. Schlesinger. Syntactic analysis of two-dimensional visual signals in noisy conditions. Kibernetika, 4: 113–130, 1976. N. N. Schraudolph. Polynomial-time exact inference in NP-hard binary MRFs via reweighted perfect matching. In AISTATS, 2010. N. N. Schraudolph and D. Kamenetsky. Efficient exact inference in planar Ising models. In NIPS, 2009. A. Shekhovtsov and V. Hlavá ˇc. On partial optimality by auxiliary submodular problems. In Control Systems and Computers, 2011. M. Sun, M. Telaprolu, H. Lee, and S. Savarese. Efficient and exact MAP-MRF inference using branch and  bound. In AISTATS, 2012.</p>
<p>[35] P. Swoboda, B. Savchynskyy, J. H. Kappes, and C. Schnörr. Partial optimality via iterative pruning for the Potts model. In SSVM, 2013.</p>
<p>[36] M. J. Wainwright and M. I. Jordan. Graphical models, exponential families, and variational inference. Foundations and Trends in Machine Learning, 1(1–2): 1–305, 2008.</p>
<p>[37] T. Werner. Revisiting the linear programming relaxation approach to Gibbs energy minimization and weighted constraint satisfaction. TPAMI, 32(8): 1474– 1488, 2010. 111777555866</p>
<br/>
<br/><br/><br/></body>
</html>
