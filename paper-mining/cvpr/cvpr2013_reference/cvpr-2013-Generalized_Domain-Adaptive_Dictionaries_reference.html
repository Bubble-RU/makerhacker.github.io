<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>185 cvpr-2013-Generalized Domain-Adaptive Dictionaries</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-185" href="../cvpr2013/cvpr-2013-Generalized_Domain-Adaptive_Dictionaries.html">cvpr2013-185</a> <a title="cvpr-2013-185-reference" href="#">cvpr2013-185-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>185 cvpr-2013-Generalized Domain-Adaptive Dictionaries</h1>
<br/><p>Source: <a title="cvpr-2013-185-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Shekhar_Generalized_Domain-Adaptive_Dictionaries_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Sumit Shekhar, Vishal M. Patel, Hien V. Nguyen, Rama Chellappa</p><p>Abstract: Data-driven dictionaries have produced state-of-the-art results in various classification tasks. However, when the target data has a different distribution than the source data, the learned sparse representation may not be optimal. In this paper, we investigate if it is possible to optimally represent both source and target by a common dictionary. Specifically, we describe a technique which jointly learns projections of data in the two domains, and a latent dictionary which can succinctly represent both the domains in the projected low-dimensional space. An efficient optimization technique is presented, which can be easily kernelized and extended to multiple domains. The algorithm is modified to learn a common discriminative dictionary, which can be further used for classification. The proposed approach does not require any explicit correspondence between the source and target domains, and shows good results even when there are only a few labels available in the target domain. Various recognition experiments show that the methodperforms onparor better than competitive stateof-the-art methods.</p><br/>
<h2>reference text</h2><p>[1] M. Aharon, M. Elad, and A. Bruckstein. K-SVD: An algorithm for designing overcomplete dictionaries for sparse representation. IEEE 333666557  Aicne)Rgamot(%in7560 a5zon/WNuembcarofl1cu0breaydws(iothur)vcaeiymn1g5esouprcimlasFSgDenL2u0mber%(taRnoigcet)876540 12RNeucmobgn3ritfdca4eo(snbwr)iytha5docmCDAisaSnpl6tLeRrzyc/ohAslnaimDWzSe7LRobncam8 cgta)en(Ri%o 348572601 2R0ecognit3D0(rcmate)nswio4h0dCDAimaSeltLnRzcsAh/oi5mnD0WSaLzeRobncm60 Figure 4. Recognition performance under different: (a) number of source images, (b) dictionary size, and (c) common subspace dimension.  Naming of domains is done as source/target. Transactions on Signal Processing, 54(11):43 11–4322, Nov 2006. 2</p>
<p>[2] H. Daumé III. Frustratingly easy domain adaptation. In ACL, 2007. 1</p>
<p>[3] M. Elad and M. Aharon. Image denoising via sparse and redundant representations over learned dictionaries. IEEE Transactions on Image Processing, 15(12):3736–3745, Dec 2006. 1</p>
<p>[4] I. Gkioulekas and T. Zickler. Dimensionality reduction using the sparse linear model. In NIPS, pages 271–279, 2011. 2</p>
<p>[5] B. Gong, Y. Shi, F. Sha, and K. Grauman. Geodesic flow kernel for unsupervised domain adaptation. In IEEE Conference on Computer Vision and Pattern Recognition, pages 2066–2073, June 2012. 2, 6, 7</p>
<p>[6] R. Gopalan, R. Li, and R. Chellappa. Domain adaptation for object recognition: An unsupervised approach. In IEEE International Conference on Computer Vision, 2011. 2, 6, 7</p>
<p>[7] R. Gopalan, R. Li, and R. Chellappa. Unsupervised adaptation across domain shift by generating intermediate data representations. In IEEE Transactions on Pattern Analysis and Machine Intelligence, Under Review. 7</p>
<p>[8] G. Griffin, A. Holub, and P. Perona. Caltech-256 object category dataset. Technical Report 7694, California Institute of Technology, 2007. 6</p>
<p>[9] R. Gross, I. Matthews, J. F. Cohn, T. Kanade, and S. Baker. Multipie. Image Vision Computing, 28(5):807–813, 2010. 5</p>
<p>[10] Y. Han, F. Wu, D. Tao, J. Shao, Y. Zhuang, and J. Jiang. Sparse unsupervised dimensionality reduction for multiple view data. IEEE Transactions on Circuits and Systems for Video Technology, 22(10): 1485–1496, Oct. 2012. 2</p>
<p>[11] I.-H. Jhuo, D. Liu, D. Lee, and S.-F. Chang. Robust visual domain adaptation with low-rank reconstruction. In IEEE Conference on Computer Vision and Pattern Recognition, pages 2168–2175, June 2012. 2, 6, 7</p>
<p>[12] Y. Jia, M. Salzmann, and T. Darrell. Factorized latent spaces with structured sparsity. In NIPS, pages 982–990, 2010. 1</p>
<p>[13] B. Kulis, K. Saenko, and T. Darrell. What you saw is not what you get: Domain adaptation using asymmetric kernel transforms. In IEEE Conference on Computer Vision and Pattern Recognition, pages 1785–1792, June 2011. 2</p>
<p>[14] J. Mairal, F. Bach, and J. Ponce. Task-driven dictionary learning. IEEE Transactions on Pattern Analysis and Machine Intelligence, 34(4):791–804, April 2012. 2</p>
<p>[15] H. V. Nguyen, V. M. Patel, N. M. Nasrabadi, and R. Chellappa. Sparse embedding: A framework for sparsity promoting dimensionality reduction. In European Conference on Computer Vision, pages 414–427, Oct. 2012. 2, 4</p>
<p>[16] B. Olshausen and D. Field. Sparse coding with an overcomplete basis set: A strategy employed by v1? Vision research, 37(23):331 1–3325, 1997. 1</p>
<p>[17] Y. Pati, R. Rezaiifar, and P. Krishnaprasad. Orthogonal matching pursuit: recursive function approximation with applications to wavelet decomposition. In Asilomar Conference on Signals, Systems and Computers, 1993. 4</p>
<p>[18] J. Pillai, A. Shrivastava, V. Patel, and R. Chellappa. Learning discriminative dictionaries with partially labeled data. In IEEE Conference on Image Processing, Oct. 2012. 3</p>
<p>[19] Q. Qiu, V. M. Patel, P. Turaga, and R. Chellappa. Domain adaptive dictionary learning. In ECCV, 2012. 1</p>
<p>[20] I. Ramírez, P. Sprechmann, and G. Sapiro. Classification and clustering via dictionary learning with structured incoherence and shared features. In IEEE Conference on Computer Vision and Pattern Recognition, pages 3501–3508, June 2010. 3</p>
<p>[21] K. Saenko, B. Kulis, M. Fritz, and T. Darrell. Adapting visual category models to new domains. In ECCV, volume 6314, pages 213– 226, 2010. 2, 6, 7</p>
<p>[22] A. Sharma and D. W. Jacobs. Bypassing synthesis: Pls for face recognition with pose, low-resolution and sketch. In IEEE Conference on Computer Vision and Pattern Recognition, pages 593–600, June 2011. 6</p>
<p>[23] A. Sharma, A. Kumar, H. D. III, and D. W. Jacobs. Generalized multiview analysis: A discriminative latent space. In IEEE Conference on Computer Vision and Pattern Recognition, pages 2160– 2167, June 2012. 6</p>
<p>[24] S. Wang, L. Zhang, Y. Liang, and Q. Pan. Semi-coupled dictio-</p>
<p>[25]</p>
<p>[26]</p>
<p>[27]</p>
<p>[28]  nary learning with applications to image super-resolution and photosketch synthesis. In IEEE Conference on Computer Vision and Pattern Recognition, pages 2216–2223, June 2012. 2 Z. Wen and W. Yin. A feasible method for optimization with orthogonality constraints. Technical report, Rice University, 2010. 4 J. Wright, A. Yang, A. Ganesh, S. Sastry, and Y. Ma. Robust face recognition via sparse representation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 3 1(2):210–227, 2009. 1 J. Yang, Z. Wang, Z. Lin, S. Cohen, and T. Huang. Coupled dictionary training for image super-resolution. IEEE Transactions on Image Processing, 21(8):3467–3478, Aug. 2012. 2 M. Yang, L. Zhang, X. Feng, and D. Zhang. Fisher Discrimination Dictionary learning for sparse representation. In IEEE International Conference on Computer Vision, pages 543–550, Nov. 2011. 3, 4, 6, 7</p>
<p>[29] L. Zhang, M. Yang, Z. Feng, and D. Zhang. On the dimensionality reduction for sparse representation based face recognition. In International Conference on Pattern Recognition, pages 1237–1240, Aug. 2010. 2 333666668</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
