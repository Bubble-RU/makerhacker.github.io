<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>91 cvpr-2013-Consensus of k-NNs for Robust Neighborhood Selection on Graph-Based Manifolds</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-91" href="../cvpr2013/cvpr-2013-Consensus_of_k-NNs_for_Robust_Neighborhood_Selection_on_Graph-Based_Manifolds.html">cvpr2013-91</a> <a title="cvpr-2013-91-reference" href="#">cvpr2013-91-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>91 cvpr-2013-Consensus of k-NNs for Robust Neighborhood Selection on Graph-Based Manifolds</h1>
<br/><p>Source: <a title="cvpr-2013-91-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Premachandran_Consensus_of_k-NNs_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Vittal Premachandran, Ramakrishna Kakarala</p><p>Abstract: Propagating similarity information along the data manifold requires careful selection of local neighborhood. Selecting a “good” neighborhood in an unsupervised setting, given an affinity graph, has been a difficult task. The most common way to select a local neighborhood has been to use the k-nearest neighborhood (k-NN) selection criterion. However, it has the tendency to include noisy edges. In this paper, we propose a way to select a robust neighborhood using the consensus of multiple rounds of k-NNs. We explain how using consensus information can give better control over neighborhood selection. We also explain in detail the problems with another recently proposed neighborhood selection criteria, i.e., Dominant Neighbors, and show that our method is immune to those problems. Finally, we show the results from experiments in which we compare our method to other neighborhood selection approaches. The results corroborate our claims that consensus ofk-NNs does indeed help in selecting more robust and stable localities.</p><br/>
<h2>reference text</h2><p>[1] X. Bai, X. Yang, L. Latecki, W. Liu, and Z. Tu. Learning context-sensitive shape similarity by graph transduction. IEEE Trans. Pattern Anal. Machine Intell., 32(5):861–874, 2010.</p>
<p>[2] S. Belongie, J. Malik, and J. Puzicha. Shape matching and object recognition using shape contexts. IEEE Trans. Pattern Anal. Machine Intell. , pages 509–522, 2002.</p>
<p>[3] M. Jaakkola. Partially labeled classification with markov random walks. In NIPS, volume 2, page 945. MIT Press, 2002.</p>
<p>[4] P. Kontschieder, M. Donoser, and H. Bischof. Beyond pairwise shape similarity analysis. In ACCV, pages 655–666. Springer, 2010.</p>
<p>[5] A. Lancichinetti and S. Fortunato. Consensus clustering in complex networks. Scientific Reports, 2, 2012.</p>
<p>[6] H. Ling and D. Jacobs. Shape classification using the innerdistance. IEEE Trans. Pattern Anal. Machine Intell., pages 286–299, 2007.</p>
<p>[7] H. Liu, X. Yang, L. Latecki, and S. Yan. Dense neighborhoods on affinity graph. Int. J. of Computer Vision, pages 1–18, 2011.</p>
<p>[8] S. Monti, P. Tamayo, J. Mesirov, and T. Golub. Consensus clustering: a resampling-based method for class discovery and visualization of gene expression microarray data. Machine learning, 52(1):91–1 18, 2003.</p>
<p>[9] M. Pavan and M. Pelillo. Dominant sets and pairwise clustering. IEEE Trans. Pattern Anal. Machine Intell., 29(1): 167–</p>
<p>[10]</p>
<p>[11]</p>
<p>[12]</p>
<p>[13]</p>
<p>[14]</p>
<p>[15]</p>
<p>[16]</p>
<p>[17]</p>
<p>[18]</p>
<p>[19]  172, 2007. P. Perona and L. Zelnik-Manor. Self-tuning spectral clustering. NIPS, 17: 1601–1608, 2004. S. Roweis and L. Saul. Nonlinear dimensionality reduction by locally linear embedding. Science, 290(5500):2323– 2326, 2000. B. Sch o¨lkopf, A. Smola, and K. M ¨uller. Nonlinear component analysis as a kernel eigenvalue problem. Neural computation, 10(5): 1299–1319, 1998. J. Tenenbaum, V. De Silva, and J. Langford. A global geometric framework for nonlinear dimensionality reduction. Science, 290(5500):2319–2323, 2000. O. Tuzel, F. Porikli, and P. Meer. Human detection via classification on riemannian manifolds. In CVPR, pages 1–8. IEEE, 2007. X. Yang, X. Bai, L. Latecki, and Z. Tu. Improving shape retrieval by learning graph transduction. ECCV, pages 788– 801, 2008. X. Yang, S. Koknar-Tezel, and L. Latecki. Locally constrained diffusion process on locally densified distance spaces with applications to shape retrieval. In CVPR, pages 357–364. IEEE, 2009. X. Yang and L. Latecki. Affinity learning on a tensor product graph with applications to shape and image retrieval. In CVPR, pages 2369–2376. IEEE, 2011. X. Yang, L. Prasad, and L. Latecki. Affinity learning with diffusion on tensor product graph. IEEE Trans. Pattern Anal. Machine Intell., 2012. Z. Zhang, J. Wang, and H. Zha. Adaptive manifold learning. IEEE Trans. Pattern Anal. Machine Intell., 34(2):253–265, 2012.  111556990199</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
