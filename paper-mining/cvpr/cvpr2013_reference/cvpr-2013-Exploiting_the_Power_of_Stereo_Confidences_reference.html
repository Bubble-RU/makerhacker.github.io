<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>155 cvpr-2013-Exploiting the Power of Stereo Confidences</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-155" href="../cvpr2013/cvpr-2013-Exploiting_the_Power_of_Stereo_Confidences.html">cvpr2013-155</a> <a title="cvpr-2013-155-reference" href="#">cvpr2013-155-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>155 cvpr-2013-Exploiting the Power of Stereo Confidences</h1>
<br/><p>Source: <a title="cvpr-2013-155-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Pfeiffer_Exploiting_the_Power_2013_CVPR_paper.pdf">pdf</a></p><p>Author: David Pfeiffer, Stefan Gehrig, Nicolai Schneider</p><p>Abstract: Applications based on stereo vision are becoming increasingly common, ranging from gaming over robotics to driver assistance. While stereo algorithms have been investigated heavily both on the pixel and the application level, far less attention has been dedicated to the use of stereo confidence cues. Mostly, a threshold is applied to the confidence values for further processing, which is essentially a sparsified disparity map. This is straightforward but it does not take full advantage of the available information. In this paper, we make full use of the stereo confidence cues by propagating all confidence values along with the measured disparities in a Bayesian manner. Before using this information, a mapping from confidence values to disparity outlier probability rate is performed based on gathered disparity statistics from labeled video data. We present an extension of the so called Stixel World, a generic 3D intermediate representation that can serve as input for many of the applications mentioned above. This scheme is modified to directly exploit stereo confidence cues in the underlying sensor model during a maximum a poste- riori estimation process. The effectiveness of this step is verified in an in-depth evaluation on a large real-world traffic data base of which parts are made publicly available. We show that using stereo confidence cues allows both reducing the number of false object detections by a factor of six while keeping the detection rate at a near constant level.</p><br/>
<h2>reference text</h2><p>[1] H. Badino, U. Franke, and R. Mester. Free space computation using stochastic occupancy grids and dynamic pro333000333  configurationmetric number of fpframes with fp number of fpframes with fpdetection rate  consfipdabersnicef lmianteponigPM KnLo RMn CN e1327, 2761924079 305(a)2,0376 01645319087512 15 0976430769(b)204978045930 0. 78 890 127415  Table 1: For evaluating our extension of the Stixel computation scheme, we considered three different stereo confidence metrics and compared against both the base line approach of Pfeiffer et al. and the straight-forward way of using sparsification of the disparity map. Table a) shows the false positive (fp) results for the large data set (76, 000 frames). Table b) shows the result for the smaller data set (2,500 frames) for which the detection rate is computed using ground truth object data. The  following thresholds for sparsification were used:</p>
<p>[2]</p>
<p>[3]</p>
<p>[4]</p>
<p>[5]  cLmCin  = 0.1,  gramming. In Workshop on Dynamical Vision, ICCV, Rio de Janeiro, Brazil, October 2007. 1, 2, 7 H. Badino, U. Franke, and D. Pfeiffer. The Stixel World A compact medium level representation of the 3D-world. In DAGM, pages 51–60, Jena, Germany, September 2009. 1, 2 R. Benenson, R. Timofte, and L. Van Gool. Stixels estimation without depth map computation. In IEEE CVVT:E2M at ICCV, November 2011. 2 G. Egnal, M. Mintz, and R. P. Wildes. A stereo confidence metric using single view imagery with comparison to five alternative approaches. Image Vision Computing, 22(12):943– 957, 2004. 2 A. E. Elfes and L. Matthies. Sensor integration for robot navigation: Combining sonar and stereo range data in a gridbased representation. In 28th IEEE Conference on Decision and Control, 1987. 1, 2</p>
<p>[6] D. Gallup, M. Pollefeys, and J.-M. Frahm. 3d reconstruction using an n-layer heightmap. In DAGM, pages 1–10, Darmstadt, Germany, September 2010. 2</p>
<p>[7] S. Gehrig, F. Eberli, and T. Meyer. A real-time low-power stereo vision engine using semi-global matching. In ICVS, Li` ege, Belgium, October 2009. Springer-Verlag. 3</p>
<p>[8] A. Geiger, P. Lenz, and R. Urtasun. Are we ready for autonomous driving? the KITTI vision benchmark suite. In IEEE CVPR, pages 3354–3361, Providence, USA, June 2012. 1</p>
<p>[9] R. Haeusler and R. Klette. Analysis of KITTI data for stereo analysis with stereo confidence measures. In ECCV Workshop on Unsolved Problems in Optical Flow and Stereo Estimation, pages 158–167, Florence, Italy, 2012. 2, 3</p>
<p>[10] H. Hirschm u¨ller. Accurate and efficient stereo processing by semi-global matching and mutual information. In IEEE CVPR, pages 807–814, San Diego, USA, June 2005. 1, 3</p>
<p>[11] H. Hirschm u¨ller and D. Scharstein. Evaluation of cost functions for stereo matching. In IEEE CVPR, Minneapolis, Minnesota, USA, June 2007. IEEE Computer Society. 3</p>
<p>[12] X. Hu and P. Mordohai. Evaluation of stereo confidence indoors and outdoors. In IEEE CVPR, pages 1466–1473, San Francisco, CA, USA, June 2010. 1, 2, 3, 3</p>
<p>[13] D. Kondermann, S. Abraham, G. J. Brostow, W. F ¨orstner, S. Gehrig, A. Imiya, B. J ¨ahne, F. Klose, M. A. Magnor,  cPmKinRN  = 0.15, and  cmMiLnM  = 0.2.  H. Mayer, R. Mester, T. Pajdla, R. Reulke, and H. Zimmer. On performance analysis of optical flow algorithms. In Theoretical Foundations of Computer Vision, 2012. 4</p>
<p>[14] O. Mac Aodha, G. J. Brostow, and M. Pollefeys. Segmenting</p>
<p>[15]</p>
<p>[16]</p>
<p>[17]</p>
<p>[18]</p>
<p>[19]</p>
<p>[20]</p>
<p>[21]</p>
<p>[22]</p>
<p>[23]</p>
<p>[24]</p>
<p>[25]  video into classes of algorithm-suitability. In IEEE CVPR, pages 1054–1061, San Francisco, CA, USA, June 2010. 4 A. Milella and R. Siegwart. Stereo-based ego-motion estimation using pixel tracking and iterative closest point. In ICVS, pages 21–30, Bari, Italy, January 2006. 2, 7 K. M ¨uhlmann, D. Maier, J. Hesser, and R. M ¨anner. Calculating dense disparity maps from color stereo images, an efficient implementation. IJCV, 47(1-3):79–88, 2002. 3 D. Pfeiffer and U. Franke. Towards a global optimal multilayer Stixel representation of dense 3D data. In BMVC, Dundee, Scotland, August 2011. 1, 2, 5, 5, 8 S. Rusinkiewicz and M. Levoy. Efficient variants of the icp algorithm. In 3D Digital Imaging and Modeling, 2001. 7 D. Scharstein and R. Szeliski. Middlebury online stereo evaluation, 2002. http://vision.middlebury.edu/stereo. 1, 4 D. Scharstein and R. Szeliski. A taxonomy and evaluation of dense two-frame stereo correspondence algorithms. IJCV, 47(1-3):7–42, 2002. 1, 3, 4 F. Stein. The challenge of putting vision algorithms into a car. In The Eighth IEEE Workshop on Embedded Vision, CVPR, pages 89–94, Providence, RI, USA, June 2012. 5 P. Steingrube, S. Gehrig, and U. Franke. Performance evaluation of stereo algorithms for automotive applications. In ICVS, pages 285–294, Li` ege, Belgium, October 2009. 2 S. Thrun. Learning occupancy grid maps with forward sensor models. Autonomous Robots, 15: 111–127, 2003. 2, 5 A. Wedel, A. Meissner, C. Rabe, U. Franke, and D. Cremers. Detection and segmentation of independently moving objects from dense scene flow. In EMMCVPR, 2009. 3 Y. Zhang, A. S. Dhua, S. J. Kiselewich, and W. A. Bauson. Challenges of embedded computer vision in automotive safety systems. In B. Kisa cˇanin, S. S. Bhattacharyya, and  S. Chai, editors, Embedded Computer Vision, Adv. in Pattern Recognition, pages 257–279. Springer London, 2009. 5</p>
<p>[26] Z. Zhang. A stereovision system for a planetary rover: Calibration, correlation, registration, and fusion. In Proc. IEEE Workshop on Planetary Rover Technology and Systems, Minneapolis, USA, April 1996. 2 333000444</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
