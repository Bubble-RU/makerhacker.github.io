<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>375 cvpr-2013-Saliency Detection via Graph-Based Manifold Ranking</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-375" href="../cvpr2013/cvpr-2013-Saliency_Detection_via_Graph-Based_Manifold_Ranking.html">cvpr2013-375</a> <a title="cvpr-2013-375-reference" href="#">cvpr2013-375-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>375 cvpr-2013-Saliency Detection via Graph-Based Manifold Ranking</h1>
<br/><p>Source: <a title="cvpr-2013-375-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Yang_Saliency_Detection_via_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Chuan Yang, Lihe Zhang, Huchuan Lu, Xiang Ruan, Ming-Hsuan Yang</p><p>Abstract: Most existing bottom-up methods measure the foreground saliency of a pixel or region based on its contrast within a local context or the entire image, whereas a few methods focus on segmenting out background regions and thereby salient objects. Instead of considering the contrast between the salient objects and their surrounding regions, we consider both foreground and background cues in a different way. We rank the similarity of the image elements (pixels or regions) with foreground cues or background cues via graph-based manifold ranking. The saliency of the image elements is defined based on their relevances to the given seeds or queries. We represent the image as a close-loop graph with superpixels as nodes. These nodes are ranked based on the similarity to background and foreground queries, based on affinity matrices. Saliency detection is carried out in a two-stage scheme to extract background regions and foreground salient objects efficiently. Experimental results on two large benchmark databases demonstrate the proposed method performs well when against the state-of-the-art methods in terms of accuracy and speed. We also create a more difficult bench- mark database containing 5,172 images to test the proposed saliency model and make this database publicly available with this paper for further studies in the saliency field.</p><br/>
<h2>reference text</h2><p>[1] R. Achanta, F. Estrada, P. Wils, and S. Susstrunk. Salient region detection and segmentation. In ICVS, 2008. 1, 6</p>
<p>[2] R. Achanta, S. Hemami, F. Estrada, and S. Susstrunk. Frequencytuned salient region detection. In CVPR, 2009. 1, 4, 5, 6, 7</p>
<p>[3] R. Achanta, K. Smith, A. Lucchi, P. Fua, and S. Susstrunk. Slic superpixels. Technical report, EPFL, Tech.Rep. 149300, 2010. 3</p>
<p>[4] A. Borji, D. Sihite, and L. Itti. Salient object detection: A benchmark. In ECCV, 2012. 4, 6</p>
<p>[5] S. Brin and L. Page. The anatomy of a large-scale hypertextual web search engine. Computer networks and ISDN systems, 30(1): 107– 117, 1998. 2</p>
<p>[6] N. Bruce and J. Tsotsos. Saliency based on information maximization. In NIPS, 2005. 1</p>
<p>[7] K.-Y. Chang, T.-L. Liu, H.-T. Chen, and S.-H. Lai. Fusing generic objectness and visual saliency for salient object detection. In ICCV, 2011. 1, 6, 7</p>
<p>[8] T. Chen, M. Cheng, P. Tan, A. Shamir, and S. Hu. Sketch2photo: Internet image montage. ACM Trans. on Graphics, 2009. 1</p>
<p>[9] M. M. Cheng, G. X. Zhang, N. J. Mitra, X. Huang, and S. M. Hu. Global contrast based salient region detection. In CVPR, 2011. 1, 4, 6</p>
<p>[10] J. Feng, Y. Wei, L. Tao, C. Zhang, and J. Sun. Salient object detection by composition. In ICCV, 2011. 1</p>
<p>[11] S. Goferman, L. Zelnik-Manor, and A. Tal. Context-aware saliency detection. In CVPR, 2010. 1, 6, 7</p>
<p>[12] V. Gopalakrishnan, Y. Hu, and D. Rajan. Random walks on graphs for salient object detection in images. IEEE TIP, 2010. 1, 2</p>
<p>[13] L. Grady, M. Jolly, and A. Seitz. Segmenation from a box. In ICCV, 2011. 2</p>
<p>[14] J. Harel, C. Koch, and P. Perona. Graph-based visual saliency. In NIPS, 2006. 1, 6</p>
<p>[15] X. Hou and L. Zhang. Saliency detection: A spectral residual approach. In CVPR, 2007. 1, 6</p>
<p>[16] L. Itti. Automatic foveation for video compression using a neurobiological model of visual attention. IEEE TIP, 2004. 1</p>
<p>[17] L. Itti, C. Koch, and E. Niebur. A model of saliency-based visual attention for rapid scene analysis. IEEE PAMI, 1998. 1, 4, 6</p>
<p>[18] H. Jiang, J. Wang, Z. Yuan, T. Liu, N. Zheng, and S. Li. Automatic salient object segmentation based on contex and shape prior. In BMVC, 2011. 6, 7</p>
<p>[19] T. Judd, K. Ehinger, F. Durand, and A. Torralba. Learning to predict where humans look. In ICCV, 2009. 1</p>
<p>[20] T. H. Kim, K. M. Lee, and S. U. Lee. Learning full pairwise affinities for spectral segmentation. In CVPR, 2010. 2</p>
<p>[21] D. Klein and S. Frintrop. Center-surround divergence of feature statistics for salient object detection. In ICCV, 2011. 1</p>
<p>[22] V. Lempitsky, P. Kohli, C. Rother, and T. Sharp. Image segmentation with a bounding box prior. In ICCV, 2009. 2</p>
<p>[23] T. Liu, Z. Yuan, J. Sun, J. Wang, N. Zheng, X. Tang, and H. Shum. Learning to detect a salient object. IEEE PAMI, 2011. 1, 5</p>
<p>[24] Y. Lu, W. Zhang, H. Lu, and X. Y. Xue. Salient object detection using concavity context. In ICCV, 2011. 1</p>
<p>[25] Y. Ma and H. Zhang. Contrast-based image attention analysis by using fuzzy growing. ACM Multimedia, 2003. 1, 6</p>
<p>[26] A. Ng, M. Jordan, Y. Weiss, et al. On spectral clustering: Analysis and an algorithm. In NIPS, pages 849–856, 2002. 2</p>
<p>[27] F. Perazzi, P. Krahenbuhl, Y. Pritch, and A. Hornung. Saliency filters: Contrast based filtering for salient region detection. In CVPR, 2012. 1, 6</p>
<p>[28] U. Rutishauser, D. Walther, C. Koch, and P. Perona. Is bottom-up attention useful for object recognition? In CVPR, 2004. 1</p>
<p>[29] B. Scholkopf, J. Platt, J. Shawe-Taylor, A. Smola, and R. Williamson. Estimating the support of a high-dimensional distribution. Neural Computation, 2001. 3</p>
<p>[30] J. Sun, H. C. Lu, and S. F. Li. Saliency detection based on integration of boundary and soft-segmentation. In ICIP, 2012. 1 [3 1] B. Tatler. The central fixation bias in scene viewing: Selecting an optimal viewing position independently of motor biases and image feature distributions. Journal of Vision, 2007. 2</p>
<p>[32] L. Wang, J. Xue, N. Zheng, and G. Hua. Automatic salient object extraction with contextual cue. In ICCV, 2011. 1</p>
<p>[33] W. Wang, Y. Wang, Q. Huang, and W. Gao. Measuring visual saliency by site entropy rate. In CVPR, 2010. 1</p>
<p>[34] Y. C. Wei, F. Wen, W. J. Zhu, and J. Sun. Geodesic saliency using background priors. In ECCV, 2012. 2, 6</p>
<p>[35] Y. L. Xie, H. C. Lu, and M. H. Yang. Bayesian saliency via low and mid level cues. IEEE TIP, 2013. 1, 6</p>
<p>[36] J. Yang and M. Yang. Top-down visual saliency via joint crf and dictionary learning. In CVPR, 2012. 1</p>
<p>[37] Y. Zhai and M. Shah. Visual attention detection in video sequences using spatiotemporal cues. ACM Multimedia, 2006. 1, 6</p>
<p>[38] D. Zhou, O. Bousquet, T. Lal, J. Weston, and B. Scholkopf. Learning with local and global consistency. In NIPS, 2003. 3</p>
<p>[39] D. Zhou, J. Weston, A. Gretton, O. Bousquet, and B. Scholkopf. Ranking on data manifolds. In NIPS, 2004. 2, 3 3 3 111777113</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
