<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>269 cvpr-2013-Light Field Distortion Feature for Transparent Object Recognition</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-269" href="../cvpr2013/cvpr-2013-Light_Field_Distortion_Feature_for_Transparent_Object_Recognition.html">cvpr2013-269</a> <a title="cvpr-2013-269-reference" href="#">cvpr2013-269-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>269 cvpr-2013-Light Field Distortion Feature for Transparent Object Recognition</h1>
<br/><p>Source: <a title="cvpr-2013-269-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Maeno_Light_Field_Distortion_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Kazuki Maeno, Hajime Nagahara, Atsushi Shimada, Rin-Ichiro Taniguchi</p><p>Abstract: Current object-recognition algorithms use local features, such as scale-invariant feature transform (SIFT) and speeded-up robust features (SURF), for visually learning to recognize objects. These approaches though cannot apply to transparent objects made of glass or plastic, as such objects take on the visual features of background objects, and the appearance ofsuch objects dramatically varies with changes in scene background. Indeed, in transmitting light, transparent objects have the unique characteristic of distorting the background by refraction. In this paper, we use a single-shot light?eld image as an input and model the distortion of the light ?eld caused by the refractive property of a transparent object. We propose a new feature, called the light ?eld distortion (LFD) feature, for identifying a transparent object. The proposal incorporates this LFD feature into the bag-of-features approach for recognizing transparent objects. We evaluated its performance in laboratory and real settings.</p><br/>
<h2>reference text</h2><p>[1] B Wilburn, M. Smulski, K. Lee, and M. A. Horowitz, “The light ?eld video camera”, SPIE Electronic ImagT.  ing: Media Processors, vol. 4674, 29-36, 2002.</p>
<p>[2] R. Ng, M. Levoy, M. Brdif, G. Duval, M. Horowitz, P. Hanrahan, “Light Field Photography with a HandHeld Plenoptic Camera”, Stanford University Computer Science Tech Report CSTR 2005-02.</p>
<p>[3] A. Lumsdaine and T. Georgiev, “Full Resolution Light?eld Rendering”, Tech. rep., Adobe Systems, January 2008 .</p>
<p>[4] www.viewplus.co.jp/product/camera/ profusion25 .html</p>
<p>[5] www.raytrix.de/</p>
<p>[6] www.lytro.com/</p>
<p>[7] J. Sivic and A. Zisserman, “Video Google: A Text Retrieval Approach to Object Matching in Videos”, Int. Conf. Computer Vision, 2003.</p>
<p>[8] G. Csurka, C. Bray, C. Dance, and L. Fan, “Visual Categorization with Bags of Keypoints”, Workshop on Statistical Learning in Computer Vision, European Conference on Computer Vision, pp. 59-74, 2004</p>
<p>[9] D. Nister and H. Stewenius, “Scalable Recognition with a Vocabulary Tree”, IEEE Conf. Computer Vision and Pattern Recognition, 2006.</p>
<p>[10] M. Fritz, M. Black, G. Bradski, S. Karayev, and T.  Darrell, “An Additive Latent Feature Model for Transparent Object Recognition”, Advances in Neural Information Processing Systems, 2009</p>
<p>[11] D. Miyazaki, M. Kagesawa, and K. Ikeuchi, “Transparent Surface Modeling from a Pair of Polarization Images”, IEEE Trans. Pattern Analysis Machine Intelligence, Vol. 26, No. 1,pp. 73-82, 2004.</p>
<p>[12] D. Miyazaki and K. Ikeuchi, “Inverse Polarization Ray Tracing: Estimating Surface Shapes of Transparent Objects”, IEEE Conf. Computer Vision and Pattern Recognition, pp. 910-917, 2005 .</p>
<p>[13] G. S. Settles, “Schlieren and Shadowgraph Techniques”, Cambridge University Press, 2001 .</p>
<p>[14] G. S. Settles, “Important Developments in Schlieren and Shadowgraph Visualization during the Last Decade”, Int. Sympo. Flow Visualization, paper no. 267, June 2010.</p>
<p>[15] G. Wetzstein and R. Raskar, W. Heidrich, “Hand-Held Schlieren Photography with Light Field Probes”, Int. Conf. Computational Photography, 2011.</p>
<p>[16] G. Wetzstein, D. Roodnick, W. Heidrich, R. Raskar, “Refractive Shape from Light Field Distortion”, Int. Conf. Computer Vision, 2011.</p>
<p>[17] M. Ben-Ezra and S. K. Nayar, “What Does Motion  Reveal About Transparency?”, Int. Conf. Computer Vision, pp. 1025-1032, 2003.</p>
<p>[18] S. Agarwal, S. P. Mallick, D. Kriegman, and S. Belongie, “On Refractive Optical Flow”, Europen Conference on Computer Vision, pp. 483-494, 2004.</p>
<p>[19] N. J. W. Morris and K. N. Kutulakos, “Dynamic Refraction Stereo”, Int. Conf. Computer Vision, pp. 1573-1580, 2005</p>
<p>[20] G. Farneback, “Two-Frame Motion Estimation Based on Polynomial Expansion”, Scandinavian Conference on Image Analysis, 2003 .</p>
<p>[21] Y. Xu, K. Maeno, H. Nagahara and R. Taniguchi, “Mobile Camera Array Calibration for Light Field Acquisition”, Int. Conf. Quality Control by Arti?cial Vision, 2013 . 222777999311</p>
<br/>
<br/><br/><br/></body>
</html>
