<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>434 cvpr-2013-Topical Video Object Discovery from Key Frames by Modeling Word Co-occurrence Prior</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-434" href="../cvpr2013/cvpr-2013-Topical_Video_Object_Discovery_from_Key_Frames_by_Modeling_Word_Co-occurrence_Prior.html">cvpr2013-434</a> <a title="cvpr-2013-434-reference" href="#">cvpr2013-434-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>434 cvpr-2013-Topical Video Object Discovery from Key Frames by Modeling Word Co-occurrence Prior</h1>
<br/><p>Source: <a title="cvpr-2013-434-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Zhao_Topical_Video_Object_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Gangqiang Zhao, Junsong Yuan, Gang Hua</p><p>Abstract: A topical video object refers to an object that is frequently highlighted in a video. It could be, e.g., the product logo and the leading actor/actress in a TV commercial. We propose a topic model that incorporates a word co-occurrence prior for efficient discovery of topical video objects from a set of key frames. Previous work using topic models, such as Latent Dirichelet Allocation (LDA), for video object discovery often takes a bag-of-visual-words representation, which ignored important co-occurrence information among the local features. We show that such data driven co-occurrence information from bottom-up can conveniently be incorporated in LDA with a Gaussian Markov prior, which combines top down probabilistic topic modeling with bottom up priors in a unified model. Our experiments on challenging videos demonstrate that the proposed approach can discover different types of topical objects despite variations in scale, view-point, color and lighting changes, or even partial occlusions. The efficacy of the co-occurrence prior is clearly demonstrated when comparing with topic models without such priors.</p><br/>
<h2>reference text</h2><p>[1] D. Andrzejewski, X. Zhu, and M. Craven. Incorporating domain knowledge into topic modeling via dirichlet forest priors. In ICML, 2009. 2</p>
<p>[2] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. J. Mach. Learn. Res., 3:993–1022, 2003. 1, 2, 3, 4, 7</p>
<p>[3] M. Blei and J. D. Lafferty. A correlated topic model of science. Ann. Appl. Stat., 2007. 2</p>
<p>[4] L. Cao and F.-F. Li. Spatially coherent latent topic model for concurrent segmentation and classification of objects and scenes. In ICCV, 2007. 2</p>
<p>[5] A. Gruber, M. Rosen-Zvi, and Y. Weiss. Hidden topic markov models. Artificial Intelligence and Statistics (AISTATS), 2007. 2</p>
<p>[6] J. Han, H. Cheng, D. Xin, and X. Yan. Frequent pattern mining: current status and future directions. In Data Mining and Knowledge Discovery, 2007. 1, 2, 5</p>
<p>[7] T. Hofmann. Probabilistic latent semantic indexing. In SIGIR, 1999. 2</p>
<p>[8] D. Liu and T. Chen. A topic-motion model for unsupervised video object discovery. In CVPR, 2007. 2</p>
<p>[9] D. Liu, G. Hua, and T. Chen. A hierarchical visual model for video object summarization. TPAMI, 2010. 2</p>
<p>[10] H. Liu and S. Yan. Common visual pattern discovery via spatially coherent correspondences. CVPR, 2010. 2</p>
<p>[11] D. Lowe. Distinctive image features from scale-invariant keypoints. IJCV, 2004. 2</p>
<p>[12] C. Nikou, N. P. Galatsanos, and A. Likas. A class-adaptive spatially variant mixture model for image segmentation. TIP, 16(4):1 121–1 130, 2007. 3 Single object discovery  Multiple objects discovery  ertsnaucbmNI12 305 0 12PL3rDoAp45se6d7Vi8eo910 12 314AvgeamuNecntsIbr6543210 0 1PL2rDoAp3s4edV5ie6o78910Avg  (a) (b) Figure 6. The number of discovered video object instances by LDA (LDA) and the proposed LDA-WCP (Proposed). (a) shows the number of single video object and (b) shows the number of multiple video objects.</p>
<p>[13] J. Philbin, J. Sivic, and A. Zisserman. Geometric lda: A generative model for particular object discovery. In BMVC, 2008. 2</p>
<p>[14] B. C. Russell, A. A. Efros, J. Sivic, W. T. Freeman, and A. Zisserman. Using multiple segmentation to discover objects and their extent in image collections. In CVPR, 2006. 1, 2, 5, 6, 8</p>
<p>[15] M.-K. Shan and L.-Y. Wei. Algorithms for discovery of spatial co-orientation patterns from images. Expert Syst. Appl., 37:5795–5802, August 2010. 1</p>
<p>[16] J. Shi and J. Malik. Normalized cuts and image segmentation. TPAMI, 22:888–905, 2000. 3, 6</p>
<p>[17] S. Todorovic and N. Ahuja. Unsupervised category modeling, recognition, and segmentation in images. TPAMI, 2008. 1, 2</p>
<p>[18] X. Wang and E. Grimson. Spatial latent dirichlet allocation. In NIPS, 2007. 2</p>
<p>[19] Y. Xie and P. S. Yu. Max-clique: A top-down graph-based</p>
<p>[20]</p>
<p>[21]</p>
<p>[22]</p>
<p>[23]  approach to frequent pattern mining. In ICDM, 2010. 1, 2 J. Yuan and Y. Wu. Spatial random partition for common visual pattern discovery. In ICCV, 2007. 2 J. Yuan, Y. Wu, and M. Yang. From frequent itemsets to semantically meaningful visual patterns. In KDD, 2007. 1, 2 J. Yuan, G. Zhao, Y. Fu, Z. Li, A. K. Katsaggelos, and Y. Wu. Discovering thematic objects in image collections and videos. IIP, 21(4):2207–2219, 2012. 2 G. Zhao and J. Yuan. Discovering thematic patterns in videos via cohesive sub-graph mining. In ICDM, 2011. 1, 2, 5, 7, 8 111666000977</p>
<br/>
<br/><br/><br/></body>
</html>
