<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>181 cvpr-2013-Fusing Depth from Defocus and Stereo with Coded Apertures</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-181" href="../cvpr2013/cvpr-2013-Fusing_Depth_from_Defocus_and_Stereo_with_Coded_Apertures.html">cvpr2013-181</a> <a title="cvpr-2013-181-reference" href="#">cvpr2013-181-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>181 cvpr-2013-Fusing Depth from Defocus and Stereo with Coded Apertures</h1>
<br/><p>Source: <a title="cvpr-2013-181-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Takeda_Fusing_Depth_from_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Yuichi Takeda, Shinsaku Hiura, Kosuke Sato</p><p>Abstract: In this paper we propose a novel depth measurement method by fusing depth from defocus (DFD) and stereo. One of the problems of passive stereo method is the difficulty of finding correct correspondence between images when an object has a repetitive pattern or edges parallel to the epipolar line. On the other hand, the accuracy of DFD method is inherently limited by the effective diameter of the lens. Therefore, we propose the fusion of stereo method and DFD by giving different focus distances for left and right cameras of a stereo camera with coded apertures. Two types of depth cues, defocus and disparity, are naturally integrated by the magnification and phase shift of a single point spread function (PSF) per camera. In this paper we give the proof of the proportional relationship between the diameter of defocus and disparity which makes the calibration easy. We also show the outstanding performance of our method which has both advantages of two depth cues through simulation and actual experiments.</p><br/>
<h2>reference text</h2><p>[1] I. Gheta, C. Frese, M. Heizmann, and J. Beyerer. A new approach for estimating depth by fusing stereo and defocus information. Gesellschaft fur Informatik e. V Notes in Informatics, P-109:26–31, 2007.</p>
<p>[2] P. Green, W. Sun, W. Matusik, and F. Durand. Multi-aperture photography. ACM Trans. Graph., 26(3), 2007.</p>
<p>[3] S. Hiura and T. Matsuyama. Depth measurement by the multi-focus camera. In CVPR ’98, pages 953 –959, 1998.</p>
<p>[4] A. Levin. Analyzing depth from coded aperture sets. In ECCV2010, pages 214–227, 2010.</p>
<p>[5] A. Levin, R. Fergus, F. Durand, and W. T. Freeman. Image and depth from a conventional camera with a coded aperture. ACM Trans. Graph., 26(3), 2007.</p>
<p>[6] C.-K. Liang, T.-H. Lin, B.-Y. Wong, C. Liu, and H. H. Chen. Programmable aperture photography: multiplexed light field acquisition. ACM Trans. Graph., 27(3):55: 1–55: 10, 2008.</p>
<p>[7] S. Nayar, M. Watanabe, and M. Noguchi. Real-time focus range sensor. In ICCV95, pages 995 –1001, 1995.</p>
<p>[8] M. Okutomi and T. Kanade. A multiple-baseline stereo. In CVPR’91, pages 63 –69, 1991.</p>
<p>[9] A. P. Pentland. A new sense for depth of field. IEEE Trans. PAMI, PAMI-9(4):523 –531, july 1987.</p>
<p>[10] A. N. Rajagopalan, S. Chaudhuri, and U. Mudenagudi. Depth estimation and image restoration using defocused stereo pairs. IEEE Trans. PAMI, 26(1 1): 1521–1525, 2004.</p>
<p>[11] Y. Y. Schechner and N. Kiryati. Depth from defocus vs. stereo: How different really are they? Int. J. Comput. Vision, 39: 141–162, 2000.</p>
<p>[12] G. Surya and M. Subbarao. Depth from defocus by changing camera aperture: a spatial domain approach. In CVPR ’93, pages 61 –67, 1993.</p>
<p>[13] Y. Takeda, S. Hiura, and K. Sato. Coded aperture stereo - for extension of depth of field and refocusing. In Int. Conf. on Computer Vision Theory and Applications, pages 103–1 11, 2012.</p>
<p>[14] A. Veeraraghavan, R. Raskar, A. Agrawal, A. Mohan, and J. Tumblin. Dappled photography: mask enhanced cameras for heterodyned light fields and coded aperture refocusing. ACM Trans. Graph., 26, 2007.</p>
<p>[15] C. Zhou, S. Lin, and S. Nayar. Coded aperture pairs for depth from defocus. In ICCV2009, pages 325 –332, 2009.</p>
<p>[16] C. Zhou and S. Nayar. What are good apertures for defocus deblurring? In Int. Conf. on Computational Photography, pages 1–8, 2009. 222111666</p>
<br/>
<br/><br/><br/></body>
</html>
