<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>284 cvpr-2013-Mesh Based Semantic Modelling for Indoor and Outdoor Scenes</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-284" href="../cvpr2013/cvpr-2013-Mesh_Based_Semantic_Modelling_for_Indoor_and_Outdoor_Scenes.html">cvpr2013-284</a> <a title="cvpr-2013-284-reference" href="#">cvpr2013-284-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>284 cvpr-2013-Mesh Based Semantic Modelling for Indoor and Outdoor Scenes</h1>
<br/><p>Source: <a title="cvpr-2013-284-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Valentin_Mesh_Based_Semantic_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Julien P.C. Valentin, Sunando Sengupta, Jonathan Warrell, Ali Shahrokni, Philip H.S. Torr</p><p>Abstract: Semantic reconstruction of a scene is important for a variety of applications such as 3D modelling, object recognition and autonomous robotic navigation. However, most object labelling methods work in the image domain and fail to capture the information present in 3D space. In this work we propose a principled way to generate object labelling in 3D. Our method builds a triangulated meshed representation of the scene from multiple depth estimates. We then define a CRF over this mesh, which is able to capture the consistency of geometric properties of the objects present in the scene. In this framework, we are able to generate object hypotheses by combining information from multiple sources: geometric properties (from the 3D mesh), and appearance properties (from images). We demonstrate the robustness of our framework in both indoor and outdoor scenes. For indoor scenes we created an augmented version of the NYU indoor scene dataset (RGB-D images) with object labelled meshes for training and evaluation. For outdoor scenes, we created ground truth object labellings for the KITTI odometry dataset (stereo image sequence). We observe a signifi- cant speed-up in the inference stage by performing labelling on the mesh, and additionally achieve higher accuracies.</p><br/>
<h2>reference text</h2><p>[1] T. Bailey and H. Durrant-Whyte. Simultaneous localization and mapping (slam): Part ii. Robotics & Automation Magazine, IEEE, 13(3): 108–1 17, 2006. 1</p>
<p>[2] J. Biswas and M. Veloso. Depth camera based indoor mobile robot localization and navigation. pages 1697–1702. ICRA, 2012. 1</p>
<p>[3] Y. Boykov, O. Veksler, and R. Zabih. Fast approximate energy minimization via graph cuts. PAMI, 23:2001, 2001 . 3, 5</p>
<p>[4] G. J. Brostow, J. Shotton, J. Fauqueur, and R. Cipolla. Segmentation and recognition using structure from motion point clouds. In ECCV (1), pages 44–57, 2008. 2</p>
<p>[5] X. Chen, A. Golovinskiy, and T. Funkhouser. A benchmark for 3D mesh segmentation. 28(3), Aug. 2009. 2</p>
<p>[6] B. Curless and M. Levoy. A volumetric method for building complex models from range images. pages 303–312. ACM, 1996. 2</p>
<p>[7] H. Dahlkamp, G. Bradski, A. Kaehler, D. Stavens, and S. Thrun. Self-supervised monocular road detection in desert terrain. In RSS, Philadelphia, 2006. 1</p>
<p>[8] F. Erbs, U. Franke, and B. Schwarz. Stixmentation - probabilistic stixel based traffic scene labeling. In BMVC, 2012. 2</p>
<p>[9] A. Geiger, P. Lenz, and R. Urtasun. Are we ready for autonomous driving? the kitti vision benchmark suite. In CVPR, June 2012. 2, 4, 5, 6, 7</p>
<p>[10] A. Geiger, J. Ziegler, and C. Stiller. Stereoscan: Dense 3d reconstruction in real-time. In IEEE Intelligent Vehicles Symposium, BadenBaden, Germany, June 2011. 2</p>
<p>[11] A. Geiger, J. Ziegler, and C. Stiller. Stereoscan: Dense 3d reconstruction in real-time. In IEEE IV, pages 963 –968, june 2011. 7</p>
<p>[12] P. Henry, M. Krainin, E. Herbst, X. Ren, and D. Fox. RGB-D mapping: Using Kinect-style depth cameras for dense 3D modeling of indoor environments. IJRR, 31(5):647–663, Apr. 2012. 1</p>
<p>[13] Q. Huang, M. Wicke, B. Adams, and L. Guibas. Shape decomposition using modal analysis. Computer Graphics Forum, 28(2):407– 416, 2009. 2</p>
<p>[14] E. Kalogerakis, A. Hertzmann, and K. Singh. Learning 3d mesh segmentation and labeling, 2010. SIGGRAPH. 2, 3, 4</p>
<p>[15] H. Koppula, A. Anand, T. Joachims, and A. Saxena. Semantic labeling of 3d point clouds for indoor scenes, 2011. NIPS. 2</p>
<p>[16] L. Ladicky, C. Russell, P. Kohli, and P. H. Torr. Associative hierarchical crfs for object class image segmentation. In ICCV, 2009. 1, 2, 3, 4, 5, 6, 7</p>
<p>[17] L. Ladicky, P. Sturgess, C. Russell, S. Sengupta, Y. Bastanlar, W. Clocksin, and P. H. Torr. Joint optimisation for object class segmentation and dense stereo reconstruction. In BMVC, 2010. 2</p>
<p>[18] R. Newcombe, S. Lovegrove, and A. Davison. Dtam: Dense tracking and mapping in real-time. In ICCV, 2011. 2, 3</p>
<p>[19] R. A. Newcombe, S. Izadi, O. Hilliges, D. Molyneaux, D. Kim, A. J. Davison, P. Kohli, J. Shotton, S. Hodges, and A. Fitzgibbon. Kinectfusion: Real-time dense surface mapping and tracking. In IEEE ISMAR, 2011. 2, 3, 5 222000777311  Figure 5. Closeup view of reconstructed semantic model of an urban sequence from KITTI dataset. The arrows relate the position in the model and the associated image.(a) shows the fence, hedge and the post (encircled) in the image and the reconstructed model. (b) shows the right side of the street in the reconstructed model, showing the car, pavement and the trees in for both the cases. (View arrows from bottom, best viewed in colour.)</p>
<p>[20] B. Payne and A. Toga. Surface mapping brain functions on 3d models. In IEEE Computer Graphics and Applications, 1990. 2, 3, 5</p>
<p>[21] R. B. Rusu and S. Cousins. 3D is here: Point Cloud Library (PCL). In ICRA, Shanghai, China, May 9-13 2011. 7</p>
<p>[22] S. Sengupta, E. Greveson, A. Shahrokni, and P. Torr. Urban 3d semantic modelling using stereo vision. In ICRA, 2013. 2</p>
<p>[23] J. Shotton, J. Winn, C. Rother, and A. Criminisi. Textonboost for image understanding: Multi-class object recognition and segmentation by jointly modeling texture, layout, and context, 2009. ICCV. 1, 2, 3</p>
<p>[24] N. Silberman and R. Fergus. Indoor scene segmentation using a structured light sensor, 2011. ICCV. 1, 2, 4, 5, 6</p>
<p>[25] N. Silberman, D. Hoiem, P. Kohli, and R. Fergus. Indoor segmentation and support inference from rgbd images. In ECCV, 2012. 2</p>
<p>[26] J. Stuckler, N. Biresev, and S. Behnke. Semantic mapping using object-class segmentation of rgb-d images. In IROS, pages 3005– 3010, 2012. 1</p>
<p>[27] P. Sturgess, K. Alahari, L. Ladicky, and P. H. S. Torr. Combining appearance and structure from motion features for road scene understanding. In BMVC, 2009. 2</p>
<p>[28] A. Torralba, K. P. Murphy, and W. T. Freeman. Sharing visual features for multiclass and multiview object detection, 2007. PAMI. 3</p>
<p>[29] V. Vineet, J. Warrell, and P. H. S. Torr. Filter-based mean-field inference for random fields with higher order terms and product labelspaces. In ECCV, pages 1–10, 2012. 1</p>
<p>[30] K. M. Wurm, R. K ¨ummerle, C. Stachniss, and W. Burgard. Improving robot navigation in structured outdoor environments by identifying vegetation from laser data. In IROS, pages 1217–1222, 2009. 1</p>
<p>[31] H.-P. S. Yutaka Ohtake, Alexander Belyaev. An integrating approach to meshing scattered point data, 2005. ACM Symposium on Solid and Physical Modeling. 1, 2, 3  222000777422</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
