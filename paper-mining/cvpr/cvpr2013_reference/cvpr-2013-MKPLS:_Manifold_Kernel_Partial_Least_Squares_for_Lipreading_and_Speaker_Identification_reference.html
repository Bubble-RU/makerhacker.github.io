<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>276 cvpr-2013-MKPLS: Manifold Kernel Partial Least Squares for Lipreading and Speaker Identification</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-276" href="../cvpr2013/cvpr-2013-MKPLS%3A_Manifold_Kernel_Partial_Least_Squares_for_Lipreading_and_Speaker_Identification.html">cvpr2013-276</a> <a title="cvpr-2013-276-reference" href="#">cvpr2013-276-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>276 cvpr-2013-MKPLS: Manifold Kernel Partial Least Squares for Lipreading and Speaker Identification</h1>
<br/><p>Source: <a title="cvpr-2013-276-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Bakry_MKPLS_Manifold_Kernel_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Amr Bakry, Ahmed Elgammal</p><p>Abstract: Visual speech recognition is a challenging problem, due to confusion between visual speech features. The speaker identification problem is usually coupled with speech recognition. Moreover, speaker identification is important to several applications, such as automatic access control, biometrics, authentication, and personal privacy issues. In this paper, we propose a novel approach for lipreading and speaker identification. Wepropose a new approachfor manifold parameterization in a low-dimensional latent space, where each manifold is represented as a point in that space. We initially parameterize each instance manifold using a nonlinear mapping from a unified manifold representation. We then factorize the parameter space using Kernel Partial Least Squares (KPLS) to achieve a low-dimension manifold latent space. We use two-way projections to achieve two manifold latent spaces, one for the speech content and one for the speaker. We apply our approach on two public databases: AVLetters and OuluVS. We show the results for three different settings of lipreading: speaker independent, speaker dependent, and speaker semi-dependent. Our approach outperforms for the speaker semi-dependent setting by at least 15% of the baseline, and competes in the other two settings.</p><br/>
<h2>reference text</h2><p>[1] M. Aizerman, E. Braverman, and L. Rozonoer. Theoretical foundations of the potential function method in pattern recognition learning. Automation and Remote Control, 25:821–837, 1964.</p>
<p>[2] K. Bennett and M. Embrechts. An optimization perspective on kernel partial least squares regression. Nato Science Series, Sub-Series III: computer and System Sciences, 190:227–249, 2003.</p>
<p>[3] S. Cox, R. Harvey, and Y. Lan. The challenge of multispeaker lip-reading. International Conference on AuditoryVisual Speech Processing, 2008.</p>
<p>[4] R. Duda, P. Hart, and D. Stork. Pattern Classification. Wiley, 2001.</p>
<p>[5] A. Elgammal and C. Lee. Separating style and content on a nonlinear manifold. IEEE Conference on Computer Vision and Pattern Recognition, 1:478–485, 2004.</p>
<p>[6] Y. Fu and X. Zhou. Lipreading by locality discriminant graph. IEEE International Conference on Image Processing, pages 325–328, 2007.</p>
<p>[7] J. Ham, L. Daniel, and L. Saul. Semisupervised alignment of manifolds. Proceedings of the Annual Conference on Uncertainty in Artificial Intelligence, 2005.</p>
<p>[8] T. Hazen, K. Saenko, C.-h. La, and J. Glass. A segment-</p>
<p>[9]</p>
<p>[10]</p>
<p>[11]</p>
<p>[12]</p>
<p>[13]</p>
<p>[14]</p>
<p>[15]</p>
<p>[16]</p>
<p>[17]  based audio-visual speech recognizer: Data collection, development, and initial experiments. Proceedings of the 6th international conference on Multimodal interfaces. ACM, 2004. G. Kimeldorf and G. Wahba. A correspondence between Bayesian estimation on stochastic processes and smoothing by splines. The Annals of Mathematical Statistics, 1970. B. Lee and et al. AVICAR: Audio-visual speech corpus in a car environment. Proc. Int. Conf. Spoken Lang. Process, 2004. C. Lee and A. Elgammal. Homeomorphic manifold analysis: Learning decomposable generative models for human motion analysis. IEEE International Conference on Computer Vision, 2005. P. J. Lewi. Pattern recognition, reflections from a chemometric point of view. Chemometrics and Intelligent Laboratory Systems, 28(1):23–33, Apr. 1995. J. Luettin, N. Thacker, and S. Beet. Speaker identification by lipreading. International Conference on Spoken Language Processing, pages 1–4, 1996. I. Matthews and T. Cootes. Extraction of visual features for lipreading. PAMI, 24(2): 198–213, 2002. H. McGurk and J. MacDonald. Hearing lips and seeing voices. Nature, 264(23 December):746–748, 1976. T. Ojala. Multiresolution gray-scale and rotation invariant texture classification with local binary patterns. PAMI, 24(7):971–987, 2002. E. Patterson and S. Gurbuz. Moving-talker, speakerindependent feature study, and baseline results using the CUAVE multimodal speech corpus. EURASIP Journal on Appl. Signal Process., 2002(1 110-8657): 1189–1201, 2002.</p>
<p>[18] T. Poggio and F. Girosi. Networks for approximation and learning. Proceedings of the IEEE, pages 1481–1497, 1990.</p>
<p>[19] G. Potamianos and C. Neti. Audio-visual automatic speech recognition: An overview. Issues in Visual and Audio-Visual Speech Processing, 2004.</p>
<p>[20] L. Rabiner. A tutorial on hidden Markov models and selected applications in speech recognition. Proceedings of the IEEE, 77(2):257–286, 1989.</p>
<p>[21] R. Rosipal and L. Trejo. Kernel partial least squares regression in reproducing kernel hilbert space. The Journal of Machine Learning Research, 2:97–123, 2002.</p>
<p>[22] K. Saenko and K. Livescu. Visual speech recognition with loosely synchronized feature streams. IEEE International Conference on Computer Vision, 2005.</p>
<p>[23] C. Sanderson and K. Paliwal. Identity verification using speech and face information. Digital Signal Processing, 14(5):449–480, Sept. 2004.</p>
<p>[24] A. Shaikh, D. Kumar, and W. Yau. Lip Reading using Optical Flow and Support Vector Machines. IEEE International Congress on Image and Signal Processing, 1:327–330, Oct. 2010.</p>
<p>[25] D. Shiell and L. Terry. Audio-Visual and Visual-Only Speech and Speaker Recognition: Issues about Theory, System Design, and Implementation. Visual speech recognition: lip segmentation and mapping, pages 1–38, 2009.</p>
<p>[26] H. Wold. Soft Modeling by Latent Variables; the Nonlinear Iterative Partial Least Squares Approach. Perspectives in Probability and Statistics. Papers in Honour of M. S. Bartlett, pages 520 – 540, 1975.</p>
<p>[27] G. Zhao. Lipreading with local spatiotemporal descriptors. IEEE Transactions on Multimedia, pages 1–1 1, 2009.</p>
<p>[28] Z. Zhou, G. Zhao, and M. Pietikainen. Towards a practical lipreading system. Computer Vision and Pattern Recognition, 2011. 6 6 6 98 89819 919</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
