<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>287 cvpr-2013-Modeling Actions through State Changes</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-287" href="../cvpr2013/cvpr-2013-Modeling_Actions_through_State_Changes.html">cvpr2013-287</a> <a title="cvpr-2013-287-reference" href="#">cvpr2013-287-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>287 cvpr-2013-Modeling Actions through State Changes</h1>
<br/><p>Source: <a title="cvpr-2013-287-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Fathi_Modeling_Actions_through_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Alireza Fathi, James M. Rehg</p><p>Abstract: In this paper we present a model of action based on the change in the state of the environment. Many actions involve similar dynamics and hand-object relationships, but differ in their purpose and meaning. The key to differentiating these actions is the ability to identify how they change the state of objects and materials in the environment. We propose a weakly supervised method for learning the object and material states that are necessary for recognizing daily actions. Once these state detectors are learned, we can apply them to input videos and pool their outputs to detect actions. We further demonstrate that our method can be used to segment discrete actions from a continuous video of an activity. Our results outperform state-of-the-art action recognition and activity segmentation results.</p><br/>
<h2>reference text</h2><br/>
<br/><br/><br/></body>
</html>
