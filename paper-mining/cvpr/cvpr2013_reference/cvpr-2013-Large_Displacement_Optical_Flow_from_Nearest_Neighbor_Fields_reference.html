<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>244 cvpr-2013-Large Displacement Optical Flow from Nearest Neighbor Fields</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-244" href="../cvpr2013/cvpr-2013-Large_Displacement_Optical_Flow_from_Nearest_Neighbor_Fields.html">cvpr2013-244</a> <a title="cvpr-2013-244-reference" href="#">cvpr2013-244-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>244 cvpr-2013-Large Displacement Optical Flow from Nearest Neighbor Fields</h1>
<br/><p>Source: <a title="cvpr-2013-244-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Chen_Large_Displacement_Optical_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Zhuoyuan Chen, Hailin Jin, Zhe Lin, Scott Cohen, Ying Wu</p><p>Abstract: We present an optical flow algorithm for large displacement motions. Most existing optical flow methods use the standard coarse-to-fine framework to deal with large displacement motions which has intrinsic limitations. Instead, we formulate the motion estimation problem as a motion segmentation problem. We use approximate nearest neighbor fields to compute an initial motion field and use a robust algorithm to compute a set of similarity transformations as the motion candidates for segmentation. To account for deviations from similarity transformations, we add local deformations in the segmentation process. We also observe that small objects can be better recovered using translations as the motion candidates. We fuse the motion results obtained under similarity transformations and under translations together before a final refinement. Experimental validation shows that our method can successfully handle large displacement motions. Although we particularly focus on large displacement motions in this work, we make no sac- rifice in terms of overall performance. In particular, our method ranks at the top of the Middlebury benchmark.</p><br/>
<h2>reference text</h2><p>[1] L. Alvarez, J. Weickert, and J. Sanchez. Reliable estimation of dense optical flow fields with large displacements. IJCV,</p>
<p>[2]</p>
<p>[3]</p>
<p>[4]</p>
<p>[5]</p>
<p>[6]</p>
<p>[7]</p>
<p>[8]</p>
<p>[9]</p>
<p>[10]</p>
<p>[11]  39(1):41–56, 2000. Anandan. A computational framework and an algorithm for the measurement of visual motion. IJCV, 2(3):283–3 10, 1989. W. Andreas, D. Cremers, T. Pock, and H. Bischof. Structureand motion-adaptive regularization for high accuracy optic flow. ICCV, 2009. S. Baker, D. Scharstein, J. P. Lewis, S. Roth, M. J. Black, and R. Szeliski. A database and evaluation methodology for optical flow. IJCV, 92(1): 1–31, 2011. C. Barnes, E. Shechtman, A. Finkelstein, and D. B. Goldman. Patchmatch: a randomized correspondence algorithm for structural image editing. ACM SIGGRAPH, 24, 2009. F. Besse, C. Rother, A. Fitzgibbon, and J. Kautz. PMBP: Patchmatch belief propagation for correspondence field estimation. In BMVC, 2012. M. J. Black and A. D. Jepson. Estimating optical flow in segmented images using variable-order parametric models with local deformations. PAMI, 18(10):972–986, 1996. Y. Boykov, O. Veksler, and R. Zabih. Fast approximate energy minimization via graph cuts. PAMI, 23(1 1): 1222–1239, 2001. T. Brox and J. Malik. Large displacement optical flow: descriptor matching in variational motion estimation. PAMI, 33(3):500–513, 2011. R. Carsten, V. Kolmogorov, V. Lempitsky, and M. Szummer. Optimizing binary mrfs via extended roof duality. CVPR, 2007. B. Connelly, E. Shechtman, D. Goldman, and A. Finkelstein. The generalized patchmatch correspondence algorithm. ECCV, 2010.</p>
<p>[12] W. Enkelmann. Investigations of multigrid algorithms for the estimation of optical flow fields in image sequences. In Computer Vision, Graphics, and Image Processing, 1988.</p>
<p>[13] K. He and J. Sun. Computing nearest-neighbor fields via propagation-assisted kd-trees. CVPR, 2012.</p>
<p>[14] K. He and J. Sun. Statistics of patch offsets for image completion. ECCV, 2012.</p>
<p>[15] B. Horn and B. Schunck. Determining optical flow. Artificial Intelligence, 16: 185–203, 1981 .</p>
<p>[16] W. Josh, S. Agarwal, and S. Belongie. What went where. CVPR, 2003.</p>
<p>[17] S. Korman and S. Avidan. Coherency sensitive hashing. ICCV, 2011.</p>
<p>[18] V. Lempitsky, S. Roth, and C. Rother. Fusionflow: Discretecontinuous optimization for optical flow estimation. CVPR, 2008.</p>
<p>[19] D. G. Lowe. Object recognition from local scale-invariant features. ICCV, 1999.</p>
<p>[20] F. Martin and R. C. Bolles. Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography. Communications ofthe ACM, 24(6):381–395, 1981.</p>
<p>[21] I. Olonetsky and S. Avidan. Treecann - k-d tree coherence approximate nearest neighbor algorithm. In ECCV, 2012.</p>
<p>[22] F. Steinbruecker, T. Pock, and D. Cremers. Large displacement optical flow computation without warping. In ICCV, 2009.</p>
<p>[23] D. Sun, S. Roth, and M. J. Black. Secrets of optical flow estimation and their principles. CVPR, 2010.</p>
<p>[24] D. Sun, E. B. Sudderth, and M. J. Black. Layered image motion with explicit occlusions, temporal consistency, and  depth ordering. In NIPS, 2010.</p>
<p>[25] M. Unger, M. Werlberger, T. Pock, and H. Bischof. Joint motion estimation and segmentation of complex scenes with label costs and occlusion modeling. In CVPR, 2012.</p>
<p>[26] L. Xu, J. Jia, and Y. Matsushita. Motion detail preserving optical flow estimation. PAMI, 16(9): 1744–1757, 2012. 222444445088</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
