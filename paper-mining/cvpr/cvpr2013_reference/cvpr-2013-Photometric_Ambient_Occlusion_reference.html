<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>330 cvpr-2013-Photometric Ambient Occlusion</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-330" href="../cvpr2013/cvpr-2013-Photometric_Ambient_Occlusion.html">cvpr2013-330</a> <a title="cvpr-2013-330-reference" href="#">cvpr2013-330-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>330 cvpr-2013-Photometric Ambient Occlusion</h1>
<br/><p>Source: <a title="cvpr-2013-330-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Hauagge_Photometric_Ambient_Occlusion_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Daniel Hauagge, Scott Wehrwein, Kavita Bala, Noah Snavely</p><p>Abstract: We present a method for computing ambient occlusion (AO) for a stack of images of a scene from a fixed viewpoint. Ambient occlusion, a concept common in computer graphics, characterizes the local visibility at a point: it approximates how much light can reach that point from different directions without getting blocked by other geometry. While AO has received surprisingly little attention in vision, we show that it can be approximated using simple, per-pixel statistics over image stacks, based on a simplified image formation model. We use our derived AO measure to compute reflectance and illumination for objects without relying on additional smoothness priors, and demonstrate state-of-the art performance on the MIT Intrinsic Images benchmark. We also demonstrate our method on several synthetic and real scenes, including 3D printed objects with known ground truth geometry.</p><br/>
<h2>reference text</h2><p>[1] Photometric Ambient Occlusion webpage. http : / /www . c s . corne l .edu /pro j e ct s /phot oao. l</p>
<p>[2] J. Ackermann, F. Langguth, S. Fuhrmann, and M. Goesele. Photometric stereo for outdoor webcams. In CVPR, 2012.</p>
<p>[3] O. Aldrian and W. A. Smith. Inverse rendering of faces on a cloudy day. In ECCV. 2012.</p>
<p>[4] J. T. Barron and J. Malik. High-frequency shape and albedo from shading using natural image statistics. In CVPR, 2011.</p>
<p>[5] J. T. Barron and J. Malik. Color constancy, intrinsic images, and shape estimation. In ECCV, 2012.</p>
<p>[6] R. Basri, D. Jacobs, and I. Kemelmacher. Photometric stereo with general, unknown lighting. IJCV, 2007.</p>
<p>[7] T. Beeler, D. Bradley, H. Zimmer, and M. Gross. Improved reconstruction of deforming surfaces by cancelling ambient occlusion. In ECCV, 2012.</p>
<p>[8] M. Chandraker, S. Agarwal, and D. Kriegman. Shadowcuts: Photometric stereo with shadows. In CVPR, 2007.</p>
<p>[9] R. Garg, H. Du, S. M. Seitz, and N. Snavely. The dimensionality of scene appearance. In ICCV, 2009.</p>
<p>[10] R. Grosse, M. Johnson, E. Adelson, and W. Freeman. Ground truth dataset and baseline evaluations for intrinsic image algorithms. In ICCV, 2009.</p>
<p>[11] R. Grosse, M. K. Johnson, E. H. Adelson, and W. T. Freeman. MIT Intrinsic Images, 2009. http : / /peopl e . c s ail . mit . edu / rgro s se / int rins i / . c</p>
<p>[12] W. Jakob. Mitsuba renderer, 2010. http : / /www . mit suba-rende rer . org.</p>
<p>[13] J. Kontkanen and S. Laine. Ambient occlusion fields. In Proc. Symp. on Interactive 3D Graphics and Games. ACM, 2005.</p>
<p>[14] P.-Y. Laffont, A. Bousseau, S. Paris, F. Durand, and G. Drettakis. Coherent intrinsic images from photo collections. SIGGRAPH Asia, 2012.</p>
<p>[15] E. Land, J. McCann, et al. Lightness and retinex theory. Journal of the Optical society of America, 1971 .</p>
<p>[16] H. Landis. Production-ready global illumination. SIGGRAPH Course Notes, 2002.</p>
<p>[17] M. S. Langer and S. W. Zucker. Shape-from-shading on a cloudy day. J. Optical Society of America A, 1994.</p>
<p>[18] K.-C. Lee, J. Ho, and D. Kriegman. The Extended Yale Face Database B, 2005. http : / /vi s i .uc s d .edu / on Ëœ leekc /ExtYaleDat abas e /ExtYaleB .html .</p>
<p>[19] J. Pantaleoni, L. Fascione, M. Hill, and T. Aila. PantaRay: Fast ray-traced occlusion caching of massive scenes. In ACM Transactions on Graphics, 2010.</p>
<p>[20] M. Pharr and S. Green. Ambient occlusion. GPU Gems, 2004.</p>
<p>[21] E. Prados, N. Jindal, and S. Soatto. A non-local approach to shape from ambient shading. In Scale Space and Variational Methods in Computer Vision. Springer, 2009.</p>
<p>[22] J. Shen, X. Yang, X. Li, and Y. Jia. Intrinsic image decomposition using optimization and user scribbles. Trans. Systems, Man, and Cybernetics, 2012.</p>
<p>[23] L. Shen and C. Yeo. Intrinsic images decomposition using a local and global sparse representation of reflectance. In CVPR, 2011.</p>
<p>[24] K. Sunkavalli, W. Matusik, H. Pfister, and S. Rusinkiewicz. Factored time-lapse video. In SIGGRAPH, 2007.</p>
<p>[25] K. Sunkavalli, T. Zickler, and H. Pfister. Visibility subspaces: Uncalibrated photometric stereo with shadows. In ECCV, 2010.</p>
<p>[26] M. Turk and A. Pentland. Eigenfaces for recognition. J. Cognitive Neuroscience, 1991 .</p>
<p>[27] Y. Weiss. Deriving intrinsic images from image sequences. In ICCV, 2001.</p>
<p>[28] R. Woodham. Analysing images of curved surfaces. Artificial Intelligence, 1981.</p>
<p>[29] C. Wu, B. Wilburn, Y. Matsushita, and C. Theobalt. Highquality shape from multi-view stereo and shading under general illumination. In CVPR, 2011.</p>
<p>[30] T. Wu and C. Tang. Photometric stereo via expectation maximization. PAMI, 2010. 222555222200</p>
<br/>
<br/><br/><br/></body>
</html>
