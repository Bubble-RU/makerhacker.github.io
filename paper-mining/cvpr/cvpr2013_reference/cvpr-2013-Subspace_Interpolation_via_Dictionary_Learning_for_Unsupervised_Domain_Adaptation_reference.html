<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>419 cvpr-2013-Subspace Interpolation via Dictionary Learning for Unsupervised Domain Adaptation</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-419" href="../cvpr2013/cvpr-2013-Subspace_Interpolation_via_Dictionary_Learning_for_Unsupervised_Domain_Adaptation.html">cvpr2013-419</a> <a title="cvpr-2013-419-reference" href="#">cvpr2013-419-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>419 cvpr-2013-Subspace Interpolation via Dictionary Learning for Unsupervised Domain Adaptation</h1>
<br/><p>Source: <a title="cvpr-2013-419-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Ni_Subspace_Interpolation_via_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Jie Ni, Qiang Qiu, Rama Chellappa</p><p>Abstract: Domain adaptation addresses the problem where data instances of a source domain have different distributions from that of a target domain, which occurs frequently in many real life scenarios. This work focuses on unsupervised domain adaptation, where labeled data are only available in the source domain. We propose to interpolate subspaces through dictionary learning to link the source and target domains. These subspaces are able to capture the intrinsic domain shift and form a shared feature representation for cross domain recognition. Further, we introduce a quantitative measure to characterize the shift between two domains, which enables us to select the optimal domain to adapt to the given multiple source domains. We present exumd .edu , rama@umiacs .umd .edu training and testing data are captured from the same underlying distribution. Yet this assumption is often violated in many real life applications. For instance, images collected from an internet search engine are compared with those captured from real life [28, 4]. Face recognition systems trained on frontal and high resolution images, are applied to probe images with non-frontal poses and low resolution [6]. Human actions are recognized from an unseen target view using training data taken from source views [21, 20]. We show some examples of dataset shifts in Figure 1. In these scenarios, magnitudes of variations of innate characteristics, which distinguish one class from another, are oftentimes smaller than the variations caused by distribution shift between training and testing dataset. Directly applying the classifier from the training set to testing set periments on face recognition across pose, illumination and blur variations, cross dataset object recognition, and report improved performance over the state of the art.</p><br/>
<h2>reference text</h2><p>[1] M. Aharon, M. Elad, and A. Bruckstein. K-SVD : An algorithm for designing of overcomplete dictionaries for sparse representation. IEEE Transactions on Signal Processing, 54(1 1):431 1–4322, 2006. 2, 3, 5, 6</p>
<p>[2] T. Ahonen, E. Rahtu, V. Ojansivu, and J. Heikkil a¨. Recognition of blurred faces using local phase quantization. In ICPR, pages 1–4, 2008. 5</p>
<p>[3] H. Bay, A. Ess, T. Tuytelaars, and L. Van Gool. Speededup robust features (surf). Comput. Vis. Image Underst., 110(3):346–359, June 2008. 6</p>
<p>[4] A. Bergamo and L. Torresani. Exploiting weakly-labeled web images to improve object classification: a domain adaptation approach. In NIPS, pages 181–189, 2010. 1</p>
<p>[5] S. Biswas, G. Aggarwal, and R. Chellappa. Robust estimation of albedo for illumination-invariant matching and shape recovery. IEEE Trans. Pattern Anal. Mach. Intell., 31(5):884–899, May 2009. 5</p>
<p>[6] S. Biswas, G. Aggarwal, and P. Flynn. Pose-robust recognition of low-resolution face images. In CVPR, pages 601 –608, June 2011. 1</p>
<p>[7] J. Blitzer, R. McDonald, and F. Pereira. Domain adaptation with structural correspondence learning. In Conference on Empirical Methods in Natural Language Processing, pages 120–128, 2006. 3</p>
<p>[8] R. Chellappa, J. Ni, and V. M. Patel. Remote identification of faces: Problems, prospects, and progress. Pattern Recogn. Lett., 33(14): 1849–1859, Oct. 2012. 1</p>
<p>[9] H. Daum e´ III. Frustratingly easy domain adaptation. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 256–263, June 2007. 3</p>
<p>[10] L. Duan, D. Xu, I. W.-H. Tsang, and J. Luo. Visual event recognition in videos by learning from web data. IEEE Trans. Pattern Anal. Mach. Intell., 34(9): 1667–1680, 2012. 3</p>
<p>[11] M. Elad and M. Aharon. Image denoising via sparse and redundant representations over learned dictionaries. IEEE Transactions on Image Processing, 15(12):3736–3745, 2006. 2</p>
<p>[12] K. Engan, S. Aase, and J. Hakon Husoy. Method of optimal directions for frame design. In ICASSP, pages 2443–2446, 1999. 4</p>
<p>[13] B. Gong, Y. Shi, F. Sha, and K. Grauman. Geodesic flow kernel for unsupervised domain adaptation. In CVPR, pages 2066–2073, 2012. 1, 3, 5, 6</p>
<p>[14] R. Gopalan, R. Li, and R. Chellappa. Domain adaptation for object recognition: An unsupervised approach. In ICCV, pages 999–1006, 2011. 1, 3, 5, 6</p>
<p>[15] G. Griffin, A. Holub, and P. Perona. Caltech-256 object category dataset. Technical report, Caltech, 2007. 6</p>
<p>[16] R. Gross, I. Matthews, and S. Baker. Appearance-based face recognition and light-fields. IEEE Trans. Pattern Anal. Mach. Intell., 26(4):449–465, April 2004. 5</p>
<p>[17] I.-H. Jhuo, D. Liu, D. T. Lee, and S.-F. Chang. Robust visual domain adaptation with low-rank reconstruction. In CVPR, pages 2168–2175, 2012. 1, 3</p>
<p>[18] B. Kulis, K. Saenko, and T. Darrell. What you saw is not what you get: Domain adaptation using asymmetric kernel transforms. In CVPR, pages 1785–1792, 2011. 3</p>
<p>[19] A. Levin, Y. Weiss, F. Durand, and W. T. Freeman. Understanding and evaluating blind deconvolution algorithms. In CVPR, pages 1964–1971, 2009. 6</p>
<p>[20] R. Li and T. Zickler. Discriminative virtual views for crossview action recognition. In CVPR, pages 2855–2862, 2012. 1</p>
<p>[21] J. Liu, M. Shah, B. Kuipers, and S. Savarese. Cross-view action recognition via view knowledge transfer. In CVPR, pages 3209–3216, 2011. 1</p>
<p>[22] J. Mairal, F. Bach, and J. Ponce. Task-driven dictionary learning. IEEE Trans. Pattern Anal. Mach. Intell., 34(4):791–804, 2012. 2</p>
<p>[23] J. Mairal, F. Bach, J. Ponce, and G. Sapiro. Online dictionary learning for sparse coding. In ICML, pages 689–696, 2009.</p>
<p>[24]</p>
<p>[25]</p>
<p>[26]</p>
<p>[27]</p>
<p>[28]</p>
<p>[29]</p>
<p>[30]  [3 1]</p>
<p>[32]</p>
<p>[33]  2 J. Mairal, F. Bach, J. Ponce, G. Sapiro, and A. Zisserman. Supervised dictionary learning. In NIPS, pages 1033–1040, 2008. 2 S. J. Pan, J. T. Kwok, and Q. Yang. Transfer learning via dimensionality reduction. In AAAI, pages 677–682, 2008. 3 S. J. Pan, I. W. Tsang, J. T. Kwok, and Q. Yang. Domain adaptation via transfer component analysis. In IJCAI, pages 1187–1 192, 2009. 3 Q. Qiu, V. Patel, P. Turage, and R. Chellappa. Domain adaptive dictionary learning. In ECCV, pages 63 1–645, 2012. 3 K. Saenko, B. Kulis, M. Fritz, and T. Darrell. Adapting visual category models to new domains. In ECCV, pages 213– 226, 2010. 1, 3, 6 Y. Shi and F. Sha. Information-theoretical learning of discriminative clusters for unsupervised domain adaptation. In ICML, 2012. 3 T. Sim, S. Baker, and M. Bsat. The cmu pose, illumination, and expression database. IEEE Trans. Pattern Anal. Mach. Intell., 25(12):1615–1618, 2003. 4, 5 C. Wang and S. Mahadevan. Manifold alignment without correspondence. In IJCAI, pages 1273–1278, 2009. 3 J. Wright, A. Y. Yang, A. Ganesh, S. S. Sastry, and Y. Ma. Robust face recognition via sparse representation. IEEE Trans. Pattern Anal. Mach. Intell., 31(2):210–227, Feb 2009. 2 J. Yang, R. Yan, and A. G. Hauptmann. Cross-domain video concept detection using adaptive svms. In ACM Multimedia, pages 188–197, 2007. 3 6 6 6 9 9 9 97 797</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
