<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>260 cvpr-2013-Learning and Calibrating Per-Location Classifiers for Visual Place Recognition</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-260" href="../cvpr2013/cvpr-2013-Learning_and_Calibrating_Per-Location_Classifiers_for_Visual_Place_Recognition.html">cvpr2013-260</a> <a title="cvpr-2013-260-reference" href="#">cvpr2013-260-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>260 cvpr-2013-Learning and Calibrating Per-Location Classifiers for Visual Place Recognition</h1>
<br/><p>Source: <a title="cvpr-2013-260-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Gronat_Learning_and_Calibrating_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Petr Gronát, Guillaume Obozinski, Josef Sivic, Tomáš Pajdla</p><p>Abstract: The aim of this work is to localize a query photograph by finding other images depicting the same place in a large geotagged image database. This is a challenging task due to changes in viewpoint, imaging conditions and the large size of the image database. The contribution of this work is two-fold. First, we cast the place recognition problem as a classification task and use the available geotags to train a classifier for each location in the database in a similar manner to per-exemplar SVMs in object recognition. Second, as onlyfewpositive training examples are availablefor each location, we propose a new approach to calibrate all the per-location SVM classifiers using only the negative examples. The calibration we propose relies on a significance measure essentially equivalent to the p-values classically used in statistical hypothesis testing. Experiments are performed on a database of 25,000 geotagged street view images of Pittsburgh and demonstrate improved place recognition accuracy of the proposed approach over the previous work. 2Center for Machine Perception, Faculty of Electrical Engineering 3WILLOW project, Laboratoire d’Informatique de l’E´cole Normale Sup e´rieure, ENS/INRIA/CNRS UMR 8548. 4Universit Paris-Est, LIGM (UMR CNRS 8049), Center for Visual Computing, Ecole des Ponts - ParisTech, 77455 Marne-la-Valle, France</p><br/>
<h2>reference text</h2><p>[1] H. Bay, T. Tuytelaars, and L. Van Gool. SURF: Speeded up robust features. In ECCV, 2006. 1, 5</p>
<p>[2] G. Casella and R. Berger. Statistical inference. 2001 . 3</p>
<p>[3] D. Chen, G. Baatz, K ¨oser, S. Tsai, R. Vedantham, T. Pylvanainen, K. Roimela, X. Chen, J. Bach, M. Pollefeys, B. Girod, and R. Grzeszczuk. City-scale landmark identification on mobile devices. In CVPR, 2011. 5</p>
<p>[4] O. Chum, A. Mikulik, M. Perdroch, and J. Matas. Total recall II: Query expansion revisited. In CVPR, 2011. 2</p>
<p>[5] O. Chum, J. Philbin, J. Sivic, M. Isard, and A. Zisserman. Total recall: Automatic query expansion with a generative feature model for object retrieval. In ICCV, 2007. 2</p>
<p>[6] G. Csurka, C. Bray, C. Dance, and L. Fan. Visual categorization with bags of keypoints. In Workshop on Statistical Learning in Computer Vision, ECCV, pages 1–22, 2004. 1</p>
<p>[7] M. Cummins and P. Newman. Highly scalable appearance-</p>
<p>[8]</p>
<p>[9]</p>
<p>[10]</p>
<p>[11]</p>
<p>[12]</p>
<p>[13]</p>
<p>[14]</p>
<p>[15]  only SLAM - FAB-MAP 2.0. In Proceedings of Robotics: Science and Systems, Seattle, USA, June 2009. 1 R.-E. Fan, K.-W. Chang, C.-J. Hsieh, X.-R. Wang, and C.-J. Lin. LIBLINEAR: A library for large linear classification. J. Machine Learning Research, 9: 1871–1874, 2008. 5 M. Gebel and C. Weihs. Calibrating classifier scores into probabilities. Advances in Data Analysis, pages 141–148, 2007. 3 A. Irschara, C. Zach, J.-M. Frahm, and H. Bischof. From structure-from-motion point clouds to fast location recognition. In CVPR, 2009. 2 H. J ´egou, M. Douze, and C. Schmid. Product Quantization for Nearest Neighbor Search. IEEE PAMI, 33(1):1 17–128, 2011. 2 H. J´ egou, F. Perronnin, M. Douze, J. S ´anchez, P. P ´erez, and C. Schmid. Aggregating local image descriptors into compact codes. IEEE PAMI, 34: 1704–1716, 2012. 6 J. Knopp, J. Sivic, and T. Pajdla. Avoidng confusing features in place recognition. In ECCV, 2010. 1, 2, 5, 6, 7 Y. Li, D. Crandall, and D. Huttenlocher. Landmark classification in large-scale image collections. In ICCV, 2009. 2 Y. Li, N. Snavely, and D. Huttenlocher. Location recognition using prioritized feature matching. In ECCV, 2010. 2 999991111122000  Query image  Per-location class.  Confuser suppression  Bag-of-words  (a)(b)(c)(d) Figure 4: Examples of query images (gray) correctly (green) and incorrectly (red) localized by different methods. (a) query image. (b) the top-ranked image retrieved by per-location classifiers (proposed method). (c) the top-ranked image retrieved by the baseline confuser suppression method [13]. (d) the top-ranked image retrieved by the baseline bagof-visual-words method. Bottom two rows: the proposed method is sometimes confused by high-scoring similar repeated texture patterns on facades. 9 9 91 1 13 1 1  Calibrated classifier score fj  Target database image j  )(Fs0 −.105 .4? −?0.35SCVlMas ?sc?oif?rie sd−0q.3uer?y ?imag−e0s.2f5j(q)  (a)(b)(c) Calibrated classifier score fj  Target database image j  Fs)(0 −.10 5.4? −0?.35SCVlMas sciofrie d s?−? 0q?.u3ery? i?m?age−s0 f.2j5(q)  (a)(b)(c) Figure 5: A visualization of learnt feature wights for two database images. In each panel: first row: (Right) Target database image j. (Left) Cumulative density function (or calibrated score) learnt for the SVM scores of the corresponding classifier fj ; three query images displayed on the second row are represented by their SVM scores and cdf values F0 (s), denoted (a)-(c) on the graph. Third row: A visualization of the contribution of each feature to the SVM score for the corresponding query image. Red circles represent features with negative weights while green circles correspond to features with positive weights. The area of each circle is proportional to the contribution of the corresponding feature to the SVM score. Notice that the correctly localized queries (c) contain more green colored features than queries from other places (b) and (a). Left panel: Query (b) gets a high score because the building has orange and white stripes similar to the the sun-blinds of the bakery, which are features that also have large positive weights in the query image (c) of the correct place. Right panel: Query (b) is in fact also an image of the same location with a portion of the left skyscraper in the target image detected in the upper left corner and the side of the rightmost building in the target image detected in the top right corner. Both are clearly detected by the method as indicated by a large quantity of green circles in the corresponding regions.</p>
<p>[16] Y. Li, N. Snavely, D. Huttenlocher, and P. Fua. Worldwide pose estimation using 3d point clouds. In ECCV, 2012. 2</p>
<p>[17] D. Lowe.  Distinctive  image features from scale-invariant  keypoints. IJCV, 60(2):91–1 10, 2004. 1</p>
<p>[18] T. Malisiewicz,  A. Gupta, and A. A. Efros.  Ensemble of  exemplar-svms for object detection and beyond.  In ICCV,  2011. 2, 5, 6</p>
<p>[19] A. Mikul ´ık, M. Perdoch, O. Chum, and J. Matas. Learning a fine vocabulary. In ECCV, 2010. 1</p>
<p>[20] D. Nister and H. Stewenius. Scalable recognition with a vocabulary tree. In CVPR, 2006. 1</p>
<p>[21] J. Philbin,  O. Chum, M. Isard, J. Sivic, and A. Zisser-  man. Object retrieval with large vocabularies and fast spatial matching. In CVPR, 2007. 1, 3, 5, 6</p>
<p>[22] J. Philbin, O. Chum, M. Isard, J. Sivic, and A. Zisserman. Lost in quantization: Improving particular object retrieval in large scale image databases. In CVPR, 2008. 2</p>
<p>[23] J. Philbin, M. Isard, J. Sivic, and A. Zisserman. Descriptor learning for efficient retrieval. In ECCV, 2010. 1</p>
<p>[24] J. Philbin, J. Sivic, and A. Zisserman. Geometric latent dirichlet allocation on a matching graph for large-scale image datasets. IJCV, 2010. 2</p>
<p>[25] J. Platt. Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods. In Advances in Large Margin Classifiers, 1999. 3</p>
<p>[26] W. Scheirer, N. Kumar, P. N. Belhumeur, and T. E. Boult. Multi-attribute spaces: Calibration for attribute fusion and similarity search. In CVPR, 2012. 4</p>
<p>[27] G. Schindler, M. Brown, and R. Szeliski. City-scale location recognition. In CVPR, 2007. 1, 2</p>
<p>[28] J. Sivic and A. Zisserman. Video Google: A text retrieval approach to object matching in videos. In ICCV, 2003. 1, 5</p>
<p>[29] A. Torii, J. Sivic, and T. Pajdla. Visual localization by linear combination of image descriptors. In IEEE Workshop on Mobile Vision, 2011. 2</p>
<p>[30] P. Turcot and D. Lowe. Better matching with fewer features: The selection of useful features in large database recognition problem. In WS-LAVD, ICCV, 2009. 2 [3 1] B. Zadrozny and C. Elkan. Transforming classifier scores into accurate multiclass probability estimates. In ACM SIGKDD, 2002. 3</p>
<p>[32] A. Zamir and M. Shah. Accurate image localization based on google maps street view. In ECCV, 2010. 2 999991111144222</p>
<br/>
<br/><br/><br/></body>
</html>
