<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>112 cvpr-2013-Dense Segmentation-Aware Descriptors</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-112" href="../cvpr2013/cvpr-2013-Dense_Segmentation-Aware_Descriptors.html">cvpr2013-112</a> <a title="cvpr-2013-112-reference" href="#">cvpr2013-112-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>112 cvpr-2013-Dense Segmentation-Aware Descriptors</h1>
<br/><p>Source: <a title="cvpr-2013-112-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Trulls_Dense_Segmentation-Aware_Descriptors_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Eduard Trulls, Iasonas Kokkinos, Alberto Sanfeliu, Francesc Moreno-Noguer</p><p>Abstract: In this work we exploit segmentation to construct appearance descriptors that can robustly deal with occlusion and background changes. For this, we downplay measurements coming from areas that are unlikely to belong to the same region as the descriptor’s center, as suggested by soft segmentation masks. Our treatment is applicable to any image point, i.e. dense, and its computational overhead is in the order of a few seconds. We integrate this idea with Dense SIFT, and also with Dense Scale and Rotation Invariant Descriptors (SID), delivering descriptors that are densely computable, invariant to scaling and rotation, and robust to background changes. We apply our approach to standard benchmarks on large displacement motion estimation using SIFT-flow and widebaseline stereo, systematically demonstrating that the introduction of segmentation yields clear improvements.</p><br/>
<h2>reference text</h2><p>[1] H. Bay, A. Ess, T. Tuytelaars, and L. V. Gool. Surf: Speeded up robust features. CVIU, 2008.</p>
<p>[2] M. Belkin and P. Niyogi. Laplacian eigenmaps for dimensionality reduction and data representation. Neural Computation, 15(6), 2003.</p>
<p>[3] S. Belongie, J. Malik, and J. Puzicha. Shape matching and object recognition using shape contexts. T.PAMI, 2002.</p>
<p>[4] A. Berg and J. Malik. Geometric blur for template matching.  In CVPR, 2001. 222888999644  Left image  Ground truth depth  Daisy, 1iter.  Daisy, 5 iter.  SSID, ‘Eigen’  Figure10.Firstcolumn:Theimagesonthel ft(Images5and7of[31])arematchedag instImage3of[31],shownisFig.2,whic  serves as the the ‘Right image’), for an increasing baseline. Second column: ground truth depth maps of [31]. Third and fourth columns: first and fifth iteration of the Daisy stereo algorithm. Fifth column: single shot depth estimation with SSID and ‘Eigen’ embeddings. The occlusion estimates for the first Daisy iteration may seem aggressive, but allow the algorithm to converge. Higher occlusion costs induce  errors in the initial estimate and degrade the final accuracy.</p>
<p>[5] Y. Boykov, O. Veksler, and R. Zabih. Fast approximate energy minimization via graph cuts. T.PAMI, 23(1 1): 1222– 1239, 2001.</p>
<p>[6] M. Brown, G. Hua, and S. Winder. Discriminative learning of local image descriptors. T.PAMI, 33(1):43–57, 2011.</p>
<p>[7] T. Brox and J. Malik. Object segmentation by long term analysis of point trajectories. In ECCV, 2010.</p>
<p>[8] M. Calonder, V. Lepetit, C. Strecha, and P. Fua. Brief: Binary robust independent elementary features. In ECCV, Heraklion, Greece, 2010.</p>
<p>[9] L. R. Dice. Measures of the amount of ecologic association between species. Ecology, 26(3), 1945.</p>
<p>[10] J. Geusebroek, A. Smeulders, and J. van de Weijer. Fast anisotropic gauss filtering. Trans. Image Processing, 12(8):938–943, 2003.</p>
<p>[11] T. Hassner, V. Mayzels, and L. Zelnik-Manor. On SIFTS and their scales. In CVPR, 2012.</p>
<p>[12] Y. Ke and R. Sukthankar. Pca-sift: A more distinctive repre-</p>
<p>[13]</p>
<p>[14]</p>
<p>[15]</p>
<p>[16]</p>
<p>[17]</p>
<p>[18]</p>
<p>[19]</p>
<p>[20]</p>
<p>[21]</p>
<p>[22]</p>
<p>[23]</p>
<p>[24]</p>
<p>[25]  sentation for local image descriptors. In CVPR, pages 5 11 517, Washington, USA, 2004. I. Kokkinos, M. Bronstein, and A. Yuille. Dense ScaleInvariant Descriptors for Images and Surfaces. Technical report, Ecole Centrale Paris, Tech Report, 2012. I. Kokkinos and A. Yuille. Scale invariance without scale selection. In CVPR, 2008. V. Kolmogorov. Convergent tree-reweighted message passing for energy minimization. T.PAMI, 2006. M. Leordeanu, R. Sukthankar, and C. Sminchisescu. Efficient closed-form solution to generalized boundary detection. In ECCV, 2012. H. Ling and D. W. Jacobs. Deformation invariant image matching. In ICCV, 2005. C. Liu, J. Yuen, and A. Torralba. Sift flow: dense correspondence across difference scenes. T.PAMI, 33(5), 2011. D. Lowe. Distinctive image features from scale-invariant keypoints. IJCV, 2004. M. Maire, P. Arbelaez, C. Fowlkes, and J. Malik. Using contours to detect and localize junctions in natural images. In CVPR, 2008. K. Mikolajczyk and C. Schmid. A performance evaluation of local descriptors. T.PAMI, 27(10), 2005. F. Moreno-Noguer. Deformation and illumination invariant feature point descriptor. In CVPR, 2011. E. Nowak, F. Jurie, and B. Triggs. Sampling strategies for bag-of-features image classification. In ECCV, 2006. P. Ott and M. Everingham. Implicit color segmentation features for pedestrian and object detection. In ICCV, 2009. M. Ozuysal, M. Calonder, V. Lepetit, and P. Fua. Fast keypoint recognition using random ferns. T.PAMI, 2010.</p>
<p>[26] E. Rublee, V. Rabaud, K. Konolige, and G. R. Bradski. Orb: An efficient alternative to sift or surf. In ICCV, 2011.</p>
<p>[27] U. Schmidt and S. Roth. Learning rotation-aware features: From invariant priors to equivariant descriptors. In CVPR, 2012.</p>
<p>[28] J. Shi and J. Malik. Normalized cuts and image segmentation. T.PAMI, 1997.</p>
<p>[29] K. Simonyan, A. Vedaldi, and A. Zisserman. Descriptor learning using convex optimisation. In ECCV, 2012.</p>
<p>[30] C. Strecha, A. M. Bronstein, M. M. Bronstein, and P. Fua. LDA-hash: Improved matching with smaller descriptors. T.PAMI, 34(1), 2012.</p>
<p>[31] C. Strecha, W. von Hansen, L. V. Gool, P. Fua, and U. Thoennessen. On benchmarking camera calibration and multi-view stereo for high resolution imagery. In CVPR, 2008.</p>
<p>[32] E. Tola, V. Lepetit, and P. Fua. Daisy: An efficient dense descriptor applied to wide-baseline stereo. T.PAMI, 32(5), 2010.</p>
<p>[33] R. Tron and R. Vidal. A benchmark for the comparison of 3-d motion segmentation algorithms. In CVPR, 2007.</p>
<p>[34] A. Vedaldi and B. Fulkerson. VLFeat: An open and portable library of computer vision algorithms. http : / /www . vlfeat .org, 2008.</p>
<p>[35] S. Winder, G. Hua, and M. Brown. Picking the best daisy. In CVPR, 2009. 222888999755</p>
<br/>
<br/><br/><br/></body>
</html>
