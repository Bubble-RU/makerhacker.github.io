<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>457 cvpr-2013-Visual Tracking via Locality Sensitive Histograms</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-457" href="../cvpr2013/cvpr-2013-Visual_Tracking_via_Locality_Sensitive_Histograms.html">cvpr2013-457</a> <a title="cvpr-2013-457-reference" href="#">cvpr2013-457-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>457 cvpr-2013-Visual Tracking via Locality Sensitive Histograms</h1>
<br/><p>Source: <a title="cvpr-2013-457-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/He_Visual_Tracking_via_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Shengfeng He, Qingxiong Yang, Rynson W.H. Lau, Jiang Wang, Ming-Hsuan Yang</p><p>Abstract: This paper presents a novel locality sensitive histogram algorithm for visual tracking. Unlike the conventional image histogram that counts the frequency of occurrences of each intensity value by adding ones to the corresponding bin, a locality sensitive histogram is computed at each pixel location and a floating-point value is added to the corresponding bin for each occurrence of an intensity value. The floating-point value declines exponentially with respect to the distance to the pixel location where the histogram is computed; thus every pixel is considered but those that are far away can be neglected due to the very small weights assigned. An efficient algorithm is proposed that enables the locality sensitive histograms to be computed in time linear in the image size and the number of bins. A robust tracking framework based on the locality sensitive histograms is proposed, which consists of two main components: a new feature for tracking that is robust to illumination changes and a novel multi-region tracking algorithm that runs in realtime even with hundreds of regions. Extensive experiments demonstrate that the proposed tracking framework outper- , forms the state-of-the-art methods in challenging scenarios, especially when the illumination changes dramatically.</p><br/>
<h2>reference text</h2><p>[1] A. Adam, E. Rivlin, and I. Shimshoni. Robust fragments-based tracking using the integral histogram. In CVPR, pages 798 – 805, 2006.</p>
<p>[2] B. Babenko, M.-H. Yang, and S. Belongie. Robust object tracking with online multiple instance learning. PAMI, 33(8): 1619 –1632, aug. 2011.</p>
<p>[3] C. Bao, Y. Wu, H. Ling, and H. Ji. Real time robust l1 tracker using accelerated proximal gradient approach. In CVPR, pages 1830 –1837, 2012.</p>
<p>[4] M. J. Black and A. D. Jepson. Eigentracking: Robust matching and tracking of articulated objects using a view-based representation.</p>
<p>[5]</p>
<p>[6]</p>
<p>[7]</p>
<p>[8]</p>
<p>[9]</p>
<p>[10]</p>
<p>[11]</p>
<p>[12]</p>
<p>[13]</p>
<p>[14]</p>
<p>[15]</p>
<p>[16]</p>
<p>[17]</p>
<p>[18]</p>
<p>[19]</p>
<p>[20]</p>
<p>[21]</p>
<p>[22]  IJCV, 26(1):63–84, 1998. H. F. Chen, P. N. Belhumeur, and D. W. Jacobs. In search of illumination invariants. In CVPR, pages 1254–1261, 2000. F. Crow. Summed-area tables for texture mapping. In SIGGRAPH, pages 207–212, 1984. H. Grabner, C. Leistner, and H. Bischof. Semi-supervised on-line boosting for robust tracking. In ECCV, pages 234–247, 2008. S. Hare, A. Saffari, and P. Torr. Struck: Structured output tracking with kernels. In ICCV, pages 263 –270, 2011. M. Isard and A. Blake. Condensation - conditional density propagation for visual tracking. IJCV, 29:5–28, 1998. D. Jacobs, P. Belhumeur, and R. Basri. Comparing images under variable illumination. In CVPR, pages 610–617, 1998. Z. Kalal, K. Mikolajczyk, and J. Matas. Tracking-learning-detection. PAMI, 34: 1409–1422, 2012. M. Kass and J. Solomon. Smoothed local histogram filters. ACM TOG, 29: 100: 1–100: 10, 2010. J. Kwon and K. M. Lee. Tracking of a non-rigid object via patchbased dynamic appearance modeling and adaptive basin hopping monte carlo sampling. In CVPR, pages 1208–1215, 2009. J. Kwon and K. M. Lee. Visual tracking decomposition. In CVPR, pages 1269–1276, 2010. F. Porikli. Integral histogram: a fast way to extract histograms in cartesian spaces. In CVPR, pages 829–836, 2005. F. Porikli. Constant time o(1) bilateral filtering. In CVPR, 2008. D. A. Ross, J. Lim, R.-S. Lin, and M.-H. Yang. Incremental learning for robust visual tracking. IJCV, 77(1-3): 125–141, 2008. Y. Rubner, C. Tomasi, and L. Guibas. The earth mover’s distance as a metric for image retrieval. IJCV, 40(2):99–121, 2000. L. Sevilla-Lara and E. Learned-Miller. Distribution fields for tracking. In CVPR, pages 1910–1917, 2012. S. M. N. Shahed, J. Ho, and M.-H. Yang. Visual tracking with histograms and articulating blocks. In CVPR, 2008. S. Shirdhonkar and D. Jacobs. Approximate earth mover’s distance in linear time. In CVPR, 2008. L. Cˇehovin, M. Kristan, and A. Leonardis. An adaptive coupled-layer</p>
<p>[23]</p>
<p>[24]</p>
<p>[25]</p>
<p>[26]</p>
<p>[27]</p>
<p>[28]  visual model for robust visual tracking. In ICCV, 2011. P. Viola and M. Jones. Robust real-time object detection. IJCV, 57(2): 137–154, 2004. S. Wang, H. Lu, F. Yang, and M.-H. Yang. Superpixel tracking. In ICCV, pages 1323–1330, 2011. B. Weiss. Fast median and bilateral filtering. ACM TOG, 25(3):519– 526, 2006. M. Werman, S. Peleg, and A. Rosenfeld. A distance metric for multidimensional histograms. CVGIP, 32(3):328 – 336, 1985. K. Zhang, L. Zhang, and M.-H. Yang. Real-time compressive tracking. In ECCV, 2012. T. Zhang, B. Ghanem, S. Liu, and N. Ahuja. Robust visual tracking via multi-task sparse learning. In CVPR, pages 2042 –2049, 2012. 222444333422</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
