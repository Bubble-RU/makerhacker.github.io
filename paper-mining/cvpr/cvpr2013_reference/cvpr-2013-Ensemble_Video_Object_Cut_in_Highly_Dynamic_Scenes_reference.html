<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>148 cvpr-2013-Ensemble Video Object Cut in Highly Dynamic Scenes</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-148" href="../cvpr2013/cvpr-2013-Ensemble_Video_Object_Cut_in_Highly_Dynamic_Scenes.html">cvpr2013-148</a> <a title="cvpr-2013-148-reference" href="#">cvpr2013-148-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>148 cvpr-2013-Ensemble Video Object Cut in Highly Dynamic Scenes</h1>
<br/><p>Source: <a title="cvpr-2013-148-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Ren_Ensemble_Video_Object_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Xiaobo Ren, Tony X. Han, Zhihai He</p><p>Abstract: We consider video object cut as an ensemble of framelevel background-foreground object classifiers which fuses information across frames and refine their segmentation results in a collaborative and iterative manner. Our approach addresses the challenging issues of modeling of background with dynamic textures and segmentation of foreground objects from cluttered scenes. We construct patch-level bagof-words background models to effectively capture the background motion and texture dynamics. We propose a foreground salience graph (FSG) to characterize the similarity of an image patch to the bag-of-words background models in the temporal domain and to neighboring image patches in the spatial domain. We incorporate this similarity information into a graph-cut energy minimization framework for foreground object segmentation. The background-foreground classification results at neighboring frames are fused together to construct a foreground probability map to update the graph weights. The resulting object shapes at neighboring frames are also used as constraints to guide the energy minimization process during graph cut. Our extensive experimental results and performance comparisons over a diverse set of challenging videos with dynamic scenes, including the new Change Detection Challenge Dataset, demonstrate that the proposed ensemble video object cut method outperforms various state-ofthe-art algorithms.</p><br/>
<h2>reference text</h2><p>[1] P. Arbelaez, M. Maire, C. Fowlkes, and J. Malik. Contour detection and hierarchical image segmentation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 33(5), 2011.</p>
<p>[2] Y. Boykov and V. Kolmogorov. An experimental comparison of min-cut maxflow algorithms for energy minimization in vision. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2004. 111999555311  Figure 7: Iterative ensemble video obejct cut; the first row: the original video frames; the second row, the segmentation results after the first iteration; the third row, the segmenta-  tion results after the first iteration; the fourth row, the final segmentation results.</p>
<p>[3] M. V. Droogenbroeck and O. Paquot. Background subtraction: Experiments and improvements for vibe. IEEE Workshop on Change Detection, CVPR, 2012.</p>
<p>[4] A. Elgammal, D. Harwood, and L. Davis. Non-parametric model for background subtraction. ICCV, 2000.</p>
<p>[5] B. S. Everitt, S. Landau, and M. Leese. Cluster analysis (fourth ed.). London: Arnold, 2001 .</p>
<p>[6] L. Ford and D. Fulkerson. Flows in networks. Princeton University Press, 1962.</p>
<p>[7] N. Goyette, P.-M. Jodoin, F. Porikli, J. Konrad, and P. Ishwar. changedetection.net: A new change detection benchmark dataset. Proc. IEEE Workshop on Change Detection (CDW12) at CVPR12, 2012.</p>
<p>[8] M. Heikkil, M. Pietikinen, and S. Member. A texture-based method for modeling the background and detecting moving objects. IEEE Trans. Pattern Anal. Machine Intell, 28, 2006.</p>
<p>[9] M. Hofmann, P.Tiefenbacher, and G. Rigoll. Background segmentation with feedback: The pixel-based adaptive segmenter. IEEE Workshop on Change Detection, CVPR, 2012.</p>
<p>[10] K. Kim, T. H. Chalidabhongse, D. Harwood, and L. Davis. Real-time foreground-background segmentation using codebook model. Real-time Imaging, 11(3): 167–256, 2005.</p>
<p>[11] T. Ko, S. Soatto, and D. Estrin. Background subtraction with distributions. In Proceedings of the European Conference on Computer Vision, 2008.</p>
<p>[12] L. Li, W. Huang, I. Y. H. Gu, and Q. Tian. Foreground object detection from videos containing complex background.</p>
<p>[13]</p>
<p>[14]</p>
<p>[15]</p>
<p>[16]</p>
<p>[17]</p>
<p>[18]</p>
<p>[19]</p>
<p>[20]</p>
<p>[21]  Proceedings of the eleventh ACM international conference on Multimedia, pages 2–10, 2003. S. Liao, G. Zhao, V. Kellokumpu, M. Pietikinen, and S. Z. Li. Modeling pixel process with scale invariant local patterns for background subtraction in complex scenes. ICCV, pages 1301–1306, 2010. L. Maddalena and A. Petrosino. The sobs algorithm: what are the limits? IEEE Workshop on Change Detection, CVPR, 2012. V. Mahadevan and N. Vasconcelos. Background subtraction in highly dynamic scenes. In IEEE Conference on Computer Vision and Pattern Recognition, pages 1–6, 2008. V. Mahadevan and N. Vasconcelos. Spatiotemporal saliency in dynamic scenes. IEEE Transactions on Pattern Analysis and Machine Intelligence, 32(1): 171–177, 2010. A. Morde, X. Ma, and S. Guler. Learning a background model for change detection. IEEE Workshop on Change Detection, CVPR, 2012. Y. Nonaka, A. Shimada, H.Nagahara, and R. Taniguchi. Evaluation report of integrated background modeling based on spatio-temporal features. IEEE Workshop on Change Detection, CVPR, 2012. O.Strauss, D. Sidib, and W. Puech. Quasi-continuous histogram based motion detection. Technical Report, LE2I, 2012. Y. Ren, C.-S. Chua, and Y.-K. Ho. Motion detection with nonstationary background. Machine Vision and Application, Springer-Verlag, 2003. C. Rother, V. Kolmogorov, and A. Blake. Grabcut: Interactive foreground extraction using iterated graph cuts. ACM Transactions on Graphics, 23:309–3 14, 2004.</p>
<p>[22] A. Schick, M.Bum, and R.Stiefelhagen. Improving foreground segmentations with probabilistic superpixel markov random fields. IEEE Workshop on Change Detection, CVPR, 2012.</p>
<p>[23] Y. Sheikh and M. Shah. Bayesian modeling of dynamic scenes for object detection. IEEE PAMI, 27: 1778–1792, 2005.</p>
<p>[24] J. Sun, W. Zhang, X. Tang, and H. Y. Shum. Background cut. In European Conference on Computer Vision, pages 628– 641, 2006.</p>
<p>[25] K. Toyama, J. Krumm, B. Brumitt, and M. Brian. Wallflower:principles and practice of background maintenance. In European Conference on Computer Vision, 255(1), 1999.</p>
<p>[26] C. Wren, A. Azarbayejani, T. Darrel, and A. Pentland. Pfinder: Real time tracking of the human body. IEEE Transactions on Pattern Analysis and Machine Intelligence, 1997.</p>
<p>[27] J. Zhong and S. Sclaroff. Segmenting foreground objects from a dynamic textured background via a robust kalman filter. ICCV, 2003. 111999555422</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
