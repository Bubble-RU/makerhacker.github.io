<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>66 cvpr-2013-Block and Group Regularized Sparse Modeling for Dictionary Learning</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-66" href="../cvpr2013/cvpr-2013-Block_and_Group_Regularized_Sparse_Modeling_for_Dictionary_Learning.html">cvpr2013-66</a> <a title="cvpr-2013-66-reference" href="#">cvpr2013-66-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>66 cvpr-2013-Block and Group Regularized Sparse Modeling for Dictionary Learning</h1>
<br/><p>Source: <a title="cvpr-2013-66-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Chi_Block_and_Group_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Yu-Tseh Chi, Mohsen Ali, Ajit Rajwade, Jeffrey Ho</p><p>Abstract: This paper proposes a dictionary learning framework that combines the proposed block/group (BGSC) or reconstructed block/group (R-BGSC) sparse coding schemes with the novel Intra-block Coherence Suppression Dictionary Learning (ICS-DL) algorithm. An important and distinguishing feature of the proposed framework is that all dictionary blocks are trained simultaneously with respect to each data group while the intra-block coherence being explicitly minimized as an important objective. We provide both empirical evidence and heuristic support for this feature that can be considered as a direct consequence of incorporating both the group structure for the input data and the block structure for the dictionary in the learning process. The optimization problems for both the dictionary learning and sparse coding can be solved efficiently using block-gradient descent, and the details of the optimization algorithms are presented. We evaluate the proposed methods using well-known datasets, and favorable comparisons with state-of-the-art dictionary learning methods demonstrate the viability and validity of the proposed framework.</p><br/>
<h2>reference text</h2><p>[1] S. Bengio, F. Pereira, Y. Singer, and D. Strelow. Group sparse coding. Advances in NIPS, 22:82–89, 2009.</p>
<p>[2] C.-C. Chang and C.-J. Lin. LIBSVM: A library for support vector machines. ACM Trans. Intell. Syst. Technol. , 2:27: 1– 27:27, 2011.</p>
<p>[3] A. Dr´ emeau and C. Herzet. An em-algorithm approach for the design of orthonormal bases adapted to sparse representations. In ICASSP, 2010, pages 2046–2049. IEEE, 2010.</p>
<p>[4] M. Elad. Sparse and Redundant Representations. Springer Verlag, 2010.</p>
<p>[5] Y. Eldar, P. Kuppinger, and H. Bolcskei. Block-sparse signals: Uncertainty relations and efficient recovery. Signal Process., IEEE Trans. on, 58(6):3042–3054, 2010.</p>
<p>[6] E. Elhamifar and R. Vidal. Robust classification using structured sparse representation. In CVPR, 2011 IEEE Confer-  ence on, pages 1873–1879. IEEE, 2011. 5Our dictionary size is 5 times smaller than what was used in SISF-DL.</p>
<p>[7] E. Elhamifar and R. Vidal. Block-sparse recovery via convex optimization. Signal Process., IEEE Trans. on, PP(99): 1, 2012.</p>
<p>[8] B. Haasdonk and D. Keysers. Tangent distance kernels for support vector machines. In ICPV, 2002, volume 2, pages 864–868. IEEE, 2002.</p>
<p>[9] J. Hull. A database for handwritten text recognition research. Pattern Anal. Mach. Intell., IEEE Trans. on, 16(5):550–554, 1994.</p>
<p>[10] R. Jenatton, J. Mairal, G. Obozinski, and F. Bach. Proximal methods for sparse hierarchical dictionary learning. In International Conference on Machine Learning (ICML), 2010.</p>
<p>[11] S. Lesage, R. Gribonval, F. Bimbot, and L. Benaroya. Learning unions of orthonormal bases with thresholded svd. In ICASSP’05., volume 5, pages v–293. IEEE, 2005.</p>
<p>[12] J. Mairal, F. Bach, J. Ponce, G. Sapiro, and A. Zisserman. Supervised dictionary learning. Advances in NIPS, 2008.</p>
<p>[13] I. Ramirez, P. Sprechmann, and G. Sapiro. Classification and clustering via dictionary learning with structured incoherence and shared features. In CVPR, 2010, pages 3501 3508. IEEE, 2010.</p>
<p>[14] R. Rubinstein, A. Bruckstein, and M. Elad. Dictionaries for sparse representation modeling. Proceedings of the IEEE, 98(6): 1045–1057, 2010.</p>
<p>[15] P. Sprechmann, I. Ramirez, G. Sapiro, and Y. Eldar. Chilasso: A collaborative hierarchical sparse modeling. Signal Process., IEEE Trans. on, 59(9):4183–4198, 2011.</p>
<p>[16] Z. Szabo, B. Poczos, and A. Lorincz. Online group-  structured dictionary learning. In CVPR, 2011 IEEE Conference on, pages 2865 –2872, june 2011.</p>
<p>[17] J. Wright, A. Yang, A. Ganesh, S. Sastry, and Y. Ma. Robust face recognition via sparse representation. Pattern Anal. Mach. Intell., IEEE Trans. on, 31(2):210–227, 2009.</p>
<p>[18] M. Yuan and Y. Lin. Model selection and estimation in regression with grouped variables. Journal of the Royal Statistical Society: Series B, 68(1):49–67, 2006. 333888002</p>
<br/>
<br/><br/><br/></body>
</html>
