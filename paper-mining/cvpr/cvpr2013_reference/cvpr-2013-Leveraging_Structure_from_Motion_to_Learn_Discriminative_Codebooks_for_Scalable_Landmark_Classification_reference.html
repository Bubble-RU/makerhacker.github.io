<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>268 cvpr-2013-Leveraging Structure from Motion to Learn Discriminative Codebooks for Scalable Landmark Classification</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-268" href="../cvpr2013/cvpr-2013-Leveraging_Structure_from_Motion_to_Learn_Discriminative_Codebooks_for_Scalable_Landmark_Classification.html">cvpr2013-268</a> <a title="cvpr-2013-268-reference" href="#">cvpr2013-268-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>268 cvpr-2013-Leveraging Structure from Motion to Learn Discriminative Codebooks for Scalable Landmark Classification</h1>
<br/><p>Source: <a title="cvpr-2013-268-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Bergamo_Leveraging_Structure_from_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Alessandro Bergamo, Sudipta N. Sinha, Lorenzo Torresani</p><p>Abstract: In this paper we propose a new technique for learning a discriminative codebook for local feature descriptors, specifically designed for scalable landmark classification. The key contribution lies in exploiting the knowledge of correspondences within sets offeature descriptors during codebook learning. Feature correspondences are obtained using structure from motion (SfM) computation on Internet photo collections which serve as the training data. Our codebook is defined by a random forest that is trained to map corresponding feature descriptors into identical codes. Unlike prior forest-based codebook learning methods, we utilize fine-grained descriptor labels and address the challenge of training a forest with an extremely large number of labels. Our codebook is used with various existing feature encoding schemes and also a variant we propose for importanceweighted aggregation of local features. We evaluate our approach on a public dataset of 25 landmarks and our new dataset of 620 landmarks (614K images). Our approach significantly outperforms the state of the art in landmark classification. Furthermore, our method is memory efficient and scalable.</p><br/>
<h2>reference text</h2><p>[1] H. Cai, F. Yan, and K. Mikolajczyk. Learning weights for codebook in image classification and retrieval. In CVPR, 2010.</p>
<p>[2] K. Chatfield, V. Lempitsky, A. Vedaldi, and A. Zisserman. The devil is in the details: an evaluation of recent feature encoding methods. In BMVC, 2011.</p>
<p>[3] D. Chen, G. Baatz, K ¨oser, Tsai, Vedantham, Pylvanainen, Roimela, Chen, J. Bach, M. Pollefeys, B. Girod, and R. Grzeszczuk. City-scale landmark identification on mobile devices. In CVPR, 2011.</p>
<p>[4] K. Crammer and Y. Singer. On the learnability and design of output codes for multiclass problems. In COLT, 2000.</p>
<p>[5] A. Criminisi, J. Shotton, and E. Konukoglu. Decision forests: A unified framework for classification, regression, density estimation, manifold learning and semi-supervised learning. Foundations and Trends in Computer Graphics and Vision, 7(2-3):81–227, 2012.</p>
<p>[6] G. Csurka, C. Dance, L. Fan, J. Willamowski, and C. Bray. Visual categorization with bags of keypoints. In Workshop on statistical learning in computer vision, ECCV, volume 1, page 22, 2004.</p>
<p>[7] S. Dasgupta and Y. Freund. Random projection trees and low dimensional manifolds. In STOC, pages 537–546, 2008.</p>
<p>[8] C. Doersch, S. Singh, A. Gupta, J. Sivic, and A. A. Efros. What makes paris look like paris? ACM Trans. Graph., 3 1(4), 2012.</p>
<p>[9] R.-E. Fan, K.-W. Chang, C.-J. Hsieh, X.-R. Wang, and C.-J. Lin. Liblinear: A library for large linear classification. JMLR, 9, 2008.</p>
<p>[10] J. C. Gemert, J.-M. Geusebroek, C. J. Veenman, and A. W. Smeulders. Kernel codebooks for scene categorization. In ECCV, 2008.</p>
<p>[11] Q. Hao, R. Cai, Z. Li, L. Zhang, Y. Pang, and F. Wu. 3d visual phrases for landmark recognition. In CVPR, pages 3594–3601, 2012.</p>
<p>[12] J. Hays and A. A. Efros. Im2gps: estimating geographic information from a single image. In CVPR, 2008.</p>
<p>[13] H. Jegou, M. Douze, C. Schmid, and P. P ´erez. Aggregating local descriptors into a compact image representation. In CVPR, 2010.</p>
<p>[14] J. Knopp, J. Sivic, and T. Pajdla. Avoiding confusing features in place recognition. ECCV, pages 748–761, 2010.</p>
<p>[15] S. Lazebnik and M. Raginsky. Supervised learning ofquantizer codebooks by information loss minimization. PAMI, 31(7), 2009.</p>
<p>[16] Y. Li, D. Crandall, and D. Huttenlocher. Landmark classification in large-scale image collections. In ICCV, 2009.</p>
<p>[17] Y. Li, N. Snavely, and D. Huttenlocher. Location recognition using prioritized feature matching. In ECCV, pages 791–804, 2010.</p>
<p>[18] Y. Li, N. Snavely, D. Huttenlocher, and P. Fua. Worldwide pose estimation using 3d point clouds. In ECCV (1), pages 15–29, 2012.</p>
<p>[19] D. Lowe. Distinctive image features from scale-invariant keypoints. IJCV, 60(2):91–1 10, 2004.</p>
<p>[20] A. Mikul ´ık, M. Perdoch, O. Chum, and J. Matas. Learning a fine vocabulary. In ECCV, pages 1–14, 2010.</p>
<p>[21] F. Moosmann, E. Nowak, and F. Jurie. Randomized clustering forests for image classification. PAMI, 30(9): 1632–1646, Sept. 2008.</p>
<p>[22] D. Nist e´r and H. Stew e´nius. Scalable recognition with a vocabulary tree. In Proc. CVPR, pages 2161–2168, 2006.</p>
<p>[23] S. Nowozin. Improved information gain estimates for decision tree induction. In ICML 2012, 2012.</p>
<p>[24] F. Perronnin and C. R. Dance. Fisher kernels on visual vocabularies for image categorization. In CVPR, 2007.</p>
<p>[25] F. Perronnin, J. S ´anchez, and T. Mensink. Improving the fisher kernel for large-scale image classification. In ECCV (4), 2010.</p>
<p>[26] J. Philbin, Chum, Isard, J. Sivic, and A. Zisserman. Object retrieval with large vocabularies and fast spatial matching. In CVPR, 2007.</p>
<p>[27] T. Sattler, B. Leibe, and L. Kobbelt. Improving image-based localization by active correspondence search. In ECCV (1), 2012.</p>
<p>[28] J. Sivic and A. Zisserman. Video Google: A text retrieval approach to object matching in videos. In ICCV, pages 1470–1477, 2003.</p>
<p>[29] N. Snavely, S. M. Seitz, and R. Szeliski. Modeling the world from</p>
<p>[30] [3 1]</p>
<p>[32]</p>
<p>[33]</p>
<p>[34]</p>
<p>[35]</p>
<p>[36]</p>
<p>[37]  Internet photo collections. IJCV, 80(2): 189–210, November 2008. A. Vedaldi and B. Fulkerson. VLFeat, http://www.vlfeat.org/. S. A. J. Winder, G. Hua, and M. Brown. Picking the best daisy. In CVPR, pages 178–185, 2009. J. Winn, A. Criminisi, and T. Minka. Object categorization by learned universal visual dictionary. In ICCV, 2005. Z. Wu, Q. Ke, J. Sun, and H.-Y. Shum. A multi-sample, multi-tree approach to bag-of-words image representation for image retrieval. In ICCV, pages 1992–1999, 2009. J. Yuan, Y. Wu, and M. Yang. Discovery of collocation patterns: from visual words to visual phrases. In CVPR, 2007. S. Zhang, Q. Tian, G. Hua, Q. Huang, and W. Gao. Generating descriptive visual words and visual phrases for large-scale image applications. IEEE Transactions on Image Processing, 2011. Y. Zhang, Z. Jia, and T. Chen. Image retrieval with geometrypreserving visual phrases. In CVPR, pages 809–816, 2011. Y. Zheng, M. Zhao, Y. Song, H. Adam, U. Buddemeier, A. Bissacco, F. Brucher, T.-S. Chua, and H. Neven. Tour the world: Building a web-scale landmark recognition engine. In CVPR, 2009. 777777766676088808</p>
<br/>
<br/><br/><br/></body>
</html>
