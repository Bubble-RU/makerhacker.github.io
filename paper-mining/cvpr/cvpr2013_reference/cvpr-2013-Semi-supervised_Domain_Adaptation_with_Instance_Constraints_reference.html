<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>387 cvpr-2013-Semi-supervised Domain Adaptation with Instance Constraints</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-387" href="../cvpr2013/cvpr-2013-Semi-supervised_Domain_Adaptation_with_Instance_Constraints.html">cvpr2013-387</a> <a title="cvpr-2013-387-reference" href="#">cvpr2013-387-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>387 cvpr-2013-Semi-supervised Domain Adaptation with Instance Constraints</h1>
<br/><p>Source: <a title="cvpr-2013-387-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Donahue_Semi-supervised_Domain_Adaptation_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Jeff Donahue, Judy Hoffman, Erik Rodner, Kate Saenko, Trevor Darrell</p><p>Abstract: Most successful object classification and detection methods rely on classifiers trained on large labeled datasets. However, for domains where labels are limited, simply borrowing labeled data from existing datasets can hurt performance, a phenomenon known as “dataset bias.” We propose a general framework for adapting classifiers from “borrowed” data to the target domain using a combination of available labeled and unlabeled examples. Specifically, we show that imposing smoothness constraints on the classifier scores over the unlabeled data can lead to improved adaptation results. Such constraints are often available in the form of instance correspondences, e.g. when the same object or individual is observed simultaneously from multiple views, or tracked between video frames. In these cases, the object labels are unknown but can be constrained to be the same or similar. We propose techniques that build on existing domain adaptation methods by explicitly modeling these relationships, and demonstrate empirically that they improve recognition accuracy in two scenarios, multicategory image classification and object detection in video.</p><br/>
<h2>reference text</h2><p>[1] Y. Aytar and A. Zisserman. Tabula rasa: Model transfer for object category detection. In CVPR, 2011. 1, 2, 3, 6, 7</p>
<p>[2] A. Bergamo and L. Torresani. Exploiting weakly-labeled web images to improve object classification: a domain adaptation approach. In NIPS, 2010. 2</p>
<p>[3] M. D. Breitenstein, F. Reichlin, B. Leibe, E. Koller-Meier, and L. V. Gool. Robust tracking-by-detection using a detector confidence particle filter. In ICCV, 2009. 2</p>
<p>[4] C. Christoudias, R. Urtasun, and T. Darrell. Multi-view learning in the presence of view disagreement. In UAI, 2008. 2</p>
<p>[5] W. Dai, Y. Chen, G.-R. Xue, Q. Yang, and Y. Yu. Translated learning: Transfer learning across different feature spaces. In NIPS, 2008. 2</p>
<p>[6] H. Daume III. Frustratingly easy domain adaptation. In ACL, 2007. 2</p>
<p>[7] L. Duan, I. W. Tsang, D. Xu, and T.-S. Chua. Domain adaptation from multiple sources via auxiliary classifiers. In ICML, 2009. 1</p>
<p>[8] L. Duan, I. W. Tsang, D. Xu, and S. J. Maybank. Domain transfer SVM for video concept detection. In CVPR, 2009. 2</p>
<p>[9] L. Duan, D. Xu, and I. Tsang. Learning with augmented features for heterogeneous domain adaptation. In ICML, 2012. 1, 2</p>
<p>[10] M. Everingham, L. Van Gool, C. Williams, J. Winn, and A. Zisserman. The PASCAL Visual Object Classes (VOC) challenge. IJCV, 88(2):303–338, 2010. 6</p>
<p>[11] A. Farhadi and M. K. Tabrizi. Learning to recognize activities from the wrong view point. In ECCV, 2008. 2</p>
<p>[12] P. F. Felzenszwalb, R. B. Girshick, D. McAllester, and D. Ramanan. Object detection with discriminatively trained part based models. PAMI, 32(9): 1627–1645, 2010. 3, 4, 6, 7</p>
<p>[13] B. Gong, Y. Shi, F. Sha, and K. Grauman. Geodesic flow kernel for unsupervised domain adaptation. In CVPR, 2012. 1, 2, 5</p>
<p>[14] R. Gopalan, R. Li, and R. Chellappa. Domain adaptation for object recognition: An unsupervised approach. In ICCV, 2011. 1, 2</p>
<p>[15] D. Hardoon, S. Szedmak, and J. Shawe-Taylor. Canonical correlation analysis: an overview with application to learning methods. Neural Computation, 16:26392664, 2004. 2</p>
<p>[16] J. Hoffman, E. Rodner, J. Donahue, T. Darrell, and K. Saenko. Efficient learning of domain-invariant image representations. In ICLR, 2013. 1, 2, 3, 4, 7</p>
<p>[17] J. Jiang. A literature survey on domain adaptation of statistical classifiers. http : / / s i faka . c s .uiuc . edu / ji ang4 / domain adapt at i / survey / . 2 on</p>
<p>[18] B. Kulis, K. Saenko, and T. Darrell. What you saw is not what you get: Domain adaptation using asymmetric kernel transforms. In CVPR, 2011. 1, 2, 5</p>
<p>[19] Y. J. Lee, J. Kim, and K. Grauman. Key-segments for video object segmentation. In ICCV, 2011. 1</p>
<p>[20] X. Li. Regularized Adaptation: Theory, Algorithms and Applications. PhD thesis, University of Washington, 2007. 2</p>
<p>[21] B. Long, P. S. Yu, and Z. Zhang. A general model for multiple view unsupervised learning. In ICDM, 2009. 2</p>
<p>[22] S. Melacci and M. Belkin. Laplacian support vector machines trained in the primal. JMLR, 12: 1149–1 184, 2011. 2, 3</p>
<p>[23] A. Prest, C. Leistner, J. Civera, C. Schmid, and V. Ferrari. Learning object class detectors from weakly annotated video. In CVPR, 2012. 2, 4</p>
<p>[24] K. Saenko, B. Kulis, M. Fritz, and T. Darrell. Adapting visual category models to new domains. In ECCV, 2010. 1, 2</p>
<p>[25] K. Saenko, B. Packer, C.-Y. Chen, S. Bandla, Y. Lee, Y. Jia, J.-C. Niebles, D. Koller, L. Fei-Fei, K. Grauman, and T. Darrell. Mid-level features improve recognition of interactive activities. Technical Report UCB/EECS-2012-209, EECS Department, University of California, Berkeley, 2012. 6</p>
<p>[26] Y. Shi and F. Sha. Information-theoretical learning of discriminative clusters for unsupervised domain adaptation. In  ICML, 2012. 2</p>
<p>[27] J. Yang, R. Yan, and A. Hauptmann. Adapting SVM classifiers to data with shifted distributions. In ICDM Workshops, 2007. 2</p>
<p>[28] J. Yang, R. Yan, and A. G. Hauptmann. Cross-domain video concept detection using adaptive SVMs. ACM Multimedia, 2007. 1 6 6 6 7 7 7 53 353</p>
<br/>
<br/><br/><br/></body>
</html>
