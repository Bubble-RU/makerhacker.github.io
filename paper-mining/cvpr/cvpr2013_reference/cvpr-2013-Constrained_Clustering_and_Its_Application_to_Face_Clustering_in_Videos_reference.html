<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>92 cvpr-2013-Constrained Clustering and Its Application to Face Clustering in Videos</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-92" href="../cvpr2013/cvpr-2013-Constrained_Clustering_and_Its_Application_to_Face_Clustering_in_Videos.html">cvpr2013-92</a> <a title="cvpr-2013-92-reference" href="#">cvpr2013-92-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>92 cvpr-2013-Constrained Clustering and Its Application to Face Clustering in Videos</h1>
<br/><p>Source: <a title="cvpr-2013-92-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Wu_Constrained_Clustering_and_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Baoyuan Wu, Yifan Zhang, Bao-Gang Hu, Qiang Ji</p><p>Abstract: In this paper, we focus on face clustering in videos. Given the detected faces from real-world videos, we partition all faces into K disjoint clusters. Different from clustering on a collection of facial images, the faces from videos are organized as face tracks and the frame index of each face is also provided. As a result, many pairwise constraints between faces can be easily obtained from the temporal and spatial knowledge of the face tracks. These constraints can be effectively incorporated into a generative clustering model based on the Hidden Markov Random Fields (HMRFs). Within the HMRF model, the pairwise constraints are augmented by label-level and constraint-level local smoothness to guide the clustering process. The parameters for both the unary and the pairwise potential functions are learned by the simulated field algorithm, and the weights of constraints can be easily adjusted. We further introduce an efficient clustering framework specially for face clustering in videos, considering that faces in adjacent frames of the same face track are very similar. The framework is applicable to other clustering algorithms to significantly reduce the computational cost. Experiments on two face data sets from real-world videos demonstrate the significantly improved performance of our algorithm over state-of-theart algorithms.</p><br/>
<h2>reference text</h2><br/>
<br/><br/><br/></body>
</html>
