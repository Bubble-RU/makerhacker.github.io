<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>396 cvpr-2013-Simultaneous Active Learning of Classifiers & Attributes via Relative Feedback</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-396" href="../cvpr2013/cvpr-2013-Simultaneous_Active_Learning_of_Classifiers_%26_Attributes_via_Relative_Feedback.html">cvpr2013-396</a> <a title="cvpr-2013-396-reference" href="#">cvpr2013-396-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>396 cvpr-2013-Simultaneous Active Learning of Classifiers & Attributes via Relative Feedback</h1>
<br/><p>Source: <a title="cvpr-2013-396-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Biswas_Simultaneous_Active_Learning_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Arijit Biswas, Devi Parikh</p><p>Abstract: Active learning provides useful tools to reduce annotation costs without compromising classifier performance. However it traditionally views the supervisor simply as a labeling machine. Recently a new interactive learning paradigm was introduced that allows the supervisor to additionally convey useful domain knowledge using attributes. The learner first conveys its belief about an actively chosen image e.g. “I think this is a forest, what do you think?”. If the learner is wrong, the supervisorprovides an explanation e.g. “No, this is too open to be a forest”. With access to a pre-trained set of relative attribute predictors, the learner fetches all unlabeled images more open than the query image, and uses them as negative examples of forests to update its classifier. This rich human-machine communication leads to better classification performance. In this work, we propose three improvements over this set-up. First, we incorporate a weighting scheme that instead of making a hard decision reasons about the likelihood of an image being a negative example. Second, we do away with pre-trained attributes and instead learn the attribute models on the fly, alleviating overhead and restrictions of a pre-determined attribute vocabulary. Finally, we propose an active learning framework that accounts for not just the label- but also the attributes-based feedback while selecting the next query image. We demonstrate significant improvement in classification accuracy on faces and shoes. We also collect and make available the largest relative attributes dataset containing 29 attributes of faces from 60 categories.</p><br/>
<h2>reference text</h2><p>[1] T. Berg, A. Berg, and J. Shih. Automatic attribute discovery and characterization from noisy web data. In ECCV, 2010.</p>
<p>[2] A. Biswas and D. W. Jacobs. Active image clustering: Seeking constraints from humans to complement algorithms. In CVPR, 2012.</p>
<p>[3] S. Branson, C. Wah, B. Babenko, F. Schroff, P. Welinder, P. Perona, and S. Belongie. Visual recognition with humans in the loop. In ECCV, 2010.</p>
<p>[4] A. Farhadi, I. Endres, D. Hoiem, and D. Forsyth. Describing objects by their attributes. In CVPR, 2009.</p>
<p>[5] M. Ferecatu and D. Geman. Interactive search for image categories by mental matching. In ICCV, 2007.</p>
<p>[6] V. Ferrari and A. Zisserman. Learning visual attributes. In NIPS, 2007.</p>
<p>[7] P. Jain and A. Kapoor. Active learning for large multi-class problems. In CVPR, 2009.</p>
<p>[8] T. Joachims. Optimizing search engines using clickthrough data. In KDD, 2002.</p>
<p>[9] A. J. Joshi, F. M. Porikli, and N. P. Papanikolopoulos. Multi-class active learning for image classification. In CVPR, 2009.</p>
<p>[10] A. Kovashka, D. Parikh, and K. Grauman. Whittlesearch: Image search with relative attribute feedback. In CVPR, 2012.</p>
<p>[11] A. Kovashka, S. Vijayanarasimhan, and K. Grauman. Actively selecting annotations among objects and attributes. In ICCV, 2011.</p>
<p>[12] N. Kumar, P. N. Belhumeur, A. Biswas, D. W. Jacobs, W. J. Kress, I. Lopez, and J. V. B. Soares. Leafsnap: A computer vision system for automatic plant species identification. In ECCV, 2012.</p>
<p>[13] N. Kumar, A. Berg, P. Belhumeur, and S. Nayar. Attribute and simile classifiers for face verification. In ICCV, 2009.</p>
<p>[14] C. H. Lampert, H. Nickisch, and S. Harmeling. Learning to detect unseen object classes by between-class attribute transfer. In CVPR, 2009.</p>
<p>[15] D. Parikh and K. Grauman. Interactively building a discriminative vocabulary of nameable attributes. In CVPR, 2011.</p>
<p>[16] D. Parikh and K. Grauman. Relative attributes. In ICCV, 2011.</p>
<p>[17] A. Parkash and D. Parikh. Attributes for Classifier Feedback. In ECCV, 2012.</p>
<p>[18] B. Settles, M. Craven, and S. Ray. Multiple-instance active learning. In J. C. Platt, D. Koller, Y. Singer, and S. T. Roweis, editors, NIPS, 2007.</p>
<p>[19] A. Shrivastava, S. Singh, and A. Gupta. Constrained semi-supervised learning using attributes and comparative attributes. In ECCV, 2012.</p>
<p>[20] B. Siddiquie and A. Gupta. Beyond active noun tagging: Modeling contextual interactions for multi-class active learning. In CVPR, pages 2979–2986. IEEE, 2010.</p>
<p>[21] S. Vijayanarasimhan and K. Grauman. Large-scale live active learning: Training object detectors with crawled data and crowds. In CVPR, 2011.</p>
<p>[22] G. Wang and D. Forsyth. Joint learning of visual attributes, object classes and visual saliency. In ICCV, 2009.</p>
<p>[23] G. Wang, D. Forsyth, and D. Hoiem. Comparative object similarity for improved recognition with few or no examples. In CVPR, 2010.</p>
<p>[24] J. Wang, K. Markert, and M. Everingham. Learning models for object recognition from natural language descriptions. In BMVC, 2009.</p>
<p>[25] J. Weston, S. Bengio, and N. Usunier. Large scale image annotation: learning to rank with joint word-image embeddings. Machine Learning, 8 1(1), 2010. 666454991</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
