<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>214 cvpr-2013-Image Understanding from Experts' Eyes by Modeling Perceptual Skill of Diagnostic Reasoning Processes</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-214" href="../cvpr2013/cvpr-2013-Image_Understanding_from_Experts%27_Eyes_by_Modeling_Perceptual_Skill_of_Diagnostic_Reasoning_Processes.html">cvpr2013-214</a> <a title="cvpr-2013-214-reference" href="#">cvpr2013-214-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>214 cvpr-2013-Image Understanding from Experts' Eyes by Modeling Perceptual Skill of Diagnostic Reasoning Processes</h1>
<br/><p>Source: <a title="cvpr-2013-214-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Li_Image_Understanding_from_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Rui Li, Pengcheng Shi, Anne R. Haake</p><p>Abstract: Eliciting and representing experts ’ remarkable perceptual capability of locating, identifying and categorizing objects in images specific to their domains of expertise will benefit image understanding in terms of transferring human domain knowledge and perceptual expertise into image-based computational procedures. In this paper, we present a hierarchical probabilistic framework to summarize the stereotypical and idiosyncratic eye movement patterns shared within 11 board-certified dermatologists while they are examining and diagnosing medical images. Each inferred eye movement pattern characterizes the similar temporal and spatial properties of its corresponding seg. edu anne .haake @ rit . edu , ments of the experts ’ eye movement sequences. We further discover a subset of distinctive eye movement patterns which are commonly exhibited across multiple images. Based on the combinations of the exhibitions of these eye movement patterns, we are able to categorize the images from the perspective of experts’ viewing strategies. In each category, images share similar lesion distributions and configurations. The performance of our approach shows that modeling physicians ’ diagnostic viewing behaviors informs about medical images’ understanding to correct diagnosis.</p><br/>
<h2>reference text</h2><p>[1] D. Batra, A. Kowdle, and D. Parikh. icoseg: Interactive cosegmentation with intelligent scribble guidance. In CVPR, pages 3169–3176, 2010.</p>
<p>[2] M. S. Castelhano, M. L. Mack, and J. M. Henderson. Viewing Task Influences Eye Movement Control during Active Scene Perception. J. Vision, 9(3): 1–15, 2009.</p>
<p>[3] J. Chen and Q. Ji. Probabilistic gaze estimation without ac-</p>
<p>[4]</p>
<p>[5]</p>
<p>[6]</p>
<p>[7]</p>
<p>[8]</p>
<p>[9]</p>
<p>[10]</p>
<p>[11]</p>
<p>[12]</p>
<p>[13]  tive personal calibration. In Proc. of CVPR, pages 609–616, 2011. D. Crandall, A. Owens, N. Snavely, and D. Huttenlocher. Discrete-continuous optimization for large-scale structure from motion. In CVPR, pages 3001–3008, 2011. E. B. Fox, E. B. Sudderth, M. I. Jordan, and A. S. Willsky. Bayesian nonparametric methods for learning markov switching processes. IEEE Signal Processing Magazine, 27(6):43–54, 2010. A. Geiger, M. Lauer, and R. Urtasum. A generative model for 3d urban scene understanding from movable platforms. In CVPR, pages 1945–1952, 2011. S. Gordon, S. Lotenberg, J. Jeronimo, and H. Greenspan. Evaluation of uterine cervis segmentations using ground truth from multiple experts. J. Computerized Medical Imaging and Graphics, 33(3):205–216, 2009. P. H. Gosselin and matthieu Cord. Actively learning methods for interactive image retrieval. IEEE Trans. on Image Processing, 17(7): 1200–121 1, 2008. A. Gupta, S. Satkin, A. A. Efros, and M. Hebert. From 3d scene geometry to human workspace. In CVPR, pages 1961 1968, 2011. V. Hedau, D. Hoiem, and D. Forsyth. Recovering the spatial layout of cluttered rooms. In ICCV, pages 1849–1856, 2009. J. M. Henderson and G. L. Malcolm. Searching in the Dark Cognitive Relevance Drives Attention in Real-world Scenes. Psychonomic Bulletin and Review, 16(5):850–856, 2009. R. Hoffman and M. S. Fiore. Perceptual (re)learning : a leverage point for human-centered computing. J. Intelligent Systems, 22(3):79–83, 2007. D. Hoiem, A. A. Efros, and M. Hebert. Recovering surface</p>
<p>[14]</p>
<p>[15]</p>
<p>[16]</p>
<p>[17]</p>
<p>[18]</p>
<p>[19]</p>
<p>[20]</p>
<p>[21]</p>
<p>[22]</p>
<p>[23]  layout from an image. IJCV, 75(1): 15 1–172, 2007. A. Kapoor, K. Grauman, R. Urtasun, and T. Darrell. Active learning with gaussian processes for object categorization. In ICCV, pages 1–8, 2007. A. Kowdle, Y.-J. Chang, A. Gallagher, and T. Chen. Active learning for piecewise planar 3d reconstruction. In CVPR, pages 929–936, 2011. D. C. Lee, M. Hebert, and T. Kanade. Geometric reasoning for single image structure recovery. In CVPR, pages 2136– 2143, 2009. S. Marat, T. H. Phuoc, L. Granjon, N. Guyader, D. Pellerin, and A. Gurin-Dugu. Modeling spatio-temporal saliency to predicit gaze direction for short videos. International Journal of Computer Vision, pages 23 1–243, 2009. A. Oliva and A. Torralba. Modeling the shape ofthe scene: A holistic representation of the spatial envelope. International Journal of Computer Vision, 42(36): 145–175, 2001. T. J. Palmeri, A. C.-N. Wong, and I. Gauthier. Computational approaches to the development ofperceptual expertise. TRENDS in Cognitive Sciences, 8(8):378–386, 2004. A. Saxena, M. Sun, and A. Y. Ng. Learning 3d scene structure from a single still image. PAMI, 3 1(5):824–840, 2009. E. B. Sudderth, A. Torralba, W. T. Freeman, and A. S. Willsky. Describing visual scenes using transformed objects and parts. International Journal of Computer Vision, 77(3):291– 330, 2008. R. Thibaux and M. I. Jordan. Hierarchical beta processes and the indian buffet process. J. Machine Learning andResearch, 22(3):25–31, 2007. S. Vijayanarasimhan, P. Jain, and K. Grauman. Far-sighted actively learning on a budget for image and video recogni-  tion. In CVPR, pages 3035–3042, 2010.</p>
<p>[24] W. Wang, C. Chen, Y. Wang, T. Jiang, F. Fang, and Y. Yao. Simulating human saccadic scanpaths on natural images. In CVPR, pages 441–448, 2011. 222111999311  (b) Images categorized as Sym etry and the Switching Pat ern recognized on them.  (d) Images categorized as High-density Lesions and the Clut er Pat ern recognized on them.  Figure 6: For each of the four categories five images are illustrated. We also demonstrate one instantiation of the signature patterns recognized from the set of subjects’ eye movement patterns which is estimated by our model. Images used with permission from Logical Images, Inc.  222111999422</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
