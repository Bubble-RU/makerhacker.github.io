<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>49 cvpr-2013-Augmenting Bag-of-Words: Data-Driven Discovery of Temporal and Structural Information for Activity Recognition</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-49" href="../cvpr2013/cvpr-2013-Augmenting_Bag-of-Words%3A_Data-Driven_Discovery_of_Temporal_and_Structural_Information_for_Activity_Recognition.html">cvpr2013-49</a> <a title="cvpr-2013-49-reference" href="#">cvpr2013-49-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>49 cvpr-2013-Augmenting Bag-of-Words: Data-Driven Discovery of Temporal and Structural Information for Activity Recognition</h1>
<br/><p>Source: <a title="cvpr-2013-49-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Bettadapura_Augmenting_Bag-of-Words_Data-Driven_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Vinay Bettadapura, Grant Schindler, Thomas Ploetz, Irfan Essa</p><p>Abstract: We present data-driven techniques to augment Bag of Words (BoW) models, which allow for more robust modeling and recognition of complex long-term activities, especially when the structure and topology of the activities are not known a priori. Our approach specifically addresses the limitations of standard BoW approaches, which fail to represent the underlying temporal and causal information that is inherent in activity streams. In addition, we also propose the use ofrandomly sampled regular expressions to discover and encode patterns in activities. We demonstrate the effectiveness of our approach in experimental evaluations where we successfully recognize activities and detect anomalies in four complex datasets.</p><br/>
<h2>reference text</h2><p>[1] D. Blei, A. Ng, and M. Jordan. Latent dirichlet allocation. JMLR, 2003. 1</p>
<p>[2] Leo Breiman. Bagging predictors. Machine Learning, 24:123–140, 1996. 1</p>
<p>[3] Chih-Chung Chang and Chih-Jen Lin. LIBSVM: A library for support vector machines. ACM Trans. on Intelligent Systems and Technology, 2011. 5</p>
<p>[4] M. Chen, L. Mummert, P. Pillai, A. Hauptmann, and R. Sukthankar. Exploiting multi-level parallelism for low-latency activity recognition in streaming video. In ACM SIGMM Conf. on Multimedia Systems, 2010. 2</p>
<p>[5] O. Duchenne, I. Laptev J., Sivic, F. Bach, and J. Ponce. Automatic annotation of human actions in video. In ICCV, pages 1491–1498, 2009. 2</p>
<p>[6] G. A. Fink. Markov Models for Pattern Recognition, From Theory to Applications. Springer, 2008. 3, 5</p>
<p>[7] A. Gaidon, Z. Harchaoui, and C. Schmid. Actom sequence models for efficient action detection. In CVPR, 2011. 2</p>
<p>[8] R. Hamid, R. K. Kumar, M. Grundmann, K. Kim, I. Essa, and J. Hodgins. Player localization using multiple static cameras for sports visualization. In CVPR, 2010. 6</p>
<p>[9] R. Hamid, S. Maddi, A. Johnson, A. Bobick, I. Essa, and C. Isbell. A novel sequence representation for unsupervised</p>
<p>[10]</p>
<p>[11]</p>
<p>[12]</p>
<p>[13]</p>
<p>[14]</p>
<p>[15]</p>
<p>[16]</p>
<p>[17]</p>
<p>[18]</p>
<p>[19]</p>
<p>[20]  analysis of human activities. Artificial Intell., 173: 1221–44, 2009. 2, 3 T. Hofmann. Probabilistic latent semantic indexing. In ACM SIGIR Conf. on IR, 1999. 1 Y. A. Ivanov and A. F. Bobick. Recognition of visual activities and interactions by stochastic parsing. PAMI, 22(2):852– 872, August 2000. 1 I. Laptev, M. Marszalek, C. Schmid, and B. Rozenfeld. Learning realistic human actions from movies. In CVPR, 2008. 2 Q. Le, W. Zou, S. Yeung, and A. Ng. Learning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis. In CVPR, 2011. 2 V. Lepetit and P. Fua. Keypoint recognition using randomized trees. PAMI, 28(9): 1465–1479, 2006. 1 J. Liu, B. Kuipers, and S. Savarese. Recognizing human actions by attributes. In CVPR, 2011. 2 C. Manning, P. Raghavan, and H. Schütze. Introduction to Information Retrieval. Cambridge Univ. Press, 2008. 2, 5 JA Martin, G. Regehr, R. Reznick, H. MacRae, J. Murnaghan, C. Hutchison, and M. Brown. Objective structured assessment of technical skill (osats) for surgical residents. British Journal of Surgery, 84(2):273–278, 1997. 6, 7 Darnell Moore and Irfan Essa. Recognizing multitasked activities from video using stochastic context-free grammar. In AAAI, 2002. 1 J. Niebles, H. Wang, and Li Fei-Fei. Unsupervised learning of human action categories using spatial-temporal words. IJCV, 2008. 1 S. Oh, A. Hoogs, M. Turek, and R. Collins. Content-based</p>
<p>[21]</p>
<p>[22]</p>
<p>[23]</p>
<p>[24]</p>
<p>[25]  retrieval of functional objects in video using scene context. In ECCV, 2010. 5 G. Salton. The SMART retrieval system: Experiments in automatic document processing. Prentice-Hall, 1971. 2 P. Turaga, R. Chellappa, V. S. Subrahmanian, and O. Udrea. Machine recognition of human activities: A survey. IEEE Trans. Circuits Systems for Video Tech., October 2008. 1 H.M. Wallach. Topic modeling: beyond bag-of-words. In ICML, pages 977–984. ACM, 2006. 1 H. Wang, A. Klaserr, C. Schmid, and C. Liu. Action recognition by dense trajectories. In CVPR, 2011. 2 H. Wang, M. M. Ullah, A. Kläser, I. Laptev, and C. Schmid. Evaluation of local spatio-temporal features for action recognition. In BMVC, 2009. 2, 6 222666222644</p>
<br/>
<br/><br/><br/></body>
</html>
