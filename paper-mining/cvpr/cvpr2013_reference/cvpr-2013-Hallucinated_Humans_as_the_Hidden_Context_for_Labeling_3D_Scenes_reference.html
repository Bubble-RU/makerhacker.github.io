<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>197 cvpr-2013-Hallucinated Humans as the Hidden Context for Labeling 3D Scenes</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-197" href="../cvpr2013/cvpr-2013-Hallucinated_Humans_as_the_Hidden_Context_for_Labeling_3D_Scenes.html">cvpr2013-197</a> <a title="cvpr-2013-197-reference" href="#">cvpr2013-197-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>197 cvpr-2013-Hallucinated Humans as the Hidden Context for Labeling 3D Scenes</h1>
<br/><p>Source: <a title="cvpr-2013-197-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Jiang_Hallucinated_Humans_as_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Yun Jiang, Hema Koppula, Ashutosh Saxena</p><p>Abstract: For scene understanding, one popular approach has been to model the object-object relationships. In this paper, we hypothesize that such relationships are only an artifact of certain hidden factors, such as humans. For example, the objects, monitor and keyboard, are strongly spatially correlated only because a human types on the keyboard while watching the monitor. Our goal is to learn this hidden human context (i.e., the human-object relationships), and also use it as a cue for labeling the scenes. We present Infinite Factored Topic Model (IFTM), where we consider a scene as being generated from two types of topics: human configurations and human-object relationships. This enables our algorithm to hallucinate the possible configurations of the humans in the scene parsimoniously. Given only a dataset of scenes containing objects but not humans, we show that our algorithm can recover the human object relationships. We then test our algorithm on the task ofattribute and object labeling in 3D scenes and show consistent improvements over the state-of-the-art.</p><br/>
<h2>reference text</h2><p>[1] E. Aksoy, A. Abramov, F. Worgotter, and B. Dellen. Categorizing object-action relations from semantic scene graphs. In ICRA, 2010.</p>
<p>[2] A. Anand, H. S. Koppula, T. Joachims, and A. Saxena. Contextually guided semantic labeling and search for 3D point clouds. IJRR, 32(1):19–34, 2013.</p>
<p>[3] D. M. Blei and J. D. McAuliffe. Supervised topic models. In NIPS, 2007.</p>
<p>[4] V. Delaitre, D. Fouhey, I. Laptev, J. Sivic, A. Gupta, and A. Efros. Scene semantics from long-term observation of people. In ECCV, 2012.</p>
<p>[5] P. Felzenszwalb, D. McAllester, and D. Ramanan. A discriminatively trained, multiscale, deformable part model. In CVPR, 2008.</p>
<p>[6] D. Fouhey, V. Delaitre, A. Gupta, A. A. Efros, I. Laptev, and</p>
<p>[7]</p>
<p>[8]</p>
<p>[9]</p>
<p>[10]</p>
<p>[11]</p>
<p>[12]</p>
<p>[13]</p>
<p>[14]</p>
<p>[15]</p>
<p>[16]</p>
<p>[17]</p>
<p>[18]</p>
<p>[19]  J. Sivic. People watching: Human actions as a cue for single view geometry. In ECCV, 2012. J. Gibson. The Ecological Approach to Visual Perception. Houghton Mifflin, 1979. H. Grabner, J. Gall, and L. J. V. Gool. What makes a chair a chair? In CVPR, 2011. A. Gupta, A. Kembhavi, and L. Davis. Observing humanobject interactions: Using spatial and functional compatibility for recognition. PAMI, 31(10): 1775–1789, 2009. A. Gupta, S. Satkin, A. A. Efros, and M. Hebert. From 3d scene geometry to human workspace. In CVPR, 2011. V. Hedau, D. Hoiem, and D. Forsyth. Thinking inside the box: Using appearance models and context based on room geometry. In ECCV, 2010. G. Heitz, S. Gould, A. Saxena, and D. Koller. Cascaded classification models: Combining models for holistic scene understanding. In NIPS, 2008. Z. Jia, A. Gallagher, A. Saxena, and T. Chen. 3d-based reasoning with blocks, support, and stability. In CVPR, 2013. Y. Jiang, M. Lim, and A. Saxena. Learning object arrangements in 3d scenes using human context. In ICML, 2012. Y. Jiang, M. Lim, C. Zheng, and A. Saxena. Learning to place new objects in a scene. IJRR, 3 1(9): 1021–1043, 2012. Y. Jiang, S. Moseson, and A. Saxena. Efficient grasping from rgbd images: Learning using a new rectangle representation. In ICRA. IEEE, 2011. Y. Jiang and A. Saxena. Hallucinating humans for learning robotic placement of objects. In ISER, 2012. Y. Jiang and A. Saxena. Discovering different types of topics: Factored topic models. In IJCAI, 2013. H. Koppula, A. Anand, T. Joachims, and A. Saxena. Seman-</p>
<p>[20]</p>
<p>[21]</p>
<p>[22]</p>
<p>[23]</p>
<p>[24]</p>
<p>[25]</p>
<p>[26]</p>
<p>[27]</p>
<p>[28]</p>
<p>[29]</p>
<p>[30] [3 1]</p>
<p>[32]  tic labeling of 3d point clouds for indoor scenes. In NIPS, 2011. H. Koppula, R. Gupta, and A. Saxena. Learning human activities and object affordances from rgb-d videos. IJRR, 2013. D. C. Lee, A. Gupta, M. Hebert, and T. Kanade. Estimating spatial layout of rooms using volumetric reasoning about objects and surfaces. In NIPS, 2010. C. Li, A. Kowdle, A. Saxena, and T. Chen. Towards holistic scene understanding: Feedback enabled cascaded classification models. In NIPS, 2010. R. Neal. Markov chain sampling methods for dirichlet process mixture models. J comp graph stats, 9(2), 2000. D. Norman. The Design of Everyday Things. 1988. H. Pirsiavash and D. Ramanan. Detecting activities of daily living in first-person camera views. In CVPR, 2012. A. Saxena, S. H. Chung, and A. Y. Ng. Learning depth from single monocular images. In NIPS 18, 2005. A. Saxena, M. Sun, and A. Y. Ng. Make3d: Learning 3d scene structure from a single still image. IEEE PAMI, 31(5):824–840, 2009. N. Silberman, D. Hoiem, P. Kohli, and R. Fergus. Indoor segmentation and support inference from rgbd images. In ECCV, 2012. J. Sung, C. Ponce, B. Selman, and A. Saxena. Human activity detection from RGBD images. In ICRA, 2012. Y. W. Teh. Dirichlet process. Encyclopedia of Machine Learning, pages 280–287, 2010. X. Xiong and D. Huber. Using context to create semantic 3d models of indoor environments. In BMVC, 2010. B. Yao and L. Fei-Fei. Modeling mutual context of object  and human pose in human-object interaction activities. CVPR, 2010. 223990990088  In</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
