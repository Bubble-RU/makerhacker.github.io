<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>411 cvpr-2013-Statistical Textural Distinctiveness for Salient Region Detection in Natural Images</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-411" href="../cvpr2013/cvpr-2013-Statistical_Textural_Distinctiveness_for_Salient_Region_Detection_in_Natural_Images.html">cvpr2013-411</a> <a title="cvpr-2013-411-reference" href="#">cvpr2013-411-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>411 cvpr-2013-Statistical Textural Distinctiveness for Salient Region Detection in Natural Images</h1>
<br/><p>Source: <a title="cvpr-2013-411-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Scharfenberger_Statistical_Textural_Distinctiveness_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Christian Scharfenberger, Alexander Wong, Khalil Fergani, John S. Zelek, David A. Clausi</p><p>Abstract: A novel statistical textural distinctiveness approach for robustly detecting salient regions in natural images is proposed. Rotational-invariant neighborhood-based textural representations are extracted and used to learn a set of representative texture atoms for defining a sparse texture model for the image. Based on the learnt sparse texture model, a weighted graphical model is constructed to characterize the statistical textural distinctiveness between all representative texture atom pairs. Finally, the saliency of each pixel in the image is computed based on the probability of occurrence of the representative texture atoms, their respective statistical textural distinctiveness based on the constructed graphical model, and general visual attentive constraints. Experimental results using a public natural image dataset and a variety of performance evaluation metrics show that the proposed approach provides interesting and promising results when compared to existing saliency detection methods.</p><br/>
<h2>reference text</h2><p>[1] R. Achanta, S. Hemami, F. Estrada, and S. Susstrunk. Frequency-tuned salient region detection. In Conf. on Computer Vision and Pattern Recognition, pages 1597 –1604, 2009.</p>
<p>[2] R. Achanta and S. Suesstrunk. Saliency detection using maximum symmetric surround. In Int. Conf. on Image Processing, pages 2653 –2656, 2010.</p>
<p>[3] S. Avidan and A. Shamir. Seam carving for content-aware image resizing. ACM Trans. on Graphics, 26(3): 10, 2007.</p>
<p>[4] C. M. Bishop. Pattern Recognition and Machine Learning (Information Science and Statistics). Springer-Verlag New York, Inc., Secaucus, NJ, USA, 2006.</p>
<p>[5] M. M. Cheng, G. X. Zhang, N. Mitra, X. Huang, and S. H. Hu. Global contrast based salient region detection. In Conf. on Computer Vision and Pattern Recognition, pages 409 416, 2011. 9 9 98 8 85 3 3  Original  IT [13]  SR [11]  CA [7]  FT [1]  SM [22]  HC [5]  RC [5]  LR [25]  SF [21]  TD  GT  Figure 8: Visual comparison of our approach (TD) with other saliency approaches and ground truth (GT).</p>
<p>[6] L. Duan, C. Wu, J. Miao, L. Qing, and Y. Fu. Visual saliency detection by spatially weighted dissimilarity. In Conf. on Computer Vision and Pattern Recognition, pages 473 –480, 2011.</p>
<p>[7] S. Goferman, L. Zelnik-Manor, and A. Tal. Context-aware saliency detection. In Conf. on Computer Vision and Pattern Recognition, pages 2376 –2383, 2010.</p>
<p>[8] C. Guo, Q. Ma, and L. Zhang. Spatio-temporal saliency detection using phase spectrum of quaternion fourier transform. In Conf. on Computer Vision and Pattern Recognition, pages 1–8, 2008.</p>
<p>[9] J. Han, K. Ngan, M. Li, and H. Zhang. Unsupervised extraction of visual attention objects in color images. IEEE Trans.  Circuits Syst. Video Technol., 16(1): 141 –145, 2006.</p>
<p>[10] J. Harel, C. Koch, and P. Perona. Graph-based visual saliency. In Advances in Neural Information Processing Systems 19, pages 545 –552, 2007.</p>
<p>[11] X. Hou and L. Zhang. Saliency detection: A spectral residual approach. In Conf. on Computer Vision and Pattern Recognition, pages 1–8, 2007.</p>
<p>[12] L. Itti and P. Baldi. Bayesian surprise attracts human attention. In NIPS, 2005.</p>
<p>[13] L. Itti, C. Koch, and E. Niebur. A model of saliency-based visual attention for rapid scene analysis. IEEE Trans. Pattern Analysis and Machine Intelligence, 20(1 1): 1254 –1259, 1998.</p>
<p>[14] T. Judd, K. Ehinger, F. Durand, and A. Torralba. Learning to predict where humans look. In Int. Conf. on Computer Vision, 2009.</p>
<p>[15] T. Kanungo, D. Mount, N. Netanyahu, C. Piatko, R. Silverman, and A. Wu. An efficient k-means clustering algorithm: analysis and implementation. IEEE Trans. Pattern Analysis and Machine Intelligence, 24(7):881 –892, Jul 2002.</p>
<p>[16] C. Koch and S. Ullman. Shifts in selective visual attention: towards the underlying neural circuitry. Human neurobiology, 4(4):219 –227, 1985.</p>
<p>[17] L. Li, P. Fieguth, G. Kuang, and H. Zha. Sorted random projections for robust texture classification. In Int. Conf. on Computer Vision, pages 391 –398, 2011.</p>
<p>[18] T. Liu, J. Sun, N. Zheng, X. Tang, and H. Shum. Learning to detect a salient object. In Conf. on Computer Vision and Pattern Recognition, pages 1–8, 2007.</p>
<p>[19] Y. Ma and H. Zhang. Contrast-based image attention analysis by using fuzzy growing. In Int. Conf. on Multimedia, ACM MULTIMEDIA, pages 374 –381, 2003.</p>
<p>[20] A. Oliva, A. Torralba, M. Castelhano, and J. Henderson. Topdown control of visual attention in object detection. In Int. Conf. on Image Processing, volume 1, pages I–253, 2003.</p>
<p>[21] F. Perazzi, P. Krahenbuhl, Y. Pritch, and A. Hornung. Saliency filters: Contrast based filtering for salient region detection. In Conf. on Computer Vision and Pattern Recognition, pages 733 –740, 2012.</p>
<p>[22] E. Rahtu, J. Kannala, M. Salo, and J. Heikkil a¨. Segmenting salient objects from images and videos. In Europe. Conf. on Computer Vision, pages 366 –379, 2010.</p>
<p>[23] C. Rother, V. Kolmogorov, and A. Blake. Grabcut: interactive foreground extraction using iterated graph cuts. ACM Trans. on Graphics, 23(3):309 –314, 2004.</p>
<p>[24] U. Rutishauser, D. Walther, C. Koch, and P. Perona. Is bottom-up attention useful for object recognition? In Conf. on Computer Vision and Pattern Recognition, volume 2, pages 2 –37, 2004.</p>
<p>[25] X. Shen and Y. Wu. A unified approach to salient object detection via low rank matrix recovery. In Conf. on Computer Vision and Pattern Recognition, 2012.</p>
<p>[26] M. Wang, J. Konrad, P. Ishwar, K. Jing, and H. Rowley. Image saliency: From intrinsic to extrinsic context. In Conf. on Computer Vision and Pattern Recognition, pages 417 –424, 2011.</p>
<p>[27] Y. Zhai and M. Shah. Visual attention detection in video sequences using spatiotemporal cues. ACM Multimedia, page 815 824, 2006. 9 9 98 8 86 4 4</p>
<br/>
<br/><br/><br/></body>
</html>
