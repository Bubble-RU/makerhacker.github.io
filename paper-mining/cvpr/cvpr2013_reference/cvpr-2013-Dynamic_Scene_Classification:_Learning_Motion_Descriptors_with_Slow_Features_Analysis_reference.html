<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>137 cvpr-2013-Dynamic Scene Classification: Learning Motion Descriptors with Slow Features Analysis</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-137" href="../cvpr2013/cvpr-2013-Dynamic_Scene_Classification%3A_Learning_Motion_Descriptors_with_Slow_Features_Analysis.html">cvpr2013-137</a> <a title="cvpr-2013-137-reference" href="#">cvpr2013-137-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>137 cvpr-2013-Dynamic Scene Classification: Learning Motion Descriptors with Slow Features Analysis</h1>
<br/><p>Source: <a title="cvpr-2013-137-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Theriault_Dynamic_Scene_Classification_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Christian Thériault, Nicolas Thome, Matthieu Cord</p><p>Abstract: In this paper, we address the challenging problem of categorizing video sequences composed of dynamic natural scenes. Contrarily to previous methods that rely on handcrafted descriptors, we propose here to represent videos using unsupervised learning of motion features. Our method encompasses three main contributions: 1) Based on the Slow Feature Analysis principle, we introduce a learned local motion descriptor which represents the principal and more stable motion components of training videos. 2) We integrate our local motion feature into a global coding/pooling architecture in order to provide an effective signature for each video sequence. 3) We report state of the art classification performances on two challenging natural scenes data sets. In particular, an outstanding improvement of 11 % in classification score is reached on a data set introduced in 2012.</p><br/>
<h2>reference text</h2><p>[1] S. Avila, N. Thome, M. Cord, E. Valle, and A. de Albuquerque. Pooling in image representation: the visual codeword point of view. CVIU, 117(5):453–465, May 2013. 3</p>
<p>[2] S. S. Beauchemin and J. L. Barron. The computation of optical flow. ACM, New York, 1995. 2</p>
<p>[3] Y. Bengio. Learning Deep Architectures for AI. Now Pub-</p>
<p>[4]</p>
<p>[5]</p>
<p>[6]</p>
<p>[7]</p>
<p>[8]</p>
<p>[9]</p>
<p>[10]</p>
<p>[11]</p>
<p>[12]</p>
<p>[13]  lishers Inc., Hanover, MA, USA, 2009. 1 A. Coates and A. Ng. The importance of encoding versus training with sparse coding and vector quantization. In ICML 2011, pages 921–928, 2011. 5 T. Crivelli, P. Bouthemy, B. Cernuschi-Frias, and J. Yao. Learning mixed-state markov models for statistical motion texture tracking. In Proc. ICCV’09, MLVMA’09, 2009. 2 T. Crivelli, G. Piriou, B. Cernuschi-Frias, P. Bouthemy, and J. Yao. Simultaneous motion detection and background reconstruction with a mixed-state conditional markov random field. In ECCV’08, volume 1, pages 113–126, 2008. 2 N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. In CVPR, vol 2, pages 886–893, 2005. 2 R. De Valois, E. Yund, and N. Hepler. The orientation and direction selectivity of cells in macaque visual cortex. Vision Research, 22:531–544, 1982. 4 K. G. Derpanis, M. Lecce, K. Daniilidis, and R. P. Wildes. Dynamic scene understanding: The role of orientation features in space and time in scene classification. In CVPR 12, pages 1306–1313, 2012. 2, 4, 5, 6 J. J. DiCarlo, D. Zoccolan, and N. C. Rust. How does the brain solve visual object recognition? Neuron, 73:415–434, 2012 Feb 9 2012. 1 A. A. Efros, A. C. Berg, G. Mori, and J. Malik. Recognizing action at a distance. In ICCV, pages 726–733, 2003. 2 M.-J. Escobar and P. Kornprobst. Action recognition via bioinspired features: The richness of center-surround interaction. CVIU, 116(5):593–605, 2012. 2, 3 D. J. Fleet and Y. Weiss. Optical Flow Estimation. In Handbook of Mathematical Models in Computer Vision N. Paragios, Y. Chen, and O. Faugeras (eds.). Springer. 2</p>
<p>[14] P. Foldiak. Learning invariance from transformation sequences. Neural Comput., 3(2): 194–200, 1991 . 2</p>
<p>[15] M. Franzius, N. Wilbert, and L. Wiskott. Invariant object recognition with slow feature analysis. In ICANN, pages 961–970, 2008. 4</p>
<p>[16] H. Goh, N. Thome, M. Cord, and J.-H. Lim. Unsupervised and supervised visual codes with restricted boltzmann machines. In ECCV, pages 298–31 1, 2012. 5</p>
<p>[17] Hubel.D and Wiesel.T. Receptive fields of single neurones in the cat’s striate cortex. J.Physiol, pages 574–591, 1959. 4</p>
<p>[18] H. Jhuang, T. Serre, L. Wolf, and T. Poggio. A biologically inspired system for action recognition. In ICCV, pages 1–8, 2007. 2, 3</p>
<p>[19] I. Laptev, B. Caputo, C. Sch u¨ldt, and T. Lindeberg. Local velocity-adapted motion events for spatio-temporal recognition. CVIU, 108(3):207–229, 2007. 1, 2, 3</p>
<p>[20] I. Laptev, M. Marszałek, C. Schmid, and B. Rozenfeld. Learning realistic human actions from movies. In CVPR, 2008. 2, 3</p>
<p>[21] P. Lazebnik.S, Schmid.C. Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories. volume 2 of CVPR, pages 2169–2178, 2006. 5</p>
<p>[22] D. G. Lowe. Distinctive image features from scale-invariant keypoints. IJCV, 60:91–1 10, 2004. 2</p>
<p>[23] M. Marszalek, I. Laptev, and C. Schmid. Actions in context. IEEE CVPR, 2009. 2, 5, 6</p>
<p>[24] G. Mitchison. Removing time variation with the anti-hebbian differential synapse.Neural Comput., 3(3):3 12–320, 1991 . 2</p>
<p>[25] J. A. Movshon, I. D. Thompson, and D. J. Tolhurst. Spatial summation in the receptive fields of simple cells in the cats striate cortex. J. Physiol, 283:53–77, 1978. 1, 2</p>
<p>[26] A. Oliva and A. Torralba. Modeling the shape of the scene: A holistic representation of the spatial envelope. IJCV, 42(3): 145–175, 2001. 5, 6</p>
<p>[27] E. T. Rolls and T. T. Milward. A model of invariant object recognition in the visual system: Learning rules, activation functions, lateral inhibition, and information-based performance measures. Neural Comput., 12:2547–2572, 2000. 2</p>
<p>[28] T. Serre, L. Wolf, S. Bileschi, M. Riesenhuber, and T. Poggio. Robust object recognition with cortex-like mechanisms. IEEE PAMI, 29:41 1–426, 2007. 3, 5</p>
<p>[29] N. Shroff, P. K. Turaga, and R. Chellappa. Moving vistas: Exploiting motion for describing scenes. In CVPR, pages 1911–1918, 2010. 2, 4, 5, 6</p>
<p>[30] E. Simoncelli and D. Heeger. A model of neural responses in visual area mt. Vision Research, 38:743–761, 1998. 1, 2 [3 1] J. Sivic and A. Zisserman. Video Google: A text retrieval approach to object matching in videos. In ICCV, volume 2, pages 1470–1477, 2003. 3</p>
<p>[32] S. Soatto, G. Doretto, and Y. N. Wu. Dynamic textures. In ICCV, pages 439–446, 2001. 2</p>
<p>[33] C. Th ´eriault, N. Thome, and M. Cord. Extended coding and pooling in the hmax model. IEEE Trans.Image processing, 22(2):764–777, Feb. 2013. 2, 4</p>
<p>[34] L. Wiskott and T. Sejnowski. Slow feature analysis: Unsupervised learning of invariances. Neural Comput., 14:715– 770, 2002. 2, 3, 4</p>
<p>[35] Z. Zhang and D. Tao. Slow feature analysis for human action recognition. IEEE, PAMI, 34(3):436–450, 2012. 2, 3, 4, 6 222666001088</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
