<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>408 cvpr-2013-Spatiotemporal Deformable Part Models for Action Detection</title>
</head>

<body>
<p><a title="cvpr" href="../cvpr_home.html">cvpr</a> <a title="cvpr-2013" href="../home/cvpr2013_home.html">cvpr2013</a> <a title="cvpr-2013-408" href="../cvpr2013/cvpr-2013-Spatiotemporal_Deformable_Part_Models_for_Action_Detection.html">cvpr2013-408</a> <a title="cvpr-2013-408-reference" href="#">cvpr2013-408-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>408 cvpr-2013-Spatiotemporal Deformable Part Models for Action Detection</h1>
<br/><p>Source: <a title="cvpr-2013-408-pdf" href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Tian_Spatiotemporal_Deformable_Part_2013_CVPR_paper.pdf">pdf</a></p><p>Author: Yicong Tian, Rahul Sukthankar, Mubarak Shah</p><p>Abstract: Deformable part models have achieved impressive performance for object detection, even on difficult image datasets. This paper explores the generalization of deformable part models from 2D images to 3D spatiotemporal volumes to better study their effectiveness for action detection in video. Actions are treated as spatiotemporal patterns and a deformable part model is generated for each action from a collection of examples. For each action model, the most discriminative 3D subvolumes are automatically selected as parts and the spatiotemporal relations between their locations are learned. By focusing on the most distinctive parts of each action, our models adapt to intra-class variation and show robustness to clutter. Extensive experiments on several video datasets demonstrate the strength of spatiotemporal DPMs for classifying and localizing actions.</p><br/>
<h2>reference text</h2><p>[1] M. Blank et al. Actions as space-time shapes. In ICCV, 2005.</p>
<p>[2] W. Brendel and S. Todorovic. Learning spatiotemporal graphs of human activities. In ICCV, 2011.</p>
<p>[3] L. Cao, Z. Liu, and T. S. Huang. Cross-dataset action detection. In CVPR, 2010.</p>
<p>[4] N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. In CVPR, 2005.</p>
<p>[5] A. Fathi and G. Mori. Action recognition by learning midlevel motion features. In CVPR, 2008.</p>
<p>[6] P. Felzenszwalb, R. Girshick, D. McAllester, and D. Ramanan. Object detection with discriminatively trained partbased models. PAMI, 32(9), 2010.</p>
<p>[7] Y. Hu et al. Action detection in complex scenes with spatial and temporal ambiguities. In ICCV, 2009.</p>
<p>[8] Y. Ke, R. Sukthankar, and M. Hebert. Efficient visual event detection using volumetric features. In ICCV, 2005.</p>
<p>[9] Y. Ke, R. Sukthankar, and M. Hebert. Event detection in crowded videos. In ICCV, 2007.</p>
<p>[10] A. Kl¨ aser, M. Marszałek, and C. Schmid. A spatio-temporal descriptor based on 3D-gradients. In BMVC, 2008.</p>
<p>[11] A. Kl¨ aser, M. Marszałek, C. Schmid, and A. Zisserman. Human Focused Action Localization in Video. In ECCV Workshop on Sign, Gesture, and Activity, 2010.</p>
<p>[12] T. Lan, Y. Wang, and G. Mori. Discriminative figure-centric models for joint action localization and recognition. In ICCV, 2011.</p>
<p>[13] I. Laptev, M. Marszałek, C. Schmid, and B. Rozenfeld. Learning realistic human actions from movies. In CVPR, 2008.</p>
<p>[14] J. Liu, J. Luo, and M. Shah. Recognizing realistic actions from videos “in the wild”. In CVPR, 2009.</p>
<p>[15] J. C. Niebles, C.-W. Chen, and L. Fei-Fei. Modeling temporal structure of decomposable motion segments for activity classification. In ECCV, 2010.</p>
<p>[16] J. C. Niebles, H. Wang, and L. Fei-Fei. Unsupervised learning of human action categories using spatial-temporal words. IJCV, 79(3), 2008.</p>
<p>[17] M. Raptis, I. Kokkinos, and S. Soatto. Discovering discrim-</p>
<p>[18]</p>
<p>[19]</p>
<p>[20]</p>
<p>[21]</p>
<p>[22]</p>
<p>[23]</p>
<p>[24]</p>
<p>[25]</p>
<p>[26]</p>
<p>[27]</p>
<p>[28]  inative action parts from mid-level video representations. In CVPR, 2012. M. Rodriguez, J. Ahmed, and M. Shah. Action MACH a spatio-temporal maximum average correlation height filter for action recognition. In CVPR, 2008. S. Satkin and M. Hebert. Modeling the temporal extent of actions. In ECCV, 2010. C. Schuldt, I. Laptev, and B. Caputo. Recognizing human actions: a local SVM approach. In ICPR, 2004. H. Seo and P. Milanfar. Action recognition from one example. PAMI, 33(5), 2011. D. Tran and A. Sorokin. Human activity recognition with metric learning. In ECCV, 2008. P. Viola and M. Jones. Rapid object detection using a boosted cascade of simple features. In CVPR, 2001 . H. Wang, A. Kl¨ aser, C. Schmid, and L. Cheng-Lin. Action Recognition by Dense Trajectories. In CVPR, 2011. H. Wang, M. Ullah, A. Kl¨ aser, I. Laptev, and C. Schmid. Evaluation of local spatio-temporal features for action recognition. In BMVC, 2009. D. Weinland and E. Boyer. Action recognition using exemplar-based embedding. In CVPR, 2008. S.-F. Wong et al. Learning motion categories using both semantic and structural information. In CVPR, 2007. A. Yilmaz and M. Shah. Actions sketch: A novel action representation. In CVPR, 2005. 222666444977</p>
<br/>
<br/><br/><br/></body>
</html>
